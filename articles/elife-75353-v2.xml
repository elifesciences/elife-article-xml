<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD with MathML3 v1.2 20190208//EN"  "JATS-archivearticle1-mathml3.dtd"><article xmlns:ali="http://www.niso.org/schemas/ali/1.0/" xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" article-type="research-article" dtd-version="1.2"><front><journal-meta><journal-id journal-id-type="nlm-ta">elife</journal-id><journal-id journal-id-type="publisher-id">eLife</journal-id><journal-title-group><journal-title>eLife</journal-title></journal-title-group><issn publication-format="electronic" pub-type="epub">2050-084X</issn><publisher><publisher-name>eLife Sciences Publications, Ltd</publisher-name></publisher></journal-meta><article-meta><article-id pub-id-type="publisher-id">75353</article-id><article-id pub-id-type="doi">10.7554/eLife.75353</article-id><article-categories><subj-group subj-group-type="display-channel"><subject>Research Article</subject></subj-group><subj-group subj-group-type="heading"><subject>Neuroscience</subject></subj-group></article-categories><title-group><article-title>Internally generated time in the rodent hippocampus is logarithmically compressed</article-title></title-group><contrib-group><contrib contrib-type="author" corresp="yes" equal-contrib="yes" id="author-259977"><name><surname>Cao</surname><given-names>Rui</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">https://orcid.org/0000-0003-0538-5336</contrib-id><email>caorui.beilia@gmail.com</email><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="fn" rid="equal-contrib1">†</xref><xref ref-type="other" rid="fund2"/><xref ref-type="other" rid="fund3"/><xref ref-type="other" rid="fund4"/><xref ref-type="other" rid="fund1"/><xref ref-type="fn" rid="con1"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" equal-contrib="yes" id="author-262485"><name><surname>Bladon</surname><given-names>John H</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">https://orcid.org/0000-0001-8993-9898</contrib-id><xref ref-type="aff" rid="aff2">2</xref><xref ref-type="fn" rid="equal-contrib1">†</xref><xref ref-type="other" rid="fund5"/><xref ref-type="fn" rid="con2"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" id="author-262486"><name><surname>Charczynski</surname><given-names>Stephen J</given-names></name><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="fn" rid="con3"/><xref ref-type="fn" rid="conf2"/></contrib><contrib contrib-type="author" id="author-140178"><name><surname>Hasselmo</surname><given-names>Michael E</given-names></name><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="fn" rid="con4"/><xref ref-type="fn" rid="conf2"/></contrib><contrib contrib-type="author" id="author-6870"><name><surname>Howard</surname><given-names>Marc W</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">https://orcid.org/0000-0002-1478-1237</contrib-id><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="fn" rid="con5"/><xref ref-type="fn" rid="conf2"/></contrib><aff id="aff1"><label>1</label><institution-wrap><institution-id institution-id-type="ror">https://ror.org/05qwgg493</institution-id><institution>Department of Psychological and Brain Sciences, Boston University</institution></institution-wrap><addr-line><named-content content-type="city">Boston</named-content></addr-line><country>United States</country></aff><aff id="aff2"><label>2</label><institution-wrap><institution-id institution-id-type="ror">https://ror.org/05abbep66</institution-id><institution>Department of Psychology, Brandeis University</institution></institution-wrap><addr-line><named-content content-type="city">Waltham</named-content></addr-line><country>United States</country></aff></contrib-group><contrib-group content-type="section"><contrib contrib-type="editor"><name><surname>Merchant</surname><given-names>Hugo</given-names></name><role>Reviewing Editor</role><aff><institution-wrap><institution-id institution-id-type="ror">https://ror.org/01tmp8f25</institution-id><institution>National Autonomous University of Mexico</institution></institution-wrap><country>Mexico</country></aff></contrib><contrib contrib-type="senior_editor"><name><surname>Gold</surname><given-names>Joshua I</given-names></name><role>Senior Editor</role><aff><institution-wrap><institution-id institution-id-type="ror">https://ror.org/00b30xv10</institution-id><institution>University of Pennsylvania</institution></institution-wrap><country>United States</country></aff></contrib></contrib-group><author-notes><fn fn-type="con" id="equal-contrib1"><label>†</label><p>These authors contributed equally to this work</p></fn></author-notes><pub-date publication-format="electronic" date-type="publication"><day>17</day><month>10</month><year>2022</year></pub-date><pub-date pub-type="collection"><year>2022</year></pub-date><volume>11</volume><elocation-id>e75353</elocation-id><history><date date-type="received" iso-8601-date="2021-11-08"><day>08</day><month>11</month><year>2021</year></date><date date-type="accepted" iso-8601-date="2022-10-14"><day>14</day><month>10</month><year>2022</year></date></history><pub-history><event><event-desc>This manuscript was published as a preprint at .</event-desc><date date-type="preprint" iso-8601-date="2021-10-26"><day>26</day><month>10</month><year>2021</year></date><self-uri content-type="preprint" xlink:href="https://doi.org/10.1101/2021.10.25.465750"/></event></pub-history><permissions><copyright-statement>© 2022, Cao, Bladon et al</copyright-statement><copyright-year>2022</copyright-year><copyright-holder>Cao, Bladon et al</copyright-holder><ali:free_to_read/><license xlink:href="http://creativecommons.org/licenses/by/4.0/"><ali:license_ref>http://creativecommons.org/licenses/by/4.0/</ali:license_ref><license-p>This article is distributed under the terms of the <ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/licenses/by/4.0/">Creative Commons Attribution License</ext-link>, which permits unrestricted use and redistribution provided that the original author and source are credited.</license-p></license></permissions><self-uri content-type="pdf" xlink:href="elife-75353-v2.pdf"/><self-uri content-type="figures-pdf" xlink:href="elife-75353-figures-v2.pdf"/><abstract><p>The Weber-Fechner law proposes that our perceived sensory input increases with physical input on a logarithmic scale. Hippocampal ‘time cells’ carry a record of recent experience by firing sequentially during a circumscribed period of time after a triggering stimulus. Different cells have ‘time fields’ at different delays up to at least tens of seconds. Past studies suggest that time cells represent a compressed timeline by demonstrating that fewer time cells fire late in the delay and their time fields are wider. This paper asks whether the compression of time cells obeys the Weber-Fechner Law. Time cells were studied with a hierarchical Bayesian model that simultaneously accounts for the firing pattern at the trial level, cell level, and population level. This procedure allows separate estimates of the within-trial receptive field width and the across-trial variability. After isolating across-trial variability, time field width increased linearly with delay. Further, the time cell population was distributed evenly along a logarithmic time axis. These findings provide strong quantitative evidence that the neural temporal representation in rodent hippocampus is logarithmically compressed and obeys a neural Weber-Fechner Law.</p></abstract><kwd-group kwd-group-type="author-keywords"><kwd>hippocampus</kwd><kwd>time cell</kwd><kwd>power-law distribution</kwd></kwd-group><kwd-group kwd-group-type="research-organism"><title>Research organism</title><kwd>Rat</kwd></kwd-group><funding-group><award-group id="fund1"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/100014036</institution-id><institution>Multidisciplinary University Research Initiative</institution></institution-wrap></funding-source><award-id>N00014-16-1-2832</award-id><principal-award-recipient><name><surname>Cao</surname><given-names>Rui</given-names></name></principal-award-recipient></award-group><award-group id="fund2"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/100000070</institution-id><institution>National Institute of Biomedical Imaging and Bioengineering</institution></institution-wrap></funding-source><award-id>R01EB022864</award-id><principal-award-recipient><name><surname>Cao</surname><given-names>Rui</given-names></name></principal-award-recipient></award-group><award-group id="fund3"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/100000025</institution-id><institution>National Institute of Mental Health</institution></institution-wrap></funding-source><award-id>R01MH112169</award-id><principal-award-recipient><name><surname>Cao</surname><given-names>Rui</given-names></name></principal-award-recipient></award-group><award-group id="fund4"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/100000025</institution-id><institution>National Institute of Mental Health</institution></institution-wrap></funding-source><award-id>R01MH095297</award-id><principal-award-recipient><name><surname>Cao</surname><given-names>Rui</given-names></name></principal-award-recipient></award-group><award-group id="fund5"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/100000025</institution-id><institution>National Institute of Mental Health</institution></institution-wrap></funding-source><award-id>R01MH132171</award-id><principal-award-recipient><name><surname>Bladon</surname><given-names>John H</given-names></name></principal-award-recipient></award-group><funding-statement>The funders had no role in study design, data collection and interpretation, or the decision to submit the work for publication.</funding-statement></funding-group><custom-meta-group><custom-meta specific-use="meta-only"><meta-name>Author impact statement</meta-name><meta-value>Receptive fields for time in the hippocampus, like receptive fields for retinal space and receptive fields for numerosity, obey the Weber-Fechner law.</meta-value></custom-meta></custom-meta-group></article-meta></front><body><sec id="s1" sec-type="intro"><title>Introduction</title><p>The Weber-Fechner law states that there is a logarithmic relationship between the perceived intensity of a sensory stimulus and the actual intensity (<xref ref-type="bibr" rid="bib25">Fechner, 1860</xref>). The Weber-Fechner law provides a good description of a wide range of phenomena in psychology including perceptual phenomena (<xref ref-type="bibr" rid="bib71">Moore, 2012</xref>), the non-verbal numerosity system (<xref ref-type="bibr" rid="bib26">Feigenson et al., 2004</xref>; <xref ref-type="bibr" rid="bib28">Gallistel and Gelman, 2000</xref>), and psychological studies of time perception (<xref ref-type="bibr" rid="bib79">Rakitin et al., 1998</xref>; <xref ref-type="bibr" rid="bib31">Gibbon et al., 1984</xref>). It has been proposed that these psychological phenomena reflect logarithmically compressed neural representations of time, space, and number (<xref ref-type="bibr" rid="bib27">Gallistel, 1989</xref>; <xref ref-type="bibr" rid="bib21">Dehaene and Brannon, 2011</xref>). It has long been known that the representation of visual space in the retina and early visual cortical regions do not map visual space veridically. Rather, the representation of visual space is logarithmically compressed as a function of distance from the fovea (<xref ref-type="bibr" rid="bib84">Schwartz, 1980</xref>; <xref ref-type="bibr" rid="bib100">Van Essen et al., 1984</xref>; <xref ref-type="bibr" rid="bib32">Glezer, 1965</xref>). Moreover, neurons in monkey parietal cortex recorded during numerosity judgements have receptive fields organized as a function of the logarithm of numerosity (<xref ref-type="bibr" rid="bib72">Nieder and Miller, 2003</xref>). Similar findings are observed in human fMRI (<xref ref-type="bibr" rid="bib11">Cantlon et al., 2006</xref>), suggesting a common system across species (<xref ref-type="bibr" rid="bib73">Nieder and Dehaene, 2009</xref>; <xref ref-type="bibr" rid="bib7">Brannon, 2006</xref>). A recent paper from a cerebellar slice preparation argues that unipolar brush cells form a logarithmically-compressed set of temporal basis functions (<xref ref-type="bibr" rid="bib35">Guo et al., 2021</xref>). This paper asks the question whether hippocampal time cells form a logarithmic code for the time of past events, consistent with a Weber-Fechner representation of past time.</p><sec id="s1-1"><title>Time cells in the hippocampus</title><p>So-called “time cells” in the hippocampus fire sequentially during unfilled delay intervals (<xref ref-type="bibr" rid="bib76">Pastalkova et al., 2008</xref>; <xref ref-type="bibr" rid="bib65">MacDonald et al., 2011</xref>). Because the sequence is reliable across trials, one can reconstruct the time at which the delay began (e.g. <xref ref-type="bibr" rid="bib67">Mau et al., 2018</xref>) and, in many cases, the identity of a stimulus that initiated the delay (<xref ref-type="bibr" rid="bib92">Taxidis et al., 2020</xref>; <xref ref-type="bibr" rid="bib17">Cruzado et al., 2020</xref>) such that at the population level hippocampal time cells construct a record of what happened when (<xref ref-type="fig" rid="fig1">Figure 1a</xref>). It is well-established that time cells do not provide a veridical record of the past; rather the accuracy of the representation of time within the delay decreases with the passage of time (<xref ref-type="bibr" rid="bib56">Kraus et al., 2013</xref>; <xref ref-type="bibr" rid="bib67">Mau et al., 2018</xref>; <xref ref-type="bibr" rid="bib92">Taxidis et al., 2020</xref>). However, unlike the visual system, which clearly shows logarithmic compression, the quantitative form of the compression for time expressed in hippocampal time cells is not known.</p><fig id="fig1" position="float"><label>Figure 1.</label><caption><title>Temporal representation and the Weber-Fechner law.</title><p>(<bold>a</bold>) A compressed timeline of the past. The horizontal line A B C … represents objective reality as the experimenter presents a series of stimuli at regularly spaced intervals. At each moment, memory carries a subjective representation of what happened and when (diagonal line). The time of more recent events are represented more clearly while distant events are less distinguishable from each other, resulting in a compression of the temporal memory. (<bold>b</bold>) A schematic illustration of a neural implementation of a logarithmically-compressed timeline. Each curve corresponds to a time field. When plotted as a function of <inline-formula><mml:math id="inf1"><mml:mi mathvariant="normal">log</mml:mi></mml:math></inline-formula> time (bottom), the receptive fields appear evenly distributed. When plotted as a function of linear time (top), the time-fields stretch out and become less numerous as time passes. (<bold>c</bold>) Heat map of hypothetical time cells firing pattern if time is represented logarithmically. (<bold>insert</bold>) Time-field widths are linearly correlated with time-field peaks. Each row represents the firing pattern of a time cell, sorted by the peak of its time-fields. Dark blue indicates low activity while light yellow indicates high activity. Because time-fields follow logarithmic compression, the sorted peaks form a specific curved line where more time cells fire at the beginning of the delay. In the insert, the time-field widths are plotted as a function of their peaks. Logarithmic compression predicts a linear relationship.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-75353-fig1-v2.tif"/></fig></sec><sec id="s1-2"><title>Quantifying logarithmic compression</title><p>Logarithmic compression leads to two quantitative relationships (<xref ref-type="fig" rid="fig1">Figure 1b and c</xref>) that have been empirically demonstrated in the visual system. First, the size of receptive fields grows linearly with distance from the fovea (<xref ref-type="bibr" rid="bib22">Dumoulin and Wandell, 2008</xref>; <xref ref-type="bibr" rid="bib29">Gattass et al., 1981</xref>). Second, the number of cells with receptive fields in a region of visual space goes down as the inverse of distance from the fovea (<xref ref-type="bibr" rid="bib19">Daniel and Whitteridge, 1961</xref>; <xref ref-type="bibr" rid="bib45">Hubel and Wiesel, 1974</xref>; <xref ref-type="bibr" rid="bib100">Van Essen et al., 1984</xref>). To see why logarithmic compression leads to these two properties, let us suppose that we have a set of time cells that fire in sequence following some event at <inline-formula><mml:math id="inf2"><mml:mrow><mml:mi>t</mml:mi><mml:mo>=</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:math></inline-formula>. Let’s order the time cells according to the time at which they peak firing and call the time at which the <inline-formula><mml:math id="inf3"><mml:mrow><mml:mi>n</mml:mi><mml:mo>⁢</mml:mo><mml:mi>t</mml:mi><mml:mo>⁢</mml:mo><mml:mi>h</mml:mi></mml:mrow></mml:math></inline-formula> time cell fires maximally as <italic>t</italic><sub><italic>n</italic></sub>. We say the time cells form a logarithmically compressed representation of time if<disp-formula id="equ1"><label>(1)</label><mml:math id="m1"><mml:mrow><mml:mi>n</mml:mi><mml:mo>=</mml:mo><mml:msub><mml:mi>log</mml:mi><mml:mrow><mml:mi>b</mml:mi></mml:mrow></mml:msub><mml:mo>⁡</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mfrac><mml:msub><mml:mi>t</mml:mi><mml:mrow><mml:mi>n</mml:mi></mml:mrow></mml:msub><mml:msub><mml:mi>t</mml:mi><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msub></mml:mfrac><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></disp-formula></p><p>where <italic>t</italic><sub>0</sub> is the peak time of the earliest time cell and <inline-formula><mml:math id="inf4"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>b</mml:mi><mml:mo>&gt;</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:mstyle></mml:math></inline-formula> is the base of the logarithm. <xref ref-type="fig" rid="fig1">Figure 1b</xref> gives an example where <inline-formula><mml:math id="inf5"><mml:mrow><mml:msub><mml:mi>t</mml:mi><mml:mn>0</mml:mn></mml:msub><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:math></inline-formula> and the <inline-formula><mml:math id="inf6"><mml:mrow><mml:mi>b</mml:mi><mml:mo>=</mml:mo><mml:mn>2</mml:mn></mml:mrow></mml:math></inline-formula> giving time field peaks at <inline-formula><mml:math id="inf7"><mml:mrow><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mn>2</mml:mn><mml:mo>,</mml:mo><mml:mn>4</mml:mn><mml:mo>,</mml:mo><mml:mrow><mml:mn>8</mml:mn><mml:mo>⁢</mml:mo><mml:mi mathvariant="normal">…</mml:mi></mml:mrow></mml:mrow></mml:math></inline-formula>.</p><p>Both of the quantitative properties of logarithmic compression follow naturally from <xref ref-type="disp-formula" rid="equ1">Equation 1</xref>. <xref ref-type="disp-formula" rid="equ1">Equation 1</xref> implies <inline-formula><mml:math id="inf8"><mml:mrow><mml:msub><mml:mi>t</mml:mi><mml:mi>n</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mrow><mml:msub><mml:mi>t</mml:mi><mml:mn>0</mml:mn></mml:msub><mml:mo>⁢</mml:mo><mml:msup><mml:mi>b</mml:mi><mml:mi>n</mml:mi></mml:msup></mml:mrow></mml:mrow></mml:math></inline-formula> and <inline-formula><mml:math id="inf9"><mml:mrow><mml:msub><mml:mi>t</mml:mi><mml:mrow><mml:mi>n</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mrow><mml:msub><mml:mi>t</mml:mi><mml:mn>0</mml:mn></mml:msub><mml:mo>⁢</mml:mo><mml:msup><mml:mi>b</mml:mi><mml:mrow><mml:mi>n</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:mrow></mml:math></inline-formula> for all choices of <inline-formula><mml:math id="inf10"><mml:mi>n</mml:mi></mml:math></inline-formula>. Notice that the ratio between adjacent time cell peaks is constant (i.e. <inline-formula><mml:math id="inf11"><mml:mi>b</mml:mi></mml:math></inline-formula>) for all <inline-formula><mml:math id="inf12"><mml:mi>n</mml:mi></mml:math></inline-formula>. Let us define <inline-formula><mml:math id="inf13"><mml:msub><mml:mi mathvariant="normal">Δ</mml:mi><mml:mi>n</mml:mi></mml:msub></mml:math></inline-formula> as the distance between <italic>t</italic><sub><italic>n</italic></sub> and <inline-formula><mml:math id="inf14"><mml:msub><mml:mi>t</mml:mi><mml:mrow><mml:mi>n</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:math></inline-formula>. So if the time cell centers are logarithmically compressed (<xref ref-type="disp-formula" rid="equ1">Equation 1</xref>), this implies that the spacing between adjacent time fields goes up proportional to the center of the time field for all <inline-formula><mml:math id="inf15"><mml:mi>n</mml:mi></mml:math></inline-formula>:<disp-formula id="equ2"><label>(2)</label><mml:math id="m2"><mml:mrow><mml:msub><mml:mi mathvariant="normal">Δ</mml:mi><mml:mrow><mml:mi>n</mml:mi></mml:mrow></mml:msub><mml:mo>≡</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mrow><mml:mi>n</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>−</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mrow><mml:mi>n</mml:mi></mml:mrow></mml:msub><mml:mtext> </mml:mtext><mml:mo>=</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mi>b</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">)</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mrow><mml:mi>n</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:math></disp-formula></p><p>The first quantitative relationship describes the width of temporal receptive fields as a function of peak time. Let us write <inline-formula><mml:math id="inf16"><mml:msub><mml:mi>σ</mml:mi><mml:mi>n</mml:mi></mml:msub></mml:math></inline-formula> to describe the width of the temporal receptive field of receptor <inline-formula><mml:math id="inf17"><mml:mi>n</mml:mi></mml:math></inline-formula> that peaks at <italic>t</italic><sub><italic>n</italic></sub>. We have seen that logarithmic compression, <xref ref-type="disp-formula" rid="equ1">Equation 1</xref>, requires that <inline-formula><mml:math id="inf18"><mml:msub><mml:mi mathvariant="normal">Δ</mml:mi><mml:mi>n</mml:mi></mml:msub></mml:math></inline-formula>, the delay between the peaks of adjacent time cells, goes up linearly with peak time, <xref ref-type="disp-formula" rid="equ2">Equation 2</xref>. Consider the overlap between adjacent temporal receptive fields. If <inline-formula><mml:math id="inf19"><mml:msub><mml:mi>σ</mml:mi><mml:mi>n</mml:mi></mml:msub></mml:math></inline-formula> grew more slowly than <inline-formula><mml:math id="inf20"><mml:msub><mml:mi mathvariant="normal">Δ</mml:mi><mml:mi>n</mml:mi></mml:msub></mml:math></inline-formula>, this would mean that the overlap of the temporal receptive fields would decrease with <inline-formula><mml:math id="inf21"><mml:mi>n</mml:mi></mml:math></inline-formula>. In this case the set of receptors would represent longer times with progressively less resolution. Conversely, if <inline-formula><mml:math id="inf22"><mml:msub><mml:mi>σ</mml:mi><mml:mi>n</mml:mi></mml:msub></mml:math></inline-formula> grew more rapidly than <inline-formula><mml:math id="inf23"><mml:msub><mml:mi mathvariant="normal">Δ</mml:mi><mml:mi>n</mml:mi></mml:msub></mml:math></inline-formula>, the overlap of the receptive fields of adjacent time cells would increase with <inline-formula><mml:math id="inf24"><mml:mi>n</mml:mi></mml:math></inline-formula>. Both of these situations are suboptimal. In contrast if <inline-formula><mml:math id="inf25"><mml:msub><mml:mi>σ</mml:mi><mml:mi>n</mml:mi></mml:msub></mml:math></inline-formula> grows like <inline-formula><mml:math id="inf26"><mml:msub><mml:mi mathvariant="normal">Δ</mml:mi><mml:mi>n</mml:mi></mml:msub></mml:math></inline-formula>, the population will cover all parts of the timeline with similar resolution. Because <inline-formula><mml:math id="inf27"><mml:msub><mml:mi mathvariant="normal">Δ</mml:mi><mml:mi>n</mml:mi></mml:msub></mml:math></inline-formula> goes up linearly with <italic>t</italic><sub><italic>n</italic></sub>, these considerations lead to the property of a logarithmic timeline that<disp-formula id="equ3"><label>(3)</label><mml:math id="m3"><mml:mrow><mml:msub><mml:mi>σ</mml:mi><mml:mrow><mml:mi>n</mml:mi></mml:mrow></mml:msub><mml:mo>∝</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mrow><mml:mi>n</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:math></disp-formula></p><p><xref ref-type="disp-formula" rid="equ2">Equation 2</xref> also specifies the relative proportion of time cells that peak at a particular time. Let us assume that there is a very large number of time cells covering a finite interval of time. Let us consider a small neighborhood around a particular value <inline-formula><mml:math id="inf28"><mml:mi>τ</mml:mi></mml:math></inline-formula> within this interval. If the spacing between time field peaks in the region around <inline-formula><mml:math id="inf29"><mml:mi>τ</mml:mi></mml:math></inline-formula> is small, we would find a lot of time cell peaks. Conversely, if the spacing between time field peaks in the region around <inline-formula><mml:math id="inf30"><mml:mi>τ</mml:mi></mml:math></inline-formula> is large, we would find fewer time cells peaking in the neighborhood around <inline-formula><mml:math id="inf31"><mml:mi>τ</mml:mi></mml:math></inline-formula>. <xref ref-type="disp-formula" rid="equ2">Equation 2</xref> says that the spacing between adjacent time cells goes up like <inline-formula><mml:math id="inf32"><mml:mi>τ</mml:mi></mml:math></inline-formula>. It stands to reason that the number of time cells we find in a neighborhood around <inline-formula><mml:math id="inf33"><mml:mi>τ</mml:mi></mml:math></inline-formula> should go down like <inline-formula><mml:math id="inf34"><mml:msup><mml:mi>τ</mml:mi><mml:mrow><mml:mo>-</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msup></mml:math></inline-formula>. Suppose we pick a time cell at random from the population tiling an interval. The probability of finding that that time cell’s peak time is <inline-formula><mml:math id="inf35"><mml:mi>t</mml:mi></mml:math></inline-formula> should obey<disp-formula id="equ4"><label>(4)</label><mml:math id="m4"><mml:mrow><mml:mi>p</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>∝</mml:mo><mml:mrow><mml:msup><mml:mi>t</mml:mi><mml:mrow><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:mrow></mml:math></disp-formula></p><p>where the constant of proportionality depends on the range of times across the population.</p></sec><sec id="s1-3"><title>Are time cells <italic>logarithmically</italic> compressed?</title><p>The goal of this paper is to rigorously test the hypothesis that time cells form a logarithmically-compressed representation of past time by evaluating these two quantitative predictions (<xref ref-type="disp-formula" rid="equ3 equ4">Equation 3 and 4)</xref>. This requires more subtle analyses than in previous time cell studies. For instance, many prior hippocampal time cell studies simply estimate the receptive field width by averaging over trials. It is conceivable that the increase in receptive field width is simply an averaging artifact due to variability in receptive field location across trials (<xref ref-type="fig" rid="fig2">Figure 2b</xref>).</p><fig id="fig2" position="float"><label>Figure 2.</label><caption><title>Schematic illustration of the best fitting hierarchical model.</title><p>(<bold>a</bold>) Graphic diagram of the model. Each node represents a variable in the model; the filled node represents the observed spike-train data and open nodes represent latent variables. Arrows represent relationships between variables and plates indicate whether the variable is estimated at the trial level, cell level, or population level. (<bold>b-c</bold>). Schematic illustration of model fitting for a group of simulated time cells. The model accounts for the firing pattern at individual trials (top rows in <bold>b</bold>), individual cells (bottom rows in <bold>b</bold>) and the population level c. (<bold>b</bold>) Two simulated cells with high (left) <italic>vs</italic> low (right) variability in time field location across trials. The pink dots indicate the spike train and the blue lines indicate the estimated time fields for each trial. At the cell level, the red lines indicate the average firing patterns across trials and the green lines indicate the estimated time fields for the cell from the model. For both the left and right cells, the overall firing pattern is similar and would result in similar time fields averaged over trials. By contrast, fitting at the individual trial level allows the model to estimate the within-trial time field. (<bold>c</bold>) Effect of <inline-formula><mml:math id="inf36"><mml:mi>α</mml:mi></mml:math></inline-formula> on time field distributions. The prior for finding a time field mean <inline-formula><mml:math id="inf37"><mml:mi>M</mml:mi></mml:math></inline-formula> goes like <inline-formula><mml:math id="inf38"><mml:msup><mml:mi>M</mml:mi><mml:mrow><mml:mo mathvariant="normal">-</mml:mo><mml:mi>α</mml:mi></mml:mrow></mml:msup></mml:math></inline-formula>. The yellow line plots the location of the time field peaks, sorted from early to late, for two specific values of <inline-formula><mml:math id="inf39"><mml:mi>α</mml:mi></mml:math></inline-formula>. Left: <inline-formula><mml:math id="inf40"><mml:mrow><mml:mi>α</mml:mi><mml:mo mathvariant="normal">=</mml:mo><mml:mn mathvariant="normal">0</mml:mn></mml:mrow></mml:math></inline-formula> gives a uniform distribution such that all points in the past are equally represented by time cells. Right: <inline-formula><mml:math id="inf41"><mml:mrow><mml:mi>α</mml:mi><mml:mo mathvariant="normal">=</mml:mo><mml:mn mathvariant="normal">1</mml:mn></mml:mrow></mml:math></inline-formula> resulting in logarithmic compression of the time axis.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-75353-fig2-v2.tif"/></fig><p>We recorded from dorsal CA1 during a memory experiment in which rats had to remember the identity of an object across an eight-second delay (<xref ref-type="fig" rid="fig3">Figure 3</xref>). This task is known to produce robust time cells, which we identified using standard methods. We estimated the distribution of time field parameters simultaneously at the levels of individual trials, individual units (across trials), and the population (across units) using a hierarchical Bayesian model (<xref ref-type="fig" rid="fig2">Figure 2</xref>). In hierarchical Bayesian modeling, each level of the hierarchy serves as a prior for parameter estimates at lower levels; parameters of the model at all levels are adjusted to maximize the likelihood of the entire observed dataset (<xref ref-type="bibr" rid="bib58">Lee, 2011</xref>). This approach allows us to separately estimate variability in receptive field centers <italic>across</italic> trials and the width of receptive fields <italic>within</italic> trials and thus test both of the quantative predictions (<xref ref-type="disp-formula" rid="equ3 equ4">Equations 3; 4</xref>) that follow from logarithmic compression.</p><fig-group><fig id="fig3" position="float"><label>Figure 3.</label><caption><title>Data acquisition.</title><p>(<bold>a</bold>) Task paradigm. Rats performed a delayed-matching task wherein each of the four study objects indicated which of the two test objects contained hidden reward. (<bold>b</bold>) Recording sites. The left panel plots example histology sections for animal 1. The red circle indicates the final recording location. The right panel plots the estimated tetrode locations for each rat (coded by different color dots) mapped onto the Paxinos and Watson atlas (1986).</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-75353-fig3-v2.tif"/></fig><fig id="fig3s1" position="float" specific-use="child-fig"><label>Figure 3—figure supplement 1.</label><caption><title>Within trial behavioral variability decreases with delay.</title><p>(<bold>a</bold>) Individual rat’s position across delay. Each dot represents the location at the second of the delay for the corresponding rat, averaged over all trials within one session. Blue indicates early in the delay and yellow indicates late in the delay. Other than Rat 4, there are very little systematic changes in rats’ location across the delay. (<bold>b</bold>) Behavioral variability of both spatial location (top panel) and head wobbles (bottom panel). In both cases, the behavioral variability decreases as time and thus could not account for the increased temporal variability observed within and across trials for later time cells (Black lines illustrate mean across animals, error bars indicate standard error of the mean and grey lines illustrate individual rats).</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-75353-fig3-figsupp1-v2.tif"/></fig></fig-group></sec></sec><sec id="s2" sec-type="results"><title>Results</title><p>Each trial started with rats exploring an object for 3 s, followed by an 8 s delay during which rats ran on a treadmill (<xref ref-type="fig" rid="fig3">Figure 3a</xref>). After the delay, rats were presented with two terra cotta pots with unique odors and digging media. The identity of the object the animal explored at the beginning of the delay specified which of the pots contained reward. Rats learned the memory task well with accuracy between 70 and 80%. There was very little variability in positions or other measurable changes in behavior after the first two seconds of the delay (<xref ref-type="fig" rid="fig3s1">Figure 3—figure supplement 1</xref>, detailed analysis in Supplemental section S1).</p><p>Among the total of 625 pyramidal CA1 units we recorded from the four animals, 159 units (30/87 for rat 1; 39/134 for rat 2; 32/111 for rat 3; 58/293 for rat 4) were classified as time cells using previous methods (<xref ref-type="bibr" rid="bib95">Tiganj et al., 2018</xref>). The proportion of time cells is similar to previous studies using similar methods (e.g. <xref ref-type="bibr" rid="bib83">Salz et al., 2016</xref>). Fourteen time cells whose peak times were considered too close to the boundaries of the delay interval (see Materials and methods for details) were removed. Because hierarchical Bayesian models estimate across-trial variability separately from within-trial variability, another 14 units were removed for low trial-count (&lt;20 trials). The detailed procedures used to select time cells for further model estimation can be found in the Materials and methods section. A total of 131 robust time cells were considered further for the hierarchical Bayesian analyses.</p><p>Below we first briefly describe the hierarchical Bayesian models considered to describe the firing patterns of time cells across trial, cell and population levels (‘Estimating time fields …’). Then we report the model results of these models in two sections. The section titled ‘The representation of time varies …’ focuses on variability in time fields across trials. The following section (‘Hippocampal time cells form a …’) focuses on the properties at the population level and provides direct tests of the hypothesis that the hippocampal time code is logarithmically compressed.</p><sec id="s2-1"><title>Estimating time fields with hierarchical Bayesian method</title><p>For expository purposes, we first sketch out the model that best describes the time fields across all levels (<xref ref-type="fig" rid="fig2">Figure 2</xref>). Note that we tested alternative assumptions at every level of the hierarchy (see <xref ref-type="table" rid="table1">Table 1</xref> for reference) and evaluated the models via Widely Applicable Information Criterion (<xref ref-type="bibr" rid="bib101">Watanabe and Opper, 2010</xref>). We refer to the best-fitting model as the ‘Main Model’. The detailed fitting procedures for all models can be found in the Materials and methods section.</p><table-wrap id="table1" position="float"><label>Table 1.</label><caption><title>WAIC of the Main Model and alternative models.</title></caption><table frame="hsides" rules="groups"><thead><tr><th align="left" valign="top"/><th align="left" valign="top">Time field</th><th align="left" valign="top">Trial variability</th><th align="left" valign="top">Population</th><th align="left" valign="top">WAIC</th></tr></thead><tbody><tr><td align="left" valign="top">Main Model</td><td align="left" valign="top">Gaussian</td><td align="left" valign="top">Location shift</td><td align="left" valign="top">Power-law</td><td align="char" char="plus" valign="top">1.4e+18</td></tr><tr><td align="left" valign="top">Log-normal Time Field Model</td><td align="left" valign="top">Log-normal</td><td align="left" valign="top">-</td><td align="left" valign="top">-</td><td align="char" char="plus" valign="top">4.8e+19</td></tr><tr><td align="left" valign="top">Alternative Trial Vary Model</td><td align="left" valign="top">-</td><td align="left" valign="top">Width vary</td><td align="left" valign="top">-</td><td align="char" char="plus" valign="top">6.3e+27</td></tr><tr><td align="left" valign="top">Exponential Compression Model</td><td align="left" valign="top">-</td><td align="left" valign="top">-</td><td align="left" valign="top">Exponential</td><td align="char" char="plus" valign="top">5.2e+26</td></tr><tr><td align="left" valign="top">Weibull Compression Model</td><td align="left" valign="top">-</td><td align="left" valign="top">-</td><td align="left" valign="top">Weibull</td><td align="char" char="plus" valign="top">1.7e+25</td></tr></tbody></table><table-wrap-foot><fn><p>Note: - indicates the same assumption as the Main Model.</p></fn></table-wrap-foot></table-wrap><p>Unlike previous time cell studies that required a single time field across all trials, the models we tested allow for separate time field estimation for each trial. Given <inline-formula><mml:math id="inf42"><mml:mi>m</mml:mi></mml:math></inline-formula> spike times <inline-formula><mml:math id="inf43"><mml:mrow><mml:msub><mml:mi>t</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>⁢</mml:mo><mml:mi mathvariant="normal">…</mml:mi><mml:mo>⁢</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mi>m</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula> on trial <inline-formula><mml:math id="inf44"><mml:mi>i</mml:mi></mml:math></inline-formula> for a time cell, the model assumes the observed spikes are a mixture of two distributions. A portion <italic>a</italic><sub>1</sub> of spikes is sampled from a Gaussian-shaped time field centered at <inline-formula><mml:math id="inf45"><mml:msub><mml:mi>μ</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:math></inline-formula> with standard deviation <inline-formula><mml:math id="inf46"><mml:msub><mml:mi>σ</mml:mi><mml:mi>w</mml:mi></mml:msub></mml:math></inline-formula>. The remaining proportion, <inline-formula><mml:math id="inf47"><mml:mrow><mml:mn>1</mml:mn><mml:mo>-</mml:mo><mml:msub><mml:mi>a</mml:mi><mml:mn>1</mml:mn></mml:msub></mml:mrow></mml:math></inline-formula> is sampled from a uniform distribution over the length of the entire delay <inline-formula><mml:math id="inf48"><mml:mi>l</mml:mi></mml:math></inline-formula>. Therefore the probability that one of the spikes happened is at time <italic>t</italic><sub><italic>j</italic></sub> is<disp-formula id="equ5"><label>(5)</label><mml:math id="m5"><mml:mrow><mml:mi>p</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:msub><mml:mi>a</mml:mi><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>μ</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>σ</mml:mi><mml:mrow><mml:mi>w</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:msub><mml:mi>a</mml:mi><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mrow><mml:mi mathvariant="script">N</mml:mi></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:msub><mml:mi>μ</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:mspace width="thinmathspace"/><mml:msubsup><mml:mi>σ</mml:mi><mml:mrow><mml:mi>w</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup><mml:mo stretchy="false">)</mml:mo><mml:mo>+</mml:mo><mml:mfrac><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:msub><mml:mi>a</mml:mi><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mi>l</mml:mi></mml:mfrac></mml:mrow></mml:math></disp-formula></p><p>An alternative model assumes that the time field follows a log-normal distribution (“Log-normal Time Field Model”, <xref ref-type="table" rid="table1">Table 1</xref>).</p><p>Note that this approach assumes that each spike is independently sampled from the mixture of distributions rather than explicitly modeling a changing firing rate. This approach ignores dependencies in spike times in favor of a simplified time field estimation that feeds into the next levels of the hierarchical model. This simplified trial-level assumption is adequate for characterizing the distribution of time field parameters. Given the independent sampling assumption, the likelihood of producing the observed set of spikes is:<disp-formula id="equ6"><label>(6)</label><mml:math id="m6"><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="script">L</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:munderover><mml:mo>∏</mml:mo><mml:mrow><mml:mi>j</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>m</mml:mi></mml:mrow></mml:munderover><mml:mi>p</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:msub><mml:mi>a</mml:mi><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>μ</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msubsup><mml:mi>σ</mml:mi><mml:mrow><mml:mi>w</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></disp-formula></p><p>To account for variability across trial, <inline-formula><mml:math id="inf49"><mml:msub><mml:mi>μ</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:math></inline-formula> is assumed to be distributed normally across trials:<disp-formula id="equ7"><label>(7)</label><mml:math id="m7"><mml:mrow><mml:msub><mml:mi>μ</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>∼</mml:mo><mml:mrow><mml:mi mathvariant="script">N</mml:mi></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>M</mml:mi><mml:mo>,</mml:mo><mml:mspace width="thinmathspace"/><mml:msubsup><mml:mi>σ</mml:mi><mml:mrow><mml:mi>t</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></disp-formula></p><p>Therefore, the mean <inline-formula><mml:math id="inf50"><mml:mi>M</mml:mi></mml:math></inline-formula> of this distribution estimates each time cell’s average peak time. The standard deviation of this distribution, <inline-formula><mml:math id="inf51"><mml:msub><mml:mi>σ</mml:mi><mml:mi>t</mml:mi></mml:msub></mml:math></inline-formula>, estimates the variability of that cell’s time field across trials. By separating the trial variability <inline-formula><mml:math id="inf52"><mml:msub><mml:mi>σ</mml:mi><mml:mi>t</mml:mi></mml:msub></mml:math></inline-formula> from the estimate of the time field width within trial <inline-formula><mml:math id="inf53"><mml:msub><mml:mi>σ</mml:mi><mml:mi>w</mml:mi></mml:msub></mml:math></inline-formula>, we are able to investigate the relationship between <inline-formula><mml:math id="inf54"><mml:msub><mml:mi>σ</mml:mi><mml:mi>w</mml:mi></mml:msub></mml:math></inline-formula> and time field peak <inline-formula><mml:math id="inf55"><mml:mi>M</mml:mi></mml:math></inline-formula> as logarithmic compression predicts that time field width within a trial goes up linearly with time field center. We also considered the possibility that the width of time fields varies across trials rather than the mean (‘Alternative Trial Vary Model’ in <xref ref-type="table" rid="table1">Table 1</xref>).</p><p>Finally, the time field locations <inline-formula><mml:math id="inf56"><mml:mi>M</mml:mi></mml:math></inline-formula> across the CA1 population was assumed to follow a power-law distribution:<disp-formula id="equ8"><label>(8)</label><mml:math id="m8"><mml:mrow><mml:mi>P</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>M</mml:mi><mml:mo>=</mml:mo><mml:mi>τ</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>∝</mml:mo><mml:mrow><mml:msup><mml:mi>τ</mml:mi><mml:mrow><mml:mo>−</mml:mo><mml:mi>α</mml:mi></mml:mrow></mml:msup></mml:mrow></mml:mrow></mml:math></disp-formula></p><p>The Main Model returns the posterior distribution of <inline-formula><mml:math id="inf57"><mml:mi>α</mml:mi></mml:math></inline-formula> given the data. That means the Main Model is capable of observing logarithmic compression—a tight posterior distribution around <inline-formula><mml:math id="inf58"><mml:mrow><mml:mi>α</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:math></inline-formula>—but also other hypotheses. For instance, <inline-formula><mml:math id="inf59"><mml:mrow><mml:mi>α</mml:mi><mml:mo>=</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:math></inline-formula> corresponds to a uniform distribution of time field locations (<xref ref-type="fig" rid="fig2">Figure 2c</xref>); every other positive real number is also possible. We considered two alternative forms of distributions for the locations of time field centers across the population (‘Exponential Compression Model’ and ‘Weibull Compression Model’, <xref ref-type="table" rid="table1">Table 1</xref>).</p><p>The Main Model provided the best quantitative description of the data (see <xref ref-type="table" rid="table1">Table 1</xref>). Accordingly, the Results section focuses on the parameters from the Main Model with the results of alternative models noted where appropriate. Note that while the results are presented sequentially from the trial level to the population level, the parameters of each model were estimated using data from all levels of description simultaneously. Although the Bayesian analysis returns posterior distributions for all of the parameters it estimates, to test hypotheses about relationships between parameters we simply considered the mean of the posterior distributions as the model’s estimate and performed inferential statistics on those means.</p></sec><sec id="s2-2"><title>The representation of time varies from trial to trial and the variance increases with the delay</title><p>Example fits of individual cells across trials for the Main Model can be found in <xref ref-type="fig" rid="fig4">Figure 4a</xref> (see also <xref ref-type="fig" rid="fig4s1">Figure 4—figure supplement 1</xref>). It is apparent that firing patterns change from trial to trial. The model captures trial variability by providing trial-level estimates of <inline-formula><mml:math id="inf60"><mml:msub><mml:mi>μ</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:math></inline-formula> on each trial <inline-formula><mml:math id="inf61"><mml:mi>i</mml:mi></mml:math></inline-formula> and by quantifying the across-trial variability for each cell <italic>via</italic> <inline-formula><mml:math id="inf62"><mml:msub><mml:mi>σ</mml:mi><mml:mi>t</mml:mi></mml:msub></mml:math></inline-formula>.</p><fig-group><fig id="fig4" position="float"><label>Figure 4.</label><caption><title>Across-trial variability measured by the Main Model.</title><p>(<bold>a</bold>) Three representative time cells with different temporal receptive fields. Rasters show estimated time fields for each trial as a blue line. In the bottom plots, the red line represents the peristimulus-time histogram averaged over trials. The green line indicates the estimated time field with within-trial time field width (<inline-formula><mml:math id="inf63"><mml:msub><mml:mi>σ</mml:mi><mml:mi>w</mml:mi></mml:msub></mml:math></inline-formula>, shown above). Across-trial variability in the location of the time field is estimated separately. (<bold>b</bold>) Trial-to-trial variability in time field location is correlated with the timing of events early in the trial. Several events happen at the beginning of each trial; the door opens to allow access to the treadmill, the animal steps onto the treadmill and then breaks a beam at the middle of the treadmill. The last event is used as time zero in this study. The y-axis in these graphs shows the Pearson correlation between time field peak location and the estimate of the time rats stepped on the treadmill on each trial. Each dot represent one time cell, shown separately for each rat. The correlation is significantly above zero for rats 2, 3, and 4. (<bold>c</bold>) Estimated trial variability <inline-formula><mml:math id="inf64"><mml:msub><mml:mi>σ</mml:mi><mml:mi>t</mml:mi></mml:msub></mml:math></inline-formula> as a function of the peak firing time <inline-formula><mml:math id="inf65"><mml:mi>M</mml:mi></mml:math></inline-formula>. The line shows the best-fitting regression (see text for details).</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-75353-fig4-v2.tif"/></fig><fig id="fig4s1" position="float" specific-use="child-fig"><label>Figure 4—figure supplement 1.</label><caption><title>Additional example time cell fits.</title><p>Format is the same as <xref ref-type="fig" rid="fig2">Figure 2a</xref>.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-75353-fig4-figsupp1-v2.tif"/></fig></fig-group><p>There are two novel findings reported in this section. First, the model was able to capture the significant variability in time field locations across trials. Model parameters were correlated with the timing of events at the beginning of the delay for each trial. This suggests that at least some part of the measured across-trial variability resulted from the variability in the behaviors at the beginning of the trial. Second, we found that the across-trial variability changed systematically as a function of the corresponding time field peak. This suggests that compression observed in previous studies of time cells is probably at least partially attributable to a trial averaging artifact. As we will see below, there is also robust evidence for compression that is not attributable to a trial averaging effect.</p><sec id="s2-2-1"><title>Variability in the timing of events early in the trial accounts for some neural trial variability</title><p>The Main Model revealed a high degree of variability in the estimated time field location from trial to trial. <xref ref-type="fig" rid="fig4">Figure 4a</xref> plots representative single units with trial-by-trial model fits for cells that fired at different times during the delay interval. One factor that could account for the observed trial variability is rats’ behaviors near to the initiation of the delay. After studying the stimuli for 3 s, animals were allowed to enter the treadmill, reach the end of the treadmill and start running on the treadmill. For each trial, the start of the delay was defined as the time when the animals first broke the laser beam pointing at the middle of the treadmill. However, it is possible that time cell sequence could be initiated by other events. Therefore the time gap between each event, which varies from trial to trial, could impact the initiation of the time cells sequences and result in an imperfect match to the clock time we measured. For some time cells, we found the time difference between the rat entering the treadmill and breaking the laser beam was positively correlated with the location of time field peak from trial to trial. The Pearson correlation score for each time cell is plotted in <xref ref-type="fig" rid="fig4">Figure 4b</xref>. The effect was particularly significant for rats 2, 3, and 4. We performed Bayesian one sample t-test using JASP (<xref ref-type="bibr" rid="bib49">JASP Team, 2022</xref>) and found the mean correlation scores were significantly higher than 0 (<inline-formula><mml:math id="inf66"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>B</mml:mi><mml:msub><mml:mi>F</mml:mi><mml:mrow><mml:mn>10</mml:mn></mml:mrow></mml:msub><mml:mo>&gt;</mml:mo><mml:mn>100</mml:mn></mml:mrow></mml:mstyle></mml:math></inline-formula> for all three rats). Note we did not observe this effect for all animals as the same Bayesian one-sample t-test came out mildly in favor of the null hypothesis (<inline-formula><mml:math id="inf67"><mml:mrow><mml:mrow><mml:mi>B</mml:mi><mml:mo>⁢</mml:mo><mml:msub><mml:mi>F</mml:mi><mml:mn>10</mml:mn></mml:msub></mml:mrow><mml:mo>=</mml:mo><mml:mn>.64</mml:mn></mml:mrow></mml:math></inline-formula>) for rat 1. We conclude that estimates of time field location across trials are a meaningful estimate of variability across trials and at least some of the variability can be accounted by the behavioral variability at the beginning of each trial. Because not all animals showed correlations with other events, and because the flag associated with breaking the laser beam is free of measurement error, we continue to measure time relative to the event of the animal breaking the laser beam on the treadmill.</p><p>Additionally, the effect of the initial event variability, quantified in the form of Pearson correlation value, decreases for time cells with centers later in the delay for rats 2, 3, and 4 (<xref ref-type="fig" rid="fig4">Figure 4b</xref>). To quantify this observation, we divided time cells into “early” <italic>vs</italic> “late” groups based on whether the average time field peak <inline-formula><mml:math id="inf68"><mml:mi>M</mml:mi></mml:math></inline-formula> was less than or greater than 2 s. The correlation was significantly higher for the early group as assessed by a Bayesian two-sample t-test over the null hypothesis that correlation in early group ≤ late group (<inline-formula><mml:math id="inf69"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>B</mml:mi><mml:msub><mml:mi>F</mml:mi><mml:mrow><mml:mn>10</mml:mn></mml:mrow></mml:msub><mml:mo>&gt;</mml:mo><mml:mn>10</mml:mn></mml:mrow></mml:mstyle></mml:math></inline-formula> for rat 2 and 4; <inline-formula><mml:math id="inf70"><mml:mrow><mml:mrow><mml:mi>B</mml:mi><mml:mo>⁢</mml:mo><mml:msub><mml:mi>F</mml:mi><mml:mn>10</mml:mn></mml:msub></mml:mrow><mml:mo>=</mml:mo><mml:mn>3</mml:mn></mml:mrow></mml:math></inline-formula> for rat 3).</p></sec><sec id="s2-2-2"><title>Estimated across-trial variability changes with delay</title><p>The Main Model separately estimates the within-trial variability—<inline-formula><mml:math id="inf71"><mml:msub><mml:mi>σ</mml:mi><mml:mi>w</mml:mi></mml:msub></mml:math></inline-formula>, the width of the time field within trial—and across-trial variability, <inline-formula><mml:math id="inf72"><mml:msub><mml:mi>σ</mml:mi><mml:mi>t</mml:mi></mml:msub></mml:math></inline-formula>. Discussion of within-trial variability is postponed to the next subsection. For each time cell <inline-formula><mml:math id="inf73"><mml:msub><mml:mi>σ</mml:mi><mml:mi>t</mml:mi></mml:msub></mml:math></inline-formula> quantifies how much the time field shifts across trials. Although the logarithmic compression hypothesis makes quantitative prediction about time fields within a trial (<xref ref-type="disp-formula" rid="equ3">Equation 3</xref>; <xref ref-type="disp-formula" rid="equ4">Equation 4</xref>), it is agnostic about the question of how time is represented <italic>across</italic> trials. Nonetheless, it is important to quantify across-trial variability in the attempt to isolate the effect of within-trial variability on trial-averaged time fields. The model identified substantial across-trial variability. The median value of <inline-formula><mml:math id="inf74"><mml:msub><mml:mi>σ</mml:mi><mml:mi>t</mml:mi></mml:msub></mml:math></inline-formula> was 0.69 s. Forty-five out of 131 time cells showed an across-trial standard deviation of more than 1 s. The model’s estimate of across-trial variability was larger than its estimate of the width of the time field for a substantial majority of time cells (<inline-formula><mml:math id="inf75"><mml:mrow><mml:mn>93</mml:mn><mml:mo>/</mml:mo><mml:mn>131</mml:mn></mml:mrow></mml:math></inline-formula>, <inline-formula><mml:math id="inf76"><mml:mrow><mml:mrow><mml:msup><mml:mi>χ</mml:mi><mml:mn>2</mml:mn></mml:msup><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mo>=</mml:mo><mml:mn>22.3</mml:mn></mml:mrow></mml:math></inline-formula>, <inline-formula><mml:math id="inf77"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>p</mml:mi><mml:mo>&lt;</mml:mo><mml:mn>.001</mml:mn></mml:mrow></mml:mstyle></mml:math></inline-formula>).</p></sec><sec id="s2-2-3"><title>Across-trial variability changes over the delay interval</title><p>There was also a systematic change in across-trial variability as a function of the peak location (<xref ref-type="fig" rid="fig4">Figure 4c</xref>). There are a number of uninteresting factors that could affect this quantitative relationship. For instance, for a time cell with peak near the edge of the delay interval, it would be more difficult to estimate a large value of <inline-formula><mml:math id="inf78"><mml:msub><mml:mi>σ</mml:mi><mml:mi>t</mml:mi></mml:msub></mml:math></inline-formula> because the distribution would be cut off by the edge of the delay. With this caveat in mind, we applied regression analysis of trial variability <inline-formula><mml:math id="inf79"><mml:msub><mml:mi>σ</mml:mi><mml:mi>t</mml:mi></mml:msub></mml:math></inline-formula> as a function of the time field peak <inline-formula><mml:math id="inf80"><mml:mi>M</mml:mi></mml:math></inline-formula>, including an intercept, linear, and quadratic terms. All three coefficients were significant (intercept, mean ± SE: <inline-formula><mml:math id="inf81"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mo>−</mml:mo><mml:mn>0.33</mml:mn><mml:mo>±</mml:mo><mml:mn>0.06</mml:mn></mml:mrow></mml:mstyle></mml:math></inline-formula>, <inline-formula><mml:math id="inf82"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>p</mml:mi><mml:mo>&lt;</mml:mo><mml:mn>.001</mml:mn></mml:mrow></mml:mstyle></mml:math></inline-formula>; slope: <inline-formula><mml:math id="inf83"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mn>0.84</mml:mn><mml:mo>±</mml:mo><mml:mn>0.05</mml:mn></mml:mrow></mml:mstyle></mml:math></inline-formula>, <inline-formula><mml:math id="inf84"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>p</mml:mi><mml:mo>&lt;</mml:mo><mml:mn>.001</mml:mn></mml:mrow></mml:mstyle></mml:math></inline-formula>; quadratic term: <inline-formula><mml:math id="inf85"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mo>−</mml:mo><mml:mn>0.11</mml:mn><mml:mo>±</mml:mo><mml:mn>0.01</mml:mn></mml:mrow></mml:mstyle></mml:math></inline-formula>, <inline-formula><mml:math id="inf86"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>p</mml:mi><mml:mo>&lt;</mml:mo><mml:mn>.001</mml:mn></mml:mrow></mml:mstyle></mml:math></inline-formula>). We also applied Bayesian linear regression and found that the model with both linear and quadratic term was the best model (<inline-formula><mml:math id="inf87"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>B</mml:mi><mml:msub><mml:mi>F</mml:mi><mml:mrow><mml:mi>M</mml:mi></mml:mrow></mml:msub><mml:mo>&gt;</mml:mo><mml:mn>100</mml:mn></mml:mrow></mml:mstyle></mml:math></inline-formula> over the null, the linear term only, and the quadratic term models). We conclude from this that variability in the location of the time field across trials varies systematically with the average location <inline-formula><mml:math id="inf88"><mml:mi>M</mml:mi></mml:math></inline-formula>.</p><p>Because variability in the location of a time field across trials is substantial and varies systematically with time within the delay, quantitative estimates of time field width as a function of time field center should control for this trial variability. Fortunately, the hierarchical Bayesian analysis provides separate estimates of within- and between-trial variability. We present results for time field width isolated from trial averaging effects in the next subsection.</p></sec></sec><sec id="s2-3"><title>Hippocampal time cells form a logarithmically compressed timeline of the past</title><p>After accounting for across-trial variability, we are now able to study the form of temporal compression of the time code within a trial. If populations of time cells represent a compressed timeline, we should observe fewer units with larger values of <inline-formula><mml:math id="inf89"><mml:mi>M</mml:mi></mml:math></inline-formula> and the time field width <inline-formula><mml:math id="inf90"><mml:msub><mml:mi>σ</mml:mi><mml:mi>w</mml:mi></mml:msub></mml:math></inline-formula> should increase with <inline-formula><mml:math id="inf91"><mml:mi>M</mml:mi></mml:math></inline-formula>. This would mean that the temporal resolution carried by the population is reduced as the event fades into the past. If the population is compressed logarithmically, this makes two quantitative predictions. First, time field width <inline-formula><mml:math id="inf92"><mml:msub><mml:mi>σ</mml:mi><mml:mi>w</mml:mi></mml:msub></mml:math></inline-formula> should increase linearly with the delay <inline-formula><mml:math id="inf93"><mml:mi>M</mml:mi></mml:math></inline-formula> (<xref ref-type="disp-formula" rid="equ3">Equation 3</xref>). Second, time field peaks <inline-formula><mml:math id="inf94"><mml:mi>M</mml:mi></mml:math></inline-formula> should be distributed according to a power-law with an exponent of 1 (<xref ref-type="disp-formula" rid="equ4">Equation 4</xref>).</p><sec id="s2-3-1"><title>Time field width increases linearly with the delay</title><p><xref ref-type="fig" rid="fig5">Figure 5b</xref> plots within-trial time field width <inline-formula><mml:math id="inf95"><mml:msub><mml:mi>σ</mml:mi><mml:mi>w</mml:mi></mml:msub></mml:math></inline-formula> as a function of the peak location of the time field <inline-formula><mml:math id="inf96"><mml:mi>M</mml:mi></mml:math></inline-formula> for each time cell. Examination of this plot suggests that time field width increases with delay, even after taking across-trial variability into consideration. To quantify this relationship, we fit a regression analysis of time field width <inline-formula><mml:math id="inf97"><mml:msub><mml:mi>σ</mml:mi><mml:mi>w</mml:mi></mml:msub></mml:math></inline-formula> as a function of time field peaks <inline-formula><mml:math id="inf98"><mml:mi>M</mml:mi></mml:math></inline-formula> time field width including constant, linear, and quadratic terms. Only the the linear term reached statistical significance (<inline-formula><mml:math id="inf99"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mn>0.14</mml:mn><mml:mo>±</mml:mo><mml:mn>0.05</mml:mn></mml:mrow></mml:mstyle></mml:math></inline-formula>, <inline-formula><mml:math id="inf100"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>p</mml:mi><mml:mo>=</mml:mo><mml:mn>0.01</mml:mn></mml:mrow></mml:mstyle></mml:math></inline-formula>, <inline-formula><mml:math id="inf101"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msubsup><mml:mi>R</mml:mi><mml:mrow><mml:mi>a</mml:mi><mml:mi>d</mml:mi><mml:mi>j</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup><mml:mo>=</mml:mo><mml:mn>0.24</mml:mn></mml:mrow></mml:mstyle></mml:math></inline-formula>). The intercept (<inline-formula><mml:math id="inf102"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mn>0.11</mml:mn><mml:mo>±</mml:mo><mml:mn>0.06</mml:mn></mml:mrow></mml:mstyle></mml:math></inline-formula>, <inline-formula><mml:math id="inf103"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>p</mml:mi><mml:mo>&lt;</mml:mo><mml:mn>.07</mml:mn></mml:mrow></mml:mstyle></mml:math></inline-formula>) and quadratic (<inline-formula><mml:math id="inf104"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mo>−</mml:mo><mml:mn>0.007</mml:mn><mml:mo>±</mml:mo><mml:mn>0.008</mml:mn></mml:mrow></mml:mstyle></mml:math></inline-formula>, <inline-formula><mml:math id="inf105"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>p</mml:mi><mml:mo>&gt;</mml:mo><mml:mn>0.4</mml:mn></mml:mrow></mml:mstyle></mml:math></inline-formula>) terms were small and neither reached traditional levels of significance. A Bayesian linear regression analysis showed the best model to be one with only the linear term (<inline-formula><mml:math id="inf106"><mml:mrow><mml:mrow><mml:mi>B</mml:mi><mml:mo>⁢</mml:mo><mml:msub><mml:mi>F</mml:mi><mml:mi>M</mml:mi></mml:msub></mml:mrow><mml:mo>=</mml:mo><mml:mn>9.756</mml:mn></mml:mrow></mml:math></inline-formula> over null, quadratic term only or quadratic plus linear terms models). The reliable linear term indicates that time field width increases with the peak time even after controlling for trial-averaging effects.</p><fig-group><fig id="fig5" position="float"><label>Figure 5.</label><caption><title>Log-compressed timeline.</title><p>(<bold>a</bold>) Normalized firing rate of time cells sorted by peak time. Yellow indicates high activity and blue indicates low activity. The dashed white line shows the peak times that would be expected if time cells uniformly sampled <inline-formula><mml:math id="inf107"><mml:mi mathvariant="normal">log</mml:mi></mml:math></inline-formula> time. Equivalently, the dashed white line shows the peak times that would result if the probability of observing a peak time <inline-formula><mml:math id="inf108"><mml:mi>M</mml:mi></mml:math></inline-formula> went down like <inline-formula><mml:math id="inf109"><mml:msup><mml:mi>M</mml:mi><mml:mrow><mml:mo mathvariant="normal">-</mml:mo><mml:mn mathvariant="normal">1</mml:mn></mml:mrow></mml:msup></mml:math></inline-formula> corresponding to <inline-formula><mml:math id="inf110"><mml:mrow><mml:mi>α</mml:mi><mml:mo mathvariant="normal">=</mml:mo><mml:mn mathvariant="normal">1.0</mml:mn></mml:mrow></mml:math></inline-formula>. (<bold>b</bold>) The width of the within-trial time field as a function of the peak firing time. The line shows the corresponding linear fit (see text for details). (<bold>c</bold>) The posterior distribution of the power-law exponent parameter <inline-formula><mml:math id="inf111"><mml:mi>α</mml:mi></mml:math></inline-formula>. The blue line on the left marks zero, corresponding to a uniform distribution. The red line marks the mean (.93) of the posterior. (<bold>d</bold>) Cumulative distribution function (CDF) of time field peaks <inline-formula><mml:math id="inf112"><mml:mi>M</mml:mi></mml:math></inline-formula> plotted on a <inline-formula><mml:math id="inf113"><mml:mi mathvariant="normal">log</mml:mi></mml:math></inline-formula> scale. The CDF function forms a straight line only when <inline-formula><mml:math id="inf114"><mml:mrow><mml:mi>α</mml:mi><mml:mo mathvariant="normal">=</mml:mo><mml:mn mathvariant="normal">1</mml:mn></mml:mrow></mml:math></inline-formula>, corresponding to logarithmic compression of the time axis. The straight red line has the same slope as the best fitting linear regression function to the CDF and is included to facilitate visual inspection of the cumulative function.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-75353-fig5-v2.tif"/></fig><fig id="fig5s1" position="float" specific-use="child-fig"><label>Figure 5—figure supplement 1.</label><caption><title>Additional analysis comparing the maximum likelihood fits and the hierarchical Bayesian fits.</title><p>(<bold>a-b</bold>) Maximum likelihood estimated time field peaks (<bold>a</bold>) and width (<bold>b</bold>) as a function of their corresponding estimation from the Hierarchical Bayesian method (x-axis). Points on the diagonal line are units where the two values are the same. Points above the diagonal line are units the higher values in the maximum likelihood fits. (<bold>c</bold>) Maximum likelihood estimated time field peaks plotted on a log-scale (x-axis), sorted on the order of their peak time location (y-axis). Pink line represents linear fit on log data excluding extremely early time cells (prior to 0.25 s). (<bold>d</bold>) Maximum likelihood estimated time field widths as a function of their time field peaks.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-75353-fig5-figsupp1-v2.tif"/></fig></fig-group><p>Logarithmic compression predicts a precisely linear relationship between within-trial time field width <inline-formula><mml:math id="inf115"><mml:msub><mml:mi>σ</mml:mi><mml:mi>w</mml:mi></mml:msub></mml:math></inline-formula> and peak time <inline-formula><mml:math id="inf116"><mml:mi>M</mml:mi></mml:math></inline-formula>. While there was no evidence for a quadratic term, the intercept did approach significance. There is no question, however, that the curve cannot literally go to the point (0,0). For time cells to peak at <inline-formula><mml:math id="inf117"><mml:mrow><mml:mi>M</mml:mi><mml:mo>=</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:math></inline-formula> it would require that hippocampal time cells respond instantaneously, which is not physically possible. Moreover, it would be impossible to estimate a <inline-formula><mml:math id="inf118"><mml:msub><mml:mi>σ</mml:mi><mml:mi>w</mml:mi></mml:msub></mml:math></inline-formula> approaching zero—it makes no sense to estimate a standard deviation without more than one spike. As it is, even if the intercept had reached significance at the upper limit of the confidence interval we observed (on the order of a few hundred ms), we would still conclude that the intercept is small in magnitude relative to the range of delay times exhibited by time cells in this experiment.</p></sec></sec><sec id="s2-4"><title>Time cell peaks are distributed according to log compression</title><p><xref ref-type="fig" rid="fig5">Figure 5a</xref> shows the firing rate, averaged over trials, for each of the time cells sorted by their estimated peak time <inline-formula><mml:math id="inf119"><mml:mi>M</mml:mi></mml:math></inline-formula>. Consistent with many prior studies of time cells (e.g. <xref ref-type="bibr" rid="bib67">Mau et al., 2018</xref>; <xref ref-type="bibr" rid="bib17">Cruzado et al., 2020</xref>), the central ridge appears curved. The curvature is a sign of a non-uniform distribution of time field peaks <inline-formula><mml:math id="inf120"><mml:mi>M</mml:mi></mml:math></inline-formula>; if <inline-formula><mml:math id="inf121"><mml:mi>M</mml:mi></mml:math></inline-formula> was uniformly distributed across time, one would expect to see a straight line when the data is plotted in this way. As observed in prior studies, the shape of the curvature appears consistent with logarithmic compression. The dashed white line on <xref ref-type="fig" rid="fig5">Figure 5a</xref> shows the curve that would be expected if the time fields were distributed uniformly over <inline-formula><mml:math id="inf122"><mml:mi>log</mml:mi></mml:math></inline-formula> time. The hierarchical Bayesian model enables us to quantify this relationship more precisely.</p><p>The Main Model estimates the distribution of time field peaks across the population as <inline-formula><mml:math id="inf123"><mml:mrow><mml:mi>M</mml:mi><mml:mo>∼</mml:mo><mml:msup><mml:mi>M</mml:mi><mml:mrow><mml:mo>-</mml:mo><mml:mi>α</mml:mi></mml:mrow></mml:msup></mml:mrow></mml:math></inline-formula> (see <xref ref-type="disp-formula" rid="equ10">Equation 10</xref> and methods for more details). When <inline-formula><mml:math id="inf124"><mml:mrow><mml:mi>α</mml:mi><mml:mo>=</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:math></inline-formula>, the peak of time cells should be distributed evenly throughout the delay, showing no temporal compression. For <inline-formula><mml:math id="inf125"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>α</mml:mi><mml:mo>&gt;</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:mstyle></mml:math></inline-formula> the representation is compressed. Crucially, <inline-formula><mml:math id="inf126"><mml:mrow><mml:mi>α</mml:mi><mml:mo>=</mml:mo><mml:mn>1.0</mml:mn></mml:mrow></mml:math></inline-formula> indicates that the compression is exactly logarithmic (<xref ref-type="disp-formula" rid="equ4">Equation 4</xref>).</p><p><xref ref-type="fig" rid="fig5">Figure 5c</xref> plots the posterior distribution of <inline-formula><mml:math id="inf127"><mml:mi>α</mml:mi></mml:math></inline-formula>. This distribution is centered around 1 (mean = 0.92 with 95% credible interval [0.73, 1.11]). Furthermore, about 54% of the posterior density is between the value of 0.9 and 1.1. This posterior conclusively argues against uniformly distributed time cells as it excludes zero by approximately five standard deviations. It also argues strongly against other ‘simple’ values for <inline-formula><mml:math id="inf128"><mml:mi>α</mml:mi></mml:math></inline-formula> that one might have considered reasonable a priori, including 1/2, 3/2, and 2. To informally assess how well the distribution of <inline-formula><mml:math id="inf129"><mml:mi>M</mml:mi></mml:math></inline-formula> approaches <inline-formula><mml:math id="inf130"><mml:mrow><mml:mi>α</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:math></inline-formula>, <xref ref-type="fig" rid="fig5">Figure 5d</xref> plots the cumulative distribution function (CDF) of time cell peaks <inline-formula><mml:math id="inf131"><mml:mi>M</mml:mi></mml:math></inline-formula> on a log axis. If <inline-formula><mml:math id="inf132"><mml:mi>α</mml:mi></mml:math></inline-formula> were 1.0, the CDF would appear as a straight line. Conversely, <inline-formula><mml:math id="inf133"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>α</mml:mi><mml:mo>&gt;</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:mstyle></mml:math></inline-formula> would result in a sub-linear CDF curve and <inline-formula><mml:math id="inf134"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>α</mml:mi><mml:mo>&lt;</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:mstyle></mml:math></inline-formula> would result in a super-linear CDF curve. It should be noted that the estimates of <inline-formula><mml:math id="inf135"><mml:mi>M</mml:mi></mml:math></inline-formula> for different time cells are not independent of one another in the hierarchical Bayesian analysis. However, one also finds similar results from traditional estimate of time fields where each cell’s firing field is estimated independently (<xref ref-type="fig" rid="fig5s1">Figure 5—figure supplement 1d</xref>), at least considering fields that peak after a few hundred ms.</p></sec><sec id="s2-5"><title>Alternative models support the conclusion of a logarithmic timeline</title><p>The conclusion that time cell sequences are logarithmically-compressed (<xref ref-type="disp-formula" rid="equ3">Equation 3</xref>; <xref ref-type="disp-formula" rid="equ4">Equation 4</xref>) was buttressed by additional analyses testing variants of the Main Model. Similar conclusions about the representation of time are reached using all of the alternative models considered (<xref ref-type="table" rid="table1">Table 1</xref>).</p><p>The Main Model assumes that the distribution of time field peaks follows a power law. Although the posterior of the exponent <inline-formula><mml:math id="inf136"><mml:mi>α</mml:mi></mml:math></inline-formula> was tightly clustered around 1, it is possible that the distribution actually follows some entirely different equation. Although it is impossible to test every possible equation, we chose two well-known alternative skewed distributions, exponential and Weibull. These distributions provided much worse quantitative fits to the data than did the Main Model (<xref ref-type="table" rid="table1">Table 1</xref>). Nonetheless, one can still assess whether within-trial time field width <inline-formula><mml:math id="inf137"><mml:msub><mml:mi>σ</mml:mi><mml:mi>w</mml:mi></mml:msub></mml:math></inline-formula> increases linearly with peak time <inline-formula><mml:math id="inf138"><mml:mi>M</mml:mi></mml:math></inline-formula> (<xref ref-type="disp-formula" rid="equ3">Equation 3</xref>). A linear increase was obseerved for both the Exponential Compression Model and the Weibull Compression Model (both <inline-formula><mml:math id="inf139"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>B</mml:mi><mml:msub><mml:mi>F</mml:mi><mml:mrow><mml:mi>M</mml:mi></mml:mrow></mml:msub><mml:mo>&gt;</mml:mo><mml:mn>100</mml:mn></mml:mrow></mml:mstyle></mml:math></inline-formula>).</p><p>Another alternative model, the Log-normal Time Field Model, assumes that time field shape is log-normal instead of Gaussian at the trial level. This model, which produces skewed time fields, described the data a bit worse than the Main Model (<xref ref-type="table" rid="table1">Table 1</xref>). Nonetheless, time field width increased linearly with peak time in the Log-normal Time Field Model (<xref ref-type="disp-formula" rid="equ3">Equation 3</xref>) and <inline-formula><mml:math id="inf140"><mml:mi>α</mml:mi></mml:math></inline-formula> was close to 1.0. A linear regression of width of time fields onto the peak time found the linear term reached statistical significance ( <inline-formula><mml:math id="inf141"><mml:mrow><mml:mn>.08</mml:mn><mml:mo>±</mml:mo><mml:mn>.024</mml:mn></mml:mrow></mml:math></inline-formula>, <inline-formula><mml:math id="inf142"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>p</mml:mi><mml:mo>&lt;</mml:mo><mml:mn>0.001</mml:mn></mml:mrow></mml:mstyle></mml:math></inline-formula>, <inline-formula><mml:math id="inf143"><mml:mrow><mml:msubsup><mml:mi>R</mml:mi><mml:mrow><mml:mi>a</mml:mi><mml:mo>⁢</mml:mo><mml:mi>d</mml:mi><mml:mo>⁢</mml:mo><mml:mi>j</mml:mi></mml:mrow><mml:mn>2</mml:mn></mml:msubsup><mml:mo>=</mml:mo><mml:mn>.085</mml:mn></mml:mrow></mml:math></inline-formula>). The same is true with Bayesian regression analysis: <inline-formula><mml:math id="inf144"><mml:mrow><mml:mrow><mml:mi>B</mml:mi><mml:mo>⁢</mml:mo><mml:msub><mml:mi>F</mml:mi><mml:mi>M</mml:mi></mml:msub></mml:mrow><mml:mo>=</mml:mo><mml:mn>58.54</mml:mn></mml:mrow></mml:math></inline-formula> over null model. In addition, the posterior of the power-law scaling parameter <inline-formula><mml:math id="inf145"><mml:mi>α</mml:mi></mml:math></inline-formula> for the Log-normal Time Field Model was centered around 1 (mean <inline-formula><mml:math id="inf146"><mml:mrow><mml:mi/><mml:mo>=</mml:mo><mml:mn>.96</mml:mn></mml:mrow></mml:math></inline-formula> with 95% credible interval [0.77, 1.15]).</p><p>The Main Model allowed the time field center to vary across trials. The Alternative Trial Vary Model kept time field centers fixed across trials but allowed the width of time fields to vary across trials. Although the Alternative Trial Vary Model described the data much less well than the Main Model (<xref ref-type="table" rid="table1">Table 1</xref>), the parameters from this model were still consistent with the hypothesis of logarithmic compression of time fields. Time field width increased linearly with time field center (<inline-formula><mml:math id="inf147"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>B</mml:mi><mml:msub><mml:mi>F</mml:mi><mml:mrow><mml:mi>M</mml:mi></mml:mrow></mml:msub><mml:mo>&gt;</mml:mo><mml:mn>100</mml:mn></mml:mrow></mml:mstyle></mml:math></inline-formula>) and the posterior of <inline-formula><mml:math id="inf148"><mml:mi>α</mml:mi></mml:math></inline-formula> was centered around 1 (mean <inline-formula><mml:math id="inf149"><mml:mrow><mml:mi/><mml:mo>=</mml:mo><mml:mn>1.01</mml:mn></mml:mrow></mml:math></inline-formula> with 95% credible interval [0.83, 1.15]).</p><p>The foregoing analyses demonstrate that the key predictions of logarithmic compression do not depend critically on any of the assumptions of the Main Model. <xref ref-type="fig" rid="fig6">Figure 6a–b</xref> provides an additional way to informally assess how well the logarithmic hypothesis describes the firing of hippocampal time cells independent of any assumptions of the hierarchical Bayesian method. In <xref ref-type="fig" rid="fig6">Figure 6b</xref>, the firing of each time cell is shown as a function of log time. If the time code for hippocampal time cells was logarithmically compressed, the peak would appear here as a line, indicating that the centers are uniformly distributed as a function of log time.</p><fig id="fig6" position="float"><label>Figure 6.</label><caption><title>Temporal rescaling translates a logarithmically compressed time line.</title><p>(<bold>a</bold>) Normalized firing rate of time cells sorted by peak time on a linear time scale (top) and on a logarithmic time scale (bottom). Yellow indicates high activity and blue indicates low activity. When plotted on a linear scale, the sequence of time cells appears curved and widens with the passage of time. In contrast, when plotted on a <inline-formula><mml:math id="inf150"><mml:mrow><mml:mi mathvariant="normal">log</mml:mi><mml:mo mathvariant="normal">⁡</mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:math></inline-formula> axis time cells appear to uniformly tile the delay. (<bold>b</bold>) Two functions of time related to one another by a constant scaling factor <inline-formula><mml:math id="inf151"><mml:mrow><mml:mi>f</mml:mi><mml:mo mathvariant="normal">⁢</mml:mo><mml:mrow><mml:mo mathvariant="normal" stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo mathvariant="normal" stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> and <inline-formula><mml:math id="inf152"><mml:mrow><mml:mi>f</mml:mi><mml:mo mathvariant="normal">⁢</mml:mo><mml:mrow><mml:mo mathvariant="normal" stretchy="false">(</mml:mo><mml:mrow><mml:mi>a</mml:mi><mml:mo mathvariant="normal">⁢</mml:mo><mml:mi>t</mml:mi></mml:mrow><mml:mo mathvariant="normal" stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula>. (Top) The two functions are plotted as a function of linear time <inline-formula><mml:math id="inf153"><mml:mi>t</mml:mi></mml:math></inline-formula>. (Bottom) The two functions plotted as a function of <inline-formula><mml:math id="inf154"><mml:mrow><mml:mi mathvariant="normal">log</mml:mi><mml:mo mathvariant="normal">⁡</mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:math></inline-formula>. Rescaling <inline-formula><mml:math id="inf155"><mml:mrow><mml:mi>t</mml:mi><mml:mo mathvariant="normal">→</mml:mo><mml:mrow><mml:mi>a</mml:mi><mml:mo mathvariant="normal">⁢</mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:mrow></mml:math></inline-formula> simply results in a translation of <inline-formula><mml:math id="inf156"><mml:mi>f</mml:mi></mml:math></inline-formula> along the <inline-formula><mml:math id="inf157"><mml:mrow><mml:mi mathvariant="normal">log</mml:mi><mml:mo mathvariant="normal">⁡</mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:math></inline-formula> axis.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-75353-fig6-v2.tif"/></fig><sec id="s2-5-1"><title>Time cells early and late in the delay show similar compression</title><p>One possible concern is that hippocampal time cells are responding to some variable that changes over the delay. While it is in principle difficult to assess this question as we cannot measure every possible variable that could be of interest to the animal, we can rule out confounds with observable behavior. In this experiment, animals were not perfectly still as they ran on the treadmill over the 8 s delay. However, variability in position, running speed, and angular acceleration was much larger early in the delay as the animal moved towards the edge of the treadmill. Variance in these variables decreased dramatically after about 2 s (see Supplementary section S1). To assess the concern that the apparent logarithmic compression over the 8 s delay was an artifact of behavioral changes during that interval, we sorted time cells into two distinct groups with peak times before and after 2 s. Fortuitously, these groups included about the same number of time cells; the early group included 63 time cells and the late group 68. Both groups showed evidence of temporal compression when considered separately.</p><p>If the early and late time cells were two distinct groups, it is possible that this could give rise to an artifactual increase in time field width with delay. For instance, suppose that the width of time fields is constant within each group but larger for time cells in the later group. However, contradicting this artifactual account, time field width increased with peak time for both early and late time cells. Bayesian linear regression analysis showed evidence in favor of a linear model over the null model for both the early group (<inline-formula><mml:math id="inf158"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>B</mml:mi><mml:msub><mml:mi>F</mml:mi><mml:mrow><mml:mn>10</mml:mn></mml:mrow></mml:msub><mml:mo>&gt;</mml:mo><mml:mn>100</mml:mn></mml:mrow></mml:mstyle></mml:math></inline-formula>) and the late group (<inline-formula><mml:math id="inf159"><mml:mrow><mml:mrow><mml:mi>B</mml:mi><mml:mo>⁢</mml:mo><mml:msub><mml:mi>F</mml:mi><mml:mn>10</mml:mn></mml:msub></mml:mrow><mml:mo>=</mml:mo><mml:mn>2.5</mml:mn></mml:mrow></mml:math></inline-formula>).</p><p>Similarly, perhaps the distribution of time field peaks observed in the Main Model is an artifact of averaging over early and late groups. Perhaps time field peaks are distributed uniformly within both the early and late groups. Additional analyses falsified this hypothesis. The distribution of time field peaks was non-uniform within each group and there was no evidence that the two groups were sampled from different distributions. A KS test against a uniform distribution sampled over the range of time field peaks in each group rejected the uniform hypothesis for both early, <inline-formula><mml:math id="inf160"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>D</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mn>63</mml:mn><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mn>.307</mml:mn><mml:mo>,</mml:mo><mml:mi>p</mml:mi><mml:mo>&lt;</mml:mo><mml:mn>.001</mml:mn></mml:mrow></mml:mstyle></mml:math></inline-formula>, and late group, <inline-formula><mml:math id="inf161"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>D</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mn>68</mml:mn><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mn>.305</mml:mn><mml:mo>,</mml:mo><mml:mi>p</mml:mi><mml:mo>&lt;</mml:mo><mml:mn>.001</mml:mn></mml:mrow></mml:mstyle></mml:math></inline-formula>. To assess whether the distributions of early and late time field peaks were different from one another, we normalized peak times within each group such that each peak time was between 0 and 1. Comparing the distributions of relative peak times between early and late groups, we could not rule out the hypothesis that they were sampled from the same distribution, <inline-formula><mml:math id="inf162"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>D</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mn>63</mml:mn><mml:mo>,</mml:mo><mml:mn>68</mml:mn><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mn>.090</mml:mn><mml:mo>,</mml:mo><mml:mi>p</mml:mi><mml:mo>&gt;</mml:mo><mml:mn>.5</mml:mn></mml:mrow></mml:mstyle></mml:math></inline-formula>.</p><p>To summarize, despite dramatic differences in behavioral variability early and late in the delay, we found no evidence suggesting that early and late time cells had different properties from one another nor that either group was qualitatively different from the population as a whole. Coupled with dramatic changes in behavioral variability during the early and late periods of the delay, this argues against the hypothesis that the empirical results arguing for logarithmic compression are artifacts of behavioral variability during the delay.</p></sec></sec></sec><sec id="s3" sec-type="discussion"><title>Discussion</title><p>The present study analyzed a group of hippocampal CA1 time cells with a hierarchical Bayesian model that describes the firing patterns simultaneously at the individual trial level, the individual cell level, and the population level. These analyses confirmed two quantitative predictions that follow from the hypothesis that hippocampal time cells evenly tile the <inline-formula><mml:math id="inf163"><mml:mi>log</mml:mi></mml:math></inline-formula> time axis (<xref ref-type="disp-formula" rid="equ1">Equation 1</xref>). First, analysis at the individual cell level, with variability across trials removed, showed that within-trial time field width increased linearly with delay (<xref ref-type="disp-formula" rid="equ3">Equation 3</xref>). Second, the distribution of time field peaks followed a power-law with exponent close to one (<xref ref-type="disp-formula" rid="equ4">Equation 4</xref>). These findings were robust to many choices of the analysis methods. Taken together, these findings show strong evidence that time cells maintain a logarithmic timeline (<xref ref-type="disp-formula" rid="equ1">Equation 1</xref>) within trial.</p><p>In addition to these findings at the cell and population levels, there was also substantial variability in time field location across trials. At least some of this variability was attributable to variability in the time of events at the beginning of each trial as the animal advanced onto the treadmill and began to run. However measurable behavior (position, velocity, acceleration) was relatively consistent after about two seconds into the trial. To address the concern that the temporal compression in hippocampal time cells is an artifact of behavior, we tested for temporal compression within the population of cells that fired earlier than 2 s and those that fired after 2 s. Both populations showed evidence for temporal compression—wider fields later in the delay and an overrepresentation of time points early in the delay—taken separately. This set of results suggests that the findings suggesting that time cells form a logarithmic timeline are not likely to be an artifact of variability in behavior that is correlated with time within the trial.</p><sec id="s3-1"><title>Compressed representations of time and space in hippocampus, entorhinal cortex and other brain regions</title><p>Many other studies of time in the hippocampus and other brain regions show a broad spectra of timescales across neurons and evidence of compression at the population level. That is, many prior studies show a graded heterogeneity of time scales across units and time scales close to zero are overrepresented relative to time scales representing times further in the past. Representations of spatial location in the hippocampus and related regions could be logarithmically compressed as well. This suggests a common computational framework for representation of many kinds of continuous variables in the hippocampus and elsewhere.</p><sec id="s3-1-1"><title>Sequentially-activated time cells in many brain regions</title><p>A growing body of work suggests that the brain uses a graded heterogeneity of time scales to represent the past. However, it is not clear if Weber-Fechner compression is a general property. Many previous papers have shown compression of hippocampal time cells in rodent hippocampus consistent with log compression (e.g. <xref ref-type="bibr" rid="bib56">Kraus et al., 2013</xref>; <xref ref-type="bibr" rid="bib67">Mau et al., 2018</xref>; <xref ref-type="bibr" rid="bib92">Taxidis et al., 2020</xref>). In addition, a qualitatively similar compression has been reported for sequentially activated cells in rodent striatum (<xref ref-type="bibr" rid="bib69">Mello et al., 2015</xref>; <xref ref-type="bibr" rid="bib1">Akhlaghpour et al., 2016</xref>; <xref ref-type="bibr" rid="bib75">Parker et al., 2022</xref>), rodent MEC (<xref ref-type="bibr" rid="bib57">Kraus et al., 2015</xref>), rodent mPFC (<xref ref-type="bibr" rid="bib94">Tiganj et al., 2017</xref>), monkey caudate nucleus and DLPFC (<xref ref-type="bibr" rid="bib50">Jin et al., 2009</xref>), monkey lPFC (<xref ref-type="bibr" rid="bib95">Tiganj et al., 2018</xref>; <xref ref-type="bibr" rid="bib17">Cruzado et al., 2020</xref>) and monkey hippocampus (<xref ref-type="bibr" rid="bib17">Cruzado et al., 2020</xref>) during a broad variety of behavioral tasks.</p></sec><sec id="s3-1-2"><title>Graded heterogeneity of decay and ramp rates in entorhinal cortex</title><p>In addition to sequentially-activated time cells, ramping and decaying activity in the entorhinal cortex (EC) can be used to decode time since a triggering event. Rather than firing sequentially with graded heterogeneity of peak times, cells in EC, which have been referred to as temporal context cells, appear to change their firing rate gradually following an exponential function as the triggering event recedes into the past. Recording from rodent LEC in a spatial exploration task, <xref ref-type="bibr" rid="bib96">Tsao et al., 2018</xref> observed cells that gradually changed their firing rate with a wide range of time constants spanning up to several minutes. Graded heterogeneity in time constants of decay (or ramp) across cells allows for the decoding of time since an event over a wide range of time scales. <xref ref-type="bibr" rid="bib8">Bright et al., 2020</xref> observed similar results in monkey EC during a free viewing task with cells triggered by onset of an image and decaying with time constants ranging from a few hundred ms up to several s.</p><p>Entorhinal neurons that are not typically understood to be coding for time also show a graded heterogeneity of time constants. <xref ref-type="bibr" rid="bib20">Dannenberg et al., 2019</xref> recorded from speed cells in rodent MEC. During exploration speed changes continuously; that study asked over what time scale filtering the speed signal provided the best account of each speed cell’s time course of firing. Rather than finding a single value, different speed cells appeared to filter the speed signal with a wide range of time constants. The distribution over cells overrepresented times near zero and showed a long tail, suggesting a compression of the time axis. Although there are many possible biological mechanisms for graded heterogeneity of time constants, slowly-inactivating currents in EC observed in slice experiments (<xref ref-type="bibr" rid="bib23">Egorov et al., 2002</xref>) are an attractive candidate for the graded heterogeneity of time constants in EC (<xref ref-type="bibr" rid="bib93">Tiganj et al., 2015</xref>; <xref ref-type="bibr" rid="bib62">Liu et al., 2019</xref>).</p></sec><sec id="s3-1-3"><title>Graded heterogeneity of time constants in cerebellum and other cortical regions</title><p>Work in the cerebellum and cortex outside of the MTL also shows graded heterogeneity of time constants. For instance, graded temporal heterogeneity in the cerebellum has been argued to result in temporal basis functions to represent what happened when in the past (<xref ref-type="bibr" rid="bib5">Barron et al., 2020</xref>; <xref ref-type="bibr" rid="bib55">Kennedy et al., 2014</xref>; <xref ref-type="bibr" rid="bib80">Raymond and Medina, 2018</xref>; <xref ref-type="bibr" rid="bib12">Cavanagh et al., 2020</xref>; <xref ref-type="bibr" rid="bib35">Guo et al., 2021</xref>). Merchant and colleagues recorded neurons in the medial premotor cortex during rhythmic tapping behaviors with a variety of speeds (e.g., <xref ref-type="bibr" rid="bib70">Merchant and Averbeck, 2017</xref>). They observed that some neurons are sensitive to the period of the interval. They observed a graded heterogeneity of preferred intervals across neurons. These same neurons showed gradual ramps or decays that extended several seconds. In addition, a wide variety of studies have shown that the firing rate of neurons regions within the monkey PFC carry temporal information during working memory tasks (e.g. <xref ref-type="bibr" rid="bib66">Machens et al., 2010</xref>). For instance <xref ref-type="bibr" rid="bib18">Cueva et al., 2020</xref> measured the dimensionality of the neural space as time elapsed. The dimensionality increased gradually, consistent with graded heterogeneity in time constants. Morever, the rate at which the dimensionality increased slowed with the passage of time, consistent with temporal compression reported for hippocampal place cells.</p><p>Work from the cerebellum shows evidence for a broad distribution of time scales and at least some evidence that the time constants are distributed along a logarithmic scale. <xref ref-type="bibr" rid="bib35">Guo et al., 2021</xref> reported that unipolar brush cells in the cerebellum form a logarithmically-compressed temporal basis set in a slice preparation. They were able to attribute slow time scales in the slice to heterogeneity in metabotropic glutamate receptors.</p><p>It is theoretically important to systematically evaluate whether the distribution of time constants across regions and tasks shows the same quantitative distributions. This would require careful experimentation. Because the experimental challenges of estimating time are greatest for times near zero, it may be preferable to conduct this experiment over time scales greater than a few seconds. It has been argued that hippocampal time cells at least fire sequentially over several minutes (<xref ref-type="bibr" rid="bib88">Shikano et al., 2021</xref>; <xref ref-type="bibr" rid="bib63">Liu et al., 2022</xref>).</p></sec><sec id="s3-1-4"><title>Compressed spatial representations in hippocampus and EC</title><p>There is evidence suggesting that place fields cluster relative to landmarks in the environment, such as the beginning of a path (<xref ref-type="bibr" rid="bib6">Bjerknes et al., 2018</xref>; <xref ref-type="bibr" rid="bib87">Sheehan et al., 2021</xref>) and edges of an open-field environment (<xref ref-type="bibr" rid="bib36">Harland et al., 2021</xref>), a result analogous to the compression of time observed here. In order to make a clear comparison between temporal representations and spatial representations, it is essential to establish the ‘zero’ of the spatial coordinate system. That is, populations of time cells appear to code for the time between a particular event and the present. However, when an animal is in any specific location in a spatial environment, many different landmarks are at different distances and headings. In order to directly compare time to space, it is essential to establish experimental control over the place code by moving a landmark in the environment and observing that the place cells move with the landmark. <xref ref-type="bibr" rid="bib87">Sheehan et al., 2021</xref>, following a method introduced by Gothard and colleagues (<xref ref-type="bibr" rid="bib33">Gothard et al., 1996</xref>; <xref ref-type="bibr" rid="bib34">Gothard et al., 2001</xref>), systematically manipulated the location of a reward box along a linear track. As observed by <xref ref-type="bibr" rid="bib33">Gothard et al., 1996</xref>; <xref ref-type="bibr" rid="bib34">Gothard et al., 2001</xref>, many hippocampal place fields moved with the box, coding for distance traveled since leaving the box. Consistent with the results from time cell experiments, place fields tiled the distance around the box smoothly. Moreover, place fields were more numerous and more narrow closer to the landmark controlling their firing than further away from the landmark (<xref ref-type="bibr" rid="bib87">Sheehan et al., 2021</xref>). It is not currently known whether the form of the compression of the place code is also logarithmic, but the results are at least qualitatively similar to those observed for time cells (see also <xref ref-type="bibr" rid="bib6">Bjerknes et al., 2018</xref>).</p><p>It has long been appreciated that the spatial frequency of grid cells falls into discrete groups that are anatomically organized (<xref ref-type="bibr" rid="bib91">Stensola et al., 2012</xref>). Interestingly, the relative ratio between the spatial frequency of adjacent clusters of grid cells is constant, as predicted by a normative account of spatial coding (<xref ref-type="bibr" rid="bib103">Wei et al., 2015</xref>). Logarithmic compression also implies that the ratio between adjacent time scales are constant (i.e. <xref ref-type="disp-formula" rid="equ2">Equation 2</xref> implies that <inline-formula><mml:math id="inf164"><mml:mrow><mml:mfrac><mml:msub><mml:mi>t</mml:mi><mml:mrow><mml:mi>n</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:msub><mml:mi>t</mml:mi><mml:mi>n</mml:mi></mml:msub></mml:mfrac><mml:mo>=</mml:mo><mml:mi>b</mml:mi></mml:mrow></mml:math></inline-formula>). That is, both spatial frequency of grid cells and temporal receptive fields for time cells evenly tile a logarithmic axis (equivalently, form a geometric series). The major differences are the parameter that controls the ratio between adjacent neurons and the number of cells that share each value. Whereas time cells appear to smoothly cover the <inline-formula><mml:math id="inf165"><mml:mi>log</mml:mi></mml:math></inline-formula> time axis, many grid cells cluster at a few evenly-spaced locations on the <inline-formula><mml:math id="inf166"><mml:mi>log</mml:mi></mml:math></inline-formula> spatial scale axis. Whereas the ratio between adjacent time scales is close to one, the ratio of the spatial frequency of one cluster of grid cells to the next is much larger. It is an interesting theoretical problem to understand why the brain has chosen distinct but closely related coding schemes for time (and perhaps also space) in the hippocampus and spatial frequency in the grid cell system. Perhaps a solution to this problem would also make sense of the firing of grid cells from MEC when recorded in a time cell experiment (<xref ref-type="bibr" rid="bib57">Kraus et al., 2015</xref>) and the observation of time-like sequences in MEC during pauses in spatial exploration (<xref ref-type="bibr" rid="bib38">Heys and Dombeck, 2018</xref>).</p></sec></sec><sec id="s3-2"><title>Implications of logarithmically compressed time for computational cognitive neuroscience</title><p>Knowing the mathematical form of the timeline represented by hippocampal time cells allows us to infer many properties of the population. <xref ref-type="fig" rid="fig6">Figure 6</xref> illustrates a property called ‘scale-covariance’ that is a consequence of a logarithmically-compressed timeline. The top panel of <xref ref-type="fig" rid="fig6">Figure 6b</xref> shows a pair of functions of time that are rescaled. To get a physical intuition to time rescaling, imagine that you repeat a behavorial experiment on an animal, but in the repetition of the experiment every time interval is changed by the same factor. We would say that the second version of the experiment is a rescaled version of the first. When plotted on a log axis in the bottom panel of <xref ref-type="fig" rid="fig6">Figure 6b</xref> the two curves have identical shape, but are shifted relative to one another. More formally, we can say that time rescaling a function results in translation on a logarithmic scale. This is true, for all possible functions and all possible scaling factors, for the simple reason that <inline-formula><mml:math id="inf167"><mml:mrow><mml:mrow><mml:mi>log</mml:mi><mml:mo>⁡</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mi>a</mml:mi><mml:mo>⁢</mml:mo><mml:mi>t</mml:mi></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mo>=</mml:mo><mml:mrow><mml:mrow><mml:mi>log</mml:mi><mml:mo>⁡</mml:mo><mml:mi>a</mml:mi></mml:mrow><mml:mo>+</mml:mo><mml:mrow><mml:mi>log</mml:mi><mml:mo>⁡</mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:mrow></mml:mrow></mml:math></inline-formula>. Rescaling time—taking <inline-formula><mml:math id="inf168"><mml:mi>t</mml:mi></mml:math></inline-formula> to <inline-formula><mml:math id="inf169"><mml:mrow><mml:mi>a</mml:mi><mml:mo>⁢</mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:math></inline-formula>—translates the neural representation, shifting time cell indexes by a factor proportional to <inline-formula><mml:math id="inf170"><mml:mrow><mml:mi>log</mml:mi><mml:mo>⁡</mml:mo><mml:mi>a</mml:mi></mml:mrow></mml:math></inline-formula>. This property of a logarithmically-compressed timeline is referred to as scale-covariance. It can be shown that only logarithmic functions give rise to this form of scale-covariance.</p><p>The scale-covariance of the neural representation should not be confused with scale-<italic>invariance</italic>. A scale-invariant system is completely unaffected by temporal rescaling. As we will see below, it is straightforward to build scale-<italic>invariant</italic> computational models from scale-<italic>covariant</italic> neural representations. There is, however, also evidence for scale-invariant neural representations of time. For instance, <xref ref-type="bibr" rid="bib69">Mello et al., 2015</xref> observed cells in the striatum that fire sequentially in a fixed interval operant conditioning task. In the fixed interval procedure, the first response after a particular interval has past is reinforced. Animals learn to respond at appropriate times. <xref ref-type="bibr" rid="bib69">Mello et al., 2015</xref> observed that when the fixed interval changed, the sequences were stretched in time. If we examined the population at the moment just before the interval ends, we would find the same pattern of firing across neurons regardless of the duration of the interval. That is, the pattern of firing across the population is invariant to rescaling time in the experiment. Neural responses that respond to serial or ordinal position even as the timing of events is rescaled are also scale-invariant (e.g., <xref ref-type="bibr" rid="bib16">Crowe et al., 2014</xref>; <xref ref-type="bibr" rid="bib66">Machens et al., 2010</xref>).</p></sec><sec id="s3-3"><title>Logarithmic timelines and scale-invariant perception</title><p>One can compute scale-invariant quantities from a scale-covariant neural representation. For instance, consider <xref ref-type="fig" rid="fig6">Figure 6b</xref>. When plotted as a function of log time the rescaled functions have the same standard deviation. The standard deviation computed from the scale-covariant representation is scale-invariant. This property of a logarithmically-compressed timeline is closely related to the ‘scalar timing’ observed behaviorally (<xref ref-type="bibr" rid="bib30">Gibbon, 1977</xref>; <xref ref-type="bibr" rid="bib79">Rakitin et al., 1998</xref>; <xref ref-type="bibr" rid="bib59">Lejeune and Wearden, 2006</xref>) and neurally (<xref ref-type="bibr" rid="bib16">Crowe et al., 2014</xref>).</p><p>When integrated into deep neural networks, scale-covariance can be exploited to build networks for perception that naturally generalize to rescaled signals. <xref ref-type="bibr" rid="bib47">Jacques et al., 2022</xref> trained a deep network with logarithmically-compressed time cells at each layer to learn to classify auditory patterns (<xref ref-type="bibr" rid="bib46">Jacques et al., 2021</xref>). After being trained to classify digits spoken at a normal rate, the network built from logarithmically-compressed time cells recognizes digits spoken much more slowly or quickly than the training examples without retraining. Notably, it has been argued that time constants in the early auditory system have a logarithmic distribution (<xref ref-type="bibr" rid="bib78">Rahman et al., 2020</xref>). <xref ref-type="bibr" rid="bib48">Jansson and Lindeberg, 2022</xref> used a similar idea, building on longstanding theoretical work in the context of computer vision (<xref ref-type="bibr" rid="bib60">Lindeberg and Fagerström, 1996</xref>; <xref ref-type="bibr" rid="bib61">Lindeberg, 2016</xref>), to build networks for visual pattern classification that generalize to images that are larger or smaller than the training set. It has long been known the retinotopic coordinates in the early visual system compress distance from the fovea logarithmically (<xref ref-type="bibr" rid="bib100">Van Essen et al., 1984</xref>).</p><p>The ubiquity of scale-covariant representations in the brain suggests that this choice for distributing receptors is a consequence of some general computational principle. Viewed from the perspective of efficient coding (<xref ref-type="bibr" rid="bib9">Brunel and Nadal, 1998</xref>; <xref ref-type="bibr" rid="bib104">Wei and Stocker, 2015</xref>; <xref ref-type="bibr" rid="bib105">Wei and Stocker, 2016</xref>), logarithmic scales are a natural consequence of the expectation of power law statistics. If the probability of observing a stimulus of value <inline-formula><mml:math id="inf171"><mml:mi>x</mml:mi></mml:math></inline-formula> goes down like <inline-formula><mml:math id="inf172"><mml:msup><mml:mi>x</mml:mi><mml:mrow><mml:mo>-</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msup></mml:math></inline-formula>, then a neural code in which receptive fields tile <inline-formula><mml:math id="inf173"><mml:mrow><mml:mi>log</mml:mi><mml:mo>⁡</mml:mo><mml:mi>x</mml:mi></mml:mrow></mml:math></inline-formula> results in each unit firing equally often (<xref ref-type="bibr" rid="bib102">Wei, 2012</xref>). Indeed, researchers have noted that many natural signals have long-range correlations (e.g. <xref ref-type="bibr" rid="bib2">Anderson and Schooler, 1991</xref>). However arguments about the metabolic or coding efficiency of a population of neurons need not lead to the conclusion that logarithmic scales are a consequence of a prior belief in power law statistics. For instance, in the presence of white noise, a logarithmic temporal code equalizes the mutual information between adjacent receptors (<xref ref-type="bibr" rid="bib86">Shankar and Howard, 2013</xref>; <xref ref-type="bibr" rid="bib44">Hsu and Marzen, 2020</xref> see also <xref ref-type="bibr" rid="bib43">Howard and Shankar, 2018</xref>).</p><sec id="s3-3-1"><title>Logarithmic timeline and temporal context in retrieval of episodic memory</title><p>In episodic memory, scale-covariance can make sense of a number of an otherwise puzzling finding about epsodic memory in humans. Human episodic memory—the vivid recollection of a specific event from one’s life—has long been thought to depend on recovery of a prior state of a gradually changing state of spatiotemporal context (<xref ref-type="bibr" rid="bib97">Tulving and Madigan, 1970</xref>). The retrieved context hypothesis has led to a number of detailed computational models of human behavior (e.g. <xref ref-type="bibr" rid="bib85">Sederberg et al., 2008</xref>). These computational models explain the contiguity effect in episodic memory—the finding that memory for a specific event spontaneously brings to mind events experienced at nearby points in space and time (<xref ref-type="bibr" rid="bib37">Healey and Kahana, 2014</xref>; <xref ref-type="bibr" rid="bib53">Kahana, 2012</xref>)—as a consequence of successful retrieval of a prior state of spatiotemporal context.</p><p>Remarkably, the contiguity effect in episodic memory is observed across a very wide range of time scales. For instance, in the free recall task recall of a word from a sequentially-presented list tends to be followed by recall of a word from a nearby position within the list (<xref ref-type="bibr" rid="bib51">Kahana, 1996</xref>). In a typical free recall task in which the words are presented one per second, a robust contiguity effect is observed (<xref ref-type="bibr" rid="bib52">Kahana, 2008</xref>). However, if one inserts a distractor-filled delay of sixteen seconds between each word, presumably clearing the contents of short-term memory between each list item, a contiguity effect is still observed (<xref ref-type="bibr" rid="bib39">Howard and Kahana, 1999</xref>). If, at the end of an experimental session lasting tens of minutes, the experimenter asks the participant to recall all the words from all the lists, there is a contiguity effect <italic>across lists</italic>, despite the fact that the words from different lists are separated by hundreds of seconds (<xref ref-type="bibr" rid="bib99">Unsworth, 2008</xref>; <xref ref-type="bibr" rid="bib40">Howard et al., 2008</xref>). At even longer scales, the contiguity effect can be observed when stimuli are presented separated by an hour (<xref ref-type="bibr" rid="bib15">Cortis Mack et al., 2017</xref>) or when participants recall news events extended over weeks and months (<xref ref-type="bibr" rid="bib98">Uitvlugt and Healey, 2019</xref>).</p><p>The persistence of the contiguity effect in episodic memory over changes in the time scale of the experiment are a serious challenge for attractor models for retrieval of spatiotemporal context. Attractor dynamics of such a network would have to be invariant to rescalings of time. Time cells and place cells are an appealing candidate for a neural implementation of a representation of spatiotemporal context (<xref ref-type="bibr" rid="bib42">Howard et al., 2015</xref>; <xref ref-type="bibr" rid="bib24">Eichenbaum, 2017</xref>). Logarithmic compression of time—and the scale-covariance that follows from this property—offers a solution to this theoretical problem. Rescaling of time translates the covariance matrix between time cells (up to a constant factor) along the log time axis. If the covariance matrix can be shaped to form a line attractor (<xref ref-type="bibr" rid="bib89">Spalla et al., 2021</xref>; <xref ref-type="bibr" rid="bib106">Zhong et al., 2020</xref>; <xref ref-type="bibr" rid="bib13">Chaudhuri et al., 2019</xref>) this would enable retrieval of logarithmically-compressed states of spatiotemporal context.</p></sec></sec><sec id="s3-4"><title>What is the upper limit of the logarithmic scale for time?</title><p>Although time cell sequences may continue much longer than the eight second delay used in this experiments (<xref ref-type="bibr" rid="bib88">Shikano et al., 2021</xref>; <xref ref-type="bibr" rid="bib63">Liu et al., 2022</xref>), it is difficult to imagine that time cell sequences persist for hours and days. However, it is possible that the temporal code is logarithmically compressed, perhaps by means of distinct neural mechanisms, over time scales much longer than minutes. For instance, <xref ref-type="bibr" rid="bib74">Nielson et al., 2015</xref> studied the pattern similarity across voxels in the hippocampus evoked by different real world memories. Pairs of memories were separated by objective distances in time and space. <xref ref-type="bibr" rid="bib74">Nielson et al., 2015</xref> found that pattern similarity fell off as a function of log time extending up to weeks. Behaviorally, <xref ref-type="bibr" rid="bib3">Arzy et al., 2009</xref> asked human participants to place real world autobiographical events on a timeline centered at the present. They found the accuracy for the time of past events decreased linearly with log-scaled time, suggesting a logarithmically-compressed temporal representation over time scales up to decades (see also <xref ref-type="bibr" rid="bib77">Peer et al., 2015</xref>). Representational drift—slow changes in the pattern of active neurons when a particular stimulus or experimental setting is repeated—is a possible candidate to play the role of spatiotemporal context over autobiographical time scales (<xref ref-type="bibr" rid="bib107">Ziv et al., 2013</xref>; <xref ref-type="bibr" rid="bib82">Rubin et al., 2015</xref>; <xref ref-type="bibr" rid="bib10">Cai et al., 2016</xref>; <xref ref-type="bibr" rid="bib67">Mau et al., 2018</xref>; <xref ref-type="bibr" rid="bib68">Mau et al., 2020</xref>).</p></sec></sec><sec id="s4" sec-type="materials|methods"><title>Materials and methods</title><sec id="s4-1"><title>Experiment and electrophysiology</title><sec id="s4-1-1"><title>Subjects</title><p>Subjects were four male Long-Evans rats (Charles River) weighing between 350 and 450 g and between the ages of 6 months to 1.5 years for the duration of the experiment. Animals were single housed and maintained on a 12 hr light-dark cycle (lights on at 8:00 AM) for the duration of the experiment. All behavioral training and experimentation were performed during the light phase. Animals were given ad-libitum water and maintained at a minimum of 85% of their ad libitum feeding body weight during all behavioral training and testing. All procedures were conducted in accordance with the requirements set by the National Institutes of Health, and were approved by the Boston University Institutional Animal Care and Use Committee (BU IACUC).</p></sec><sec id="s4-1-2"><title>Behavioral apparatus</title><p>The behavioral apparatus consisted of a custom-built 355 cm long by 7.5 cm wide circular track with an integrated treadmill using commercially available parts (Columbus Instruments). The treadmill had walls funneling into a small exit to ensure the animals’ head position was fixed for the duration of the treadmill run. At the end of the treadmill existed a 20 x 20 cm square platform onto which the test objects were placed. The track was elevated 95 cm above the floor, positioned at least 20 cm away from all walls but in a position in which various distal visual cues were available to the rat. The maze contained two automatic doors, one at the front of the treadmill and one on the return arm that was controlled by infrared beam breaks (Arduino microcontroller, hardware from Adafruit industries).</p></sec><sec id="s4-1-3"><title>Training procedure</title><p>Rats were trained in a similar manner to previous experiments (<xref ref-type="bibr" rid="bib81">Robinson et al., 2017</xref>). Briefly, rats were initially trained to run in one direction around the maze for froot-loop reward. Once rats reliably looped, they were shaped to retrieve the reward hidden in a flower pot each lap (roughly 4 days). Then, rats were trained to sample one of two test objects before running through the treadmill platform and then choosing the matching one of two terra cotta pots discriminable by scent and digging media (<xref ref-type="bibr" rid="bib54">Keene et al., 2016</xref>). The terra-cotta pots were always placed side-by-side on the platform in a pseudorandomized position. A choice was determined to be made once the animal disturbed the surface of the media at which point the opposite pot was immediately removed at this and all subsequent stages of behavior. One crushed froot loop was added to each pot at the beginning of each day, and every 7–9 trials neither pot contained a food reward, and the reward was given after 1 second of digging to prevent the possibility of reward scent guiding behavior. This shaping was performed by initially running each object-pot pair in large blocks of trials (&gt;10 consecutive trials) and progressively weaning down to random presentation over the course of 2 weeks. Once animals were performing at &gt;80% discrimination, two new objects were added one at a time to the study set using the same progressively shrinking block design. Once animals were able to discriminate between the 4 objects to retrieve reward from the correct terra-cotta pot of the two with &gt;90% accuracy, a running delay was imposed. Initially, animals were trained to wait for a fraction of a second while the treadmill was nudged forward between the study and test phases. This treadmill delay was progressively increased until performance fell to between 70 and 80%, typically 8 seconds. Typically, this training schedule took roughly 2 months to train animals on the first pair of study objects, and then another 1.5 months for rats to perform with 4 study objects and with a sufficiently long treadmill delay.</p></sec><sec id="s4-1-4"><title>Surgery</title><p>Anesthesia was induced via inhalation of 5% isofluorane (Webster Veterinary Supply) in oxygen, and then a stable plane was maintained at 1.5–3% throughout the entire surgery. Immediately following the induction, animals were injected with the analgesic Buprenex (Buprenorphine hydrochloride, 0.03 mg/kg i.m.; Reckitt Benckiser Healthcare), and the antibiotic cefazolin 330 mg/ml i.m.; West-Ward Pharmaceuticals. The rat was then fixed to a stereotaxic frame (Kopf). Craniotomies then were made above the dorsal hippocampus (dHPC) (AP-4.1, ML 3.0 mm), and the rostral lateral entorhinal cortex (LEC) (AP-6.8, ML 4.5). Six to eight sterile stainless steel screws were then fixed to the skull, and the remaining skull surface was covered with Metabond (Parkell, Inc). A hyperdrive consisting of 24 independently moveable tetrodes was then lowered into the craniotomy, and fixed to the skull using dental cement. Two ground screws were inserted above the cerebellum, and soldered to the ground leads on the electrode interface board during surgery. Each tetrode was composed of four 12 µM RO 800 wires (Sandvik Kanthal HP Reid Precision Fine Tetrode Wire; Sandvik). Tetrodes were plated with non-cyanide gold solution (Neuralynx) via electrolysis using a Nano-Z (White Matter LLC) in order to reduce impedance to between 180 and 220 kOhms. At the conclusion of surgery tetrodes were lowered 1 mm into dorsal cortex. Animals were given Buprenex and Cefazolin twice a day as needed for up to three days post-surgery.</p></sec><sec id="s4-1-5"><title>Data acquisition</title><p>All electrophysiological recordings were performed using a 96 channel multichannel Acquisition Processor (MAP) recording system (Plexon). Each spike channel was amplified 1000 x, then between 3 and 10 x depending on the region. Spike channels were manually referenced to a local tetrode with no apparent unit firing, bandpass filtered between 200 and 10 kHz, and digitized at 40 kHz. LFP signals were uniformly referenced to ground, amplified 2000 x, and bandpass filtered between 0.5 Hz and 300 Hz. Tetrodes were moved a minimum of 60 uM after each recording session to prevent resampling the same units. Tetrodes were lowered a minimum of 12 hr before all recording sessions to ensure tetrode stability. The animal’s position and behavior were tracked via two LEDs fixed to his hyperdrive on one overhead camera, and on one camera positioned behind the two terra-cotta pots each recording at 30 fps and about 2 pixels per cm. Cineplex Studio (Plexon) was used for capturing behavioral data, and Cineplex Editor (Plexon) was used to manually enter event markers and to verify animal position tracking. For position data, the LED fixed to the rat’s implant was automatically tracked online in Cineplex. Missing data epochs larger than 1 s were manually interpolated, and those less than a second were linearly interpolated. Behavioral events were manually scored using a two camera system to enable frame-by-frame determination of behaviors (<xref ref-type="video" rid="video1">Video 1</xref>). Crucially, we hand scored the moment the rat placed his first paw on the treadmill as well as the moment he touched the closed door at the front of the treadmill. The treadmill was initiated via IR beam break positioned at the midpoint of the treadmill and was not hand-scored. The delay ended automatically and was signaled by simultaneous termination of the treadmill belt and opening of the exit door.</p><media mimetype="video" mime-subtype="mp4" xlink:href="elife-75353-video1.mp4" id="video1"><label>Video 1.</label><caption><title>Video of example trials Three consecutive trials from example session (Rat 1).</title><p>An Overhead camera tracked the position of the rat on the maze and on the treadmill, whereas a second camera (inset) positioned at the reward objects allowed us to precisely score when the rat made a choice. Data were acquired at 30 frames per second at 640x480 pixel resolution (1/2 cm per pixel for overhead camera).</p></caption></media></sec><sec id="s4-1-6"><title>Spike sorting and data processing</title><p>Spikes were assigned to individual units by offline manual clustering of waveform characteristics (valley amplitude, peak-valley, energy, principal components, and waveform width at half max). Tetrode localization was performed using histology, and further guided by the LFP theta amplitude and phase, and sharp-wave ripple amplitude. Only well-isolated units (Isolation Rating &gt; 40 L-Ratio &lt;0.001) were kept for further analysis. Behavior was monitored from an overhead camera and a second camera with a close-up view of the test pots (see above). Door movements, and treadmill onset and offset were automatically strobed into the recording amplifier. Test object sampling events were hand-coded using CinePlex editor (Plexon) using video taken at 30 Hz from the camera trained on the reward objects.</p></sec></sec><sec id="s4-2"><title>Data analysis</title><p>The goal of the analysis is to find the parameters that best describe the properties of time fields from trial to the population level. First, we identify time cells using the standard methods (<xref ref-type="bibr" rid="bib95">Tiganj et al., 2018</xref>) and systematically eliminate time cells near the event boundary. Then we apply five hierarchical Bayesian models to this population (<xref ref-type="table" rid="table1">Table 1</xref>). The Main Model allows us to test the logarithmic compression hypothesis directly. Although the Main Model is presented first to aid readers’ understanding of the fitting process, we also considered alternative ways to characterize the properties of time fields at <italic>every level</italic> of the hierarchy and tested those alternative models following the same model fitting procedures.</p><sec id="s4-2-1"><title>Selecting time cells as input to hierarchical Bayesian models</title><p>As a first pass to identify time cells to be passed on to the hierarchical Bayesian models, we used established methods reported in other papers (<xref ref-type="bibr" rid="bib95">Tiganj et al., 2018</xref>; <xref ref-type="bibr" rid="bib17">Cruzado et al., 2020</xref>). Additionally, the models aim to characterize the population as a whole to estimate the temporal compression, we exclude a small portion of neurons if their estimated peak firing is too close to the event boundaries (<xref ref-type="bibr" rid="bib14">Clauset et al., 2009</xref>). Finally, to ensure that the variability across trials could be reliably estimated, we required that units considered in the hierarchical Bayesian analysis fired at least one spike on at least 20 trials.</p></sec><sec id="s4-2-2"><title>Prior methods for estimating time cells</title><p>The particular method we applied to identify time cells (<xref ref-type="bibr" rid="bib95">Tiganj et al., 2018</xref>; <xref ref-type="bibr" rid="bib17">Cruzado et al., 2020</xref>) is conservative in that it uses multiple tests to ensure that a particular unit reliably codes for time across trials and is meaningfully related to time within the delay period. It does not control for variability across trials nor to does it try to assess the properties of the population.</p><p>In order to be classified as a time cell, a unit had to satisfy several criteria. First, to exclude interneurons, we required the firing rate over all delay intervals had to be less than 5 Hz. Second, to be classified as a time cell, units had to show a reliable time field. This was quantified by comparing two models to describe the firing rate as a function of time. One model included a Gaussian-shaped time field, with a mean and a standard deviation, and a constant term. The other model only estimated a constant firing rate. Best-fitting parameters for each model were identified for each unit and each model using scipy’s basin-hopping method scipy.optimize.basinhopping with truncated Newton algorithm (arguments stepsize = 1000, niter = 500, method = TNC, use_jac = T, t=1). In order to pass this criterion, the log-likelihood ratio for the time field model compared to the constant model had to exceed 5.66. The two models differ by three degrees of freedom; 5.66 is the threshold needed to exceed the log-likelihood ratio test with three degrees of freedom at the <inline-formula><mml:math id="inf174"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>p</mml:mi><mml:mo>&lt;</mml:mo><mml:mn>.01</mml:mn></mml:mrow></mml:mstyle></mml:math></inline-formula> level. Additionally, different criterion options were tested and we found six more units (average time field peak at 1.12 s) would be admitted if the criterion is relaxed to <inline-formula><mml:math id="inf175"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>p</mml:mi><mml:mo>&lt;</mml:mo><mml:mn>.05</mml:mn></mml:mrow></mml:mstyle></mml:math></inline-formula>. On the other hand, six units (average time field peak at 1.54 s) would be eliminated if the criterion is tightened to <inline-formula><mml:math id="inf176"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>p</mml:mi><mml:mo>&lt;</mml:mo><mml:mn>.005</mml:mn></mml:mrow></mml:mstyle></mml:math></inline-formula>. Since only a small fraction of the population (6/159) is impacted by the choice of criterion and the impact seemed to be unbiased (median time field peak of the population is 1.22 s), we proceeded with the criterion of <inline-formula><mml:math id="inf177"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>p</mml:mi><mml:mo>&lt;</mml:mo><mml:mn>.05</mml:mn></mml:mrow></mml:mstyle></mml:math></inline-formula> following the previous examples (<xref ref-type="bibr" rid="bib95">Tiganj et al., 2018</xref>).</p><p>To ensure that the units classified as time cells were reliable across trials, we required that the time field model was statistically reliable for both even and odd trials considered separately. To ensure that the method identified time fields within the delay interval, rather than monotonically ramping or decaying firing (or a time field centered outside the interval), we additionally required that the mean of the Gaussian firing field was within the delay.</p></sec><sec id="s4-2-3"><title>Setting the bounds for temporal compression estimation</title><p>Because the hierarchical Bayesian models we considered estimate the compression at the population level as they estimate the time field peak location for each cell and trial simultaneously, it is important to exclude time cells near the event boundary. Specifically with the power-law distribution, which we used to quantify the temporal compression at the population level, there exist some standard procedures to exclude extreme values (<xref ref-type="bibr" rid="bib14">Clauset et al., 2009</xref>). <xref ref-type="bibr" rid="bib14">Clauset et al., 2009</xref> argued that the chosen boundary should make the probability density function from the bounded data as close to the best-fit power-law distribution as possible. Following their advice, we performed Kolmogorov-Smirnov statistic (KS test) to measure the probability that the bounded data, estimated time field peaks from the maximum likelihood methods in our case, was sampled from the best-fit power-law distribution and chose the boundary parameters that produced the highest p-value. For the lower bound parameter (<italic>min</italic> parameter in the hierarchical Bayesian model), we searched the range from 100 to 400 ms with a 50 ms grid. For the upper bound parameter(<italic>max</italic> parameter in the hierarchical Bayesian model), we searched in the range of 6400–8000 ms with a 400 ms grid (5% of the overall trial-length 8000 ms). For each of the lower bound and upper bound pairs, we took the estimated time field peaks that fell in the range and estimated the corresponding power-law distribution (<xref ref-type="disp-formula" rid="equ10">Equation 10</xref>) with the Bayesian model fitting method. The posterior of the compression parameter <inline-formula><mml:math id="inf178"><mml:mi>α</mml:mi></mml:math></inline-formula> is generated through the rStan package (<xref ref-type="bibr" rid="bib90">Stan development team, 2021</xref>) with three independent Markov-Chain-Monte-Carlo (MCMC) chains (4000 warm-up iterations and 1000 post warm-up samples in each of the MCMC chains). Then we applied the KS test that compares the data against the best-fitting power-law distribution composed with the corresponding <inline-formula><mml:math id="inf179"><mml:mi>α</mml:mi></mml:math></inline-formula>. The cumulative density function (CDF) of the bounded power-law is defined as:<disp-formula id="equ9"><label>(9)</label><mml:math id="m9"><mml:mrow><mml:mi>P</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>x</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:msup><mml:mi>x</mml:mi><mml:mrow><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:mi>α</mml:mi></mml:mrow></mml:msup><mml:mo>−</mml:mo><mml:mover><mml:mo movablelimits="true" form="prefix">min</mml:mo><mml:mrow><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:mi>α</mml:mi></mml:mrow></mml:mover></mml:mrow><mml:mrow><mml:mover><mml:mo movablelimits="true" form="prefix">max</mml:mo><mml:mrow><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:mi>α</mml:mi></mml:mrow></mml:mover><mml:mo>−</mml:mo><mml:mover><mml:mo movablelimits="true" form="prefix">min</mml:mo><mml:mrow><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:mi>α</mml:mi></mml:mrow></mml:mover></mml:mrow></mml:mfrac></mml:mrow></mml:math></disp-formula></p><p>In our KS test results, we found the pair with the highest p-value is (350ms, 7200ms) with a p-value of .855. We excluded any cells outside of the range (14/159) and applied this range limit for the compression estimation in the hierarchical Bayesian models fitting below. Although we ended up with one particular boundary pair, the estimated <inline-formula><mml:math id="inf180"><mml:mi>α</mml:mi></mml:math></inline-formula> distribution does not change much between different pairs in our results: after excluding some very early choices (100-200 ms) for lower bound and very late choice (8000 ms), power law distribution provides a reasonable fit from the remaining pairs: <inline-formula><mml:math id="inf181"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>p</mml:mi><mml:mo>&gt;</mml:mo><mml:mn>0.5</mml:mn></mml:mrow></mml:mstyle></mml:math></inline-formula> based on KS test. Moreover, the corresponding estimated <inline-formula><mml:math id="inf182"><mml:mi>α</mml:mi></mml:math></inline-formula> posteriors are between 0.5 and 1.5 and always include 1.</p></sec><sec id="s4-2-4"><title>Hierarchical Bayesian estimation of time fields across trials and neurons</title><p>We tested five hierarchical Bayesian models for the data set (see <xref ref-type="table" rid="table1">Table 1</xref>). Here, we first describe the Main Model. A schematic illustration of the Main Model can be found in <xref ref-type="fig" rid="fig2">Figure 2</xref>. Following the Main Model, we describe alternative models where we scrutinize the specific model assumptions by testing alternative hypotheses, one level at a time to isolate the impact. All of the models follow the same fitting procedures.</p><p>Bayesian model fitting procedures search the space of possible values of parameters through iterations to improve the likelihood of predicting the observed data. However, rather than finding the <italic>best</italic> fitting value, the program returns a posterior distribution that include a range of likely values for a given parameter. For expository purposes we discuss the specific hypothesis at each level in sequence, but the program fits parameters from all levels simultaneously. Each model has parameters that affect the likelihood of the observed data, aggregated across cells and trials. One only estimates hypotheses from fits of all levels together. Therefore all the alternative models adopt the assumptions of the Main Model <italic>except</italic> the specific assumption they aim to test.</p><p>The posterior distributions of estimated parameters were generated through the rStan package (<xref ref-type="bibr" rid="bib90">Stan development team, 2021</xref>) with 8 independent Markov-Chain-Monte-Carlo (MCMC) chains (4800 warm-up iterations and 200 post warm-up samples in each of the MCMC chains). Stan returns the multiple levels simultaneously. This procedure returns posteriors of the likelihood of the data as well as posteriors for the parameters of the model.</p></sec><sec id="s4-2-5"><title>Main Model</title><p>The Main Model assumes a Gaussian-shaped time field, with the peak location at <inline-formula><mml:math id="inf183"><mml:msub><mml:mi>μ</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:math></inline-formula> and width of <inline-formula><mml:math id="inf184"><mml:msub><mml:mi>σ</mml:mi><mml:mi>w</mml:mi></mml:msub></mml:math></inline-formula>, for each time cell (<xref ref-type="disp-formula" rid="equ5">Equation 5</xref>). The location of the time field is assumed to shift across trials according to a normal distribution that centered at <inline-formula><mml:math id="inf185"><mml:mi>M</mml:mi></mml:math></inline-formula> with standard deviation of <inline-formula><mml:math id="inf186"><mml:msub><mml:mi>σ</mml:mi><mml:mi>t</mml:mi></mml:msub></mml:math></inline-formula> (<xref ref-type="disp-formula" rid="equ7">Equation 7</xref>). The time field peaks <inline-formula><mml:math id="inf187"><mml:mi>M</mml:mi></mml:math></inline-formula> are distributed according to the power-law across the population (<xref ref-type="disp-formula" rid="equ10">Equation 10</xref>). Because we have described the Main Model at the beginning of the Results section and there are no amendments to the description of model assumptions at the trial level and the population level, here we continue to describe the Main Model at the population level.</p><p>The Main Model assumes that the population of time cells is distributed according to power-law function: <inline-formula><mml:math id="inf188"><mml:mrow><mml:mi>y</mml:mi><mml:mo>=</mml:mo><mml:msup><mml:mi>x</mml:mi><mml:mrow><mml:mo>-</mml:mo><mml:mi>α</mml:mi></mml:mrow></mml:msup></mml:mrow></mml:math></inline-formula>. A probability density function for the time field peak at <inline-formula><mml:math id="inf189"><mml:mi>τ</mml:mi></mml:math></inline-formula> can be derived within a specific range [min, max]:<disp-formula id="equ10"><label>(10)</label><mml:math id="m10"><mml:mrow><mml:mi>p</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>M</mml:mi><mml:mo>=</mml:mo><mml:mi>τ</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:msup><mml:mi>τ</mml:mi><mml:mrow><mml:mo>−</mml:mo><mml:mi>α</mml:mi></mml:mrow></mml:msup><mml:mrow><mml:mo>/</mml:mo></mml:mrow><mml:mi>c</mml:mi></mml:mrow></mml:math></disp-formula></p><p>where<disp-formula id="equ11"><label>(11)</label><mml:math id="m11"><mml:mrow><mml:mi>C</mml:mi><mml:mo>=</mml:mo><mml:mrow><mml:msubsup><mml:mo largeop="true" symmetric="true">∫</mml:mo><mml:mi>min</mml:mi><mml:mi>max</mml:mi></mml:msubsup><mml:mrow><mml:mpadded width="+1.7pt"><mml:msup><mml:mi>M</mml:mi><mml:mrow><mml:mo>-</mml:mo><mml:mi>α</mml:mi></mml:mrow></mml:msup></mml:mpadded><mml:mo>⁢</mml:mo><mml:mrow><mml:mo rspace="0pt">d</mml:mo><mml:mpadded width="+5pt"><mml:mi>M</mml:mi></mml:mpadded></mml:mrow></mml:mrow></mml:mrow></mml:mrow></mml:math></disp-formula></p><p>is the power-law function integrated over [min, max]. Dividing the power-law function by <inline-formula><mml:math id="inf190"><mml:mi>C</mml:mi></mml:math></inline-formula> ensures the area between [min, max] sums to 1, which makes it a probability distribution within the bounds.</p><p>When <inline-formula><mml:math id="inf191"><mml:mrow><mml:mi>α</mml:mi><mml:mo>≠</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:math></inline-formula>, the result of the integration is:<disp-formula id="equ12"><label>(12)</label><mml:math id="m12"><mml:mrow><mml:mi>C</mml:mi><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:msup><mml:mrow><mml:mo movablelimits="true" form="prefix">max</mml:mo></mml:mrow><mml:mrow><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:mi>α</mml:mi></mml:mrow></mml:msup><mml:mo>−</mml:mo><mml:msup><mml:mrow><mml:mo movablelimits="true" form="prefix">min</mml:mo></mml:mrow><mml:mrow><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:mi>α</mml:mi></mml:mrow></mml:msup></mml:mrow><mml:mrow><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:mi>α</mml:mi></mml:mrow></mml:mfrac></mml:mrow></mml:math></disp-formula></p><p>When  <inline-formula><mml:math id="inf192"><mml:mi>α</mml:mi></mml:math></inline-formula> = 1, the result is:<disp-formula id="equ13"><label>(13)</label><mml:math id="m13"><mml:mrow><mml:mi>C</mml:mi><mml:mo>=</mml:mo><mml:mrow><mml:mrow><mml:mi>ln</mml:mi><mml:mo>⁡</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>max</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mo>-</mml:mo><mml:mrow><mml:mi>ln</mml:mi><mml:mo>⁡</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>min</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:mrow></mml:math></disp-formula></p><p>As described above, we estimated the range through the Kolmogorov-Smirnov test prior to the hierarchical Bayesian model fitting following the procedure suggested by <xref ref-type="bibr" rid="bib14">Clauset et al., 2009</xref>.</p><p>The value of <inline-formula><mml:math id="inf193"><mml:mi>α</mml:mi></mml:math></inline-formula> reflects the degree of compression in the distribution where a higher <inline-formula><mml:math id="inf194"><mml:mi>α</mml:mi></mml:math></inline-formula> value indicates that a bigger portion of time cells fire early in the delay. Crucially, when <inline-formula><mml:math id="inf195"><mml:mi>α</mml:mi></mml:math></inline-formula> approaches zero, <xref ref-type="disp-formula" rid="equ10">Equation 10</xref> becomes <inline-formula><mml:math id="inf196"><mml:mrow><mml:mrow><mml:mi>p</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mi>M</mml:mi><mml:mo>=</mml:mo><mml:mi>τ</mml:mi></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mo>=</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mrow><mml:mi>max</mml:mi><mml:mo>-</mml:mo><mml:mi>min</mml:mi></mml:mrow></mml:mfrac></mml:mrow></mml:math></inline-formula>, a uniform distribution between [min,max]. When sorting a group of evenly distributed time cells based on their temporal locations, one would expect the time fields to form a straight line. Another value of great theoretical interest for <inline-formula><mml:math id="inf197"><mml:mi>α</mml:mi></mml:math></inline-formula> is 1: where the time cells are distributed according to logarithmic compression. When sorting the log-compressed time cells on their temporal locations, one would expect to see more time cells early in the delay. The bottom panel of <xref ref-type="fig" rid="fig2">Figure 2b</xref> shows simulated time cells with these two <inline-formula><mml:math id="inf198"><mml:mi>α</mml:mi></mml:math></inline-formula> values.</p></sec><sec id="s4-2-6"><title>Log-normal Time Field Model</title><p>The Main Model assumes the shape of time fields to be symmetric but previous research (<xref ref-type="bibr" rid="bib41">Howard et al., 2014</xref>) showed evidence for asymmetric time fields. Therefore, an alternative model assuming a log-normal shaped time field–an asymmetric receptive field–was applied to the data. Specifically, the Log-normal Time Field Model assumes that the probability of the observed spike at time t for trial i is<disp-formula id="equ14"><label>(14)</label><mml:math id="m14"><mml:mrow><mml:msub><mml:mi>p</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:msub><mml:mi>a</mml:mi><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mfrac><mml:mn>1</mml:mn><mml:mrow><mml:mi>x</mml:mi><mml:mi>σ</mml:mi><mml:msqrt><mml:mn>2</mml:mn><mml:mi>π</mml:mi></mml:msqrt></mml:mrow></mml:mfrac><mml:mi>exp</mml:mi><mml:mo>⁡</mml:mo><mml:mrow><mml:mo>[</mml:mo><mml:mrow><mml:mo>−</mml:mo><mml:mfrac><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>ln</mml:mi><mml:mo>⁡</mml:mo><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mo>−</mml:mo><mml:mi>μ</mml:mi><mml:msup><mml:mo stretchy="false">)</mml:mo><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:mrow><mml:mrow><mml:mn>2</mml:mn><mml:msup><mml:mi>σ</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:mfrac></mml:mrow><mml:mo>]</mml:mo></mml:mrow><mml:mo>+</mml:mo><mml:mfrac><mml:mrow><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:msub><mml:mi>a</mml:mi><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mrow><mml:mi>l</mml:mi></mml:mfrac></mml:mrow></mml:math></disp-formula></p><p>The Log-normal Tim Field Model is fitted in the same way as the Main Model except that the median of log-normal tuning curve, <inline-formula><mml:math id="inf199"><mml:mrow><mml:mi>exp</mml:mi><mml:mo>⁡</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>μ</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula>, is used as the time-field peak location for trial variability estimation at the cell level and temporal compression rate estimation at the population level. We used the standard deviation of the log-normal tuning curve for time field width, defined as<disp-formula id="equ15"><label>(15)</label><mml:math id="m15"><mml:mrow><mml:msub><mml:mi>σ</mml:mi><mml:mrow><mml:mi>n</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:msqrt><mml:mo stretchy="false">[</mml:mo><mml:mi>exp</mml:mi><mml:mo>⁡</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:msup><mml:mi>σ</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup><mml:mo stretchy="false">)</mml:mo><mml:mo>−</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">]</mml:mo><mml:mi>exp</mml:mi><mml:mo>⁡</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mn>2</mml:mn><mml:mi>μ</mml:mi><mml:mo>+</mml:mo><mml:msup><mml:mi>σ</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup><mml:mo stretchy="false">)</mml:mo></mml:msqrt></mml:mrow></mml:math></disp-formula></p></sec><sec id="s4-2-7"><title>Alternative Trial Vary Model</title><p>The Main Model assumes the width of the time field stays consistent across trials, and the location of the time field shifts from trial to trial. Instead the Alternative Trial Vary Model assumes the time field location is fixed while the width varies across trials. Therefore the time field width for the specific trial <inline-formula><mml:math id="inf200"><mml:mi>i</mml:mi></mml:math></inline-formula>, <inline-formula><mml:math id="inf201"><mml:msub><mml:mi>σ</mml:mi><mml:mrow><mml:mi>w</mml:mi><mml:mo>⁢</mml:mo><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula>, is sampled from a normal distribution centered at <inline-formula><mml:math id="inf202"><mml:msub><mml:mi>σ</mml:mi><mml:mi>W</mml:mi></mml:msub></mml:math></inline-formula>:<disp-formula id="equ16"><label>(16)</label><mml:math id="m16"><mml:mrow><mml:msub><mml:mi>σ</mml:mi><mml:mrow><mml:mi>w</mml:mi><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>∼</mml:mo><mml:mrow><mml:mi mathvariant="script">N</mml:mi></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>σ</mml:mi><mml:mrow><mml:mi>W</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:mspace width="thinmathspace"/><mml:msubsup><mml:mi>σ</mml:mi><mml:mrow><mml:mi>t</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></disp-formula></p></sec><sec id="s4-2-8"><title>Exponential Compression Model and Weibull Compression Model</title><p>The Main Model assumes the compression at the population level is quantified with a power law distribution. Here, we tested two alternative common compression assumptions.</p><p>The Exponential Compression Model assumes that the time cell peaks M is distributed according to<disp-formula id="equ17"><label>(17)</label><mml:math id="m17"><mml:mrow><mml:mi>p</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>M</mml:mi><mml:mo>=</mml:mo><mml:mi>τ</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mi>β</mml:mi><mml:mi>exp</mml:mi><mml:mo>⁡</mml:mo><mml:mrow><mml:mo>−</mml:mo><mml:mi>β</mml:mi><mml:mi>τ</mml:mi></mml:mrow></mml:mrow></mml:math></disp-formula></p><p>The Weibull Compression Model assumes that time field peaks M is distributed as<disp-formula id="equ18"><label>(18)</label><mml:math id="m18"><mml:mrow><mml:mi>p</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>M</mml:mi><mml:mo>=</mml:mo><mml:mi>τ</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mfrac><mml:mi>k</mml:mi><mml:mi>λ</mml:mi></mml:mfrac><mml:msup><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mfrac><mml:mi>τ</mml:mi><mml:mi>λ</mml:mi></mml:mfrac><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mrow><mml:mi>k</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msup><mml:mi>exp</mml:mi><mml:mo>⁡</mml:mo><mml:mrow><mml:mrow><mml:mo>[</mml:mo><mml:mrow><mml:mo>−</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mfrac><mml:mi>τ</mml:mi><mml:mi>λ</mml:mi></mml:mfrac></mml:mrow><mml:msup><mml:mo stretchy="false">)</mml:mo><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:msup></mml:mrow><mml:mo>]</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:math></disp-formula></p><p>The <inline-formula><mml:math id="inf203"><mml:mi>k</mml:mi></mml:math></inline-formula> parameter controls the compression rate and results in a wide range of shapes that can be used to describe the asymmetry we clearly observed in time cell peak distributions. Specifically, when <inline-formula><mml:math id="inf204"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>k</mml:mi><mml:mo>&lt;</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:mstyle></mml:math></inline-formula>, more time cells would fire early; when <inline-formula><mml:math id="inf205"><mml:mrow><mml:mi>k</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:math></inline-formula>, it becomes the exponential distribution; and when <inline-formula><mml:math id="inf206"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>k</mml:mi><mml:mo>&gt;</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:mstyle></mml:math></inline-formula>, it can approximate some heavy tail distributions such as ex-Gaussian or log-normal (<xref ref-type="bibr" rid="bib64">Logan, 1995</xref>).</p></sec></sec></sec></body><back><sec sec-type="additional-information" id="s5"><title>Additional information</title><fn-group content-type="competing-interest"><title>Competing interests</title><fn fn-type="COI-statement" id="conf1"><p>No competing interests declared</p></fn><fn fn-type="COI-statement" id="conf2"><p>No competing interests declared</p></fn></fn-group><fn-group content-type="author-contribution"><title>Author contributions</title><fn fn-type="con" id="con1"><p>Formal analysis, Visualization, Methodology, Writing – original draft</p></fn><fn fn-type="con" id="con2"><p>Data curation, Investigation, Writing – original draft</p></fn><fn fn-type="con" id="con3"><p>Data curation, Software</p></fn><fn fn-type="con" id="con4"><p>Conceptualization, Resources, Supervision, Funding acquisition</p></fn><fn fn-type="con" id="con5"><p>Conceptualization, Supervision, Funding acquisition, Project administration, Writing - review and editing</p></fn></fn-group><fn-group content-type="ethics-information"><title>Ethics</title><fn fn-type="other"><p>All procedures were conducted in accordance with the requirements set by the National Institutes of Health, and were approved by the Boston University Institutional Animal Care and Use Committee (BU IACUC protocol #16-021). Animals were given ad-libitum water and maintained at a minimum of 85% of their ad libitum feeding body weight during all behavioral training and testing. Surgeries were performed under isoflurane anesthesia, and analgesics were administered postoperatively.</p></fn></fn-group></sec><sec sec-type="supplementary-material" id="s6"><title>Additional files</title><supplementary-material id="transrepform"><label>Transparent reporting form</label><media xlink:href="elife-75353-transrepform1-v2.pdf" mimetype="application" mime-subtype="pdf"/></supplementary-material></sec><sec sec-type="data-availability" id="s7"><title>Data availability</title><p>The data and code for all the analysis is available on Open Science Framework at <ext-link ext-link-type="uri" xlink:href="https://osf.io/pqhjz/">https://osf.io/pqhjz/</ext-link>.</p><p>The following dataset was generated:</p><p><element-citation publication-type="data" specific-use="isSupplementedBy" id="dataset1"><person-group person-group-type="author"><name><surname>Cao</surname><given-names>R</given-names></name><name><surname>Bladon</surname><given-names>JH</given-names></name><name><surname>Charczynski</surname><given-names>SJ</given-names></name><name><surname>Hasselmo</surname><given-names>ME</given-names></name><name><surname>Howard</surname><given-names>MW</given-names></name></person-group><year iso-8601-date="2021">2021</year><data-title>Weber-Fechner Time cells</data-title><source>Open Science Framework</source><pub-id pub-id-type="accession" xlink:href="https://osf.io/pqhjz/">pqhjz</pub-id></element-citation></p></sec><ack id="ack"><title>Acknowledgements</title><p>The authors gratefully acknowledge support from ONR MURI N00014-16-1-2832, NIBIB R01EB022864, NIMH R01MH112169, NIMH R01MH095297, and NIMH R01MH132171. The authors gratefully acknowledge the contributions of Howard Eichenbaum to designing the behavioral task and data collection in this study.</p></ack><ref-list><title>References</title><ref id="bib1"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Akhlaghpour</surname><given-names>H</given-names></name><name><surname>Wiskerke</surname><given-names>J</given-names></name><name><surname>Choi</surname><given-names>JY</given-names></name><name><surname>Taliaferro</surname><given-names>JP</given-names></name><name><surname>Au</surname><given-names>J</given-names></name><name><surname>Witten</surname><given-names>IB</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Dissociated sequential activity and stimulus encoding in the dorsomedial striatum during spatial working memory</article-title><source>eLife</source><volume>5</volume><elocation-id>e19507</elocation-id><pub-id pub-id-type="doi">10.7554/eLife.19507</pub-id><pub-id pub-id-type="pmid">27636864</pub-id></element-citation></ref><ref id="bib2"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Anderson</surname><given-names>J</given-names></name><name><surname>Schooler</surname><given-names>L</given-names></name></person-group><year iso-8601-date="1991">1991</year><article-title>Reflections of the environment in memory</article-title><source>Psycho981 Logical Science</source><volume>2</volume><fpage>396</fpage><lpage>408</lpage><pub-id pub-id-type="doi">10.1111/j.1467-9280.1991.tb00174</pub-id></element-citation></ref><ref id="bib3"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Arzy</surname><given-names>S</given-names></name><name><surname>Adi-Japha</surname><given-names>E</given-names></name><name><surname>Blanke</surname><given-names>O</given-names></name></person-group><year iso-8601-date="2009">2009</year><article-title>The mental time line: an analogue of the mental number line in the mapping of life events</article-title><source>Consciousness and Cognition</source><volume>18</volume><fpage>781</fpage><lpage>785</lpage><pub-id pub-id-type="doi">10.1016/j.concog.2009.05.007</pub-id><pub-id pub-id-type="pmid">19553141</pub-id></element-citation></ref><ref id="bib4"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Balasubramaniam</surname><given-names>R</given-names></name><name><surname>Haegens</surname><given-names>S</given-names></name><name><surname>Jazayeri</surname><given-names>M</given-names></name><name><surname>Merchant</surname><given-names>H</given-names></name><name><surname>Sternad</surname><given-names>D</given-names></name><name><surname>Song</surname><given-names>JH</given-names></name></person-group><year iso-8601-date="2021">2021</year><article-title>Neural encoding and representation of time for sensorimotor control and learning</article-title><source>The Journal of Neuroscience</source><volume>41</volume><fpage>866</fpage><lpage>872</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.1652-20.2020</pub-id><pub-id pub-id-type="pmid">33380468</pub-id></element-citation></ref><ref id="bib5"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Barron</surname><given-names>HC</given-names></name><name><surname>Reeve</surname><given-names>HM</given-names></name><name><surname>Koolschijn</surname><given-names>RS</given-names></name><name><surname>Perestenko</surname><given-names>PV</given-names></name><name><surname>Shpektor</surname><given-names>A</given-names></name><name><surname>Nili</surname><given-names>H</given-names></name><name><surname>Rothaermel</surname><given-names>R</given-names></name><name><surname>Campo-Urriza</surname><given-names>N</given-names></name><name><surname>O’Reilly</surname><given-names>JX</given-names></name><name><surname>Bannerman</surname><given-names>DM</given-names></name><name><surname>Behrens</surname><given-names>TEJ</given-names></name><name><surname>Dupret</surname><given-names>D</given-names></name></person-group><year iso-8601-date="2020">2020</year><article-title>Neuronal computation underlying inferential reasoning in humans and mice</article-title><source>Cell</source><volume>183</volume><fpage>228</fpage><lpage>243</lpage><pub-id pub-id-type="doi">10.1016/j.cell.2020.08.035</pub-id><pub-id pub-id-type="pmid">32946810</pub-id></element-citation></ref><ref id="bib6"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bjerknes</surname><given-names>TL</given-names></name><name><surname>Dagslott</surname><given-names>NC</given-names></name><name><surname>Moser</surname><given-names>EI</given-names></name><name><surname>Moser</surname><given-names>MB</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>Path integration in place cells of developing rats</article-title><source>PNAS</source><volume>115</volume><fpage>E1637</fpage><lpage>E1646</lpage><pub-id pub-id-type="doi">10.1073/pnas.1719054115</pub-id><pub-id pub-id-type="pmid">29382754</pub-id></element-citation></ref><ref id="bib7"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Brannon</surname><given-names>EM</given-names></name></person-group><year iso-8601-date="2006">2006</year><article-title>The representation of numerical magnitude</article-title><source>Current Opinion in Neurobiology</source><volume>16</volume><fpage>222</fpage><lpage>229</lpage><pub-id pub-id-type="doi">10.1016/j.conb.2006.03.002</pub-id><pub-id pub-id-type="pmid">16546373</pub-id></element-citation></ref><ref id="bib8"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bright</surname><given-names>IM</given-names></name><name><surname>Meister</surname><given-names>MLR</given-names></name><name><surname>Cruzado</surname><given-names>NA</given-names></name><name><surname>Tiganj</surname><given-names>Z</given-names></name><name><surname>Buffalo</surname><given-names>EA</given-names></name><name><surname>Howard</surname><given-names>MW</given-names></name></person-group><year iso-8601-date="2020">2020</year><article-title>A temporal record of the past with A spectrum of time constants in the monkey entorhinal cortex</article-title><source>PNAS</source><volume>117</volume><fpage>20274</fpage><lpage>20283</lpage><pub-id pub-id-type="doi">10.1073/pnas.1917197117</pub-id><pub-id pub-id-type="pmid">32747574</pub-id></element-citation></ref><ref id="bib9"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Brunel</surname><given-names>N</given-names></name><name><surname>Nadal</surname><given-names>JP</given-names></name></person-group><year iso-8601-date="1998">1998</year><article-title>Mutual information, Fisher information, and population coding</article-title><source>Neural Computation</source><volume>10</volume><fpage>1731</fpage><lpage>1757</lpage><pub-id pub-id-type="doi">10.1162/089976698300017115</pub-id><pub-id pub-id-type="pmid">9744895</pub-id></element-citation></ref><ref id="bib10"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Cai</surname><given-names>DJ</given-names></name><name><surname>Aharoni</surname><given-names>D</given-names></name><name><surname>Shuman</surname><given-names>T</given-names></name><name><surname>Shobe</surname><given-names>J</given-names></name><name><surname>Biane</surname><given-names>J</given-names></name><name><surname>Song</surname><given-names>W</given-names></name><name><surname>Wei</surname><given-names>B</given-names></name><name><surname>Veshkini</surname><given-names>M</given-names></name><name><surname>La-Vu</surname><given-names>M</given-names></name><name><surname>Lou</surname><given-names>J</given-names></name><name><surname>Flores</surname><given-names>SE</given-names></name><name><surname>Kim</surname><given-names>I</given-names></name><name><surname>Sano</surname><given-names>Y</given-names></name><name><surname>Zhou</surname><given-names>M</given-names></name><name><surname>Baumgaertel</surname><given-names>K</given-names></name><name><surname>Lavi</surname><given-names>A</given-names></name><name><surname>Kamata</surname><given-names>M</given-names></name><name><surname>Tuszynski</surname><given-names>M</given-names></name><name><surname>Mayford</surname><given-names>M</given-names></name><name><surname>Golshani</surname><given-names>P</given-names></name><name><surname>Silva</surname><given-names>AJ</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>A shared neural ensemble links distinct contextual memories encoded close in time</article-title><source>Nature</source><volume>534</volume><fpage>115</fpage><lpage>118</lpage><pub-id pub-id-type="doi">10.1038/nature17955</pub-id><pub-id pub-id-type="pmid">27251287</pub-id></element-citation></ref><ref id="bib11"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Cantlon</surname><given-names>JF</given-names></name><name><surname>Brannon</surname><given-names>EM</given-names></name><name><surname>Carter</surname><given-names>EJ</given-names></name><name><surname>Pelphrey</surname><given-names>KA</given-names></name></person-group><year iso-8601-date="2006">2006</year><article-title>Functional imaging of numerical processing in adults and 4-y-old children</article-title><source>PLOS Biology</source><volume>4</volume><elocation-id>e125</elocation-id><pub-id pub-id-type="doi">10.1371/journal.pbio.0040125</pub-id><pub-id pub-id-type="pmid">16594732</pub-id></element-citation></ref><ref id="bib12"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Cavanagh</surname><given-names>SE</given-names></name><name><surname>Hunt</surname><given-names>LT</given-names></name><name><surname>Kennerley</surname><given-names>SW</given-names></name></person-group><year iso-8601-date="2020">2020</year><article-title>A diversity of intrinsic timescales underlie neural computations</article-title><source>Frontiers in Neural Circuits</source><volume>14</volume><elocation-id>615626</elocation-id><pub-id pub-id-type="doi">10.3389/fncir.2020.615626</pub-id><pub-id pub-id-type="pmid">33408616</pub-id></element-citation></ref><ref id="bib13"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Chaudhuri</surname><given-names>R</given-names></name><name><surname>Gerçek</surname><given-names>B</given-names></name><name><surname>Pandey</surname><given-names>B</given-names></name><name><surname>Peyrache</surname><given-names>A</given-names></name><name><surname>Fiete</surname><given-names>I</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>The intrinsic attractor manifold and population dynamics of a canonical cognitive circuit across waking and sleep</article-title><source>Nature Neuroscience</source><volume>22</volume><fpage>1512</fpage><lpage>1520</lpage><pub-id pub-id-type="doi">10.1038/s41593-019-0460-x</pub-id><pub-id pub-id-type="pmid">31406365</pub-id></element-citation></ref><ref id="bib14"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Clauset</surname><given-names>A</given-names></name><name><surname>Shalizi</surname><given-names>CR</given-names></name><name><surname>Newman</surname><given-names>MEJ</given-names></name></person-group><year iso-8601-date="2009">2009</year><article-title>Power-Law distributions in empirical data</article-title><source>SIAM Review</source><volume>51</volume><fpage>661</fpage><lpage>703</lpage><pub-id pub-id-type="doi">10.1137/070710111</pub-id></element-citation></ref><ref id="bib15"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Cortis Mack</surname><given-names>C</given-names></name><name><surname>Cinel</surname><given-names>C</given-names></name><name><surname>Davies</surname><given-names>N</given-names></name><name><surname>Harding</surname><given-names>M</given-names></name><name><surname>Ward</surname><given-names>G</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>Serial position, output order, and list length effects for words presented on smartphones over very long intervals</article-title><source>Journal of Memory and Language</source><volume>97</volume><fpage>61</fpage><lpage>80</lpage><pub-id pub-id-type="doi">10.1016/j.jml.2017.07.009</pub-id><pub-id pub-id-type="pmid">29200611</pub-id></element-citation></ref><ref id="bib16"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Crowe</surname><given-names>DA</given-names></name><name><surname>Zarco</surname><given-names>W</given-names></name><name><surname>Bartolo</surname><given-names>R</given-names></name><name><surname>Merchant</surname><given-names>H</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>Dynamic representation of the temporal and sequential structure of rhythmic movements in the primate medial premotor cortex</article-title><source>The Journal of Neuroscience</source><volume>34</volume><fpage>11972</fpage><lpage>11983</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.2177-14.2014</pub-id><pub-id pub-id-type="pmid">25186744</pub-id></element-citation></ref><ref id="bib17"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Cruzado</surname><given-names>NA</given-names></name><name><surname>Tiganj</surname><given-names>Z</given-names></name><name><surname>Brincat</surname><given-names>SL</given-names></name><name><surname>Miller</surname><given-names>EK</given-names></name><name><surname>Howard</surname><given-names>MW</given-names></name></person-group><year iso-8601-date="2020">2020</year><article-title>Conjunctive representation of what and when in monkey hippocampus and lateral prefrontal cortex during an associative memory task</article-title><source>Hippocampus</source><volume>30</volume><fpage>1332</fpage><lpage>1346</lpage><pub-id pub-id-type="doi">10.1002/hipo.23282</pub-id><pub-id pub-id-type="pmid">33174670</pub-id></element-citation></ref><ref id="bib18"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Cueva</surname><given-names>CJ</given-names></name><name><surname>Saez</surname><given-names>A</given-names></name><name><surname>Marcos</surname><given-names>E</given-names></name><name><surname>Genovesio</surname><given-names>A</given-names></name><name><surname>Jazayeri</surname><given-names>M</given-names></name><name><surname>Romo</surname><given-names>R</given-names></name><name><surname>Salzman</surname><given-names>CD</given-names></name><name><surname>Shadlen</surname><given-names>MN</given-names></name><name><surname>Fusi</surname><given-names>S</given-names></name></person-group><year iso-8601-date="2020">2020</year><article-title>Low-dimensional dynamics for working memory and time encoding</article-title><source>PNAS</source><volume>117</volume><fpage>23021</fpage><lpage>23032</lpage><pub-id pub-id-type="doi">10.1073/pnas.1915984117</pub-id><pub-id pub-id-type="pmid">32859756</pub-id></element-citation></ref><ref id="bib19"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Daniel</surname><given-names>PM</given-names></name><name><surname>Whitteridge</surname><given-names>D</given-names></name></person-group><year iso-8601-date="1961">1961</year><article-title>The representation of the visual field on the cerebral cortex in monkeys</article-title><source>The Journal of Physiology</source><volume>159</volume><fpage>203</fpage><lpage>221</lpage><pub-id pub-id-type="doi">10.1113/jphysiol.1961.sp006803</pub-id><pub-id pub-id-type="pmid">13883391</pub-id></element-citation></ref><ref id="bib20"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Dannenberg</surname><given-names>H</given-names></name><name><surname>Kelley</surname><given-names>C</given-names></name><name><surname>Hoyland</surname><given-names>A</given-names></name><name><surname>Monaghan</surname><given-names>CK</given-names></name><name><surname>Hasselmo</surname><given-names>ME</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>The firing rate speed code of entorhinal speed cells differs across behaviorally relevant time scales and does not depend on medial septum inputs</article-title><source>The Journal of Neuroscience</source><volume>1</volume><fpage>1418</fpage><lpage>1450</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.1450-18.2019</pub-id><pub-id pub-id-type="pmid">30804092</pub-id></element-citation></ref><ref id="bib21"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Dehaene</surname><given-names>S</given-names></name><name><surname>Brannon</surname><given-names>E</given-names></name></person-group><year iso-8601-date="2011">2011</year><source>Space, Time and Number in the Brain: Searching for the Foundations of Mathematical Thought</source><publisher-name>Academic Press</publisher-name><pub-id pub-id-type="doi">10.1016/C2010-0-66570-9</pub-id></element-citation></ref><ref id="bib22"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Dumoulin</surname><given-names>SO</given-names></name><name><surname>Wandell</surname><given-names>BA</given-names></name></person-group><year iso-8601-date="2008">2008</year><article-title>Population receptive field estimates in human visual cortex</article-title><source>NeuroImage</source><volume>39</volume><fpage>647</fpage><lpage>660</lpage><pub-id pub-id-type="doi">10.1016/j.neuroimage.2007.09.034</pub-id><pub-id pub-id-type="pmid">17977024</pub-id></element-citation></ref><ref id="bib23"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Egorov</surname><given-names>AV</given-names></name><name><surname>Hamam</surname><given-names>BN</given-names></name><name><surname>Fransén</surname><given-names>E</given-names></name><name><surname>Hasselmo</surname><given-names>ME</given-names></name><name><surname>Alonso</surname><given-names>AA</given-names></name></person-group><year iso-8601-date="2002">2002</year><article-title>Graded persistent activity in entorhinal cortex neurons</article-title><source>Nature</source><volume>420</volume><fpage>173</fpage><lpage>178</lpage><pub-id pub-id-type="doi">10.1038/nature01171</pub-id><pub-id pub-id-type="pmid">12432392</pub-id></element-citation></ref><ref id="bib24"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Eichenbaum</surname><given-names>H</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>Time (and space) in the hippocampus</article-title><source>Current Opinion in Behavioral Sciences</source><volume>17</volume><fpage>65</fpage><lpage>70</lpage><pub-id pub-id-type="doi">10.1016/j.cobeha.2017.06.010</pub-id><pub-id pub-id-type="pmid">28840180</pub-id></element-citation></ref><ref id="bib25"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Fechner</surname><given-names>GT</given-names></name></person-group><year iso-8601-date="1860">1860</year><source>Elemente Der Psychophysik</source><publisher-name>Breitkopf u. Härtel</publisher-name></element-citation></ref><ref id="bib26"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Feigenson</surname><given-names>L</given-names></name><name><surname>Dehaene</surname><given-names>S</given-names></name><name><surname>Spelke</surname><given-names>E</given-names></name></person-group><year iso-8601-date="2004">2004</year><article-title>Core systems of number</article-title><source>Trends in Cognitive Sciences</source><volume>8</volume><fpage>307</fpage><lpage>314</lpage><pub-id pub-id-type="doi">10.1016/j.tics.2004.05.002</pub-id><pub-id pub-id-type="pmid">15242690</pub-id></element-citation></ref><ref id="bib27"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Gallistel</surname><given-names>CR</given-names></name></person-group><year iso-8601-date="1989">1989</year><article-title>Animal cognition: the representation of space, time and number</article-title><source>Annual Review of Psychology</source><volume>40</volume><fpage>155</fpage><lpage>189</lpage><pub-id pub-id-type="doi">10.1146/annurev.ps.40.020189.001103</pub-id><pub-id pub-id-type="pmid">2648974</pub-id></element-citation></ref><ref id="bib28"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Gallistel</surname><given-names>CR</given-names></name><name><surname>Gelman</surname><given-names>R</given-names></name></person-group><year iso-8601-date="2000">2000</year><article-title>Non-verbal numerical cognition: from reals to integers</article-title><source>Trends in Cognitive Sciences</source><volume>4</volume><fpage>59</fpage><lpage>65</lpage><pub-id pub-id-type="doi">10.1016/s1364-6613(99)01424-2</pub-id><pub-id pub-id-type="pmid">10652523</pub-id></element-citation></ref><ref id="bib29"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Gattass</surname><given-names>R</given-names></name><name><surname>Gross</surname><given-names>CG</given-names></name><name><surname>Sandell</surname><given-names>JH</given-names></name></person-group><year iso-8601-date="1981">1981</year><article-title>Visual topography of V2 in the macaque</article-title><source>The Journal of Comparative Neurology</source><volume>201</volume><fpage>519</fpage><lpage>539</lpage><pub-id pub-id-type="doi">10.1002/cne.902010405</pub-id><pub-id pub-id-type="pmid">7287933</pub-id></element-citation></ref><ref id="bib30"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Gibbon</surname><given-names>J</given-names></name></person-group><year iso-8601-date="1977">1977</year><article-title>Scalar expectancy theory and weber’s law in animal timing</article-title><source>Psychological Review</source><volume>84</volume><fpage>279</fpage><lpage>325</lpage><pub-id pub-id-type="doi">10.1037/0033-295X.84.3.279</pub-id></element-citation></ref><ref id="bib31"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Gibbon</surname><given-names>J</given-names></name><name><surname>Church</surname><given-names>RM</given-names></name><name><surname>Meck</surname><given-names>WH</given-names></name></person-group><year iso-8601-date="1984">1984</year><article-title>Scalar timing in memory</article-title><source>Annals of the New York Academy of Sciences</source><volume>423</volume><fpage>52</fpage><lpage>77</lpage><pub-id pub-id-type="doi">10.1111/j.1749-6632.1984.tb23417.x</pub-id><pub-id pub-id-type="pmid">6588812</pub-id></element-citation></ref><ref id="bib32"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Glezer</surname><given-names>VD</given-names></name></person-group><year iso-8601-date="1965">1965</year><article-title>The receptive fields of the retina</article-title><source>Vision Research</source><volume>5</volume><fpage>497</fpage><lpage>525</lpage><pub-id pub-id-type="doi">10.1016/0042-6989(65)90084-2</pub-id><pub-id pub-id-type="pmid">5862172</pub-id></element-citation></ref><ref id="bib33"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Gothard</surname><given-names>KM</given-names></name><name><surname>Skaggs</surname><given-names>WE</given-names></name><name><surname>Moore</surname><given-names>KM</given-names></name><name><surname>McNaughton</surname><given-names>BL</given-names></name></person-group><year iso-8601-date="1996">1996</year><article-title>Binding of hippocampal CA1 neural activity to multiple reference frames in a landmark-based navigation task</article-title><source>The Journal of Neuroscience</source><volume>16</volume><fpage>823</fpage><lpage>835</lpage><pub-id pub-id-type="pmid">8551362</pub-id></element-citation></ref><ref id="bib34"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Gothard</surname><given-names>KM</given-names></name><name><surname>Hoffman</surname><given-names>KL</given-names></name><name><surname>Battaglia</surname><given-names>FP</given-names></name><name><surname>McNaughton</surname><given-names>BL</given-names></name></person-group><year iso-8601-date="2001">2001</year><article-title>Dentate gyrus and CA1 ensemble activity during spatial reference frame shifts in the presence and absence of visual input</article-title><source>The Journal of Neuroscience</source><volume>21</volume><fpage>7284</fpage><lpage>7292</lpage><pub-id pub-id-type="pmid">11549738</pub-id></element-citation></ref><ref id="bib35"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Guo</surname><given-names>C</given-names></name><name><surname>Huson</surname><given-names>V</given-names></name><name><surname>Macosko</surname><given-names>EZ</given-names></name><name><surname>Regehr</surname><given-names>WG</given-names></name></person-group><year iso-8601-date="2021">2021</year><article-title>Graded heterogeneity of metabotropic signaling underlies a continuum of cell-intrinsic temporal responses in unipolar brush cells</article-title><source>Nature Communications</source><volume>12</volume><fpage>1</fpage><lpage>12</lpage><pub-id pub-id-type="doi">10.1038/s41467-021-22893-8</pub-id><pub-id pub-id-type="pmid">34620856</pub-id></element-citation></ref><ref id="bib36"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Harland</surname><given-names>B</given-names></name><name><surname>Contreras</surname><given-names>M</given-names></name><name><surname>Souder</surname><given-names>M</given-names></name><name><surname>Fellous</surname><given-names>JM</given-names></name></person-group><year iso-8601-date="2021">2021</year><article-title>Dorsal CA1 hippocampal place cells form a multi-scale representation of megaspace</article-title><source>Current Biology</source><volume>31</volume><fpage>2178</fpage><lpage>2190</lpage><pub-id pub-id-type="doi">10.1016/j.cub.2021.03.003</pub-id><pub-id pub-id-type="pmid">33770492</pub-id></element-citation></ref><ref id="bib37"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Healey</surname><given-names>MK</given-names></name><name><surname>Kahana</surname><given-names>MJ</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>Is memory search governed by universal principles or idiosyncratic strategies?</article-title><source>Journal of Experimental Psychology. General</source><volume>143</volume><fpage>575</fpage><lpage>596</lpage><pub-id pub-id-type="doi">10.1037/a0033715</pub-id><pub-id pub-id-type="pmid">23957279</pub-id></element-citation></ref><ref id="bib38"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Heys</surname><given-names>JG</given-names></name><name><surname>Dombeck</surname><given-names>DA</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>Evidence for a subcircuit in medial entorhinal cortex representing elapsed time during immobility</article-title><source>Nature Neuroscience</source><volume>21</volume><fpage>1574</fpage><lpage>1582</lpage><pub-id pub-id-type="doi">10.1038/s41593-018-0252-8</pub-id><pub-id pub-id-type="pmid">30349104</pub-id></element-citation></ref><ref id="bib39"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Howard</surname><given-names>M.W</given-names></name><name><surname>Kahana</surname><given-names>MJ</given-names></name></person-group><year iso-8601-date="1999">1999</year><article-title>Contextual variability and serial position effects in free recall</article-title><source>Journal of Experimental Psychology. Learning, Memory, and Cognition</source><volume>25</volume><fpage>923</fpage><lpage>941</lpage><pub-id pub-id-type="doi">10.1037//0278-7393.25.4.923</pub-id><pub-id pub-id-type="pmid">10439501</pub-id></element-citation></ref><ref id="bib40"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Howard</surname><given-names>MW</given-names></name><name><surname>Youker</surname><given-names>TE</given-names></name><name><surname>Venkatadass</surname><given-names>V</given-names></name></person-group><year iso-8601-date="2008">2008</year><article-title>The persistence of memory: contiguity effects across several minutes</article-title><source>PBR</source><volume>15</volume><fpage>58</fpage><lpage>63</lpage><pub-id pub-id-type="doi">10.3758/PBR.15.1.58</pub-id><pub-id pub-id-type="pmid">18605480</pub-id></element-citation></ref><ref id="bib41"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Howard</surname><given-names>M.W</given-names></name><name><surname>MacDonald</surname><given-names>CJ</given-names></name><name><surname>Tiganj</surname><given-names>Z</given-names></name><name><surname>Shankar</surname><given-names>KH</given-names></name><name><surname>Du</surname><given-names>Q</given-names></name><name><surname>Hasselmo</surname><given-names>ME</given-names></name><name><surname>Eichenbaum</surname><given-names>H</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>A unified mathematical framework for coding time, space, and sequences in the hippocampal region</article-title><source>The Journal of Neuroscience</source><volume>34</volume><fpage>4692</fpage><lpage>4707</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.5808-12.2014</pub-id><pub-id pub-id-type="pmid">24672015</pub-id></element-citation></ref><ref id="bib42"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Howard</surname><given-names>MW</given-names></name><name><surname>Shankar</surname><given-names>KH</given-names></name><name><surname>Aue</surname><given-names>WR</given-names></name><name><surname>Criss</surname><given-names>AH</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>A distributed representation of internal time</article-title><source>Psychological Review</source><volume>122</volume><fpage>24</fpage><lpage>53</lpage><pub-id pub-id-type="doi">10.1037/a0037840</pub-id><pub-id pub-id-type="pmid">25330329</pub-id></element-citation></ref><ref id="bib43"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Howard</surname><given-names>M.W</given-names></name><name><surname>Shankar</surname><given-names>KH</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>Neural scaling laws for an uncertain world</article-title><source>Psychological Review</source><volume>125</volume><fpage>47</fpage><lpage>58</lpage><pub-id pub-id-type="doi">10.1037/rev0000081</pub-id><pub-id pub-id-type="pmid">29035080</pub-id></element-citation></ref><ref id="bib44"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hsu</surname><given-names>A</given-names></name><name><surname>Marzen</surname><given-names>SE</given-names></name></person-group><year iso-8601-date="2020">2020</year><article-title>Time cells might be optimized for predictive capacity, not redundancy reduction or memory capacity</article-title><source>Physical Review. E</source><volume>102</volume><elocation-id>062404</elocation-id><pub-id pub-id-type="doi">10.1103/PhysRevE.102.062404</pub-id><pub-id pub-id-type="pmid">33465990</pub-id></element-citation></ref><ref id="bib45"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hubel</surname><given-names>DH</given-names></name><name><surname>Wiesel</surname><given-names>TN</given-names></name></person-group><year iso-8601-date="1974">1974</year><article-title>Uniformity of monkey striate cortex: a parallel relationship between field size, scatter, and magnification factor</article-title><source>The Journal of Comparative Neurology</source><volume>158</volume><fpage>295</fpage><lpage>305</lpage><pub-id pub-id-type="doi">10.1002/cne.901580305</pub-id><pub-id pub-id-type="pmid">4436457</pub-id></element-citation></ref><ref id="bib46"><element-citation publication-type="preprint"><person-group person-group-type="author"><name><surname>Jacques</surname><given-names>B</given-names></name><name><surname>Tiganj</surname><given-names>Z</given-names></name><name><surname>Howard</surname><given-names>MW</given-names></name><name><surname>Sederberg</surname><given-names>PB</given-names></name></person-group><year iso-8601-date="2021">2021</year><article-title>DeepSITH: Efficient Learning via Decomposition of What and When Across Time Scales</article-title><source>arXiv</source><pub-id pub-id-type="doi">10.48550/arXiv.2104.04646</pub-id></element-citation></ref><ref id="bib47"><element-citation publication-type="confproc"><person-group person-group-type="author"><name><surname>Jacques</surname><given-names>BG</given-names></name><name><surname>Tiganj</surname><given-names>Z</given-names></name><name><surname>Sarkar</surname><given-names>A</given-names></name><name><surname>Howard</surname><given-names>M</given-names></name><name><surname>Sederberg</surname><given-names>P</given-names></name></person-group><year iso-8601-date="2022">2022</year><article-title>A deep convolutional neural network that is invariant to time rescaling</article-title><conf-name>In: International Conference on Machine Learning PMLR</conf-name><fpage>9729</fpage><lpage>9738</lpage></element-citation></ref><ref id="bib48"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Jansson</surname><given-names>Y</given-names></name><name><surname>Lindeberg</surname><given-names>T</given-names></name></person-group><year iso-8601-date="2022">2022</year><article-title>Scale-invariant scale-channel networks: deep networks that generalise to previously unseen scales</article-title><source>Journal of Mathematical Imaging and Vision</source><volume>64</volume><fpage>506</fpage><lpage>536</lpage><pub-id pub-id-type="doi">10.1007/s10851-022-01082-2</pub-id></element-citation></ref><ref id="bib49"><element-citation publication-type="software"><person-group person-group-type="author"><collab>JASP Team</collab></person-group><year iso-8601-date="2022">2022</year><data-title>JASP</data-title><version designator="0.16.3">0.16.3</version><source>Jasp-Stats</source><ext-link ext-link-type="uri" xlink:href="https://jasp-stats.org/">https://jasp-stats.org/</ext-link></element-citation></ref><ref id="bib50"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Jin</surname><given-names>DZ</given-names></name><name><surname>Fujii</surname><given-names>N</given-names></name><name><surname>Graybiel</surname><given-names>AM</given-names></name></person-group><year iso-8601-date="2009">2009</year><article-title>Neural representation of time in cortico-basal ganglia circuits</article-title><source>PNAS</source><volume>106</volume><fpage>19156</fpage><lpage>19161</lpage><pub-id pub-id-type="doi">10.1073/pnas.0909881106</pub-id><pub-id pub-id-type="pmid">19850874</pub-id></element-citation></ref><ref id="bib51"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kahana</surname><given-names>MJ</given-names></name></person-group><year iso-8601-date="1996">1996</year><article-title>Associative retrieval processes in free recall</article-title><source>Memory &amp; Cognition</source><volume>24</volume><fpage>103</fpage><lpage>109</lpage><pub-id pub-id-type="doi">10.3758/bf03197276</pub-id><pub-id pub-id-type="pmid">8822162</pub-id></element-citation></ref><ref id="bib52"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Kahana</surname><given-names>MJ</given-names></name></person-group><year iso-8601-date="2008">2008</year><chapter-title>Associative processes in episodic memory</chapter-title><person-group person-group-type="editor"><name><surname>Roediger III</surname><given-names>HL</given-names></name></person-group><source>Learning and Memory: A Comprehensive Reference</source><publisher-name>Elsevier</publisher-name><fpage>476</fpage><lpage>490</lpage></element-citation></ref><ref id="bib53"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Kahana</surname><given-names>MJ</given-names></name></person-group><year iso-8601-date="2012">2012</year><source>Foundations of Human Memory</source><publisher-name>OUP</publisher-name></element-citation></ref><ref id="bib54"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Keene</surname><given-names>CS</given-names></name><name><surname>Bladon</surname><given-names>J</given-names></name><name><surname>McKenzie</surname><given-names>S</given-names></name><name><surname>Liu</surname><given-names>CD</given-names></name><name><surname>O’Keefe</surname><given-names>J</given-names></name><name><surname>Eichenbaum</surname><given-names>H</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Complementary functional organization of neuronal activity patterns in the perirhinal, lateral entorhinal, and medial entorhinal cortices</article-title><source>The Journal of Neuroscience</source><volume>36</volume><fpage>3660</fpage><lpage>3675</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.4368-15.2016</pub-id><pub-id pub-id-type="pmid">27030753</pub-id></element-citation></ref><ref id="bib55"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kennedy</surname><given-names>A</given-names></name><name><surname>Wayne</surname><given-names>G</given-names></name><name><surname>Kaifosh</surname><given-names>P</given-names></name><name><surname>Alviña</surname><given-names>K</given-names></name><name><surname>Abbott</surname><given-names>LF</given-names></name><name><surname>Sawtell</surname><given-names>NB</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>A temporal basis for predicting the sensory consequences of motor commands in an electric fish</article-title><source>Nature Neuroscience</source><volume>17</volume><fpage>416</fpage><lpage>422</lpage><pub-id pub-id-type="doi">10.1038/nn.3650</pub-id><pub-id pub-id-type="pmid">24531306</pub-id></element-citation></ref><ref id="bib56"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kraus</surname><given-names>BJ</given-names></name><name><surname>Robinson</surname><given-names>RJ</given-names></name><name><surname>White</surname><given-names>JA</given-names></name><name><surname>Eichenbaum</surname><given-names>H</given-names></name><name><surname>Hasselmo</surname><given-names>ME</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>Hippocampal “time cells”: time versus path integration</article-title><source>Neuron</source><volume>78</volume><fpage>1090</fpage><lpage>1101</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2013.04.015</pub-id><pub-id pub-id-type="pmid">23707613</pub-id></element-citation></ref><ref id="bib57"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kraus</surname><given-names>BJ</given-names></name><name><surname>Brandon</surname><given-names>MP</given-names></name><name><surname>Robinson</surname><given-names>RJ</given-names></name><name><surname>Connerney</surname><given-names>MA</given-names></name><name><surname>Hasselmo</surname><given-names>ME</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>Grid cells integrate elapsed time and distance run</article-title><source>Neuron</source><volume>88</volume><fpage>578</fpage><lpage>589</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2015.09.031</pub-id></element-citation></ref><ref id="bib58"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Lee</surname><given-names>MD</given-names></name></person-group><year iso-8601-date="2011">2011</year><article-title>How cognitive modeling can benefit from hierarchical Bayesian models</article-title><source>Journal of Mathematical Psychology</source><volume>55</volume><fpage>1</fpage><lpage>7</lpage><pub-id pub-id-type="doi">10.1016/j.jmp.2010.08.013</pub-id></element-citation></ref><ref id="bib59"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Lejeune</surname><given-names>H</given-names></name><name><surname>Wearden</surname><given-names>JH</given-names></name></person-group><year iso-8601-date="2006">2006</year><article-title>Scalar properties in animal timing: conformity and violations</article-title><source>Quarterly Journal of Experimental Psychology</source><volume>59</volume><fpage>1875</fpage><lpage>1908</lpage><pub-id pub-id-type="doi">10.1080/17470210600784649</pub-id><pub-id pub-id-type="pmid">16987779</pub-id></element-citation></ref><ref id="bib60"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Lindeberg</surname><given-names>T</given-names></name><name><surname>Fagerström</surname><given-names>D</given-names></name></person-group><year iso-8601-date="1996">1996</year><article-title>Scale-space with casual time direction</article-title><source>Space Scale Theory</source><volume>1</volume><fpage>229</fpage><lpage>240</lpage></element-citation></ref><ref id="bib61"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Lindeberg</surname><given-names>T</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Time-causal and time-recursive spatio-temporal receptive fields</article-title><source>Journal of Mathematical Imaging and Vision</source><volume>55</volume><fpage>50</fpage><lpage>88</lpage><pub-id pub-id-type="doi">10.1007/s10851-015-0613-9</pub-id></element-citation></ref><ref id="bib62"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Liu</surname><given-names>Y</given-names></name><name><surname>Tiganj</surname><given-names>Z</given-names></name><name><surname>Hasselmo</surname><given-names>ME</given-names></name><name><surname>Howard</surname><given-names>MW</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>A neural microcircuit model for a scalable scale-invariant representation of time</article-title><source>Hippocampus</source><volume>29</volume><fpage>260</fpage><lpage>274</lpage><pub-id pub-id-type="doi">10.1002/hipo.22994</pub-id><pub-id pub-id-type="pmid">30421473</pub-id></element-citation></ref><ref id="bib63"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Liu</surname><given-names>Y</given-names></name><name><surname>Levy</surname><given-names>S</given-names></name><name><surname>Mau</surname><given-names>W</given-names></name><name><surname>Geva</surname><given-names>N</given-names></name><name><surname>Rubin</surname><given-names>A</given-names></name><name><surname>Ziv</surname><given-names>Y</given-names></name><name><surname>Hasselmo</surname><given-names>M</given-names></name><name><surname>Howard</surname><given-names>M</given-names></name></person-group><year iso-8601-date="2022">2022</year><article-title>Consistent population activity on the scale of minutes in the mouse hippocampus</article-title><source>Hippocampus</source><volume>32</volume><fpage>359</fpage><lpage>372</lpage><pub-id pub-id-type="doi">10.1002/hipo.23409</pub-id><pub-id pub-id-type="pmid">35225408</pub-id></element-citation></ref><ref id="bib64"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Logan</surname><given-names>GD</given-names></name></person-group><year iso-8601-date="1995">1995</year><article-title>The weibull distribution, the power law, and the instance theory of automaticity</article-title><source>Psychological Review</source><volume>102</volume><fpage>751</fpage><lpage>756</lpage><pub-id pub-id-type="doi">10.1037/0033-295X.102.4.751</pub-id></element-citation></ref><ref id="bib65"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>MacDonald</surname><given-names>CJ</given-names></name><name><surname>Lepage</surname><given-names>KQ</given-names></name><name><surname>Eden</surname><given-names>UT</given-names></name><name><surname>Eichenbaum</surname><given-names>H</given-names></name></person-group><year iso-8601-date="2011">2011</year><article-title>Hippocampal “ time cells ” bridge the gap in memory for discontiguous events</article-title><source>Neuron</source><volume>71</volume><fpage>737</fpage><lpage>749</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2011.07.012</pub-id><pub-id pub-id-type="pmid">21867888</pub-id></element-citation></ref><ref id="bib66"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Machens</surname><given-names>CK</given-names></name><name><surname>Romo</surname><given-names>R</given-names></name><name><surname>Brody</surname><given-names>CD</given-names></name></person-group><year iso-8601-date="2010">2010</year><article-title>Functional, but not anatomical, separation of “what” and “when” in prefrontal cortex</article-title><source>The Journal of Neuroscience</source><volume>30</volume><fpage>350</fpage><lpage>360</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.3276-09.2010</pub-id><pub-id pub-id-type="pmid">20053916</pub-id></element-citation></ref><ref id="bib67"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Mau</surname><given-names>W</given-names></name><name><surname>Sullivan</surname><given-names>DW</given-names></name><name><surname>Kinsky</surname><given-names>NR</given-names></name><name><surname>Hasselmo</surname><given-names>ME</given-names></name><name><surname>Howard</surname><given-names>MW</given-names></name><name><surname>Eichenbaum</surname><given-names>H</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>The same hippocampal CA1 population simultaneously codes temporal information over multiple timescales</article-title><source>Current Biology</source><volume>28</volume><fpage>1499</fpage><lpage>1508</lpage><pub-id pub-id-type="doi">10.1016/j.cub.2018.03.051</pub-id><pub-id pub-id-type="pmid">29706516</pub-id></element-citation></ref><ref id="bib68"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Mau</surname><given-names>W</given-names></name><name><surname>Hasselmo</surname><given-names>ME</given-names></name><name><surname>Cai</surname><given-names>DJ</given-names></name></person-group><year iso-8601-date="2020">2020</year><article-title>The brain in motion: how ensemble fluidity drives memory-updating and flexibility</article-title><source>eLife</source><volume>9</volume><elocation-id>e63550</elocation-id><pub-id pub-id-type="doi">10.7554/eLife.63550</pub-id><pub-id pub-id-type="pmid">33372892</pub-id></element-citation></ref><ref id="bib69"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Mello</surname><given-names>GBM</given-names></name><name><surname>Soares</surname><given-names>S</given-names></name><name><surname>Paton</surname><given-names>JJ</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>A scalable population code for time in the striatum</article-title><source>Current Biology</source><volume>25</volume><fpage>1113</fpage><lpage>1122</lpage><pub-id pub-id-type="doi">10.1016/j.cub.2015.02.036</pub-id><pub-id pub-id-type="pmid">25913405</pub-id></element-citation></ref><ref id="bib70"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Merchant</surname><given-names>H</given-names></name><name><surname>Averbeck</surname><given-names>BB</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>The computational and neural basis of rhythmic 1160 timing in medial premotor cortex</article-title><source>Journal of Neuroscience</source><volume>37</volume><fpage>4552</fpage><lpage>4564</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.0367-17.2017</pub-id></element-citation></ref><ref id="bib71"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Moore</surname><given-names>BC</given-names></name></person-group><year iso-8601-date="2012">2012</year><source>An Introduction to the Psychology of Hearing</source><publisher-name>Brill</publisher-name></element-citation></ref><ref id="bib72"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Nieder</surname><given-names>A</given-names></name><name><surname>Miller</surname><given-names>EK</given-names></name></person-group><year iso-8601-date="2003">2003</year><article-title>Coding of cognitive magnitude: compressed scaling of numerical information in the primate prefrontal cortex</article-title><source>Neuron</source><volume>37</volume><fpage>149</fpage><lpage>157</lpage><pub-id pub-id-type="doi">10.1016/s0896-6273(02)01144-3</pub-id><pub-id pub-id-type="pmid">12526780</pub-id></element-citation></ref><ref id="bib73"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Nieder</surname><given-names>A</given-names></name><name><surname>Dehaene</surname><given-names>S</given-names></name></person-group><year iso-8601-date="2009">2009</year><article-title>Representation of number in the brain</article-title><source>Annual Review of Neuroscience</source><volume>32</volume><fpage>185</fpage><lpage>208</lpage><pub-id pub-id-type="doi">10.1146/annurev.neuro.051508.135550</pub-id><pub-id pub-id-type="pmid">19400715</pub-id></element-citation></ref><ref id="bib74"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Nielson</surname><given-names>DM</given-names></name><name><surname>Smith</surname><given-names>TA</given-names></name><name><surname>Sreekumar</surname><given-names>V</given-names></name><name><surname>Dennis</surname><given-names>S</given-names></name><name><surname>Sederberg</surname><given-names>PB</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>Human hippocampus represents space and time during retrieval of real-world memories</article-title><source>PNAS</source><volume>112</volume><fpage>11078</fpage><lpage>11083</lpage><pub-id pub-id-type="doi">10.1073/pnas.1507104112</pub-id><pub-id pub-id-type="pmid">26283350</pub-id></element-citation></ref><ref id="bib75"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Parker</surname><given-names>NF</given-names></name><name><surname>Baidya</surname><given-names>A</given-names></name><name><surname>Cox</surname><given-names>J</given-names></name><name><surname>Haetzel</surname><given-names>LM</given-names></name><name><surname>Zhukovskaya</surname><given-names>A</given-names></name><name><surname>Murugan</surname><given-names>M</given-names></name><name><surname>Engelhard</surname><given-names>B</given-names></name><name><surname>Goldman</surname><given-names>MS</given-names></name><name><surname>Witten</surname><given-names>IB</given-names></name></person-group><year iso-8601-date="2022">2022</year><article-title>Choice-selective sequences dominate in cortical relative to thalamic inputs to NAC to support reinforcement learning</article-title><source>Cell Reports</source><volume>39</volume><elocation-id>110756</elocation-id><pub-id pub-id-type="doi">10.1016/j.celrep.2022.110756</pub-id><pub-id pub-id-type="pmid">35584665</pub-id></element-citation></ref><ref id="bib76"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Pastalkova</surname><given-names>E</given-names></name><name><surname>Itskov</surname><given-names>V</given-names></name><name><surname>Amarasingham</surname><given-names>A</given-names></name><name><surname>Buzsáki</surname><given-names>G</given-names></name></person-group><year iso-8601-date="2008">2008</year><article-title>Internally generated cell assembly sequences in the rat hippocampus</article-title><source>Science</source><volume>321</volume><fpage>1322</fpage><lpage>1327</lpage><pub-id pub-id-type="doi">10.1126/science.1159775</pub-id><pub-id pub-id-type="pmid">18772431</pub-id></element-citation></ref><ref id="bib77"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Peer</surname><given-names>M</given-names></name><name><surname>Salomon</surname><given-names>R</given-names></name><name><surname>Goldberg</surname><given-names>I</given-names></name><name><surname>Blanke</surname><given-names>O</given-names></name><name><surname>Arzy</surname><given-names>S</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>Brain system for mental orientation in space, time, and person</article-title><source>PNAS</source><volume>112</volume><fpage>11072</fpage><lpage>11077</lpage><pub-id pub-id-type="doi">10.1073/pnas.1504242112</pub-id><pub-id pub-id-type="pmid">26283353</pub-id></element-citation></ref><ref id="bib78"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Rahman</surname><given-names>M</given-names></name><name><surname>Willmore</surname><given-names>BDB</given-names></name><name><surname>King</surname><given-names>AJ</given-names></name><name><surname>Harper</surname><given-names>NS</given-names></name></person-group><year iso-8601-date="2020">2020</year><article-title>Simple transformations capture auditory input to cortex</article-title><source>PNAS</source><volume>117</volume><fpage>28442</fpage><lpage>28451</lpage><pub-id pub-id-type="doi">10.1073/pnas.1922033117</pub-id><pub-id pub-id-type="pmid">33097665</pub-id></element-citation></ref><ref id="bib79"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Rakitin</surname><given-names>BC</given-names></name><name><surname>Gibbon</surname><given-names>J</given-names></name><name><surname>Penney</surname><given-names>TB</given-names></name><name><surname>Malapani</surname><given-names>C</given-names></name><name><surname>Hinton</surname><given-names>SC</given-names></name><name><surname>Meck</surname><given-names>WH</given-names></name></person-group><year iso-8601-date="1998">1998</year><article-title>Scalar expectancy theory and peak-interval timing in humans</article-title><source>Journal of Experimental Psychology. Animal Behavior Processes</source><volume>24</volume><fpage>15</fpage><lpage>33</lpage><pub-id pub-id-type="doi">10.1037//0097-7403.24.1.15</pub-id><pub-id pub-id-type="pmid">9438963</pub-id></element-citation></ref><ref id="bib80"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Raymond</surname><given-names>JL</given-names></name><name><surname>Medina</surname><given-names>JF</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>Computational principles of supervised learning in the cerebellum</article-title><source>Annual Review of Neuroscience</source><volume>41</volume><fpage>233</fpage><lpage>253</lpage><pub-id pub-id-type="doi">10.1146/annurev-neuro-080317-061948</pub-id><pub-id pub-id-type="pmid">29986160</pub-id></element-citation></ref><ref id="bib81"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Robinson</surname><given-names>NTM</given-names></name><name><surname>Priestley</surname><given-names>JB</given-names></name><name><surname>Rueckemann</surname><given-names>JW</given-names></name><name><surname>Garcia</surname><given-names>AD</given-names></name><name><surname>Smeglin</surname><given-names>VA</given-names></name><name><surname>Marino</surname><given-names>FA</given-names></name><name><surname>Eichenbaum</surname><given-names>H</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>Medial entorhinal cortex selectively supports temporal coding by hippocampal neurons</article-title><source>Neuron</source><volume>94</volume><fpage>677</fpage><lpage>688</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2017.04.003</pub-id><pub-id pub-id-type="pmid">28434800</pub-id></element-citation></ref><ref id="bib82"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Rubin</surname><given-names>A</given-names></name><name><surname>Geva</surname><given-names>N</given-names></name><name><surname>Sheintuch</surname><given-names>L</given-names></name><name><surname>Ziv</surname><given-names>Y</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>Hippocampal ensemble dynamics timestamp events in long-term memory</article-title><source>eLife</source><volume>4</volume><elocation-id>e12247</elocation-id><pub-id pub-id-type="doi">10.7554/eLife.12247</pub-id><pub-id pub-id-type="pmid">26682652</pub-id></element-citation></ref><ref id="bib83"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Salz</surname><given-names>DM</given-names></name><name><surname>Tiganj</surname><given-names>Z</given-names></name><name><surname>Khasnabish</surname><given-names>S</given-names></name><name><surname>Kohley</surname><given-names>A</given-names></name><name><surname>Sheehan</surname><given-names>D</given-names></name><name><surname>Howard</surname><given-names>MW</given-names></name><name><surname>Eichenbaum</surname><given-names>H</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Time cells in hippocampal area CA3</article-title><source>The Journal of Neuroscience</source><volume>36</volume><fpage>7476</fpage><lpage>7484</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.0087-16.2016</pub-id><pub-id pub-id-type="pmid">27413157</pub-id></element-citation></ref><ref id="bib84"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Schwartz</surname><given-names>EL</given-names></name></person-group><year iso-8601-date="1980">1980</year><article-title>Computational anatomy and functional architecture of striate cortex: a spatial mapping approach to perceptual coding</article-title><source>Vision Research</source><volume>20</volume><fpage>645</fpage><lpage>669</lpage><pub-id pub-id-type="doi">10.1016/0042-6989(80)90090-5</pub-id><pub-id pub-id-type="pmid">7445436</pub-id></element-citation></ref><ref id="bib85"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Sederberg</surname><given-names>PB</given-names></name><name><surname>Howard</surname><given-names>MW</given-names></name><name><surname>Kahana</surname><given-names>MJ</given-names></name></person-group><year iso-8601-date="2008">2008</year><article-title>A context-based theory of recency and contiguity in free recall</article-title><source>Psychological Review</source><volume>115</volume><fpage>893</fpage><lpage>912</lpage><pub-id pub-id-type="doi">10.1037/a0013396</pub-id><pub-id pub-id-type="pmid">18954208</pub-id></element-citation></ref><ref id="bib86"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Shankar</surname><given-names>KH</given-names></name><name><surname>Howard</surname><given-names>MW</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>Optimally fuzzy temporal memory</article-title><source>Journal of Machine Learning Research</source><volume>14</volume><fpage>3753</fpage><lpage>3780</lpage></element-citation></ref><ref id="bib87"><element-citation publication-type="preprint"><person-group person-group-type="author"><name><surname>Sheehan</surname><given-names>DJ</given-names></name><name><surname>Charczynski</surname><given-names>S</given-names></name><name><surname>Fordyce</surname><given-names>BA</given-names></name><name><surname>Hasselmo</surname><given-names>ME</given-names></name><name><surname>Howard</surname><given-names>MW</given-names></name></person-group><year iso-8601-date="2021">2021</year><article-title>“A Compressed Representation of Spatial Distance in the Rodent Hippocampus</article-title><source>bioRxiv</source><pub-id pub-id-type="doi">10.1101/2021.02.15.431306</pub-id></element-citation></ref><ref id="bib88"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Shikano</surname><given-names>Y</given-names></name><name><surname>Ikegaya</surname><given-names>Y</given-names></name><name><surname>Sasaki</surname><given-names>T</given-names></name></person-group><year iso-8601-date="2021">2021</year><article-title>Minute-encoding neurons in hippocampal-striatal circuits</article-title><source>Current Biology</source><volume>31</volume><fpage>1438</fpage><lpage>1449</lpage><pub-id pub-id-type="doi">10.1016/j.cub.2021.01.032</pub-id><pub-id pub-id-type="pmid">33545048</pub-id></element-citation></ref><ref id="bib89"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Spalla</surname><given-names>D</given-names></name><name><surname>Cornacchia</surname><given-names>IM</given-names></name><name><surname>Treves</surname><given-names>A</given-names></name></person-group><year iso-8601-date="2021">2021</year><article-title>Continuous attractors for dynamic memories</article-title><source>eLife</source><volume>10</volume><elocation-id>e69499</elocation-id><pub-id pub-id-type="doi">10.7554/eLife.69499</pub-id><pub-id pub-id-type="pmid">34520345</pub-id></element-citation></ref><ref id="bib90"><element-citation publication-type="software"><person-group person-group-type="author"><collab>Stan development team</collab></person-group><year iso-8601-date="2021">2021</year><data-title>RStan: the R interface to stan</data-title><version designator="2.17.3">2.17.3</version><source>R Package</source><ext-link ext-link-type="uri" xlink:href="http://mc-stan.org/8">http://mc-stan.org/8</ext-link></element-citation></ref><ref id="bib91"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Stensola</surname><given-names>H</given-names></name><name><surname>Stensola</surname><given-names>T</given-names></name><name><surname>Solstad</surname><given-names>T</given-names></name><name><surname>Frøland</surname><given-names>K</given-names></name><name><surname>Moser</surname><given-names>MB</given-names></name><name><surname>Moser</surname><given-names>EI</given-names></name></person-group><year iso-8601-date="2012">2012</year><article-title>The entorhinal grid MAP is discretized</article-title><source>Nature</source><volume>492</volume><fpage>72</fpage><lpage>78</lpage><pub-id pub-id-type="doi">10.1038/nature11649</pub-id><pub-id pub-id-type="pmid">23222610</pub-id></element-citation></ref><ref id="bib92"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Taxidis</surname><given-names>J</given-names></name><name><surname>Pnevmatikakis</surname><given-names>EA</given-names></name><name><surname>Dorian</surname><given-names>CC</given-names></name><name><surname>Mylavarapu</surname><given-names>AL</given-names></name><name><surname>Arora</surname><given-names>JS</given-names></name><name><surname>Samadian</surname><given-names>KD</given-names></name><name><surname>Hoffberg</surname><given-names>EA</given-names></name><name><surname>Golshani</surname><given-names>P</given-names></name></person-group><year iso-8601-date="2020">2020</year><article-title>Differential emergence and stability of sensory and temporal representations in context-specific hippocampal sequences</article-title><source>Neuron</source><volume>108</volume><fpage>984</fpage><lpage>998</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2020.08.028</pub-id><pub-id pub-id-type="pmid">32949502</pub-id></element-citation></ref><ref id="bib93"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Tiganj</surname><given-names>Z</given-names></name><name><surname>Hasselmo</surname><given-names>ME</given-names></name><name><surname>Howard</surname><given-names>MW</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>A simple biophysically plausible model for long time constants in single neurons</article-title><source>Hippocampus</source><volume>25</volume><fpage>27</fpage><lpage>37</lpage><pub-id pub-id-type="doi">10.1002/hipo.22347</pub-id><pub-id pub-id-type="pmid">25113022</pub-id></element-citation></ref><ref id="bib94"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Tiganj</surname><given-names>Z</given-names></name><name><surname>Kim</surname><given-names>J</given-names></name><name><surname>Jung</surname><given-names>MW</given-names></name><name><surname>Howard</surname><given-names>MW</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>Sequential firing codes for time in rodent mpfc</article-title><source>Cerebral Cortex</source><volume>27</volume><fpage>5663</fpage><lpage>5671</lpage><pub-id pub-id-type="doi">10.1093/cercor/bhw336</pub-id></element-citation></ref><ref id="bib95"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Tiganj</surname><given-names>Z</given-names></name><name><surname>Cromer</surname><given-names>JA</given-names></name><name><surname>Roy</surname><given-names>JE</given-names></name><name><surname>Miller</surname><given-names>EK</given-names></name><name><surname>Howard</surname><given-names>MW</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>Compressed timeline of recent experience in monkey lpfc</article-title><source>Journal of Cognitive Neuroscience</source><volume>30</volume><fpage>935</fpage><lpage>950</lpage><pub-id pub-id-type="doi">10.1162/jocn_a_01273</pub-id></element-citation></ref><ref id="bib96"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Tsao</surname><given-names>A</given-names></name><name><surname>Sugar</surname><given-names>J</given-names></name><name><surname>Lu</surname><given-names>L</given-names></name><name><surname>Wang</surname><given-names>C</given-names></name><name><surname>Knierim</surname><given-names>JJ</given-names></name><name><surname>Moser</surname><given-names>MB</given-names></name><name><surname>Moser</surname><given-names>EI</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>Integrating time from experience in the lateral entorhinal cortex</article-title><source>Nature</source><volume>561</volume><fpage>57</fpage><lpage>62</lpage><pub-id pub-id-type="doi">10.1038/s41586-018-0459-6</pub-id><pub-id pub-id-type="pmid">30158699</pub-id></element-citation></ref><ref id="bib97"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Tulving</surname><given-names>E</given-names></name><name><surname>Madigan</surname><given-names>SA</given-names></name></person-group><year iso-8601-date="1970">1970</year><article-title>Memory and verbal learning</article-title><source>Annual Review of Psychology</source><volume>21</volume><fpage>437</fpage><lpage>484</lpage><pub-id pub-id-type="doi">10.1146/annurev.ps.21.020170.002253</pub-id></element-citation></ref><ref id="bib98"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Uitvlugt</surname><given-names>MG</given-names></name><name><surname>Healey</surname><given-names>MK</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>Temporal proximity links unrelated news events in memory</article-title><source>Psychological Science</source><volume>30</volume><fpage>92</fpage><lpage>104</lpage><pub-id pub-id-type="doi">10.1177/0956797618808474</pub-id><pub-id pub-id-type="pmid">30513038</pub-id></element-citation></ref><ref id="bib99"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Unsworth</surname><given-names>N</given-names></name></person-group><year iso-8601-date="2008">2008</year><article-title>Exploring the retrieval dynamics of delayed and final free recall: further evidence for temporal-contextual search☆</article-title><source>Journal of Memory and Language</source><volume>59</volume><fpage>223</fpage><lpage>236</lpage><pub-id pub-id-type="doi">10.1016/j.jml.2008.04.002</pub-id></element-citation></ref><ref id="bib100"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Van Essen</surname><given-names>DC</given-names></name><name><surname>Newsome</surname><given-names>WT</given-names></name><name><surname>Maunsell</surname><given-names>JH</given-names></name></person-group><year iso-8601-date="1984">1984</year><article-title>The visual field representation in striate cortex of the macaque monkey: asymmetries, anisotropies, and individual variability</article-title><source>Vision Research</source><volume>24</volume><fpage>429</fpage><lpage>448</lpage><pub-id pub-id-type="doi">10.1016/0042-6989(84)90041-5</pub-id><pub-id pub-id-type="pmid">6740964</pub-id></element-citation></ref><ref id="bib101"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Watanabe</surname><given-names>S</given-names></name><name><surname>Opper</surname><given-names>M</given-names></name></person-group><year iso-8601-date="2010">2010</year><article-title>Asymptotic equivalence of bayes cross validation and widely applicable information criterion in singular learning theory</article-title><source>Journal of Machine Learning Research</source><volume>11</volume><fpage>3571</fpage><lpage>3594</lpage></element-citation></ref><ref id="bib102"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Wei</surname><given-names>XX</given-names></name></person-group><year iso-8601-date="2012">2012</year><chapter-title>Bayesian inference with efficient neural population codes</chapter-title><person-group person-group-type="editor"><name><surname>Wei</surname><given-names>XX</given-names></name></person-group><source>In: Artificial Neural Networks and Machine Learning–ICANN</source><publisher-name>Springer</publisher-name><fpage>523</fpage><lpage>530</lpage><pub-id pub-id-type="doi">10.1007/978-3-642-33269-2</pub-id></element-citation></ref><ref id="bib103"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wei</surname><given-names>X-X</given-names></name><name><surname>Prentice</surname><given-names>J</given-names></name><name><surname>Balasubramanian</surname><given-names>V</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>A principle of economy predicts the functional architecture of grid cells</article-title><source>eLife</source><volume>4</volume><elocation-id>e08362</elocation-id><pub-id pub-id-type="doi">10.7554/eLife.08362</pub-id><pub-id pub-id-type="pmid">26335200</pub-id></element-citation></ref><ref id="bib104"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wei</surname><given-names>X-X</given-names></name><name><surname>Stocker</surname><given-names>AA</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>A Bayesian observer model constrained by efficient coding can explain “ anti-bayesian ” percepts</article-title><source>Nature Neuroscience</source><volume>18</volume><fpage>1509</fpage><lpage>1517</lpage><pub-id pub-id-type="doi">10.1038/nn.4105</pub-id><pub-id pub-id-type="pmid">26343249</pub-id></element-citation></ref><ref id="bib105"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wei</surname><given-names>X-X</given-names></name><name><surname>Stocker</surname><given-names>AA</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Mutual information, Fisher information, and efficient coding</article-title><source>Neural Computation</source><volume>28</volume><fpage>305</fpage><lpage>326</lpage><pub-id pub-id-type="doi">10.1162/NECO_a_00804</pub-id><pub-id pub-id-type="pmid">26654209</pub-id></element-citation></ref><ref id="bib106"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Zhong</surname><given-names>W</given-names></name><name><surname>Lu</surname><given-names>Z</given-names></name><name><surname>Schwab</surname><given-names>DJ</given-names></name><name><surname>Murugan</surname><given-names>A</given-names></name></person-group><year iso-8601-date="2020">2020</year><article-title>Nonequilibrium statistical mechanics of continuous attractors</article-title><source>Neural Computation</source><volume>32</volume><fpage>1033</fpage><lpage>1068</lpage><pub-id pub-id-type="doi">10.1162/neco_a_01280</pub-id><pub-id pub-id-type="pmid">32343645</pub-id></element-citation></ref><ref id="bib107"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ziv</surname><given-names>Y</given-names></name><name><surname>Burns</surname><given-names>LD</given-names></name><name><surname>Cocker</surname><given-names>ED</given-names></name><name><surname>Hamel</surname><given-names>EO</given-names></name><name><surname>Ghosh</surname><given-names>KK</given-names></name><name><surname>Kitch</surname><given-names>LJ</given-names></name><name><surname>El Gamal</surname><given-names>A</given-names></name><name><surname>Schnitzer</surname><given-names>MJ</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>Long-Term dynamics of CA1 hippocampal place codes</article-title><source>Nature Neuroscience</source><volume>16</volume><fpage>264</fpage><lpage>266</lpage><pub-id pub-id-type="doi">10.1038/nn.3329</pub-id><pub-id pub-id-type="pmid">23396101</pub-id></element-citation></ref></ref-list><app-group><app id="appendix-1"><title>Appendix 1</title><sec sec-type="appendix" id="s8"><title>Supplementary Materials</title><sec sec-type="appendix" id="s8-1"><title>S1: Rats engaged stereotypical behavior with little variability after 2 s</title><p>In the Main Model, we found the temporal variability carried out by time cells linearly increases with delay. Given the well-documented interaction between timing and sensorimotor control (for review, see <xref ref-type="bibr" rid="bib4">Balasubramaniam et al., 2021</xref>) , it is crucial to rule out the possibility that the widened time field for later time cells was simply due to some behavioral pattern that happens to be more variable towards the end of the delay. When we examined the average spatial location of each rat across the delay (<xref ref-type="fig" rid="fig3s1">Figure 3—figure supplement 1a</xref>), we saw little evidence suggesting the locations varied systematically across the delay, probably due to the absence of task demand for timing. In addition, we measured the variability of the stereotyped behavior engaged by animals below and found the variability was highest at the beginning, contrasting with the increased variability in the temporal information carried out by time cells.</p><p>We quantified two complementary measures of repetitive or stereotyped running behavior during the delay: spatial dispersion and head wobble distance. Spatial dispersion is the standard deviation of the Euclidean distance of a cluster of points in 2d space around a centroid. We measured the spatial dispersion of the rat’s head at each second during the delay from the whole delay centroid to determine whether the rat behaved or positioned himself in a unique or stereotyped manner during any moment during the delay, which would amount to a dancing or counting behavior. Indeed, only in the first second during the delay did the mean dispersion exceed that across the remainder of the delay (<xref ref-type="fig" rid="fig3s1">Figure 3—figure supplement 1b</xref> top, under Friedman test, post-hoc ranksum second 1 was found different from all other seconds at p&lt;.05). We then performed a complementary analysis on stereotyped running behaviors during the treadmill run. Some rats galloped on the treadmill, taking long strides and oscillating their bodies forward and backward, while others ran at a trot on the treadmill keeping their head more stationary, and yet others did a combination of the two. To quantify these two behaviors, we measured the total head wobble distance each rat covered at each second during the delay using unsmoothed position data. Indeed, rat 1 trotted during all delays, rats 2, and 4 performed a combination of the two, and rat 3 galloped almost entirely. Upon quantifying these behaviors during each second of the run, however, we found there is no significant difference in wobble across delay time except for in the first second (<xref ref-type="fig" rid="fig3s1">Figure 3—figure supplement 1b</xref> bottom, under Friedman test, post-hoc ranksum second 1 was found different from seconds 3–8 at p&lt;.05).</p></sec><sec sec-type="appendix" id="s8-2-1"><title>S2: Maximum Likelihood Fits</title><p>In this section, we report the results from the maximum likelihood fits for time cell selection (<xref ref-type="bibr" rid="bib95">Tiganj et al., 2018</xref>; <xref ref-type="bibr" rid="bib17">Cruzado et al., 2020</xref>) and compare them with fits from the Main Model. In <xref ref-type="fig" rid="fig5s1">Figure 5—figure supplement 1a</xref>, we compare the maximum likelihood estimated time field peaks as a function of the Main Model estimation. As shown in the figure, aside from a few outliers cluster toward the bottom, most of the cells were closely alongside the diagonal line, which suggests that the results from both methods are well aligned (r(129)=.92, p&lt;.001 under Pearson correlation test). Similarly, when plotted on the log scale, the sorted time field peaks from Maximum likelihood fits tiled the delay evenly on the log scale (<xref ref-type="fig" rid="fig5s1">Figure 5—figure supplement 1c</xref>).</p><p>In <xref ref-type="fig" rid="fig5s1">Figure 5—figure supplement 1b</xref>, we plotted the maximum likelihood estimated time field width as a function of the estimation from the Main Model. Contrary to the time field peaks plot (<xref ref-type="fig" rid="fig5s1">Figure 5—figure supplement 1a</xref>), most of the cells here were above the diagonal line, which means the time field widths estimated under the maximum likelihood method tend to be larger than the ones from the Main Model. A paired t-test comparing the two confirmed that the difference was significant: t(131)=9.38, p&lt;.001, with 95 percent confidence interval of [.34, .52]. The Bayesian paired t-test came to the same conclusion with . This result is expected as the maximum likelihood estimation does not separate the time field width from the across-trial variability. Additionally, in the Results section we reported a significant linear relationship between the estimated time field widths and time field peaks from the Main Model. However, when the same linear regression analysis was applied to the maximum likelihood estimated time field widths as a function of their time field peaks, both linear (.64±.06 p&lt;.001) and quadratic term (-.06±.01, p&lt;.001 ) were significant (<inline-formula><mml:math id="inf207"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msup><mml:mi>R</mml:mi><mml:mn>2</mml:mn></mml:msup></mml:mrow></mml:mstyle></mml:math></inline-formula>=.674, <xref ref-type="fig" rid="fig5s1">Figure 5—figure supplement 1d</xref>). Again it is likely because the maximum likelihood method included the trial-variability in the time field width estimation.</p></sec></sec></app></app-group></back><sub-article article-type="editor-report" id="sa0"><front-stub><article-id pub-id-type="doi">10.7554/eLife.75353.sa0</article-id><title-group><article-title>Editor's evaluation</article-title></title-group><contrib-group><contrib contrib-type="author"><name><surname>Merchant</surname><given-names>Hugo</given-names></name><role specific-use="editor">Reviewing Editor</role><aff><institution-wrap><institution-id institution-id-type="ror">https://ror.org/01tmp8f25</institution-id><institution>National Autonomous University of Mexico</institution></institution-wrap><country>Mexico</country></aff></contrib></contrib-group><related-object id="sa0ro1" object-id-type="id" object-id="10.1101/2021.10.25.465750" link-type="continued-by" xlink:href="https://sciety.org/articles/activity/10.1101/2021.10.25.465750"/></front-stub><body><p>This is a rigorous evaluation of whether the compression of time cells in the hippocampus follows the Weber-Fechner Law, using a hierarchical Bayesian model that simultaneously accounts for the firing pattern at the trial, cell, and population levels. The two key results are that the time field width increases linearly with delay, even after taking into account the across trial response variability, and that the time cell population is distributed evenly on a logarithmic time scale.</p></body></sub-article><sub-article article-type="decision-letter" id="sa1"><front-stub><article-id pub-id-type="doi">10.7554/eLife.75353.sa1</article-id><title-group><article-title>Decision letter</article-title></title-group><contrib-group content-type="section"><contrib contrib-type="editor"><name><surname>Merchant</surname><given-names>Hugo</given-names></name><role>Reviewing Editor</role><aff><institution-wrap><institution-id institution-id-type="ror">https://ror.org/01tmp8f25</institution-id><institution>National Autonomous University of Mexico</institution></institution-wrap><country>Mexico</country></aff></contrib></contrib-group></front-stub><body><boxed-text id="sa2-box1"><p>Our editorial process produces two outputs: (i) <ext-link ext-link-type="uri" xlink:href="https://sciety.org/articles/activity/10.1101/2021.10.25.465750">public reviews</ext-link> designed to be posted alongside <ext-link ext-link-type="uri" xlink:href="https://www.biorxiv.org/content/10.1101/2021.10.25.465750v1">the preprint</ext-link> for the benefit of readers; (ii) feedback on the manuscript for the authors, including requests for revisions, shown below. We also include an acceptance summary that explains what the editors found interesting or important about the work.</p></boxed-text><p><bold>Decision letter after peer review:</bold></p><p>Thank you for submitting your article &quot;Internally Generated Time in the Rodent Hippocampus is Logarithmically Compressed&quot; for consideration by <italic>eLife</italic>. Your article has been reviewed by 3 peer reviewers, one of whom is a member of our Board of Reviewing Editors, and the evaluation has been overseen by Joshua Gold as the Senior Editor. The reviewers have opted to remain anonymous.</p><p>The reviewers have discussed their reviews with one another, and the Reviewing Editor has drafted this to help you prepare a revised submission.</p><p>Recommendations for the authors:</p><p>The authors state that &quot;The goal of the analyses in this paper is to rigorously test the hypothesis that time cells form a logarithmically-compressed representation of past time.&quot; While the authors made great strides and this rigorous analysis, unfortunately, no other hypothesis was really considered. It is common in timing tasks that subjects learn some rote behavioral sequence that happens to match the target interval. Therefore, correlates observed anywhere in the brain cannot uniquely be attributes to time, or that behavioral sequence. Moreover, it is not clear in the present report if the animals have actually learned the target duration and therefore have some representation of that duration. To pose the question in an actionable and concrete manner: what differs about the trials when time fields occur earlier than expected versus later? I strongly recommend that the authors classify each trial as an early firing versus late firing trial (or some other demarcation) and revisit the videos to assess whether animal behavior can explain any variability. My guess is that the behavior is more variable late into the treadmill running, and this could likely explain the variability of the firing fields.</p><p>Another major comment pertain to the nature of the statistical modeling. It is not totally clear what data is being used for the goodness-of-fit analysis, though it appears to be single trial firing rates. Are these smoothed? What is the bin size? These issues are important because a main focus of the manuscript is on trial-to-trial variability. The authors use their model to describe a conditional intensity function (equation 2), which is then tested directly with the spiking output. Typically, spikes are thought of as being probabilistically generated from an underlying intensity function and often Poisson link functions are used to translate between the world of stochastic events (spikes) and the world of the underlying, deterministic intensity functions (e.g. equation 2). How can the authors justify a direct estimation of the intensity function?</p><p>The authors test which coefficient best describes the power-law distribution of M in the hierarchical bayes model. No other distribution is considered, and then much of the paper is dedicated to a description of the implication of logarithmically compressed time field allocation. First, other distributions should be considered and compared (i.e. with AIC), and second, credible interval analysis should be used to motivate that the coefficient of the power law is not different from one (e.g. Keysers et al., 2020, https://dx.doi.org/10.1038%2Fs41593-020-0660-4).</p><p>Other models, and empirical observations, suggest skewed receptive fields that significantly differ from Gaussian – do the findings hold if the assumption of a Gaussian tuning is relaxed and other functions are considered (e.g. α function)?</p><p>The pairwise analysis for consistent shifts in the time field location is interesting though the effect seems modest. Two points, (1) since the authors are working within a Bayesian framework, confidence intervals and effect sizes can be given through an analysis of credible intervals (Keysers et al., 2020, https://dx.doi.org/10.1038%2Fs41593-020-0660-4), (2) Is it possible to leverage more than just a pairwise analysis since the authors conducted high density recordings. Several recent methods exist for such an analysis, such as Williams et al., 2020 https://doi.org/10.1016/j.neuron.2019.10.020, or Kawabata et al., 2020 https://doi.org/10.1152/jn.00200.2020. Similarly, a hidden markov model approach could be fruitful as well (Chen et al., 2012, https://dx.doi.org/10.1007%2Fs10827-012-0384-x).</p><p>In Figure 4c, the curved dashed line shows a sparsification of the putative temporal representation of long intervals. One issue is that, as the authors quantify, the time fields at the later delays are broader and show more variability. How does the compression differ with more relaxed inclusion criteria? This issue is important as the inclusion criteria (“a Gaussian-shaped time field, with a mean and a standard deviation, and a constant term”) select specifically for fields that show high trial-to-trial reliability (e.g. early fields). The authors must report how many total neurons per rat were recorded and what percentage was included/excluded.</p><p>Figure 5b – To my eye, it looks like there are a number of cells with low width throughout the interval hovering around the bottom of this graph and, at later peak times, across a gap from 0.25-0.5. I’m curious what the authors think about these cells. Are they merely outliers, or are there possibly subsets of cells that retain strong temporal fidelity even far into the interval? Is it possible to use unsupervised learning techniques like k-means clustering to find differences between these cells and the other ones which seem to follow the logarithmic law? Are there differences in the overall firing rates or any other properties? If there end up being different classes of cells, that would not invalidate the overall conclusion, but could be a novel discovery, And it could make the relationship with the other set of cells even stronger.</p><p>If I were of the opinion that a number of cells simply fired due to the onset of the event (as they would to an event boundary) and had different onset times as a result of the beginning of the interval due to the sudden change (Bright et al., 2020) but did not believe that variability increased thereafter, how would the authors address this? I realize this is tricky because it is not clear at what time point one may not consider a response to be directly related to some onset, but if the relationship in Figure 4b held when only investigating cells with peak firing times between two seconds and the end of the interval, that would address the concern.</p><p>In the regression analysis at the bottom of page 7, is the argument that the linear significance is relevant here? If so, the authors should make this more explicit, especially because the quadratic aspect looks so prominent.</p><p>“Section S1 of the supplementary materials provides an elementary explanation of why logarithmic compression leads to these properties.” It would be preferable to include a brief description of this logic in the main paper.</p><p>In discussing the Nielson Study, it seems highly relevant that the relationship between representational similarity and both space and time was logarithmic. It would also be nice to include the neurophysiological timing literature on the scalar property of timing. Recordings in the primate medial premotor areas during rhythmic timing have shown neural sequences linked with temporal processing (Crowe et al., 2014i; Merchant et al., 2015 i) and neural population codes that could underpin the scalar property of timing (Averbeck and Merchant, 2017; Gamez et al., 2019).</p></body></sub-article><sub-article article-type="reply" id="sa2"><front-stub><article-id pub-id-type="doi">10.7554/eLife.75353.sa2</article-id><title-group><article-title>Author response</article-title></title-group></front-stub><body><disp-quote content-type="editor-comment"><p>Recommendations for the authors:</p><p>The authors state that “The goal of the analyses in this paper is to rigorously test the hypothesis that time cells form a logarithmically-compressed representation of past time.” While the authors made great strides and this rigorous analysis, unfortunately, no other hypothesis was really considered. It is common in timing tasks that subjects learn some rote behavioral sequence that happens to match the target interval. Therefore, correlates observed anywhere in the brain cannot uniquely be attributes to time, or that behavioral sequence. Moreover, it is not clear in the present report if the animals have actually learned the target duration and therefore have some representation of that duration. To pose the question in an actionable and concrete manner: what differs about the trials when time fields occur earlier than expected versus later? I strongly recommend that the authors classify each trial as an early firing versus late firing trial (or some other demarcation) and revisit the videos to assess whether animal behavior can explain any variability. My guess is that the behavior is more variable late into the treadmill running, and this could likely explain the variability of the firing fields.</p></disp-quote><p>The revision thoroughly explored the impact arkovioral variability on time cells, both within the delay and across trials and as predicted by the reviewers we observed a strong behavioral predictor of variability in time field location across trials. The original submission and the revision take the moment the animal crosses a laser beam on the treadmill as time zero for each trial. In the revision, we asked whether some variability in time field location across trials could be accounted for by instead using the moment the animal touches the treadmill (Figure 4b in the revision). For 3 out of the 4 animals, this variable accounted for trial-to-trial variability in some time cells, especially early in the delay. The section “Variability in the timing of events early in the trial accounts for some neural trial variability” (pp. 8-9) describes these results in more detail.</p><p>However, the revision also makes it clear that there is no evidence that behavioral variability across trials accounts for the evidence for logarithmically compressed time cells within a trial. The revision includes data about behavior as a function of time (e.g., Figure 3–supplement figure 1a). Animals moved from the front to the back of the treadmill over the first two seconds of the delay (accompanied by a lot of behavioral variability across trials) and were relatively stationary thereafter (see Supplementary S1). If behavioral variability could account for within trial effects (equations 3,4) we would expect time cells that peak before 2 s and after 2 s to have very different properties from the population as a whole. This was not the case (p.14, section “Time cells early and late in the delay show similar compression”). We thank the reviewers for raising the issue of behavioral variability. The additional analyses have led to a cleaner presentation (the revision de-emphasizes the importance of within-trial correlations) and a stronger empirical case that the logarithmic compression within-trial is not an artifact of behavior.</p><p>As a secondary question, it is true that in this study there is no behavioral demand for the animals to learn the delay interval and there is no evidence that the animals learned the delay. However, “hippocampal time cells” appear to be found in many experiments that do not explicitly require animals to learn a delay interval (e.g., Cruzado, et al., 2020; Taxidis, et al., 2020; Goh, 2021; Schonhaut, et al., 2022). If anything, the lack of an explicit timing demand would seem to reduce the incentive for animals to adopt a complex behavioral strategy as a proxy for time, thus reducing concerns that time cell phenomena observed in these experiments is merely a confound of a behavioral strategy.</p><disp-quote content-type="editor-comment"><p>Another major comment pertain to the nature of the statistical arkovng. It is not totally clear what data is being used for the goodness-of-fit analysis, though it appears to be single trial firing rates. Are these smoothed? What is the bin size? These issues are important because a main focus of the manuscript is on trial-to-trial variability. The authors use their model to describe a conditional intensity function (equation 2), which is then tested directly with the spiking output. Typically, spikes are thought of as being probabilistically generated from an underlying intensity function and often Poisson link functions are used to translate between the world of stochastic events (spikes) and the world of the underlying, deterministic intensity functions (e.g. equation 2). How can the authors justify a direct estimation of the intensity function?</p></disp-quote><p>The revision makes the method used in this paper more clear (section “Estimating time fields with hierarchical Bayesian method”, starting with line 130, p. 6). Briefly, the method does not estimate the intensity function, at the cost of being blind to overall firing rates. Instead the model assumes that a proportion of the observed spikes on each trial is independently sampled from the time field, specified by parameters for location and width. The goal of this method is to characterize the parameters of the time field at the trial level so those parameters can be fed to the next levels of the hierarchical Bayesian models. This is appropriate in that our hypothesis is specified in terms of the parameters of time fields (equations 3, 4). Although this method is limited in its utility, it is sufficient to ask this theoretically important question.</p><disp-quote content-type="editor-comment"><p>The authors test which coefficient best describes the power-law distribution of M in the hierarchical bayes model. No other distribution is considered, and then much of the paper is dedicated to a description of the implication of logarithmically compressed time field allocation. First, other distributions should be considered and compared (i.e. with AIC), and second, credible interval analysis should be used to motivate that the coefficient of the power law is not different from one (e.g. Keysers et al., 2020, https://dx.doi.org/10.1038%2Fs41593-020-0660-4).</p></disp-quote><p>In response to the first point, the revision considers several alternatives to the power law distribution of time field peaks (Table 1). The revision refers to the model from the initial submission as the “Main Model” and evaluates several alternative models. Two of these models, the Exponential Compression Model and the Weibull Compression Model, evaluate alternatives to the assumptions that time field peaks are distributed according to a power law. The exponential distribution and Weibull distribution are standard alternative distributions to test against power-law distribution (Clauset et al., 2009). The Main Model, which assumes a power-law distribution, outperforms both of these alternatives (Table 1). The observed spiking data is astronomically more likely if the values were generated from a power law distribution than either exponential or Weibull distributions. Detailed descriptions of the two alternative models can be found in section “Exponential Compression Model and Weibull Compression Model” (p. 28). Notably, even in the models where the model assumed that the distribution of time field peaks was not power law (equation 4), the parameters generated by these models still supported the other prediction of a logarithmically-compressed timeline (equation 3). As discussed in the revision (p. 12, “Alternative models …”) the width of receptive fields increased linearly with peak time when assuming both exponential and Weibull distributed peaks. We thank the reviewers for raising this issue; the inclusion of the alternative models allows the revision to make a much stronger empirical case for logarithmically-compressed time than did the original submission.</p><p>In response to the second point, the revision includes a 95% credible interval [.73, 1.11] for the exponent of the power law. Furthermore, about 54% of the posterior density is between the values of.9 and 1.1. Thank you for pointing out the Keysers et al., paper. That method is not applicable here as there is no prior in the analyses for the shape or the value of the exponent and the revision reports the posterior distribution in full. There is no null hypothesis in this context to generate the Bayes factor; performing additional statistical tests in Keysers et al., (2020) directly on the posterior distribution would violate the “independent sampling” assumption.</p><disp-quote content-type="editor-comment"><p>Other models, and empirical observations, suggest skewed receptive fields that significantly differ from Gaussian – do the findings hold if the assumption of a Gaussian tuning is relaxed and other functions are considered (e.g. α function)?</p></disp-quote><p>The revision makes clear that the answer to this question is “yes”. In the revision the Log-normal Time Field Model assumes skewed log-normal receptive fields (p. 27, line 878). As shown in Table 1, the Log-normal Time Field Model gives a somewhat inferior fit to the Main Model (which assumes Gaussian fields). The parameters of the Log-normal Time Field Model show similar evidence for both of the quantitative predictions of a logarithmic timeline (equations 3,4, see p. 12, line 331) as the Main Model.</p><disp-quote content-type="editor-comment"><p>The pairwise analysis for consistent shifts in the time field location is interesting though the effect seems modest. Two points, (1) since the authors are working within a Bayesian framework, confidence intervals and effect sizes can be given through an analysis of credible intervals (Keysers et al., 2020, https://dx.doi.org/10.1038%2Fs41593-020-0660-4), (2) Is it possible to leverage more than just a pairwise analysis since the authors conducted high density recordings. Several recent methods exist for such an analysis, such as Williams et al., 2020 https://doi.org/10.1016/j.neuron.2019.10.020, or Kawabata et al., 2020 https://doi.org/10.1152/jn.00200.2020. Similarly, a hidden arkov model approach could be fruitful as well (Chen et al., 2012, https://dx.doi.org/10.1007%2Fs10827-012-0384-x).</p></disp-quote><p>The revision does not include any data on pairwise correlations among time cells. After carefully considering the results of additional analyses showing that time field peaks can vary across trials in tandem with behavioral variability (in response to point 1) we decided that there is no reason to conclude that pairwise correlations are evidence for an “internal timeline”. Insofar as time cells are correlated with behavioral variables it is not surprising they are correlated with one another. It would be meaningful to say the timeline is “internal” if one had measured behavior more extensively (e.g., with deeplabcut) and still found correlations between time cell peaks after controlling for behavior. However, this question is not central to the question of whether the timeline is logarithmic within trial.</p><disp-quote content-type="editor-comment"><p>In Figure 4c, the curved dashed line shows a sparsification of the putative temporal representation of long intervals. One issue is that, as the authors quantify, the time fields at the later delays are broader and show more variability. How does the compression differ with more relaxed inclusion criteria? This issue is important as the inclusion criteria (&quot;a Gaussian-shaped time field, with a mean and a standard deviation, and a constant term&quot;) select specifically for fields that show high trial-to-trial reliability (e.g. early fields). The authors must report how many total neurons per rat were recorded and what percentage was included/excluded.</p></disp-quote><p>The revision reports the total number of units recorded and included/excluded per rat on page 6. Overall, the fraction of time cells, 159/625, was in the same ballpark as previous time cell papers (e.g., Salz et al., 2016). In addition, only a small portion of units, 6/159, was impacted by relaxing the criterion for including time cells (p. 25, line 784). Notably, none of those cells had a peak after 4 s. Thus the revision makes a much stronger case that the conclusions about the number density of units were not an artifact of a specific criterion for including time cells in the hierarchical Bayesian analyses. We thank the reviewers for suggesting these changes, which have resulted in a much stronger empirical case.</p><disp-quote content-type="editor-comment"><p>Figure 5b – To my eye, it looks like there are a number of cells with low width throughout the interval hovering around the bottom of this graph and, at later peak times, across a gap from 0.25-0.5. I'm curious what the authors think about these cells. Are they merely outliers, or are there possibly subsets of cells that retain strong temporal fidelity even far into the interval? Is it possible to use unsupervised learning techniques like k-means clustering to find differences between these cells and the other ones which seem to follow the logarithmic law? Are there differences in the overall firing rates or any other properties? If there end up being different classes of cells, that would not invalidate the overall conclusion, but could be a novel discovery, And it could make the relationship with the other set of cells even stronger.</p></disp-quote><p>The revision makes clear that the apparent cluster of cells with narrow width and broad time field peak in the previous submission was largely due to units with low spike count within the time field—several of the units have less than two spikes attributable to the time field per trial. The revision uses shading in the scatterplot to indicate the number of spikes under the time field (see Figure 5b). Note that the number of spikes per trial attributable to the time field is distinct from the number of spikes per trial, which was a criterion for inclusion in the hierarchical analyses.</p><disp-quote content-type="editor-comment"><p>If I were of the opinion that a number of cells simply fired due to the onset of the event (as they would to an event boundary) and had different onset times as a result of the beginning of the interval due to the sudden change (Bright et al., 2020) but did not believe that variability increased thereafter, how would the authors address this? I realize this is tricky because it is not clear at what time point one may not consider a response to be directly related to some onset, but if the relationship in Figure 4b held when only investigating cells with peak firing times between two seconds and the end of the interval, that would address the concern.</p></disp-quote><p>The revision explicitly shows that the relationship in figure 3b holds “when only investigating cells with peak firing times between two seconds and the end of the interval”. Fortuitously, the choice suggested by the reviewers also does a good job of separating periods with high behavioral variability and low behavioral variability (Figure 3–supplement figure 1, response to point 1 above). The section of the revision entitled “Time cells early and late in the delay show similar compression” (p. 14, line 355) provides details. Briefly, there is an increase in time field width as a function of peak time (the relationship in Figure 5b) for both groups. Dividing the population into two groups we lose statistical power and can’t make statements with the same precision (e.g., it’s not possible to argue that the peaks are distributed with power law with exponent near 1, but simply to argue that the peaks are not uniformly distributed). More broadly, there is no evidence that the groups differ from one another despite a dramatic difference in behavioral variability between those time periods. Thank you to the reviewers for raising this issue, which has enabled the revision to rule out an alternative interpretation of the results.</p><disp-quote content-type="editor-comment"><p>In the regression analysis at the bottom of page 7, is the argument that the linear significance is relevant here? If so, the authors should make this more explicit, especially because the quadratic aspect looks so prominent.</p></disp-quote><p>The revision is careful not to make any claim that the linear term is of special importance for across-trial variability. The text (section “Across-trial variability changes over the delay interval”, p. 9) and the caption of Figure 4 make clear that the regression describing across trial variability as a function of peak time produced reliable intercept, linear and quadratic terms. Note that the question of across-trial variability is orthogonal to the questions about within-trial temporal receptive fields which are central to the hypothesis of the paper. By contrast, the same Bayesian regression analysis for the within-trial fields preferred the linear-term-only model over alternative models including one with both the linear term and the quadratic term (detailed analysis on p. 11, line 274).</p><disp-quote content-type="editor-comment"><p>&quot;Section S1 of the supplementary materials provides an elementary explanation of why logarithmic compression leads to these properties.&quot; It would be preferable to include a brief description of this logic in the main paper.</p></disp-quote><p>The revision integrates the elementary explanation of how logarithmic compression leads to two particular quantitative relationships (equations 3,4) into the introduction of the revision (“Quantifying logarithmic compression”, starting on p. 2, line 44). This was an excellent suggestion as it focuses the reader on two well-specified quantitative questions that frame the empirical results.</p><disp-quote content-type="editor-comment"><p>In discussing the Nielson Study, it seems highly relevant that the relationship between representational similarity and both space and time was logarithmic. It would also be nice to include the neurophysiological timing literature on the scalar property of timing. Recordings in the primate medial premotor areas during rhythmic timing have shown neural sequences linked with temporal processing (Crowe et al., 2014i; Merchant et al., 2015 i) and neural population codes that could underpin the scalar property of timing (Averbeck and Merchant, 2017; Gamez et al., 2019).</p></disp-quote><p>The discussion of the revision makes both of these points. The discussion points out that the Nielsen et al., (2015) paper observed logarithmic compression in both time and space (p. 21, line 641). The discussion also discusses the relationship between the results observed here and evidence for scale-invariant representations of time and sequence (“Implications of logarithmically-compressed time…”, p.18). Briefly, logarithmically-compressed time cells are scale-covariant; rescaling time in an experiment would result in translation of the activity across the set of neurons. Figure 6, which is new to the revision, clarifies this idea. Scalar timing models—more generally scale-invariant properties—can be computed from a scale-covariant representation. The confluence of these kind of results across many different brain regions suggests a design principle for the brain’s estimates of time.</p></body></sub-article></article>