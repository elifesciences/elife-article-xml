<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD with MathML3 v1.2 20190208//EN"  "JATS-archivearticle1-mathml3.dtd"><article article-type="research-article" dtd-version="1.2" xmlns:ali="http://www.niso.org/schemas/ali/1.0/" xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink"><front><journal-meta><journal-id journal-id-type="nlm-ta">elife</journal-id><journal-id journal-id-type="publisher-id">eLife</journal-id><journal-title-group><journal-title>eLife</journal-title></journal-title-group><issn pub-type="epub" publication-format="electronic">2050-084X</issn><publisher><publisher-name>eLife Sciences Publications, Ltd</publisher-name></publisher></journal-meta><article-meta><article-id pub-id-type="publisher-id">71801</article-id><article-id pub-id-type="doi">10.7554/eLife.71801</article-id><article-categories><subj-group subj-group-type="display-channel"><subject>Research Article</subject></subj-group><subj-group subj-group-type="heading"><subject>Neuroscience</subject></subj-group></article-categories><title-group><article-title>Gated recurrence enables simple and accurate sequence prediction in stochastic, changing, and structured environments</article-title></title-group><contrib-group><contrib contrib-type="author" id="author-245431"><name><surname>Foucault</surname><given-names>Cédric</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">https://orcid.org/0000-0002-7247-6927</contrib-id><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="aff" rid="aff2">2</xref><xref ref-type="other" rid="fund1"/><xref ref-type="fn" rid="con1"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" corresp="yes" id="author-53268"><name><surname>Meyniel</surname><given-names>Florent</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">https://orcid.org/0000-0002-6992-678X</contrib-id><email>florent.meyniel@cea.fr</email><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="other" rid="fund2"/><xref ref-type="other" rid="fund3"/><xref ref-type="fn" rid="con2"/><xref ref-type="fn" rid="conf1"/></contrib><aff id="aff1"><label>1</label><institution>Cognitive Neuroimaging Unit, INSERM, CEA, Université Paris-Saclay, NeuroSpin center</institution><addr-line><named-content content-type="city">Gif sur Yvette</named-content></addr-line><country>France</country></aff><aff id="aff2"><label>2</label><institution>Sorbonne Université, Collège Doctoral</institution><addr-line><named-content content-type="city">Paris</named-content></addr-line><country>France</country></aff></contrib-group><contrib-group content-type="section"><contrib contrib-type="editor"><name><surname>Ostojic</surname><given-names>Srdjan</given-names></name><role>Reviewing Editor</role><aff><institution>Ecole Normale Superieure Paris</institution><country>France</country></aff></contrib><contrib contrib-type="senior_editor"><name><surname>Frank</surname><given-names>Michael J</given-names></name><role>Senior Editor</role><aff><institution>Brown University</institution><country>United States</country></aff></contrib></contrib-group><pub-date date-type="publication" publication-format="electronic"><day>02</day><month>12</month><year>2021</year></pub-date><pub-date pub-type="collection"><year>2021</year></pub-date><volume>10</volume><elocation-id>e71801</elocation-id><history><date date-type="received" iso-8601-date="2021-06-30"><day>30</day><month>06</month><year>2021</year></date><date date-type="accepted" iso-8601-date="2021-12-01"><day>01</day><month>12</month><year>2021</year></date></history><pub-history><event><event-desc>This manuscript was published as a preprint at .</event-desc><date date-type="preprint" iso-8601-date="2021-05-03"><day>03</day><month>05</month><year>2021</year></date><self-uri content-type="preprint" xlink:href="https://doi.org/10.1101/2021.05.03.442240"/></event></pub-history><permissions><copyright-statement>© 2021, Foucault and Meyniel</copyright-statement><copyright-year>2021</copyright-year><copyright-holder>Foucault and Meyniel</copyright-holder><ali:free_to_read/><license xlink:href="http://creativecommons.org/licenses/by/4.0/"><ali:license_ref>http://creativecommons.org/licenses/by/4.0/</ali:license_ref><license-p>This article is distributed under the terms of the <ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/licenses/by/4.0/">Creative Commons Attribution License</ext-link>, which permits unrestricted use and redistribution provided that the original author and source are credited.</license-p></license></permissions><self-uri content-type="pdf" xlink:href="elife-71801-v4.pdf"/><self-uri content-type="figures-pdf" xlink:href="elife-71801-figures-v4.pdf"/><abstract><p>From decision making to perception to language, predicting what is coming next is crucial. It is also challenging in stochastic, changing, and structured environments; yet the brain makes accurate predictions in many situations. What computational architecture could enable this feat? Bayesian inference makes optimal predictions but is prohibitively difficult to compute. Here, we show that a specific recurrent neural network architecture enables simple and accurate solutions in several environments. This architecture relies on three mechanisms: gating, lateral connections, and recurrent weight training. Like the optimal solution and the human brain, such networks develop internal representations of their changing environment (including estimates of the environment’s latent variables and the precision of these estimates), leverage multiple levels of latent structure, and adapt their effective learning rate to changes without changing their connection weights. Being ubiquitous in the brain, gated recurrence could therefore serve as a generic building block to predict in real-life environments.</p></abstract><kwd-group kwd-group-type="author-keywords"><kwd>artificial neural network</kwd><kwd>Bayesian inference</kwd><kwd>learning</kwd><kwd>volatility</kwd><kwd>recurrence</kwd><kwd>gating</kwd><kwd>sequence</kwd><kwd>prediction</kwd></kwd-group><kwd-group kwd-group-type="research-organism"><title>Research organism</title><kwd>None</kwd></kwd-group><funding-group><award-group id="fund1"><funding-source><institution-wrap><institution>École normale supérieure Paris-Saclay</institution></institution-wrap></funding-source><award-id>PhD fellowship &quot;Contrat doctoral spécifique normalien&quot;</award-id><principal-award-recipient><name><surname>Foucault</surname><given-names>Cédric</given-names></name></principal-award-recipient></award-group><award-group id="fund2"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/501100001665</institution-id><institution>Agence Nationale de la Recherche</institution></institution-wrap></funding-source><award-id>18-CE37-0010-01 &quot;CONFI LEARN&quot;</award-id><principal-award-recipient><name><surname>Meyniel</surname><given-names>Florent</given-names></name></principal-award-recipient></award-group><award-group id="fund3"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/100010663</institution-id><institution>H2020 European Research Council</institution></institution-wrap></funding-source><award-id>ERC StG 947105 &quot;NEURAL PROB&quot;</award-id><principal-award-recipient><name><surname>Meyniel</surname><given-names>Florent</given-names></name></principal-award-recipient></award-group><funding-statement>The funders had no role in study design, data collection and interpretation, or the decision to submit the work for publication.</funding-statement></funding-group><custom-meta-group><custom-meta specific-use="meta-only"><meta-name>Author impact statement</meta-name><meta-value>Small gated recurrent neural networks can dynamically adapt to inferred changes in the environment, represent and use the precision of their estimate to weight their updates, and leverage the environment's latent hierarchical structure, like the Bayesian agent and the brain.</meta-value></custom-meta></custom-meta-group></article-meta></front><body><sec id="s1" sec-type="intro"><title>Introduction</title><p>Being able to correctly predict what is coming next is advantageous: it enables better decisions (<xref ref-type="bibr" rid="bib33">Dolan and Dayan, 2013</xref>; <xref ref-type="bibr" rid="bib137">Sutton and Barto, 1998</xref>), a more accurate perception of our world, and faster reactions (<xref ref-type="bibr" rid="bib29">de Lange et al., 2018</xref>; <xref ref-type="bibr" rid="bib30">Dehaene et al., 2015</xref>; <xref ref-type="bibr" rid="bib114">Saffran et al., 1996</xref>; <xref ref-type="bibr" rid="bib124">Sherman et al., 2020</xref>; <xref ref-type="bibr" rid="bib133">Summerfield and de Lange, 2014</xref>). In many situations, predictions are informed by a sequence of past observations. In that case, the prediction process formally corresponds to a statistical inference that uses past observations to estimate latent variables of the environment (e.g. the probability of a stimulus) that then serve to predict what is likely to be observed next. Specific features of real-life environments make this inference a challenge: they are often partly random, changing, and structured in different ways. Yet, in many situations, the brain is able to overcome these challenges and shows several aspects of the optimal solution (<xref ref-type="bibr" rid="bib30">Dehaene et al., 2015</xref>; <xref ref-type="bibr" rid="bib33">Dolan and Dayan, 2013</xref>; <xref ref-type="bibr" rid="bib49">Gallistel et al., 2014</xref>; <xref ref-type="bibr" rid="bib133">Summerfield and de Lange, 2014</xref>). Here, we aim to identify the computational mechanisms that could enable the brain to exhibit these aspects of optimality in these environments.</p><p>We start by unpacking two specific challenges which arise in real-life environments. First, the joint presence of randomness and changes (i.e. the non-stationarity of the stochastic process generating the observations) poses a well-known tension between stability and flexibility (<xref ref-type="bibr" rid="bib8">Behrens et al., 2007</xref>; <xref ref-type="bibr" rid="bib129">Soltani and Izquierdo, 2019</xref>; <xref ref-type="bibr" rid="bib136">Sutton, 1992</xref>). Randomness in observations requires integrating information over time to derive a stable estimate. However, when a change in the estimated variable is suspected, it is better to limit the integration of past observations to update the estimate more quickly. The prediction should thus be adaptive, that is, dynamically adjusted to promote flexibility in the face of changes and stability otherwise. Past studies have shown that the brain does so in many contexts: perception (<xref ref-type="bibr" rid="bib40">Fairhall et al., 2001</xref>; <xref ref-type="bibr" rid="bib149">Wark et al., 2009</xref>), homeostatic regulation (<xref ref-type="bibr" rid="bib105">Pezzulo et al., 2015</xref>; <xref ref-type="bibr" rid="bib132">Sterling, 2004</xref>), sensorimotor control (<xref ref-type="bibr" rid="bib11">Berniker and Kording, 2008</xref>; <xref ref-type="bibr" rid="bib150">Wolpert et al., 1995</xref>), and reinforcement learning (<xref ref-type="bibr" rid="bib8">Behrens et al., 2007</xref>; <xref ref-type="bibr" rid="bib62">Iglesias et al., 2013</xref>; <xref ref-type="bibr" rid="bib129">Soltani and Izquierdo, 2019</xref>; <xref ref-type="bibr" rid="bib137">Sutton and Barto, 1998</xref>).</p><p>Second, the structure of our environment can involve complex relationships. For instance, the sentence beginnings &quot;what science can do for you is...&quot; and &quot;what you can do for science is...&quot; call for different endings even though they contain the same words, illustrating that prediction takes into account the ordering of observations. Such structures appear not only in human language but also in animal communication (<xref ref-type="bibr" rid="bib30">Dehaene et al., 2015</xref>; <xref ref-type="bibr" rid="bib54">Hauser et al., 2001</xref>; <xref ref-type="bibr" rid="bib112">Robinson, 1979</xref>; <xref ref-type="bibr" rid="bib113">Rose et al., 2004</xref>), and all kinds of stimulus-stimulus and stimulus-action associations in the world (<xref ref-type="bibr" rid="bib114">Saffran et al., 1996</xref>; <xref ref-type="bibr" rid="bib121">Schapiro et al., 2013</xref>; <xref ref-type="bibr" rid="bib129">Soltani and Izquierdo, 2019</xref>; <xref ref-type="bibr" rid="bib137">Sutton and Barto, 1998</xref>). Such a structure is often latent (i.e. not directly observable) and it governs the relationship between observations (e.g. words forming a sentence, stimulus-action associations). These relationships must be leveraged by the prediction, making it more difficult to compute.</p><p>In sum, the randomness, changes, and latent structure of real-life environments pose two major challenges: that of adapting to changes and that of leveraging the latent structure. Two commonly used approaches offer different solutions to these challenges. The Bayesian approach allows to derive statistically optimal predictions for a given environment knowing its underlying generative model. This optimal solution is a useful benchmark and has some descriptive validity since, in some contexts, organisms behave close to optimally (<xref ref-type="bibr" rid="bib84">Ma and Jazayeri, 2014</xref>; <xref ref-type="bibr" rid="bib139">Tauber et al., 2017</xref>) or exhibit several qualitative aspects of the optimal solution (<xref ref-type="bibr" rid="bib8">Behrens et al., 2007</xref>; <xref ref-type="bibr" rid="bib56">Heilbron and Meyniel, 2019</xref>; <xref ref-type="bibr" rid="bib91">Meyniel et al., 2015</xref>). However, a specific Bayes-optimal solution only applies to a specific generative model (or class of models [<xref ref-type="bibr" rid="bib140">Tenenbaum et al., 2011</xref>]). This mathematical solution also does not in general lead to an algorithm of reasonable complexity (<xref ref-type="bibr" rid="bib24">Cooper, 1990</xref>; <xref ref-type="bibr" rid="bib28">Dagum and Luby, 1993</xref>). Bayesian inference therefore says little about the algorithms that the brain could use, and the biological basis of those computations remains mostly unknown with only a few proposals highly debated (<xref ref-type="bibr" rid="bib45">Fiser et al., 2010</xref>; <xref ref-type="bibr" rid="bib82">Ma et al., 2006</xref>; <xref ref-type="bibr" rid="bib115">Sahani and Dayan, 2003</xref>).</p><p>Opposite to the Bayes-optimal approach is the heuristics approach: solutions that are easy to compute and accurate in specific environments (<xref ref-type="bibr" rid="bib143">Todd and Gigerenzer, 2000</xref>). However, heuristics lack generality: their performance can be quite poor outside the environment that suits them. In addition, although simple, their biological implementation often remains unknown (besides the delta-rule [<xref ref-type="bibr" rid="bib39">Eshel et al., 2013</xref>; <xref ref-type="bibr" rid="bib110">Rescorla and Wagner, 1972</xref>; <xref ref-type="bibr" rid="bib122">Schultz et al., 1997</xref>]).</p><p>Those two approaches leave open the following questions: Is there a general, biologically feasible architecture that enables, in different environments, solutions that are simple, effective, and that reproduce the qualitative aspects of optimal prediction observed in organisms? If so, what are its essential mechanistic elements?</p><p>Our approach stands in contrast with the elegant closed-form but intractable mathematical solutions offered by Bayesian inference, and the simple but specialized algorithms offered by heuristics. Instead, we look for general mechanisms under the constraints of feasibility and simplicity. We used recurrent neural networks because they can offer a generic, biologically feasible architecture able to realize different prediction algorithms (see <xref ref-type="bibr" rid="bib76">LeCun et al., 2015</xref>; <xref ref-type="bibr" rid="bib118">Saxe et al., 2021</xref> and Discussion). We used small network sizes in order to produce simple (i.e. low-complexity, memory-bounded) solutions. We tested their generality using different environments. To determine the simplest architecture sufficient for effective solutions and derive mechanistic insights, we considered different architectures that varied in size and mechanisms. For each one, we instantiated several networks and trained them to approach their best possible prediction algorithm in a given environment. We treated the training procedure as a methodological step without claiming it to be biologically plausible. To provide interpretability, we inspected the networks’ internal model and representations, and tested specific optimal aspects of their behavior—previously reported in humans (<xref ref-type="bibr" rid="bib56">Heilbron and Meyniel, 2019</xref>; <xref ref-type="bibr" rid="bib91">Meyniel et al., 2015</xref>; <xref ref-type="bibr" rid="bib96">Nassar et al., 2010</xref>; <xref ref-type="bibr" rid="bib97">Nassar et al., 2012</xref>)—which demonstrate the ability to adapt to changes and leverage the latent structure of the environment.</p></sec><sec id="s2" sec-type="results"><title>Results</title><sec id="s2-1"><title>The framework: sequence prediction and network architectures</title><p>All our analyses confront simulated agents with the same general problem: sequence prediction. It consists in predicting, at each time step in a sequence where one time step represents one observation, the probability distribution over the value of the next observation given the previous observations (here we used binary observations coded as ‘0’ and ‘1’) (<xref ref-type="fig" rid="fig1">Figure 1a</xref>). The environment generates the sequence, and the agent’s goal is to make the most accurate predictions possible in this environment. Below, we introduce three environments. All of them are stochastic (observations are governed by latent probabilities) and changing (these latent probabilities change across time), and thus require dynamically adapting the stability-flexibility tradeoff. They also feature increasing levels of latent structure that must be leveraged, making the computation of predictions more complex.</p><fig-group><fig id="fig1" position="float"><label>Figure 1.</label><caption><title>Problem to solve and network architectures.</title><p>(<bold>a</bold>) Sequence prediction problem. At each time step t, the environment generates one binary observation x<sub>t</sub>. The agent receives it and returns a prediction p<sub>t</sub>: its estimate of the probability that the next observation will be one given the observations collected so far. The agent’s goal is to make the most accurate predictions possible. The agent can measure its accuracy by comparing its prediction p<sub>t</sub> with the actual value observed at the next time step x<sub>t+1</sub>, allowing it to learn from the observations without any external supervision. (<bold>b</bold>) Common three-layer template of the recurrent neural network architectures. Input connections transmit the observation to the recurrent units and output connections allow the prediction to be read from the recurrent units. (<bold>c</bold>) Three key mechanisms of recurrent neural network architectures. Gating allows for multiplicative interaction between activities. Lateral connections allow the activities of different recurrent units i and j to interact. Recurrent weight training allows the connection weights of recurrent units to be adjusted to the training environment. i’ may be equal to i. (<bold>d</bold>) The gated recurrent architecture includes all three mechanisms: gating, lateral connections, and recurrent weight training. Each alternative architecture includes all but one of the three mechanisms.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-71801-fig1-v4.tif"/></fig><fig id="fig1s1" position="float" specific-use="child-fig"><label>Figure 1—figure supplement 1.</label><caption><title>Graphical model of the generative process of each environment.</title><p>Nodes encode the variables and edges the conditional dependencies between variables. Each graph represents a factorization of the joint probability distribution of all variables in the generative process: this joint distribution is the product of the conditional probability distributions of each variable given its parents in the graph. For further details on the generative processes, see Materials and methods. In all environments, inferring the next observation from previous observations using such a graph is computationally difficult because it requires computing and marginalizing over the continuous probability distribution of the latent probabilities. This distribution is not easy to compute because it incorporates the likelihoods of the observations (for any latent probability value) and the change point probabilities from all previous time steps, and requires normalization. Notice also the increasingly complex conditional structures of the graphs from left to right. In the unigram environment, observations are conditionally independent given the latent probabilities, but in the bigram environments, they interact. In the bigram environment with coupled change points, the hierarchical structure implies that the two latent bigram probabilities are no longer conditionally independent of each other given their values at the previous time step, since they are connected by a common parent (the change point).</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-71801-fig1-figsupp1-v4.tif"/></fig></fig-group><p>How do agents learn to make predictions that fit a particular environment? In real life, agents often do not benefit from any external supervision and must rely only on the observations. To do so, they can take advantage of an intrinsic error signal that measures the discrepancy between their prediction and the actual value observed at the next time step. We adopted this learning paradigm (often called unsupervised, self-supervised, or predictive learning in machine learning [<xref ref-type="bibr" rid="bib38">Elman, 1991</xref>; <xref ref-type="bibr" rid="bib77">LeCun, 2016</xref>]) to train our agents in silico. We trained the agents by exposing them to sequences generated by a given environment and letting them adjust their parameters to improve their prediction (see Materials and methods).</p><p>During testing, we kept the parameters of the trained agents frozen, exposed them to new sequences, and performed targeted analyses to probe whether they exhibit specific capabilities and better understand how they solve the problem.</p><p>Our investigation focuses on a particular class of agent architectures known as recurrent neural networks. These are well suited for sequence prediction because recurrence allows to process inputs sequentially while carrying information over time in recurrent activity. The network architectures we used all followed the same three-layer template, consisting of one input unit whose activity codes for the current observation, one output unit whose activity codes for the prediction about the next observation, and a number of recurrent units that are fed by the input unit and project to the output unit (<xref ref-type="fig" rid="fig1">Figure 1b</xref>). All architectures had self-recurrent connections.</p><p>We identified three mechanisms of recurrent neural network architectures that endow a network with specific computational properties which have proven advantageous in our environments (<xref ref-type="fig" rid="fig1">Figure 1c</xref>). One mechanism is gating, which allows for multiplicative interactions between the activities of units. A second mechanism is lateral connectivity, which allows the activities of different recurrent units to interact with each other. A third mechanism is the training of recurrent connection weights, which allows the dynamics of recurrent activities to be adjusted to the training environment.</p><p>To get mechanistic insight, we compared an architecture that included all three mechanisms, to alternative architectures that were deprived of one of the three mechanisms but maintained the other two (<xref ref-type="fig" rid="fig1">Figure 1d</xref>; see Materials and methods for equations). Here, we call an architecture with all three mechanisms ‘gated recurrent’, and the particular architecture we used is known as GRU (<xref ref-type="bibr" rid="bib22">Cho et al., 2014</xref>; <xref ref-type="bibr" rid="bib23">Chung et al., 2014</xref>). When deprived of gating, multiplicative interactions between activities are removed, and the architecture reduces to that of a vanilla recurrent neural network also known as the Elman network (<xref ref-type="bibr" rid="bib37">Elman, 1990</xref>). When deprived of lateral connections, the recurrent units become independent of each other, thus each recurrent unit acts as a temporal filter on the input observations (with possibly time-varying filter weights thanks to gating). When deprived of recurrent weight training, the recurrent activity dynamics become independent of the environment and the only parameters that can be trained are those of the output unit; this architecture is thus one form of reservoir computing (<xref ref-type="bibr" rid="bib138">Tanaka et al., 2019</xref>). In the results below, unless otherwise stated, the networks all had 11 recurrent units (the smallest network size beyond which the gated recurrent network showed no substantial increase in performance in any of the environments), but the results across architectures are robust to this choice of network size (see the last section of the Results).</p></sec><sec id="s2-2"><title>Performance in the face of changes in latent probabilities</title><p>We designed a first environment to investigate the ability to handle changes in a latent probability (<xref ref-type="fig" rid="fig2">Figure 2a</xref>; see <xref ref-type="fig" rid="fig1s1">Figure 1—figure supplement 1</xref> for a graphical model). In this environment we used the simplest kind of latent probability: p(1), the probability of occurrence (or base rate) of the observation being 1 (note that p(0) = 1−p(1)), here called ‘unigram probability’. The unigram probability suddenly changed from one value to another at so-called ‘change points’, which could occur at any time, randomly with a given fixed probability.</p><fig id="fig2" position="float"><label>Figure 2.</label><caption><title>Gated recurrent networks perform quasi-optimally in the face of changes in latent probabilities.</title><p>(<bold>a</bold>) Sample sequence of observations (dots) and latent unigram probability (line) generated in the changing unigram environment. At each time step, a binary observation is randomly generated based on the latent unigram probability, and a change point can occur with a fixed probability, suddenly changing the unigram probability to a new value uniformly drawn in [0,1]. (<bold>b</bold>) Prediction performance in the changing unigram environment. For each type of agent, 20 trained agents (trained with different random seeds) were tested (dots: agents; bars: average). Their prediction performance was measured as the % of optimal log likelihood (0% being chance performance and 100 % optimal performance, see <xref ref-type="disp-formula" rid="equ1">Equation 1</xref> for the log likelihood) and averaged over observations and sequences. The gated recurrent network significantly outperformed every other type of agent (p &lt; 0.001, two-tailed two independent samples t-test with Welch’s correction for unequal variances).</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-71801-fig2-v4.tif"/></fig><p>This environment, here called ‘changing unigram environment’, corresponds for instance to a simple oddball task (<xref ref-type="bibr" rid="bib3">Aston-Jones et al., 1997</xref>; <xref ref-type="bibr" rid="bib67">Kaliukhovich and Vogels, 2014</xref>; <xref ref-type="bibr" rid="bib145">Ulanovsky et al., 2004</xref>), or the probabilistic delivery of a reward with abrupt changes in reward probabilities (<xref ref-type="bibr" rid="bib8">Behrens et al., 2007</xref>; <xref ref-type="bibr" rid="bib146">Vinckier et al., 2016</xref>). In such an environment, predicting accurately is difficult due to the stability-flexibility tradeoff induced by the stochastic nature of the observations (governed by the unigram probability) and the possibility of a change point at any moment.</p><p>To assess the networks’ prediction accuracy, we compared the networks with the optimal agent for this specific environment, that is, the optimal solution to the prediction problem determined using Bayesian inference. This optimal solution knows the environment’s underlying generative process and uses it to compute, via Bayes’ rule, the probability distribution over the possible values of the latent probability given the past observation sequence,<inline-formula><mml:math id="inf1"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>p</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msubsup><mml:mi>p</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>e</mml:mi><mml:mi>n</mml:mi><mml:mi>v</mml:mi></mml:mrow></mml:msubsup><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:msub><mml:mi>x</mml:mi><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:mo>.</mml:mo><mml:mo>.</mml:mo><mml:mo>.</mml:mo><mml:mo>,</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mstyle></mml:math></inline-formula> known as the posterior distribution. It then outputs as prediction the mean of this distribution. (For details see Materials and methods and <xref ref-type="bibr" rid="bib56">Heilbron and Meyniel, 2019</xref>).</p><p>We also compared the networks to two types of heuristics which perform very well in this environment: the classic 'delta-rule' heuristic (<xref ref-type="bibr" rid="bib110">Rescorla and Wagner, 1972</xref>; <xref ref-type="bibr" rid="bib137">Sutton and Barto, 1998</xref>) and the more accurate 'leaky' heuristic (<xref ref-type="bibr" rid="bib50">Gijsen et al., 2021</xref>; <xref ref-type="bibr" rid="bib56">Heilbron and Meyniel, 2019</xref>; <xref ref-type="bibr" rid="bib92">Meyniel et al., 2016</xref>; <xref ref-type="bibr" rid="bib155">Yu and Cohen, 2008</xref>) (see Materials and methods for details). To test the statistical reliability of our conclusions, we trained separately 20 agents of each type (each type of network and each type of heuristic).</p><p>We found that even with as few as 11 units, the gated recurrent networks performed quasi-optimally. Their prediction performance was 99 % of optimal (CI ±0.1%), 0 % corresponding to chance level (<xref ref-type="fig" rid="fig2">Figure 2b</xref>). Being only 1 % short of optimal, the gated recurrent networks outperformed the delta rule and leaky agents, which performed 10 times and 5 times further from optimal, respectively (<xref ref-type="fig" rid="fig2">Figure 2b</xref>).</p><p>For mechanistic insight, we tested the alternative architectures deprived of one mechanism. Without either gating, lateral connections, or recurrent weight training, the average performance was respectively 6 times, 4 times, and 12 times further from optimal (<xref ref-type="fig" rid="fig2">Figure 2b</xref>), that is, the level of a leaky agent or worse. The drops in performance remain similar when considering only the best network of each architecture instead of the average performance (<xref ref-type="fig" rid="fig2">Figure 2b</xref>, compare rightmost dots across rows).</p><p>These results show that small gated recurrent networks can achieve quasi-optimal predictions and that the removal of one of the mechanisms of the gated recurrent architecture results in a systematic drop in performance.</p></sec><sec id="s2-3"><title>Adaptation to changes through the adjustment of the effective learning rate</title><p>In a changing environment, the ability to adapt to changes is key. Networks exposed to more changing environments during training updated their predictions more overall during testing, similarly to the optimal agent (see <xref ref-type="fig" rid="fig3s1">Figure 3—figure supplement 1</xref>) and, to some extent, humans (<xref ref-type="bibr" rid="bib8">Behrens et al., 2007</xref>, Figure 2e; <xref ref-type="bibr" rid="bib44">Findling et al., 2021</xref>, Figure 4c). At a finer timescale, the moment-by-moment updating of the predictions also showed sensible dynamics around change points.</p><p><xref ref-type="fig" rid="fig3">Figure 3a</xref> illustrates a key difference in behavior between, on the one hand, the optimal agent and the gated recurrent network, and on the other hand, the heuristic agents: the dynamics of their update differ. This difference is particularly noticeable when recent observations suggest that a change point has just occurred: the optimal agent quickly updates the prediction by giving more weight to the new observations; the gated recurrent network behaves the same but not the heuristic agents. We formally tested this dynamic updating around change points by measuring the moment-by-moment effective learning rate, which normalizes the amount of update in the prediction by the prediction error (i.e. the difference between the previous prediction and the actual observation; see Materials and methods, <xref ref-type="disp-formula" rid="equ7">Equation 2</xref>).</p><fig-group><fig id="fig3" position="float"><label>Figure 3.</label><caption><title>Gated recurrent but not alternative networks adjust their moment-by-moment effective learning rate around changes like the optimal agent.</title><p>(<bold>a</bold>) Example prediction sequence illustrating the prediction updates of different types of agents. Within each type of agent, the agent (out of 20) yielding median performance in <xref ref-type="fig" rid="fig2">Figure 2b</xref> was selected for illustration purposes. Dots are observations, lines are predictions. (<bold>b</bold>) Moment-by-moment effective learning rate of each type of agent. 20 trained agents of each type were tested on 10,000 sequences whose change points were locked at the same time steps, for illustration purposes. The moment-by-moment effective learning rate was measured as the ratio of prediction update to prediction error (see Materials and methods, <xref ref-type="disp-formula" rid="equ7">Equation 2</xref>), and averaged over sequences. Lines and bands show the mean and the 95 % confidence interval of the mean.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-71801-fig3-v4.tif"/></fig><fig id="fig3s1" position="float" specific-use="child-fig"><label>Figure 3—figure supplement 1.</label><caption><title>Attunement of the effective learning rate to the change point probabilities.</title><p>(<bold>a</bold>) Average effective learning rate of the gated recurrent networks as a function of the change point probability used during testing (columns) and during training (rows). Each row corresponds to a different set of 20 networks trained in the changing unigram environment with the indicated change point probability. Each column corresponds to a different test set with the indicated change point probability, each of 1000 out-of-sample sequences. The networks’ effective learning rate was measured and averaged over time, sequences, and networks. (<bold>b</bold>) Average effective learning rate of the optimal agent as a function of the change point probability used during testing (columns) and the prior on the change point probability assumed by the model (rows). The optimal agent was tested on the same sets of sequences as the gated recurrent networks and its effective learning rate was averaged over time and sequences.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-71801-fig3-figsupp1-v4.tif"/></fig></fig-group><p>Gated recurrent networks turned out to adjust their moment-by-moment effective learning rate as the optimal agent did, showing the same characteristic peaks, at the same time and with almost the same amplitude (<xref ref-type="fig" rid="fig3">Figure 3b</xref>, top plot). By contrast, the effective learning rate of the delta-rule agents was (by construction) constant, and that of the leaky agents changed only marginally.</p><p>When one of the mechanisms of the gated recurrence was taken out, the networks’ ability to adjust their effective learning rate was greatly degraded (but not entirely removed) (<xref ref-type="fig" rid="fig3">Figure 3b</xref>, bottom plots). Without gating, without lateral connections, or without recurrent weight training, the amplitude was lower (showing both a lower peak value and a higher baseline value), and the peak occurred earlier.</p><p>This shows that gated recurrent networks can reproduce a key aspect of optimal behavior: the ability to adapt the update of their prediction to change points, which is lacking in heuristic agents and alternative networks.</p></sec><sec id="s2-4"><title>Internal representation of precision and dynamic interaction with the prediction</title><p>Beyond behavior, we sought to determine whether a network’s ability to adapt to changes relied on idiosyncratic computations or followed the more general principle of precision-weighting derived from probability theory. According to this principle, the precision of the current prediction (calculated in the optimal agent as the negative logarithm of the standard deviation of the posterior distribution over the latent probability, see <xref ref-type="disp-formula" rid="equ8">Equation 3</xref> in Materials and methods) should influence the weight of the current prediction relative to the next observation in the updating process: for a given prediction error, the lower the precision, the higher the subsequent effective learning rate. This precision-weighting principle results in an automatic adjustment of the effective learning rate in response to a change, because the precision of the prediction decreases when a change is suspected.</p><p>In line with this principle, human participants can estimate not only the prediction but also its precision as estimated by the optimal agent (<xref ref-type="bibr" rid="bib15">Boldt et al., 2019</xref>, Figure 2; <xref ref-type="bibr" rid="bib91">Meyniel et al., 2015</xref>, Figure 4B), and this precision indeed relates to the participants’ effective learning rate (<xref ref-type="bibr" rid="bib90">McGuire et al., 2014</xref>, Figure 2C and S1A; <xref ref-type="bibr" rid="bib96">Nassar et al., 2010</xref>, Figure 4C and 3B; <xref ref-type="bibr" rid="bib97">Nassar et al., 2012</xref>, Figure 5 and 7c, ).</p><p>We tested whether a network could represent this optimal precision too, by trying to linearly read it from the network’s recurrent activity (<xref ref-type="fig" rid="fig4">Figure 4a</xref>). Note that the networks were trained only to maximize prediction accuracy (not to estimate precision). Yet, in gated recurrent networks, we found that the read precision on left-out data was highly accurate (<xref ref-type="fig" rid="fig4">Figure 4a</xref>, left plot: the median Pearson correlation with the optimal precision is 0.82), and correlated with their subsequent effective learning rate as in the optimal agent (<xref ref-type="fig" rid="fig4">Figure 4a</xref>, right plot: the median correlation for gated recurrent networks is –0.79; for comparison, it is –0.88 for the optimal agent).</p><fig id="fig4" position="float"><label>Figure 4.</label><caption><title>Gated recurrent networks have an internal representation of the precision of their estimate that dynamically interacts with the prediction following the precision-weighting principle.</title><p>(<bold>a</bold>) Left to right: Schematic of the readout of precision from the recurrent activity of a network (obtained by fitting a multiple linear regression from the recurrent activity to the log precision of the optimal posterior distribution); Accuracy of the read precision (calculated as its Pearson correlation with the optimal precision); Pearson correlation between the read precision and the network’s subsequent effective learning rate (the optimal value was calculated from the optimal agent’s own precision and learning rate); Example sequence illustrating their anti-correlation in the gated recurrent network. In both dot plots, large and small dots show the median and individual values, respectively. (<bold>b</bold>) Dynamics of the optimal posterior (left) and the network activity (right) in three sequences (green, yellow, and pink). The displayed dynamics are responses to a streak of 1 s after different sequences of observations (with different generative probabilities as shown at the bottom). The optimal posterior distribution is plotted as a color map over time (dark blue and light green correspond to low and high probability densities, respectively) and as a line plot at two times: on the left, the time t<sub>start</sub> just before the streak of 1s, and on the right, a time t<sub>A</sub>/t<sub>B</sub>/t<sub>C</sub> when the prediction (i.e. mean) is approximately equal in all three cases; note that the precision differs. The network activity was projected onto the two-dimensional subspace spanned by the prediction and precision vectors (for the visualization, the precision axis was orthogonalized with respect to the prediction axis). In the gated recurrent network, the arrow Δp shows the update to the prediction performed in the next three time steps starting at the time t<sub>A</sub>/t<sub>B</sub>/t<sub>C</sub> defined from the optimal posterior. Like the optimal posterior and unlike the network without gating, the gated recurrent network represents different levels of precision at an equal prediction, and the lower the precision, the higher the subsequent update to the prediction—a principle called precision-weighting. In all example plots (<bold>a–b</bold>), the displayed network is the one of the 20 that yielded the median read precision accuracy.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-71801-fig4-v4.tif"/></fig><p>To better understand how precision information is represented and how it interacts with the prediction dynamically in the network activity, we plotted the dynamics of the network activity in the subspace spanned by the prediction and precision vectors (<xref ref-type="fig" rid="fig4">Figure 4b</xref>). Such visualization captures both the temporal dynamics and the relationships between the variables represented in the network, and has helped understand network computations in other works (<xref ref-type="bibr" rid="bib86">Mante et al., 2013</xref>; <xref ref-type="bibr" rid="bib127">Sohn et al., 2019</xref>). Here, two observations can be made.</p><p>First, in the gated recurrent network (<xref ref-type="fig" rid="fig4">Figure 4b</xref>, second plot from the right), the trajectories are well separated along the precision axis (for the same prediction, the network can represent multiple precisions), meaning that the representation of precision is not reducible to the prediction. By contrast, in the network without gating (<xref ref-type="fig" rid="fig4">Figure 4b</xref>, rightmost plot), these trajectories highly overlap, which indicates that the representation of precision and prediction are mutually dependent. To measure this dependence, we computed the mutual information between the read precision and the prediction of the network, and it turned out to be very high in the network without gating (median MI = 5.2) compared to the gated recurrent network (median MI = 0.7) and the optimal agent (median MI = 0.6) (without lateral connections, median MI = 1.3; without recurrent weight training, median MI = 1.9), confirming that gating is important to separate the precision from the prediction.</p><p>Second, in the gated recurrent network, the precision interacts dynamically with the prediction in a manner consistent with the precision-weighting principle: for a given prediction, the lower the precision, the larger the subsequent updates to the prediction (<xref ref-type="fig" rid="fig4">Figure 4b</xref>, vertical dotted line indicates the level of prediction and arrows the subsequent updates).</p><p>These results indicate that in the network without gating, precision is confounded with prediction and the correlation between precision and effective learning rate is spuriously driven by the prediction itself, whereas in the network with gating, there is a genuine representation of precision beyond the prediction itself, which interacts with the updating of predictions. However, we have so far only provided correlational evidence; to show that the precision represented in the network plays a causal role in the subsequent prediction update, we need to perform an intervention that acts selectively on this precision.</p></sec><sec id="s2-5"><title>Causal role of precision-weighting for adaptation to changes</title><p>We tested whether the internal representation of precision causally regulated the effective learning rate in the networks using a perturbation experiment. We designed perturbations of the recurrent activity that induced a controlled change in the read precision, while leaving the networks’ current prediction unchanged to control for the effect of the prediction error (for the construction of the perturbations, see <xref ref-type="fig" rid="fig5">Figure 5</xref> bottom left diagram and legend, and Materials and methods). These perturbations caused significant changes in the networks’ subsequent effective learning rate, commensurate with the induced change in precision, as predicted by the principle of precision-weighting (<xref ref-type="fig" rid="fig5">Figure 5</xref>, middle plot). Importantly, this causal relationship was abolished in the alternative networks that lacked one of the mechanisms of the gated recurrent architecture (<xref ref-type="fig" rid="fig5">Figure 5</xref>, right three plots; the slope of the effect was significantly different between the gated recurrent network group and any of the alternative network groups, two-tailed two independent samples t-test, all t(38) &gt; 4.1, all p &lt; 0.001, all Cohen’s d &gt; 1.3).</p><fig id="fig5" position="float"><label>Figure 5.</label><caption><title>Precision-weighting causally determines the adjustment of the effective learning rate in gated recurrent networks only.</title><p>Causal test of a network’s precision on its effective learning rate. The recurrent activity was perturbed to induce a controlled change δ in the read precision, while keeping the prediction at the current time step—and thus the prediction error at the next time step—constant. This was done by making the perturbation vector orthogonal to the prediction vector and making its projection onto the precision vector equal to δ (bottom left diagram). We measured the perturbation’s effect on the subsequent effective learning rate as the difference in learning rate ‘with perturbation’ minus ‘without perturbation’ at the next time step (four plots on the right). Each dot (and joining line) corresponds to one network. ***: p &lt; 0.001, n.s.: p &gt; 0.05 (one-tailed paired t-test).</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-71801-fig5-v4.tif"/></fig><p>These results show that the gated recurrent networks’ ability to adapt to changes indeed relies on their precision-dependent updating and that such precision-weighting does not arise without all three mechanisms of the gated recurrence.</p></sec><sec id="s2-6"><title>Leveraging and internalizing a latent structure: bigram probabilities</title><p>While the changing unigram environment already covers many tasks in the behavioral and neuroscience literature, real-world sequences often exhibit more structure. To study the ability to leverage such structure, we designed a new stochastic and changing environment in which the sequence of observations is no longer generated according to a single unigram probability, p(1), but two ‘bigram probabilities’ (also known as transition probabilities), p(0|0) and p(1|1), which denote the probability of occurrence of a 0 after a 0 and of a 1 after a 1, respectively (<xref ref-type="fig" rid="fig6">Figure 6a</xref>; see <xref ref-type="fig" rid="fig1s1">Figure 1—figure supplement 1</xref> for a graphical model). These bigram probabilities are also changing randomly, with independent change points.</p><fig-group><fig id="fig6" position="float"><label>Figure 6.</label><caption><title>Gated recurrent networks correctly leverage and internalize the latent bigram structure.</title><p>(<bold>a</bold>) Schematic of the changing bigram environment’s latent probabilities (left) and sample generated sequence (right, dots: observations, lines: latent bigram probabilities). At each time step, a binary observation is randomly generated according to the relevant latent bigram probability, p<sub>0|0</sub> or p<sub>1|1</sub> depending on the previous observation. p<sub>0|0</sub> denotes the probability of occurrence of a 0 after a 0 and p<sub>1|1</sub> that of a 1 after a 1 (note that p<sub>1|0</sub>=1-p<sub>0|0</sub> and p<sub>0|1</sub>=1-p<sub>1|1</sub>). At any time step, each of the two bigram probabilities can suddenly change to a new value uniformly drawn in [0,1], randomly with a fixed probability and independently from each other. (<bold>b</bold>) Example prediction sequence illustrating each network’s ability or inability to change prediction according to the local context, compared to the optimal prediction (dots: observations, lines: predictions). (<bold>c</bold>) Prediction performance of each type of agent in the changing bigram environment. 20 new agents of each type were trained and tested as in <xref ref-type="fig" rid="fig2">Figure 2b</xref> but now in the changing bigram environment (dots: agents; bars: average). The gated recurrent network significantly outperformed every other type of agent (p &lt; 0.001, two-tailed two independent samples t-test with Welch’s correction for unequal variances). (<bold>d</bold>) Internalization of the latent structure as shown on an out-of-sample sequence: the two bigram probabilities are simultaneously represented in the gated recurrent network (top), and closely follow the optimal estimates (bottom). The readouts were obtained through linear regression from the recurrent activity to four estimates separately: the log odds of the mean and the log precision of the optimal posterior distribution on p<sub>0|0</sub> and p<sub>1|1</sub>. In (<bold>b</bold>) and (<bold>d</bold>), the networks (out of 20) yielding median performance were selected for illustration purposes.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-71801-fig6-v4.tif"/></fig><fig id="fig6s1" position="float" specific-use="child-fig"><label>Figure 6—figure supplement 1.</label><caption><title>Performance across training and test environments.</title><p>For each type of agent and each environment, a set of 20 agents was trained in the given environment as in <xref ref-type="fig" rid="fig2">Figures 2</xref>, <xref ref-type="fig" rid="fig5">5</xref> and <xref ref-type="fig" rid="fig6">6</xref>. The performance of each set of trained agents was then evaluated in each test environment, using 1,000 new sequences per environment and the same performance measure as in <xref ref-type="fig" rid="fig2">Figures 2</xref> and <xref ref-type="fig" rid="fig5">5</xref>. ch.: changing; ind.: independent change points; coup: coupled change points.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-71801-fig6-figsupp1-v4.tif"/></fig></fig-group><p>This ‘changing bigram environment’ is well motivated because there is ample evidence that bigram probabilities play a key role in sequence knowledge in humans and other animals (<xref ref-type="bibr" rid="bib30">Dehaene et al., 2015</xref>) even in the face of changes (<xref ref-type="bibr" rid="bib16">Bornstein and Daw, 2013</xref>; <xref ref-type="bibr" rid="bib91">Meyniel et al., 2015</xref>).</p><p>We assessed how well the networks could leverage the latent bigram structure after having been trained in this environment. For comparison, we tested the optimal agent for this environment as well as two groups of heuristics: delta-rule and leaky estimation of unigram probabilities (as in <xref ref-type="fig" rid="fig2">Figure 2b</xref>), and now also delta rule and leaky estimation of bigram probabilities (see Materials and methods for details).</p><p>The gated recurrent networks achieved 98 % of optimal prediction performance (CI ±0.3%), outperforming the heuristic agents estimating bigram probabilities, and even more so those estimating a unigram probability (<xref ref-type="fig" rid="fig6">Figure 6c</xref>). To demonstrate that this was due to their internalization of the latent structure, we also tested the gated recurrent networks that had been trained in the changing unigram environment: their performance was much worse (<xref ref-type="fig" rid="fig6s1">Figure 6—figure supplement 1</xref>).</p><p>At the mechanistic level, all three mechanisms of the gated recurrence are important for this ability to leverage the latent bigram structure. Not only does the performance drop when one of these mechanisms is removed (<xref ref-type="fig" rid="fig6">Figure 6c</xref>), but also this drop in performance is much larger than that observed in the changing unigram environment (without gating: –11.2 % [CI ±1.5 % calculated by Welch’s t-interval] in the bigram environment vs. –5.5 % [CI ±0.6%] in the unigram environment, without lateral connections: –18.5 % [CI ±1.8%] vs. –2.9 % [CI ±0.2%]; without recurrent weight training: –29.9 % [CI ±1.6%] vs. –11.0 % [CI ±2.1%]; for every mechanism, there was a significant interaction effect between the removal of the mechanism and the environment on performance, all F(1,76) &gt; 47.9, all p &lt; 0.001).</p><p><xref ref-type="fig" rid="fig6">Figure 6b</xref> illustrates the gated recurrent networks’ ability to correctly incorporate the bigram context into its predictions compared to networks lacking one of the mechanisms of the gated recurrence. While a gated recurrent network aptly changes its prediction from one observation to the next according to the preceding observation as the optimal agent does, the other networks fail to show such context-dependent behavior, sometimes even changing their prediction away from the optimal agent.</p><p>Altogether these results show that gated recurrent networks can leverage the latent bigram structure, but this ability is impaired when one mechanism of the gated recurrence is missing.</p><p>Is the networks’ representation of the latent bigram structure impenetrable or easily accessible? We tested the latter possibility by trying to linearly read out the optimal estimate of each of the latent bigram probabilities from the recurrent activity of a gated recurrent network (see Materials and methods). Arguing in favor of an explicit representation, we found that the read estimates of each of the latent bigram probabilities on left-out data were highly accurate (Pearson correlation with the optimal estimates, median and CI: 0.97 [0.97, 0.98] for each of the two bigram probabilities).</p><p>In addition to the point estimates of the latent bigram probabilities, we also tested whether a network maintained some information about the precision of each estimate. Again, we assessed the possibility to linearly read out the optimal precision of each estimate and found that the read precisions on left-out data were quite accurate (Pearson correlation with the optimal precisions, median and CI: 0.77 [0.74, 0.78] for one bigram probability and 0.76 [0.74, 0.78] for the other probability).</p><p><xref ref-type="fig" rid="fig6">Figure 6d</xref> illustrates the striking resemblance between the estimates read from a gated recurrent network and the optimal estimates. Furthermore, it shows that the network successfully disentangles one bigram probability from the other since the read estimates can evolve independently from each other (for instance during the first 20 time steps, the value for 1|1 changes while the value for 0|0 does not, since only 1 s are observed). It is particularly interesting that both bigram probabilities are simultaneously represented, given that only one of them is relevant for the moment-by-moment prediction read by the network’s output unit (whose weights cannot change during the sequence).</p><p>We conclude that gated recurrent networks internalize the latent bigram structure in such a way that both bigram probabilities are available simultaneously, even though only one of the two is needed at any one time for the prediction.</p></sec><sec id="s2-7"><title>Leveraging a higher-level structure: inference about latent changes</title><p>In real life, latent structures can also exhibit different levels that are organized hierarchically (<xref ref-type="bibr" rid="bib13">Bill et al., 2020</xref>; <xref ref-type="bibr" rid="bib91">Meyniel et al., 2015</xref>; <xref ref-type="bibr" rid="bib107">Purcell and Kiani, 2016</xref>). To study the ability to leverage such a hierarchical structure, we designed a third environment in which, in addition to bigram probabilities, we introduced a higher-level factor: the change points of the two bigram probabilities are now coupled, rather than independent as they were in the previous environment (<xref ref-type="fig" rid="fig7">Figure 7a</xref>; <xref ref-type="fig" rid="fig1s1">Figure 1—figure supplement 1</xref> shows the hierarchical structure). Due to this coupling, from the agent’s point of view, the likelihood that a change point has occurred depends on the observations about both bigrams. Thus, optimal prediction requires the ability to make a higher-level inference: having observed that the frequency of one of the bigrams has changed, one should not only suspect that the latent probability of this bigram has changed but also transfer this suspicion of a change to the latent probability of the other bigram, even without any observations about that bigram.</p><fig id="fig7" position="float"><label>Figure 7.</label><caption><title>Gated recurrent but not alternative networks leverage a higher-level structure, distinguishing the case where change points are coupled vs. independent.</title><p>Procedure to test the higher-level inference: (<bold>a</bold>) For each network architecture, 20 networks were trained on sequences where the change points of the two latent bigram probabilities are coupled and 20 other networks were trained on sequences where they are independent (the plots show an example training sequence for each case); (<bold>b</bold>) The networks were then tested on sequences designed to trigger the suspicion of a change point in one bigram probability and measure their inference about the other bigram probability: |p<sub>after</sub>−p<sub>before</sub>| should be larger when the agent assumes change points to be coupled rather than independent. The plot shows an example test sequence. Red, blue, solid, and dashed lines: as in (<bold>c</bold>), except that only the gated recurrent network (out of 20) yielding median performance is shown for illustration purposes. (<bold>c</bold>) Change in prediction about the unobserved bigram probability of the networks trained on coupled change points (red) and independent change points (blue) for each network architecture, averaged over sequences. Solid lines and bands show the mean and the 95 % confidence interval of the mean over networks. Dotted lines show the corresponding values of the optimal agent for the two cases. Only the gated recurrent architecture yields a significant difference between networks trained on coupled vs. independent change points (one-tailed two independent samples t-test, ***: p &lt; 0.001, n.s.: p &gt; 0.05).</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-71801-fig7-v4.tif"/></fig><p>Such a transfer has been reported in humans (<xref ref-type="bibr" rid="bib56">Heilbron and Meyniel, 2019</xref>, Figure 5B). A typical situation is when a streak of repetitions is encountered (<xref ref-type="fig" rid="fig7">Figure 7b</xref>): if a long streak of 1 s was deemed unlikely, it should trigger the suspicion of a change point such that p(1|1) is now high, and this suspicion should be transferred to p(0|0) by partially resetting it. This reset is reflected in the change between the prediction following the 0 just before the streak and that following the 0 just after the streak (<xref ref-type="fig" rid="fig7">Figure 7b</xref>, |p<sub>after</sub>−p<sub>before</sub>|).</p><p>We tested the networks’ ability for higher-level inference in the same way, by exposing them to such streaks of repetitions and measuring their change in prediction about the unobserved bigram before and after the streak. More accurately, we compared the change in prediction of the networks trained in the environment with coupled change points to that of the networks trained in the environment with independent change points, since the higher-level inference should only be made in the coupled case.</p><p>We found that gated recurrent networks trained in the coupled environment changed their prediction about the unobserved bigram significantly more than networks trained in the independent environment, and this was true across a large range of streak lengths (<xref ref-type="fig" rid="fig7">Figure 7c</xref>, top plot). The mere presence of this effect is particularly impressive given that the coupling makes very little difference in terms of raw performance (<xref ref-type="fig" rid="fig6s1">Figure 6—figure supplement 1</xref>, the networks trained in either the coupled or the independent environment perform very similarly when tested in either environment). All mechanisms of the gated recurrence are important to achieve this higher-level inference since the networks deprived of either gating, lateral connections, or recurrent weight training did not show any effect, no matter the streak length (<xref ref-type="fig" rid="fig7">Figure 7c</xref>, bottom three plots; for every mechanism, there was a significant interaction effect between the removal of the mechanism and the training environment on the change in prediction over networks and streak lengths, all F(1,6076) &gt; 43.2, all p &lt; 0.001).</p><p>These results show that gated recurrent networks but not alternative networks leverage the higher level of structure where the change points of the latent probabilities are coupled.</p></sec><sec id="s2-8"><title>Gated recurrence enables simple solutions</title><p>Finally, we highlight the small number of units sufficient to perform quasi-optimally in the increasingly structured environments that we tested: the above-mentioned results were obtained with 11 recurrent units. It turns out that gated recurrent networks can reach a similar performance with even fewer units, especially in simpler environments (<xref ref-type="fig" rid="fig8">Figure 8a and b</xref>, left plot). For instance, in the unigram environment, gated recurrent networks reach 99 % of their asymptotic performance with no more than 3 units.</p><fig-group><fig id="fig8" position="float"><label>Figure 8.</label><caption><title>Low-complexity solutions are uniquely enabled by the combination of gating, lateral connections, and recurrent weight training.</title><p>(<bold>a</bold> and <bold>b</bold>) Prediction performance of each network architecture in the changing unigram environment and the changing bigram environment, respectively, as a function of the number of recurrent units (i.e. space complexity) of the network. For each network architecture and each number of units, 20 networks were trained using hyperparameters that had been optimized prior to training, and prediction performance was measured as the % of optimal log likelihood on new test sequences. Solid lines, bands, and dashed lines show the mean, 95 % confidence interval of the mean, and maximum performance, respectively. At the maximum displayed number of units, all of the alternative architectures have exceeded the complexity of the 11-unit gated recurrent network shown on the left and in previous Figures, both in terms of the number of units and the number of trained parameters (indicated on the twin x-axes), but none of them have yet reached its performance.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-71801-fig8-v4.tif"/></fig><fig id="fig8s1" position="float" specific-use="child-fig"><label>Figure 8—figure supplement 1.</label><caption><title>Training speed of the gated recurrent networks in the changing unigram and bigram environments.</title><p>During training, the networks’ weights were iteratively updated, with each update based on the evaluation of the cost function on 20 sequences. Prediction performance was repeatedly measured after each iteration as the % of optimal log likelihood on an out-of-sample validation set of 200 sequences. The thin lines and the thick line show the mean and the individual performances of the 20 networks, respectively.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-71801-fig8-figsupp1-v4.tif"/></fig></fig-group><p>By contrast, without either gating, lateral connections, or recurrent weight training, even when the networks are provided with more units to match the number of trained parameters in the 11-unit gated recurrent networks, they are unable to achieve similar performance (<xref ref-type="fig" rid="fig8">Figure 8a and b</xref>, right three plots, the twin x-axes indicate the number of units and trained parameters).</p><p>With an unlimited number of units, at least in the case without gating (i.e. a vanilla RNN, short for recurrent neural network), the networks will be able to achieve such performance since they are universal approximators of dynamical systems (<xref ref-type="bibr" rid="bib27">Cybenko, 1989</xref>; <xref ref-type="bibr" rid="bib120">Schäfer and Zimmermann, 2006</xref>). However, our results indicate that this could require a very large number of units even in the simplest environment tested here (see <xref ref-type="fig" rid="fig8">Figure 8a and b</xref>, without gating at 1000 units). Indeed, the slow growth of the vanilla RNNs’ performance with the number of units is well described by a power law function, of the form: (100−p) = c(1/N)<sup>α</sup>, where p is the % of optimal performance and N is the number of units. We fitted this law in the unigram environment using the obtained performance from 2 to 45 units and it yielded a goodness-of-fit of R<sup>2</sup> = 92.4% (fitting was done by linear regression on the logarithm of N and (100−p)). To further confirm the validity of the power law, we then extrapolated to 1,000 units and found that the predicted performance was within 0.2 % of the obtained performance for networks of this size (predicted: 97.8%, obtained: 97.6%). Based on this power law, more than 10<sup>4</sup> units would be needed for the vanilla RNN to reach the performance exhibited by the GRU with only 11 units.</p><p>Note that, in terms of computational complexity, the number of units is a fair measure of space complexity (i.e. the amount of memory) across the architectures we considered, since in all of them it is equal to the number of state variables (having one state variable <ext-link ext-link-type="uri" xlink:href="https://www.codecogs.com/eqnedit.php?latex=h_i#0">hi</ext-link> per unit, see Materials and methods). What varies across architectures is the number of trained parameters, that is, the degrees of freedom that can be used during training to achieve different dynamics. Still, the conclusion remains the same when an alternative network exceeds the complexity of an 11-unit gated recurrent network in both its number of units and its number of trained parameters.</p><p>Therefore, it is the specific computational properties provided by the combination of the three mechanisms that afford effective low-complexity solutions.</p></sec></sec><sec id="s3" sec-type="discussion"><title>Discussion</title><p>We have shown that the gated recurrent architecture enables simple and effective solutions: with only 11 units, the networks perform quasi-optimally in environments fraught with randomness, changes, and different levels of latent structure. Moreover, these solutions reproduce several aspects of optimality observed in organisms, including the adaptation of their effective learning rate, the ability to represent the precision of their estimation and to use it to weight their updates, and the ability to represent and leverage the latent structure of the environment. By depriving the architecture of one of its mechanisms, we have shown that three of them are important to achieve such solutions: gating, lateral connections, and the training of recurrent weights.</p><sec id="s3-1"><title>Can small neural networks behave like Bayesian agents?</title><p>A central and much-debated question in the scientific community is whether the brain can perform Bayesian inference (<xref ref-type="bibr" rid="bib73">Knill and Pouget, 2004</xref>; <xref ref-type="bibr" rid="bib17">Bowers and Davis, 2012</xref>; <xref ref-type="bibr" rid="bib52">Griffiths et al., 2012</xref>; <xref ref-type="bibr" rid="bib108">Rahnev and Denison, 2018</xref>; <xref ref-type="bibr" rid="bib78">Lee and Mumford, 2003</xref>; <xref ref-type="bibr" rid="bib109">Rao and Ballard, 1999</xref>; <xref ref-type="bibr" rid="bib117">Sanborn and Chater, 2016</xref>; <xref ref-type="bibr" rid="bib20">Chater et al., 2006</xref>; <xref ref-type="bibr" rid="bib42">Findling et al., 2019</xref>; <xref ref-type="bibr" rid="bib151">Wyart and Koechlin, 2016</xref>; <xref ref-type="bibr" rid="bib129">Soltani and Izquierdo, 2019</xref>; <xref ref-type="bibr" rid="bib44">Findling et al., 2021</xref>). From a computational viewpoint, there exists no tractable solution (even approximate) for Bayesian inference in an arbitrary environment, since it is NP-hard (<xref ref-type="bibr" rid="bib24">Cooper, 1990</xref>; <xref ref-type="bibr" rid="bib28">Dagum and Luby, 1993</xref>). Being a bounded agent (<xref ref-type="bibr" rid="bib125">Simon, 1955</xref>; <xref ref-type="bibr" rid="bib126">Simon, 1972</xref>), the brain cannot solve Bayesian inference in its most general form. The interesting question is whether the brain can perform Bayesian inference in some environments that occur in real life. More precisely, by ‘perform Bayesian inference’ one usually means that it performs computations that satisfy certain desirable properties of Bayesian inference, such as taking into account a certain type of uncertainty and a certain type of latent structure (<xref ref-type="bibr" rid="bib26">Courville et al., 2006</xref>; <xref ref-type="bibr" rid="bib32">Deroy et al., 2016</xref>; <xref ref-type="bibr" rid="bib52">Griffiths et al., 2012</xref>; <xref ref-type="bibr" rid="bib73">Knill and Pouget, 2004</xref>; <xref ref-type="bibr" rid="bib83">Ma, 2010</xref>; <xref ref-type="bibr" rid="bib84">Ma and Jazayeri, 2014</xref>; <xref ref-type="bibr" rid="bib139">Tauber et al., 2017</xref>). In this study, we selected specific properties and showed that they can indeed be satisfied when using specific (not all) neural architectures.</p><p>In the changing unigram and changing bigram environments, our results provide an existence proof: there exist plausible solutions that are almost indistinguishable from Bayesian inference (i.e. the optimal solution). They exhibit qualitative properties of Bayesian inference that have been demonstrated in humans but are lacking in heuristic solutions, such as the dynamic adjustment of the effective learning rate (<xref ref-type="bibr" rid="bib8">Behrens et al., 2007</xref>; <xref ref-type="bibr" rid="bib96">Nassar et al., 2010</xref>; <xref ref-type="bibr" rid="bib97">Nassar et al., 2012</xref>), the internal representation of latent variables and the precision of their estimates (<xref ref-type="bibr" rid="bib15">Boldt et al., 2019</xref>; <xref ref-type="bibr" rid="bib91">Meyniel et al., 2015</xref>), the precision-weighting of updates (<xref ref-type="bibr" rid="bib90">McGuire et al., 2014</xref>; <xref ref-type="bibr" rid="bib96">Nassar et al., 2010</xref>; <xref ref-type="bibr" rid="bib97">Nassar et al., 2012</xref>), and the ability for higher-level inference (<xref ref-type="bibr" rid="bib13">Bill et al., 2020</xref>; <xref ref-type="bibr" rid="bib56">Heilbron and Meyniel, 2019</xref>; <xref ref-type="bibr" rid="bib107">Purcell and Kiani, 2016</xref>).</p><p>The performance we obtained with the gated recurrent architecture is consistent with the numerous other successes it produced in other cognitive neuroscience tasks (<xref ref-type="bibr" rid="bib147">Wang et al., 2018</xref>; <xref ref-type="bibr" rid="bib154">Yang et al., 2019</xref>; <xref ref-type="bibr" rid="bib157">Zhang et al., 2020</xref>). Our detailed study reveals that it offers quasi-optimal low-complexity solutions to new and difficult challenges, including those posed by bigram and higher-level structures and latent probabilities that change unpredictably anywhere in the unit interval. We acknowledge that further generalization to additional challenges remains to be investigated, including the use of more than two categories of observations or continuous observations, and latent structures with longer range dependencies (beyond bigram probabilities).</p></sec><sec id="s3-2"><title>Minimal set of mechanisms</title><p>What are the essential mechanistic elements that enable such solutions? We show that it suffices to have recurrent units of computation equipped with three mechanisms: (1) input, self, and lateral connections which enable each unit to sum up the input with their own and other units’ prior value before a non-linear transformation is applied; (2) gating, which enables multiplicative interactions between activities at the summation step; (3) the training of connection weights.</p><p>One of the advantages of such mechanisms is their generic character: they do not include any components specifically designed to perform certain probabilistic operations or estimate certain types of latent variables, as often done in neuroscience (<xref ref-type="bibr" rid="bib36">Echeveste et al., 2020</xref>; <xref ref-type="bibr" rid="bib48">Fusi et al., 2007</xref>; <xref ref-type="bibr" rid="bib64">Jazayeri and Movshon, 2006</xref>; <xref ref-type="bibr" rid="bib82">Ma et al., 2006</xref>; <xref ref-type="bibr" rid="bib103">Pecevski et al., 2011</xref>; <xref ref-type="bibr" rid="bib128">Soltani and Wang, 2010</xref>). In addition, they allow adaptive behavior only through recurrent activity dynamics, without involving synaptic plasticity as in other models (<xref ref-type="bibr" rid="bib41">Farashahi et al., 2017</xref>; <xref ref-type="bibr" rid="bib47">Fusi et al., 2005</xref>; <xref ref-type="bibr" rid="bib63">Iigaya, 2016</xref>; <xref ref-type="bibr" rid="bib122">Schultz et al., 1997</xref>). This distinction has implications for the timescale of adaptation: in the brain, recurrent dynamics and synaptic plasticity often involve short and long timescales, respectively. Our study supports this view: recurrent dynamics allow the networks to quickly adapt to a given change in the environment (<xref ref-type="fig" rid="fig3">Figure 3</xref>), while synaptic plasticity allows the training process to tune the speed of this adaptation to the frequency of change of the environment (<xref ref-type="fig" rid="fig3s1">Figure 3—figure supplement 1</xref>).</p><p>Our findings suggest that these mechanisms are particularly advantageous to enable solutions with low computational complexity. Without one of them, it seems that a very large number of units (i.e. a large amount of memory) would be needed to achieve comparable performance (<xref ref-type="fig" rid="fig8">Figure 8</xref>) (note that universal approximation bounds in vanilla RNNs can be very large in terms of number of units [<xref ref-type="bibr" rid="bib6">Barron, 1993</xref>; <xref ref-type="bibr" rid="bib27">Cybenko, 1989</xref>; <xref ref-type="bibr" rid="bib120">Schäfer and Zimmermann, 2006</xref>]). These mechanisms thus seem to be key computational building blocks to build simple and effective solutions. This efficiency can be formalized as the minimum number of units sufficient for near-optimal performance (as in <xref ref-type="bibr" rid="bib98">Orhan and Ma, 2017</xref> who made a similar argument), and it is important for the brain since the brain has limited computational resources (often quantified by the Shannon capacity, i.e. the number of bits that can be transmitted per unit of time, which here amounts to the number of units) (<xref ref-type="bibr" rid="bib12">Bhui et al., 2021</xref>; <xref ref-type="bibr" rid="bib80">Lieder and Griffiths, 2019</xref>). Moreover, simplicity promotes our understanding, and it is with the same goal of understanding that others have used model reduction in large networks (<xref ref-type="bibr" rid="bib35">Dubreuil et al., 2020</xref>; <xref ref-type="bibr" rid="bib65">Jazayeri and Ostojic, 2021</xref>; <xref ref-type="bibr" rid="bib119">Schaeffer et al., 2020</xref>).</p><p>Since we cannot exhaustively test all possible parameter values, it might be possible that better solutions exist that were not discovered during training. However, to maximize the chances that the best possible performance is achieved after training, we conducted an extensive hyperparameter optimization, repeated for each environment, architecture, and several number of units, until there is no more improvement according to the Bayesian optimization (see Materials and methods).</p></sec><sec id="s3-3"><title>Biological implementations of the mechanisms</title><p>What biological elements could implement the mechanisms of the gated recurrence? Recurrent connections are ubiquitous in the brain (<xref ref-type="bibr" rid="bib34">Douglas and Martin, 2007</xref>; <xref ref-type="bibr" rid="bib60">Hunt and Hayden, 2017</xref>); the lesser-known aspect is that of gating. In the next paragraph, we speculate on the possible biological implementations of gating, broadly defined as a mechanism that modulates the effective weight of a connection as a function of the network state (and not limited to the very specific form of gating of the GRU).</p><p>In neuroscience, many forms of gating have been observed, and they can generally be grouped into three categories according to the neural process that supports them: neural circuits, neural oscillations, and neuromodulation. In neural circuits, a specific pathway can be gated through inhibition/disinhibition by inhibitory (GABAergic) neurons. This has been observed in microscopic circuits, e.g. in pyramidal neurons a dendritic pathway can be gated by interneurons (<xref ref-type="bibr" rid="bib25">Costa et al., 2017</xref>; <xref ref-type="bibr" rid="bib153">Yang et al., 2016</xref>), or macroscopic circuits, for example in basal ganglia-thalamo-cortical circuits a cortico-cortical pathway can be gated by the basal ganglia and the mediodorsal nucleus of thalamus (<xref ref-type="bibr" rid="bib99">O’Reilly, 2006</xref>; <xref ref-type="bibr" rid="bib100">O’Reilly and Frank, 2006</xref>; <xref ref-type="bibr" rid="bib111">Rikhye et al., 2018</xref>; <xref ref-type="bibr" rid="bib148">Wang and Halassa, 2021</xref>; <xref ref-type="bibr" rid="bib152">Yamakawa, 2020</xref>). In addition to inhibition/disinhibition, an effective gating can also be achieved by a large population of interacting neurons taking advantage of their nonlinearity (<xref ref-type="bibr" rid="bib9">Beiran et al., 2021</xref>; <xref ref-type="bibr" rid="bib35">Dubreuil et al., 2020</xref>). Regarding neural oscillations, experiments have shown that activity in certain frequency bands (typically, alpha and beta) can gate behavioral and neuronal responses to the same stimulus (<xref ref-type="bibr" rid="bib7">Baumgarten et al., 2016</xref>; <xref ref-type="bibr" rid="bib18">Busch et al., 2009</xref>; <xref ref-type="bibr" rid="bib58">Hipp et al., 2011</xref>; <xref ref-type="bibr" rid="bib61">Iemi et al., 2019</xref>; <xref ref-type="bibr" rid="bib71">Klimesch, 1999</xref>; <xref ref-type="bibr" rid="bib89">Mathewson et al., 2009</xref>). One of the most influential accounts is known as ‘pulsed inhibition’ (<xref ref-type="bibr" rid="bib53">Hahn et al., 2019</xref>; <xref ref-type="bibr" rid="bib66">Jensen and Mazaheri, 2010</xref>; <xref ref-type="bibr" rid="bib72">Klimesch et al., 2007</xref>): a low-frequency signal periodically inhibits a high-frequency signal, effectively silencing the high-frequency signal when the low-frequency signal exceeds a certain threshold. Finally, the binding of certain neuromodulators to the certain receptors of a synapse changes the gain of its input-output transfer function, thus changing its effective weight. This has been demonstrated in neurophysiological studies implicating noradrenaline (<xref ref-type="bibr" rid="bib4">Aston-Jones and Cohen, 2005</xref>; <xref ref-type="bibr" rid="bib116">Salgado et al., 2016</xref>; <xref ref-type="bibr" rid="bib123">Servan-Schreiber et al., 1990</xref>), dopamine (<xref ref-type="bibr" rid="bib95">Moyer et al., 2007</xref>; <xref ref-type="bibr" rid="bib123">Servan-Schreiber et al., 1990</xref>; <xref ref-type="bibr" rid="bib131">Stalter et al., 2020</xref>; <xref ref-type="bibr" rid="bib142">Thurley et al., 2008</xref>), and acetylcholine (<xref ref-type="bibr" rid="bib51">Gil et al., 1997</xref>; <xref ref-type="bibr" rid="bib57">Herrero et al., 2008</xref>) (see review in <xref ref-type="bibr" rid="bib141">Thiele and Bellgrove, 2018</xref>).</p><p>We claim that gated recurrence provides plausible solutions for the brain because its mechanisms can all be biologically implemented and lead to efficient solutions. However, given their multiple biological realizability, the mapping between artificial units and biological neurons is not straightforward: one unit may map to a large population of neurons (e.g. a brain area), or even to a microscopic, subneuronal component (e.g. the dendritic level).</p></sec><sec id="s3-4"><title>Training: Its role and possible biological counterpart</title><p>Regarding the training, our results highlight that it is important to adjust the recurrent weights and thus the network dynamics to the environment (and not fix them as in reservoir computing [<xref ref-type="bibr" rid="bib138">Tanaka et al., 2019</xref>]), but we make no claims about the biological process that leads to such adjustment in brains. It could occur during development (<xref ref-type="bibr" rid="bib124">Sherman et al., 2020</xref>), the life span (<xref ref-type="bibr" rid="bib81">Lillicrap et al., 2020</xref>), or the evolution process (<xref ref-type="bibr" rid="bib156">Zador, 2019</xref>) (these possibilities are not mutually exclusive). Although our training procedure may not be accurate for biology as a whole, two aspects of it may be informative for future research. First, it relies only on the observation sequence (no supervision or reinforcement), leveraging prediction error signals, which have been found in the brain in many studies (<xref ref-type="bibr" rid="bib31">den Ouden et al., 2012</xref>; <xref ref-type="bibr" rid="bib39">Eshel et al., 2013</xref>; <xref ref-type="bibr" rid="bib85">Maheu et al., 2019</xref>). Importantly, in predictive coding (<xref ref-type="bibr" rid="bib109">Rao and Ballard, 1999</xref>), the computation of prediction errors is part of the prediction process; here we are suggesting that it may also be part of the training process (as argued in <xref ref-type="bibr" rid="bib101">O’Reilly et al., 2021</xref>). Second, relatively few iterations of training suffice (<xref ref-type="fig" rid="fig8s1">Figure 8—figure supplement 1</xref>, in the order of 10–100; for comparison, <xref ref-type="bibr" rid="bib147">Wang et al., 2018</xref> reported training for 40,000 episodes in an environment similar to ours).</p></sec><sec id="s3-5"><title>Suboptimalities in human behavior</title><p>In this study we have focused on some aspects of optimality that humans exhibit in the three environments we explored, but several aspects of their behavior are also suboptimal. In the laboratory, their behavior is often at best qualitatively Bayesian but quantitatively suboptimal. For example, although they adjust their effective learning rate to changes, the base value of their learning rate and their dynamic adjustments may depart from the optimal values (<xref ref-type="bibr" rid="bib96">Nassar et al., 2010</xref>; <xref ref-type="bibr" rid="bib97">Nassar et al., 2012</xref>; <xref ref-type="bibr" rid="bib106">Prat-Carrabin et al., 2021</xref>). They may also not update their prediction on every trial, unlike the optimal solution (<xref ref-type="bibr" rid="bib49">Gallistel et al., 2014</xref>; <xref ref-type="bibr" rid="bib68">Khaw et al., 2017</xref>). Finally, there is substantial interindividual variability which does not exist in the optimal solution (<xref ref-type="bibr" rid="bib69">Khaw et al., 2021</xref>; <xref ref-type="bibr" rid="bib96">Nassar et al., 2010</xref>; <xref ref-type="bibr" rid="bib97">Nassar et al., 2012</xref>; <xref ref-type="bibr" rid="bib106">Prat-Carrabin et al., 2021</xref>). In the future, these suboptimalities could be explored using our networks by making them suboptimal in three ways (among others): by stopping training before quasi-optimal performance is reached (<xref ref-type="bibr" rid="bib19">Caucheteux and King, 2021</xref>; <xref ref-type="bibr" rid="bib98">Orhan and Ma, 2017</xref>), by constraining the size of the network or its weights (with hard constraints or with regularization penalties) (<xref ref-type="bibr" rid="bib88">Mastrogiuseppe and Ostojic, 2017</xref>; <xref ref-type="bibr" rid="bib134">Sussillo et al., 2015</xref>), or by altering the network in a certain way, such as pruning some of the units or some of the connections (<xref ref-type="bibr" rid="bib14">Blalock et al., 2020</xref>; <xref ref-type="bibr" rid="bib21">Chechik et al., 1999</xref>; <xref ref-type="bibr" rid="bib75">LeCun et al., 1990</xref>; <xref ref-type="bibr" rid="bib130">Srivastava et al., 2014</xref>), or introducing random noise into the activity (<xref ref-type="bibr" rid="bib44">Findling et al., 2021</xref>; <xref ref-type="bibr" rid="bib43">Findling and Wyart, 2020</xref>; <xref ref-type="bibr" rid="bib79">Legenstein and Maass, 2014</xref>). In this way, one could perhaps reproduce the quantitative deviations from optimality while preserving the qualitative aspects of optimality observed in the laboratory.</p></sec><sec id="s3-6"><title>Implications for experimentalists</title><p>If already trained gated recurrent networks exist in the brain, then one can be used in a new but similar enough environment without further training. This is an interesting possibility because, in laboratory experiments mirroring our study, humans perform reasonably well with almost no training but explicit task instructions given in natural language, along with a baggage of prior experience (<xref ref-type="bibr" rid="bib49">Gallistel et al., 2014</xref>; <xref ref-type="bibr" rid="bib56">Heilbron and Meyniel, 2019</xref>; <xref ref-type="bibr" rid="bib69">Khaw et al., 2021</xref>; <xref ref-type="bibr" rid="bib91">Meyniel et al., 2015</xref>; <xref ref-type="bibr" rid="bib104">Peterson and Beach, 1967</xref>). In favor of the possibility to reuse an existing solution, we found that a gated recurrent network can still perform well in conditions different from those it was trained in: across probabilities of change points (<xref ref-type="fig" rid="fig3s1">Figure 3—figure supplement 1</xref>) and latent structures (<xref ref-type="fig" rid="fig6s1">Figure 6—figure supplement 1</xref>, from bigram to unigram).</p><p>In this study, we adopted a self-supervised training paradigm to see if the networks could in principle discover the latent structure from the sequences of observations alone. However, in laboratory experiments, humans often do not have to discover the structure since they are explicitly told what structure they will face and the experiment starts only after ensuring that they have understood it, which makes the comparison to our networks impossible in this setting in terms of training (see similar argument in <xref ref-type="bibr" rid="bib98">Orhan and Ma, 2017</xref>). In the future, it could be interesting to study the ability of gated recurrent networks to switch from one structure to another after having been informed of the current structure as humans do in these experiments. One possible way would be to give a label that indicates the current structure as additional input to our networks, as in <xref ref-type="bibr" rid="bib154">Yang et al., 2019</xref>.</p><p>One of our findings may be particularly interesting to experimentalists: in a gated recurrent network, the representations of latent probabilities and the precision of these probability estimates (sometimes referred to as confidence [<xref ref-type="bibr" rid="bib15">Boldt et al., 2019</xref>; <xref ref-type="bibr" rid="bib91">Meyniel et al., 2015</xref>], estimation uncertainty [<xref ref-type="bibr" rid="bib90">McGuire et al., 2014</xref>; <xref ref-type="bibr" rid="bib102">Payzan-LeNestour et al., 2013</xref>], or epistemic uncertainty [<xref ref-type="bibr" rid="bib2">Amini et al., 2020</xref>; <xref ref-type="bibr" rid="bib46">Friston et al., 2015</xref>; <xref ref-type="bibr" rid="bib105">Pezzulo et al., 2015</xref>]) are linearly readable from recurrent activity, the form of decoding most frequently used in neuroscience (<xref ref-type="bibr" rid="bib55">Haxby et al., 2014</xref>; <xref ref-type="bibr" rid="bib74">Kriegeskorte and Diedrichsen, 2019</xref>). These representations arise spontaneously, and their emergence seems to come from the computational properties of gated recurrence together with the need to perform well in a stochastic and changing environment. This yields an empirical prediction: if such networks can be found in the brain, then latent probability estimates and their precision should also be decodable in brain signals, as already found in some studies (<xref ref-type="bibr" rid="bib5">Bach et al., 2011</xref>; <xref ref-type="bibr" rid="bib90">McGuire et al., 2014</xref>; <xref ref-type="bibr" rid="bib94">Meyniel, 2020</xref>; <xref ref-type="bibr" rid="bib93">Meyniel and Dehaene, 2017</xref>; <xref ref-type="bibr" rid="bib102">Payzan-LeNestour et al., 2013</xref>; <xref ref-type="bibr" rid="bib144">Tomov et al., 2020</xref>).</p></sec></sec><sec id="s4" sec-type="materials|methods"><title>Materials and methods</title><sec id="s4-1"><title>Sequence prediction problem</title><p>The sequence prediction problem to be solved is the following. At each time step, an agent receives as input a binary-valued 'observation', <inline-formula><mml:math id="inf2"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>x</mml:mi><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>∈</mml:mo><mml:mo fence="false" stretchy="false">{</mml:mo><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:mn>1</mml:mn><mml:mo fence="false" stretchy="false">}</mml:mo></mml:mrow></mml:mstyle></mml:math></inline-formula>, and gives as output a real-valued 'prediction', <inline-formula><mml:math id="inf3"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>p</mml:mi><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>∈</mml:mo><mml:mo stretchy="false">[</mml:mo><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">]</mml:mo></mml:mrow></mml:mstyle></mml:math></inline-formula> which is an estimate of the probability that the value of the next observation is equal to 1, <inline-formula><mml:math id="inf4"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>p</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mstyle></mml:math></inline-formula>. Coding the prediction in terms of the observation being 1 rather than 0 is inconsequential since one can be deduced from the other: <inline-formula><mml:math id="inf5"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>p</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:mi>p</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mn>0</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mstyle></mml:math></inline-formula>. The agent’s objective is to make predictions that maximize the (log) likelihood of observations in the sequence, which technically corresponds to the negative binary cross-entropy cost function:<disp-formula id="equ1"><label>(1)</label><mml:math id="m1"><mml:mrow><mml:mi>L</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>p</mml:mi><mml:mo>;</mml:mo><mml:mi>x</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:munderover><mml:mo>∑</mml:mo><mml:mrow><mml:mi>t</mml:mi><mml:mo>=</mml:mo><mml:mn>0</mml:mn></mml:mrow><mml:mrow><mml:mi>T</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:munderover><mml:mrow><mml:mrow><mml:mi mathvariant="normal">l</mml:mi><mml:mi mathvariant="normal">o</mml:mi><mml:mi mathvariant="normal">g</mml:mi></mml:mrow><mml:mo stretchy="false">[</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:msub><mml:mi>p</mml:mi><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:msub><mml:mi>p</mml:mi><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:mo stretchy="false">]</mml:mo></mml:mrow></mml:mrow></mml:math></disp-formula></p></sec><sec id="s4-2"><title>Network architectures</title><p>All network architectures consist of a binary input unit, which codes for the current observation, one recurrent layer (sometimes called hidden layer) with a number N of recurrent units, and an output unit, which represents the network’s prediction. Unless otherwise stated, N = 11. At every time step, the recurrent unit <italic>i</italic> receives as input the value of the observation, <inline-formula><mml:math id="inf6"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>x</mml:mi><mml:mi>t</mml:mi></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula><ext-link ext-link-type="uri" xlink:href="https://www.codecogs.com/eqnedit.php?latex=x_%7bt%7d#0">,</ext-link> and the previous activation values of the recurrent units <italic>j</italic> that connect to <italic>i,</italic> <inline-formula><mml:math id="inf7"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>h</mml:mi><mml:mrow><mml:mi>j</mml:mi><mml:mo>,</mml:mo><mml:mi>t</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula>. It produces as output a new activation value, <inline-formula><mml:math id="inf8"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>h</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula>, which is a real number. The output unit receives as input the activations of all of the recurrent units, and produces as output the prediction <inline-formula><mml:math id="inf9"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>p</mml:mi><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula>.</p><p>The parameterized function of the output unit is the same for all network architectures:<disp-formula id="equ2"><mml:math id="m2"><mml:mrow><mml:msub><mml:mi>p</mml:mi><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mi>σ</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:munderover><mml:mo>∑</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>N</mml:mi></mml:mrow></mml:munderover><mml:msub><mml:mi>w</mml:mi><mml:mrow><mml:mi>h</mml:mi><mml:mi>p</mml:mi><mml:mo>,</mml:mo><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:msub><mml:mi>h</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mi>b</mml:mi><mml:mrow><mml:mi>h</mml:mi><mml:mi>p</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></disp-formula></p><p>where <inline-formula><mml:math id="inf10"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>σ</mml:mi></mml:mrow></mml:mstyle></mml:math></inline-formula> is the logistic sigmoid, <inline-formula><mml:math id="inf11"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>w</mml:mi><mml:mrow><mml:mi>h</mml:mi><mml:mi>p</mml:mi><mml:mo>,</mml:mo><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula> is the weight parameter of the connection from the <italic>i</italic>-th recurrent unit to the output unit, and <inline-formula><mml:math id="inf12"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>b</mml:mi><mml:mrow><mml:mi>h</mml:mi><mml:mi>p</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula> is the bias parameter of the output unit.</p><p>The updating of <inline-formula><mml:math id="inf13"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>h</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula> takes a different form depending on whether gating or lateral connections are included, as described below.</p><sec id="s4-2-1"><title>Gated recurrent network</title><p>A gated recurrent network includes both gating and lateral connections. This enables multiplicative interactions between the input and recurrent activity as well as the activities of different recurrent units during the updating of <inline-formula><mml:math id="inf14"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>h</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula>. The variant of gating used here is GRU (<xref ref-type="bibr" rid="bib22">Cho et al., 2014</xref>; <xref ref-type="bibr" rid="bib23">Chung et al., 2014</xref>). For convenience of exposition, we introduce, for each recurrent unit <italic>i</italic>, two intermediate variables in the calculation of the update: the reset gate <inline-formula><mml:math id="inf15"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>r</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula> and the update gate <inline-formula><mml:math id="inf16"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>z</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula>, both of which have their own set of weights and bias. The update gate corresponds to the extent to which a unit can change its values from one time step to the next, and the reset gate corresponds to the balance between recurrent activity and input activity in case of update. Note that <inline-formula><mml:math id="inf17"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>r</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula> and <inline-formula><mml:math id="inf18"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>z</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula> do not count as state variables since the system would be equivalently characterized without them by injecting their expression into the update equation of <inline-formula><mml:math id="inf19"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>h</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula> below. The update is calculated as follows:<disp-formula id="equ3"><mml:math id="m3"><mml:mrow><mml:msub><mml:mi>r</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>t</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mi>σ</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>w</mml:mi><mml:mrow><mml:mi>x</mml:mi><mml:mi>r</mml:mi><mml:mo>,</mml:mo><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:msub><mml:mi>x</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mi>b</mml:mi><mml:mrow><mml:mi>x</mml:mi><mml:mi>r</mml:mi><mml:mo>,</mml:mo><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mi>w</mml:mi><mml:mrow><mml:mi>h</mml:mi><mml:mi>r</mml:mi><mml:mo>,</mml:mo><mml:mi>i</mml:mi><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:msub><mml:mi>h</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:munder><mml:mo>∑</mml:mo><mml:mrow><mml:mi>j</mml:mi><mml:mo>≠</mml:mo><mml:mi>i</mml:mi></mml:mrow></mml:munder><mml:msub><mml:mi>w</mml:mi><mml:mrow><mml:mi>h</mml:mi><mml:mi>r</mml:mi><mml:mo>,</mml:mo><mml:mi>j</mml:mi><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:msub><mml:mi>h</mml:mi><mml:mrow><mml:mi>j</mml:mi><mml:mo>,</mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mi>b</mml:mi><mml:mrow><mml:mi>h</mml:mi><mml:mi>r</mml:mi><mml:mo>,</mml:mo><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mspace linebreak="newline"/><mml:msub><mml:mi>z</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>t</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mi>σ</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>w</mml:mi><mml:mrow><mml:mi>x</mml:mi><mml:mi>z</mml:mi><mml:mo>,</mml:mo><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:msub><mml:mi>x</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mi>b</mml:mi><mml:mrow><mml:mi>x</mml:mi><mml:mi>z</mml:mi><mml:mo>,</mml:mo><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mi>w</mml:mi><mml:mrow><mml:mi>h</mml:mi><mml:mi>z</mml:mi><mml:mo>,</mml:mo><mml:mi>i</mml:mi><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:msub><mml:mi>h</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:munder><mml:mo>∑</mml:mo><mml:mrow><mml:mi>j</mml:mi><mml:mo>≠</mml:mo><mml:mi>i</mml:mi></mml:mrow></mml:munder><mml:msub><mml:mi>w</mml:mi><mml:mrow><mml:mi>h</mml:mi><mml:mi>z</mml:mi><mml:mo>,</mml:mo><mml:mi>j</mml:mi><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:msub><mml:mi>h</mml:mi><mml:mrow><mml:mi>j</mml:mi><mml:mo>,</mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mi>b</mml:mi><mml:mrow><mml:mi>h</mml:mi><mml:mi>z</mml:mi><mml:mo>,</mml:mo><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mspace linebreak="newline"/><mml:msub><mml:mi>h</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>t</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:msub><mml:mi>z</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>t</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:msub><mml:mi>h</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mspace linebreak="newline"/><mml:mo>+</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:msub><mml:mi>z</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>t</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:mrow><mml:mi mathvariant="normal">t</mml:mi><mml:mi mathvariant="normal">a</mml:mi><mml:mi mathvariant="normal">n</mml:mi><mml:mi mathvariant="normal">h</mml:mi></mml:mrow><mml:mrow><mml:mo>[</mml:mo><mml:mrow><mml:msub><mml:mi>w</mml:mi><mml:mrow><mml:mi>x</mml:mi><mml:mi>h</mml:mi><mml:mo>,</mml:mo><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:msub><mml:mi>x</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mi>b</mml:mi><mml:mrow><mml:mi>x</mml:mi><mml:mi>h</mml:mi><mml:mo>,</mml:mo><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mi>r</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>t</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>w</mml:mi><mml:mrow><mml:mi>h</mml:mi><mml:mi>h</mml:mi><mml:mo>,</mml:mo><mml:mi>i</mml:mi><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:msub><mml:mi>h</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:munder><mml:mo>∑</mml:mo><mml:mrow><mml:mi>j</mml:mi><mml:mo>≠</mml:mo><mml:mi>i</mml:mi></mml:mrow></mml:munder><mml:msub><mml:mi>w</mml:mi><mml:mrow><mml:mi>h</mml:mi><mml:mi>h</mml:mi><mml:mo>,</mml:mo><mml:mi>j</mml:mi><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:msub><mml:mi>h</mml:mi><mml:mrow><mml:mi>j</mml:mi><mml:mo>,</mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:mo>+</mml:mo><mml:msub><mml:mi>b</mml:mi><mml:mrow><mml:mi>h</mml:mi><mml:mi>h</mml:mi><mml:mo>,</mml:mo><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>]</mml:mo></mml:mrow><mml:mspace linebreak="newline"/><mml:msub><mml:mi>h</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>t</mml:mi><mml:mo>=</mml:mo><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:math></disp-formula></p><p>where (<inline-formula><mml:math id="inf20"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>w</mml:mi><mml:mrow><mml:mi>x</mml:mi><mml:mi>r</mml:mi><mml:mo>,</mml:mo><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>b</mml:mi><mml:mrow><mml:mi>x</mml:mi><mml:mi>r</mml:mi><mml:mo>,</mml:mo><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>w</mml:mi><mml:mrow><mml:mi>h</mml:mi><mml:mi>r</mml:mi><mml:mo>,</mml:mo><mml:mi>j</mml:mi><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>b</mml:mi><mml:mrow><mml:mi>h</mml:mi><mml:mi>r</mml:mi><mml:mo>,</mml:mo><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula>), (<inline-formula><mml:math id="inf21"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>w</mml:mi><mml:mrow><mml:mi>x</mml:mi><mml:mi>z</mml:mi><mml:mo>,</mml:mo><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>b</mml:mi><mml:mrow><mml:mi>x</mml:mi><mml:mi>z</mml:mi><mml:mo>,</mml:mo><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>w</mml:mi><mml:mrow><mml:mi>h</mml:mi><mml:mi>z</mml:mi><mml:mo>,</mml:mo><mml:mi>j</mml:mi><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>b</mml:mi><mml:mrow><mml:mi>h</mml:mi><mml:mi>z</mml:mi><mml:mo>,</mml:mo><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula>), (<inline-formula><mml:math id="inf22"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>w</mml:mi><mml:mrow><mml:mi>x</mml:mi><mml:mi>h</mml:mi><mml:mo>,</mml:mo><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>b</mml:mi><mml:mrow><mml:mi>x</mml:mi><mml:mi>h</mml:mi><mml:mo>,</mml:mo><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>w</mml:mi><mml:mrow><mml:mi>h</mml:mi><mml:mi>h</mml:mi><mml:mo>,</mml:mo><mml:mi>j</mml:mi><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>b</mml:mi><mml:mrow><mml:mi>h</mml:mi><mml:mi>h</mml:mi><mml:mo>,</mml:mo><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula>) are the connection weights and biases from the input unit and the recurrent units to unit <italic>i</italic> corresponding to the reset gate, the update gate, and the ungated new activity, respectively.</p><p>Another variant of gating is the LSTM (<xref ref-type="bibr" rid="bib59">Hochreiter and Schmidhuber, 1997</xref>). It incorporates similar gating mechanisms as that of the GRU and can achieve the same performance in our task. We chose the GRU because it is simpler than the LSTM and it turned out sufficient.</p></sec><sec id="s4-2-2"><title>Without gating</title><p>Removing the gating mechanism from the gated recurrent network is equivalent to setting the above variables <inline-formula><mml:math id="inf23"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>r</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula> equal to 1 and <inline-formula><mml:math id="inf24"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>z</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula> equal to 0. This simplifies the calculation of the activations to a single equation, which boils down to a weighted sum of the input and the recurrent units’ activity before applying a non-linearity, as follows:<disp-formula id="equ4"><mml:math id="m4"><mml:mrow><mml:msub><mml:mi>h</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>t</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mrow><mml:mi mathvariant="normal">t</mml:mi><mml:mi mathvariant="normal">a</mml:mi><mml:mi mathvariant="normal">n</mml:mi><mml:mi mathvariant="normal">h</mml:mi></mml:mrow><mml:mrow><mml:mo>[</mml:mo><mml:mrow><mml:msub><mml:mi>w</mml:mi><mml:mrow><mml:mi>x</mml:mi><mml:mi>h</mml:mi><mml:mo>,</mml:mo><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:msub><mml:mi>x</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mi>b</mml:mi><mml:mrow><mml:mi>x</mml:mi><mml:mi>h</mml:mi><mml:mo>,</mml:mo><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mi>w</mml:mi><mml:mrow><mml:mi>h</mml:mi><mml:mi>h</mml:mi><mml:mo>,</mml:mo><mml:mi>i</mml:mi><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:msub><mml:mi>h</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:munder><mml:mo movablelimits="false">∑</mml:mo><mml:mrow><mml:mi>j</mml:mi><mml:mo>≠</mml:mo><mml:mi>i</mml:mi></mml:mrow></mml:munder><mml:mrow><mml:msub><mml:mi>w</mml:mi><mml:mrow><mml:mi>h</mml:mi><mml:mi>h</mml:mi><mml:mo>,</mml:mo><mml:mi>j</mml:mi><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:msub><mml:mi>h</mml:mi><mml:mrow><mml:mi>j</mml:mi><mml:mo>,</mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mi>b</mml:mi><mml:mrow><mml:mi>h</mml:mi><mml:mi>h</mml:mi><mml:mo>,</mml:mo><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mrow><mml:mo>]</mml:mo></mml:mrow></mml:mrow></mml:math></disp-formula></p><p>Another possibility (not considered here) would be to set the value of <inline-formula><mml:math id="inf25"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>z</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula> to a constant other than 1 and treat this value (which amounts to a time constant) as a hyperparameter.</p></sec><sec id="s4-2-3"><title>Without lateral connections</title><p>Removing lateral connections from the gated recurrent network is equivalent to setting the weights <inline-formula><mml:math id="inf26"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>w</mml:mi><mml:mrow><mml:mi>h</mml:mi><mml:mi>r</mml:mi><mml:mo>,</mml:mo><mml:mi>j</mml:mi><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula>, <inline-formula><mml:math id="inf27"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>w</mml:mi><mml:mrow><mml:mi>h</mml:mi><mml:mi>z</mml:mi><mml:mo>,</mml:mo><mml:mi>j</mml:mi><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula>, and <inline-formula><mml:math id="inf28"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>w</mml:mi><mml:mrow><mml:mi>h</mml:mi><mml:mi>h</mml:mi><mml:mo>,</mml:mo><mml:mi>j</mml:mi><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula> to 0 for all <inline-formula><mml:math id="inf29"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>j</mml:mi><mml:mo>≠</mml:mo><mml:mi>i</mml:mi></mml:mrow></mml:mstyle></mml:math></inline-formula>. This abolishes the possibility of interaction between recurrent units, which simplifies the calculation of the activations as follows:<disp-formula id="equ5"><mml:math id="m5"><mml:mrow><mml:mtable columnalign="left left" columnspacing="1em" rowspacing="4pt"><mml:mtr><mml:mtd><mml:msub><mml:mi>r</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>t</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mtd><mml:mtd><mml:mo>=</mml:mo><mml:mi>σ</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>w</mml:mi><mml:mrow><mml:mi>x</mml:mi><mml:mi>r</mml:mi><mml:mo>,</mml:mo><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:msub><mml:mi>x</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mi>b</mml:mi><mml:mrow><mml:mi>x</mml:mi><mml:mi>r</mml:mi><mml:mo>,</mml:mo><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mi>w</mml:mi><mml:mrow><mml:mi>h</mml:mi><mml:mi>r</mml:mi><mml:mo>,</mml:mo><mml:mi>i</mml:mi><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:msub><mml:mi>h</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mi>b</mml:mi><mml:mrow><mml:mi>h</mml:mi><mml:mi>r</mml:mi><mml:mo>,</mml:mo><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:msub><mml:mi>z</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>t</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mtd><mml:mtd><mml:mo>=</mml:mo><mml:mi>σ</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>w</mml:mi><mml:mrow><mml:mi>x</mml:mi><mml:mi>z</mml:mi><mml:mo>,</mml:mo><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:msub><mml:mi>x</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mi>b</mml:mi><mml:mrow><mml:mi>x</mml:mi><mml:mi>z</mml:mi><mml:mo>,</mml:mo><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mi>w</mml:mi><mml:mrow><mml:mi>h</mml:mi><mml:mi>z</mml:mi><mml:mo>,</mml:mo><mml:mi>i</mml:mi><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:msub><mml:mi>h</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mi>b</mml:mi><mml:mrow><mml:mi>h</mml:mi><mml:mi>z</mml:mi><mml:mo>,</mml:mo><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:msub><mml:mi>h</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>t</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mtd><mml:mtd><mml:mo>=</mml:mo><mml:msub><mml:mi>z</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>t</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:msub><mml:mi>h</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:msub><mml:mi>z</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>t</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:mrow><mml:mi mathvariant="normal">t</mml:mi><mml:mi mathvariant="normal">a</mml:mi><mml:mi mathvariant="normal">n</mml:mi><mml:mi mathvariant="normal">h</mml:mi></mml:mrow><mml:mo stretchy="false">[</mml:mo><mml:msub><mml:mi>w</mml:mi><mml:mrow><mml:mi>x</mml:mi><mml:mi>h</mml:mi><mml:mo>,</mml:mo><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:msub><mml:mi>x</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mi>r</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>t</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:msub><mml:mi>w</mml:mi><mml:mrow><mml:mi>h</mml:mi><mml:mi>h</mml:mi><mml:mo>,</mml:mo><mml:mi>i</mml:mi><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:msub><mml:mi>h</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mi>b</mml:mi><mml:mrow><mml:mi>h</mml:mi><mml:mi>h</mml:mi><mml:mo>,</mml:mo><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">]</mml:mo></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:math></disp-formula></p><p>Note that this architecture still contains gating. We could have tested a simpler architecture without lateral connection and without gating; however, our point is to demonstrate the specific importance of lateral connections to solve the problem we are interested in with few units, and the result is all the more convincing if the network lacking lateral connections has gating (without gating, it would fail even more dramatically).</p></sec><sec id="s4-2-4"><title>Without recurrent weight training</title><p>The networks referred to as ‘without recurrent weight training’ have the same architecture as the gated recurrent networks and differ from them only in the way they are trained. While in the other networks, all of the weights and bias parameters are trained, for those networks, only the weights and bias of the output unit, <inline-formula><mml:math id="inf30"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>w</mml:mi><mml:mrow><mml:mi>h</mml:mi><mml:mi>p</mml:mi><mml:mo>,</mml:mo><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula><inline-formula><mml:math id="inf31"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>w</mml:mi><mml:mrow><mml:mi>h</mml:mi><mml:mi>p</mml:mi><mml:mo>,</mml:mo><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula> and <inline-formula><mml:math id="inf32"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>b</mml:mi><mml:mrow><mml:mi>h</mml:mi><mml:mi>p</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula>, are trained; other weights and biases are fixed to the value drawn at initialization.</p></sec></sec><sec id="s4-3"><title>Environments</title><p>An environment is characterized by its data generating process, that is, the stochastic process used to generate a sequence of observations in that environment. Each of the generative processes is described by a graphical model in <xref ref-type="fig" rid="fig1s1">Figure 1—figure supplement 1</xref> and further detailed below.</p><sec id="s4-3-1"><title>Changing unigram environment</title><p>In the changing unigram environment, at each time step, one observation is drawn from a Bernoulli distribution whose probability parameter is the latent variable <inline-formula><mml:math id="inf33"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msubsup><mml:mi>p</mml:mi><mml:mrow><mml:mi>t</mml:mi></mml:mrow><mml:mrow><mml:mi>e</mml:mi><mml:mi>n</mml:mi><mml:mi>v</mml:mi></mml:mrow></mml:msubsup></mml:mrow></mml:mstyle></mml:math></inline-formula>. The evolution of this latent variable is described by the following stochastic process.</p><list list-type="bullet"><list-item><p>Initially, <inline-formula><mml:math id="inf34"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msubsup><mml:mi>p</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mo>=</mml:mo><mml:mn>0</mml:mn></mml:mrow><mml:mrow><mml:mi>e</mml:mi><mml:mi>n</mml:mi><mml:mi>v</mml:mi></mml:mrow></mml:msubsup></mml:mrow></mml:mstyle></mml:math></inline-formula> is drawn from a uniform distribution on [0,1].</p></list-item><list-item><p>At the next time step, with probability <inline-formula><mml:math id="inf35"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>p</mml:mi><mml:mi>c</mml:mi></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula>, <inline-formula><mml:math id="inf36"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msubsup><mml:mi>p</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>e</mml:mi><mml:mi>n</mml:mi><mml:mi>v</mml:mi></mml:mrow></mml:msubsup></mml:mrow></mml:mstyle></mml:math></inline-formula> is drawn anew from a uniform distribution on [0,1] (this event is called a 'change point'), otherwise, <inline-formula><mml:math id="inf37"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msubsup><mml:mi>p</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>e</mml:mi><mml:mi>n</mml:mi><mml:mi>v</mml:mi></mml:mrow></mml:msubsup></mml:mrow></mml:mstyle></mml:math></inline-formula> remains equal to <inline-formula><mml:math id="inf38"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msubsup><mml:mi>p</mml:mi><mml:mrow><mml:mi>t</mml:mi></mml:mrow><mml:mrow><mml:mi>e</mml:mi><mml:mi>n</mml:mi><mml:mi>v</mml:mi></mml:mrow></mml:msubsup></mml:mrow></mml:mstyle></mml:math></inline-formula>. The change point probability <inline-formula><mml:math id="inf39"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>p</mml:mi><mml:mrow><mml:mi>c</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula> is fixed in a given environment.</p></list-item></list></sec><sec id="s4-3-2"><title>Changing bigram environments</title><p>In the changing bigram environments, at each time step, one observation is drawn from a Bernoulli distribution whose probability parameter is either equal to the latent variable <inline-formula><mml:math id="inf40"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msubsup><mml:mi>p</mml:mi><mml:mrow><mml:mn>1</mml:mn><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mi>t</mml:mi></mml:mrow><mml:mrow><mml:mi>e</mml:mi><mml:mi>n</mml:mi><mml:mi>v</mml:mi></mml:mrow></mml:msubsup></mml:mrow></mml:mstyle></mml:math></inline-formula>, if the previous observation was equal to 1, or to the latent variable <inline-formula><mml:math id="inf41"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:msubsup><mml:mi>p</mml:mi><mml:mrow><mml:mn>0</mml:mn><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:mi>t</mml:mi></mml:mrow><mml:mrow><mml:mi>e</mml:mi><mml:mi>n</mml:mi><mml:mi>v</mml:mi></mml:mrow></mml:msubsup><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mstyle></mml:math></inline-formula> otherwise (at t = 0, the previous observation is considered to be equal to 0). The evolution of those latent variables is described by a stochastic process which differs depending on whether the change points are independent or coupled.</p><list list-type="bullet"><list-item><p>In both cases, initially, <inline-formula><mml:math id="inf42"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msubsup><mml:mi>p</mml:mi><mml:mrow><mml:mn>0</mml:mn><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:mi>t</mml:mi><mml:mo>=</mml:mo><mml:mn>0</mml:mn></mml:mrow><mml:mrow><mml:mi>e</mml:mi><mml:mi>n</mml:mi><mml:mi>v</mml:mi></mml:mrow></mml:msubsup></mml:mrow></mml:mstyle></mml:math></inline-formula> and <inline-formula><mml:math id="inf43"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msubsup><mml:mi>p</mml:mi><mml:mrow><mml:mn>1</mml:mn><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mi>t</mml:mi><mml:mo>=</mml:mo><mml:mn>0</mml:mn></mml:mrow><mml:mrow><mml:mi>e</mml:mi><mml:mi>n</mml:mi><mml:mi>v</mml:mi></mml:mrow></mml:msubsup></mml:mrow></mml:mstyle></mml:math></inline-formula> are both drawn independently from a uniform distribution on [0,1].</p></list-item><list-item><p>In the case of <italic>independent change points</italic>, at the next time step, with probability <inline-formula><mml:math id="inf44"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>p</mml:mi><mml:mi>c</mml:mi></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula>, <inline-formula><mml:math id="inf45"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msubsup><mml:mi>p</mml:mi><mml:mrow><mml:mn>0</mml:mn><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:mi>t</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>e</mml:mi><mml:mi>n</mml:mi><mml:mi>v</mml:mi></mml:mrow></mml:msubsup></mml:mrow></mml:mstyle></mml:math></inline-formula> is drawn anew from a uniform distribution on [0,1], otherwise, <inline-formula><mml:math id="inf46"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msubsup><mml:mi>p</mml:mi><mml:mrow><mml:mn>0</mml:mn><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:mi>t</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>e</mml:mi><mml:mi>n</mml:mi><mml:mi>v</mml:mi></mml:mrow></mml:msubsup></mml:mrow></mml:mstyle></mml:math></inline-formula> remains equal to <inline-formula><mml:math id="inf47"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msubsup><mml:mi>p</mml:mi><mml:mrow><mml:mn>0</mml:mn><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:mi>t</mml:mi></mml:mrow><mml:mrow><mml:mi>e</mml:mi><mml:mi>n</mml:mi><mml:mi>v</mml:mi></mml:mrow></mml:msubsup></mml:mrow></mml:mstyle></mml:math></inline-formula>. Similarly, <inline-formula><mml:math id="inf48"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msubsup><mml:mi>p</mml:mi><mml:mrow><mml:mn>1</mml:mn><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mi>t</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>e</mml:mi><mml:mi>n</mml:mi><mml:mi>v</mml:mi></mml:mrow></mml:msubsup></mml:mrow></mml:mstyle></mml:math></inline-formula> is either drawn anew with probability <inline-formula><mml:math id="inf49"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>p</mml:mi><mml:mrow><mml:mi>c</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula> or remains equal to <inline-formula><mml:math id="inf50"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msubsup><mml:mi>p</mml:mi><mml:mrow><mml:mn>1</mml:mn><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mi>t</mml:mi></mml:mrow><mml:mrow><mml:mi>e</mml:mi><mml:mi>n</mml:mi><mml:mi>v</mml:mi></mml:mrow></mml:msubsup></mml:mrow></mml:mstyle></mml:math></inline-formula><inline-formula><mml:math id="inf51"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msubsup><mml:mi>p</mml:mi><mml:mrow><mml:mn>1</mml:mn><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mi>t</mml:mi></mml:mrow><mml:mrow><mml:mi>e</mml:mi><mml:mi>n</mml:mi><mml:mi>v</mml:mi></mml:mrow></mml:msubsup></mml:mrow></mml:mstyle></mml:math></inline-formula> otherwise, and critically, the occurrence of a change point in <inline-formula><mml:math id="inf52"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msubsup><mml:mi>p</mml:mi><mml:mrow><mml:mn>1</mml:mn><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>e</mml:mi><mml:mi>n</mml:mi><mml:mi>v</mml:mi></mml:mrow></mml:msubsup></mml:mrow></mml:mstyle></mml:math></inline-formula> is independent from the occurrence of a change point in <inline-formula><mml:math id="inf53"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msubsup><mml:mi>p</mml:mi><mml:mrow><mml:mn>0</mml:mn><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mn>0</mml:mn></mml:mrow><mml:mrow><mml:mi>e</mml:mi><mml:mi>n</mml:mi><mml:mi>v</mml:mi></mml:mrow></mml:msubsup></mml:mrow></mml:mstyle></mml:math></inline-formula>.</p></list-item><list-item><p>In the case of <italic>coupled change points</italic>, at the next time step, with probability <inline-formula><mml:math id="inf54"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>p</mml:mi><mml:mi>c</mml:mi></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula>, <inline-formula><mml:math id="inf55"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msubsup><mml:mi>p</mml:mi><mml:mrow><mml:mn>0</mml:mn><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:mi>t</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>e</mml:mi><mml:mi>n</mml:mi><mml:mi>v</mml:mi></mml:mrow></mml:msubsup></mml:mrow></mml:mstyle></mml:math></inline-formula> and <inline-formula><mml:math id="inf56"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msubsup><mml:mi>p</mml:mi><mml:mrow><mml:mn>1</mml:mn><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mi>t</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>e</mml:mi><mml:mi>n</mml:mi><mml:mi>v</mml:mi></mml:mrow></mml:msubsup></mml:mrow></mml:mstyle></mml:math></inline-formula> are both drawn anew and independently from a uniform distribution on [0,1], otherwise, both remain equal to <inline-formula><mml:math id="inf57"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msubsup><mml:mi>p</mml:mi><mml:mrow><mml:mn>0</mml:mn><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:mi>t</mml:mi></mml:mrow><mml:mrow><mml:mi>e</mml:mi><mml:mi>n</mml:mi><mml:mi>v</mml:mi></mml:mrow></mml:msubsup></mml:mrow></mml:mstyle></mml:math></inline-formula> and <inline-formula><mml:math id="inf58"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msubsup><mml:mi>p</mml:mi><mml:mrow><mml:mn>1</mml:mn><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mi>t</mml:mi></mml:mrow><mml:mrow><mml:mi>e</mml:mi><mml:mi>n</mml:mi><mml:mi>v</mml:mi></mml:mrow></mml:msubsup></mml:mrow></mml:mstyle></mml:math></inline-formula> respectively.</p></list-item></list><p>The changing bigram environment with independent change points and that with coupled change points constitute two distinct environments. When the type of change points is not explicitly mentioned, the default case is independent change points. For conciseness, we sometimes refer to the changing unigram and changing bigram environments simply as ‘unigram’ and ‘bigram’ environments.</p><p>In all environments, unless otherwise stated, the length of a sequence is <inline-formula><mml:math id="inf59"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>T</mml:mi><mml:mo>=</mml:mo><mml:mn>380</mml:mn></mml:mrow></mml:mstyle></mml:math></inline-formula> observations, and the change point probability is <inline-formula><mml:math id="inf60"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>p</mml:mi><mml:mrow><mml:mi>c</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mn>75</mml:mn></mml:mfrac></mml:mrow></mml:mstyle></mml:math></inline-formula>, as in previous experiments done with human participants (<xref ref-type="bibr" rid="bib56">Heilbron and Meyniel, 2019</xref>; <xref ref-type="bibr" rid="bib91">Meyniel et al., 2015</xref>).</p></sec></sec><sec id="s4-4"><title>Optimal solution</title><p>For a given environment among the three possibilities defined above, the optimal solution to the prediction problem can be determined as detailed in <xref ref-type="bibr" rid="bib56">Heilbron and Meyniel, 2019</xref>. This solution consists in inverting the data-generating process of the environment using Bayesian inference, that is, computing the posterior probability distribution over the values of the latent variables given the history of observation values, and then marginalizing over that distribution to compute the prediction (which is the probability of the next observation given the history of observations). This can be done using a hidden Markov model formulation of the data-generating process where the hidden state includes the values of the latent variables as well as the previous observation in the bigram case, and using the forward algorithm to compute the posterior distribution over the hidden state. Because it would be impossible to compute the probabilities for the infinitely many possible values of the latent variables in the continuous interval [0,1], we discretized the interval into 20 equal-width bins for each of the latent variables. For a more exhaustive treatment, see <xref ref-type="bibr" rid="bib56">Heilbron and Meyniel, 2019</xref> and the online code (<ext-link ext-link-type="uri" xlink:href="https://github.com/florentmeyniel/TransitionProbModel">https://github.com/florentmeyniel/TransitionProbModel</ext-link>).</p></sec><sec id="s4-5"><title>Heuristic solutions</title><p>The four heuristic solutions used here can be classified into 2 × 2 groups depending on:</p><list list-type="bullet"><list-item><p>which kind of variables are estimated: a <italic>unigram probability</italic> or two <italic>bigram probabilities</italic>.</p></list-item><list-item><p>which heuristic rule is used in the calculation of the estimates: the <italic>delta-rule</italic> or the <italic>leaky rule</italic>.</p></list-item></list><p>The equations used to calculate the estimates are provided below.</p><list list-type="bullet"><list-item><p><italic>Unigram, delta-rule</italic>:</p></list-item><list-item><p><inline-formula><mml:math id="inf61"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mtable columnalign="left left" columnspacing="1em" rowspacing="4pt"><mml:mtr><mml:mtd><mml:mrow><mml:msub><mml:mrow><mml:mover><mml:mi>p</mml:mi><mml:mo>^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>t</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:mtd><mml:mtd><mml:mo>=</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mover><mml:mi>p</mml:mi><mml:mo>^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>+</mml:mo><mml:mi>α</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>−</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mover><mml:mi>p</mml:mi><mml:mo>^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mrow><mml:msub><mml:mrow><mml:mover><mml:mi>p</mml:mi><mml:mo>^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>t</mml:mi><mml:mo>=</mml:mo><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:mtd><mml:mtd><mml:mo>=</mml:mo><mml:mn>0.5</mml:mn></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:mstyle></mml:math></inline-formula></p></list-item><list-item><p><italic>Unigram, leaky rule</italic>:</p></list-item><list-item><p><inline-formula><mml:math id="inf62"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mtable columnalign="right left" columnspacing="1em" rowspacing="4pt"><mml:mtr><mml:mtd><mml:msub><mml:mi>n</mml:mi><mml:mrow><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:mi>t</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mtd><mml:mtd><mml:mo>=</mml:mo><mml:mi>α</mml:mi><mml:msub><mml:mi>n</mml:mi><mml:mrow><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:msub><mml:mi>n</mml:mi><mml:mrow><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mi>t</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mtd><mml:mtd><mml:mo>=</mml:mo><mml:mi>α</mml:mi><mml:msub><mml:mi>n</mml:mi><mml:mrow><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:msub><mml:mi>n</mml:mi><mml:mrow><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:mi>t</mml:mi><mml:mo>=</mml:mo><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mtd><mml:mtd><mml:mo>=</mml:mo><mml:msub><mml:mi>n</mml:mi><mml:mrow><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mi>t</mml:mi><mml:mo>=</mml:mo><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mn>0</mml:mn></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mrow><mml:msub><mml:mrow><mml:mover><mml:mi>p</mml:mi><mml:mo>^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mtd><mml:mtd><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:msub><mml:mi>n</mml:mi><mml:mrow><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:msub><mml:mi>n</mml:mi><mml:mrow><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mi>n</mml:mi><mml:mrow><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:mn>2</mml:mn></mml:mrow></mml:mfrac></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:mstyle></mml:math></inline-formula></p></list-item><list-item><p><italic>Bigrams, delta-rule</italic>:</p></list-item><list-item><p><inline-formula><mml:math id="inf63"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mtable columnalign="left left" columnspacing="1em" rowspacing="4pt"><mml:mtr><mml:mtd><mml:mrow><mml:msub><mml:mrow><mml:mover><mml:mi>p</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mn>0</mml:mn><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:mi>t</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:mtd><mml:mtd><mml:mo>=</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mover><mml:mi>p</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mn>0</mml:mn><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>+</mml:mo><mml:mi>α</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>−</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mover><mml:mi>p</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mn>0</mml:mn><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mrow><mml:msub><mml:mrow><mml:mover><mml:mi>p</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mn>1</mml:mn><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mi>t</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:mtd><mml:mtd><mml:mo>=</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mover><mml:mi>p</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mn>1</mml:mn><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>+</mml:mo><mml:mi>α</mml:mi><mml:msub><mml:mi>x</mml:mi><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>−</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mover><mml:mi>p</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mn>1</mml:mn><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mrow><mml:msub><mml:mrow><mml:mover><mml:mi>p</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mn>0</mml:mn><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:mi>t</mml:mi><mml:mo>=</mml:mo><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:mtd><mml:mtd><mml:mo>=</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mover><mml:mi>p</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mn>1</mml:mn><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mi>t</mml:mi><mml:mo>=</mml:mo><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mrow><mml:mo>=</mml:mo><mml:mn>0.5</mml:mn></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:mstyle></mml:math></inline-formula></p></list-item><list-item><p><italic>Bigrams, leaky rule</italic>:</p></list-item><list-item><p><inline-formula><mml:math id="inf64"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mtable columnalign="right left" columnspacing="1em" rowspacing="4pt"><mml:mtr><mml:mtd><mml:msub><mml:mi>n</mml:mi><mml:mrow><mml:mn>0</mml:mn><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:mi>t</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mtd><mml:mtd><mml:mo>=</mml:mo><mml:mi>α</mml:mi><mml:msub><mml:mi>n</mml:mi><mml:mrow><mml:mrow><mml:mn>0</mml:mn><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:msub><mml:mi>n</mml:mi><mml:mrow><mml:mn>1</mml:mn><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:mi>t</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mtd><mml:mtd><mml:mo>=</mml:mo><mml:mi>α</mml:mi><mml:msub><mml:mi>n</mml:mi><mml:mrow><mml:mrow><mml:mn>1</mml:mn><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:msub><mml:mi>n</mml:mi><mml:mrow><mml:mn>0</mml:mn><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mi>t</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mtd><mml:mtd><mml:mo>=</mml:mo><mml:mi>α</mml:mi><mml:msub><mml:mi>n</mml:mi><mml:mrow><mml:mn>0</mml:mn><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:msub><mml:mi>n</mml:mi><mml:mrow><mml:mn>1</mml:mn><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mi>t</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mtd><mml:mtd><mml:mo>=</mml:mo><mml:mi>α</mml:mi><mml:msub><mml:mi>n</mml:mi><mml:mrow><mml:mn>1</mml:mn><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:msub><mml:mi>x</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:msub><mml:mi>n</mml:mi><mml:mrow><mml:mn>0</mml:mn><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:mi>t</mml:mi><mml:mo>=</mml:mo><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mtd><mml:mtd><mml:mo>=</mml:mo><mml:msub><mml:mi>n</mml:mi><mml:mrow><mml:mn>1</mml:mn><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:mi>t</mml:mi><mml:mo>=</mml:mo><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:msub><mml:mi>n</mml:mi><mml:mrow><mml:mn>0</mml:mn><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mi>t</mml:mi><mml:mo>=</mml:mo><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:msub><mml:mi>n</mml:mi><mml:mrow><mml:mn>1</mml:mn><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mi>t</mml:mi><mml:mo>=</mml:mo><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mn>0</mml:mn></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mrow><mml:msub><mml:mrow><mml:mover><mml:mi>p</mml:mi><mml:mo>^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mn>0</mml:mn><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mtd><mml:mtd><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:msub><mml:mi>n</mml:mi><mml:mrow><mml:mn>0</mml:mn><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:msub><mml:mi>n</mml:mi><mml:mrow><mml:mn>0</mml:mn><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mi>n</mml:mi><mml:mrow><mml:mn>1</mml:mn><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:mn>2</mml:mn></mml:mrow></mml:mfrac></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mrow><mml:msub><mml:mrow><mml:mover><mml:mi>p</mml:mi><mml:mo>^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mn>1</mml:mn><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mtd><mml:mtd><mml:mo>=</mml:mo><mml:mfrac><mml:msub><mml:mi>n</mml:mi><mml:mrow><mml:mn>1</mml:mn><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mi>t</mml:mi><mml:mo>+</mml:mo><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:mrow><mml:msub><mml:mi>n</mml:mi><mml:mrow><mml:mn>1</mml:mn><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mi>n</mml:mi><mml:mrow><mml:mn>0</mml:mn><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:mn>2</mml:mn></mml:mrow></mml:mfrac></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:mstyle></mml:math></inline-formula></p></list-item></list><p>The delta-rule corresponds to the update rule of the Rescorla-Wagner model (<xref ref-type="bibr" rid="bib110">Rescorla and Wagner, 1972</xref>). The leaky rule corresponds to the mean of an approximate posterior which is a Beta distribution whose parameters depend on the leaky counts of observations: <inline-formula><mml:math id="inf65"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>n</mml:mi><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:mstyle></mml:math></inline-formula> and <inline-formula><mml:math id="inf66"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>n</mml:mi><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:mstyle></mml:math></inline-formula> (see <xref ref-type="bibr" rid="bib92">Meyniel et al., 2016</xref> for more details).</p><p>The output prediction value is equal to <inline-formula><mml:math id="inf67"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mover><mml:mi>p</mml:mi><mml:mo>^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mrow></mml:mstyle></mml:math></inline-formula> in the unigram case, and in the bigram case, to <inline-formula><mml:math id="inf68"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mrow><mml:mover><mml:mi>p</mml:mi><mml:mo>^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mn>1</mml:mn><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula> if <inline-formula><mml:math id="inf69"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>x</mml:mi><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:mstyle></mml:math></inline-formula> and <inline-formula><mml:math id="inf70"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:msub><mml:mrow><mml:mover><mml:mi>p</mml:mi><mml:mo>^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mn>0</mml:mn><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mstyle></mml:math></inline-formula> otherwise. The parameter <inline-formula><mml:math id="inf71"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>α</mml:mi></mml:mrow></mml:mstyle></mml:math></inline-formula> is a free parameter which is trained (using the same training data as the networks) and thus adjusted to the training environment.</p></sec><sec id="s4-6"><title>Training</title><p>For a given environment and a given type of agent among the network types and heuristic types, all the reported results are based on 20 agents, each sharing the same set of hyperparameters and initialized with a different random seed. During training, the parameters of a given agent were adjusted to minimize the binary cross-entropy cost function (see <xref ref-type="disp-formula" rid="equ1">Equation 1</xref>). During one iteration of training, the gradients of the cost function with respect to the parameters are computed on a subset of the training data (called a minibatch) using backpropagation through time and are used to update the parameters according to the selected training algorithm. The training algorithm was Adam (<xref ref-type="bibr" rid="bib70">Kingma and Ba, 2015</xref>) for the network types and stochastic gradient descent for the heuristic types.</p><p>For the unigram environment, the analyses reported in <xref ref-type="fig" rid="fig2">Figures 2</xref>—<xref ref-type="fig" rid="fig5">5</xref> were conducted after training on a common training dataset of 160 minibatches of 20 sequences. For each of the two bigram environments, the analyses reported in <xref ref-type="fig" rid="fig6">Figures 6</xref>–<xref ref-type="fig" rid="fig7">7</xref> were conducted after training on a common training dataset (one per environment) of 400 minibatches of 20 sequences. These sizes were sufficient for the validation performance to converge before the end of training for all types of agents.</p></sec><sec id="s4-7"><title>Parameters initialization</title><p>For all of the networks, the bias parameters are randomly initialized from a uniform distribution on <inline-formula><mml:math id="inf72"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mo stretchy="false">[</mml:mo><mml:mo>−</mml:mo><mml:mn>1</mml:mn><mml:mrow><mml:mo>/</mml:mo></mml:mrow><mml:msqrt><mml:mi>N</mml:mi></mml:msqrt><mml:mo>,</mml:mo><mml:mo>+</mml:mo><mml:mn>1</mml:mn><mml:mrow><mml:mo>/</mml:mo></mml:mrow><mml:msqrt><mml:mi>N</mml:mi></mml:msqrt><mml:mo stretchy="false">]</mml:mo></mml:mrow></mml:mstyle></mml:math></inline-formula> and the weights <inline-formula><mml:math id="inf73"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>w</mml:mi><mml:mrow><mml:mi>h</mml:mi><mml:mi>p</mml:mi><mml:mo>,</mml:mo><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula> are randomly initialized from a normal distribution with standard deviation <inline-formula><mml:math id="inf74"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mn>1</mml:mn><mml:mrow><mml:mo>/</mml:mo></mml:mrow><mml:msqrt><mml:mi>N</mml:mi></mml:msqrt></mml:mrow></mml:mstyle></mml:math></inline-formula> and mean 0. For all the networks, the weights <inline-formula><mml:math id="inf75"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>w</mml:mi><mml:mrow><mml:mi>x</mml:mi><mml:mi>r</mml:mi><mml:mo>,</mml:mo><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula>, <inline-formula><mml:math id="inf76"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>w</mml:mi><mml:mrow><mml:mi>x</mml:mi><mml:mi>z</mml:mi><mml:mo>,</mml:mo><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula>, <inline-formula><mml:math id="inf77"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>w</mml:mi><mml:mrow><mml:mi>x</mml:mi><mml:mi>h</mml:mi><mml:mo>,</mml:mo><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula> are randomly initialized from a normal distribution with standard deviation <inline-formula><mml:math id="inf78"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>σ</mml:mi><mml:mrow><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:mi>x</mml:mi><mml:mo>⋅</mml:mo></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula> and mean 0, and the weights <inline-formula><mml:math id="inf79"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>w</mml:mi><mml:mrow><mml:mi>h</mml:mi><mml:mi>r</mml:mi><mml:mo>,</mml:mo><mml:mi>j</mml:mi><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>w</mml:mi><mml:mrow><mml:mi>h</mml:mi><mml:mi>z</mml:mi><mml:mo>,</mml:mo><mml:mi>j</mml:mi><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>w</mml:mi><mml:mrow><mml:mi>h</mml:mi><mml:mi>h</mml:mi><mml:mo>,</mml:mo><mml:mi>j</mml:mi><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula> are randomly initialized from a normal distribution with standard deviation <inline-formula><mml:math id="inf80"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>σ</mml:mi><mml:mrow><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:mi>h</mml:mi><mml:mo>⋅</mml:mo></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula> and mean 0 for all <inline-formula><mml:math id="inf81"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>j</mml:mi><mml:mo>≠</mml:mo><mml:mi>i</mml:mi></mml:mrow></mml:mstyle></mml:math></inline-formula> and <inline-formula><mml:math id="inf82"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>μ</mml:mi><mml:mrow><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:mi>h</mml:mi><mml:mo>.</mml:mo><mml:mo>,</mml:mo><mml:mi>i</mml:mi><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula> for <inline-formula><mml:math id="inf83"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>j</mml:mi><mml:mo>=</mml:mo><mml:mi>i</mml:mi></mml:mrow></mml:mstyle></mml:math></inline-formula>. <inline-formula><mml:math id="inf84"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>σ</mml:mi><mml:mrow><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:mi>x</mml:mi><mml:mo>⋅</mml:mo></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>σ</mml:mi><mml:mrow><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:mi>h</mml:mi><mml:mo>⋅</mml:mo></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>μ</mml:mi><mml:mrow><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:mi>h</mml:mi><mml:mo>⋅</mml:mo><mml:mo>,</mml:mo><mml:mtext> </mml:mtext><mml:mi>i</mml:mi><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula> are hyperparameters that were optimized for a given environment, type of network, and number of units as detailed in the hyperparameter optimization section (the values resulting from this optimization are listed in <xref ref-type="table" rid="table1">Table 1</xref>).</p><table-wrap id="table1" position="float"><label>Table 1.</label><caption><title>Selected hyperparameter values after optimization.</title><p>(*: fixed value.)</p></caption><table frame="hsides" rules="groups"><thead><tr><th align="left" valign="bottom">Environment</th><th align="left" valign="bottom">Network architecture</th><th align="left" valign="bottom">N</th><th align="left" valign="bottom"><inline-formula><mml:math id="inf85"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>η</mml:mi><mml:mn>0</mml:mn></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula></th><th align="left" valign="bottom"><inline-formula><mml:math id="inf86"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>σ</mml:mi><mml:mrow><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:mi>x</mml:mi><mml:mo>⋅</mml:mo></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula></th><th align="left" valign="bottom"><inline-formula><mml:math id="inf87"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>σ</mml:mi><mml:mrow><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:mi>h</mml:mi><mml:mo>⋅</mml:mo></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula></th><th align="left" valign="bottom"><inline-formula><mml:math id="inf88"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>μ</mml:mi><mml:mrow><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:mi>h</mml:mi><mml:mo>⋅</mml:mo><mml:mo>,</mml:mo><mml:mi>i</mml:mi><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula></th></tr></thead><tbody><tr><td align="left" valign="bottom">unigram</td><td align="left" valign="bottom">gated recurrent network</td><td align="char" char="." valign="bottom">3</td><td align="char" char="hyphen" valign="bottom">8.00E-02</td><td align="char" char="." valign="bottom">0.02</td><td align="char" char="." valign="bottom">0.02</td><td align="char" char="." valign="bottom">0*</td></tr><tr><td align="left" valign="bottom">unigram</td><td align="left" valign="bottom">gated recurrent network</td><td align="char" char="." valign="bottom">11</td><td align="char" char="hyphen" valign="bottom">6.60E-02</td><td align="char" char="." valign="bottom">0.43</td><td align="char" char="." valign="bottom">0.21</td><td align="char" char="." valign="bottom">0*</td></tr><tr><td align="left" valign="bottom">unigram</td><td align="left" valign="bottom">gated recurrent network</td><td align="char" char="." valign="bottom">45</td><td align="char" char="hyphen" valign="bottom">4.20E-02</td><td align="char" char="." valign="bottom">1</td><td align="char" char="." valign="bottom">0.02</td><td align="char" char="." valign="bottom">0*</td></tr><tr><td align="left" valign="bottom">unigram</td><td align="left" valign="bottom">without gating</td><td align="char" char="." valign="bottom">3</td><td align="char" char="hyphen" valign="bottom">2.50E-02</td><td align="char" char="." valign="bottom">1</td><td align="char" char="." valign="bottom">0.07</td><td align="char" char="." valign="bottom">0*</td></tr><tr><td align="left" valign="bottom">unigram</td><td align="left" valign="bottom">without gating</td><td align="char" char="." valign="bottom">11</td><td align="char" char="hyphen" valign="bottom">1.70E-02</td><td align="char" char="." valign="bottom">1</td><td align="char" char="." valign="bottom">0.07</td><td align="char" char="." valign="bottom">0*</td></tr><tr><td align="left" valign="bottom">unigram</td><td align="left" valign="bottom">without gating</td><td align="char" char="." valign="bottom">45</td><td align="char" char="hyphen" valign="bottom">7.60E-03</td><td align="char" char="." valign="bottom">1</td><td align="char" char="." valign="bottom">0.08</td><td align="char" char="." valign="bottom">0*</td></tr><tr><td align="left" valign="bottom">unigram</td><td align="left" valign="bottom">without gating</td><td align="char" char="." valign="bottom">1,000</td><td align="char" char="hyphen" valign="bottom">1.34E-04</td><td align="char" char="." valign="bottom">1</td><td align="char" char="." valign="bottom">0.04</td><td align="char" char="." valign="bottom">0*</td></tr><tr><td align="left" valign="bottom">unigram</td><td align="left" valign="bottom">without lateral connections</td><td align="char" char="." valign="bottom">3</td><td align="char" char="hyphen" valign="bottom">5.30E-02</td><td align="char" char="." valign="bottom">0.02</td><td align="char" char="." valign="bottom">0.02</td><td align="char" char="." valign="bottom">1</td></tr><tr><td align="left" valign="bottom">unigram</td><td align="left" valign="bottom">without lateral connections</td><td align="char" char="." valign="bottom">11</td><td align="char" char="hyphen" valign="bottom">2.70E-02</td><td align="char" char="." valign="bottom">1</td><td align="char" char="." valign="bottom">0.02</td><td align="char" char="." valign="bottom">1</td></tr><tr><td align="left" valign="bottom">unigram</td><td align="left" valign="bottom">without lateral connections</td><td align="char" char="." valign="bottom">45</td><td align="char" char="hyphen" valign="bottom">1.30E-02</td><td align="char" char="." valign="bottom">1</td><td align="char" char="." valign="bottom">1</td><td align="char" char="." valign="bottom">1</td></tr><tr><td align="left" valign="bottom">unigram</td><td align="left" valign="bottom">without recurrent weight training</td><td align="char" char="." valign="bottom">3</td><td align="char" char="hyphen" valign="bottom">1.00E-01</td><td align="char" char="." valign="bottom">1.07</td><td align="char" char="." valign="bottom">0.55</td><td align="char" char="." valign="bottom">0*</td></tr><tr><td align="left" valign="bottom">unigram</td><td align="left" valign="bottom">without recurrent weight training</td><td align="char" char="." valign="bottom">11</td><td align="char" char="hyphen" valign="bottom">1.00E-01</td><td align="char" char="." valign="bottom">2</td><td align="char" char="." valign="bottom">0.41</td><td align="char" char="." valign="bottom">0*</td></tr><tr><td align="left" valign="bottom">unigram</td><td align="left" valign="bottom">without recurrent weight training</td><td align="char" char="." valign="bottom">45</td><td align="char" char="hyphen" valign="bottom">1.00E-01</td><td align="char" char="." valign="bottom">2</td><td align="char" char="." valign="bottom">0.26</td><td align="char" char="." valign="bottom">0*</td></tr><tr><td align="left" valign="bottom">unigram</td><td align="left" valign="bottom">without recurrent weight training</td><td align="char" char="." valign="bottom">474</td><td align="char" char="hyphen" valign="bottom">9.60E-03</td><td align="char" char="." valign="bottom">1</td><td align="char" char="." valign="bottom">0.1</td><td align="char" char="." valign="bottom">0*</td></tr><tr><td align="left" valign="bottom">bigram</td><td align="left" valign="bottom">gated recurrent network</td><td align="char" char="." valign="bottom">3</td><td align="char" char="hyphen" valign="bottom">6.30E-02</td><td align="char" char="." valign="bottom">0.02</td><td align="char" char="." valign="bottom">1</td><td align="char" char="." valign="bottom">0*</td></tr><tr><td align="left" valign="bottom">bigram</td><td align="left" valign="bottom">gated recurrent network</td><td align="char" char="." valign="bottom">11</td><td align="char" char="hyphen" valign="bottom">4.40E-02</td><td align="char" char="." valign="bottom">1</td><td align="char" char="." valign="bottom">0.02</td><td align="char" char="." valign="bottom">0*</td></tr><tr><td align="left" valign="bottom">bigram</td><td align="left" valign="bottom">gated recurrent network</td><td align="char" char="." valign="bottom">45</td><td align="char" char="hyphen" valign="bottom">1.60E-02</td><td align="char" char="." valign="bottom">1</td><td align="char" char="." valign="bottom">0.02</td><td align="char" char="." valign="bottom">0*</td></tr><tr><td align="left" valign="bottom">bigram</td><td align="left" valign="bottom">without gating</td><td align="char" char="." valign="bottom">3</td><td align="char" char="hyphen" valign="bottom">5.50E-02</td><td align="char" char="." valign="bottom">0.02</td><td align="char" char="." valign="bottom">0.13</td><td align="char" char="." valign="bottom">0*</td></tr><tr><td align="left" valign="bottom">bigram</td><td align="left" valign="bottom">without gating</td><td align="char" char="." valign="bottom">11</td><td align="char" char="hyphen" valign="bottom">3.20E-02</td><td align="char" char="." valign="bottom">1</td><td align="char" char="." valign="bottom">0.05</td><td align="char" char="." valign="bottom">0*</td></tr><tr><td align="left" valign="bottom">bigram</td><td align="left" valign="bottom">without gating</td><td align="char" char="." valign="bottom">45</td><td align="char" char="hyphen" valign="bottom">8.90E-03</td><td align="char" char="." valign="bottom">1</td><td align="char" char="." valign="bottom">0.06</td><td align="char" char="." valign="bottom">0*</td></tr><tr><td align="left" valign="bottom">bigram</td><td align="left" valign="bottom">without gating</td><td align="char" char="." valign="bottom">1,000</td><td align="char" char="hyphen" valign="bottom">5.97E-05</td><td align="char" char="." valign="bottom">1</td><td align="char" char="." valign="bottom">0.03</td><td align="char" char="." valign="bottom">0*</td></tr><tr><td align="left" valign="bottom">bigram</td><td align="left" valign="bottom">without lateral connections</td><td align="char" char="." valign="bottom">3</td><td align="char" char="hyphen" valign="bottom">4.30E-02</td><td align="char" char="." valign="bottom">1</td><td align="char" char="." valign="bottom">0.02</td><td align="char" char="." valign="bottom">0</td></tr><tr><td align="left" valign="bottom">bigram</td><td align="left" valign="bottom">without lateral connections</td><td align="char" char="." valign="bottom">11</td><td align="char" char="hyphen" valign="bottom">4.30E-02</td><td align="char" char="." valign="bottom">1</td><td align="char" char="." valign="bottom">1</td><td align="char" char="." valign="bottom">0</td></tr><tr><td align="left" valign="bottom">bigram</td><td align="left" valign="bottom">without lateral connections</td><td align="char" char="." valign="bottom">45</td><td align="char" char="hyphen" valign="bottom">2.80E-02</td><td align="char" char="." valign="bottom">1</td><td align="char" char="." valign="bottom">1</td><td align="char" char="." valign="bottom">0</td></tr><tr><td align="left" valign="bottom">bigram</td><td align="left" valign="bottom">without recurrent weight training</td><td align="char" char="." valign="bottom">3</td><td align="char" char="hyphen" valign="bottom">6.60E-02</td><td align="char" char="." valign="bottom">0.73</td><td align="char" char="." valign="bottom">0.55</td><td align="char" char="." valign="bottom">0*</td></tr><tr><td align="left" valign="bottom">bigram</td><td align="left" valign="bottom">without recurrent weight training</td><td align="char" char="." valign="bottom">11</td><td align="char" char="hyphen" valign="bottom">1.00E-01</td><td align="char" char="." valign="bottom">2</td><td align="char" char="." valign="bottom">0.45</td><td align="char" char="." valign="bottom">0*</td></tr></tbody></table></table-wrap><p>For the initialization of the parameter <inline-formula><mml:math id="inf89"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>α</mml:mi></mml:mrow></mml:mstyle></mml:math></inline-formula> in the heuristic solutions, a random value r is drawn from a log-uniform distribution on the interval [10<sup>-2.5</sup>,10<sup>-0.5</sup>], and the initial value of <inline-formula><mml:math id="inf90"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>α</mml:mi></mml:mrow></mml:mstyle></mml:math></inline-formula> is set to r in the delta-rule case or exp(-r) in the leaky rule case.</p></sec><sec id="s4-8"><title>Hyperparameter optimization</title><p>Each type of agent had a specific set of hyperparameters to be optimized. For all network types, it included the initial learning rate of Adam <inline-formula><mml:math id="inf91"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>η</mml:mi><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula> and the initialization hyperparameters <inline-formula><mml:math id="inf92"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>σ</mml:mi><mml:mrow><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:mi>x</mml:mi><mml:mo>⋅</mml:mo></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula>, <inline-formula><mml:math id="inf93"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>σ</mml:mi><mml:mrow><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:mi>h</mml:mi><mml:mo>⋅</mml:mo></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula>. For the networks without lateral connections specifically, it also included <inline-formula><mml:math id="inf94"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>μ</mml:mi><mml:mrow><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:mi>h</mml:mi><mml:mo>.</mml:mo><mml:mo>,</mml:mo><mml:mi>i</mml:mi><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula> (for those networks, setting it close to one can help avoid the vanishing gradient problem during training <xref ref-type="bibr" rid="bib10">Bengio et al., 1994</xref>; <xref ref-type="bibr" rid="bib135">Sutskever et al., 2013</xref>) for the other networks, this was set to 0. For the heuristic types, it included only the learning rate of the stochastic gradient descent. A unique set of hyperparameter values was determined for each type of agent, each environment, and, for the network types, each number of units, through the optimization described next.</p><p>We used Bayesian optimization (<xref ref-type="bibr" rid="bib1">Agnihotri and Batra, 2020</xref>) with Gaussian processes and the upper confidence bound acquisition function to identify the best hyperparameters for each network architecture, environment, and number of units. During the optimization, combinations of hyperparameter values were iteratively sampled, each evaluated over 10 trials with different random seeds, for a total of 60 iterations (hence, 600 trials) for a given architecture, environment, and number of units. In each trial, one network was created, trained, and its cross-entropy was measured on independent test data. The training and test datasets used for the hyperparameter optimization procedure were not used in any other analyses. The training datasets contained respectively 160 and 400 minibatches of 20 sequences for the unigram and the bigram environment; the test datasets contained 200 sequences for each environment. We selected the combination of hyperparameter values corresponding to the iteration that led to the lowest mean test cross-entropy over the 10 trials. The selected values are listed in <xref ref-type="table" rid="table1">Table 1</xref>.</p><p>For the heuristic types, we used random search from a log uniform distribution in the [10<sup>–6</sup>, 10<sup>–1</sup>] range over 80 trials to determine the optimal learning rate of the stochastic gradient descent. This led to selecting the value 3.10<sup>–3</sup> for all heuristic types and all three environments.</p></sec><sec id="s4-9"><title>Performance analyses</title><p>All agents were tested in the environment they were trained in (except for <xref ref-type="fig" rid="fig6s1">Figure 6—figure supplement 1</xref> which tests cross-environment performance). We used a single test dataset per environment of 1000 sequences independent of the training dataset. The log likelihood L of a given agent was measured from its predictions according to <xref ref-type="disp-formula" rid="equ1">Equation 1</xref>. The optimal log likelihood <inline-formula><mml:math id="inf95"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>L</mml:mi><mml:mrow><mml:mi>o</mml:mi><mml:mi>p</mml:mi><mml:mi>t</mml:mi><mml:mi>i</mml:mi><mml:mi>m</mml:mi><mml:mi>a</mml:mi><mml:mi>l</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula> was measured from the predictions of the optimal solution for the given environment. The chance log likelihood <inline-formula><mml:math id="inf96"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>L</mml:mi><mml:mrow><mml:mi>c</mml:mi><mml:mi>h</mml:mi><mml:mi>a</mml:mi><mml:mi>n</mml:mi><mml:mi>c</mml:mi><mml:mi>e</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula> was measured using a constant prediction of 0.5. To facilitate the interpretation of the results, the prediction performance of the agent was expressed as the % of optimal log likelihood, defined as:<disp-formula id="equ6"><mml:math id="m6"><mml:mrow><mml:mfrac><mml:mrow><mml:mi>L</mml:mi><mml:mo>−</mml:mo><mml:msub><mml:mi>L</mml:mi><mml:mrow><mml:mi>c</mml:mi><mml:mi>h</mml:mi><mml:mi>a</mml:mi><mml:mi>n</mml:mi><mml:mi>c</mml:mi><mml:mi>e</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:msub><mml:mi>L</mml:mi><mml:mrow><mml:mi>o</mml:mi><mml:mi>p</mml:mi><mml:mi>t</mml:mi><mml:mi>i</mml:mi><mml:mi>m</mml:mi><mml:mi>a</mml:mi><mml:mi>l</mml:mi></mml:mrow></mml:msub><mml:mo>−</mml:mo><mml:msub><mml:mi>L</mml:mi><mml:mrow><mml:mi>c</mml:mi><mml:mi>h</mml:mi><mml:mi>a</mml:mi><mml:mi>n</mml:mi><mml:mi>c</mml:mi><mml:mi>e</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfrac><mml:mo>×</mml:mo><mml:mn>100</mml:mn></mml:mrow></mml:math></disp-formula></p><p>To test the statistical significance of a comparison of performance between two types of agents, we used a two-tailed two independent samples t-test with Welch’s correction for unequal variances.</p></sec><sec id="s4-10"><title>Analysis of the effective learning rate</title><p>The instantaneous effective learning rate of an agent that updates its prediction from <inline-formula><mml:math id="inf97"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>p</mml:mi><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula> to <inline-formula><mml:math id="inf98"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>p</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula> upon receiving observation <inline-formula><mml:math id="inf99"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>x</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula> is calculated as:<disp-formula id="equ7"><label>(2)</label><mml:math id="m7"><mml:mrow><mml:mtable columnalign="left left" columnspacing="1em" rowspacing="4pt"><mml:mtr><mml:mtd><mml:msub><mml:mi>α</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mtd><mml:mtd><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:msub><mml:mi>p</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>−</mml:mo><mml:msub><mml:mi>p</mml:mi><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:msub><mml:mi>x</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>−</mml:mo><mml:msub><mml:mi>p</mml:mi><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfrac></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:msub><mml:mi>α</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mo>=</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:msub></mml:mtd><mml:mtd><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:msub><mml:mi>p</mml:mi><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msub><mml:mo>−</mml:mo><mml:mn>0.5</mml:mn></mml:mrow><mml:mrow><mml:msub><mml:mi>x</mml:mi><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msub><mml:mo>−</mml:mo><mml:mn>0.5</mml:mn></mml:mrow></mml:mfrac></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:math></disp-formula></p><p>We call it ‘effective learning rate’ because, had the agent been using a delta-rule algorithm, it would be equivalent to the learning rate of the delta-rule (as can be seen by rearranging the above formula into an update equation), and because it can be measured even if the agent uses another algorithm.</p></sec><sec id="s4-11"><title>Readout analyses</title><p>The readout of a given quantity from the recurrent units of a network consists of a weighted sum of the activation values of each unit. To determine the weights of the readout for a given network, we ran a multiple linear regression using, as input variables, the activation of each recurrent unit at a given time step <inline-formula><mml:math id="inf100"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>h</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula>, and as target variable, the desired quantity calculated at the same time step. The regression was run on a training dataset of 900 sequences of 380 observations each (hence, 342,000 samples).</p><p>In the unigram environment, the precision readout was obtained using as desired quantity the log precision of the posterior distribution over the unigram variable calculated by the optimal solution as previously described, that is, <inline-formula><mml:math id="inf101"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>ψ</mml:mi><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mo>−</mml:mo><mml:mi>log</mml:mi><mml:mo>⁡</mml:mo><mml:msub><mml:mi>σ</mml:mi><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula>, where <inline-formula><mml:math id="inf102"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>σ</mml:mi><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula> is the standard deviation of the posterior distribution over <inline-formula><mml:math id="inf103"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msubsup><mml:mi>p</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>e</mml:mi><mml:mi>n</mml:mi><mml:mi>v</mml:mi></mml:mrow></mml:msubsup></mml:mrow></mml:mstyle></mml:math></inline-formula>:<disp-formula id="equ8"><label>(3)</label><mml:math id="m8"><mml:mrow><mml:msub><mml:mi>σ</mml:mi><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mrow><mml:mi mathvariant="double-struck">S</mml:mi><mml:mi mathvariant="double-struck">D</mml:mi></mml:mrow><mml:mo stretchy="false">[</mml:mo><mml:msubsup><mml:mi>p</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>e</mml:mi><mml:mi>n</mml:mi><mml:mi>v</mml:mi></mml:mrow></mml:msubsup><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:msub><mml:mi>x</mml:mi><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:mo>.</mml:mo><mml:mo>.</mml:mo><mml:mo>.</mml:mo><mml:mo>,</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">]</mml:mo></mml:mrow></mml:math></disp-formula></p><p>In the bigram environment, the readout of the estimate of a given bigram variable was obtained using as desired quantity the log odds of the mean of the posterior distribution over that bigram variable calculated by the optimal solution, and the readout of the precision of that estimate was obtained using the log precision of that same posterior under the above definition of precision.</p><p>In <xref ref-type="fig" rid="fig4">Figure 4a</xref>, to measure the accuracy of the readout from a given network, we calculated the Pearson correlation between the quantity read from the network and the optimal quantity on a test dataset of 100 sequences (hence, 38,000 samples), independent from any training dataset. To measure the Pearson correlation between the read precision and the subsequent effective learning rate, we used 300 out-of-sample sequences (hence, 114,000 samples). To measure the mutual information between the read precision and the prediction of the network, we also used 300 out-of-sample sequences (114,000 samples).</p><p>In <xref ref-type="fig" rid="fig6">Figure 6d</xref>, the log odds and log precision were transformed back into mean and standard deviation for visualization purposes.</p></sec><sec id="s4-12"><title>Dynamics of network activity in the prediction-precision subspace</title><p>In <xref ref-type="fig" rid="fig4">Figure 4b</xref>, the network activity (i.e. the population activity of the recurrent units in the network) was projected onto the two-dimensional subspace spanned by the prediction vector and the precision vector. The prediction vector is the vector of the weights from the recurrent units to the output unit of the network, <inline-formula><mml:math id="inf104"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>w</mml:mi><mml:mrow><mml:mi>h</mml:mi><mml:mi>p</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula>. The precision vector is the vector of the weights of the precision readout described above, <inline-formula><mml:math id="inf105"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>w</mml:mi><mml:mrow><mml:mi>h</mml:mi><mml:mi>ψ</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula>. For the visualization, we orthogonalized the precision vector against the prediction vector using the Gram-Schmidt process (i.e. by subtracting from the precision vector its projection onto the prediction vector), and used the orthogonalized precision vector to define the y-axis shown in <xref ref-type="fig" rid="fig4">Figure 4b</xref>.</p></sec><sec id="s4-13"><title>Perturbation experiment to test precision-weighting</title><p>The perturbation experiment reported in <xref ref-type="fig" rid="fig5">Figure 5</xref> is designed to test the causal role of the precision read from a given network on its weighting of the next observation, measured through its effective learning rate. We performed this perturbation experiment on each of the 20 networks that were trained within each of the four architectures we considered. The causal instrument is a perturbation vector q that is added to the network’s recurrent unit activations. The perturbation vector was randomly generated subject to the following constraints:</p><list list-type="bullet"><list-item><p><inline-formula><mml:math id="inf106"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>q</mml:mi><mml:mo>⋅</mml:mo><mml:msub><mml:mi>w</mml:mi><mml:mrow><mml:mi>h</mml:mi><mml:mi>ψ</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mi>δ</mml:mi><mml:mi>ψ</mml:mi></mml:mrow></mml:mstyle></mml:math></inline-formula>is the desired change in precision (we used five levels) that is read from the units’ activities; it is computed by projecting the perturbation onto the weight vector of the precision readout (<inline-formula><mml:math id="inf107"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>w</mml:mi><mml:mrow><mml:mi>h</mml:mi><mml:mi>ψ</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:mo>⋅</mml:mo></mml:mrow></mml:mstyle></mml:math></inline-formula> is the dot product);</p></list-item><list-item><p>the perturbation <inline-formula><mml:math id="inf108"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>q</mml:mi></mml:mrow></mml:mstyle></mml:math></inline-formula> induces no change in the prediction of the network: <inline-formula><mml:math id="inf109"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>q</mml:mi><mml:mo>⋅</mml:mo><mml:msub><mml:mi>w</mml:mi><mml:mrow><mml:mi>h</mml:mi><mml:mi>p</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:mstyle></mml:math></inline-formula>, where <inline-formula><mml:math id="inf110"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>w</mml:mi><mml:mrow><mml:mi>h</mml:mi><mml:mi>p</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula> is the weight vector of the output unit of the network;</p></list-item><list-item><p>the perturbation has a constant intensity c across simulations, which we formalize as the norm of the perturbation: <inline-formula><mml:math id="inf111"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mrow><mml:mo symmetric="true">‖</mml:mo><mml:mi>q</mml:mi><mml:mo symmetric="true">‖</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mi>c</mml:mi></mml:mrow></mml:mstyle></mml:math></inline-formula>.</p></list-item></list><p>We describe below the algorithm that we used to generate random perturbations <inline-formula><mml:math id="inf112"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>q</mml:mi></mml:mrow></mml:mstyle></mml:math></inline-formula> that satisfy these constraints. The idea is to decompose <inline-formula><mml:math id="inf113"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>q</mml:mi></mml:mrow></mml:mstyle></mml:math></inline-formula> into two components: both components leave the prediction unaffected, the first (<inline-formula><mml:math id="inf114"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>q</mml:mi><mml:mrow><mml:mi>ψ</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula>) is used to induce a controlled change in precision, the second (<inline-formula><mml:math id="inf115"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>q</mml:mi><mml:mrow><mml:mi>r</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula>) does not change the precision but is added to ensure a constant intensity of the perturbation across simulations.</p><list list-type="order"><list-item><p>To ensure no change in precision, we compute Q, the subspace of the activation space spanned by all vectors q that are orthogonal to the prediction weight vector <inline-formula><mml:math id="inf116"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>w</mml:mi><mml:mrow><mml:mi>h</mml:mi><mml:mi>p</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula>, as the null space of <inline-formula><mml:math id="inf117"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>w</mml:mi><mml:mrow><mml:mi>h</mml:mi><mml:mi>p</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula> (i.e. the orthogonal complement of the subspace spanned by <inline-formula><mml:math id="inf118"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>w</mml:mi><mml:mrow><mml:mi>h</mml:mi><mml:mi>p</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula>, dimension N-1).</p></list-item><list-item><p>We compute <inline-formula><mml:math id="inf119"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>q</mml:mi><mml:mrow><mml:mi>ψ</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula>, the vector component of Q that affects precision, as the orthogonal projection of <inline-formula><mml:math id="inf120"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>w</mml:mi><mml:mrow><mml:mi>h</mml:mi><mml:mi>ψ</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula> onto Q (<inline-formula><mml:math id="inf121"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>q</mml:mi><mml:mrow><mml:mi>ψ</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula> is thus collinear to the orthogonalized precision axis shown in <xref ref-type="fig" rid="fig4">Figure 4b</xref> and described above).</p></list-item><list-item><p>We compute <inline-formula><mml:math id="inf122"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>β</mml:mi><mml:mrow><mml:mi>ψ</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula>, the coefficient to assign to <inline-formula><mml:math id="inf123"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>q</mml:mi><mml:mrow><mml:mi>ψ</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula> in the perturbation vector to produce the desired change in precision <inline-formula><mml:math id="inf124"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>δ</mml:mi><mml:mi>ψ</mml:mi></mml:mrow></mml:mstyle></mml:math></inline-formula>, as <inline-formula><mml:math id="inf125"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>β</mml:mi><mml:mrow><mml:mi>ψ</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mi>δ</mml:mi><mml:mi>ψ</mml:mi></mml:mrow><mml:mrow><mml:mo fence="false" stretchy="false">‖</mml:mo><mml:msub><mml:mi>q</mml:mi><mml:mrow><mml:mi>ψ</mml:mi></mml:mrow></mml:msub><mml:mo>⋅</mml:mo><mml:msub><mml:mi>w</mml:mi><mml:mrow><mml:mi>h</mml:mi><mml:mi>ψ</mml:mi></mml:mrow></mml:msub><mml:mo fence="false" stretchy="false">‖</mml:mo></mml:mrow></mml:mfrac></mml:mrow></mml:mstyle></mml:math></inline-formula>.</p></list-item><list-item><p>We compute R, the subspace spanned by all vector components of Q that do not affect precision, as the null space of <inline-formula><mml:math id="inf126"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>q</mml:mi><mml:mrow><mml:mi>ψ</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula> (dimension N-2). A perturbation vector in R therefore leaves both the prediction and the precision unchanged.</p></list-item><list-item><p>We draw a random unit vector <inline-formula><mml:math id="inf127"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>q</mml:mi><mml:mrow><mml:mi>r</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula> within R (by drawing from all N-2 components).</p></list-item><list-item><p>We compute <inline-formula><mml:math id="inf128"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>β</mml:mi><mml:mrow><mml:mi>r</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula>, the coefficient to assign to <inline-formula><mml:math id="inf129"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>q</mml:mi><mml:mrow><mml:mi>r</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula> in the perturbation vector so as to ensure that the final perturbation’s norm equals c, as <inline-formula><mml:math id="inf130"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>β</mml:mi><mml:mrow><mml:mi>r</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:msqrt><mml:msup><mml:mi>c</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup><mml:mo>−</mml:mo><mml:msubsup><mml:mi>β</mml:mi><mml:mrow><mml:mi>ψ</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup><mml:msup><mml:mrow><mml:mo symmetric="true">‖</mml:mo><mml:msub><mml:mi>q</mml:mi><mml:mrow><mml:mi>ψ</mml:mi></mml:mrow></mml:msub><mml:mo symmetric="true">‖</mml:mo></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:msqrt></mml:mrow></mml:mstyle></mml:math></inline-formula>.</p></list-item><list-item><p>We combine <inline-formula><mml:math id="inf131"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>q</mml:mi><mml:mrow><mml:mi>ψ</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula> and <inline-formula><mml:math id="inf132"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>q</mml:mi><mml:mrow><mml:mi>r</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula> into the final perturbation vector as <inline-formula><mml:math id="inf133"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>q</mml:mi><mml:mo>=</mml:mo><mml:msub><mml:mi>β</mml:mi><mml:mrow><mml:mi>ψ</mml:mi></mml:mrow></mml:msub><mml:msub><mml:mi>q</mml:mi><mml:mrow><mml:mi>ψ</mml:mi></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mi>β</mml:mi><mml:mrow><mml:mi>r</mml:mi></mml:mrow></mml:msub><mml:msub><mml:mi>q</mml:mi><mml:mrow><mml:mi>r</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula>.</p></list-item></list><p>The experiment was run on a set of 1000 sample time points randomly drawn from 300 sequences. First, the unperturbed learning rate was measured by running the network on all of the sequences. Second, for each sample time point, the network was run unperturbed up until that point, a perturbation vector was randomly generated for the desired change of precision and applied to the network at that point, then the perturbed network was run on the next time point and its perturbed learning rate was measured. This was repeated for each level of change in precision. Finally, for a given change in precision, the change in learning rate was calculated as the difference between the perturbed and the unperturbed learning rate.</p><p>For statistical analysis, we ran a one-tailed paired t-test to test whether the population’s mean change in learning rate was higher at one level of precision change than at the next level of precision change. This was done for each of the four consecutive pairs of levels of change in precision.</p></sec><sec id="s4-14"><title>Test of higher-level inference about changes</title><p>For a given network architecture, higher-level inference about changes was assessed by comparing the population of 20 networks trained in the environment with coupled change points to the population of 20 networks trained in the environment with independent change points.</p><p>In <xref ref-type="fig" rid="fig7">Figure 7c</xref>, the change in unobserved bigram prediction for a given streak length <italic>m</italic> was computed as follows. First, prior sequences were generated and each network was run on each of the sequences. We generated initial sequences of 74 observations each with a probability of 0.2 for the 'observed' bigram (which will render its repetition surprising) and a probability <italic>p</italic> for the 'unobserved' bigram equal to 0.2 or 0.8 (such probabilities, symmetric and substantially different from the default prior 0.5, should render a change in their inferred value detectable). We crossed all possibilities (0|0 or 1|1 as observed bigram, 0.2 or 0.8 for <italic>p</italic>) and generated 100 sequences for each (hence 400 sequences total). Second, at the end of each of these initial sequences, the prediction for the unobserved bigram, p<sub>before</sub>, was queried by retrieving the output of the network after giving it as input ‘0’ if the unobserved bigram was 0|0 or ‘1’ otherwise. Third, the network was further presented with <italic>m</italic> repeated observations of the same value: ‘1’ if the observed bigram was 1|1 or ‘0’ otherwise. Finally, after this streak of repetition, the new prediction for the unobserved bigram, p<sub>after</sub>, was queried (as before) and we measured its change with respect to the previous query, |p<sub>after</sub>−p<sub>before</sub>|. This procedure was repeated for <italic>m</italic> ranging from 2 and 75.</p><p>For statistics, we ran a one-tailed two independent samples t-test to test whether the mean change in unobserved bigram prediction of the population trained on coupled change points was higher than that of the population trained on independent change points.</p></sec><sec id="s4-15"><title>Complexity analyses</title><p>The complexity analysis reported in <xref ref-type="fig" rid="fig8">Figure 8</xref> consisted in measuring, for each network architecture and each environment, the performance of optimally trained networks as a function of the number of units N. For optimal training, hyperparameter optimization was repeated at several values of N, for each type of network and each environment (the resulting values are listed in <xref ref-type="table" rid="table1">Table 1</xref>). For the complexity analysis, a grid of equally spaced N values in logarithmic space between 1 and 45 was generated, an additional value of 474 was included specifically for the networks without recurrent weight training so as to match their number of trained parameters to that of an 11-unit gated recurrent network, and an additional value of 1,000 was included specifically for the networks without gating to facilitate the extrapolation. For every value on this grid, 20 networks of a given architecture in a given environment were randomly initialized with the set of hyperparameter values that was determined to be optimal for the nearest neighboring N value in logarithmic space. The performance of these networks after training was evaluated using a new couple of training and test datasets per environment, each consisting of 400 minibatches of 20 sequences for training and 1000 sequences for testing.</p></sec><sec id="s4-16"><title>Statistics</title><p>To assess the variability between different agent solutions, we trained 20 agents for each type of agent and each environment. These agents have different random seeds (which changes their parameter initialization and how their training data is shuffled). Throughout the article, we report mean or median over these agents, and individual data points when possible or 95 % confidence intervals (abbreviated as &quot;CI&quot;) otherwise, as fully described in the text and figure legends. No statistical methods were used to pre-determine sample sizes but our sample sizes are similar to those reported in previous publications (<xref ref-type="bibr" rid="bib87">Masse et al., 2019</xref>; <xref ref-type="bibr" rid="bib154">Yang et al., 2019</xref>). Data analysis was not performed blind to the conditions of the experiments. No data were excluded from the analyses. All statistical tests were two-tailed unless otherwise noted. The data distribution was assumed to be normal, but this was not formally tested. The specific details of each statistical analysis are reported directly in the text.</p></sec><sec id="s4-17"><title>Code availability</title><p>The code to reproduce exhaustively the analyses of this paper is available at <ext-link ext-link-type="uri" xlink:href="https://github.com/cedricfoucault/networks_for_sequence_prediction">https://github.com/cedricfoucault/networks_for_sequence_prediction</ext-link> and archived on Zenodo with DOI: <ext-link ext-link-type="uri" xlink:href="https://zenodo.org/badge/latestdoi/426944818">10.5281/zenodo.5707498</ext-link>. This code also enables to train new networks equipped with any number of units and generate <xref ref-type="fig" rid="fig2">Figures 2</xref>—<xref ref-type="fig" rid="fig7">7</xref> with those networks.</p></sec><sec id="s4-18"><title>Data availability</title><p>This paper presents no experimental data. All synthetic data are available in the code repository at <ext-link ext-link-type="uri" xlink:href="https://github.com/cedricfoucault/networks_for_sequence_prediction">https://github.com/cedricfoucault/networks_for_sequence_prediction</ext-link> and archived on Zenodo with DOI: <ext-link ext-link-type="uri" xlink:href="https://zenodo.org/badge/latestdoi/426944818">10.5281/zenodo.5707498</ext-link>.</p></sec></sec></body><back><sec id="s5" sec-type="additional-information"><title>Additional information</title><fn-group content-type="competing-interest"><title>Competing interests</title><fn fn-type="COI-statement" id="conf1"><p>No competing interests declared</p></fn></fn-group><fn-group content-type="author-contribution"><title>Author contributions</title><fn fn-type="con" id="con1"><p>Conceptualization, Formal analysis, Funding acquisition, Methodology, Project administration, Supervision, Visualization, Writing - original draft, Writing - review and editing</p></fn><fn fn-type="con" id="con2"><p>Conceptualization, Formal analysis, Funding acquisition, Methodology, Project administration, Supervision, Visualization, Writing - original draft, Writing - review and editing</p></fn></fn-group></sec><sec id="s6" sec-type="supplementary-material"><title>Additional files</title><supplementary-material id="transrepform"><label>Transparent reporting form</label><media mime-subtype="docx" mimetype="application" xlink:href="elife-71801-transrepform1-v4.docx"/></supplementary-material></sec><sec id="s7" sec-type="data-availability"><title>Data availability</title><p>This paper presents no experimental data. All synthetic data are available in the code repository at <ext-link ext-link-type="uri" xlink:href="https://github.com/cedricfoucault/networks_for_sequence_prediction">https://github.com/cedricfoucault/networks_for_sequence_prediction</ext-link> and archived on Zenodo with <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.5281/zenodo.5707498">https://doi.org/10.5281/zenodo.5707498</ext-link>.</p><p>The following dataset was generated:</p><p><element-citation id="dataset1" publication-type="data" specific-use="isSupplementedBy"><person-group person-group-type="author"><name><surname>Foucault</surname><given-names>C</given-names></name></person-group><year iso-8601-date="2021">2021</year><data-title>Networks for sequence prediction</data-title><source>Github</source><pub-id pub-id-type="accession" xlink:href="https://github.com/cedricfoucault/networks_for_sequence_prediction">prediction</pub-id></element-citation></p><p><element-citation id="dataset2" publication-type="data" specific-use="isSupplementedBy"><person-group person-group-type="author"><name><surname>Foucault</surname><given-names>C</given-names></name></person-group><year iso-8601-date="2021">2021</year><data-title>Networks for sequence prediction</data-title><source>Zenodo</source><pub-id pub-id-type="doi">10.5281/zenodo.5707498</pub-id></element-citation></p></sec><ack id="ack"><title>Acknowledgements</title><p>We thank Yair Lakretz for useful feedback, advice, and discussions throughout the project, Alexandre Pouget for his input when starting this project, and Charles Findling for comments on a previous version of the manuscript.</p></ack><ref-list><title>References</title><ref id="bib1"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Agnihotri</surname><given-names>A</given-names></name><name><surname>Batra</surname><given-names>N</given-names></name></person-group><year iso-8601-date="2020">2020</year><article-title>Exploring Bayesian Optimization</article-title><source>Distill</source><volume>5</volume><elocation-id>e26</elocation-id><pub-id pub-id-type="doi">10.23915/distill.00026</pub-id></element-citation></ref><ref id="bib2"><element-citation publication-type="confproc"><person-group person-group-type="author"><name><surname>Amini</surname><given-names>A</given-names></name><name><surname>Schwarting</surname><given-names>W</given-names></name><name><surname>Soleimany</surname><given-names>A</given-names></name><name><surname>Rus</surname><given-names>D</given-names></name></person-group><year iso-8601-date="2020">2020</year><conf-name>Deep Evidential Regression</conf-name><article-title>Advances in Neural Information Processing Systems</article-title><fpage>14927</fpage><lpage>14937</lpage></element-citation></ref><ref id="bib3"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Aston-Jones</surname><given-names>G</given-names></name><name><surname>Rajkowski</surname><given-names>J</given-names></name><name><surname>Kubiak</surname><given-names>P</given-names></name></person-group><year iso-8601-date="1997">1997</year><article-title>Conditioned responses of monkey locus coeruleus neurons anticipate acquisition of discriminative behavior in a vigilance task</article-title><source>Neuroscience</source><volume>80</volume><fpage>697</fpage><lpage>715</lpage><pub-id pub-id-type="doi">10.1016/s0306-4522(97)00060-2</pub-id><pub-id pub-id-type="pmid">9276487</pub-id></element-citation></ref><ref id="bib4"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Aston-Jones</surname><given-names>G</given-names></name><name><surname>Cohen</surname><given-names>JD</given-names></name></person-group><year iso-8601-date="2005">2005</year><article-title>An integrative theory of locus coeruleus-norepinephrine function: adaptive gain and optimal performance</article-title><source>Annual Review of Neuroscience</source><volume>28</volume><fpage>403</fpage><lpage>450</lpage><pub-id pub-id-type="doi">10.1146/annurev.neuro.28.061604.135709</pub-id><pub-id pub-id-type="pmid">16022602</pub-id></element-citation></ref><ref id="bib5"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bach</surname><given-names>DR</given-names></name><name><surname>Hulme</surname><given-names>O</given-names></name><name><surname>Penny</surname><given-names>WD</given-names></name><name><surname>Dolan</surname><given-names>RJ</given-names></name></person-group><year iso-8601-date="2011">2011</year><article-title>The known unknowns: neural representation of second-order uncertainty, and ambiguity</article-title><source>The Journal of Neuroscience</source><volume>31</volume><fpage>4811</fpage><lpage>4820</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.1452-10.2011</pub-id><pub-id pub-id-type="pmid">21451019</pub-id></element-citation></ref><ref id="bib6"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Barron</surname><given-names>AR</given-names></name></person-group><year iso-8601-date="1993">1993</year><article-title>Universal approximation bounds for superpositions of a sigmoidal function</article-title><source>IEEE Transactions on Information Theory</source><volume>39</volume><fpage>930</fpage><lpage>945</lpage><pub-id pub-id-type="doi">10.1109/18.256500</pub-id></element-citation></ref><ref id="bib7"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Baumgarten</surname><given-names>TJ</given-names></name><name><surname>Schnitzler</surname><given-names>A</given-names></name><name><surname>Lange</surname><given-names>J</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Prestimulus Alpha Power Influences Tactile Temporal Perceptual Discrimination and Confidence in Decisions</article-title><source>Cerebral Cortex</source><volume>26</volume><fpage>891</fpage><lpage>903</lpage><pub-id pub-id-type="doi">10.1093/cercor/bhu247</pub-id><pub-id pub-id-type="pmid">25331603</pub-id></element-citation></ref><ref id="bib8"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Behrens</surname><given-names>TEJ</given-names></name><name><surname>Woolrich</surname><given-names>MW</given-names></name><name><surname>Walton</surname><given-names>ME</given-names></name><name><surname>Rushworth</surname><given-names>MFS</given-names></name></person-group><year iso-8601-date="2007">2007</year><article-title>Learning the value of information in an uncertain world</article-title><source>Nature Neuroscience</source><volume>10</volume><fpage>1214</fpage><lpage>1221</lpage><pub-id pub-id-type="doi">10.1038/nn1954</pub-id><pub-id pub-id-type="pmid">17676057</pub-id></element-citation></ref><ref id="bib9"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Beiran</surname><given-names>M</given-names></name><name><surname>Dubreuil</surname><given-names>A</given-names></name><name><surname>Valente</surname><given-names>A</given-names></name><name><surname>Mastrogiuseppe</surname><given-names>F</given-names></name><name><surname>Ostojic</surname><given-names>S</given-names></name></person-group><year iso-8601-date="2021">2021</year><article-title>Shaping Dynamics With Multiple Populations in Low-Rank Recurrent Networks</article-title><source>Neural Computation</source><volume>33</volume><fpage>1572</fpage><lpage>1615</lpage><pub-id pub-id-type="doi">10.1162/neco_a_01381</pub-id><pub-id pub-id-type="pmid">34496384</pub-id></element-citation></ref><ref id="bib10"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bengio</surname><given-names>Y</given-names></name><name><surname>Simard</surname><given-names>P</given-names></name><name><surname>Frasconi</surname><given-names>P</given-names></name></person-group><year iso-8601-date="1994">1994</year><article-title>Learning long-term dependencies with gradient descent is difficult</article-title><source>IEEE Transactions on Neural Networks</source><volume>5</volume><fpage>157</fpage><lpage>166</lpage><pub-id pub-id-type="doi">10.1109/72.279181</pub-id><pub-id pub-id-type="pmid">18267787</pub-id></element-citation></ref><ref id="bib11"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Berniker</surname><given-names>M</given-names></name><name><surname>Kording</surname><given-names>K</given-names></name></person-group><year iso-8601-date="2008">2008</year><article-title>Estimating the sources of motor errors for adaptation and generalization</article-title><source>Nature Neuroscience</source><volume>11</volume><fpage>1454</fpage><lpage>1461</lpage><pub-id pub-id-type="doi">10.1038/nn.2229</pub-id><pub-id pub-id-type="pmid">19011624</pub-id></element-citation></ref><ref id="bib12"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bhui</surname><given-names>R</given-names></name><name><surname>Lai</surname><given-names>L</given-names></name><name><surname>Gershman</surname><given-names>SJ</given-names></name></person-group><year iso-8601-date="2021">2021</year><article-title>Resource-rational decision making</article-title><source>Current Opinion in Behavioral Sciences</source><volume>41</volume><fpage>15</fpage><lpage>21</lpage><pub-id pub-id-type="doi">10.1016/j.cobeha.2021.02.015</pub-id></element-citation></ref><ref id="bib13"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bill</surname><given-names>J</given-names></name><name><surname>Pailian</surname><given-names>H</given-names></name><name><surname>Gershman</surname><given-names>SJ</given-names></name><name><surname>Drugowitsch</surname><given-names>J</given-names></name></person-group><year iso-8601-date="2020">2020</year><article-title>Hierarchical structure is employed by humans during visual motion perception</article-title><source>PNAS</source><volume>117</volume><fpage>24581</fpage><lpage>24589</lpage><pub-id pub-id-type="doi">10.1073/pnas.2008961117</pub-id><pub-id pub-id-type="pmid">32938799</pub-id></element-citation></ref><ref id="bib14"><element-citation publication-type="preprint"><person-group person-group-type="author"><name><surname>Blalock</surname><given-names>D</given-names></name><name><surname>Ortiz</surname><given-names>JJG</given-names></name><name><surname>Frankle</surname><given-names>J</given-names></name><name><surname>Guttag</surname><given-names>J</given-names></name></person-group><year iso-8601-date="2020">2020</year><article-title>What Is the State of Neural Network Pruning</article-title><source>arXiv</source><ext-link ext-link-type="uri" xlink:href="http://arxiv.org/abs/2003.03033">http://arxiv.org/abs/2003.03033</ext-link></element-citation></ref><ref id="bib15"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Boldt</surname><given-names>A</given-names></name><name><surname>Blundell</surname><given-names>C</given-names></name><name><surname>De Martino</surname><given-names>B</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>Confidence modulates exploration and exploitation in value-based learning</article-title><source>Neuroscience of Consciousness</source><volume>2019</volume><elocation-id>niz004</elocation-id><pub-id pub-id-type="doi">10.1093/nc/niz004</pub-id><pub-id pub-id-type="pmid">31086679</pub-id></element-citation></ref><ref id="bib16"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bornstein</surname><given-names>AM</given-names></name><name><surname>Daw</surname><given-names>ND</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>Cortical and hippocampal correlates of deliberation during model-based decisions for rewards in humans</article-title><source>PLOS Computational Biology</source><volume>9</volume><elocation-id>e1003387</elocation-id><pub-id pub-id-type="doi">10.1371/journal.pcbi.1003387</pub-id><pub-id pub-id-type="pmid">24339770</pub-id></element-citation></ref><ref id="bib17"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bowers</surname><given-names>JS</given-names></name><name><surname>Davis</surname><given-names>CJ</given-names></name></person-group><year iso-8601-date="2012">2012</year><article-title>Bayesian just-so stories in psychology and neuroscience</article-title><source>Psychological Bulletin</source><volume>138</volume><fpage>389</fpage><lpage>414</lpage><pub-id pub-id-type="doi">10.1037/a0026450</pub-id><pub-id pub-id-type="pmid">22545686</pub-id></element-citation></ref><ref id="bib18"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Busch</surname><given-names>NA</given-names></name><name><surname>Dubois</surname><given-names>J</given-names></name><name><surname>VanRullen</surname><given-names>R</given-names></name></person-group><year iso-8601-date="2009">2009</year><article-title>The phase of ongoing EEG oscillations predicts visual perception</article-title><source>The Journal of Neuroscience</source><volume>29</volume><fpage>7869</fpage><lpage>7876</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.0113-09.2009</pub-id><pub-id pub-id-type="pmid">19535598</pub-id></element-citation></ref><ref id="bib19"><element-citation publication-type="preprint"><person-group person-group-type="author"><name><surname>Caucheteux</surname><given-names>C</given-names></name><name><surname>King</surname><given-names>JR</given-names></name></person-group><year iso-8601-date="2021">2021</year><article-title>Language Processing in Brains and Deep Neural Networks: Computational Convergence and Its Limits</article-title><source>bioRxiv</source><pub-id pub-id-type="doi">10.1101/2020.07.03.186288</pub-id></element-citation></ref><ref id="bib20"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Chater</surname><given-names>N</given-names></name><name><surname>Tenenbaum</surname><given-names>JB</given-names></name><name><surname>Yuille</surname><given-names>A</given-names></name></person-group><year iso-8601-date="2006">2006</year><article-title>Probabilistic models of cognition: conceptual foundations</article-title><source>Trends in Cognitive Sciences</source><volume>10</volume><fpage>287</fpage><lpage>291</lpage><pub-id pub-id-type="doi">10.1016/j.tics.2006.05.007</pub-id><pub-id pub-id-type="pmid">16807064</pub-id></element-citation></ref><ref id="bib21"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Chechik</surname><given-names>G</given-names></name><name><surname>Meilijson</surname><given-names>I</given-names></name><name><surname>Ruppin</surname><given-names>E</given-names></name></person-group><year iso-8601-date="1999">1999</year><article-title>Neuronal regulation: A mechanism for synaptic pruning during brain maturation</article-title><source>Neural Computation</source><volume>11</volume><fpage>2061</fpage><lpage>2080</lpage><pub-id pub-id-type="doi">10.1162/089976699300016089</pub-id><pub-id pub-id-type="pmid">10578044</pub-id></element-citation></ref><ref id="bib22"><element-citation publication-type="confproc"><person-group person-group-type="author"><name><surname>Cho</surname><given-names>K</given-names></name><name><surname>van Merrienboer</surname><given-names>B</given-names></name><name><surname>Gulcehre</surname><given-names>C</given-names></name><name><surname>Bahdanau</surname><given-names>D</given-names></name><name><surname>Bougares</surname><given-names>F</given-names></name><name><surname>Schwenk</surname><given-names>H</given-names></name><name><surname>Bengio</surname><given-names>Y</given-names></name></person-group><year iso-8601-date="2014">2014</year><conf-name>Learning Phrase Representations using RNN Encoder–Decoder for Statistical Machine Translation</conf-name><article-title>Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing</article-title><fpage>1724</fpage><lpage>1734</lpage><pub-id pub-id-type="doi">10.3115/v1/D14-1179</pub-id></element-citation></ref><ref id="bib23"><element-citation publication-type="preprint"><person-group person-group-type="author"><name><surname>Chung</surname><given-names>J</given-names></name><name><surname>Gulcehre</surname><given-names>C</given-names></name><name><surname>Cho</surname><given-names>K</given-names></name><name><surname>Bengio</surname><given-names>Y</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>Empirical Evaluation of Gated Recurrent Neural Networks on Sequence Modeling</article-title><source>ArXiv:1412.3555 [Cs</source><ext-link ext-link-type="uri" xlink:href="http://arxiv.org/abs/1412.3555">http://arxiv.org/abs/1412.3555</ext-link></element-citation></ref><ref id="bib24"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Cooper</surname><given-names>GF</given-names></name></person-group><year iso-8601-date="1990">1990</year><article-title>The computational complexity of probabilistic inference using bayesian belief networks</article-title><source>Artificial Intelligence</source><volume>42</volume><fpage>393</fpage><lpage>405</lpage><pub-id pub-id-type="doi">10.1016/0004-3702(90)90060-D</pub-id></element-citation></ref><ref id="bib25"><element-citation publication-type="confproc"><person-group person-group-type="author"><name><surname>Costa</surname><given-names>R</given-names></name><name><surname>Assael</surname><given-names>IA</given-names></name><name><surname>Shillingford</surname><given-names>B</given-names></name><name><surname>de Freitas</surname><given-names>N</given-names></name><name><surname>Vogels</surname><given-names>T</given-names></name></person-group><year iso-8601-date="2017">2017</year><conf-name>Cortical microcircuits as gated-recurrent neural networks</conf-name><article-title>Advances in Neural Information Processing Systems</article-title></element-citation></ref><ref id="bib26"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Courville</surname><given-names>AC</given-names></name><name><surname>Daw</surname><given-names>ND</given-names></name><name><surname>Touretzky</surname><given-names>DS</given-names></name></person-group><year iso-8601-date="2006">2006</year><article-title>Bayesian theories of conditioning in a changing world</article-title><source>Trends in Cognitive Sciences</source><volume>10</volume><fpage>294</fpage><lpage>300</lpage><pub-id pub-id-type="doi">10.1016/j.tics.2006.05.004</pub-id><pub-id pub-id-type="pmid">16793323</pub-id></element-citation></ref><ref id="bib27"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Cybenko</surname><given-names>G</given-names></name></person-group><year iso-8601-date="1989">1989</year><article-title>Approximation by superpositions of a sigmoidal function</article-title><source>Mathematics of Control, Signals, and Systems</source><volume>2</volume><fpage>303</fpage><lpage>314</lpage><pub-id pub-id-type="doi">10.1007/BF02551274</pub-id></element-citation></ref><ref id="bib28"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Dagum</surname><given-names>P</given-names></name><name><surname>Luby</surname><given-names>M</given-names></name></person-group><year iso-8601-date="1993">1993</year><article-title>Approximating probabilistic inference in Bayesian belief networks is NP-hard</article-title><source>Artificial Intelligence</source><volume>60</volume><fpage>141</fpage><lpage>153</lpage><pub-id pub-id-type="doi">10.1016/0004-3702(93)90036-B</pub-id></element-citation></ref><ref id="bib29"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>de Lange</surname><given-names>FP</given-names></name><name><surname>Heilbron</surname><given-names>M</given-names></name><name><surname>Kok</surname><given-names>P</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>How Do Expectations Shape Perception?</article-title><source>Trends in Cognitive Sciences</source><volume>22</volume><fpage>764</fpage><lpage>779</lpage><pub-id pub-id-type="doi">10.1016/j.tics.2018.06.002</pub-id><pub-id pub-id-type="pmid">30122170</pub-id></element-citation></ref><ref id="bib30"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Dehaene</surname><given-names>S</given-names></name><name><surname>Meyniel</surname><given-names>F</given-names></name><name><surname>Wacongne</surname><given-names>C</given-names></name><name><surname>Wang</surname><given-names>L</given-names></name><name><surname>Pallier</surname><given-names>C</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>The Neural Representation of Sequences: From Transition Probabilities to Algebraic Patterns and Linguistic Trees</article-title><source>Neuron</source><volume>88</volume><fpage>2</fpage><lpage>19</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2015.09.019</pub-id><pub-id pub-id-type="pmid">26447569</pub-id></element-citation></ref><ref id="bib31"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>den Ouden</surname><given-names>HEM</given-names></name><name><surname>Kok</surname><given-names>P</given-names></name><name><surname>de Lange</surname><given-names>FP</given-names></name></person-group><year iso-8601-date="2012">2012</year><article-title>How prediction errors shape perception, attention, and motivation</article-title><source>Frontiers in Psychology</source><volume>3</volume><elocation-id>548</elocation-id><pub-id pub-id-type="doi">10.3389/fpsyg.2012.00548</pub-id><pub-id pub-id-type="pmid">23248610</pub-id></element-citation></ref><ref id="bib32"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Deroy</surname><given-names>O</given-names></name><name><surname>Spence</surname><given-names>C</given-names></name><name><surname>Noppeney</surname><given-names>U</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Metacognition in Multisensory Perception</article-title><source>Trends in Cognitive Sciences</source><volume>20</volume><fpage>736</fpage><lpage>747</lpage><pub-id pub-id-type="doi">10.1016/j.tics.2016.08.006</pub-id><pub-id pub-id-type="pmid">27612983</pub-id></element-citation></ref><ref id="bib33"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Dolan</surname><given-names>RJ</given-names></name><name><surname>Dayan</surname><given-names>P</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>Goals and habits in the brain</article-title><source>Neuron</source><volume>80</volume><fpage>312</fpage><lpage>325</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2013.09.007</pub-id><pub-id pub-id-type="pmid">24139036</pub-id></element-citation></ref><ref id="bib34"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Douglas</surname><given-names>RJ</given-names></name><name><surname>Martin</surname><given-names>KAC</given-names></name></person-group><year iso-8601-date="2007">2007</year><article-title>Recurrent neuronal circuits in the neocortex</article-title><source>Current Biology</source><volume>17</volume><fpage>R496</fpage><lpage>R500</lpage><pub-id pub-id-type="doi">10.1016/j.cub.2007.04.024</pub-id><pub-id pub-id-type="pmid">17610826</pub-id></element-citation></ref><ref id="bib35"><element-citation publication-type="preprint"><person-group person-group-type="author"><name><surname>Dubreuil</surname><given-names>A</given-names></name><name><surname>Valente</surname><given-names>A</given-names></name><name><surname>Beiran</surname><given-names>M</given-names></name><name><surname>Mastrogiuseppe</surname><given-names>F</given-names></name><name><surname>Ostojic</surname><given-names>S</given-names></name></person-group><year iso-8601-date="2020">2020</year><article-title>Complementary Roles of Dimensionality and Population Structure in Neural Computations</article-title><source>bioRxiv</source><pub-id pub-id-type="doi">10.1101/2020.07.03.185942</pub-id></element-citation></ref><ref id="bib36"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Echeveste</surname><given-names>R</given-names></name><name><surname>Aitchison</surname><given-names>L</given-names></name><name><surname>Hennequin</surname><given-names>G</given-names></name><name><surname>Lengyel</surname><given-names>M</given-names></name></person-group><year iso-8601-date="2020">2020</year><article-title>Cortical-like dynamics in recurrent circuits optimized for sampling-based probabilistic inference</article-title><source>Nature Neuroscience</source><volume>23</volume><fpage>1138</fpage><lpage>1149</lpage><pub-id pub-id-type="doi">10.1038/s41593-020-0671-1</pub-id><pub-id pub-id-type="pmid">32778794</pub-id></element-citation></ref><ref id="bib37"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Elman</surname><given-names>JL</given-names></name></person-group><year iso-8601-date="1990">1990</year><article-title>Finding Structure in Time</article-title><source>Cognitive Science</source><volume>14</volume><fpage>179</fpage><lpage>211</lpage><pub-id pub-id-type="doi">10.1207/s15516709cog1402_1</pub-id></element-citation></ref><ref id="bib38"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Elman</surname><given-names>JL</given-names></name></person-group><year iso-8601-date="1991">1991</year><article-title>Distributed representations, simple recurrent networks, and grammatical structure</article-title><source>Machine Learning</source><volume>7</volume><fpage>195</fpage><lpage>225</lpage><pub-id pub-id-type="doi">10.1007/BF00114844</pub-id></element-citation></ref><ref id="bib39"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Eshel</surname><given-names>N</given-names></name><name><surname>Tian</surname><given-names>J</given-names></name><name><surname>Uchida</surname><given-names>N</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>Opening the black box: dopamine, predictions, and learning</article-title><source>Trends in Cognitive Sciences</source><volume>17</volume><fpage>430</fpage><lpage>431</lpage><pub-id pub-id-type="doi">10.1016/j.tics.2013.06.010</pub-id><pub-id pub-id-type="pmid">23830895</pub-id></element-citation></ref><ref id="bib40"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Fairhall</surname><given-names>AL</given-names></name><name><surname>Lewen</surname><given-names>GD</given-names></name><name><surname>Bialek</surname><given-names>W</given-names></name><name><surname>de Ruyter Van Steveninck</surname><given-names>RR</given-names></name></person-group><year iso-8601-date="2001">2001</year><article-title>Efficiency and ambiguity in an adaptive neural code</article-title><source>Nature</source><volume>412</volume><fpage>787</fpage><lpage>792</lpage><pub-id pub-id-type="doi">10.1038/35090500</pub-id><pub-id pub-id-type="pmid">11518957</pub-id></element-citation></ref><ref id="bib41"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Farashahi</surname><given-names>S</given-names></name><name><surname>Donahue</surname><given-names>CH</given-names></name><name><surname>Khorsand</surname><given-names>P</given-names></name><name><surname>Seo</surname><given-names>H</given-names></name><name><surname>Lee</surname><given-names>D</given-names></name><name><surname>Soltani</surname><given-names>A</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>Metaplasticity as a Neural Substrate for Adaptive Learning and Choice under Uncertainty</article-title><source>Neuron</source><volume>94</volume><fpage>401</fpage><lpage>414</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2017.03.044</pub-id><pub-id pub-id-type="pmid">28426971</pub-id></element-citation></ref><ref id="bib42"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Findling</surname><given-names>C</given-names></name><name><surname>Skvortsova</surname><given-names>V</given-names></name><name><surname>Dromnelle</surname><given-names>R</given-names></name><name><surname>Palminteri</surname><given-names>S</given-names></name><name><surname>Wyart</surname><given-names>V</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>Computational noise in reward-guided learning drives behavioral variability in volatile environments</article-title><source>Nature Neuroscience</source><volume>22</volume><fpage>2066</fpage><lpage>2077</lpage><pub-id pub-id-type="doi">10.1038/s41593-019-0518-9</pub-id><pub-id pub-id-type="pmid">31659343</pub-id></element-citation></ref><ref id="bib43"><element-citation publication-type="preprint"><person-group person-group-type="author"><name><surname>Findling</surname><given-names>C</given-names></name><name><surname>Wyart</surname><given-names>V</given-names></name></person-group><year iso-8601-date="2020">2020</year><article-title>Computation Noise Promotes Cognitive Resilience to Adverse Conditions during Decision-Making</article-title><source>bioRxiv</source><pub-id pub-id-type="doi">10.1101/2020.06.10.145300</pub-id></element-citation></ref><ref id="bib44"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Findling</surname><given-names>C</given-names></name><name><surname>Chopin</surname><given-names>N</given-names></name><name><surname>Koechlin</surname><given-names>E</given-names></name></person-group><year iso-8601-date="2021">2021</year><article-title>Imprecise neural computations as a source of adaptive behaviour in volatile environments</article-title><source>Nature Human Behaviour</source><volume>5</volume><fpage>99</fpage><lpage>112</lpage><pub-id pub-id-type="doi">10.1038/s41562-020-00971-z</pub-id><pub-id pub-id-type="pmid">33168951</pub-id></element-citation></ref><ref id="bib45"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Fiser</surname><given-names>J</given-names></name><name><surname>Berkes</surname><given-names>P</given-names></name><name><surname>Orbán</surname><given-names>G</given-names></name><name><surname>Lengyel</surname><given-names>M</given-names></name></person-group><year iso-8601-date="2010">2010</year><article-title>Statistically optimal perception and learning: from behavior to neural representations</article-title><source>Trends in Cognitive Sciences</source><volume>14</volume><fpage>119</fpage><lpage>130</lpage><pub-id pub-id-type="doi">10.1016/j.tics.2010.01.003</pub-id><pub-id pub-id-type="pmid">20153683</pub-id></element-citation></ref><ref id="bib46"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Friston</surname><given-names>K</given-names></name><name><surname>Rigoli</surname><given-names>F</given-names></name><name><surname>Ognibene</surname><given-names>D</given-names></name><name><surname>Mathys</surname><given-names>C</given-names></name><name><surname>Fitzgerald</surname><given-names>T</given-names></name><name><surname>Pezzulo</surname><given-names>G</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>Active inference and epistemic value</article-title><source>Cognitive Neuroscience</source><volume>6</volume><fpage>187</fpage><lpage>214</lpage><pub-id pub-id-type="doi">10.1080/17588928.2015.1020053</pub-id><pub-id pub-id-type="pmid">25689102</pub-id></element-citation></ref><ref id="bib47"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Fusi</surname><given-names>S</given-names></name><name><surname>Drew</surname><given-names>PJ</given-names></name><name><surname>Abbott</surname><given-names>LF</given-names></name></person-group><year iso-8601-date="2005">2005</year><article-title>Cascade models of synaptically stored memories</article-title><source>Neuron</source><volume>45</volume><fpage>599</fpage><lpage>611</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2005.02.001</pub-id><pub-id pub-id-type="pmid">15721245</pub-id></element-citation></ref><ref id="bib48"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Fusi</surname><given-names>S</given-names></name><name><surname>Asaad</surname><given-names>WF</given-names></name><name><surname>Miller</surname><given-names>EK</given-names></name><name><surname>Wang</surname><given-names>XJ</given-names></name></person-group><year iso-8601-date="2007">2007</year><article-title>A neural circuit model of flexible sensorimotor mapping: learning and forgetting on multiple timescales</article-title><source>Neuron</source><volume>54</volume><fpage>319</fpage><lpage>333</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2007.03.017</pub-id><pub-id pub-id-type="pmid">17442251</pub-id></element-citation></ref><ref id="bib49"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Gallistel</surname><given-names>CR</given-names></name><name><surname>Krishan</surname><given-names>M</given-names></name><name><surname>Liu</surname><given-names>Y</given-names></name><name><surname>Miller</surname><given-names>R</given-names></name><name><surname>Latham</surname><given-names>PE</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>The perception of probability</article-title><source>Psychological Review</source><volume>121</volume><fpage>96</fpage><lpage>123</lpage><pub-id pub-id-type="doi">10.1037/a0035232</pub-id><pub-id pub-id-type="pmid">24490790</pub-id></element-citation></ref><ref id="bib50"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Gijsen</surname><given-names>S</given-names></name><name><surname>Grundei</surname><given-names>M</given-names></name><name><surname>Lange</surname><given-names>RT</given-names></name><name><surname>Ostwald</surname><given-names>D</given-names></name><name><surname>Blankenburg</surname><given-names>F</given-names></name></person-group><year iso-8601-date="2021">2021</year><article-title>Neural surprise in somatosensory Bayesian learning</article-title><source>PLOS Computational Biology</source><volume>17</volume><elocation-id>e1008068</elocation-id><pub-id pub-id-type="doi">10.1371/journal.pcbi.1008068</pub-id><pub-id pub-id-type="pmid">33529181</pub-id></element-citation></ref><ref id="bib51"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Gil</surname><given-names>Z</given-names></name><name><surname>Connors</surname><given-names>BW</given-names></name><name><surname>Amitai</surname><given-names>Y</given-names></name></person-group><year iso-8601-date="1997">1997</year><article-title>Differential regulation of neocortical synapses by neuromodulators and activity</article-title><source>Neuron</source><volume>19</volume><fpage>679</fpage><lpage>686</lpage><pub-id pub-id-type="doi">10.1016/s0896-6273(00)80380-3</pub-id><pub-id pub-id-type="pmid">9331357</pub-id></element-citation></ref><ref id="bib52"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Griffiths</surname><given-names>TL</given-names></name><name><surname>Chater</surname><given-names>N</given-names></name><name><surname>Norris</surname><given-names>D</given-names></name><name><surname>Pouget</surname><given-names>A</given-names></name></person-group><year iso-8601-date="2012">2012</year><article-title>How the Bayesians got their beliefs (and what those beliefs actually are): comment on Bowers and Davis (2012)</article-title><source>Psychological Bulletin</source><volume>138</volume><fpage>415</fpage><lpage>422</lpage><pub-id pub-id-type="doi">10.1037/a0026884</pub-id><pub-id pub-id-type="pmid">22545687</pub-id></element-citation></ref><ref id="bib53"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hahn</surname><given-names>G</given-names></name><name><surname>Ponce-Alvarez</surname><given-names>A</given-names></name><name><surname>Deco</surname><given-names>G</given-names></name><name><surname>Aertsen</surname><given-names>A</given-names></name><name><surname>Kumar</surname><given-names>A</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>Portraits of communication in neuronal networks</article-title><source>Nature Reviews. Neuroscience</source><volume>20</volume><fpage>117</fpage><lpage>127</lpage><pub-id pub-id-type="doi">10.1038/s41583-018-0094-0</pub-id><pub-id pub-id-type="pmid">30552403</pub-id></element-citation></ref><ref id="bib54"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hauser</surname><given-names>MD</given-names></name><name><surname>Newport</surname><given-names>EL</given-names></name><name><surname>Aslin</surname><given-names>RN</given-names></name></person-group><year iso-8601-date="2001">2001</year><article-title>Segmentation of the speech stream in a non-human primate: statistical learning in cotton-top tamarins</article-title><source>Cognition</source><volume>78</volume><fpage>B53</fpage><lpage>B64</lpage><pub-id pub-id-type="doi">10.1016/s0010-0277(00)00132-3</pub-id><pub-id pub-id-type="pmid">11124355</pub-id></element-citation></ref><ref id="bib55"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Haxby</surname><given-names>JV</given-names></name><name><surname>Connolly</surname><given-names>AC</given-names></name><name><surname>Guntupalli</surname><given-names>JS</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>Decoding neural representational spaces using multivariate pattern analysis</article-title><source>Annual Review of Neuroscience</source><volume>37</volume><fpage>435</fpage><lpage>456</lpage><pub-id pub-id-type="doi">10.1146/annurev-neuro-062012-170325</pub-id><pub-id pub-id-type="pmid">25002277</pub-id></element-citation></ref><ref id="bib56"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Heilbron</surname><given-names>M</given-names></name><name><surname>Meyniel</surname><given-names>F</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>Confidence resets reveal hierarchical adaptive learning in humans</article-title><source>PLOS Computational Biology</source><volume>15</volume><elocation-id>e1006972</elocation-id><pub-id pub-id-type="doi">10.1371/journal.pcbi.1006972</pub-id><pub-id pub-id-type="pmid">30964861</pub-id></element-citation></ref><ref id="bib57"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Herrero</surname><given-names>JL</given-names></name><name><surname>Roberts</surname><given-names>MJ</given-names></name><name><surname>Delicato</surname><given-names>LS</given-names></name><name><surname>Gieselmann</surname><given-names>MA</given-names></name><name><surname>Dayan</surname><given-names>P</given-names></name><name><surname>Thiele</surname><given-names>A</given-names></name></person-group><year iso-8601-date="2008">2008</year><article-title>Acetylcholine contributes through muscarinic receptors to attentional modulation in V1</article-title><source>Nature</source><volume>454</volume><fpage>1110</fpage><lpage>1114</lpage><pub-id pub-id-type="doi">10.1038/nature07141</pub-id><pub-id pub-id-type="pmid">18633352</pub-id></element-citation></ref><ref id="bib58"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hipp</surname><given-names>JF</given-names></name><name><surname>Engel</surname><given-names>AK</given-names></name><name><surname>Siegel</surname><given-names>M</given-names></name></person-group><year iso-8601-date="2011">2011</year><article-title>Oscillatory synchronization in large-scale cortical networks predicts perception</article-title><source>Neuron</source><volume>69</volume><fpage>387</fpage><lpage>396</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2010.12.027</pub-id><pub-id pub-id-type="pmid">21262474</pub-id></element-citation></ref><ref id="bib59"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hochreiter</surname><given-names>S</given-names></name><name><surname>Schmidhuber</surname><given-names>J</given-names></name></person-group><year iso-8601-date="1997">1997</year><article-title>Long short-term memory</article-title><source>Neural Computation</source><volume>9</volume><fpage>1735</fpage><lpage>1780</lpage><pub-id pub-id-type="doi">10.1162/neco.1997.9.8.1735</pub-id><pub-id pub-id-type="pmid">9377276</pub-id></element-citation></ref><ref id="bib60"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hunt</surname><given-names>LT</given-names></name><name><surname>Hayden</surname><given-names>BY</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>A distributed, hierarchical and recurrent framework for reward-based choice</article-title><source>Nature Reviews. Neuroscience</source><volume>18</volume><fpage>172</fpage><lpage>182</lpage><pub-id pub-id-type="doi">10.1038/nrn.2017.7</pub-id><pub-id pub-id-type="pmid">28209978</pub-id></element-citation></ref><ref id="bib61"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Iemi</surname><given-names>L</given-names></name><name><surname>Busch</surname><given-names>NA</given-names></name><name><surname>Laudini</surname><given-names>A</given-names></name><name><surname>Haegens</surname><given-names>S</given-names></name><name><surname>Samaha</surname><given-names>J</given-names></name><name><surname>Villringer</surname><given-names>A</given-names></name><name><surname>Nikulin</surname><given-names>VV</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>Multiple mechanisms link prestimulus neural oscillations to sensory responses</article-title><source>eLife</source><volume>8</volume><elocation-id>e43620</elocation-id><pub-id pub-id-type="doi">10.7554/eLife.43620</pub-id><pub-id pub-id-type="pmid">31188126</pub-id></element-citation></ref><ref id="bib62"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Iglesias</surname><given-names>S</given-names></name><name><surname>Mathys</surname><given-names>C</given-names></name><name><surname>Brodersen</surname><given-names>KH</given-names></name><name><surname>Kasper</surname><given-names>L</given-names></name><name><surname>Piccirelli</surname><given-names>M</given-names></name><name><surname>den Ouden</surname><given-names>HEM</given-names></name><name><surname>Stephan</surname><given-names>KE</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>Hierarchical prediction errors in midbrain and basal forebrain during sensory learning</article-title><source>Neuron</source><volume>80</volume><fpage>519</fpage><lpage>530</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2013.09.009</pub-id><pub-id pub-id-type="pmid">24139048</pub-id></element-citation></ref><ref id="bib63"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Iigaya</surname><given-names>K</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Adaptive learning and decision-making under uncertainty by metaplastic synapses guided by a surprise detection system</article-title><source>eLife</source><volume>5</volume><elocation-id>e18073</elocation-id><pub-id pub-id-type="doi">10.7554/eLife.18073</pub-id><pub-id pub-id-type="pmid">27504806</pub-id></element-citation></ref><ref id="bib64"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Jazayeri</surname><given-names>M</given-names></name><name><surname>Movshon</surname><given-names>JA</given-names></name></person-group><year iso-8601-date="2006">2006</year><article-title>Optimal representation of sensory information by neural populations</article-title><source>Nature Neuroscience</source><volume>9</volume><fpage>690</fpage><lpage>696</lpage><pub-id pub-id-type="doi">10.1038/nn1691</pub-id><pub-id pub-id-type="pmid">16617339</pub-id></element-citation></ref><ref id="bib65"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Jazayeri</surname><given-names>M</given-names></name><name><surname>Ostojic</surname><given-names>S</given-names></name></person-group><year iso-8601-date="2021">2021</year><article-title>Interpreting neural computations by examining intrinsic and embedding dimensionality of neural activity</article-title><source>Current Opinion in Neurobiology</source><volume>70</volume><fpage>113</fpage><lpage>120</lpage><pub-id pub-id-type="doi">10.1016/j.conb.2021.08.002</pub-id><pub-id pub-id-type="pmid">34537579</pub-id></element-citation></ref><ref id="bib66"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Jensen</surname><given-names>O</given-names></name><name><surname>Mazaheri</surname><given-names>A</given-names></name></person-group><year iso-8601-date="2010">2010</year><article-title>Shaping functional architecture by oscillatory alpha activity: gating by inhibition</article-title><source>Frontiers in Human Neuroscience</source><volume>4</volume><elocation-id>186</elocation-id><pub-id pub-id-type="doi">10.3389/fnhum.2010.00186</pub-id><pub-id pub-id-type="pmid">21119777</pub-id></element-citation></ref><ref id="bib67"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kaliukhovich</surname><given-names>DA</given-names></name><name><surname>Vogels</surname><given-names>R</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>Neurons in macaque inferior temporal cortex show no surprise response to deviants in visual oddball sequences</article-title><source>The Journal of Neuroscience</source><volume>34</volume><fpage>12801</fpage><lpage>12815</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.2154-14.2014</pub-id><pub-id pub-id-type="pmid">25232116</pub-id></element-citation></ref><ref id="bib68"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Khaw</surname><given-names>MW</given-names></name><name><surname>Stevens</surname><given-names>L</given-names></name><name><surname>Woodford</surname><given-names>M</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>Discrete adjustment to a changing environment: Experimental evidence</article-title><source>Journal of Monetary Economics</source><volume>91</volume><fpage>88</fpage><lpage>103</lpage><pub-id pub-id-type="doi">10.1016/j.jmoneco.2017.09.001</pub-id></element-citation></ref><ref id="bib69"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Khaw</surname><given-names>MW</given-names></name><name><surname>Stevens</surname><given-names>L</given-names></name><name><surname>Woodford</surname><given-names>M</given-names></name></person-group><year iso-8601-date="2021">2021</year><article-title>Individual differences in the perception of probability</article-title><source>PLOS Computational Biology</source><volume>17</volume><elocation-id>e1008871</elocation-id><pub-id pub-id-type="doi">10.1371/journal.pcbi.1008871</pub-id><pub-id pub-id-type="pmid">33793574</pub-id></element-citation></ref><ref id="bib70"><element-citation publication-type="confproc"><person-group person-group-type="author"><name><surname>Kingma</surname><given-names>DP</given-names></name><name><surname>Ba</surname><given-names>J</given-names></name></person-group><year iso-8601-date="2015">2015</year><conf-name>Adam: A Method for Stochastic Optimization</conf-name><article-title>3rd International Conference on Learning Representations, ICLR 2015</article-title></element-citation></ref><ref id="bib71"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Klimesch</surname><given-names>W</given-names></name></person-group><year iso-8601-date="1999">1999</year><article-title>EEG alpha and theta oscillations reflect cognitive and memory performance: a review and analysis</article-title><source>Brain Research. Brain Research Reviews</source><volume>29</volume><fpage>169</fpage><lpage>195</lpage><pub-id pub-id-type="doi">10.1016/s0165-0173(98)00056-3</pub-id><pub-id pub-id-type="pmid">10209231</pub-id></element-citation></ref><ref id="bib72"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Klimesch</surname><given-names>W</given-names></name><name><surname>Sauseng</surname><given-names>P</given-names></name><name><surname>Hanslmayr</surname><given-names>S</given-names></name></person-group><year iso-8601-date="2007">2007</year><article-title>EEG alpha oscillations: the inhibition-timing hypothesis</article-title><source>Brain Research Reviews</source><volume>53</volume><fpage>63</fpage><lpage>88</lpage><pub-id pub-id-type="doi">10.1016/j.brainresrev.2006.06.003</pub-id><pub-id pub-id-type="pmid">16887192</pub-id></element-citation></ref><ref id="bib73"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Knill</surname><given-names>DC</given-names></name><name><surname>Pouget</surname><given-names>A</given-names></name></person-group><year iso-8601-date="2004">2004</year><article-title>The Bayesian brain: the role of uncertainty in neural coding and computation</article-title><source>Trends in Neurosciences</source><volume>27</volume><fpage>712</fpage><lpage>719</lpage><pub-id pub-id-type="doi">10.1016/j.tins.2004.10.007</pub-id><pub-id pub-id-type="pmid">15541511</pub-id></element-citation></ref><ref id="bib74"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kriegeskorte</surname><given-names>N</given-names></name><name><surname>Diedrichsen</surname><given-names>J</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>Peeling the Onion of Brain Representations</article-title><source>Annual Review of Neuroscience</source><volume>42</volume><fpage>407</fpage><lpage>432</lpage><pub-id pub-id-type="doi">10.1146/annurev-neuro-080317-061906</pub-id><pub-id pub-id-type="pmid">31283895</pub-id></element-citation></ref><ref id="bib75"><element-citation publication-type="confproc"><person-group person-group-type="author"><name><surname>LeCun</surname><given-names>Y</given-names></name><name><surname>Denker</surname><given-names>J</given-names></name><name><surname>Solla</surname><given-names>S</given-names></name></person-group><year iso-8601-date="1990">1990</year><conf-name>Optimal Brain Damage</conf-name><article-title>Advances in Neural Information Processing Systems</article-title></element-citation></ref><ref id="bib76"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>LeCun</surname><given-names>Y</given-names></name><name><surname>Bengio</surname><given-names>Y</given-names></name><name><surname>Hinton</surname><given-names>G</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>Deep learning</article-title><source>Nature</source><volume>521</volume><fpage>436</fpage><lpage>444</lpage><pub-id pub-id-type="doi">10.1038/nature14539</pub-id><pub-id pub-id-type="pmid">26017442</pub-id></element-citation></ref><ref id="bib77"><element-citation publication-type="confproc"><person-group person-group-type="author"><name><surname>LeCun</surname><given-names>Y</given-names></name></person-group><year iso-8601-date="2016">2016</year><conf-name>Predictive learning</conf-name><article-title>Proc. Speech NIPS</article-title></element-citation></ref><ref id="bib78"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Lee</surname><given-names>TS</given-names></name><name><surname>Mumford</surname><given-names>D</given-names></name></person-group><year iso-8601-date="2003">2003</year><article-title>Hierarchical Bayesian inference in the visual cortex</article-title><source>Journal of the Optical Society of America. A, Optics, Image Science, and Vision</source><volume>20</volume><fpage>1434</fpage><lpage>1448</lpage><pub-id pub-id-type="doi">10.1364/josaa.20.001434</pub-id><pub-id pub-id-type="pmid">12868647</pub-id></element-citation></ref><ref id="bib79"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Legenstein</surname><given-names>R</given-names></name><name><surname>Maass</surname><given-names>W</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>Ensembles of spiking neurons with noise support optimal probabilistic inference in a dynamically changing environment</article-title><source>PLOS Computational Biology</source><volume>10</volume><elocation-id>e1003859</elocation-id><pub-id pub-id-type="doi">10.1371/journal.pcbi.1003859</pub-id><pub-id pub-id-type="pmid">25340749</pub-id></element-citation></ref><ref id="bib80"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Lieder</surname><given-names>F</given-names></name><name><surname>Griffiths</surname><given-names>TL</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>Resource-rational analysis: Understanding human cognition as the optimal use of limited computational resources</article-title><source>The Behavioral and Brain Sciences</source><volume>43</volume><elocation-id>e1</elocation-id><pub-id pub-id-type="doi">10.1017/S0140525X1900061X</pub-id><pub-id pub-id-type="pmid">30714890</pub-id></element-citation></ref><ref id="bib81"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Lillicrap</surname><given-names>TP</given-names></name><name><surname>Santoro</surname><given-names>A</given-names></name><name><surname>Marris</surname><given-names>L</given-names></name><name><surname>Akerman</surname><given-names>CJ</given-names></name><name><surname>Hinton</surname><given-names>G</given-names></name></person-group><year iso-8601-date="2020">2020</year><article-title>Backpropagation and the brain</article-title><source>Nature Reviews. Neuroscience</source><volume>21</volume><fpage>335</fpage><lpage>346</lpage><pub-id pub-id-type="doi">10.1038/s41583-020-0277-3</pub-id><pub-id pub-id-type="pmid">32303713</pub-id></element-citation></ref><ref id="bib82"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ma</surname><given-names>WJ</given-names></name><name><surname>Beck</surname><given-names>JM</given-names></name><name><surname>Latham</surname><given-names>PE</given-names></name><name><surname>Pouget</surname><given-names>A</given-names></name></person-group><year iso-8601-date="2006">2006</year><article-title>Bayesian inference with probabilistic population codes</article-title><source>Nature Neuroscience</source><volume>9</volume><fpage>1432</fpage><lpage>1438</lpage><pub-id pub-id-type="doi">10.1038/nn1790</pub-id><pub-id pub-id-type="pmid">17057707</pub-id></element-citation></ref><ref id="bib83"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ma</surname><given-names>WJ</given-names></name></person-group><year iso-8601-date="2010">2010</year><article-title>Signal detection theory, uncertainty, and Poisson-like population codes</article-title><source>Vision Research</source><volume>50</volume><fpage>2308</fpage><lpage>2319</lpage><pub-id pub-id-type="doi">10.1016/j.visres.2010.08.035</pub-id><pub-id pub-id-type="pmid">20828581</pub-id></element-citation></ref><ref id="bib84"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ma</surname><given-names>WJ</given-names></name><name><surname>Jazayeri</surname><given-names>M</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>Neural coding of uncertainty and probability</article-title><source>Annual Review of Neuroscience</source><volume>37</volume><fpage>205</fpage><lpage>220</lpage><pub-id pub-id-type="doi">10.1146/annurev-neuro-071013-014017</pub-id><pub-id pub-id-type="pmid">25032495</pub-id></element-citation></ref><ref id="bib85"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Maheu</surname><given-names>M</given-names></name><name><surname>Dehaene</surname><given-names>S</given-names></name><name><surname>Meyniel</surname><given-names>F</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>Brain signatures of a multiscale process of sequence learning in humans</article-title><source>eLife</source><volume>8</volume><elocation-id>e41541</elocation-id><pub-id pub-id-type="doi">10.7554/eLife.41541</pub-id><pub-id pub-id-type="pmid">30714904</pub-id></element-citation></ref><ref id="bib86"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Mante</surname><given-names>V</given-names></name><name><surname>Sussillo</surname><given-names>D</given-names></name><name><surname>Shenoy</surname><given-names>KV</given-names></name><name><surname>Newsome</surname><given-names>WT</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>Context-dependent computation by recurrent dynamics in prefrontal cortex</article-title><source>Nature</source><volume>503</volume><fpage>78</fpage><lpage>84</lpage><pub-id pub-id-type="doi">10.1038/nature12742</pub-id><pub-id pub-id-type="pmid">24201281</pub-id></element-citation></ref><ref id="bib87"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Masse</surname><given-names>NY</given-names></name><name><surname>Yang</surname><given-names>GR</given-names></name><name><surname>Song</surname><given-names>HF</given-names></name><name><surname>Wang</surname><given-names>XJ</given-names></name><name><surname>Freedman</surname><given-names>DJ</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>Circuit mechanisms for the maintenance and manipulation of information in working memory</article-title><source>Nature Neuroscience</source><volume>22</volume><fpage>1159</fpage><lpage>1167</lpage><pub-id pub-id-type="doi">10.1038/s41593-019-0414-3</pub-id><pub-id pub-id-type="pmid">31182866</pub-id></element-citation></ref><ref id="bib88"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Mastrogiuseppe</surname><given-names>F</given-names></name><name><surname>Ostojic</surname><given-names>S</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>Intrinsically-generated fluctuating activity in excitatory-inhibitory networks</article-title><source>PLOS Computational Biology</source><volume>13</volume><elocation-id>e1005498</elocation-id><pub-id pub-id-type="doi">10.1371/journal.pcbi.1005498</pub-id><pub-id pub-id-type="pmid">28437436</pub-id></element-citation></ref><ref id="bib89"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Mathewson</surname><given-names>KE</given-names></name><name><surname>Gratton</surname><given-names>G</given-names></name><name><surname>Fabiani</surname><given-names>M</given-names></name><name><surname>Beck</surname><given-names>DM</given-names></name><name><surname>Ro</surname><given-names>T</given-names></name></person-group><year iso-8601-date="2009">2009</year><article-title>To see or not to see: prestimulus alpha phase predicts visual awareness</article-title><source>The Journal of Neuroscience</source><volume>29</volume><fpage>2725</fpage><lpage>2732</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.3963-08.2009</pub-id><pub-id pub-id-type="pmid">19261866</pub-id></element-citation></ref><ref id="bib90"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>McGuire</surname><given-names>JT</given-names></name><name><surname>Nassar</surname><given-names>MR</given-names></name><name><surname>Gold</surname><given-names>JI</given-names></name><name><surname>Kable</surname><given-names>JW</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>Functionally dissociable influences on learning rate in a dynamic environment</article-title><source>Neuron</source><volume>84</volume><fpage>870</fpage><lpage>881</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2014.10.013</pub-id><pub-id pub-id-type="pmid">25459409</pub-id></element-citation></ref><ref id="bib91"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Meyniel</surname><given-names>F</given-names></name><name><surname>Schlunegger</surname><given-names>D</given-names></name><name><surname>Dehaene</surname><given-names>S</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>The Sense of Confidence during Probabilistic Learning: A Normative Account</article-title><source>PLOS Computational Biology</source><volume>11</volume><elocation-id>e1004305</elocation-id><pub-id pub-id-type="doi">10.1371/journal.pcbi.1004305</pub-id><pub-id pub-id-type="pmid">26076466</pub-id></element-citation></ref><ref id="bib92"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Meyniel</surname><given-names>F</given-names></name><name><surname>Maheu</surname><given-names>M</given-names></name><name><surname>Dehaene</surname><given-names>S</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Human Inferences about Sequences: A Minimal Transition Probability Model</article-title><source>PLOS Computational Biology</source><volume>12</volume><elocation-id>e1005260</elocation-id><pub-id pub-id-type="doi">10.1371/journal.pcbi.1005260</pub-id><pub-id pub-id-type="pmid">28030543</pub-id></element-citation></ref><ref id="bib93"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Meyniel</surname><given-names>F</given-names></name><name><surname>Dehaene</surname><given-names>S</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>Brain networks for confidence weighting and hierarchical inference during probabilistic learning</article-title><source>PNAS</source><volume>114</volume><fpage>E3859</fpage><lpage>E3868</lpage><pub-id pub-id-type="doi">10.1073/pnas.1615773114</pub-id><pub-id pub-id-type="pmid">28439014</pub-id></element-citation></ref><ref id="bib94"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Meyniel</surname><given-names>F</given-names></name></person-group><year iso-8601-date="2020">2020</year><article-title>Brain dynamics for confidence-weighted learning</article-title><source>PLOS Computational Biology</source><volume>16</volume><elocation-id>e1007935</elocation-id><pub-id pub-id-type="doi">10.1371/journal.pcbi.1007935</pub-id><pub-id pub-id-type="pmid">32484806</pub-id></element-citation></ref><ref id="bib95"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Moyer</surname><given-names>JT</given-names></name><name><surname>Wolf</surname><given-names>JA</given-names></name><name><surname>Finkel</surname><given-names>LH</given-names></name></person-group><year iso-8601-date="2007">2007</year><article-title>Effects of dopaminergic modulation on the integrative properties of the ventral striatal medium spiny neuron</article-title><source>Journal of Neurophysiology</source><volume>98</volume><fpage>3731</fpage><lpage>3748</lpage><pub-id pub-id-type="doi">10.1152/jn.00335.2007</pub-id><pub-id pub-id-type="pmid">17913980</pub-id></element-citation></ref><ref id="bib96"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Nassar</surname><given-names>MR</given-names></name><name><surname>Wilson</surname><given-names>RC</given-names></name><name><surname>Heasly</surname><given-names>B</given-names></name><name><surname>Gold</surname><given-names>JI</given-names></name></person-group><year iso-8601-date="2010">2010</year><article-title>An approximately Bayesian delta-rule model explains the dynamics of belief updating in a changing environment</article-title><source>The Journal of Neuroscience</source><volume>30</volume><fpage>12366</fpage><lpage>12378</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.0822-10.2010</pub-id><pub-id pub-id-type="pmid">20844132</pub-id></element-citation></ref><ref id="bib97"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Nassar</surname><given-names>MR</given-names></name><name><surname>Rumsey</surname><given-names>KM</given-names></name><name><surname>Wilson</surname><given-names>RC</given-names></name><name><surname>Parikh</surname><given-names>K</given-names></name><name><surname>Heasly</surname><given-names>B</given-names></name><name><surname>Gold</surname><given-names>JI</given-names></name></person-group><year iso-8601-date="2012">2012</year><article-title>Rational regulation of learning dynamics by pupil-linked arousal systems</article-title><source>Nature Neuroscience</source><volume>15</volume><fpage>1040</fpage><lpage>1046</lpage><pub-id pub-id-type="doi">10.1038/nn.3130</pub-id><pub-id pub-id-type="pmid">22660479</pub-id></element-citation></ref><ref id="bib98"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Orhan</surname><given-names>AE</given-names></name><name><surname>Ma</surname><given-names>WJ</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>Efficient probabilistic inference in generic neural networks trained with non-probabilistic feedback</article-title><source>Nature Communications</source><volume>8</volume><fpage>1</fpage><lpage>14</lpage><pub-id pub-id-type="doi">10.1038/s41467-017-00181-8</pub-id><pub-id pub-id-type="pmid">28743932</pub-id></element-citation></ref><ref id="bib99"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>O’Reilly</surname><given-names>RC</given-names></name></person-group><year iso-8601-date="2006">2006</year><article-title>Biologically based computational models of high-level cognition</article-title><source>Science</source><volume>314</volume><fpage>91</fpage><lpage>94</lpage><pub-id pub-id-type="doi">10.1126/science.1127242</pub-id><pub-id pub-id-type="pmid">17023651</pub-id></element-citation></ref><ref id="bib100"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>O’Reilly</surname><given-names>RC</given-names></name><name><surname>Frank</surname><given-names>MJ</given-names></name></person-group><year iso-8601-date="2006">2006</year><article-title>Making working memory work: a computational model of learning in the prefrontal cortex and basal ganglia</article-title><source>Neural Computation</source><volume>18</volume><fpage>283</fpage><lpage>328</lpage><pub-id pub-id-type="doi">10.1162/089976606775093909</pub-id><pub-id pub-id-type="pmid">16378516</pub-id></element-citation></ref><ref id="bib101"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>O’Reilly</surname><given-names>RC</given-names></name><name><surname>Russin</surname><given-names>JL</given-names></name><name><surname>Zolfaghar</surname><given-names>M</given-names></name><name><surname>Rohrlich</surname><given-names>J</given-names></name></person-group><year iso-8601-date="2021">2021</year><article-title>Deep Predictive Learning in Neocortex and Pulvinar</article-title><source>Journal of Cognitive Neuroscience</source><volume>33</volume><fpage>1158</fpage><lpage>1196</lpage><pub-id pub-id-type="doi">10.1162/jocn_a_01708</pub-id><pub-id pub-id-type="pmid">34428793</pub-id></element-citation></ref><ref id="bib102"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Payzan-LeNestour</surname><given-names>E</given-names></name><name><surname>Dunne</surname><given-names>S</given-names></name><name><surname>Bossaerts</surname><given-names>P</given-names></name><name><surname>O’Doherty</surname><given-names>JP</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>The neural representation of unexpected uncertainty during value-based decision making</article-title><source>Neuron</source><volume>79</volume><fpage>191</fpage><lpage>201</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2013.04.037</pub-id><pub-id pub-id-type="pmid">23849203</pub-id></element-citation></ref><ref id="bib103"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Pecevski</surname><given-names>D</given-names></name><name><surname>Buesing</surname><given-names>L</given-names></name><name><surname>Maass</surname><given-names>W</given-names></name></person-group><year iso-8601-date="2011">2011</year><article-title>Probabilistic inference in general graphical models through sampling in stochastic networks of spiking neurons</article-title><source>PLOS Computational Biology</source><volume>7</volume><elocation-id>e1002294</elocation-id><pub-id pub-id-type="doi">10.1371/journal.pcbi.1002294</pub-id><pub-id pub-id-type="pmid">22219717</pub-id></element-citation></ref><ref id="bib104"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Peterson</surname><given-names>CR</given-names></name><name><surname>Beach</surname><given-names>LR</given-names></name></person-group><year iso-8601-date="1967">1967</year><article-title>Man as an intuitive statistician</article-title><source>Psychological Bulletin</source><volume>68</volume><fpage>29</fpage><lpage>46</lpage><pub-id pub-id-type="doi">10.1037/h0024722</pub-id><pub-id pub-id-type="pmid">6046307</pub-id></element-citation></ref><ref id="bib105"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Pezzulo</surname><given-names>G</given-names></name><name><surname>Rigoli</surname><given-names>F</given-names></name><name><surname>Friston</surname><given-names>K</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>Active Inference, homeostatic regulation and adaptive behavioural control</article-title><source>Progress in Neurobiology</source><volume>134</volume><fpage>17</fpage><lpage>35</lpage><pub-id pub-id-type="doi">10.1016/j.pneurobio.2015.09.001</pub-id><pub-id pub-id-type="pmid">26365173</pub-id></element-citation></ref><ref id="bib106"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Prat-Carrabin</surname><given-names>A</given-names></name><name><surname>Wilson</surname><given-names>RC</given-names></name><name><surname>Cohen</surname><given-names>JD</given-names></name><name><surname>Azeredo da Silveira</surname><given-names>R</given-names></name></person-group><year iso-8601-date="2021">2021</year><article-title>Human inference in changing environments with temporal structure</article-title><source>Psychological Review</source><volume>128</volume><fpage>879</fpage><lpage>912</lpage><pub-id pub-id-type="doi">10.1037/rev0000276</pub-id><pub-id pub-id-type="pmid">34516148</pub-id></element-citation></ref><ref id="bib107"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Purcell</surname><given-names>BA</given-names></name><name><surname>Kiani</surname><given-names>R</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Hierarchical decision processes that operate over distinct timescales underlie choice and changes in strategy</article-title><source>PNAS</source><volume>113</volume><fpage>E4531</fpage><lpage>E4540</lpage><pub-id pub-id-type="doi">10.1073/pnas.1524685113</pub-id><pub-id pub-id-type="pmid">27432960</pub-id></element-citation></ref><ref id="bib108"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Rahnev</surname><given-names>D</given-names></name><name><surname>Denison</surname><given-names>RN</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>Suboptimality in perceptual decision making</article-title><source>The Behavioral and Brain Sciences</source><volume>41</volume><elocation-id>e223</elocation-id><pub-id pub-id-type="doi">10.1017/S0140525X18000936</pub-id><pub-id pub-id-type="pmid">29485020</pub-id></element-citation></ref><ref id="bib109"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Rao</surname><given-names>RP</given-names></name><name><surname>Ballard</surname><given-names>DH</given-names></name></person-group><year iso-8601-date="1999">1999</year><article-title>Predictive coding in the visual cortex: a functional interpretation of some extra-classical receptive-field effects</article-title><source>Nature Neuroscience</source><volume>2</volume><fpage>79</fpage><lpage>87</lpage><pub-id pub-id-type="doi">10.1038/4580</pub-id><pub-id pub-id-type="pmid">10195184</pub-id></element-citation></ref><ref id="bib110"><element-citation publication-type="confproc"><person-group person-group-type="author"><name><surname>Rescorla</surname><given-names>RA</given-names></name><name><surname>Wagner</surname><given-names>AR</given-names></name></person-group><year iso-8601-date="1972">1972</year><conf-name>A theory of Pavlovian conditioning: Variations in the effectiveness of reinforcement and nonreinforcement</conf-name><article-title>Classical Conditioning II: Current Research and Theory</article-title><fpage>64</fpage><lpage>99</lpage></element-citation></ref><ref id="bib111"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Rikhye</surname><given-names>RV</given-names></name><name><surname>Gilra</surname><given-names>A</given-names></name><name><surname>Halassa</surname><given-names>MM</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>Thalamic regulation of switching between cortical representations enables cognitive flexibility</article-title><source>Nature Neuroscience</source><volume>21</volume><fpage>1753</fpage><lpage>1763</lpage><pub-id pub-id-type="doi">10.1038/s41593-018-0269-z</pub-id><pub-id pub-id-type="pmid">30455456</pub-id></element-citation></ref><ref id="bib112"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Robinson</surname><given-names>JG</given-names></name></person-group><year iso-8601-date="1979">1979</year><article-title>An analysis of the organization of vocal communication in the titi monkey Callicebus moloch</article-title><source>Zeitschrift Fur Tierpsychologie</source><volume>49</volume><fpage>381</fpage><lpage>405</lpage><pub-id pub-id-type="doi">10.1111/j.1439-0310.1979.tb00300.x</pub-id><pub-id pub-id-type="pmid">115173</pub-id></element-citation></ref><ref id="bib113"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Rose</surname><given-names>GJ</given-names></name><name><surname>Goller</surname><given-names>F</given-names></name><name><surname>Gritton</surname><given-names>HJ</given-names></name><name><surname>Plamondon</surname><given-names>SL</given-names></name><name><surname>Baugh</surname><given-names>AT</given-names></name><name><surname>Cooper</surname><given-names>BG</given-names></name></person-group><year iso-8601-date="2004">2004</year><article-title>Species-typical songs in white-crowned sparrows tutored with only phrase pairs</article-title><source>Nature</source><volume>432</volume><fpage>753</fpage><lpage>758</lpage><pub-id pub-id-type="doi">10.1038/nature02992</pub-id><pub-id pub-id-type="pmid">15592413</pub-id></element-citation></ref><ref id="bib114"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Saffran</surname><given-names>JR</given-names></name><name><surname>Aslin</surname><given-names>RN</given-names></name><name><surname>Newport</surname><given-names>EL</given-names></name></person-group><year iso-8601-date="1996">1996</year><article-title>Statistical learning by 8-month-old infants</article-title><source>Science</source><volume>274</volume><fpage>1926</fpage><lpage>1928</lpage><pub-id pub-id-type="doi">10.1126/science.274.5294.1926</pub-id><pub-id pub-id-type="pmid">8943209</pub-id></element-citation></ref><ref id="bib115"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Sahani</surname><given-names>M</given-names></name><name><surname>Dayan</surname><given-names>P</given-names></name></person-group><year iso-8601-date="2003">2003</year><article-title>Doubly distributional population codes: simultaneous representation of uncertainty and multiplicity</article-title><source>Neural Computation</source><volume>15</volume><fpage>2255</fpage><lpage>2279</lpage><pub-id pub-id-type="doi">10.1162/089976603322362356</pub-id><pub-id pub-id-type="pmid">14511521</pub-id></element-citation></ref><ref id="bib116"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Salgado</surname><given-names>H</given-names></name><name><surname>Treviño</surname><given-names>M</given-names></name><name><surname>Atzori</surname><given-names>M</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Layer- and area-specific actions of norepinephrine on cortical synaptic transmission</article-title><source>Brain Research</source><volume>1641</volume><fpage>163</fpage><lpage>176</lpage><pub-id pub-id-type="doi">10.1016/j.brainres.2016.01.033</pub-id><pub-id pub-id-type="pmid">26820639</pub-id></element-citation></ref><ref id="bib117"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Sanborn</surname><given-names>AN</given-names></name><name><surname>Chater</surname><given-names>N</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Bayesian Brains without Probabilities</article-title><source>Trends in Cognitive Sciences</source><volume>20</volume><fpage>883</fpage><lpage>893</lpage><pub-id pub-id-type="doi">10.1016/j.tics.2016.10.003</pub-id><pub-id pub-id-type="pmid">28327290</pub-id></element-citation></ref><ref id="bib118"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Saxe</surname><given-names>A</given-names></name><name><surname>Nelli</surname><given-names>S</given-names></name><name><surname>Summerfield</surname><given-names>C</given-names></name></person-group><year iso-8601-date="2021">2021</year><article-title>If deep learning is the answer, what is the question?</article-title><source>Nature Reviews. Neuroscience</source><volume>22</volume><fpage>55</fpage><lpage>67</lpage><pub-id pub-id-type="doi">10.1038/s41583-020-00395-8</pub-id><pub-id pub-id-type="pmid">33199854</pub-id></element-citation></ref><ref id="bib119"><element-citation publication-type="confproc"><person-group person-group-type="author"><name><surname>Schaeffer</surname><given-names>R</given-names></name><name><surname>Khona</surname><given-names>M</given-names></name><name><surname>Meshulam</surname><given-names>L</given-names></name><name><surname>Laboratory</surname><given-names>IB</given-names></name><name><surname>Fiete</surname><given-names>IR</given-names></name></person-group><year iso-8601-date="2020">2020</year><conf-name>Reverse-engineering Recurrent Neural Network solutions to a hierarchical inference task for mice</conf-name><article-title>NeurIPS ProceedingsSearch</article-title><pub-id pub-id-type="doi">10.1101/2020.06.09.142745</pub-id></element-citation></ref><ref id="bib120"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Schäfer</surname><given-names>AM</given-names></name><name><surname>Zimmermann</surname><given-names>HG</given-names></name></person-group><year iso-8601-date="2006">2006</year><chapter-title>Recurrent Neural Networks Are Universal Approximators</chapter-title><person-group person-group-type="editor"><name><surname>Kollias</surname><given-names>SD</given-names></name><name><surname>Stafylopatis</surname><given-names>A</given-names></name><name><surname>Duch</surname><given-names>W</given-names></name><name><surname>Oja</surname><given-names>E</given-names></name></person-group><source>Artificial Neural Networks – ICANN 2006</source><publisher-loc>Berlin Heidelberg</publisher-loc><publisher-name>Springer</publisher-name><fpage>632</fpage><lpage>640</lpage><pub-id pub-id-type="doi">10.1007/11840817</pub-id></element-citation></ref><ref id="bib121"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Schapiro</surname><given-names>AC</given-names></name><name><surname>Rogers</surname><given-names>TT</given-names></name><name><surname>Cordova</surname><given-names>NI</given-names></name><name><surname>Turk-Browne</surname><given-names>NB</given-names></name><name><surname>Botvinick</surname><given-names>MM</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>Neural representations of events arise from temporal community structure</article-title><source>Nature Neuroscience</source><volume>16</volume><fpage>486</fpage><lpage>492</lpage><pub-id pub-id-type="doi">10.1038/nn.3331</pub-id><pub-id pub-id-type="pmid">23416451</pub-id></element-citation></ref><ref id="bib122"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Schultz</surname><given-names>W</given-names></name><name><surname>Dayan</surname><given-names>P</given-names></name><name><surname>Montague</surname><given-names>PR</given-names></name></person-group><year iso-8601-date="1997">1997</year><article-title>A neural substrate of prediction and reward</article-title><source>Science</source><volume>275</volume><fpage>1593</fpage><lpage>1599</lpage><pub-id pub-id-type="doi">10.1126/science.275.5306.1593</pub-id><pub-id pub-id-type="pmid">9054347</pub-id></element-citation></ref><ref id="bib123"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Servan-Schreiber</surname><given-names>D</given-names></name><name><surname>Printz</surname><given-names>H</given-names></name><name><surname>Cohen</surname><given-names>JD</given-names></name></person-group><year iso-8601-date="1990">1990</year><article-title>A network model of catecholamine effects: gain, signal-to-noise ratio, and behavior</article-title><source>Science</source><volume>249</volume><fpage>892</fpage><lpage>895</lpage><pub-id pub-id-type="doi">10.1126/science.2392679</pub-id><pub-id pub-id-type="pmid">2392679</pub-id></element-citation></ref><ref id="bib124"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Sherman</surname><given-names>BE</given-names></name><name><surname>Graves</surname><given-names>KN</given-names></name><name><surname>Turk-Browne</surname><given-names>NB</given-names></name></person-group><year iso-8601-date="2020">2020</year><article-title>The prevalence and importance of statistical learning in human cognition and behavior</article-title><source>Current Opinion in Behavioral Sciences</source><volume>32</volume><fpage>15</fpage><lpage>20</lpage><pub-id pub-id-type="doi">10.1016/j.cobeha.2020.01.015</pub-id><pub-id pub-id-type="pmid">32258249</pub-id></element-citation></ref><ref id="bib125"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Simon</surname><given-names>HA</given-names></name></person-group><year iso-8601-date="1955">1955</year><article-title>A Behavioral Model of Rational Choice</article-title><source>The Quarterly Journal of Economics</source><volume>69</volume><elocation-id>99</elocation-id><pub-id pub-id-type="doi">10.2307/1884852</pub-id></element-citation></ref><ref id="bib126"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Simon</surname><given-names>HA</given-names></name></person-group><year iso-8601-date="1972">1972</year><article-title>Theories of bounded rationality</article-title><source>Decision and Organization</source><volume>1</volume><fpage>161</fpage><lpage>176</lpage></element-citation></ref><ref id="bib127"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Sohn</surname><given-names>H</given-names></name><name><surname>Narain</surname><given-names>D</given-names></name><name><surname>Meirhaeghe</surname><given-names>N</given-names></name><name><surname>Jazayeri</surname><given-names>M</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>Bayesian Computation through Cortical Latent Dynamics</article-title><source>Neuron</source><volume>103</volume><fpage>934</fpage><lpage>947</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2019.06.012</pub-id><pub-id pub-id-type="pmid">31320220</pub-id></element-citation></ref><ref id="bib128"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Soltani</surname><given-names>A</given-names></name><name><surname>Wang</surname><given-names>XJ</given-names></name></person-group><year iso-8601-date="2010">2010</year><article-title>Synaptic computation underlying probabilistic inference</article-title><source>Nature Neuroscience</source><volume>13</volume><fpage>112</fpage><lpage>119</lpage><pub-id pub-id-type="doi">10.1038/nn.2450</pub-id><pub-id pub-id-type="pmid">20010823</pub-id></element-citation></ref><ref id="bib129"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Soltani</surname><given-names>A</given-names></name><name><surname>Izquierdo</surname><given-names>A</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>Adaptive learning under expected and unexpected uncertainty</article-title><source>Nature Reviews. Neuroscience</source><volume>20</volume><fpage>635</fpage><lpage>644</lpage><pub-id pub-id-type="doi">10.1038/s41583-019-0180-y</pub-id><pub-id pub-id-type="pmid">31147631</pub-id></element-citation></ref><ref id="bib130"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Srivastava</surname><given-names>N</given-names></name><name><surname>Hinton</surname><given-names>G</given-names></name><name><surname>Krizhevsky</surname><given-names>A</given-names></name><name><surname>Sutskever</surname><given-names>I</given-names></name><name><surname>Salakhutdinov</surname><given-names>R</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>Dropout: A simple way to prevent neural networks from overfitting</article-title><source>The Journal of Machine Learning Research</source><volume>15</volume><fpage>1929</fpage><lpage>1958</lpage></element-citation></ref><ref id="bib131"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Stalter</surname><given-names>M</given-names></name><name><surname>Westendorff</surname><given-names>S</given-names></name><name><surname>Nieder</surname><given-names>A</given-names></name></person-group><year iso-8601-date="2020">2020</year><article-title>Dopamine Gates Visual Signals in Monkey Prefrontal Cortex Neurons</article-title><source>Cell Reports</source><volume>30</volume><fpage>164</fpage><lpage>172</lpage><pub-id pub-id-type="doi">10.1016/j.celrep.2019.11.082</pub-id><pub-id pub-id-type="pmid">31914383</pub-id></element-citation></ref><ref id="bib132"><element-citation publication-type="confproc"><person-group person-group-type="author"><name><surname>Sterling</surname><given-names>P</given-names></name></person-group><year iso-8601-date="2004">2004</year><conf-name>Principles of allostasis: Optimal design, predictive regulation, pathophysiology, and rational therapeutics</conf-name><article-title>Allostasis, Homeostasis, and the Costs of Physiological Adaptation</article-title><fpage>17</fpage><lpage>64</lpage><pub-id pub-id-type="doi">10.1017/CBO9781316257081</pub-id></element-citation></ref><ref id="bib133"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Summerfield</surname><given-names>C</given-names></name><name><surname>de Lange</surname><given-names>FP</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>Expectation in perceptual decision making: neural and computational mechanisms</article-title><source>Nature Reviews. Neuroscience</source><volume>15</volume><fpage>745</fpage><lpage>756</lpage><pub-id pub-id-type="doi">10.1038/nrn3838</pub-id><pub-id pub-id-type="pmid">25315388</pub-id></element-citation></ref><ref id="bib134"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Sussillo</surname><given-names>D</given-names></name><name><surname>Churchland</surname><given-names>MM</given-names></name><name><surname>Kaufman</surname><given-names>MT</given-names></name><name><surname>Shenoy</surname><given-names>KV</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>A neural network that finds a naturalistic solution for the production of muscle activity</article-title><source>Nature Neuroscience</source><volume>18</volume><fpage>1025</fpage><lpage>1033</lpage><pub-id pub-id-type="doi">10.1038/nn.4042</pub-id><pub-id pub-id-type="pmid">26075643</pub-id></element-citation></ref><ref id="bib135"><element-citation publication-type="confproc"><person-group person-group-type="author"><name><surname>Sutskever</surname><given-names>I</given-names></name><name><surname>Martens</surname><given-names>J</given-names></name><name><surname>Dahl</surname><given-names>G</given-names></name><name><surname>Hinton</surname><given-names>G</given-names></name></person-group><year iso-8601-date="2013">2013</year><conf-name>On the importance of initialization and momentum in deep learning</conf-name><article-title>International Conference on Machine Learning</article-title><fpage>1139</fpage><lpage>1147</lpage></element-citation></ref><ref id="bib136"><element-citation publication-type="confproc"><person-group person-group-type="author"><name><surname>Sutton</surname><given-names>R</given-names></name></person-group><year iso-8601-date="1992">1992</year><conf-name>Gain Adaptation Beats Least Squares</conf-name><article-title>In Proceedings of the 7th Yale Workshop on Adaptive and Learning Systems</article-title><fpage>161</fpage><lpage>166</lpage></element-citation></ref><ref id="bib137"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Sutton</surname><given-names>RS</given-names></name><name><surname>Barto</surname><given-names>AG</given-names></name></person-group><year iso-8601-date="1998">1998</year><source>Introduction to Reinforcement Learning</source><publisher-name>MIT Press</publisher-name><pub-id pub-id-type="doi">10.1109/TNN.1998.712192</pub-id></element-citation></ref><ref id="bib138"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Tanaka</surname><given-names>G</given-names></name><name><surname>Yamane</surname><given-names>T</given-names></name><name><surname>Héroux</surname><given-names>JB</given-names></name><name><surname>Nakane</surname><given-names>R</given-names></name><name><surname>Kanazawa</surname><given-names>N</given-names></name><name><surname>Takeda</surname><given-names>S</given-names></name><name><surname>Numata</surname><given-names>H</given-names></name><name><surname>Nakano</surname><given-names>D</given-names></name><name><surname>Hirose</surname><given-names>A</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>Recent advances in physical reservoir computing: A review</article-title><source>Neural Networks</source><volume>115</volume><fpage>100</fpage><lpage>123</lpage><pub-id pub-id-type="doi">10.1016/j.neunet.2019.03.005</pub-id><pub-id pub-id-type="pmid">30981085</pub-id></element-citation></ref><ref id="bib139"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Tauber</surname><given-names>S</given-names></name><name><surname>Navarro</surname><given-names>DJ</given-names></name><name><surname>Perfors</surname><given-names>A</given-names></name><name><surname>Steyvers</surname><given-names>M</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>Bayesian models of cognition revisited: Setting optimality aside and letting data drive psychological theory</article-title><source>Psychological Review</source><volume>124</volume><fpage>410</fpage><lpage>441</lpage><pub-id pub-id-type="doi">10.1037/rev0000052</pub-id><pub-id pub-id-type="pmid">28358549</pub-id></element-citation></ref><ref id="bib140"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Tenenbaum</surname><given-names>JB</given-names></name><name><surname>Kemp</surname><given-names>C</given-names></name><name><surname>Griffiths</surname><given-names>TL</given-names></name><name><surname>Goodman</surname><given-names>ND</given-names></name></person-group><year iso-8601-date="2011">2011</year><article-title>How to grow a mind: statistics, structure, and abstraction</article-title><source>Science</source><volume>331</volume><fpage>1279</fpage><lpage>1285</lpage><pub-id pub-id-type="doi">10.1126/science.1192788</pub-id><pub-id pub-id-type="pmid">21393536</pub-id></element-citation></ref><ref id="bib141"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Thiele</surname><given-names>A</given-names></name><name><surname>Bellgrove</surname><given-names>MA</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>Neuromodulation of Attention</article-title><source>Neuron</source><volume>97</volume><fpage>769</fpage><lpage>785</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2018.01.008</pub-id><pub-id pub-id-type="pmid">29470969</pub-id></element-citation></ref><ref id="bib142"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Thurley</surname><given-names>K</given-names></name><name><surname>Senn</surname><given-names>W</given-names></name><name><surname>Lüscher</surname><given-names>HR</given-names></name></person-group><year iso-8601-date="2008">2008</year><article-title>Dopamine increases the gain of the input-output response of rat prefrontal pyramidal neurons</article-title><source>Journal of Neurophysiology</source><volume>99</volume><fpage>2985</fpage><lpage>2997</lpage><pub-id pub-id-type="doi">10.1152/jn.01098.2007</pub-id><pub-id pub-id-type="pmid">18400958</pub-id></element-citation></ref><ref id="bib143"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Todd</surname><given-names>PM</given-names></name><name><surname>Gigerenzer</surname><given-names>G</given-names></name></person-group><year iso-8601-date="2000">2000</year><article-title>Précis of Simple heuristics that make us smart</article-title><source>The Behavioral and Brain Sciences</source><volume>23</volume><fpage>727</fpage><lpage>741</lpage><pub-id pub-id-type="doi">10.1017/s0140525x00003447</pub-id><pub-id pub-id-type="pmid">11301545</pub-id></element-citation></ref><ref id="bib144"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Tomov</surname><given-names>MS</given-names></name><name><surname>Truong</surname><given-names>VQ</given-names></name><name><surname>Hundia</surname><given-names>RA</given-names></name><name><surname>Gershman</surname><given-names>SJ</given-names></name></person-group><year iso-8601-date="2020">2020</year><article-title>Dissociable neural correlates of uncertainty underlie different exploration strategies</article-title><source>Nature Communications</source><volume>11</volume><elocation-id>2371</elocation-id><pub-id pub-id-type="doi">10.1038/s41467-020-15766-z</pub-id><pub-id pub-id-type="pmid">32398675</pub-id></element-citation></ref><ref id="bib145"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ulanovsky</surname><given-names>N</given-names></name><name><surname>Las</surname><given-names>L</given-names></name><name><surname>Farkas</surname><given-names>D</given-names></name><name><surname>Nelken</surname><given-names>I</given-names></name></person-group><year iso-8601-date="2004">2004</year><article-title>Multiple time scales of adaptation in auditory cortex neurons</article-title><source>The Journal of Neuroscience</source><volume>24</volume><fpage>10440</fpage><lpage>10453</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.1905-04.2004</pub-id><pub-id pub-id-type="pmid">15548659</pub-id></element-citation></ref><ref id="bib146"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Vinckier</surname><given-names>F</given-names></name><name><surname>Gaillard</surname><given-names>R</given-names></name><name><surname>Palminteri</surname><given-names>S</given-names></name><name><surname>Rigoux</surname><given-names>L</given-names></name><name><surname>Salvador</surname><given-names>A</given-names></name><name><surname>Fornito</surname><given-names>A</given-names></name><name><surname>Adapa</surname><given-names>R</given-names></name><name><surname>Krebs</surname><given-names>MO</given-names></name><name><surname>Pessiglione</surname><given-names>M</given-names></name><name><surname>Fletcher</surname><given-names>PC</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Confidence and psychosis: a neuro-computational account of contingency learning disruption by NMDA blockade</article-title><source>Molecular Psychiatry</source><volume>21</volume><fpage>946</fpage><lpage>955</lpage><pub-id pub-id-type="doi">10.1038/mp.2015.73</pub-id><pub-id pub-id-type="pmid">26055423</pub-id></element-citation></ref><ref id="bib147"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wang</surname><given-names>JX</given-names></name><name><surname>Kurth-Nelson</surname><given-names>Z</given-names></name><name><surname>Kumaran</surname><given-names>D</given-names></name><name><surname>Tirumala</surname><given-names>D</given-names></name><name><surname>Soyer</surname><given-names>H</given-names></name><name><surname>Leibo</surname><given-names>JZ</given-names></name><name><surname>Hassabis</surname><given-names>D</given-names></name><name><surname>Botvinick</surname><given-names>M</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>Prefrontal cortex as a meta-reinforcement learning system</article-title><source>Nature Neuroscience</source><volume>21</volume><fpage>860</fpage><lpage>868</lpage><pub-id pub-id-type="doi">10.1038/s41593-018-0147-8</pub-id><pub-id pub-id-type="pmid">29760527</pub-id></element-citation></ref><ref id="bib148"><element-citation publication-type="preprint"><person-group person-group-type="author"><name><surname>Wang</surname><given-names>MB</given-names></name><name><surname>Halassa</surname><given-names>MM</given-names></name></person-group><year iso-8601-date="2021">2021</year><article-title>Thalamocortical Contribution to Solving Credit Assignment in Neural Systems</article-title><source>arXiv</source><ext-link ext-link-type="uri" xlink:href="http://arxiv.org/abs/2104.01474">http://arxiv.org/abs/2104.01474</ext-link></element-citation></ref><ref id="bib149"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wark</surname><given-names>B</given-names></name><name><surname>Fairhall</surname><given-names>A</given-names></name><name><surname>Rieke</surname><given-names>F</given-names></name></person-group><year iso-8601-date="2009">2009</year><article-title>Timescales of inference in visual adaptation</article-title><source>Neuron</source><volume>61</volume><fpage>750</fpage><lpage>761</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2009.01.019</pub-id><pub-id pub-id-type="pmid">19285471</pub-id></element-citation></ref><ref id="bib150"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wolpert</surname><given-names>DM</given-names></name><name><surname>Ghahramani</surname><given-names>Z</given-names></name><name><surname>Jordan</surname><given-names>MI</given-names></name></person-group><year iso-8601-date="1995">1995</year><article-title>An internal model for sensorimotor integration</article-title><source>Science</source><volume>269</volume><fpage>1880</fpage><lpage>1882</lpage><pub-id pub-id-type="doi">10.1126/science.7569931</pub-id><pub-id pub-id-type="pmid">7569931</pub-id></element-citation></ref><ref id="bib151"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wyart</surname><given-names>V</given-names></name><name><surname>Koechlin</surname><given-names>E</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Choice variability and suboptimality in uncertain environments</article-title><source>Current Opinion in Behavioral Sciences</source><volume>11</volume><fpage>109</fpage><lpage>115</lpage><pub-id pub-id-type="doi">10.1016/j.cobeha.2016.07.003</pub-id></element-citation></ref><ref id="bib152"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Yamakawa</surname><given-names>H</given-names></name></person-group><year iso-8601-date="2020">2020</year><article-title>Attentional Reinforcement Learning in the Brain</article-title><source>New Generation Computing</source><volume>38</volume><fpage>49</fpage><lpage>64</lpage><pub-id pub-id-type="doi">10.1007/s00354-019-00081-z</pub-id></element-citation></ref><ref id="bib153"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Yang</surname><given-names>GR</given-names></name><name><surname>Murray</surname><given-names>JD</given-names></name><name><surname>Wang</surname><given-names>XJ</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>A dendritic disinhibitory circuit mechanism for pathway-specific gating</article-title><source>Nature Communications</source><volume>7</volume><elocation-id>12815</elocation-id><pub-id pub-id-type="doi">10.1038/ncomms12815</pub-id></element-citation></ref><ref id="bib154"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Yang</surname><given-names>GR</given-names></name><name><surname>Joglekar</surname><given-names>MR</given-names></name><name><surname>Song</surname><given-names>HF</given-names></name><name><surname>Newsome</surname><given-names>WT</given-names></name><name><surname>Wang</surname><given-names>XJ</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>Task representations in neural networks trained to perform many cognitive tasks</article-title><source>Nature Neuroscience</source><volume>22</volume><fpage>297</fpage><lpage>306</lpage><pub-id pub-id-type="doi">10.1038/s41593-018-0310-2</pub-id><pub-id pub-id-type="pmid">30643294</pub-id></element-citation></ref><ref id="bib155"><element-citation publication-type="confproc"><person-group person-group-type="author"><name><surname>Yu</surname><given-names>AJ</given-names></name><name><surname>Cohen</surname><given-names>JD</given-names></name></person-group><year iso-8601-date="2008">2008</year><conf-name>Sequential effects: Superstition or rational behavior?</conf-name><article-title>Advances in neural information processing systems</article-title><fpage>1873</fpage><lpage>1880</lpage></element-citation></ref><ref id="bib156"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Zador</surname><given-names>AM</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>A critique of pure learning and what artificial neural networks can learn from animal brains</article-title><source>Nature Communications</source><volume>10</volume><elocation-id>3770</elocation-id><pub-id pub-id-type="doi">10.1038/s41467-019-11786-6</pub-id><pub-id pub-id-type="pmid">31434893</pub-id></element-citation></ref><ref id="bib157"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Zhang</surname><given-names>Z</given-names></name><name><surname>Cheng</surname><given-names>H</given-names></name><name><surname>Yang</surname><given-names>T</given-names></name></person-group><year iso-8601-date="2020">2020</year><article-title>A recurrent neural network framework for flexible and adaptive decision making based on sequence learning</article-title><source>PLOS Computational Biology</source><volume>16</volume><elocation-id>e1008342</elocation-id><pub-id pub-id-type="doi">10.1371/journal.pcbi.1008342</pub-id><pub-id pub-id-type="pmid">33141824</pub-id></element-citation></ref></ref-list></back><sub-article article-type="editor-report" id="sa0"><front-stub><article-id pub-id-type="doi">10.7554/eLife.71801.sa0</article-id><title-group><article-title>Editor's evaluation</article-title></title-group><contrib-group><contrib contrib-type="author"><name><surname>Ostojic</surname><given-names>Srdjan</given-names></name><role specific-use="editor">Reviewing Editor</role><aff><institution>Ecole Normale Superieure Paris</institution><country>France</country></aff></contrib></contrib-group><related-object id="sa0ro1" link-type="continued-by" object-id="10.1101/2021.05.03.442240" object-id-type="id" xlink:href="https://sciety.org/articles/activity/10.1101/2021.05.03.442240"/></front-stub><body><p>There has been a longstanding interest in developing normative models of how humans handle latent information in stochastic and volatile environments. This study examines recurrent neural network models trained on sequence-prediction tasks analogous to those used in human cognitive studies. The results demonstrate that such models lead to highly accurate predictions for challenging sequences in which the statistics are non-stationary and change at random times. These novel and remarkable results open up new avenues for cognitive modelling.</p></body></sub-article><sub-article article-type="decision-letter" id="sa1"><front-stub><article-id pub-id-type="doi">10.7554/eLife.71801.sa1</article-id><title-group><article-title>Decision letter</article-title></title-group><contrib-group content-type="section"><contrib contrib-type="editor"><name><surname>Ostojic</surname><given-names>Srdjan</given-names></name><role>Reviewing Editor</role><aff><institution>Ecole Normale Superieure Paris</institution><country>France</country></aff></contrib></contrib-group><contrib-group><contrib contrib-type="reviewer"><name><surname>Ostojic</surname><given-names>Srdjan</given-names></name><role>Reviewer</role><aff><institution>Ecole Normale Superieure Paris</institution><country>France</country></aff></contrib><contrib contrib-type="reviewer"><name><surname>Jazayeri</surname><given-names>Mehrdad</given-names></name><role>Reviewer</role><aff><institution>Massachusetts Institute of Technology</institution><country>United States</country></aff></contrib></contrib-group></front-stub><body><boxed-text id="box1"><p>Our editorial process produces two outputs: (i) <ext-link ext-link-type="uri" xlink:href="https://sciety.org/articles/activity/10.1101/2021.05.03.442240">public reviews</ext-link> designed to be posted alongside <ext-link ext-link-type="uri" xlink:href="https://www.biorxiv.org/content/10.1101/2021.05.03.442240v1">the preprint</ext-link> for the benefit of readers; (ii) feedback on the manuscript for the authors, including requests for revisions, shown below. We also include an acceptance summary that explains what the editors found interesting or important about the work.</p></boxed-text><p><bold>Decision letter after peer review:</bold></p><p>Thank you for submitting your article &quot;Gated recurrence enables simple and accurate sequence prediction in stochastic, changing, and structured environments&quot; for consideration by <italic>eLife</italic>. Your article has been reviewed by 3 peer reviewers, including Srdjan Ostojic as the Reviewing Editor and Reviewer #1, and the evaluation has been overseen by Michael Frank as the Senior Editor. The following individual involved in review of your submission has agreed to reveal their identity: Mehrdad Jazayeri (Reviewer #2).</p><p>The three reviewers are enthusiastic about the manuscript, but have found that the main claims need to be contextualised or rephrased to avoid giving an overstated impression. In the absence of any direct comparison with human behavior and/or neural activity, and considering the high degree of abstraction in model (11 units with abstract computational building blocks), the paper needs a major revision in Discussion to highlight the gap between the results and neurobiology/behavior.</p><p>The Reviewing Editor has drafted a consolidated review to help you prepare a revised submission.</p><p>Essential revisions:</p><p>1. The most notable weakness of the paper is that is not clear whether its aim is to develop a neural model that is close to optimal or a neural model that explains how biological brains handle stochasticity and volatility. There is no serious and quantitative comparison to behavior or neural data recorded in humans or animal models. All the comparisons are with other algorithms and reduced GRU networks. One can appreciate these comparisons if the goal is to show that a full GRU network is close to optimal (which, in many cases, it is). But do humans exhibit a similar level of optimality? One possibility would have been to provide some sort of analysis that would show that the types of errors the model makes are in some counterintuitive (or even intuitive) way like the types of errors humans make. In some of the papers where certain heuristics were proposed, the entire goal was to explain characteristic sub-optimalities in human behavior. As an example, see the recent paper from the Koechlin group in Nature Human Behavior. More generally, there is no shortage of papers quantifying human behavior in stochastic volatile environments. It would be great to see that the errors humans make in at least some task map onto the errors GRU networks make. Imagine for example that such a comparison would show that human errors are more similar to a lesioned version of the GRU, even though the full GRU is closer to optimal. The natural conclusion for such an observation would be that some of the proposed mechanisms are in fact not at play. In any case, all the reviewers think the comparison to human behavior would be valuable, and should be at minimum extensively discussed.</p><p>2. On the importance of gating: a lot of emphasis is put on the necessity of gating (eg title, abstract, discussion line 478). But the methods used in the paper cannot demonstrate necessity. Indeed other studies (see eg Collins, Sohl-Dickenstein and Sussillo, arxiv 2016) have argued that gating in RNNs improves their trainability, but does not increase their capacity. That study argued that large vanilla RNNs are able to reach the same performance as gated RNNs with more extensive training and/or hyper-parameter tuning. The claims and discussion should be revised to reflect this limitation.</p><p>3. The biological relevance of gating seems also somewhat over-stated (eg in the abstract): while there is no doubt various forms of gating are present in the nervous system, how they map to the specific time-dependent form used in GRUs is far from clear. The relationship of these gate variables with actual synapses, neurons, or populations of neurons is at best speculative at this point.</p><p>4. In terms of comparing to biology, the discussion states that &quot;mapping between artificial units and biological neurons may not be straightforward.&quot; But biological and artificial models can still be compared quite effectively in terms of activity in the state space, and these comparisons can help reject hypotheses quite effectively. Training RNNs have been a productive avenue for understanding neural computations in the past years, in many studies of this class networks are constrained or contrasted by experimental data (Mante and Sussillo et al., 2013, Rajan et al., 2016 or Finkelstein and Fontolan et al., 2021 as some examples). It could have been possible to try to understand the geometry of neural representations of latent variables in network dynamics and how it is learned and depends on the environment. Additionally, by performing dynamical system analysis (see eg Susillo and Barak, 2013 or Dubreuil and Valente et al., bioRxiv as examples) it might be possible to understand the role of gating in the network computations.</p><p>5. The focus on very small network does not necessarily seem relevant when comparing with biologic networks (the phrase &quot;reasonably sized networks&quot; on l.479 seems inappropriate). The analysis of network size in Figure 7 goes until 45 units, which remains very small, and it's difficult to extrapolate the results to larger networks. For instance, large vanilla RNNs implement an effective form of gating based on their non=linearity (Dubreuil et al. 2020), and this mechanism may be able to drastically increase sequence-prediction performance.</p><p>6. Another weakness of the paper is that, for each new task, it trains a new GRU. Humans seem to be able to adapt to changes in the latent structure of the generative process without massive retraining. How does this flexibility map onto the proposed scheme? In one of the supplements, cross-task performances have been shown. One notable result is that a GRU trained on a changing bigram with or without coupled change points does quite poorly on the changing unigram. This is an example of failed generalization from a much more complex latent structure to a simpler one, which is indicative of overfitting (to the structure of a generative model – not its parameters). Somewhat counterintuitively, for the GRU model (as well as various other models), the smallest hit on generalization performance occurs when the models are trained on the changing unigram, which is the simplest latent structure considered. This is consistent with several psychophysical studies suggesting that humans may not rely on accurate latent models and may instead rely on simpler heuristics. In the end, is it justified to train new GRUs for each task?</p><p>7. Note that LSTMs are able to perform similar computations like the ones in this study here as is shown in Wang and Kurt-Nelson et al., 2019.</p><p>8. As a more technical point, the comparison with networks without gating does not seem fully fair. Freezing gating effectively reduces the number of time-dependent variables by a factor 3. Also, when freezing gating, one could treat the gating parameters as fixed hyper-parameters to be optimized, rather than setting them by hand to one.</p></body></sub-article><sub-article article-type="reply" id="sa2"><front-stub><article-id pub-id-type="doi">10.7554/eLife.71801.sa2</article-id><title-group><article-title>Author response</article-title></title-group></front-stub><body><disp-quote content-type="editor-comment"><p>Essential revisions:</p><p>1. The most notable weakness of the paper is that is not clear whether its aim is to develop a neural model that is close to optimal or a neural model that explains how biological brains handle stochasticity and volatility. There is no serious and quantitative comparison to behavior or neural data recorded in humans or animal models. All the comparisons are with other algorithms and reduced GRU networks. One can appreciate these comparisons if the goal is to show that a full GRU network is close to optimal (which, in many cases, it is). But do humans exhibit a similar level of optimality? One possibility would have been to provide some sort of analysis that would show that the types of errors the model makes are in some counterintuitive (or even intuitive) way like the types of errors humans make. In some of the papers where certain heuristics were proposed, the entire goal was to explain characteristic sub-optimalities in human behavior. As an example, see the recent paper from the Koechlin group in Nature Human Behavior. More generally, there is no shortage of papers quantifying human behavior in stochastic volatile environments. It would be great to see that the errors humans make in at least some task map onto the errors GRU networks make. Imagine for example that such a comparison would show that human errors are more similar to a lesioned version of the GRU, even though the full GRU is closer to optimal. The natural conclusion for such an observation would be that some of the proposed mechanisms are in fact not at play. In any case, all the reviewers think the comparison to human behavior would be valuable, and should be at minimum extensively discussed.</p></disp-quote><p>The primary aim of our study is to develop neural models that are both close to optimal and simple (i.e. with a small number of units), and to determine under what conditions they can do so, rather than to develop models that can be directly compared with biological brains. Still, the models we develop can inform neuroscience insofar as the tasks we have chosen are tasks that humans and other animals are capable of doing, and in which they show the specific qualitative aspects of optimality that we have investigated (even if they are otherwise suboptimal in several ways). We have modified the Introduction (l. 28, 30, 71) and the Abstract (l. 13) to make our goal clearer. We also now provide further details on several citations throughout the Results by pointing to the relevant figures of previous papers where these qualitative signatures are observed in humans (see l. 197–198, 241, 242–243, 406).</p><p>The direct comparison with the brain (behavioral or neural data), and in particular its suboptimalities, remains a very interesting future direction and it was not sufficiently discussed in the previous version of the manuscript. We have added a section in the Discussion dedicated to this topic and have incorporated new elements: see the section &quot;Suboptimalities in human behavior&quot; l. 607. In particular, we have detailed three possible ways to explore suboptimality with the networks: using networks with less training, using networks with fewer units or sparser connections, or using networks that are altered in some way (as suggested by the reviewers).</p><p>Note that although there is no shortage of experimental data on learning in stochastic and volatile environments in general, a direct comparison of the data between our study and previous experimental studies can rarely be made, either because the participant responses are categorical choices (often binary) rather than continuous estimates (e.g. Findling, Chopin, and Koechlin, 2021; Findling and Wyart et al. 2019), or because the generative process is very different (such as when observations are sampled from a Gaussian, e.g. Nassar et al. 2010; 2012; Prat-Carrabin et al., 2021). The lack of experimental data suitable for direct comparison is even more pronounced in the case of the changing bigram environments (the second and third environments in our study): the only data we are aware of are those collected in our lab, which have the shortcoming that participant responses are far too infrequent (one question every ~15 observations on average, Meyniel et al. 2015; 2017; 2019; 2020). We intend to acquire new data (including trial-by-trial estimates) to allow such a comparison in the future.</p><disp-quote content-type="editor-comment"><p>2. On the importance of gating: a lot of emphasis is put on the necessity of gating (eg title, abstract, discussion line 478). But the methods used in the paper cannot demonstrate necessity. Indeed other studies (see eg Collins, Sohl-Dickenstein and Sussillo, arxiv 2016) have argued that gating in RNNs improves their trainability, but does not increase their capacity. That study argued that large vanilla RNNs are able to reach the same performance as gated RNNs with more extensive training and/or hyper-parameter tuning. The claims and discussion should be revised to reflect this limitation.</p></disp-quote><p>We agree with the reviewer that our study cannot prove necessity in the strict mathematical sense. Proving necessity would require proving the non-existence of other architectures with similar performance; in practice we can only compare a limited number of architectures (one could conceive of others), and even within these architectures, we cannot test the infinity of possible parameter values. We had tried to say this in the Discussion paragraph about the minimal set of mechanisms but we now realize based on the reviews that it is not sufficient. We have rephrased this Discussion paragraph (see l. 544–560), and screened our text to eliminate phrasing suggestive of strict necessity (including in the Abstract, the Introduction, the Results, and the Discussion).</p><p>We also agree that a much larger vanilla RNN can achieve the same task performance as a smaller gated RNN. We intended to demonstrate this point through Figure 8 and the related text. To better convey this message, we have rephrased the text (see new paragraph l. 466 and legend l. 463), and have added to Figure 8 a new data point corresponding to a much larger number of units for the vanilla RNN, to facilitate the extrapolation and indicate that a larger vanilla RNN can ultimately approach optimality. We interpret this as evidence of the advantage afforded by gating to perform the computation simply, i.e. with few units (see also our response to comment #5).</p><p>This slow growth of the vanilla RNN’s performance with the number of units is well described by a power law. More precisely, if <italic>N</italic> is the number of units, and <italic>p</italic> is the % of optimal performance, the law would be: (100 – <italic>p</italic>) = c (1 / <italic>N</italic>)<sup>α</sup>. We fitted this law in the unigram environment with a least-squares linear regression on the logarithm of <italic>N</italic> and (100 – <italic>p</italic>) using the data points from 2 to 45 units, and obtained a goodness-of-fit R<sup>2</sup>=92.4%. We then extrapolated to <italic>N</italic>=1000 using the fitted parameters, and found that the predicted performance was within 0.2% of the performance we actually obtained for networks of this size (predicted: 97.8%, obtained: 97.6%), which further confirms the validity of the power law. Based on this power law, more than 10<sup>4</sup> units would be needed for the vanilla RNN to reach the performance of the GRU at 11 units. We have reported this power law analysis in the revised manuscript (see new paragraph l. 466).</p><p>Regarding trainability: gating is best known indeed for improving the network’s trainability; however, that gating seems advantageous for performing the computation we’re interested in with few units, and not just for trainability, is one outcome of our study that we find interesting. We tried as much as possible to eliminate the trainability factor and approach the best possible performance for each network architecture by conducting an extensive hyperparameter optimization (repeated for each task, each architecture, and several numbers of units). One indication that this procedure worked well is that a plateau is reached (Snoek et al., 2012): the optimal value was always found in the first three quarters of the procedure (most often in the first half); in the last quarter, the validation performances of the new samples are almost identical (although lower), which contrasts with the highly variable performance of the first samples and indicates that Bayesian optimization does not gain from further exploration. Still, we have modified the text to mention the issue of trainability and better gauge the strength of the claim (see paragraph l. 556).</p><p>Our findings are not at odds with Collins et al.'s (2016) argument that gating does not increase the capacity of a RNN, because capacity (as measured in their study) is not what we measured. In their study, capacity was defined either as the number of bits per parameter that the RNN can store about its task during training, or as the number of bits per hidden unit that the RNN can remember about its input history. What we measured, and what we’re interested in, is the capability to perform the specific type of probabilistic inference in the specific type of environments that we have introduced (not to perform any task). In fact, capacity is actually what we want to control for rather than measure: given a certain memory capacity, does a particular architecture perform better than another? (See also our response to comment #5 about simplicity.)</p><disp-quote content-type="editor-comment"><p>3. The biological relevance of gating seems also somewhat over-stated (eg in the abstract): while there is no doubt various forms of gating are present in the nervous system, how they map to the specific time-dependent form used in GRUs is far from clear. The relationship of these gate variables with actual synapses, neurons, or populations of neurons is at best speculative at this point.</p></disp-quote><p>We fully agree and this is actually what we meant when we listed different possible candidates of gating in biology: it is speculative. We have strengthened this point by now stating it explicitly in the Discussion (see l. 564). What we meant was that since gating as a computational mechanism seems useful for solving the kind of problems that the brain faces, it is an invitation for us as neuroscientists to see if we can interpret the processes at play in the brain as doing gating, and it is all the more welcome given that, in biology, many forms of gating have already been observed. We also agree that the GRU has a very specific form of gating and we did not mean to imply that it is only this very specific form that one should consider. When exploring biological substrates it is therefore important not to be too attached to the precise form of gating of the GRU. We have rephrased the Discussion to stress this point (see l. 564–566) and have provided additional references for the possible biological implementations of gating (l. 573–574 and 574–576).</p><disp-quote content-type="editor-comment"><p>4. In terms of comparing to biology, the discussion states that &quot;mapping between artificial units and biological neurons may not be straightforward.&quot; But biological and artificial models can still be compared quite effectively in terms of activity in the state space, and these comparisons can help reject hypotheses quite effectively. Training RNNs have been a productive avenue for understanding neural computations in the past years, in many studies of this class networks are constrained or contrasted by experimental data (Mante and Sussillo et al., 2013, Rajan et al., 2016 or Finkelstein and Fontolan et al., 2021 as some examples). It could have been possible to try to understand the geometry of neural representations of latent variables in network dynamics and how it is learned and depends on the environment. Additionally, by performing dynamical system analysis (see eg Susillo and Barak, 2013 or Dubreuil and Valente et al., bioRxiv as examples) it might be possible to understand the role of gating in the network computations.</p></disp-quote><p>First, concerning the comparison to biology, please see our response to comment #1.</p><p>Second, we would like to thank the reviewers for their suggestion which allowed us to illustrate our point in a different, geometrical and telling way. We have followed the reviewers’ suggestion and made a new figure (analogous to figure 2 and 5 in Mante and Sussillo et al., 2013) that illustrates the dynamics of network activity in the state space, with and without gating, and how these relate to the ideal observer behavior—see Figure 4b. This helps to understand the network computations and the difference that gating makes. The geometry of the trajectories shows that, with gating, the network is able to separate the information about the precision of its estimate from the information about the prediction and to use the former to adapt its rate of update in the latter, whereas without gating, these two are not separated.</p><p>This allowed us to see that, in the network without gating, the decoded precision seemed very strongly dependent on the prediction. To quantify this dependence, we computed the mutual information between the decoded precision and the network’s prediction. It turned out to be very high in the network without gating (median MI=5.2) compared to the network with gating (median MI=0.7) and the ideal observer (MI=0.6). Note that the mutual information is not zero in the ideal observer (and the GRU) because precision tends to be higher for more predictable observations (i.e. when the prediction gets closer to 0 or 1). This is consistent with the rest of our results and completes our argument because adaptive behavior leverages the part of precision that is independent of the prediction.</p><p>We have incorporated this supplementary analysis and the new figure into our results by splitting the old figure 4 and the corresponding section of the Results into two figures and sections, revamping the text and figures accordingly (see l. 251–295, l. 230, l. 296, Figure 4, and Figure 5), and completing the Methods (l. 870–877 and l. 866–867).</p><p>This suggestion also helped us to illustrate the perturbation experiment (see bottom left diagram in Figure 5).</p><disp-quote content-type="editor-comment"><p>5. The focus on very small network does not necessarily seem relevant when comparing with biologic networks (the phrase &quot;reasonably sized networks&quot; on l.479 seems inappropriate). The analysis of network size in Figure 7 goes until 45 units, which remains very small, and it's difficult to extrapolate the results to larger networks. For instance, large vanilla RNNs implement an effective form of gating based on their non=linearity (Dubreuil et al. 2020), and this mechanism may be able to drastically increase sequence-prediction performance.</p></disp-quote><p>Please see our response to comment #1 about our primary goal which is not to develop networks directly comparable with biological neural networks. The phrase &quot;reasonably sized networks&quot; was misleading in that respect and we removed it; thank you for pointing it out.</p><p>In response to comment #2, we have added a data point to Figure 8 to facilitate the extrapolation to larger vanilla RNNs.</p><p>As for the biological implementation of this gating, we quite agree that it remains an open question: do biological neural networks use a mechanism to perform this gating without many neurons, or do they use a very large number of neurons to perform an effective gating as a vanilla RNN would (these are not mutually exclusive)? We have added the latter to our list of possible biological implementations of gating, along with the references that detail how this effective form of gating can be achieved (Beiran, Dubreuil, Valente, Mastrogiuseppe, Ostojic, Neural Computation 2021; Dubreuil, Valente, Beiran, Mastrogiuseppe, Ostojic, bioRxiv) (l. 574–576).</p><p>Regarding our focus on small networks, it is motivated by the desideratum of <italic>simplicity</italic>, which has two advantages:</p><p>1) The reduced model description, which provides better understanding. As scientists, we do not merely want our model to perform the task, we also want to understand how it does it. Constraining the size of the network ensures that the algorithm it performs can be described simply, i.e. with a few effective state variables. Knowing which key computational building blocks enable such simple solutions provides insight into the functioning of the system. This is similar to model reduction approaches as described in (Jazayeri and Ostojic, 2021, last paragraph before the conclusion), such as the reduction to a 2-unit network in (Schaeffer et al., 2020), or the reduction to an effective circuit with 2 internal variables in (Dubreuil et al., 2020).</p><p>2) The efficiency of the solution (low-memory, low-computational complexity). This is relevant for the brain insofar as the brain's computational resources are limited (Lieder and Griffiths, 2020). Here by “computational resources” we mean more precisely the amount of memory required for the computation, which is often quantified by the Shannon capacity, i.e. the number of bits that can be transmitted per unit of time (see for example Bates and Jacobs 2020; Bhui, Lai, and Gershman, 2021). In our case, this amounts to the number of units (each unit stores the same number of bits, encoded by the hidden state). Therefore, the minimum number of units sufficient for near-optimal performance gives us a measure of efficiency. (Orhan and Ma, 2017) also used this measure of efficiency.</p><p>Given the reviewers’ comments, it seems that this point about simplicity was not sufficiently well conveyed in the previous version of the manuscript. We have modified the Introduction (paragraph l. 73) to better motivate our focus on small networks and relate it to simplicity more explicitly, and have further elaborated on it in the Discussion including the above two advantages (l. 548–555).</p><disp-quote content-type="editor-comment"><p>6. Another weakness of the paper is that, for each new task, it trains a new GRU. Humans seem to be able to adapt to changes in the latent structure of the generative process without massive retraining. How does this flexibility map onto the proposed scheme? In one of the supplements, cross-task performances have been shown. One notable result is that a GRU trained on a changing bigram with or without coupled change points does quite poorly on the changing unigram. This is an example of failed generalization from a much more complex latent structure to a simpler one, which is indicative of overfitting (to the structure of a generative model – not its parameters). Somewhat counterintuitively, for the GRU model (as well as various other models), the smallest hit on generalization performance occurs when the models are trained on the changing unigram, which is the simplest latent structure considered. This is consistent with several psychophysical studies suggesting that humans may not rely on accurate latent models and may instead rely on simpler heuristics. In the end, is it justified to train new GRUs for each task?</p></disp-quote><p>Regarding the cross-task performances, it seems that there was some misunderstanding because our results actually show the opposite: it is the GRU trained in the more complex environment (either of the bigram environments) that generalizes best to the simpler environment (unigram) (Figure 6—figure supplement 1). The reviewer's comment made us realize that this figure was difficult to read in the previous version. We therefore grouped the data differently and present of another set of comparisons to highlight this result more clearly: for one GRU trained in a given environment, the performances in the three test environments are now side by side, which allows the reader to better see the generalization performance given one training environment and to compare it with that given a different training environment (see Figure 6—figure supplement 1).</p><p>Regarding the question of whether it is justified to train a new GRU for each environment given that humans seem to be able to adapt to the environment without massive retraining: In fact, it would be unfair to compare the GRUs’ generalization performance as presented here with humans’ ability to generalize as observed in our lab, because when humans do this task in the lab, they are explicitly told what the latent structure is (i.e., the generative process of the observations), they do not have to discover it, unlike GRUs. This point was mentioned but not explicit enough, we now explain it in a new Discussion paragraph (l. 633).</p><p>In this study, we focused on the ability to leverage the latent structure during inference rather than the ability to discover this structure during training. From a theoretical point of view, neither the GRU nor humans can be expected to discover the structure purely from the observations without a large sample size, since even an ideal observer model that arbitrates between the two bigram structures in a statistically optimal fashion requires many observations to determine the correct structure—see Heilbron and Meyniel (2019) p.14:</p><p>“In our task, the optimal hierarchical model is able to correctly identify the current task structure (coupled vs. uncoupled change points), but only with moderate certainty even after observing the entire experiment presented to one subject (log-likelihood ratios range from 2 to 5 depending on subjects) [one experiment corresponds to 4 sequences i.e. 4*380=1520 observations]. […] We speculate that in real-life situations, some cues or priors inform subjects about the relevant dependencies in their environment; if true, then our experiment in which subjects were instructed about the correct task structure may have some ecological validity.”.</p><p>Regarding humans’ ability to flexibly switch from one structure to another without retraining given a cue about the current structure, it would be interesting to study the same ability in our network. This could be done by giving an additional input to the network that codes for the cue. We now mention this future direction in the new Discussion paragraph (see l. 637–641).</p><disp-quote content-type="editor-comment"><p>7. Note that LSTMs are able to perform similar computations like the ones in this study here as is shown in Wang and Kurt-Nelson et al., 2019.</p></disp-quote><p>Thank you for reminding us to mention the LSTM because it is a very popular architecture and many readers are likely to think about it too. We agree: the LSTM incorporates gating mechanisms similar to that of the GRU that allow it to perform the same computation. We have verified this in practice by repeating the hyperparameter optimization, training, and testing procedure with the LSTM: we indeed obtain a performance comparable to the GRU—see <xref ref-type="fig" rid="sa2fig1">Author response image 1</xref> (99% in the unigram environment and 98% in the bigram environment). We added a note in the paper to mention that the LSTM architecture also incorporates gating and can achieve the same performance as the GRU (l. 690–692) and have rephrased our exposition of the architectures to indicate that the GRU is only one particular case of a ‘gated recurrent’ architecture (see l. 136–137).</p><fig id="sa2fig1" position="float"><label>Author response image 1.</label><caption><title>At an equal number of units, the LSTM matches the GRU in performance but is more complex.</title></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-71801-sa2-fig1-v4.tif"/></fig><p>The reason we had chosen the GRU over the LSTM is that we were looking for the minimal sufficient architecture, and the LSTM is a more complex architecture than the GRU, which turned out sufficient. LSTM units are more complex than GRU units in two ways: they have three gates instead of two, and they have an additional state variable called “cell state” (or “memory cell”) that adds to the hidden state. Thus, for the same number of units, the LSTM has not only more parameters than the GRU (at 11 units, the LSTM has 629 parameters and the GRU 475 parameters), but also and more importantly a state space twice as large as that of the GRU and the other architectures we considered (at 11 units, the number of state variables is 22 for the LSTM and 11 for the GRU and the others; see response to main comment #8 about which variables count as state variables). Besides, the introduction of the cell state means that we cannot always perform the same analyses and interventions that we perform on the other architectures.</p><disp-quote content-type="editor-comment"><p>8. As a more technical point, the comparison with networks without gating does not seem fully fair. Freezing gating effectively reduces the number of time-dependent variables by a factor 3. Also, when freezing gating, one could treat the gating parameters as fixed hyper-parameters to be optimized, rather than setting them by hand to one.</p></disp-quote><p>It seems that clarifying the definition of <italic>variables</italic> is key to answer this question. Removing gating does not reduce the number of <italic>state variables</italic> of the system because what we called the “gating variables” (<italic>r</italic> and <italic>z</italic>) are not state variables. The hidden state (<italic>h</italic>) is the only state variable since it alone suffices to determine the future behavior of the system (GRU and others). Our use of the gating variables is merely for convenience of exposition, to make the GRU more intelligible to us researchers (by labeling the factors in the equation that correspond to gating). One can equivalently characterize the system without these variables using a single recurrence equation that contains only the hidden state. We added a note to mention this (l. 683–684). Furthermore, note that when gating is removed, even when tripling the size of the state space, the vanilla RNN does not reach the performance of the GRU (Figure 8).</p><p>Regarding the possibility to treat the gating parameters as fixed hyper-parameters, it is an interesting possibility. In the case of <italic>r</italic>, if we’re not mistaken, it should not change anything because this fixed hyper-parameter could be absorbed into the recurrent weights (w’=rw), which are optimized during training. In the case of <italic>z</italic>, it would amount to treating the time constant of the units as a hyperparameter. We have added a sentence in the Methods to mention this possibility (l. 698).</p></body></sub-article></article>