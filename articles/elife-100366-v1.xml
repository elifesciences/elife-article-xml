<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD with MathML3 v1.3 20210610//EN"  "JATS-archivearticle1-3-mathml3.dtd"><article xmlns:ali="http://www.niso.org/schemas/ali/1.0/" xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" article-type="research-article" dtd-version="1.3"><front><journal-meta><journal-id journal-id-type="nlm-ta">elife</journal-id><journal-id journal-id-type="publisher-id">eLife</journal-id><journal-title-group><journal-title>eLife</journal-title></journal-title-group><issn publication-format="electronic" pub-type="epub">2050-084X</issn><publisher><publisher-name>eLife Sciences Publications, Ltd</publisher-name></publisher></journal-meta><article-meta><article-id pub-id-type="publisher-id">100366</article-id><article-id pub-id-type="doi">10.7554/eLife.100366</article-id><article-id pub-id-type="doi" specific-use="version">10.7554/eLife.100366.3</article-id><article-version article-version-type="publication-state">version of record</article-version><article-categories><subj-group subj-group-type="display-channel"><subject>Research Article</subject></subj-group><subj-group subj-group-type="heading"><subject>Neuroscience</subject></subj-group></article-categories><title-group><article-title>Individual differences in tail risk sensitive exploration using Bayes-adaptive Markov decision processes</article-title></title-group><contrib-group><contrib contrib-type="author" corresp="yes"><name><surname>Shen</surname><given-names>Tingke</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">https://orcid.org/0009-0000-0286-5663</contrib-id><email>kshentingke@gmail.com</email><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="fn" rid="con1"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author"><name><surname>Dayan</surname><given-names>Peter</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">https://orcid.org/0000-0003-3476-1839</contrib-id><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="other" rid="fund1"/><xref ref-type="other" rid="fund3"/><xref ref-type="other" rid="fund4"/><xref ref-type="other" rid="fund2"/><xref ref-type="fn" rid="con2"/><xref ref-type="fn" rid="conf1"/></contrib><aff id="aff1"><label>1</label><institution-wrap><institution-id institution-id-type="ror">https://ror.org/026nmvv73</institution-id><institution>Max Planck Institute for Biological Cybernetics</institution></institution-wrap><addr-line><named-content content-type="city">TÃ¼bingen</named-content></addr-line><country>Germany</country></aff></contrib-group><contrib-group content-type="section"><contrib contrib-type="editor"><name><surname>Langdon</surname><given-names>Angela</given-names></name><role>Reviewing Editor</role><aff><institution-wrap><institution-id institution-id-type="ror">https://ror.org/04xeg9z08</institution-id><institution>National Institute of Mental Health</institution></institution-wrap><country>United States</country></aff></contrib><contrib contrib-type="senior_editor"><name><surname>Frank</surname><given-names>Michael J</given-names></name><role>Senior Editor</role><aff><institution-wrap><institution-id institution-id-type="ror">https://ror.org/05gq02987</institution-id><institution>Brown University</institution></institution-wrap><country>United States</country></aff></contrib></contrib-group><pub-date publication-format="electronic" date-type="publication"><day>01</day><month>12</month><year>2025</year></pub-date><volume>13</volume><elocation-id>RP100366</elocation-id><history><date date-type="sent-for-review" iso-8601-date="2024-07-22"><day>22</day><month>07</month><year>2024</year></date></history><pub-history><event><event-desc>This manuscript was published as a preprint.</event-desc><date date-type="preprint" iso-8601-date="2024-08-14"><day>14</day><month>08</month><year>2024</year></date><self-uri content-type="preprint" xlink:href="https://doi.org/10.1101/2024.01.07.574574"/></event><event><event-desc>This manuscript was published as a reviewed preprint.</event-desc><date date-type="reviewed-preprint" iso-8601-date="2024-11-11"><day>11</day><month>11</month><year>2024</year></date><self-uri content-type="reviewed-preprint" xlink:href="https://doi.org/10.7554/eLife.100366.1"/></event><event><event-desc>The reviewed preprint was revised.</event-desc><date date-type="reviewed-preprint" iso-8601-date="2025-09-26"><day>26</day><month>09</month><year>2025</year></date><self-uri content-type="reviewed-preprint" xlink:href="https://doi.org/10.7554/eLife.100366.2"/></event></pub-history><permissions><copyright-statement>Â© 2024, Shen and Dayan</copyright-statement><copyright-year>2024</copyright-year><copyright-holder>Shen and Dayan</copyright-holder><ali:free_to_read/><license xlink:href="http://creativecommons.org/licenses/by/4.0/"><ali:license_ref>http://creativecommons.org/licenses/by/4.0/</ali:license_ref><license-p>This article is distributed under the terms of the <ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/licenses/by/4.0/">Creative Commons Attribution License</ext-link>, which permits unrestricted use and redistribution provided that the original author and source are credited.</license-p></license></permissions><self-uri content-type="pdf" xlink:href="elife-100366-v1.pdf"/><abstract><p>Novelty is a double-edged sword for agents and animals alike: they might benefit from untapped resources or face unexpected costs or dangers such as predation. The conventional exploration/exploitation tradeoff is thus colored by risk sensitivity. A wealth of experiments has shown how animals solve this dilemma, for example, using intermittent approach. However, there are large individual differences in the nature of approach, and modeling has yet to elucidate how this might be based on animalsâ€™ differing prior expectations about reward and threat, and differing degrees of risk aversion. To capture these factors, we built a Bayes-adaptive Markov decision process model with three key components: an adaptive hazard function capturing potential predation, an intrinsic reward function providing the urge to explore, and a conditional value at risk (CVaR) objective, which is a contemporary measure of trait risk sensitivity. We fit this model to a coarse-grain abstraction of the behavior of 26 animals who freely explored a novel object in an open-field arena. We show that the model captures both quantitative (frequency, duration of exploratory bouts) and qualitative (with distinguished, cautious, tail-behind approach) features of behavior, including the substantial idiosyncrasies that were observed. Some animals begin with cautious exploration and quickly transition to a confident approach to maximize exploration for reward; we classify them as potentially more risk neutral and enjoying a flexible hazard prior. By contrast, other animals only ever approach in a cautious manner and display a form of self-censoring; they are characterized by potential risk aversion and high and inflexible hazard priors. Explaining risk-sensitive exploration using factorized parameters of reinforcement learning models could aid in the understanding, diagnosis, and treatment of psychiatric abnormalities such as anxiety disorders.</p></abstract><kwd-group kwd-group-type="author-keywords"><kwd>exploration</kwd><kwd>risk sensitivity</kwd><kwd>Bayesian reinforcement learning</kwd></kwd-group><kwd-group kwd-group-type="research-organism"><title>Research organism</title><kwd>Mouse</kwd></kwd-group><funding-group><award-group id="fund1"><funding-source><institution-wrap><institution-id institution-id-type="ror">https://ror.org/01hhn8329</institution-id><institution>Max Planck Society</institution></institution-wrap></funding-source><principal-award-recipient><name><surname>Dayan</surname><given-names>Peter</given-names></name></principal-award-recipient></award-group><award-group id="fund2"><funding-source><institution-wrap><institution-id institution-id-type="ror">https://ror.org/012kf4317</institution-id><institution>Alexander von Humboldt Foundation</institution></institution-wrap></funding-source><principal-award-recipient><name><surname>Dayan</surname><given-names>Peter</given-names></name></principal-award-recipient></award-group><award-group id="fund3"><funding-source><institution-wrap><institution-id institution-id-type="ror">https://ror.org/018mejw64</institution-id><institution>Deutsche Forschungsgemeinschaft</institution></institution-wrap></funding-source><award-id>Machine Learning Cluster of Excellence, EXC number 2064/1 â€“ Project number 39072764</award-id><principal-award-recipient><name><surname>Dayan</surname><given-names>Peter</given-names></name></principal-award-recipient></award-group><award-group id="fund4"><funding-source><institution-wrap><institution-id institution-id-type="ror">https://ror.org/03zcxha54</institution-id><institution>Else KrÃ¶ner-Fresenius-Stiftung</institution></institution-wrap></funding-source><award-id>ClinbrAIn: Artificial Intelligence for Clinical Brain Research</award-id><principal-award-recipient><name><surname>Dayan</surname><given-names>Peter</given-names></name></principal-award-recipient></award-group><funding-statement>The funders had no role in study design, data collection, and interpretation, or the decision to submit the work for publication. Open access funding provided by Max Planck Society.</funding-statement></funding-group><custom-meta-group><custom-meta specific-use="meta-only"><meta-name>Author impact statement</meta-name><meta-value>A normative computational model of individual differences in mouse exploration driven by reward and threat uncertainty as well as risk sensitivity when faced with a novel object in an open field.</meta-value></custom-meta><custom-meta specific-use="meta-only"><meta-name>publishing-route</meta-name><meta-value>prc</meta-value></custom-meta></custom-meta-group></article-meta></front><body><sec id="s1" sec-type="intro"><title>Introduction</title><p>In naturalistic environments, novelty can be a source of both reward and dangers. Despite these dueling aspects, investigations of novelty in reinforcement learning have mostly focused on neophilia driven by optimism in the face of uncertainty, and so information-seeking (<xref ref-type="bibr" rid="bib22">Duff, 2002b</xref>; <xref ref-type="bibr" rid="bib17">Dayan and Sejnowski, 1996</xref>; <xref ref-type="bibr" rid="bib33">Gottlieb et al., 2013</xref>; <xref ref-type="bibr" rid="bib70">Wilson et al., 2014</xref>). Neophobia has attracted fewer computational studies, apart from some interesting evolutionary analyses (<xref ref-type="bibr" rid="bib34">Greggor et al., 2015</xref>).</p><p>Excessive novelty seeking and excessive novelty avoidance can both be maladaptive â€“ they are flip sides of a disturbed balance. Here, we seek to examine potential sources of such disturbances, for instance, in distorted priors about the magnitude or probabilities of rewards (which have been linked to mania; <xref ref-type="bibr" rid="bib57">Radulescu and Niv, 2019</xref>; <xref ref-type="bibr" rid="bib7">Bennett and Niv, 2020</xref>; <xref ref-type="bibr" rid="bib25">Eldar et al., 2016</xref>) or threats (linked to anxiety and depression; <xref ref-type="bibr" rid="bib8">Bishop and Gagne, 2018</xref>; <xref ref-type="bibr" rid="bib56">Paulus and Yu, 2012</xref>), or in extreme risk attitudes (<xref ref-type="bibr" rid="bib29">Gagne and Dayan, 2022</xref>).</p><p>To do this, we take advantage of a recent study by <xref ref-type="bibr" rid="bib2">Akiti et al., 2022</xref> on the behavior of mice exploring a familiar open-field arena after the introduction of a novel object near to one corner. The mice could move freely and interact with the object at will. <xref ref-type="bibr" rid="bib2">Akiti et al., 2022</xref> performed detailed analyses of how individual animalsâ€™ trajectories reflected the novel object, including using DeepLabCut (<xref ref-type="bibr" rid="bib48">Mathis et al., 2018</xref>) to track the orientation of the mice relative to the object and MOSEQ (<xref ref-type="bibr" rid="bib71">Wiltschko et al., 2020</xref>) to extract behavioral â€˜syllablesâ€™ whose prevalence was affected by it. The animals differed markedly in how they approached the object and in what pattern. For the former, <xref ref-type="bibr" rid="bib2">Akiti et al., 2022</xref> observed two characteristic positionings of the animals when near to the object: â€˜tail-behindâ€™ (bouts where the animalâ€™s nose was closer to the object than the tail for the entire bout) and â€˜tail-exposedâ€™ (bouts where the animalâ€™s tail is closer to the object than the nose at some point during the bout), associated, respectively, with cautious risk assessment and engagement. For the latter, there was substantial heterogeneity, with all animals initially performing tail-behind approach, but some taking much longer (or failing altogether) to transition to tail-exposed approach.</p><p><xref ref-type="bibr" rid="bib2">Akiti et al., 2022</xref> provide a model-free reinforcement learning account of their data, focusing on the prediction of threat and its realization in the tail of the striatum (TS). Here, we provide a model-based reinforcement learning account, focusing on the rich details of the dynamics of approach carefully characterized by <xref ref-type="bibr" rid="bib2">Akiti et al., 2022</xref>. These include intermittency (i.e. why animals retreat from the object), approach drive (or why animals approach in the first place), the significant long-run approach of cautious animals despite having reached periods of â€˜avoidanceâ€™ behavior, and how the intensity of approach increases when the other animals transition from risk assessment to engagement and then decreases in the long run of the â€˜engagementâ€™ phase. Our model provides an alternative explanation for why animals learn to avoid the novel object in a completely benign environment. Through modeling these additional statistics and behaviors, we reveal the multidimensional aspect of caution in exploration that cannot be captured just in terms of time spent at the object.</p><p>We model an abstract depiction of the behavior of individual mice by combining the Bayes-adaptive Markov decision process (BAMDP) treatment of rational exploration (<xref ref-type="bibr" rid="bib20">Dearden et al., 2013</xref>; <xref ref-type="bibr" rid="bib22">Duff, 2002b</xref>; <xref ref-type="bibr" rid="bib35">Guez et al., 2013</xref>) with two sources of risk sensitivity: the prior over the potential hazard associated with the object, and the conditional value at risk (CVaR) probability distortion mechanism (<xref ref-type="bibr" rid="bib5">Artzner et al., 1999</xref>; <xref ref-type="bibr" rid="bib14">Chow et al., 2015</xref>; <xref ref-type="bibr" rid="bib29">Gagne and Dayan, 2022</xref>; <xref ref-type="bibr" rid="bib6">Bellemare et al., 2023</xref>).</p><p>In a BAMDP, the agent maintains a belief about the possible rewards, costs, and transitions in the environment and decides upon optimal actions based on these beliefs. Since the agent can optionally reuse or abandon incompletely known actions based on what it discovers about them, these actions traditionally enjoy an exploration bonus or â€˜value of informationâ€™, which generalizes the famous Gittins indices (<xref ref-type="bibr" rid="bib31">Gittins, 1979</xref>; <xref ref-type="bibr" rid="bib69">Weber, 1992</xref>). In addition to beliefs about reward, the agent also maintains a belief about potential hazard, which is the first source of risk sensitivity. These beliefs are initialized as prior expectations about the environment and so are readily subject to individual differences.</p><p>In addition to beliefs about hazards which may be specific to a particular environment, we include a second, potentially more general, source of risk sensitivity. That is, we consider optimizing the CVaR, in which agents concentrate on the average value within lower (risk-averse) or upper (risk-seeking) quantiles of the distribution of potential outcomes (<xref ref-type="bibr" rid="bib60">Rigter et al., 2021</xref>). In the context of a BAMDP, this can force agents to pay particular attention to hazards. More extreme quantiles are associated with more extreme risk sensitivity and again are a potential locus of individual differences (as examined in regular Markov decision processes in the context of anxiety disorders in <xref ref-type="bibr" rid="bib29">Gagne and Dayan, 2022</xref>).</p><p>In sum, we present a behavioral model of risk-sensitive exploration, with an agent computing optimal actions using the BAMDP framework under a CVaR objective. This model provides a normative explanation of individual variability â€“ the agent makes decisions by trading off potential reward and threat in a principled way. Different priors and risk sensitivities lead to exploratory schedules that differ in duration, frequency, and type of approach (risk assessment versus engagement) through time. We report features of the different behavioral trajectories the model is able to capture, providing mechanistic insight into how the trade-off between potential reward and threat leads to rational exploratory schedules. Behavioral phenotypes emerge from the interaction of the separate computational mechanisms elucidated by our model-based treatment. This paves the way for future experimental investigations of these mechanisms, including the unexpected non-identifiability of our two sources of risk sensitivity: hazard priors and CVaR.</p></sec><sec id="s2" sec-type="results"><title>Results</title><sec id="s2-1"><title>Behavior phases and animal groups</title><p>Our goal is to provide a computational account of the exploratory behavior of individual mice under the assumption that they have different prior expectations and risk sensitivities. We start from <xref ref-type="bibr" rid="bib2">Akiti et al., 2022</xref>â€™s observation that the animal approaches and remains within a threshold distance (determined by them to be 7 cm) of the object in â€˜boutsâ€™ which can be characterized as â€˜cautiousâ€™ or tail-behind (if the animalâ€™s nose lies between the object and tail) or otherwise â€˜confidentâ€™ or tail-exposed. We sought to capture these qualitative differences (cautious versus confident) as well as aspects of the quantitative changes in bout durations and frequencies as the animal learns about their environment. To make this readily possible, we abstracted the data in two ways: averaging bout statistics over time and clustering the animals into three groups with operationally distinct behaviors.</p><p><xref ref-type="bibr" rid="bib2">Akiti et al., 2022</xref>â€™s classification into bouts can be seen as a very useful abstraction over some of the detailed complexities of the behavior. In order to focus narrowly on interaction with the object, we abstracted further. In particular, instead of modeling the details of the animalsâ€™ spatial interaction with the object, we fitted boxcar functions to the percentages of its time <inline-formula><alternatives><mml:math id="inf1"><mml:semantics><mml:mrow><mml:msup><mml:mrow><mml:mi>ğ‘”</mml:mi></mml:mrow><mml:mrow><mml:mstyle class="text"><mml:mtext>cau</mml:mtext></mml:mstyle></mml:mrow></mml:msup><mml:mo class="MathClass-open" stretchy="false">(</mml:mo><mml:mi>ğ‘¡</mml:mi><mml:mo class="MathClass-close" stretchy="false">)</mml:mo><mml:mo class="MathClass-punc" stretchy="false">,</mml:mo><mml:msup><mml:mrow><mml:mi>ğ‘”</mml:mi></mml:mrow><mml:mrow><mml:mstyle class="text"><mml:mtext>con</mml:mtext></mml:mstyle></mml:mrow></mml:msup><mml:mo class="MathClass-open" stretchy="false">(</mml:mo><mml:mi>ğ‘¡</mml:mi><mml:mo class="MathClass-close" stretchy="false">)</mml:mo></mml:mrow></mml:semantics></mml:math><tex-math id="inft1">\begin{document}$g^{\text{cau}}(t), g^{\text{con}}(t)$\end{document}</tex-math></alternatives></inline-formula> that the animal spends in cautious and confident bouts around time <inline-formula><alternatives><mml:math id="inf2"><mml:semantics><mml:mrow><mml:mi>ğ‘¡</mml:mi></mml:mrow></mml:semantics></mml:math><tex-math id="inft2">\begin{document}$t$\end{document}</tex-math></alternatives></inline-formula> in the apparatus. We can then well encompass the behavior of most animals via four coarse phases of behavior that arise from two binary factors: whether the animal is mainly performing cautious or confident approaches, and whether bouts happen frequently, at a peak rate, or at a lower, steady-state rate. The time an animal spends near the object in one of these phases reflects the product of how frequently it visits the object and how long it stays per visit. We average these two factors within each phase.</p><p>Consider the behavior of the animal in <xref ref-type="fig" rid="fig1">Figure 1a</xref>. Here, <inline-formula><alternatives><mml:math id="inf3"><mml:semantics><mml:mrow><mml:msup><mml:mrow><mml:mi>ğ‘”</mml:mi></mml:mrow><mml:mrow><mml:mstyle class="text"><mml:mtext>cau</mml:mtext></mml:mstyle></mml:mrow></mml:msup><mml:mo class="MathClass-open" stretchy="false">(</mml:mo><mml:mi>ğ‘¡</mml:mi><mml:mo class="MathClass-close" stretchy="false">)</mml:mo></mml:mrow></mml:semantics></mml:math><tex-math id="inft3">\begin{document}$g^{\text{cau}}(t)$\end{document}</tex-math></alternatives></inline-formula> (top graph) makes a transition from an initial level <inline-formula><alternatives><mml:math id="inf4"><mml:semantics><mml:mrow><mml:msubsup><mml:mrow><mml:mi>ğ‘”</mml:mi></mml:mrow><mml:mrow><mml:mi>ğ‘–</mml:mi></mml:mrow><mml:mrow><mml:mstyle class="text"><mml:mtext>cau</mml:mtext></mml:mstyle></mml:mrow></mml:msubsup></mml:mrow></mml:semantics></mml:math><tex-math id="inft4">\begin{document}$g^{\text{cau}}_i$\end{document}</tex-math></alternatives></inline-formula> (during the â€˜cautiousâ€™ phase) to a final steady-state level <inline-formula><alternatives><mml:math id="inf5"><mml:semantics><mml:mrow><mml:msubsup><mml:mrow><mml:mi>ğ‘”</mml:mi></mml:mrow><mml:mrow><mml:mi>ğ‘ </mml:mi></mml:mrow><mml:mrow><mml:mstyle class="text"><mml:mtext>cau</mml:mtext></mml:mstyle></mml:mrow></mml:msubsup></mml:mrow></mml:semantics></mml:math><tex-math id="inft5">\begin{document}$g^{\text{cau}}_s$\end{document}</tex-math></alternatives></inline-formula> (which we simplify as being <inline-formula><alternatives><mml:math id="inf6"><mml:semantics><mml:mrow><mml:msubsup><mml:mrow><mml:mi>ğ‘”</mml:mi></mml:mrow><mml:mrow><mml:mi>ğ‘ </mml:mi></mml:mrow><mml:mrow><mml:mstyle class="text"><mml:mtext>cau</mml:mtext></mml:mstyle></mml:mrow></mml:msubsup><mml:mo class="MathClass-rel" stretchy="false">=</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:semantics></mml:math><tex-math id="inft6">\begin{document}$g^{\text{cau}}_s=0$\end{document}</tex-math></alternatives></inline-formula>) at a transition point <inline-formula><alternatives><mml:math id="inf7"><mml:semantics><mml:mrow><mml:mi>ğ‘¡</mml:mi><mml:mo class="MathClass-rel" stretchy="false">=</mml:mo><mml:msub><mml:mrow><mml:mi>ğ‘¡</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:semantics></mml:math><tex-math id="inft7">\begin{document}$t=t_1$\end{document}</tex-math></alternatives></inline-formula>. At the same time point, <inline-formula><alternatives><mml:math id="inf8"><mml:semantics><mml:mrow><mml:msup><mml:mrow><mml:mi>ğ‘”</mml:mi></mml:mrow><mml:mrow><mml:mstyle class="text"><mml:mtext>con</mml:mtext></mml:mstyle></mml:mrow></mml:msup><mml:mo class="MathClass-open" stretchy="false">(</mml:mo><mml:mi>ğ‘¡</mml:mi><mml:mo class="MathClass-close" stretchy="false">)</mml:mo></mml:mrow></mml:semantics></mml:math><tex-math id="inft8">\begin{document}$g^{\text{con}}(t)$\end{document}</tex-math></alternatives></inline-formula> (second row) makes a transition from 0 to a peak level <inline-formula><alternatives><mml:math id="inf9"><mml:semantics><mml:mrow><mml:msubsup><mml:mrow><mml:mi>ğ‘”</mml:mi></mml:mrow><mml:mrow><mml:mi>ğ‘</mml:mi></mml:mrow><mml:mrow><mml:mstyle class="text"><mml:mtext>con</mml:mtext></mml:mstyle></mml:mrow></mml:msubsup></mml:mrow></mml:semantics></mml:math><tex-math id="inft9">\begin{document}$g^{\text{con}}_p$\end{document}</tex-math></alternatives></inline-formula> of confident approach (defining the â€˜peak confidentâ€™ phase). Finally, there is another transition at time <inline-formula><alternatives><mml:math id="inf10"><mml:semantics><mml:mrow><mml:msub><mml:mrow><mml:mi>ğ‘¡</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:semantics></mml:math><tex-math id="inft10">\begin{document}$t_2$\end{document}</tex-math></alternatives></inline-formula> from peak to a steady-state confident approach time <inline-formula><alternatives><mml:math id="inf11"><mml:semantics><mml:mrow><mml:msubsup><mml:mrow><mml:mi>ğ‘”</mml:mi></mml:mrow><mml:mrow><mml:mi>ğ‘ </mml:mi></mml:mrow><mml:mrow><mml:mstyle class="text"><mml:mtext>con</mml:mtext></mml:mstyle></mml:mrow></mml:msubsup></mml:mrow></mml:semantics></mml:math><tex-math id="inft11">\begin{document}$g^{\text{con}}_s$\end{document}</tex-math></alternatives></inline-formula> (in the â€˜steady-state confidentâ€™ phase). The lower two rows of <xref ref-type="fig" rid="fig1">Figure 1a</xref> show the duration of the bouts in the relevant phases and the frequency per unit time of such bouts. The upper panel of <xref ref-type="fig" rid="fig1">Figure 1b</xref> shows the same data in a more convenient manner. The colors in the top row indicate the type of approach (green is cautious; blue is confident). The second and third rows indicate the duration and frequency of approach. Darker colors represent higher values.</p><fig id="fig1" position="float"><label>Figure 1.</label><caption><title>Extraction of phase-averaged behavioral statistics from minute-resolution bouts data.</title><p>(<bold>a</bold>) Detailed visualization of minute-to-minute statistics of animal 25 (in the sessions after the introduction of the novel object). From top to bottom, the plots show % time within (<xref ref-type="bibr" rid="bib2">Akiti et al., 2022</xref>)â€™s 7 cm threshold of the object with (cautious) and without (confident) tail-behind, the length of a bout at the object and the number of bouts per minute. Orange lines are the box-car functions fitted to segment phases and illustrate the change in time, duration, and frequency statistics across phases. The transition points <inline-formula><alternatives><mml:math id="inf12"><mml:semantics><mml:mrow><mml:msub><mml:mrow><mml:mi>ğ‘¡</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:semantics></mml:math><tex-math id="inft12">\begin{document}$t_1$\end{document}</tex-math></alternatives></inline-formula> and <inline-formula><alternatives><mml:math id="inf13"><mml:semantics><mml:mrow><mml:msub><mml:mrow><mml:mi>ğ‘¡</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:semantics></mml:math><tex-math id="inft13">\begin{document}$t_2$\end{document}</tex-math></alternatives></inline-formula> as well as the initial cautious <inline-formula><alternatives><mml:math id="inf14"><mml:semantics><mml:mrow><mml:msubsup><mml:mrow><mml:mi>ğ‘”</mml:mi></mml:mrow><mml:mrow><mml:mi>ğ‘–</mml:mi></mml:mrow><mml:mrow><mml:mstyle class="text"><mml:mtext>cau</mml:mtext></mml:mstyle></mml:mrow></mml:msubsup></mml:mrow></mml:semantics></mml:math><tex-math id="inft14">\begin{document}$g^{\text{cau}}_i$\end{document}</tex-math></alternatives></inline-formula>, final cautious <inline-formula><alternatives><mml:math id="inf15"><mml:semantics><mml:mrow><mml:msubsup><mml:mrow><mml:mi>ğ‘”</mml:mi></mml:mrow><mml:mrow><mml:mi>ğ‘ </mml:mi></mml:mrow><mml:mrow><mml:mstyle class="text"><mml:mtext>cau</mml:mtext></mml:mstyle></mml:mrow></mml:msubsup></mml:mrow></mml:semantics></mml:math><tex-math id="inft15">\begin{document}$g^{\text{cau}}_s$\end{document}</tex-math></alternatives></inline-formula>, peak confident <inline-formula><alternatives><mml:math id="inf16"><mml:semantics><mml:mrow><mml:msubsup><mml:mrow><mml:mi>ğ‘”</mml:mi></mml:mrow><mml:mrow><mml:mi>ğ‘</mml:mi></mml:mrow><mml:mrow><mml:mstyle class="text"><mml:mtext>con</mml:mtext></mml:mstyle></mml:mrow></mml:msubsup></mml:mrow></mml:semantics></mml:math><tex-math id="inft16">\begin{document}$g^{\text{con}}_p$\end{document}</tex-math></alternatives></inline-formula> and steady-state confident <inline-formula><alternatives><mml:math id="inf17"><mml:semantics><mml:mrow><mml:msubsup><mml:mrow><mml:mi>ğ‘”</mml:mi></mml:mrow><mml:mrow><mml:mi>ğ‘ </mml:mi></mml:mrow><mml:mrow><mml:mstyle class="text"><mml:mtext>con</mml:mtext></mml:mstyle></mml:mrow></mml:msubsup></mml:mrow></mml:semantics></mml:math><tex-math id="inft17">\begin{document}$g^{\text{con}}_s$\end{document}</tex-math></alternatives></inline-formula> approach percentage times are shown. The right plots show examples of minute-to-minute and phase-averaged approach time, duration, and frequency for (<bold>b</bold>) brave, (<bold>c</bold>) intermediate, and (<bold>d</bold>) timid animals. Note that animals are ordered by the group-timidity animal index (see A spectrum of risk-sensitive exploration trajectories). Green indicates cautious and blue indicates confident approach. Darker colors indicate higher values. For the purpose of modeling, we average the idiosyncrasies of behavior over phases and thereby characterize a high-level summary of learning dynamics.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-100366-fig1-v1.tif"/></fig><p>The orange-colored lines in <xref ref-type="fig" rid="fig1">Figure 1a</xref> and the lower panel in <xref ref-type="fig" rid="fig1">Figure 1b</xref> render the abstracted behavior of this animal in an integrated form, showing how we generate â€˜phase-levelâ€™ statistics from minute-to-minute statistics. Averaging statistics over phases ignores idiosyncrasies of behavior and allows us to fit the high-level statistics of behavior: phase-transition times, phase-averaged durations, and frequencies. We consider animal 25 to be a â€˜braveâ€™ animal because of its transition to peak and then steady-state confident approach. There were 12 brave mice out of the 26 in total.</p><p><xref ref-type="fig" rid="fig1">Figure 1c</xref> shows an example of another characteristic â€˜intermediateâ€™ animal. This animal makes a transition from cautious to confident approach (where both duration and frequency of visits can change), but the approach time during the confident phase <inline-formula><alternatives><mml:math id="inf18"><mml:semantics><mml:mrow><mml:msubsup><mml:mrow><mml:mi>ğ‘”</mml:mi></mml:mrow><mml:mrow><mml:mi>ğ‘ </mml:mi></mml:mrow><mml:mrow><mml:mstyle class="text"><mml:mtext>con</mml:mtext></mml:mstyle></mml:mrow></mml:msubsup></mml:mrow></mml:semantics></mml:math><tex-math id="inft18">\begin{document}$g^{\text{con}}_s$\end{document}</tex-math></alternatives></inline-formula> does not decrease. Hence, intermediate animals do not have a transition from peak to steady-state confident phase. There were five such intermediate mice.</p><p><xref ref-type="fig" rid="fig1">Figure 1d</xref> shows the behavior of an example of the last class of â€˜timidâ€™ animals. This animal never makes a transition to confident approach. Hence, for it, <inline-formula><alternatives><mml:math id="inf19"><mml:semantics><mml:mrow><mml:msup><mml:mrow><mml:mi>ğ‘”</mml:mi></mml:mrow><mml:mrow><mml:mstyle class="text"><mml:mtext>con</mml:mtext></mml:mstyle></mml:mrow></mml:msup><mml:mo class="MathClass-open" stretchy="false">(</mml:mo><mml:mi>ğ‘¡</mml:mi><mml:mo class="MathClass-close" stretchy="false">)</mml:mo><mml:mo class="MathClass-rel" stretchy="false">=</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:semantics></mml:math><tex-math id="inft19">\begin{document}$g^{\text{con}}(t)=0$\end{document}</tex-math></alternatives></inline-formula>. However, the cautious approach time makes a transition to a non-zero steady state (<inline-formula><alternatives><mml:math id="inf20"><mml:semantics><mml:mrow><mml:msubsup><mml:mrow><mml:mi>ğ‘”</mml:mi></mml:mrow><mml:mrow><mml:mi>ğ‘ </mml:mi></mml:mrow><mml:mrow><mml:mstyle class="text"><mml:mtext>cau</mml:mtext></mml:mstyle></mml:mrow></mml:msubsup><mml:mo class="MathClass-rel" stretchy="false">&gt;</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:semantics></mml:math><tex-math id="inft20">\begin{document}$g^{\text{cau}}_s \gt 0$\end{document}</tex-math></alternatives></inline-formula>), often via a change in frequency, defining the fourth phase (steady-state cautious). There were nine such timid mice.</p><p><xref ref-type="fig" rid="fig2">Figure 2</xref> summarizes our categorization of the animals into the three groups: brave, intermediate, and timid based on the phases identified in the animalâ€™s exploratory trajectories. Timid animals spend no time in confident approach and are plotted in orange at the origin of <xref ref-type="fig" rid="fig2">Figure 2</xref>. Brave animals differ from intermediate animals in that their approach time during the first 10 min of the confident phase is greater than the last 10 min (steady-state phase). Brave animals are plotted in green above and intermediate animals are plotted in black below the <inline-formula><alternatives><mml:math id="inf21"><mml:semantics><mml:mrow><mml:mi>ğ‘¦</mml:mi><mml:mo class="MathClass-rel" stretchy="false">=</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:semantics></mml:math><tex-math id="inft21">\begin{document}$y=1$\end{document}</tex-math></alternatives></inline-formula> line in <xref ref-type="fig" rid="fig2">Figure 2</xref>.</p><fig id="fig2" position="float"><label>Figure 2.</label><caption><title>Categorization of animals into timid, intermediate, and brave groups based on cautious and confident bout statistics.</title><p>The <italic>x</italic>-axis shows the ratio of total time spent in confident versus cautious bouts. The <italic>y</italic>-axis shows the ratio of bout time in the first 10 min of confident approach and the last 10 min of confident approach (set to 0 for timid animals that do not have a confident phase). The horizontal line indicates <inline-formula><alternatives><mml:math id="inf22"><mml:mstyle><mml:mrow><mml:mstyle displaystyle="false"><mml:mrow><mml:mi mathvariant="italic">y</mml:mi></mml:mrow><mml:mo>=</mml:mo><mml:mn>1.0</mml:mn></mml:mstyle></mml:mrow></mml:mstyle></mml:math><tex-math id="inft22">\begin{document}${\it y}=1.0$\end{document}</tex-math></alternatives></inline-formula>. All nine timid animals are close to the origin. We separate brave and intermediate animals according to the <inline-formula><alternatives><mml:math id="inf23"><mml:mstyle><mml:mrow><mml:mstyle displaystyle="false"><mml:mi>y</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mstyle></mml:mrow></mml:mstyle></mml:math><tex-math id="inft23">\begin{document}$y=1$\end{document}</tex-math></alternatives></inline-formula> line. Solid green dots are brave animals that pass the Benjaminiâ€“Hochberg procedure for ï»¿<inline-formula><alternatives><mml:math id="inf24"><mml:semantics><mml:mrow><mml:mi>ğ‘¦</mml:mi><mml:mo class="MathClass-rel" stretchy="false">&gt;</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:semantics></mml:math><tex-math id="inft24">\begin{document}$y \gt 1$\end{document}</tex-math></alternatives></inline-formula> at level ï»¿ï»¿<inline-formula><alternatives><mml:math id="inf25"><mml:semantics><mml:mrow><mml:mi>ğ‘</mml:mi><mml:mo class="MathClass-rel" stretchy="false">=</mml:mo><mml:mn>0.05</mml:mn></mml:mrow></mml:semantics></mml:math><tex-math id="inft25">\begin{document}$q=0.05$\end{document}</tex-math></alternatives></inline-formula> according to a random permutation test. Hollow dots represent brave animals that did not pass. We decided to model these animals as brave since they had ï»¿<inline-formula><alternatives><mml:math id="inf26"><mml:semantics><mml:mrow><mml:mi>ğ‘¦</mml:mi><mml:mo class="MathClass-rel" stretchy="false">&gt;</mml:mo><mml:mn>1.5</mml:mn></mml:mrow></mml:semantics></mml:math><tex-math id="inft26">\begin{document}$y \gt 1.5$\end{document}</tex-math></alternatives></inline-formula> and hence a relatively clear confident-peak to confident-steady-state transition point. Modeling them as intermediate animals instead would not have significantly affected our results. Black dots are intermediate animals. They did not pass the Benjaminiâ€“Hochberg procedure for either ï»¿ï»¿<inline-formula><alternatives><mml:math id="inf27"><mml:semantics><mml:mrow><mml:mi>ğ‘¦</mml:mi><mml:mo class="MathClass-rel" stretchy="false">&gt;</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:semantics></mml:math><tex-math id="inft27">\begin{document}$y \gt 1$\end{document}</tex-math></alternatives></inline-formula> or ï»¿ï»¿<inline-formula><alternatives><mml:math id="inf28"><mml:semantics><mml:mrow><mml:mi>ğ‘¦</mml:mi><mml:mo class="MathClass-rel" stretchy="false">&lt;</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:semantics></mml:math><tex-math id="inft28">\begin{document}$y \lt 1$\end{document}</tex-math></alternatives></inline-formula>.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-100366-fig2-v1.tif"/></fig></sec><sec id="s2-2"><title>A Bayes-adaptive model-based model for exploration and timidity</title><sec id="s2-2-1"><title>State description</title><p>We use a model-based Bayes-adaptive reinforcement learning model (BAMDP) to provide a mechanistic account of the behavior of the mice under threat of predation. This extends the model-free description of threat in <xref ref-type="bibr" rid="bib2">Akiti et al., 2022</xref> by constructing various mechanisms to explain additional facets of the dynamics of the behavior.</p><p>Underlying the BAMDP is a standard multi-step decision-making problem of the sort that is the focus of a huge wealth of studies (<xref ref-type="bibr" rid="bib61">Russell and Norvig, 2016</xref>). We cartoon the problem with the four real and four counterfactual states shown in <xref ref-type="fig" rid="fig3">Figure 3</xref>. The nest is a place of safety, modeling all places in the environment away from the object, ignoring, for instance, the change to thigmotactic behavior that the mice exhibit when the object is introduced. The animal can choose to stay at the nest (possibly for multiple steps) or choose to approach the object. For convenience, we adopt <xref ref-type="bibr" rid="bib2">Akiti et al., 2022</xref>â€™s binary classification of approach, while acknowledging the substantial simplification this classification entails (a fuller but more complex characterization of approach would be continuous and multidimensional). We represent the tail-behind (respectively, tail-exposed) approach as transitioning to the cautious (respectively, confident) object state.</p><fig id="fig3" position="float"><label>Figure 3.</label><caption><title>Markov decision process underlying the Bayes-adaptive Markov decision process (BAMDP) model.</title><p>Four real (nest, cautious object, confident object, retreat) and three imagined (cautious detect, confident detect, dead) states. Agent actions are italicized. Blue arrows indicate (possibly stochastic) transitions caused by agent actions. Green arrows indicate (possibly stochastic) forced transitions. A cautious approach provides less informational reward ï»¿<inline-formula><alternatives><mml:math id="inf29"><mml:semantics><mml:mrow><mml:msub><mml:mrow><mml:mi>ğ‘Ÿ</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:mo class="MathClass-rel" stretchy="false">&lt;</mml:mo><mml:msub><mml:mrow><mml:mi>ğ‘Ÿ</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:semantics></mml:math><tex-math id="inft29">\begin{document}$r_2 \lt r_1$\end{document}</tex-math></alternatives></inline-formula> but has a smaller chance of death ï»¿<inline-formula><alternatives><mml:math id="inf30"><mml:semantics><mml:mrow><mml:msub><mml:mrow><mml:mi>ğ‘</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:mo class="MathClass-rel" stretchy="false">&lt;</mml:mo><mml:msub><mml:mrow><mml:mi>ğ‘</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:semantics></mml:math><tex-math id="inft30">\begin{document}$p_2 \lt p_1$\end{document}</tex-math></alternatives></inline-formula> compared to a confident approach. Travel and dying costs are not shown.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-100366-fig3-v1.tif"/></fig><p>At an approach state, the modeled agent can either stay or return to the nest via the retreat state; the latter happens anyhow after four steps. The animal also imagines the (in reality, counterfactual) possibility of being detected by a potential predator. It can then either manage to escape back to the nest or alternatively expire. We parameterize costs associated with the various movements and also the probability of unsuccessful escape starting from confident (<inline-formula><alternatives><mml:math id="inf31"><mml:semantics><mml:mrow><mml:msub><mml:mrow><mml:mi>ğ‘</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:semantics></mml:math><tex-math id="inft31">\begin{document}$p_1$\end{document}</tex-math></alternatives></inline-formula>) or cautious (<inline-formula><alternatives><mml:math id="inf32"><mml:semantics><mml:mrow><mml:msub><mml:mrow><mml:mi>ğ‘</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:mo class="MathClass-rel" stretchy="false">&lt;</mml:mo><mml:msub><mml:mrow><mml:mi>ğ‘</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:semantics></mml:math><tex-math id="inft32">\begin{document}$p_2 \lt p_1$\end{document}</tex-math></alternatives></inline-formula>) approach.</p><p>We describe the dilemma between a cautious and a confident approach as a calculation of the risk and reward trade-off between the two types of approaches. A cautious approach (the â€˜cautious objectâ€™ state) has a lower (informational) reward (e.g. because in the cautious state the animal spends more cognitive effort monitoring for lurking predators rather than exploring the object). However, a cautious approach leads to a lower probability of expiring if detected than does a confident approach (the â€˜cautious objectâ€™ state) (e.g. because in the cautious state the animal is better poised to escape). Risk aversion modulates the agentâ€™s choice of approach type.</p><p>The next sections describe the components of the BAMDP model: a characterization of the time-dependent risk of predation, an informational reward for exploration, and a method for handling risk sensitivity. Finally, we will discuss the way we fitted individual mice and present a full analysis of their behavior. We report on recovery simulations in the supplement.</p><sec id="s2-2-1-1"><title>Modeling threat with a Bayesian, generalizing hazard function</title><p>While exploring the novel object in the â€˜objectâ€™ state, the decision problem allows for the possibility of detection, and then attack, by a predator whose appearance is governed by a temporal hazard function (see <xref ref-type="fig" rid="fig4">Figure 4</xref>).</p><fig id="fig4" position="float"><label>Figure 4.</label><caption><title>Hazard function learning for (<bold>a</bold>) brave and (<bold>b</bold>) timid animals.</title><p>Brave animals start with a flexible hazard prior with a low mean for <inline-formula><alternatives><mml:math id="inf33"><mml:semantics><mml:mrow><mml:msub><mml:mrow><mml:mi>â„</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:semantics></mml:math><tex-math id="inft33">\begin{document}$h_2$\end{document}</tex-math></alternatives></inline-formula>. This leads to longer bouts (first length 2, then 3 and 4), which imply that the hazard posterior quickly approaches zero (here, after 10 bouts). Timid animals start with an inflexible hazard prior with a higher mean <inline-formula><alternatives><mml:math id="inf34"><mml:semantics><mml:mrow><mml:msub><mml:mrow><mml:mi>â„</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:semantics></mml:math><tex-math id="inft34">\begin{document}$h_2$\end{document}</tex-math></alternatives></inline-formula>, and are limited to length bouts. The hazard posterior only changes slightly after 10 bouts.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-100366-fig4-v1.tif"/></fig><p>Formally, the probability of detection given either cautious or confident approach is modeled using the hazard function <inline-formula><alternatives><mml:math id="inf35"><mml:semantics><mml:mrow><mml:msub><mml:mrow><mml:mi>â„</mml:mi></mml:mrow><mml:mrow><mml:mi>ğœ</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:semantics></mml:math><tex-math id="inft35">\begin{document}$h_{\tau}$\end{document}</tex-math></alternatives></inline-formula>, where <inline-formula><alternatives><mml:math id="inf36"><mml:semantics><mml:mrow><mml:mi>ğœ</mml:mi></mml:mrow></mml:semantics></mml:math><tex-math id="inft36">\begin{document}$\tau$\end{document}</tex-math></alternatives></inline-formula> is the number of steps the animal has so far spent at the object in the current bout. In a key simplification, this probability resets back to baseline upon a return to the nest. We treat the hazard function as being learned in a Bayesian manner, from the experience (in this case, of not being detected). We assume that the animal has the inductive bias that the hazard function is increasing over time, reflecting a potential predatorâ€™s evidence accumulation process about the prey. Therefore, we derive it from a succession of independent Beta-distributed random variables <inline-formula><alternatives><mml:math id="inf37"><mml:semantics><mml:mrow><mml:msub><mml:mrow><mml:mi>ğœƒ</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo class="MathClass-rel" stretchy="false">=</mml:mo><mml:mn>0</mml:mn><mml:mo class="MathClass-punc" stretchy="false">;</mml:mo><mml:msub><mml:mrow><mml:mi>ğœƒ</mml:mi></mml:mrow><mml:mrow><mml:mi>ğœ</mml:mi></mml:mrow></mml:msub><mml:mi>âˆ¼</mml:mi><mml:mstyle class="text"><mml:mtext>Beta</mml:mtext></mml:mstyle><mml:mo class="MathClass-open" stretchy="false">(</mml:mo><mml:msub><mml:mrow><mml:mi>ğœ‡</mml:mi></mml:mrow><mml:mrow><mml:mi>ğœ</mml:mi></mml:mrow></mml:msub><mml:mo class="MathClass-punc" stretchy="false">,</mml:mo><mml:msub><mml:mrow><mml:mi>ğœ</mml:mi></mml:mrow><mml:mrow><mml:mi>ğœ</mml:mi></mml:mrow></mml:msub><mml:mo class="MathClass-close" stretchy="false">)</mml:mo><mml:mo class="MathClass-punc" stretchy="false">,</mml:mo><mml:mi>ğœ</mml:mi><mml:mo class="MathClass-rel" stretchy="false">&gt;</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:semantics></mml:math><tex-math id="inft37">\begin{document}$\theta_1=0; \theta_{\tau}\sim\text{Beta}(\mu_{\tau}, \sigma_{\tau}), \tau \gt 1$\end{document}</tex-math></alternatives></inline-formula> as<disp-formula id="equ1"><label>(1)</label><alternatives><mml:math id="m1"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msub><mml:mi>h</mml:mi><mml:mrow><mml:mi>Ï„</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mn>1</mml:mn><mml:mo>âˆ’</mml:mo><mml:munderover><mml:mo movablelimits="false">âˆ</mml:mo><mml:mrow><mml:mi>j</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>Ï„</mml:mi></mml:mrow></mml:munderover><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mn>1</mml:mn><mml:mo>âˆ’</mml:mo><mml:msub><mml:mi>Î¸</mml:mi><mml:mi>j</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mstyle></mml:mrow></mml:mstyle></mml:math><tex-math id="t1">\begin{document}$$\displaystyle  h_{\tau} = 1 - \prod\limits_{j=1}^{\tau}{ (1 - \theta_j)} $$\end{document}</tex-math></alternatives></disp-formula><disp-formula id="equ2"><label>(2)</label><alternatives><mml:math id="m2"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mo>=</mml:mo><mml:msub><mml:mi>h</mml:mi><mml:mrow><mml:mi>Ï„</mml:mi><mml:mo>âˆ’</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mn>1</mml:mn><mml:mo>âˆ’</mml:mo><mml:msub><mml:mi>h</mml:mi><mml:mrow><mml:mi>Ï„</mml:mi><mml:mo>âˆ’</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:msub><mml:mi>Î¸</mml:mi><mml:mrow><mml:mi>Ï„</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:mspace width="2em"/><mml:mrow><mml:mtext>forÂ </mml:mtext><mml:mrow><mml:mi>Ï„</mml:mi><mml:mo>&gt;</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:mrow></mml:mstyle></mml:mrow></mml:mstyle></mml:math><tex-math id="t2">\begin{document}$$\displaystyle = h_{\tau-1} + \left(1-h_{\tau-1}\right)\theta_{\tau}, \qquad\text{for $\tau \gt 1$}$$\end{document}</tex-math></alternatives></disp-formula></p><p>rather as in what is known as a stick-breaking process. Note that, for convenience, we parameterize the Beta distribution in terms of its mean <inline-formula><alternatives><mml:math id="inf38"><mml:semantics><mml:mrow><mml:mi>ğœ‡</mml:mi></mml:mrow></mml:semantics></mml:math><tex-math id="inft38">\begin{document}$\mu$\end{document}</tex-math></alternatives></inline-formula> and standard deviation <inline-formula><alternatives><mml:math id="inf39"><mml:semantics><mml:mrow><mml:mi>ğœ</mml:mi></mml:mrow></mml:semantics></mml:math><tex-math id="inft39">\begin{document}$\sigma$\end{document}</tex-math></alternatives></inline-formula> rather than its pseudocounts, as is perhaps more common.</p><p><xref ref-type="disp-formula" rid="equ2">Equation 2</xref> shows that the hazard function is always increasing. As we will see, the duration of bouts at the object depends on the (discrete) slope of the hazard function, with steep hazard functions leading to short bouts. In our model, the agent can stay at the object 2, 3, or 4 turns (we take <inline-formula><alternatives><mml:math id="inf40"><mml:semantics><mml:mrow><mml:msub><mml:mrow><mml:mi>ğœƒ</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo class="MathClass-rel" stretchy="false">=</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:semantics></mml:math><tex-math id="inft40">\begin{document}$\theta_1=0$\end{document}</tex-math></alternatives></inline-formula> as a way of coding actual approach).We therefore sometimes refer to cautious â€“<italic>k</italic> or confidentâ€“<italic>k</italic> bouts in which the model animal spends <italic>k</italic> = {2, 3, 4} steps at the object. Hence, the collection of random variables, <inline-formula><alternatives><mml:math id="inf41"><mml:semantics><mml:mrow><mml:msub><mml:mrow><mml:mi>â„</mml:mi></mml:mrow><mml:mrow><mml:mi>ğœ</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:semantics></mml:math><tex-math id="inft41">\begin{document}$h_\tau$\end{document}</tex-math></alternatives></inline-formula>, is derived from six parameters (the mean <inline-formula><alternatives><mml:math id="inf42"><mml:semantics><mml:mrow><mml:msub><mml:mrow><mml:mi>ğœ‡</mml:mi></mml:mrow><mml:mrow><mml:mi>ğœ</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:semantics></mml:math><tex-math id="inft42">\begin{document}$\mu_\tau$\end{document}</tex-math></alternatives></inline-formula> and the standard deviation <inline-formula><alternatives><mml:math id="inf43"><mml:semantics><mml:mrow><mml:msub><mml:mrow><mml:mi>ğœ</mml:mi></mml:mrow><mml:mrow><mml:mi>ğœ</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:semantics></mml:math><tex-math id="inft43">\begin{document}$\sigma_\tau$\end{document}</tex-math></alternatives></inline-formula> of the Beta distribution for the turn). These start at initial prior values and are subject to an update from experience. Here, that experience is exclusively negative, since there is no actual predator; this implies that the update has a simple, closed form (see Methods). The animalsâ€™ initial ignorance, which is mitigated by learning, makes the problem a BAMDP, whose solution is a risk-averse itinerant policy.</p><p>A particular characteristic of the noisy-or hazard function of <xref ref-type="disp-formula" rid="equ1">Equation 1</xref> is that the derived bout duration increases progressively. This is because not being detected at <inline-formula><alternatives><mml:math id="inf44"><mml:semantics><mml:mrow><mml:mi>ğœ</mml:mi><mml:mo class="MathClass-rel" stretchy="false">=</mml:mo><mml:mn>2</mml:mn></mml:mrow></mml:semantics></mml:math><tex-math id="inft44">\begin{document}$\tau=2$\end{document}</tex-math></alternatives></inline-formula>, say, provides information that <inline-formula><alternatives><mml:math id="inf45"><mml:semantics><mml:mrow><mml:msub><mml:mrow><mml:mi>ğœƒ</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:semantics></mml:math><tex-math id="inft45">\begin{document}$\theta_2$\end{document}</tex-math></alternatives></inline-formula> is small, and so reduces the hazard function for longer bouts <inline-formula><alternatives><mml:math id="inf46"><mml:semantics><mml:mrow><mml:mi>ğœ</mml:mi><mml:mo class="MathClass-rel" stretchy="false">&gt;</mml:mo><mml:mn>2</mml:mn></mml:mrow></mml:semantics></mml:math><tex-math id="inft46">\begin{document}$\tau \gt 2$\end{document}</tex-math></alternatives></inline-formula>.</p><p><xref ref-type="fig" rid="fig4">Figure 4</xref> shows the fitted priors of a brave (top) and timid (bottom) animal, as well as the posteriors after ten exploratory bouts. The brave animal starts with a high variance prior. This flexibility allows it to transition from short, cautious bouts (duration <inline-formula><alternatives><mml:math id="inf47"><mml:semantics><mml:mrow><mml:mi>ğœ</mml:mi><mml:mo class="MathClass-rel" stretchy="false">=</mml:mo><mml:mn>2</mml:mn></mml:mrow></mml:semantics></mml:math><tex-math id="inft47">\begin{document}$\tau=2$\end{document}</tex-math></alternatives></inline-formula>) to longer confident bouts (duration <inline-formula><alternatives><mml:math id="inf48"><mml:semantics><mml:mrow><mml:mi>ğœ</mml:mi><mml:mo class="MathClass-rel" stretchy="false">=</mml:mo><mml:mn>3</mml:mn><mml:mo class="MathClass-punc" stretchy="false">,</mml:mo><mml:mn>4</mml:mn></mml:mrow></mml:semantics></mml:math><tex-math id="inft48">\begin{document}$\tau=3, 4$\end{document}</tex-math></alternatives></inline-formula>), reducing the hazard function to near zero. The timid animal has a low variance prior and does not stay long enough at the object to build sufficient confidence (only performing duration <inline-formula><alternatives><mml:math id="inf49"><mml:semantics><mml:mrow><mml:mi>ğœ</mml:mi><mml:mo class="MathClass-rel" stretchy="false">=</mml:mo><mml:mn>2</mml:mn></mml:mrow></mml:semantics></mml:math><tex-math id="inft49">\begin{document}$\tau=2$\end{document}</tex-math></alternatives></inline-formula> bouts). As a result, its posterior hazard function remains similar to its prior.</p></sec><sec id="s2-2-1-2"><title>Modeling the motivation to approach</title><p>We model the mouseâ€™s drive to approach the object as stemming from its belief that the object might be rewarding. In a fully Bayesian treatment, the agent would maintain a posterior over the possibility of rewards and would enjoy a conventional, informational, Bayes-adaptive exploration bonus encouraging it to approach the object. However, this would add substantial computational complexity. Thus, instead, we use a simple, heuristic, exploration bonus <inline-formula><alternatives><mml:math id="inf50"><mml:semantics><mml:mrow><mml:mi>ğº</mml:mi><mml:mo class="MathClass-open" stretchy="false">(</mml:mo><mml:mi>ğ‘¡</mml:mi><mml:mo class="MathClass-close" stretchy="false">)</mml:mo></mml:mrow></mml:semantics></mml:math><tex-math id="inft50">\begin{document}$G(t)$\end{document}</tex-math></alternatives></inline-formula> (<xref ref-type="bibr" rid="bib40">Kakade and Dayan, 2002</xref>). The model mouse moves from the â€˜nestâ€™ state to the â€˜objectâ€™ state when this exploration bonus exceeds the costs implied by the risk of being attacked.</p><p>We characterize the exploration bonus as coming from an initial â€˜poolâ€™ <inline-formula><alternatives><mml:math id="inf51"><mml:semantics><mml:mrow><mml:msub><mml:mrow><mml:mi>ğº</mml:mi></mml:mrow><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:semantics></mml:math><tex-math id="inft51">\begin{document}$G_0$\end{document}</tex-math></alternatives></inline-formula> that becomes depleted when the animal is at the object, as it experiences a lack of reward, but is replenished at a steady rate <inline-formula><alternatives><mml:math id="inf52"><mml:semantics><mml:mrow><mml:mi>ğ‘“</mml:mi></mml:mrow></mml:semantics></mml:math><tex-math id="inft52">\begin{document}$f$\end{document}</tex-math></alternatives></inline-formula> when the animal is at the nest, through forgetting or potential change. We model the animal as harvesting this exploration bonus pool more quickly under confident than cautious approaches, for instance, since it can pay more attention to the object (an issue captured in more explicit detail in the context of foraging by <xref ref-type="bibr" rid="bib43">Lloyd and Dayan, 2018</xref>). This underpins the transition between the two types of approach for non-timid animals. In simulations, when <inline-formula><alternatives><mml:math id="inf53"><mml:semantics><mml:mrow><mml:mi>ğº</mml:mi><mml:mo class="MathClass-open" stretchy="false">(</mml:mo><mml:mi>ğ‘¡</mml:mi><mml:mo class="MathClass-close" stretchy="false">)</mml:mo></mml:mrow></mml:semantics></mml:math><tex-math id="inft53">\begin{document}$G(t)$\end{document}</tex-math></alternatives></inline-formula> is high, the agent has a high motivation to explore the object, spending only a single turn in the nest state between bouts. In other words, the depletion from <inline-formula><alternatives><mml:math id="inf54"><mml:semantics><mml:mrow><mml:msub><mml:mrow><mml:mi>ğº</mml:mi></mml:mrow><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:semantics></mml:math><tex-math id="inft54">\begin{document}$G_0$\end{document}</tex-math></alternatives></inline-formula> substantially influences the time point at which approach makes a transition from peak to steady state; the steady-state time then depends on the dynamics of depletion (when at the object) and replenishment (when at the nest). In particular, in the steady-state phases, the agent must wait multiple turns at the nest for <inline-formula><alternatives><mml:math id="inf55"><mml:semantics><mml:mrow><mml:mi>ğº</mml:mi><mml:mo class="MathClass-open" stretchy="false">(</mml:mo><mml:mi>ğ‘¡</mml:mi><mml:mo class="MathClass-close" stretchy="false">)</mml:mo></mml:mrow></mml:semantics></mml:math><tex-math id="inft55">\begin{document}$G(t)$\end{document}</tex-math></alternatives></inline-formula> to regenerate so that informational reward once again exceeds the potential cost of hazard.</p><p>Finally, the animal is also motivated to approach by instrumental informational reward arising from the hazard function (which can be exploited to collect more future reward) â€“ according to a standard Bayes-adaptive bonus mechanism (<xref ref-type="bibr" rid="bib22">Duff, 2002b</xref>).</p></sec><sec id="s2-2-1-3"><title>Conditional value at risk sensitivity</title><p>Along with varying degrees of pessimism in their prior over the hazard function, the mice could have different degrees of risk sensitivity in the aspect of the return that they seek to optimize. There are various ways in which the mice might be risk-sensitive. Following <xref ref-type="bibr" rid="bib29">Gagne and Dayan, 2022</xref>, we consider a form called nested conditional value at risk (nCVaR). In general, CVaRÎ±, for risk sensitivity <inline-formula><alternatives><mml:math id="inf56"><mml:semantics><mml:mrow><mml:mn>0</mml:mn><mml:mi mathvariant="italic">â‰¤ğ›¼â‰¤</mml:mi><mml:mn>1</mml:mn></mml:mrow></mml:semantics></mml:math><tex-math id="inft56">\begin{document}$0\leq\alpha\leq1$\end{document}</tex-math></alternatives></inline-formula>, measures the expected value in the lower <italic>Î±</italic> quantile of returns â€“ thus over-weighting the worse outcomes. The lower <italic>Î±</italic>, the more extreme the risk aversion; with <inline-formula><alternatives><mml:math id="inf57"><mml:semantics><mml:mrow><mml:mi>ğ›¼</mml:mi><mml:mo class="MathClass-rel" stretchy="false">=</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:semantics></mml:math><tex-math id="inft57">\begin{document}$\alpha=1$\end{document}</tex-math></alternatives></inline-formula> being associated with the conventional, risk neutral, expected value of the return. The Bellman updates for BAMDP nCVaR section details the approximate optimization procedure concerned (<xref ref-type="bibr" rid="bib14">Chow et al., 2015</xref>; <xref ref-type="bibr" rid="bib36">Hau et al., 2023</xref>) â€“ it operates by upweighting the probabilities of outcomes with low returns â€“ which come here from detection and expiration. Thus, when <italic>Î±</italic> is low, confident and longer bouts are costly, inducing shorter, cautious ones. nCVaRÎ± affects behavior in a similar manner to pessimistic hazard priors, except that nCVaRÎ± acts on both the aleatoric uncertainty of expiring and epistemic uncertainty of detection, while priors only affect the latter. As we will see, despite this difference, we were not able to differentiate pessimistic priors from risk sensitivity using the data in <xref ref-type="bibr" rid="bib2">Akiti et al., 2022</xref>.</p></sec><sec id="s2-2-1-4"><title>Model fitting</title><p>The output of each simulation is a sequence of states which we use to derive summary statistics that can be compared directly with our abstraction of the behavior of a mouse (as in <xref ref-type="fig" rid="fig1">Figure 1</xref>). This requires us to model transition points in this behavior, and the times involved in each state.</p><p>In the model, the transition point from cautious to confident approach happens when the agent first ventures a confident approach; this switch is rarely reversed. Peak to steady-state transition points occur when the model mouse decreases its frequency of bouts, which tends to happen abruptly in the model. We fit the transition points in mouse data by mapping the length of a step in the model to wall-clock time. As in the abstraction of the experimental data, we average the duration (number of turns at the object) and frequency statistics in each phase. We characterize the relative frequencies of the bouts across phase transitions. Frequency mainly governs the total time at or away from the object and is formally defined as the inverse of the number of steps the model spends at the object and the nest.</p><p>We use a form of Approximate Bayesian Computation Sequential Monte Carlo (ABCSMC; <xref ref-type="bibr" rid="bib67">Toni et al., 2009</xref>) to fit the elements of our abstraction of the approach behavior of the mice (see Behavior phases and animal groups), namely change points, peak and steady-state durations as well as relative frequencies of bouts. See the Data fitting for details on the fitted statistics. At the core of ABCSMC is the ability to simulate the behavior of model mice for given parameters. We do this by solving the underlying BAMDP problem approximately using receding horizon tree search with a maximum depth of five steps (which covers the longest allowable bout, defined as a subsequence of states where the model mouse goes from the nest to the object and back to the nest).</p><p>The full set of parameters includes six for the prior over the hazard function (given that we limit to four the number of time steps the model mouse can stay at the object), the risk sensitivity parameter <inline-formula><alternatives><mml:math id="inf58"><mml:semantics><mml:mrow><mml:mi>ğ›¼</mml:mi></mml:mrow></mml:semantics></mml:math><tex-math id="inft58">\begin{document}$\alpha$\end{document}</tex-math></alternatives></inline-formula> for CVaRÎ±, the initial reward pool <inline-formula><alternatives><mml:math id="inf59"><mml:semantics><mml:mrow><mml:msub><mml:mrow><mml:mi>ğº</mml:mi></mml:mrow><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:semantics></mml:math><tex-math id="inft59">\begin{document}$G_0$\end{document}</tex-math></alternatives></inline-formula> and the forgetting rate <inline-formula><alternatives><mml:math id="inf60"><mml:semantics><mml:mrow><mml:mi>ğ‘“</mml:mi></mml:mrow></mml:semantics></mml:math><tex-math id="inft60">\begin{document}$f$\end{document}</tex-math></alternatives></inline-formula>.</p></sec></sec></sec><sec id="s2-3"><title>Explaining exploration schedules with fitted model parameters</title><sec id="s2-3-1"><title>A spectrum of risk-sensitive exploration trajectories</title><p><xref ref-type="fig" rid="fig5">Figure 5</xref> shows model fits on the 26 mice from <xref ref-type="bibr" rid="bib2">Akiti et al., 2022</xref>. The animal ranking is sorted first by animal group, and second by total time spent near the object. We call this ranking the group-timidity animal index â€“ it slightly differs from the timidity index used in <xref ref-type="bibr" rid="bib2">Akiti et al., 2022</xref> which is only based on total time spent near the object. The model captures many details of the data across the entire spectrum of courage to timidity, explaining the behavior mechanistically. Differing schedules of exploration emerge because of the battle between learning about threat and reward. All animals initially assess risk with a cautious approach, since the costs of potential predation significantly outweigh potential rewards. Brave animals assess risk either with short (length 2 bouts) or medium (length 3 bouts) depending on the hazard priors (<xref ref-type="fig" rid="fig6">Figure 6a and b versus c and d</xref>). If <inline-formula><alternatives><mml:math id="inf61"><mml:semantics><mml:mrow><mml:mi>ğ¸</mml:mi><mml:mo class="MathClass-open" stretchy="false">[</mml:mo><mml:msub><mml:mrow><mml:mi>â„</mml:mi></mml:mrow><mml:mrow><mml:mn>3</mml:mn></mml:mrow></mml:msub><mml:mo class="MathClass-close" stretchy="false">]</mml:mo></mml:mrow></mml:semantics></mml:math><tex-math id="inft61">\begin{document}$E[h_3]$\end{document}</tex-math></alternatives></inline-formula> is high, then the animal performs cautious length 2 bouts, otherwise, it performs cautious length 3 bouts. With more bout experience, the posterior hazard function becomes more optimistic (since there is no actual predator to observe; <xref ref-type="fig" rid="fig4">Figure 4</xref>), empowering it to take on more risk by staying even longer at the object and performing confident approach. Animals with low <inline-formula><alternatives><mml:math id="inf62"><mml:semantics><mml:mrow><mml:mi>ğ¸</mml:mi><mml:mo class="MathClass-open" stretchy="false">[</mml:mo><mml:msub><mml:mrow><mml:mi>â„</mml:mi></mml:mrow><mml:mrow><mml:mn>4</mml:mn></mml:mrow></mml:msub><mml:mo class="MathClass-close" stretchy="false">]</mml:mo></mml:mrow></mml:semantics></mml:math><tex-math id="inft62">\begin{document}$E[h_4]$\end{document}</tex-math></alternatives></inline-formula> perform the longest, confident, length 4 bouts instead of length 3 bouts (<xref ref-type="fig" rid="fig6">Figure 6a and c versus b and d</xref>). How long brave animals spend assessing risk depends on hazard priors and the risk sensitivity: nCVaRâ€™s <inline-formula><alternatives><mml:math id="inf63"><mml:semantics><mml:mrow><mml:mi>ğ›¼</mml:mi></mml:mrow></mml:semantics></mml:math><tex-math id="inft63">\begin{document}$\alpha$\end{document}</tex-math></alternatives></inline-formula>.</p><fig id="fig5" position="float"><label>Figure 5.</label><caption><title>Summary of model fit.</title><p>Left panels: minute-to-minute time the animals spend within 7 cm of the novel object (top), duration (middle), and frequency (bottom). There are 26 animals (one per row) sorted by the group-timidity animal index (see A spectrum of risk-sensitive exploration trajectories). Central panels: the same values averaged over behavioral phases. Right panels: time, duration, and frequency of bouts generated as sample trajectories from the individual fits of the Bayes-adaptive Markov decision process (BAMDP) model. Legend: green/blue distinguishes cautious and confident bouts. The intensity of colors indicates higher values, and gray indicates zeros.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-100366-fig5-v1.tif"/></fig><fig id="fig6" position="float"><label>Figure 6.</label><caption><title>The bout durations of brave animals depend on the hazard prior.</title><p>(<bold>a</bold>) Brave animals that initially perform cautious-2 bouts, then confident-3 bouts. The prior mean <inline-formula><alternatives><mml:math id="inf64"><mml:semantics><mml:mrow><mml:msub><mml:mrow><mml:mi>ğœ‡</mml:mi></mml:mrow><mml:mrow><mml:mn>3</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:semantics></mml:math><tex-math id="inft64">\begin{document}$\mu_3$\end{document}</tex-math></alternatives></inline-formula> for <inline-formula><alternatives><mml:math id="inf65"><mml:semantics><mml:mrow><mml:mi>ğœ</mml:mi><mml:mo class="MathClass-rel" stretchy="false">=</mml:mo><mml:mn>3</mml:mn></mml:mrow></mml:semantics></mml:math><tex-math id="inft65">\begin{document}$\tau=3$\end{document}</tex-math></alternatives></inline-formula> is higher than in (<bold>c</bold>) because there is some hazard to overcome before the animal does a duration-3 bout. Blue indicates individual animals and black indicates the mean. The y-axis <inline-formula><alternatives><mml:math id="inf66"><mml:semantics><mml:mrow><mml:mi>ğ¸</mml:mi><mml:mo class="MathClass-open" stretchy="false">[</mml:mo><mml:msub><mml:mrow><mml:mi>ğœ‡</mml:mi></mml:mrow><mml:mrow><mml:mi>ğœ</mml:mi></mml:mrow></mml:msub><mml:mo class="MathClass-close" stretchy="false">]</mml:mo></mml:mrow></mml:semantics></mml:math><tex-math id="inft66">\begin{document}$E[\mu_\tau]$\end{document}</tex-math></alternatives></inline-formula>, shows <inline-formula><alternatives><mml:math id="inf67"><mml:semantics><mml:mrow><mml:msub><mml:mrow><mml:mi>ğœ‡</mml:mi></mml:mrow><mml:mrow><mml:mi>ğœ</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:semantics></mml:math><tex-math id="inft67">\begin{document}$\mu_\tau$\end{document}</tex-math></alternatives></inline-formula> averaged over the Approximate Bayesian Computation Sequential Monte Carlo (ABCSMC) posterior particles for each animal. (<bold>b</bold>) Cautious-2 then confident-4 animals. Since the mean <inline-formula><alternatives><mml:math id="inf68"><mml:semantics><mml:mrow><mml:msub><mml:mrow><mml:mi>ğœ‡</mml:mi></mml:mrow><mml:mrow><mml:mn>4</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:semantics></mml:math><tex-math id="inft68">\begin{document}$\mu_4$\end{document}</tex-math></alternatives></inline-formula> prior is low, once the animal overcomes the <inline-formula><alternatives><mml:math id="inf69"><mml:semantics><mml:mrow><mml:mi>ğœ</mml:mi><mml:mo class="MathClass-rel" stretchy="false">=</mml:mo><mml:mn>2</mml:mn></mml:mrow></mml:semantics></mml:math><tex-math id="inft69">\begin{document}$\tau=2$\end{document}</tex-math></alternatives></inline-formula> hazard, it quickly transitions from duration 2 to 4. (<bold>c</bold>) Cautious-3, then confident-3 animals. These animals are fitted with a low <inline-formula><alternatives><mml:math id="inf70"><mml:semantics><mml:mrow><mml:msub><mml:mrow><mml:mi>ğœ‡</mml:mi></mml:mrow><mml:mrow><mml:mn>3</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:semantics></mml:math><tex-math id="inft70">\begin{document}$\mu_3$\end{document}</tex-math></alternatives></inline-formula> prior and high <inline-formula><alternatives><mml:math id="inf71"><mml:semantics><mml:mrow><mml:msub><mml:mrow><mml:mi>ğœ‡</mml:mi></mml:mrow><mml:mrow><mml:mn>4</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:semantics></mml:math><tex-math id="inft71">\begin{document}$\mu_4$\end{document}</tex-math></alternatives></inline-formula> prior because they never perform duration-4 bouts. (<bold>d</bold>) Cautious-3 then confident-4 animals. Since the <inline-formula><alternatives><mml:math id="inf72"><mml:semantics><mml:mrow><mml:msub><mml:mrow><mml:mi>ğœ‡</mml:mi></mml:mrow><mml:mrow><mml:mn>3</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:semantics></mml:math><tex-math id="inft72">\begin{document}$\mu_3$\end{document}</tex-math></alternatives></inline-formula> prior is lower than in (<bold>b</bold>), these animals begin with duration-3 bouts.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-100366-fig6-v1.tif"/></fig><p><xref ref-type="fig" rid="fig7">Figure 7</xref> shows that the fitted hazard priors and risk sensitivity relate to the group-timidity animal index. Brave animals are fitted with higher <inline-formula><alternatives><mml:math id="inf73"><mml:semantics><mml:mrow><mml:mi>ğ›¼</mml:mi></mml:mrow></mml:semantics></mml:math><tex-math id="inft73">\begin{document}$\alpha$\end{document}</tex-math></alternatives></inline-formula> and a low slope and high variance (flexibility) hazard prior. In other words, the model brave mouse believes that the hazard probability for long bouts is low in its environment. Timid animals are fitted by lower <italic>Î±</italic> and a higher slope, inflexible hazard prior. The parameters for intermediate animals lie between those for brave and timid animals.</p><fig id="fig7" position="float"><label>Figure 7.</label><caption><title>Group-level and within-group variation in fitted risk-sensitivity and hazard priors.</title><p>(<bold>a</bold>) nCVaRâ€™s <italic>Î±</italic> versus the group-timidity animal index ranking defined in A spectrum of risk-sensitive exploration trajectories. Color indicates the animal group. More timid animals are generally fitted by a lower <italic>Î±</italic>. Prior hazard parameter for <italic>t</italic> = 2 (<bold>b</bold>), <italic>t</italic> = 3 (<bold>c</bold>), and <italic>t</italic> = 4 (<bold>d</bold>) versus timidity ranking. Dots indicate the mean; the probability density is represented by color where darker means higher density regions. The <italic>t</italic> = 2 prior mean is similar across all animals (timid = <inline-formula><alternatives><mml:math id="inf74"><mml:semantics><mml:mrow><mml:mn>0.28</mml:mn><mml:mi>Â±</mml:mi><mml:mn>0.02</mml:mn></mml:mrow></mml:semantics></mml:math><tex-math id="inft74">\begin{document}$0.28 \pm0.02$\end{document}</tex-math></alternatives></inline-formula>, intermediate = <inline-formula><alternatives><mml:math id="inf75"><mml:semantics><mml:mrow><mml:mn>0.26</mml:mn><mml:mi>Â±</mml:mi><mml:mn>0.04</mml:mn></mml:mrow></mml:semantics></mml:math><tex-math id="inft75">\begin{document}$0.26 \pm0.04$\end{document}</tex-math></alternatives></inline-formula>, brave = <inline-formula><alternatives><mml:math id="inf76"><mml:semantics><mml:mrow><mml:mn>0.22</mml:mn><mml:mi>Â±</mml:mi><mml:mn>0.08</mml:mn></mml:mrow></mml:semantics></mml:math><tex-math id="inft76">\begin{document}$0.22 \pm0.08$\end{document}</tex-math></alternatives></inline-formula>) explaining the short, cautious bouts all animals initially use to assess risk. However, timid animals are best fit with lower variance (inflexible) and higher <italic>t</italic> = 3 and <italic>t</italic> = 4 prior means. This leads to shorter, cautious bouts in the long run. Brave animals are fitted by a low slope (indicated by lower mean for <italic>t</italic> = 3 and <italic>t</italic> = 4) and high variance (flexible) hazard prior. This allows them to perform longer bouts over time. <italic>t</italic> = 4 mean is low (panel d) for brave animals that perform length 4 bouts. Like brave animals, most intermediate animals have flexible, gradual hazards up to <italic>t</italic> = 3.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-100366-fig7-v1.tif"/></fig><p><inline-formula><alternatives><mml:math id="inf77"><mml:semantics><mml:mrow><mml:msub><mml:mrow><mml:mi>ğº</mml:mi></mml:mrow><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:semantics></mml:math><tex-math id="inft77">\begin{document}$G_0$\end{document}</tex-math></alternatives></inline-formula> determines how much time brave animals spend in the peak-confident exploration phase, or the peak to steady-state change point. Animals with larger <inline-formula><alternatives><mml:math id="inf78"><mml:semantics><mml:mrow><mml:msub><mml:mrow><mml:mi>ğº</mml:mi></mml:mrow><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:semantics></mml:math><tex-math id="inft78">\begin{document}$G_0$\end{document}</tex-math></alternatives></inline-formula> tend to have high bout frequencies for a longer period (see <xref ref-type="fig" rid="fig8">Figure 8</xref>). Finally, how often brave animals revisit the object, which is related to the relative steady-state frequency, is determined by the forgetting rate.</p><fig id="fig8" position="float"><label>Figure 8.</label><caption><title>Influence of exploration pool and forgetting rate on steady-state behavior.</title><p>(<bold>a</bold>) The relationship between <inline-formula><alternatives><mml:math id="inf79"><mml:semantics><mml:mrow><mml:msub><mml:mrow><mml:mi>ğº</mml:mi></mml:mrow><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:semantics></mml:math><tex-math id="inft79">\begin{document}$G_0$\end{document}</tex-math></alternatives></inline-formula> and the peak to steady-state change point for brave animals. The best fit line is shown in black. Higher <inline-formula><alternatives><mml:math id="inf80"><mml:semantics><mml:mrow><mml:msub><mml:mrow><mml:mi>ğº</mml:mi></mml:mrow><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:semantics></mml:math><tex-math id="inft80">\begin{document}$G_0$\end{document}</tex-math></alternatives></inline-formula> means the agent explores longer, hence postponing the change point. (<bold>b</bold>) <inline-formula><alternatives><mml:math id="inf81"><mml:semantics><mml:mrow><mml:msub><mml:mrow><mml:mi>ğº</mml:mi></mml:mrow><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:semantics></mml:math><tex-math id="inft81">\begin{document}$G_0$\end{document}</tex-math></alternatives></inline-formula> versus peak to steady-state change point for timid animals. (<bold>c</bold>) Forgetting rate versus steady-state turns at the nest state for brave animals. A higher forgetting rate leads to quicker replenishment of the exploration pool and hence fewer turns at the nest before approaching the object. (<bold>d</bold>) Forgetting rate versus turns at nest timid animal. All correlations are significant with <inline-formula><alternatives><mml:math id="inf82"><mml:semantics><mml:mrow><mml:mi>ğ‘</mml:mi><mml:mo class="MathClass-rel" stretchy="false">&lt;</mml:mo><mml:mn>0.002</mml:mn></mml:mrow></mml:semantics></mml:math><tex-math id="inft82">\begin{document}$p \lt 0.002$\end{document}</tex-math></alternatives></inline-formula>.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-100366-fig8-v1.tif"/></fig><p>Timid animals have short bouts and continue to assess risk with a cautious approach in the steady state. <xref ref-type="fig" rid="fig7">Figure 7</xref> shows that their hazard priors are inflexible (low variance), with a high slope, and that they have low <italic>Î±</italic>. The priors are slow to update, and risk sensitivity causes timid agents to overestimate the probability of bad outcomes, leading to their prolonged cautious behavior. Hence, the reward exploration pool is depleted (i.e. the agent transitions to the steady-state phase) before the agent overcomes its priors. This particular dynamic of approach-drive and hazard function updating leads to self-censoring and neophobia. In the steady-state phase, the agent stays long periods at the nest (how long depends again on the forgetting rate). As a result, the animal (at least during the course of the experiment) never accumulates sufficient evidence to learn the safety of the object or if the object yields rewards. Akiti et al.â€™s experiment did not last long enough to answer the question of whether all animals, even the most timid ones, eventually perform confident approach. Our model predicts that they will since the agent only accumulates negative evidence for the hazard function. However, with sufficiently low <inline-formula><alternatives><mml:math id="inf83"><mml:semantics><mml:mrow><mml:mi>ğ›¼</mml:mi></mml:mrow></mml:semantics></mml:math><tex-math id="inft83">\begin{document}$\alpha$\end{document}</tex-math></alternatives></inline-formula> or pessimistic priors, this may take a very long time.</p><p>Intermediate animals, like brave animals, eventually switch to a confident approach to maximize information gained about potential rewards. Similar to brave animals, the cautious to confident transition tends to be later with lower <inline-formula><alternatives><mml:math id="inf84"><mml:semantics><mml:mrow><mml:mi>ğ›¼</mml:mi></mml:mrow></mml:semantics></mml:math><tex-math id="inft84">\begin{document}$\alpha$\end{document}</tex-math></alternatives></inline-formula> and steeper, less flexible priors. Intermediate animals perform both cautious and confident bouts with medium duration. This is captured by a hazard prior with smaller <inline-formula><alternatives><mml:math id="inf85"><mml:semantics><mml:mrow><mml:mi>ğ¸</mml:mi><mml:mo class="MathClass-open" stretchy="false">[</mml:mo><mml:msub><mml:mrow><mml:mi>â„</mml:mi></mml:mrow><mml:mrow><mml:mn>3</mml:mn></mml:mrow></mml:msub><mml:mo class="MathClass-close" stretchy="false">]</mml:mo></mml:mrow></mml:semantics></mml:math><tex-math id="inft85">\begin{document}$E[h_3]$\end{document}</tex-math></alternatives></inline-formula> and larger <inline-formula><alternatives><mml:math id="inf86"><mml:semantics><mml:mrow><mml:mi>ğ¸</mml:mi><mml:mo class="MathClass-open" stretchy="false">[</mml:mo><mml:msub><mml:mrow><mml:mi>â„</mml:mi></mml:mrow><mml:mrow><mml:mn>4</mml:mn></mml:mrow></mml:msub><mml:mo class="MathClass-close" stretchy="false">]</mml:mo></mml:mrow></mml:semantics></mml:math><tex-math id="inft86">\begin{document}$E[h_4]$\end{document}</tex-math></alternatives></inline-formula>. The percentage of time spent at the object is relatively constant throughout the experiment for intermediate animals. This can be explained by either large <inline-formula><alternatives><mml:math id="inf87"><mml:semantics><mml:mrow><mml:msub><mml:mrow><mml:mi>ğº</mml:mi></mml:mrow><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:semantics></mml:math><tex-math id="inft87">\begin{document}$G_0$\end{document}</tex-math></alternatives></inline-formula> or a high forgetting rate. In other words, the animal is either slow to update its belief about the potential reward at the object, or it expects the reward probability to change quickly.</p><p><xref ref-type="fig" rid="fig5">Figure 5</xref> also illustrates several limitations of the model. In particular, the duration of bouts can only increase, whereas a few animals exhibit decreasing bout duration between confident-peak and confident-steady-state phases. Furthermore, the model has trouble capturing abrupt changes in duration (from 2 turns to 4) coinciding with an animalâ€™s transition from cautious to confident approach.</p><sec id="s2-3-1-1"><title>Risk sensitivity versus prior belief pessimism</title><p>We found that risk sensitivity and prior pessimism could not be teased apart in our model fits. This is illustrated in <xref ref-type="fig" rid="fig9">Figure 9</xref>. In the ABCSMC posterior distributions, nCVaRâ€™s <inline-formula><alternatives><mml:math id="inf88"><mml:semantics><mml:mrow><mml:mi>ğ›¼</mml:mi></mml:mrow></mml:semantics></mml:math><tex-math id="inft88">\begin{document}$\alpha$\end{document}</tex-math></alternatives></inline-formula> is correlated with the mean <inline-formula><alternatives><mml:math id="inf89"><mml:semantics><mml:mrow><mml:msub><mml:mrow><mml:mi>ğœ‡</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:semantics></mml:math><tex-math id="inft89">\begin{document}$\mu_2$\end{document}</tex-math></alternatives></inline-formula> for timid and intermediate animals, <inline-formula><alternatives><mml:math id="inf90"><mml:semantics><mml:mrow><mml:msub><mml:mrow><mml:mi>ğœ‡</mml:mi></mml:mrow><mml:mrow><mml:mn>3</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:semantics></mml:math><tex-math id="inft90">\begin{document}$\mu_3$\end{document}</tex-math></alternatives></inline-formula> for cautious-2/confident-4 and cautious-2/confident-3 animals, and <inline-formula><alternatives><mml:math id="inf91"><mml:semantics><mml:mrow><mml:msub><mml:mrow><mml:mi>ğœ‡</mml:mi></mml:mrow><mml:mrow><mml:mn>4</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:semantics></mml:math><tex-math id="inft91">\begin{document}$\mu_4$\end{document}</tex-math></alternatives></inline-formula> for cautious-2/confident-4 and cautious-3/confident-4 animals. In other words, lower <inline-formula><alternatives><mml:math id="inf92"><mml:semantics><mml:mrow><mml:mi>ğ›¼</mml:mi></mml:mrow></mml:semantics></mml:math><tex-math id="inft92">\begin{document}$\alpha$\end{document}</tex-math></alternatives></inline-formula> (higher risk sensitivity) can be traded off against lower (more optimistic) priors to explain the observed risk aversion in animals.</p><fig id="fig9" position="float"><label>Figure 9.</label><caption><title>Non-identifiability of nCVaRâ€™s <italic>Î±</italic> against the hazard prior.</title><p>Animals are labeled using the group-timidity animal index. (<bold>a</bold>) The scatter plot shows the <italic>t</italic> = 2 prior mean (<inline-formula><alternatives><mml:math id="inf93"><mml:semantics><mml:mrow><mml:msub><mml:mrow><mml:mi>ğœ‡</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:semantics></mml:math><tex-math id="inft93">\begin{document}$\mu_2$\end{document}</tex-math></alternatives></inline-formula>) versus <italic>Î±</italic> for Approximate Bayesian Computation Sequential Monte Carlo (ABCSMC) particles of timid animal 1. The ellipse indicates one standard deviation in a Gaussian density model. Animal 1 (and timid animals generally) can be either fit with a higher <italic>Î±</italic> and a higher <inline-formula><alternatives><mml:math id="inf94"><mml:semantics><mml:mrow><mml:msub><mml:mrow><mml:mi>ğœ‡</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:semantics></mml:math><tex-math id="inft94">\begin{document}$\mu_2$\end{document}</tex-math></alternatives></inline-formula>, or a lower <italic>Î±</italic> and a lower <inline-formula><alternatives><mml:math id="inf95"><mml:semantics><mml:mrow><mml:msub><mml:mrow><mml:mi>ğœ‡</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:semantics></mml:math><tex-math id="inft95">\begin{document}$\mu_2$\end{document}</tex-math></alternatives></inline-formula>. The box-and-whisker plot illustrates the correlation between <inline-formula><alternatives><mml:math id="inf96"><mml:semantics><mml:mrow><mml:msub><mml:mrow><mml:mi>ğœ‡</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:semantics></mml:math><tex-math id="inft96">\begin{document}$\mu_2$\end{document}</tex-math></alternatives></inline-formula> and <italic>Î±</italic> across all timid animals. (<bold>b</bold>) The scatter plot shows an example intermediate animal 10; the box-and-whisker plot shows <inline-formula><alternatives><mml:math id="inf97"><mml:semantics><mml:mrow><mml:msub><mml:mrow><mml:mi>ğœ‡</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:semantics></mml:math><tex-math id="inft97">\begin{document}$\mu_2$\end{document}</tex-math></alternatives></inline-formula> versus <italic>Î±</italic> for the intermediate population. (<bold>c</bold>) The scatter plot shows an example animal 11 from the group containing cautious-2/confident-4 and cautious-2/confident-3 animals. This group of animals starts with duration = 2 bouts and hence must overcome the prior <inline-formula><alternatives><mml:math id="inf98"><mml:semantics><mml:mrow><mml:msub><mml:mrow><mml:mi>ğœ‡</mml:mi></mml:mrow><mml:mrow><mml:mn>3</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:semantics></mml:math><tex-math id="inft98">\begin{document}$\mu_3$\end{document}</tex-math></alternatives></inline-formula>. The box-and-whisker plot shows <inline-formula><alternatives><mml:math id="inf99"><mml:semantics><mml:mrow><mml:msub><mml:mrow><mml:mi>ğœ‡</mml:mi></mml:mrow><mml:mrow><mml:mn>3</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:semantics></mml:math><tex-math id="inft99">\begin{document}$\mu_3$\end{document}</tex-math></alternatives></inline-formula> versus <italic>Î±</italic> for the population. (<bold>d</bold>) The scatter plot shows an example animal 25 from the group containing cautious-2/confident-4 and cautious-3/confident-4 animals. This group of animals eventually performs duration = 4 bouts and hence must overcome the prior <inline-formula><alternatives><mml:math id="inf100"><mml:semantics><mml:mrow><mml:msub><mml:mrow><mml:mi>ğœ‡</mml:mi></mml:mrow><mml:mrow><mml:mn>4</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:semantics></mml:math><tex-math id="inft100">\begin{document}$\mu_4$\end{document}</tex-math></alternatives></inline-formula>. The box-and-whisker plot shows <inline-formula><alternatives><mml:math id="inf101"><mml:semantics><mml:mrow><mml:msub><mml:mrow><mml:mi>ğœ‡</mml:mi></mml:mrow><mml:mrow><mml:mn>4</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:semantics></mml:math><tex-math id="inft101">\begin{document}$\mu_4$\end{document}</tex-math></alternatives></inline-formula> versus <inline-formula><alternatives><mml:math id="inf102"><mml:semantics><mml:mrow><mml:mi>ğ›¼</mml:mi></mml:mrow></mml:semantics></mml:math><tex-math id="inft102">\begin{document}$\alpha$\end{document}</tex-math></alternatives></inline-formula> for the population. <inline-formula><alternatives><mml:math id="inf103"><mml:semantics><mml:mrow><mml:mi>ğ›¼</mml:mi></mml:mrow></mml:semantics></mml:math><tex-math id="inft103">\begin{document}$\alpha$\end{document}</tex-math></alternatives></inline-formula> and <inline-formula><alternatives><mml:math id="inf104"><mml:semantics><mml:mrow><mml:mi>ğœ‡</mml:mi></mml:mrow></mml:semantics></mml:math><tex-math id="inft104">\begin{document}$\mu$\end{document}</tex-math></alternatives></inline-formula> are correlated in the ABCSMC posterior for all animals and hence non-identifiable. <inline-formula><alternatives><mml:math id="inf105"><mml:semantics><mml:mrow><mml:mi>ğ‘</mml:mi><mml:mo class="MathClass-rel" stretchy="false">&lt;</mml:mo><mml:mn>0.05</mml:mn></mml:mrow></mml:semantics></mml:math><tex-math id="inft105">\begin{document}$p \lt 0.05$\end{document}</tex-math></alternatives></inline-formula> for all correlations.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-100366-fig9-v1.tif"/></fig><p>In ablation studies (not shown), we found that it is possible to fit the full range of the behavior equally well with a risk-neutral nCVaR1.0 objective, only varying the hazard priors (with their many extra parameters). There is a technical advantage of fitting both nCVaRÎ± and hazard priors to each animal, namely greater diversity in the particles discovered by ABCSMC.</p><p>By contrast, we found that nCVaRÎ± alone, with the same hazard prior for all animals, is incapable of fitting the full range of animal behavior (results not shown). This can be explained by the fact that nCVaRÎ± cannot model the different slopes in the hazard function. For example, a cautious-2/confident-3 animal must be modeled using a high value of <inline-formula><alternatives><mml:math id="inf106"><mml:semantics><mml:mrow><mml:msub><mml:mrow><mml:mi>ğœ‡</mml:mi></mml:mrow><mml:mrow><mml:mn>4</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:semantics></mml:math><tex-math id="inft106">\begin{document}$\mu_4$\end{document}</tex-math></alternatives></inline-formula>. Starting with the parameters for a cautious-2/confident-4 animal and decreasing <italic>Î±</italic> will not create a cautious-2/confident-3 animal. Instead, decreasing <italic>Î±</italic> will delay the cautious-to-confident transition of the cautious-2/confident-4 animal and eventually create a cautious-2 timid animal. Therefore, in our task, structured prior beliefs are required to model the detailed behavior of animals. It is not clear in general in which environments one can expect <italic>Î±</italic> and priors to be identifiable given the complex interaction of these two sources of risk sensitivity.</p></sec><sec id="s2-3-1-2"><title>Familiar object novel context</title><p>As a contrast to their main experiment, in which mice were exposed to an unfamiliar object in a novel context (UONC), <xref ref-type="bibr" rid="bib2">Akiti et al., 2022</xref> also looked at the consequences of exposing animals to a familiar object in a novel context (FONC), where the animals still habituate in the arena over 2 days but the combination of the object and arena is novel. We fit the behavior of the 9 FONC animals, and, as the closest match, compared this with that of the 11 brave animals in the UONC condition. <xref ref-type="fig" rid="fig10">Figure 10</xref> shows that there are one intermediate and eight brave FONC animals, with the latter having exploration schedules similar to the bravest UONC animals. The eight FONC animals have confident-peak and confident-steady-state phases, meaning their approach decreases in the steady state, suggesting that they are reinvestigating the familiar object for reward.</p><fig id="fig10" position="float"><label>Figure 10.</label><caption><title>Comparing the behavior of FONC and UONC conditions.</title><p>There are 9 FONC and 11 UONC brave animals (one per row). Left panels: minute-to-minute time the animals spend within 7 cm of the novel object (top), duration (middle), and frequency (bottom). Animals are again sorted by group-timidity animal index but split by experiment condition (UONC then FONC). Central panels: the same values averaged over behavioral phases. Right panels: time, duration, and frequency of bouts generated as sample trajectories from the individual fits of the Bayes-adaptive Markov decision process (BAMDP) model.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-100366-fig10-v1.tif"/></fig><p><xref ref-type="fig" rid="fig11">Figure 11</xref> compares the posteriors of the ABCSMC fit of brave UONC and FONC animals. The <italic>x</italic>-axis shows the group-timidity animal index, but split by experiment condition (UONC then FONC). Compared to brave UONC animals, FONC animals are fitted with higher nCVaRâ€™s <italic>Î±</italic> and lower hazard priors (average posterior parameters across animals are significantly different according to the Kolmogorovâ€“Smirnov test, <inline-formula><alternatives><mml:math id="inf107"><mml:semantics><mml:mrow><mml:mi>ğ‘</mml:mi><mml:mo class="MathClass-rel" stretchy="false">&lt;</mml:mo><mml:mn>0.05</mml:mn></mml:mrow></mml:semantics></mml:math><tex-math id="inft107">\begin{document}$p \lt 0.05$\end{document}</tex-math></alternatives></inline-formula>). Both the hazard prior means and variances are lower for the FONC animals, indicating these animals are more certain of the safety of the object compared to UONC animals. For three animals, the hazard prior means are nearly zero, indicating belief of almost certain safety. This is similar to the hazard function of a brave UONC animal at the end of the experiment. For the other six FONC animals, the hazard prior is high enough to warrant initial cautious bouts suggesting that the novelty of the context has increased their beliefs of the threat level of the familiar object. However, even these animals transition faster to a confident approach than the brave UONC animals. This can be seen in <xref ref-type="fig" rid="fig10">Figure 10</xref>. <xref ref-type="fig" rid="fig11">Figure 11b</xref> shows that FONC animals also have on average lower <inline-formula><alternatives><mml:math id="inf108"><mml:mstyle><mml:mrow><mml:mstyle displaystyle="false"><mml:mo stretchy="false">(</mml:mo><mml:mi>p</mml:mi><mml:mo>&lt;</mml:mo><mml:mn>0.05</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mstyle></mml:mrow></mml:mstyle></mml:math><tex-math id="inft108">\begin{document}$(p \lt 0.05)$\end{document}</tex-math></alternatives></inline-formula> exploration pool than brave UONC animals. Taken together, these results show that pre-exposure to the object decreases both the animalsâ€™ beliefs about potential hazards and their motivation to explore the object for reward.</p><fig id="fig11" position="float"><label>Figure 11.</label><caption><title>Approximate Bayesian Computation Sequential Monte Carlo (ABCSMC) parameter fits of the 9 FONC and 11 UONC animals (with the latter replotted from <xref ref-type="fig" rid="fig7">Figure 7</xref> for convenience).</title><p>The <italic>x</italic>-axis shows group-timidity animal index, but UONC and FONC animals are separated. (<bold>a</bold>) Average nCVaRâ€™s <italic>Î±</italic> over posterior particles of each animal. Color indicates the animal group. Dashed lines indicate the average (across animals) values of each condition (UONC brave or FONC brave). <inline-formula><alternatives><mml:math id="inf109"><mml:semantics><mml:mrow><mml:mi>ğ‘</mml:mi><mml:mstyle class="text"><mml:mtext>-values</mml:mtext></mml:mstyle></mml:mrow></mml:semantics></mml:math><tex-math id="inft109">\begin{document}$p\text{-values}$\end{document}</tex-math></alternatives></inline-formula> for the Kolmogorovâ€“Smirnov test of condition differences is shown. <inline-formula><alternatives><mml:math id="inf110"><mml:semantics><mml:mrow><mml:mi>ğ‘</mml:mi><mml:mo class="MathClass-rel" stretchy="false">&lt;</mml:mo><mml:mn>0.05</mml:mn></mml:mrow></mml:semantics></mml:math><tex-math id="inft110">\begin{document}$p \lt 0.05$\end{document}</tex-math></alternatives></inline-formula> and therefore the <italic>Î±</italic> values of brave FONC animals are significantly higher than those of brave UONC animals. (<bold>b</bold>) Exploration bonus pool, which is also significantly different between FONC and UONC animals. (<bold>c</bold>) Forgetting rate, which is not significantly different between the two conditions. Prior hazard parameter for <italic>t</italic> = 2 (<bold>d</bold>), <italic>t</italic> = 3 (<bold>e</bold>), and <italic>t</italic> = 4 (<bold>f</bold>). The probability density is represented by color where darker means higher density regions. Dots indicate the mean. Dashed lines indicate the average of mean values across animals, while dotted lines indicate the average of standard deviation values across animals. ï»¿<inline-formula><alternatives><mml:math id="inf111"><mml:semantics><mml:mrow><mml:mi>ğ‘</mml:mi><mml:mstyle class="text"><mml:mtext>-values</mml:mtext></mml:mstyle></mml:mrow></mml:semantics></mml:math><tex-math id="inft111">\begin{document}$p\text{-values}$\end{document}</tex-math></alternatives></inline-formula> testing the difference between the two conditionsâ€™ means and standard deviations is shown on the right-hand side and left-hand side of the plots, respectively. Brave FONC animals have both significantly lower hazard prior mean and standard deviation than brave UONC animals.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-100366-fig11-v1.tif"/></fig></sec></sec></sec></sec><sec id="s3" sec-type="discussion"><title>Discussion</title><p>We combined a Bayes-adaptive Markov decision process framework with beliefs about hazards, and a conditional value at risk objective to capture many facets of an abstraction of the substantially different risk-sensitive exploration of individual animals reported by <xref ref-type="bibr" rid="bib2">Akiti et al., 2022</xref>. In the model, behavior reflects a battle between learning about potential threat and potential reward (neither of which actually exists). The substantial individual variability in the schedules of exploratory approach was explained by different risk sensitivities, forgetting rates, exploration bonuses, and prior beliefs about an assumed hazard associated with a novel object. Neophilia arises from a form of optimism in the face of uncertainty, and neophobia from the hazard. Critically, the hazard function is generalizing (reducing the <inline-formula><alternatives><mml:math id="inf112"><mml:semantics><mml:mrow><mml:mi>ğ‘¡</mml:mi><mml:mo class="MathClass-rel" stretchy="false">=</mml:mo><mml:mn>2</mml:mn></mml:mrow></mml:semantics></mml:math><tex-math id="inft112">\begin{document}$t=2$\end{document}</tex-math></alternatives></inline-formula> hazard reduces the <inline-formula><alternatives><mml:math id="inf113"><mml:semantics><mml:mrow><mml:mi>ğ‘¡</mml:mi><mml:mo class="MathClass-rel" stretchy="false">=</mml:mo><mml:mn>4</mml:mn></mml:mrow></mml:semantics></mml:math><tex-math id="inft113">\begin{document}$t=4$\end{document}</tex-math></alternatives></inline-formula> hazard) and monotonic. The former property induces an increasing approach duration over time (<xref ref-type="bibr" rid="bib4">Arsenian, 1943</xref>). Furthermore, the exploration bonus associated with the object regenerates, as if the subjects consider its affordance to be non-stationary (<xref ref-type="bibr" rid="bib18">Dayan et al., 2000</xref>). This encourages even the most timid animals to continue revisiting it. Nevertheless, a main source of persistent timidity is a sort of path-dependent self-censoring (<xref ref-type="bibr" rid="bib19">Dayan et al., 2020</xref>). That is, the agents could be so pessimistic about the object that they never visit it for long enough to overturn their negative beliefs.</p><p>In our model, timid behavior can, in principle, arise from either excessive risk sensitivity or overly pessimistic priors about the hazard function. Indeed, CVaR is a probability distortion-based risk measure that is calculated by boosting the probabilities associated with the worst possibilities. Such boosting has obvious parallels with the effect of increasing prior expectations about those worst possibilities â€“ particularly if the consequence of the boosting is a path-dependent reluctance to gather the experience necessary to overwhelm the prior. Given their similar behavioral phenotypes in this task, we duly found that it was not possible to use the model to disentangle the extent to which priors versus values of <italic>Î±</italic> were responsible for the observed timidity/bravery. One key difference is that risk aversion continues to affect behavior at the asymptote of learning; something that might be revealed by due choice of a series of environments. Certainly, according to the model, forced exposure (<xref ref-type="bibr" rid="bib37">Huys et al., 2022</xref>) would hasten convergence to the true hazard function and the transition to confident approach.</p><p>Due to the complexity of the dataset, we made several rather substantial simplifying assumptions. First, the model employs a particular set of state abstractions, for instance, representing thigmotaxis as a notional â€˜nestâ€™ (<xref ref-type="bibr" rid="bib64">Simon et al., 1994</xref>). Motivated by tail-behind versus tail-exposed in <xref ref-type="bibr" rid="bib2">Akiti et al., 2022</xref>, we model approach using a dichotomy between cautious and confident approach states. This is likely a crude approximation to the continuous and multifaceted nature of animal approach behavior. For example, during approach, animals likely adjust their levels of vigilance continuously (or discretely; <xref ref-type="bibr" rid="bib43">Lloyd and Dayan, 2018</xref>) to monitor threat, and choose different velocities for movement, and different attentional strategies for inspecting the novel object. We hope future works will model these additional behavioral complexities, perhaps with additional internal states, and corroborate these states with neurobiological data.</p><p>Second, the model only allows the frequency of approach, and not its duration, to decrease during the steady-state phase â€“ some animals are better fit by decreasing duration. This limitation could be lifted in future models with, for example, a mechanism for boredom causing the animal to retreat when little potential reward remains at the object.</p><p>Third, the probability of being detected was the same between cautious and confident approaches, which may not be true in general. Note that the agent decides the type of approach before the bout and is incapable of switching from cautious to confident mid-bout or vice versa.</p><p>Fourth, we modeled the relative amount of time the animal spends at the object versus elsewhere in the environment, which depends on the differential risk in the two states. However, it is likely the animals avoid the novel object largely because of the object itself, rather than the potential danger associated with the arena since they spend much less time at the center of the arena during novelty than habituation days.</p><p>Finally, we restricted ourselves to a monotonic hazard function for the predator. It would be interesting to experiment with a non-monotonic hazard function instead, as would arise, for instance, if the agent believed that if the predator has not shown up after a long time, then there actually is no predator. Of course, a sophisticated predator would exploit the agentâ€™s inductive bias about the hazard function â€“ by waiting until the agentâ€™s posterior distribution has settled. In more general terms, the hazard function is a first-order approximation to a complex game-theoretic battle between prey and predator, which could be modeled, for instance, using an interactive IPOMDP (<xref ref-type="bibr" rid="bib32">Gmytrasiewicz and Doshi, 2005</xref>). How the predatorâ€™s belief about the whereabouts of the prey diminishes could also be modeled game-theoretically, leading to partial hazard resetting rather than the simplified complete resetting in our model.</p><p>Our account is model-based, with the mice assumed to be learning the statistics of the environment and engaging in prospective planning (<xref ref-type="bibr" rid="bib53">Mobbs et al., 2020</xref>). By contrast, <xref ref-type="bibr" rid="bib2">Akiti et al., 2022</xref> provide a model-free account of the same data. They suggest that the mice learn the values of threat using an analog of temporal difference learning (<xref ref-type="bibr" rid="bib66">Sutton, 1988</xref>) and explain individual variability as differences in value initialization (<xref ref-type="bibr" rid="bib2">Akiti et al., 2022</xref>). The initial values are generalizations from previous experiences with similar objects and are implemented by activity of dopamine in the TS responding to stimuli salience (<xref ref-type="bibr" rid="bib2">Akiti et al., 2022</xref>). By contrast, our model encompasses extra features of behavior such as bout duration, frequency, and type of approach â€“ ultimately arriving at a different mechanistic explanation of neophobia. In the context of our model, TS dopamine could still respond to the physical salience of the novel object but might then affect choices by determining the potential cost of the encountered threat (a parameter we did not explore here) or perhaps the prior on the hazard function. An analogous mechanism may set the exploration pool or the prior belief about reward â€“ perhaps involving projections from other dopamine neurons, which have been implicated in novelty in the context of exploration bonuses (<xref ref-type="bibr" rid="bib40">Kakade and Dayan, 2002</xref>) and information-seeking for reward (<xref ref-type="bibr" rid="bib54">Ogasawara et al., 2022</xref>; <xref ref-type="bibr" rid="bib10">Bromberg-Martin and Hikosaka, 2009</xref>).</p><p>CVaR is known to come in different flavors in the case of temporally extended behavior. <xref ref-type="bibr" rid="bib28">Gagne and Dayan, 2021</xref> introduce two alternative time-consistent formulations of CVaR: nested CVaR (nCVaR) and precommitted CVaR (pCVaR). nCVaR and pCVaR both enjoy Bellman equations which make it possible to compute approximately optimal policies without directly computing whole distributions of the outcomes. We use nCVaR in this study for its computational efficiency. There is, of course, great current interest in distributional reinforcement learning, which does acquire such whole distributions, not the least because of prominent observations linking non-linearities in the response functions of dopamine neurons to methods for learning distributions of outcomes (<xref ref-type="bibr" rid="bib16">Dabney et al., 2020</xref>; <xref ref-type="bibr" rid="bib47">Masset et al., 2023</xref>; <xref ref-type="bibr" rid="bib65">Sousa et al., 2023</xref>). One functional motivation for considering entire outcome distributions is the possibility of using them to determine risk-sensitive policies (<xref ref-type="bibr" rid="bib28">Gagne and Dayan, 2021</xref>). While it is possible to compute CVaR directly from return distributions, <xref ref-type="bibr" rid="bib28">Gagne and Dayan, 2021</xref> showed that this can lead to temporally inconsistent policies where the agent deviates from its original plans (the authors called this the fixed CVaR or fCVaR measure).</p><p>Rather further removed from our model-based methods is work from <xref ref-type="bibr" rid="bib3">Antonov and Dayan, 2023</xref>, who consider a model-free exploration strategy which exploits full return distributions to compute the value of perfect information which is used as a heuristic for trying actions with uncertain consequences. Future works can examine risk-sensitive versions of <xref ref-type="bibr" rid="bib3">Antonov and Dayan, 2023</xref>â€™s computationally efficient model-free algorithm as one solution to the burdensome computations in our model-based method.</p><p>As reported in <xref ref-type="bibr" rid="bib2">Akiti et al., 2022</xref>, animals in the FONC condition in which the object is familiar (though the context is less so) transition quickly to tail-exposed approach and therefore spend more time near the object compared to animals in the UONC condition. <xref ref-type="bibr" rid="bib2">Akiti et al., 2022</xref> models the FONC animals using low initial mean threat and high initial threat uncertainty. We directly compare the behavior of FONC animals against that of the 11 brave UONC animals, showing that FONC animals make choices that are comparable to the bravest UONC animals. FONC behavior is fit by significantly higher nCVaRâ€™s <inline-formula><alternatives><mml:math id="inf114"><mml:semantics><mml:mrow><mml:mi>ğ›¼</mml:mi></mml:mrow></mml:semantics></mml:math><tex-math id="inft114">\begin{document}$\alpha$\end{document}</tex-math></alternatives></inline-formula> than brave UONC behavior animals. This is surprising if we interpret <inline-formula><alternatives><mml:math id="inf115"><mml:semantics><mml:mrow><mml:mi>ğ›¼</mml:mi></mml:mrow></mml:semantics></mml:math><tex-math id="inft115">\begin{document}$\alpha$\end{document}</tex-math></alternatives></inline-formula> as a trait that is stable through time. Unfortunately, due to the non-identifiability between <inline-formula><alternatives><mml:math id="inf116"><mml:semantics><mml:mrow><mml:mi>ğ›¼</mml:mi></mml:mrow></mml:semantics></mml:math><tex-math id="inft116">\begin{document}$\alpha$\end{document}</tex-math></alternatives></inline-formula> and hazard priors, we cannot verify whether <inline-formula><alternatives><mml:math id="inf117"><mml:semantics><mml:mrow><mml:mi>ğ›¼</mml:mi></mml:mrow></mml:semantics></mml:math><tex-math id="inft117">\begin{document}$\alpha$\end{document}</tex-math></alternatives></inline-formula> is actually higher for FONC animals than UONC animals. FONC animals are also characterized by both lower hazard prior means and standard deviations compared to UONC animals, implying greater certainty about the objectâ€™s safety. Furthermore, FONC behavior is fitted with lower exploration pools than brave UONC behavior. Taken together, we can understand the FONC animals as having both lower uncertainty about hazard and reward compared to the brave UONC animals at the start of the experiment. However, the hazard and reward uncertainties are higher than what we might expect of UONC animals at the end of the experiment, suggesting the novel context modulates both of these uncertainties. However, heterogeneity exists between FONC individuals in terms of nCVaRâ€™s <inline-formula><alternatives><mml:math id="inf118"><mml:semantics><mml:mrow><mml:mi>ğ›¼</mml:mi></mml:mrow></mml:semantics></mml:math><tex-math id="inft118">\begin{document}$\alpha$\end{document}</tex-math></alternatives></inline-formula>, hazard priors, and exploration pool, which allows another possibility: that both hazard and reward uncertainty are restored by forgetting during the time that passed between pre-exposure and the experiment.</p><p>Our model-based account recovers several behavioral phenotypes in addition to those considered in <xref ref-type="bibr" rid="bib2">Akiti et al., 2022</xref>. First, intermittency in our model emerges from the fact that the (possibly CVaR perturbed) hazard function increases with time spent at the object. Therefore, it is rational for the model mice to retreat to the nest when the probability of detection becomes too high and wait until (they believe) the â€˜predator has forgotten about themâ€™, before venturing to the object again.</p><p>Second, we offer an alternative explanation for why animals avoid after risk assessment in a benign environment. In Akitiâ€™s model, timid animals perform risk assessment because of the delay in model-free value updating from the initial threat at the object (at timestep <inline-formula><alternatives><mml:math id="inf119"><mml:semantics><mml:mrow><mml:mi>ğ‘¡</mml:mi><mml:mo class="MathClass-rel" stretchy="false">=</mml:mo><mml:mn>10</mml:mn></mml:mrow></mml:semantics></mml:math><tex-math id="inft119">\begin{document}$t=10$\end{document}</tex-math></alternatives></inline-formula> in their account) to the time of decision (<inline-formula><alternatives><mml:math id="inf120"><mml:semantics><mml:mrow><mml:mi>ğ‘¡</mml:mi><mml:mo class="MathClass-rel" stretchy="false">=</mml:mo><mml:mn>8</mml:mn></mml:mrow></mml:semantics></mml:math><tex-math id="inft120">\begin{document}$t=8$\end{document}</tex-math></alternatives></inline-formula>). In our model, avoidance arises from a rational trade-off between potential risk and reward: timid animals perform risk assessment because of the potential reward at the object and having found none, cease to approach because, although potential threat is lower than at the outset, it still outweighs the even further-reduced potential reward. The same exhaustion of the exploration bonus explains why the brave animals decrease their approach during the steady state of engagement. If the potential reward is low, there is no reason to return to the object at the initial, high rate of engagement.</p><p>Third, the temporally evolving battle between reward and threat also explains why brave animals increase their duration of approach when transitioning from risk assessment to engagement. During a confident approach, the animals harvest the exploration pool faster, at the cost of an increased probability of expiring. For brave animals, the hazard posterior decreases faster than the depletion of the exploration pool, and hence brave animals decide to save on travel costs by exploring the object longer in each bout.</p><p>Fourth, timid animals return to the object in the steady state of â€˜avoidanceâ€™, albeit at a lower rate than during risk assessment. This was not considered in <xref ref-type="bibr" rid="bib2">Akiti et al., 2022</xref>â€™s account. In our model, timid animalsâ€™ steady-state approach is explained by the regenerating exploration pool. Such regeneration is natural if the animals assume that the environment is non-stationary, allowing reward structures to change and thus potentially repaying occasional returns to the object if the potential threat has become sufficiently low. Similarly, the animal may believe that the threat is non-stationary. Threat forgetting may act on longer time scales than reward forgetting in our studied environment and is one possible explanation for the initial non-zero hazard functions of some brave animals in the FONC condition.</p><p>Finally, our model shows the multi-faceted nature of timidity during exploration. Not only do animals differ in time spent near the object but also in how quickly they transition from cautious to confident approach and their duration and frequency of approach along their exploration schedules. These proxies for timidity are imperfectly correlated. Indeed, an animal could believe that short bouts (<inline-formula><alternatives><mml:math id="inf121"><mml:semantics><mml:mrow><mml:mi>ğœ</mml:mi><mml:mo class="MathClass-rel" stretchy="false">=</mml:mo><mml:mn>2</mml:mn></mml:mrow></mml:semantics></mml:math><tex-math id="inft121">\begin{document}$\tau=2$\end{document}</tex-math></alternatives></inline-formula>) are very safe while long bouts (<inline-formula><alternatives><mml:math id="inf122"><mml:semantics><mml:mrow><mml:mi>ğœ</mml:mi><mml:mo class="MathClass-rel" stretchy="false">=</mml:mo><mml:mn>4</mml:mn></mml:mrow></mml:semantics></mml:math><tex-math id="inft122">\begin{document}$\tau=4$\end{document}</tex-math></alternatives></inline-formula>) certainly lead to expiration.</p><p>Of course, agents do not need to be fully model-free or model-based. They can truncate model-based planning using model-free values at leaf nodes (<xref ref-type="bibr" rid="bib42">Keramati et al., 2016</xref>). Furthermore, replay-like prioritized model-based updates can update a model-free policy when environmental contingencies change (<xref ref-type="bibr" rid="bib3">Antonov and Dayan, 2023</xref>). Finally, while online BAMDP planning can be computationally expensive, a model-based agent may simply amortize planning into a model-free policy which it can reuse in similar environments or even precompile model-based strategies into an efficient model-free policy using meta-learning (<xref ref-type="bibr" rid="bib68">Wang et al., 2017</xref>). Agents may have faced many different exploration environments with differing reward and threat trade-offs through their lifetimes and even over evolution that they have used to create fast, instinctive model-free policies that resemble prospective, model-based behavior (<xref ref-type="bibr" rid="bib62">Rusu et al., 2016</xref>; <xref ref-type="bibr" rid="bib49">Mattar and Daw, 2018</xref>). In turn, TS dopamine might reflect aspects of MF values or prediction errors that had been trained by an MB system following the precepts we outlined.</p><p>In <xref ref-type="bibr" rid="bib2">Akiti et al., 2022</xref>, ablating TS-projecting dopamine neurons made mice â€˜braverâ€™. They spent more time near the object, performed more tail-exposed approach, and transitioned faster to tail-exposed approach compared to control. In <xref ref-type="bibr" rid="bib52">Menegas et al., 2018</xref>, TS ablation affected the learning dynamics for actual, rather than predicted threat. Both ablated and control animals initially demonstrated retreat responses toward airpuffs, but only control mice maintained this response (<xref ref-type="bibr" rid="bib52">Menegas et al., 2018</xref>). After airpuff punishment, ablated individuals surprisingly did not decrease their choices of water ports associated with airpuffs (while controls did). One possibility is that this additional exposure could have caused acclimatization to the airpuffs in the same way that brave animals in our study acclimatize to the novel object by approaching more, and timid animals fail to acclimatize because of self-censoring. Indeed, future experiments might investigate why punishment avoidance does not occur in ablated animals and whether the same holds in risk-sensitive exploration settings (<xref ref-type="bibr" rid="bib52">Menegas et al., 2018</xref>). In other words, would mice decrease approach after reaching the â€˜detectedâ€™ state, as expected by our model, or would they maladaptively continue the same rate of approach? Finally, while our study has focused on threat, <xref ref-type="bibr" rid="bib51">Menegas et al., 2017</xref> showed that TS also responds to novelty and salience in the context of rewards and neutral stimuli. That TS ablated animals spend more, rather than less time near the novel object suggests that the link from novelty to neophilia and exploration bonuses might not be mediated by this structure.</p><p>The behavior of the mice in <xref ref-type="bibr" rid="bib2">Akiti et al., 2022</xref> somewhat resembles attachment behavior in toddlers (<xref ref-type="bibr" rid="bib1">Ainsworth, 1964</xref>; <xref ref-type="bibr" rid="bib9">Bowlby, 1955</xref>), albeit with the caregiverâ€™s trusty leg (a secure base from which to explore) replaced by thigmotaxis (or, in our case, the notional â€˜nestâ€™). Characteristic to this behavior is an intermittent exploration strategy, with babies venturing away from the leg for a period before retreating back to its safety. Through the time course of exposure to a novel environment, toddlers progressively venture out longer and farther away, spending more time actively playing with the toys rather than passively observing them in hesitation (<xref ref-type="bibr" rid="bib4">Arsenian, 1943</xref>). This is another example of a dynamic exploratory strategy, putatively arising again from differential updates to beliefs about threats and the rewards in the environment (<xref ref-type="bibr" rid="bib4">Arsenian, 1943</xref>; <xref ref-type="bibr" rid="bib1">Ainsworth, 1964</xref>).</p><p>Our data show that there is substantial variation in the degrees of risk sensitivity across the mice. Previous works have reported substantial interpopulation and intrapopulation differences in risk sensitivity in humans which depend on gender, age, socioeconomic status, personality characteristics, wealth, and culture (<xref ref-type="bibr" rid="bib59">Rieger et al., 2015</xref>; <xref ref-type="bibr" rid="bib27">Frey et al., 2017</xref>). Despite the normative appeal of <inline-formula><alternatives><mml:math id="inf123"><mml:semantics><mml:mrow><mml:mi>ğ›¼</mml:mi><mml:mo class="MathClass-rel" stretchy="false">=</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:semantics></mml:math><tex-math id="inft123">\begin{document}$\alpha= 1$\end{document}</tex-math></alternatives></inline-formula>, it is possible that a population may benefit from including individuals with <inline-formula><alternatives><mml:math id="inf124"><mml:semantics><mml:mrow><mml:mi>ğ›¼</mml:mi></mml:mrow></mml:semantics></mml:math><tex-math id="inft124">\begin{document}$\alpha$\end{document}</tex-math></alternatives></inline-formula> different from <inline-formula><alternatives><mml:math id="inf125"><mml:semantics><mml:mrow><mml:mn>1.0</mml:mn></mml:mrow></mml:semantics></mml:math><tex-math id="inft125">\begin{document}$1.0$\end{document}</tex-math></alternatives></inline-formula> or highly negative priors. For example, more cautious individuals could learn from merely observing the risky behavior of less cautious individuals. Furthermore, we have only considered risk sensitivity under epistemic uncertainty in our work. Risk-averse individuals, for instance, with <inline-formula><alternatives><mml:math id="inf126"><mml:semantics><mml:mrow><mml:mi>ğ›¼</mml:mi><mml:mo class="MathClass-rel" stretchy="false">&lt;</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:semantics></mml:math><tex-math id="inft126">\begin{document}$\alpha \lt 1$\end{document}</tex-math></alternatives></inline-formula> may be more successful than risk-neutral agents in environments where there are unexpected dangers (unknown unknowns). Risk aversion is thus a temperament of ecological and evolutionary significance (<xref ref-type="bibr" rid="bib58">RÃ©ale et al., 2007</xref>).</p><p>Consistent with this, variability in timidity during exploration has been reported in other animal species and can be caused by differences in both prior experience and genotype. Fish from predator-dense environments tend to make more inspection approaches but stay further away, avoid dangerous areas (attack-cone avoidance), and approach in larger shoals compared to fish from predator-sparse environments (<xref ref-type="bibr" rid="bib45">Magurran and Seghers, 1990</xref>; <xref ref-type="bibr" rid="bib23">Dugatkin, 1988</xref>; <xref ref-type="bibr" rid="bib44">Magurran, 1986</xref>). <xref ref-type="bibr" rid="bib23">Dugatkin, 1988</xref> and <xref ref-type="bibr" rid="bib44">Magurran, 1986</xref> report significant within-population differences in the inspection behavior of guppies and minnows, respectively. <xref ref-type="bibr" rid="bib11">Brown and Dreier, 2002</xref> directly manipulate the predator experience of glowlight tetras, leading to changes to inspection behavior. Similar inter- and intra-population differences in timidity have been reported in mammals. In <xref ref-type="bibr" rid="bib15">Coss and Biardi, 1997</xref>, the squirrel population sympatric with the tested predators stayed further away and spent less time facing the predator compared to the allopatric population. Furthermore, the number of inspection bouts differed between litters, between individuals within the same litter, and even between the same individuals at different times during development (<xref ref-type="bibr" rid="bib15">Coss and Biardi, 1997</xref>). In <xref ref-type="bibr" rid="bib41">Kemp and Kaplan, 2011</xref>, marmosets differed in risk aversion when inspecting a potential (taxidermic) predator, but risk aversion was not stable across contexts for some individuals. <xref ref-type="bibr" rid="bib26">FitzGibbon, 1994</xref> reports age differences in inspection behavior â€“ adolescent gazelles inspected cheetahs more than adults or half-growns. Finally, <xref ref-type="bibr" rid="bib50">Mazza et al., 2019</xref>; <xref ref-type="bibr" rid="bib24">Eccard et al., 2020</xref> report substantial individual differences in the foraging behavior of voles in risky environments, and <xref ref-type="bibr" rid="bib43">Lloyd and Dayan, 2018</xref> provide a somewhat general model of foraging under risk.</p><p>Inter-individual differences in risk sensitivity are also of critical importance in psychiatry, reflected in a panoply of anxiety disorders (<xref ref-type="bibr" rid="bib12">Butler and Mathews, 1983</xref>; <xref ref-type="bibr" rid="bib30">Giorgetta et al., 2012</xref>; <xref ref-type="bibr" rid="bib46">Maner et al., 2007</xref>; <xref ref-type="bibr" rid="bib13">Charpentier et al., 2017</xref>), along with worry and rumination (<xref ref-type="bibr" rid="bib29">Gagne and Dayan, 2022</xref>). Understanding the spectrum of extreme priors and extreme values of <inline-formula><alternatives><mml:math id="inf127"><mml:semantics><mml:mrow><mml:mi>ğ›¼</mml:mi></mml:mrow></mml:semantics></mml:math><tex-math id="inft127">\begin{document}$\alpha$\end{document}</tex-math></alternatives></inline-formula> could have therapeutic implications, adding significance to the search for tasks that can more cleanly separate them.</p><p>In conclusion, our model shows that risk-sensitive, normative, reinforcement learning can account for individual variability in exploratory schedules of animals, providing a crisp account of the competition between neophilia and neophobia that characterizes many interactions with an incompletely known world.</p></sec><sec id="s4" sec-type="materials|methods"><title>Materials and methods</title><sec id="s4-1"><title>BAMDP hyperstate</title><p>A BAMDP (<xref ref-type="bibr" rid="bib21">Duff, 2002a</xref>; <xref ref-type="bibr" rid="bib35">Guez et al., 2013</xref>) is an extension of model-based MDP and a special case of a partially observable Markov decision process (POMDP; <xref ref-type="bibr" rid="bib39">Kaelbling et al., 1998</xref>) in which the agent models its uncertainty about the (unchanging) transition dynamics. In a BAMDP, the agent extends its state representation into a hyperstate consisting of the original MDP state <inline-formula><alternatives><mml:math id="inf128"><mml:semantics><mml:mrow><mml:mi>ğ‘ </mml:mi></mml:mrow></mml:semantics></mml:math><tex-math id="inft128">\begin{document}$s$\end{document}</tex-math></alternatives></inline-formula>, and the belief over the transition dynamics <inline-formula><alternatives><mml:math id="inf129"><mml:semantics><mml:mrow><mml:mi>ğ‘</mml:mi><mml:mo class="MathClass-open" stretchy="false">(</mml:mo><mml:mi>ğ‘‡</mml:mi><mml:mo class="MathClass-close" stretchy="false">)</mml:mo></mml:mrow></mml:semantics></mml:math><tex-math id="inft129">\begin{document}$b(T)$\end{document}</tex-math></alternatives></inline-formula>.</p><p>In our model <inline-formula><alternatives><mml:math id="inf130"><mml:semantics><mml:mrow><mml:mi>ğ‘ </mml:mi></mml:mrow></mml:semantics></mml:math><tex-math id="inft130">\begin{document}$s$\end{document}</tex-math></alternatives></inline-formula> is the conjunction of the â€˜physical stateâ€™ (the location of the agent, as shown in <xref ref-type="fig" rid="fig3">Figure 3</xref>) and the number of turns the agent has spent at the object so far <inline-formula><alternatives><mml:math id="inf131"><mml:semantics><mml:mrow><mml:mi>ğœ</mml:mi></mml:mrow></mml:semantics></mml:math><tex-math id="inft131">\begin{document}$\tau$\end{document}</tex-math></alternatives></inline-formula>. In the general case, <inline-formula><alternatives><mml:math id="inf132"><mml:semantics><mml:mrow><mml:mi>ğ‘‡</mml:mi></mml:mrow></mml:semantics></mml:math><tex-math id="inft132">\begin{document}$T$\end{document}</tex-math></alternatives></inline-formula> is a <inline-formula><alternatives><mml:math id="inf133"><mml:semantics><mml:mrow><mml:mi mathvariant="italic">|ğ‘†|</mml:mi><mml:mi mathvariant="italic">Ã—|ğ´|</mml:mi><mml:mi mathvariant="italic">Ã—|ğ‘†|</mml:mi></mml:mrow></mml:semantics></mml:math><tex-math id="inft133">\begin{document}$|S| \times|A| \times|S|$\end{document}</tex-math></alternatives></inline-formula> tensor where each element is <inline-formula><alternatives><mml:math id="inf134"><mml:semantics><mml:mrow><mml:mi>ğ‘</mml:mi><mml:mo class="MathClass-open" stretchy="false">(</mml:mo><mml:mi>ğ‘ </mml:mi><mml:mo class="MathClass-punc" stretchy="false">,</mml:mo><mml:mi>ğ‘</mml:mi><mml:mo class="MathClass-punc" stretchy="false">,</mml:mo><mml:msup><mml:mrow><mml:mi>ğ‘ </mml:mi></mml:mrow><mml:mrow><mml:mi>â€²</mml:mi></mml:mrow></mml:msup><mml:mo class="MathClass-close" stretchy="false">)</mml:mo></mml:mrow></mml:semantics></mml:math><tex-math id="inft134">\begin{document}$p(s, a, s')$\end{document}</tex-math></alternatives></inline-formula> and <inline-formula><alternatives><mml:math id="inf135"><mml:semantics><mml:mrow><mml:mi mathvariant="italic">|ğ‘†|</mml:mi></mml:mrow></mml:semantics></mml:math><tex-math id="inft135">\begin{document}$|S|$\end{document}</tex-math></alternatives></inline-formula> and <inline-formula><alternatives><mml:math id="inf136"><mml:semantics><mml:mrow><mml:mi mathvariant="italic">|ğ´|</mml:mi></mml:mrow></mml:semantics></mml:math><tex-math id="inft136">\begin{document}$|A|$\end{document}</tex-math></alternatives></inline-formula> are the number of states and actions, respectively. Therefore, <inline-formula><alternatives><mml:math id="inf137"><mml:semantics><mml:mrow><mml:mi>ğ‘</mml:mi><mml:mo class="MathClass-open" stretchy="false">(</mml:mo><mml:mi>ğ‘‡</mml:mi><mml:mo class="MathClass-close" stretchy="false">)</mml:mo></mml:mrow></mml:semantics></mml:math><tex-math id="inft137">\begin{document}$b(T)$\end{document}</tex-math></alternatives></inline-formula> is a probability distribution over (possibly infinite) transition tensors. In our model, all transition probabilities are assumed fixed except for the hazard function probabilities. Therefore, a belief over transition tensors <inline-formula><alternatives><mml:math id="inf138"><mml:semantics><mml:mrow><mml:mi>ğ‘</mml:mi><mml:mo class="MathClass-open" stretchy="false">(</mml:mo><mml:mi>ğ‘‡</mml:mi><mml:mo class="MathClass-close" stretchy="false">)</mml:mo></mml:mrow></mml:semantics></mml:math><tex-math id="inft138">\begin{document}$b(T)$\end{document}</tex-math></alternatives></inline-formula> is a belief over hazard functions <inline-formula><alternatives><mml:math id="inf139"><mml:semantics><mml:mrow><mml:mi>ğ‘</mml:mi><mml:mo class="MathClass-open" stretchy="false">(</mml:mo><mml:mi>â„</mml:mi><mml:mo class="MathClass-close" stretchy="false">)</mml:mo></mml:mrow></mml:semantics></mml:math><tex-math id="inft139">\begin{document}$b(h)$\end{document}</tex-math></alternatives></inline-formula>. We use a noisy-or hazard function parameterized by a vector of Beta distribution parameters <inline-formula><alternatives><mml:math id="inf140"><mml:semantics><mml:mrow><mml:mi>â„</mml:mi><mml:mo class="MathClass-open" stretchy="false">(</mml:mo><mml:mi>ğœ</mml:mi><mml:mo class="MathClass-punc" stretchy="false">;</mml:mo><mml:mover accent="true"><mml:mrow><mml:mi>ğœ‡</mml:mi></mml:mrow><mml:mo accent="true">â†’</mml:mo></mml:mover><mml:mo class="MathClass-punc" stretchy="false">,</mml:mo><mml:mover accent="true"><mml:mrow><mml:mi>ğœ</mml:mi></mml:mrow><mml:mo accent="true">â†’</mml:mo></mml:mover><mml:mo class="MathClass-close" stretchy="false">)</mml:mo></mml:mrow></mml:semantics></mml:math><tex-math id="inft140">\begin{document}$h(\tau; \vec\mu, \vec\sigma)$\end{document}</tex-math></alternatives></inline-formula>, <inline-formula><alternatives><mml:math id="inf141"><mml:semantics><mml:mrow><mml:mover accent="true"><mml:mrow><mml:mi>ğœ‡</mml:mi></mml:mrow><mml:mo accent="true">â†’</mml:mo></mml:mover><mml:mo class="MathClass-rel" stretchy="false">=</mml:mo><mml:mo class="MathClass-open" stretchy="false">[</mml:mo><mml:msub><mml:mrow><mml:mi>ğœ‡</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mi>â€¦</mml:mi><mml:mo class="MathClass-punc" stretchy="false">,</mml:mo><mml:msub><mml:mrow><mml:mi>ğœ‡</mml:mi></mml:mrow><mml:mrow><mml:mi>ğœ</mml:mi></mml:mrow></mml:msub><mml:mo class="MathClass-close" stretchy="false">]</mml:mo></mml:mrow></mml:semantics></mml:math><tex-math id="inft141">\begin{document}$\vec\mu= [\mu_1 \dots, \mu_\tau]$\end{document}</tex-math></alternatives></inline-formula>, <inline-formula><alternatives><mml:math id="inf142"><mml:semantics><mml:mrow><mml:mover accent="true"><mml:mrow><mml:mi>ğœ</mml:mi></mml:mrow><mml:mo accent="true">â†’</mml:mo></mml:mover><mml:mo class="MathClass-rel" stretchy="false">=</mml:mo><mml:mo class="MathClass-open" stretchy="false">[</mml:mo><mml:msub><mml:mrow><mml:mi>ğœ</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mi>â€¦</mml:mi><mml:mo class="MathClass-punc" stretchy="false">,</mml:mo><mml:msub><mml:mrow><mml:mi>ğœ</mml:mi></mml:mrow><mml:mrow><mml:mi>ğœ</mml:mi></mml:mrow></mml:msub><mml:mo class="MathClass-close" stretchy="false">]</mml:mo></mml:mrow></mml:semantics></mml:math><tex-math id="inft142">\begin{document}$\vec\sigma= [\sigma_1 \dots, \sigma_\tau]$\end{document}</tex-math></alternatives></inline-formula>. In totality, the belief over transition tensors <inline-formula><alternatives><mml:math id="inf143"><mml:semantics><mml:mrow><mml:mi>ğ‘</mml:mi><mml:mo class="MathClass-open" stretchy="false">(</mml:mo><mml:mi>ğ‘‡</mml:mi><mml:mo class="MathClass-close" stretchy="false">)</mml:mo></mml:mrow></mml:semantics></mml:math><tex-math id="inft143">\begin{document}$b(T)$\end{document}</tex-math></alternatives></inline-formula> is a belief over parameter vectors <inline-formula><alternatives><mml:math id="inf144"><mml:semantics><mml:mrow><mml:mi>ğ‘</mml:mi><mml:mo class="MathClass-open" stretchy="false">(</mml:mo><mml:mo class="MathClass-open" stretchy="false">[</mml:mo><mml:mover accent="true"><mml:mrow><mml:mi>ğœ‡</mml:mi></mml:mrow><mml:mo accent="true">â†’</mml:mo></mml:mover><mml:mo class="MathClass-punc" stretchy="false">,</mml:mo><mml:mover accent="true"><mml:mrow><mml:mi>ğœ</mml:mi></mml:mrow><mml:mo accent="true">â†’</mml:mo></mml:mover><mml:mo class="MathClass-close" stretchy="false">]</mml:mo><mml:mo class="MathClass-close" stretchy="false">)</mml:mo></mml:mrow></mml:semantics></mml:math><tex-math id="inft144">\begin{document}$b([\vec\mu, \vec\sigma])$\end{document}</tex-math></alternatives></inline-formula>,<disp-formula id="equ3"><label>(3)</label><alternatives><mml:math id="m3"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>b</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>T</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mi>p</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>T</mml:mi><mml:mo>;</mml:mo><mml:mrow><mml:mover><mml:mi>Î¼</mml:mi><mml:mo stretchy="false">â†’</mml:mo></mml:mover></mml:mrow><mml:mo>,</mml:mo><mml:mrow><mml:mover><mml:mi>Ïƒ</mml:mi><mml:mo stretchy="false">â†’</mml:mo></mml:mover></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mstyle></mml:mrow></mml:mstyle></mml:math><tex-math id="t3">\begin{document}$$\displaystyle b(T) = p(T; \vec\mu, \vec\sigma)$$\end{document}</tex-math></alternatives></disp-formula></p><p>However, to maintain generality in the next section, we derive the Bellman updates using the notation <inline-formula><alternatives><mml:math id="inf145"><mml:mstyle><mml:mrow><mml:mstyle displaystyle="false"><mml:mi>b</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>T</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mstyle></mml:mrow></mml:mstyle></mml:math><tex-math id="inft145">\begin{document}$b(T)$\end{document}</tex-math></alternatives></inline-formula>.</p><p>Our hyperstate additionally contains the nCVaR static risk preference <inline-formula><alternatives><mml:math id="inf146"><mml:semantics><mml:mrow><mml:mover accent="true"><mml:mrow><mml:mi>ğ›¼</mml:mi></mml:mrow><mml:mo accent="true">Â¯</mml:mo></mml:mover></mml:mrow></mml:semantics></mml:math><tex-math id="inft146">\begin{document}$\bar\alpha$\end{document}</tex-math></alternatives></inline-formula>, and the parameters of the heuristic exploration bonus <inline-formula><alternatives><mml:math id="inf147"><mml:semantics><mml:mrow><mml:mi>ğº</mml:mi><mml:mo class="MathClass-punc" stretchy="false">,</mml:mo><mml:msubsup><mml:mrow><mml:mi>ğ‘›</mml:mi></mml:mrow><mml:mrow><mml:mn>0</mml:mn></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msubsup><mml:mo class="MathClass-punc" stretchy="false">,</mml:mo><mml:msubsup><mml:mrow><mml:mi>ğ‘›</mml:mi></mml:mrow><mml:mrow><mml:mn>0</mml:mn></mml:mrow><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msubsup></mml:mrow></mml:semantics></mml:math><tex-math id="inft147">\begin{document}$G, n^1_0, n^0_0$\end{document}</tex-math></alternatives></inline-formula> (see Heuristic exploration bonus pool).</p></sec><sec id="s4-2"><title>Bellman updates for BAMDP nCVaR</title><p>As for a conventional MDP, the nCVaR objective for a BAMDP can be solved using Bellman updates. We use <xref ref-type="disp-formula" rid="equ4">Equation 4</xref> which assumes a deterministic, state-dependent, reward,<disp-formula id="equ4"><label>(4)</label><alternatives><mml:math id="m4"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msup><mml:mi>V</mml:mi><mml:mo>âˆ—</mml:mo></mml:msup><mml:mo stretchy="false">(</mml:mo><mml:mi>b</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>T</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>,</mml:mo><mml:mi>s</mml:mi><mml:mo>,</mml:mo><mml:mrow><mml:mover><mml:mi>Î±</mml:mi><mml:mo stretchy="false">Â¯</mml:mo></mml:mover></mml:mrow><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:munder><mml:mo movablelimits="true" form="prefix">max</mml:mo><mml:mi>a</mml:mi></mml:munder><mml:mrow><mml:mo>[</mml:mo><mml:mrow><mml:mi>r</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>s</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>+</mml:mo><mml:mi>Î³</mml:mi><mml:munder><mml:mo movablelimits="true" form="prefix">min</mml:mo><mml:mrow><mml:mi>Î¾</mml:mi><mml:mo>âˆˆ</mml:mo><mml:mrow><mml:mi class="mathcal" mathvariant="script">U</mml:mi></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mover><mml:mi>Î±</mml:mi><mml:mo stretchy="false">Â¯</mml:mo></mml:mover></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:munder><mml:munder><mml:mo>âˆ‘</mml:mo><mml:mrow><mml:msup><mml:mi>s</mml:mi><mml:mo>â€²</mml:mo></mml:msup></mml:mrow></mml:munder><mml:mi>Î¾</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msup><mml:mi>b</mml:mi><mml:mo>â€²</mml:mo></mml:msup><mml:mo stretchy="false">(</mml:mo><mml:mi>T</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>,</mml:mo><mml:msup><mml:mi>s</mml:mi><mml:mo>â€²</mml:mo></mml:msup><mml:mo stretchy="false">)</mml:mo><mml:mrow><mml:mover><mml:mi>T</mml:mi><mml:mo stretchy="false">Â¯</mml:mo></mml:mover></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>s</mml:mi><mml:mo>,</mml:mo><mml:mi>a</mml:mi><mml:mo>,</mml:mo><mml:msup><mml:mi>s</mml:mi><mml:mo>â€²</mml:mo></mml:msup><mml:mo stretchy="false">)</mml:mo><mml:msup><mml:mi>V</mml:mi><mml:mo>âˆ—</mml:mo></mml:msup><mml:mo stretchy="false">(</mml:mo><mml:msup><mml:mi>b</mml:mi><mml:mo>â€²</mml:mo></mml:msup><mml:mo stretchy="false">(</mml:mo><mml:mi>T</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>,</mml:mo><mml:msup><mml:mi>s</mml:mi><mml:mo>â€²</mml:mo></mml:msup><mml:mo>,</mml:mo><mml:mrow><mml:mover><mml:mi>Î±</mml:mi><mml:mo stretchy="false">Â¯</mml:mo></mml:mover></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>]</mml:mo></mml:mrow></mml:mstyle></mml:mstyle></mml:mrow></mml:mstyle></mml:math><tex-math id="t4">\begin{document}$$\displaystyle  V^*(b(T), s, \bar \alpha) = \max _ a \left [r(s) + \gamma \min _{\xi \in \mathcal{U} (\bar \alpha)} \sum _{s'} \xi (b'(T), s') \bar T(s, a, s') V^*(b'(T), s', \bar \alpha) \right]$$\end{document}</tex-math></alternatives></disp-formula></p><p><inline-formula><alternatives><mml:math id="inf148"><mml:semantics><mml:mrow><mml:msup><mml:mrow><mml:mi>ğ‘ </mml:mi></mml:mrow><mml:mrow><mml:mi>â€²</mml:mi></mml:mrow></mml:msup></mml:mrow></mml:semantics></mml:math><tex-math id="inft148">\begin{document}$s'$\end{document}</tex-math></alternatives></inline-formula> is the next state and <inline-formula><alternatives><mml:math id="inf149"><mml:semantics><mml:mrow><mml:msup><mml:mrow><mml:mi>ğ‘</mml:mi></mml:mrow><mml:mrow><mml:mi>â€²</mml:mi></mml:mrow></mml:msup><mml:mo class="MathClass-open" stretchy="false">(</mml:mo><mml:mi>ğ‘‡</mml:mi><mml:mo class="MathClass-close" stretchy="false">)</mml:mo></mml:mrow></mml:semantics></mml:math><tex-math id="inft149">\begin{document}$b'(T)$\end{document}</tex-math></alternatives></inline-formula> is the posterior belief over transition dynamics after observing the transition <inline-formula><alternatives><mml:math id="inf150"><mml:semantics><mml:mrow><mml:mo class="MathClass-open" stretchy="false">(</mml:mo><mml:mi>ğ‘ </mml:mi><mml:mo class="MathClass-punc" stretchy="false">,</mml:mo><mml:mi>ğ‘</mml:mi><mml:mo class="MathClass-punc" stretchy="false">,</mml:mo><mml:msup><mml:mrow><mml:mi>ğ‘ </mml:mi></mml:mrow><mml:mrow><mml:mi>â€²</mml:mi></mml:mrow></mml:msup><mml:mo class="MathClass-close" stretchy="false">)</mml:mo></mml:mrow></mml:semantics></mml:math><tex-math id="inft150">\begin{document}$(s, a, s')$\end{document}</tex-math></alternatives></inline-formula>. <inline-formula><alternatives><mml:math id="inf151"><mml:mstyle><mml:mrow><mml:mstyle displaystyle="false"><mml:mrow><mml:mover><mml:mi>T</mml:mi><mml:mo stretchy="false">Â¯</mml:mo></mml:mover></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>s</mml:mi><mml:mo>,</mml:mo><mml:mi>a</mml:mi><mml:mo>,</mml:mo><mml:msup><mml:mi>s</mml:mi><mml:mo>â€²</mml:mo></mml:msup><mml:mo stretchy="false">)</mml:mo></mml:mstyle></mml:mrow></mml:mstyle></mml:math><tex-math id="inft151">\begin{document}$\bar{T}(s, a, s')$\end{document}</tex-math></alternatives></inline-formula> is the expected transition probability,<disp-formula id="equ5"><label>(5)</label><alternatives><mml:math id="m5"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mover><mml:mi>T</mml:mi><mml:mo stretchy="false">Â¯</mml:mo></mml:mover></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>s</mml:mi><mml:mo>,</mml:mo><mml:mi>a</mml:mi><mml:mo>,</mml:mo><mml:msup><mml:mi>s</mml:mi><mml:mo>â€²</mml:mo></mml:msup><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mo>âˆ«</mml:mo><mml:mi>T</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>s</mml:mi><mml:mo>,</mml:mo><mml:mi>a</mml:mi><mml:mo>,</mml:mo><mml:msup><mml:mi>s</mml:mi><mml:mo>â€²</mml:mo></mml:msup><mml:mo stretchy="false">)</mml:mo><mml:mspace width="thinmathspace"/><mml:mi>b</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>T</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mspace width="thinmathspace"/><mml:mi>d</mml:mi><mml:mi>T</mml:mi></mml:mstyle></mml:mrow></mml:mstyle></mml:math><tex-math id="t5">\begin{document}$$\displaystyle \bar{T}(s, a, s') = \int T(s, a, s')\, b(T)\, dT$$\end{document}</tex-math></alternatives></disp-formula></p><p>Proof of <xref ref-type="disp-formula" rid="equ4">Equation 4</xref>.<disp-formula id="equ6"><alternatives><mml:math id="m6"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mtable columnalign="left left" rowspacing="4pt" columnspacing="1em"><mml:mtr><mml:mtd><mml:msup><mml:mi>V</mml:mi><mml:mo>âˆ—</mml:mo></mml:msup><mml:mo stretchy="false">(</mml:mo><mml:mi>b</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>T</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>,</mml:mo><mml:mi>s</mml:mi><mml:mo>,</mml:mo><mml:mrow><mml:mover><mml:mi>Î±</mml:mi><mml:mo stretchy="false">Â¯</mml:mo></mml:mover></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mtd><mml:mtd><mml:mo>=</mml:mo><mml:munder><mml:mo movablelimits="true" form="prefix">max</mml:mo><mml:mrow><mml:mi>a</mml:mi></mml:mrow></mml:munder><mml:mo fence="false" stretchy="false">{</mml:mo><mml:mi>r</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>x</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>+</mml:mo><mml:mi>Î³</mml:mi><mml:munder><mml:mo movablelimits="true" form="prefix">min</mml:mo><mml:mrow><mml:mi>Î¾</mml:mi><mml:mo>âˆˆ</mml:mo><mml:mrow><mml:mi class="mathcal" mathvariant="script">U</mml:mi></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mover><mml:mi>Î±</mml:mi><mml:mo stretchy="false">Â¯</mml:mo></mml:mover></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:munder><mml:msub><mml:mo>âˆ«</mml:mo><mml:mrow><mml:mrow><mml:mover><mml:mi>b</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>T</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>,</mml:mo><mml:msup><mml:mi>s</mml:mi><mml:mo>â€²</mml:mo></mml:msup></mml:mrow></mml:msub></mml:mtd></mml:mtr><mml:mtr><mml:mtd/><mml:mtd><mml:mi>Î¾</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mover><mml:mi>b</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>T</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>,</mml:mo><mml:msup><mml:mi>s</mml:mi><mml:mo>â€²</mml:mo></mml:msup><mml:mo stretchy="false">)</mml:mo><mml:mo>â‹…</mml:mo><mml:mi>p</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mo stretchy="false">[</mml:mo><mml:mi>b</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>T</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>,</mml:mo><mml:mi>s</mml:mi><mml:mo stretchy="false">]</mml:mo><mml:mo>,</mml:mo><mml:mi>a</mml:mi><mml:mo>,</mml:mo><mml:mo stretchy="false">[</mml:mo><mml:mrow><mml:mover><mml:mi>b</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>T</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>,</mml:mo><mml:msup><mml:mi>s</mml:mi><mml:mo>â€²</mml:mo></mml:msup><mml:mo stretchy="false">]</mml:mo><mml:mo stretchy="false">)</mml:mo><mml:mo>â‹…</mml:mo><mml:msup><mml:mi>V</mml:mi><mml:mo>âˆ—</mml:mo></mml:msup><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mover><mml:mi>b</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>T</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>,</mml:mo><mml:msup><mml:mi>s</mml:mi><mml:mo>â€²</mml:mo></mml:msup><mml:mo>,</mml:mo><mml:mrow><mml:mover><mml:mi>Î±</mml:mi><mml:mo stretchy="false">Â¯</mml:mo></mml:mover></mml:mrow><mml:mo stretchy="false">)</mml:mo><mml:mi>d</mml:mi><mml:mo stretchy="false">[</mml:mo><mml:mrow><mml:mover><mml:mi>b</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>T</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>,</mml:mo><mml:msup><mml:mi>s</mml:mi><mml:mo>â€²</mml:mo></mml:msup><mml:mo stretchy="false">]</mml:mo><mml:mo fence="false" stretchy="false">}</mml:mo></mml:mtd></mml:mtr></mml:mtable></mml:mstyle></mml:mrow></mml:mstyle></mml:math><tex-math id="t6">\begin{document}$$\displaystyle \begin{array}{ll} V^*(b(T), s, \bar\alpha) &amp;= \max_{a} \{ r(x) + \gamma\min_{\xi\in\mathcal{U} (\bar\alpha)} \int_{ \hat b(T), s'} \\ &amp; \xi(\hat b(T), s') \cdotp p([b(T), s], a, [\hat b(T), s']) \cdot V^*(\hat b(T), s', \bar\alpha) d[\hat b(T), s'] \} \end{array}$$\end{document}</tex-math></alternatives></disp-formula></p><p>where <inline-formula><alternatives><mml:math id="inf152"><mml:mstyle><mml:mrow><mml:mstyle displaystyle="false"><mml:mrow><mml:mi class="mathcal" mathvariant="script">U</mml:mi></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mover><mml:mi>Î±</mml:mi><mml:mo stretchy="false">Â¯</mml:mo></mml:mover></mml:mrow><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mo fence="false" stretchy="false">{</mml:mo><mml:mi>Î¾</mml:mi><mml:mo>:</mml:mo><mml:mi>Î¾</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mover><mml:mi>b</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>T</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>,</mml:mo><mml:msup><mml:mi>s</mml:mi><mml:mo>â€²</mml:mo></mml:msup><mml:mo stretchy="false">)</mml:mo><mml:mo>âˆˆ</mml:mo><mml:mo stretchy="false">[</mml:mo><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mrow><mml:mover><mml:mi>Î±</mml:mi><mml:mo stretchy="false">Â¯</mml:mo></mml:mover></mml:mrow></mml:mfrac><mml:mo stretchy="false">]</mml:mo><mml:mo>,</mml:mo><mml:msub><mml:mo>âˆ«</mml:mo><mml:mrow><mml:mrow><mml:mover><mml:mi>b</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>T</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>,</mml:mo><mml:msup><mml:mi>s</mml:mi><mml:mo>â€²</mml:mo></mml:msup></mml:mrow></mml:msub><mml:mi>Î¾</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mover><mml:mi>b</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>T</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>,</mml:mo><mml:msup><mml:mi>s</mml:mi><mml:mo>â€²</mml:mo></mml:msup><mml:mo stretchy="false">)</mml:mo><mml:mi>p</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mo stretchy="false">[</mml:mo><mml:mi>b</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>T</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>,</mml:mo><mml:mi>s</mml:mi><mml:mo stretchy="false">]</mml:mo><mml:mo>,</mml:mo><mml:mi>a</mml:mi><mml:mo>,</mml:mo><mml:mo stretchy="false">[</mml:mo><mml:mrow><mml:mover><mml:mi>b</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>T</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>,</mml:mo><mml:msup><mml:mi>s</mml:mi><mml:mo>â€²</mml:mo></mml:msup><mml:mo stretchy="false">]</mml:mo><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mn>1</mml:mn><mml:mo fence="false" stretchy="false">}</mml:mo></mml:mstyle></mml:mrow></mml:mstyle></mml:math><tex-math id="inft152">\begin{document}$\mathcal{U} (\bar\alpha) = \{ \xi: \xi(\hat{b} (T), s') \in[0, \frac{1}{\bar\alpha}], \int_{\hat{b}(T), s'} \xi(\hat{b} (T), s') p([b(T), s], a, [\hat{b}(T), s']) =1 \}$\end{document}</tex-math></alternatives></inline-formula> is the risk envelope for CVaR (<xref ref-type="bibr" rid="bib14">Chow et al., 2015</xref>). But <inline-formula><alternatives><mml:math id="inf153"><mml:mstyle><mml:mrow><mml:mstyle displaystyle="false"><mml:mi>p</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mo stretchy="false">[</mml:mo><mml:mi>b</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>T</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>,</mml:mo><mml:mi>s</mml:mi><mml:mo stretchy="false">]</mml:mo><mml:mo>,</mml:mo><mml:mi>a</mml:mi><mml:mo>,</mml:mo><mml:mo stretchy="false">[</mml:mo><mml:mrow><mml:mover><mml:mi>b</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>T</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>,</mml:mo><mml:msup><mml:mi>s</mml:mi><mml:mo>â€²</mml:mo></mml:msup><mml:mo stretchy="false">]</mml:mo><mml:mo stretchy="false">)</mml:mo></mml:mstyle></mml:mrow></mml:mstyle></mml:math><tex-math id="inft153">\begin{document}$p([b(T), s], a, [\hat{b}(T), s'])$\end{document}</tex-math></alternatives></inline-formula> is only non-zero when <inline-formula><alternatives><mml:math id="inf154"><mml:mstyle><mml:mrow><mml:mstyle displaystyle="false"><mml:mrow><mml:mover><mml:mi>b</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>T</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:msup><mml:mi>b</mml:mi><mml:mo>â€²</mml:mo></mml:msup><mml:mo stretchy="false">(</mml:mo><mml:mi>T</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mstyle></mml:mrow></mml:mstyle></mml:math><tex-math id="inft154">\begin{document}$\hat{b}(T) = b'(T)$\end{document}</tex-math></alternatives></inline-formula>,<disp-formula id="equ7"><alternatives><mml:math id="m7"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mtable columnalign="right left right left right left right left right left right left" rowspacing="0.9em 0.9em 0.3em" columnspacing="0em 2em 0em 2em 0em 2em 0em 2em 0em 2em 0em" displaystyle="true"><mml:mlabeledtr><mml:mtd id="mjx-eqn-10"><mml:mtext>(10)</mml:mtext></mml:mtd><mml:mtd><mml:mi>p</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mo stretchy="false">[</mml:mo><mml:mi>b</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>T</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>,</mml:mo><mml:mi>s</mml:mi><mml:mo stretchy="false">]</mml:mo><mml:mo>,</mml:mo><mml:mi>a</mml:mi><mml:mo>,</mml:mo><mml:mo stretchy="false">[</mml:mo><mml:mrow><mml:mover><mml:mi>b</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>T</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>,</mml:mo><mml:msup><mml:mi>s</mml:mi><mml:mo>â€²</mml:mo></mml:msup><mml:mo stretchy="false">]</mml:mo><mml:mo stretchy="false">)</mml:mo></mml:mtd><mml:mtd><mml:mi/><mml:mo>=</mml:mo><mml:msub><mml:mo>âˆ«</mml:mo><mml:mi>T</mml:mi></mml:msub><mml:mi>p</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mover><mml:mi>b</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>T</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>,</mml:mo><mml:msup><mml:mi>s</mml:mi><mml:mo>â€²</mml:mo></mml:msup><mml:mo>âˆ£</mml:mo><mml:mi>T</mml:mi><mml:mo>,</mml:mo><mml:mi>s</mml:mi><mml:mo>,</mml:mo><mml:mi>a</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mspace width="thinmathspace"/><mml:mi>b</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>T</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mspace width="thinmathspace"/><mml:mi>d</mml:mi><mml:mi>T</mml:mi></mml:mtd></mml:mlabeledtr><mml:mlabeledtr><mml:mtd id="mjx-eqn-11"><mml:mtext>(11)</mml:mtext></mml:mtd><mml:mtd/><mml:mtd><mml:mi/><mml:mo>=</mml:mo><mml:msub><mml:mo>âˆ«</mml:mo><mml:mi>T</mml:mi></mml:msub><mml:mi>Î´</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mover><mml:mi>b</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>T</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>âˆ’</mml:mo><mml:msup><mml:mi>b</mml:mi><mml:mo>â€²</mml:mo></mml:msup><mml:mo stretchy="false">(</mml:mo><mml:mi>T</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo stretchy="false">)</mml:mo><mml:mspace width="thinmathspace"/><mml:mi>T</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msup><mml:mi>s</mml:mi><mml:mo>â€²</mml:mo></mml:msup><mml:mo>âˆ£</mml:mo><mml:mi>s</mml:mi><mml:mo>,</mml:mo><mml:mi>a</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mspace width="thinmathspace"/><mml:mi>b</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>T</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mspace width="thinmathspace"/><mml:mi>d</mml:mi><mml:mi>T</mml:mi></mml:mtd></mml:mlabeledtr><mml:mlabeledtr><mml:mtd id="mjx-eqn-12"><mml:mtext>(12)</mml:mtext></mml:mtd><mml:mtd/><mml:mtd><mml:mi/><mml:mo>=</mml:mo><mml:mrow><mml:mo>{</mml:mo><mml:mtable columnalign="left left" rowspacing="1.2em 0.2em" columnspacing="1em" displaystyle="false"><mml:mtr><mml:mtd><mml:mrow><mml:mover><mml:mi>T</mml:mi><mml:mo stretchy="false">~</mml:mo></mml:mover></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>s</mml:mi><mml:mo>,</mml:mo><mml:mi>a</mml:mi><mml:mo>,</mml:mo><mml:msup><mml:mi>s</mml:mi><mml:mo>â€²</mml:mo></mml:msup><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msub><mml:mo>âˆ«</mml:mo><mml:mi>T</mml:mi></mml:msub><mml:mi>T</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msup><mml:mi>s</mml:mi><mml:mo>â€²</mml:mo></mml:msup><mml:mo>âˆ£</mml:mo><mml:mi>s</mml:mi><mml:mo>,</mml:mo><mml:mi>a</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mspace width="thinmathspace"/><mml:mi>b</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>T</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mspace width="thinmathspace"/><mml:mi>d</mml:mi><mml:mi>T</mml:mi><mml:mo>,</mml:mo></mml:mstyle></mml:mtd><mml:mtd><mml:mtext>ifÂ </mml:mtext><mml:mrow><mml:mover><mml:mi>b</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>T</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:msup><mml:mi>b</mml:mi><mml:mo>â€²</mml:mo></mml:msup><mml:mo stretchy="false">(</mml:mo><mml:mi>T</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>,</mml:mo></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mn>0</mml:mn><mml:mo>,</mml:mo></mml:mtd><mml:mtd><mml:mtext>otherwise</mml:mtext><mml:mo>.</mml:mo></mml:mtd></mml:mtr></mml:mtable><mml:mo fence="true" stretchy="true" symmetric="true"/></mml:mrow></mml:mtd></mml:mlabeledtr></mml:mtable></mml:mstyle></mml:mrow></mml:mstyle></mml:math><tex-math id="t7">\begin{document}$$\displaystyle \begin{align} p([b(T),s], a, [\hat{b}(T), s']) &amp;= \int_T p(\hat{b}(T), s' \mid T, s, a)\, b(T)\, dT \\[6pt] &amp;= \int_T \delta(\hat{b}(T) - b'(T))\, T(s' \mid s, a)\, b(T)\, dT \\[6pt] &amp;= \begin{cases} \tilde{T}(s, a, s') = \int_T T(s' \mid s, a)\, b(T)\, dT, &amp; \text{if } \hat{b}(T) = b'(T), \\[10pt] 0, &amp; \text{otherwise}. \end{cases} \end{align}$$\end{document}</tex-math></alternatives></disp-formula></p><p>Hence, we can drop the independent integration over <inline-formula><alternatives><mml:math id="inf155"><mml:semantics><mml:mrow><mml:mover accent="true"><mml:mrow><mml:mi>ğ‘</mml:mi></mml:mrow><mml:mo accent="true">^</mml:mo></mml:mover><mml:mo class="MathClass-open" stretchy="false">(</mml:mo><mml:mi>ğ‘‡</mml:mi><mml:mo class="MathClass-close" stretchy="false">)</mml:mo></mml:mrow></mml:semantics></mml:math><tex-math id="inft155">\begin{document}$\hatb (T)$\end{document}</tex-math></alternatives></inline-formula>, and only integrate over <inline-formula><alternatives><mml:math id="inf156"><mml:semantics><mml:mrow><mml:msup><mml:mrow><mml:mi>ğ‘ </mml:mi></mml:mrow><mml:mrow><mml:mi>â€²</mml:mi></mml:mrow></mml:msup></mml:mrow></mml:semantics></mml:math><tex-math id="inft156">\begin{document}$s'$\end{document}</tex-math></alternatives></inline-formula>,<disp-formula id="equ8"><alternatives><mml:math id="m8"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mtable columnalign="left left" rowspacing="4pt" columnspacing="1em"><mml:mtr><mml:mtd><mml:msup><mml:mi>V</mml:mi><mml:mo>âˆ—</mml:mo></mml:msup><mml:mo stretchy="false">(</mml:mo><mml:mi>b</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>T</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>,</mml:mo><mml:mi>s</mml:mi><mml:mo>,</mml:mo><mml:mrow><mml:mover><mml:mi>Î±</mml:mi><mml:mo stretchy="false">Â¯</mml:mo></mml:mover></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mtd><mml:mtd><mml:mo>=</mml:mo><mml:munder><mml:mo movablelimits="true" form="prefix">max</mml:mo><mml:mrow><mml:mi>a</mml:mi></mml:mrow></mml:munder><mml:mo fence="false" stretchy="false">{</mml:mo><mml:mi>r</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>s</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>+</mml:mo><mml:mi>Î³</mml:mi><mml:munder><mml:mo movablelimits="true" form="prefix">min</mml:mo><mml:mrow><mml:mi>Î¾</mml:mi><mml:mo>âˆˆ</mml:mo><mml:mrow><mml:mi class="mathcal" mathvariant="script">U</mml:mi></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mover><mml:mi>Î±</mml:mi><mml:mo stretchy="false">Â¯</mml:mo></mml:mover></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:munder><mml:msub><mml:mo>âˆ«</mml:mo><mml:mrow><mml:msup><mml:mi>s</mml:mi><mml:mo>â€²</mml:mo></mml:msup></mml:mrow></mml:msub><mml:mi>Î¾</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msup><mml:mi>b</mml:mi><mml:mo>â€²</mml:mo></mml:msup><mml:mo stretchy="false">(</mml:mo><mml:mi>T</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>,</mml:mo><mml:msup><mml:mi>s</mml:mi><mml:mo>â€²</mml:mo></mml:msup><mml:mo stretchy="false">)</mml:mo><mml:mo>â‹…</mml:mo><mml:mrow><mml:mover><mml:mi>T</mml:mi><mml:mo stretchy="false">Â¯</mml:mo></mml:mover></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>s</mml:mi><mml:mo>,</mml:mo><mml:mi>a</mml:mi><mml:mo>,</mml:mo><mml:msup><mml:mi>s</mml:mi><mml:mo>â€²</mml:mo></mml:msup><mml:mo stretchy="false">)</mml:mo><mml:mo>â‹…</mml:mo><mml:msup><mml:mi>V</mml:mi><mml:mo>âˆ—</mml:mo></mml:msup><mml:mo stretchy="false">(</mml:mo><mml:msup><mml:mi>b</mml:mi><mml:mo>â€²</mml:mo></mml:msup><mml:mo stretchy="false">(</mml:mo><mml:mi>T</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>,</mml:mo><mml:msup><mml:mi>s</mml:mi><mml:mo>â€²</mml:mo></mml:msup><mml:mo>,</mml:mo><mml:mrow><mml:mover><mml:mi>Î±</mml:mi><mml:mo stretchy="false">Â¯</mml:mo></mml:mover></mml:mrow><mml:mo stretchy="false">)</mml:mo><mml:mi>d</mml:mi><mml:msup><mml:mi>s</mml:mi><mml:mo>â€²</mml:mo></mml:msup><mml:mo fence="false" stretchy="false">}</mml:mo></mml:mtd></mml:mtr><mml:mtr><mml:mtd/><mml:mtd><mml:mo>=</mml:mo><mml:munder><mml:mo movablelimits="true" form="prefix">max</mml:mo><mml:mrow><mml:mi>a</mml:mi></mml:mrow></mml:munder><mml:mo fence="false" stretchy="false">{</mml:mo><mml:mi>r</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>s</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>+</mml:mo><mml:mi>Î³</mml:mi><mml:munder><mml:mo movablelimits="true" form="prefix">min</mml:mo><mml:mrow><mml:mi>Î¾</mml:mi><mml:mo>âˆˆ</mml:mo><mml:mrow><mml:mi class="mathcal" mathvariant="script">U</mml:mi></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mover><mml:mi>Î±</mml:mi><mml:mo stretchy="false">Â¯</mml:mo></mml:mover></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:munder><mml:munder><mml:mo>âˆ‘</mml:mo><mml:mrow><mml:msup><mml:mi>s</mml:mi><mml:mo>â€²</mml:mo></mml:msup></mml:mrow></mml:munder><mml:mi>Î¾</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msup><mml:mi>b</mml:mi><mml:mo>â€²</mml:mo></mml:msup><mml:mo stretchy="false">(</mml:mo><mml:mi>T</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>,</mml:mo><mml:msup><mml:mi>s</mml:mi><mml:mo>â€²</mml:mo></mml:msup><mml:mo stretchy="false">)</mml:mo><mml:mo>â‹…</mml:mo><mml:mrow><mml:mover><mml:mi>T</mml:mi><mml:mo stretchy="false">Â¯</mml:mo></mml:mover></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>s</mml:mi><mml:mo>,</mml:mo><mml:mi>a</mml:mi><mml:mo>,</mml:mo><mml:msup><mml:mi>s</mml:mi><mml:mo>â€²</mml:mo></mml:msup><mml:mo stretchy="false">)</mml:mo><mml:mo>â‹…</mml:mo><mml:msup><mml:mi>V</mml:mi><mml:mo>âˆ—</mml:mo></mml:msup><mml:mo stretchy="false">(</mml:mo><mml:msup><mml:mi>b</mml:mi><mml:mo>â€²</mml:mo></mml:msup><mml:mo stretchy="false">(</mml:mo><mml:mi>T</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>,</mml:mo><mml:msup><mml:mi>s</mml:mi><mml:mo>â€²</mml:mo></mml:msup><mml:mo>,</mml:mo><mml:mrow><mml:mover><mml:mi>Î±</mml:mi><mml:mo stretchy="false">Â¯</mml:mo></mml:mover></mml:mrow><mml:mo stretchy="false">)</mml:mo><mml:mo fence="false" stretchy="false">}</mml:mo><mml:mspace width="2em"/><mml:mi>â—»</mml:mi></mml:mtd></mml:mtr></mml:mtable></mml:mstyle></mml:mstyle></mml:mrow></mml:mstyle></mml:math><tex-math id="t8">\begin{document}$$\displaystyle  \begin{array}{ll} V^*(b(T), s, \bar\alpha) &amp;= \max_{a} \{ r(s) + \gamma\min_{\xi\in\mathcal{U} (\bar\alpha)} \int_{ s'} \xi(b'(T), s') \cdot\bar T(s, a, s') \cdot V^*(b'(T), s', \bar\alpha) ds' \} \\ &amp;= \max_{a} \{ r(s) + \gamma\min_{\xi\in\mathcal{U} (\bar\alpha)} \sum_{ s'} \xi(b'(T), s') \cdot\bar T(s, a, s') \cdot V^*(b'(T), s', \bar\alpha) \}\qquad \square \end{array}$$\end{document}</tex-math></alternatives></disp-formula></p><p>Epistemic uncertainty about the transitions only generates risk in as much as it affects the probabilities of realizable transitions in the environment.</p></sec><sec id="s4-3"><title>Noisy-or hazard function</title><p><disp-formula id="equ9"><label>(6)</label><alternatives><mml:math id="m9"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msub><mml:mi>X</mml:mi><mml:mi>Ï„</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:msub><mml:mi>Z</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>âˆª</mml:mo><mml:msub><mml:mi>Z</mml:mi><mml:mn>2</mml:mn></mml:msub><mml:mo>âˆª</mml:mo><mml:mo>â€¦</mml:mo><mml:msub><mml:mi>Z</mml:mi><mml:mi>Ï„</mml:mi></mml:msub></mml:mstyle></mml:mrow></mml:mstyle></mml:math><tex-math id="t9">\begin{document}$$\displaystyle X_\tau= Z_1 \cup Z_2 \cup\dots Z_\tau$$\end{document}</tex-math></alternatives></disp-formula></p><p>In our model, the hazard function defines a binary detection event <inline-formula><alternatives><mml:math id="inf157"><mml:semantics><mml:mrow><mml:msub><mml:mrow><mml:mi>ğ‘‹</mml:mi></mml:mrow><mml:mrow><mml:mi>ğœ</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:semantics></mml:math><tex-math id="inft157">\begin{document}$X_\tau$\end{document}</tex-math></alternatives></inline-formula> for each number of turns the agent spends at the object <inline-formula><alternatives><mml:math id="inf158"><mml:semantics><mml:mrow><mml:mi>ğœ</mml:mi><mml:mo class="MathClass-rel" stretchy="false">=</mml:mo><mml:mn>2</mml:mn><mml:mo class="MathClass-punc" stretchy="false">,</mml:mo><mml:mn>3</mml:mn><mml:mo class="MathClass-punc" stretchy="false">,</mml:mo><mml:mn>4</mml:mn></mml:mrow></mml:semantics></mml:math><tex-math id="inft158">\begin{document}$\tau=2,3,4$\end{document}</tex-math></alternatives></inline-formula>. The predator detects the agent when <inline-formula><alternatives><mml:math id="inf159"><mml:semantics><mml:mrow><mml:msub><mml:mrow><mml:mi>ğ‘‹</mml:mi></mml:mrow><mml:mrow><mml:mi>ğœ</mml:mi></mml:mrow></mml:msub><mml:mo class="MathClass-rel" stretchy="false">=</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:semantics></mml:math><tex-math id="inft159">\begin{document}$X_\tau=1$\end{document}</tex-math></alternatives></inline-formula>. We use a noisy-or hazard function which defines <inline-formula><alternatives><mml:math id="inf160"><mml:semantics><mml:mrow><mml:msub><mml:mrow><mml:mi>ğ‘‹</mml:mi></mml:mrow><mml:mrow><mml:mi>ğœ</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:semantics></mml:math><tex-math id="inft160">\begin{document}$X_\tau$\end{document}</tex-math></alternatives></inline-formula> as the union of Bernoulli random variables <inline-formula><alternatives><mml:math id="inf161"><mml:semantics><mml:mrow><mml:msub><mml:mrow><mml:mi>ğ‘</mml:mi></mml:mrow><mml:mrow><mml:mi>ğ‘—</mml:mi></mml:mrow></mml:msub><mml:mi>âˆ¼</mml:mi><mml:mstyle class="text"><mml:mtext>Bernoulli</mml:mtext></mml:mstyle><mml:mo class="MathClass-open" stretchy="false">(</mml:mo><mml:msub><mml:mrow><mml:mi>ğœƒ</mml:mi></mml:mrow><mml:mrow><mml:mi>ğ‘—</mml:mi></mml:mrow></mml:msub><mml:mo class="MathClass-close" stretchy="false">)</mml:mo></mml:mrow></mml:semantics></mml:math><tex-math id="inft161">\begin{document}$Z_j \sim\text{Bernoulli} (\theta_j)$\end{document}</tex-math></alternatives></inline-formula> (<xref ref-type="disp-formula" rid="equ9">Equation 6</xref>) with priors <inline-formula><alternatives><mml:math id="inf162"><mml:semantics><mml:mrow><mml:msub><mml:mrow><mml:mi>ğœƒ</mml:mi></mml:mrow><mml:mrow><mml:mi>ğ‘—</mml:mi></mml:mrow></mml:msub><mml:mi>âˆ¼</mml:mi><mml:mstyle class="text"><mml:mtext>Beta</mml:mtext></mml:mstyle><mml:mo class="MathClass-open" stretchy="false">(</mml:mo><mml:msub><mml:mrow><mml:mi>ğœ‡</mml:mi></mml:mrow><mml:mrow><mml:mi>ğ‘—</mml:mi></mml:mrow></mml:msub><mml:mo class="MathClass-punc" stretchy="false">,</mml:mo><mml:msub><mml:mrow><mml:mi>ğœ</mml:mi></mml:mrow><mml:mrow><mml:mi>ğ‘—</mml:mi></mml:mrow></mml:msub><mml:mo class="MathClass-close" stretchy="false">)</mml:mo></mml:mrow></mml:semantics></mml:math><tex-math id="inft162">\begin{document}$\theta_j \sim\text{Beta}(\mu_j, \sigma_j)$\end{document}</tex-math></alternatives></inline-formula> for <inline-formula><alternatives><mml:math id="inf163"><mml:semantics><mml:mrow><mml:mi>ğ‘—</mml:mi><mml:mo class="MathClass-rel" stretchy="false">=</mml:mo><mml:mn>2</mml:mn><mml:mo class="MathClass-punc" stretchy="false">,</mml:mo><mml:mn>3</mml:mn><mml:mo class="MathClass-punc" stretchy="false">,</mml:mo><mml:mn>4</mml:mn></mml:mrow></mml:semantics></mml:math><tex-math id="inft163">\begin{document}$j=2, 3, 4$\end{document}</tex-math></alternatives></inline-formula>. <xref ref-type="fig" rid="fig12">Figure 12</xref> shows the relationships between the random variables in plate notation.</p><fig id="fig12" position="float"><label>Figure 12.</label><caption><title>Bayes net showing the relationship between the random variables in the noisy-or model.</title><p>Only <inline-formula><alternatives><mml:math id="inf164"><mml:mstyle><mml:mrow><mml:mstyle displaystyle="false"><mml:msub><mml:mi>x</mml:mi><mml:mi>Ï„</mml:mi></mml:msub></mml:mstyle></mml:mrow></mml:mstyle></mml:math><tex-math id="inft164">\begin{document}$x_\tau$\end{document}</tex-math></alternatives></inline-formula> is shown <inline-formula><alternatives><mml:math id="inf165"><mml:mstyle><mml:mrow><mml:mstyle displaystyle="false"><mml:msub><mml:mi>x</mml:mi><mml:mrow><mml:mi>Ï„</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mstyle></mml:mrow></mml:mstyle></mml:math><tex-math id="inft165">\begin{document}$x_{\tau+1}$\end{document}</tex-math></alternatives></inline-formula>. depends on <inline-formula><alternatives><mml:math id="inf166"><mml:mstyle><mml:mrow><mml:mstyle displaystyle="false"><mml:msub><mml:mi>z</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn><mml:mo>:</mml:mo><mml:mi>Ï„</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mstyle></mml:mrow></mml:mstyle></mml:math><tex-math id="inft166">\begin{document}$z_{t=1:\tau+1}$\end{document}</tex-math></alternatives></inline-formula>, and so on.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-100366-fig12-v1.tif"/></fig><p>Posterior inference for the noisy-or model is intractable in the general case (<xref ref-type="bibr" rid="bib38">Jaakkola and Jordan, 1999</xref>). However, there is a closed-form solution for the posterior when the agent only makes negative observations, meaning <inline-formula><alternatives><mml:math id="inf167"><mml:semantics><mml:mrow><mml:msubsup><mml:mrow><mml:mi>ğ‘¥</mml:mi></mml:mrow><mml:mrow><mml:mi>ğœ</mml:mi></mml:mrow><mml:mrow><mml:mi>ğ‘–</mml:mi></mml:mrow></mml:msubsup><mml:mo class="MathClass-rel" stretchy="false">=</mml:mo><mml:mn>0</mml:mn><mml:mspace class="thinspace" width="0.17em"/><mml:mspace class="thinspace" width="0.17em"/><mml:mi mathvariant="italic">âˆ€ğ‘–</mml:mi></mml:mrow></mml:semantics></mml:math><tex-math id="inft167">\begin{document}$x^i_\tau= 0 \, \, \foralli$\end{document}</tex-math></alternatives></inline-formula> (in our case, since there is no actual predator). For example, given a single observation <inline-formula><alternatives><mml:math id="inf168"><mml:semantics><mml:mrow><mml:msub><mml:mrow><mml:mi>ğ‘¥</mml:mi></mml:mrow><mml:mrow><mml:mi>ğœ</mml:mi></mml:mrow></mml:msub><mml:mo class="MathClass-rel" stretchy="false">=</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:semantics></mml:math><tex-math id="inft168">\begin{document}$x_\tau= 0$\end{document}</tex-math></alternatives></inline-formula>,<disp-formula id="equ10"><alternatives><mml:math id="m10"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mtable columnalign="left left" rowspacing="4pt" columnspacing="1em"><mml:mtr><mml:mtd><mml:mi>p</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>Î¸</mml:mi><mml:mrow><mml:mi>j</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn><mml:mo>:</mml:mo><mml:mi>Ï„</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:msub><mml:mi>x</mml:mi><mml:mi>Ï„</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mn>0</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mtd><mml:mtd><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mi>p</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mi>Ï„</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mn>0</mml:mn><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:msub><mml:mi>Î¸</mml:mi><mml:mrow><mml:mi>j</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn><mml:mo>:</mml:mo><mml:mi>Ï„</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:mi>p</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>Î¸</mml:mi><mml:mrow><mml:mi>j</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn><mml:mo>:</mml:mo><mml:mi>Ï„</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mrow><mml:mi>p</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mi>Ï„</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mn>0</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mfrac></mml:mtd></mml:mtr><mml:mtr><mml:mtd/><mml:mtd><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:munder><mml:mo>âˆ</mml:mo><mml:mrow><mml:mi>j</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn><mml:mo>:</mml:mo><mml:mi>Ï„</mml:mi></mml:mrow></mml:munder><mml:mi>p</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>z</mml:mi><mml:mi>j</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mn>0</mml:mn><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:msub><mml:mi>Î¸</mml:mi><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:mi>p</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>Î¸</mml:mi><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mrow><mml:mi>p</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mi>Ï„</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mn>0</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mfrac></mml:mtd></mml:mtr><mml:mtr><mml:mtd/><mml:mtd><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:munder><mml:mo>âˆ</mml:mo><mml:mrow><mml:mi>j</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn><mml:mo>:</mml:mo><mml:mi>Ï„</mml:mi></mml:mrow></mml:munder><mml:mo stretchy="false">(</mml:mo><mml:mn>1</mml:mn><mml:mo>âˆ’</mml:mo><mml:msub><mml:mi>Î¸</mml:mi><mml:mi>j</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:mtext>Beta</mml:mtext><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>Î¸</mml:mi><mml:mi>j</mml:mi></mml:msub><mml:mo>;</mml:mo><mml:msub><mml:mi>a</mml:mi><mml:mi>j</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>b</mml:mi><mml:mi>j</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mrow><mml:mi>p</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mi>Ï„</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mn>0</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mfrac></mml:mtd></mml:mtr></mml:mtable></mml:mstyle></mml:mrow></mml:mstyle></mml:math><tex-math id="t10">\begin{document}$$\displaystyle \begin{array}{ll} p(\theta_{j=1:\tau} | x_\tau= 0) &amp;= \frac{p(x_\tau= 0 | \theta_{j=1:\tau})p(\theta_{j=1:\tau})}{p(x_\tau= 0)}\\ &amp;= \frac{\prod_{j=1:\tau} p(z_j = 0 | \theta_{t})p(\theta_{j})}{p(x_\tau= 0)}\\ &amp;= \frac{\prod_{j=1:\tau} (1-\theta_j) \text{Beta}(\theta_j ; a_j, b_j)}{p(x_\tau= 0)} \end{array}$$\end{document}</tex-math></alternatives></disp-formula></p><p>Here, we switch back to the pseudocount parameterization of the Beta distribution <inline-formula><alternatives><mml:math id="inf169"><mml:semantics><mml:mrow><mml:mstyle class="text"><mml:mtext>Beta</mml:mtext></mml:mstyle><mml:mo class="MathClass-open" stretchy="false">(</mml:mo><mml:mi>ğœƒ</mml:mi><mml:mo class="MathClass-punc" stretchy="false">;</mml:mo><mml:mi>ğ‘</mml:mi><mml:mo class="MathClass-punc" stretchy="false">,</mml:mo><mml:mi>ğ‘</mml:mi><mml:mo class="MathClass-close" stretchy="false">)</mml:mo></mml:mrow></mml:semantics></mml:math><tex-math id="inft169">\begin{document}$\text{Beta}(\theta; a, b)$\end{document}</tex-math></alternatives></inline-formula> to exploit its conjugacy,<disp-formula id="equ11"><label>(7)</label><alternatives><mml:math id="m11"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>p</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>Î¸</mml:mi><mml:mrow><mml:mi>j</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn><mml:mo>:</mml:mo><mml:mi>Ï„</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:msub><mml:mi>x</mml:mi><mml:mi>Ï„</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mn>0</mml:mn><mml:mo stretchy="false">)</mml:mo><mml:mo>âˆ¼</mml:mo><mml:munder><mml:mo>âˆ</mml:mo><mml:mrow><mml:mi>j</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn><mml:mo>:</mml:mo><mml:mi>Ï„</mml:mi></mml:mrow></mml:munder><mml:mtext>Beta</mml:mtext><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>Î¸</mml:mi><mml:mi>t</mml:mi></mml:msub><mml:mo>;</mml:mo><mml:msub><mml:mi>a</mml:mi><mml:mi>j</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>b</mml:mi><mml:mi>j</mml:mi></mml:msub><mml:mo>+</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mstyle></mml:mrow></mml:mstyle></mml:math><tex-math id="t11">\begin{document}$$\displaystyle  p(\theta_{j=1:\tau} | x_\tau= 0) \sim\prod_{j=1:\tau} \text{Beta}(\theta_t; a _j, b_j + 1)$$\end{document}</tex-math></alternatives></disp-formula></p><p>Hence, the posterior update simply increments the <inline-formula><alternatives><mml:math id="inf170"><mml:semantics><mml:mrow><mml:mstyle class="text"><mml:mtext>Beta</mml:mtext></mml:mstyle></mml:mrow></mml:semantics></mml:math><tex-math id="inft170">\begin{document}$\text{Beta}$\end{document}</tex-math></alternatives></inline-formula> pseudocounts for the â€˜0â€™ outcomes. The hazard probability is the posterior predictive distribution <inline-formula><alternatives><mml:math id="inf171"><mml:semantics><mml:mrow><mml:mi>â„</mml:mi><mml:mo class="MathClass-open" stretchy="false">(</mml:mo><mml:mi>ğœ</mml:mi><mml:mo class="MathClass-close" stretchy="false">)</mml:mo><mml:mo class="MathClass-rel" stretchy="false">=</mml:mo><mml:mi>ğ‘</mml:mi><mml:mo class="MathClass-open" stretchy="false">(</mml:mo><mml:msub><mml:mrow><mml:mi>ğ‘¥</mml:mi></mml:mrow><mml:mrow><mml:mi>ğœ</mml:mi></mml:mrow></mml:msub><mml:mo class="MathClass-rel" stretchy="false">=</mml:mo><mml:mn>1</mml:mn><mml:mi mathvariant="italic">|ğ·</mml:mi><mml:mo class="MathClass-close" stretchy="false">)</mml:mo></mml:mrow></mml:semantics></mml:math><tex-math id="inft171">\begin{document}$h(\tau) = p(x_\tau= 1| D)$\end{document}</tex-math></alternatives></inline-formula> where <inline-formula><alternatives><mml:math id="inf172"><mml:semantics><mml:mrow><mml:mi>ğ·</mml:mi></mml:mrow></mml:semantics></mml:math><tex-math id="inft172">\begin{document}$D$\end{document}</tex-math></alternatives></inline-formula> are a set of observations of <inline-formula><alternatives><mml:math id="inf173"><mml:semantics><mml:mrow><mml:msub><mml:mrow><mml:mi>ğ‘‹</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo class="MathClass-punc" stretchy="false">,</mml:mo><mml:msub><mml:mrow><mml:mi>ğ‘‹</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:mo class="MathClass-punc" stretchy="false">,</mml:mo><mml:mi>â€¦</mml:mi><mml:msub><mml:mrow><mml:mi>ğ‘‹</mml:mi></mml:mrow><mml:mrow><mml:mi>ğœ</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:semantics></mml:math><tex-math id="inft173">\begin{document}$X_1, X_2, \dotsX_\tau$\end{document}</tex-math></alternatives></inline-formula>,<disp-formula id="equ12"><label>(8)</label><alternatives><mml:math id="m12"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>p</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mi>Ï„</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mn>1</mml:mn><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mi>D</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mn>1</mml:mn><mml:mo>âˆ’</mml:mo><mml:munderover><mml:mo>âˆ</mml:mo><mml:mrow><mml:mi>j</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>Ï„</mml:mi></mml:munderover><mml:mo stretchy="false">(</mml:mo><mml:mn>1</mml:mn><mml:mo>âˆ’</mml:mo><mml:msub><mml:mi>Î¼</mml:mi><mml:mi>j</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mstyle></mml:mrow></mml:mstyle></mml:math><tex-math id="t12">\begin{document}$$\displaystyle p(x_\tau= 1| D) = 1-\prod_{j=1}^\tau(1-\mu_j)$$\end{document}</tex-math></alternatives></disp-formula></p><p>where <inline-formula><alternatives><mml:math id="inf174"><mml:semantics><mml:mrow><mml:msub><mml:mrow><mml:mi>ğœ‡</mml:mi></mml:mrow><mml:mrow><mml:mi>ğ‘—</mml:mi></mml:mrow></mml:msub><mml:mo class="MathClass-rel" stretchy="false">=</mml:mo><mml:mi>ğ”¼</mml:mi><mml:mo class="MathClass-open" stretchy="false">[</mml:mo><mml:msub><mml:mrow><mml:mi>ğœƒ</mml:mi></mml:mrow><mml:mrow><mml:mi>ğ‘—</mml:mi></mml:mrow></mml:msub><mml:mo class="MathClass-close" stretchy="false">]</mml:mo></mml:mrow></mml:semantics></mml:math><tex-math id="inft174">\begin{document}$\mu_j = \mathbb{E}[\theta_j]$\end{document}</tex-math></alternatives></inline-formula> is the expected value of the posterior on <inline-formula><alternatives><mml:math id="inf175"><mml:semantics><mml:mrow><mml:msub><mml:mrow><mml:mi>ğœƒ</mml:mi></mml:mrow><mml:mrow><mml:mi>ğ‘—</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:semantics></mml:math><tex-math id="inft175">\begin{document}$\theta_j$\end{document}</tex-math></alternatives></inline-formula>.</p><p>Proof of <xref ref-type="disp-formula" rid="equ12">Equation 8</xref>.<disp-formula id="equ13"><alternatives><mml:math id="m13"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mtable columnalign="left left" rowspacing="4pt" columnspacing="1em"><mml:mtr><mml:mtd><mml:mi>p</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mi>Ï„</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mn>1</mml:mn><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mi>D</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mtd><mml:mtd><mml:mo>=</mml:mo><mml:mn>1</mml:mn><mml:mo>âˆ’</mml:mo><mml:mi>p</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mi>Ï„</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mn>0</mml:mn><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mi>D</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mtd></mml:mtr><mml:mtr><mml:mtd/><mml:mtd><mml:mo>=</mml:mo><mml:mn>1</mml:mn><mml:mo>âˆ’</mml:mo><mml:mo>âˆ«</mml:mo><mml:mi>p</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mi>Ï„</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mn>0</mml:mn><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:msub><mml:mi>Î¸</mml:mi><mml:mrow><mml:mi>j</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn><mml:mo>:</mml:mo><mml:mi>Ï„</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:mi>P</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>Î¸</mml:mi><mml:mrow><mml:mi>j</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn><mml:mo>:</mml:mo><mml:mi>Ï„</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mi>D</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mi>d</mml:mi><mml:msub><mml:mi>Î¸</mml:mi><mml:mrow><mml:mi>j</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn><mml:mo>:</mml:mo><mml:mi>Ï„</mml:mi></mml:mrow></mml:msub></mml:mtd></mml:mtr><mml:mtr><mml:mtd/><mml:mtd><mml:mo>=</mml:mo><mml:mn>1</mml:mn><mml:mo>âˆ’</mml:mo><mml:mo>âˆ«</mml:mo><mml:munderover><mml:mo>âˆ</mml:mo><mml:mrow><mml:mi>j</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>Ï„</mml:mi></mml:munderover><mml:mi>p</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>z</mml:mi><mml:mi>j</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mn>0</mml:mn><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:msub><mml:mi>Î¸</mml:mi><mml:mi>j</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:mi>P</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>Î¸</mml:mi><mml:mi>j</mml:mi></mml:msub><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mi>D</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mi>d</mml:mi><mml:msub><mml:mi>Î¸</mml:mi><mml:mi>j</mml:mi></mml:msub></mml:mtd></mml:mtr><mml:mtr><mml:mtd/><mml:mtd><mml:mo>=</mml:mo><mml:mn>1</mml:mn><mml:mo>âˆ’</mml:mo><mml:mo>âˆ«</mml:mo><mml:munderover><mml:mo>âˆ</mml:mo><mml:mrow><mml:mi>j</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>Ï„</mml:mi></mml:munderover><mml:mo stretchy="false">(</mml:mo><mml:mn>1</mml:mn><mml:mo>âˆ’</mml:mo><mml:msub><mml:mi>Î¸</mml:mi><mml:mi>j</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:mtext>Beta</mml:mtext><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>Î¸</mml:mi><mml:mi>j</mml:mi></mml:msub><mml:mo>;</mml:mo><mml:msub><mml:mi>a</mml:mi><mml:mi>j</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mover><mml:mi>b</mml:mi><mml:mo stretchy="false">~</mml:mo></mml:mover></mml:mrow><mml:mi>j</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:mi>d</mml:mi><mml:msub><mml:mi>Î¸</mml:mi><mml:mi>j</mml:mi></mml:msub></mml:mtd></mml:mtr><mml:mtr><mml:mtd/><mml:mtd><mml:mo>=</mml:mo><mml:mn>1</mml:mn><mml:mo>âˆ’</mml:mo><mml:munderover><mml:mo>âˆ</mml:mo><mml:mrow><mml:mi>j</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>Ï„</mml:mi></mml:munderover><mml:mo>âˆ«</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mn>1</mml:mn><mml:mo>âˆ’</mml:mo><mml:msub><mml:mi>Î¸</mml:mi><mml:mi>j</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:mtext>Beta</mml:mtext><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>Î¸</mml:mi><mml:mi>j</mml:mi></mml:msub><mml:mo>;</mml:mo><mml:msub><mml:mi>a</mml:mi><mml:mi>j</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mover><mml:mi>b</mml:mi><mml:mo stretchy="false">~</mml:mo></mml:mover></mml:mrow><mml:mi>j</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:mi>d</mml:mi><mml:msub><mml:mi>Î¸</mml:mi><mml:mi>j</mml:mi></mml:msub></mml:mtd></mml:mtr><mml:mtr><mml:mtd/><mml:mtd><mml:mo>=</mml:mo><mml:mn>1</mml:mn><mml:mo>âˆ’</mml:mo><mml:munderover><mml:mo>âˆ</mml:mo><mml:mrow><mml:mi>j</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>Ï„</mml:mi></mml:munderover><mml:mo stretchy="false">(</mml:mo><mml:mn>1</mml:mn><mml:mo>âˆ’</mml:mo><mml:msub><mml:mi>Î¼</mml:mi><mml:mi>j</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:mspace width="30pt"/><mml:mspace width="30pt"/><mml:mspace width="30pt"/><mml:mspace width="30pt"/><mml:mspace width="30pt"/><mml:mi>â—»</mml:mi></mml:mtd></mml:mtr></mml:mtable></mml:mstyle></mml:mrow></mml:mstyle></mml:math><tex-math id="t13">\begin{document}$$\displaystyle \begin{array}{ll} p(x_\tau=1 |D) &amp;= 1-p(x_\tau= 0 |D) \\ &amp;= 1- \int p(x_\tau= 0 | \theta_{j=1:\tau}) P(\theta_{j=1:\tau} | D) d \theta_{j=1:\tau} \\ &amp;= 1- \int\prod_{j=1}^\tau p(z_j = 0 | \theta_j) P(\theta_j | D) d \theta_j \\ &amp;= 1- \int\prod_{j=1}^\tau(1-\theta_j) \text{Beta}(\theta_j; a_j, \tilde b_j) d \theta_j \\ &amp;= 1- \prod_{j=1}^\tau\int(1-\theta_j) \text{Beta}(\theta_j ; a_j, \tilde b_j) d \theta_j \\ &amp;= 1- \prod_{j=1}^\tau(1-\mu_j) \hspace{30 pt} \hspace{30 pt} \hspace{30 pt} \hspace{30 pt} \hspace{30 pt} \square \end{array}$$\end{document}</tex-math></alternatives></disp-formula></p><p>where <inline-formula><alternatives><mml:math id="inf176"><mml:mstyle><mml:mrow><mml:mstyle displaystyle="false"><mml:msub><mml:mrow><mml:mover><mml:mi>b</mml:mi><mml:mo stretchy="false">~</mml:mo></mml:mover></mml:mrow><mml:mi>j</mml:mi></mml:msub></mml:mstyle></mml:mrow></mml:mstyle></mml:math><tex-math id="inft176">\begin{document}$\tilde b_j$\end{document}</tex-math></alternatives></inline-formula> are the pseudocounts of negative observations after updating the Beta prior with <inline-formula><alternatives><mml:math id="inf177"><mml:semantics><mml:mrow><mml:mi>ğ·</mml:mi></mml:mrow></mml:semantics></mml:math><tex-math id="inft177">\begin{document}$D$\end{document}</tex-math></alternatives></inline-formula> using <xref ref-type="disp-formula" rid="equ11">Equation 7</xref>. It can be shown that <inline-formula><alternatives><mml:math id="inf178"><mml:semantics><mml:mrow><mml:mi>â„</mml:mi><mml:mo class="MathClass-open" stretchy="false">(</mml:mo><mml:mi>ğœ</mml:mi><mml:mo class="MathClass-close" stretchy="false">)</mml:mo></mml:mrow></mml:semantics></mml:math><tex-math id="inft178">\begin{document}$h(\tau)$\end{document}</tex-math></alternatives></inline-formula> is recursive,<disp-formula id="equ14"><label>(9)</label><alternatives><mml:math id="m14"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>h</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>Ï„</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mi>h</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>Ï„</mml:mi><mml:mo>âˆ’</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">)</mml:mo><mml:mo>+</mml:mo><mml:mo stretchy="false">[</mml:mo><mml:mn>1</mml:mn><mml:mo>âˆ’</mml:mo><mml:mi>h</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>Ï„</mml:mi><mml:mo>âˆ’</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">)</mml:mo><mml:mo stretchy="false">]</mml:mo><mml:msub><mml:mi>Î¼</mml:mi><mml:mi>Ï„</mml:mi></mml:msub></mml:mstyle></mml:mrow></mml:mstyle></mml:math><tex-math id="t14">\begin{document}$$\displaystyle h(\tau) = h(\tau-1) + [1-h(\tau-1)] \mu_\tau$$\end{document}</tex-math></alternatives></disp-formula></p><p>This recursion has two implications. First, the hazard function is monotonic since <inline-formula><alternatives><mml:math id="inf179"><mml:semantics><mml:mrow><mml:mo class="MathClass-open" stretchy="false">(</mml:mo><mml:mn>1</mml:mn><mml:mo class="MathClass-bin" stretchy="false">âˆ’</mml:mo><mml:mi>â„</mml:mi><mml:mo class="MathClass-open" stretchy="false">(</mml:mo><mml:mi>ğœ</mml:mi><mml:mo class="MathClass-bin" stretchy="false">âˆ’</mml:mo><mml:mn>1</mml:mn><mml:mo class="MathClass-close" stretchy="false">)</mml:mo><mml:mo class="MathClass-close" stretchy="false">)</mml:mo><mml:mo class="MathClass-rel" stretchy="false">&gt;</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:semantics></mml:math><tex-math id="inft179">\begin{document}$(1-h(\tau-1)) \gt 0$\end{document}</tex-math></alternatives></inline-formula> and <inline-formula><alternatives><mml:math id="inf180"><mml:semantics><mml:mrow><mml:msub><mml:mrow><mml:mi>ğœ‡</mml:mi></mml:mrow><mml:mrow><mml:mi>ğœ</mml:mi></mml:mrow></mml:msub><mml:mo class="MathClass-rel" stretchy="false">&gt;</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:semantics></mml:math><tex-math id="inft180">\begin{document}$\mu_\tau \gt 0$\end{document}</tex-math></alternatives></inline-formula>. Second, the hazard function generalizes. From <xref ref-type="disp-formula" rid="equ14">Equation 9</xref> it is clear if <inline-formula><alternatives><mml:math id="inf181"><mml:semantics><mml:mrow><mml:mi>â„</mml:mi><mml:mo class="MathClass-open" stretchy="false">(</mml:mo><mml:mi>ğœ</mml:mi><mml:mo class="MathClass-bin" stretchy="false">âˆ’</mml:mo><mml:mn>1</mml:mn><mml:mo class="MathClass-close" stretchy="false">)</mml:mo></mml:mrow></mml:semantics></mml:math><tex-math id="inft181">\begin{document}$h(\tau-1)$\end{document}</tex-math></alternatives></inline-formula> increases, then <inline-formula><alternatives><mml:math id="inf182"><mml:semantics><mml:mrow><mml:mi>â„</mml:mi><mml:mo class="MathClass-open" stretchy="false">(</mml:mo><mml:mi>ğœ</mml:mi><mml:mo class="MathClass-close" stretchy="false">)</mml:mo></mml:mrow></mml:semantics></mml:math><tex-math id="inft182">\begin{document}$h(\tau)$\end{document}</tex-math></alternatives></inline-formula> increases. It is this generalization that allows the agent to progressively spend more turns at the object.</p><sec id="s4-3-1"><title>Transforming <inline-formula><alternatives><mml:math id="inf183"><mml:semantics><mml:mrow><mml:mi>ğœ‡</mml:mi><mml:mo class="MathClass-punc" stretchy="false">,</mml:mo><mml:mi>ğœ</mml:mi></mml:mrow></mml:semantics></mml:math><tex-math id="inft183">\begin{document}$\mu, \sigma$\end{document}</tex-math></alternatives></inline-formula> to pseudocount parameterization of Beta distribution</title><p>We use the mean <inline-formula><alternatives><mml:math id="inf184"><mml:semantics><mml:mrow><mml:mi>ğœ‡</mml:mi></mml:mrow></mml:semantics></mml:math><tex-math id="inft184">\begin{document}$\mu$\end{document}</tex-math></alternatives></inline-formula> and variance <inline-formula><alternatives><mml:math id="inf185"><mml:semantics><mml:mrow><mml:mi>ğ‘£</mml:mi><mml:mo class="MathClass-rel" stretchy="false">=</mml:mo><mml:msup><mml:mrow><mml:mi>ğœ</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:semantics></mml:math><tex-math id="inft185">\begin{document}$v = \sigma^2$\end{document}</tex-math></alternatives></inline-formula> parameterization of the Beta distribution to get a more uniform sampling of the prior parameter space for ABCSMC fitting. We sample <inline-formula><alternatives><mml:math id="inf186"><mml:semantics><mml:mrow><mml:mi>ğœ‡</mml:mi></mml:mrow></mml:semantics></mml:math><tex-math id="inft186">\begin{document}$\mu$\end{document}</tex-math></alternatives></inline-formula> and <inline-formula><alternatives><mml:math id="inf187"><mml:semantics><mml:mrow><mml:mi>ğœ</mml:mi></mml:mrow></mml:semantics></mml:math><tex-math id="inft187">\begin{document}$\sigma$\end{document}</tex-math></alternatives></inline-formula> from uniform distributions. However, it is more convenient to work with pseudocounts for computing the hazard posterior. Therefore, we transform <inline-formula><alternatives><mml:math id="inf188"><mml:semantics><mml:mrow><mml:mi>ğœ‡</mml:mi></mml:mrow></mml:semantics></mml:math><tex-math id="inft188">\begin{document}$\mu$\end{document}</tex-math></alternatives></inline-formula> and <inline-formula><alternatives><mml:math id="inf189"><mml:semantics><mml:mrow><mml:mi>ğœ</mml:mi></mml:mrow></mml:semantics></mml:math><tex-math id="inft189">\begin{document}$\sigma$\end{document}</tex-math></alternatives></inline-formula> to pseudocounts <inline-formula><alternatives><mml:math id="inf190"><mml:semantics><mml:mrow><mml:mi>ğ‘</mml:mi><mml:mo class="MathClass-punc" stretchy="false">,</mml:mo><mml:mi>ğ‘</mml:mi></mml:mrow></mml:semantics></mml:math><tex-math id="inft190">\begin{document}$a, b$\end{document}</tex-math></alternatives></inline-formula> using the identities below. Note that <inline-formula><alternatives><mml:math id="inf191"><mml:semantics><mml:mrow><mml:mi>ğ‘£</mml:mi></mml:mrow></mml:semantics></mml:math><tex-math id="inft191">\begin{document}$v$\end{document}</tex-math></alternatives></inline-formula> must be less than <inline-formula><alternatives><mml:math id="inf192"><mml:semantics><mml:mrow><mml:mi>ğœ‡</mml:mi><mml:mo class="MathClass-bin" stretchy="false">âˆ’</mml:mo><mml:msup><mml:mrow><mml:mi>ğœ‡</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:semantics></mml:math><tex-math id="inft192">\begin{document}$\mu-\mu^2$\end{document}</tex-math></alternatives></inline-formula> to avoid negative values of <inline-formula><alternatives><mml:math id="inf193"><mml:semantics><mml:mrow><mml:mi>ğ‘</mml:mi><mml:mo class="MathClass-punc" stretchy="false">,</mml:mo><mml:mi>ğ‘</mml:mi></mml:mrow></mml:semantics></mml:math><tex-math id="inft193">\begin{document}$a, b$\end{document}</tex-math></alternatives></inline-formula>,<disp-formula id="equ15"><label>(10)</label><alternatives><mml:math id="m15"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>Î¼</mml:mi><mml:mo>âˆ¼</mml:mo><mml:mo stretchy="false">[</mml:mo><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">]</mml:mo></mml:mstyle></mml:mrow></mml:mstyle></mml:math><tex-math id="t15">\begin{document}$$\displaystyle \mu\sim[0, 1]$$\end{document}</tex-math></alternatives></disp-formula><disp-formula id="equ16"><label>(11)</label><alternatives><mml:math id="m16"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>v</mml:mi><mml:mo>âˆ¼</mml:mo><mml:mo stretchy="false">[</mml:mo><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:mi>Î¼</mml:mi><mml:mo>âˆ’</mml:mo><mml:msup><mml:mi>Î¼</mml:mi><mml:mn>2</mml:mn></mml:msup><mml:mo stretchy="false">]</mml:mo></mml:mstyle></mml:mrow></mml:mstyle></mml:math><tex-math id="t16">\begin{document}$$\displaystyle v \sim[0, \mu-\mu^2]$$\end{document}</tex-math></alternatives></disp-formula><disp-formula id="equ17"><label>(12)</label><alternatives><mml:math id="m17"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>a</mml:mi><mml:mo>=</mml:mo><mml:mo>âˆ’</mml:mo><mml:mfrac><mml:mrow><mml:mi>Î¼</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msup><mml:mi>Î¼</mml:mi><mml:mn>2</mml:mn></mml:msup><mml:mo>âˆ’</mml:mo><mml:mi>Î¼</mml:mi><mml:mo>+</mml:mo><mml:mi>v</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mi>v</mml:mi></mml:mfrac></mml:mstyle></mml:mrow></mml:mstyle></mml:math><tex-math id="t17">\begin{document}$$\displaystyle a = -\frac{\mu(\mu^2 - \mu+ v)}{v}$$\end{document}</tex-math></alternatives></disp-formula><disp-formula id="equ18"><label>(13)</label><alternatives><mml:math id="m18"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>b</mml:mi><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>Î¼</mml:mi><mml:mo>âˆ’</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">)</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:msup><mml:mi>Î¼</mml:mi><mml:mn>2</mml:mn></mml:msup><mml:mo>âˆ’</mml:mo><mml:mi>Î¼</mml:mi><mml:mo>+</mml:mo><mml:mi>v</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mi>v</mml:mi></mml:mfrac></mml:mstyle></mml:mrow></mml:mstyle></mml:math><tex-math id="t18">\begin{document}$$\displaystyle b = \frac{(\mu- 1)(\mu^2 - \mu+ v)}{v}$$\end{document}</tex-math></alternatives></disp-formula></p></sec></sec><sec id="s4-4"><title>Heuristic exploration bonus pool</title><p>The heuristic reward function approximates the sort of exploration bonus (<xref ref-type="bibr" rid="bib31">Gittins, 1979</xref>) that would arise from uncertainty about potential exploitable benefits of the object. It incentivizes approach and engagement. In the experiment, there is no actual reward so the motivation is purely intrinsic (<xref ref-type="bibr" rid="bib55">Oudeyer and Kaplan, 2007</xref>). The exploration bonus depletes as the agent learns about the object but regenerates if the agent believes that the object can change over time (or, equivalently, if the agent forgets what it has learned). This regenerating uncertainty can be modeled normatively using POMDPs but is only approximated here. Since we imagine the agent as finding more out about the object through a confident than a cautious approach, the former generates a greater bonus per step, but also depletes it more quickly.</p><p>We model the exploration-based reward as an exponentially decreasing resource. <inline-formula><alternatives><mml:math id="inf194"><mml:semantics><mml:mrow><mml:mi>ğº</mml:mi><mml:mo class="MathClass-open" stretchy="false">(</mml:mo><mml:mi>ğ‘¡</mml:mi><mml:mo class="MathClass-close" stretchy="false">)</mml:mo></mml:mrow></mml:semantics></mml:math><tex-math id="inft194">\begin{document}$G(t)$\end{document}</tex-math></alternatives></inline-formula> is the â€˜exploration bonus poolâ€™ and can be interpreted as the agentâ€™s remaining motivation to explore in the future. We fit the size of the initial exploration pool <inline-formula><alternatives><mml:math id="inf195"><mml:semantics><mml:mrow><mml:mi>ğº</mml:mi><mml:mo class="MathClass-open" stretchy="false">(</mml:mo><mml:mn>0</mml:mn><mml:mo class="MathClass-close" stretchy="false">)</mml:mo><mml:mo class="MathClass-rel" stretchy="false">=</mml:mo><mml:msub><mml:mrow><mml:mi>ğº</mml:mi></mml:mrow><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:semantics></mml:math><tex-math id="inft195">\begin{document}$G(0) = G_0$\end{document}</tex-math></alternatives></inline-formula> to the behavior of each animal. During planning, the agent imagines receiving rewards at the cautious and confident object states proportional to <inline-formula><alternatives><mml:math id="inf196"><mml:semantics><mml:mrow><mml:mi>ğº</mml:mi><mml:mo class="MathClass-open" stretchy="false">(</mml:mo><mml:mi>ğ‘¡</mml:mi><mml:mo class="MathClass-close" stretchy="false">)</mml:mo></mml:mrow></mml:semantics></mml:math><tex-math id="inft196">\begin{document}$G(t)$\end{document}</tex-math></alternatives></inline-formula>,<disp-formula id="equ19"><label>(14)</label><alternatives><mml:math id="m19"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msub><mml:mrow><mml:mover><mml:mi>r</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mtext>cautious</mml:mtext></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:msub><mml:mi>Ï‰</mml:mi><mml:mrow><mml:mtext>cautious</mml:mtext></mml:mrow></mml:msub><mml:mo>â‹…</mml:mo><mml:mi>G</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mstyle></mml:mrow></mml:mstyle></mml:math><tex-math id="t19">\begin{document}$$\displaystyle \hat r_{\text{cautious}} = \omega_{\text{cautious}} \cdot G(t)$$\end{document}</tex-math></alternatives></disp-formula><disp-formula id="equ20"><label>(15)</label><alternatives><mml:math id="m20"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msub><mml:mrow><mml:mover><mml:mi>r</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mtext>confident</mml:mtext></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:msub><mml:mi>Ï‰</mml:mi><mml:mrow><mml:mtext>confident</mml:mtext></mml:mrow></mml:msub><mml:mo>â‹…</mml:mo><mml:mi>G</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mstyle></mml:mrow></mml:mstyle></mml:math><tex-math id="t20">\begin{document}$$\displaystyle \hat r_{\text{confident}} = \omega_{\text{confident}} \cdot G(t)$$\end{document}</tex-math></alternatives></disp-formula><disp-formula id="equ21"><label>(16)</label><alternatives><mml:math id="m21"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msub><mml:mrow><mml:mover><mml:mi>r</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mtext>cautious</mml:mtext></mml:mrow></mml:msub><mml:mo>&lt;</mml:mo><mml:msub><mml:mrow><mml:mover><mml:mi>r</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mtext>confident</mml:mtext></mml:mrow></mml:msub></mml:mstyle></mml:mrow></mml:mstyle></mml:math><tex-math id="t21">\begin{document}$$\displaystyle \hat r_{\text{cautious}} \lt \hat r_{\text{confident}}$$\end{document}</tex-math></alternatives></disp-formula></p><p>On every turn at the cautious or confident object states, the agent extracts reward <inline-formula><alternatives><mml:math id="inf197"><mml:semantics><mml:mrow><mml:msub><mml:mrow><mml:mover accent="true"><mml:mrow><mml:mi>ğ‘Ÿ</mml:mi></mml:mrow><mml:mo accent="true">^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mstyle class="text"><mml:mtext>cautious</mml:mtext></mml:mstyle></mml:mrow></mml:msub></mml:mrow></mml:semantics></mml:math><tex-math id="inft197">\begin{document}$\hatr_{\text{cautious}}$\end{document}</tex-math></alternatives></inline-formula> or <inline-formula><alternatives><mml:math id="inf198"><mml:semantics><mml:mrow><mml:msub><mml:mrow><mml:mover accent="true"><mml:mrow><mml:mi>ğ‘Ÿ</mml:mi></mml:mrow><mml:mo accent="true">^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mstyle class="text"><mml:mtext>confident</mml:mtext></mml:mstyle></mml:mrow></mml:msub></mml:mrow></mml:semantics></mml:math><tex-math id="inft198">\begin{document}$\hatr_{\text{confident}}$\end{document}</tex-math></alternatives></inline-formula> from its budget <inline-formula><alternatives><mml:math id="inf199"><mml:semantics><mml:mrow><mml:mi>ğº</mml:mi></mml:mrow></mml:semantics></mml:math><tex-math id="inft199">\begin{document}$G$\end{document}</tex-math></alternatives></inline-formula>, depleting <inline-formula><alternatives><mml:math id="inf200"><mml:semantics><mml:mrow><mml:mi>ğº</mml:mi></mml:mrow></mml:semantics></mml:math><tex-math id="inft200">\begin{document}$G$\end{document}</tex-math></alternatives></inline-formula> at rates <inline-formula><alternatives><mml:math id="inf201"><mml:semantics><mml:mrow><mml:msub><mml:mrow><mml:mi>ğœ”</mml:mi></mml:mrow><mml:mrow><mml:mstyle class="text"><mml:mtext>cautious</mml:mtext></mml:mstyle></mml:mrow></mml:msub></mml:mrow></mml:semantics></mml:math><tex-math id="inft201">\begin{document}$\omega_{\text{cautious}}$\end{document}</tex-math></alternatives></inline-formula> or <inline-formula><alternatives><mml:math id="inf202"><mml:semantics><mml:mrow><mml:msub><mml:mrow><mml:mi>ğœ”</mml:mi></mml:mrow><mml:mrow><mml:mstyle class="text"><mml:mtext>confident</mml:mtext></mml:mstyle></mml:mrow></mml:msub></mml:mrow></mml:semantics></mml:math><tex-math id="inft202">\begin{document}$\omega_{\text{confident}}$\end{document}</tex-math></alternatives></inline-formula>. This leads to an exponential decrease in <inline-formula><alternatives><mml:math id="inf203"><mml:semantics><mml:mrow><mml:mi>ğº</mml:mi><mml:mo class="MathClass-open" stretchy="false">(</mml:mo><mml:mi>ğ‘¡</mml:mi><mml:mo class="MathClass-close" stretchy="false">)</mml:mo></mml:mrow></mml:semantics></mml:math><tex-math id="inft203">\begin{document}$G(t)$\end{document}</tex-math></alternatives></inline-formula> with turns spent at the object, which is clear from <xref ref-type="disp-formula" rid="equ22">Equation 17</xref>. For example, at the cautious object state, the update to <inline-formula><alternatives><mml:math id="inf204"><mml:semantics><mml:mrow><mml:mi>ğº</mml:mi><mml:mo class="MathClass-open" stretchy="false">(</mml:mo><mml:mi>ğ‘¡</mml:mi><mml:mo class="MathClass-close" stretchy="false">)</mml:mo></mml:mrow></mml:semantics></mml:math><tex-math id="inft204">\begin{document}$G(t)$\end{document}</tex-math></alternatives></inline-formula> is,<disp-formula id="equ22"><label>(17)</label><alternatives><mml:math id="m22"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>G</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mi>G</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>âˆ’</mml:mo><mml:msub><mml:mrow><mml:mover><mml:mi>r</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mtext>cautious</mml:mtext></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mn>1</mml:mn><mml:mo>âˆ’</mml:mo><mml:msub><mml:mi>Ï‰</mml:mi><mml:mrow><mml:mtext>cautious</mml:mtext></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:mi>G</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mstyle></mml:mrow></mml:mstyle></mml:math><tex-math id="t22">\begin{document}$$\displaystyle G(t+1) = G(t) - \hat r_{\text{cautious}} = (1 - \omega_{\text{cautious}}) G(t)$$\end{document}</tex-math></alternatives></disp-formula></p><p>However, a secondary factor affects the update to <inline-formula><alternatives><mml:math id="inf205"><mml:mstyle><mml:mrow><mml:mstyle displaystyle="false"><mml:mi>G</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mstyle></mml:mrow></mml:mstyle></mml:math><tex-math id="inft205">\begin{document}$G(t)$\end{document}</tex-math></alternatives></inline-formula>. <inline-formula><alternatives><mml:math id="inf206"><mml:mstyle><mml:mrow><mml:mstyle displaystyle="false"><mml:mi>G</mml:mi></mml:mstyle></mml:mrow></mml:mstyle></mml:math><tex-math id="inft206">\begin{document}$G$\end{document}</tex-math></alternatives></inline-formula> linearly regenerates back to <inline-formula><alternatives><mml:math id="inf207"><mml:mstyle><mml:mrow><mml:mstyle displaystyle="false"><mml:msub><mml:mi>G</mml:mi><mml:mn>0</mml:mn></mml:msub></mml:mstyle></mml:mrow></mml:mstyle></mml:math><tex-math id="inft207">\begin{document}$G_0$\end{document}</tex-math></alternatives></inline-formula> at the forgetting rate <inline-formula><alternatives><mml:math id="inf208"><mml:mstyle><mml:mrow><mml:mstyle displaystyle="false"><mml:mi>f</mml:mi></mml:mstyle></mml:mrow></mml:mstyle></mml:math><tex-math id="inft208">\begin{document}$f$\end{document}</tex-math></alternatives></inline-formula> which we also fit for each animal. The full update to the reward pool for spending one turn at the cautious object state is,<disp-formula id="equ23"><label>(18)</label><alternatives><mml:math id="m23"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>G</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mo movablelimits="true" form="prefix">min</mml:mo><mml:mo fence="false" stretchy="false">{</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mn>1</mml:mn><mml:mo>âˆ’</mml:mo><mml:msub><mml:mi>Ï‰</mml:mi><mml:mrow><mml:mtext>cautious</mml:mtext></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:mi>G</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>+</mml:mo><mml:mi>f</mml:mi><mml:mo>,</mml:mo><mml:msub><mml:mi>G</mml:mi><mml:mn>0</mml:mn></mml:msub><mml:mo fence="false" stretchy="false">}</mml:mo></mml:mstyle></mml:mrow></mml:mstyle></mml:math><tex-math id="t23">\begin{document}$$\displaystyle G(t+1) = \min\{(1-\omega_{\text{cautious}}) G(t) + f, G_0\}$$\end{document}</tex-math></alternatives></disp-formula></p><p>Note that <inline-formula><alternatives><mml:math id="inf209"><mml:mstyle><mml:mrow><mml:mstyle displaystyle="false"><mml:mi>G</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mstyle></mml:mrow></mml:mstyle></mml:math><tex-math id="inft209">\begin{document}$G(t)$\end{document}</tex-math></alternatives></inline-formula> regenerates by <inline-formula><alternatives><mml:math id="inf210"><mml:mstyle><mml:mrow><mml:mstyle displaystyle="false"><mml:mi>f</mml:mi></mml:mstyle></mml:mrow></mml:mstyle></mml:math><tex-math id="inft210">\begin{document}$f$\end{document}</tex-math></alternatives></inline-formula> in all states, not only at the object states. We use linear forgetting for its simplicity, although other mechanisms such as exponential forgetting are possible.</p><p>Finally, for completeness in other environments, the reward the agent imagines receiving also depends on the actual reward it has received in the past. Let <inline-formula><alternatives><mml:math id="inf211"><mml:semantics><mml:mrow><mml:msup><mml:mrow><mml:mi>ğ‘›</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:semantics></mml:math><tex-math id="inft211">\begin{document}$n^1$\end{document}</tex-math></alternatives></inline-formula> and <inline-formula><alternatives><mml:math id="inf212"><mml:semantics><mml:mrow><mml:msup><mml:mrow><mml:mi>ğ‘›</mml:mi></mml:mrow><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:semantics></mml:math><tex-math id="inft212">\begin{document}$n^0$\end{document}</tex-math></alternatives></inline-formula> be the number of times the agent has received one or zero reward at the object state, analogous to the pseudocounts of a Beta posterior in a fully Bayesian treatment of reward. Furthermore, let <inline-formula><alternatives><mml:math id="inf213"><mml:semantics><mml:mrow><mml:msubsup><mml:mrow><mml:mi>ğ‘›</mml:mi></mml:mrow><mml:mrow><mml:mn>0</mml:mn></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msubsup></mml:mrow></mml:semantics></mml:math><tex-math id="inft213">\begin{document}$n^1_0$\end{document}</tex-math></alternatives></inline-formula> and <inline-formula><alternatives><mml:math id="inf214"><mml:semantics><mml:mrow><mml:msubsup><mml:mrow><mml:mi>ğ‘›</mml:mi></mml:mrow><mml:mrow><mml:mn>0</mml:mn></mml:mrow><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msubsup></mml:mrow></mml:semantics></mml:math><tex-math id="inft214">\begin{document}$n^0_0$\end{document}</tex-math></alternatives></inline-formula> be the (fitted) values at <inline-formula><alternatives><mml:math id="inf215"><mml:semantics><mml:mrow><mml:mi>ğ‘¡</mml:mi><mml:mo class="MathClass-rel" stretchy="false">=</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:semantics></mml:math><tex-math id="inft215">\begin{document}$t=0$\end{document}</tex-math></alternatives></inline-formula>. We use <inline-formula><alternatives><mml:math id="inf216"><mml:semantics><mml:mrow><mml:msubsup><mml:mrow><mml:mi>ğ‘›</mml:mi></mml:mrow><mml:mrow><mml:mn>0</mml:mn></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msubsup><mml:mo class="MathClass-rel" stretchy="false">=</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:semantics></mml:math><tex-math id="inft216">\begin{document}$n^1_0=1$\end{document}</tex-math></alternatives></inline-formula> and <inline-formula><alternatives><mml:math id="inf217"><mml:semantics><mml:mrow><mml:msubsup><mml:mrow><mml:mi>ğ‘›</mml:mi></mml:mrow><mml:mrow><mml:mn>0</mml:mn></mml:mrow><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msubsup><mml:mo class="MathClass-rel" stretchy="false">=</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:semantics></mml:math><tex-math id="inft217">\begin{document}$n^0_0=1$\end{document}</tex-math></alternatives></inline-formula>. The agent imagines receiving reward<disp-formula id="equ24"><label>(19)</label><alternatives><mml:math id="m24"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msub><mml:mi>r</mml:mi><mml:mrow><mml:mtext>cautious</mml:mtext></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:msub><mml:mrow><mml:mover><mml:mi>r</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mtext>cautious</mml:mtext></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:mfrac><mml:msup><mml:mi>n</mml:mi><mml:mn>1</mml:mn></mml:msup><mml:mrow><mml:msup><mml:mi>n</mml:mi><mml:mn>1</mml:mn></mml:msup><mml:mo>+</mml:mo><mml:msup><mml:mi>n</mml:mi><mml:mn>0</mml:mn></mml:msup></mml:mrow></mml:mfrac></mml:mstyle></mml:mrow></mml:mstyle></mml:math><tex-math id="t24">\begin{document}$$\displaystyle r_{\text{cautious}} = \hat {r}_{\text{cautious}} + \frac{n^1}{n^1+n^0}$$\end{document}</tex-math></alternatives></disp-formula></p><p>after spending one turn in the cautious object state. A similar equation applies to the confident object state.</p><p>We define the depletion rates as <inline-formula><alternatives><mml:math id="inf218"><mml:semantics><mml:mrow><mml:msub><mml:mrow><mml:mi>ğœ”</mml:mi></mml:mrow><mml:mrow><mml:mstyle class="text"><mml:mtext>confident</mml:mtext></mml:mstyle></mml:mrow></mml:msub><mml:mo class="MathClass-rel" stretchy="false">=</mml:mo><mml:mfrac><mml:mrow><mml:mi>ğ‘…</mml:mi></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>ğº</mml:mi></mml:mrow><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:mfrac></mml:mrow></mml:semantics></mml:math><tex-math id="inft218">\begin{document}$\omega_{\text{confident}} = \frac{R}{G_0}$\end{document}</tex-math></alternatives></inline-formula> and <inline-formula><alternatives><mml:math id="inf219"><mml:semantics><mml:mrow><mml:msub><mml:mrow><mml:mi>ğœ”</mml:mi></mml:mrow><mml:mrow><mml:mstyle class="text"><mml:mtext>cautious</mml:mtext></mml:mstyle></mml:mrow></mml:msub><mml:mo class="MathClass-rel" stretchy="false">=</mml:mo><mml:mi>ğ¾</mml:mi><mml:mo class="MathClass-bin" stretchy="false">â‹…</mml:mo><mml:msub><mml:mrow><mml:mi>ğœ”</mml:mi></mml:mrow><mml:mrow><mml:mstyle class="text"><mml:mtext>confident</mml:mtext></mml:mstyle></mml:mrow></mml:msub></mml:mrow></mml:semantics></mml:math><tex-math id="inft219">\begin{document}$\omega_{\text{cautious}} = K \cdot\omega_{\text{confident}}$\end{document}</tex-math></alternatives></inline-formula> with constants <inline-formula><alternatives><mml:math id="inf220"><mml:semantics><mml:mrow><mml:mi>ğ‘…</mml:mi><mml:mo class="MathClass-rel" stretchy="false">=</mml:mo><mml:mn>1.1</mml:mn></mml:mrow></mml:semantics></mml:math><tex-math id="inft220">\begin{document}$R=1.1$\end{document}</tex-math></alternatives></inline-formula> and <inline-formula><alternatives><mml:math id="inf221"><mml:semantics><mml:mrow><mml:mi>ğ¾</mml:mi><mml:mo class="MathClass-rel" stretchy="false">=</mml:mo><mml:mn>0.89</mml:mn><mml:mo class="MathClass-rel" stretchy="false">&lt;</mml:mo><mml:mn>1.0</mml:mn></mml:mrow></mml:semantics></mml:math><tex-math id="inft221">\begin{document}$K=0.89 \lt 1.0$\end{document}</tex-math></alternatives></inline-formula>. These values were fitted to capture the full range of behavior of the 26 animals.</p></sec><sec id="s4-5"><title>Data fitting</title><p>Data fitting aims to elucidate individual differences and population patterns in behavior by searching for the model parameters that best describe the behavior of each animal. We map the behavior of model and animals to a shared abstract space using a common set of statistics and then fit the model to data using ABCSMC.</p><sec id="s4-5-1"><title>Animal statistics</title><p>To extract animal statistics, we first coarse-grain behavior into phases and subsequently classify the animals into three groups: brave, intermediate, and timid (as described in the main text). This allows us to maintain the temporal dynamics of the behavior while reducing the dimension of the data. We average the approach type, duration, and frequency over each phase and fit a subset of statistics that capture the high-level temporal dynamics of behavior of animals in each group.</p><p>The behavior of brave animals comes in three phases: cautious, confident-peak, and confident-steady state. We fit five statistics: the transition time from cautious to confident-peak phase <inline-formula><alternatives><mml:math id="inf222"><mml:semantics><mml:mrow><mml:msup><mml:mrow><mml:mi>ğ‘¡</mml:mi></mml:mrow><mml:mrow><mml:mstyle class="text"><mml:mtext>cautious-to-confident</mml:mtext></mml:mstyle></mml:mrow></mml:msup></mml:mrow></mml:semantics></mml:math><tex-math id="inft222">\begin{document}$t^{\text{cautious-to-confident}}$\end{document}</tex-math></alternatives></inline-formula>, the transition time from confident-peak to confident-steady-state phase <inline-formula><alternatives><mml:math id="inf223"><mml:semantics><mml:mrow><mml:msup><mml:mrow><mml:mi>ğ‘¡</mml:mi></mml:mrow><mml:mrow><mml:mstyle class="text"><mml:mtext>peak-to-steady</mml:mtext></mml:mstyle></mml:mrow></mml:msup></mml:mrow></mml:semantics></mml:math><tex-math id="inft223">\begin{document}$t^{\text{peak-to-steady}}$\end{document}</tex-math></alternatives></inline-formula>, the average durations during the cautious and confident-peak phases <inline-formula><alternatives><mml:math id="inf224"><mml:semantics><mml:mrow><mml:msup><mml:mrow><mml:mi>ğ‘‘</mml:mi></mml:mrow><mml:mrow><mml:mstyle class="text"><mml:mtext>cautious</mml:mtext></mml:mstyle></mml:mrow></mml:msup><mml:mo class="MathClass-punc" stretchy="false">,</mml:mo><mml:msup><mml:mrow><mml:mi>ğ‘‘</mml:mi></mml:mrow><mml:mrow><mml:mstyle class="text"><mml:mtext>peak-confident</mml:mtext></mml:mstyle></mml:mrow></mml:msup></mml:mrow></mml:semantics></mml:math><tex-math id="inft224">\begin{document}$d^{\text{cautious}}, d^{\text{peak-confident}}$\end{document}</tex-math></alternatives></inline-formula>, and the ratio of confident-peak and confident-steady-state phasesâ€™ frequencies <inline-formula><alternatives><mml:math id="inf225"><mml:semantics><mml:mrow><mml:mfrac><mml:mrow><mml:msup><mml:mrow><mml:mi>ğ‘“</mml:mi></mml:mrow><mml:mrow><mml:mstyle class="text"><mml:mtext>confident-peak</mml:mtext></mml:mstyle></mml:mrow></mml:msup></mml:mrow><mml:mrow><mml:msup><mml:mrow><mml:mi>ğ‘“</mml:mi></mml:mrow><mml:mrow><mml:mstyle class="text"><mml:mtext>confident-steady</mml:mtext></mml:mstyle></mml:mrow></mml:msup></mml:mrow></mml:mfrac></mml:mrow></mml:semantics></mml:math><tex-math id="inft225">\begin{document}$\frac{f^{\text{confident-peak}}}{f^{\text{confident-steady}}}$\end{document}</tex-math></alternatives></inline-formula>.</p><p>Intermediate animals only exhibit two phases: cautious and confident. We fit four statistics: the transition time from cautious to confident phase <inline-formula><alternatives><mml:math id="inf226"><mml:semantics><mml:mrow><mml:msup><mml:mrow><mml:mi>ğ‘¡</mml:mi></mml:mrow><mml:mrow><mml:mstyle class="text"><mml:mtext>cautious-to-confident</mml:mtext></mml:mstyle></mml:mrow></mml:msup></mml:mrow></mml:semantics></mml:math><tex-math id="inft226">\begin{document}$t^{\text{cautious-to-confident}}$\end{document}</tex-math></alternatives></inline-formula>, the durations of the two phases <inline-formula><alternatives><mml:math id="inf227"><mml:semantics><mml:mrow><mml:msup><mml:mrow><mml:mi>ğ‘‘</mml:mi></mml:mrow><mml:mrow><mml:mstyle class="text"><mml:mtext>cautious</mml:mtext></mml:mstyle></mml:mrow></mml:msup><mml:mo class="MathClass-punc" stretchy="false">,</mml:mo><mml:msup><mml:mrow><mml:mi>ğ‘‘</mml:mi></mml:mrow><mml:mrow><mml:mstyle class="text"><mml:mtext>confident</mml:mtext></mml:mstyle></mml:mrow></mml:msup></mml:mrow></mml:semantics></mml:math><tex-math id="inft227">\begin{document}$d^{\text{cautious}}, d^{\text{confident}}$\end{document}</tex-math></alternatives></inline-formula>, and the ratio of the cautious and confident phases frequencies <inline-formula><alternatives><mml:math id="inf228"><mml:semantics><mml:mrow><mml:mfrac><mml:mrow><mml:msup><mml:mrow><mml:mi>ğ‘“</mml:mi></mml:mrow><mml:mrow><mml:mstyle class="text"><mml:mtext>cautious</mml:mtext></mml:mstyle></mml:mrow></mml:msup></mml:mrow><mml:mrow><mml:msup><mml:mrow><mml:mi>ğ‘“</mml:mi></mml:mrow><mml:mrow><mml:mstyle class="text"><mml:mtext>confident</mml:mtext></mml:mstyle></mml:mrow></mml:msup></mml:mrow></mml:mfrac></mml:mrow></mml:semantics></mml:math><tex-math id="inft228">\begin{document}$\frac{f^{\text{cautious}}}{f^{\text{confident}}}$\end{document}</tex-math></alternatives></inline-formula>. However, one limitation of the model is that frequency can only decrease, not increase, because of the dynamics of depletion and replenishment of the exploration bonus pool. Hence, we instead fit <inline-formula><alternatives><mml:math id="inf229"><mml:mstyle><mml:mrow><mml:mstyle displaystyle="false"><mml:mo movablelimits="true" form="prefix">max</mml:mo><mml:mo fence="false" stretchy="false">{</mml:mo><mml:mfrac><mml:msup><mml:mi>f</mml:mi><mml:mrow><mml:mtext>cautious</mml:mtext></mml:mrow></mml:msup><mml:msup><mml:mi>f</mml:mi><mml:mrow><mml:mtext>confident</mml:mtext></mml:mrow></mml:msup></mml:mfrac><mml:mo>,</mml:mo><mml:mn>1.0</mml:mn><mml:mo fence="false" stretchy="false">}</mml:mo></mml:mstyle></mml:mrow></mml:mstyle></mml:math><tex-math id="inft229">\begin{document}$\max\{\frac{f^{\text{cautious}}}{f^{\text{confident}}}, 1.0 \}$\end{document}</tex-math></alternatives></inline-formula>.</p><p>Timid animals also only exhibit two phases, albeit different ones from the intermediate animals: cautious-peak and cautious-steady-state. We fit four statistics: the transition time from cautious-peak to cautious-steady-state phase <inline-formula><alternatives><mml:math id="inf230"><mml:semantics><mml:mrow><mml:msup><mml:mrow><mml:mi>ğ‘¡</mml:mi></mml:mrow><mml:mrow><mml:mstyle class="text"><mml:mtext>peak-to-steady</mml:mtext></mml:mstyle></mml:mrow></mml:msup></mml:mrow></mml:semantics></mml:math><tex-math id="inft230">\begin{document}$t^{\text{peak-to-steady}}$\end{document}</tex-math></alternatives></inline-formula>, the durations of the two phases <inline-formula><alternatives><mml:math id="inf231"><mml:semantics><mml:mrow><mml:msup><mml:mrow><mml:mi>ğ‘‘</mml:mi></mml:mrow><mml:mrow><mml:mstyle class="text"><mml:mtext>cautious-peak</mml:mtext></mml:mstyle></mml:mrow></mml:msup></mml:mrow></mml:semantics></mml:math><tex-math id="inft231">\begin{document}$d^{\text{cautious-peak}}$\end{document}</tex-math></alternatives></inline-formula> and <inline-formula><alternatives><mml:math id="inf232"><mml:semantics><mml:mrow><mml:msup><mml:mrow><mml:mi>ğ‘‘</mml:mi></mml:mrow><mml:mrow><mml:mstyle class="text"><mml:mtext>cautious-steady</mml:mtext></mml:mstyle></mml:mrow></mml:msup></mml:mrow></mml:semantics></mml:math><tex-math id="inft232">\begin{document}$d^{\text{cautious-steady}}$\end{document}</tex-math></alternatives></inline-formula>, and the ratio of the frequencies of the two phases <inline-formula><alternatives><mml:math id="inf233"><mml:semantics><mml:mrow><mml:mfrac><mml:mrow><mml:msup><mml:mrow><mml:mi>ğ‘“</mml:mi></mml:mrow><mml:mrow><mml:mstyle class="text"><mml:mtext>cautious-peak</mml:mtext></mml:mstyle></mml:mrow></mml:msup></mml:mrow><mml:mrow><mml:msup><mml:mrow><mml:mi>ğ‘“</mml:mi></mml:mrow><mml:mrow><mml:mstyle class="text"><mml:mtext>cautious-steady</mml:mtext></mml:mstyle></mml:mrow></mml:msup></mml:mrow></mml:mfrac></mml:mrow></mml:semantics></mml:math><tex-math id="inft233">\begin{document}$\frac{f^{\text{cautious-peak}}}{f^{\text{cautious-steady}}}$\end{document}</tex-math></alternatives></inline-formula>.</p><sec id="s4-5-1-1"><title>Model statistics</title><p>By design, our BAMDP agent also enjoys a notion of bouts and behavioral phases. We map the behavior of the agent to the same abstract space of duration, frequency, and transition time statistics as the animals to allow the fitting.</p><p>We consider the agent as performing a bout when it leaves the nest, stays at the object state for some turns, and finally returns to the nest. We parse bouts and behavioral phases from the overall state trajectory of the agent which, like the animals, has what we can describe as contiguous periods of cautious or confident approach and low or high approach frequency.</p><p>The transition from the cautious to the confident phase (measured in the number of turns) is when the model begins visiting the confident-object state rather than the cautious-object state (this transition never happens for low <inline-formula><alternatives><mml:math id="inf234"><mml:semantics><mml:mrow><mml:mover accent="true"><mml:mrow><mml:mi>ğ›¼</mml:mi></mml:mrow><mml:mo accent="true">Â¯</mml:mo></mml:mover></mml:mrow></mml:semantics></mml:math><tex-math id="inft234">\begin{document}$\bar\alpha$\end{document}</tex-math></alternatives></inline-formula>). The transition from peak to steady-state phase is when the model starts spending &gt;1 consecutive turns at the nest (to regenerate <inline-formula><alternatives><mml:math id="inf235"><mml:semantics><mml:mrow><mml:mi>ğº</mml:mi></mml:mrow></mml:semantics></mml:math><tex-math id="inft235">\begin{document}$G$\end{document}</tex-math></alternatives></inline-formula>), which happens when <inline-formula><alternatives><mml:math id="inf236"><mml:semantics><mml:mrow><mml:mi>ğº</mml:mi></mml:mrow></mml:semantics></mml:math><tex-math id="inft236">\begin{document}$G$\end{document}</tex-math></alternatives></inline-formula> reaches its steady-state value determined by the forgetting rate. We linearly map the agentâ€™s transition times (in units of turns) to the space of animalsâ€™ transition times (units of minutes) using the relationship: 2 turns to 1 min. Therefore, the agent is simulated for 200 turns corresponding to 100 min in the experiment.</p><p>Bout duration is naturally defined as the number of consecutive turns the agent spends at the object. Because the agent lives in discrete time, we map its duration (units of turns) to the space of animal duration (units of seconds) using the formula,<disp-formula id="equ25"><label>(20)</label><alternatives><mml:math id="m25"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msub><mml:mi>d</mml:mi><mml:mrow><mml:mtext>animal</mml:mtext></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mn>0.75</mml:mn><mml:mo>+</mml:mo><mml:mn>1.5</mml:mn><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>d</mml:mi><mml:mrow><mml:mtext>agent</mml:mtext></mml:mrow></mml:msub><mml:mo>âˆ’</mml:mo><mml:mn>2</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mstyle></mml:mrow></mml:mstyle></mml:math><tex-math id="t25">\begin{document}$$\displaystyle d_{\text{animal}} = 0.75 + 1.5 (d_{\text{agent}}-2)$$\end{document}</tex-math></alternatives></disp-formula></p><p>Hence, the agent is capable of having durations from 0.75 to 3.75 s. This captures a large range of the animalsâ€™ phase-averaged durations.</p><p>We define the momentary frequency with which the agent visits the object as the inverse of the period, which is the number of turns between two consecutive bouts (sum of turns at nest and object states). Frequency ratios are computed by dividing the average periods of two phases (in units of turns) and are unitless. Hence, no mapping between agent and animal frequency ratios is necessary.</p></sec><sec id="s4-5-1-2"><title>Approximate Bayesian computation</title><p>We fit each of the 26 animals from <xref ref-type="bibr" rid="bib2">Akiti et al., 2022</xref> separately using an ABCSMC algorithm (<xref ref-type="bibr" rid="bib67">Toni et al., 2009</xref>). We use an adaptive acceptance threshold schedule that sets <inline-formula><alternatives><mml:math id="inf237"><mml:semantics><mml:mrow><mml:msub><mml:mrow><mml:mi>ğœ–</mml:mi></mml:mrow><mml:mrow><mml:mi>ğ‘¡</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:semantics></mml:math><tex-math id="inft237">\begin{document}$\epsilon_ t$\end{document}</tex-math></alternatives></inline-formula> to the lowest 30-percentile of distances <inline-formula><alternatives><mml:math id="inf238"><mml:semantics><mml:mrow><mml:mi>ğ‘‘</mml:mi><mml:mo class="MathClass-open" stretchy="false">(</mml:mo><mml:mi>ğ‘¥</mml:mi><mml:mo class="MathClass-punc" stretchy="false">,</mml:mo><mml:msub><mml:mrow><mml:mi>ğ‘¥</mml:mi></mml:mrow><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msub><mml:mo class="MathClass-close" stretchy="false">)</mml:mo></mml:mrow></mml:semantics></mml:math><tex-math id="inft238">\begin{document}$d(x, x_0)$\end{document}</tex-math></alternatives></inline-formula> in the previous population. We use a Gaussian transition kernel <inline-formula><alternatives><mml:math id="inf239"><mml:semantics><mml:mrow><mml:msub><mml:mrow><mml:mi>ğ¾</mml:mi></mml:mrow><mml:mrow><mml:mi>ğ‘¡</mml:mi></mml:mrow></mml:msub><mml:mo class="MathClass-open" stretchy="false">(</mml:mo><mml:mi mathvariant="italic">ğœƒ|</mml:mi><mml:msup><mml:mrow><mml:mi>ğœƒ</mml:mi></mml:mrow><mml:mrow><mml:mo class="MathClass-bin" stretchy="false">âˆ—</mml:mo></mml:mrow></mml:msup><mml:mo class="MathClass-close" stretchy="false">)</mml:mo><mml:mo class="MathClass-rel" stretchy="false">=</mml:mo><mml:mstyle mathvariant="script"><mml:mi>ğ‘</mml:mi></mml:mstyle><mml:mo class="MathClass-open" stretchy="false">(</mml:mo><mml:mn>0</mml:mn><mml:mo class="MathClass-punc" stretchy="false">,</mml:mo><mml:mi mathvariant="normal">Î£</mml:mi><mml:mo class="MathClass-close" stretchy="false">)</mml:mo></mml:mrow></mml:semantics></mml:math><tex-math id="inft239">\begin{document}$K_t(\theta|\theta^*) = \mathcal{N}(0, \Sigma)$\end{document}</tex-math></alternatives></inline-formula>, where the bandwidth of <inline-formula><alternatives><mml:math id="inf240"><mml:semantics><mml:mrow><mml:mi mathvariant="normal">Î£</mml:mi></mml:mrow></mml:semantics></mml:math><tex-math id="inft240">\begin{document}$\Sigma$\end{document}</tex-math></alternatives></inline-formula> is set using the Silverman heuristic. We ran ABCSMC for <inline-formula><alternatives><mml:math id="inf241"><mml:semantics><mml:mrow><mml:mi>ğ‘‡</mml:mi><mml:mo class="MathClass-rel" stretchy="false">=</mml:mo><mml:mn>30</mml:mn></mml:mrow></mml:semantics></mml:math><tex-math id="inft241">\begin{document}$T=30$\end{document}</tex-math></alternatives></inline-formula> populations for each animal, but most animals converged earlier. We used uniform priors. <xref ref-type="table" rid="table1">Table 1</xref> contains a list of ABCSMC parameters.</p><table-wrap id="table1" position="float"><label>Table 1.</label><caption><title>Table of Approximate Bayesian Computation Sequential Monte Carlo (ABCSMC) parameters.</title></caption><table frame="hsides" rules="groups"><thead><tr><th align="left" valign="top">Parameter</th><th align="left" valign="top">Description</th><th align="left" valign="top">Value</th></tr></thead><tbody><tr><td align="left" valign="top"><inline-formula><alternatives><mml:math id="inf242"><mml:mstyle><mml:mrow><mml:mstyle displaystyle="false"><mml:mi>T</mml:mi></mml:mstyle></mml:mrow></mml:mstyle></mml:math><tex-math id="inft242">\begin{document}$T$\end{document}</tex-math></alternatives></inline-formula></td><td align="left" valign="top">Number of populations</td><td align="left" valign="top">30</td></tr><tr><td align="left" valign="top"><inline-formula><alternatives><mml:math id="inf243"><mml:mstyle><mml:mrow><mml:mstyle displaystyle="false"><mml:mi>B</mml:mi></mml:mstyle></mml:mrow></mml:mstyle></mml:math><tex-math id="inft243">\begin{document}$B$\end{document}</tex-math></alternatives></inline-formula></td><td align="left" valign="top">Population size</td><td align="left" valign="top">100</td></tr><tr><td align="left" valign="top"><inline-formula><alternatives><mml:math id="inf244"><mml:semantics><mml:mrow><mml:msub><mml:mrow><mml:mi>ğœ–</mml:mi></mml:mrow><mml:mrow><mml:mi>ğ‘¡</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:semantics></mml:math><tex-math id="inft244">\begin{document}$\epsilon_t$\end{document}</tex-math></alternatives></inline-formula></td><td align="left" valign="top">Set adaptively to lowest 30-percentile</td><td align="left" valign="top"/></tr><tr><td align="left" valign="top"><inline-formula><alternatives><mml:math id="inf245"><mml:mstyle><mml:mrow><mml:mstyle displaystyle="false"><mml:mi>Ï€</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>Î¸</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mstyle></mml:mrow></mml:mstyle></mml:math><tex-math id="inft245">\begin{document}$\pi(\theta)$\end{document}</tex-math></alternatives></inline-formula></td><td align="left" valign="top">Prior distributions for fitted parameters</td><td align="left" valign="top">Uniform</td></tr><tr><td align="left" valign="top"><inline-formula><alternatives><mml:math id="inf246"><mml:mstyle><mml:mrow><mml:mstyle displaystyle="false"><mml:msub><mml:mi>K</mml:mi><mml:mi>t</mml:mi></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>Î¸</mml:mi><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:msup><mml:mi>Î¸</mml:mi><mml:mo>âˆ—</mml:mo></mml:msup><mml:mo stretchy="false">)</mml:mo></mml:mstyle></mml:mrow></mml:mstyle></mml:math><tex-math id="inft246">\begin{document}$K_t(\theta|\theta^*)$\end{document}</tex-math></alternatives></inline-formula></td><td align="left" valign="top">Transition kernel</td><td align="left" valign="top"><inline-formula><alternatives><mml:math id="inf247"><mml:mstyle><mml:mrow><mml:mstyle displaystyle="false"><mml:mrow><mml:mi class="mathcal" mathvariant="script">N</mml:mi></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:mi mathvariant="normal">Î£</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mstyle></mml:mrow></mml:mstyle></mml:math><tex-math id="inft247">\begin{document}$\mathcal{N}(0, \Sigma)$\end{document}</tex-math></alternatives></inline-formula></td></tr><tr><td align="left" valign="top"><inline-formula><alternatives><mml:math id="inf248"><mml:mstyle><mml:mrow><mml:mstyle displaystyle="false"><mml:mi>d</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>x</mml:mi><mml:mo>,</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mn>0</mml:mn></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mstyle></mml:mrow></mml:mstyle></mml:math><tex-math id="inft248">\begin{document}$d(x, x_0)$\end{document}</tex-math></alternatives></inline-formula></td><td align="left" valign="top">Distance function</td><td align="left" valign="top"><inline-formula><alternatives><mml:math id="inf249"><mml:mstyle><mml:mrow><mml:mstyle displaystyle="false"><mml:msub><mml:mi>L</mml:mi><mml:mn>1</mml:mn></mml:msub></mml:mstyle></mml:mrow></mml:mstyle></mml:math><tex-math id="inft249">\begin{document}$L_1$\end{document}</tex-math></alternatives></inline-formula> distance</td></tr></tbody></table></table-wrap><p>Given agent statistics <inline-formula><alternatives><mml:math id="inf250"><mml:mstyle><mml:mrow><mml:mstyle displaystyle="false"><mml:mrow><mml:mi mathvariant="bold">x</mml:mi></mml:mrow></mml:mstyle></mml:mrow></mml:mstyle></mml:math><tex-math id="inft250">\begin{document}$\mathbf{x} $\end{document}</tex-math></alternatives></inline-formula> and animal statistics <inline-formula><alternatives><mml:math id="inf251"><mml:mstyle><mml:mrow><mml:mstyle displaystyle="false"><mml:msub><mml:mrow><mml:mi mathvariant="bold">x</mml:mi></mml:mrow><mml:mn>0</mml:mn></mml:msub></mml:mstyle></mml:mrow></mml:mstyle></mml:math><tex-math id="inft251">\begin{document}$\mathbf{x}_0 $\end{document}</tex-math></alternatives></inline-formula> in a joint space, we compute the ABC distance <inline-formula><alternatives><mml:math id="inf252"><mml:mstyle><mml:mrow><mml:mstyle displaystyle="false"><mml:mi>d</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mi mathvariant="bold">x</mml:mi></mml:mrow><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi mathvariant="bold">x</mml:mi></mml:mrow><mml:mn>0</mml:mn></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mstyle></mml:mrow></mml:mstyle></mml:math><tex-math id="inft252">\begin{document}$d(\mathbf{x},\mathbf{x}_0)$\end{document}</tex-math></alternatives></inline-formula> using the a normalized <italic>L</italic><sub><italic>1</italic></sub> distance function.<disp-formula id="equ26"><label>(21)</label><alternatives><mml:math id="m26"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>d</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mi mathvariant="bold">x</mml:mi></mml:mrow><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi mathvariant="bold">x</mml:mi></mml:mrow><mml:mn>0</mml:mn></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mi>n</mml:mi></mml:mfrac><mml:munderover><mml:mo>âˆ‘</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>n</mml:mi></mml:mrow></mml:munderover><mml:mfrac><mml:mn>1</mml:mn><mml:mrow><mml:msup><mml:mi>C</mml:mi><mml:mi>i</mml:mi></mml:msup><mml:mo stretchy="false">(</mml:mo><mml:msup><mml:mi>x</mml:mi><mml:mi>i</mml:mi></mml:msup><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mfrac><mml:mrow><mml:mo>|</mml:mo><mml:mrow><mml:msup><mml:mi>x</mml:mi><mml:mi>i</mml:mi></mml:msup><mml:mo>âˆ’</mml:mo><mml:msubsup><mml:mi>x</mml:mi><mml:mn>0</mml:mn><mml:mi>i</mml:mi></mml:msubsup></mml:mrow><mml:mo>|</mml:mo></mml:mrow></mml:mstyle></mml:mstyle></mml:mrow></mml:mstyle></mml:math><tex-math id="t26">\begin{document}$$\displaystyle  d(\mathbf{x}, \mathbf{x}_0) = \frac{1}{n} \sum_{i=1}^{n} \frac{1}{C^i(x^i)} \left| x^i - x_0^i \right|$$\end{document}</tex-math></alternatives></disp-formula></p><p>where <inline-formula><alternatives><mml:math id="inf253"><mml:semantics><mml:mrow><mml:mi>ğ‘–</mml:mi></mml:mrow></mml:semantics></mml:math><tex-math id="inft253">\begin{document}$i$\end{document}</tex-math></alternatives></inline-formula> indexes the statistics. <inline-formula><alternatives><mml:math id="inf254"><mml:semantics><mml:mrow><mml:msup><mml:mrow><mml:mi>ğ¶</mml:mi></mml:mrow><mml:mrow><mml:mi>ğ‘–</mml:mi></mml:mrow></mml:msup><mml:mo class="MathClass-open" stretchy="false">(</mml:mo><mml:msup><mml:mrow><mml:mi>ğ‘¥</mml:mi></mml:mrow><mml:mrow><mml:mi>ğ‘–</mml:mi></mml:mrow></mml:msup><mml:mo class="MathClass-close" stretchy="false">)</mml:mo></mml:mrow></mml:semantics></mml:math><tex-math id="inft254">\begin{document}$C^i(x^i)$\end{document}</tex-math></alternatives></inline-formula> is a normalization constant that depends on the statistic and possibly the value <inline-formula><alternatives><mml:math id="inf255"><mml:semantics><mml:mrow><mml:msup><mml:mrow><mml:mi>ğ‘¥</mml:mi></mml:mrow><mml:mrow><mml:mi>ğ‘–</mml:mi></mml:mrow></mml:msup></mml:mrow></mml:semantics></mml:math><tex-math id="inft255">\begin{document}$x^i$\end{document}</tex-math></alternatives></inline-formula>. Normalization is necessary because the statistics have different units and value ranges.</p><p>We normalize durations using a constant <inline-formula><alternatives><mml:math id="inf256"><mml:semantics><mml:mrow><mml:msup><mml:mrow><mml:mi>ğ¶</mml:mi></mml:mrow><mml:mrow><mml:mi>ğ‘–</mml:mi></mml:mrow></mml:msup><mml:mo class="MathClass-open" stretchy="false">(</mml:mo><mml:msup><mml:mrow><mml:mi>ğ‘¥</mml:mi></mml:mrow><mml:mrow><mml:mi>ğ‘–</mml:mi></mml:mrow></mml:msup><mml:mo class="MathClass-close" stretchy="false">)</mml:mo><mml:mo class="MathClass-rel" stretchy="false">=</mml:mo><mml:mn>4.0</mml:mn></mml:mrow></mml:semantics></mml:math><tex-math id="inft256">\begin{document}$C^i(x^i) = 4.0$\end{document}</tex-math></alternatives></inline-formula> s. We normalize the transition times using a piece-wise linear function to prevent extremely small or large values from dominating the distance,<disp-formula id="equ27"><label>(22)</label><alternatives><mml:math id="m27"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msup><mml:mi>C</mml:mi><mml:mi>i</mml:mi></mml:msup><mml:mo stretchy="false">(</mml:mo><mml:msup><mml:mi>x</mml:mi><mml:mi>i</mml:mi></mml:msup><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mo movablelimits="true" form="prefix">min</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mn>30</mml:mn><mml:mo>,</mml:mo><mml:mn>10</mml:mn><mml:mo>+</mml:mo><mml:mn>0.8</mml:mn><mml:mo movablelimits="true" form="prefix">max</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:msup><mml:mi>x</mml:mi><mml:mi>i</mml:mi></mml:msup><mml:mo>âˆ’</mml:mo><mml:mn>5</mml:mn><mml:mo>,</mml:mo><mml:mn>0</mml:mn><mml:mo stretchy="false">)</mml:mo><mml:mo stretchy="false">)</mml:mo></mml:mstyle></mml:mrow></mml:mstyle></mml:math><tex-math id="t27">\begin{document}$$\displaystyle C^i(x^i) = \min(30, 10+0.8 \max(x^i-5, 0))$$\end{document}</tex-math></alternatives></disp-formula></p><p>We also normalize the frequency ratio using a piece-wise linear function,<disp-formula id="equ28"><label>(23)</label><alternatives><mml:math id="m28"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msup><mml:mi>C</mml:mi><mml:mi>i</mml:mi></mml:msup><mml:mo stretchy="false">(</mml:mo><mml:msup><mml:mi>x</mml:mi><mml:mi>i</mml:mi></mml:msup><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mo movablelimits="true" form="prefix">min</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mn>20</mml:mn><mml:mo>,</mml:mo><mml:mn>2</mml:mn><mml:mo>+</mml:mo><mml:mfrac><mml:mn>18</mml:mn><mml:mn>19</mml:mn></mml:mfrac><mml:mo movablelimits="true" form="prefix">max</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:msup><mml:mi>x</mml:mi><mml:mi>i</mml:mi></mml:msup><mml:mo>âˆ’</mml:mo><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mn>0</mml:mn><mml:mo stretchy="false">)</mml:mo><mml:mo stretchy="false">)</mml:mo></mml:mstyle></mml:mrow></mml:mstyle></mml:math><tex-math id="t28">\begin{document}$$\displaystyle C^i(x^i) = \min(20, 2 + \frac{18}{19} \max(x^i-1 , 0))$$\end{document}</tex-math></alternatives></disp-formula></p></sec></sec></sec></sec></body><back><sec sec-type="additional-information" id="s5"><title>Additional information</title><fn-group content-type="competing-interest"><title>Competing interests</title><fn fn-type="COI-statement" id="conf1"><p>No competing interests declared</p></fn></fn-group><fn-group content-type="author-contribution"><title>Author contributions</title><fn fn-type="con" id="con1"><p>Conceptualization, Data curation, Software, Formal analysis, Investigation, Visualization, Methodology, Writing â€“ original draft, Writing â€“ review and editing</p></fn><fn fn-type="con" id="con2"><p>Conceptualization, Supervision, Funding acquisition, Investigation, Methodology, Writing â€“ original draft, Project administration, Writing â€“ review and editing</p></fn></fn-group></sec><sec sec-type="supplementary-material" id="s6"><title>Additional files</title><supplementary-material id="mdar"><label>MDAR checklist</label><media xlink:href="elife-100366-mdarchecklist1-v1.docx" mimetype="application" mime-subtype="docx"/></supplementary-material></sec><sec sec-type="data-availability" id="s7"><title>Data availability</title><p>The analysis code used in this study is publicly available at <ext-link ext-link-type="uri" xlink:href="https://github.com/shenkev/Risking-your-Tail-Modeling-Individual-Differences-in-Risk-sensitive-Exploration">GitHub</ext-link> (copy archived at <xref ref-type="bibr" rid="bib63">Shen, 2025</xref>).</p><p>The following previously published dataset was used:</p><p><element-citation publication-type="data" specific-use="references" id="dataset1"><person-group person-group-type="author"><name><surname>Watabe-Uchida</surname><given-names>M</given-names></name><name><surname>Akiti</surname><given-names>K</given-names></name><name><surname>Tsutsui-Kimura</surname><given-names>I</given-names></name><name><surname>Xie</surname><given-names>Y</given-names></name><name><surname>Mathis</surname><given-names>A</given-names></name><name><surname>Markowitz</surname><given-names>J</given-names></name><name><surname>Anyoha</surname><given-names>R</given-names></name><name><surname>Datta</surname><given-names>S</given-names></name><name><surname>Weygandt Mathis</surname><given-names>M</given-names></name><name><surname>Uchida</surname><given-names>N</given-names></name></person-group><year iso-8601-date="2023">2023</year><data-title>Dopamine activity in the tail of the striatum, DeepLabCut and MoSeq during novel object exploration</data-title><source>Dryad Digital Repository</source><pub-id pub-id-type="doi">10.5061/dryad.41ns1rnh2</pub-id></element-citation></p></sec><ack id="ack"><title>Acknowledgements</title><p>We are grateful to Chris Gagne, Vikki Neville, Mike Mendl, Elizabeth S Paul, Richard Gao, and particularly Mitsuko Watabe-Uchida for their helpful discussion and feedback. Funding was from the Max Planck Society and the Humboldt Foundation. Open access funding provided by Max Planck Society. PD is a member of the Machine Learning Cluster of Excellence, EXC number 2064/1 â€“ Project number 39072764 and of the Else KrÃ¶ner Medical Scientist Kolleg 'ClinbrAIn: Artificial Intelligence for Clinical Brain Research'. We thank the IT team from the Max Planck Institute for Biological Cybernetics for technical support.</p></ack><ref-list><title>References</title><ref id="bib1"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ainsworth</surname><given-names>MD</given-names></name></person-group><year iso-8601-date="1964">1964</year><article-title>Patterns of attachment behavior shown by the infant in interaction with his mother</article-title><source>Merrill-Palmer Quarterly of Behavior and Development</source><volume>10</volume><fpage>51</fpage><lpage>58</lpage></element-citation></ref><ref id="bib2"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Akiti</surname><given-names>K</given-names></name><name><surname>Tsutsui-Kimura</surname><given-names>I</given-names></name><name><surname>Xie</surname><given-names>Y</given-names></name><name><surname>Mathis</surname><given-names>A</given-names></name><name><surname>Markowitz</surname><given-names>JE</given-names></name><name><surname>Anyoha</surname><given-names>R</given-names></name><name><surname>Datta</surname><given-names>SR</given-names></name><name><surname>Mathis</surname><given-names>MW</given-names></name><name><surname>Uchida</surname><given-names>N</given-names></name><name><surname>Watabe-Uchida</surname><given-names>M</given-names></name></person-group><year iso-8601-date="2022">2022</year><article-title>Striatal dopamine explains novelty-induced behavioral dynamics and individual variability in threat prediction</article-title><source>Neuron</source><volume>110</volume><fpage>3789</fpage><lpage>3804</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2022.08.022</pub-id><pub-id pub-id-type="pmid">36130595</pub-id></element-citation></ref><ref id="bib3"><element-citation publication-type="preprint"><person-group person-group-type="author"><name><surname>Antonov</surname><given-names>G</given-names></name><name><surname>Dayan</surname><given-names>P</given-names></name></person-group><year iso-8601-date="2023">2023</year><article-title>Exploring replay</article-title><source>bioRxiv</source><pub-id pub-id-type="doi">10.1101/2023.01.27.525847</pub-id></element-citation></ref><ref id="bib4"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Arsenian</surname><given-names>JM</given-names></name></person-group><year iso-8601-date="1943">1943</year><article-title>Young children in an insecure situation</article-title><source>The Journal of Abnormal and Social Psychology</source><volume>38</volume><fpage>225</fpage><lpage>249</lpage><pub-id pub-id-type="doi">10.1037/h0062815</pub-id></element-citation></ref><ref id="bib5"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Artzner</surname><given-names>P</given-names></name><name><surname>Delbaen</surname><given-names>F</given-names></name><name><surname>Eber</surname><given-names>JM</given-names></name><name><surname>Heath</surname><given-names>D</given-names></name></person-group><year iso-8601-date="1999">1999</year><article-title>Coherent measures of risk</article-title><source>Mathematical Finance</source><volume>9</volume><fpage>203</fpage><lpage>228</lpage><pub-id pub-id-type="doi">10.1111/1467-9965.00068</pub-id></element-citation></ref><ref id="bib6"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Bellemare</surname><given-names>MG</given-names></name><name><surname>Dabney</surname><given-names>W</given-names></name><name><surname>Rowland</surname><given-names>M</given-names></name></person-group><year iso-8601-date="2023">2023</year><source>Distributional Reinforcement Learning</source><publisher-name>MIT Press</publisher-name><pub-id pub-id-type="doi">10.7551/mitpress/14207.001.0001</pub-id></element-citation></ref><ref id="bib7"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bennett</surname><given-names>D</given-names></name><name><surname>Niv</surname><given-names>Y</given-names></name></person-group><year iso-8601-date="2020">2020</year><article-title>Opening burtonâ€™s clock: Psychiatric insights from computational cognitive models</article-title><source>The Cognitive Neurosciences</source><volume>2020</volume><fpage>439</fpage><lpage>450</lpage><pub-id pub-id-type="doi">10.7551/mitpress/11442.003.0049</pub-id></element-citation></ref><ref id="bib8"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bishop</surname><given-names>SJ</given-names></name><name><surname>Gagne</surname><given-names>C</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>Anxiety, depression, and decision making: a computational perspective</article-title><source>Annual Review of Neuroscience</source><volume>41</volume><fpage>371</fpage><lpage>388</lpage><pub-id pub-id-type="doi">10.1146/annurev-neuro-080317-062007</pub-id><pub-id pub-id-type="pmid">29709209</pub-id></element-citation></ref><ref id="bib9"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bowlby</surname><given-names>J</given-names></name></person-group><year iso-8601-date="1955">1955</year><article-title>(b) The growth of independence in the young child</article-title><source>Journal Royal Society of Health</source><volume>76</volume><fpage>587</fpage><lpage>591</lpage><pub-id pub-id-type="doi">10.1177/146642405507600912</pub-id></element-citation></ref><ref id="bib10"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bromberg-Martin</surname><given-names>ES</given-names></name><name><surname>Hikosaka</surname><given-names>O</given-names></name></person-group><year iso-8601-date="2009">2009</year><article-title>Midbrain dopamine neurons signal preference for advance information about upcoming rewards</article-title><source>Neuron</source><volume>63</volume><fpage>119</fpage><lpage>126</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2009.06.009</pub-id><pub-id pub-id-type="pmid">19607797</pub-id></element-citation></ref><ref id="bib11"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Brown</surname><given-names>GE</given-names></name><name><surname>Dreier</surname><given-names>VM</given-names></name></person-group><year iso-8601-date="2002">2002</year><article-title>Predator inspection behaviour and attack cone avoidance in a characin fish: the effects of predator diet and prey experience</article-title><source>Animal Behaviour</source><volume>63</volume><fpage>1175</fpage><lpage>1181</lpage><pub-id pub-id-type="doi">10.1006/anbe.2002.3024</pub-id></element-citation></ref><ref id="bib12"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Butler</surname><given-names>G</given-names></name><name><surname>Mathews</surname><given-names>A</given-names></name></person-group><year iso-8601-date="1983">1983</year><article-title>Cognitive processes in anxiety</article-title><source>Advances in Behaviour Research and Therapy</source><volume>5</volume><fpage>51</fpage><lpage>62</lpage><pub-id pub-id-type="doi">10.1016/0146-6402(83)90015-2</pub-id></element-citation></ref><ref id="bib13"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Charpentier</surname><given-names>CJ</given-names></name><name><surname>Aylward</surname><given-names>J</given-names></name><name><surname>Roiser</surname><given-names>JP</given-names></name><name><surname>Robinson</surname><given-names>OJ</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>Enhanced risk aversion, but not loss aversion, in unmedicated pathological anxiety</article-title><source>Biological Psychiatry</source><volume>81</volume><fpage>1014</fpage><lpage>1022</lpage><pub-id pub-id-type="doi">10.1016/j.biopsych.2016.12.010</pub-id><pub-id pub-id-type="pmid">28126210</pub-id></element-citation></ref><ref id="bib14"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Chow</surname><given-names>Y</given-names></name><name><surname>Tamar</surname><given-names>A</given-names></name><name><surname>Mannor</surname><given-names>S</given-names></name><name><surname>Pavone</surname><given-names>M</given-names></name></person-group><year iso-8601-date="2015">2015</year><source>Risk-Sensitive and Robust Decision-Making: A Cvar Optimization Approach</source><publisher-name>Advances in Neural Information Processing Systems</publisher-name></element-citation></ref><ref id="bib15"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Coss</surname><given-names>RG</given-names></name><name><surname>Biardi</surname><given-names>JE</given-names></name></person-group><year iso-8601-date="1997">1997</year><article-title>Individual variation in the antisnake behavior of california ground squirrels (Spermophilus beecheyi)</article-title><source>Journal of Mammalogy</source><volume>78</volume><fpage>294</fpage><lpage>310</lpage><pub-id pub-id-type="doi">10.2307/1382883</pub-id></element-citation></ref><ref id="bib16"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Dabney</surname><given-names>W</given-names></name><name><surname>Kurth-Nelson</surname><given-names>Z</given-names></name><name><surname>Uchida</surname><given-names>N</given-names></name><name><surname>Starkweather</surname><given-names>CK</given-names></name><name><surname>Hassabis</surname><given-names>D</given-names></name><name><surname>Munos</surname><given-names>R</given-names></name><name><surname>Botvinick</surname><given-names>M</given-names></name></person-group><year iso-8601-date="2020">2020</year><article-title>A distributional code for value in dopamine-based reinforcement learning</article-title><source>Nature</source><volume>577</volume><fpage>671</fpage><lpage>675</lpage><pub-id pub-id-type="doi">10.1038/s41586-019-1924-6</pub-id><pub-id pub-id-type="pmid">31942076</pub-id></element-citation></ref><ref id="bib17"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Dayan</surname><given-names>P</given-names></name><name><surname>Sejnowski</surname><given-names>TJ</given-names></name></person-group><year iso-8601-date="1996">1996</year><article-title>Exploration bonuses and dual control</article-title><source>Machine Learning</source><volume>25</volume><fpage>5</fpage><lpage>22</lpage><pub-id pub-id-type="doi">10.1023/A:1018357105171</pub-id></element-citation></ref><ref id="bib18"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Dayan</surname><given-names>P</given-names></name><name><surname>Kakade</surname><given-names>S</given-names></name><name><surname>Montague</surname><given-names>PR</given-names></name></person-group><year iso-8601-date="2000">2000</year><article-title>Learning and selective attention</article-title><source>Nature Neuroscience</source><volume>3 Suppl</volume><fpage>1218</fpage><lpage>1223</lpage><pub-id pub-id-type="doi">10.1038/81504</pub-id><pub-id pub-id-type="pmid">11127841</pub-id></element-citation></ref><ref id="bib19"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Dayan</surname><given-names>P</given-names></name><name><surname>Roiser</surname><given-names>JP</given-names></name><name><surname>Viding</surname><given-names>E</given-names></name></person-group><year iso-8601-date="2020">2020</year><chapter-title>The first steps on long marches: the costs of active observation</chapter-title><person-group person-group-type="editor"><name><surname>Savulescu</surname><given-names>J</given-names></name><name><surname>Roache</surname><given-names>R</given-names></name><name><surname>Davies</surname><given-names>W</given-names></name><name><surname>Loebel</surname><given-names>JP</given-names></name></person-group><source>Psychiatry Reborn: Biopsychosocial Psychiatry in Modern Medicine</source><publisher-name>Oxford University Press</publisher-name><fpage>213</fpage><lpage>228</lpage><pub-id pub-id-type="doi">10.1093/med/9780198789697.003.0014</pub-id></element-citation></ref><ref id="bib20"><element-citation publication-type="preprint"><person-group person-group-type="author"><name><surname>Dearden</surname><given-names>R</given-names></name><name><surname>Friedman</surname><given-names>N</given-names></name><name><surname>Andre</surname><given-names>D</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>Model-based bayesian exploration</article-title><source>arXiv</source><pub-id pub-id-type="doi">10.48550/arXiv.1301.6690</pub-id></element-citation></ref><ref id="bib21"><element-citation publication-type="thesis"><person-group person-group-type="author"><name><surname>Duff</surname><given-names>M</given-names></name></person-group><year iso-8601-date="2002">2002a</year><article-title>Optimal learning: Computational procedures for Bayes-adaptive Markov decision processes</article-title><publisher-name>University of Massachusetts Amherst</publisher-name></element-citation></ref><ref id="bib22"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Duff</surname><given-names>MO</given-names></name></person-group><year iso-8601-date="2002">2002b</year><source>Optimal Learning: Computational Procedures for Bayes-Adaptive Markov Decision Processes</source><publisher-name>University of Massachusetts Amherst</publisher-name></element-citation></ref><ref id="bib23"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Dugatkin</surname><given-names>LA</given-names></name></person-group><year iso-8601-date="1988">1988</year><article-title>Do guppies play TIT FOR TAT during predator inspection visits?</article-title><source>Behavioral Ecology and Sociobiology</source><volume>23</volume><fpage>395</fpage><lpage>399</lpage><pub-id pub-id-type="doi">10.1007/BF00303714</pub-id></element-citation></ref><ref id="bib24"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Eccard</surname><given-names>JA</given-names></name><name><surname>Liesenjohann</surname><given-names>T</given-names></name><name><surname>Dammhahn</surname><given-names>M</given-names></name></person-group><year iso-8601-date="2020">2020</year><article-title>Among-individual differences in foraging modulate resource exploitation under perceived predation risk</article-title><source>Oecologia</source><volume>194</volume><fpage>621</fpage><lpage>634</lpage><pub-id pub-id-type="doi">10.1007/s00442-020-04773-y</pub-id><pub-id pub-id-type="pmid">33141325</pub-id></element-citation></ref><ref id="bib25"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Eldar</surname><given-names>E</given-names></name><name><surname>Rutledge</surname><given-names>RB</given-names></name><name><surname>Dolan</surname><given-names>RJ</given-names></name><name><surname>Niv</surname><given-names>Y</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Mood as representation of momentum</article-title><source>Trends in Cognitive Sciences</source><volume>20</volume><fpage>15</fpage><lpage>24</lpage><pub-id pub-id-type="doi">10.1016/j.tics.2015.07.010</pub-id></element-citation></ref><ref id="bib26"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>FitzGibbon</surname><given-names>CD</given-names></name></person-group><year iso-8601-date="1994">1994</year><article-title>The costs and benefits of predator inspection behaviour in Thomsonâ€™s gazelles</article-title><source>Behavioral Ecology and Sociobiology</source><volume>34</volume><fpage>139</fpage><lpage>148</lpage><pub-id pub-id-type="doi">10.1007/BF00164184</pub-id></element-citation></ref><ref id="bib27"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Frey</surname><given-names>R</given-names></name><name><surname>Pedroni</surname><given-names>A</given-names></name><name><surname>Mata</surname><given-names>R</given-names></name><name><surname>Rieskamp</surname><given-names>J</given-names></name><name><surname>Hertwig</surname><given-names>R</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>Risk preference shares the psychometric structure of major psychological traits</article-title><source>Science Advances</source><volume>3</volume><elocation-id>e1701381</elocation-id><pub-id pub-id-type="doi">10.1126/sciadv.1701381</pub-id><pub-id pub-id-type="pmid">28983511</pub-id></element-citation></ref><ref id="bib28"><element-citation publication-type="confproc"><person-group person-group-type="author"><name><surname>Gagne</surname><given-names>C</given-names></name><name><surname>Dayan</surname><given-names>P</given-names></name></person-group><year iso-8601-date="2021">2021</year><article-title>Two steps to risk sensitivity</article-title><conf-name>Advances in Neural Information Processing Systems 34 (NeurIPS 2021)</conf-name><fpage>22209</fpage><lpage>22220</lpage></element-citation></ref><ref id="bib29"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Gagne</surname><given-names>C</given-names></name><name><surname>Dayan</surname><given-names>P</given-names></name></person-group><year iso-8601-date="2022">2022</year><article-title>Peril, prudence and planning as risk, avoidance and worry</article-title><source>Journal of Mathematical Psychology</source><volume>106</volume><elocation-id>102617</elocation-id><pub-id pub-id-type="doi">10.1016/j.jmp.2021.102617</pub-id></element-citation></ref><ref id="bib30"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Giorgetta</surname><given-names>C</given-names></name><name><surname>Grecucci</surname><given-names>A</given-names></name><name><surname>Zuanon</surname><given-names>S</given-names></name><name><surname>Perini</surname><given-names>L</given-names></name><name><surname>Balestrieri</surname><given-names>M</given-names></name><name><surname>Bonini</surname><given-names>N</given-names></name><name><surname>Sanfey</surname><given-names>AG</given-names></name><name><surname>Brambilla</surname><given-names>P</given-names></name></person-group><year iso-8601-date="2012">2012</year><article-title>Reduced risk-taking behavior as a trait feature of anxiety</article-title><source>Emotion</source><volume>12</volume><fpage>1373</fpage><lpage>1383</lpage><pub-id pub-id-type="doi">10.1037/a0029119</pub-id><pub-id pub-id-type="pmid">22775123</pub-id></element-citation></ref><ref id="bib31"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Gittins</surname><given-names>JC</given-names></name></person-group><year iso-8601-date="1979">1979</year><article-title>Bandit processes and dynamic allocation indices</article-title><source>Journal of the Royal Statistical Society Series B</source><volume>41</volume><fpage>148</fpage><lpage>164</lpage><pub-id pub-id-type="doi">10.1111/j.2517-6161.1979.tb01068.x</pub-id></element-citation></ref><ref id="bib32"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Gmytrasiewicz</surname><given-names>PJ</given-names></name><name><surname>Doshi</surname><given-names>P</given-names></name></person-group><year iso-8601-date="2005">2005</year><article-title>A framework for sequential planning in multi-agent settings</article-title><source>Journal of Artificial Intelligence Research</source><volume>24</volume><fpage>49</fpage><lpage>79</lpage><pub-id pub-id-type="doi">10.1613/jair.1579</pub-id></element-citation></ref><ref id="bib33"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Gottlieb</surname><given-names>J</given-names></name><name><surname>Oudeyer</surname><given-names>PY</given-names></name><name><surname>Lopes</surname><given-names>M</given-names></name><name><surname>Baranes</surname><given-names>A</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>Information-seeking, curiosity, and attention: computational and neural mechanisms</article-title><source>Trends in Cognitive Sciences</source><volume>17</volume><fpage>585</fpage><lpage>593</lpage><pub-id pub-id-type="doi">10.1016/j.tics.2013.09.001</pub-id></element-citation></ref><ref id="bib34"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Greggor</surname><given-names>AL</given-names></name><name><surname>Thornton</surname><given-names>A</given-names></name><name><surname>Clayton</surname><given-names>NS</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>Neophobia is not only avoidance: improving neophobia tests by combining cognition and ecology</article-title><source>Current Opinion in Behavioral Sciences</source><volume>6</volume><fpage>82</fpage><lpage>89</lpage><pub-id pub-id-type="doi">10.1016/j.cobeha.2015.10.007</pub-id></element-citation></ref><ref id="bib35"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Guez</surname><given-names>A</given-names></name><name><surname>Silver</surname><given-names>D</given-names></name><name><surname>Dayan</surname><given-names>P</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>Scalable and efficient bayes-adaptive reinforcement learning based on monte-carlo tree search</article-title><source>Journal of Artificial Intelligence Research</source><volume>48</volume><fpage>841</fpage><lpage>883</lpage><pub-id pub-id-type="doi">10.1613/jair.4117</pub-id></element-citation></ref><ref id="bib36"><element-citation publication-type="preprint"><person-group person-group-type="author"><name><surname>Hau</surname><given-names>JL</given-names></name><name><surname>Delage</surname><given-names>E</given-names></name><name><surname>Ghavamzadeh</surname><given-names>M</given-names></name><name><surname>Petrik</surname><given-names>M</given-names></name></person-group><year iso-8601-date="2023">2023</year><article-title>On dynamic program decompositions of static risk measures</article-title><source>arXiv</source><pub-id pub-id-type="doi">10.48550/arXiv.2304.12477</pub-id></element-citation></ref><ref id="bib37"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Huys</surname><given-names>QJM</given-names></name><name><surname>Russek</surname><given-names>EM</given-names></name><name><surname>Abitante</surname><given-names>G</given-names></name><name><surname>Kahnt</surname><given-names>T</given-names></name><name><surname>Gollan</surname><given-names>JK</given-names></name></person-group><year iso-8601-date="2022">2022</year><source>Components of Behavioral Activation Therapy for Depression Engage Specific Reinforcement Learning Mechanisms in a Pilot Study</source><publisher-name>Computational Psychiatry</publisher-name><pub-id pub-id-type="doi">10.5334/cpsy.81</pub-id></element-citation></ref><ref id="bib38"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Jaakkola</surname><given-names>TS</given-names></name><name><surname>Jordan</surname><given-names>MI</given-names></name></person-group><year iso-8601-date="1999">1999</year><article-title>Variational probabilistic inference and the QMR-DT Network</article-title><source>Journal of Artificial Intelligence Research</source><volume>10</volume><fpage>291</fpage><lpage>322</lpage><pub-id pub-id-type="doi">10.1613/jair.583</pub-id></element-citation></ref><ref id="bib39"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kaelbling</surname><given-names>LP</given-names></name><name><surname>Littman</surname><given-names>ML</given-names></name><name><surname>Cassandra</surname><given-names>AR</given-names></name></person-group><year iso-8601-date="1998">1998</year><article-title>Planning and acting in partially observable stochastic domains</article-title><source>Artificial Intelligence</source><volume>101</volume><fpage>99</fpage><lpage>134</lpage><pub-id pub-id-type="doi">10.1016/S0004-3702(98)00023-X</pub-id></element-citation></ref><ref id="bib40"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kakade</surname><given-names>S</given-names></name><name><surname>Dayan</surname><given-names>P</given-names></name></person-group><year iso-8601-date="2002">2002</year><article-title>Dopamine: generalization and bonuses</article-title><source>Neural Networks</source><volume>15</volume><fpage>549</fpage><lpage>559</lpage><pub-id pub-id-type="doi">10.1016/s0893-6080(02)00048-5</pub-id><pub-id pub-id-type="pmid">12371511</pub-id></element-citation></ref><ref id="bib41"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kemp</surname><given-names>C</given-names></name><name><surname>Kaplan</surname><given-names>G</given-names></name></person-group><year iso-8601-date="2011">2011</year><article-title>Individual modulation of anti-predator responses in common marmosets</article-title><source>International Journal of Comparative Psychology</source><volume>24</volume><elocation-id>01.02</elocation-id><pub-id pub-id-type="doi">10.46867/IJCP.2011.24.01.02</pub-id></element-citation></ref><ref id="bib42"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Keramati</surname><given-names>M</given-names></name><name><surname>Smittenaar</surname><given-names>P</given-names></name><name><surname>Dolan</surname><given-names>RJ</given-names></name><name><surname>Dayan</surname><given-names>P</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Adaptive integration of habits into depth-limited planning defines a habitual-goalâ€“directed spectrum</article-title><source>PNAS</source><volume>113</volume><fpage>12868</fpage><lpage>12873</lpage><pub-id pub-id-type="doi">10.1073/pnas.1609094113</pub-id></element-citation></ref><ref id="bib43"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Lloyd</surname><given-names>K</given-names></name><name><surname>Dayan</surname><given-names>P</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>Interrupting behaviour: Minimizing decision costs via temporal commitment and low-level interrupts</article-title><source>PLOS Computational Biology</source><volume>14</volume><elocation-id>e1005916</elocation-id><pub-id pub-id-type="doi">10.1371/journal.pcbi.1005916</pub-id><pub-id pub-id-type="pmid">29338004</pub-id></element-citation></ref><ref id="bib44"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Magurran</surname><given-names>AE</given-names></name></person-group><year iso-8601-date="1986">1986</year><article-title>Predator inspection behaviour in minnow shoals: differences between populations and individuals</article-title><source>Behavioral Ecology and Sociobiology</source><volume>19</volume><fpage>267</fpage><lpage>273</lpage><pub-id pub-id-type="doi">10.1007/BF00300641</pub-id></element-citation></ref><ref id="bib45"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Magurran</surname><given-names>AE</given-names></name><name><surname>Seghers</surname><given-names>BH</given-names></name></person-group><year iso-8601-date="1990">1990</year><article-title>Population differences in predator recognition and attack cone avoidance in the guppy Poecilia reticulata</article-title><source>Animal Behaviour</source><volume>40</volume><fpage>443</fpage><lpage>452</lpage><pub-id pub-id-type="doi">10.1016/S0003-3472(05)80524-X</pub-id></element-citation></ref><ref id="bib46"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Maner</surname><given-names>JK</given-names></name><name><surname>Richey</surname><given-names>JA</given-names></name><name><surname>Cromer</surname><given-names>K</given-names></name><name><surname>Mallott</surname><given-names>M</given-names></name><name><surname>Lejuez</surname><given-names>CW</given-names></name><name><surname>Joiner</surname><given-names>TE</given-names></name><name><surname>Schmidt</surname><given-names>NB</given-names></name></person-group><year iso-8601-date="2007">2007</year><article-title>Dispositional anxiety and risk-avoidant decision-making</article-title><source>Personality and Individual Differences</source><volume>42</volume><fpage>665</fpage><lpage>675</lpage><pub-id pub-id-type="doi">10.1016/j.paid.2006.08.016</pub-id></element-citation></ref><ref id="bib47"><element-citation publication-type="preprint"><person-group person-group-type="author"><name><surname>Masset</surname><given-names>P</given-names></name><name><surname>Tano</surname><given-names>P</given-names></name><name><surname>Kim</surname><given-names>HR</given-names></name><name><surname>Malik</surname><given-names>AN</given-names></name><name><surname>Pouget</surname><given-names>A</given-names></name><name><surname>Uchida</surname><given-names>N</given-names></name></person-group><year iso-8601-date="2023">2023</year><article-title>Multi-timescale reinforcement learning in the brain</article-title><source>bioRxiv</source><pub-id pub-id-type="doi">10.1101/2023.11.12.566754</pub-id></element-citation></ref><ref id="bib48"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Mathis</surname><given-names>A</given-names></name><name><surname>Mamidanna</surname><given-names>P</given-names></name><name><surname>Cury</surname><given-names>KM</given-names></name><name><surname>Abe</surname><given-names>T</given-names></name><name><surname>Murthy</surname><given-names>VN</given-names></name><name><surname>Mathis</surname><given-names>MW</given-names></name><name><surname>Bethge</surname><given-names>M</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>DeepLabCut: markerless pose estimation of user-defined body parts with deep learning</article-title><source>Nature Neuroscience</source><volume>21</volume><fpage>1281</fpage><lpage>1289</lpage><pub-id pub-id-type="doi">10.1038/s41593-018-0209-y</pub-id><pub-id pub-id-type="pmid">30127430</pub-id></element-citation></ref><ref id="bib49"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Mattar</surname><given-names>MG</given-names></name><name><surname>Daw</surname><given-names>ND</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>Prioritized memory access explains planning and hippocampal replay</article-title><source>Nature Neuroscience</source><volume>21</volume><fpage>1609</fpage><lpage>1617</lpage><pub-id pub-id-type="doi">10.1038/s41593-018-0232-z</pub-id><pub-id pub-id-type="pmid">30349103</pub-id></element-citation></ref><ref id="bib50"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Mazza</surname><given-names>V</given-names></name><name><surname>Jacob</surname><given-names>J</given-names></name><name><surname>Dammhahn</surname><given-names>M</given-names></name><name><surname>Zaccaroni</surname><given-names>M</given-names></name><name><surname>Eccard</surname><given-names>JA</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>Individual variation in cognitive style reflects foraging and anti-predator strategies in a small mammal</article-title><source>Scientific Reports</source><volume>9</volume><elocation-id>10157</elocation-id><pub-id pub-id-type="doi">10.1038/s41598-019-46582-1</pub-id><pub-id pub-id-type="pmid">31300696</pub-id></element-citation></ref><ref id="bib51"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Menegas</surname><given-names>W</given-names></name><name><surname>Babayan</surname><given-names>BM</given-names></name><name><surname>Uchida</surname><given-names>N</given-names></name><name><surname>Watabe-Uchida</surname><given-names>M</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>Opposite initialization to novel cues in dopamine signaling in ventral and posterior striatum in mice</article-title><source>eLife</source><volume>6</volume><elocation-id>e21886</elocation-id><pub-id pub-id-type="doi">10.7554/eLife.21886</pub-id><pub-id pub-id-type="pmid">28054919</pub-id></element-citation></ref><ref id="bib52"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Menegas</surname><given-names>W</given-names></name><name><surname>Akiti</surname><given-names>K</given-names></name><name><surname>Amo</surname><given-names>R</given-names></name><name><surname>Uchida</surname><given-names>N</given-names></name><name><surname>Watabe-Uchida</surname><given-names>M</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>Dopamine neurons projecting to the posterior striatum reinforce avoidance of threatening stimuli</article-title><source>Nature Neuroscience</source><volume>21</volume><fpage>1421</fpage><lpage>1430</lpage><pub-id pub-id-type="doi">10.1038/s41593-018-0222-1</pub-id><pub-id pub-id-type="pmid">30177795</pub-id></element-citation></ref><ref id="bib53"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Mobbs</surname><given-names>D</given-names></name><name><surname>Headley</surname><given-names>DB</given-names></name><name><surname>Ding</surname><given-names>W</given-names></name><name><surname>Dayan</surname><given-names>P</given-names></name></person-group><year iso-8601-date="2020">2020</year><article-title>Space, time, and fear: survival computations along defensive circuits</article-title><source>Trends in Cognitive Sciences</source><volume>24</volume><fpage>228</fpage><lpage>241</lpage><pub-id pub-id-type="doi">10.1016/j.tics.2019.12.016</pub-id></element-citation></ref><ref id="bib54"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ogasawara</surname><given-names>T</given-names></name><name><surname>Sogukpinar</surname><given-names>F</given-names></name><name><surname>Zhang</surname><given-names>K</given-names></name><name><surname>Feng</surname><given-names>YY</given-names></name><name><surname>Pai</surname><given-names>J</given-names></name><name><surname>Jezzini</surname><given-names>A</given-names></name><name><surname>Monosov</surname><given-names>IE</given-names></name></person-group><year iso-8601-date="2022">2022</year><article-title>A primate temporal cortex-zona incerta pathway for novelty seeking</article-title><source>Nature Neuroscience</source><volume>25</volume><fpage>50</fpage><lpage>60</lpage><pub-id pub-id-type="doi">10.1038/s41593-021-00950-1</pub-id><pub-id pub-id-type="pmid">34903880</pub-id></element-citation></ref><ref id="bib55"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Oudeyer</surname><given-names>PY</given-names></name><name><surname>Kaplan</surname><given-names>F</given-names></name></person-group><year iso-8601-date="2007">2007</year><article-title>What is intrinsic motivation? a typology of computational approaches</article-title><source>Frontiers in Neurorobotics</source><volume>1</volume><elocation-id>6</elocation-id><pub-id pub-id-type="doi">10.3389/neuro.12.006.2007</pub-id><pub-id pub-id-type="pmid">18958277</pub-id></element-citation></ref><ref id="bib56"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Paulus</surname><given-names>MP</given-names></name><name><surname>Yu</surname><given-names>AJ</given-names></name></person-group><year iso-8601-date="2012">2012</year><article-title>Emotion and decision-making: affect-driven belief systems in anxiety and depression</article-title><source>Trends in Cognitive Sciences</source><volume>16</volume><fpage>476</fpage><lpage>483</lpage><pub-id pub-id-type="doi">10.1016/j.tics.2012.07.009</pub-id></element-citation></ref><ref id="bib57"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Radulescu</surname><given-names>A</given-names></name><name><surname>Niv</surname><given-names>Y</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>State representation in mental illness</article-title><source>Current Opinion in Neurobiology</source><volume>55</volume><fpage>160</fpage><lpage>166</lpage><pub-id pub-id-type="doi">10.1016/j.conb.2019.03.011</pub-id><pub-id pub-id-type="pmid">31051434</pub-id></element-citation></ref><ref id="bib58"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>RÃ©ale</surname><given-names>D</given-names></name><name><surname>Reader</surname><given-names>SM</given-names></name><name><surname>Sol</surname><given-names>D</given-names></name><name><surname>McDougall</surname><given-names>PT</given-names></name><name><surname>Dingemanse</surname><given-names>NJ</given-names></name></person-group><year iso-8601-date="2007">2007</year><article-title>Integrating animal temperament within ecology and evolution</article-title><source>Biological Reviews of the Cambridge Philosophical Society</source><volume>82</volume><fpage>291</fpage><lpage>318</lpage><pub-id pub-id-type="doi">10.1111/j.1469-185X.2007.00010.x</pub-id><pub-id pub-id-type="pmid">17437562</pub-id></element-citation></ref><ref id="bib59"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Rieger</surname><given-names>MO</given-names></name><name><surname>Wang</surname><given-names>M</given-names></name><name><surname>Hens</surname><given-names>T</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>Risk preferences around the world</article-title><source>Management Science</source><volume>61</volume><fpage>637</fpage><lpage>648</lpage><pub-id pub-id-type="doi">10.1287/mnsc.2013.1869</pub-id></element-citation></ref><ref id="bib60"><element-citation publication-type="confproc"><person-group person-group-type="author"><name><surname>Rigter</surname><given-names>M</given-names></name><name><surname>Lacerda</surname><given-names>B</given-names></name><name><surname>Hawes</surname><given-names>N</given-names></name></person-group><year iso-8601-date="2021">2021</year><article-title>Risk-averse bayes-adaptive reinforcement learning</article-title><conf-name>Advances in Neural Information Processing Systems 34</conf-name><fpage>1142</fpage><lpage>1154</lpage></element-citation></ref><ref id="bib61"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Russell</surname><given-names>SJ</given-names></name><name><surname>Norvig</surname><given-names>P</given-names></name></person-group><year iso-8601-date="2016">2016</year><source>Artificial Intelligence: A Modern Approach</source><publisher-name>Pearson Education Limited</publisher-name></element-citation></ref><ref id="bib62"><element-citation publication-type="preprint"><person-group person-group-type="author"><name><surname>Rusu</surname><given-names>AA</given-names></name><name><surname>Colmenarejo</surname><given-names>SG</given-names></name><name><surname>Gulcehre</surname><given-names>C</given-names></name><name><surname>Desjardins</surname><given-names>G</given-names></name><name><surname>Kirkpatrick</surname><given-names>J</given-names></name><name><surname>Pascanu</surname><given-names>R</given-names></name><name><surname>Mnih</surname><given-names>V</given-names></name><name><surname>Kavukcuoglu</surname><given-names>K</given-names></name><name><surname>Hadsell</surname><given-names>R</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Policy Distillation</article-title><source>arXiv</source><pub-id pub-id-type="doi">10.48550/arXiv.1511.06295</pub-id></element-citation></ref><ref id="bib63"><element-citation publication-type="software"><person-group person-group-type="author"><name><surname>Shen</surname><given-names>T</given-names></name></person-group><year iso-8601-date="2025">2025</year><data-title>Risking-your-tail-modeling-individual-differences-in-risk-sensitive-exploration</data-title><version designator="swh:1:rev:73126ab1952b96842a588f6fa4fc4eed6a80b264">swh:1:rev:73126ab1952b96842a588f6fa4fc4eed6a80b264</version><source>Software Heritage</source><ext-link ext-link-type="uri" xlink:href="https://archive.softwareheritage.org/swh:1:dir:1e57b66b4cea20aa9aeac42046646c38d4919648;origin=https://github.com/shenkev/Risking-your-Tail-Modeling-Individual-Differences-in-Risk-sensitive-Exploration;visit=swh:1:snp:4e617ceb034057cfab1c6ec8b831e5a6eeef3360;anchor=swh:1:rev:73126ab1952b96842a588f6fa4fc4eed6a80b264">https://archive.softwareheritage.org/swh:1:dir:1e57b66b4cea20aa9aeac42046646c38d4919648;origin=https://github.com/shenkev/Risking-your-Tail-Modeling-Individual-Differences-in-Risk-sensitive-Exploration;visit=swh:1:snp:4e617ceb034057cfab1c6ec8b831e5a6eeef3360;anchor=swh:1:rev:73126ab1952b96842a588f6fa4fc4eed6a80b264</ext-link></element-citation></ref><ref id="bib64"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Simon</surname><given-names>P</given-names></name><name><surname>Dupuis</surname><given-names>R</given-names></name><name><surname>Costentin</surname><given-names>J</given-names></name></person-group><year iso-8601-date="1994">1994</year><article-title>Thigmotaxis as an index of anxiety in mice. Influence of dopaminergic transmissions</article-title><source>Behavioural Brain Research</source><volume>61</volume><fpage>59</fpage><lpage>64</lpage><pub-id pub-id-type="doi">10.1016/0166-4328(94)90008-6</pub-id><pub-id pub-id-type="pmid">7913324</pub-id></element-citation></ref><ref id="bib65"><element-citation publication-type="preprint"><person-group person-group-type="author"><name><surname>Sousa</surname><given-names>M</given-names></name><name><surname>Bujalski</surname><given-names>P</given-names></name><name><surname>Cruz</surname><given-names>BF</given-names></name><name><surname>Louie</surname><given-names>K</given-names></name><name><surname>McNamee</surname><given-names>D</given-names></name><name><surname>Paton</surname><given-names>JJ</given-names></name></person-group><year iso-8601-date="2023">2023</year><article-title>Dopamine neurons encode a multidimensional probabilistic map of future reward</article-title><source>bioRxiv</source><pub-id pub-id-type="doi">10.1101/2023.11.12.566727</pub-id></element-citation></ref><ref id="bib66"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Sutton</surname><given-names>RS</given-names></name></person-group><year iso-8601-date="1988">1988</year><article-title>Learning to predict by the methods of temporal differences</article-title><source>Machine Learning</source><volume>3</volume><fpage>9</fpage><lpage>44</lpage><pub-id pub-id-type="doi">10.1023/A:1022633531479</pub-id></element-citation></ref><ref id="bib67"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Toni</surname><given-names>T</given-names></name><name><surname>Welch</surname><given-names>D</given-names></name><name><surname>Strelkowa</surname><given-names>N</given-names></name><name><surname>Ipsen</surname><given-names>A</given-names></name><name><surname>Stumpf</surname><given-names>MPH</given-names></name></person-group><year iso-8601-date="2009">2009</year><article-title>Approximate Bayesian computation scheme for parameter inference and model selection in dynamical systems</article-title><source>Journal of the Royal Society, Interface</source><volume>6</volume><fpage>187</fpage><lpage>202</lpage><pub-id pub-id-type="doi">10.1098/rsif.2008.0172</pub-id><pub-id pub-id-type="pmid">19205079</pub-id></element-citation></ref><ref id="bib68"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wang</surname><given-names>JX</given-names></name><name><surname>Kurth-Nelson</surname><given-names>Z</given-names></name><name><surname>Tirumala</surname><given-names>D</given-names></name><name><surname>Soyer</surname><given-names>H</given-names></name><name><surname>Leibo</surname><given-names>JZ</given-names></name><name><surname>Munos</surname><given-names>R</given-names></name><name><surname>Blundell</surname><given-names>C</given-names></name><name><surname>Kumaran</surname><given-names>D</given-names></name><name><surname>Botvinick</surname><given-names>M</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>Learning to reinforcement learn</article-title><source>Machine Learning</source><volume>3</volume><fpage>9</fpage><lpage>44</lpage></element-citation></ref><ref id="bib69"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Weber</surname><given-names>R</given-names></name></person-group><year iso-8601-date="1992">1992</year><article-title>On the gittins index for multiarmed bandits</article-title><source>The Annals of Applied Probability</source><volume>2</volume><elocation-id>1033</elocation-id><pub-id pub-id-type="doi">10.1214/aoap/1177005588</pub-id></element-citation></ref><ref id="bib70"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wilson</surname><given-names>RC</given-names></name><name><surname>Geana</surname><given-names>A</given-names></name><name><surname>White</surname><given-names>JM</given-names></name><name><surname>Ludvig</surname><given-names>EA</given-names></name><name><surname>Cohen</surname><given-names>JD</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>Humans use directed and random exploration to solve the explore-exploit dilemma</article-title><source>Journal of Experimental Psychology. General</source><volume>143</volume><fpage>2074</fpage><lpage>2081</lpage><pub-id pub-id-type="doi">10.1037/a0038199</pub-id><pub-id pub-id-type="pmid">25347535</pub-id></element-citation></ref><ref id="bib71"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wiltschko</surname><given-names>AB</given-names></name><name><surname>Tsukahara</surname><given-names>T</given-names></name><name><surname>Zeine</surname><given-names>A</given-names></name><name><surname>Anyoha</surname><given-names>R</given-names></name><name><surname>Gillis</surname><given-names>WF</given-names></name><name><surname>Markowitz</surname><given-names>JE</given-names></name><name><surname>Peterson</surname><given-names>RE</given-names></name><name><surname>Katon</surname><given-names>J</given-names></name><name><surname>Johnson</surname><given-names>MJ</given-names></name><name><surname>Datta</surname><given-names>SR</given-names></name></person-group><year iso-8601-date="2020">2020</year><article-title>Revealing the structure of pharmacobehavioral space through motion sequencing</article-title><source>Nature Neuroscience</source><volume>23</volume><fpage>1433</fpage><lpage>1443</lpage><pub-id pub-id-type="doi">10.1038/s41593-020-00706-3</pub-id><pub-id pub-id-type="pmid">32958923</pub-id></element-citation></ref></ref-list><app-group><app id="appendix-1"><title>Appendix 1</title><sec sec-type="appendix" id="s8"><title>A recovery analysis</title><p>We performed recovery analysis on our ABCSMC fits. The recovery targets were the best-fitting particles for each of the 26 mice. We ran ABCSMC a second time, using the same hyperparameters, to check that we could recover the recovery targets.</p><p><xref ref-type="fig" rid="app1fig1">Appendix 1â€”figure 1</xref> compares the recovery targets against the closest particles in the posterior of the (recovery) ABCSMC fit. Each subplot shows one of the nine fitted parameters: <inline-formula><alternatives><mml:math id="inf257"><mml:semantics><mml:mrow><mml:msub><mml:mrow><mml:mstyle class="text"><mml:mtext>nCVaR</mml:mtext></mml:mstyle></mml:mrow><mml:mrow><mml:mi>ğ›¼</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:semantics></mml:math><tex-math id="inft257">\begin{document}$\text{nCVaR}_\alpha$\end{document}</tex-math></alternatives></inline-formula>, <inline-formula><alternatives><mml:math id="inf258"><mml:semantics><mml:mrow><mml:msub><mml:mrow><mml:mi>ğº</mml:mi></mml:mrow><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:semantics></mml:math><tex-math id="inft258">\begin{document}$G_0$\end{document}</tex-math></alternatives></inline-formula>, the forgetting rate <inline-formula><alternatives><mml:math id="inf259"><mml:semantics><mml:mrow><mml:mi>ğ‘“</mml:mi></mml:mrow></mml:semantics></mml:math><tex-math id="inft259">\begin{document}$f$\end{document}</tex-math></alternatives></inline-formula>, the three hazard prior means, and the three hazard prior deviations. In general, the ABCSMC fitting algorithm recovers the recovery target reasonably well for all animals, with a minimum <inline-formula><alternatives><mml:math id="inf260"><mml:semantics><mml:mrow><mml:msup><mml:mrow><mml:mi>ğ‘…</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:semantics></mml:math><tex-math id="inft260">\begin{document}$R^2$\end{document}</tex-math></alternatives></inline-formula> value of 0.72.</p><fig id="app1fig1" position="float"><label>Appendix 1â€”figure 1.</label><caption><title>Recovery targets versus the closest particles in the ABCSMC posterior.</title><p>Each subplot plots one of the nine fitted parameters for all 26 animals. The colors of the points indicate the animal group. The gray <inline-formula><alternatives><mml:math id="inf261"><mml:semantics><mml:mrow><mml:mi>ğ‘¦</mml:mi><mml:mo class="MathClass-rel" stretchy="false">=</mml:mo><mml:mi>ğ‘¥</mml:mi></mml:mrow></mml:semantics></mml:math><tex-math id="inft261">\begin{document}$y=x$\end{document}</tex-math></alternatives></inline-formula> line represents a perfect recovery of the recovery targets. Most points lie close to the <inline-formula><alternatives><mml:math id="inf262"><mml:semantics><mml:mrow><mml:mi>ğ‘¦</mml:mi><mml:mo class="MathClass-rel" stretchy="false">=</mml:mo><mml:mi>ğ‘¥</mml:mi></mml:mrow></mml:semantics></mml:math><tex-math id="inft262">\begin{document}$y=x$\end{document}</tex-math></alternatives></inline-formula> line, suggesting our ABCSMC fitting algorithm has good recoverability.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-100366-app1-fig1-v1.tif"/></fig><p><xref ref-type="fig" rid="app1fig2">Appendix 1â€”figure 2</xref> compares the recovery targets against the (marginal) means of the ABCSMC posterior. The exploration pool <inline-formula><alternatives><mml:math id="inf263"><mml:semantics><mml:mrow><mml:msub><mml:mrow><mml:mi>ğº</mml:mi></mml:mrow><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:semantics></mml:math><tex-math id="inft263">\begin{document}$G_0$\end{document}</tex-math></alternatives></inline-formula> and forgetting rate <inline-formula><alternatives><mml:math id="inf264"><mml:semantics><mml:mrow><mml:mi>ğ‘“</mml:mi></mml:mrow></mml:semantics></mml:math><tex-math id="inft264">\begin{document}$f$\end{document}</tex-math></alternatives></inline-formula> are well recovered. However, there is poor recoverability for <inline-formula><alternatives><mml:math id="inf265"><mml:mstyle><mml:mrow><mml:mstyle displaystyle="false"><mml:msub><mml:mtext>nCVaR</mml:mtext><mml:mi>Î±</mml:mi></mml:msub></mml:mstyle></mml:mrow></mml:mstyle></mml:math><tex-math id="inft265">\begin{document}$\text{nCVaR}_\alpha$\end{document}</tex-math></alternatives></inline-formula> and the prior parameters due to non-identifiability. This is further illustrated in <xref ref-type="fig" rid="app1fig3">Appendix 1â€”figure 3</xref> for a single brave animal. <xref ref-type="fig" rid="app1fig3">Appendix 1â€”figure 3</xref> plots the univariate and bivariate marginals of the ABCSMC posterior. As expected, the recovery targets lie within a narrow range of the posterior distributions for <inline-formula><alternatives><mml:math id="inf266"><mml:semantics><mml:mrow><mml:msub><mml:mrow><mml:mi>ğº</mml:mi></mml:mrow><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:semantics></mml:math><tex-math id="inft266">\begin{document}$G_0$\end{document}</tex-math></alternatives></inline-formula> and <inline-formula><alternatives><mml:math id="inf267"><mml:semantics><mml:mrow><mml:mi>ğ‘“</mml:mi></mml:mrow></mml:semantics></mml:math><tex-math id="inft267">\begin{document}$f$\end{document}</tex-math></alternatives></inline-formula>. For <inline-formula><alternatives><mml:math id="inf268"><mml:semantics><mml:mrow><mml:msub><mml:mrow><mml:mstyle class="text"><mml:mtext>nCVaR</mml:mtext></mml:mstyle></mml:mrow><mml:mrow><mml:mi>ğ›¼</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:semantics></mml:math><tex-math id="inft268">\begin{document}$\text{nCVaR}_\alpha$\end{document}</tex-math></alternatives></inline-formula> and the prior parameters, the recovery targets are farther from the means of the posterior but still lie within a region of the posterior with support.</p><fig id="app1fig2" position="float"><label>Appendix 1â€”figure 2.</label><caption><title>Identical to <xref ref-type="fig" rid="app1fig1">Appendix 1â€”figure 1</xref> but the recovery targets are plotted against the (marginal) means of the ABCSMC posterior.</title><p>We chose the final ABCSMC population for the posterior (population 15). <inline-formula><alternatives><mml:math id="inf269"><mml:semantics><mml:mrow><mml:msup><mml:mrow><mml:mi>ğ‘…</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:semantics></mml:math><tex-math id="inft269">\begin{document}$R^2$\end{document}</tex-math></alternatives></inline-formula> is high for <inline-formula><alternatives><mml:math id="inf270"><mml:semantics><mml:mrow><mml:msub><mml:mrow><mml:mi>ğº</mml:mi></mml:mrow><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:semantics></mml:math><tex-math id="inft270">\begin{document}$G_0$\end{document}</tex-math></alternatives></inline-formula> and,<inline-formula><alternatives><mml:math id="inf271"><mml:semantics><mml:mrow><mml:mi>ğ‘“</mml:mi></mml:mrow></mml:semantics></mml:math><tex-math id="inft271">\begin{document}$f$\end{document}</tex-math></alternatives></inline-formula> suggesting that these parameters are identifiable. <inline-formula><alternatives><mml:math id="inf272"><mml:semantics><mml:mrow><mml:msup><mml:mrow><mml:mi>ğ‘…</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:semantics></mml:math><tex-math id="inft272">\begin{document}$R^2$\end{document}</tex-math></alternatives></inline-formula> is low for <inline-formula><alternatives><mml:math id="inf273"><mml:semantics><mml:mrow><mml:msub><mml:mrow><mml:mstyle class="text"><mml:mtext>nCVaR</mml:mtext></mml:mstyle></mml:mrow><mml:mrow><mml:mi>ğ›¼</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:semantics></mml:math><tex-math id="inft273">\begin{document}$\text{nCVaR}_\alpha$\end{document}</tex-math></alternatives></inline-formula> and the hazard priors due to the non-identifiability discussed in the main text. In particular, <inline-formula><alternatives><mml:math id="inf274"><mml:semantics><mml:mrow><mml:msup><mml:mrow><mml:mi>ğ‘…</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:semantics></mml:math><tex-math id="inft274">\begin{document}$R^2$\end{document}</tex-math></alternatives></inline-formula> is less than 0.0 for <inline-formula><alternatives><mml:math id="inf275"><mml:semantics><mml:mrow><mml:msub><mml:mrow><mml:mstyle class="text"><mml:mtext>nCVaR</mml:mtext></mml:mstyle></mml:mrow><mml:mrow><mml:mi>ğ›¼</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:semantics></mml:math><tex-math id="inft275">\begin{document}$\text{nCVaR}_\alpha$\end{document}</tex-math></alternatives></inline-formula> and <inline-formula><alternatives><mml:math id="inf276"><mml:semantics><mml:mrow><mml:msub><mml:mrow><mml:mi>ğœƒ</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:mstyle class="text"><mml:mtext>-mean</mml:mtext></mml:mstyle></mml:mrow></mml:semantics></mml:math><tex-math id="inft276">\begin{document}$\theta_2 \text{-mean}$\end{document}</tex-math></alternatives></inline-formula> suggesting these parameters are the most confounded. However, <inline-formula><alternatives><mml:math id="inf277"><mml:semantics><mml:mrow><mml:msup><mml:mrow><mml:mi>ğ‘…</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:semantics></mml:math><tex-math id="inft277">\begin{document}$R^2$\end{document}</tex-math></alternatives></inline-formula> is high for, <inline-formula><alternatives><mml:math id="inf278"><mml:semantics><mml:mrow><mml:msub><mml:mrow><mml:mi>ğœƒ</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:mstyle class="text"><mml:mtext>-deviation</mml:mtext></mml:mstyle></mml:mrow></mml:semantics></mml:math><tex-math id="inft278">\begin{document}$\theta_2\text{-deviation}$\end{document}</tex-math></alternatives></inline-formula> suggesting <inline-formula><alternatives><mml:math id="inf279"><mml:semantics><mml:mrow><mml:msub><mml:mrow><mml:mstyle class="text"><mml:mtext>nCVaR</mml:mtext></mml:mstyle></mml:mrow><mml:mrow><mml:mi>ğ›¼</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:semantics></mml:math><tex-math id="inft279">\begin{document}$\text{nCVaR}_\alpha$\end{document}</tex-math></alternatives></inline-formula> does not confound the flexibility of the hazard function. Finally, the <inline-formula><alternatives><mml:math id="inf280"><mml:semantics><mml:mrow><mml:msup><mml:mrow><mml:mi>ğ‘…</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:semantics></mml:math><tex-math id="inft280">\begin{document}$R^2$\end{document}</tex-math></alternatives></inline-formula> for <inline-formula><alternatives><mml:math id="inf281"><mml:semantics><mml:mrow><mml:msub><mml:mrow><mml:mi>ğœƒ</mml:mi></mml:mrow><mml:mrow><mml:mn>3</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:semantics></mml:math><tex-math id="inft281">\begin{document}$\theta_3$\end{document}</tex-math></alternatives></inline-formula> is nearly zero. This is expected because timid and some intermediate animals do not have duration-3 approach, and for these animals, <inline-formula><alternatives><mml:math id="inf282"><mml:semantics><mml:mrow><mml:msub><mml:mrow><mml:mi>ğœƒ</mml:mi></mml:mrow><mml:mrow><mml:mn>3</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:semantics></mml:math><tex-math id="inft282">\begin{document}$\theta_3$\end{document}</tex-math></alternatives></inline-formula> can take on arbitrarily large values.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-100366-app1-fig2-v1.tif"/></fig><fig id="app1fig3" position="float"><label>Appendix 1â€”figure 3.</label><caption><title>The ABCSMC posterior for animal 24.</title><p>Univariate and bivariate marginals are shown on the diagonal and off-diagonal, respectively. Recovery targets are shown as green vertical lines in univariate plots and green points on bivariate plots. Marginal means are shown in orange. Recovery targets and means are close for <inline-formula><alternatives><mml:math id="inf283"><mml:semantics><mml:mrow><mml:msub><mml:mrow><mml:mi>ğº</mml:mi></mml:mrow><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:semantics></mml:math><tex-math id="inft283">\begin{document}$G_0$\end{document}</tex-math></alternatives></inline-formula> and <inline-formula><alternatives><mml:math id="inf284"><mml:semantics><mml:mrow><mml:mi>ğ‘“</mml:mi></mml:mrow></mml:semantics></mml:math><tex-math id="inft284">\begin{document}$f$\end{document}</tex-math></alternatives></inline-formula> due to their identifiability. <inline-formula><alternatives><mml:math id="inf285"><mml:mstyle><mml:mrow><mml:mstyle displaystyle="false"><mml:msub><mml:mrow><mml:mi mathvariant="normal">n</mml:mi><mml:mi mathvariant="normal">C</mml:mi><mml:mi mathvariant="normal">V</mml:mi><mml:mi mathvariant="normal">a</mml:mi><mml:mi mathvariant="normal">R</mml:mi></mml:mrow><mml:mi>Î±</mml:mi></mml:msub></mml:mstyle></mml:mrow></mml:mstyle></mml:math><tex-math id="inft285">\begin{document}$\rm{nCVaR}_\alpha$\end{document}</tex-math></alternatives></inline-formula> and the hazard prior parameters are non-identifiable. Hence, the recovery targets are farther from the mean but still lie in a region of the posterior with support.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-100366-app1-fig3-v1.tif"/></fig></sec></app></app-group></back><sub-article article-type="editor-report" id="sa0"><front-stub><article-id pub-id-type="doi">10.7554/eLife.100366.3.sa0</article-id><title-group><article-title>eLife Assessment</article-title></title-group><contrib-group><contrib contrib-type="author"><name><surname>Langdon</surname><given-names>Angela</given-names></name><role specific-use="editor">Reviewing Editor</role><aff><institution>National Institute of Mental Health</institution><country>United States</country></aff></contrib></contrib-group><kwd-group kwd-group-type="evidence-strength"><kwd>Convincing</kwd></kwd-group><kwd-group kwd-group-type="claim-importance"><kwd>Important</kwd></kwd-group></front-stub><body><p>Shen et al. present a computational account of individual differences in mouse exploration when faced with a novel object in an open field from a previously published study (Akiti et al.) that relates subject-specific intrinsic exploration and caution about potential hazards to the spectrum of behaviors observed in this setting. Overall, this computational study is an <bold>important</bold> contribution that leverages a very general modeling framework (a Bayes Adaptive Markov Decision Process) to quantify and interrogate distinct drivers of exploratory behavior under potential threat. Given their assumptions, the modeling results are <bold>convincing</bold>: the authors are able to describe a substantial amount of the behavioral features and idiosyncracies in this dataset, and their model affords a normative interpretation related to inherent risk aversion and predation hazard &quot;flexibility&quot; of individual animals and should be of broad interest to researchers working to understand open-ended exploratory behaviors.</p></body></sub-article><sub-article article-type="referee-report" id="sa1"><front-stub><article-id pub-id-type="doi">10.7554/eLife.100366.3.sa1</article-id><title-group><article-title>Reviewer #1 (Public review):</article-title></title-group><contrib-group><contrib contrib-type="author"><anonymous/><role specific-use="referee">Reviewer</role></contrib></contrib-group></front-stub><body><p>Summary:</p><p>This work computationally characterized the threat-reward learning behavior of mice in a recent study (Akiti et al.), which had prominent individual differences. The authors constructed a Bayes-adaptive Markov decision process model, and fitted the behavioral data by the model. The model assumed (i) hazard function staring from a prior (with free mean and SD parameters) and updated in a Bayesian manner through experience (actually no real threat or reward was given in the experiment), (ii) risk-sensitive evaluation of future outcomes (calculating lower ğ›¼ quantile of outcomes with free ğ›¼ parameter), and (iii) heuristic exploration bonus. The authors found that (i) brave animals had more widespread hazard priors than timid animals and thereby quickly learned that there was in fact little real threat, (ii) brave animals may also be less risk-aversive than timid animals in future outcome evaluation, and (iii) the exploration bonus could explain the observed behavioral features, including the transition of behavior from the peak to steady-state frequency of bout. Overall, this work is a novel interesting analysis of threat-reward learning, and provides useful insights for future experimental and theoretical work. However, there are several issues that I think need to be addressed.</p><p>Strengths:</p><p>- This work provides a normative Bayesian account for individual differences in braveness/timidity in reward-threat learning behavior, which complements the analysis by Akiti et al. based on model-free threat reinforcement learning.</p><p>- Specifically, the individual differences were characterized by (i) the difference in the variance of hazard prior and potentially also (ii) the difference in the risk-sensitivity in evaluation of future returns.</p><p>Weakness:</p><p>- Theoretically the effect of prior is diluted over experience whereas the effect of biased (risk-aversive) evaluation persists, but these two effects could not be teased apart in the fitting analysis of the current data.</p><p>- It is currently unclear how (whether) the proposed model corresponds to neurobiological (rather than behavioral) findings, different from the analysis by Akiti et al.</p><p>Comments on revisions:</p><p>The authors have adequately replied to all the concerns that I raised in my review of the original manuscript. I do not have any remaining concern, and I am now more convinced that this work provides novel important insights and stimulates future experimental and theoretical examinations.</p></body></sub-article><sub-article article-type="referee-report" id="sa2"><front-stub><article-id pub-id-type="doi">10.7554/eLife.100366.3.sa2</article-id><title-group><article-title>Reviewer #3 (Public review):</article-title></title-group><contrib-group><contrib contrib-type="author"><anonymous/><role specific-use="referee">Reviewer</role></contrib></contrib-group></front-stub><body><p>Summary:</p><p>The manuscript presents computational modelling of the behaviour of mice during encounters with novel and familiar objects, originally reported in Akiti et al. (Neuron 110, 2022). Mice typically perform short bouts of approach followed by retreat to a safe distance, presumably to balance exploration to discover possible reward with the potential risk of predation. However, there is considerable heterogeneity in this exploratory behaviour, both across time as an individual subject becomes more confident in approaching the object, and across subjects; with some mice rapidly becoming confident to closely explore the object, while other timid mice never become fully confident that the object is safe. The current work aims to explain both the dynamics of adaptation of individual animals over time, and the quantitative and qualitative differences in behaviour between subjects, by modelling their behaviour as arising from model-based planning in a Bayes adaptive Markov Decision Process (BAMDP) framework, in which the subjects maintain and update probabilistic estimates of the uncertain hazard presented by the object, and rationally balance the potential reward from exploring the object with the potential risk of predation it presents.</p><p>In order to fit these complex models to the behaviour the authors necessarily make substantial simplifying assumptions, including coarse-graining the exploratory behaviour into phases quantified by a set of summary statistics related to the approach bouts of the animal. Inter-individual variation between subjects is modelled both by differences in their prior beliefs about the possible hazard presented by the object, and by differences in their risk preference, modelled using a conditional value at risk (CVaR) objective, which focuses the subject's evaluation on different quantiles of the expected distribution of outcomes. Interestingly, these two conceptually different possible sources of inter-subject variation in brave vs timid exploratory behaviour turn out not to be dissociable in the current dataset as they can largely compensate for each other in their effects on the measured behaviour. Nonetheless, the modelling captures a wide range of quantitative and qualitative differences between subjects in the dynamics of how they explore the object, essentially through differences in how subject's beliefs about the potential risk and reward presented by the object evolve over the course of exploration, and are combined to drive behaviour.</p><p>Exploration in the face of risk is a ubiquitous feature of the decision-making problem faced by organisms, with strong clinical relevance, yet remains poorly understood and under-studied, making this work a timely and welcome addition to the literature.</p><p>Strengths:</p><p>- Individual differences in exploratory behaviour are an interesting, important, and under-studied topic.</p><p>- Application of cutting-edge modelling methods to a rich behavioural dataset, successfully accounting for diverse qualitative and qualitative features of the data in a normative framework.</p><p>- Thoughtful discussion of the results in the context of prior literature.</p><p>Limitations:</p><p>- The model-fitting approach used of coarse-graining the behaviour into phases and fitting to their summary statistics may not be applicable to exploratory behaviours in more complex environments where coarse-graining is less straightforward.</p><p>Comments on revisions:</p><p>All recommendations to authors from the first review were addressed in the revised manuscript.</p></body></sub-article><sub-article article-type="author-comment" id="sa3"><front-stub><article-id pub-id-type="doi">10.7554/eLife.100366.3.sa3</article-id><title-group><article-title>Author response</article-title></title-group><contrib-group><contrib contrib-type="author"><name><surname>Shen</surname><given-names>Tingke</given-names></name><role specific-use="author">Author</role><aff><institution>Max Planck Institute for Biological Cybernetics</institution><addr-line><named-content content-type="city">TÃ¼bingen</named-content></addr-line><country>Germany</country></aff></contrib><contrib contrib-type="author"><name><surname>Dayan</surname><given-names>Peter</given-names></name><role specific-use="author">Author</role><aff><institution>Max Planck Institute for Biological Cybernetics</institution><addr-line><named-content content-type="city">TÃ¼bingen</named-content></addr-line><country>Germany</country></aff></contrib></contrib-group></front-stub><body><p>The following is the authorsâ€™ response to the original reviews.</p><disp-quote content-type="editor-comment"><p><bold>Reviewer #1 (Public review):</bold></p><p>This work computationally characterized the threat-reward learning behavior of mice in a recent study (Akiti et al.), which had prominent individual differences. The authors constructed a Bayes-adaptive Markov decision process model and fitted the behavioral data by the model. The model assumed (i) hazard function starting from a prior (with free mean and SD parameters) and updated in a Bayesian manner through experience (actually no real threat or reward was given in the experiment), (ii) risk-sensitive evaluation of future outcomes (calculating lower ğ›¼ quantile of outcomes with free ğ›¼ parameter), and (iii) heuristic exploration bonus. The authors found that (i) brave animals had more widespread hazard priors than timid animals and thereby quickly learned that there was in fact little real threat, (ii) brave animals may also be less risk-aversive than timid animals in future outcome evaluation, and (iii) the exploration bonus could explain the observed behavioral features, including the transition of behavior from the peak to steady-state frequency of bout. Overall, this work is a novel interesting analysis of threat-reward learning, and provides useful insights for future experimental and theoretical work. However, there are several issues that I think need to be addressed.</p><p>Strengths:</p><p>(1) This work provides a normative Bayesian account for individual differences in braveness/timidity in reward-threat learning behavior, which complements the analysis by Akiti et al. based on model-free threat reinforcement learning.</p><p>(2) Specifically, the individual differences were characterized by (i) the difference in the variance of hazard prior and potentially also (ii) the difference in the risk-sensitivity in the evaluation of future returns.</p><p>Weakness:</p><p>(1) Theoretically the effect of prior is diluted over experience whereas the effect of biased (risk-aversive) evaluation persists, but these two effects could not be teased apart in the fitting analysis of the current data.</p><p>(2) It is currently unclear how (whether) the proposed model corresponds to neurobiological (rather than behavioral) findings, different from the analysis by Akiti et al.</p></disp-quote><p>We thank reviewer #1 for their useful feedback which weâ€™ve used to improve the discussion, formatting and clarity of the paper, and for highlighting important questions for future extensions of our work.</p><disp-quote content-type="editor-comment"><p>Major points:</p><p>(1) Line 219</p><p>It was assumed that the exploration bonus was replenished at a steady rate when the animal was at the nest. An alternative way would be assuming that the exploration bonus slowly degraded over time or experience, and if doing so, there appears to be a possibility that the transition of the bout rate from peak to steady-state could be at least partially explained by such a decrease in the exploration bonus.</p></disp-quote><p>Section 2.2.3 explains the mechanism of the exploration bonus which motivates approach. We think that the mechanism suggested by the reviewer is, in essence, what is happening in the model. The exploration pool is indeed depleted over time or bouts of experience at the object. In the peak confident phase for brave animals and the peak cautious phase for timid animals, the rate of depletion exceeds the rate of regeneration, since the agent spends only a single turn at the nest between bouts. In the steady-state phase, the exploration pool has depleted so much previously that the agent must wait multiple turns at the nest for the pool to regenerate to a sufficiently high value to justify approaching the object again.</p><p>We have updated section 2.2.3 to explain that agents spend one turn at the nest during peak phase but multiple turns during steady-state phase. Hopefully, this makes our mechanism clear:</p><p>â€œIn simulations, when ğº(ğ‘¡) is high, the agent has a high motivation to explore the object, spending only a single turn in the nest state between bouts. In other words, the depletion from ğº0 substantially influences the time point at which approach makes a transition from peak to steady-state; the steady-state time then depends on the dynamics of depletion (when at the object) and replenishment (when at the nest). In particular, in the steady-state phases, the agent must wait multiple turns at the nest for ğº(ğ‘¡) to regenerate so that informational reward once again exceeds the potential cost of hazard.â€œ</p><disp-quote content-type="editor-comment"><p>(2) Line 237- (Section 2.2.6, 2.2.7, Figures 7, 9)</p><p>I was confused by the descriptions about nCVaR. I looked at the cited original literature Gagne &amp; Dayan 2022, and understood that nCVaR is a risk-sensitive version of expected future returns (equation 4) with parameter Î± (Î±-bar) (ranging from 0 to 1) representing risk preference. Line 269-271 and Section 4.2 of the present manuscript described (in my understanding) that Î± was a parameter of the model. Then, isn't it more natural to report estimated values of Î±, rather than nCVaR, for individual animals in Section 2.2.6, 2.2.7, Figures 7, 9 (even though nCVaR monotonically depends on Î±)? In Figures 7 and 9, nCVaR appears to be upper-bounded to 1. The upper limit of Î± is 1 by definition, but I have no idea why nCVaR was also bounded by 1. So I would like to ask the authors to add more detailed explanations on nCVaR. Currently, CVaR is explained in Lines 237-243, but actually, there is no explanation about nCVaR rather than its formal name 'nested conditional value at risk' in Line 237.</p></disp-quote><p>Thank you for pointing out this error. We have corrected the paper to use nCVaR to refer to the objective and nCVaR's Î±, or sometimes just Î±, to refer to the risk sensitivity parameter and thus the degree of risk sensitivity.</p><disp-quote content-type="editor-comment"><p>(3) Line 333 (and Abstract)</p><p>Given that animals' behaviors could be equally well fitted by the model having both nCVaR (free Î±) and hazard prior and the alternative model having only hazard prior (with Î± = 1), may it be difficult to confidently claim that brave (/timid) animals had risk-neutral (/risk-aversive) preference in addition to widespread (/low-variance) hazard prior? Then, it might be good to somewhat weaken the corresponding expression in the Abstract (e.g., add 'potentially also' to the result for risk sensitivity) or mention the inseparability of risk sensitivity and prior belief pessimism (e.g., &quot;... although risk sensitivity and prior belief pessimism could not be teased apart&quot;).</p></disp-quote><p>Thank you for this suggestion, we have duly weakened the wording in the Abstract to say â€œpotentially more risk neutralâ€:</p><p>â€œSome animals begin with cautious exploration, and quickly transition to confident approach to maximize exploration for reward; we classify them as potentially more risk neutral, and enjoying a flexible hazard prior. By contrast, other animals only ever approach in a cautious manner and display a form of self-censoring; they are characterized by potential risk aversion and high and inflexible hazard priors.â€</p><disp-quote content-type="editor-comment"><p><bold>Reviewer #2 (Public Review):</bold></p><p>Shen and Dayan build a Bayes adaptive Markov decision process model with three key components: an adaptive hazard function capturing potential predation, an intrinsic reward function providing the urge to explore, and a conditional value at risk (CvaR, closely related to probability distortion explanations of risk traits). The model itself is very interesting and has many strengths including considering different sources of risk preference in generating behavior under uncertainty. I think this model will be useful to consider for those studying approach/avoid behaviors in dynamic contexts.</p><p>The authors argue that the model explains behavior in a very simple and unconstrained behavioral task in which animals are shown novel objects and retreat from them in various manners (different body postures and patterns of motor chunks/syllables). The model itself does capture lots of the key mouse behavioral variability (at least on average on a mouse-by-mouse basis) which is interesting and potentially useful. However, the variables in the model - and the internal states it implies the mice have during the behavior - are relatively unconstrained given the wide range of explanations one can offer for the mouse behavior in the original study (Akiti et al). This reviewer commends the authors on an original and innovative expansion of existing models of animal behaviour, but recommends that the authors revise their study to reflect the obvious challenges . I would also recommend a reduction in claiming that this exercise gives a normative-like or at least quantitative account of mental disorders.</p></disp-quote><p>We thank reviewer #2 for highlighting some of the strengths of our paper as well as pointing out important limitations of Akiti et alâ€™s original study which weâ€™ve inherited as well as some limitations of our own method. We address their concerns below.</p><p>We have added a paragraph to the discussion discussing the limitations of the state representation we adopted from Akitiâ€™s study.</p><p>(Reviewer #1 had the same concern, see above) â€œMotivated by tail-behind versus tail-exposed in Akiti et al. (2022), we model approach using a dichotomy between cautious and confident approach states [...]â€</p><p>We have reduced the suggestion that our model provides an account of mental disorders in the abstract.</p><p>Before:</p><p>â€œOn the other hand, â€œtimidâ€ animals, characterized by risk aversion and high and inflexible hazard priors, display self-censoring that leads to the sort of asymptotic maladaptive behavior that is often associated with psychiatric illnesses such as anxiety and depression.â€</p><p>After:</p><p>â€œBy contrast, other animals only ever approach in a cautious manner and display a form of self-censoring; they are characterized by potential risk aversion and high and inflexible hazard priors. â€œ</p><disp-quote content-type="editor-comment"><p>My main comment is that this paper is a very nice model creation that can characterize the heterogeneity rodent behavior in a very simple approach/avoid context (Akiti et al; when a novel object is placed in an arena) that itself can be interpreted in a multitude of ways. The use of terms like &quot;exploration&quot;, &quot;brave&quot;, etc in this context is tricky because the task does not allow the original authors (Akiti et al) to quantify these &quot;internal states&quot; or &quot;traits&quot; with the appropriate level of quantitative detail to say whether this model is correct or not in capturing the internal states that result in the rodent behavior. That said, the original behavioral setup is so simple that one could imagine capturing the behavioral variability in multiple ways (potentially without evoking complex computations that the original authors never showed the mouse brain performs). I would recommend reframing the paper as a new model that proposes a set of internal states that could give rise to the behavioral heterogeneity observed in Akiti et al, but nonetheless is at this time only a hypothesis. Furthermore, an explanation of what would be really required to test this would be appreciated to make the point clearer.</p></disp-quote><p>We thought very hard about using terms that might be considered to be anthropomorphic such as â€˜timidâ€™ and â€˜braveâ€™. We are, of course, aware, of the concerns articulated by investigators such as LeDoux about this. However, we think that, provided that we are clear on the first appearance (using â€˜scareâ€™ quotes) that we are using them as indeed labels for latent characteristics that capture correlations in various aspects of behaviour, they are more helpful than harmful in making our descriptions understandable.</p><disp-quote content-type="editor-comment"><p><bold>Reviewer #3 (Public Review):</bold></p><p>Summary:</p><p>The manuscript presents computational modelling of the behaviour of mice during encounters with novel and familiar objects, originally reported by Akiti et al. (Neuron 110, 2022) . Mice typically perform short bouts of approach followed by a retreat to a safe distance, presumably to balance exploration to discover possible rewards with the potential risk of predation. However, there is considerable heterogeneity in this exploratory behaviour, both across time as an individual subject becomes more confident in approaching the object, and across subjects; with some mice rapidly becoming confident to closely explore the object, while other timid mice never become fully confident that the object is safe. The current work aims to explain both the dynamics of adaptation of individual animals over time, and the quantitative and qualitative differences in behaviour between subjects, by modelling their behaviour as arising from model-based planning in a Bayes adaptive Markov Decision Process (BAMDP) framework, in which the subjects maintain and update probabilistic estimates of the uncertain hazard presented by the object, and rationally balance the potential reward from exploring the object with the potential risk of predation it presents.</p><p>In order to fit these complex models to the behaviour the authors necessarily make substantial simplifying assumptions, including coarse-graining the exploratory behaviour into phases quantified by a set of summary statistics related to the approach bouts of the animal. Inter-individual variation between subjects is modelled both by differences in their prior beliefs about the possible hazard presented by the object and by differences in their risk preference, modelled using a conditional value at risk (CVaR) objective, which focuses the subject's evaluation on different quantiles of the expected distribution of outcomes. Interestingly these two conceptually different possible sources of inter-subject variation in brave vs timid exploratory behaviour turn out not to be dissociable in the current dataset as they can largely compensate for each other in their effects on the measured behaviour. Nonetheless, the modelling captures a wide range of quantitative and qualitative differences between subjects in the dynamics of how they explore the object, essentially through differences in how subject's beliefs about the potential risk and reward presented by the object evolve over the course of exploration, and are combined to drive behaviour.</p><p>Exploration in the face of risk is a ubiquitous feature of the decision-making problem faced by organisms, with strong clinical relevance, yet remains poorly understood and under-studied, making this work a timely and welcome addition to the literature.</p><p>Strengths:</p><p>(1) Individual differences in exploratory behaviour are an interesting, important, and under-studied topic.</p><p>(2) Application of cutting-edge modelling methods to a rich behavioural dataset, successfully accounting for diverse qualitative and qualitative features of the data in a normative framework.</p><p>(3) Thoughtful discussion of the results in the context of prior literature.</p><p>Limitations:</p><p>(1) The model-fitting approach used of coarse-graining the behaviour into phases and fitting to their summary statistics may not be applicable to exploratory behaviours in more complex environments where coarse-graining is less straightforward.</p><p>(2) Some aspects of the work could be more usefully clarified within the manuscript.</p></disp-quote><p>We thank reviewer #3 for their positive feedback and helping us to improve the clarity of our paper. We have added discussion they thought was missing.</p><disp-quote content-type="editor-comment"><p><bold>Reviewer #1 (Recommendations for the authors):</bold></p><p>(1) Line 25-28</p><p>This part of the Abstract might give an impression that timidity (but not braveness) is potentially associated with psychiatric illness and even that timidity is thus inferior to braveness. However, even though extreme timidity might indeed be associated with anxiety or depression, extreme braveness could also be associated with other psychiatric or behavioral problems. Moreover, as a population, the existence of both timid and brave individuals could be advantageous, and it could be a reason why both types of individuals evolutionarily survived in the case of wild animals (although Akiti et al. used mice, which may have no or very limited genetic varieties, and so things may be different). So I would like to encourage the authors to elaborate on the expression of this part of the Abstract and/or enrich the related discussion in the Discussion.</p></disp-quote><p>This is an important point. We note on line 38 that excessive novelty seeking (potentially caused by excessive braveness) could also be maladaptive.</p><p>Additionally, we have added a paragraph to the discussion discussing heterogeneity in risk sensitivity within a population.</p><p>â€œOur data show that there is substantial variation in the degrees of risk sensitivity across the mice. Previous works have reported substantial interpopulation and intrapopulation differences in risk-sensitivity in humans which depend on gender, age, socioeconomic status, personality characteristics, wealth and culture (Rieger et al., 2015; Frey et al., 2017). Despite the normative appeal of ğ›¼ = 1, it is possible that a population may benefit from including individuals with $\alpha$ different from 1.0 or highly negative priors. For example, more cautious individuals could learn from merely observing the risky behavior of less cautious individuals. Furthermore, we have only considered risk-sensitivity under epistemic uncertainty in our work. Risk averse individuals, for instance with ğ›¼ &lt; 1 may be more successful than risk-neutral agents in environments where there are unexpected dangers (unknown unknowns). Risk-aversion is thus a temperament of ecological and evolutionary significance (RÃ©ale et al., 2007).â€</p><disp-quote content-type="editor-comment"><p>(2) Line 149</p><p>Section 2.2 consists of eight subsections. I think this organization may not be very appealing, because there are a bit too many subsections, and their relations are not immediately clear to readers. So I would like to encourage the authors to make an elaboration. For example, since 2.2.1 - 2.2.5 describes a summary of model construction and model fitting whereas 2.2.6-2.2.8 shows the results, it could be good to divide these into separate sections (2.2.1 - 2.2.5 and 2.3.1 - 2.3.3).</p></disp-quote><p>Thank you for pointing this out. Weâ€™ve renumbered the sections as youâ€™ve suggested.</p><disp-quote content-type="editor-comment"><p>(3) Line 347-8</p><p>Theoretically, the effect of prior is diluted over experience whereas the effect of biased (risk-aversive) evaluation persists, as the authors mentioned in Lines 393-394. Then isn't it possible to consider environments/conditions in which the two effects can be separated?</p></disp-quote><p>We appreciate this suggestion. Indeed, our original thought in modeling this experiment was that this would be exactly the case here - with epistemic uncertainty reducing as the object became more familiar. However, proving to an animal that a single environment is completely stationary/fixed is hard - reflected in our conclusion here that the exploration bonus pool replenishes. Thus, we argued in the discussion that a series of environments would be necessary to separate risk sensitivity from priors.</p><disp-quote content-type="editor-comment"><p>(4) Line 407</p><p>It would be nice to add a brief phrase explaining how (in what sense) this model's assumption was consistent with the reported behavior. Also, should the assumption of having two discrete approach states (cautious and confident) itself be regarded as a limitation of the model? If the tail-behind and tail-exposure approaches were not merely operationally categorized but were indicated to be two qualitatively distinct behaviors in the experiment by Akiti et al., it is reasonable to model them as two discrete states, but otherwise, the assumption of two discrete states would need to be mentioned as a simplification/limitation.</p></disp-quote><p>We have now removed line 407, and now have an additional paragraph in the discussion discussing the limitations of the tail-behind and tail-exposure state representation: â€œMotivated by tail-behind versus tail-exposed in Akiti et al. (2022), we model approach using a dichotomy between cautious and confident approach states. This is likely a crude approximation to the continuous and multifaceted nature of animal approach behavior. For example, during approach animals likely adjust their levels of vigilance continuously (or discretely; Lloyd and Dayan (2018)) to monitor threat, and choose different velocities for movement, and different attentional strategies for inspecting the novel object. We hope future works will model these additional behavioral complexities, perhaps with additional internal states, and corroborate these states with neurobiological data.â€</p><disp-quote content-type="editor-comment"><p>(5) Line 418</p><p>The authors contrasted their model-based analyses with the model-free analyses of Akiti et al. Another aspect of differences between the authors' model and the model of Akiti et al. is whether it is normative or mechanistic: while how the model of Akiti et al. can be biologically implemented appears to be clear (TS dopamine represents threat TD error, and TS dopamine-dependent cortico-striatal plasticity implements TD error-based update of model-free threat prediction), biological implementation of the authors' model seems more elusive. Given this, it might be a fruitful direction to explore how these two models can be integrated in the future.</p></disp-quote><p>We enthusiastically agree that it would be most interesting in the future to explore the integration of the two models - and, in the discussion (Lines 537-548, 454-461) , point to some first steps that might be fruitful along these lines. There are two separate considerations here: one is that our account is mostly computational and algorithmic, whereas Akitiâ€™s model is mostly algorithmic and implementational; the second is, as noted by the reviewer, that our account is model-based, whereas Akitiâ€™s model is model-free (in the sense of reinforcement learning; RL). These are related - thanks in no small part to the work from the group including Akiti, we know a lot more about the implementation of model-free than model-based RL. However, our model-based account does reach additional features of behavior not captured in Akiti et al.â€™s model such as bout duration, frequency, and approach type. Thus, the temptation of unification.</p><disp-quote content-type="editor-comment"><p>(6) Line 426</p><p>Related to the previous point, it would be nice to more specifically describe what variable TS dopamine can represent in the authors' model if possible.</p></disp-quote><p>In the discussion (Lines 454-461) , we speculate that TS dopamine could still respond to the physical salience of the novel object and affect choices by determining the potential cost of the encountered threat or the prior on the hazard function. For example, perhaps ablating TS dopamine reduces the hazard priors which leads to faster transition from cautious to confident approach and longer bout durations, consistent with the optogenetics behavioral data reported in Akiti et al.</p><disp-quote content-type="editor-comment"><p><bold>Reviewer #2 (Recommendations for the authors):</bold></p><p>My guess is simpler versions of the model would not fit the data well. But this does not mean for example that the mice have probability distortions (CvaR) or that even probabilistic reasoning and the internal models necessary to support them are acting in the behavioral context studied by Akiti. So related to the above, I would ask what other models would fit and would not fit the data? And what does this mean?</p></disp-quote><p>These are good points. Our model provides an approximately normative account of the animalsâ€™ behavior in terms of what it achieves relative to a utility function. In practice, the animals could deploy a precompiled model-free policy (which does not rely on probabilistic computations) that is exactly equivalent to our model-based policy. With the current experiment, we cannot conclude whether or not the animals are performing the prospective calculations in an online manner. Of course, the extent to which animals or humans are performing probabilistic computations online and have internal models are on-going questions of study.</p><p>Model comparison is difficult because currently we do not know of any other risk-sensitive exploration models. We cannot directly compare to the model in Akiti et al. since our model explains additional features of behavior: bout duration, frequency, and approach type. Indeed, our model is as simple as it can be in the sense with the exception of nCVaR, removing any of the other parameters makes it difficult to fit some animals in our dataset. In the future, our model could be used to fit other datasets of risk-sensitive exploration and, ideally, be compared to other models.</p><disp-quote content-type="editor-comment"><p>Explaining why animals avoid the novel object in what the offers call benign environment is a very tricky issue. In Akiti et al, the readers are not yet convinced that the mice know that this environment is benign. Being placed in an arena with a novel object presents mice with a great uncertainty and we do not know whether they treat this as benign. Therefore, the alternative explanations in this study need to be carefully discussed in lieu of the limitations of the initial study.</p></disp-quote><p>It is certainly true that it is unclear if the arena is completely benign to the animals. However, the amount of time the animal spends in the center of the arena decreases significantly from habituation to novelty days. This suggests that the animals avoid the novel object largely because of the object itself, rather than the potential danger associated with the arena. Furthermore, the animals are not reported as exhibiting more extreme behaviours such as freezing. In any case, our account is relative in the sense that we are comparing the time the animal spends at the object versus elsewhere in the environment, driven by the relative novelty and relative risk of the environment versus the object. Trying to get more absolute measures of these quantities would require a richer experimental set-up, for instance with different degree of habituation or experience of the occurrence of (other) novel objects, in general.</p><p>We added a short note to the discussion to explain this:</p><p>â€œFourth, we modeled the relative amount of time the animal spends at the object versus elsewhere in the environment which depends on the differential risk in the two states. However, it is likely the animals avoid the novel object largely because of the object itself, rather than the potential danger associated with the arena since they spend much less time at the center of the arena during novelty than habituation days.â€</p><disp-quote content-type="editor-comment"><p>Figure 2 - how confident are the authors that each mouse differs from y=1? Related to this, the behavior in Akiti is very noisy and changes across time. I am not sure if the authors fully describe at what levels their model captures the behavior vs not in a detailed enough fashion.</p></disp-quote><p>We have performed a random permutation test on the minute-to-minute data. We have updated Figure 2 so that brave animals that pass the Benjaminiâ€“Hochberg procedure y&gt;1 at level q=0.05 are represented with solid green dots and animals that donâ€™t pass are represented with hollow dots. 8 out of 11 brave animals passed Benjaminiâ€“Hochberg.</p><disp-quote content-type="editor-comment"><p><bold>Reviewer #3 (Recommendations for the authors):</bold></p><p>(1) I could not find information in the preprint about code availability. Please consider making the code public to help others apply these modelling methods.</p></disp-quote><p>We have released code and included the url in the paper in the Methods section.</p><disp-quote content-type="editor-comment"><p>(2) Though the manuscript was generally clearly written, there were a number of places where some additional information or clarification would be useful:</p><p>a) Please define and explain the terms 'tail-behind' and 'tail-exposed' (used to describe approach bout types) when first used.</p></disp-quote><p>We have added definitions when we first mention these terms:</p><p>â€œ[...] 'tail-behind' (bouts where the animal's nose was closer to the object than the tail for the entire bout) and 'tail-exposed' (bouts where the animal's tail is closer to the object than the nose at some point during the bout), associated respectively with cautious risk-assessment and engagementâ€</p><disp-quote content-type="editor-comment"><p>b) At lines 57-58 when contrasting the 'model-free' account of Akiti et al with the 'model-based' account of the current work, it would be worth clarifying that these terms are being used in the RL sense rather than e.g. a model-based analysis of the data.</p></disp-quote><p>We have updated the relevant lines to say â€œmodel-free/based reinforcement learningâ€.</p><disp-quote content-type="editor-comment"><p>c) Line 61, the phrase 'the significant long-run approach of timid animals despite having reached the &quot;avoid&quot; state' is unclear as the 'avoid' state has not been defined.</p></disp-quote><p>We updated the terminology to â€œavoidance behaviorâ€ to be consistent with Akiti et al. Avoidance refers to the animal routinely avoiding the object and therefore being unable to learn whether it is safe.</p><disp-quote content-type="editor-comment"><p>d) It was not completely clear to me how the coarse-graining of the behaviour was implemented. Specifically, how were animals assigned to the brave, intermediate, or timid group, and how were the parameters of the resulting behavioural phases fit?</p></disp-quote><p>Sorry that this was not clear. Section 2.1 explains how the minute-to-minute behavioral data was coarse-grained and how animal groups were assigned. We have added further explanation of Figure 2 to the main text:</p><p>â€œFig 2 summarizes our categorization of the animals into the three groups: brave, intermediate, and timid based on the phases identified in the animal's exploratory trajectories. Timid animals spend no time in confident approach and are plotted in orange at the origin of Fig 2. Brave animals differ from intermediate animals in that their approach time during the first ten minutes of the confident phase is greater than the last ten minutes (steady-state phase). Brave animals are plotted in green above and intermediate animals are plotted in black below the y=1 line in Fig 2.â€</p><p>We also added extra information to outline the goal, and methodology of coarse-graining and animal grouping:</p><p>â€œWe sought to capture these qualitative differences (cautious versus confident) as well as aspects of the quantitative changes in bout durations and frequencies as the animal learns about their environment. To make this readily possible, we abstracted the data in two ways:</p><p>averaging bout statistics over time, and clustering the animals into three groups with operationally distinct behaviors.â€</p><disp-quote content-type="editor-comment"><p>e) What purpose does the 'retreat' state serve in the BAMDP model (as opposed to transitioning directly from 'object' to 'nest' states), and why do subjects not pass through it following 'detect' states?</p></disp-quote><p>Thank you for pointing this out. We have updated Figure 3 to note that the two â€œdetected statesâ€ also point to the â€œretreatâ€ state. The reviewer is correct that there could be alternative versions of the state diagram, and the â€˜retreatâ€™ state could indeed have been eliminated. However, we thought that it was helpful to structure the animalâ€™s progress through state space.</p><disp-quote content-type="editor-comment"><p>f) Why was the hazard function parameterised via the mean and SD at each time step rather than with a parametric form of the mean and SD as a function of time?</p></disp-quote><p>Since the agent can only spend 2, 3, or 4 turns at the object states, we didnâ€™t see a need to parameterize the mean and SD as a function of time. Doing so is a good solution to scaling up the hazard function to more time-steps.</p><disp-quote content-type="editor-comment"><p>(3) There were also a couple of points that could potentially be usefully touched on in the discussion:</p><p>a) What, if any, is the relationship between the CVaR objective and distributional RL? They seem potentially related due to both focussing on quantiles of the outcome distribution.</p></disp-quote><p>We have added a paragraph to the discussion discussing the connection between distributional RL and CVaR:</p><p>â€œCVaR is known to come in different flavors in the case of temporally-extended behavior. Gagne and Dayan (2021) introduces two alternative time-consistent formulations of CVaR: nested CVaR (nCVaR) and precommitted CVaR (pCVaR). nCVaR and pCVaR both enjoy Bellman equations which make it possible to compute approximately optimal policies without directly computing whole distributions of the outcomes. We use nCVaR in this study for its computational efficiency. There is, of course, great current interest in distributional reinforcement learning (Bellemare et al., 2023b) which does acquire such whole distributions, not the least because of prominent observations linking non-linearities in the response functions of dopamine neurons to methods for learning distributions of outcomes (Dabney et al., 2020; Masset et al., 2023; Sousa et al., 2023). One functional motivation for considering entire outcome distributions is the possibility of using them to determine risk-sensitive policies (Gagne and Dayan, 2021).</p><p>While it is possible to compute CVaR directly from return distributions, Gagne and Dayan (2021) showed that this can lead to temporally inconsistent policies where the agent deviates from its original plans (the authors called this the fixed CVaR or fCVaR measure).</p><p>Rather further removed from our model-based methods is work from Antonov and Dayan (2023), who consider a model-free exploration strategy which exploits full return distributions to compute the value of perfect information which is used as a heuristic for trying actions with uncertain consequences. Future works can examine risk-sensitive versions of Antonov and Dayan (2023)'s computationally efficient model-free algorithm as one solution to the burdensome computations in our model-based method.â€</p><disp-quote content-type="editor-comment"><p>b) Why normatively might subjects have non-neutral risk preference as captured by the CvaR?</p></disp-quote><p>We also added a paragraph to the discussion discussing the advantage of heterogeneity in risk sensitivity within a population:</p><p>(Reviewer #1 had the same question, see above) â€œOur data show that there is substantial variation in the degrees of risk sensitivity across the mice. Previous works have reported substantial interpopulation and intrapopulation differences in risk-sensitivity in humans which depend on gender, age, socioeconomic status, personality characteristics, wealth and culture [...]â€</p><disp-quote content-type="editor-comment"><p>c) Relevance of the current modelling work to clinical conditions characterised by dysregulation of risk assesment (e.g. anxiety or PTSD).</p></disp-quote><p>Weâ€™ve added a paragraph to the discussion:</p><p>â€œInter-individual differences in risk sensitivity are also of critical importance in psychiatry, reflected in a panoply of anxiety disorders (Butler and Mathews, 1983; Giorgetta et al., 2012; Maner et al., 2007; Charpentier et al., 2017), along with worry and rumination (Gagne and Dayan, 2022). Understanding the spectrum of extreme priors and extreme values of ğ›¼ could have therapeutic implications, adding significance to the search for tasks that can more cleanly separate them.â€</p><disp-quote content-type="editor-comment"><p>d) Is it surprising to see differences in risk preference (nCVaR) between the familiar object and novel object condition, given that risk preference might be conceptualised as a trait rather than a state variable?</p></disp-quote><p>Thank you for raising this point. You are right that we expected risk sensitivity (nCVaR alpha) to be the same between FONC and UONC animals on average. It is difficult to know if alpha is higher for FONC than UONC animals due to the non-identifiability between alpha and hazard priors. We have added this discussion to the paper:</p><p>â€œThis is surprising if we interpret ğ›¼ as a trait that is stable through time. Unfortunately, due to the non-identifiability between ğ›¼ and hazard priors, we cannot verify whether ğ›¼ is actually higher for FONC animals than UONC animals.â€</p></body></sub-article></article>