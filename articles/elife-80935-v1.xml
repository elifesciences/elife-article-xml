<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD v1.1d3 20150301//EN"  "JATS-archivearticle1.dtd"><article xmlns:xlink="http://www.w3.org/1999/xlink" article-type="research-article" dtd-version="1.1d3"><front><journal-meta><journal-id journal-id-type="nlm-ta">elife</journal-id><journal-id journal-id-type="publisher-id">eLife</journal-id><journal-title-group><journal-title>eLife</journal-title></journal-title-group><issn publication-format="electronic">2050-084X</issn><publisher><publisher-name>eLife Sciences Publications, Ltd</publisher-name></publisher></journal-meta><article-meta><article-id pub-id-type="publisher-id">80935</article-id><article-id pub-id-type="doi">10.7554/eLife.80935</article-id><article-categories><subj-group subj-group-type="display-channel"><subject>Research Article</subject></subj-group><subj-group subj-group-type="heading"><subject>Neuroscience</subject></subj-group></article-categories><title-group><article-title>Cortical activity during naturalistic music listening reflects short-range predictions based on long-term experience</article-title></title-group><contrib-group><contrib contrib-type="author" id="author-285028"><name><surname>Kern</surname><given-names>Pius</given-names></name><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" id="author-271502"><name><surname>Heilbron</surname><given-names>Micha</given-names></name><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" id="author-28130"><name><surname>de Lange</surname><given-names>Floris P</given-names></name><contrib-id contrib-id-type="orcid">http://orcid.org/0000-0002-6730-1452</contrib-id><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="other" rid="par-2"/><xref ref-type="fn" rid="conf2"/></contrib><contrib contrib-type="author" corresp="yes" id="author-101312"><name><surname>Spaak</surname><given-names>Eelke</given-names></name><contrib-id contrib-id-type="orcid">http://orcid.org/0000-0002-2018-3364</contrib-id><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="corresp" rid="cor1">*</xref><xref ref-type="other" rid="par-1"/><xref ref-type="fn" rid="conf1"/></contrib><aff id="aff1"><institution content-type="dept">Donders Institute for Brain, Cognition and Behaviour</institution>, <institution>Radboud University Nijmegen</institution>, <addr-line><named-content content-type="city">Nijmegen</named-content></addr-line>, <country>Netherlands</country></aff></contrib-group><contrib-group content-type="section"><contrib contrib-type="editor" id="author-21838"><name><surname>Obleser</surname><given-names>Jonas</given-names></name><role>Reviewing editor</role><aff><institution>University of Lübeck</institution>, <country>Germany</country></aff></contrib></contrib-group><author-notes><corresp id="cor1"><label>*</label>For correspondence: <email>eelke.spaak@donders.ru.nl</email> (ES);</corresp></author-notes><pub-date date-type="pub" publication-format="electronic"><day>23</day><month>12</month><year>2022</year></pub-date><volume>11</volume><elocation-id>e80935</elocation-id><history><date date-type="received"><day>09</day><month>06</month><year>2022</year></date><date date-type="accepted"><day>22</day><month>12</month><year>2022</year></date></history><permissions><copyright-statement>© 2022, Kern et al</copyright-statement><copyright-year>2022</copyright-year><copyright-holder>Kern et al</copyright-holder><license xlink:href="http://creativecommons.org/licenses/by/4.0/"><license-p>This article is distributed under the terms of the <ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/licenses/by/4.0/">Creative Commons Attribution License</ext-link> permitting unrestricted use and redistribution provided that the original author and source are credited.</license-p></license></permissions><self-uri content-type="pdf" xlink:href="elife-80935-v1.pdf"/><abstract><p>Expectations shape our experience of music. However, the internal model upon which listeners form melodic expectations is still debated. Do expectations stem from Gestalt-like principles or statistical learning? If the latter, does long-term experience play an important role, or are short-term regularities sufficient? And finally, what length of context informs contextual expectations? To answer these questions, we presented human listeners with diverse naturalistic compositions from Western classical music, while recording neural activity using MEG. We quantified note-level melodic surprise and uncertainty using various computational models of music, including a state-of-the-art transformer neural network. A time-resolved regression analysis revealed that neural activity over fronto-temporal sensors tracked melodic surprise particularly around 200 ms and 300–500 ms after note onset. This neural surprise response was dissociated from sensory-acoustic and adaptation effects. Neural surprise was best predicted by computational models that incorporated long-term statistical learning – rather than by simple, Gestalt-like principles. Yet, intriguingly, the surprise reflected primarily short-range musical contexts of less than ten notes. We present a full replication of our novel MEG results in an openly available EEG dataset. Together, these results elucidate the internal model that shapes melodic predictions during naturalistic music listening.</p></abstract><kwd-group kwd-group-type="research-organism"><title>Research organism</title><kwd>Human</kwd></kwd-group><funding-group><award-group id="par-1"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/501100003246</institution-id><institution>Nederlandse Organisatie voor Wetenschappelijk Onderzoek</institution></institution-wrap></funding-source><award-id>016.Veni.198.065</award-id><principal-award-recipient><name><surname>Spaak</surname><given-names>Eelke</given-names></name></principal-award-recipient></award-group><award-group id="par-2"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/501100000781</institution-id><institution>European Research Council</institution></institution-wrap></funding-source><award-id>101000942</award-id><principal-award-recipient><name><surname>de Lange</surname><given-names>Floris P</given-names></name></principal-award-recipient></award-group><funding-statement>The funders had no role in study design, data collection and interpretation, or the decision to submit the work for publication.</funding-statement></funding-group></article-meta></front><back><sec id="s1" sec-type="additional-information"><title>Additional information</title><fn-group content-type="competing-interest"><title>Competing interest</title><fn fn-type="conflict" id="conf2"><p>Floris P de Lange, Senior editor, <italic>eLife</italic>.</p></fn><fn fn-type="conflict" id="conf1"><p>The other authors declare that no competing interests exist.</p></fn></fn-group><fn-group content-type="ethics-information"><title>Ethics</title><fn fn-type="other"><p>Human subjects: The study was approved under the general ethical approval for the Donders Centre for Cognitive Neuroimaging (Imaging Human Cognition, CMO2014/288) by the local ethics committee (CMO Arnhem-Nijmegen, Radboud University Medical Centre). Participants provided written informed consent before the experiment and received monetary compensation.</p></fn></fn-group></sec><sec id="s2" sec-type="supplementary-material"><title>Additional Files</title><sec id="s3" sec-type="data-availability"><title>Data availability</title><p>All data have been deposited into the Donders Repository under CC-BY-4.0 license, under identifier https://doi.org/10.34973/5qxw-nn97 . (NOTE: The persistent doi is not yet active during peer review! Data are available to reviewers with a special reviewer access link provided in the manuscript.)</p><p>The following datasets were generated:</p><p><element-citation id="dataset1" publication-type="data" specific-use="isSupplementedBy"><person-group person-group-type="author"><collab>Kern P</collab><collab>Heilbron M</collab><collab>de Lange FP</collab><collab>Spaak E</collab></person-group><year iso-8601-date="2022">2022</year><source>Tracking predictions in naturalistic music listening using MEG and computational models of music</source><ext-link ext-link-type="uri" xlink:href="https://doi.org/10.34973/5qxw-nn97">https://doi.org/10.34973/5qxw-nn97</ext-link><comment>Donders Repository, doi:10.34973/5qxw-nn97</comment></element-citation></p><p>The following previously published datasets were used:</p><p><element-citation id="dataset2" publication-type="data" specific-use="references"><person-group person-group-type="author"><collab>DiLiberto et al</collab></person-group><year iso-8601-date="2020">2020</year><source>Cortical encoding of melodic expectations in human temporal cortex</source><ext-link ext-link-type="uri" xlink:href="https://doi.org/10.5061/dryad.g1jwstqmh">https://doi.org/10.5061/dryad.g1jwstqmh</ext-link><comment>Dryad Digital Repository, doi:10.5061/dryad.g1jwstqmh</comment></element-citation></p></sec></sec></back></article>