<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD with MathML3 v1.3 20210610//EN"  "JATS-archivearticle1-3-mathml3.dtd"><article xmlns:ali="http://www.niso.org/schemas/ali/1.0/" xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" article-type="review-article" dtd-version="1.3"><front><journal-meta><journal-id journal-id-type="nlm-ta">elife</journal-id><journal-id journal-id-type="publisher-id">eLife</journal-id><journal-title-group><journal-title>eLife</journal-title></journal-title-group><issn publication-format="electronic" pub-type="epub">2050-084X</issn><publisher><publisher-name>eLife Sciences Publications, Ltd</publisher-name></publisher></journal-meta><article-meta><article-id pub-id-type="publisher-id">82268</article-id><article-id pub-id-type="doi">10.7554/eLife.82268</article-id><article-categories><subj-group subj-group-type="display-channel"><subject>Review Article</subject></subj-group><subj-group subj-group-type="heading"><subject>Epidemiology and Global Health</subject></subj-group></article-categories><title-group><article-title>Misstatements, misperceptions, and mistakes in controlling for covariates in observational research</article-title></title-group><contrib-group><contrib contrib-type="author" equal-contrib="yes" id="author-287775"><name><surname>Yu</surname><given-names>Xiaoxin</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">https://orcid.org/0000-0002-3679-2455</contrib-id><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="fn" rid="equal-contrib1">†</xref><xref ref-type="fn" rid="con1"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" corresp="yes" equal-contrib="yes" id="author-273149"><name><surname>Zoh</surname><given-names>Roger S</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">https://orcid.org/0000-0002-8066-1153</contrib-id><email>rszoh@iu.edu</email><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="fn" rid="equal-contrib1">†</xref><xref ref-type="fn" rid="con2"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" id="author-287776"><name><surname>Fluharty</surname><given-names>David A</given-names></name><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="fn" rid="con3"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" id="author-243263"><name><surname>Mestre</surname><given-names>Luis M</given-names></name><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="fn" rid="con4"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" id="author-273806"><name><surname>Valdez</surname><given-names>Danny</given-names></name><xref ref-type="aff" rid="aff2">2</xref><xref ref-type="fn" rid="con5"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" id="author-250689"><name><surname>Tekwe</surname><given-names>Carmen D</given-names></name><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="other" rid="fund4"/><xref ref-type="fn" rid="con6"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" id="author-220585"><name><surname>Vorland</surname><given-names>Colby J</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">https://orcid.org/0000-0003-4225-372X</contrib-id><xref ref-type="aff" rid="aff2">2</xref><xref ref-type="other" rid="fund2"/><xref ref-type="fn" rid="con7"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" id="author-287778"><name><surname>Jamshidi-Naeini</surname><given-names>Yasaman</given-names></name><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="fn" rid="con8"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" id="author-287779"><name><surname>Chiou</surname><given-names>Sy Han</given-names></name><xref ref-type="aff" rid="aff3">3</xref><xref ref-type="fn" rid="con9"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" id="author-287780"><name><surname>Lartey</surname><given-names>Stella T</given-names></name><xref ref-type="aff" rid="aff4">4</xref><xref ref-type="fn" rid="con10"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" corresp="yes" equal-contrib="yes" id="author-56678"><name><surname>Allison</surname><given-names>David B</given-names></name><email>Allison@IU.edu</email><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="fn" rid="equal-contrib1">†</xref><xref ref-type="other" rid="fund1"/><xref ref-type="fn" rid="con11"/><xref ref-type="fn" rid="conf1"/></contrib><aff id="aff1"><label>1</label><institution-wrap><institution-id institution-id-type="ror">https://ror.org/01kg8sb98</institution-id><institution>Department of Epidemiology and Biostatistics, Indiana University School of Public Health-Bloomington</institution></institution-wrap><addr-line><named-content content-type="city">Bloomington</named-content></addr-line><country>United States</country></aff><aff id="aff2"><label>2</label><institution-wrap><institution-id institution-id-type="ror">https://ror.org/01kg8sb98</institution-id><institution>Department of Applied Health Science, Indiana University School of Public Health-Bloomington</institution></institution-wrap><addr-line><named-content content-type="city">Bloomington</named-content></addr-line><country>United States</country></aff><aff id="aff3"><label>3</label><institution-wrap><institution-id institution-id-type="ror">https://ror.org/042tdr378</institution-id><institution>Department of Statistics and Data Science, Southern Methodist University</institution></institution-wrap><addr-line><named-content content-type="city">Dallas</named-content></addr-line><country>United States</country></aff><aff id="aff4"><label>4</label><institution-wrap><institution-id institution-id-type="ror">https://ror.org/01cq23130</institution-id><institution>University of Memphis, School of Public Health</institution></institution-wrap><addr-line><named-content content-type="city">Memphis</named-content></addr-line><country>United Kingdom</country></aff></contrib-group><contrib-group content-type="section"><contrib contrib-type="editor"><name><surname>Iqbal</surname><given-names>Jameel</given-names></name><role>Reviewing Editor</role><aff><institution>DaVita Labs</institution><country>United States</country></aff></contrib><contrib contrib-type="senior_editor"><name><surname>Weigel</surname><given-names>Detlef</given-names></name><role>Senior Editor</role><aff><institution-wrap><institution-id institution-id-type="ror">https://ror.org/0243gzr89</institution-id><institution>Max Planck Institute for Biology Tübingen</institution></institution-wrap><country>Germany</country></aff></contrib></contrib-group><author-notes><fn fn-type="con" id="equal-contrib1"><label>†</label><p>These authors contributed equally to this work</p></fn></author-notes><pub-date publication-format="electronic" date-type="publication"><day>16</day><month>05</month><year>2024</year></pub-date><volume>13</volume><elocation-id>e82268</elocation-id><history><date date-type="received" iso-8601-date="2022-07-29"><day>29</day><month>07</month><year>2022</year></date><date date-type="accepted" iso-8601-date="2024-04-02"><day>02</day><month>04</month><year>2024</year></date></history><permissions><copyright-statement>© 2024, Yu, Zoh et al</copyright-statement><copyright-year>2024</copyright-year><copyright-holder>Yu, Zoh et al</copyright-holder><ali:free_to_read/><license xlink:href="http://creativecommons.org/licenses/by/4.0/"><ali:license_ref>http://creativecommons.org/licenses/by/4.0/</ali:license_ref><license-p>This article is distributed under the terms of the <ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/licenses/by/4.0/">Creative Commons Attribution License</ext-link>, which permits unrestricted use and redistribution provided that the original author and source are credited.</license-p></license></permissions><self-uri content-type="pdf" xlink:href="elife-82268-v1.pdf"/><abstract><p>We discuss 12 misperceptions, misstatements, or mistakes concerning the use of covariates in observational or <italic>nonrandomized</italic> research. Additionally, we offer advice to help investigators, editors, reviewers, and readers make more informed decisions about conducting and interpreting research where the influence of covariates may be at issue. We primarily address misperceptions in the context of statistical management of the covariates through various forms of modeling, although we also emphasize design and model or variable selection. Other approaches to addressing the effects of covariates, including matching, have logical extensions from what we discuss here but are not dwelled upon heavily. The misperceptions, misstatements, or mistakes we discuss include accurate representation of covariates, effects of measurement error, overreliance on covariate categorization, underestimation of power loss when controlling for covariates, misinterpretation of significance in statistical models, and misconceptions about confounding variables, selecting on a collider, and p value interpretations in covariate-inclusive analyses. This condensed overview serves to correct common errors and improve research quality in general and in nutrition research specifically.</p></abstract><kwd-group kwd-group-type="author-keywords"><kwd>independent variable</kwd><kwd>covariate measurement error</kwd><kwd>confounding</kwd><kwd>bias</kwd><kwd>causal effect</kwd><kwd>association</kwd></kwd-group><funding-group><award-group id="fund1"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/100000002</institution-id><institution>National Institutes of Health</institution></institution-wrap></funding-source><award-id>R25HL124208</award-id><principal-award-recipient><name><surname>Allison</surname><given-names>David B</given-names></name></principal-award-recipient></award-group><award-group id="fund2"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/100000002</institution-id><institution>National Institutes of Health</institution></institution-wrap></funding-source><award-id>R25DK099080</award-id><principal-award-recipient><name><surname>Vorland</surname><given-names>Colby J</given-names></name></principal-award-recipient></award-group><award-group id="fund3"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/100000002</institution-id><institution>National Institutes of Health</institution></institution-wrap></funding-source><award-id>1R01DK136994-01</award-id><principal-award-recipient><name><surname>Zoh</surname><given-names>Roger S</given-names></name></principal-award-recipient></award-group><award-group id="fund4"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/100000002</institution-id><institution>National Institutes of Health</institution></institution-wrap></funding-source><award-id>1R01DK132385-01</award-id><principal-award-recipient><name><surname>Tekwe</surname><given-names>Carmen D</given-names></name></principal-award-recipient></award-group><funding-statement>The funders had no role in study design, data collection and interpretation, or the decision to submit the work for publication.</funding-statement></funding-group><custom-meta-group><custom-meta specific-use="meta-only"><meta-name>Author impact statement</meta-name><meta-value>This quick reference guide for researchers addresses common misconceptions in the use of covariates in observational research and offers tips for preventing misstatements and mistakes.</meta-value></custom-meta></custom-meta-group></article-meta></front><body><sec id="s1" sec-type="intro"><title>Introduction</title><p>In observational or <italic>nonrandomized</italic> research, it is common and often wise to control for certain variables in statistical models. Such variables are often referred to as <italic>covariates</italic>. Covariates may be controlled through multiple means, such as inclusion on the ‘right-hand side’ or ‘predictor side’ of a statistical model, matching, propensity score analysis, and other methods (<xref ref-type="bibr" rid="bib34">Cochran and Rubin, 1961</xref>; <xref ref-type="bibr" rid="bib114">Streeter et al., 2017</xref>). Authors of observational research reports will frequently state that they controlled for a particular covariate and, therefore, that bias due to (often phrased as ‘confounding by’) that covariate is not present (<xref ref-type="box" rid="box1">Box 1</xref>). However, authors may write ‘We controlled for…’ when in fact they did not because of common misstatements, misperceptions, and mistakes in controlling for covariates in observational research.</p><boxed-text id="box1"><label>Box 1.</label><p>“Since both tickets had an equal probability of winning the same payoff, uncertainty about the true value of the goods exchanged could not confound results.” (<xref ref-type="bibr" rid="bib8">Arlen and Tontrup, 2015</xref>)</p><p>“In our study population, NSAIDs other than Aspirin was not associated to PC risk and, therefore, could not confound result.” (<xref ref-type="bibr" rid="bib98">Perron et al., 2004</xref>)</p><p>“Most of the demographic, social, and economic differences between patients in different countries were not associated significantly with acquired drug resistance and, therefore, could not confound the association.” (<xref ref-type="bibr" rid="bib28">Cegielski et al., 2014</xref>)</p><p>“Furthermore, study time, as well as self-expectation regarding educational achievements (another potential confounder), could be controlled in the IV models. Therefore, these potential channels could not confound our analysis.” (<xref ref-type="bibr" rid="bib107">Shih and Lin, 2017</xref>)</p></boxed-text><p>Herein, we describe these multiple misperceptions, misstatements, and mistakes involving the use of covariates or control variables. We have discussed misperceptions that in our collective years of experience as authors, reviewers, editors, and readers, in areas including but not limited to aging and geroscience, obesity, nutrition, statistical teaching, cancer research, behavioral science, and other life-science domains have observed to prevail in the literatures of these fields. Determining the frequency with which these misperceptions are held would require very extensive and rigorous survey research. Instead, we offer them as those we find pertinent and readers may decide for themselves which they wish to study. We now make this clear in the manuscript. Some terms we use are defined in the Glossary in <xref ref-type="box" rid="box2">Box 2</xref>. Because of the critical role of attempting to minimize or eliminate biases in association and effect estimates derived from observational research, as recently pointed out elsewhere (<xref ref-type="bibr" rid="bib24">Brown et al., 2023</xref>), we primarily focus on misperceptions, misstatements, or mistakes leading to decisions about whether and how to control for a covariate that fails to actually control for and minimize or eliminate the possibility of bias. We also consider other errors (<xref ref-type="bibr" rid="bib23">Brenner and Loomis, 1994</xref>) in implementation, interpretation, and understanding around analyses that involve covariate adjustment.</p><boxed-text id="box2"><label>Box 2.</label><caption><title>Terminology/Glossary</title></caption><p><bold>Bias.</bold> Here, we define bias as either bias in coefficients in a model or bias in frequentist statistical significance tests. Frequentist statistical significance tests, or the ordinary tests of statistical significance using p values, are commonly reported in this journal and are described more fully here (<xref ref-type="bibr" rid="bib83">Mayo and Cox, 2006</xref>). Under the null hypothesis that there is no true association or effect to detect in a situation, a proper unbiased frequentist test of statistical significance with continuous data and a continuous test statistic yields a uniform sampling distribution of p values (i.e. rectangular) on the interval zero. The distribution is such that the probability of observing any p value less than or equal to a, where a is the preset statistical significance level (i.e. most often 0.05), is a itself. Any statistical significance test that does not meet this standard can be said to be biased. With respect to coefficients or parameter estimates, we can say that bias is equal to the expected value of the coefficient or parameter estimate minus the actual value of the parameter or quantity to be estimated. In an unbiased estimation procedure, that quantity will be zero, meaning that the expected value of the estimate is equivalent to the value to be estimated.</p><p><bold>Replicability.</bold> The National Academies of Sciences uses the following working definition for replicability: “Obtaining consistent results across studies aimed at answering the same scientific question, each of which has obtained its own data” (<xref ref-type="bibr" rid="bib88">National Academies of Sciences, Engineering, and Medicine, 2019</xref>).</p><p><bold>Reproducibility.</bold> The National Academies of Sciences uses the following working definition for reproducibility: “Obtaining consistent results using the same input data; computational steps, methods, and code; and conditions of analysis. This definition is synonymous with ‘computational reproducibility” (<xref ref-type="bibr" rid="bib88">National Academies of Sciences, Engineering, and Medicine, 2019</xref>). Disqualifying reproducibility criteria include nonpublic data and code, inadequate record keeping, nontransparent reporting, obsolescence of the digital artifacts, flawed attempts to reproduce others’ research, and barriers in the culture of research (<xref ref-type="bibr" rid="bib88">National Academies of Sciences, Engineering, and Medicine, 2019</xref>).</p><p><bold>Confounder.</bold> There are many definitions of confounder and not all are equivalent. One definition is “(…) A pre-exposure covariate C [can] be considered a confounder for the effect of A on Y if there exists a set of covariates X such that the effect of the exposure on the outcome is unconfounded conditional on (X, C) but for no proper subset (X, C) is the effect of the exposure on the outcome unconfounded given the subset. Equivalently, a confounder is a member of a minimally sufficient adjustment set” (<xref ref-type="bibr" rid="bib123">VanderWeele and Shpitser, 2013</xref>).</p><p><bold>Collider</bold>. “A collider for a certain pair of variables is any variable that is causally influenced by both of them” (<xref ref-type="bibr" rid="bib101">Rohrer, 2018</xref>).</p><p><bold>Covariate</bold>. We utilize the word covariate to indicate a variable which could, in principle, be included in a statistical model assessing the relations between an independent variable (IV) and a dependent variable (DV).</p><p><bold>Residual.</bold> The difference between the observed and fitted value of the outcome (<xref ref-type="bibr" rid="bib19">Bewick et al., 2003</xref>).</p><p><bold>Independent Variable.</bold> “Independent variables (IVs) generally refer to the presumed causes that are deliberately manipulated by experimenters” (<xref ref-type="bibr" rid="bib29">Chen and Krauss, 2005</xref>) or observed in non-interventional research.</p><p><bold>Dependent Variable.</bold> “Dependent variables (DVs) are viewed as outcomes that are affected by the independent variables” (<xref ref-type="bibr" rid="bib29">Chen and Krauss, 2005</xref>).</p><p><bold>Association.</bold> Two variables are associated when they are not independent, i.e., when the distribution of one of the variables depends on the level of the other variable (<xref ref-type="bibr" rid="bib68">Hernán, 2004</xref>).</p><p><bold>Related.</bold> We say that two variables are related; when the distribution of one variable depends on the level of the other variable. In this context, we use the words ‘related’, ‘associated’, and ‘dependent’ as interchangeable and a complement of independent (<xref ref-type="bibr" rid="bib39">Dawid, 1979</xref>).</p><p><bold>[The 4 highlighted variables merit different and better definitions] Causal effect</bold>: “A difference between the counterfactual risk of the outcome had everybody in the population of interest been exposed and the counterfactual risk of the outcome had everybody in the population been unexposed” (<xref ref-type="bibr" rid="bib68">Hernán, 2004</xref>).</p><p><bold>Statistical Model</bold>: A model used to represent the data-generating process embodying a set of assumptions, and including the uncertainties about the model itself (<xref ref-type="bibr" rid="bib35">Cox, 2006</xref>).</p><p><bold>Precision</bold>: How dispersed the measurements are between each other (<xref ref-type="bibr" rid="bib75">ISO, 1994</xref>).</p><p><bold>Mediator:</bold> Variable that is on the causal pathway from the exposure to outcome (<xref ref-type="bibr" rid="bib124">VanderWeele and Vansteelandt, 2014</xref>).</p><p>*We have used some definitions as phrased in this glossary in some of our other manuscripts currently under review, published, or in-press articles.</p></boxed-text><p>We sometimes use the words <italic>confound</italic>, <italic>confounder</italic>, <italic>confounding</italic>, and other variants by convention or for consistency with the literature we are citing. However, because of the difficulty and inconsistency in defining confounding (<xref ref-type="bibr" rid="bib97">Pearl and Mackenzie, 2018</xref>), we will minimize such use and try to refer primarily to potentially biasing covariates (PBCs). We define PBCs as variables other than the independent variable (IV) or dependent variable (DV) for which decisions about whether and how to condition on them, including by incorporation into a statistical model, can affect the extent to which the expected value of the estimated association of the IV with the DV deviates from the causal effect of the IV on the DV.</p></sec><sec id="s2"><title>Misperception 1. Construct validity</title><p>Simply because we believe an observed variable (e.g. highest educational degree earned) is a measure of a construct (e.g. socioeconomic status), it does not mean that that the observed variable accurately measures that construct or that it has sufficient validity for the elimination of it as a source of covariation biasing estimation of a parameter. This scenario is a misperception attributed to construct validity, which is defined as the extent to which a test or measure accurately measures what it is intended to measure. This misperception is conceptually defined as the assumption that a measure or set of measures accurately measures the outcome of interest; however, associations between tested variables may not adequately or appropriately represent the outcome of interest. This specific type of construct validity is perhaps best exemplified through the use of proxy variables, or variables believed to measure a construct of interest while not necessarily holding a strong linear relationship with that construct. In psychology, the Patient Health Questionaire-9 (PHQ-9) is a highly reliable, nine-item psychological inventory for screening, diagnosing, and monitoring depression as an internalizing disorder. Although these nine items have been extensively tested as an appropriate measure for depression and other internalizing disorders (<xref ref-type="bibr" rid="bib17">Bell, 1994</xref>), it is not uncommon for researchers to modify this scale for shorter surveys (<xref ref-type="bibr" rid="bib99">Poongothai et al., 2009</xref>). However, because the PHQ-9 has been empirically tested with a specific item set, any modification may not effectively measure depressive symptomology as accurately as when the PHQ-9 is used as intended. This problem is also salient in nutritional epidemiology for food categorization (<xref ref-type="bibr" rid="bib64">Hanley-Cook et al., 2023</xref>). For example, ongoing debate remains about ‘food addiction’ as a measurable construct despite limited evidence to suggest such a phenomenon exists and can be empirically measured (<xref ref-type="bibr" rid="bib48">Fletcher and Kenny, 2018</xref>).</p><sec id="s2-1"><title>Why misperception 1 occurs</title><p>This misperception persists simply because issues with construct validity are difficult to identify. First, owing to continuous scientific innovations, we are finding new ways to measure complex behaviors. However, the production of new instruments or tests remains greatly outpaced by such innovation. As such, scientists may rely on old, established instruments to measure problems germane to the 21<sup>st</sup> century. However, the use of these instruments has not been tested in such scenarios, i.e., measuring screentime as a predictor/construct/measure of depression and other internalizing disorders. Second, although it is easy to create a new test or instrument, testing the instrument to ensure construct validity is time-consuming and tedious. If a new instrument is not tested, then no certainty exists as to whether the construct measures what it is intended to measure. Additionally, outcomes measured from old, adapted, and new measures may only be marginally incorrect. Thus, any ability to identify unusual metrics or outcomes becomes impeded, allowing this misperception to continue.</p></sec><sec id="s2-2"><title>How to avoid misperception 1</title><p>We offer two practical recommendations to avoid this misperception. First, if using an established test or instrument that measures many constructs, then the instrument should be used in its entirety. Any alteration to the instrument (particularly relating to question wording, format, and question omission) may alter response patters to a large enough degree that the construct no longer appropriately measures what it is intended to measure. However, in cases where measures are adapted, tailored to specific populations, or created anew, the instrument will ideally be empirically tested using a variety of psychometric analyses (e.g. confirmatory factor analysis) to compare factor weights and loadings between new and adapted measures. Ideally, adaptations to an existing instrument will perform the same such that scores reflect the outcome of interest equally across versions. Other options beyond a confirmatory factor analysis include test/retest reliability—a measure of how consistently a measure obtains similar data between participants—as a secondary metric to again test the reliability and validity of an instrument relative to a measured construct.</p></sec></sec><sec id="s3"><title>Misperception 2. Measurement error in a covariate only attenuates associations or effect estimates and does not create apparent effects</title><p>Measurement errors can take many forms (<xref ref-type="bibr" rid="bib51">Fuller, 2009</xref>; <xref ref-type="bibr" rid="bib27">Carroll et al., 2006</xref>) and are not limited to random, independent, or normally distributed errors. The errors themselves may be correlated, or the errors in measurement may be correlated, with true values of the covariate or with true values of other variables or errors in other variables. The distribution of a covariate’s measurement errors, including their variance and their associations with other variables, can greatly influence the extent to which controlling for that error-contaminated covariate will reduce, increase, or have no appreciable impact on the bias of model parameter estimation and significance testing. That is, the extent to which including a PBC will eliminate, reduce, not effect, or even potentially increase bias in estimating some elements of the model is also influenced by the measurement error distributions. Indeed, a recent review by <xref ref-type="bibr" rid="bib132">Yland et al., 2022</xref> delineates seven ways in which even so-called ‘non-differential’ measurement error can lead to biases away from the null hypothesis in observational epidemiologic research. We do not include all of them here but refer the reader to this cogent paper.</p><p>A frequent misleading statement in the epidemiologic literature is that ‘classical’ measurement error only attenuates effects. For example, Gibson and Zezza state, “Classical measurement errors provide comfort …since they don’t cause bias if on the left-hand side, and just attenuate if on the right-hand side, giving a conservative lower bound to any estimated causal impacts” (<xref ref-type="bibr" rid="bib56">Gibson and Zezza, 2018</xref>). That this is untrue is knowable from theory (<xref ref-type="bibr" rid="bib51">Fuller, 2009</xref>; <xref ref-type="bibr" rid="bib27">Carroll et al., 2006</xref>) and has been demonstrated empirically on multiple occasions. While it is well known that the presence of measurement error in simple linear regression models leads to attenuation, the influence of measurement errors in more complex statistical models depends on the outcomes and the statistical models. Therefore, measurement error and covariates, as well as outcomes, need to be considered (<xref ref-type="bibr" rid="bib121">Tosteson et al., 1998</xref>; <xref ref-type="bibr" rid="bib26">Buonaccorsi et al., 2000</xref>; <xref ref-type="bibr" rid="bib131">Yi et al., 2012</xref>; <xref ref-type="bibr" rid="bib116">Tekwe et al., 2014</xref>; <xref ref-type="bibr" rid="bib117">Tekwe et al., 2016</xref>; <xref ref-type="bibr" rid="bib118">Tekwe et al., 2018</xref>; <xref ref-type="bibr" rid="bib119">Tekwe et al., 2019</xref>).</p><p>Measurement error in the covariates is often ignored or not formally modeled. This may be the result of a general lack of awareness of the consequences on estimation and conclusions drawn regarding the covariates in regression models. This may also be the result of insufficient information regarding the measurement error variance to be included in the modeling. Yet, as a field, we should move toward analyses that account for measurement error in the covariates whenever possible (<xref ref-type="bibr" rid="bib119">Tekwe et al., 2019</xref>).</p><sec id="s3-1"><title>Why misperception 2 occurs</title><p>The influence of measurement error depends on the regression model. Therefore, it cannot be generalized that measurement error always attenuates covariate effects. In some models, the presence of measurement error does lead to attenuation, while in others, it leads to inflated effects of the covariates. A simple way to think about how measurement error can lead to bias is by exploring the nature of random measurement error itself. Let us assume that the random measurement error in our covariate exists. By <italic>random</italic> we mean that all the errors are independent of each other and of all other factors in the model or pertinent to the model. We know that under such circumstances, the variance in the measured values of the covariate will simply be the sum of the true variance of the construct the covariate represents plus the variance of the random measurement errors. As the ratio of the variance of the random errors over the variance of the true construct approaches infinity, the proportion of variance due to the true value of the construct approaches zero and the covariate itself is effectively nothing more than random noise. For example, we wouldn’t expect that simply controlling for the random noise generated from a random number generator would reduce the bias of the IV–DV relationship from any PBC. Although this is an extreme and exaggerated hypothetical, it makes the point that the greater the error variance, the less that controlling for the covariate actually controls for the PBC of interest. Because we know that many PBCs in the field of nutrition and obesity, perhaps most notably those involving self-reported dietary intake, are measured with error, we cannot assume that when we have controlled for a covariate, we have eliminated its biasing influence. If we allow for the possibility—indeed the virtual certainty (<xref ref-type="bibr" rid="bib41">Dhurandhar et al., 2015</xref>; <xref ref-type="bibr" rid="bib55">Gibney, 2022</xref>; <xref ref-type="bibr" rid="bib54">Gibney et al., 2020</xref>)—that the errors are not all random but in some cases will be correlated with important factors in the model, then ‘all bets are off.’ We cannot predict what the effect on the model will be and the extent to which biases will be created, reduced, or both by the inclusion of such covariates without fully specifying the nature of the error structure relative to the model.</p></sec><sec id="s3-2"><title>How to avoid misperception 2</title><p>One way to reduce the concerns of such measurement error is through measurement error correction methods. Fully elucidating them is beyond the scope of this article, but thorough discussions are available (<xref ref-type="bibr" rid="bib51">Fuller, 2009</xref>). Of course, the best way of dealing with measurement error is not to have it, but that is unachievable, particularly in observational studies. Nevertheless, we should continue to strive for ever better measurements in which measurement error is minimized (<xref ref-type="bibr" rid="bib128">Westfall and Yarkoni, 2016</xref>) to levels that plausibly have far less biasing capacity.</p></sec></sec><sec id="s4"><title>Misperception 3 (two parts)</title><sec id="s4-1"><title>Misperception 3a. Continuous covariates divided into polychotomous categories for better interpretation are still well-controlled</title><sec id="s4-1-1"><title>Why misperception 3a occurs</title><p>Another way in which controlling for PBCs can fail involves the intersection of residual confounding and nonlinearity discussed later (see Misperception 5B).</p><p>An astute investigator may recognize the potential for nonlinearity and, therefore, choose to allow for nonlinear effects or associations of the covariate with the outcome by breaking the covariate into categories that could also allow for easier interpretation (<xref ref-type="bibr" rid="bib21">Blas Achic et al., 2018</xref>).</p><p>This is most commonly done through the use of quantiles (on a terminological note, the adjacent bins into which subjects can be placed when the covariate is ‘chopped up’ in this manner might better be termed ‘quantile-defined categories’ and not as quantiles, quintiles, quartiles, etc). The quantiles are the cut points, not the bins formed by the cutting (<xref ref-type="bibr" rid="bib5">Altman and Bland, 1994</xref>). Yet doing so yields, as many have explained (<xref ref-type="bibr" rid="bib127">Veiel, 1988</xref>; <xref ref-type="bibr" rid="bib45">Fitzsimons, 2008</xref>; <xref ref-type="bibr" rid="bib73">Hunter and Schmidt, 1990</xref>; <xref ref-type="bibr" rid="bib74">Irwin and McClelland, 2003</xref>; <xref ref-type="bibr" rid="bib87">Naggara et al., 2011</xref>), ‘coarse categorization’ that effectively creates additional measurement error in the covariate. This is true even if there was no measurement error to begin with, unless the true relationship between the covariate and the outcome miraculously happens to be exactly a series of step functions with the stepping occurring exactly at the points of cutting. In contrast, if the true association is more monotonic, then this categorization loses information and increases the likely residual bias (aka ‘residual confounding’). The result is an apparent control for the covariate of interest that does not truly eliminate bias from the PBC.</p></sec><sec id="s4-1-2"><title>How to avoid misperception 3a</title><p>For optimal analysis, it is advisable for researchers to avoid dichotomizing continuous covariates as much as possible, as this approach may lead to unnecessary suboptimal analysis.</p></sec></sec><sec id="s4-2"><title>Misperception 3b. Covariates categorized in coarse rather than fine categories are more reliable in the presence of measurement error</title><sec id="s4-2-1"><title>Why misperception 3b occurs</title><p>A similar misperception to 3 a is that in the presence of certain forms of measurement error, coarse categorization will make the covariate data more reliable because the original data cannot support fine-grained distinctions. As described by <xref ref-type="bibr" rid="bib80">MacCallum et al., 2002</xref>:</p><p><italic>In questioning colleagues about their reasons for the use of dichotomization, we have often encountered a defense regarding reliability. The argument is that the raw measure of X is viewed as not highly reliable in terms of providing precise information about individual differences but that it can at least be trusted to indicate whether an individual is high or low on the attribute of interest. Based on this view, dichotomization, typically at the median, would provide a ‘more reliable’ measure</italic>.</p><p>It may be true that for some communication purposes, data measured with low precision merit being communicated only in broad categories and not with more precise numbers. Yet, as MacCallum et al. explains after studying dichotomization (a special case or ‘the lower limit’ of polychotomization or categorization), “...the foregoing detailed analysis shows that dichotomization will result in moderate to substantial decreases in measurement reliability under assumptions of classical test theory, regardless of how one defines a true score. As noted by <xref ref-type="bibr" rid="bib72">Humphreys, 1978</xref>, this loss of reliable information due to categorization will tend to attenuate correlations involving dichotomized variables, contributing to the negative statistical consequences described earlier in this article. To argue that dichotomization increases reliability, one would have to define conditions that were very different from those represented in classical measurement theory” (<xref ref-type="bibr" rid="bib80">MacCallum et al., 2002</xref>).</p></sec><sec id="s4-2-2"><title>How to avoid misperception 3b</title><p>Researchers are advised to refrain from dichotomizing covariates that have low reliability because this can have a negative impact on the analysis. Claiming dichotomization will improve reliability would require defining conditions that deviate significantly from classical measurement theory (<xref ref-type="bibr" rid="bib80">MacCallum et al., 2002</xref>), which is simply difficult to verify in real application.</p></sec></sec></sec><sec id="s5"><title>Misperception 4. Controlling for a covariate reduces the power to detect an association of the IV of interest with the DV of interest</title><sec id="s5-1"><title>Why misperception 4 occurs</title><p>Investigators are often reluctant to control for covariates because they believe that doing so will reduce the power to detect the association or effective interest between the IV and the DV or outcome. Therefore, if they perceive that the covariate is one that has a bivariate unadjusted correlation of zero with the IV, they may seize upon this as an opportunity to dismiss that nonsignificant covariate from further consideration. Ironically, this is the very situation in which controlling for the covariate may be most helpful for detecting a statistically significant association between the IV and the DV. This is most clearly recognized by statistical methodologists in randomized experiments or randomized controlled trials, but is frequently misunderstood by non-statistician investigators.</p><p>If a covariate is correlated (especially if it is strongly correlated) with the outcome of interest but uncorrelated with (orthogonal to in linear models) the IV (e.g. treatment assignment in a randomized experiment), then controlling for that covariate reduces residual variance in the DV without affecting the parameter estimate for the association or effect of the IV with the DV. Unless the sample size is extremely small such that the loss of a degree of freedom by including the covariate in the analysis makes an important difference (again, it rarely will in observational studies of any size), then this increases power, often quite substantially, by reducing the residual variance and thereby lowering the denominator of the F-statistic in a regression or ANOVA context or related statistics with other testing. Omission of orthogonal covariates has been well described in the literature (<xref ref-type="bibr" rid="bib4">Allison et al., 1997</xref>; <xref ref-type="bibr" rid="bib3">Allison, 1995</xref>). Although omission of orthogonal covariates is ‘cleanest and clearest’ in the context of randomized experiments, conditions may prevail in observational studies in which a variable is strongly related to the DV but minimally related to the IV or exposure of interest.</p><p>Such covariates are ideal to help the investigator explore his or her hypothesis, or better yet, to formally test them with frequentist significance testing methods. Doing so will increase statistical power and precision of estimation (i.e. reduced confidence intervals on the estimated associations or effects of interest).</p></sec><sec id="s5-2"><title>How to avoid misperception 4</title><p>When conducting an analysis, it is important to base the decision to control for covariates on the scientific knowledge of the problem at hand, rather than solely on the desire for a powerful test. Researchers should keep in mind that the main purpose of adjusting for covariates is to eliminate any influence of PBCs that may distort the estimate of the desired effect. To finish, we also note that including too many variables in the model can be detrimental because one runs the risk of inducing excessive multicollinearity and overfitting.</p></sec></sec><sec id="s6"><title>Misperception 5 (two parts)</title><sec id="s6-1"><title>Misperception 5 a. If when controlling for <italic>X</italic> and <italic>Z</italic> simultaneously in a statistical model as predictors of an outcome <italic>Y</italic>, <italic>X</italic> is significant with <italic>Z</italic> in the model, but <italic>Z</italic> is not significant with <italic>X</italic> in the model, then <italic>X</italic> is a ‘better’ predictor than <italic>Z</italic></title><sec id="s6-1-1"><title>Why misperception 5a occurs</title><p>Investigators may also incorrectly conclude that <italic>X</italic> has a true causal effect on <italic>Y</italic> and that <italic>Z</italic> does not, that <italic>X</italic> has a stronger causal effect on <italic>Y</italic> than does <italic>Z</italic>, or that <italic>Z</italic> may have a causal effect on <italic>Y</italic> but only through <italic>X</italic> as a mediating variable. None of the above conclusions necessarily follow from the stated conditions. An example of a context in which these misperceptions occur was discussed recently in a podcast in which the interlocutors considered the differential associations or effects of muscle size versus muscle strength on longevity in humans (<xref ref-type="bibr" rid="bib11">Attia, 2022</xref>). After cogently and appropriately noting the limitations of observational research in general and in the observational study under consideration in particular, the discussants pointed out that when a statistical model was used in which both muscle size and muscle strength measurements were included at the same time, muscle size was not a significant predictor of mortality rate conditional upon muscle strength, but muscle strength was a significant predictor of mortality rate conditional upon muscle size. The discussants thus tentatively concluded that muscle strength had a causal effect on longevity and that muscle size either had no causal effect, conditional upon muscle strength, or had a lesser causal effect.</p><p>While the discussants’ conclusions may be entirely correct, as the philosophers of science say, the data are underdetermined by the hypotheses. That is, the data are consistent with the discussants’ interpretation, but that interpretation is not the only one with which the data are consistent. Therefore, the data do not definitively demonstrate the correctness of the discussants' tentative conclusions. There are alternative possibilities. In <xref ref-type="fig" rid="fig1">Figure 1</xref>, we show two DAGs consistent with the discussants’ conclusions. Yet they imply a completely different causal association between X and Y. <xref ref-type="fig" rid="fig1">Figure 1a</xref> is a simple DAG and agrees with the discussants’ conclusion. <xref ref-type="fig" rid="fig1">Figure 1b</xref> also agrees with the discussants’ conclusion, but X has no causal relationship with Y (no arrows). Yet, in some settings and some level of correlation between X and Z, X appears significant in a regression model with Z<sup>’</sup> included in the model in lieu of Z.</p><fig id="fig1" position="float"><label>Figure 1.</label><caption><title>Agree (a) vs. disagree (b) with the interpretation of Misperception 5a.</title><p>Demonstrates a nonlinear and non-monotonic association between body mass index (BMI) and mortality among U.S. adults aged 18–85 years old. This figure suggests that BMI ranging between 23–26 kg/m<sup>2</sup> formed the nadir of the curve with the best outcome while persons with BMI levels below or above the nadir of the curve experienced increased mortality on average. Source: (<xref ref-type="bibr" rid="bib49">Fontaine et al., 2003</xref>).</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-82268-fig1-v1.tif"/></fig><p>First, there is tremendous collinearity between muscle mass and muscle strength. Given that almost all the pertinent human studies have non-experimental designs, the collinearity makes it especially difficult to determine whether there is cause and effect here and, if so, which of the two variables has a greater effect. With such strong multicollinearity between the strength and the mass measurements, any differential measurement error could make it appear that the more reliably measured variable had a greater causal effect over the less reliably measured variable, even if the opposite were true. Similarly, any differential nonlinearity of the effects of one of the two variables on the outcome relative to the others, if not effectively captured in the statistical modeling, could lead one variable to appear more strongly associated or effective than the other. In fact, the variable may just be more effectively modeled in this statistical procedure because of its greater linearity or greater conformity of its nonlinear pattern to the nonlinear model fit. We note that variance inflation factors are often used to diagnose multicollinearity in regressions.</p><p>Finally, even in linearly related sets of variables, the power to detect an association between a postulated cause and a postulated effect is highly dependent on the degree of variability in the causal factor in the population. If the variance were to be increased, the significance of the relationship would likely be accentuated. Thus, without an understanding of the measurement properties, the variability in the population, the variability which could exist in the population, and the causal structure among the variables, such analyses can only indicate hypotheses that are provisionally consistent with the data. Such analyses do not demonstrate that one variable does or does not definitively have a greater causal effect than the other or that one variable has a causal effect and the other variable does not. Note, regression coefficients within a model can be tested for equivalence in straightforward manners. Tests for non-trivial (non-zero) equivalence of some regression parameters can be done when it makes sense. In the linear regression model, testing for equivalence between parameters amounts to comparing the reduction in the sum of square error between a larger (in terms of number of parameters) model and a smaller model (with selected parameters constrained to be equal) relative to the large model sum of squares. The test then has an F distribution from which we can obtain the critical values and compute the p value (<xref ref-type="bibr" rid="bib89">Neter et al., 1996</xref>).</p></sec><sec id="s6-1-2"><title>How to avoid misperception 5a</title><p>Researchers should ensure that the variables to be adjusted for in the model are not too correlated to avoid multicollinearity issues. Variance inflation (VIF) tests available in most statistical software can be used to diagnose the presence of multicollinearity. Additionally, if measurement error or low covariate reliability is suspected, measurement error correction should be considered if possible.</p></sec></sec><sec id="s6-2"><title>Misperception 5b. Controlling for the linear effect of a covariate is equivalent to controlling for the covariate</title><sec id="s6-2-1"><title>Why misperception 5b occurs</title><p>This assumption is not necessarily true because the relationships between some variables can be nonlinear. Thus, if one controls for only the linear term (which is typical) of a quantitative variable, say <italic>Z</italic>, as a PBC, then one does not effectively control for all the variance and potential bias induced by <italic>Z</italic>. The extent to which any residual bias in <italic>Y</italic> due to controlling <italic>Z</italic> only in its linear effects or association may be large or small depending on the degree of nonlinearity involved. In practice, much nonlinearity is monotonic. However, this is not true in all cases. For many risk factors such as body mass index (BMI), cholesterol, and nutrient intakes like sodium, there are often U-shaped (or more accurately concave upward) relationships in which persons with intermediate levels have the best outcomes and persons with covariate levels below or above the nadir of the curve have poorer outcomes, on average. An example of the nonlinear and non-monotonous relationship between BMI (the explanatory variable) and mortality (the outcome variable) is illustrated in <xref ref-type="fig" rid="fig2">Figure 2</xref>; <xref ref-type="bibr" rid="bib49">Fontaine et al., 2003</xref>. In this example, mortality was treated as a time-to-event outcome modeled via survival analysis. This relationship has often been demonstrated to be U- or J-shaped (<xref ref-type="bibr" rid="bib49">Fontaine et al., 2003</xref>; <xref ref-type="bibr" rid="bib47">Flegal et al., 2007</xref>; <xref ref-type="bibr" rid="bib46">Flegal et al., 2005</xref>; <xref ref-type="bibr" rid="bib94">Pavela et al., 2022</xref>). Thus, when BMI is modeled linearly, the estimates will likely be potentially highly biased compared to when it is non-linearly modeled.</p><fig id="fig2" position="float"><label>Figure 2.</label><caption><title>Association between body mass index and hazard ratio for death among U.S. adults aged 18–85 years old.</title></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-82268-fig2-v1.tif"/></fig></sec></sec><sec id="s6-3"><title>How to avoid misperception 5b</title><p>It is important that one assesses for residual relationships (the relationships between nonlinear functions of <italic>Z</italic> and the model residuals after controlling for a linear function of <italic>Z</italic>) or chooses to allow for nonlinearity from the onset of the analysis. Nonlinearity can be accommodated through models that are nonlinear in the parameters (e.g. having parameters be exponents on the covariates) (<xref ref-type="bibr" rid="bib85">Meloun and Militký, 2011</xref>; <xref ref-type="bibr" rid="bib7">Andersen, 2009</xref>) or through use of techniques like the Box-Tidwell method transformations (<xref ref-type="bibr" rid="bib9">Armstrong, 2017</xref>), splines (<xref ref-type="bibr" rid="bib106">Schmidt et al., 2013</xref>; <xref ref-type="bibr" rid="bib91">Oleszak, 2019</xref>), knotted regressions (<xref ref-type="bibr" rid="bib71">Holmes and Mallick, 2003</xref>), categorical values (although see the next section for caveats around course categorization) (<xref ref-type="bibr" rid="bib100">Reed Education, 2021</xref>), or good old-fashioned polynomials (<xref ref-type="bibr" rid="bib91">Oleszak, 2019</xref>; <xref ref-type="bibr" rid="bib100">Reed Education, 2021</xref>; <xref ref-type="bibr" rid="bib66">Hastie et al., 2017</xref>) or in some cases factional polynomials (<xref ref-type="bibr" rid="bib105">Sauerbrei et al., 2020</xref>; <xref ref-type="bibr" rid="bib20">Binder et al., 2013</xref>; <xref ref-type="bibr" rid="bib103">Royston and Altman, 1994</xref>; <xref ref-type="bibr" rid="bib104">Royston and Sauerbrei, 2008</xref>).</p></sec></sec><sec id="s7"><title>Misperception 6. One should check whether covariates are normally distributed and take corrective action if not</title><sec id="s7-1"><title>Why misperception 6 occurs</title><p>This is not true. It is a common misperception that variables included in a parametric statistical model must be normally distributed. In fact, there is no requirement that any variable included in standard parametric regression or general linear models (<xref ref-type="bibr" rid="bib2">Allison et al., 1993</xref>), either as a predictor or as a DV, be normally distributed. What is embedded in the <italic>Gauss Markov Assumptions</italic> (<xref ref-type="bibr" rid="bib18">Berry, 1993</xref>), the assumptions of ordinary least-squares regression models (the models typically used in this journal), is that the residuals of the model be normally distributed. That is, the differences between the observed value of a DV for each subject and the predicted value of that DV from the model (and not any observed variable itself) are assumed to be normally distributed.</p><p>Moreover, this assumption about residuals applies only to the residuals of the DV. No assumption about the distribution of the predictor variables, covariates, or IV is made other than that they have finite mean and variance. Therefore, there is no need to assess the distributions of predictive variables, to take presumed corrective action if they are not normally distributed, or to suspect that the model is violated or biased if predictor variables are not normally distributed. One might be concerned with highly skewed or kurtotic covariates in that such distributions may contain extreme values, or outliers, that may serve as leverage points in the analysis, but that is a different issue. For an overview of outlier detection and the influence detection statistics best for managing concerns in this domain, see <xref ref-type="bibr" rid="bib50">Fox, 2019</xref>.</p></sec><sec id="s7-2"><title>How to avoid misperception 6</title><p>This misperception can be avoided by recalling that in the regression model, the analysis is done conditional on the IVs (or covariates), which are assumed to be fixed. Thus, their distributions are irrelevant in the analysis. However, it is required that the residuals be uncorrelated with the IVs.</p></sec></sec><sec id="s8"><title>Misperception 7. If the relation between a plausible confounder and the IV of interest is not <italic>statistically significant</italic>, the plausible confounder can be excluded with no concern for bias</title><p>In this misperception, the emphasis is on a relation that is <italic>not statistically significant</italic> instead of merely <italic>not related</italic>. This strategy is often implemented through stepwise regression techniques that are available in most statistical software. Statistical-significance-based criteria for including covariates can, if the predictor variable in question is actually a confounder (we rely on the word ‘confounder’ here for consistency with much of the scientific literature), lead to bias in both coefficient estimates and tests of statistical significance (<xref ref-type="bibr" rid="bib81">Maldonado and Greenland, 1993</xref>; <xref ref-type="bibr" rid="bib57">Greenland, 1989</xref>; <xref ref-type="bibr" rid="bib77">Lee, 2014</xref>). As Greenland has pointed out, this “too often leads to deletion of important confounders (false negative decisions)” (<xref ref-type="bibr" rid="bib58">Greenland, 2008</xref>). This is because the statistical-significance-based approach does not directly account for the actual degree of confounding produced by the variable in question.</p><sec id="s8-1"><title>Why misperception 7 occurs</title><p>There could be confusion in understanding the nature of the question asked when selecting a variable for its confounding potential and the question asked in usual statistical significance testing (<xref ref-type="bibr" rid="bib36">Dales and Ury, 1978</xref>). These two questions are fundamentally different. Even though a plausible confounder may not have a statistically significant association with the IV or the DV, or a statistically significant conditional association in the overall model, its actual association may still not be zero. That non-zero association in the population, even though not statistically significant in the sample, can still produce sufficient biases to allow false conclusions to occur at an inflated frequency. Additionally, a motivation for significance testing to select confounders may be to fit a more parsimonious final model in the large number of covariates and relatively modest sample size setting (<xref ref-type="bibr" rid="bib126">VanderWeele, 2019</xref>). That is, false-positive decisions (i.e. selecting a harmless nonconfounder) are considered more deleterious than false-negative decisions (deleting a true confounder). It has been argued that the opposite applies: deleting a true confounder is more deleterious than including a harmless nonconfounder. The reason is that deleting a true confounder introduces bias and is only justified if the action is worth the precision gained. Whereas, including a harmless nonconfounder reduces precision, which is the price of protection against confounding (<xref ref-type="bibr" rid="bib58">Greenland, 2008</xref>). We note that in not all circumstances is including a nonconfounder ‘harmless’ (<xref ref-type="bibr" rid="bib95">Pearl, 2011</xref>).</p></sec><sec id="s8-2"><title>How to avoid misperception 7</title><p>Selection of confounders may be best when relying on substantive knowledge informing judgments of plausibility, the knowledge gained from previous studies in which similar research questions were examined, or a priori hypotheses and expectations for relationships among variables. If a variable is plausibly a confounder, it should be included in the model regardless of its statistical significance. As an additional approach, one can conduct the analysis with and without the confounder as a form of sensitivity analysis (<xref ref-type="bibr" rid="bib125">VanderWeele and Ding, 2017</xref>; <xref ref-type="bibr" rid="bib102">Rosenbaum, 2002</xref>) and report the results of both analyses. Such an approach is often referred to as the approach of the wise data analyst, who is willing to settle for, as Tukey defines, “an approximate answer to the right question, which is often vague, [rather] than an exact answer to the wrong question, which can always be made precise” (<xref ref-type="bibr" rid="bib122">Tukey, 1962</xref>). We note that serious criticisms have been leveraged against the use of E-values in a sensitivity analysis as they tend to understate the residual confounding effect (<xref ref-type="bibr" rid="bib60">Greenland, 2020</xref>; <xref ref-type="bibr" rid="bib111">Sjölander and Greenland, 2022</xref>). However, attending to those critics is not within the scope of the current review.</p></sec></sec><sec id="s9"><title>Misperception 8. Analyzing the residuals of an analysis in which a DV is regressed on the PBC is equivalent to including the PBC in an overall statistical model with the IV of interest</title><sec id="s9-1"><title>Why misperception 8 occurs</title><p>This is untrue. As Maxwell pointed out several decades ago, the effects of analyzing residuals as opposed to including the PBC of interest in the model will depend on how those residuals are calculated (<xref ref-type="bibr" rid="bib82">Maxwell et al., 1985</xref>). As Maxwell puts it, ANOVA on residuals is not ANCOVA. Maxwell shows that if the residuals are calculated separately for different levels of the IV, bias may accrue in one direction. In contrast, if residuals are calculated for the overall sample, bias may accrue in a different manner.</p><p><italic>Although this conceptualization of an equivalence between the two procedures</italic> [ANOVA on residuals vs ANCOVA] <italic>may be intuitively appealing, it is mathematically incorrect. If residuals are obtained from the pooled within-groups regression coefficient (b<sub>w</sub>), an analysis of variance on the residuals results in an inflated a-level. If the regression coefficient for the total sample combined into one group (b<sub>T</sub>) is used, ANOVA on the residuals yields an inappropriately conservative test. In either case, analysis of variance of residuals fails to provide a correct test, because the significance test in analysis of covariance requires consideration of both b<sub>w</sub> and b<sub>T</sub>, unlike analysis of residuals</italic> (<xref ref-type="bibr" rid="bib82">Maxwell et al., 1985</xref>).</p><p>Notably, this procedure can introduce bias in the magnitude of the coefficients (effect sizes) characterizing the effects or associations of the IV of interest, and not just the test of statistical significance.</p></sec><sec id="s9-2"><title>How to avoid misperception 8</title><p>As Maxwell points out, there are ways to use residualization that do not permit these biases to occur. Hence, in some situations where models become so complex that residualizing for covariate effects beforehand makes the analysis that would otherwise be intractable tractable, this may be a reasonable approach. Nevertheless, additional concerns may emerge (<xref ref-type="bibr" rid="bib92">Pain et al., 2018</xref>) and under ordinary circumstances, it is best to include PBCs in the model instead of residualizing for them first outside the model.</p></sec></sec><sec id="s10"><title>Misperception 9. Excluding a covariate that is not associated with the outcome of interest does not affect the association of the IV with the outcome</title><sec id="s10-1"><title>Why misperception 9 occurs</title><p>This is referred to as the suppressor effect. Adenovirus 36 (Ad36) infection provides an example of a suppressor effect. Although Ad36 increases adiposity, which is commonly linked to impaired glucoregulatory function and negative lipid profiles, Ad36 infection surprisingly leads to improved glucoregulatory function and serum lipid profiles (<xref ref-type="bibr" rid="bib1">Akheruzzaman et al., 2019</xref>).</p><p>To illustrate the point, we set  <inline-formula><mml:math id="inf1"><mml:msub><mml:mrow><mml:mi>β</mml:mi></mml:mrow><mml:mrow><mml:mi>A</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> = 0.5, <inline-formula><mml:math id="inf2"><mml:msub><mml:mrow><mml:mi>β</mml:mi></mml:mrow><mml:mrow><mml:mi>B</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> = –0.24, <inline-formula><mml:math id="inf3"><mml:msub><mml:mrow><mml:mi>λ</mml:mi></mml:mrow><mml:mrow><mml:mi>A</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> = 0.8 and <inline-formula><mml:math id="inf4"><mml:msub><mml:mrow><mml:mi>λ</mml:mi></mml:mrow><mml:mrow><mml:mi>B</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> = 0.6 implying zero-order correlation between the intake of fats of type B and <italic>Y</italic> would be zero. Yet, by controlling for fats of type B in the model, we would obtain an unbiased estimate of the effect of fats of type A on <italic>Y</italic> as <inline-formula><mml:math id="inf5"><mml:msub><mml:mrow><mml:mi>β</mml:mi></mml:mrow><mml:mrow><mml:mi>A</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> , whereas if we did not control for fats of type B, we would mistakenly calculate the correlation between fats of type A and <italic>Y</italic> to be <inline-formula><mml:math id="inf6"><mml:msub><mml:mrow><mml:mi>λ</mml:mi></mml:mrow><mml:mrow><mml:mi>A</mml:mi></mml:mrow></mml:msub><mml:msub><mml:mrow><mml:mi>β</mml:mi></mml:mrow><mml:mrow><mml:mi>B</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> . This example demonstrates that failing to control for the suppressor variable, or the PBC that creates omitted variable bias, could result in a biased estimate of IV effects on the outcome, even when the suppressor variable has no correlation with the outcome. This disputes the premise that a covariate uncorrelated with the outcome cannot be biasing the results of an association test between another variable and the outcome as an indicator of a causal effect, thus undermining the original assumption. Whereas in the psychometrics literature, such patterns have commonly been termed <italic>suppressor effects</italic>, in a nutrition epidemiology paper they were referred to as <italic>negative confounders</italic> (<xref ref-type="bibr" rid="bib31">Choi et al., 2008</xref>). We provide both theoretical and empirical justifications for these observations in Appendix A in the supplementary text file.</p></sec><sec id="s10-2"><title>How to avoid misperception 9</title><p>This misperception is easily avoided if we refrain from only relying on marginal correlation to select covariates to include in the model and instead apply a backdoor criterion (<xref ref-type="bibr" rid="bib97">Pearl and Mackenzie, 2018</xref>) to help decide which variables to adjust for and which to not adjust for. Provided that the directed acyclic diagram (DAG) in <xref ref-type="fig" rid="fig3">Figure 3</xref> conforms to the true DAG, intake of fats B meets the backdoor criterion and must be adjusted for when estimating the effect of intake of fats, A on the outcome Y.</p><fig id="fig3" position="float"><label>Figure 3.</label><caption><title>Causal relationships of health outcome, dietary fat consumption, and the belief that consumption of dietary fat is not dangerous.</title><p>Direction of arrows represents causal directions and <italic>λ<sub>A</sub>, λ<sub>B</sub>, β<sub>A</sub></italic>, and <italic>β<sub>B</sub></italic> are structural coefficients.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-82268-fig3-v1.tif"/></fig><p><xref ref-type="fig" rid="fig3">Figure 3</xref> shows a simple causal model. On the left side of the figure is a variable representing an individual’s belief about the danger of dietary fat consumption. This belief affects their consumption of two types of fats, A and B. Fat type A is harmful and has a negative impact on health, while fat type B has a positive effect and improves health outcomes. The Greek letters on the paths indicate the causal effects in the model. Without loss of generality, we assume all variables have been standardized to have a variance of 1.0. From the rules of path diagrams (<xref ref-type="bibr" rid="bib6">Alwin and Hauser, 1975</xref>; <xref ref-type="bibr" rid="bib22">Bollen, 1987</xref>; <xref ref-type="bibr" rid="bib30">Cheong and MacKinnon, 2012</xref>), we can calculate the correlations between <italic>Y</italic> and intake of fats of type B to be <inline-formula><mml:math id="inf7"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>ρ</mml:mi><mml:mrow><mml:mi>Y</mml:mi><mml:mi>B</mml:mi><mml:mo>=</mml:mo><mml:msub><mml:mi>β</mml:mi><mml:mrow><mml:mi>B</mml:mi></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mi>λ</mml:mi><mml:mrow><mml:mi>B</mml:mi></mml:mrow></mml:msub><mml:msub><mml:mi>λ</mml:mi><mml:mrow><mml:mi>A</mml:mi></mml:mrow></mml:msub><mml:msub><mml:mi>β</mml:mi><mml:mrow><mml:mi>A</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula>. This correlation is zero when <inline-formula><mml:math id="inf8"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>λ</mml:mi><mml:mrow><mml:mi>A</mml:mi></mml:mrow></mml:msub><mml:msub><mml:mi>λ</mml:mi><mml:mrow><mml:mi>B</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mo>−</mml:mo><mml:msub><mml:mi>β</mml:mi><mml:mrow><mml:mi>B</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:msub><mml:mi>β</mml:mi><mml:mrow><mml:mi>A</mml:mi></mml:mrow></mml:msub></mml:mfrac></mml:mrow></mml:mstyle></mml:math></inline-formula>.</p></sec></sec><sec id="s11"><title>Misperception 10. If a plausible confounding variable is one that has a bivariate unadjusted correlation of zero with the IV, then it does not create bias in the association of the IV with the outcome</title><sec id="s11-1"><title>Why misperception 10 occurs</title><p>This misperception is based on the same premises as stated above but manifests differently. Let us replace ‘confounding variable’ with ‘PBC,’ which we defined earlier. For Misperception 10, the presumption is that a PBC, if not properly included and controlled for in the design or analysis, will only bias the extent to which the association between the IV and the DV represents the cause or effect of the IV on the DV if the PBC is related to <italic>both</italic> the IV and the DV.</p><p>Under those assumptions, if we consider a PBC and find that it is one that has a bivariate unadjusted correlation of zero with the IV, then it cannot be creating bias. Yet, this is not true. Multiple circumstances could produce a pattern of results in which a biasing variable has a correlation of zero, as well as no nonlinear association with the outcome, and yet creates a bias if not properly accommodated by design or analysis. Moreover, there may be circumstances in which statistically adjusting for a variable does not reduce the bias even though in other circumstances such adjustment would. Consider the causal model depicted in <xref ref-type="fig" rid="fig4">Figure 4</xref>, which follows the same notational conventions as <xref ref-type="fig" rid="fig3">Figure 3</xref>.</p><fig id="fig4" position="float"><label>Figure 4.</label><caption><title>Causal relationships of outcome, covariate, and potentially biasing covariate (PBC).</title><p>Direction of arrows represents causal directions and <italic>λ<sub>z</sub>,</italic> α<italic><sub>z</sub>,</italic> α<italic><sub>x</sub>, β<sub>z</sub></italic>, and <italic>βx</italic> are structural coefficients. The error terms e1 and e2 have variances chosen so Y1 and Y2 have variances 1 (see the Appendices for more details).</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-82268-fig4-v1.tif"/></fig><p>In this case, both <italic>X</italic> and <italic>Z</italic> have a causal effect on <italic>Y</italic><sub>1</sub>. <italic>Y</italic><sub>1</sub> can then be referred to as a ‘collider’ (see Glossary). It is well established that conditioning on a collider will alter the association between joint causes of it. Most often, collider bias is discussed in terms of creating associations. For example, in the figure shown here, if <italic>Z</italic> and <italic>X</italic> were not correlated, but both caused increases in <italic>Y</italic><sub>1</sub>, then conditioning on (i.e. ‘controlling for’) <italic>Y</italic><sub>1</sub> would create a positive or negative correlation between <italic>X</italic> and <italic>Z</italic>. However, as <xref ref-type="bibr" rid="bib86">Munafò et al., 2018</xref> explain, collider bias need not simply create associations, but can also reduce or eliminate associations: “Selection can induce collider bias… which can lead to biased observational… associations. This bias can be towards or away from any true association, and can distort a true association or a true lack of association.”</p><p>In <xref ref-type="fig" rid="fig4">Figure 4</xref> Appp, there is an association between <italic>X</italic> and <italic>Z</italic>, and <italic>Z</italic> would be the PBC (confounding variable in conventional terminology) of the relationship between <italic>X</italic> and <italic>Y</italic><sub>1</sub> and <italic>Y</italic><sub>2</sub>. But, if we set up the coefficients to have certain values, selecting on <italic>Y</italic><sub>1</sub> (for example, by studying only people with diagnosed hypertension defined as a systolic blood pressure greater than 140 mm Hg) could actually drive the positive association between <italic>X</italic> and <italic>Z</italic> to zero. Specifically, for these coefficient values [β<sub>x</sub> = 0.1857, , β<sub>z</sub> = 0.8175, λ<sub>z</sub> = 0.4, α<sub>x</sub> = 0.0, α<sub>x</sub> = 0.6], if all variables were normally distributed (in the derivation in Appendix 2, we assume that all variables have a joint multivariate normal distribution. Whether this applies to cases in which the data are not multivariate normal is not something we have proven one way or another). with mean zero and standard deviation 1 (this would be after standardization of the variables), then using a cutoff of approximately 1.8276 standard deviations above the mean of <italic>Y</italic><sub>1</sub> would cause the correlation in that subsample between <italic>X</italic> and <italic>Z</italic> to be zero (<xref ref-type="bibr" rid="bib10">Arnold and Beaver, 2000</xref>; <xref ref-type="bibr" rid="bib13">Azzalini and Capitanio, 2013</xref>).</p><p>Furthermore, let us assume that all the relations in this hypothetical circumstance are linear. This can include linear relationships of zero, but no nonlinear or curved relationships. Here, when we control for the PBC Z in the selected sample of persons with hypertension, it will have no effect on the estimated slope of the regression of <italic>Y</italic><sub>2</sub> on <italic>X</italic>. The collider bias has altered the association between <italic>Z</italic> and <italic>X</italic> such that controlling for <italic>Z</italic> in a conventional statistical model, i.e., an ordinary least-squares linear regression, no longer removes the bias. And yet, the bias is there. We justify this through mathematical arguments along with a small simulation to elucidate the manifestation of this misperception in Appendix 2.</p><p>More sophisticated models involving missing data approaches and other approaches could also be brought to bear (<xref ref-type="bibr" rid="bib62">Groenwold et al., 2012</xref>; <xref ref-type="bibr" rid="bib130">Yang et al., 2019</xref>; <xref ref-type="bibr" rid="bib61">Greenwood et al., 2006</xref>), but this simple example shows that just because a PBC has no association with a postulated IV (i.e. cause), this does not mean that the variable cannot be creating bias (confounding) in the estimated relationship between the postulated IV and the postulated result or outcome. In the end, as Pedhazur put it, quoting Fisher, “If…we choose a group of social phenomena with no antecedent knowledge of the causation or the absence of causation among them, then the calculation of correlation coefficients, total or partial, will not advance us a step towards evaluating the importance of the causes at work…In no case, however, can we judge whether or not it is profitable to eliminate a certain variate unless we know, or are willing to assume, a qualitative scheme of causation” (<xref ref-type="bibr" rid="bib44">Fisher, 1970</xref>).</p><p>In the end, there is no substitute for either randomization or, at a minimum, informed argument and assumptions about the causal structure among the variables. No simple statistical rule will allow one to decide whether a covariate or its exclusion is or is not creating bias.</p></sec><sec id="s11-2"><title>How to avoid misperception 10</title><p>Selecting or conditioning on a collider can bias estimated effects in unforeseeable ways. Given a causal DAG, the use of the backdoor criterion can help the analyst identify variables that can safely be adjusted for and those that can bias (confound) the effect estimate of interest. In <xref ref-type="fig" rid="fig4">Figure 4</xref>, for example, Y<sub>1</sub> does not meet the backdoor criterion from Y<sub>2</sub> to X, and adjusting for it or selecting on it will bias the estimate of the effect estimate.</p></sec></sec><sec id="s12"><title>Misperception 11. The method used to control for a covariate can be assumed to have been chosen appropriately and other methods would not, on average, produce substantially different results</title><p>This is, in essence, a statement of the unbiasedness of an analytic approach. By this we mean that the method of controlling for the covariate is not chosen, intentionally or unintentionally, to achieve a particular study finding, and that the answer obtained does not deviate from the answer one would get if one optimally controlled for the covariate. By ‘optimally controlled,’ we mean using a method that would eliminate or reduce to the greatest extent possible any effects of not controlling for the covariate and that is commensurate with the stated goals of the analysis (which is more important than the interests of the investigator).</p><p>Unfortunately, we have substantial evidence from many sources that many investigators instead choose analytical approaches, including the treatment of covariates, that serve their interests (e.g. <xref ref-type="bibr" rid="bib67">Head et al., 2015</xref>; <xref ref-type="bibr" rid="bib129">Wicherts et al., 2016</xref>; <xref ref-type="bibr" rid="bib25">Bruns and Ioannidis, 2016</xref>). Conventionally, this is termed ‘p-hacking’ (<xref ref-type="bibr" rid="bib109">Simonsohn et al., 2014</xref>), ‘investigator degrees of freedom’ (<xref ref-type="bibr" rid="bib108">Simmons et al., 2011</xref>), ‘taking the garden of forking paths’ (<xref ref-type="bibr" rid="bib52">Gelman and Loken, 2013</xref>), and so on. If such methods are used, that is, if investigators try multiple ways of controlling for which, how many, or form of covariates until they select the one that produces the results most commensurate with those they wish for, the results will most certainly be biased (<xref ref-type="bibr" rid="bib115">Sturman et al., 2022</xref>; <xref ref-type="bibr" rid="bib76">Kavvoura et al., 2007</xref>; <xref ref-type="bibr" rid="bib16">Banks et al., 2016</xref>; <xref ref-type="bibr" rid="bib90">O’Boyle et al., 2017</xref>; <xref ref-type="bibr" rid="bib108">Simmons et al., 2011</xref>; <xref ref-type="bibr" rid="bib32">Christensen et al., 2021</xref>; <xref ref-type="bibr" rid="bib113">Stefan and Schönbrodt, 2022</xref>; <xref ref-type="bibr" rid="bib12">Austin and Brunner, 2004</xref>).</p><sec id="s12-1"><title>Why misperception 11 occurs</title><p>To our knowledge, surveys do not exist describing the extent to which authors are aware of the consequences of intentionally choosing and reporting models that control for covariates to obtain a certain result. Some evidence exists, however, that suggests authors do sometimes intentionally select covariates to achieve statistical significance, such as a survey by Banks et al. of active management researchers (<xref ref-type="bibr" rid="bib16">Banks et al., 2016</xref>). O’Boyle et al. observed changes in how control variables were used in journal articles compared with dissertations of the same work, with the final publications reporting more statistically significant findings than the dissertations (<xref ref-type="bibr" rid="bib90">O’Boyle et al., 2017</xref>). Research on the motivations of these practices may help to focus preventive interventions.</p></sec><sec id="s12-2"><title>How to avoid misperception 11</title><p>This concern with <italic>P</italic>-hacking is one of the major impetuses behind those in our field encouraging investigators in observational studies to preregister their analyses (; <xref ref-type="bibr" rid="bib37">Dal Ré et al., 2014</xref>). Many steps in the model-building process could consciously or unconsciously influence the probability of type I error, from the conceptualization of the research question (e.g. the quality of prior literature review, discussions with collaborators and colleagues that shape modeling choices), to any prior or exploratory analysis using that dataset, or to the numerous analytical decisions in selecting covariates, selecting their forms, accounting for missing data, and so on. Future theoretical and empirical modeling is needed to inform which decisions have the least likelihood of producing biased findings.</p><p>However, that is not to say that investigators should not limit their flexibility in each of these steps, engage in exploratory analyses, or change their minds after the fact—or that we do not do that ourselves. But this should be disclosed so that the reader can make an informed decision about what the data and results mean. Within our group, we often say colloquially, we are going to analyze the heck out of these data and try many models, but then we are then going to disclose this to the reader. Indeed, transparency is often lacking for how the inclusion or form of adjustment is determined in observational research (<xref ref-type="bibr" rid="bib78">Lenz and Sahn, 2021</xref>). In situations where authors want to explore how covariate selection flexibility may affect results, so-called multiverse-style methods (<xref ref-type="bibr" rid="bib112">Steegen et al., 2016</xref>) (also called vibration of effects <xref ref-type="bibr" rid="bib93">Patel et al., 2015</xref>) or specification curve analysis (<xref ref-type="bibr" rid="bib110">Simonsohn et al., 2020</xref>) can be used, although careful thought is needed to ensure such analyses do not also produce misleading conclusions (<xref ref-type="bibr" rid="bib40">Del Giudice and Gangestad, 2021</xref>).</p></sec></sec><sec id="s13"><title>Misperception 12. p values derived from implementing statistical methods incorporating covariates mean exactly what they appear to mean and can be interpreted at face value</title><sec id="s13-1"><title>Why misperception 12 occurs</title><p>This is not necessarily true. An article from many years ago discusses the problem of a reproducible ‘Six Sigma’ finding from physics (<xref ref-type="bibr" rid="bib79">Linderman et al., 2003</xref>). A Six Sigma finding is simply a finding whose test statistic is six or more standard deviations from the expectation under the null hypothesis. Six Sigma findings should be indescribably rare based on known probability theory (Actually, they are exactly describably rare and should occur, under the null hypothesis, 10e-10 proportion of the time.). However, it seems that all too often, Six Sigma findings, even in what might be seen as a mature science like physics, are regularly overturned (<xref ref-type="bibr" rid="bib65">Harry and Schroeder, 2005</xref>; <xref ref-type="bibr" rid="bib38">Daniels, 2001</xref>). Why is this? There are likely multiple reasons, but one is plausible that the assumptions made about the measurement properties of the data, the distributions of the data, and the performance of the test statistics under violations of their pure assumptions were not fully understood or met (<xref ref-type="bibr" rid="bib63">Hanin, 2021</xref>). This issue involving violations of assumptions of statistical methods (<xref ref-type="bibr" rid="bib59">Greenland et al., 2016</xref>) may be especially important when dealing with unusually small alpha levels (i.e. significance levels) (<xref ref-type="bibr" rid="bib15">Bangalore et al., 2009</xref>). This is because a test statistic that is highly robust to even modest or large violations of some assumptions at higher alpha levels such as 0.05 may be highly sensitive to even small violations of assumptions at much smaller alpha levels, such as those used with Six Sigma results in physics. Another example is with the use of multiple testing ‘corrections’ in certain areas like genetic epidemiology with genome-wide association testing in nutrition and obesity research, where significance levels of 10e-8 are commonly used and p values far, far lower than that are not infrequently reported.</p></sec><sec id="s13-2"><title>How to avoid misperception 12</title><p>In short, robustness at one significance level does not necessarily imply robustness at a different significance level. Independent replication not only takes into account purely stochastic sources of error but also potentially allows one to detect the inadvertent biasing effects of other unknown and unspecifiable factors beyond stochastic variation.</p></sec></sec><sec id="s14" sec-type="discussion"><title>Discussion</title><p>We have discussed 12 issues involving the use of covariates. Although our description of each misperception is mostly done in a linear model setting, we note that these issues also remain in the nonlinear model. We hope that our attention to these issues will help readers better understand how to most effectively control for potential biases, without inducing further biases, by choosing how and when to include certain covariates in the design and analysis of their studies. We hope the list is helpful, but we wish to note several things. First, the list of issues we provide is not exhaustive. No single source, that we are aware of, will necessarily discuss them all, but some useful references exist (<xref ref-type="bibr" rid="bib33">Cinelli et al., 2020</xref>; <xref ref-type="bibr" rid="bib53">Gelman et al., 2020</xref>; <xref ref-type="bibr" rid="bib42">Ding and Miratrix, 2015</xref>). Second, by pointing out a particular analytical approach or solution, we do not mean to imply that these are the only analytic approaches or solutions available today or that will exist in the future. For example, we have not discussed the Bayesian approach much. Bayesian approaches differ from their non-Bayesian counterparts in that the researcher first posits a model describing how observable and unobservable quantities are interrelated, which is often done via a graph. Many of the misconceptions detailed here are related to covariate selection bias and omitted or missing covariates bias, which can be corrected for in a Bayesian analysis provided it is known how the unobserved variables are related to other model terms (see (<xref ref-type="bibr" rid="bib84">McElreath, 2020</xref>) for an accessible and concise introduction to Bayesian analysis and its computation aspects). Third, most of the misconceptions discussed here and ways to avoid them have a direct connection with causal inference. Namely, assuming a DAG depicting the data-generating process, we can use the front-door or front-door criterion derived from the do-calculus framework of <xref ref-type="bibr" rid="bib97">Pearl and Mackenzie, 2018</xref>; <xref ref-type="bibr" rid="bib96">Pearl et al., 2016</xref>. Determination of the adjusting set in a DAG can sometimes be challenging, especially in larger DAGs. The freely available web application dagitty (<ext-link ext-link-type="uri" xlink:href="https://www.dagitty.net/">https://www.dagitty.net/</ext-link>) allows users to specify their DAGs and the application provides the set of controlling variables (<xref ref-type="bibr" rid="bib120">Textor et al., 2016</xref>).</p><p>We encourage readers to seek the advice of professional statisticians in designing and analyzing studies around these issues. Furthermore, it is important to recognize that no one statistical approach to the use or nonuse of any particular covariate or set of covariates in observational research will guarantee that one will obtain the ‘right’ answer or an unbiased estimate of some parameter without demanding assumptions. There is no substitute for the gold standard of experimentation: strictly supervised double-blind interventional experiments with random selection and random assignment. This was aptly illustrated in a study by <xref ref-type="bibr" rid="bib43">Ejima et al., 2016</xref>. This does not mean that one should not try to estimate associations or causal effects in observational research. Indeed, as Hernán effectively argues (<xref ref-type="bibr" rid="bib69">Hernán, 2018</xref>), we should not be afraid of causation. When we do much observational research, we are interested in estimating causal effects. But we must be honest: what we are actually estimating is associations, and we can then discuss the extent to which those estimates of associations may represent causal effects. Our ability to rule out competing explanations for the associations observed, other than causal effects, strengthens the argument that the associations may represent causal effects, and that is where the wise use of covariates comes in. But such arguments used with covariates do not demonstrate causal effects, they merely make more or less plausible in the eyes of the beholder that an association does or does not represent causation. In making such arguments, as cogently noted on the value of epistemic humility and how to truly enact it, “Intellectual humility requires more than cursory statements about these limitations; it requires taking them seriously and limiting our conclusions accordingly” (<xref ref-type="bibr" rid="bib70">Hoekstra and Vazire, 2021</xref>). That is, consideration of arguments about the plausibility of causation from association should not be given in such a way as to convince the reader, but rather to truly give a fair and balanced consideration of the notion that an association does or does not represent a particular causal effect. As Francis Bacon famously said, “Read not to contradict and confute; nor to believe and take for granted; nor to find talk and discourse; but to weigh and consider” (<xref ref-type="bibr" rid="bib14">Bacon, 2022</xref>).</p><sec id="s14-1"><title>Data availability</title><p>All data generated or analyzed during this study are included in the manuscript and supplementary files; R studio software used for the description and illustration of misperception 5 a, misperception 9 and misperception 10 are publicly available on GitHub.</p></sec></sec></body><back><sec sec-type="additional-information" id="s15"><title>Additional information</title><fn-group content-type="competing-interest"><title>Competing interests</title><fn fn-type="COI-statement" id="conf1"><p>No competing interests declared</p></fn></fn-group><fn-group content-type="author-contribution"><title>Author contributions</title><fn fn-type="con" id="con1"><p>Investigation, Writing – original draft, Writing – review and editing</p></fn><fn fn-type="con" id="con2"><p>Investigation, Writing – original draft, Writing – review and editing</p></fn><fn fn-type="con" id="con3"><p>Writing – original draft</p></fn><fn fn-type="con" id="con4"><p>Writing – original draft</p></fn><fn fn-type="con" id="con5"><p>Writing – original draft</p></fn><fn fn-type="con" id="con6"><p>Writing – original draft, Writing – review and editing</p></fn><fn fn-type="con" id="con7"><p>Writing – original draft, Writing – review and editing</p></fn><fn fn-type="con" id="con8"><p>Writing – original draft, Writing – review and editing</p></fn><fn fn-type="con" id="con9"><p>Writing – original draft</p></fn><fn fn-type="con" id="con10"><p>Writing – original draft, Writing – review and editing</p></fn><fn fn-type="con" id="con11"><p>Investigation, Writing – original draft, Project administration, Writing – review and editing</p></fn></fn-group></sec><ack id="ack"><title>Acknowledgements</title><p>DBA and CJV are supported in part by NIH grants R25HL124208 and R25DK099080. RSZ is supported in part by NIH grant 1R01DK136994-01 and CDT is supported in part by NIH grant 1R01DK132385-01. The authors thank the following colleagues for critical comments on the manuscript: Boyi Guo, Joseph Kush, Cai Li, Sanjay Shete, Lehana Thabane, Ahmad Zia Wahdat, and Rafi Zad. Jennifer Holmes, ELS, provided medical editing and editorial assistance.</p></ack><ref-list><title>References</title><ref id="bib1"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Akheruzzaman</surname><given-names>M</given-names></name><name><surname>Hegde</surname><given-names>V</given-names></name><name><surname>Dhurandhar</surname><given-names>NV</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>Twenty-five years of research about adipogenic adenoviruses: a systematic review</article-title><source>Obesity Reviews</source><volume>20</volume><fpage>499</fpage><lpage>509</lpage><pub-id pub-id-type="doi">10.1111/obr.12808</pub-id><pub-id pub-id-type="pmid">30562840</pub-id></element-citation></ref><ref id="bib2"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Allison</surname><given-names>DB</given-names></name><name><surname>Gorman</surname><given-names>BS</given-names></name><name><surname>Primavera</surname><given-names>LH</given-names></name></person-group><year iso-8601-date="1993">1993</year><article-title>Some of the most common questions asked of statistical consultants: Our favorite responses and recommended readings</article-title><source>Genetic, Social, and General Psychology Monographs</source><volume>119</volume><fpage>153</fpage><lpage>185</lpage></element-citation></ref><ref id="bib3"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Allison</surname><given-names>DB</given-names></name></person-group><year iso-8601-date="1995">1995</year><article-title>When is it worth measuring a covariate in a randomized clinical trial?</article-title><source>Journal of Consulting and Clinical Psychology</source><volume>63</volume><fpage>339</fpage><lpage>343</lpage><pub-id pub-id-type="doi">10.1037//0022-006x.63.3.339</pub-id><pub-id pub-id-type="pmid">7608345</pub-id></element-citation></ref><ref id="bib4"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Allison</surname><given-names>DB</given-names></name><name><surname>Allison</surname><given-names>RL</given-names></name><name><surname>Faith</surname><given-names>MS</given-names></name><name><surname>Paultre</surname><given-names>F</given-names></name><name><surname>Pi-Sunyer</surname><given-names>FX</given-names></name></person-group><year iso-8601-date="1997">1997</year><article-title>Power and money: designing statistically powerful studies while minimizing financial costs</article-title><source>Psychological Methods</source><volume>2</volume><fpage>20</fpage><lpage>33</lpage><pub-id pub-id-type="doi">10.1037//1082-989X.2.1.20</pub-id></element-citation></ref><ref id="bib5"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Altman</surname><given-names>DG</given-names></name><name><surname>Bland</surname><given-names>JM</given-names></name></person-group><year iso-8601-date="1994">1994</year><article-title>Quartiles, quintiles, centiles, and other quantiles</article-title><source>BMJ</source><volume>309</volume><elocation-id>996</elocation-id><pub-id pub-id-type="doi">10.1136/bmj.309.6960.996</pub-id><pub-id pub-id-type="pmid">7950724</pub-id></element-citation></ref><ref id="bib6"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Alwin</surname><given-names>DF</given-names></name><name><surname>Hauser</surname><given-names>RM</given-names></name></person-group><year iso-8601-date="1975">1975</year><article-title>The decomposition of effects in path analysis</article-title><source>American Sociological Review</source><volume>40</volume><elocation-id>37</elocation-id><pub-id pub-id-type="doi">10.2307/2094445</pub-id></element-citation></ref><ref id="bib7"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Andersen</surname><given-names>R</given-names></name></person-group><year iso-8601-date="2009">2009</year><article-title>Nonparametric methods for modeling nonlinearity in regression analysis</article-title><source>Annual Review of Sociology</source><volume>35</volume><fpage>67</fpage><lpage>85</lpage><pub-id pub-id-type="doi">10.1146/annurev.soc.34.040507.134631</pub-id></element-citation></ref><ref id="bib8"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Arlen</surname><given-names>J</given-names></name><name><surname>Tontrup</surname><given-names>S</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>Does the endowment effect justify legal intervention? the debiasing effect of institutions</article-title><source>The Journal of Legal Studies</source><volume>44</volume><fpage>143</fpage><lpage>182</lpage><pub-id pub-id-type="doi">10.1086/680991</pub-id></element-citation></ref><ref id="bib9"><element-citation publication-type="web"><person-group person-group-type="author"><name><surname>Armstrong</surname><given-names>D</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>Regression III lecture 4: linearity diagnostics</article-title><ext-link ext-link-type="uri" xlink:href="https://quantoid.net/files/reg3/lecture4_2017.pdf">https://quantoid.net/files/reg3/lecture4_2017.pdf</ext-link><date-in-citation iso-8601-date="2018-03-09">March 9, 2018</date-in-citation></element-citation></ref><ref id="bib10"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Arnold</surname><given-names>BC</given-names></name><name><surname>Beaver</surname><given-names>RJ</given-names></name></person-group><year iso-8601-date="2000">2000</year><article-title>Hidden truncation models</article-title><source>Sankhyā: The Indian Journal of Statistics, Series A</source><volume>01</volume><fpage>23</fpage><lpage>35</lpage></element-citation></ref><ref id="bib11"><element-citation publication-type="web"><person-group person-group-type="author"><name><surname>Attia</surname><given-names>P</given-names></name></person-group><year iso-8601-date="2022">2022</year><article-title>Peter Attia</article-title><ext-link ext-link-type="uri" xlink:href="https://peterattiamd.com/ama27/">https://peterattiamd.com/ama27/</ext-link><date-in-citation iso-8601-date="2022-04-23">April 23, 2022</date-in-citation></element-citation></ref><ref id="bib12"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Austin</surname><given-names>PC</given-names></name><name><surname>Brunner</surname><given-names>LJ</given-names></name></person-group><year iso-8601-date="2004">2004</year><article-title>Inflation of the type I error rate when a continuous confounding variable is categorized in logistic regression analyses</article-title><source>Statistics in Medicine</source><volume>23</volume><fpage>1159</fpage><lpage>1178</lpage><pub-id pub-id-type="doi">10.1002/sim.1687</pub-id><pub-id pub-id-type="pmid">15057884</pub-id></element-citation></ref><ref id="bib13"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Azzalini</surname><given-names>A</given-names></name><name><surname>Capitanio</surname><given-names>A</given-names></name></person-group><year iso-8601-date="2013">2013</year><source>The Skew-Normal and Related Families</source><publisher-name>Cambridge University Press</publisher-name><pub-id pub-id-type="doi">10.1017/CBO9781139248891</pub-id></element-citation></ref><ref id="bib14"><element-citation publication-type="web"><person-group person-group-type="author"><name><surname>Bacon</surname><given-names>F</given-names></name></person-group><year iso-8601-date="2022">2022</year><article-title>wikiquote</article-title><ext-link ext-link-type="uri" xlink:href="https://en.wikiquote.org/w/index.php?title=Francis_Bacon&amp;oldid=3028558">https://en.wikiquote.org/w/index.php?title=Francis_Bacon&amp;oldid=3028558</ext-link><date-in-citation iso-8601-date="2022-04-26">April 26, 2022</date-in-citation></element-citation></ref><ref id="bib15"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bangalore</surname><given-names>SS</given-names></name><name><surname>Wang</surname><given-names>J</given-names></name><name><surname>Allison</surname><given-names>DB</given-names></name></person-group><year iso-8601-date="2009">2009</year><article-title>How accurate are the extremely small p-values used in genomic research: an evaluation of numerical libraries</article-title><source>Computational Statistics &amp; Data Analysis</source><volume>53</volume><fpage>2446</fpage><lpage>2452</lpage><pub-id pub-id-type="doi">10.1016/j.csda.2008.11.028</pub-id><pub-id pub-id-type="pmid">20161126</pub-id></element-citation></ref><ref id="bib16"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Banks</surname><given-names>GC</given-names></name><name><surname>O’Boyle</surname><given-names>EH</given-names></name><name><surname>Pollack</surname><given-names>JM</given-names></name><name><surname>White</surname><given-names>CD</given-names></name><name><surname>Batchelor</surname><given-names>JH</given-names></name><name><surname>Whelpley</surname><given-names>CE</given-names></name><name><surname>Abston</surname><given-names>KA</given-names></name><name><surname>Bennett</surname><given-names>AA</given-names></name><name><surname>Adkins</surname><given-names>CL</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Questions about questionable research practices in the field of management</article-title><source>Journal of Management</source><volume>42</volume><fpage>5</fpage><lpage>20</lpage><pub-id pub-id-type="doi">10.1177/0149206315619011</pub-id></element-citation></ref><ref id="bib17"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bell</surname><given-names>CC</given-names></name></person-group><year iso-8601-date="1994">1994</year><article-title>DSM-IV: diagnostic and statistical manual of mental disorders</article-title><source>JAMA</source><volume>272</volume><elocation-id>828</elocation-id><pub-id pub-id-type="doi">10.1001/jama.1994.03520100096046</pub-id><pub-id pub-id-type="pmid">7933395</pub-id></element-citation></ref><ref id="bib18"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Berry</surname><given-names>WD</given-names></name></person-group><year iso-8601-date="1993">1993</year><article-title>The consequences of the regression assumptions being satisfied</article-title><source>Understanding Regression Assumptions</source><volume>01</volume><fpage>19</fpage><lpage>22</lpage><pub-id pub-id-type="doi">10.4135/9781412986427</pub-id></element-citation></ref><ref id="bib19"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bewick</surname><given-names>V</given-names></name><name><surname>Cheek</surname><given-names>L</given-names></name><name><surname>Ball</surname><given-names>J</given-names></name></person-group><year iso-8601-date="2003">2003</year><article-title>Statistics review 7: correlation and regression</article-title><source>Critical Care</source><volume>7</volume><fpage>451</fpage><lpage>459</lpage><pub-id pub-id-type="doi">10.1186/cc2401</pub-id><pub-id pub-id-type="pmid">14624685</pub-id></element-citation></ref><ref id="bib20"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Binder</surname><given-names>H</given-names></name><name><surname>Sauerbrei</surname><given-names>W</given-names></name><name><surname>Royston</surname><given-names>P</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>Comparison between splines and fractional polynomials for multivariable model building with continuous covariates: a simulation study with continuous response</article-title><source>Statistics in Medicine</source><volume>32</volume><fpage>2262</fpage><lpage>2277</lpage><pub-id pub-id-type="doi">10.1002/sim.5639</pub-id><pub-id pub-id-type="pmid">23034770</pub-id></element-citation></ref><ref id="bib21"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Blas Achic</surname><given-names>BG</given-names></name><name><surname>Wang</surname><given-names>T</given-names></name><name><surname>Su</surname><given-names>Y</given-names></name><name><surname>Kipnis</surname><given-names>V</given-names></name><name><surname>Dodd</surname><given-names>K</given-names></name><name><surname>Carroll</surname><given-names>RJ</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>Categorizing a continuous predictor subject to measurement error</article-title><source>Electronic Journal of Statistics</source><volume>12</volume><fpage>4032</fpage><lpage>4056</lpage><pub-id pub-id-type="doi">10.1214/18-EJS1489</pub-id></element-citation></ref><ref id="bib22"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bollen</surname><given-names>KA</given-names></name></person-group><year iso-8601-date="1987">1987</year><article-title>Total, direct, and indirect effects in structural equation models</article-title><source>Sociological Methodology</source><volume>17</volume><elocation-id>37</elocation-id><pub-id pub-id-type="doi">10.2307/271028</pub-id></element-citation></ref><ref id="bib23"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Brenner</surname><given-names>H</given-names></name><name><surname>Loomis</surname><given-names>D</given-names></name></person-group><year iso-8601-date="1994">1994</year><article-title>Varied forms of bias due to nondifferential error in measuring exposure</article-title><source>Epidemiology</source><volume>5</volume><fpage>510</fpage><lpage>517</lpage><pub-id pub-id-type="pmid">7986865</pub-id></element-citation></ref><ref id="bib24"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Brown</surname><given-names>AW</given-names></name><name><surname>Aslibekyan</surname><given-names>S</given-names></name><name><surname>Bier</surname><given-names>D</given-names></name><name><surname>Ferreira da Silva</surname><given-names>R</given-names></name><name><surname>Hoover</surname><given-names>A</given-names></name><name><surname>Klurfeld</surname><given-names>DM</given-names></name><name><surname>Loken</surname><given-names>E</given-names></name><name><surname>Mayo-Wilson</surname><given-names>E</given-names></name><name><surname>Menachemi</surname><given-names>N</given-names></name><name><surname>Pavela</surname><given-names>G</given-names></name><name><surname>Quinn</surname><given-names>PD</given-names></name><name><surname>Schoeller</surname><given-names>D</given-names></name><name><surname>Tekwe</surname><given-names>C</given-names></name><name><surname>Valdez</surname><given-names>D</given-names></name><name><surname>Vorland</surname><given-names>CJ</given-names></name><name><surname>Whigham</surname><given-names>LD</given-names></name><name><surname>Allison</surname><given-names>DB</given-names></name></person-group><year iso-8601-date="2023">2023</year><article-title>Toward more rigorous and informative nutritional epidemiology: The rational space between dismissal and defense of the status quo</article-title><source>Critical Reviews in Food Science and Nutrition</source><volume>63</volume><fpage>3150</fpage><lpage>3167</lpage><pub-id pub-id-type="doi">10.1080/10408398.2021.1985427</pub-id><pub-id pub-id-type="pmid">34678079</pub-id></element-citation></ref><ref id="bib25"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bruns</surname><given-names>SB</given-names></name><name><surname>Ioannidis</surname><given-names>JPA</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>P-Curve and P-hacking in observational research</article-title><source>PLOS ONE</source><volume>11</volume><elocation-id>e0149144</elocation-id><pub-id pub-id-type="doi">10.1371/journal.pone.0149144</pub-id><pub-id pub-id-type="pmid">26886098</pub-id></element-citation></ref><ref id="bib26"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Buonaccorsi</surname><given-names>J</given-names></name><name><surname>Demidenko</surname><given-names>E</given-names></name><name><surname>Tosteson</surname><given-names>T</given-names></name></person-group><year iso-8601-date="2000">2000</year><source>Estimation in longitudinal random effects models with measurement error</source><publisher-name>Statistica Sinica</publisher-name></element-citation></ref><ref id="bib27"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Carroll</surname><given-names>RJ</given-names></name><name><surname>Ruppert</surname><given-names>D</given-names></name><name><surname>Stefanski</surname><given-names>LA</given-names></name><name><surname>Crainiceanu</surname><given-names>CM</given-names></name></person-group><year iso-8601-date="2006">2006</year><source>Measurement error in nonlinear models: a modern perspective</source><publisher-name>Chapman and Hall/CRC</publisher-name><pub-id pub-id-type="doi">10.1201/9781420010138</pub-id></element-citation></ref><ref id="bib28"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Cegielski</surname><given-names>JP</given-names></name><name><surname>Dalton</surname><given-names>T</given-names></name><name><surname>Yagui</surname><given-names>M</given-names></name><name><surname>Wattanaamornkiet</surname><given-names>W</given-names></name><name><surname>Volchenkov</surname><given-names>GV</given-names></name><name><surname>Via</surname><given-names>LE</given-names></name><name><surname>Van Der Walt</surname><given-names>M</given-names></name><name><surname>Tupasi</surname><given-names>T</given-names></name><name><surname>Smith</surname><given-names>SE</given-names></name><name><surname>Odendaal</surname><given-names>R</given-names></name><name><surname>Leimane</surname><given-names>V</given-names></name><name><surname>Kvasnovsky</surname><given-names>C</given-names></name><name><surname>Kuznetsova</surname><given-names>T</given-names></name><name><surname>Kurbatova</surname><given-names>E</given-names></name><name><surname>Kummik</surname><given-names>T</given-names></name><name><surname>Kuksa</surname><given-names>L</given-names></name><name><surname>Kliiman</surname><given-names>K</given-names></name><name><surname>Kiryanova</surname><given-names>EV</given-names></name><name><surname>Kim</surname><given-names>H</given-names></name><name><surname>Kim</surname><given-names>C</given-names></name><name><surname>Kazennyy</surname><given-names>BY</given-names></name><name><surname>Jou</surname><given-names>R</given-names></name><name><surname>Huang</surname><given-names>WL</given-names></name><name><surname>Ershova</surname><given-names>J</given-names></name><name><surname>Erokhin</surname><given-names>VV</given-names></name><name><surname>Diem</surname><given-names>L</given-names></name><name><surname>Contreras</surname><given-names>C</given-names></name><name><surname>Cho</surname><given-names>SN</given-names></name><name><surname>Chernousova</surname><given-names>LN</given-names></name><name><surname>Chen</surname><given-names>MP</given-names></name><name><surname>Caoili</surname><given-names>JC</given-names></name><name><surname>Bayona</surname><given-names>J</given-names></name><name><surname>Akksilp</surname><given-names>S</given-names></name><collab>Global Preserving Effective TB Treatment Study (PETTS) Investigators</collab></person-group><year iso-8601-date="2014">2014</year><article-title>Extensive drug resistance acquired during treatment of multidrug-resistant tuberculosis</article-title><source>Clinical Infectious Diseases</source><volume>59</volume><fpage>1049</fpage><lpage>1063</lpage><pub-id pub-id-type="doi">10.1093/cid/ciu572</pub-id><pub-id pub-id-type="pmid">25057101</pub-id></element-citation></ref><ref id="bib29"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Chen</surname><given-names>PY</given-names></name><name><surname>Krauss</surname><given-names>AD</given-names></name></person-group><year iso-8601-date="2005">2005</year><chapter-title>Experiments, psychology</chapter-title><person-group person-group-type="editor"><name><surname>Kempf-Leonard</surname><given-names>K</given-names></name></person-group><source>Encyclopedia of Social Measurement</source><publisher-name>Elsevier</publisher-name><fpage>911</fpage><lpage>918</lpage><pub-id pub-id-type="doi">10.1016/B0-12-369398-5/00327-3</pub-id></element-citation></ref><ref id="bib30"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Cheong</surname><given-names>J</given-names></name><name><surname>MacKinnon</surname><given-names>DP</given-names></name></person-group><year iso-8601-date="2012">2012</year><source>Mediation/indirect effects in structural equation modeling</source><publisher-name>Handbook of Structural Equation Modeling</publisher-name></element-citation></ref><ref id="bib31"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Choi</surname><given-names>AL</given-names></name><name><surname>Cordier</surname><given-names>S</given-names></name><name><surname>Weihe</surname><given-names>P</given-names></name><name><surname>Grandjean</surname><given-names>P</given-names></name></person-group><year iso-8601-date="2008">2008</year><article-title>Negative confounding in the evaluation of toxicity: the case of methylmercury in fish and seafood</article-title><source>Critical Reviews in Toxicology</source><volume>38</volume><fpage>877</fpage><lpage>893</lpage><pub-id pub-id-type="doi">10.1080/10408440802273164</pub-id><pub-id pub-id-type="pmid">19012089</pub-id></element-citation></ref><ref id="bib32"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Christensen</surname><given-names>JD</given-names></name><name><surname>Orquin</surname><given-names>JL</given-names></name><name><surname>Perkovic</surname><given-names>S</given-names></name><name><surname>Lagerkvist</surname><given-names>CJ</given-names></name></person-group><year iso-8601-date="2021">2021</year><source>Preregistration is important, but not enough: many statistical analyses can inflate the risk of false-positives</source><publisher-name>Research Gate</publisher-name></element-citation></ref><ref id="bib33"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Cinelli</surname><given-names>C</given-names></name><name><surname>Forney</surname><given-names>A</given-names></name><name><surname>Pearl</surname><given-names>J</given-names></name></person-group><year iso-8601-date="2020">2020</year><article-title>A crash course in good and bad controls</article-title><source>SSRN Electronic Journal</source><volume>01</volume><elocation-id>3689437</elocation-id><pub-id pub-id-type="doi">10.2139/ssrn.3689437</pub-id></element-citation></ref><ref id="bib34"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Cochran</surname><given-names>GW</given-names></name><name><surname>Rubin</surname><given-names>BD</given-names></name></person-group><year iso-8601-date="1961">1961</year><article-title>Controlling bias in observational studies: a review</article-title><source>Sankhyā: The Indian Journal of Statistics, Series A</source><volume>35</volume><fpage>417</fpage><lpage>446</lpage></element-citation></ref><ref id="bib35"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Cox</surname><given-names>DR</given-names></name></person-group><year iso-8601-date="2006">2006</year><source>Principles of Statistical Inference</source><publisher-name>Cambridge university press</publisher-name><pub-id pub-id-type="doi">10.1017/CBO9780511813559</pub-id></element-citation></ref><ref id="bib36"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Dales</surname><given-names>LG</given-names></name><name><surname>Ury</surname><given-names>HK</given-names></name></person-group><year iso-8601-date="1978">1978</year><article-title>An improper use of statistical significance testing in studying covariables</article-title><source>International Journal of Epidemiology</source><volume>7</volume><fpage>373</fpage><lpage>375</lpage><pub-id pub-id-type="doi">10.1093/ije/7.4.373</pub-id><pub-id pub-id-type="pmid">744677</pub-id></element-citation></ref><ref id="bib37"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Dal Ré</surname><given-names>R</given-names></name><name><surname>Ioannidis</surname><given-names>JP</given-names></name><name><surname>Bracken</surname><given-names>MB</given-names></name><name><surname>Buffler</surname><given-names>PA</given-names></name><name><surname>Chan</surname><given-names>AW</given-names></name><name><surname>Franco</surname><given-names>EL</given-names></name><name><surname>La Vecchia</surname><given-names>C</given-names></name><name><surname>Weiderpass</surname><given-names>E</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>Making prospective registration of observational research a reality</article-title><source>Science Translational Medicine</source><volume>6</volume><elocation-id>3007513</elocation-id><pub-id pub-id-type="doi">10.1126/scitranslmed.3007513</pub-id><pub-id pub-id-type="pmid">24553383</pub-id></element-citation></ref><ref id="bib38"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Daniels</surname><given-names>L</given-names></name></person-group><year iso-8601-date="2001">2001</year><article-title>Managing six sigma: a practical guide to understanding, assessing, and implementing the strategy that yields bottom line success</article-title><source>Journal of Quality Technology</source><volume>33</volume><fpage>525</fpage><lpage>526</lpage><pub-id pub-id-type="doi">10.1080/00224065.2001.11980112</pub-id></element-citation></ref><ref id="bib39"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Dawid</surname><given-names>AP</given-names></name></person-group><year iso-8601-date="1979">1979</year><article-title>Conditional independence in statistical theory</article-title><source>Journal of the Royal Statistical Society</source><volume>41</volume><fpage>1</fpage><lpage>15</lpage><pub-id pub-id-type="doi">10.1111/j.2517-6161.1979.tb01052.x</pub-id></element-citation></ref><ref id="bib40"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Del Giudice</surname><given-names>M</given-names></name><name><surname>Gangestad</surname><given-names>SW</given-names></name></person-group><year iso-8601-date="2021">2021</year><article-title>A traveler’s guide to the multiverse: promises, pitfalls, and a framework for the evaluation of analytic decisions</article-title><source>Advances in Methods and Practices in Psychological Science</source><volume>4</volume><elocation-id>251524592095492</elocation-id><pub-id pub-id-type="doi">10.1177/2515245920954925</pub-id></element-citation></ref><ref id="bib41"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Dhurandhar</surname><given-names>NV</given-names></name><name><surname>Schoeller</surname><given-names>D</given-names></name><name><surname>Brown</surname><given-names>AW</given-names></name><name><surname>Heymsfield</surname><given-names>SB</given-names></name><name><surname>Thomas</surname><given-names>D</given-names></name><name><surname>Sørensen</surname><given-names>TIA</given-names></name><name><surname>Speakman</surname><given-names>JR</given-names></name><name><surname>Jeansonne</surname><given-names>M</given-names></name><name><surname>Allison</surname><given-names>DB</given-names></name><collab>the Energy Balance Measurement Working Group</collab></person-group><year iso-8601-date="2015">2015</year><article-title>Energy balance measurement: when something is not better than nothing</article-title><source>International Journal of Obesity</source><volume>39</volume><fpage>1109</fpage><lpage>1113</lpage><pub-id pub-id-type="doi">10.1038/ijo.2014.199</pub-id></element-citation></ref><ref id="bib42"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ding</surname><given-names>P</given-names></name><name><surname>Miratrix</surname><given-names>LW</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>To adjust or not to adjust? sensitivity analysis of m-bias and butterfly-bias</article-title><source>Journal of Causal Inference</source><volume>3</volume><fpage>41</fpage><lpage>57</lpage><pub-id pub-id-type="doi">10.1515/jci-2013-0021</pub-id></element-citation></ref><ref id="bib43"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ejima</surname><given-names>K</given-names></name><name><surname>Li</surname><given-names>P</given-names></name><name><surname>Smith</surname><given-names>DL</given-names></name><name><surname>Nagy</surname><given-names>TR</given-names></name><name><surname>Kadish</surname><given-names>I</given-names></name><name><surname>van Groen</surname><given-names>T</given-names></name><name><surname>Dawson</surname><given-names>JA</given-names></name><name><surname>Yang</surname><given-names>Y</given-names></name><name><surname>Patki</surname><given-names>A</given-names></name><name><surname>Allison</surname><given-names>DB</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Observational research rigour alone does not justify causal inference</article-title><source>European Journal of Clinical Investigation</source><volume>46</volume><fpage>985</fpage><lpage>993</lpage><pub-id pub-id-type="doi">10.1111/eci.12681</pub-id><pub-id pub-id-type="pmid">27711975</pub-id></element-citation></ref><ref id="bib44"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Fisher</surname><given-names>RA</given-names></name></person-group><year iso-8601-date="1970">1970</year><source>Statistical methods for research workers</source><publisher-name>Collier-MacMillan Publishers</publisher-name></element-citation></ref><ref id="bib45"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Fitzsimons</surname><given-names>GJ</given-names></name></person-group><year iso-8601-date="2008">2008</year><article-title>Death to dichotomizing: figure 1</article-title><source>Journal of Consumer Research</source><volume>35</volume><fpage>5</fpage><lpage>8</lpage><pub-id pub-id-type="doi">10.1086/589561</pub-id></element-citation></ref><ref id="bib46"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Flegal</surname><given-names>KM</given-names></name><name><surname>Graubard</surname><given-names>BI</given-names></name><name><surname>Williamson</surname><given-names>DF</given-names></name><name><surname>Gail</surname><given-names>MH</given-names></name></person-group><year iso-8601-date="2005">2005</year><article-title>Excess deaths associated with underweight, overweight, and obesity</article-title><source>JAMA</source><volume>293</volume><fpage>1861</fpage><lpage>1867</lpage><pub-id pub-id-type="doi">10.1001/jama.293.15.1861</pub-id><pub-id pub-id-type="pmid">15840860</pub-id></element-citation></ref><ref id="bib47"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Flegal</surname><given-names>KM</given-names></name><name><surname>Graubard</surname><given-names>BI</given-names></name><name><surname>Williamson</surname><given-names>DF</given-names></name><name><surname>Gail</surname><given-names>MH</given-names></name></person-group><year iso-8601-date="2007">2007</year><article-title>Cause-specific excess deaths associated with underweight, overweight, and obesity</article-title><source>JAMA</source><volume>298</volume><fpage>2028</fpage><lpage>2037</lpage><pub-id pub-id-type="doi">10.1001/jama.298.17.2028</pub-id><pub-id pub-id-type="pmid">17986696</pub-id></element-citation></ref><ref id="bib48"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Fletcher</surname><given-names>PC</given-names></name><name><surname>Kenny</surname><given-names>PJ</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>Food addiction: a valid concept?</article-title><source>Neuropsychopharmacology</source><volume>43</volume><fpage>2506</fpage><lpage>2513</lpage><pub-id pub-id-type="doi">10.1038/s41386-018-0203-9</pub-id><pub-id pub-id-type="pmid">30188514</pub-id></element-citation></ref><ref id="bib49"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Fontaine</surname><given-names>KR</given-names></name><name><surname>Redden</surname><given-names>DT</given-names></name><name><surname>Wang</surname><given-names>C</given-names></name><name><surname>Westfall</surname><given-names>AO</given-names></name><name><surname>Allison</surname><given-names>DB</given-names></name></person-group><year iso-8601-date="2003">2003</year><article-title>Years of life lost due to obesity</article-title><source>JAMA</source><volume>289</volume><fpage>187</fpage><lpage>193</lpage><pub-id pub-id-type="doi">10.1001/jama.289.2.187</pub-id><pub-id pub-id-type="pmid">12517229</pub-id></element-citation></ref><ref id="bib50"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Fox</surname><given-names>J</given-names></name></person-group><year iso-8601-date="2019">2019</year><source>Regression diagnostics: an introduction</source><publisher-name>SAGE Publications</publisher-name></element-citation></ref><ref id="bib51"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Fuller</surname><given-names>WA</given-names></name></person-group><year iso-8601-date="2009">2009</year><source>Measurement Error Models</source><publisher-name>John Wiley &amp; Sons</publisher-name><pub-id pub-id-type="doi">10.1002/9780470316665</pub-id></element-citation></ref><ref id="bib52"><element-citation publication-type="web"><person-group person-group-type="author"><name><surname>Gelman</surname><given-names>A</given-names></name><name><surname>Loken</surname><given-names>E</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>The garden of forking paths: Why multiple comparisons can be a problem, even when there is no “fishing expedition” or “p-hacking” and the research hypothesis was posited ahead of time</article-title><ext-link ext-link-type="uri" xlink:href="http://www.stat.columbia.edu/~gelman/research/unpublished/p_hacking.pdf">http://www.stat.columbia.edu/~gelman/research/unpublished/p_hacking.pdf</ext-link><date-in-citation iso-8601-date="2021-12-06">December 6, 2021</date-in-citation></element-citation></ref><ref id="bib53"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Gelman</surname><given-names>A</given-names></name><name><surname>Hill</surname><given-names>J</given-names></name><name><surname>Vehtari</surname><given-names>A</given-names></name></person-group><year iso-8601-date="2020">2020</year><source>Regression and other stories</source><publisher-name>Cambridge University Press</publisher-name><pub-id pub-id-type="doi">10.1017/9781139161879</pub-id></element-citation></ref><ref id="bib54"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Gibney</surname><given-names>M</given-names></name><name><surname>Allison</surname><given-names>D</given-names></name><name><surname>Bier</surname><given-names>D</given-names></name><name><surname>Dwyer</surname><given-names>J</given-names></name></person-group><year iso-8601-date="2020">2020</year><article-title>Uncertainty in human nutrition research</article-title><source>Nature Food</source><volume>1</volume><fpage>247</fpage><lpage>249</lpage><pub-id pub-id-type="doi">10.1038/s43016-020-0073-2</pub-id></element-citation></ref><ref id="bib55"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Gibney</surname><given-names>MJ</given-names></name></person-group><year iso-8601-date="2022">2022</year><article-title>From populations to molecules: a life in food and health</article-title><source>European Journal of Clinical Nutrition</source><volume>76</volume><fpage>1633</fpage><lpage>1635</lpage><pub-id pub-id-type="doi">10.1038/s41430-021-01002-4</pub-id><pub-id pub-id-type="pmid">34675404</pub-id></element-citation></ref><ref id="bib56"><element-citation publication-type="web"><person-group person-group-type="author"><name><surname>Gibson</surname><given-names>J</given-names></name><name><surname>Zezza</surname><given-names>A</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>What do we measure when we measure food consumption?</article-title><ext-link ext-link-type="uri" xlink:href="https://blogs.worldbank.org/impactevaluations/what-do-we-measure-when-we-measure-food-consumption">https://blogs.worldbank.org/impactevaluations/what-do-we-measure-when-we-measure-food-consumption</ext-link><date-in-citation iso-8601-date="2022-02-12">February 12, 2022</date-in-citation></element-citation></ref><ref id="bib57"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Greenland</surname><given-names>S</given-names></name></person-group><year iso-8601-date="1989">1989</year><article-title>Modeling and variable selection in epidemiologic analysis</article-title><source>American Journal of Public Health</source><volume>79</volume><fpage>340</fpage><lpage>349</lpage><pub-id pub-id-type="doi">10.2105/ajph.79.3.340</pub-id><pub-id pub-id-type="pmid">2916724</pub-id></element-citation></ref><ref id="bib58"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Greenland</surname><given-names>S</given-names></name></person-group><year iso-8601-date="2008">2008</year><article-title>Invited commentary: variable selection versus shrinkage in the control of multiple confounders</article-title><source>American Journal of Epidemiology</source><volume>167</volume><fpage>523</fpage><lpage>529</lpage><pub-id pub-id-type="doi">10.1093/aje/kwm355</pub-id><pub-id pub-id-type="pmid">18227100</pub-id></element-citation></ref><ref id="bib59"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Greenland</surname><given-names>S</given-names></name><name><surname>Senn</surname><given-names>SJ</given-names></name><name><surname>Rothman</surname><given-names>KJ</given-names></name><name><surname>Carlin</surname><given-names>JB</given-names></name><name><surname>Poole</surname><given-names>C</given-names></name><name><surname>Goodman</surname><given-names>SN</given-names></name><name><surname>Altman</surname><given-names>DG</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Statistical tests, P values, confidence intervals, and power: a guide to misinterpretations</article-title><source>European Journal of Epidemiology</source><volume>31</volume><fpage>337</fpage><lpage>350</lpage><pub-id pub-id-type="doi">10.1007/s10654-016-0149-3</pub-id></element-citation></ref><ref id="bib60"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Greenland</surname><given-names>S</given-names></name></person-group><year iso-8601-date="2020">2020</year><article-title>Commentary: An argument against E-values for assessing the plausibility that an association could be explained away by residual confounding</article-title><source>International Journal of Epidemiology</source><volume>49</volume><fpage>1501</fpage><lpage>1503</lpage><pub-id pub-id-type="doi">10.1093/ije/dyaa095</pub-id><pub-id pub-id-type="pmid">32808028</pub-id></element-citation></ref><ref id="bib61"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Greenwood</surname><given-names>DC</given-names></name><name><surname>Gilthorpe</surname><given-names>MS</given-names></name><name><surname>Cade</surname><given-names>JE</given-names></name></person-group><year iso-8601-date="2006">2006</year><article-title>The impact of imprecisely measured covariates on estimating gene-environment interactions</article-title><source>BMC Medical Research Methodology</source><volume>6</volume><fpage>1</fpage><lpage>8</lpage><pub-id pub-id-type="doi">10.1186/1471-2288-6-21</pub-id><pub-id pub-id-type="pmid">16674808</pub-id></element-citation></ref><ref id="bib62"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Groenwold</surname><given-names>RHH</given-names></name><name><surname>White</surname><given-names>IR</given-names></name><name><surname>Donders</surname><given-names>ART</given-names></name><name><surname>Carpenter</surname><given-names>JR</given-names></name><name><surname>Altman</surname><given-names>DG</given-names></name><name><surname>Moons</surname><given-names>KGM</given-names></name></person-group><year iso-8601-date="2012">2012</year><article-title>Missing covariate data in clinical research: when and when not to use the missing-indicator method for analysis</article-title><source>Canadian Medical Association Journal</source><volume>184</volume><fpage>1265</fpage><lpage>1269</lpage><pub-id pub-id-type="doi">10.1503/cmaj.110977</pub-id></element-citation></ref><ref id="bib63"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hanin</surname><given-names>L</given-names></name></person-group><year iso-8601-date="2021">2021</year><article-title>Cavalier use of inferential statistics is a major source of false and irreproducible scientific findings</article-title><source>Mathematics</source><volume>9</volume><elocation-id>603</elocation-id><pub-id pub-id-type="doi">10.3390/math9060603</pub-id></element-citation></ref><ref id="bib64"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hanley-Cook</surname><given-names>GT</given-names></name><name><surname>Daly</surname><given-names>AJ</given-names></name><name><surname>Remans</surname><given-names>R</given-names></name><name><surname>Jones</surname><given-names>AD</given-names></name><name><surname>Murray</surname><given-names>KA</given-names></name><name><surname>Huybrechts</surname><given-names>I</given-names></name><name><surname>De Baets</surname><given-names>B</given-names></name><name><surname>Lachat</surname><given-names>C</given-names></name></person-group><year iso-8601-date="2023">2023</year><article-title>Food biodiversity: Quantifying the unquantifiable in human diets</article-title><source>Critical Reviews in Food Science and Nutrition</source><volume>63</volume><fpage>7837</fpage><lpage>7851</lpage><pub-id pub-id-type="doi">10.1080/10408398.2022.2051163</pub-id><pub-id pub-id-type="pmid">35297716</pub-id></element-citation></ref><ref id="bib65"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Harry</surname><given-names>MJ</given-names></name><name><surname>Schroeder</surname><given-names>RR</given-names></name></person-group><year iso-8601-date="2005">2005</year><source>Six sigma: the breakthrough management strategy revolutionizing the world’s top corporations</source><publisher-name>Crown Pub</publisher-name></element-citation></ref><ref id="bib66"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Hastie</surname><given-names>T</given-names></name><name><surname>Tibshirani</surname><given-names>R</given-names></name><name><surname>Friedman</surname><given-names>J</given-names></name></person-group><year iso-8601-date="2017">2017</year><source>The elements of statistical learning data mining, inference, and prediction</source><publisher-name>Springer open</publisher-name></element-citation></ref><ref id="bib67"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Head</surname><given-names>ML</given-names></name><name><surname>Holman</surname><given-names>L</given-names></name><name><surname>Lanfear</surname><given-names>R</given-names></name><name><surname>Kahn</surname><given-names>AT</given-names></name><name><surname>Jennions</surname><given-names>MD</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>The extent and consequences of p-hacking in science</article-title><source>PLOS Biology</source><volume>13</volume><elocation-id>e1002106</elocation-id><pub-id pub-id-type="doi">10.1371/journal.pbio.1002106</pub-id><pub-id pub-id-type="pmid">25768323</pub-id></element-citation></ref><ref id="bib68"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hernán</surname><given-names>MA</given-names></name></person-group><year iso-8601-date="2004">2004</year><article-title>A definition of causal effect for epidemiological research</article-title><source>Journal of Epidemiology and Community Health</source><volume>58</volume><fpage>265</fpage><lpage>271</lpage><pub-id pub-id-type="doi">10.1136/jech.2002.006361</pub-id><pub-id pub-id-type="pmid">15026432</pub-id></element-citation></ref><ref id="bib69"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hernán</surname><given-names>MA</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>The C-Word: scientific euphemisms do not improve causal inference from observational data</article-title><source>American Journal of Public Health</source><volume>108</volume><fpage>616</fpage><lpage>619</lpage><pub-id pub-id-type="doi">10.2105/AJPH.2018.304337</pub-id><pub-id pub-id-type="pmid">29565659</pub-id></element-citation></ref><ref id="bib70"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hoekstra</surname><given-names>R</given-names></name><name><surname>Vazire</surname><given-names>S</given-names></name></person-group><year iso-8601-date="2021">2021</year><article-title>Aspiring to greater intellectual humility in science</article-title><source>Nature Human Behaviour</source><volume>5</volume><fpage>1602</fpage><lpage>1607</lpage><pub-id pub-id-type="doi">10.1038/s41562-021-01203-8</pub-id><pub-id pub-id-type="pmid">34711978</pub-id></element-citation></ref><ref id="bib71"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Holmes</surname><given-names>CC</given-names></name><name><surname>Mallick</surname><given-names>BK</given-names></name></person-group><year iso-8601-date="2003">2003</year><article-title>Generalized nonlinear modeling with multivariate free-knot regression splines</article-title><source>Journal of the American Statistical Association</source><volume>98</volume><fpage>352</fpage><lpage>368</lpage><pub-id pub-id-type="doi">10.1198/016214503000143</pub-id></element-citation></ref><ref id="bib72"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Humphreys</surname><given-names>LG</given-names></name></person-group><year iso-8601-date="1978">1978</year><article-title>Doing research the hard way: Substituting analysis of variance for a problem in correlational analysis</article-title><source>Journal of Educational Psychology</source><volume>70</volume><fpage>873</fpage><lpage>876</lpage><pub-id pub-id-type="doi">10.1037//0022-0663.70.6.873</pub-id></element-citation></ref><ref id="bib73"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hunter</surname><given-names>JE</given-names></name><name><surname>Schmidt</surname><given-names>FL</given-names></name></person-group><year iso-8601-date="1990">1990</year><article-title>Dichotomization of continuous variables: The implications for meta-analysis</article-title><source>Journal of Applied Psychology</source><volume>75</volume><fpage>334</fpage><lpage>349</lpage><pub-id pub-id-type="doi">10.1037/0021-9010.75.3.334</pub-id></element-citation></ref><ref id="bib74"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Irwin</surname><given-names>JR</given-names></name><name><surname>McClelland</surname><given-names>GH</given-names></name></person-group><year iso-8601-date="2003">2003</year><article-title>Negative consequences of dichotomizing continuous predictor variables</article-title><source>Journal of Marketing Research</source><volume>40</volume><fpage>366</fpage><lpage>371</lpage><pub-id pub-id-type="doi">10.1509/jmkr.40.3.366.19237</pub-id></element-citation></ref><ref id="bib75"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>ISO</surname><given-names>A</given-names></name></person-group><year iso-8601-date="1994">1994</year><source>Of measurement methods and results—part 1: general principles and definitions</source><publisher-name>International Organization for Standardization</publisher-name></element-citation></ref><ref id="bib76"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kavvoura</surname><given-names>FK</given-names></name><name><surname>Liberopoulos</surname><given-names>G</given-names></name><name><surname>Ioannidis</surname><given-names>JPA</given-names></name></person-group><year iso-8601-date="2007">2007</year><article-title>Selection in reported epidemiological risks: an empirical assessment</article-title><source>PLOS Medicine</source><volume>4</volume><elocation-id>e79</elocation-id><pub-id pub-id-type="doi">10.1371/journal.pmed.0040079</pub-id><pub-id pub-id-type="pmid">17341129</pub-id></element-citation></ref><ref id="bib77"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Lee</surname><given-names>PH</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>Should we adjust for A confounder if empirical and theoretical criteria yield contradictory results? A simulation study</article-title><source>Scientific Reports</source><volume>4</volume><elocation-id>6085</elocation-id><pub-id pub-id-type="doi">10.1038/srep06085</pub-id><pub-id pub-id-type="pmid">25124526</pub-id></element-citation></ref><ref id="bib78"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Lenz</surname><given-names>GS</given-names></name><name><surname>Sahn</surname><given-names>A</given-names></name></person-group><year iso-8601-date="2021">2021</year><article-title>Achieving statistical significance with control variables and without transparency</article-title><source>Political Analysis</source><volume>29</volume><fpage>356</fpage><lpage>369</lpage><pub-id pub-id-type="doi">10.1017/pan.2020.31</pub-id></element-citation></ref><ref id="bib79"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Linderman</surname><given-names>K</given-names></name><name><surname>Schroeder</surname><given-names>RG</given-names></name><name><surname>Zaheer</surname><given-names>S</given-names></name><name><surname>Choo</surname><given-names>AS</given-names></name></person-group><year iso-8601-date="2003">2003</year><article-title>Six Sigma: a goal‐theoretic perspective</article-title><source>Journal of Operations Management</source><volume>21</volume><fpage>193</fpage><lpage>203</lpage><pub-id pub-id-type="doi">10.1016/S0272-6963(02)00087-6</pub-id></element-citation></ref><ref id="bib80"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>MacCallum</surname><given-names>RC</given-names></name><name><surname>Zhang</surname><given-names>S</given-names></name><name><surname>Preacher</surname><given-names>KJ</given-names></name><name><surname>Rucker</surname><given-names>DD</given-names></name></person-group><year iso-8601-date="2002">2002</year><article-title>On the practice of dichotomization of quantitative variables</article-title><source>Psychological Methods</source><volume>7</volume><fpage>19</fpage><lpage>40</lpage><pub-id pub-id-type="doi">10.1037/1082-989x.7.1.19</pub-id><pub-id pub-id-type="pmid">11928888</pub-id></element-citation></ref><ref id="bib81"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Maldonado</surname><given-names>G</given-names></name><name><surname>Greenland</surname><given-names>S</given-names></name></person-group><year iso-8601-date="1993">1993</year><article-title>Simulation study of confounder-selection strategies</article-title><source>American Journal of Epidemiology</source><volume>138</volume><fpage>923</fpage><lpage>936</lpage><pub-id pub-id-type="doi">10.1093/oxfordjournals.aje.a116813</pub-id><pub-id pub-id-type="pmid">8256780</pub-id></element-citation></ref><ref id="bib82"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Maxwell</surname><given-names>SE</given-names></name><name><surname>Delaney</surname><given-names>HD</given-names></name><name><surname>Manheimer</surname><given-names>JM</given-names></name></person-group><year iso-8601-date="1985">1985</year><article-title>ANOVA of Residuals and ANCOVA: correcting an illusion by using model comparisons and graphs</article-title><source>Journal of Educational Statistics</source><volume>10</volume><fpage>197</fpage><lpage>209</lpage><pub-id pub-id-type="doi">10.3102/10769986010003197</pub-id></element-citation></ref><ref id="bib83"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Mayo</surname><given-names>DG</given-names></name><name><surname>Cox</surname><given-names>RD</given-names></name></person-group><year iso-8601-date="2006">2006</year><article-title>Frequentist statistics as a theory of inductive inference</article-title><source>Lecture Notes-Monograph Series</source><volume>49</volume><fpage>77</fpage><lpage>97</lpage></element-citation></ref><ref id="bib84"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>McElreath</surname><given-names>R</given-names></name></person-group><year iso-8601-date="2020">2020</year><source>Statistical rethinking: a bayesian course with examples in r and stan</source><publisher-name>Chapman and Hall</publisher-name><pub-id pub-id-type="doi">10.1201/9780429029608</pub-id></element-citation></ref><ref id="bib85"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Meloun</surname><given-names>M</given-names></name><name><surname>Militký</surname><given-names>J</given-names></name></person-group><year iso-8601-date="2011">2011</year><chapter-title>8 - Nonlinear regression models</chapter-title><source>Statistical Data Analysis: A Practical Guide</source><publisher-name>Woodhead Publishing Limited</publisher-name><fpage>667</fpage><lpage>762</lpage></element-citation></ref><ref id="bib86"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Munafò</surname><given-names>MR</given-names></name><name><surname>Tilling</surname><given-names>K</given-names></name><name><surname>Taylor</surname><given-names>AE</given-names></name><name><surname>Evans</surname><given-names>DM</given-names></name><name><surname>Davey Smith</surname><given-names>G</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>Collider scope: when selection bias can substantially influence observed associations</article-title><source>International Journal of Epidemiology</source><volume>47</volume><fpage>226</fpage><lpage>235</lpage><pub-id pub-id-type="doi">10.1093/ije/dyx206</pub-id><pub-id pub-id-type="pmid">29040562</pub-id></element-citation></ref><ref id="bib87"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Naggara</surname><given-names>O</given-names></name><name><surname>Raymond</surname><given-names>J</given-names></name><name><surname>Guilbert</surname><given-names>F</given-names></name><name><surname>Roy</surname><given-names>D</given-names></name><name><surname>Weill</surname><given-names>A</given-names></name><name><surname>Altman</surname><given-names>DG</given-names></name></person-group><year iso-8601-date="2011">2011</year><article-title>Analysis by categorizing or dichotomizing continuous variables is inadvisable: an example from the natural history of unruptured aneurysms</article-title><source>AJNR. American Journal of Neuroradiology</source><volume>32</volume><fpage>437</fpage><lpage>440</lpage><pub-id pub-id-type="doi">10.3174/ajnr.A2425</pub-id><pub-id pub-id-type="pmid">21330400</pub-id></element-citation></ref><ref id="bib88"><element-citation publication-type="report"><person-group person-group-type="author"><collab>National Academies of Sciences, Engineering, and Medicine</collab></person-group><year iso-8601-date="2019">2019</year><source>Reproducibility and Replicability in Science</source><publisher-loc>Washington, DC</publisher-loc><publisher-name>The National Academies Press</publisher-name></element-citation></ref><ref id="bib89"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Neter</surname><given-names>J</given-names></name><name><surname>Gorman</surname><given-names>BS</given-names></name><name><surname>Primavera</surname><given-names>LH</given-names></name><name><surname>Nachtsheim</surname><given-names>CJ</given-names></name><name><surname>Wasserman</surname><given-names>W</given-names></name></person-group><year iso-8601-date="1996">1996</year><source>Applied Linear Statistical Models</source><publisher-name>University of Florida</publisher-name></element-citation></ref><ref id="bib90"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>O’Boyle</surname><given-names>EH</given-names></name><name><surname>Banks</surname><given-names>GC</given-names></name><name><surname>Gonzalez-Mulé</surname><given-names>E</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>The chrysalis effect: How ugly initial results metamorphosize into beautiful articles</article-title><source>Journal of Management</source><volume>43</volume><fpage>376</fpage><lpage>399</lpage><pub-id pub-id-type="doi">10.1177/0149206314527133</pub-id></element-citation></ref><ref id="bib91"><element-citation publication-type="web"><person-group person-group-type="author"><name><surname>Oleszak</surname><given-names>M</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>Non-linear regression: basis expansion, polynomials &amp; splines</article-title><ext-link ext-link-type="uri" xlink:href="https://towardsdatascience.com/non-linear-regression-basis-expansion-polynomials-splines-2d7adb2cc226">https://towardsdatascience.com/non-linear-regression-basis-expansion-polynomials-splines-2d7adb2cc226</ext-link><date-in-citation iso-8601-date="2022-12-26">December 26, 2022</date-in-citation></element-citation></ref><ref id="bib92"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Pain</surname><given-names>O</given-names></name><name><surname>Dudbridge</surname><given-names>F</given-names></name><name><surname>Ronald</surname><given-names>A</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>Are your covariates under control? How normalization can re-introduce covariate effects</article-title><source>European Journal of Human Genetics</source><volume>26</volume><fpage>1194</fpage><lpage>1201</lpage><pub-id pub-id-type="doi">10.1038/s41431-018-0159-6</pub-id><pub-id pub-id-type="pmid">29706643</pub-id></element-citation></ref><ref id="bib93"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Patel</surname><given-names>CJ</given-names></name><name><surname>Burford</surname><given-names>B</given-names></name><name><surname>Ioannidis</surname><given-names>JPA</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>Assessment of vibration of effects due to model specification can demonstrate the instability of observational associations</article-title><source>Journal of Clinical Epidemiology</source><volume>68</volume><fpage>1046</fpage><lpage>1058</lpage><pub-id pub-id-type="doi">10.1016/j.jclinepi.2015.05.029</pub-id><pub-id pub-id-type="pmid">26279400</pub-id></element-citation></ref><ref id="bib94"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Pavela</surname><given-names>G</given-names></name><name><surname>Yi</surname><given-names>N</given-names></name><name><surname>Mestre</surname><given-names>L</given-names></name><name><surname>Lartey</surname><given-names>S</given-names></name><name><surname>Xun</surname><given-names>P</given-names></name><name><surname>Allison</surname><given-names>DB</given-names></name></person-group><year iso-8601-date="2022">2022</year><article-title>The associations between relative and absolute body mass index with mortality rate based on predictions from stigma theory</article-title><source>SSM - Population Health</source><volume>19</volume><elocation-id>101200</elocation-id><pub-id pub-id-type="doi">10.1016/j.ssmph.2022.101200</pub-id><pub-id pub-id-type="pmid">36033349</pub-id></element-citation></ref><ref id="bib95"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Pearl</surname><given-names>J</given-names></name></person-group><year iso-8601-date="2011">2011</year><article-title>Invited commentary: understanding bias amplification</article-title><source>American Journal of Epidemiology</source><volume>174</volume><fpage>1223</fpage><lpage>1227</lpage><pub-id pub-id-type="doi">10.1093/aje/kwr352</pub-id><pub-id pub-id-type="pmid">22034488</pub-id></element-citation></ref><ref id="bib96"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Pearl</surname><given-names>J</given-names></name><name><surname>Glymour</surname><given-names>M</given-names></name><name><surname>Jewell</surname><given-names>NP</given-names></name></person-group><year iso-8601-date="2016">2016</year><source>Causal Inference in Statistics: A Primer</source><publisher-name>John Wiley &amp; Sons</publisher-name></element-citation></ref><ref id="bib97"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Pearl</surname><given-names>J</given-names></name><name><surname>Mackenzie</surname><given-names>D</given-names></name></person-group><year iso-8601-date="2018">2018</year><source>The book of why: the new science of cause and effect</source><publisher-name>Basic books</publisher-name></element-citation></ref><ref id="bib98"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Perron</surname><given-names>L</given-names></name><name><surname>Bairati</surname><given-names>I</given-names></name><name><surname>Harel</surname><given-names>F</given-names></name><name><surname>Meyer</surname><given-names>F</given-names></name></person-group><year iso-8601-date="2004">2004</year><article-title>Antihypertensive drug use and the risk of prostate cancer (Canada)</article-title><source>Cancer Causes &amp; Control</source><volume>15</volume><fpage>535</fpage><lpage>541</lpage><pub-id pub-id-type="doi">10.1023/B:CACO.0000036152.58271.5e</pub-id></element-citation></ref><ref id="bib99"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Poongothai</surname><given-names>S</given-names></name><name><surname>Pradeepa</surname><given-names>R</given-names></name><name><surname>Ganesan</surname><given-names>A</given-names></name><name><surname>Mohan</surname><given-names>V</given-names></name></person-group><year iso-8601-date="2009">2009</year><article-title>Reliability and validity of a modified PHQ-9 item inventory (PHQ-12) as a screening instrument for assessing depression in Asian Indians (CURES-65)</article-title><source>The Journal of the Association of Physicians of India</source><volume>57</volume><fpage>147</fpage><lpage>152</lpage><pub-id pub-id-type="pmid">19582982</pub-id></element-citation></ref><ref id="bib100"><element-citation publication-type="web"><person-group person-group-type="author"><collab>Reed Education</collab></person-group><year iso-8601-date="2021">2021</year><article-title>Section 6 Functional Form and Nonlinearities</article-title><ext-link ext-link-type="uri" xlink:href="https://www.reed.edu/economics/parker/s11/312/notes/Notes6.pdf">https://www.reed.edu/economics/parker/s11/312/notes/Notes6.pdf</ext-link><date-in-citation iso-8601-date="2021-12-03">December 3, 2021</date-in-citation></element-citation></ref><ref id="bib101"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Rohrer</surname><given-names>JM</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>Thinking clearly about correlations and causation: graphical causal models for observational data</article-title><source>Advances in Methods and Practices in Psychological Science</source><volume>1</volume><fpage>27</fpage><lpage>42</lpage><pub-id pub-id-type="doi">10.1177/2515245917745629</pub-id></element-citation></ref><ref id="bib102"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Rosenbaum</surname><given-names>PR</given-names></name></person-group><year iso-8601-date="2002">2002</year><source>Sensitivity to Hidden Bias</source><publisher-name>Springer</publisher-name><pub-id pub-id-type="doi">10.1007/978-1-4757-3692-2</pub-id></element-citation></ref><ref id="bib103"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Royston</surname><given-names>P</given-names></name><name><surname>Altman</surname><given-names>DG</given-names></name></person-group><year iso-8601-date="1994">1994</year><article-title>Regression using fractional polynomials of continuous covariates: parsimonious parametric modelling</article-title><source>Applied Statistics</source><volume>43</volume><elocation-id>429</elocation-id><pub-id pub-id-type="doi">10.2307/2986270</pub-id></element-citation></ref><ref id="bib104"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Royston</surname><given-names>P</given-names></name><name><surname>Sauerbrei</surname><given-names>W</given-names></name></person-group><year iso-8601-date="2008">2008</year><source>Multivariable model-building: a pragmatic approach to regression anaylsis based on fractional polynomials for modelling continuous variables</source><publisher-name>John Wiley &amp; Sons</publisher-name><pub-id pub-id-type="doi">10.1002/9780470770771</pub-id></element-citation></ref><ref id="bib105"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Sauerbrei</surname><given-names>W</given-names></name><name><surname>Perperoglou</surname><given-names>A</given-names></name><name><surname>Schmid</surname><given-names>M</given-names></name><name><surname>Abrahamowicz</surname><given-names>M</given-names></name><name><surname>Becher</surname><given-names>H</given-names></name><name><surname>Binder</surname><given-names>H</given-names></name><name><surname>Dunkler</surname><given-names>D</given-names></name><name><surname>Harrell</surname><given-names>FE</given-names><suffix>Jr</suffix></name><name><surname>Royston</surname><given-names>P</given-names></name><name><surname>Heinze</surname><given-names>G</given-names></name><collab>for TG2 of the STRATOS initiative</collab></person-group><year iso-8601-date="2020">2020</year><article-title>State of the art in selection of variables and functional forms in multivariable analysis—outstanding issues</article-title><source>Diagnostic and Prognostic Research</source><volume>4</volume><fpage>1</fpage><lpage>18</lpage><pub-id pub-id-type="doi">10.1186/s41512-020-00074-3</pub-id></element-citation></ref><ref id="bib106"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Schmidt</surname><given-names>CO</given-names></name><name><surname>Ittermann</surname><given-names>T</given-names></name><name><surname>Schulz</surname><given-names>A</given-names></name><name><surname>Grabe</surname><given-names>HJ</given-names></name><name><surname>Baumeister</surname><given-names>SE</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>Linear, nonlinear or categorical: how to treat complex associations? Splines and nonparametric approaches</article-title><source>International Journal of Public Health</source><volume>58</volume><fpage>161</fpage><lpage>165</lpage><pub-id pub-id-type="doi">10.1007/s00038-012-0363-z</pub-id><pub-id pub-id-type="pmid">22588308</pub-id></element-citation></ref><ref id="bib107"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Shih</surname><given-names>HH</given-names></name><name><surname>Lin</surname><given-names>MJ</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>Does anxiety affect adolescent academic performance? the inverted-u hypothesis revisited</article-title><source>Journal of Labor Research</source><volume>38</volume><fpage>45</fpage><lpage>81</lpage><pub-id pub-id-type="doi">10.1007/s12122-016-9238-z</pub-id></element-citation></ref><ref id="bib108"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Simmons</surname><given-names>JP</given-names></name><name><surname>Nelson</surname><given-names>LD</given-names></name><name><surname>Simonsohn</surname><given-names>U</given-names></name></person-group><year iso-8601-date="2011">2011</year><article-title>False-positive psychology: undisclosed flexibility in data collection and analysis allows presenting anything as significant</article-title><source>Psychological Science</source><volume>22</volume><fpage>1359</fpage><lpage>1366</lpage><pub-id pub-id-type="doi">10.1177/0956797611417632</pub-id><pub-id pub-id-type="pmid">22006061</pub-id></element-citation></ref><ref id="bib109"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Simonsohn</surname><given-names>U</given-names></name><name><surname>Nelson</surname><given-names>LD</given-names></name><name><surname>Simmons</surname><given-names>JP</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>P-curve: A key to the file-drawer</article-title><source>Journal of Experimental Psychology. General</source><volume>143</volume><fpage>534</fpage><lpage>547</lpage><pub-id pub-id-type="doi">10.1037/a0033242</pub-id><pub-id pub-id-type="pmid">23855496</pub-id></element-citation></ref><ref id="bib110"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Simonsohn</surname><given-names>U</given-names></name><name><surname>Simmons</surname><given-names>JP</given-names></name><name><surname>Nelson</surname><given-names>LD</given-names></name></person-group><year iso-8601-date="2020">2020</year><article-title>Specification curve analysis</article-title><source>Nature Human Behaviour</source><volume>4</volume><fpage>1208</fpage><lpage>1214</lpage><pub-id pub-id-type="doi">10.1038/s41562-020-0912-z</pub-id><pub-id pub-id-type="pmid">32719546</pub-id></element-citation></ref><ref id="bib111"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Sjölander</surname><given-names>A</given-names></name><name><surname>Greenland</surname><given-names>S</given-names></name></person-group><year iso-8601-date="2022">2022</year><article-title>Are E-values too optimistic or too pessimistic? Both and neither!</article-title><source>International Journal of Epidemiology</source><volume>51</volume><fpage>355</fpage><lpage>363</lpage><pub-id pub-id-type="doi">10.1093/ije/dyac018</pub-id><pub-id pub-id-type="pmid">35229872</pub-id></element-citation></ref><ref id="bib112"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Steegen</surname><given-names>S</given-names></name><name><surname>Tuerlinckx</surname><given-names>F</given-names></name><name><surname>Gelman</surname><given-names>A</given-names></name><name><surname>Vanpaemel</surname><given-names>W</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Increasing transparency through a multiverse analysis</article-title><source>Perspectives on Psychological Science</source><volume>11</volume><fpage>702</fpage><lpage>712</lpage><pub-id pub-id-type="doi">10.1177/1745691616658637</pub-id><pub-id pub-id-type="pmid">27694465</pub-id></element-citation></ref><ref id="bib113"><element-citation publication-type="preprint"><person-group person-group-type="author"><name><surname>Stefan</surname><given-names>AM</given-names></name><name><surname>Schönbrodt</surname><given-names>FD</given-names></name></person-group><year iso-8601-date="2022">2022</year><article-title>Big Little Lies: A Compendium and Simulation of p-Hacking Strategies</article-title><source>PsyArXiv</source><pub-id pub-id-type="doi">10.31234/osf.io/xy2dk</pub-id></element-citation></ref><ref id="bib114"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Streeter</surname><given-names>AJ</given-names></name><name><surname>Lin</surname><given-names>NX</given-names></name><name><surname>Crathorne</surname><given-names>L</given-names></name><name><surname>Haasova</surname><given-names>M</given-names></name><name><surname>Hyde</surname><given-names>C</given-names></name><name><surname>Melzer</surname><given-names>D</given-names></name><name><surname>Henley</surname><given-names>WE</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>Adjusting for unmeasured confounding in nonrandomized longitudinal studies: a methodological review</article-title><source>Journal of Clinical Epidemiology</source><volume>87</volume><fpage>23</fpage><lpage>34</lpage><pub-id pub-id-type="doi">10.1016/j.jclinepi.2017.04.022</pub-id></element-citation></ref><ref id="bib115"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Sturman</surname><given-names>MC</given-names></name><name><surname>Sturman</surname><given-names>AJ</given-names></name><name><surname>Sturman</surname><given-names>CJ</given-names></name></person-group><year iso-8601-date="2022">2022</year><article-title>Uncontrolled control variables: The extent that a researcher’s degrees of freedom with control variables increases various types of statistical errors</article-title><source>The Journal of Applied Psychology</source><volume>107</volume><fpage>9</fpage><lpage>22</lpage><pub-id pub-id-type="doi">10.1037/apl0000849</pub-id><pub-id pub-id-type="pmid">33661656</pub-id></element-citation></ref><ref id="bib116"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Tekwe</surname><given-names>CD</given-names></name><name><surname>Carter</surname><given-names>RL</given-names></name><name><surname>Cullings</surname><given-names>HM</given-names></name><name><surname>Carroll</surname><given-names>RJ</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>Multiple indicators, multiple causes measurement error models</article-title><source>Statistics in Medicine</source><volume>33</volume><fpage>4469</fpage><lpage>4481</lpage><pub-id pub-id-type="doi">10.1002/sim.6243</pub-id><pub-id pub-id-type="pmid">24962535</pub-id></element-citation></ref><ref id="bib117"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Tekwe</surname><given-names>CD</given-names></name><name><surname>Carter</surname><given-names>RL</given-names></name><name><surname>Cullings</surname><given-names>HM</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Generalized multiple indicators, multiple causes measurement error models</article-title><source>Statistical Modelling</source><volume>16</volume><fpage>140</fpage><lpage>159</lpage><pub-id pub-id-type="doi">10.1177/1471082X16638478</pub-id></element-citation></ref><ref id="bib118"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Tekwe</surname><given-names>CD</given-names></name><name><surname>Zoh</surname><given-names>RS</given-names></name><name><surname>Bazer</surname><given-names>FW</given-names></name><name><surname>Wu</surname><given-names>G</given-names></name><name><surname>Carroll</surname><given-names>RJ</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>Functional multiple indicators, multiple causes measurement error models</article-title><source>Biometrics</source><volume>74</volume><fpage>127</fpage><lpage>134</lpage><pub-id pub-id-type="doi">10.1111/biom.12706</pub-id><pub-id pub-id-type="pmid">28482110</pub-id></element-citation></ref><ref id="bib119"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Tekwe</surname><given-names>CD</given-names></name><name><surname>Zoh</surname><given-names>RS</given-names></name><name><surname>Yang</surname><given-names>M</given-names></name><name><surname>Carroll</surname><given-names>RJ</given-names></name><name><surname>Honvoh</surname><given-names>G</given-names></name><name><surname>Allison</surname><given-names>DB</given-names></name><name><surname>Benden</surname><given-names>M</given-names></name><name><surname>Xue</surname><given-names>L</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>Instrumental variable approach to estimating the scalar-on-function regression model with measurement error with application to energy expenditure assessment in childhood obesity</article-title><source>Statistics in Medicine</source><volume>38</volume><fpage>3764</fpage><lpage>3781</lpage><pub-id pub-id-type="doi">10.1002/sim.8179</pub-id><pub-id pub-id-type="pmid">31222793</pub-id></element-citation></ref><ref id="bib120"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Textor</surname><given-names>J</given-names></name><name><surname>van der Zander</surname><given-names>B</given-names></name><name><surname>Gilthorpe</surname><given-names>MS</given-names></name><name><surname>Liskiewicz</surname><given-names>M</given-names></name><name><surname>Ellison</surname><given-names>GT</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Robust causal inference using directed acyclic graphs: the R package “dagitty.”</article-title><source>International Journal of Epidemiology</source><volume>45</volume><fpage>1887</fpage><lpage>1894</lpage><pub-id pub-id-type="doi">10.1093/ije/dyw341</pub-id><pub-id pub-id-type="pmid">28089956</pub-id></element-citation></ref><ref id="bib121"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Tosteson</surname><given-names>TD</given-names></name><name><surname>Buonaccorsi</surname><given-names>JP</given-names></name><name><surname>Demidenko</surname><given-names>E</given-names></name></person-group><year iso-8601-date="1998">1998</year><article-title>Covariate measurement error and the estimation of random effect parameters in a mixed model for longitudinal data</article-title><source>Statistics in Medicine</source><volume>17</volume><fpage>1959</fpage><lpage>1971</lpage><pub-id pub-id-type="doi">10.1002/(sici)1097-0258(19980915)17:17&lt;1959::aid-sim886&gt;3.0.co;2-f</pub-id><pub-id pub-id-type="pmid">9777689</pub-id></element-citation></ref><ref id="bib122"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Tukey</surname><given-names>JW</given-names></name></person-group><year iso-8601-date="1962">1962</year><article-title>The future of data analysis</article-title><source>The Annals of Mathematical Statistics</source><volume>33</volume><fpage>1</fpage><lpage>67</lpage><pub-id pub-id-type="doi">10.1214/aoms/1177704711</pub-id></element-citation></ref><ref id="bib123"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>VanderWeele</surname><given-names>TJ</given-names></name><name><surname>Shpitser</surname><given-names>I</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>On the definition of a confounder</article-title><source>Annals of Statistics</source><volume>41</volume><fpage>196</fpage><lpage>220</lpage><pub-id pub-id-type="doi">10.1214/12-aos1058</pub-id><pub-id pub-id-type="pmid">25544784</pub-id></element-citation></ref><ref id="bib124"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>VanderWeele</surname><given-names>TJ</given-names></name><name><surname>Vansteelandt</surname><given-names>S</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>Mediation analysis with multiple mediators</article-title><source>Epidemiologic Methods</source><volume>2</volume><fpage>95</fpage><lpage>115</lpage><pub-id pub-id-type="doi">10.1515/em-2012-0010</pub-id><pub-id pub-id-type="pmid">25580377</pub-id></element-citation></ref><ref id="bib125"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>VanderWeele</surname><given-names>TJ</given-names></name><name><surname>Ding</surname><given-names>P</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>Sensitivity analysis in observational research: introducing the E-Value</article-title><source>Annals of Internal Medicine</source><volume>167</volume><fpage>268</fpage><lpage>274</lpage><pub-id pub-id-type="doi">10.7326/M16-2607</pub-id><pub-id pub-id-type="pmid">28693043</pub-id></element-citation></ref><ref id="bib126"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>VanderWeele</surname><given-names>TJ</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>Principles of confounder selection</article-title><source>European Journal of Epidemiology</source><volume>34</volume><fpage>211</fpage><lpage>219</lpage><pub-id pub-id-type="doi">10.1007/s10654-019-00494-6</pub-id><pub-id pub-id-type="pmid">30840181</pub-id></element-citation></ref><ref id="bib127"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Veiel</surname><given-names>HO</given-names></name></person-group><year iso-8601-date="1988">1988</year><article-title>Base-rates, cut-points and interaction effects: the problem with dichotomized continuous variables</article-title><source>Psychological Medicine</source><volume>18</volume><fpage>703</fpage><lpage>710</lpage><pub-id pub-id-type="doi">10.1017/s0033291700008394</pub-id><pub-id pub-id-type="pmid">3186870</pub-id></element-citation></ref><ref id="bib128"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Westfall</surname><given-names>J</given-names></name><name><surname>Yarkoni</surname><given-names>T</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Statistically controlling for confounding constructs is harder than you think</article-title><source>PLOS ONE</source><volume>11</volume><elocation-id>e0152719</elocation-id><pub-id pub-id-type="doi">10.1371/journal.pone.0152719</pub-id><pub-id pub-id-type="pmid">27031707</pub-id></element-citation></ref><ref id="bib129"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wicherts</surname><given-names>JM</given-names></name><name><surname>Veldkamp</surname><given-names>CLS</given-names></name><name><surname>Augusteijn</surname><given-names>HEM</given-names></name><name><surname>Bakker</surname><given-names>M</given-names></name><name><surname>van Aert</surname><given-names>RCM</given-names></name><name><surname>van Assen</surname><given-names>MALM</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Degrees of freedom in planning, running, analyzing, and reporting psychological studies: a checklist to avoid <italic>p</italic>-Hacking</article-title><source>Frontiers in Psychology</source><volume>7</volume><elocation-id>1832</elocation-id><pub-id pub-id-type="doi">10.3389/fpsyg.2016.01832</pub-id><pub-id pub-id-type="pmid">27933012</pub-id></element-citation></ref><ref id="bib130"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Yang</surname><given-names>S</given-names></name><name><surname>Wang</surname><given-names>L</given-names></name><name><surname>Ding</surname><given-names>P</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>Causal inference with confounders missing not at random</article-title><source>Biometrika</source><volume>106</volume><fpage>875</fpage><lpage>888</lpage><pub-id pub-id-type="doi">10.1093/biomet/asz048</pub-id></element-citation></ref><ref id="bib131"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Yi</surname><given-names>GY</given-names></name><name><surname>Ma</surname><given-names>Y</given-names></name><name><surname>Carroll</surname><given-names>RJ</given-names></name></person-group><year iso-8601-date="2012">2012</year><article-title>A functional generalized method of moments approach for longitudinal studies with missing responses and covariate measurement error</article-title><source>Biometrika</source><volume>99</volume><fpage>151</fpage><lpage>165</lpage><pub-id pub-id-type="doi">10.1093/biomet/asr076</pub-id><pub-id pub-id-type="pmid">28781377</pub-id></element-citation></ref><ref id="bib132"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Yland</surname><given-names>JJ</given-names></name><name><surname>Wesselink</surname><given-names>AK</given-names></name><name><surname>Lash</surname><given-names>TL</given-names></name><name><surname>Fox</surname><given-names>MP</given-names></name></person-group><year iso-8601-date="2022">2022</year><article-title>Misconceptions about misclassification: non-differential misclassification does not always bias results toward the null</article-title><source>American Journal of Epidemiology</source><volume>191</volume><fpage>1485</fpage><lpage>1495</lpage><pub-id pub-id-type="doi">10.1093/aje/kwac035</pub-id></element-citation></ref></ref-list><app-group><app id="appendix-1"><title>Appendix 1</title><sec sec-type="appendix" id="s16"><title>Misperception 9. Excluding a covariate that is not associated with the outcome of interest does not affect the association of the IV with the outcome</title><p>Consider a simple causal model depicted in <xref ref-type="fig" rid="app1fig1">Appendix 1—figure 1</xref> (<xref ref-type="fig" rid="fig2">Figure 2</xref> in the main text). At the left side of <xref ref-type="fig" rid="app1fig1">Appendix 1—figure 1</xref>, we have a variable that is the degree of one’s belief that dietary fat consumption is not dangerous or, conceived alternatively, one minus the strength of belief that dietary fat consumption is dangerous or should be avoided. Suppose this variable relates to dietary consumption of two kinds of dietary fats, and , where dietary fat of type A decreases some health outcome of interest (i.e. is harmful). In contrast, dietary fat of type B decreases the negative health outcome (i.e. is helpful).</p><p>We can use the following linear model to describe the causal effects in <xref ref-type="fig" rid="app1fig1">Appendix 1—figure 1</xref>:<disp-formula id="equ1"><label>(1)</label><mml:math id="m1"><mml:mrow><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msub><mml:mi>M</mml:mi><mml:mrow><mml:mi>F</mml:mi></mml:mrow></mml:msub><mml:mo>:</mml:mo><mml:mi>Y</mml:mi><mml:mo>=</mml:mo><mml:msub><mml:mi>β</mml:mi><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mi>β</mml:mi><mml:mrow><mml:mi>A</mml:mi></mml:mrow></mml:msub><mml:msub><mml:mi>X</mml:mi><mml:mrow><mml:mi>A</mml:mi></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mi>β</mml:mi><mml:mrow><mml:mi>B</mml:mi></mml:mrow></mml:msub><mml:msub><mml:mi>X</mml:mi><mml:mrow><mml:mi>B</mml:mi></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:mi>ϵ</mml:mi></mml:mstyle></mml:mrow></mml:math></disp-formula></p><p>where Y is the response variable, <inline-formula><mml:math id="inf9"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>X</mml:mi><mml:mi>A</mml:mi></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula> and <inline-formula><mml:math id="inf10"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>X</mml:mi><mml:mi>B</mml:mi></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula> are IVs representing the fat consumptions of dietary fat types <italic>A</italic> and <italic>B</italic>, respectively, and ε is an independent error term with the variance <inline-formula><mml:math id="inf11"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msubsup><mml:mi>σ</mml:mi><mml:mrow><mml:mi>ε</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup></mml:mrow></mml:mstyle></mml:math></inline-formula> . Of the two covariates, we suppose <italic>X</italic><sub><italic>A</italic></sub> is the exposure of interest that is correlated with <italic>Y</italic> and <italic>X<sub>B</sub></italic> is a confounding variable that is correlated with <italic>Y</italic>, resulting in the correlations <inline-formula><mml:math id="inf12"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>ρ</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>X</mml:mi><mml:mi>A</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:mi>Y</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>≠</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:mstyle></mml:math></inline-formula>, <inline-formula><mml:math id="inf13"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>ρ</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>X</mml:mi><mml:mi>B</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:mi>Y</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:mstyle></mml:math></inline-formula>, respectively. Following the causal diagram in <xref ref-type="fig" rid="app1fig1">Appendix 1—figure 1</xref>, we generate <italic>X<sub>A</sub></italic> and <italic>X<sub>B</sub></italic> from a latent variable Z, where<disp-formula id="equ2"><mml:math id="m2"><mml:mrow><mml:mtable columnalign="center center" rowspacing="4pt" columnspacing="1em"><mml:mtr><mml:mtd><mml:msub><mml:mi>X</mml:mi><mml:mrow><mml:mi>A</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:msub><mml:mi>λ</mml:mi><mml:mrow><mml:mi>A</mml:mi></mml:mrow></mml:msub><mml:mi>Z</mml:mi><mml:mo>+</mml:mo><mml:mi>η</mml:mi></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:msub><mml:mi>X</mml:mi><mml:mrow><mml:mi>B</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:msub><mml:mi>λ</mml:mi><mml:mrow><mml:mi>B</mml:mi></mml:mrow></mml:msub><mml:mi>Z</mml:mi><mml:mo>+</mml:mo><mml:mi>γ</mml:mi></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:math></disp-formula></p><p>where <inline-formula><mml:math id="inf14"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>λ</mml:mi><mml:mrow><mml:mi>A</mml:mi></mml:mrow></mml:msub><mml:mo>≠</mml:mo><mml:mi>o</mml:mi><mml:mo>,</mml:mo><mml:msub><mml:mi>λ</mml:mi><mml:mrow><mml:mi>B</mml:mi></mml:mrow></mml:msub><mml:mo>≠</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:mstyle></mml:math></inline-formula> and <italic>η</italic> and <italic>γ</italic> are independent error terms with variances <inline-formula><mml:math id="inf15"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msubsup><mml:mi>σ</mml:mi><mml:mrow><mml:mi>η</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup></mml:mrow></mml:mstyle></mml:math></inline-formula> and <inline-formula><mml:math id="inf16"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msubsup><mml:mi>σ</mml:mi><mml:mrow><mml:mi>γ</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup></mml:mrow></mml:mstyle></mml:math></inline-formula>, respectively. Without loss of generality, we assume that variables <italic>X<sub>A</sub></italic>, <italic>X<sub>B</sub></italic>, and <italic>Z</italic> have been standardized to unit variance, and the additional regression parameters are chosen so that the <italic>Y</italic> also has unit variance. This then implies the causal effects <inline-formula><mml:math id="inf17"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>ρ</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>Y</mml:mi><mml:mo>,</mml:mo><mml:msub><mml:mi>X</mml:mi><mml:mrow><mml:mi>A</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:msub><mml:mi>β</mml:mi><mml:mrow><mml:mi>A</mml:mi></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mi>β</mml:mi><mml:mrow><mml:mi>A</mml:mi></mml:mrow></mml:msub><mml:msub><mml:mi>λ</mml:mi><mml:mrow><mml:mi>A</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>λ</mml:mi><mml:mrow><mml:mi>B</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula>, <inline-formula><mml:math id="inf18"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>ρ</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>Y</mml:mi><mml:mo>,</mml:mo><mml:msub><mml:mi>X</mml:mi><mml:mrow><mml:mi>B</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:msub><mml:mi>β</mml:mi><mml:mrow><mml:mi>B</mml:mi></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mi>β</mml:mi><mml:mrow><mml:mi>A</mml:mi></mml:mrow></mml:msub><mml:msub><mml:mi>λ</mml:mi><mml:mrow><mml:mi>A</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>λ</mml:mi><mml:mrow><mml:mi>B</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula>, and <inline-formula><mml:math id="inf19"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>ρ</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>X</mml:mi><mml:mrow><mml:mi>A</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>X</mml:mi><mml:mrow><mml:mi>B</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:msub><mml:mi>λ</mml:mi><mml:mrow><mml:mi>A</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>λ</mml:mi><mml:mrow><mml:mi>B</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula> <sub><italic>.</italic></sub></p><p>Consider the following reduced model where the confounding variable, <italic>X<sub>B</sub></italic>, is excluded from the full model (1):<disp-formula id="equ3"><label>(2)</label><mml:math id="m3"><mml:mrow><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msub><mml:mi>M</mml:mi><mml:mrow><mml:mi>R</mml:mi></mml:mrow></mml:msub><mml:mo>:</mml:mo><mml:mi>Y</mml:mi><mml:mo>=</mml:mo><mml:msub><mml:mi>β</mml:mi><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mi>β</mml:mi><mml:mrow><mml:mi>A</mml:mi></mml:mrow></mml:msub><mml:msub><mml:mi>X</mml:mi><mml:mi>A</mml:mi></mml:msub><mml:mo>+</mml:mo><mml:mi>ε</mml:mi></mml:mstyle></mml:mrow></mml:math></disp-formula></p><p>and <inline-formula><mml:math id="inf20"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>ε</mml:mi><mml:mo>≡</mml:mo><mml:msub><mml:mi>β</mml:mi><mml:mrow><mml:mi>B</mml:mi></mml:mrow></mml:msub><mml:msub><mml:mi>X</mml:mi><mml:mrow><mml:mi>B</mml:mi></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:mi>ε</mml:mi></mml:mrow></mml:mstyle></mml:math></inline-formula>. The least-squares estimate for <italic>β</italic><sub><italic>A</italic></sub> under the reduced model (2) is<disp-formula id="equ4"><mml:math id="m4"><mml:mrow><mml:mtable columnalign="center center" rowspacing="4pt" columnspacing="1em"><mml:mtr><mml:mtd><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msub><mml:mrow><mml:mover><mml:mi>β</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>A</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mi>C</mml:mi><mml:mi>o</mml:mi><mml:mi>v</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>Y</mml:mi><mml:mo>,</mml:mo><mml:msub><mml:mi>X</mml:mi><mml:mi>A</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mrow><mml:mi>V</mml:mi><mml:mi>a</mml:mi><mml:mi>r</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>X</mml:mi><mml:mi>A</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mfrac></mml:mstyle></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mo>=</mml:mo><mml:mi>C</mml:mi><mml:mi>o</mml:mi><mml:mi>v</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>β</mml:mi><mml:mn>0</mml:mn></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mi>β</mml:mi><mml:mi>A</mml:mi></mml:msub><mml:msub><mml:mi>X</mml:mi><mml:mi>A</mml:mi></mml:msub><mml:mo>+</mml:mo><mml:msup><mml:mi>ϵ</mml:mi><mml:mo>∗</mml:mo></mml:msup><mml:mo>,</mml:mo><mml:msub><mml:mi>X</mml:mi><mml:mi>A</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mstyle></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mo>=</mml:mo><mml:msub><mml:mi>β</mml:mi><mml:mi>A</mml:mi></mml:msub><mml:mo>+</mml:mo><mml:mi>C</mml:mi><mml:mi>o</mml:mi><mml:mi>v</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msup><mml:mi>ϵ</mml:mi><mml:mo>∗</mml:mo></mml:msup><mml:mo>,</mml:mo><mml:msub><mml:mi>X</mml:mi><mml:mi>A</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mo>=</mml:mo><mml:msub><mml:mi>β</mml:mi><mml:mi>A</mml:mi></mml:msub><mml:mo>+</mml:mo><mml:mi>C</mml:mi><mml:mi>o</mml:mi><mml:mi>v</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>β</mml:mi><mml:mi>B</mml:mi></mml:msub><mml:msub><mml:mi>X</mml:mi><mml:mi>B</mml:mi></mml:msub><mml:mo>+</mml:mo><mml:mi>ϵ</mml:mi><mml:mo>,</mml:mo><mml:msub><mml:mi>X</mml:mi><mml:mi>A</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mstyle></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mo>=</mml:mo><mml:msub><mml:mi>β</mml:mi><mml:mi>A</mml:mi></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mi>β</mml:mi><mml:mi>B</mml:mi></mml:msub><mml:mi>C</mml:mi><mml:mi>o</mml:mi><mml:mi>v</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>X</mml:mi><mml:mi>B</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>X</mml:mi><mml:mi>A</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mstyle></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mo>=</mml:mo><mml:msub><mml:mi>β</mml:mi><mml:mi>A</mml:mi></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mi>β</mml:mi><mml:mi>B</mml:mi></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mi>λ</mml:mi><mml:mi>A</mml:mi></mml:msub><mml:msub><mml:mi>λ</mml:mi><mml:mi>B</mml:mi></mml:msub></mml:mstyle></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:math></disp-formula></p><p>Under the assumption that <inline-formula><mml:math id="inf21"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>ρ</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>Y</mml:mi><mml:mo>,</mml:mo><mml:msub><mml:mi>X</mml:mi><mml:mi>B</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:mstyle></mml:math></inline-formula>, we have <inline-formula><mml:math id="inf22"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>β</mml:mi><mml:mi>B</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mo>−</mml:mo><mml:msub><mml:mi>β</mml:mi><mml:mi>A</mml:mi></mml:msub><mml:msub><mml:mi>λ</mml:mi><mml:mi>A</mml:mi></mml:msub><mml:msub><mml:mi>λ</mml:mi><mml:mi>B</mml:mi></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula>. Plugging this into equation <inline-formula><mml:math id="inf23"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mrow><mml:mover><mml:mi>β</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mi>A</mml:mi></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula>, we have<disp-formula id="equ5"><mml:math id="m5"><mml:mrow><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msub><mml:mrow><mml:mover><mml:mi>β</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mi>A</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:msub><mml:mi>β</mml:mi><mml:mi>A</mml:mi></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mi>β</mml:mi><mml:mi>A</mml:mi></mml:msub><mml:msub><mml:mi>λ</mml:mi><mml:mi>A</mml:mi></mml:msub><mml:msub><mml:mi>λ</mml:mi><mml:mi>B</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:msub><mml:mi>β</mml:mi><mml:mi>A</mml:mi></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:msubsup><mml:mi>λ</mml:mi><mml:mrow><mml:mi>A</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup><mml:mo>+</mml:mo><mml:msubsup><mml:mi>λ</mml:mi><mml:mrow><mml:mi>B</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup><mml:mo stretchy="false">)</mml:mo><mml:mo>≠</mml:mo><mml:msub><mml:mi>β</mml:mi><mml:mi>A</mml:mi></mml:msub></mml:mstyle></mml:mrow></mml:math></disp-formula></p><p>Since <inline-formula><mml:math id="inf24"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>λ</mml:mi><mml:mi>A</mml:mi></mml:msub><mml:mo>≠</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:mstyle></mml:math></inline-formula>, <inline-formula><mml:math id="inf25"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>λ</mml:mi><mml:mi>B</mml:mi></mml:msub><mml:mo>≠</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:mstyle></mml:math></inline-formula>. The above derivation demonstrates that omitted variable bias cannot be avoided under the imposed assumption in the causal model of <xref ref-type="fig" rid="app1fig1">Appendix 1—figure 1</xref>. However, those requirements contradict the imposed assumption in the causal model of <xref ref-type="fig" rid="app1fig1">Appendix 1—figure 1</xref> indicating that the omitted variable bias cannot be avoided.</p><p>Despite the theoretical justification, we conducted simulation studies to illustrate our points. To generate simulated data under the imposed assumptions, we select regression parameters following the restrictions:<disp-formula id="equ6"><label>(3)</label><mml:math id="m6"><mml:mrow><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msub><mml:mi>β</mml:mi><mml:mi>A</mml:mi></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mi>β</mml:mi><mml:mi>B</mml:mi></mml:msub><mml:msub><mml:mi>λ</mml:mi><mml:mi>A</mml:mi></mml:msub><mml:msub><mml:mi>λ</mml:mi><mml:mi>B</mml:mi></mml:msub><mml:mo>≠</mml:mo><mml:mn>0</mml:mn></mml:mstyle></mml:mrow></mml:math></disp-formula><disp-formula id="equ7"><label>(4)</label><mml:math id="m7"><mml:mrow><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msub><mml:mi>β</mml:mi><mml:mi>B</mml:mi></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mi>β</mml:mi><mml:mi>A</mml:mi></mml:msub><mml:msub><mml:mi>λ</mml:mi><mml:mi>A</mml:mi></mml:msub><mml:msub><mml:mi>λ</mml:mi><mml:mi>B</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mn>0</mml:mn></mml:mstyle></mml:mrow></mml:math></disp-formula><disp-formula id="equ8"><label>(5)</label><mml:math id="m8"><mml:mrow><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msubsup><mml:mi>λ</mml:mi><mml:mrow><mml:mi>A</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup><mml:mo>+</mml:mo><mml:msubsup><mml:mi>σ</mml:mi><mml:mrow><mml:mi>η</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mstyle></mml:mrow></mml:math></disp-formula><disp-formula id="equ9"><label>(6)</label><mml:math id="m9"><mml:mrow><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msubsup><mml:mi>λ</mml:mi><mml:mrow><mml:mi>B</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup><mml:mo>+</mml:mo><mml:msubsup><mml:mi>σ</mml:mi><mml:mrow><mml:mi>γ</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mstyle></mml:mrow></mml:math></disp-formula><disp-formula id="equ10"><label>(7)</label><mml:math id="m10"><mml:mrow><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msubsup><mml:mi>β</mml:mi><mml:mrow><mml:mi>A</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup><mml:mo>+</mml:mo><mml:msubsup><mml:mi>β</mml:mi><mml:mrow><mml:mi>B</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup><mml:mo>+</mml:mo><mml:msubsup><mml:mi>σ</mml:mi><mml:mrow><mml:mi>ϵ</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup><mml:mo>+</mml:mo><mml:mn>2</mml:mn><mml:msub><mml:mi>β</mml:mi><mml:mrow><mml:mi>A</mml:mi></mml:mrow></mml:msub><mml:msub><mml:mi>β</mml:mi><mml:mrow><mml:mi>B</mml:mi></mml:mrow></mml:msub><mml:msub><mml:mi>λ</mml:mi><mml:mi>A</mml:mi></mml:msub><mml:msub><mml:mi>λ</mml:mi><mml:mi>B</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mstyle></mml:mrow></mml:math></disp-formula></p><p>where restrictions (5), (6), and (7) are required to have <inline-formula><mml:math id="inf26"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>V</mml:mi><mml:mi>a</mml:mi><mml:mi>r</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>X</mml:mi><mml:mi>A</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:mstyle></mml:math></inline-formula>, <inline-formula><mml:math id="inf27"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>V</mml:mi><mml:mi>a</mml:mi><mml:mi>r</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>X</mml:mi><mml:mi>B</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:mstyle></mml:math></inline-formula>, and <inline-formula><mml:math id="inf28"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>V</mml:mi><mml:mi>a</mml:mi><mml:mi>r</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>Y</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:mstyle></mml:math></inline-formula>, respectively. Plugging (5) and (6) into (3) yields <inline-formula><mml:math id="inf29"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msubsup><mml:mi>σ</mml:mi><mml:mrow><mml:mi>γ</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup><mml:mo>+</mml:mo><mml:msubsup><mml:mi>σ</mml:mi><mml:mrow><mml:mi>η</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup><mml:mo>−</mml:mo><mml:msubsup><mml:mi>σ</mml:mi><mml:mrow><mml:mi>γ</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup><mml:msubsup><mml:mi>σ</mml:mi><mml:mrow><mml:mi>η</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup><mml:mo>≠</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:mstyle></mml:math></inline-formula>. We consider simulation settings based on the parameter specifications presented in <xref ref-type="table" rid="app1table1">Appendix 1—table 1</xref>, where variables <inline-formula><mml:math id="inf30"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>Z</mml:mi><mml:mo>,</mml:mo><mml:mi>ε</mml:mi><mml:mo>,</mml:mo><mml:mi>η</mml:mi></mml:mrow></mml:mstyle></mml:math></inline-formula>, and γ were generated from independent normal distributions with zero means. For all scenarios considered, the empirical Pearson’s correlations between <inline-formula><mml:math id="inf31"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>Y</mml:mi></mml:mrow></mml:mstyle></mml:math></inline-formula> and <inline-formula><mml:math id="inf32"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>X</mml:mi><mml:mi>B</mml:mi></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula> are close to zero. With the simulated data, we examined the bias of least-squares estimator for <inline-formula><mml:math id="inf33"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>β</mml:mi><mml:mi>A</mml:mi></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula> under the full model of (1) and the reduced model (2). With 10,000 replications and three levels of sample sizes <inline-formula><mml:math id="inf34"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi mathvariant="normal">n</mml:mi><mml:mspace width="thinmathspace"/><mml:mi>ϵ</mml:mi><mml:mrow><mml:mo>{</mml:mo><mml:mrow><mml:mn>500</mml:mn><mml:mo>,</mml:mo><mml:mn>1000</mml:mn><mml:mo>,</mml:mo><mml:mn>2000</mml:mn></mml:mrow><mml:mo>}</mml:mo></mml:mrow></mml:mrow></mml:mstyle></mml:math></inline-formula>, the summary of bias is presented in <xref ref-type="table" rid="app1table2">Appendix 1—table 2</xref>. As expected, the bias of <inline-formula><mml:math id="inf35"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>β</mml:mi><mml:mi>A</mml:mi></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula> is virtually zero when controlling for <inline-formula><mml:math id="inf36"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>X</mml:mi><mml:mi>B</mml:mi></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula> in the full model. On the contrary, failing to control for <inline-formula><mml:math id="inf37"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>X</mml:mi><mml:mi>B</mml:mi></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula> in the model, one would mistakenly estimate the causal effect between <inline-formula><mml:math id="inf38"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>X</mml:mi><mml:mi>A</mml:mi></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula> and <inline-formula><mml:math id="inf39"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>Y</mml:mi></mml:mrow></mml:mstyle></mml:math></inline-formula> resulting in a bias that agrees closely to <inline-formula><mml:math id="inf40"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>β</mml:mi><mml:mi>A</mml:mi></mml:msub><mml:msub><mml:mi>λ</mml:mi><mml:mi>A</mml:mi></mml:msub><mml:msub><mml:mi>λ</mml:mi><mml:mi>B</mml:mi></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula><italic><sub>.</sub></italic> Our simulation results confirm that excluding confounding variables from the model could bias the coefficient estimates, hence introducing omitted variable biases. In addition, our results dispute the premise that a covariate that is uncorrelated with the outcome cannot be biasing the results of an association test between another variable and the outcome as an indicator of a causal effect and disputes the premise we began with. Whereas in the psychometrics literature such patterns have usually been termed <italic>suppressor effects</italic>, in a nutrition epidemiology paper they were referred to as <italic>negative confounders</italic> (<xref ref-type="bibr" rid="bib31">Choi et al., 2008</xref>).</p><table-wrap id="app1table1" position="float"><label>Appendix 1—table 1.</label><caption><title>Parameters used to generate simulated data for the simulation studies under Misperception 9.</title></caption><table frame="hsides" rules="groups"><thead><tr><th align="left" valign="bottom">Scenario</th><th align="left" valign="bottom">β<sub>A</sub></th><th align="left" valign="bottom"><italic>β</italic><sub><italic>B</italic></sub></th><th align="left" valign="bottom"><italic>λ</italic><sub><italic>A</italic></sub></th><th align="left" valign="bottom"><italic>λ</italic><sub><italic>B</italic></sub></th><th align="left" valign="bottom"><inline-formula><mml:math id="inf41"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msubsup><mml:mi>σ</mml:mi><mml:mrow><mml:mi>ϵ</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup></mml:mrow></mml:mstyle></mml:math></inline-formula></th><th align="left" valign="bottom"><inline-formula><mml:math id="inf42"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msubsup><mml:mi>σ</mml:mi><mml:mrow><mml:mi>η</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup></mml:mrow></mml:mstyle></mml:math></inline-formula></th><th align="left" valign="bottom"><inline-formula><mml:math id="inf43"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msubsup><mml:mi>σ</mml:mi><mml:mrow><mml:mi>γ</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup></mml:mrow></mml:mstyle></mml:math></inline-formula></th></tr></thead><tbody><tr><td align="left" valign="bottom">I</td><td align="left" valign="bottom">–0.4</td><td align="left" valign="bottom">0.3</td><td align="left" valign="bottom"><inline-formula><mml:math id="inf44"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msqrt><mml:mn>3</mml:mn></mml:msqrt><mml:mrow><mml:mo>/</mml:mo></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:mrow></mml:mstyle></mml:math></inline-formula></td><td align="left" valign="bottom"><inline-formula><mml:math id="inf45"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msqrt><mml:mn>3</mml:mn></mml:msqrt><mml:mrow><mml:mo>/</mml:mo></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:mrow></mml:mstyle></mml:math></inline-formula></td><td align="left" valign="bottom">0.93</td><td align="left" valign="bottom">0.25</td><td align="left" valign="bottom">0.25</td></tr><tr><td align="left" valign="bottom">II</td><td align="left" valign="bottom">0.4</td><td align="left" valign="bottom">–0.3</td><td align="left" valign="bottom"><inline-formula><mml:math id="inf46"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msqrt><mml:mn>3</mml:mn></mml:msqrt><mml:mrow><mml:mo>/</mml:mo></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:mrow></mml:mstyle></mml:math></inline-formula></td><td align="left" valign="bottom"><inline-formula><mml:math id="inf47"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msqrt><mml:mn>3</mml:mn></mml:msqrt><mml:mrow><mml:mo>/</mml:mo></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:mrow></mml:mstyle></mml:math></inline-formula></td><td align="left" valign="bottom">0.93</td><td align="left" valign="bottom">0.25</td><td align="left" valign="bottom">0.25</td></tr><tr><td align="left" valign="bottom">III</td><td align="left" valign="bottom">–0.5</td><td align="left" valign="bottom">0.24</td><td align="left" valign="bottom">0.8</td><td align="left" valign="bottom">0.6</td><td align="left" valign="bottom">0.8076</td><td align="left" valign="bottom">0.36</td><td align="left" valign="bottom">0.64</td></tr><tr><td align="left" valign="bottom">IV</td><td align="left" valign="bottom">0.5</td><td align="left" valign="bottom">–0.24</td><td align="left" valign="bottom">0.8</td><td align="left" valign="bottom">0.6</td><td align="left" valign="bottom">0.8076</td><td align="left" valign="bottom">0.36</td><td align="left" valign="bottom">0.64</td></tr></tbody></table></table-wrap><table-wrap id="app1table2" position="float"><label>Appendix 1—table 2.</label><caption><title>Summary of bias when fitting the full model (𝑀<sub>𝐹</sub>) and the reduced model (<italic>M</italic><sub><italic>R</italic></sub>).</title><p>The bias is defined as <inline-formula><mml:math id="inf48"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mrow><mml:mover><mml:mi>β</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mo>−</mml:mo><mml:msub><mml:mi>β</mml:mi><mml:mi>A</mml:mi></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula>, where <inline-formula><mml:math id="inf49"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mrow><mml:mover><mml:mi>β</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow></mml:mrow></mml:mstyle></mml:math></inline-formula> is the least-squares estimate under the corresponding model.</p></caption><table frame="hsides" rules="groups"><thead><tr><th align="left" valign="bottom">Scenario</th><th align="left" valign="bottom" colspan="2">n=500</th><th align="left" valign="bottom" colspan="2">n=1000</th><th align="left" valign="bottom" colspan="2">n=2000</th></tr></thead><tbody><tr><td align="left" valign="bottom"/><td align="left" valign="bottom"><italic>M</italic><sub><italic>F</italic></sub></td><td align="left" valign="bottom"><italic>M</italic><sub><italic>R</italic></sub></td><td align="left" valign="bottom"><italic>M</italic><sub><italic>F</italic></sub></td><td align="left" valign="bottom"><italic>M</italic><sub><italic>R</italic></sub></td><td align="left" valign="bottom"><italic>M<sub>F</sub></italic></td><td align="left" valign="bottom"><italic>M</italic><sub><italic>R</italic></sub></td></tr><tr><td align="left" valign="bottom">I</td><td align="char" char="." valign="bottom">–0.0007</td><td align="char" char="." valign="bottom">0.2248</td><td align="char" char="." valign="bottom">0.0001</td><td align="char" char="." valign="bottom">0.2251</td><td align="char" char="." valign="bottom">–0.0001</td><td align="char" char="." valign="bottom">0.2249</td></tr><tr><td align="left" valign="bottom">II</td><td align="char" char="." valign="bottom">0.0005</td><td align="char" char="." valign="bottom">–0.2249</td><td align="char" char="." valign="bottom">0.0003</td><td align="char" char="." valign="bottom">–0.2249</td><td align="char" char="." valign="bottom">0.0002</td><td align="char" char="." valign="bottom">–0.2248</td></tr><tr><td align="left" valign="bottom">III</td><td align="char" char="." valign="bottom">–0.0001</td><td align="char" char="." valign="bottom">0.24</td><td align="char" char="." valign="bottom">0.0003</td><td align="char" char="." valign="bottom">0.2405</td><td align="char" char="." valign="bottom">–0.0003</td><td align="char" char="." valign="bottom">0.2399</td></tr><tr><td align="left" valign="bottom">IV</td><td align="char" char="." valign="bottom">0.0004</td><td align="char" char="." valign="bottom">–0.2396</td><td align="char" char="." valign="bottom">–0.0002</td><td align="char" char="." valign="bottom">–0.24</td><td align="char" char="." valign="bottom">–0.0005</td><td align="char" char="." valign="bottom">–0.2402</td></tr></tbody></table></table-wrap><fig id="app1fig1" position="float"><label>Appendix 1—figure 1.</label><caption><title>Causal relationships of health outcome, dietary fat consumption, and the belief that consumption of dietary fat is not dangerous.</title><p>Direction of arrows represents causal directions and 𝜆<sub><italic>A</italic></sub>, 𝜆<sub><italic>B</italic></sub>, 𝛽<sub><italic>A</italic></sub>, and 𝛽<sub><italic>B</italic></sub> are structural coefficients.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-82268-app1-fig1-v1.tif"/></fig></sec></app><app id="appendix-2"><title>Appendix 2</title><sec sec-type="appendix" id="s17"><title>Misperception 10. If a plausible confounding variable is unrelated to the IV, then it does not create bias in the association of the IV with the outcome</title><p>To illustrate this misconception, let’s consider the causal diagram shown in <xref ref-type="fig" rid="app2fig1">Appendix 2—figure 1</xref>.<disp-formula id="equ11"><mml:math id="m11"><mml:mrow><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msup><mml:mi mathvariant="normal">Θ</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup><mml:mo>=</mml:mo><mml:msubsup><mml:mi>β</mml:mi><mml:mrow><mml:mi>z</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup><mml:mo>+</mml:mo><mml:msubsup><mml:mi>β</mml:mi><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup><mml:msubsup><mml:mi>λ</mml:mi><mml:mrow><mml:mi>z</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup><mml:mo>+</mml:mo><mml:msubsup><mml:mi>β</mml:mi><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup><mml:mo>+</mml:mo><mml:mn>2</mml:mn><mml:msub><mml:mi>β</mml:mi><mml:mrow><mml:mi>z</mml:mi></mml:mrow></mml:msub><mml:msub><mml:mi>β</mml:mi><mml:mrow><mml:mi>x</mml:mi></mml:mrow></mml:msub><mml:msub><mml:mi>λ</mml:mi><mml:mrow><mml:mi>z</mml:mi></mml:mrow></mml:msub></mml:mstyle></mml:mrow></mml:math></disp-formula></p><p>where</p><p>Data-generating model:</p><p>Let us consider the setting we had in the description of Misconception 9 in Appendix 1. Furthermore, <inline-formula><mml:math id="inf50"><mml:msub><mml:mrow><mml:mi>Y</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:math></inline-formula> and <inline-formula><mml:math id="inf51"><mml:msub><mml:mrow><mml:mi>Y</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub></mml:math></inline-formula> are the outcomes or DVs, <italic>X</italic> is the covariate of primary interest, and <italic>Z</italic> is the confounder in the casual association of the covariate with each response. We have the following model:<disp-formula id="equ12"><mml:math id="m12"><mml:mrow><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msub><mml:mi>Y</mml:mi><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:msub><mml:mi>β</mml:mi><mml:mrow><mml:mi>x</mml:mi></mml:mrow></mml:msub><mml:mi>X</mml:mi><mml:mo>+</mml:mo><mml:msub><mml:mi>β</mml:mi><mml:mrow><mml:mi>z</mml:mi></mml:mrow></mml:msub><mml:mi>Z</mml:mi><mml:mo>+</mml:mo><mml:msub><mml:mi>ϵ</mml:mi><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mstyle></mml:mrow></mml:math></disp-formula><disp-formula id="equ13"><mml:math id="m13"><mml:msub><mml:mrow><mml:mi>Y</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:msub><mml:mrow><mml:mi>α</mml:mi></mml:mrow><mml:mrow><mml:mi>x</mml:mi></mml:mrow></mml:msub><mml:mi>X</mml:mi><mml:mo>+</mml:mo><mml:msub><mml:mrow><mml:mi>α</mml:mi></mml:mrow><mml:mrow><mml:mi>z</mml:mi></mml:mrow></mml:msub><mml:mi>Z</mml:mi><mml:mo>+</mml:mo><mml:msub><mml:mrow><mml:mi>ϵ</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub></mml:math></disp-formula><disp-formula id="equ14"><mml:math id="m14"><mml:mi>X</mml:mi><mml:mo>=</mml:mo><mml:msub><mml:mrow><mml:mi>λ</mml:mi></mml:mrow><mml:mrow><mml:mi>z</mml:mi></mml:mrow></mml:msub><mml:mi>Z</mml:mi><mml:mo>+</mml:mo><mml:msub><mml:mrow><mml:mi>ϵ</mml:mi></mml:mrow><mml:mrow><mml:mi>x</mml:mi></mml:mrow></mml:msub></mml:math></disp-formula></p><p>We further assume that <italic>Z</italic> has a Gaussian distribution with mean 0 and variance 1; <inline-formula><mml:math id="inf52"><mml:msub><mml:mrow><mml:mi>ϵ</mml:mi></mml:mrow><mml:mrow><mml:mi>x</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> has a normal distribution with mean zero and variance <inline-formula><mml:math id="inf53"><mml:msubsup><mml:mrow><mml:mi>σ</mml:mi></mml:mrow><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup></mml:math></inline-formula> ; <inline-formula><mml:math id="inf54"><mml:msub><mml:mrow><mml:mi>e</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:math></inline-formula> has a normal distribution with mean zero and variance <inline-formula><mml:math id="inf55"><mml:msubsup><mml:mrow><mml:mi>σ</mml:mi></mml:mrow><mml:mrow><mml:mi>ϵ</mml:mi><mml:mo>,</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup></mml:math></inline-formula> ; and <inline-formula><mml:math id="inf56"><mml:msub><mml:mrow><mml:mi>e</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub></mml:math></inline-formula> has a normal distribution with mean zero and variance <inline-formula><mml:math id="inf57"><mml:msubsup><mml:mrow><mml:mi>σ</mml:mi></mml:mrow><mml:mrow><mml:mi>ϵ</mml:mi><mml:mo>,</mml:mo><mml:mn>2</mml:mn></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup></mml:math></inline-formula> . Without loss of generality, we select the variance term so that the outcomes <inline-formula><mml:math id="inf58"><mml:msub><mml:mrow><mml:mi>Y</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:math></inline-formula> and <inline-formula><mml:math id="inf59"><mml:msub><mml:mrow><mml:mi>Y</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub></mml:math></inline-formula> and the exposure <italic>X</italic> and the confounder <italic>Z</italic> all have unit variance. The joint distribution of (<italic>Z</italic>, <italic>X</italic>, <inline-formula><mml:math id="inf60"><mml:msub><mml:mrow><mml:mi>Y</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>Y</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:math></inline-formula>) is a multivariate normal distribution with mean zero vector and the correlation matrix provided in <xref ref-type="table" rid="app2table1">Appendix 2—table 1</xref>.</p><p>Where <inline-formula><mml:math id="inf61"><mml:msubsup><mml:mrow><mml:mi>σ</mml:mi></mml:mrow><mml:mrow><mml:mi>ϵ</mml:mi><mml:mo>,</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup><mml:mo>=</mml:mo><mml:mn>1</mml:mn><mml:mo>-</mml:mo><mml:mfenced separators="|"><mml:mrow><mml:msubsup><mml:mrow><mml:mi>β</mml:mi></mml:mrow><mml:mrow><mml:mi>z</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup><mml:mo>+</mml:mo><mml:msubsup><mml:mrow><mml:mi>β</mml:mi></mml:mrow><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup><mml:msubsup><mml:mrow><mml:mi>λ</mml:mi></mml:mrow><mml:mrow><mml:mi>z</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup><mml:mo>+</mml:mo><mml:mn>2</mml:mn><mml:msub><mml:mrow><mml:mi>β</mml:mi></mml:mrow><mml:mrow><mml:mi>z</mml:mi></mml:mrow></mml:msub><mml:msub><mml:mrow><mml:mi>β</mml:mi></mml:mrow><mml:mrow><mml:mi>x</mml:mi></mml:mrow></mml:msub><mml:msub><mml:mrow><mml:mi>λ</mml:mi></mml:mrow><mml:mrow><mml:mi>z</mml:mi></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msubsup><mml:mrow><mml:mi>β</mml:mi></mml:mrow><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup></mml:mrow></mml:mfenced><mml:mo>;</mml:mo><mml:msubsup><mml:mrow><mml:mi>σ</mml:mi></mml:mrow><mml:mrow><mml:mi>ϵ</mml:mi><mml:mo>,</mml:mo><mml:mn>2</mml:mn></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup><mml:mo>=</mml:mo><mml:mn>1</mml:mn><mml:mo>-</mml:mo><mml:mfenced separators="|"><mml:mrow><mml:msubsup><mml:mrow><mml:mi>α</mml:mi></mml:mrow><mml:mrow><mml:mi>z</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup><mml:mo>+</mml:mo><mml:msubsup><mml:mrow><mml:mi>α</mml:mi></mml:mrow><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup><mml:msubsup><mml:mrow><mml:mi>λ</mml:mi></mml:mrow><mml:mrow><mml:mi>z</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup><mml:mo>+</mml:mo><mml:mn>2</mml:mn><mml:msub><mml:mrow><mml:mi>α</mml:mi></mml:mrow><mml:mrow><mml:mi>z</mml:mi></mml:mrow></mml:msub><mml:msub><mml:mrow><mml:mi>α</mml:mi></mml:mrow><mml:mrow><mml:mi>x</mml:mi></mml:mrow></mml:msub><mml:msub><mml:mrow><mml:mi>λ</mml:mi></mml:mrow><mml:mrow><mml:mi>z</mml:mi></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msubsup><mml:mrow><mml:mi>α</mml:mi></mml:mrow><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup></mml:mrow></mml:mfenced></mml:math></inline-formula> ; <inline-formula><mml:math id="inf62"><mml:msubsup><mml:mrow><mml:mi>σ</mml:mi></mml:mrow><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup><mml:mo>=</mml:mo><mml:mn>1</mml:mn><mml:mo>-</mml:mo><mml:msubsup><mml:mrow><mml:mi>λ</mml:mi></mml:mrow><mml:mrow><mml:mi>z</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup></mml:math></inline-formula> . Thus, <inline-formula><mml:math id="inf63"><mml:mi>V</mml:mi><mml:mi>a</mml:mi><mml:mi>r</mml:mi><mml:mfenced separators="|"><mml:mrow><mml:msub><mml:mrow><mml:mi>Y</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:mfenced><mml:mo>=</mml:mo><mml:mi>V</mml:mi><mml:mi>a</mml:mi><mml:mi>r</mml:mi><mml:mfenced separators="|"><mml:mrow><mml:msub><mml:mrow><mml:mi>Y</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:mfenced><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:math></inline-formula>. This clearly implies the following constraints on the parameters <inline-formula><mml:math id="inf64"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mn>0</mml:mn><mml:mo>&lt;</mml:mo><mml:msub><mml:mi>β</mml:mi><mml:mrow><mml:mi>z</mml:mi></mml:mrow></mml:msub><mml:mo>&lt;</mml:mo><mml:msqrt><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:msubsup><mml:mi>β</mml:mi><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup></mml:msqrt><mml:mo>−</mml:mo><mml:msub><mml:mi>λ</mml:mi><mml:mrow><mml:mi>z</mml:mi></mml:mrow></mml:msub><mml:msub><mml:mi>β</mml:mi><mml:mrow><mml:mi>x</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula>, <inline-formula><mml:math id="inf65"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mn>0</mml:mn><mml:mo>&lt;</mml:mo><mml:msub><mml:mi>α</mml:mi><mml:mrow><mml:mi>z</mml:mi></mml:mrow></mml:msub><mml:mo>&lt;</mml:mo><mml:msqrt><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:msubsup><mml:mi>α</mml:mi><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup></mml:msqrt><mml:mo>−</mml:mo><mml:msub><mml:mi>λ</mml:mi><mml:mrow><mml:mi>x</mml:mi></mml:mrow></mml:msub><mml:msub><mml:mi>α</mml:mi><mml:mrow><mml:mi>x</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula>.<disp-formula id="equ15"><label>(8)</label><mml:math id="m15"><mml:mrow><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mn>0</mml:mn><mml:mo>≤</mml:mo><mml:msub><mml:mi>β</mml:mi><mml:mrow><mml:mi>z</mml:mi></mml:mrow></mml:msub><mml:mo>≤</mml:mo><mml:msqrt><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:msubsup><mml:mi>β</mml:mi><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup></mml:msqrt><mml:mo>−</mml:mo><mml:msub><mml:mi>λ</mml:mi><mml:mrow><mml:mi>z</mml:mi></mml:mrow></mml:msub><mml:msub><mml:mi>β</mml:mi><mml:mrow><mml:mi>x</mml:mi></mml:mrow></mml:msub></mml:mstyle></mml:mrow></mml:math></disp-formula><disp-formula id="equ16"><label>(9)</label><mml:math id="m16"><mml:mrow><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mn>0</mml:mn><mml:mo>≤</mml:mo><mml:msubsup><mml:mi>β</mml:mi><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup><mml:mo>≤</mml:mo><mml:mn>1</mml:mn><mml:mrow><mml:mo>/</mml:mo></mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mn>1</mml:mn><mml:mo>+</mml:mo><mml:msubsup><mml:mi>λ</mml:mi><mml:mrow><mml:mi>z</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mstyle></mml:mrow></mml:math></disp-formula><disp-formula id="equ17"><label>(10)</label><mml:math id="m17"><mml:mrow><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mn>0</mml:mn><mml:mo>≤</mml:mo><mml:msub><mml:mi>α</mml:mi><mml:mrow><mml:mi>z</mml:mi></mml:mrow></mml:msub><mml:mo>≤</mml:mo><mml:msqrt><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:msubsup><mml:mi>α</mml:mi><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup></mml:msqrt><mml:mo>−</mml:mo><mml:msub><mml:mi>λ</mml:mi><mml:mrow><mml:mi>x</mml:mi></mml:mrow></mml:msub><mml:msub><mml:mi>α</mml:mi><mml:mrow><mml:mi>x</mml:mi></mml:mrow></mml:msub></mml:mstyle></mml:mrow></mml:math></disp-formula><disp-formula id="equ18"><label>(11)</label><mml:math id="m18"><mml:mrow><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mn>0</mml:mn><mml:mo>≤</mml:mo><mml:msubsup><mml:mi>α</mml:mi><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup><mml:mo>≤</mml:mo><mml:mn>1</mml:mn><mml:mrow><mml:mo>/</mml:mo></mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mn>1</mml:mn><mml:mo>+</mml:mo><mml:msubsup><mml:mi>λ</mml:mi><mml:mrow><mml:mi>z</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mstyle></mml:mrow></mml:math></disp-formula></p><table-wrap id="app2table1" position="float"><label>Appendix 2—table 1.</label><caption><title>The correlation matrix among <italic>Z</italic>, <italic>X</italic>, <italic>Y</italic><sub>2</sub>, and <italic>Y</italic><sub>1</sub> without selecting on <italic>Y</italic><sub>1</sub>.</title></caption><table frame="hsides" rules="groups"><thead><tr><th align="left" valign="bottom"><inline-formula><mml:math id="inf66"><mml:mi>Σ</mml:mi></mml:math></inline-formula></th><th align="left" valign="bottom">Z</th><th align="left" valign="bottom">X</th><th align="left" valign="bottom">Y<sub>2</sub></th><th align="left" valign="bottom">Y<sub>1</sub></th></tr></thead><tbody><tr><td align="left" valign="bottom">Z</td><td align="left" valign="bottom">1</td><td align="left" valign="bottom"><inline-formula><mml:math id="inf67"><mml:msub><mml:mrow><mml:mi>λ</mml:mi></mml:mrow><mml:mrow><mml:mi>z</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula></td><td align="left" valign="bottom"><inline-formula><mml:math id="inf68"><mml:msub><mml:mrow><mml:mi>α</mml:mi></mml:mrow><mml:mrow><mml:mi>z</mml:mi></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mrow><mml:mi>α</mml:mi></mml:mrow><mml:mrow><mml:mi>x</mml:mi></mml:mrow></mml:msub><mml:msub><mml:mrow><mml:mi>λ</mml:mi></mml:mrow><mml:mrow><mml:mi>z</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula></td><td align="left" valign="bottom"><inline-formula><mml:math id="inf69"><mml:msub><mml:mrow><mml:mi>β</mml:mi></mml:mrow><mml:mrow><mml:mi>z</mml:mi></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mrow><mml:mi>β</mml:mi></mml:mrow><mml:mrow><mml:mi>x</mml:mi></mml:mrow></mml:msub><mml:msub><mml:mrow><mml:mi>λ</mml:mi></mml:mrow><mml:mrow><mml:mi>z</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula></td></tr><tr><td align="left" valign="bottom">X</td><td align="left" valign="bottom"><inline-formula><mml:math id="inf70"><mml:msub><mml:mrow><mml:mi>λ</mml:mi></mml:mrow><mml:mrow><mml:mi>z</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula></td><td align="left" valign="bottom">1</td><td align="left" valign="bottom"><inline-formula><mml:math id="inf71"><mml:msub><mml:mrow><mml:mi>α</mml:mi></mml:mrow><mml:mrow><mml:mi>x</mml:mi></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mrow><mml:mi>α</mml:mi></mml:mrow><mml:mrow><mml:mi>z</mml:mi></mml:mrow></mml:msub><mml:msub><mml:mrow><mml:mi>λ</mml:mi></mml:mrow><mml:mrow><mml:mi>z</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula></td><td align="left" valign="bottom"><inline-formula><mml:math id="inf72"><mml:msub><mml:mrow><mml:mi>β</mml:mi></mml:mrow><mml:mrow><mml:mi>x</mml:mi></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mrow><mml:mi>β</mml:mi></mml:mrow><mml:mrow><mml:mi>z</mml:mi></mml:mrow></mml:msub><mml:msub><mml:mrow><mml:mi>λ</mml:mi></mml:mrow><mml:mrow><mml:mi>z</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula></td></tr><tr><td align="left" valign="bottom">Y<sub>2</sub></td><td align="left" valign="bottom"><inline-formula><mml:math id="inf73"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>α</mml:mi><mml:mrow><mml:mi>z</mml:mi></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mi>α</mml:mi><mml:mrow><mml:mi>x</mml:mi></mml:mrow></mml:msub><mml:msub><mml:mi>λ</mml:mi><mml:mrow><mml:mi>z</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula></td><td align="left" valign="bottom"><inline-formula><mml:math id="inf74"><mml:msub><mml:mrow><mml:mi>α</mml:mi></mml:mrow><mml:mrow><mml:mi>x</mml:mi></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mrow><mml:mi>α</mml:mi></mml:mrow><mml:mrow><mml:mi>z</mml:mi></mml:mrow></mml:msub><mml:msub><mml:mrow><mml:mi>λ</mml:mi></mml:mrow><mml:mrow><mml:mi>z</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula></td><td align="left" valign="bottom">1</td><td align="left" valign="bottom"><inline-formula><mml:math id="inf75"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>α</mml:mi><mml:mrow><mml:mi>z</mml:mi></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mi>α</mml:mi><mml:mrow><mml:mi>x</mml:mi></mml:mrow></mml:msub><mml:msub><mml:mi>λ</mml:mi><mml:mrow><mml:mi>z</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:mspace width="thinmathspace"/><mml:msub><mml:mi>β</mml:mi><mml:mrow><mml:mi>z</mml:mi></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mi>β</mml:mi><mml:mrow><mml:mi>x</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>α</mml:mi><mml:mrow><mml:mi>x</mml:mi></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mi>α</mml:mi><mml:mrow><mml:mi>z</mml:mi></mml:mrow></mml:msub><mml:msub><mml:mi>λ</mml:mi><mml:mrow><mml:mi>z</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mstyle></mml:math></inline-formula></td></tr><tr><td align="left" valign="bottom">Y<sub>1</sub></td><td align="left" valign="bottom"><inline-formula><mml:math id="inf76"><mml:msub><mml:mrow><mml:mi>β</mml:mi></mml:mrow><mml:mrow><mml:mi>z</mml:mi></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mrow><mml:mi>β</mml:mi></mml:mrow><mml:mrow><mml:mi>x</mml:mi></mml:mrow></mml:msub><mml:msub><mml:mrow><mml:mi>λ</mml:mi></mml:mrow><mml:mrow><mml:mi>z</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula></td><td align="left" valign="bottom"><inline-formula><mml:math id="inf77"><mml:msub><mml:mrow><mml:mi>β</mml:mi></mml:mrow><mml:mrow><mml:mi>x</mml:mi></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mrow><mml:mi>β</mml:mi></mml:mrow><mml:mrow><mml:mi>z</mml:mi></mml:mrow></mml:msub><mml:msub><mml:mrow><mml:mi>λ</mml:mi></mml:mrow><mml:mrow><mml:mi>z</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula></td><td align="left" valign="bottom"><inline-formula><mml:math id="inf78"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>α</mml:mi><mml:mrow><mml:mi>z</mml:mi></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mi>α</mml:mi><mml:mrow><mml:mi>x</mml:mi></mml:mrow></mml:msub><mml:msub><mml:mi>λ</mml:mi><mml:mrow><mml:mi>z</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:msub><mml:mi>β</mml:mi><mml:mrow><mml:mi>z</mml:mi></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mi>β</mml:mi><mml:mrow><mml:mi>x</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>α</mml:mi><mml:mrow><mml:mi>x</mml:mi></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mi>α</mml:mi><mml:mrow><mml:mi>z</mml:mi></mml:mrow></mml:msub><mml:msub><mml:mi>λ</mml:mi><mml:mrow><mml:mi>z</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mstyle></mml:math></inline-formula></td><td align="left" valign="bottom">1</td></tr></tbody></table></table-wrap><p>Suppose we restrict the sample to values of <inline-formula><mml:math id="inf79"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>Y</mml:mi><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>&gt;</mml:mo><mml:mi>E</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:msub><mml:mi>Y</mml:mi><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>)</mml:mo></mml:mrow><mml:mo>+</mml:mo><mml:mi>τ</mml:mi><mml:msub><mml:mi>σ</mml:mi><mml:mrow><mml:msub><mml:mi>Y</mml:mi><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula> and <inline-formula><mml:math id="inf80"><mml:mi>v</mml:mi><mml:mi>a</mml:mi><mml:mi>r</mml:mi><mml:mfenced separators="|"><mml:mrow><mml:msub><mml:mrow><mml:mi>Y</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:mfenced><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:math></inline-formula>. This will ultimately perturb the joint distribution of <inline-formula><mml:math id="inf81"><mml:mfenced separators="|"><mml:mrow><mml:mi>Z</mml:mi><mml:mo>,</mml:mo><mml:mi>X</mml:mi><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>Y</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:mfenced></mml:math></inline-formula> . We can analytically derive the joint distribution of <inline-formula><mml:math id="inf82"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>Z</mml:mi><mml:mo>,</mml:mo><mml:mi>X</mml:mi><mml:mo>,</mml:mo><mml:msub><mml:mi>Y</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>∨</mml:mo><mml:msub><mml:mi>Y</mml:mi><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>&gt;</mml:mo><mml:mi>τ</mml:mi></mml:mrow></mml:mstyle></mml:math></inline-formula>. Using results from (2), the joint distribution of <inline-formula><mml:math id="inf83"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>Z</mml:mi><mml:mo>,</mml:mo><mml:mi>X</mml:mi><mml:mo>,</mml:mo><mml:msub><mml:mi>Y</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>∨</mml:mo><mml:msub><mml:mi>Y</mml:mi><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>&gt;</mml:mo><mml:mi>τ</mml:mi></mml:mrow></mml:mstyle></mml:math></inline-formula> is an extended multivariate skew-normal. Namely, the density of the vector is<disp-formula id="equ19"><mml:math id="m19"><mml:mrow><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>f</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>υ</mml:mi><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:msub><mml:mi>Y</mml:mi><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>&gt;</mml:mo><mml:mi>τ</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mi mathvariant="normal">Φ</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msup><mml:mi>α</mml:mi><mml:mrow><mml:mi>T</mml:mi></mml:mrow></mml:msup><mml:mi>υ</mml:mi><mml:mo>+</mml:mo><mml:msub><mml:mi>α</mml:mi><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mrow><mml:mi mathvariant="normal">Φ</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mo>−</mml:mo><mml:mi>τ</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mfrac><mml:mi>ϕ</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msup><mml:mi>υ</mml:mi><mml:mrow><mml:mi>T</mml:mi></mml:mrow></mml:msup><mml:munderover><mml:mo movablelimits="false">∑</mml:mo><mml:mrow><mml:mn>12</mml:mn></mml:mrow><mml:mrow><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:munderover><mml:mrow><mml:mi>υ</mml:mi></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mstyle></mml:mrow></mml:math></disp-formula></p><p>Where <inline-formula><mml:math id="inf84"><mml:mi>ϕ</mml:mi><mml:mfenced separators="|"><mml:mrow><mml:mo>.</mml:mo></mml:mrow></mml:mfenced></mml:math></inline-formula> and <inline-formula><mml:math id="inf85"><mml:mi>Φ</mml:mi><mml:mfenced separators="|"><mml:mrow><mml:mo>.</mml:mo></mml:mrow></mml:mfenced></mml:math></inline-formula> denote the density function and the cumulative density function of the normal distribution. After selecting on values of <inline-formula><mml:math id="inf86"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>Y</mml:mi><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>&gt;</mml:mo><mml:mi>τ</mml:mi></mml:mrow></mml:mstyle></mml:math></inline-formula><disp-formula id="equ20"><label>(12)</label><mml:math id="m20"><mml:mrow><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>E</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>υ</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mi>ϕ</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mo>−</mml:mo><mml:mi>τ</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mrow><mml:mi mathvariant="normal">Φ</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mo>−</mml:mo><mml:mi>τ</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mfrac><mml:mi>ρ</mml:mi></mml:mstyle></mml:mrow></mml:math></disp-formula><disp-formula id="equ21"><label>(13)</label><mml:math id="m21"><mml:mrow><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msubsup><mml:mi>σ</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup><mml:mo>=</mml:mo><mml:msub><mml:mi>σ</mml:mi><mml:mrow><mml:mn>12</mml:mn><mml:mo>,</mml:mo><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:mfrac><mml:mrow><mml:mi>ϕ</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mo>−</mml:mo><mml:mi>τ</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mrow><mml:mi mathvariant="normal">Φ</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mo>−</mml:mo><mml:mi>τ</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mfrac><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>τ</mml:mi><mml:mo>−</mml:mo><mml:mfrac><mml:mrow><mml:mi>ϕ</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mo>−</mml:mo><mml:mi>τ</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mrow><mml:mi mathvariant="normal">Φ</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mo>−</mml:mo><mml:mi>τ</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mfrac></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:msub><mml:mi>ρ</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:msub><mml:mi>ρ</mml:mi><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:mstyle></mml:mrow></mml:math></disp-formula></p><p>where<disp-formula id="equ22"><mml:math id="m22"><mml:mrow><mml:mi mathvariant="bold-italic">ρ</mml:mi><mml:mo>=</mml:mo><mml:mrow><mml:mo>{</mml:mo><mml:mrow><mml:msub><mml:mi>β</mml:mi><mml:mrow><mml:mi>z</mml:mi></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mi>β</mml:mi><mml:mrow><mml:mi>x</mml:mi></mml:mrow></mml:msub><mml:msub><mml:mi>λ</mml:mi><mml:mrow><mml:mi>z</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>β</mml:mi><mml:mrow><mml:mi>x</mml:mi></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mi>β</mml:mi><mml:mrow><mml:mi>z</mml:mi></mml:mrow></mml:msub><mml:msub><mml:mi>λ</mml:mi><mml:mrow><mml:mi>z</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>β</mml:mi><mml:mrow><mml:mi>z</mml:mi></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mi>β</mml:mi><mml:mrow><mml:mi>x</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>α</mml:mi><mml:mi>x</mml:mi></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mi>α</mml:mi><mml:mi>z</mml:mi></mml:msub><mml:msub><mml:mi>λ</mml:mi><mml:mrow><mml:mi>z</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>}</mml:mo></mml:mrow></mml:mrow></mml:math></disp-formula></p><p>and <inline-formula><mml:math id="inf87"><mml:msub><mml:mrow><mml:mi>ρ</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> is the ith element of <inline-formula><mml:math id="inf88"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi mathvariant="bold-italic">ρ</mml:mi></mml:mrow></mml:mstyle></mml:math></inline-formula> and <inline-formula><mml:math id="inf89"><mml:msubsup><mml:mrow><mml:mi>σ</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup></mml:math></inline-formula> is the entry of the matrix in <xref ref-type="table" rid="app2table1">Appendix 2—table 1</xref> at row i and column j. To find <inline-formula><mml:math id="inf90"><mml:mi>τ</mml:mi></mml:math></inline-formula> so that <inline-formula><mml:math id="inf91"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msubsup><mml:mi>σ</mml:mi><mml:mrow><mml:mn>12</mml:mn></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup><mml:mo>=</mml:mo><mml:mi>c</mml:mi><mml:mi>o</mml:mi><mml:mi>r</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>X</mml:mi><mml:mo>,</mml:mo><mml:mi>Z</mml:mi><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:msub><mml:mi>Y</mml:mi><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>&gt;</mml:mo><mml:mi>τ</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:mstyle></mml:math></inline-formula>, we need to solve the following equation for <inline-formula><mml:math id="inf92"><mml:mi>τ</mml:mi></mml:math></inline-formula><disp-formula id="equ23"><mml:math id="m23"><mml:mrow><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msub><mml:mi>λ</mml:mi><mml:mrow><mml:mi>z</mml:mi></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:mfrac><mml:mrow><mml:mi>ϕ</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mo>−</mml:mo><mml:mi>τ</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mrow><mml:mi mathvariant="normal">Φ</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mo>−</mml:mo><mml:mi>τ</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mfrac><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>τ</mml:mi><mml:mo>−</mml:mo><mml:mfrac><mml:mrow><mml:mi>ϕ</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mo>−</mml:mo><mml:mi>τ</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mrow><mml:mi mathvariant="normal">Φ</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mo>−</mml:mo><mml:mi>τ</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mfrac></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>β</mml:mi><mml:mrow><mml:mi>z</mml:mi></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mi>λ</mml:mi><mml:mrow><mml:mi>z</mml:mi></mml:mrow></mml:msub><mml:msub><mml:mi>β</mml:mi><mml:mrow><mml:mi>x</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>β</mml:mi><mml:mrow><mml:mi>x</mml:mi></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:mi>λ</mml:mi><mml:msub><mml:mi>β</mml:mi><mml:mrow><mml:mi>z</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mn>0</mml:mn></mml:mstyle></mml:mrow></mml:math></disp-formula></p><p>Since the quantity on the right-hand side is non-negative and takes on a value between 0 and 1, then for any choices of the triplet <inline-formula><mml:math id="inf93"><mml:mfenced separators="|"><mml:mrow><mml:msub><mml:mrow><mml:mi>λ</mml:mi></mml:mrow><mml:mrow><mml:mi>z</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>β</mml:mi></mml:mrow><mml:mrow><mml:mi>x</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>β</mml:mi></mml:mrow><mml:mrow><mml:mi>z</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfenced></mml:math></inline-formula> , where <inline-formula><mml:math id="inf94"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>λ</mml:mi><mml:mrow><mml:mi>z</mml:mi></mml:mrow></mml:msub><mml:mo>&lt;</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>β</mml:mi><mml:mrow><mml:mi>z</mml:mi></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mi>β</mml:mi><mml:mrow><mml:mi>x</mml:mi></mml:mrow></mml:msub><mml:msub><mml:mi>λ</mml:mi><mml:mrow><mml:mi>z</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>β</mml:mi><mml:mrow><mml:mi>x</mml:mi></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mi>β</mml:mi><mml:mrow><mml:mi>x</mml:mi></mml:mrow></mml:msub><mml:msub><mml:mi>λ</mml:mi><mml:mrow><mml:mi>z</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mstyle></mml:math></inline-formula> , we can find a <inline-formula><mml:math id="inf95"><mml:mi>τ</mml:mi></mml:math></inline-formula> so that <inline-formula><mml:math id="inf96"><mml:mi>c</mml:mi><mml:mi>o</mml:mi><mml:mi>r</mml:mi><mml:mi>r</mml:mi><mml:mfenced separators="|"><mml:mrow><mml:mi>X</mml:mi><mml:mo>,</mml:mo><mml:mi>Z</mml:mi></mml:mrow></mml:mfenced><mml:mo>=</mml:mo><mml:mn>0</mml:mn></mml:math></inline-formula> based on the data for which <inline-formula><mml:math id="inf97"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>Y</mml:mi><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>&gt;</mml:mo><mml:mi>τ</mml:mi><mml:mo>.</mml:mo></mml:mrow></mml:mstyle></mml:math></inline-formula> Let’s further assume that for a given <inline-formula><mml:math id="inf98"><mml:msub><mml:mrow><mml:mi>λ</mml:mi></mml:mrow><mml:mrow><mml:mi>x</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>β</mml:mi></mml:mrow><mml:mrow><mml:mi>x</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mi>a</mml:mi></mml:mrow><mml:mrow><mml:msqrt><mml:mn>1</mml:mn><mml:mo>+</mml:mo><mml:msubsup><mml:mrow><mml:mi>λ</mml:mi></mml:mrow><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup></mml:msqrt></mml:mrow></mml:mfrac><mml:mo>∧</mml:mo><mml:msub><mml:mrow><mml:mi>β</mml:mi></mml:mrow><mml:mrow><mml:mi>z</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mi>b</mml:mi><mml:mfenced separators="|"><mml:mrow><mml:mfrac><mml:mrow><mml:msqrt><mml:mn>1</mml:mn><mml:mo>+</mml:mo><mml:msubsup><mml:mrow><mml:mi>λ</mml:mi></mml:mrow><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup><mml:mo>+</mml:mo><mml:msup><mml:mrow><mml:mi>a</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:msqrt><mml:mo>-</mml:mo><mml:msub><mml:mrow><mml:mi>λ</mml:mi></mml:mrow><mml:mrow><mml:mi>x</mml:mi></mml:mrow></mml:msub><mml:mi>a</mml:mi></mml:mrow><mml:mrow><mml:msqrt><mml:mn>1</mml:mn><mml:mo>+</mml:mo><mml:msubsup><mml:mrow><mml:mi>λ</mml:mi></mml:mrow><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup></mml:msqrt></mml:mrow></mml:mfrac></mml:mrow></mml:mfenced><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mi>b</mml:mi></mml:mrow><mml:mrow><mml:mi>a</mml:mi></mml:mrow></mml:mfrac><mml:msub><mml:mrow><mml:mi>β</mml:mi></mml:mrow><mml:mrow><mml:mi>x</mml:mi></mml:mrow></mml:msub><mml:mfenced separators="|"><mml:mrow><mml:msqrt><mml:mn>1</mml:mn><mml:mo>+</mml:mo><mml:msubsup><mml:mrow><mml:mi>λ</mml:mi></mml:mrow><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup><mml:mo>+</mml:mo><mml:msup><mml:mrow><mml:mi>a</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:msqrt><mml:mo>-</mml:mo><mml:msub><mml:mrow><mml:mi>λ</mml:mi></mml:mrow><mml:mrow><mml:mi>x</mml:mi></mml:mrow></mml:msub><mml:mi>a</mml:mi></mml:mrow></mml:mfenced><mml:mo>,</mml:mo></mml:math></inline-formula> for fixed <inline-formula><mml:math id="inf99"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mn>0</mml:mn><mml:mo>&lt;</mml:mo><mml:msub><mml:mi>λ</mml:mi><mml:mrow><mml:mi>z</mml:mi></mml:mrow></mml:msub><mml:mo>&lt;</mml:mo><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mo>∧</mml:mo><mml:mn>0</mml:mn><mml:mo>≤</mml:mo><mml:mi>a</mml:mi><mml:mo>,</mml:mo><mml:mi>b</mml:mi><mml:mo>≤</mml:mo><mml:mn>1.</mml:mn></mml:mrow></mml:mstyle></mml:math></inline-formula> Thus for any pair <inline-formula><mml:math id="inf100"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>a</mml:mi><mml:mo>,</mml:mo><mml:mi>b</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mi>w</mml:mi><mml:mi>i</mml:mi><mml:mi>t</mml:mi><mml:mi>h</mml:mi><mml:mspace width="thinmathspace"/><mml:mn>0</mml:mn><mml:mo>≤</mml:mo><mml:mi>a</mml:mi><mml:mo>,</mml:mo><mml:mi>b</mml:mi><mml:mo>&lt;</mml:mo><mml:mn>1</mml:mn><mml:mo>,</mml:mo></mml:mrow></mml:mstyle></mml:math></inline-formula> we have a set of possible values of <inline-formula><mml:math id="inf101"><mml:msub><mml:mrow><mml:mi>λ</mml:mi></mml:mrow><mml:mrow><mml:mi>z</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> that satisfies all the constraints enumerated above. In the setting, <inline-formula><mml:math id="inf102"><mml:msub><mml:mrow><mml:mi>β</mml:mi></mml:mrow><mml:mrow><mml:mi>x</mml:mi></mml:mrow></mml:msub><mml:mo>∧</mml:mo><mml:msub><mml:mrow><mml:mi>β</mml:mi></mml:mrow><mml:mrow><mml:mi>z</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> involve the constants <inline-formula><mml:math id="inf103"><mml:mi>a</mml:mi><mml:mo>,</mml:mo><mml:mi>b</mml:mi><mml:mo>,</mml:mo><mml:mo>∧</mml:mo><mml:msub><mml:mrow><mml:mi>λ</mml:mi></mml:mrow><mml:mrow><mml:mi>z</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> in a nonlinear fashion. We rely on numerical approaches to identify values of <inline-formula><mml:math id="inf104"><mml:msub><mml:mrow><mml:mi>λ</mml:mi></mml:mrow><mml:mrow><mml:mi>z</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> consistent with the values of <inline-formula><mml:math id="inf105"><mml:mi>a</mml:mi><mml:mo>∧</mml:mo><mml:mi>b</mml:mi></mml:math></inline-formula>. We illustrate this with the case where <inline-formula><mml:math id="inf106"><mml:mi>a</mml:mi><mml:mo>,</mml:mo><mml:mi>b</mml:mi><mml:mo>∈</mml:mo><mml:mo>{</mml:mo><mml:mn>0.2,0.9</mml:mn><mml:mo>}</mml:mo></mml:math></inline-formula>, which results in four possible pairs <inline-formula><mml:math id="inf107"><mml:mfenced separators="|"><mml:mrow><mml:mn>0.2,0.2</mml:mn></mml:mrow></mml:mfenced></mml:math></inline-formula> , <inline-formula><mml:math id="inf108"><mml:mfenced separators="|"><mml:mrow><mml:mn>0.2,0.9</mml:mn></mml:mrow></mml:mfenced></mml:math></inline-formula> , <inline-formula><mml:math id="inf109"><mml:mfenced separators="|"><mml:mrow><mml:mn>0.9,0.2</mml:mn></mml:mrow></mml:mfenced></mml:math></inline-formula> , and <inline-formula><mml:math id="inf110"><mml:mfenced separators="|"><mml:mrow><mml:mn>0.9,0.9</mml:mn></mml:mrow></mml:mfenced><mml:mo>.</mml:mo></mml:math></inline-formula> In <xref ref-type="fig" rid="app2fig2">Appendix 2—figure 2</xref>, we show the set of possible values of <inline-formula><mml:math id="inf111"><mml:msub><mml:mrow><mml:mi>λ</mml:mi></mml:mrow><mml:mrow><mml:mi>z</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> , combined with the value of <inline-formula><mml:math id="inf112"><mml:msub><mml:mrow><mml:mi>β</mml:mi></mml:mrow><mml:mrow><mml:mi>x</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>β</mml:mi></mml:mrow><mml:mrow><mml:mi>z</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> for which we can find a value of <inline-formula><mml:math id="inf113"><mml:mi>τ</mml:mi></mml:math></inline-formula>.</p><p>Selecting on <italic>Y</italic><sub>1</sub> affects the joint dependence between these variables. To this consider <xref ref-type="table" rid="app2table1">Appendix 2—table 1</xref>, the correlation matrix among <italic>X</italic>, <italic>Z</italic>, <italic>Y</italic><sub>1</sub>, and <italic>Y</italic><sub>2</sub> <italic>without</italic> selecting on <italic>Y</italic><sub>1</sub>. Contrast this with <xref ref-type="disp-formula" rid="equ24">A1</xref>, the correlation matrix among <italic>X</italic>, <italic>Z</italic>, <italic>Y</italic><sub>1</sub>, and <italic>Y</italic><sub>2</sub> <italic>with</italic> selecting on <italic>Y</italic><sub>1</sub>.<disp-formula id="equ24"><label>(A1)</label><mml:math id="m24"><mml:mrow><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mover><mml:mi mathvariant="normal">Σ</mml:mi><mml:mo stretchy="false">~</mml:mo></mml:mover></mml:mrow><mml:mo>=</mml:mo><mml:mrow><mml:mo>[</mml:mo><mml:mtable rowspacing="4pt" columnspacing="1em"><mml:mtr><mml:mtd><mml:mtext> </mml:mtext><mml:msub><mml:mrow><mml:mover><mml:mi mathvariant="normal">Σ</mml:mi><mml:mo stretchy="false">~</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mn>12</mml:mn></mml:mrow></mml:msub></mml:mtd><mml:mtd><mml:mi>C</mml:mi><mml:mi>o</mml:mi><mml:mi>v</mml:mi><mml:mrow><mml:mrow><mml:mo>{</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>Z</mml:mi><mml:mo>,</mml:mo><mml:mi>X</mml:mi><mml:mo>,</mml:mo><mml:msub><mml:mi>Y</mml:mi><mml:mn>2</mml:mn></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:mo>,</mml:mo><mml:msub><mml:mi>Y</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>∣</mml:mo><mml:msub><mml:mi>Y</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>&gt;</mml:mo><mml:mi>a</mml:mi></mml:mrow><mml:mo>}</mml:mo></mml:mrow></mml:mrow></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mi>C</mml:mi><mml:mi>o</mml:mi><mml:mi>v</mml:mi><mml:mrow><mml:mrow><mml:mo>{</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>Z</mml:mi><mml:mo>,</mml:mo><mml:mi>X</mml:mi><mml:mo>,</mml:mo><mml:msub><mml:mi>Y</mml:mi><mml:mn>2</mml:mn></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:mo>,</mml:mo><mml:msub><mml:mi>Y</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>∣</mml:mo><mml:msub><mml:mi>Y</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>&gt;</mml:mo><mml:mi>a</mml:mi></mml:mrow><mml:mo>}</mml:mo></mml:mrow></mml:mrow></mml:mtd><mml:mtd><mml:mi>V</mml:mi><mml:mi>a</mml:mi><mml:mi>r</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>Y</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>∣</mml:mo><mml:msub><mml:mi>Y</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>&gt;</mml:mo><mml:mi>a</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mtd></mml:mtr></mml:mtable><mml:mo>]</mml:mo></mml:mrow></mml:mstyle></mml:mrow></mml:math></disp-formula></p><p>Where:<disp-formula id="equ25"><label>(14)</label><mml:math id="m25"><mml:mrow><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msub><mml:mrow><mml:mover><mml:mi mathvariant="normal">Σ</mml:mi><mml:mo stretchy="false">~</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mn>12</mml:mn></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:msub><mml:mi mathvariant="normal">Σ</mml:mi><mml:mrow><mml:mn>12</mml:mn></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:mfrac><mml:mrow><mml:mi>ϕ</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mo>−</mml:mo><mml:mi>α</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mrow><mml:mi mathvariant="normal">Φ</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mo>−</mml:mo><mml:mi>α</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mfrac><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>α</mml:mi><mml:mo>−</mml:mo><mml:mfrac><mml:mrow><mml:mi>ϕ</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mo>−</mml:mo><mml:mi>α</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mrow><mml:mi mathvariant="normal">Φ</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mo>−</mml:mo><mml:mi>α</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mfrac></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mi>ρ</mml:mi><mml:msup><mml:mi>ρ</mml:mi><mml:mrow><mml:mi>T</mml:mi></mml:mrow></mml:msup></mml:mstyle></mml:mrow></mml:math></disp-formula><disp-formula id="equ26"><mml:math id="m26"><mml:mrow><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msub><mml:mi mathvariant="normal">Σ</mml:mi><mml:mrow><mml:mn>12</mml:mn></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mrow><mml:mo>[</mml:mo><mml:mtable rowspacing="4pt" columnspacing="1em"><mml:mtr><mml:mtd><mml:mn>1</mml:mn></mml:mtd><mml:mtd><mml:msub><mml:mi>λ</mml:mi><mml:mrow><mml:mi>z</mml:mi></mml:mrow></mml:msub></mml:mtd><mml:mtd><mml:msub><mml:mi>α</mml:mi><mml:mrow><mml:mi>x</mml:mi></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mi>α</mml:mi><mml:mrow><mml:mi>x</mml:mi></mml:mrow></mml:msub><mml:msub><mml:mi>λ</mml:mi><mml:mi>z</mml:mi></mml:msub></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:msub><mml:mi>λ</mml:mi><mml:mrow><mml:mi>z</mml:mi></mml:mrow></mml:msub></mml:mtd><mml:mtd><mml:mn>1</mml:mn></mml:mtd><mml:mtd><mml:msub><mml:mi>α</mml:mi><mml:mrow><mml:mi>x</mml:mi></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mi>α</mml:mi><mml:mrow><mml:mi>x</mml:mi></mml:mrow></mml:msub><mml:msub><mml:mi>λ</mml:mi><mml:mi>z</mml:mi></mml:msub></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:msub><mml:mi>α</mml:mi><mml:mrow><mml:mi>z</mml:mi></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mi>α</mml:mi><mml:mrow><mml:mi>x</mml:mi></mml:mrow></mml:msub><mml:msub><mml:mi>λ</mml:mi><mml:mi>x</mml:mi></mml:msub></mml:mtd><mml:mtd><mml:msub><mml:mi>α</mml:mi><mml:mrow><mml:mi>x</mml:mi></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mi>α</mml:mi><mml:mrow><mml:mi>z</mml:mi></mml:mrow></mml:msub><mml:msub><mml:mi>λ</mml:mi><mml:mi>z</mml:mi></mml:msub></mml:mtd><mml:mtd><mml:mn>1</mml:mn></mml:mtd></mml:mtr></mml:mtable><mml:mo>]</mml:mo></mml:mrow></mml:mstyle></mml:mrow></mml:math></disp-formula><disp-formula id="equ27"><label>(15)</label><mml:math id="m27"><mml:mrow><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>V</mml:mi><mml:mi>a</mml:mi><mml:mi>r</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>Y</mml:mi><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:msub><mml:mi>Y</mml:mi><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>&gt;</mml:mo><mml:mi>a</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mrow><mml:mo>{</mml:mo><mml:mrow><mml:mn>1</mml:mn><mml:mo>+</mml:mo><mml:mfrac><mml:mrow><mml:mi>ϕ</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mo>−</mml:mo><mml:mi>a</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mrow><mml:mi mathvariant="normal">Φ</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mo>−</mml:mo><mml:mi>a</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mfrac><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>a</mml:mi><mml:mo>−</mml:mo><mml:mfrac><mml:mrow><mml:mi>ϕ</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mo>−</mml:mo><mml:mi>a</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mrow><mml:mi mathvariant="normal">Φ</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mo>−</mml:mo><mml:mi>a</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mfrac></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>}</mml:mo></mml:mrow><mml:msubsup><mml:mi>σ</mml:mi><mml:mrow><mml:mi>y</mml:mi><mml:mo>,</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup></mml:mstyle></mml:mrow></mml:math></disp-formula><disp-formula id="equ28"><label>(16)</label><mml:math id="m28"><mml:mrow><mml:mi>C</mml:mi><mml:mi>o</mml:mi><mml:mi>v</mml:mi><mml:mrow><mml:mo>{</mml:mo><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>Z</mml:mi><mml:mo>,</mml:mo><mml:mi>X</mml:mi><mml:mo>,</mml:mo><mml:msub><mml:mi>Y</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>,</mml:mo><mml:msub><mml:mi>Y</mml:mi><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:msub><mml:mi>Y</mml:mi><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>&gt;</mml:mo><mml:mi>a</mml:mi></mml:mrow><mml:mo>}</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mrow><mml:mo>{</mml:mo><mml:mrow><mml:mn>1</mml:mn><mml:mo>+</mml:mo><mml:mfrac><mml:mrow><mml:mi>ϕ</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mo>−</mml:mo><mml:mi>a</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mrow><mml:mi mathvariant="normal">Φ</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mo>−</mml:mo><mml:mi>a</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mfrac><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>a</mml:mi><mml:mo>−</mml:mo><mml:mfrac><mml:mrow><mml:mi>ϕ</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mo>−</mml:mo><mml:mi>a</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mrow><mml:mi mathvariant="normal">Φ</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mo>−</mml:mo><mml:mi>a</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mfrac></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>}</mml:mo></mml:mrow><mml:mi>ρ</mml:mi></mml:mrow></mml:math></disp-formula></p><p>Let <inline-formula><mml:math id="inf114"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>a</mml:mi><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mi>ϕ</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mo>−</mml:mo><mml:mi>α</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mrow><mml:mi mathvariant="normal">Φ</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mo>−</mml:mo><mml:mi>α</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mfrac><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>α</mml:mi><mml:mo>−</mml:mo><mml:mfrac><mml:mrow><mml:mi>ϕ</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mo>−</mml:mo><mml:mi>α</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mrow><mml:mi mathvariant="normal">Φ</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mo>−</mml:mo><mml:mi>α</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mfrac></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mstyle></mml:math></inline-formula>, <inline-formula><mml:math id="inf115"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>a</mml:mi><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:msub><mml:mi>α</mml:mi><mml:mrow><mml:mi>z</mml:mi></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mi>α</mml:mi><mml:mrow><mml:mi>x</mml:mi></mml:mrow></mml:msub><mml:msub><mml:mi>λ</mml:mi><mml:mrow><mml:mi>z</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>a</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:msub><mml:mi>α</mml:mi><mml:mrow><mml:mi>x</mml:mi></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mi>α</mml:mi><mml:mrow><mml:mi>z</mml:mi></mml:mrow></mml:msub><mml:msub><mml:mi>λ</mml:mi><mml:mrow><mml:mi>z</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula>, <inline-formula><mml:math id="inf116"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>ρ</mml:mi><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:msub><mml:mi>β</mml:mi><mml:mrow><mml:mi>z</mml:mi></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mi>β</mml:mi><mml:mrow><mml:mi>x</mml:mi></mml:mrow></mml:msub><mml:msub><mml:mi>λ</mml:mi><mml:mrow><mml:mi>z</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula>, <inline-formula><mml:math id="inf117"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>ρ</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:msub><mml:mi>β</mml:mi><mml:mrow><mml:mi>x</mml:mi></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mi>β</mml:mi><mml:mrow><mml:mi>z</mml:mi></mml:mrow></mml:msub><mml:msub><mml:mi>λ</mml:mi><mml:mrow><mml:mi>z</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula>, and <inline-formula><mml:math id="inf118"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>ρ</mml:mi><mml:mrow><mml:mn>3</mml:mn></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>α</mml:mi><mml:mi>z</mml:mi></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mi>α</mml:mi><mml:mi>x</mml:mi></mml:msub><mml:msub><mml:mi>λ</mml:mi><mml:mi>z</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:msub><mml:mi>β</mml:mi><mml:mi>z</mml:mi></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>α</mml:mi><mml:mi>x</mml:mi></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mi>α</mml:mi><mml:mi>z</mml:mi></mml:msub><mml:msub><mml:mi>λ</mml:mi><mml:mi>z</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mstyle></mml:math></inline-formula><disp-formula id="equ29"><mml:math id="m29"><mml:mrow><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msub><mml:mrow><mml:mover><mml:mi mathvariant="normal">Σ</mml:mi><mml:mo stretchy="false">~</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mn>12</mml:mn></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mrow><mml:mo>[</mml:mo><mml:mtable rowspacing="4pt" columnspacing="1em"><mml:mtr><mml:mtd><mml:mn>1</mml:mn><mml:mo>+</mml:mo><mml:msub><mml:mi>a</mml:mi><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msub><mml:msubsup><mml:mi>ρ</mml:mi><mml:mrow><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup></mml:mtd><mml:mtd><mml:msub><mml:mi>λ</mml:mi><mml:mrow><mml:mi>z</mml:mi></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mi>a</mml:mi><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msub><mml:msub><mml:mi>ρ</mml:mi><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:msub><mml:mi>ρ</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub></mml:mtd><mml:mtd><mml:msub><mml:mi>a</mml:mi><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mi>a</mml:mi><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msub><mml:msub><mml:mi>ρ</mml:mi><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:msub><mml:mi>ρ</mml:mi><mml:mrow><mml:mn>3</mml:mn></mml:mrow></mml:msub></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:msub><mml:mi>λ</mml:mi><mml:mrow><mml:mi>z</mml:mi></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mi>a</mml:mi><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msub><mml:msub><mml:mi>ρ</mml:mi><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:msub><mml:mi>ρ</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub></mml:mtd><mml:mtd><mml:mn>1</mml:mn><mml:mo>+</mml:mo><mml:msub><mml:mi>a</mml:mi><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msub><mml:msubsup><mml:mi>ρ</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup></mml:mtd><mml:mtd><mml:msub><mml:mi>a</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mi>a</mml:mi><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msub><mml:msub><mml:mi>ρ</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:msub><mml:mi>ρ</mml:mi><mml:mrow><mml:mn>3</mml:mn></mml:mrow></mml:msub></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:msub><mml:mi>a</mml:mi><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mi>a</mml:mi><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msub><mml:msub><mml:mi>ρ</mml:mi><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:msub><mml:mi>ρ</mml:mi><mml:mrow><mml:mn>3</mml:mn></mml:mrow></mml:msub></mml:mtd><mml:mtd><mml:msub><mml:mi>a</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mi>a</mml:mi><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msub><mml:msub><mml:mi>ρ</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:msub><mml:mi>ρ</mml:mi><mml:mrow><mml:mn>3</mml:mn></mml:mrow></mml:msub></mml:mtd><mml:mtd><mml:mn>1</mml:mn><mml:mo>+</mml:mo><mml:msub><mml:mi>a</mml:mi><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msub><mml:msubsup><mml:mi>ρ</mml:mi><mml:mrow><mml:mn>3</mml:mn></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup></mml:mtd></mml:mtr></mml:mtable><mml:mo>]</mml:mo></mml:mrow></mml:mstyle></mml:mrow></mml:math></disp-formula></p><p>From the elements of <xref ref-type="table" rid="app2table1">Appendix 2—table 1</xref> and , we can derive the elements of <xref ref-type="table" rid="app2table2">Appendix 2—table 2</xref>, which shows the squared (partial or zero-order) correlation and (partial or univariable) slope of the regression of <italic>Y</italic><sub>2</sub> on <italic>X</italic> with and without controlling for <italic>Z</italic> and with and without selecting on <italic>Y</italic><sub>1</sub>.</p><table-wrap id="app2table2" position="float"><label>Appendix 2—table 2.</label><caption><title>The squared correlation and slope of regression.</title></caption><table frame="hsides" rules="groups"><thead><tr><th align="left" valign="bottom">Quantity of interest</th><th align="left" valign="bottom">Without selection on Y<sub>1</sub></th><th align="left" valign="bottom">With selection on Y<sub>1</sub></th></tr></thead><tbody><tr><td align="left" valign="middle">Squared (zero-order) correlation of X and Y<sub>2</sub></td><td align="center" valign="middle"><inline-formula><mml:math id="inf119"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msup><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>λ</mml:mi><mml:mrow><mml:mi>z</mml:mi></mml:mrow></mml:msub><mml:msub><mml:mi>α</mml:mi><mml:mrow><mml:mi>z</mml:mi></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mi>α</mml:mi><mml:mrow><mml:mi>x</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:mstyle></mml:math></inline-formula></td><td align="center" valign="middle"><inline-formula><mml:math id="inf120"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msup><mml:mrow><mml:mo>(</mml:mo><mml:mfrac><mml:msub><mml:mrow><mml:mover><mml:mi>σ</mml:mi><mml:mo stretchy="false">~</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mn>23</mml:mn></mml:mrow></mml:msub><mml:mrow><mml:msqrt><mml:msub><mml:mrow><mml:mover><mml:mi>σ</mml:mi><mml:mo stretchy="false">~</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mn>22</mml:mn></mml:mrow></mml:msub></mml:msqrt><mml:msqrt><mml:msub><mml:mrow><mml:mover><mml:mi>σ</mml:mi><mml:mo stretchy="false">~</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mn>33</mml:mn></mml:mrow></mml:msub></mml:msqrt></mml:mrow></mml:mfrac><mml:mo>)</mml:mo></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:mstyle></mml:math></inline-formula></td></tr><tr><td align="left" valign="middle">Squared (partial) correlation of X and Y<sub>2</sub>, controlling for Z</td><td align="center" valign="middle"><inline-formula><mml:math id="inf121"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mfrac><mml:msup><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mo>−</mml:mo><mml:msub><mml:mrow><mml:mover><mml:mi>σ</mml:mi><mml:mo stretchy="false">~</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mn>23</mml:mn></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup><mml:mrow><mml:msub><mml:mrow><mml:mover><mml:mi>σ</mml:mi><mml:mo stretchy="false">~</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mn>22</mml:mn></mml:mrow></mml:msub><mml:msub><mml:mrow><mml:mover><mml:mi>σ</mml:mi><mml:mo stretchy="false">~</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mn>33</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:mfrac></mml:mrow></mml:mstyle></mml:math></inline-formula></td><td align="center" valign="middle"><inline-formula><mml:math id="inf122"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msup><mml:mrow><mml:mo>(</mml:mo><mml:mfrac><mml:msubsup><mml:mrow><mml:mover><mml:mi>σ</mml:mi><mml:mo stretchy="false">~</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mn>23</mml:mn></mml:mrow><mml:mo>∗</mml:mo></mml:msubsup><mml:mrow><mml:msqrt><mml:msubsup><mml:mrow><mml:mover><mml:mi>σ</mml:mi><mml:mo stretchy="false">~</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mn>22</mml:mn></mml:mrow><mml:mo>∗</mml:mo></mml:msubsup></mml:msqrt><mml:msqrt><mml:msubsup><mml:mrow><mml:mover><mml:mi>σ</mml:mi><mml:mo stretchy="false">~</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mn>33</mml:mn></mml:mrow><mml:mo>∗</mml:mo></mml:msubsup></mml:msqrt></mml:mrow></mml:mfrac><mml:mo>)</mml:mo></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:mstyle></mml:math></inline-formula></td></tr><tr><td align="left" valign="middle">Slope of univariable regression of Y<sub>2</sub> on X</td><td align="center" valign="middle"><inline-formula><mml:math id="inf123"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>λ</mml:mi><mml:mrow><mml:mi>z</mml:mi></mml:mrow></mml:msub><mml:msub><mml:mi>α</mml:mi><mml:mrow><mml:mi>z</mml:mi></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mi>α</mml:mi><mml:mrow><mml:mi>x</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mstyle></mml:math></inline-formula></td><td align="center" valign="middle"><inline-formula><mml:math id="inf124"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mfrac><mml:msub><mml:mrow><mml:mover><mml:mi>σ</mml:mi><mml:mo stretchy="false">~</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mn>23</mml:mn></mml:mrow></mml:msub><mml:msub><mml:mrow><mml:mover><mml:mi>σ</mml:mi><mml:mo stretchy="false">~</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mn>22</mml:mn></mml:mrow></mml:msub></mml:mfrac></mml:mrow></mml:mstyle></mml:math></inline-formula></td></tr><tr><td align="left" valign="middle">Partial slope of regression of Y<sub>2</sub> on X, controlling for Z</td><td align="center" valign="middle"><inline-formula><mml:math id="inf125"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mfrac><mml:mrow><mml:msub><mml:mi>α</mml:mi><mml:mrow><mml:mi>x</mml:mi></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mi>α</mml:mi><mml:mrow><mml:mi>x</mml:mi></mml:mrow></mml:msub><mml:msubsup><mml:mi>λ</mml:mi><mml:mrow><mml:mi>z</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup></mml:mrow><mml:mrow><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:msubsup><mml:mi>λ</mml:mi><mml:mrow><mml:mi>z</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup></mml:mrow></mml:mfrac></mml:mrow></mml:mstyle></mml:math></inline-formula></td><td align="center" valign="middle"><inline-formula><mml:math id="inf126"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mfrac><mml:msqrt><mml:msub><mml:mrow><mml:mover><mml:mi>σ</mml:mi><mml:mo stretchy="false">~</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mn>33</mml:mn></mml:mrow></mml:msub></mml:msqrt><mml:msqrt><mml:msub><mml:mrow><mml:mover><mml:mi>σ</mml:mi><mml:mo stretchy="false">~</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mn>22</mml:mn></mml:mrow></mml:msub></mml:msqrt></mml:mfrac><mml:mo>)</mml:mo></mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mfrac><mml:mrow><mml:msub><mml:mrow><mml:mover><mml:mi>ρ</mml:mi><mml:mo stretchy="false">~</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mn>23</mml:mn></mml:mrow></mml:msub><mml:mo>−</mml:mo><mml:msub><mml:mrow><mml:mover><mml:mi>ρ</mml:mi><mml:mo stretchy="false">~</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mn>13</mml:mn></mml:mrow></mml:msub><mml:msub><mml:mrow><mml:mover><mml:mi>ρ</mml:mi><mml:mo stretchy="false">~</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mn>12</mml:mn></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:msubsup><mml:mrow><mml:mover><mml:mi>ρ</mml:mi><mml:mo stretchy="false">~</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mn>12</mml:mn></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup></mml:mrow></mml:mfrac><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mstyle></mml:math></inline-formula></td></tr></tbody></table></table-wrap><p><inline-formula><mml:math id="inf127"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mrow><mml:mover><mml:mi>σ</mml:mi><mml:mo stretchy="false">~</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mn>12</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mover><mml:mi>σ</mml:mi><mml:mo stretchy="false">~</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mn>13</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mover><mml:mi>σ</mml:mi><mml:mo stretchy="false">~</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mn>23</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mover><mml:mi>σ</mml:mi><mml:mo stretchy="false">~</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mn>11</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mover><mml:mi>σ</mml:mi><mml:mo stretchy="false">~</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mn>22</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mover><mml:mi>σ</mml:mi><mml:mo stretchy="false">~</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mn>33</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula> are the entries of the matrix <inline-formula><mml:math id="inf128"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mrow><mml:mover><mml:mi mathvariant="normal">Σ</mml:mi><mml:mo stretchy="false">~</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mn>12</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula> and <inline-formula><mml:math id="inf129"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mrow><mml:mover><mml:mi>ρ</mml:mi><mml:mo stretchy="false">~</mml:mo></mml:mover></mml:mrow></mml:mrow></mml:mstyle></mml:math></inline-formula> are entries of the correlation matrix obtained from <inline-formula><mml:math id="inf130"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mrow><mml:mover><mml:mi mathvariant="normal">Σ</mml:mi><mml:mo stretchy="false">~</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mn>12</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula> .</p><p>When <inline-formula><mml:math id="inf131"><mml:msub><mml:mrow><mml:mi>α</mml:mi></mml:mrow><mml:mrow><mml:mi>x</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mn>0</mml:mn><mml:mo>,</mml:mo></mml:math></inline-formula> then <inline-formula><mml:math id="inf132"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>a</mml:mi><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:msub><mml:mi>α</mml:mi><mml:mrow><mml:mi>z</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula>, <inline-formula><mml:math id="inf133"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>a</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:msub><mml:mi>α</mml:mi><mml:mrow><mml:mi>z</mml:mi></mml:mrow></mml:msub><mml:msub><mml:mi>λ</mml:mi><mml:mrow><mml:mi>z</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula>, <inline-formula><mml:math id="inf134"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>ρ</mml:mi><mml:mrow><mml:mn>3</mml:mn></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:msub><mml:mi>α</mml:mi><mml:mrow><mml:mi>z</mml:mi></mml:mrow></mml:msub><mml:msub><mml:mi>ρ</mml:mi><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula>, <inline-formula><mml:math id="inf135"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mrow><mml:mover><mml:mi>σ</mml:mi><mml:mo stretchy="false">~</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mn>12</mml:mn></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:msub><mml:mi>λ</mml:mi><mml:mrow><mml:mi>z</mml:mi></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mi>a</mml:mi><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msub><mml:msub><mml:mi>ρ</mml:mi><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:msub><mml:mi>ρ</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula><disp-formula id="equ30"><mml:math id="m30"><mml:mrow><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msub><mml:mrow><mml:mover><mml:mi>σ</mml:mi><mml:mo stretchy="false">~</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mn>13</mml:mn></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:msub><mml:mi>α</mml:mi><mml:mrow><mml:mi>z</mml:mi></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mi>a</mml:mi><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msub><mml:msub><mml:mi>α</mml:mi><mml:mrow><mml:mi>z</mml:mi></mml:mrow></mml:msub><mml:msubsup><mml:mi>ρ</mml:mi><mml:mrow><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mover><mml:mi>σ</mml:mi><mml:mo stretchy="false">~</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mn>23</mml:mn></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:msub><mml:mi>α</mml:mi><mml:mrow><mml:mi>z</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>λ</mml:mi><mml:mrow><mml:mi>z</mml:mi></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mi>a</mml:mi><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msub><mml:msub><mml:mi>ρ</mml:mi><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:msub><mml:mi>ρ</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mover><mml:mi>σ</mml:mi><mml:mo stretchy="false">~</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mn>11</mml:mn></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mn>1</mml:mn><mml:mo>+</mml:mo><mml:msub><mml:mi>a</mml:mi><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msub><mml:msubsup><mml:mi>ρ</mml:mi><mml:mrow><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup><mml:mo>,</mml:mo></mml:mstyle></mml:mrow></mml:math></disp-formula><disp-formula id="equ31"><mml:math id="m31"><mml:mrow><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msub><mml:mrow><mml:mover><mml:mi>σ</mml:mi><mml:mo stretchy="false">~</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mn>22</mml:mn></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mn>1</mml:mn><mml:mo>+</mml:mo><mml:msub><mml:mi>a</mml:mi><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msub><mml:msubsup><mml:mi>ρ</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mover><mml:mi>σ</mml:mi><mml:mo stretchy="false">~</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mn>33</mml:mn></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mn>1</mml:mn><mml:mo>+</mml:mo><mml:msub><mml:mi>a</mml:mi><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msub><mml:msubsup><mml:mi>α</mml:mi><mml:mrow><mml:mi>z</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup><mml:msubsup><mml:mi>ρ</mml:mi><mml:mrow><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup></mml:mstyle></mml:mrow></mml:math></disp-formula></p><p>Namely,<disp-formula id="equ32"><mml:math id="m32"><mml:mrow><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msub><mml:mrow><mml:mover><mml:mi>ρ</mml:mi><mml:mo stretchy="false">~</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mn>23</mml:mn></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:msup><mml:mrow><mml:mo>(</mml:mo><mml:mfrac><mml:msub><mml:mrow><mml:mover><mml:mi>σ</mml:mi><mml:mo stretchy="false">~</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mn>23</mml:mn></mml:mrow></mml:msub><mml:mrow><mml:msqrt><mml:msub><mml:mrow><mml:mover><mml:mi>σ</mml:mi><mml:mo stretchy="false">~</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mn>22</mml:mn></mml:mrow></mml:msub></mml:msqrt><mml:msqrt><mml:msub><mml:mrow><mml:mover><mml:mi>σ</mml:mi><mml:mo stretchy="false">~</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mn>33</mml:mn></mml:mrow></mml:msub></mml:msqrt></mml:mrow></mml:mfrac><mml:mo>)</mml:mo></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mover><mml:mi>ρ</mml:mi><mml:mo stretchy="false">~</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mn>13</mml:mn></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:msup><mml:mrow><mml:mo>(</mml:mo><mml:mfrac><mml:msub><mml:mrow><mml:mover><mml:mi>σ</mml:mi><mml:mo stretchy="false">~</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mn>13</mml:mn></mml:mrow></mml:msub><mml:mrow><mml:msqrt><mml:msub><mml:mrow><mml:mover><mml:mi>σ</mml:mi><mml:mo stretchy="false">~</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mn>11</mml:mn></mml:mrow></mml:msub></mml:msqrt><mml:msqrt><mml:msub><mml:mrow><mml:mover><mml:mi>σ</mml:mi><mml:mo stretchy="false">~</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mn>33</mml:mn></mml:mrow></mml:msub></mml:msqrt></mml:mrow></mml:mfrac><mml:mo>)</mml:mo></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mover><mml:mi>ρ</mml:mi><mml:mo stretchy="false">~</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mn>12</mml:mn></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:msup><mml:mrow><mml:mo>(</mml:mo><mml:mfrac><mml:msub><mml:mrow><mml:mover><mml:mi>σ</mml:mi><mml:mo stretchy="false">~</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mn>12</mml:mn></mml:mrow></mml:msub><mml:mrow><mml:msqrt><mml:msub><mml:mrow><mml:mover><mml:mi>σ</mml:mi><mml:mo stretchy="false">~</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mn>11</mml:mn></mml:mrow></mml:msub></mml:msqrt><mml:msqrt><mml:msub><mml:mrow><mml:mover><mml:mi>σ</mml:mi><mml:mo stretchy="false">~</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mn>22</mml:mn></mml:mrow></mml:msub></mml:msqrt></mml:mrow></mml:mfrac><mml:mo>)</mml:mo></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:mstyle></mml:mrow></mml:math></disp-formula></p><p>and <inline-formula><mml:math id="inf136"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msubsup><mml:mrow><mml:mover><mml:mi>σ</mml:mi><mml:mo stretchy="false">~</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mn>23</mml:mn></mml:mrow><mml:mrow><mml:mo>∗</mml:mo></mml:mrow></mml:msubsup><mml:mo>,</mml:mo><mml:msubsup><mml:mrow><mml:mover><mml:mi>σ</mml:mi><mml:mo stretchy="false">~</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mn>22</mml:mn></mml:mrow><mml:mrow><mml:mo>∗</mml:mo></mml:mrow></mml:msubsup><mml:mo>,</mml:mo><mml:msubsup><mml:mrow><mml:mover><mml:mi>σ</mml:mi><mml:mo stretchy="false">~</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mn>33</mml:mn></mml:mrow><mml:mrow><mml:mo>∗</mml:mo></mml:mrow></mml:msubsup></mml:mrow></mml:mstyle></mml:math></inline-formula> are coming from the inverse of <inline-formula><mml:math id="inf137"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mrow><mml:mover><mml:mi mathvariant="normal">Σ</mml:mi><mml:mo stretchy="false">~</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mn>12</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula><disp-formula id="equ33"><mml:math id="m33"><mml:mrow><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msubsup><mml:mrow><mml:mover><mml:mi>σ</mml:mi><mml:mo stretchy="false">~</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mn>23</mml:mn></mml:mrow><mml:mrow><mml:mo>∗</mml:mo></mml:mrow></mml:msubsup><mml:mo>=</mml:mo><mml:msub><mml:mi>λ</mml:mi><mml:mrow><mml:mi>z</mml:mi></mml:mrow></mml:msub><mml:msub><mml:mi>a</mml:mi><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mi>a</mml:mi><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msub><mml:msub><mml:mi>λ</mml:mi><mml:mrow><mml:mi>z</mml:mi></mml:mrow></mml:msub><mml:msub><mml:mi>ρ</mml:mi><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:msub><mml:mi>ρ</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mi>a</mml:mi><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msub><mml:msub><mml:mi>a</mml:mi><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:msub><mml:mi>ρ</mml:mi><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:msub><mml:mi>ρ</mml:mi><mml:mrow><mml:mn>3</mml:mn></mml:mrow></mml:msub><mml:mo>−</mml:mo><mml:msub><mml:mi>a</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:mo>−</mml:mo><mml:msub><mml:mi>a</mml:mi><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msub><mml:msub><mml:mi>ρ</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:msub><mml:mi>ρ</mml:mi><mml:mrow><mml:mn>3</mml:mn></mml:mrow></mml:msub><mml:mo>−</mml:mo><mml:msub><mml:mi>a</mml:mi><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msub><mml:msub><mml:mi>a</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:msubsup><mml:mi>ρ</mml:mi><mml:mrow><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup></mml:mstyle></mml:mrow></mml:math></disp-formula><disp-formula id="equ34"><mml:math id="m34"><mml:mrow><mml:mo>=</mml:mo><mml:msub><mml:mi>a</mml:mi><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msub><mml:msub><mml:mi>λ</mml:mi><mml:mrow><mml:mi>z</mml:mi></mml:mrow></mml:msub><mml:msub><mml:mi>ρ</mml:mi><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:msub><mml:mi>ρ</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mi>a</mml:mi><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msub><mml:msubsup><mml:mi>α</mml:mi><mml:mrow><mml:mi>z</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup><mml:msubsup><mml:mi>ρ</mml:mi><mml:mrow><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup><mml:mo>−</mml:mo><mml:msub><mml:mi>a</mml:mi><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msub><mml:msub><mml:mi>α</mml:mi><mml:mrow><mml:mi>z</mml:mi></mml:mrow></mml:msub><mml:msub><mml:mi>ρ</mml:mi><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:msub><mml:mi>ρ</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:mo>−</mml:mo><mml:msub><mml:mi>a</mml:mi><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msub><mml:msub><mml:mi>α</mml:mi><mml:mrow><mml:mi>z</mml:mi></mml:mrow></mml:msub><mml:msub><mml:mi>λ</mml:mi><mml:mrow><mml:mi>z</mml:mi></mml:mrow></mml:msub><mml:msubsup><mml:mi>ρ</mml:mi><mml:mrow><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup></mml:mrow></mml:math></disp-formula><disp-formula id="equ35"><mml:math id="m35"><mml:mrow><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msubsup><mml:mrow><mml:mover><mml:mi>σ</mml:mi><mml:mo stretchy="false">~</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mn>22</mml:mn></mml:mrow><mml:mrow><mml:mo>∗</mml:mo></mml:mrow></mml:msubsup><mml:mo>=</mml:mo><mml:mn>1</mml:mn><mml:mo>+</mml:mo><mml:msub><mml:mi>a</mml:mi><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msub><mml:msubsup><mml:mi>ρ</mml:mi><mml:mrow><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup><mml:mo>+</mml:mo><mml:msub><mml:mi>a</mml:mi><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msub><mml:msubsup><mml:mi>ρ</mml:mi><mml:mrow><mml:mn>3</mml:mn></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup><mml:mo>−</mml:mo><mml:msubsup><mml:mi>a</mml:mi><mml:mrow><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup><mml:mo>−</mml:mo><mml:mn>2</mml:mn><mml:msub><mml:mi>a</mml:mi><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msub><mml:msub><mml:mi>a</mml:mi><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:msub><mml:mi>ρ</mml:mi><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:msub><mml:mi>ρ</mml:mi><mml:mrow><mml:mn>3</mml:mn></mml:mrow></mml:msub></mml:mstyle></mml:mrow></mml:math></disp-formula><disp-formula id="equ36"><mml:math id="m36"><mml:mrow><mml:mo>=</mml:mo><mml:mn>1</mml:mn><mml:mo>+</mml:mo><mml:msub><mml:mi>a</mml:mi><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msub><mml:msubsup><mml:mi>ρ</mml:mi><mml:mrow><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup><mml:mo>−</mml:mo><mml:msubsup><mml:mi>α</mml:mi><mml:mrow><mml:mi>z</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup><mml:mo>−</mml:mo><mml:msub><mml:mi>a</mml:mi><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msub><mml:msubsup><mml:mi>α</mml:mi><mml:mrow><mml:mi>z</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup><mml:msubsup><mml:mi>ρ</mml:mi><mml:mrow><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup></mml:mrow></mml:math></disp-formula><disp-formula id="equ37"><mml:math id="m37"><mml:mrow><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msubsup><mml:mrow><mml:mover><mml:mi>σ</mml:mi><mml:mo stretchy="false">~</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mn>33</mml:mn></mml:mrow><mml:mrow><mml:mo>∗</mml:mo></mml:mrow></mml:msubsup><mml:mo>=</mml:mo><mml:mn>1</mml:mn><mml:mo>+</mml:mo><mml:msub><mml:mi>a</mml:mi><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msub><mml:msubsup><mml:mi>ρ</mml:mi><mml:mrow><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup><mml:mo>+</mml:mo><mml:msub><mml:mi>a</mml:mi><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msub><mml:msubsup><mml:mi>ρ</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup><mml:mo>−</mml:mo><mml:msubsup><mml:mi>λ</mml:mi><mml:mrow><mml:mi>z</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup><mml:mo>−</mml:mo><mml:mn>2</mml:mn><mml:msub><mml:mi>a</mml:mi><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msub><mml:msub><mml:mi>λ</mml:mi><mml:mrow><mml:mi>z</mml:mi></mml:mrow></mml:msub><mml:msub><mml:mi>ρ</mml:mi><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:msub><mml:mi>ρ</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub></mml:mstyle></mml:mrow></mml:math></disp-formula></p><p>In all, our derivations show that selecting on <italic>Y</italic><sub>1</sub> can have some impact on the causal estimate of the effect of covariate <italic>X</italic> on <italic>Y</italic><sub>2</sub>. To bring our point home, we perform a simulation study where we randomly select a data set of 1000 according to our data generating above. We consider the eight pairs (<italic>a</italic>, <italic>b</italic>) discussed above, and for each pair, we chose two values of <inline-formula><mml:math id="inf138"><mml:mi>τ</mml:mi></mml:math></inline-formula> (high and low). To each value of <inline-formula><mml:math id="inf139"><mml:mi>τ</mml:mi><mml:mo>,</mml:mo></mml:math></inline-formula> we have an associated value of <inline-formula><mml:math id="inf140"><mml:msub><mml:mrow><mml:mi>λ</mml:mi></mml:mrow><mml:mrow><mml:mi>z</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>β</mml:mi></mml:mrow><mml:mrow><mml:mi>x</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>β</mml:mi></mml:mrow><mml:mrow><mml:mi>z</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> . We choose the value of <inline-formula><mml:math id="inf141"><mml:msub><mml:mrow><mml:mi>α</mml:mi></mml:mrow><mml:mrow><mml:mi>x</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mn>0</mml:mn></mml:math></inline-formula> and <inline-formula><mml:math id="inf142"><mml:msub><mml:mrow><mml:mi>α</mml:mi></mml:mrow><mml:mrow><mml:mi>z</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mn>0.6</mml:mn></mml:math></inline-formula>. The sample size for each data set simulated is 50,000 and we report the average bias for the adjusted (controlling for the confounder <italic>Z</italic>) and unadjusted causal effect of the covariate <italic>X</italic> on the response <inline-formula><mml:math id="inf143"><mml:msub><mml:mrow><mml:mi>Y</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub></mml:math></inline-formula> based on the full data (All Data) and the data obtained after selecting on <inline-formula><mml:math id="inf144"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>Y</mml:mi><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>S</mml:mi><mml:mi>e</mml:mi><mml:mi>l</mml:mi><mml:mi>e</mml:mi><mml:mi>c</mml:mi><mml:mi>t</mml:mi><mml:mi>o</mml:mi><mml:mi>n</mml:mi><mml:msub><mml:mi>Y</mml:mi><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>&gt;</mml:mo><mml:mi>τ</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mstyle></mml:math></inline-formula>.  We report our findings in <xref ref-type="table" rid="app2table3">Appendix 2—table 3</xref>. Adjusting for the confounder yields an unbiased estimate of the causal effect of <italic>X</italic> on <inline-formula><mml:math id="inf145"><mml:msub><mml:mrow><mml:mi>Y</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn><mml:mo>.</mml:mo></mml:mrow></mml:msub></mml:math></inline-formula> Under both full and selected data scenarios, that estimated effect is biased. However, the estimated causal effect is biased for the full data and unbiased for the selected data when omitting the confounder.</p><table-wrap id="app2table3" position="float"><label>Appendix 2—table 3.</label><caption><title>Estimated Average Bias of <inline-formula><mml:math id="inf146"><mml:msub><mml:mrow><mml:mi>α</mml:mi></mml:mrow><mml:mrow><mml:mi>x</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> Under Various Scenarios.</title><p>Where <inline-formula><mml:math id="inf147"><mml:mi>τ</mml:mi><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>β</mml:mi></mml:mrow><mml:mrow><mml:mi>x</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>β</mml:mi></mml:mrow><mml:mrow><mml:mi>z</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> are selected to Induce a Zero Correlation Between <inline-formula><mml:math id="inf148"><mml:mi>X</mml:mi></mml:math></inline-formula> and <inline-formula><mml:math id="inf149"><mml:mi>Z</mml:mi></mml:math></inline-formula> After Selecting on <inline-formula><mml:math id="inf150"><mml:msub><mml:mrow><mml:mi>Y</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:math></inline-formula> . Results are based on sample size of n=50,000 and 1000 samples obtained from the data-generating model described above.</p></caption><table frame="hsides" rules="groups"><thead><tr><th align="left" valign="bottom" rowspan="2"><inline-formula><mml:math id="inf151"><mml:mi>a</mml:mi></mml:math></inline-formula></th><th align="left" valign="bottom" rowspan="2"><inline-formula><mml:math id="inf152"><mml:mi>b</mml:mi></mml:math></inline-formula></th><th align="left" valign="bottom" rowspan="2"><inline-formula><mml:math id="inf153"><mml:msub><mml:mrow><mml:mi>λ</mml:mi></mml:mrow><mml:mrow><mml:mi>z</mml:mi></mml:mrow></mml:msub><mml:mfenced separators="|"><mml:mrow><mml:mi>m</mml:mi><mml:mi>a</mml:mi><mml:mi>x</mml:mi></mml:mrow></mml:mfenced></mml:math></inline-formula></th><th align="left" valign="bottom" rowspan="2"><inline-formula><mml:math id="inf154"><mml:msub><mml:mrow><mml:mi>β</mml:mi></mml:mrow><mml:mrow><mml:mi>x</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula></th><th align="left" valign="bottom" rowspan="2"><inline-formula><mml:math id="inf155"><mml:msub><mml:mrow><mml:mi>β</mml:mi></mml:mrow><mml:mrow><mml:mi>z</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula></th><th align="left" valign="bottom" rowspan="2"><inline-formula><mml:math id="inf156"><mml:msub><mml:mrow><mml:mi>λ</mml:mi></mml:mrow><mml:mrow><mml:mi>z</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula></th><th align="left" valign="bottom" rowspan="2"><inline-formula><mml:math id="inf157"><mml:mi>τ</mml:mi></mml:math></inline-formula></th><th align="left" valign="bottom" colspan="2">All data</th><th align="left" valign="bottom" colspan="2">Select on <inline-formula><mml:math id="inf158"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>Y</mml:mi><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>&gt;</mml:mo><mml:mi>τ</mml:mi></mml:mrow></mml:mstyle></mml:math></inline-formula></th></tr><tr><th align="left" valign="bottom"><inline-formula><mml:math id="inf159"><mml:msub><mml:mrow><mml:mi>α</mml:mi></mml:mrow><mml:mrow><mml:mi>x</mml:mi><mml:mo>.</mml:mo><mml:mi>z</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula></th><th align="left" valign="bottom"><inline-formula><mml:math id="inf160"><mml:msub><mml:mrow><mml:mi>α</mml:mi></mml:mrow><mml:mrow><mml:mi>x</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula></th><th align="left" valign="bottom"><inline-formula><mml:math id="inf161"><mml:msub><mml:mrow><mml:mi>α</mml:mi></mml:mrow><mml:mrow><mml:mi>x</mml:mi><mml:mo>.</mml:mo><mml:mi>z</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula></th><th align="left" valign="bottom"><inline-formula><mml:math id="inf162"><mml:msub><mml:mrow><mml:mi>α</mml:mi></mml:mrow><mml:mrow><mml:mi>x</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula></th></tr></thead><tbody><tr><td align="left" valign="bottom">0.2</td><td align="left" valign="bottom">0.2</td><td align="left" valign="bottom">0.0422</td><td align="left" valign="bottom">0.2000</td><td align="left" valign="bottom">0.1952</td><td align="left" valign="bottom">0.0200</td><td align="left" valign="bottom">–0.5774</td><td align="left" valign="bottom">–0.0000</td><td align="left" valign="bottom">0.0118</td><td align="left" valign="bottom">–0.0002</td><td align="left" valign="bottom">–0.0002</td></tr><tr><td align="left" valign="bottom">0.2</td><td align="left" valign="bottom">0.2</td><td align="left" valign="bottom">0.0422</td><td align="left" valign="bottom">0.1999</td><td align="left" valign="bottom">0.1946</td><td align="left" valign="bottom">0.0350</td><td align="left" valign="bottom">1.3809</td><td align="left" valign="bottom">–0.0001</td><td align="left" valign="bottom">0.0208</td><td align="left" valign="bottom">–0.0004</td><td align="left" valign="bottom">–0.0008</td></tr><tr><td align="left" valign="bottom">0.2</td><td align="left" valign="bottom">0.9</td><td align="left" valign="bottom">0.5519</td><td align="left" valign="bottom">0.1931</td><td align="left" valign="bottom">0.8361</td><td align="left" valign="bottom">0.2700</td><td align="left" valign="bottom">0.4647</td><td align="left" valign="bottom">–0.0001</td><td align="left" valign="bottom">0.1620</td><td align="left" valign="bottom">–0.0002</td><td align="left" valign="bottom">–0.0001</td></tr><tr><td align="left" valign="bottom">0.2</td><td align="left" valign="bottom">0.9</td><td align="left" valign="bottom">0.5519</td><td align="left" valign="bottom">0.1857</td><td align="left" valign="bottom">0.8175</td><td align="left" valign="bottom">0.4000</td><td align="left" valign="bottom">1.8276</td><td align="left" valign="bottom">–0.0001</td><td align="left" valign="bottom">0.2398</td><td align="left" valign="bottom">–0.0002</td><td align="left" valign="bottom">–0.0003</td></tr><tr><td align="left" valign="bottom">0.9</td><td align="left" valign="bottom">0.2</td><td align="left" valign="bottom">0.2277</td><td align="left" valign="bottom">0.8936</td><td align="left" valign="bottom">0.0683</td><td align="left" valign="bottom">0.1200</td><td align="left" valign="bottom">0.6717</td><td align="left" valign="bottom">0.0001</td><td align="left" valign="bottom">0.0721</td><td align="left" valign="bottom">0.0005</td><td align="left" valign="bottom">0.0009</td></tr><tr><td align="left" valign="bottom">0.9</td><td align="left" valign="bottom">0.2</td><td align="left" valign="bottom">0.2277</td><td align="left" valign="bottom">0.8842</td><td align="left" valign="bottom">0.0598</td><td align="left" valign="bottom">0.1900</td><td align="left" valign="bottom">3.0584</td><td align="left" valign="bottom">0.0001</td><td align="left" valign="bottom">0.1140</td><td align="left" valign="bottom">–0.0080</td><td align="left" valign="bottom">–0.0118</td></tr><tr><td align="left" valign="bottom">0.9</td><td align="left" valign="bottom">0.9</td><td align="left" valign="bottom">0.5156</td><td align="left" valign="bottom">0.8710</td><td align="left" valign="bottom">0.2383</td><td align="left" valign="bottom">0.2600</td><td align="left" valign="bottom">–0.1627</td><td align="left" valign="bottom">–0.0002</td><td align="left" valign="bottom">0.1556</td><td align="left" valign="bottom">–0.0001</td><td align="left" valign="bottom">–0.0003</td></tr><tr><td align="left" valign="bottom">0.9</td><td align="left" valign="bottom">0.9</td><td align="left" valign="bottom">0.5156</td><td align="left" valign="bottom">0.8207</td><td align="left" valign="bottom">0.1818</td><td align="left" valign="bottom">0.4500</td><td align="left" valign="bottom">2.3590</td><td align="left" valign="bottom">–0.0002</td><td align="left" valign="bottom">0.2699</td><td align="left" valign="bottom">0.0011</td><td align="left" valign="bottom">–0.0005</td></tr></tbody></table></table-wrap><fig id="app2fig1" position="float"><label>Appendix 2—figure 1.</label><caption><title>Causal relationships of outcome, covariate, and confounding.</title><p>Direction of arrows represents causal directions and 𝜆<sub><italic>z</italic></sub>, 𝛼<sub><italic>z</italic></sub>, 𝛼<sub><italic>x</italic></sub><italic>,</italic> 𝛽<sub><italic>z</italic></sub>, and 𝛽<sub><italic>x</italic></sub> are structural coefficients.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-82268-app2-fig1-v1.tif"/></fig><fig id="app2fig2" position="float"><label>Appendix 2—figure 2.</label><caption><title>Possible values of <inline-formula><mml:math id="inf163"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>λ</mml:mi><mml:mrow><mml:mi>z</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula> based on each choice of the pairs of a, b.</title><p>The area shaded in green denotes the area for which a <inline-formula><mml:math id="inf164"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>λ</mml:mi><mml:mrow><mml:mi>z</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula> value has a value τ that makes <xref ref-type="disp-formula" rid="equ21">Equation 13</xref> equal zero.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-82268-app2-fig2-v1.tif"/></fig></sec></app></app-group></back></article>