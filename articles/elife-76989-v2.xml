<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD with MathML3 v1.2 20190208//EN"  "JATS-archivearticle1-mathml3.dtd"><article xmlns:ali="http://www.niso.org/schemas/ali/1.0/" xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" article-type="research-article" dtd-version="1.2"><front><journal-meta><journal-id journal-id-type="nlm-ta">elife</journal-id><journal-id journal-id-type="publisher-id">eLife</journal-id><journal-title-group><journal-title>eLife</journal-title></journal-title-group><issn publication-format="electronic" pub-type="epub">2050-084X</issn><publisher><publisher-name>eLife Sciences Publications, Ltd</publisher-name></publisher></journal-meta><article-meta><article-id pub-id-type="publisher-id">76989</article-id><article-id pub-id-type="doi">10.7554/eLife.76989</article-id><article-categories><subj-group subj-group-type="display-channel"><subject>Research Article</subject></subj-group><subj-group subj-group-type="heading"><subject>Physics of Living Systems</subject></subj-group></article-categories><title-group><article-title>Alternation emerges as a multi-modal strategy for turbulent odor navigation</article-title></title-group><contrib-group><contrib contrib-type="author" equal-contrib="yes" id="author-246493"><name><surname>Rigolli</surname><given-names>Nicola</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">https://orcid.org/0000-0002-0734-2105</contrib-id><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="aff" rid="aff2">2</xref><xref ref-type="aff" rid="aff3">3</xref><xref ref-type="fn" rid="equal-contrib1">†</xref><xref ref-type="fn" rid="con1"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" equal-contrib="yes" id="author-186691"><name><surname>Reddy</surname><given-names>Gautam</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">https://orcid.org/0000-0002-1276-9613</contrib-id><xref ref-type="aff" rid="aff4">4</xref><xref ref-type="aff" rid="aff5">5</xref><xref ref-type="aff" rid="aff6">6</xref><xref ref-type="fn" rid="equal-contrib1">†</xref><xref ref-type="other" rid="fund1"/><xref ref-type="other" rid="fund6"/><xref ref-type="fn" rid="con2"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" corresp="yes" id="author-72412"><name><surname>Seminara</surname><given-names>Agnese</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">https://orcid.org/0000-0001-5633-8180</contrib-id><email>agnese.seminara@unige.it</email><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="aff" rid="aff2">2</xref><xref ref-type="other" rid="fund2"/><xref ref-type="other" rid="fund3"/><xref ref-type="other" rid="fund4"/><xref ref-type="fn" rid="con3"/><xref ref-type="fn" rid="conf2"/></contrib><contrib contrib-type="author" corresp="yes" id="author-266653"><name><surname>Vergassola</surname><given-names>Massimo</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">https://orcid.org/0000-0002-7212-8244</contrib-id><email>massimo.vergassola@phys.ens.fr</email><xref ref-type="aff" rid="aff7">7</xref><xref ref-type="other" rid="fund5"/><xref ref-type="fn" rid="con4"/><xref ref-type="fn" rid="conf3"/></contrib><aff id="aff1"><label>1</label><institution-wrap><institution-id institution-id-type="ror">https://ror.org/0107c5v14</institution-id><institution>MalGa, Department of Civil, Chemical and Mechanical Engineering, University of Genova</institution></institution-wrap><addr-line><named-content content-type="city">Genova</named-content></addr-line><country>Italy</country></aff><aff id="aff2"><label>2</label><institution-wrap><institution-id institution-id-type="ror">https://ror.org/019tgvf94</institution-id><institution>Institut de Physique de Nice, Université Côte d’Azur, Centre National de la Recherche Scientifique</institution></institution-wrap><addr-line><named-content content-type="city">Nice</named-content></addr-line><country>France</country></aff><aff id="aff3"><label>3</label><institution-wrap><institution-id institution-id-type="ror">https://ror.org/0107c5v14</institution-id><institution>Department of Physics and INFN Genova, University of Genova</institution></institution-wrap><addr-line><named-content content-type="city">Genova</named-content></addr-line><country>Italy</country></aff><aff id="aff4"><label>4</label><institution-wrap><institution-id institution-id-type="ror">https://ror.org/03vek6s52</institution-id><institution>NSF-Simons Center for Mathematical and Statistical Analysis of Biology, Harvard University</institution></institution-wrap><addr-line><named-content content-type="city">Cambridge</named-content></addr-line><country>United States</country></aff><aff id="aff5"><label>5</label><institution>Physics &amp; Informatics Laboratories, NTT Research, Inc</institution><addr-line><named-content content-type="city">Sunnyvale</named-content></addr-line><country>United States</country></aff><aff id="aff6"><label>6</label><institution-wrap><institution-id institution-id-type="ror">https://ror.org/03vek6s52</institution-id><institution>Center for Brain Science, Harvard University</institution></institution-wrap><addr-line><named-content content-type="city">Cambridge</named-content></addr-line><country>United States</country></aff><aff id="aff7"><label>7</label><institution-wrap><institution-id institution-id-type="ror">https://ror.org/03a26mh11</institution-id><institution>Laboratoire de physique de l’École Normale Supérieure, CNRS, PSL Research University, Sorbonne Université</institution></institution-wrap><addr-line><named-content content-type="city">Paris</named-content></addr-line><country>France</country></aff></contrib-group><contrib-group content-type="section"><contrib contrib-type="editor"><name><surname>Sharpee</surname><given-names>Tatyana O</given-names></name><role>Reviewing Editor</role><aff><institution-wrap><institution-id institution-id-type="ror">https://ror.org/03xez1567</institution-id><institution>Salk Institute for Biological Studies</institution></institution-wrap><country>United States</country></aff></contrib><contrib contrib-type="senior_editor"><name><surname>Calabrese</surname><given-names>Ronald L</given-names></name><role>Senior Editor</role><aff><institution-wrap><institution-id institution-id-type="ror">https://ror.org/03czfpz43</institution-id><institution>Emory University</institution></institution-wrap><country>United States</country></aff></contrib></contrib-group><author-notes><fn fn-type="con" id="equal-contrib1"><label>†</label><p>These authors contributed equally to this work</p></fn></author-notes><pub-date publication-format="electronic" date-type="publication"><day>23</day><month>08</month><year>2022</year></pub-date><pub-date pub-type="collection"><year>2022</year></pub-date><volume>11</volume><elocation-id>e76989</elocation-id><history><date date-type="received" iso-8601-date="2022-01-11"><day>11</day><month>01</month><year>2022</year></date><date date-type="accepted" iso-8601-date="2022-08-07"><day>07</day><month>08</month><year>2022</year></date></history><pub-history><event><event-desc>This manuscript was published as a preprint at .</event-desc><date date-type="preprint" iso-8601-date="2021-12-16"><day>16</day><month>12</month><year>2021</year></date><self-uri content-type="preprint" xlink:href="https://doi.org/10.1101/2021.12.14.472675"/></event></pub-history><permissions><copyright-statement>© 2022, Rigolli, Reddy et al</copyright-statement><copyright-year>2022</copyright-year><copyright-holder>Rigolli, Reddy et al</copyright-holder><ali:free_to_read/><license xlink:href="http://creativecommons.org/licenses/by/4.0/"><ali:license_ref>http://creativecommons.org/licenses/by/4.0/</ali:license_ref><license-p>This article is distributed under the terms of the <ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/licenses/by/4.0/">Creative Commons Attribution License</ext-link>, which permits unrestricted use and redistribution provided that the original author and source are credited.</license-p></license></permissions><self-uri content-type="pdf" xlink:href="elife-76989-v2.pdf"/><self-uri content-type="figures-pdf" xlink:href="elife-76989-figures-v2.pdf"/><related-article related-article-type="commentary" ext-link-type="doi" xlink:href="10.7554/eLife.82635" id="ra1"/><abstract><p>Foraging mammals exhibit a familiar yet poorly characterized phenomenon, ‘alternation’, a pause to sniff in the air preceded by the animal rearing on its hind legs or raising its head. Rodents spontaneously alternate in the presence of airflow, suggesting that alternation serves an important role during plume-tracking. To test this hypothesis, we combine fully resolved simulations of turbulent odor transport and Bellman optimization methods for decision-making under partial observability. We show that an agent trained to minimize search time in a realistic odor plume exhibits extensive alternation together with the characteristic cast-and-surge behavior observed in insects. Alternation is linked with casting and occurs more frequently far downwind of the source, where the likelihood of detecting airborne cues is higher relative to ground cues. Casting and alternation emerge as complementary tools for effective exploration with sparse cues. A model based on marginal value theory captures the interplay between casting, surging, and alternation.</p></abstract><kwd-group kwd-group-type="author-keywords"><kwd>olfactory navigation</kwd><kwd>turbulence</kwd><kwd>decision-making</kwd><kwd>foraging</kwd></kwd-group><kwd-group kwd-group-type="research-organism"><title>Research organism</title><kwd>None</kwd></kwd-group><funding-group><award-group id="fund1"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/100000001</institution-id><institution>National Science Foundation</institution></institution-wrap></funding-source><award-id>1764269</award-id><principal-award-recipient><name><surname>Reddy</surname><given-names>Gautam</given-names></name></principal-award-recipient></award-group><award-group id="fund2"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/501100000781</institution-id><institution>European Research Council</institution></institution-wrap></funding-source><award-id>101002724</award-id><principal-award-recipient><name><surname>Seminara</surname><given-names>Agnese</given-names></name></principal-award-recipient></award-group><award-group id="fund3"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/100000181</institution-id><institution>Air Force Office of Scientific Research</institution></institution-wrap></funding-source><award-id>FA8655-20-1-7028</award-id><principal-award-recipient><name><surname>Seminara</surname><given-names>Agnese</given-names></name></principal-award-recipient></award-group><award-group id="fund4"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/100000052</institution-id><institution>NIH Office of the Director</institution></institution-wrap></funding-source><award-id>R01DC018789</award-id><principal-award-recipient><name><surname>Seminara</surname><given-names>Agnese</given-names></name></principal-award-recipient></award-group><award-group id="fund5"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/100000001</institution-id><institution>National Science Foundation</institution></institution-wrap></funding-source><award-id>PHY-1748958</award-id><principal-award-recipient><name><surname>Vergassola</surname><given-names>Massimo</given-names></name></principal-award-recipient></award-group><award-group id="fund6"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/100000936</institution-id><institution>Gordon and Betty Moore Foundation</institution></institution-wrap></funding-source><award-id>2919.02</award-id><principal-award-recipient><name><surname>Reddy</surname><given-names>Gautam</given-names></name></principal-award-recipient></award-group><funding-statement>The funders had no role in study design, data collection and interpretation, or the decision to submit the work for publication.</funding-statement></funding-group><custom-meta-group><custom-meta specific-use="meta-only"><meta-name>Author impact statement</meta-name><meta-value>A tracking animal's decision to intermittently pause and sniff the air reflects its belief that it is far downwind of the odor source, where benefits of sensing rare airborne cues outweigh the cost of pausing.</meta-value></custom-meta></custom-meta-group></article-meta></front><body><sec id="s1" sec-type="intro"><title>Introduction</title><p>The behavior of dogs alternating between sniffing in the air and close to the ground while tracking an odor scent is familiar to any cynophilist (<xref ref-type="bibr" rid="bib30">Thesen et al., 1993</xref>; <xref ref-type="bibr" rid="bib28">Steen et al., 1996</xref>; <xref ref-type="bibr" rid="bib12">Hepper and Wells, 2005</xref>; <xref ref-type="bibr" rid="bib13">Jinn et al., 2020</xref>). A similar behavior is well documented for rodents, where the slowdown associated with sniffing in the air can lead to stopping and rearing of the animal on its hind legs (<xref ref-type="bibr" rid="bib15">Khan et al., 2012</xref>; <xref ref-type="bibr" rid="bib9">Gire et al., 2016</xref>). This ‘alternation’ between the two sensorimotor modalities strongly suggests that both airborne and ground odor cues may be exploited by animals and integrated into a multi-modal navigation strategy.</p><p>Despite the behavior’s familiarity, the reasons underlying the alternation between airborne and ground odor cues as well as the rationale of their integration are largely unknown (<xref ref-type="bibr" rid="bib21">Reddy et al., 2022</xref>). Rodents may rear on their hind legs for a variety of reasons, generally associated with novelty detection, information gathering, anxiety and fear, as reviewed by <xref ref-type="bibr" rid="bib16">Lever et al., 2006</xref>. In the laboratory odor-guided search developed by <xref ref-type="bibr" rid="bib9">Gire et al., 2016</xref>, mice tend to pause and rear more often in the early stages of the task. This empirical observation is consistent with rearing in response to novelty and the hypothesis that raising their head may provide the animals additional olfactory information (<xref ref-type="bibr" rid="bib16">Lever et al., 2006</xref>). On the physical side, it is expected that ground and airborne odor signals convey complementary information even if both signals are generated by a single source of odors. Indeed, airborne odors are valuable as distal cues because they are transported rapidly over long distances by flows that are often turbulent. The downside of airborne cues is that turbulence breaks odor plumes in discrete pockets, which can only be detected sparsely (<xref ref-type="bibr" rid="bib19">Murlis and Jones, 1981</xref>; <xref ref-type="bibr" rid="bib25">Shraiman and Siggia, 2000</xref>; <xref ref-type="bibr" rid="bib7">Falkovich et al., 2001</xref>; <xref ref-type="bibr" rid="bib4">Celani et al., 2014</xref>). Furthermore, since local gradients are randomized in relation to the source direction at the timescales of olfactory searches, gradient-ascent navigation strategies are not possible (<xref ref-type="bibr" rid="bib31">Vergassola et al., 2007</xref>). Conversely, odor cues close to the ground are smoother and more continuous than odors in the air (<xref ref-type="bibr" rid="bib6">Fackrell and Robins, 1982</xref>; <xref ref-type="bibr" rid="bib20">Nironi et al., 2015</xref>). The physical reason is that viscous effects make fluids slow down while flowing close to the ground at rest. As a result, boundary layers are created and the structure of the flow depends on the height from the ground (<xref ref-type="bibr" rid="bib1">Anderson, 2005</xref>). In short, airborne cues are more sparse and difficult to exploit for navigation than ground signals, yet they are faster and cover longer ranges. It is therefore likely that the relative value of sniffing closer vs. farther from the ground depends on the position of the searcher relative to the source via the statistics of odor detections that the searcher experiences. The corresponding decision of the most appropriate sensorimotor modality in response to a given history of detections is then expected to play a major role in determining an effective navigational strategy.</p><p>Here, we propose a normative theory to rationalize alternation behavior and the integration of airborne and ground-based olfactory modalities. First, we create a well-controlled setup using fully resolved numerical simulations of the odor concentration field generated by an odor source in a channel flow. Simulations produce realistic odor plumes over distances of several meters to the source. Second, we ask what is the optimal strategy to reach the olfactory source (target) as identified by machine learning methods. Specifically, we formalize the olfactory search problem as a partially observable Markov decision process (POMDP) and use state-of-the-art methods to solve the corresponding Bellman optimization problem. The agent performing the olfactory search is given the choice between the actions of freely moving while sniffing on the ground or stopping and sniffing in the air. Solving the POMDP yields a policy of actions taken in response to a history of odor stimuli, which is encoded into a set of probabilistic beliefs about the location of the source. While the searcher could a priori reach the target using ground cues only, we demonstrate that learned strategies generically feature alternation between airborne and ground odor cues. Alternation is more frequent far downwind of the source and is associated with casting. The emergence of this non-trivial behavior is rationalized as the need to gather information under strong uncertainty from distal airborne cues, which leads to better long-term reward compared to local exploration for the source or proximal ground cues.</p><sec id="s1-1"><title>Model</title><p>Consider a food source located outdoors which exudes odor at a constant rate. The odor is steadily carried by the wind and dispersed due to turbulent fluctuations. In the atmosphere, turbulent transport of odors dominates molecular diffusion and determines the statistics of the odor signal. A plume-tracking agent which enters the area downwind has to navigate its way upwind toward the source by sniffing the ground or pausing to sniff in the air for odor.</p><p>The statistics of odors on the ground is profoundly different from the statistics of odors in the air (see representative time courses in <xref ref-type="fig" rid="fig1">Figure 1</xref>). In the situation represented in <xref ref-type="fig" rid="fig1">Figure 1</xref>, the divide between air and ground is dictated by the fluid dynamics in the boundary layer close to the ground. In our direct numerical simulations (DNS) of odor transport, the air travels in a channel from left and hits an obstacle at 25 cm/s, which generates turbulence. The simulations are designed to resolve the dynamics at all relevant scales, from few mm to several m, which demands massive computational resources (see Materials and methods for details of the numerical scheme). Odor is released from a spherical source of size 4 cm located 56 cm above the ground. At the height of the source, odor is efficiently carried several meters downwind within pockets of odor-laden air which remain relatively concentrated, but are distorted and broken by turbulence. Thus, odor in the air is intense but intermittent, that is, it varies abruptly in time. Conversely, odor near the ground is smoother but also less intense (see <xref ref-type="fig" rid="fig1">Figure 1</xref>). It is smoother because the air in contact with the ground is still, which creates a nearly stagnant boundary layer where the disruptive effect of turbulence is tamed; it is less intense because odorant molecules generally bind to surfaces, which act as odor sinks (see comprehensive discussions in the context of the design of olfactory tasks <xref ref-type="bibr" rid="bib10">Gorur-Shandilya et al., 2019</xref>).</p><fig id="fig1" position="float"><label>Figure 1.</label><caption><title>Alternation between different olfactory modalities is widespread in animal behavior.</title><p>Left: A rodent rearing on hind legs and smelling with its nose high up in the air; a dog performing a similar behavior. Credit: <ext-link ext-link-type="uri" xlink:href="https://www.shutterstock.com/explore/india-stock-assets-0221?c3apidt=p70314379936&amp;gclid=Cj0KCQjwxveXBhDDARIsAI0Q0x14h8f6TfPos0HmfiBXlK07z0svCWfRy-vrMnb3QKFtrsAt_p9nNkcaAoX5EALw_wcB&amp;gclsrc=aw.ds&amp;kw=shutterstock.com">irin-k/Shutterstock.com</ext-link> and <ext-link ext-link-type="uri" xlink:href="https://www.shutterstock.com/explore/india-stock-assets-0221?c3apidt=p71651485114&amp;gclid=Cj0KCQjwxveXBhDDARIsAI0Q0x3FwMqNQwsNmA4p2xnV8Cuq_OBTh-ZDCPLqmnvWjLntY-CEz4tJ8moaAv1HEALw_wcB&amp;gclsrc=aw.ds&amp;kw=shutterstock">Kasefoto/Shutterstock.com</ext-link>. Right: Side view of the direct numerical simulation of odor transport. Shades of blue give a qualitative view of the intensity of velocity fluctuations in a snapshot of the field. Colors are meant to emphasize the boundary layer near the bottom, where the velocity is reduced by the no-slip condition at the ground. Representative time courses of intense intermittent odor cues in air (sampled at 53 cm from the ground, locations marked with 1 and 2) vs. smoother and dimmer cues near the ground (sampled at 5 mm from from the ground, locations marked with 1’ and 2’). Different animals sniff at different heights, which alters details of the plumes but does not affect the general conclusions. Data obtained from direct numerical simulations of odor transport as described in the text, see Materials and methods for details.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-76989-fig1-v2.tif"/></fig><p>Our simulations specifically consider the limiting case of total adsorption of odor molecules. Qualitatively, similar results are expected for models intermediate between total adsorption and total reflection, where particles have a finite likelihood of being adsorbed or re-emitted in the bulk. Total (or partial) depletion of odors at the ground surface implies that an agent with a finite detection threshold can only sense ground odors near the source. Conversely, the agent can sense larger plumes in the air than on the ground compare top views in the air vs. the ground in <xref ref-type="fig" rid="fig2">Figure 2a-b</xref>, and it is able to detect odor in air across a more extended area (see <xref ref-type="fig" rid="fig2">Figure 2c</xref> and <xref ref-type="fig" rid="fig2s1">Figure 2—figure supplement 1</xref>).</p><fig-group><fig id="fig2" position="float"><label>Figure 2.</label><caption><title>Snapshots of odor plume obtained from direct numerical simulations of the Navier-Stokes equations in three spatial dimensions.</title><p>Top view of the odor plume (<bold>a</bold>) at nose height and (<bold>b</bold>) at ground. (<bold>c</bold>) 10% isoline of the probability to detect the odor <inline-formula><mml:math id="inf1"><mml:mrow><mml:mi>r</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>x</mml:mi><mml:mo>,</mml:mo><mml:mi>y</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> (defined as the probability that odor is above a fixed threshold of 0.14% with respect to the maximum concentration at the source) at the ground (gray) and at the nose height (black). Data to generate <xref ref-type="fig" rid="fig2">Figure 2</xref> are public on Zenodo (<ext-link ext-link-type="uri" xlink:href="https://zenodo.org/record/6538177#.Yqrl_5BByJE">https://zenodo.org/record/6538177#.Yqrl_5BByJE</ext-link>).</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-76989-fig2-v2.tif"/></fig><fig id="fig2s1" position="float" specific-use="child-fig"><label>Figure 2—figure supplement 1.</label><caption><title>Detection probability maps in the air and at the ground.</title><p>The probability per unit step of detecting an odor signal in the air and at the ground obtained from direct numerical simulations of odor transport. These detection rate maps constitute the observation likelihood models used to train the partially observable Markov decision process (POMDP). Note that the arena defined in the POMDP is larger than the volume where numerical simulations are conducted, depicted here (see <xref ref-type="fig" rid="fig3">Figure 3</xref> for instance). The detection rate in the space beyond the region simulated numerically is set to zero. Data to generate <xref ref-type="fig" rid="fig2s1">Figure 2—figure supplement 1</xref> are available in <xref ref-type="supplementary-material" rid="supp1">Supplementary file 1</xref>, folder fig5/statistics.mat.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-76989-fig2-figsupp1-v2.tif"/></fig></fig-group><p>The statistics of odor encounters detected along the search path of a plume-tracking agent provides useful information about the location of the source, which guides subsequent navigation. We consider an agent moving along a path <inline-formula><mml:math id="inf2"><mml:mrow><mml:msub><mml:mi>r</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>r</mml:mi><mml:mn>2</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:mi mathvariant="normal">…</mml:mi><mml:mo>,</mml:mo><mml:msub><mml:mi>r</mml:mi><mml:mi>t</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula> while measuring the odor signal <inline-formula><mml:math id="inf3"><mml:mrow><mml:msub><mml:mi>o</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>o</mml:mi><mml:mn>2</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:mi mathvariant="normal">…</mml:mi><mml:mo>,</mml:mo><mml:msub><mml:mi>o</mml:mi><mml:mi>t</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula>. The agent’s present knowledge is fully summarized by the posterior distribution of the agent’s location relative to the source, <inline-formula><mml:math id="inf4"><mml:msub><mml:mi mathvariant="bold">b</mml:mi><mml:mi>t</mml:mi></mml:msub></mml:math></inline-formula>, also called the belief vector. The agent computes Bayesian updates of the belief <inline-formula><mml:math id="inf5"><mml:msub><mml:mi mathvariant="bold">b</mml:mi><mml:mi>t</mml:mi></mml:msub></mml:math></inline-formula> using a model (the likelihood of odor detections) and the current observation <italic>o</italic><sub><italic>t</italic></sub>. At each time step, <italic>t</italic><sub><italic>s</italic></sub>, the agent decides among six alternatives: (i–iv) move to one of the four neighboring locations while sniffing the ground, (v) stay at the same location and sniff the ground, or (vi) stay at the same location and sniff the air. The agent decides among these choices based on the long-term reward it expects to receive, as discussed in the next paragraph.</p><p>We pose the agent’s task in the framework of optimal decision-making under uncertainty. The agent’s actions are driven by a unit reward received when it successfully finds the source. Rewards are discounted at a rate <italic>λ</italic>, that is, the expected long-term reward is <inline-formula><mml:math id="inf6"><mml:msub><mml:mrow><mml:mo stretchy="false">⟨</mml:mo><mml:msup><mml:mi>e</mml:mi><mml:mrow><mml:mo>-</mml:mo><mml:mrow><mml:mi>λ</mml:mi><mml:mo>⁢</mml:mo><mml:mi>T</mml:mi></mml:mrow></mml:mrow></mml:msup><mml:mo stretchy="false">⟩</mml:mo></mml:mrow><mml:mi>T</mml:mi></mml:msub></mml:math></inline-formula>. Here, <inline-formula><mml:math id="inf7"><mml:mi>T</mml:mi></mml:math></inline-formula> is the time taken to find the source and the expectation is over the prior knowledge available to the agent, its navigational strategy, and the statistics of odor encounters. The expected long-term reward or <italic>value</italic>, <inline-formula><mml:math id="inf8"><mml:mrow><mml:mi>V</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi mathvariant="bold">b</mml:mi><mml:mi>t</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula>, given the current state of knowledge, <inline-formula><mml:math id="inf9"><mml:msub><mml:mi mathvariant="bold">b</mml:mi><mml:mi>t</mml:mi></mml:msub></mml:math></inline-formula>, can be calculated using the Bellman equation, a dynamic programming equation which takes into account all possible future trajectories of an optimal agent. Specifically, we obtain the Bellman equation (see Materials and methods for details)<disp-formula id="equ1"><label>(1)</label><mml:math id="m1"><mml:mrow><mml:mi>V</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:msub><mml:mrow><mml:mi mathvariant="bold">b</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:munder><mml:mo movablelimits="true" form="prefix">max</mml:mo><mml:mrow><mml:mi>a</mml:mi></mml:mrow></mml:munder><mml:mrow><mml:mo>{</mml:mo><mml:mrow><mml:msub><mml:mi mathvariant="normal">Γ</mml:mi><mml:mrow><mml:mi>a</mml:mi></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:mi>γ</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:msub><mml:mi mathvariant="normal">Γ</mml:mi><mml:mrow><mml:mi>a</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:munder><mml:mo>∑</mml:mo><mml:mrow><mml:msub><mml:mi>o</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:munder><mml:mi>P</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>o</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="bold">b</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:mi>a</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mi>V</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:msub><mml:mrow><mml:mi mathvariant="bold">b</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>}</mml:mo></mml:mrow><mml:mo>,</mml:mo></mml:mrow></mml:math></disp-formula></p><p>where <inline-formula><mml:math id="inf10"><mml:msub><mml:mi mathvariant="normal">Γ</mml:mi><mml:mi>a</mml:mi></mml:msub></mml:math></inline-formula> is the probability of finding the source immediately after taking action <inline-formula><mml:math id="inf11"><mml:mi>a</mml:mi></mml:math></inline-formula>, <inline-formula><mml:math id="inf12"><mml:mrow><mml:mi>γ</mml:mi><mml:mo>≡</mml:mo><mml:msup><mml:mi>e</mml:mi><mml:mrow><mml:mo>-</mml:mo><mml:mrow><mml:mi>λ</mml:mi><mml:mo>⁢</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mi>s</mml:mi></mml:msub></mml:mrow></mml:mrow></mml:msup></mml:mrow></mml:math></inline-formula> and the probability <inline-formula><mml:math id="inf13"><mml:mrow><mml:mi>P</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:msub><mml:mi>o</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo lspace="2.5pt" rspace="2.5pt" stretchy="false">|</mml:mo><mml:mrow><mml:msub><mml:mi mathvariant="bold">b</mml:mi><mml:mi>t</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:mi>a</mml:mi></mml:mrow></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> of observing <inline-formula><mml:math id="inf14"><mml:msub><mml:mi>o</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:math></inline-formula> is determined by the physical environment and the signal detection threshold of the agent. Intuitively, the terms in the argument of the <inline-formula><mml:math id="inf15"><mml:mi>max</mml:mi></mml:math></inline-formula> function in <xref ref-type="disp-formula" rid="equ1">Equation 1</xref> represent the value of finding the source, detecting the odor signal or not detecting the odor signal, each event being weighted by its probability. The optimal action is the one that maximizes the value, that is, the parenthesis on the right-hand side of <xref ref-type="disp-formula" rid="equ1">Equation 1</xref>. For simplicity, we discretize observations into detections (odor signal above a fixed threshold) and non-detections, which implies that the behavior depends solely on the probability per unit time of detecting the odor on the ground or in the air (<xref ref-type="fig" rid="fig2">Figure 2c</xref>). Thus, the agent uses a (partially inaccurate) Poissonian detection model. The model is partially inaccurate as the average detection rate does match the simulated odor plumes but the model of the agent lacks the appropriate spatiotemporal correlations because detections are independent in the Poissonian model and they are not in the real flow. See Results for more details and the corresponding performance.</p><p>The decision-making dynamics form a POMDP (see Materials and methods for a brief introduction to POMDPs). To solve <xref ref-type="disp-formula" rid="equ1">Equation 1</xref>, we use approximate methods, which exploit a piecewise linear representation of the value function: <inline-formula><mml:math id="inf16"><mml:mrow><mml:mi>V</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi mathvariant="bold">b</mml:mi><mml:mi>t</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>≈</mml:mo><mml:msub><mml:mi>max</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mrow><mml:mo stretchy="false">{</mml:mo><mml:msub><mml:mi>α</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>.</mml:mo><mml:msub><mml:mi mathvariant="bold">b</mml:mi><mml:mi>t</mml:mi></mml:msub><mml:mo stretchy="false">}</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> (<xref ref-type="bibr" rid="bib24">Shani et al., 2013</xref>). The <inline-formula><mml:math id="inf17"><mml:msub><mml:mi>α</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:math></inline-formula>’s are a set of hyperplanes, which are found by simulating trajectories of the agent along exploratory search paths (Materials and methods). Given an existing set of <inline-formula><mml:math id="inf18"><mml:msub><mml:mi>α</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:math></inline-formula>’s, the rule for adding new hyperplanes is obtained by plugging in <inline-formula><mml:math id="inf19"><mml:mrow><mml:mi>V</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi mathvariant="bold">b</mml:mi><mml:mi>t</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>≈</mml:mo><mml:msub><mml:mi>max</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mrow><mml:mo stretchy="false">{</mml:mo><mml:msub><mml:mi>α</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>.</mml:mo><mml:msub><mml:mi mathvariant="bold">b</mml:mi><mml:mi>t</mml:mi></mml:msub><mml:mo stretchy="false">}</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> into <xref ref-type="disp-formula" rid="equ1">Equation 1</xref>. As training progresses, the set of hyperplanes grows and yields increasingly accurate approximations of the value function. For each test run, we begin with a uniform prior distribution and simulate the POMDP until the agent finds the source. If the agent does not find the source within 1000 steps, we interrupt the simulation. The time step, <italic>t</italic><sub><italic>s</italic></sub>, and the distance traveled at each step are set such that the agent sniffs three times per second and at every step it moves 12 cm.</p></sec></sec><sec id="s2" sec-type="results"><title>Results</title><sec id="s2-1"><title>The agent navigates by alternating between sniffing the ground and air</title><p>An agent initially downwind of the odor source learns to navigate the odor plume to maximize the discounted reward described previously, that is, to minimize the search time. The upshot of the learning phase is that the final search policy alternates between sniffing on the ground and the air (<xref ref-type="fig" rid="fig3">Figure 3</xref>). The average time taken to reach the source reduces considerably with the training time, indicating the emergence of an effective navigational strategy (<xref ref-type="fig" rid="fig3s1">Figure 3—figure supplement 1A, B</xref>).</p><fig-group><fig id="fig3" position="float"><label>Figure 3.</label><caption><title>Representative trajectories undertaken by an agent learning how to reach the source of a turbulent odor cue.</title><p>(<bold>a</bold>) Top view of a representative trajectory at the end of training. (<bold>b</bold>) Three-dimensional view of sample trajectory from panel (<bold>a</bold>), superimposed to two snapshots of odor plumes near ground (shades of blue) and in the air (shades of red). Trajectories are obtained by training a partially observable Markov decision process (POMDP), where the agent computes Bayesian updates of the belief using observations (odor detection or no detection) and their likelihood (detection rates from simulations of odor transport). Agents trained with this idealized model of odor plumes successfully track targets when tested in realistic conditions (see <xref ref-type="video" rid="fig3video1">Figure 3—video 1</xref>).</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-76989-fig3-v2.tif"/></fig><fig id="fig3s1" position="float" specific-use="child-fig"><label>Figure 3—figure supplement 1.</label><caption><title>Training efficiency and computational cost of partially observable Markov decision process (POMDP).</title><p>Performance of POMDP improves with training episodes and saturates after a certain number of iterations. (<bold>A</bold>) Training converges for different values of the discount factor <italic>γ</italic>, yellow is <italic>γ</italic>=0.90, red is <italic>γ</italic>=0.95, and blue is <italic>γ</italic>=0.99. The gain in performance with increasing <italic>γ</italic> is indicative of the development of a long-term strategy. We use <italic>γ</italic>=0.99 and number of training episodes <italic>i</italic>=320 throughout the Results section. (<bold>B</bold>) Few tens of training episodes are sufficient for the agent to locate the odor source but a bimodal performance emerges: most of the time the agent reaches the target in the standard amount of steps, but sometimes it takes many more. More training episodes are required to prevent the agent from locating the target in a long time. (<bold>C</bold>) Increasing the number of training episodes has a cost in terms of memory (<italic>α</italic> vectors to be stored during the training phase) and computational resources.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-76989-fig3-figsupp1-v2.tif"/></fig><media mimetype="video" mime-subtype="mp4" xlink:href="elife-76989-fig3-video1.mp4" id="fig3video1"><label>Figure 3—video 1.</label><caption><title>Trajectory of a partially observable Markov decision process (POMDP) agent navigating the realistic odor plumes simulated numerically.</title><p>The agent starts from the location marked with a white star, orange dots represent sniffs in the air, red crosses are detections, and the source is indicated by the red dot. Note that the agent successfully navigates this realistic odor plume, despite the fact that the POMDP is trained with a Poissonian model for odor detection ignoring the full spatiotemporal correlations of odor statistics.</p></caption></media></fig-group><p>The trajectories learnt by the agent display a variety of behaviors reminiscent of those exhibited by animals, which include wide crosswind casts interleaved with upwind surges. Notably, the agent exhibits a recurring motif which cycles between moving to a new location and pausing to sniff in the air. The alternating behavior emerges directly as a consequence of the statistics of the physical environment in spite of pausing to sniff in the air, which leads to the cost of a stronger discount in the reward.</p><p>When, where, and why does the agent sniff in the air? Trajectories shown in <xref ref-type="fig" rid="fig3">Figure 3</xref> exhibit extensive alternation at the beginning of the search when the agent is far downwind compared to when it is close to the source. A quantitative analysis across training and test realizations confirms that the agent’s rate of sniffing in the air is significantly higher farther away from the source (<xref ref-type="fig" rid="fig4">Figure 4(a)</xref>). This observation is rationalized by the greater probability of detecting an odor signal in the air at distant locations (<xref ref-type="fig" rid="fig2">Figure 2(c)</xref>) despite the increased intermittency in the airborne signal (<xref ref-type="fig" rid="fig1">Figure 1</xref>). In spite of the added cost entailed by slowing down locomotion, sniffing in the air ultimately speeds up the localization of the source (<xref ref-type="fig" rid="fig4">Figure 4(b)</xref>). This behavior is maintained across different training realizations and when the discount factor, <italic>γ</italic>, is reduced so that the delay incurs a greater cost. In sum, alternation emerges as a robust, functional aspect of an effective long-term strategy of olfactory search (see also <xref ref-type="fig" rid="fig4s1">Figure 4—figure supplement 1</xref>).</p><fig-group><fig id="fig4" position="float"><label>Figure 4.</label><caption><title>Empirical characterization of the alternation between olfactory sensory modalities.</title><p>(<bold>a</bold>) The agent sniffs more often in the air when it is far from the source, that is, outside of the airborne plume. The rate of sniffing in the air is the fraction of times the agent decides to sniff in the air rather than move and sniff on the ground. The fraction is computed over the entire trajectory in the conditions identified in the different panels. Statistics is collected over different realizations of the training process and many trajectories, with different starting positions (see Materials and methods for details). (<bold>b</bold>) The number of steps needed to reach the target minus the number of steps needed to travel from the starting position to the source in a straight line. The horizontal line marks the median, boxes mark 25th and 75th percentiles; red dot: outlier (value exceeds 75th percentile + ×1.5 interquartile range). Dashed lines mark 10th and 90th percentile. For reference, a straight line from the center of the belief to the source is 240 steps. Agents that are given the possibility to pause and sniff in the air are able to reach the target sooner than agents that can only sniff on the ground. (<bold>c</bold>) Agents sniff in the air once every five steps on average when they cast (three consecutive steps crosswind), whereas they only sniff in the air once every 60 steps while surging upwind (three consecutive steps upwind). (<bold>d</bold>) Entropy (cyan) and value (purple) of the belief vs. time, along the course of one trajectory. The red dot indicates a detection, which provides considerable information about source location and thus makes entropy plummet and value increase.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-76989-fig4-v2.tif"/></fig><fig id="fig4s1" position="float" specific-use="child-fig"><label>Figure 4—figure supplement 1.</label><caption><title>Empirical characterization of the alternation between olfactory sensory modalities when <inline-formula><mml:math id="inf20"><mml:mrow><mml:mi>γ</mml:mi><mml:mo>=</mml:mo><mml:mn>0.95</mml:mn></mml:mrow></mml:math></inline-formula>.</title><p>Here, we show the results analogous to <xref ref-type="fig" rid="fig4">Figure 4</xref> with a smaller discount factor <inline-formula><mml:math id="inf21"><mml:mrow><mml:mi>γ</mml:mi><mml:mo>=</mml:mo><mml:mn>0.95</mml:mn></mml:mrow></mml:math></inline-formula>. Alternation between olfactory modalities is preserved, as well as surging and casting.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-76989-fig4-figsupp1-v2.tif"/></fig><fig id="fig4s2" position="float" specific-use="child-fig"><label>Figure 4—figure supplement 2.</label><caption><title>Performance of an agent in a different environment during test.</title><p>Agent performance when it is trained in a certain environment and performs its search in a different one. On the left, the agent has access to static detection probability maps during test: from left to right, they have respectively ratio 1.5, 1, 0.75, 0.5 to the detection probability map used during training. On the right, the detection probability map during test rotates in time: A, a Ornstein-Uhlenbeck process (standard deviation = <inline-formula><mml:math id="inf22"><mml:msup><mml:mn>10</mml:mn><mml:mo>∘</mml:mo></mml:msup></mml:math></inline-formula>, frequency <inline-formula><mml:math id="inf23"><mml:mrow><mml:mi/><mml:mo>∼</mml:mo><mml:mrow><mml:mn>1</mml:mn><mml:mo>/</mml:mo><mml:mi>T</mml:mi></mml:mrow></mml:mrow></mml:math></inline-formula>) is used to simulate a meandering flow. Here, <inline-formula><mml:math id="inf24"><mml:mi>T</mml:mi></mml:math></inline-formula> is the large eddy turnover time equal to 64 time steps (<xref ref-type="table" rid="table1">Table 1</xref>); B, the test detection probability map rotates by 5° every time step in the interval [10, −10]; C, same as B, but the rotation frequency is <inline-formula><mml:math id="inf25"><mml:mrow><mml:mi/><mml:mo>∼</mml:mo><mml:mrow><mml:mn>1</mml:mn><mml:mo>/</mml:mo><mml:mi>T</mml:mi></mml:mrow></mml:mrow></mml:math></inline-formula>; D, same as B but the angular interval is extended to [30°, −30°]. The strategy learned during training is robust to variations of the detection probability map, implying that our algorithm is robust to changes in flow conditions; interestingly, we observe that on rare occasions the agent performs poorly or fails (bimodal behavior in the violin plots). Note that in these cases the test detection probability map deviates from the expected one and the overall detection probability is also reduced.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-76989-fig4-figsupp2-v2.tif"/></fig></fig-group><p>A striking feature of the trajectories in <xref ref-type="fig" rid="fig3">Figure 3</xref> is the strong correlation between casting and sniffing the air before the first detection is made. To quantify this effect, we categorize the agent’s behavior into casts (persistent crosswind movements) and surges (upwind movement), and measure the rate of sniffing the air (fraction of time spent executing action (vi) – staying at the same location and sniffing the air – among the six possible actions offered to the searcher) for both of these behaviors. We consider the agent to be surging if it moves <inline-formula><mml:math id="inf26"><mml:mi>k</mml:mi></mml:math></inline-formula> consecutive steps upwind and casting if it moves <inline-formula><mml:math id="inf27"><mml:mi>k</mml:mi></mml:math></inline-formula> consecutive steps crosswind or sniffs in the air. We use <inline-formula><mml:math id="inf28"><mml:mrow><mml:mi>k</mml:mi><mml:mo>=</mml:mo><mml:mn>3</mml:mn></mml:mrow></mml:math></inline-formula>, results shown hereafter do not depend strongly on this choice. We find that the rate of sniffing in the air is typically an order of magnitude greater during casts as compared to surges (<xref ref-type="fig" rid="fig4">Figure 4(c)</xref>), indicating that alternation is tightly linked to the switch between casting and surging. Casting has been classically interpreted as a strategy for efficient exploration in an intermittent environment. The coupling between casting and alternation observed here suggests that sniffing in the air is an alternative mode of exploration which aids and complements casting when searching for a sparse cue. Exploration dominates the first part of the search until the first detections which substantially reduce uncertainty (see entropy of the posterior distribution in <xref ref-type="fig" rid="fig4">Figure 4(d)</xref>).</p><p>Overall, we led to the following picture of the search dynamics. At the beginning of the search, the agent has a broad prior that is much larger than the odor plume of size <inline-formula><mml:math id="inf29"><mml:mrow><mml:mi/><mml:mo>∼</mml:mo><mml:mrow><mml:msub><mml:mi>x</mml:mi><mml:mtext>thr</mml:mtext></mml:msub><mml:mo>×</mml:mo><mml:msub><mml:mi>y</mml:mi><mml:mtext>thr</mml:mtext></mml:msub></mml:mrow></mml:mrow></mml:math></inline-formula>, where <inline-formula><mml:math id="inf30"><mml:msub><mml:mi>x</mml:mi><mml:mtext>thr</mml:mtext></mml:msub></mml:math></inline-formula> is the plume length and <inline-formula><mml:math id="inf31"><mml:msub><mml:mi>y</mml:mi><mml:mtext>thr</mml:mtext></mml:msub></mml:math></inline-formula> is the plume width when sniffing in the air. The agent then has to identify and home into the <inline-formula><mml:math id="inf32"><mml:mrow><mml:msub><mml:mi>x</mml:mi><mml:mtext>thr</mml:mtext></mml:msub><mml:mo>×</mml:mo><mml:msub><mml:mi>y</mml:mi><mml:mtext>thr</mml:mtext></mml:msub></mml:mrow></mml:math></inline-formula> region that contains the odor plume. The bottleneck in this phase is the scarcity of odor detections, which require an efficient exploration strategy. Once the odor plume is detected, the agent knows it is near the source and the search is driven by surface-borne odor cues, while the frequency of sniffing in the air is significantly reduced. In short, our simulations show that the behavior can be split into two distinct phases: (1) an initial exploration phase accompanied by extensive casting and alternation, where the agent attempts to localize the plume, and (2) odor-guided behavior in a regime relatively rich in cues, which enable the agent to precisely locate the source within the plume.</p><p>We conclude this section noting that the above remarks are expected to hold more generally than in the specific setup of our simulations. <xref ref-type="video" rid="fig3video1">Figure 3—video 1</xref> shows that the same behaviors are displayed by agents navigating a realistic plume despite their learning in a (partially inaccurate) Poissonian model of odor detections. This finding indicates the robustness of the learning scheme to inaccuracies in the model of the environment, which are inevitably present in any realistic situation. More specifically, the static information provided by the average detection rate map is found to be sufficient for navigation and alternation. While more information on dynamical spatiotemporal correlations may help further improve performance, the fundamental requirement for alternation is the presence of wider detection rate maps in the air than on the ground. Thus, as long as this feature is preserved, we expect agents to display alternating behaviors and the two phases mentioned above. In particular, these properties should hold also when different models of odor transport are employed by the searcher and/or surface adsorption chemistry is more involved than pure adsorption. <xref ref-type="fig" rid="fig4s2">Figure 4—figure supplement 2</xref> shows that the agent navigates successfully when the odor statistics is different from the one that was used for training, suggesting that the strategy is robust to a broad set of different flow conditions.</p></sec><sec id="s2-2"><title>Intuition</title><p>We now proceed to understand the transition between the two distinct phases of search that were identified previously. While a detailed analysis of each individual decision is challenging, we can gain intuition by decomposing the agent’s overall behavior into segments. Each segment is then rationalized by examining how the agent explores the locations where it believes it can find an odor signal or the source. For this purpose, let us examine how the agent’s belief of its location relative to the source evolves as the search proceeds.</p><p>In the representative example depicted in <xref ref-type="fig" rid="fig5">Figure 5</xref>, the agent begins with a uniform prior belief, much larger than the plume, as shown in the top row of <xref ref-type="fig" rid="fig5">Figure 5</xref>. The agent makes its first action by sniffing in the air and does not detect an odor signal. Since odor is not detected, the likelihood that the agent is immediately downwind of the source is reduced, which leads to a posterior belief updated via Bayes’ rule (second row, <xref ref-type="fig" rid="fig5">Figure 5</xref>). The agent proceeds by casting crosswind in a loop while occasionally pausing to sniff in the air (third row, <xref ref-type="fig" rid="fig5">Figure 5</xref>), after which it executes an upwind surge (fourth row, <xref ref-type="fig" rid="fig5">Figure 5</xref>). The decision to surge at that specific moment can be understood from examining the belief immediately before the surge: because the agent did not detect any odor over the entire cast-and-sniff sequence, the likelihood that the agent is located near the source, that is, within the plume, is extremely low (third row, <xref ref-type="fig" rid="fig5">Figure 5</xref>).</p><fig id="fig5" position="float"><label>Figure 5.</label><caption><title>Progression of the belief the agent has about its own position relative to the source.</title><p>From top, first panel: Before starting the search the agent has a flat belief about its own position, much broader than the plume in air represented by the 25% isoline of the probability of detection. Second: Belief after a single sniff in the air and no detection. The white region corresponds to the extent of the plume in air and indicates that because the agent did not detect the odor, it now believes it is <italic>not</italic> within the plume right downstream of the source. Third: As the agent casts, its belief about its own position translates sideways with it; additionally, at each sniff in the air with no detection, the belief gets depleted right downstream of the source, as in the panel right above. As a result, the cast-and-sniff cycle sweeps away a region of the belief as wide as the cast and as long as the plume. Fourth: As the agent surges upwind, its belief about its own position translates forward with it; additionally, as it sniffs on the ground with no detection, the belief gets depleted in a small region right downstream of the source, corresponding to the extent of the plume on the ground. Fifth: After detection, the belief shrinks to a narrow region around the actual position of the agent, which leads to the final phase of the search within the plume. Green (purple) wedges indicate that the entropy of the belief decreases (value of the belief increases) as the agent narrows down its possible positions (and approaches the source).</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-76989-fig5-v2.tif"/></fig><p>At this point, it is more valuable to surge upwind rather than continuing to explore the same area. By surging forward, the agent is now more likely to encounter the plume, which enables it to effectively explore the remaining part of the belief. The key to the above argument is that the agent lacks knowledge of its position relative to the source, and it acts so as to narrow down its belief. Indeed, over the course of a search, entropy of the belief steadily declines, while its value increases (<xref ref-type="fig" rid="fig4">Figure 4(d)</xref>).</p><p>A repetition of the sequence of casting, alternation, and surging follows as the agent steadily narrows down the belief, until it finally detects the odor (bottom panel, <xref ref-type="fig" rid="fig5">Figure 5</xref>). The detection shrinks the posterior to a small patch which makes entropy plummet (<xref ref-type="fig" rid="fig4">Figure 4(d)</xref>) and leads the agent rapidly to the source. The first detection event (identified by the red dot in <xref ref-type="fig" rid="fig4">Figure 4(d)</xref>) is what marks the transition between searching <italic>for</italic> the plume and searching <italic>within</italic> the plume, as discussed above.</p></sec><sec id="s2-3"><title>Searching for airborne cues</title><p>We now expand on the intuition above by introducing a simplified, quantitative model of the search. We aim to address the search dynamics in the initial phase before detection, when the agent searches for the plume. This is the key phase as the localization of the plume largely dominates the search time (see red dot in <xref ref-type="fig" rid="fig4">Figure 4(d)</xref>). We identify three main questions about the search, which we address in more detail below: (1) how wide should the agent cast?; (2) how long should the agent spend casting before surging upwind?; (3) where should the agent sniff during the casting phase? Specifically, we highlight and quantify the various trade-offs associated with the cast-sniff-surge modes of exploration.</p><p>To introduce the main simplification of the model, we note that in the exploratory regime at large distances, the agent is more likely to detect odor by sniffing in the air due to the larger detection range of airborne cues. We therefore ignore odor signal on the ground and assume the agent only detects odor by sniffing in the air. This simplifies the analysis considerably as the search path is then parameterized by the discrete locations at which the agent sniffs in the air rather than the specific trajectory taken between sampling locations. The agent’s prior belief distribution, <inline-formula><mml:math id="inf33"><mml:mrow><mml:mi mathvariant="bold">b</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>x</mml:mi><mml:mo>,</mml:mo><mml:mi>y</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula>, of its location with respect to the source is assumed to be uniform with length <inline-formula><mml:math id="inf34"><mml:msub><mml:mi>L</mml:mi><mml:mi>x</mml:mi></mml:msub></mml:math></inline-formula> (<inline-formula><mml:math id="inf35"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mo>≫</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mrow><mml:mtext>thr</mml:mtext></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula>) (along the downwind direction) and width <inline-formula><mml:math id="inf36"><mml:msub><mml:mi>L</mml:mi><mml:mi>y</mml:mi></mml:msub></mml:math></inline-formula> (<inline-formula><mml:math id="inf37"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mo>≫</mml:mo><mml:msub><mml:mi>y</mml:mi><mml:mrow><mml:mtext>thr</mml:mtext></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula>), similar to the example shown in <xref ref-type="fig" rid="fig5">Figure 5</xref> (top). The probability of detecting an odor signal in a sniff, <inline-formula><mml:math id="inf38"><mml:mrow><mml:mi>r</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>x</mml:mi><mml:mo>,</mml:mo><mml:mi>y</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula>, depends on the range and width of the plume through the parameters <inline-formula><mml:math id="inf39"><mml:msub><mml:mi>x</mml:mi><mml:mtext>thr</mml:mtext></mml:msub></mml:math></inline-formula> and <inline-formula><mml:math id="inf40"><mml:msub><mml:mi>y</mml:mi><mml:mtext>thr</mml:mtext></mml:msub></mml:math></inline-formula> respectively, which we assume are known to the agent. To decouple the upwind surge and crosswind cast, we approximate the detection probability map in <xref ref-type="fig" rid="fig2">Figure 2(c)</xref> as <inline-formula><mml:math id="inf41"><mml:mrow><mml:mrow><mml:mi>r</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>x</mml:mi><mml:mo>,</mml:mo><mml:mi>y</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mo>=</mml:mo><mml:mrow><mml:mi>f</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>x</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>⁢</mml:mo><mml:mi>g</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>y</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:math></inline-formula>, where <inline-formula><mml:math id="inf42"><mml:mrow><mml:mi>f</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>x</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> is a constant when <inline-formula><mml:math id="inf43"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mn>0</mml:mn><mml:mo>&lt;</mml:mo><mml:mi>x</mml:mi><mml:mo>&lt;</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mrow><mml:mtext>thr</mml:mtext></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula> and 0 otherwise and <inline-formula><mml:math id="inf44"><mml:mrow><mml:mi>g</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>y</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> has a characteristic length scale <inline-formula><mml:math id="inf45"><mml:msub><mml:mi>y</mml:mi><mml:mtext>thr</mml:mtext></mml:msub></mml:math></inline-formula>, namely, <inline-formula><mml:math id="inf46"><mml:mrow><mml:mrow><mml:mi>g</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>y</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mo>=</mml:mo><mml:msup><mml:mi>e</mml:mi><mml:mrow><mml:mo>-</mml:mo><mml:mrow><mml:mrow><mml:msup><mml:mi>y</mml:mi><mml:mn>2</mml:mn></mml:msup><mml:mo>/</mml:mo><mml:mn>2</mml:mn></mml:mrow><mml:mo>⁢</mml:mo><mml:msubsup><mml:mi>y</mml:mi><mml:mtext>thr</mml:mtext><mml:mn>2</mml:mn></mml:msubsup></mml:mrow></mml:mrow></mml:msup></mml:mrow></mml:math></inline-formula>. Instead of receiving reward for finding the source, the agent receives a unit reward (discounted at a rate <italic>λ</italic>) on detecting odor, at which point the search ends.</p><p>We first build an intuitive picture of the search dynamics in this simplified setting. To detect the plume, the agent has to sufficiently explore the region in which it expects to detect odor, which is delineated by the prior. Each sniff in the air will sample a patch of size <inline-formula><mml:math id="inf47"><mml:mrow><mml:mi/><mml:mo>∼</mml:mo><mml:mrow><mml:msub><mml:mi>x</mml:mi><mml:mtext>thr</mml:mtext></mml:msub><mml:mo>×</mml:mo><mml:msub><mml:mi>y</mml:mi><mml:mtext>thr</mml:mtext></mml:msub></mml:mrow></mml:mrow></mml:math></inline-formula> immediately upwind from its location. Since the prior’s width is larger than the plume width (<inline-formula><mml:math id="inf48"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>L</mml:mi><mml:mrow><mml:mi>y</mml:mi></mml:mrow></mml:msub><mml:mo>≫</mml:mo><mml:msub><mml:mi>y</mml:mi><mml:mrow><mml:mtext>thr</mml:mtext></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula>), the agent cannot sample the full breadth of the prior in one sniff and will thus have to cast crosswind and sniff the air. As each sniff explores a patch of length <inline-formula><mml:math id="inf49"><mml:msub><mml:mi>x</mml:mi><mml:mtext>thr</mml:mtext></mml:msub></mml:math></inline-formula>, a few bouts of cast-and-sniff across a width <inline-formula><mml:math id="inf50"><mml:msub><mml:mi>L</mml:mi><mml:mi>y</mml:mi></mml:msub></mml:math></inline-formula> will effectively explore an upwind region of size <inline-formula><mml:math id="inf51"><mml:mrow><mml:msub><mml:mi>x</mml:mi><mml:mtext>thr</mml:mtext></mml:msub><mml:mo>×</mml:mo><mml:msub><mml:mi>L</mml:mi><mml:mi>y</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula>. If odor is not detected during the bouts, the likelihood that the source is contained within this region is negligible. An application of Bayes’ rule converts the initial prior of length <inline-formula><mml:math id="inf52"><mml:msub><mml:mi>L</mml:mi><mml:mi>x</mml:mi></mml:msub></mml:math></inline-formula> into a posterior of reduced length <inline-formula><mml:math id="inf53"><mml:mrow><mml:msub><mml:mi>L</mml:mi><mml:mi>x</mml:mi></mml:msub><mml:mo>-</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mtext>thr</mml:mtext></mml:msub></mml:mrow></mml:math></inline-formula>. Since the agent now believes that it is downwind of the plume by at least a distance <inline-formula><mml:math id="inf54"><mml:msub><mml:mi>x</mml:mi><mml:mtext>thr</mml:mtext></mml:msub></mml:math></inline-formula>, it will surge upwind by <inline-formula><mml:math id="inf55"><mml:msub><mml:mi>x</mml:mi><mml:mtext>thr</mml:mtext></mml:msub></mml:math></inline-formula> and explore the next patch using the same procedure of cast-and-sniff. The process is repeated until the plume is detected.</p><p>The above argument implies that the search process can be split into distinct episodes where in each episode the agent executes bouts of cast-and-sniff followed by a surge of length <inline-formula><mml:math id="inf56"><mml:msub><mml:mi>x</mml:mi><mml:mtext>thr</mml:mtext></mml:msub></mml:math></inline-formula>. The search can then be decomposed into a maximum of <inline-formula><mml:math id="inf57"><mml:mrow><mml:mi>N</mml:mi><mml:mo>∼</mml:mo><mml:mrow><mml:msub><mml:mi>L</mml:mi><mml:mi>x</mml:mi></mml:msub><mml:mo>/</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mtext>thr</mml:mtext></mml:msub></mml:mrow></mml:mrow></mml:math></inline-formula> distinct episodes or until the agent detects odor. Suppose that in each episode <inline-formula><mml:math id="inf58"><mml:mi>n</mml:mi></mml:math></inline-formula> (<inline-formula><mml:math id="inf59"><mml:mrow><mml:mi>n</mml:mi><mml:mo>=</mml:mo><mml:mrow><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mn>2</mml:mn><mml:mo>,</mml:mo><mml:mi mathvariant="normal">…</mml:mi><mml:mo>,</mml:mo><mml:mi>N</mml:mi></mml:mrow></mml:mrow></mml:math></inline-formula>), the agent spends time <italic>t</italic><sub><italic>n</italic></sub> executing bouts of cast-and-sniff. The casting duration <italic>t</italic><sub><italic>n</italic></sub> is to be optimized. As discussed next, the optimal <italic>t</italic><sub><italic>n</italic></sub> depends on the cumulative probability of not detecting the signal (conditional on the target being in that patch) after casting for time <inline-formula><mml:math id="inf60"><mml:mi>t</mml:mi></mml:math></inline-formula>, denoted <inline-formula><mml:math id="inf61"><mml:mrow><mml:mi>c</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula>, which in turn depends on the sampling strategy during casting.</p><p>The expected discounted reward at the beginning of the search is <inline-formula><mml:math id="inf62"><mml:mrow><mml:msub><mml:mi>V</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>≡</mml:mo><mml:msub><mml:mrow><mml:mo stretchy="false">⟨</mml:mo><mml:msup><mml:mi>e</mml:mi><mml:mrow><mml:mo>-</mml:mo><mml:mrow><mml:mi>λ</mml:mi><mml:mo>⁢</mml:mo><mml:mi>T</mml:mi></mml:mrow></mml:mrow></mml:msup><mml:mo stretchy="false">⟩</mml:mo></mml:mrow><mml:mi>T</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula>, where <inline-formula><mml:math id="inf63"><mml:mi>T</mml:mi></mml:math></inline-formula> is the time taken to find the odor signal. We use dynamic programming to compute and optimize <italic>V</italic><sub>1</sub>. <italic>V</italic><sub>1</sub> is the sum of the expected reward if the agent finds odor in the first patch within time <italic>t</italic><sub>1</sub> and the expected reward after moving to the next patch if it does not. The information gained from not detecting odor is taken into account in the latter term through a Bayesian update of the prior. However, we show that <italic>V</italic><sub>1</sub> and the casting times, <inline-formula><mml:math id="inf64"><mml:mrow><mml:msub><mml:mi>t</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mn>2</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:mi mathvariant="normal">…</mml:mi><mml:mo>,</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mi>N</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula>, can be calculated using an equivalent, simpler expression which does not require Bayesian updates (Materials and methods). Denote <inline-formula><mml:math id="inf65"><mml:msub><mml:mi>V</mml:mi><mml:mi>n</mml:mi></mml:msub></mml:math></inline-formula> as the expected discounted reward at the beginning of the <italic>n</italic>th episode. We show that <italic>V</italic><sub>1</sub> can be calculated using the recursive equation<disp-formula id="equ2"><label>(2)</label><mml:math id="m2"><mml:mrow><mml:msub><mml:mi>V</mml:mi><mml:mrow><mml:mi>n</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:munder><mml:mo movablelimits="true" form="prefix">max</mml:mo><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:munder><mml:mrow><mml:mo>{</mml:mo><mml:mrow><mml:mo>−</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mi>N</mml:mi></mml:mfrac><mml:msubsup><mml:mo>∫</mml:mo><mml:mrow><mml:mn>0</mml:mn></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msubsup><mml:msup><mml:mi>c</mml:mi><mml:mrow><mml:mi mathvariant="normal">′</mml:mi></mml:mrow></mml:msup><mml:mo stretchy="false">(</mml:mo><mml:mi>s</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:msup><mml:mi>e</mml:mi><mml:mrow><mml:mo>−</mml:mo><mml:mi>λ</mml:mi><mml:mi>s</mml:mi></mml:mrow></mml:msup><mml:mi>d</mml:mi><mml:mi>s</mml:mi><mml:mo>+</mml:mo><mml:msup><mml:mi>e</mml:mi><mml:mrow><mml:mo>−</mml:mo><mml:mi>λ</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>t</mml:mi><mml:mo>+</mml:mo><mml:mfrac><mml:msub><mml:mi>x</mml:mi><mml:mrow><mml:mtext>thr</mml:mtext></mml:mrow></mml:msub><mml:mi>v</mml:mi></mml:mfrac></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:msup><mml:msub><mml:mi>V</mml:mi><mml:mrow><mml:mi>n</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mrow><mml:mo>}</mml:mo></mml:mrow><mml:mo>.</mml:mo></mml:mrow></mml:math></disp-formula></p><p>The time <inline-formula><mml:math id="inf66"><mml:mi>t</mml:mi></mml:math></inline-formula> that maximizes the parenthesis determines the optimal duration <italic>t</italic><sub><italic>n</italic></sub> the agent should spend casting before surging upwind. The first and second terms in the parenthesis of (2) are the expected discounted rewards if the agent detects odor during casting and the search ends or if it does not detect odor, surges a distance <inline-formula><mml:math id="inf67"><mml:msub><mml:mi>x</mml:mi><mml:mtext>thr</mml:mtext></mml:msub></mml:math></inline-formula> (which takes time <inline-formula><mml:math id="inf68"><mml:mrow><mml:msub><mml:mi>x</mml:mi><mml:mtext>thr</mml:mtext></mml:msub><mml:mo>/</mml:mo><mml:mi>v</mml:mi></mml:mrow></mml:math></inline-formula>) and continues to the next episode, respectively. The factor <inline-formula><mml:math id="inf69"><mml:mrow><mml:mo>-</mml:mo><mml:msup><mml:mi>c</mml:mi><mml:mo>′</mml:mo></mml:msup></mml:mrow></mml:math></inline-formula> in the first term is the probability density to detect odor at time <inline-formula><mml:math id="inf70"><mml:mi>t</mml:mi></mml:math></inline-formula> conditional on the target being in the current patch, which depends on the casting strategy discussed further below. Since the prior is uniform, the probability that the target is in the current patch is <inline-formula><mml:math id="inf71"><mml:mrow><mml:mn>1</mml:mn><mml:mo>/</mml:mo><mml:mi>N</mml:mi></mml:mrow></mml:math></inline-formula>, which sets the factor in front of the integral.</p><p>We first show that the duration <italic>t</italic><sub><italic>n</italic></sub> obeys a marginality condition. The agent should stop casting when the value of continuing to explore the current patch is just outweighed by the value of moving on to the next patch. This intuition is quantified by the optimization over <inline-formula><mml:math id="inf72"><mml:mi>t</mml:mi></mml:math></inline-formula> in <xref ref-type="disp-formula" rid="equ2">Equation 2</xref>. Zeroing the time derivative of <xref ref-type="disp-formula" rid="equ2">Equation 2</xref>, we obtain that <italic>t</italic><sub><italic>n</italic></sub> is the value of <inline-formula><mml:math id="inf73"><mml:mi>t</mml:mi></mml:math></inline-formula> that satisfies the equality <inline-formula><mml:math id="inf74"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mo>−</mml:mo><mml:msup><mml:mi>c</mml:mi><mml:mrow><mml:mi mathvariant="normal">′</mml:mi></mml:mrow></mml:msup><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:msup><mml:mi>e</mml:mi><mml:mrow><mml:mo>−</mml:mo><mml:mi>λ</mml:mi><mml:mi>t</mml:mi></mml:mrow></mml:msup><mml:mrow><mml:mo>/</mml:mo></mml:mrow><mml:mi>N</mml:mi><mml:mo>=</mml:mo><mml:mi>λ</mml:mi><mml:msup><mml:mi>e</mml:mi><mml:mrow><mml:mo>−</mml:mo><mml:mi>λ</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>t</mml:mi><mml:mo>+</mml:mo><mml:mfrac><mml:msub><mml:mi>x</mml:mi><mml:mrow><mml:mtext>thr</mml:mtext></mml:mrow></mml:msub><mml:mi>v</mml:mi></mml:mfrac></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:msup><mml:msub><mml:mi>V</mml:mi><mml:mrow><mml:mi>n</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula>. The left-hand side is the rate of value acquired for staying in the current patch. The right-hand side is the rate of value lost for delaying departure. Thus, by maximizing value we obtain that, at optimality, the added value of continuing to cast matches the added value of anticipating surge, similar to the condition prescribed for patch-leaving decisions during foraging by marginal value theory (MVT) (<xref ref-type="bibr" rid="bib5">Charnov, 1976</xref>). The marginality condition leads to a relationship between the casting time and the value at the next episode<disp-formula id="equ3"><label>(3)</label><mml:math id="m3"><mml:mrow><mml:mo>−</mml:mo><mml:msup><mml:mi>c</mml:mi><mml:mrow><mml:mi mathvariant="normal">′</mml:mi></mml:mrow></mml:msup><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mrow><mml:mi>n</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mi>N</mml:mi><mml:mi>λ</mml:mi><mml:msup><mml:mi>e</mml:mi><mml:mrow><mml:mo>−</mml:mo><mml:mi>λ</mml:mi><mml:msub><mml:mi>x</mml:mi><mml:mrow><mml:mtext>thr</mml:mtext></mml:mrow></mml:msub><mml:mrow><mml:mo>/</mml:mo></mml:mrow><mml:mi>v</mml:mi></mml:mrow></mml:msup><mml:msub><mml:mi>V</mml:mi><mml:mrow><mml:mi>n</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>.</mml:mo></mml:mrow></mml:math></disp-formula></p><p>When <inline-formula><mml:math id="inf75"><mml:mrow><mml:mi>n</mml:mi><mml:mo>=</mml:mo><mml:mi>N</mml:mi></mml:mrow></mml:math></inline-formula>, the agent casts indefinitely, which gives <inline-formula><mml:math id="inf76"><mml:mrow><mml:msub><mml:mi>V</mml:mi><mml:mi>N</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mrow><mml:mo>-</mml:mo><mml:mrow><mml:mfrac><mml:mn>1</mml:mn><mml:mi>N</mml:mi></mml:mfrac><mml:mo>⁢</mml:mo><mml:mrow><mml:msubsup><mml:mo largeop="true" symmetric="true">∫</mml:mo><mml:mn>0</mml:mn><mml:mi mathvariant="normal">∞</mml:mi></mml:msubsup><mml:mrow><mml:msup><mml:mi>c</mml:mi><mml:mo>′</mml:mo></mml:msup><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>s</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>⁢</mml:mo><mml:msup><mml:mi>e</mml:mi><mml:mrow><mml:mo>-</mml:mo><mml:mrow><mml:mi>λ</mml:mi><mml:mo>⁢</mml:mo><mml:mi>s</mml:mi></mml:mrow></mml:mrow></mml:msup><mml:mo>⁢</mml:mo><mml:mrow><mml:mo rspace="0pt">d</mml:mo><mml:mi>s</mml:mi></mml:mrow></mml:mrow></mml:mrow></mml:mrow></mml:mrow></mml:mrow></mml:math></inline-formula> from <xref ref-type="disp-formula" rid="equ2">Equation 2</xref>. The casting time for each episode is obtained using the boundary condition <xref ref-type="disp-formula" rid="equ3">Equation 3</xref> and <inline-formula><mml:math id="inf77"><mml:mrow><mml:mi>c</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula>, which we shall determine in the next paragraph. Note that we have ignored the possibility that after the <italic>N</italic>th episode, the agent turns back and moves downwind to re-explore earlier regions, which can be incorporated into this framework by imposing a different boundary condition. This extension marginally affects the earlier stages of the search path and does not affect general conclusions.</p><p>We now optimize for the sampling strategy during the bouts of cast-and-sniff, which in turn determines <inline-formula><mml:math id="inf78"><mml:mrow><mml:mi>c</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula>. Each cast-and-sniff requires the agent to decide where to sniff on the crosswind axis, given the marginal posterior distribution <inline-formula><mml:math id="inf79"><mml:mrow><mml:mrow><mml:mover accent="true"><mml:mi mathvariant="bold">b</mml:mi><mml:mo stretchy="false">~</mml:mo></mml:mover><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>y</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mo>=</mml:mo><mml:mrow><mml:msubsup><mml:mo largeop="true" symmetric="true">∫</mml:mo><mml:mn>0</mml:mn><mml:msub><mml:mi>x</mml:mi><mml:mtext>thr</mml:mtext></mml:msub></mml:msubsup><mml:mrow><mml:mrow><mml:mo rspace="0pt">d</mml:mo><mml:mpadded width="+1.7pt"><mml:mi>x</mml:mi></mml:mpadded></mml:mrow><mml:mo>⁢</mml:mo><mml:mi mathvariant="bold">b</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>x</mml:mi><mml:mo>,</mml:mo><mml:mi>y</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:mrow></mml:math></inline-formula>. The next sniff location at a displacement <inline-formula><mml:math id="inf80"><mml:mrow><mml:mi mathvariant="normal">Δ</mml:mi><mml:mo>⁢</mml:mo><mml:mi>y</mml:mi></mml:mrow></mml:math></inline-formula> from the current location is obtained from a dynamic programming equation similar to <xref ref-type="disp-formula" rid="equ2">Equation 2</xref>, which relates the current value to the value of moving and sampling elsewhere.<disp-formula id="equ4"><label>(4)</label><mml:math id="m4"><mml:mrow><mml:mtable columnalign="right left" rowspacing="4pt" columnspacing="1em"><mml:mtr><mml:mtd><mml:mi>V</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mover><mml:mrow><mml:mi mathvariant="bold">b</mml:mi></mml:mrow><mml:mo stretchy="false">~</mml:mo></mml:mover></mml:mrow><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:munder><mml:mo movablelimits="true" form="prefix">max</mml:mo><mml:mrow><mml:mi mathvariant="normal">Δ</mml:mi><mml:mi>y</mml:mi></mml:mrow></mml:munder><mml:mrow><mml:mo>{</mml:mo><mml:mrow><mml:mo>[</mml:mo><mml:mrow><mml:msub><mml:mi mathvariant="normal">Γ</mml:mi><mml:mrow><mml:mrow><mml:mover><mml:mrow><mml:mi mathvariant="bold">b</mml:mi></mml:mrow><mml:mo stretchy="false">~</mml:mo></mml:mover></mml:mrow></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi mathvariant="normal">Δ</mml:mi><mml:mi>y</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>+</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:msub><mml:mi mathvariant="normal">Γ</mml:mi><mml:mrow><mml:mrow><mml:mover><mml:mrow><mml:mi mathvariant="bold">b</mml:mi></mml:mrow><mml:mo stretchy="false">~</mml:mo></mml:mover></mml:mrow></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi mathvariant="normal">Δ</mml:mi><mml:mi>y</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo stretchy="false">)</mml:mo><mml:mi>V</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msup><mml:mrow><mml:mover><mml:mrow><mml:mi mathvariant="bold">b</mml:mi></mml:mrow><mml:mo stretchy="false">~</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi mathvariant="normal">′</mml:mi></mml:mrow></mml:msup><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>]</mml:mo></mml:mrow><mml:mo fence="true" stretchy="true" symmetric="true"/></mml:mrow></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mrow><mml:mo fence="true" stretchy="true" symmetric="true"/><mml:mrow><mml:mo>×</mml:mo><mml:msup><mml:mi>e</mml:mi><mml:mrow><mml:mo>−</mml:mo><mml:mi>λ</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mi mathvariant="normal">Δ</mml:mi><mml:mi>y</mml:mi><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mrow><mml:mo>/</mml:mo></mml:mrow><mml:mi>v</mml:mi><mml:mo>+</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mrow><mml:mtext>sniff</mml:mtext></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:msup></mml:mrow><mml:mo>}</mml:mo></mml:mrow><mml:mo>,</mml:mo></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:math></disp-formula></p><p>where <inline-formula><mml:math id="inf81"><mml:msup><mml:mover accent="true"><mml:mi mathvariant="bold">b</mml:mi><mml:mo stretchy="false">~</mml:mo></mml:mover><mml:mo>′</mml:mo></mml:msup></mml:math></inline-formula> is the posterior after sampling at the new location conditional on no detection, and <inline-formula><mml:math id="inf82"><mml:mrow><mml:msub><mml:mi mathvariant="normal">Γ</mml:mi><mml:mover accent="true"><mml:mi mathvariant="bold">b</mml:mi><mml:mo stretchy="false">~</mml:mo></mml:mover></mml:msub><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mi mathvariant="normal">Δ</mml:mi><mml:mo>⁢</mml:mo><mml:mi>y</mml:mi></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> is the probability of detection. The two terms in the Bellman equation correspond to the cases when the agent detects odor and does not detect odor, respectively, which are discounted in proportion to the time taken to travel a distance <inline-formula><mml:math id="inf83"><mml:mrow><mml:mo stretchy="false">|</mml:mo><mml:mrow><mml:mi mathvariant="normal">Δ</mml:mi><mml:mo>⁢</mml:mo><mml:mi>y</mml:mi></mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow></mml:math></inline-formula>, <inline-formula><mml:math id="inf84"><mml:mrow><mml:mrow><mml:mo stretchy="false">|</mml:mo><mml:mrow><mml:mi mathvariant="normal">Δ</mml:mi><mml:mo>⁢</mml:mo><mml:mi>y</mml:mi></mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mo>/</mml:mo><mml:mi>v</mml:mi></mml:mrow></mml:math></inline-formula>, and the time taken to sniff in the air, denoted by <inline-formula><mml:math id="inf85"><mml:msub><mml:mi>t</mml:mi><mml:mtext>sniff</mml:mtext></mml:msub></mml:math></inline-formula>. At each decision, the recursion in <xref ref-type="disp-formula" rid="equ4">Equation 4</xref> is expanded and optimized with respect to the subsequent <inline-formula><mml:math id="inf86"><mml:msub><mml:mi>n</mml:mi><mml:mtext>steps</mml:mtext></mml:msub></mml:math></inline-formula> sniff locations <inline-formula><mml:math id="inf87"><mml:mrow><mml:mrow><mml:mi mathvariant="normal">Δ</mml:mi><mml:mo>⁢</mml:mo><mml:msub><mml:mi>y</mml:mi><mml:mn>1</mml:mn></mml:msub></mml:mrow><mml:mo>,</mml:mo><mml:mrow><mml:mi mathvariant="normal">Δ</mml:mi><mml:mo>⁢</mml:mo><mml:msub><mml:mi>y</mml:mi><mml:mn>2</mml:mn></mml:msub></mml:mrow><mml:mo>,</mml:mo><mml:mi mathvariant="normal">…</mml:mi><mml:mo>,</mml:mo><mml:mrow><mml:mi mathvariant="normal">Δ</mml:mi><mml:mo>⁢</mml:mo><mml:msub><mml:mi>y</mml:mi><mml:msub><mml:mi>n</mml:mi><mml:mtext>steps</mml:mtext></mml:msub></mml:msub></mml:mrow></mml:mrow></mml:math></inline-formula> using standard gradient-free optimization methods. The agent then moves by <inline-formula><mml:math id="inf88"><mml:mrow><mml:mi mathvariant="normal">Δ</mml:mi><mml:mo>⁢</mml:mo><mml:msub><mml:mi>y</mml:mi><mml:mn>1</mml:mn></mml:msub></mml:mrow></mml:math></inline-formula>, <inline-formula><mml:math id="inf89"><mml:mover accent="true"><mml:mi mathvariant="bold">b</mml:mi><mml:mo stretchy="false">~</mml:mo></mml:mover></mml:math></inline-formula> is updated using Bayes’ rule and the procedure is repeated. Optimization yields a sampling strategy and the corresponding <inline-formula><mml:math id="inf90"><mml:mrow><mml:mi>c</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula>.</p><p>The optimized casting strategy is a zigzag (<xref ref-type="fig" rid="fig6">Figure 6a</xref>) which expands over time to the width of the prior. The expanding casting width can be again interpreted in the marginal value framework: at the first counterturn, the value of finding odor toward the agent’s previous heading is just outweighed by the value of finding it on the opposite side after appropriate discounting due to travel time. The discounted value on the opposite side can match the value at the current side due to the imbalance in the probabilities of detection between the two sides after the Bayesian update. This idea extends to subsequent counterturns, until the zigzags extend to the prior’s width. The probability of not detecting odor decays exponentially with a rate that increases with optimization depth <inline-formula><mml:math id="inf91"><mml:msub><mml:mi>n</mml:mi><mml:mtext>steps</mml:mtext></mml:msub></mml:math></inline-formula> (<xref ref-type="fig" rid="fig6">Figure 6b</xref>), highlighting the importance of a long-term strategy. In the low-detection rate limit, we generically expect a constant detection rate (say <inline-formula><mml:math id="inf92"><mml:mrow><mml:mrow><mml:mi>c</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mo>=</mml:mo><mml:msup><mml:mi>e</mml:mi><mml:mrow><mml:mo>-</mml:mo><mml:mrow><mml:mi>κ</mml:mi><mml:mo>⁢</mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:mrow></mml:msup></mml:mrow></mml:math></inline-formula>), consistent with the exponential decay observed in simulations. The detection rate <italic>κ</italic> decreases with <inline-formula><mml:math id="inf93"><mml:msub><mml:mi>t</mml:mi><mml:mtext>sniff</mml:mtext></mml:msub></mml:math></inline-formula> (<xref ref-type="fig" rid="fig6">Figure 6c</xref>), which in turn translates to a decreased value (from <xref ref-type="disp-formula" rid="equ3">Equation 3</xref>) and highlights the cost of pausing to sniff in the air. From <xref ref-type="disp-formula" rid="equ3">Equation 3</xref>, we then have<disp-formula id="equ5"> <label>(5)</label><mml:math id="m5"><mml:mrow><mml:msub><mml:mi>t</mml:mi><mml:mrow><mml:mi>n</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:msup><mml:mi>κ</mml:mi><mml:mrow><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msup><mml:mi>log</mml:mi><mml:mo>⁡</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mfrac><mml:mrow><mml:mi>κ</mml:mi><mml:msup><mml:mi>e</mml:mi><mml:mrow><mml:mi>λ</mml:mi><mml:msub><mml:mi>x</mml:mi><mml:mrow><mml:mtext>thr</mml:mtext></mml:mrow></mml:msub><mml:mrow><mml:mo>/</mml:mo></mml:mrow><mml:mi>v</mml:mi></mml:mrow></mml:msup></mml:mrow><mml:mrow><mml:mi>N</mml:mi><mml:mi>λ</mml:mi><mml:mtext> </mml:mtext><mml:msub><mml:mi>V</mml:mi><mml:mrow><mml:mi>n</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:mfrac><mml:mo>)</mml:mo></mml:mrow><mml:mo>.</mml:mo></mml:mrow></mml:math></disp-formula></p><fig id="fig6" position="float"><label>Figure 6.</label><caption><title>Predictions of a simplified POMDP with detections allowed in the air only.</title><p>Results are both shown for an analytical (green, left) and a computational (orange, right) model. (<bold>a</bold>) Optimized sniff locations during casting (conditional on no detection) show a zigzag of increasing amplitude. (<bold>b</bold>) The probability of not detecting the signal against time, <inline-formula><mml:math id="inf94"><mml:mrow><mml:mi>c</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula>, decays exponentially with detection rate, <italic>κ</italic>, shown here for different values of the optimization depth <inline-formula><mml:math id="inf95"><mml:msub><mml:mi>n</mml:mi><mml:mtext>steps</mml:mtext></mml:msub></mml:math></inline-formula>. <italic>κ</italic> saturates beyond <inline-formula><mml:math id="inf96"><mml:mrow><mml:msub><mml:mi>n</mml:mi><mml:mtext>steps</mml:mtext></mml:msub><mml:mo>=</mml:mo><mml:mn>9</mml:mn></mml:mrow></mml:math></inline-formula>. (<bold>c</bold>) <italic>κ</italic> monotonically decreases with the time per sniff, <inline-formula><mml:math id="inf97"><mml:msub><mml:mi>t</mml:mi><mml:mtext>sniff</mml:mtext></mml:msub></mml:math></inline-formula>, reflecting the cost of pausing to sniff the air. In panels (<bold>a</bold>), (<bold>b</bold>), and (<bold>c</bold>), we use <inline-formula><mml:math id="inf98"><mml:mrow><mml:mrow><mml:msub><mml:mi>y</mml:mi><mml:mtext>thr</mml:mtext></mml:msub><mml:mo>/</mml:mo><mml:msub><mml:mi>L</mml:mi><mml:mi>y</mml:mi></mml:msub></mml:mrow><mml:mo>=</mml:mo><mml:mrow><mml:mn>1</mml:mn><mml:mo>/</mml:mo><mml:mn>20</mml:mn></mml:mrow></mml:mrow></mml:math></inline-formula>, <inline-formula><mml:math id="inf99"><mml:mrow><mml:msub><mml:mi>L</mml:mi><mml:mi>y</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:math></inline-formula>, <inline-formula><mml:math id="inf100"><mml:mrow><mml:mi>λ</mml:mi><mml:mo>=</mml:mo><mml:mn>0.5</mml:mn></mml:mrow></mml:math></inline-formula>, <inline-formula><mml:math id="inf101"><mml:mrow><mml:mi>v</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:math></inline-formula>, and <inline-formula><mml:math id="inf102"><mml:mrow><mml:msub><mml:mi>t</mml:mi><mml:mtext>sniff</mml:mtext></mml:msub><mml:mo>=</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:math></inline-formula> (for (<bold>a</bold>) and (<bold>b</bold>)). (<bold>d</bold>) Casting times (in units of <inline-formula><mml:math id="inf103"><mml:mrow><mml:mn>1</mml:mn><mml:mo>/</mml:mo><mml:mi>λ</mml:mi></mml:mrow></mml:math></inline-formula>) generally increase as the search progresses. Obtained using <xref ref-type="disp-formula" rid="equ5">Equation 5</xref> for different values of <inline-formula><mml:math id="inf104"><mml:mrow><mml:mi>κ</mml:mi><mml:mo>/</mml:mo><mml:mi>λ</mml:mi></mml:mrow></mml:math></inline-formula> (colored lines). Here, <inline-formula><mml:math id="inf105"><mml:mrow><mml:mi>N</mml:mi><mml:mo>=</mml:mo><mml:mn>6</mml:mn></mml:mrow></mml:math></inline-formula> and <inline-formula><mml:math id="inf106"><mml:mrow><mml:mrow><mml:mrow><mml:mi>λ</mml:mi><mml:mo>⁢</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mtext>thr</mml:mtext></mml:msub></mml:mrow><mml:mo>/</mml:mo><mml:mi>v</mml:mi></mml:mrow><mml:mo>=</mml:mo><mml:mn>0.05</mml:mn></mml:mrow></mml:math></inline-formula>. (<bold>e,f</bold>) The surge length and cast width from simulations of a simplified partially observable Markov decision process (POMDP), where the agent can detect an odor signal only by sniffing in the air. Results for different prior and plume dimensions (blue stars) align with the theoretical prediction (red line) that the surge length and cast width are equal to the detection range in air, <inline-formula><mml:math id="inf107"><mml:msub><mml:mi>x</mml:mi><mml:mtext>thr</mml:mtext></mml:msub></mml:math></inline-formula>, and the prior width, <inline-formula><mml:math id="inf108"><mml:msub><mml:mi>L</mml:mi><mml:mi>y</mml:mi></mml:msub></mml:math></inline-formula>, respectively. Results from the full POMDP, where the agent can detect odor on the ground, are also consistent with the predictions (yellow crosses). Experiments were repeated over 5 different seeds. (<bold>g</bold>) The time spent casting in each patch for the simplified and full POMDP increases as the search progresses, as predicted by the theory (panel (<bold>d</bold>)). Here, we set the prior length, <inline-formula><mml:math id="inf109"><mml:mrow><mml:msub><mml:mi>L</mml:mi><mml:mi>x</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mrow><mml:mn>4</mml:mn><mml:mo>⁢</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mtext>thr</mml:mtext></mml:msub></mml:mrow></mml:mrow></mml:math></inline-formula>, which corresponds to <inline-formula><mml:math id="inf110"><mml:mrow><mml:mi>N</mml:mi><mml:mo>=</mml:mo><mml:mn>4</mml:mn></mml:mrow></mml:math></inline-formula> patches. Boxes and dashed lines represent the standard error and the standard deviation around the mean, respectively.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-76989-fig6-v2.tif"/></fig><p>We use <xref ref-type="disp-formula" rid="equ2 equ5">Equations 2 and 5</xref> along with the boundary condition <inline-formula><mml:math id="inf111"><mml:mrow><mml:msub><mml:mi>V</mml:mi><mml:mi>N</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mfrac><mml:mi>κ</mml:mi><mml:mrow><mml:mi>N</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mi>κ</mml:mi><mml:mo>+</mml:mo><mml:mi>λ</mml:mi></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:mfrac></mml:mrow></mml:math></inline-formula> to solve for the casting times. The results show increasing casting times with episode index <inline-formula><mml:math id="inf112"><mml:mi>n</mml:mi></mml:math></inline-formula> (<xref ref-type="fig" rid="fig6">Figure 6d</xref>). Intuitively, as the search progresses, the marginal cost for the agent to continue casting decreases due to its increasing confidence that it is in the right patch, driving the agent to spend more time casting before leaving the patch.</p><p>We test predictions from the theory using simulations of a simplified POMDP. Specifically, the agent is trained to find the target with an odor signal that can be detected only by sniffing in the air. The detection probability map <inline-formula><mml:math id="inf113"><mml:mrow><mml:mi>r</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>x</mml:mi><mml:mo>,</mml:mo><mml:mi>y</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> is rectangular with plume detection range <inline-formula><mml:math id="inf114"><mml:msub><mml:mi>x</mml:mi><mml:mtext>thr</mml:mtext></mml:msub></mml:math></inline-formula> and width <inline-formula><mml:math id="inf115"><mml:msub><mml:mi>y</mml:mi><mml:mtext>thr</mml:mtext></mml:msub></mml:math></inline-formula>. Simulations confirm that the surge length and cast width are equal to the detection range and the prior width, respectively (<xref ref-type="fig" rid="fig6">Figure 6e and f</xref>). The time spent exploring a patch increases monotonically as the search progresses, as predicted by the theory (<xref ref-type="fig" rid="fig6">Figure 6d and g</xref>). Notably, we find that the trajectories from the full POMDP considered in the previous sections are also consistent with these predictions, suggesting that these aspects are generic features of foraging for a sparse odor signal during the first phase of exploration.</p></sec></sec><sec id="s3" sec-type="discussion"><title>Discussion</title><p>Motivated by the goal of disentangling elementary components in the complexity of animal behavior, we have investigated a dynamics driven entirely by olfactory cues. In the model, an agent searches for a source of odors transported by a turbulent flow and at each step decides either to move while sniffing on the ground or pause, rear up and sniff in the air. The goal is to locate the source in the shortest possible time, which is the reward function used to identify effective policies of action using machine learning methods. Analogously to dogs and rodents mentioned in the introduction, we obtain behavioral policies which feature alternation between the two modalities of sniffing on the ground vs. in the air. The appeal of our approach is that we could identify the rationale for the observed alternation and its basic factors. On the one hand, movement and progression toward the source is halted during the rearing phase of sniffing in the air. On the other hand, odor sources create large turbulent plumes that reach larger distances in the air than on the ground. Therefore, sniffing in the air may have a higher chance of intersecting odor cues than on the ground. These two competing effects underlie the process of alternation and their balance determines the rate of switching between the two modalities, which depends on the distance as discussed in the next paragraph.</p><p>The effect of alternation is particularly pronounced at large distances to the source. There, due to turbulent mixing, the odor concentration drops substantially and no gradients are present (<xref ref-type="bibr" rid="bib4">Celani et al., 2014</xref>). In our realistic setting, where the searcher does start at large distances, the process can be qualitatively split in two phases: first, the agent needs to approach the source enough for an almost continuous odor plume to be present; second, it needs to locate the source within the plume. The latter task, which is the regime that most laboratory experiments have considered so far (<xref ref-type="bibr" rid="bib21">Reddy et al., 2022</xref>), is much easier than the former as the rate of odor detection close to the source and within the conical plume is relatively high. Therefore, the task boils down to staying close to the center of the conical plume, where the signal is highest. Conversely, the bottleneck during the first, harder phase is the scarcity of information on the location of the source, which the agent tries to overcome by increasing its chances of odor detection. Slowing down its progression is thus the price that the agent pays in order to get oriented in the uncertain conditions typical of large distances to the source. The transition between the two search phases typically occurs after a handful of odor detections.</p><p>Note that we have focused here on the case of a stationary source, where odor statistics in the air and on the bottom layers are discriminated by the adsorption on the ground. In fact, at the onset of odor emission (and even in the absence of adsorption), plumes start out larger in the air than near the ground, simply because air travels more slowly near the ground. It follows from our results that alternation should be more frequent in the early stages of odor release in non-steady conditions. This prediction could be tested experimentally by switching on an odor source and monitoring the fraction of sniffing in the air as a function of the time elapsed since the switch and the onset of odor emission. We expect that the benefits of sniffing the air vs. the ground will hold even if the adsorption of odor molecules is modified. While the fully absorbing conditions considered here clearly reduce the amount of odors close to the ground, the odors will extend less on the ground than in the air even for other boundary conditions where partial absorption is considered. We expect then that quantitative properties of the odor will depend on details of the adsorption process but alternation and its increase with the distance to the source will qualitatively hold in general.</p><p>While we considered here two olfactory sensorimotor modalities, we expect that our methodology and results apply more broadly to distinct sensory systems and cues. If there is no conflict in the acquisition and processing of multiple sensory cues, then it is clearly advantageous to combine them. Conversely, if their combination has some form of cost and a partial or total conflict exists, then our results suggest that the logic identified here will apply and there will be some form of alternation.</p><p>The machine learning methodology that we have employed here to identify effective policies of actions belongs to the general family of POMDP (<xref ref-type="bibr" rid="bib14">Kaelbling et al., 1998</xref>; <xref ref-type="bibr" rid="bib29">Sutton and Barto, 2018</xref>). This framework applies to a broad class of decision problems, where agents need to accomplish a prescribed task by a series of actions taken with partial knowledge of the environment. Specifically, the agent combines external cues and its internal model of the world to infer a belief about the state of the environment. In our setting, the agent is the searcher, cues are odor detections (or their absence), the task is to localize the source, and beliefs pertain to the location of the source of odors. While the agent proceeds along its path and gathers information via odor cues, its belief narrows down and eventually concentrates at the location of the source. Trajectories of a POMDP agent with a single sensory modality and their relation to phenomenological approaches as <xref ref-type="bibr" rid="bib31">Vergassola et al., 2007</xref>, were discussed in <xref ref-type="bibr" rid="bib21">Reddy et al., 2022</xref>. Here, we have given the agent the choice of multiple sensory modalities at each decision step, which allowed us to highlight the presence of alternation and establish its link with MVT (<xref ref-type="bibr" rid="bib5">Charnov, 1976</xref>).</p><p>MVT describes the behavior of an optimally foraging individual in a system with spatially separated resources. Due to the spatial separation, animals must spend time traveling between patches. Since organisms face diminishing returns, there is a moment the animal exhausts the patch and ought to leave. In MVT, the optimal departure time is determined as the time at which the marginal value of staying in a patch equals that of leaving and exploring another patch. In our setting, these patches correspond to regions of the agent’s belief which are explored using a combination of casting and sniffing in the air. MVT thus determines when to stop cast-and-sniff exploration and surge toward the next patch in the belief.</p><p>As MVT, our machine learning methodology provides a normative theory that disregards constraints by construction, for instance on memory of the agent or its capacity of processing data. The goals of the approach are threefold: first, it provides understanding and fundamental limits on performances; second, understanding can inspire the development of strategies less demanding, as it was the case with <xref ref-type="bibr" rid="bib31">Vergassola et al., 2007</xref>, and <xref ref-type="bibr" rid="bib17">Masson, 2014</xref>; third, the developed methodologies apply to robots, which are typically less constrained than animals (<xref ref-type="bibr" rid="bib23">Russell, 1999</xref>; <xref ref-type="bibr" rid="bib34">Webb and Consilvio, 2001</xref>). The counterpart of cognitive strategies like those developed here is provided by reactive strategies, which take the opposite view of enforcing strong constraints, for example, on memory, and explore what can be achieved within those limits. The two approaches provide complementary views to the problem and we refer to the work in <xref ref-type="bibr" rid="bib33">Voges et al., 2014</xref>, for a discussion of their comparison, values, and limits. While a similar study for the case of alternation is beyond the scope of this work, a few comments on memory requirements and robustness of our strategies are worth. The increase of the number of hyperplanes with the number of training episodes is shown in <xref ref-type="fig" rid="fig3s1">Figure 3—figure supplement 1</xref>. As in the case of olfactory searches mentioned above, we expect that simplified strategies with less memory requirements will be inspired by our algorithms. The robustness of our strategies is investigated in <xref ref-type="fig" rid="fig4s2">Figure 4—figure supplement 2</xref>. The plots show the performance of our search strategy when the model of the environment is incorrect. Robustness with respect to the length and steadiness of the model are reported. Specifically, training is performed with a model that is consistent with the stationary plume used in the main text. The agent is then tested for localization of the source of a larger or smaller plume (<xref ref-type="fig" rid="fig4s2">Figure 4—figure supplement 2</xref> left, for different sizes of the plume) or of a meandering plume (i.e. identical in size to the plume used for training, but rotating with different frequencies and amplitudes, <xref ref-type="fig" rid="fig4s2">Figure 4—figure supplement 2</xref> right). Note that while the plume varies in these simulations, the agent still keeps the static model used for training, thus the model is now inaccurate. The upshot is that strategies developed here do not need to have their parameters set exactly at the correct values of the environment and are robust to partial misrepresentations.</p><p>We conclude by noting that, in addition to the familiar cases of dogs and rodents mentioned in the introduction, other species can sense chemical cues both in the bulk and on surfaces, and may feature a similar phenomenology of alternation. In particular, a large body of experimental evidence has been collected for turbulent plume-tracking by aquatic organisms, as reviewed in <xref ref-type="bibr" rid="bib35">Webster and Weissburg, 2009</xref>. Crustaceans sense chemical cues with their antennules floating in water and switch to sensing with their feet as they approach the target (<xref ref-type="bibr" rid="bib11">Grasso, 2001</xref>). For example, lobsters were observed in dim light in a flume of dimensions 2.5 m × 90 cm × 20 cm, as they left their shelter upon release of a turbulent plume of odor obtained from grounded mussel (<xref ref-type="bibr" rid="bib18">Moore et al., 1991</xref>). As the animals encountered the plume, they often displayed special behaviors, including raising up, sweeping their sensory legs on the bottom of the flume, and increasing flicking of lateral antennules. Similar observations were made for blue crabs capturing live clams or tracking spouts releasing clam extract (<xref ref-type="bibr" rid="bib36">Weissburg and Zimmer-Faust, 2002</xref>). In these experiments blue crabs would occasionally lower their abdomen closer to the surface or extend their walking legs to raise above their normal height. Finally, pelagic marine mollusks <italic>Nautilus pompilius,</italic> were observed to track the source of a turbulent plume by swimming at different heights, above and below the center of the plume. Interestingly, most animals sampled at higher heights beyond 1 m from the source, and swam at lower heights when closer to the source (<xref ref-type="bibr" rid="bib2">Basil and Atema, 2000</xref>). These experiments indicate that animals may alternate between different heights, and that sampling at higher elevation may be particularly useful at larger distances, which is again in qualitative agreement with our results. The ensemble of these observations suggest that alternation between sensorimotor modalities is likely to be present in the behavior of aquatic organisms as well. We hope that results presented here will motivate more experiments, on dogs, rodents, and aquatic organisms alike, with the goal of assessing quantitative aspects of the observed behaviors, testing our framework and advancing understanding of how sensorimotor modalities are integrated.</p></sec><sec id="s4" sec-type="materials|methods"><title>Materials and methods</title><sec id="s4-1"><title>Direct numerical simulations</title><p>The Navier-Stokes (<xref ref-type="disp-formula" rid="equ6">Equation M1</xref>) and the advection-diffusion equation for passive odor transport (<xref ref-type="disp-formula" rid="equ7">Equation M2</xref>) describe the spatiotemporal evolution of odor released in a fluid. We can solve these equations with DNS and obtain realistic odor fields to feed the POMDP algorithm:<disp-formula id="equ6"><label>(M1)</label><mml:math id="m6"><mml:mrow><mml:mrow><mml:mrow><mml:mrow><mml:msub><mml:mo>∂</mml:mo><mml:mi>t</mml:mi></mml:msub><mml:mo>⁡</mml:mo><mml:mi>u</mml:mi></mml:mrow><mml:mo>+</mml:mo><mml:mrow><mml:mi>u</mml:mi><mml:mo>⋅</mml:mo><mml:mrow><mml:mo>∇</mml:mo><mml:mo>⁡</mml:mo><mml:mi>u</mml:mi></mml:mrow></mml:mrow></mml:mrow><mml:mo>=</mml:mo><mml:mrow><mml:mrow><mml:mo>-</mml:mo><mml:mrow><mml:mfrac><mml:mn>1</mml:mn><mml:mi>ρ</mml:mi></mml:mfrac><mml:mo>⁢</mml:mo><mml:mrow><mml:mo>∇</mml:mo><mml:mo>⁡</mml:mo><mml:mi>P</mml:mi></mml:mrow></mml:mrow></mml:mrow><mml:mo>+</mml:mo><mml:mrow><mml:mi>ν</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:msup><mml:mo>∇</mml:mo><mml:mn>2</mml:mn></mml:msup><mml:mo>⁡</mml:mo><mml:mi>u</mml:mi></mml:mrow></mml:mrow></mml:mrow></mml:mrow><mml:mo mathvariant="italic" separator="true">  </mml:mo><mml:mrow><mml:mrow><mml:mo>∇</mml:mo><mml:mo>⋅</mml:mo><mml:mi>u</mml:mi></mml:mrow><mml:mo>=</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:mrow></mml:math></disp-formula><disp-formula id="equ7">,<label>(M2)</label><mml:math id="m7"><mml:mrow><mml:mrow><mml:mrow><mml:msub><mml:mo>∂</mml:mo><mml:mi>t</mml:mi></mml:msub><mml:mo>⁡</mml:mo><mml:mi>θ</mml:mi></mml:mrow><mml:mo>+</mml:mo><mml:mrow><mml:mi>u</mml:mi><mml:mo>⋅</mml:mo><mml:mrow><mml:mo>∇</mml:mo><mml:mo>⁡</mml:mo><mml:mi>θ</mml:mi></mml:mrow></mml:mrow></mml:mrow><mml:mo>=</mml:mo><mml:mrow><mml:mrow><mml:msub><mml:mi>κ</mml:mi><mml:mi>θ</mml:mi></mml:msub><mml:mo>⁢</mml:mo><mml:mrow><mml:msup><mml:mo>∇</mml:mo><mml:mn>2</mml:mn></mml:msup><mml:mo>⁡</mml:mo><mml:mi>θ</mml:mi></mml:mrow></mml:mrow><mml:mo>+</mml:mo><mml:mi>q</mml:mi></mml:mrow></mml:mrow></mml:math></disp-formula></p><p>where <inline-formula><mml:math id="inf116"><mml:mi mathvariant="bold">u</mml:mi></mml:math></inline-formula> is the velocity field, <italic>ρ</italic> is the fluid density, <inline-formula><mml:math id="inf117"><mml:mi>P</mml:mi></mml:math></inline-formula> is pressure, <italic>ν</italic> is the fluid kinematic viscosity, <italic>θ</italic> is the odor concentration, <inline-formula><mml:math id="inf118"><mml:msub><mml:mi>κ</mml:mi><mml:mi>θ</mml:mi></mml:msub></mml:math></inline-formula> is its diffusivity, and <inline-formula><mml:math id="inf119"><mml:mi>q</mml:mi></mml:math></inline-formula> an odor source.</p><p>We simulate a turbulent channel of length <inline-formula><mml:math id="inf120"><mml:mi>L</mml:mi></mml:math></inline-formula>, width <inline-formula><mml:math id="inf121"><mml:mi>W</mml:mi></mml:math></inline-formula>, and height <inline-formula><mml:math id="inf122"><mml:mi>H</mml:mi></mml:math></inline-formula>, where fluid flows from left to right and hits a solid hemicylindrical obstacle of height 38 cm set on the ground, which produces turbulence. A horizontal parabolic velocity profile is set at the left boundary <inline-formula><mml:math id="inf123"><mml:mrow><mml:mi>u</mml:mi><mml:mo>=</mml:mo><mml:mrow><mml:mn>6</mml:mn><mml:mo>⁢</mml:mo><mml:msub><mml:mi>U</mml:mi><mml:mi>b</mml:mi></mml:msub><mml:mo>⁢</mml:mo><mml:mrow><mml:mo>[</mml:mo><mml:mrow><mml:mfrac><mml:mi>z</mml:mi><mml:mi>H</mml:mi></mml:mfrac><mml:mo>-</mml:mo><mml:msup><mml:mrow><mml:mo>(</mml:mo><mml:mfrac><mml:mi>z</mml:mi><mml:mi>H</mml:mi></mml:mfrac><mml:mo>)</mml:mo></mml:mrow><mml:mn>2</mml:mn></mml:msup></mml:mrow><mml:mo>]</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:math></inline-formula>, where <inline-formula><mml:math id="inf124"><mml:mi>z</mml:mi></mml:math></inline-formula> is the vertical coordinate and <inline-formula><mml:math id="inf125"><mml:msub><mml:mi>U</mml:mi><mml:mi>b</mml:mi></mml:msub></mml:math></inline-formula> is the mean horizontal speed. We impose the no-slip condition at the ground and on the obstacle and an outflow condition at the other boundaries (see <xref ref-type="bibr" rid="bib22">Rigolli et al., 2021</xref>, for more details).</p><p>When the turbulent flow is fully developed a concentrated odor source is added at 0.58 m from the ground, that is, 20 cm above the center of the obstacle. The source is defined by a Gaussian profile with radius <inline-formula><mml:math id="inf126"><mml:mrow><mml:mi>σ</mml:mi><mml:mo>∼</mml:mo><mml:mrow><mml:mn>5</mml:mn><mml:mo>⁢</mml:mo><mml:mi>η</mml:mi></mml:mrow></mml:mrow></mml:math></inline-formula>, where <italic>η</italic> is the smallest scale of turbulent eddies (see <xref ref-type="table" rid="table1">Table 1</xref>). We set adsorbing boundary conditions at the inlet, on the ground, and on the obstacle and zero gradient conditions on the sides and top.</p><table-wrap id="table1" position="float"><label>Table 1.</label><caption><title>Parameters of the simulation.</title><p>Length <inline-formula><mml:math id="inf127"><mml:mi>L</mml:mi></mml:math></inline-formula>, width <inline-formula><mml:math id="inf128"><mml:mi>W</mml:mi></mml:math></inline-formula>, height <inline-formula><mml:math id="inf129"><mml:mi>H</mml:mi></mml:math></inline-formula> of the computational domain; horizontal speed along the centerline <inline-formula><mml:math id="inf130"><mml:mi>U</mml:mi></mml:math></inline-formula>; mean horizontal speed <inline-formula><mml:math id="inf131"><mml:mrow><mml:msub><mml:mi>U</mml:mi><mml:mi>b</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mrow><mml:mo stretchy="false">⟨</mml:mo><mml:mi>u</mml:mi><mml:mo stretchy="false">⟩</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula>; Kolmogorov length scale <inline-formula><mml:math id="inf132"><mml:mrow><mml:mi>η</mml:mi><mml:mo>=</mml:mo><mml:msup><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:msup><mml:mi>ν</mml:mi><mml:mn>3</mml:mn></mml:msup><mml:mo>/</mml:mo><mml:mi>ϵ</mml:mi></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mrow><mml:mn>1</mml:mn><mml:mo>/</mml:mo><mml:mn>4</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:math></inline-formula>, where <italic>ν</italic> is the kinematic viscosity and <inline-formula><mml:math id="inf133"><mml:mi>ϵ</mml:mi></mml:math></inline-formula> is the energy dissipation rate; mean size of grid cell <inline-formula><mml:math id="inf134"><mml:mrow><mml:mi mathvariant="normal">Δ</mml:mi><mml:mo>⁢</mml:mo><mml:mi>x</mml:mi></mml:mrow></mml:math></inline-formula>; Kolmogorov timescale <inline-formula><mml:math id="inf135"><mml:mrow><mml:msub><mml:mi>τ</mml:mi><mml:mi>η</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mrow><mml:msup><mml:mi>η</mml:mi><mml:mn>2</mml:mn></mml:msup><mml:mo>/</mml:mo><mml:mi>ν</mml:mi></mml:mrow></mml:mrow></mml:math></inline-formula>; energy dissipation rate <inline-formula><mml:math id="inf136"><mml:mrow><mml:mi>ϵ</mml:mi><mml:mo>=</mml:mo><mml:mrow><mml:mrow><mml:mi>ν</mml:mi><mml:mo>/</mml:mo><mml:mn>2</mml:mn></mml:mrow><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">⟨</mml:mo><mml:msup><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mrow><mml:mrow><mml:mo>∂</mml:mo><mml:mo>⁡</mml:mo><mml:msub><mml:mi>u</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow><mml:mo>/</mml:mo><mml:mrow><mml:mo>∂</mml:mo><mml:mo>⁡</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mi>j</mml:mi></mml:msub></mml:mrow></mml:mrow><mml:mo>+</mml:mo><mml:mrow><mml:mrow><mml:mo>∂</mml:mo><mml:mo>⁡</mml:mo><mml:msub><mml:mi>u</mml:mi><mml:mi>j</mml:mi></mml:msub></mml:mrow><mml:mo>/</mml:mo><mml:mrow><mml:mo>∂</mml:mo><mml:mo>⁡</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:mrow></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mn>2</mml:mn></mml:msup><mml:mo stretchy="false">⟩</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:math></inline-formula>; Taylor microscale <inline-formula><mml:math id="inf137"><mml:mrow><mml:mi>λ</mml:mi><mml:mo>=</mml:mo><mml:msqrt><mml:mrow><mml:mrow><mml:mo stretchy="false">⟨</mml:mo><mml:msup><mml:mi>u</mml:mi><mml:mn>2</mml:mn></mml:msup><mml:mo stretchy="false">⟩</mml:mo></mml:mrow><mml:mo>/</mml:mo><mml:mrow><mml:mo stretchy="false">⟨</mml:mo><mml:msup><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mrow><mml:mo>∂</mml:mo><mml:mo>⁡</mml:mo><mml:mi>u</mml:mi></mml:mrow><mml:mo>/</mml:mo><mml:mrow><mml:mo>∂</mml:mo><mml:mo>⁡</mml:mo><mml:mi>x</mml:mi></mml:mrow></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mn>2</mml:mn></mml:msup><mml:mo stretchy="false">⟩</mml:mo></mml:mrow></mml:mrow></mml:msqrt></mml:mrow></mml:math></inline-formula>; wall length scale <inline-formula><mml:math id="inf138"><mml:mrow><mml:msup><mml:mi>y</mml:mi><mml:mo>+</mml:mo></mml:msup><mml:mo>=</mml:mo><mml:mrow><mml:mi>ν</mml:mi><mml:mo>/</mml:mo><mml:msub><mml:mi>u</mml:mi><mml:mi>τ</mml:mi></mml:msub></mml:mrow></mml:mrow></mml:math></inline-formula>, where the friction velocity is <inline-formula><mml:math id="inf139"><mml:mrow><mml:msub><mml:mi>u</mml:mi><mml:mi>τ</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:msqrt><mml:mrow><mml:mi>τ</mml:mi><mml:mo>/</mml:mo><mml:mi>ρ</mml:mi></mml:mrow></mml:msqrt></mml:mrow></mml:math></inline-formula> and the wall stress is <inline-formula><mml:math id="inf140"><mml:mrow><mml:mi>τ</mml:mi><mml:mo>=</mml:mo><mml:msub><mml:mrow><mml:mrow><mml:mrow><mml:mrow><mml:mi>ρ</mml:mi><mml:mo>⁢</mml:mo><mml:mi>ν</mml:mi><mml:mo>⁢</mml:mo><mml:mi>d</mml:mi><mml:mo>⁢</mml:mo><mml:mi>u</mml:mi></mml:mrow><mml:mo>/</mml:mo><mml:mi>d</mml:mi></mml:mrow><mml:mo>⁢</mml:mo><mml:mi>z</mml:mi></mml:mrow><mml:mo fence="true" stretchy="false">|</mml:mo></mml:mrow><mml:mrow><mml:mi>z</mml:mi><mml:mo>=</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:math></inline-formula>; Reynolds number <inline-formula><mml:math id="inf141"><mml:mrow><mml:mrow><mml:mi>R</mml:mi><mml:mo>⁢</mml:mo><mml:mi>e</mml:mi></mml:mrow><mml:mo>=</mml:mo><mml:mrow><mml:mrow><mml:mi>U</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mi>H</mml:mi><mml:mo>/</mml:mo><mml:mn>2</mml:mn></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mo>/</mml:mo><mml:mi>ν</mml:mi></mml:mrow></mml:mrow></mml:math></inline-formula> based on the centerline speed <inline-formula><mml:math id="inf142"><mml:mi>U</mml:mi></mml:math></inline-formula> and half height; Reynolds number <inline-formula><mml:math id="inf143"><mml:mrow><mml:mrow><mml:mi>R</mml:mi><mml:mo>⁢</mml:mo><mml:msub><mml:mi>e</mml:mi><mml:mi>λ</mml:mi></mml:msub></mml:mrow><mml:mo>=</mml:mo><mml:mrow><mml:mrow><mml:mi>U</mml:mi><mml:mo>⁢</mml:mo><mml:mi>λ</mml:mi></mml:mrow><mml:mo>/</mml:mo><mml:mi>ν</mml:mi></mml:mrow></mml:mrow></mml:math></inline-formula> based on the centerline speed and the Taylor microscale <italic>λ</italic>; magnitude of velocity fluctuations <inline-formula><mml:math id="inf144"><mml:msup><mml:mi>u</mml:mi><mml:mo>′</mml:mo></mml:msup></mml:math></inline-formula> relative to the centerline speed; large eddy turnover time <inline-formula><mml:math id="inf145"><mml:mrow><mml:mi>T</mml:mi><mml:mo>=</mml:mo><mml:mrow><mml:mrow><mml:mi>H</mml:mi><mml:mo>/</mml:mo><mml:mn>2</mml:mn></mml:mrow><mml:mo>⁢</mml:mo><mml:msup><mml:mi>u</mml:mi><mml:mo>′</mml:mo></mml:msup></mml:mrow></mml:mrow></mml:math></inline-formula>. First and third rows are the labels, second and forth rows report results in non-dimensional units, third and fifth rows correspond to dimensional parameters in air, assuming the mean speed is 25 cm/s.</p></caption><table frame="hsides" rules="groups"><thead><tr><th align="left" valign="bottom"><inline-formula><mml:math id="inf146"><mml:mi>L</mml:mi></mml:math></inline-formula></th><th align="left" valign="bottom"><inline-formula><mml:math id="inf147"><mml:mi>W</mml:mi></mml:math></inline-formula></th><th align="left" valign="bottom"><inline-formula><mml:math id="inf148"><mml:mi>H</mml:mi></mml:math></inline-formula></th><th align="left" valign="bottom"><inline-formula><mml:math id="inf149"><mml:mi>U</mml:mi></mml:math></inline-formula></th><th align="left" valign="bottom"><inline-formula><mml:math id="inf150"><mml:msub><mml:mi>U</mml:mi><mml:mi>b</mml:mi></mml:msub></mml:math></inline-formula></th><th align="left" valign="bottom"><italic>η</italic></th><th align="left" valign="bottom"><inline-formula><mml:math id="inf151"><mml:mrow><mml:mi mathvariant="normal">Δ</mml:mi><mml:mo>⁢</mml:mo><mml:mi>x</mml:mi></mml:mrow></mml:math></inline-formula></th><th align="left" valign="bottom"/></tr></thead><tbody><tr><td align="left" valign="bottom">40</td><td align="left" valign="bottom">8</td><td align="left" valign="bottom">4</td><td align="left" valign="bottom">32</td><td align="left" valign="bottom">25</td><td align="left" valign="bottom">0.006</td><td align="left" valign="bottom">0.025</td><td align="left" valign="bottom"/></tr><tr><td align="left" valign="bottom">15 m</td><td align="left" valign="bottom">3 m</td><td align="left" valign="bottom">1.5 m</td><td align="left" valign="bottom">0.33 m/s</td><td align="left" valign="bottom">0.25 m/s</td><td align="left" valign="bottom">0.23 cm</td><td align="left" valign="bottom">1 cm</td><td align="left" valign="bottom"/></tr> <tr><td align="left" valign="bottom"><inline-formula><mml:math id="inf152"><mml:msub><mml:mi>τ</mml:mi><mml:mi>η</mml:mi></mml:msub></mml:math></inline-formula></td><td align="left" valign="bottom"><inline-formula><mml:math id="inf153"><mml:mi>ϵ</mml:mi></mml:math></inline-formula></td><td align="left" valign="bottom"><italic>λ</italic></td><td align="left" valign="bottom"><inline-formula><mml:math id="inf154"><mml:msup><mml:mi>y</mml:mi><mml:mo>+</mml:mo></mml:msup></mml:math></inline-formula></td><td align="left" valign="bottom">Re</td><td align="left" valign="bottom">Re<italic>λ</italic></td><td align="left" valign="bottom"><inline-formula><mml:math id="inf155"><mml:mrow><mml:msup><mml:mi>u</mml:mi><mml:mo>′</mml:mo></mml:msup><mml:mo>/</mml:mo><mml:mi>U</mml:mi></mml:mrow></mml:math></inline-formula></td><td align="left" valign="bottom"><inline-formula><mml:math id="inf156"><mml:mi>T</mml:mi></mml:math></inline-formula></td></tr><tr><td align="left" valign="bottom">0.01</td><td align="left" valign="bottom">39</td><td align="left" valign="bottom">0.17</td><td align="left" valign="bottom">0.004</td><td align="left" valign="bottom">16000</td><td align="left" valign="bottom">1370</td><td align="left" valign="bottom">10%</td><td align="left" valign="bottom"><inline-formula><mml:math id="inf157"><mml:mrow><mml:mn>64</mml:mn><mml:mo>⁢</mml:mo><mml:msub><mml:mi>τ</mml:mi><mml:mi>η</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula></td></tr><tr><td align="left" valign="bottom">0.36 s</td><td align="left" valign="bottom">1.2e-4 m<sup>2</sup>/s<sup>3</sup></td><td align="left" valign="bottom">6 cm</td><td align="left" valign="bottom">0.14 cm</td><td align="left" valign="bottom"/><td align="left" valign="bottom"/><td align="left" valign="bottom"/><td align="left" valign="bottom"/></tr></tbody></table></table-wrap><p>The simulation was realized by customizing the open-source software Nek5000 (<xref ref-type="bibr" rid="bib8">Fischer et al., 2008</xref>) developed at Argonne National Laboratory, Illinois. The three-dimensional (3D) volume of the channel is discretized in a finite number of elements and Nek5000 solves the Navier-Stokes and scalar transport equations within every element with a spectral element method. To accurately describe all relevant scales of turbulence from the dissipative scale to the length of the domain, the solution is expanded in eighth grade polynomials in each of 160,000 elements, thus effectively discretizing space in 81,920,000 grid points. <xref ref-type="table" rid="table1">Table 1</xref> summarizes the parameters that characterize the flow. Each DNS runs for 300,000 time steps where <inline-formula><mml:math id="inf158"><mml:mrow><mml:mrow><mml:mi>δ</mml:mi><mml:mo>⁢</mml:mo><mml:mi>t</mml:mi></mml:mrow><mml:mo>=</mml:mo><mml:mrow><mml:msup><mml:mn>10</mml:mn><mml:mrow><mml:mo>-</mml:mo><mml:mn>2</mml:mn></mml:mrow></mml:msup><mml:mo>⁢</mml:mo><mml:msub><mml:mi>τ</mml:mi><mml:mi>η</mml:mi></mml:msub></mml:mrow></mml:mrow></mml:math></inline-formula> following a strict Courant criterionwith <inline-formula><mml:math id="inf159"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>U</mml:mi><mml:mi mathvariant="normal">Δ</mml:mi><mml:mi>t</mml:mi><mml:mrow><mml:mo>/</mml:mo></mml:mrow><mml:mi mathvariant="normal">Δ</mml:mi><mml:mi>x</mml:mi><mml:mo>&lt;</mml:mo><mml:mn>0.4</mml:mn></mml:mrow></mml:mstyle></mml:math></inline-formula> to ensure convergence of both the velocity and scalar fields. Snapshots of velocity and odor fields are saved at constant frequency <inline-formula><mml:math id="inf160"><mml:mrow><mml:mi>ω</mml:mi><mml:mo>=</mml:mo><mml:mrow><mml:mn>1</mml:mn><mml:mo>/</mml:mo><mml:msub><mml:mi>τ</mml:mi><mml:mi>η</mml:mi></mml:msub></mml:mrow></mml:mrow></mml:math></inline-formula>. Fully parallelized simulations require 2 weeks of computational time using 320 cpu, see <xref ref-type="bibr" rid="bib22">Rigolli et al., 2021</xref>, for further details. The dataset containing odor concentration fields at nose and ground level is publicly available at <ext-link ext-link-type="uri" xlink:href="https://zenodo.org/record/6538177#.Yqrl_5BByJE">https://zenodo.org/record/6538177#.Yqrl_5BByJE</ext-link>.</p></sec><sec id="s4-2"><title>The POMDP framework</title><p>We briefly introduce POMDPs before describing the specific algorithms used in our simulations. We refer to <xref ref-type="bibr" rid="bib24">Shani et al., 2013</xref>, for a detailed review on POMDPs. POMDPs are a generalization of Markov decision processes (MDPs) analogous to the relationship between hidden Markov models and Markov models (<xref ref-type="bibr" rid="bib14">Kaelbling et al., 1998</xref>; <xref ref-type="bibr" rid="bib29">Sutton and Barto, 2018</xref>). In an MDP, we define a state space, an action space, and a reward function. The dynamics of the state space is Markovian and is defined entirely by the transition matrix, <inline-formula><mml:math id="inf161"><mml:mrow><mml:mi>T</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:msup><mml:mi>s</mml:mi><mml:mo>′</mml:mo></mml:msup><mml:mo lspace="2.5pt" rspace="2.5pt" stretchy="false">|</mml:mo><mml:mrow><mml:mi>s</mml:mi><mml:mo>,</mml:mo><mml:mi>a</mml:mi></mml:mrow></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula>, which gives the probability of transitioning to state <inline-formula><mml:math id="inf162"><mml:msup><mml:mi>s</mml:mi><mml:mo>′</mml:mo></mml:msup></mml:math></inline-formula> given the current state <inline-formula><mml:math id="inf163"><mml:mi>s</mml:mi></mml:math></inline-formula> and the action taken, <inline-formula><mml:math id="inf164"><mml:mi>a</mml:mi></mml:math></inline-formula>. After each transition, the agent receives a reward, which has expectation <inline-formula><mml:math id="inf165"><mml:mrow><mml:mi>r</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>s</mml:mi><mml:mo>,</mml:mo><mml:mi>a</mml:mi><mml:mo>,</mml:mo><mml:msup><mml:mi>s</mml:mi><mml:mo>′</mml:mo></mml:msup><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula>. Given the transition matrix and the reward function, the goal is typically to find the unique optimal policy, <inline-formula><mml:math id="inf166"><mml:mrow><mml:msup><mml:mi mathvariant="normal">Π</mml:mi><mml:mo>*</mml:mo></mml:msup><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>s</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula>, which maximizes the discounted sum of future rewards, <inline-formula><mml:math id="inf167"><mml:mrow><mml:mo stretchy="false">⟨</mml:mo><mml:mrow><mml:msub><mml:mi>r</mml:mi><mml:mn>0</mml:mn></mml:msub><mml:mo>+</mml:mo><mml:mrow><mml:mi>γ</mml:mi><mml:mo>⁢</mml:mo><mml:msub><mml:mi>r</mml:mi><mml:mn>1</mml:mn></mml:msub></mml:mrow><mml:mo>+</mml:mo><mml:mrow><mml:msup><mml:mi>γ</mml:mi><mml:mn>2</mml:mn></mml:msup><mml:mo>⁢</mml:mo><mml:msub><mml:mi>r</mml:mi><mml:mn>2</mml:mn></mml:msub></mml:mrow><mml:mo>+</mml:mo><mml:mi mathvariant="normal">…</mml:mi></mml:mrow><mml:mo stretchy="false">⟩</mml:mo></mml:mrow></mml:math></inline-formula>, where <italic>γ</italic> is the discount factor and <italic>r</italic><sub><italic>t</italic></sub> is the expected reward <inline-formula><mml:math id="inf168"><mml:mi>t</mml:mi></mml:math></inline-formula> steps after the initial state. Often, but not always, this involves solving for the value function, <inline-formula><mml:math id="inf169"><mml:mrow><mml:mi>V</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>s</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula>, which is the expected discounted sum of rewards from state <inline-formula><mml:math id="inf170"><mml:mi>s</mml:mi></mml:math></inline-formula>, conditional on policy <inline-formula><mml:math id="inf171"><mml:mrow><mml:msup><mml:mi mathvariant="normal">Π</mml:mi><mml:mo>*</mml:mo></mml:msup><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>s</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula>. The value function satisfies the central dynamic programming equation known as the <xref ref-type="bibr" rid="bib3">Bellman, 2003</xref>, equation:<disp-formula id="equ8"><label>(M3)</label><mml:math id="m8"><mml:mrow><mml:mrow><mml:mrow><mml:mi>V</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>s</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mo>=</mml:mo><mml:mrow><mml:munder><mml:mi>max</mml:mi><mml:mi>a</mml:mi></mml:munder><mml:mo>⁡</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:munder><mml:mo largeop="true" movablelimits="false" symmetric="true">∑</mml:mo><mml:msup><mml:mi>s</mml:mi><mml:mo>′</mml:mo></mml:msup></mml:munder><mml:mrow><mml:mi>T</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:msup><mml:mi>s</mml:mi><mml:mo>′</mml:mo></mml:msup><mml:mo lspace="2.5pt" rspace="2.5pt" stretchy="false">|</mml:mo><mml:mrow><mml:mi>a</mml:mi><mml:mo>,</mml:mo><mml:mi>s</mml:mi></mml:mrow></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>⁢</mml:mo><mml:mrow><mml:mo>{</mml:mo><mml:mrow><mml:mrow><mml:mi>r</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>s</mml:mi><mml:mo>,</mml:mo><mml:mi>a</mml:mi><mml:mo>,</mml:mo><mml:msup><mml:mi>s</mml:mi><mml:mo>′</mml:mo></mml:msup><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mo>+</mml:mo><mml:mrow><mml:mi>γ</mml:mi><mml:mo>⁢</mml:mo><mml:mi>V</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msup><mml:mi>s</mml:mi><mml:mo>′</mml:mo></mml:msup><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:mrow><mml:mo>}</mml:mo></mml:mrow></mml:mrow></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mrow><mml:mo>.</mml:mo></mml:mrow></mml:math></disp-formula></p><p>While MDPs deal with fully observable states, POMDPs have one additional feature which makes it appropriate for our setting. Instead of observing the current state, the agent only receives certain observations, <inline-formula><mml:math id="inf172"><mml:mi>o</mml:mi></mml:math></inline-formula>, from which the true latent state has to be dynamically inferred. The agent is assumed to have a model of the environment, <inline-formula><mml:math id="inf173"><mml:mrow><mml:mi>P</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mi>o</mml:mi><mml:mo lspace="2.5pt" rspace="2.5pt" stretchy="false">|</mml:mo><mml:mrow><mml:mi>s</mml:mi><mml:mo>,</mml:mo><mml:mi>a</mml:mi></mml:mrow></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula>. In our setting, this likelihood function encodes the statistics of detections and non-detections at various locations downwind of an odor source (<xref ref-type="fig" rid="fig2s1">Figure 2—figure supplement 1</xref>). A POMDP therefore maps a sequence of recent observations and actions <inline-formula><mml:math id="inf174"><mml:mrow><mml:msub><mml:mi>o</mml:mi><mml:mrow><mml:mo>-</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>a</mml:mi><mml:mrow><mml:mo>-</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>o</mml:mi><mml:mrow><mml:mo>-</mml:mo><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>a</mml:mi><mml:mrow><mml:mo>-</mml:mo><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:mi mathvariant="normal">…</mml:mi></mml:mrow></mml:math></inline-formula> to a strategic action. While the dimensionality increases rapidly with the length of the observation history, the entire history is encoded by the current posterior distribution over states, <inline-formula><mml:math id="inf175"><mml:mi mathvariant="bold">b</mml:mi></mml:math></inline-formula>, also known as the <italic>belief vector</italic>. The problem of solving for the optimal action is recast as the problem of solving for the policy <inline-formula><mml:math id="inf176"><mml:mrow><mml:msup><mml:mi mathvariant="normal">Π</mml:mi><mml:mo>*</mml:mo></mml:msup><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi mathvariant="bold">b</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula>. The Bellman equation on states for MDPs translates into a Bellman equation on belief vectors for POMDPs:<disp-formula id="equ9"><label>(M4)</label><mml:math id="m9"><mml:mrow><mml:mtable columnalign="right left" rowspacing="4pt" columnspacing="1em"><mml:mtr><mml:mtd><mml:mi>V</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mi mathvariant="bold">b</mml:mi></mml:mrow><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:munder><mml:mo movablelimits="true" form="prefix">max</mml:mo><mml:mrow><mml:mi>a</mml:mi></mml:mrow></mml:munder><mml:mrow><mml:mo maxsize="2.047em" minsize="2.047em">(</mml:mo></mml:mrow><mml:munder><mml:mo>∑</mml:mo><mml:mrow><mml:mi>s</mml:mi><mml:mo>,</mml:mo><mml:msup><mml:mi>s</mml:mi><mml:mrow><mml:mi mathvariant="normal">′</mml:mi></mml:mrow></mml:msup></mml:mrow></mml:munder></mml:mtd><mml:mtd><mml:mrow><mml:mi mathvariant="bold">b</mml:mi></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>s</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mi>T</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msup><mml:mi>s</mml:mi><mml:mrow><mml:mi mathvariant="normal">′</mml:mi></mml:mrow></mml:msup><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mi>a</mml:mi><mml:mo>,</mml:mo><mml:mi>s</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mtd></mml:mtr><mml:mtr><mml:mtd/><mml:mtd><mml:mo>×</mml:mo><mml:mrow><mml:mo maxsize="2.047em" minsize="2.047em">{</mml:mo></mml:mrow><mml:mi>r</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>s</mml:mi><mml:mo>,</mml:mo><mml:mi>a</mml:mi><mml:mo>,</mml:mo><mml:msup><mml:mi>s</mml:mi><mml:mrow><mml:mi mathvariant="normal">′</mml:mi></mml:mrow></mml:msup><mml:mo stretchy="false">)</mml:mo><mml:mo>+</mml:mo><mml:mi>γ</mml:mi><mml:munder><mml:mo>∑</mml:mo><mml:mrow><mml:mi>o</mml:mi></mml:mrow></mml:munder><mml:mi>P</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>o</mml:mi><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:msup><mml:mi>s</mml:mi><mml:mrow><mml:mi mathvariant="normal">′</mml:mi></mml:mrow></mml:msup><mml:mo>,</mml:mo><mml:mi>a</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mi>V</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msup><mml:mrow><mml:mi mathvariant="bold">b</mml:mi></mml:mrow><mml:mrow><mml:mi>a</mml:mi><mml:mo>,</mml:mo><mml:mi>o</mml:mi></mml:mrow></mml:msup><mml:mo stretchy="false">)</mml:mo><mml:mrow><mml:mo maxsize="2.047em" minsize="2.047em">}</mml:mo></mml:mrow><mml:mrow><mml:mo maxsize="2.047em" minsize="2.047em">)</mml:mo></mml:mrow><mml:mo>,</mml:mo></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:math></disp-formula></p><p>where <inline-formula><mml:math id="inf177"><mml:msup><mml:mi mathvariant="bold">b</mml:mi><mml:mrow><mml:mi>a</mml:mi><mml:mo>,</mml:mo><mml:mi>o</mml:mi></mml:mrow></mml:msup></mml:math></inline-formula> is the posterior belief state given the agent takes action <inline-formula><mml:math id="inf178"><mml:mi>a</mml:mi></mml:math></inline-formula> and observes <inline-formula><mml:math id="inf179"><mml:mi>o</mml:mi></mml:math></inline-formula>. Using Bayes’ rule, <inline-formula><mml:math id="inf180"><mml:msup><mml:mi mathvariant="bold">b</mml:mi><mml:mrow><mml:mi>a</mml:mi><mml:mo>,</mml:mo><mml:mi>o</mml:mi></mml:mrow></mml:msup></mml:math></inline-formula> is given by<disp-formula id="equ10"><label>(M5)</label><mml:math id="m10"><mml:mrow><mml:msup><mml:mrow><mml:mi mathvariant="bold">b</mml:mi></mml:mrow><mml:mrow><mml:mi>a</mml:mi><mml:mo>,</mml:mo><mml:mi>o</mml:mi></mml:mrow></mml:msup><mml:mo stretchy="false">(</mml:mo><mml:msup><mml:mi>s</mml:mi><mml:mrow><mml:mi mathvariant="normal">′</mml:mi></mml:mrow></mml:msup><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mi>P</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msup><mml:mi>s</mml:mi><mml:mrow><mml:mi mathvariant="normal">′</mml:mi></mml:mrow></mml:msup><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mi>a</mml:mi><mml:mo>,</mml:mo><mml:mi>o</mml:mi><mml:mo>,</mml:mo><mml:mrow><mml:mi mathvariant="bold">b</mml:mi></mml:mrow><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mi>P</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>o</mml:mi><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:msup><mml:mi>s</mml:mi><mml:mrow><mml:mi mathvariant="normal">′</mml:mi></mml:mrow></mml:msup><mml:mo>,</mml:mo><mml:mi>a</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:munder><mml:mo>∑</mml:mo><mml:mrow><mml:mi>s</mml:mi></mml:mrow></mml:munder><mml:mi>T</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msup><mml:mi>s</mml:mi><mml:mrow><mml:mi mathvariant="normal">′</mml:mi></mml:mrow></mml:msup><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mi>s</mml:mi><mml:mo>,</mml:mo><mml:mi>a</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mrow><mml:mi mathvariant="bold">b</mml:mi></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>s</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mrow><mml:mi>P</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>o</mml:mi><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mrow><mml:mi mathvariant="bold">b</mml:mi></mml:mrow><mml:mo>,</mml:mo><mml:mi>a</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mfrac><mml:mo>,</mml:mo></mml:mrow></mml:math></disp-formula></p><p>where the normalizing factor is<disp-formula id="equ11">.<label>(M6)</label><mml:math id="m11"><mml:mrow><mml:mi>P</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>o</mml:mi><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mrow><mml:mi mathvariant="bold">b</mml:mi></mml:mrow><mml:mo>,</mml:mo><mml:mi>a</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:munder><mml:mo>∑</mml:mo><mml:mrow><mml:msup><mml:mi>s</mml:mi><mml:mrow><mml:mi mathvariant="normal">′</mml:mi></mml:mrow></mml:msup></mml:mrow></mml:munder><mml:mrow><mml:mi mathvariant="bold">b</mml:mi></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msup><mml:mi>s</mml:mi><mml:mrow><mml:mi mathvariant="normal">′</mml:mi></mml:mrow></mml:msup><mml:mo stretchy="false">)</mml:mo><mml:munder><mml:mo>∑</mml:mo><mml:mrow><mml:mi>s</mml:mi></mml:mrow></mml:munder><mml:mi>T</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>s</mml:mi><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:msup><mml:mi>s</mml:mi><mml:mrow><mml:mi mathvariant="normal">′</mml:mi></mml:mrow></mml:msup><mml:mo>,</mml:mo><mml:mi>a</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mi>P</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>o</mml:mi><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mi>s</mml:mi><mml:mo>,</mml:mo><mml:mi>a</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></disp-formula></p><p>Recall that <inline-formula><mml:math id="inf181"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mrow><mml:mi mathvariant="bold">b</mml:mi></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>s</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mi>P</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>s</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mstyle></mml:math></inline-formula> and thus the term <inline-formula><mml:math id="inf182"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:munder><mml:mo>∑</mml:mo><mml:mrow><mml:mi>s</mml:mi></mml:mrow></mml:munder><mml:mi>T</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msup><mml:mi>s</mml:mi><mml:mrow><mml:mi mathvariant="normal">′</mml:mi></mml:mrow></mml:msup><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mi>s</mml:mi><mml:mo>,</mml:mo><mml:mi>a</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mrow><mml:mi mathvariant="bold">b</mml:mi></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>s</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mstyle></mml:math></inline-formula> is the probability of transitioning to state <inline-formula><mml:math id="inf183"><mml:msup><mml:mi>s</mml:mi><mml:mo>′</mml:mo></mml:msup></mml:math></inline-formula> given the current belief state <inline-formula><mml:math id="inf184"><mml:mi mathvariant="bold">b</mml:mi></mml:math></inline-formula> and action <inline-formula><mml:math id="inf185"><mml:mi>a</mml:mi></mml:math></inline-formula> whereas <inline-formula><mml:math id="inf186"><mml:mrow><mml:mi>P</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mi>o</mml:mi><mml:mo lspace="2.5pt" rspace="2.5pt" stretchy="false">|</mml:mo><mml:mrow><mml:msup><mml:mi>s</mml:mi><mml:mo>′</mml:mo></mml:msup><mml:mo>,</mml:mo><mml:mi>a</mml:mi></mml:mrow></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> is the probability of observing <inline-formula><mml:math id="inf187"><mml:mi>o</mml:mi></mml:math></inline-formula> at the new state <inline-formula><mml:math id="inf188"><mml:msup><mml:mi>s</mml:mi><mml:mo>′</mml:mo></mml:msup></mml:math></inline-formula>. Intuitively, the Bayes’ rule takes into account the new information gained from the most recent observation (via <inline-formula><mml:math id="inf189"><mml:mrow><mml:mi>P</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mi>o</mml:mi><mml:mo lspace="2.5pt" rspace="2.5pt" stretchy="false">|</mml:mo><mml:mrow><mml:msup><mml:mi>s</mml:mi><mml:mo>′</mml:mo></mml:msup><mml:mo>,</mml:mo><mml:mi>a</mml:mi></mml:mrow></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula>) and the information lost due to the state space dynamics (via <inline-formula><mml:math id="inf190"><mml:mrow><mml:mi>T</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:msup><mml:mi>s</mml:mi><mml:mo>′</mml:mo></mml:msup><mml:mo lspace="2.5pt" rspace="2.5pt" stretchy="false">|</mml:mo><mml:mrow><mml:mi>s</mml:mi><mml:mo>,</mml:mo><mml:mi>a</mml:mi></mml:mrow></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula>), which are in turn influenced by the action.</p></sec><sec id="s4-3"><title>Algorithms to solve POMDPs</title><p>We use POMDP-solvers which approximate the value function, <inline-formula><mml:math id="inf191"><mml:mrow><mml:mi>V</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi mathvariant="bold">b</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula>, for all <inline-formula><mml:math id="inf192"><mml:mi mathvariant="bold">b</mml:mi></mml:math></inline-formula> . If the value function is known, the optimal policy is simply to choose the action that yields the highest future expected return given the current belief vector:<disp-formula id="equ12"><label>(M7)</label><mml:math id="m12"><mml:mrow><mml:mtable columnalign="right left" rowspacing="4pt" columnspacing="1em"><mml:mtr><mml:mtd><mml:msup><mml:mi mathvariant="normal">Π</mml:mi><mml:mrow><mml:mo>∗</mml:mo></mml:mrow></mml:msup><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mi mathvariant="bold">b</mml:mi></mml:mrow><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mi>arg</mml:mi><mml:mo>⁡</mml:mo><mml:munder><mml:mo movablelimits="true" form="prefix">max</mml:mo><mml:mrow><mml:mi>a</mml:mi></mml:mrow></mml:munder></mml:mtd><mml:mtd><mml:munder><mml:mo>∑</mml:mo><mml:mrow><mml:mi>s</mml:mi><mml:mo>,</mml:mo><mml:msup><mml:mi>s</mml:mi><mml:mrow><mml:mi mathvariant="normal">′</mml:mi></mml:mrow></mml:msup></mml:mrow></mml:munder><mml:mrow><mml:mi mathvariant="bold">b</mml:mi></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>s</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mi>T</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msup><mml:mi>s</mml:mi><mml:mrow><mml:mi mathvariant="normal">′</mml:mi></mml:mrow></mml:msup><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mi>a</mml:mi><mml:mo>,</mml:mo><mml:mi>s</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mtd></mml:mtr><mml:mtr><mml:mtd/><mml:mtd><mml:mo>×</mml:mo><mml:mrow><mml:mo maxsize="2.047em" minsize="2.047em">{</mml:mo></mml:mrow><mml:mi>r</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>s</mml:mi><mml:mo>,</mml:mo><mml:mi>a</mml:mi><mml:mo>,</mml:mo><mml:msup><mml:mi>s</mml:mi><mml:mrow><mml:mi mathvariant="normal">′</mml:mi></mml:mrow></mml:msup><mml:mo stretchy="false">)</mml:mo><mml:mo>+</mml:mo><mml:mi>γ</mml:mi><mml:munder><mml:mo>∑</mml:mo><mml:mrow><mml:mi>o</mml:mi></mml:mrow></mml:munder><mml:mi>P</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>o</mml:mi><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:msup><mml:mi>s</mml:mi><mml:mrow><mml:mi mathvariant="normal">′</mml:mi></mml:mrow></mml:msup><mml:mo>,</mml:mo><mml:mi>a</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mi>V</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msup><mml:mrow><mml:mi mathvariant="bold">b</mml:mi></mml:mrow><mml:mrow><mml:mi>a</mml:mi><mml:mo>,</mml:mo><mml:mi>o</mml:mi></mml:mrow></mml:msup><mml:mo stretchy="false">)</mml:mo><mml:mrow><mml:mo maxsize="2.047em" minsize="2.047em">}</mml:mo></mml:mrow><mml:mo>.</mml:mo></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:math></disp-formula></p><p>Computing the value function <inline-formula><mml:math id="inf193"><mml:mrow><mml:mi>V</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi mathvariant="bold">b</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> exactly for all belief vectors for tasks containing more than a handful of states is infeasible. Existing methods exploit a specific representation of the value function, which leads to the approximation discussed by <xref ref-type="bibr" rid="bib24">Shani et al., 2013</xref>. We recapitulate here the main results and refer to <xref ref-type="bibr" rid="bib24">Shani et al., 2013</xref>, for more details. In particular, it can be shown that the value function can be approximated arbitrarily well by a finite set <inline-formula><mml:math id="inf194"><mml:mi>H</mml:mi></mml:math></inline-formula> of hyperplanes (<xref ref-type="bibr" rid="bib26">Sondik, 1978</xref>), each of which is parameterized by <inline-formula><mml:math id="inf195"><mml:mrow><mml:mi>α</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>s</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula>:<disp-formula id="equ13"><label>(M8)</label><mml:math id="m13"><mml:mrow><mml:mi>V</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mi mathvariant="bold">b</mml:mi></mml:mrow><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:munder><mml:mo movablelimits="true" form="prefix">max</mml:mo><mml:mrow><mml:mrow><mml:mi>α</mml:mi></mml:mrow><mml:mo>∈</mml:mo><mml:mi>H</mml:mi></mml:mrow></mml:munder><mml:mrow><mml:mi>α</mml:mi></mml:mrow><mml:mo>⋅</mml:mo><mml:mrow><mml:mi mathvariant="bold">b</mml:mi></mml:mrow><mml:mo>.</mml:mo></mml:mrow></mml:math></disp-formula></p><p>An initial set <inline-formula><mml:math id="inf196"><mml:mi>H</mml:mi></mml:math></inline-formula> is expanded using the Bellman <xref ref-type="disp-formula" rid="equ9">Equation M4</xref>. Using vector notation, we can write<disp-formula id="equ14"><label>(M9)</label><mml:math id="m14"><mml:mrow><mml:mi>V</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mi mathvariant="bold">b</mml:mi></mml:mrow><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:munder><mml:mo movablelimits="true" form="prefix">max</mml:mo><mml:mrow><mml:mi>a</mml:mi></mml:mrow></mml:munder><mml:mrow><mml:mo>{</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="bold">r</mml:mi></mml:mrow><mml:mrow><mml:mi>a</mml:mi></mml:mrow></mml:msub><mml:mo>⋅</mml:mo><mml:mrow><mml:mi mathvariant="bold">b</mml:mi></mml:mrow><mml:mo>+</mml:mo><mml:mi>γ</mml:mi><mml:munder><mml:mo>∑</mml:mo><mml:mrow><mml:mi>o</mml:mi></mml:mrow></mml:munder><mml:mi>P</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>o</mml:mi><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mrow><mml:mi mathvariant="bold">b</mml:mi></mml:mrow><mml:mo>,</mml:mo><mml:mi>a</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mi>V</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msup><mml:mrow><mml:mi mathvariant="bold">b</mml:mi></mml:mrow><mml:mrow><mml:mi>a</mml:mi><mml:mo>,</mml:mo><mml:mi>o</mml:mi></mml:mrow></mml:msup><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>}</mml:mo></mml:mrow><mml:mo>,</mml:mo></mml:mrow></mml:math></disp-formula></p><p>where <inline-formula><mml:math id="inf197"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="bold">r</mml:mi></mml:mrow><mml:mrow><mml:mi>a</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>s</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>≡</mml:mo><mml:munder><mml:mo>∑</mml:mo><mml:mrow><mml:msup><mml:mi>s</mml:mi><mml:mrow><mml:mi mathvariant="normal">′</mml:mi></mml:mrow></mml:msup></mml:mrow></mml:munder><mml:mi>T</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msup><mml:mi>s</mml:mi><mml:mrow><mml:mi mathvariant="normal">′</mml:mi></mml:mrow></mml:msup><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mi>a</mml:mi><mml:mo>,</mml:mo><mml:mi>s</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mi>r</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>s</mml:mi><mml:mo>,</mml:mo><mml:mi>a</mml:mi><mml:mo>,</mml:mo><mml:msup><mml:mi>s</mml:mi><mml:mrow><mml:mi mathvariant="normal">′</mml:mi></mml:mrow></mml:msup><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mstyle></mml:math></inline-formula>. Let <inline-formula><mml:math id="inf198"><mml:mrow><mml:msup><mml:mi>α</mml:mi><mml:mrow><mml:mi>a</mml:mi><mml:mo>,</mml:mo><mml:mi>o</mml:mi></mml:mrow></mml:msup><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>s</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> be defined as<disp-formula id="equ15"><label>(M10)</label><mml:math id="m15"><mml:mrow><mml:msup><mml:mrow><mml:mi>α</mml:mi></mml:mrow><mml:mrow><mml:mi>a</mml:mi><mml:mo>,</mml:mo><mml:mi>o</mml:mi></mml:mrow></mml:msup><mml:mo stretchy="false">(</mml:mo><mml:mi>s</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:munder><mml:mo>∑</mml:mo><mml:mrow><mml:msup><mml:mi>s</mml:mi><mml:mrow><mml:mi mathvariant="normal">′</mml:mi></mml:mrow></mml:msup></mml:mrow></mml:munder><mml:mrow><mml:mi>α</mml:mi></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msup><mml:mi>s</mml:mi><mml:mrow><mml:mi mathvariant="normal">′</mml:mi></mml:mrow></mml:msup><mml:mo stretchy="false">)</mml:mo><mml:mi>P</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>o</mml:mi><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:msup><mml:mi>s</mml:mi><mml:mrow><mml:mi mathvariant="normal">′</mml:mi></mml:mrow></mml:msup><mml:mo>,</mml:mo><mml:mi>a</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mi>T</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msup><mml:mi>s</mml:mi><mml:mrow><mml:mi mathvariant="normal">′</mml:mi></mml:mrow></mml:msup><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mi>s</mml:mi><mml:mo>,</mml:mo><mml:mi>a</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mspace width="thinmathspace"/><mml:mo>.</mml:mo></mml:mrow></mml:math></disp-formula></p><p>and using the belief update (<xref ref-type="disp-formula" rid="equ10">Equation M5</xref>), it follows that<disp-formula id="equ16"><label>(M11)</label><mml:math id="m16"><mml:mrow><mml:mi>V</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mi mathvariant="bold">b</mml:mi></mml:mrow><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:munder><mml:mo movablelimits="true" form="prefix">max</mml:mo><mml:mrow><mml:mi>a</mml:mi></mml:mrow></mml:munder><mml:mrow><mml:mo>{</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="bold">r</mml:mi></mml:mrow><mml:mrow><mml:mi>a</mml:mi></mml:mrow></mml:msub><mml:mo>⋅</mml:mo><mml:mrow><mml:mi mathvariant="bold">b</mml:mi></mml:mrow><mml:mo>+</mml:mo><mml:mi>γ</mml:mi><mml:munder><mml:mo>∑</mml:mo><mml:mrow><mml:mi>o</mml:mi></mml:mrow></mml:munder><mml:munder><mml:mo movablelimits="true" form="prefix">max</mml:mo><mml:mrow><mml:mrow><mml:mi>α</mml:mi></mml:mrow></mml:mrow></mml:munder><mml:mrow><mml:mi mathvariant="bold">b</mml:mi></mml:mrow><mml:mo>⋅</mml:mo><mml:msup><mml:mrow><mml:mi>α</mml:mi></mml:mrow><mml:mrow><mml:mi>a</mml:mi><mml:mo>,</mml:mo><mml:mi>o</mml:mi></mml:mrow></mml:msup></mml:mrow><mml:mo>}</mml:mo></mml:mrow><mml:mspace width="thinmathspace"/><mml:mo>.</mml:mo></mml:mrow></mml:math></disp-formula></p><p>Given the previous set <inline-formula><mml:math id="inf199"><mml:mi>H</mml:mi></mml:math></inline-formula>, we can add a new <italic>α</italic> vector to it corresponding to belief vector <inline-formula><mml:math id="inf200"><mml:mi mathvariant="bold">b</mml:mi></mml:math></inline-formula> called the ‘backup’ operation:<disp-formula id="equ17"><label>(M12)</label><mml:math id="m17"><mml:mrow><mml:mtable columnalign="right left" rowspacing="4pt" columnspacing="1em"><mml:mtr><mml:mtd/><mml:mtd><mml:mtext>backup</mml:mtext><mml:mo stretchy="false">(</mml:mo><mml:mi>H</mml:mi><mml:mo>,</mml:mo><mml:mrow><mml:mi mathvariant="bold">b</mml:mi></mml:mrow><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mi>arg</mml:mi><mml:mo>⁡</mml:mo><mml:munder><mml:mo movablelimits="true" form="prefix">max</mml:mo><mml:mrow><mml:msubsup><mml:mrow><mml:mi>α</mml:mi></mml:mrow><mml:mrow><mml:mi>a</mml:mi></mml:mrow><mml:mrow><mml:mrow><mml:mi mathvariant="bold">b</mml:mi></mml:mrow></mml:mrow></mml:msubsup></mml:mrow></mml:munder><mml:mrow><mml:mi mathvariant="bold">b</mml:mi></mml:mrow><mml:mo>⋅</mml:mo><mml:msubsup><mml:mrow><mml:mi>α</mml:mi></mml:mrow><mml:mrow><mml:mi>a</mml:mi></mml:mrow><mml:mrow><mml:mrow><mml:mi mathvariant="bold">b</mml:mi></mml:mrow></mml:mrow></mml:msubsup><mml:mo>,</mml:mo></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:math></disp-formula><disp-formula id="equ18"><label>(M13)</label><mml:math id="m18"><mml:mrow><mml:mtable columnalign="right left" rowspacing="4pt" columnspacing="1em"><mml:mtr><mml:mtd/><mml:mtd><mml:mtext>where</mml:mtext><mml:mspace width="1em"/><mml:msubsup><mml:mrow><mml:mi>α</mml:mi></mml:mrow><mml:mrow><mml:mi>a</mml:mi></mml:mrow><mml:mrow><mml:mrow><mml:mi mathvariant="bold">b</mml:mi></mml:mrow></mml:mrow></mml:msubsup><mml:mo>=</mml:mo><mml:msub><mml:mrow><mml:mi mathvariant="bold">r</mml:mi></mml:mrow><mml:mrow><mml:mi>a</mml:mi></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:mi>γ</mml:mi><mml:munder><mml:mo>∑</mml:mo><mml:mrow><mml:mi>o</mml:mi></mml:mrow></mml:munder><mml:mi>arg</mml:mi><mml:mo>⁡</mml:mo><mml:munder><mml:mo movablelimits="true" form="prefix">max</mml:mo><mml:mrow><mml:msup><mml:mrow><mml:mi>α</mml:mi></mml:mrow><mml:mrow><mml:mi>a</mml:mi><mml:mo>,</mml:mo><mml:mi>o</mml:mi></mml:mrow></mml:msup></mml:mrow></mml:munder><mml:mrow><mml:mi mathvariant="bold">b</mml:mi></mml:mrow><mml:mo>⋅</mml:mo><mml:msup><mml:mrow><mml:mi>α</mml:mi></mml:mrow><mml:mrow><mml:mi>a</mml:mi><mml:mo>,</mml:mo><mml:mi>o</mml:mi></mml:mrow></mml:msup><mml:mo>.</mml:mo></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:math></disp-formula></p><p>In other words, given a previous set <inline-formula><mml:math id="inf201"><mml:mi>H</mml:mi></mml:math></inline-formula> and new belief vector, one can use the Bellman equation to update <inline-formula><mml:math id="inf202"><mml:mi>H</mml:mi></mml:math></inline-formula> and obtain a better approximation to the value function. The key computational advantage of using the above backup operation is that the <inline-formula><mml:math id="inf203"><mml:msup><mml:mi>α</mml:mi><mml:mrow><mml:mi>a</mml:mi><mml:mo>,</mml:mo><mml:mi>o</mml:mi></mml:mrow></mml:msup></mml:math></inline-formula>’s can be pre-computed for the current <inline-formula><mml:math id="inf204"><mml:mi>H</mml:mi></mml:math></inline-formula> and re-used when backing up.</p><p>The question then is: how do we efficiently collect new belief vectors to update <inline-formula><mml:math id="inf205"><mml:mi>H</mml:mi></mml:math></inline-formula> and prune vectors from <inline-formula><mml:math id="inf206"><mml:mi>H</mml:mi></mml:math></inline-formula> that are no longer necessary? Algorithms differ at these two stages. We use <xref ref-type="bibr" rid="bib27">Spaan and Vlassis, 2005</xref>, which simulates random exploration of the agent. Specifically, at each step in a ‘training’ episode, we start from an initial prior, pick actions (uniform) randomly and then sample observations from <inline-formula><mml:math id="inf207"><mml:mrow><mml:mi>P</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mi>o</mml:mi><mml:mo lspace="2.5pt" rspace="2.5pt" stretchy="false">|</mml:mo><mml:mrow><mml:mi mathvariant="bold">b</mml:mi><mml:mo>,</mml:mo><mml:mi>a</mml:mi></mml:mrow></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula>. The new belief vector obtained using Bayes’ rule is then used to backup <inline-formula><mml:math id="inf208"><mml:mi>H</mml:mi></mml:math></inline-formula>. Finally, after adding a new set of <italic>α</italic> vectors into <inline-formula><mml:math id="inf209"><mml:mi>H</mml:mi></mml:math></inline-formula>, it is efficient to prune the existing ones that are guaranteed to not be used. We prune the <italic>α</italic> vectors whose every component is smaller than those of another vector (see <xref ref-type="bibr" rid="bib24">Shani et al., 2013</xref>, for other heuristic pruning methods).</p><p>Three parameters can be tuned: the discount factor <italic>γ</italic>, the number of belief points sampled per each episode of random exploration, and the total number of training episodes. The discount rate sets the planning horizon, which is set to be of the same order as the typical number of steps to get to the target. Increasing the latter two parameters improves the strategy at the expense of increased training time. We solve the POMDP for various values of these two parameters and show that the performance saturates at a parameter range within computational feasibility.</p></sec><sec id="s4-4"><title>POMDPs for learning sniff-and-search strategies</title><p>To implement POMDPs that learn to navigate odor plumes by employing multiple modes of search, we consider a simple state space consisting of a 2D grid with dimensions <inline-formula><mml:math id="inf210"><mml:mrow><mml:mn>10</mml:mn><mml:mo>×</mml:mo><mml:mn>2</mml:mn></mml:mrow></mml:math></inline-formula> discretized with 30 points per unit length so that the state space has size <inline-formula><mml:math id="inf211"><mml:mrow><mml:mrow><mml:mn>10</mml:mn><mml:mo>×</mml:mo><mml:mn>2</mml:mn><mml:mo>×</mml:mo><mml:msup><mml:mn>30</mml:mn><mml:mn>2</mml:mn></mml:msup></mml:mrow><mml:mo>=</mml:mo><mml:mrow><mml:mn>18</mml:mn><mml:mo>,</mml:mo><mml:mn>000</mml:mn></mml:mrow></mml:mrow></mml:math></inline-formula>. The agent can take six possible actions corresponding to movement in either of the four directions or staying at the same spot while sniffing ground odor cues. The sixth action corresponds to staying at the same spot and sniffing airborne odor cues. After every action, the agent can make one of three observations – no detection, an odor detection, or finding the odor source. Odor detections are binarized, that is, the odor is detected if the concentration is above a certain threshold. The intermittent nature of turbulent fluctuations imply that there is little additional information in the graded concentration beyond the information contained in the detection rate (<xref ref-type="bibr" rid="bib31">Vergassola et al., 2007</xref>; <xref ref-type="bibr" rid="bib32">Victor et al., 2019</xref>). We assume a Poisson rate of detection with the rate map at the ground level and at the nose level when sniffing in the air obtained by measuring the fraction of time the odor concentration is above 0.14% with respect to the maximum concentration at source in the flow simulations. As described above, we use the Perseus algorithm (<xref ref-type="bibr" rid="bib27">Spaan and Vlassis, 2005</xref>), which performs random exploration starting from a given prior belief of where the source is located. We use a uniform prior of dimensions <inline-formula><mml:math id="inf212"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mn>28.6</mml:mn><mml:mspace width="thinmathspace"/><mml:mi mathvariant="normal">m</mml:mi><mml:mo>×</mml:mo><mml:mn>3.4</mml:mn><mml:mspace width="thinmathspace"/><mml:mi mathvariant="normal">m</mml:mi></mml:mrow></mml:mstyle></mml:math></inline-formula>. After training, the POMDP algorithm yields a set <inline-formula><mml:math id="inf213"><mml:mi>H</mml:mi></mml:math></inline-formula> which encodes an approximation to the value function mapping belief vectors to expected discounted rewards for each of the possible actions. The decision at each step is then obtained from (<xref ref-type="disp-formula" rid="equ12">Equation M7</xref>).</p></sec><sec id="s4-5"><title>Parameters for POMDP used in main text</title><p>The main figures represent results using: discount factor <inline-formula><mml:math id="inf214"><mml:mrow><mml:mi>γ</mml:mi><mml:mo>=</mml:mo><mml:mn>0.99</mml:mn></mml:mrow></mml:math></inline-formula>, number of training episodes <inline-formula><mml:math id="inf215"><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>320</mml:mn></mml:mrow></mml:math></inline-formula>, number of belief points sampled per training episode <inline-formula><mml:math id="inf216"><mml:mrow><mml:msup><mml:mi>i</mml:mi><mml:mo>′</mml:mo></mml:msup><mml:mo>=</mml:mo><mml:mn>100</mml:mn></mml:mrow></mml:math></inline-formula>, likelihood in the air and at the ground is defined as shown in <xref ref-type="fig" rid="fig2s1">Figure 2—figure supplement 1</xref>, in <xref ref-type="fig" rid="fig6">Figure 6</xref> likelihood in the air is defined as a rectangle with dimensions <inline-formula><mml:math id="inf217"><mml:mrow><mml:msub><mml:mi>x</mml:mi><mml:mtext>thr</mml:mtext></mml:msub><mml:mo>×</mml:mo><mml:msub><mml:mi>y</mml:mi><mml:mtext>thr</mml:mtext></mml:msub></mml:mrow></mml:math></inline-formula>. Results in <xref ref-type="fig" rid="fig4">Figure 4</xref> are tested and averaged over three different starting positions (<italic>x</italic>=8; <italic>y</italic>=0, 0.3, –0.5), 8 different seeds, 50 different realizations for the same seed (trajectories differ for the history of detections according to the Poissonian model).</p><p>The effect of varying <italic>γ</italic> are represented in <xref ref-type="fig" rid="fig4s1">Figure 4—figure supplement 1</xref>. (all other parameters are kept constant); the effect of varying the number of training episodes is represented in <xref ref-type="fig" rid="fig3s1">Figure 3—figure supplement 1</xref> (averaged over three different locations and three seeds): few tens of training episodes are enough to successfully locate the target, to obtain a robust strategy and to avoid the poor performance showed in the first two violin plots of <xref ref-type="fig" rid="fig3s1">Figure 3—figure supplement 1B</xref>, it is necessary to increase the number of training episodes. <xref ref-type="fig" rid="fig3s1">Figure 3—figure supplement 1C</xref> shows the cost of increasing the number of episodes in terms of memory (i.e. the number of <italic>α</italic> vectors the agent has to store during the training phase).</p><p>Training requires up to 2 days in time on one processor, while testing a single realization takes <inline-formula><mml:math id="inf218"><mml:mrow><mml:mi/><mml:mo>∼</mml:mo><mml:mn>10</mml:mn></mml:mrow></mml:math></inline-formula> hr.</p></sec><sec id="s4-6"><title>Derivation of (<xref ref-type="disp-formula" rid="equ2">Equation 2</xref>)</title><p>We consider a scenario where a target is located at one of <inline-formula><mml:math id="inf219"><mml:mi>N</mml:mi></mml:math></inline-formula> possible patches, <inline-formula><mml:math id="inf220"><mml:mrow><mml:mi>n</mml:mi><mml:mo>=</mml:mo><mml:mrow><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mn>2</mml:mn><mml:mo>,</mml:mo><mml:mi mathvariant="normal">…</mml:mi><mml:mo>,</mml:mo><mml:mi>N</mml:mi></mml:mrow></mml:mrow></mml:math></inline-formula> with probabilities <inline-formula><mml:math id="inf221"><mml:mrow><mml:msub><mml:mi mathvariant="bold">p</mml:mi><mml:mn>0</mml:mn></mml:msub><mml:mo>=</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>p</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>p</mml:mi><mml:mn>2</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:mi mathvariant="normal">…</mml:mi><mml:mo>,</mml:mo><mml:msub><mml:mi>p</mml:mi><mml:mi>N</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mrow><mml:msub><mml:mo largeop="true" symmetric="true">∑</mml:mo><mml:mi>n</mml:mi></mml:msub><mml:msub><mml:mi>p</mml:mi><mml:mi>n</mml:mi></mml:msub></mml:mrow><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:math></inline-formula>. Note that <inline-formula><mml:math id="inf222"><mml:mrow><mml:msub><mml:mi>p</mml:mi><mml:mi>n</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mrow><mml:mn>1</mml:mn><mml:mo>/</mml:mo><mml:mi>N</mml:mi></mml:mrow></mml:mrow></mml:math></inline-formula> for all <inline-formula><mml:math id="inf223"><mml:mi>n</mml:mi></mml:math></inline-formula> for the prior considered in the main text. The agent starts at <inline-formula><mml:math id="inf224"><mml:mrow><mml:mi>n</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:math></inline-formula> and moves sequentially from <inline-formula><mml:math id="inf225"><mml:mrow><mml:mi>n</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:math></inline-formula> to <inline-formula><mml:math id="inf226"><mml:mrow><mml:mi>n</mml:mi><mml:mo>=</mml:mo><mml:mi>N</mml:mi></mml:mrow></mml:math></inline-formula> while spending time <italic>t</italic><sub><italic>n</italic></sub> sampling in each patch. Moving from a patch to the next one takes time <inline-formula><mml:math id="inf227"><mml:mrow><mml:mi>τ</mml:mi><mml:mo>≡</mml:mo><mml:mrow><mml:msub><mml:mi>x</mml:mi><mml:mtext>thr</mml:mtext></mml:msub><mml:mo>/</mml:mo><mml:mi>v</mml:mi></mml:mrow></mml:mrow></mml:math></inline-formula>. At <inline-formula><mml:math id="inf228"><mml:mrow><mml:mi>n</mml:mi><mml:mo>=</mml:mo><mml:mi>N</mml:mi></mml:mrow></mml:math></inline-formula>, the agent samples indefinitely, <inline-formula><mml:math id="inf229"><mml:mrow><mml:msub><mml:mi>t</mml:mi><mml:mi>N</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mi mathvariant="normal">∞</mml:mi></mml:mrow></mml:math></inline-formula>. The agent receives reward of one when the target is found in a patch, which is discounted at rate <italic>λ</italic>. The value <inline-formula><mml:math id="inf230"><mml:mrow><mml:msub><mml:mi>V</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>≡</mml:mo><mml:msub><mml:mrow><mml:mo stretchy="false">⟨</mml:mo><mml:msup><mml:mi>e</mml:mi><mml:mrow><mml:mo>-</mml:mo><mml:mrow><mml:mi>λ</mml:mi><mml:mo>⁢</mml:mo><mml:mi>T</mml:mi></mml:mrow></mml:mrow></mml:msup><mml:mo stretchy="false">⟩</mml:mo></mml:mrow><mml:mi>T</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula>, where <inline-formula><mml:math id="inf231"><mml:mi>T</mml:mi></mml:math></inline-formula> is the search time, is the expected discounted reward optimized w.r.t. <italic>t</italic><sub><italic>n</italic></sub>’s. We derive two sets of recursive equations (with and without Bayesian updates) to calculate <italic>V</italic><sub>1</sub>. We show that both formulations lead to the same optimal casting times, however, the set of equations without Bayesian updates are much simpler to compute.</p><p>Suppose the cumulative probability of finding the target in time <inline-formula><mml:math id="inf232"><mml:mi>t</mml:mi></mml:math></inline-formula><italic>conditional</italic> on the target being in that patch is <inline-formula><mml:math id="inf233"><mml:mrow><mml:mi>d</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula>. Note that <inline-formula><mml:math id="inf234"><mml:mrow><mml:mrow><mml:mi>c</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mo>≡</mml:mo><mml:mrow><mml:mn>1</mml:mn><mml:mo>-</mml:mo><mml:mrow><mml:mi>d</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:mrow></mml:math></inline-formula> is used in the main text. Denote <inline-formula><mml:math id="inf235"><mml:mrow><mml:mrow><mml:mi>r</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mo>≡</mml:mo><mml:mrow><mml:msubsup><mml:mo largeop="true" symmetric="true">∫</mml:mo><mml:mn>0</mml:mn><mml:mi>t</mml:mi></mml:msubsup><mml:mrow><mml:msup><mml:mi>d</mml:mi><mml:mo>′</mml:mo></mml:msup><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>s</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>⁢</mml:mo><mml:msup><mml:mi>e</mml:mi><mml:mrow><mml:mo>-</mml:mo><mml:mrow><mml:mi>λ</mml:mi><mml:mo>⁢</mml:mo><mml:mi>s</mml:mi></mml:mrow></mml:mrow></mml:msup><mml:mo>⁢</mml:mo><mml:mrow><mml:mo rspace="0pt">d</mml:mo><mml:mi>s</mml:mi></mml:mrow></mml:mrow></mml:mrow></mml:mrow></mml:math></inline-formula>. This is the expected discounted reward if the agent searches for time <inline-formula><mml:math id="inf236"><mml:mi>t</mml:mi></mml:math></inline-formula> in a patch that contains the target.</p><p>Say <inline-formula><mml:math id="inf237"><mml:mrow><mml:mi>N</mml:mi><mml:mo>=</mml:mo><mml:mn>3</mml:mn></mml:mrow></mml:math></inline-formula>. Since <italic>V</italic><sub>1</sub> is the expected discounted reward optimized over the casting times <inline-formula><mml:math id="inf238"><mml:mrow><mml:msub><mml:mi>t</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mn>2</mml:mn></mml:msub></mml:mrow></mml:math></inline-formula>, we have<disp-formula id="equ19">.<label>(M14)</label><mml:math id="m19"><mml:mrow><mml:mtable columnalign="right left" rowspacing="4pt" columnspacing="1em"><mml:mtr><mml:mtd><mml:msub><mml:mi>V</mml:mi><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mtd><mml:mtd><mml:mo>=</mml:mo><mml:munder><mml:mo movablelimits="true" form="prefix">max</mml:mo><mml:mrow><mml:msub><mml:mi>t</mml:mi><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:munder><mml:mrow><mml:mo>{</mml:mo><mml:mrow><mml:msub><mml:mi>p</mml:mi><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mi>r</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:mo>+</mml:mo><mml:msup><mml:mi>e</mml:mi><mml:mrow><mml:mo>−</mml:mo><mml:mi>λ</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:mi>τ</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup><mml:msub><mml:mi>p</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:mi>r</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:mo>+</mml:mo><mml:msup><mml:mi>e</mml:mi><mml:mrow><mml:mo>−</mml:mo><mml:mi>λ</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:mn>2</mml:mn><mml:mi>τ</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup><mml:msub><mml:mi>p</mml:mi><mml:mrow><mml:mn>3</mml:mn></mml:mrow></mml:msub><mml:mi>r</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi mathvariant="normal">∞</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>}</mml:mo></mml:mrow></mml:mtd></mml:mtr><mml:mtr><mml:mtd/><mml:mtd><mml:mo>=</mml:mo><mml:munder><mml:mo movablelimits="true" form="prefix">max</mml:mo><mml:mrow><mml:msub><mml:mi>t</mml:mi><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:munder><mml:mrow><mml:mo>{</mml:mo><mml:mrow><mml:msub><mml:mi>p</mml:mi><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mi>r</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:mo>+</mml:mo><mml:msup><mml:mi>e</mml:mi><mml:mrow><mml:mo>−</mml:mo><mml:mi>λ</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:mi>τ</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>p</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:mi>r</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:mo>+</mml:mo><mml:msup><mml:mi>e</mml:mi><mml:mrow><mml:mo>−</mml:mo><mml:mi>λ</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:mi>τ</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>p</mml:mi><mml:mrow><mml:mn>3</mml:mn></mml:mrow></mml:msub><mml:mi>r</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi mathvariant="normal">∞</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>}</mml:mo></mml:mrow></mml:mtd></mml:mtr><mml:mtr><mml:mtd/><mml:mtd><mml:mo>=</mml:mo><mml:munder><mml:mo movablelimits="true" form="prefix">max</mml:mo><mml:mrow><mml:msub><mml:mi>t</mml:mi><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:munder><mml:mrow><mml:mo maxsize="1.2em" minsize="1.2em">{</mml:mo></mml:mrow><mml:msub><mml:mi>p</mml:mi><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mi>r</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:mo>+</mml:mo><mml:msup><mml:mi>e</mml:mi><mml:mrow><mml:mo>−</mml:mo><mml:mi>λ</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:mi>τ</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup></mml:mtd></mml:mtr><mml:mtr><mml:mtd/><mml:mtd><mml:mspace width="56.905512pt"/><mml:mo>×</mml:mo><mml:munder><mml:mo movablelimits="true" form="prefix">max</mml:mo><mml:mrow><mml:msub><mml:mi>t</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:munder><mml:mrow><mml:mo>{</mml:mo><mml:mrow><mml:msub><mml:mi>p</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:mi>r</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:mo>+</mml:mo><mml:msup><mml:mi>e</mml:mi><mml:mrow><mml:mo>−</mml:mo><mml:mi>λ</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:mi>τ</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>p</mml:mi><mml:mrow><mml:mn>3</mml:mn></mml:mrow></mml:msub><mml:mi>r</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi mathvariant="normal">∞</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>}</mml:mo></mml:mrow><mml:mrow><mml:mo maxsize="1.2em" minsize="1.2em">}</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:math></disp-formula></p><p>The last equation above motivates a recursive equation for general <inline-formula><mml:math id="inf239"><mml:mi>N</mml:mi></mml:math></inline-formula>:<disp-formula id="equ20"><label>(M15)</label><mml:math id="m20"><mml:mrow><mml:msub><mml:mi>V</mml:mi><mml:mrow><mml:mi>n</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:munder><mml:mo movablelimits="true" form="prefix">max</mml:mo><mml:mrow><mml:msub><mml:mi>t</mml:mi><mml:mrow><mml:mi>n</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:munder><mml:mrow><mml:mo>{</mml:mo><mml:mrow><mml:msub><mml:mi>p</mml:mi><mml:mrow><mml:mi>n</mml:mi></mml:mrow></mml:msub><mml:mi>r</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mrow><mml:mi>n</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:mo>+</mml:mo><mml:msup><mml:mi>e</mml:mi><mml:mrow><mml:mo>−</mml:mo><mml:mi>λ</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mrow><mml:mi>n</mml:mi></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:mi>τ</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup><mml:msub><mml:mi>V</mml:mi><mml:mrow><mml:mi>n</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mrow><mml:mo>}</mml:mo></mml:mrow><mml:mo>,</mml:mo></mml:mrow></mml:math></disp-formula></p><p>with boundary condition, <inline-formula><mml:math id="inf240"><mml:mrow><mml:msub><mml:mi>V</mml:mi><mml:mi>N</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mrow><mml:msub><mml:mi>p</mml:mi><mml:mi>N</mml:mi></mml:msub><mml:mo>⁢</mml:mo><mml:mi>r</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi mathvariant="normal">∞</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:math></inline-formula>. Optimizing over <italic>t</italic><sub><italic>n</italic></sub>, we obtain the marginal value condition<disp-formula id="equ21"> <label>(M16)</label><mml:math id="m21"><mml:mrow><mml:msub><mml:mi>p</mml:mi><mml:mrow><mml:mi>n</mml:mi></mml:mrow></mml:msub><mml:msup><mml:mi>r</mml:mi><mml:mrow><mml:mi mathvariant="normal">′</mml:mi></mml:mrow></mml:msup><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mrow><mml:mi>n</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mi>λ</mml:mi><mml:msup><mml:mi>e</mml:mi><mml:mrow><mml:mo>−</mml:mo><mml:mi>λ</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mrow><mml:mi>n</mml:mi></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:mi>τ</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup><mml:msub><mml:mi>V</mml:mi><mml:mrow><mml:mi>n</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>.</mml:mo></mml:mrow></mml:math></disp-formula></p><p>If the rate of detection during casting is a constant <italic>κ</italic>, we have <inline-formula><mml:math id="inf241"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>d</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:msup><mml:mi>e</mml:mi><mml:mrow><mml:mo>−</mml:mo><mml:mi>κ</mml:mi><mml:mi>t</mml:mi></mml:mrow></mml:msup><mml:mo>,</mml:mo><mml:mi>r</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mi>κ</mml:mi><mml:msubsup><mml:mo>∫</mml:mo><mml:mrow><mml:mn>0</mml:mn></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msubsup><mml:msup><mml:mi>e</mml:mi><mml:mrow><mml:mo>−</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mi>κ</mml:mi><mml:mo>+</mml:mo><mml:mi>λ</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mi>s</mml:mi></mml:mrow></mml:msup><mml:mi>d</mml:mi><mml:mi>s</mml:mi><mml:mo>=</mml:mo><mml:mfrac><mml:mi>κ</mml:mi><mml:mrow><mml:mi>κ</mml:mi><mml:mo>+</mml:mo><mml:mi>λ</mml:mi></mml:mrow></mml:mfrac><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:msup><mml:mi>e</mml:mi><mml:mrow><mml:mo>−</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mi>λ</mml:mi><mml:mo>+</mml:mo><mml:mi>κ</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:msup></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mstyle></mml:math></inline-formula> and <inline-formula><mml:math id="inf242"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msup><mml:mi>r</mml:mi><mml:mrow><mml:mi mathvariant="normal">′</mml:mi></mml:mrow></mml:msup><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mi>κ</mml:mi><mml:msup><mml:mi>e</mml:mi><mml:mrow><mml:mo>−</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mi>κ</mml:mi><mml:mo>+</mml:mo><mml:mi>λ</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:msup></mml:mrow></mml:mstyle></mml:math></inline-formula>. Plugging this expression into (<xref ref-type="disp-formula" rid="equ21">Equation M16</xref>), we get<disp-formula id="equ22"><label>(M17)</label><mml:math id="m22"><mml:mrow><mml:msub><mml:mi>t</mml:mi><mml:mrow><mml:mi>n</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:msup><mml:mi>κ</mml:mi><mml:mrow><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msup><mml:mi>log</mml:mi><mml:mo>⁡</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mfrac><mml:mrow><mml:msub><mml:mi>p</mml:mi><mml:mrow><mml:mi>n</mml:mi></mml:mrow></mml:msub><mml:mi>κ</mml:mi><mml:msup><mml:mi>e</mml:mi><mml:mrow><mml:mi>λ</mml:mi><mml:mi>τ</mml:mi></mml:mrow></mml:msup></mml:mrow><mml:mrow><mml:mi>λ</mml:mi><mml:msub><mml:mi>V</mml:mi><mml:mrow><mml:mi>n</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:mfrac><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></disp-formula></p><p>Now, let’s calculate <italic>V</italic><sub>1</sub> using Bayesian updates and show that the optimal times exactly correspond to what we have in the previous equation. Denote <inline-formula><mml:math id="inf243"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mrow><mml:mover><mml:mi>V</mml:mi><mml:mo stretchy="false">~</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>n</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mi mathvariant="bold">q</mml:mi></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mstyle></mml:math></inline-formula> as the value at patch <inline-formula><mml:math id="inf244"><mml:mi>n</mml:mi></mml:math></inline-formula> for an arbitrary probability vector <inline-formula><mml:math id="inf245"><mml:mrow><mml:mi mathvariant="bold">q</mml:mi><mml:mo>=</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>q</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>q</mml:mi><mml:mn>2</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:mi mathvariant="normal">…</mml:mi><mml:mo>,</mml:mo><mml:msub><mml:mi>q</mml:mi><mml:mi>N</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula>. We now show that <inline-formula><mml:math id="inf246"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>V</mml:mi><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:msub><mml:mrow><mml:mover><mml:mi>V</mml:mi><mml:mo stretchy="false">~</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mrow><mml:mi mathvariant="bold">p</mml:mi></mml:mrow><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mstyle></mml:math></inline-formula>, where <inline-formula><mml:math id="inf247"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="bold">p</mml:mi></mml:mrow><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>p</mml:mi><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>p</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:mo>…</mml:mo><mml:mo>,</mml:mo><mml:msub><mml:mi>p</mml:mi><mml:mrow><mml:mi>N</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mstyle></mml:math></inline-formula> is the prior. We have<disp-formula id="equ23"><label>(M18)</label><mml:math id="m23"><mml:mrow><mml:msub><mml:mrow><mml:mover><mml:mi>V</mml:mi><mml:mo stretchy="false">~</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>n</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mi mathvariant="bold">q</mml:mi></mml:mrow><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:munder><mml:mo movablelimits="true" form="prefix">max</mml:mo><mml:mrow><mml:msub><mml:mi>t</mml:mi><mml:mrow><mml:mi>n</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:munder><mml:mrow><mml:mo>{</mml:mo><mml:mrow><mml:msub><mml:mi>q</mml:mi><mml:mrow><mml:mi>n</mml:mi></mml:mrow></mml:msub><mml:mi>r</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mrow><mml:mi>n</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:mo>+</mml:mo><mml:msup><mml:mi>e</mml:mi><mml:mrow><mml:mo>−</mml:mo><mml:mi>λ</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mrow><mml:mi>n</mml:mi></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:mi>τ</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:msub><mml:mi>q</mml:mi><mml:mrow><mml:mi>n</mml:mi></mml:mrow></mml:msub><mml:mi>d</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mrow><mml:mi>n</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:msub><mml:mrow><mml:mover><mml:mi>V</mml:mi><mml:mo stretchy="false">~</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>n</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:msup><mml:mrow><mml:mi mathvariant="bold">q</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">′</mml:mi></mml:mrow></mml:msup><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>}</mml:mo></mml:mrow><mml:mo>,</mml:mo></mml:mrow></mml:math></disp-formula></p><p>where <inline-formula><mml:math id="inf248"><mml:msup><mml:mi mathvariant="bold">q</mml:mi><mml:mo>′</mml:mo></mml:msup></mml:math></inline-formula> is the posterior conditional on no detection. The two terms on the right-hand side correspond to the case when the agent finds the target in the patch before <italic>t</italic><sub><italic>n</italic></sub> (with probability <inline-formula><mml:math id="inf249"><mml:mrow><mml:msub><mml:mi>q</mml:mi><mml:mi>n</mml:mi></mml:msub><mml:mo>⁢</mml:mo><mml:mi>d</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mi>n</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula>) and does not find it (with probability <inline-formula><mml:math id="inf250"><mml:mrow><mml:mn>1</mml:mn><mml:mo>-</mml:mo><mml:mrow><mml:msub><mml:mi>q</mml:mi><mml:mi>n</mml:mi></mml:msub><mml:mo>⁢</mml:mo><mml:mi>d</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mi>n</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:math></inline-formula>), respectively. Given the observation that the target is not found in patch <inline-formula><mml:math id="inf251"><mml:mi>n</mml:mi></mml:math></inline-formula>, the posterior probabilities, <inline-formula><mml:math id="inf252"><mml:msup><mml:mi mathvariant="bold">q</mml:mi><mml:mo>′</mml:mo></mml:msup></mml:math></inline-formula>, are obtained using Bayes’ rule:<disp-formula id="equ24"><label>(M19)</label><mml:math id="m24"><mml:mrow><mml:mtable columnalign="right left" rowspacing="4pt" columnspacing="1em"><mml:mtr><mml:mtd><mml:msubsup><mml:mi>q</mml:mi><mml:mrow><mml:mi>m</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">′</mml:mi></mml:mrow></mml:msubsup></mml:mtd><mml:mtd><mml:mo>=</mml:mo><mml:mfrac><mml:msub><mml:mi>q</mml:mi><mml:mrow><mml:mi>m</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:msub><mml:mi>q</mml:mi><mml:mrow><mml:mi>n</mml:mi></mml:mrow></mml:msub><mml:mi>d</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mrow><mml:mi>n</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mfrac><mml:mo>,</mml:mo><mml:mspace width="1em"/><mml:mtext>for </mml:mtext><mml:mi>m</mml:mi><mml:mo>≠</mml:mo><mml:mi>n</mml:mi><mml:mo>,</mml:mo></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:msubsup><mml:mi>q</mml:mi><mml:mrow><mml:mi>n</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">′</mml:mi></mml:mrow></mml:msubsup></mml:mtd><mml:mtd><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:msub><mml:mi>q</mml:mi><mml:mrow><mml:mi>n</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:mi>d</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mrow><mml:mi>n</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mrow><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:msub><mml:mi>q</mml:mi><mml:mrow><mml:mi>n</mml:mi></mml:mrow></mml:msub><mml:mi>d</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mrow><mml:mi>n</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mfrac><mml:mo>.</mml:mo></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:math></disp-formula></p><p>We show that <inline-formula><mml:math id="inf253"><mml:mrow><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi>V</mml:mi><mml:mo stretchy="false">~</mml:mo></mml:mover><mml:mn>1</mml:mn></mml:msub><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi mathvariant="bold">p</mml:mi><mml:mn>0</mml:mn></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mo>=</mml:mo><mml:msub><mml:mi>V</mml:mi><mml:mn>1</mml:mn></mml:msub></mml:mrow></mml:math></inline-formula> for <inline-formula><mml:math id="inf254"><mml:mrow><mml:mi>N</mml:mi><mml:mo>=</mml:mo><mml:mn>3</mml:mn></mml:mrow></mml:math></inline-formula>. The general case of starting from any patch, prior and number of patches (<inline-formula><mml:math id="inf255"><mml:mi>N</mml:mi></mml:math></inline-formula>) follows. Expanding (<xref ref-type="disp-formula" rid="equ23">Equation M18</xref>) starting from <inline-formula><mml:math id="inf256"><mml:mrow><mml:mi>n</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:math></inline-formula>,<disp-formula id="equ25"><label>(M20)</label><mml:math id="m25"><mml:mrow><mml:mtable columnalign="center center" rowspacing="4pt" columnspacing="1em"><mml:mtr><mml:mtd><mml:msub><mml:mrow><mml:mover><mml:mi>V</mml:mi><mml:mo stretchy="false">~</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mrow><mml:mi mathvariant="bold">p</mml:mi></mml:mrow><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mtd><mml:mtd><mml:mo>=</mml:mo><mml:munder><mml:mo movablelimits="true" form="prefix">max</mml:mo><mml:mrow><mml:msub><mml:mi>t</mml:mi><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:munder><mml:mrow><mml:mo maxsize="1.2em" minsize="1.2em">{</mml:mo></mml:mrow><mml:msub><mml:mi>p</mml:mi><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mi>r</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:mo>+</mml:mo><mml:msup><mml:mi>e</mml:mi><mml:mrow><mml:mo>−</mml:mo><mml:mi>λ</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:mi>τ</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup><mml:mo stretchy="false">(</mml:mo><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:msub><mml:mi>p</mml:mi><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mi>d</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:mo stretchy="false">)</mml:mo></mml:mtd></mml:mtr><mml:mtr><mml:mtd/><mml:mtd><mml:mo>×</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msubsup><mml:mi>p</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow><mml:mrow><mml:mi mathvariant="normal">′</mml:mi></mml:mrow></mml:msubsup><mml:mi>r</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:mo>+</mml:mo><mml:msup><mml:mi>e</mml:mi><mml:mrow><mml:mo>−</mml:mo><mml:mi>λ</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:mi>τ</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup><mml:mo stretchy="false">(</mml:mo><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:msubsup><mml:mi>p</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow><mml:mrow><mml:mi mathvariant="normal">′</mml:mi></mml:mrow></mml:msubsup><mml:mi>d</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:mo stretchy="false">)</mml:mo><mml:msubsup><mml:mi>p</mml:mi><mml:mrow><mml:mn>3</mml:mn></mml:mrow><mml:mrow><mml:mi mathvariant="normal">′</mml:mi><mml:mi mathvariant="normal">′</mml:mi></mml:mrow></mml:msubsup><mml:mi>r</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi mathvariant="normal">∞</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mrow><mml:mo maxsize="1.2em" minsize="1.2em">}</mml:mo></mml:mrow><mml:mo>,</mml:mo></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:math></disp-formula></p><p>where <inline-formula><mml:math id="inf257"><mml:msubsup><mml:mi>p</mml:mi><mml:mn>2</mml:mn><mml:mo>′</mml:mo></mml:msubsup></mml:math></inline-formula> is obtained from the first Bayesian update and <inline-formula><mml:math id="inf258"><mml:msubsup><mml:mi>p</mml:mi><mml:mn>3</mml:mn><mml:mo>′′</mml:mo></mml:msubsup></mml:math></inline-formula> is obtained after the second Bayesian update. Using (<xref ref-type="disp-formula" rid="equ24">Equation M19</xref>), we have <inline-formula><mml:math id="inf259"><mml:mrow><mml:mrow><mml:msubsup><mml:mi>p</mml:mi><mml:mn>2</mml:mn><mml:mo>′</mml:mo></mml:msubsup><mml:mo>=</mml:mo><mml:mrow><mml:msub><mml:mi>p</mml:mi><mml:mn>2</mml:mn></mml:msub><mml:mo>/</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mn>1</mml:mn><mml:mo>-</mml:mo><mml:mrow><mml:msub><mml:mi>p</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>⁢</mml:mo><mml:mi>d</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:mrow><mml:mo>,</mml:mo><mml:mrow><mml:msubsup><mml:mi>p</mml:mi><mml:mn>3</mml:mn><mml:mo>′</mml:mo></mml:msubsup><mml:mo>=</mml:mo><mml:mrow><mml:msub><mml:mi>p</mml:mi><mml:mn>3</mml:mn></mml:msub><mml:mo>/</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mn>1</mml:mn><mml:mo>-</mml:mo><mml:mrow><mml:msub><mml:mi>p</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>⁢</mml:mo><mml:mi>d</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:mrow></mml:math></inline-formula> and <inline-formula><mml:math id="inf260"><mml:mrow><mml:msubsup><mml:mi>p</mml:mi><mml:mn>3</mml:mn><mml:mo>′′</mml:mo></mml:msubsup><mml:mo>=</mml:mo><mml:mrow><mml:msubsup><mml:mi>p</mml:mi><mml:mn>3</mml:mn><mml:mo>′</mml:mo></mml:msubsup><mml:mo>/</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mn>1</mml:mn><mml:mo>-</mml:mo><mml:mrow><mml:msubsup><mml:mi>p</mml:mi><mml:mn>2</mml:mn><mml:mo>′</mml:mo></mml:msubsup><mml:mo>⁢</mml:mo><mml:mi>d</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mn>2</mml:mn></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mo>=</mml:mo><mml:mrow><mml:msub><mml:mi>p</mml:mi><mml:mn>3</mml:mn></mml:msub><mml:mo>/</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mn>1</mml:mn><mml:mo>-</mml:mo><mml:mrow><mml:msub><mml:mi>p</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>⁢</mml:mo><mml:mi>d</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mo>-</mml:mo><mml:mrow><mml:msub><mml:mi>p</mml:mi><mml:mn>2</mml:mn></mml:msub><mml:mo>⁢</mml:mo><mml:mi>d</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mn>2</mml:mn></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:math></inline-formula>.</p><p>Since <inline-formula><mml:math id="inf261"><mml:mrow><mml:mrow><mml:msubsup><mml:mi>p</mml:mi><mml:mn>3</mml:mn><mml:mo>′′</mml:mo></mml:msubsup><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mn>1</mml:mn><mml:mo>-</mml:mo><mml:mrow><mml:msubsup><mml:mi>p</mml:mi><mml:mn>2</mml:mn><mml:mo>′</mml:mo></mml:msubsup><mml:mo>⁢</mml:mo><mml:mi>d</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mn>2</mml:mn></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mo>=</mml:mo><mml:msubsup><mml:mi>p</mml:mi><mml:mn>3</mml:mn><mml:mo>′</mml:mo></mml:msubsup></mml:mrow></mml:math></inline-formula>, simplifying (<xref ref-type="disp-formula" rid="equ25">Equation M20</xref>), we get<disp-formula id="equ26"><label>(M21)</label><mml:math id="m26"><mml:mrow><mml:mtable columnalign="right left" rowspacing="4pt" columnspacing="1em"><mml:mtr><mml:mtd><mml:msub><mml:mrow><mml:mover><mml:mi>V</mml:mi><mml:mo stretchy="false">~</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mi mathvariant="bold">p</mml:mi></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mtd><mml:mtd><mml:mo>=</mml:mo><mml:munder><mml:mo movablelimits="true" form="prefix">max</mml:mo><mml:mrow><mml:msub><mml:mi>t</mml:mi><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:munder><mml:mrow><mml:mo maxsize="1.2em" minsize="1.2em">{</mml:mo></mml:mrow><mml:msub><mml:mi>p</mml:mi><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mi>r</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:mo>+</mml:mo><mml:msup><mml:mi>e</mml:mi><mml:mrow><mml:mo>−</mml:mo><mml:mi>λ</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:mi>τ</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup><mml:mo stretchy="false">(</mml:mo><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:msub><mml:mi>p</mml:mi><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mi>d</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:mo stretchy="false">)</mml:mo></mml:mtd></mml:mtr><mml:mtr><mml:mtd/><mml:mtd><mml:mspace width="56.905512pt"/><mml:mo>×</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msubsup><mml:mi>p</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow><mml:mrow><mml:mi mathvariant="normal">′</mml:mi></mml:mrow></mml:msubsup><mml:mi>r</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:mo>+</mml:mo><mml:msup><mml:mi>e</mml:mi><mml:mrow><mml:mo>−</mml:mo><mml:mi>λ</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:mi>τ</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup><mml:msubsup><mml:mi>p</mml:mi><mml:mrow><mml:mn>3</mml:mn></mml:mrow><mml:mrow><mml:mi mathvariant="normal">′</mml:mi></mml:mrow></mml:msubsup><mml:mi>r</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi mathvariant="normal">∞</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mrow><mml:mo maxsize="1.2em" minsize="1.2em">}</mml:mo></mml:mrow><mml:mo>,</mml:mo></mml:mtd></mml:mtr><mml:mtr><mml:mtd/><mml:mtd><mml:mo>=</mml:mo><mml:munder><mml:mo movablelimits="true" form="prefix">max</mml:mo><mml:mrow><mml:msub><mml:mi>t</mml:mi><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:munder><mml:mrow><mml:mo>{</mml:mo><mml:mrow><mml:msub><mml:mi>p</mml:mi><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mi>r</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:mo>+</mml:mo><mml:msup><mml:mi>e</mml:mi><mml:mrow><mml:mo>−</mml:mo><mml:mi>λ</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:mi>τ</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>p</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:mi>r</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:mo>+</mml:mo><mml:msup><mml:mi>e</mml:mi><mml:mrow><mml:mo>−</mml:mo><mml:mi>λ</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:mi>τ</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup><mml:msub><mml:mi>p</mml:mi><mml:mrow><mml:mn>3</mml:mn></mml:mrow></mml:msub><mml:mi>r</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi mathvariant="normal">∞</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>}</mml:mo></mml:mrow><mml:mo>,</mml:mo></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:math></disp-formula></p><p>where <inline-formula><mml:math id="inf262"><mml:mrow><mml:mrow><mml:msubsup><mml:mi>p</mml:mi><mml:mn>2</mml:mn><mml:mo>′</mml:mo></mml:msubsup><mml:mo>=</mml:mo><mml:mrow><mml:msub><mml:mi>p</mml:mi><mml:mn>2</mml:mn></mml:msub><mml:mo>/</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mn>1</mml:mn><mml:mo>-</mml:mo><mml:mrow><mml:msub><mml:mi>p</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>⁢</mml:mo><mml:mi>d</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:mrow><mml:mo>,</mml:mo><mml:mrow><mml:msubsup><mml:mi>p</mml:mi><mml:mn>3</mml:mn><mml:mo>′</mml:mo></mml:msubsup><mml:mo>=</mml:mo><mml:mrow><mml:msub><mml:mi>p</mml:mi><mml:mn>3</mml:mn></mml:msub><mml:mo>/</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mn>1</mml:mn><mml:mo>-</mml:mo><mml:mrow><mml:msub><mml:mi>p</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>⁢</mml:mo><mml:mi>d</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:mrow></mml:math></inline-formula> are used in the second step. This equation exactly corresponds to (<xref ref-type="disp-formula" rid="equ19">Equation M14</xref>). The upshot is that the normalization factors from the Bayesian updates go through the parenthesis and cancel out. However, optimizing for <italic>t</italic><sub><italic>n</italic></sub> directly using (<xref ref-type="disp-formula" rid="equ23">Equation M18</xref>) is difficult due to the dependence of <inline-formula><mml:math id="inf263"><mml:msup><mml:mi mathvariant="bold">q</mml:mi><mml:mo>′</mml:mo></mml:msup></mml:math></inline-formula> on <italic>t</italic><sub><italic>n</italic></sub>.</p></sec></sec></body><back><sec sec-type="additional-information" id="s5"><title>Additional information</title><fn-group content-type="competing-interest"><title>Competing interests</title><fn fn-type="COI-statement" id="conf1"><p>No competing interests declared</p></fn><fn fn-type="COI-statement" id="conf2"><p>Reviewing editor, <italic>eLife</italic></p></fn><fn fn-type="COI-statement" id="conf3"><p>No competing interests declared</p></fn></fn-group><fn-group content-type="author-contribution"><title>Author contributions</title><fn fn-type="con" id="con1"><p>Conceptualization, Investigation, Methodology, Writing – original draft, Writing – review and editing</p></fn><fn fn-type="con" id="con2"><p>Conceptualization, Investigation, Methodology, Writing – original draft, Writing – review and editing</p></fn><fn fn-type="con" id="con3"><p>Conceptualization, Investigation, Methodology, Writing – original draft, Writing – review and editing</p></fn><fn fn-type="con" id="con4"><p>Conceptualization, Investigation, Methodology, Writing – original draft, Writing – review and editing</p></fn></fn-group></sec><sec sec-type="supplementary-material" id="s6"><title>Additional files</title><supplementary-material id="transrepform"><label>Transparent reporting form</label><media xlink:href="elife-76989-transrepform1-v2.docx" mimetype="application" mime-subtype="docx"/></supplementary-material><supplementary-material id="supp1"><label>Supplementary file 1.</label><caption><title>Data and scripts to generate <xref ref-type="fig" rid="fig3">Figures 3</xref>—<xref ref-type="fig" rid="fig6">6</xref>.</title></caption><media xlink:href="elife-76989-supp1-v2.zip" mimetype="application" mime-subtype="zip"/></supplementary-material></sec><sec sec-type="data-availability" id="s7"><title>Data availability</title><p>All data generated or analyzed during this study are included in the manuscript and supporting file. The dataset with the simulation results has been made public at <ext-link ext-link-type="uri" xlink:href="https://zenodo.org/record/6538177#.Yqrl_5BByJE">https://zenodo.org/record/6538177#.Yqrl_5BByJE</ext-link>.</p><p>The following dataset was generated:</p><p><element-citation publication-type="data" specific-use="isSupplementedBy" id="dataset1"><person-group person-group-type="author"><name><surname>Rigolli</surname><given-names>N</given-names></name><name><surname>Reddy</surname><given-names>G</given-names></name><name><surname>Seminara</surname><given-names>A</given-names></name><name><surname>Vergassola</surname><given-names>M</given-names></name></person-group><year iso-8601-date="2022">2022</year><data-title>Alternation emerges as a multi-modal strategy for turbulent odor navigation - Dataset</data-title><source>Zenodo</source><pub-id pub-id-type="doi">10.5281/zenodo.6538177</pub-id></element-citation></p></sec><ack id="ack"><title>Acknowledgements</title><p>GR was partially supported by the NSF-Simons Center for Mathematical &amp; Statistical Analysis of Biology at Harvard (award number #1764269) and the Harvard Quantitative Biology Initiative. This work received support from: the European Research Council (ERC) under the European Union’s Horizon 2020 research and innovation programme (grant agreement No. 101002724 RIDING); the Air Force Office of Scientific Research under award number FA8655-20-1-7028; the National Institutes of Health (NIH) under award number R01DC018789. The authors are grateful to the OPAL infrastructure from Université Côte d’Azur and the Université Côte d’Azur’s Center for High-Performance Computing for providing resources and support. NR is thankful for the support of Instituto Nazionale di Fisica Nucleare (INFN) Scientific Initiative SFT. This research was initiated at the Kavli Institute for Theoretical Physics supported in part by NSF Grant No. PHY-1748958 and the Gordon and Betty Moore Foundation Grant No. 2919.02.</p></ack><ref-list><title>References</title><ref id="bib1"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Anderson</surname><given-names>JJ</given-names></name></person-group><year iso-8601-date="2005">2005</year><article-title>Ludwig prandtl’s boundary layer</article-title><source>Physics Today</source><volume>58</volume><elocation-id>42</elocation-id><pub-id pub-id-type="doi">10.1063/1.2169443</pub-id></element-citation></ref><ref id="bib2"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Basil</surname><given-names>J</given-names></name><name><surname>Atema</surname><given-names>J</given-names></name></person-group><year iso-8601-date="2000">2000</year><article-title>Lobster orientation in turbulent odor plumes: simultaneous measurement of tracking behavior and temporal odor patterns</article-title><source>The Biological Bulletin</source><volume>187</volume><fpage>272</fpage><lpage>273</lpage><pub-id pub-id-type="doi">10.1086/BBLv187n2p272</pub-id></element-citation></ref><ref id="bib3"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Bellman</surname><given-names>R</given-names></name></person-group><year iso-8601-date="2003">2003</year><source>Dynamic Programming</source><publisher-name>Dover</publisher-name></element-citation></ref><ref id="bib4"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Celani</surname><given-names>A</given-names></name><name><surname>Villermaux</surname><given-names>E</given-names></name><name><surname>Vergassola</surname><given-names>M</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>Odor landscapes in turbulent environments</article-title><source>Physical Review. X</source><volume>4</volume><elocation-id>041015</elocation-id><pub-id pub-id-type="doi">10.1103/PhysRevX.4.041015</pub-id></element-citation></ref><ref id="bib5"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Charnov</surname><given-names>EL</given-names></name></person-group><year iso-8601-date="1976">1976</year><article-title>Optimal foraging, the marginal value theorem</article-title><source>Theoretical Population Biology</source><volume>9</volume><fpage>129</fpage><lpage>136</lpage><pub-id pub-id-type="doi">10.1016/0040-5809(76)90040-x</pub-id><pub-id pub-id-type="pmid">1273796</pub-id></element-citation></ref><ref id="bib6"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Fackrell</surname><given-names>J</given-names></name><name><surname>Robins</surname><given-names>A</given-names></name></person-group><year iso-8601-date="1982">1982</year><article-title>Concentration fluctuations and fluxes in plumes from point sources in a turbulent boundary layer</article-title><source>Journal of Fluid Mechanics</source><volume>117</volume><elocation-id>1</elocation-id><pub-id pub-id-type="doi">10.1017/S0022112082001499</pub-id></element-citation></ref><ref id="bib7"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Falkovich</surname><given-names>G</given-names></name><name><surname>Gawȩdzki</surname><given-names>K</given-names></name><name><surname>Vergassola</surname><given-names>M</given-names></name></person-group><year iso-8601-date="2001">2001</year><article-title>Particles and fields in fluid turbulence</article-title><source>Reviews of Modern Physics</source><volume>73</volume><fpage>913</fpage><lpage>975</lpage><pub-id pub-id-type="doi">10.1103/RevModPhys.73.913</pub-id></element-citation></ref><ref id="bib8"><element-citation publication-type="software"><person-group person-group-type="author"><name><surname>Fischer</surname><given-names>PF</given-names></name><name><surname>Lottes</surname><given-names>JW</given-names></name><name><surname>Kerkemeier</surname><given-names>JG</given-names></name></person-group><year iso-8601-date="2008">2008</year><data-title>Nek5000 web page</data-title><source>Nek5000</source><ext-link ext-link-type="uri" xlink:href="http://nek5000.mcs.anl.gov">http://nek5000.mcs.anl.gov</ext-link></element-citation></ref><ref id="bib9"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Gire</surname><given-names>DH</given-names></name><name><surname>Kapoor</surname><given-names>V</given-names></name><name><surname>Arrighi-Allisan</surname><given-names>A</given-names></name><name><surname>Seminara</surname><given-names>A</given-names></name><name><surname>Murthy</surname><given-names>VN</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Mice develop efficient strategies for foraging and navigation using complex natural stimuli</article-title><source>Current Biology</source><volume>26</volume><fpage>1261</fpage><lpage>1273</lpage><pub-id pub-id-type="doi">10.1016/j.cub.2016.03.040</pub-id><pub-id pub-id-type="pmid">27112299</pub-id></element-citation></ref><ref id="bib10"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Gorur-Shandilya</surname><given-names>S</given-names></name><name><surname>Martelli</surname><given-names>C</given-names></name><name><surname>Demir</surname><given-names>M</given-names></name><name><surname>Emonet</surname><given-names>T</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>Controlling and measuring dynamic odorant stimuli in the laboratory</article-title><source>The Journal of Experimental Biology</source><volume>222</volume><fpage>222</fpage><lpage>223</lpage><pub-id pub-id-type="doi">10.1242/jeb.207787</pub-id><pub-id pub-id-type="pmid">31672728</pub-id></element-citation></ref><ref id="bib11"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Grasso</surname><given-names>FW</given-names></name></person-group><year iso-8601-date="2001">2001</year><article-title>Invertebrate-inspired sensory-motor systems and autonomous, olfactory-guided exploration</article-title><source>The Biological Bulletin</source><volume>200</volume><fpage>160</fpage><lpage>168</lpage><pub-id pub-id-type="doi">10.2307/1543310</pub-id></element-citation></ref><ref id="bib12"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hepper</surname><given-names>PG</given-names></name><name><surname>Wells</surname><given-names>DL</given-names></name></person-group><year iso-8601-date="2005">2005</year><article-title>How many footsteps do dogs need to determine the direction of an odour trail?</article-title><source>Chemical Senses</source><volume>30</volume><fpage>291</fpage><lpage>298</lpage><pub-id pub-id-type="doi">10.1093/chemse/bji023</pub-id><pub-id pub-id-type="pmid">15741595</pub-id></element-citation></ref><ref id="bib13"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Jinn</surname><given-names>J</given-names></name><name><surname>Connor</surname><given-names>EG</given-names></name><name><surname>Jacobs</surname><given-names>LF</given-names></name></person-group><year iso-8601-date="2020">2020</year><article-title>How ambient environment influences olfactory orientation in search and rescue dogs</article-title><source>Chemical Senses</source><volume>45</volume><fpage>625</fpage><lpage>634</lpage><pub-id pub-id-type="doi">10.1093/chemse/bjaa060</pub-id><pub-id pub-id-type="pmid">32940645</pub-id></element-citation></ref><ref id="bib14"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kaelbling</surname><given-names>LP</given-names></name><name><surname>Littman</surname><given-names>ML</given-names></name><name><surname>Cassandra</surname><given-names>AR</given-names></name></person-group><year iso-8601-date="1998">1998</year><article-title>Planning and acting in partially observable stochastic domains</article-title><source>Artificial Intelligence</source><volume>101</volume><fpage>99</fpage><lpage>134</lpage><pub-id pub-id-type="doi">10.1016/S0004-3702(98)00023-X</pub-id></element-citation></ref><ref id="bib15"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Khan</surname><given-names>AG</given-names></name><name><surname>Sarangi</surname><given-names>M</given-names></name><name><surname>Bhalla</surname><given-names>US</given-names></name></person-group><year iso-8601-date="2012">2012</year><article-title>Rats track odour trails accurately using a multi-layered strategy with near-optimal sampling</article-title><source>Nature Communications</source><volume>3</volume><elocation-id>703</elocation-id><pub-id pub-id-type="doi">10.1038/ncomms1712</pub-id><pub-id pub-id-type="pmid">22426224</pub-id></element-citation></ref><ref id="bib16"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Lever</surname><given-names>C</given-names></name><name><surname>Burton</surname><given-names>S</given-names></name><name><surname>O’Keefe</surname><given-names>J</given-names></name></person-group><year iso-8601-date="2006">2006</year><article-title>Rearing on hind legs, environmental novelty, and the hippocampal formation</article-title><source>Reviews in the Neurosciences</source><volume>17</volume><fpage>111</fpage><lpage>133</lpage><pub-id pub-id-type="doi">10.1515/revneuro.2006.17.1-2.111</pub-id><pub-id pub-id-type="pmid">16703946</pub-id></element-citation></ref><ref id="bib17"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Masson</surname><given-names>JB</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>Olfactory searches with limited space perception</article-title><source>PNAS</source><volume>110</volume><fpage>11261</fpage><lpage>11266</lpage><pub-id pub-id-type="doi">10.1073/pnas.1221091110</pub-id></element-citation></ref><ref id="bib18"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Moore</surname><given-names>PA</given-names></name><name><surname>Scholz</surname><given-names>N</given-names></name><name><surname>Atema</surname><given-names>J</given-names></name></person-group><year iso-8601-date="1991">1991</year><article-title>Chemical orientation of lobsters, <italic>Homarus americanus</italic>, in turbulent odor plumes</article-title><source>Journal of Chemical Ecology</source><volume>17</volume><fpage>1293</fpage><lpage>1307</lpage><pub-id pub-id-type="doi">10.1007/BF00983763</pub-id><pub-id pub-id-type="pmid">24257791</pub-id></element-citation></ref><ref id="bib19"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Murlis</surname><given-names>J</given-names></name><name><surname>Jones</surname><given-names>CD</given-names></name></person-group><year iso-8601-date="1981">1981</year><article-title>Fine-scale structure of odour plumes in relation to insect orientation to distant pheromone and other attractant sources</article-title><source>Physiological Entomology</source><volume>6</volume><fpage>71</fpage><lpage>86</lpage><pub-id pub-id-type="doi">10.1111/j.1365-3032.1981.tb00262.x</pub-id></element-citation></ref><ref id="bib20"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Nironi</surname><given-names>C</given-names></name><name><surname>Salizzoni</surname><given-names>P</given-names></name><name><surname>Marro</surname><given-names>M</given-names></name><name><surname>Mejean</surname><given-names>P</given-names></name><name><surname>Grosjean</surname><given-names>N</given-names></name><name><surname>Soulhac</surname><given-names>L</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>Dispersion of a passive scalar fluctuating plume in a turbulent boundary layer. Part i: Velocity and concentration measurements</article-title><source>Boundary-Layer Meteorology</source><volume>156</volume><fpage>415</fpage><lpage>446</lpage><pub-id pub-id-type="doi">10.1007/s10546-015-0040-x</pub-id></element-citation></ref><ref id="bib21"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Reddy</surname><given-names>G</given-names></name><name><surname>Murthy</surname><given-names>VN</given-names></name><name><surname>Vergassola</surname><given-names>M</given-names></name></person-group><year iso-8601-date="2022">2022</year><article-title>Olfactory sensing and navigation in turbulent environments</article-title><source>Annual Review of Condensed Matter Physics</source><volume>13</volume><fpage>191</fpage><lpage>213</lpage><pub-id pub-id-type="doi">10.1146/annurev-conmatphys-031720-032754</pub-id></element-citation></ref><ref id="bib22"><element-citation publication-type="preprint"><person-group person-group-type="author"><name><surname>Rigolli</surname><given-names>N</given-names></name><name><surname>Magnoli</surname><given-names>N</given-names></name><name><surname>Rosasco</surname><given-names>L</given-names></name><name><surname>Seminara</surname><given-names>A</given-names></name></person-group><year iso-8601-date="2021">2021</year><article-title>Learning to Predict Target Location with Turbulent Odor Plumes</article-title><source>arXiv</source><ext-link ext-link-type="uri" xlink:href="https://arxiv.org/abs/2106.08988">https://arxiv.org/abs/2106.08988</ext-link></element-citation></ref><ref id="bib23"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Russell</surname><given-names>RA</given-names></name></person-group><year iso-8601-date="1999">1999</year><source>Odor Detection by Mobile Robots</source><publisher-loc>Singapore</publisher-loc><publisher-name>Orld Scientific</publisher-name></element-citation></ref><ref id="bib24"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Shani</surname><given-names>G</given-names></name><name><surname>Pineau</surname><given-names>J</given-names></name><name><surname>Kaplow</surname><given-names>R</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>A survey of point-based pomdp solvers</article-title><source>Autonomous Agents and Multi-Agent Systems</source><volume>27</volume><fpage>1</fpage><lpage>51</lpage><pub-id pub-id-type="doi">10.1007/s10458-012-9200-2</pub-id></element-citation></ref><ref id="bib25"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Shraiman</surname><given-names>B</given-names></name><name><surname>Siggia</surname><given-names>E</given-names></name></person-group><year iso-8601-date="2000">2000</year><article-title>Scalar turbulence</article-title><source>Nature</source><volume>405</volume><fpage>639</fpage><lpage>646</lpage><pub-id pub-id-type="doi">10.1038/35015000</pub-id><pub-id pub-id-type="pmid">10864314</pub-id></element-citation></ref><ref id="bib26"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Sondik</surname><given-names>EJ</given-names></name></person-group><year iso-8601-date="1978">1978</year><article-title>The optimal control of partially observable markov processes over the infinite horizon: discounted costs</article-title><source>Operations Research</source><volume>26</volume><fpage>282</fpage><lpage>304</lpage><pub-id pub-id-type="doi">10.1287/opre.26.2.282</pub-id></element-citation></ref><ref id="bib27"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Spaan</surname><given-names>MTJ</given-names></name><name><surname>Vlassis</surname><given-names>N</given-names></name></person-group><year iso-8601-date="2005">2005</year><article-title>Perseus: randomized point-based value iteration for pomdps</article-title><source>Journal of Artificial Intelligence Research</source><volume>24</volume><fpage>195</fpage><lpage>220</lpage><pub-id pub-id-type="doi">10.1613/jair.1659</pub-id></element-citation></ref><ref id="bib28"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Steen</surname><given-names>JB</given-names></name><name><surname>Mohus</surname><given-names>I</given-names></name><name><surname>Kvesetberg</surname><given-names>T</given-names></name><name><surname>Walløe</surname><given-names>L</given-names></name></person-group><year iso-8601-date="1996">1996</year><article-title>Olfaction in bird dogs during hunting</article-title><source>Acta Physiologica Scandinavica</source><volume>157</volume><fpage>115</fpage><lpage>119</lpage><pub-id pub-id-type="doi">10.1046/j.1365-201X.1996.479227000.x</pub-id><pub-id pub-id-type="pmid">8735662</pub-id></element-citation></ref><ref id="bib29"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Sutton</surname><given-names>R</given-names></name><name><surname>Barto</surname><given-names>A</given-names></name></person-group><year iso-8601-date="2018">2018</year><source>Reinforcement Learning: An Introduction</source><publisher-name>MIT Press</publisher-name></element-citation></ref><ref id="bib30"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Thesen</surname><given-names>A</given-names></name><name><surname>Steen</surname><given-names>JB</given-names></name><name><surname>Døving</surname><given-names>KB</given-names></name></person-group><year iso-8601-date="1993">1993</year><article-title>Behaviour of dogs during olfactory tracking</article-title><source>The Journal of Experimental Biology</source><volume>180</volume><fpage>247</fpage><lpage>251</lpage><pub-id pub-id-type="doi">10.1242/jeb.180.1.247</pub-id><pub-id pub-id-type="pmid">8371085</pub-id></element-citation></ref><ref id="bib31"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Vergassola</surname><given-names>M</given-names></name><name><surname>Villermaux</surname><given-names>E</given-names></name><name><surname>Shraiman</surname><given-names>BI</given-names></name></person-group><year iso-8601-date="2007">2007</year><article-title>“Infotaxis” as a strategy for searching without gradients</article-title><source>Nature</source><volume>445</volume><fpage>406</fpage><lpage>409</lpage><pub-id pub-id-type="doi">10.1038/nature05464</pub-id><pub-id pub-id-type="pmid">17251974</pub-id></element-citation></ref><ref id="bib32"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Victor</surname><given-names>JD</given-names></name><name><surname>Boie</surname><given-names>SD</given-names></name><name><surname>Connor</surname><given-names>EG</given-names></name><name><surname>Crimaldi</surname><given-names>JP</given-names></name><name><surname>Ermentrout</surname><given-names>GB</given-names></name><name><surname>Nagel</surname><given-names>KI</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>Olfactory navigation and the receptor nonlinearity</article-title><source>The Journal of Neuroscience</source><volume>39</volume><fpage>3713</fpage><lpage>3727</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.2512-18.2019</pub-id><pub-id pub-id-type="pmid">30846614</pub-id></element-citation></ref><ref id="bib33"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Voges</surname><given-names>N</given-names></name><name><surname>Chaffiol</surname><given-names>A</given-names></name><name><surname>Lucas</surname><given-names>P</given-names></name><name><surname>Martinez</surname><given-names>D</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>Reactive searching and infotaxis in odor source localization</article-title><source>PLOS Computational Biology</source><volume>10</volume><elocation-id>1003861</elocation-id><pub-id pub-id-type="doi">10.1371/journal.pcbi.1003861</pub-id></element-citation></ref><ref id="bib34"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Webb</surname><given-names>B</given-names></name><name><surname>Consilvio</surname><given-names>T</given-names></name></person-group><year iso-8601-date="2001">2001</year><source>Biorobotics</source><publisher-name>MIT Press</publisher-name></element-citation></ref><ref id="bib35"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Webster</surname><given-names>DR</given-names></name><name><surname>Weissburg</surname><given-names>MJ</given-names></name></person-group><year iso-8601-date="2009">2009</year><article-title>The hydrodynamics of chemical cues among aquatic organisms</article-title><source>Annual Review of Fluid Mechanics</source><volume>41</volume><fpage>73</fpage><lpage>90</lpage><pub-id pub-id-type="doi">10.1146/annurev.fluid.010908.165240</pub-id></element-citation></ref><ref id="bib36"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Weissburg</surname><given-names>MJ</given-names></name><name><surname>Zimmer-Faust</surname><given-names>RK</given-names></name></person-group><year iso-8601-date="2002">2002</year><article-title>Odor plumes and how blue crabs use them in finding prey</article-title><source>The Journal of Experimental Biology</source><volume>197</volume><fpage>349</fpage><lpage>375</lpage><pub-id pub-id-type="doi">10.1242/jeb.197.1.349</pub-id><pub-id pub-id-type="pmid">7852909</pub-id></element-citation></ref></ref-list></back><sub-article article-type="editor-report" id="sa0"><front-stub><article-id pub-id-type="doi">10.7554/eLife.76989.sa0</article-id><title-group><article-title>Editor's evaluation</article-title></title-group><contrib-group><contrib contrib-type="author"><name><surname>Sharpee</surname><given-names>Tatyana O</given-names></name><role specific-use="editor">Reviewing Editor</role><aff><institution-wrap><institution-id institution-id-type="ror">https://ror.org/03xez1567</institution-id><institution>Salk Institute for Biological Studies</institution></institution-wrap><country>United States</country></aff></contrib></contrib-group><related-object id="sa0ro1" object-id-type="id" object-id="10.1101/2021.12.14.472675" link-type="continued-by" xlink:href="https://sciety.org/articles/activity/10.1101/2021.12.14.472675"/></front-stub><body><p>This work demonstrates how animals can combine different kinds of sensing actions to improve the accuracy of finding the sources of olfactory signals. Previous work have provided an explanation of the casting and surging behaviors used to find the plume in order to navigate towards the sources. This work adds &quot;alternation&quot; - sniffing in the air far from the ground - that animals can do by rearing on hind legs. The authors show that alternation occurs more frequently far away from the source and that this can be explained by the marginal value theory.</p></body></sub-article><sub-article article-type="decision-letter" id="sa1"><front-stub><article-id pub-id-type="doi">10.7554/eLife.76989.sa1</article-id><title-group><article-title>Decision letter</article-title></title-group><contrib-group content-type="section"><contrib contrib-type="editor"><name><surname>Sharpee</surname><given-names>Tatyana O</given-names></name><role>Reviewing Editor</role><aff><institution-wrap><institution-id institution-id-type="ror">https://ror.org/03xez1567</institution-id><institution>Salk Institute for Biological Studies</institution></institution-wrap><country>United States</country></aff></contrib></contrib-group></front-stub><body><boxed-text id="sa2-box1"><p>Our editorial process produces two outputs: (i) <ext-link ext-link-type="uri" xlink:href="https://sciety.org/articles/activity/10.1101/2021.12.14.472675">public reviews</ext-link> designed to be posted alongside <ext-link ext-link-type="uri" xlink:href="https://www.biorxiv.org/content/10.1101/2021.12.14.472675v1">the preprint</ext-link> for the benefit of readers; (ii) feedback on the manuscript for the authors, including requests for revisions, shown below. We also include an acceptance summary that explains what the editors found interesting or important about the work.</p></boxed-text><p><bold>Decision letter after peer review:</bold></p><p>Thank you for submitting your article &quot;Alternation emerges as a multi-modal strategy for turbulent odor navigation&quot; for consideration by <italic>eLife</italic>. Your article has been reviewed by 2 peer reviewers, one of whom is a member of our Board of Reviewing Editors, and the evaluation has been overseen by Ronald Calabrese as the Senior Editor. The reviewers have opted to remain anonymous.</p><p>The reviewers have discussed their reviews with one another, and the Reviewing Editor has drafted this to help you prepare a revised submission.</p><p>Essential revisions:</p><p>It is important to add discussions of implementation constraints associated with memory requirements and assumptions about wind parameters and movement of the sources as discussed in detail by Reviewer 1.</p><p>Reviewer 2 stresses the importance of making the simulation dataset easily accessible to readers.</p><p><italic>Reviewer #2 (Recommendations for the authors):</italic></p><p>Please make the dataset with the simulation results available. I did not see it in the zip file.</p><p>Please provide color for velocity fluctuations in Figure 1.</p><p>Please clarify the statement on line 134 that the model lacks the appropriate spatiotemporal correlations.</p><p>Line 139 and ff: there are missing words and text. For example, there is (1) but no subsequent points. In any case, please add more here about how hyper-planes are constructed.</p><p>The possible set of actions is described in line 111ff but the rate of sniffing is not described as one of the variables there. Later (line 172ff), the authors discuss the frequency of sniffing as a function of distance from the source. Therefore, this frequency should be explicitly included in the initial setup of the model.</p><p>Line 178 double word: &quot;the the&quot;.</p></body></sub-article><sub-article article-type="reply" id="sa2"><front-stub><article-id pub-id-type="doi">10.7554/eLife.76989.sa2</article-id><title-group><article-title>Author response</article-title></title-group></front-stub><body><disp-quote content-type="editor-comment"><p>Reviewer #2 (Recommendations for the authors):</p><p>Please make the dataset with the simulation results available. I did not see it in the zip file.</p></disp-quote><p>The dataset has been made public at https://zenodo.org/record/6538177#.Yqrl_5BByJE</p><disp-quote content-type="editor-comment"><p>Please provide color for velocity fluctuations in Figure 1.</p></disp-quote><p>The flow is an illustration and colors have been chosen for visual purposes. We prefer then to keep things as they are and to take the above remark into account by changing the caption so as to make it clear that it is an illustration that has the purpose of providing an artistic view of the dynamics.</p><disp-quote content-type="editor-comment"><p>Please clarify the statement on line 134 that the model lacks the appropriate spatiotemporal correlations.</p></disp-quote><p>The sentence “The model is partially inaccurate as the average detection rate does match the simulated odor plumes but the model of the agent lacks the appropriate spatiotemporal correlations because detections are independent in the Poissonian model and they are not in the real flow.” (Lines 133-135) has been added for clarification.</p><disp-quote content-type="editor-comment"><p>Line 139 and ff: there are missing words and text. For example, there is (1) but no subsequent points. In any case, please add more here about how hyper-planes are constructed.</p></disp-quote><p>We have modified the text to describe in some more detail the idea for the construction of the hyperplanes without consulting the Methods. The relevant lines are 138-143.</p><disp-quote content-type="editor-comment"><p>The possible set of actions is described in line 111ff but the rate of sniffing is not described as one of the variables there. Later (line 172ff), the authors discuss the frequency of sniffing as a function of distance from the source. Therefore, this frequency should be explicitly included in the initial setup of the model.</p></disp-quote><p>The frequency of sniffing is fixed throughout the search and is not modified as a function of distance to the source. What we meant by “rate of sniffing the air” is the fraction of time spent in action (vi) among the six possible alternative actions offered to the searcher ((i-iv) move to one of the four neighboring locations while sniffing the ground, (v) stay at the same location and sniff the ground or (vi) stay at the same location and sniff the air). The sentence at line 175 has been modified to clarify the possible ambiguity as: “… and measure the rate of sniffing the air (fraction of time spent in the action (vi) -- staying at the same location and sniffing the air -- among the six possible alternative actions offered to the searcher) for both of these behaviors.”</p><disp-quote content-type="editor-comment"><p>Line 178 double word: &quot;the the&quot;.</p></disp-quote><p>The typographical error has been corrected.</p></body></sub-article></article>