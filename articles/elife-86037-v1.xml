<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD with MathML3 v1.3 20210610//EN"  "JATS-archivearticle1-3-mathml3.dtd"><article xmlns:ali="http://www.niso.org/schemas/ali/1.0/" xmlns:xlink="http://www.w3.org/1999/xlink" article-type="research-article" dtd-version="1.3"><front><journal-meta><journal-id journal-id-type="nlm-ta">elife</journal-id><journal-id journal-id-type="publisher-id">eLife</journal-id><journal-title-group><journal-title>eLife</journal-title></journal-title-group><issn publication-format="electronic" pub-type="epub">2050-084X</issn><publisher><publisher-name>eLife Sciences Publications, Ltd</publisher-name></publisher></journal-meta><article-meta><article-id pub-id-type="publisher-id">86037</article-id><article-id pub-id-type="doi">10.7554/eLife.86037</article-id><article-categories><subj-group subj-group-type="display-channel"><subject>Research Article</subject></subj-group><subj-group subj-group-type="heading"><subject>Neuroscience</subject></subj-group></article-categories><title-group><article-title>Cross-movie prediction of individualized functional topography</article-title></title-group><contrib-group><contrib contrib-type="author" id="author-302942"><name><surname>Jiahui</surname><given-names>Guo</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">https://orcid.org/0000-0002-1528-9025</contrib-id><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="fn" rid="con1"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" id="author-306013"><name><surname>Feilong</surname><given-names>Ma</given-names></name><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="fn" rid="con2"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" id="author-216946"><name><surname>Nastase</surname><given-names>Samuel A</given-names></name><xref ref-type="aff" rid="aff2">2</xref><xref ref-type="fn" rid="con3"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" id="author-19763"><name><surname>Haxby</surname><given-names>James V</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">https://orcid.org/0000-0002-6558-3118</contrib-id><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="other" rid="fund1"/><xref ref-type="fn" rid="con4"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" corresp="yes" id="author-79787"><name><surname>Gobbini</surname><given-names>M Ida</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">https://orcid.org/0000-0001-6727-7934</contrib-id><email>mariaida.gobbini@unibo.it</email><xref ref-type="aff" rid="aff3">3</xref><xref ref-type="aff" rid="aff4">4</xref><xref ref-type="other" rid="fund2"/><xref ref-type="fn" rid="con5"/><xref ref-type="fn" rid="conf1"/></contrib><aff id="aff1"><label>1</label><institution-wrap><institution-id institution-id-type="ror">https://ror.org/049s0rh22</institution-id><institution>Center for Cognitive Neuroscience, Dartmouth College</institution></institution-wrap><addr-line><named-content content-type="city">Hanover</named-content></addr-line><country>United States</country></aff><aff id="aff2"><label>2</label><institution-wrap><institution-id institution-id-type="ror">https://ror.org/00hx57361</institution-id><institution>Princeton Neuroscience Institute, Princeton University</institution></institution-wrap><addr-line><named-content content-type="city">Princeton</named-content></addr-line><country>United States</country></aff><aff id="aff3"><label>3</label><institution-wrap><institution-id institution-id-type="ror">https://ror.org/01111rn36</institution-id><institution>Department of Medical and Surgical Sciences (DIMEC), University of Bologna</institution></institution-wrap><addr-line><named-content content-type="city">Bologna</named-content></addr-line><country>Italy</country></aff><aff id="aff4"><label>4</label><institution-wrap><institution-id institution-id-type="ror">https://ror.org/02mgzgr95</institution-id><institution>IRCCS, Istituto delle Scienze Neurologiche di Bologna</institution></institution-wrap><addr-line><named-content content-type="city">Bologna</named-content></addr-line><country>Italy</country></aff></contrib-group><contrib-group content-type="section"><contrib contrib-type="editor"><name><surname>Meng</surname><given-names>Ming</given-names></name><role>Reviewing Editor</role><aff><institution-wrap><institution-id institution-id-type="ror">https://ror.org/01kq0pv72</institution-id><institution>South China Normal University</institution></institution-wrap><country>China</country></aff></contrib><contrib contrib-type="senior_editor"><name><surname>Baker</surname><given-names>Chris I</given-names></name><role>Senior Editor</role><aff><institution-wrap><institution-id institution-id-type="ror">https://ror.org/04xeg9z08</institution-id><institution>National Institute of Mental Health</institution></institution-wrap><country>United States</country></aff></contrib></contrib-group><pub-date publication-format="electronic" date-type="publication"><day>23</day><month>11</month><year>2023</year></pub-date><pub-date pub-type="collection"><year>2023</year></pub-date><volume>12</volume><elocation-id>e86037</elocation-id><history><date date-type="received" iso-8601-date="2023-01-09"><day>09</day><month>01</month><year>2023</year></date><date date-type="accepted" iso-8601-date="2023-11-09"><day>09</day><month>11</month><year>2023</year></date></history><pub-history><event><event-desc>This manuscript was published as a preprint at bioRxiv.</event-desc><date date-type="preprint" iso-8601-date="2022-11-22"><day>22</day><month>11</month><year>2022</year></date><self-uri content-type="preprint" xlink:href="https://doi.org/10.1101/2022.11.21.517253"/></event></pub-history><permissions><copyright-statement>Â© 2023, Jiahui et al</copyright-statement><copyright-year>2023</copyright-year><copyright-holder>Jiahui et al</copyright-holder><ali:free_to_read/><license xlink:href="http://creativecommons.org/licenses/by/4.0/"><ali:license_ref>http://creativecommons.org/licenses/by/4.0/</ali:license_ref><license-p>This article is distributed under the terms of the <ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/licenses/by/4.0/">Creative Commons Attribution License</ext-link>, which permits unrestricted use and redistribution provided that the original author and source are credited.</license-p></license></permissions><self-uri content-type="pdf" xlink:href="elife-86037-v1.pdf"/><self-uri content-type="figures-pdf" xlink:href="elife-86037-figures-v1.pdf"/><abstract><p>Participant-specific, functionally defined brain areas are usually mapped with functional localizers and estimated by making contrasts between responses to single categories of input. Naturalistic stimuli engage multiple brain systems in parallel, provide more ecologically plausible estimates of real-world statistics, and are friendly to special populations. The current study shows that cortical functional topographies in individual participants can be estimated with high fidelity from naturalistic stimuli. Importantly, we demonstrate that robust, individualized estimates can be obtained even when participants watched different movies, were scanned with different parameters/scanners, and were sampled from different institutes across the world. Our results create a foundation for future studies that allow researchers to estimate a broad range of functional topographies based on naturalistic movies and a normative database, making it possible to integrate high-level cognitive functions across datasets from laboratories worldwide.</p></abstract><kwd-group kwd-group-type="author-keywords"><kwd>hyperalignment</kwd><kwd>category selectivity</kwd><kwd>localizer</kwd><kwd>connectivity</kwd><kwd>naturalistic stimuli</kwd></kwd-group><kwd-group kwd-group-type="research-organism"><title>Research organism</title><kwd>Human</kwd></kwd-group><funding-group><award-group id="fund1"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/100000001</institution-id><institution>National Science Foundation</institution></institution-wrap></funding-source><award-id>1607845</award-id><principal-award-recipient><name><surname>Haxby</surname><given-names>James V</given-names></name></principal-award-recipient></award-group><award-group id="fund2"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/100000001</institution-id><institution>National Science Foundation</institution></institution-wrap></funding-source><award-id>1835200</award-id><principal-award-recipient><name><surname>Gobbini</surname><given-names>M Ida</given-names></name></principal-award-recipient></award-group><award-group id="fund3"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/100000025</institution-id><institution>National Institute of Mental Health</institution></institution-wrap></funding-source><award-id>MH127199</award-id><principal-award-recipient><name><surname>Haxby</surname><given-names>James V</given-names></name></principal-award-recipient></award-group><funding-statement>The funders had no role in study design, data collection and interpretation, or the decision to submit the work for publication.</funding-statement></funding-group><custom-meta-group><custom-meta specific-use="meta-only"><meta-name>Author impact statement</meta-name><meta-value>A computational approach based on connectivity hyperalignment can estimate individualized functional topography with high fidelity across movie contents, scanners, protocols, and languages.</meta-value></custom-meta></custom-meta-group></article-meta></front><body><sec id="s1" sec-type="intro"><title>Introduction</title><p>Category-selective functional topographies are a prominent and consistent feature of lateral occipital, ventral temporal, and lateral temporal visual cortices (<xref ref-type="bibr" rid="bib3">Downing et al., 2001</xref>; <xref ref-type="bibr" rid="bib4">Epstein et al., 1999</xref>; <xref ref-type="bibr" rid="bib12">Grill-Spector and Weiner, 2014</xref>; <xref ref-type="bibr" rid="bib22">Kanwisher et al., 1997</xref>). Category-selective topographies are mostly similar across individuals but are idiosyncratic in terms of their precise conformation and location (<xref ref-type="bibr" rid="bib39">Zhen et al., 2015</xref>; <xref ref-type="bibr" rid="bib40">Zhen et al., 2017</xref>). Because of these idiosyncrasies, category-selective topographies and areas are typically mapped in each individual using a functional localizer fMRI scan (<xref ref-type="bibr" rid="bib6">Fedorenko et al., 2010</xref>; <xref ref-type="bibr" rid="bib30">Saxe et al., 2006</xref>). Functional localizers map individualized topographies with simple contrasts between responses to different categories, such as contrasting responses to faces versus objects to localize face-selective areas.</p><p>We reported an alternative approach to map category-selective topographies using fMRI data collected while participants view a naturalistic movie (<xref ref-type="bibr" rid="bib13">Guntupalli et al., 2016</xref>; <xref ref-type="bibr" rid="bib17">Haxby et al., 2011</xref>; <xref ref-type="bibr" rid="bib19">Jiahui et al., 2020</xref>). With this approach, movie-viewing and functional localizer data are collected in a normative sample, and new participants need only be scanned during movie viewing. Movie data are used to calculate transformation matrices using hyperalignment (<xref ref-type="bibr" rid="bib13">Guntupalli et al., 2016</xref>; <xref ref-type="bibr" rid="bib17">Haxby et al., 2011</xref>; <xref ref-type="bibr" rid="bib19">Jiahui et al., 2020</xref>; <xref ref-type="bibr" rid="bib7">Feilong et al., 2018</xref>; <xref ref-type="bibr" rid="bib8">Feilong et al., 2021</xref>; <xref ref-type="bibr" rid="bib8">Feilong et al., 2021</xref>; <xref ref-type="bibr" rid="bib14">Guntupalli et al., 2018</xref>) that afford projecting the localizer data from the normative sample into the idiosyncratic cortical topography of new participants. Using this hyperalignment procedure, we can estimate the idiosyncratic details of individual topographies with high fidelity based on localizer data from the normative sample. Unlike functional localizers, naturalistic stimuli (e.g., movies) evoke a rich variety of brain states and engage multiple brain systems in parallel. This makes it possible to efficiently map multiple functional topographies using data from a single movie and avoid the time and cost of running multiple localizers. Compared to controlled localizers, movies better simulate real-world cognition and better engage participantsâ attention (<xref ref-type="bibr" rid="bib35">Vanderwal et al., 2015</xref>; <xref ref-type="bibr" rid="bib36">Vanderwal et al., 2017</xref>; <xref ref-type="bibr" rid="bib37">Vanderwal et al., 2019</xref>), contributing to more ecologically valid and higher-quality maps. In addition, movies are more friendly and engaging for special populations, such as young children.</p><p>In previous work, we used response hyperalignment (RHA) to predict functional topographies in new participants. RHA requires that all participants watch the same movie to obtain time-locked responses to the same stimuli. It is often important, however, to tailor the movie to meet the specific needs of participants in different experiments. For example, participants from different countries may prefer movies that reflect their diverse backgrounds and are in their native languages (<xref ref-type="bibr" rid="bib16">Hanke et al., 2016</xref>; <xref ref-type="bibr" rid="bib32">Sengupta et al., 2016</xref>); movies for infants and young children are differently structured from those for adults (<xref ref-type="bibr" rid="bib35">Vanderwal et al., 2015</xref>). Thus, it is unrealistic to limit all participants from diverse populations and backgrounds to watch the same movie. Additionally, experimenters may need to shorten or edit the stimuli to fit their data collection schedule. Finally, participants are often scanned with different parameters from one experiment to another, at different institutes across the world, and with different scanner models. Due to these factors, it is impractical to expect two laboratories to acquire the same movie scans across individuals.</p><p>Here, we test whether connectivity hyperalignment (CHA) (<xref ref-type="bibr" rid="bib14">Guntupalli et al., 2018</xref>) can be used to map category-selective functional topographies. CHA, in contrast to RHA, affords calculation of transformation matrices using stimuli that are not the same for normative and index participants. We analyzed four different datasets collected with three different movies, three different scanners, and two different types of functional localizers that used dynamic or static stimuli. We first demonstrated that CHA based on participantsâ connectomes that were calculated using their responses to movies was able to generate high-fidelity maps of category-selective topographies within datasets that were equivalent to maps estimated using RHA. Then, critically, we showed that cross-dataset predictions that used connectomes calculated from different movies for the normative and index brains were as good as those from participants in the same dataset. This means that different laboratories can use different movies to derive functional topographies from a normative sample.</p><p>In summary, we demonstrate that a target participantâs individualized category-selective topography can be accurately estimated using CHA, regardless of whether different movies are used to calculate the connectome and regardless of other data collection parameters. Movies engage multiple cognitive domains in parallel, such as visual perception, audition, language comprehension, theory of mind, and social interaction. In addition to estimating different functional topographies from a single movie, our approach allows us to estimate topographies from different movies. We provide a novel alternative for future data collection that can save time and money using rich and efficient movie scans.</p></sec><sec id="s2" sec-type="results"><title>Results</title><sec id="s2-1"><title>High-fidelity prediction with CHA</title><p>We predicted category-selective topographies by projecting other participantsâ functional localizer data into each participantâs native cortical topography using a new, enhanced CHA algorithm. For each participant, we calculated transformation matrices based on functional connectivity estimated during movie viewing in an iterative way (see Materials and methods). These transformation matrices resample fMRI data from othersâ brains into a given participantâs cortex. We then projected the functional localizer data for all other participants into the given participantâs native cortical space and calculated independent functional contrasts based on that participantâs own localizer data and based on other participantsâ localizer data projected into that participantâs cortex. We also estimated functional topographies by projecting othersâ localizer data into that participantâs cortex based on high-performing surface-based anatomical alignment as a control analysis. We calculated the correlations between topographies based on participantsâ own localizer contrasts and on other participantsâ data. Because the localizer task comprises several scanning runs, we calculated the reliability of the localizer across runs with Cronbachâs alpha to provide an estimate of the noise ceiling for these correlations. We repeated this procedure for all participants.</p><p>We tested the estimation of visual category-selective functional topographies (faces, bodies, scenes, and objects) in four different datasets using three different movies, localizers with static or dynamic stimuli, different scanning sequence parameters, and three different scanner models (see Materials and methods).</p><p>Category-selective topographies estimated with CHA recovered the idiosyncrasies of individualsâ topographies, capturing fine details of the individual-specific configuration and extent. By contrast, topographies estimated with anatomical alignment generated highly blurred maps that were essentially the same for all participants, losing individual-specific idiosyncratic features (<xref ref-type="fig" rid="fig1">Figure 1A</xref>).</p><fig-group><fig id="fig1" position="float"><label>Figure 1.</label><caption><title>Predicting individual category-selective topographies using connectivity hyperalignment (CHA).</title><p>(<bold>A</bold>) Face-selective topographies (faces-vs-all) and zoomed-in views of an example participant estimated from this participantâs own localizer (Own Localizer), and other participantsâ localizers using CHA, and surface anatomical alignment (AA). (<bold>B</bold>) Scatter plots display the Pearson correlation coefficients between estimated face-selective topographies based on own localizer data and other participantsâ localizer data in individual participants in four different datasets. The y-axis corresponds to correlations between each target participantâs own localizer-based face-selective topographies and face-selective topographies estimated from other participants using CHA. The x-axis corresponds to correlations between each target participantâs own localizer-based face-selective topographies and face-selective topographies estimated from other participants with surface-based anatomical alignment. (<bold>C</bold>) Bar plots show the mean correlations across participants in four datasets (Budapest &amp; Sraiders: <italic>n</italic> = 20; Forrest: <italic>n</italic> = 15; Raiders: <italic>n</italic> = 9. Same sample sizes in other figures for each dataset unless noted.) and for all four category-selective topographies. Black bars stand for the mean Cronbachâs alphas across participants. Error bars indicate Â±1 standard error of the mean. Category topographies were defined based on contrasts between the target category and all other categories. (<bold>D</bold>) Scatter plots of Pearson correlation coefficients using CHA and response hyperalignment (RHA) for individual participants within four different datasets for the face-selective topography. Values on the y-axis stand for correlations between each target participantâs own localizer-based topographies and topographies estimated from other participants in the same dataset using RHA. Values on the x-axis stand for correlations between each target participantâs own localizer-based topographies and topographies estimated from other participants in the same dataset using CHA.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-86037-fig1-v1.tif"/></fig><fig id="fig1s1" position="float" specific-use="child-fig"><label>Figure 1âfigure supplement 1.</label><caption><title>Schematic data analysis procedures.</title><p>In the enhanced connectivity hyperalignment (CHA) analysis, transformation matrices derived from projecting connectome based on the movie data in each training participantâs cortical space to the target participantâs space were applied to each training participantâs localizer runs. These steps were iterated six times, and in each step, the connectome and the localizer data were both updated. The original localizer runs were used to calculate category-selective topographies for each training participant and averaged across runs and participants to obtain the surface alignment predicted topography for the target participant. The localizer runs hyperaligned after all iteration steps were used to obtain CHA predicted topographies with similar procedures. Outside of this loop, each target participantâ own original localizer runs were used to obtain this participantâs own localizer estimated topographies.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-86037-fig1-figsupp1-v1.tif"/></fig></fig-group><p>The superior performance of CHA-based estimation over anatomical-alignment-based estimation was consistent across participants, visual stimulus categories, and datasets. In all four category-selective topographies and in all four datasets, correlations between estimations based on hyperalignment and their own localizer data were significantly higher than the correlations between estimations based on anatomical alignment and each participantâs own localizer (Fisher z-transformed, p&lt;0.001, Bonferroni corrected). We compared these correlations between topographies estimated from a participantâs own localizer data and those from other participantsâ data to the reliability of the localizer, calculated with Cronbachâs alpha. Predictions made with hyperalignment were close to and sometimes even exceeded the reliability values (<xref ref-type="fig" rid="fig1">Figure 1B</xref>), which indicate that the predicted category-selective topographies from other participantsâ data using hyperalignment were as precise and sometimes even better than the topographies estimated with their own localizer data.</p><p>Estimates using CHA to calculate transformation matrices were also equivalent to estimates using RHA (<xref ref-type="fig" rid="fig1">Figure 1D</xref>). RHA, however, requires that all subjects watch the same movie, whereas CHA can use connectivity matrices derived from responses to different movies, potentially making our new approach more flexible. Next we tested the validity of estimating topographies using transformation matrices that were based on functional connectivities calculated from responses to different movies for the test participant and other participants.</p></sec><sec id="s2-2"><title>CHA enables cross-movie predictions</title><p>Experimental design considerations and constraints can make using the same stimulus across all studies and participants inadvisable, and datasets are often collected under diverse conditions. Here, we aim to test whether connectivity-based hyperalignment can predict category-selective topographies in new individuals even if their connectomes are estimated from data collected while they watched a different movie. Using this method, participants across datasets without matched time-locked functional series can benefit from those who have functional localizer data but were scanned with different naturalistic stimuli.</p><p>We estimated category-selective topographies for each participant in each dataset from participants in the other dataset that used the same type of localizer (dynamic or static) by calculating transformation matrices based on functional connectivities measured while watching different movies. We also estimated topographies based on anatomical alignment. The cross-movie predictions using CHA outperformed predictions based on anatomical alignment and were nearly as precise as within-movie predictions (<xref ref-type="fig" rid="fig2">Figure 2A</xref>). The superior performance was consistent across datasets and categories (p&lt;0.001 for all comparisons, <xref ref-type="fig" rid="fig2">Figure 2B</xref>) and in all individual participants (<xref ref-type="fig" rid="fig2s2">Figure 2âfigure supplement 2</xref>). Similarly, accuracies of these predictions matched and sometimes even exceeded the reliability measures of their own localizer runs (<xref ref-type="fig" rid="fig2">Figure 2B</xref>).</p><fig-group><fig id="fig2" position="float"><label>Figure 2.</label><caption><title>Predicting category-selective topographies using connectivity profiles across movies.</title><p>(<bold>A</bold>) Scatter plots of Pearson correlation coefficients for individual participants in four different datasets and for four categories. Values on the y-axis stand for correlations between each target participantâs own localizer-based topographies and topographies estimated from other participants in the same movie using connectivity hyperalignment (CHA). Values on the x-axis stand for correlations between each target participantâs own localizer-based topographies and topographies estimated from participants in another dataset based on cross-movie CHA. (<bold>B</bold>) Bar plots display the mean Pearson correlation coefficients (r) and Cronbachâs alphas across participants in all four datasets for all four categories. Error bars stand for Â±1 standard error of the mean. S to B: Sraiders to Budapest, B to S: Budapest to Sraiders, R to F: Raiders to Forrest, F to R: Forrest to Raiders.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-86037-fig2-v1.tif"/></fig><fig id="fig2s1" position="float" specific-use="child-fig"><label>Figure 2âfigure supplement 1.</label><caption><title>Connectivity hyperalignment (CHA) predictions.</title><p>Bar plots display the mean Pearson correlation coefficients (r) and Cronbachâs alphas across participants in all four datasets for all four categories. Error bars stand for Â±1 standard error of the mean. The abbreviations are the same in all figures, including this one. S to B: Sraiders to Budapest, F to B: Forrest to Budapest, R to B: Raiders to Budapest, B to S: Budapest to Sraiders, F to S: Forrest to Sraiders, R to S: Raiders to Sraiders, R to F: Raiders to Forrest, B to F: Budapest to Forrest, S to F: Sraiders to Forrest, F to R: Forrest to Raiders, B to R: Budapest to Raiders, S to R: Sraiders to Raiders.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-86037-fig2-figsupp1-v1.tif"/></fig><fig id="fig2s2" position="float" specific-use="child-fig"><label>Figure 2âfigure supplement 2.</label><caption><title>Prediction performances for each individual participant.</title><p>Prediction performance (Pearson r) for the face-selective topography for each individual participant using response hyperalignment (RHA), connectivity hyperalignment (CHA), cross-movie CHA, and surface alignment (AA) in all four datasets. Black dots stand for individual participantsâ Cronbachâs alphas of their own face-selective topographies across localizer runs. Dashed lines are the mean values across participants. S to B: Sraiders to Budapest, F to B: Forrest to Budapest, R to B: Raiders to Budapest, B to S: Budapest to Sraiders, F to S: Forrest to Sraiders, R to S: Raiders to Sraiders, R to F: Raiders to Forrest, B to F: Budapest to Forrest, S to F: Sraiders to Forrest, F to R: Forrest to Raiders, B to R: Budapest to Raiders, S to R: Sraiders to Raiders.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-86037-fig2-figsupp2-v1.tif"/></fig></fig-group><p>Cross-movie predictions of cortical topographies based on different localizer types (static to dynamic or dynamic to static) produced lower correlations than did cross-movie predictions based on the same localizer type (<xref ref-type="fig" rid="fig2s1">Figure 2âfigure supplement 1</xref>), consistent with previous reports showing significant differences between topographies estimated by static and dynamic localizers, especially in superior temporal and frontal cortices (<xref ref-type="bibr" rid="bib11">Fox et al., 2009</xref>; <xref ref-type="bibr" rid="bib26">Pitcher et al., 2011</xref>).</p><p>To demonstrate how hyperalignment increased prediction performance for individual participants from a different dataset, we plotted topographies estimated using hyperalignment and anatomical alignment, as well as from their own localizer runs (<xref ref-type="fig" rid="fig3">Figure 3</xref>, <xref ref-type="fig" rid="fig3s1">Figure 3âfigure supplement 1</xref> and <xref ref-type="fig" rid="fig3s2">Figure 3âfigure supplement 2</xref>). Topographies between datasets recovered similar idiosyncratic features as the topographies predicted within datasets.</p><fig-group><fig id="fig3" position="float"><label>Figure 3.</label><caption><title>Sample contrast maps and enlarged views of the ventral temporal cortex.</title><p>Contrast maps for face-selective topographies (faces-vs-all) and their zoomed-in views of the ventral temporal cortex were plotted in four sample participants in (<bold>A</bold>) Budapest, (<bold>B</bold>) Sraiders, (<bold>C</bold>) Forrest, and (<bold>D</bold>) Raiders. In all four subplots, in the left-most panel, faces-vs-all maps were plotted on the sample participantsâ own cortical surfaces. The next two columns display maps estimated from other participantsâ data. In the right two columns, the first column presents predicted face-selective topographies from participants in the same dataset using connectivity hyperalignment (CHA). The next column presents face-selective topographies from participants in another dataset (cross-movie CHA). The zoomed-in panels are displayed accordingly with the whole-brain map. The color bar is the same as that in <xref ref-type="fig" rid="fig1">Figure 1</xref>. S to B: Sraiders to Budapest, B to S: Budapest to Sraiders, R to F: Raiders to Forrest, F to R: Forrest to Raiders.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-86037-fig3-v1.tif"/></fig><fig id="fig3s1" position="float" specific-use="child-fig"><label>Figure 3âfigure supplement 1.</label><caption><title>Sample contrast maps and enlarged views of the ventral temporal cortex.</title><p>Contrast maps for face-selective topographies (faces-vs-all) and their enlarged views of the ventral temporal cortex were plotted in sample participants in (<bold>A</bold>) Budapest, (<bold>B</bold>) Sraiders, (<bold>C</bold>) Forrest, and (<bold>D</bold>) Raiders. In all five subplots for the whole-brain maps, the faces-vs-all maps were plotted on the sample participantsâ own cortical surfaces (left single panel). The second column presents predicted face-selective topographies from participants in the same dataset using connectivity hyperalignment (top) and surface alignment (bottom). The next three columns present face-selective topographies from participants in another dataset with the same (second column) and a different type (the last two columns) of localizers. In the four right columns, the top row presents the map using hyperalignment (HA), and the bottom row presents the map using surface alignment (AA). The enlarged panels were displayed accordingly with the whole-brain map. The color bar was the same as that in <xref ref-type="fig" rid="fig1">Figure 1</xref>.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-86037-fig3-figsupp1-v1.tif"/></fig><fig id="fig3s2" position="float" specific-use="child-fig"><label>Figure 3âfigure supplement 2.</label><caption><title>Sample contrast maps of body-, scene-, and object-selective topographies.</title><p>Contrast maps of the other three categories were plotted in participants in (<bold>A</bold>) Budapest, (<bold>B</bold>) Sraiders, (<bold>C</bold>) Forrest, and (<bold>D</bold>) Raiders. In all five subplots for the whole-brain maps, the maps estimated from their own localizer runs were plotted on the sample participant (left single panel). The other columns present predicted topographies from participants in the same dataset using connectivity hyperalignment (top) and surface alignment (bottom).</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-86037-fig3-figsupp2-v1.tif"/></fig></fig-group><p>To further examine the topographies predicted using different datasets and compare the prediction performances to reliability measures, we calculated local correlations between maps estimated from each participantâs own localizer runs and those estimated from other participantsâ runs with a searchlight analysis. We also calculated Cronbachâs alpha across localizer runs in each searchlight. Generally, searchlights in the high-level visual areas and with strong category selectivity (e.g., ventral temporal cortex, lateral temporal cortex) showed the highest mean correlation values, which often exceeded 0.8 (<xref ref-type="fig" rid="fig4">Figure 4</xref>, <xref ref-type="fig" rid="fig4s1">Figure 4âfigure supplement 1</xref>, <xref ref-type="fig" rid="fig4s3">Figure 4âfigure supplement 3</xref>, and <xref ref-type="fig" rid="fig4s10">Figure 4âfigure supplement 10</xref>). The lower mean correlations in other cortices (e.g., sensorimotor cortex) reflect low reliabilities of the localizer runs.</p><fig-group><fig id="fig4" position="float"><label>Figure 4.</label><caption><title>Searchlight analysis of Cronbachâs alphas and prediction performances.</title><p>(<bold>A, B, C, and D</bold>) The left-most column presents Cronbachâs alphas of the own-localizer-based face-selective topographies in each dataset using a searchlight analysis (15 mm radius). The next two columns present local correlations (correlation maps) using the searchlight analysis between face-selective maps estimated from participantsâ own localizers and from other participants based on within-movie and between-movie connectivity hyperalignment (CHA) (hyperalignment [HA], top row) and surface alignment (AA, bottom row). Histogram plots present Cronbachâs alphas (dark gray) and coefficients for the correlation maps above (estimated with CHA in color, with AA in light gray). The left and right hemisphere histograms were plotted separately. B to S: Budapest to Sraiders, S to B: Sraiders to Budapest, R to F: Raiders to Forrest, F to R: Forrest to Raiders.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-86037-fig4-v1.tif"/></fig><fig id="fig4s1" position="float" specific-use="child-fig"><label>Figure 4âfigure supplement 1.</label><caption><title>Searchlight correlations.</title><p>(<bold>A, B, C, and D</bold>) The left-most column shows the Cronbachâs alphas of the own localizer-based face-selective topographies in each dataset using a searchlight analysis (15 mm radius). The next four columns show local correlations (correlation maps) using the searchlight analysis between the face-selective maps estimated from other participants based on within-movie (second column, top row) and between-movie (the next three columns, top row) connectivity hyperalignment (CHA) and surface alignment (AA, bottom row).</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-86037-fig4-figsupp1-v1.tif"/></fig><fig id="fig4s2" position="float" specific-use="child-fig"><label>Figure 4âfigure supplement 2.</label><caption><title>Distribution of correlation coefficients in major cortices.</title><p>Histogram plots of local Cronbachâs alphas (dark gray) and local correlation coefficients between face-selective topographies estimated from own and othersâ localizers across the cortex (hyperalignment [HA] in color, light gray for surface alignment [AA]) in major cortices (ventral temporal, dorsal temporal, occipital, frontal, and parietal) in the four datasets (see <xref ref-type="fig" rid="fig4">Figure 4</xref> for the whole-brain maps and distributions). The left and right hemisphere histograms were plotted separately in each cortical parcel.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-86037-fig4-figsupp2-v1.tif"/></fig><fig id="fig4s3" position="float" specific-use="child-fig"><label>Figure 4âfigure supplement 3.</label><caption><title>Searchlight analysis results for other categories.</title><p>(<bold>A, B, C, and D</bold>) The left-most column shows the Cronbachâs alphas of the own localizer-based topographies in each dataset using a searchlight analysis (15 mm radius). The next four columns show local correlations (correlation maps) using the searchlight analysis between the category-selective maps estimated from other participants based on within-movie (second column, top row) and between-movie (the next three columns, top row) connectivity hyperalignment (CHA) and surface alignment (AA, bottom row).</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-86037-fig4-figsupp3-v1.tif"/></fig><fig id="fig4s4" position="float" specific-use="child-fig"><label>Figure 4âfigure supplement 4.</label><caption><title>Advanced connectivity hyperalignment (CHA) improved prediction performances.</title><p>(<bold>A</bold>) In each subplot, each line with dots showed the improvement of the mean correlation across participants between the category-selective maps estimated from each participantâs own localizer runs and those estimated from participantsâ data in other datasets from step 1 to step 6 using our new advanced iterative CHA algorithm. Horizontal dotted lines are the mean Cronbachâs alphas (gray) and the mean performance using response hyperalignment (RHA) (colored). (<bold>B, C</bold>, and <bold>D</bold>) had the same layout as A with participants in Sraiders, Forrest, and Raiders dataset as the prediction target.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-86037-fig4-figsupp4-v1.tif"/></fig><fig id="fig4s5" position="float" specific-use="child-fig"><label>Figure 4âfigure supplement 5.</label><caption><title>Prediction performance changing with number of runs and participants.</title><p>(<bold>A</bold>) In each subplot, each line with dots showed the improvement of the mean correlation across participants between the category-selective maps (faces, bodies, scenes, and objects) estimated from each participantâs own localizer runs and those estimated from other participantsâ data using the 1, 1â2, 1â3, 1â4, and all five runs of the Budapest movie or all four runs of the Sraiders movie. The length of each movie-viewing run in the Budapest dataset is 598 s, 498 s, 535 s, 618 s, and 803 s accordingly, and 840 s for each of the four runs in the Sraiders dataset. Horizontal dotted lines are the mean Cronbachâs alphas (red) and the mean performance based on surface alignment (gray). (<bold>B</bold>) In each subplot, each line with dots showed the improvement of the mean correlation across participants between the category-selective maps (faces, bodies, scenes, and objects) estimated from each participantâs own localizer runs and those estimated from other participantsâ data using 5, 10, 15, or all 20 participants in the Budapest dataset. Horizontal dotted lines are the mean Cronbachâs alphas (red) and gray lines with dots showing the mean performance based on surface alignment.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-86037-fig4-figsupp5-v1.tif"/></fig><fig id="fig4s6" position="float" specific-use="child-fig"><label>Figure 4âfigure supplement 6.</label><caption><title>Predictions based on the 1-step and the 2-step methods.</title><p>Bar plots display the mean Pearson correlation coefficients (r) and Cronbachâs alphas across participants in all four datasets for all four categories. Bars with solid outlines stand for results based on the 1-step method, and bars with dashed outlines are based on the 2-step method. Error bars stand for Â±1 standard error of the mean.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-86037-fig4-figsupp6-v1.tif"/></fig><fig id="fig4s7" position="float" specific-use="child-fig"><label>Figure 4âfigure supplement 7.</label><caption><title>Comparing prediction performance between projecting time series and projecting contrast maps to the target participant.</title><p>(<bold>A, B, and C</bold>) Scatter plots of Pearson correlation coefficients with Budapest dataset, using response hyperalignment (RHA), connectivity hyperalignment (CHA), and cross-movie from Sraiders to Budapest for individual participants for the face, body, scene, and object-selective topographies. Values on the y-axis stand for correlations between each target participantâs own localizer-based topographies and topographies estimated from other participants when transformation matrices were applied to the localizer time series. Values on the x-axis stand for correlations between each target participantâs own localizer-based topographies and topographies estimated from other participants when transformation matrices were applied directly to contrast maps. (<bold>D</bold>) In each subplot, each line with dots showed the mean correlation across participants between the category-selective maps estimated from each participantâs own localizer runs and those estimated from participantsâ data in other datasets from step 1 to step 6 using the new advanced iterative CHA algorithm. Darker shades stand for the performance when transformation matrices were applied to localizer time series, and lighter shades stand for the mean performance when transformation matrices were applied directly to contrast maps. Horizontal dotted lines are the mean Cronbachâs alphas (red) and the mean performance using only surface alignment (gray).</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-86037-fig4-figsupp7-v1.tif"/></fig><fig id="fig4s8" position="float" specific-use="child-fig"><label>Figure 4âfigure supplement 8.</label><caption><title>Prediction performance using participants with similar connectivity profiles.</title><p>Bar plots display the mean Pearson correlation coefficients (r) across participants using all or part of the training participants for face-selective topography using connectivity hyperalignment (CHA) with the Budapest dataset. Participants were divided based on their connectivity profile similarities to the target participant and were measured using a 10 mm searchlight in the right ventral temporal cortex that was roughly at the location of the posterior fusiform face area (rpFFA). Bars in color are based on CHA, and bars in gray are based on surface alignment. Error bars stand for Â±1 standard error of the mean.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-86037-fig4-figsupp8-v1.tif"/></fig><fig id="fig4s9" position="float" specific-use="child-fig"><label>Figure 4âfigure supplement 9.</label><caption><title>Similarities between fine-grained connectivities in two different movie-viewing tasks.</title><p>(<bold>A</bold>) For each participant in the Budapest and the Sraiders dataset, connectomes that described the connectivity between each target in the searchlight and each vertex on the cortex were calculated for each dataset and correlated across the two datasets. This whole-brain map shows the mean correlations across participants. (<bold>B</bold>) Histogram plots of the correlation coefficients in A in the left and the right hemisphere. (<bold>C</bold>) The two datasets were split into two halves, and similarities of the fine-grained connectivity between the two halves within and across the two movies were calculated following the same procedures above. This plot shows the mean correlations across participants and searchlights.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-86037-fig4-figsupp9-v1.tif"/></fig><fig id="fig4s10" position="float" specific-use="child-fig"><label>Figure 4âfigure supplement 10.</label><caption><title>Searchlight correlations with different searchlight sizes.</title><p>Each set of brain maps shows the averaged local correlations between the category-selective map (column) estimated from other participants in the Budapest dataset based on enhanced connectivity hyperalignment (CHA) and the map estimated from their own localizers using a specific size of searchlight (row). Local correlations remained relatively similar across different searchlight sizes for all categories.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-86037-fig4-figsupp10-v1.tif"/></fig></fig-group></sec></sec><sec id="s3" sec-type="discussion"><title>Discussion</title><p>In this study, using four datasets that contain three different movies, two different types of functional localizers, and collected with three different scanners, we showed that individualized category-selective topographies can be estimated with high fidelity using CHA. Unlike RHA, which requires the same âtime-lockedâ response time series in the normative sample and new participants, CHA affords the calculation of transformation matrices based on responses to completely different movies. By showing that CHA based on participantsâ connectomes calculated using their responses to different movies generated high-fidelity mappings that were as good as those using RHA with participants in the same dataset, we demonstrated that CHA is able to effectively predict topographies across diverse situations. This study opens new possibilities connecting independent public and in-lab datasets for future data analysis so that researchers can derive multiple topographies at once for each individual with excellent performance based on the naturalistic movie data and the localizer data from another normative dataset. Our results also provide a novel alternative for new data collection to take better advantage of naturalistic stimuli.</p><p>We used a new, enhanced CHA in this study that optimized our previous CHA algorithm with iterative steps. In each step, transformation matrices to each index brain were calculated from other participantsâ brains and the matrices were applied to both the movie and the localizer data. Because using dense connectivity targets (e.g., using all vertices as connectivity targets) with anatomically alignment data often leads to suboptimal alignment across participants (<xref ref-type="bibr" rid="bib15">Hanke et al., 2014</xref>), we started with coarse connectivity targets and gradually increased the number of connectivity targets to form a denser representation of connectivity profiles. The iterations improved the prediction performance step by step, and at the final step (step 6, all vertices were used as connectivity targets) in this analysis, the enhanced CHA generated comparable performance with RHA (<xref ref-type="fig" rid="fig4s4">Figure 4âfigure supplement 4</xref>). We investigated the influence of naturalistic movie length and the size of the training group on the prediction accuracy of individualized functional topographies. By incrementally increasing both the number of movie runs in the training and target dataset and the participants in the training group in the Budapest and Sraiders dataset, we observed enhanced prediction accuracy (<xref ref-type="fig" rid="fig4s5">Figure 4âfigure supplement 5</xref>). Notably, even with just one movie run in the training or target dataset, or with a mere five participants in the training group, our prediction performance (Pearson r) ranged from about 0.6 to 0.7. This accuracy significantly outperformed results obtained using surface-based alignment. In addition, this study is based on the new optimized 1-step hyperalignment procedure (<xref ref-type="bibr" rid="bib19">Jiahui et al., 2020</xref>). The classic hyperalignment method (2-step), builds a common information model space at the initial step that is based on all normative group participants, then projects information encoded in idiosyncratic representational spaces to the common model space, and lastly projects the information back to the individual participantâs space based on the transpose of the transformation matrices from the former step. Different from the 2-step method, the 1-step method directly projects the data for each normative sample brain to the index participantâs space without the intermediate step of building a common information model space. This method requires fewer steps and is free from the accumulation of errors across steps. The 1-step method consistently improved the prediction performances across all conditions and datasets (<xref ref-type="fig" rid="fig4s6">Figure 4âfigure supplement 6</xref>). This method is particularly useful for estimating information encoded in each individualâs brain space. Our original algorithm is designed to apply transformation matrices to the time series of localizer data of training participants before generating contrast maps. To explore whether directly applying these matrices to pre-calculated contrast maps yields comparable results, we conducted an additional analysis across the four categories. Our findings indicate that the prediction outcomes were indeed quite similar between the two approaches for both the within- and across-datasets predictions (<xref ref-type="fig" rid="fig4s7">Figure 4âfigure supplement 7</xref>). However, it is worth noting that the improvements observed with enhanced CHA were not as pronounced when applied directly to the contrast maps as opposed to the time series. In our study, we used fine-scale connectomes, noting that some participants are more similar to the target participant in specific searchlights. It is an interesting question whether predictions could be enhanced by exclusively selecting those more similar participants for the target participant. To explore this option, we examined a searchlight in the right ventral temporal cortex that was roughly at the location of the posterior fusiform area using the top and bottom nine participants similar to each target participant measured by their fine-scale connectome similarities in the budapest dataset. Generally, using all or part of the participants for the prediction generated similar results (<xref ref-type="fig" rid="fig4s8">Figure 4âfigure supplement 8</xref>). Compared to using all the participants, using only the top nine participants who are the most similar to the target participants did not significantly improve the prediction (Tukey test, z=â0.09, p=0.996), but using only the bottom nine participants generated significantly lower prediction accuracies (Tukey test, z=2.492, p=0.034). This suggests a trade-off between the number of participants included in the prediction and the similarity of the participants. Future studies are needed to explore the optimal threshold for the number of participants included for each searchlight to refine the algorithm.</p><p>By leveraging transformation matrices obtained from hyperaligning participants based on movie-viewing data, we successfully mapped these relationships to the training participantsâ localizer data, enabling robust predictions. Prior work employing diffusion-weighted imaging has underscored the link between anatomical connectivity and category selectivity across diverse visual fields (<xref ref-type="bibr" rid="bib25">Osher et al., 2016</xref>; <xref ref-type="bibr" rid="bib31">Saygin et al., 2012</xref>) and has established a notable congruence between structural and functional connectivities (<xref ref-type="bibr" rid="bib18">Hermundstad et al., 2013</xref>). These findings suggest that the unique anatomical connectivity patterns of individuals may serve as a foundational mechanism, contributing to the stable fine-scale functional connectome that underpins our approach. The connectivity-based shared response model (cSRM) proposed by <xref ref-type="bibr" rid="bib24">Nastase et al., 2020</xref>, used connectivity to functionally align individuals similar to the CHA algorithm. While both approaches share overarching goals, they diverge considerably in implementation and application. First and most important, cSRM used inter-subject functional connectivity rather than within-subject functional connectivity to initially estimate the connectome. As a result, cSRM requires participants to have time-locked fMRI time series. Therefore, unlike our algorithm, the cSRM approach does not support cross-content applications and also is not suitable for use with resting-state data. Second, cSRM is implemented based on a predefined cortical parcellation rather than the overlapping, regularly spaced cortical searchlights applied in our method which are not constrained by areal borders. For the application, cSRM has mainly been used to do ROI analysis rather than the estimation of the whole-brain topography that requires broader coverage of the cortex with a searchlight analysis. Third, our method is specifically designed to work in each individualâs space, while cSRM decomposes data across subjects into shared and subject-specific transformations, focusing on a communal connectivity space. In summary, although cSRM presents a promising alternative for similar aims, its current implementation precludes it from fulfilling the range of applications for which our method is optimized.</p><p>The within-movie and cross-movie CHA predictions generated highly similar topographies (<xref ref-type="fig" rid="fig3">Figure 3</xref>). This result raises a fascinating question of whether different movie inputs estimate similar fine-grained connectivity profiles in the brain. Previous studies reported that the coarse-grained connectome (based on coarse parcellations) varies across separate cognitive tasks (<xref ref-type="bibr" rid="bib33">Shine et al., 2016</xref>; <xref ref-type="bibr" rid="bib34">Telesford et al., 2016</xref>), and that naturalistic movies yield the most condition-specific functional atlases among other classic cognitive tasks (<xref ref-type="bibr" rid="bib28">Salehi et al., 2020</xref>). In the Budapest and Sraiders datasets, the same group of participants watched the Grand Budapest Hotel and Raiders of the Lost Ark in different sessions in the same 3 T scanner. We built connectivity profiles for each participant separately for the two movies and correlated the two fine-grained connectomes in each searchlight. Results showed that the two fine-grained connectomes based on different movies were very similar in most of the brain regions (r&gt;0.8, <xref ref-type="fig" rid="fig4s9">Figure 4âfigure supplement 9A, B</xref>). We split each movie into two halves (Run 1â3/Run 4â5 for Budapest; Run 1â2/Run 3â4 for Sraiders) and averaged the connectome similarities across split halves over searchlights and participants. We found that the across-movie connectome similarities for split halves were high (r&gt;0.74), and the within-movie similarities were even higher in both datasets (r&gt;0.85, <xref ref-type="fig" rid="fig4s9">Figure 4âfigure supplement 9C</xref>). Our analysis showed that although the fine-grained connectome was affected by the input naturalistic stimulus content, it was nonetheless highly stable. This result suggested the brain may undergo shared cognitive processes across different movie free-viewing tasks. It could be because featured movies sample a broad range of real-life statistics, and the rich information elicits overall similar representations and connectivities when the entire time series is considered. Studies comparing movie-viewing and resting-state functional connectivity have shown that both paradigms yield overlapping macroscale cortical organizations (<xref ref-type="bibr" rid="bib29">Samara et al., 2023</xref>), though naturalistic viewing introduces unique modality-specific hierarchical gradients. However, there remains a gap in research comparing the fine-scaled connectomes of naturalistic and resting-state paradigms. <xref ref-type="bibr" rid="bib14">Guntupalli et al., 2018</xref>, revealed a shared fine-scale structure that coexists with the coarse-scale structure, and CHA successfully improved intersubject correlations across a wide variety of tasks. <xref ref-type="bibr" rid="bib8">Feilong et al., 2021</xref>, noted that the fine-scaled connectivity profiles in both resting and task states are highly predictive of general intelligence. This suggests a reliable and biologically relevant fine-scale resting-state connectivity structure among individuals. Therefore, it is plausible that individualized functional topography could be effectively estimated using resting-state functional connectivity, expanding the applicability of our approach. Future studies are needed to explore this direction.</p><p>The four datasets in our study included two types of category-selective localizers (dynamic and static). The dynamic localizer used short video clips for each category and the traditional static localizer used still images. For all categories, the dynamic localizer elicited stronger and broader category-selective activations than the static localizer, and the searchlight analysis showed that the dynamic localizer had higher reliabilities across the cortex, especially in regions that were selectively responsive to the target category. Due to differences between topographies activated by the dynamic and the static localizers, predictions across localizer types generated lower correlations than those within localizer types. For example, for the face-selective topographies, the dynamic localizer activated more areas than the static localizer (e.g., in superior temporal and frontal cortices). In the ventral temporal cortex, especially in the right hemisphere, both dynamic and static localizers performed well in the cross-localizer-type predictions. But in cortical areas where the static localizer did not match the dynamic localizer, predictions from the same dynamic localizer always outperformed the predictions from a different static localizer (<xref ref-type="fig" rid="fig4s1">Figure 4âfigure supplement 1</xref>, <xref ref-type="fig" rid="fig4s3">Figure 4âfigure supplement 3</xref>, and <xref ref-type="fig" rid="fig4s10">Figure 4âfigure supplement 10</xref>). The low correlations were not because the prediction method failed but reflected the difference in the topographies activated by different types of localizers.</p><p>This study successfully illustrated that accurate individualized predictions are both robust and applicable across a variety of conditions, including movie types, languages, scanning parameters, and scanner models. Importantly, the intricate connectivity profiles remain consistent even when participants view entirely different movies, as evidenced by <xref ref-type="fig" rid="fig4s9">Figure 4âfigure supplement 9</xref>, reinforcing the predictionâs stability in various scenarios. However, all four datasets in this study only included typical participants with anatomically intact brains. An unanswered question is whether individualized topographies of neuropsychological populations with atypical cortical function (e.g., developmental prosopagnosics) or with lesioned brains (e.g., acquired prosopagnosics) could also be accurately predicted using the hyperalignment-based methods. Up to now, as far as we know, no previous literature has investigated this question. Beyond neuropsychological groups, it is also valuable to investigate how well the predictions will be across a wide range of age, from infants to the elderly. Future research is essential to adapt our algorithms to diverse populations.</p><p>In summary, our study demonstrated that accurate predictions of individualized category-selective topographies can be achieved with high fidelity using CHA across different naturalistic movie contents, across different scanners, and across different scanning parameters. Compared to traditional functional localizers, naturalistic stimuli are more ecologically valid, engaging multiple cognitive systems in parallel, and more friendly to participants. Our method not only can be applied directly to current public and in-lab datasets, but has the important potential to allow researchers to derive a broad range of topographies based on naturalistic movies and a normative database in the future. By building such a database that comprises various high-quality topographies and naturalistic stimuli, our study opens the gate to new research possibilities that could integrate high-level cognitive functions across datasets from laboratories worldwide.</p></sec><sec id="s4" sec-type="materials|methods"><title>Materials and methods</title><sec id="s4-1"><title>Datasets</title><sec id="s4-1-1"><title>The Budapest dataset</title><p>The <italic>Budapest</italic> dataset included 20 participants (mean age 27.2 years, 10 females) for this analysis. These participants were scanned while watching both <italic>Grand Budapest Hotel</italic> and <italic>Raiders of the Lost Ark</italic> and were a subset of the dataset in <xref ref-type="bibr" rid="bib19">Jiahui et al., 2020</xref>. The <italic>Grand Budapest Hotel</italic> dataset contained five movie runs (~50 min, each part lasting 9â13 min each) and four dynamic localizer runs. Before entering the scanner, participants watched the first part of the movie (~45 min) outside. The rest of the movie was divided into five parts (each part lasting 9â13 min, ~50 min in total) and participants watched each part/run with audio. The dynamic localizer data were collected in a separate scanning section (<xref ref-type="bibr" rid="bib26">Pitcher et al., 2011</xref>). This dataset comprised four blocked-designed runs (3.9 min each), and each run comprised 10 blocks (18 s each), two per category (faces, bodies, scenes, objects, and scrambled objects). Each block comprised six 3-s-long video clips in random order. Participants did a one-back task during the localizer scan to maintain attention.</p><p>All scans in the Grand Budapest Hotel dataset were acquired using a 3 T S Magnetom Prisma MRI scanner with a 32-channel head coil at the Dartmouth Brain Imaging Center. BOLD images were acquired in an interleaved fashion using gradient-echo echo-planar imaging with pre-scan normalization, fat suppression, multiband (i.e., simultaneous multi-slice) acceleration factor of 4 (using blipped CAIPIRINHA), and no in-plane acceleration (i.e., GRAPPA acceleration factor of 1): TR/TE = 1000/33 ms, flip angle = 59Â°, resolution = 2.5 mm<sup>3</sup> isotropic voxels, matrix size = 96 Ã 96, FoV = 240 Ã 240 mm<sup>2</sup>, 52 axial slices with full brain coverage and no gap, anterior-posterior phase encoding. See more details in <xref ref-type="bibr" rid="bib38">Visconti di Oleggio Castello et al., 2020</xref>.</p></sec><sec id="s4-1-2"><title>The Sraiders dataset</title><p>The same participants were included for analysis in the <italic>Sraiders</italic> dataset as in the <italic>Budapest</italic> dataset. The movie <italic>Raiders of the Lost Ark</italic> was split into eight parts (~15 min each), and the first four parts were watched outside of the scanner prior to the scanning (~56 min). The later four parts were watched in the scanner (57 min) with audio (<xref ref-type="bibr" rid="bib23">Nastase, 2018</xref>). The <italic>Sraiders</italic> dataset and the <italic>Budapest</italic> dataset shared the same dynamic localizer data. The <italic>Sraiders</italic> dataset was collected with the same scan protocols as the <italic>Budapest</italic> dataset (<xref ref-type="bibr" rid="bib23">Nastase, 2018</xref>; <xref ref-type="bibr" rid="bib9">Feilong et al., 2022</xref>).</p></sec><sec id="s4-1-3"><title>The Forrest dataset</title><p>This dataset contains scans from 15 adults (mean age 29.4 years, 6 females). Participants were scanned at the Otto-von-Guericke University in Germany and were native German speakers (<xref ref-type="bibr" rid="bib16">Hanke et al., 2016</xref>; <xref ref-type="bibr" rid="bib32">Sengupta et al., 2016</xref>). The dataset is publicly available at <ext-link ext-link-type="uri" xlink:href="http://www.studyforrest.org/">http://www.studyforrest.org/</ext-link> (<xref ref-type="bibr" rid="bib15">Hanke et al., 2014</xref>). A shortened version of the movie <italic>Forrest Gump</italic> was divided into eight parts with each part lasting approximately 15 min. Participants watched each part/run in the scanner with audio (<xref ref-type="bibr" rid="bib16">Hanke et al., 2016</xref>). A category-selective localizer using still images was included in this dataset. This static localizer comprised four runs (5.2 min each). Each run comprised two 16 s blocks for each of the six categories (human faces, human bodies without heads, small objects, houses and outdoor scenes that include nature and street scenes, and phase scrambled images). In each block, 16 images from one category were displayed (900 ms display + 100 ms intertrial interval each). Participants were asked to do a one-back task to maintain attention.</p><p>Scanning was carried out using a whole-body 3 T Philips Achieva dStream MRI scanner equipped with a 32-channel head coil. Data were collected with gradient-echo, 2 s repetition time (TR), 30 ms echo time (TE), 90Â° flip angle, 1943 Hz/px bandwidth, and parallel acquisition with sensitivity encoding (SENSE) reduction factor 2. Each volume comprised 35 axial slices with anterior-to-posterior phase-encoding direction that were collected in ascending order, which mostly covered the entire brain. Each slice was 3.0 mm thick with a 10% inter-slice gap, and had a 240Ã240 mm<sup>2</sup> field-of-view comprising 80Ã80 3 mm<sup>2</sup> isotropic voxels. More acquisition parameters can be found in <xref ref-type="bibr" rid="bib16">Hanke et al., 2016</xref>, and <xref ref-type="bibr" rid="bib32">Sengupta et al., 2016</xref>.</p></sec><sec id="s4-1-4"><title>The Raiders dataset</title><p>A subset of nine participants from the original eleven participants (7 men, mean age = 24.8 years) participated in the face and object study at Dartmouth in <xref ref-type="bibr" rid="bib17">Haxby et al., 2011</xref>, and were included in this dataset. The audio-visual movie <italic>Raiders of the Lost Ark</italic> was split into eight parts (~15 min each), similarly to those used in the <italic>Sraiders</italic> Dataset. Participants watched all eight parts in the scanner with audio (one part/per run). The <italic>Raiders</italic> dataset contains a static localizer that was similarly designed as in the <italic>Forrest</italic> dataset.</p><p>Brain images were acquired using a 3 T Philips Intera Achieva scanner with an eight-channel head coil at Dartmouth College. For the movie study, whole-brain volumes of 413-mm-thick sagittal images (TR = 2.5 s, TE = 35 ms, flip angle = 90Â°, 80Ã80 matrix, FOV = 240Ã240 mm<sup>2</sup>, resolution = 0.938Ã0.938Ã1.0 mm<sup>3</sup>) were obtained in an interleaved slice order. For more details see <xref ref-type="bibr" rid="bib17">Haxby et al., 2011</xref>.</p></sec><sec id="s4-1-5"><title>MRI preprocessing</title><p>All datasets were preprocessed with fMRIPrep (<xref ref-type="bibr" rid="bib5">Esteban et al., 2019</xref>), using version 20.1.1 for the <italic>Budapest</italic> dataset, 20.2.0 for the <italic>Sraiders</italic> dataset, 20.1.1 for the <italic>Forrest</italic> dataset, and 20.1.1 for the <italic>Raiders</italic> dataset. After fMRIPrep, functional data were projected onto a standard cortical surface aligned to the fsaverage template (<xref ref-type="bibr" rid="bib10">Fischl et al., 1999</xref>) based on cortical folding patterns. The datasets were further preprocessed following <xref ref-type="bibr" rid="bib19">Jiahui et al., 2020</xref>; <xref ref-type="bibr" rid="bib7">Feilong et al., 2018</xref>. The datasets were resampled to a cortical mesh with 18,742 vertices across both hemispheres (approximately 3 mm vertex spacing; 20,484 vertices before removing non-cortical vertices). Six motion parameters and their derivatives, global signal, framewise displacement (<xref ref-type="bibr" rid="bib27">Power et al., 2014</xref>), six principal components from cerebrospinal fluid and white matter (<xref ref-type="bibr" rid="bib1">Behzadi et al., 2007</xref>), and polynomial trends up to second order were rf out from both movie and localizer data for each run independently.</p></sec></sec><sec id="s4-2"><title>Searchlight hyperalignment</title><sec id="s4-2-1"><title>CHA (step 1)</title><p>Each participantâs connectivity profile was built based on that participantâs movie data. We first defined the connectivity seeds and targets. In this analysis, the connectivity seeds were the same as the surface cortical vertices. The connectivity targets were defined using a sparser cortical surface with 642 vertices in each hemisphere before removing the medial wall. We then centered a 13 mm searchlight on each of these vertices and computed the average time series for the searchlight over vertices from the denser cortical model. The mean time series was assigned to the center vertex to serve as the connectivity target. For each hemisphere, the connectivity profile was calculated as the correlation between the connectivity seeds in this hemisphere and the whole-brain 1175 connectivity targets. The connectivity profile of each participant was normalized to zero mean and unit variance for each connectivity seed before hyperalignment.</p><p>We used an optimized hyperalignment method that directly transforms one participantâs connectivity profile to another participantâs cortical space, without the interim step of projecting the connectome into a common model space (<xref ref-type="bibr" rid="bib19">Jiahui et al., 2020</xref>). In detail, for each 15 mm searchlight, a participantâs patterns of connectivity to targets were aligned to another participantâs connectivity patterns using the Procrustes transformation. The transformation matrices from each searchlight in a hemisphere were then aggregated into a single transformation matrix for each pair of participants.</p></sec><sec id="s4-2-2"><title>Response hyperalignment</title><p>RHA was applied with the same steps as the CHA. The only difference is that instead of using connectivity profiles in each searchlight for each participant, we directly used the response pattern of the movie (time points of the movie Ã vertices in the searchlight) to align a pair of participants. In this method, response patterns in a pair of participants must be from neural responses to the same movie. Due to this restriction, RHA was only applied to participants from the same dataset.</p></sec><sec id="s4-2-3"><title>Advanced CHA</title><p>Using dense connectivity targets (e.g., using all 18,742 vertices on the surface) with anatomically aligned data usually generates poor functional correspondence across participants (<xref ref-type="bibr" rid="bib2">Busch et al., 2021</xref>). It is, however, beneficial to include more targets for calculating connectivity patterns after the first iteration of CHA and repeated iterations to lead to a better solution by gradually aligning the information at finer scales.</p><p>We used six steps to further improve the CHA method. Step 1 was the initial CHA step as described above that was based on the raw anatomically aligned movie data. The resultant transformation matrices were applied to those movie runs, and the hyperaligned data were then used in step 2 to calculate new connectivity patterns and calculate new transformation matrices. We repeated this procedure iteratively six times and derived transformation matrices for each step. In steps 1, 2, and 3, 642Ã2 (icoorder3, before removing the medial wall) connectivity targets were defined with 13 mm searchlights. In steps 4 and 5, 2562Ã2 (icoorder 4, before removing the medial wall) connectivity targets were used with 7 mm searchlights to calculate target mean time series. In the final step 6, all 18,742 vertices were included as separate connectivity targets, using each vertexâs time series rather than calculating the mean in a searchlight. Each step of this advanced CHA algorithm increased the prediction performance (<xref ref-type="fig" rid="fig4s2">Figure 4âfigure supplement 2</xref>).</p></sec></sec><sec id="s4-3"><title>Predicting individual contrast maps</title><sec id="s4-3-1"><title>Estimating contrast maps from each participantâs own localizer data</title><p>We estimated each participantâs category-selective maps by calculating the unthresholded GLM univariate contrasts using his/her own localizer data in each run and averaging the t-values across all the localizer runs. We included face-, body-, scene-, and object-selective maps in the analysis. The contrast maps in each category were calculated based on the contrast of the target category vs. all the other categories. For example, the face-selective map was calculated using faces vs. all the other categories in the localizer data (e.g., bodies, objects).</p></sec><sec id="s4-3-2"><title>Estimating contrast maps from other participantsâ localizer data</title><p>Transformation matrices from each participant to a target participant derived from hyperalignment were applied to the localizer runs of all other participants to project their localizer data into that target participantâs cortical anatomy. These hyperaligned localizer runs and anatomical surface aligned localizer runs were used separately for GLM univariate analysis for each run in each other participant, and then averaged across the t-maps from all runs and all other participants to estimate the target participantâs contrast maps for each category.</p><p>In summary, each participantâs category-selective map was estimated based on that target participantâs own localizer data and on all other participantsâ localizer data that was projected into that participantâs cortical space using hyperalignment and anatomical surface alignment (see <xref ref-type="fig" rid="fig1s1">Figure 1âfigure supplement 1</xref>). After obtaining these estimated maps, we calculated correlations between the target participantâs category-selective maps based on his/her own localizer data and the maps estimated from other participantsâ data (hyperaligned or anatomically aligned). We also calculated Cronbachâs alpha values (<xref ref-type="bibr" rid="bib19">Jiahui et al., 2020</xref>; <xref ref-type="bibr" rid="bib7">Feilong et al., 2018</xref>; <xref ref-type="bibr" rid="bib20">Jiahui et al., 2022</xref>) across the multiple runs to measure the reliability of the category-selective maps for each participant and compared the correlations to the reliability values. Cronbachâs alpha calculates the correlation score between localizer-based maps across the runs, and it reflects the amount of noise in maps based on individual localizer runs. Traditionally, the reliability was estimated based on split-half correlations. The common odd/even split measure underestimated reliability and necessitated recalculation of correlations between maps for only half the data to provide valid comparisons. In contrast, Cronbachâs alpha involves all localizer runs and provides a more accurate statistical estimate of the reliability of the topographies estimated with localizer runs. To measure the local estimation performance and compare that to local reliabilities, we calculated correlations and Cronbachâs alphas in searchlights with a radius of 15 mm.</p></sec></sec></sec></body><back><sec sec-type="additional-information" id="s5"><title>Additional information</title><fn-group content-type="competing-interest"><title>Competing interests</title><fn fn-type="COI-statement" id="conf1"><p>No competing interests declared</p></fn></fn-group><fn-group content-type="author-contribution"><title>Author contributions</title><fn fn-type="con" id="con1"><p>Conceptualization, Formal analysis, Investigation, Methodology, Software, Visualization, Writing â original draft, Writing â review and editing</p></fn><fn fn-type="con" id="con2"><p>Writing â original draft, Writing â review and editing, Investigation, Methodology</p></fn><fn fn-type="con" id="con3"><p>Writing â original draft, Methodology</p></fn><fn fn-type="con" id="con4"><p>Conceptualization, Resources, Supervision, Funding acquisition, Investigation, Visualization, Methodology</p></fn><fn fn-type="con" id="con5"><p>Conceptualization, Resources, Supervision, Funding acquisition, Investigation, Visualization, Methodology</p></fn></fn-group><fn-group content-type="ethics-information"><title>Ethics</title><fn fn-type="other"><p>All participants gave their written informed consent to participate in the study. Data collection of the Forrest dataset was approved by the Ethics Committee of Otto-von-Guericke University (approval reference 37/13). Data collection of the other datasets (Raiders, Budapest, SRaiders) were approved by the Dartmouth Committee for the Protection of Human Subjects.</p></fn></fn-group></sec><sec sec-type="supplementary-material" id="s6"><title>Additional files</title><supplementary-material id="mdar"><label>MDAR checklist</label><media xlink:href="elife-86037-mdarchecklist1-v1.docx" mimetype="application" mime-subtype="docx"/></supplementary-material></sec><sec sec-type="data-availability" id="s7"><title>Data availability</title><p>All data needed to evaluate the conclusions in the paper are present in the paper and/or the Supplementary Materials. Additional data and materials that support the findings of this study can be found at <ext-link ext-link-type="uri" xlink:href="https://github.com/GUO-Jiahui/CHA_Cross-Movie_Prediction">https://github.com/GUO-Jiahui/CHA_Cross-Movie_Prediction</ext-link>; (copy archived at <xref ref-type="bibr" rid="bib21">Jiahui, 2023</xref>).</p><p>The following previously published datasets were used:</p><p><element-citation publication-type="data" specific-use="references" id="dataset1"><person-group person-group-type="author"><name><surname>Speck</surname><given-names>O</given-names></name><name><surname>Hanke</surname><given-names>M</given-names></name><name><surname>Baumgartner</surname><given-names>FJ</given-names></name><name><surname>Ibe</surname><given-names>P</given-names></name><name><surname>Kaule</surname><given-names>FR</given-names></name><name><surname>Pollmann</surname><given-names>S</given-names></name><name><surname>Speck</surname><given-names>O</given-names></name><name><surname>Zinke</surname><given-names>W</given-names></name><name><surname>Stadler</surname><given-names>J</given-names></name></person-group><year iso-8601-date="2018">2018</year><data-title>Forrest Gump</data-title><source>OpenNeuro</source><pub-id pub-id-type="accession" xlink:href="https://openneuro.org/datasets/ds000113">ds000113</pub-id></element-citation></p><p><element-citation publication-type="data" specific-use="references" id="dataset2"><person-group person-group-type="author"><name><surname>Oleggio Castello</surname><given-names>MVD</given-names></name><name><surname>Chauhan</surname><given-names>V</given-names></name><name><surname>Jiahui</surname><given-names>G</given-names></name><name><surname>Gobbini</surname><given-names>MI</given-names></name></person-group><year iso-8601-date="2020">2020</year><data-title>An fMRI dataset in response to 'The Grand Budapest Hotel', a socially-rich, naturalistic movie</data-title><source>OpenNeuro</source><pub-id pub-id-type="accession" xlink:href="https://openneuro.org/datasets/ds003017">ds003017</pub-id></element-citation></p></sec><ack id="ack"><title>Acknowledgements</title><p>This work was supported by NSF grants 1607845 (JVH) and 1835200 (MIG), and NIH grant R01 MH127199 (JVH and MIG).</p></ack><ref-list><title>References</title><ref id="bib1"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Behzadi</surname><given-names>Y</given-names></name><name><surname>Restom</surname><given-names>K</given-names></name><name><surname>Liau</surname><given-names>J</given-names></name><name><surname>Liu</surname><given-names>TT</given-names></name></person-group><year iso-8601-date="2007">2007</year><article-title>A component based noise correction method (CompCor) for BOLD and perfusion based fMRI</article-title><source>NeuroImage</source><volume>37</volume><fpage>90</fpage><lpage>101</lpage><pub-id pub-id-type="doi">10.1016/j.neuroimage.2007.04.042</pub-id><pub-id pub-id-type="pmid">17560126</pub-id></element-citation></ref><ref id="bib2"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Busch</surname><given-names>EL</given-names></name><name><surname>Slipski</surname><given-names>L</given-names></name><name><surname>Feilong</surname><given-names>M</given-names></name><name><surname>Guntupalli</surname><given-names>JS</given-names></name><name><surname>Castello</surname><given-names>MVO</given-names></name><name><surname>Huckins</surname><given-names>JF</given-names></name><name><surname>Nastase</surname><given-names>SA</given-names></name><name><surname>Gobbini</surname><given-names>MI</given-names></name><name><surname>Wager</surname><given-names>TD</given-names></name><name><surname>Haxby</surname><given-names>JV</given-names></name></person-group><year iso-8601-date="2021">2021</year><article-title>Hybrid hyperalignment: A single high-dimensional model of shared information embedded in cortical patterns of response and functional connectivity</article-title><source>NeuroImage</source><volume>233</volume><elocation-id>117975</elocation-id><pub-id pub-id-type="doi">10.1016/j.neuroimage.2021.117975</pub-id><pub-id pub-id-type="pmid">33762217</pub-id></element-citation></ref><ref id="bib3"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Downing</surname><given-names>PE</given-names></name><name><surname>Jiang</surname><given-names>Y</given-names></name><name><surname>Shuman</surname><given-names>M</given-names></name><name><surname>Kanwisher</surname><given-names>N</given-names></name></person-group><year iso-8601-date="2001">2001</year><article-title>A cortical area selective for visual processing of the human body</article-title><source>Science</source><volume>293</volume><fpage>2470</fpage><lpage>2473</lpage><pub-id pub-id-type="doi">10.1126/science.1063414</pub-id><pub-id pub-id-type="pmid">11577239</pub-id></element-citation></ref><ref id="bib4"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Epstein</surname><given-names>R</given-names></name><name><surname>Harris</surname><given-names>A</given-names></name><name><surname>Stanley</surname><given-names>D</given-names></name><name><surname>Kanwisher</surname><given-names>N</given-names></name></person-group><year iso-8601-date="1999">1999</year><article-title>The parahippocampal place area</article-title><source>Neuron</source><volume>23</volume><fpage>115</fpage><lpage>125</lpage><pub-id pub-id-type="doi">10.1016/S0896-6273(00)80758-8</pub-id></element-citation></ref><ref id="bib5"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Esteban</surname><given-names>O</given-names></name><name><surname>Markiewicz</surname><given-names>CJ</given-names></name><name><surname>Blair</surname><given-names>RW</given-names></name><name><surname>Moodie</surname><given-names>CA</given-names></name><name><surname>Isik</surname><given-names>AI</given-names></name><name><surname>Erramuzpe</surname><given-names>A</given-names></name><name><surname>Kent</surname><given-names>JD</given-names></name><name><surname>Goncalves</surname><given-names>M</given-names></name><name><surname>DuPre</surname><given-names>E</given-names></name><name><surname>Snyder</surname><given-names>M</given-names></name><name><surname>Oya</surname><given-names>H</given-names></name><name><surname>Ghosh</surname><given-names>SS</given-names></name><name><surname>Wright</surname><given-names>J</given-names></name><name><surname>Durnez</surname><given-names>J</given-names></name><name><surname>Poldrack</surname><given-names>RA</given-names></name><name><surname>Gorgolewski</surname><given-names>KJ</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>fMRIPrep: a robust preprocessing pipeline for functional MRI</article-title><source>Nature Methods</source><volume>16</volume><fpage>111</fpage><lpage>116</lpage><pub-id pub-id-type="doi">10.1038/s41592-018-0235-4</pub-id></element-citation></ref><ref id="bib6"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Fedorenko</surname><given-names>E</given-names></name><name><surname>Hsieh</surname><given-names>PJ</given-names></name><name><surname>Nieto-CastaÃ±Ã³n</surname><given-names>A</given-names></name><name><surname>Whitfield-Gabrieli</surname><given-names>S</given-names></name><name><surname>Kanwisher</surname><given-names>N</given-names></name></person-group><year iso-8601-date="2010">2010</year><article-title>New method for fMRI investigations of language: defining ROIs functionally in individual subjects</article-title><source>Journal of Neurophysiology</source><volume>104</volume><fpage>1177</fpage><lpage>1194</lpage><pub-id pub-id-type="doi">10.1152/jn.00032.2010</pub-id><pub-id pub-id-type="pmid">20410363</pub-id></element-citation></ref><ref id="bib7"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Feilong</surname><given-names>M</given-names></name><name><surname>Nastase</surname><given-names>SA</given-names></name><name><surname>Guntupalli</surname><given-names>JS</given-names></name><name><surname>Haxby</surname><given-names>JV</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>Reliable individual differences in fine-grained cortical functional architecture</article-title><source>NeuroImage</source><volume>183</volume><fpage>375</fpage><lpage>386</lpage><pub-id pub-id-type="doi">10.1016/j.neuroimage.2018.08.029</pub-id><pub-id pub-id-type="pmid">30118870</pub-id></element-citation></ref><ref id="bib8"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Feilong</surname><given-names>M</given-names></name><name><surname>Guntupalli</surname><given-names>JS</given-names></name><name><surname>Haxby</surname><given-names>JV</given-names></name></person-group><year iso-8601-date="2021">2021</year><article-title>The neural basis of intelligence in fine-grained cortical topographies</article-title><source>eLife</source><volume>10</volume><elocation-id>e64058</elocation-id><pub-id pub-id-type="doi">10.7554/eLife.64058</pub-id><pub-id pub-id-type="pmid">33683205</pub-id></element-citation></ref><ref id="bib9"><element-citation publication-type="preprint"><person-group person-group-type="author"><name><surname>Feilong</surname><given-names>M</given-names></name><name><surname>Nastase</surname><given-names>SA</given-names></name><name><surname>Jiahui</surname><given-names>G</given-names></name><name><surname>Halchenko</surname><given-names>YO</given-names></name><name><surname>Gobbini</surname><given-names>MI</given-names></name><name><surname>Haxby</surname><given-names>JV</given-names></name></person-group><year iso-8601-date="2022">2022</year><article-title>The Individualized Neural Tuning Model: Precise and Generalizable Cartography of Functional Architecture in Individual Brains</article-title><source>bioRxiv</source><pub-id pub-id-type="doi">10.1101/2022.05.15.492022</pub-id></element-citation></ref><ref id="bib10"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Fischl</surname><given-names>B</given-names></name><name><surname>Sereno</surname><given-names>MI</given-names></name><name><surname>Dale</surname><given-names>AM</given-names></name></person-group><year iso-8601-date="1999">1999</year><article-title>Cortical surface-based analysis. II: inflation, flattening, and a surface-based coordinate system</article-title><source>NeuroImage</source><volume>9</volume><fpage>195</fpage><lpage>207</lpage><pub-id pub-id-type="doi">10.1006/nimg.1998.0396</pub-id><pub-id pub-id-type="pmid">9931269</pub-id></element-citation></ref><ref id="bib11"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Fox</surname><given-names>CJ</given-names></name><name><surname>Iaria</surname><given-names>G</given-names></name><name><surname>Barton</surname><given-names>JJS</given-names></name></person-group><year iso-8601-date="2009">2009</year><article-title>Defining the face processing network: optimization of the functional localizer in fMRI</article-title><source>Human Brain Mapping</source><volume>30</volume><fpage>1637</fpage><lpage>1651</lpage><pub-id pub-id-type="doi">10.1002/hbm.20630</pub-id><pub-id pub-id-type="pmid">18661501</pub-id></element-citation></ref><ref id="bib12"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Grill-Spector</surname><given-names>K</given-names></name><name><surname>Weiner</surname><given-names>KS</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>The functional architecture of the ventral temporal cortex and its role in categorization</article-title><source>Nature Reviews. Neuroscience</source><volume>15</volume><fpage>536</fpage><lpage>548</lpage><pub-id pub-id-type="doi">10.1038/nrn3747</pub-id><pub-id pub-id-type="pmid">24962370</pub-id></element-citation></ref><ref id="bib13"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Guntupalli</surname><given-names>JS</given-names></name><name><surname>Hanke</surname><given-names>M</given-names></name><name><surname>Halchenko</surname><given-names>YO</given-names></name><name><surname>Connolly</surname><given-names>AC</given-names></name><name><surname>Ramadge</surname><given-names>PJ</given-names></name><name><surname>Haxby</surname><given-names>JV</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>A model of representational spaces in human cortex</article-title><source>Cerebral Cortex</source><volume>26</volume><fpage>2919</fpage><lpage>2934</lpage><pub-id pub-id-type="doi">10.1093/cercor/bhw068</pub-id><pub-id pub-id-type="pmid">26980615</pub-id></element-citation></ref><ref id="bib14"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Guntupalli</surname><given-names>JS</given-names></name><name><surname>Feilong</surname><given-names>M</given-names></name><name><surname>Haxby</surname><given-names>JV</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>A computational model of shared fine-scale structure in the human connectome</article-title><source>PLOS Computational Biology</source><volume>14</volume><elocation-id>e1006120</elocation-id><pub-id pub-id-type="doi">10.1371/journal.pcbi.1006120</pub-id><pub-id pub-id-type="pmid">29664910</pub-id></element-citation></ref><ref id="bib15"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hanke</surname><given-names>M</given-names></name><name><surname>Baumgartner</surname><given-names>FJ</given-names></name><name><surname>Ibe</surname><given-names>P</given-names></name><name><surname>Kaule</surname><given-names>FR</given-names></name><name><surname>Pollmann</surname><given-names>S</given-names></name><name><surname>Speck</surname><given-names>O</given-names></name><name><surname>Zinke</surname><given-names>W</given-names></name><name><surname>Stadler</surname><given-names>J</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>A high-resolution 7-Tesla fMRI dataset from complex natural stimulation with an audio movie</article-title><source>Scientific Data</source><volume>1</volume><elocation-id>140003</elocation-id><pub-id pub-id-type="doi">10.1038/sdata.2014.3</pub-id><pub-id pub-id-type="pmid">25977761</pub-id></element-citation></ref><ref id="bib16"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hanke</surname><given-names>M</given-names></name><name><surname>AdelhÃ¶fer</surname><given-names>N</given-names></name><name><surname>Kottke</surname><given-names>D</given-names></name><name><surname>Iacovella</surname><given-names>V</given-names></name><name><surname>Sengupta</surname><given-names>A</given-names></name><name><surname>Kaule</surname><given-names>FR</given-names></name><name><surname>Nigbur</surname><given-names>R</given-names></name><name><surname>Waite</surname><given-names>AQ</given-names></name><name><surname>Baumgartner</surname><given-names>F</given-names></name><name><surname>Stadler</surname><given-names>J</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>A studyforrest extension, simultaneous fMRI and eye gaze recordings during prolonged natural stimulation</article-title><source>Scientific Data</source><volume>3</volume><elocation-id>160092</elocation-id><pub-id pub-id-type="doi">10.1038/sdata.2016.92</pub-id><pub-id pub-id-type="pmid">27779621</pub-id></element-citation></ref><ref id="bib17"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Haxby</surname><given-names>JV</given-names></name><name><surname>Guntupalli</surname><given-names>JS</given-names></name><name><surname>Connolly</surname><given-names>AC</given-names></name><name><surname>Halchenko</surname><given-names>YO</given-names></name><name><surname>Conroy</surname><given-names>BR</given-names></name><name><surname>Gobbini</surname><given-names>MI</given-names></name><name><surname>Hanke</surname><given-names>M</given-names></name><name><surname>Ramadge</surname><given-names>PJ</given-names></name><name><surname>Common</surname><given-names>A</given-names></name></person-group><year iso-8601-date="2011">2011</year><article-title>A common, high-dimensional model of the representational space in human ventral temporal cortex</article-title><source>Neuron</source><volume>72</volume><fpage>404</fpage><lpage>416</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2011.08.026</pub-id><pub-id pub-id-type="pmid">22017997</pub-id></element-citation></ref><ref id="bib18"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hermundstad</surname><given-names>AM</given-names></name><name><surname>Bassett</surname><given-names>DS</given-names></name><name><surname>Brown</surname><given-names>KS</given-names></name><name><surname>Aminoff</surname><given-names>EM</given-names></name><name><surname>Clewett</surname><given-names>D</given-names></name><name><surname>Freeman</surname><given-names>S</given-names></name><name><surname>Frithsen</surname><given-names>A</given-names></name><name><surname>Johnson</surname><given-names>A</given-names></name><name><surname>Tipper</surname><given-names>CM</given-names></name><name><surname>Miller</surname><given-names>MB</given-names></name><name><surname>Grafton</surname><given-names>ST</given-names></name><name><surname>Carlson</surname><given-names>JM</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>Structural foundations of resting-state and task-based functional connectivity in the human brain</article-title><source>PNAS</source><volume>110</volume><fpage>6169</fpage><lpage>6174</lpage><pub-id pub-id-type="doi">10.1073/pnas.1219562110</pub-id><pub-id pub-id-type="pmid">23530246</pub-id></element-citation></ref><ref id="bib19"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Jiahui</surname><given-names>G</given-names></name><name><surname>Feilong</surname><given-names>M</given-names></name><name><surname>Visconti di Oleggio Castello</surname><given-names>M</given-names></name><name><surname>Guntupalli</surname><given-names>JS</given-names></name><name><surname>Chauhan</surname><given-names>V</given-names></name><name><surname>Haxby</surname><given-names>JV</given-names></name><name><surname>Gobbini</surname><given-names>MI</given-names></name></person-group><year iso-8601-date="2020">2020</year><article-title>Predicting individual face-selective topography using naturalistic stimuli</article-title><source>NeuroImage</source><volume>216</volume><elocation-id>116458</elocation-id><pub-id pub-id-type="doi">10.1016/j.neuroimage.2019.116458</pub-id><pub-id pub-id-type="pmid">31843709</pub-id></element-citation></ref><ref id="bib20"><element-citation publication-type="preprint"><person-group person-group-type="author"><name><surname>Jiahui</surname><given-names>G</given-names></name><name><surname>Feilong</surname><given-names>M</given-names></name><name><surname>Visconti di Oleggio Castello</surname><given-names>M</given-names></name><name><surname>Nastase</surname><given-names>SA</given-names></name><name><surname>Haxby</surname><given-names>JV</given-names></name><name><surname>Gobbini</surname><given-names>MI</given-names></name></person-group><year iso-8601-date="2022">2022</year><article-title>Modeling Naturalistic Face Processing in Humans with Deep Convolutional Neural Networks</article-title><source>bioRxiv</source><pub-id pub-id-type="doi">10.1101/2021.11.17.469009</pub-id></element-citation></ref><ref id="bib21"><element-citation publication-type="software"><person-group person-group-type="author"><name><surname>Jiahui</surname><given-names>G</given-names></name></person-group><year iso-8601-date="2023">2023</year><data-title>Cha_Cross-Movie_Prediction</data-title><version designator="swh:1:rev:6b3c1e8c222fff618a904590f9faaf062851c27d">swh:1:rev:6b3c1e8c222fff618a904590f9faaf062851c27d</version><source>Software Heritage</source><ext-link ext-link-type="uri" xlink:href="https://archive.softwareheritage.org/swh:1:dir:a1b5cdf0b5cdbad868d166af7743ed7470bbb122;origin=https://github.com/GUO-Jiahui/CHA_Cross-Movie_Prediction;visit=swh:1:snp:e94144cc5984a33815270736238503631d917cec;anchor=swh:1:rev:6b3c1e8c222fff618a904590f9faaf062851c27d">https://archive.softwareheritage.org/swh:1:dir:a1b5cdf0b5cdbad868d166af7743ed7470bbb122;origin=https://github.com/GUO-Jiahui/CHA_Cross-Movie_Prediction;visit=swh:1:snp:e94144cc5984a33815270736238503631d917cec;anchor=swh:1:rev:6b3c1e8c222fff618a904590f9faaf062851c27d</ext-link></element-citation></ref><ref id="bib22"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kanwisher</surname><given-names>N</given-names></name><name><surname>McDermott</surname><given-names>J</given-names></name><name><surname>Chun</surname><given-names>MM</given-names></name></person-group><year iso-8601-date="1997">1997</year><article-title>The fusiform face area: A module in human extrastriate cortex specialized for face perception</article-title><source>The Journal of Neuroscience</source><volume>17</volume><fpage>4302</fpage><lpage>4311</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.17-11-04302.1997</pub-id><pub-id pub-id-type="pmid">9151747</pub-id></element-citation></ref><ref id="bib23"><element-citation publication-type="thesis"><person-group person-group-type="author"><name><surname>Nastase</surname><given-names>SA</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>The Geometry of Observed Action Representation During Natural Vision</article-title><publisher-name>Dartmouth College</publisher-name></element-citation></ref><ref id="bib24"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Nastase</surname><given-names>SA</given-names></name><name><surname>Liu</surname><given-names>YF</given-names></name><name><surname>Hillman</surname><given-names>H</given-names></name><name><surname>Norman</surname><given-names>KA</given-names></name><name><surname>Hasson</surname><given-names>U</given-names></name></person-group><year iso-8601-date="2020">2020</year><article-title>Leveraging shared connectivity to aggregate heterogeneous datasets into a common response space</article-title><source>NeuroImage</source><volume>217</volume><elocation-id>116865</elocation-id><pub-id pub-id-type="doi">10.1016/j.neuroimage.2020.116865</pub-id><pub-id pub-id-type="pmid">32325212</pub-id></element-citation></ref><ref id="bib25"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Osher</surname><given-names>DE</given-names></name><name><surname>Saxe</surname><given-names>RR</given-names></name><name><surname>Koldewyn</surname><given-names>K</given-names></name><name><surname>Gabrieli</surname><given-names>JDE</given-names></name><name><surname>Kanwisher</surname><given-names>N</given-names></name><name><surname>Saygin</surname><given-names>ZM</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Structural connectivity fingerprints predict cortical selectivity for multiple visual categories across cortex</article-title><source>Cerebral Cortex</source><volume>26</volume><fpage>1668</fpage><lpage>1683</lpage><pub-id pub-id-type="doi">10.1093/cercor/bhu303</pub-id></element-citation></ref><ref id="bib26"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Pitcher</surname><given-names>D</given-names></name><name><surname>Dilks</surname><given-names>DD</given-names></name><name><surname>Saxe</surname><given-names>RR</given-names></name><name><surname>Triantafyllou</surname><given-names>C</given-names></name><name><surname>Kanwisher</surname><given-names>N</given-names></name></person-group><year iso-8601-date="2011">2011</year><article-title>Differential selectivity for dynamic versus static information in face-selective cortical regions</article-title><source>NeuroImage</source><volume>56</volume><fpage>2356</fpage><lpage>2363</lpage><pub-id pub-id-type="doi">10.1016/j.neuroimage.2011.03.067</pub-id><pub-id pub-id-type="pmid">21473921</pub-id></element-citation></ref><ref id="bib27"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Power</surname><given-names>JD</given-names></name><name><surname>Mitra</surname><given-names>A</given-names></name><name><surname>Laumann</surname><given-names>TO</given-names></name><name><surname>Snyder</surname><given-names>AZ</given-names></name><name><surname>Schlaggar</surname><given-names>BL</given-names></name><name><surname>Petersen</surname><given-names>SE</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>Methods to detect, characterize, and remove motion artifact in resting state fMRI</article-title><source>NeuroImage</source><volume>84</volume><fpage>320</fpage><lpage>341</lpage><pub-id pub-id-type="doi">10.1016/j.neuroimage.2013.08.048</pub-id><pub-id pub-id-type="pmid">23994314</pub-id></element-citation></ref><ref id="bib28"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Salehi</surname><given-names>M</given-names></name><name><surname>Greene</surname><given-names>AS</given-names></name><name><surname>Karbasi</surname><given-names>A</given-names></name><name><surname>Shen</surname><given-names>X</given-names></name><name><surname>Scheinost</surname><given-names>D</given-names></name><name><surname>Constable</surname><given-names>RT</given-names></name></person-group><year iso-8601-date="2020">2020</year><article-title>There is no single functional atlas even for a single individual: Functional parcel definitions change with task</article-title><source>NeuroImage</source><volume>208</volume><elocation-id>116366</elocation-id><pub-id pub-id-type="doi">10.1016/j.neuroimage.2019.116366</pub-id><pub-id pub-id-type="pmid">31740342</pub-id></element-citation></ref><ref id="bib29"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Samara</surname><given-names>A</given-names></name><name><surname>Eilbott</surname><given-names>J</given-names></name><name><surname>Margulies</surname><given-names>DS</given-names></name><name><surname>Xu</surname><given-names>T</given-names></name><name><surname>Vanderwal</surname><given-names>T</given-names></name></person-group><year iso-8601-date="2023">2023</year><article-title>Cortical gradients during naturalistic processing are hierarchical and modality-specific</article-title><source>NeuroImage</source><volume>271</volume><elocation-id>120023</elocation-id><pub-id pub-id-type="doi">10.1016/j.neuroimage.2023.120023</pub-id><pub-id pub-id-type="pmid">36921679</pub-id></element-citation></ref><ref id="bib30"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Saxe</surname><given-names>R</given-names></name><name><surname>Brett</surname><given-names>M</given-names></name><name><surname>Kanwisher</surname><given-names>N</given-names></name></person-group><year iso-8601-date="2006">2006</year><article-title>Divide and conquer: a defense of functional localizers</article-title><source>NeuroImage</source><volume>30</volume><fpage>1088</fpage><lpage>1096</lpage><pub-id pub-id-type="doi">10.1016/j.neuroimage.2005.12.062</pub-id><pub-id pub-id-type="pmid">16635578</pub-id></element-citation></ref><ref id="bib31"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Saygin</surname><given-names>ZM</given-names></name><name><surname>Osher</surname><given-names>DE</given-names></name><name><surname>Koldewyn</surname><given-names>K</given-names></name><name><surname>Reynolds</surname><given-names>G</given-names></name><name><surname>Gabrieli</surname><given-names>JDE</given-names></name><name><surname>Saxe</surname><given-names>RR</given-names></name></person-group><year iso-8601-date="2012">2012</year><article-title>Anatomical connectivity patterns predict face selectivity in the fusiform gyrus</article-title><source>Nature Neuroscience</source><volume>15</volume><fpage>321</fpage><lpage>327</lpage><pub-id pub-id-type="doi">10.1038/nn.3001</pub-id><pub-id pub-id-type="pmid">22197830</pub-id></element-citation></ref><ref id="bib32"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Sengupta</surname><given-names>A</given-names></name><name><surname>Kaule</surname><given-names>FR</given-names></name><name><surname>Guntupalli</surname><given-names>JS</given-names></name><name><surname>Hoffmann</surname><given-names>MB</given-names></name><name><surname>HÃ¤usler</surname><given-names>C</given-names></name><name><surname>Stadler</surname><given-names>J</given-names></name><name><surname>Hanke</surname><given-names>M</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>A studyforrest extension, retinotopic mapping and localization of higher visual areas</article-title><source>Scientific Data</source><volume>3</volume><elocation-id>160093</elocation-id><pub-id pub-id-type="doi">10.1038/sdata.2016.93</pub-id><pub-id pub-id-type="pmid">27779618</pub-id></element-citation></ref><ref id="bib33"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Shine</surname><given-names>JM</given-names></name><name><surname>Bissett</surname><given-names>PG</given-names></name><name><surname>Bell</surname><given-names>PT</given-names></name><name><surname>Koyejo</surname><given-names>O</given-names></name><name><surname>Balsters</surname><given-names>JH</given-names></name><name><surname>Gorgolewski</surname><given-names>KJ</given-names></name><name><surname>Moodie</surname><given-names>CA</given-names></name><name><surname>Poldrack</surname><given-names>RA</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>The dynamics of functional brain networks: Integrated network states during cognitive task performance</article-title><source>Neuron</source><volume>92</volume><fpage>544</fpage><lpage>554</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2016.09.018</pub-id><pub-id pub-id-type="pmid">27693256</pub-id></element-citation></ref><ref id="bib34"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Telesford</surname><given-names>QK</given-names></name><name><surname>Lynall</surname><given-names>ME</given-names></name><name><surname>Vettel</surname><given-names>J</given-names></name><name><surname>Miller</surname><given-names>MB</given-names></name><name><surname>Grafton</surname><given-names>ST</given-names></name><name><surname>Bassett</surname><given-names>DS</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Detection of functional brain network reconfiguration during task-driven cognitive states</article-title><source>NeuroImage</source><volume>142</volume><fpage>198</fpage><lpage>210</lpage><pub-id pub-id-type="doi">10.1016/j.neuroimage.2016.05.078</pub-id><pub-id pub-id-type="pmid">27261162</pub-id></element-citation></ref><ref id="bib35"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Vanderwal</surname><given-names>T</given-names></name><name><surname>Kelly</surname><given-names>C</given-names></name><name><surname>Eilbott</surname><given-names>J</given-names></name><name><surname>Mayes</surname><given-names>LC</given-names></name><name><surname>Castellanos</surname><given-names>FX</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>Inscapes: A movie paradigm to improve compliance in functional magnetic resonance imaging</article-title><source>NeuroImage</source><volume>122</volume><fpage>222</fpage><lpage>232</lpage><pub-id pub-id-type="doi">10.1016/j.neuroimage.2015.07.069</pub-id><pub-id pub-id-type="pmid">26241683</pub-id></element-citation></ref><ref id="bib36"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Vanderwal</surname><given-names>T</given-names></name><name><surname>Eilbott</surname><given-names>J</given-names></name><name><surname>Finn</surname><given-names>ES</given-names></name><name><surname>Craddock</surname><given-names>RC</given-names></name><name><surname>Turnbull</surname><given-names>A</given-names></name><name><surname>Castellanos</surname><given-names>FX</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>Individual differences in functional connectivity during naturalistic viewing conditions</article-title><source>NeuroImage</source><volume>157</volume><fpage>521</fpage><lpage>530</lpage><pub-id pub-id-type="doi">10.1016/j.neuroimage.2017.06.027</pub-id><pub-id pub-id-type="pmid">28625875</pub-id></element-citation></ref><ref id="bib37"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Vanderwal</surname><given-names>T</given-names></name><name><surname>Eilbott</surname><given-names>J</given-names></name><name><surname>Castellanos</surname><given-names>FX</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>Movies in the magnet: Naturalistic paradigms in developmental functional neuroimaging</article-title><source>Developmental Cognitive Neuroscience</source><volume>36</volume><elocation-id>100600</elocation-id><pub-id pub-id-type="doi">10.1016/j.dcn.2018.10.004</pub-id><pub-id pub-id-type="pmid">30551970</pub-id></element-citation></ref><ref id="bib38"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Visconti di Oleggio Castello</surname><given-names>M</given-names></name><name><surname>Chauhan</surname><given-names>V</given-names></name><name><surname>Jiahui</surname><given-names>G</given-names></name><name><surname>Gobbini</surname><given-names>MI</given-names></name></person-group><year iso-8601-date="2020">2020</year><article-title>An fMRI dataset in response to âThe Grand Budapest Hotelâ, a socially-rich, naturalistic movie</article-title><source>Scientific Data</source><volume>7</volume><elocation-id>383</elocation-id><pub-id pub-id-type="doi">10.1038/s41597-020-00735-4</pub-id><pub-id pub-id-type="pmid">33177526</pub-id></element-citation></ref><ref id="bib39"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Zhen</surname><given-names>Z</given-names></name><name><surname>Yang</surname><given-names>Z</given-names></name><name><surname>Huang</surname><given-names>L</given-names></name><name><surname>Kong</surname><given-names>X-Z</given-names></name><name><surname>Wang</surname><given-names>X</given-names></name><name><surname>Dang</surname><given-names>X</given-names></name><name><surname>Huang</surname><given-names>Y</given-names></name><name><surname>Song</surname><given-names>Y</given-names></name><name><surname>Liu</surname><given-names>J</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>Quantifying interindividual variability and asymmetry of face-selective regions: A probabilistic functional atlas</article-title><source>NeuroImage</source><volume>113</volume><fpage>13</fpage><lpage>25</lpage><pub-id pub-id-type="doi">10.1016/j.neuroimage.2015.03.010</pub-id><pub-id pub-id-type="pmid">25772668</pub-id></element-citation></ref><ref id="bib40"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Zhen</surname><given-names>Z</given-names></name><name><surname>Kong</surname><given-names>XZ</given-names></name><name><surname>Huang</surname><given-names>L</given-names></name><name><surname>Yang</surname><given-names>Z</given-names></name><name><surname>Wang</surname><given-names>X</given-names></name><name><surname>Hao</surname><given-names>X</given-names></name><name><surname>Huang</surname><given-names>T</given-names></name><name><surname>Song</surname><given-names>Y</given-names></name><name><surname>Liu</surname><given-names>J</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>Quantifying the variability of scene-selective regions: Interindividual, interhemispheric, and sex differences</article-title><source>Human Brain Mapping</source><volume>38</volume><fpage>2260</fpage><lpage>2275</lpage><pub-id pub-id-type="doi">10.1002/hbm.23519</pub-id><pub-id pub-id-type="pmid">28117508</pub-id></element-citation></ref></ref-list></back><sub-article article-type="editor-report" id="sa0"><front-stub><article-id pub-id-type="doi">10.7554/eLife.86037.sa0</article-id><title-group><article-title>Editor's evaluation</article-title></title-group><contrib-group><contrib contrib-type="author"><name><surname>Meng</surname><given-names>Ming</given-names></name><role specific-use="editor">Reviewing Editor</role><aff><institution-wrap><institution-id institution-id-type="ror">https://ror.org/01kq0pv72</institution-id><institution>South China Normal University</institution></institution-wrap><country>China</country></aff></contrib></contrib-group><related-object id="sa0ro1" object-id-type="id" object-id="10.1101/2022.11.21.517253" link-type="continued-by" xlink:href="https://sciety.org/articles/activity/10.1101/2022.11.21.517253"/></front-stub><body><p>This valuable study presents a tool for hyperaligning functional brain topography between individuals, which is based on fMRI connectivity data gathered when participants watched different movies. The tool is validated through strong correlations between functional topographic maps generated from a participant's own localizer data and those derived from other participants' data based on this hyperalignment, even when the training and target participants were drawn from different datasets. The study will potentially be of interest to researchers working with a wide range of fMRI datasets.</p></body></sub-article><sub-article article-type="decision-letter" id="sa1"><front-stub><article-id pub-id-type="doi">10.7554/eLife.86037.sa1</article-id><title-group><article-title>Decision letter</article-title></title-group><contrib-group content-type="section"><contrib contrib-type="editor"><name><surname>Meng</surname><given-names>Ming</given-names></name><role>Reviewing Editor</role><aff><institution-wrap><institution-id institution-id-type="ror">https://ror.org/01kq0pv72</institution-id><institution>South China Normal University</institution></institution-wrap><country>China</country></aff></contrib></contrib-group><contrib-group><contrib contrib-type="reviewer"><name><surname>Meng</surname><given-names>Ming</given-names></name><role>Reviewer</role><aff><institution-wrap><institution-id institution-id-type="ror">https://ror.org/01kq0pv72</institution-id><institution>South China Normal University</institution></institution-wrap><country>China</country></aff></contrib><contrib contrib-type="reviewer"><name><surname>Zhen</surname><given-names>Zonglei</given-names></name><role>Reviewer</role><aff><institution-wrap><institution-id institution-id-type="ror">https://ror.org/022k4wk35</institution-id><institution>Beijing Normal University</institution></institution-wrap><country>China</country></aff></contrib></contrib-group></front-stub><body><boxed-text id="sa2-box1"><p>Our editorial process produces two outputs: (i) <ext-link ext-link-type="uri" xlink:href="https://sciety.org/articles/activity/10.1101/2022.11.21.517253">public reviews</ext-link> designed to be posted alongside <ext-link ext-link-type="uri" xlink:href="https://www.biorxiv.org/content/10.1101/2022.11.21.517253v2">the preprint</ext-link> for the benefit of readers; (ii) feedback on the manuscript for the authors, including requests for revisions, shown below. We also include an acceptance summary that explains what the editors found interesting or important about the work.</p></boxed-text><p><bold>Decision letter after peer review:</bold></p><p>Thank you for submitting your article &quot;Cross-movie prediction of individualized functional topography&quot; for consideration by <italic>eLife</italic>. Your article has been reviewed by 3 peer reviewers, including Ming Meng X as the Reviewing Editor and Reviewer #1, and the evaluation has been overseen by Chris Baker as the Senior Editor. The following individual involved in the review of your submission has agreed to reveal their identity: Zonglei Zhen (Reviewer #2).</p><p>The reviewers have discussed their reviews with one another, and the Reviewing Editor has drafted this to help you prepare a revised submission.</p><p>Essential revisions:</p><p>1) Add discussion of the limit of the present hyper alignment approach: for example, to what extent the present hyper alignment approach would be applicable to individuals with atypical functional brain topography such as brain lesion patients with e.g., acquired prosopagnosia? Even in typical populations, while bilateral fusiform face areas can be identified in the majority through functional localizer scans, the left fusiform face area sometimes cannot be found. Moreover, many top-down factors are known to modulate functional brain topography. Due to these factors, brain responses and functional connectivity may be different even when the same subject watched the same movie twice (e.g., Cui et al., 2021).</p><p>2) Explain how the length of movie-viewing fMRI may affect the accuracy in predicting the idiosyncratic cortical topography? Similarly, how does the number of participants in the normative database affect the prediction of the category-selective topography? This information is important for the researchers who are interested in using the approach in their studies.</p><p>3) The data show that category-selective topography can be accurately estimated using connectivity hyper alignment, regardless of whether different movies are used to calculate the connectome and regardless of other data collection parameters. However, can the functional connectome from resting state fMRI accomplish the same as the movie-watching fMRI? If yes, this would expand the approach to much broader data.</p><p>4) The authors averaged the hyper-aligned functional localizer data from all of the subjects to predict individual category-selective topographies. As there is large spatial variability in the functional areas across subjects, averaging the data from many subjects may blur the boundaries of the functional areas. A better solution might be to average those subjects who show highly similar connectome to the target subjects.</p><p>5) Add discussion to clarify relations between the present hyperalignment approach and approaches in the literature that address the same question. Specifically, as reviewer #2 pointed out, 'Saygin and her colleagues have demonstrated that structural connectivity fingerprints can predict cortical selectivity for multiple visual categories across cortex (Osher DE et al., 2016, Cerebral Cortex; Saygin et al., 2011, Nat. Neurosci). I think there's a connection between those studies and the current study. If the author can discuss the connection between them, it may help us understand why CHA work so well.' And as reviewer #3 pointed out, 'the authors do not cite a paper that has already successfully demonstrated a functional alignment method that can address exactly this need: a connectivity-based Shared Response Model (cSRM; Nastase et al., 2020, NeuroImage). It would be relevant for the authors to consider the cSRM method in relation to their enhanced CHA method in detail. In particular, both the relative predictive performance as well as associated computational costs would be useful for researchers to understand in considering enhanced CHA for their applications.'</p><p>6) Justify the particular six step, iterative approach. That is: why were six steps chosen over any other number? At present, it is not clear if there is an explicit loss function that the authors are minimizing over their iterations. The relative computational cost of six iterations is also likely significant, particularly compared to previous hyperalignment algorithms. A more detailed theoretical understanding of why six iterations are necessary-or if other researchers could adopt a variable number according to the characteristics of their data-would significantly improve the transferability of this method.</p><p>7) The existing evaluations for enhanced CHA appear to be entirely based on image-derived correlations. That is, the authors compare the predicted image from CHA with the ground-truth image using correlation. While this provides promising initial evidence, correlation-based measures are often difficult to interpret given their sensitivity to image characteristics such as smoothness. Including Cronbach's Î± reliability as a baseline does not address this concern, as it is similarly an image-based statistic. It would be useful to see additional predictive experiments using frameworks such as time-segment classification, inter-subject decoding, or encoding models.</p><p>8) Make available the code for implementing CHA, or justify why this could not be done at the present.</p><p><italic>Reviewer #1 (Recommendations for the authors):</italic></p><p>In addition to adding more discussions on the limit of the present hyperalignment approach as I mentioned in the public review section, I would suggest more direct comparisons of the current CHA results and previous RHA results. I.e., perhaps consider moving Figure S2 to the main text?</p><p><italic>Reviewer #3 (Recommendations for the authors):</italic></p><p>â On L336 of The Raiders Dataset, the authors note that a subset of nine of the original eleven participants are included in the current experiments; however, from the current it is not obvious why two participants were excluded.</p><p>â Please confirm the radius of the searchlights used throughout the experiments. For example, in L361 of Connectivity Hyperalignment (Step One) the searchlight is described as 13mm radius, while on L370 of the same section it is a 15mm radius.</p><p>â In Figure S2, I noted the following two typos: In section (A), The second axis description should read &quot;Values on the x-axis stand for correlations between each target participant's own localized-based topographies and topographies from other participants in the same dataset using CHA.&quot; In section (B), &quot;Conbach's alphas&quot; should be &quot;Cronbach's alphas.&quot;</p><p>â In Figure S3, the in-figure legend (e.g., F to B) does not appear to relate to the figure content and is not explained in the figure description.</p><p>â It seems that code for implementing CHA is not currently available, as the GitHub repository listed in the Data Availability (but not in-text) does not contain executable code as far as I can tell. This would be particularly useful for other author's hoping to apply this method in their own datasets!</p></body></sub-article><sub-article article-type="reply" id="sa2"><front-stub><article-id pub-id-type="doi">10.7554/eLife.86037.sa2</article-id><title-group><article-title>Author response</article-title></title-group></front-stub><body><disp-quote content-type="editor-comment"><p>Essential revisions:</p><p>1) Add discussion of the limit of the present hyper alignment approach: for example, to what extent the present hyper alignment approach would be applicable to individuals with atypical functional brain topography such as brain lesion patients with e.g., acquired prosopagnosia? Even in typical populations, while bilateral fusiform face areas can be identified in the majority through functional localizer scans, the left fusiform face area sometimes cannot be found. Moreover, many top-down factors are known to modulate functional brain topography. Due to these factors, brain responses and functional connectivity may be different even when the same subject watched the same movie twice (e.g., Cui et al., 2021).</p></disp-quote><p>We thank the reviewer for the suggestion and agree that it would be fascinating if the predictions can be made with high fidelity in neuropsychological populations. Although we are optimistic that our algorithm is able to generalize across diverse populations, to date, no previous literature has provided empirical evidence to illustrate the effectiveness, including optimizations and special applications beyond typical brains. Besides the neuropsychological population, it would also be valuable to study the generalization across a broad age range, for example, from infants to the elderly. The brain changes across age both anatomically and functionally, so it is a challenge to predict functional topographies based on a normative group that only includes young participants. With all these potential applications in mind, future research is needed to illustrate the efficacy, build the pipeline, and construct the representative normative groups to meet the requirements of accurate individualized predictions in diverse populations.</p><p>In typical populations, although participants have great individual variabilities in their functional topographies, for instance, some participants have distinguishable patches of activations in their left ventral temporal cortex while some participants donât, our algorithms successfully captured these individualized differences in the prediction. <xref ref-type="fig" rid="sa2fig1">Author response image 1</xref> shows, as an example, the face-selective topographies of two individuals that have markedly different face-selective topographies on the left ventral temporal cortex. The left participant has prominent face-selective areas on the left ventral temporal cortex that are in similar sizes as the right side, while the right participant only has a few scattered small face-selective spots on the left side. No matter what their face-selective areas look like, our algorithm accurately recovered the individualized locations, shapes, and sizes, retaining the individual variability in the functional topographies.</p><fig id="sa2fig1" position="float"><label>Author response image 1.</label><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-86037-sa2-fig1-v1.tif"/></fig><p>Functional connectivity profiles based on naturalistic stimuli are very stable across the cortex, even when participants watch different movies. In Figure 4âfigure supplement 9, the mean correlations of fine-scaled connectome for most searchlights (r = 15mm) when participants watched The Grand Budapest Hotel and the Raiders of the Lost Ark were generally around 0.8. The mean correlations were about 0.9 between the first and second half of the same movie although the stimuli contents were different between the two halves. Thus, the fine-grained functional connectivity profiles remain highly stable and reliable across movie contents, which contributes to the robustness of cross-movie, time, and other parameters (e.g., scanner models, scanning parameter) predictions using our algorithms.We added a paragraph in the discuss section to address the concerns (page 18-19):</p><p>âThis study successfully illustrated that accurate individualized predictions are both robust and applicable across a variety of conditions, including movie types, languages, scanning parameters, and scanner models. Importantly, the intricate connectivity profiles remain consistent even when participants view entirely different movies, as evidenced by Figure 4âfigure supplement 9, reinforcing the prediction's stability in various scenarios. However, all four datasets in this study only included typical participants with anatomically intact brains. An unanswered question is whether individualized topographies of neuropsychological populations with atypical cortical function (e.g., developmental prosopagnosics) or with lesioned brains (e.g., acquired prosopagnosics) could also be accurately predicted using the hyperalignment-based methods. Up to now, as far as we know, no previous literature has investigated this question. Beyond neuropsychological groups, it is also valuable to investigate how well the predictions will be across a wide range of age, from infants to the elderly. Future research is essential to adapt our algorithms to diverse populations.â</p><disp-quote content-type="editor-comment"><p>2) Explain how the length of movie-viewing fMRI may affect the accuracy in predicting the idiosyncratic cortical topography? Similarly, how does the number of participants in the normative database affect the prediction of the category-selective topography? This information is important for the researchers who are interested in using the approach in their studies.</p></disp-quote><p>To investigate the influence of movie-viewing data length and the number of participants in the normative database on prediction performance, we systematically varied these parameters. Specifically, we altered the number of runs utilized in the analysis for both the normative and target data and experimented with varying the number of participants in the normative dataset using the Budapest and the Sraiders datasets. We have included a new Figure 4âfigure supplement 5 to present a summary of these findings.</p><p>The results reveal that both within-dataset and between-dataset prediction performances are positively correlated with the length of movie-viewing fMRI data used for both the normative and target groups. A similar trend was observed with respect to the number of participants included in the normative dataset. It is important to highlight, though, that, even when analyzing as little as one run of movie-viewing dataâroughly 10-15 minutes, our hyperalignment-based prediction performance was significantly higher than that achieved using traditional surface alignment. This held true even when the normative dataset included as few as five participants.</p><p>In summary, our results show that prediction performance generally improves with longer movie-viewing sessions and larger normative datasets. However, it is noteworthy that even with minimal dataâ10 minutes of movie-viewing and a small number of participants in the normative datasetâour algorithm still outperforms traditional surface alignment methods significantly.</p><p>We also added sentences in the Discussion section (page 15):</p><p>âWe investigated the influence of naturalistic movie length and the size of the training group on the prediction accuracy of individualized functional topographies. By incrementally increasing both the number of movie runs in the training and target dataset and the participants in the training group in the Budapest and Sraiders dataset, we observed enhanced prediction accuracy (Figure 4âfigure supplement 5). Notably, even with just one movie run in the training or target dataset, or with a mere five participants in the training group, our prediction performance (Pearson <italic>r</italic>) ranged from about 0.6 to 0.7. This accuracy significantly outperformed results obtained using surface-based alignment.â</p><disp-quote content-type="editor-comment"><p>3) The data show that category-selective topography can be accurately estimated using connectivity hyper alignment, regardless of whether different movies are used to calculate the connectome and regardless of other data collection parameters. However, can the functional connectome from resting state fMRI accomplish the same as the movie-watching fMRI? If yes, this would expand the approach to much broader data.</p></disp-quote><p>We agree with the reviewer that demonstrating the applicability of the resting state data will expand the application scenarios of this approach. Most previous findings on resting state connectivity, including the comparison between the naturalistic and the resting state paradigms, focused on the macro-scale similarities and differences (e.g., Samara et al., 2023). Very few studies have investigated the fine-scaled connectome based on resting state data. The study on connectivity hyperalignment (Guntupalli et al., 2018) demonstrated a shared fine-scale connectivity structure among individuals that co-exists with the common coarse-scale structure and built the algorithm to successfully hyperalign individuals to the shared fine-scaled space. Another study from our lab (Feilong et al., 2021) revealed that the fine-scaled connectivity profiles in both resting and task states are highly predictive of general intelligence, indicating reliable and biologically relevant fine-scaled resting state connectome structures. Thus, it is highly plausible that our approach is able to be generalized to the resting state data, generating significantly better predictions of individualized functional topographies than traditional surface alignment. However, due to the limitations of the current datasets, we do not have resting state data available in the current datasets to perform this analysis. We are in the process of collecting new data to explore this hypothesis in future work.</p><p>We added sentences to the Discussion section to discuss this idea (page 18):</p><p>âStudies comparing movie-viewing and resting state functional connectivity have shown that both paradigms yield overlapping macroscale cortical organizations (<italic>29</italic>), though naturalistic viewing introduces unique modality-specific hierarchical gradients. However, there remains a gap in research comparing the fine-scaled connectomes of naturalistic and resting state paradigms. Guntupalli and colleagues (<italic>14</italic>) revealed a shared fine-scale structure that coexists with the coarse-scale structure, and connectivity hyperalignment successfully improved intersubject correlations across a wide variety of tasks. Feilong et al. (<italic>13</italic>) noted that the fine-scaled connectivity profiles in both resting and task states are highly predictive of general intelligence. This suggests a reliable and biologically relevant fine-scale resting state connectivity structure among individuals. Therefore, it is plausible that individualized functional topography could be effectively estimated using resting state functional connectivity, expanding the applicability of our approach. Future studies are needed to explore this direction.â</p><disp-quote content-type="editor-comment"><p>4) The authors averaged the hyper-aligned functional localizer data from all of the subjects to predict individual category-selective topographies. As there is large spatial variability in the functional areas across subjects, averaging the data from many subjects may blur the boundaries of the functional areas. A better solution might be to average those subjects who show highly similar connectome to the target subjects.</p></disp-quote><p>We appreciate the reviewerâs insightful question about optimizing prediction performance by selecting participants most similar in functional connectivity to the target individuals. This is a promising direction and difficult problem as well. Our approach is based on fine-scale connectome to hyperalign participants, thus different groups of participants may be similar to the target participant in different searchlights. In addition, based on results discussed in the response to Q2, the more participants included in the normative dataset, the better the prediction performance. Thus, there is a trade-off between the number of participants included in the normative dataset for the prediction and the overall similarity of those participants to the target participant.</p><p>To quantitatively explore this idea, we used a searchlight in the right ventral temporal cortex, roughly at the location of posterior fusiform face area (pFFA). We sorted participants by their connectome similarity to each target participant and then examined prediction performance based on either the top nine most similar participants or the bottom nine least similar participants. Our results, presented in Figure 4âfigure supplement 8, reveal that hyperalignment consistently outperforms surface alignment regardless of the subset of participants used. Notably, using the nine most similar participants did not significantly alter prediction performance (Tukey Test, z = -0.09, p = 0.996), while using the least similar participants did negatively impact it (Tukey Test, z = 2.492, p = 0.034). Interestingly, the stability of hyperalignment-based predictions remained high even when only a subset of participants was used, contrasting with the variability observed in surface-alignment-based predictions.</p><p>Overall, these findings suggest that while selecting functionally similar participants is a promising avenue for future optimization, the process will require nuanced, searchlight-specific criteria. Each searchlight may necessitate its own set of optimal participants to balance between the performance boost from having more participants and the fidelity gained from participant similarity.</p><p>We added the following to the discussion in the manuscript (page 16):</p><p>âIn our study, we used fine-scale connectomes, noting that some participants are more similar to the target participant in specific searchlights. It is an interesting question whether predictions could be enhanced by exclusively selecting those more similar participants for the target participant. To explore this option, we examined a searchlight in the right ventral temporal cortex that was roughly at the location of the posterior fusiform area (pFFA) using the top and bottom nine participants similar to each target participant measured by their fine-scale connectome similarities in the budapest dataset. Generally, using all or part of the participants for the prediction generated similar results (Figure 4âfigure supplement 8). Compared to using all the participants, using only the top nine participants who are the most similar to the target participants did not significantly improve the prediction (Tukey Test, z = -0.09, p = 0.996), but using only the bottom nine participants generated significantly lower prediction accuracies (Tukey Test, z = 2.492, p = 0.034). This suggests a trade-off between the number of participants included in the prediction and the similarity of the participants. Future studies are needed to explore the optimal threshold for the number of participants included for each searchlight to refine the algorithm.â</p><disp-quote content-type="editor-comment"><p>5) Add discussion to clarify relations between the present hyperalignment approach and approaches in the literature that address the same question. Specifically, as reviewer #2 pointed out, 'Saygin and her colleagues have demonstrated that structural connectivity fingerprints can predict cortical selectivity for multiple visual categories across cortex (Osher DE et al., 2016, Cerebral Cortex; Saygin et al., 2011, Nat. Neurosci). I think there's a connection between those studies and the current study. If the author can discuss the connection between them, it may help us understand why CHA work so well.' And as reviewer #3 pointed out, 'the authors do not cite a paper that has already successfully demonstrated a functional alignment method that can address exactly this need: a connectivity-based Shared Response Model (cSRM; Nastase et al., 2020, NeuroImage). It would be relevant for the authors to consider the cSRM method in relation to their enhanced CHA method in detail. In particular, both the relative predictive performance as well as associated computational costs would be useful for researchers to understand in considering enhanced CHA for their applications.'</p></disp-quote><p>We thank the reviewer for raising this point that provides us with the chance of clarifying how our approach differs with methods previously reported in the literature. The computational logic underlying our approach is that we derived the transformation matrices between the training and the target participants in the high-dimensional space based on functional connectivity calculated from the movie data. Then, we applied these transformation matrices to the training participantâs localizer data to accomplish the prediction. On the other hand, Saygin and colleagues directly used diffusion-weighted imaging (DWI) data and predicted participantsâ functional responses based on the anatomical-functional correspondence. They evaluated the prediction by calculating the mean absolute errors (AE) of the difference between the actual and predicted contrast responses. Although AE linearly increases with the quality of the prediction, it is difficult to measure the prediction performance of the shape, size, and location of the functional areas precisely using this mean value. With our algorithm, we were able to predict the general location and size of the areas and recover the individualized shapes, generating more powerful predictions. We also used the searchlight analysis to evaluate the performance across the cortex systematically. In addition, Osher et al. (2016) and Saygin et al. (2012) always have a few participants failing to show better predictions based on the connectivity than the group averaged method. Our algorithm is more stable, as all participants across all four datasets had better predicted performance using our algorithm than using the group average. However, although we did not directly use the anatomical-functional correspondence with DWI, the relationships between individual structural connectivity and cortical visual category selectivity could be one of the biological underpinnings that contribute to this robust and accurate prediction.</p><p>The Connectivity-Based Shared Response Model (cSRM, Nastase et al., 2020) offers an alternative framework for aligning individuals through functional connectivity. While the overarching aim of cSRM and our methodology converges, substantial differences emerge in the respective implementation and application between the two methods that make our approach the more suitable for predicting individualized topographies. The most significant difference between the two is that, instead of focusing on within-individual connectivity profiles, cSRM used inter-subject functional connectivity (ISFC) in the initial step. This design requires that all participants must have time-locked time series, making the algorithm unusable for cross-content prediction and making it incompatible with resting-state data. Our approach, on the other hand, does not require time-locked stimuli, thereby offering a more flexible framework that permits generalization across different types of stimuli and experimental settings and enables bringing data across laboratories across the world together. Secondly, cSRM predominantly focuses on Region of Interest (ROI) analyses, whereas our model employs searchlight-based analyses designed to comprehensively cover the entire cortical sheet. Whole-brain coverage is needed to generate the topography that reflects the patterns across the cortex. Finally, with the optimized 1step method, our approach directly hyeraligns the training and target participants together, avoiding the accumulation of errors from the intermediate common space. cSRM, with an implementation similar to the classic connectivity hyperalignment, creates and hyperaligns all participants to a shared information space. In summary, while our approach and cSRM share a similar theoretical foundation, our approach has been specifically optimized to address the challenges and complexities in predicting individualized whole-brain functional topographies. Moreover, our approach demonstrates a remarkable ability to generalize across a variety of contexts and stimuli, offering a significant advantage in dealing with diverse experimental settings and datasets.</p><p>We have added the contents to the Discussion section (page 16-17):</p><p>âBy leveraging transformation matrices obtained from hyperaligning participants based on movie-viewing data, we successfully mapped these relationships to the training participantsâ localizer data, enabling robust predictions. Prior work employing diffusion-weighted imaging (DWI) has underscored the link between anatomical connectivity and category selectivity across diverse visual fields (<italic>22, 23</italic>) and has established a notable congruence between structural and functional connectivities (<italic>24</italic>). These findings suggest that the unique anatomical connectivity patterns of individuals may serve as a foundational mechanism, contributing to the stable finescale functional connectome that underpins our approach. The connectivity-based Shared Response Model (cSRM) proposed by Nastase and colleagues (<italic>25</italic>) used connectivity to functionally align individuals similar to the connectivity hyperalignment algorithm. While both approaches share overarching goals, they diverge considerably in implementation and application. First and most important, cSRM used inter-subject functional connectivity (ISFC) rather than within-subject functional connectivity to initially estimate the connectome. As a result, cSRM requires participants to have time-locked fMRI time series. Therefore, unlike our algorithm, the cSRM approach does not support cross-content applications and also is not suitable for use with resting-state data. Second, cSRM is implemented based on a predefined cortical parcellation rather than the overlapping, regularly-spaced cortical searchlights applied in our method which are not constrained by areal borders. For the application, cSRM has mainly been used to do ROI analysis rather than the estimation of the whole-brain topography that requires broader coverage of the cortex with a searchlight analysis. Third, our method is specifically designed to work in each individualâs space, while cSRM decomposes data across subjects into shared and subject specific transformations, focusing on a communal connectivity space. In summary, although cSRM presents a promising alternative for similar aims, its current implementation precludes it from fulfilling the range of applications for which our method is optimized.â</p><disp-quote content-type="editor-comment"><p>6) Justify the particular six step, iterative approach. That is: why were six steps chosen over any other number? At present, it is not clear if there is an explicit loss function that the authors are minimizing over their iterations. The relative computational cost of six iterations is also likely significant, particularly compared to previous hyperalignment algorithms. A more detailed theoretical understanding of why six iterations are necessary-or if other researchers could adopt a variable number according to the characteristics of their data-would significantly improve the transferability of this method.</p></disp-quote><p>In the advanced connectivity hyperalignment implementation, we gradually increased the number of targets. The six steps were not intentionally chosen but were the result of the increase to the maximum number of fine-grained targets, namely single cortical vertices.</p><p>Our datasets were resampled to the cortical mesh with 18,742 vertices across both hemispheres (approximately 3 mm vertex spacing; icoorder 5; 20,484 vertices before removing non-cortical vertices). Step 1 was the classic standard connectivity hyperalignment implementation based on the anatomically-aligned data. Since using dense connectivity targets (e.g., using all 18742 vertices on the surface) with anatomically-aligned data generates poor functional correspondence across participants (Busch et al., 2021), we used 1,284 vertices (icoorder 3, before removing the medial wall) as connectivity targets in step 1. However, it is beneficial to include more targets for calculating connectivity patterns after the first iteration of connectivity hyperalignment and repeated iterations to lead to a better solution by gradually aligning the information at finer scales. To better align across participants, we iterated the alignment for another two times (step 2 and step 3) with the same number of 1,284 coarse connectivity targets to ensure improved alignment before increasing the number of targets in the later steps. In step 4, we increased the number of targets to 5,124 (icoorder 4, before removing the medial wall), and iterated with this number of vertices for two times in total (step 4 and step 5) before using all vertices as targets. In the final step (step 6), all vertices were used as connectivity targets.</p><p>It is true that the multiple iteration steps largely increased the computational complexity compared to the classic connectivity hyperalignment, but the prediction increase was steady across all datasets and became comparable to response hyperalignment performance which requires time-locked stimuli. We did not use an explicit loss function in the algorithm, but followed the natural progression of the number of potential connectivity targets in the implementation. On the other hand, the difference between the performance of the improved and the classic connectivity hyperalignment was relatively small (difference of <italic>r</italic> &lt; 0.05), which indicates the effectiveness of our classic algorithm. It is up to the researchersâ own options to adopt the number of iterations and the pace of increasing the number of targets in each step. If computational resources are limited or if a shorter total computational time is the primary priority, using the classic connectivity hyperalignment may be the best option to balance the trade-offs.</p><p>The Materials and methods section had the details of the implementation (page 22-23):</p><p>âUsing dense connectivity targets (e.g., using all 18742 vertices on the surface) with anatomically-aligned data usually generates poor functional correspondence across participants (33). It is, however, beneficial to include more targets for calculating connectivity patterns after the first iteration of connectivity hyperalignment and repeated iterations to lead to a better solution by gradually aligning the information at finer scales.</p><p>We used six steps to further improve the connectivity hyperalignment method. Step 1 was the initial connectivity hyperalignment step as described above that was based on the raw anatomically aligned movie data. The resultant transformation matrices were applied to those movie runs, and the hyperaligned data were then used in step 2 to calculate new connectivity patterns and calculate new transformation matrices. We repeated this procedure iteratively six times and derived transformation matrices for each step. In steps 1, 2, and 3, 642 Ã 2 (icoorder3, before removing the medial wall) connectivity targets were defined with 13 mm searchlights. In step 4 and 5, 2562 Ã 2 (icoorder 4, before removing the medial wall) connectivity targets were used with 7 mm searchlights to calculate target mean time series. In the final step 6, all 18742 vertices were included as separate connectivity targets, using each vertexâs time series rather than calculating the mean in a searchlight. Each step of this advanced connectivity hyperalignment algorithm increased the prediction performance (Figure 4âfigure supplement 2).â</p><p>But to help the readers understand the logic of the advanced connectivity hyperalignment algorithm used in this study, we expanded the Discussion section (page 15):</p><p>âBecause using dense connectivity targets (e.g., using all vertices as connectivity targets) with anatomically-alignment data often leads to suboptimal alignment across participants (<italic>33</italic>), we started with coarse connectivity targets and gradually increased the number of connectivity targets to form a denser representation of connectivity profiles. The iterations improved the prediction performance step by step, and at the final step (step 6, all vertices were used as connectivity targets) in this analysis, the enhanced CHA generated comparable performance with RHA (Figure 4âfigure supplement 4).â</p><disp-quote content-type="editor-comment"><p>7) The existing evaluations for enhanced CHA appear to be entirely based on image-derived correlations. That is, the authors compare the predicted image from CHA with the ground-truth image using correlation. While this provides promising initial evidence, correlation-based measures are often difficult to interpret given their sensitivity to image characteristics such as smoothness. Including Cronbach's Î± reliability as a baseline does not address this concern, as it is similarly an image-based statistic. It would be useful to see additional predictive experiments using frameworks such as time-segment classification, inter-subject decoding, or encoding models.</p></disp-quote><p>We appreciate the reviewerâs concern regarding the stability of local correlations in relation to image characteristics. To address this, we conducted additional analysis using different searchlight sizes (with radii of 10 mm, 15 mm, and 20 mm) to evaluate the predicted categoryselective maps, focusing specifically on the Budapest dataset. The local correlations between the predicted category-selective maps (obtained using enhanced CHA) and participantsâ own maps based on classic localizer runs were calculated for each searchlight. We averaged these correlations across participants and plotted the resulting maps, as shown in Figure 4âfigure supplement 10. Although using a larger searchlight radius is similar to employing a larger smoothing kernel, the results remained relatively stable across different searchlight sizes, particularly in regions selectively responsive to the specific category. This stability suggests that while the evaluation may be influenced by image-related features, the conclusion would remain consistent under varying parameters.</p><p>As for the use of enhanced CHA, it serves as an optimized version of the classic CHA, specifically designed for predicting individualized functional topographies. Evaluating prediction performance in our study is based on t-value contrast maps for each participant. Given this, it's unclear how time-segment classification or other decoding/encoding models could be appropriately implemented for performance evaluation. However, prior research from our lab has already established the effectiveness of classic CHA. Specifically, Guntupalli et al. (2018) showed that classic CHA significantly improved intersubject correlations (ISC) of connectivity profiles across the cortex. They also revealed that CHA captured fine-scale variations in connectivity profiles for nearby cortical nodes across participants and led to improved betweensubject multivariate pattern classification accuracies (bsMVPC) of movie segments. These findings serve as robust evidence for the effectiveness of classic CHA, laying the groundwork for our enhanced CHA approach.</p><p>We added Figure 4âfigure supplement 10 to the supplementary material:</p><disp-quote content-type="editor-comment"><p>8) Make available the code for implementing CHA, or justify why this could not be done at the present.</p></disp-quote><p>We will make the implementation code available once the article is accepted.</p><disp-quote content-type="editor-comment"><p>Reviewer #1 (Recommendations for the authors):</p><p>In addition to adding more discussions on the limit of the present hyperalignment approach as I mentioned in the public review section, I would suggest more direct comparisons of the current CHA results and previous RHA results. I.e., perhaps consider moving Figure S2 to the main text?</p></disp-quote><p>We thank the reviewer for pointing this out. To help readers better understand the comparison between CHA and RHA results, we moved Figure S2A (current Figure 2âfigure supplement 1A) to the main text and combined it with Figure 1 as panel D.</p><p>The corresponding content in the manuscript is in the Results section (page 4):</p><p>âEstimates using CHA to calculate transformation matrices were also equivalent to estimates using RHA (Figure 1D). RHA, however, requires that all subjects watch the same movie, whereas CHA can use connectivity matrices derived from responses to different movies, potentially making our new approach more flexible.â</p><disp-quote content-type="editor-comment"><p>Reviewer #3 (Recommendations for the authors):</p><p>â On L336 of The Raiders Dataset, the authors note that a subset of nine of the original eleven participants are included in the current experiments; however, from the current it is not obvious why two participants were excluded.</p></disp-quote><p>Nine of the total eleven original participants have the localizer data, thus, only these nine participants were included in this study.</p><disp-quote content-type="editor-comment"><p>â Please confirm the radius of the searchlights used throughout the experiments. For example, in L361 of Connectivity Hyperalignment (Step One) the searchlight is described as 13mm radius, while on L370 of the same section it is a 15mm radius.</p></disp-quote><p>The details are correct. We used slightly smaller sized (13 mm) searchlights when building the connectivity profiles and the common sized (15 mm) searchlights in the functional alignment.</p><disp-quote content-type="editor-comment"><p>â In Figure S2, I noted the following two typos: In section (A), The second axis description should read &quot;Values on the x-axis stand for correlations between each target participant's own localized-based topographies and topographies from other participants in the same dataset using CHA.&quot; In section (B), &quot;Conbach's alphas&quot; should be &quot;Cronbach's alphas.&quot;</p></disp-quote><p>We made the revision as suggested for section (B). We moved Figure S2A (current Figure 2figure supplement 1A) to current Figure 1D and kept the figure caption to explicitly describe that the predicted topographies were estimated from other participants in the same dataset.</p><disp-quote content-type="editor-comment"><p>â In Figure S3, the in-figure legend (e.g., F to B) does not appear to relate to the figure content and is not explained in the figure description.</p></disp-quote><p>For each dataset, we included RHA, within-movie CHA, AA, and all possible cross-movie CHA predictions. So for each individual participant in the figure, all colored dots reflecting the listed contents were plotted. We apologize for the confusion, and added the explanation of the legends in the figure caption.</p><disp-quote content-type="editor-comment"><p>â It seems that code for implementing CHA is not currently available, as the GitHub repository listed in the Data Availability (but not in-text) does not contain executable code as far as I can tell. This would be particularly useful for other author's hoping to apply this method in their own datasets!</p></disp-quote><p>We will make the implementation code available once the article is accepted.</p><p>References</p><p>Feilong, M., Guntupalli, J. S., and Haxby, J. V. (2021). The neural basis of intelligence in finegrained cortical topographies. <italic>eLife</italic>, <italic>10</italic>, e64058. https://doi.org/10.7554/<italic>eLife</italic>.64058</p><p>Guntupalli, J. S., Feilong, M., and Haxby, J. V. (2018). A computational model of shared finescale structure in the human connectome. <italic>PLOS Computational Biology</italic>, <italic>14</italic>(4), e1006120. https://doi.org/10.1371/journal.pcbi.1006120</p><p>Guntupalli, J. S., Hanke, M., Halchenko, Y. O., Connolly, A. C., Ramadge, P. J., and Haxby, J. V. (2016). A Model of Representational Spaces in Human Cortex. Cerebral Cortex, 26(6), 2919â2934. https://doi.org/10.1093/cercor/bhw068</p><p>Jiahui, G., Feilong, M., Visconti di Oleggio Castello, M., Guntupalli, J. S., Chauhan, V., Haxby, J. V., and Gobbini, M. I. (2020). Predicting individual face-selective topography using naturalistic stimuli. <italic>NeuroImage</italic>, <italic>216</italic>, 116458. https://doi.org/10.1016/j.neuroimage.2019.116458</p><p>Jiahui, G., Feilong, M., Visconti di Oleggio Castello, M., Nastase, S. A., Haxby, J. V., and Gobbini, M. I. (2023). Modeling naturalistic face processing in humans with deep convolutional neural networks. <italic>Proceedings of the National Academy of Sciences</italic>, <italic>120</italic>(43), e2304085120. https://doi.org/10.1073/pnas.2304085120</p><p>Nastase, S. A., Liu, Y.-F., Hillman, H., Norman, K. A., and Hasson, U. (2020). Leveraging shared connectivity to aggregate heterogeneous datasets into a common response space. <italic>NeuroImage</italic>, <italic>217</italic>, 116865. https://doi.org/10.1016/j.neuroimage.2020.116865</p><p>Osher, D. E., Saxe, R. R., Koldewyn, K., Gabrieli, J. D. E., Kanwisher, N., and Saygin, Z. M. (2016). Structural Connectivity Fingerprints Predict Cortical Selectivity for Multiple Visual Categories across Cortex. Cerebral Cortex (New York, NY), 26(4), 1668â1683. https://doi.org/10.1093/cercor/bhu303</p><p>Samara, A., Eilbott, J., Margulies, D. S., Xu, T., and Vanderwal, T. (2023). Cortical gradients during naturalistic processing are hierarchical and modality-specific. <italic>NeuroImage</italic>, <italic>271</italic>, 120023. https://doi.org/10.1016/j.neuroimage.2023.120023</p><p>Saygin, Z. M., Osher, D. E., Koldewyn, K., Reynolds, G., Gabrieli, J. D. E., and Saxe, R. R. (2012). Anatomical connectivity patterns predict face selectivity in the fusiform gyrus. Nature Neuroscience, 15(2), 321â327. https://doi.org/10.1038/nn.3001</p></body></sub-article></article>