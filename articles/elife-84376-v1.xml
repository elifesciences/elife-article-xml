<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD with MathML3 v1.3 20210610//EN"  "JATS-archivearticle1-3-mathml3.dtd"><article xmlns:ali="http://www.niso.org/schemas/ali/1.0/" xmlns:xlink="http://www.w3.org/1999/xlink" article-type="research-article" dtd-version="1.3"><front><journal-meta><journal-id journal-id-type="nlm-ta">elife</journal-id><journal-id journal-id-type="publisher-id">eLife</journal-id><journal-title-group><journal-title>eLife</journal-title></journal-title-group><issn publication-format="electronic" pub-type="epub">2050-084X</issn><publisher><publisher-name>eLife Sciences Publications, Ltd</publisher-name></publisher></journal-meta><article-meta><article-id pub-id-type="publisher-id">84376</article-id><article-id pub-id-type="doi">10.7554/eLife.84376</article-id><article-categories><subj-group subj-group-type="display-channel"><subject>Research Article</subject></subj-group><subj-group subj-group-type="heading"><subject>Neuroscience</subject></subj-group></article-categories><title-group><article-title>Brain-imaging evidence for compression of binary sound sequences in human memory</article-title></title-group><contrib-group><contrib contrib-type="author" corresp="yes" equal-contrib="yes" id="author-296506"><name><surname>Al Roumi</surname><given-names>Fosca</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">https://orcid.org/0000-0001-9590-080X</contrib-id><email>fosca.alroumi@cea.fr</email><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="fn" rid="equal-contrib1">†</xref><xref ref-type="fn" rid="con1"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" equal-contrib="yes" id="author-299577"><name><surname>Planton</surname><given-names>Samuel</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">https://orcid.org/0000-0001-8588-7146</contrib-id><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="fn" rid="equal-contrib1">†</xref><xref ref-type="fn" rid="con2"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" id="author-52172"><name><surname>Wang</surname><given-names>Liping</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">https://orcid.org/0000-0003-2038-0234</contrib-id><xref ref-type="aff" rid="aff2">2</xref><xref ref-type="fn" rid="con3"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" id="author-174107"><name><surname>Dehaene</surname><given-names>Stanislas</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">https://orcid.org/0000-0002-7418-8275</contrib-id><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="aff" rid="aff3">3</xref><xref ref-type="other" rid="fund1"/><xref ref-type="fn" rid="con4"/><xref ref-type="fn" rid="conf1"/></contrib><aff id="aff1"><label>1</label><institution-wrap><institution-id institution-id-type="ror">https://ror.org/056wdpc91</institution-id><institution>Cognitive Neuroimaging Unit, Université Paris-Saclay, INSERM, CEA, CNRS, NeuroSpin center</institution></institution-wrap><addr-line><named-content content-type="city">Gif/Yvette</named-content></addr-line><country>France</country></aff><aff id="aff2"><label>2</label><institution-wrap><institution-id institution-id-type="ror">https://ror.org/00vpwhm04</institution-id><institution>Institute of Neuroscience, Key Laboratory of Primate Neurobiology, CAS Center for Excellence in Brain Science and Intelligence Technology, Chinese Academy of Sciences</institution></institution-wrap><addr-line><named-content content-type="city">Shanghai</named-content></addr-line><country>China</country></aff><aff id="aff3"><label>3</label><institution-wrap><institution-id institution-id-type="ror">https://ror.org/013cjyk83</institution-id><institution>Collège de France, Université Paris Sciences Lettres (PSL)</institution></institution-wrap><addr-line><named-content content-type="city">Paris</named-content></addr-line><country>France</country></aff></contrib-group><contrib-group content-type="section"><contrib contrib-type="editor"><name><surname>Obleser</surname><given-names>Jonas</given-names></name><role>Reviewing Editor</role><aff><institution-wrap><institution-id institution-id-type="ror">https://ror.org/00t3r8h32</institution-id><institution>University of Lübeck</institution></institution-wrap><country>Germany</country></aff></contrib><contrib contrib-type="senior_editor"><name><surname>Shinn-Cunningham</surname><given-names>Barbara G</given-names></name><role>Senior Editor</role><aff><institution-wrap><institution-id institution-id-type="ror">https://ror.org/05x2bcf33</institution-id><institution>Carnegie Mellon University</institution></institution-wrap><country>United States</country></aff></contrib></contrib-group><author-notes><fn fn-type="con" id="equal-contrib1"><label>†</label><p>These authors contributed equally to this work</p></fn></author-notes><pub-date publication-format="electronic" date-type="publication"><day>01</day><month>11</month><year>2023</year></pub-date><pub-date pub-type="collection"><year>2023</year></pub-date><volume>12</volume><elocation-id>e84376</elocation-id><history><date date-type="received" iso-8601-date="2022-10-21"><day>21</day><month>10</month><year>2022</year></date><date date-type="accepted" iso-8601-date="2023-10-14"><day>14</day><month>10</month><year>2023</year></date></history><pub-history><event><event-desc>This manuscript was published as a preprint at bioRxiv.</event-desc><date date-type="preprint" iso-8601-date="2022-10-17"><day>17</day><month>10</month><year>2022</year></date><self-uri content-type="preprint" xlink:href="https://doi.org/10.1101/2022.10.15.512361"/></event></pub-history><permissions><copyright-statement>© 2023, Al Roumi, Planton et al</copyright-statement><copyright-year>2023</copyright-year><copyright-holder>Al Roumi, Planton et al</copyright-holder><ali:free_to_read/><license xlink:href="http://creativecommons.org/licenses/by/4.0/"><ali:license_ref>http://creativecommons.org/licenses/by/4.0/</ali:license_ref><license-p>This article is distributed under the terms of the <ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/licenses/by/4.0/">Creative Commons Attribution License</ext-link>, which permits unrestricted use and redistribution provided that the original author and source are credited.</license-p></license></permissions><self-uri content-type="pdf" xlink:href="elife-84376-v1.pdf"/><self-uri content-type="figures-pdf" xlink:href="elife-84376-figures-v1.pdf"/><abstract><p>According to the language-of-thought hypothesis, regular sequences are compressed in human memory using recursive loops akin to a mental program that predicts future items. We tested this theory by probing memory for 16-item sequences made of two sounds. We recorded brain activity with functional MRI and magneto-encephalography (MEG) while participants listened to a hierarchy of sequences of variable complexity, whose minimal description required transition probabilities, chunking, or nested structures. Occasional deviant sounds probed the participants’ knowledge of the sequence. We predicted that task difficulty and brain activity would be proportional to the complexity derived from the minimal description length in our formal language. Furthermore, activity should increase with complexity for learned sequences, and decrease with complexity for deviants. These predictions were upheld in both fMRI and MEG, indicating that sequence predictions are highly dependent on sequence structure and become weaker and delayed as complexity increases. The proposed language recruited bilateral superior temporal, precentral, anterior intraparietal, and cerebellar cortices. These regions overlapped extensively with a localizer for mathematical calculation, and much less with spoken or written language processing. We propose that these areas collectively encode regular sequences as repetitions with variations and their recursive composition into nested structures.</p></abstract><kwd-group kwd-group-type="author-keywords"><kwd>sequence</kwd><kwd>compression</kwd><kwd>language of thought</kwd><kwd>auditory processing</kwd><kwd>working memory</kwd><kwd>syntax</kwd></kwd-group><kwd-group kwd-group-type="research-organism"><title>Research organism</title><kwd>Human</kwd></kwd-group><funding-group><award-group id="fund1"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/501100000781</institution-id><institution>European Research Council</institution></institution-wrap></funding-source><award-id>NeuroSyntax - Grant agreement ID: 695403</award-id><principal-award-recipient><name><surname>Dehaene</surname><given-names>Stanislas</given-names></name></principal-award-recipient></award-group><funding-statement>The funders had no role in study design, data collection and interpretation, or the decision to submit the work for publication.</funding-statement></funding-group><custom-meta-group><custom-meta specific-use="meta-only"><meta-name>Author impact statement</meta-name><meta-value>Humans memorize structured sound sequences using a language-of-thought compression algorithm.</meta-value></custom-meta></custom-meta-group></article-meta></front><body><sec id="s1" sec-type="intro"><title>Introduction</title><p>The ability to learn and manipulate serially ordered lists of elements, that is sequence processing, is central to several human activities (<xref ref-type="bibr" rid="bib85">Lashley, 1951</xref>). This capacity is inherent to the ordered series of subtasks that make up the actions of daily life, but is especially decisive for the implementation of high-level human skills such as language, mathematics, or music. In non-human primates, multiple levels of sequence encoding ability, with increasing complexity, have been identified, from the mere representation of transition probabilities and timings to ordinal knowledge (which element comes first, second, third, etc.), recurring chunks, and even abstract patterns (e.g. does the sequence obey the pattern xxxxY, i.e. a repetition ending with a different element) (<xref ref-type="bibr" rid="bib34">Dehaene et al., 2015</xref>; <xref ref-type="bibr" rid="bib71">Jiang et al., 2018</xref>; <xref ref-type="bibr" rid="bib128">Shima et al., 2007</xref>; <xref ref-type="bibr" rid="bib146">Wang et al., 2015</xref>; <xref ref-type="bibr" rid="bib148">Wilson et al., 2013</xref>). We and others, however, proposed that the representation of sequences in humans may be unique in its ability to encode recursively nested hierarchical structures, similar to the nested phrase structures that linguists postulate to underlie human language (<xref ref-type="bibr" rid="bib34">Dehaene et al., 2015</xref>; <xref ref-type="bibr" rid="bib48">Fitch and Martins, 2014</xref>; <xref ref-type="bibr" rid="bib63">Hauser et al., 2002</xref>). Building on this idea, it was suggested that humans would spontaneously encode temporal sequences of stimuli using a language-like system of nested rules, a ‘language of thought’ (LOT; <xref ref-type="bibr" rid="bib50">Fodor, 1975</xref>; <xref ref-type="bibr" rid="bib3">Al Roumi et al., 2021</xref>; <xref ref-type="bibr" rid="bib5">Amalric and Dehaene, 2017a</xref>; <xref ref-type="bibr" rid="bib24">Chater and Vitányi, 2003</xref>; <xref ref-type="bibr" rid="bib42">Feldman, 2000</xref>; <xref ref-type="bibr" rid="bib89">Li and Vitányi, 1993</xref>; <xref ref-type="bibr" rid="bib94">Mathy and Feldman, 2012</xref>; <xref ref-type="bibr" rid="bib115">Planton et al., 2021</xref>; <xref ref-type="bibr" rid="bib147">Wang et al., 2019</xref>). For instance, when faced with a sequence such as xxYYxYxY, humans may encode it using an abstract internal expression equivalent to ‘2 groups of 2, and then an alternation of 4’.</p><p>The assumption that humans encode sequences in a recursive, language-like manner, was recently tested with a non-linguistic visuo-spatial task, by asking human adults and children to memorize and track geometric sequences of locations on the vertices of an octagon (<xref ref-type="bibr" rid="bib3">Al Roumi et al., 2021</xref>; <xref ref-type="bibr" rid="bib6">Amalric et al., 2017b</xref>; <xref ref-type="bibr" rid="bib147">Wang et al., 2019</xref>). Behavioral and brain-imaging studies showed that such sequences are internally compressed in human memory using an abstract ‘language of geometry’ that captures their numerical and geometrical regularities (e.g. ‘next element clockwise’, ‘vertical symmetry’). Indeed, behavioral results showed that the difficulty of memorizing a sequence was linearly modulated, not by the actual sequence length, but by the length of the program capable of generating it using the proposed language (‘minimal description length’ [MDL]; for a definition and brief review, see <xref ref-type="bibr" rid="bib35">Dehaene et al., 2022</xref>). The length of this program provides a predictor of sequence complexity. We will, from now on, refer to it as LoT complexity. In a follow-up fMRI experiment where participants had to follow the same sequences with their gaze, activity in the dorsal part of inferior prefrontal cortex correlated with the LoT complexity while the right dorsolateral prefrontal cortex encoded the presence of embedded structure (<xref ref-type="bibr" rid="bib147">Wang et al., 2019</xref>). These results indicate that sequences are stored in memory in a compressed manner, the size of this code being the length of the shortest program that describes the sequence in the proposed formal language. Memory for sequences would therefore follow the ‘MDL’ principle inherited from information theory (<xref ref-type="bibr" rid="bib59">Grunwald, 2004</xref>) and often used to capture various human behaviors (<xref ref-type="bibr" rid="bib24">Chater and Vitányi, 2003</xref>; <xref ref-type="bibr" rid="bib42">Feldman, 2000</xref>; <xref ref-type="bibr" rid="bib94">Mathy and Feldman, 2012</xref>). <xref ref-type="bibr" rid="bib147">Wang et al., 2019</xref>, further showed that the encoding and compression of such sequences involved brain areas supporting the processing of mathematical expressions rather than language-related areas, suggesting that multiple internal languages, not necessarily involving classical language areas, are present in the human brain. In a follow-up study, <xref ref-type="bibr" rid="bib3">Al Roumi et al., 2021</xref>, showed with MEG that the spatial, ordinal, and geometrical primitive codes postulated in the proposed LoT could be extracted from brain activity.</p><p>In the present work, we ask whether this LoT may also explain the human memory for binary auditory sequences (i.e. sequences made up of only two possible items, for instance two sounds with high and low pitch, respectively). While arguably minimal, binary sequences preserve the possibility of forming structures at different hierarchical levels. They therefore provide an elementary window into the mental representation of nested language-like rules, and which aspect of this representation, if any, is unique to the human species. While it would make little sense to ask if non-human animals can store spoken human sentences, it does seem more reasonable to submit them to a protocol with minimal, binary sound sequences, and ask whether they use a recursive language-like format for encoding in memory, or whether they are confined to statistical learning or chunking. The latter mechanisms are important to consider because they are thought to underpin the processing of several aspects of sequence processing in human infants and adults as well as several animal species, such as the extraction of chunks within a stream of syllables, tones, or shapes ( <xref ref-type="bibr" rid="bib49">Fló et al., 2019</xref>; <xref ref-type="bibr" rid="bib125">Santolin and Saffran, 2018</xref>; <xref ref-type="bibr" rid="bib138">Toro and Trobalón, 2005</xref>; <xref ref-type="bibr" rid="bib123">Saffran et al., 1996</xref>), or the community structure that generates a sequence of events (<xref ref-type="bibr" rid="bib73">Karuza et al., 2019</xref>; <xref ref-type="bibr" rid="bib126">Schapiro et al., 2013</xref>). Yet, very few studies have tried to separate the brain mechanisms underlying rule-based predictions from those of probabilistic sequence learning (<xref ref-type="bibr" rid="bib20">Bhanji et al., 2010</xref>; <xref ref-type="bibr" rid="bib79">Kóbor et al., 2018</xref>; <xref ref-type="bibr" rid="bib93">Maheu et al., 2021</xref>). Our goal here is to develop such a paradigm in humans, and to test the hypothesis that human internal models are based on a recursive LoT.</p><p>The present work capitalized on a series of behavioral experiments (<xref ref-type="bibr" rid="bib115">Planton et al., 2021</xref>) in which we proved that human performance in memorizing binary auditory sequences, as tested by the capacity to detect occasional violations, could be predicted by a modified version of the language of geometry, based on the hierarchical combination of very few primitives (repeat, alternate, concatenate, and integers). This work considered binary sequences of various lengths (from 6 to 16 items) mainly in the auditory but also in the visual modality, and showed that LoT complexity was correlated with participants’ oddball detection performance. This was especially true for longer sequences of 16 items as their length exceeds typical working memory capacity (<xref ref-type="bibr" rid="bib29">Cowan, 2001</xref>; <xref ref-type="bibr" rid="bib30">Cowan, 2010</xref>; <xref ref-type="bibr" rid="bib100">Miller, 1956</xref>) and therefore requires compression. In this work, LoT predictions were compared to competitor models of cognitive complexity and information compression (<xref ref-type="bibr" rid="bib1">Aksentijevic and Gibson, 2012</xref>; <xref ref-type="bibr" rid="bib2">Alexander and Carey, 1968</xref>; <xref ref-type="bibr" rid="bib36">Delahaye and Zenil, 2012</xref>; <xref ref-type="bibr" rid="bib55">Gauvrit et al., 2014</xref>; <xref ref-type="bibr" rid="bib57">Glanzer and Clark, 1963</xref>; <xref ref-type="bibr" rid="bib117">Psotka, 1975</xref>; <xref ref-type="bibr" rid="bib141">Vitz and Todd, 1969</xref>). The predictive power of LoT outperformed all competing theories (<xref ref-type="bibr" rid="bib115">Planton et al., 2021</xref>).</p><p>Here, we use functional MRI and magneto-encephalography (MEG) to investigate the cerebral underpinnings of the proposed language in the human brain. We exposed participants to 16-item auditory binary sequences, with varying levels of regularity, while recording their brain activity with fMRI and MEG in two separate experiments (see <xref ref-type="fig" rid="fig1">Figure 1</xref>). By combining these two techniques, we aimed at obtaining both the spatial and the temporal resolution needed to characterize in depth the neural mechanisms supporting sequence encoding and compression.</p><fig id="fig1" position="float"><label>Figure 1.</label><caption><title>Experimental design.</title><p>(<bold>A</bold>) List of the different 16-item sequences used in the magneto-encephalography (MEG) and fMRI experiments, with associated language of thought (LoT) complexity, and categorized according to the type of knowledge assumed to be required for optimal memory encoding. Orange marks indicate positions in which violations could occur (4 possible positions per sequence, all between positions 9 and 15). *Sequences used only in the fMRI experiment. Sequence description provided by the LoT and the corresponding verbal description are provided in <xref ref-type="supplementary-material" rid="supp1">Supplementary file 1</xref>. (<bold>B</bold>) Overview of the presentation paradigm (example with a session the Pairs&amp;Alt.1 sequence), with the respective characteristics of the fMRI experiment and the MEG experiment. One unique sequence was used in any given session. Each sequence was tested twice, in two different sessions (reversing the mapping between A/B items and low/high pitch).</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-84376-fig1-v1.tif"/></fig><p>In both fMRI and MEG, the experiment was composed of two phases. In a habituation phase, the sequences were repeatedly presented in order for participants to memorize them, thus probing the complexity of their internal model. In a test phase, sequences were occasionally presented with deviants (a single tone A replacing another tone B), thus probing the violations of expectations generated by the internal model (<xref ref-type="fig" rid="fig1">Figure 1B</xref>). We focused on a very simple prediction arising from the hierarchical predictive coding framework (<xref ref-type="bibr" rid="bib52">Friston, 2005</xref>). According to this view, and to much experimental research (e.g. <xref ref-type="bibr" rid="bib17">Bekinschtein et al., 2009</xref>; <xref ref-type="bibr" rid="bib23">Chao et al., 2018</xref>; <xref ref-type="bibr" rid="bib65">Heilbron and Chait, 2018</xref>; <xref ref-type="bibr" rid="bib132">Summerfield and de Lange, 2014</xref>; <xref ref-type="bibr" rid="bib144">Wacongne et al., 2011</xref>), the internal model of the sequence, as described by the postulated LoT, would be encoded by prefrontal regions of the brain, which would send anticipation signals to auditory areas, where they would be subtracted from incoming signals. As a consequence, we predict a reciprocal effect of LoT on the brain signals during habituation and during deviancy. In the habituation part of the experiment, lower amplitude response signals should be observed for sequences of low complexity – and conversely, during low complexity sequences, we expect top-down predictions to be stronger and therefore deviants to elicit larger responses, than for complex, hard to predict sequences.</p><p>Two subtleties further qualify this overall theoretical picture. First, at the highest level of sequence complexity, sequences cannot be compressed in a simple LoT expression, and therefore we expect the brain areas involved in nested sequence coding to exhibit no further increase in activation, or even a decrease (<xref ref-type="bibr" rid="bib142">Vogel and Machizawa, 2004</xref>; <xref ref-type="bibr" rid="bib147">Wang et al., 2019</xref>). We will evaluate the presence of such a non-linear trend by testing a quadratic term for LoT complexity in addition to a purely linear term in the regression models. Second, a simpler system of statistical learning, based on transition probabilities, may operate in parallel with LoT predictions (<xref ref-type="bibr" rid="bib17">Bekinschtein et al., 2009</xref>; <xref ref-type="bibr" rid="bib23">Chao et al., 2018</xref>; <xref ref-type="bibr" rid="bib92">Maheu et al., 2019</xref>; <xref ref-type="bibr" rid="bib93">Maheu et al., 2021</xref>; <xref ref-type="bibr" rid="bib99">Meyniel et al., 2016</xref>; <xref ref-type="bibr" rid="bib132">Summerfield and de Lange, 2014</xref>). To separate their contributions, we will use multiple predictors in a general linear model (GLM) of behavior and of MEG signals, whose temporal resolution allows to track individual sequence items (in fMRI, the BOLD response was too slow relative to the sequence rate of 250 ms per item).</p></sec><sec id="s2" sec-type="results"><title>Results</title><sec id="s2-1"><title>The LoT for binary sequences</title><p>As used in the present work, the LoT hypothesis postulates that humans encode mental objects such as sequences or geometric shapes using ‘mental programs’, that is expressions in a symbolic language characterized by (1) a small set of primitives and (2) the capacity to recursively combine these primitives through three operators: concatenation, repetition (possibly with variations), and recursive nesting (i.e. calling of a subprogram) (<xref ref-type="bibr" rid="bib35">Dehaene et al., 2022</xref>; <xref ref-type="bibr" rid="bib122">Sablé-Meyer et al., 2022</xref>). In this framework, defining a language requires the selection of a vocabulary of primitives that be recursively combined.</p><p>The language for binary sequences that we evaluate here is an adaptation of a LoT for spatial sequences with geometrical regularities, which accounted for participants’ predictions in an explicit sequence completion task (<xref ref-type="bibr" rid="bib5">Amalric and Dehaene, 2017a</xref>) and in a gaze anticipation task (<xref ref-type="bibr" rid="bib147">Wang et al., 2019</xref>). Previous fMRI and MEG studies have found neural evidence that human participants use such an LoT to encode geometrical sequences in memory and predict upcoming items (<xref ref-type="bibr" rid="bib3">Al Roumi et al., 2021</xref>; <xref ref-type="bibr" rid="bib147">Wang et al., 2019</xref>). For an in-depth description of this language, please see supporting information in <xref ref-type="bibr" rid="bib6">Amalric et al., 2017b</xref>.</p><p>In <xref ref-type="bibr" rid="bib115">Planton et al., 2021</xref>, we showed how the very same language could also account for the compression of auditory sequences made of two sounds. To obtain this language for binary sequences, instead of the eight vertices of the octagon, we consider only two states, A and B (e.g. a high-pitch and a low-pitch tone). The primitive operations are now reduced to the <italic>stay</italic> operation (called +<italic>0</italic>) and the <italic>change</italic> operation (called <italic>b</italic>). Note that, similarly to a Turing machine, the descriptions are sequential: each operation is relative to the previous state. The repetition operation, denoted by ^n, allows any sequence of operations to be repeated <italic>n</italic> times, possibly with variations, denoted by &lt;&gt;. For instance, the instruction ‘[xxx]^2&lt; +0 &gt;’ indicates that the expression [xxx] is executed twice, with the same starting point: ‘&lt; +0 &gt;’, while ‘[xxx]^2&lt; b &gt;’ indicates that the expression [xxx] is executed twice, with a change in the starting point: ‘&lt; b &gt;’ (see <xref ref-type="supplementary-material" rid="supp1">Supplementary file 1</xref>).</p><p>The description length of a mental program is computed as a weighted sum of the fixed costs attached to each primitive instruction (see supporting information in <xref ref-type="bibr" rid="bib6">Amalric et al., 2017b</xref>). The cost for repeating an instruction <italic>n</italic> times is assumed to correspond to log10(<italic>n</italic>) (rounded up), that is the number of digits needed to encode the number in decimal notation. Note that any given sequence has several possible descriptions. For instance, AAAA could be described as [+0,+0,+0,+0] or in a more compact manner as [+0]^4. LoT complexity is the MDL of a sequence, that is the shortest possible description of it in the proposed language.</p><p>In our previous work, we compared extensively the proposed LoT to other sequence encoding models such as entropy, change complexity, or algorithmic complexity (<xref ref-type="bibr" rid="bib115">Planton et al., 2021</xref>). The findings indicated that LoT complexity for chunk-preserving expressions, that is those that do not split any chunk of repetitions, provided the best fit of participants’ behavior, over and above all other competing models. The present study builds on these results and investigates the neural code of the LoT.</p></sec><sec id="s2-2"><title>Stimulus design</title><p>We designed a hierarchy of sequences (<xref ref-type="fig" rid="fig1">Figure 1</xref>) of fixed length (16 items) that should systematically vary in complexity according to our previously proposed LoT (<xref ref-type="bibr" rid="bib115">Planton et al., 2021</xref>) and whose gradations separate the lower-level representations of sequences that may be accessible to non-human primates (as outlined in <xref ref-type="bibr" rid="bib34">Dehaene et al., 2015</xref>) from the more abstract ones that may only be accessible to humans (<xref ref-type="fig" rid="fig1">Figure 1A</xref>).</p><p><xref ref-type="fig" rid="fig1">Figure 1</xref> presents the sequences we selected for the experiments and their complexit. In <xref ref-type="supplementary-material" rid="supp1">Supplementary file 1</xref>, we also give the formal LoT description and a short verbal description of their minimal program. The sequences formed a hierarchy. At the lowest level, much evidence indicates that the brain spontaneously encodes statistical regularities such as transition probabilities in sequential sensory inputs and uses them to make predictions (e.g. <xref ref-type="bibr" rid="bib14">Barascud et al., 2016</xref>; <xref ref-type="bibr" rid="bib19">Bendixen et al., 2009</xref>; <xref ref-type="bibr" rid="bib97">McDermott et al., 2013</xref>; <xref ref-type="bibr" rid="bib99">Meyniel et al., 2016</xref>; <xref ref-type="bibr" rid="bib123">Saffran et al., 1996</xref>), an ability well within the grasp of various non-human animals (e.g <xref ref-type="bibr" rid="bib62">Hauser et al., 2001</xref>; <xref ref-type="bibr" rid="bib98">Meyer and Olson, 2011</xref>). The first two sequences in our hierarchy therefore consisted in predictable repetitions (AAAA…) and alternations (ABABA…). In terms of information compression, such sequences can be represented with a very short LoT expression (a mere repetition, or a repetition of alternations).</p><p>At the next level, we tested chunking, the ability to group a recurring set of contiguous items into a single unit, another major sequence encoding mechanism which is also accessible to non-human primates (<xref ref-type="bibr" rid="bib22">Buiatti et al., 2009</xref>; <xref ref-type="bibr" rid="bib54">Fujii and Graybiel, 2003</xref>; <xref ref-type="bibr" rid="bib123">Saffran et al., 1996</xref>; <xref ref-type="bibr" rid="bib124">Sakai et al., 2003</xref>; <xref ref-type="bibr" rid="bib139">Uhrig et al., 2014</xref>). Thus, we included sequences made of pairs (AABBAABB…) or quadruplets (AAAABBBB…). Our LoT model attributes them a high level of compressibility, but already some degree of hierarchy (a loop of chunks). Relative to the previous sequences, they require monitoring the number of repetitions before a new chunk starts (ABABA…=1; AABBAA…=2; AAAABBBB…=4), and may therefore be expected to engage the number system, though to involve the bilateral intraparietal sulci, particularly their horizontal and anterior segments (<xref ref-type="bibr" rid="bib33">Dehaene et al., 2003</xref>; <xref ref-type="bibr" rid="bib37">Eger et al., 2009</xref>; <xref ref-type="bibr" rid="bib61">Harvey et al., 2013</xref>; <xref ref-type="bibr" rid="bib72">Kanayet et al., 2018</xref>).</p><p>The next level required nested structures, that is a hierarchical representation of smaller chunks embedded in larger chunks. Although there is some debate on whether this level of representation can be accessed by non-human animals, especially with extensive training (<xref ref-type="bibr" rid="bib43">Ferrigno et al., 2020</xref>; <xref ref-type="bibr" rid="bib56">Gentner et al., 2006</xref>; <xref ref-type="bibr" rid="bib71">Jiang et al., 2018</xref>; <xref ref-type="bibr" rid="bib140">van Heijningen et al., 2009</xref>), many agree that the ability to access it quickly and spontaneously is a potential human-specific trait in sequence learning and many related cognitive domains (<xref ref-type="bibr" rid="bib34">Dehaene et al., 2015</xref>; <xref ref-type="bibr" rid="bib45">Fitch and Hauser, 2004</xref>; <xref ref-type="bibr" rid="bib48">Fitch and Martins, 2014</xref>; <xref ref-type="bibr" rid="bib63">Hauser et al., 2002</xref>). We probe it using a variety of complex but compressible sequences such as ‘AABBABABAABBABAB’ (whose hierarchical description is [A²B²[AB]²]² and can be paraphrased as ‘2 pairs then 4 alternations, repeated twice’). Here again, our LoT model easily compresses such nested structures by using only one additional bit whenever a chunk needs to be repeated, regardless of its hierarchical depth (for details, see <xref ref-type="bibr" rid="bib5">Amalric and Dehaene, 2017a</xref>).</p><p>Finally, as a control, our paradigm also includes a high-complexity, largely incompressible sequence, with balanced transition probabilities and minimal chunking possibilities. We selected a sequence which our language predicted to be of maximal complexity (highest MDL), and which was therefore predicted to challenge the limits of working memory (<xref ref-type="fig" rid="fig1">Figure 1A</xref>). Note that because such a complex sequence, devoid of recurring regularities, is not easily encodable within our language (except for a trivial concatenation of chunks), we expect the brain areas involved in nested sequence coding to exhibit no further increase in activation, or even a decrease (<xref ref-type="bibr" rid="bib142">Vogel and Machizawa, 2004</xref>).</p></sec><sec id="s2-3"><title>Behavior in deviant detection</title><p>Similar to <xref ref-type="bibr" rid="bib115">Planton et al., 2021</xref>, we used task performance in the fMRI deviant detection task to quantify the LoT model’s ability to predict behavior. Sensitivity (<italic>d</italic>’) was calculated by examining the hit rate for each sequence and each violation position, relative to the overall false-alarm rate on standard no-violation trials. On average, participants managed to detect the deviants at above chance level in all sequences and at all positions (min <italic>d</italic>’=0.556, min t(22) = 2.919, p&lt;0.0080). Thus, they were able to detect a great variety of violation types in regular sequences (unexpected alternations, repetitions, change in number, or chunk boundaries). However, performance worsened as the 16-item sequences became too complex to be easily memorized. The group-averaged performance in violation detection for each sequence (regardless of deviant position) was linearly correlated with LoT complexity, both for response times to correctly detected items (RTs) (F(1, 8)=43.87, p&lt;0.0002, <italic>R</italic>²=0.85) and for sensitivity (<italic>d</italic>’) (F(1, 8)=159.4, p&lt;0.0001, <italic>R</italic>²=0.95) (see <xref ref-type="fig" rid="fig2">Figure 2A</xref>). When including the participants as a random factor in a linear mixed model, we obtained a very similar result for sensitivity (F(1, 206)=192.92, p&lt;0.0001, with estimates of –0.092±0.007 for the LoT complexity predictor, and 3.39±0.17 for the intercept), as well as for responses times (F(1, 203)=110.87, p&lt;0.0001, with estimates of 17.4 ms±1.6 for the LoT complexity predictor, and 475.4 ms±38.6 for the intercept). As for false alarms, they were rare, and no significant linear relationship with LoT complexity was found in group averages (F(1, 8)=2.18, p=0.18), although a small effect was found in a linear mixed model with participant as the random factor (F(1, 206)=4.83, p&lt;0.03, with estimates of 0.038±0.017 for the LoT complexity predictor, and 1.57±0.39 for the intercept).</p><fig-group><fig id="fig2" position="float"><label>Figure 2.</label><caption><title>Behavioral data.</title><p>(<bold>A</bold>) Group-averaged sensitivity (<bold><italic>d</italic>’</bold>) and response times for each sequence in the deviant detection task, plotted against the language of thought (LoT) complexity. A significant linear relationship with LoT complexity was found in both cases. The Pearson correlation coefficient and associated p-value are reported. Error bars represent SEM. (<bold>B</bold>) Comparison of the goodness of fit (indexed by the Akaike information criterion) of 12 mixed models (for sensitivity, top, and for response time, bottom), that is, each testing one out of six different complexity metrics (see main text) and including or not a transition-based surprise predictor. Δ<italic>(</italic>AIC) is the difference in AIC with the best model of the 12. A lower value indicates a better fit. The best model (Δ(AIC)=0) is marked by a green rectangle on the vertical axis. (<bold>C</bold>) The heatmap for each sequence represents the vector of the average number of brackets drawn by the participants around each item in the sequence bracketing task (after smoothing for illustration purposes). The Pearson correlation coefficient with the vector of brackets predicted by the LoT model is reported on the right side. A high correlation was obtained for all sequences but <italic>Alternate</italic>, since several subjects segmented this sequence in eight groups of two items, while the shortest LoT expression represented it in a single group of 16 items with 15 alternations.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-84376-fig2-v1.tif"/></fig><fig id="fig2s1" position="float" specific-use="child-fig"><label>Figure 2—figure supplement 1.</label><caption><title>Task performance: average sensitivity (<bold><italic>d</italic>’</bold>), for each position and each sequence.</title><p>Error bars represent SEM.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-84376-fig2-figsupp1-v1.tif"/></fig></fig-group><p>We evaluated whether these results could be explained by statistical learning, that is whether deviants were more easily or more rapidly detected when they violated the transition probabilities of the current sequence. For sensitivity (<italic>d</italic>’), a likelihood ratio test showed that adding a transition-probability measure of surprise (<xref ref-type="bibr" rid="bib92">Maheu et al., 2019</xref>; <xref ref-type="bibr" rid="bib99">Meyniel et al., 2016</xref>) to the linear regression with LoT complexity improved the goodness of fit (<italic>χ</italic>²(1)=4.35, p&lt;0.038). The effect of transition-based surprise was indeed significant in the new model (F(1, 205)=4.35, p&lt;0.039), but LoT complexity effect remained highly significant (F(1, 205)=106.28, p&lt;0.0001). Similarly, for RTs, adding transition-based surprise to the model significantly improved model fit (<italic>χ</italic>²(1)=12.27, p&lt;0.0005). Transition-based surprise explained some of the variance in RTs (F(1, 202)=12.51, p&lt;0.0006), but again the effect of LoT complexity remained highly significant (F(1, 202)=46.3, p&lt;0.0001).</p><p>We also added a quadratic complexity term to the models to determine whether the trend was purely linear (i.e., performance degrading continuously with complexity) or also had a non-linear component (e.g. ‘plateau’ performance after reaching a certain level of complexity). For sensitivity, a quadratic term did not improve goodness of fit, whether transition-based surprise was also included (<italic>χ</italic>²(1)=1.58, p=0.21) or not (<italic>χ</italic>²(1)=0.02, p=0.89). For RTs, it did not improve goodness of fit in the model including transition-based surprise (<italic>χ</italic>²(1)=1.43, p=0.23), but it did when transition-based surprise was not included (<italic>χ</italic>²(1)=6.76, p&lt;0.010). These results indicate that the effect of complexity on behavior is primarily linear, although a non-linear trend may be present on response times, as suggested by examining <xref ref-type="fig" rid="fig2">Figure 2A</xref>.</p><p>We then assessed whether alternative models of sequence complexity could better explain the present behavioral data, in an analysis similar to <xref ref-type="bibr" rid="bib115">Planton et al., 2021</xref>. The five alternative accounts we considered were: <italic>Entropy</italic>, a measure of information that quantifies the uncertainty of a distribution, here based on transition pairs (<xref ref-type="bibr" rid="bib93">Maheu et al., 2021</xref>); <italic>Lempel-Ziv complexity</italic>, derived from the popular lossless data compression algorithm (<xref ref-type="bibr" rid="bib88">Lempel and Ziv, 1976</xref>); <italic>number of subsymmetries</italic>, proposed by <xref ref-type="bibr" rid="bib2">Alexander and Carey, 1968</xref>, which is the number of symmetric subsequences of any length within a sequence; <italic>chunk complexity</italic>, a measure of the number of runs or chunks weighted by their length (<xref ref-type="bibr" rid="bib94">Mathy and Feldman, 2012</xref>; <xref ref-type="bibr" rid="bib115">Planton et al., 2021</xref>); and <italic>change complexity</italic>, a metric proposed by <xref ref-type="bibr" rid="bib1">Aksentijevic and Gibson, 2012</xref>, quantifying the average amount of ‘change’ across all subsequences contained in a sequence (see <xref ref-type="bibr" rid="bib115">Planton et al., 2021</xref>, for additional details on these metrics). As before, for each of these metrics plus LoT, we fitted two linear mixed models, with and without the transition-based surprise regressor, resulting in 12 models for sensitivity and 12 models for RTs. All models included participants as a random factor along with the fixed factor(s). The Akaike information criterion (AIC) was used as an indicator of goodness of fit. As presented in <xref ref-type="fig" rid="fig2">Figure 2B</xref>, for sensitivity, the best models to predict performance were, in this order, ‘LoT complexity + surprise’ (AIC = 582.9, conditional <italic>R</italic>²=0.62), ‘LoT complexity’ (AIC = 587.9, conditional <italic>R</italic>²=0.62) and ‘change complexity + surprise’ (AIC = 610.8, conditional <italic>R</italic>²=0.55). For RTs, the best models were ‘LoT complexity + surprise’ (AIC = 3031.2, conditional <italic>R</italic>²=0.55), ‘change complexity + surprise’ (AIC = 3038.1,, conditional <italic>R</italic>²=0.52) and ‘change complexity’ (AIC = 610.8, conditional <italic>R</italic>²=0.52). Regardless of the complexity metric, adding the transition-based surprise regressor in the model always resulted in improved goodness of fit (reduction in AIC of 18.54 on average for sensitivity, and 18.49 for RTs).</p><p>In summary, using a partially different set of sequences, we replicated the behavioral findings of <xref ref-type="bibr" rid="bib115">Planton et al., 2021</xref>: for long sequences that largely exceed the storage capacity in working memory, violation detection and response speed (both indexing the ease of memorizing the sequence and anticipating the next item) were well correlated with the LoT model of sequence compression, which outperformed other approaches for quantifying sequence complexity.</p></sec><sec id="s2-4"><title>Behavioral bracketing task</title><p>After brain imaging, we also asked all participants to report their intuitions of how each sequence should be parsed by drawing brackets on a visual representation of its contents (after listening to it). The results (see heatmaps in <xref ref-type="fig" rid="fig2">Figure 2C</xref>) indicated that participants agreed about how a sequence should be parsed and used bracketing levels appropriately for nested sequences. For instance, they consistently placed brackets in the middle of sequences that consisted of two repetitions of eight items, but did so less frequently both within those phrases and when the midpoint was not a predicted parsing point (CenterMirror in <xref ref-type="fig" rid="fig2">Figure 2C</xref>). In order to assess the correspondence between the parsings and the organization proposed by the LoT model, we computed for each sequence the correlation between the group-averaged number-of-brackets vector and the LoT model vector (obtained from the sequence segmentation derived from the LoT description in terms of repeat, alternate, and concatenate instructions). A strong correlation was found for sequences <italic>Repeat</italic> (Pearson <italic>r</italic>=0.96, p&lt;0.0001), <italic>Pairs</italic> (<italic>r</italic>=0.88, p&lt;0.0001), <italic>Quadruplets</italic> (<italic>r</italic>=0.96, p&lt;0.0001), <italic>Pairs&amp;Alt.1</italic> (<italic>r</italic>=0.94, p&lt;0.0001), <italic>Shrinking</italic> (<italic>r</italic>=0.93, p&lt;0.0001), <italic>Pairs&amp;Alt.2</italic> (<italic>r</italic>=0.85, p&lt;0.0001), <italic>ThreeTwo</italic> (<italic>r</italic>=0.95, p&lt;0.0001), <italic>CenterMirror</italic> (<italic>r</italic>=0.95, p&lt;0.0001), and <italic>Complex</italic> (<italic>r</italic>=0.84, p&lt;0.0001), but not for <italic>Alternate</italic> (<italic>r</italic>=0.08, p=0.77). For the latter, a departure from the proposed encoding was found: while the shortest LoT representation encodes it as ‘15 alternations’, the participants’ parses corresponded to ‘8 AB pairs’. In the discussion, we explain how this small departure from theory could have arisen from the specifics of the visual bracketing task, rather than the actual encoding of the auditory sequence.</p><p>It could be suggested that, rather than the structure predicted by the LoT model, participants use transition probabilities to segment a sequence, with rare transitions acting as chunk boundaries. We thus tested the correlations between the group-averaged number-of-brackets vector and the transition-based surprise derived from transition probabilities. There are 15 item-to-item transitions in 16-item sequences, thus brackets before the first and after the last items were excluded from this analysis. Surprise was computed by pooling over all the transitions in a given sequence. Due to lack of variance, a correlation with transition-based surprise was impossible for sequences <italic>Repeat</italic> (all transitions are 100% predictable repetitions) and <italic>Alternate</italic> (all transitions are 100% predictable alternations). For other sequences, a positive correlation was found for sequences <italic>Quadruplets</italic> (<italic>r</italic>=0.99, p&lt;0.0001), <italic>Pairs</italic> (<italic>r</italic>=0.88, p&lt;0.0001), <italic>Complex</italic> (<italic>r</italic>=0.79, p&lt;0.0005), <italic>Shrinking</italic> (<italic>r</italic>=0.73, p&lt;0.002), <italic>ThreeTwo</italic> (<italic>r</italic>=0.68, p&lt;0.006), and <italic>CenterMirror</italic> (<italic>r</italic>=0.64, p&lt;0.02). Crucially, however, no positive correlation was found for sequences <italic>Pairs&amp;Alt.1</italic> (<italic>r</italic>=–0.48, p=0.071) and <italic>Pairs&amp;Alt.2</italic> (<italic>r</italic>=–0.58, p&lt;0.03). This was due to the fact that repetitions were the rarest and therefore the most surprising transitions in these sequences: thus transition probabilities predicted a breaking of the chunks of repeated item, while participants correctly did not do so and placed their brackets at chunk boundaries (<xref ref-type="bibr" rid="bib115">Planton et al., 2021</xref>). Therefore, although surprise arising from the learning of transition probabilities can partially predict participants’ bracketing behavior in some cases, notably when a sequence is composed of frequent repetitions and rare alternations, this model completely fails in other (e.g. when repetitions are rare), again indicating that higher-level models such as LoT are needed to explain behavior.</p><p>In summary, using a partially different set of sequences, we replicated the behavioral findings of <xref ref-type="bibr" rid="bib115">Planton et al., 2021</xref>, showing that, especially for long sequences that largely exceed the storage capacity in working memory, violation detection (an index of learning quality) and response speed (potentially indexing the degree of predictability) were well predicted by our LoT model of sequence compression.</p></sec><sec id="s2-5"><title>fMRI data</title><sec id="s2-5-1"><title>A positive effect of complexity during sequence learning and tracking</title><p>As predicted, during the habituation phase (i.e. during sequence learning), fMRI activation mostly increased with sequence complexity in a broad and bilateral network involving supplementary motor area (SMA), precentral gyrus (preCG) abutting the dorsal part of Brodmann area 44, cerebellum (lobules VI and VIII), superior and middle temporal gyri (STG/MTG), and the anterior intraparietal sulcus (IPS) region (close to its junction with the postcentral gyrus) (<xref ref-type="fig" rid="fig3">Figure 3A</xref> and <xref ref-type="table" rid="table1">Table 1</xref>). These regions partially overlapped with those observed in sequence learning for a completely different domain, yet a similar language: the visuo-spatial sequences of <xref ref-type="bibr" rid="bib147">Wang et al., 2019</xref>. In the opposite direction, a reduction of activation with complexity was seen in a smaller network, mostly corresponding to the default-mode network, which was increasingly deactivated as working memory load increased (<xref ref-type="bibr" rid="bib96">Mazoyer et al., 2001</xref>; <xref ref-type="bibr" rid="bib118">Raichle, 2015</xref>): medial frontal cortex, left middle cingulate gyrus, left angular gyrus (AG), and left pars orbitalis of the inferior frontal gyrus (IFGorb) (<xref ref-type="table" rid="table1">Table 1</xref>).</p><fig-group><fig id="fig3" position="float"><label>Figure 3.</label><caption><title>Sequence complexity in the proposed language of thought (LoT) modulates fMRI responses.</title><p>(<bold>A</bold>) Brain areas showing an increase (hot colors) or a decrease (cold colors) in activation with sequence LoT complexity during habituation (voxel-wise p&lt;0.001, uncorrected; cluster-wise p&lt;0.05, FDR corrected). Scatterplots represent the group-averaged activation for each of the ten sequences as a function of their LoT complexity (left panels: habituation trials; right panels, deviant trials) in each of nine regions of interest (ROIs). Data values are from a participant-specific ROI analysis. Error bars represent SEM. Linear trends are represented by a solid line (with 95% CI in dark gray) and quadratic trend by a dashed line (with 95% CI in light gray). Pearson linear correlation coefficients are also reported. (<bold>B</bold>) Time course of group-averaged BOLD signals for each sequence, for four representative ROIs. Each mini-session lasted 160 s and consisted of 28 trials divided into 5 blocks (2×5 habituation and 3×6 test trials), interspersed with short rest periods of variable duration (depicted in light gray). The full time course was reconstituted by resynchronizing the data at the onset of each successive block (see Materials and methods). Shading around each time course represents one SEM.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-84376-fig3-v1.tif"/></fig><fig id="fig3s1" position="float" specific-use="child-fig"><label>Figure 3—figure supplement 1.</label><caption><title>Positive (hot colors) and negative (cold colors) effects of language of thought (LoT) complexity effects on standard trials (voxel-wise p&lt;0.001, uncorrected; cluster-wise p&lt;0.05, FDR corrected).</title></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-84376-fig3-figsupp1-v1.tif"/></fig><fig id="fig3s2" position="float" specific-use="child-fig"><label>Figure 3—figure supplement 2.</label><caption><title>Time course of group-averaged BOLD signals for each sequence in nine regions of interest (ROIs) where a language of thought (LoT) complexity effect was found.</title><p>Each mini-session lasted 160 s and was composed of five blocks (two habituation and three tests) interspersed with short rest periods of variable duration (depicted in light gray). The full time course was reconstituted by resynchronizing the data at the onset of each successive block (see Materials and methods). Shading around each time course represents one SEM.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-84376-fig3-figsupp2-v1.tif"/></fig></fig-group><table-wrap id="table1" position="float"><label>Table 1.</label><caption><title>Coordinates of brain areas modulated by language of thought (LoT) complexity during habituation.</title></caption><table frame="hsides" rules="groups"><thead><tr><th align="left" valign="bottom"><italic>Positive LoT complexity effect in habituation trials</italic></th><th align="left" valign="bottom"/><th align="left" valign="bottom"/><th align="left" valign="bottom"/><th align="left" valign="bottom"/><th align="left" valign="bottom"/><th align="left" valign="bottom"/><th align="left" valign="bottom"/><th align="left" valign="bottom"/></tr><tr><th align="left" valign="bottom">Region</th><th align="left" valign="bottom"><italic>H</italic></th><th align="left" valign="bottom"><italic>k</italic></th><th align="left" valign="bottom">p(unc.)</th><th align="left" valign="bottom">p(FWE-corr)</th><th align="left" valign="bottom"><italic>T</italic></th><th align="left" valign="bottom"><italic>x</italic></th><th align="left" valign="bottom"><italic>y</italic></th><th align="left" valign="bottom"><italic>z</italic></th></tr></thead><tbody><tr><td align="left" valign="bottom" rowspan="3">Supplementary motor area, precentral gyrus, superior frontal gyrus (dorsolateral), middle frontal gyrus</td><td align="left" valign="bottom">L/R</td><td align="left" valign="bottom">8991</td><td align="left" valign="bottom">&lt;0.0001</td><td align="left" valign="bottom">&lt;0.0001</td><td align="left" valign="bottom">6.62</td><td align="left" valign="bottom">1</td><td align="left" valign="bottom">5</td><td align="left" valign="bottom">65</td></tr><tr><td align="left" valign="bottom"/><td align="left" valign="bottom"> </td><td align="left" valign="bottom">&lt;0.0001</td><td align="left" valign="bottom">&lt;0.001</td><td align="left" valign="bottom">5.82</td><td align="left" valign="bottom">8</td><td align="left" valign="bottom">12</td><td align="left" valign="bottom">49</td></tr><tr><td align="left" valign="bottom"/><td align="left" valign="bottom"> </td><td align="left" valign="bottom">&lt;0.0001</td><td align="left" valign="bottom">&lt;0.05</td><td align="left" valign="bottom">5.59</td><td align="left" valign="bottom">27</td><td align="left" valign="bottom">5</td><td align="left" valign="bottom">52</td></tr><tr><td align="left" valign="bottom">Lobule VIII of cerebellar hemisphere</td><td align="left" valign="bottom">L</td><td align="left" valign="bottom">1411</td><td align="left" valign="bottom">&lt;0.0001</td><td align="left" valign="bottom">&lt;0.0001</td><td align="left" valign="bottom">6.19</td><td align="left" valign="bottom">22</td><td align="left" valign="bottom">68</td><td align="left" valign="bottom">53</td></tr><tr><td align="left" valign="bottom">Lobule VI and Crus I of cerebellar hemisphere</td><td align="left" valign="bottom">L</td><td align="left" valign="bottom">939</td><td align="left" valign="bottom">&lt;0.0001</td><td align="left" valign="bottom">&lt;0.001</td><td align="left" valign="bottom">5.97</td><td align="left" valign="bottom">29</td><td align="left" valign="bottom">56</td><td align="left" valign="bottom">28</td></tr><tr><td align="left" valign="bottom" rowspan="3">Superior temporal gyrus, middle temporal gyrus</td><td align="left" valign="bottom">L</td><td align="left" valign="bottom">2022</td><td align="left" valign="bottom">&lt;0.0001</td><td align="left" valign="bottom">&lt;0.05</td><td align="left" valign="bottom">5.56</td><td align="left" valign="bottom">68</td><td align="left" valign="bottom">23</td><td align="left" valign="bottom">5</td></tr><tr><td align="left" valign="bottom"/><td align="left" valign="bottom"> </td><td align="left" valign="bottom">&lt;0.0001</td><td align="left" valign="bottom">&lt;0.05</td><td align="left" valign="bottom">4.80</td><td align="left" valign="bottom">59</td><td align="left" valign="bottom">35</td><td align="left" valign="bottom">12</td></tr><tr><td align="left" valign="bottom"/><td align="left" valign="bottom"> </td><td align="left" valign="bottom">&lt;0.0001</td><td align="left" valign="bottom">0.213</td><td align="left" valign="bottom">4.25</td><td align="left" valign="bottom">55</td><td align="left" valign="bottom">42</td><td align="left" valign="bottom">23</td></tr><tr><td align="left" valign="bottom">Lobule VI of cerebellar hemisphere</td><td align="left" valign="bottom">R</td><td align="left" valign="bottom">1216</td><td align="left" valign="bottom">&lt;0.0001</td><td align="left" valign="bottom">&lt;0.05</td><td align="left" valign="bottom">5.45</td><td align="left" valign="bottom">27</td><td align="left" valign="bottom">58</td><td align="left" valign="bottom">27</td></tr><tr><td align="left" valign="bottom" rowspan="2">Lobule VIII of cerebellar hemisphere</td><td align="left" valign="bottom">L</td><td align="left" valign="bottom">1549</td><td align="left" valign="bottom">&lt;0.0001</td><td align="left" valign="bottom">&lt;0.05</td><td align="left" valign="bottom">5.04</td><td align="left" valign="bottom">22</td><td align="left" valign="bottom">67</td><td align="left" valign="bottom">53</td></tr><tr><td align="left" valign="bottom"/><td align="left" valign="bottom"> </td><td align="left" valign="bottom">&lt;0.0001</td><td align="left" valign="bottom">0.118</td><td align="left" valign="bottom">4.44</td><td align="left" valign="bottom">33</td><td align="left" valign="bottom">54</td><td align="left" valign="bottom">55</td></tr><tr><td align="left" valign="bottom" rowspan="3">Superior temporal gyrus</td><td align="left" valign="bottom">R</td><td align="left" valign="bottom">1039</td><td align="left" valign="bottom">&lt;0.0001</td><td align="left" valign="bottom">&lt;0.05</td><td align="left" valign="bottom">4.93</td><td align="left" valign="bottom">48</td><td align="left" valign="bottom">30</td><td align="left" valign="bottom">3</td></tr><tr><td align="left" valign="bottom"/><td align="left" valign="bottom"> </td><td align="left" valign="bottom">&lt;0.0001</td><td align="left" valign="bottom">&lt;0.05</td><td align="left" valign="bottom">4.79</td><td align="left" valign="bottom">67</td><td align="left" valign="bottom">44</td><td align="left" valign="bottom">17</td></tr><tr><td align="left" valign="bottom"/><td align="left" valign="bottom"> </td><td align="left" valign="bottom">&lt;0.001</td><td align="left" valign="bottom">0.880</td><td align="left" valign="bottom">3.55</td><td align="left" valign="bottom">69</td><td align="left" valign="bottom">23</td><td align="left" valign="bottom">3</td></tr><tr><td align="left" valign="bottom" rowspan="3">Postcentral gyrus, Inferior parietal gyrus</td><td align="left" valign="bottom">R</td><td align="left" valign="bottom">1478</td><td align="left" valign="bottom">&lt;0.0001</td><td align="left" valign="bottom">&lt;0.05</td><td align="left" valign="bottom">4.79</td><td align="left" valign="bottom">36</td><td align="left" valign="bottom">46</td><td align="left" valign="bottom">56</td></tr><tr><td align="left" valign="bottom"/><td align="left" valign="bottom"> </td><td align="left" valign="bottom">&lt;0.0001</td><td align="left" valign="bottom">0.061</td><td align="left" valign="bottom">4.63</td><td align="left" valign="bottom">46</td><td align="left" valign="bottom">35</td><td align="left" valign="bottom">61</td></tr><tr><td align="left" valign="bottom"/><td align="left" valign="bottom"> </td><td align="left" valign="bottom">&lt;0.0001</td><td align="left" valign="bottom">0.170</td><td align="left" valign="bottom">4.33</td><td align="left" valign="bottom">46</td><td align="left" valign="bottom">32</td><td align="left" valign="bottom">47</td></tr><tr><td align="left" valign="bottom" rowspan="2">Superior parietal gyrus, Precuneus</td><td align="left" valign="bottom">R</td><td align="left" valign="bottom">547</td><td align="left" valign="bottom">&lt;0.0001</td><td align="left" valign="bottom">0.085</td><td align="left" valign="bottom">4.54</td><td align="left" valign="bottom">17</td><td align="left" valign="bottom">67</td><td align="left" valign="bottom">58</td></tr><tr><td align="left" valign="bottom"/><td align="left" valign="bottom"> </td><td align="left" valign="bottom">&lt;0.001</td><td align="left" valign="bottom">0.792</td><td align="left" valign="bottom">3.65</td><td align="left" valign="bottom">24</td><td align="left" valign="bottom">60</td><td align="left" valign="bottom">42</td></tr><tr><td align="left" valign="bottom" rowspan="3">Inferior parietal gyrus, Postcentral gyrus</td><td align="left" valign="bottom">L</td><td align="left" valign="bottom">1570</td><td align="left" valign="bottom">&lt;0.0001</td><td align="left" valign="bottom">0.106</td><td align="left" valign="bottom">4.47</td><td align="left" valign="bottom">31</td><td align="left" valign="bottom">42</td><td align="left" valign="bottom">44</td></tr><tr><td align="left" valign="bottom"/><td align="left" valign="bottom"> </td><td align="left" valign="bottom">&lt;0.0001</td><td align="left" valign="bottom">0.149</td><td align="left" valign="bottom">4.37</td><td align="left" valign="bottom">45</td><td align="left" valign="bottom">35</td><td align="left" valign="bottom">38</td></tr><tr><td align="left" valign="bottom"/><td align="left" valign="bottom"> </td><td align="left" valign="bottom">&lt;0.0001</td><td align="left" valign="bottom">0.530</td><td align="left" valign="bottom">3.90</td><td align="left" valign="bottom">40</td><td align="left" valign="bottom">42</td><td align="left" valign="bottom">61</td></tr><tr><td align="left" valign="bottom"><bold><italic>Negative LoT complexity effect in habituation trials</italic></bold></td><td align="left" valign="bottom"/><td align="left" valign="bottom"> </td><td align="left" valign="bottom"> </td><td align="left" valign="bottom"> </td><td align="left" valign="bottom"> </td><td align="left" valign="bottom"> </td><td align="left" valign="bottom"> </td><td align="left" valign="bottom"> </td></tr><tr><td align="left" valign="bottom"><bold>Region</bold></td><td align="left" valign="bottom"><bold><italic>H</italic></bold></td><td align="left" valign="bottom"><bold><italic>k</italic></bold></td><td align="left" valign="bottom"><bold>p(unc</bold>.)</td><td align="left" valign="bottom"><bold>p(FWE-corr</bold>)</td><td align="left" valign="bottom"><bold><italic>T</italic></bold></td><td align="left" valign="bottom"><bold><italic>x</italic></bold></td><td align="left" valign="bottom"><bold><italic>y</italic></bold></td><td align="left" valign="bottom"><bold><italic>z</italic></bold></td></tr><tr><td align="left" valign="bottom" rowspan="3">Superior frontal gyrus (dorsolateral, medial, medial orbital), middle frontal gyrus</td><td align="left" valign="bottom">L/R</td><td align="left" valign="bottom">12366</td><td align="left" valign="bottom">&lt;0.0001</td><td align="left" valign="bottom">&lt;0.001</td><td align="left" valign="bottom">5.86</td><td align="left" valign="bottom">19</td><td align="left" valign="bottom">67</td><td align="left" valign="bottom">12</td></tr><tr><td align="left" valign="bottom"/><td align="left" valign="bottom"> </td><td align="left" valign="bottom">&lt;0.0001</td><td align="left" valign="bottom">&lt;0.05</td><td align="left" valign="bottom">5.42</td><td align="left" valign="bottom">29</td><td align="left" valign="bottom">25</td><td align="left" valign="bottom">47</td></tr><tr><td align="left" valign="bottom"/><td align="left" valign="bottom"> </td><td align="left" valign="bottom">&lt;0.0001</td><td align="left" valign="bottom">&lt;0.05</td><td align="left" valign="bottom">5.33</td><td align="left" valign="bottom">6</td><td align="left" valign="bottom">44</td><td align="left" valign="bottom">58</td></tr><tr><td align="left" valign="bottom">Middle cingulate and paracingulate gyri, precuneus</td><td align="left" valign="bottom">L</td><td align="left" valign="bottom">1444</td><td align="left" valign="bottom">&lt;0.0001</td><td align="left" valign="bottom">&lt;0.05</td><td align="left" valign="bottom">5.26</td><td align="left" valign="bottom">1</td><td align="left" valign="bottom">33</td><td align="left" valign="bottom">51</td></tr><tr><td align="left" valign="bottom" rowspan="3">Angular gyrus</td><td align="left" valign="bottom">L</td><td align="left" valign="bottom">1530</td><td align="left" valign="bottom">&lt;0.0001</td><td align="left" valign="bottom">0.060</td><td align="left" valign="bottom">4.63</td><td align="left" valign="bottom">43</td><td align="left" valign="bottom">65</td><td align="left" valign="bottom">37</td></tr><tr><td align="left" valign="bottom"/><td align="left" valign="bottom"> </td><td align="left" valign="bottom">&lt;0.001</td><td align="left" valign="bottom">0.816</td><td align="left" valign="bottom">3.63</td><td align="left" valign="bottom">33</td><td align="left" valign="bottom">54</td><td align="left" valign="bottom">24</td></tr><tr><td align="left" valign="bottom"/><td align="left" valign="bottom"> </td><td align="left" valign="bottom">&lt;0.001</td><td align="left" valign="bottom">0.938</td><td align="left" valign="bottom">3.45</td><td align="left" valign="bottom">27</td><td align="left" valign="bottom">82</td><td align="left" valign="bottom">44</td></tr><tr><td align="left" valign="bottom" rowspan="3">IFG pars orbitalis</td><td align="left" valign="bottom">L</td><td align="left" valign="bottom">522</td><td align="left" valign="bottom">&lt;0.0001</td><td align="left" valign="bottom">0.354</td><td align="left" valign="bottom">4.07</td><td align="left" valign="bottom">52</td><td align="left" valign="bottom">35</td><td align="left" valign="bottom">14</td></tr><tr><td align="left" valign="bottom"/><td align="left" valign="bottom"> </td><td align="left" valign="bottom">&lt;0.0001</td><td align="left" valign="bottom">0.473</td><td align="left" valign="bottom">3.95</td><td align="left" valign="bottom">34</td><td align="left" valign="bottom">40</td><td align="left" valign="bottom">7</td></tr><tr><td align="left" valign="bottom"/><td align="left" valign="bottom"> </td><td align="left" valign="bottom">&lt;0.0001</td><td align="left" valign="bottom">0.645</td><td align="left" valign="bottom">3.80</td><td align="left" valign="bottom">27</td><td align="left" valign="bottom">33</td><td align="left" valign="bottom">16</td></tr></tbody></table></table-wrap><p>We then computed the same contrast with the standard trials of the test phase (sequences without violation). The network of areas showing a positive complexity effect was much smaller than during habituation: it included bilateral superior parietal cortex extending into the precuneus, left dorsal premotor area, as well as two cerebellar regions (right lobule IV, left lobule VIII) (<xref ref-type="fig" rid="fig2s1">Figure 2—figure supplement 1</xref>, <xref ref-type="supplementary-material" rid="supp2">Supplementary file 2</xref>). These areas were also found during the habituation phase, although the (predominantly left) parietal superior/precuneus activation was larger and extended more posteriorily than during habituation. Regions showing a negative LoT complexity effect in standard trials (reduced activation for increasing complexity) were more numerous: medial frontal regions, middle cingulate gyri, bilateral AG, bilateral anterior part of the inferior temporal gyrus, bilateral putamen, as well as left frontal orbital region and left occipital gyrus. Here again, they largely resemble what was already observed in habituation trials (i.e. a deactivation of a default-mode network), with a few additional elements such as the putamen.</p></sec><sec id="s2-5-2"><title>A negative effect of complexity on deviant responses</title><p>The effect of LoT complexity at the whole-brain level was first assessed on the responses to all deviant stimuli (whether detected or not). A positive linear effect of complexity was only found in a small cluster of the medial part of the superior frontal gyrus (SFG) (<xref ref-type="supplementary-material" rid="supp3">Supplementary file 3</xref>). As predicted, a much larger network showed a negative effect (i.e. reduced activation with complexity or increased activation for less complex sequences): bilateral postcentral gyrus (with major peak in the ventral part), supramarginal gyrus (SMG), IPS, STG, posterior MTG, ventral preCG, insula, SMA and middle cingulate gyrus, cerebellum (lobules VI, VIII, and vermis), right pars triangularis of the IFG (red activation map of <xref ref-type="fig" rid="fig4">Figure 4</xref>, <xref ref-type="supplementary-material" rid="supp3">Supplementary file 3</xref>). This network is thus the possible brain counterpart of the increase in deviant detection performance observed as sequences become less and less complex. However, this result could be partly due to a motor effect, since manual motor responses to deviants were less frequent for more complex sequences, as attested by an effect of LoT complexity on sensitivity. We therefore computed the same contrast using an alternative GLM modeling-only deviant trials to which the participant correctly responded (note that this model consequently included fewer trials, especially for higher complexity sequences). Negative effects of LoT complexity were still present in this alternative model, now unconfounded by motor responses. As shown in <xref ref-type="fig" rid="fig4">Figure 4</xref> (yellow) the negative effect network was a subpart of the network identified in the previous model, and concerned bilateral STG, MTG, SMG/postcentral gyrus, insula, SMA, and middle cingulate gyrus. A positive effect was still present in a medial SFG cluster, part of the default-mode network showing less deactivation for deviants as complexity increased.</p><fig id="fig4" position="float"><label>Figure 4.</label><caption><title>Brain responses to deviants decrease with language of thought (LoT) complexity.</title><p>Colors indicate the brain areas whose activation on deviant trials decreased significantly with complexity, in two distinct general linear models (GLMs): one in which all deviant stimuli were modeled (red), and one in which only correctly detected deviant stimuli were modeled (green) (voxel-wise p&lt;0.001, uncorrected; cluster-wise p&lt;0.05, FDR corrected). Overlap is shown in yellow.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-84376-fig4-v1.tif"/></fig></sec><sec id="s2-5-3"><title>ROI analyses of the profile of the complexity effect</title><p>We next used individual ROIs to measure the precise shape of the complexity effect and test the hypothesis that (1) activation increases with complexity but may reach a plateau or decrease for the most complex, incompressible sequence; and (2) on deviant trials, the complexity effect occurs in the opposite direction. Because merely plotting the signal at peaks identified by a linear or quadratic contrast would bias the results (<xref ref-type="bibr" rid="bib143">Vul et al., 2009</xref>), we designed cross-validated individual ROI analyses, which consisted in (1) considering half of the runs to identify responsive subject-specific voxels within each ROI, using a contrast of positive effect of complexity during habituation; and (2) considering the other half to extract the activation levels for each standard or deviant sequence. Only the initial search volumes were defined on the basis of the entire data from the present study, which is likely to introduce only a minimal degree of circularity. We focused on nine areas that exhibited a positive complexity contrast in habituation (<xref ref-type="fig" rid="fig3">Figure 3</xref>), where the effect was robust and was computed on the learning phase of the experiment, therefore uncontaminated by deviant stimuli and manual motor responses.</p><p>In each ROI, mixed-effect models with participants as the random factor were used to assess the replicability of the linear effect of complexity during habituation. A significant effect was found in all ROIs (after Bonferroni correction for nine ROIs), although with variable effect size: SMA: <italic>β</italic> estimate = 0.10, t(21) = 5.37, p.corr &lt;0.0003; L-STG: <italic>β</italic>=0.06, t(21) = 4.75, p.corr &lt;0.001; L-CER6: <italic>β</italic>=0.04, t(21) = 4.73, p.corr &lt;0.002; R-IPS: <italic>β</italic>=0.07, t(21) = 4.08, p.corr &lt;0.005; L-preCG: <italic>β</italic>=0.07, t(21) = 3.98, p.corr &lt;0.007; R-preCG: <italic>β</italic>=0.08, t(21) = 3.8, p.corr &lt;0.01; R-STG: <italic>β</italic>=0.03, t(21) = 3.35, p.corr &lt;0.03; R-CER8: <italic>β</italic>=0.03, t(21) = 3.32, p.corr &lt;0.03, and L-IPS: <italic>β</italic>=0.03, t(21) = 3.25, p.corr &lt;0.04. These results are illustrated in <xref ref-type="fig" rid="fig3">Figure 3A</xref>, showing the linear regression trend with values averaged per condition across participants. The addition of a quadratic term was significant for seven ROIs (SMA, L-CER6, L-IPS, L-preCG, L-STG, R-CER8, and R-IPS), but did not reached significance in R-preCG nor in R-STG. This effect was always negative, indicating that the activation increases with complexity reached saturation or decreased from the most complex sequence (see dashed lines in the scatter plots of <xref ref-type="fig" rid="fig3">Figure 3A</xref>).</p><p>We also examined the time course of activation profiles within each mini-session of the experiment, that is two habituation blocks followed by three test blocks. As shown in <xref ref-type="fig" rid="fig3">Figure 3B</xref> (see <xref ref-type="fig" rid="fig3s1">Figure 3—figure supplement 1</xref> for all nine ROIs), the activation time courses showed a brief activation to sequences, presumably corresponding to a brief search period. 5–10 s following the first block onset, however, activation quickly dropped to a similar and very low activation, or even a deactivation below the rest level, selectively for the four lowest-complexity sequences which involved only simple processes of transition probabilities or chunking. For other sequences, the BOLD effect increased in proportion to complexity, yet with a midlevel amplitude for the most complex sequence reflecting the saturation and the quadratic effect noted earlier. Thus, in 5–10 s, the profile of the complexity effect was firmly established, and it remained sustained over time during habituation and, with reduced amplitude, during test blocks. This finding indicated that the same areas were responsible for discovering the sequence profile and for monitoring it for violations during the test period. The profile was similar across regions, with one exception: while most areas showed the same, low activation to the first four, simplest sequences, the left and right IPS showed an increasing activation as a function of the number of items in a chunk (ABABAB…=1; AABBAA…=2; AAAABBBB…=4). This observation fits with the hypothesis that these regions are involved in numerosity representation, and may therefore implement the repetitions postulated in our language.</p><p>The ROI analyses were next performed with data from the deviant trials, in order to test whether areas previously identified as sensitive to sequence complexity when learning the sequence also showed an opposite modulation of their response to deviant trials. All ROIs indeed showed a significant negative effect of LoT complexity: R-STG: <italic>β</italic>=–0.46, t(197) = –8.01, p.corr &lt;0.0001; L-IPS: <italic>β</italic>=–0.44, t(197) = –6.35, p.corr &lt;0.0001; R-CER8: <italic>β</italic>=–0.23, t(197) = –5.09, p.corr &lt;0.0001; L-STG: <italic>β</italic>=–0.45, t(197) = –4.61, p.corr &lt;0.0001; L-CER6: <italic>β</italic>=–0.23, t(197) = –4.57, p.corr &lt;0.0001; R-preCG: <italic>β</italic>=–0.37, t(197) = –3.92, p.corr &lt;0.002; R-IPS: <italic>β</italic>=–0.49, t(197) = –3.85, p.corr &lt;0.002; SMA: <italic>β</italic>=–0.33, t(197) = –3.57, p.corr &lt;0.004, and L-preCG: <italic>β</italic>=–0.27, t(197) = –2.9, p.corr &lt;0.04. Interestingly, unlike during habituation, the addition of a quadratic term did not improve the regression except in a single area, L-STG: <italic>β</italic>=0.05, t(196) = 3.9, p.corr &lt;0.002. Smaller effects of the quadratic term were present in three other areas, but they were not significant after Bonferroni correction: R-CER8: <italic>β</italic>=0.02, t(196) = 2.68, p&lt;0.009; R-STG: <italic>β</italic>=0.02, t(196) = 2.42, p&lt;0.02, and L-IPS: <italic>β</italic>=0.02, t(196) = 2.3, p&lt;0.03.</p><p>As in the whole-brain analysis, we finally conducted a complementary analysis using activation computed with correctly detected deviants trials only. The linear LoT complexity was now only significant in four of the nine ROIs: R-STG: <italic>β</italic>=–0.48, t(197) = –7.64, p.corr &lt;0.0001; L-IPS: <italic>β</italic>=–0.34, t(197) = –4.54, p.corr &lt;0.0001; L-STG: <italic>β</italic>=–0.42, t(197) = –4.12, p.corr &lt;0.0006; R-CER8: <italic>β</italic>=–0.15, t(197) = –3.17, p.corr &lt;0.02. When adding a quadratic term, no significant effects were observed at the predefined threshold, although uncorrected ones were present for L-STG: <italic>β</italic>=0.03, t(196) = 2.37, p&lt;0.02 and R-CER8: <italic>β</italic>=0.01, t(196) = 2.05, p&lt;0.05.</p></sec><sec id="s2-5-4"><title>Overlap with the brain networks for language and mathematics</title><p>Past and present behavioral results suggest that an inner ‘language’ is required to explain human memory for auditory sequences – but is this language similar to natural language, or to the language of mathematics, and more specifically geometry, from which it is derived (<xref ref-type="bibr" rid="bib3">Al Roumi et al., 2021</xref>; <xref ref-type="bibr" rid="bib6">Amalric et al., 2017b</xref>; <xref ref-type="bibr" rid="bib147">Wang et al., 2019</xref>)? By including in our fMRI protocol an independent language and mathematics localizer experiment, we tested whether the very same cortical sites are involved in natural sentence processing, mathematical processing, and auditory sequences.</p><p>At the whole-brain group level, large amount of overlap was found between the mathematics network (whole-brain mental computation &gt; sentences processing contrast, in a second-level ANOVA of the localizer experiment) and the LoT complexity network (see <xref ref-type="fig" rid="fig5">Figure 5A</xref>): SMA, bilateral precentral cortex, bilateral anterior IPS, and bilateral cerebellum (lobules VI). Some overlap was also present, to a lower extent, with the language network (auditory and visual sentences &gt; auditory and visual control stimuli) and the LoT complexity network: left STG, SMA, left precentral gyrus, and right cerebellum.</p><fig id="fig5" position="float"><label>Figure 5.</label><caption><title>Sequence complexity effects in mathematics and language networks.</title><p>(<bold>A</bold>) Overlap between the brain areas showing an increase of activation with sequence language of thought (LoT) complexity during habituation in the main experiment (in red) and the brain areas showing an increased activation for mathematical processing (relative to simple listening/reading of non-mathematical sentences) in the localizer experiment (in green; both maps thresholded at voxel-wise p&lt;0.001 uncorrected, cluster-wise p&lt;0.05, FDR corrected). Overlap between the two activation maps is shown in yellow. (<bold>B</bold>) Overview of the seven search volumes representing the mathematics network (left) and the seven search volumes representing the language network (right) used in the region-of-interest (ROI) analyses. Within each ROI, each scatter plot represents the group-averaged activation for each of the 10 sequences according to their LoT complexity, for habitation blocks and for deviant trials (same format as <xref ref-type="fig" rid="fig3">Figure 3</xref>). A star (*) indicates significance of the linear effect of LoT complexity in a linear mixed-effects model.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-84376-fig5-v1.tif"/></fig><p>Such group-level overlap, however, could be misleading since they involve a significant degree of intersubject smoothing and averaging. For a more precise assessment of overlap, we extracted, for each subject and within each of seven language-related and seven math-related ROIs (see <xref ref-type="fig" rid="fig5">Figure 5</xref>), the subject-specific voxels that responded, respectively, to sentence processing and to mental calculation (same contrasts as above, but now within each subject). We then extracted the results from those ROIs and examined their variation with LoT complexity in the main experiment (during habituation). In the language network, a significant positive effect of LoT complexity during the habituation phase was only found in left IFGoper: <italic>β</italic>=0.03, t(197) = 4.25, p.corr &lt;0.0005 (<xref ref-type="fig" rid="fig5">Figure 5B</xref>). In fact, most other language areas showed either no activation or were deactivated (e.g. IFGorb, anterior superior temporal sulcus [aSTS], temporal pole [TP], temporoparietal junction [TPJ]). As concerns deviants, a significant negative effect of LoT complexity was found in left IFGoper: <italic>β</italic>=–0.23, t(197) = –3.04, p.corr &lt;0.04; and in left posterior superior temporal sulcus (pSTS): <italic>β</italic>=–0.24, t(197) = –3.27, p.corr &lt;0.02. The quadratic term was never found significant.</p><p>On the contrary, in the mathematics-related network, all areas showed a positive LoT complexity effect in habituation (<xref ref-type="fig" rid="fig5">Figure 5B</xref>): SMA: <italic>β</italic>=0.05, t(197) = 5.6, p.corr &lt;0.0001; left preCG/IFG: <italic>β</italic>=0.05, t(197) = 5.03, p.corr &lt;0.0001; right IPS: <italic>β</italic>=0.05, t(197) = 4.69, p.corr &lt;0.0001; right preCG/IFG: <italic>β</italic>=0.05, t(197) = 4.56, p.corr &lt;0.0002; right SFG: <italic>β</italic>=0.04, t(197) = 4, p.corr &lt;0.002; left IPS: <italic>β</italic>=0.04, t(197) = 3.78, p.corr &lt;0.003 and left SFG: <italic>β</italic>=0.02, t(197) = 3.15, p.corr &lt;0.03. The quadratic term in the second model was also significant for three of them: SMA: <italic>β</italic>=–0.01, t(196) = –4.11, p.corr &lt;0.0009; right preCG/IFG: <italic>β</italic>=0, t(196) = –3.21, p.corr &lt;0.03 and left preCG/IFG: <italic>β</italic>=0, t(196) = –3.1, p.corr &lt;0.04. A negative complexity effect for deviant trials reached significance in four areas: left IPS: <italic>β</italic>=–0.42, t(197) = –4.44, p.corr &lt;0.0003; left preCG/IFG: <italic>β</italic>=–0.48, t(197) = –4.31, p.corr &lt;0.0004; right IPS: <italic>β</italic>=–0.41, t(197) = –4, p.corr &lt;0.002, and SMA: <italic>β</italic>=–0.29, t(197) = –2.97, p.corr &lt;0.05. Their response pattern was not significantly quadratic.</p><p>To summarize, all dorsal regions previously identified as involved in mathematical-processing regions were sensitive to the complexity of our auditory binary sequences, as manifested by an increase, up to a certain level of complexity, during habituation; and, for most regions, a reduction of the novelty to deviants (especially for SMA, left preCG, and IPS). Such a sensitivity to complexity was conspicuously absent from language areas, except for the left pars opercularis of the IFG.</p></sec></sec><sec id="s2-6"><title>MEG results</title><p>The low temporal resolution of fMRI did not permit us to track the brain response to each of the 16 successive sequence items, nor to any local sequence properties such as item-by-item variations in surprise. To address this limit, a similar paradigm was tested with MEG. To maximize signal-to-noise, especially on rare deviant trials, only seven sequences were selected (<xref ref-type="fig" rid="fig1">Figures 1</xref> and <xref ref-type="fig" rid="fig6">6</xref>). Unlike the fMRI experiment, during MEG we merely asked participants to listen carefully to the presented sequences of sounds, without providing any button response, thus yielding pure measures of violation detection uncontaminated by the need to respond.</p><fig-group><fig id="fig6" position="float"><label>Figure 6.</label><caption><title>Sequence complexity in the proposed language of thought (LoT) modulates magneto-encephalography (MEG) signals to habituation, standard, and deviant trials.</title><p>(<bold>A</bold>) Global field power computed for each sequence (see color legend) from the evoked potentials of the <italic>habituation, standard,</italic> and <italic>deviant</italic> trials. 0 ms indicates sound onset. Note that the time window ranges until 350 ms for <italic>habituation</italic> and <italic>standard</italic> trials (with a new sound onset at S0A=250 ms), and until 600 ms for <italic>deviant</italic> trials and for the others. Significant correlation with sequence complexity was found in <italic>habituation</italic> and <italic>deviant</italic> GFPs and are indicated by the shaded areas. (<bold>B</bold>) Regressions of MEG signals as a function of sequence complexity. Left: amplitude of the regression coefficients β of the complexity regressor for each MEG sensor. Insets show the projection of those coefficients in source space at the maximal amplitude peak, indicated by a vertical dotted line. Right: spatiotemporal clusters where regression coefficients were significantly different from 0. While several clusters were found (see text and <xref ref-type="fig" rid="fig6s3">Figure 6—figure supplement 3</xref>), for the sake of illustration, only one is shown for each trial type. The clusters involved the same sensors but on different time windows (indicated by the shaded areas) and with an opposite t-value for <italic>deviant</italic> trials. Neural signals were averaged over significant sensors for each sequence type and were plotted separately.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-84376-fig6-v1.tif"/></fig><fig id="fig6s1" position="float" specific-use="child-fig"><label>Figure 6—figure supplement 1.</label><caption><title>Sequence complexity modulates the contrast of deviant / matched standard trials.</title><p>(<bold>A</bold>) Global field power computed for the deviant / matched standard contrast for each sequence (see color legend). 0 ms indicates sound onset. Significant correlation with sequence complexity is indicated by the shaded areas. (<bold>B</bold>) Regressions of contrast as a function of sequence complexity. Left: amplitude of the regression coefficients β of the complexity regressor for each magneto-encephalography (MEG) sensor. Right: spatiotemporal clusters where regression coefficients were significantly different from 0. Two clusters were found, the sake of illustration, only one is shown here. Unsurprisingly, the clusters involved the same sensors as in <xref ref-type="fig" rid="fig6">Figure 6</xref>. Neural signals were averaged over significant sensors for each sequence type and were plotted separately.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-84376-fig6-figsupp1-v1.tif"/></fig><fig id="fig6s2" position="float" specific-use="child-fig"><label>Figure 6—figure supplement 2.</label><caption><title>Unconfounding the effects of statistical surprise and sequence complexity on magneto-encephalography (MEG) signals.</title><p>Left: amplitude of the regression coefficients β of the complexity regressor for each MEG sensor, in a general linear model where transition-based surprise, repetition, and alternation were also modeled. Insets show the projection of these coefficients on the source space for its maximal amplitude value, indicated by the vertical dotted lines. Right: illustration of spatiotemporal clusters where regression coefficients were significantly different from 0. The time windows identified by the permutation test are indicated by the shaded areas and have an opposite t-value for <italic>deviant</italic> trials. Neural signals were averaged over the cluster sensors for each sequence type and were plotted separately (see color legend). Note that the time window goes until 600 ms for <italic>deviant</italic> trials and until 350 ms for the other trials.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-84376-fig6-figsupp2-v1.tif"/></fig><fig id="fig6s3" position="float" specific-use="child-fig"><label>Figure 6—figure supplement 3.</label><caption><title>Spatiotemporal clusters for the complexity regressor in sensor space, shown separately for the three trial types (<italic>habituation, standard, deviant</italic>) and three general linear models of magneto-encephalography (MEG) signals: with complexity alone (left column); with complexity, transition-based surprise and repeat/alternate (middle column); and with complexity after regressing out transition-based surprise and repeat/alternate signals.</title><p>The clusters are very similar in all three cases, suggesting a robust effect of complexity irrespectively of transition statistics.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-84376-fig6-figsupp3-v1.tif"/></fig><fig id="fig6s4" position="float" specific-use="child-fig"><label>Figure 6—figure supplement 4.</label><caption><title>Amplitude of the regression coefficient β for each magneto-encephalography (MEG) sensor for the four regressors of transition statistics: repetition/alternation for item <italic>n</italic> (presented at <italic>t</italic>=0 ms), repetition/alternation for item <italic>n</italic>+1 (presented at <italic>t</italic>=250 ms), transition-based surprise for item <italic>n,</italic> and transition-based surprise for item <italic>n</italic>+1.</title><p>The transition-based surprise predictor is computed using an ideal observer estimating surprise over 100 past observations. The projection on the source space at the time of its maximal amplitude is also shown.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-84376-fig6-figsupp4-v1.tif"/></fig></fig-group><sec id="s2-6-1"><title>Neural signatures of complexity at the univariate level</title><p>We first determine if a summary measure of brain activity, the global field power, is modulated by sequence complexity. To do so, we consider the brain responses to sounds occurring in the <italic>habituation</italic> phase, to non-deviant sounds occurring in the test phase (referred to as <italic>standard</italic> sounds) and to <italic>deviant</italic> sounds. On <italic>habituation</italic> trials, the late part of the auditory response (108–208 ms) correlated positively with complexity (p=0.00024, see shaded area in the top panel of <xref ref-type="fig" rid="fig6">Figure 6A</xref>): the more complex the sequence, the larger the brain response. On <italic>standard</italic> trials, this modulation of the GFP by complexity had vanished (middle panel of <xref ref-type="fig" rid="fig6">Figure 6A</xref>). Finally, as predicted, the GFP computed on the <italic>deviant</italic> exhibited the reversed effect, that is a negative correlation with complexity on the 116–300 ms time window (p=0.0005) and on the 312–560 ms time window (p=0.0005), indicating that <italic>deviants</italic> elicit larger brain responses in sequences with lower complexity (bottom panel of <xref ref-type="fig" rid="fig6">Figure 6A</xref>).</p><p>To better characterize the mechanisms of sequence coding, we ran a linear regression of the evoked responses to sounds as a function of sequence complexity. Regression coefficients of the sequence complexity predictor were projected to source space. The results showed that complexity effects were present in temporal and precentral regions of the cortex. To assess the significance of the regression coefficients, we ran a spatiotemporal cluster-based permutation test at the sensor level. Several significant clusters were found for each of the three trial types (<italic>habituation:</italic> cluster 1 from 72 to 216 ms, p=0.0004, cluster 2 from 96 to 212 ms, p=0.0002; <italic>standard</italic>: cluster 1 from 96 to 180 ms, p=0.0038, cluster 2 from 96 to 184 ms, p=0.001; <italic>deviant</italic>: cluster 1 from 60 to 600 ms, p=0.0002, cluster 2 from 56 to 600 ms, p=0.0002). <xref ref-type="fig" rid="fig6">Figure 6</xref> illustrates one significant cluster for each trial type. See <xref ref-type="fig" rid="fig6s3">Figure 6—figure supplement 3</xref> for all the clusters.</p><p>The same analyses were performed on the contrast of deviants-matched standards conditions. Matched-standard trials are selected such that they matched the deviants’ ordinal position, which was specific to each sequence. These results are reported in <xref ref-type="fig" rid="fig6s1">Figure 6—figure supplement 1</xref>. The clusters shown involve the same sensors but exhibit opposite regression signs for the brain responses to <italic>deviant</italic> sounds, suggesting that, as in fMRI, the same brain regions are involved in the processing of standard and deviant items but are affected by complexity in an opposite manner.</p></sec><sec id="s2-6-2"><title>Controlling for local transition probabilities</title><p>Several studies have shown that human EEG/MEG responses are sensitive to the statistics of sounds and sound transitions in a sequence (<xref ref-type="bibr" rid="bib92">Maheu et al., 2019</xref>; <xref ref-type="bibr" rid="bib99">Meyniel et al., 2016</xref>; <xref ref-type="bibr" rid="bib105">Näätänen et al., 1989</xref>; <xref ref-type="bibr" rid="bib135">Todorovic et al., 2011</xref>; <xref ref-type="bibr" rid="bib136">Todorovic and de Lange, 2012</xref>; <xref ref-type="bibr" rid="bib145">Wacongne et al., 2012</xref>), including in infants (<xref ref-type="bibr" rid="bib123">Saffran et al., 1996</xref>). When listening to probabilistic binary sequences of sounds, early brain responses reflect simple statistics such as item frequency while later brain responses reflect more complex, longer-term inferences (<xref ref-type="bibr" rid="bib92">Maheu et al., 2019</xref>). Since local transition-based surprise and global complexity were partially correlated in our sequences, could this surprise alone account for our results? To disentangle the contributions of transition probabilities and sequence structure in the present brain responses, we regressed the brain signals as a function of complexity and of surprise based on transition probabilities. To capture the latter, we added several predictors: the presence of a repetition or an alternation and the surprise of an ideal observer that makes optimal inferences about transition probabilities from the past 100 items (see <xref ref-type="bibr" rid="bib92">Maheu et al., 2019</xref>, for details). Both predictors were computed for two consecutive items: the one at stimulus onset (<italic>t</italic>=0 ms) and the next item (<italic>t</italic>=250 ms later) and included together with LoT complexity as multiple regressors of every time point.</p><p><xref ref-type="fig" rid="fig6s2">Figure 6—figure supplement 2</xref> shows the temporal profile of the regression coefficient for sequence complexity for each MEG sensor and its projection onto the source space, once these controlling variables were introduced. The contribution of auditory regions was slightly diminished compared to the simple regression of brain signals as a function of complexity. To assess the significance of the regression coefficient, we ran a spatiotemporal cluster-based permutation test at the sensor level. Several significant clusters were found for each of the three trial types (<italic>habituation:</italic> cluster 1 from 96 to 244 ms, p=0.0162, cluster 2 from 112 to 220 ms, p=0.014; <italic>standard</italic>: cluster 1 from 104.0 to 180.0 ms, cluster value=1.50, p=0.0226, cluster 2 from 100 to 220 ms, p=0.0004; <italic>deviant</italic>: cluster 1 from 224 to 600 ms, p=0.0088, cluster 2 from 116 to 600 ms, p=0.0006; see <xref ref-type="fig" rid="fig6s3">Figure 6—figure supplement 3</xref> for complete cluster profiles). The results remained even when the transition-based surprise regressors were entered first, and then the regression on complexity was performed on the residuals (<xref ref-type="fig" rid="fig6s2">Figure 6—figure supplement 2</xref>, right column). In summary, the positive effect of complexity on habituation and standard trials, and its negative effect on deviant trials, were not solely due to local transition-based surprise signals.</p></sec><sec id="s2-6-3"><title>Time-resolved decoding of violation responses</title><p>The above results were obtained by averaging sensor data across successive stimuli and across participants. A potentially more sensitive analysis method is multivariate decoding. It is a manner similar to <xref ref-type="bibr" rid="bib78">King and Dehaene, 2014</xref>, which searches, at each time point and within each participant, for an optimal pattern of sensor activity reflecting a given type of mental representation. Therefore, to further characterize the brain representations of sequence structure and complexity, we next used multivariate time-resolved analyses, which allowed us to track sequence coding for each item in the sequence, at the millisecond scale.</p><p>We trained a decoder to classify all standard versus all deviant trials (<xref ref-type="bibr" rid="bib38">El Karoui et al., 2015</xref>; <xref ref-type="bibr" rid="bib77">King et al., 2013</xref>). As the two versions of the same sequence were presented on two separated runs (respectively starting with sound ‘A’ or ‘B’), we trained and tested the decoder in a leave-one-run out manner, thus forcing it to identify non-stimulus-specific sequence violation responses. In addition, and most importantly, we selected standard trials that matched the deviants’ ordinal position, which was specific to each sequence (see <xref ref-type="fig" rid="fig1">Figure 1</xref>, orange lines). <xref ref-type="fig" rid="fig7">Figure 7</xref> shows the average projection on the decision vector of the classifier’s predictions on left-out data for the different sequences, when tested on both position-matched <italic>deviants</italic> versus <italic>standards</italic> (<xref ref-type="fig" rid="fig7">Figure 7A</xref>) and on <italic>habituation</italic> trials (<xref ref-type="fig" rid="fig7">Figure 7B</xref>). Significance was determined by temporal cluster-based permutation tests.</p><fig id="fig7" position="float"><label>Figure 7.</label><caption><title>Multivariate decoding of deviant trials from magneto-encephalography (MEG) signals, and its variation with sequence complexity.</title><p>(<bold>A</bold>) A decoder was trained to classify standard from deviant trials from MEG signals at a given time point. We here show the difference in the projection on the decision vector for <italic>standard</italic> and <italic>deviant</italic> trials, that is a measure of the decoder’s accuracy. The decoder was trained jointly on all sequences, but its performance is plotted here for left-out trials separately for each sequence type. Shaded areas indicate s.e.m. and colored lines at bottom indicate the time windows identified by the temporal cluster-based permutation test (p&lt;0.05 corrected) obtained from cluster-based permutation test on the full window. The heatmap at the bottom represents the correlation of the performance with sequence complexity (Pearson’s r). The gray shaded time window in the main graph indicates the time window identified by the two-tailed p&lt;0.05, temporal cluster-based permutation test. (<bold>B</bold>) Projection on the decision vector for <italic>habituation</italic> trials. The early brain response is classified as deviant but later as standard. This projection time course is increasingly delayed as a function of sequence complexity (same format as A). (<bold>C</bold>) Sensor map showing the relative contribution of each sensor to overall decoding performance. At the time of maximal overall decoding performance (165 ms) we trained and tested 4000 new decoders that used only a subset of 40 gradiometers at 20 sensor locations. For each sensor location, the color on the maps in the right column indicates the average decoding performance when this sensor location was used in decoding, thus assessing its contribution to overall decoding.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-84376-fig7-v1.tif"/></fig><p>Decoding of deviants reached significance for all sequences except for the most complex ones (<italic>Shrinking</italic> and <italic>Complex</italic>). For the simplest <italic>Repeat</italic> and <italic>Alternate</italic> sequences, which could be learned solely based on transition probabilities, a sharp initial mismatch response was seen, peaking at ~150 ms. For all other sequences, the decoder exhibited a later, slower, lower-amplitude and sustained development of above-chance performance, suggesting that deviant items elicit decodable long-lasting brain signals. A temporal cluster-based permutation test on Pearson correlation with sequence complexity showed that the decoding of violations significantly correlated with complexity (temporal cluster from 90 to 580 ms).</p><p>The time courses of the decoder performance on habituation trials also revealed a clear hierarchy in the time it took for the brain to decide that a given tone was not a deviant (<xref ref-type="fig" rid="fig7">Figure 7B</xref>). The seven curves were ordered by predicted sequence complexity. Thus, the decoder’s classification as standard, quantified as the projection on the decision vector, decreased significantly with sequence complexity over two time windows (temporal cluster from ~90–220 ms and ~330–460 ms). This suggests that the more the sequence is complex, the more brittle its classification as standard is.</p></sec><sec id="s2-6-4"><title>Decoder performance over the full extent of each sequence</title><p>To characterize the time course of brain activity over the entire course of each sequence, we projected each MEG time point onto the decoding axis of the standard/deviant decoder trained on data from a 130–210 ms time window (<xref ref-type="fig" rid="fig8">Figure 8</xref>). The projection was computed separately for each sequence, separately for habituation, standard, and the four possible positions of deviant trials. We determined if deviants differed from standards using a cluster-based permutation test on a 0–600 ms window after each violation (colored lines at the bottom of each sequence in <xref ref-type="fig" rid="fig8">Figure 8A</xref>).</p><fig id="fig8" position="float"><label>Figure 8.</label><caption><title>Time course of the deviancy decoder across the different types of sequences and deviant positions.</title><p>(<bold>A</bold>) Average projection of magneto-encephalography (MEG) signals onto the decoding axis of the standard/deviant decoder. For each sequence, the time course of the projection was computed separately for habituation trials, standard trials, and for the four types of trials containing a deviant at a given position. The figure shows the average output of decoders trained between 130 and 210 ms post-deviant. Red indicates that a trial tends to be classified as a deviant, blue as a standard. Colored lines at the bottom of each graph indicate the time windows obtained from the cluster permutation test comparing deviants and standards in a 0–600 ms window after deviant onset. (<bold>B</bold>) Average generalization-across-time (GAT) matrices showing decoding performance as a function of decoder training time (y axis) and testing time (x axis). Vertical and horizontal lines indicate the onset of the next tone. The dashed lines outline p&lt;0.05 cluster-level significance, corrected for multiple comparisons (see Materials and methods). Simpler sequences exhibit overall greater and more sustained performance. We note that, while deviancy detection does not reach significance for Shrinking and Complex sequences in the GAT matrices, violation signals reached significance for deviant position 15.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-84376-fig8-v1.tif"/></fig><p>All individual deviants elicited a decodable response (see <italic>Materials and methods</italic>) except for the two highest-complexity sequences: <italic>Shrinking</italic> and <italic>Complex</italic> (failure at all positions exception the last one, i.e. 15). Interestingly, for the alternate sequence, two consecutive peaks indicate that, when a single repetition is introduced in an alternating sequence (e.g. ABABBBAB… instead of ABABABAB…), the brain interprets it as two consecutive violations, probably due to transition probabilities, as each of the B items is predicted to be followed by an A.</p><p>Most crucially, the analysis of specific violation responses allowed us to evaluate the range of properties that humans use to encode sequences, and to test the hypothesis that they integrate numerical and structural information at multiple nested levels (<xref ref-type="bibr" rid="bib146">Wang et al., 2015</xref>). First, within a chunk of consecutive items, they detect violations consisting in both chunk shortening (one repeated tone instead of two in <italic>Pairs</italic>; three tones instead of four in <italic>Quadruplets</italic>) and chunk lengthening (three repeated tones instead of two, as well as five instead of four). The contrast between those two sequences clearly shows that participants possess a sophisticated context-dependent representation of each sequence. Thus, their brain emits a violation response upon hearing three consecutive items (AA<bold>A</bold>) within the <italic>Pairs</italic> sequence, where it is unexpected, but not when the same sequence occurs within the <italic>Quadruplets</italic> sequence. Conversely, participants are surprised to hear the transition BBAA<bold>B</bold> in the <italic>Quadruplet</italic> context, but not in the <italic>Pairs</italic> context. Finally, in the <italic>Pairs+Alt</italic>.<italic>1</italic> sequence, such context dependence changes over time, thus indicating an additional level of nesting: at positions 9–12, subjects expect to hear two pairs (AABB) and are surprised to hear A<bold>B</bold>BB (unexpected alternation), but just a second later, at positions 13–16, they expect an alternation (ABAB) and are surprised to hear A<bold>A</bold>AB (unexpected repetition). Similar, though less significant, evidence for syntax-based violation responses is present in the <italic>Shrinking</italic> sequence, which also ends with two pairs and an alternation.</p><p><xref ref-type="fig" rid="fig8">Figure 8</xref> also shows in detail how the participants’ brain fluctuates between predictability (in blue) and violation detection (in red) during all phases of the experiment. Initially, during habituation (top line), sequences are partially unpredictable, as shown by red responses to successive stimuli, but that effect is strongly modulated by complexity, as previously reported (red responses, particularly for the most complex sequences). In a sense, while the sequence is being learned, all items in those sequences appear as deviants. As expected, after habituation, the deviancy response to standards is much reduced, but still ordered by complexity. Higher-complexity sequences such as <italic>Shrinking</italic> thus create a globally less predictable environment (red colors) relative to which the violation responses to deviants appear to be reduced.</p><p><xref ref-type="fig" rid="fig8">Figure 8B</xref> also shows how the standard-deviant decoder generalizes over time, separately for each sequence. The performance for the <italic>Repeat</italic> sequence exhibits a peak corresponding to the deviant item’s presentation (~150 ms) and a large and a partial square pattern, indicating a sustained maintenance of the deviance information. The performance for the <italic>Alternate</italic> sequence shows four peaks spaced by the SOA, corresponding to the two deviant transitions elicited by the deviant item. <italic>Pairs, Quadruplets,</italic> and <italic>Pairs+Alt</italic>.<italic>1</italic> sequences still show significant decoding but not <italic>Shrinking</italic> and <italic>Complex</italic> sequences, indicating that the ability to decode deviant signals decreases with complexity.</p></sec></sec></sec><sec id="s3" sec-type="discussion"><title>Discussion</title><p>The goal of this study was to characterize the mental representation that humans utilize to encode binary sequences of sounds in memory and to detect occasional deviants. The results indicate that, in the human brain, deviant responses go way beyond the sole detection of violations in habitual sounds (<xref ref-type="bibr" rid="bib95">May and Tiitinen, 2010</xref>) or in transition probabilities (<xref ref-type="bibr" rid="bib145">Wacongne et al., 2012</xref>), and are also sensitive to more complex, larger-scale regularities (<xref ref-type="bibr" rid="bib17">Bekinschtein et al., 2009</xref>; <xref ref-type="bibr" rid="bib18">Bendixen et al., 2007</xref>; <xref ref-type="bibr" rid="bib92">Maheu et al., 2019</xref>; <xref ref-type="bibr" rid="bib127">Schröger et al., 2007</xref>; <xref ref-type="bibr" rid="bib144">Wacongne et al., 2011</xref>; <xref ref-type="bibr" rid="bib146">Wang et al., 2015</xref>). Instead of merely storing each successive sound in a distinct memory slot (<xref ref-type="bibr" rid="bib9">Baddeley, 2003</xref>; <xref ref-type="bibr" rid="bib8">Baddeley and Hitch, 1974</xref>; <xref ref-type="bibr" rid="bib21">Botvinick and Watanabe, 2007</xref>; <xref ref-type="bibr" rid="bib67">Hurlstone et al., 2014</xref>), behavioral and brain imaging results suggest that participants mentally compressed these sequences using an algorithmic-like description where sequence regularities are expressed in terms of recursive combinations of simple rules (<xref ref-type="bibr" rid="bib3">Al Roumi et al., 2021</xref>; <xref ref-type="bibr" rid="bib34">Dehaene et al., 2015</xref>; <xref ref-type="bibr" rid="bib115">Planton et al., 2021</xref>). Consistently with the predictions of this formal LoT, behavioral performance and brain responses were modulated by the MDL of the sequence, which we term LoT complexity. We discuss those points in turn.</p><p>Behavioral results during fMRI fully replicated our previously behavioral work (<xref ref-type="bibr" rid="bib115">Planton et al., 2021</xref>). First, performance in detecting occasional deviants, thus indexing sequence memory, was strongly modulated by MDL in our formal language (LoT complexity; <xref ref-type="fig" rid="fig2">Figure 2A</xref>, top). Second, even when a deviant was correctly detected, response time was strongly correlated with LoT complexity (<xref ref-type="fig" rid="fig2">Figure 2A</xref>, bottom). Both findings indicate that novelty detection mechanisms were impacted by sequence structure. Finally, after the experiment, when participants were asked to segment the sequences with brackets, their segmentations closely matched the LoT sequence descriptions. For instance, they segmented the <italic>Pairs+Alt</italic>.<italic>1</italic> sequence as [[AA][BB]][[ABAB]]. The sole exception was the alternate sequence (ABAB…) which was encoded by our theory as 15 alternations, but was bracketed by participants as 8 repetitions of the subsequence AB. This interesting departure from our theory may indicate that, during sequence parsing, participants do not necessarily identify the most compact representation, but wait until a repeated subsequence occurs, and then encode how often it repeats (including nested repetitions). This parsing strategy would yield a minor departure from our proposed encodings. Undoubtedly, there is still room for improvement in our LoT theory, which is highly idealized and does not incorporate real-time parsing constraints. However, an alternative interpretation of the bracketing results is that the visual bracketing task itself may bias the perception of auditory sequences. By making the entire sequence visible at once, including its start and end point, the visual format may have incited subjects to subdivide it into groups of two, while the auditory sequential presentation alone would have encouraged the ‘15 alternations’ encoding. In support of the latter interpretation, we did not find any evidence for grouping by two in the timing of button presses when subjects reproduced the alternate sequence from memory (Al Roumi and Tabbane, unpublished data). More research, with a greater diversity of sequences and tasks, will be needed to understand whether and where the present theory needs to be amended.</p><p>Altogether, these behavioral results confirm that the postulated LoT provides a plausible description of how binary sequences are encoded. They fit with a long line of cognitive psychological research searching for computer-like languages that capture the human concept of sequence regularity (<xref ref-type="bibr" rid="bib86">Leeuwenberg, 1969</xref>; <xref ref-type="bibr" rid="bib120">Restle, 1970</xref>; <xref ref-type="bibr" rid="bib121">Restle and Brown, 1970</xref>; <xref ref-type="bibr" rid="bib130">Simon, 1972</xref>; <xref ref-type="bibr" rid="bib129">Simon and Kotovsky, 1963</xref>). Here, as in <xref ref-type="bibr" rid="bib114">Planton and Dehaene, 2021</xref>, a formal statistical comparison demonstrated the superiority of LoT complexity against many competing measures such as transition probability, chunk complexity, entropy, subsymmetries, Lempel-Ziv compression, change complexity, or algorithmic complexity. In the next sections, we discuss how brain imaging results provide additional information on how sequence compression is implemented in the human brain.</p><p>According to our hypothesis, the more complex the sequence, the longer the internal model and the larger the effort to parse it, encode it and maintain it in working memory. Consequently, we expected during the habituation phase larger brain activations for more complex sequences in regions that are involved in auditory sequence encoding. Both fMRI and MEG results supported this hypothesis. Importantly, contrary to the fMRI experiment, the MEG experiment did not require overt responses, yet several neural markers, such as global field power, showed a significant increase with sequence complexity (<xref ref-type="fig" rid="fig6">Figure 6A</xref>). Furthermore, linear regressions showed that brain activity increased with sequence complexity for sensors that corresponded to the auditory and inferior frontal regions (<xref ref-type="fig" rid="fig6">Figure 6B</xref>).</p><p>Many levels of sequence-processing mechanisms coexist in the human brain (<xref ref-type="bibr" rid="bib34">Dehaene et al., 2015</xref>) and statistical learning is a well-known contributor to brain activity. Thanks to the high temporal resolution of MEG, we could separate the effects of transition probabilities from those of sequence structure (<xref ref-type="bibr" rid="bib17">Bekinschtein et al., 2009</xref>; <xref ref-type="bibr" rid="bib92">Maheu et al., 2019</xref>; <xref ref-type="bibr" rid="bib144">Wacongne et al., 2011</xref>). To separate them, we ran a multilinear regression model with regressors for both. Even after adding four additional regressions for immediate and longer-term transition statistics, a cluster-based permutation test provided similar spatiotemporal clusters for the regressor for LoT complexity (<xref ref-type="fig" rid="fig6s2">Figure 6—figure supplement 2</xref> and <xref ref-type="fig" rid="fig6s3">Figure 6—figure supplement 3</xref>). As shown in <xref ref-type="fig" rid="fig6s4">Figure 6—figure supplement 4</xref>, for habituation and standard trials, repetition/alternation impacted on both an early peak at 80 ms and a later one at 170 ms after stim onset, perhaps reflecting sensory bottom-up versus top-down processes. Transition-based surprise exhibited only one peak at ~110 ms after stim onset. The 20 ms delay between the peaks supports the possibility that the first reflects low-level neural adaptation while the second corresponds to a violation of expectations based on transition probabilities. Complexity effects, however, showed a later and more sustained response, extending much beyond 200 ms for deviant trials, in agreement with a distinct rule-based process.</p><p>Previous fMRI results led us to expect several prefrontal regions to exhibit an increasing activity with sequence complexity (<xref ref-type="bibr" rid="bib11">Badre, 2008</xref>; <xref ref-type="bibr" rid="bib12">Badre et al., 2010</xref>; <xref ref-type="bibr" rid="bib14">Barascud et al., 2016</xref>; <xref ref-type="bibr" rid="bib80">Koechlin et al., 2003</xref>; <xref ref-type="bibr" rid="bib81">Koechlin and Jubault, 2006</xref>; <xref ref-type="bibr" rid="bib147">Wang et al., 2019</xref>), but no such activation was observed in MEG source reconstruction. This negative result has several potential explanations. First of all, sequence complexity may act as a context effect and therefore may be sustained across time (<xref ref-type="bibr" rid="bib14">Barascud et al., 2016</xref>; <xref ref-type="bibr" rid="bib131">Southwell and Chait, 2018</xref>). As we baselined the data on a short time window before each sound onset, such a constant effect may be removed. Furthermore, frontal brain regions may be too distributed, intermixed, and/or too far from the MEG helmet to be faithfully reconstructed. Finally, the fMRI experiment allowed us to clearly identify a large network of brain areas involved in complexity, but recruiting a rather posterior region of prefrontal cortex, the preCG (or dorsal premotor cortex, PMd, bordering on the dorsal part of Brodmann area 44) together with the STG, SMA, cerebellum, and IPS that all exhibited the predicted increase in activity with LoT complexity. All these regions showed the predicted increasing response with complexity during habituation, and decreasing response with complexity to deviants.</p><p>All these areas have been shown to be associated with temporal sequence processing, although mostly with oddball paradigms using much shorter or simpler sequences (<xref ref-type="bibr" rid="bib17">Bekinschtein et al., 2009</xref>; <xref ref-type="bibr" rid="bib66">Huettel et al., 2002</xref>; <xref ref-type="bibr" rid="bib114">Planton and Dehaene, 2021</xref>; <xref ref-type="bibr" rid="bib146">Wang et al., 2015</xref>; <xref ref-type="bibr" rid="bib147">Wang et al., 2019</xref>). They can be decomposed into modality-specific and modality-independent regions (<xref ref-type="bibr" rid="bib53">Frost et al., 2015</xref>). STG activation was observed for auditory sequences here and in other studies (<xref ref-type="bibr" rid="bib17">Bekinschtein et al., 2009</xref>; <xref ref-type="bibr" rid="bib146">Wang et al., 2015</xref>) but not for visuo-spatial sequences (<xref ref-type="bibr" rid="bib147">Wang et al., 2019</xref>). The modality specificity of STG was explicitly confirmed by <xref ref-type="bibr" rid="bib114">Planton and Dehaene, 2021</xref>, using visual and auditory sequences with identical structures. Other regions, meanwhile, were modality-independent and coincided with those found in a similar paradigm with visuo-spatial sequences (<xref ref-type="bibr" rid="bib147">Wang et al., 2019</xref>), consistent with a role in abstract rule formation. The IPS and preCG, in particular, are jointly activated in various conditions of mental calculation and mathematics (<xref ref-type="bibr" rid="bib6">Amalric et al., 2017b</xref>; <xref ref-type="bibr" rid="bib33">Dehaene et al., 2003</xref>), with anterior IPS housing a modality-invariant representation of number (<xref ref-type="bibr" rid="bib33">Dehaene et al., 2003</xref>; <xref ref-type="bibr" rid="bib37">Eger et al., 2009</xref>; <xref ref-type="bibr" rid="bib61">Harvey et al., 2013</xref>; <xref ref-type="bibr" rid="bib72">Kanayet et al., 2018</xref>). The overlap between auditory sequences and arithmetic was confirmed here using sensitive single-subject analyses (<xref ref-type="fig" rid="fig5">Figure 5</xref>). PreCG and IPS may thus be jointly involved in the nested ‘for i=1:n’ loops, i.e. the repetitions of the proposed language, and in the real-time tracking of item and chunk number needed to follow a given auditory sequence even after it was learned. Such a role is consistent with the more general proposal of a role for these dorsal regions, particularly the IPS, in structure learning (<xref ref-type="bibr" rid="bib133">Summerfield et al., 2020</xref>). While these regions coactivated with STG during the present auditory task, in a previous visuo-spatial version of the same task they did so together with bilateral occipito-parietal areas (<xref ref-type="bibr" rid="bib147">Wang et al., 2019</xref>). This is consistent with the behavioral observation that the very same language, involving concatenation, loops, and recursion, when applied to visual or auditory primitives, can account for sequence memory in both modalities (<xref ref-type="bibr" rid="bib35">Dehaene et al., 2022</xref>; <xref ref-type="bibr" rid="bib115">Planton et al., 2021</xref>).</p><p>Our data also point to the SMA, or rather pre-SMA (<xref ref-type="bibr" rid="bib106">Nachev et al., 2008</xref>), in processing increasingly complex sequences. Such a domain-general sequence-processing function was indeed advocated by <xref ref-type="bibr" rid="bib27">Cona and Semenza, 2017</xref>, given its various involvements in action sequences, music processing, numerical cognition, spatial processing, time processing, as well as language. Remarkably, the cerebellum also participated in our complexity network. Its role in working memory has been rarely reported or discussed and might have been underestimated in the parsing of non-motor sequences, as it is classically associated with motor sequence learning (<xref ref-type="bibr" rid="bib70">Jenkins et al., 1994</xref>; <xref ref-type="bibr" rid="bib137">Toni et al., 1998</xref>). The present results confirm that the cerebellum may be involved in abstract, non-motor sequence encoding and expectation (<xref ref-type="bibr" rid="bib87">Leggio et al., 2008</xref>; <xref ref-type="bibr" rid="bib101">Molinari et al., 2008</xref>; <xref ref-type="bibr" rid="bib107">Nixon, 2003</xref>). Indeed, cerebellum, SMA, and premotor cortex were already reported as involved in the passive listening of rhythms (<xref ref-type="bibr" rid="bib25">Chen et al., 2008</xref>), consistent with a role in the identification of sequence regularities. A tentative hypothesis is that (pre)SMA, cerebellum, and possibly premotor cortex may participate in a beat- (<xref ref-type="bibr" rid="bib102">Morillon and Baillet, 2017</xref>) or time-processing network (<xref ref-type="bibr" rid="bib28">Coull et al., 2011</xref>), thus possibly involved in the translation from the abstract structures of the proposed language to concrete, precisely timed sensory predictions.</p><p>Interestingly, we found that, while task performance was primarily linearly related to LoT complexity, fMRI activity was not. Rather, as the sequence becomes too complex, activation tended to stop increasing, or even decreased, just yielding a significant downward quadratic trend. <xref ref-type="bibr" rid="bib147">Wang et al., 2019</xref>, observed a similar effect with visuo-spatial sequences. In both cases, the highest complexity sequences were largely incompressible because they did not have any significant regularity in our language and, given their length, could not be easily memorized. The collapse of activity at a certain level of LoT complexity, in regions that are precisely involved in working memory, is therefore logical. Indeed, in a more classical object memory task, <xref ref-type="bibr" rid="bib142">Vogel and Machizawa, 2004</xref>, found that working memory activity does not solely increase with the number of elements stored in working memory, but saturates or decreases once the stimuli exceed storage capacity, thought to be around three or four items (<xref ref-type="bibr" rid="bib29">Cowan, 2001</xref>; for discussion, see <xref ref-type="bibr" rid="bib90">Ma et al., 2014</xref>). Naturally, such a collapse can only lead to reduced predictions and therefore reduced violation detection – thus explaining that behavioral responses to deviants continue to increase linearly with complexity, while model-related fMRI activations vary as an inverted U function of complexity. An analogous phenomenon was described in infants (<xref ref-type="bibr" rid="bib75">Kidd et al., 2012</xref>; <xref ref-type="bibr" rid="bib76">Kidd et al., 2014</xref>): they allocate their attention to visually or auditory presented sequences that are neither too simple nor too complex, thus showing a U-shaped pattern that implies boredom for stimuli with low information content and saturation from stimuli that exceed their cognitive resources.</p><p>Detailed examination of the responses to violations in MEG confirmed that human participants were able to encode details of the hierarchical structures of sequences. Not only did the amplitude of violation responses tightly track the proposed LoT complexity (<xref ref-type="fig" rid="fig7">Figure 7</xref>), but the specific violation responses proved that the human brain changed its expectations in a hierarchical manner (<xref ref-type="fig" rid="fig8">Figure 8</xref>). This was clearest in the case of the <italic>Pairs+Alt1</italic> sequence, which consists in two pairs (AABB) followed by four alternations (ABAB). In those two consecutive parts, the predictions are exactly opposite at central locations (A<bold>AB</bold>B versus A<bold>BA</bold>B), such that what is a violation for one is a correct prediction for the other, and vice versa. The fact that we observe significant violation responses at each of these locations (i.e. locations 10, 12, 14, and 15 in the <italic>Pairs+Alt1</italic> sequence), as well as for the matched <italic>Alternate</italic> and <italic>Pairs</italic> sequences, indicates that the human brain is able to quickly change its anticipations as a function of sequence hierarchical structure. To do so, it must contain a representation of sequences as nested parts within parts, and switch between those parts after a fixed number of items (4 in this case). Violation detection in the <italic>Pairs</italic> and <italic>Quadruplets</italic> sequences further confirmed that subjects kept track of the exact number of items in each subsequence, since their brain reacted to violations that either shortened or lengthened a chunk of identical consecutive items.</p><p>While present and past results indicate that a language is necessary to account for the human encoding of binary auditory sequences (<xref ref-type="bibr" rid="bib35">Dehaene et al., 2022</xref>; <xref ref-type="bibr" rid="bib115">Planton et al., 2021</xref>), this language differs from those used for communication: it involves repetitions, numbers, and symmetries, while the syntax of natural language systematically avoids these features (<xref ref-type="bibr" rid="bib103">Moro, 1997</xref>; <xref ref-type="bibr" rid="bib104">Musso et al., 2003</xref>). In agreement with this observation, there was little overlap between our auditory sequence complexity network and the classical left-hemisphere language network. Instead, complexity effects were systematically distributed symmetrically in both hemispheres, unlike natural language processing. Within individually defined language functional ROIs (fROIs) (defined by their activity during visual or auditory sentence processing relative to a low-level control), no significant complexity effect was found except in a single region, the left IFGoper (a negative effect of complexity for deviants was also found there and in pSTS). Even that finding may well be a partial volume effect, as this area was absent from whole-brain contrasts, and the centroid of the complexity-related activation was centered at a more dorsal location in preCG (<xref ref-type="fig" rid="fig3">Figure 3</xref>). Broca’s area is the main candidate region for language-like processing of hierarchical structures, and such role is advocated for in various previous rule-learning studies using artificial grammars (<xref ref-type="bibr" rid="bib13">Bahlmann et al., 2008</xref>; <xref ref-type="bibr" rid="bib46">Fitch and Friederici, 2012</xref>; <xref ref-type="bibr" rid="bib51">Friederici et al., 2006</xref>), structured sequences of actions (<xref ref-type="bibr" rid="bib10">Badre and D’Esposito, 2007</xref>; <xref ref-type="bibr" rid="bib81">Koechlin and Jubault, 2006</xref>), sequence processing (<xref ref-type="bibr" rid="bib146">Wang et al., 2015</xref>), and even music (<xref ref-type="bibr" rid="bib91">Maess et al., 2001</xref>; <xref ref-type="bibr" rid="bib110">Patel, 2003</xref>). However, Broca’s area is a heterogeneous region (<xref ref-type="bibr" rid="bib7">Amunts et al., 2010</xref>), of which certain sub-regions support language while others underlie a variety of other cognitive functions, including mathematics and working memory (<xref ref-type="bibr" rid="bib40">Fedorenko et al., 2012</xref>). Interpretation must remain careful since functions that were once thought to overlap in Broca’s area, such as language and musical syntax (<xref ref-type="bibr" rid="bib39">Fadiga et al., 2009</xref>; <xref ref-type="bibr" rid="bib82">Koelsch et al., 2002</xref>; <xref ref-type="bibr" rid="bib83">Kunert et al., 2015</xref>), are now clearly dissociated by higher-resolution single-subject analyses (<xref ref-type="bibr" rid="bib26">Chen et al., 2021</xref>).</p><p>Conversely, a very different picture was observed when examining the overlap of LoT complexity fMRI activity and the mathematical calculation network. There was considerable overlap at the whole-brain level (SMA, IPS, premotor cortex, cerebellum) and, most importantly, a significant sequence complexity effect within each of the individual mathematical fROIs. A similar result was reported by <xref ref-type="bibr" rid="bib147">Wang et al., 2019</xref>; they found activation of mathematics-related regions but not language-related ones when participants were processing visuo-spatial sequences. <xref ref-type="bibr" rid="bib114">Planton and Dehaene, 2021</xref>, reached a similar conclusion by showing novelty effects to pattern violations of both visual and auditory short sequences in mathematics but not in language areas. Since their data, as well as the present data, was obtained with binary sequences which, contrary to <xref ref-type="bibr" rid="bib147">Wang et al., 2019</xref>, were devoid of any geometrical content, those results indicate that the amodal language of thought for sequences shares common neural mechanisms with mathematical thinking, even when no overt geometrical content is present.</p><p>The present results therefore support the hypothesis that the human brain hosts multiple internal languages, depending on the types of structures and contents that are being processed (<xref ref-type="bibr" rid="bib35">Dehaene et al., 2022</xref>; <xref ref-type="bibr" rid="bib41">Fedorenko and Varley, 2016</xref>; <xref ref-type="bibr" rid="bib60">Hagoort, 2013</xref>). While the capacity to encode nested sequences may well be a fundamental overarching function of the human brain, fundamental to the manipulation of hierarchical structures in language, mathematics, music, complex actions, etc. (<xref ref-type="bibr" rid="bib34">Dehaene et al., 2015</xref>; <xref ref-type="bibr" rid="bib47">Fitch, 2014</xref>; <xref ref-type="bibr" rid="bib63">Hauser et al., 2002</xref>; <xref ref-type="bibr" rid="bib85">Lashley, 1951</xref>), those abilities may rely on partially dissociable networks. This conclusion fits with much prior evidence that, at the individual level, language and mathematics do not share the same cerebral substrates and may be dissociated by brain injuries (<xref ref-type="bibr" rid="bib4">Amalric and Dehaene, 2016</xref>; <xref ref-type="bibr" rid="bib41">Fedorenko and Varley, 2016</xref>), just like language and music (<xref ref-type="bibr" rid="bib25">Chen et al., 2008</xref>; <xref ref-type="bibr" rid="bib108">Norman-Haignere et al., 2015</xref>; <xref ref-type="bibr" rid="bib112">Peretz et al., 2015</xref>). During hominization, we speculate that an enhanced functionality for recursive nesting may have jointly emerged in all of those neuronal circuits (<xref ref-type="bibr" rid="bib35">Dehaene et al., 2022</xref>). In the future, this hypothesis could be tested by submitting non-human primates to the present hierarchy of sequences, and examine up to which level their brains can react to violations. We already know that the macaque monkey brain can detect violations of simple habitual, sequential, or numerical patterns (<xref ref-type="bibr" rid="bib139">Uhrig et al., 2014</xref>; <xref ref-type="bibr" rid="bib148">Wilson et al., 2013</xref>), with both convergence (<xref ref-type="bibr" rid="bib149">Wilson et al., 2017</xref>) and divergence (<xref ref-type="bibr" rid="bib146">Wang et al., 2015</xref>) relative to human results. The present design may help determine precisely where to draw the line.</p></sec><sec id="s4" sec-type="materials|methods"><title>Materials and methods</title><sec id="s4-1"><title>Participants</title><p>Nineteen participants (10 men, M<sub>age</sub> = 27.6 years, SD<sub>age</sub> = 4.7 years) took part in the MEG experiment and 23 (11 men, M<sub>age</sub> = 26.1 years, SD<sub>age</sub> = 4.7 years) in the fMRI experiment. The two groups of participants were distinct. We did not test any effect of gender on the results of this study. All participants had normal or corrected to normal vision and no history or indications of psychological or neurological disorders. In compliance with institutional guidelines, all subjects gave written informed consent prior to enrollment and received 90€ as compensation. The experiments were approved by the national ethical committees (CPP Ile-de-France III and CPP Sud-Est VI).</p></sec><sec id="s4-2"><title>Stimuli and tasks</title><p>Auditory binary sequences of 16 sounds were used in both experiments. They were composed of low-pitch and high-pitch sounds, constructed as the superimposition of sinusoidal signals of respectively <italic>f</italic>=350 Hz, 700 Hz, and 1400 Hz, and <italic>f</italic>=500 Hz, 1000 Hz, and 2000 Hz. Each tone lasted 50 ms and the 16 tones were presented in sequence with a fixed SOA of 250 ms.</p><p>Ten 16-item sequential patterns spanning a large range of complexities were selected (see <xref ref-type="fig" rid="fig1">Figure 1A</xref>). Six of them were used in previous behavioral experiments (<xref ref-type="bibr" rid="bib115">Planton et al., 2021</xref>). The complexity metric used to predict behavior and brain activity was the ‘LoT – <italic>chunk</italic>’ complexity, which was previously shown to be well correlated with behavior (<xref ref-type="bibr" rid="bib115">Planton et al., 2021</xref>). This metric roughly measures the length of the shortest description of the pattern in a formal language that uses a small set of atomic rules (e.g. repetition, alternation) that can be recursively embedded. The <italic>chunk</italic> version of the metric includes only expressions that preserve chunks of consecutive repeated items (for instance, the sequence ABBA is parsed as [A][BB][A] rather than [AB][BA]). 10 sequences were used in the fMRI experiment, and 7 of them in the MEG experiment (i.e. all but <italic>Pairs&amp;Alt.2</italic>, <italic>ThreeTwo,</italic> and <italic>CenterMirror</italic>).</p><p>Each auditory sequence (4000 ms long) was repeatedly presented to a participant in a mini-session with 500 ms ITI. Mini-sessions had the following structure. Participants first discovered and encoded the sequence during a habituation phase of 10 trials. Then, during a test phase, occasional violations consisting in the replacement of a high-pitch sound by a low-pitch one (or vice versa) were presented at the locations specified in <xref ref-type="fig" rid="fig1">Figure 1A</xref>. As described in <xref ref-type="fig" rid="fig1">Figure 1B</xref>, in the MEG experiment, the test phase included 36 trials of which 2/3 comprised a deviant sound. In the fMRI experiment, the test phase included 18 trials of which 1/3 comprised a deviant sound. Participants were unaware of the mini-session structure.</p><p>In the MEG experiment, habituation and test sequences followed each other seamlessly, and participants were merely asked to listen attentively. After each mini-session, they were asked one general question about what they had just heard such as: <italic>How many different sounds could you hear? Did you find it musical? How complex was the sequence of sounds?</italic> The full experiment was divided temporally into two parts such that the seven sequence types appeared twice, once in each version (starting with A or B), once at the beginning and once at the end of the experiment. The overall experiment lasted about 80 min.</p><p>In the fMRI experiment, participants were explicitly instructed to detect and respond to violations, by pressing a button, as quickly as possible, with either their right or left hand. The correct response button (left or right, counterbalanced over the two repetitions of each sequence) was indicated by a 2 s visual message on the screen during the rest period preceding the first test trial. In order to optimize the estimation of the BOLD response, trials were presented in two blocks of five trials for the habituation phase, then three blocks of six trials for the test phase, separated by rest periods of variable duration (6 s±1.5). The 10 sequences appeared twice, once in each version (starting with A or B). The 20 mini-sessions were presented across five fMRI sessions of approximately 11 min.</p></sec><sec id="s4-3"><title>Post-experimental sequence bracketing task</title><p>After the experiment, participants were given a questionnaire to assess their own representation of the structure of the sequence. For each sequence of the experiment (i.e. 7 for the MEG participants, 10 for the fMRI participants), after listening to it several times if needed, participants were asked to segment the sequence by drawing brackets (opening and closing) on its visual representation (As and Bs were respectively represented by empty and filled circles on a sheet of paper). In this way, they were instructed to indicate how they tended to group consecutive items together in their mind when listening to the sequence, if they did.</p></sec><sec id="s4-4"><title>fMRI experiment procedures</title><sec id="s4-4-1"><title>Localizer session</title><p>Together with the main sequence-processing task described above, the fMRI experimental protocol also included a 6 min localizer session designed to localize cerebral regions involved in language processing and in mathematics. This localizer was already used in our previous work (<xref ref-type="bibr" rid="bib114">Planton and Dehaene, 2021</xref>) and is a variant of a previously published functional localizer which is fully described elsewhere (<xref ref-type="bibr" rid="bib113">Pinel et al., 2007</xref>). A sentence-processing network was identified in each subject by contrasting sentence reading/listening conditions (i.e. visually and auditorily presented sentences) from control conditions (i.e. meaningless auditory stimuli consisting in rotated sentences, and meaningless visual stimuli of the same size and visual complexity as visual words). A mathematics network was identified in each subject by contrasting mental calculation conditions (i.e. mental processing of simple subtraction problems, such as 7–2, presented visually, and auditorily) from sentence reading/listening conditions.</p></sec><sec id="s4-4-2"><title>fMRI acquisition and preprocessing</title><p>MRI acquisition was performed on a 3T scanner (Siemens, Tim Trio), equipped with a 64-channel head coil. 354 functional scans covering the whole brain were acquired for each of the five sessions of the main experiment, as well as 175 functional scans for the localizer session, all using a T2*-weighted gradient echo-planar imaging sequence (69 interleaved slices, TR = 1.81 s, TE = 30.4 ms, voxel size = 1.75 mm<sup>3</sup>, multiband factor = 3). To estimate distortions, two volumes with opposite phase encoding direction were acquired: one volume in the anterior-to-posterior direction (AP) and one volume in the other direction (PA). A 3D T1-weighted structural image was also acquired (TR = 2.30 s, TE = 2.98 ms, voxel size = 1.0 mm<sup>3</sup>).</p><p>Data processing (except the TOPUP correction) was performed with SPM12 (Wellcome Department of Cognitive Neurology, <ext-link ext-link-type="uri" xlink:href="http://www.fil.ion.ucl.ac.uk/spm">http://www.fil.ion.ucl.ac.uk/spm</ext-link>). The anatomical scan was spatially normalized to a standard Montreal Neurological Institute (MNI) reference anatomical template brain using the default parameters. Functional images were unwarped (using the AP/PA volumes, processed with the TOPUP software; FSL, fMRIB), corrected for slice timing differences (first slice as reference), realigned (registered to the mean using second-degree B-splines), coregistered to the anatomy (using normalized mutual information), spatially normalized to the MNI brain space (using the parameters obtained from the normalization of the anatomy), and smoothed with an isotropic Gaussian filter of 5 mm FWHM.</p><p>In addition to the 6 motion regressors from the realignment step, 12 regressors were computed using the aCompCor method (<xref ref-type="bibr" rid="bib16">Behzadi et al., 2007</xref>), applied to the CSF and to white matter (first five components of two principal component analyses, and one for the raw signal), in order to better correct for motion-related and physiological noise in the statistical models (using the PhysIO Toolbox; <xref ref-type="bibr" rid="bib74">Kasper et al., 2017</xref>). Additional regressors for motion outliers were also computed (framewise displacement larger than 0.5 mm; see <xref ref-type="bibr" rid="bib116">Power et al., 2012</xref>), they represented 0.5% of volumes per subject on average. One participant was excluded from the fMRI analyses due to excessive movement in the scanner (average translational displacement of 2.9 mm within each fMRI session, which was 3.3 SD above group average).</p></sec><sec id="s4-4-3"><title>fMRI analysis</title><sec id="s4-4-3-1"><title>General linear model</title><p>Statistical analyses were performed using SPM12 and GLM that included the motion-related and physiological noise-related regressors (described above) as covariates of no interest. fMRI images were high-pass filtered at 0.01 Hz. Time series from the sequences of stimuli of each condition (each tone modeled as an event) were convolved with the canonical hemodynamic response function. Specifically, for each of the 20 mini-sessions (i.e. each sequence being tested twice, reverting the attribution of the two tones), one regressor for the items of the habituation phase, one for the items of the test phase, and one for the deviant items were included in the GLM. Since motor responses and deviant trials were highly collinear, manual motor responses were not modeled. However, motor responses could be less frequent for more complex sequences (i.e. increased miss rate), thus creating a potential confound with the effect of complexity in deviant trials. We thus also computed an alternative model in which only correctly detected deviants trials were included. In order to test for a relationship between brain activation and LoT complexity in different trial types (i.e. habituation trials, deviant trials), corresponding beta maps for each of the 10 sequences and each participant were entered in second-level within-subject ANOVA. Linear parametric contrasts using the LoT complexity value were then computed.</p></sec><sec id="s4-4-3-2"><title>Cross-validated ROI plots and analyses</title><p>To further test the reliability of the complexity effect across participants, a cross-validated ROI analysis, using individually defined fROIs, was conducted. Nine of the most salient peaks from the positive LoT complexity contrast in habituation were first selected, and used to build nine 20-mm-diameter spherical search volumes: SMA (coordinates: –1, 5, 65), right precentral gyrus (R-preCG; 46, 2, 44), left precentral gyrus (L-preCG; –47, 0, 45), right intraparietal sulcus (R-IPS; 36, –46, 56), left intraparietal sulcus (L-IPS; −31, –42, 44), right superior temporal gyrus (R-STG; 48, –32, 3), left superior temporal gyrus (L-STG; −68, –23, 5), lobule VI of the left cerebellar hemisphere (L-CER6; −29, –56, –28) and lobule VI of the right cerebellar hemisphere (R-CER8; 22, –68, –51). Since these search volumes were defined on group-level results, to reduce the degree of circularity when extracting the individual ROI data, these were extracted in a cross-validated manner, by separating each participant data into two halves. Individual fROIs were then defined for each participant by selecting the 20% most active voxels at the intersection between each search volume and the contrast ‘LoT complexity effect in habituation’ computed on half of the blocks (i.e. blocks of sequences starting with ‘A’). Mean contrast estimates for each fROI and each condition was then extracted using the other half of the blocks (i.e. blocks of sequences starting with ‘B’). The same procedure was repeated a second time by reversing the role of the two halves (i.e. fROIs computed using blocks of sequences starting with ‘B’, data extracted from blocks of sequences starting with ‘A’). It should be noted that this procedure does not fully eliminate the circularity in the analysis, since the initial search volumes were still based on whole-group data – however, such circularity should be minimal, as the ROIs themselves. To test for the significance of the complexity effect in each ROI, the mean of the output of the two procedures (i.e. the cross-validated activation value), for each of the 10 conditions (i.e. habituation blocks for each of the 10 sequences) and each participant, was entered in a linear mixed-effect model with participant as random factor and LoT complexity value as a fixed-effect predictor. p-Values were corrected for multiple comparison using Bonferroni correction for nine ROIs. Along with such a linear effect of complexity, we also tested a quadratic effect by adding a quadratic term in the mixed-effect model.</p><p>In order to track activation over time, we also extracted, using the same cross-validated procedure, the BOLD activation time course for each 28-trial mini-session. To account for the fact that the duration of rest periods between blocks could vary, data were actually extracted for a [–6 s –32 s] period relative to the onset of the first trial of each block rest period, and the whole mini-session curve was recomposed by averaging over the overlapping period of two consecutive parts (see vertical shadings in <xref ref-type="fig" rid="fig3">Figure 3B</xref>). Each individual time course was upsampled and smoothed using cubic spline interpolation, and baseline corrected with a 6 s period preceding the onset of the first trial.</p><p>Finally, two set of ROIs were selected in order to test for the involvement of language and mathematics-related areas in the present sequence-processing task, and especially to assess a potential sequence complexity effect. Seven language-related ROIs came from the sentence-processing experiment of <xref ref-type="bibr" rid="bib109">Pallier et al., 2011</xref>: pars orbitalis (IFGorb), triangularis (IFGtri), and opercularis (IFGoper) of the inferior frontal gyrus, TP, TPJ, aSTS, and pSTS. Seven mathematics-related ROIs came from the mathematical thinking experiment of <xref ref-type="bibr" rid="bib4">Amalric and Dehaene, 2016</xref>: left and right IPS, left and right SFG, left and right precentral/inferior frontal gyrus (preCG/IFG), SMA. These two sets of ROIs were already used in the past (<xref ref-type="bibr" rid="bib114">Planton and Dehaene, 2021</xref>; <xref ref-type="bibr" rid="bib147">Wang et al., 2019</xref>). In order to build individual and functional ROIs from these literature-based ROIs, we used the same procedure as <xref ref-type="bibr" rid="bib114">Planton and Dehaene, 2021</xref>, consisting in selecting, for each subject, the 20% most active voxels within the intersection between the ROI mask and an fMRI contrast of interest from the independent localizer session. The contrast of interest was ‘Listening &amp; reading sentences &gt; Rotated speech &amp; false font script’ for the ROIs of the language network, and ‘Mental calculation visual &amp; auditory &gt; Sentence listening &amp; reading’ for the ROIs of the mathematics network. Mean contrast estimates for each fROI and each condition was then extracted, and entered into linear mixed-effect model with participant as random factor and LoT complexity value as a fixed effect predictor. A Bonferroni correction for 14 ROIs was applied to the p-values.</p></sec></sec></sec><sec id="s4-5"><title>Behavioral data analysis</title><p>Data for the sequence bracketing task included all productions collected in the fMRI and MEG experiment (42 participants for seven sequences, and 23 participants for the three that were only presented during fMRI). For each production, we counted the total number of brackets (opening and closing) drawn at each interval between two consecutive items (as well as before the first and after the last item, resulting in a vector of length 17) (see <xref ref-type="fig" rid="fig2">Figure 2A</xref>). To determine if participants’ reported sequence structure matched the predictions of the LoT model, we computed the correlation between the average over participants of the number of brackets in each interval and the postulated bracketing of the sequence (derived from its expression in the LoT). For the first two sequences, the representations ‘[A][A][A]…’ and ‘[AAA…]’, as well as ‘[A][B][A]…’, and ‘[ABA…]’, respectively, derived from the expressions [+0]^16 and [+0]^16&lt;b &gt;, were considered as equivalent.</p><p>For the violation detection task of the fMRI experiment, we considered as a correct response (or ‘hit’) all button presses occurring between 200 ms and 2500 ms after the onset of a deviant sound. We thus allowed for potential delayed responses (but found that 97.7% of correct responses were below 1500 ms). An absence of response in this interval was counted as a miss, a button press outside this interval was counted as a false alarm. We then computed, for each subject and each sequence, the average response time as well as, using the proportions of hits and false alarms, the sensitivity (or <italic>d</italic>’). The method of <xref ref-type="bibr" rid="bib64">Hautus, 1995</xref>, was used to adjust extreme values. To test whether subject performance correlated with LoT complexity, we performed linear regressions on group-averaged data, as well as linear mixed models including participant as the (only) random factor. The random effect structure of the mixed models was kept minimal, and did not include any random slopes, to avoid the convergence issues often encountered when attempting to fit more complex models. Analyses were performed in R 4.0.2 (<xref ref-type="bibr" rid="bib119">R Development Core Team, 2020</xref>), using the lme4 (<xref ref-type="bibr" rid="bib15">Bates et al., 2015</xref>) and lmerTest (<xref ref-type="bibr" rid="bib84">Kuznetsova et al., 2017</xref>) packages. Surprise for each deviant item was computed from transition probabilities, within each block for each subject, using an ideal observer Bayesian model (<xref ref-type="bibr" rid="bib92">Maheu et al., 2019</xref>; <xref ref-type="bibr" rid="bib99">Meyniel et al., 2016</xref>) and tested as an additional predictor in the mixed-effect models. For the analysis of <italic>d</italic>’, we used the average surprise of the deviant items of the block (i.e. all deviants presented to the subject, whether or not they detected them). For the analysis of response times, we used the average transition-based surprise of the correctly detected deviant items of the block.</p></sec><sec id="s4-6"><title>MEG experiment procedures</title><sec id="s4-6-1"><title>MEG recordings</title><p>Participants listened to the sequences while sitting inside an electromagnetically shielded room. The magnetic component of their brain activity was recorded with a 306-channel, whole-head MEG by Elekta Neuromag (Helsinki, Finland). 102 triplets, each comprising one magnetometer and two orthogonal planar gradiometers composed the MEG helmet. The brain signals were acquired at a sampling rate of 1000 Hz with a hardware high-pass filter at 0.1 Hz. The data was then resampled at 250 Hz.</p><p>Eye movements and heartbeats were monitored with vertical and horizontal electro-oculograms (EOGs) and electrocardiograms (ECGs). Head shape was digitized using various points on the scalp as well as the nasion, left and right pre-auricular points (FASTTRACK, Polhemus). Subjects’ head position inside the helmet was measured at the beginning of each run with an isotrack Polhemus Inc system from the location of four coils placed over frontal and mastoïdian skull areas. Sounds were presented using Eatymotic audio system (an HiFi-quality artifact-free headphone system with wide-frequency response) while participants had to fixate a central cross. The analysis was performed with MNE Python (<xref ref-type="bibr" rid="bib58">Gramfort et al., 2013</xref>; <xref ref-type="bibr" rid="bib69">Jas et al., 2018</xref>), version 0.23.0.</p><sec id="s4-6-1-1"><title>Data cleaning: maxfiltering</title><p>We applied the signal space separation algorithm <italic>mne.preprocessing.maxwell_filter</italic> (<xref ref-type="bibr" rid="bib134">Taulu et al., 2004</xref>) to suppress magnetic signals from outside the sensor helmet and interpolate bad channels that we identified visually in the raw signal and in the power spectrum. This algorithm also compensated for head movements between experimental blocks by realigning all data to an average head position.</p></sec><sec id="s4-6-1-2"><title>Data cleaning: independent component analysis</title><p>Oculomotor and cardiac artifacts were removed performing an independent component analysis on the four last runs of the experiment. The components that correlated the most with the EOG and ECG signals were automatically detected. We then visually inspected their topography and correlation to the ECG and EOG time series to confirm their rejection from the MEG data. A maximum of one component for the cardiac artifact and two components for the ocular artifacts were considered. Finally, we removed them from the whole recording (14 runs).</p></sec><sec id="s4-6-1-3"><title>Data cleaning: autoreject</title><p>We used an automated algorithm for rejection and repair of bad trials (<xref ref-type="bibr" rid="bib68">Jas et al., 2017</xref>) that computes the optimal peak-to-peak threshold per channel type in a cross-validated manner. It was applied to baselined epochs and removed on average 4.6% of the epochs.</p></sec><sec id="s4-6-1-4"><title>Epoching parameters and projection on magnetometers</title><p>Epochs on items were baselined from –50 to 0 ms (stimulus onset) and epochs on the full sequences were baselined between –200 and 0 ms (first sequence item onset). For sensor level analyses, instead of working with the 306 sensors (102 magnetometers and 206 gradiometers), we projected the spherical sources of signal onto the magnetometers using MNE epochs method <italic>epochs.as_type(‘mag’,mode=’accurate’</italic>).</p></sec></sec></sec><sec id="s4-7"><title>Univariate analyses</title><sec id="s4-7-1"><title>GFP and linear regressions</title><p>Global field power was computed as the root-mean-square of evoked responses or the difference of evoked responses. Linear regressions were computed using fourfold cross-validation and with the <italic>linear_model.LinearRegression</italic> function of scikit-learn package version 0.24.1. Pearson correlation was computed with the <italic>stats.pearsonr</italic> function from <italic>scipy</italic> package. The predictors for surprise from transition probabilities were computed using an ideal observer Bayesian model learning first-order transitions with an exponential memory decay over 100 items. This was done thanks to the TransitionProbModel python package, which is the python version of the <italic>Matlab version</italic> used in <xref ref-type="bibr" rid="bib92">Maheu et al., 2019</xref>; <xref ref-type="bibr" rid="bib99">Meyniel et al., 2016</xref>.</p></sec><sec id="s4-7-2"><title>Source reconstruction</title><p>A T1-weighted anatomical MRI image with 1 mm isometric resolution was acquired for each participant (3T Prisma Siemens scanner). The anatomical MRI was segmented with FreeSurfer (<xref ref-type="bibr" rid="bib31">Dale et al., 1999</xref>; <xref ref-type="bibr" rid="bib44">Fischl et al., 2002</xref>) and co-registered with MEG data in MNE using the digitized markers. A three-layer boundary element model (inner skull, outer skull, and outer skin) was used to estimate the current-source density distribution over the cortical surface. Source reconstruction was performed on the linear regression coefficients using the dSPM solution with MNE default values (loose orientation of 0.2, depth weighting of 0.8, SNR value of 3) (<xref ref-type="bibr" rid="bib32">Dale et al., 2000</xref>). The noise covariance matrix used for data whitening was estimated from the signal within the 200 ms preceding the onset of the first item of each sound sequence. The resulting sources estimates were transformed to a standard anatomical template (<italic>fsaverage</italic>) with 20,484 vertices using the MNE morphing procedure, and averaged across subjects.</p></sec></sec><sec id="s4-8"><title>Multivariate analyses</title><p>Data was smoothed with a 100 ms sliding window and, instead of working with the 306 sensors (102 magnetometers and 206 gradiometers), we projected the spherical sources of signal onto the magnetometers using MNE epochs method <italic>epochs.as_type(‘mag’,mode=’accurate’</italic>).</p><sec id="s4-8-1"><title>Time-resolved multivariate decoding of brain responses to standard and deviant sounds</title><p>The goal of multivariate of time-resolved decoding analyses was to predict from single-trial brain activity (<italic>X</italic>) a specific categorical variable (<italic>y</italic>), namely if the trial corresponded to the presentation of a deviant sound or not. These analyses were performed using MNE-python function <italic>GeneralizingEstimator</italic> from version 0.23.0 (<xref ref-type="bibr" rid="bib58">Gramfort et al., 2013</xref>) and with Scikit-learn package version 1.1.1 (<xref ref-type="bibr" rid="bib111">Pedregosa et al., 2011</xref>). Prior to model fitting, channels were z-scored across trials for every time point. The estimator was fitted on each participant separately, across all MEG sensors using the parameters set to their default values provided by the Scikit-Learn package (<xref ref-type="bibr" rid="bib111">Pedregosa et al., 2011</xref>).</p></sec><sec id="s4-8-2"><title>Cross-validation</title><p>One run was dedicated to each version of the sequence (7 sequence types × 2 versions [starting with A or starting with B]=14 runs). To build the training set, we randomly picked one run for each sequence, irrespectively of the sequence version. We trained the decoder on all deviant trials of the 7 sequences and on standard trials (non-deviant trials from the test phase) that were matched to sequence-specific deviants in ordinal position. We then tested this decoder on the remaining 7 blocks, determining its performance for the 7 sequences separately. The training and the testing sets were then inverted, resulting in a twofold cross-validation. This procedure avoided any confound with item identity, as the sounds A and B were swapped in the cross-validation folds.</p></sec><sec id="s4-8-3"><title>Generalization across time</title><p>To access the temporal organization of the neural representations, we computed the generalization-across-time matrices (<xref ref-type="bibr" rid="bib78">King and Dehaene, 2014</xref>). These matrices represent the decoding score of an estimator trained at time <italic>t</italic> (training time on the vertical axis) and tested with data from another time <italic>t</italic>’ (testing time on the horizontal axis).</p></sec><sec id="s4-8-4"><title>Statistical analyses</title><p>Temporal, spatiotemporal, and temporal-temporal cluster-based permutation tests were computed on the time windows of interest (0–350 ms for habituation and standard items and 0–600 ms for deviants) using <italic>stats.permutation_cluster_1samp_test</italic> from MNE python package. To obtain the significance results presented in <xref ref-type="fig" rid="fig8">Figure 8</xref>, we ran the temporal permutation test on the difference between the predictions of the deviancy decoder for standard and deviant sounds for a time window from 0 to 600 ms after deviant onset. To compute spatiotemporal clusters, we provided the function with an adjacency matrix from <italic>mne.channels.find_ch_connectivity</italic>.</p></sec></sec></sec></body><back><sec sec-type="additional-information" id="s5"><title>Additional information</title><fn-group content-type="competing-interest"><title>Competing interests</title><fn fn-type="COI-statement" id="conf1"><p>No competing interests declared</p></fn></fn-group><fn-group content-type="author-contribution"><title>Author contributions</title><fn fn-type="con" id="con1"><p>Conceptualization, Data curation, Formal analysis, Investigation, Visualization, Methodology, Writing – original draft, Writing – review and editing</p></fn><fn fn-type="con" id="con2"><p>Conceptualization, Data curation, Formal analysis, Investigation, Visualization, Methodology, Writing – original draft, Writing – review and editing</p></fn><fn fn-type="con" id="con3"><p>Conceptualization, Writing – review and editing</p></fn><fn fn-type="con" id="con4"><p>Conceptualization, Resources, Formal analysis, Supervision, Funding acquisition, Investigation, Methodology, Writing – review and editing</p></fn></fn-group><fn-group content-type="ethics-information"><title>Ethics</title><fn fn-type="other"><p>In compliance with institutional guidelines, all subjects gave written informed consent prior to enrollment. They received 90€ as compensation. The experiments were approved by the national ethical committees (CPP 100049 and 100050).</p></fn></fn-group></sec><sec sec-type="supplementary-material" id="s6"><title>Additional files</title><supplementary-material id="supp1"><label>Supplementary file 1.</label><caption><title>Selected sequences.</title><p>The first column indicates the list of the different 16-item sequences used in the magneto-encephalography (MEG) and fMRI experiments. *Sequences used only in the fMRI experiment. The second column provides the sequence description obtained from the LoT. The third column is its verbal description, meant to ease the understanding of the formal expression.</p></caption><media xlink:href="elife-84376-supp1-v1.docx" mimetype="application" mime-subtype="docx"/></supplementary-material><supplementary-material id="supp2"><label>Supplementary file 2.</label><caption><title>fMRI complexity effect on standard trials (voxel-wise p&lt;0.001, uncorrected; cluster-wise p&lt;0.05, FDR corrected).</title></caption><media xlink:href="elife-84376-supp2-v1.docx" mimetype="application" mime-subtype="docx"/></supplementary-material><supplementary-material id="supp3"><label>Supplementary file 3.</label><caption><title>fMRI complexity effect on deviant trials (voxel-wise p&lt;0.001, uncorrected; cluster-wise p&lt;0.05, FDR corrected).</title></caption><media xlink:href="elife-84376-supp3-v1.docx" mimetype="application" mime-subtype="docx"/></supplementary-material><supplementary-material id="mdar"><label>MDAR checklist</label><media xlink:href="elife-84376-mdarchecklist1-v1.docx" mimetype="application" mime-subtype="docx"/></supplementary-material></sec><sec sec-type="data-availability" id="s7"><title>Data availability</title><p>The raw MEG and fMRI raw data are available via OpenNeuro (<ext-link ext-link-type="uri" xlink:href="https://openneuro.org/datasets/ds004483/versions/1.0.0">https://openneuro.org/datasets/ds004483/versions/1.0.0</ext-link> and <ext-link ext-link-type="uri" xlink:href="https://openneuro.org/datasets/ds004482/versions/1.0.0">https://openneuro.org/datasets/ds004482/versions/1.0.0</ext-link>).</p><p>The following datasets were generated:</p><p><element-citation publication-type="data" specific-use="isSupplementedBy" id="dataset1"><person-group person-group-type="author"><name><surname>Planton</surname><given-names>S</given-names></name><name><surname>Roumi</surname><given-names>FA</given-names></name><name><surname>Wang</surname><given-names>L</given-names></name><name><surname>Dehaene</surname><given-names>S</given-names></name></person-group><year iso-8601-date="2023">2023</year><data-title>ABSeqMEG</data-title><source>OpenNeuro</source><pub-id pub-id-type="doi">10.18112/openneuro.ds004483.v1.0.0</pub-id></element-citation></p><p><element-citation publication-type="data" specific-use="isSupplementedBy" id="dataset2"><person-group person-group-type="author"><name><surname>Planton</surname><given-names>S</given-names></name><name><surname>Roumi</surname><given-names>FA</given-names></name><name><surname>Wang</surname><given-names>L</given-names></name><name><surname>Dehaene</surname><given-names>S</given-names></name></person-group><year iso-8601-date="2023">2023</year><data-title>ABSeqfMRI</data-title><source>OpenNeuro</source><pub-id pub-id-type="doi">10.18112/openneuro.ds004482.v1.0.0</pub-id></element-citation></p></sec><ack id="ack"><title>Acknowledgements</title><p>This work was supported by INSERM (Institut National de la Santé et de la Recherche Médicale), CEA (Commissariat à l'Energie Atomique et aux Energies Alternatives), Collège de France, the Bettencourt-Schueller foundation, and a European Research Council ERC grant ‘NeuroSyntax’ to S.D. We gratefully acknowledge extensive discussions with Ghislaine Dehaene-Lambertz, Christophe Pallier, Maxime, Maheu, Lucas Benjamin, Mathias Sablé-Meyer. We thank all the volunteers for their participation. We are grateful to the UNIACT team for their help in recruiting subjects and in data acquisition.</p></ack><ref-list><title>References</title><ref id="bib1"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Aksentijevic</surname><given-names>A</given-names></name><name><surname>Gibson</surname><given-names>K</given-names></name></person-group><year iso-8601-date="2012">2012</year><article-title>Complexity equals change</article-title><source>Cognitive Systems Research</source><volume>15–16</volume><fpage>1</fpage><lpage>16</lpage><pub-id pub-id-type="doi">10.1016/j.cogsys.2011.01.002</pub-id></element-citation></ref><ref id="bib2"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Alexander</surname><given-names>C</given-names></name><name><surname>Carey</surname><given-names>S</given-names></name></person-group><year iso-8601-date="1968">1968</year><article-title>Subsymmetries</article-title><source>Perception &amp; Psychophysics</source><volume>4</volume><fpage>73</fpage><lpage>77</lpage><pub-id pub-id-type="doi">10.3758/BF03209511</pub-id></element-citation></ref><ref id="bib3"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Al Roumi</surname><given-names>F</given-names></name><name><surname>Marti</surname><given-names>S</given-names></name><name><surname>Wang</surname><given-names>L</given-names></name><name><surname>Amalric</surname><given-names>M</given-names></name><name><surname>Dehaene</surname><given-names>S</given-names></name></person-group><year iso-8601-date="2021">2021</year><article-title>Mental compression of spatial sequences in human working memory using numerical and geometrical primitives</article-title><source>Neuron</source><volume>109</volume><fpage>2627</fpage><lpage>2639</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2021.06.009</pub-id><pub-id pub-id-type="pmid">34228961</pub-id></element-citation></ref><ref id="bib4"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Amalric</surname><given-names>M</given-names></name><name><surname>Dehaene</surname><given-names>S</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Origins of the brain networks for advanced mathematics in expert mathematicians</article-title><source>PNAS</source><volume>113</volume><fpage>4909</fpage><lpage>4917</lpage><pub-id pub-id-type="doi">10.1073/pnas.1603205113</pub-id><pub-id pub-id-type="pmid">27071124</pub-id></element-citation></ref><ref id="bib5"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Amalric</surname><given-names>M</given-names></name><name><surname>Dehaene</surname><given-names>S</given-names></name></person-group><year iso-8601-date="2017">2017a</year><article-title>Cortical circuits for mathematical knowledge: evidence for a major subdivision within the brain’s semantic networks</article-title><source>Philosophical Transactions of the Royal Society of London. Series B, Biological Sciences</source><volume>373</volume><elocation-id>20160515</elocation-id><pub-id pub-id-type="doi">10.1098/rstb.2016.0515</pub-id><pub-id pub-id-type="pmid">29292362</pub-id></element-citation></ref><ref id="bib6"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Amalric</surname><given-names>M</given-names></name><name><surname>Wang</surname><given-names>L</given-names></name><name><surname>Pica</surname><given-names>P</given-names></name><name><surname>Figueira</surname><given-names>S</given-names></name><name><surname>Sigman</surname><given-names>M</given-names></name><name><surname>Dehaene</surname><given-names>S</given-names></name></person-group><year iso-8601-date="2017">2017b</year><article-title>The language of geometry: Fast comprehension of geometrical primitives and rules in human adults and preschoolers</article-title><source>PLOS Computational Biology</source><volume>13</volume><elocation-id>e1005273</elocation-id><pub-id pub-id-type="doi">10.1371/journal.pcbi.1005273</pub-id><pub-id pub-id-type="pmid">28125595</pub-id></element-citation></ref><ref id="bib7"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Amunts</surname><given-names>K</given-names></name><name><surname>Lenzen</surname><given-names>M</given-names></name><name><surname>Friederici</surname><given-names>AD</given-names></name><name><surname>Schleicher</surname><given-names>A</given-names></name><name><surname>Morosan</surname><given-names>P</given-names></name><name><surname>Palomero-Gallagher</surname><given-names>N</given-names></name><name><surname>Zilles</surname><given-names>K</given-names></name></person-group><year iso-8601-date="2010">2010</year><article-title>Broca’s region: novel organizational principles and multiple receptor mapping</article-title><source>PLOS Biology</source><volume>8</volume><elocation-id>e1000489</elocation-id><pub-id pub-id-type="doi">10.1371/journal.pbio.1000489</pub-id><pub-id pub-id-type="pmid">20877713</pub-id></element-citation></ref><ref id="bib8"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Baddeley</surname><given-names>AD</given-names></name><name><surname>Hitch</surname><given-names>G</given-names></name></person-group><year iso-8601-date="1974">1974</year><chapter-title>Working memory</chapter-title><person-group person-group-type="editor"><name><surname>Bower</surname><given-names>D</given-names></name></person-group><source>Recent Advances in Learning and Motivation</source><publisher-loc>New York</publisher-loc><publisher-name>Academic Press</publisher-name><fpage>47</fpage><lpage>89</lpage><pub-id pub-id-type="doi">10.1016/s0079-7421(08)60452-1</pub-id></element-citation></ref><ref id="bib9"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Baddeley</surname><given-names>A</given-names></name></person-group><year iso-8601-date="2003">2003</year><article-title>Working memory: looking back and looking forward</article-title><source>Nature Reviews. Neuroscience</source><volume>4</volume><fpage>829</fpage><lpage>839</lpage><pub-id pub-id-type="doi">10.1038/nrn1201</pub-id><pub-id pub-id-type="pmid">14523382</pub-id></element-citation></ref><ref id="bib10"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Badre</surname><given-names>D</given-names></name><name><surname>D’Esposito</surname><given-names>M</given-names></name></person-group><year iso-8601-date="2007">2007</year><article-title>Functional magnetic resonance imaging evidence for a hierarchical organization of the prefrontal cortex</article-title><source>Journal of Cognitive Neuroscience</source><volume>19</volume><fpage>2082</fpage><lpage>2099</lpage><pub-id pub-id-type="doi">10.1162/jocn.2007.19.12.2082</pub-id><pub-id pub-id-type="pmid">17892391</pub-id></element-citation></ref><ref id="bib11"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Badre</surname><given-names>D</given-names></name></person-group><year iso-8601-date="2008">2008</year><article-title>Cognitive control, hierarchy, and the rostro-caudal organization of the frontal lobes</article-title><source>Trends in Cognitive Sciences</source><volume>12</volume><fpage>193</fpage><lpage>200</lpage><pub-id pub-id-type="doi">10.1016/j.tics.2008.02.004</pub-id><pub-id pub-id-type="pmid">18403252</pub-id></element-citation></ref><ref id="bib12"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Badre</surname><given-names>D</given-names></name><name><surname>Kayser</surname><given-names>AS</given-names></name><name><surname>D’Esposito</surname><given-names>M</given-names></name></person-group><year iso-8601-date="2010">2010</year><article-title>Frontal cortex and the discovery of abstract action rules</article-title><source>Neuron</source><volume>66</volume><fpage>315</fpage><lpage>326</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2010.03.025</pub-id><pub-id pub-id-type="pmid">20435006</pub-id></element-citation></ref><ref id="bib13"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bahlmann</surname><given-names>J</given-names></name><name><surname>Schubotz</surname><given-names>RI</given-names></name><name><surname>Friederici</surname><given-names>AD</given-names></name></person-group><year iso-8601-date="2008">2008</year><article-title>Hierarchical artificial grammar processing engages Broca’s area</article-title><source>NeuroImage</source><volume>42</volume><fpage>525</fpage><lpage>534</lpage><pub-id pub-id-type="doi">10.1016/j.neuroimage.2008.04.249</pub-id><pub-id pub-id-type="pmid">18554927</pub-id></element-citation></ref><ref id="bib14"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Barascud</surname><given-names>N</given-names></name><name><surname>Pearce</surname><given-names>MT</given-names></name><name><surname>Griffiths</surname><given-names>TD</given-names></name><name><surname>Friston</surname><given-names>KJ</given-names></name><name><surname>Chait</surname><given-names>M</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Brain responses in humans reveal ideal observer-like sensitivity to complex acoustic patterns</article-title><source>PNAS</source><volume>113</volume><fpage>E616</fpage><lpage>E625</lpage><pub-id pub-id-type="doi">10.1073/pnas.1508523113</pub-id><pub-id pub-id-type="pmid">26787854</pub-id></element-citation></ref><ref id="bib15"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bates</surname><given-names>D</given-names></name><name><surname>Mächler</surname><given-names>M</given-names></name><name><surname>Bolker</surname><given-names>B</given-names></name><name><surname>Walker</surname><given-names>S</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>Fitting Linear Mixed-Effects Models Using lme4</article-title><source>Journal of Statistical Software</source><volume>67</volume><fpage>1</fpage><lpage>48</lpage><pub-id pub-id-type="doi">10.18637/jss.v067.i01</pub-id></element-citation></ref><ref id="bib16"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Behzadi</surname><given-names>Y</given-names></name><name><surname>Restom</surname><given-names>K</given-names></name><name><surname>Liau</surname><given-names>J</given-names></name><name><surname>Liu</surname><given-names>TT</given-names></name></person-group><year iso-8601-date="2007">2007</year><article-title>A component based noise correction method (CompCor) for BOLD and perfusion based fMRI</article-title><source>NeuroImage</source><volume>37</volume><fpage>90</fpage><lpage>101</lpage><pub-id pub-id-type="doi">10.1016/j.neuroimage.2007.04.042</pub-id><pub-id pub-id-type="pmid">17560126</pub-id></element-citation></ref><ref id="bib17"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bekinschtein</surname><given-names>TA</given-names></name><name><surname>Dehaene</surname><given-names>S</given-names></name><name><surname>Rohaut</surname><given-names>B</given-names></name><name><surname>Tadel</surname><given-names>F</given-names></name><name><surname>Cohen</surname><given-names>L</given-names></name><name><surname>Naccache</surname><given-names>L</given-names></name></person-group><year iso-8601-date="2009">2009</year><article-title>Neural signature of the conscious processing of auditory regularities</article-title><source>PNAS</source><volume>106</volume><fpage>1672</fpage><lpage>1677</lpage><pub-id pub-id-type="doi">10.1073/pnas.0809667106</pub-id><pub-id pub-id-type="pmid">19164526</pub-id></element-citation></ref><ref id="bib18"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bendixen</surname><given-names>A</given-names></name><name><surname>Roeber</surname><given-names>U</given-names></name><name><surname>Schröger</surname><given-names>E</given-names></name></person-group><year iso-8601-date="2007">2007</year><article-title>Regularity extraction and application in dynamic auditory stimulus sequences</article-title><source>Journal of Cognitive Neuroscience</source><volume>19</volume><fpage>1664</fpage><lpage>1677</lpage><pub-id pub-id-type="doi">10.1162/jocn.2007.19.10.1664</pub-id><pub-id pub-id-type="pmid">18271740</pub-id></element-citation></ref><ref id="bib19"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bendixen</surname><given-names>A</given-names></name><name><surname>Schröger</surname><given-names>E</given-names></name><name><surname>Winkler</surname><given-names>I</given-names></name></person-group><year iso-8601-date="2009">2009</year><article-title>I heard that coming: event-related potential evidence for stimulus-driven prediction in the auditory system</article-title><source>The Journal of Neuroscience</source><volume>29</volume><fpage>8447</fpage><lpage>8451</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.1493-09.2009</pub-id><pub-id pub-id-type="pmid">19571135</pub-id></element-citation></ref><ref id="bib20"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bhanji</surname><given-names>JP</given-names></name><name><surname>Beer</surname><given-names>JS</given-names></name><name><surname>Bunge</surname><given-names>SA</given-names></name></person-group><year iso-8601-date="2010">2010</year><article-title>Taking a gamble or playing by the rules: dissociable prefrontal systems implicated in probabilistic versus deterministic rule-based decisions</article-title><source>NeuroImage</source><volume>49</volume><fpage>1810</fpage><lpage>1819</lpage><pub-id pub-id-type="doi">10.1016/j.neuroimage.2009.09.030</pub-id><pub-id pub-id-type="pmid">19781652</pub-id></element-citation></ref><ref id="bib21"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Botvinick</surname><given-names>M</given-names></name><name><surname>Watanabe</surname><given-names>T</given-names></name></person-group><year iso-8601-date="2007">2007</year><article-title>From numerosity to ordinal rank: a gain-field model of serial order representation in cortical working memory</article-title><source>The Journal of Neuroscience</source><volume>27</volume><fpage>8636</fpage><lpage>8642</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.2110-07.2007</pub-id><pub-id pub-id-type="pmid">17687041</pub-id></element-citation></ref><ref id="bib22"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Buiatti</surname><given-names>M</given-names></name><name><surname>Peña</surname><given-names>M</given-names></name><name><surname>Dehaene-Lambertz</surname><given-names>G</given-names></name></person-group><year iso-8601-date="2009">2009</year><article-title>Investigating the neural correlates of continuous speech computation with frequency-tagged neuroelectric responses</article-title><source>NeuroImage</source><volume>44</volume><fpage>509</fpage><lpage>519</lpage><pub-id pub-id-type="doi">10.1016/j.neuroimage.2008.09.015</pub-id><pub-id pub-id-type="pmid">18929668</pub-id></element-citation></ref><ref id="bib23"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Chao</surname><given-names>ZC</given-names></name><name><surname>Takaura</surname><given-names>K</given-names></name><name><surname>Wang</surname><given-names>L</given-names></name><name><surname>Fujii</surname><given-names>N</given-names></name><name><surname>Dehaene</surname><given-names>S</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>Large-scale cortical networks for hierarchical prediction and prediction error in the primate brain</article-title><source>Neuron</source><volume>100</volume><fpage>1252</fpage><lpage>1266</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2018.10.004</pub-id><pub-id pub-id-type="pmid">30482692</pub-id></element-citation></ref><ref id="bib24"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Chater</surname><given-names>N</given-names></name><name><surname>Vitányi</surname><given-names>P</given-names></name></person-group><year iso-8601-date="2003">2003</year><article-title>Simplicity: A unifying principle in cognitive science?</article-title><source>Trends in Cognitive Sciences</source><volume>7</volume><fpage>19</fpage><lpage>22</lpage><pub-id pub-id-type="doi">10.1016/s1364-6613(02)00005-0</pub-id><pub-id pub-id-type="pmid">12517354</pub-id></element-citation></ref><ref id="bib25"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Chen</surname><given-names>JL</given-names></name><name><surname>Penhune</surname><given-names>VB</given-names></name><name><surname>Zatorre</surname><given-names>RJ</given-names></name></person-group><year iso-8601-date="2008">2008</year><article-title>Listening to musical rhythms recruits motor regions of the brain</article-title><source>Cerebral Cortex</source><volume>18</volume><fpage>2844</fpage><lpage>2854</lpage><pub-id pub-id-type="doi">10.1093/cercor/bhn042</pub-id><pub-id pub-id-type="pmid">18388350</pub-id></element-citation></ref><ref id="bib26"><element-citation publication-type="preprint"><person-group person-group-type="author"><name><surname>Chen</surname><given-names>X</given-names></name><name><surname>Affourtit</surname><given-names>J</given-names></name><name><surname>Ryskin</surname><given-names>R</given-names></name><name><surname>Regev</surname><given-names>TI</given-names></name><name><surname>Norman-Haignere</surname><given-names>S</given-names></name><name><surname>Jouravlev</surname><given-names>O</given-names></name><name><surname>Malik-Moraleda</surname><given-names>S</given-names></name><name><surname>Kean</surname><given-names>H</given-names></name><name><surname>Varley</surname><given-names>R</given-names></name><name><surname>Fedorenko</surname><given-names>E</given-names></name></person-group><year iso-8601-date="2021">2021</year><article-title>The Human Language System, Including Its Inferior Frontal Component in ‘Broca’s Area’, Does Not Support Music Perception</article-title><source>bioRxiv</source><pub-id pub-id-type="doi">10.1101/2021.06.01.446439</pub-id></element-citation></ref><ref id="bib27"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Cona</surname><given-names>G</given-names></name><name><surname>Semenza</surname><given-names>C</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>Supplementary motor area as key structure for domain-general sequence processing: A unified account</article-title><source>Neuroscience and Biobehavioral Reviews</source><volume>72</volume><fpage>28</fpage><lpage>42</lpage><pub-id pub-id-type="doi">10.1016/j.neubiorev.2016.10.033</pub-id><pub-id pub-id-type="pmid">27856331</pub-id></element-citation></ref><ref id="bib28"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Coull</surname><given-names>JT</given-names></name><name><surname>Cheng</surname><given-names>RK</given-names></name><name><surname>Meck</surname><given-names>WH</given-names></name></person-group><year iso-8601-date="2011">2011</year><article-title>Neuroanatomical and neurochemical substrates of timing</article-title><source>Neuropsychopharmacology</source><volume>36</volume><fpage>3</fpage><lpage>25</lpage><pub-id pub-id-type="doi">10.1038/npp.2010.113</pub-id><pub-id pub-id-type="pmid">20668434</pub-id></element-citation></ref><ref id="bib29"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Cowan</surname><given-names>N</given-names></name></person-group><year iso-8601-date="2001">2001</year><article-title>The magical number 4 in short-term memory: A reconsideration of mental storage capacity</article-title><source>The Behavioral and Brain Sciences</source><volume>24</volume><fpage>87</fpage><lpage>114</lpage><pub-id pub-id-type="doi">10.1017/s0140525x01003922</pub-id><pub-id pub-id-type="pmid">11515286</pub-id></element-citation></ref><ref id="bib30"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Cowan</surname><given-names>N</given-names></name></person-group><year iso-8601-date="2010">2010</year><article-title>The magical mystery four: how is working memory capacity limited, and why?</article-title><source>Current Directions in Psychological Science</source><volume>19</volume><fpage>51</fpage><lpage>57</lpage><pub-id pub-id-type="doi">10.1177/0963721409359277</pub-id><pub-id pub-id-type="pmid">20445769</pub-id></element-citation></ref><ref id="bib31"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Dale</surname><given-names>AM</given-names></name><name><surname>Fischl</surname><given-names>B</given-names></name><name><surname>Sereno</surname><given-names>MI</given-names></name></person-group><year iso-8601-date="1999">1999</year><article-title>Cortical Surface-Based Analysis</article-title><source>NeuroImage</source><volume>9</volume><fpage>179</fpage><lpage>194</lpage><pub-id pub-id-type="doi">10.1006/nimg.1998.0395</pub-id><pub-id pub-id-type="pmid">9931268</pub-id></element-citation></ref><ref id="bib32"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Dale</surname><given-names>AM</given-names></name><name><surname>Liu</surname><given-names>AK</given-names></name><name><surname>Fischl</surname><given-names>BR</given-names></name><name><surname>Buckner</surname><given-names>RL</given-names></name><name><surname>Belliveau</surname><given-names>JW</given-names></name><name><surname>Lewine</surname><given-names>JD</given-names></name><name><surname>Halgren</surname><given-names>E</given-names></name></person-group><year iso-8601-date="2000">2000</year><article-title>Dynamic statistical parametric mapping: combining fMRI and MEG for high-resolution imaging of cortical activity</article-title><source>Neuron</source><volume>26</volume><fpage>55</fpage><lpage>67</lpage><pub-id pub-id-type="doi">10.1016/s0896-6273(00)81138-1</pub-id><pub-id pub-id-type="pmid">10798392</pub-id></element-citation></ref><ref id="bib33"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Dehaene</surname><given-names>S</given-names></name><name><surname>Piazza</surname><given-names>M</given-names></name><name><surname>Pinel</surname><given-names>P</given-names></name><name><surname>Cohen</surname><given-names>L</given-names></name></person-group><year iso-8601-date="2003">2003</year><article-title>Three parietal circuits for number processing</article-title><source>Cognitive Neuropsychology</source><volume>20</volume><fpage>487</fpage><lpage>506</lpage><pub-id pub-id-type="doi">10.1080/02643290244000239</pub-id><pub-id pub-id-type="pmid">20957581</pub-id></element-citation></ref><ref id="bib34"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Dehaene</surname><given-names>S</given-names></name><name><surname>Meyniel</surname><given-names>F</given-names></name><name><surname>Wacongne</surname><given-names>C</given-names></name><name><surname>Wang</surname><given-names>L</given-names></name><name><surname>Pallier</surname><given-names>C</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>The neural representation of sequences: from transition probabilities to algebraic patterns and linguistic trees</article-title><source>Neuron</source><volume>88</volume><fpage>2</fpage><lpage>19</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2015.09.019</pub-id><pub-id pub-id-type="pmid">26447569</pub-id></element-citation></ref><ref id="bib35"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Dehaene</surname><given-names>S</given-names></name><name><surname>Al Roumi</surname><given-names>F</given-names></name><name><surname>Lakretz</surname><given-names>Y</given-names></name><name><surname>Planton</surname><given-names>S</given-names></name><name><surname>Sablé-Meyer</surname><given-names>M</given-names></name></person-group><year iso-8601-date="2022">2022</year><article-title>Symbols and mental programs: a hypothesis about human singularity</article-title><source>Trends in Cognitive Sciences</source><volume>26</volume><fpage>751</fpage><lpage>766</lpage><pub-id pub-id-type="doi">10.1016/j.tics.2022.06.010</pub-id><pub-id pub-id-type="pmid">35933289</pub-id></element-citation></ref><ref id="bib36"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Delahaye</surname><given-names>JP</given-names></name><name><surname>Zenil</surname><given-names>H</given-names></name></person-group><year iso-8601-date="2012">2012</year><article-title>Numerical evaluation of algorithmic complexity for short strings: a glance into the innermost structure of randomness</article-title><source>Applied Mathematics and Computation</source><volume>219</volume><fpage>63</fpage><lpage>77</lpage><pub-id pub-id-type="doi">10.1016/j.amc.2011.10.006</pub-id></element-citation></ref><ref id="bib37"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Eger</surname><given-names>E</given-names></name><name><surname>Michel</surname><given-names>V</given-names></name><name><surname>Thirion</surname><given-names>B</given-names></name><name><surname>Amadon</surname><given-names>A</given-names></name><name><surname>Dehaene</surname><given-names>S</given-names></name><name><surname>Kleinschmidt</surname><given-names>A</given-names></name></person-group><year iso-8601-date="2009">2009</year><article-title>Deciphering cortical number coding from human brain activity patterns</article-title><source>Current Biology</source><volume>19</volume><fpage>1608</fpage><lpage>1615</lpage><pub-id pub-id-type="doi">10.1016/j.cub.2009.08.047</pub-id><pub-id pub-id-type="pmid">19781939</pub-id></element-citation></ref><ref id="bib38"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>El Karoui</surname><given-names>I</given-names></name><name><surname>King</surname><given-names>JR</given-names></name><name><surname>Sitt</surname><given-names>J</given-names></name><name><surname>Meyniel</surname><given-names>F</given-names></name><name><surname>Van Gaal</surname><given-names>S</given-names></name><name><surname>Hasboun</surname><given-names>D</given-names></name><name><surname>Adam</surname><given-names>C</given-names></name><name><surname>Navarro</surname><given-names>V</given-names></name><name><surname>Baulac</surname><given-names>M</given-names></name><name><surname>Dehaene</surname><given-names>S</given-names></name><name><surname>Cohen</surname><given-names>L</given-names></name><name><surname>Naccache</surname><given-names>L</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>Event-related potential, time-frequency, and functional connectivity facets of local and global auditory novelty processing: an intracranial study in humans</article-title><source>Cerebral Cortex</source><volume>25</volume><fpage>4203</fpage><lpage>4212</lpage><pub-id pub-id-type="doi">10.1093/cercor/bhu143</pub-id><pub-id pub-id-type="pmid">24969472</pub-id></element-citation></ref><ref id="bib39"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Fadiga</surname><given-names>L</given-names></name><name><surname>Craighero</surname><given-names>L</given-names></name><name><surname>D’Ausilio</surname><given-names>A</given-names></name></person-group><year iso-8601-date="2009">2009</year><article-title>Broca’s area in language, action, and music</article-title><source>Annals of the New York Academy of Sciences</source><volume>1169</volume><fpage>448</fpage><lpage>458</lpage><pub-id pub-id-type="doi">10.1111/j.1749-6632.2009.04582.x</pub-id><pub-id pub-id-type="pmid">19673823</pub-id></element-citation></ref><ref id="bib40"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Fedorenko</surname><given-names>E</given-names></name><name><surname>Duncan</surname><given-names>J</given-names></name><name><surname>Kanwisher</surname><given-names>N</given-names></name></person-group><year iso-8601-date="2012">2012</year><article-title>Language-selective and domain-general regions lie side by side within Broca’s area</article-title><source>Current Biology</source><volume>22</volume><fpage>2059</fpage><lpage>2062</lpage><pub-id pub-id-type="doi">10.1016/j.cub.2012.09.011</pub-id><pub-id pub-id-type="pmid">23063434</pub-id></element-citation></ref><ref id="bib41"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Fedorenko</surname><given-names>E</given-names></name><name><surname>Varley</surname><given-names>R</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Language and thought are not the same thing: evidence from neuroimaging and neurological patients</article-title><source>Annals of the New York Academy of Sciences</source><volume>1369</volume><fpage>132</fpage><lpage>153</lpage><pub-id pub-id-type="doi">10.1111/nyas.13046</pub-id><pub-id pub-id-type="pmid">27096882</pub-id></element-citation></ref><ref id="bib42"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Feldman</surname><given-names>J</given-names></name></person-group><year iso-8601-date="2000">2000</year><article-title>Minimization of Boolean complexity in human concept learning</article-title><source>Nature</source><volume>407</volume><fpage>630</fpage><lpage>633</lpage><pub-id pub-id-type="doi">10.1038/35036586</pub-id><pub-id pub-id-type="pmid">11034211</pub-id></element-citation></ref><ref id="bib43"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ferrigno</surname><given-names>S</given-names></name><name><surname>Cheyette</surname><given-names>SJ</given-names></name><name><surname>Piantadosi</surname><given-names>ST</given-names></name><name><surname>Cantlon</surname><given-names>JF</given-names></name></person-group><year iso-8601-date="2020">2020</year><article-title>Recursive sequence generation in monkeys, children, U.S. adults, and native Amazonians</article-title><source>Science Advances</source><volume>6</volume><elocation-id>eaaz1002</elocation-id><pub-id pub-id-type="doi">10.1126/sciadv.aaz1002</pub-id><pub-id pub-id-type="pmid">32637593</pub-id></element-citation></ref><ref id="bib44"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Fischl</surname><given-names>B</given-names></name><name><surname>Salat</surname><given-names>DH</given-names></name><name><surname>Busa</surname><given-names>E</given-names></name><name><surname>Albert</surname><given-names>M</given-names></name><name><surname>Dieterich</surname><given-names>M</given-names></name><name><surname>Haselgrove</surname><given-names>C</given-names></name><name><surname>van der Kouwe</surname><given-names>A</given-names></name><name><surname>Killiany</surname><given-names>R</given-names></name><name><surname>Kennedy</surname><given-names>D</given-names></name><name><surname>Klaveness</surname><given-names>S</given-names></name><name><surname>Montillo</surname><given-names>A</given-names></name><name><surname>Makris</surname><given-names>N</given-names></name><name><surname>Rosen</surname><given-names>B</given-names></name><name><surname>Dale</surname><given-names>AM</given-names></name></person-group><year iso-8601-date="2002">2002</year><article-title>Whole brain segmentation: automated labeling of neuroanatomical structures in the human brain</article-title><source>Neuron</source><volume>33</volume><fpage>341</fpage><lpage>355</lpage><pub-id pub-id-type="doi">10.1016/s0896-6273(02)00569-x</pub-id><pub-id pub-id-type="pmid">11832223</pub-id></element-citation></ref><ref id="bib45"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Fitch</surname><given-names>WT</given-names></name><name><surname>Hauser</surname><given-names>MD</given-names></name></person-group><year iso-8601-date="2004">2004</year><article-title>Computational constraints on syntactic processing in a nonhuman primate</article-title><source>Science</source><volume>303</volume><fpage>377</fpage><lpage>380</lpage><pub-id pub-id-type="doi">10.1126/science.1089401</pub-id><pub-id pub-id-type="pmid">14726592</pub-id></element-citation></ref><ref id="bib46"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Fitch</surname><given-names>WT</given-names></name><name><surname>Friederici</surname><given-names>AD</given-names></name></person-group><year iso-8601-date="2012">2012</year><article-title>Artificial grammar learning meets formal language theory: an overview</article-title><source>Philosophical Transactions of the Royal Society of London. Series B, Biological Sciences</source><volume>367</volume><fpage>1933</fpage><lpage>1955</lpage><pub-id pub-id-type="doi">10.1098/rstb.2012.0103</pub-id><pub-id pub-id-type="pmid">22688631</pub-id></element-citation></ref><ref id="bib47"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Fitch</surname><given-names>WT</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>Attending to the forest and the trees: reply to comments on “Toward a computational framework for cognitive biology: unifying approaches from cognitive neuroscience and comparative cognition.”</article-title><source>Physics of Life Reviews</source><volume>11</volume><fpage>391</fpage><lpage>399</lpage><pub-id pub-id-type="doi">10.1016/j.plrev.2014.07.008</pub-id><pub-id pub-id-type="pmid">25112825</pub-id></element-citation></ref><ref id="bib48"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Fitch</surname><given-names>WT</given-names></name><name><surname>Martins</surname><given-names>MD</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>Hierarchical processing in music, language, and action: Lashley revisited</article-title><source>Annals of the New York Academy of Sciences</source><volume>1316</volume><fpage>87</fpage><lpage>104</lpage><pub-id pub-id-type="doi">10.1111/nyas.12406</pub-id><pub-id pub-id-type="pmid">24697242</pub-id></element-citation></ref><ref id="bib49"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Fló</surname><given-names>A</given-names></name><name><surname>Brusini</surname><given-names>P</given-names></name><name><surname>Macagno</surname><given-names>F</given-names></name><name><surname>Nespor</surname><given-names>M</given-names></name><name><surname>Mehler</surname><given-names>J</given-names></name><name><surname>Ferry</surname><given-names>AL</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>Newborns are sensitive to multiple cues for word segmentation in continuous speech</article-title><source>Developmental Science</source><volume>22</volume><elocation-id>e12802</elocation-id><pub-id pub-id-type="doi">10.1111/desc.12802</pub-id><pub-id pub-id-type="pmid">30681763</pub-id></element-citation></ref><ref id="bib50"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Fodor</surname><given-names>JA</given-names></name></person-group><year iso-8601-date="1975">1975</year><source>The Language of Thought</source><publisher-name>Harvard University Press</publisher-name></element-citation></ref><ref id="bib51"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Friederici</surname><given-names>AD</given-names></name><name><surname>Bahlmann</surname><given-names>J</given-names></name><name><surname>Heim</surname><given-names>S</given-names></name><name><surname>Schubotz</surname><given-names>RI</given-names></name><name><surname>Anwander</surname><given-names>A</given-names></name></person-group><year iso-8601-date="2006">2006</year><article-title>The brain differentiates human and non-human grammars: functional localization and structural connectivity</article-title><source>PNAS</source><volume>103</volume><fpage>2458</fpage><lpage>2463</lpage><pub-id pub-id-type="doi">10.1073/pnas.0509389103</pub-id><pub-id pub-id-type="pmid">16461904</pub-id></element-citation></ref><ref id="bib52"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Friston</surname><given-names>K</given-names></name></person-group><year iso-8601-date="2005">2005</year><article-title>A theory of cortical responses</article-title><source>Philosophical Transactions of the Royal Society of London. Series B, Biological Sciences</source><volume>360</volume><fpage>815</fpage><lpage>836</lpage><pub-id pub-id-type="doi">10.1098/rstb.2005.1622</pub-id><pub-id pub-id-type="pmid">15937014</pub-id></element-citation></ref><ref id="bib53"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Frost</surname><given-names>R</given-names></name><name><surname>Armstrong</surname><given-names>BC</given-names></name><name><surname>Siegelman</surname><given-names>N</given-names></name><name><surname>Christiansen</surname><given-names>MH</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>Domain generality versus modality specificity: the paradox of statistical learning</article-title><source>Trends in Cognitive Sciences</source><volume>19</volume><fpage>117</fpage><lpage>125</lpage><pub-id pub-id-type="doi">10.1016/j.tics.2014.12.010</pub-id><pub-id pub-id-type="pmid">25631249</pub-id></element-citation></ref><ref id="bib54"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Fujii</surname><given-names>N</given-names></name><name><surname>Graybiel</surname><given-names>AM</given-names></name></person-group><year iso-8601-date="2003">2003</year><article-title>Representation of action sequence boundaries by macaque prefrontal cortical neurons</article-title><source>Science</source><volume>301</volume><fpage>1246</fpage><lpage>1249</lpage><pub-id pub-id-type="doi">10.1126/science.1086872</pub-id><pub-id pub-id-type="pmid">12947203</pub-id></element-citation></ref><ref id="bib55"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Gauvrit</surname><given-names>N</given-names></name><name><surname>Zenil</surname><given-names>H</given-names></name><name><surname>Delahaye</surname><given-names>JP</given-names></name><name><surname>Soler-Toscano</surname><given-names>F</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>Algorithmic complexity for short binary strings applied to psychology: a primer</article-title><source>Behavior Research Methods</source><volume>46</volume><fpage>732</fpage><lpage>744</lpage><pub-id pub-id-type="doi">10.3758/s13428-013-0416-0</pub-id><pub-id pub-id-type="pmid">24311059</pub-id></element-citation></ref><ref id="bib56"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Gentner</surname><given-names>TQ</given-names></name><name><surname>Fenn</surname><given-names>KM</given-names></name><name><surname>Margoliash</surname><given-names>D</given-names></name><name><surname>Nusbaum</surname><given-names>HC</given-names></name></person-group><year iso-8601-date="2006">2006</year><article-title>Recursive syntactic pattern learning by songbirds</article-title><source>Nature</source><volume>440</volume><fpage>1204</fpage><lpage>1207</lpage><pub-id pub-id-type="doi">10.1038/nature04675</pub-id><pub-id pub-id-type="pmid">16641998</pub-id></element-citation></ref><ref id="bib57"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Glanzer</surname><given-names>M</given-names></name><name><surname>Clark</surname><given-names>WH</given-names></name></person-group><year iso-8601-date="1963">1963</year><article-title>Accuracy of perceptual recall: An analysis of organization</article-title><source>Journal of Verbal Learning and Verbal Behavior</source><volume>1</volume><fpage>289</fpage><lpage>299</lpage><pub-id pub-id-type="doi">10.1016/S0022-5371(63)80008-0</pub-id></element-citation></ref><ref id="bib58"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Gramfort</surname><given-names>A</given-names></name><name><surname>Luessi</surname><given-names>M</given-names></name><name><surname>Larson</surname><given-names>E</given-names></name><name><surname>Engemann</surname><given-names>DA</given-names></name><name><surname>Strohmeier</surname><given-names>D</given-names></name><name><surname>Brodbeck</surname><given-names>C</given-names></name><name><surname>Goj</surname><given-names>R</given-names></name><name><surname>Jas</surname><given-names>M</given-names></name><name><surname>Brooks</surname><given-names>T</given-names></name><name><surname>Parkkonen</surname><given-names>L</given-names></name><name><surname>Hämäläinen</surname><given-names>M</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>MEG and EEG data analysis with MNE-Python</article-title><source>Frontiers in Neuroscience</source><volume>7</volume><elocation-id>267</elocation-id><pub-id pub-id-type="doi">10.3389/fnins.2013.00267</pub-id><pub-id pub-id-type="pmid">24431986</pub-id></element-citation></ref><ref id="bib59"><element-citation publication-type="preprint"><person-group person-group-type="author"><name><surname>Grunwald</surname><given-names>P</given-names></name></person-group><year iso-8601-date="2004">2004</year><article-title>A Tutorial Introduction to the Minimum Description Length Principle</article-title><source>arXiv</source><ext-link ext-link-type="uri" xlink:href="http://arxiv.org/abs/math/0406077">http://arxiv.org/abs/math/0406077</ext-link></element-citation></ref><ref id="bib60"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hagoort</surname><given-names>P</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>MUC (Memory, Unification, Control) and beyond</article-title><source>Frontiers in Psychology</source><volume>4</volume><elocation-id>416</elocation-id><pub-id pub-id-type="doi">10.3389/fpsyg.2013.00416</pub-id><pub-id pub-id-type="pmid">23874313</pub-id></element-citation></ref><ref id="bib61"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Harvey</surname><given-names>BM</given-names></name><name><surname>Klein</surname><given-names>BP</given-names></name><name><surname>Petridou</surname><given-names>N</given-names></name><name><surname>Dumoulin</surname><given-names>SO</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>Topographic representation of numerosity in the human parietal cortex</article-title><source>Science</source><volume>341</volume><fpage>1123</fpage><lpage>1126</lpage><pub-id pub-id-type="doi">10.1126/science.1239052</pub-id><pub-id pub-id-type="pmid">24009396</pub-id></element-citation></ref><ref id="bib62"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hauser</surname><given-names>MD</given-names></name><name><surname>Newport</surname><given-names>EL</given-names></name><name><surname>Aslin</surname><given-names>RN</given-names></name></person-group><year iso-8601-date="2001">2001</year><article-title>Segmentation of the speech stream in a non-human primate: statistical learning in cotton-top tamarins</article-title><source>Cognition</source><volume>78</volume><fpage>B53</fpage><lpage>B64</lpage><pub-id pub-id-type="doi">10.1016/s0010-0277(00)00132-3</pub-id><pub-id pub-id-type="pmid">11124355</pub-id></element-citation></ref><ref id="bib63"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hauser</surname><given-names>MD</given-names></name><name><surname>Chomsky</surname><given-names>N</given-names></name><name><surname>Fitch</surname><given-names>WT</given-names></name></person-group><year iso-8601-date="2002">2002</year><article-title>The faculty of language: what is it, who has it, and how did it evolve?</article-title><source>Science</source><volume>298</volume><fpage>1569</fpage><lpage>1579</lpage><pub-id pub-id-type="doi">10.1126/science.298.5598.1569</pub-id><pub-id pub-id-type="pmid">12446899</pub-id></element-citation></ref><ref id="bib64"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hautus</surname><given-names>MJ</given-names></name></person-group><year iso-8601-date="1995">1995</year><article-title>Corrections for extreme proportions and their biasing effects on estimated values ofd′</article-title><source>Behavior Research Methods, Instruments, &amp; Computers</source><volume>27</volume><fpage>46</fpage><lpage>51</lpage><pub-id pub-id-type="doi">10.3758/BF03203619</pub-id></element-citation></ref><ref id="bib65"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Heilbron</surname><given-names>M</given-names></name><name><surname>Chait</surname><given-names>M</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>Great expectations: is there evidence for predictive coding in auditory cortex?</article-title><source>Neuroscience</source><volume>389</volume><fpage>54</fpage><lpage>73</lpage><pub-id pub-id-type="doi">10.1016/j.neuroscience.2017.07.061</pub-id><pub-id pub-id-type="pmid">28782642</pub-id></element-citation></ref><ref id="bib66"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Huettel</surname><given-names>SA</given-names></name><name><surname>Mack</surname><given-names>PB</given-names></name><name><surname>McCarthy</surname><given-names>G</given-names></name></person-group><year iso-8601-date="2002">2002</year><article-title>Perceiving patterns in random series: dynamic processing of sequence in prefrontal cortex</article-title><source>Nature Neuroscience</source><volume>5</volume><fpage>485</fpage><lpage>490</lpage><pub-id pub-id-type="doi">10.1038/nn841</pub-id><pub-id pub-id-type="pmid">11941373</pub-id></element-citation></ref><ref id="bib67"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hurlstone</surname><given-names>MJ</given-names></name><name><surname>Hitch</surname><given-names>GJ</given-names></name><name><surname>Baddeley</surname><given-names>AD</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>Memory for serial order across domains: An overview of the literature and directions for future research</article-title><source>Psychological Bulletin</source><volume>140</volume><fpage>339</fpage><lpage>373</lpage><pub-id pub-id-type="doi">10.1037/a0034221</pub-id><pub-id pub-id-type="pmid">24079725</pub-id></element-citation></ref><ref id="bib68"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Jas</surname><given-names>M</given-names></name><name><surname>Engemann</surname><given-names>DA</given-names></name><name><surname>Bekhti</surname><given-names>Y</given-names></name><name><surname>Raimondo</surname><given-names>F</given-names></name><name><surname>Gramfort</surname><given-names>A</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>Autoreject: Automated artifact rejection for MEG and EEG data</article-title><source>NeuroImage</source><volume>159</volume><fpage>417</fpage><lpage>429</lpage><pub-id pub-id-type="doi">10.1016/j.neuroimage.2017.06.030</pub-id><pub-id pub-id-type="pmid">28645840</pub-id></element-citation></ref><ref id="bib69"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Jas</surname><given-names>M</given-names></name><name><surname>Larson</surname><given-names>E</given-names></name><name><surname>Engemann</surname><given-names>DA</given-names></name><name><surname>Leppäkangas</surname><given-names>J</given-names></name><name><surname>Taulu</surname><given-names>S</given-names></name><name><surname>Hämäläinen</surname><given-names>M</given-names></name><name><surname>Gramfort</surname><given-names>A</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>A Reproducible MEG/EEG Group Study With the MNE Software: Recommendations, Quality Assessments, and Good Practices</article-title><source>Frontiers in Neuroscience</source><volume>12</volume><elocation-id>530</elocation-id><pub-id pub-id-type="doi">10.3389/fnins.2018.00530</pub-id><pub-id pub-id-type="pmid">30127712</pub-id></element-citation></ref><ref id="bib70"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Jenkins</surname><given-names>IH</given-names></name><name><surname>Brooks</surname><given-names>DJ</given-names></name><name><surname>Nixon</surname><given-names>PD</given-names></name><name><surname>Frackowiak</surname><given-names>RS</given-names></name><name><surname>Passingham</surname><given-names>RE</given-names></name></person-group><year iso-8601-date="1994">1994</year><article-title>Motor sequence learning: a study with positron emission tomography</article-title><source>The Journal of Neuroscience</source><volume>14</volume><fpage>3775</fpage><lpage>3790</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.14-06-03775.1994</pub-id><pub-id pub-id-type="pmid">8207487</pub-id></element-citation></ref><ref id="bib71"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Jiang</surname><given-names>X</given-names></name><name><surname>Long</surname><given-names>T</given-names></name><name><surname>Cao</surname><given-names>W</given-names></name><name><surname>Li</surname><given-names>J</given-names></name><name><surname>Dehaene</surname><given-names>S</given-names></name><name><surname>Wang</surname><given-names>L</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>Production of supra-regular spatial sequences by macaque monkeys</article-title><source>Current Biology</source><volume>28</volume><fpage>1851</fpage><lpage>1859</lpage><pub-id pub-id-type="doi">10.1016/j.cub.2018.04.047</pub-id><pub-id pub-id-type="pmid">29887304</pub-id></element-citation></ref><ref id="bib72"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kanayet</surname><given-names>FJ</given-names></name><name><surname>Mattarella-Micke</surname><given-names>A</given-names></name><name><surname>Kohler</surname><given-names>PJ</given-names></name><name><surname>Norcia</surname><given-names>AM</given-names></name><name><surname>McCandliss</surname><given-names>BD</given-names></name><name><surname>McClelland</surname><given-names>JL</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>Distinct representations of magnitude and spatial position within parietal cortex during number-space mapping</article-title><source>Journal of Cognitive Neuroscience</source><volume>30</volume><fpage>200</fpage><lpage>218</lpage><pub-id pub-id-type="doi">10.1162/jocn_a_01199</pub-id><pub-id pub-id-type="pmid">29040015</pub-id></element-citation></ref><ref id="bib73"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Karuza</surname><given-names>EA</given-names></name><name><surname>Kahn</surname><given-names>AE</given-names></name><name><surname>Bassett</surname><given-names>DS</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>Human sensitivity to community structure is robust to topological variation</article-title><source>Complexity</source><volume>2019</volume><fpage>1</fpage><lpage>8</lpage><pub-id pub-id-type="doi">10.1155/2019/8379321</pub-id></element-citation></ref><ref id="bib74"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kasper</surname><given-names>L</given-names></name><name><surname>Bollmann</surname><given-names>S</given-names></name><name><surname>Diaconescu</surname><given-names>AO</given-names></name><name><surname>Hutton</surname><given-names>C</given-names></name><name><surname>Heinzle</surname><given-names>J</given-names></name><name><surname>Iglesias</surname><given-names>S</given-names></name><name><surname>Hauser</surname><given-names>TU</given-names></name><name><surname>Sebold</surname><given-names>M</given-names></name><name><surname>Manjaly</surname><given-names>ZM</given-names></name><name><surname>Pruessmann</surname><given-names>KP</given-names></name><name><surname>Stephan</surname><given-names>KE</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>The PhysIO Toolbox for Modeling Physiological Noise in fMRI Data</article-title><source>Journal of Neuroscience Methods</source><volume>276</volume><fpage>56</fpage><lpage>72</lpage><pub-id pub-id-type="doi">10.1016/j.jneumeth.2016.10.019</pub-id><pub-id pub-id-type="pmid">27832957</pub-id></element-citation></ref><ref id="bib75"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kidd</surname><given-names>C</given-names></name><name><surname>Piantadosi</surname><given-names>ST</given-names></name><name><surname>Aslin</surname><given-names>RN</given-names></name><name><surname>Rodriguez-Fornells</surname><given-names>A</given-names></name></person-group><year iso-8601-date="2012">2012</year><article-title>The Goldilocks effect: human infants allocate attention to visual sequences that are neither too simple nor too complex</article-title><source>PLOS ONE</source><volume>7</volume><elocation-id>e36399</elocation-id><pub-id pub-id-type="doi">10.1371/journal.pone.0036399</pub-id><pub-id pub-id-type="pmid">22649492</pub-id></element-citation></ref><ref id="bib76"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kidd</surname><given-names>C</given-names></name><name><surname>Piantadosi</surname><given-names>ST</given-names></name><name><surname>Aslin</surname><given-names>RN</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>The Goldilocks effect in infant auditory attention</article-title><source>Child Development</source><volume>85</volume><fpage>1795</fpage><lpage>1804</lpage><pub-id pub-id-type="doi">10.1111/cdev.12263</pub-id><pub-id pub-id-type="pmid">24990627</pub-id></element-citation></ref><ref id="bib77"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>King</surname><given-names>JR</given-names></name><name><surname>Faugeras</surname><given-names>F</given-names></name><name><surname>Gramfort</surname><given-names>A</given-names></name><name><surname>Schurger</surname><given-names>A</given-names></name><name><surname>El Karoui</surname><given-names>I</given-names></name><name><surname>Sitt</surname><given-names>JD</given-names></name><name><surname>Rohaut</surname><given-names>B</given-names></name><name><surname>Wacongne</surname><given-names>C</given-names></name><name><surname>Labyt</surname><given-names>E</given-names></name><name><surname>Bekinschtein</surname><given-names>T</given-names></name><name><surname>Cohen</surname><given-names>L</given-names></name><name><surname>Naccache</surname><given-names>L</given-names></name><name><surname>Dehaene</surname><given-names>S</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>Single-trial decoding of auditory novelty responses facilitates the detection of residual consciousness</article-title><source>NeuroImage</source><volume>83</volume><fpage>726</fpage><lpage>738</lpage><pub-id pub-id-type="doi">10.1016/j.neuroimage.2013.07.013</pub-id><pub-id pub-id-type="pmid">23859924</pub-id></element-citation></ref><ref id="bib78"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>King</surname><given-names>JR</given-names></name><name><surname>Dehaene</surname><given-names>S</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>Characterizing the dynamics of mental representations: the temporal generalization method</article-title><source>Trends in Cognitive Sciences</source><volume>18</volume><fpage>203</fpage><lpage>210</lpage><pub-id pub-id-type="doi">10.1016/j.tics.2014.01.002</pub-id><pub-id pub-id-type="pmid">24593982</pub-id></element-citation></ref><ref id="bib79"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kóbor</surname><given-names>A</given-names></name><name><surname>Takács</surname><given-names>Á</given-names></name><name><surname>Kardos</surname><given-names>Z</given-names></name><name><surname>Janacsek</surname><given-names>K</given-names></name><name><surname>Horváth</surname><given-names>K</given-names></name><name><surname>Csépe</surname><given-names>V</given-names></name><name><surname>Nemeth</surname><given-names>D</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>ERPs differentiate the sensitivity to statistical probabilities and the learning of sequential structures during procedural learning</article-title><source>Biological Psychology</source><volume>135</volume><fpage>180</fpage><lpage>193</lpage><pub-id pub-id-type="doi">10.1016/j.biopsycho.2018.04.001</pub-id><pub-id pub-id-type="pmid">29634990</pub-id></element-citation></ref><ref id="bib80"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Koechlin</surname><given-names>E</given-names></name><name><surname>Ody</surname><given-names>C</given-names></name><name><surname>Kouneiher</surname><given-names>F</given-names></name></person-group><year iso-8601-date="2003">2003</year><article-title>The architecture of cognitive control in the human prefrontal cortex</article-title><source>Science</source><volume>302</volume><fpage>1181</fpage><lpage>1185</lpage><pub-id pub-id-type="doi">10.1126/science.1088545</pub-id><pub-id pub-id-type="pmid">14615530</pub-id></element-citation></ref><ref id="bib81"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Koechlin</surname><given-names>E</given-names></name><name><surname>Jubault</surname><given-names>T</given-names></name></person-group><year iso-8601-date="2006">2006</year><article-title>Broca’s area and the hierarchical organization of human behavior</article-title><source>Neuron</source><volume>50</volume><fpage>963</fpage><lpage>974</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2006.05.017</pub-id><pub-id pub-id-type="pmid">16772176</pub-id></element-citation></ref><ref id="bib82"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Koelsch</surname><given-names>S</given-names></name><name><surname>Gunter</surname><given-names>TC</given-names></name><name><surname>v Cramon</surname><given-names>DY</given-names></name><name><surname>Zysset</surname><given-names>S</given-names></name><name><surname>Lohmann</surname><given-names>G</given-names></name><name><surname>Friederici</surname><given-names>AD</given-names></name></person-group><year iso-8601-date="2002">2002</year><article-title>Bach speaks: a cortical “language-network” serves the processing of music</article-title><source>NeuroImage</source><volume>17</volume><fpage>956</fpage><lpage>966</lpage><pub-id pub-id-type="pmid">12377169</pub-id></element-citation></ref><ref id="bib83"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kunert</surname><given-names>R</given-names></name><name><surname>Willems</surname><given-names>RM</given-names></name><name><surname>Casasanto</surname><given-names>D</given-names></name><name><surname>Patel</surname><given-names>AD</given-names></name><name><surname>Hagoort</surname><given-names>P</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>Music and Language Syntax Interact in Broca’s Area: An fMRI Study</article-title><source>PLOS ONE</source><volume>10</volume><elocation-id>e0141069</elocation-id><pub-id pub-id-type="doi">10.1371/journal.pone.0141069</pub-id><pub-id pub-id-type="pmid">26536026</pub-id></element-citation></ref><ref id="bib84"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kuznetsova</surname><given-names>A</given-names></name><name><surname>Brockhoff</surname><given-names>PB</given-names></name><name><surname>Christensen</surname><given-names>RHB</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>lmertest package: tests in linear mixed effects models</article-title><source>Journal of Statistical Software</source><volume>82</volume><fpage>1</fpage><lpage>26</lpage><pub-id pub-id-type="doi">10.18637/jss.v082.i13</pub-id></element-citation></ref><ref id="bib85"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Lashley</surname><given-names>KS</given-names></name></person-group><year iso-8601-date="1951">1951</year><chapter-title>The problem of serial order in behavior</chapter-title><person-group person-group-type="editor"><name><surname>Jeffress</surname><given-names>LA</given-names></name></person-group><source>Cerebral Mechanisms in Behavior; the Hixon Symposium</source><publisher-name>Wiley</publisher-name><fpage>112</fpage><lpage>146</lpage></element-citation></ref><ref id="bib86"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Leeuwenberg</surname><given-names>EL</given-names></name></person-group><year iso-8601-date="1969">1969</year><article-title>Quantitative specification of information in sequential patterns</article-title><source>Psychological Review</source><volume>76</volume><fpage>216</fpage><lpage>220</lpage><pub-id pub-id-type="doi">10.1037/h0027285</pub-id><pub-id pub-id-type="pmid">5778471</pub-id></element-citation></ref><ref id="bib87"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Leggio</surname><given-names>MG</given-names></name><name><surname>Tedesco</surname><given-names>AM</given-names></name><name><surname>Chiricozzi</surname><given-names>FR</given-names></name><name><surname>Clausi</surname><given-names>S</given-names></name><name><surname>Orsini</surname><given-names>A</given-names></name><name><surname>Molinari</surname><given-names>M</given-names></name></person-group><year iso-8601-date="2008">2008</year><article-title>Cognitive sequencing impairment in patients with focal or atrophic cerebellar damage</article-title><source>Brain</source><volume>131</volume><fpage>1332</fpage><lpage>1343</lpage><pub-id pub-id-type="doi">10.1093/brain/awn040</pub-id><pub-id pub-id-type="pmid">18334535</pub-id></element-citation></ref><ref id="bib88"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Lempel</surname><given-names>A</given-names></name><name><surname>Ziv</surname><given-names>J</given-names></name></person-group><year iso-8601-date="1976">1976</year><article-title>On the complexity of finite sequences</article-title><source>IEEE Transactions on Information Theory</source><volume>22</volume><fpage>75</fpage><lpage>81</lpage><pub-id pub-id-type="doi">10.1109/TIT.1976.1055501</pub-id></element-citation></ref><ref id="bib89"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Li</surname><given-names>M</given-names></name><name><surname>Vitányi</surname><given-names>P</given-names></name></person-group><year iso-8601-date="1993">1993</year><source>In An Introduction to Kolmogorov Complexity and Its Applications</source><publisher-name>Springer</publisher-name><pub-id pub-id-type="doi">10.1007/978-1-4757-3860-5</pub-id></element-citation></ref><ref id="bib90"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ma</surname><given-names>WJ</given-names></name><name><surname>Husain</surname><given-names>M</given-names></name><name><surname>Bays</surname><given-names>PM</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>Changing concepts of working memory</article-title><source>Nature Neuroscience</source><volume>17</volume><fpage>347</fpage><lpage>356</lpage><pub-id pub-id-type="doi">10.1038/nn.3655</pub-id><pub-id pub-id-type="pmid">24569831</pub-id></element-citation></ref><ref id="bib91"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Maess</surname><given-names>B</given-names></name><name><surname>Koelsch</surname><given-names>S</given-names></name><name><surname>Gunter</surname><given-names>TC</given-names></name><name><surname>Friederici</surname><given-names>AD</given-names></name></person-group><year iso-8601-date="2001">2001</year><article-title>Musical syntax is processed in Broca’s area: an MEG study</article-title><source>Nature Neuroscience</source><volume>4</volume><fpage>540</fpage><lpage>545</lpage><pub-id pub-id-type="doi">10.1038/87502</pub-id><pub-id pub-id-type="pmid">11319564</pub-id></element-citation></ref><ref id="bib92"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Maheu</surname><given-names>M</given-names></name><name><surname>Dehaene</surname><given-names>S</given-names></name><name><surname>Meyniel</surname><given-names>F</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>Brain signatures of a multiscale process of sequence learning in humans</article-title><source>eLife</source><volume>8</volume><elocation-id>e41541</elocation-id><pub-id pub-id-type="doi">10.7554/eLife.41541</pub-id><pub-id pub-id-type="pmid">30714904</pub-id></element-citation></ref><ref id="bib93"><element-citation publication-type="preprint"><person-group person-group-type="author"><name><surname>Maheu</surname><given-names>M</given-names></name><name><surname>Meyniel</surname><given-names>F</given-names></name><name><surname>Dehaene</surname><given-names>S</given-names></name></person-group><year iso-8601-date="2021">2021</year><article-title>Rational Arbitration between Statistics and Rules in Human Sequence Processing</article-title><source>bioRxiv</source><pub-id pub-id-type="doi">10.1101/2020.02.06.937706</pub-id></element-citation></ref><ref id="bib94"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Mathy</surname><given-names>F</given-names></name><name><surname>Feldman</surname><given-names>J</given-names></name></person-group><year iso-8601-date="2012">2012</year><article-title>What’s magic about magic numbers? Chunking and data compression in short-term memory</article-title><source>Cognition</source><volume>122</volume><fpage>346</fpage><lpage>362</lpage><pub-id pub-id-type="doi">10.1016/j.cognition.2011.11.003</pub-id><pub-id pub-id-type="pmid">22176752</pub-id></element-citation></ref><ref id="bib95"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>May</surname><given-names>PJC</given-names></name><name><surname>Tiitinen</surname><given-names>H</given-names></name></person-group><year iso-8601-date="2010">2010</year><article-title>Mismatch negativity (MMN), the deviance-elicited auditory deflection, explained</article-title><source>Psychophysiology</source><volume>47</volume><fpage>66</fpage><lpage>122</lpage><pub-id pub-id-type="doi">10.1111/j.1469-8986.2009.00856.x</pub-id><pub-id pub-id-type="pmid">19686538</pub-id></element-citation></ref><ref id="bib96"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Mazoyer</surname><given-names>B</given-names></name><name><surname>Zago</surname><given-names>L</given-names></name><name><surname>Mellet</surname><given-names>E</given-names></name><name><surname>Bricogne</surname><given-names>S</given-names></name><name><surname>Etard</surname><given-names>O</given-names></name><name><surname>Houdé</surname><given-names>O</given-names></name><name><surname>Crivello</surname><given-names>F</given-names></name><name><surname>Joliot</surname><given-names>M</given-names></name><name><surname>Petit</surname><given-names>L</given-names></name><name><surname>Tzourio-Mazoyer</surname><given-names>N</given-names></name></person-group><year iso-8601-date="2001">2001</year><article-title>Cortical networks for working memory and executive functions sustain the conscious resting state in man</article-title><source>Brain Research Bulletin</source><volume>54</volume><fpage>287</fpage><lpage>298</lpage><pub-id pub-id-type="doi">10.1016/s0361-9230(00)00437-8</pub-id><pub-id pub-id-type="pmid">11287133</pub-id></element-citation></ref><ref id="bib97"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>McDermott</surname><given-names>JH</given-names></name><name><surname>Schemitsch</surname><given-names>M</given-names></name><name><surname>Simoncelli</surname><given-names>EP</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>Summary statistics in auditory perception</article-title><source>Nature Neuroscience</source><volume>16</volume><fpage>493</fpage><lpage>498</lpage><pub-id pub-id-type="doi">10.1038/nn.3347</pub-id><pub-id pub-id-type="pmid">23434915</pub-id></element-citation></ref><ref id="bib98"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Meyer</surname><given-names>T</given-names></name><name><surname>Olson</surname><given-names>CR</given-names></name></person-group><year iso-8601-date="2011">2011</year><article-title>Statistical learning of visual transitions in monkey inferotemporal cortex</article-title><source>PNAS</source><volume>108</volume><fpage>19401</fpage><lpage>19406</lpage><pub-id pub-id-type="doi">10.1073/pnas.1112895108</pub-id><pub-id pub-id-type="pmid">22084090</pub-id></element-citation></ref><ref id="bib99"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Meyniel</surname><given-names>F</given-names></name><name><surname>Maheu</surname><given-names>M</given-names></name><name><surname>Dehaene</surname><given-names>S</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Human inferences about sequences: a minimal transition probability model</article-title><source>PLOS Computational Biology</source><volume>12</volume><elocation-id>e1005260</elocation-id><pub-id pub-id-type="doi">10.1371/journal.pcbi.1005260</pub-id><pub-id pub-id-type="pmid">28030543</pub-id></element-citation></ref><ref id="bib100"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Miller</surname><given-names>GA</given-names></name></person-group><year iso-8601-date="1956">1956</year><article-title>The magical number seven plus or minus two: some limits on our capacity for processing information</article-title><source>Psychological Review</source><volume>63</volume><fpage>81</fpage><lpage>97</lpage><pub-id pub-id-type="pmid">13310704</pub-id></element-citation></ref><ref id="bib101"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Molinari</surname><given-names>M</given-names></name><name><surname>Chiricozzi</surname><given-names>FR</given-names></name><name><surname>Clausi</surname><given-names>S</given-names></name><name><surname>Tedesco</surname><given-names>AM</given-names></name><name><surname>De Lisa</surname><given-names>M</given-names></name><name><surname>Leggio</surname><given-names>MG</given-names></name></person-group><year iso-8601-date="2008">2008</year><article-title>Cerebellum and detection of sequences, from perception to cognition</article-title><source>Cerebellum</source><volume>7</volume><fpage>611</fpage><lpage>615</lpage><pub-id pub-id-type="doi">10.1007/s12311-008-0060-x</pub-id><pub-id pub-id-type="pmid">18941861</pub-id></element-citation></ref><ref id="bib102"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Morillon</surname><given-names>B</given-names></name><name><surname>Baillet</surname><given-names>S</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>Motor origin of temporal predictions in auditory attention</article-title><source>PNAS</source><volume>114</volume><fpage>E8913</fpage><lpage>E8921</lpage><pub-id pub-id-type="doi">10.1073/pnas.1705373114</pub-id><pub-id pub-id-type="pmid">28973923</pub-id></element-citation></ref><ref id="bib103"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Moro</surname><given-names>A</given-names></name></person-group><year iso-8601-date="1997">1997</year><article-title>Dynamic antisymmetry: movement as a symmetry-breaking phenomenon</article-title><source>Studia Linguistica</source><volume>51</volume><fpage>50</fpage><lpage>76</lpage><pub-id pub-id-type="doi">10.1111/1467-9582.00017</pub-id></element-citation></ref><ref id="bib104"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Musso</surname><given-names>M</given-names></name><name><surname>Moro</surname><given-names>A</given-names></name><name><surname>Glauche</surname><given-names>V</given-names></name><name><surname>Rijntjes</surname><given-names>M</given-names></name><name><surname>Reichenbach</surname><given-names>J</given-names></name><name><surname>Büchel</surname><given-names>C</given-names></name><name><surname>Weiller</surname><given-names>C</given-names></name></person-group><year iso-8601-date="2003">2003</year><article-title>Broca’s area and the language instinct</article-title><source>Nature Neuroscience</source><volume>6</volume><fpage>774</fpage><lpage>781</lpage><pub-id pub-id-type="doi">10.1038/nn1077</pub-id><pub-id pub-id-type="pmid">12819784</pub-id></element-citation></ref><ref id="bib105"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Näätänen</surname><given-names>R</given-names></name><name><surname>Paavilainen</surname><given-names>P</given-names></name><name><surname>Alho</surname><given-names>K</given-names></name><name><surname>Reinikainen</surname><given-names>K</given-names></name><name><surname>Sams</surname><given-names>M</given-names></name></person-group><year iso-8601-date="1989">1989</year><article-title>Do event-related potentials reveal the mechanism of the auditory sensory memory in the human brain?</article-title><source>Neuroscience Letters</source><volume>98</volume><fpage>217</fpage><lpage>221</lpage><pub-id pub-id-type="doi">10.1016/0304-3940(89)90513-2</pub-id><pub-id pub-id-type="pmid">2710416</pub-id></element-citation></ref><ref id="bib106"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Nachev</surname><given-names>P</given-names></name><name><surname>Kennard</surname><given-names>C</given-names></name><name><surname>Husain</surname><given-names>M</given-names></name></person-group><year iso-8601-date="2008">2008</year><article-title>Functional role of the supplementary and pre-supplementary motor areas</article-title><source>Nature Reviews. Neuroscience</source><volume>9</volume><fpage>856</fpage><lpage>869</lpage><pub-id pub-id-type="doi">10.1038/nrn2478</pub-id><pub-id pub-id-type="pmid">18843271</pub-id></element-citation></ref><ref id="bib107"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Nixon</surname><given-names>PD</given-names></name></person-group><year iso-8601-date="2003">2003</year><article-title>The role of the cerebellum in preparing responses to predictable sensory events</article-title><source>Cerebellum</source><volume>2</volume><fpage>114</fpage><lpage>122</lpage><pub-id pub-id-type="doi">10.1080/14734220309410</pub-id><pub-id pub-id-type="pmid">12880179</pub-id></element-citation></ref><ref id="bib108"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Norman-Haignere</surname><given-names>S</given-names></name><name><surname>Kanwisher</surname><given-names>NG</given-names></name><name><surname>McDermott</surname><given-names>JH</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>Distinct cortical pathways for music and speech revealed by hypothesis-free voxel decomposition</article-title><source>Neuron</source><volume>88</volume><fpage>1281</fpage><lpage>1296</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2015.11.035</pub-id><pub-id pub-id-type="pmid">26687225</pub-id></element-citation></ref><ref id="bib109"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Pallier</surname><given-names>C</given-names></name><name><surname>Devauchelle</surname><given-names>AD</given-names></name><name><surname>Dehaene</surname><given-names>S</given-names></name></person-group><year iso-8601-date="2011">2011</year><article-title>Cortical representation of the constituent structure of sentences</article-title><source>PNAS</source><volume>108</volume><fpage>2522</fpage><lpage>2527</lpage><pub-id pub-id-type="doi">10.1073/pnas.1018711108</pub-id><pub-id pub-id-type="pmid">21224415</pub-id></element-citation></ref><ref id="bib110"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Patel</surname><given-names>AD</given-names></name></person-group><year iso-8601-date="2003">2003</year><article-title>Language, music, syntax and the brain</article-title><source>Nature Neuroscience</source><volume>6</volume><fpage>674</fpage><lpage>681</lpage><pub-id pub-id-type="doi">10.1038/nn1082</pub-id><pub-id pub-id-type="pmid">12830158</pub-id></element-citation></ref><ref id="bib111"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Pedregosa</surname><given-names>F</given-names></name><name><surname>Varoquaux</surname><given-names>G</given-names></name><name><surname>Gramfort</surname><given-names>A</given-names></name><name><surname>Michel</surname><given-names>V</given-names></name><name><surname>Thirion</surname><given-names>B</given-names></name><name><surname>Grisel</surname><given-names>O</given-names></name><name><surname>Blondel</surname><given-names>M</given-names></name><name><surname>Prettenhofer</surname><given-names>P</given-names></name><name><surname>Weiss</surname><given-names>R</given-names></name><name><surname>Dubourg</surname><given-names>V</given-names></name><name><surname>Vanderplas</surname><given-names>J</given-names></name><name><surname>Passos</surname><given-names>A</given-names></name><name><surname>Cournapeau</surname><given-names>D</given-names></name><name><surname>Brucher</surname><given-names>M</given-names></name><name><surname>Perrot</surname><given-names>M</given-names></name><name><surname>Duchesnay</surname><given-names>É</given-names></name></person-group><year iso-8601-date="2011">2011</year><article-title>Scikit-learn: machine learning in python</article-title><source>Journal of Machine Learning Research</source><volume>12</volume><fpage>2825</fpage><lpage>2830</lpage></element-citation></ref><ref id="bib112"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Peretz</surname><given-names>I</given-names></name><name><surname>Vuvan</surname><given-names>D</given-names></name><name><surname>Lagrois</surname><given-names>MÉ</given-names></name><name><surname>Armony</surname><given-names>JL</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>Neural overlap in processing music and speech</article-title><source>Philosophical Transactions of the Royal Society of London. Series B, Biological Sciences</source><volume>370</volume><elocation-id>20140090</elocation-id><pub-id pub-id-type="doi">10.1098/rstb.2014.0090</pub-id><pub-id pub-id-type="pmid">25646513</pub-id></element-citation></ref><ref id="bib113"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Pinel</surname><given-names>P</given-names></name><name><surname>Thirion</surname><given-names>B</given-names></name><name><surname>Meriaux</surname><given-names>S</given-names></name><name><surname>Jobert</surname><given-names>A</given-names></name><name><surname>Serres</surname><given-names>J</given-names></name><name><surname>Le Bihan</surname><given-names>D</given-names></name><name><surname>Poline</surname><given-names>JB</given-names></name><name><surname>Dehaene</surname><given-names>S</given-names></name></person-group><year iso-8601-date="2007">2007</year><article-title>Fast reproducible identification and large-scale databasing of individual functional cognitive networks</article-title><source>BMC Neuroscience</source><volume>8</volume><elocation-id>91</elocation-id><pub-id pub-id-type="doi">10.1186/1471-2202-8-91</pub-id><pub-id pub-id-type="pmid">17973998</pub-id></element-citation></ref><ref id="bib114"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Planton</surname><given-names>S</given-names></name><name><surname>Dehaene</surname><given-names>S</given-names></name></person-group><year iso-8601-date="2021">2021</year><article-title>Cerebral representation of sequence patterns across multiple presentation formats</article-title><source>Cortex; a Journal Devoted to the Study of the Nervous System and Behavior</source><volume>145</volume><fpage>13</fpage><lpage>36</lpage><pub-id pub-id-type="doi">10.1016/j.cortex.2021.09.003</pub-id><pub-id pub-id-type="pmid">34673292</pub-id></element-citation></ref><ref id="bib115"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Planton</surname><given-names>S</given-names></name><name><surname>van Kerkoerle</surname><given-names>T</given-names></name><name><surname>Abbih</surname><given-names>L</given-names></name><name><surname>Maheu</surname><given-names>M</given-names></name><name><surname>Meyniel</surname><given-names>F</given-names></name><name><surname>Sigman</surname><given-names>M</given-names></name><name><surname>Wang</surname><given-names>L</given-names></name><name><surname>Figueira</surname><given-names>S</given-names></name><name><surname>Romano</surname><given-names>S</given-names></name><name><surname>Dehaene</surname><given-names>S</given-names></name></person-group><year iso-8601-date="2021">2021</year><article-title>A theory of memory for binary sequences: evidence for a mental compression algorithm in humans</article-title><source>PLOS Computational Biology</source><volume>17</volume><elocation-id>e1008598</elocation-id><pub-id pub-id-type="doi">10.1371/journal.pcbi.1008598</pub-id><pub-id pub-id-type="pmid">33465081</pub-id></element-citation></ref><ref id="bib116"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Power</surname><given-names>JD</given-names></name><name><surname>Barnes</surname><given-names>KA</given-names></name><name><surname>Snyder</surname><given-names>AZ</given-names></name><name><surname>Schlaggar</surname><given-names>BL</given-names></name><name><surname>Petersen</surname><given-names>SE</given-names></name></person-group><year iso-8601-date="2012">2012</year><article-title>Spurious but systematic correlations in functional connectivity MRI networks arise from subject motion</article-title><source>NeuroImage</source><volume>59</volume><fpage>2142</fpage><lpage>2154</lpage><pub-id pub-id-type="doi">10.1016/j.neuroimage.2011.10.018</pub-id><pub-id pub-id-type="pmid">22019881</pub-id></element-citation></ref><ref id="bib117"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Psotka</surname><given-names>J</given-names></name></person-group><year iso-8601-date="1975">1975</year><article-title>Simplicity, symmetry, and syntely: stimulus measures of binary pattern structure</article-title><source>Memory &amp; Cognition</source><volume>3</volume><fpage>434</fpage><lpage>444</lpage><pub-id pub-id-type="doi">10.3758/BF03212938</pub-id><pub-id pub-id-type="pmid">21287100</pub-id></element-citation></ref><ref id="bib118"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Raichle</surname><given-names>ME</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>The brain’s default mode network</article-title><source>Annual Review of Neuroscience</source><volume>38</volume><fpage>433</fpage><lpage>447</lpage><pub-id pub-id-type="doi">10.1146/annurev-neuro-071013-014030</pub-id><pub-id pub-id-type="pmid">25938726</pub-id></element-citation></ref><ref id="bib119"><element-citation publication-type="software"><person-group person-group-type="author"><collab>R Development Core Team</collab></person-group><year iso-8601-date="2020">2020</year><data-title>R: A language and environment for statistical computing</data-title><publisher-loc>Vienna, Austria</publisher-loc><publisher-name>R Foundation for Statistical Computing</publisher-name><ext-link ext-link-type="uri" xlink:href="https://www.r-project.org/">https://www.r-project.org/</ext-link></element-citation></ref><ref id="bib120"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Restle</surname><given-names>F</given-names></name></person-group><year iso-8601-date="1970">1970</year><article-title>Theory of serial pattern learning: structural trees</article-title><source>Psychological Review</source><volume>77</volume><fpage>481</fpage><lpage>495</lpage><pub-id pub-id-type="doi">10.1037/h0029964</pub-id></element-citation></ref><ref id="bib121"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Restle</surname><given-names>F</given-names></name><name><surname>Brown</surname><given-names>ER</given-names></name></person-group><year iso-8601-date="1970">1970</year><article-title>Serial pattern learning: pretraining of runs and trills</article-title><source>Psychonomic Science</source><volume>19</volume><fpage>321</fpage><lpage>322</lpage><pub-id pub-id-type="doi">10.3758/BF03328838</pub-id></element-citation></ref><ref id="bib122"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Sablé-Meyer</surname><given-names>M</given-names></name><name><surname>Ellis</surname><given-names>K</given-names></name><name><surname>Tenenbaum</surname><given-names>J</given-names></name><name><surname>Dehaene</surname><given-names>S</given-names></name></person-group><year iso-8601-date="2022">2022</year><article-title>A language of thought for the mental representation of geometric shapes</article-title><source>Cognitive Psychology</source><volume>139</volume><elocation-id>101527</elocation-id><pub-id pub-id-type="doi">10.1016/j.cogpsych.2022.101527</pub-id><pub-id pub-id-type="pmid">36403385</pub-id></element-citation></ref><ref id="bib123"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Saffran</surname><given-names>JR</given-names></name><name><surname>Aslin</surname><given-names>RN</given-names></name><name><surname>Newport</surname><given-names>EL</given-names></name></person-group><year iso-8601-date="1996">1996</year><article-title>Statistical learning by 8-month-old infants</article-title><source>Science</source><volume>274</volume><fpage>1926</fpage><lpage>1928</lpage><pub-id pub-id-type="doi">10.1126/science.274.5294.1926</pub-id><pub-id pub-id-type="pmid">8943209</pub-id></element-citation></ref><ref id="bib124"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Sakai</surname><given-names>K</given-names></name><name><surname>Kitaguchi</surname><given-names>K</given-names></name><name><surname>Hikosaka</surname><given-names>O</given-names></name></person-group><year iso-8601-date="2003">2003</year><article-title>Chunking during human visuomotor sequence learning</article-title><source>Experimental Brain Research</source><volume>152</volume><fpage>229</fpage><lpage>242</lpage><pub-id pub-id-type="doi">10.1007/s00221-003-1548-8</pub-id><pub-id pub-id-type="pmid">12879170</pub-id></element-citation></ref><ref id="bib125"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Santolin</surname><given-names>C</given-names></name><name><surname>Saffran</surname><given-names>JR</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>Constraints on statistical learning across species</article-title><source>Trends in Cognitive Sciences</source><volume>22</volume><fpage>52</fpage><lpage>63</lpage><pub-id pub-id-type="doi">10.1016/j.tics.2017.10.003</pub-id><pub-id pub-id-type="pmid">29150414</pub-id></element-citation></ref><ref id="bib126"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Schapiro</surname><given-names>AC</given-names></name><name><surname>Rogers</surname><given-names>TT</given-names></name><name><surname>Cordova</surname><given-names>NI</given-names></name><name><surname>Turk-Browne</surname><given-names>NB</given-names></name><name><surname>Botvinick</surname><given-names>MM</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>Neural representations of events arise from temporal community structure</article-title><source>Nature Neuroscience</source><volume>16</volume><fpage>486</fpage><lpage>492</lpage><pub-id pub-id-type="doi">10.1038/nn.3331</pub-id><pub-id pub-id-type="pmid">23416451</pub-id></element-citation></ref><ref id="bib127"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Schröger</surname><given-names>E</given-names></name><name><surname>Bendixen</surname><given-names>A</given-names></name><name><surname>Trujillo-Barreto</surname><given-names>NJ</given-names></name><name><surname>Roeber</surname><given-names>U</given-names></name><name><surname>He</surname><given-names>S</given-names></name></person-group><year iso-8601-date="2007">2007</year><article-title>Processing of abstract rule violations in audition</article-title><source>PLOS ONE</source><volume>2</volume><elocation-id>e1131</elocation-id><pub-id pub-id-type="doi">10.1371/journal.pone.0001131</pub-id><pub-id pub-id-type="pmid">17987118</pub-id></element-citation></ref><ref id="bib128"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Shima</surname><given-names>K</given-names></name><name><surname>Isoda</surname><given-names>M</given-names></name><name><surname>Mushiake</surname><given-names>H</given-names></name><name><surname>Tanji</surname><given-names>J</given-names></name></person-group><year iso-8601-date="2007">2007</year><article-title>Categorization of behavioural sequences in the prefrontal cortex</article-title><source>Nature</source><volume>445</volume><fpage>315</fpage><lpage>318</lpage><pub-id pub-id-type="doi">10.1038/nature05470</pub-id><pub-id pub-id-type="pmid">17183266</pub-id></element-citation></ref><ref id="bib129"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Simon</surname><given-names>HA</given-names></name><name><surname>Kotovsky</surname><given-names>K</given-names></name></person-group><year iso-8601-date="1963">1963</year><article-title>Human acquisition of concepts for sequential patterns</article-title><source>Psychological Review</source><volume>70</volume><fpage>534</fpage><lpage>546</lpage><pub-id pub-id-type="doi">10.1037/h0043901</pub-id></element-citation></ref><ref id="bib130"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Simon</surname><given-names>HA</given-names></name></person-group><year iso-8601-date="1972">1972</year><article-title>Complexity and the representation of patterned sequences of symbols</article-title><source>Psychological Review</source><volume>79</volume><fpage>369</fpage><lpage>382</lpage><pub-id pub-id-type="doi">10.1037/h0033118</pub-id></element-citation></ref><ref id="bib131"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Southwell</surname><given-names>R</given-names></name><name><surname>Chait</surname><given-names>M</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>Enhanced deviant responses in patterned relative to random sound sequences</article-title><source>Cortex; a Journal Devoted to the Study of the Nervous System and Behavior</source><volume>109</volume><fpage>92</fpage><lpage>103</lpage><pub-id pub-id-type="doi">10.1016/j.cortex.2018.08.032</pub-id><pub-id pub-id-type="pmid">30312781</pub-id></element-citation></ref><ref id="bib132"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Summerfield</surname><given-names>C</given-names></name><name><surname>de Lange</surname><given-names>FP</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>Expectation in perceptual decision making: neural and computational mechanisms</article-title><source>Nature Reviews. Neuroscience</source><volume>15</volume><fpage>745</fpage><lpage>756</lpage><pub-id pub-id-type="doi">10.1038/nrn3838</pub-id><pub-id pub-id-type="pmid">25315388</pub-id></element-citation></ref><ref id="bib133"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Summerfield</surname><given-names>C</given-names></name><name><surname>Luyckx</surname><given-names>F</given-names></name><name><surname>Sheahan</surname><given-names>H</given-names></name></person-group><year iso-8601-date="2020">2020</year><article-title>Structure learning and the posterior parietal cortex</article-title><source>Progress in Neurobiology</source><volume>184</volume><elocation-id>101717</elocation-id><pub-id pub-id-type="doi">10.1016/j.pneurobio.2019.101717</pub-id><pub-id pub-id-type="pmid">31669186</pub-id></element-citation></ref><ref id="bib134"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Taulu</surname><given-names>S</given-names></name><name><surname>Kajola</surname><given-names>M</given-names></name><name><surname>Simola</surname><given-names>J</given-names></name></person-group><year iso-8601-date="2004">2004</year><article-title>Suppression of interference and artifacts by the signal space separation method</article-title><source>Brain Topography</source><volume>16</volume><fpage>269</fpage><lpage>275</lpage><pub-id pub-id-type="doi">10.1023/b:brat.0000032864.93890.f9</pub-id><pub-id pub-id-type="pmid">15379226</pub-id></element-citation></ref><ref id="bib135"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Todorovic</surname><given-names>A</given-names></name><name><surname>van Ede</surname><given-names>F</given-names></name><name><surname>Maris</surname><given-names>E</given-names></name><name><surname>de Lange</surname><given-names>FP</given-names></name></person-group><year iso-8601-date="2011">2011</year><article-title>Prior expectation mediates neural adaptation to repeated sounds in the auditory cortex: an MEG study</article-title><source>The Journal of Neuroscience</source><volume>31</volume><fpage>9118</fpage><lpage>9123</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.1425-11.2011</pub-id><pub-id pub-id-type="pmid">21697363</pub-id></element-citation></ref><ref id="bib136"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Todorovic</surname><given-names>A</given-names></name><name><surname>de Lange</surname><given-names>FP</given-names></name></person-group><year iso-8601-date="2012">2012</year><article-title>Repetition suppression and expectation suppression are dissociable in time in early auditory evoked fields</article-title><source>The Journal of Neuroscience</source><volume>32</volume><fpage>13389</fpage><lpage>13395</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.2227-12.2012</pub-id><pub-id pub-id-type="pmid">23015429</pub-id></element-citation></ref><ref id="bib137"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Toni</surname><given-names>I</given-names></name><name><surname>Krams</surname><given-names>M</given-names></name><name><surname>Turner</surname><given-names>R</given-names></name><name><surname>Passingham</surname><given-names>RE</given-names></name></person-group><year iso-8601-date="1998">1998</year><article-title>The time course of changes during motor sequence learning: a whole-brain fMRI study</article-title><source>NeuroImage</source><volume>8</volume><fpage>50</fpage><lpage>61</lpage><pub-id pub-id-type="doi">10.1006/nimg.1998.0349</pub-id><pub-id pub-id-type="pmid">9698575</pub-id></element-citation></ref><ref id="bib138"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Toro</surname><given-names>JM</given-names></name><name><surname>Trobalón</surname><given-names>JB</given-names></name></person-group><year iso-8601-date="2005">2005</year><article-title>Statistical computations over a speech stream in a rodent</article-title><source>Perception &amp; Psychophysics</source><volume>67</volume><fpage>867</fpage><lpage>875</lpage><pub-id pub-id-type="doi">10.3758/bf03193539</pub-id><pub-id pub-id-type="pmid">16334058</pub-id></element-citation></ref><ref id="bib139"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Uhrig</surname><given-names>L</given-names></name><name><surname>Dehaene</surname><given-names>S</given-names></name><name><surname>Jarraya</surname><given-names>B</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>A hierarchy of responses to auditory regularities in the macaque brain</article-title><source>The Journal of Neuroscience</source><volume>34</volume><fpage>1127</fpage><lpage>1132</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.3165-13.2014</pub-id><pub-id pub-id-type="pmid">24453305</pub-id></element-citation></ref><ref id="bib140"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>van Heijningen</surname><given-names>CAA</given-names></name><name><surname>de Visser</surname><given-names>J</given-names></name><name><surname>Zuidema</surname><given-names>W</given-names></name><name><surname>ten Cate</surname><given-names>C</given-names></name></person-group><year iso-8601-date="2009">2009</year><article-title>Simple rules can explain discrimination of putative recursive syntactic structures by a songbird species</article-title><source>PNAS</source><volume>106</volume><fpage>20538</fpage><lpage>20543</lpage><pub-id pub-id-type="doi">10.1073/pnas.0908113106</pub-id><pub-id pub-id-type="pmid">19918074</pub-id></element-citation></ref><ref id="bib141"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Vitz</surname><given-names>PC</given-names></name><name><surname>Todd</surname><given-names>TC</given-names></name></person-group><year iso-8601-date="1969">1969</year><article-title>A coded element model of the perceptual processing of sequential stimuli</article-title><source>Psychological Review</source><volume>76</volume><fpage>433</fpage><lpage>449</lpage><pub-id pub-id-type="doi">10.1037/h0028113</pub-id></element-citation></ref><ref id="bib142"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Vogel</surname><given-names>EK</given-names></name><name><surname>Machizawa</surname><given-names>MG</given-names></name></person-group><year iso-8601-date="2004">2004</year><article-title>Neural activity predicts individual differences in visual working memory capacity</article-title><source>Nature</source><volume>428</volume><fpage>748</fpage><lpage>751</lpage><pub-id pub-id-type="doi">10.1038/nature02447</pub-id><pub-id pub-id-type="pmid">15085132</pub-id></element-citation></ref><ref id="bib143"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Vul</surname><given-names>E</given-names></name><name><surname>Harris</surname><given-names>C</given-names></name><name><surname>Winkielman</surname><given-names>P</given-names></name><name><surname>Pashler</surname><given-names>H</given-names></name></person-group><year iso-8601-date="2009">2009</year><article-title>Puzzlingly high correlations in fmri studies of emotion, personality, and social cognition</article-title><source>Perspectives on Psychological Science</source><volume>4</volume><fpage>274</fpage><lpage>290</lpage><pub-id pub-id-type="doi">10.1111/j.1745-6924.2009.01125.x</pub-id></element-citation></ref><ref id="bib144"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wacongne</surname><given-names>C</given-names></name><name><surname>Labyt</surname><given-names>E</given-names></name><name><surname>van Wassenhove</surname><given-names>V</given-names></name><name><surname>Bekinschtein</surname><given-names>T</given-names></name><name><surname>Naccache</surname><given-names>L</given-names></name><name><surname>Dehaene</surname><given-names>S</given-names></name></person-group><year iso-8601-date="2011">2011</year><article-title>Evidence for a hierarchy of predictions and prediction errors in human cortex</article-title><source>PNAS</source><volume>108</volume><fpage>20754</fpage><lpage>20759</lpage><pub-id pub-id-type="doi">10.1073/pnas.1117807108</pub-id><pub-id pub-id-type="pmid">22147913</pub-id></element-citation></ref><ref id="bib145"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wacongne</surname><given-names>C</given-names></name><name><surname>Changeux</surname><given-names>JP</given-names></name><name><surname>Dehaene</surname><given-names>S</given-names></name></person-group><year iso-8601-date="2012">2012</year><article-title>A neuronal model of predictive coding accounting for the mismatch negativity</article-title><source>The Journal of Neuroscience</source><volume>32</volume><fpage>3665</fpage><lpage>3678</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.5003-11.2012</pub-id><pub-id pub-id-type="pmid">22423089</pub-id></element-citation></ref><ref id="bib146"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wang</surname><given-names>L</given-names></name><name><surname>Uhrig</surname><given-names>L</given-names></name><name><surname>Jarraya</surname><given-names>B</given-names></name><name><surname>Dehaene</surname><given-names>S</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>Representation of numerical and sequential patterns in macaque and human brains</article-title><source>Current Biology</source><volume>25</volume><fpage>1966</fpage><lpage>1974</lpage><pub-id pub-id-type="doi">10.1016/j.cub.2015.06.035</pub-id><pub-id pub-id-type="pmid">26212883</pub-id></element-citation></ref><ref id="bib147"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wang</surname><given-names>L</given-names></name><name><surname>Amalric</surname><given-names>M</given-names></name><name><surname>Fang</surname><given-names>W</given-names></name><name><surname>Jiang</surname><given-names>X</given-names></name><name><surname>Pallier</surname><given-names>C</given-names></name><name><surname>Figueira</surname><given-names>S</given-names></name><name><surname>Sigman</surname><given-names>M</given-names></name><name><surname>Dehaene</surname><given-names>S</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>Representation of spatial sequences using nested rules in human prefrontal cortex</article-title><source>NeuroImage</source><volume>186</volume><fpage>245</fpage><lpage>255</lpage><pub-id pub-id-type="doi">10.1016/j.neuroimage.2018.10.061</pub-id><pub-id pub-id-type="pmid">30449729</pub-id></element-citation></ref><ref id="bib148"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wilson</surname><given-names>B</given-names></name><name><surname>Slater</surname><given-names>H</given-names></name><name><surname>Kikuchi</surname><given-names>Y</given-names></name><name><surname>Milne</surname><given-names>AE</given-names></name><name><surname>Marslen-Wilson</surname><given-names>WD</given-names></name><name><surname>Smith</surname><given-names>K</given-names></name><name><surname>Petkov</surname><given-names>CI</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>Auditory artificial grammar learning in macaque and marmoset monkeys</article-title><source>The Journal of Neuroscience</source><volume>33</volume><fpage>18825</fpage><lpage>18835</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.2414-13.2013</pub-id><pub-id pub-id-type="pmid">24285889</pub-id></element-citation></ref><ref id="bib149"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wilson</surname><given-names>B</given-names></name><name><surname>Marslen-Wilson</surname><given-names>WD</given-names></name><name><surname>Petkov</surname><given-names>CI</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>Conserved sequence processing in primate frontal cortex</article-title><source>Trends in Neurosciences</source><volume>40</volume><fpage>72</fpage><lpage>82</lpage><pub-id pub-id-type="doi">10.1016/j.tins.2016.11.004</pub-id><pub-id pub-id-type="pmid">28063612</pub-id></element-citation></ref></ref-list></back><sub-article article-type="editor-report" id="sa0"><front-stub><article-id pub-id-type="doi">10.7554/eLife.84376.sa0</article-id><title-group><article-title>Editor's evaluation</article-title></title-group><contrib-group><contrib contrib-type="author"><name><surname>Obleser</surname><given-names>Jonas</given-names></name><role specific-use="editor">Reviewing Editor</role><aff><institution-wrap><institution-id institution-id-type="ror">https://ror.org/00t3r8h32</institution-id><institution>University of Lübeck</institution></institution-wrap><country>Germany</country></aff></contrib></contrib-group><related-object id="sa0ro1" object-id-type="id" object-id="10.1101/2022.10.15.512361" link-type="continued-by" xlink:href="https://sciety.org/articles/activity/10.1101/2022.10.15.512361"/></front-stub><body><p>This article brings to bear an important set of behavioral methods and neural data reporting that activity in numerous cortical regions robustly covaries with the complexity of tone sequences encoded in memory. The study provides convincing evidence that humans store these sequences based on representations related to the so-called language of thought.</p></body></sub-article><sub-article article-type="decision-letter" id="sa1"><front-stub><article-id pub-id-type="doi">10.7554/eLife.84376.sa1</article-id><title-group><article-title>Decision letter</article-title></title-group><contrib-group content-type="section"><contrib contrib-type="editor"><name><surname>Obleser</surname><given-names>Jonas</given-names></name><role>Reviewing Editor</role><aff><institution-wrap><institution-id institution-id-type="ror">https://ror.org/00t3r8h32</institution-id><institution>University of Lübeck</institution></institution-wrap><country>Germany</country></aff></contrib></contrib-group><contrib-group><contrib contrib-type="reviewer"><name><surname>Christophel</surname><given-names>Thomas B</given-names></name><role>Reviewer</role><aff><institution>Distributed Cognition and Memory Group</institution><country>Germany</country></aff></contrib></contrib-group></front-stub><body><boxed-text id="sa2-box1"><p>Our editorial process produces two outputs: (i) <ext-link ext-link-type="uri" xlink:href="https://sciety.org/articles/activity/10.1101/2022.10.15.512361">public reviews</ext-link> designed to be posted alongside <ext-link ext-link-type="uri" xlink:href="https://www.biorxiv.org/content/10.1101/2022.10.15.512361v1">the preprint</ext-link> for the benefit of readers; (ii) feedback on the manuscript for the authors, including requests for revisions, shown below. We also include an acceptance summary that explains what the editors found interesting or important about the work.</p></boxed-text><p><bold>Decision letter after peer review:</bold></p><p>Thank you for submitting your article &quot;Compression of binary sound sequences in human working memory&quot; for consideration by <italic>eLife</italic>. Your article has been reviewed by 2 peer reviewers, and the evaluation has been overseen by a Reviewing Editor and Barbara Shinn-Cunningham as the Senior Editor.</p><p>The reviewers have discussed their reviews with one another, and the Reviewing Editor has drafted this to help you prepare a revised submission.</p><p>Essential revisions:</p><p>A revision should thoroughly address the many points raised by both reviewers, but let us editorially highlight especially the following requests/concerns:</p><p>– As outlined by Reviewer 1, a core issue of the manuscript in its present form is the missing formal description of the LoT model and alternatives, inconsistencies in the model comparisons, and no clear argumentation that would allow the reader to understand the selection of the alternative model. Similar to a recent paper by similar authors (Planton et al., 2021 PLOS Computational Biology), an explicit model comparison analysis would allow a much stronger conclusion. Also, these analyses would provide a more extensive evidence base for the favored LoT model.</p><p>– We deem it desirable, if not required, to make the analysis pipeline and the raw data publicly available to investigate the pipeline in detail and reproduce the results (provided hyperlinks are not functional).</p><p>– As outlined by Reviewer 2, it is unclear whether the authors have successfully &quot;characterize[d] the mental representation that humans utilize to encode binary sequences of sounds in working memory and detect occasional deviants&quot; as they set out to do. While it is possible that the regions found &quot;constitute the minimal network needed to track sequences&quot; we find the evidence insufficient to assert this.</p><p>Further analyses might be needed to elucidate the temporal evolution of the neural signals over its repeated presentation over habituation and test, as well as the experiment overall. Further research might be needed to study persistent activity while minimizing influences from perceptual processing and could even distinguish the representation of individual sequences from each other using pattern analysis.</p><p>– Please reconsider the terminology used to describe the proposed model, as argued convincingly and exemplified by Reviewer 2.</p><p><italic>Reviewer #1 (Recommendations for the authors):</italic></p><p>Weaknesses:</p><p>Inconsistencies in the analysis across datasets, for example, a direct comparison of the alternative model with the LoT on the behavioral data (but no figure for the alternative model effect), no analysis including the alternative model for the fMRI data, and providing the linear regression analysis for the MEG data that includes the predictor related to the alternative model only as a secondary analysis is unfortunate. It weakens the main conclusion of the manuscript. The manuscript could establish more robust conclusions when, for example, the or multiple alternative models would be treated equally (e.g., figures for the behavioral data). For the fMRI analysis, one could compare the models with an overlap analysis (similar to in Figure 4) and compare effect sizes from different regions. For the MEG data, one could focus on the analysis that considers both models, as one could expect that the model has a higher model fit and provide extensive descriptions for both effects.</p><p>Also, a critical case for the model is the 0-correlation of behavior and LoT for the Alternate condition. The authors choose not to include a correlation between behavior in the bracket task and the alternative account. Moreover, no critical discussion of this inconsistency is included.</p><p>Moreover, recent developments indicate selective implementation of representations depending on the complexity of the task (e.g., see Boominathan, L., and Pitkow, X. (2022). Phase transitions in when feedback is useful. Advances in Neural Information Processing Systems, 35, 10849-10861.) the investigation of an interaction of the complexity parameter and the transitional probabilities would be highly intriguing.</p><p>Further points:</p><p>It is highly recommended to make the analysis pipeline and the raw data publicly available to investigate the pipeline in detail and reproduce the results (provided hyperlinks are not functional).</p><p>Figure 1.: For a clear understanding for the reader, one could provide the tree structure for the experimental conditions reflecting the LoT complexity</p><p>Figure 2 Please present the p-value and the r in bold letters. The current presentation suggests higher importance for the statistics than the effect size estimate.</p><p>Results</p><p>195-199. As indicated before, the low correlation between bracketing behavior and the LoT model simulations is low. The following section is provided but unclear from reading the previous sections. Please provide more context here and elaborate in the discussion.</p><p>&quot;For the latter, a minor departure from the proposed encoding was found, as the shortest LoT representation (i.e. [+0]^16) can be paraphrased as &quot;16 alternations&quot;, while the participants' parses corresponded to &quot;8 AB pairs&quot;. The latter encoding, however, only has a marginally larger complexity, so this deviation should not affect subsequent results. &quot;</p><p>211-219: Be precise on the formulation of the linear mixed effect model. As the random effect structure can vary drastically, it is essential to present the complete form of the model, especially when reanalyzing it with and without the subject random effect. Also, no indication of the inclusion of random slopes or other random effects like stimuli is included.</p><p>220-230: Statistical learning as an alternative explanation. The critical test needs to be included. Has the stats learning or the LoT complexity predictor the higher model fit? Also, why not use a metric that penalizes for the number of predictors in the model (e.g., Akaike Information Criterion). Also, please provide the correlation of the two predictors from the models. A similarity estimation is essential to interpret the findings.</p><p>341-345: Why use a quadratic trend, and what is the benefit of making the statistical model more complex here? Please elaborate</p><p>364&quot; &quot;for loops&quot; postulated in our language&quot;; Please elaborate.</p><p>fMRI part:</p><p>Comparison analysis based on the alternative model (based on transitional probabilities) needs to be included. This analysis would allow us to investigate which regions contribute to the added behavioral explainability found in the behavioral analysis.</p><p>MEG part:</p><p>Unclear why the quadratic trend used for the fMRI analysis is not considered here. Please provide an argumentation.</p><p>Alternative model, based on transitional probabilities. Figure S4 provides the complexity effects based on a regression model, including the transitional probabilities measure. For clarity, please provide the corrected version in Figure 6 alongside the effect of the alternative model. Again model comparison or if both show considerable effects, one could investigate the interaction of complexity and transitional probabilities. Similarly, use both parameters or the interaction for the classifier data presented in Figure 7.</p><p>L 534: Please provide an argument here, why the leave-one-out was used here. Alternatively, one could use a 5-fold cross-validation that is more efficient to estimate and less problematic when it comes to overfitting. I expect this analysis was implemented because the analysis presented in Figure 7 is based only on the unseen dataset.</p><p>L 628 It is not clear what statistical test established cross decoding, as the cluster test provided cannot differentiate between time windows (see Sassenhagen, J., and Draschkow, D. (2019). Cluster‐based permutation tests of MEG/EEG data do not establish significance of effect latency or location. Psychophysiology, 56(6), e13335.).</p><p>L 763 &quot;fMRI, MEG and behavioral responses to deviants vary linearly with complexity, while model-related fMRI activations vary as an inverted U function of complexity&quot;. This result was not tested for, e.g., the MEG data. As described, no non-linear relationships have been investigated in the study.</p><p>Subjects:</p><p>Please justify the number of participants participating in the experiment using a Power analysis. If no a-priory analysis was implemented, provide a post hoc analysis. This is especially important because it was previously shown that low power could result in false positive inflation for fMRI data (e.g., Yarkoni, T. (2009). Big correlations in little studies: Inflated fMRI correlations reflect low statistical power-Commentary on Vul et al.(2009). Perspectives on psychological science, 4(3), 294-298.)</p><p>L 924-929: Please provide the threshold r used for the automatic detection. Also, explain why the number of components was fixed to 1 for cardio and 2 for eye-movement artifacts.</p><p><italic>Reviewer #2 (Recommendations for the authors):</italic></p><p>Before we share our evaluations and concerns, we would like to emphasize that our primary expertise is within working memory research using fMRI and behavioral methods. We hope that our comments will prove to be helpful to the authors.</p><p>Is this 'in human working memory'</p><p>It is almost impossible to design an experiment that fully precludes some use of working memory. This means that to argue that a process is selectively contained within working memory requires the experimenter to rule out influences of perceptual and long-term memory processes.</p><p>Behaviorally, this would mean designing a task where information has to be retained over time, and that discourages the use of long-term memory. Instead, the complexity of the stimuli used (which are likely to exceed working memory capacity) and the intense ongoing stimulation (operating in part as a distractor to working memory processing) seems to encourage the use of long-term memory. Consistently, subjects need to be 'habituated' to the to-be-memorized sequence about ten times, making an influence of early forms of long-term memory very likely.</p><p>More importantly, when a neural signal is to be attributed to working memory processing this typically requires some claim of delay period activity (i.e. some form of persistent activity). Here, there is little evidence of differential delay-period activity that is different for different task conditions. Instead, MEG data is most reliably affected by sequence complexity between 100 and 200 ms after the onset of an individual stimulus and complexity specific responses only extend beyond this when a violation of the sequence is detected. The fMRI data does little to alleviate this concern and evaluating this question is made harder by the fact that we could not directly link the time-resolved fMRI data time courses (Figure 3B) with the experimental timeline presented in the methods section.</p><p>Despite this, the authors seem to argue that the signals found are a kind of load-like signal that is indicative of the storage of the compressed sequences. For this, it is worth noting that whether load-signals are indicative of an underlying representation of memorized content is questionable (Emrich et al., 2013) and that we know of no instance where the load signals reverse like it does here in deviant trials. The authors, however, argue that the successful quadratic fits of the neural complexity signals are akin to ceiling-in-load effects found in the working memory literature (Vogel and Machizawa, 2004) where neural load-signals reach a ceiling for loads that exceed working memory capacity. This ceiling-in-load effect, however, relies on this tight link between neural and behavioral data evidence which is not presented. Furthermore, the 'quadratic' effect reported here seems to be expressed as data for both the most and least complex sequences diverging from the linear trend. This simply might indicate that the precise complexity of extremely simple and highly complex sequences is less precisely captured by the compression model.</p><p>In the introduction the authors, however, also highlight a potentially more specific interpretation of their signals. &quot;[…] the internal model of the sequence, as described by the postulated LoT, would be encoded by prefrontal regions of the brain, and would send anticipation signals to auditory areas, where they would be subtracted from incoming signals. As a consequence, we predict a reciprocal effect of LoT on the brain signals during habituation and during deviancy. In the habituation part of the experiment, lower amplitude response signals should be observed for sequences of low complexity – and conversely, during low complexity sequences, we expect top-down predictions to be stronger and therefore deviants to elicit larger responses, than for complex, hard to predict sequences.&quot; To us, this prediction-error-like interpretation seems to be more in line with the data presented. We believe that the time-courses presented in MEG closely match both early and late mismatch signals (mismatch activity and P300). The fMRI data is to the extent we can judge consistent with this interpretation, as is the apparent decline in complexity modulation from habituation to deviant free test trials and the inversion when deviance is detected. The authors argue, in this regard, that the complexity effect is not solely explained by a 'surprise' model. But at least some of the variance in question is explained by surprise. This leaves us to ask whether a better surprise or mismatch model could be found than the one used to capture the results fully (the current implementation of which should be fully explained in the methods). In the end, the more complex a sequence, the less predictable it is and the more surprising its individual elements are when initially presented.</p><p>Thus, it is unclear whether the authors have successfully &quot;characterize[d] the mental representation that humans utilize to encode binary sequences of sounds in working memory and detect occasional deviants&quot; as they set out to do. While it is possible that the regions found &quot;constitute the minimal network needed to track sequences&quot; we find the evidence insufficient to assert this.</p><p>Further analyses might help elucidate the temporal evolution of the neural signals over its repeated presentation over habituation and test, as well as the experiment overall. Further research might be needed to study persistent activity while minimizing influences from perceptual processing and could even distinguish the representation of individual sequences from each other using pattern analysis. Sequence complexity might be seen as a confound in such research as it leads to prediction-error-like or load-like response that can be independent of the representation of the individual sequence.</p><p>The essence of our concerns [has been covered above]. In short, we are convinced that the evidence speaks to a prediction-error-like signal that covaries with the complexity, and not a signal directly related to working memory retention. Our first major recommendation is therefore to put substantially more emphasis on this alternative interpretation of the results.</p><p>Arguing for a working memory-specific signal would – in our view – require directly establishing the presence of some form of persistent activity that is linked to the current results. Because of the rapid presentation of the sequences and the absence of a delay, we see no avenue to pursue this in the current fMRI data. Even for the EEG data, one would have to look at the brief time periods between individual habituations and see whether the recorded data carries information about the presented sequences. Even in this case, one would need to find a way to carefully distinguish these results from the prediction-area-like signals found so far. It is possible the authors intended to establish a connection to working memory in a way that we did not comprehend. In this case, this point requires clarification.</p><p>It would be of interest to further understand the role of long-term memory in this task. For this, it would be helpful to investigate how the complexity effect changes over the course of the experiment. Comparing the first and second (inverted) presentation of the sequence could establish whether the complexity effect is mediated by long-term memory.</p><p>Finally, we would suggest reconsidering the terminology used to describe the proposed model. On first read, we got distracted by questioning what the authors meant by 'language of thought' and how it related to the experimentation presented (e.g. &quot;The present results therefore support the hypothesis that the human brain hosts multiple internal languages&quot;). The terminology currently used implies a direct link to the subject's subjective experience of thought and while we all want to know how the words (and 'words') we 'think' come to be, we do not see how the data presented speak to that question, directly.</p></body></sub-article><sub-article article-type="reply" id="sa2"><front-stub><article-id pub-id-type="doi">10.7554/eLife.84376.sa2</article-id><title-group><article-title>Author response</article-title></title-group></front-stub><body><disp-quote content-type="editor-comment"><p>Essential revisions:</p><p>A revision should thoroughly address the many points raised by both reviewers, but let us editorially highlight especially the following requests/concerns:</p><p>– As outlined by Reviewer 1, a core issue of the manuscript in its present form is the missing formal description of the LoT model and alternatives, inconsistencies in the model comparisons, and no clear argumentation that would allow the reader to understand the selection of the alternative model. Similar to a recent paper by similar authors (Planton et al., 2021 PLOS Computational Biology), an explicit model comparison analysis would allow a much stronger conclusion. Also, these analyses would provide a more extensive evidence base for the favored LoT model.</p></disp-quote><p>We wish to thank Reviewer 1 for their request, which have led to a significant enrichment of the manuscript:</p><list list-type="bullet"><list-item><p>We added a formal description of the LoT in the subsection <italic>The Language of Thought for binary sequences</italic> in the <italic>Results section</italic>. We have added the formal LoT description of the selected sequences in Table S1 as well as their verbal description.</p></list-item><list-item><p>Furthermore, we performed a model comparison similar to the one done in (Planton et al., 2021 PLOS Computational Biology). This new analysis beautifully replicates our previous results, and provides more support for the proposed model. This analysis is now included in Figure 2 and in the <italic>Behavioral data</italic> subsection of the <italic>Results section</italic>.</p></list-item></list><disp-quote content-type="editor-comment"><p>– We deem it desirable, if not required, to make the analysis pipeline and the raw data publicly available to investigate the pipeline in detail and reproduce the results (provided hyperlinks are not functional).</p></disp-quote><p>The pipeline and data are now available online.</p><p>Data: https://openneuro.org/datasets/ds004483/versions/1.0.0 and https://openneuro.org/datasets/ds004482/versions/1.0.0</p><p>Analysis and stimulation scripts: https://github.com/sam-planton/ABseqfMRI_scripts and https://github.com/Fosca/Binary_Sequences</p><disp-quote content-type="editor-comment"><p>– As outlined by Reviewer 2, it is unclear whether the authors have successfully &quot;characterize[d] the mental representation that humans utilize to encode binary sequences of sounds in working memory and detect occasional deviants&quot; as they set out to do. While it is possible that the regions found &quot;constitute the minimal network needed to track sequences&quot; we find the evidence insufficient to assert this.</p></disp-quote><p>We have removed the term “working memory” from the title. The main claim of this work is not about the type of memory in which the compressed information is stored. We thus have changed the title of the article to Brain imaging evidence for compression of binary sound sequences in human memory. It seems that the notion of Working Memory (WM) is defined differently for researchers from different fields. Here, we consider Baddeley’s 1986’s definition of working memory as “a system for the temporary holding and manipulation of information during the performance of a range of cognitive tasks such as [language] comprehension, learning and reasoning”. WM can then be required in goal directed behaviours, in planning and executive control. Here, the sequence compressed description is stored in a temporary memory store that follows the above definition of WM. We thus have kept in the manuscript the term “working memory” when it was used to refer to these properties.</p><p>We also removed the sentence “constitute the minimal network…”, since indeed we have no evidence that this network is minimal.</p><disp-quote content-type="editor-comment"><p>Further analyses might be needed to elucidate the temporal evolution of the neural signals over its repeated presentation over habituation and test, as well as the experiment overall. Further research might be needed to study persistent activity while minimizing influences from perceptual processing and could even distinguish the representation of individual sequences from each other using pattern analysis.</p></disp-quote><p>We agree that the suggested analyses, applied to a delay period without stimuli, could be useful to investigate in depth the type of memory that is involved in this experiment. The present experiments, however, are sufficient to our goal, which is to investigate how the structure of a binary melody affects its encoding in the human brain, and to test the predictions of a specific model (language of thought) against others.</p><disp-quote content-type="editor-comment"><p>– Please reconsider the terminology used to describe the proposed model, as argued convincingly and exemplified by Reviewer 2.</p></disp-quote><p>We would like to keep the notion of &quot;language of thought”, which was introduced by Fodor in 1975 and that we present in the first paragraph of the Introduction. We thank the Reviewers for noting that this concept was not clearly defined and not detailed enough. We have now added a subsection on the “Language of Thought for binary sequences” in the <italic>Results section</italic> that provides additional information on the model.</p><disp-quote content-type="editor-comment"><p>Reviewer #1 (Recommendations for the authors):</p><p>Weaknesses:</p><p>Inconsistencies in the analysis across datasets, for example, a direct comparison of the alternative model with the LoT on the behavioral data (but no figure for the alternative model effect), no analysis including the alternative model for the fMRI data, and providing the linear regression analysis for the MEG data that includes the predictor related to the alternative model only as a secondary analysis is unfortunate. It weakens the main conclusion of the manuscript.</p></disp-quote><p>We thank the Reviewer and are sorry if our manuscript appeared to suffer from inconsistencies. We have endeavored to address the multiple points raised by the referee.</p><list list-type="order"><list-item><p>Behavior. We have added an entire section and a new figure panel in Figure 2, to perform model comparison on behavioral data. We now contrast our LoT model with the other 5 main models of sequence encoding (see below). LoT complexity once again appears as the best predictor of behavior, as previously shown by our work (Planton et al. 2020)</p></list-item><list-item><p>Once this point is settled, we no longer compare all these models on fMRI and MEG data. We now solely examine LoT complexity while accounting for the possible contributions of statistical transition probabilities. Note that we do not consider that assessing the contribution of statistical processing in addition to the language of thought predictions constitutes a competing (alternative) model. Statistical learning takes place simultaneously to the mechanism we are investigating and therefore accounts for part of the variance. However, statistical learning is a well-known contributor to brain activity, and therefore is important to model as a regressor. This aspect was now clarified by the following paragraph in the Discussion:</p></list-item></list><p>“Many levels of sequence processing mechanisms coexist in the human brain (Dehaene et al., 2015) and statistical learning is a well-known contributor to brain activity. Thanks to the high temporal resolution of MEG, we could separate the effects of transition probabilities from those of sequence structure (as also done by, e.g. Bekinschtein et al., 2009; Maheu et al., 2019; Wacongne et al., 2011).”</p><list list-type="bullet"><list-item><p>fMRI and MEG are very different in their temporal dynamics. Given the low temporal resolution of fMRI (TR = 1.81s), characterizing the contribution of surprise in brain activation related to sequence perception, and distinguishing it from the effect of LoT complexity is a more challenging task in fMRI than it is in MEG. Given the shape of the BOLD response, fMRI signals average over much, if not all of the sounds in each sequence, while it is the rapid changes between a sound and the next one (SOA of 250 ms) that are of concern for the surprise regressor. Tracking item-by-item surprise with the low temporal resolution of fMRI would be equivalent to using a smoothed version of our surprise regressor, such as a moving average. However, when we did so, we found that this average tends towards an identical value for many sequences: Pairs, Shrinking, ThreeTwo, CenterMir, Complex, all have the same global transition probabilities (as many repetitions as alternations across the 16 items) and thus the same average surprise value (see <xref ref-type="fig" rid="sa2fig1">Author response image 1</xref>). Thus, our fMRI experiment was not designed to identify the contributions of item-by-item surprise.</p></list-item></list><fig id="sa2fig1" position="float"><label>Author response image 1.</label><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-84376-sa2-fig1-v1.tif"/></fig><p>We have now added the following paragraph in the introduction:“Second, a simpler system of statistical learning, based on transition probabilities, may operate in parallel with LoT predictions (Bekinschtein et al., 2009; Chao et al., 2018; Maheu et al., 2019, 2021; Meyniel et al., 2016; Summerfield and de Lange, 2014). To separate their contributions, we will use multiple predictors in a general linear model of behavior and of MEG signals, whose temporal resolution allows to track individual sequence items (in fMRI, the BOLD response was too slow relative to the sequence rate of 250 ms per item).”</p><p>and this sentence at the beginning of the MEG results part:</p><p>“The low temporal resolution of fMRI did not permit us to track the brain response to each of the 16 successive sequence items, nor to any local sequence properties such as item-by-item variations in surprise.”</p><p>For this reason, in our previous manuscript, we deemed it unreasonable to attempt to extract or to fit fast surprise predictors to fMRI signals evoked by a sequence with 250-ms SOA. Prompted by the referee, we did try. We used one possibility offered in the SPM software which is to use a parametric modulator for surprise, along with the “boxcar” regressor used to model the onsets and durations in each condition. We computed such an alternative GLM that included a surprise parametric modulator for each condition of the experiment. We computed the same contrasts as before, at the group level, to assess how much the LoT complexity effect was affected. As illustrated in <xref ref-type="fig" rid="sa2fig2">Author response image 2</xref>, adding the surprise modulator did not affect the complexity contrast in habituation.</p><fig id="sa2fig2" position="float"><label>Author response image 2.</label><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-84376-sa2-fig2-v1.tif"/></fig><p>The other contrast for the effect of complexity on deviancy was affected a bit more, as shown in <xref ref-type="fig" rid="sa2fig3">Author response image 3</xref> -- but there were much fewer trials with deviants, and the noise was therefore higher:</p><fig id="sa2fig3" position="float"><label>Author response image 3.</label><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-84376-sa2-fig3-v1.tif"/></fig><p>Overall, we are therefore not confident that it was reasonable to attempt to model both complexity and surprise in the slow fMRI signals. Our design was solely conceived in order to track complexity, which is a sequence-level variable, rather than surprise, which is a much faster item-level variable.</p><disp-quote content-type="editor-comment"><p>The manuscript could establish more robust conclusions when, for example, the or multiple alternative models would be treated equally (e.g., figures for the behavioral data). For the fMRI analysis, one could compare the models with an overlap analysis (similar to in Figure 4) and compare effect sizes from different regions. For the MEG data, one could focus on the analysis that considers both models, as one could expect that the model has a higher model fit and provide extensive descriptions for both effects.</p></disp-quote><p>We have added the suggested model comparison of alternative models on behavioral data (Planton et al., 2021 PLOS Computational Biology). This analysis is now included in Figure 2 and in the Behavioral data subsection of the Results section. It replicates previous behavioral results obtained in <italic>Planton et al., 2021 PLOS Computational Biology,</italic> namely that complexity, as measured by minimal description length is the best predictor of participants’ behaviour.</p><p>Based on these behavioral results, we did not proceed further in the investigation of the neural correlates for the alternative models.</p><disp-quote content-type="editor-comment"><p>Also, a critical case for the model is the 0-correlation of behavior and LoT for the Alternate condition. The authors choose not to include a correlation between behavior in the bracket task and the alternative account.</p></disp-quote><p>We now explicitly test the hypothesis that surprise from transition probabilities could explain the bracketing behavior. We computed the correlation between item-by-item surprise and participants’ bracketing. As seen in <xref ref-type="fig" rid="sa2fig4">Author response image 4</xref>, for several sequences, those correlations are low or even negative, and thus fail to explain the observed complexity effects.</p><fig id="sa2fig4" position="float"><label>Author response image 4.</label><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-84376-sa2-fig4-v1.tif"/></fig><p>A new paragraph was introduced in the behavioral results:“It could be suggested that, rather than the structure predicted by the LoT model, participants use transition probabilities to segment a sequence, with rare transitions acting as chunk boundaries. We thus tested the correlations between the group-averaged number-of-brackets vector and the transition-based surprise derived from transition probabilities. There are 15 item-to-item transitions in 16-item sequences, thus brackets before the first and after the last items were excluded from this analysis. Surprise was computed by pooling over all the transitions in a given sequence. Due to lack of variance, a correlation with transition-based surprise was impossible for sequences Repeat (all transitions are 100% predictable repetitions) and Alternate (all transitions are 100% predictable alternations). For other sequences, a positive correlation was found for sequences Quadruplets (r = 0.99, p &lt;.0001), Pairs (r = 0.88, p &lt;.0001), Complex (r = 0.79, p &lt;.0005), Shrinking (r = 0.73, p &lt;.002), ThreeTwo (r = 0.68, p &lt;.006), and CenterMirror (r = 0.64, p &lt;.02). Crucially, however, no positive correlation was found for sequences PairsandAlt.1 (r = -0.48, p = .071) and PairsandAlt.2 (r = -0.58, p &lt;.03). This was due to the fact, in these sequences, that repetitions were the rarest and therefore the most surprising transitions: thus in these sequences, transition probabilities predicted a breaking of the chunks of repeated item, while participants correctly did not do so and placed their brackets at chunk boundaries (see Planton et al., 2021). Thus, although surprise arising from the learning of transition probabilities can partially predict participants’ bracketing behavior in some cases, notably when a sequence is composed of frequent repetitions and rare alternations, this model completely fails in other (e.g., when repetitions are rare), again indicating that higher-level models such as LoT are needed to explain behavior.”</p><disp-quote content-type="editor-comment"><p>Moreover, no critical discussion of this inconsistency is included.</p></disp-quote><p>We have now added a full discussion of this small departure from our theory. The new paragraph now reads:</p><p>“Finally, after the experiment, when participants were asked to segment the sequences with brackets, their segmentations closely matched the LoT sequence descriptions. For instance, they segmented the Pairs+Alt.1 sequence as [[AA][BB]][[ABAB]]. The sole exception was the alternate sequence (ABAB…) which was encoded by our theory as 15 alternations, but was bracketed by participants as 8 repetitions of the subsequence AB. This interesting departure from our theory may indicate that, during sequence parsing, participants do not necessarily identify the most compact representation, but wait until a repeated subsequence occurs, and then encode how often it repeats (including nested repetitions). This parsing strategy would yield a minor departure from our proposed encodings. Undoubtedly, there is still room for improvement in our LoT theory, which is highly idealized and does not incorporate real-time parsing constraints. However, an alternative interpretation of the bracketing results is that the visual bracketing task itself may bias the perception of auditory sequences. By making the entire sequence visible at once, including its start and end point, the visual format may have incited subjects to subdivide it into groups of two, while the auditory sequential presentation alone would have encouraged the “15 alternations” encoding. In support of the latter interpretation, we did not find any evidence for grouping by two in the timing of button presses when subjects reproduced the alternate sequence from memory (Al Roumi and Tabbane, unpublished data). More research, with a greater diversity of sequences and tasks, will be needed to understand whether and where the present theory needs to be amended.”</p><p>Indeed, in an experiment we are currently running where participants have to reproduce 12-item sequences of spatial positions, there is no effect of chunking by groups of 2 items in the reproduction RTs (the only detectable effect is an increase in RT between the 10th and 11th item, corresponding to participants’ uncertainty about sequence length). See <xref ref-type="fig" rid="sa2fig5">Author response image 5</xref>.</p><fig id="sa2fig5" position="float"><label>Author response image 5.</label><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-84376-sa2-fig5-v1.tif"/></fig><disp-quote content-type="editor-comment"><p>Moreover, recent developments indicate selective implementation of representations depending on the complexity of the task (e.g., see Boominathan, L., and Pitkow, X. (2022). Phase transitions in when feedback is useful. Advances in Neural Information Processing Systems, 35, 10849-10861.) the investigation of an interaction of the complexity parameter and the transitional probabilities would be highly intriguing.</p></disp-quote><p>We thank the reviewers for this very interesting remark and for pointing to the article. In the current study, the selected sequences do not allow for such an assessment: surprise has mostly the same value for all the sequences. Nonetheless, the goal of the upcoming fMRI article is precisely to determine if the brain regions involved in the representation of sequence structure are distinct or not from the ones of sequence statistical properties and how they interact.</p><disp-quote content-type="editor-comment"><p>Further points:</p><p>It is highly recommended to make the analysis pipeline and the raw data publicly available to investigate the pipeline in detail and reproduce the results (provided hyperlinks are not functional).</p></disp-quote><p>This has now been fixed, the data and the analysis pipeline are now available online.</p><disp-quote content-type="editor-comment"><p>Figure 1.: For a clear understanding for the reader, one could provide the tree structure for the experimental conditions reflecting the LoT complexity</p></disp-quote><p>For the sake of clarity, we have now added Figure 1—figure supplement 1, that contains the sequence descriptions provided by the Language of Thought and a verbal description of the sequence. We believe this eases the reader’s understanding of the LoT and the sequences formal descriptions.</p><disp-quote content-type="editor-comment"><p>Figure 2 Please present the p-value and the r in bold letters. The current presentation suggests higher importance for the statistics than the effect size estimate.</p></disp-quote><p>We thank the reviewer for this remark. This change has now been done.</p><disp-quote content-type="editor-comment"><p>Results</p><p>195-199. As indicated before, the low correlation between bracketing behavior and the LoT model simulations is low. The following section is provided but unclear from reading the previous sections. Please provide more context here and elaborate in the discussion.</p><p>&quot;For the latter, a minor departure from the proposed encoding was found, as the shortest LoT representation (i.e. [+0]^16) can be paraphrased as &quot;16 alternations&quot;, while the participants' parses corresponded to &quot;8 AB pairs&quot;. The latter encoding, however, only has a marginally larger complexity, so this deviation should not affect subsequent results. &quot;</p></disp-quote><p>We hope the various changes to the manuscript that are reported above, in the previous section, now address the Reviewer’s concern.</p><disp-quote content-type="editor-comment"><p>211-219: Be precise on the formulation of the linear mixed effect model. As the random effect structure can vary drastically, it is essential to present the complete form of the model, especially when reanalyzing it with and without the subject random effect. Also, no indication of the inclusion of random slopes or other random effects like stimuli is included.</p></disp-quote><p>We hope the changes to the manuscript and response now address the Reviewer’s concern.</p><disp-quote content-type="editor-comment"><p>220-230: Statistical learning as an alternative explanation. The critical test needs to be included. Has the stats learning or the LoT complexity predictor the higher model fit? Also, why not use a metric that penalizes for the number of predictors in the model (e.g., Akaike Information Criterion). Also, please provide the correlation of the two predictors from the models. A similarity estimation is essential to interpret the findings.</p></disp-quote><p>As explained above, surprise from transitional probabilities is not an alternative model, but a mechanism that takes place in parallel to the one of interest here. There is therefore no strong motivation to determine which predictor has the highest model fit. Nonetheless, Figures S5 and S7 present the regression betas for LoT complexity and surprise from transitional probabilities. By comparing their amplitude, we can estimate their relative contribution to the signal variance.</p><p>Regarding this point, several clarifications to the manuscript have now been done. They have been described in the previous responses.</p><disp-quote content-type="editor-comment"><p>341-345: Why use a quadratic trend, and what is the benefit of making the statistical model more complex here? Please elaborate</p></disp-quote><p>This point was now clarified in the Introduction:</p><p>“Two subtleties further qualify this overall theoretical picture. First, at the highest level of sequence complexity, sequences cannot be compressed in a simple LoT expression, and therefore we expect the brain areas involved in nested sequence coding to exhibit no further increase in activation, or even a decrease (Vogel and Machizawa, 2004; Wang et al., 2019). We will evaluate the presence of such a non-linear trend by testing a quadratic term for LoT-complexity in addition to a purely linear term in the regression models.”</p><disp-quote content-type="editor-comment"><p>364&quot; &quot;for loops&quot; postulated in our language&quot;; Please elaborate.</p></disp-quote><p>We thank the Reviewer for pointing this unclear terminology. We have now replaced “for loops” by ‘repetitions’ as it is more closely related to the terminology we introduced in the Result section The Language of Thought for binary sequences and in Figure 1—figure supplement 1.</p><disp-quote content-type="editor-comment"><p>fMRI part:</p><p>Comparison analysis based on the alternative model (based on transitional probabilities) needs to be included. This analysis would allow us to investigate which regions contribute to the added behavioral explainability found in the behavioral analysis.</p></disp-quote><p>We hope that the Reviewer is satisfied with the answer given in the previous section.</p><disp-quote content-type="editor-comment"><p>MEG part:</p><p>Unclear why the quadratic trend used for the fMRI analysis is not considered here. Please provide an argumentation.</p></disp-quote><p>We hope that the Reviewer is satisfied with the answer given in the previous section.</p><disp-quote content-type="editor-comment"><p>Alternative model, based on transitional probabilities. Figure S4 provides the complexity effects based on a regression model, including the transitional probabilities measure. For clarity, please provide the corrected version in Figure 6 alongside the effect of the alternative model. Again model comparison or if both show considerable effects, one could investigate the interaction of complexity and transitional probabilities. Similarly, use both parameters or the interaction for the classifier data presented in Figure 7.</p></disp-quote><p>We hope that the Reviewer is satisfied with the answer given in the previous section.</p><disp-quote content-type="editor-comment"><p>L 534: Please provide an argument here, why the leave-one-out was used here. Alternatively, one could use a 5-fold cross-validation that is more efficient to estimate and less problematic when it comes to overfitting. I expect this analysis was implemented because the analysis presented in Figure 7 is based only on the unseen dataset.</p></disp-quote><p>In this work, the cross-validation is two-folds, with a leave-one-run-out method. Indeed, for each sequence, there are two runs, each of them investigating the coding of the same sequence structure, but starting with a different tone (e.g. for a given subject, in run number 2 the “Shrinking” sequence starts with tone A, and in run number 9 it starts with tone B). Therefore, if we train a decoder on the data from all the sequences but coming only from one of the two runs, and we find that the decoder generalizes to the other run, then the decoding has to be independently of stimulus identity. Therefore, there is no risk of overfitting.</p><p>This is what was written in the Materials and methods:</p><p>“One run was dedicated to each version of the sequence (7 sequence types x 2 versions [starting with A or starting with B] = 14 runs). To build the training set, we randomly picked one run for each sequence, irrespectively of the sequence version. We trained the decoder on all deviant trials of the 7 sequences and on standard trials (non-deviant trials from the test phase) that were matched to sequence-specific deviants in ordinal position. We then tested this decoder on the remaining 7 blocks, determining its performance for the 7 sequences separately. The training and the testing sets were then inverted, resulting in a 2-folds cross-validation. This procedure avoided any confound with item identity, as the sounds A and B were swapped in the cross-validation folds.”</p><disp-quote content-type="editor-comment"><p>L 628 It is not clear what statistical test established cross decoding, as the cluster test provided cannot differentiate between time windows (see Sassenhagen, J., and Draschkow, D. (2019). Cluster‐based permutation tests of MEG/EEG data do not establish significance of effect latency or location. Psychophysiology, 56(6), e13335.).</p></disp-quote><p>We thank the reviewer for this precious and pedagogical article that raises an important (and common) mistake that was present in this work. We have now modified accordingly the text when discussing the significance of the results, in order to avoid making claims on the position and time-windows on which the effects are significant.</p><disp-quote content-type="editor-comment"><p>L 763 &quot;fMRI, MEG and behavioral responses to deviants vary linearly with complexity, while model-related fMRI activations vary as an inverted U function of complexity&quot;. This result was not tested for, e.g., the MEG data. As described, no non-linear relationships have been investigated in the study.</p></disp-quote><p>We hope the reviewer finds satisfactory the response we previously provided on this point.</p><disp-quote content-type="editor-comment"><p>Subjects:</p><p>Please justify the number of participants participating in the experiment using a Power analysis. If no a-priory analysis was implemented, provide a post hoc analysis. This is especially important because it was previously shown that low power could result in false positive inflation for fMRI data (e.g., Yarkoni, T. (2009). Big correlations in little studies: Inflated fMRI correlations reflect low statistical power-Commentary on Vul et al.(2009). Perspectives on psychological science, 4(3), 294-298.)</p></disp-quote><p>It is true that the sample size was not justified by a power analysis. We determined the number of participants based on our knowledge of practices for this type of study, while considering the limits of our own resources (in a Covid time period). We are well aware of the debates and concerns about the lack of statistical power of fMRI or behavioral science studies, but we do not think that there is any solution that would not significantly increase the costs of such studies. Increasing the sample size can be just as costly as carrying out an independent pilot study to determine the sample size a priori via power analysis. Such approach also has some flaws; pilot data are underpowered and subject to a lot of variability, thus weakening the capacity to estimate effects sizes and their variance. Besides, in an fMRI study investigating several effects across many conditions and many areas, a power analysis usually requires choosing one or multiple effects of interest with associated regions of interest, which could be seen as a weakness of the approach. A power analysis could attest for a sufficiently powered effect of LoT complexity in the SMA during habituation, while telling nothing about the power of a different contrast (e.g., complexity effect in deviants) in another area (e.g. STG). Power is also dependent on Signal-to-noise ratio, which can vary with coil, sequence choices, etc – the sources of variations are endless, and as a result, we know of no well-accepted procedure for power analysis.</p><p>Following the reviewer’s suggestion, we considered the possibility to estimate power using our current data (although we note there is some controversy about the possibility of estimating power in such a post-hoc manner, e.g. Hoenig and Heisey, 2001). However, although there are regular publications on the subject of power analysis in fMRI, these remain rare and are sometimes called into question. Perhaps as a result of these difficulties, some of the tools that were used in the community are now inaccessible or discontinued: Fmripower (Mumford and Nichols, 2008; https://jeanettemumford.org/fmripower/), Neuropowertools (http://www.neuropowertools.org/ Durnez et al., 2016). We were however able to use PowerMap (Joyce and Hayasaka, 2012), and generate a power map for the contrast “Complexity effect in habituation”. Please see the results in author response image 6 (conducted using all the significant positive clusters of the contrast as a mask and using a threshold for the power analysis of p &lt; 0.05 with FDR correction). They indicate that the power is at least of 0.70 for the highest peak of each cluster. It is maximal at the SMA. However, because this method is designed for pilot studies and is highly circular, we do not think that it provides a correct estimate power in a post-hoc manner. We are open to suggestions from the reviewer to perform such a post-hoc power analysis in a reliable manner.</p><fig id="sa2fig6" position="float"><label>Author response image 6.</label><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-84376-sa2-fig6-v1.tif"/></fig><disp-quote content-type="editor-comment"><p>L 924-929: Please provide the threshold r used for the automatic detection. Also, explain why the number of components was fixed to 1 for cardio and 2 for eye-movement artifacts.</p></disp-quote><p>The cluster threshold was set automatically based on the F-threshold corresponding to a p-value of 0.05 for the given number of observations (19), namely 4.381.</p><disp-quote content-type="editor-comment"><p>Reviewer #2 (Recommendations for the authors):</p><p>Before we share our evaluations and concerns, we would like to emphasize that our primary expertise is within working memory research using fMRI and behavioral methods. We hope that our comments will prove to be helpful to the authors.</p><p>Is this 'in human working memory'</p><p>It is almost impossible to design an experiment that fully precludes some use of working memory. This means that to argue that a process is selectively contained within working memory requires the experimenter to rule out influences of perceptual and long-term memory processes.</p><p>Behaviorally, this would mean designing a task where information has to be retained over time, and that discourages the use of long-term memory. Instead, the complexity of the stimuli used (which are likely to exceed working memory capacity) and the intense ongoing stimulation (operating in part as a distractor to working memory processing) seems to encourage the use of long-term memory. Consistently, subjects need to be 'habituated' to the to-be-memorized sequence about ten times, making an influence of early forms of long-term memory very likely.</p><p>More importantly, when a neural signal is to be attributed to working memory processing this typically requires some claim of delay period activity (i.e. some form of persistent activity). Here, there is little evidence of differential delay-period activity that is different for different task conditions. Instead, MEG data is most reliably affected by sequence complexity between 100 and 200 ms after the onset of an individual stimulus and complexity specific responses only extend beyond this when a violation of the sequence is detected. The fMRI data does little to alleviate this concern and evaluating this question is made harder by the fact that we could not directly link the time-resolved fMRI data time courses (Figure 3B) with the experimental timeline presented in the methods section.</p></disp-quote><p>We are sorry if our paper gave the impression that it is focussed on whether sequence information is in “working memory” as opposed to other forms of memory. This is not our goal, and we have significantly changed the paper by removing the term “working memory” from the title and other places. The main claim of this article is not about the specific type of short-term memory (WM, early form of long-term memory etc) that is recruited to encode the sequences, but about the fact that they are compressed in memory, and that understanding this compression requires the postulation of a specific “language of thought”. This is why we did not design the study to test specific attributes of WM, such as a delay-period activity.</p><p>We believe that the notion of Working Memory is defined differently for researchers from different fields. Here, we consider working memory as “a system for the temporary holding and manipulation of information during the performance of a range of cognitive tasks such as [language] comprehension, learning and reasoning”, as defined by Baddeley in 1986. It may be required in goal directed behaviours and more generally in planning and executive control.</p><p>In this study, we assume that sequences are compressed in memory according to the description provided by the language. Participants discover this compressed code during habituation and store it in memory. The content of memory will change according to the context: in a different run, another sequence will be compressed and stored in memory to predict next items and detect deviants. Moreover, fMRI results show activations in the fronto-parietal network, that is generally found in WM studies. This is why we had considered that the type of short-term memory that is recruited in this task is working memory, but it is not so central to our paper.</p><disp-quote content-type="editor-comment"><p>Despite this, the authors seem to argue that the signals found are a kind of load-like signal that is indicative of the storage of the compressed sequences. For this, it is worth noting that whether load-signals are indicative of an underlying representation of memorized content is questionable (Emrich et al., 2013) and that we know of no instance where the load signals reverse like it does here in deviant trials.</p></disp-quote><p>We thank the reviewers for this very interesting article. We agree that the current experimental design does not allow to clearly address the questions raised by the reviewer and in the above-mentioned article – but we hope that the referee will agree that our experimental design suffices to our goal, which is to put to a test the specific predictions of the language-of-thought model.</p><p>We have started to run a new experiment that should be able to address these issues better, as the trial structure is the following: participants see a sequence, have to hold it in memory (maintenance period) and then have to reproduce it. We will therefore be able to determine, separately for the two main phases of sequence presentation and maintenance, which brain regions represent stimulus identity and which exhibit load-like signals.</p><p>In the current work, we assume that, in a similar manner to Vogel et al. 2005, the brain regions that hold in memory the compressed description of the sequence should exhibit an activity proportional to LoT-complexity, i.e. the length of the description that is stored in memory. In this current paradigm, any brain area that is involved in the prediction of the upcoming item should also exhibit this type of activity as it is less costly to decompress a simple expression than a complex one. We agree that the current paradigm does not allow to disentangle between purely predictive mechanisms versus pure memorization – here, those are two sides of the same coin.</p><disp-quote content-type="editor-comment"><p>The authors, however, argue that the successful quadratic fits of the neural complexity signals are akin to ceiling-in-load effects found in the working memory literature (Vogel and Machizawa, 2004) where neural load-signals reach a ceiling for loads that exceed working memory capacity. This ceiling-in-load effect, however, relies on this tight link between neural and behavioral data evidence which is not presented.</p></disp-quote><p>The quadratic trend that we predicted and identified in the data is not attributed to working memory load, but to the fact that, beyond a certain level of complexity (not length), the sequence becomes impossible to compress and to encode in a compact manner using the proposed language-of-thought. We hope that this is clear in the current version of the manuscript, where we tried to re-explain why behavior should not show such a quadratic trend.</p><p>The behavioral task involves deviant detection. As complexity increases, and the capacity to encode the sequence becomes increasingly difficult, then collapses, this can only lead to a monotonic reduction in predictions, and therefore reduced deviant detection. Had we tested various such incompressible sequences, we would maybe have found a ceiling effet in behavioral performance: above a given complexity value, participants may start responding at chance. For the chosen sequence complexity values, we indeed do not see this ceiling effect in behaviour.</p><disp-quote content-type="editor-comment"><p>Furthermore, the 'quadratic' effect reported here seems to be expressed as data for both the most and least complex sequences diverging from the linear trend. This simply might indicate that the precise complexity of extremely simple and highly complex sequences is less precisely captured by the compression model.</p></disp-quote><p>As noted in the Discussion section, we found that, while task performance was primarily linearly related to LoT complexity, fMRI activity was not. It is based on this observation that we excluded the interpretation suggested by the reviewer, namely that extremely simple and highly complex sequences is less precisely captured by the compression model, and interpreted the results in terms of collapse of memory capacities. Most complex sequences exceed memory capacity, and such a collapse in memory capacity leads to reduced predictions and therefore reduced violation detection. This explains why behavioral responses to deviants are mainly linearly correlated with complexity, while model-related fMRI activations vary as an inverted U function of complexity.</p><disp-quote content-type="editor-comment"><p>In the introduction the authors, however, also highlight a potentially more specific interpretation of their signals. &quot;[…] the internal model of the sequence, as described by the postulated LoT, would be encoded by prefrontal regions of the brain, and would send anticipation signals to auditory areas, where they would be subtracted from incoming signals. As a consequence, we predict a reciprocal effect of LoT on the brain signals during habituation and during deviancy. In the habituation part of the experiment, lower amplitude response signals should be observed for sequences of low complexity – and conversely, during low complexity sequences, we expect top-down predictions to be stronger and therefore deviants to elicit larger responses, than for complex, hard to predict sequences.&quot; To us, this prediction-error-like interpretation seems to be more in line with the data presented. We believe that the time-courses presented in MEG closely match both early and late mismatch signals (mismatch activity and P300). The fMRI data is to the extent we can judge consistent with this interpretation, as is the apparent decline in complexity modulation from habituation to deviant free test trials and the inversion when deviance is detected.</p></disp-quote><p>This very interesting point ties in with the one raised by the reviewers on the previous page. In this work, we do not oppose predictive coding and working memory mechanisms. Instead, we consider that, in the case of the memorization of structured information, as the compressed code that is stored in memory has to be unfolded to predict upcoming events, these two functions have to be jointly recruited, but on different time-scales.</p><disp-quote content-type="editor-comment"><p>The authors argue, in this regard, that the complexity effect is not solely explained by a 'surprise' model. But at least some of the variance in question is explained by surprise. This leaves us to ask whether a better surprise or mismatch model could be found than the one used to capture the results fully (the current implementation of which should be fully explained in the methods). In the end, the more complex a sequence, the less predictable it is and the more surprising its individual elements are when initially presented.</p></disp-quote><p>We apologize for the confusion. In the previous version of the manuscript, in accord with several previous publications, we used the term “surprise” to refer to “surprise arising from transition probabilities”. The reviewer is right, surprise signals are not only due to surprise from transition probabilities but also to observations that are in disagreement with the expectations based on the sequence LoT-description. As the terminology can be misleading, we have now clarified the use of the term ‘surprise’ and replaced it by “transition-based surprise” when its usage was ambiguous.</p><disp-quote content-type="editor-comment"><p>Thus, it is unclear whether the authors have successfully &quot;characterize[d] the mental representation that humans utilize to encode binary sequences of sounds in working memory and detect occasional deviants&quot; as they set out to do. While it is possible that the regions found &quot;constitute the minimal network needed to track sequences&quot; we find the evidence insufficient to assert this.</p></disp-quote><p>Once again, the main claim of this work is not about the type of memory in which the compressed information is stored, and we agree that this experiment was not designed to determine which one is. We thus have changed the title of the article and refocused it. However, we hope that the referee is convinced that our paper (now including explicit model comparisons) strongly supports the view that a pure transition-based view of sequence prediction is not tenable here, and that the concepts of compression and language-of-thought are needed.</p><disp-quote content-type="editor-comment"><p>Further analyses might help elucidate the temporal evolution of the neural signals over its repeated presentation over habituation and test, as well as the experiment overall. Further research might be needed to study persistent activity while minimizing influences from perceptual processing and could even distinguish the representation of individual sequences from each other using pattern analysis. Sequence complexity might be seen as a confound in such research as it leads to prediction-error-like or load-like response that can be independent of the representation of the individual sequence.</p></disp-quote><p>We hope our previous responses address in a convincing manner this point.</p><disp-quote content-type="editor-comment"><p>The essence of our concerns [has been covered above]. In short, we are convinced that the evidence speaks to a prediction-error-like signal that covaries with the complexity, and not a signal directly related to working memory retention. Our first major recommendation is therefore to put substantially more emphasis on this alternative interpretation of the results.</p></disp-quote><p>As explained in the previous responses, we consider that predictive coding and working memory mechanisms coexist and that the memorized information has to be uncompressed to predict upcoming events. These two functions have to be jointly recruited to perform the experiments. As described above, we have made changes to the manuscript to clarify this aspect.</p><disp-quote content-type="editor-comment"><p>Arguing for a working memory-specific signal would – in our view – require directly establishing the presence of some form of persistent activity that is linked to the current results. Because of the rapid presentation of the sequences and the absence of a delay, we see no avenue to pursue this in the current fMRI data. Even for the EEG data, one would have to look at the brief time periods between individual habituations and see whether the recorded data carries information about the presented sequences. Even in this case, one would need to find a way to carefully distinguish these results from the prediction-area-like signals found so far. It is possible the authors intended to establish a connection to working memory in a way that we did not comprehend. In this case, this point requires clarification.</p></disp-quote><p>We hope our previous responses provide a satisfying answer to this point. To summarize, we agree on the fact that the current design is not adequate to determine which precise type of short-term memory is recruited by the brain in this task and it is not the primary goal of this work. This aspect will be investigated in the next experiment.</p><disp-quote content-type="editor-comment"><p>It would be of interest to further understand the role of long-term memory in this task. For this, it would be helpful to investigate how the complexity effect changes over the course of the experiment. Comparing the first and second (inverted) presentation of the sequence could establish whether the complexity effect is mediated by long-term memory.</p></disp-quote><p>We thank the reviewers for this remark. This would definitely be very interesting in a work that focuses on the characterization of the types of memories that are required in this task. It may thus be of great value in our future works.</p><disp-quote content-type="editor-comment"><p>Finally, we would suggest reconsidering the terminology used to describe the proposed model. On first read, we got distracted by questioning what the authors meant by 'language of thought' and how it related to the experimentation presented (e.g. &quot;The present results therefore support the hypothesis that the human brain hosts multiple internal languages&quot;). The terminology currently used implies a direct link to the subject's subjective experience of thought and while we all want to know how the words (and 'words') we 'think' come to be, we do not see how the data presented speak to that question, directly.</p></disp-quote><p>The notion of &quot;language of thought” was introduced by Fodor in 1975 and we present it in the first paragraph of the Introduction. As this was not clear and detailed enough, we have now added a subsection on the “Language of Thought” in the <italic>Results section</italic> that provides additional information on the model.</p></body></sub-article></article>