<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD with MathML3 v1.3 20210610//EN"  "JATS-archivearticle1-3-mathml3.dtd"><article xmlns:ali="http://www.niso.org/schemas/ali/1.0/" xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" article-type="research-article" dtd-version="1.3"><front><journal-meta><journal-id journal-id-type="nlm-ta">elife</journal-id><journal-id journal-id-type="publisher-id">eLife</journal-id><journal-title-group><journal-title>eLife</journal-title></journal-title-group><issn publication-format="electronic" pub-type="epub">2050-084X</issn><publisher><publisher-name>eLife Sciences Publications, Ltd</publisher-name></publisher></journal-meta><article-meta><article-id pub-id-type="publisher-id">89911</article-id><article-id pub-id-type="doi">10.7554/eLife.89911</article-id><article-id pub-id-type="doi" specific-use="version">10.7554/eLife.89911.3</article-id><article-categories><subj-group subj-group-type="display-channel"><subject>Research Article</subject></subj-group><subj-group subj-group-type="heading"><subject>Neuroscience</subject></subj-group></article-categories><title-group><article-title>Determinantal point process attention over grid cell code supports out of distribution generalization</article-title></title-group><contrib-group><contrib contrib-type="author" corresp="yes"><name><surname>Mondal</surname><given-names>Shanka Subhra</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">https://orcid.org/0000-0003-1252-0129</contrib-id><email>smondal@princeton.edu</email><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="other" rid="fund1"/><xref ref-type="fn" rid="con1"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author"><name><surname>Frankland</surname><given-names>Steven</given-names></name><xref ref-type="aff" rid="aff2">2</xref><xref ref-type="other" rid="fund1"/><xref ref-type="fn" rid="con2"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author"><name><surname>Webb</surname><given-names>Taylor W</given-names></name><xref ref-type="aff" rid="aff3">3</xref><xref ref-type="other" rid="fund1"/><xref ref-type="fn" rid="con3"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author"><name><surname>Cohen</surname><given-names>Jonathan D</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">https://orcid.org/0000-0003-2316-0763</contrib-id><xref ref-type="aff" rid="aff2">2</xref><xref ref-type="other" rid="fund1"/><xref ref-type="fn" rid="con4"/><xref ref-type="fn" rid="conf1"/></contrib><aff id="aff1"><label>1</label><institution-wrap><institution-id institution-id-type="ror">https://ror.org/00hx57361</institution-id><institution>Department of Electrical and Computer Engineering, Princeton University</institution></institution-wrap><addr-line><named-content content-type="city">Princeton</named-content></addr-line><country>United States</country></aff><aff id="aff2"><label>2</label><institution-wrap><institution-id institution-id-type="ror">https://ror.org/00hx57361</institution-id><institution>Princeton Neuroscience Institute, Princeton University</institution></institution-wrap><addr-line><named-content content-type="city">Princeton</named-content></addr-line><country>United States</country></aff><aff id="aff3"><label>3</label><institution-wrap><institution-id institution-id-type="ror">https://ror.org/046rm7j60</institution-id><institution>Department of Psychology, University of California, Los Angeles</institution></institution-wrap><addr-line><named-content content-type="city">Los Angeles</named-content></addr-line><country>United States</country></aff></contrib-group><contrib-group content-type="section"><contrib contrib-type="editor"><name><surname>Schapiro</surname><given-names>Anna C</given-names></name><role>Reviewing Editor</role><aff><institution-wrap><institution-id institution-id-type="ror">https://ror.org/00b30xv10</institution-id><institution>University of Pennsylvania</institution></institution-wrap><country>United States</country></aff></contrib><contrib contrib-type="senior_editor"><name><surname>Behrens</surname><given-names>Timothy E</given-names></name><role>Senior Editor</role><aff><institution-wrap><institution-id institution-id-type="ror">https://ror.org/052gg0110</institution-id><institution>University of Oxford</institution></institution-wrap><country>United Kingdom</country></aff></contrib></contrib-group><pub-date publication-format="electronic" date-type="publication"><day>01</day><month>08</month><year>2024</year></pub-date><volume>12</volume><elocation-id>RP89911</elocation-id><history><date date-type="sent-for-review" iso-8601-date="2023-06-17"><day>17</day><month>06</month><year>2023</year></date></history><pub-history><event><event-desc>This manuscript was published as a preprint.</event-desc><date date-type="preprint" iso-8601-date="2023-05-28"><day>28</day><month>05</month><year>2023</year></date><self-uri content-type="preprint" xlink:href="https://doi.org/10.48550/arXiv.2305.18417"/></event><event><event-desc>This manuscript was published as a reviewed preprint.</event-desc><date date-type="reviewed-preprint" iso-8601-date="2023-08-23"><day>23</day><month>08</month><year>2023</year></date><self-uri content-type="reviewed-preprint" xlink:href="https://doi.org/10.7554/eLife.89911.1"/></event><event><event-desc>The reviewed preprint was revised.</event-desc><date date-type="reviewed-preprint" iso-8601-date="2024-03-21"><day>21</day><month>03</month><year>2024</year></date><self-uri content-type="reviewed-preprint" xlink:href="https://doi.org/10.7554/eLife.89911.2"/></event></pub-history><permissions><copyright-statement>© 2023, Mondal et al</copyright-statement><copyright-year>2023</copyright-year><copyright-holder>Mondal et al</copyright-holder><ali:free_to_read/><license xlink:href="http://creativecommons.org/licenses/by/4.0/"><ali:license_ref>http://creativecommons.org/licenses/by/4.0/</ali:license_ref><license-p>This article is distributed under the terms of the <ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/licenses/by/4.0/">Creative Commons Attribution License</ext-link>, which permits unrestricted use and redistribution provided that the original author and source are credited.</license-p></license></permissions><self-uri content-type="pdf" xlink:href="elife-89911-v1.pdf"/><abstract><p>Deep neural networks have made tremendous gains in emulating human-like intelligence, and have been used increasingly as ways of understanding how the brain may solve the complex computational problems on which this relies. However, these still fall short of, and therefore fail to provide insight into how the brain supports strong forms of generalization of which humans are capable. One such case is out-of-distribution (OOD) generalization – successful performance on test examples that lie outside the distribution of the training set. Here, we identify properties of processing in the brain that may contribute to this ability. We describe a two-part algorithm that draws on speciﬁc features of neural computation to achieve OOD generalization, and provide a proof of concept by evaluating performance on two challenging cognitive tasks. First we draw on the fact that the mammalian brain represents metric spaces using grid cell code (e.g., in the entorhinal cortex): abstract representations of relational structure, organized in recurring motifs that cover the representational space. Second, we propose an attentional mechanism that operates over the grid cell code using determinantal point process (DPP), that we call DPP attention (DPP-A) – a transformation that ensures maximum sparseness in the coverage of that space. We show that a loss function that combines standard task-optimized error with DPP-A can exploit the recurring motifs in the grid cell code, and can be integrated with common architectures to achieve strong OOD generalization performance on analogy and arithmetic tasks. This provides both an interpretation of how the grid cell code in the mammalian brain may contribute to generalization performance, and at the same time a potential means for improving such capabilities in artiﬁcial neural networks.</p></abstract><kwd-group kwd-group-type="author-keywords"><kwd>grid code</kwd><kwd>generalization</kwd><kwd>attention</kwd><kwd>determinantal point process</kwd></kwd-group><kwd-group kwd-group-type="research-organism"><title>Research organism</title><kwd>None</kwd></kwd-group><funding-group><award-group id="fund1"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/100000006</institution-id><institution>Office of Naval Research</institution></institution-wrap></funding-source><principal-award-recipient><name><surname>Mondal</surname><given-names>Shanka Subhra</given-names></name><name><surname>Frankland</surname><given-names>Steven</given-names></name><name><surname>Webb</surname><given-names>Taylor W</given-names></name><name><surname>Cohen</surname><given-names>Jonathan D</given-names></name></principal-award-recipient></award-group><funding-statement>The funders had no role in study design, data collection, and interpretation, or the decision to submit the work for publication.</funding-statement></funding-group><custom-meta-group><custom-meta specific-use="meta-only"><meta-name>Author impact statement</meta-name><meta-value>Strong out of distribution generalization using an attentional mechanism over grid cell code inspired by determinantal point processes.</meta-value></custom-meta><custom-meta specific-use="meta-only"><meta-name>publishing-route</meta-name><meta-value>prc</meta-value></custom-meta></custom-meta-group></article-meta></front><body><sec id="s1" sec-type="intro"><title>Introduction</title><p>Deep neural networks now meet, or even exceed, human competency in many challenging task domains (<xref ref-type="bibr" rid="bib33">He et al., 2016</xref>; <xref ref-type="bibr" rid="bib64">Silver et al., 2017</xref>; <xref ref-type="bibr" rid="bib77">Wu et al., 2016</xref>; <xref ref-type="bibr" rid="bib34">He et al., 2017</xref>). Their success on these tasks, however, is generally limited to the narrow set of conditions under which they were trained, falling short of the capacity for strong forms of generalization that is central to human intelligence (<xref ref-type="bibr" rid="bib5">Barrett et al., 2018</xref>; <xref ref-type="bibr" rid="bib47">Lake and Baroni, 2018</xref>; <xref ref-type="bibr" rid="bib35">Hill et al., 2019</xref>; <xref ref-type="bibr" rid="bib73">Webb et al., 2020</xref>), and hence fail to provide insights into how our brain supports them. One such case is out-of-distribution (OOD) generalization where the test data lies outside the distribution of the training data. Here, we consider two challenging cognitive problems that often require a capacity for OOD generalization: (1) analogy and (2) arithmetic. What enables the human brain to successfully generalize on these tasks, and how might we better realize that ability in deep learning systems?</p><p>To address the problem, we focus on two properties of processing in the brain that we hypothesize are useful for OOD generalization: (1) the <italic>abstract representations</italic> of relational structure, in which relations are preserved across transformations like translation and scaling (such as observed for grid cells in mammalian medial entorhinal cortex <xref ref-type="bibr" rid="bib31">Hafting et al., 2005</xref>); and (2) an <italic>attentional objective</italic> inspired from determinantal point processes (DPPs), which are probabilistic models of repulsion arising in quantum physics (<xref ref-type="bibr" rid="bib49">Macchi, 1975</xref>), to attend to abstract representations that have maximum variance and minimum correlation among them, over the training data. We refer to this as DPP attention or DPP-A. The net eﬀect of these two properties is to normalize the representations of training and testing data in a way that preserves their relational structure, and allows the network to learn that structure in a form that can be applied well beyond the domain over which it was trained.</p><p>In previous work, it has been shown that such OOD generalization can be accomplished in a neural network by providing it with a mechanism for temporal context normalization (TCN) (<xref ref-type="bibr" rid="bib73">Webb et al., 2020</xref>), a technique that allows neural networks to preserve the relational structure between the inputs in a local temporal context, while abstracting over the diﬀerences between contexts. [Temporal context normalization (<xref ref-type="bibr" rid="bib73">Webb et al., 2020</xref>) is a normalization procedure proposed for use in training a neural network, similar to batch normalization (<xref ref-type="bibr" rid="bib40">Ioﬀe and Szegedy, 2015</xref>), in which tensor normalization is applied over the temporal instead of the batch dimension, which is shown to help with OOD generalization. It is unrelated to the temporal context model (<xref ref-type="bibr" rid="bib39">Howard et al., 2005</xref>), which is a computational model that proposes a role for temporal coding in the functions of the medialtemporal lobe in support of episodic recall, and spatial navigation.] Here, we test whether the same capabilities can be achieved using a well-established, biologically plausible embedding scheme – grid cell code – and an adaptive form of normalization that is based strictly on the statistics of the training data in the embedding space. We show that when deep neural networks are presented with data that exhibits such relational structure, grid cell code coupled with an error-minimizing/attentional objective promotes strong OOD generalization. We unpack each of these theoretical components in turn before describing the tasks, modeling architectures, and results.</p><sec id="s1-1"><title>Abstract representations of relational structure</title><p>The ﬁrst component of the proposed framework relies on the idea that a key element underlying human-like OOD generalization is the use of low-dimensional representations that emphasize the relational structure between data points. Empirical evidence suggests that, for spatial information, this is accomplished in the brain by encoding the organism’s spatial position using a periodic code consisting of diﬀerent frequencies and phases (akin to a Fourier transform of the space). Although grid cells were discovered for representations of space (<xref ref-type="bibr" rid="bib31">Hafting et al., 2005</xref>; <xref ref-type="bibr" rid="bib66">Sreenivasan and Fiete, 2011</xref>; <xref ref-type="bibr" rid="bib52">Mathis et al., 2012</xref>) and used for guiding spatial behavior (<xref ref-type="bibr" rid="bib23">Erdem and Hasselmo, 2014</xref>; <xref ref-type="bibr" rid="bib13">Bush et al., 2015</xref>), they have since been identiﬁed in non-spatial domains, such as auditory tones (<xref ref-type="bibr" rid="bib1">Aronov et al., 2017</xref>), odor (<xref ref-type="bibr" rid="bib4">Bao et al., 2019</xref>), episodic memory (<xref ref-type="bibr" rid="bib14">Chandra et al., 2023</xref>), and conceptual dimensions (<xref ref-type="bibr" rid="bib17">Constantinescu et al., 2016</xref>). These ﬁndings suggest that the coding scheme used by grid cells may serve as a general representation of metric structure that may be exploited for reasoning about the abstract conceptual dimensions required for higher-level reasoning tasks, such as analogy and mathematics (<xref ref-type="bibr" rid="bib54">McNamee et al., 2022</xref>). Of interest here, the periodic response function displayed by grid cells belonging to a particular frequency is invariant to translation by its period, and increasing the scale of a higher-frequency response gives a lower-frequency response and vice versa, making it invariant to scale across frequencies. This is particularly promising for prospects of OOD generalization: downstream systems that acquire parameters over a narrow training region may be able to successfully apply those parameters across transformations of translation or scale, given the shared structure (which can also be learned; <xref ref-type="bibr" rid="bib18">Cueva and Wei, 2018</xref>; <xref ref-type="bibr" rid="bib3">Banino et al., 2018</xref>; <xref ref-type="bibr" rid="bib76">Whittington et al., 2020</xref>).</p></sec><sec id="s1-2"><title>DPP-A</title><p>The second component of our proposed framework is a novel attentional objective that uses the statistics of the training data to sculpt the inﬂuence of grid cells on downstream computation. Despite the use of a relational encoding metric (i.e., grid cell code), generalization may also require identifying which aspects of this encoding that could potentially be shared across training and test distributions. Here, we implement this by identifying, and restricting further processing to those grid cell embeddings that exhibit the greatest variance, but are least redundant (i.e., pairwise uncorrelated) over the training data. Formally, this is captured by maximizing the determinant of the covariance matrix of the grid cell embeddings computed over the training data (<xref ref-type="bibr" rid="bib46">Kulesza and Taskar, 2012</xref>). To avoid overﬁtting the training data, we attend to a subset of grid cell embeddings that maximize the volume in the representational space, diminishing the inﬂuence of low-variance codes (irrelevant), or codes with high similarity to other codes (redundant), which decrease the determinant of the covariance matrix.</p><p>DPP-A is inspired by mathematical work in statistical physics using DPPs that originated for modeling the distribution of fermions at thermal equilibrium (<xref ref-type="bibr" rid="bib49">Macchi, 1975</xref>). DPPs have since been adopted in machine learning for applications in which diversity in a subset of selected items is desirable, such as recommender systems (<xref ref-type="bibr" rid="bib46">Kulesza and Taskar, 2012</xref>). Recent work in computational cognitive science has shown DPPs naturally capture inductive biases in human inference, such as some word-learning and reasoning tasks (e.g., one noun should only refer to one object) while also serving as an eﬃcient memory code (<xref ref-type="bibr" rid="bib73">Webb et al., 2020</xref>). In that context, the learner is biased to ﬁnd a set of possible word-meaning pairs whose representations exhibit the greatest variance and lowest covariance on a task-relevant dataset. DPPs also provide a formal objective for the type of orthogonal coding that has been proposed to be characteristic of representations in mammalian hippocampus, and integral for episodic memory (<xref ref-type="bibr" rid="bib53">McClelland et al., 1995</xref>). Thus, using the DPP objective to govern attention over the grid cell code, known to be implemented in the entorhinal cortex (<xref ref-type="bibr" rid="bib31">Hafting et al., 2005</xref>; <xref ref-type="bibr" rid="bib7">Barry et al., 2007</xref>; <xref ref-type="bibr" rid="bib69">Stensola et al., 2012</xref>; <xref ref-type="bibr" rid="bib29">Giocomo et al., 2011</xref>; <xref ref-type="bibr" rid="bib11">Brandon et al., 2011</xref>) (one synapse upstream of the hippocampus), aligns with the function and organization of cognitive and neural systems underlying the capability for abstraction.</p><p>Taken together, the representational and attention mechanisms outlined above deﬁne a two-component framework of neural computation for OOD generalization, by minimizing task-speciﬁc error subject to: (1) embeddings that encode relational structure among the data (grid cell code), and (2) attention to those embeddings that maximize the ‘volume’ of the representational space that is covered, while minimizing redundancy (DPP-A). Below, we demonstrate proof of concept by showing that these mechanisms allow artiﬁcial neural networks to learn representations that support OOD generalization on two challenging cognitive tasks and therefore serve as a reasonable starting point for examining the properties of interest in these networks.</p></sec></sec><sec id="s2" sec-type="methods"><title>Methods</title><p><xref ref-type="fig" rid="fig1">Figure 1</xref> illustrates the general framework. Task inputs, corresponding to points in a metric space, are represented as a set of grid cell embeddings <inline-formula><mml:math id="inf1"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi mathvariant="bold-italic">x</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mo>=</mml:mo><mml:mn>1..</mml:mn><mml:mi>T</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula>, that are then passed to the inference module <inline-formula><mml:math id="inf2"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi mathvariant="bold-italic">R</mml:mi></mml:mrow></mml:mstyle></mml:math></inline-formula>. The embedding of each input is represented by the pattern of activity of grid cells that respond selectively to diﬀerent combinations of phases and frequencies. Attention over these is a learned gating <inline-formula><mml:math id="inf3"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi mathvariant="bold-italic">g</mml:mi></mml:mrow></mml:mstyle></mml:math></inline-formula> of the grid cells, the gated activations of which (<inline-formula><mml:math id="inf4"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi mathvariant="bold-italic">x</mml:mi><mml:mo>⊙</mml:mo><mml:mi mathvariant="bold-italic">g</mml:mi></mml:mrow></mml:mstyle></mml:math></inline-formula>) are passed to the inference module (<inline-formula><mml:math id="inf5"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi mathvariant="bold-italic">R</mml:mi></mml:mrow></mml:mstyle></mml:math></inline-formula>). The parameterization of <inline-formula><mml:math id="inf6"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi mathvariant="bold-italic">g</mml:mi></mml:mrow></mml:mstyle></mml:math></inline-formula> and <inline-formula><mml:math id="inf7"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi mathvariant="bold-italic">R</mml:mi></mml:mrow></mml:mstyle></mml:math></inline-formula> are determined by backpropagation of the error signal obtained by two loss functions over the training set. Note that learning of parameter <inline-formula><mml:math id="inf8"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi mathvariant="bold-italic">g</mml:mi></mml:mrow></mml:mstyle></mml:math></inline-formula> occurs only over the training space and is not further modiﬁed during testing (i.e., over the test spaces). The ﬁrst loss function, <inline-formula><mml:math id="inf9"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="script">L</mml:mi></mml:mrow><mml:mrow><mml:mi>D</mml:mi><mml:mi>P</mml:mi><mml:mi>P</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula> favors attentional gatings over the grid cells that maximize the DPP-A objective; that is, the ‘volume’ of the representational space covered by the attended grid cells. The second loss function, <inline-formula><mml:math id="inf10"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="script">L</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi><mml:mi>a</mml:mi><mml:mi>s</mml:mi><mml:mi>k</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula> is a standard task error term (e.g., the cross-entropy of targets <inline-formula><mml:math id="inf11"><mml:semantics><mml:mi>y</mml:mi></mml:semantics></mml:math></inline-formula> and task outputs <inline-formula><mml:math id="inf12"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mrow><mml:mover><mml:mi>y</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow></mml:mrow></mml:mstyle></mml:math></inline-formula> over the training set). We describe each of these components in the following sections.</p><fig id="fig1" position="float"><label>Figure 1.</label><caption><title>Schematic of the overall framework.</title><p>Given a task (e.g., an analogy to solve), inputs (denoted as <inline-formula><mml:math id="inf13"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mo fence="false" stretchy="false">{</mml:mo><mml:mi>A</mml:mi><mml:mo>,</mml:mo><mml:mi>B</mml:mi><mml:mo>,</mml:mo><mml:mi>C</mml:mi><mml:mo>,</mml:mo><mml:mi>D</mml:mi><mml:mo fence="false" stretchy="false">}</mml:mo></mml:mrow></mml:mstyle></mml:math></inline-formula>) are represented by the grid cell code, consisting of units (grid cells) representing different combinations of frequencies and phases. Grid cell embeddings (<inline-formula><mml:math id="inf14"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi mathvariant="bold-italic">x</mml:mi><mml:mrow><mml:mi>A</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula>, <inline-formula><mml:math id="inf15"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi mathvariant="bold-italic">x</mml:mi><mml:mrow><mml:mi>B</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula>, <inline-formula><mml:math id="inf16"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi mathvariant="bold-italic">x</mml:mi><mml:mrow><mml:mi>C</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula>, <inline-formula><mml:math id="inf17"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi mathvariant="bold-italic">x</mml:mi><mml:mrow><mml:mi>D</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula>) are multiplied elementwise (represented as a Hadamard product <inline-formula><mml:math id="inf18"><mml:semantics><mml:mo>⊙</mml:mo></mml:semantics></mml:math></inline-formula>) by a set of learned attention gates <inline-formula><mml:math id="inf19"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi mathvariant="bold-italic">g</mml:mi></mml:mrow></mml:mstyle></mml:math></inline-formula>, then passed to the inference module <inline-formula><mml:math id="inf20"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi mathvariant="bold-italic">R</mml:mi></mml:mrow></mml:mstyle></mml:math></inline-formula>. The attention gates <inline-formula><mml:math id="inf21"><mml:semantics><mml:mi>g</mml:mi></mml:semantics></mml:math></inline-formula> are optimized using <inline-formula><mml:math id="inf22"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="script">L</mml:mi></mml:mrow><mml:mrow><mml:mi>D</mml:mi><mml:mi>P</mml:mi><mml:mi>P</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula>, which encourages attention to grid cell embeddings that maximize the volume of the representational space. The inference module outputs a score for each candidate analogy (consisting of <inline-formula><mml:math id="inf23"><mml:semantics><mml:mrow><mml:mi>A</mml:mi><mml:mo>,</mml:mo><mml:mi>B</mml:mi><mml:mo>,</mml:mo><mml:mi>C</mml:mi></mml:mrow></mml:semantics></mml:math></inline-formula> and a candidate answer choice <inline-formula><mml:math id="inf24"><mml:semantics><mml:mi>D</mml:mi></mml:semantics></mml:math></inline-formula>). The scores for all answer choices are passed through a softmax to generate an answer <inline-formula><mml:math id="inf25"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mrow><mml:mover><mml:mi>y</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow></mml:mrow></mml:mstyle></mml:math></inline-formula>, which is compared against the target <inline-formula><mml:math id="inf26"><mml:semantics><mml:mi>y</mml:mi></mml:semantics></mml:math></inline-formula> to generate the task loss <inline-formula><mml:math id="inf27"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="script">L</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi><mml:mi>a</mml:mi><mml:mi>s</mml:mi><mml:mi>k</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula>.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-89911-fig1-v1.tif"/></fig><sec id="s2-1"><title>Task setup</title><sec id="s2-1-1"><title>Analogy task</title><p>We constructed proportional analogy problems with four terms, of the form <inline-formula><mml:math id="inf28"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>A</mml:mi><mml:mo>:</mml:mo><mml:mi>B</mml:mi><mml:mo>:</mml:mo><mml:mo>:</mml:mo><mml:mi>C</mml:mi><mml:mo>:</mml:mo><mml:mi>D</mml:mi></mml:mrow></mml:mstyle></mml:math></inline-formula>, where the relation between <inline-formula><mml:math id="inf29"><mml:semantics><mml:mi>A</mml:mi></mml:semantics></mml:math></inline-formula> and <inline-formula><mml:math id="inf30"><mml:semantics><mml:mi>B</mml:mi></mml:semantics></mml:math></inline-formula> was the same as between <inline-formula><mml:math id="inf31"><mml:semantics><mml:mi>C</mml:mi></mml:semantics></mml:math></inline-formula> and <inline-formula><mml:math id="inf32"><mml:semantics><mml:mi>D</mml:mi></mml:semantics></mml:math></inline-formula>. Each of <inline-formula><mml:math id="inf33"><mml:semantics><mml:mrow><mml:mi>A</mml:mi><mml:mo>,</mml:mo><mml:mi>B</mml:mi><mml:mo>,</mml:mo><mml:mi>C</mml:mi><mml:mo>,</mml:mo><mml:mi>D</mml:mi></mml:mrow></mml:semantics></mml:math></inline-formula> was a point in the integer space <inline-formula><mml:math id="inf34"><mml:semantics><mml:mrow><mml:msup><mml:mi>ℤ</mml:mi><mml:mn>2</mml:mn></mml:msup></mml:mrow></mml:semantics></mml:math></inline-formula>, with each dimension sampled from the range <inline-formula><mml:math id="inf35"><mml:semantics><mml:mrow><mml:mo stretchy="false">[</mml:mo><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:mi>M</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">]</mml:mo></mml:mrow></mml:semantics></mml:math></inline-formula>, where <inline-formula><mml:math id="inf36"><mml:semantics><mml:mi>M</mml:mi></mml:semantics></mml:math></inline-formula> denotes the size of the training region. To form an analogy, two pairs of points (<inline-formula><mml:math id="inf37"><mml:semantics><mml:mrow><mml:mi>A</mml:mi><mml:mo>,</mml:mo><mml:mi>B</mml:mi></mml:mrow></mml:semantics></mml:math></inline-formula>) and (<inline-formula><mml:math id="inf38"><mml:semantics><mml:mrow><mml:mi>C</mml:mi><mml:mo>,</mml:mo><mml:mi>D</mml:mi></mml:mrow></mml:semantics></mml:math></inline-formula>) were chosen such that the vectors <inline-formula><mml:math id="inf39"><mml:semantics><mml:mrow><mml:mi>A</mml:mi><mml:mi>B</mml:mi></mml:mrow></mml:semantics></mml:math></inline-formula> and <inline-formula><mml:math id="inf40"><mml:semantics><mml:mrow><mml:mi>C</mml:mi><mml:mi>D</mml:mi></mml:mrow></mml:semantics></mml:math></inline-formula> were equal. Each analogy problem also contained a set of six foil items sampled in the range <inline-formula><mml:math id="inf41"><mml:semantics><mml:mrow><mml:msup><mml:mrow><mml:mo stretchy="false">[</mml:mo><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:mi>M</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">]</mml:mo></mml:mrow><mml:mn>2</mml:mn></mml:msup></mml:mrow></mml:semantics></mml:math></inline-formula> excluding <inline-formula><mml:math id="inf42"><mml:semantics><mml:mi>D</mml:mi></mml:semantics></mml:math></inline-formula>, such that they did not form an analogy with <inline-formula><mml:math id="inf43"><mml:semantics><mml:mrow><mml:mi>A</mml:mi><mml:mo>,</mml:mo><mml:mi>B</mml:mi><mml:mo>,</mml:mo><mml:mi>C</mml:mi></mml:mrow></mml:semantics></mml:math></inline-formula>. The task was, given <inline-formula><mml:math id="inf44"><mml:semantics><mml:mi>A</mml:mi></mml:semantics></mml:math></inline-formula>, <inline-formula><mml:math id="inf45"><mml:semantics><mml:mi>B</mml:mi></mml:semantics></mml:math></inline-formula>, and <inline-formula><mml:math id="inf46"><mml:semantics><mml:mi>C</mml:mi></mml:semantics></mml:math></inline-formula>, to select <inline-formula><mml:math id="inf47"><mml:semantics><mml:mi>D</mml:mi></mml:semantics></mml:math></inline-formula> from a set of multiple choices consisting of <inline-formula><mml:math id="inf48"><mml:semantics><mml:mi>D</mml:mi></mml:semantics></mml:math></inline-formula> and the six foil items. During training, the networks were exposed to sets of points sampled uniformly over locations in the training range, and with pairs of points forming vectors of varying length. The network was trained on 80% of all such sets of points in the training range, with 20% held out as the validation set.</p><p>To study OOD generalization, we created two cases of test data, that tested for OOD generalization in translation and scale. For the <italic>translation invariance</italic> case (<xref ref-type="fig" rid="fig2">Figure 2a</xref>), the constituents of the training analogies were translated along both dimensions by the same integer value (obtained by multiplying <inline-formula><mml:math id="inf49"><mml:semantics><mml:mi>K</mml:mi></mml:semantics></mml:math></inline-formula> and <inline-formula><mml:math id="inf50"><mml:semantics><mml:mi>M</mml:mi></mml:semantics></mml:math></inline-formula>, both of which are integer values) such that the test analogies were in the range <inline-formula><mml:math id="inf51"><mml:semantics><mml:mrow><mml:msup><mml:mrow><mml:mo stretchy="false">[</mml:mo><mml:mi>K</mml:mi><mml:mi>M</mml:mi><mml:mo>,</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mi>K</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">)</mml:mo><mml:mi>M</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">]</mml:mo></mml:mrow><mml:mn>2</mml:mn></mml:msup></mml:mrow></mml:semantics></mml:math></inline-formula> after translation. [We transformed by the same amount along both dimensions so that the OOD generalization regimes are similar to <xref ref-type="bibr" rid="bib73">Webb et al., 2020</xref>.] Non-overlapping test regions were generated for <inline-formula><mml:math id="inf52"><mml:semantics><mml:mrow><mml:mi>K</mml:mi><mml:mo>∈</mml:mo><mml:mo stretchy="false">[</mml:mo><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mn>9</mml:mn><mml:mo stretchy="false">]</mml:mo></mml:mrow></mml:semantics></mml:math></inline-formula>. Similar to the translation OOD generalization regime of <xref ref-type="bibr" rid="bib73">Webb et al., 2020</xref>, this allowed the graded evaluation of OOD generalization to a series of increasingly remote test domains as the distance from the training region increased. For example a training analogy <inline-formula><mml:math id="inf53"><mml:semantics><mml:mrow><mml:mi>A</mml:mi><mml:mo>:</mml:mo><mml:mi>B</mml:mi><mml:mo>:</mml:mo><mml:mo>:</mml:mo><mml:mi>C</mml:mi><mml:mo>:</mml:mo><mml:mi>D</mml:mi></mml:mrow></mml:semantics></mml:math></inline-formula> after translation by <inline-formula><mml:math id="inf54"><mml:semantics><mml:mrow><mml:mi>K</mml:mi><mml:mi>M</mml:mi></mml:mrow></mml:semantics></mml:math></inline-formula>, would be <inline-formula><mml:math id="inf55"><mml:semantics><mml:mrow><mml:mi>A</mml:mi><mml:mo>+</mml:mo><mml:mi>K</mml:mi><mml:mi>M</mml:mi><mml:mo>:</mml:mo><mml:mi>B</mml:mi><mml:mo>+</mml:mo><mml:mi>K</mml:mi><mml:mi>M</mml:mi><mml:mo>:</mml:mo><mml:mo>:</mml:mo><mml:mi>C</mml:mi><mml:mo>+</mml:mo><mml:mi>K</mml:mi><mml:mi>M</mml:mi><mml:mo>:</mml:mo><mml:mi>D</mml:mi><mml:mo>+</mml:mo><mml:mi>K</mml:mi><mml:mi>M</mml:mi></mml:mrow></mml:semantics></mml:math></inline-formula>.</p><fig id="fig2" position="float"><label>Figure 2.</label><caption><title>Generation of test analogies from training analogies (region marked in blue) by: (<bold>a</bold>) translating both dimension values of <inline-formula><mml:math id="inf56"><mml:semantics><mml:mrow><mml:mi>A</mml:mi><mml:mo>,</mml:mo><mml:mi>B</mml:mi><mml:mo>,</mml:mo><mml:mi>C</mml:mi><mml:mo>,</mml:mo><mml:mi>D</mml:mi></mml:mrow></mml:semantics></mml:math></inline-formula> by the same amount; and (<bold>b</bold>) scaling both dimension values of <inline-formula><mml:math id="inf57"><mml:semantics><mml:mrow><mml:mi>A</mml:mi><mml:mo>,</mml:mo><mml:mi>B</mml:mi><mml:mo>,</mml:mo><mml:mi>C</mml:mi><mml:mo>,</mml:mo><mml:mi>D</mml:mi></mml:mrow></mml:semantics></mml:math></inline-formula> by the same amount.</title><p>Since both dimension values are transformed by the same amount, each input gets transformed along the diagonal.</p><p><supplementary-material id="fig2sdata1"><label>Figure 2—source data 1.</label><caption><title>The zip file contains the data for the analogy task depicted in <xref ref-type="fig" rid="fig2">Figure 2</xref>.</title></caption><media mimetype="application" mime-subtype="zip" xlink:href="elife-89911-fig2-data1-v1.zip"/></supplementary-material></p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-89911-fig2-v1.tif"/></fig><p>For the <italic>scale invariance</italic> case (<xref ref-type="fig" rid="fig2">Figure 2b</xref>), we scaled each constituent of the training analogies by <inline-formula><mml:math id="inf58"><mml:semantics><mml:mi>K</mml:mi></mml:semantics></mml:math></inline-formula> so that the test analogies after scaling were in the range <inline-formula><mml:math id="inf59"><mml:semantics><mml:mrow><mml:msup><mml:mrow><mml:mo stretchy="false">[</mml:mo><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:mi>K</mml:mi><mml:mi>M</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">]</mml:mo></mml:mrow><mml:mn>2</mml:mn></mml:msup></mml:mrow></mml:semantics></mml:math></inline-formula>. Thus, an analogy <inline-formula><mml:math id="inf60"><mml:semantics><mml:mrow><mml:mi>A</mml:mi><mml:mo>:</mml:mo><mml:mi>B</mml:mi><mml:mo>:</mml:mo><mml:mo>:</mml:mo><mml:mi>C</mml:mi><mml:mo>:</mml:mo><mml:mi>D</mml:mi></mml:mrow></mml:semantics></mml:math></inline-formula> after scaling by <inline-formula><mml:math id="inf61"><mml:semantics><mml:mi>K</mml:mi></mml:semantics></mml:math></inline-formula>, would be <inline-formula><mml:math id="inf62"><mml:semantics><mml:mrow><mml:mi>K</mml:mi><mml:mi>A</mml:mi><mml:mo>:</mml:mo><mml:mi>K</mml:mi><mml:mi>B</mml:mi><mml:mo>:</mml:mo><mml:mo>:</mml:mo><mml:mi>K</mml:mi><mml:mi>C</mml:mi><mml:mo>:</mml:mo><mml:mi>K</mml:mi><mml:mi>D</mml:mi></mml:mrow></mml:semantics></mml:math></inline-formula>. By varying the value of <inline-formula><mml:math id="inf63"><mml:semantics><mml:mi>K</mml:mi></mml:semantics></mml:math></inline-formula> from 1 to 9, we scaled the training analogies to occupy increasingly distant and larger regions of the test space. It is worth noting that while humans can exhibit complex and sophisticated forms of analogical reasoning (<xref ref-type="bibr" rid="bib38">Holyoak, 2012</xref>; <xref ref-type="bibr" rid="bib48">Lu et al., 2022</xref>; <xref ref-type="bibr" rid="bib74">Webb et al., 2023</xref>), here we focused on a relatively simple form, that was inspired by Rumelhart’s parallelogram model of analogy (<xref ref-type="bibr" rid="bib55">Mikolov et al., 2013</xref>; <xref ref-type="bibr" rid="bib61">Rumelhart and Abrahamson, 1973</xref>) that has been used to explain traditional human verbal analogies (e.g., “king is to what as man is to woman?”). Our model, like that one, seeks to explain analogical reasoning in terms of the computation of simple Euclidean distances (i.e., <inline-formula><mml:math id="inf64"><mml:semantics><mml:mrow><mml:mi>A</mml:mi><mml:mo>−</mml:mo><mml:mi>B</mml:mi><mml:mo>=</mml:mo><mml:mi>C</mml:mi><mml:mo>−</mml:mo><mml:mi>D</mml:mi></mml:mrow></mml:semantics></mml:math></inline-formula>, where <inline-formula><mml:math id="inf65"><mml:semantics><mml:mrow><mml:mi>A</mml:mi><mml:mo>,</mml:mo><mml:mi>B</mml:mi><mml:mo>,</mml:mo><mml:mi>C</mml:mi><mml:mo>,</mml:mo><mml:mi>D</mml:mi></mml:mrow></mml:semantics></mml:math></inline-formula> are vectors in 2D space).</p></sec><sec id="s2-1-2"><title>Arithmetic task</title><p>We tested two types of arithmetic operations, corresponding to the translation and scaling transformations used in the analogy tasks: elementwise addition and multiplication of two inputs <inline-formula><mml:math id="inf66"><mml:semantics><mml:mi>A</mml:mi></mml:semantics></mml:math></inline-formula> and <inline-formula><mml:math id="inf67"><mml:semantics><mml:mi>B</mml:mi></mml:semantics></mml:math></inline-formula>, each a point in <inline-formula><mml:math id="inf68"><mml:semantics><mml:mrow><mml:msup><mml:mi>ℤ</mml:mi><mml:mn>2</mml:mn></mml:msup></mml:mrow></mml:semantics></mml:math></inline-formula>, for which <inline-formula><mml:math id="inf69"><mml:semantics><mml:mi>C</mml:mi></mml:semantics></mml:math></inline-formula> was the point corresponding to the answer (i.e., <inline-formula><mml:math id="inf70"><mml:semantics><mml:mrow><mml:mi>C</mml:mi><mml:mo>=</mml:mo><mml:mi>A</mml:mi><mml:mo>+</mml:mo><mml:mi>B</mml:mi></mml:mrow></mml:semantics></mml:math></inline-formula> or <inline-formula><mml:math id="inf71"><mml:semantics><mml:mrow><mml:mi>C</mml:mi><mml:mo>=</mml:mo><mml:mi>A</mml:mi><mml:mo>*</mml:mo><mml:mi>B</mml:mi></mml:mrow></mml:semantics></mml:math></inline-formula>). As with the analogy task, each arithmetic problem also contained a set of six foil items sampled in the range <inline-formula><mml:math id="inf72"><mml:semantics><mml:mrow><mml:msup><mml:mrow><mml:mo stretchy="false">[</mml:mo><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:mi>M</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">]</mml:mo></mml:mrow><mml:mn>2</mml:mn></mml:msup></mml:mrow></mml:semantics></mml:math></inline-formula>, excluding <inline-formula><mml:math id="inf73"><mml:semantics><mml:mi>C</mml:mi></mml:semantics></mml:math></inline-formula>. The task was to select <inline-formula><mml:math id="inf74"><mml:semantics><mml:mi>C</mml:mi></mml:semantics></mml:math></inline-formula> from a set of choices consisting of <inline-formula><mml:math id="inf75"><mml:semantics><mml:mi>C</mml:mi></mml:semantics></mml:math></inline-formula> and the six foil items. Similar to the analogy task, training data was constructed from a uniform distribution of points and vector lengths in the training range, with 20% held out as the validation set. To study OOD generalization, we created testing data corresponding to <inline-formula><mml:math id="inf76"><mml:semantics><mml:mrow><mml:mi>K</mml:mi><mml:mo>=</mml:mo><mml:mn>9</mml:mn></mml:mrow></mml:semantics></mml:math></inline-formula> non-overlapping regions, such that <inline-formula><mml:math id="inf77"><mml:semantics><mml:mrow><mml:mi>C</mml:mi><mml:mo>∈</mml:mo><mml:msup><mml:mrow><mml:mo stretchy="false">[</mml:mo><mml:mi>M</mml:mi><mml:mo>,</mml:mo><mml:mn>2</mml:mn><mml:mi>M</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">]</mml:mo></mml:mrow><mml:mn>2</mml:mn></mml:msup><mml:mo>,</mml:mo><mml:msup><mml:mrow><mml:mo stretchy="false">[</mml:mo><mml:mn>2</mml:mn><mml:mi>M</mml:mi><mml:mo>,</mml:mo><mml:mn>3</mml:mn><mml:mi>M</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">]</mml:mo></mml:mrow><mml:mn>2</mml:mn></mml:msup><mml:mo>,</mml:mo><mml:mn>...</mml:mn><mml:msup><mml:mrow><mml:mo stretchy="false">[</mml:mo><mml:mi>K</mml:mi><mml:mi>M</mml:mi><mml:mo>,</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mi>K</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">)</mml:mo><mml:mi>M</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">]</mml:mo></mml:mrow><mml:mn>2</mml:mn></mml:msup></mml:mrow></mml:semantics></mml:math></inline-formula>.</p></sec></sec><sec id="s2-2"><title>Architecture</title><sec id="s2-2-1"><title>Grid cell code</title><p>As discussed above, the grid cell code is found in the mammalian neocortex, that support structured, low-dimensional representations of task-relevant information. For example, an organism’s location in 2D allocentric space (<xref ref-type="bibr" rid="bib31">Hafting et al., 2005</xref>), the frequency of 1D auditory stimuli (<xref ref-type="bibr" rid="bib1">Aronov et al., 2017</xref>), and conceptual knowledge in two continuous dimensions <xref ref-type="bibr" rid="bib21">Doeller et al., 2010</xref>; <xref ref-type="bibr" rid="bib17">Constantinescu et al., 2016</xref> have all been shown to be represented as unique, similarity-preserving combinations of frequencies and phases. Here, these codes are of interest because the relational structure in the input is preserved in the code across translation and scale. This oﬀers a promising metric that can be used to learn structure relevant to the processing of analogies (<xref ref-type="bibr" rid="bib25">Frankland et al., 2019</xref>) and arithmetic over a restricted range of stimulus values, and then used to generalize such processing to stimuli outside of the domain of task training.</p><p>To derive the grid cell code for stimuli, we follow the analytic approach described by <xref ref-type="bibr" rid="bib9">Bicanski and Burgess, 2019</xref> (<ext-link ext-link-type="uri" xlink:href="https://github.com/bicanski/VisualGridsRecognitionMem">https://github.com/bicanski/VisualGridsRecognitionMem</ext-link>; <xref ref-type="bibr" rid="bib8">Bicanski, 2019</xref>). Speciﬁcally, the grid cell embedding for a particular stimulus location <inline-formula><mml:math id="inf78"><mml:semantics><mml:mi>A</mml:mi></mml:semantics></mml:math></inline-formula> is given by:<disp-formula id="equ1"><label>(1)</label><mml:math id="m1"><mml:mrow><mml:msub><mml:mi mathvariant="bold-italic">x</mml:mi><mml:mrow><mml:mi>A</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mo movablelimits="true" form="prefix">max</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:mi>cos</mml:mi><mml:mo>⁡</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi mathvariant="bold-italic">z</mml:mi><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:mo>+</mml:mo><mml:mi>cos</mml:mi><mml:mo>⁡</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi mathvariant="bold-italic">z</mml:mi><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:mo>+</mml:mo><mml:mi>cos</mml:mi><mml:mo>⁡</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi mathvariant="bold-italic">z</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></disp-formula></p><p>where,<disp-formula id="equ2"><label>(2)</label><mml:math id="m2"><mml:mrow><mml:msub><mml:mi mathvariant="bold-italic">z</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:msub><mml:mi mathvariant="bold-italic">b</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>∗</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>F</mml:mi><mml:mi>A</mml:mi><mml:mo>+</mml:mo><mml:msub><mml:mi>A</mml:mi><mml:mrow><mml:mi>o</mml:mi><mml:mi>f</mml:mi><mml:mi>f</mml:mi><mml:mi>s</mml:mi><mml:mi>e</mml:mi><mml:mi>t</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></disp-formula><disp-formula id="equ3"><label>(3)</label><mml:math id="m3"><mml:mrow><mml:msub><mml:mi mathvariant="bold-italic">b</mml:mi><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mtable rowspacing="4pt" columnspacing="1em"><mml:mtr><mml:mtd><mml:mi>cos</mml:mi><mml:mo>⁡</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mn>0</mml:mn><mml:mo>)</mml:mo></mml:mrow></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mi>sin</mml:mi><mml:mo>⁡</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mn>0</mml:mn><mml:mo>)</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable><mml:mo>)</mml:mo></mml:mrow><mml:mo>,</mml:mo><mml:mspace width="thinmathspace"/><mml:msub><mml:mi mathvariant="bold-italic">b</mml:mi><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mtable rowspacing="4pt" columnspacing="1em"><mml:mtr><mml:mtd><mml:mi>cos</mml:mi><mml:mo>⁡</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mfrac><mml:mi>π</mml:mi><mml:mn>3</mml:mn></mml:mfrac><mml:mo>)</mml:mo></mml:mrow></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mi>sin</mml:mi><mml:mo>⁡</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mfrac><mml:mi>π</mml:mi><mml:mn>3</mml:mn></mml:mfrac><mml:mo>)</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable><mml:mo>)</mml:mo></mml:mrow><mml:mo>,</mml:mo><mml:mspace width="thinmathspace"/><mml:msub><mml:mi mathvariant="bold-italic">b</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mtable rowspacing="4pt" columnspacing="1em"><mml:mtr><mml:mtd><mml:mi>cos</mml:mi><mml:mo>⁡</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mfrac><mml:mrow><mml:mn>2</mml:mn><mml:mi>π</mml:mi></mml:mrow><mml:mn>3</mml:mn></mml:mfrac><mml:mo>)</mml:mo></mml:mrow></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mi>sin</mml:mi><mml:mo>⁡</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mfrac><mml:mrow><mml:mn>2</mml:mn><mml:mi>π</mml:mi></mml:mrow><mml:mn>3</mml:mn></mml:mfrac><mml:mo>)</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></disp-formula></p><p>The spatial frequencies of grids (<inline-formula><mml:math id="inf79"><mml:semantics><mml:mi>F</mml:mi></mml:semantics></mml:math></inline-formula>) begin at a value of <inline-formula><mml:math id="inf80"><mml:semantics><mml:mrow><mml:mn>0.0028</mml:mn><mml:mo>*</mml:mo><mml:mn>2</mml:mn><mml:mi>π</mml:mi></mml:mrow></mml:semantics></mml:math></inline-formula>. <xref ref-type="bibr" rid="bib75">Wei et al., 2015</xref> have shown that, to minimize the number of variables needed to represent an integer domain of size <inline-formula><mml:math id="inf81"><mml:semantics><mml:mi>S</mml:mi></mml:semantics></mml:math></inline-formula>, the ﬁring rate widths and frequencies should scale geometrically in a range <inline-formula><mml:math id="inf82"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msqrt><mml:mn>2</mml:mn></mml:msqrt><mml:mo>,</mml:mo><mml:msqrt><mml:mi>e</mml:mi></mml:msqrt><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mstyle></mml:math></inline-formula>, closely matching empirically observed scaling in entorhinal cortex (<xref ref-type="bibr" rid="bib69">Stensola et al., 2012</xref>). We choose a scaling factor of <inline-formula><mml:math id="inf83"><mml:semantics><mml:mrow><mml:msqrt><mml:mn>2</mml:mn></mml:msqrt></mml:mrow></mml:semantics></mml:math></inline-formula> to eﬃciently tile the space. One consequence of this eﬃciency is that the total number of discrete frequencies in the entorhinal cortex is expected to be small. Empirically, it has been estimated to be between 8 and 12 (<xref ref-type="bibr" rid="bib57">Moser et al., 2015</xref>) [It seems likely that the use of grid cell code for abstraction in human cognition requires a considerably greater number of states <italic>S</italic> than that used by the rodent for sensory encoding. However, given exponential scaling, the total number of frequencies is expected to remain low, increasing as a logarithm of <italic>S</italic>.]. Here, we choose <inline-formula><mml:math id="inf84"><mml:semantics><mml:mrow><mml:msub><mml:mi>N</mml:mi><mml:mi>f</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mn>9</mml:mn></mml:mrow></mml:semantics></mml:math></inline-formula> (dimension of <inline-formula><mml:math id="inf85"><mml:semantics><mml:mi>F</mml:mi></mml:semantics></mml:math></inline-formula>) as the number of frequencies. <inline-formula><mml:math id="inf86"><mml:semantics><mml:mi>A</mml:mi></mml:semantics></mml:math></inline-formula> refers to a particular location in a two dimensional space, and 100 oﬀsets (<inline-formula><mml:math id="inf87"><mml:semantics><mml:mrow><mml:msub><mml:mi>A</mml:mi><mml:mrow><mml:mi>o</mml:mi><mml:mi>f</mml:mi><mml:mi>f</mml:mi><mml:mi>s</mml:mi><mml:mi>e</mml:mi><mml:mi>t</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:semantics></mml:math></inline-formula>) are used for each frequency to evenly cover a space of 1000 × 1000 locations using 900 grid cells. These oﬀsets represent diﬀerent phases within each frequency and since there are 100 of them, <inline-formula><mml:math id="inf88"><mml:semantics><mml:mrow><mml:msub><mml:mi>N</mml:mi><mml:mi>p</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mn>100</mml:mn></mml:mrow></mml:semantics></mml:math></inline-formula>. Hence <inline-formula><mml:math id="inf89"><mml:semantics><mml:mrow><mml:msub><mml:mi>N</mml:mi><mml:mi>p</mml:mi></mml:msub><mml:mo>×</mml:mo><mml:msub><mml:mi>N</mml:mi><mml:mi>f</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mn>900</mml:mn></mml:mrow></mml:semantics></mml:math></inline-formula>, which denotes the number of grid cells. Each point from the set of 2D points for the stimuli in a task (described in Task setup), was represented using the ﬁring rate of 900 grid cells which constituted the grid cell embedding for that point to form the inputs to our model.</p></sec><sec id="s2-2-2"><title>DPP-A</title><p>We hypothesize that the use of a relational encoding metric (i.e., grid cell code) is extremely useful, but not suﬃcient for a system to achieve strong generalization, which requires attending to particular aspects of the encoding that can capture the same relational structure across the training and test distributions. Toward this end, we propose an attentional objective that uses the statistics of the training data to attend to grid cell embeddings that can induce the inference module to achieve strong generalization. Our objective, which we describe in detail below, seeks to identify those grid cell embeddings that exhibit the greatest variance but are least redundant (pairwise uncorrelated over the training data). Formally, this is captured by maximizing the determinant of the covariance matrix of the grid cell embeddings computed over the training data (<xref ref-type="bibr" rid="bib46">Kulesza and Taskar, 2012</xref>). Although in machine learning, DPPs have been particularly inﬂuential in work on recommender systems (<xref ref-type="bibr" rid="bib15">Chen et al., 2018</xref>), summarization (<xref ref-type="bibr" rid="bib30">Gong et al., 2014</xref>; <xref ref-type="bibr" rid="bib59">Perez-Beltrachini and Lapata, 2021</xref>), and neural network pruning (<xref ref-type="bibr" rid="bib50">Mariet and Sra, 2015</xref>), here, we propose to use maximization of the determinant of the covariance matrix as an attentional mechanism to limit the inﬂuence of grid cell embeddings with low-variance (which are less relevant) or with high similarity to other grid cell embeddings (which are redundant).</p><p>For the speciﬁc tasks that we study here, we have assumed the grid cell embeddings to be pre-learned to represent the entire space of possible test data points, and we are simply focused on the problem of how to determine which of these are most useful in enabling generalization for a task-optimized network trained on a small fraction of that space (<xref ref-type="fig" rid="fig2">Figure 2</xref>). That is, we look for a way to attend to a subset of grid cells frequencies whose embeddings capture recurring task-relevant relational structure. We ﬁnd that grid cell embeddings corresponding to the higher spatial frequency grid cells exhibit greater variance over the training data than the lower-frequency embeddings, while at the same time the correlations among those grid cell embeddings are lower than the correlations among the lower-frequency grid cell embeddings. The determinant of the covariance matrix of the grid cell embeddings is maximized when the variances of the grid cell embeddings are high (they are ‘expressive’) and the correlation among the grid cell embeddings is low (they ‘cover the representational space’). As a result, the higher-frequency grid cell embeddings more eﬃciently cover the representational space of the training data, allowing them to eﬃciently capture the same relational structure across training and test distributions which is required for OOD generalization.</p><table-wrap id="inlinetable1" position="anchor"><table frame="hsides" rules="groups"><thead><tr><th align="left" valign="bottom">Algorithm 1. Training with DPP-A</th></tr></thead><tbody><tr><td align="left" valign="bottom"><bold>Parameters:</bold> inference module <inline-formula><mml:math id="inf90"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi mathvariant="bold-italic">R</mml:mi></mml:mrow></mml:mstyle></mml:math></inline-formula>, attention gates <inline-formula><mml:math id="inf91"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi mathvariant="bold-italic">g</mml:mi></mml:mrow></mml:mstyle></mml:math></inline-formula><break/><bold>Hyperparameters:</bold> number of frequencies <inline-formula><mml:math id="inf92"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>N</mml:mi><mml:mi>f</mml:mi></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula>, number of phases <inline-formula><mml:math id="inf93"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>N</mml:mi><mml:mi>p</mml:mi></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula>, number of epochs optimizing DPP attention <inline-formula><mml:math id="inf94"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>N</mml:mi><mml:mrow><mml:msub><mml:mi>E</mml:mi><mml:mrow><mml:mi>D</mml:mi><mml:mi>P</mml:mi><mml:mi>P</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula>, number of epochs optimizing task loss <inline-formula><mml:math id="inf95"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>N</mml:mi><mml:mrow><mml:msub><mml:mi>E</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mi>a</mml:mi><mml:mi>s</mml:mi><mml:mi>k</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula>, number of batches per epoch <inline-formula><mml:math id="inf96"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>N</mml:mi><mml:mi>b</mml:mi></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula><break/><bold>Inputs:</bold> covariance matrix <inline-formula><mml:math id="inf97"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi mathvariant="bold-italic">V</mml:mi></mml:mrow></mml:mstyle></mml:math></inline-formula>, grid cell embeddings <inline-formula><mml:math id="inf98"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi mathvariant="bold-italic">x</mml:mi></mml:mrow></mml:mstyle></mml:math></inline-formula> and targets <inline-formula><mml:math id="inf99"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>y</mml:mi></mml:mrow></mml:mstyle></mml:math></inline-formula> for all training problems</td></tr><tr><td align="left" valign="bottom">Initialize <inline-formula><mml:math id="inf100"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi mathvariant="bold-italic">g</mml:mi></mml:mrow></mml:mstyle></mml:math></inline-formula>, <inline-formula><mml:math id="inf101"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi mathvariant="bold-italic">R</mml:mi></mml:mrow></mml:mstyle></mml:math></inline-formula><break/><bold>for</bold> <inline-formula><mml:math id="inf102"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:mstyle></mml:math></inline-formula> <bold>to</bold> <inline-formula><mml:math id="inf103"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>N</mml:mi><mml:mrow><mml:msub><mml:mi>E</mml:mi><mml:mrow><mml:mi>D</mml:mi><mml:mi>P</mml:mi><mml:mi>P</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula> <bold>do</bold><break/><bold>    for</bold> <inline-formula><mml:math id="inf104"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>j</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:mstyle></mml:math></inline-formula> <bold>to</bold> <inline-formula><mml:math id="inf105"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>N</mml:mi><mml:mrow><mml:mi>b</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula> <bold>do</bold><break/>      <inline-formula><mml:math id="inf106"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mover><mml:mi>F</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi mathvariant="bold-italic">g</mml:mi><mml:mo>,</mml:mo><mml:mi mathvariant="bold-italic">V</mml:mi><mml:mo>,</mml:mo><mml:msub><mml:mi>N</mml:mi><mml:mrow><mml:mi>f</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>N</mml:mi><mml:mrow><mml:mi>p</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:munderover><mml:mo movablelimits="false">∑</mml:mo><mml:mrow><mml:mi>f</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:msub><mml:mi>N</mml:mi><mml:mrow><mml:mi>f</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:munderover><mml:mrow><mml:mi>log</mml:mi><mml:mspace width="thinmathspace"/><mml:mo movablelimits="true" form="prefix">det</mml:mo></mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mrow><mml:mi mathvariant="normal">d</mml:mi><mml:mi mathvariant="normal">i</mml:mi><mml:mi mathvariant="normal">a</mml:mi><mml:mi mathvariant="normal">g</mml:mi></mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>σ</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi mathvariant="bold-italic">g</mml:mi><mml:mrow><mml:mi mathvariant="bold-italic">f</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi mathvariant="bold-italic">V</mml:mi><mml:mi mathvariant="bold-italic">f</mml:mi></mml:msub><mml:mo>−</mml:mo><mml:mi mathvariant="bold-italic">I</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>+</mml:mo><mml:mi mathvariant="bold-italic">I</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mstyle></mml:mrow></mml:mstyle></mml:math></inline-formula><break/>       <inline-formula><mml:math id="inf107"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mrow><mml:mi class="mathcal" mathvariant="script">L</mml:mi></mml:mrow><mml:mrow><mml:mi>D</mml:mi><mml:mi>P</mml:mi><mml:mi>P</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mo>−</mml:mo><mml:mrow><mml:mover><mml:mi>F</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi mathvariant="bold-italic">g</mml:mi><mml:mo>,</mml:mo><mml:mi mathvariant="bold-italic">V</mml:mi><mml:mo>,</mml:mo><mml:msub><mml:mi>N</mml:mi><mml:mrow><mml:mi>f</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>N</mml:mi><mml:mrow><mml:mi>p</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mstyle></mml:math></inline-formula><break/>       Update <inline-formula><mml:math id="inf108"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi mathvariant="bold-italic">g</mml:mi></mml:mrow></mml:mstyle></mml:math></inline-formula><break/><bold>    end for</bold><break/><bold>end for</bold><break/><inline-formula><mml:math id="inf109"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mrow><mml:mover><mml:mi>F</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>f</mml:mi><mml:mo>∈</mml:mo><mml:mrow><mml:mo>[</mml:mo><mml:mrow><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:msub><mml:mi>N</mml:mi><mml:mrow><mml:mi>f</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>]</mml:mo></mml:mrow></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mrow><mml:mi>log</mml:mi><mml:mo>⁡</mml:mo><mml:mo movablelimits="true" form="prefix">det</mml:mo></mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mrow><mml:mi mathvariant="normal">d</mml:mi><mml:mi mathvariant="normal">i</mml:mi><mml:mi mathvariant="normal">a</mml:mi><mml:mi mathvariant="normal">g</mml:mi></mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>σ</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi mathvariant="bold-italic">g</mml:mi><mml:mi mathvariant="bold-italic">f</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi mathvariant="bold-italic">V</mml:mi><mml:mi mathvariant="bold-italic">f</mml:mi></mml:msub><mml:mo>−</mml:mo><mml:mi mathvariant="bold-italic">I</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>+</mml:mo><mml:mi mathvariant="bold-italic">I</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mstyle></mml:math></inline-formula><break/><inline-formula><mml:math id="inf110"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>f</mml:mi><mml:mrow><mml:msub><mml:mrow><mml:mi>m</mml:mi><mml:mi>a</mml:mi><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mi>D</mml:mi><mml:mi>P</mml:mi><mml:mi>P</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:msub><mml:mrow><mml:mi>arg</mml:mi><mml:mo>⁡</mml:mo><mml:mo movablelimits="true" form="prefix">max</mml:mo></mml:mrow><mml:mrow><mml:mi>f</mml:mi><mml:mo>∈</mml:mo><mml:mrow><mml:mo>[</mml:mo><mml:mrow><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:msub><mml:mi>N</mml:mi><mml:mrow><mml:mi>f</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>]</mml:mo></mml:mrow></mml:mrow></mml:msub><mml:msub><mml:mrow><mml:mover><mml:mi>F</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>f</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula><break/><bold>for</bold> <inline-formula><mml:math id="inf111"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:mstyle></mml:math></inline-formula> <bold>to</bold> <inline-formula><mml:math id="inf112"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>N</mml:mi><mml:mrow><mml:msub><mml:mi>E</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mi>a</mml:mi><mml:mi>s</mml:mi><mml:mi>k</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula> <bold>do</bold><break/><bold>    for</bold> <inline-formula><mml:math id="inf113"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>j</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:mstyle></mml:math></inline-formula> <bold>to</bold> <inline-formula><mml:math id="inf114"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>N</mml:mi><mml:mrow><mml:mi>b</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula> <bold>do</bold><break/>        <inline-formula><mml:math id="inf115"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mrow><mml:mover><mml:mi>y</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mo>=</mml:mo><mml:mi mathvariant="bold-italic">R</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi mathvariant="bold-italic">x</mml:mi><mml:mrow><mml:mi>f</mml:mi><mml:mo>=</mml:mo><mml:msub><mml:mi>f</mml:mi><mml:mrow><mml:msub><mml:mrow><mml:mi>m</mml:mi><mml:mi>a</mml:mi><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mi>D</mml:mi><mml:mi>P</mml:mi><mml:mi>P</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:msub></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mstyle></mml:math></inline-formula><break/>       <inline-formula><mml:math id="inf116"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mrow><mml:mi class="mathcal" mathvariant="script">L</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi><mml:mi>a</mml:mi><mml:mi>s</mml:mi><mml:mi>k</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mrow><mml:mi mathvariant="normal">c</mml:mi><mml:mi mathvariant="normal">r</mml:mi><mml:mi mathvariant="normal">o</mml:mi><mml:mi mathvariant="normal">s</mml:mi><mml:mi mathvariant="normal">s</mml:mi><mml:mtext>-</mml:mtext><mml:mi mathvariant="normal">e</mml:mi><mml:mi mathvariant="normal">n</mml:mi><mml:mi mathvariant="normal">t</mml:mi><mml:mi mathvariant="normal">r</mml:mi><mml:mi mathvariant="normal">o</mml:mi><mml:mi mathvariant="normal">p</mml:mi><mml:mi mathvariant="normal">y</mml:mi></mml:mrow><mml:mo>⁡</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mover><mml:mi>y</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mo>,</mml:mo><mml:mi>y</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mstyle></mml:math></inline-formula><break/>        Update <inline-formula><mml:math id="inf117"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi mathvariant="bold-italic">R</mml:mi></mml:mrow></mml:mstyle></mml:math></inline-formula><break/><bold>    end for<break/>end for<break/></bold></td></tr></tbody></table></table-wrap><p>Formally, we treat obtaining <inline-formula><mml:math id="inf118"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="script">L</mml:mi></mml:mrow><mml:mrow><mml:mi>D</mml:mi><mml:mi>P</mml:mi><mml:mi>P</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula> as an approximation of a DPP. A DPP <inline-formula><mml:math id="inf119"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mrow><mml:mi mathvariant="script">P</mml:mi></mml:mrow></mml:mrow></mml:mstyle></mml:math></inline-formula> deﬁnes a probability measure on all subsets of a set of items <inline-formula><mml:math id="inf120"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mrow><mml:mi mathvariant="bold-script">U</mml:mi></mml:mrow><mml:mo>=</mml:mo><mml:mo fence="false" stretchy="false">{</mml:mo><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mn>2</mml:mn><mml:mo>,</mml:mo><mml:mo>.</mml:mo><mml:mo>.</mml:mo><mml:mo>.</mml:mo><mml:mi>N</mml:mi><mml:mo fence="false" stretchy="false">}</mml:mo></mml:mrow></mml:mstyle></mml:math></inline-formula>. For every <inline-formula><mml:math id="inf121"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi mathvariant="bold-italic">u</mml:mi><mml:mo>⊆</mml:mo><mml:mrow><mml:mi mathvariant="bold-script">U</mml:mi></mml:mrow></mml:mrow></mml:mstyle></mml:math></inline-formula>, <inline-formula><mml:math id="inf122"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>P</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi mathvariant="bold-italic">u</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>∝</mml:mo><mml:mo movablelimits="true" form="prefix">det</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:msub><mml:mi mathvariant="bold-italic">V</mml:mi><mml:mi mathvariant="bold-italic">u</mml:mi></mml:msub><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mstyle></mml:math></inline-formula>. Here, <inline-formula><mml:math id="inf123"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi mathvariant="bold-italic">V</mml:mi></mml:mrow></mml:mstyle></mml:math></inline-formula> is a positive semideﬁnite covariance matrix and <inline-formula><mml:math id="inf124"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi mathvariant="bold-italic">V</mml:mi><mml:mi mathvariant="bold-italic">u</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:msub><mml:mrow><mml:mo>[</mml:mo><mml:msub><mml:mi>V</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>]</mml:mo></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>j</mml:mi><mml:mo>∈</mml:mo><mml:mi mathvariant="bold-italic">u</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula> denotes the matrix <inline-formula><mml:math id="inf125"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi mathvariant="bold-italic">V</mml:mi></mml:mrow></mml:mstyle></mml:math></inline-formula> restricted to the entries indexed by elements of <inline-formula><mml:math id="inf126"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi mathvariant="bold-italic">u</mml:mi></mml:mrow></mml:mstyle></mml:math></inline-formula>. The maximum a posteriori (MAP) problem <inline-formula><mml:math id="inf127"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>a</mml:mi><mml:mi>r</mml:mi><mml:mi>g</mml:mi><mml:mi>m</mml:mi><mml:mi>a</mml:mi><mml:mi>x</mml:mi></mml:mrow><mml:mi mathvariant="bold-italic">u</mml:mi></mml:msub></mml:mrow><mml:mo movablelimits="true" form="prefix">det</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi mathvariant="bold-italic">V</mml:mi><mml:mi mathvariant="bold-italic">u</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mstyle></mml:math></inline-formula> is NP-hard (<xref ref-type="bibr" rid="bib44">Ko et al., 1995</xref>). However, <inline-formula><mml:math id="inf128"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>f</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi mathvariant="bold-italic">u</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mi>log</mml:mi><mml:mo>⁡</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mo movablelimits="true" form="prefix">det</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi mathvariant="bold-italic">V</mml:mi><mml:mi mathvariant="bold-italic">u</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mstyle></mml:math></inline-formula> satisﬁes the property of a submodular function, and various algorithms exist for approximately maximizing them. One common way is to approximate this discrete optimization problem by replacing the discrete variables with continuous variables and extending the objective function to the continuous domain. <xref ref-type="bibr" rid="bib28">Gillenwater et al., 2012</xref> proposed a continuous extension that is eﬃciently computable and diﬀerentiable:<disp-formula id="equ4"><label>(4)</label><mml:math id="m4"><mml:mrow><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mover><mml:mi>F</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi mathvariant="bold-italic">w</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mi>log</mml:mi><mml:mo>⁡</mml:mo><mml:munder><mml:mo>∑</mml:mo><mml:mi mathvariant="bold-italic">u</mml:mi></mml:munder><mml:munder><mml:mo>∏</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>∈</mml:mo><mml:mi mathvariant="bold-italic">u</mml:mi></mml:mrow></mml:munder><mml:msub><mml:mi>w</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:munder><mml:mo>∏</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>∈</mml:mo><mml:mi mathvariant="bold-italic">u</mml:mi></mml:mrow></mml:munder><mml:mo stretchy="false">(</mml:mo><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:msub><mml:mi>w</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:mi>exp</mml:mi><mml:mo>⁡</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>f</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi mathvariant="bold-italic">u</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>,</mml:mo><mml:mi mathvariant="bold-italic">w</mml:mi><mml:mo>∈</mml:mo><mml:msup><mml:mrow><mml:mo>[</mml:mo><mml:mrow><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mo>]</mml:mo></mml:mrow><mml:mrow><mml:mi>N</mml:mi></mml:mrow></mml:msup><mml:mo>.</mml:mo></mml:mstyle></mml:mrow></mml:math></disp-formula></p><p>We use the following theorem from <xref ref-type="bibr" rid="bib28">Gillenwater et al., 2012</xref> to construct <inline-formula><mml:math id="inf129"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="script">L</mml:mi></mml:mrow><mml:mrow><mml:mi>D</mml:mi><mml:mi>P</mml:mi><mml:mi>P</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula>:</p><sec id="s2-2-2-1"><title>Theorem 2.1</title><p>For a positive semideﬁnite matrix <inline-formula><mml:math id="inf130"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi mathvariant="bold-italic">V</mml:mi></mml:mrow></mml:mstyle></mml:math></inline-formula> and <inline-formula><mml:math id="inf131"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mrow><mml:mi mathvariant="bold-italic">w</mml:mi></mml:mrow><mml:mo>∈</mml:mo><mml:msup><mml:mrow><mml:mo>[</mml:mo><mml:mrow><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mo>]</mml:mo></mml:mrow><mml:mrow><mml:mi>N</mml:mi></mml:mrow></mml:msup></mml:mrow></mml:mstyle></mml:math></inline-formula>:<disp-formula id="equ5"><label>(5)</label><mml:math id="m5"><mml:mrow><mml:mstyle displaystyle="true" scriptlevel="0"><mml:munder><mml:mo>∑</mml:mo><mml:mi mathvariant="bold-italic">u</mml:mi></mml:munder><mml:munder><mml:mo>∏</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>∈</mml:mo><mml:mi mathvariant="bold-italic">u</mml:mi></mml:mrow></mml:munder><mml:msub><mml:mi>w</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:munder><mml:mo>∏</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>∈</mml:mo><mml:mi mathvariant="bold-italic">u</mml:mi></mml:mrow></mml:munder><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:msub><mml:mi>w</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo movablelimits="true" form="prefix">det</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:msub><mml:mi mathvariant="bold-italic">V</mml:mi><mml:mi mathvariant="bold-italic">u</mml:mi></mml:msub><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mo movablelimits="true" form="prefix">det</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mrow><mml:mi mathvariant="normal">d</mml:mi><mml:mi mathvariant="normal">i</mml:mi><mml:mi mathvariant="normal">a</mml:mi><mml:mi mathvariant="normal">g</mml:mi></mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mi mathvariant="bold-italic">w</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi mathvariant="bold-italic">V</mml:mi><mml:mo>−</mml:mo><mml:mi mathvariant="bold-italic">I</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>+</mml:mo><mml:mi mathvariant="bold-italic">I</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mstyle></mml:mrow></mml:math></disp-formula></p><p>We propose an attention mechanism that uses <inline-formula><mml:math id="inf132"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mrow><mml:mi class="mathcal" mathvariant="script">L</mml:mi></mml:mrow><mml:mrow><mml:mi>D</mml:mi><mml:mi>P</mml:mi><mml:mi>P</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula> to attend to subsets of grid cell embeddings for further processing. Algorithm 1 describes the training procedure with DPP-A which consists of two steps, using <inline-formula><mml:math id="inf133"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="script">L</mml:mi></mml:mrow><mml:mrow><mml:mi>D</mml:mi><mml:mi>P</mml:mi><mml:mi>P</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula> as the ﬁrst step. This step maximizes the objective function:<disp-formula id="equ6"><label>(6)</label><mml:math id="m6"><mml:mrow><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mover><mml:mi>F</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi mathvariant="bold-italic">g</mml:mi><mml:mo>,</mml:mo><mml:mi mathvariant="bold-italic">V</mml:mi><mml:mo>,</mml:mo><mml:msub><mml:mi>N</mml:mi><mml:mrow><mml:mi>f</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>N</mml:mi><mml:mrow><mml:mi>p</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:munderover><mml:mo movablelimits="false">∑</mml:mo><mml:mrow><mml:mi>f</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:msub><mml:mi>N</mml:mi><mml:mrow><mml:mi>f</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:munderover><mml:mrow><mml:mi>log</mml:mi><mml:mo>⁡</mml:mo><mml:mo movablelimits="true" form="prefix">det</mml:mo></mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mrow><mml:mi mathvariant="normal">d</mml:mi><mml:mi mathvariant="normal">i</mml:mi><mml:mi mathvariant="normal">a</mml:mi><mml:mi mathvariant="normal">g</mml:mi></mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>σ</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi mathvariant="bold-italic">g</mml:mi><mml:mi mathvariant="bold-italic">f</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi mathvariant="bold-italic">V</mml:mi><mml:mi mathvariant="bold-italic">f</mml:mi></mml:msub><mml:mo>−</mml:mo><mml:mi>I</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>+</mml:mo><mml:mi mathvariant="bold-italic">I</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mstyle></mml:mrow></mml:math></disp-formula></p><p>using stochastic gradient ascent for <inline-formula><mml:math id="inf134"><mml:semantics><mml:mrow><mml:msub><mml:mi>N</mml:mi><mml:mrow><mml:msub><mml:mi>E</mml:mi><mml:mrow><mml:mi>D</mml:mi><mml:mi>P</mml:mi><mml:mi>P</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:msub></mml:mrow></mml:semantics></mml:math></inline-formula> epochs, which is equivalent to minimizing <inline-formula><mml:math id="inf135"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mrow><mml:mi class="mathcal" mathvariant="script">L</mml:mi></mml:mrow><mml:mrow><mml:mi>D</mml:mi><mml:mi>P</mml:mi><mml:mi>P</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula>, as <inline-formula><mml:math id="inf136"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mrow><mml:mi class="mathcal" mathvariant="script">L</mml:mi></mml:mrow><mml:mrow><mml:mi>D</mml:mi><mml:mi>P</mml:mi><mml:mi>P</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mo>−</mml:mo><mml:mrow><mml:mover><mml:mi>F</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi mathvariant="bold-italic">g</mml:mi><mml:mo>,</mml:mo><mml:mi mathvariant="bold-italic">V</mml:mi><mml:mo>,</mml:mo><mml:msub><mml:mi>N</mml:mi><mml:mrow><mml:mi>f</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>N</mml:mi><mml:mrow><mml:mi>p</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mstyle></mml:math></inline-formula>. It involves attending to grid cell embeddings that exhibit the greatest within-frequency variance but are least redundant (i.e., that are least also pairwise uncorrelated) over the training data. This is achieved by maximizing the determinant of the covariance matrix over the within-frequency grid cell embeddings of the training data, and <xref ref-type="disp-formula" rid="equ6">Equation 6</xref> is obtained by applying log on both sides of the Theorem 2.1, and in our case <inline-formula><mml:math id="inf137"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mrow><mml:mi mathvariant="bold-script">U</mml:mi></mml:mrow></mml:mrow></mml:mstyle></mml:math></inline-formula> refers to grid cells of a particular frequency. Here, <inline-formula><mml:math id="inf138"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi mathvariant="bold-italic">g</mml:mi></mml:mrow></mml:mstyle></mml:math></inline-formula> are the attention gates corresponding to each grid cell, and <inline-formula><mml:math id="inf139"><mml:semantics><mml:mrow><mml:msub><mml:mi>N</mml:mi><mml:mi>f</mml:mi></mml:msub></mml:mrow></mml:semantics></mml:math></inline-formula> is the number of distinct frequencies. The matrix <inline-formula><mml:math id="inf140"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi mathvariant="bold-italic">V</mml:mi></mml:mrow></mml:mstyle></mml:math></inline-formula> captures a measure of the covariance of the grid cell embeddings over the training region. We used the <inline-formula><mml:math id="inf141"><mml:semantics><mml:mrow><mml:mi>s</mml:mi><mml:mi>y</mml:mi><mml:mi>n</mml:mi><mml:mi>t</mml:mi><mml:mi>h</mml:mi><mml:mo>_</mml:mo><mml:mi>k</mml:mi><mml:mi>e</mml:mi><mml:mi>r</mml:mi><mml:mi>n</mml:mi><mml:mi>e</mml:mi><mml:mi>l</mml:mi></mml:mrow></mml:semantics></mml:math></inline-formula> function (<ext-link ext-link-type="uri" xlink:href="https://github.com/insuhan/fastdppmap/blob/db7a28c38ce654bdbfd5ab1128d3d5910b68df6b/test_greedy.m#L123">https://github.com/insuhan/fastdppmap/blob/db7a28c38ce654bdbfd5ab1128d3d5910b68df6b/test_greedy.m#L123</ext-link>; <xref ref-type="bibr" rid="bib32">Han, 2017</xref>) to construct <inline-formula><mml:math id="inf142"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi mathvariant="bold-italic">V</mml:mi></mml:mrow></mml:mstyle></mml:math></inline-formula>, where in our case <inline-formula><mml:math id="inf143"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi mathvariant="bold-italic">m</mml:mi></mml:mrow></mml:mstyle></mml:math></inline-formula> are the variances of the grid cell embeddings <inline-formula><mml:math id="inf144"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi mathvariant="bold-italic">S</mml:mi></mml:mrow></mml:mstyle></mml:math></inline-formula> computed over the training region <inline-formula><mml:math id="inf145"><mml:semantics><mml:mi>M</mml:mi></mml:semantics></mml:math></inline-formula>, <inline-formula><mml:math id="inf146"><mml:semantics><mml:mi>N</mml:mi></mml:semantics></mml:math></inline-formula> is the number of grid cells and <inline-formula><mml:math id="inf147"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>w</mml:mi><mml:mi>m</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:mi>b</mml:mi></mml:mrow></mml:mstyle></mml:math></inline-formula> are hyperparameters with values of 1 and 0.1, respectively. [<inline-formula><mml:math id="inf148"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>S</mml:mi></mml:mrow></mml:mstyle></mml:math></inline-formula> need not be a square matrix in our case, whose second dimension <italic>M</italic> is the size of the training region. <italic>L_kernel</italic> is same as <inline-formula><mml:math id="inf149"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi mathvariant="bold-italic">V</mml:mi></mml:mrow></mml:mstyle></mml:math></inline-formula>.] The dimensionality of <inline-formula><mml:math id="inf150"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi mathvariant="bold-italic">V</mml:mi></mml:mrow></mml:mstyle></mml:math></inline-formula> is <inline-formula><mml:math id="inf151"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>N</mml:mi><mml:mrow><mml:mi>f</mml:mi></mml:mrow></mml:msub><mml:msub><mml:mi>N</mml:mi><mml:mrow><mml:mi>p</mml:mi></mml:mrow></mml:msub><mml:mo>×</mml:mo><mml:msub><mml:mi>N</mml:mi><mml:mrow><mml:mi>f</mml:mi></mml:mrow></mml:msub><mml:msub><mml:mi>N</mml:mi><mml:mrow><mml:mi>p</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mn>900</mml:mn><mml:mo>×</mml:mo><mml:mn>900</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mstyle></mml:math></inline-formula>. <inline-formula><mml:math id="inf152"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi mathvariant="bold-italic">g</mml:mi><mml:mi mathvariant="bold-italic">f</mml:mi></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula> are the gates of the grid cells belonging to the <inline-formula><mml:math id="inf153"><mml:semantics><mml:mi>f</mml:mi></mml:semantics></mml:math></inline-formula>th frequency, so <inline-formula><mml:math id="inf154"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi mathvariant="bold-italic">g</mml:mi><mml:mi mathvariant="bold-italic">f</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mi mathvariant="bold-italic">g</mml:mi><mml:mo stretchy="false">[</mml:mo><mml:mi>f</mml:mi><mml:msub><mml:mi>N</mml:mi><mml:mrow><mml:mi>p</mml:mi></mml:mrow></mml:msub><mml:mo>:</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mi>f</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">)</mml:mo><mml:msub><mml:mi>N</mml:mi><mml:mrow><mml:mi>p</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">]</mml:mo></mml:mrow></mml:mstyle></mml:math></inline-formula>, where <inline-formula><mml:math id="inf155"><mml:semantics><mml:mrow><mml:msub><mml:mi>N</mml:mi><mml:mi>p</mml:mi></mml:msub></mml:mrow></mml:semantics></mml:math></inline-formula> is the number of phases for each frequency. <inline-formula><mml:math id="inf156"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi mathvariant="bold-italic">V</mml:mi><mml:mi mathvariant="bold-italic">f</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mi mathvariant="bold-italic">V</mml:mi><mml:mo stretchy="false">[</mml:mo><mml:mi>f</mml:mi><mml:msub><mml:mi>N</mml:mi><mml:mrow><mml:mi>p</mml:mi></mml:mrow></mml:msub><mml:mo>:</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mi>f</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">)</mml:mo><mml:msub><mml:mi>N</mml:mi><mml:mrow><mml:mi>p</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:mi>f</mml:mi><mml:msub><mml:mi>N</mml:mi><mml:mrow><mml:mi>p</mml:mi></mml:mrow></mml:msub><mml:mo>:</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mi>f</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">)</mml:mo><mml:msub><mml:mi>N</mml:mi><mml:mrow><mml:mi>p</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">]</mml:mo></mml:mrow></mml:mstyle></mml:math></inline-formula> is the restriction of <inline-formula><mml:math id="inf157"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi mathvariant="bold-italic">V</mml:mi></mml:mrow></mml:mstyle></mml:math></inline-formula> to the grid cell embeddings for <inline-formula><mml:math id="inf158"><mml:semantics><mml:mi>f</mml:mi></mml:semantics></mml:math></inline-formula> th frequency, so it captured the covariance of the grid cell embeddings belonging to the <inline-formula><mml:math id="inf159"><mml:semantics><mml:mi>f</mml:mi></mml:semantics></mml:math></inline-formula> th frequency. <inline-formula><mml:math id="inf160"><mml:semantics><mml:mi>σ</mml:mi></mml:semantics></mml:math></inline-formula> is sigmoid nonlinearity applied to <inline-formula><mml:math id="inf161"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi mathvariant="bold-italic">g</mml:mi><mml:mi mathvariant="bold-italic">f</mml:mi></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula>, deﬁned as <inline-formula><mml:math id="inf162"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>σ</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi mathvariant="bold-italic">g</mml:mi><mml:mi mathvariant="bold-italic">f</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mn>1</mml:mn><mml:mrow><mml:mo>/</mml:mo></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mn>1</mml:mn><mml:mo>+</mml:mo><mml:msup><mml:mi>e</mml:mi><mml:mrow><mml:mo>−</mml:mo><mml:msub><mml:mi mathvariant="bold-italic">g</mml:mi><mml:mi mathvariant="bold-italic">f</mml:mi></mml:msub></mml:mrow></mml:msup><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mstyle></mml:math></inline-formula>, so that their values are between 0 and 1. <inline-formula><mml:math id="inf163"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mrow><mml:mi mathvariant="normal">d</mml:mi><mml:mi mathvariant="normal">i</mml:mi><mml:mi mathvariant="normal">a</mml:mi><mml:mi mathvariant="normal">g</mml:mi></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>σ</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi mathvariant="bold-italic">g</mml:mi><mml:mi mathvariant="bold-italic">f</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mstyle></mml:math></inline-formula> converts vector <inline-formula><mml:math id="inf164"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>σ</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi mathvariant="bold-italic">g</mml:mi><mml:mi mathvariant="bold-italic">f</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mstyle></mml:math></inline-formula> into a matrix with <inline-formula><mml:math id="inf165"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>σ</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi mathvariant="bold-italic">g</mml:mi><mml:mi mathvariant="bold-italic">f</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mstyle></mml:math></inline-formula> as the diagonal of the matrix and the rest entries are zero, which is multiplied with <inline-formula><mml:math id="inf166"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi mathvariant="bold-italic">V</mml:mi><mml:mo mathvariant="bold">−</mml:mo><mml:mi mathvariant="bold-italic">I</mml:mi></mml:mrow></mml:mstyle></mml:math></inline-formula>, which results in elementwise multiplication of <inline-formula><mml:math id="inf167"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>σ</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi mathvariant="bold-italic">g</mml:mi><mml:mi mathvariant="bold-italic">f</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mstyle></mml:math></inline-formula> with the column vectors of <inline-formula><mml:math id="inf168"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi mathvariant="bold-italic">V</mml:mi><mml:mo mathvariant="bold">−</mml:mo><mml:mi mathvariant="bold-italic">I</mml:mi></mml:mrow></mml:mstyle></mml:math></inline-formula>. <xref ref-type="disp-formula" rid="equ6">Equation 6</xref> which involved summation of the logarithm of the determinant of the gated covariance matrix of grid cell embeddings within each frequency, over <inline-formula><mml:math id="inf169"><mml:semantics><mml:mrow><mml:msub><mml:mi>N</mml:mi><mml:mi>f</mml:mi></mml:msub></mml:mrow></mml:semantics></mml:math></inline-formula> frequencies was used to compute the negative of <inline-formula><mml:math id="inf170"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="script">L</mml:mi></mml:mrow><mml:mrow><mml:mi>D</mml:mi><mml:mi>P</mml:mi><mml:mi>P</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula>. Maximizing <inline-formula><mml:math id="inf171"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mrow><mml:mover><mml:mi>F</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow></mml:mrow></mml:mstyle></mml:math></inline-formula> gave the approximate maximum within-frequency log determinant for each frequency <inline-formula><mml:math id="inf172"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>f</mml:mi><mml:mo>∈</mml:mo><mml:mo stretchy="false">[</mml:mo><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:msub><mml:mi>N</mml:mi><mml:mrow><mml:mi>f</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">]</mml:mo></mml:mrow></mml:mstyle></mml:math></inline-formula>, which we denote for the <inline-formula><mml:math id="inf173"><mml:semantics><mml:mi>f</mml:mi></mml:semantics></mml:math></inline-formula> th frequency as <inline-formula><mml:math id="inf174"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mrow><mml:mover><mml:mi>F</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>f</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula>. In the second step of the training procedure, we used the <inline-formula><mml:math id="inf175"><mml:semantics><mml:mrow><mml:msub><mml:mi>f</mml:mi><mml:mrow><mml:mi>m</mml:mi><mml:mi>a</mml:mi><mml:msub><mml:mi>x</mml:mi><mml:mrow><mml:mi>D</mml:mi><mml:mi>P</mml:mi><mml:mi>P</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:msub></mml:mrow></mml:semantics></mml:math></inline-formula> grid cell frequency, where <inline-formula><mml:math id="inf176"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>f</mml:mi><mml:mrow><mml:mi>m</mml:mi><mml:mi>a</mml:mi><mml:msub><mml:mi>x</mml:mi><mml:mrow><mml:mi>D</mml:mi><mml:mi>P</mml:mi><mml:mi>P</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:msub><mml:mrow><mml:mi mathvariant="normal">a</mml:mi><mml:mi mathvariant="normal">r</mml:mi><mml:mi mathvariant="normal">g</mml:mi><mml:mspace width="thinmathspace"/><mml:mi mathvariant="normal">m</mml:mi><mml:mi mathvariant="normal">a</mml:mi><mml:mi mathvariant="normal">x</mml:mi></mml:mrow><mml:mrow><mml:mi>f</mml:mi><mml:mo>∈</mml:mo><mml:mo stretchy="false">[</mml:mo><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:msub><mml:mi>N</mml:mi><mml:mrow><mml:mi>f</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">]</mml:mo></mml:mrow></mml:msub><mml:msub><mml:mrow><mml:mover><mml:mi>F</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>f</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula>. In other words, we used the grid cell embeddings for the frequency which had the maximum within-frequency log determinant at the end of the ﬁrst step, which we ﬁnd are best at capturing the relational structure across the training and testing data, thereby promoting OOD generalization. In this step, we trained the inference module minimizing <inline-formula><mml:math id="inf177"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="script">L</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi><mml:mi>a</mml:mi><mml:mi>s</mml:mi><mml:mi>k</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula> over <inline-formula><mml:math id="inf178"><mml:semantics><mml:mrow><mml:msub><mml:mi>N</mml:mi><mml:mrow><mml:msub><mml:mi>E</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mi>a</mml:mi><mml:mi>s</mml:mi><mml:mi>k</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:msub></mml:mrow></mml:semantics></mml:math></inline-formula> epochs. More details can be found in Appendix 1: ‘DPP-A attentional modulation’.</p></sec></sec></sec><sec id="s2-3"><title>Inference module</title><p>We implemented the inference module <inline-formula><mml:math id="inf179"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi mathvariant="bold-italic">R</mml:mi></mml:mrow></mml:mstyle></mml:math></inline-formula> in two forms, one using Long Short Term Memory (LSTM) (<xref ref-type="bibr" rid="bib37">Hochreiter and Schmidhuber, 1997</xref>) and the other using a transformer (<xref ref-type="bibr" rid="bib71">Vaswani et al., 2017</xref>) architecture. Separate networks were trained for the analogy and arithmetic tasks using each form of inference module. For each task, the attended grid cell embeddings of each stimulus obtained from the DPP-A process (<inline-formula><mml:math id="inf180"><mml:semantics><mml:mrow><mml:msub><mml:mi>x</mml:mi><mml:mrow><mml:mi>f</mml:mi><mml:mo>=</mml:mo><mml:msub><mml:mi>f</mml:mi><mml:mrow><mml:mi>m</mml:mi><mml:mi>a</mml:mi><mml:msub><mml:mi>x</mml:mi><mml:mrow><mml:mi>D</mml:mi><mml:mi>P</mml:mi><mml:mi>P</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:msub></mml:mrow></mml:msub></mml:mrow></mml:semantics></mml:math></inline-formula>), were provided to <inline-formula><mml:math id="inf181"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi mathvariant="bold-italic">R</mml:mi></mml:mrow></mml:mstyle></mml:math></inline-formula> as its inputs, which we denote as <inline-formula><mml:math id="inf182"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi mathvariant="bold-italic">x</mml:mi><mml:mi mathvariant="bold-italic">R</mml:mi></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula> for brevity. For the arithmetic task, we also concatenated to <inline-formula><mml:math id="inf183"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi mathvariant="bold-italic">x</mml:mi><mml:mi mathvariant="bold-italic">R</mml:mi></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula> a one-hot tensor of dimension 2, before feeding to <inline-formula><mml:math id="inf184"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi mathvariant="bold-italic">R</mml:mi></mml:mrow></mml:mstyle></mml:math></inline-formula> that speciﬁed which computation to perform (addition or multiplication). As proposed by <xref ref-type="bibr" rid="bib35">Hill et al., 2019</xref>, we treated both the analogy and arithmetic tasks as scoring (i.e., multiple choice) problems. For each analogy, the inference module was presented with multiple problems, each consisting of three stimuli, <inline-formula><mml:math id="inf185"><mml:semantics><mml:mrow><mml:mi>A</mml:mi><mml:mo>,</mml:mo><mml:mi>B</mml:mi><mml:mo>,</mml:mo><mml:mi>C</mml:mi></mml:mrow></mml:semantics></mml:math></inline-formula>, and a candidate completion from the set containing <inline-formula><mml:math id="inf186"><mml:semantics><mml:mi>D</mml:mi></mml:semantics></mml:math></inline-formula> (the correct completion) and six foil completions. For each instance of the arithmetic task, it was presented with two stimuli, <inline-formula><mml:math id="inf187"><mml:semantics><mml:mrow><mml:mi>A</mml:mi><mml:mo>,</mml:mo><mml:mi>B</mml:mi></mml:mrow></mml:semantics></mml:math></inline-formula>, and a candidate completion from the set containing <inline-formula><mml:math id="inf188"><mml:semantics><mml:mi>C</mml:mi></mml:semantics></mml:math></inline-formula> (the correct completion) and six foil completions. Stimuli were presented sequentially for <inline-formula><mml:math id="inf189"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi mathvariant="bold-italic">R</mml:mi></mml:mrow></mml:mstyle></mml:math></inline-formula> constructed using an LSTM, which consists of three gates, and computations using them deﬁned as below:<disp-formula id="equ7"><label>(7)</label><mml:math id="m7"><mml:mrow><mml:mrow><mml:mi mathvariant="bold-italic">i</mml:mi><mml:mi mathvariant="bold-italic">n</mml:mi><mml:mi mathvariant="bold-italic">p</mml:mi><mml:mi mathvariant="bold-italic">u</mml:mi><mml:mi mathvariant="bold-italic">t</mml:mi><mml:mi mathvariant="bold">_</mml:mi><mml:mi mathvariant="bold-italic">g</mml:mi><mml:mi mathvariant="bold-italic">a</mml:mi><mml:mi mathvariant="bold-italic">t</mml:mi><mml:mi mathvariant="bold-italic">e</mml:mi></mml:mrow><mml:mrow><mml:mo>[</mml:mo><mml:mi>t</mml:mi><mml:mo>]</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mi>σ</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi mathvariant="bold-italic">W</mml:mi><mml:mrow><mml:mi mathvariant="bold-italic">i</mml:mi><mml:mi mathvariant="bold-italic">i</mml:mi></mml:mrow></mml:msub><mml:msub><mml:mi mathvariant="bold-italic">x</mml:mi><mml:mrow><mml:mi mathvariant="bold-italic">R</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo>[</mml:mo><mml:mi>t</mml:mi><mml:mo>]</mml:mo></mml:mrow><mml:mo>+</mml:mo><mml:msub><mml:mi mathvariant="bold-italic">b</mml:mi><mml:mrow><mml:mi mathvariant="bold-italic">i</mml:mi><mml:mi mathvariant="bold-italic">i</mml:mi></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:mrow><mml:msub><mml:mi mathvariant="bold-italic">W</mml:mi><mml:mrow><mml:mi mathvariant="bold-italic">h</mml:mi><mml:mi mathvariant="bold-italic">i</mml:mi></mml:mrow></mml:msub><mml:mi mathvariant="bold-italic">h</mml:mi></mml:mrow><mml:mrow><mml:mo>[</mml:mo><mml:mrow><mml:mi>t</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mo>]</mml:mo></mml:mrow><mml:mo>+</mml:mo><mml:msub><mml:mi mathvariant="bold-italic">b</mml:mi><mml:mrow><mml:mi mathvariant="bold-italic">h</mml:mi><mml:mi mathvariant="bold-italic">i</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></disp-formula><disp-formula id="equ8"><label>(8)</label><mml:math id="m8"><mml:mrow><mml:mrow><mml:mi mathvariant="bold-italic">f</mml:mi><mml:mi mathvariant="bold-italic">o</mml:mi><mml:mi mathvariant="bold-italic">r</mml:mi><mml:mi mathvariant="bold-italic">g</mml:mi><mml:mi mathvariant="bold-italic">e</mml:mi><mml:mi mathvariant="bold-italic">t</mml:mi><mml:mi mathvariant="bold">_</mml:mi><mml:mi mathvariant="bold-italic">g</mml:mi><mml:mi mathvariant="bold-italic">a</mml:mi><mml:mi mathvariant="bold-italic">t</mml:mi><mml:mi mathvariant="bold-italic">e</mml:mi></mml:mrow><mml:mrow><mml:mo>[</mml:mo><mml:mi>t</mml:mi><mml:mo>]</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mi>σ</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi mathvariant="bold-italic">W</mml:mi><mml:mrow><mml:mi mathvariant="bold-italic">i</mml:mi><mml:mi mathvariant="bold-italic">f</mml:mi></mml:mrow></mml:msub><mml:msub><mml:mi mathvariant="bold-italic">x</mml:mi><mml:mrow><mml:mi mathvariant="bold-italic">R</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo>[</mml:mo><mml:mi>t</mml:mi><mml:mo>]</mml:mo></mml:mrow><mml:mo>+</mml:mo><mml:msub><mml:mi mathvariant="bold-italic">b</mml:mi><mml:mrow><mml:mi mathvariant="bold-italic">i</mml:mi><mml:mi mathvariant="bold-italic">f</mml:mi></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:mrow><mml:msub><mml:mi mathvariant="bold-italic">W</mml:mi><mml:mrow><mml:mi mathvariant="bold-italic">h</mml:mi><mml:mi mathvariant="bold-italic">f</mml:mi></mml:mrow></mml:msub><mml:mi mathvariant="bold-italic">h</mml:mi></mml:mrow><mml:mrow><mml:mo>[</mml:mo><mml:mrow><mml:mi>t</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mo>]</mml:mo></mml:mrow><mml:mo>+</mml:mo><mml:msub><mml:mi mathvariant="bold-italic">b</mml:mi><mml:mrow><mml:mi mathvariant="bold-italic">h</mml:mi><mml:mi mathvariant="bold-italic">f</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></disp-formula><disp-formula id="equ9"><label>(9)</label><mml:math id="m9"><mml:mrow><mml:mrow><mml:mi mathvariant="bold-italic">o</mml:mi><mml:mi mathvariant="bold-italic">u</mml:mi><mml:mi mathvariant="bold-italic">t</mml:mi><mml:mi mathvariant="bold-italic">p</mml:mi><mml:mi mathvariant="bold-italic">u</mml:mi><mml:mi mathvariant="bold-italic">t</mml:mi><mml:mi mathvariant="bold">_</mml:mi><mml:mi mathvariant="bold-italic">g</mml:mi><mml:mi mathvariant="bold-italic">a</mml:mi><mml:mi mathvariant="bold-italic">t</mml:mi><mml:mi mathvariant="bold-italic">e</mml:mi></mml:mrow><mml:mrow><mml:mo>[</mml:mo><mml:mi>t</mml:mi><mml:mo>]</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mi>σ</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mrow><mml:msub><mml:mi mathvariant="bold-italic">W</mml:mi><mml:mrow><mml:mi mathvariant="bold-italic">i</mml:mi><mml:mi mathvariant="bold-italic">o</mml:mi></mml:mrow></mml:msub><mml:msub><mml:mi mathvariant="bold-italic">x</mml:mi><mml:mrow><mml:mi mathvariant="bold-italic">R</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:mo>[</mml:mo><mml:mi>t</mml:mi><mml:mo>]</mml:mo></mml:mrow><mml:mo>+</mml:mo><mml:msub><mml:mi mathvariant="bold-italic">b</mml:mi><mml:mrow><mml:mi mathvariant="bold-italic">i</mml:mi><mml:mi mathvariant="bold-italic">o</mml:mi></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:mrow><mml:msub><mml:mi mathvariant="bold-italic">W</mml:mi><mml:mrow><mml:mi mathvariant="bold-italic">h</mml:mi><mml:mi mathvariant="bold-italic">o</mml:mi></mml:mrow></mml:msub><mml:mi mathvariant="bold-italic">h</mml:mi></mml:mrow><mml:mrow><mml:mo>[</mml:mo><mml:mrow><mml:mi>t</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mo>]</mml:mo></mml:mrow><mml:mo>+</mml:mo><mml:msub><mml:mi mathvariant="bold-italic">b</mml:mi><mml:mrow><mml:mi mathvariant="bold-italic">h</mml:mi><mml:mi mathvariant="bold-italic">o</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></disp-formula><disp-formula id="equ10"><label>(10)</label><mml:math id="m10"><mml:mrow><mml:mi mathvariant="bold-italic">c</mml:mi><mml:mrow><mml:mo>[</mml:mo><mml:mi>t</mml:mi><mml:mo>]</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mrow><mml:mi mathvariant="bold-italic">f</mml:mi><mml:mi mathvariant="bold-italic">o</mml:mi><mml:mi mathvariant="bold-italic">r</mml:mi><mml:mi mathvariant="bold-italic">g</mml:mi><mml:mi mathvariant="bold-italic">e</mml:mi><mml:mi mathvariant="bold-italic">t</mml:mi><mml:mi mathvariant="bold">_</mml:mi><mml:mi mathvariant="bold-italic">g</mml:mi><mml:mi mathvariant="bold-italic">a</mml:mi><mml:mi mathvariant="bold-italic">t</mml:mi><mml:mi mathvariant="bold-italic">e</mml:mi></mml:mrow><mml:mrow><mml:mo>[</mml:mo><mml:mi>t</mml:mi><mml:mo>]</mml:mo></mml:mrow><mml:mo>⊙</mml:mo><mml:mi mathvariant="bold-italic">c</mml:mi><mml:mrow><mml:mo>[</mml:mo><mml:mrow><mml:mi>t</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mo>]</mml:mo></mml:mrow><mml:mo>+</mml:mo><mml:mrow><mml:mi mathvariant="bold-italic">i</mml:mi><mml:mi mathvariant="bold-italic">n</mml:mi><mml:mi mathvariant="bold-italic">p</mml:mi><mml:mi mathvariant="bold-italic">u</mml:mi><mml:mi mathvariant="bold-italic">t</mml:mi><mml:mi mathvariant="bold">_</mml:mi><mml:mi mathvariant="bold-italic">g</mml:mi><mml:mi mathvariant="bold-italic">a</mml:mi><mml:mi mathvariant="bold-italic">t</mml:mi><mml:mi mathvariant="bold-italic">e</mml:mi></mml:mrow><mml:mrow><mml:mo>[</mml:mo><mml:mi>t</mml:mi><mml:mo>]</mml:mo></mml:mrow><mml:mo>⊙</mml:mo><mml:mi>tanh</mml:mi><mml:mo>⁡</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mrow><mml:msub><mml:mi mathvariant="bold-italic">W</mml:mi><mml:mrow><mml:mi mathvariant="bold-italic">i</mml:mi><mml:mi mathvariant="bold-italic">c</mml:mi></mml:mrow></mml:msub><mml:msub><mml:mi mathvariant="bold-italic">x</mml:mi><mml:mrow><mml:mi mathvariant="bold-italic">R</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:mo>[</mml:mo><mml:mi>t</mml:mi><mml:mo>]</mml:mo></mml:mrow><mml:mo>+</mml:mo><mml:msub><mml:mi mathvariant="bold-italic">b</mml:mi><mml:mrow><mml:mi mathvariant="bold-italic">i</mml:mi><mml:mi mathvariant="bold-italic">c</mml:mi></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:mrow><mml:msub><mml:mi mathvariant="bold-italic">W</mml:mi><mml:mrow><mml:mi mathvariant="bold-italic">h</mml:mi><mml:mi mathvariant="bold-italic">c</mml:mi></mml:mrow></mml:msub><mml:mi mathvariant="bold-italic">h</mml:mi></mml:mrow><mml:mrow><mml:mo>[</mml:mo><mml:mrow><mml:mi>t</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mo>]</mml:mo></mml:mrow><mml:mo>+</mml:mo><mml:msub><mml:mi mathvariant="bold-italic">b</mml:mi><mml:mrow><mml:mi mathvariant="bold-italic">h</mml:mi><mml:mi mathvariant="bold-italic">c</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></disp-formula><disp-formula id="equ11"><label>(11)</label><mml:math id="m11"><mml:mrow><mml:mi mathvariant="bold-italic">h</mml:mi><mml:mrow><mml:mo>[</mml:mo><mml:mi>t</mml:mi><mml:mo>]</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mrow><mml:mi mathvariant="bold-italic">o</mml:mi><mml:mi mathvariant="bold-italic">u</mml:mi><mml:mi mathvariant="bold-italic">t</mml:mi><mml:mi mathvariant="bold-italic">p</mml:mi><mml:mi mathvariant="bold-italic">u</mml:mi><mml:mi mathvariant="bold-italic">t</mml:mi><mml:mi mathvariant="bold">_</mml:mi><mml:mi mathvariant="bold-italic">g</mml:mi><mml:mi mathvariant="bold-italic">a</mml:mi><mml:mi mathvariant="bold-italic">t</mml:mi><mml:mi mathvariant="bold-italic">e</mml:mi></mml:mrow><mml:mrow><mml:mo>[</mml:mo><mml:mi>t</mml:mi><mml:mo>]</mml:mo></mml:mrow><mml:mo>⊙</mml:mo><mml:mi>tanh</mml:mi><mml:mo>⁡</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi mathvariant="bold-italic">c</mml:mi><mml:mrow><mml:mo>[</mml:mo><mml:mi>t</mml:mi><mml:mo>]</mml:mo></mml:mrow></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></disp-formula></p><p>where <inline-formula><mml:math id="inf190"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi mathvariant="bold-italic">W</mml:mi><mml:mrow><mml:mi mathvariant="bold-italic">i</mml:mi><mml:mi mathvariant="bold-italic">i</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula>,<inline-formula><mml:math id="inf191"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi mathvariant="bold-italic">W</mml:mi><mml:mrow><mml:mi mathvariant="bold-italic">h</mml:mi><mml:mi mathvariant="bold-italic">i</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula>,<inline-formula><mml:math id="inf192"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi mathvariant="bold-italic">W</mml:mi><mml:mrow><mml:mi mathvariant="bold-italic">i</mml:mi><mml:mi mathvariant="bold-italic">f</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula>,<inline-formula><mml:math id="inf193"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi mathvariant="bold-italic">W</mml:mi><mml:mrow><mml:mi mathvariant="bold-italic">h</mml:mi><mml:mi mathvariant="bold-italic">f</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula>,<inline-formula><mml:math id="inf194"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi mathvariant="bold-italic">W</mml:mi><mml:mrow><mml:mi mathvariant="bold-italic">i</mml:mi><mml:mi mathvariant="bold-italic">o</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula>,<inline-formula><mml:math id="inf195"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi mathvariant="bold-italic">W</mml:mi><mml:mrow><mml:mi mathvariant="bold-italic">h</mml:mi><mml:mi mathvariant="bold-italic">o</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula>,<inline-formula><mml:math id="inf196"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi mathvariant="bold-italic">W</mml:mi><mml:mrow><mml:mi mathvariant="bold-italic">i</mml:mi><mml:mi mathvariant="bold-italic">c</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula>,<inline-formula><mml:math id="inf197"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi mathvariant="bold-italic">W</mml:mi><mml:mrow><mml:mi mathvariant="bold-italic">h</mml:mi><mml:mi mathvariant="bold-italic">c</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula> are weight matrices and <inline-formula><mml:math id="inf198"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi mathvariant="bold-italic">b</mml:mi><mml:mrow><mml:mi mathvariant="bold-italic">i</mml:mi><mml:mi mathvariant="bold-italic">i</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula>, <inline-formula><mml:math id="inf199"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi mathvariant="bold-italic">b</mml:mi><mml:mrow><mml:mi mathvariant="bold-italic">h</mml:mi><mml:mi mathvariant="bold-italic">i</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula>, <inline-formula><mml:math id="inf200"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi mathvariant="bold-italic">b</mml:mi><mml:mrow><mml:mi mathvariant="bold-italic">i</mml:mi><mml:mi mathvariant="bold-italic">f</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula>, <inline-formula><mml:math id="inf201"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi mathvariant="bold-italic">b</mml:mi><mml:mrow><mml:mi mathvariant="bold-italic">h</mml:mi><mml:mi mathvariant="bold-italic">f</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula>, <inline-formula><mml:math id="inf202"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi mathvariant="bold-italic">b</mml:mi><mml:mrow><mml:mi mathvariant="bold-italic">i</mml:mi><mml:mi mathvariant="bold-italic">o</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula>, <inline-formula><mml:math id="inf203"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi mathvariant="bold-italic">b</mml:mi><mml:mrow><mml:mi mathvariant="bold-italic">h</mml:mi><mml:mi mathvariant="bold-italic">o</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula>, <inline-formula><mml:math id="inf204"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi mathvariant="bold-italic">b</mml:mi><mml:mrow><mml:mi mathvariant="bold-italic">i</mml:mi><mml:mi mathvariant="bold-italic">c</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula>, <inline-formula><mml:math id="inf205"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi mathvariant="bold-italic">b</mml:mi><mml:mrow><mml:mi mathvariant="bold-italic">h</mml:mi><mml:mi mathvariant="bold-italic">c</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula> are bias vectors. <inline-formula><mml:math id="inf206"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi mathvariant="bold-italic">h</mml:mi><mml:mo stretchy="false">[</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">]</mml:mo></mml:mrow></mml:mstyle></mml:math></inline-formula> and <inline-formula><mml:math id="inf207"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi mathvariant="bold-italic">c</mml:mi><mml:mo stretchy="false">[</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">]</mml:mo></mml:mrow></mml:mstyle></mml:math></inline-formula> are the hidden state and the cell state at time <inline-formula><mml:math id="inf208"><mml:semantics><mml:mi>t</mml:mi></mml:semantics></mml:math></inline-formula>, respectively. The hidden state for the last timestep was passed through a linear layer with a single output unit to generate a score for the candidate completions for each problem. We used a single layered LSTM of 512 hidden units, which corresponds to the size of the hidden state, cell state, bias vectors, and weight matrices. The hidden and cell state of the LSTM was reinitialized at the start of each sequence for each candidate completion.</p><p>For <inline-formula><mml:math id="inf209"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi mathvariant="bold-italic">R</mml:mi></mml:mrow></mml:mstyle></mml:math></inline-formula> constructed using a transformer, we used the standard multi-head self attention (<inline-formula><mml:math id="inf210"><mml:semantics><mml:mrow><mml:mi>M</mml:mi><mml:mi>H</mml:mi><mml:mi>S</mml:mi><mml:mi>A</mml:mi></mml:mrow></mml:semantics></mml:math></inline-formula>) mechanism followed by a multi-layered perceptron (<inline-formula><mml:math id="inf211"><mml:semantics><mml:mrow><mml:mi>M</mml:mi><mml:mi>L</mml:mi><mml:mi>P</mml:mi></mml:mrow></mml:semantics></mml:math></inline-formula>) – a feedforward neural network with one hidden layer, with layer normalization (<xref ref-type="bibr" rid="bib2">Ba et al., 2016</xref>) (<inline-formula><mml:math id="inf212"><mml:semantics><mml:mrow><mml:mi>L</mml:mi><mml:mi>N</mml:mi></mml:mrow></mml:semantics></mml:math></inline-formula>) to transform <inline-formula><mml:math id="inf213"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi mathvariant="bold-italic">x</mml:mi><mml:mrow><mml:mi mathvariant="bold-italic">R</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula> at each layer of the transformer, deﬁned as below:<disp-formula id="equ12"><label>(12)</label><mml:math id="m12"><mml:mrow><mml:mi>S</mml:mi><mml:mi>A</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi mathvariant="bold-italic">Q</mml:mi><mml:mo mathvariant="bold">,</mml:mo><mml:mi mathvariant="bold-italic">K</mml:mi><mml:mo mathvariant="bold">,</mml:mo><mml:mi mathvariant="bold-italic">V</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mi>s</mml:mi><mml:mi>o</mml:mi><mml:mi>f</mml:mi><mml:mi>t</mml:mi><mml:mi>m</mml:mi><mml:mi>a</mml:mi><mml:mi>x</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mfrac><mml:msup><mml:mrow><mml:mi mathvariant="bold-italic">Q</mml:mi><mml:mi mathvariant="bold-italic">K</mml:mi></mml:mrow><mml:mrow><mml:mi>T</mml:mi></mml:mrow></mml:msup><mml:msqrt><mml:msub><mml:mi>d</mml:mi><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:msub></mml:msqrt></mml:mfrac><mml:mo>)</mml:mo></mml:mrow><mml:mi mathvariant="bold-italic">V</mml:mi></mml:mrow></mml:math></disp-formula><disp-formula id="equ13"><label>(13)</label><mml:math id="m13"><mml:mrow><mml:mi>M</mml:mi><mml:mi>H</mml:mi><mml:mi>S</mml:mi><mml:mi>A</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi mathvariant="bold-italic">x</mml:mi><mml:mrow><mml:mi mathvariant="bold-italic">R</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mi>C</mml:mi><mml:mi>o</mml:mi><mml:mi>n</mml:mi><mml:mi>c</mml:mi><mml:mi>a</mml:mi><mml:mi>t</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>S</mml:mi><mml:mi>A</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msubsup><mml:mi mathvariant="bold-italic">W</mml:mi><mml:mrow><mml:mn mathvariant="bold">1</mml:mn></mml:mrow><mml:mrow><mml:mi mathvariant="bold-italic">Q</mml:mi></mml:mrow></mml:msubsup><mml:msub><mml:mi mathvariant="bold-italic">x</mml:mi><mml:mrow><mml:mi mathvariant="bold-italic">R</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msubsup><mml:mi mathvariant="bold-italic">W</mml:mi><mml:mrow><mml:mn mathvariant="bold">1</mml:mn></mml:mrow><mml:mrow><mml:mi mathvariant="bold-italic">K</mml:mi></mml:mrow></mml:msubsup><mml:msub><mml:mi mathvariant="bold-italic">x</mml:mi><mml:mrow><mml:mi mathvariant="bold-italic">R</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msubsup><mml:mi mathvariant="bold-italic">W</mml:mi><mml:mrow><mml:mn mathvariant="bold">1</mml:mn></mml:mrow><mml:mrow><mml:mi mathvariant="bold-italic">V</mml:mi></mml:mrow></mml:msubsup><mml:msub><mml:mi mathvariant="bold-italic">x</mml:mi><mml:mrow><mml:mi mathvariant="bold-italic">R</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>,</mml:mo><mml:mo>.</mml:mo><mml:mo>.</mml:mo><mml:mo>.</mml:mo><mml:mo>.</mml:mo><mml:mo>,</mml:mo><mml:mi>S</mml:mi><mml:mi>A</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msubsup><mml:mi mathvariant="bold-italic">W</mml:mi><mml:mrow><mml:mi mathvariant="bold-italic">H</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="bold-italic">Q</mml:mi></mml:mrow></mml:msubsup><mml:msub><mml:mi mathvariant="bold-italic">x</mml:mi><mml:mrow><mml:mi mathvariant="bold-italic">R</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msubsup><mml:mi mathvariant="bold-italic">W</mml:mi><mml:mrow><mml:mi mathvariant="bold-italic">H</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="bold-italic">K</mml:mi></mml:mrow></mml:msubsup><mml:msub><mml:mi mathvariant="bold-italic">x</mml:mi><mml:mrow><mml:mi mathvariant="bold-italic">R</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msubsup><mml:mi mathvariant="bold-italic">W</mml:mi><mml:mrow><mml:mi mathvariant="bold-italic">H</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="bold-italic">V</mml:mi></mml:mrow></mml:msubsup><mml:msub><mml:mi mathvariant="bold-italic">x</mml:mi><mml:mrow><mml:mi mathvariant="bold-italic">R</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:msup><mml:mi mathvariant="bold-italic">W</mml:mi><mml:mrow><mml:mi mathvariant="bold-italic">O</mml:mi></mml:mrow></mml:msup></mml:mrow></mml:math></disp-formula><disp-formula id="equ14"><label>(14)</label><mml:math id="m14"><mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mover><mml:mi mathvariant="bold-italic">x</mml:mi><mml:mo stretchy="false">~</mml:mo></mml:mover></mml:mrow><mml:mi mathvariant="bold-italic">R</mml:mi></mml:msub></mml:mrow><mml:mo>=</mml:mo><mml:mi>M</mml:mi><mml:mi>L</mml:mi><mml:mi>P</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>L</mml:mi><mml:mi>N</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>M</mml:mi><mml:mi>H</mml:mi><mml:mi>S</mml:mi><mml:mi>A</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>L</mml:mi><mml:mi>N</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:msub><mml:mi mathvariant="bold-italic">x</mml:mi><mml:mrow><mml:mi mathvariant="bold-italic">R</mml:mi></mml:mrow></mml:msub><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>+</mml:mo><mml:msub><mml:mi mathvariant="bold-italic">x</mml:mi><mml:mrow><mml:mi mathvariant="bold-italic">R</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>+</mml:mo><mml:mi>M</mml:mi><mml:mi>H</mml:mi><mml:mi>S</mml:mi><mml:mi>A</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>L</mml:mi><mml:mi>N</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:msub><mml:mi mathvariant="bold-italic">x</mml:mi><mml:mrow><mml:mi mathvariant="bold-italic">R</mml:mi></mml:mrow></mml:msub><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>+</mml:mo><mml:msub><mml:mi mathvariant="bold-italic">x</mml:mi><mml:mrow><mml:mi mathvariant="bold-italic">R</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:math></disp-formula></p><p>where <inline-formula><mml:math id="inf214"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi mathvariant="bold-italic">Q</mml:mi></mml:mrow></mml:mstyle></mml:math></inline-formula>, <inline-formula><mml:math id="inf215"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi mathvariant="bold-italic">K</mml:mi></mml:mrow></mml:mstyle></mml:math></inline-formula>, and <inline-formula><mml:math id="inf216"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi mathvariant="bold-italic">V</mml:mi></mml:mrow></mml:mstyle></mml:math></inline-formula> are called the query, key, and value matrices, respectively, <inline-formula><mml:math id="inf217"><mml:semantics><mml:mrow><mml:msub><mml:mi>d</mml:mi><mml:mi>k</mml:mi></mml:msub></mml:mrow></mml:semantics></mml:math></inline-formula> is the dimension of the matrices, <inline-formula><mml:math id="inf218"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msup><mml:mi mathvariant="bold-italic">W</mml:mi><mml:mi mathvariant="bold-italic">Q</mml:mi></mml:msup></mml:mrow></mml:mstyle></mml:math></inline-formula>, <inline-formula><mml:math id="inf219"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msup><mml:mi mathvariant="bold-italic">W</mml:mi><mml:mi mathvariant="bold-italic">K</mml:mi></mml:msup></mml:mrow></mml:mstyle></mml:math></inline-formula>, and <inline-formula><mml:math id="inf220"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msup><mml:mi mathvariant="bold-italic">W</mml:mi><mml:mi mathvariant="bold-italic">V</mml:mi></mml:msup></mml:mrow></mml:mstyle></mml:math></inline-formula> are the corresponding projection matrices, <inline-formula><mml:math id="inf221"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msup><mml:mi mathvariant="bold-italic">W</mml:mi><mml:mi mathvariant="bold-italic">O</mml:mi></mml:msup></mml:mrow></mml:mstyle></mml:math></inline-formula> is the output projection matrix which is applied to the concatenation of self attention (<inline-formula><mml:math id="inf222"><mml:semantics><mml:mrow><mml:mi>S</mml:mi><mml:mi>A</mml:mi></mml:mrow></mml:semantics></mml:math></inline-formula>) output for each head, and <inline-formula><mml:math id="inf223"><mml:semantics><mml:mi>H</mml:mi></mml:semantics></mml:math></inline-formula> is the number of heads. The <inline-formula><mml:math id="inf224"><mml:semantics><mml:mrow><mml:mi>s</mml:mi><mml:mi>o</mml:mi><mml:mi>f</mml:mi><mml:mi>t</mml:mi><mml:mi>m</mml:mi><mml:mi>a</mml:mi><mml:mi>x</mml:mi></mml:mrow></mml:semantics></mml:math></inline-formula> function is used to convert real valued vector inputs into a probability distribution, deﬁned as <inline-formula><mml:math id="inf225"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>s</mml:mi><mml:mi>o</mml:mi><mml:mi>f</mml:mi><mml:mi>t</mml:mi><mml:mi>m</mml:mi><mml:mi>a</mml:mi><mml:mi>x</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>z</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:msup><mml:mi>e</mml:mi><mml:mrow><mml:msub><mml:mi>z</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:msup><mml:mrow><mml:mo>/</mml:mo></mml:mrow><mml:munder><mml:mo>∑</mml:mo><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:munder><mml:msup><mml:mi>e</mml:mi><mml:mrow><mml:msub><mml:mi>z</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:msup></mml:mrow></mml:mstyle></mml:math></inline-formula>. We used a transformer with 6 layers, each of which had 8 heads, <inline-formula><mml:math id="inf226"><mml:semantics><mml:mrow><mml:msub><mml:mi>d</mml:mi><mml:mi>k</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mn>32</mml:mn></mml:mrow></mml:semantics></mml:math></inline-formula>, and <inline-formula><mml:math id="inf227"><mml:semantics><mml:mrow><mml:mi>M</mml:mi><mml:mi>L</mml:mi><mml:mi>P</mml:mi></mml:mrow></mml:semantics></mml:math></inline-formula> hidden layer dimension of 512. The stimuli were presented together and projected into 128 dimensions to be more easily divisible by the number of heads, followed by layer normalization. Since a transformer is naturally invariant to the order of the stimuli, to make use of the order we added to <inline-formula><mml:math id="inf228"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi mathvariant="bold-italic">x</mml:mi><mml:mi mathvariant="bold-italic">R</mml:mi></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula> a learnable positional encoding (<xref ref-type="bibr" rid="bib41">Kazemnejad, 2019</xref>), which is the linear projection of one-hot tensors denoting the position of stimuli in the sequence. We then concatenated a learned CLS (short for ‘classiﬁcation’) token (analogous to the CLS token in <xref ref-type="bibr" rid="bib20">Devlin et al., 2018</xref>) to <inline-formula><mml:math id="inf229"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi mathvariant="bold-italic">x</mml:mi><mml:mi mathvariant="bold-italic">R</mml:mi></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula>, before transforming with <xref ref-type="disp-formula" rid="equ14">Equation 14</xref>. We took the transformed value (<inline-formula><mml:math id="inf230"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mrow><mml:mover><mml:mi mathvariant="bold-italic">x</mml:mi><mml:mo stretchy="false">~</mml:mo></mml:mover></mml:mrow><mml:mi mathvariant="bold-italic">R</mml:mi></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula>) corresponding to the CLS token, and passed it to a linear layer with 1 output unit to generate a score for each candidate completion. This procedure was repeated for each candidate completion.</p><p>The seven scores (one for the correct completion and for six foil completions) were normalized using a softmax function, such that a higher score would correspond to a higher probability and vice versa, and the probabilities sum to 1. The inference module was trained using the task-speciﬁc cross-entropy loss (<inline-formula><mml:math id="inf231"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mrow><mml:mi class="mathcal" mathvariant="script">L</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi><mml:mi>a</mml:mi><mml:mi>s</mml:mi><mml:mi>k</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mrow><mml:mi mathvariant="normal">c</mml:mi><mml:mi mathvariant="normal">r</mml:mi><mml:mi mathvariant="normal">o</mml:mi><mml:mi mathvariant="normal">s</mml:mi><mml:mi mathvariant="normal">s</mml:mi><mml:mtext>-</mml:mtext><mml:mi mathvariant="normal">e</mml:mi><mml:mi mathvariant="normal">n</mml:mi><mml:mi mathvariant="normal">t</mml:mi><mml:mi mathvariant="normal">r</mml:mi><mml:mi mathvariant="normal">o</mml:mi><mml:mi mathvariant="normal">p</mml:mi><mml:mi mathvariant="normal">y</mml:mi></mml:mrow></mml:mrow></mml:mstyle></mml:math></inline-formula>) between the softmax-normalized scores and the index for the correct completion (target), deﬁned as <inline-formula><mml:math id="inf232"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mo>−</mml:mo><mml:mi>log</mml:mi><mml:mo>⁡</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mi>s</mml:mi><mml:mi>o</mml:mi><mml:mi>f</mml:mi><mml:mi>t</mml:mi><mml:mi>m</mml:mi><mml:mi>a</mml:mi><mml:mi>x</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mi mathvariant="normal">s</mml:mi><mml:mi mathvariant="normal">c</mml:mi><mml:mi mathvariant="normal">o</mml:mi><mml:mi mathvariant="normal">r</mml:mi><mml:mi mathvariant="normal">e</mml:mi><mml:mi mathvariant="normal">s</mml:mi></mml:mrow><mml:mo stretchy="false">)</mml:mo><mml:mo stretchy="false">[</mml:mo><mml:mrow><mml:mi mathvariant="normal">t</mml:mi><mml:mi mathvariant="normal">a</mml:mi><mml:mi mathvariant="normal">r</mml:mi><mml:mi mathvariant="normal">g</mml:mi><mml:mi mathvariant="normal">e</mml:mi><mml:mi mathvariant="normal">t</mml:mi></mml:mrow><mml:mo stretchy="false">]</mml:mo><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mstyle></mml:math></inline-formula>. It is worth noting that the properties of equivariance hold, since the probability distribution after applying softmax remains the same when the transformation (translation or scaling) is applied to the scores for each of the answer choices obtained from the output of the inference module, and when the same transformation is applied to the stimuli for the task and all the answer choices before presenting as input to the inference module to obtain the scores. We also tried formulating the tasks as regression problems, the details of which can be found in Appendix 1: ‘Regression formulation’.</p><p>While our model is not construed to be as speciﬁc about the implementation of the <inline-formula><mml:math id="inf233"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi mathvariant="bold-italic">R</mml:mi></mml:mrow></mml:mstyle></mml:math></inline-formula> module, we assume that – as a standard deep learning component – it is likely to map onto neocortical structures that interact with the entorhinal cortex and, in particular, regions of the prefrontal–posterior parietal network widely believed to be involved in abstract relational processes (<xref ref-type="bibr" rid="bib72">Waltz et al., 1999</xref>; <xref ref-type="bibr" rid="bib16">Christoff et al., 2001</xref>; <xref ref-type="bibr" rid="bib43">Knowlton et al., 2012</xref>; <xref ref-type="bibr" rid="bib70">Summerfield et al., 2020</xref>). In particular, the role of the prefrontal cortex in the encoding and active maintenance of abstract information needed for task performance (such as rules and relations) has often been modeled using gated recurrent networks, such as LSTMs (<xref ref-type="bibr" rid="bib24">Frank et al., 2001</xref>; <xref ref-type="bibr" rid="bib12">Braver and Cohen, 2000</xref>), and the posterior parietal cortex has long been known to support ‘maps’ that may provide an important substrate for computing complex relations (<xref ref-type="bibr" rid="bib70">Summerfield et al., 2020</xref>).</p></sec><sec id="s2-4"><title>Experiments</title><sec id="s2-4-1"><title>Experimental details</title><p>For each task, the sequence of stimuli for a given problem was encoded using grid cell code (see Grid cell code), that were then modulated by DPP-A (see DPP-A), and passed to the inference module <inline-formula><mml:math id="inf234"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi mathvariant="bold-italic">R</mml:mi></mml:mrow></mml:mstyle></mml:math></inline-formula> (see Inference module). We trained three networks using each type of inference module. For networks using an LSTM in the inference module, we trained each network for number of epochs for optimizing DPP attention <inline-formula><mml:math id="inf235"><mml:semantics><mml:mrow><mml:msub><mml:mi>N</mml:mi><mml:mrow><mml:msub><mml:mi>E</mml:mi><mml:mrow><mml:mi>D</mml:mi><mml:mi>P</mml:mi><mml:mi>P</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mn>50</mml:mn></mml:mrow></mml:semantics></mml:math></inline-formula>, number of epochs for optimizing task loss <inline-formula><mml:math id="inf236"><mml:semantics><mml:mrow><mml:msub><mml:mi>N</mml:mi><mml:mrow><mml:msub><mml:mi>E</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mi>a</mml:mi><mml:mi>s</mml:mi><mml:mi>k</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mn>50</mml:mn></mml:mrow></mml:semantics></mml:math></inline-formula>, on analogy problems, and for <inline-formula><mml:math id="inf237"><mml:semantics><mml:mrow><mml:msub><mml:mi>N</mml:mi><mml:mrow><mml:msub><mml:mi>E</mml:mi><mml:mrow><mml:mi>D</mml:mi><mml:mi>P</mml:mi><mml:mi>P</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mn>500</mml:mn></mml:mrow></mml:semantics></mml:math></inline-formula>, <inline-formula><mml:math id="inf238"><mml:semantics><mml:mrow><mml:msub><mml:mi>N</mml:mi><mml:mrow><mml:msub><mml:mi>E</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mi>a</mml:mi><mml:mi>s</mml:mi><mml:mi>k</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mn>500</mml:mn><mml:mo>,</mml:mo></mml:mrow></mml:semantics></mml:math></inline-formula> on arithmetic problems with a batch size of 256, using the ADAM optimizer (<xref ref-type="bibr" rid="bib42">Kingma and Ba, 2014</xref>), and a learning rate of <inline-formula><mml:math id="inf239"><mml:semantics><mml:mrow><mml:mn>1</mml:mn><mml:msup><mml:mi>e</mml:mi><mml:mrow><mml:mo>−</mml:mo><mml:mn>3</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:semantics></mml:math></inline-formula>. For networks using a transformer in the inference module, we trained with a batch size of 128 on analogy with a learning rate of <inline-formula><mml:math id="inf240"><mml:semantics><mml:mrow><mml:mn>5</mml:mn><mml:msup><mml:mi>e</mml:mi><mml:mrow><mml:mo>−</mml:mo><mml:mn>4</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:semantics></mml:math></inline-formula>, and on arithmetic problems with a learning rate of <inline-formula><mml:math id="inf241"><mml:semantics><mml:mrow><mml:mn>5</mml:mn><mml:msup><mml:mi>e</mml:mi><mml:mrow><mml:mo>−</mml:mo><mml:mn>5</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:semantics></mml:math></inline-formula>. More details can be found in Appendix 1: ‘More experimental details’.</p></sec><sec id="s2-4-2"><title>Comparison models</title><p>To evaluate how the grid cell code coupled with DPP-A compares with other architectures and approaches to generalization, and the extent to which each of these components contributed to the performance of the model, we compared it with several alternative models for performing the analogy and arithmetic tasks. First, we compared it with the TCN model (<xref ref-type="bibr" rid="bib73">Webb et al., 2020</xref>) (see Related work), but modiﬁed so as to use the grid cell code as input. We passed the grid cell embeddings for each input through a shared feedforward encoder which consisted of two fully connected layers with 256 units per layer. ReLU nonlinearities were used in both the layers. The ﬁnal embedding was generated with a linear layer of 256 units. TCN was applied to these embeddings and then passed as a sequence for each candidate completion to the inference module. This implementation of TCN involved a learned encoder on top of the grid cell embeddings, so it is closely analogous to the original TCN.</p><p>Next, we compared our model to one that used variational dropout (<xref ref-type="bibr" rid="bib27">Gal and Ghahramani, 2016</xref>), which is shown to be more eﬀective in generalization compared to naive dropout (<xref ref-type="bibr" rid="bib67">Srivastava et al., 2014</xref>). We randomly sampled a dropout mask (50% dropout), zeroing out the contribution of some of the grid cell code in the input to the inference module. We then use that locked dropout mask for every time step in the sequence. We also compared DPP-A to a model that had an additional penalty (L1 regularization) proportional to the absolute sum of the attention gates <inline-formula><mml:math id="inf242"><mml:semantics><mml:mi>g</mml:mi></mml:semantics></mml:math></inline-formula> along with the task-speciﬁc loss. We experimented with diﬀerent values of <italic>λ</italic>, which controlled the strength of the penalty relative to the cross-entropy loss. We report accuracy values for <italic>λ</italic> that achieved the best performance on the validation set. Accuracy values for various <italic>λ</italic>s are provided in Appendix 1: ‘Eﬀect of L1 Regularization strength (<italic>λ</italic>)’. Dropout and L1 regularization were chosen as a proxy for DPP-A and hence we used the same input data for fair comparison. Finally, we compared to a model that used the complete grid cell code, that is no DPP-A.</p></sec></sec><sec id="s2-5"><title>Related work</title><p>A body of recent computational work has shown that representations similar to grid cells can be derived using standard analytical techniques for dimensionality reduction (<xref ref-type="bibr" rid="bib22">Dordek et al., 2016</xref>; <xref ref-type="bibr" rid="bib68">Stachenfeld et al., 2017</xref>), as well as from error-driven learning paradigms (<xref ref-type="bibr" rid="bib18">Cueva and Wei, 2018</xref>; <xref ref-type="bibr" rid="bib3">Banino et al., 2018</xref>; <xref ref-type="bibr" rid="bib76">Whittington et al., 2020</xref>; <xref ref-type="bibr" rid="bib65">Sorscher et al., 2023</xref>). Previous work has also shown that grid cells emerge in networks trained to generalize to novel location/object combinations, and support transitive inference (<xref ref-type="bibr" rid="bib76">Whittington et al., 2020</xref>). Here, we show that grid cells enable strong OOD generalization when coupled with the appropriate attentional mechanism. Our proposed method is thus complementary to these previous approaches for obtaining grid cell representations from raw data.</p><p>In the ﬁeld of machine learning, DPPs have been used for supervised video summarization (<xref ref-type="bibr" rid="bib30">Gong et al., 2014</xref>), diverse recommendations (<xref ref-type="bibr" rid="bib15">Chen et al., 2018</xref>), selecting a subset of diverse neurons to prune a neural network without hurting performance (<xref ref-type="bibr" rid="bib50">Mariet and Sra, 2015</xref>), and diverse minibatch attention for stochastic gradient descent (<xref ref-type="bibr" rid="bib78">Zhang et al., 2017</xref>). Recently, <xref ref-type="bibr" rid="bib51">Mariet et al., 2019</xref> generated approximate DPP samples by proposing an inhibitive attention mechanism based on transformer networks as a proxy for capturing the dissimilarity between feature vectors, and <xref ref-type="bibr" rid="bib59">Perez-Beltrachini and Lapata, 2021</xref> used DPP-based attention with seq-to-seq architectures for diverse and relevant multi-document summarization. To our knowledge, however, DPPs have not previously been combined with the grid cell code that we employ here, and have not been used to enable OOD generalization.</p><p>Various approaches have been proposed to prevent deep learning systems from overﬁtting, and enable them to generalize. A commonly employed technique is weight decay (<xref ref-type="bibr" rid="bib45">Krogh and Hertz, 1992</xref>). <xref ref-type="bibr" rid="bib67">Srivastava et al., 2014</xref> proposed dropout, a regularization technique which reduces overﬁtting by randomly zeroing units from the neural network during training. Recently, <xref ref-type="bibr" rid="bib73">Webb et al., 2020</xref> proposed TCN in which a normalization similar to batch normalization (<xref ref-type="bibr" rid="bib40">Ioﬀe and Szegedy, 2015</xref>) was applied over the temporal dimension instead of the batch dimension. However, unlike these previous approaches, the method reported here achieves nearly perfect OOD generalization when operating over the appropriate representation, as we show in the results. Our proposed method also has the virtue of being based on a well understood, and biologically plausible, encoding scheme (grid cell code).</p></sec></sec><sec id="s3" sec-type="results"><title>Results</title><sec id="s3-1"><title>Analogy</title><p>We ﬁrst present results on the analogy task for two types of testing data, translation and scaling using two types of inference module, LSTM and transformer. We trained three networks for each method and report mean accuracy along with standard error of the mean. <xref ref-type="fig" rid="fig3">Figure 3</xref> shows the results for the analogy task using an LSTM in the inference module. The left panel shows results for the translation regime, and the right panel shows results for the scaling regime. Both plots show accuracy on the training and validation sets, and on a series of nine (increasingly distant) OOD generalization test regions. DPP-A (shown in blue) achieves nearly perfect accuracy on all of the test regions, considerably outperforming the other models.</p><fig id="fig3" position="float"><label>Figure 3.</label><caption><title>Results on analogy on each region for translation and scaling using LSTM in the inference module.</title></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-89911-fig3-v1.tif"/></fig><p>For the case of translation, using all the grid cell code with no DPP-A (shown in purple) led to the worst OOD generalization performance, overﬁtting on the training set. Locked dropout (denoted by green) and L1 regularization (denoted by red) reduced overﬁtting and demonstrated better OOD generalization performance than no DPP-A but still performed considerably worse than DPP-A. For the case of scaling, locked dropout and L1 regularization performed slightly better than TCN, achieving marginally higher test accuracy, but DPP-A still substantially outperformed all other models, with a nearly 70% improvement in average test accuracy.</p><p>To test the generality of the grid cell code and DPP-A across network architectures, we also tested a transformer (<xref ref-type="bibr" rid="bib71">Vaswani et al., 2017</xref>) in place of the LSTM in the inference module. Previous work has suggested that transformers are particularly useful for extracting structure in sequential data and have been used for OOD generalization (<xref ref-type="bibr" rid="bib62">Saxton et al., 2019</xref>). <xref ref-type="fig" rid="fig4">Figure 4</xref> shows the results for the analogy task using a transformer in the inference module. With no explicit attention (no DPP-A) over the grid cell code (shown in orange), the transformer did poorly on the analogies on the test regions. This suggests that simply using a more sophisticated architecture with standard forms of attention is not suﬃcient to enable OOD generalization based on the grid cell code. With DPP-A (shown in blue), the OOD generalization performance of the transformer is nearly perfect for both translation and scaling. These results also demonstrate that grid cell code coupled with DPP-A can be exploited for OOD generalization eﬀectively by diﬀerent architectures.</p><fig id="fig4" position="float"><label>Figure 4.</label><caption><title>Results on analogy on each region for translation and scaling using the transformer in the inference module.</title></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-89911-fig4-v1.tif"/></fig></sec><sec id="s3-2"><title>Arithmetic</title><p>We next present results on the arithmetic task for two types of operations, addition and multiplication using two types of inference module, LSTM and transformer. We trained three networks for each method and report mean accuracy along with standard error of the mean.</p><p><xref ref-type="fig" rid="fig5">Figure 5</xref> shows the results for arithmetic problems using an LSTM in the inference module. The left panel shows results for addition problems, and the right panel shows results for multiplication problems. DPP-A achieves higher accuracy for addition than multiplication on the test regions. However, in both cases DPP-A signiﬁcantly outperforms the other models, achieving nearly perfect OOD generalization for addition, and 65% accuracy for multiplication, compared with under 20% accuracy for all the other models. We found that grid cell embeddings obtained after the ﬁrst step in Algorithm 1 are not able to fully preserve the relational structure for multiplication problems on the test regions (more details in Appendix 1: ‘Why is OOD generalization performance worse for the multiplication task?’), but still it aﬀords superior capacity for OOD generalization than any of the other models. Thus, while it does not match the generalizability of a genuine algorithmic (i.e., symbolic) arithmetic function, it may be suﬃcient for some tasks (e.g., approximate multiplication ability in young children; <xref ref-type="bibr" rid="bib60">Qu et al., 2021</xref>).</p><fig id="fig5" position="float"><label>Figure 5.</label><caption><title>Results on arithmetic on each region using LSTM in the inference module.</title></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-89911-fig5-v1.tif"/></fig><p><xref ref-type="fig" rid="fig6">Figure 6</xref> shows the results for arithmetic problems using a transformer in the inference module. With no DPP-A over the grid cell code the transformer did poorly on addition and multiplication on the test regions, achieving around 20–30% accuracy. With DPP-A, the OOD generalization performance of the transformer shows a pattern similar to that for LSTM: it is nearly perfect for addition and, though not as good on multiplication, nevertheless shows approximately 40% better performance than the transformer multiplication.</p><fig id="fig6" position="float"><label>Figure 6.</label><caption><title>Results on arithmetic on each region using the transformer in the inference module.</title></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-89911-fig6-v1.tif"/></fig></sec><sec id="s3-3"><title>Ablation study</title><p>To determine the individual importance of the grid cell code and the DPP-A attention objective, we carried out several ablation studies. First, to evaluate the importance of grid cell code, we analyzed the eﬀect of DPP-A with other embeddings, using either one-hot or smoothed one-hot embeddings (similar to place cell coding) with standard deviations of 1, 10, and 100, each passed through a learned feedforward encoder, which consisted of two fully connected layers with 1024 units per layer, and ReLU nonlinearities. The ﬁnal embedding was generated with a fully connected layer with 1024 units and sigmoid nonlinearity. Since these embeddings do not have a frequency component, the training procedure with DPP-A consisted of only one step: minimizing the loss function <inline-formula><mml:math id="inf243"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mrow><mml:mi class="mathcal" mathvariant="script">L</mml:mi></mml:mrow><mml:mo>=</mml:mo><mml:msub><mml:mrow><mml:mi class="mathcal" mathvariant="script">L</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi><mml:mi>a</mml:mi><mml:mi>s</mml:mi><mml:mi>k</mml:mi></mml:mrow></mml:msub><mml:mo>−</mml:mo><mml:mi>λ</mml:mi><mml:mo>∗</mml:mo><mml:mrow><mml:mover><mml:mi>F</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi mathvariant="bold-italic">g</mml:mi><mml:mo>,</mml:mo><mml:mi mathvariant="bold-italic">V</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mstyle></mml:math></inline-formula>. We tried diﬀerent values of <italic>λ</italic> (0.001, 0.01, 0.1, 1, 10, 100, 1000, 10,000). For each type of embedding (one-hots and smoothed one-hots with each value of standard deviation), we trained three networks and report for the model that achieved best performance on the validation set. Note that, given the much higher dimensionality and therefore memory demands of embeddings based on one-hots and smoothed one-hots, we had to limit the evaluation to a subset of the total space, resulting in evaluation on only two test regions (i.e., <inline-formula><mml:math id="inf244"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>K</mml:mi><mml:mo>∈</mml:mo><mml:mo stretchy="false">[</mml:mo><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mn>3</mml:mn><mml:mo stretchy="false">]</mml:mo></mml:mrow></mml:mstyle></mml:math></inline-formula>).</p><p><xref ref-type="fig" rid="fig7">Figure 7</xref> shows the results for the analogy task (results for the arithmetic task are in Appendix 1: ‘Ablation study on arithmetic task’, <xref ref-type="fig" rid="app1fig3">Appendix 1—figure 3</xref>) using an LSTM in the inference module. The average accuracy on the test regions for translation and scaling using smoothed one-hots passed through an encoder (shown in green) is nearly 30% better than simple one-hot embeddings passed through an encoder (shown in orange), but both still achieve signiﬁcantly lower test accuracy than grid cell code which support perfect OOD generalization.</p><fig id="fig7" position="float"><label>Figure 7.</label><caption><title>Results on analogy on each region using determinantal point process attention (DPP-A), an LSTM in the inference module, and different embeddings (grid cell code, one-hots, and smoothed one-hots passed through a learned encoder) for translation (left) and scaling (right).</title><p>Each point is mean accuracy over three networks, and bars show standard error of the mean.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-89911-fig7-v1.tif"/></fig><p>With respect to the importance of the DPP-A, we note that the simulations reported earlier show that replacing the DPP-A mechanism with either other forms of regularization (dropout and L1 regularization; see Comparison models) or a transformer (<xref ref-type="fig" rid="fig4">Figure 4</xref> in Analogy for analogy and <xref ref-type="fig" rid="fig6">Figure 6</xref> in Arithmetic for arithmetic tasks) failed to achieve the same level of OOD generalization as the network that used DPP-A. The results using a transformer are particularly instructive, as that incorporates a powerful mechanism for learned attention, but, even when provided with grid cell embeddings, failed to produce results comparable to DPP-A, suggesting that the latter provides a simple but powerful form of attention objective, at least when used in conjunction with grid cell embeddings.</p><p>Finally, for completeness, we also carried out a set of simulations that examined the performance of networks with various embeddings (grid cell code, and one-hots or smoothed one-hots with or without a learned feedforward encoder), but no attention or regularization (i.e., neither DPP-A, transformer, nor TCN, L1 Regularization, or Dropout). <xref ref-type="fig" rid="fig8">Figure 8</xref> shows the results for the diﬀerent embeddings on the analogy task (results for the arithmetic task are in Appendix 1: ‘Ablation study on arithmetic task’, <xref ref-type="fig" rid="app1fig4">Appendix 1—figure 4</xref>). For translation (left), the average accuracy over the test regions using grid cell code (shown in blue) is nearly 25% more compared to other embeddings, which all yield performance near chance (∼15%). For scaling (right), although other embeddings achieve higher performance than chance (except smoothed one-hots), they still achieve lower test accuracy than grid cell code. More ablation studies can be found in Appendix 1: ‘Ablation study on choice of frequency’, ‘Ablation on DPP-A’, and Figure A5.</p><fig id="fig8" position="float"><label>Figure 8.</label><caption><title>Results on analogy on each region using different embeddings (grid cell code, and one-hots or smoothed one-hots with and without an encoder) and an LSTM in the inference module, but without determinantal point process attention (DPP-A), temporal context normalization (TCN), L1 Regularization, or Dropout for translation (left) and scaling (right).</title></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-89911-fig8-v1.tif"/></fig></sec></sec><sec id="s4" sec-type="discussion"><title>Discussion</title><p>We have identiﬁed how particular properties of processing observed in the brain can be used to achieve strong OOD generalization, and introduced a two-component algorithm to promote OOD generalization in deep neural networks. The ﬁrst component is a structured representation of the training data, modeled closely on known properties of grid cells – a population of cells that collectively represent abstract position using a periodic code. However, despite their intrinsic structure, we ﬁnd that grid cell code and standard error-driven learning alone are insuﬃcient to promote OOD generalization, and standard approaches for preventing overﬁtting oﬀer only modest gains. This is addressed by the second component, using DPP-A to implement attentional regularization over the grid cell code. DPP-A allows only a relevant and diverse subset of cells to inﬂuence downstream computation in the inference module using the statistics of the training data. For proof of concept, we started with two challenging cognitive tasks (analogy and arithmetic), and showed that the combination of grid cell code and DPP-A promotes OOD generalization across both translation and scale when incorporated into common architectures (LSTM and transformer). It is worth noting that the DPP-A attentional mechanism is diﬀerent from the attentional mechanism in the transformer module, and both are needed for strong OOD generalization in the case of transformers. Use of the standard self-attention mechanism in transformers over the inputs (i.e., A, B, C, and D for the analogy task) in place of DPP-A would lead to weightings of grid cell embeddings over all frequencies and phases. The objective function for the DPP-A represents an inductive bias, that selectively assigns the greatest weight to all grid cell embeddings (i.e., for all phases) of the frequency for which the determinant of the covariance matrix is greatest computed over the training space. The transformer inference module then attends over the inputs with the selected grid cell embeddings based on the DPP-A objective.</p><p>The current approach has some limitations and presents interesting directions for future work. First, we derive the grid cell code from known properties of neural systems, rather than obtaining the code directly from real-world data. Here, we are encouraged by the body of work providing evidence for grid cell code in the hidden layers of neural networks in a variety of task contexts and architectures (<xref ref-type="bibr" rid="bib75">Wei et al., 2015</xref>; <xref ref-type="bibr" rid="bib18">Cueva and Wei, 2018</xref>; <xref ref-type="bibr" rid="bib3">Banino et al., 2018</xref>; <xref ref-type="bibr" rid="bib76">Whittington et al., 2020</xref>). This suggests reason for optimism that DPP-A may promote strong generalization in cases where grid cell code naturally emerge: for example, navigation tasks (<xref ref-type="bibr" rid="bib3">Banino et al., 2018</xref>) and reasoning by transitive inference (<xref ref-type="bibr" rid="bib76">Whittington et al., 2020</xref>). Integrating our approach with structured representations acquired from high-dimensional, naturalistic datasets remains a critical next step which would have signiﬁcant potential for broader future practical applications. So too does application to more complex transformations beyond translation and scale, such as rotation, and complex forms of representations, and analogical reasoning tasks (<xref ref-type="bibr" rid="bib38">Holyoak, 2012</xref>; <xref ref-type="bibr" rid="bib74">Webb et al., 2023</xref>; <xref ref-type="bibr" rid="bib48">Lu et al., 2022</xref>). Second, it is not clear how DPP-A might be implemented in a neural network. In that regard, <xref ref-type="bibr" rid="bib10">Bozkurt et al., 2022</xref> recently proposed a biologically plausible neural network algorithm using a weighted similarity matrix approach to implement a determinant maximization criterion, which is the core idea underlying the objective function we use for DPP-A (<xref ref-type="disp-formula" rid="equ6">Equation 6</xref>), suggesting that the DPP-A mechanism we describe may also be biologically plausible. This could be tested experimentally by exposing individuals (e.g., rodents or humans) to a task that requires consistent exposure to a subregion, and evaluating the distribution of activity over the grid cells. Our model predicts that high-frequency grid cells should increase their ﬁring rate more than low-frequency cells, since the high-frequency grid cells maximize the determinant of the covariance matrix of the grid cell embeddings. It is also worth noting that <xref ref-type="bibr" rid="bib26">Frankland and Cohen, 2020</xref> have suggested that the use of DPPs may also help explain a mutual exclusivity bias observed in human word learning and reasoning. While this is not direct evidence of biological plausibility, it is consistent with the idea that the human brain selects representations for processing that maximize the volume of the representational space, which can be achieved by maximizing the DPP-A objective function deﬁned in <xref ref-type="disp-formula" rid="equ6">Equation 6</xref>. Third, we compared grid cell code to only one-hots and place cell code. Future work could compare to a broader range of potential biological coding schemes for the overall space, for example boundary vector cell coding (<xref ref-type="bibr" rid="bib6">Barry et al., 2006</xref>), band cell coding, or egocentric boundary cell coding (<xref ref-type="bibr" rid="bib36">Hinman et al., 2019</xref>).</p><p>Finally, we focus on analogies in linear spaces which limits the generality of our approach in nonlinear spaces. In that regard, there are at least two potential directions that could be pursued. One is to directly encode nonlinear structures (such as trees and rings) with grid cells, to which DPP-A could be applied as described in our model. The Tolman-Eichenbaum Machine (TEM) model (<xref ref-type="bibr" rid="bib76">Whittington et al., 2020</xref>) suggests that grid cells in the medial entorhinal may form a basis set that captures structural knowledge for such nonlinear spaces, such as social hierarchies and transitive inference when formalized as a connected graph. Another would be to use eigen decomposition of the successor representation (<xref ref-type="bibr" rid="bib19">Dayan, 1993</xref>), a learnable predictive representation of possible future states that has been shown by <xref ref-type="bibr" rid="bib68">Stachenfeld et al., 2017</xref> to provide an abstract structured representation of a space that is analogous to the grid cell code. This general-purpose mechanism could be applied to represent analogies in nonlinear spaces (<xref ref-type="bibr" rid="bib25">Frankland et al., 2019</xref>), for which there may not be a clear factorization in terms of grid cells (i.e., distinct frequencies and multiple phases within each frequency). Since the DPP-A mechanism, as we have described it, requires representations to be factored in this way it would need to be modiﬁed for such purpose. Either of these approaches, if successful, would allow our model to be extended to domains containing nonlinear forms of structure. To the extent that diﬀerent coding schemes (i.e., basis sets) are needed for diﬀerent forms of structure, the question of how these are identiﬁed and engaged for use in a given setting is clearly an important one, that is not addressed by the current work. We imagine that this is likely subserved by monitoring and selection mechanisms proposed to underlie the capacity for selective attention and cognitive control (<xref ref-type="bibr" rid="bib63">Shenhav et al., 2013</xref>), though the speciﬁc computational mechanisms that underlie this function remain an important direction for future research.</p></sec></body><back><sec sec-type="additional-information" id="s5"><title>Additional information</title><fn-group content-type="competing-interest"><title>Competing interests</title><fn fn-type="COI-statement" id="conf1"><p>No competing interests declared</p></fn></fn-group><fn-group content-type="author-contribution"><title>Author contributions</title><fn fn-type="con" id="con1"><p>Data curation, Formal analysis, Visualization, Methodology, Writing - original draft</p></fn><fn fn-type="con" id="con2"><p>Conceptualization, Supervision, Writing – review and editing</p></fn><fn fn-type="con" id="con3"><p>Conceptualization, Supervision, Writing – review and editing</p></fn><fn fn-type="con" id="con4"><p>Conceptualization, Supervision, Funding acquisition, Project administration, Writing – review and editing</p></fn></fn-group></sec><sec sec-type="supplementary-material" id="s6"><title>Additional files</title><supplementary-material id="mdar"><label>MDAR checklist</label><media xlink:href="elife-89911-mdarchecklist1-v1.docx" mimetype="application" mime-subtype="docx"/></supplementary-material><supplementary-material id="sdata1"><label>Source data 1.</label><caption><title>The zip file contains the data for the arithmetic task.</title></caption><media xlink:href="elife-89911-data1-v1.zip" mimetype="application" mime-subtype="zip"/></supplementary-material><supplementary-material id="scode1"><label>Source code 1.</label><caption><title>The zip file contains the code downloaded from the github repo provided earlier.</title></caption><media xlink:href="elife-89911-code1-v1.zip" mimetype="application" mime-subtype="zip"/></supplementary-material></sec><sec sec-type="data-availability" id="s7"><title>Data availability</title><p>All data generated during this study are uploaded as source data files. Modeling code is uploaded as <xref ref-type="supplementary-material" rid="scode1">Source code 1</xref>.</p></sec><ref-list><title>References</title><ref id="bib1"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Aronov</surname><given-names>D</given-names></name><name><surname>Nevers</surname><given-names>R</given-names></name><name><surname>Tank</surname><given-names>DW</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>Mapping of a non-spatial dimension by the hippocampal-entorhinal circuit</article-title><source>Nature</source><volume>543</volume><fpage>719</fpage><lpage>722</lpage><pub-id pub-id-type="doi">10.1038/nature21692</pub-id><pub-id pub-id-type="pmid">28358077</pub-id></element-citation></ref><ref id="bib2"><element-citation publication-type="preprint"><person-group person-group-type="author"><name><surname>Ba</surname><given-names>JL</given-names></name><name><surname>Kiros</surname><given-names>JR</given-names></name><name><surname>Hinton</surname><given-names>GE</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Layer Normalization</article-title><source>arXiv</source><ext-link ext-link-type="uri" xlink:href="https://arxiv.org/abs/1607.06450">https://arxiv.org/abs/1607.06450</ext-link></element-citation></ref><ref id="bib3"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Banino</surname><given-names>A</given-names></name><name><surname>Barry</surname><given-names>C</given-names></name><name><surname>Uria</surname><given-names>B</given-names></name><name><surname>Blundell</surname><given-names>C</given-names></name><name><surname>Lillicrap</surname><given-names>T</given-names></name><name><surname>Mirowski</surname><given-names>P</given-names></name><name><surname>Pritzel</surname><given-names>A</given-names></name><name><surname>Chadwick</surname><given-names>MJ</given-names></name><name><surname>Degris</surname><given-names>T</given-names></name><name><surname>Modayil</surname><given-names>J</given-names></name><name><surname>Wayne</surname><given-names>G</given-names></name><name><surname>Soyer</surname><given-names>H</given-names></name><name><surname>Viola</surname><given-names>F</given-names></name><name><surname>Zhang</surname><given-names>B</given-names></name><name><surname>Goroshin</surname><given-names>R</given-names></name><name><surname>Rabinowitz</surname><given-names>N</given-names></name><name><surname>Pascanu</surname><given-names>R</given-names></name><name><surname>Beattie</surname><given-names>C</given-names></name><name><surname>Petersen</surname><given-names>S</given-names></name><name><surname>Sadik</surname><given-names>A</given-names></name><name><surname>Gaffney</surname><given-names>S</given-names></name><name><surname>King</surname><given-names>H</given-names></name><name><surname>Kavukcuoglu</surname><given-names>K</given-names></name><name><surname>Hassabis</surname><given-names>D</given-names></name><name><surname>Hadsell</surname><given-names>R</given-names></name><name><surname>Kumaran</surname><given-names>D</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>Vector-based navigation using grid-like representations in artificial agents</article-title><source>Nature</source><volume>557</volume><fpage>429</fpage><lpage>433</lpage><pub-id pub-id-type="doi">10.1038/s41586-018-0102-6</pub-id><pub-id pub-id-type="pmid">29743670</pub-id></element-citation></ref><ref id="bib4"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bao</surname><given-names>X</given-names></name><name><surname>Gjorgieva</surname><given-names>E</given-names></name><name><surname>Shanahan</surname><given-names>LK</given-names></name><name><surname>Howard</surname><given-names>JD</given-names></name><name><surname>Kahnt</surname><given-names>T</given-names></name><name><surname>Gottfried</surname><given-names>JA</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>Grid-like neural representations support olfactory navigation of a two-dimensional odor space</article-title><source>Neuron</source><volume>102</volume><fpage>1066</fpage><lpage>1075</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2019.03.034</pub-id><pub-id pub-id-type="pmid">31023509</pub-id></element-citation></ref><ref id="bib5"><element-citation publication-type="confproc"><person-group person-group-type="author"><name><surname>Barrett</surname><given-names>D</given-names></name><name><surname>Hill</surname><given-names>F</given-names></name><name><surname>Santoro</surname><given-names>A</given-names></name><name><surname>Morcos</surname><given-names>A</given-names></name><name><surname>Lillicrap</surname><given-names>T</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>Measuring abstract reasoning in neural networks</article-title><conf-name>Proceedings of the 35th International Conference on Machine Learning</conf-name><fpage>511</fpage><lpage>520</lpage></element-citation></ref><ref id="bib6"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Barry</surname><given-names>C</given-names></name><name><surname>Lever</surname><given-names>C</given-names></name><name><surname>Hayman</surname><given-names>R</given-names></name><name><surname>Hartley</surname><given-names>T</given-names></name><name><surname>Burton</surname><given-names>S</given-names></name><name><surname>O’Keefe</surname><given-names>J</given-names></name><name><surname>Jeffery</surname><given-names>K</given-names></name><name><surname>Burgess</surname><given-names>N</given-names></name></person-group><year iso-8601-date="2006">2006</year><article-title>The boundary vector cell model of place cell firing and spatial memory</article-title><source>Reviews in the Neurosciences</source><volume>17</volume><fpage>71</fpage><lpage>97</lpage><pub-id pub-id-type="doi">10.1515/revneuro.2006.17.1-2.71</pub-id><pub-id pub-id-type="pmid">16703944</pub-id></element-citation></ref><ref id="bib7"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Barry</surname><given-names>C</given-names></name><name><surname>Hayman</surname><given-names>R</given-names></name><name><surname>Burgess</surname><given-names>N</given-names></name><name><surname>Jeffery</surname><given-names>KJ</given-names></name></person-group><year iso-8601-date="2007">2007</year><article-title>Experience-dependent rescaling of entorhinal grids</article-title><source>Nature Neuroscience</source><volume>10</volume><fpage>682</fpage><lpage>684</lpage><pub-id pub-id-type="doi">10.1038/nn1905</pub-id><pub-id pub-id-type="pmid">17486102</pub-id></element-citation></ref><ref id="bib8"><element-citation publication-type="software"><person-group person-group-type="author"><name><surname>Bicanski</surname><given-names>A</given-names></name></person-group><year iso-8601-date="2019">2019</year><data-title>VisualGridsRecognitionMem</data-title><version designator="9d56e64">9d56e64</version><source>GitHub</source><ext-link ext-link-type="uri" xlink:href="https://github.com/bicanski/VisualGridsRecognitionMem">https://github.com/bicanski/VisualGridsRecognitionMem</ext-link></element-citation></ref><ref id="bib9"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bicanski</surname><given-names>A</given-names></name><name><surname>Burgess</surname><given-names>N</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>A computational model of visual recognition memory via grid cells</article-title><source>Current Biology</source><volume>29</volume><fpage>979</fpage><lpage>990</lpage><pub-id pub-id-type="doi">10.1016/j.cub.2019.01.077</pub-id><pub-id pub-id-type="pmid">30853437</pub-id></element-citation></ref><ref id="bib10"><element-citation publication-type="confproc"><person-group person-group-type="author"><name><surname>Bozkurt</surname><given-names>B</given-names></name><name><surname>Pehlevan</surname><given-names>C</given-names></name><name><surname>Erdogan</surname><given-names>A</given-names></name></person-group><year iso-8601-date="2022">2022</year><article-title>Biologically-plausible determinant maximization neural networks for blind separation of correlated sources</article-title><conf-name>Advances in Neural Information Processing Systems</conf-name><fpage>13704</fpage><lpage>13717</lpage></element-citation></ref><ref id="bib11"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Brandon</surname><given-names>MP</given-names></name><name><surname>Bogaard</surname><given-names>AR</given-names></name><name><surname>Libby</surname><given-names>CP</given-names></name><name><surname>Connerney</surname><given-names>MA</given-names></name><name><surname>Gupta</surname><given-names>K</given-names></name><name><surname>Hasselmo</surname><given-names>ME</given-names></name></person-group><year iso-8601-date="2011">2011</year><article-title>Reduction of theta rhythm dissociates grid cell spatial periodicity from directional tuning</article-title><source>Science</source><volume>332</volume><fpage>595</fpage><lpage>599</lpage><pub-id pub-id-type="doi">10.1126/science.1201652</pub-id><pub-id pub-id-type="pmid">21527714</pub-id></element-citation></ref><ref id="bib12"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Braver</surname><given-names>TS</given-names></name><name><surname>Cohen</surname><given-names>JD</given-names></name></person-group><year iso-8601-date="2000">2000</year><article-title>On the control of control: The role of dopamine in regulating prefrontal function and working memory</article-title><source>Attention and Performance</source><volume>18</volume><fpage>712</fpage><lpage>737</lpage></element-citation></ref><ref id="bib13"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bush</surname><given-names>D</given-names></name><name><surname>Barry</surname><given-names>C</given-names></name><name><surname>Manson</surname><given-names>D</given-names></name><name><surname>Burgess</surname><given-names>N</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>Using grid cells for navigation</article-title><source>Neuron</source><volume>87</volume><fpage>507</fpage><lpage>520</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2015.07.006</pub-id><pub-id pub-id-type="pmid">26247860</pub-id></element-citation></ref><ref id="bib14"><element-citation publication-type="preprint"><person-group person-group-type="author"><name><surname>Chandra</surname><given-names>S</given-names></name><name><surname>Sharma</surname><given-names>S</given-names></name><name><surname>Chaudhuri</surname><given-names>R</given-names></name><name><surname>Fiete</surname><given-names>I</given-names></name></person-group><year iso-8601-date="2023">2023</year><article-title>High-Capacity FLexible Hippocampal Associative and Episodic Memory Enabled by Prestructured”spatial”representations</article-title><source>bioRxiv</source><pub-id pub-id-type="doi">10.1101/2023.11.28.568960</pub-id></element-citation></ref><ref id="bib15"><element-citation publication-type="confproc"><person-group person-group-type="author"><name><surname>Chen</surname><given-names>L</given-names></name><name><surname>Zhang</surname><given-names>G</given-names></name><name><surname>Zhou</surname><given-names>H</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>Fast greedy map inference for determinantal point process to improve recommendation diversity</article-title><conf-name>Proceedings of the 32nd International Conference on Neural Information Processing Systems</conf-name><fpage>5627</fpage><lpage>5638</lpage></element-citation></ref><ref id="bib16"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Christoff</surname><given-names>K</given-names></name><name><surname>Prabhakaran</surname><given-names>V</given-names></name><name><surname>Dorfman</surname><given-names>J</given-names></name><name><surname>Zhao</surname><given-names>Z</given-names></name><name><surname>Kroger</surname><given-names>JK</given-names></name><name><surname>Holyoak</surname><given-names>KJ</given-names></name><name><surname>Gabrieli</surname><given-names>JD</given-names></name></person-group><year iso-8601-date="2001">2001</year><article-title>Rostrolateral prefrontal cortex involvement in relational integration during reasoning</article-title><source>NeuroImage</source><volume>14</volume><fpage>1136</fpage><lpage>1149</lpage><pub-id pub-id-type="doi">10.1006/nimg.2001.0922</pub-id><pub-id pub-id-type="pmid">11697945</pub-id></element-citation></ref><ref id="bib17"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Constantinescu</surname><given-names>AO</given-names></name><name><surname>O’Reilly</surname><given-names>JX</given-names></name><name><surname>Behrens</surname><given-names>TEJ</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Organizing conceptual knowledge in humans with a gridlike code</article-title><source>Science</source><volume>352</volume><fpage>1464</fpage><lpage>1468</lpage><pub-id pub-id-type="doi">10.1126/science.aaf0941</pub-id><pub-id pub-id-type="pmid">27313047</pub-id></element-citation></ref><ref id="bib18"><element-citation publication-type="preprint"><person-group person-group-type="author"><name><surname>Cueva</surname><given-names>CJ</given-names></name><name><surname>Wei</surname><given-names>XX</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>Emergence of Grid-like Representations by Training Recurrent Neural Networks to Perform Spatial Localization</article-title><source>arXiv</source><ext-link ext-link-type="uri" xlink:href="https://arxiv.org/abs/1803.07770">https://arxiv.org/abs/1803.07770</ext-link></element-citation></ref><ref id="bib19"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Dayan</surname><given-names>P</given-names></name></person-group><year iso-8601-date="1993">1993</year><article-title>Improving generalization for temporal difference learning: The successor representation</article-title><source>Neural Computation</source><volume>5</volume><fpage>613</fpage><lpage>624</lpage><pub-id pub-id-type="doi">10.1162/neco.1993.5.4.613</pub-id></element-citation></ref><ref id="bib20"><element-citation publication-type="preprint"><person-group person-group-type="author"><name><surname>Devlin</surname><given-names>J</given-names></name><name><surname>Chang</surname><given-names>MW</given-names></name><name><surname>Lee</surname><given-names>K</given-names></name><name><surname>Toutanova</surname><given-names>K</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>Bert: Pre-Training of Deep Bidirectional Transformers for Language Understanding</article-title><source>arXiv</source><ext-link ext-link-type="uri" xlink:href="https://arxiv.org/abs/1810.04805">https://arxiv.org/abs/1810.04805</ext-link></element-citation></ref><ref id="bib21"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Doeller</surname><given-names>CF</given-names></name><name><surname>Barry</surname><given-names>C</given-names></name><name><surname>Burgess</surname><given-names>N</given-names></name></person-group><year iso-8601-date="2010">2010</year><article-title>Evidence for grid cells in a human memory network</article-title><source>Nature</source><volume>463</volume><fpage>657</fpage><lpage>661</lpage><pub-id pub-id-type="doi">10.1038/nature08704</pub-id><pub-id pub-id-type="pmid">20090680</pub-id></element-citation></ref><ref id="bib22"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Dordek</surname><given-names>Y</given-names></name><name><surname>Soudry</surname><given-names>D</given-names></name><name><surname>Meir</surname><given-names>R</given-names></name><name><surname>Derdikman</surname><given-names>D</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Extracting grid cell characteristics from place cell inputs using non-negative principal component analysis</article-title><source>eLife</source><volume>5</volume><elocation-id>e10094</elocation-id><pub-id pub-id-type="doi">10.7554/eLife.10094</pub-id><pub-id pub-id-type="pmid">26952211</pub-id></element-citation></ref><ref id="bib23"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Erdem</surname><given-names>UM</given-names></name><name><surname>Hasselmo</surname><given-names>ME</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>A biologically inspired hierarchical goal directed navigation model</article-title><source>Journal of Physiology, Paris</source><volume>108</volume><fpage>28</fpage><lpage>37</lpage><pub-id pub-id-type="doi">10.1016/j.jphysparis.2013.07.002</pub-id><pub-id pub-id-type="pmid">23891644</pub-id></element-citation></ref><ref id="bib24"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Frank</surname><given-names>MJ</given-names></name><name><surname>Loughry</surname><given-names>B</given-names></name><name><surname>O’reilly</surname><given-names>RC</given-names></name></person-group><year iso-8601-date="2001">2001</year><article-title>Interactions between frontal cortex and basal ganglia in working memory: A computational model</article-title><source>Cognitive, Affective, &amp; Behavioral Neuroscience</source><volume>1</volume><fpage>137</fpage><lpage>160</lpage><pub-id pub-id-type="doi">10.3758/CABN.1.2.137</pub-id></element-citation></ref><ref id="bib25"><element-citation publication-type="confproc"><person-group person-group-type="author"><name><surname>Frankland</surname><given-names>S</given-names></name><name><surname>Webb</surname><given-names>TW</given-names></name><name><surname>Petrov</surname><given-names>AA</given-names></name><name><surname>O’Reilly</surname><given-names>RC</given-names></name><name><surname>Cohen</surname><given-names>J</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>Extracting and utilizing abstract, structured representations for analogy</article-title><conf-name>Proceedings of the 41st Annual Meeting of the Cognitive Science Society: Creativity + Cognition + Computation, CogSci 2019</conf-name><fpage>1766</fpage><lpage>1772</lpage></element-citation></ref><ref id="bib26"><element-citation publication-type="confproc"><person-group person-group-type="author"><name><surname>Frankland</surname><given-names>S</given-names></name><name><surname>Cohen</surname><given-names>J</given-names></name></person-group><year iso-8601-date="2020">2020</year><article-title>Determinantal point processes for memory and structured inference</article-title><conf-name>42nd Annual Meeting of the Cognitive Science Society: Developing a Mind: Learning in Humans, Animals, and Machines, CogSci 2020</conf-name><fpage>3302</fpage><lpage>3308</lpage></element-citation></ref><ref id="bib27"><element-citation publication-type="confproc"><person-group person-group-type="author"><name><surname>Gal</surname><given-names>Y</given-names></name><name><surname>Ghahramani</surname><given-names>Z</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>A theoretically grounded application of dropout in recurrent neural networks</article-title><conf-name>Advances in Neural Information Processing Systems</conf-name><fpage>1019</fpage><lpage>1027</lpage></element-citation></ref><ref id="bib28"><element-citation publication-type="confproc"><person-group person-group-type="author"><name><surname>Gillenwater</surname><given-names>J</given-names></name><name><surname>Kulesza</surname><given-names>A</given-names></name><name><surname>Taskar</surname><given-names>B</given-names></name></person-group><year iso-8601-date="2012">2012</year><article-title>Near-optimal map inference for determinantal point processes</article-title><conf-name>Advances in Neural Information Processing Systems</conf-name><fpage>2744</fpage><lpage>2752</lpage></element-citation></ref><ref id="bib29"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Giocomo</surname><given-names>LM</given-names></name><name><surname>Hussaini</surname><given-names>SA</given-names></name><name><surname>Zheng</surname><given-names>F</given-names></name><name><surname>Kandel</surname><given-names>ER</given-names></name><name><surname>Moser</surname><given-names>M-B</given-names></name><name><surname>Moser</surname><given-names>EI</given-names></name></person-group><year iso-8601-date="2011">2011</year><article-title>Grid cells use HCN1 channels for spatial scaling</article-title><source>Cell</source><volume>147</volume><fpage>1159</fpage><lpage>1170</lpage><pub-id pub-id-type="doi">10.1016/j.cell.2011.08.051</pub-id><pub-id pub-id-type="pmid">22100643</pub-id></element-citation></ref><ref id="bib30"><element-citation publication-type="confproc"><person-group person-group-type="author"><name><surname>Gong</surname><given-names>B</given-names></name><name><surname>Chao</surname><given-names>W-L</given-names></name><name><surname>Grauman</surname><given-names>K</given-names></name><name><surname>Sha</surname><given-names>F</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>Diverse sequential subset selection for supervised video summarization</article-title><conf-name>Advances in Neural Information Processing Systems</conf-name><fpage>2069</fpage><lpage>2077</lpage></element-citation></ref><ref id="bib31"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hafting</surname><given-names>T</given-names></name><name><surname>Fyhn</surname><given-names>M</given-names></name><name><surname>Molden</surname><given-names>S</given-names></name><name><surname>Moser</surname><given-names>M-B</given-names></name><name><surname>Moser</surname><given-names>EI</given-names></name></person-group><year iso-8601-date="2005">2005</year><article-title>Microstructure of a spatial map in the entorhinal cortex</article-title><source>Nature</source><volume>436</volume><fpage>801</fpage><lpage>806</lpage><pub-id pub-id-type="doi">10.1038/nature03721</pub-id><pub-id pub-id-type="pmid">15965463</pub-id></element-citation></ref><ref id="bib32"><element-citation publication-type="software"><person-group person-group-type="author"><name><surname>Han</surname><given-names>I</given-names></name></person-group><year iso-8601-date="2017">2017</year><data-title>Faster greedy MAP inference for determinantal point processes</data-title><version designator="db7a28c">db7a28c</version><source>GitHub</source><ext-link ext-link-type="uri" xlink:href="https://github.com/insuhan/fastdppmap">https://github.com/insuhan/fastdppmap</ext-link></element-citation></ref><ref id="bib33"><element-citation publication-type="confproc"><person-group person-group-type="author"><name><surname>He</surname><given-names>K</given-names></name><name><surname>Zhang</surname><given-names>X</given-names></name><name><surname>Ren</surname><given-names>S</given-names></name><name><surname>Sun</surname><given-names>J</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Deep residual learning for image recognition</article-title><conf-name>Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</conf-name><fpage>770</fpage><lpage>778</lpage><pub-id pub-id-type="doi">10.1109/CVPR.2016.90</pub-id></element-citation></ref><ref id="bib34"><element-citation publication-type="confproc"><person-group person-group-type="author"><name><surname>He</surname><given-names>K</given-names></name><name><surname>Gkioxari</surname><given-names>G</given-names></name><name><surname>Dollár</surname><given-names>P</given-names></name><name><surname>Girshick</surname><given-names>R</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>Mask R-CNN</article-title><conf-name>Proceedings of the IEEE International Conference on Computer Vision</conf-name><fpage>2961</fpage><lpage>2969</lpage><pub-id pub-id-type="doi">10.1109/ICCV.2017.322</pub-id></element-citation></ref><ref id="bib35"><element-citation publication-type="preprint"><person-group person-group-type="author"><name><surname>Hill</surname><given-names>F</given-names></name><name><surname>Santoro</surname><given-names>A</given-names></name><name><surname>Barrett</surname><given-names>DG</given-names></name><name><surname>Morcos</surname><given-names>AS</given-names></name><name><surname>Lillicrap</surname><given-names>T</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>Learning to Make Analogies by Contrasting Abstract Relational Structure</article-title><source>arXiv</source><ext-link ext-link-type="uri" xlink:href="https://arxiv.org/abs/1902.00120">https://arxiv.org/abs/1902.00120</ext-link></element-citation></ref><ref id="bib36"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hinman</surname><given-names>JR</given-names></name><name><surname>Chapman</surname><given-names>GW</given-names></name><name><surname>Hasselmo</surname><given-names>ME</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>Neuronal representation of environmental boundaries in egocentric coordinates</article-title><source>Nature Communications</source><volume>10</volume><elocation-id>2772</elocation-id><pub-id pub-id-type="doi">10.1038/s41467-019-10722-y</pub-id><pub-id pub-id-type="pmid">31235693</pub-id></element-citation></ref><ref id="bib37"><element-citation publication-type="confproc"><person-group person-group-type="author"><name><surname>Hochreiter</surname><given-names>S</given-names></name><name><surname>Schmidhuber</surname><given-names>J</given-names></name></person-group><year iso-8601-date="1997">1997</year><article-title>Lstm can solve hard long time lag problems</article-title><conf-name>Advances in Neural Information Processing Systems</conf-name><fpage>473</fpage><lpage>479</lpage></element-citation></ref><ref id="bib38"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Holyoak</surname><given-names>KJ</given-names></name></person-group><year iso-8601-date="2012">2012</year><chapter-title>Analogy and relational reasoning</chapter-title><person-group person-group-type="editor"><name><surname>Holyoak</surname><given-names>KJ</given-names></name><name><surname>Morrison</surname><given-names>RG</given-names></name></person-group><source>The Oxford Handbook of Thinking and Reasoning</source><publisher-name>Oxford University Press</publisher-name><fpage>234</fpage><lpage>259</lpage><pub-id pub-id-type="doi">10.1093/oxfordhb/9780199734689.013.0013</pub-id></element-citation></ref><ref id="bib39"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Howard</surname><given-names>MW</given-names></name><name><surname>Fotedar</surname><given-names>MS</given-names></name><name><surname>Datey</surname><given-names>AV</given-names></name><name><surname>Hasselmo</surname><given-names>ME</given-names></name></person-group><year iso-8601-date="2005">2005</year><article-title>The temporal context model in spatial navigation and relational learning: toward a common explanation of medial temporal lobe function across domains</article-title><source>Psychological Review</source><volume>112</volume><fpage>75</fpage><lpage>116</lpage><pub-id pub-id-type="doi">10.1037/0033-295X.112.1.75</pub-id><pub-id pub-id-type="pmid">15631589</pub-id></element-citation></ref><ref id="bib40"><element-citation publication-type="confproc"><person-group person-group-type="author"><name><surname>Ioﬀe</surname><given-names>S</given-names></name><name><surname>Szegedy</surname><given-names>C</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>Batch normalization: Accelerating deep network training by reducing internal covariate shift</article-title><conf-name>International Conference on Machine Learning</conf-name><fpage>448</fpage><lpage>456</lpage></element-citation></ref><ref id="bib41"><element-citation publication-type="web"><person-group person-group-type="author"><name><surname>Kazemnejad</surname><given-names>A</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>Transformer architecture: The positional encoding</article-title><ext-link ext-link-type="uri" xlink:href="https://kazemnejad.com/blog/transformer_architecture_positional_encoding/">https://kazemnejad.com/blog/transformer_architecture_positional_encoding/</ext-link><date-in-citation iso-8601-date="2019-09-20">September 20, 2019</date-in-citation></element-citation></ref><ref id="bib42"><element-citation publication-type="preprint"><person-group person-group-type="author"><name><surname>Kingma</surname><given-names>DP</given-names></name><name><surname>Ba</surname><given-names>J</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>Adam: A Method for Stochastic Optimization</article-title><source>arXiv</source><ext-link ext-link-type="uri" xlink:href="https://arxiv.org/abs/1412.6980">https://arxiv.org/abs/1412.6980</ext-link></element-citation></ref><ref id="bib43"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Knowlton</surname><given-names>BJ</given-names></name><name><surname>Morrison</surname><given-names>RG</given-names></name><name><surname>Hummel</surname><given-names>JE</given-names></name><name><surname>Holyoak</surname><given-names>KJ</given-names></name></person-group><year iso-8601-date="2012">2012</year><article-title>A neurocomputational system for relational reasoning</article-title><source>Trends in Cognitive Sciences</source><volume>16</volume><fpage>373</fpage><lpage>381</lpage><pub-id pub-id-type="doi">10.1016/j.tics.2012.06.002</pub-id></element-citation></ref><ref id="bib44"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ko</surname><given-names>C-W</given-names></name><name><surname>Lee</surname><given-names>J</given-names></name><name><surname>Queyranne</surname><given-names>M</given-names></name></person-group><year iso-8601-date="1995">1995</year><article-title>An exact algorithm for maximum entropy sampling</article-title><source>Operations Research</source><volume>43</volume><fpage>684</fpage><lpage>691</lpage><pub-id pub-id-type="doi">10.1287/opre.43.4.684</pub-id></element-citation></ref><ref id="bib45"><element-citation publication-type="confproc"><person-group person-group-type="author"><name><surname>Krogh</surname><given-names>A</given-names></name><name><surname>Hertz</surname><given-names>JA</given-names></name></person-group><year iso-8601-date="1992">1992</year><article-title>A simple weight decay can improve generalization</article-title><conf-name>Advances in Neural Information Processing Systems</conf-name><fpage>950</fpage><lpage>957</lpage></element-citation></ref><ref id="bib46"><element-citation publication-type="preprint"><person-group person-group-type="author"><name><surname>Kulesza</surname><given-names>A</given-names></name><name><surname>Taskar</surname><given-names>B</given-names></name></person-group><year iso-8601-date="2012">2012</year><article-title>Determinantal Point Processes for Machine Learning</article-title><source>arXiv</source><ext-link ext-link-type="uri" xlink:href="https://arxiv.org/abs/1207.6083">https://arxiv.org/abs/1207.6083</ext-link></element-citation></ref><ref id="bib47"><element-citation publication-type="confproc"><person-group person-group-type="author"><name><surname>Lake</surname><given-names>B</given-names></name><name><surname>Baroni</surname><given-names>M</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>Generalization without systematicity: On the compositional skills of sequence-to-sequence recurrent networks</article-title><conf-name>International Conference on Machine Learning</conf-name><fpage>2873</fpage><lpage>2882</lpage></element-citation></ref><ref id="bib48"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Lu</surname><given-names>H</given-names></name><name><surname>Ichien</surname><given-names>N</given-names></name><name><surname>Holyoak</surname><given-names>KJ</given-names></name></person-group><year iso-8601-date="2022">2022</year><article-title>Probabilistic analogical mapping with semantic relation networks</article-title><source>Psychological Review</source><volume>129</volume><fpage>1078</fpage><lpage>1103</lpage><pub-id pub-id-type="doi">10.1037/rev0000358</pub-id><pub-id pub-id-type="pmid">35389714</pub-id></element-citation></ref><ref id="bib49"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Macchi</surname><given-names>O</given-names></name></person-group><year iso-8601-date="1975">1975</year><article-title>The coincidence approach to stochastic point processes</article-title><source>Advances in Applied Probability</source><volume>7</volume><fpage>83</fpage><lpage>122</lpage><pub-id pub-id-type="doi">10.2307/1425855</pub-id></element-citation></ref><ref id="bib50"><element-citation publication-type="preprint"><person-group person-group-type="author"><name><surname>Mariet</surname><given-names>Z</given-names></name><name><surname>Sra</surname><given-names>S</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>Diversity Networks: Neural Network Compression Using Determinantal Point Processes</article-title><source>arXiv</source><ext-link ext-link-type="uri" xlink:href="https://arxiv.org/abs/1511.05077">https://arxiv.org/abs/1511.05077</ext-link></element-citation></ref><ref id="bib51"><element-citation publication-type="preprint"><person-group person-group-type="author"><name><surname>Mariet</surname><given-names>Z</given-names></name><name><surname>Ovadia</surname><given-names>Y</given-names></name><name><surname>Snoek</surname><given-names>J</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>Dppnet: Approximating Determinantal Point Processes with Deep Networks</article-title><source>arXiv</source><ext-link ext-link-type="uri" xlink:href="https://arxiv.org/abs/1901.02051">https://arxiv.org/abs/1901.02051</ext-link></element-citation></ref><ref id="bib52"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Mathis</surname><given-names>A</given-names></name><name><surname>Herz</surname><given-names>AV</given-names></name><name><surname>Stemmler</surname><given-names>M</given-names></name></person-group><year iso-8601-date="2012">2012</year><article-title>Optimal population codes for space: grid cells outperform place cells</article-title><source>Neural Computation</source><volume>24</volume><fpage>2280</fpage><lpage>2317</lpage><pub-id pub-id-type="doi">10.1162/NECO_a_00319</pub-id><pub-id pub-id-type="pmid">22594833</pub-id></element-citation></ref><ref id="bib53"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>McClelland</surname><given-names>JL</given-names></name><name><surname>McNaughton</surname><given-names>BL</given-names></name><name><surname>O’Reilly</surname><given-names>RC</given-names></name></person-group><year iso-8601-date="1995">1995</year><article-title>Why there are complementary learning systems in the hippocampus and neocortex: insights from the successes and failures of connectionist models of learning and memory</article-title><source>Psychological Review</source><volume>102</volume><fpage>419</fpage><lpage>457</lpage><pub-id pub-id-type="doi">10.1037/0033-295X.102.3.419</pub-id><pub-id pub-id-type="pmid">7624455</pub-id></element-citation></ref><ref id="bib54"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>McNamee</surname><given-names>DC</given-names></name><name><surname>Stachenfeld</surname><given-names>KL</given-names></name><name><surname>Botvinick</surname><given-names>MM</given-names></name><name><surname>Gershman</surname><given-names>SJ</given-names></name></person-group><year iso-8601-date="2022">2022</year><article-title>Compositional sequence generation in the entorhinal-hippocampal system</article-title><source>Entropy</source><volume>24</volume><elocation-id>1791</elocation-id><pub-id pub-id-type="doi">10.3390/e24121791</pub-id><pub-id pub-id-type="pmid">36554196</pub-id></element-citation></ref><ref id="bib55"><element-citation publication-type="preprint"><person-group person-group-type="author"><name><surname>Mikolov</surname><given-names>T</given-names></name><name><surname>Chen</surname><given-names>K</given-names></name><name><surname>Corrado</surname><given-names>G</given-names></name><name><surname>Dean</surname><given-names>J</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>Eﬃcient Estimation of Word Representations in Vector Space</article-title><source>arXiv</source><ext-link ext-link-type="uri" xlink:href="https://arxiv.org/abs/1301.3781">https://arxiv.org/abs/1301.3781</ext-link></element-citation></ref><ref id="bib56"><element-citation publication-type="software"><person-group person-group-type="author"><name><surname>Mondal</surname><given-names>SS</given-names></name></person-group><year iso-8601-date="2024">2024</year><data-title>DPP-Attention_Grid-cell-code</data-title><version designator="swh:1:rev:f7c2d97feddd5427992a25b4bedf4f7af453c845">swh:1:rev:f7c2d97feddd5427992a25b4bedf4f7af453c845</version><source>Software Heritage</source><ext-link ext-link-type="uri" xlink:href="https://archive.softwareheritage.org/swh:1:dir:254a2d2ddc55f91afd102943f115ab68c126f5ae;origin=https://github.com/Shanka123/DPP-Attention_Grid-Cell-Code;visit=swh:1:snp:061922fece7d2d628477865513968f27ea71c634;anchor=swh:1:rev:f7c2d97feddd5427992a25b4bedf4f7af453c845">https://archive.softwareheritage.org/swh:1:dir:254a2d2ddc55f91afd102943f115ab68c126f5ae;origin=https://github.com/Shanka123/DPP-Attention_Grid-Cell-Code;visit=swh:1:snp:061922fece7d2d628477865513968f27ea71c634;anchor=swh:1:rev:f7c2d97feddd5427992a25b4bedf4f7af453c845</ext-link></element-citation></ref><ref id="bib57"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Moser</surname><given-names>M-B</given-names></name><name><surname>Rowland</surname><given-names>DC</given-names></name><name><surname>Moser</surname><given-names>EI</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>Place cells, grid cells, and memory</article-title><source>Cold Spring Harbor Perspectives in Biology</source><volume>7</volume><elocation-id>a021808</elocation-id><pub-id pub-id-type="doi">10.1101/cshperspect.a021808</pub-id><pub-id pub-id-type="pmid">25646382</pub-id></element-citation></ref><ref id="bib58"><element-citation publication-type="confproc"><person-group person-group-type="author"><name><surname>Paszke</surname><given-names>A</given-names></name><name><surname>Gross</surname><given-names>S</given-names></name><name><surname>Chintala</surname><given-names>S</given-names></name><name><surname>Chanan</surname><given-names>G</given-names></name><name><surname>Yang</surname><given-names>E</given-names></name><name><surname>DeVito</surname><given-names>Z</given-names></name><name><surname>Lin</surname><given-names>Z</given-names></name><name><surname>Desmaison</surname><given-names>A</given-names></name><name><surname>Antiga</surname><given-names>L</given-names></name><name><surname>Lerer</surname><given-names>A</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>Automatic differentiation in PyTorch</article-title><conf-name>Advances in Neural Information Processing Systems</conf-name></element-citation></ref><ref id="bib59"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Perez-Beltrachini</surname><given-names>L</given-names></name><name><surname>Lapata</surname><given-names>M</given-names></name></person-group><year iso-8601-date="2021">2021</year><article-title>Multi-document summarization with determinantal point process attention</article-title><source>Journal of Artificial Intelligence Research</source><volume>71</volume><fpage>371</fpage><lpage>399</lpage><pub-id pub-id-type="doi">10.1613/jair.1.12522</pub-id></element-citation></ref><ref id="bib60"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Qu</surname><given-names>C</given-names></name><name><surname>Szkudlarek</surname><given-names>E</given-names></name><name><surname>Brannon</surname><given-names>EM</given-names></name></person-group><year iso-8601-date="2021">2021</year><article-title>Approximate multiplication in young children prior to multiplication instruction</article-title><source>Journal of Experimental Child Psychology</source><volume>207</volume><elocation-id>105116</elocation-id><pub-id pub-id-type="doi">10.1016/j.jecp.2021.105116</pub-id><pub-id pub-id-type="pmid">33677334</pub-id></element-citation></ref><ref id="bib61"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Rumelhart</surname><given-names>DE</given-names></name><name><surname>Abrahamson</surname><given-names>AA</given-names></name></person-group><year iso-8601-date="1973">1973</year><article-title>A model for analogical reasoning</article-title><source>Cognitive Psychology</source><volume>5</volume><fpage>1</fpage><lpage>28</lpage><pub-id pub-id-type="doi">10.1016/0010-0285(73)90023-6</pub-id></element-citation></ref><ref id="bib62"><element-citation publication-type="preprint"><person-group person-group-type="author"><name><surname>Saxton</surname><given-names>D</given-names></name><name><surname>Grefenstette</surname><given-names>E</given-names></name><name><surname>Hill</surname><given-names>F</given-names></name><name><surname>Kohli</surname><given-names>P</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>Analysing Mathematical Reasoning Abilities of Neural Models</article-title><source>arXiv</source><ext-link ext-link-type="uri" xlink:href="https://arxiv.org/abs/1904.01557">https://arxiv.org/abs/1904.01557</ext-link></element-citation></ref><ref id="bib63"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Shenhav</surname><given-names>A</given-names></name><name><surname>Botvinick</surname><given-names>MM</given-names></name><name><surname>Cohen</surname><given-names>JD</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>The expected value of control: an integrative theory of anterior cingulate cortex function</article-title><source>Neuron</source><volume>79</volume><fpage>217</fpage><lpage>240</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2013.07.007</pub-id><pub-id pub-id-type="pmid">23889930</pub-id></element-citation></ref><ref id="bib64"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Silver</surname><given-names>D</given-names></name><name><surname>Schrittwieser</surname><given-names>J</given-names></name><name><surname>Simonyan</surname><given-names>K</given-names></name><name><surname>Antonoglou</surname><given-names>I</given-names></name><name><surname>Huang</surname><given-names>A</given-names></name><name><surname>Guez</surname><given-names>A</given-names></name><name><surname>Hubert</surname><given-names>T</given-names></name><name><surname>Baker</surname><given-names>L</given-names></name><name><surname>Lai</surname><given-names>M</given-names></name><name><surname>Bolton</surname><given-names>A</given-names></name><name><surname>Chen</surname><given-names>Y</given-names></name><name><surname>Lillicrap</surname><given-names>T</given-names></name><name><surname>Hui</surname><given-names>F</given-names></name><name><surname>Sifre</surname><given-names>L</given-names></name><name><surname>van den Driessche</surname><given-names>G</given-names></name><name><surname>Graepel</surname><given-names>T</given-names></name><name><surname>Hassabis</surname><given-names>D</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>Mastering the game of Go without human knowledge</article-title><source>Nature</source><volume>550</volume><fpage>354</fpage><lpage>359</lpage><pub-id pub-id-type="doi">10.1038/nature24270</pub-id><pub-id pub-id-type="pmid">29052630</pub-id></element-citation></ref><ref id="bib65"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Sorscher</surname><given-names>B</given-names></name><name><surname>Mel</surname><given-names>GC</given-names></name><name><surname>Ocko</surname><given-names>SA</given-names></name><name><surname>Giocomo</surname><given-names>LM</given-names></name><name><surname>Ganguli</surname><given-names>S</given-names></name></person-group><year iso-8601-date="2023">2023</year><article-title>A unified theory for the computational and mechanistic origins of grid cells</article-title><source>Neuron</source><volume>111</volume><fpage>121</fpage><lpage>137</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2022.10.003</pub-id><pub-id pub-id-type="pmid">36306779</pub-id></element-citation></ref><ref id="bib66"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Sreenivasan</surname><given-names>S</given-names></name><name><surname>Fiete</surname><given-names>I</given-names></name></person-group><year iso-8601-date="2011">2011</year><article-title>Grid cells generate an analog error-correcting code for singularly precise neural computation</article-title><source>Nature Neuroscience</source><volume>14</volume><fpage>1330</fpage><lpage>1337</lpage><pub-id pub-id-type="doi">10.1038/nn.2901</pub-id><pub-id pub-id-type="pmid">21909090</pub-id></element-citation></ref><ref id="bib67"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Srivastava</surname><given-names>N</given-names></name><name><surname>Hinton</surname><given-names>G</given-names></name><name><surname>Krizhevsky</surname><given-names>A</given-names></name><name><surname>Sutskever</surname><given-names>I</given-names></name><name><surname>Salakhutdinov</surname><given-names>R</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>Dropout: a simple way to prevent neural networks from overﬁtting</article-title><source>The Journal of Machine Learning Research</source><volume>15</volume><fpage>1929</fpage><lpage>1958</lpage></element-citation></ref><ref id="bib68"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Stachenfeld</surname><given-names>KL</given-names></name><name><surname>Botvinick</surname><given-names>MM</given-names></name><name><surname>Gershman</surname><given-names>SJ</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>The hippocampus as a predictive map</article-title><source>Nature Neuroscience</source><volume>20</volume><fpage>1643</fpage><lpage>1653</lpage><pub-id pub-id-type="doi">10.1038/nn.4650</pub-id><pub-id pub-id-type="pmid">28967910</pub-id></element-citation></ref><ref id="bib69"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Stensola</surname><given-names>H</given-names></name><name><surname>Stensola</surname><given-names>T</given-names></name><name><surname>Solstad</surname><given-names>T</given-names></name><name><surname>Frøland</surname><given-names>K</given-names></name><name><surname>Moser</surname><given-names>M-B</given-names></name><name><surname>Moser</surname><given-names>EI</given-names></name></person-group><year iso-8601-date="2012">2012</year><article-title>The entorhinal grid map is discretized</article-title><source>Nature</source><volume>492</volume><fpage>72</fpage><lpage>78</lpage><pub-id pub-id-type="doi">10.1038/nature11649</pub-id><pub-id pub-id-type="pmid">23222610</pub-id></element-citation></ref><ref id="bib70"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Summerfield</surname><given-names>C</given-names></name><name><surname>Luyckx</surname><given-names>F</given-names></name><name><surname>Sheahan</surname><given-names>H</given-names></name></person-group><year iso-8601-date="2020">2020</year><article-title>Structure learning and the posterior parietal cortex</article-title><source>Progress in Neurobiology</source><volume>184</volume><elocation-id>101717</elocation-id><pub-id pub-id-type="doi">10.1016/j.pneurobio.2019.101717</pub-id><pub-id pub-id-type="pmid">31669186</pub-id></element-citation></ref><ref id="bib71"><element-citation publication-type="confproc"><person-group person-group-type="author"><name><surname>Vaswani</surname><given-names>A</given-names></name><name><surname>Shazeer</surname><given-names>N</given-names></name><name><surname>Parmar</surname><given-names>N</given-names></name><name><surname>Uszkoreit</surname><given-names>J</given-names></name><name><surname>Jones</surname><given-names>L</given-names></name><name><surname>Gomez</surname><given-names>AN</given-names></name><name><surname>Kaiser</surname><given-names>Ł</given-names></name><name><surname>Polosukhin</surname><given-names>I</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>Attention is all you need</article-title><conf-name>Advances in Neural Information Processing Systems</conf-name><fpage>5998</fpage><lpage>6008</lpage></element-citation></ref><ref id="bib72"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Waltz</surname><given-names>JA</given-names></name><name><surname>Knowlton</surname><given-names>BJ</given-names></name><name><surname>Holyoak</surname><given-names>KJ</given-names></name><name><surname>Boone</surname><given-names>KB</given-names></name><name><surname>Mishkin</surname><given-names>FS</given-names></name><name><surname>de Menezes Santos</surname><given-names>M</given-names></name><name><surname>Thomas</surname><given-names>CR</given-names></name><name><surname>Miller</surname><given-names>BL</given-names></name></person-group><year iso-8601-date="1999">1999</year><article-title>A system for relational reasoning in human prefrontal cortex</article-title><source>Psychological Science</source><volume>10</volume><fpage>119</fpage><lpage>125</lpage><pub-id pub-id-type="doi">10.1111/1467-9280.00118</pub-id></element-citation></ref><ref id="bib73"><element-citation publication-type="confproc"><person-group person-group-type="author"><name><surname>Webb</surname><given-names>T</given-names></name><name><surname>Dulberg</surname><given-names>Z</given-names></name><name><surname>Frankland</surname><given-names>S</given-names></name><name><surname>Petrov</surname><given-names>A</given-names></name><name><surname>O’Reilly</surname><given-names>R</given-names></name><name><surname>Cohen</surname><given-names>J</given-names></name></person-group><year iso-8601-date="2020">2020</year><article-title>Learning representations that support extrapolation</article-title><conf-name>International Conference on Machine Learning</conf-name><fpage>10136</fpage><lpage>10146</lpage></element-citation></ref><ref id="bib74"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Webb</surname><given-names>T</given-names></name><name><surname>Fu</surname><given-names>S</given-names></name><name><surname>Bihl</surname><given-names>T</given-names></name><name><surname>Holyoak</surname><given-names>KJ</given-names></name><name><surname>Lu</surname><given-names>H</given-names></name></person-group><year iso-8601-date="2023">2023</year><article-title>Zero-shot visual reasoning through probabilistic analogical mapping</article-title><source>Nature Communications</source><volume>14</volume><elocation-id>5144</elocation-id><pub-id pub-id-type="doi">10.1038/s41467-023-40804-x</pub-id><pub-id pub-id-type="pmid">37620313</pub-id></element-citation></ref><ref id="bib75"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wei</surname><given-names>X-X</given-names></name><name><surname>Prentice</surname><given-names>J</given-names></name><name><surname>Balasubramanian</surname><given-names>V</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>A principle of economy predicts the functional architecture of grid cells</article-title><source>eLife</source><volume>4</volume><elocation-id>e08362</elocation-id><pub-id pub-id-type="doi">10.7554/eLife.08362</pub-id><pub-id pub-id-type="pmid">26335200</pub-id></element-citation></ref><ref id="bib76"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Whittington</surname><given-names>JC</given-names></name><name><surname>Muller</surname><given-names>TH</given-names></name><name><surname>Mark</surname><given-names>S</given-names></name><name><surname>Chen</surname><given-names>G</given-names></name><name><surname>Barry</surname><given-names>C</given-names></name><name><surname>Burgess</surname><given-names>N</given-names></name><name><surname>Behrens</surname><given-names>TE</given-names></name></person-group><year iso-8601-date="2020">2020</year><article-title>The tolman-eichenbaum machine: Unifying space and relational memory through generalization in the hippocampal formation</article-title><source>Cell</source><volume>183</volume><fpage>1249</fpage><lpage>1263</lpage><pub-id pub-id-type="doi">10.1016/j.cell.2020.10.024</pub-id><pub-id pub-id-type="pmid">33181068</pub-id></element-citation></ref><ref id="bib77"><element-citation publication-type="preprint"><person-group person-group-type="author"><name><surname>Wu</surname><given-names>Y</given-names></name><name><surname>Schuster</surname><given-names>M</given-names></name><name><surname>Chen</surname><given-names>Z</given-names></name><name><surname>Le</surname><given-names>QV</given-names></name><name><surname>Norouzi</surname><given-names>M</given-names></name><name><surname>Macherey</surname><given-names>W</given-names></name><name><surname>Krikun</surname><given-names>M</given-names></name><name><surname>Cao</surname><given-names>Y</given-names></name><name><surname>Gao</surname><given-names>Q</given-names></name><name><surname>Macherey</surname><given-names>K</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Google’s Neural Machine Translation System: Bridging the Gap between Human and Machine Translation</article-title><source>arXiv</source><ext-link ext-link-type="uri" xlink:href="https://arxiv.org/abs/1609.08144">https://arxiv.org/abs/1609.08144</ext-link></element-citation></ref><ref id="bib78"><element-citation publication-type="preprint"><person-group person-group-type="author"><name><surname>Zhang</surname><given-names>C</given-names></name><name><surname>Kjellstrom</surname><given-names>H</given-names></name><name><surname>Mandt</surname><given-names>S</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>Determinantal Point Processes for Mini-Batch Diversiﬁcation</article-title><source>arXiv</source><ext-link ext-link-type="uri" xlink:href="https://arxiv.org/abs/1705.00607">https://arxiv.org/abs/1705.00607</ext-link></element-citation></ref></ref-list><app-group><app id="appendix-1"><title>Appendix 1</title><sec sec-type="appendix" id="s8"><title>Code and data availability</title><p>The code and the data can be downloaded from <ext-link ext-link-type="uri" xlink:href="https://github.com/Shanka123/DPP-Attention_Grid-Cell-Code">https://github.com/Shanka123/DPP-Attention_Grid-Cell-Code</ext-link> (copy archived at <xref ref-type="bibr" rid="bib56">Mondal, 2024</xref>).</p></sec><sec sec-type="appendix" id="s9"><title>More experimental details</title><p>The size of the training region was 100. For the analogy task, we used 653,216 training samples, 163,304 validation samples, and 20,000 testing samples for each of the nine regions. For the arithmetic task, we used 80,000 training samples, 20,000 validation samples, and 20,000 testing samples for each of the nine regions with equal number of addition and multiplication problems. We used the PyTorch library (<xref ref-type="bibr" rid="bib58">Paszke et al., 2017</xref>) for all experiments. For each network, the training epoch that achieved the best validation accuracy was used to report performance accuracy for the training stimulus sets, validation sets (held out stimuli from the training range), and OOD generalization test sets (from regions beyond the range of the training data).</p></sec><sec sec-type="appendix" id="s10"><title>Why is OOD generalization performance worse for the multiplication task?</title><p>In an eﬀort to understand why DPP-A achieved around 65% average test accuracy on multiplication compared to nearly perfect accuracy for addition and analogy tasks, we analyzed the distribution of the grid cell embeddings for the frequency which had the maximum within-frequency determinant at the end of the ﬁrst step in Algorithm 1. More speciﬁcally for <inline-formula><mml:math id="inf245"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>A</mml:mi></mml:mrow></mml:mstyle></mml:math></inline-formula>, <inline-formula><mml:math id="inf246"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>B</mml:mi></mml:mrow></mml:mstyle></mml:math></inline-formula>, and the correct answer <inline-formula><mml:math id="inf247"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>C</mml:mi></mml:mrow></mml:mstyle></mml:math></inline-formula>, we analyzed the distribution of each grid cell for the training and the nine test regions. Note that since the total number of grid cells was 900 and there were nine frequencies, the dimension of the grid cell embeddings corresponding to <inline-formula><mml:math id="inf248"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>f</mml:mi><mml:mrow><mml:mi>m</mml:mi><mml:mi>a</mml:mi><mml:msub><mml:mi>x</mml:mi><mml:mrow><mml:mi>D</mml:mi><mml:mi>P</mml:mi><mml:mi>P</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula> grid cell frequency was 100. To quantify the similarity between training and the test distributions, we computed cosine distance (1 − cosine similarity), and averaged it over the 100 dimensions and nine test regions. We found that the average cosine distance is 5× greater for multiplication than addition problem (0.0002 for addition: 0.001 for multiplication). In this respect, grid cell code does not perfectly preserve the relational structure of the multiplication problem, which we would expect to limit DPP-A’s OOD generalization ability in that task domain.</p></sec><sec sec-type="appendix" id="s11"><title>Ablation study on choice of frequency</title><fig id="app1fig1" position="float"><label>Appendix 1—figure 1.</label><caption><title>Results on analogy on each region using LSTM in the inference module for choosing top <inline-formula><mml:math id="inf249"><mml:semantics><mml:mi>K</mml:mi></mml:semantics></mml:math></inline-formula> frequencies with <inline-formula><mml:math id="inf250"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mrow><mml:mover><mml:mi>F</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>f</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula> in Algorithm 1.</title><p>Results show mean accuracy on each region averaged over three trained networks along with errorbar (standard error of the mean).</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-89911-app1-fig1-v1.tif"/></fig></sec><sec sec-type="appendix" id="s12"><title>Baseline using dynamic attention across frequencies</title><fig id="app1fig2" position="float"><label>Appendix 1—figure 2.</label><caption><title>Results on analogy on each region for translation and scaling using the transformer in the inference module.</title></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-89911-app1-fig2-v1.tif"/></fig></sec><sec sec-type="appendix" id="s13"><title>Ablation study on arithmetic task</title><fig id="app1fig3" position="float"><label>Appendix 1—figure 3.</label><caption><title>Results on arithmetic with different embeddings (with determinantal point process attention [DPP-A]) using LSTM in the inference module.</title><p>Results show mean accuracy on each region averaged over three trained networks along with errorbar (standard error of the mean).</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-89911-app1-fig3-v1.tif"/></fig><fig id="app1fig4" position="float"><label>Appendix 1—figure 4.</label><caption><title>Results on arithmetic with different embeddings (without determinantal point process attention [DPP-A], temporal context normalization [TCN], L1 Regularization, or Dropout) using LSTM in the inference module.</title><p>Results show mean accuracy on each region averaged over three trained networks along with errorbar (standard error of the mean).</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-89911-app1-fig4-v1.tif"/></fig><fig id="app1fig5" position="float"><label>Appendix 1—figure 5.</label><caption><title>Results on arithmetic for increasing number of grid cell frequencies <inline-formula><mml:math id="inf251"><mml:semantics><mml:mrow><mml:msub><mml:mi>N</mml:mi><mml:mi>f</mml:mi></mml:msub></mml:mrow></mml:semantics></mml:math></inline-formula> on each region using LSTM in the inference module.</title><p>Results show mean accuracy on each region averaged over three trained networks along with errorbar (standard error of the mean).</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-89911-app1-fig5-v1.tif"/></fig></sec><sec sec-type="appendix" id="s14"><title>Regression formulation</title><fig id="app1fig6" position="float"><label>Appendix 1—figure 6.</label><caption><title>Results for regression on analogy using LSTM in the inference module.</title><p>Results show mean squared error on each region averaged over three trained networks along with errorbar (standard error of the mean).</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-89911-app1-fig6-v1.tif"/></fig><fig id="app1fig7" position="float"><label>Appendix 1—figure 7.</label><caption><title>Results for regression on arithmetic on each region using LSTM in the inference module.</title><p>Results show mean squared error on each region averaged over three trained networks along with errorbar (standard error of the mean).</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-89911-app1-fig7-v1.tif"/></fig><p>We also tried formulating the analogy and arithmetic tasks as regression instead of classiﬁcation via a scoring mechanism. For DPP-A, the inference module was trained to generate the grid cell embeddings belonging to the <inline-formula><mml:math id="inf252"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>f</mml:mi><mml:mrow><mml:mi>m</mml:mi><mml:mi>a</mml:mi><mml:msub><mml:mi>x</mml:mi><mml:mrow><mml:mi>D</mml:mi><mml:mi>P</mml:mi><mml:mi>P</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula> frequency, which had the maximum within-frequency determinant at the end of the ﬁrst step in Algorithm 1 for the correct completion, given as input the <inline-formula><mml:math id="inf253"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>f</mml:mi><mml:mrow><mml:mi>m</mml:mi><mml:mi>a</mml:mi><mml:msub><mml:mi>x</mml:mi><mml:mrow><mml:mi>D</mml:mi><mml:mi>P</mml:mi><mml:mi>P</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula> frequency grid cell embeddings for <inline-formula><mml:math id="inf254"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>A</mml:mi></mml:mrow></mml:mstyle></mml:math></inline-formula>, <inline-formula><mml:math id="inf255"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>B</mml:mi></mml:mrow></mml:mstyle></mml:math></inline-formula>, <inline-formula><mml:math id="inf256"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>C</mml:mi></mml:mrow></mml:mstyle></mml:math></inline-formula> for the analogy task and <inline-formula><mml:math id="inf257"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>A</mml:mi></mml:mrow></mml:mstyle></mml:math></inline-formula>, <inline-formula><mml:math id="inf258"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>B</mml:mi></mml:mrow></mml:mstyle></mml:math></inline-formula> for the arithmetic task. A linear layer with 100 units and sigmoid activation was used to generate the output of the inference module and was trained to minimize the mean squared error with the <inline-formula><mml:math id="inf259"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>f</mml:mi><mml:mrow><mml:mi>m</mml:mi><mml:mi>a</mml:mi><mml:msub><mml:mi>x</mml:mi><mml:mrow><mml:mi>D</mml:mi><mml:mi>P</mml:mi><mml:mi>P</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula> frequency grid cell embeddings of the correct completion. We compared DPP-A with a version that didn’t use the attentional objective (no DPP-A), where the inference module was trained to generate the grid cell embeddings for all the frequencies, but was evaluated on only the <inline-formula><mml:math id="inf260"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>f</mml:mi><mml:mrow><mml:mi>m</mml:mi><mml:mi>a</mml:mi><mml:msub><mml:mi>x</mml:mi><mml:mrow><mml:mi>D</mml:mi><mml:mi>P</mml:mi><mml:mi>P</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula> frequency grid cell embeddings for fair comparison with the DPP-A version. <xref ref-type="fig" rid="app1fig6">Appendix 1—figure 6</xref> shows the results for the analogy task using an LSTM in the inference module. For both the translation (left) and scaling (right) regimes, DPP-A achieves nearly zero mean squared error on all the test regions, considerably outperforming the no DPP-A which achieves a much higher error. <xref ref-type="fig" rid="app1fig7">Appendix 1—figure 7</xref> shows the results for arithmetic problems using an LSTM in the inference module. For addition problems, shown on the left, DPP-A achieves nearly zero mean squared error on the test regions. For multiplication problems, shown on the right, DPP-A achieves a lower mean squared error on the test regions, 0.11, compared to no DPP-A which achieves around 0.17.</p></sec><sec sec-type="appendix" id="s15"><title>Eﬀect of L1 regularization strength (<italic>λ</italic>)</title><fig id="app1fig8" position="float"><label>Appendix 1—figure 8.</label><caption><title>Results on analogy for L1 regularization for various <italic>λ</italic>s for translation and scaling using LSTM in the inference module.</title><p>Results show mean accuracy on each region averaged over three trained networks along with errorbar (standard error of the mean).</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-89911-app1-fig8-v1.tif"/></fig><fig id="app1fig9" position="float"><label>Appendix 1—figure 9.</label><caption><title>Results on arithmetic for L1 regularization for various <italic>λ</italic>s using LSTM in the inference module.</title><p>Results show mean accuracy on each region averaged over three trained networks along with errorbar (standard error of the mean).</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-89911-app1-fig9-v1.tif"/></fig></sec><sec sec-type="appendix" id="s16"><title>Ablation on DPP-A</title><fig id="app1fig10" position="float"><label>Appendix 1—figure 10.</label><caption><title>Results on analogy for one step determinantal point process attention (DPP-A) over the complete grid cell code for various <italic>λ</italic>s for translation and scaling using LSTM in the inference module.</title><p>Results show mean accuracy on each region averaged over three trained networks along with errorbar (standard error of the mean).</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-89911-app1-fig10-v1.tif"/></fig><fig id="app1fig11" position="float"><label>Appendix 1—figure 11.</label><caption><title>Results on analogy for one step determinantal point process attention (DPP-A) within frequencies for various <italic>λ</italic>s for translation and scaling using LSTM in the inference module.</title><p>Results show mean accuracy on each region averaged over three trained networks along with errorbar (standard error of the mean).</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-89911-app1-fig11-v1.tif"/></fig><p>The proposed DPP-A method (Algorithm 1) consists of two steps with <inline-formula><mml:math id="inf261"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="script">L</mml:mi></mml:mrow><mml:mrow><mml:mi>D</mml:mi><mml:mi>P</mml:mi><mml:mi>P</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula> in the ﬁrst step and <inline-formula><mml:math id="inf262"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="script">L</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi><mml:mi>a</mml:mi><mml:mi>s</mml:mi><mml:mi>k</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula> in the second step. We considered two ablation experiments which consists of a single step. In one case, we maximized the objective function, <inline-formula><mml:math id="inf263"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mrow><mml:mover><mml:mi>F</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mi mathvariant="bold-italic">g</mml:mi><mml:mo mathvariant="bold">,</mml:mo><mml:mi mathvariant="bold-italic">V</mml:mi></mml:mrow><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mrow><mml:mi>log</mml:mi><mml:mspace width="thinmathspace"/><mml:mo movablelimits="true" form="prefix">det</mml:mo></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mi mathvariant="normal">d</mml:mi><mml:mi mathvariant="normal">i</mml:mi><mml:mi mathvariant="normal">a</mml:mi><mml:mi mathvariant="normal">g</mml:mi></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>σ</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mi mathvariant="bold">g</mml:mi></mml:mrow><mml:mo stretchy="false">)</mml:mo><mml:mo stretchy="false">)</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mi mathvariant="bold-italic">V</mml:mi><mml:mo mathvariant="bold">−</mml:mo><mml:mi mathvariant="bold-italic">I</mml:mi></mml:mrow><mml:mo stretchy="false">)</mml:mo><mml:mo>+</mml:mo><mml:mi mathvariant="bold-italic">I</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mstyle></mml:math></inline-formula>, over the grid cell embeddings of all frequencies and phases (instead of summing <inline-formula><mml:math id="inf264"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mrow><mml:mover><mml:mi>F</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow></mml:mrow></mml:mstyle></mml:math></inline-formula> corresponding to the grid cell embeddings from each frequency independently as done in the ﬁrst step of Algorithm 1), using stochastic gradient ascent, along with minimizing <inline-formula><mml:math id="inf265"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="script">L</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi><mml:mi>a</mml:mi><mml:mi>s</mml:mi><mml:mi>k</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula>, which would use all the attended grid cell embeddings (instead of using <inline-formula><mml:math id="inf266"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>f</mml:mi><mml:mrow><mml:mi>m</mml:mi><mml:mi>a</mml:mi><mml:msub><mml:mi>x</mml:mi><mml:mrow><mml:mi>D</mml:mi><mml:mi>P</mml:mi><mml:mi>P</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula> frequency grid cell embeddings as done in the second step of Algorithm 1). So total loss, <inline-formula><mml:math id="inf267"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mrow><mml:mi class="mathcal" mathvariant="script">L</mml:mi></mml:mrow><mml:mo>=</mml:mo><mml:msub><mml:mrow><mml:mi class="mathcal" mathvariant="script">L</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi><mml:mi>a</mml:mi><mml:mi>s</mml:mi><mml:mi>k</mml:mi></mml:mrow></mml:msub><mml:mo>−</mml:mo><mml:mi>λ</mml:mi><mml:mo>∗</mml:mo><mml:mrow><mml:mover><mml:mi>F</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi mathvariant="bold-italic">g</mml:mi><mml:mo>,</mml:mo><mml:mi mathvariant="bold-italic">V</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mstyle></mml:math></inline-formula>. We refer to this ablation experiment as one step DPP-A over the complete grid cell code. The results on the analogy for this ablation experiment are shown in <xref ref-type="fig" rid="app1fig10">Appendix 1—figure 10</xref>. We see that the accuracy on test analogies for translation for various <italic>λ</italic>s is around 30–60%, and for scaling around 20–40%, which is much lower than the nearly perfect accuracy achieved by the proposed DPP-A method. In the other case, we maximized the objective function <inline-formula><mml:math id="inf268"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mrow><mml:mover><mml:mi>F</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi mathvariant="bold-italic">g</mml:mi><mml:mo>,</mml:mo><mml:mi mathvariant="bold-italic">V</mml:mi><mml:mo>,</mml:mo><mml:msub><mml:mi>N</mml:mi><mml:mrow><mml:mi>f</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>N</mml:mi><mml:mrow><mml:mi>p</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:munderover><mml:mo movablelimits="false">∑</mml:mo><mml:mrow><mml:mi>f</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:msub><mml:mi>N</mml:mi><mml:mrow><mml:mi>f</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:munderover><mml:mrow><mml:mi>log</mml:mi><mml:mo>⁡</mml:mo><mml:mo movablelimits="true" form="prefix">det</mml:mo></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mi mathvariant="normal">d</mml:mi><mml:mi mathvariant="normal">i</mml:mi><mml:mi mathvariant="normal">a</mml:mi><mml:mi mathvariant="normal">g</mml:mi></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>σ</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi mathvariant="bold-italic">g</mml:mi><mml:mi mathvariant="bold-italic">f</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:mo stretchy="false">)</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi mathvariant="bold-italic">V</mml:mi><mml:mi mathvariant="bold-italic">f</mml:mi></mml:msub><mml:mo>−</mml:mo><mml:mi mathvariant="bold-italic">I</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>+</mml:mo><mml:mi mathvariant="bold-italic">I</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mstyle></mml:math></inline-formula>, using stochastic gradient ascent, which is same as <inline-formula><mml:math id="inf269"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="script">L</mml:mi></mml:mrow><mml:mrow><mml:mi>D</mml:mi><mml:mi>P</mml:mi><mml:mi>P</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula> in the ﬁrst step of Algorithm 1, along with minimizing <inline-formula><mml:math id="inf270"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="script">L</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi><mml:mi>a</mml:mi><mml:mi>s</mml:mi><mml:mi>k</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula>, which would use all the attended grid cell embeddings. So total loss, <inline-formula><mml:math id="inf271"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mrow><mml:mi class="mathcal" mathvariant="script">L</mml:mi></mml:mrow><mml:mo>=</mml:mo><mml:msub><mml:mrow><mml:mi class="mathcal" mathvariant="script">L</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi><mml:mi>a</mml:mi><mml:mi>s</mml:mi><mml:mi>k</mml:mi></mml:mrow></mml:msub><mml:mo>−</mml:mo><mml:mi>λ</mml:mi><mml:mo>∗</mml:mo><mml:mrow><mml:mover><mml:mi>F</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi mathvariant="bold-italic">g</mml:mi><mml:mo>,</mml:mo><mml:mi mathvariant="bold-italic">V</mml:mi><mml:mo>,</mml:mo><mml:msub><mml:mi>N</mml:mi><mml:mi>f</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>N</mml:mi><mml:mi>p</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mstyle></mml:math></inline-formula>. We refer to this ablation experiment as one step DPP-A within frequencies. As shown in <xref ref-type="fig" rid="app1fig11">Appendix 1—figure 11</xref>, the accuracy on test analogies for both translation and scaling for various <italic>λ</italic>s is in a similar range to one step DPP-A over the complete grid cell code, and is much lower than the nearly perfect accuracy achieved by the proposed DPP-A method.</p></sec><sec sec-type="appendix" id="s17"><title>DPP-A attentional modulation</title><fig id="app1fig12" position="float"><label>Appendix 1—figure 12.</label><caption><title>Approximate maximum log determinant of the covariance matrix over the grid cell embeddings (<italic>y</italic>-axis) for each frequency (<italic>x</italic>-axis), obtained after maximizing <xref ref-type="disp-formula" rid="equ6">Equation 6</xref>.</title></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-89911-app1-fig12-v1.tif"/></fig><p>The gates within each frequency were optimized (independent of the task inputs), according to <xref ref-type="disp-formula" rid="equ6">Equation 6</xref>, to compute the approximate maximum within-frequency log determinant of the covariance matrix over the grid cell embeddings individually for each frequency. We then used the grid cell embeddings belonging to the frequency that had the maximum within-frequency log determinant for training the inference module, which always happened to be grid cells within the top three frequencies. <xref ref-type="fig" rid="app1fig12">Appendix 1—figure 12</xref> shows the approximate maximum log determinant (on the y-axis) for the diﬀerent frequencies (on the x-axis). The intuition behind why DPP-A identiﬁed grid cell embeddings corresponding to the highest spatial frequencies, and why this produced the best OOD generalization (i.e., extrapolation on our analogy tasks), is because those grid cell embeddings exhibited greater variance over the training data than the lower-frequency embeddings, while at the same time the correlations among those grid cell embeddings were lower than the correlations among the lower-frequency grid cell embeddings. The determinant of the covariance matrix of the grid cell embeddings is maximized when the variances of the grid cell embeddings are high (they are ‘expressive’) and the correlation among the grid cell embeddings is low (they ‘cover the representational space’). As a result, the higher-frequency grid cell embeddings more eﬃciently covered the representational space of the training data, allowing them to eﬃciently capture the same relational structure across training and test distributions which is required for OOD generalization.</p><p>To demonstrate that the higher grid cell frequencies more eﬃciently cover the representational space, we analyzed in <xref ref-type="fig" rid="app1fig13">Appendix 1—figure 13</xref>, the results after the summation of the multiplication of the grid cell embeddings over the 2D space of 1000 × 1000 locations, with their corresponding gates for three representative frequencies (left, middle, and right panels showing results for the lowest, middle, and highest grid cell frequencies, respectively, of the nine used in the model), obtained after maximizing <xref ref-type="disp-formula" rid="equ6">Equation 6</xref> for each grid cell frequency. The color code indicates the responsiveness of the grid cells to diﬀerent X and Y locations in the input space (lighter color corresponding to greater responsiveness). Note that the dark blue area (denoting regions of least responsiveness to any grid cell) is greatest for the lowest frequency and nearly zero for the highest frequency, illustrating that grid cell embeddings belonging to the highest frequency more eﬃciently cover the representational space which allows them to capture the same relational structure across training and test distributions as required for OOD generalization.</p><fig id="app1fig13" position="float"><label>Appendix 1—figure 13.</label><caption><title>Each panel shows the results after summation of the multiplication of the grid cell embeddings over the 2D space of 1000 × 1000 locations, with their corresponding gates for a particular frequency, obtained after maximizing <xref ref-type="disp-formula" rid="equ6">Equation 6</xref> for each grid cell frequency.</title><p>The left, middle, and right panels show results for the lowest, middle, and highest grid cell frequencies, respectively, of the nine used in the model. Lighter color in each panel corresponds to greater responsiveness of grid cells at that particular location in the 2D space.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-89911-app1-fig13-v1.tif"/></fig></sec></app></app-group></back><sub-article article-type="editor-report" id="sa0"><front-stub><article-id pub-id-type="doi">10.7554/eLife.89911.3.sa0</article-id><title-group><article-title>eLife assessment</article-title></title-group><contrib-group><contrib contrib-type="author"><name><surname>Schapiro</surname><given-names>Anna C</given-names></name><role specific-use="editor">Reviewing Editor</role><aff><institution>University of Pennsylvania</institution><country>United States</country></aff></contrib></contrib-group><kwd-group kwd-group-type="evidence-strength"><kwd>Compelling</kwd></kwd-group><kwd-group kwd-group-type="claim-importance"><kwd>Important</kwd></kwd-group></front-stub><body><p>This <bold>important</bold> modeling work demonstrates out-of-distribution generalization using a grid cell coding scheme combined with an attentional mechanism that operates over these representations (Determinantal Point Process Attention). The simulations provide <bold>compelling</bold> evidence that the model can improve generalization performance for analogies, addition, and multiplication. The paper is significant in demonstrating how neural grid codes can support human-like generalization capabilities in analogy and arithmetic tasks, which has been a challenge for prior models.</p></body></sub-article><sub-article article-type="referee-report" id="sa1"><front-stub><article-id pub-id-type="doi">10.7554/eLife.89911.3.sa1</article-id><title-group><article-title>Reviewer #1 (Public review):</article-title></title-group><contrib-group><contrib contrib-type="author"><anonymous/><role specific-use="referee">Reviewer</role></contrib></contrib-group></front-stub><body><p>This paper presents a cognitive model of out-of-distribution generalisation, where the representational basis is grid-cell codes. In particular, the authors consider the tasks of analogies, addition, and multiplication, and the out-of-distribution tests are shifting or scaling the input domain. The authors utilise grid cell codes, which are multi-scale as well as translationally invariant due to their periodicity. To allow for domain adaptation, the authors use DPP-A which is, in this context, a mechanism of adapting to input scale changes. The authors present simulations results demonstrating this model can perform out-of-distribution generalisation to input translations and re-scaling, whereas other models fail.</p><p>This paper makes the point it sets out to - that there are some underlying representational bases, like grid cells, that when combined with a domain adaptation mechanism, like DPP-A, can facilitate out-of-generalisation. I don't have any issues with the technical details.</p><p>The paper nicely demonstrates how neural codes can be transformed into a common representational space so that analogies, and presumably other useful tasks/computations, can be performed.</p></body></sub-article><sub-article article-type="author-comment" id="sa2"><front-stub><article-id pub-id-type="doi">10.7554/eLife.89911.3.sa2</article-id><title-group><article-title>Author response</article-title></title-group><contrib-group><contrib contrib-type="author"><name><surname>Mondal</surname><given-names>Shanka Subhra</given-names></name><role specific-use="author">Author</role><aff><institution>Princeton University</institution><addr-line><named-content content-type="city">Princeton</named-content></addr-line><country>United States</country></aff></contrib><contrib contrib-type="author"><name><surname>Frankland</surname><given-names>Steven</given-names></name><role specific-use="author">Author</role><aff><institution>Princeton University</institution><addr-line><named-content content-type="city">Princeton</named-content></addr-line><country>United States</country></aff></contrib><contrib contrib-type="author"><name><surname>Webb</surname><given-names>Taylor</given-names></name><role specific-use="author">Author</role><aff><institution>University of California, Los Angeles</institution><addr-line><named-content content-type="city">Los Angeles</named-content></addr-line><country>United States</country></aff></contrib><contrib contrib-type="author"><name><surname>Cohen</surname><given-names>Jonathan D</given-names></name><role specific-use="author">Author</role><aff><institution>Princeton University</institution><addr-line><named-content content-type="city">Princeton</named-content></addr-line><country>United States</country></aff></contrib></contrib-group></front-stub><body><p>The following is the authors’ response to the original reviews.</p><disp-quote content-type="editor-comment"><p><bold>Major comments (Public Reviews)</bold></p></disp-quote><p><bold>Generality of grid cells</bold></p><p>We appreciate the reviewers’ concern regarding the generality of our approach, and in particular for analogies in nonlinear spaces. In that regard, there are at least two potential directions that could be pursued. One is to directly encode nonlinear structures (such as trees, rings, etc.) with grid cells, to which DPP-A could be applied as described in our model. The TEM model [1] suggests that grid cells in the medial entorhinal may form a basis set that captures structural knowledge for such nonlinear spaces, such as social hierarchies and transitive inference when formalized as a connected graph. Another would be to use eigen-decomposition of the successor representation [2], a learnable predictive representation of possible future states that has been shown by Stachenfield et al. [3] to provide an abstract structured representation of a space that is analogous to the grid cell code. This general-purpose mechanism could be applied to represent analogies in nonlinear spaces [4], for which there may not be a clear factorization in terms of grid cells (i.e., distinct frequencies and multiple phases within each frequency). Since the DPP-A mechanism, as we have described it, requires representations to be factored in this way it would need to be modified for such purpose. Either of these approaches, if successful, would allow our model to be extended to domains containing nonlinear forms of structure. To the extent that different coding schemes (i.e., basis sets) are needed for different forms of structure, the question of how these are identified and engaged for use in a given setting is clearly an important one, that is not addressed by the current work. We imagine that this is likely subserved by monitoring and selection mechanisms proposed to underlie the capacity for selective attention and cognitive control [5], though the specific computational mechanisms that underlie this function remain an important direction for future research. We have added a discussion of these issues in Section 6 of the updated manuscript.</p><p>(1) Whittington, J.C., Muller, T.H., Mark, S., Chen, G., Barry, C., Burgess, N. and Behrens, T.E., 2020. The Tolman-Eichenbaum machine: unifying space and relational memory through generalization in the hippocampal formation. Cell, 183(5), pp.1249-1263.</p><p>(2) Dayan, P., 1993. Improving generalization for temporal difference learning: The successor representation. Neural computation, 5(4), pp.613-624.</p><p>(3) Stachenfeld, K.L., Botvinick, M.M. and Gershman, S.J., 2017. The hippocampus as a predictive map. Nature neuroscience, 20(11), pp.1643-1653.</p><p>(4) Frankland, S., Webb, T.W., Petrov, A.A., O'Reilly, R.C. and Cohen, J., 2019. Extracting and Utilizing Abstract, Structured Representations for Analogy. In CogSci (pp. 1766-1772).</p><p>(5) Shenhav, A., Botvinick, M.M. and Cohen, J.D., 2013. The expected value of control: an integrative theory of anterior cingulate cortex function. Neuron, 79(2), pp.217-240.</p><p><bold>Biological plausibility of DPP-A</bold></p><p>We appreciate the reviewers’ interest in the biological plausibility of our model, and in particular the question of whether and how DPP-A might be implemented in a neural network. In that regard, Bozkurt et al. [1] recently proposed a biologically plausible neural network algorithm using a weighted similarity matrix approach to implement a determinant maximization criterion, which is the core idea underlying the objective function we use for DPP-A, suggesting that the DPP-A mechanism we describe may also be biologically plausible. This could be tested experimentally by exposing individuals (e.g., rodents or humans) to a task that requires consistent exposure to a subregion, and evaluating the distribution of activity over the grid cells. Our model predicts that high frequency grid cells should increase their firing rate more than low frequency cells, since the high frequency grid cells maximize the determinant of the covariance matrix of the grid cell embeddings. It is also worth noting that Frankland et al. [2] have suggested that the use of DPPs may also help explain a mutual exclusivity bias observed in human word learning and reasoning. While this is not direct evidence of biological plausibility, it is consistent with the idea that the human brain selects representations for processing that maximize the volume of the representational space, which can be achieved by maximizing the DPP-A objective function defined in Equation 6. We have added a comment to this effect in Section 6 of the updated manuscript.</p><p>(1) Bozkurt, B., Pehlevan, C. and Erdogan, A., 2022. Biologically-plausible determinant maximization neural networks for blind separation of correlated sources. Advances in Neural Information Processing Systems, 35, pp.13704-13717.</p><p>(2) Frankland, S. and Cohen, J., 2020. Determinantal Point Processes for Memory and Structured Inference. In CogSci.</p><p><bold>Simplicity of analogical problem and comparison to other models using this task</bold></p><p>First, we would like to point out that analogical reasoning is a signatory feature of human cognition, which supports flexible and efficient adaptation to novel inputs that remains a challenge for most current neural network architectures. While humans can exhibit complex and sophisticated forms of analogical reasoning [1, 2, 3], here we focused on a relatively simple form, that was inspired by Rumelhart’s parallelogram model of analogy [4,5] that has been used to explain traditional human verbal analogies (e.g., “king is to what as man is to woman?”). Our model, like that one, seeks to explain analogical reasoning in terms of the computation of simple Euclidean distances (i.e., A - B = C - D, where A, B, C, D are vectors in 2D space). We have now noted this in Section 2.1.1 of the updated manuscript. It is worth noting that, despite the seeming simplicity of this construction, we show that standard neural network architectures (e.g., LSTMs and transformers) struggle to generalize on such tasks without the use of the DPP-A mechanism.</p><p>Second, we are not aware of any previous work other than Frankland et al. [6] cited in the first paragraph of Section 2.2.1, that has examined the capacity of neural network architectures to perform even this simple form of analogy. The models in that study were hardcoded to perform analogical reasoning, whereas we trained models to learn to perform analogies. That said, clearly a useful line of future work would be to scale our model further to deal with more complex forms of representation and analogical reasoning tasks [1,2,3]. We have noted this in Section 6 of the updated manuscript.</p><p>(1) Holyoak, K.J., 2012. Analogy and relational reasoning. The Oxford handbook of thinking and reasoning, pp.234-259.</p><p>(2) Webb, T., Fu, S., Bihl, T., Holyoak, K.J. and Lu, H., 2023. Zero-shot visual reasoning through probabilistic analogical mapping. Nature Communications, 14(1), p.5144.</p><p>(3) Lu, H., Ichien, N. and Holyoak, K.J., 2022. Probabilistic analogical mapping with semantic relation networks. Psychological review.</p><p>(4) Rumelhart, D.E. and Abrahamson, A.A., 1973. A model for analogical reasoning. Cognitive Psychology, 5(1), pp.1-28.</p><p>(5) Mikolov, T., Chen, K., Corrado, G. and Dean, J., 2013. Efficient estimation of word representations in vector space. arXiv preprint arXiv:1301.3781.</p><p>(6) Frankland, S., Webb, T.W., Petrov, A.A., O'Reilly, R.C. and Cohen, J., 2019. Extracting and Utilizing Abstract, Structured Representations for Analogy. In CogSci (pp. 1766-1772).</p><p><bold>Clarification of DPP-A attentional modulation</bold></p><p>We would like to clarify several concerns regarding the DPP-A attentional modulation. First, we would like to make it clear that ω is not meant to correspond to synaptic weights, and thank the reviewer for noting the possibility for confusion on this point. It is also distinct from a biasing input, which is often added to the product of the input features and weights. Rather, in our model ω is a vector, and diag (ω) converts it into a matrix with ω as the diagonal of the matrix, and the rest entries are zero. In Equation 6, diag(ω) is matrix multiplied with the covariance matrix V, which results in elementwise multiplication of ω with column vectors of V, and hence acts more like gates. We have noted this in Section 2.2.2 and have changed all instances of “weights (ω)” to “gates (ɡ)” in the updated manuscript. We have also rewritten the definition of Equation 6 and uses of it (as in Algorithm 1) to depict the use of sigmoid nonlinearity (σ) to , so that the resulting values are always between 0 and 1.</p><p>Second, we would like to clarify that we don’t compute the inner product between the gates ɡ and the grid cell embeddings x anywhere in our model. The gates within each frequency were optimized (independent of the task inputs), according to Equation 6, to compute the approximate maximum log determinant of the covariance matrix over the grid cell embeddings individually for each frequency. We then used the grid cell embeddings belonging to the frequency that had the maximum within-frequency log determinant for training the inference module, which always happened to be grid cells within the top three frequencies. Author response image 1 (also added to the Appendix, Section 7.10 of the updated manuscript) shows the approximate maximum log determinant (on the y-axis) for the different frequencies (on the x-axis).</p><fig id="sa2fig1" position="float"><label>Author response image 1.</label><caption><title>Approximate maximum log determinant of the covariance matrix over the grid cell embeddings (y-axis) for each frequency (x-axis), obtained after maximizing Equation 6.</title></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-89911-sa2-fig1-v1.tif"/></fig><p>Third, we would like to clarify our interpretation of why DPP-A identified grid cell embeddings corresponding to the highest spatial frequencies, and why this produced the best OOD generalization (i.e., extrapolation on our analogy tasks). It is because those grid cell embeddings exhibited greater variance over the training data than the lower frequency embeddings, while at the same time the correlations among those grid cell embeddings were lower than the correlations among the lower frequency grid cell embeddings. The determinant of the covariance matrix of the grid cell embeddings is maximized when the variances of the grid cell embeddings are high (they are “expressive”) and the correlation among the grid cell embeddings is low (they “cover the representational space”). As a result, the higher frequency grid cell embeddings more efficiently covered the representational space of the training data, allowing them to efficiently capture the same relational structure across training and test distributions which is required for OOD generalization. We have added some clarification to the second paragraph of Section 2.2.2 in the updated manuscript. Furthermore, to illustrate this graphically, Author response image 2 (added to the Appendix, Section 7.10 of the updated manuscript) shows the results after the summation of the multiplication of the grid cell embeddings over the 2d space of 1000x1000 locations, with their corresponding gates for 3 representative frequencies (left, middle and right panels showing results for the lowest, middle and highest grid cell frequencies, respectively, of the 9 used in the model), obtained after maximizing Equation 6 for each grid cell frequency. The color code indicates the responsiveness of the grid cells to different X and Y locations in the input space (lighter color corresponding to greater responsiveness). Note that the dark blue area (denoting regions of least responsiveness to any grid cell) is greatest for the lowest frequency and nearly zero for the highest frequency, illustrating that grid cell embeddings belonging to the highest frequency more efficiently cover the representational space which allows them to capture the same relational structure across training and test distributions as required for OOD generalization.</p><fig id="sa2fig2" position="float"><label>Author response image 2.</label><caption><title>Each panel shows the results after summation of the multiplication of the grid cell embeddings over the 2d space of 1000x1000 locations, with their corresponding gates for a particular frequency, obtained after maximizing Equation 6 for each grid cell frequency.</title><p>The left, middle, and right panels show results for the lowest, middle, and highest grid cell frequencies, respectively, of the 9 used in the model. Lighter color in each panel corresponds to greater responsiveness of grid cells at that particular location in the 2d space.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-89911-sa2-fig2-v1.tif"/></fig><p>Finally, we would like to clarify how the DPP-A attentional mechanism is different from the attentional mechanism in the transformer module, and why both are needed for strong OOD generalization. Use of the standard self-attention mechanism in transformers over the inputs (i.e., A, B, C, and D for the analogy task) in place of DPP-A would lead to weightings of grid cell embeddings over all frequencies and phases. The objective function for the DPP-A represents an inductive bias, that selectively assigns the greatest weight to all grid cell embeddings (i.e., for all phases) of the frequency for which the determinant of the covariance matrix is greatest computed over the training space. The transformer inference module then attends over the inputs with the selected grid cell embeddings based on the DPP-A objective. We have added a discussion of this point in Section 6 of the updated manuscript.</p><p>We would like to thank the reviewers for their recommendations. We have tried our best to incorporate them into our updated manuscript. Below we provide a detailed response to each of the recommendations grouped for each reviewer.</p><disp-quote content-type="editor-comment"><p><bold>Reviewer #1 (Recommendations for the authors)</bold></p><p>(1) It would be helpful to see some equations for R in the main text.</p></disp-quote><p>We thank the reviewer for this suggestion. We have now added some equations explaining the working of R in Section 2.2.3 of the updated manuscript.</p><disp-quote content-type="editor-comment"><p>(2) Typo: p 11 'alongwith' -&gt; 'along with'</p></disp-quote><p>We have changed all instances of ‘alongwith’ to ‘along with’ in the updated manuscript.</p><disp-quote content-type="editor-comment"><p>(3) Presumably, this is related to equivariant ML - it would be helpful to comment on this.</p></disp-quote><p>Yes, this is related to equivariant ML, since the properties of equivariance hold for our model. Specifically, the probability distribution after applying softmax remains the same when the transformation (translation or scaling) is applied to the scores for each of the answer choices obtained from the output of the inference module, and when the same transformation is applied to the stimuli for the task and all the answer choices before presenting as input to the inference module to obtain the scores. We have commented on this in Section 2.2.3 of the updated manuscript.</p><disp-quote content-type="editor-comment"><p><bold>Reviewer #2 (Recommendations for the authors)</bold></p><p>(1) Page 2 - &quot;Webb et al.&quot; temporal context - they should also cite and compare this to work by Marc Howard on generalization based on multi-scale temporal context.</p></disp-quote><p>While we appreciate the important contributions that have been made by Marc Howard and his colleagues to temporal coding and its role in episodic memory and hippocampal function, we would like to clarify that his temporal context model is unrelated to the temporal context normalization developed by Webb et al. (2020) and mentioned on Page 2. The former (Temporal Context Model) is a computational model that proposes a role for temporal coding in the functions of the medial temporal lobe in support of episodic recall, and spatial navigation. The latter (temporal context normalization) is a normalization procedure proposed for use in training a neural network, similar to batch normalization [1], in which tensor normalization is applied over the temporal instead of the batch dimension, which is shown to help with OOD generalization. We apologize for any confusion engendered by the similarity of these terms, and failure to clarify the difference between these, that we have now attempted to do in a footnote on Page 2.</p><p>Ioffe, S. and Szegedy, C., 2015, June. Batch normalization: Accelerating deep network training by reducing internal covariate shift. In International conference on machine learning (pp. 448-456). pmlr.</p><disp-quote content-type="editor-comment"><p>(2) page 3 - &quot;known to be implemented in entorhinal&quot; - It's odd that they seem to avoid citing the actual biology papers on grid cells. They should cite more of the grid cell recording papers when they mention the entorhinal cortex (i.e. Hafting et al., 2005; Barry et al., 2007; Stensola et al., 2012; Giocomo et al., 2011; Brandon et al., 2011).</p></disp-quote><p>We have now cited the references mentioned below, on page 3 after the phrase “known to be implemented in entohinal cortex”.</p><p>(1) Barry, C., Hayman, R., Burgess, N. and Jeffery, K.J., 2007. Experience-dependent rescaling of entorhinal grids. Nature neuroscience, 10(6), pp.682-684.</p><p>(2) Stensola, H., Stensola, T., Solstad, T., Frøland, K., Moser, M.B. and Moser, E.I., 2012. The entorhinal grid map is discretized. Nature, 492(7427), pp.72-78.</p><p>(3) Giocomo, L.M., Hussaini, S.A., Zheng, F., Kandel, E.R., Moser, M.B. and Moser, E.I., 2011. Grid cells use HCN1 channels for spatial scaling. Cell, 147(5), pp.1159-1170.</p><p>(4) Brandon, M.P., Bogaard, A.R., Libby, C.P., Connerney, M.A., Gupta, K. and Hasselmo, M.E., 2011. Reduction of theta rhythm dissociates grid cell spatial periodicity from directional tuning. Science, 332(6029), pp.595-599.</p><disp-quote content-type="editor-comment"><p>(3) To enhance the connection to biological systems, they should cite more of the experimental and modeling work on grid cell coding (for example on page 2 where they mention relational coding by grid cells). Currently, they tend to cite studies of grid cell relational representations that are very indirect in their relationship to grid cell recordings (i.e. indirect fMRI measures by Constaninescu et al., 2016 or the very abstract models by Whittington et al., 2020). They should cite more papers on actual neurophysiological recordings of grid cells that suggest relational/metric representations, and they should cite more of the previous modeling papers that have addressed relational representations. This could include work on using grid cell relational coding to guide spatial behavior (e.g. Erdem and Hasselmo, 2014; Bush, Barry, Manson, Burges, 2015). This could also include other papers on the grid cell code beyond the paper by Wei et al., 2015 - they could also cite work on the efficiency of coding by Sreenivasan and Fiete and by Mathis, Herz, and Stemmler.</p></disp-quote><p>We thank the reviewer for bringing the additional references to our attention. We have cited the references mentioned below on page 2 of the updated manuscript.</p><p>(1) Erdem, U.M. and Hasselmo, M.E., 2014. A biologically inspired hierarchical goal directed navigation model. Journal of Physiology-Paris, 108(1), pp.28-37.</p><p>(2) Sreenivasan, S. and Fiete, I., 2011. Grid cells generate an analog error-correcting code for singularly precise neural computation. Nature neuroscience, 14(10), pp.1330-1337.</p><p>(3) Mathis, A., Herz, A.V. and Stemmler, M., 2012. Optimal population codes for space: grid cells outperform place cells. Neural computation, 24(9), pp.2280-2317.</p><p>(4) Bush, D., Barry, C., Manson, D. and Burgess, N., 2015. Using grid cells for navigation. Neuron, 87(3), pp.507-520</p><disp-quote content-type="editor-comment"><p>(4) Page 3 - &quot;Determinantal Point Processes (DPPs)&quot; - it is rather annoying that DPP is defined after DPP-A is defined. There ought to be a spot where the definition of DPP-A is clearly stated in a single location.</p></disp-quote><p>We agree it makes more sense to define Determinantal Point Process (DPP) before DPP-A. We have now rephrased the sentences accordingly. In the “Abstract”, the sentence now reads “Second, we propose an attentional mechanism that operates over the grid cell code using Determinantal Point Process (DPP), which we call DPP attention (DPP-A) - a transformation that ensures maximum sparseness in the coverage of that space.” We have also modified the second paragraph of the “Introduction”. The modified portion now reads “(2) an attentional objective inspired from Determinantal Point Processes (DPPs), which are probabilistic models of repulsion arising in quantum physics [1], to attend to abstract representations that have maximum variance and minimum correlation among them, over the training data. We refer to this as DPP attention or DPP-A.” Due to this change, we removed the last sentence of the fifth paragraph of the “Introduction”.</p><p>(1) Macchi, O., 1975. The coincidence approach to stochastic point processes. Advances in Applied Probability, 7(1), pp.83-122.</p><disp-quote content-type="editor-comment"><p>(5) Page 3 - &quot;the inference module R&quot; - there should be some discussion about how this component using LSTM or transformers could relate to the function of actual brain regions interacting with entorhinal cortex. Or if there is no biological connection, they should state that this is not seen as a biological model and that only the grid cell code is considered biological.</p></disp-quote><p>While we agree that the model is not construed to be as specific about the implementation of the R module, we assume that — as a standard deep learning component — it is likely to map onto neocortical structures that interact with the entorhinal cortex and, in particular, regions of the prefrontal-posterior parietal network widely believed to be involved in abstract relational processes [1,2,3,4]. In particular, the role of the prefrontal cortex in the encoding and active maintenance of abstract information needed for task performance (such as rules and relations) has often been modeled using gated recurrent networks, such as LSTMs [5,6], and the posterior parietal cortex has long been known to support “maps” that may provide an important substrate for computing complex relations [4]. We have added some discussion about this in Section 2.2.3 of the updated manuscript.</p><p>(1) Waltz, J.A., Knowlton, B.J., Holyoak, K.J., Boone, K.B., Mishkin, F.S., de Menezes Santos, M., Thomas, C.R. and Miller, B.L., 1999. A system for relational reasoning in human prefrontal cortex. Psychological science, 10(2), pp.119-125.</p><p>(2) Christoff, K., Prabhakaran, V., Dorfman, J., Zhao, Z., Kroger, J.K., Holyoak, K.J. and Gabrieli, J.D., 2001. Rostrolateral prefrontal cortex involvement in relational integration during reasoning. Neuroimage, 14(5), pp.1136-1149.</p><p>(3) Knowlton, B.J., Morrison, R.G., Hummel, J.E. and Holyoak, K.J., 2012. A neurocomputational system for relational reasoning. Trends in cognitive sciences, 16(7), pp.373-381.</p><p>(4) Summerfield, C., Luyckx, F. and Sheahan, H., 2020. Structure learning and the posterior parietal cortex. Progress in neurobiology, 184, p.101717.</p><p>(5) Frank, M.J., Loughry, B. and O’Reilly, R.C., 2001. Interactions between frontal cortex and basal ganglia in working memory: a computational model. Cognitive, Affective, &amp; Behavioral Neuroscience, 1, pp.137-160.</p><p>(6) Braver, T.S. and Cohen, J.D., 2000. On the control of control: The role of dopamine in regulating prefrontal function and working memory. Control of cognitive processes: Attention and performance XVIII, (2000).</p><disp-quote content-type="editor-comment"><p>(6) Page 4 - &quot;Learned weighting w&quot; - it is somewhat confusing to use &quot;w&quot; as that is commonly used for synaptic weights, whereas I understand this to be an attentional modulation vector with the same dimensionality as the grid cell code. It seems more similar to a neural network bias input than a weight matrix.</p></disp-quote><p>We refer to the first paragraph of our response above to the topic “Clarification of DPP-A attentional modulation” under “Major comments (Public Reviews)”, which contains our response to this issue.</p><disp-quote content-type="editor-comment"><p>(7) Page 4 - &quot;parameterization of w... by two loss functions over the training set.&quot; - I realize that this has been stated here, but to emphasize the significance to a naïve reader, I think they should emphasize that the learning is entirely focused on the initial training space, and there is NO training done in the test spaces. It's very impressive that the parameterization is allowing generalization to translated or scaled spaces without requiring ANY training on the translated or scaled spaces.</p></disp-quote><p>We have added the sentence “Note that learning of parameter occurs only over the training space and is not further modified during testing (i.e. over the test spaces)” to the updated manuscript.</p><disp-quote content-type="editor-comment"><p>(8) Page 4 - &quot;The first,&quot; - This should be specific - &quot;The first loss function&quot;</p></disp-quote><p>We have changed it to “The first loss function” in the updated manuscript.</p><disp-quote content-type="editor-comment"><p>(9) Page 4 - The analogy task seems rather simplistic when first presented (i.e. just a spatial translation to different parts of a space, which has already been shown to work in simulations of spatial behavior such as Erdem and Hasselmo, 2014 or Bush, Barry, Manson, Burgess, 2015). To make the connection to analogy, they might provide a brief mention of how this relates to the analogy space created by word2vec applied to traditional human verbal analogies (i.e. king-man+woman=queen).</p></disp-quote><p>We agree that the analogy task is simple, and recognize that grid cells can be used to navigate to different parts of space over which the test analogies are defined when those are explicitly specified, as shown by Erdem and Hasselmo (2014) and Bush, Barry, Manson, and Burgess (2015). However, for the analogy task, the appropriate set of grid cell embeddings must be identified that capture the same relational structure between training and test analogies to demonstrate strong OOD generalization, and that is achieved by the attentional mechanism DPP-A. As suggested by the reviewer’s comment, our analogy task is inspired by Rumelhart’s parallelogram model of analogy [1,2] (and therefore similar to traditional human verbal analogies) in as much as it involves differences (i.e A - B = C - D, where A, B, C, D are vectors in 2D space). We have now noted this in Section 2.1.1 of the updated manuscript.</p><p>(1) Rumelhart, D.E. and Abrahamson, A.A., 1973. A model for analogical reasoning. Cognitive Psychology, 5(1), pp.1-28.</p><p>(2) Mikolov, T., Chen, K., Corrado, G. and Dean, J., 2013. Efficient estimation of word representations in vector space. arXiv preprint arXiv:1301.3781.</p><disp-quote content-type="editor-comment"><p>(10) Page 5 - The variable &quot;KM&quot; is a bit confusing when it first appears. It would be good to re-iterate that K and M are separate points and KM is the vector between these points.</p></disp-quote><p>We apologize for the confusion on this point. KM is meant to refer to an integer value, obtained by multiplying K and M, which is added to both dimensions of A, B, C and D, which are points in ℤ2, to translate them to a different region of the space. K is an integer value ranging from 1 to 9 and M is also an integer value denoting the size of the training region, which in our implementation is 100. We have clarified this in Section 2.1.1 of the updated manuscript.</p><disp-quote content-type="editor-comment"><p>(11) Page 5 - &quot;two continuous dimensions (Constantinescu et al._)&quot; - this ought to give credit to the original study showing the abstract six-fold rotational symmetry for spatial coding (Doeller, Barry and Burgess).</p></disp-quote><p>We have now cited the original work by Doeller et al. [1] along with Constantinescu et al. (2016) in the updated manuscript after the phrase “two continuous dimensions” on page 5.</p><p>(1) Doeller, C.F., Barry, C. and Burgess, N., 2010. Evidence for grid cells in a human memory network. Nature, 463(7281), pp.657-661.</p><disp-quote content-type="editor-comment"><p>(12) Page 6 - Np=100. This is done later, but it would be clearer if they right away stated that Np*Nf=900 in this first presentation.</p></disp-quote><p>We have now added this sentence after Np=100. “Hence Np*Nf=900, which denotes the number of grid cells.”</p><disp-quote content-type="editor-comment"><p>(13) Page 6 - They provide theorem 2.1 on the determinant of the covariance matrix of the grid code, but they ought to cite this the first time this is mentioned.</p></disp-quote><p>We have cited Gilenwater et al. (2012) before mentioning theorem 2.1. The sentence just before that reads “We use the following theorem from Gillenwater et al. (2012) to construct :”</p><disp-quote content-type="editor-comment"><p>(14) Page 6 - It would greatly enhance the impact of the paper if they could give neuroscientists some sense of how the maximization of the determinant of the covariance matrix of the grid cell code could be implemented by a biological circuit. OR at least to show an example of the output of this algorithm when it is used as an inner product with the grid cell code. This would require plotting the grid cell code in the spatial domain rather than the 900 element vector.</p></disp-quote><p>We refer to our response above to the topic “Biological plausibility of DPP-A” and second, third, and fourth paragraphs of our response above to the topic “Clarification of DPP-A attentional modulation” under “Major comments (Public Reviews)”, which contain our responses to this issue.</p><disp-quote content-type="editor-comment"><p>(15) Page 6 - &quot;That encode higher spatial frequencies...&quot; This seems intuitive, but it would be nice to give a more intuitive description of how this is related to the determinant of the covariance matrix.</p></disp-quote><p>We refer to the third paragraph of our response above to the topic “Clarification of DPP-A attentional modulation” under “Major comments (Public Reviews)”, which contains our response to this issue.</p><disp-quote content-type="editor-comment"><p>(16) Page 7 - log of both sides... Nf is number of frequencies... Would be good to mention here that they are referring to equation 6 which is only mentioned later in the paragraph.</p></disp-quote><p>As suggested, we now refer to Equation 6 in the updated manuscript. The sentence now reads “This is achieved by maximizing the determinant of the covariance matrix over the within frequency grid cell embeddings of the training data, and Equation 6 is obtained by applying the log on both sides of Theorem 2.1, and in our case where refers to grid cells of a particular frequency.”</p><disp-quote content-type="editor-comment"><p>(17) Page 7 - Equation 6 - They should discuss how this is proposed to be implemented in brain circuits.</p></disp-quote><p>We refer to our response above to the topic “Biological plausibility of DPP-A” under “Major comments (Public Reviews)”, which contains our response to this issue.</p><disp-quote content-type="editor-comment"><p>1. Page 9 - &quot;egeneralize&quot; - presumably this is a typo?</p></disp-quote><p>Yes. We have corrected it to “generalize” in the updated manuscript.</p><disp-quote content-type="editor-comment"><p>(19) Page 9 - &quot;biologically plausible encoding scheme&quot; - This is valid for the grid cell code, but they should be clear that this is not valid for other parts of the model, or specify how other parts of the model such as DPP-A could be biologically plausible.</p></disp-quote><p>We refer to our response above to the topic “Biological plausibility of DPP-A” under “Major comments (Public Reviews)”, which contains our response to this issue.</p><disp-quote content-type="editor-comment"><p>(20) Page 12 - Figure 7 - comparsion to one-hots or smoothed one-hots. The text should indicate whether the smoothed one-hots are similar to place cell coding. This is the most relevant comparison of coding for those knowledgeable about biological coding schemes.</p></disp-quote><p>Yes, smoothed one-hots are similar to place cell coding. We now mention this in Section 5.3 of the updated manuscript.</p><disp-quote content-type="editor-comment"><p>(21) Page 12 - They could compare to a broader range of potential biological coding schemes for the overall space. This could include using coding based on the boundary vector cell coding of the space, band cell coding (one dimensional input to grid cells), or egocentric boundary cell coding.</p></disp-quote><p>We appreciate these useful suggestions, which we now mention as potentially valuable directions for future work in the second paragraph of Section 6 of the updated manuscript.</p><disp-quote content-type="editor-comment"><p>(22) Page 13 - &quot;transformers are particularly instructive&quot; - They mention this as a useful comparison, but they might discuss further why a much better function is obtained when attention is applied to the system twice (once by DPP-A and then by a transformer in the inference module).</p></disp-quote><p>We refer to the last paragraph of our response above to the topic “Clarification of DPP-A attentional modulation” under “Major comments (Public Reviews)”, which contains our response to this issue.</p><disp-quote content-type="editor-comment"><p>(23) Page 13 - &quot;Section 5.1 for analogy and Section 5.2 for arithmetic&quot; - it would be clearer if they perhaps also mentioned the specific figures (Figure 4 and Figure 6) presenting the results for the transformer rather than the LSTM.</p></disp-quote><p>We have now rephrased to also refer to the figures in the updated manuscript. The phrase now reads “a transformer (Figure 4 in Section 5.1 for analogy and Figure 6 in Section 5.2 for arithmetic tasks) failed to achieve the same level of OOD generalization as the network that used DPP-A.”</p><disp-quote content-type="editor-comment"><p>(24) Page 14 - &quot;statistics of the training data&quot; - The most exciting feature of this paper is that learning during the training space analogies can so effectively generalize to other spaces based on the right attention DPP-A, but this is not really made intuitive. Again, they should illustrate the result of the xT w inner product to demonstrate why this work so effectively!</p></disp-quote><p>We refer to the second, third, and fourth paragraphs of our response above to the topic “Clarification of DPP-A attentional modulation” under “Major comments (Public Reviews)”, which contains our response to this issue.</p><disp-quote content-type="editor-comment"><p>(25) Bibliography - Silver et al., go paper - journal name &quot;nature&quot; should be capitalized. There are other journal titles that should be capitalized. Also, I believe eLife lists family names first.</p></disp-quote><p>We have made the changes to the bibliography of the updated manuscript suggested by the reviewer.</p></body></sub-article></article>