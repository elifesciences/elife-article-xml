<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD with MathML3 v1.2 20190208//EN"  "JATS-archivearticle1-mathml3.dtd"><article article-type="research-article" dtd-version="1.2" xmlns:ali="http://www.niso.org/schemas/ali/1.0/" xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink"><front><journal-meta><journal-id journal-id-type="nlm-ta">elife</journal-id><journal-id journal-id-type="publisher-id">eLife</journal-id><journal-title-group><journal-title>eLife</journal-title></journal-title-group><issn pub-type="epub" publication-format="electronic">2050-084X</issn><publisher><publisher-name>eLife Sciences Publications, Ltd</publisher-name></publisher></journal-meta><article-meta><article-id pub-id-type="publisher-id">76096</article-id><article-id pub-id-type="doi">10.7554/eLife.76096</article-id><article-categories><subj-group subj-group-type="display-channel"><subject>Research Article</subject></subj-group><subj-group subj-group-type="heading"><subject>Neuroscience</subject></subj-group></article-categories><title-group><article-title>Invariant neural subspaces maintained by feedback modulation</article-title></title-group><contrib-group><contrib contrib-type="author" corresp="yes" id="author-191462"><name><surname>Naumann</surname><given-names>Laura B</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">https://orcid.org/0000-0002-7919-7349</contrib-id><email>laura-bella.naumann@bccn-berlin.de</email><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="aff" rid="aff2">2</xref><xref ref-type="fn" rid="con1"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" id="author-263520"><name><surname>Keijser</surname><given-names>Joram</given-names></name><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="fn" rid="con2"/><xref ref-type="fn" rid="conf2"/></contrib><contrib contrib-type="author" id="author-43434"><name><surname>Sprekeler</surname><given-names>Henning</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">https://orcid.org/0000-0003-0690-3553</contrib-id><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="aff" rid="aff2">2</xref><xref ref-type="fn" rid="con3"/><xref ref-type="fn" rid="conf2"/></contrib><aff id="aff1"><label>1</label><institution-wrap><institution-id institution-id-type="ror">https://ror.org/03v4gjf40</institution-id><institution>Modelling of Cognitive Processes, Technical University of Berlin</institution></institution-wrap><addr-line><named-content content-type="city">Berlin</named-content></addr-line><country>Germany</country></aff><aff id="aff2"><label>2</label><institution-wrap><institution-id institution-id-type="ror">https://ror.org/05ewdps05</institution-id><institution>Bernstein Center for Computational Neuroscience</institution></institution-wrap><addr-line><named-content content-type="city">Berlin</named-content></addr-line><country>Germany</country></aff></contrib-group><contrib-group content-type="section"><contrib contrib-type="editor"><name><surname>Ostojic</surname><given-names>Srdjan</given-names></name><role>Reviewing Editor</role><aff><institution-wrap><institution-id institution-id-type="ror">https://ror.org/05a0dhs15</institution-id><institution>Ecole Normale Superieure Paris</institution></institution-wrap><country>France</country></aff></contrib><contrib contrib-type="senior_editor"><name><surname>King</surname><given-names>Andrew J</given-names></name><role>Senior Editor</role><aff><institution-wrap><institution-id institution-id-type="ror">https://ror.org/052gg0110</institution-id><institution>University of Oxford</institution></institution-wrap><country>United Kingdom</country></aff></contrib></contrib-group><pub-date date-type="publication" publication-format="electronic"><day>20</day><month>04</month><year>2022</year></pub-date><pub-date pub-type="collection"><year>2022</year></pub-date><volume>11</volume><elocation-id>e76096</elocation-id><history><date date-type="received" iso-8601-date="2021-12-03"><day>03</day><month>12</month><year>2021</year></date><date date-type="accepted" iso-8601-date="2022-04-06"><day>06</day><month>04</month><year>2022</year></date></history><pub-history><event><event-desc>This manuscript was published as a preprint at bioRxiv.</event-desc><date date-type="preprint" iso-8601-date="2021-11-01"><day>01</day><month>11</month><year>2021</year></date><self-uri content-type="preprint" xlink:href="https://doi.org/10.1101/2021.10.29.466453"/></event></pub-history><permissions><copyright-statement>Â© 2022, Naumann et al</copyright-statement><copyright-year>2022</copyright-year><copyright-holder>Naumann et al</copyright-holder><ali:free_to_read/><license xlink:href="http://creativecommons.org/licenses/by/4.0/"><ali:license_ref>http://creativecommons.org/licenses/by/4.0/</ali:license_ref><license-p>This article is distributed under the terms of the <ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/licenses/by/4.0/">Creative Commons Attribution License</ext-link>, which permits unrestricted use and redistribution provided that the original author and source are credited.</license-p></license></permissions><self-uri content-type="pdf" xlink:href="elife-76096-v2.pdf"/><self-uri content-type="figures-pdf" xlink:href="elife-76096-figures-v2.pdf"/><abstract><p>Sensory systems reliably process incoming stimuli in spite of changes in context. Most recent models accredit this context invariance to an extraction of increasingly complex sensory features in hierarchical feedforward networks. Here, we study how context-invariant representations can be established by feedback rather than feedforward processing. We show that feedforward neural networks modulated by feedback can dynamically generate invariant sensory representations. The required feedback can be implemented as a slow and spatially diffuse gain modulation. The invariance is not present on the level of individual neurons, but emerges only on the population level. Mechanistically, the feedback modulation dynamically reorients the manifold of neural activity and thereby maintains an invariant neural subspace in spite of contextual variations. Our results highlight the importance of population-level analyses for understanding the role of feedback in flexible sensory processing.</p></abstract><kwd-group kwd-group-type="author-keywords"><kwd>feedback</kwd><kwd>sensory processing</kwd><kwd>invariance</kwd><kwd>gain modulation</kwd><kwd>blind source separation</kwd><kwd>population analyses</kwd></kwd-group><kwd-group kwd-group-type="research-organism"><title>Research organism</title><kwd>None</kwd></kwd-group><funding-group><funding-statement>No external funding was received for this work.</funding-statement></funding-group><custom-meta-group><custom-meta specific-use="meta-only"><meta-name>Author impact statement</meta-name><meta-value>Feedback-driven gain modulation provides a mechanism to generate and maintain invariant sensory representations in the presence of contextual changes by dynamically adapting feedforward sensory processing.</meta-value></custom-meta></custom-meta-group></article-meta></front><body><sec id="s1" sec-type="intro"><title>Introduction</title><p>In natural environments, our senses are exposed to a colourful mix of sensory impressions. Behaviourally relevant stimuli can appear in varying contexts, such as variations in lighting, acoustics, stimulus position, or the presence of other stimuli. Different contexts may require different responses to the same stimulus, for example, when the behavioural task changes (context dependence). Alternatively, the same response may be required for different stimuli, for example, when the sensory context changes (context invariance). Recent advances have elucidated how context-<italic>dependent</italic> processing can be performed by recurrent feedback in neural circuits (<xref ref-type="bibr" rid="bib52">Mante et al., 2013</xref>; <xref ref-type="bibr" rid="bib93">Wang et al., 2018a</xref>; <xref ref-type="bibr" rid="bib21">Dubreuil et al., 2020</xref>). In contrast, the role of feedback mechanisms in context-<italic>invariant</italic> processing is not well understood.</p><p>In the classical view, stimuli are hierarchically processed towards a behaviourally relevant percept that is invariant to contextual variations. This is achieved by extracting increasingly complex features in a feedforward network (<xref ref-type="bibr" rid="bib45">Kriegeskorte, 2015</xref>; <xref ref-type="bibr" rid="bib98">Zhuang et al., 2021</xref>; <xref ref-type="bibr" rid="bib97">Yamins and DiCarlo, 2016</xref>). Models of such feedforward networks have been remarkably successful at learning complex perceptual tasks (<xref ref-type="bibr" rid="bib49">LeCun et al., 2015</xref>), and they account for various features of cortical sensory representations (<xref ref-type="bibr" rid="bib16">DiCarlo and Cox, 2007</xref>; <xref ref-type="bibr" rid="bib44">Kriegeskorte et al., 2008</xref>; <xref ref-type="bibr" rid="bib17">DiCarlo et al., 2012</xref>; <xref ref-type="bibr" rid="bib35">Hong et al., 2016</xref>; <xref ref-type="bibr" rid="bib14">Cichy et al., 2016</xref>). Yet, these models neglect feedback pathways, which are abundant in sensory cortex (<xref ref-type="bibr" rid="bib23">Felleman and Van Essen, 1991</xref>; <xref ref-type="bibr" rid="bib53">Markov et al., 2014</xref>) and shape sensory processing in critical ways (<xref ref-type="bibr" rid="bib27">Gilbert and Li, 2013</xref>). Incorporating these feedback loops into models of sensory processing increases their flexibility and robustness (<xref ref-type="bibr" rid="bib85">Spoerer et al., 2017</xref>; <xref ref-type="bibr" rid="bib2">Alamia et al., 2021</xref>; <xref ref-type="bibr" rid="bib61">Nayebi et al., 2021</xref>) and improves their fit to neural data (<xref ref-type="bibr" rid="bib39">Kar et al., 2019</xref>; <xref ref-type="bibr" rid="bib42">Kietzmann et al., 2019</xref>; <xref ref-type="bibr" rid="bib61">Nayebi et al., 2021</xref>). At the neuronal level, feedback is thought to modulate rather than drive local responses (<xref ref-type="bibr" rid="bib82">Sherman and Guillery, 1998</xref>), for instance, depending on behavioural context (<xref ref-type="bibr" rid="bib62">Niell and Stryker, 2010</xref>; <xref ref-type="bibr" rid="bib92">Vinck et al., 2015</xref>; <xref ref-type="bibr" rid="bib46">Kuchibhotla et al., 2017</xref>; <xref ref-type="bibr" rid="bib18">Dipoppa et al., 2018</xref>).</p><p>Here, we investigate the hypothesis that feedback modulation provides a neural mechanism for context-invariant perception. To this end, we trained a feedback-modulated network model to perform a context-invariant perceptual task and studied the resulting neural mechanisms. We show that the feedback modulation does not need to be temporally or spatially precise and can be realised by feedback-driven gain modulation in rate-based networks of excitatory and inhibitory neurons. To solve the task, the feedback loop dynamically maintains an invariant subspace in the population representation (<xref ref-type="bibr" rid="bib35">Hong et al., 2016</xref>). This invariance is not present at the single-neuron level. Finally, we find that the feedback conveys a nonlinear representation of the context itself, which can be hard to discern by linear decoding methods.</p><p>These findings corroborate that feedback-driven gain modulation of feedforward networks enables context-invariant sensory processing. The underlying mechanism links single-neuron modulation with its function at the population level, highlighting the importance of population-level analyses.</p></sec><sec id="s2" sec-type="results"><title>Results</title><p>As a simple instance of a context-invariant task, we considered a dynamic version of the blind source separation problem. The task is to recover unknown sensory sources, such as voices at a cocktail party (<xref ref-type="bibr" rid="bib56">McDermott, 2009</xref>), from sensory stimuli that are an unknown mixture of the sources. In contrast to the classical blind source separation problem, the mixture can change in time, for example, when the speakers move around, thus providing a time-varying sensory context. Because the task requires a dynamic inference of the context, it cannot be solved by feedforward networks (<xref ref-type="fig" rid="fig1s1">Figure 1âfigure supplement 1</xref>) or standard blind source separation algorithms (e.g. independent component analysis; <xref ref-type="bibr" rid="bib6">Bell and Sejnowski, 1995</xref>; <xref ref-type="bibr" rid="bib37">HyvÃ¤rinen and Oja, 2000</xref>). We hypothesised that this dynamic task can be solved by a feedforward network that is subject to modulation from a feedback signal. In our model, the feedback signal is provided by a modulatory system that receives both sensory stimuli and network output (<xref ref-type="fig" rid="fig1">Figure 1a</xref>).</p><fig-group><fig id="fig1" position="float"><label>Figure 1.</label><caption><title>Dynamic blind source separation by modulation of feedforward connections.</title><p>(<bold>a</bold>) Schematic of the feedforward network model receiving feedback modulation from a modulator (a recurrent network). (<bold>b</bold>) Top: sources (<inline-formula><mml:math id="inf1"><mml:msub><mml:mi>s</mml:mi><mml:mrow><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mn>2</mml:mn></mml:mrow></mml:msub></mml:math></inline-formula>), sensory stimuli (<inline-formula><mml:math id="inf2"><mml:msub><mml:mi>x</mml:mi><mml:mrow><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mn>2</mml:mn></mml:mrow></mml:msub></mml:math></inline-formula>), and network output (<inline-formula><mml:math id="inf3"><mml:msub><mml:mi>y</mml:mi><mml:mrow><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mn>2</mml:mn></mml:mrow></mml:msub></mml:math></inline-formula>) for two different source locations (contexts). Bottom: deviation of output from the sources. (<bold>c</bold>) Top: modulated readout weights across six contexts (source locations); dotted lines indicate the true weights of the inverted mixing matrix. Bottom: deviation of readout from target weights. (<bold>d</bold>) Correlation between the sources and the sensory stimuli (left), the network outputs (centre), and calculation of the <italic>signal clarity</italic> (right). Error bars indicate standard deviation across 20 contexts. (<bold>e</bold>) Violin plot of the signal clarity for different noise levels in the sensory stimuli across 20 different contexts.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-76096-fig1-v2.tif"/></fig><fig id="fig1s1" position="float" specific-use="child-fig"><label>Figure 1âfigure supplement 1.</label><caption><title>The dynamic blind source separation task cannot be solved with a feedforward network unless the network receives a sequence of inputs at once. This would require an additional mechanism to retain information over time.</title><p>(<bold>a</bold>) Schematic of a feedforward network consisting of a linear readout only. (<bold>b</bold>) Pairwise signal clarity of one context when the network is trained on another context. (<bold>c</bold>) Correlation between the distance between two contexts and their pairwise signal clarity (see (<bold>b</bold>)). (<bold>d</bold>) Schematic of a multilayer feedforward network with three hidden layers (32, 16, and 8 rectified linear units). (<bold>e</bold>) Loss during training for the network in (<bold>d</bold>), measured by the mean squared error between the output and the sources. (<bold>f</bold>) Network performance after training. Left: correlation of the outputs with the sources over 20 contexts. Error bars indicate standard deviation. Right: signal clarity across 20 contexts for the trained network. (<bold>g</bold>) Schematic of network architecture and training setup when using a sequence of <italic>n</italic><sub><italic>t</italic></sub> samples as input to the multilayer network. (<bold>h</bold>) Same as (<bold>e</bold>) but for different number of samples. Colour code corresponds to (<bold>i</bold>). (<bold>i</bold>) Signal clarity for trained networks that receive different numbers of samples as input.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-76096-fig1-figsupp1-v2.tif"/></fig><fig id="fig1s2" position="float" specific-use="child-fig"><label>Figure 1âfigure supplement 2.</label><caption><title>Robustness of the feedback-driven modulation mechanism.</title><p>(<bold>a</bold>) Loss over training for five different random initialisations of the model and (<bold>b</bold>) signal clarity for 20 test contexts in the corresponding trained networks. The model performance is robust across model instantiations. (<bold>c</bold>) Samples from the two default signals are uncorrelated. (<bold>d</bold>) Signal clarity for different lengths of the context during testing. The length of the context interval is not crucial for performance, indicating that the network did not learn the interval by heart. (<bold>e</bold>) Example traces of the sensory stimuli for different signal-to-noise ratios.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-76096-fig1-figsupp2-v2.tif"/></fig><fig id="fig1s3" position="float" specific-use="child-fig"><label>Figure 1âfigure supplement 3.</label><caption><title>Model performance for two different sets of source signals.</title><p>Left: compositions of sines with <inline-formula><mml:math id="inf4"><mml:mrow><mml:msub><mml:mi>f</mml:mi><mml:mn>11</mml:mn></mml:msub><mml:mo>=</mml:mo><mml:mn>120</mml:mn></mml:mrow></mml:math></inline-formula> Hz, <inline-formula><mml:math id="inf5"><mml:mrow><mml:msub><mml:mi>f</mml:mi><mml:mn>12</mml:mn></mml:msub><mml:mo>=</mml:mo><mml:mn>2.2</mml:mn></mml:mrow></mml:math></inline-formula> Hz, <inline-formula><mml:math id="inf6"><mml:mrow><mml:msub><mml:mi>f</mml:mi><mml:mn>21</mml:mn></mml:msub><mml:mo>=</mml:mo><mml:mn>100</mml:mn></mml:mrow></mml:math></inline-formula> Hz, and <inline-formula><mml:math id="inf7"><mml:mrow><mml:msub><mml:mi>f</mml:mi><mml:mn>22</mml:mn></mml:msub><mml:mo>=</mml:mo><mml:mn>145</mml:mn></mml:mrow></mml:math></inline-formula> Hz. Right: sawtooth function with frequency 140 Hz and composed sine of 150 Hz and 210 Hz. (<bold>a<sub>1/2</sub></bold>) Loss over training. (<bold>b<sub>1/2</sub></bold>) Signal clarity for 20 test contexts measured in the sensory stimuli and the network output. (<bold>c<sub>1/2</sub></bold>) Example traces of the sources and the network output (top) and corresponding deviation between them (bottom). The context changes at time 0. (<bold>d<sub>1/2</sub></bold>) Top: readout weights across six contexts; dotted lines indicate the optimal weights. Bottom: deviation of readout from the optimal weights.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-76096-fig1-figsupp3-v2.tif"/></fig><fig id="fig1s4" position="float" specific-use="child-fig"><label>Figure 1âfigure supplement 4.</label><caption><title>Model performance for three source signals.</title><p>(<bold>a</bold>) Loss over training. (<bold>b</bold>) Correlation of the sources with the mixed sensory stimuli (left) and with the network outputs (right). (<bold>c</bold>) Example traces of the three source signals and network outputs (top) and corresponding deviation between them (bottom). The context changes at time 0. The source signals are a sawtooth of frequency 140 Hz, a sine wave of frequency 120 Hz, and a square wave signal of 80 Hz. (<bold>d</bold>) Top: readout weights across six contexts. Bottom: deviation of readout from the optimal weights.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-76096-fig1-figsupp4-v2.tif"/></fig><fig id="fig1s5" position="float" specific-use="child-fig"><label>Figure 1âfigure supplement 5.</label><caption><title>The modulated network model generalises across frequencies.</title><p>(<bold>a</bold>) Illustration of the source signals used during training (solid lines) and only during testing (dotted lines). During the training, the model experiences only a subset of potential signals. (<bold>b</bold>) Signal clarity for different combinations of test frequencies. Combinations used during training are marked with a pink cross.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-76096-fig1-figsupp5-v2.tif"/></fig><fig id="fig1s6" position="float" specific-use="child-fig"><label>Figure 1âfigure supplement 6.</label><caption><title>The modulator learns a model of the sources and contexts, and infers the current context from the stimuli. Testing the network on sources and contexts with different statistics than during training thus impairs its performance.</title><p>(<bold>a</bold>) Deviation of network output from sources within contexts. Average across contexts shown in dark red. (<bold>b</bold>) Signal clarity for different test cases: same sources and same context statistics as during training (âcontrolâ), new sources (ânew srcâ), same sources but different context statistic (i.e. unnormed mixing matrices, ânew ctxâ), and different context statistics but when training the network on them (âunnorm ctxâ). (<bold>c</bold>) Top: sources (<inline-formula><mml:math id="inf8"><mml:msub><mml:mi>s</mml:mi><mml:mrow><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mn>2</mml:mn></mml:mrow></mml:msub></mml:math></inline-formula>) and network output (<inline-formula><mml:math id="inf9"><mml:msub><mml:mi>y</mml:mi><mml:mrow><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mn>2</mml:mn></mml:mrow></mml:msub></mml:math></inline-formula>) for a context when testing on new sources. Bottom: deviation of outputs from the sources. (<bold>d</bold>) Top: modulated readout weights across six contexts when testing on new sources; dotted lines indicate the inverse of the current mixing. Bottom: deviation of readout from target weights.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-76096-fig1-figsupp6-v2.tif"/></fig></fig-group><sec id="s2-1"><title>Dynamic blind source separation by modulation of feedforward weights</title><p>Before we gradually take this to the neural level, we illustrate the proposed mechanism in a simple example, in which the modulatory system provides a time-varying multiplicative modulation of a linear two-layer network (see âMaterials and methodsâ). For illustration, we used compositions of sines with different frequencies as source signals (<inline-formula><mml:math id="inf10"><mml:mi>s</mml:mi></mml:math></inline-formula>, <xref ref-type="fig" rid="fig1">Figure 1b</xref>, top). These sources were linearly mixed to generate the sensory stimuli (<inline-formula><mml:math id="inf11"><mml:mi>x</mml:mi></mml:math></inline-formula>) that the network received as input; <inline-formula><mml:math id="inf12"><mml:mrow><mml:mi>x</mml:mi><mml:mo>=</mml:mo><mml:mrow><mml:mpadded width="+2.8pt"><mml:msub><mml:mi>A</mml:mi><mml:mi>t</mml:mi></mml:msub></mml:mpadded><mml:mo>â¢</mml:mo><mml:mi>s</mml:mi></mml:mrow></mml:mrow></mml:math></inline-formula> (<xref ref-type="fig" rid="fig1">Figure 1a and b</xref>). The linear mixture (<inline-formula><mml:math id="inf13"><mml:msub><mml:mi>A</mml:mi><mml:mi>t</mml:mi></mml:msub></mml:math></inline-formula>) changed over time, akin to varying the location of sound sources in a room (<xref ref-type="fig" rid="fig1">Figure 1a</xref>). These locations provided a time-varying sensory context that changed on a slower timescale than the sources themselves. The feedforward network had to recover the sources from the mixed sensory stimuli. To achieve this, we trained the modulator to dynamically adjust the weights of the feedforward network (<italic>W</italic><sub>0</sub>) such that the network output (<inline-formula><mml:math id="inf14"><mml:mi>y</mml:mi></mml:math></inline-formula>) matches the sources:<disp-formula id="equ1"><mml:math id="m1"><mml:mrow><mml:mi>y</mml:mi><mml:mo>=</mml:mo><mml:msub><mml:mi>W</mml:mi><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mspace width="thickmathspace"/><mml:mi>x</mml:mi><mml:mo>=</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>M</mml:mi><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>â</mml:mo><mml:msub><mml:mi>W</mml:mi><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:mspace width="thickmathspace"/><mml:mi>x</mml:mi></mml:mrow></mml:math></disp-formula><disp-formula id="equ2"><mml:math id="m2"><mml:mrow><mml:msub><mml:mi>M</mml:mi><mml:mi>t</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mtext>modulator</mml:mtext><mml:mo stretchy="false">(</mml:mo><mml:mtext>history ofÂ </mml:mtext><mml:mi>x</mml:mi><mml:mo>,</mml:mo><mml:mi>y</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mspace width="thickmathspace"/><mml:mo>.</mml:mo></mml:mrow></mml:math></disp-formula></p><p>Because the modulation requires a dynamic inference of the context, the modulator is a recurrent neural network. The modulator was trained using supervised learning. Afterwards, its weights were fixed and it no longer had access to the target sources (see âMaterials and methods,â Figure 8). The modulator therefore had to use its recurrent dynamics to determine the appropriate modulatory feedback for the time-varying context, based on the sensory stimuli and the network output. Put differently, the modulator had to learn an internal model of the sensory data and the contexts, and use it to establish the desired context invariance in the output.</p><p>After learning, the modulated network disentangled the sources, even when the context changed (<xref ref-type="fig" rid="fig1">Figure 1b</xref>, <xref ref-type="fig" rid="fig1s1">Figure 1âfigure supplement 1a and b</xref>). Context changes produced a transient error in the networkâs output, but it quickly resumed matching the sources (<xref ref-type="fig" rid="fig1">Figure 1b</xref>, bottom). The transient errors occur because the modulator needs time to infer the new context from the time-varying inputs before it can provide the appropriate feedback signal to the feedforward network (<xref ref-type="fig" rid="fig1s6">Figure 1âfigure supplement 6a</xref>, compare with <xref ref-type="fig" rid="fig1s1">Figure 1âfigure supplement 1gâi</xref>). The modulated feedforward weights inverted the linear mixture of sources by switching on the same timescale (<xref ref-type="fig" rid="fig1">Figure 1c</xref>).</p><p>To quantify how well the sources were separated, we measured the correlation coefficient of the outputs with each source over several contexts. Consistent with a clean separation, we found that each of the two outputs strongly correlated with only one of the sources. In contrast, the sensory stimuli showed a positive average correlation for both sources as expected given the positive linear mixture (<xref ref-type="fig" rid="fig1">Figure 1d</xref>, left). We determined the <italic>signal clarity</italic> as the absolute difference between the correlation with the first compared to the second source, averaged over the two outputs, normalised by the sum of the correlations (<xref ref-type="fig" rid="fig1">Figure 1d</xref>, right; see âMaterials and methodsâ). The signal clarity thus determines the degree of signal separation, where a value close to 1 indicates a clean separation as in <xref ref-type="fig" rid="fig1">Figure 1d</xref>. Note that the signal clarity of the sensory stimuli is around 0.5 and can be used as a reference.</p><p>We next probed the networkâs robustness by adding noise to the sensory stimuli. We found that the signal clarity gradually decreased with increasing noise levels, but only degraded to chance performance when the signal-to-noise ratio was close to 1 (1.1 dB, <xref ref-type="fig" rid="fig1">Figure 1e</xref>, <xref ref-type="fig" rid="fig1s2">Figure 1âfigure supplement 2e</xref>). The network performance did not depend on the specific source signals (<xref ref-type="fig" rid="fig1s3">Figure 1âfigure supplement 3</xref>) or the number of sources (<xref ref-type="fig" rid="fig1s4">Figure 1âfigure supplement 4</xref>) as long as it had seen them during training. Yet, because the network had to learn an internal model of the task, we expected a limited degree of generalisation to new situations. Indeed, the network was able to interpolate between source frequencies seen during training (<xref ref-type="fig" rid="fig1s5">Figure 1âfigure supplement 5</xref>), but failed on sources and contexts that were qualitatively different (<xref ref-type="fig" rid="fig1s6">Figure 1âfigure supplement 6bâd</xref>). The specific computations performed by the modulator are therefore idiosyncratic to the problem at hand. Hence, we did not investigate the internal dynamics of the modulator in detail, but concentrated on its effect on the feedforward network.</p><p>Since feedback-driven modulation enables flexible context-invariant processing in a simple abstract model, we wondered how this mechanism might be implemented at the neural level. For example, how does feedback-driven modulation function when feedback signals are slow and imprecise? And how does the modulation affect population activity? In the following, we will gradually increase the model complexity to account for biological constraints and pinpoint the population-level mechanisms of feedback-mediated invariance.</p></sec><sec id="s2-2"><title>Invariance can be established by slow feedback modulation</title><p>Among the many modulatory mechanisms, even the faster ones are believed to operate on timescales of hundreds of milliseconds (<xref ref-type="bibr" rid="bib4">Bang et al., 2020</xref>; <xref ref-type="bibr" rid="bib58">Molyneaux and Hasselmo, 2002</xref>), raising the question if feedback-driven modulation is sufficiently fast to compensate for dynamic changes in environmental context.</p><p>To investigate how the timescale of modulation affects the performance in the dynamic blind source separation task, we trained network models, in which the modulatory feedback had an intrinsic timescale that forced it to be slow. We found that the signal clarity degraded only when this timescale was on the same order of magnitude as the timescale of contextual changes (<xref ref-type="fig" rid="fig2">Figure 2a</xref>). Note that timescales in this model are relative and could be arbitrarily rescaled. While slower feedback modulation produced a larger initial error (<xref ref-type="fig" rid="fig2">Figure 2b and c</xref>), it also reduced the fluctuations in the readout weights such that they more closely follow the optimal weights (<xref ref-type="fig" rid="fig2">Figure 2b</xref>). This speed-accuracy trade-off explains the lower and more variable signal clarity for slow modulation (<xref ref-type="fig" rid="fig2">Figure 2a</xref>) because the signal clarity was measured over the whole duration of a context and the transient onset error dominated over the reduced fluctuations.</p><fig-group><fig id="fig2" position="float"><label>Figure 2.</label><caption><title>The network model is not sensitive to slow feedback modulation.</title><p>(<bold>a</bold>) Signal clarity in the network output for varying timescales of modulation relative to the intervals at which the source locations change. (<bold>b</bold>) Modulated readout weights across four source locations (contexts) for fast (top) and slow (centre) feedback modulation; dotted lines indicate the optimal weights (the inverse of the mixing matrix). Bottom: deviation of the readout weights from the optimal weights for fast and slow modulation. Colours correspond to the relative timescales in (<bold>a</bold>). Fast and slow timescales are 0.001 and 1, respectively. (<bold>c</bold>) Mean deviation of readout from optimal weights within contexts; averaged over 20 contexts. Colours code for timescale of modulation (see (<bold>a</bold>)). (<bold>d</bold>, <bold>e</bold>) Same as (<bold>a</bold>) but for models in which the modulatory system only received the sensory stimuli <inline-formula><mml:math id="inf15"><mml:mi>x</mml:mi></mml:math></inline-formula> or the network output <inline-formula><mml:math id="inf16"><mml:mi>y</mml:mi></mml:math></inline-formula>, respectively.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-76096-fig2-v2.tif"/></fig><fig id="fig2s1" position="float" specific-use="child-fig"><label>Figure 2âfigure supplement 1.</label><caption><title>Robustness to slow feedback modulation depends on the inputs to the modulatory system.</title><p>(<bold>a</bold>) Illustration of different input configurations: the modulatory system receives only the sensory stimuli as feedforward input (left), only the network output as feedback input (right), or both (right). (<bold>b</bold>) Loss over training for different timescales. Colours correspond to values shown in (<bold>d </bold>). (<bold>c</bold>) Deviation of the readout weights from the optimal weights over the duration of a context for different modulation timescales, averaged across 20 contexts. Colours correspond to values shown in (<bold>d</bold>). (<bold>d</bold>) Signal clarity for different timescales of the modulatory feedback signal.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-76096-fig2-figsupp1-v2.tif"/></fig></fig-group><p>To determine architectural constraints on the modulatory system, we asked how these results depended on the input it received. So far, the modulatory system received the feedforward networkâs inputs (the sensory stimuli) and its outputs (the inferred sources, see <xref ref-type="fig" rid="fig1">Figure 1a</xref>), but are both of these necessary to solve the task? We found that when the modulatory system only received the sensory stimuli, the model could still learn the task, though it was more sensitive to slow modulation (<xref ref-type="fig" rid="fig2">Figure 2d</xref>, <xref ref-type="fig" rid="fig2s1">Figure 2âfigure supplement 1</xref>). When the modulatory system had to rely on the network output alone, task performance was impaired even for fast modulation (<xref ref-type="fig" rid="fig2">Figure 2e</xref>, <xref ref-type="fig" rid="fig2s1">Figure 2âfigure supplement 1</xref>). Thus, while the modulatory system is more robust to slow modulation when it receives the network output, the output is not sufficient to solve the task.</p><p>Taken together, these results show that the biological timescale of modulatory mechanisms does not pose a problem for flexible feedback-driven processing as long as the feedback modulation changes on a faster timescale than variations in the context. In fact, slow modulation can increase processing accuracy by averaging out fluctuations in the feedback signal. Nevertheless, slow modulation likely requires the modulatory system to receive both input and output of the sensory system it modulates.</p></sec><sec id="s2-3"><title>Invariance can be established by spatially diffuse feedback modulation</title><p>Neuromodulators are classically believed to diffusely affect large areas of the brain. Furthermore, signals in the brain are processed by populations of neurons. We wondered if the proposed modulation mechanism is consistent with such biological constraints. We therefore extended the network model such that the sensory stimuli are projected to a population of 100 neurons. A fixed linear readout of this population determined the network output. The neurons in the population received spatially diffuse modulatory feedback (<xref ref-type="fig" rid="fig3">Figure 3a</xref>) such that the feedback modulation affected neighbouring neurons similarly. We here assume that all synaptic weights to a neuron receive the same modulation, such that the feedback performs a gain modulation of neural activity (<xref ref-type="bibr" rid="bib24">Ferguson and Cardin, 2020</xref>). The spatial specificity of the modulation was determined by the number of distinct feedback signals and their spatial spread (<xref ref-type="fig" rid="fig3">Figure 3b</xref>, <xref ref-type="fig" rid="fig3s1">Figure 3âfigure supplement 1a</xref>).</p><fig-group><fig id="fig3" position="float"><label>Figure 3.</label><caption><title>Feedback modulation in the model can be spatially diffuse.</title><p>(<bold>a</bold>) Schematic of the feedforward network with a population that receives diffuse feedback-driven modulation. (<bold>b</bold>) Spatial spread of the modulation mediated by four modulatory feedback signals with a width of 0.2. (<bold>c</bold>) Top: per neuron modulation during eight different contexts. Bottom: corresponding deviation of the network output from sources. (<bold>d</bold>) Mean signal clarity across 20 contexts for different numbers of feedback signals; modulation width is 0.2. Error bars indicate standard deviation. Purple triangle indicates default parameters used in (<bold>c</bold>). (<bold>e</bold>) Same as (<bold>d</bold>) but for different modulation widths; number of feedback signals is 4. The modulation width â<inline-formula><mml:math id="inf17"><mml:mi mathvariant="normal">â</mml:mi></mml:math></inline-formula>â corresponds to uniform modulation across the population.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-76096-fig3-v2.tif"/></fig><fig id="fig3s1" position="float" specific-use="child-fig"><label>Figure 3âfigure supplement 1.</label><caption><title>Robustness to the spatial scale of feedback modulation.</title><p>(<bold>a</bold>) Examples of the spatial extent of feedback modulation for different numbers of feedback signals (# FB) and spatial spread (<inline-formula><mml:math id="inf18"><mml:msubsup><mml:mi>Ï</mml:mi><mml:mi>m</mml:mi><mml:mn>2</mml:mn></mml:msubsup></mml:math></inline-formula>). (<bold>b</bold>) Signal clarity and (<bold>c</bold>) final log loss in network models with different parameters determining the spatial scale of feedback modulation. Signal clarity was averaged across 20 contexts. Final loss was averaged across the last 200 batches during training. The purple star indicates default values used in the main results. Modulation width of â<inline-formula><mml:math id="inf19"><mml:mi mathvariant="normal">â</mml:mi></mml:math></inline-formula>â corresponds to a homogeneous modulation over the whole population. (<bold>d</bold>) Top: effective weights from stimuli to network output over eight contexts. Effective weights are computed as the modulated weights from stimuli to neural population, multiplied with the readout weights. Dotted lines indicate inverse of mixing. Bottom: deviation of effective weights from the inverse.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-76096-fig3-figsupp1-v2.tif"/></fig></fig-group><p>This population-based model with less specific feedback modulation could still solve the dynamic blind source separation task. The diffuse feedback modulation switched when the context changed, but was roughly constant within contexts (<xref ref-type="fig" rid="fig3">Figure 3c</xref>), as in the simple model. The effective weight from the stimuli to the network output also inverted the linear mixture of the sources (<xref ref-type="fig" rid="fig3s1">Figure 3âfigure supplement 1d</xref>, compare with <xref ref-type="fig" rid="fig1">Figure 1c</xref>).</p><p>We found that only a few distinct feedback signals were needed for a clean separation of the sources across contexts (<xref ref-type="fig" rid="fig3">Figure 3d</xref>). Moreover, the feedback could have a spatially broad effect on the modulated population without degrading the signal clarity (<xref ref-type="fig" rid="fig3">Figure 3e</xref>, <xref ref-type="fig" rid="fig3s1">Figure 3âfigure supplement 1</xref>), consistent with the low dimensionality of the context.</p><p>We conclude that, in our model, neuromodulation does not need to be spatially precise to enable flexible processing. Given that the suggested feedback-driven modulation mechanism works for slow and diffuse feedback signals, it could in principle be realised by neuromodulatory pathways present in the brain.</p></sec><sec id="s2-4"><title>Invariance emerges at the population level</title><p>Having established that slow and spatially diffuse feedback modulation enables context-invariant processing, we next investigated the underlying mechanisms at the single-neuron and population level. Given that the readout of the population activity was fixed, it is not clear how the context-dependent modulation of single neurons could give rise to a context-independent network output. One possible explanation is that some of the neurons are context-invariant and are exploited by the readout. However, a first inspection of neural activity indicated that single neurons are strongly modulated by context (<xref ref-type="fig" rid="fig4">Figure 4a</xref>). To quantify this, we determined the signal clarity for each neuron at each stage of the feedforward network, averaged across contexts (<xref ref-type="fig" rid="fig4">Figure 4b</xref>). As expected, the signal clarity was low for the sensory stimuli. Intriguingly, the same was true for all neurons of the modulated neural population, indicating no clean separation of the sources at the level of single neurons. Although most neurons had a high signal clarity in some of the contexts, there was no group of neurons that consistently represented one or the other source (<xref ref-type="fig" rid="fig4">Figure 4c</xref>). Furthermore, the average signal clarity of the neurons did not correlate with their contribution to the readout (<xref ref-type="fig" rid="fig4">Figure 4d</xref>). Since single-neuron responses were not invariant, context invariance must arise at the population level.</p><fig id="fig4" position="float"><label>Figure 4.</label><caption><title>Invariance emerges at the population level.</title><p>(<bold>a</bold>) Population activity in two contexts. (<bold>b</bold>) Violin plot of the signal clarity in the sensory stimuli (<inline-formula><mml:math id="inf20"><mml:mi>x</mml:mi></mml:math></inline-formula>), neural population (<inline-formula><mml:math id="inf21"><mml:mi>z</mml:mi></mml:math></inline-formula>), and network output (<inline-formula><mml:math id="inf22"><mml:mi>y</mml:mi></mml:math></inline-formula>), computed across 20 different contexts. (<bold>c</bold>) Signal clarity of single neurons in the modulated population for different contexts. (<bold>d</bold>) Correlation between average signal clarity over contexts and magnitude of neuronsâ readout weight. Corresponding Pearson <inline-formula><mml:math id="inf23"><mml:mi>r</mml:mi></mml:math></inline-formula> and <inline-formula><mml:math id="inf24"><mml:mi>p</mml:mi></mml:math></inline-formula>-value are indicated in the panel. (<bold>e</bold>) Violin plot of the linear decoding performance of the sources from different stages of the feedforward network, computed across 20 contexts. The decoder was trained on a different set of 20 contexts.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-76096-fig4-v2.tif"/></fig><p>To confirm this, we asked how well the sources could be decoded at different stages of the feedforward network. We trained a single linear decoder of the sources on one set of contexts and tested its generalisation to novel contexts. We found that the decoding performance was poor for the sensory stimuli (<xref ref-type="fig" rid="fig4">Figure 4e</xref>), indicating that these did not contain a context-invariant representation. In contrast, the sources could be decoded with high accuracy from the modulated population.</p><p>This demonstrates that while individual neurons were not invariant, the population activity contained a context-invariant subspace. In fact, the population had to contain an invariant subspace because the fixed linear readout of the population was able to extract the sources across contexts. However, the linear decoding approach shows that this subspace can be revealed from the population activity itself with only a few contexts and no knowledge of how the neural representation is used downstream. The same approach could therefore be used to reveal context-invariant subspaces in neural data from population recordings. Note that the learned readout and the decoder obtained from population activity are not necessarily identical due to the high dimensionality of the population activity compared to the sources.</p></sec><sec id="s2-5"><title>Feedback reorients the population representation</title><p>The question remains how exactly the context-invariant subspace is maintained by feedback modulation. In contrast to a pure feedforward model of invariant perception (<xref ref-type="bibr" rid="bib45">Kriegeskorte, 2015</xref>; <xref ref-type="bibr" rid="bib97">Yamins and DiCarlo, 2016</xref>), feedback-mediated invariance requires time to establish after contextual changes. Experimentally, hallmarks of this adaptive process should be visible when comparing the population representations immediately after a change and at a later point in time. Our model allows to cleanly separate the early and late representation by freezing the feedback signals in the initial period after a contextual change (<xref ref-type="fig" rid="fig5">Figure 5a</xref>), thereby disentangling the effects of feedback and context on population activity.</p><fig-group><fig id="fig5" position="float"><label>Figure 5.</label><caption><title>Feedback reorients the population representation.</title><p>(<bold>a</bold>) Network output (top) and feedback modulation (bottom) for two contexts. The feedback modulation is frozen for the initial period after the context changes. (<bold>b</bold>) Population activity in the space of the two readout axes and the first principal component. Projection onto the readout is indicated at the bottom (see (<bold>c</bold>)). The signal representation is shown for different phases of the experiment. Left: context 1 with intact feedback; centre: context 2 with frozen feedback; right: context 2 with intact feedback. The blue plane spans the population activity subspace in context 1 (left). (<bold>c</bold>) Same as (<bold>b</bold>), but projected onto the readout space (dotted lines in (<bold>b</bold>)). The light blue trace corresponds to the sources. (<bold>d</bold>) Left: change in subspace orientation across 40 repetitions of the experiment, measured by the angle between the original subspace and the subspace for context changes (ctx change), feedback modulation (FB mod), and feedback modulation for similar contexts (ctx close) or dissimilar contexts (ctx far). Right: two-dimensional context space, defined by the coefficients in the mixing matrix. Arrows indicate similar (light blue) and dissimilar contexts (purple). (<bold>e</bold>) Distance between pairs of contexts versus the angle between population activity subspaces for these contexts. Circles indicate similar contexts (from the same side of the diagonal, see (<bold>d</bold>)) and triangles dissimilar contexts (from different sides of the diagonal). Pearson <inline-formula><mml:math id="inf25"><mml:mi>r</mml:mi></mml:math></inline-formula> and <inline-formula><mml:math id="inf26"><mml:mi>p</mml:mi></mml:math></inline-formula>-value indicated in the panel.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-76096-fig5-v2.tif"/></fig><fig id="fig5s1" position="float" specific-use="child-fig"><label>Figure 5âfigure supplement 1.</label><caption><title>Principal component (PC) analysis captures the low-dimensional population subspaces and the subspace reorientation with feedback.</title><p>(<bold>a</bold>) Fraction of variance explained by principal component analyses on single contexts (coloured lines) and across all contexts (black line). (<bold>b</bold>) Population activity in the space of the first three PCs for five contexts. Colour indicates the location of the contexts in context space as shown in (<bold>c</bold>). (<bold>d</bold>) Violin plot of the angle change between original subspace and the subspace for context changes (ctx change) and feedback modulation (FB mod). (<bold>e</bold>) Population activity in the space of the first three PCs in different stages of the experiment. Left: context 1 with intact feedback; centre: context 2 with frozen feedback; right: context 2 with intact feedback. Black lines indicate the readout vectors. (<bold>f</bold>) Same as (<bold>e</bold>) but from a different viewpoint to show the readout space.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-76096-fig5-figsupp1-v2.tif"/></fig></fig-group><p>The simulated experiment consisted of three stages: first, the feedback was intact for a particular context and the network outputs closely tracked the sources. Second, the context was changed but the feedback modulation was frozen at the same value as before. As expected, this produced deviations of the output from the sources. Third, for the same context the feedback modulation was turned back on, which reinstated the source signals in the output. In this experiment, we used pure sines as signals for visualisation purposes (<xref ref-type="fig" rid="fig5">Figure 5a and c</xref>). To visualise the population activity in the three stages of the experiment, we considered the space of the two readout dimensions and the first principal component (<xref ref-type="fig" rid="fig5">Figure 5b</xref>). We chose this space rather than, for example, the first three principal components (<xref ref-type="fig" rid="fig5s1">Figure 5âfigure supplement 1</xref>), because it provides an intuitive illustration of the invariant subspace.</p><p>Because the sources were two-dimensional, the population activity followed a pattern within a two-dimensional subspace (<xref ref-type="fig" rid="fig5">Figure 5b</xref>, left; <xref ref-type="fig" rid="fig5s1">Figure 5âfigure supplement 1a</xref>). For intact feedback, this population activity matched the sources when projected onto the readout (<xref ref-type="fig" rid="fig5">Figure 5c</xref>, left). Changing the context while freezing the feedback rotated and stretched this representation within the same subspace, such that the readout did not match the sources (<xref ref-type="fig" rid="fig5">Figure 5b and c</xref>, centre). Would turning the feedback modulation back on simply reverse this transformation to re-establish an invariant subspace? We found that this was not the case. Instead, the feedback rotated the representation out of the old subspace (<xref ref-type="fig" rid="fig5">Figure 5b</xref>, right), thereby reorienting it into the invariant readout (<xref ref-type="fig" rid="fig5">Figure 5c</xref>, right).</p><p>To quantify the transformation of the population representation, we repeated this experiment multiple times and determined the angle between the neural subspaces. Consistent with the illustration in <xref ref-type="fig" rid="fig5">Figure 5b</xref>, changing the context did not change the subspace orientation, whereas unfreezing the feedback caused a consistent reorientation (<xref ref-type="fig" rid="fig5">Figure 5d</xref>). The magnitude of this subspace reorientation depended on the similarity of the old and new context. Similar contexts generally evoked population activity with similar subspace orientations (<xref ref-type="fig" rid="fig5">Figure 5d and e</xref>). This highlights that there is a consistent mapping between contexts and the resulting low-dimensional population activity.</p><p>In summary, the role of feedback-driven modulation in our model is to reorient the population representation in response to changing contexts such that an invariant subspace is preserved.</p></sec><sec id="s2-6"><title>The mechanism generalises to a hierarchical Dalean network</title><p>So far, we considered a linear network, in which neural activity could be positive and negative. Moreover, feedback modulation could switch the sign of the neuronsâ downstream influence, which is inconsistent with Daleâs principle. We wondered if the same population-level mechanisms would operate in a Dalean network, in which feedback is implemented as a positive gain modulation. Although gain modulation is a broadly observed phenomenon that is attributed to a range of cellular mechanisms (<xref ref-type="bibr" rid="bib24">Ferguson and Cardin, 2020</xref>; <xref ref-type="bibr" rid="bib79">Salinas and Thier, 2000</xref>), its effect at the population level is less clear (<xref ref-type="bibr" rid="bib84">Shine et al., 2021</xref>).</p><p>We extended the feedforward model as follows (<xref ref-type="fig" rid="fig6">Figure 6a</xref>): first, all neurons had positive firing rates. Second, we split the neural population (<inline-formula><mml:math id="inf27"><mml:mi>z</mml:mi></mml:math></inline-formula> in the previous model) into a âlower-levelâ (<inline-formula><mml:math id="inf28"><mml:msup><mml:mi>z</mml:mi><mml:mi mathvariant="normal">L</mml:mi></mml:msup></mml:math></inline-formula>) and âhigher-levelâ population (<inline-formula><mml:math id="inf29"><mml:msup><mml:mi>z</mml:mi><mml:mi mathvariant="normal">H</mml:mi></mml:msup></mml:math></inline-formula>). The lower-level population served as a neural representation of the sensory stimuli, whereas the higher-level population was modulated by feedback. This allowed a direct comparison between a modulated and an unmodulated neural population. It also allowed us to include Dalean weights between the two populations. Direct projections from the lower-level to the higher-level population were excitatory. In addition, a small population of local inhibitory neurons provided feedforward inhibition to the higher-level population. Third, the modulation of the higher-level population was implemented as a local gain modulation that scaled the neural responses. As a specific realisation of gain modulation, we assumed that feedback targeted inhibitory interneurons (e.g. in layer 1; <xref ref-type="bibr" rid="bib1">Abs et al., 2018</xref>; <xref ref-type="bibr" rid="bib24">Ferguson and Cardin, 2020</xref>; <xref ref-type="bibr" rid="bib15">Cohen-Kashi Malina et al., 2021</xref>) that mediate the modulation in the higher-level population (e.g. via presynaptic inhibition; <xref ref-type="bibr" rid="bib65">Pardi et al., 2020</xref>; <xref ref-type="bibr" rid="bib59">Naumann and Sprekeler, 2020</xref>). This means that stronger feedback decreased the gain of neurons (<xref ref-type="fig" rid="fig4">Figure 4b</xref>). We will refer to these modulatory interneurons as modulation units <inline-formula><mml:math id="inf30"><mml:mi>m</mml:mi></mml:math></inline-formula> (green units in <xref ref-type="fig" rid="fig4">Figure 4a</xref>).</p><fig-group><fig id="fig6" position="float"><label>Figure 6.</label><caption><title>Feedback-driven gain modulation in a hierarchical rate network.</title><p>(<bold>a</bold>) Schematic of the Dalean network comprising a lower- and higher-level population (<inline-formula><mml:math id="inf31"><mml:msup><mml:mi>z</mml:mi><mml:mi mathvariant="normal">L</mml:mi></mml:msup></mml:math></inline-formula> and <inline-formula><mml:math id="inf32"><mml:msup><mml:mi>z</mml:mi><mml:mi mathvariant="normal">H</mml:mi></mml:msup></mml:math></inline-formula>), a population of local inhibitory neurons (blue), and diffuse gain modulation mediated by modulatory interneurons (green). (<bold>b</bold>) Decrease in gain (i.e. release probability) with stronger modulatory feedback. (<bold>c</bold>) Top: modulation of neurons in the higher-level population for 10 different contexts. Bottom: corresponding deviation of outputs <inline-formula><mml:math id="inf33"><mml:mi>y</mml:mi></mml:math></inline-formula> from sources <inline-formula><mml:math id="inf34"><mml:mi>s</mml:mi></mml:math></inline-formula>. (<bold>d</bold>) Histogram of neuron-specific release probabilities averaged across 20 contexts (filled, light green) and during two different contexts (yellow and dark green, see (<bold>c</bold>)). (<bold>e</bold>) Violin plot of signal clarity at different stages of the Dalean model: sensory stimuli (<inline-formula><mml:math id="inf35"><mml:mi>x</mml:mi></mml:math></inline-formula>), lower-level (<inline-formula><mml:math id="inf36"><mml:msup><mml:mi>z</mml:mi><mml:mi mathvariant="normal">L</mml:mi></mml:msup></mml:math></inline-formula>) and higher-level population (<inline-formula><mml:math id="inf37"><mml:msup><mml:mi>z</mml:mi><mml:mi mathvariant="normal">H</mml:mi></mml:msup></mml:math></inline-formula>), modulatory units (<inline-formula><mml:math id="inf38"><mml:mi>m</mml:mi></mml:math></inline-formula>), and network output (<inline-formula><mml:math id="inf39"><mml:mi>y</mml:mi></mml:math></inline-formula>), computed across 20 contexts (compare with <xref ref-type="fig" rid="fig4">Figure 4a</xref>). (<bold>f</bold>) Violin plot of linear decoding performance of the sources from the same stages as in (<bold>e</bold>) (compare with <xref ref-type="fig" rid="fig4">Figure 4d</xref>). (<bold>g</bold>) Feedback modulation reorients the population activity (compare with <xref ref-type="fig" rid="fig5">Figure 5d</xref>).</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-76096-fig6-v2.tif"/></fig><fig id="fig6s1" position="float" specific-use="child-fig"><label>Figure 6âfigure supplement 1.</label><caption><title>The Dalean network can learn the dynamic blind source separation task, and the performance does not depend on specifics of the model architecture.</title><p>(<bold>a</bold>) Loss over training. (<bold>b</bold>) Violin plot of the signal clarity for 20 test contexts measured in the sensory stimuli and the network output. (<bold>c</bold>) Violin plot of signal clarity for models in which excitatory, inhibitory, or both types of synapses are modulated by feedback; measured over 20 contexts. (<bold>d</bold>) Mean signal clarity across 20 contexts for different numbers of inhibitory neurons <inline-formula><mml:math id="inf40"><mml:msub><mml:mi>N</mml:mi><mml:mi>I</mml:mi></mml:msub></mml:math></inline-formula> (relative to the number of neurons in the higher-level population). Colours correspond to the targets of modulation from (<bold>c</bold>). Error bars indicate standard deviation. The yellow arrow indicates the default parameter used in the main results. The star indicates networks without feedforward inhibition (see (<bold>e</bold>)). (<bold>e</bold>) Top: modulation of neurons in the higher-level population across 10 contexts without feedforward inhibition. The modulation does not switch with the context but fluctuates on a faster timescale. Bottom: corresponding deviation of the network output from the sources.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-76096-fig6-figsupp1-v2.tif"/></fig></fig-group><p>We found that this biologically more constrained model could still learn the context-invariant processing task (<xref ref-type="fig" rid="fig6s1">Figure 6âfigure supplement 1a and b</xref>). Notably, the networkâs performance did not depend on specifics of the model architecture, such as the target of the modulation or the number of inhibitory neurons (<xref ref-type="fig" rid="fig6s1">Figure 6âfigure supplement 1câe</xref>). In analogy to the previous model, the gain modulation of individual neurons changed with the context and thus enabled the flexible processing required to account for varying context (<xref ref-type="fig" rid="fig4">Figure 4c</xref>). The average gain over contexts was similar across neurons, whereas within a context the gains were broadly distributed (<xref ref-type="fig" rid="fig4">Figure 4d</xref>).</p><p>To verify if the task is solved by the same population-level mechanism, we repeated our previous analyses on the single-neuron and population level. Indeed, all results generalised to the Dalean network with feedback-driven gain modulation (compare with <xref ref-type="fig" rid="fig4">Figures 4</xref>â<xref ref-type="fig" rid="fig6">6</xref>). Single neurons in the higher- and lower-level population were not context-invariant (<xref ref-type="fig" rid="fig6">Figure 6e</xref>), but the higher-level population contained a context-invariant subspace (<xref ref-type="fig" rid="fig6">Figure 6f</xref>). This was not the case for the lower-level population, underscoring that invariant representations do not just arise from projecting the sensory stimuli into a higher dimensional space. Instead, the invariant subspace in the higher-level population was again maintained by the feedback modulation, which reoriented the population activity in response to context changes (<xref ref-type="fig" rid="fig6">Figure 6g</xref>).</p></sec><sec id="s2-7"><title>Feedback conveys a nonlinear representation of the context</title><p>Since single neurons in the higher-level population were not invariant to context, the population representation must also contain contextual information. Indeed, contextual variables could be linearly decoded from the higher-level population activity (<xref ref-type="fig" rid="fig7">Figure 7a</xref>). In contrast, decoding the context from the lower-level population gave much lower accuracy. This shows that the contextual information is not just inherited from the sensory stimuli but conveyed by the feedback via the modulatory units. We therefore expected that the modulatory units themselves would contain a representation of the context. To our surprise, decoding accuracy on the modulatory units was low. This seems counterintuitive, especially since the modulatory units clearly covaried with the contextual variables (<xref ref-type="fig" rid="fig7">Figure 7b</xref>). To understand these seemingly conflicting results, we examined how the context was represented in the activity of the modulation units.</p><fig id="fig7" position="float"><label>Figure 7.</label><caption><title>Feedback conveys a nonlinear representation of the context.</title><p>(<bold>a</bold>) Linear decoding performance of the context (i.e. mixing) from the network. (<bold>b</bold>) Context variables (e.g. source locations, top) and activity of modulatory interneurons (bottom) over contexts; one of the modulatory interneurons is silent in all contexts. (<bold>c</bold>) Left: activity of the three active modulatory interneurons (see (<bold>b</bold>)) for different contexts. The context variables are colour-coded as indicated on the right. (<bold>d</bold>) Performance of different decoders trained to predict the context from the modulatory interneuron activity. Decoder types are a linear decoder, a decoder on a quadratic expansion, and a linear decoder trained to predict the inverse of the mixing matrix.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-76096-fig7-v2.tif"/></fig><p>We found that the modulation unit activity did encode the contextual variables, albeit in a nonlinear way (<xref ref-type="fig" rid="fig7">Figure 7c</xref>). The underlying reason is that the feedback modulation needs to remove contextual variations, which requires nonlinear computations. Specifically, the blind source separation task requires an inversion of the linear mixture of sources. Consistent with this idea, nonlinear decoding approaches performed better (<xref ref-type="fig" rid="fig7">Figure 7d</xref>). In fact, the modulatory units contained a linear representation of the âinverse contextâ (i.e. the inverse mixing matrix, see âMaterials and methodsâ).</p><p>In summary, the higher-level population provides a linear representation not only of the stimuli, but also of the context. In contrast, the modulatory units contained a nonlinear representation of the context, which could not be extracted by linear decoding approaches. We speculate that if contextual feedback modulation is mediated by interneurons in layer 1, they should represent the context in a nonlinear way.</p></sec></sec><sec id="s3" sec-type="discussion"><title>Discussion</title><p>Accumulating evidence suggests that sensory processing is strongly modulated by top-down feedback projections (<xref ref-type="bibr" rid="bib27">Gilbert and Li, 2013</xref>; <xref ref-type="bibr" rid="bib41">Keller and Mrsic-Flogel, 2018</xref>). Here, we demonstrate that feedback-driven gain modulation of a feedforward network could underlie stable perception in varying contexts. The feedback can be slow, spatially diffuse, and low-dimensional. To elucidate how the context invariance is achieved, we performed single-neuron and population analyses. We found that invariance was not evident at the single-neuron level, but only emerged in a subspace of the population representation. The feedback modulation dynamically transformed the manifold of neural activity patterns such that this subspace was maintained across contexts. Our results provide further support that gain modulation at the single-cell level enables nontrivial computations at the population level (<xref ref-type="bibr" rid="bib22">Failor et al., 2021</xref>; <xref ref-type="bibr" rid="bib84">Shine et al., 2021</xref>).</p><sec id="s3-1"><title>Invariance in sensory processing</title><p>As an example of context-invariant sensory processing, we chose a dynamic variant of the blind source separation task. This task is commonly illustrated by a mixture of voices at a cocktail party (<xref ref-type="bibr" rid="bib12">Cherry, 1953</xref>; <xref ref-type="bibr" rid="bib56">McDermott, 2009</xref>). For auditory signals, bottom-up mechanisms of frequency segregation can provide a first processing step for the separation of multiple sound sources (<xref ref-type="bibr" rid="bib10">Bronkhorst, 2015</xref>; <xref ref-type="bibr" rid="bib56">McDermott, 2009</xref>). However, separating more complex sounds requires additional active top-down processes (<xref ref-type="bibr" rid="bib66">Parthasarathy et al., 2020</xref>; <xref ref-type="bibr" rid="bib63">Oberfeld and KlÃ¶ckner-Nowotny, 2016</xref>). In our model, top-down feedback guides the source separation itself, while the selection of a source would occur at a later processing stage â consistent with recent evidence for âlate selectionâ (<xref ref-type="bibr" rid="bib9">Brodbeck et al., 2020</xref>; <xref ref-type="bibr" rid="bib31">Har-Shai Yahav and Zion Golumbic, 2021</xref>).</p><p>Although blind source separation is commonly illustrated with auditory signals, the suggested mechanism of context-invariant perception is not limited to a given sensory modality. The key nature of the task is that it contains stimulus dimensions that need to be encoded (the sources) and dimensions that need to be ignored (the context). In visual object recognition, for example, the identity of visual objects needs to be encoded, while contextual variables such as size, location, orientation, or surround need to be ignored. Neural hallmarks of invariant object recognition are present at the population level (<xref ref-type="bibr" rid="bib16">DiCarlo and Cox, 2007</xref>; <xref ref-type="bibr" rid="bib17">DiCarlo et al., 2012</xref>; <xref ref-type="bibr" rid="bib35">Hong et al., 2016</xref>), and to some extent also on the level of single neurons (<xref ref-type="bibr" rid="bib73">Quiroga et al., 2005</xref>). Classically, the emergence of invariance has been attributed to the extraction of invariant features in feedforward networks (<xref ref-type="bibr" rid="bib75">Riesenhuber and Poggio, 1999</xref>; <xref ref-type="bibr" rid="bib96">Wiskott and Sejnowski, 2002</xref>; <xref ref-type="bibr" rid="bib16">DiCarlo and Cox, 2007</xref>; <xref ref-type="bibr" rid="bib45">Kriegeskorte, 2015</xref>), but recent work also highlights the role of recurrence and feedback (<xref ref-type="bibr" rid="bib27">Gilbert and Li, 2013</xref>; <xref ref-type="bibr" rid="bib39">Kar et al., 2019</xref>; <xref ref-type="bibr" rid="bib42">Kietzmann et al., 2019</xref>; <xref ref-type="bibr" rid="bib87">Thorat et al., 2021</xref>). Here, we focused on the role of feedback, but clearly, feedforward and feedback processes are not mutually exclusive and likely work in concert to create invariance. Their relative contribution to invariant perception requires further studies and may depend on the invariance in question.</p><p>Similarly, how invariance can be learned will depend on the underlying mechanism. The feedback-driven mechanism we propose is reminiscent of meta-learning consisting of an inner and an outer loop (<xref ref-type="bibr" rid="bib34">Hochreiter et al., 2001</xref>; <xref ref-type="bibr" rid="bib94">Wang et al., 2018b</xref>). In the inner loop, the modulatory system infers the context to modulate the feedforward network accordingly. This process is unsupervised. In the outer loop, the modulatory system is trained to generalise across contexts. Here, we performed this training using supervised learning, which requires the modulatory system to experience the sources in isolation (or at least obtain an error signal). Such an identification of the individual sources could, for example, be aided by other sensory modalities (<xref ref-type="bibr" rid="bib56">McDermott, 2009</xref>). However, the optimisation of the modulatory system does not necessarily require supervised learning. It could also be guided by task demands via reinforcement learning or by unsupervised priors such as a non-Gaussianity of the outputs.</p></sec><sec id="s3-2"><title>Mechanisms of feedback-driven gain modulation</title><p>There are different ways in which feedback can affect local processing. Here, we focused on gain modulation (<xref ref-type="bibr" rid="bib55">McAdams and Maunsell, 1999</xref>; <xref ref-type="bibr" rid="bib74">Reynolds and Heeger, 2009</xref>; <xref ref-type="bibr" rid="bib92">Vinck et al., 2015</xref>). Neuronal gains can be modulated by a range of mechanisms (<xref ref-type="bibr" rid="bib24">Ferguson and Cardin, 2020</xref>; <xref ref-type="bibr" rid="bib84">Shine et al., 2021</xref>). In our model, the mechanism needs to satisfy a few key requirements: (i) the modulation is not uniform across the population, (ii) it operates on a timescale similar to that of changes in context, and (iii) it is driven by a brain region that has access to the information needed to infer the context.</p><p>Classical neuromodulators such as acetylcholine (<xref ref-type="bibr" rid="bib19">Disney et al., 2007</xref>; <xref ref-type="bibr" rid="bib40">Kawai et al., 2007</xref>), dopamine (<xref ref-type="bibr" rid="bib88">Thurley et al., 2008</xref>), or serotonin (<xref ref-type="bibr" rid="bib3">Azimi et al., 2020</xref>) are signalled through specialised neuromodulatory pathways from subcortical nuclei (<xref ref-type="bibr" rid="bib90">van den Brink et al., 2019</xref>). These neuromodulators can control the neural gain depending on behavioural states such as arousal, attention, or expectation of rewards (<xref ref-type="bibr" rid="bib24">Ferguson and Cardin, 2020</xref>; <xref ref-type="bibr" rid="bib32">Hasselmo and McGaughy, 2004</xref>; <xref ref-type="bibr" rid="bib5">Bayer and Glimcher, 2005</xref>; <xref ref-type="bibr" rid="bib70">Polack et al., 2013</xref>; <xref ref-type="bibr" rid="bib46">Kuchibhotla et al., 2017</xref>). Their effect is typically thought to be brain-wide and long-lasting, but recent advances in measurement techniques (<xref ref-type="bibr" rid="bib77">Sabatini and Tian, 2020</xref>; <xref ref-type="bibr" rid="bib51">Lohani et al., 2020</xref>) indicate that it could be area- or even layer-specific, and vary on sub-second timescales (<xref ref-type="bibr" rid="bib51">Lohani et al., 2020</xref>; <xref ref-type="bibr" rid="bib4">Bang et al., 2020</xref>; <xref ref-type="bibr" rid="bib71">Poorthuis et al., 2013</xref>; <xref ref-type="bibr" rid="bib69">Pinto et al., 2013</xref>).</p><p>More specific feedback projections arrive in layer 1 of the cortex, where they target the distal dendrites of pyramidal cells and inhibitory interneurons (<xref ref-type="bibr" rid="bib20">Douglas and Martin, 2004</xref>; <xref ref-type="bibr" rid="bib76">Roth et al., 2016</xref>; <xref ref-type="bibr" rid="bib54">Marques et al., 2018</xref>). Dendritic input can change the gain of the neural transfer function on fast timescales (<xref ref-type="bibr" rid="bib47">Larkum et al., 2004</xref>; <xref ref-type="bibr" rid="bib38">Jarvis et al., 2018</xref>). The spatial scale of the modulation will depend on the spatial spread of the feedback projections and the dendritic arbourisation. Feedback to layer 1 interneurons provides an alternative mechanism of local gain control. In particular, neuron-derived neurotrophic factor-expressing interneurons (NDNF) in layer 1 receive a variety of top-down feedback projections and produce GABAergic volume transmission (<xref ref-type="bibr" rid="bib1">Abs et al., 2018</xref>), thereby downregulating synaptic transmission (<xref ref-type="bibr" rid="bib57">Miller, 1998</xref>; <xref ref-type="bibr" rid="bib48">Laviv et al., 2010</xref>). This gain modulation can act on a timescale of hundreds of milliseconds (<xref ref-type="bibr" rid="bib8">Branco and Staras, 2009</xref>; <xref ref-type="bibr" rid="bib89">Urban-Ciecko et al., 2015</xref>; <xref ref-type="bibr" rid="bib15">Cohen-Kashi Malina et al., 2021</xref>; <xref ref-type="bibr" rid="bib58">Molyneaux and Hasselmo, 2002</xref>), and, although generally considered diffuse, can also be synapse type-specific (<xref ref-type="bibr" rid="bib13">Chittajallu et al., 2013</xref>).</p><p>The question remains where in the brain the feedback signals originate. Our model requires the responsible network to receive feedforward sensory input to infer the context. In addition, feedback inputs from higher-level sensory areas to the modulatory system allow a better control of the modulated network state. Higher-order thalamic nuclei are ideally situated to integrate different sources of sensory inputs and top-down feedback (<xref ref-type="bibr" rid="bib81">Sampathkumar et al., 2021</xref>) and mediate the resulting modulation by targeting layer 1 of lower-level sensory areas (<xref ref-type="bibr" rid="bib72">Purushothaman et al., 2012</xref>; <xref ref-type="bibr" rid="bib76">Roth et al., 2016</xref>; <xref ref-type="bibr" rid="bib83">Sherman, 2016</xref>). In our task setting, the inference of the context requires the integration of sensory signals over time and therefore recurrent neural processing. For this kind of task, thalamus may not be the site of contextual inference because it lacks the required recurrent connectivity (<xref ref-type="bibr" rid="bib30">Halassa and Sherman, 2019</xref>). However, contextual inference may be performed by higher-order cortical areas and could either be relayed back via the thalamus or transmitted directly, for example, via cortico-cortical feedback connections.</p></sec><sec id="s3-3"><title>Testable predictions</title><p>Our model makes several predictions that could be tested in animals performing invariant sensory perception. Firstly, our model indicates that invariance across contexts may only be evident at the neural population level, but not on the single-cell level. Probing context invariance at different hierarchical stages of sensory processing may therefore require population recordings and corresponding statistical analyses such as neural decoding (<xref ref-type="bibr" rid="bib28">Glaser et al., 2020</xref>). Secondly, we assumed that this context invariance is mediated by feedback modulation. The extent to which context invariance is enabled by feedback on a particular level of the sensory hierarchy could be studied by manipulating feedback connections. Since layer 1 receives a broad range of feedback inputs from different sources, this may require targeted manipulations. If no effect of feedback on context invariance is found, this may either indicate that feedforward mechanisms dominate or that the invariance in question is inherited from an earlier stage, in which it may well be the result of feedback modulation. Given that feedback is more pronounced in higher cortical areas (<xref ref-type="bibr" rid="bib55">McAdams and Maunsell, 1999</xref>; <xref ref-type="bibr" rid="bib65">Pardi et al., 2020</xref>), we expect that the contribution of feedback may play a larger role for the more complex forms of invariance further up in the sensory processing hierarchy. Thirdly, for feedback to mediate context invariance, the feedback projections need to contain a representation of the contextual variables. Our findings suggest, however, that the detection of this representation may require a nonlinear decoding method. Finally, a distinguishing feature of feedback and feedforward mechanisms is that feedback mechanisms take more time. We found that immediately following a sudden contextual change, the neuronal representation initially changes within the manifold associated with the previous context. Later, the feedback reorients the manifold to re-establish the invariance on the population level. Whether these dynamics are a signature of feedback processing or also present in feedforward networks will be an interesting question for future work.</p></sec><sec id="s3-4"><title>Comparison to prior work</title><p>Computational models have implicated neuronal gain modulation for a variety of functions (<xref ref-type="bibr" rid="bib80">Salinas and Sejnowski, 2001</xref>; <xref ref-type="bibr" rid="bib74">Reynolds and Heeger, 2009</xref>). Even homogeneous changes in neuronal gain can achieve interesting population effects (<xref ref-type="bibr" rid="bib84">Shine et al., 2021</xref>), such as orthogonalisation of sensory responses (<xref ref-type="bibr" rid="bib22">Failor et al., 2021</xref>). More heterogeneous gain modulation provides additional degrees of freedom that enables, for example, attentional modulation (<xref ref-type="bibr" rid="bib74">Reynolds and Heeger, 2009</xref>; <xref ref-type="bibr" rid="bib11">Carandini and Heeger, 2011</xref>), coordinate transformations (<xref ref-type="bibr" rid="bib79">Salinas and Thier, 2000</xref>), and â when amplified by recurrent dynamics â a rich repertoire of neural trajectories (<xref ref-type="bibr" rid="bib86">Stroud et al., 2018</xref>). Gain modulation has also been suggested as a means to establish invariant processing (<xref ref-type="bibr" rid="bib78">Salinas and Abbott, 1997</xref>), as a biological implementation of dynamic routing (<xref ref-type="bibr" rid="bib64">Olshausen et al., 1993</xref>). While the modulation in these models of invariance can be interpreted as an abstract form of feedback, the resulting effects on the population level were not studied.</p><p>An interesting question is by which mechanisms the appropriate gain modulation is computed. In previous work, gain factors were often learned individually for each context, for example, by gradient descent or Hebbian plasticity (<xref ref-type="bibr" rid="bib64">Olshausen et al., 1993</xref>; <xref ref-type="bibr" rid="bib78">Salinas and Abbott, 1997</xref>; <xref ref-type="bibr" rid="bib86">Stroud et al., 2018</xref>), mechanisms that may be too slow to achieve invariance on a perceptual timescale (<xref ref-type="bibr" rid="bib91">van Hemmen and Sejnowski, 2006</xref>). In our model, by contrast, the modulation is dynamically controlled by a recurrent network. Once it has been trained, such a recurrent modulatory system can rapidly infer the current context and provide an appropriate feedback signal on a timescale only limited by the modulatory mechanism.</p></sec><sec id="s3-5"><title>Limitations and future work</title><p>In our model, we simplified many aspects of sensory processing. Using simplistic sensory stimuli â compositions of sines â allowed us to focus on the mechanisms at the population level, while avoiding the complexities of natural sensory stimuli and deep sensory hierarchies. Although we do not expect conceptual problems in generalising our results to more complex stimuli, such as speech or visual stimuli, the associated computational challenges are substantial. For example, the feedback in our model was provided by a recurrent network, whose parameters were trained by backpropagating errors through the network and through time. This training process can get very challenging for large networks and long temporal dependencies (<xref ref-type="bibr" rid="bib7">Bengio et al., 1994</xref>; <xref ref-type="bibr" rid="bib67">Pascanu et al., 2013</xref>).</p><p>In our simulations, we trained the whole model â the modulatory system, the sensory representation, and the readout. For the simplistic stimuli we used, we observed that the training process mostly concentrated on optimising the modulatory system and readout, while a random mapping of sensory stimuli to neural representations seemed largely sufficient to solve the task. For more demanding stimuli, we expect that the sensory representation the modulatory system acts upon may become more important. A well-suited representation could minimise the need for modulatory interventions (<xref ref-type="bibr" rid="bib25">Finn et al., 2017</xref>), in a coordinated interaction of feedforward and feedback.</p><p>To understand the effects of feedback modulation on population representations, we included biological constraints in the feedforward network and the structure of the modulatory feedback. However, we did not strive to provide a biologically plausible implementation for the computation of the appropriate feedback signals and instead used an off-the-shelf recurrent neural network (<xref ref-type="bibr" rid="bib33">Hochreiter and Schmidhuber, 1997</xref>). The question how these signals could be computed in a biologically plausible way remains for future studies. The same applies to the question how the appropriate feedback signals can be learned by local learning rules (<xref ref-type="bibr" rid="bib50">Lillicrap et al., 2020</xref>) and how neural representations and modulatory systems learn to act in concert.</p></sec></sec><sec id="s4" sec-type="materials|methods"><title>Materials and methods</title><p>To study how feedback-driven modulation can enable flexible sensory processing, we built models of feedforward networks that are modulated by feedback. The feedback was dynamically generated by a modulatory system, which we implemented as a recurrent network. The weights of the recurrent network were trained such that the feedback modulation allowed the feedforward network to solve a flexible invariant processing task.</p><sec id="s4-1"><title>The dynamic blind source separation task</title><p>As an instance of flexible sensory processing, we used a dynamic variant of blind source separation. In classical blind source separation, two or more unknown time-varying sources <inline-formula><mml:math id="inf41"><mml:mrow><mml:mover accent="true"><mml:mi>s</mml:mi><mml:mo stretchy="false">â</mml:mo></mml:mover><mml:mo>â¢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> need to be recovered from a set of observations (i.e. sensory stimuli) <inline-formula><mml:math id="inf42"><mml:mrow><mml:mover accent="true"><mml:mi>x</mml:mi><mml:mo stretchy="false">â</mml:mo></mml:mover><mml:mo>â¢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula>. The sensory stimuli are composed of an unknown linear mixture of the sources such that <inline-formula><mml:math id="inf43"><mml:mrow><mml:mrow><mml:mover accent="true"><mml:mi>x</mml:mi><mml:mo stretchy="false">â</mml:mo></mml:mover><mml:mo>â¢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mo>=</mml:mo><mml:mrow><mml:mi>A</mml:mi><mml:mo>â¢</mml:mo><mml:mover accent="true"><mml:mi>s</mml:mi><mml:mo stretchy="false">â</mml:mo></mml:mover><mml:mo>â¢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:math></inline-formula> with a fixed mixing matrix <inline-formula><mml:math id="inf44"><mml:mi>A</mml:mi></mml:math></inline-formula>. Recovering the sources requires to find weights <inline-formula><mml:math id="inf45"><mml:mi>W</mml:mi></mml:math></inline-formula> such that <inline-formula><mml:math id="inf46"><mml:mrow><mml:mrow><mml:mi>W</mml:mi><mml:mo>â¢</mml:mo><mml:mover accent="true"><mml:mi>x</mml:mi><mml:mo stretchy="false">â</mml:mo></mml:mover><mml:mo>â¢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mo>â</mml:mo><mml:mrow><mml:mover accent="true"><mml:mi>s</mml:mi><mml:mo stretchy="false">â</mml:mo></mml:mover><mml:mo>â¢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:math></inline-formula>. Ideally, <inline-formula><mml:math id="inf47"><mml:mi>W</mml:mi></mml:math></inline-formula> is equal to the pseudo-inverse of the unknown mixing matrix <inline-formula><mml:math id="inf48"><mml:mi>A</mml:mi></mml:math></inline-formula>, up to permutations.</p><p>In our dynamic blind source separation task, we model variations in the stimulus context by changing the linear mixture over time â albeit on a slower timescale than the time-varying signals. Thus, the sensory stimuli are constructed as<disp-formula id="equ3"><label>(1)</label><mml:math id="m3"><mml:mrow><mml:mrow><mml:mrow><mml:mover accent="true"><mml:mi>x</mml:mi><mml:mo stretchy="false">â</mml:mo></mml:mover><mml:mo>â¢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mo>=</mml:mo><mml:mrow><mml:mrow><mml:mi>A</mml:mi><mml:mo>â¢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>â¢</mml:mo><mml:mover accent="true"><mml:mi>s</mml:mi><mml:mo stretchy="false">â</mml:mo></mml:mover><mml:mo>â¢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mo>+</mml:mo><mml:mrow><mml:msub><mml:mi>Ï</mml:mi><mml:mi>n</mml:mi></mml:msub><mml:mo>â¢</mml:mo><mml:mover accent="true"><mml:mi>Î¾</mml:mi><mml:mo stretchy="false">â</mml:mo></mml:mover><mml:mo>â¢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:mrow><mml:mo mathvariant="italic" separator="true">â</mml:mo><mml:mo>,</mml:mo></mml:mrow></mml:math></disp-formula></p><p>where <inline-formula><mml:math id="inf49"><mml:mrow><mml:mi>A</mml:mi><mml:mo>â¢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> is a time-dependent mixing matrix and <inline-formula><mml:math id="inf50"><mml:msub><mml:mi>Ï</mml:mi><mml:mi>n</mml:mi></mml:msub></mml:math></inline-formula> is the amplitude of additive white noise <inline-formula><mml:math id="inf51"><mml:mrow><mml:mover accent="true"><mml:mi>Î¾</mml:mi><mml:mo stretchy="false">â</mml:mo></mml:mover><mml:mo>â¢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula>. The time-dependent mixing matrix determines the current context and was varied in discrete time intervalsâ<inline-formula><mml:math id="inf52"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>n</mml:mi><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula>, meaning that the mixing matrix <inline-formula><mml:math id="inf53"><mml:mrow><mml:mi>A</mml:mi><mml:mo>â¢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> (i.e. the context) was constant for <inline-formula><mml:math id="inf54"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>n</mml:mi><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula>âsamples before it changed. The goal of the dynamic blind source separation task is to recover the original signal sources <inline-formula><mml:math id="inf55"><mml:mover accent="true"><mml:mi>s</mml:mi><mml:mo stretchy="false">â</mml:mo></mml:mover></mml:math></inline-formula> from the sensory stimuli <inline-formula><mml:math id="inf56"><mml:mover accent="true"><mml:mi>x</mml:mi><mml:mo stretchy="false">â</mml:mo></mml:mover></mml:math></inline-formula> across varying contexts. Thus, the network model output needs to be invariant to the specific context of the sources. Note that while the context was varied, the sources themselves were the same throughout the task, unless stated otherwise. Furthermore, in the majority of experiments the number of source signals and sensory stimuli was <inline-formula><mml:math id="inf57"><mml:mrow><mml:msub><mml:mi>n</mml:mi><mml:mi>s</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mn>2</mml:mn></mml:mrow></mml:math></inline-formula>. A list of default parameters for the dynamic blind source separation task can be found in <xref ref-type="table" rid="table1">Table 1</xref>.</p><table-wrap id="table1" position="float"><label>Table 1.</label><caption><title>Default parameters of the dynamic blind source separation task.</title></caption><table frame="hsides" rules="groups"><thead><tr><th align="left" valign="bottom">Parameter</th><th align="left" valign="bottom">Symbol</th><th align="center" valign="bottom">Value</th></tr></thead><tbody><tr><td align="left" valign="bottom">Number of signals</td><td align="left" valign="bottom"><inline-formula><mml:math id="inf58"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>n</mml:mi><mml:mrow><mml:mi>s</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula></td><td align="center" valign="bottom">2</td></tr><tr><td align="left" valign="bottom">Number of samples in context</td><td align="left" valign="bottom"><inline-formula><mml:math id="inf59"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>n</mml:mi><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula></td><td align="center" valign="bottom">1000</td></tr><tr><td align="left" valign="bottom">Additive noise</td><td align="left" valign="bottom"><inline-formula><mml:math id="inf60"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>Ï</mml:mi><mml:mrow><mml:mi>n</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula></td><td align="center" valign="bottom">0.001</td></tr><tr><td align="left" valign="bottom">Sampling frequency</td><td align="left" valign="bottom"><inline-formula><mml:math id="inf61"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>f</mml:mi><mml:mrow><mml:mi>s</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula></td><td align="center" valign="bottom">8 KHz</td></tr></tbody></table></table-wrap><sec id="s4-1-1"><title>Source signals</title><p>As default source signals, we used two compositions of two sines each (âchordsâ) with a sampling rate of <inline-formula><mml:math id="inf62"><mml:mrow><mml:msub><mml:mi>f</mml:mi><mml:mi>s</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mn>8000</mml:mn></mml:mrow></mml:math></inline-formula> Hz that can be written as<disp-formula id="equ4"><label>(2)</label><mml:math id="m4"><mml:mrow><mml:mrow><mml:msub><mml:mi>s</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>â¢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mo>=</mml:mo><mml:mrow><mml:mrow><mml:mi>sin</mml:mi><mml:mo>â¡</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mrow><mml:mn>2</mml:mn><mml:mo>â¢</mml:mo><mml:mi>Ï</mml:mi><mml:mo>â¢</mml:mo><mml:msub><mml:mi>f</mml:mi><mml:mn>11</mml:mn></mml:msub><mml:mo>â¢</mml:mo><mml:mi>t</mml:mi></mml:mrow><mml:mo>/</mml:mo><mml:msub><mml:mi>f</mml:mi><mml:mi>s</mml:mi></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>+</mml:mo><mml:mrow><mml:mi>sin</mml:mi><mml:mo>â¡</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mrow><mml:mn>2</mml:mn><mml:mo>â¢</mml:mo><mml:mi>Ï</mml:mi><mml:mo>â¢</mml:mo><mml:msub><mml:mi>f</mml:mi><mml:mn>12</mml:mn></mml:msub><mml:mo>â¢</mml:mo><mml:mi>t</mml:mi></mml:mrow><mml:mo>/</mml:mo><mml:msub><mml:mi>f</mml:mi><mml:mi>s</mml:mi></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:mrow></mml:math></disp-formula><disp-formula id="equ5"><label>(3)</label><mml:math id="m5"><mml:mrow><mml:mrow><mml:msub><mml:mi>s</mml:mi><mml:mn>2</mml:mn></mml:msub><mml:mo>â¢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mo>=</mml:mo><mml:mrow><mml:mrow><mml:mi>sin</mml:mi><mml:mo>â¡</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mrow><mml:mn>2</mml:mn><mml:mo>â¢</mml:mo><mml:mi>Ï</mml:mi><mml:mo>â¢</mml:mo><mml:msub><mml:mi>f</mml:mi><mml:mn>21</mml:mn></mml:msub><mml:mo>â¢</mml:mo><mml:mi>t</mml:mi></mml:mrow><mml:mo>/</mml:mo><mml:msub><mml:mi>f</mml:mi><mml:mi>s</mml:mi></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>+</mml:mo><mml:mrow><mml:mi>sin</mml:mi><mml:mo>â¡</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mrow><mml:mn>2</mml:mn><mml:mo>â¢</mml:mo><mml:mi>Ï</mml:mi><mml:mo>â¢</mml:mo><mml:msub><mml:mi>f</mml:mi><mml:mn>22</mml:mn></mml:msub><mml:mo>â¢</mml:mo><mml:mi>t</mml:mi></mml:mrow><mml:mo>/</mml:mo><mml:msub><mml:mi>f</mml:mi><mml:mi>s</mml:mi></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:mrow></mml:math></disp-formula></p><p>with frequencies <inline-formula><mml:math id="inf63"><mml:mrow><mml:msub><mml:mi>f</mml:mi><mml:mn>11</mml:mn></mml:msub><mml:mo>=</mml:mo><mml:mn>100</mml:mn></mml:mrow></mml:math></inline-formula> Hz, <inline-formula><mml:math id="inf64"><mml:mrow><mml:msub><mml:mi>f</mml:mi><mml:mn>12</mml:mn></mml:msub><mml:mo>=</mml:mo><mml:mn>125</mml:mn></mml:mrow></mml:math></inline-formula> Hz, <inline-formula><mml:math id="inf65"><mml:mrow><mml:msub><mml:mi>f</mml:mi><mml:mn>21</mml:mn></mml:msub><mml:mo>=</mml:mo><mml:mn>150</mml:mn></mml:mrow></mml:math></inline-formula> Hz, and <inline-formula><mml:math id="inf66"><mml:mrow><mml:msub><mml:mi>f</mml:mi><mml:mn>22</mml:mn></mml:msub><mml:mo>=</mml:mo><mml:mn>210</mml:mn></mml:mrow></mml:math></inline-formula> Hz. Note that in our model we measure time as the number of samples from the source signals, meaning that timescales are relative and could be arbitrarily rescaled.</p><p>In <xref ref-type="fig" rid="fig5">Figure 5</xref>, we used pure sine signals with frequency <inline-formula><mml:math id="inf67"><mml:mi>f</mml:mi></mml:math></inline-formula> for visualisation purposes: <inline-formula><mml:math id="inf68"><mml:mrow><mml:msub><mml:mi>s</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mrow><mml:mi>sin</mml:mi><mml:mo>â¡</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mrow><mml:mn>2</mml:mn><mml:mo>â¢</mml:mo><mml:mi>Ï</mml:mi><mml:mo>â¢</mml:mo><mml:mi>f</mml:mi><mml:mo>â¢</mml:mo><mml:mi>t</mml:mi></mml:mrow><mml:mo>/</mml:mo><mml:msub><mml:mi>f</mml:mi><mml:mi>s</mml:mi></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:math></inline-formula>. We also validated the model on signals that are not made of sine waves, as a sawtooth and a square wave signal (<xref ref-type="fig" rid="fig1s4">Figure 1âfigure supplement 4</xref>). Unless stated otherwise, the same signals were used for training and testing the model.</p></sec><sec id="s4-1-2"><title>Time-varying contexts</title><p>We generated the mixing matrix <inline-formula><mml:math id="inf69"><mml:mi>A</mml:mi></mml:math></inline-formula> for each context by drawing random weights from a uniform distribution between 0 and 1, allowing only positive mixtures of the sources. Unless specified otherwise, we sampled new contexts for each training batch and for the test data, such that the training and test data followed the same distribution without necessarily being the same. The dimension of the mixing matrices was determined by number of signalsâ<inline-formula><mml:math id="inf70"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>n</mml:mi><mml:mrow><mml:mi>s</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula> such that <inline-formula><mml:math id="inf71"><mml:mi>A</mml:mi></mml:math></inline-formula> was of shape <inline-formula><mml:math id="inf72"><mml:mrow><mml:msub><mml:mi>n</mml:mi><mml:mi>s</mml:mi></mml:msub><mml:mo>Ã</mml:mo><mml:msub><mml:mi>n</mml:mi><mml:mi>s</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula>. To keep the overall amplitude of the sensory stimuli in a similar range across different mixtures, we normalised the row sums of each mixing matrix to one. In the case of <inline-formula><mml:math id="inf73"><mml:mrow><mml:msub><mml:mi>n</mml:mi><mml:mi>s</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mn>2</mml:mn></mml:mrow></mml:math></inline-formula>, this implies that the contexts (i.e. the mixing matrices) are drawn from a two-dimensional manifold (see <xref ref-type="fig" rid="fig8">Figure 8</xref>, bottom left). In addition, we only used the randomly generated mixing matrices whose determinant was larger than some threshold value. We did this to ensure that each signal mixture was invertible and that the weights needed to invert the mixing matrix were not too extreme. A threshold value of 0.2 was chosen based on visual inspection of the weights from the inverted mixing matrix.</p><fig id="fig8" position="float"><label>Figure 8.</label><caption><title>Schematic of the dynamic blind source separation task, context space, and the modulated feedforward network.</title><p>Information flow is indicated by black arrows, and the flow of the error during training with backpropagation through time (BPTT) is shown in yellow.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-76096-fig8-v2.tif"/></fig></sec></sec><sec id="s4-2"><title>Modulated feedforward network models</title><p>Throughout this work, we modelled feedforward networks of increasing complexity. Common to all networks was that they received the sensory stimuli <inline-formula><mml:math id="inf74"><mml:mover accent="true"><mml:mi>x</mml:mi><mml:mo stretchy="false">â</mml:mo></mml:mover></mml:math></inline-formula> and should provide an output <inline-formula><mml:math id="inf75"><mml:mover accent="true"><mml:mi>y</mml:mi><mml:mo stretchy="false">â</mml:mo></mml:mover></mml:math></inline-formula> that matches the source signals <inline-formula><mml:math id="inf76"><mml:mover accent="true"><mml:mi>s</mml:mi><mml:mo stretchy="false">â</mml:mo></mml:mover></mml:math></inline-formula>. In the following, we first introduce the simplest model variant and how it is affected by feedback from the modulatory system, and subsequently describe the different model extensions.</p><sec id="s4-2-1"><title>Modulation of feedforward weights by a recurrent network</title><p>In the simplest feedforward network, the network output <inline-formula><mml:math id="inf77"><mml:mrow><mml:mover accent="true"><mml:mi>y</mml:mi><mml:mo stretchy="false">â</mml:mo></mml:mover><mml:mo>â¢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> is simply a linear readout of the sensory stimuli <inline-formula><mml:math id="inf78"><mml:mrow><mml:mover accent="true"><mml:mi>x</mml:mi><mml:mo stretchy="false">â</mml:mo></mml:mover><mml:mo>â¢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula>, with readout weights that are dynamically changed by the modulatory system:<disp-formula id="equ6"><label>(4)</label><mml:math id="m6"><mml:mrow><mml:mrow><mml:mrow><mml:mover accent="true"><mml:mi>y</mml:mi><mml:mo stretchy="false">â</mml:mo></mml:mover><mml:mo>â¢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mo>=</mml:mo><mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mrow><mml:mi>M</mml:mi><mml:mo>â¢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mo>â</mml:mo><mml:msub><mml:mi>W</mml:mi><mml:mn>0</mml:mn></mml:msub></mml:mrow><mml:mo rspace="7.5pt" stretchy="false">)</mml:mo></mml:mrow><mml:mo>â¢</mml:mo><mml:mover accent="true"><mml:mi>x</mml:mi><mml:mo stretchy="false">â</mml:mo></mml:mover><mml:mo>â¢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:mrow><mml:mo mathvariant="italic" separator="true">â</mml:mo></mml:mrow></mml:math></disp-formula></p><p>where <inline-formula><mml:math id="inf79"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>W</mml:mi><mml:mn>0</mml:mn></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula> are the baseline weights and <inline-formula><mml:math id="inf80"><mml:mrow><mml:mi>M</mml:mi><mml:mo>â¢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> the modulation provided by the modulatory system. <inline-formula><mml:math id="inf81"><mml:mrow><mml:mi>M</mml:mi><mml:mo>â¢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> is of the same shape as <inline-formula><mml:math id="inf82"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>W</mml:mi><mml:mn>0</mml:mn></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula> and determines the element-wise multiplicative modulation of the baseline weights. Because the task requires the modulatory system to dynamically infer the context, we modelled it as a recurrent network â more specifically, a long-short-term memory network (LSTMs; <xref ref-type="bibr" rid="bib33">Hochreiter and Schmidhuber, 1997</xref>) â with <inline-formula><mml:math id="inf83"><mml:mrow><mml:msub><mml:mi>N</mml:mi><mml:mi>h</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mn>100</mml:mn></mml:mrow></mml:math></inline-formula> hidden units. In particular, we used LSTMs with forget gates (<xref ref-type="bibr" rid="bib26">Gers et al., 2000</xref>) but no peephole connections (for an overview of LSTM variants, see <xref ref-type="bibr" rid="bib29">Greff et al., 2017</xref>).</p><p>In this work, we treated the LSTM as a black-box modulatory system that receives the sensory stimuli and the feedforward networkâs output and provides the feedback signal in return (<xref ref-type="fig" rid="fig1">Figure 1a</xref>). A linear readout of the LSTMâs output determines the modulation <inline-formula><mml:math id="inf84"><mml:mrow><mml:mi>M</mml:mi><mml:mo>â¢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> in <xref ref-type="disp-formula" rid="equ6">Equation 4</xref>. In brief, this means that<disp-formula id="equ7"><label>(5)</label><mml:math id="m7"><mml:mrow><mml:mrow><mml:mrow><mml:mi>M</mml:mi><mml:mo>â¢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mo>=</mml:mo><mml:mrow><mml:mi>LSTM</mml:mi><mml:mo>â¢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mover accent="true"><mml:mi>x</mml:mi><mml:mo stretchy="false">â</mml:mo></mml:mover><mml:mo>â¢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mo>,</mml:mo><mml:mrow><mml:mover accent="true"><mml:mi>y</mml:mi><mml:mo stretchy="false">â</mml:mo></mml:mover><mml:mo>â¢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mo rspace="4.2pt" stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:mrow><mml:mo>,</mml:mo></mml:mrow></mml:math></disp-formula></p><p>where <inline-formula><mml:math id="inf85"><mml:mrow><mml:mi>LSTM</mml:mi><mml:mo>â¢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mo>â</mml:mo><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> is a function that returns the LSTM readout. For two-dimensional sources and sensory stimuli, for instance, <inline-formula><mml:math id="inf86"><mml:mrow><mml:mi>LSTM</mml:mi><mml:mo>â¢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mo>â</mml:mo><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> receives a concatenation of the two-dimensional vectors <inline-formula><mml:math id="inf87"><mml:mrow><mml:mover accent="true"><mml:mi>x</mml:mi><mml:mo stretchy="false">â</mml:mo></mml:mover><mml:mo>â¢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> and <inline-formula><mml:math id="inf88"><mml:mrow><mml:mover accent="true"><mml:mi>y</mml:mi><mml:mo stretchy="false">â</mml:mo></mml:mover><mml:mo>â¢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> as input and returns a two-by-two feedback modulation matrix â one multiplicative factor for each weight in <italic>W</italic><sub>0</sub>. The baseline weights <italic>W</italic><sub>0</sub> were randomly drawn from the Gaussian distribution <inline-formula><mml:math id="inf89"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mrow><mml:mi mathvariant="script">N</mml:mi></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mn>0.001</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mstyle></mml:math></inline-formula> and fixed throughout the task. The LSTM parameters and readout were learned during training of the model.</p></sec><sec id="s4-2-2"><title>Extension 1: Reducing the temporal specificity of feedback modulation</title><p>To probe our modelâs sensitivity to the timescale of the modulatory feedback (<xref ref-type="fig" rid="fig2">Figure 2</xref>), we added a temporal filter to <xref ref-type="disp-formula" rid="equ7">Equation 5</xref>. In that case, the modulation <inline-formula><mml:math id="inf90"><mml:mrow><mml:mi>M</mml:mi><mml:mo>â¢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> followed the dynamics<disp-formula id="equ8"><label>(6)</label><mml:math id="m8"><mml:mrow><mml:mi>Ï</mml:mi><mml:mfrac><mml:mrow><mml:mi>d</mml:mi><mml:mi>M</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mi>t</mml:mi></mml:mfrac><mml:mo>=</mml:mo><mml:mo>â</mml:mo><mml:mi>M</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>+</mml:mo><mml:mrow><mml:mi mathvariant="normal">L</mml:mi><mml:mi mathvariant="normal">S</mml:mi><mml:mi mathvariant="normal">T</mml:mi><mml:mi mathvariant="normal">M</mml:mi></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mover><mml:mi>x</mml:mi><mml:mo stretchy="false">â</mml:mo></mml:mover></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>,</mml:mo><mml:mrow><mml:mover><mml:mi>y</mml:mi><mml:mo stretchy="false">â</mml:mo></mml:mover></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo stretchy="false">)</mml:mo><mml:mspace width="thinmathspace"/><mml:mo>,</mml:mo></mml:mrow></mml:math></disp-formula></p><p>with <inline-formula><mml:math id="inf91"><mml:mi>Ï</mml:mi></mml:math></inline-formula> being the time constant of modulation. For small <inline-formula><mml:math id="inf92"><mml:mi>Ï</mml:mi></mml:math></inline-formula>, the feedback rapidly affects the feedforward network, whereas larger <inline-formula><mml:math id="inf93"><mml:mi>Ï</mml:mi></mml:math></inline-formula> imply a slowly changing modulatory feedback signal. The unit of this timescale is the number of samples from the source signals. Note that the timescale of the modulation should be considered relative to the timescale of the context changes <italic>n</italic><sub><italic>t</italic></sub>. As a default time constant, we used <inline-formula><mml:math id="inf94"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>Ï</mml:mi><mml:mo>=</mml:mo><mml:mn>100</mml:mn><mml:mo>&lt;</mml:mo><mml:msub><mml:mi>n</mml:mi><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula> (see <xref ref-type="table" rid="table2">Table 2</xref>).</p><table-wrap id="table2" position="float"><label>Table 2.</label><caption><title>Default parameters of the network models.</title></caption><table frame="hsides" rules="groups"><thead><tr><th align="left" valign="bottom">Parameter</th><th align="center" valign="bottom">Symbol</th><th align="center" valign="bottom">Value</th></tr></thead><tbody><tr><td align="left" valign="bottom">Number of hidden units in long-short-term memory network</td><td align="center" valign="bottom"><inline-formula><mml:math id="inf95"><mml:msub><mml:mi>N</mml:mi><mml:mi>h</mml:mi></mml:msub></mml:math></inline-formula></td><td align="center" valign="bottom">100</td></tr><tr><td align="left" valign="bottom">Number of units in middle layer z</td><td align="center" valign="bottom"><inline-formula><mml:math id="inf96"><mml:msub><mml:mi>N</mml:mi><mml:mi>z</mml:mi></mml:msub></mml:math></inline-formula></td><td align="center" valign="bottom">100</td></tr><tr><td align="left" valign="bottom">Number of distinct feedback signals</td><td align="center" valign="bottom"><inline-formula><mml:math id="inf97"><mml:msub><mml:mi>N</mml:mi><mml:mi>FB</mml:mi></mml:msub></mml:math></inline-formula></td><td align="center" valign="bottom">4</td></tr><tr><td align="left" valign="bottom">Number of neurons in lower-level population</td><td align="center" valign="bottom"><inline-formula><mml:math id="inf98"><mml:msub><mml:mi>N</mml:mi><mml:mi>L</mml:mi></mml:msub></mml:math></inline-formula></td><td align="center" valign="bottom">40</td></tr><tr><td align="left" valign="bottom">Number of neurons in higher-level population</td><td align="center" valign="bottom"><inline-formula><mml:math id="inf99"><mml:msub><mml:mi>N</mml:mi><mml:mi>H</mml:mi></mml:msub></mml:math></inline-formula></td><td align="center" valign="bottom">100</td></tr><tr><td align="left" valign="bottom">Number of inhibitory neurons</td><td align="center" valign="bottom"><inline-formula><mml:math id="inf100"><mml:msub><mml:mi>N</mml:mi><mml:mi>I</mml:mi></mml:msub></mml:math></inline-formula></td><td align="center" valign="bottom">20</td></tr><tr><td align="left" valign="bottom">Timescale of modulation</td><td align="center" valign="bottom"><inline-formula><mml:math id="inf101"><mml:mi>Ï</mml:mi></mml:math></inline-formula></td><td align="center" valign="bottom">100</td></tr><tr><td align="left" valign="bottom">Spatial spread of modulation</td><td align="center" valign="bottom"><inline-formula><mml:math id="inf102"><mml:msubsup><mml:mi>Ï</mml:mi><mml:mi>m</mml:mi><mml:mn>2</mml:mn></mml:msubsup></mml:math></inline-formula></td><td align="center" valign="bottom">0.2</td></tr></tbody></table></table-wrap></sec><sec id="s4-2-3"><title>Extension 2: Reducing the spatial specificity of feedback modulation</title><p>To allow for spatially diffuse feedback modulation (<xref ref-type="fig" rid="fig3">Figure 3</xref>), we added an intermediate layer between the sensory stimuli and the network output. This intermediate layer consisted of a population of <inline-formula><mml:math id="inf103"><mml:mrow><mml:msub><mml:mi>N</mml:mi><mml:mi>z</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mn>100</mml:mn></mml:mrow></mml:math></inline-formula> units that were modulated by the feedback, where neighbouring units were modulated similarly. More specifically, the units were arranged on a ring to allow for a spatially constrained modulation without boundary effects. The populationâs activity vector <inline-formula><mml:math id="inf104"><mml:mrow><mml:mover accent="true"><mml:mi>z</mml:mi><mml:mo stretchy="false">â</mml:mo></mml:mover><mml:mo>â¢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> is described by<disp-formula id="equ9"><label>(7)</label><mml:math id="m9"><mml:mrow><mml:mrow><mml:mrow><mml:mover accent="true"><mml:mi>z</mml:mi><mml:mo stretchy="false">â</mml:mo></mml:mover><mml:mo>â¢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mo>=</mml:mo><mml:mrow><mml:mrow><mml:mover accent="true"><mml:mi>m</mml:mi><mml:mo stretchy="false">â</mml:mo></mml:mover><mml:mo>â¢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mo>â</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:msup><mml:mi>W</mml:mi><mml:mi mathvariant="normal">x</mml:mi></mml:msup><mml:mo>â¢</mml:mo><mml:mover accent="true"><mml:mi>x</mml:mi><mml:mo stretchy="false">â</mml:mo></mml:mover><mml:mo>â¢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mo rspace="4.2pt" stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:mrow><mml:mo>,</mml:mo></mml:mrow></mml:math></disp-formula></p><p>with the sensory stimuli <inline-formula><mml:math id="inf105"><mml:mrow><mml:mover accent="true"><mml:mi>x</mml:mi><mml:mo stretchy="false">â</mml:mo></mml:mover><mml:mo>â¢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula>, a weight matrix <inline-formula><mml:math id="inf106"><mml:msup><mml:mi>W</mml:mi><mml:mi mathvariant="normal">x</mml:mi></mml:msup></mml:math></inline-formula> of size <inline-formula><mml:math id="inf107"><mml:mrow><mml:msub><mml:mi>N</mml:mi><mml:mi>z</mml:mi></mml:msub><mml:mo>Ã</mml:mo><mml:msub><mml:mi>n</mml:mi><mml:mi>s</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula>, and the vector of unit-specific multiplicative modulations <inline-formula><mml:math id="inf108"><mml:mrow><mml:mover accent="true"><mml:mi>m</mml:mi><mml:mo stretchy="false">â</mml:mo></mml:mover><mml:mo>â¢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula>. Note that the activity of the units was not constrained to be positive here. The output of the network was then determined by a linear readout of the population activity vector according to<disp-formula id="equ10"><label>(8)</label><mml:math id="m10"><mml:mrow><mml:mrow><mml:mover accent="true"><mml:mi>y</mml:mi><mml:mo stretchy="false">â</mml:mo></mml:mover><mml:mo>â¢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mo>=</mml:mo><mml:mrow><mml:msup><mml:mi>W</mml:mi><mml:mi>ro</mml:mi></mml:msup><mml:mo>â¢</mml:mo><mml:mover accent="true"><mml:mi>z</mml:mi><mml:mo stretchy="false">â</mml:mo></mml:mover><mml:mo>â¢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:math></disp-formula></p><p>with a fixed readout matrix <inline-formula><mml:math id="inf109"><mml:msup><mml:mi>W</mml:mi><mml:mi>ro</mml:mi></mml:msup></mml:math></inline-formula>.</p><p>The modulation to a single unit <inline-formula><mml:math id="inf110"><mml:mi>i</mml:mi></mml:math></inline-formula> was given by<disp-formula id="equ11"><label>(9a)</label><mml:math id="m11"><mml:mrow><mml:mi>Ï</mml:mi><mml:mfrac><mml:mrow><mml:mi>d</mml:mi><mml:msub><mml:mi>m</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mi>t</mml:mi></mml:mfrac><mml:mo>=</mml:mo><mml:mo>â</mml:mo><mml:msub><mml:mi>m</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>+</mml:mo><mml:munderover><mml:mo>â</mml:mo><mml:mrow><mml:mi>j</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:msub><mml:mi>N</mml:mi><mml:mrow><mml:mrow><mml:mi mathvariant="normal">F</mml:mi><mml:mi mathvariant="normal">B</mml:mi></mml:mrow></mml:mrow></mml:msub></mml:mrow></mml:munderover><mml:msub><mml:mi>K</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mtext>Â </mml:mtext><mml:msub><mml:mi>l</mml:mi><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mspace width="thinmathspace"/><mml:mo>,</mml:mo></mml:mrow></mml:math></disp-formula><disp-formula id="equ12"><label>(9b)</label><mml:math id="m12"><mml:mrow><mml:mrow><mml:mrow><mml:mtext>with</mml:mtext><mml:mo mathvariant="italic" separator="true">â</mml:mo><mml:msub><mml:mi>l</mml:mi><mml:mi>j</mml:mi></mml:msub></mml:mrow><mml:mo>=</mml:mo><mml:mrow><mml:mi>LSTM</mml:mi><mml:mo>â¢</mml:mo><mml:mpadded width="+5pt"><mml:msub><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mi>x</mml:mi><mml:mo>â¢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mo>,</mml:mo><mml:mrow><mml:mi>y</mml:mi><mml:mo>â¢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mi>j</mml:mi></mml:msub></mml:mpadded></mml:mrow></mml:mrow><mml:mo>.</mml:mo></mml:mrow></mml:math></disp-formula></p><p>Here, <inline-formula><mml:math id="inf111"><mml:mi>Ï</mml:mi></mml:math></inline-formula> is the modulation time constant, <inline-formula><mml:math id="inf112"><mml:mi>K</mml:mi></mml:math></inline-formula> is a kernel that determines the spatial specificity of modulation, <inline-formula><mml:math id="inf113"><mml:mrow><mml:mi>LSTM</mml:mi><mml:mo>â¢</mml:mo><mml:msub><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mo>â</mml:mo><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mi>j</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula> the <inline-formula><mml:math id="inf114"><mml:mi>j</mml:mi></mml:math></inline-formula>th feedback signal from the LSTM, and <inline-formula><mml:math id="inf115"><mml:msub><mml:mi>N</mml:mi><mml:mi>FB</mml:mi></mml:msub></mml:math></inline-formula> is the total number of feedback signals. As in the simple model, the <inline-formula><mml:math id="inf116"><mml:msub><mml:mi>N</mml:mi><mml:mi>FB</mml:mi></mml:msub></mml:math></inline-formula> feedback signals were determined by a linear readout from LSTM.</p><p>The modulation kernel <inline-formula><mml:math id="inf117"><mml:mi>K</mml:mi></mml:math></inline-formula> was defined as a set of von Mises functions:<disp-formula id="equ13"><label>(10)</label><mml:math id="m13"><mml:mrow><mml:mrow><mml:msub><mml:mi>K</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo>â¢</mml:mo><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mpadded width="+1.7pt"><mml:mrow><mml:mi>exp</mml:mi><mml:mo>â¡</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mfrac><mml:mn>1</mml:mn><mml:msubsup><mml:mi>Ï</mml:mi><mml:mi>m</mml:mi><mml:mn>2</mml:mn></mml:msubsup></mml:mfrac></mml:mstyle><mml:mo>â¢</mml:mo><mml:mrow><mml:mi>cos</mml:mi><mml:mo>â¡</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msubsup><mml:mi>z</mml:mi><mml:mi>i</mml:mi><mml:mi>loc</mml:mi></mml:msubsup><mml:mo>-</mml:mo><mml:msubsup><mml:mi>l</mml:mi><mml:mi>j</mml:mi><mml:mi>loc</mml:mi></mml:msubsup></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mpadded></mml:mrow><mml:mo>,</mml:mo></mml:mrow></mml:math></disp-formula></p><p>where <inline-formula><mml:math id="inf118"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msubsup><mml:mi>z</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mrow><mml:mi mathvariant="normal">l</mml:mi><mml:mi mathvariant="normal">o</mml:mi><mml:mi mathvariant="normal">c</mml:mi></mml:mrow></mml:mrow></mml:msubsup><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mn>2</mml:mn><mml:mi>Ï</mml:mi><mml:mi>i</mml:mi></mml:mrow><mml:msub><mml:mi>N</mml:mi><mml:mrow><mml:mi>z</mml:mi></mml:mrow></mml:msub></mml:mfrac><mml:mo>â</mml:mo><mml:mo stretchy="false">[</mml:mo><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:mn>2</mml:mn><mml:mi>Ï</mml:mi><mml:mo stretchy="false">]</mml:mo></mml:mrow></mml:mstyle></mml:math></inline-formula> represents the location of the modulated unit <italic>i</italic> on the ring and <inline-formula><mml:math id="inf119"><mml:msubsup><mml:mi>l</mml:mi><mml:mi>j</mml:mi><mml:mi>loc</mml:mi></mml:msubsup></mml:math></inline-formula> the âpreferred locationâ of modulatory unit <inline-formula><mml:math id="inf120"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:mstyle></mml:math></inline-formula>, that is, the location on the ring that it modulates most effectively. These âpreferred locationsâ <inline-formula><mml:math id="inf121"><mml:msubsup><mml:mi>l</mml:mi><mml:mi>j</mml:mi><mml:mi>loc</mml:mi></mml:msubsup></mml:math></inline-formula> of the feedback units were evenly distributed on the ring. The variance parameter <inline-formula><mml:math id="inf122"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msubsup><mml:mi>Ï</mml:mi><mml:mrow><mml:mi>m</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup></mml:mrow></mml:mstyle></mml:math></inline-formula> determines the spatial spread of the modulatory effect of the feedback units, that is, the spatial specificity of the modulation. Overall, the spatial distribution of the modulation was therefore determined by the number of distinct feedback signals <inline-formula><mml:math id="inf123"><mml:msub><mml:mi>N</mml:mi><mml:mi>FB</mml:mi></mml:msub></mml:math></inline-formula> and their spatial spread <inline-formula><mml:math id="inf124"><mml:msubsup><mml:mi>Ï</mml:mi><mml:mi>m</mml:mi><mml:mn>2</mml:mn></mml:msubsup></mml:math></inline-formula> (see <xref ref-type="table" rid="table2">Table 2</xref> for a list of network parameters).</p></sec><sec id="s4-2-4"><title>Extension 3: Hierarchical rate-based network</title><p>We further extended the model with spatial modulation (<xref ref-type="disp-formula" rid="equ9">Equation 7</xref>â<xref ref-type="disp-formula" rid="equ13">Equation 10</xref>) to include a two-stage hierarchy, positive rates and synaptic weights that obey Daleâs law. Furthermore, we implemented the feedback modulation as a gain modulation that scales neural rates but keeps them positive. To this end, we modelled the feedforward network as a hierarchy of a lower-level and a higher-level population. Only the higher-level population received feedback modulation. Splitting the neural populations in this way allowed us to model the connections between them with weights that follow Daleâs law. Furthermore, the unmodulated lower-level population could serve as a control for the emergence of context-invariant representations. The lower-level population consisted of <inline-formula><mml:math id="inf125"><mml:mrow><mml:msub><mml:mi>N</mml:mi><mml:mi mathvariant="normal">L</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mn>40</mml:mn></mml:mrow></mml:math></inline-formula> rate-based neurons and the population activity vector was given by<disp-formula id="equ14"><label>(11)</label><mml:math id="m14"><mml:mrow><mml:mrow><mml:mrow><mml:msup><mml:mover accent="true"><mml:mi>z</mml:mi><mml:mo stretchy="false">â</mml:mo></mml:mover><mml:mi mathvariant="normal">L</mml:mi></mml:msup><mml:mo>â¢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mo>=</mml:mo><mml:msub><mml:mrow><mml:mo>[</mml:mo><mml:mrow><mml:msup><mml:mi>W</mml:mi><mml:mi>Lx</mml:mi></mml:msup><mml:mo>â¢</mml:mo><mml:mover accent="true"><mml:mi>x</mml:mi><mml:mo stretchy="false">â</mml:mo></mml:mover><mml:mo>â¢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mo>]</mml:mo></mml:mrow><mml:mo>+</mml:mo></mml:msub></mml:mrow><mml:mo mathvariant="italic" separator="true">â</mml:mo><mml:mo>,</mml:mo></mml:mrow></mml:math></disp-formula></p><p>where <inline-formula><mml:math id="inf126"><mml:msup><mml:mi>W</mml:mi><mml:mi>Lx</mml:mi></mml:msup></mml:math></inline-formula> is a fixed weight matrix, <inline-formula><mml:math id="inf127"><mml:mrow><mml:mover accent="true"><mml:mi>x</mml:mi><mml:mo stretchy="false">â</mml:mo></mml:mover><mml:mo>â¢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> the sensory stimuli, and the rectification <inline-formula><mml:math id="inf128"><mml:mrow><mml:msub><mml:mrow><mml:mo>[</mml:mo><mml:mo>â</mml:mo><mml:mo>]</mml:mo></mml:mrow><mml:mo>+</mml:mo></mml:msub><mml:mo>=</mml:mo><mml:mrow><mml:mi>max</mml:mi><mml:mo>â¡</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:mo>â</mml:mo><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:math></inline-formula> ensures that rates are positive. The lower-level population thus provides a neural representation of the sensory stimuli. The higher-level population consisted of <inline-formula><mml:math id="inf129"><mml:mrow><mml:msub><mml:mi>N</mml:mi><mml:mi mathvariant="normal">H</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mn>100</mml:mn></mml:mrow></mml:math></inline-formula> rate-based neurons that received feedforward input from the lower-level population. The feedforward input consisted of direct excitatory projections as well as feedforward inhibition through a population of <inline-formula><mml:math id="inf130"><mml:mrow><mml:msub><mml:mi>N</mml:mi><mml:mi mathvariant="normal">I</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mn>20</mml:mn></mml:mrow></mml:math></inline-formula> local inhibitory neurons. The activity vector of the higher-level population <inline-formula><mml:math id="inf131"><mml:mrow><mml:msup><mml:mover accent="true"><mml:mi>z</mml:mi><mml:mo stretchy="false">â</mml:mo></mml:mover><mml:mi mathvariant="normal">H</mml:mi></mml:msup><mml:mo>â¢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> was thus given by<disp-formula id="equ15"><label>(12)</label><mml:math id="m15"><mml:mrow><mml:msup><mml:mover accent="true"><mml:mi>z</mml:mi><mml:mo stretchy="false">â</mml:mo></mml:mover><mml:mi mathvariant="normal">H</mml:mi></mml:msup><mml:mo>â¢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mrow><mml:mi/><mml:mo>=</mml:mo><mml:msub><mml:mrow><mml:mo>[</mml:mo><mml:mrow><mml:mrow><mml:mover accent="true"><mml:mi>p</mml:mi><mml:mo stretchy="false">â</mml:mo></mml:mover><mml:mo>â¢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mo>â</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mrow><mml:msup><mml:mi>W</mml:mi><mml:mi>HL</mml:mi></mml:msup><mml:mo>â¢</mml:mo><mml:msup><mml:mover accent="true"><mml:mi>z</mml:mi><mml:mo stretchy="false">â</mml:mo></mml:mover><mml:mi mathvariant="normal">L</mml:mi></mml:msup><mml:mo>â¢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mo>-</mml:mo><mml:mrow><mml:msup><mml:mi>W</mml:mi><mml:mi>HI</mml:mi></mml:msup><mml:mo>â¢</mml:mo><mml:msup><mml:mover accent="true"><mml:mi>z</mml:mi><mml:mo stretchy="false">â</mml:mo></mml:mover><mml:mi mathvariant="normal">I</mml:mi></mml:msup><mml:mo>â¢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mo>]</mml:mo></mml:mrow><mml:mo>+</mml:mo></mml:msub></mml:mrow></mml:math></disp-formula><disp-formula id="equ16"><label>(13)</label><mml:math id="m16"><mml:mrow><mml:msup><mml:mover accent="true"><mml:mi>z</mml:mi><mml:mo stretchy="false">â</mml:mo></mml:mover><mml:mi mathvariant="normal">I</mml:mi></mml:msup><mml:mo>â¢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mrow><mml:mrow><mml:mi/><mml:mo>=</mml:mo><mml:msub><mml:mrow><mml:mo>[</mml:mo><mml:mrow><mml:msup><mml:mi>W</mml:mi><mml:mi>IL</mml:mi></mml:msup><mml:mo>â¢</mml:mo><mml:msup><mml:mover accent="true"><mml:mi>z</mml:mi><mml:mo stretchy="false">â</mml:mo></mml:mover><mml:mi mathvariant="normal">L</mml:mi></mml:msup><mml:mo>â¢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mo>]</mml:mo></mml:mrow><mml:mo>+</mml:mo></mml:msub></mml:mrow><mml:mo mathvariant="italic" separator="true">â</mml:mo><mml:mo>.</mml:mo></mml:mrow></mml:math></disp-formula></p><p>Here, <inline-formula><mml:math id="inf132"><mml:msup><mml:mi>W</mml:mi><mml:mi>HL</mml:mi></mml:msup></mml:math></inline-formula>, <inline-formula><mml:math id="inf133"><mml:msup><mml:mi>W</mml:mi><mml:mi>HI</mml:mi></mml:msup></mml:math></inline-formula>, and <inline-formula><mml:math id="inf134"><mml:msup><mml:mi>W</mml:mi><mml:mi>IL</mml:mi></mml:msup></mml:math></inline-formula> are positive weight matrices, <inline-formula><mml:math id="inf135"><mml:mrow><mml:msup><mml:mover accent="true"><mml:mi>z</mml:mi><mml:mo stretchy="false">â</mml:mo></mml:mover><mml:mi mathvariant="normal">I</mml:mi></mml:msup><mml:mo>â¢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> is the inhibitory neuron activities, and <inline-formula><mml:math id="inf136"><mml:mrow><mml:mover accent="true"><mml:mi>p</mml:mi><mml:mo stretchy="false">â</mml:mo></mml:mover><mml:mo>â¢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> is the neuron-specific gain modulation factors. As for the spatially modulated network of Extension 2, the network output <inline-formula><mml:math id="inf137"><mml:mrow><mml:mover accent="true"><mml:mi>y</mml:mi><mml:mo stretchy="false">â</mml:mo></mml:mover><mml:mo>â¢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> was determined by a fixed linear readout <inline-formula><mml:math id="inf138"><mml:msup><mml:mi>W</mml:mi><mml:mi>ro</mml:mi></mml:msup></mml:math></inline-formula> (see <xref ref-type="disp-formula" rid="equ10">Equation 8</xref>). The distributions used to randomly initialise the weight matrices are provided in <xref ref-type="table" rid="table3">Table 3</xref>.</p><table-wrap id="table3" position="float"><label>Table 3.</label><caption><title>Distributions used for randomly initialised weight parameters.</title></caption><table frame="hsides" rules="groups"><thead><tr><th align="left" valign="bottom">Weights</th><th align="center" valign="bottom">Distribution</th></tr></thead><tbody><tr><td align="left" valign="bottom"><inline-formula><mml:math id="inf139"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>W</mml:mi><mml:mn>0</mml:mn></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula></td><td align="center" valign="bottom"><inline-formula><mml:math id="inf140"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mrow><mml:mi mathvariant="script">N</mml:mi></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mn>0.001</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mstyle></mml:math></inline-formula></td></tr><tr><td align="left" valign="bottom"><inline-formula><mml:math id="inf141"><mml:msup><mml:mi>W</mml:mi><mml:mi mathvariant="normal">x</mml:mi></mml:msup></mml:math></inline-formula></td><td align="center" valign="bottom"><inline-formula><mml:math id="inf142"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mrow><mml:mi mathvariant="script">N</mml:mi></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:mn>0.5</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mstyle></mml:math></inline-formula></td></tr><tr><td align="left" valign="bottom"><inline-formula><mml:math id="inf143"><mml:msup><mml:mi>W</mml:mi><mml:mi>Lx</mml:mi></mml:msup></mml:math></inline-formula></td><td align="center" valign="bottom"><inline-formula><mml:math id="inf144"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mrow><mml:mi mathvariant="script">N</mml:mi></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:mn>0.5</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mstyle></mml:math></inline-formula></td></tr><tr><td align="left" valign="bottom"><inline-formula><mml:math id="inf145"><mml:msup><mml:mi>W</mml:mi><mml:mi>ro</mml:mi></mml:msup></mml:math></inline-formula></td><td align="center" valign="bottom"><inline-formula><mml:math id="inf146"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mrow><mml:mi mathvariant="script">N</mml:mi></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:mn>0.5</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mstyle></mml:math></inline-formula></td></tr><tr><td align="left" valign="bottom"><inline-formula><mml:math id="inf147"><mml:msup><mml:mi>W</mml:mi><mml:mi>HL</mml:mi></mml:msup></mml:math></inline-formula></td><td align="center" valign="bottom"><inline-formula><mml:math id="inf148"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mrow><mml:mi mathvariant="script">N</mml:mi></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mn>0.5</mml:mn><mml:mo stretchy="false">)</mml:mo><mml:mo>â</mml:mo><mml:mn>20</mml:mn><mml:mrow><mml:mo>/</mml:mo></mml:mrow><mml:msub><mml:mi>N</mml:mi><mml:mrow><mml:mrow><mml:mi mathvariant="normal">H</mml:mi></mml:mrow></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula></td></tr><tr><td align="left" valign="bottom"><inline-formula><mml:math id="inf149"><mml:msup><mml:mi>W</mml:mi><mml:mi>IL</mml:mi></mml:msup></mml:math></inline-formula></td><td align="center" valign="bottom"><inline-formula><mml:math id="inf150"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mrow><mml:mi mathvariant="script">N</mml:mi></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mn>0.5</mml:mn><mml:mo stretchy="false">)</mml:mo><mml:mrow><mml:mo>/</mml:mo></mml:mrow><mml:msub><mml:mi>N</mml:mi><mml:mrow><mml:mrow><mml:mi mathvariant="normal">I</mml:mi></mml:mrow></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula></td></tr><tr><td align="left" valign="bottom"><inline-formula><mml:math id="inf151"><mml:msup><mml:mi>W</mml:mi><mml:mi>HI</mml:mi></mml:msup></mml:math></inline-formula></td><td align="center" valign="bottom"><inline-formula><mml:math id="inf152"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mrow><mml:mi mathvariant="script">N</mml:mi></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">)</mml:mo><mml:mo>â</mml:mo><mml:mn>20</mml:mn><mml:mrow><mml:mo>/</mml:mo></mml:mrow><mml:msub><mml:mi>N</mml:mi><mml:mrow><mml:mrow><mml:mi mathvariant="normal">H</mml:mi></mml:mrow></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula></td></tr><tr><td align="left" valign="bottom">Long-short-term memory network parameters</td><td align="center" valign="bottom"><inline-formula><mml:math id="inf153"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mrow><mml:mi mathvariant="script">U</mml:mi></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mo>â</mml:mo><mml:msqrt><mml:mn>1</mml:mn><mml:mrow><mml:mo>/</mml:mo></mml:mrow><mml:msub><mml:mi>N</mml:mi><mml:mrow><mml:mrow><mml:mi mathvariant="normal">H</mml:mi></mml:mrow></mml:mrow></mml:msub></mml:msqrt><mml:mo>,</mml:mo><mml:msqrt><mml:mn>1</mml:mn><mml:mrow><mml:mo>/</mml:mo></mml:mrow><mml:msub><mml:mi>N</mml:mi><mml:mrow><mml:mrow><mml:mi mathvariant="normal">H</mml:mi></mml:mrow></mml:mrow></mml:msub></mml:msqrt><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mstyle></mml:math></inline-formula></td></tr><tr><td align="left" valign="bottom">Long-short-term memory network readout</td><td align="center" valign="bottom"><inline-formula><mml:math id="inf154"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mrow><mml:mi mathvariant="script">U</mml:mi></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mo>â</mml:mo><mml:msqrt><mml:mn>1</mml:mn><mml:mrow><mml:mo>/</mml:mo></mml:mrow><mml:msub><mml:mi>N</mml:mi><mml:mrow><mml:mrow><mml:mi mathvariant="normal">F</mml:mi><mml:mi mathvariant="normal">B</mml:mi></mml:mrow></mml:mrow></mml:msub></mml:msqrt><mml:mo>,</mml:mo><mml:msqrt><mml:mn>1</mml:mn><mml:mrow><mml:mo>/</mml:mo></mml:mrow><mml:msub><mml:mi>N</mml:mi><mml:mrow><mml:mrow><mml:mi mathvariant="normal">F</mml:mi><mml:mi mathvariant="normal">B</mml:mi></mml:mrow></mml:mrow></mml:msub></mml:msqrt><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mstyle></mml:math></inline-formula></td></tr></tbody></table></table-wrap><p>Again, the modulation was driven by feedback from the LSTM, but in this model variant we assumed inhibitory feedback, that is, stronger feedback signals monotonically decreased the gain. More specifically, we assumed that the feedback signal targets a population of modulation units <inline-formula><mml:math id="inf155"><mml:mover accent="true"><mml:mi>m</mml:mi><mml:mo stretchy="false">â</mml:mo></mml:mover></mml:math></inline-formula>, which in turn modulate the gain in the higher-level population. The gain modulation of neuron <inline-formula><mml:math id="inf156"><mml:mi>i</mml:mi></mml:math></inline-formula> was constrained between 0 and 1 and determined by<disp-formula id="equ17"><label>(14)</label><mml:math id="m17"><mml:mrow><mml:mrow><mml:msub><mml:mi>p</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>â¢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mo>=</mml:mo><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mfrac><mml:mn>1</mml:mn><mml:mrow><mml:mn>1</mml:mn><mml:mo>+</mml:mo><mml:mrow><mml:mi>exp</mml:mi><mml:mo>â¡</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>m</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>â¢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:mfrac></mml:mstyle></mml:mrow></mml:math></disp-formula></p><p>with <inline-formula><mml:math id="inf157"><mml:mrow><mml:msub><mml:mi>m</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>â¢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> being the activity of a modulation unit <inline-formula><mml:math id="inf158"><mml:mi>i</mml:mi></mml:math></inline-formula>, which follows the same dynamics as in <xref ref-type="disp-formula" rid="equ11">Equation 9a</xref> (see <xref ref-type="fig" rid="fig6">Figure 6a</xref>).</p></sec><sec id="s4-2-5"><title>Training the model</title><p>We used gradient descent to find the model parameters that minimise the difference between the source signal <inline-formula><mml:math id="inf159"><mml:mrow><mml:mover accent="true"><mml:mi>s</mml:mi><mml:mo stretchy="false">â</mml:mo></mml:mover><mml:mo>â¢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> and the feedforward networkâs output <inline-formula><mml:math id="inf160"><mml:mrow><mml:mover accent="true"><mml:mi>y</mml:mi><mml:mo stretchy="false">â</mml:mo></mml:mover><mml:mo>â¢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula>:<disp-formula id="equ18"><label>(15)</label><mml:math id="m18"><mml:mrow><mml:mi class="ltx_font_mathcaligraphic">â</mml:mi><mml:mo>=</mml:mo><mml:mrow><mml:mstyle displaystyle="true" scriptlevel="0"><mml:munderover><mml:mo largeop="true" movablelimits="false" symmetric="true">â</mml:mo><mml:mrow><mml:mi>t</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:msub><mml:mi>n</mml:mi><mml:mi>t</mml:mi></mml:msub></mml:munderover></mml:mstyle><mml:mrow><mml:mi>dist</mml:mi><mml:mo>â¢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mover accent="true"><mml:mi>s</mml:mi><mml:mo stretchy="false">â</mml:mo></mml:mover><mml:mo>â¢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mo>,</mml:mo><mml:mrow><mml:mover accent="true"><mml:mi>y</mml:mi><mml:mo stretchy="false">â</mml:mo></mml:mover><mml:mo>â¢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:mrow></mml:math></disp-formula></p><p>with a distance measure <inline-formula><mml:math id="inf161"><mml:mrow><mml:mi>dist</mml:mi><mml:mo>â¢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mo>â</mml:mo><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula>. We used the machine learning framework PyTorch (<xref ref-type="bibr" rid="bib68">Paszke et al., 2019</xref>) to simulate the network model, obtain the gradients of the objective <inline-formula><mml:math id="inf162"><mml:mi class="ltx_font_mathcaligraphic">â</mml:mi></mml:math></inline-formula> by automatic differentiation, and update the parameters of the LSTM using the Adam optimiser (<xref ref-type="bibr" rid="bib43">Kingma and Ba, 2014</xref>) with a learning rate of <inline-formula><mml:math id="inf163"><mml:mrow><mml:mi>Î·</mml:mi><mml:mo>=</mml:mo><mml:msup><mml:mn>10</mml:mn><mml:mrow><mml:mo>-</mml:mo><mml:mn>3</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:math></inline-formula>. As distance measure in the objective, we used a smooth variant of the L1 norm (PyTorchâs smooth L1 loss variant) because it is less sensitive to outliers than the mean squared error (<xref ref-type="bibr" rid="bib36">Huber, 1964</xref>).</p><p>During training, we simulated the network dynamics over batches of 32 trials using forward Euler with a time step of <inline-formula><mml:math id="inf164"><mml:mrow><mml:mrow><mml:mi mathvariant="normal">Î</mml:mi><mml:mo>â¢</mml:mo><mml:mi>t</mml:mi></mml:mrow><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:math></inline-formula>. Each trial consisted of <italic>n</italic><sub><italic>t</italic></sub> time steps (i.e. samples) and the context (i.e. mixing matrix) differed between trials. Since the model contains feedback and recurrent connections, we trained it using backpropagation through time (<xref ref-type="bibr" rid="bib95">Werbos, 1990</xref>). This means that for each trial we simulated the model and computed the loss for every time step. At the end of the trial, we propagated the error through the <italic>n</italic><sub><italic>t</italic></sub> steps of the model to obtain the gradients and updated the parameters accordingly (<xref ref-type="fig" rid="fig8">Figure 8</xref>). Although the source signals were the same in every trial, we varied their phase independently across trials to prevent the LSTM from learning the exact signal sequence. To this end, we generated 16,000 samples of the source signals and in every batch randomly selected chunks of <italic>n</italic><sub><italic>t</italic></sub> samples independently from each source. Model parameters were initialised according to the distributions listed in <xref ref-type="table" rid="table3">Table 3</xref>.</p><p>In all model variants, we optimised the parameters of the modulator (input, recurrent, and readout weights as well as the biases of the LSTM; see <xref ref-type="disp-formula" rid="equ7">Equation 5</xref> and <xref ref-type="disp-formula" rid="equ12">Equation 9b</xref>). The parameters were initialised with the defaults from the corresponding PyTorch modules, as listed in <xref ref-type="table" rid="table3">Table 3</xref>. To facilitate the training in the hierarchical rate-based network despite additional constraints, we also optimised the feedforward weights <inline-formula><mml:math id="inf165"><mml:msup><mml:mi>W</mml:mi><mml:mi>HL</mml:mi></mml:msup></mml:math></inline-formula>, <inline-formula><mml:math id="inf166"><mml:msup><mml:mi>W</mml:mi><mml:mi>HI</mml:mi></mml:msup></mml:math></inline-formula>, <inline-formula><mml:math id="inf167"><mml:msup><mml:mi>W</mml:mi><mml:mi>IL</mml:mi></mml:msup></mml:math></inline-formula>, <inline-formula><mml:math id="inf168"><mml:msup><mml:mi>W</mml:mi><mml:mi>Lx</mml:mi></mml:msup></mml:math></inline-formula>, and <inline-formula><mml:math id="inf169"><mml:msup><mml:mi>W</mml:mi><mml:mi>ro</mml:mi></mml:msup></mml:math></inline-formula>. In principle, this allows to adapt the representation in the two intermediate layers such that the modulation is most effective. However, although we did not quantify it, we observed that optimising the network readout <inline-formula><mml:math id="inf170"><mml:msup><mml:mi>W</mml:mi><mml:mi>ro</mml:mi></mml:msup></mml:math></inline-formula> facilitated the training the most, suggesting that a specific format of the sensory representations was not required for an effective modulation.</p><p>To prevent the gain modulation factor from saturating at 0 or 1, we added a regularisation term <inline-formula><mml:math id="inf171"><mml:mi class="ltx_font_mathcaligraphic">â</mml:mi></mml:math></inline-formula> to the loss function <xref ref-type="disp-formula" rid="equ18">Equation 15</xref> that keeps the LSTMâs output small:<disp-formula id="equ19"><label>(16)</label><mml:math id="m19"><mml:mrow><mml:mi class="ltx_font_mathcaligraphic">â</mml:mi><mml:mo>=</mml:mo><mml:mrow><mml:msub><mml:mi>Î»</mml:mi><mml:mi>out</mml:mi></mml:msub><mml:mo>â¢</mml:mo><mml:mrow><mml:mstyle displaystyle="true" scriptlevel="0"><mml:munderover><mml:mo largeop="true" movablelimits="false" symmetric="true">â</mml:mo><mml:mrow><mml:mi>t</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:msub><mml:mi>n</mml:mi><mml:mi>t</mml:mi></mml:msub></mml:munderover></mml:mstyle><mml:mrow><mml:mstyle displaystyle="true" scriptlevel="0"><mml:munderover><mml:mo largeop="true" movablelimits="false" symmetric="true">â</mml:mo><mml:mrow><mml:mi>j</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:msub><mml:mi>N</mml:mi><mml:mi>FB</mml:mi></mml:msub></mml:munderover></mml:mstyle><mml:mrow><mml:mo maxsize="120%" minsize="120%">|</mml:mo><mml:mrow><mml:mi>LSTM</mml:mi><mml:mo>â¢</mml:mo><mml:msub><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mi>x</mml:mi><mml:mo>â¢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mo>,</mml:mo><mml:mrow><mml:mi>y</mml:mi><mml:mo>â¢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mi>j</mml:mi></mml:msub></mml:mrow><mml:mo maxsize="120%" minsize="120%">|</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:mrow></mml:mrow></mml:math></disp-formula></p><p>with <inline-formula><mml:math id="inf172"><mml:mrow><mml:msub><mml:mi>Î»</mml:mi><mml:mi>out</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:msup><mml:mn>10</mml:mn><mml:mrow><mml:mo>-</mml:mo><mml:mn>5</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:math></inline-formula>.</p><p>Gradient values were clipped between â1 and 1 before each update to avoid large updates. For weights that were constrained to be positive, we used their absolute value in the model. Each network was trained for 10,000â12,000 batches and for 5 random initialisations (<xref ref-type="fig" rid="fig1s2">Figure 1âfigure supplement 2</xref>).</p></sec><sec id="s4-2-6"><title>Testing and manipulating the model</title><p>We tested the network model performance on an independent random set of contexts (i.e. mixing matrices), but with the same source signals as during training. During testing, we also changed the context every <italic>n</italic><sub><italic>t</italic></sub> steps, but the length of this interval was not crucial for performance (<xref ref-type="fig" rid="fig1s1">Figure 1âfigure supplement 1d</xref>).</p><p>To manipulate the feedback modulation in the hierarchical rate-based network (<xref ref-type="fig" rid="fig4">Figure 4</xref>), we provided an additional input to the modulation units <inline-formula><mml:math id="inf173"><mml:mi>m</mml:mi></mml:math></inline-formula> in <xref ref-type="disp-formula" rid="equ11">Equation 9a</xref>. We used an input of 3 or â3 depending on whether the modulation units were activated or inactivated, respectively. To freeze the feedback modulation (<xref ref-type="fig" rid="fig6">Figure 6</xref>), we discarded the feedback signal and held the local modulation <inline-formula><mml:math id="inf174"><mml:mi>p</mml:mi></mml:math></inline-formula> in <xref ref-type="disp-formula" rid="equ17">Equation 14</xref> at a constant value determined by the feedback before the manipulation. The dynamics of the LSTM were continued, but remained hidden to the feedforward network until the freezing was stopped.</p></sec></sec><sec id="s4-3"><title>Unmodulated feedforward network models</title><sec id="s4-3-1"><title>Linear regression</title><p>As a control, we trained feedforward networks with weights that were not changed by a modulatory system. First, we used the simplest possible network architecture, in which the sensory stimuli are linearly mapped to the outputs (<xref ref-type="fig" rid="fig1s1">Figure 1âfigure supplement 1a</xref>):<disp-formula id="equ20"><label>(17)</label><mml:math id="m20"><mml:mrow><mml:mrow><mml:mrow><mml:mi>y</mml:mi><mml:mo>â¢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mo>=</mml:mo><mml:mrow><mml:mi>W</mml:mi><mml:mo>â¢</mml:mo><mml:mi>x</mml:mi><mml:mo>â¢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:mrow><mml:mo>.</mml:mo></mml:mrow></mml:math></disp-formula></p><p>It is intuitive that a fixed set of weights <inline-formula><mml:math id="inf175"><mml:mi>W</mml:mi></mml:math></inline-formula> cannot invert two different contexts (i.e. different mixing matrices <italic>A</italic><sub>1</sub> and <italic>A</italic><sub>2</sub>). As an illustration, we trained this simple feedforward network on one context and tested it on different contexts. To find the weights <inline-formula><mml:math id="inf176"><mml:mi>W</mml:mi></mml:math></inline-formula>, we used linear regression to minimise the mean squared error between the source signal <inline-formula><mml:math id="inf177"><mml:mrow><mml:mi>s</mml:mi><mml:mo>â¢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> and the networkâs output <inline-formula><mml:math id="inf178"><mml:mrow><mml:mi>y</mml:mi><mml:mo>â¢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula>. The training data consisted of 1024 consecutive time steps of the sensory stimuli for a fixed context, and the test data consisted of different 1024 time steps generated under a potentially different mixing. We repeated this procedure by training and testing a network for all combinations of 20 random contexts.</p></sec><sec id="s4-3-2"><title>Multilayer nonlinear network</title><p>Since solving the task was not possible with a single set of readout weights, we extended the feedforward model to include three hidden layers consisting of 32, 16, and 8 rectified linear units (<xref ref-type="fig" rid="fig1s1">Figure 1âfigure supplement 1d</xref>). The input to this network was one time point from the sensory stimuli and the target output the corresponding time point of the sources. We trained the multilayer network on 5000 batches of 32 contexts using Adam (learning rate 0.001) to minimise the mean squared error between the network output and the sources.</p></sec><sec id="s4-3-3"><title>Multilayer network with sequences as input</title><p>Solving the task requires the network to map the same sensory stimulus to different outputs depending on the context. However, inferring the context takes more than one time point. To test if a feedforward network with access to multiple time points at once could in principle solve the task, we changed the architecture of the multilayer network, such that it receives a sequence of the sensory stimuli (<xref ref-type="fig" rid="fig1s1">Figure 1âfigure supplement 1g</xref>). The output of the network was a sequence of equal length. We again trained this network on 5000 batches of 32 contexts to minimise the error between its output and the target sources, where both the network input and output were sequences. The length of these sequences was varied between 1 and 150.</p></sec></sec><sec id="s4-4"><title>Data analysis</title><sec id="s4-4-1"><title>Signal clarity</title><p>To determine task performance, we measured how clear the representation of the source signals is in the network output. We first computed the correlation coefficient of each signal <italic>s</italic><sub><italic>i</italic></sub> with each output <italic>y</italic><sub><italic>j</italic></sub><disp-formula id="equ21"><label>(18)</label><mml:math id="m21"><mml:mrow><mml:mrow><mml:msub><mml:mi>r</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo>â¢</mml:mo><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mfrac><mml:mrow><mml:msub><mml:mo largeop="true" symmetric="true">â</mml:mo><mml:mi>t</mml:mi></mml:msub><mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mrow><mml:msub><mml:mi>s</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>â¢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mo>-</mml:mo><mml:msub><mml:mover accent="true"><mml:mi>s</mml:mi><mml:mo stretchy="false">Â¯</mml:mo></mml:mover><mml:mi>i</mml:mi></mml:msub></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>â¢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mrow><mml:msub><mml:mi>y</mml:mi><mml:mi>j</mml:mi></mml:msub><mml:mo>â¢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mo>-</mml:mo><mml:msub><mml:mover accent="true"><mml:mi>y</mml:mi><mml:mo stretchy="false">Â¯</mml:mo></mml:mover><mml:mi>j</mml:mi></mml:msub></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:mrow><mml:mrow><mml:msub><mml:mi>Ï</mml:mi><mml:mrow><mml:mi>s</mml:mi><mml:mo>,</mml:mo><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>â¢</mml:mo><mml:msub><mml:mi>Ï</mml:mi><mml:mrow><mml:mi>y</mml:mi><mml:mo>,</mml:mo><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfrac></mml:mstyle></mml:mrow><mml:mo mathvariant="italic" separator="true">â</mml:mo><mml:mo>,</mml:mo></mml:mrow></mml:math></disp-formula></p><p>where <inline-formula><mml:math id="inf179"><mml:msub><mml:mover accent="true"><mml:mi>s</mml:mi><mml:mo stretchy="false">Â¯</mml:mo></mml:mover><mml:mi>i</mml:mi></mml:msub></mml:math></inline-formula> and <inline-formula><mml:math id="inf180"><mml:msub><mml:mover accent="true"><mml:mi>y</mml:mi><mml:mo stretchy="false">Â¯</mml:mo></mml:mover><mml:mi>j</mml:mi></mml:msub></mml:math></inline-formula> are the respective temporal mean and <inline-formula><mml:math id="inf181"><mml:msub><mml:mi>Ï</mml:mi><mml:mrow><mml:mi>s</mml:mi><mml:mo>,</mml:mo><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> and <inline-formula><mml:math id="inf182"><mml:msub><mml:mi>Ï</mml:mi><mml:mrow><mml:mi>y</mml:mi><mml:mo>,</mml:mo><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> the respective temporal standard deviations. The signal clarity in output <italic>y</italic><sub><italic>j</italic></sub> is then given by the absolute difference between the absolute correlation with one compared to the other signal:<disp-formula id="equ22"><label>(19)</label><mml:math id="m22"><mml:mrow><mml:mrow><mml:msub><mml:mi>c</mml:mi><mml:mi>j</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mrow><mml:mo rspace="7.5pt" stretchy="false">|</mml:mo><mml:mrow><mml:mrow><mml:mo stretchy="false">|</mml:mo><mml:msub><mml:mi>r</mml:mi><mml:mrow><mml:mn>1</mml:mn><mml:mo>â¢</mml:mo><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mo>-</mml:mo><mml:mrow><mml:mo stretchy="false">|</mml:mo><mml:msub><mml:mi>r</mml:mi><mml:mrow><mml:mn>2</mml:mn><mml:mo>â¢</mml:mo><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo rspace="7.5pt" stretchy="false">|</mml:mo></mml:mrow></mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow></mml:mrow><mml:mo mathvariant="italic" separator="true">â</mml:mo><mml:mo>.</mml:mo></mml:mrow></mml:math></disp-formula></p><p>By averaging over outputs, we determined the overall signal clarity within the output. Note that the same measure can be computed on other processing stages of the feedforward network. For instance, we used the signal clarity of sources in the sensory stimuli as a baseline control.</p></sec><sec id="s4-4-2"><title>Signal-to-noise ratio</title><p>The signal-to-noise ratio in the sensory stimuli was determined as the variability in the signal compared to the noise. Since the mean of both the stimuli and the noise was zero, the signal-to-noise ratio could be computed by<disp-formula id="equ23"><mml:math id="m23"><mml:mrow><mml:mrow><mml:mi>SNR</mml:mi><mml:mo>=</mml:mo><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mfrac><mml:msubsup><mml:mi>Ï</mml:mi><mml:mi>s</mml:mi><mml:mn>2</mml:mn></mml:msubsup><mml:msubsup><mml:mi>Ï</mml:mi><mml:mi>n</mml:mi><mml:mn>2</mml:mn></mml:msubsup></mml:mfrac></mml:mstyle></mml:mrow><mml:mo mathvariant="italic" separator="true">â</mml:mo><mml:mo>,</mml:mo></mml:mrow></mml:math></disp-formula></p><p>where <inline-formula><mml:math id="inf183"><mml:msub><mml:mi>Ï</mml:mi><mml:mi>n</mml:mi></mml:msub></mml:math></inline-formula> is the standard deviation of the additive white noise and <inline-formula><mml:math id="inf184"><mml:msub><mml:mi>Ï</mml:mi><mml:mi>s</mml:mi></mml:msub></mml:math></inline-formula> is the measured standard deviation in the noise-free sensory stimuli, which was around 0.32. As a scale of the signal-to-noise ratio, we used decibels (<inline-formula><mml:math id="inf185"><mml:mi>dB</mml:mi></mml:math></inline-formula>), that is, we used <inline-formula><mml:math id="inf186"><mml:mrow><mml:mi>dB</mml:mi><mml:mo>=</mml:mo><mml:mrow><mml:mn>10</mml:mn><mml:mo>â¢</mml:mo><mml:mrow><mml:msub><mml:mi>log</mml:mi><mml:mn>10</mml:mn></mml:msub><mml:mo>â¡</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>SNR</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:mrow></mml:math></inline-formula>.</p></sec></sec><sec id="s4-5"><title>Linear decoding analysis</title><sec id="s4-5-1"><title>Signal decoding</title><p>We investigated the population-level invariance by using a linear decoding approach. If there was an invariant population subspace, the source signals could be decoded by the same decoder across different contexts. We therefore performed linear regression between the activity in a particular population and the source signals. This linear decoder was trained on <inline-formula><mml:math id="inf187"><mml:mrow><mml:msub><mml:mi>n</mml:mi><mml:mi>c</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mn>10</mml:mn></mml:mrow></mml:math></inline-formula> different contexts with <inline-formula><mml:math id="inf188"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>n</mml:mi><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mn>000</mml:mn></mml:mrow></mml:mstyle></mml:math></inline-formula> time points each, such that the total number of samples was 10,000. The linear decoding was then tested on 10 new contexts and the performance determined using the R<sup>2</sup> measure.</p></sec><sec id="s4-5-2"><title>Context decoding</title><p>We took a similar approach to determine from which populations the context could be decoded. For the dynamic blind source separation task, the context is given by the source mixture, as determined by the mixing matrix. Since we normalised the rows of each mixing matrix, the context was determined by two context variables. We calculated the temporal average of the neuronal activities within each context and performed a linear regression of the context variables onto these averages. To exclude onset transients, we only considered the second half (500 samples) of every context. Contexts were sampled from the two-dimensional grid of potential contexts. More specifically, we sampled 20 points along each dimension and excluded contexts, in which the sensory stimuli were too similar (analogously to the generation of mixing matrices), leaving 272 different contexts (see <xref ref-type="fig" rid="fig7">Figure 7c</xref>, right). The linear decoding performance was determined with a fivefold cross-validation and measured using R<sup>2</sup>. Since the modulatory feedback signals depend nonlinearly on the context (<xref ref-type="fig" rid="fig7">Figure 7c</xref>), we tested two nonlinear versions of the decoding approach. First, we performed a quadratic expansion of the averaged population activity before a linear decoding. Second, we tested a linear decoding of the inverse mixing matrix (four weights) instead of the two variables determining the context.</p></sec></sec><sec id="s4-6"><title>Population subspace analysis</title><p>We visualised the invariant population subspaces by projecting the activity vector onto the two readout dimensions and the first principal component. To measure how the orientation of the subspaces changes when the context or feedback changes, we computed the angle between the planes spanned by the respective subspaces. These planes were fitted on the three-dimensional data described above using the least-squares method. Since we were only interested in the relative orientation of the subspaces, we used a circular measure of the angles, such that a rotation of 180Â° corresponded to 0Â°. This means that angles could range between 0 and 90Â°.</p></sec><sec id="s4-7"><title>Code availability</title><p>The code for models and data analysis is publicly available under <ext-link ext-link-type="uri" xlink:href="https://github.com/sprekelerlab/feedback_modulation_Naumann22">https://github.com/sprekelerlab/feedback_modulation_Naumann22</ext-link>, (copy archived at <ext-link ext-link-type="uri" xlink:href="https://archive.softwareheritage.org/swh:1:dir:ee3aa6ce292eea649252b7f5b3175b3561e7d8ed;origin=https://github.com/sprekelerlab/feedback_modulation_Naumann22;visit=swh:1:snp:7225dc0edc82b286290d94bb47dd51093317e3dc;anchor=swh:1:rev:05373b093803e464082ad5b9e8ab2dbbf43bb23e">swh:1:rev:05373b093803e464082ad5b9e8ab2dbbf43bb23e</ext-link>; <xref ref-type="bibr" rid="bib60">Naumann, 2022</xref>).</p></sec></sec></body><back><sec id="s5" sec-type="additional-information"><title>Additional information</title><fn-group content-type="competing-interest"><title>Competing interests</title><fn fn-type="COI-statement" id="conf1"><p>No competing interests declared</p></fn><fn fn-type="COI-statement" id="conf2"><p>No competing interests declared</p></fn></fn-group><fn-group content-type="author-contribution"><title>Author contributions</title><fn fn-type="con" id="con1"><p>Conceptualization, Formal analysis, Investigation, Methodology, Project administration, Software, Visualization, Writing â original draft, Writing â review and editing</p></fn><fn fn-type="con" id="con2"><p>Conceptualization, Methodology, Project administration, Supervision, Writing â original draft, Writing â review and editing</p></fn><fn fn-type="con" id="con3"><p>Conceptualization, Funding acquisition, Methodology, Project administration, Resources, Supervision, Writing â original draft, Writing â review and editing</p></fn></fn-group></sec><sec id="s6" sec-type="supplementary-material"><title>Additional files</title><supplementary-material id="mdar"><label>MDAR checklist</label><media mime-subtype="docx" mimetype="application" xlink:href="elife-76096-mdarchecklist1-v2.docx"/></supplementary-material></sec><sec id="s7" sec-type="data-availability"><title>Data availability</title><p>The current manuscript is a computational study, so no data have been generated for this manuscript. Modelling code is available under <ext-link ext-link-type="uri" xlink:href="https://github.com/sprekelerlab/feedback_modulation_Naumann21">https://github.com/sprekelerlab/feedback_modulation_Naumann21</ext-link>, (copy archived at <ext-link ext-link-type="uri" xlink:href="https://archive.softwareheritage.org/swh:1:dir:ee3aa6ce292eea649252b7f5b3175b3561e7d8ed;origin=https://github.com/sprekelerlab/feedback_modulation_Naumann22;visit=swh:1:snp:7225dc0edc82b286290d94bb47dd51093317e3dc;anchor=swh:1:rev:05373b093803e464082ad5b9e8ab2dbbf43bb23e">swh:1:rev:05373b093803e464082ad5b9e8ab2dbbf43bb23e</ext-link>) upon publication.</p></sec><ack id="ack"><title>Acknowledgements</title><p>We thank Owen Mackwood for providing a code framework that manages simulations on a compute cluster, Loreen HertÃ¤g and Johannes Letzkus for feedback on the manuscript, and the members of the Sprekeler lab for valuable discussions. No external funding was received for this work.</p></ack><ref-list><title>References</title><ref id="bib1"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Abs</surname><given-names>E</given-names></name><name><surname>Poorthuis</surname><given-names>RB</given-names></name><name><surname>Apelblat</surname><given-names>D</given-names></name><name><surname>Muhammad</surname><given-names>K</given-names></name><name><surname>Pardi</surname><given-names>MB</given-names></name><name><surname>Enke</surname><given-names>L</given-names></name><name><surname>Kushinsky</surname><given-names>D</given-names></name><name><surname>Pu</surname><given-names>DL</given-names></name><name><surname>Eizinger</surname><given-names>MF</given-names></name><name><surname>Conzelmann</surname><given-names>KK</given-names></name><name><surname>Spiegel</surname><given-names>I</given-names></name><name><surname>Letzkus</surname><given-names>JJ</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>Learning-Related Plasticity in Dendrite-Targeting Layer 1 Interneurons</article-title><source>Neuron</source><volume>100</volume><fpage>684</fpage><lpage>699</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2018.09.001</pub-id><pub-id pub-id-type="pmid">30269988</pub-id></element-citation></ref><ref id="bib2"><element-citation publication-type="preprint"><person-group person-group-type="author"><name><surname>Alamia</surname><given-names>A</given-names></name><name><surname>Mozafari</surname><given-names>M</given-names></name><name><surname>Choksi</surname><given-names>B</given-names></name><name><surname>VanRullen</surname><given-names>R</given-names></name></person-group><year iso-8601-date="2021">2021</year><article-title>On the Role of Feedback in Visual Processing: A Predictive Coding Perspective</article-title><source>arXiv</source><ext-link ext-link-type="uri" xlink:href="https://arxiv.org/abs/2106.04225">https://arxiv.org/abs/2106.04225</ext-link></element-citation></ref><ref id="bib3"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Azimi</surname><given-names>Z</given-names></name><name><surname>Barzan</surname><given-names>R</given-names></name><name><surname>Spoida</surname><given-names>K</given-names></name><name><surname>Surdin</surname><given-names>T</given-names></name><name><surname>Wollenweber</surname><given-names>P</given-names></name><name><surname>Mark</surname><given-names>MD</given-names></name><name><surname>Herlitze</surname><given-names>S</given-names></name><name><surname>Jancke</surname><given-names>D</given-names></name></person-group><year iso-8601-date="2020">2020</year><article-title>Separable gain control of ongoing and evoked activity in the visual cortex by serotonergic input</article-title><source>eLife</source><volume>9</volume><elocation-id>e53552</elocation-id><pub-id pub-id-type="doi">10.7554/eLife.53552</pub-id><pub-id pub-id-type="pmid">32252889</pub-id></element-citation></ref><ref id="bib4"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bang</surname><given-names>D</given-names></name><name><surname>Kishida</surname><given-names>KT</given-names></name><name><surname>Lohrenz</surname><given-names>T</given-names></name><name><surname>White</surname><given-names>JP</given-names></name><name><surname>Laxton</surname><given-names>AW</given-names></name><name><surname>Tatter</surname><given-names>SB</given-names></name><name><surname>Fleming</surname><given-names>SM</given-names></name><name><surname>Montague</surname><given-names>PR</given-names></name></person-group><year iso-8601-date="2020">2020</year><article-title>Sub-second Dopamine and Serotonin Signaling in Human Striatum during Perceptual Decision-Making</article-title><source>Neuron</source><volume>108</volume><fpage>999</fpage><lpage>1010</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2020.09.015</pub-id><pub-id pub-id-type="pmid">33049201</pub-id></element-citation></ref><ref id="bib5"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bayer</surname><given-names>HM</given-names></name><name><surname>Glimcher</surname><given-names>PW</given-names></name></person-group><year iso-8601-date="2005">2005</year><article-title>Midbrain dopamine neurons encode a quantitative reward prediction error signal</article-title><source>Neuron</source><volume>47</volume><fpage>129</fpage><lpage>141</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2005.05.020</pub-id><pub-id pub-id-type="pmid">15996553</pub-id></element-citation></ref><ref id="bib6"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bell</surname><given-names>AJ</given-names></name><name><surname>Sejnowski</surname><given-names>TJ</given-names></name></person-group><year iso-8601-date="1995">1995</year><article-title>An information-maximization approach to blind separation and blind deconvolution</article-title><source>Neural Computation</source><volume>7</volume><fpage>1129</fpage><lpage>1159</lpage><pub-id pub-id-type="doi">10.1162/neco.1995.7.6.1129</pub-id><pub-id pub-id-type="pmid">7584893</pub-id></element-citation></ref><ref id="bib7"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bengio</surname><given-names>Y</given-names></name><name><surname>Simard</surname><given-names>P</given-names></name><name><surname>Frasconi</surname><given-names>P</given-names></name></person-group><year iso-8601-date="1994">1994</year><article-title>Learning long-term dependencies with gradient descent is difficult</article-title><source>IEEE Transactions on Neural Networks</source><volume>5</volume><fpage>157</fpage><lpage>166</lpage><pub-id pub-id-type="doi">10.1109/72.279181</pub-id><pub-id pub-id-type="pmid">18267787</pub-id></element-citation></ref><ref id="bib8"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Branco</surname><given-names>T</given-names></name><name><surname>Staras</surname><given-names>K</given-names></name></person-group><year iso-8601-date="2009">2009</year><article-title>The probability of neurotransmitter release: variability and feedback control at single synapses</article-title><source>Nature Reviews. Neuroscience</source><volume>10</volume><fpage>373</fpage><lpage>383</lpage><pub-id pub-id-type="doi">10.1038/nrn2634</pub-id><pub-id pub-id-type="pmid">19377502</pub-id></element-citation></ref><ref id="bib9"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Brodbeck</surname><given-names>C</given-names></name><name><surname>Jiao</surname><given-names>A</given-names></name><name><surname>Hong</surname><given-names>LE</given-names></name><name><surname>Simon</surname><given-names>JZ</given-names></name></person-group><year iso-8601-date="2020">2020</year><article-title>Neural speech restoration at the cocktail party: Auditory cortex recovers masked speech of both attended and ignored speakers</article-title><source>PLOS Biology</source><volume>18</volume><elocation-id>e3000883</elocation-id><pub-id pub-id-type="doi">10.1371/journal.pbio.3000883</pub-id><pub-id pub-id-type="pmid">33091003</pub-id></element-citation></ref><ref id="bib10"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bronkhorst</surname><given-names>AW</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>The cocktail-party problem revisited: early processing and selection of multi-talker speech</article-title><source>Attention, Perception &amp; Psychophysics</source><volume>77</volume><fpage>1465</fpage><lpage>1487</lpage><pub-id pub-id-type="doi">10.3758/s13414-015-0882-9</pub-id><pub-id pub-id-type="pmid">25828463</pub-id></element-citation></ref><ref id="bib11"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Carandini</surname><given-names>M</given-names></name><name><surname>Heeger</surname><given-names>DJ</given-names></name></person-group><year iso-8601-date="2011">2011</year><article-title>Normalization as a canonical neural computation</article-title><source>Nature Reviews. Neuroscience</source><volume>13</volume><fpage>51</fpage><lpage>62</lpage><pub-id pub-id-type="doi">10.1038/nrn3136</pub-id><pub-id pub-id-type="pmid">22108672</pub-id></element-citation></ref><ref id="bib12"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Cherry</surname><given-names>EC</given-names></name></person-group><year iso-8601-date="1953">1953</year><article-title>Some Experiments on the Recognition of Speech, with One and with Two Ears</article-title><source>The Journal of the Acoustical Society of America</source><volume>25</volume><fpage>975</fpage><lpage>979</lpage><pub-id pub-id-type="doi">10.1121/1.1907229</pub-id></element-citation></ref><ref id="bib13"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Chittajallu</surname><given-names>R</given-names></name><name><surname>Pelkey</surname><given-names>KA</given-names></name><name><surname>McBain</surname><given-names>CJ</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>Neurogliaform cells dynamically regulate somatosensory integration via synapse-specific modulation</article-title><source>Nature Neuroscience</source><volume>16</volume><fpage>13</fpage><lpage>15</lpage><pub-id pub-id-type="doi">10.1038/nn.3284</pub-id><pub-id pub-id-type="pmid">23222912</pub-id></element-citation></ref><ref id="bib14"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Cichy</surname><given-names>RM</given-names></name><name><surname>Khosla</surname><given-names>A</given-names></name><name><surname>Pantazis</surname><given-names>D</given-names></name><name><surname>Torralba</surname><given-names>A</given-names></name><name><surname>Oliva</surname><given-names>A</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Comparison of deep neural networks to spatio-temporal cortical dynamics of human visual object recognition reveals hierarchical correspondence</article-title><source>Scientific Reports</source><volume>6</volume><fpage>1</fpage><lpage>13</lpage><pub-id pub-id-type="doi">10.1038/srep27755</pub-id><pub-id pub-id-type="pmid">27282108</pub-id></element-citation></ref><ref id="bib15"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Cohen-Kashi Malina</surname><given-names>K</given-names></name><name><surname>Tsivourakis</surname><given-names>E</given-names></name><name><surname>Kushinsky</surname><given-names>D</given-names></name><name><surname>Apelblat</surname><given-names>D</given-names></name><name><surname>Shtiglitz</surname><given-names>S</given-names></name><name><surname>Zohar</surname><given-names>E</given-names></name><name><surname>Sokoletsky</surname><given-names>M</given-names></name><name><surname>Tasaka</surname><given-names>G-I</given-names></name><name><surname>Mizrahi</surname><given-names>A</given-names></name><name><surname>Lampl</surname><given-names>I</given-names></name><name><surname>Spiegel</surname><given-names>I</given-names></name></person-group><year iso-8601-date="2021">2021</year><article-title>NDNF interneurons in layer 1 gain-modulate whole cortical columns according to an animalâs behavioral state</article-title><source>Neuron</source><volume>109</volume><fpage>2150</fpage><lpage>2164</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2021.05.001</pub-id><pub-id pub-id-type="pmid">34038743</pub-id></element-citation></ref><ref id="bib16"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>DiCarlo</surname><given-names>JJ</given-names></name><name><surname>Cox</surname><given-names>DD</given-names></name></person-group><year iso-8601-date="2007">2007</year><article-title>Untangling invariant object recognition</article-title><source>Trends in Cognitive Sciences</source><volume>11</volume><fpage>333</fpage><lpage>341</lpage><pub-id pub-id-type="doi">10.1016/j.tics.2007.06.010</pub-id><pub-id pub-id-type="pmid">17631409</pub-id></element-citation></ref><ref id="bib17"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>DiCarlo</surname><given-names>JJ</given-names></name><name><surname>Zoccolan</surname><given-names>D</given-names></name><name><surname>Rust</surname><given-names>NC</given-names></name></person-group><year iso-8601-date="2012">2012</year><article-title>How does the brain solve visual object recognition?</article-title><source>Neuron</source><volume>73</volume><fpage>415</fpage><lpage>434</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2012.01.010</pub-id><pub-id pub-id-type="pmid">22325196</pub-id></element-citation></ref><ref id="bib18"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Dipoppa</surname><given-names>M</given-names></name><name><surname>Ranson</surname><given-names>A</given-names></name><name><surname>Krumin</surname><given-names>M</given-names></name><name><surname>Pachitariu</surname><given-names>M</given-names></name><name><surname>Carandini</surname><given-names>M</given-names></name><name><surname>Harris</surname><given-names>KD</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>Vision and Locomotion Shape the Interactions between Neuron Types in Mouse Visual Cortex</article-title><source>Neuron</source><volume>98</volume><fpage>602</fpage><lpage>615</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2018.03.037</pub-id><pub-id pub-id-type="pmid">29656873</pub-id></element-citation></ref><ref id="bib19"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Disney</surname><given-names>AA</given-names></name><name><surname>Aoki</surname><given-names>C</given-names></name><name><surname>Hawken</surname><given-names>MJ</given-names></name></person-group><year iso-8601-date="2007">2007</year><article-title>Gain modulation by nicotine in macaque v1</article-title><source>Neuron</source><volume>56</volume><fpage>701</fpage><lpage>713</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2007.09.034</pub-id><pub-id pub-id-type="pmid">18031686</pub-id></element-citation></ref><ref id="bib20"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Douglas</surname><given-names>RJ</given-names></name><name><surname>Martin</surname><given-names>KAC</given-names></name></person-group><year iso-8601-date="2004">2004</year><article-title>Neuronal circuits of the neocortex</article-title><source>Annual Review of Neuroscience</source><volume>27</volume><fpage>419</fpage><lpage>451</lpage><pub-id pub-id-type="doi">10.1146/annurev.neuro.27.070203.144152</pub-id><pub-id pub-id-type="pmid">15217339</pub-id></element-citation></ref><ref id="bib21"><element-citation publication-type="preprint"><person-group person-group-type="author"><name><surname>Dubreuil</surname><given-names>A</given-names></name><name><surname>Valente</surname><given-names>A</given-names></name><name><surname>Beiran</surname><given-names>M</given-names></name><name><surname>Mastrogiuseppe</surname><given-names>F</given-names></name><name><surname>Ostojic</surname><given-names>S</given-names></name></person-group><year iso-8601-date="2020">2020</year><article-title>Complementary Roles of Dimensionality and Population Structure in Neural Computations</article-title><source>bioRxiv</source><pub-id pub-id-type="doi">10.1101/2020.07.03.185942</pub-id></element-citation></ref><ref id="bib22"><element-citation publication-type="preprint"><person-group person-group-type="author"><name><surname>Failor</surname><given-names>SW</given-names></name><name><surname>Carandini</surname><given-names>M</given-names></name><name><surname>Harris</surname><given-names>KD</given-names></name></person-group><year iso-8601-date="2021">2021</year><article-title>Learning Orthogonalizes Visual Cortical Population Codes</article-title><source>bioRxiv</source><pub-id pub-id-type="doi">10.1101/2021.05.23.445338</pub-id></element-citation></ref><ref id="bib23"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Felleman</surname><given-names>DJ</given-names></name><name><surname>Van Essen</surname><given-names>DC</given-names></name></person-group><year iso-8601-date="1991">1991</year><article-title>Distributed hierarchical processing in the primate cerebral cortex</article-title><source>Cerebral Cortex (New York, N.Y</source><volume>1</volume><fpage>1</fpage><lpage>47</lpage><pub-id pub-id-type="doi">10.1093/cercor/1.1.1-a</pub-id><pub-id pub-id-type="pmid">1822724</pub-id></element-citation></ref><ref id="bib24"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ferguson</surname><given-names>KA</given-names></name><name><surname>Cardin</surname><given-names>JA</given-names></name></person-group><year iso-8601-date="2020">2020</year><article-title>Mechanisms underlying gain modulation in the cortex</article-title><source>Nature Reviews. Neuroscience</source><volume>21</volume><fpage>80</fpage><lpage>92</lpage><pub-id pub-id-type="doi">10.1038/s41583-019-0253-y</pub-id><pub-id pub-id-type="pmid">31911627</pub-id></element-citation></ref><ref id="bib25"><element-citation publication-type="confproc"><person-group person-group-type="author"><name><surname>Finn</surname><given-names>C</given-names></name><name><surname>Abbeel</surname><given-names>P</given-names></name><name><surname>Levine</surname><given-names>S</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>Model-agnostic meta-learning for fast adaptation of deep networks</article-title><conf-name>In International Conference on Machine Learning</conf-name><fpage>1126</fpage><lpage>1135</lpage></element-citation></ref><ref id="bib26"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Gers</surname><given-names>FA</given-names></name><name><surname>Schmidhuber</surname><given-names>J</given-names></name><name><surname>Cummins</surname><given-names>F</given-names></name></person-group><year iso-8601-date="2000">2000</year><article-title>Learning to forget: continual prediction with LSTM</article-title><source>Neural Computation</source><volume>12</volume><fpage>2451</fpage><lpage>2471</lpage><pub-id pub-id-type="doi">10.1162/089976600300015015</pub-id><pub-id pub-id-type="pmid">11032042</pub-id></element-citation></ref><ref id="bib27"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Gilbert</surname><given-names>CD</given-names></name><name><surname>Li</surname><given-names>W</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>Top-down influences on visual processing</article-title><source>Nature Reviews. Neuroscience</source><volume>14</volume><fpage>350</fpage><lpage>363</lpage><pub-id pub-id-type="doi">10.1038/nrn3476</pub-id><pub-id pub-id-type="pmid">23595013</pub-id></element-citation></ref><ref id="bib28"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Glaser</surname><given-names>JI</given-names></name><name><surname>Benjamin</surname><given-names>AS</given-names></name><name><surname>Chowdhury</surname><given-names>RH</given-names></name><name><surname>Perich</surname><given-names>MG</given-names></name><name><surname>Miller</surname><given-names>LE</given-names></name><name><surname>Kording</surname><given-names>KP</given-names></name></person-group><year iso-8601-date="2020">2020</year><article-title>Machine Learning for Neural Decoding</article-title><source>ENeuro</source><volume>7</volume><elocation-id>ENEURO.0506-19.2020</elocation-id><pub-id pub-id-type="doi">10.1523/ENEURO.0506-19.2020</pub-id><pub-id pub-id-type="pmid">32737181</pub-id></element-citation></ref><ref id="bib29"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Greff</surname><given-names>K</given-names></name><name><surname>Srivastava</surname><given-names>RK</given-names></name><name><surname>Koutnik</surname><given-names>J</given-names></name><name><surname>Steunebrink</surname><given-names>BR</given-names></name><name><surname>Schmidhuber</surname><given-names>J</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>LSTM: A Search Space Odyssey</article-title><source>IEEE Transactions on Neural Networks and Learning Systems</source><volume>28</volume><fpage>2222</fpage><lpage>2232</lpage><pub-id pub-id-type="doi">10.1109/TNNLS.2016.2582924</pub-id><pub-id pub-id-type="pmid">27411231</pub-id></element-citation></ref><ref id="bib30"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Halassa</surname><given-names>MM</given-names></name><name><surname>Sherman</surname><given-names>SM</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>Thalamocortical Circuit Motifs: A General Framework</article-title><source>Neuron</source><volume>103</volume><fpage>762</fpage><lpage>770</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2019.06.005</pub-id><pub-id pub-id-type="pmid">31487527</pub-id></element-citation></ref><ref id="bib31"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Har-Shai Yahav</surname><given-names>P</given-names></name><name><surname>Zion Golumbic</surname><given-names>E</given-names></name></person-group><year iso-8601-date="2021">2021</year><article-title>Linguistic processing of task-irrelevant speech at a cocktail party</article-title><source>eLife</source><volume>10</volume><elocation-id>e65096</elocation-id><pub-id pub-id-type="doi">10.7554/eLife.65096</pub-id><pub-id pub-id-type="pmid">33942722</pub-id></element-citation></ref><ref id="bib32"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hasselmo</surname><given-names>ME</given-names></name><name><surname>McGaughy</surname><given-names>J</given-names></name></person-group><year iso-8601-date="2004">2004</year><article-title>High acetylcholine levels set circuit dynamics for attention and encoding and low acetylcholine levels set dynamics for consolidation</article-title><source>Progress in Brain Research</source><volume>145</volume><fpage>207</fpage><lpage>231</lpage><pub-id pub-id-type="doi">10.1016/S0079-6123(03)45015-2</pub-id><pub-id pub-id-type="pmid">14650918</pub-id></element-citation></ref><ref id="bib33"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hochreiter</surname><given-names>S</given-names></name><name><surname>Schmidhuber</surname><given-names>J</given-names></name></person-group><year iso-8601-date="1997">1997</year><article-title>Long short-term memory</article-title><source>Neural Computation</source><volume>9</volume><fpage>1735</fpage><lpage>1780</lpage><pub-id pub-id-type="doi">10.1162/neco.1997.9.8.1735</pub-id><pub-id pub-id-type="pmid">9377276</pub-id></element-citation></ref><ref id="bib34"><element-citation publication-type="confproc"><person-group person-group-type="author"><name><surname>Hochreiter</surname><given-names>S</given-names></name><name><surname>Younger</surname><given-names>AS</given-names></name><name><surname>Conwell</surname><given-names>PR</given-names></name></person-group><year iso-8601-date="2001">2001</year><article-title>Learning to learn using gradient descent</article-title><conf-name>In International Conference on Artificial Neural Networks</conf-name><fpage>87</fpage><lpage>94</lpage><pub-id pub-id-type="doi">10.1007/3-540-44668-0</pub-id></element-citation></ref><ref id="bib35"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hong</surname><given-names>H</given-names></name><name><surname>Yamins</surname><given-names>DLK</given-names></name><name><surname>Majaj</surname><given-names>NJ</given-names></name><name><surname>DiCarlo</surname><given-names>JJ</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Explicit information for category-orthogonal object properties increases along the ventral stream</article-title><source>Nature Neuroscience</source><volume>19</volume><fpage>613</fpage><lpage>622</lpage><pub-id pub-id-type="doi">10.1038/nn.4247</pub-id><pub-id pub-id-type="pmid">26900926</pub-id></element-citation></ref><ref id="bib36"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Huber</surname><given-names>PJ</given-names></name></person-group><year iso-8601-date="1964">1964</year><article-title>Robust Estimation of a Location Parameter</article-title><source>The Annals of Mathematical Statistics</source><volume>35</volume><fpage>73</fpage><lpage>101</lpage><pub-id pub-id-type="doi">10.1214/aoms/1177703732</pub-id></element-citation></ref><ref id="bib37"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>HyvÃ¤rinen</surname><given-names>A</given-names></name><name><surname>Oja</surname><given-names>E</given-names></name></person-group><year iso-8601-date="2000">2000</year><article-title>Independent component analysis: algorithms and applications</article-title><source>Neural Networks</source><volume>13</volume><fpage>411</fpage><lpage>430</lpage><pub-id pub-id-type="doi">10.1016/s0893-6080(00)00026-5</pub-id><pub-id pub-id-type="pmid">10946390</pub-id></element-citation></ref><ref id="bib38"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Jarvis</surname><given-names>S</given-names></name><name><surname>Nikolic</surname><given-names>K</given-names></name><name><surname>Schultz</surname><given-names>SR</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>Neuronal gain modulability is determined by dendritic morphology: A computational optogenetic study</article-title><source>PLOS Computational Biology</source><volume>14</volume><elocation-id>e1006027</elocation-id><pub-id pub-id-type="doi">10.1371/journal.pcbi.1006027</pub-id><pub-id pub-id-type="pmid">29522509</pub-id></element-citation></ref><ref id="bib39"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kar</surname><given-names>K</given-names></name><name><surname>Kubilius</surname><given-names>J</given-names></name><name><surname>Schmidt</surname><given-names>K</given-names></name><name><surname>Issa</surname><given-names>EB</given-names></name><name><surname>DiCarlo</surname><given-names>JJ</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>Evidence that recurrent circuits are critical to the ventral streamâs execution of core object recognition behavior</article-title><source>Nature Neuroscience</source><volume>22</volume><fpage>974</fpage><lpage>983</lpage><pub-id pub-id-type="doi">10.1038/s41593-019-0392-5</pub-id><pub-id pub-id-type="pmid">31036945</pub-id></element-citation></ref><ref id="bib40"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kawai</surname><given-names>H</given-names></name><name><surname>Lazar</surname><given-names>R</given-names></name><name><surname>Metherate</surname><given-names>R</given-names></name></person-group><year iso-8601-date="2007">2007</year><article-title>Nicotinic control of axon excitability regulates thalamocortical transmission</article-title><source>Nature Neuroscience</source><volume>10</volume><fpage>1168</fpage><lpage>1175</lpage><pub-id pub-id-type="doi">10.1038/nn1956</pub-id><pub-id pub-id-type="pmid">17704774</pub-id></element-citation></ref><ref id="bib41"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Keller</surname><given-names>GB</given-names></name><name><surname>Mrsic-Flogel</surname><given-names>TD</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>Predictive Processing: A Canonical Cortical Computation</article-title><source>Neuron</source><volume>100</volume><fpage>424</fpage><lpage>435</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2018.10.003</pub-id><pub-id pub-id-type="pmid">30359606</pub-id></element-citation></ref><ref id="bib42"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kietzmann</surname><given-names>TC</given-names></name><name><surname>Spoerer</surname><given-names>CJ</given-names></name><name><surname>SÃ¶rensen</surname><given-names>LKA</given-names></name><name><surname>Cichy</surname><given-names>RM</given-names></name><name><surname>Hauk</surname><given-names>O</given-names></name><name><surname>Kriegeskorte</surname><given-names>N</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>Recurrence is required to capture the representational dynamics of the human visual system</article-title><source>PNAS</source><volume>116</volume><fpage>21854</fpage><lpage>21863</lpage><pub-id pub-id-type="doi">10.1073/pnas.1905544116</pub-id><pub-id pub-id-type="pmid">31591217</pub-id></element-citation></ref><ref id="bib43"><element-citation publication-type="preprint"><person-group person-group-type="author"><name><surname>Kingma</surname><given-names>DP</given-names></name><name><surname>Ba</surname><given-names>J</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>Adam: A Method for Stochastic Optimization</article-title><source>arXiv</source><ext-link ext-link-type="uri" xlink:href="https://arxiv.org/abs/1412.6980">https://arxiv.org/abs/1412.6980</ext-link></element-citation></ref><ref id="bib44"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kriegeskorte</surname><given-names>N</given-names></name><name><surname>Mur</surname><given-names>M</given-names></name><name><surname>Bandettini</surname><given-names>PA</given-names></name></person-group><year iso-8601-date="2008">2008</year><article-title>Representational similarity analysis - connecting the branches of systems neuroscience</article-title><source>Frontiers in Systems Neuroscience</source><volume>2</volume><elocation-id>4</elocation-id><pub-id pub-id-type="doi">10.3389/neuro.06.004.2008</pub-id><pub-id pub-id-type="pmid">19104670</pub-id></element-citation></ref><ref id="bib45"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kriegeskorte</surname><given-names>N</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>Deep Neural Networks: A New Framework for Modeling Biological Vision and Brain Information Processing</article-title><source>Annual Review of Vision Science</source><volume>1</volume><fpage>417</fpage><lpage>446</lpage><pub-id pub-id-type="doi">10.1146/annurev-vision-082114-035447</pub-id><pub-id pub-id-type="pmid">28532370</pub-id></element-citation></ref><ref id="bib46"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kuchibhotla</surname><given-names>KV</given-names></name><name><surname>Gill</surname><given-names>JV</given-names></name><name><surname>Lindsay</surname><given-names>GW</given-names></name><name><surname>Papadoyannis</surname><given-names>ES</given-names></name><name><surname>Field</surname><given-names>RE</given-names></name><name><surname>Sten</surname><given-names>TAH</given-names></name><name><surname>Miller</surname><given-names>KD</given-names></name><name><surname>Froemke</surname><given-names>RC</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>Parallel processing by cortical inhibition enables context-dependent behavior</article-title><source>Nature Neuroscience</source><volume>20</volume><fpage>62</fpage><lpage>71</lpage><pub-id pub-id-type="doi">10.1038/nn.4436</pub-id><pub-id pub-id-type="pmid">27798631</pub-id></element-citation></ref><ref id="bib47"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Larkum</surname><given-names>ME</given-names></name><name><surname>Senn</surname><given-names>W</given-names></name><name><surname>LÃ¼scher</surname><given-names>HR</given-names></name></person-group><year iso-8601-date="2004">2004</year><article-title>Top-down dendritic input increases the gain of layer 5 pyramidal neurons</article-title><source>Cerebral Cortex (New York, N.Y</source><volume>14</volume><fpage>1059</fpage><lpage>1070</lpage><pub-id pub-id-type="doi">10.1093/cercor/bhh065</pub-id><pub-id pub-id-type="pmid">15115747</pub-id></element-citation></ref><ref id="bib48"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Laviv</surname><given-names>T</given-names></name><name><surname>Riven</surname><given-names>I</given-names></name><name><surname>Dolev</surname><given-names>I</given-names></name><name><surname>Vertkin</surname><given-names>I</given-names></name><name><surname>Balana</surname><given-names>B</given-names></name><name><surname>Slesinger</surname><given-names>PA</given-names></name><name><surname>Slutsky</surname><given-names>I</given-names></name></person-group><year iso-8601-date="2010">2010</year><article-title>Basal GABA regulates GABA(B)R conformation and release probability at single hippocampal synapses</article-title><source>Neuron</source><volume>67</volume><fpage>253</fpage><lpage>267</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2010.06.022</pub-id><pub-id pub-id-type="pmid">20670833</pub-id></element-citation></ref><ref id="bib49"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>LeCun</surname><given-names>Y</given-names></name><name><surname>Bengio</surname><given-names>Y</given-names></name><name><surname>Hinton</surname><given-names>G</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>Deep learning</article-title><source>Nature</source><volume>521</volume><fpage>436</fpage><lpage>444</lpage><pub-id pub-id-type="doi">10.1038/nature14539</pub-id><pub-id pub-id-type="pmid">26017442</pub-id></element-citation></ref><ref id="bib50"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Lillicrap</surname><given-names>TP</given-names></name><name><surname>Santoro</surname><given-names>A</given-names></name><name><surname>Marris</surname><given-names>L</given-names></name><name><surname>Akerman</surname><given-names>CJ</given-names></name><name><surname>Hinton</surname><given-names>G</given-names></name></person-group><year iso-8601-date="2020">2020</year><article-title>Backpropagation and the brain</article-title><source>Nature Reviews. Neuroscience</source><volume>21</volume><fpage>335</fpage><lpage>346</lpage><pub-id pub-id-type="doi">10.1038/s41583-020-0277-3</pub-id><pub-id pub-id-type="pmid">32303713</pub-id></element-citation></ref><ref id="bib51"><element-citation publication-type="preprint"><person-group person-group-type="author"><name><surname>Lohani</surname><given-names>S</given-names></name><name><surname>Moberly</surname><given-names>AH</given-names></name><name><surname>Benisty</surname><given-names>H</given-names></name><name><surname>Landa</surname><given-names>B</given-names></name><name><surname>Jing</surname><given-names>M</given-names></name><name><surname>Li</surname><given-names>Y</given-names></name><name><surname>Higley</surname><given-names>MJ</given-names></name><name><surname>Cardin</surname><given-names>JA</given-names></name></person-group><year iso-8601-date="2020">2020</year><article-title>Dual color mesoscopic imaging reveals spatiotemporally heterogeneous coordination of cholinergic and neocortical activity</article-title><source>bioRxiv</source><pub-id pub-id-type="doi">10.1101/2020.12.09.418632</pub-id></element-citation></ref><ref id="bib52"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Mante</surname><given-names>V</given-names></name><name><surname>Sussillo</surname><given-names>D</given-names></name><name><surname>Shenoy</surname><given-names>KV</given-names></name><name><surname>Newsome</surname><given-names>WT</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>Context-dependent computation by recurrent dynamics in prefrontal cortex</article-title><source>Nature</source><volume>503</volume><fpage>78</fpage><lpage>84</lpage><pub-id pub-id-type="doi">10.1038/nature12742</pub-id><pub-id pub-id-type="pmid">24201281</pub-id></element-citation></ref><ref id="bib53"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Markov</surname><given-names>NT</given-names></name><name><surname>Vezoli</surname><given-names>J</given-names></name><name><surname>Chameau</surname><given-names>P</given-names></name><name><surname>Falchier</surname><given-names>A</given-names></name><name><surname>Quilodran</surname><given-names>R</given-names></name><name><surname>Huissoud</surname><given-names>C</given-names></name><name><surname>Lamy</surname><given-names>C</given-names></name><name><surname>Misery</surname><given-names>P</given-names></name><name><surname>Giroud</surname><given-names>P</given-names></name><name><surname>Ullman</surname><given-names>S</given-names></name><name><surname>Barone</surname><given-names>P</given-names></name><name><surname>Dehay</surname><given-names>C</given-names></name><name><surname>Knoblauch</surname><given-names>K</given-names></name><name><surname>Kennedy</surname><given-names>H</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>Anatomy of hierarchy: feedforward and feedback pathways in macaque visual cortex</article-title><source>The Journal of Comparative Neurology</source><volume>522</volume><fpage>225</fpage><lpage>259</lpage><pub-id pub-id-type="doi">10.1002/cne.23458</pub-id><pub-id pub-id-type="pmid">23983048</pub-id></element-citation></ref><ref id="bib54"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Marques</surname><given-names>T</given-names></name><name><surname>Nguyen</surname><given-names>J</given-names></name><name><surname>Fioreze</surname><given-names>G</given-names></name><name><surname>Petreanu</surname><given-names>L</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>The functional organization of cortical feedback inputs to primary visual cortex</article-title><source>Nature Neuroscience</source><volume>21</volume><fpage>757</fpage><lpage>764</lpage><pub-id pub-id-type="doi">10.1038/s41593-018-0135-z</pub-id><pub-id pub-id-type="pmid">29662217</pub-id></element-citation></ref><ref id="bib55"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>McAdams</surname><given-names>CJ</given-names></name><name><surname>Maunsell</surname><given-names>JH</given-names></name></person-group><year iso-8601-date="1999">1999</year><article-title>Effects of attention on orientation-tuning functions of single neurons in macaque cortical area V4</article-title><source>The Journal of Neuroscience</source><volume>19</volume><fpage>431</fpage><lpage>441</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.19-01-00431.1999</pub-id><pub-id pub-id-type="pmid">9870971</pub-id></element-citation></ref><ref id="bib56"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>McDermott</surname><given-names>JH</given-names></name></person-group><year iso-8601-date="2009">2009</year><article-title>The cocktail party problem</article-title><source>Current Biology</source><volume>19</volume><fpage>R1024</fpage><lpage>R1027</lpage><pub-id pub-id-type="doi">10.1016/j.cub.2009.09.005</pub-id><pub-id pub-id-type="pmid">19948136</pub-id></element-citation></ref><ref id="bib57"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Miller</surname><given-names>RJ</given-names></name></person-group><year iso-8601-date="1998">1998</year><article-title>Presynaptic receptors</article-title><source>Annual Review of Pharmacology and Toxicology</source><volume>38</volume><fpage>201</fpage><lpage>227</lpage><pub-id pub-id-type="doi">10.1146/annurev.pharmtox.38.1.201</pub-id><pub-id pub-id-type="pmid">9597154</pub-id></element-citation></ref><ref id="bib58"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Molyneaux</surname><given-names>BJ</given-names></name><name><surname>Hasselmo</surname><given-names>ME</given-names></name></person-group><year iso-8601-date="2002">2002</year><article-title>GABA(B) presynaptic inhibition has an in vivo time constant sufficiently rapid to allow modulation at theta frequency</article-title><source>Journal of Neurophysiology</source><volume>87</volume><fpage>1196</fpage><lpage>1205</lpage><pub-id pub-id-type="doi">10.1152/jn.00077.2001</pub-id><pub-id pub-id-type="pmid">11877493</pub-id></element-citation></ref><ref id="bib59"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Naumann</surname><given-names>LB</given-names></name><name><surname>Sprekeler</surname><given-names>H</given-names></name></person-group><year iso-8601-date="2020">2020</year><article-title>Presynaptic inhibition rapidly stabilises recurrent excitation in the face of plasticity</article-title><source>PLOS Computational Biology</source><volume>16</volume><elocation-id>e1008118</elocation-id><pub-id pub-id-type="doi">10.1371/journal.pcbi.1008118</pub-id><pub-id pub-id-type="pmid">32764742</pub-id></element-citation></ref><ref id="bib60"><element-citation publication-type="software"><person-group person-group-type="author"><name><surname>Naumann</surname><given-names>LB</given-names></name></person-group><year iso-8601-date="2022">2022</year><data-title>sprekelerlab/feedback_modulation_Naumann22</data-title><version designator="swh:1:rev:05373b093803e464082ad5b9e8ab2dbbf43bb23e">swh:1:rev:05373b093803e464082ad5b9e8ab2dbbf43bb23e</version><source>Software Heritage</source><ext-link ext-link-type="uri" xlink:href="https://archive.softwareheritage.org/swh:1:dir:ee3aa6ce292eea649252b7f5b3175b3561e7d8ed;origin=https://github.com/sprekelerlab/feedback_modulation_Naumann22;visit=swh:1:snp:7225dc0edc82b286290d94bb47dd51093317e3dc;anchor=swh:1:rev:05373b093803e464082ad5b9e8ab2dbbf43bb23e">https://archive.softwareheritage.org/swh:1:dir:ee3aa6ce292eea649252b7f5b3175b3561e7d8ed;origin=https://github.com/sprekelerlab/feedback_modulation_Naumann22;visit=swh:1:snp:7225dc0edc82b286290d94bb47dd51093317e3dc;anchor=swh:1:rev:05373b093803e464082ad5b9e8ab2dbbf43bb23e</ext-link></element-citation></ref><ref id="bib61"><element-citation publication-type="preprint"><person-group person-group-type="author"><name><surname>Nayebi</surname><given-names>A</given-names></name><name><surname>Sagastuy-Brena</surname><given-names>J</given-names></name><name><surname>Bear</surname><given-names>DM</given-names></name><name><surname>Kar</surname><given-names>K</given-names></name><name><surname>Kubilius</surname><given-names>J</given-names></name><name><surname>Ganguli</surname><given-names>S</given-names></name><name><surname>Sussillo</surname><given-names>D</given-names></name><name><surname>DiCarlo</surname><given-names>JJ</given-names></name><name><surname>Yamins</surname><given-names>DL</given-names></name></person-group><year iso-8601-date="2021">2021</year><article-title>Goal-Driven Recurrent Neural Network Models of the Ventral Visual Stream</article-title><source>bioRxiv</source><pub-id pub-id-type="doi">10.1101/2021.02.17.431717</pub-id></element-citation></ref><ref id="bib62"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Niell</surname><given-names>CM</given-names></name><name><surname>Stryker</surname><given-names>MP</given-names></name></person-group><year iso-8601-date="2010">2010</year><article-title>Modulation of visual responses by behavioral state in mouse visual cortex</article-title><source>Neuron</source><volume>65</volume><fpage>472</fpage><lpage>479</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2010.01.033</pub-id><pub-id pub-id-type="pmid">20188652</pub-id></element-citation></ref><ref id="bib63"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Oberfeld</surname><given-names>D</given-names></name><name><surname>KlÃ¶ckner-Nowotny</surname><given-names>F</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Individual differences in selective attention predict speech identification at a cocktail party</article-title><source>eLife</source><volume>5</volume><elocation-id>e16747</elocation-id><pub-id pub-id-type="doi">10.7554/eLife.16747</pub-id><pub-id pub-id-type="pmid">27580272</pub-id></element-citation></ref><ref id="bib64"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Olshausen</surname><given-names>BA</given-names></name><name><surname>Anderson</surname><given-names>CH</given-names></name><name><surname>Van Essen</surname><given-names>DC</given-names></name></person-group><year iso-8601-date="1993">1993</year><article-title>A neurobiological model of visual attention and invariant pattern recognition based on dynamic routing of information</article-title><source>The Journal of Neuroscience</source><volume>13</volume><fpage>4700</fpage><lpage>4719</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.13-11-04700.1993</pub-id><pub-id pub-id-type="pmid">8229193</pub-id></element-citation></ref><ref id="bib65"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Pardi</surname><given-names>MB</given-names></name><name><surname>Vogenstahl</surname><given-names>J</given-names></name><name><surname>Dalmay</surname><given-names>T</given-names></name><name><surname>SpanÃ²</surname><given-names>T</given-names></name><name><surname>Pu</surname><given-names>DL</given-names></name><name><surname>Naumann</surname><given-names>LB</given-names></name><name><surname>Kretschmer</surname><given-names>F</given-names></name><name><surname>Sprekeler</surname><given-names>H</given-names></name><name><surname>Letzkus</surname><given-names>JJ</given-names></name></person-group><year iso-8601-date="2020">2020</year><article-title>A thalamocortical top-down circuit for associative memory</article-title><source>Science (New York, N.Y.)</source><volume>370</volume><fpage>844</fpage><lpage>848</lpage><pub-id pub-id-type="doi">10.1126/science.abc2399</pub-id><pub-id pub-id-type="pmid">33184213</pub-id></element-citation></ref><ref id="bib66"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Parthasarathy</surname><given-names>A</given-names></name><name><surname>Hancock</surname><given-names>KE</given-names></name><name><surname>Bennett</surname><given-names>K</given-names></name><name><surname>DeGruttola</surname><given-names>V</given-names></name><name><surname>Polley</surname><given-names>DB</given-names></name></person-group><year iso-8601-date="2020">2020</year><article-title>Bottom-up and top-down neural signatures of disordered multi-talker speech perception in adults with normal hearing</article-title><source>eLife</source><volume>9</volume><elocation-id>e51419</elocation-id><pub-id pub-id-type="doi">10.7554/eLife.51419</pub-id><pub-id pub-id-type="pmid">31961322</pub-id></element-citation></ref><ref id="bib67"><element-citation publication-type="preprint"><person-group person-group-type="author"><name><surname>Pascanu</surname><given-names>R</given-names></name><name><surname>Mikolov</surname><given-names>T</given-names></name><name><surname>Bengio</surname><given-names>Y</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>On the Difficulty of Training Recurrent Neural Networks</article-title><source>arXiv</source><ext-link ext-link-type="uri" xlink:href="https://arxiv.org/abs/1211.5063">https://arxiv.org/abs/1211.5063</ext-link></element-citation></ref><ref id="bib68"><element-citation publication-type="confproc"><person-group person-group-type="author"><name><surname>Paszke</surname><given-names>A</given-names></name><name><surname>Gross</surname><given-names>S</given-names></name><name><surname>Massa</surname><given-names>F</given-names></name><name><surname>Lerer</surname><given-names>A</given-names></name><name><surname>Bradbury</surname><given-names>J</given-names></name><name><surname>Chanan</surname><given-names>G</given-names></name><name><surname>Killeen</surname><given-names>T</given-names></name><name><surname>Lin</surname><given-names>Z</given-names></name><name><surname>Gimelshein</surname><given-names>N</given-names></name><name><surname>Antiga</surname><given-names>L</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>Pytorch: An imperative style, high-performance deep learning library</article-title><conf-name>Advances in Neural Information Processing Systems</conf-name><fpage>8026</fpage><lpage>8037</lpage></element-citation></ref><ref id="bib69"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Pinto</surname><given-names>L</given-names></name><name><surname>Goard</surname><given-names>MJ</given-names></name><name><surname>Estandian</surname><given-names>D</given-names></name><name><surname>Xu</surname><given-names>M</given-names></name><name><surname>Kwan</surname><given-names>AC</given-names></name><name><surname>Lee</surname><given-names>SH</given-names></name><name><surname>Harrison</surname><given-names>TC</given-names></name><name><surname>Feng</surname><given-names>G</given-names></name><name><surname>Dan</surname><given-names>Y</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>Fast modulation of visual perception by basal forebrain cholinergic neurons</article-title><source>Nature Neuroscience</source><volume>16</volume><fpage>1857</fpage><lpage>1863</lpage><pub-id pub-id-type="doi">10.1038/nn.3552</pub-id><pub-id pub-id-type="pmid">24162654</pub-id></element-citation></ref><ref id="bib70"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Polack</surname><given-names>PO</given-names></name><name><surname>Friedman</surname><given-names>J</given-names></name><name><surname>Golshani</surname><given-names>P</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>Cellular mechanisms of brain state-dependent gain modulation in visual cortex</article-title><source>Nature Neuroscience</source><volume>16</volume><fpage>1331</fpage><lpage>1339</lpage><pub-id pub-id-type="doi">10.1038/nn.3464</pub-id><pub-id pub-id-type="pmid">23872595</pub-id></element-citation></ref><ref id="bib71"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Poorthuis</surname><given-names>RB</given-names></name><name><surname>Bloem</surname><given-names>B</given-names></name><name><surname>Schak</surname><given-names>B</given-names></name><name><surname>Wester</surname><given-names>J</given-names></name><name><surname>de Kock</surname><given-names>CPJ</given-names></name><name><surname>Mansvelder</surname><given-names>HD</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>Layer-specific modulation of the prefrontal cortex by nicotinic acetylcholine receptors</article-title><source>Cerebral Cortex (New York, N.Y)</source><volume>23</volume><fpage>148</fpage><lpage>161</lpage><pub-id pub-id-type="doi">10.1093/cercor/bhr390</pub-id><pub-id pub-id-type="pmid">22291029</pub-id></element-citation></ref><ref id="bib72"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Purushothaman</surname><given-names>G</given-names></name><name><surname>Marion</surname><given-names>R</given-names></name><name><surname>Li</surname><given-names>K</given-names></name><name><surname>Casagrande</surname><given-names>VA</given-names></name></person-group><year iso-8601-date="2012">2012</year><article-title>Gating and control of primary visual cortex by pulvinar</article-title><source>Nature Neuroscience</source><volume>15</volume><fpage>905</fpage><lpage>912</lpage><pub-id pub-id-type="doi">10.1038/nn.3106</pub-id><pub-id pub-id-type="pmid">22561455</pub-id></element-citation></ref><ref id="bib73"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Quiroga</surname><given-names>RQ</given-names></name><name><surname>Reddy</surname><given-names>L</given-names></name><name><surname>Kreiman</surname><given-names>G</given-names></name><name><surname>Koch</surname><given-names>C</given-names></name><name><surname>Fried</surname><given-names>I</given-names></name></person-group><year iso-8601-date="2005">2005</year><article-title>Invariant visual representation by single neurons in the human brain</article-title><source>Nature</source><volume>435</volume><fpage>1102</fpage><lpage>1107</lpage><pub-id pub-id-type="doi">10.1038/nature03687</pub-id><pub-id pub-id-type="pmid">15973409</pub-id></element-citation></ref><ref id="bib74"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Reynolds</surname><given-names>JH</given-names></name><name><surname>Heeger</surname><given-names>DJ</given-names></name></person-group><year iso-8601-date="2009">2009</year><article-title>The normalization model of attention</article-title><source>Neuron</source><volume>61</volume><fpage>168</fpage><lpage>185</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2009.01.002</pub-id><pub-id pub-id-type="pmid">19186161</pub-id></element-citation></ref><ref id="bib75"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Riesenhuber</surname><given-names>M</given-names></name><name><surname>Poggio</surname><given-names>T</given-names></name></person-group><year iso-8601-date="1999">1999</year><article-title>Hierarchical models of object recognition in cortex</article-title><source>Nature Neuroscience</source><volume>2</volume><fpage>1019</fpage><lpage>1025</lpage><pub-id pub-id-type="doi">10.1038/14819</pub-id><pub-id pub-id-type="pmid">10526343</pub-id></element-citation></ref><ref id="bib76"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Roth</surname><given-names>MM</given-names></name><name><surname>Dahmen</surname><given-names>JC</given-names></name><name><surname>Muir</surname><given-names>DR</given-names></name><name><surname>Imhof</surname><given-names>F</given-names></name><name><surname>Martini</surname><given-names>FJ</given-names></name><name><surname>Hofer</surname><given-names>SB</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Thalamic nuclei convey diverse contextual information to layer 1 of visual cortex</article-title><source>Nature Neuroscience</source><volume>19</volume><fpage>299</fpage><lpage>307</lpage><pub-id pub-id-type="doi">10.1038/nn.4197</pub-id><pub-id pub-id-type="pmid">26691828</pub-id></element-citation></ref><ref id="bib77"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Sabatini</surname><given-names>BL</given-names></name><name><surname>Tian</surname><given-names>L</given-names></name></person-group><year iso-8601-date="2020">2020</year><article-title>Imaging Neurotransmitter and Neuromodulator Dynamics In Vivo with Genetically Encoded Indicators</article-title><source>Neuron</source><volume>108</volume><fpage>17</fpage><lpage>32</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2020.09.036</pub-id><pub-id pub-id-type="pmid">33058762</pub-id></element-citation></ref><ref id="bib78"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Salinas</surname><given-names>E</given-names></name><name><surname>Abbott</surname><given-names>LF</given-names></name></person-group><year iso-8601-date="1997">1997</year><article-title>Invariant visual responses from attentional gain fields</article-title><source>Journal of Neurophysiology</source><volume>77</volume><fpage>3267</fpage><lpage>3272</lpage><pub-id pub-id-type="doi">10.1152/jn.1997.77.6.3267</pub-id><pub-id pub-id-type="pmid">9212273</pub-id></element-citation></ref><ref id="bib79"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Salinas</surname><given-names>E</given-names></name><name><surname>Thier</surname><given-names>P</given-names></name></person-group><year iso-8601-date="2000">2000</year><article-title>Gain modulation: a major computational principle of the central nervous system</article-title><source>Neuron</source><volume>27</volume><fpage>15</fpage><lpage>21</lpage><pub-id pub-id-type="doi">10.1016/s0896-6273(00)00004-0</pub-id><pub-id pub-id-type="pmid">10939327</pub-id></element-citation></ref><ref id="bib80"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Salinas</surname><given-names>E</given-names></name><name><surname>Sejnowski</surname><given-names>TJ</given-names></name></person-group><year iso-8601-date="2001">2001</year><article-title>Gain modulation in the central nervous system: where behavior, neurophysiology, and computation meet</article-title><source>The Neuroscientist</source><volume>7</volume><fpage>430</fpage><lpage>440</lpage><pub-id pub-id-type="doi">10.1177/107385840100700512</pub-id><pub-id pub-id-type="pmid">11597102</pub-id></element-citation></ref><ref id="bib81"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Sampathkumar</surname><given-names>V</given-names></name><name><surname>Miller-Hansen</surname><given-names>A</given-names></name><name><surname>Sherman</surname><given-names>SM</given-names></name><name><surname>Kasthuri</surname><given-names>N</given-names></name></person-group><year iso-8601-date="2021">2021</year><article-title>Integration of signals from different cortical areas in higher order thalamic neurons</article-title><source>PNAS</source><volume>118</volume><elocation-id>e2104137118</elocation-id><pub-id pub-id-type="doi">10.1073/pnas.2104137118</pub-id><pub-id pub-id-type="pmid">34282018</pub-id></element-citation></ref><ref id="bib82"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Sherman</surname><given-names>SM</given-names></name><name><surname>Guillery</surname><given-names>RW</given-names></name></person-group><year iso-8601-date="1998">1998</year><article-title>On the actions that one nerve cell can have on another: distinguishing âdriversâ from âmodulators.â</article-title><source>PNAS</source><volume>95</volume><fpage>7121</fpage><lpage>7126</lpage><pub-id pub-id-type="doi">10.1073/pnas.95.12.7121</pub-id><pub-id pub-id-type="pmid">9618549</pub-id></element-citation></ref><ref id="bib83"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Sherman</surname><given-names>SM</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Thalamus plays a central role in ongoing cortical functioning</article-title><source>Nature Neuroscience</source><volume>19</volume><fpage>533</fpage><lpage>541</lpage><pub-id pub-id-type="doi">10.1038/nn.4269</pub-id><pub-id pub-id-type="pmid">27021938</pub-id></element-citation></ref><ref id="bib84"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Shine</surname><given-names>JM</given-names></name><name><surname>MÃ¼ller</surname><given-names>EJ</given-names></name><name><surname>Munn</surname><given-names>B</given-names></name><name><surname>Cabral</surname><given-names>J</given-names></name><name><surname>Moran</surname><given-names>RJ</given-names></name><name><surname>Breakspear</surname><given-names>M</given-names></name></person-group><year iso-8601-date="2021">2021</year><article-title>Computational models link cellular mechanisms of neuromodulation to large-scale neural dynamics</article-title><source>Nature Neuroscience</source><volume>24</volume><fpage>765</fpage><lpage>776</lpage><pub-id pub-id-type="doi">10.1038/s41593-021-00824-6</pub-id><pub-id pub-id-type="pmid">33958801</pub-id></element-citation></ref><ref id="bib85"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Spoerer</surname><given-names>CJ</given-names></name><name><surname>McClure</surname><given-names>P</given-names></name><name><surname>Kriegeskorte</surname><given-names>N</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>Recurrent Convolutional Neural Networks: A Better Model of Biological Object Recognition</article-title><source>Frontiers in Psychology</source><volume>8</volume><elocation-id>1551</elocation-id><pub-id pub-id-type="doi">10.3389/fpsyg.2017.01551</pub-id><pub-id pub-id-type="pmid">28955272</pub-id></element-citation></ref><ref id="bib86"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Stroud</surname><given-names>JP</given-names></name><name><surname>Porter</surname><given-names>MA</given-names></name><name><surname>Hennequin</surname><given-names>G</given-names></name><name><surname>Vogels</surname><given-names>TP</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>Motor primitives in space and time via targeted gain modulation in cortical networks</article-title><source>Nature Neuroscience</source><volume>21</volume><fpage>1774</fpage><lpage>1783</lpage><pub-id pub-id-type="doi">10.1038/s41593-018-0276-0</pub-id><pub-id pub-id-type="pmid">30482949</pub-id></element-citation></ref><ref id="bib87"><element-citation publication-type="preprint"><person-group person-group-type="author"><name><surname>Thorat</surname><given-names>S</given-names></name><name><surname>Aldegheri</surname><given-names>G</given-names></name><name><surname>Kietzmann</surname><given-names>TC</given-names></name></person-group><year iso-8601-date="2021">2021</year><article-title>Category-Orthogonal Object Features Guide Information Processing in Recurrent Neural Networks Trained for Object Categorization</article-title><source>arXiv</source><ext-link ext-link-type="uri" xlink:href="https://arxiv.org/abs/2111.07898">https://arxiv.org/abs/2111.07898</ext-link></element-citation></ref><ref id="bib88"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Thurley</surname><given-names>K</given-names></name><name><surname>Senn</surname><given-names>W</given-names></name><name><surname>LÃ¼scher</surname><given-names>H-R</given-names></name></person-group><year iso-8601-date="2008">2008</year><article-title>Dopamine increases the gain of the input-output response of rat prefrontal pyramidal neurons</article-title><source>Journal of Neurophysiology</source><volume>99</volume><fpage>2985</fpage><lpage>2997</lpage><pub-id pub-id-type="doi">10.1152/jn.01098.2007</pub-id><pub-id pub-id-type="pmid">18400958</pub-id></element-citation></ref><ref id="bib89"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Urban-Ciecko</surname><given-names>J</given-names></name><name><surname>Fanselow</surname><given-names>EE</given-names></name><name><surname>Barth</surname><given-names>AL</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>Neocortical somatostatin neurons reversibly silence excitatory transmission via GABAb receptors</article-title><source>Current Biology</source><volume>25</volume><fpage>722</fpage><lpage>731</lpage><pub-id pub-id-type="doi">10.1016/j.cub.2015.01.035</pub-id><pub-id pub-id-type="pmid">25728691</pub-id></element-citation></ref><ref id="bib90"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>van den Brink</surname><given-names>RL</given-names></name><name><surname>Pfeffer</surname><given-names>T</given-names></name><name><surname>Donner</surname><given-names>TH</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>Brainstem Modulation of Large-Scale Intrinsic Cortical Activity Correlations</article-title><source>Frontiers in Human Neuroscience</source><volume>13</volume><elocation-id>340</elocation-id><pub-id pub-id-type="doi">10.3389/fnhum.2019.00340</pub-id><pub-id pub-id-type="pmid">31649516</pub-id></element-citation></ref><ref id="bib91"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>van Hemmen</surname><given-names>JL</given-names></name><name><surname>Sejnowski</surname><given-names>TJ</given-names></name></person-group><year iso-8601-date="2006">2006</year><chapter-title>How Does Our Visual System Achieve Shift and Size Invariance</chapter-title><person-group person-group-type="editor"><name><surname>van Hemmen</surname><given-names>JL</given-names></name></person-group><source>Problems in Systems Neuroscience</source><publisher-name>Oxford University Press</publisher-name><fpage>322</fpage><lpage>340</lpage><pub-id pub-id-type="doi">10.1093/acprof:oso/9780195148220.003.0016</pub-id></element-citation></ref><ref id="bib92"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Vinck</surname><given-names>M</given-names></name><name><surname>Batista-Brito</surname><given-names>R</given-names></name><name><surname>Knoblich</surname><given-names>U</given-names></name><name><surname>Cardin</surname><given-names>JA</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>Arousal and locomotion make distinct contributions to cortical activity patterns and visual encoding</article-title><source>Neuron</source><volume>86</volume><fpage>740</fpage><lpage>754</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2015.03.028</pub-id><pub-id pub-id-type="pmid">25892300</pub-id></element-citation></ref><ref id="bib93"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wang</surname><given-names>JX</given-names></name><name><surname>Kurth-Nelson</surname><given-names>Z</given-names></name><name><surname>Kumaran</surname><given-names>D</given-names></name><name><surname>Tirumala</surname><given-names>D</given-names></name><name><surname>Soyer</surname><given-names>H</given-names></name><name><surname>Leibo</surname><given-names>JZ</given-names></name><name><surname>Hassabis</surname><given-names>D</given-names></name><name><surname>Botvinick</surname><given-names>M</given-names></name></person-group><year iso-8601-date="2018">2018a</year><article-title>Prefrontal cortex as a meta-reinforcement learning system</article-title><source>Nature Neuroscience</source><volume>21</volume><fpage>860</fpage><lpage>868</lpage><pub-id pub-id-type="doi">10.1038/s41593-018-0147-8</pub-id><pub-id pub-id-type="pmid">29760527</pub-id></element-citation></ref><ref id="bib94"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wang</surname><given-names>J</given-names></name><name><surname>Narain</surname><given-names>D</given-names></name><name><surname>Hosseini</surname><given-names>EA</given-names></name><name><surname>Jazayeri</surname><given-names>M</given-names></name></person-group><year iso-8601-date="2018">2018b</year><article-title>Flexible timing by temporal scaling of cortical responses</article-title><source>Nature Neuroscience</source><volume>21</volume><fpage>102</fpage><lpage>110</lpage><pub-id pub-id-type="doi">10.1038/s41593-017-0028-6</pub-id><pub-id pub-id-type="pmid">29203897</pub-id></element-citation></ref><ref id="bib95"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Werbos</surname><given-names>PJ</given-names></name></person-group><year iso-8601-date="1990">1990</year><article-title>Backpropagation through time: what it does and how to do it</article-title><source>Proceedings of the IEEE</source><volume>78</volume><fpage>1550</fpage><lpage>1560</lpage><pub-id pub-id-type="doi">10.1109/5.58337</pub-id></element-citation></ref><ref id="bib96"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wiskott</surname><given-names>L</given-names></name><name><surname>Sejnowski</surname><given-names>TJ</given-names></name></person-group><year iso-8601-date="2002">2002</year><article-title>Slow feature analysis: unsupervised learning of invariances</article-title><source>Neural Computation</source><volume>14</volume><fpage>715</fpage><lpage>770</lpage><pub-id pub-id-type="doi">10.1162/089976602317318938</pub-id><pub-id pub-id-type="pmid">11936959</pub-id></element-citation></ref><ref id="bib97"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Yamins</surname><given-names>DLK</given-names></name><name><surname>DiCarlo</surname><given-names>JJ</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Using goal-driven deep learning models to understand sensory cortex</article-title><source>Nature Neuroscience</source><volume>19</volume><fpage>356</fpage><lpage>365</lpage><pub-id pub-id-type="doi">10.1038/nn.4244</pub-id><pub-id pub-id-type="pmid">26906502</pub-id></element-citation></ref><ref id="bib98"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Zhuang</surname><given-names>C</given-names></name><name><surname>Yan</surname><given-names>S</given-names></name><name><surname>Nayebi</surname><given-names>A</given-names></name><name><surname>Schrimpf</surname><given-names>M</given-names></name><name><surname>Frank</surname><given-names>MC</given-names></name><name><surname>DiCarlo</surname><given-names>JJ</given-names></name><name><surname>Yamins</surname><given-names>DLK</given-names></name></person-group><year iso-8601-date="2021">2021</year><article-title>Unsupervised neural network models of the ventral visual stream</article-title><source>PNAS</source><volume>118</volume><elocation-id>e2014196118</elocation-id><pub-id pub-id-type="doi">10.1073/pnas.2014196118</pub-id><pub-id pub-id-type="pmid">33431673</pub-id></element-citation></ref></ref-list></back><sub-article article-type="editor-report" id="sa0"><front-stub><article-id pub-id-type="doi">10.7554/eLife.76096.sa0</article-id><title-group><article-title>Editor's evaluation</article-title></title-group><contrib-group><contrib contrib-type="author"><name><surname>Ostojic</surname><given-names>Srdjan</given-names></name><role specific-use="editor">Reviewing Editor</role><aff><institution-wrap><institution-id institution-id-type="ror">https://ror.org/05a0dhs15</institution-id><institution>Ecole Normale Superieure Paris</institution></institution-wrap><country>France</country></aff></contrib></contrib-group></front-stub><body><p>One of the key questions in sensory neuroscience is how cortical networks extract invariant percepts from variable sensory inputs. While much of the literature focuses on the role of feedforward hierarchical processing for extracting invariant percepts, this study proposes a novel implementation based on top-down feedback. The article analyses the underlying mechanism based on an invariant subspace and presents instantiations of this mechanism at different levels of biophysical realism.</p></body></sub-article><sub-article article-type="decision-letter" id="sa1"><front-stub><article-id pub-id-type="doi">10.7554/eLife.76096.sa1</article-id><title-group><article-title>Decision letter</article-title></title-group><contrib-group content-type="section"><contrib contrib-type="editor"><name><surname>Ostojic</surname><given-names>Srdjan</given-names></name><role>Reviewing Editor</role><aff><institution-wrap><institution-id institution-id-type="ror">https://ror.org/05a0dhs15</institution-id><institution>Ecole Normale Superieure Paris</institution></institution-wrap><country>France</country></aff></contrib></contrib-group></front-stub><body><boxed-text id="sa2-box1"><p>In the interests of transparency, eLife publishes the most substantive revision requests and the accompanying author responses.</p></boxed-text><p><bold>Decision letter after peer review:</bold></p><p>[Editorsâ note: the authors submitted for reconsideration following the decision after peer review. What follows is the decision letter after the first round of review.]</p><p>Thank you for submitting the paper &quot;Invariant neural subspaces maintained by feedback modulation&quot; for consideration by <italic>eLife</italic>. Your article has been reviewed by 3 peer reviewers, one of whom is a member of our Board of Reviewing Editors, and the evaluation has been overseen by a Senior Editor. The reviewers have opted to remain anonymous.</p><p>We are sorry to say that, after consultation with the reviewers, we have decided that this work will not be considered further for publication by <italic>eLife</italic> at this time.</p><p>While all three reviewers appreciated the novelty of the proposed computational role for feedback connections, they estimated that substantial additional work would be needed to establish more firmly the mechanisms underlying contextâinvariant processing and its biological relevance. Given the extent of the criticisms, we have decided to reject the paper. Should further analyses allow you to fully address these criticisms we would be open to a resubmission.</p><p><italic>Reviewer #1:</italic></p><p>One of the key questions in sensory neuroscience is how cortical networks extract invariant percepts from variable sensory inputs. Much of the existing literature focuses on the role of feedâforward hierarchical processing for extracting such invariances. The present study proposes an alternative mechanism based on topâdown feedback. Focusing on the soâcalled sourceâseparation, or cocktailâparty problem, the manuscript shows how sources mixed in a contextâdependent manner can be separated independently of context, using feedâforward networks modulated by topâdown contextâdependent inputs.</p><p>The manuscript starts with a simplified, abstract network, and then progressively moves to more biologically plausible ones. By performing population analyses of network activity, the authors then argue for a mechanism based on contextâinvariant subspaces.</p><p>Strengths of the paper:</p><p>â novel proposal for an important class of cortical computations</p><p>â very elegant formulation of the problem</p><p>â the writing style is very clear and appealing</p><p>â network implementations at different levels of biophysical realism.</p><p>Weaknesses of the paper:</p><p>â the announced mechanism, based on invariant subspaces, is not clearly explained and needs to be supported by additional evidence.</p><p>â how the network detects contextual changes does not seem to be explained</p><p>â the analyses of network activity, their rationale and the resulting conclusions are difficult to follow.</p><p>While I very much appreciated the novelty and the elegance of the approach developed in this paper, ultimately, I was left wondering how the networks perform their task.</p><p>â The title and abstract announce a mechanism based on invariant neural subspaces. Clearly, since the readout is fixed, there must be an invariant subspace, but the key question is how it is generated and maintained across contexts. In the Results, this mechanism is explained only briefly at the very end of the results, in connection to Figure 6, which seems to be just an illustration. The authors would need to unpack what precisely the mechanism is (not clear right now) and give more evidence for it.</p><p>â An important complementary issue is how the network detects context changes. The manuscript states that &quot;feedbackâmediated invariance requires time to establish after contextual changes&quot; (lines 245â246), but how this works does not seem to be explained. What type of error signal does the network use to change the gains?</p><p>On a related note, is the network trained on all the contexts it sees during testing, or is it able to deal with totally novel contexts?</p><p>â The logic of the sequence of analysis (optogenetic manipulations; correlation; changes in gainâ¦) is a bit difficult to follow and needs more motivation. In particular, why is the nonâlinear encoding of context important?</p><p>â It is a bit surprising that the analyses focus on the most complex version of the network to examine mechanisms. Presumably the simplified networks could be leveraged to identify and explain the mechanisms in a more transparent manner.</p><p><italic>Reviewer #2:</italic></p><p>The authors aim to explore an understudied potential function of feedback connections: providing contextâindependent sensory processing. Invariant sensory processing is frequently assumed to be carried out by feedforward processing and much of the study of feedback focuses on how feedback could implement contextâdependent processing. This makes this study promising and relatively novel.</p><p>The strengths of this paper are that it demonstrates convincingly and using a variety of network architectures and feedback mechanisms that feedback modulations can indeed help a network read out sensory input in a contextâindependent way.</p><p>The weaknesses are in the analysis and comparisons of the various networks. While the basic finding that this invariance does not result from invariant activity on the individual neuron level is interesting and of value, the explanation that it instead leads to invariant population activity is almost tautological given the network architecture. It is also unclear how the simpler models the authors present are meant to provide insight on either the more biologically detailed hierarchical model or on real neural processing, especially given that the mode of modulation in the simplest model (reâweighting of feedforward weights) differs from that of the later models (reâweighting of neural activation). In this way I don't feel that the authors fully achieved their goal of describing the mechanism of feedback modulation.</p><p>The methods appear technically sound, but I am confused by some of the choices. For example, the authors start with a single layer network where feedback modulates the weights between the input and output. This is a different mechanism than the normal neuronal gain usually attributed to feedback. The authors then add more details to push the model more in the biological direction, but multiple details are sometimes added at once and the logic behind these choices isn't always clear. I believe the authors switch to using neuronal gain when they want to explore spatially correlated modulation, but they don't talk about neuronal modulation until they introduce their full hierarchical model. The hierarchical model also adds Dale's law and a separate inhibitory population but it is not clear why these details were added or if/how they change the function of the model in a way relevant to understanding feedback modulation. Even the use of a multiâlayer model is not very well motivated given that they show that this task can be completed with a very small one layer model. The simplicity of the task has implications for understanding some of these findings as well. For example, to show that modulatory signals can be spatially correlated, the authors create a model with many more neurons than is needed to solve the task and show that the modulatory signal can target nearby cells in this population similarly without sacrificing performance. But the low dimensional nature of the modulatory signal is only really an issue of interest in the context of a higher dimensional task. As a thought experiment: if the 2 neurons in the original model were simply replicated to 50 each and each population of 50 neurons was given the same modulation, this would be essentially equivalent to the original 2 cell model, but under the logic of what the authors have shown here, would supposedly demonstrate that modulatory signals still work if low dimensional. In this way, that analysis fell short.</p><p>I think that this work may spur more interest in studying the role of feedback for invariant sensory processing, which would be a very productive outcome. Furthermore, the demonstration that the context signals cannot be linearly readout from the cells performing the modulation is an important lesson for the analysis of neural data. I also think further reflection on the finding that the modulatory network needs direct sensory input (more so even than the input from later processing stages) will be very important for understanding how this modulation works and how it relates to biological structures. As the authors note, this may mean that their model is more akin to inputs from higher order thalamic areas, though even that mapping is imperfect due to the lack of recurrence.</p><p>I think it would help the readability of the paper if the authors included a few more brief descriptions of the methods in the Results. For example, a better description of how the signals are generated, the fact that the networks are trained with a single set of signals only, etc. Also, there were points where it wasn't clear if a network was tested under different conditions or actually retrained for them (for example, in figure 2d/e). Also, the fact that the modulation went from being on the weights to on the neurons themselves was not made clear in section &quot;Invariance can be established by spatially diffuse feedback modulation&quot;. I also found the schematic in Figure 1a a bit confusing. I don't know why x is represented as a question mark when it is a sum of the two signals. I'd prefer a diagram that makes the dimensionality of x clearer (relatedly, why are there only 3 weights from x to y when I believe it is a 2x2 matrix).</p><p>&quot;While we trained the modulatory system using supervised learning, the contextual inference is performed by its dynamics without access to the target sources and thus unsupervised&quot; I feel this could be read as saying that an actual unsupervised objective was used, when in fact only supervised learning took place, so I would suggest reâwording.</p><p>I didn't understand the claim about matched EI inputs and how it depends on using gain modulation. This should probably be expanded and related to the main questions of the paper or possibly removed.</p><p>Figure 4i seems to be the main demonstration that individual neural activity itself is not invariant to context. I'd like to see a more inâdepth exploration of this. Particularly, if the readout only relied on a small handful of neurons then finding that the rest of the neurons are not contextâinvariant wouldn't prove that individual neural invariance is not a relevant mechanism. Given that the readout from this network is known, it would be particularly easy to determine if the heavily weighted neurons in particular are or are not context invariant.</p><p>In general, I don't understand why the authors use a separately trained linear readout when trying to show that the population activity at the final layer is invariant. They eventually acknowledge that &quot;Since this readout is obtained from the data, this procedure does not require knowledge of the readout in the network model. Note that the trained decoder and the network readout are not necessarily identical&quot; but they don't explain why they are using this alternative readout or what new insights its use adds. Particularly, the performance of the network indicates the there is some sort of context invariant read out possible from this population, yet the authors use this other readout in a way that is seemingly supposed to add something to the explanation.</p><p>Be sure to say what errorbars are based on in all figures.</p><p>&quot;In our model, the mechanism needs to satisfy a few key</p><p>requirements: i) the modulation is not uniform across the population, ii) it operates on a timescale similar to that of changes in context, and iii) it is driven by feedback projections.&quot; I don't understand claim (iii). If anything, the results show the importance of the modulation being driven by feedforward sensory signals (figure 2d/e).</p><p>&quot;In addition, feedback inputs from the sensory to the modulatory system allow a better control of the modulated network state.&quot; I don't see how the connections from a sensory system to a modulatory system are &quot;feedback&quot;.</p><p><italic>Reviewer #3:</italic></p><p>I appreciate the didactic way in which the manuscript was written (and beautiful figures!), in particular the progression from a vanilla architecture towards the full fledged model with EI rectified neurons with spatially specific modulation. My main concerns (detailed below) are twoâfold:</p><p>1. I felt that some extensions were not explicitly justified (e.g. why 2 layers instead of 2, etc)</p><p>2. I was expecting more 'reverseâengineering' of the mechanism through which the network accomplishes a context invariant projection. This is the main result of the paper, as reflected in the title, so I think it deserves more unpacking. Below I unpack these concerns, sometimes providing some suggestions to improve the motivation and clarity of the paper (without any particular order)</p><p>1. Overall, the architecture choices are a bit unjustified. In the extreme, wouldn't the LSTM alone solve the task? The addition of each feedforward layer should be better motivated (e.g. more biologically realistic? In what sense?). For example, why add an extra layer from extensions 2 and 3? If those are necessary, this should be explained. If they are not necessary, they should be removed.</p><p>2. 'Because the task requires a dynamic inference of the context, it cannot be solved by feedforward networks or standard blind source separation algorithms' I think the paper could be better motivated if this was shown explicitly with some examples.</p><p>3. A figure explicitly illustrating the training setup would help motivate what is trivially solved and what is actually challenging. For instance, in the main manuscript, it is not clear in which cases the network is trained and tested on the same contexts (ie A(t)) and which cases it is not. In the first case, the context can be easily inferred from x(t) but the latter is more challenging?</p><p>4. however I understand that the paper is already too long, Intra / extrapolation results deserve more spotlight and unpacking in my opinion. In general, if there is a lack of space, I would merge Figure 1 and figure 2 â and jump directly to extension 1 â and move most of figure 2 to sup.</p><p>5. Most important concern to me: Figure 6, in which the mechanism is revealed, deserves more quantifications to explicitly pinpoint the mechanism. Three suggestions come to mind:</p><p>a. Plot the 3 PCs components (instead of just 1) and show the readout in this space. The key result is that the readout is invariant to context and this is not clearly illustrated at the moment. Instead, what is shown is that the representation changes, but that it changes in a way that preserves invariance on the readout is not clearly highlighted.</p><p>b. The authors highlight that the network is not just reversing the new mixing coefficients and projecting the activity back into the 2d low manifold. Instead, it is rotating everything out of this manifold. My suggestion would be to show this alternatively explicitly. Is it actually possible? Relatedly, what happens if the context is changed back to context 1?</p><p>c. Finally, all the statements made about this figure should be quantified and not just illustrated for 1 trial.</p></body></sub-article><sub-article article-type="reply" id="sa2"><front-stub><article-id pub-id-type="doi">10.7554/eLife.76096.sa2</article-id><title-group><article-title>Author response</article-title></title-group></front-stub><body><p>[Editorsâ note: The authors appealed the original decision. What follows is the authorsâ response to the first round of review.]</p><disp-quote content-type="editor-comment"><p>Reviewer #1:</p><p>One of the key questions in sensory neuroscience is how cortical networks extract invariant percepts from variable sensory inputs. Much of the existing literature focuses on the role of feedâforward hierarchical processing for extracting such invariances. The present study proposes an alternative mechanism based on topâdown feedback. Focusing on the soâcalled sourceâseparation, or cocktailâparty problem, the manuscript shows how sources mixed in a contextâdependent manner can be separated independently of context, using feedâforward networks modulated by topâdown contextâdependent inputs.</p><p>The manuscript starts with a simplified, abstract network, and then progressively moves to more biologically plausible ones. By performing population analyses of network activity, the authors then argue for a mechanism based on contextâinvariant subspaces.</p><p>Strengths of the paper:</p><p>â novel proposal for an important class of cortical computations</p><p>â very elegant formulation of the problem</p><p>â the writing style is very clear and appealing</p><p>â network implementations at different levels of biophysical realism.</p><p>Weaknesses of the paper:</p><p>â the announced mechanism, based on invariant subspaces, is not clearly explained and needs to be supported by additional evidence.</p><p>â how the network detects contextual changes does not seem to be explained</p><p>â the analyses of network activity, their rationale and the resulting conclusions are difficult to follow.</p></disp-quote><p>We thank the reviewer for their interest in our work. We hope to have addressed all of the weaknesses listed above with the revision of the manuscript. In brief:</p><p>â We provide a more in-depth analysis of the mechanism based on invariant subspaces (see Change 2 above).</p><p>â We show and discuss what the network needs to detect context changes (see Change 4 above).</p><p>â We rearranged the results in the manuscript and added additional explanations to make the sequence of analyses and main findings clearer (see Change 1 and 3 above).</p><disp-quote content-type="editor-comment"><p>While I very much appreciated the novelty and the elegance of the approach developed in this paper, ultimately, I was left wondering how the networks perform their task.</p><p>â The title and abstract announce a mechanism based on invariant neural subspaces. Clearly, since the readout is fixed, there must be an invariant subspace, but the key question is how it is generated and maintained across contexts. In the Results, this mechanism is explained only briefly at the very end of the results, in connection to Figure 6, which seems to be just an illustration. The authors would need to unpack what precisely the mechanism is (not clear right now) and give more evidence for it.</p></disp-quote><p>We agree with the reviewer that the mechanism based on invariant subspaces needed more unpacking to underscore the main claims of the paper. As outlined in Change 2 above, we have extended our analyses of the mechanism and provided a quantification of the findings illustrated in the previous Figure 6.</p><disp-quote content-type="editor-comment"><p>â An important complementary issue is how the network detects context changes. The manuscript states that &quot;feedbackâmediated invariance requires time to establish after contextual changes&quot; (lines 245â246), but how this works does not seem to be explained. What type of error signal does the network use to change the gains?</p><p>On a related note, is the network trained on all the contexts it sees during testing, or is it able to deal with totally novel contexts?</p></disp-quote><p>We thank the reviewer for pointing out that this was not sufficiently explained. As described in Change 4, we have added several sentences and a supplementary figure to clarify how the modulator maps its input to the correct feedback modulation:</p><p>â[â¦] The modulator therefore had to use its recurrent dynamics to determine the appropriate modulatory feedback for the time-varying context, based on the sensory stimuli and the network output. Put differently, the modulator had to learn an internal model of the sensory data and the contexts, and use it to establish the desired context invariance in the output.â (ll. 57-61)</p><p>âBecause the network had to learn an internal model of the task, we expected a limited degree of generalisation to new situations. Indeed, the network was able to interpolate between source frequencies seen during training (Supp. Figure S5), but failed on sources and contexts that were qualitatively different (Supp. Figure S6 b-d). The specific computations performed by the modulator are therefore idiosyncratic to the problem at hand. Hence, we did not investigate the internal dynamics of the modulator in detail, but concentrated on its effect on the feedforward network.â (ll. 85-91)</p><p>These excerpts should also answer the question regarding new contexts. Note that contexts were randomly sampled from a continuous context space for training and testing. The network is therefore not tested on the exact same contexts, but on contexts from the same distribution (unless specified otherwise). We have also clarified this in the methods section:</p><p>âUnless specified otherwise, we sampled new contexts for each training batch and for the test data, such that the training and test data followed the same distribution without necessarily being the same.â (ll. 494-497)</p><p>Regarding the question of the error signal: The modulator does not use an error signal, but computes a new mapping from its input to the correct modulation in response to context changes. Since the inputs are time-dependent the modulator needs to see a sufficient number of time-points before it can provide the appropriate feedback signal.</p><p>In additional analyses we found that a feedforward network can also solve the task, if it is given a time window of the sensory signals rather than a single moment in time. Such a network requires about the same number of timesteps from the stimuli (compare with Supp. Figure S1i and Supp. Figure S6a) as the modular-based architecture. This shows that the time it takes the network to infer the context from its input is not particular to our model but to the task, i.e. the statistics of the sources and contexts.</p><disp-quote content-type="editor-comment"><p>â The logic of the sequence of analysis (optogenetic manipulations; correlation; changes in gainâ¦) is a bit difficult to follow and needs more motivation. In particular, why is the nonâlinear encoding of context important?</p></disp-quote><p>As described in the general answer, we agree that the sequence of analyses was not intuitive to the reader and thus rearranged the results in the new version of the manuscript. In particular, we have removed the optogenetic manipulations and considerations of E/I balance, since they are not central to the message of the paper (see Change 1 and 3 above).</p><p>Regarding the non-linear encoding of the context: We now include a deeper discussion of the results (see Change 3) that aim to clarify the relevance of these findings:</p><p>âIn summary, the higher-population provides a linear representation not only of the stimuli, but also of the context. In contrast, the modulatory units contained a nonlinear representation of the context, which could not be extracted by linear decoding approaches. We speculate that if contextual feedback modulation is mediated by interneurons in layer 1, they should represent the context in a nonlinear way.â (ll. 288-292).</p><disp-quote content-type="editor-comment"><p>â It is a bit surprising that the analyses focus on the most complex version of the network to examine mechanisms. Presumably the simplified networks could be leveraged to identify and explain the mechanisms in a more transparent manner.</p></disp-quote><p>We want to thank the reviewer for this suggestion as we think it has significantly helped us to improve the structure of the manuscript. We now perform the single cell and population analyses on the network with spatially diffuse modulation (from Figure 3), as this is the simplest model comprising a neural population. We then verify that the findings hold for the Dalean network (new Figure 6). Details on the new order of the results can be found in the list of major changes above (specifically point 1).</p><disp-quote content-type="editor-comment"><p>Reviewer #2:</p><p>The authors aim to explore an understudied potential function of feedback connections: providing contextâindependent sensory processing. Invariant sensory processing is frequently assumed to be carried out by feedforward processing and much of the study of feedback focuses on how feedback could implement contextâdependent processing. This makes this study promising and relatively novel.</p><p>The strengths of this paper are that it demonstrates convincingly and using a variety of network architectures and feedback mechanisms that feedback modulations can indeed help a network read out sensory input in a contextâindependent way.</p><p>The weaknesses are in the analysis and comparisons of the various networks. While the basic finding that this invariance does not result from invariant activity on the individual neuron level is interesting and of value, the explanation that it instead leads to invariant population activity is almost tautological given the network architecture. It is also unclear how the simpler models the authors present are meant to provide insight on either the more biologically detailed hierarchical model or on real neural processing, especially given that the mode of modulation in the simplest model (reâweighting of feedforward weights) differs from that of the later models (reâweighting of neural activation). In this way I don't feel that the authors fully achieved their goal of describing the mechanism of feedback modulation.</p><p>The methods appear technically sound, but I am confused by some of the choices. For example, the authors start with a single layer network where feedback modulates the weights between the input and output. This is a different mechanism than the normal neuronal gain usually attributed to feedback. The authors then add more details to push the model more in the biological direction, but multiple details are sometimes added at once and the logic behind these choices isn't always clear. I believe the authors switch to using neuronal gain when they want to explore spatially correlated modulation, but they don't talk about neuronal modulation until they introduce their full hierarchical model. The hierarchical model also adds Dale's law and a separate inhibitory population but it is not clear why these details were added or if/how they change the function of the model in a way relevant to understanding feedback modulation. Even the use of a multiâlayer model is not very well motivated given that they show that this task can be completed with a very small one layer model. The simplicity of the task has implications for understanding some of these findings as well. For example, to show that modulatory signals can be spatially correlated, the authors create a model with many more neurons than is needed to solve the task and show that the modulatory signal can target nearby cells in this population similarly without sacrificing performance. But the low dimensional nature of the modulatory signal is only really an issue of interest in the context of a higher dimensional task. As a thought experiment: if the 2 neurons in the original model were simply replicated to 50 each and each population of 50 neurons was given the same modulation, this would be essentially equivalent to the original 2 cell model, but under the logic of what the authors have shown here, would supposedly demonstrate that modulatory signals still work if low dimensional. In this way, that analysis fell short.</p><p>I think that this work may spur more interest in studying the role of feedback for invariant sensory processing, which would be a very productive outcome. Furthermore, the demonstration that the context signals cannot be linearly readout from the cells performing the modulation is an important lesson for the analysis of neural data. I also think further reflection on the finding that the modulatory network needs direct sensory input (more so even than the input from later processing stages) will be very important for understanding how this modulation works and how it relates to biological structures. As the authors note, this may mean that their model is more akin to inputs from higher order thalamic areas, though even that mapping is imperfect due to the lack of recurrence.</p></disp-quote><p>We thank the reviewer for their thorough assessment of our work and for raising important concerns about the sequence of analyses and line of argumentation. In the following we first address what we think are the main concerns raised. After that, we respond to the specific recommendations in more detail.</p><p>Main concerns and answers:</p><p>1. Concern: The emergence of subspaces at the population level is not a surprising finding.</p><p>It is indeed not surprising that the neural population contains a context-invariant subspace. We do not think the existence of an invariant subspace is the main finding of our work, but rather how this subspace can be dynamically maintained by feedback modulation. Nevertheless, we think it is worth noting that the invariant subspace can not only be extracted with the readout learned during training, but also with a separate decoder that was trained on only a few contexts. To make clearer why this could be of interest, we have edited the respective text:</p><p>âIn fact, the population had to contain an invariant subspace, because the fixed linear readout of the population was able to extract the sources across contexts. However, the linear decoding approach shows that this subspace can be revealed from the population activity itself with only a few contexts and no knowledge of how the neural representation is used downstream. The same approach could therefore be used to reveal context-invariant subspaces in neural data from population recordings.â (ll. 179-185)</p><p>2. Concern: It is unclear how simpler models give insight into the more complex models. Relatedly, some model choices are not well motivated.</p><p>We acknowledge that the connection between the models was not made sufficiently clear. To address this, we made several changes to the manuscript. First, we demonstrate explicitly that the network with spatial modulation finds an equivalent solution to the initial linear readout network. In particular, we show that the effective weights from the stimuli to the network output in the network with spatial modulation also follow the inverse of the mixing (Supp. Figure S8d) and describe this in the text:</p><p>âThe diffuse feedback modulation switched when the context changed, but was roughly constant within contexts (Figure 3c), as in the simple model. The effective weight from the stimuli to the network output also inverted the linear mixture of the sources (Supp. Figure S8d, compare with Figure 1c).â (ll. 143-146)</p><p>Second, we perform the population level analyses on the simpler spatially modulated model and then verify that the same results hold for the Dalean network (see Major Change 1 and 3 above). This demonstrates that our findings are not a result of the specific architecture of the feedforward model. Third, we have added a few more sentences to motivate the distinction between the two neural populations in the Dalean model:</p><p>âWe extended the feedforward model as follows (Figure 6a): First, all neurons had positive firing rates. Second, we split the neural population (z in the previous model) into a &quot;lower-level&quot; (z<sup>L</sup>) and &quot;higher-level&quot; population (z<sup>H</sup>). The lower-level population served as a neural representation of the sensory stimuli, whereas the higher-level population was modulated by feedback. This allowed a direct comparison between a modulated and an unmodulated neural population. It also allowed us to include Dalean weights between the <italic>two populations.â (ll. 236-242)</italic></p><p>3. Concern: The feedback can only be low-dimensional, because the task is low-dimensional.</p><p>The reviewer is right that the low dimensionality of the task is why the feedback modulation can be low-dimensional. More precisely, it is the low dimensionality of the context that allows a low-dimensional feedback modulation. We acknowledge this in lines 148-150 of the manuscript:</p><p>âMoreover, the feedback could have a spatially broad effect on the modulated population without degrading the signal clarity (Figure 3e, Supp. Figure S6), consistent with the low dimensionality of the context.â (ll. 148-150)</p><p>The size of the neural populations that are necessary to solve the task are more related to the dimensionality of the stimuli or the degree of nonlinearity in the input-output mapping. Therefore, a low-dimensional and diffuse modulation may still be functional for more high-dimensional or nonlinear tasks, as long as the context remains low-dimensional. We also think that for higher dimensional inputs feedforward mechanisms could play a role in preprocessing them either directly towards invariance or into a form where the modulation can achieve it most effectively.</p><disp-quote content-type="editor-comment"><p>I think it would help the readability of the paper if the authors included a few more brief descriptions of the methods in the Results. For example, a better description of how the signals are generated, the fact that the networks are trained with a single set of signals only, etc. Also, there were points where it wasn't clear if a network was tested under different conditions or actually retrained for them (for example, in figure 2d/e). Also, the fact that the modulation went from being on the weights to on the neurons themselves was not made clear in section &quot;Invariance can be established by spatially diffuse feedback modulation&quot;. I also found the schematic in Figure 1a a bit confusing. I don't know why x is represented as a question mark when it is a sum of the two signals. I'd prefer a diagram that makes the dimensionality of x clearer (relatedly, why are there only 3 weights from x to y when I believe it is a 2x2 matrix).</p></disp-quote><p>We thank the reviewer for providing specific recommendations on how to improve the readability of the manuscript. We have implemented this advice by adding the key equations of the setup to the results. We also added a methods figure that explicitly illustrates the task, the model and the training setup on a more technical level (see Figure 8). Furthermore, we adapted Figure 1a according to the reviewerâs recommendation.</p><p>Regarding the lack of clarity if the network was retrained or not, we hope that the additional analyses on the generalisation ability of the network help make this point clearer. To make explicit that networks were retrained for Figure 2 we modified the text to say:</p><p>âTo investigate how the timescale of modulation affects the performance in the dynamic blind source separation task, we trained network models, in which the modulatory feedback had an intrinsic timescale that forced it to be slow.â (ll. 103-105)</p><p>Finally, it is correct that in Figure 3 the modulation went from modulating weights to modulating neurons. For the spatially diffuse modulation, we assumed that all weights to a neuron receive the same modulation. Since synaptic inputs are integrated linearly, this is equivalent to a neuronal gain modulation. We have added an explicit explanation to the results:</p><p>âWe here assume that all synaptic weights to a neuron receive the same modulation, such that the feedback performs a gain modulation of neural activity (Ferguson and Cardin, 2020).â (ll. 137-139)</p><disp-quote content-type="editor-comment"><p>&quot;While we trained the modulatory system using supervised learning, the contextual inference is performed by its dynamics without access to the target sources and thus unsupervised&quot; I feel this could be read as saying that an actual unsupervised objective was used, when in fact only supervised learning took place, so I would suggest reâwording.</p></disp-quote><p>Good point. We have changed this sentence to make clear that the training of the network itself is unsupervised. It now reads:</p><p>âThe modulator was trained using supervised learning. Afterwards, its weights were fixed and it no longer had access to the target sources (see Materials and methods, Figure 8). The modulator therefore had to use its recurrent dynamics to determine the appropriate modulatory feedback for the time-varying context, based on the sensory stimuli and the network output. Put differently, the modulator had to learn an internal model of the sensory data and the contexts, and use it to establish the desired context invariance in the output.â (ll. 55-61)</p><disp-quote content-type="editor-comment"><p>I didn't understand the claim about matched EI inputs and how it depends on using gain modulation. This should probably be expanded and related to the main questions of the paper or possibly removed.</p></disp-quote><p>Motivated by this recommendation and other comments we have removed these results from the paper in order to make more room for the central claims of the manuscript (see Change 3 above).</p><disp-quote content-type="editor-comment"><p>Figure 4i seems to be the main demonstration that individual neural activity itself is not invariant to context. I'd like to see a more inâdepth exploration of this. Particularly, if the readout only relied on a small handful of neurons then finding that the rest of the neurons are not contextâinvariant wouldn't prove that individual neural invariance is not a relevant mechanism. Given that the readout from this network is known, it would be particularly easy to determine if the heavily weighted neurons in particular are or are not context invariant.</p></disp-quote><p>We thank the reviewer for this suggestion on how to further explore the lack of invariance of single neurons. These analyses are now performed on the simpler network in a new Figure 4 (see Change 1 above). We have extended our analyses and the text according to the reviewerâs suggestions:</p><p>âHowever, a first inspection of neural activity indicated that single neurons are strongly modulated by context (Figure 4a). To quantify this, we determined the signal clarity for each neuron at each stage of the feedforward network, averaged across contexts (Figure 4b). As expected, the signal clarity was low for the sensory stimuli. Intriguingly, the same was true for all neurons of the modulated neural population, indicating no clean separation of the sources at the level of single neurons. Although most neurons had a high signal clarity in some of the contexts, there was no group of neurons that consistently represented one or the other source (Figure 4c). Furthermore, the average signal clarity of the neurons did not correlate with their contribution to the readout (Figure 4d).â (ll. 161-170)</p><disp-quote content-type="editor-comment"><p>In general, I don't understand why the authors use a separately trained linear readout when trying to show that the population activity at the final layer is invariant. They eventually acknowledge that &quot;Since this readout is obtained from the data, this procedure does not require knowledge of the readout in the network model. Note that the trained decoder and the network readout are not necessarily identical&quot; but they don't explain why they are using this alternative readout or what new insights its use adds. Particularly, the performance of the network indicates the there is some sort of context invariant read out possible from this population, yet the authors use this other readout in a way that is seemingly supposed to add something to the explanation.</p></disp-quote><p>We agree with the reviewer that it was not sufficiently clear why we used the linear readout obtained from the data. The original idea was to highlight that these analyses can be done on neural data, because they do not require knowing the readout that is performed by downstream areas. We acknowledge that raising this point while explaining the feedback-freezing-experiment is confusing. To address this, we now use the modelâs readout (former Figure 6, now Figure 5). In addition, we explicitly highlight that an invariant readout could be obtained from neural data (see response to public review above).</p><disp-quote content-type="editor-comment"><p>Be sure to say what errorbars are based on in all figures.</p></disp-quote><p>Thank you for pointing this out. We have added the respective information to the captions.</p><disp-quote content-type="editor-comment"><p>&quot;In our model, the mechanism needs to satisfy a few key</p><p>requirements: i) the modulation is not uniform across the population, ii) it operates on a timescale similar to that of changes in context, and iii) it is driven by feedback projections.&quot; I don't understand claim (iii). If anything, the results show the importance of the modulation being driven by feedforward sensory signals (figure 2d/e).</p></disp-quote><p>Yes, that's a fair point. We have rephrased the respective sentence as follows:</p><p>â[â¦] iii) it is driven by a brain region that has access to the information needed to infer the contextâ (ll. 349-350)</p><disp-quote content-type="editor-comment"><p>&quot;In addition, feedback inputs from the sensory to the modulatory system allow a better control of the modulated network state.&quot; I don't see how the connections from a sensory system to a modulatory system are &quot;feedback&quot;.</p></disp-quote><p>We believe that our phrasing was unfortunate. We meant feedback from the feedforward networkâs output. In the brain, this could correspond to higher-level sensory areas:</p><p>âIn addition, feedback inputs from higher-level sensory areas to the modulatory system allow a better control of the modulated network state.â (ll. 375-377).</p><disp-quote content-type="editor-comment"><p>Reviewer #3:</p><p>I appreciate the didactic way in which the manuscript was written (and beautiful figures!), in particular the progression from a vanilla architecture towards the full fledged model with EI rectified neurons with spatially specific modulation. My main concerns (detailed below) are twoâfold:</p><p>1. I felt that some extensions were not explicitly justified (e.g. why 2 layers instead of 2, etc)</p><p>2. I was expecting more 'reverseâengineering' of the mechanism through which the network accomplishes a context invariant projection. This is the main result of the paper, as reflected in the title, so I think it deserves more unpacking. Below I unpack these concerns, sometimes providing some suggestions to improve the motivation and clarity of the paper (without any particular order)</p></disp-quote><p>We thank the reviewer for their very constructive feedback and agree with both points made here. We hope to have addressed them with the revision of the manuscript, in particular Changes 1-3 (see above). Below we provide answers to the specific recommendations and questions in some more detail.</p><disp-quote content-type="editor-comment"><p>1. Overall, the architecture choices are a bit unjustified. In the extreme, wouldn't the LSTM alone solve the task? The addition of each feedforward layer should be better motivated (e.g. more biologically realistic? In what sense?). For example, why add an extra layer from extensions 2 and 3? If those are necessary, this should be explained. If they are not necessary, they should be removed.</p></disp-quote><p>We are glad that the reviewers have brought this to our attention. We have substantially reorganised the paper to clarify which architectural choices are relevant for which finding (Changes 1 and 3).</p><p>We modified the description of the Dalean network to make our model choices more transparent to the reader:</p><p>âWe extended the feedforward model as follows (Figure 6a): First, all neurons had positive firing rates. Second, we split the neural population (z in the previous model) into a &quot;lower-level&quot; (z<sup>L</sup>) and &quot;higher-level&quot; population (z<sup>H</sup>). [â¦] This allowed for a direct comparison between a modulated and an unmodulated neural population. It also allowed us to include Dalean weights between the two populations.â (ll. 236-242)</p><p>â[â¦] the higher-level population contained a context-invariant subspace (Figure 6f). This was not the case for the lower-level population, underscoring that invariant representations do not just arise from projecting the sensory stimuli into a higher dimensional space.â (ll. 262-266)</p><p>Furthermore, we decided to perform our single neuron and population analyses on the simpler network with spatially diffuse modulation and verify them on the Dalean network (see Change 1). We hope that the new manuscript structure and the additional analyses address the concerns raised above.</p><p>Regarding the question whether an LSTM alone can solve the task: yes it can. We tested this during the course of the project. This is not surprising, because an LSTM could in principle even learn the same architecture as we use here. Our architecture may even make it more difficult to solve the task since it contains more constraints. However, the focus of this project was not on whether a recurrent network can solve this task, but rather what role feedback modulation could play in (invariant) sensory processing. We have therefore decided not to include any results from a purely recurrent network.</p><disp-quote content-type="editor-comment"><p>2. 'Because the task requires a dynamic inference of the context, it cannot be solved by feedforward networks or standard blind source separation algorithms' I think the paper could be better motivated if this was shown explicitly with some examples.</p></disp-quote><p>We agree that this would help to motivate the architecture of our model and have included a new supplementary figure, in which we explicitly demonstrate that a feedforward network cannot solve the task (see Supp. Figure S1).</p><disp-quote content-type="editor-comment"><p>3. A figure explicitly illustrating the training setup would help motivate what is trivially solved and what is actually challenging. For instance, in the main manuscript, it is not clear in which cases the network is trained and tested on the same contexts (ie A(t)) and which cases it is not. In the first case, the context can be easily inferred from x(t) but the latter is more challenging?</p></disp-quote><p>We thought this was an excellent idea and have created a methods figure that illustrates the task, the model and the training setup explicitly (see Figure 8). Generally, we always sample new contexts when testing the model, from the same distribution as during training (unless stated otherwise). We now also show that the network does not generalise to out-of-distribution contexts or sensory stimuli (Supp. Figure S6, see also Change 4 above).</p><disp-quote content-type="editor-comment"><p>4. however I understand that the paper is already too long, Intra / extrapolation results deserve more spotlight and unpacking in my opinion. In general, if there is a lack of space, I would merge Figure 1 and figure 2 â and jump directly to extension 1 â and move most of figure 2 to sup.</p></disp-quote><p>We thank the reviewer for this suggestion. We removed some results and reorganised the remaining results such that there is more focus on the invariant subspaces. Hence, we do not feel that the manuscript has become substantially longer. Furthermore, we would prefer to only show the proof of concept in the first figure, in order to not overload the reader. If the reviewers find that the paper is much too long, we could move figure 2 to the supplementary material.</p><disp-quote content-type="editor-comment"><p>5. Most important concern to me: Figure 6, in which the mechanism is revealed, deserves more quantifications to explicitly pinpoint the mechanism. Three suggestions come to mind:</p></disp-quote><p>Thanks, these are great suggestions.</p><disp-quote content-type="editor-comment"><p>a. Plot the 3 PCs components (instead of just 1) and show the readout in this space. The key result is that the readout is invariant to context and this is not clearly illustrated at the moment. Instead, what is shown is that the representation changes, but that it changes in a way that preserves invariance on the readout is not clearly highlighted.</p></disp-quote><p>Unfortunately, using the space of the first 3 PCs instead of the first PC and the readout axes does not illustrate the invariant subspace in an intuitive way (see Change 2). Therefore, we decided to stick with the more unconventional space but verify our findings for PC space in a new supplementary figure (Supp. Figure S9). To better illustrate that the readout is context-invariant we plotted the projection of the subspace onto the readout into the 3D figure (Figure 5b) and make explicit that this is the same projection as shown in Figure 5c.</p><disp-quote content-type="editor-comment"><p>b. The authors highlight that the network is not just reversing the new mixing coefficients and projecting the activity back into the 2d low manifold. Instead, it is rotating everything out of this manifold. My suggestion would be to show this alternatively explicitly. Is it actually possible? Relatedly, what happens if the context is changed back to context 1?</p><p>c. Finally, all the statements made about this figure should be quantified and not just illustrated for 1 trial.</p></disp-quote><p>Regarding b and c: As described in Change 2, we have implemented the reviewerâs advice by adding a quantification to the former Figure 6 (now Figure 5) in terms of the angles between the subspaces (Figure 5d). We also show that the magnitude of this change depends on the similarity of the old and the new context (Figure 5dande), indicating that there is a consistent mapping between context and the low-dimensional population activity. Switching back to context 1 would therefore reinstate the original subspace, without hysteretic effects.</p></body></sub-article></article>