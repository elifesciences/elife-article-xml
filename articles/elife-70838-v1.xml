<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD v1.2 20190208//EN"  "JATS-archivearticle1.dtd"><article article-type="research-article" dtd-version="1.2" xmlns:ali="http://www.niso.org/schemas/ali/1.0/" xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink"><front><journal-meta><journal-id journal-id-type="nlm-ta">elife</journal-id><journal-id journal-id-type="publisher-id">eLife</journal-id><journal-title-group><journal-title>eLife</journal-title></journal-title-group><issn pub-type="epub" publication-format="electronic">2050-084X</issn><publisher><publisher-name>eLife Sciences Publications, Ltd</publisher-name></publisher></journal-meta><article-meta><article-id pub-id-type="publisher-id">70838</article-id><article-id pub-id-type="doi">10.7554/eLife.70838</article-id><article-categories><subj-group subj-group-type="display-channel"><subject>Research Article</subject></subj-group><subj-group subj-group-type="heading"><subject>Neuroscience</subject></subj-group></article-categories><title-group><article-title>Visual pursuit behavior in mice maintains the pursued prey on the retinal region with least optic flow</article-title></title-group><contrib-group><contrib contrib-type="author" equal-contrib="yes" id="author-242732"><name><surname>Holmgren</surname><given-names>Carl D</given-names></name><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="fn" rid="equal-contrib1">†</xref><xref ref-type="fn" rid="con1"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" equal-contrib="yes" id="author-242733"><name><surname>Stahr</surname><given-names>Paul</given-names></name><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="fn" rid="equal-contrib1">†</xref><xref ref-type="fn" rid="con2"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" id="author-242730"><name><surname>Wallace</surname><given-names>Damian J</given-names></name><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="fn" rid="con3"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" id="author-242734"><name><surname>Voit</surname><given-names>Kay-Michael</given-names></name><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="fn" rid="con4"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" id="author-242735"><name><surname>Matheson</surname><given-names>Emily J</given-names></name><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="fn" rid="con5"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" id="author-242736"><name><surname>Sawinski</surname><given-names>Juergen</given-names></name><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="fn" rid="con6"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" id="author-177428"><name><surname>Bassetto</surname><given-names>Giacomo</given-names></name><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="aff" rid="aff2">2</xref><xref ref-type="fn" rid="con7"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" corresp="yes" id="author-72109"><name><surname>Kerr</surname><given-names>Jason ND</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">https://orcid.org/0000-0001-9459-883X</contrib-id><email>jason.kerr@caesar.de</email><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="fn" rid="con8"/><xref ref-type="fn" rid="conf1"/></contrib><aff id="aff1"><label>1</label><institution>Department of Behavior and Brain Organization, Research center caesar</institution><addr-line><named-content content-type="city">Bonn</named-content></addr-line><country>Germany</country></aff><aff id="aff2"><label>2</label><institution>Machine Learning in Science, Eberhard Karls University of Tübingen</institution><addr-line><named-content content-type="city">Tübingen</named-content></addr-line><country>Germany</country></aff></contrib-group><contrib-group content-type="section"><contrib contrib-type="editor"><name><surname>Vinck</surname><given-names>Martin</given-names></name><role>Reviewing Editor</role><aff><institution>Ernst Strüngmann Institute (ESI) for Neuroscience in Cooperation with Max Planck Society</institution><country>Germany</country></aff></contrib><contrib contrib-type="senior_editor"><name><surname>Moore</surname><given-names>Tirin</given-names></name><role>Senior Editor</role><aff><institution>Stanford University</institution><country>United States</country></aff></contrib></contrib-group><author-notes><fn fn-type="con" id="equal-contrib1"><label>†</label><p>These authors contributed equally to this work</p></fn></author-notes><pub-date date-type="publication" publication-format="electronic"><day>26</day><month>10</month><year>2021</year></pub-date><pub-date pub-type="collection"><year>2021</year></pub-date><volume>10</volume><elocation-id>e70838</elocation-id><history><date date-type="received" iso-8601-date="2021-05-31"><day>31</day><month>05</month><year>2021</year></date><date date-type="accepted" iso-8601-date="2021-09-30"><day>30</day><month>09</month><year>2021</year></date></history><pub-history><event><event-desc>This manuscript was published as a preprint at bioRxiv.</event-desc><date date-type="preprint" iso-8601-date="2021-06-16"><day>16</day><month>06</month><year>2021</year></date><self-uri content-type="preprint" xlink:href="https://doi.org/10.1101/2021.06.15.448520"/></event></pub-history><permissions><copyright-statement>© 2021, Holmgren et al</copyright-statement><copyright-year>2021</copyright-year><copyright-holder>Holmgren et al</copyright-holder><ali:free_to_read/><license xlink:href="http://creativecommons.org/licenses/by/4.0/"><ali:license_ref>http://creativecommons.org/licenses/by/4.0/</ali:license_ref><license-p>This article is distributed under the terms of the <ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/licenses/by/4.0/">Creative Commons Attribution License</ext-link>, which permits unrestricted use and redistribution provided that the original author and source are credited.</license-p></license></permissions><self-uri content-type="pdf" xlink:href="elife-70838-v1.pdf"/><abstract><p>Mice have a large visual field that is constantly stabilized by vestibular ocular reflex (VOR) driven eye rotations that counter head-rotations. While maintaining their extensive visual coverage is advantageous for predator detection, mice also track and capture prey using vision. However, in the freely moving animal quantifying object location in the field of view is challenging. Here, we developed a method to digitally reconstruct and quantify the visual scene of freely moving mice performing a visually based prey capture task. By isolating the visual sense and combining a mouse eye optic model with the head and eye rotations, the detailed reconstruction of the digital environment and retinal features were projected onto the corneal surface for comparison, and updated throughout the behavior. By quantifying the spatial location of objects in the visual scene and their motion throughout the behavior, we show that the prey image consistently falls within a small area of the VOR-stabilized visual field. This functional focus coincides with the region of minimal optic flow within the visual field and consequently area of minimal motion-induced image-blur, as during pursuit mice ran directly toward the prey. The functional focus lies in the upper-temporal part of the retina and coincides with the reported high density-region of Alpha-ON sustained retinal ganglion cells.</p></abstract><abstract abstract-type="executive-summary"><title>eLife digest</title><p>Mice have a lot to keep an eye on.</p><p>To survive, they need to dodge predators looming on land and from the skies, while also hunting down the small insects that are part of their diet. To do this, they are helped by their large panoramic field of vision, which stretches from behind and over their heads to below their snouts.</p><p>To stabilize their gaze when they are on the prowl, mice reflexively move their eyes to counter the movement of their head: in fact, they are unable to move their eyes independently. This raises the question: what part of their large visual field of view do these rodents use when tracking a prey, and to what advantage?</p><p>This is difficult to investigate, since it requires simultaneously measuring the eye and head movements of mice as they chase and capture insects. In response, Holmgren, Stahr et al. developed a new technique to record the precise eye positions, head rotations and prey location of mice hunting crickets in surroundings that were fully digitized at high resolution. Combining this information allowed the team to mathematically recreate what mice would see as they chased the insects, and to assess what part of their large visual field they were using.</p><p>This revealed that, once a cricket had entered any part of the mice’s large field of view, the rodents shifted their head – but not their eyes – to bring the prey into both eye views, and then ran directly at it. If the insect escaped, the mice repeated that behavior. During the pursuit, the cricket’s position was mainly held in a small area of the mouse’s view that corresponds to a specialized region in the eye which is thought to help track objects. This region also allowed the least motion-induced image blur when the animals were running forward.</p><p>The approach developed by Holmgren, Stahr et al. gives a direct insight into what animals see when they hunt, and how this constantly changing view ties to what happens in the eyes. This method could be applied to other species, ushering in a new wave of tools to explore what freely moving animals see, and the relationship between behaviour and neural circuitry.</p></abstract><kwd-group kwd-group-type="author-keywords"><kwd>vision</kwd><kwd>eye movements</kwd><kwd>freely moving behavior</kwd><kwd>prey capture</kwd><kwd>optic flow</kwd><kwd>methods development</kwd></kwd-group><kwd-group kwd-group-type="research-organism"><title>Research organism</title><kwd>Mouse</kwd></kwd-group><funding-group><funding-statement>No external funding was received for this work.</funding-statement></funding-group><custom-meta-group><custom-meta specific-use="meta-only"><meta-name>Author impact statement</meta-name><meta-value>Digital reconstruction of environment combined with eye and head-tracking enabled the process of prey-detection and capture to be seen from the freely moving mouse’s point-of-view and shows the exact visual-field and retinal location mice use when chasing prey and the advantage.</meta-value></custom-meta></custom-meta-group></article-meta></front><body><sec id="s1" sec-type="intro"><title>Introduction</title><p>The visual system of mice serves a variety of seemingly opposing functions that range from detection of predators, to finding shelter and selection of food and mates, and is required to do so in a diverse set of environments (<xref ref-type="bibr" rid="bib6">Boursot et al., 1993</xref>). For example, foraging in open areas where food is available involves object selection, and in the case of insect predation (<xref ref-type="bibr" rid="bib2">Badan, 1986</xref>; <xref ref-type="bibr" rid="bib63">Tann et al., 1991</xref>), involves prey tracking and capture (<xref ref-type="bibr" rid="bib18">Hoy et al., 2016</xref>; <xref ref-type="bibr" rid="bib31">Langley, 1983</xref>; <xref ref-type="bibr" rid="bib32">Langley, 1984</xref>; <xref ref-type="bibr" rid="bib33">Langley, 1988</xref>), but the visual system can also simultaneously be relied on for avoidance of predation, particularly from airborne predators (<xref ref-type="bibr" rid="bib21">Hughes, 1977</xref>). Like with many ground-dwelling rodents (<xref ref-type="bibr" rid="bib25">Johnson and Gadow, 1901</xref>), predator detection in mice is served by a panoramic visual field which is achieved by the lateral placement of the eyes in the head (<xref ref-type="bibr" rid="bib11">Dräger, 1978</xref>; <xref ref-type="bibr" rid="bib22">Hughes, 1979</xref>; <xref ref-type="bibr" rid="bib43">Oommen and Stahl, 2008</xref>) combined with monocular visual fields of around 200 degrees (<xref ref-type="bibr" rid="bib12">Dräger and Olsen, 1980</xref>; <xref ref-type="bibr" rid="bib22">Hughes, 1979</xref>; <xref ref-type="bibr" rid="bib60">Sterratt et al., 2013</xref>). In mice, the panoramic visual field extends to cover regions above the animal’s head, below the animal's snout and laterally to cover ipsilaterally from behind the animal's head to the contralateral side, with the overlapping visual fields from both eyes forming a large binocular region overhead and in front of the animal (<xref ref-type="bibr" rid="bib21">Hughes, 1977</xref>; <xref ref-type="bibr" rid="bib51">Sabbah et al., 2017</xref>). In addition, eye movements in freely moving mice constantly stabilize the animal’s visual field by counteracting head rotations through the vestibulo-ocular reflex (VOR) (<xref ref-type="bibr" rid="bib38">Meyer et al., 2020</xref>; <xref ref-type="bibr" rid="bib37">Meyer et al., 2018</xref>; <xref ref-type="bibr" rid="bib39">Michaiel et al., 2020</xref>; <xref ref-type="bibr" rid="bib45">Payne and Raymond, 2017</xref>) maintaining the large panoramic overhead view (<xref ref-type="bibr" rid="bib68">Wallace et al., 2013</xref>) critical for predator detection (<xref ref-type="bibr" rid="bib69">Yilmaz and Meister, 2013</xref>).</p><p>Given the VOR stabilized panoramic field of view, it is not clear what part of the visual field mice use to detect and track prey (but see: <xref ref-type="bibr" rid="bib24">Johnson et al., 2021</xref>). Mouse retina contains retinal ganglion cells (RGCs), the output cells of the retina, with a broad diversity of functional classes (<xref ref-type="bibr" rid="bib3">Baden et al., 2016</xref>; <xref ref-type="bibr" rid="bib5">Bleckert et al., 2014</xref>; <xref ref-type="bibr" rid="bib14">Franke et al., 2017</xref>; <xref ref-type="bibr" rid="bib70">Zhang et al., 2012</xref>). Given the lateral eye position, the highest overall density faces laterally (<xref ref-type="bibr" rid="bib13">Dräger and Olsen, 1981</xref>; <xref ref-type="bibr" rid="bib51">Sabbah et al., 2017</xref>; <xref ref-type="bibr" rid="bib53">Salinas-Navarro et al., 2009</xref>; <xref ref-type="bibr" rid="bib59">Stabio et al., 2018</xref>). Further, as the functionally defined ganglion cells (<xref ref-type="bibr" rid="bib3">Baden et al., 2016</xref>; <xref ref-type="bibr" rid="bib5">Bleckert et al., 2014</xref>; <xref ref-type="bibr" rid="bib14">Franke et al., 2017</xref>; <xref ref-type="bibr" rid="bib70">Zhang et al., 2012</xref>) and cone sub-types (<xref ref-type="bibr" rid="bib62">Szél et al., 1992</xref>) are segregated into retinal subregions within the large stabilized field of view, recent studies suggest that retinal subregions are tuned for specific behavioral tasks depending on what part of the world they subtend (<xref ref-type="bibr" rid="bib3">Baden et al., 2016</xref>; <xref ref-type="bibr" rid="bib5">Bleckert et al., 2014</xref>; <xref ref-type="bibr" rid="bib21">Hughes, 1977</xref>; <xref ref-type="bibr" rid="bib51">Sabbah et al., 2017</xref>; <xref ref-type="bibr" rid="bib61">Szatko et al., 2020</xref>; <xref ref-type="bibr" rid="bib70">Zhang et al., 2012</xref>).</p><p>The challenge is to measure what part of the visual field the mouse is attending to during a visually based tracking task (<xref ref-type="bibr" rid="bib18">Hoy et al., 2016</xref>) and the location of all objects within the field of view during the behavior. While recent studies have implied the relationship between prey and retina through tracking head position (<xref ref-type="bibr" rid="bib24">Johnson et al., 2021</xref>) or measured both the horizontal and vertical eye rotations (<xref ref-type="bibr" rid="bib38">Meyer et al., 2020</xref>; <xref ref-type="bibr" rid="bib37">Meyer et al., 2018</xref>) during pursuit behavior (<xref ref-type="bibr" rid="bib39">Michaiel et al., 2020</xref>) to uncover a large proportion of stabilizing eye-rotations, what is missing is the extent and location of the area used when detecting and pursuing prey, and the relationship to the retina (<xref ref-type="bibr" rid="bib5">Bleckert et al., 2014</xref>).</p><p>Here, we measured the position of a cricket in the visual fields of freely moving mice performing a prey pursuit behavior, using head and eye tracking in all three rotational axes, namely horizontal, vertical, and torsional. Eye tracking included an anatomical calibration to accurately account for the anatomical positions of both eyes. To quantify object location in the animal’s field of view and generate optic flow fields, head and eye rotations were combined with a high-resolution digital reconstruction of the arena to form a detailed visual map from the animal’s eye perspective. Given that mice use multisensory strategies during prey pursuit (<xref ref-type="bibr" rid="bib17">Gire et al., 2016</xref>; <xref ref-type="bibr" rid="bib31">Langley, 1983</xref>; <xref ref-type="bibr" rid="bib33">Langley, 1988</xref>) and can track prey using auditory, visual, or olfactory cues (<xref ref-type="bibr" rid="bib31">Langley, 1983</xref>; <xref ref-type="bibr" rid="bib33">Langley, 1988</xref>), we developed a behavioral arena that isolated the visual aspect of the behavior by removing auditory and olfactory directional cues to ensure that the behavior was visually guided. To transfer the retinal topography onto the corneal surface, we developed an eye model capturing the optical properties of the mouse eye. We show that during prey detection mice preferentially position prey objects in stable foci located in the binocular field and undertake direct pursuit. Prey objects remain in the functional foci through the stabilizing action of the VOR, and not through active prey-pursuit eye movements. The stabilized functional foci are spatially distinct from the regions of highest total retinal ganglion cell density, which are directed laterally, but coincides with the regions of the visual field where there is minimal optic flow and therefore minimal motion-induced image disturbance during the behavior, as the mouse runs towards the cricket. Lastly, by building an optical model that allows corneal spatial locations to be projected onto the retina, we suggest that the functional foci correspond to retinal subregions containing a large density of Alpha-ON sustained RGCs that have center-surround receptive fields and project to both superior colliculus and dLGN (<xref ref-type="bibr" rid="bib20">Huberman et al., 2008</xref>) and possess properties consistent with the requirements for tracking small and mobile targets (<xref ref-type="bibr" rid="bib26">Krieger et al., 2017</xref>).</p></sec><sec id="s2" sec-type="results"><title>Results</title><sec id="s2-1"><title>Forming a view from the animal’s point of view</title><p>To measure what part of the visual field mice use during prey capture while also considering that mice can use multisensory strategies during prey pursuit (<xref ref-type="bibr" rid="bib17">Gire et al., 2016</xref>; <xref ref-type="bibr" rid="bib31">Langley, 1983</xref>; <xref ref-type="bibr" rid="bib33">Langley, 1988</xref>), we first developed an arena which isolated the visual component of prey pursuit by masking olfactory and auditory spatial cues (<xref ref-type="fig" rid="fig1">Figure 1A</xref>, see Materials and methods for details). By removing both olfactory and auditory cues, the average time to capture a cricket approximately doubled compared to removal of auditory cues alone (time to capture, median ± SD, control 24.92 ± 16.77 s, olfactory and auditory cues removed, 43.51 ± 27.82 s, p = 0.0471, Wilcoxon rank sum test, N=13 control and 12 cue removed trials from N = 5 mice). To track mouse head and eye rotations during prey capture, we further developed a lightweight version of our head mounted oculo-videography and camera-based pose and position tracking system (<xref ref-type="bibr" rid="bib68">Wallace et al., 2013</xref>; <xref ref-type="fig" rid="fig1">Figure 1B</xref> and Materials and methods). This approach allowed quantification of head rotations in all three axes of rotation (pitch, roll, and yaw), as well as eye rotations in all three ocular rotation axes (torsion, horizontal, and vertical, <xref ref-type="fig" rid="fig1">Figure 1C</xref>, <xref ref-type="fig" rid="fig1s1">Figure 1—figure supplement 1A and B</xref>). The same camera-based system was used to track and triangulate the position of the cricket (see Materials and methods and <xref ref-type="fig" rid="fig1s1">Figure 1—figure supplement 1C</xref>). To quantify the position and motion of the environment and cricket in the mouse's field of view, we also developed a method that enabled a calibrated environment digitization to be projected onto the corneal surface. This approach utilized a combination of laser scanning and photogrammetry, giving a resolution for the reconstruction of the entire experimental room of 2 mm, as well as a detailed measurement of eye and head rotations (<xref ref-type="fig" rid="fig1">Figure 1D–E</xref>, and see Materials and methods). Mice, like rats (<xref ref-type="bibr" rid="bib68">Wallace et al., 2013</xref>), have a large visual field of view which extends to also cover the region over the animal’s head (<xref ref-type="fig" rid="fig1">Figure 1F</xref>). To ensure the entire visual fields of the mouse could be captured during behavior, we digitized the entire experimental room and contents (<xref ref-type="fig" rid="fig1">Figure 1E</xref>, <xref ref-type="fig" rid="fig1s1">Figure 1—figure supplement 1D–F</xref>, <xref ref-type="video" rid="video1">Video 1</xref>). The coordinate systems of the environmental digitization and mouse and cricket tracking systems were registered using 16–20 fiducial markers identified in both the overhead camera images and the digitized environment. The average differences in position of fiducial points between the two coordinate systems were less than 1 mm (mean ± SD, x position, 0.18 ± 3.1 mm, y position, 0.07 ± 1.6 mm, z position, 0.66 ± 1.8 mm, N=54 fiducial points from three datasets). The next step was to re-create the view for each eye. First, and for each mouse, the positions of both eyes and nostrils were measured with respect to both the head-rotation tracking LEDs and head-mounted cameras, then calibrated into a common coordinate system (<xref ref-type="fig" rid="fig1">Figure 1B</xref>). Together, this enabled a rendered representation of the digitized field of view for each combination of head and eye rotations. This rendered image, from the animal’s point of view, contained all the arena and lab objects (<xref ref-type="fig" rid="fig1">Figure 1G–H</xref>, <xref ref-type="video" rid="video2">Video 2</xref> and <xref ref-type="video" rid="video3">3</xref>, <xref ref-type="fig" rid="fig1s1">Figure 1—figure supplement 1G</xref>). In addition to object position and distance (<xref ref-type="fig" rid="fig1">Figure 1I</xref>), the motion of the environment and each object in the field of view could be quantified as the mouse performed prey capture behaviors (<xref ref-type="fig" rid="fig1">Figure 1J</xref>, and <xref ref-type="fig" rid="fig1s1">Figure 1—figure supplement 1H</xref>).</p><fig-group><fig id="fig1" position="float"><label>Figure 1.</label><caption><title>Reconstruction of experimental arena and surrounds from the animal’s perspective.</title><p>(<bold>A</bold>) Schematic of experimental arena with olfactory and auditory noise. (<bold>B</bold>) Schematic of tracking, anatomical and eye camera calibration. Head position and orientation was tracked using seven IR-LEDs (colored circles). Nostrils (red, yellow filled circles), left (blue filled circle), and right (green filled circle) medial canthi were identified and triangulated in calibration images and used to define a common coordinate system (forward, blue arrow, right, green arrow, and up, red arrow), into which the calibrated eye camera location and orientation could also be placed (eye camera vertical, cyan, horizontal, purple, camera optical axis, red). (<bold>C</bold>) Example left- and right eye camera images with tracked pupil position (white dashed outlines). (<bold>D</bold>) Rendered digital reconstruction of the laboratory room and (E) experimental arena. (<bold>F</bold>) Schematic representation of mouse’s left- (blue) and right (green) visual fields, showing also the region of binocular overlap (yellow) and un-seen region (white). (<bold>G</bold>) Reconstruction of the arena and room from the animal’s left- and right eye perspective, with monocular and binocular regions colored as in (F). (<bold>H</bold>) Reconstruction of the animal’s view of the prey (cricket - black) in the experiment arena. (<bold>I</bold>) Representation of left and right eye views of the arena and surrounding objects grayscale-coded by distance from the eye. (<bold>J</bold>) Rendered animal’s eye views from the left- and right eyes with overlay of arrows representing optic flow during 10 ms of free motion.</p><p><supplementary-material id="fig1sdata1"><label>Figure 1—source data 1.</label><caption><title>Related to <xref ref-type="fig" rid="fig1">Figure 1D</xref>.</title></caption><media mime-subtype="zip" mimetype="application" xlink:href="elife-70838-fig1-data1-v1.zip"/></supplementary-material></p><p><supplementary-material id="fig1sdata2"><label>Figure 1—source data 2.</label><caption><title>Related to <xref ref-type="fig" rid="fig1">Figure 1G</xref>.</title></caption><media mime-subtype="zip" mimetype="application" xlink:href="elife-70838-fig1-data2-v1.zip"/></supplementary-material></p><p><supplementary-material id="fig1sdata3"><label>Figure 1—source data 3.</label><caption><title>Related to <xref ref-type="fig" rid="fig1">Figure 1H</xref>.</title></caption><media mime-subtype="zip" mimetype="application" xlink:href="elife-70838-fig1-data3-v1.zip"/></supplementary-material></p><p><supplementary-material id="fig1sdata4"><label>Figure 1—source data 4.</label><caption><title>Related to <xref ref-type="fig" rid="fig1">Figure 1I</xref>.</title></caption><media mime-subtype="zip" mimetype="application" xlink:href="elife-70838-fig1-data4-v1.zip"/></supplementary-material></p><p><supplementary-material id="fig1sdata5"><label>Figure 1—source data 5.</label><caption><title>Related to <xref ref-type="fig" rid="fig1">Figure 1J</xref>.</title></caption><media mime-subtype="zip" mimetype="application" xlink:href="elife-70838-fig1-data5-v1.zip"/></supplementary-material></p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-70838-fig1-v1.tif"/></fig><fig id="fig1s1" position="float" specific-use="child-fig"><label>Figure 1—figure supplement 1.</label><caption><title>Generation of mouse eye views during cricket pursuit.</title><p>(<bold>A</bold>) Head pitch (red), roll (blue) and yaw (orange) and associated left (blue) and right (green) horizontal, vertical and torsional eye movements during the 46.2 s, example cricket pursuit sequence shown in C. (Right) Head and eye rotations during the 0.65 s region between i and ii in the cricket pursuit sequence in C. (<bold>B</bold>) Example (upper rows) head pitch, roll, and horizontal, vertical and torsional, eye rotations during non-pursuit and pursuit sequences (n=1 animal). Lower rows: head and eye rotations during non-pursuit and pursuit sequences from three mice. (<bold>C</bold>) Mouse (black) and cricket (orange) paths during a 46.2 s segment of a single pursuit sequence for one animal. (<bold>D</bold>) Photograph of experiment arena and surrounding environment. (<bold>E</bold>) Digital rendering of the same experiment arena and surrounding environment. (<bold>F</bold>) Top-down view of the mouse’s left and right monocular and binocular fields of view (mouse’s head would be centered at the intersection point of monocular and binocular fields of view). (<bold>G</bold>) Cricket (red) position in the rendered left and right eye corneal fields of view of the experiment arena and surrounding environment during the pursuit sequence in C. (<bold>H</bold>) Trajectory of the projected cricket position in the left and right corneal views, during the pursuit sequence in C.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-70838-fig1-figsupp1-v1.tif"/></fig></fig-group><media id="video1" mime-subtype="mp4" mimetype="video" xlink:href="elife-70838-video1.mp4"><label>Video 1.</label><caption><title>Digitized and rendered view of the experiment arena and surrounding environment.</title><p>Laser scanned and digitally reconstructed experiment environmental, providing positional information of objects within the mouse’s environment. When combined with the tracked 3D cricket positions and the tracked mouse head and eye positions and rotations this allowed the generation of a frame-by-frame mouse eye view of the prey and the surroundings.</p></caption></media><media id="video2" mime-subtype="mp4" mimetype="video" xlink:href="elife-70838-video2.mp4"><label>Video 2.</label><caption><title>Reconstruction of the mouse’s left and right eye field of view during one example behavioral sequence.</title><p>Real speed.</p></caption></media><media id="video3" mime-subtype="mp4" mimetype="video" xlink:href="elife-70838-video3.mp4"><label>Video 3.</label><caption><title>Reconstruction of the mouse’s left and right eye field of view during one example behavioral sequence, as shown in <xref ref-type="video" rid="video2">Video 2</xref>, but slowed to 0.5x real speed.</title></caption></media></sec><sec id="s2-2"><title>During pursuit the image of the prey consistently falls in a localized visual region</title><p>Crickets (<italic>Acheta domesticus</italic>), shown previously to be readily pursued and preyed upon by laboratory mice (<xref ref-type="bibr" rid="bib18">Hoy et al., 2016</xref>), provided a prey target that could successfully evade capture for extended periods of time (total time for each cricket before capture: 64.4 ± 39.3 s, average time ± SD, N = 21 crickets and three mice, <xref ref-type="video" rid="video4">Video 4</xref> and <xref ref-type="video" rid="video5">5</xref>). To ensure that only data where the mouse was actively engaged in the detection and tracking of the cricket were used, we identified occasions where the mouse either captured the cricket, or contacted the cricket but the cricket escaped (see Materials and methods for definitions), and then quantified the trajectories of both mouse and cricket leading up to the capture or capture-escape (<xref ref-type="fig" rid="fig2">Figure 2A</xref>). Within these chase sequences we defined three behavioral epochs (detect, track, and capture, <xref ref-type="fig" rid="fig2">Figure 2B</xref>, see Materials and methods for definition details) based on the behavior of mouse and cricket, and similar to previous studies (<xref ref-type="bibr" rid="bib18">Hoy et al., 2016</xref>).</p><fig-group><fig id="fig2" position="float"><label>Figure 2.</label><caption><title>Mice use a focal region of their visual field to track prey.</title><p>(<bold>A</bold>) Mouse (black) and cricket (orange) paths during a single pursuit sequence (left), and for all pursuit sequences in one session for one animal (right). Pursuit start denoted as filled circles and cricket capture as X. (<bold>B</bold>) Mouse (red and blue) and cricket (orange) paths during an individual pursuit sequence (left) and all pursuit sequences in one session from one animal (right), showing detect (red) and track (blue) epochs of the mouse path. Paths after a cricket escape shown dashed. Pursuit sequence start shown as filled circles, cricket landing point after a jump shown as a filled triangle. (<bold>C</bold>) Euclidean distance between mouse and cricket during detect (red) and track (blue) epochs (n=65 trajectories, n=3 mice). (<bold>D</bold>) Mean and SD bearing to cricket (angle between mouse’s forward direction and cricket location) during detect (red), and track (blue) epochs from all animals (detect: 57 epochs; track: 65 epochs, n=3 animals, bin size = 5°). (<bold>E</bold>) Trajectory of the projected cricket position in the left and right corneal views, during a single pursuit sequence. Color scheme as for D. The inner dashed circle is 45° from the optical axes. Dorsal (D), ventral (V), nasal (N), and temporal (T) directions indicated. (<bold>F</bold>) Average probability density maps for detect epochs (4628 frames from three animals). Orientation as in E. (<bold>G</bold>) Average probability density maps for track epochs (13641 frames from three animals). Orientation as in E. (<bold>H</bold>) Isodensity contours calculated from the average probability density maps for track epochs. (note that 50% means that this region contains 50% of the total density, and likewise for the other contours). Orientation as in E.</p><p><supplementary-material id="fig2sdata1"><label>Figure 2—source data 1.</label><caption><title>Related to <xref ref-type="fig" rid="fig2">Figure 2A,B,C,D,H</xref>.</title></caption><media mime-subtype="xlsx" mimetype="application" xlink:href="elife-70838-fig2-data1-v1.xlsx"/></supplementary-material></p><p><supplementary-material id="fig2sdata2"><label>Figure 2—source data 2.</label><caption><title>Related to <xref ref-type="fig" rid="fig2">Figure 2E</xref>.</title></caption><media mime-subtype="zip" mimetype="application" xlink:href="elife-70838-fig2-data2-v1.zip"/></supplementary-material></p><p><supplementary-material id="fig2sdata3"><label>Figure 2—source data 3.</label><caption><title>Related to <xref ref-type="fig" rid="fig2">Figure 2F</xref>.</title></caption><media mime-subtype="zip" mimetype="application" xlink:href="elife-70838-fig2-data3-v1.zip"/></supplementary-material></p><p><supplementary-material id="fig2sdata4"><label>Figure 2—source data 4.</label><caption><title>Related to <xref ref-type="fig" rid="fig2">Figure 2G</xref>.</title></caption><media mime-subtype="zip" mimetype="application" xlink:href="elife-70838-fig2-data4-v1.zip"/></supplementary-material></p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-70838-fig2-v1.tif"/></fig><fig id="fig2s1" position="float" specific-use="child-fig"><label>Figure 2—figure supplement 1.</label><caption><title>Individual corneal prey image heatmaps.</title><p>(<bold>A</bold>) Probability density maps for detect (upper row) and track (lower row) epochs for each of the three animals individually. Data from 4 detect and 5 track sequences, 27 detect and 28 track sequences and 17 detect and 19 track sequences for mouse 1, 2, and 3, respectively. (<bold>B</bold>) Isodensity contours calculated from the average probability density maps for all detect epochs from all three animals. (<bold>C</bold>) Isodensity contours for all track epochs from all three animals. (<bold>D</bold>) 50% isodensity contour (defined as in <xref ref-type="fig" rid="fig2">Figure 2H</xref>) during track epochs for each of the three mice (m1-m3) individually.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-70838-fig2-figsupp1-v1.tif"/></fig></fig-group><media id="video4" mime-subtype="mp4" mimetype="video" xlink:href="elife-70838-video4.mp4"><label>Video 4.</label><caption><title>Left and right eye camera images and one overhead camera view showing one complete cricket pursuit, from shortly after release of the cricket into the arena to cricket capture.</title><p>Real Speed.</p></caption></media><media id="video5" mime-subtype="mp4" mimetype="video" xlink:href="elife-70838-video5.mp4"><label>Video 5.</label><caption><title>The same cricket pursuit as shown in <xref ref-type="video" rid="video4">Video 4</xref> but slowed to 0.5x real speed.</title></caption></media><p>Upon cricket detection, mice oriented and ran towards the cricket, resulting in a significant adjustment to their trajectory (Δ target bearing: 40.2 ± 35.1°, P = 6.20 x 10<sup>−10</sup>, Δ speed: 10.2 ± 7.4 cm/s, P = 1.91 x 10<sup>−10</sup>; N=57 detect-track sequences N = 3 mice; Paired Wilcoxon’s signed rank test for both tests), and a rapid reduction in the Euclidean distance to the cricket (<xref ref-type="fig" rid="fig2">Figure 2C</xref>). During tracking, the cricket was kept in front of the mouse, resulting in a significant reduction in the spread of target bearings compared to during detect epochs (<xref ref-type="fig" rid="fig2">Figure 2D</xref>, Target bearing: detect 6.2 ± 62.1°, track: 2.5 ± 25.6°, mean ± SD, Brown-Forsythe test p = 0, <italic>F</italic> statistic=7.05x10<sup>3</sup>, N=4406 detect and 13624 track frames, N=3 mice), consistent with previous findings (<xref ref-type="bibr" rid="bib18">Hoy et al., 2016</xref>). To avoid the closing phase of the pursuit being associated with whisker strikes (<xref ref-type="bibr" rid="bib58">Shang et al., 2019</xref>; <xref ref-type="bibr" rid="bib71">Zhao et al., 2019</xref>), tracking periods were only analyzed when the mouse was more than 3 cm from the cricket, based on whisker length (<xref ref-type="bibr" rid="bib23">Ibrahim and Wright, 1975</xref>).</p><p>Using the detailed digitization of the behavioral arena and surrounding laboratory (<xref ref-type="fig" rid="fig1">Figure 1E</xref>, <xref ref-type="video" rid="video1">Video 1</xref>), an image of the cricket and objects in the environment was calculated for each head and eye position during the predator-prey interaction (<xref ref-type="video" rid="video2">Video 2 and 3</xref>). Using this approach, we addressed the question of what area of the visual field was the cricket located in during the various behavioral epochs. In the example pursuit sequence in <xref ref-type="fig" rid="fig2">Figure 2E</xref>, the cricket was initially located in the peripheral visual field and then transitioned to the lower nasal binocular quadrant of the cornea-view during pursuit and capture (red trace in left eye to blue trace in both eyes). Correspondingly, an average probability density map calculated for all animals during the detect epoch showed a very broad distribution of cricket positions across the visual field (<xref ref-type="fig" rid="fig2">Figure 2F</xref>, <xref ref-type="fig" rid="fig2s1">Figure 2—figure supplement 1A and B</xref>). Upon detection the mouse oriented toward the cricket, bringing it toward the lower nasal binocular visual field (<xref ref-type="fig" rid="fig2">Figure 2E</xref>, <xref ref-type="video" rid="video6">Video 6</xref>). When averaged for all pursuit sequences from all animals, projected cricket positions formed a dense cluster on the cornea of both eyes (<xref ref-type="fig" rid="fig2">Figure 2G and H</xref>, <xref ref-type="fig" rid="fig2s1">Figure 2—figure supplements 1A,C–D</xref>, 50% contour center for left and right eye respectively, radial displacement from optical axis 64.3 ± 7.5° and 63.3 ± 9.9°, rotational angle 126.2 ± 8.9° and −115.7 ± 6.1°, mean ± SD, N = 3 mice), which was significantly different from the cluster in the detect epoch (average histogram of the location of cricket image during tracking phase vs average histogram of the location of cricket during detect phase: Left eye P = 3.54 x 10<sup>−46</sup>, Right eye P = 1.08 x 10<sup>−81</sup>, differences calculated by taking the Mean Absolute Difference with bootstrapping, N=57 detect-track sequences, N = 3 mice). Thus, during the tracking and pursuit behavior the image of the prey consistently fell on a local and specific retinal area that we refer to from here on as the functional focus. The functional focus fell within the binocular field, while the region of elevated density of RGCs has been found to be located near the optical axis (<xref ref-type="bibr" rid="bib13">Dräger and Olsen, 1981</xref>), which suggests that the location of the retinal specialization may not overlap with the functional focus.</p><media id="video6" mime-subtype="mp4" mimetype="video" xlink:href="elife-70838-video6.mp4"><label>Video 6.</label><caption><title>Reconstructed left and right mouse-eye views for one example pursuit behavioral sequence, showing the trajectory of the cricket position in the eye views during the detect (red) and track (blue) segments of the behavior.</title></caption></media></sec><sec id="s2-3"><title>Relative locations of functional foci and ganglion cell density distributions</title><p>To establish the relation between the identified functional focus and the density distribution of RGCs, we made a mouse eye-model (<xref ref-type="fig" rid="fig3">Figure 3A</xref>), modified from previous models (<xref ref-type="bibr" rid="bib4">Barathi et al., 2008</xref>). Using the eye model, retinal spatial locations could be projected through the optics of the mouse eye to the corneal surface. We first reconstructed the isodensity contours quantifying the distribution of all RGCs (<xref ref-type="bibr" rid="bib13">Dräger and Olsen, 1981</xref>) to define the retinal location with the highest overall ganglion cell density (<xref ref-type="fig" rid="fig3s1">Figure 3—figure supplement 1A–C</xref>, note that these contours are also in agreement with other recently published maps of total RGC density [<xref ref-type="bibr" rid="bib5">Bleckert et al., 2014</xref>; <xref ref-type="bibr" rid="bib70">Zhang et al., 2012</xref>]). The lens optical properties were based on a GRIN lens (present in both rats [<xref ref-type="bibr" rid="bib22">Hughes, 1979</xref>; <xref ref-type="bibr" rid="bib47">Philipson, 1969</xref>] and mice [<xref ref-type="bibr" rid="bib7">Chakraborty et al., 2014</xref>]). To determine the optical characteristics of this lens, we developed a method which combined models of the lens surface and refractive index gradient (<xref ref-type="fig" rid="fig3">Figure 3A</xref>, <xref ref-type="fig" rid="fig3s1">Figure 3—figure supplement 1D</xref> and <xref ref-type="table" rid="table1">Tables 1</xref> and <xref ref-type="table" rid="table2">2</xref>, see Materials and methods for details). Using this model, the contours representing the retinal specializations were projected through the eye model onto the corneal surface to determine equivalent corneal locations (<xref ref-type="fig" rid="fig3">Figure 3B</xref>, <xref ref-type="fig" rid="fig3s1">Figure 3—figure supplement 1E</xref>). Comparing this location to the functional focus location showed that the region with the highest overall RGC counts and the functional focus (<xref ref-type="fig" rid="fig3">Figure 3B</xref>) occupied distinct retinal locations (<xref ref-type="fig" rid="fig3">Figure 3C</xref>). Viewed from above the animal’s head, the functional foci were directed at the region in front of the animal’s nose and within the region of stable binocular overlap (azimuth: 1.4 ± 8.8° and −4.4 ± 9.3°, elevation 5.7 ± 2.1° and 4.9 ± 1.4° for left and right eyes respectively, N = 13641 frames, N=3 mice), while the retinal specialization was directed laterally (azimuth: −66.2 ± 6.7° and 70.3 ± 4.7°, elevation: 30.8 ± 12.2° and 41.0 ± 13.5° for left and right eyes respectively, N = 13641 frames N=3 mice. <xref ref-type="fig" rid="fig3">Figure 3D</xref>, <xref ref-type="fig" rid="fig3s1">Figure 3—figure supplement 1F–G</xref>). Given that density distributions for different subtypes of RGCs can be spatially heterogeneous with density peaks in distinctly different retinal locations, and that the region of peak density for Alpha-ON sustained RGC’s is spatially located on the dorso-temporal retina (<xref ref-type="bibr" rid="bib5">Bleckert et al., 2014</xref>), consistent with projecting to the front of the animal, we next quantified whether this region overlapped with the functional focus observed here (<xref ref-type="fig" rid="fig3">Figure 3E</xref>).</p><fig-group><fig id="fig3" position="float"><label>Figure 3.</label><caption><title>Functional foci are not sampled by the highest density retinal ganglion cell region.</title><p>(<bold>A</bold>) Schematic of mouse eye model (left upper) with profile of all refractive indices (RI, left lower). Reconstructions of the optic disc (black), highest (&gt;8000 cells/mm<sup>2</sup>, beige) and second highest (&gt;7000 cells/mm<sup>2</sup>, brown) retinal ganglion cell (RGC) density regions redrawn from <xref ref-type="bibr" rid="bib13">Dräger and Olsen, 1981</xref>, shown in lower right. (<bold>B</bold>) Position in corneal views of the high RGC density regions (brown and beige filled regions), and isodensity contours from <xref ref-type="fig" rid="fig2">Figure 2H</xref> after projection through the eye model. Orientation as in <xref ref-type="fig" rid="fig2">Figure 2E</xref>. (<bold>C</bold>) Horizontal axis histograms for the nasal half of the corneal view of the second highest RGC region (brown) and 50% isodensity contour for left (blue) and right (green) eyes. (<bold>D</bold>) Top-down view of the coverage regions for the right eye of the 50% isodensity contour (green, N = 7551 frames) and second highest RGC region (brown, N = 51007 frames) for a single animal. Bars represent the probability density function for the respective regions at that azimuth angle. (<bold>E</bold>) Position in corneal views of Alpha-ON sustained RGC densities (redrawn from <xref ref-type="bibr" rid="bib5">Bleckert et al., 2014</xref>) after projection through the eye model. Colored regions show the 95% (dark purple), 75% (medium purple), and 50% (light purple) contour regions of the peak Alpha-ON sustained RGC density. Isodensity contours from <xref ref-type="fig" rid="fig2">Figure 2H</xref>. (<bold>F</bold>) Top-down view of the coverage regions for the right eye of the 95% (dark purple), 75% (medium purple), and 50% (light purple) Alpha-ON sustained RGC contour regions (same as in E, N = 51007 frames) and the 50% isodensity contour from D (green) for a single animal. For the Alpha-ON sustained RGC contour regions, 50% means that this region contains all points which are at least 50% of the peak RGC density.</p><p><supplementary-material id="fig3sdata1"><label>Figure 3—source data 1.</label><caption><title>Related to <xref ref-type="fig" rid="fig3">Figure 3A</xref>.</title></caption><media mime-subtype="zip" mimetype="application" xlink:href="elife-70838-fig3-data1-v1.zip"/></supplementary-material></p><p><supplementary-material id="fig3sdata2"><label>Figure 3—source data 2.</label><caption><title>Related to <xref ref-type="fig" rid="fig3">Figure 3B</xref>.</title></caption><media mime-subtype="zip" mimetype="application" xlink:href="elife-70838-fig3-data2-v1.zip"/></supplementary-material></p><p><supplementary-material id="fig3sdata3"><label>Figure 3—source data 3.</label><caption><title>Related to <xref ref-type="fig" rid="fig3">Figure 3C</xref>.</title></caption><media mime-subtype="xlsx" mimetype="application" xlink:href="elife-70838-fig3-data3-v1.xlsx"/></supplementary-material></p><p><supplementary-material id="fig3sdata4"><label>Figure 3—source data 4.</label><caption><title>Related to <xref ref-type="fig" rid="fig3">Figure 3D</xref>.</title></caption><media mime-subtype="zip" mimetype="application" xlink:href="elife-70838-fig3-data4-v1.zip"/></supplementary-material></p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-70838-fig3-v1.tif"/></fig><fig id="fig3s1" position="float" specific-use="child-fig"><label>Figure 3—figure supplement 1.</label><caption><title>Projecting high retinal ganglion cell density region from retina to cornea.</title><p>(<bold>A</bold>) Retinal whole mount redrawn from <xref ref-type="bibr" rid="bib13">Dräger and Olsen, 1981</xref> including whole mount outline (black), and outlines of the optic disc (black) and highest (&gt;8000 cells/mm<sup>2</sup>, beige) and second highest (&gt;7000 cells/mm<sup>2</sup> brown) retinal ganglion cell density isodensity lines. (<bold>B</bold>) Overlay of the redrawn retinal whole mount from A and a representation of the mouse eye equatorial diameter (dashed) from <xref ref-type="bibr" rid="bib64">Tkatchenko et al., 2010</xref>. The center of the equatorial diameter was overlaid with the center of mass of the outline of the optic disc of the redrawn whole mount (black cross). Color coding as in A. (<bold>C</bold>) Retinal isodensity lines represented in spherical coordinates. Color coding as in A. (<bold>D</bold>) Schematic of mouse eye model (from <xref ref-type="fig" rid="fig3">Figure 3A</xref>). (<bold>E</bold>) Regions within the isodensity contours from A and the 50% isodensity contour from the track epochs from <xref ref-type="fig" rid="fig2">Figure 2H</xref> projected through the mouse eye model into the corneal view from the left eye (from <xref ref-type="fig" rid="fig3">Figure 3B</xref>). (<bold>F</bold>) Top-down view of the coverage region for the left eye of the 50% isodensity contour (blue) and second highest RGC region (brown). Bars represent the probability density function for the respective regions at that azimuth angle. Mouse’s forward direction directed to 0°, and mouse’s right directed to 90°. (<bold>G</bold>) Top-down view of the coverage region for the right eye of the 50% isodensity contour (green) and second highest RGC region (brown). Conventions as in F.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-70838-fig3-figsupp1-v1.tif"/></fig></fig-group><table-wrap id="table1" position="float"><label>Table 1.</label><caption><title>Mouse eye model curvatures.</title><p>Radii of curvature of the optical components of the mouse eye model in <xref ref-type="fig" rid="fig3">Figure 3A</xref>.</p></caption><table frame="hsides" rules="groups"><thead><tr><th valign="top"><italic>Ocular Component</italic></th><th valign="top"><italic>Radius of curvature (μm)</italic></th></tr></thead><tbody><tr><td valign="top"><italic>Anterior Cornea</italic></td><td valign="top">−1408*</td></tr><tr><td valign="top"><italic>Posterior Cornea</italic></td><td valign="top">−1372*</td></tr><tr><td valign="top"><italic>Anterior Lens</italic></td><td valign="top">1150*</td></tr><tr><td valign="top"><italic>Posterior Lens</italic></td><td valign="top">1134*</td></tr><tr><td valign="top"><italic>Retina</italic></td><td valign="top">1598*</td></tr></tbody></table><table-wrap-foot><fn><p>* Values from <xref ref-type="bibr" rid="bib4">Barathi et al., 2008</xref>.</p></fn></table-wrap-foot></table-wrap><table-wrap id="table2" position="float"><label>Table 2.</label><caption><title>Mouse eye model thicknesses and refractive indices.</title></caption><table frame="hsides" rules="groups"><thead><tr><th valign="top"><italic>Ocular Component</italic></th><th valign="top"><italic>Thickness(μm)</italic></th><th valign="top"><italic>Index of refraction</italic></th></tr></thead><tbody><tr><td valign="top"><italic>Cornea</italic></td><td valign="top">92*</td><td valign="top">1.402*</td></tr><tr><td valign="top"><italic>Anterior chamber</italic></td><td valign="top">278*</td><td valign="top">1.334*</td></tr><tr><td valign="top"><italic>Lens</italic></td><td valign="top">2004*</td><td valign="top">1.36–1.55<sup>†</sup></td></tr><tr><td valign="top"><italic>Vitreous chamber</italic></td><td valign="top">609*</td><td valign="top">1.333*</td></tr></tbody></table><table-wrap-foot><fn><p>* Values from <xref ref-type="bibr" rid="bib4">Barathi et al., 2008</xref>.</p><p>† Minimum and maximum values after eye model optimization.</p></fn></table-wrap-foot></table-wrap><p>The average 50% contour of the functional focus was overlapped by the highest density of Alpha-ON sustained RGC's by 35% and 67% for left and right eye respectively (<xref ref-type="fig" rid="fig3">Figure 3E</xref>, black, mean ± SD for left and right eye, 35.1 ± 19.8%, 66.7 ± 0.09%, p = 0.095 and 0.019, one-sided Student’s t-test), and the overlap with the second highest density was 83% and 95% (mean ± SD for left and right eye, 82.8 ± 20.1%, 94.8 ± 24.7%, p = 0.042 and 0.003, one-sided Student’s t-test), suggesting a high degree of correspondence between the highest density of Alpha-ON sustained RGC’s and the functional focus during pursuit behavior. Viewed from above the animal’s head the functional foci were directed at the region in front of the animal’s nose azimuth: 1.4 ± 8.8° and −4.4 ± 9.3°, elevation: 5.7 ± 2.1° and 4.9 ± 1.4° for left and right eyes respectively, N = 13641 frames, N=3 mice. The Alpha-ON sustained RGC’s were also directed in front of the animal’s nose (mean ± SD, elevation:16.0 ± 6.9° and 10.8 ± 11.0°, azimuth: −3.6 ± 0.7° and 5.8 ± 7.9° for left and right eyes respectively, N = 168400 frames, N = 3 mice, <xref ref-type="fig" rid="fig3">Figure 3F</xref>). Together this suggests that objects falling within the functional foci are processed by Alpha-ON sustained RGC’s.</p></sec><sec id="s2-4"><title>Combination of torsional, horizontal, and vertical eye rotations counter head rotations</title><p>Eye movements in freely moving mice, like with rats (<xref ref-type="bibr" rid="bib68">Wallace et al., 2013</xref>), can be large and rapid (<xref ref-type="bibr" rid="bib38">Meyer et al., 2020</xref>; <xref ref-type="bibr" rid="bib45">Payne and Raymond, 2017</xref>), and counter head rotations through the VOR, enabling the large field of view around the animals head to be stabilized while the animal is moving. The relationships between head rotations and both the horizontal and vertical eye rotations have recently been quantified, and in addition it has been reported that both during exploration and hunting, mice also have abrupt gaze shifts brought about by the combination of head rotation and conjugate saccade-like horizontal eye rotations (<xref ref-type="bibr" rid="bib38">Meyer et al., 2020</xref>; <xref ref-type="bibr" rid="bib39">Michaiel et al., 2020</xref>). We also observed both forms of eye movements in the current study (<xref ref-type="fig" rid="fig4s1">Figure 4—figure supplement 1</xref>). However, how these rotations combine with torsional rotations is not known. If mouse VOR operates similar to that observed in the rat (<xref ref-type="bibr" rid="bib68">Wallace et al., 2013</xref>), torsional rotations in the mouse will play a significant role in stabilizing the visual field particularly during changes in head pitch. As with the vertical and horizontal rotations (<xref ref-type="bibr" rid="bib37">Meyer et al., 2018</xref>), torsional rotations in freely moving mice spanned a wide range of rotation angles (<xref ref-type="fig" rid="fig4s2">Figure 4—figure supplement 2A–D</xref>), and were correlated with head pitch (Pearson’s correlation coefficient (r): detect −0.72, 0.58, track: −0.60 and 0.53 for left and right eyes respectively, N=4406 detect and 13624 track frames, N=3 mice, <xref ref-type="fig" rid="fig4s2">Figure 4—figure supplement 2C–D</xref>) as well as head roll (Pearson’s correlation coefficient (r): detect: −0.46, –0.47 track: −0.45 and −0.48 for left and right eyes respectively, N=4406 detect and 13624 track frames, N=3 mice, <xref ref-type="fig" rid="fig4s2">Figure 4—figure supplement 2L–M</xref>), as found previously for freely moving rats (<xref ref-type="bibr" rid="bib68">Wallace et al., 2013</xref>). As with rats, the rotational relationship between the two eyes was dynamic with different forms of coordination (<xref ref-type="fig" rid="fig4s2">Figure 4—figure supplement 2E–I</xref>), including episodes of in- and excyclovergence (torsional rotation of both eyes toward or away from the nose, respectively) as well as dextro- and levocycloversion (torsional rotation of both eyes to the animal’s right or left, respectively). We next analyzed how effectively rotations of the eye around multiple rotational axes combined to compensate the rotation of the head (<xref ref-type="fig" rid="fig4">Figure 4A</xref>, <xref ref-type="fig" rid="fig4s3">Figure 4—figure supplement 3A–G</xref>). We compared movement of the head around its rotational axes and eye movements around the same rotational axes (<xref ref-type="fig" rid="fig4">Figure 4A</xref>), effectively defining alternative rotational axes for the eyes to match the axes of the head. Rotation of the eye around these re-defined axes would involve simultaneous rotations in multiple of the eye’s anatomical axes. The gain of this compensation was relatively linear and less than unity for both pitch- and roll-axes, indicating on average under-compensation of the head rotation (slope (gain) of relation for pitch axis, −0.45 ± 0.12 and −0.48 ± 0.06; roll axis −0.51 ± 0.12 and −0.62 ± 0.05 for left and right eye respectively, 168852 frames, N=3 mice). The relatively linear relationships between head and eye rotation around the head pitch and roll axes (<xref ref-type="fig" rid="fig4">Figure 4B</xref>) with a transition through the origin suggests that the horizontal, vertical and torsional eye movements are combined to effectively compensate pitch- and roll-related head movements. We next digitally froze each individual eye rotation axis (torsion, vertical, and horizontal) and measured the effect on countering the head rotation (<xref ref-type="fig" rid="fig4">Figure 4C</xref>). For rotations around the head x-axis (head pitch changes) the gain of compensation was most affected by freezing torsional rotations (<xref ref-type="fig" rid="fig4">Figure 4C</xref>, gain mean ± SD, control: −0.45 ± 0.12and-0.48 ± 0.06; torsion frozen −0.24 ± 0.1 and −0.24 ± 0.01, for left and right eyes respectively, N = 168852 frames, N=3 mice), while freezing vertical or horizontal rotations had more minor effects (<xref ref-type="fig" rid="fig4">Figure 4C</xref>, <xref ref-type="table" rid="table3">Table 3</xref>). The gain of compensation for rotations around the head y-axis (head roll changes) was dramatically affected by freezing vertical rotations (<xref ref-type="fig" rid="fig4">Figure 4C</xref>, gain mean ± SD, control: −0.51 ± 0.12 and −0.62 ± 0.05, vertical frozen −0.16 ± 0.14 and −0.17 ± 0.03, for left and right eyes respectively, N = 168852 frames, N=3 mice), with freezing torsion also reducing compensation gain but to a lesser extent (<xref ref-type="fig" rid="fig4">Figure 4C</xref>, <xref ref-type="table" rid="table3">Table 3</xref>). We next quantified the stability and alignment of the animal’s binocular visual field during the pursuit sequences and determined the location of the functional foci within the stabilized region.</p><fig-group><fig id="fig4" position="float"><label>Figure 4.</label><caption><title>Functional foci are located within binocular regions in which motion is stabilized.</title><p>(<bold>A</bold>) Schematic of the common head and eye rotational axes. (<bold>B</bold>) Relationship between head and eye rotations around the common X (left, 154,625 frames from three animals) and Y (right, 165,432 frames from three animals) rotational axes during pursuit and non-pursuit sequences. Plots show mean for left (blue) and right (green) eyes with standard deviation (gray). (<bold>C</bold>) Relationship between head and left eye rotations around the common X (left) and Y (right) rotational axes with; all eye rotations present (blue), torsional eye rotations frozen (red), vertical eye rotations frozen (black) or horizontal eye rotations frozen (orange). Plots show mean (lines) and standard deviations (colored filled regions). (<bold>D</bold>) Corneal view showing probability of overlap of left and right visual fields for one example animal (71995 frames), with overlay of isodensity contours (red) from functional foci (see <xref ref-type="fig" rid="fig2s1">Figure 2—figure supplement 1D</xref>) and contour of second highest RGC region (brown) from <xref ref-type="fig" rid="fig3">Figure 3B</xref>. (<bold>E</bold>) Schematic of inter-ocular alignment. (<bold>F</bold>) Corneal view of alignment reference point in left eye (left) and variability in alignment of the re-projection of that point in the right eye (right) for a 1.6 s data segment. (<bold>G</bold>) Kinetics (left) and associated distribution (right) of the variability in ocular alignment for left eye point projected to right eye (blue) and right eye point in left eye (green) for one example data segment (shown in G) from one animal. (<bold>H</bold>) Distributions of ocular alignment from all data segments (159,318 frames, n=3 mice) with the measured eye movements for left into right eye (blue) and right into left eye (green) and alignment with eye movements frozen (left into right eye, black, right into left, orange). (<bold>I</bold>) Map of average inter-ocular alignment for all data segments (159,318 frames, n=3 animals) with overlay of isodensity contours from <xref ref-type="fig" rid="fig2">Figure 2H</xref>. (<bold>J</bold>) Map of average inter-ocular alignment as in J with left eye movements frozen.</p><p><supplementary-material id="fig4sdata1"><label>Figure 4—source data 1.</label><caption><title>Related to <xref ref-type="fig" rid="fig4">Figure 4B,C</xref>.</title></caption><media mime-subtype="xlsx" mimetype="application" xlink:href="elife-70838-fig4-data1-v1.xlsx"/></supplementary-material></p><p><supplementary-material id="fig4sdata2"><label>Figure 4—source data 2.</label><caption><title>Related to <xref ref-type="fig" rid="fig4">Figure 4D</xref>.</title></caption><media mime-subtype="zip" mimetype="application" xlink:href="elife-70838-fig4-data2-v1.zip"/></supplementary-material></p><p><supplementary-material id="fig4sdata3"><label>Figure 4—source data 3.</label><caption><title>Related to <xref ref-type="fig" rid="fig4">Figure 4G</xref>.</title></caption><media mime-subtype="zip" mimetype="application" xlink:href="elife-70838-fig4-data3-v1.zip"/></supplementary-material></p><p><supplementary-material id="fig4sdata4"><label>Figure 4—source data 4.</label><caption><title>Related to <xref ref-type="fig" rid="fig4">Figure 4H</xref>.</title></caption><media mime-subtype="zip" mimetype="application" xlink:href="elife-70838-fig4-data4-v1.zip"/></supplementary-material></p><p><supplementary-material id="fig4sdata5"><label>Figure 4—source data 5.</label><caption><title>Related to <xref ref-type="fig" rid="fig4">Figure 4I</xref>.</title></caption><media mime-subtype="zip" mimetype="application" xlink:href="elife-70838-fig4-data5-v1.zip"/></supplementary-material></p><p><supplementary-material id="fig4sdata6"><label>Figure 4—source data 6.</label><caption><title>Related to <xref ref-type="fig" rid="fig4">Figure 4J</xref>.</title></caption><media mime-subtype="zip" mimetype="application" xlink:href="elife-70838-fig4-data6-v1.zip"/></supplementary-material></p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-70838-fig4-v1.tif"/></fig><fig id="fig4s1" position="float" specific-use="child-fig"><label>Figure 4—figure supplement 1.</label><caption><title>VOR relationships between head and eye rotations and abrupt shifts in gaze.</title><p>VOR relationships between head and eye rotations and alignment of left and right eyes. (<bold>A</bold>) Relationship between mouse head pitch and horizontal eye rotations (left eye (171,942 frames), blue; right eye (364,259 frames), green; mean ± SD). (<bold>B</bold>) Relationship between head roll and vertical eye rotations. Plot conventions as in A. Left eye (164840 frames); right eye (363,713 frames). (<bold>C</bold>) Relationship between head pitch and torsional eye rotations. Plot conventions as in A. Left eye (171,942 frames); right eye (364,259 frames). Data for A-C, from three animals. (<bold>D</bold>) Example trace from one animal of abrupt shifts (gray boxes) in gaze (lower) resulting from combined head rotation (upper) and conjugate horizontal eye rotations (middle).</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-70838-fig4-figsupp1-v1.tif"/></fig><fig id="fig4s2" position="float" specific-use="child-fig"><label>Figure 4—figure supplement 2.</label><caption><title>Ocular torsion during cricket pursuit.</title><p>(<bold>A</bold>) Distribution of left (blue) and right (green) eye torsional rotations during detect epochs. Data from 57 epochs (4406 frames) from three animals. (<bold>B</bold>) Distribution of ocular torsion during track epochs. Conventions as in A. Data from 65 epochs (13624 frames) from three animals. (<bold>C</bold>) Average relationship (mean ± SD) between head pitch and torsional eye rotations during detect epochs for left (blue and right (green) eyes). Data from 57 epochs (4406 frames) from three animals. (<bold>D</bold>) Average head pitch and torsional eye rotations relationships during track epochs. Conventions as in C. Data from 65 epochs (13,624 frames) from three animals. (<bold>E</bold>) Mouse (detect epoch, blue; track epoch, red) and cricket (black) trajectories during one example pursuit sequence. (<bold>F</bold>) Torsional rotations of the left (blue) and right (green) eyes, and head pitch (purple) and roll (orange), during the pursuit sequence in E. Lower panels show example eye images from the indicated time points in the kinetic traces. Red arrows indicate tracked TiO<sub>2</sub> spots. (<bold>G</bold>) Example sequences showing torsional rotation kinetic traces for left (blue) and right (green) eyes during in- (i) and excyclovergence (ii) from one pursuit sequence. Schematics show the ocular rotations in the left and right eyes. (<bold>H</bold>) Example sequence showing dextrocycloversion in one pursuit sequence. Conventions as in G. (<bold>I</bold>) Example of the effect of torsional rotations on prey image location. Corneal eye views of the cricket (black ellipse in red dashed circle) and arena (upper) and associated eye images (middle) at the time points indicated in the torsion kinetic traces (lower) for the left (blue) and right (green) eyes. Note cricket trajectories in left and right corneal eye views, which show the trajectory of the cricket in the corneal views between time points 1 and 2. Red arrows in eye images show TiO<sub>2</sub> torsion tracking spots. (<bold>J</bold>) Performance of a model predicting torsion based on head pitch alone for left (blue) and right (green) eyes during detect and (<bold>K</bold>) track epochs. (<bold>L</bold>) Average (mean ± SD) relationship between head roll and torsional eye rotations during detect epochs for left (blue) and right (green) eyes. Data from 57 epochs (4406 frames) from three animals. (<bold>M</bold>) Average head roll and torsional eye rotation relationship during track epochs. Conventions as in L. Data from 65 epochs (13,624 frames) from three animals. (<bold>N</bold>) Performance of a model predicting torsion based on both head pitch and roll. Conventions as in J. For both J and N, data taken from 57 detect epochs (4406 frames), from three animals. (<bold>O</bold>) Performance of a model predicting torsion based on both head pitch and roll during tracking phases. For both K and O, data taken from 65 prey tracking epochs (13,624 frames), from three animals.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-70838-fig4-figsupp2-v1.tif"/></fig><fig id="fig4s3" position="float" specific-use="child-fig"><label>Figure 4—figure supplement 3.</label><caption><title>VOR relationships between head and eye rotations and alignment of left and right eyes.</title><p>(<bold>A</bold>) Image of mouse with detachable miniaturized eye cameras and head position tracking system. (<bold>B</bold>) Example eye images showing horizontal, vertical and torsional eye rotations. Note TiO<sub>2</sub> spots on the corneal surface for tracking torsion highlighted in lower panels. (<bold>C</bold>) Schematic of the common head and eye rotational axes. Relationship between (<bold>D</bold>) left and right eye X-rotations, (<bold>E</bold>) Y-rotations and (<bold>F</bold>) Z-rotations in common rotational axes. (<bold>G</bold>) Relationship between head X rotations and eye Z rotations for left eye (blue) and right eye (green). Data for D-G are represented as mean ± SD, and are from 168,400 frames from three animals. (<bold>H</bold>) Corneal view showing probability of overlap of left and right visual fields for two example animals m1 (left, 36,449 frames) and m2 (right, 50,874 frames), with overlay of isodensity contours (m1 -black, m2 - blue) from functional foci (see <xref ref-type="fig" rid="fig2s1">Figure 2—figure supplement 1D</xref>) and contour of second highest RGC region (brown) from <xref ref-type="fig" rid="fig3">Figure 3B</xref>. (<bold>I</bold>) Profile of probability of overlap for left (dotted) and right (solid) eyes as a function of angular distance from optical axis for all three animals. Profile taken from horizontal axis through optical axis as shown in <xref ref-type="fig" rid="fig4">Figure 4D</xref> (dotted line in 4D, N = 3 animals, green = 36,449 frames, blue = 50,874 frames, purple = 71,995 frames, respectively). Examples of ocular alignment for the reference spot in the left eye projected into the right eye (<bold>J</bold>), reference spot in the right eye projected into the left eye (<bold>K</bold>), and alignment over time for both reference spots (<bold>L</bold>).</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-70838-fig4-figsupp3-v1.tif"/></fig></fig-group><table-wrap id="table3" position="float"><label>Table 3.</label><caption><title>Compensation gain of eye rotations for head X or Y-axis rotations.</title><p>Effect of digitally freezing torsional, vertical, and horizontal eye rotations on the gain of compensation of X and Y head rotations. Data taken from 168,852 frames, from three animals.</p></caption><table frame="hsides" rules="groups"><thead><tr><th valign="top">Eye</th><th valign="top">Rotation direction</th><th valign="top">Rotation</th><th valign="top">All Rotations <break/>(mean ± SD)</th><th valign="top">Eye rotation frozen <break/>(mean ± SD)</th></tr></thead><tbody><tr><td rowspan="3" valign="top"><bold>Left</bold></td><td rowspan="3" valign="top">X</td><td valign="top">Torsion</td><td>−0.45 ± 0.12</td><td>−0.24 ± 0.1</td></tr><tr><td valign="top">Horizontal</td><td>−0.45 ± 0.12</td><td>−0.32 ± 0.06</td></tr><tr><td valign="top">Vertical</td><td>−0.45 ± 0.12</td><td>−0.35 ± 0.08</td></tr><tr><td rowspan="3" valign="top"><bold>Right</bold></td><td rowspan="3" valign="top">X</td><td valign="top">Torsion</td><td>−0.48 ± 0.06</td><td>−0.24 ± 0.01</td></tr><tr><td valign="top">Horizontal</td><td>−0.48 ± 0.06</td><td>−0.36 ± 0.08</td></tr><tr><td valign="top">Vertical</td><td>−0.48 ± 0.06</td><td>−0.34 ± 0.03</td></tr><tr><td rowspan="3" valign="top"><bold>Left</bold></td><td rowspan="3" valign="top">Y</td><td valign="top">Torsion</td><td>−0.51 ± 0.12</td><td>−0.35 ± 0.05</td></tr><tr><td valign="top">Horizontal</td><td>−0.51 ± 0.12</td><td>−0.51 ± 0.11</td></tr><tr><td valign="top">Vertical</td><td>−0.51 ± 0.12</td><td>−0.16 ± 0.14</td></tr><tr><td rowspan="3" valign="top"><bold>Right</bold></td><td rowspan="3" valign="top">Y</td><td valign="top">Torsion</td><td>−0.62 ± 0.05</td><td>−0.45 ± 0.05</td></tr><tr><td valign="top">Horizontal</td><td>−0.62 ± 0.05</td><td>−0.62 ± 0.02</td></tr><tr><td valign="top">Vertical</td><td>−0.62 ± 0.05</td><td>−0.17 ± 0.03</td></tr></tbody></table></table-wrap></sec><sec id="s2-5"><title>Functional foci are located in the motion-stabilized binocular visual field</title><p>Similar to rats, left and right visual fields overlapped extensively (<xref ref-type="bibr" rid="bib12">Dräger and Olsen, 1980</xref>; <xref ref-type="bibr" rid="bib22">Hughes, 1979</xref>), with eye movements creating variability in the extent of the overlap at the edges of the two visual fields, the transition from monocular to binocular (<xref ref-type="fig" rid="fig4">Figure 4D</xref>). The functional foci for both eyes were predominately contained within the region of continuous binocular overlap. A horizontal transect through the optical axis for all animals showed a gradual transition from continuous binocular coverage to zero binocular coverage commencing just nasal of the optical axis (<xref ref-type="fig" rid="fig4">Figure 4D</xref>, <xref ref-type="fig" rid="fig4s3">Figure 4—figure supplement 3H and I</xref>), indicating that the region of highest overall RGC density spans this transitional region whereas the functional foci are, on average, contained within the binocular region (<xref ref-type="fig" rid="fig4s3">Figure 4—figure supplement 3H</xref>).</p><p>We next quantified the variability of alignment of the left and right visual fields within the binocular region, and specifically in the functional focus location (<xref ref-type="fig" rid="fig4">Figure 4E</xref>) by using the center of mass (50% isodensity contour center) of the left eye functional focus as an initial reference point and projecting this point to the boundary of a hypothetical sphere surrounding the head. This contact point on the sphere was then re-projected into the right eye to identify the matching location of the left eye (<xref ref-type="fig" rid="fig4">Figure 4E</xref>). We then followed the trajectory of the re-projected point in the right eye to get a measurement of alignment variability (<xref ref-type="fig" rid="fig4">Figure 4F</xref>, for comparison with the locations in the right eye projected into the left eye see <xref ref-type="fig" rid="fig4s3">Figure 4—figure supplement 3I–K</xref>). While pursuing crickets, alignment precision varied through time (<xref ref-type="fig" rid="fig4">Figure 4G</xref>) with the mean alignment of the reference point over all animals and data segments being ~8–9°, which is around the size of V1 cortical neuron receptive fields (~5–15° [<xref ref-type="bibr" rid="bib41">Niell and Stryker, 2008</xref>], <xref ref-type="fig" rid="fig4">Figure 4H</xref>, mean ± SD, left eye projected into right eye 8.8 ± 6.9°; right eye projected into left eye 8.6 ± 6.7°). Repeating this analysis for all points within the region where the probability of binocular overlap was greater than 5% showed that there was a relatively uniform alignment over the entire region (<xref ref-type="fig" rid="fig4">Figure 4I</xref>), and that the average alignment error in the functional foci was 8–10°. Coordination of eye movements was important for alignment, as freezing the movements of one eye to its mean position resulted in a significant increase in the alignment error when comparing individual cricket tracking sequences (left all rotations vs. left eye frozen P = 1.78 x 10<sup>−10</sup>, right eye all rotations vs. right eye frozen P = 7.12 x 10<sup>−11</sup>, N=52 sequences, unpaired Student’s t-test), and a ~54% increase in the mean alignment error over all frames for the reference location (<xref ref-type="fig" rid="fig4">Figure 4I</xref>, left eye projected into right eye (left eye frozen) 13.4 ± 8.3°; Right eye projected into left eye (right eye frozen) 13.4 ± 8.3°, mean ± SD, 159318 frames, N=3 mice), which also resulted in a uniform increase in alignment error over the whole overlap region (<xref ref-type="fig" rid="fig4">Figure 4J</xref> and <xref ref-type="fig" rid="fig4s3">Figure 4—figure supplement 3J–L</xref>). In summary, during pursuit behavior the functional foci are located in a stable binocular region of the mouse’s visual field. However, in the absence of a mechanism for voluntarily directing its gaze toward a specific target, such as smooth pursuit, tight coupling of VOR-evoked eye movements to head rotations would seem to be restrictive to an animal’s ability to move the target into a specific part of their visual field during pursuit. We therefore next measured what mechanisms mice use to bring the prey into their functional focus.</p></sec><sec id="s2-6"><title>Behavioral mechanisms for maintaining prey within functional foci</title><p>At detection, mice orient toward their target, aligning their head with the prey and running towards it (<xref ref-type="fig" rid="fig2">Figure 2D</xref>), keeping the cricket within a narrow window around its forward direction. This provides a direct way for mice to hold their prey within their binocular visual fields (<xref ref-type="fig" rid="fig4">Figure 4D</xref>). We next measured whether additional head or eye movements are used to keep the target within the functional foci. If the mice were actively maintaining the prey within a fixed location of their visual fields, the position of the cricket image should not change as the mouse approaches the cricket. The cricket image location could be maintained by either a head or eye rotation. If they were not actively maintaining the prey in a fixed location, the cricket images should shift downwards in the visual fields as the mouse approaches. To distinguish between these two possibilities, we plotted the cricket positions in the eye views color-coded by the distance between the mouse and cricket (<xref ref-type="fig" rid="fig5">Figure 5A</xref>). As the mouse approached the cricket during the track behavioral epoch, the projected cricket positions systematically shifted lower in the visual field (<xref ref-type="fig" rid="fig5">Figure 5A</xref> lower). This suggests that the mice did not use additional head or eye movements (<xref ref-type="fig" rid="fig5s1">Figure 5—figure supplement 1</xref>) to bring the cricket into the functional foci, but rather manipulated the cricket’s position in the eye view by orienting and moving towards the target. Consistent with this, head pitch remained stable as the mice approached the crickets (<xref ref-type="fig" rid="fig5">Figure 5B</xref>). Furthermore, there was no significant difference in head pitch as a function of distance to the cricket between non-tracking and tracking periods (non-tracking head pitch: −3.7 ± 26.5°, mean ± SD, median = −11.3°, tracking head pitch: −12.9 ± 15.7°, mean ± SD, median = −14.6°, Ks test, P = 0.709, paired Student’s t-test P = 0.197, N = 18 non-tracking and track sequences, N = 3 mice). In addition, and consistent with previous findings (<xref ref-type="bibr" rid="bib39">Michaiel et al., 2020</xref>), mice did not significantly converge their eyes as they approached the crickets (non-tracking head vergence: 7.6 ± 13.5°, mean ± SD, median = 8.6°, tracking head vergence: 2.5 ± 16.7°, mean ± SD, median = 3.2°. Ks test, P = 0.425, paired Student’s t-test P = 0.225, N=18 non-tracking and track sequences, N = 3 mice, <xref ref-type="fig" rid="fig5s1">Figure 5—figure supplement 1J</xref> and <xref ref-type="table" rid="table4">Table 4</xref>). These observations suggest that the primary role for the eye movements is stabilizing the visual fields.</p><fig-group><fig id="fig5" position="float"><label>Figure 5.</label><caption><title>Mechanisms used to maintain prey within a focal visual region.</title><p>(<bold>A</bold>) Corneal locations of cricket position color-coded by Euclidean distance to cricket for non-track (upper) and track (lower) epochs (18 data sequences, 15649 non-tracking and 8510 tracking frames, n=3 animals). (<bold>B</bold>) Mean and SD head pitch with Euclidean distance to cricket (left) and distribution of head pitch angles (right) for non-track (red) and track (blue) epochs (datasets as in A). (<bold>C</bold>) Mouse trajectories during non-track epochs rotated and overlaid to show deviation from a direct path (13 trajectories from three animals). (<bold>D</bold>) Mouse trajectories as in C but during track epochs (13 trajectories from three animals). (<bold>E</bold>) Histogram of lateral deviations for non-track (red) and track (blue) data in C and D calculated 20 cm from the end of the trajectory. (<bold>F</bold>) Boxplots and individual data points of absolute maximal lateral deviation from a direct path between start and end points for non-track (red) and track (blue) epochs (datasets as in C and D), ** p = 0.0006, Wilcoxon’s Rank Sum Test. (<bold>G</bold>) Boxplots and individual data points of area under the curve (AUC) of mouse trajectories during non-track (red) and track (blue) epochs (datasets as in C and D), ** p = 0.0029, Wilcoxon’s Rank Sum Test.</p><p><supplementary-material id="fig5sdata1"><label>Figure 5—source data 1.</label><caption><title>Related to <xref ref-type="fig" rid="fig5">Figure 5A–G</xref>.</title></caption><media mime-subtype="xlsx" mimetype="application" xlink:href="elife-70838-fig5-data1-v1.xlsx"/></supplementary-material></p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-70838-fig5-v1.tif"/></fig><fig id="fig5s1" position="float" specific-use="child-fig"><label>Figure 5—figure supplement 1.</label><caption><title>Eye movements during non-tracking and tracking periods.</title><p>(<bold>A</bold>) Violin plots showing the variability in horizontal eye rotations for left (blue) and right (green) eyes during non-tracking (Non-trk) and track (Track) epochs. (<bold>B</bold>) Variability in vertical eye rotations during non-tracking and track epochs. Conventions as in A. (<bold>C</bold>) Variability in torsional eye rotations during non-tracking and track epochs. Conventions as in A. (<bold>D</bold>) Variability in ocular vergence during non-tracking and track epochs. Conventions as in A. (<bold>E</bold>) Average relationship (mean ± SD) between head roll and Euclidean distance from mouse to cricket during non-track (red) and track (blue) epochs. Data histogram shown at right. (<bold>F</bold>) Average relationship (mean ± SD) between vertical eye rotations of left (blue) and right (green) eyes and Euclidean distance between mouse and cricket during non-track epochs. Data histogram shown at right. (<bold>G</bold>) Average relationship between vertical eye rotations and mouse-cricket Euclidean distance during track epochs. Conventions as in F. (<bold>H</bold>) Average relationship between torsional eye rotations and mouse-cricket Euclidean distance during non-track epochs. Conventions as in F. (<bold>I</bold>) Average relationship between torsional eye rotations and mouse-cricket Euclidean distance during non-track epochs. Conventions as in F. (<bold>J</bold>) Average relationship between ocular vergence and mouse-cricket Euclidean distance during non-tracking and tracking epochs. Conventions as in E. For all panels, data taken from 18 non-track epochs and 18 track epochs, from three animals.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-70838-fig5-figsupp1-v1.tif"/></fig></fig-group><table-wrap id="table4" position="float"><label>Table 4.</label><caption><title>Eye rotations during non-tracking and tracking periods.</title><p>Horizontal, vertical, and torsional eye rotations during the non-tracking and tracking periods in <xref ref-type="fig" rid="fig5">Figure 5</xref>. Data taken from 18 non-track epochs and 18 track epochs, from three animals.</p></caption><table frame="hsides" rules="groups"><thead><tr><th valign="top">Ocular Rotation</th><th valign="top">Non-Trk <break/>(mean ± SD) (median)</th><th valign="top">Track <break/>(mean ± SD) (median)</th><th valign="top">p value (KS)</th><th valign="top">P value (Student <break/>T-test)</th></tr></thead><tbody><tr><td valign="top">Lt Horizontal</td><td valign="top">−1.8 ± 9.9° <break/>(−1.7°)</td><td valign="top">−1.8 ± 14.9° <break/>(−3.5°)</td><td valign="top">3.9x10<sup>−2</sup></td><td valign="top">0.162</td></tr><tr><td valign="top">Lt Vertical</td><td valign="top">0.8 ± 11.2° <break/>(−0.4°)</td><td valign="top">4.5 ± 11.1° <break/>(4.9°)</td><td valign="top">0.425</td><td valign="top">0.616</td></tr><tr><td valign="top">Lt Torsional</td><td valign="top">2.9 ± 16.1° <break/>(0.0°)</td><td valign="top">1.3 ± 20.6° <break/>(0.0°)</td><td valign="top">0.945</td><td valign="top">0.610</td></tr><tr><td valign="top">Rt Horizontal</td><td valign="top">5.7 ± 10.9° <break/>(5.5°)</td><td valign="top">1.0 ± 9.9° <break/>(1.7°)</td><td valign="top">9.82x10<sup>−2</sup></td><td valign="top">1.08x10<sup>−2</sup></td></tr><tr><td valign="top">Rt Vertical</td><td valign="top">−3.6 ± 13.4° <break/>(−6.3°)</td><td valign="top">5.6 ± 12.7° <break/>(−7.1°)</td><td valign="top">0.945</td><td valign="top">0.804</td></tr><tr><td valign="top">Rt Torsional</td><td valign="top">0.32 ± 13.5° <break/>(0.0°)</td><td valign="top">0.7 ± 12.3° <break/>(0.0°)</td><td valign="top">0.425</td><td valign="top">0.366</td></tr></tbody></table></table-wrap><p>If mice successfully track and capture prey by retaining the target in front of them then this should be reflected in the trajectories taken by the mice during the tracking epoch compared to the non-tracking behavioral epochs. During cricket tracking periods, mice ran directly toward the cricket, and their trajectories were significantly straighter than during equivalent non-tracking phases (<xref ref-type="fig" rid="fig5">Figure 5C–G</xref>). Lateral deviation at the half-way point (<xref ref-type="fig" rid="fig5">Figure 5E</xref>, non-tracking 4.3 ± 4.0 cm, tracking 1.4 ± 2.0 cm, p = 0.009), maximum lateral deviation (<xref ref-type="fig" rid="fig5">Figure 5F</xref>, non-tracking, 7.7 ± 4.9 cm, tracking 2.8 ± 2.0 cm, p = 0.0006) and the area between the trajectory and minimum distance path to the target (<xref ref-type="fig" rid="fig5">Figure 5G</xref>, area under the curve, non-tracking 135.6 ± 102.7 cm<sup>2</sup>, tracking 51.3 ± 45.8 cm<sup>2</sup>, p = 0.0029) were all significantly smaller in the tracking epochs (all comparisons mean ± SD, N=13 tracking and non-tracking sequences, N=3 mice, Wilcoxon’s Rank Sum Test).</p><p>Together this suggests that mice do not make compensatory vertical head movements, tracking eye movements or vergence eye movements to keep prey within their functional foci, but instead retain their target within a restricted bearing by running straight towards it. This raised the question of what is unique about the position of the functional focus on the cornea?</p></sec><sec id="s2-7"><title>Functional foci are located in region of minimized optic flow</title><p>Optic flow is the pattern of object motion across the retina that can be self-induced, through eye, head or translational motion, or induced by motion of objects in the environment, or combinations thereof (for review see: <xref ref-type="bibr" rid="bib1">Angelaki and Hess, 2005</xref>). In a freely moving animal in a still environment, translational motion results in a pattern of optic flow that consists of a radial flow-fields emanating from a point of zero-optic flow (<xref ref-type="fig" rid="fig6">Figure 6A</xref>). While optic flow is used by many species for both navigation and the estimation of the motion properties of moving objects, motion induced blur degrades image formation on the retina and decreases resolution depending on the animal’s direction of travel (<xref ref-type="bibr" rid="bib30">Land, 1999</xref>). Optic flow is minimized in the direction of travel directly in front of the animal (<xref ref-type="bibr" rid="bib51">Sabbah et al., 2017</xref>), with flow fields directed away from the travel direction and forming a second minimum directly behind the animal’s head (<xref ref-type="fig" rid="fig6">Figure 6A</xref>, see also <xref ref-type="bibr" rid="bib1">Angelaki and Hess, 2005</xref>). To measure the characteristics of optic flow in in both eyes of freely moving mice and to relate this flow pattern to the location of the functional foci, we next calculated average optic flow from freely moving data during pursuit behavior using the digitized environment and eye-views (<xref ref-type="fig" rid="fig6">Figure 6B</xref>). First, we calculated optic flow in the idealized case of forward translation motion when all surrounding surfaces were equidistant (<xref ref-type="fig" rid="fig6">Figure 6C</xref>). As mice have laterally facing eyes (optical axis = 59.9 ± 19.8° and −62.3 ± 14.7° lateral of frontal for the left and right eyes respectively, N=3 mice), idealized forward motion resulted in the region of minimal optic flow in each eye being located off optical axis in the ventro-medial corneal region representing the animal’s forward direction (radial displacement from optical axis 36.64 ± 0.92° and −41.11 ± 2.27°, rotational angle 122.95 ± 17.05° and −107.94 ± 9.96°, for the left and right eyes respectively, mean ± SD, N=2 mice, <xref ref-type="fig" rid="fig6">Figure 6C</xref>). During free movement both the distance from the eyes to objects in the environment, as well as head and eye-rotations had a strong influence on the optic flow fields. We visualized the average flow fields during free motion by calculating the optic flow on the cornea during multiple pursuit trials (N=20 prey chases containing 52 tracking sequences, initial Euclidean distance mouse-cricket &gt;20 cm). The resulting optic flow density maps were complex with a wide range of average speeds (133.44 ± 221.42 °/s, mean ± 1SD, median 28.64 °/s, interquartile range 4.57–137.18 °/s, N=2 mice, <xref ref-type="fig" rid="fig6">Figure 6D</xref>). The area of lowest optic flow extended from the nasal part of the field of view to overhead (<xref ref-type="fig" rid="fig6">Figure 6D</xref>) but, unlike the simulated case (<xref ref-type="fig" rid="fig6">Figure 6C</xref>), optic flow was not symmetric around the regions of minimal optic flow. Optic flow in the 30x30° region surrounding the ventro-medial point of minimal optic flow was significantly lower than that in an equivalent region in the ventro-temporal region during free movement, but not in the simulated case (free movement: nasal 46.3 ± 9.8 °/s, temporal: 199.4 ± 29.0 °/s, p = 0.0014, simulated: nasal 163.6 ± 82.2 °/s, temporal: 833.0 ± 416.5 °/s, p = 0.0662, mean ± SD, two-sided t-test, unequal variance, N=2 mice). Optic flow was higher in the lower visual field and considerably lower in the upper visual field (lower left eye visual field: 262.44 ± 106.50 °/s, upper left eye visual field: 44.87 ± 24.31 °/s, p = 1.78x10<sup>−20</sup>, lower right eye visual field: 361.91 ± 168.80 °/s, upper right eye visual field: 40.59 ± 22.79 °/s, p = 6.68x10<sup>−19</sup>, Two-sided t-test, unequal variance, N=2 mice), due to the greater distance between ceiling and mouse (distance to floor 2 ± 1 cm, distance to ceiling 308 ± 107 cm, 9873 frames, N=3 mice). Given the advantage of low optic flow to mammalian vision, we next quantified the position of least optic flow during prey tracking. We calculated the location of the translational optic flow minimum in each frame for each eye, and created a probability map of this location over the visual field (<xref ref-type="fig" rid="fig6">Figure 6E</xref>). The region of highest likelihood for the presence of the optic flow minimum overlapped considerably with the functional foci in both eyes during the tracking epochs of the pursuit behavior (overlap of optic flow 95% minima and functional foci 50% regions: 100% and 99 ± 1%, overlap of optic flow 50% minima and functional foci 50% regions: 61 ± 14% and 72 ± 4% in left and right eyes respectively, N=3 mice, <xref ref-type="fig" rid="fig6">Figure 6E</xref>). Together this shows that the behavioral strategy employed by mice during hunting, consisting of orienting themselves to directly face the prey and following a straight and direct course to it, results in the image of their prey coinciding with the region of reduced optic flow during pursuit, where the retinal image of their prey is least distorted due to motion induced image blur.</p><fig id="fig6" position="float"><label>Figure 6.</label><caption><title>Functional foci are located in the regions of reduced optic flow during forward motion.</title><p>(<bold>A</bold>) Schematic of idealized optic flow (black arrows) as a mouse translates forwards (after <xref ref-type="bibr" rid="bib51">Sabbah et al., 2017</xref>). Left (blue arrow) and right (green arrow) gaze vectors. (<bold>B</bold>) Location of optic flow minima in reconstructed mouse eye views of the cricket and experiment arena (from <xref ref-type="fig" rid="fig1">Figure 1H</xref>), dashed circle represents 45°. (<bold>C</bold>) Optic flow map in corneal views, showing flow velocity (color coding) and direction (white arrows) calculated for the idealized spherical environment in 6A with forward motion of 50 cm/s. (<bold>D</bold>) Optic flow maps in corneal views during track epochs (5269 frames), from one animal. (<bold>E</bold>) Probability density map of optic flow poles in mouse corneal views during track epochs (data as in <xref ref-type="fig" rid="fig2">Figures 2G</xref>, 13,641 frames), with overlay of isodensity contours from <xref ref-type="fig" rid="fig2">Figure 2H</xref>.</p><p><supplementary-material id="fig6sdata1"><label>Figure 6—source data 1.</label><caption><title>Related to <xref ref-type="fig" rid="fig6">Figure 6C</xref>.</title></caption><media mime-subtype="zip" mimetype="application" xlink:href="elife-70838-fig6-data1-v1.zip"/></supplementary-material></p><p><supplementary-material id="fig6sdata2"><label>Figure 6—source data 2.</label><caption><title>Related to <xref ref-type="fig" rid="fig6">Figure 6D</xref>.</title></caption><media mime-subtype="zip" mimetype="application" xlink:href="elife-70838-fig6-data2-v1.zip"/></supplementary-material></p><p><supplementary-material id="fig6sdata3"><label>Figure 6—source data 3.</label><caption><title>Related to <xref ref-type="fig" rid="fig6">Figure 6E</xref>.</title></caption><media mime-subtype="zip" mimetype="application" xlink:href="elife-70838-fig6-data3-v1.zip"/></supplementary-material></p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-70838-fig6-v1.tif"/></fig></sec></sec><sec id="s3" sec-type="discussion"><title>Discussion</title><p>We developed a technique for reconstructing the visual fields in a freely moving mouse during prey pursuit to quantify the spatial relationship between the environment, cricket and the mouse. Using this approach, we show that during pursuit of crickets, the hunting behavior employed by mice results in the image of the prey consistently falling within a localized region of their visual field, termed here the functional focus. The positional maintenance of the cricket was not achieved by active eye movements that followed the prey, but rather by the animal’s change in behavior, specifically the head-movement and orientation toward the prey during pursuit. While eye rotations stabilized the visual field via the vestibulo-ocular reflex by countering head rotations, the rotations were not specific to either prey detection or prey tracking. This strongly suggested that eye-rotations in mice, like in rats, primarily stabilize their large field of view and that all three rotational axes, including ocular torsion, combine to counter head rotations. In addition, we also show that eye rotations cannot be predicted from head rotations in any one axis as has been suggested by recent studies of mouse eye motion (<xref ref-type="bibr" rid="bib38">Meyer et al., 2020</xref>; <xref ref-type="bibr" rid="bib37">Meyer et al., 2018</xref>; <xref ref-type="bibr" rid="bib39">Michaiel et al., 2020</xref>) but rather by a combination of all head rotations (<xref ref-type="fig" rid="fig4s2">Figure 4—figure supplement 2</xref>). As the eye rotations were predominately associated with countering head-rotations, this raised the question of whether the mouse can use a large fraction of its stabilized visual field to pursuit crickets, or whether a specific region is utilized. To accurately determine the correspondence between the animal’s visual field and the retinal image, we developed a quantitative model of the mouse eye and optics. Using this we show that the location of the functional focus occurs within a dorso-temporal retinal region in an area with the highest density of Alpha-ON sustained RGCs, whose general properties have been previously proposed to be well suited for this purpose (<xref ref-type="bibr" rid="bib5">Bleckert et al., 2014</xref>). Finally, we used the detailed, digitally rendered reconstruction of the arena and surrounding room to calculate the realistic optic flow in the visual fields (<xref ref-type="bibr" rid="bib16">Gibson et al., 1955</xref>; <xref ref-type="bibr" rid="bib51">Sabbah et al., 2017</xref>; <xref ref-type="bibr" rid="bib52">Saleem, 2020</xref>) of the mice as they pursued crickets, which showed that the functional foci coincide with the region of the visual fields with minimal optic flow during the cricket pursuit, and presumably are thereby minimally distorted by motion-induced image blur (for review see <xref ref-type="bibr" rid="bib1">Angelaki and Hess, 2005</xref>). Critical to this finding was the ability to isolate the visual sense, generate a detailed reconstruction of both the local environment and the animal’s ocular anatomy and optical pathways, but also record eye motion in all three optical axes especially ocular torsion, something that has only been achieved in rats (<xref ref-type="bibr" rid="bib68">Wallace et al., 2013</xref>). Lastly, by building an optical model and establishing the relationship between the retinal surface and the corneal surface we were able to relate the data generated from published studies on retinal anatomy (<xref ref-type="bibr" rid="bib5">Bleckert et al., 2014</xref>; <xref ref-type="bibr" rid="bib13">Dräger and Olsen, 1981</xref>; <xref ref-type="bibr" rid="bib60">Sterratt et al., 2013</xref>) and physiology (<xref ref-type="bibr" rid="bib10">Dhande et al., 2015</xref>; <xref ref-type="bibr" rid="bib36">Martersteck et al., 2017</xref>; <xref ref-type="bibr" rid="bib40">Murphy and Rieke, 2006</xref>; <xref ref-type="bibr" rid="bib44">Pang et al., 2003</xref>; <xref ref-type="bibr" rid="bib51">Sabbah et al., 2017</xref>; <xref ref-type="bibr" rid="bib66">van Wyk et al., 2009</xref>) to our behavioral data.</p><p>Both estimates of the field of view of the mouse eye (<xref ref-type="bibr" rid="bib11">Dräger, 1978</xref>) and electrophysiological measurements of receptive field locations of visually responsive neurons (<xref ref-type="bibr" rid="bib12">Dräger and Olsen, 1980</xref>; <xref ref-type="bibr" rid="bib67">Wagor et al., 1980</xref>) have established that the binocular region of the visual field in mice is contained within the nasal visual field of each eye, and spans a region of 30-40° in front of the animal (<xref ref-type="bibr" rid="bib67">Wagor et al., 1980</xref>). We present here, that similar to the rat (<xref ref-type="bibr" rid="bib68">Wallace et al., 2013</xref>), the overlapping monocular fields that make up the binocular overlap are not constantly maintained (<xref ref-type="fig" rid="fig4">Figure 4H</xref>) but fluctuate at the margins as the eyes rotate to counter head rotations (<xref ref-type="fig" rid="fig4">Figure 4D</xref>), resulting in a region where there is a transition from one area with near continuous binocular coverage, through to a region that is invariably monocular. The functional focus described here lies within the region of high probability of maintained binocular overlap. This region of the visual field projects onto the temporal retina, which contains both ipsilaterally projecting (uncrossed) RGCs (<xref ref-type="bibr" rid="bib12">Dräger and Olsen, 1980</xref>; <xref ref-type="bibr" rid="bib50">Reese and Cowey, 1986</xref>) and RGCs which form part of the callosal projection pathway (<xref ref-type="bibr" rid="bib29">Laing et al., 2015</xref>; <xref ref-type="bibr" rid="bib42">Olavarria and Van Sluyters, 1983</xref>; <xref ref-type="bibr" rid="bib49">Ramachandra et al., 2020</xref>), both of which are considered central to binocular visual processing. In addition, the current study adds to the significance of these previous findings and suggests that the functional focus location is well placed to support stereoscopic depth perception, assuming that this form of visual processing is available to and employed by the mouse (<xref ref-type="bibr" rid="bib27">La Chioma et al., 2019</xref>; <xref ref-type="bibr" rid="bib28">La Chioma et al., 2020</xref>; <xref ref-type="bibr" rid="bib54">Samonds et al., 2019</xref>; <xref ref-type="bibr" rid="bib55">Scholl et al., 2013</xref>; <xref ref-type="bibr" rid="bib56">Scholl et al., 2015</xref>). Further supportive of the importance and relevance of the region of binocular overlap, another recent study provides strong evidence to suggest that ipsilaterally projecting RGCs in the ventro-temporal retina are important in the final phase of cricket pursuit (mouse to cricket distance less than 6 cm), with selective ablation of these RGCs reducing the probability that coming into close proximity with the cricket resulted in its capture (<xref ref-type="bibr" rid="bib24">Johnson et al., 2021</xref>). This finding is complimentary to the current study, in that it deals with the section of the hunting behavior excluded from analysis in the current study, that being behavioral segments where the distance between mouse and cricket is &lt; 3 cm. This criteria was used in the current study to mitigate the possibility that the mouse was using its mystacial whiskers to detect or assist in detection of the cricket location. In the current study, we find that the location of the image of the cricket systematically shifts nasally and slightly ventrally on the cornea (temporally and slightly dorsally on the retina) as the mouse closes in on the cricket, and this may place the cricket’s image within the retinal region containing the ipsilaterally-projecting RGCs. As the mouse closes further, beyond our distance threshold, these RGCs may become increasingly important, particularly when the cricket is within grasping distance, where binocular vision and stereopsis may be most relevant.</p><p>While the overall highest density of retinal ganglion cells in mice is located in the region around the optical axis (<xref ref-type="bibr" rid="bib13">Dräger and Olsen, 1981</xref>), a recent study examining the distributions of various different subclasses of RGCs has shown that the highest density of Alpha-ON sustained RGCs resides in the superior-temporal retina (<xref ref-type="bibr" rid="bib5">Bleckert et al., 2014</xref>) in a region which would approximately coincide with the functional focus. These Alpha-ON sustained RGCs have center-surround receptive fields, a rapid response and fast conducting axon, and are thought to be ‘spot detectors’ (for review see <xref ref-type="bibr" rid="bib10">Dhande et al., 2015</xref>). In addition, the Alpha-ON sustained RGCs in this particular retinal region differ from the same RGC-type in other regions of the retina as they have a significantly smaller dendritic tree radius and subtend a smaller area of physical space as well as have overlapping receptive fields (<xref ref-type="bibr" rid="bib5">Bleckert et al., 2014</xref>). Taken together, the cellular properties as well as the region in-front of the animal which provides their input are consistent with the requirements for tracking small and mobile targets (<xref ref-type="bibr" rid="bib5">Bleckert et al., 2014</xref>; <xref ref-type="bibr" rid="bib9">Dean et al., 1989</xref>; <xref ref-type="bibr" rid="bib35">Lettvin et al., 1959</xref>; <xref ref-type="bibr" rid="bib48">Procacci et al., 2020</xref>). A recent study has shown that both wide-field and narrow-field neuronal types in the mouse superior colliculus play central roles in the detection and pursuit phases of this pursuit task, respectively (<xref ref-type="bibr" rid="bib19">Hoy et al., 2019</xref>), and consistent with this, Alpha-ON sustained RGCs having projections to the superior colliculus (<xref ref-type="bibr" rid="bib36">Martersteck et al., 2017</xref>). It is currently unclear how the primary visual cortex (V1) contributes to this behavior, but some role is possible if not probable, which would also be supported by the strong Alpha RGC projection to the dorsal lateral geniculate nucleus and thus V1 (<xref ref-type="bibr" rid="bib36">Martersteck et al., 2017</xref>). Additionally, an increased cortical magnification factor occurs in the region corresponding to the nasal, binocular visual field (<xref ref-type="bibr" rid="bib15">Garrett et al., 2014</xref>; <xref ref-type="bibr" rid="bib57">Schuett et al., 2002</xref>).</p><p>Finally, we show that the region that contains these Alpha-ON sustained RGCs also coincides with the region of minimum optic flow and therefore reduced image blur during translation pursuit, a feature which would support accurate localization of small targets by Alpha-ON sustained RGCs. Patterns of optic flow are thought to be an important component of perception of self-motion (<xref ref-type="bibr" rid="bib34">Lappe et al., 1999</xref>). Mechanistically supporting this, global alignment across the retina of the preferred orientation of direction-selective retinal ganglion cells with the cardinal directions of optic flow during idealized motion has been shown in mice (<xref ref-type="bibr" rid="bib51">Sabbah et al., 2017</xref>). The average optic flow measured here was, perhaps not surprisingly, strikingly different from that observed with idealized motion, resulting in large part from the large differences to objects in the environment in which the behaviors were performed. For fast moving, ground dwelling animals like mice, considerable asymmetry in optic flow across the visual field may be the more normal case, considering that objects above the animal are, in general, likely to be more distant.</p><p>In freely moving rats, it has been shown that ocular torsion is correlated with head pitch such that nose-up rotation of the head is counteracted by incyclotorsion (rotation toward the nose) of both eyes, with nose-down pitch counteracted by excyclotorsion (<xref ref-type="bibr" rid="bib68">Wallace et al., 2013</xref>). These rotations have the effect of stabilizing the horizontal plane of the retina with respect to the horizon. The considerable radial separation between the optical axis of the eye and both the functional foci observed in the current study as well as the highest density region of Alpha-ON sustained RGCs (<xref ref-type="bibr" rid="bib5">Bleckert et al., 2014</xref>) renders the direction in which these regions point highly sensitive to torsional rotation. Consequently, torsional rotation also has an important effect on alignment of the left and right visual fields in addition to its role in visual field stabilization. We show here that torsional rotation in freely moving mice is also dynamic, with episodes showing in- and excyclovergence as well as dextro- and levocycloversion. Further, while the correlation between torsional rotation and head pitch observed in rats was measured, there was also an additional relation between ocular torsion and head roll consistent with VOR-evoked dextro- and levocycloversion. Consequently, prediction of torsion using a model based on head pitch alone resulted in an average error of around 7°, while an expanded model including roll as well performed better (<xref ref-type="fig" rid="fig4s2">Figure 4—figure supplement 2J–O</xref>).</p><p>In summary, we show here that during pursuit in mice the image of the intended prey falls consistently in a localized region of their visual fields, referred to here as the functional focus, and that this occurs through the animal orientating their head and body and running directly toward the prey rather than with specific eye movements. The location of the functional focus is within the binocular visual field, but in addition also coincides with the region of minimal optic flow during the pursuit, and presumably also minimally distorted by motion blur.</p></sec><sec id="s4" sec-type="materials|methods"><title>Materials and methods</title><table-wrap id="keyresource" position="anchor"><label>Key resources table</label><table frame="hsides" rules="groups"><thead><tr><th valign="top">Reagent type (species) or resource</th><th valign="top">Designation</th><th valign="top">Source or reference</th><th valign="top">Identifiers</th><th valign="top">Additional information</th></tr></thead><tbody><tr><td valign="top">Software, algorithm</td><td valign="top">Matlab</td><td valign="top">Mathworks</td><td valign="top">Matlab 2019b</td><td valign="top"/></tr><tr><td valign="top">Software, algorithm</td><td valign="top">OpenJDK</td><td valign="top">Oracle</td><td valign="top">Version 1.8.0_292</td><td valign="top"/></tr><tr><td valign="top">Software, algorithm</td><td valign="top">Cuda</td><td valign="top">Nvidia</td><td valign="top">Release 10.1, V10.1.243</td><td valign="top"/></tr><tr><td valign="top">Software, algorithm</td><td valign="top">Python</td><td valign="top">Python Software Foundation</td><td valign="top">Python 3.8.10</td><td valign="top"/></tr><tr><td valign="top">Software, algorithm</td><td valign="top">Qt</td><td valign="top">Qt Project</td><td valign="top">Qmake 3.1, Qt 5.9.5</td><td valign="top"/></tr><tr><td valign="top">Software, algorithm</td><td valign="top">OpenGL</td><td valign="top">Khronos Group/Nvidia/AMD</td><td valign="top">Version 4.6.0</td><td valign="top"/></tr></tbody></table></table-wrap><sec id="s4-1"><title>Animal details</title><p>Experiments were carried out in accordance with protocols approved by the local animal welfare authorities (Landesamt für Natur Umwelt und Verbraucherschutz, Nordrhein-Westfalen, Germany, protocol number 84–02.04.2017.A260). Experiments were carried out using male C57Bl/6J mice acquired from Charles River Laboratories. At the time of the cricket hunting experiments, mice (n=9) were between 2 and 8 months old, and weighed between 21 and 29 g. Mice were maintained on a 12 hr light/dark cycle. Crickets (<italic>Acheta domesticus</italic>, Bugs-International, Germany) were housed in 480x375x210 cm cages with <italic>ad lib</italic> water and food (powdered mouse chow). During experiments in which head and eye rotations were recorded cricket body sizes ranged from 1 cm to 2 cm (1.8 ± 0.3 cm, mean ± SD, n=25).</p></sec><sec id="s4-2"><title>Implant surgery</title><p>Animals were anesthetized using fentanyl, medetomidine, and midazolam (50 µg/kg, 5 mg/kg, and 0.5 mg/kg, delivered i.p., respectively), and analgesia was provided with carprofen (7 mg/kg delivered s.c.). Body temperature was maintained using a thermostatically regulated heating pad. Respiration rate and depth of anesthesia was monitored throughout the procedure. Following opening of the skin and removal of connective tissue overlying the sagittal suture and parietal bones, the skull was cleaned with H<sub>2</sub>O<sub>2</sub> (3%). A custom-made implant, consisting of a flat circular attachment surface for attachment to the skull, and implant body with three anti-rotation pins and a magnet (<xref ref-type="fig" rid="fig7">Figure 7A–B</xref>), was fixed to the dried skull using a UV-curing dental adhesive (Optibond FL, Kerr Corporation, Orange, California, USA) and a UV-curing dental composite (Charisma, Kulzer GmbH, Hanau, Germany). The implant attachment surface and body were made from light-weight, bio-compatible dental resin (Dental SG, Formlabs, Germany). Skin margins were closed with 5/0 Vicryl sutures (Ethicon Inc, Somerville, NJ, USA) and a cyanoacrylate adhesive (Histoacryl, B.Braun, Melsungen, Germany). The injectable anesthetic combination was antagonized with naloxone, atipamezole and flumazenil (respectively 1.2 mg/kg, 0.5 mg/kg and 0.75 mg/kg, delivered i.p.), and the animal was allowed to recover.</p><fig id="fig7" position="float"><label>Figure 7.</label><caption><title>Methods.</title><p>(<bold>A</bold>) Implanted baseplate with magnetic attachment point and restraining pin holes. (<bold>B</bold>) Miniaturized eye cameras and head position tracking system. Infrared illumination LEDs were mounted on the camera objective and reflected onto the eye using an IR-reflective mirror. Head position tracking IR-LEDs were mounted on three carbon-fiber struts attached to the head-mount. (<bold>C</bold>) Cricket capture times in lit or dark conditions in mice without (n=19 pursuit sequences, n=6 mice) or with (n=10 pursuit sequences in lit conditions and n=9 pursuit sequences in the dark, n=3 mice) corneal TiO<sub>2</sub> torsion tracking spots, Lit vs Dark with no spot, p = 0.0012, Lit vs Dark TiO<sub>2</sub> spot, p = 0.0133, Lit without spot vs Lit with TiO<sub>2</sub> spot, p = 0.69, Dark without spot vs Dark with TiO<sub>2</sub> spot, p = 1. n.s. = non-significant, *p&lt;0.05, **p&lt;0.01. Paired Wilcoxon’s signed rank tests. For these experiments, pursuits were conducted in a smaller arena (480 x 375 x 210 cm). (<bold>D</bold>) Images of mouse with eye camera and head position tracking system for anatomical calibration. Head mount and anatomical features marked. Anatomical features: Left (blue filled circles) and right (green filled circle) medial canthi, left (orange filled circles) and right (red filled circle) nostril positions. Head mount features: position tracking LEDs (large colored circles), IR mirror corner positions (small colored filled squares). (<bold>E</bold>) Sensitivity of the radial elevation on the retina in the mouse eye model to changes in the radii of curvature and thicknesses of the model optical components.</p><p><supplementary-material id="fig7sdata1"><label>Figure 7—source data 1.</label><caption><title>Related to <xref ref-type="fig" rid="fig7">Figure 7C</xref>.</title></caption><media mime-subtype="xlsx" mimetype="application" xlink:href="elife-70838-fig7-data1-v1.xlsx"/></supplementary-material></p><p><supplementary-material id="fig7sdata2"><label>Figure 7—source data 2.</label><caption><title>Related to <xref ref-type="fig" rid="fig7">Figure 7E</xref>.</title></caption><media mime-subtype="zip" mimetype="application" xlink:href="elife-70838-fig7-data2-v1.zip"/></supplementary-material></p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-70838-fig7-v1.tif"/></fig></sec><sec id="s4-3"><title>Positioning of the head-mounted cameras</title><p>The eye cameras for oculo-videography were mounted on mounting arms which were attached to a baseplate with complementary holes to the anti-rotation pins on the implant and fitted with a magnet of complementary polarity. During positioning of the head-camera, mice were anesthetized with isoflurane (induction: 3–5% isoflurane, maintenance: 2.0% isoflurane in air). Anesthetic depth and body temperature were monitored as above. The cameras were positioned to have a sharp image of the entire eye, with the mounting arms adjusted such that the cameras and mounting system caused minimal disruption to the mouse’s lateral and frontal field of view. Mounting arms were secured with cyanoacrylate adhesive glue (Histoacryl, B.Braun, Melsungen, Germany). The eye-camera system was then removed and the animal allowed to recover.</p></sec><sec id="s4-4"><title>Training procedure</title><p>Mice were acclimated to cricket capture in their home cage. Individual crickets were placed in the mouse’s home cage overnight, in addition to their standard ad lib mouse food. Mice were handled and habituated to the experimenter, the head cameras, and the head tracking mounts. The ability of each mouse to visually track the crickets was assessed using the protocol of <xref ref-type="bibr" rid="bib18">Hoy et al., 2016</xref>. Briefly, the ability of the mice to track and capture crickets in a white walled, 480 x 375 x 210 cm arena was assessed in lit and dark conditions (<xref ref-type="fig" rid="fig7">Figure 7C</xref>). Mice were given 2 min in which to capture the crickets. Prior to the assessment mice were food deprived overnight before the trial.</p></sec><sec id="s4-5"><title>Placement of torsion tracking marks</title><p>Crenellations along the iridial-pupil border were less distinct in mice than those previous described in rats (<xref ref-type="bibr" rid="bib68">Wallace et al., 2013</xref>). Ocular torsion changes were therefore measured by tracking the rotations of small spots of titanium dioxide (TiO<sub>2</sub>) paste dots (~300 μm) applied to ventral and/or temporal locations on the cornea as described in <xref ref-type="bibr" rid="bib65">van Alphen et al., 2010</xref>. The TiO<sub>2</sub> paste consisted of TiO<sub>2</sub> powder (Kronos Titan GmBH, Leverkusen, Germany) mixed with a small quantity of sterile artificial cerebrospinal fluid solution with the following composition (in mM): 135 NaCl, 5.4 KCl, 1.8 CaCl2, 1 MgCl2, 5 HEPES, pH balanced to 7.2 (300 mOsm/l). Application of the TiO<sub>2</sub> spots was performed with the animal anesthetized with isoflurane (induction: 5% isoflurane, maintenance: 0.5–1.0% isoflurane in air, total time anesthetized 5-10mins). Anesthetic depth and body temperature was monitored as above. Following application of TiO<sub>2</sub> spots, mice were allowed to recover for &gt;45 min prior to a cricket hunt. The presence of the TiO<sub>2</sub> marks did not significantly change the animal’s cricket hunting performance as assessed by the average time taken to capture crickets (<xref ref-type="fig" rid="fig7">Figure 7C</xref>).</p></sec><sec id="s4-6"><title>Experiment procedure</title><p>Initially, mice were allowed to explore the experimental arena (1x1x0.26 m) without head camera mounts. During subsequent training sessions, mice were acclimated to cricket hunting, with the head cameras on, in the experiment arena. Auditory white noise (60–65 dB, NCH-Tone generator v 3.26, NCH Software, Inc Greenwood Village, USA) was provided through four speakers (Visaton, Germany), one on each wall of the arena. Olfactory noise was provided by ventilating the arena (TD-1000/200 Silent fan, S and P, Barcelona, Spain) through a perforated floor (5 cm perforation spacing) with air blown through a cage containing live crickets (cricket cage dimensions 480x375x210cm). During experiments the arena was lit by a single lamp (4000 K, 9W, Osram, Munich, Germany) positioned ~1 m above the arena. During each experiment, the mouse was given 5 min to explore the arena without head cameras. After this period, the mouse was removed from the arena and the head cameras were mounted. At the commencement of each hunt, the cricket was released at a variable location into the central region of the arena.</p></sec><sec id="s4-7"><title>Eye camera and head position tracking system</title><p>Head and eye tracking was performed as described in <xref ref-type="bibr" rid="bib68">Wallace et al., 2013</xref>, with modifications as described below. The eye camera mount and implant were re-designed to be smaller, lighter and stronger (<xref ref-type="fig" rid="fig7">Figure 7A–B</xref>). The camera system body, camera holders and mounting arms were produced using a Formlabs Form2 SLA 3D printer (Formlabs Inc, USA), with Dental SG Resin (Formlabs Inc, USA) as the primary construction material. The cable used for position tracking LEDs power inputs and for data transfer and camera were custom cables (Axon Kabel GmbH, Leonberg, Germany) combined with custom-designed flexible flat cables (IBR Ringler, Bad Rappenau, Germany) for the cameras, to reduce stiffness over the last 30 cm. Eye movements were recorded at 60 Hz (camera resolution 752x480 pixels), with illumination provided by a ring of three IR-LEDs (λ=850 nm, OSRAM SFH4050 or SFH4053 @ 70mA, RS Components, Germany) surrounding the camera lens. The mouse’s head position and head rotations were tracked using seven IR-LEDs (λ = 950 nm, OSRAM SFH4043 @ 70mA, RS Components, Germany) mounted on three struts of carbon fiber that projected from the body of the camera system. The resultant total system weight was ~3 g, including effective cable weight.</p></sec><sec id="s4-8"><title>Mouse head and cricket position tracking</title><p>The positions of the cricket within the arena were recorded using four cameras (488 x 648 px, recorded at 200 Hz, piA640-210gm, Basler cameras, Basler Ahrensburg, Germany) fitted with NIR-blocking filters (Calflex X, Qioptiq, Germany). Cameras were located ~1.5 m above the arena and were positioned so that the arena was covered at all points by two or more cameras from differing vantage points. Mouse IR-head tracking LEDs were recorded at 200 Hz using four cameras (piA640-210gm, Basler cameras, Basler Ahrensburg, Germany). Image acquisition, synchronization, and mouse head rotation calculations were performed as described previously (<xref ref-type="bibr" rid="bib68">Wallace et al., 2013</xref>).</p></sec><sec id="s4-9"><title>Anatomical model</title><p>Head mount features and mouse anatomical features (medial canthi and nostril positions) were recorded at 50 Hz using four synchronized cameras (acA2040-90um, Basler cameras, Basler Ahrensburg, Germany) fitted with 25 mm focal length objectives (CCTV lens, Kowa Optical Products Co. Ltd, Japan) calibrated as described below. Cameras were positioned to provide images of the animal and headset from different angles to allow triangulation of the anatomical features (<xref ref-type="fig" rid="fig7">Figure 7D</xref>). During acquisition of the calibration images, the animal was illuminated with 12 IR-LED modules, (λ = 850 nm, Oslon Black PowerStar IR-LED module, ILH-IO01-85ML-SC201_WIR200, <ext-link ext-link-type="uri" xlink:href="https://i-led.co.uk/">i-led.co.uk</ext-link>, Berkshire, UK) run at 1 A. Position tracking LEDs, medial canthi, nares, mirror corner and camera chip corner positions were marked in two or more camera views, in multiple synchronized frames. Based on the triangulated positions of anatomical features, head cameras and position tracking LEDs the mouse’s eye position could be placed a common coordinate system.</p><p>To establish the animal’s horizontal plane from the head tracking LEDs, a position for the animal’s nose was first defined by averaging to 3D positions of the marked nostrils. A pre-forward vector was calculated using the direction between mean of eyes and nose and a pre-up vector as vector orthogonal to the pre-forward and vector between the eyes. Next, the left vector was defined as orthogonal to pre-forward and pre-up. Finally, the system was rotated by 40° around the left vector such that forward vector was elevated. This established a head-fixed forward-left-up coordinate system that was based on the bregma-lambda sagittal plane by tilting the eyes-nose plane by an angle of 40°.</p></sec><sec id="s4-10"><title>Interpolation</title><p>Head tracking frame rates were 200 Hz, while eye tracking cameras recorded at 60 Hz. Eye positions were consequently interpolated as follows: Let<disp-formula id="equ1"><mml:math id="m1"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>R</mml:mi><mml:mrow><mml:msub><mml:mi>t</mml:mi><mml:mn>1</mml:mn></mml:msub></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:mspace width="thinmathspace"/><mml:msub><mml:mi>R</mml:mi><mml:mrow><mml:msub><mml:mi>t</mml:mi><mml:mn>2</mml:mn></mml:msub></mml:mrow></mml:msub><mml:mo>∈</mml:mo><mml:mi>S</mml:mi><mml:mi>O</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mn>3</mml:mn><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mstyle></mml:math></disp-formula>be two rotations that transform the vector <inline-formula><mml:math id="inf1"><mml:msup><mml:mrow><mml:mfenced separators="|"><mml:mrow><mml:mn>0,0</mml:mn><mml:mo>,</mml:mo><mml:mo>-</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:mfenced></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msup></mml:math></inline-formula> into the gaze vectors <inline-formula><mml:math id="inf2"><mml:msub><mml:mrow><mml:mi>v</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:math></inline-formula>, <inline-formula><mml:math id="inf3"><mml:msub><mml:mrow><mml:mi>v</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi><mml:mn>2</mml:mn></mml:mrow></mml:msub></mml:math></inline-formula> in head fixed coordinates at times <inline-formula><mml:math id="inf4"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>t</mml:mi><mml:mn>1</mml:mn></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula>, <inline-formula><mml:math id="inf5"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>t</mml:mi><mml:mn>2</mml:mn></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula>. Then for a time <inline-formula><mml:math id="inf6"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msup><mml:mi>t</mml:mi><mml:mo>′</mml:mo></mml:msup></mml:mrow></mml:mstyle></mml:math></inline-formula> with<disp-formula id="equ2"><mml:math id="m2"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msup><mml:mi>t</mml:mi><mml:mrow><mml:mo>′</mml:mo></mml:mrow></mml:msup><mml:mo>=</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>+</mml:mo><mml:mi>s</mml:mi><mml:mo>⋅</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>t</mml:mi><mml:mn>2</mml:mn></mml:msub><mml:mo>−</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mn>1</mml:mn></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>,</mml:mo><mml:mspace width="1em"/><mml:mn>0</mml:mn><mml:mo>&lt;</mml:mo><mml:mi>s</mml:mi><mml:mo>&lt;</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:mstyle></mml:math></disp-formula>the corresponding rotation <inline-formula><mml:math id="inf7"><mml:msub><mml:mrow><mml:mi>R</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi><mml:mi>'</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> is interpolated such that <inline-formula><mml:math id="inf8"><mml:msub><mml:mrow><mml:mi>v</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi><mml:mi>'</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> is placed on the geodesic defined by <inline-formula><mml:math id="inf9"><mml:msub><mml:mrow><mml:mi>v</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:math></inline-formula>, <inline-formula><mml:math id="inf10"><mml:msub><mml:mrow><mml:mi>v</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi><mml:mn>2</mml:mn></mml:mrow></mml:msub></mml:math></inline-formula> with an angle of <inline-formula><mml:math id="inf11"><mml:mi>s</mml:mi><mml:mi>*</mml:mi><mml:mi/><mml:mi>∠</mml:mi><mml:mi/><mml:mo>(</mml:mo><mml:msub><mml:mrow><mml:mi>v</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>v</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:mo>)</mml:mo></mml:math></inline-formula> to <inline-formula><mml:math id="inf12"><mml:msub><mml:mrow><mml:mi>v</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:math></inline-formula>, and the rotation of a vector perpendicular to <inline-formula><mml:math id="inf13"><mml:msup><mml:mrow><mml:mo>(</mml:mo><mml:mn>0,0</mml:mn><mml:mo>,</mml:mo><mml:mo>-</mml:mo><mml:mn>1</mml:mn><mml:mo>)</mml:mo></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msup></mml:math></inline-formula> is continuous and uniform between <inline-formula><mml:math id="inf14"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>t</mml:mi><mml:mn>1</mml:mn></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula> and <inline-formula><mml:math id="inf15"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>t</mml:mi><mml:mn>2</mml:mn></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula>.</p></sec><sec id="s4-11"><title>Camera calibration</title><p>Overhead cameras for animal position and cricket tracking, were calibrated as previously described for the overhead cameras (<xref ref-type="bibr" rid="bib68">Wallace et al., 2013</xref>), with the addition of automated detection of corresponding points in the calibration images using openCV and the eye camera calibration performed as described in <xref ref-type="bibr" rid="bib68">Wallace et al., 2013</xref>.</p></sec><sec id="s4-12"><title>Pupil position and pupil torsion tracking</title><p>Pupil boundary tracking, compensation for eye image displacement, and gaze vector calculation was performed as described previously in <xref ref-type="bibr" rid="bib68">Wallace et al., 2013</xref>. Where contrast between pupil and iris was insufficient to allow automated pupil position tracking, pupil positions were manually tracked.</p><p>The TiO<sub>2</sub> spots for tracking ocular torsion were tracked manually in each image frame. Torsional rotations were determined based on the tracked TiO<sub>2</sub> spot positions as follows. Total rotation of the eye was defined as previously described in <xref ref-type="bibr" rid="bib68">Wallace et al., 2013</xref>, as:<disp-formula id="equ3"><mml:math id="m3"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>R</mml:mi><mml:mtext>eye</mml:mtext></mml:msub><mml:mo>=</mml:mo><mml:msub><mml:mi>R</mml:mi><mml:mrow><mml:mi>ϕ</mml:mi></mml:mrow></mml:msub><mml:msub><mml:mi>R</mml:mi><mml:mrow><mml:mi>θ</mml:mi></mml:mrow></mml:msub><mml:msub><mml:mi>R</mml:mi><mml:mrow><mml:mi>ψ</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math></disp-formula><disp-formula id="equ4"><mml:math id="m4"><mml:mi/><mml:mi/><mml:mi/><mml:mi/><mml:mi/><mml:mi/><mml:mi/><mml:mi/><mml:mi/><mml:mi/><mml:mi/><mml:mi/><mml:mo>=</mml:mo><mml:mi/><mml:mfenced close="]" open="[" separators="|"><mml:mrow><mml:mtable><mml:mtr><mml:mtd><mml:mn>1</mml:mn></mml:mtd><mml:mtd><mml:mn>0</mml:mn></mml:mtd><mml:mtd><mml:mn>0</mml:mn></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mn>0</mml:mn></mml:mtd><mml:mtd><mml:mrow><mml:mrow><mml:mi mathvariant="normal">cos</mml:mi></mml:mrow><mml:mo>⁡</mml:mo><mml:mrow><mml:mi>ϕ</mml:mi></mml:mrow></mml:mrow></mml:mtd><mml:mtd><mml:mo>-</mml:mo><mml:mrow><mml:mrow><mml:mi mathvariant="normal">sin</mml:mi></mml:mrow><mml:mo>⁡</mml:mo><mml:mrow><mml:mi>ϕ</mml:mi></mml:mrow></mml:mrow></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mn>0</mml:mn></mml:mtd><mml:mtd><mml:mrow><mml:mrow><mml:mi mathvariant="normal">sin</mml:mi></mml:mrow><mml:mo>⁡</mml:mo><mml:mrow><mml:mi>ϕ</mml:mi></mml:mrow></mml:mrow></mml:mtd><mml:mtd><mml:mrow><mml:mrow><mml:mi mathvariant="normal">cos</mml:mi></mml:mrow><mml:mo>⁡</mml:mo><mml:mrow><mml:mi>ϕ</mml:mi></mml:mrow></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:mfenced><mml:mi/><mml:mfenced close="]" open="[" separators="|"><mml:mrow><mml:mtable><mml:mtr><mml:mtd><mml:mrow><mml:mrow><mml:mi mathvariant="normal">cos</mml:mi></mml:mrow><mml:mo>⁡</mml:mo><mml:mrow><mml:mi>θ</mml:mi></mml:mrow></mml:mrow></mml:mtd><mml:mtd><mml:mn>0</mml:mn></mml:mtd><mml:mtd><mml:mrow><mml:mrow><mml:mo>-</mml:mo><mml:mi mathvariant="normal">sin</mml:mi></mml:mrow><mml:mo>⁡</mml:mo><mml:mrow><mml:mi>θ</mml:mi></mml:mrow></mml:mrow></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mn>0</mml:mn></mml:mtd><mml:mtd><mml:mn>1</mml:mn></mml:mtd><mml:mtd><mml:mn>0</mml:mn></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mrow><mml:mrow><mml:mi mathvariant="normal">sin</mml:mi></mml:mrow><mml:mo>⁡</mml:mo><mml:mrow><mml:mi>θ</mml:mi></mml:mrow></mml:mrow></mml:mtd><mml:mtd><mml:mn>0</mml:mn></mml:mtd><mml:mtd><mml:mrow><mml:mrow><mml:mi mathvariant="normal">cos</mml:mi></mml:mrow><mml:mo>⁡</mml:mo><mml:mrow><mml:mi>θ</mml:mi></mml:mrow></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:mfenced><mml:mfenced close="]" open="[" separators="|"><mml:mrow><mml:mtable><mml:mtr><mml:mtd><mml:mrow><mml:mrow><mml:mi mathvariant="normal">cos</mml:mi></mml:mrow><mml:mo>⁡</mml:mo><mml:mrow><mml:mi>ψ</mml:mi></mml:mrow></mml:mrow></mml:mtd><mml:mtd><mml:mo>-</mml:mo><mml:mrow><mml:mrow><mml:mi mathvariant="normal">sin</mml:mi></mml:mrow><mml:mo>⁡</mml:mo><mml:mrow><mml:mi>ψ</mml:mi></mml:mrow></mml:mrow></mml:mtd><mml:mtd><mml:mn>0</mml:mn></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mrow><mml:mrow><mml:mi mathvariant="normal">sin</mml:mi></mml:mrow><mml:mo>⁡</mml:mo><mml:mrow><mml:mi>ψ</mml:mi></mml:mrow></mml:mrow></mml:mtd><mml:mtd><mml:mrow><mml:mrow><mml:mi mathvariant="normal">cos</mml:mi></mml:mrow><mml:mo>⁡</mml:mo><mml:mrow><mml:mi>ψ</mml:mi></mml:mrow></mml:mrow></mml:mtd><mml:mtd><mml:mn>0</mml:mn></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mn>0</mml:mn></mml:mtd><mml:mtd><mml:mn>0</mml:mn></mml:mtd><mml:mtd><mml:mn>1</mml:mn></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:mfenced></mml:math></disp-formula>where <inline-formula><mml:math id="inf16"><mml:mi>ϕ</mml:mi></mml:math></inline-formula> = vertical, <inline-formula><mml:math id="inf17"><mml:mi>θ</mml:mi></mml:math></inline-formula> = horizontal and <inline-formula><mml:math id="inf18"><mml:mi>ψ</mml:mi></mml:math></inline-formula> = torsional rotations. The mouse’s gaze vector has the coordinates <inline-formula><mml:math id="inf19"><mml:msup><mml:mrow><mml:mfenced close="]" open="[" separators="|"><mml:mrow><mml:mtable><mml:mtr><mml:mtd><mml:mn>0</mml:mn></mml:mtd><mml:mtd><mml:mn>0</mml:mn></mml:mtd><mml:mtd><mml:mo>-</mml:mo><mml:mn>1</mml:mn></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:mfenced></mml:mrow><mml:mrow><mml:mi>T</mml:mi></mml:mrow></mml:msup></mml:math></inline-formula> for the reference position of the eye, and in each frame:<disp-formula id="equ5"><mml:math id="m5"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msup><mml:mi>v</mml:mi><mml:mtext>gaze</mml:mtext></mml:msup><mml:mo>=</mml:mo><mml:msub><mml:mi>R</mml:mi><mml:mtext>eye</mml:mtext></mml:msub><mml:mrow><mml:mo>[</mml:mo><mml:mtable columnspacing="1em" rowspacing="4pt"><mml:mtr><mml:mtd><mml:mn>0</mml:mn></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mn>0</mml:mn></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mtd></mml:mtr></mml:mtable><mml:mo>]</mml:mo></mml:mrow></mml:mrow></mml:mstyle></mml:math></disp-formula></p><p>With the eye in its reference position, we assume that the marked TiO<sub>2</sub> spot is located in the x-y plane of the eye camera (<xref ref-type="bibr" rid="bib68">Wallace et al., 2013</xref>). The anatomical location of this marked spot can then be described by two unknown parameters <inline-formula><mml:math id="inf20"><mml:mi>r</mml:mi></mml:math></inline-formula> (where r&gt;1 is the 3D distance of the eyeball surface to the eyeball center, and a distance of 1 describes the rotation radius of the pupil) and <inline-formula><mml:math id="inf21"><mml:mi>α</mml:mi></mml:math></inline-formula> is the fixed angle between the TiO<sub>2</sub> mark and the gaze vector. After eye rotation the 3D location of the TiO<sub>2</sub> is:<disp-formula id="equ6"><mml:math id="m6"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msup><mml:mi>v</mml:mi><mml:mtext>mark</mml:mtext></mml:msup><mml:mo>=</mml:mo><mml:msub><mml:mi>R</mml:mi><mml:mtext>eye</mml:mtext></mml:msub><mml:mrow><mml:mo>[</mml:mo><mml:mtable columnspacing="1em" rowspacing="4pt"><mml:mtr><mml:mtd><mml:mi>r</mml:mi><mml:mi>sin</mml:mi><mml:mo>⁡</mml:mo><mml:mi>α</mml:mi></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mn>0</mml:mn></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mo>−</mml:mo><mml:mi>r</mml:mi><mml:mi>cos</mml:mi><mml:mo>⁡</mml:mo><mml:mi>α</mml:mi></mml:mtd></mml:mtr></mml:mtable><mml:mo>]</mml:mo></mml:mrow></mml:mrow></mml:mstyle></mml:math></disp-formula>and the predicted pixel coordinates of the spot in the image are:<disp-formula id="equ7"><mml:math id="m7"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msup><mml:mrow><mml:mi>p</mml:mi></mml:mrow><mml:mtext>mark</mml:mtext></mml:msup><mml:mo>=</mml:mo><mml:mrow><mml:mo>[</mml:mo><mml:mtable columnspacing="1em" rowspacing="4pt"><mml:mtr><mml:mtd><mml:msub><mml:mi>a</mml:mi><mml:mtext>EC</mml:mtext></mml:msub></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:msub><mml:mi>b</mml:mi><mml:mtext>EC</mml:mtext></mml:msub></mml:mtd></mml:mtr></mml:mtable><mml:mo>]</mml:mo></mml:mrow><mml:mo>+</mml:mo><mml:mfrac><mml:mi>f</mml:mi><mml:msub><mml:mi>z</mml:mi><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msub></mml:mfrac><mml:mrow><mml:mo>[</mml:mo><mml:mtable columnspacing="1em" rowspacing="4pt"><mml:mtr><mml:mtd><mml:msubsup><mml:mi>v</mml:mi><mml:mrow><mml:mn>1</mml:mn></mml:mrow><mml:mtext>mark</mml:mtext></mml:msubsup></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:msubsup><mml:mi>v</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow><mml:mtext>mark</mml:mtext></mml:msubsup></mml:mtd></mml:mtr></mml:mtable><mml:mo>]</mml:mo></mml:mrow></mml:mrow></mml:mstyle></mml:math></disp-formula>where <inline-formula><mml:math id="inf22"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>a</mml:mi><mml:mtext>EC</mml:mtext></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula> and <inline-formula><mml:math id="inf23"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>b</mml:mi><mml:mtext>EC</mml:mtext></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula> are the location in the image of the center of the eye ball and <inline-formula><mml:math id="inf24"><mml:mfrac><mml:mrow><mml:mi>f</mml:mi></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>z</mml:mi></mml:mrow><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:mfrac></mml:math></inline-formula> a scaling factor, both of which are determined in the calibration procedure for pupil boundary tracking, described in full in <xref ref-type="bibr" rid="bib68">Wallace et al., 2013</xref>.</p><p>When <inline-formula><mml:math id="inf25"><mml:mi>r</mml:mi></mml:math></inline-formula> and <inline-formula><mml:math id="inf26"><mml:mi>α</mml:mi></mml:math></inline-formula> are known the value <inline-formula><mml:math id="inf27"><mml:mi>ψ</mml:mi></mml:math></inline-formula> can be determined. Using the Matlab function <bold>fminbnd</bold> the squared 2D distance<disp-formula id="equ8"><mml:math id="m8"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mrow><mml:mo>|</mml:mo><mml:mtable columnalign="center center" columnspacing="1em" rowspacing="4pt"><mml:mtr><mml:mtd><mml:msup><mml:mover><mml:mi>p</mml:mi><mml:mrow/></mml:mover><mml:mtext>mark</mml:mtext></mml:msup></mml:mtd><mml:mtd><mml:msup><mml:mi>p</mml:mi><mml:mtext>mark</mml:mtext></mml:msup></mml:mtd></mml:mtr></mml:mtable><mml:mo>|</mml:mo></mml:mrow><mml:mtable columnspacing="1em" rowspacing="4pt"><mml:mtr><mml:mtd><mml:mn>2</mml:mn></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mn>2</mml:mn></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:mstyle></mml:math></disp-formula>between the predicted and marked locations of the TiO<sub>2</sub> mark is minimized.</p><p>This method is used to determine the ocular torsion based on the TiO<sub>2</sub> spot location, both during and after calibration. Calibration was performed as follows:</p><p>For a given <inline-formula><mml:math id="inf28"><mml:mi>r</mml:mi></mml:math></inline-formula> and <inline-formula><mml:math id="inf29"><mml:mi>α</mml:mi></mml:math></inline-formula> choice, <inline-formula><mml:math id="inf30"><mml:mi>ψ</mml:mi></mml:math></inline-formula> can be calculated as above. The sum of square errors in pixel locations is then calculated over all frames. We optimized over <inline-formula><mml:math id="inf31"><mml:mi>r</mml:mi></mml:math></inline-formula> and <inline-formula><mml:math id="inf32"><mml:mi>α</mml:mi></mml:math></inline-formula> using the Matlab function <bold>fminsearch</bold>. To initialize <inline-formula><mml:math id="inf33"><mml:mi>r</mml:mi></mml:math></inline-formula>, we make use of the fact that the pupil model, <inline-formula><mml:math id="inf34"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msup><mml:mi>p</mml:mi><mml:mtext>mark</mml:mtext></mml:msup></mml:mrow></mml:mstyle></mml:math></inline-formula> and <inline-formula><mml:math id="inf35"><mml:mi>r</mml:mi></mml:math></inline-formula> together determine the 3D location of the mark <inline-formula><mml:math id="inf36"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msup><mml:mi>v</mml:mi><mml:mtext>mark</mml:mtext></mml:msup></mml:mrow></mml:mstyle></mml:math></inline-formula> in each image. For each frame, we first calculated:<disp-formula id="equ9"><mml:math id="m9"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mrow><mml:mi mathvariant="normal">Δ</mml:mi></mml:mrow><mml:mi>a</mml:mi><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:msubsup><mml:mi>p</mml:mi><mml:mrow><mml:mn>1</mml:mn></mml:mrow><mml:mtext>mark</mml:mtext></mml:msubsup><mml:mo>−</mml:mo><mml:msub><mml:mi>a</mml:mi><mml:mtext>EC</mml:mtext></mml:msub></mml:mrow><mml:mrow><mml:mi>f</mml:mi><mml:mrow><mml:mo>/</mml:mo></mml:mrow><mml:msub><mml:mi>z</mml:mi><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:mfrac></mml:mrow></mml:mstyle></mml:math></disp-formula><disp-formula id="equ10"><mml:math id="m10"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mrow><mml:mi mathvariant="normal">Δ</mml:mi></mml:mrow><mml:mi>b</mml:mi><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:msubsup><mml:mi>p</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow><mml:mtext>mark</mml:mtext></mml:msubsup><mml:mo>−</mml:mo><mml:msub><mml:mi>b</mml:mi><mml:mtext>EC</mml:mtext></mml:msub></mml:mrow><mml:mrow><mml:mi>f</mml:mi><mml:mrow><mml:mo>/</mml:mo></mml:mrow><mml:msub><mml:mi>z</mml:mi><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:mfrac></mml:mrow></mml:mstyle></mml:math></disp-formula><disp-formula id="equ11"><mml:math id="m11"><mml:mi>m</mml:mi><mml:mo>=</mml:mo><mml:mi/><mml:mrow><mml:mrow><mml:mi mathvariant="normal">min</mml:mi></mml:mrow><mml:mo>⁡</mml:mo><mml:mrow><mml:mfenced separators="|"><mml:mrow><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mfrac><mml:mrow><mml:mi>r</mml:mi></mml:mrow><mml:mrow><mml:msqrt><mml:mi mathvariant="normal">Δ</mml:mi><mml:msup><mml:mrow><mml:mi>a</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup><mml:mo>+</mml:mo><mml:mi/><mml:mi mathvariant="normal">Δ</mml:mi><mml:msup><mml:mrow><mml:mi>b</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:msqrt></mml:mrow></mml:mfrac></mml:mrow></mml:mfenced></mml:mrow></mml:mrow></mml:math></disp-formula><disp-formula id="equ12"><mml:math id="m12"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msubsup><mml:mi>v</mml:mi><mml:mtext>init</mml:mtext><mml:mtext>mark</mml:mtext></mml:msubsup><mml:mo>=</mml:mo><mml:mrow><mml:mo>[</mml:mo><mml:mtable columnspacing="1em" rowspacing="4pt"><mml:mtr><mml:mtd><mml:mi>m</mml:mi><mml:mrow><mml:mi mathvariant="normal">Δ</mml:mi></mml:mrow><mml:mi>a</mml:mi></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mi>m</mml:mi><mml:mrow><mml:mi mathvariant="normal">Δ</mml:mi></mml:mrow><mml:mi>b</mml:mi></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mo>−</mml:mo><mml:msqrt><mml:msup><mml:mi>r</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup><mml:mo>−</mml:mo><mml:msup><mml:mi>m</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mrow><mml:mi mathvariant="normal">Δ</mml:mi></mml:mrow><mml:msup><mml:mi>a</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup><mml:mo>+</mml:mo><mml:mrow><mml:mi mathvariant="normal">Δ</mml:mi></mml:mrow><mml:msup><mml:mi>b</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:msqrt></mml:mtd></mml:mtr></mml:mtable><mml:mo>]</mml:mo></mml:mrow></mml:mrow></mml:mstyle></mml:math></disp-formula><disp-formula id="equ13"><mml:math id="m13"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>α</mml:mi><mml:mtext>init</mml:mtext></mml:msub><mml:mo>=</mml:mo><mml:msup><mml:mi>cos</mml:mi><mml:mrow><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msup><mml:mo>⁡</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msup><mml:mi>v</mml:mi><mml:mtext>gaze</mml:mtext></mml:msup><mml:mo>.</mml:mo><mml:msubsup><mml:mi>v</mml:mi><mml:mtext>init</mml:mtext><mml:mtext>mark</mml:mtext></mml:msubsup><mml:mrow><mml:mo>/</mml:mo></mml:mrow><mml:mi>r</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mstyle></mml:math></disp-formula></p><p>Using this method, <inline-formula><mml:math id="inf37"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>α</mml:mi><mml:mtext>init</mml:mtext></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula> is estimated separately for each frame, and if the choice of <inline-formula><mml:math id="inf38"><mml:mi>r</mml:mi></mml:math></inline-formula> is correct then these values should agree. We can use <bold>fminbind</bold> to minimize the following with respect to <inline-formula><mml:math id="inf39"><mml:mi>r</mml:mi></mml:math></inline-formula>:<disp-formula id="equ14"><mml:math id="m14"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mrow><mml:mi mathvariant="normal">V</mml:mi><mml:mi mathvariant="normal">a</mml:mi><mml:mi mathvariant="normal">r</mml:mi></mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:msub><mml:mi>α</mml:mi><mml:mtext>init</mml:mtext></mml:msub><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mover><mml:msup><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>α</mml:mi><mml:mtext>init</mml:mtext></mml:msub><mml:mo>−</mml:mo><mml:mover><mml:msub><mml:mi>α</mml:mi><mml:mtext>init</mml:mtext></mml:msub><mml:mo accent="false">¯</mml:mo></mml:mover></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mn>2</mml:mn></mml:msup><mml:mo accent="false">¯</mml:mo></mml:mover></mml:mrow></mml:mstyle></mml:math></disp-formula></p><p>After <inline-formula><mml:math id="inf40"><mml:mi>r</mml:mi></mml:math></inline-formula> is initialized, <inline-formula><mml:math id="inf41"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>α</mml:mi><mml:mtext>init</mml:mtext></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula> is calculated, with <inline-formula><mml:math id="inf42"><mml:mi>α</mml:mi></mml:math></inline-formula> initialized using the mean over frames.</p><p>Torsional rotations were normalized by calculating a mean torsion value for the 0.01% of frames that were closest to both median pitch and roll of the head. Torsional values in other tracked frames were then normalized to this mean torsion value.</p></sec><sec id="s4-13"><title>Cricket position tracking</title><p>Cricket body positions were automatically tracked using the method and algorithm described for tracking eye corners, as described in the section ‘<italic>Compensation for lateral eyeball displacement – tracking of anatomical landmarks around the eye’</italic> in <xref ref-type="bibr" rid="bib68">Wallace et al., 2013</xref>. To increase the contrast between the region around the cricket in the image and the cricket, ~100 background image frames (in which neither mouse nor cricket was present) were averaged and subtracted from frames in which the cricket was present. In frames where automated cricket position tracking was not possible, frames were tracked manually. As the cameras used for cricket tracking had been calibrated along with the animal position tracking cameras (see above), the three-dimensional location of the cricket could be triangulated in a common coordinate system with the animal’s position.</p></sec><sec id="s4-14"><title>Classification of behavioral periods</title><p>To decrease the effects of tracking noise and rapid head rotations, mouse velocity, target bearing and inter-animal Euclidean distances were first filtered using a 50 ms sliding window Gaussian filter.</p><p>The criteria used to classify the different hunt phases were based on those described in <xref ref-type="bibr" rid="bib18">Hoy et al., 2016</xref>. In an initial step, behavioral end points (t<sub>end</sub>) for capture periods were identified by manual inspection of the tracking videos. Further identification of the behavioral start points (t<sub>start</sub>) and t<sub>end</sub> points for the different hunt sequence epochs were then identified as described below.</p><p>The t<sub>end</sub> points were defined as:</p><list list-type="order"><list-item><p>The t<sub>end</sub> point for a detect period was defined as the last frame before (1) Mouse head velocity in the direction of the cricket was &gt;= 20 cm/s, (2) The mouse’s bearing towards the cricket was constantly below 90° and (3) the Euclidean distance between the mouse and cricket was continuously decreasing.</p></list-item><list-item><p>The t<sub>end</sub> point for a tracking period was identified by locating local minima in the mouse-cricket Euclidean distance time plots, where local minima were defined as points at which the mouse came within a contact distance of 6 cm (measured from the tracked point on the mouse’s head, giving a &gt; 3 cm separation between the mouse’s nose and the cricket). These were followed either by a capture period (see below) or were followed by a ⩾ 5 cm increase in inter-animal Euclidean distance, which were defined as cricket escapes. In cases where the absolute value of the target bearing was &gt; 90° before the mouse turned towards the prey, the start of the tracking period was taken as the first frame in which the bearing to the target was &lt;90°. Only tracking periods, in which the initial Euclidean distance between the mouse and cricket was &gt;20 cm were analyzed.</p></list-item><list-item><p>The t<sub>end</sub> point for the capture period was taken to be the point 6 cm away from the cricket, following which a cricket captured and consumed.</p></list-item></list><p>The start points of the hunt epochs were defined as follows:</p><list list-type="order"><list-item><p>The t<sub>start</sub> for the detect period was the frame 500 ms prior to the detect t<sub>end</sub> point.</p></list-item><list-item><p>The t<sub>start</sub> for the tracking period was the first frame after the t<sub>end</sub> detect frame.</p></list-item><list-item><p>The t<sub>start</sub> for the capture period was either; (1) the first period in which the mouse approached the cricket and directly caught it, or (2) the first frame in which the mouse approached the cricket and all subsequent cricket escapes (prior to the final cricket capture) were less than 5 cm outside the contact zone (11 cm inter-animal Euclidean distance).</p></list-item></list><p>Cases in which the eye cameras were dislodged by the animal during the chase (n=4 hunt sequences) were included in the dataset up until the point where the cameras were dislodged.</p></sec><sec id="s4-15"><title>Target bearing</title><p>Target bearing was defined as the angle between the cricket position and the mouse’s forward head direction in the horizontal plane.</p></sec><sec id="s4-16"><title>Digital reconstruction of arena</title><p>For the digital reconstruction, the company 3dScanlab (Cologne, Germany) was engaged to create a complete scan, photo series and 3D mesh model of the arena and room, which they performed using an RTC 360 3D laser scanner (Leica, Germany). The 3D point cloud produced by the laser scanner was converted to a 3D mesh model, to which textures of the experiment arena obtained from photographs (Nikon D810, 36 Mpx) were baked.</p><p>The camera tracking coordinate system, in which the mouse and cricket positions were tracked, and the scanned coordinate system of the 3D mesh model were aligned based on 16 fiducial points which could be clearly identified in both tracking camera images and the scan. Crickets were modeled as 2 cm diameter, 1 cm thick disks centered on their tracked position with the disk's axis oriented parallel to gravity.</p></sec><sec id="s4-17"><title>Generation of animal’s eye view</title><p>Each eye was modeled as a hemisphere with a 180° field of view whose equator was perpendicular to the animal’s gaze vector. For the projection of the environment onto the cornea, frame-wise animal’s eye views for both eyes were created with custom written software in C++ (g++ 7.5.0, QMake 3.1, Qt 5.9.5, libopenexr 2.2.0, libpng 1.6.34 and OpenGL-core-profile 4.6.0) on a GeForce RTX 2070 (NVidia driver 450.66), using first cube mapping followed by a transformation into a spherical coordinate system. To do this, individual frame-wise coordinate transformations were made using the eye locations and orientations determined as described above to transform the mesh model of the arena and cricket to a static eye coordinate system using custom written vertex shaders to perform the coordinate transformation and the fragment shaders to texture the mesh. A cube-map (1024 x 1024 pixels per face) was created by performing such coordinate transformations for a 90 degree view in the direction of the optical axis of the eye and four mutually orthogonal directions. Custom written code was then used to transform the cube-map into a spherical coordinate system, with a 180 degree opening angle, using fragment shaders, resulting in a 1024 x 1024 pixel frame exported as png and OpenEXR files. In addition to the color map, maps of depth (pixel-wise object intersection distance), object identification, optic flow and 3D position of the object intersection point in the contralateral eye’s coordinate system were also generated.</p></sec><sec id="s4-18"><title>Prey image probability density maps</title><p>For generation of the prey image probability density maps, animal’s eye views were rendered that contained the cricket only (i.e. without inclusion of arena and room). Density maps from multiple detect-track sequences, and multiple animals, were made by averaging.</p></sec><sec id="s4-19"><title>Ocular alignment</title><p>Ocular alignment was defined as the consistency of the projection of a given point in the eye view of one eye into the other in an infinitely distant environment. This is equivalent to a projection in an idealized finite-distant spherical environment while assuming a distance between the animal’s eyes of 0. For calculation, the radius of the sphere can then be set to 1 (without loss of generality). A point, located at the center of mass of the functional focus in each eye, was chosen from which to calculate the degree of inter-ocular alignment. This point was projected from one eye to the sphere surface and into the contralateral eye. The degree of alignment between the two eyes was calculated as follows:</p><p>Let<disp-formula id="equ15"><mml:math id="m15"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>R</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:mspace width="thinmathspace"/><mml:msub><mml:mi>L</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>:</mml:mo><mml:msup><mml:mrow><mml:mi mathvariant="double-struck">R</mml:mi></mml:mrow><mml:mrow><mml:mn>3</mml:mn></mml:mrow></mml:msup><mml:mo stretchy="false">→</mml:mo><mml:msup><mml:mrow><mml:mi mathvariant="double-struck">R</mml:mi></mml:mrow><mml:mrow><mml:mn>3</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:mstyle></mml:math></disp-formula>be the affine transformations for the left and right eye, and let<disp-formula id="equ16"><mml:math id="m16"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>E</mml:mi><mml:mo>⊆</mml:mo><mml:msup><mml:mrow><mml:mi mathvariant="double-struck">R</mml:mi></mml:mrow><mml:mrow><mml:mn>3</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:mstyle></mml:math></disp-formula>be the idealized environment. For a given direction <inline-formula><mml:math id="inf43"><mml:mi>u</mml:mi><mml:mi/><mml:mo>∈</mml:mo><mml:mi>S</mml:mi></mml:math></inline-formula><sup>2</sup> we calculate the projection into the right eye <inline-formula><mml:math id="inf44"><mml:msub><mml:mrow><mml:mi>p</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>∈</mml:mo><mml:mi mathvariant="double-struck">R</mml:mi></mml:math></inline-formula><sup>3</sup> by:<disp-formula id="equ17"><mml:math id="m17"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>p</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:msubsup><mml:mi>L</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msubsup><mml:mo>∘</mml:mo><mml:msub><mml:mi>R</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>∘</mml:mo><mml:mi>u</mml:mi></mml:mrow></mml:mstyle></mml:math></disp-formula></p><p>The average alignment is then calculated using the formula:<disp-formula id="equ18"><mml:math id="m18"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mover><mml:mo movablelimits="false">∑</mml:mo><mml:mo accent="false">¯</mml:mo></mml:mover><mml:mn>2</mml:mn><mml:mo>⋅</mml:mo><mml:mi>arcsin</mml:mi><mml:mo>⁡</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mrow><mml:mo>|</mml:mo><mml:mrow><mml:msub><mml:mi>p</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>−</mml:mo><mml:mrow><mml:mo>⟨</mml:mo><mml:mrow><mml:mover><mml:mo movablelimits="false">∑</mml:mo><mml:mo accent="false">¯</mml:mo></mml:mover><mml:msub><mml:mi>p</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>⟩</mml:mo></mml:mrow></mml:mrow><mml:mo>|</mml:mo></mml:mrow><mml:mrow><mml:mo>/</mml:mo></mml:mrow><mml:mn>2</mml:mn></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mstyle></mml:math></disp-formula>where <inline-formula><mml:math id="inf45"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mover><mml:mo movablelimits="false">∑</mml:mo><mml:mo accent="false">¯</mml:mo></mml:mover><mml:msub><mml:mi>p</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula> denotes mean and <inline-formula><mml:math id="inf46"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mo fence="false" stretchy="false">⟨</mml:mo><mml:mo fence="false" stretchy="false">⟩</mml:mo></mml:mrow></mml:mstyle></mml:math></inline-formula> denotes normalization.</p></sec><sec id="s4-20"><title>Visual field overlap</title><p>Visual field overlap was analyzed in the idealized finite-distant spherical environment described above for ocular alignment. Visual overlap was calculated from the frame-wise maps of 3D object intersection points in the contralateral eye (see above section ‘<italic>Generation of animal’s eye view’</italic>) generated for the ocular alignment analysis: pixels whose 3D object intersection points had an angle of less than 90° to the optical axis were considered part of the overlapping field of view. Probability maps of overlap were calculated by averaging.</p><p>For analyses of the effect of freezing eye movements, eye rotations (horizontal, vertical, and torsional) were set to the mean rotation in one eye, and the effect quantified in the other eye view.</p></sec><sec id="s4-21"><title>Optic flow</title><p>To calculate the optic flow in a given pixel for a given eye, we consider the difference vector between the 3D positions in the static eye coordinate system of the object intersection point for this pixel one frame before and after the frame of interest, divided by <inline-formula><mml:math id="inf47"><mml:mn>2</mml:mn><mml:mo>∙</mml:mo><mml:mi>d</mml:mi><mml:mi>t</mml:mi><mml:mi/></mml:math></inline-formula> and mapped to unit distance by dividing by the distance between eye and interception point. This yields a 3D motion vector which is independent of influences of the frame rate and rendering resolution. The spherical projection used in the rendering process described above is a non-conformal, locally non-isometric map, meaning that angles between lines and distances between points are not preserved. This makes it necessary to evaluate the flow in each point in a local, orthonormal 3D coordinate system defined by the direction vector between the eye position and the object intersection point and derivative vectors along the angular coordinates <inline-formula><mml:math id="inf48"><mml:mi>v</mml:mi><mml:mi>θ</mml:mi></mml:math></inline-formula> and <inline-formula><mml:math id="inf49"><mml:mi>v</mml:mi><mml:mi>φ</mml:mi></mml:math></inline-formula> at that point. Thus, we define the 2D flow at a given point as the orthogonal projection of the 3D flow vector onto the local plane spanned by <inline-formula><mml:math id="inf50"><mml:mi>v</mml:mi><mml:mi>θ</mml:mi></mml:math></inline-formula> and <inline-formula><mml:math id="inf51"><mml:mi>v</mml:mi><mml:mi>φ</mml:mi></mml:math></inline-formula>. In this study, we only use the first two components of the vector, while the third component contains the motion in radial direction to the eye.</p><p>In <xref ref-type="fig" rid="fig5">Figure 5C</xref>, optic flow was calculated for the animal in the idealized spherical environment described above, meaning the animal’s head was equidistant to the surrounding at all points. This simplified scene was characterized as follows. Let<disp-formula id="equ19"><mml:math id="m19"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>h</mml:mi><mml:mo>∈</mml:mo><mml:msup><mml:mrow><mml:mi mathvariant="double-struck">R</mml:mi></mml:mrow><mml:mrow><mml:mn>3</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:mstyle></mml:math></disp-formula>be the coordinate of the center of the mouse’s head, then the scene around it was defined as<disp-formula id="equ20"><mml:math id="m20"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mrow><mml:mo>{</mml:mo><mml:mrow><mml:mi>p</mml:mi><mml:mo>∈</mml:mo><mml:msup><mml:mrow><mml:mi mathvariant="double-struck">R</mml:mi></mml:mrow><mml:mrow><mml:mn>3</mml:mn></mml:mrow></mml:msup><mml:mspace width="thinmathspace"/><mml:mrow><mml:mo maxsize="1.2em" minsize="1.2em">|</mml:mo></mml:mrow><mml:mspace width="thinmathspace"/><mml:mrow><mml:mo>|</mml:mo><mml:mrow><mml:mi>p</mml:mi><mml:mo>−</mml:mo><mml:mi>h</mml:mi></mml:mrow><mml:mo>|</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mi>r</mml:mi></mml:mrow><mml:mo>}</mml:mo></mml:mrow></mml:mrow></mml:mstyle></mml:math></disp-formula>with r = 50 cm. For optic flow calculations, the sphere is considered fixed in global coordinates, and the flow is evaluated at the point where the mouse is in the center of the sphere translating forward at a speed of 1 cm/s.</p><p>In <xref ref-type="fig" rid="fig5">Figure 5E</xref>, optic flow was calculated with the animal in the digitally reconstructed environment (see above).</p></sec><sec id="s4-22"><title>Coloring of optic flow poles in mouse corneal views</title><p>The points in the scatter plot of optic flow poles in mouse corneal views were color-coded for the density of neighboring points using a two-dimensional Gaussian smoother with standard deviation<disp-formula id="equ21"><mml:math id="m21"><mml:mi>σ</mml:mi><mml:mo>=</mml:mo><mml:mi/><mml:mfrac><mml:mrow><mml:mn>2</mml:mn><mml:mi>π</mml:mi></mml:mrow><mml:mrow><mml:mn>180</mml:mn></mml:mrow></mml:mfrac></mml:math></disp-formula></p><p>For a given point, the density was calculated as:<disp-formula id="equ22"><mml:math id="m22"><mml:msub><mml:mrow><mml:mi>s</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mi/><mml:mrow><mml:munder><mml:mo>∑</mml:mo><mml:mrow><mml:mi>j</mml:mi><mml:mo>∈</mml:mo><mml:mi>F</mml:mi></mml:mrow></mml:munder><mml:mrow><mml:mfrac><mml:mrow><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mn>2</mml:mn><mml:mi>π</mml:mi><mml:msup><mml:mrow><mml:mi>σ</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:mfrac><mml:mrow><mml:mrow><mml:mi mathvariant="normal">exp</mml:mi></mml:mrow><mml:mo>⁡</mml:mo><mml:mrow><mml:mfenced separators="|"><mml:mrow><mml:mfrac><mml:mrow><mml:msup><mml:mrow><mml:mo>-</mml:mo><mml:mfenced close="|" open="|" separators="|"><mml:mrow><mml:msub><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>-</mml:mo><mml:msub><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfenced></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:mrow><mml:mrow><mml:mn>2</mml:mn><mml:mo>∙</mml:mo><mml:msup><mml:mrow><mml:mi>σ</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:mfrac></mml:mrow></mml:mfenced></mml:mrow></mml:mrow><mml:mo>/</mml:mo><mml:mo>|</mml:mo><mml:mi>F</mml:mi><mml:mo>|</mml:mo></mml:mrow></mml:mrow></mml:math></disp-formula>where <inline-formula><mml:math id="inf52"><mml:mi>F</mml:mi></mml:math></inline-formula> is the set of all considered frame indices, and<disp-formula id="equ23"><mml:math id="m23"><mml:msub><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mi/><mml:mfrac><mml:mrow><mml:msub><mml:mrow><mml:mo>∂</mml:mo></mml:mrow><mml:mrow><mml:mi>h</mml:mi></mml:mrow></mml:msub><mml:msub><mml:mrow><mml:mfenced close="]" open="[" separators="|"><mml:mrow><mml:mi>p</mml:mi></mml:mrow></mml:mfenced></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mi/><mml:mi/><mml:mi/><mml:mi/><mml:mi/><mml:mi/></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:mfenced close="|" open="|" separators="|"><mml:mrow><mml:msub><mml:mrow><mml:mo>∂</mml:mo></mml:mrow><mml:mrow><mml:mi>h</mml:mi></mml:mrow></mml:msub><mml:msub><mml:mrow><mml:mfenced close="]" open="[" separators="|"><mml:mrow><mml:mi>p</mml:mi></mml:mrow></mml:mfenced></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mi/></mml:mrow></mml:msub></mml:mrow></mml:mfenced></mml:mrow></mml:mfrac></mml:math></disp-formula>where <inline-formula><mml:math id="inf53"><mml:msub><mml:mrow><mml:mo>∂</mml:mo></mml:mrow><mml:mrow><mml:mi>h</mml:mi></mml:mrow></mml:msub><mml:msub><mml:mrow><mml:mo>[</mml:mo><mml:mi>p</mml:mi><mml:mo>]</mml:mo></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mi/><mml:mi/></mml:mrow></mml:msub></mml:math></inline-formula> is the discrete central difference quotient of the mouse’s eye trajectory <italic>p</italic> in frame <italic>i,</italic> in the coordinate system of the respective eye, evaluated over h=4 frames.</p></sec><sec id="s4-23"><title>Mouse eye model</title><p>When constructing the eye model, we took experimentally determined values from <xref ref-type="bibr" rid="bib4">Barathi et al., 2008</xref> (see <xref ref-type="table" rid="table1">Table 1</xref>). While we recognize that this study employed a different strain of mice to the one used here, the methodology used provides estimates of physical and optical parameters measured under conditions closest to those relevant for the current study. Further, variation of these parameters was not found to change the model to an extent that would influence the conclusions drawn from analyses involving the eye model (see below). These values distinctly define the spatial shapes and positions of the refractive components of the model eye (<xref ref-type="fig" rid="fig3">Figure 3A</xref>), as well as refractive indices for all but the lens, <inline-formula><mml:math id="inf54"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>n</mml:mi><mml:mtext>lens</mml:mtext></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula>. We further assume a pupil radius of 594 µm, which is the mean of constricted and dilated mouse pupil sizes from <xref ref-type="bibr" rid="bib46">Pennesi et al., 1998</xref>. We define the focal point of a bundle of rays as the point with minimal least squares distance to the rays. To optimize the missing refractive index <inline-formula><mml:math id="inf55"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>n</mml:mi><mml:mtext>lens</mml:mtext></mml:msub><mml:mo>:</mml:mo><mml:mrow><mml:mi mathvariant="normal">Ω</mml:mi></mml:mrow><mml:mo stretchy="false">→</mml:mo><mml:msup><mml:mrow><mml:mi mathvariant="double-struck">R</mml:mi></mml:mrow><mml:mrow><mml:mo>+</mml:mo></mml:mrow></mml:msup></mml:mrow></mml:mstyle></mml:math></inline-formula> inside the lens body <inline-formula><mml:math id="inf56"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mrow><mml:mi mathvariant="normal">Ω</mml:mi></mml:mrow><mml:mo>⊂</mml:mo><mml:msup><mml:mrow><mml:mi mathvariant="double-struck">R</mml:mi></mml:mrow><mml:mrow><mml:mn>3</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:mstyle></mml:math></inline-formula>, we first calculated two lens models and optimized them such that the focal point of 10000 rays emitted from an object at 10 cm distance on the optical axis lay on the retina. The first model, for optimization of the lens surface, was derived with optimal constant refractive index <inline-formula><mml:math id="inf57"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>n</mml:mi><mml:mtext>c</mml:mtext></mml:msub><mml:mo>∈</mml:mo><mml:msup><mml:mrow><mml:mi mathvariant="double-struck">R</mml:mi></mml:mrow><mml:mrow><mml:mo>+</mml:mo></mml:mrow></mml:msup></mml:mrow></mml:mstyle></mml:math></inline-formula> over the volume. The second model, for lens gradient optimization, was derived with a smooth transition of refractive index to the anterior and posterior lens boundary, that is, <inline-formula><mml:math id="inf58"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>n</mml:mi><mml:mtext>b</mml:mtext></mml:msub><mml:mo>=</mml:mo><mml:mn>1.333</mml:mn></mml:mrow></mml:mstyle></mml:math></inline-formula> on <inline-formula><mml:math id="inf59"><mml:mo>∂</mml:mo><mml:mi mathvariant="normal">Ω</mml:mi></mml:math></inline-formula>. We then used Poisson’s equation <inline-formula><mml:math id="inf60"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>δ</mml:mi><mml:msub><mml:mi>n</mml:mi><mml:mtext>g</mml:mtext></mml:msub><mml:mo>=</mml:mo><mml:mi>c</mml:mi></mml:mrow></mml:mstyle></mml:math></inline-formula>, and optimized the strength of the gradient <inline-formula><mml:math id="inf61"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>c</mml:mi><mml:mo>∈</mml:mo><mml:msup><mml:mrow><mml:mi mathvariant="double-struck">R</mml:mi></mml:mrow><mml:mrow><mml:mo>+</mml:mo></mml:mrow></mml:msup></mml:mrow></mml:mstyle></mml:math></inline-formula>. We assumed the final lens model as a linear combination of these two models:<disp-formula id="equ24"><mml:math id="m24"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>n</mml:mi><mml:mtext>lens</mml:mtext></mml:msub><mml:mo>=</mml:mo><mml:mrow><mml:mi>α</mml:mi></mml:mrow><mml:mo>⋅</mml:mo><mml:msub><mml:mi>n</mml:mi><mml:mtext>c</mml:mtext></mml:msub><mml:mo>+</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:mrow><mml:mi>α</mml:mi></mml:mrow></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>⋅</mml:mo><mml:msub><mml:mi>n</mml:mi><mml:mtext>g</mml:mtext></mml:msub></mml:mrow></mml:mstyle></mml:math></disp-formula>with <inline-formula><mml:math id="inf62"><mml:mi>α</mml:mi><mml:mi/><mml:mo>∈</mml:mo><mml:mi/><mml:mfenced close="]" open="[" separators="|"><mml:mrow><mml:mn>0,1</mml:mn></mml:mrow></mml:mfenced></mml:math></inline-formula>, where we optimized <inline-formula><mml:math id="inf63"><mml:mi>α</mml:mi></mml:math></inline-formula> as described for the above models, but from a point 10 cm away and 45° off optical axis. The derived refractive indices (<xref ref-type="table" rid="table2">Table 2</xref>) were within the range measured in <xref ref-type="bibr" rid="bib8">Cheng et al., 2019</xref>.</p><p>To test the sensitivity of the model to changes in assumed physical parameters, we systematically changed the radius of curvatures listed in <xref ref-type="table" rid="table1">Table 1</xref>, and the thickness listed in <xref ref-type="table" rid="table2">Table 2</xref> by 10, 50, and 100 µm (several different values were used, to check the linearity of the dependence). We calculated the propagation of uncertainty through the eye model by analyzing the variation of radial elevation on the retina of the 45 rays (above), taking the numerical differentiation of each input variable that was used in the model. Lens optimization was performed for each newly generated eye model (as described above). The maximum deviations were 0.4, 1.38 and 2.76 degrees for the 10, 50, and 100 µm changes, respectively (<xref ref-type="fig" rid="fig7">Figure 7E</xref>), and overall, none of the observed effects on the model would influence the conclusions drawn from the analyses performed using the eye model.</p></sec><sec id="s4-24"><title>Projection from retina to cornea</title><p>The refractive elements in the rodent eye do not behave like ideally corrected optical elements, with the result that there is a distribution of incident rays with slightly varying angles of incidence on the cornea which converge on any given point on the retina. Projection from retina to cornea therefore requires an estimate of the distribution of outside world angles of incidence for any point of interest on the retina. To do this, we used a Monte-Carlo simulation to back-trace through the optics a set of randomly chosen rays emerging from the point of interest on the retina. Since the intensity of light on a surface with an incoming angle of θ is proportional to <inline-formula><mml:math id="inf64"><mml:mrow><mml:mrow><mml:mi mathvariant="normal">cos</mml:mi></mml:mrow><mml:mo>⁡</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mi>θ</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula>, this function was also chosen for the probability density distribution of ray exit angles. The rays were then traced until they either hit any opaque surface, resulting in the affected ray being discarded, or passed through the anterior cornea, in which case the ray was accepted and its angle added to the distribution of passing exit angles for the respective point on the retina.</p><p>Refraction on boundary layers between different indices of refraction was performed analytically according to Snell’s law. In volumes with a continuous variable refractive index (i.e. gradient-index (GRIN) optics), we used a finite-elements model. We first discretized the lens as a 40x40x40 lattice of side length 2.4 mm. We then started from initial conditions where s(0) is the point of incidence and v(0) is the vector of incidence multiplied by the speed of light c. The subsequent discrete trajectory and direction of propagation is then calculated step-wise according to<disp-formula id="equ25"><mml:math id="m25"><mml:mi>s</mml:mi><mml:mfenced separators="|"><mml:mrow><mml:msub><mml:mrow><mml:mi>t</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:mfenced><mml:mi/><mml:mo>:</mml:mo><mml:mo>=</mml:mo><mml:mi>s</mml:mi><mml:mfenced separators="|"><mml:mrow><mml:msub><mml:mrow><mml:mi>t</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfenced><mml:mo>+</mml:mo><mml:mi/><mml:mi>υ</mml:mi><mml:mo>(</mml:mo><mml:msub><mml:mrow><mml:mi>t</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>)</mml:mo><mml:mo>∙</mml:mo><mml:mo>(</mml:mo><mml:msub><mml:mrow><mml:mi>t</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>-</mml:mo><mml:msub><mml:mrow><mml:mi>t</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>)</mml:mo></mml:math></disp-formula><disp-formula id="equ26"><mml:math id="m26"><mml:mover accent="true"><mml:mrow><mml:mi>υ</mml:mi></mml:mrow><mml:mo>~</mml:mo></mml:mover><mml:mfenced separators="|"><mml:mrow><mml:msub><mml:mrow><mml:mi>t</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:mfenced><mml:mi/><mml:mo>:</mml:mo><mml:mo>=</mml:mo><mml:mi/><mml:mover accent="true"><mml:mrow><mml:mi>υ</mml:mi></mml:mrow><mml:mo>~</mml:mo></mml:mover><mml:mfenced separators="|"><mml:mrow><mml:msub><mml:mrow><mml:mi>t</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfenced><mml:mo>+</mml:mo><mml:mo>∇</mml:mo><mml:mrow><mml:mrow><mml:mi mathvariant="normal">log</mml:mi></mml:mrow><mml:mo>⁡</mml:mo><mml:mrow><mml:mi>n</mml:mi><mml:mfenced separators="|"><mml:mrow><mml:mi>s</mml:mi><mml:mfenced separators="|"><mml:mrow><mml:msub><mml:mrow><mml:mi>t</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:mfenced></mml:mrow></mml:mfenced><mml:mo>∙</mml:mo></mml:mrow></mml:mrow><mml:mo>(</mml:mo><mml:msub><mml:mrow><mml:mi>t</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>-</mml:mo><mml:mi/><mml:msub><mml:mrow><mml:mi>t</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>)</mml:mo></mml:math></disp-formula><disp-formula id="equ27"><mml:math id="m27"><mml:mi>υ</mml:mi><mml:mfenced separators="|"><mml:mrow><mml:msub><mml:mrow><mml:mi>t</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfenced><mml:mi/><mml:mo>∶</mml:mo><mml:mo>=</mml:mo><mml:mi/><mml:mfrac><mml:mrow><mml:mover accent="true"><mml:mrow><mml:mi>υ</mml:mi></mml:mrow><mml:mo>~</mml:mo></mml:mover><mml:mfenced separators="|"><mml:mrow><mml:msub><mml:mrow><mml:mi>t</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfenced></mml:mrow><mml:mrow><mml:msup><mml:mrow><mml:mo>|</mml:mo><mml:mover accent="true"><mml:mrow><mml:mi>υ</mml:mi></mml:mrow><mml:mo>~</mml:mo></mml:mover><mml:mfenced separators="|"><mml:mrow><mml:msub><mml:mrow><mml:mi>t</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfenced><mml:mo>|</mml:mo></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:mfrac></mml:math></disp-formula></p><p>The gradient is calculated in the lens lattice as the three-dimensional difference quotient, and then trilinearly interpolated to the exact position <inline-formula><mml:math id="inf65"><mml:mi>s</mml:mi><mml:mfenced separators="|"><mml:mrow><mml:msub><mml:mrow><mml:mi>t</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfenced></mml:math></inline-formula> of the ray.</p></sec><sec id="s4-25"><title>Projection of retinal ganglion cell density contours onto the model eye cornea</title><p>To determine the corneal location corresponding to the histologically identified retinal specialization in the mouse, isodensity lines were redrawn from <xref ref-type="bibr" rid="bib12">Dräger and Olsen, 1980</xref> in Illustrator and digitized using Matlab. Isodensity lines enclosing regions containing the highest and second highest density of retinal ganglion cells, as well as the optic disc and outline of the retinal whole mount, were redrawn directly from Figure 3A in <xref ref-type="bibr" rid="bib13">Dräger and Olsen, 1981</xref>, with horizontal being taken as horizontal (nasal-temporal) in the figure. The isodensity lines were scaled to match the eye diameter used for model eye, then placed into the model eye such that the center of mass of the optic disc reconstructed with the retinal ganglion cell contours was coincident with the intersection of the optic axis and retina in the eye model (<xref ref-type="fig" rid="fig2s1">Figure 2—figure supplement 1A-C</xref>). As the eye model was rotationally symmetrical, no further alignment between the histology and eye model was necessary. The high retinal ganglion cell density regions were then back-projected from retina to cornea as described above (<xref ref-type="fig" rid="fig2s1">Figure 2—figure supplement 1D-E</xref>).</p></sec><sec id="s4-26"><title>Eye in head coordinates</title><p>To quantify the effect of head rotations on VOR evoked eye movements in a common coordinate system, head rotations were normalized such that the average pitch and roll were 0. Axes were labeled X and Y respectively and eye rotations were represented using this horizon-aligned X-Y coordinate system. Positive head X values indicate head pitched up, while negative head X values indicate head pitched down. Negative head Y values indicate roll left, while positive Y values indicate roll right. Comparisons of the relationship between head and eye rotations were carried out using differential rotations between frame and average pose, defined in the following way:<disp-formula id="equ28"><mml:math id="m28"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msup><mml:mrow><mml:mi mathvariant="normal">l</mml:mi></mml:mrow><mml:mrow><mml:mrow><mml:mo>′</mml:mo></mml:mrow></mml:mrow></mml:msup><mml:mo>:</mml:mo><mml:mrow><mml:mi mathvariant="normal">L</mml:mi></mml:mrow><mml:mo stretchy="false">→</mml:mo><mml:mrow><mml:mi mathvariant="normal">G</mml:mi></mml:mrow><mml:mo>,</mml:mo><mml:msup><mml:mrow><mml:mi mathvariant="normal">r</mml:mi></mml:mrow><mml:mrow><mml:mrow><mml:mo>′</mml:mo></mml:mrow></mml:mrow></mml:msup><mml:mo>:</mml:mo><mml:mrow><mml:mi mathvariant="normal">R</mml:mi></mml:mrow><mml:mo stretchy="false">→</mml:mo><mml:mrow><mml:mi mathvariant="normal">G</mml:mi></mml:mrow><mml:mo>,</mml:mo><mml:mrow><mml:mi mathvariant="normal">h</mml:mi></mml:mrow><mml:mo>:</mml:mo><mml:mrow><mml:mi mathvariant="normal">H</mml:mi></mml:mrow><mml:mo stretchy="false">→</mml:mo><mml:mrow><mml:mi mathvariant="normal">G</mml:mi></mml:mrow></mml:mrow></mml:mstyle></mml:math></disp-formula>are the affine transformations between Cartesian global coordinate system <inline-formula><mml:math id="inf66"><mml:mi mathvariant="normal">G</mml:mi></mml:math></inline-formula>, head-fixed coordinate system <inline-formula><mml:math id="inf67"><mml:mi mathvariant="normal">H</mml:mi></mml:math></inline-formula> and left/right-eye coordiante systems <inline-formula><mml:math id="inf68"><mml:mi mathvariant="normal">L</mml:mi></mml:math></inline-formula>/<inline-formula><mml:math id="inf69"><mml:mi mathvariant="normal">R</mml:mi></mml:math></inline-formula>.</p><p>The transformations from <inline-formula><mml:math id="inf70"><mml:mi mathvariant="normal">L</mml:mi></mml:math></inline-formula>/<inline-formula><mml:math id="inf71"><mml:mi mathvariant="normal">R</mml:mi></mml:math></inline-formula> respectively to <inline-formula><mml:math id="inf72"><mml:mi mathvariant="normal"/><mml:mi mathvariant="normal">H</mml:mi></mml:math></inline-formula> are:<disp-formula id="equ29"><mml:math id="m29"><mml:mi mathvariant="normal">l</mml:mi><mml:mi/><mml:mo>=</mml:mo><mml:mi/><mml:msup><mml:mrow><mml:mi mathvariant="normal">h</mml:mi></mml:mrow><mml:mrow><mml:mo>-</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msup><mml:mi/><mml:mo>∙</mml:mo><mml:mi mathvariant="normal">l</mml:mi><mml:mi>'</mml:mi></mml:math></disp-formula><disp-formula id="equ30"><mml:math id="m30"><mml:mi mathvariant="normal">r</mml:mi><mml:mi/><mml:mo>=</mml:mo><mml:mi/><mml:msup><mml:mrow><mml:mi mathvariant="normal">h</mml:mi></mml:mrow><mml:mrow><mml:mo>-</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msup><mml:mi/><mml:mo>∙</mml:mo><mml:mi mathvariant="normal">r</mml:mi><mml:mi>'</mml:mi></mml:math></disp-formula></p><p>We calculate the left and right eye differential rotations as:<disp-formula id="equ31"><mml:math id="m31"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="normal">l</mml:mi></mml:mrow><mml:mtext>delta</mml:mtext></mml:msub><mml:mo>=</mml:mo><mml:mrow><mml:mi mathvariant="normal">l</mml:mi></mml:mrow><mml:mo>⋅</mml:mo><mml:msup><mml:mrow><mml:mover><mml:mrow><mml:mi mathvariant="normal">l</mml:mi></mml:mrow><mml:mo stretchy="false">¯</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:mstyle></mml:math></disp-formula><disp-formula id="equ32"><mml:math id="m32"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="normal">r</mml:mi></mml:mrow><mml:mtext>delta</mml:mtext></mml:msub><mml:mo>=</mml:mo><mml:mrow><mml:mi mathvariant="normal">r</mml:mi></mml:mrow><mml:mo>⋅</mml:mo><mml:msup><mml:mrow><mml:mover><mml:mrow><mml:mi mathvariant="normal">r</mml:mi></mml:mrow><mml:mo stretchy="false">¯</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:mstyle></mml:math></disp-formula>where <inline-formula><mml:math id="inf73"><mml:mover accent="false"><mml:mrow><mml:mi mathvariant="normal">l</mml:mi></mml:mrow><mml:mo>¯</mml:mo></mml:mover></mml:math></inline-formula> and <inline-formula><mml:math id="inf74"><mml:mover accent="false"><mml:mrow><mml:mi mathvariant="normal">r</mml:mi></mml:mrow><mml:mo>¯</mml:mo></mml:mover></mml:math></inline-formula> denote the average transformations over all frames (chordal L2 mean, implementation from SciPy 1.4.1).</p></sec><sec id="s4-27"><title>Statistical analysis</title><p>Within one experimental trial, the experimentally measured variables of interest are highly correlated with each other. This fact prevents us from using standard statistical tests on the whole time-trace to establish if any difference we observed in the data across different experimental conditions are significant or not, as one requirement of these kind on tests is that the samples from the populations being compared are independent of each other. However, we realized that trial-to-trial variability is the dominant source of variability in the data, whereas within-trial variability explains a smaller fraction of the total variance observed (a more detailed report is found in <xref ref-type="table" rid="table4">Table 4</xref>). For this reason, we decided to represent each temporal trace by its median value. We used the median and not the mean, because the former is more resistant to the presence of outliers and it is better suited to represent the ‘average’ value of a variable in this context. This operation reduced the size of the dataset to one data points per trial, which we can reasonably assume to be independent of each other.</p></sec></sec></body><back><ack id="ack"><title>Acknowledgements</title><p>We thank Michael Bräuer, Rolf Honnef, Michael Straussfeld and Bernd Scheiding from the mechanical workshop for fabrication of the setup components. Arne Monsees and Florian Franzen for providing a version of the OpenCV based camera calibration software and Arne Monsees for helping with some aspects of the camera calibration. We also thank Samuel Akorli, Nada Eiadeh, Dennis Franzke, Julia Mauz, Kristina Mendeliene, Anastasia Nychyporchuk and Iftekha Hasan Siraje for assistance with pupil, head and cricket position tracking.</p></ack><sec id="s5" sec-type="additional-information"><title>Additional information</title><fn-group content-type="competing-interest"><title>Competing interests</title><fn fn-type="COI-statement" id="conf1"><p>No competing interests declared</p></fn></fn-group><fn-group content-type="author-contribution"><title>Author contributions</title><fn fn-type="con" id="con1"><p>Formal analysis, Validation, Investigation, Visualization, Methodology, Writing - original draft</p></fn><fn fn-type="con" id="con2"><p>Software, Formal analysis, Validation, Visualization, Methodology</p></fn><fn fn-type="con" id="con3"><p>Software, Formal analysis, Supervision, Investigation, Visualization, Methodology, Writing - original draft, Writing - review and editing</p></fn><fn fn-type="con" id="con4"><p>Software, Formal analysis, Supervision, Writing - original draft, Writing - review and editing</p></fn><fn fn-type="con" id="con5"><p>Resources, Writing - review and editing</p></fn><fn fn-type="con" id="con6"><p>Resources, Investigation</p></fn><fn fn-type="con" id="con7"><p>Formal analysis, Writing - review and editing</p></fn><fn fn-type="con" id="con8"><p>Conceptualization, Supervision, Funding acquisition, Visualization, Writing - original draft, Project administration, Writing - review and editing</p></fn></fn-group><fn-group content-type="ethics-information"><title>Ethics</title><fn fn-type="other" id="fn1"><p>Animal experimentation: Experiments were carried out in accordance with protocols approved by the local animal welfare authorities (Landesamt für Natur Umwelt und Verbraucherschutz, Nordrhein-Westfalen, Germany, protocol number 84-02.04.2017.A260). Experiments were carried out using male C57Bl/6JCrl mice acquired from Charles River Laboratories.</p></fn></fn-group></sec><sec id="s6" sec-type="supplementary-material"><title>Additional files</title><supplementary-material id="transrepform"><label>Transparent reporting form</label><media mime-subtype="docx" mimetype="application" xlink:href="elife-70838-transrepform-v1.docx"/></supplementary-material></sec><sec id="s7" sec-type="data-availability"><title>Data availability</title><p>The mouse and cricket tracking data and resources for generating the reconstructed eye views are available on Dryad with DOI: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.5061/dryad.2z34tmpnc">https://doi.org/10.5061/dryad.2z34tmpnc</ext-link>.</p><p>The following dataset was generated:</p><p><element-citation id="dataset1" publication-type="data" specific-use="isSupplementedBy"><person-group person-group-type="author"><name><surname>Holmgren</surname><given-names>C</given-names></name><name><surname>Stahr</surname><given-names>P</given-names></name><name><surname>Wallace</surname><given-names>D</given-names></name><name><surname>Voit</surname><given-names>K</given-names></name><name><surname>Matheson</surname><given-names>E</given-names></name><name><surname>Sawinski</surname><given-names>J</given-names></name><name><surname>Bassetto</surname><given-names>G</given-names></name><name><surname>Kerr</surname><given-names>J</given-names></name></person-group><year iso-8601-date="2021">2021</year><data-title>Visual pursuit behavior in mice maintains the pursued prey on the retinal region with least optic flow</data-title><source>Dryad Digital Repository</source><pub-id assigning-authority="Dryad" pub-id-type="doi">10.5061/dryad.2z34tmpnc</pub-id></element-citation></p></sec><ref-list><title>References</title><ref id="bib1"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Angelaki</surname> <given-names>DE</given-names></name><name><surname>Hess</surname> <given-names>BJ</given-names></name></person-group><year iso-8601-date="2005">2005</year><article-title>Self-motion-induced eye movements: effects on visual acuity and navigation</article-title><source>Nature Reviews Neuroscience</source><volume>6</volume><fpage>966</fpage><lpage>976</lpage><pub-id pub-id-type="doi">10.1038/nrn1804</pub-id><pub-id pub-id-type="pmid">16340956</pub-id></element-citation></ref><ref id="bib2"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Badan</surname> <given-names>D</given-names></name></person-group><year iso-8601-date="1986">1986</year><article-title>Diet of the house mouse (Mus-Musculus L) in 2 pine and a kauri forest</article-title><source>New Zealand Journal of Ecology</source><volume>9</volume><fpage>137</fpage><lpage>141</lpage></element-citation></ref><ref id="bib3"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Baden</surname> <given-names>T</given-names></name><name><surname>Berens</surname> <given-names>P</given-names></name><name><surname>Franke</surname> <given-names>K</given-names></name><name><surname>Román Rosón</surname> <given-names>M</given-names></name><name><surname>Bethge</surname> <given-names>M</given-names></name><name><surname>Euler</surname> <given-names>T</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>The functional diversity of retinal ganglion cells in the mouse</article-title><source>Nature</source><volume>529</volume><fpage>345</fpage><lpage>350</lpage><pub-id pub-id-type="doi">10.1038/nature16468</pub-id><pub-id pub-id-type="pmid">26735013</pub-id></element-citation></ref><ref id="bib4"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Barathi</surname> <given-names>VA</given-names></name><name><surname>Boopathi</surname> <given-names>VG</given-names></name><name><surname>Yap</surname> <given-names>EP</given-names></name><name><surname>Beuerman</surname> <given-names>RW</given-names></name></person-group><year iso-8601-date="2008">2008</year><article-title>Two models of experimental myopia in the mouse</article-title><source>Vision Research</source><volume>48</volume><fpage>904</fpage><lpage>916</lpage><pub-id pub-id-type="doi">10.1016/j.visres.2008.01.004</pub-id><pub-id pub-id-type="pmid">18289630</pub-id></element-citation></ref><ref id="bib5"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bleckert</surname> <given-names>A</given-names></name><name><surname>Schwartz</surname> <given-names>GW</given-names></name><name><surname>Turner</surname> <given-names>MH</given-names></name><name><surname>Rieke</surname> <given-names>F</given-names></name><name><surname>Wong</surname> <given-names>RO</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>Visual space is represented by nonmatching topographies of distinct mouse retinal ganglion cell types</article-title><source>Current Biology</source><volume>24</volume><fpage>310</fpage><lpage>315</lpage><pub-id pub-id-type="doi">10.1016/j.cub.2013.12.020</pub-id><pub-id pub-id-type="pmid">24440397</pub-id></element-citation></ref><ref id="bib6"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Boursot</surname> <given-names>P</given-names></name><name><surname>Auffray</surname> <given-names>J-C</given-names></name><name><surname>Britton-Davidian</surname> <given-names>J</given-names></name><name><surname>Bonhomme</surname> <given-names>F</given-names></name></person-group><year iso-8601-date="1993">1993</year><article-title>The evolution of house mice</article-title><source>Annual Review of Ecology and Systematics</source><volume>24</volume><fpage>119</fpage><lpage>152</lpage><pub-id pub-id-type="doi">10.1146/annurev.es.24.110193.001003</pub-id></element-citation></ref><ref id="bib7"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Chakraborty</surname> <given-names>R</given-names></name><name><surname>Lacy</surname> <given-names>KD</given-names></name><name><surname>Tan</surname> <given-names>CC</given-names></name><name><surname>Park</surname> <given-names>HN</given-names></name><name><surname>Pardue</surname> <given-names>MT</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>Refractive index measurement of the mouse crystalline lens using optical coherence tomography</article-title><source>Experimental Eye Research</source><volume>125</volume><fpage>62</fpage><lpage>70</lpage><pub-id pub-id-type="doi">10.1016/j.exer.2014.05.015</pub-id><pub-id pub-id-type="pmid">24939747</pub-id></element-citation></ref><ref id="bib8"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Cheng</surname> <given-names>C</given-names></name><name><surname>Parreno</surname> <given-names>J</given-names></name><name><surname>Nowak</surname> <given-names>RB</given-names></name><name><surname>Biswas</surname> <given-names>SK</given-names></name><name><surname>Wang</surname> <given-names>K</given-names></name><name><surname>Hoshino</surname> <given-names>M</given-names></name><name><surname>Uesugi</surname> <given-names>K</given-names></name><name><surname>Yagi</surname> <given-names>N</given-names></name><name><surname>Moncaster</surname> <given-names>JA</given-names></name><name><surname>Lo</surname> <given-names>WK</given-names></name><name><surname>Pierscionek</surname> <given-names>B</given-names></name><name><surname>Fowler</surname> <given-names>VM</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>Age-related changes in eye lens biomechanics, morphology, refractive index and transparency</article-title><source>Aging</source><volume>11</volume><fpage>12497</fpage><lpage>12531</lpage><pub-id pub-id-type="doi">10.18632/aging.102584</pub-id><pub-id pub-id-type="pmid">31844034</pub-id></element-citation></ref><ref id="bib9"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Dean</surname> <given-names>P</given-names></name><name><surname>Redgrave</surname> <given-names>P</given-names></name><name><surname>Westby</surname> <given-names>GW</given-names></name></person-group><year iso-8601-date="1989">1989</year><article-title>Event or emergency? two response systems in the mammalian superior colliculus</article-title><source>Trends in Neurosciences</source><volume>12</volume><fpage>137</fpage><lpage>147</lpage><pub-id pub-id-type="doi">10.1016/0166-2236(89)90052-0</pub-id><pub-id pub-id-type="pmid">2470171</pub-id></element-citation></ref><ref id="bib10"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Dhande</surname> <given-names>OS</given-names></name><name><surname>Stafford</surname> <given-names>BK</given-names></name><name><surname>Lim</surname> <given-names>JA</given-names></name><name><surname>Huberman</surname> <given-names>AD</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>Contributions of retinal ganglion cells to subcortical visual processing and behaviors</article-title><source>Annual Review of Vision Science</source><volume>1</volume><fpage>291</fpage><lpage>328</lpage><pub-id pub-id-type="doi">10.1146/annurev-vision-082114-035502</pub-id><pub-id pub-id-type="pmid">28532372</pub-id></element-citation></ref><ref id="bib11"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Dräger</surname> <given-names>UC</given-names></name></person-group><year iso-8601-date="1978">1978</year><article-title>Observations on monocular deprivation in mice</article-title><source>Journal of Neurophysiology</source><volume>41</volume><fpage>28</fpage><lpage>42</lpage><pub-id pub-id-type="doi">10.1152/jn.1978.41.1.28</pub-id><pub-id pub-id-type="pmid">621544</pub-id></element-citation></ref><ref id="bib12"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Dräger</surname> <given-names>UC</given-names></name><name><surname>Olsen</surname> <given-names>JF</given-names></name></person-group><year iso-8601-date="1980">1980</year><article-title>Origins of crossed and uncrossed retinal projections in pigmented and albino mice</article-title><source>Journal of Comparative Neurology</source><volume>191</volume><fpage>383</fpage><lpage>412</lpage><pub-id pub-id-type="doi">10.1002/cne.901910306</pub-id><pub-id pub-id-type="pmid">7410600</pub-id></element-citation></ref><ref id="bib13"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Dräger</surname> <given-names>UC</given-names></name><name><surname>Olsen</surname> <given-names>JF</given-names></name></person-group><year iso-8601-date="1981">1981</year><article-title>Ganglion cell distribution in the retina of the mouse</article-title><source>Investigative Ophthalmology &amp; Visual Science</source><volume>20</volume><fpage>285</fpage><lpage>293</lpage><pub-id pub-id-type="pmid">6162818</pub-id></element-citation></ref><ref id="bib14"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Franke</surname> <given-names>K</given-names></name><name><surname>Berens</surname> <given-names>P</given-names></name><name><surname>Schubert</surname> <given-names>T</given-names></name><name><surname>Bethge</surname> <given-names>M</given-names></name><name><surname>Euler</surname> <given-names>T</given-names></name><name><surname>Baden</surname> <given-names>T</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>Inhibition decorrelates visual feature representations in the inner retina</article-title><source>Nature</source><volume>542</volume><fpage>439</fpage><lpage>444</lpage><pub-id pub-id-type="doi">10.1038/nature21394</pub-id><pub-id pub-id-type="pmid">28178238</pub-id></element-citation></ref><ref id="bib15"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Garrett</surname> <given-names>ME</given-names></name><name><surname>Nauhaus</surname> <given-names>I</given-names></name><name><surname>Marshel</surname> <given-names>JH</given-names></name><name><surname>Callaway</surname> <given-names>EM</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>Topography and areal organization of mouse visual cortex</article-title><source>Journal of Neuroscience</source><volume>34</volume><fpage>12587</fpage><lpage>12600</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.1124-14.2014</pub-id><pub-id pub-id-type="pmid">25209296</pub-id></element-citation></ref><ref id="bib16"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Gibson</surname> <given-names>JJ</given-names></name><name><surname>Olum</surname> <given-names>P</given-names></name><name><surname>Rosenblatt</surname> <given-names>F</given-names></name></person-group><year iso-8601-date="1955">1955</year><article-title>Parallax and perspective during aircraft landings</article-title><source>The American Journal of Psychology</source><volume>68</volume><fpage>372</fpage><lpage>385</lpage><pub-id pub-id-type="doi">10.2307/1418521</pub-id><pub-id pub-id-type="pmid">13248971</pub-id></element-citation></ref><ref id="bib17"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Gire</surname> <given-names>DH</given-names></name><name><surname>Kapoor</surname> <given-names>V</given-names></name><name><surname>Arrighi-Allisan</surname> <given-names>A</given-names></name><name><surname>Seminara</surname> <given-names>A</given-names></name><name><surname>Murthy</surname> <given-names>VN</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Mice develop efficient strategies for foraging and navigation using complex natural stimuli</article-title><source>Current Biology</source><volume>26</volume><fpage>1261</fpage><lpage>1273</lpage><pub-id pub-id-type="doi">10.1016/j.cub.2016.03.040</pub-id><pub-id pub-id-type="pmid">27112299</pub-id></element-citation></ref><ref id="bib18"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hoy</surname> <given-names>JL</given-names></name><name><surname>Yavorska</surname> <given-names>I</given-names></name><name><surname>Wehr</surname> <given-names>M</given-names></name><name><surname>Niell</surname> <given-names>CM</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Vision drives accurate approach behavior during prey capture in laboratory mice</article-title><source>Current Biology</source><volume>26</volume><fpage>3046</fpage><lpage>3052</lpage><pub-id pub-id-type="doi">10.1016/j.cub.2016.09.009</pub-id><pub-id pub-id-type="pmid">27773567</pub-id></element-citation></ref><ref id="bib19"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hoy</surname> <given-names>JL</given-names></name><name><surname>Bishop</surname> <given-names>HI</given-names></name><name><surname>Niell</surname> <given-names>CM</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>Defined cell types in superior colliculus make distinct contributions to prey capture behavior in the mouse</article-title><source>Current Biology</source><volume>29</volume><fpage>4130</fpage><lpage>4138</lpage><pub-id pub-id-type="doi">10.1016/j.cub.2019.10.017</pub-id><pub-id pub-id-type="pmid">31761701</pub-id></element-citation></ref><ref id="bib20"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Huberman</surname> <given-names>AD</given-names></name><name><surname>Manu</surname> <given-names>M</given-names></name><name><surname>Koch</surname> <given-names>SM</given-names></name><name><surname>Susman</surname> <given-names>MW</given-names></name><name><surname>Lutz</surname> <given-names>AB</given-names></name><name><surname>Ullian</surname> <given-names>EM</given-names></name><name><surname>Baccus</surname> <given-names>SA</given-names></name><name><surname>Barres</surname> <given-names>BA</given-names></name></person-group><year iso-8601-date="2008">2008</year><article-title>Architecture and activity-mediated refinement of axonal projections from a mosaic of genetically identified retinal ganglion cells</article-title><source>Neuron</source><volume>59</volume><fpage>425</fpage><lpage>438</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2008.07.018</pub-id><pub-id pub-id-type="pmid">18701068</pub-id></element-citation></ref><ref id="bib21"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Hughes</surname> <given-names>A</given-names></name></person-group><year iso-8601-date="1977">1977</year><chapter-title>The topography of vision in mammals of contrasting life style: comparative optics and retinal organization</chapter-title><person-group person-group-type="editor"><name><surname>Crescitelli</surname> <given-names>F</given-names></name></person-group><source>Handbook of Sensory Physiology VII</source><publisher-loc>Berlin</publisher-loc><publisher-name>Springer-Verlag</publisher-name><fpage>613</fpage><lpage>756</lpage><pub-id pub-id-type="doi">10.1007/978-3-642-66468-7_11</pub-id></element-citation></ref><ref id="bib22"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hughes</surname> <given-names>A</given-names></name></person-group><year iso-8601-date="1979">1979</year><article-title>A schematic eye for the rat</article-title><source>Vision Research</source><volume>19</volume><fpage>569</fpage><lpage>588</lpage><pub-id pub-id-type="doi">10.1016/0042-6989(79)90143-3</pub-id><pub-id pub-id-type="pmid">483586</pub-id></element-citation></ref><ref id="bib23"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ibrahim</surname> <given-names>L</given-names></name><name><surname>Wright</surname> <given-names>EA</given-names></name></person-group><year iso-8601-date="1975">1975</year><article-title>The growth of rats and mice vibrissae under normal and some abnormal conditions</article-title><source>Journal of Embryology and Experimental Morphology</source><volume>33</volume><fpage>831</fpage><lpage>844</lpage><pub-id pub-id-type="pmid">1176877</pub-id></element-citation></ref><ref id="bib24"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Johnson</surname> <given-names>KP</given-names></name><name><surname>Fitzpatrick</surname> <given-names>MJ</given-names></name><name><surname>Zhao</surname> <given-names>L</given-names></name><name><surname>Wang</surname> <given-names>B</given-names></name><name><surname>McCracken</surname> <given-names>S</given-names></name><name><surname>Williams</surname> <given-names>PR</given-names></name><name><surname>Kerschensteiner</surname> <given-names>D</given-names></name></person-group><year iso-8601-date="2021">2021</year><article-title>Cell-type-specific binocular vision guides predation in mice</article-title><source>Neuron</source><volume>109</volume><fpage>1527</fpage><lpage>1539</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2021.03.010</pub-id><pub-id pub-id-type="pmid">33784498</pub-id></element-citation></ref><ref id="bib25"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Johnson</surname> <given-names>GL</given-names></name><name><surname>Gadow</surname> <given-names>HF</given-names></name></person-group><year iso-8601-date="1901">1901</year><article-title>I. Contributions to the comparative anatomy of the mammalian eye, chiefly based on ophthalmoscopic examination</article-title><source>Philosophical Transactions of the Royal Society of London. Series B, Containing Papers of a Biological Character</source><volume>194</volume><fpage>1</fpage><lpage>82</lpage><pub-id pub-id-type="doi">10.1098/rstb.1901.0001</pub-id></element-citation></ref><ref id="bib26"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Krieger</surname> <given-names>B</given-names></name><name><surname>Qiao</surname> <given-names>M</given-names></name><name><surname>Rousso</surname> <given-names>DL</given-names></name><name><surname>Sanes</surname> <given-names>JR</given-names></name><name><surname>Meister</surname> <given-names>M</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>Four alpha ganglion cell types in mouse retina: function, structure, and molecular signatures</article-title><source>PLOS ONE</source><volume>12</volume><elocation-id>e0180091</elocation-id><pub-id pub-id-type="doi">10.1371/journal.pone.0180091</pub-id><pub-id pub-id-type="pmid">28753612</pub-id></element-citation></ref><ref id="bib27"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>La Chioma</surname> <given-names>A</given-names></name><name><surname>Bonhoeffer</surname> <given-names>T</given-names></name><name><surname>Hübener</surname> <given-names>M</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>Area-Specific mapping of binocular disparity across mouse visual cortex</article-title><source>Current Biology</source><volume>29</volume><fpage>2954</fpage><lpage>2960</lpage><pub-id pub-id-type="doi">10.1016/j.cub.2019.07.037</pub-id><pub-id pub-id-type="pmid">31422884</pub-id></element-citation></ref><ref id="bib28"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>La Chioma</surname> <given-names>A</given-names></name><name><surname>Bonhoeffer</surname> <given-names>T</given-names></name><name><surname>Hübener</surname> <given-names>M</given-names></name></person-group><year iso-8601-date="2020">2020</year><article-title>Disparity sensitivity and binocular integration in mouse visual cortex areas</article-title><source>The Journal of Neuroscience</source><volume>40</volume><fpage>8883</fpage><lpage>8899</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.1060-20.2020</pub-id><pub-id pub-id-type="pmid">33051348</pub-id></element-citation></ref><ref id="bib29"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Laing</surname> <given-names>RJ</given-names></name><name><surname>Turecek</surname> <given-names>J</given-names></name><name><surname>Takahata</surname> <given-names>T</given-names></name><name><surname>Olavarria</surname> <given-names>JF</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>Identification of Eye-Specific domains and their relation to callosal connections in primary visual cortex of long evans rats</article-title><source>Cerebral Cortex</source><volume>25</volume><fpage>3314</fpage><lpage>3329</lpage><pub-id pub-id-type="doi">10.1093/cercor/bhu128</pub-id><pub-id pub-id-type="pmid">24969475</pub-id></element-citation></ref><ref id="bib30"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Land</surname> <given-names>MF</given-names></name></person-group><year iso-8601-date="1999">1999</year><article-title>Motion and vision: why animals move their eyes</article-title><source>Journal of Comparative Physiology A: Sensory, Neural, and Behavioral Physiology</source><volume>185</volume><fpage>341</fpage><lpage>352</lpage><pub-id pub-id-type="doi">10.1007/s003590050393</pub-id></element-citation></ref><ref id="bib31"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Langley</surname> <given-names>WM</given-names></name></person-group><year iso-8601-date="1983">1983</year><article-title>Relative importance of the distance senses in grasshopper mouse predatory behaviour</article-title><source>Animal Behaviour</source><volume>31</volume><fpage>199</fpage><lpage>205</lpage><pub-id pub-id-type="doi">10.1016/S0003-3472(83)80189-4</pub-id></element-citation></ref><ref id="bib32"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Langley</surname> <given-names>WM</given-names></name></person-group><year iso-8601-date="1984">1984</year><article-title>Recognition of prey species by their odors in the grasshopper mouse (<italic>Onychomys leucogaster</italic>)</article-title><source>Behavioural Processes</source><volume>9</volume><fpage>277</fpage><lpage>280</lpage><pub-id pub-id-type="doi">10.1016/0376-6357(84)90048-2</pub-id><pub-id pub-id-type="pmid">24896524</pub-id></element-citation></ref><ref id="bib33"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Langley</surname> <given-names>WM</given-names></name></person-group><year iso-8601-date="1988">1988</year><article-title>Spiny mouse's (Acomys Cahirinus) use of its distance senses in prey localization</article-title><source>Behavioural Processes</source><volume>16</volume><fpage>67</fpage><lpage>73</lpage><pub-id pub-id-type="doi">10.1016/0376-6357(88)90018-6</pub-id><pub-id pub-id-type="pmid">24896404</pub-id></element-citation></ref><ref id="bib34"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Lappe</surname> <given-names>M</given-names></name><name><surname>Bremmer</surname> <given-names>F</given-names></name><name><surname>van den Berg</surname> <given-names>AV</given-names></name></person-group><year iso-8601-date="1999">1999</year><article-title>Perception of self-motion from visual flow</article-title><source>Trends in Cognitive Sciences</source><volume>3</volume><fpage>329</fpage><lpage>336</lpage><pub-id pub-id-type="doi">10.1016/S1364-6613(99)01364-9</pub-id><pub-id pub-id-type="pmid">10461195</pub-id></element-citation></ref><ref id="bib35"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Lettvin</surname> <given-names>JY</given-names></name><name><surname>Maturana</surname> <given-names>HR</given-names></name><name><surname>Mcculloch</surname> <given-names>WS</given-names></name><name><surname>Pitts</surname> <given-names>WH</given-names></name></person-group><year iso-8601-date="1959">1959</year><article-title>What the frogs eye tells the frogs brain</article-title><source>Proceedings of the Institute of Radio Engineers</source><volume>47</volume><fpage>1940</fpage><lpage>1951</lpage><pub-id pub-id-type="doi">10.1109/JRPROC.1959.287207</pub-id></element-citation></ref><ref id="bib36"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Martersteck</surname> <given-names>EM</given-names></name><name><surname>Hirokawa</surname> <given-names>KE</given-names></name><name><surname>Evarts</surname> <given-names>M</given-names></name><name><surname>Bernard</surname> <given-names>A</given-names></name><name><surname>Duan</surname> <given-names>X</given-names></name><name><surname>Li</surname> <given-names>Y</given-names></name><name><surname>Ng</surname> <given-names>L</given-names></name><name><surname>Oh</surname> <given-names>SW</given-names></name><name><surname>Ouellette</surname> <given-names>B</given-names></name><name><surname>Royall</surname> <given-names>JJ</given-names></name><name><surname>Stoecklin</surname> <given-names>M</given-names></name><name><surname>Wang</surname> <given-names>Q</given-names></name><name><surname>Zeng</surname> <given-names>H</given-names></name><name><surname>Sanes</surname> <given-names>JR</given-names></name><name><surname>Harris</surname> <given-names>JA</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>Diverse central projection patterns of retinal ganglion cells</article-title><source>Cell Reports</source><volume>18</volume><fpage>2058</fpage><lpage>2072</lpage><pub-id pub-id-type="doi">10.1016/j.celrep.2017.01.075</pub-id><pub-id pub-id-type="pmid">28228269</pub-id></element-citation></ref><ref id="bib37"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Meyer</surname> <given-names>AF</given-names></name><name><surname>Poort</surname> <given-names>J</given-names></name><name><surname>O'Keefe</surname> <given-names>J</given-names></name><name><surname>Sahani</surname> <given-names>M</given-names></name><name><surname>Linden</surname> <given-names>JF</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>A Head-Mounted camera system integrates detailed behavioral monitoring with multichannel electrophysiology in freely moving mice</article-title><source>Neuron</source><volume>100</volume><fpage>46</fpage><lpage>60</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2018.09.020</pub-id><pub-id pub-id-type="pmid">30308171</pub-id></element-citation></ref><ref id="bib38"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Meyer</surname> <given-names>AF</given-names></name><name><surname>O'Keefe</surname> <given-names>J</given-names></name><name><surname>Poort</surname> <given-names>J</given-names></name></person-group><year iso-8601-date="2020">2020</year><article-title>Two distinct types of Eye-Head coupling in freely moving mice</article-title><source>Current Biology</source><volume>30</volume><fpage>2116</fpage><lpage>2130</lpage><pub-id pub-id-type="doi">10.1016/j.cub.2020.04.042</pub-id><pub-id pub-id-type="pmid">32413309</pub-id></element-citation></ref><ref id="bib39"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Michaiel</surname> <given-names>AM</given-names></name><name><surname>Abe</surname> <given-names>ET</given-names></name><name><surname>Niell</surname> <given-names>CM</given-names></name></person-group><year iso-8601-date="2020">2020</year><article-title>Dynamics of gaze control during prey capture in freely moving mice</article-title><source>eLife</source><volume>9</volume><elocation-id>e57458</elocation-id><pub-id pub-id-type="doi">10.7554/eLife.57458</pub-id><pub-id pub-id-type="pmid">32706335</pub-id></element-citation></ref><ref id="bib40"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Murphy</surname> <given-names>GJ</given-names></name><name><surname>Rieke</surname> <given-names>F</given-names></name></person-group><year iso-8601-date="2006">2006</year><article-title>Network variability limits stimulus-evoked spike timing precision in retinal ganglion cells</article-title><source>Neuron</source><volume>52</volume><fpage>511</fpage><lpage>524</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2006.09.014</pub-id><pub-id pub-id-type="pmid">17088216</pub-id></element-citation></ref><ref id="bib41"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Niell</surname> <given-names>CM</given-names></name><name><surname>Stryker</surname> <given-names>MP</given-names></name></person-group><year iso-8601-date="2008">2008</year><article-title>Highly selective receptive fields in mouse visual cortex</article-title><source>Journal of Neuroscience</source><volume>28</volume><fpage>7520</fpage><lpage>7536</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.0623-08.2008</pub-id><pub-id pub-id-type="pmid">18650330</pub-id></element-citation></ref><ref id="bib42"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Olavarria</surname> <given-names>J</given-names></name><name><surname>Van Sluyters</surname> <given-names>RC</given-names></name></person-group><year iso-8601-date="1983">1983</year><article-title>Widespread callosal connections in infragranular visual cortex of the rat</article-title><source>Brain Research</source><volume>279</volume><fpage>233</fpage><lpage>237</lpage><pub-id pub-id-type="doi">10.1016/0006-8993(83)90182-8</pub-id><pub-id pub-id-type="pmid">6640342</pub-id></element-citation></ref><ref id="bib43"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Oommen</surname> <given-names>BS</given-names></name><name><surname>Stahl</surname> <given-names>JS</given-names></name></person-group><year iso-8601-date="2008">2008</year><article-title>Eye orientation during static tilts and its relationship to spontaneous head pitch in the laboratory mouse</article-title><source>Brain Research</source><volume>1193</volume><fpage>57</fpage><lpage>66</lpage><pub-id pub-id-type="doi">10.1016/j.brainres.2007.11.053</pub-id><pub-id pub-id-type="pmid">18178173</pub-id></element-citation></ref><ref id="bib44"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Pang</surname> <given-names>JJ</given-names></name><name><surname>Gao</surname> <given-names>F</given-names></name><name><surname>Wu</surname> <given-names>SM</given-names></name></person-group><year iso-8601-date="2003">2003</year><article-title>Light-evoked excitatory and inhibitory synaptic inputs to ON and OFF alpha ganglion cells in the mouse retina</article-title><source>The Journal of Neuroscience</source><volume>23</volume><fpage>6063</fpage><lpage>6073</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.23-14-06063.2003</pub-id><pub-id pub-id-type="pmid">12853425</pub-id></element-citation></ref><ref id="bib45"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Payne</surname> <given-names>HL</given-names></name><name><surname>Raymond</surname> <given-names>JL</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>Magnetic eye tracking in mice</article-title><source>eLife</source><volume>6</volume><elocation-id>e29222</elocation-id><pub-id pub-id-type="doi">10.7554/eLife.29222</pub-id><pub-id pub-id-type="pmid">28872455</pub-id></element-citation></ref><ref id="bib46"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Pennesi</surname> <given-names>ME</given-names></name><name><surname>Lyubarsky</surname> <given-names>AL</given-names></name><name><surname>Pugh</surname> <given-names>EN</given-names></name></person-group><year iso-8601-date="1998">1998</year><article-title>Extreme responsiveness of the pupil of the dark-adapted mouse to steady retinal illumination</article-title><source>Investigative Ophthalmology &amp; Visual Science</source><volume>39</volume><fpage>2148</fpage><lpage>2156</lpage><pub-id pub-id-type="pmid">9761294</pub-id></element-citation></ref><ref id="bib47"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Philipson</surname> <given-names>B</given-names></name></person-group><year iso-8601-date="1969">1969</year><article-title>Distribution of protein within the normal rat lens</article-title><source>Investigative Ophthalmology</source><volume>8</volume><fpage>258</fpage><lpage>270</lpage><pub-id pub-id-type="pmid">5772717</pub-id></element-citation></ref><ref id="bib48"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Procacci</surname> <given-names>NM</given-names></name><name><surname>Allen</surname> <given-names>KM</given-names></name><name><surname>Robb</surname> <given-names>GE</given-names></name><name><surname>Ijekah</surname> <given-names>R</given-names></name><name><surname>Lynam</surname> <given-names>H</given-names></name><name><surname>Hoy</surname> <given-names>JL</given-names></name></person-group><year iso-8601-date="2020">2020</year><article-title>Context-dependent modulation of natural approach behaviour in mice</article-title><source>Proceedings of the Royal Society B: Biological Sciences</source><volume>287</volume><elocation-id>20201189</elocation-id><pub-id pub-id-type="doi">10.1098/rspb.2020.1189</pub-id></element-citation></ref><ref id="bib49"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ramachandra</surname> <given-names>V</given-names></name><name><surname>Pawlak</surname> <given-names>V</given-names></name><name><surname>Wallace</surname> <given-names>DJ</given-names></name><name><surname>Kerr</surname> <given-names>JND</given-names></name></person-group><year iso-8601-date="2020">2020</year><article-title>Impact of visual callosal pathway is dependent upon ipsilateral thalamus</article-title><source>Nature Communications</source><volume>11</volume><elocation-id>1889</elocation-id><pub-id pub-id-type="doi">10.1038/s41467-020-15672-4</pub-id><pub-id pub-id-type="pmid">32313167</pub-id></element-citation></ref><ref id="bib50"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Reese</surname> <given-names>BE</given-names></name><name><surname>Cowey</surname> <given-names>A</given-names></name></person-group><year iso-8601-date="1986">1986</year><article-title>Large retinal ganglion cells in the rat: their distribution and laterality of projection</article-title><source>Experimental Brain Research</source><volume>61</volume><fpage>375</fpage><lpage>385</lpage><pub-id pub-id-type="doi">10.1007/BF00239526</pub-id><pub-id pub-id-type="pmid">3948944</pub-id></element-citation></ref><ref id="bib51"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Sabbah</surname> <given-names>S</given-names></name><name><surname>Gemmer</surname> <given-names>JA</given-names></name><name><surname>Bhatia-Lin</surname> <given-names>A</given-names></name><name><surname>Manoff</surname> <given-names>G</given-names></name><name><surname>Castro</surname> <given-names>G</given-names></name><name><surname>Siegel</surname> <given-names>JK</given-names></name><name><surname>Jeffery</surname> <given-names>N</given-names></name><name><surname>Berson</surname> <given-names>DM</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>A retinal code for motion along the gravitational and body axes</article-title><source>Nature</source><volume>546</volume><fpage>492</fpage><lpage>497</lpage><pub-id pub-id-type="doi">10.1038/nature22818</pub-id><pub-id pub-id-type="pmid">28607486</pub-id></element-citation></ref><ref id="bib52"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Saleem</surname> <given-names>AB</given-names></name></person-group><year iso-8601-date="2020">2020</year><article-title>Two stream hypothesis of visual processing for navigation in mouse</article-title><source>Current Opinion in Neurobiology</source><volume>64</volume><fpage>70</fpage><lpage>78</lpage><pub-id pub-id-type="doi">10.1016/j.conb.2020.03.009</pub-id><pub-id pub-id-type="pmid">32294570</pub-id></element-citation></ref><ref id="bib53"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Salinas-Navarro</surname> <given-names>M</given-names></name><name><surname>Jiménez-López</surname> <given-names>M</given-names></name><name><surname>Valiente-Soriano</surname> <given-names>FJ</given-names></name><name><surname>Alarcón-Martínez</surname> <given-names>L</given-names></name><name><surname>Avilés-Trigueros</surname> <given-names>M</given-names></name><name><surname>Mayor</surname> <given-names>S</given-names></name><name><surname>Holmes</surname> <given-names>T</given-names></name><name><surname>Lund</surname> <given-names>RD</given-names></name><name><surname>Villegas-Pérez</surname> <given-names>MP</given-names></name><name><surname>Vidal-Sanz</surname> <given-names>M</given-names></name></person-group><year iso-8601-date="2009">2009</year><article-title>Retinal ganglion cell population in adult albino and pigmented mice: a computerized analysis of the entire population and its spatial distribution</article-title><source>Vision Research</source><volume>49</volume><fpage>637</fpage><lpage>647</lpage><pub-id pub-id-type="doi">10.1016/j.visres.2009.01.010</pub-id><pub-id pub-id-type="pmid">19948111</pub-id></element-citation></ref><ref id="bib54"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Samonds</surname> <given-names>JM</given-names></name><name><surname>Choi</surname> <given-names>V</given-names></name><name><surname>Priebe</surname> <given-names>NJ</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>Mice discriminate stereoscopic surfaces without fixating in depth</article-title><source>The Journal of Neuroscience</source><volume>39</volume><fpage>8024</fpage><lpage>8037</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.0895-19.2019</pub-id><pub-id pub-id-type="pmid">31462533</pub-id></element-citation></ref><ref id="bib55"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Scholl</surname> <given-names>B</given-names></name><name><surname>Burge</surname> <given-names>J</given-names></name><name><surname>Priebe</surname> <given-names>NJ</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>Binocular integration and disparity selectivity in mouse primary visual cortex</article-title><source>Journal of Neurophysiology</source><volume>109</volume><fpage>3013</fpage><lpage>3024</lpage><pub-id pub-id-type="doi">10.1152/jn.01021.2012</pub-id><pub-id pub-id-type="pmid">23515794</pub-id></element-citation></ref><ref id="bib56"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Scholl</surname> <given-names>B</given-names></name><name><surname>Pattadkal</surname> <given-names>JJ</given-names></name><name><surname>Dilly</surname> <given-names>GA</given-names></name><name><surname>Priebe</surname> <given-names>NJ</given-names></name><name><surname>Zemelman</surname> <given-names>BV</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>Local integration accounts for weak selectivity of mouse neocortical parvalbumin interneurons</article-title><source>Neuron</source><volume>87</volume><fpage>424</fpage><lpage>436</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2015.06.030</pub-id><pub-id pub-id-type="pmid">26182423</pub-id></element-citation></ref><ref id="bib57"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Schuett</surname> <given-names>S</given-names></name><name><surname>Bonhoeffer</surname> <given-names>T</given-names></name><name><surname>Hübener</surname> <given-names>M</given-names></name></person-group><year iso-8601-date="2002">2002</year><article-title>Mapping retinotopic structure in mouse visual cortex with optical imaging</article-title><source>The Journal of Neuroscience</source><volume>22</volume><fpage>6549</fpage><lpage>6559</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.22-15-06549.2002</pub-id><pub-id pub-id-type="pmid">12151534</pub-id></element-citation></ref><ref id="bib58"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Shang</surname> <given-names>C</given-names></name><name><surname>Liu</surname> <given-names>A</given-names></name><name><surname>Li</surname> <given-names>D</given-names></name><name><surname>Xie</surname> <given-names>Z</given-names></name><name><surname>Chen</surname> <given-names>Z</given-names></name><name><surname>Huang</surname> <given-names>M</given-names></name><name><surname>Li</surname> <given-names>Y</given-names></name><name><surname>Wang</surname> <given-names>Y</given-names></name><name><surname>Shen</surname> <given-names>WL</given-names></name><name><surname>Cao</surname> <given-names>P</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>A subcortical excitatory circuit for sensory-triggered predatory hunting in mice</article-title><source>Nature Neuroscience</source><volume>22</volume><fpage>909</fpage><lpage>920</lpage><pub-id pub-id-type="doi">10.1038/s41593-019-0405-4</pub-id><pub-id pub-id-type="pmid">31127260</pub-id></element-citation></ref><ref id="bib59"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Stabio</surname> <given-names>ME</given-names></name><name><surname>Sondereker</surname> <given-names>KB</given-names></name><name><surname>Haghgou</surname> <given-names>SD</given-names></name><name><surname>Day</surname> <given-names>BL</given-names></name><name><surname>Chidsey</surname> <given-names>B</given-names></name><name><surname>Sabbah</surname> <given-names>S</given-names></name><name><surname>Renna</surname> <given-names>JM</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>A novel map of the mouse eye for orienting retinal topography in anatomical space</article-title><source>Journal of Comparative Neurology</source><volume>526</volume><fpage>1749</fpage><lpage>1759</lpage><pub-id pub-id-type="doi">10.1002/cne.24446</pub-id><pub-id pub-id-type="pmid">29633277</pub-id></element-citation></ref><ref id="bib60"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Sterratt</surname> <given-names>DC</given-names></name><name><surname>Lyngholm</surname> <given-names>D</given-names></name><name><surname>Willshaw</surname> <given-names>DJ</given-names></name><name><surname>Thompson</surname> <given-names>ID</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>Standard anatomical and visual space for the mouse retina: computational reconstruction and transformation of flattened retinae with the retistruct package</article-title><source>PLOS Computational Biology</source><volume>9</volume><elocation-id>e1002921</elocation-id><pub-id pub-id-type="doi">10.1371/journal.pcbi.1002921</pub-id><pub-id pub-id-type="pmid">23468609</pub-id></element-citation></ref><ref id="bib61"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Szatko</surname> <given-names>KP</given-names></name><name><surname>Korympidou</surname> <given-names>MM</given-names></name><name><surname>Ran</surname> <given-names>Y</given-names></name><name><surname>Berens</surname> <given-names>P</given-names></name><name><surname>Dalkara</surname> <given-names>D</given-names></name><name><surname>Schubert</surname> <given-names>T</given-names></name><name><surname>Euler</surname> <given-names>T</given-names></name><name><surname>Franke</surname> <given-names>K</given-names></name></person-group><year iso-8601-date="2020">2020</year><article-title>Neural circuits in the mouse retina support color vision in the upper visual field</article-title><source>Nature Communications</source><volume>11</volume><elocation-id>3481</elocation-id><pub-id pub-id-type="doi">10.1038/s41467-020-17113-8</pub-id><pub-id pub-id-type="pmid">32661226</pub-id></element-citation></ref><ref id="bib62"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Szél</surname> <given-names>A</given-names></name><name><surname>Röhlich</surname> <given-names>P</given-names></name><name><surname>Caffé</surname> <given-names>AR</given-names></name><name><surname>Juliusson</surname> <given-names>B</given-names></name><name><surname>Aguirre</surname> <given-names>G</given-names></name><name><surname>Van Veen</surname> <given-names>T</given-names></name></person-group><year iso-8601-date="1992">1992</year><article-title>Unique topographic separation of two spectral classes of cones in the mouse retina</article-title><source>The Journal of Comparative Neurology</source><volume>325</volume><fpage>327</fpage><lpage>342</lpage><pub-id pub-id-type="doi">10.1002/cne.903250302</pub-id><pub-id pub-id-type="pmid">1447405</pub-id></element-citation></ref><ref id="bib63"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Tann</surname> <given-names>CR</given-names></name><name><surname>Singleton</surname> <given-names>GR</given-names></name><name><surname>Coman</surname> <given-names>BJ</given-names></name></person-group><year iso-8601-date="1991">1991</year><article-title>Diet of the house mouse, Mus Domesticus, in the Mallee wheatlands of North-Western victoria</article-title><source>Wildlife Research</source><volume>18</volume><fpage>1</fpage><lpage>12</lpage><pub-id pub-id-type="doi">10.1071/WR9910001</pub-id></element-citation></ref><ref id="bib64"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Tkatchenko</surname> <given-names>TV</given-names></name><name><surname>Shen</surname> <given-names>Y</given-names></name><name><surname>Tkatchenko</surname> <given-names>AV</given-names></name></person-group><year iso-8601-date="2010">2010</year><article-title>Analysis of postnatal eye development in the mouse with high-resolution small animal magnetic resonance imaging</article-title><source>Investigative Opthalmology &amp; Visual Science</source><volume>51</volume><fpage>21</fpage><lpage>27</lpage><pub-id pub-id-type="doi">10.1167/iovs.08-2767</pub-id><pub-id pub-id-type="pmid">19661239</pub-id></element-citation></ref><ref id="bib65"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>van Alphen</surname> <given-names>B</given-names></name><name><surname>Winkelman</surname> <given-names>BHJ</given-names></name><name><surname>Frens</surname> <given-names>MA</given-names></name></person-group><year iso-8601-date="2010">2010</year><article-title>Three-Dimensional optokinetic eye movements in the C57BL/6J mouse</article-title><source>Investigative Opthalmology &amp; Visual Science</source><volume>51</volume><fpage>623</fpage><lpage>630</lpage><pub-id pub-id-type="doi">10.1167/iovs.09-4072</pub-id></element-citation></ref><ref id="bib66"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>van Wyk</surname> <given-names>M</given-names></name><name><surname>Wässle</surname> <given-names>H</given-names></name><name><surname>Taylor</surname> <given-names>WR</given-names></name></person-group><year iso-8601-date="2009">2009</year><article-title>Receptive field properties of ON- and OFF-ganglion cells in the mouse retina</article-title><source>Visual Neuroscience</source><volume>26</volume><fpage>297</fpage><lpage>308</lpage><pub-id pub-id-type="doi">10.1017/S0952523809990137</pub-id><pub-id pub-id-type="pmid">19602302</pub-id></element-citation></ref><ref id="bib67"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wagor</surname> <given-names>E</given-names></name><name><surname>Mangini</surname> <given-names>NJ</given-names></name><name><surname>Pearlman</surname> <given-names>AL</given-names></name></person-group><year iso-8601-date="1980">1980</year><article-title>Retinotopic organization of striate and extrastriate visual cortex in the mouse</article-title><source>The Journal of Comparative Neurology</source><volume>193</volume><fpage>187</fpage><lpage>202</lpage><pub-id pub-id-type="doi">10.1002/cne.901930113</pub-id><pub-id pub-id-type="pmid">6776164</pub-id></element-citation></ref><ref id="bib68"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wallace</surname> <given-names>DJ</given-names></name><name><surname>Greenberg</surname> <given-names>DS</given-names></name><name><surname>Sawinski</surname> <given-names>J</given-names></name><name><surname>Rulla</surname> <given-names>S</given-names></name><name><surname>Notaro</surname> <given-names>G</given-names></name><name><surname>Kerr</surname> <given-names>JN</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>Rats maintain an overhead binocular field at the expense of constant fusion</article-title><source>Nature</source><volume>498</volume><fpage>65</fpage><lpage>69</lpage><pub-id pub-id-type="doi">10.1038/nature12153</pub-id><pub-id pub-id-type="pmid">23708965</pub-id></element-citation></ref><ref id="bib69"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Yilmaz</surname> <given-names>M</given-names></name><name><surname>Meister</surname> <given-names>M</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>Rapid innate defensive responses of mice to looming visual stimuli</article-title><source>Current Biology</source><volume>23</volume><fpage>2011</fpage><lpage>2015</lpage><pub-id pub-id-type="doi">10.1016/j.cub.2013.08.015</pub-id><pub-id pub-id-type="pmid">24120636</pub-id></element-citation></ref><ref id="bib70"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Zhang</surname> <given-names>Y</given-names></name><name><surname>Kim</surname> <given-names>IJ</given-names></name><name><surname>Sanes</surname> <given-names>JR</given-names></name><name><surname>Meister</surname> <given-names>M</given-names></name></person-group><year iso-8601-date="2012">2012</year><article-title>The most numerous ganglion cell type of the mouse retina is a selective feature detector</article-title><source>PNAS</source><volume>109</volume><fpage>E2391</fpage><lpage>E2398</lpage><pub-id pub-id-type="doi">10.1073/pnas.1211547109</pub-id><pub-id pub-id-type="pmid">22891316</pub-id></element-citation></ref><ref id="bib71"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Zhao</surname> <given-names>ZD</given-names></name><name><surname>Chen</surname> <given-names>Z</given-names></name><name><surname>Xiang</surname> <given-names>X</given-names></name><name><surname>Hu</surname> <given-names>M</given-names></name><name><surname>Xie</surname> <given-names>H</given-names></name><name><surname>Jia</surname> <given-names>X</given-names></name><name><surname>Cai</surname> <given-names>F</given-names></name><name><surname>Cui</surname> <given-names>Y</given-names></name><name><surname>Chen</surname> <given-names>Z</given-names></name><name><surname>Qian</surname> <given-names>L</given-names></name><name><surname>Liu</surname> <given-names>J</given-names></name><name><surname>Shang</surname> <given-names>C</given-names></name><name><surname>Yang</surname> <given-names>Y</given-names></name><name><surname>Ni</surname> <given-names>X</given-names></name><name><surname>Sun</surname> <given-names>W</given-names></name><name><surname>Hu</surname> <given-names>J</given-names></name><name><surname>Cao</surname> <given-names>P</given-names></name><name><surname>Li</surname> <given-names>H</given-names></name><name><surname>Shen</surname> <given-names>WL</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>Zona incerta GABAergic neurons integrate prey-related sensory signals and induce an appetitive drive to promote hunting</article-title><source>Nature Neuroscience</source><volume>22</volume><fpage>921</fpage><lpage>932</lpage><pub-id pub-id-type="doi">10.1038/s41593-019-0404-5</pub-id><pub-id pub-id-type="pmid">31127258</pub-id></element-citation></ref></ref-list></back><sub-article article-type="decision-letter" id="sa1"><front-stub><article-id pub-id-type="doi">10.7554/eLife.70838.sa1</article-id><title-group><article-title>Decision letter</article-title></title-group><contrib-group><contrib contrib-type="editor"><name><surname>Vinck</surname><given-names>Martin</given-names></name><role>Reviewing Editor</role><aff><institution>Ernst Strüngmann Institute (ESI) for Neuroscience in Cooperation with Max Planck Society</institution><country>Germany</country></aff></contrib></contrib-group><contrib-group><contrib contrib-type="reviewer"><name><surname>Vinck</surname><given-names>Martin</given-names> </name><role>Reviewer</role><aff><institution>Ernst Strüngmann Institute (ESI) for Neuroscience in Cooperation with Max Planck Society</institution><country>Germany</country></aff></contrib></contrib-group></front-stub><body><boxed-text><p>In the interests of transparency, eLife publishes the most substantive revision requests and the accompanying author responses.</p></boxed-text><p><bold>Acceptance summary:</bold></p><p>During natural behavior, like chasing prey, animals make continuous body, eye and head movements. These change the specific retinotopic regions that process the target stimulus. Holmgren et al., describe a technical tour de force that allows for reconstruction of what mice exactly see during natural behavior. They find that during prey hunting, the mice's movements are coordinated in such a way that mice keep the prey in a specialized retinotopic region. This region has characteristic properties that appear optimized for visual processing of the prey.</p><p><bold>Decision letter after peer review:</bold></p><p>Thank you for submitting your article &quot;Freely-moving mice visually pursue prey using a retinal area with least optic flow&quot; for consideration by <italic>eLife</italic>. Your article has been reviewed by 2 peer reviewers, including Martin Vinck as Reviewing Editor and Reviewer #1, and the evaluation has been overseen by Tirin Moore as the Senior Editor.</p><p>The two reviewers have discussed their reviews with one another, and the Reviewing Editor has drafted this to help you prepare a revised submission. Overall the reviewers were positive and appreciate the major technical tour de force to precisely monitor head and eye movements. The reviewers accept the statistical analyses and results. However they have concerns wrt the interpretation and to what extent the results are a consequence of the mouse simply running towards the cricket, or whether there is indeed something special about the specific binocular zone in which the cricket &quot;lands&quot;. Addressing this should be a matter of enhancing the discussion, or if the authors want to make a strong claim adding some causal experiments.</p><p>Essential revisions:</p><p>1) A major concern is that readers will come away with the idea that the mouse is &quot;foveating&quot; the cricket and that there is something special about this location for optic flow, when both of these are consequences of the fact that the mouse is running toward the cricket. The authors should clarify what is active gaze control vs what is just a consequence of cricket pursuit. We encourage the authors that if they want to make a strong claim that this region is being actively used, there should be some causal support.</p><p>2) It would be useful to quantify whether the eye movements are strictly compensatory for head movements, or whether there are larger abrupts shift in gaze, as found in Michaiel.</p><p>3) Figures can be improved by labelling subpanels, as it is unclear what eg many of the circular plots represent without reading the caption.</p><p>4) The title is a bit misleading – it implies that mice are making active effort to use this region. Likewise, the abstract should note that both the specific retinal area and the optic flow pattern are direct consequences of running toward the cricket. And overall there is a lot of language that implies active targeting – the &quot;the image of the prey is kept on a specific area&quot;. Since this is a consequence of the pursuit, rather than active maintaining the gaze, we suggest language more like &quot;the image lands on a specific area&quot; or &quot;the image remains in a specific area&quot;.</p><p>5) If the authors want to support the inherent claim that this region is important for visually guided pursuit, which would provide more a significant advance, then some type of causal test would be helpful. Most conclusive would be a precise manipulation such as Johnson et al., 2020, e.g. manipulating α ganglion cells, or alternatively a lesion of the functional focus or blinders to occlude the functional focus.</p><p>6) The fact that the cricket does not land on the region of highest overall RGC density is a bit of an implausible strawman. Given that the cricket is in front of the mouse and that this region is located laterally (further than the amplitude of mouse eye movements) it's fairly clear that these will not overlap.</p><p>7) Johnson et al., (2021) provided a causal test demonstrating that mice not only use the binocular zone to pursue prey, but that the ipsi projecting RGCs that generate binocular receptive fields are necessary. This provides causal support for the findings demonstrated correlatively in this paper, yet this finding is not discussed beyond a reference to the fact that Johnson et al., also tracked head position during prey capture.</p><p>8) The authors emphasize that their setup eliminates auditory and olfactory cues. Is this essential to their results, i.e. do they find different targeting when these are not eliminated. Likewise, the title emphasizes visual pursuit, but does the cricket land on the same region when performing auditory pursuit (when controlled for pursuit accuracy?)</p><p>Reviewer #1 (Recommendations for the authors):</p><p>Holmgren et al., investigate how the head and eye movements in mice are coordinated during prey capture of crickets. A technical tour-de-force with eye and head tracking in freely moving animals allows for precise quantification of a cricket's position in the retinal field of view. Mice oriented towards the cricket using head rotations, maintaining the cricket in a narrow functional focus in the binocular, upper-temporal part of the retina. Eye movement were, as found in previous studies, primarily compensatory for head movements. The functional focus region has minimal optical flow and a high density region of α-ON retinal ganglion cells.</p><p>This is an impressive study, establishing a rich set of techniques for reconstruction of what the mice see during freely moving behavior, an approach that can be used for many different questions in the future. While some of the findings of the study are extensions of previous work, in particular, the compensatory head movements, the finding that during approach of the cricket it is kept within a relatively narrow functional focus with specialized properties is highly interesting. The finding will appeal to vision researchers, as well as researchers interested in the way in which our body optimizes sensory sampling of our environment according to ecological demands. The paper is well written and accessible to a broad audience.</p><p>An interesting question for future work would be to assess whether the head movements of the mice predict future trajectories of the cricket, thereby bringing the cricket into the predicted field of view, or whether the head movements are merely reactive to the cricket's behavior.</p><p>It would be useful to quantify whether the eye movements are strictly compensatory for head movements, or whether there are larger abrupts shift in gaze, as found in Michaiel.</p><p>A causal demonstration that silencing SC or V1 activity in this field of view disrupts behavior seems feasible and would provide direct support for the functional interpretations of the authors, but is not necessary for acceptance of the paper.</p><p>Figures can be improved by labelling subpanels, as it is unclear what eg many of the circular plots represent without reading the caption.</p><p><italic>Reviewer #2 (Recommendations for the authors):</italic></p><p>This study aims to determine whether mice use a specific region of their visual field, and consequently retina, to pursues a target during natural behavior, prey capture. This is an interesting question because mice do not have a clear fovea like primates, and it is significant in the field since the mouse Is a common model system for vision. Recent studies have shown that eye movements in the mouse are mostly compensatory with saccades serving to reset eye centering, and that eye movements and direction of gaze are primarily driven by head movements (Meyer et al., 2020), including in prey capture (Michael et al., 2020). Likewise, mice accurately aim towards prey during pursuit (Hoy et al., 2016), and thus the prey is in the binocular zone based on amplitude of eye movements (Michael et al., 2020). Furthermore, a recent study (Johnson et al., 2021) used ablation of ipsi-projecting retinal ganglion cells to show that the binocular visual field is necessary for prey capture.</p><p>The authors use a tour-de-force computational approach to determine the visual scene as projected on to the retina, based on 3-D scanning and virtual reconstruction of the environment, improved eye tracking methods, and computational projection of the scene onto the retina, all while mice pursue and capture crickets. This novel and rigorous approach, which will likely be useful to others in the field, is a significant advance and the real strength of the paper. However, as discussed below, most of the results they obtain from this effort do not provide a clear advance beyond what was known from previous studies, and are largely a direct consequence of mice running towards crickets during pursuit, though the impression one gets from the title and abstract is that this is an active and optimal gaze targeting strategy. One significant new piece of knowledge is that the cricket image lands on the region of highest density of α retinal ganglion cells, and this might be something to emphasize or explore more fully.</p><p>1. A main finding is that the cricket is generally maintained in a specific location in the lower binocular zone, which they term a &quot;functional focus&quot;. Furthermore, the authors do several tests as to whether this is an active centering process and conclude that is not. &quot;Mice do not make compensatory vertical head movements, tracking eye movements or vergence eye movements to keep prey within their functional foci but instead retain their target within a restricted bearing by running straight towards it&quot;. Thus, this main finding is just a direct consequence of the fact that mice are pursuing crickets by running towards them. And indeed two previous papers (Michael et al., 2020, Johnson et al., 2021) showed that mice keep prey in their binocular zone and maintain their head tilted downward, so this is not necessarily new information.</p><p>2. The authors also ask &quot;what advantage is this behavior to the mouse?&quot; The obvious answer is that running straight toward crickets is how to catch them. In other words, this is not a gaze targeting strategy but simply a consequence of that fact that if you want to catch something, you run towards it. However, instead the authors analyze the pattern of optic flow and demonstrate that this places the cricket in the region of least optic flow. Again, this is likely a trivial consequence of the fact that mice are running straight towards the cricket. Translational motion results in a focus of expansion (FOE) of optic flow in the heading direction, and the FOE itself is a minimum in the optic flow. Hence, as long as the mice are running toward the cricket, it will be in a region that is on average (given distortions of optic flow resulting from eye movements) a minimum of optic flow. Therefore I don't see this as a significant finding, and particularly as the title, unless they can demonstrate that this is not trivially true.</p><p>3. The title is a bit misleading – it implies that mice are making active effort to use this region. Likewise, the abstract should note that both the specific retinal area and the optic flow pattern are direct consequences of running toward the cricket. And overall there is a lot of language that implies active targeting – the &quot;the image of the prey is kept on a specific area&quot;. Since this is a consequence of the pursuit, rather than active maintaining the gaze, I'd suggest language more like &quot;the image lands on a specific area&quot; or &quot;the image remains in a specific area&quot;.</p><p>4. If the authors want to support the inherent claim that this region is important for visually guided pursuit, which would provide more a significant advance, then some type of causal test would be helpful. Most conclusive would be a precise manipulation such as Johnson et al., 2020, e.g. manipulating α ganglion cells, or alternatively a lesion of the functional focus or blinders to occlude the functional focus.</p><p>5. The fact that the cricket does not land on the region of highest overall RGC density is a bit of an implausible strawman. Given that the cricket is in front of the mouse and that this region is located laterally (further than the amplitude of mouse eye movements) it's fairly clear that these will not overlap.</p><p>6. Johnson et al., (2021) provided a causal test demonstrating that mice not only use the binocular zone to pursue prey, but that the ipsi projecting RGCs that generate binocular receptive fields are necessary. This provides causal support for the findings demonstrated correlatively in this paper, yet this finding is not discussed beyond a reference to the fact that Johnson et al., also tracked head position during prey capture.</p><p>7. The authors emphasize that their setup eliminates auditory and olfactory cues. Is this essential to their results, i.e. do they find different targeting when these are not eliminated. Likewise, the title emphasizes visual pursuit, but does the cricket land on the same region when performing auditory pursuit (when controlled for pursuit accuracy?)</p><p>[Editors' note: further revisions were suggested prior to acceptance, as described below.]</p><p>Thank you for resubmitting your work entitled &quot;Visual pursuit behavior in mice maintains the pursued prey on the retinal region with least optic flow&quot; for further consideration by <italic>eLife</italic>. Your revised article has been evaluated by Tirin Moore (Senior Editor) and a Reviewing Editor.</p><p>The manuscript has been improved but there are some remaining issues that need to be addressed before final acceptance, as outlined below. These can be addressed with textual changes. Please clearly indicate those changes so we can proceed with acceptance as soon as possible.</p><p><italic>Reviewer #1 (Recommendations for the authors):</italic></p><p>The authors have addressed all of my comments.</p><p><italic>Reviewer #2 (Recommendations for the authors):</italic></p><p>The authors have overall done an excellent job of revising their claims to match the data and avoid misleading conclusions by readers. I have two remaining points that weren't fully addressed.</p><p>1. The authors have generally improved the wording in the text to avoid implying that mice are actively targeting the cricket to this region. However, this is still not very clearly stated in the abstract, which is what most people take away from a paper. Indeed, in their response, the authors state that their findings are best stated in the first paragraph of the discussion as &quot;The positional maintenance of the cricket was not achieved by active eye movements that followed the prey, but rather by the animal's change in behavior, specifically the head-movement and orientation towards the prey during pursuit.&quot; A statement along these lines in the abstract would be very effective, so that readers don't have to wait until the discussion to have this stated explicitly. If word length is the issue, I suggest finding something else to trim since as the authors themselves note, this is the best statement of the conclusion from their findings.</p><p>2. In the public section of the original review, I noted that the fact that the cricket lands in the region of least motion blur was an almost trivial consequence of the fact that the mouse is running towards the cricket, and hence the cricket is at the focus of expansion (minimum of optic flow). However, this has not been addressed in the revision – I apologize if that is because it was in the public comments rather than author comments. However, it seems essential to address this so that readers do not think that this is an &quot;design principle&quot; of mouse vision. Unless the authors can provide a compelling argument for how this could not be the case, given the geometry of optic flow, then the statement that it lands on the region of least motion blur should be accompanied, in the abstract and elsewhere, by the clarification that this is a direct consequence of motion towards the cricket rather than a specific optimality. I also suggest revising the title to emphasize a more compelling finding (e.g. α RGCs), but if the authors want to continue to use this title, accompanied by appropriate explanation in the abstract, then that is their prerogative.</p></body></sub-article><sub-article article-type="reply" id="sa2"><front-stub><article-id pub-id-type="doi">10.7554/eLife.70838.sa2</article-id><title-group><article-title>Author response</article-title></title-group></front-stub><body><disp-quote content-type="editor-comment"><p>Essential revisions:</p><p>1) A major concern is that readers will come away with the idea that the mouse is &quot;foveating&quot; the cricket and that there is something special about this location for optic flow, when both of these are consequences of the fact that the mouse is running toward the cricket. The authors should clarify what is active gaze control vs what is just a consequence of cricket pursuit. We encourage the authors that if they want to make a strong claim that this region is being actively used, there should be some causal support.</p></disp-quote><p>We thank the reviewers for raising this point, because this is a central and important conclusion of the study. To state it clearly here, our conclusion is that mice do not “foveate” or have pursuit-like eye movements for following the cricket. We found no evidence to support the presence of pursuit-like movements, neither vergence movements (Figure 5 —figure supplement 1J) nor combinations of movements that would fulfill the role of keeping the cricket image in a consistent location on the cornea (Figure 5a) during the tracking phase of the behavior. Our conclusion was probably best stated in the first paragraph of the Discussion of the initially submitted manuscript as:</p><p>“…The positional maintenance of the cricket was not achieved by active eye movements that followed the prey, but rather by the animal’s change in behavior, specifically the head-movement and orientation towards the prey during pursuit. While eye rotations stabilized the visual field via the vestibulo-ocular reflex by countering head rotations, the rotations were not specific to either prey detection or prey tracking. This strongly suggested that eye-rotations in mice, like in rats, primarily stabilize their large field of view and that all three rotational axes, including ocular torsion, combine to counter head rotations. …”.</p><p>We agree with the reviewers that there were several sections of the submitted text that have the potential to give a reader an incorrect impression of our conclusion in this regard, and we have modified the text with the aim of making this point clearer and more consistent throughout the document. The text modifications are outlined below.</p><p>Abstract:</p><p>“…the behavior. By quantifying the spatial location of objects in the visual scene and their motion throughout the behavior, we show that the prey image consistently falls within a small area of the VOR-stabilized visual field. This functional focus coincides with the region of minimal optic flow in the visual field and consequently minimal motion-induced image blur during pursuit. The functional focus lies in the upper-temporal part of the retina and coincides with the reported high density-region of Α-ON sustained retinal ganglion cells.”</p><p>Introduction:</p><p>page 5: “…the binocular field and undertake direct pursuit. Prey objects remain in the functional foci through the stabilizing action of the VOR, and not through active prey-pursuit eye movements. The stabilized…”</p><p>Results:</p><p>page 7, heading: “During pursuit the image of the prey consistently falls in a localized visual region”</p><p>page 9: “…Mean Absolute Difference with bootstrapping, N=57 detect-track sequences, N = 3 mice. Thus, during the tracking and pursuit behavior the image of the prey consistently fell on a local and specific retinal area that we refer to from here on as the functional focus. The functional focus fell within the binocular field, while the region …”</p><p>page 18: “… N=3 mice, Figure 6E. Together this shows that the behavioral strategy employed by mice during hunting, consisting of orienting themselves to directly face the prey and following a straight, direct course to it, results in the image of their prey coinciding with the region of reduced optic flow during pursuit, where the retinal image of their prey is least distorted due to motion induced image blur.”</p><p>page 19: “…environment, cricket and the mouse. Using this approach, we show that during pursuit of crickets the hunting behavior employed by mice results in the image of the prey consistently falling within a localized region of their visual field, termed here the functional focus. …”</p><p>page 23: “In summary, we show here that during pursuit in mice the image of the intended prey falls consistently in a localized region of their visual fields, referred to here as the functional focus, and that this occurs through the animal orientating their head and body and running directly towards…”</p><disp-quote content-type="editor-comment"><p>2) It would be useful to quantify whether the eye movements are strictly compensatory for head movements, or whether there are larger abrupts shift in gaze, as found in Michaiel.</p></disp-quote><p>We did observe the abrupt shifts in gaze reported by Michiael et al., and by Meyer et al., 2020 and these are included in the trajectories and calculations. However, as these eye movements occur in conjunction with the animal’s yaw turns they neither formed a large fraction of total duration of the data we analyzed nor were they of direct consequence to the location of the cricket in the eye view during the tracking phase of the behavior, which was the primary interest in this manuscript. In addition, as these eye movements had been described previously in the above mentioned publications we elected not to isolate and analyze them. However, in response to this reviewer comment we have added a reference to these movements in the text and an example trace in figure 4 supplement 1. The text now reads as follows:</p><p>page 11: “…and counter head rotations through the VOR, enabling the large field of view around the animals head to be stabilized while the animal is moving. The relationships between head rotations and both the horizontal and vertical eye rotations have recently been quantified, and in addition it has been reported that both during exploration and hunting, mice also have abrupt gaze shifts brought about by the combination of head rotation and conjugate saccade-like horizontal eye rotations(Meyer, O'Keefe et al., 2020, Michaiel, Abe et al., 2020). We also observed both forms of eye movements in the current study (Figure 4 —figure supplement 1). However, how these rotations combine with torsional rotations is not known. If mouse …”</p><disp-quote content-type="editor-comment"><p>3) Figures can be improved by labelling subpanels, as it is unclear what eg many of the circular plots represent without reading the caption.</p></disp-quote><p>With the aim of making the figures clearer we have now added labels on figure panels 1IandJ, 2E-H, 3BandE, 4D, F and I, 5A and 6C-E, as well as figure 1 supplement 1 panel H, all panels in figure 2 supplement 1 and figure 4 supplement 1 panels H, J, KandL. We feel this is a reasonable balance between adding clarity to the figures while not overcrowding.</p><disp-quote content-type="editor-comment"><p>4) The title is a bit misleading – it implies that mice are making active effort to use this region. Likewise, the abstract should note that both the specific retinal area and the optic flow pattern are direct consequences of running toward the cricket. And overall there is a lot of language that implies active targeting – the &quot;the image of the prey is kept on a specific area&quot;. Since this is a consequence of the pursuit, rather than active maintaining the gaze, we suggest language more like &quot;the image lands on a specific area&quot; or &quot;the image remains in a specific area&quot;.</p></disp-quote><p>We appreciate the reviewers concerns regarding implications about active targeting, and have made a number of modifications to address this throughout the document.</p><p>First, we have modified the title to “Visual pursuit behavior in mice maintains the pursued prey on the retinal region with least optic flow”.</p><p>With respect to the abstract, we would like to point out that the localization of the functional focus is not only a consequence of the mouse running directly toward the cricket, but rather a consequence of this behavior and the visual-stabilizing effect of the vestibular-ocular reflex. We have modified the abstract with this point in mind, as described in our response to point 1. Further, we have also made numerous modifications throughout the text to address this concern as also described in our response to point 1.</p><disp-quote content-type="editor-comment"><p>5) If the authors want to support the inherent claim that this region is important for visually guided pursuit, which would provide more a significant advance, then some type of causal test would be helpful. Most conclusive would be a precise manipulation such as Johnson et al., 2020, e.g. manipulating α ganglion cells, or alternatively a lesion of the functional focus or blinders to occlude the functional focus.</p></disp-quote><p>While we agree with the reviewers that a causal demonstration would reinforce the conclusion of the study, we do not think that there is an experimental design which allows the causality to be unequivocally established in this case, and further, the additional time delay imposed by the need to obtain both approval for new experiments and to acquire and control the required mouse lines or other experimental devices would preclude timely publication of the results in this study.</p><p>In addition, the primary difficulty in performing an experiment designed to demonstrate the causal link between a retinal region or ganglion cell type or subtype and a behavioral outcome, is the requirement that it can be unequivocally shown that any behavioral impairment is really due specifically to the intended manipulation and not to simply the loss of vision in part of the visual field. To take the example of the study by Johnson et al., 2021, while their manipulation should indeed cleanly eliminate the function of the ventro-temporal ipsilaterally projecting RGCs, the wide distribution of these neurons across the retina shown in their figure 3 would indicate that this inhibition may cause a very broad loss or impairment of vision across the animals visual field. This visual loss alone may disturb the animals’ behavior rather than the behavioral impairment being due to a deficit specifically in binocular vision or stereopsis. That this hunting behavior is predominantly a visual behavior would seem to be clear, and consequently showing that the behavior was impaired by a manipulation causing some form of loss of vision is perhaps not particularly compelling. The same logic applies also to manipulations involving either blinkering of the visual field or a lesion. A manipulation that selectively targeted the Α-ON sustained subset of Α RGCs (not all Α RCGs have an enhanced density in the dorso-temporal region (Bleckert 2014)) would provide considerable strength to the conclusion, however, we are not currently aware of a mouse line that would allow this specific manipulation and even if it were available the administration associated with performing the experiment would prevent timely publication of the current result. We will of course try to follow up on this in future studies.</p><disp-quote content-type="editor-comment"><p>6) The fact that the cricket does not land on the region of highest overall RGC density is a bit of an implausible strawman. Given that the cricket is in front of the mouse and that this region is located laterally (further than the amplitude of mouse eye movements) it's fairly clear that these will not overlap.</p></disp-quote><p>We acknowledge the reviewers point, but maintain that the comparison of the locations of the functional focus and density contours for all ganglion cells is a reasonable and impartial comparison which is of general interest. The abundance of RGCs contributing to the density distribution for all RGCs is numerically two orders of magnitude greater, and presumably has a substantial biological significance, for what, is now not clear.</p><p>We have modified the introductory heading to this part of the Results section and substantially re-written it with this criticism in mind, and have removed the section dealing with the rotations and errors required for the functional focus and overall RGC density contours to overlap, as we agree with the reviewers that this comparison is not necessary. We have also modified a section of the discussion dealing with this topic, and removed 4 panels from figure 3 supplement 1 (panels H-K) which also dealt with this.</p><p>This section now contains numerous small and some larger modifications and has not been reproduced here for the sake of space, however the section begins on page 9 with the modified heading “Relative locations of functional foci and ganglion cell density distributions”.</p><p>The modified Discussion reads:</p><p>page 19: “…of the mouse eye and optics. Using this we show that the location of the functional focus occurs within a dorso-temporal retinal region in an area with the highest density of Α-ON sustained RGCs, whose general properties have been previously proposed to be well suited for this purpose (Bleckert, Schwartz et al., 2014). Finally,…”</p><disp-quote content-type="editor-comment"><p>7) Johnson et al., (2021) provided a causal test demonstrating that mice not only use the binocular zone to pursue prey, but that the ipsi projecting RGCs that generate binocular receptive fields are necessary. This provides causal support for the findings demonstrated correlatively in this paper, yet this finding is not discussed beyond a reference to the fact that Johnson et al., also tracked head position during prey capture.</p></disp-quote><p>We understand the point of the reviewers but we somewhat disagree with the strength of the conclusions possible from the Johnson et al., (2021) manuscript. Firstly, ablation of the ipsilaterally-projecting RGCs did not extinguish the behavior, but rather reduced the probability of a successful capture when the mouse was in close proximity with the cricket and extended the total time required for capture. They provide strong evidence that these RGCs are involved in close-range interaction between the mouse and cricket, and it may be the case that these RGCs are required for binocular viewing, binocular correspondence or stereopsis at this range. By the same argumentation, we further think that to call this a “causal” demonstration is perhaps extending the reasonable conclusions from the Johnson et al., study a little beyond their intention; the mice could still successfully pursue and capture crickets in the absence of functional ipsilaterally-projecting RGCs and it was not determined by the Johnson et al., study whether this was residual visual ability or alternatively guided by tactile or olfactory cues.</p><p>With regard to methodology, Johnson et al., do not measure eye position directly but infer the animals’ visual fields from its head orientation, which they measure from lateral imaging. Without high resolution imaging and 3D triangulation it is difficult to accurately measure 3D changes in head orientation, and with this in mind we note that their estimate of average pitch in their study is close to double that reported in the current study and by other studies (Oommen and Stahl 2008, Michaiel, Abe et al., 2020).</p><p>We do acknowledge that the Johnson et al., study is very complimentary to the current study, in that they focus on the final phase of the capture behavior (mouse-cricket distance &lt; 6cm) while we specifically exclude this data (mouse-cricket distance &lt; 3cm) to avoid any misinterpretation arising from the animal using its tactile sense through the mystacial whiskers. Further, the data presented in our Figure 5A suggests that as the mouse approaches the cricket, the cricket image systematically drifts further and further toward the dorsal tip of the retinal region in which the ipsilaterally-projecting RGCs reside, which is supportive of a potential role for these RGCs in the final phase of the hunt where the cricket is in close proximity to the mouse.</p><p>We have now included an extended description of the points outlined in the paragraph above in the Discussion section as follows:</p><p>page 21: “…and employed by the mouse (Scholl, Burge et al., 2013, Scholl, Pattadkal et al., 2015, La Chioma, Bonhoeffer et al., 2019, Samonds, Choi et al., 2019, La Chioma, Bonhoeffer et al., 2020). Further supportive of the importance and relevance of the region of binocular overlap, another recent study provides strong evidence to suggest that ipsilaterally-projecting RGCs in the ventro-temporal retina are important in the final phase of cricket pursuit (mouse to cricket distance less than 6 cm), with selective ablation of these RGCs reducing the probability that coming into close proximity with the cricket resulted in its capture (Johnson, Fitzpatrick et al., 2021). This finding is complimentary to the current study, in that it deals with the section of the hunting behavior excluded from analysis in the current study, that being behavioral segments where the distance between mouse and cricket is &lt; 3cm. This criteria was used in the current study to mitigate the possibility that the mouse was using its mystacial whiskers to detect or assist in detection of the cricket location. In the current study we find that the location of the image of the cricket systematically shifts nasally and slightly ventrally on the cornea (temporally and slightly dorsally on the retina) as the mouse closes in on the cricket, and this may place the cricket’s image within the retinal region containing the ipsilaterally-projecting RGCs. As the mouse closes further, beyond our distance threshold, these RGCs may become increasingly important, particularly when the cricket is within grasping distance, where binocular vision and stereopsis may be most relevant.”</p><disp-quote content-type="editor-comment"><p>8) The authors emphasize that their setup eliminates auditory and olfactory cues. Is this essential to their results, i.e. do they find different targeting when these are not eliminated. Likewise, the title emphasizes visual pursuit, but does the cricket land on the same region when performing auditory pursuit (when controlled for pursuit accuracy?)</p></disp-quote><p>We conclude here that the functional focus observed is a consequence of both the behavioral strategy employed by the mice during pursuit and the VOR-based stabilization of the visual field during the animal’s movement. As mice use auditory, visual and olfactory cues during prey pursuit and can swap between modalities (Langley 1983, <italic>Animal Behaviour, 31</italic>, 199-205; Langley 1988, <italic>Behav Processes, 16</italic>, 67-73; Gire, Kapoor et al., 2016, <italic>Curr Biol, 26</italic>, 1261-1273) we removed any potential confound by conducting the experiments in the presence of olfactory and auditory noise. We did measure the time to capture with and without olfactory cues from the same mice and found that, as expected from the literature, without olfactory cues the mice took significantly longer than with olfactory cues present (Results section, page 6). There were no overt differences in behavior, but we did not record eye movements during these control experiments. Unless the animals changed their behavioral strategy when they have useful information from all senses available to them, we cannot see how the targeting would change, given the strong influence of the VOR on their eye position.</p><p>Regarding the image localization on the cornea in the case of auditory pursuit, while this is a very interesting point it is a bit beyond the scope of the current study. A reasonable initial expectation would be that the animal should employ a behavioral strategy for hunting which minimizes the energy expenditure during the pursuit and maximizes the probability of success. Assuming that the mouse can localize the cricket accurately, running directly towards it, as we observed in the current study, is presumably one way in which the required energy expenditure can be reduced or minimized. If we further assume that the mouse can localize the cricket accurately with its auditory sense alone, then the direct path to the cricket would be similar, resulting in similar targeting of the cricket in the eye view. This has the caveat that if the best orientation of the head for auditory-based localization is different to that for ideal visual localization, then the location of the cricket image on the cornea may be different as a consequence of the altered behavior. [Editors' note: further revisions were suggested prior to acceptance, as described below.]</p><disp-quote content-type="editor-comment"><p>Reviewer #2 (Recommendations for the authors):</p><p>The authors have overall done an excellent job of revising their claims to match the data and avoid misleading conclusions by readers. I have two remaining points that weren't fully addressed.</p><p>1. The authors have generally improved the wording in the text to avoid implying that mice are actively targeting the cricket to this region. However, this is still not very clearly stated in the abstract, which is what most people take away from a paper. Indeed, in their response, the authors state that their findings are best stated in the first paragraph of the discussion as &quot;The positional maintenance of the cricket was not achieved by active eye movements that followed the prey, but rather by the animal's change in behavior, specifically the head-movement and orientation towards the prey during pursuit.&quot; A statement along these lines in the abstract would be very effective, so that readers don't have to wait until the discussion to have this stated explicitly. If word length is the issue, I suggest finding something else to trim since as the authors themselves note, this is the best statement of the conclusion from their findings.</p></disp-quote><p>Thank you for the additional comments for clarification. We have now changed the abstract to include the following sentence:</p><p>“This functional focus coincides with the region of minimal optic flow within the visual field and consequently area of minimal motion-induced image-blur, as during pursuit mice ran directly toward the prey.”</p><disp-quote content-type="editor-comment"><p>2. In the public section of the original review, I noted that the fact that the cricket lands in the region of least motion blur was an almost trivial consequence of the fact that the mouse is running towards the cricket, and hence the cricket is at the focus of expansion (minimum of optic flow). However, this has not been addressed in the revision – I apologize if that is because it was in the public comments rather than author comments. However, it seems essential to address this so that readers do not think that this is an &quot;design principle&quot; of mouse vision. Unless the authors can provide a compelling argument for how this could not be the case, given the geometry of optic flow, then the statement that it lands on the region of least motion blur should be accompanied, in the abstract and elsewhere, by the clarification that this is a direct consequence of motion towards the cricket rather than a specific optimality.</p></disp-quote><p>We thank the reviewers for raising this point, which we had unfortunately overlooked and not directly responded to in our previous author comments. We had/have amended sections of the text to clarify for the reader that the overlap of the prey image and the region of minimal optic flow arises as a result of the animal’s motion towards the prey. In particular:</p><p>1. We have changed the wording of the abstract (please see point 1).</p><p>We have added an ending to the following sentence:</p><p>2. Introduction, Line (83): “The stabilized functional foci are spatially distinct from the regions of highest total retinal ganglion cell density, which are directed laterally, but coincides with the regions of the visual field where there is minimal optic flow and therefore minimal motion-induced image disturbance during the behavior as the mouse runs towards the cricket.”</p><p>In addition, in light of the previous reviewer comments, we had modified the text to:</p><p>3. Results: “Together this suggests that mice do not make compensatory vertical head movements, tracking eye movements or vergence eye movements to keep prey within their functional foci but instead retain their target within a restricted bearing by running straight towards it.</p><p>4. Results: “Together this shows that the behavioral strategy employed by mice during hunting, consisting of orienting themselves to directly face the prey and following a straight and direct course to it, results in the image of their prey coinciding with the region of reduced optic flow during pursuit, where the retinal image of their prey is least distorted due to motion induced image blur.”</p><p>5. Discussion: “The positional maintenance of the cricket was not achieved by active eye movements that followed the prey, but rather by the animal’s change in behavior, specifically the head-movement and orientation towards the prey during pursuit.”</p><p>6. Discussion: “Finally, we show that the region that contains these Α-ON sustained RGCs also coincides with the region of minimum optic flow and therefore reduced image blur during translation pursuit, a feature which would supports accurate localization of small targets by Α-ON sustained RGCs.”</p><p>7. Discussion: “In summary, we show here that during pursuit in mice the image of the preferentially keep their intended prey falls consistently in a localized region of their visual fields, referred to here as the functional focus, and that this occurs through the animal but do so by orientating their head and body and running directly towards the prey rather than with specific eye movements.”</p><p>As to the question as to whether or not this is a “design principle” of mouse vision we would suggest that it is hard to differentiate what is by design and what is not. In general, there is a tradeoff between panoramic field of view and eye-position in the head, which in addition, at least for the mouse and rat, is stabilized by a strong VOR. These factors undoubtably aid the rodents in survival and in many respects dictate how vision is used by the animal. Together with the topographical differences in the retinal densities of some functionally important retinal cell types, this means that cells tuned for tuned some specific tasks will sample different regions of visual space (Baden et al., 2016; Bleckert et al., 2014; Hughes, 1977; Sabbah et al., 2017; Szatko et al., 2020; Franke et al., 2017; Zhang et al., 2012, Szel et al., 1992). Dorso-ventral differences in cone subtype aid contrast detection of objects in the sky (Baden 2013), W3 cells in the ventral retina aid detection of prey in the sky (Zhang et al., 2012) and the orientation and location of direction selective RGCs in the retina align with the orientation of idealized optic flow fields (Sabbah et al., 2017). Spectral differences in UV in ground vs sky and specific features of the aerial predator may be selective evolutionary pressures in the first two cases, while in the latter case, the characteristics of optic flow during forward translational motion may be a part of the evolutionary pressure influencing the direction selective RGCs. Similarly, for visualization of objects in the ventro-medial visual field, the properties of the optic flow fields produced as the mouse runs forwards towards its target may be a selective pressure on VOR-stabilized RGCs in the dorso-temporal retina.</p><p>With regards to the point that it seems ‘trivial’ that the location of the functional focus and the region of least optic flow coincide, our suggestion is that this results from a behavioral strategy employed by the mouse, that being to run directly at the cricket. This need not have been the case. The mouse could theoretically instead have used a strategy of predicting the future position of the cricket based on the cricket’s current trajectory and speed and run at that. This would result in the cricket being outside the region of minimal optic flow.</p><p>In both cases these points are more speculative and we have therefore not included them in the Discussion section.</p><disp-quote content-type="editor-comment"><p>I also suggest revising the title to emphasize a more compelling finding (e.g. α RGCs), but if the authors want to continue to use this title, accompanied by appropriate explanation in the abstract, then that is their prerogative.</p></disp-quote><p>While we are very curious about the overlap of the functional focus and the reported high density-region of Α-ONsustained retinal ganglion cells, we think that it is a bit premature at this stage to put this in the title. Consequently, we have elected to keep the current title but have changed the abstract as requested (please see point 1).</p></body></sub-article></article>