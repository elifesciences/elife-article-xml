<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD with MathML3 v1.3 20210610//EN"  "JATS-archivearticle1-3-mathml3.dtd"><article xmlns:ali="http://www.niso.org/schemas/ali/1.0/" xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" article-type="research-article" dtd-version="1.3"><front><journal-meta><journal-id journal-id-type="nlm-ta">elife</journal-id><journal-id journal-id-type="publisher-id">eLife</journal-id><journal-title-group><journal-title>eLife</journal-title></journal-title-group><issn publication-format="electronic" pub-type="epub">2050-084X</issn><publisher><publisher-name>eLife Sciences Publications, Ltd</publisher-name></publisher></journal-meta><article-meta><article-id pub-id-type="publisher-id">87881</article-id><article-id pub-id-type="doi">10.7554/eLife.87881</article-id><article-id pub-id-type="doi" specific-use="version">10.7554/eLife.87881.4</article-id><article-categories><subj-group subj-group-type="display-channel"><subject>Research Article</subject></subj-group><subj-group subj-group-type="heading"><subject>Neuroscience</subject></subj-group></article-categories><title-group><article-title>Revealing unexpected complex encoding but simple decoding mechanisms in motor cortex via separating behaviorally relevant neural signals</article-title></title-group><contrib-group><contrib contrib-type="author"><name><surname>Li</surname><given-names>Yangang</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">https://orcid.org/0000-0002-7271-2993</contrib-id><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="aff" rid="aff2">2</xref><xref ref-type="aff" rid="aff3">3</xref><xref ref-type="aff" rid="aff4">4</xref><xref ref-type="fn" rid="con1"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author"><name><surname>Zhu</surname><given-names>Xinyun</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">https://orcid.org/0009-0007-3820-4761</contrib-id><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="aff" rid="aff2">2</xref><xref ref-type="aff" rid="aff3">3</xref><xref ref-type="aff" rid="aff4">4</xref><xref ref-type="fn" rid="con2"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" corresp="yes"><name><surname>Qi</surname><given-names>Yu</given-names></name><email>qiyu@zju.edu.cn</email><xref ref-type="aff" rid="aff2">2</xref><xref ref-type="aff" rid="aff3">3</xref><xref ref-type="aff" rid="aff4">4</xref><xref ref-type="aff" rid="aff5">5</xref><xref ref-type="fn" rid="con3"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" corresp="yes"><name><surname>Wang</surname><given-names>Yueming</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">https://orcid.org/0000-0001-7742-0722</contrib-id><email>ymingwang@zju.edu.cn</email><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="aff" rid="aff2">2</xref><xref ref-type="aff" rid="aff3">3</xref><xref ref-type="aff" rid="aff4">4</xref><xref ref-type="aff" rid="aff5">5</xref><xref ref-type="fn" rid="fn1">†</xref><xref ref-type="other" rid="fund1"/><xref ref-type="other" rid="fund3"/><xref ref-type="fn" rid="con4"/><xref ref-type="fn" rid="conf1"/></contrib><aff id="aff1"><label>1</label><institution-wrap><institution-id institution-id-type="ror">https://ror.org/00a2xv884</institution-id><institution>Qiushi Academy for Advanced Studies, Zhejiang University</institution></institution-wrap><addr-line><named-content content-type="city">Hangzhou</named-content></addr-line><country>China</country></aff><aff id="aff2"><label>2</label><institution>Nanhu Brain-Computer Interface Institute</institution><addr-line><named-content content-type="city">Hangzhou</named-content></addr-line><country>China</country></aff><aff id="aff3"><label>3</label><institution-wrap><institution-id institution-id-type="ror">https://ror.org/00a2xv884</institution-id><institution>College of Computer Science and Technology, Zhejiang University</institution></institution-wrap><addr-line><named-content content-type="city">Hangzhou</named-content></addr-line><country>China</country></aff><aff id="aff4"><label>4</label><institution-wrap><institution-id institution-id-type="ror">https://ror.org/00a2xv884</institution-id><institution>The State Key Lab of Brain-Machine Intelligence, Zhejiang University</institution></institution-wrap><addr-line><named-content content-type="city">Hangzhou</named-content></addr-line><country>China</country></aff><aff id="aff5"><label>5</label><institution-wrap><institution-id institution-id-type="ror">https://ror.org/0310dsa24</institution-id><institution>Affiliated Mental Health Center &amp; Hangzhou Seventh People’s Hospital and the MOE Frontier Science Center for Brain Science and Brain-Machine Integration, Zhejiang University School of Medicine</institution></institution-wrap><addr-line><named-content content-type="city">Hangzhou</named-content></addr-line><country>China</country></aff></contrib-group><contrib-group content-type="section"><contrib contrib-type="editor"><name><surname>Gallego</surname><given-names>Juan Alvaro</given-names></name><role>Reviewing Editor</role><aff><institution-wrap><institution-id institution-id-type="ror">https://ror.org/041kmwe10</institution-id><institution>Imperial College London</institution></institution-wrap><country>United Kingdom</country></aff></contrib><contrib contrib-type="senior_editor"><name><surname>Makin</surname><given-names>Tamar R</given-names></name><role>Senior Editor</role><aff><institution-wrap><institution-id institution-id-type="ror">https://ror.org/013meh722</institution-id><institution>University of Cambridge</institution></institution-wrap><country>United Kingdom</country></aff></contrib></contrib-group><author-notes><fn fn-type="other" id="fn1"><label>†</label><p>Lead contact</p></fn></author-notes><pub-date publication-format="electronic" date-type="publication"><day>09</day><month>08</month><year>2024</year></pub-date><volume>12</volume><elocation-id>RP87881</elocation-id><history><date date-type="sent-for-review" iso-8601-date="2023-05-08"><day>08</day><month>05</month><year>2023</year></date></history><pub-history><event><event-desc>This manuscript was published as a preprint.</event-desc><date date-type="preprint" iso-8601-date="2023-05-09"><day>09</day><month>05</month><year>2023</year></date><self-uri content-type="preprint" xlink:href="https://doi.org/10.1101/2022.11.13.515644"/></event><event><event-desc>This manuscript was published as a reviewed preprint.</event-desc><date date-type="reviewed-preprint" iso-8601-date="2023-07-14"><day>14</day><month>07</month><year>2023</year></date><self-uri content-type="reviewed-preprint" xlink:href="https://doi.org/10.7554/eLife.87881.1"/></event><event><event-desc>The reviewed preprint was revised.</event-desc><date date-type="reviewed-preprint" iso-8601-date="2024-02-02"><day>02</day><month>02</month><year>2024</year></date><self-uri content-type="reviewed-preprint" xlink:href="https://doi.org/10.7554/eLife.87881.2"/></event><event><event-desc>The reviewed preprint was revised.</event-desc><date date-type="reviewed-preprint" iso-8601-date="2024-07-18"><day>18</day><month>07</month><year>2024</year></date><self-uri content-type="reviewed-preprint" xlink:href="https://doi.org/10.7554/eLife.87881.3"/></event></pub-history><permissions><copyright-statement>© 2023, Li et al</copyright-statement><copyright-year>2023</copyright-year><copyright-holder>Li et al</copyright-holder><ali:free_to_read/><license xlink:href="http://creativecommons.org/licenses/by/4.0/"><ali:license_ref>http://creativecommons.org/licenses/by/4.0/</ali:license_ref><license-p>This article is distributed under the terms of the <ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/licenses/by/4.0/">Creative Commons Attribution License</ext-link>, which permits unrestricted use and redistribution provided that the original author and source are credited.</license-p></license></permissions><self-uri content-type="pdf" xlink:href="elife-87881-v1.pdf"/><self-uri content-type="figures-pdf" xlink:href="elife-87881-figures-v1.pdf"/><abstract><p>In motor cortex, behaviorally relevant neural responses are entangled with irrelevant signals, which complicates the study of encoding and decoding mechanisms. It remains unclear whether behaviorally irrelevant signals could conceal some critical truth. One solution is to accurately separate behaviorally relevant and irrelevant signals at both single-neuron and single-trial levels, but this approach remains elusive due to the unknown ground truth of behaviorally relevant signals. Therefore, we propose a framework to define, extract, and validate behaviorally relevant signals. Analyzing separated signals in three monkeys performing different reaching tasks, we found neural responses previously considered to contain little information actually encode rich behavioral information in complex nonlinear ways. These responses are critical for neuronal redundancy and reveal movement behaviors occupy a higher-dimensional neural space than previously expected. Surprisingly, when incorporating often-ignored neural dimensions, behaviorally relevant signals can be decoded linearly with comparable performance to nonlinear decoding, suggesting linear readout may be performed in motor cortex. Our findings prompt that separating behaviorally relevant signals may help uncover more hidden cortical mechanisms.</p></abstract><kwd-group kwd-group-type="author-keywords"><kwd>neural signal separation</kwd><kwd>neural encoding</kwd><kwd>neural decoding</kwd></kwd-group><kwd-group kwd-group-type="research-organism"><title>Research organism</title><kwd>Rhesus macaque</kwd></kwd-group><funding-group><award-group id="fund1"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/501100001809</institution-id><institution>National Natural Science Foundation of China</institution></institution-wrap></funding-source><award-id>no. 62336007</award-id><principal-award-recipient><name><surname>Wang</surname><given-names>Yueming</given-names></name></principal-award-recipient></award-group><award-group id="fund2"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/100022963</institution-id><institution>Key Research and Development Program of Zhejiang</institution></institution-wrap></funding-source><award-id>no. 2022C03011</award-id><principal-award-recipient><name><surname>Wang</surname><given-names>Yueming</given-names></name></principal-award-recipient></award-group><award-group id="fund3"><funding-source><institution-wrap><institution>Starry Night Science Fund of Zhejiang University Shanghai Institute for Advanced Study</institution></institution-wrap></funding-source><award-id>SN-ZJU-SIAS-002</award-id><principal-award-recipient><name><surname>Wang</surname><given-names>Yueming</given-names></name></principal-award-recipient></award-group><award-group id="fund4"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/501100012226</institution-id><institution>Fundamental Research Funds for the Central Universities</institution></institution-wrap></funding-source><principal-award-recipient><name><surname>Wang</surname><given-names>Yueming</given-names></name></principal-award-recipient></award-group><funding-statement>The funders had no role in study design, data collection and interpretation, or the decision to submit the work for publication.</funding-statement></funding-group><custom-meta-group><custom-meta specific-use="meta-only"><meta-name>Author impact statement</meta-name><meta-value>Separating behaviorally relevant signals from irrelevant signals reveals that neural signals previously considered to contain little information encode rich information and suggests that linear readout may be performed in motor cortex.</meta-value></custom-meta><custom-meta specific-use="meta-only"><meta-name>publishing-route</meta-name><meta-value>prc</meta-value></custom-meta></custom-meta-group></article-meta></front><body><sec id="s1" sec-type="intro"><title>Introduction</title><p>Understanding how motor cortex encodes and decodes movement behaviors is a fundamental goal of neuroscience (<xref ref-type="bibr" rid="bib30">Kriegeskorte and Douglas, 2019</xref>; <xref ref-type="bibr" rid="bib48">Saxena and Cunningham, 2019</xref>). Here, we define behaviors as behavioral variables of interest measured within a given task, such as arm kinematics during a motor control task; we employ terms like ‘behaviorally relevant’ and ‘behaviorally irrelevant’ only regarding such measured behavioral variables. However, achieving this goal faces significant challenges because behaviorally relevant neural responses are entangled with behaviorally irrelevant factors such as responses for other variables of no interest (<xref ref-type="bibr" rid="bib14">Fusi et al., 2016</xref>; <xref ref-type="bibr" rid="bib44">Rigotti et al., 2013</xref>) and ongoing noise (<xref ref-type="bibr" rid="bib3">Azouz and Gray, 1999</xref>; <xref ref-type="bibr" rid="bib13">Faisal et al., 2008</xref>). Generally, irrelevant signals would hinder the accurate investigation of the relationship between neural activity and movement behaviors. This raises concerns about whether irrelevant signals could conceal some critical facts about neural encoding and decoding mechanisms.</p><p>If the answer is yes, a natural question arises: what critical facts about neural encoding and decoding would irrelevant signals conceal? In terms of neural encoding, irrelevant signals may mask some small neural components, making their encoded information difficult to detect (<xref ref-type="bibr" rid="bib34">Moreno-Bote et al., 2014</xref>), thereby misleading us to neglect the role of these signals, leading to a partial understanding of neural mechanisms. For example, at the single-neuron level, weakly tuned neurons are often assumed to contain little information and not analyzed (<xref ref-type="bibr" rid="bib19">Georgopoulos et al., 1986</xref>; <xref ref-type="bibr" rid="bib23">Hochberg et al., 2012</xref>; <xref ref-type="bibr" rid="bib56">Wodlinger et al., 2015</xref>; <xref ref-type="bibr" rid="bib25">Inoue et al., 2018</xref>); at the population level, neural signals composed of lower variance principal components (PCs) are typically treated as noise and discarded (<xref ref-type="bibr" rid="bib6">Churchland et al., 2012</xref>; <xref ref-type="bibr" rid="bib16">Gallego et al., 2018</xref>; <xref ref-type="bibr" rid="bib17">Gallego et al., 2020</xref>; <xref ref-type="bibr" rid="bib8">Cunningham and Yu, 2014</xref>). So, do these ignored signals truly contain little information, or do they appear that way only because they are obscured by irrelevant signals? And what’s the role of these ignored signals? In terms of neural decoding, irrelevant signals would significantly complicate the information readout (<xref ref-type="bibr" rid="bib43">Pitkow et al., 2015</xref>; <xref ref-type="bibr" rid="bib58">Yang et al., 2021</xref>), potentially hindering the discovery of the true readout mechanism of behaviorally relevant responses. Specifically, in motor cortex, in what form (linear or nonlinear) downstream neurons readout behavioral information is an open question. Current studies typically use noisy raw signals for decoding behavioral information (<xref ref-type="bibr" rid="bib19">Georgopoulos et al., 1986</xref>; <xref ref-type="bibr" rid="bib23">Hochberg et al., 2012</xref>; <xref ref-type="bibr" rid="bib56">Wodlinger et al., 2015</xref>; <xref ref-type="bibr" rid="bib20">Glaser et al., 2020</xref>; <xref ref-type="bibr" rid="bib55">Willsey et al., 2022</xref>). The linear readout is biologically plausible and widely used (<xref ref-type="bibr" rid="bib19">Georgopoulos et al., 1986</xref>; <xref ref-type="bibr" rid="bib23">Hochberg et al., 2012</xref>; <xref ref-type="bibr" rid="bib56">Wodlinger et al., 2015</xref>), but recent studies (<xref ref-type="bibr" rid="bib20">Glaser et al., 2020</xref>; <xref ref-type="bibr" rid="bib55">Willsey et al., 2022</xref>) demonstrate nonlinear readout outperforms linear readout. So which readout scheme is the motor cortex more likely to adopt for decoding information from behaviorally relevant signals? Whether irrelevant signals are the culprits for the performance gap observed with raw signals? Unfortunately, all the above issues remain unclear.</p><p>One approach to address the above issues is to accurately separate behaviorally relevant and irrelevant signals at both single-neuron and single-trial levels and then analyze noise-free behaviorally relevant signals, which enables us to gain a more accurate and comprehensive understanding of the underlying neural mechanisms. However, this approach is hampered by the fact that the ground truth of behaviorally relevant signals is unknown, which makes the definition, extraction, and validation of behaviorally relevant signals a challenging task. As a result, methods of accurate separation remain elusive to date. Existing methods for extracting behaviorally relevant patterns at the single-trial level mainly focus on the latent population level (<xref ref-type="bibr" rid="bib47">Sani et al., 2021</xref>; <xref ref-type="bibr" rid="bib24">Hurwitz, 2021</xref>; <xref ref-type="bibr" rid="bib62">Zhou, 2020</xref>) rather than the single-neuron level, and they extract neural activities based on assumptions about specific neural properties, such as linear or nonlinear dynamics (<xref ref-type="bibr" rid="bib47">Sani et al., 2021</xref>; <xref ref-type="bibr" rid="bib24">Hurwitz, 2021</xref>). Although these methods have shown promising results, they fail to capture other parts of behaviorally relevant neural activity that do not meet their assumptions, thereby providing an incomplete picture of behaviorally relevant neural activity. Some studies (<xref ref-type="bibr" rid="bib29">Kobak et al., 2016</xref>; <xref ref-type="bibr" rid="bib45">Rouse and Schieber, 2018</xref>) are able to extract behaviorally relevant neural signals at the single-neuron level, but they utilize trial-averaged responses, thereby losing the single-trial information. To overcome these limitations and obtain accurate behaviorally relevant signals at both single-neuron and single-trial levels, we propose a novel framework that defines, extracts, and validates behaviorally relevant signals by simultaneously considering such signals’ encoding (behaviorally relevant signals should be similar to raw signals to preserve the underlying neuronal properties) and decoding (behaviorally relevant signals should contain behavioral information as much as possible) properties (see Methods and <xref ref-type="fig" rid="fig1">Figure 1</xref>). This framework establishes a prerequisite foundation for the subsequent detailed analysis of neural mechanisms.</p><fig-group><fig id="fig1" position="float"><label>Figure 1.</label><caption><title>Semantic illustration of extracting and validating behaviorally relevant signals.</title><p>(<bold>a–e</bold>) The ideal decomposition of raw signals. (<bold>a</bold>) The temporal neuronal activity of raw signals, where x-axis denotes time, and y-axis represents firing rate. Raw signals are decomposed to relevant (<bold>b</bold>) and irrelevant (<bold>d</bold>) signals. The red dotted line indicates the decoding performance of raw signals. The red and blue bars represent the decoding performance of relevant and irrelevant signals. The purple bar represents the reconstruction performance of relevant signals, which measures the neural similarity between generated signals and raw signals. The longer the bar, the larger the performance. The ground truth of relevant signals decodes information perfectly (<bold>c</bold>, red bar) and is similar to raw signals to some extent (<bold>c</bold>, purple bar), and the ground truth of irrelevant signals contains little behavioral information (<bold>e</bold>, blue bar). (<bold>f–h</bold>) Three different cases of behaviorally relevant signals distillation. (<bold>f</bold>) When the model is biased toward generating relevant signals that are similar to raw signals, it will achieve high reconstruction performance, but the decoding performance will suffer due to the inclusion of too many irrelevant signals. As it is difficult for models to extract complete relevant signals, the residuals will also contain some behavioral information. (<bold>g</bold>) When the model is biased toward generating signals that prioritize decoding over similarity to raw signals, it will achieve high decoding performance, but the reconstruction performance will be low. Meanwhile, the residuals will contain a significant amount of behavioral information. (<bold>h</bold>) When the model balances the trade-off of decoding and reconstruction capabilities of relevant signals, both decoding and reconstruction performance will be good, and the residuals will only contain a little behavioral information.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-87881-fig1-v1.tif"/></fig><fig id="fig1s1" position="float" specific-use="child-fig"><label>Figure 1—figure supplement 1.</label><caption><title>Semantic overview of distill-variational autoencoder (d-VAE).</title><p>On the left, we present a set of raw signal examples (depicted by purple lines). The input neural signals fed into the d-VAE consist of single time step samples. Initially, the encoder compresses these input signals into latent variables. We constrain latent variables to decode behaviors to preserve behavioral information. Subsequently, these latent variables are transmitted to the generator, which produces behaviorally relevant signals (depicted by red lines). To maintain the underlying neuronal properties, we constrain these generated signals to resemble the raw signals closely. At this juncture, relying solely on the constraint for signal resemblance to raw signals makes it challenging to determine the extent of irrelevant signals present within the generated relevant signals. To tackle this hurdle, we introduce the generated signals back into the encoder. We then impose constraints on the resultant latent variables to decode behaviors. This approach is rooted in the assumption that irrelevant signals function as noise relative to relevant signals. Consequently, an excessive presence of irrelevant signals within the generated signals would lead to a degradation in their decoding performance. In essence, there exists a trade-off relationship between the decoding performance and the reconstruction performance of the generated signals. By striking a balance between these two constraints, we can effectively extract behaviorally relevant signals.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-87881-fig1-figsupp1-v1.tif"/></fig><fig id="fig1s2" position="float" specific-use="child-fig"><label>Figure 1—figure supplement 2.</label><caption><title>Visualization of latent variables.</title><p>(<bold>a</bold>) The velocity samples of onefold test data. Different colors denote different directions of the eight-direction center-out. (<bold>b</bold>) The distribution plot of the top three principal components (PCs) of latent variables. The points on the bottom plane represent the two-dimensional projections of the three-dimensional data. (<bold>c</bold>) The distribution plot of the top three PCs of learned prior latent variables. We can see that the distribution of prior latent variables closely resembles that of latent variables, thus illustrating the effectiveness of the Kullback-Leibler (KL) divergence.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-87881-fig1-figsupp2-v1.tif"/></fig></fig-group><p>Here, we conducted experiments using datasets recorded from the motor cortex of three monkeys performing different reaching tasks, where the behavioral variable is movement kinematics. After signal separation by our approach, we first explored how the presence of behaviorally irrelevant signals affects the analysis of neural activity. We found that behaviorally irrelevant signals account for a large amount of trial-to-trial neuronal variability, and are evenly distributed across the neural dimensions of behaviorally relevant signals. Then, we explored whether irrelevant signals conceal some facts of neural encoding and decoding. For neural encoding, irrelevant signals obscure the behavioral information encoded by neural responses, especially for neural responses with a large degree of nonlinearity. Surprisingly, neural responses that are usually ignored (weakly tuned neurons and neural signals composed of small variance PCs) actually encode rich behavioral information in complex nonlinear ways. These responses underpin an unprecedented neuronal redundancy and reveal that movement behaviors are distributed in a higher-dimensional neural space than previously thought. In addition, we found that the integration of smaller and larger variance PCs results in a synergistic effect, allowing the smaller variance PC signals that cannot be linearly decoded to significantly enhance the linear decoding performance, particularly for finer speed control. This finding suggests that lower variance PC signals are involved in regulating precise motor control. For neural decoding, irrelevant signals complicate information readout. Strikingly, when uncovering small neural components obscured by irrelevant signals, linear decoders can achieve comparable decoding performance with nonlinear decoders, providing strong evidence for the presence of linear readout in motor cortex. Together, our findings reveal unexpected complex encoding but simple decoding mechanisms in the motor cortex. Finally, our study also has implications for developing accurate and robust brain-machine interfaces (BMIs) and, more generally, provides a powerful framework for separating behaviorally relevant and irrelevant signals, which can be applied to other cortical data to uncover more neural mechanisms masked by behaviorally irrelevant signals.</p></sec><sec id="s2" sec-type="results"><title>Results</title><sec id="s2-1"><title>Framework for defining, extracting, and validating behaviorally relevant neural signals</title><sec id="s2-1-1"><title>What are behaviorally relevant neural signals?</title><p>Since the ground truth of behaviorally relevant signals is unknown, their precise definition is not yet well established. Before a definition is established, it is essential to first differentiate between relevant and irrelevant signals. Behaviorally irrelevant signals refer to those not directly associated with the behavioral variables of interest and may include noise or signals from variables of no interest. In contrast, behaviorally relevant signals refer to those directly related to the behavioral variables of interest.</p><p>Here, we define behaviorally relevant signals based on the following two requirements: (1) they should closely resemble raw signals to preserve the underlying neuronal properties, without becoming so similar that they include irrelevant signals (encoding requirement), and (2) they should contain behavioral information as much as possible (decoding requirement). Signals that meet both requirements are considered effective behaviorally relevant signals.</p><p>In this study, we assume raw signals (<xref ref-type="fig" rid="fig1">Figure 1a</xref>) are additively composed of behaviorally relevant (<xref ref-type="fig" rid="fig1">Figure 1b</xref>) and irrelevant (<xref ref-type="fig" rid="fig1">Figure 1d</xref>) signals. Thus, behaviorally irrelevant signals are derived by subtracting the behaviorally relevant signals from raw signals.</p></sec><sec id="s2-1-2"><title>How to extract behaviorally relevant signals?</title><p>One way to extract behaviorally relevant signals is to use a distillation model to generate them from raw signals while considering the remaining signals as behaviorally irrelevant. However, due to the unknown ground truth of behaviorally relevant signals, a key challenge for the model is to determine the optimal degree of similarity between the generated signals and raw signals. If the generated signals are too similar to raw signals, they may contain a large amount of irrelevant information, which would hinder the exploration of neural mechanisms. Conversely, if the generated signals are too dissimilar to raw signals, they may lose behaviorally relevant information, also hindering the exploration of neural mechanisms. Therefore, finding the appropriate prior regularization knowledge to constrain the generated signals to resemble raw signals appropriately is key to modeling. We have formalized this extraction process as the following optimization problem:<disp-formula id="equ1"><label>(1)</label><mml:math id="m1"><mml:mrow><mml:mstyle displaystyle="true" scriptlevel="0"><mml:munder><mml:mrow><mml:mtext>min</mml:mtext></mml:mrow><mml:mrow><mml:msub><mml:mi mathvariant="bold-italic">x</mml:mi><mml:mi>r</mml:mi></mml:msub></mml:mrow></mml:munder><mml:mo>⁡</mml:mo><mml:mrow><mml:mi mathvariant="normal">E</mml:mi></mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi mathvariant="bold-italic">x</mml:mi><mml:mi>r</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:mi mathvariant="bold-italic">x</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>+</mml:mo><mml:mrow><mml:mi mathvariant="normal">R</mml:mi></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi mathvariant="bold-italic">x</mml:mi><mml:mi>r</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:mo>,</mml:mo></mml:mstyle></mml:mrow></mml:math></disp-formula></p><p>where <inline-formula><mml:math id="inf1"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi mathvariant="bold-italic">x</mml:mi></mml:mrow></mml:mstyle></mml:math></inline-formula> denotes raw signals, <inline-formula><mml:math id="inf2"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi mathvariant="bold-italic">x</mml:mi><mml:mrow><mml:mi>r</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula> denotes generated signals, <inline-formula><mml:math id="inf3"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mrow><mml:mi mathvariant="normal">E</mml:mi></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mo>⋅</mml:mo><mml:mo>,</mml:mo><mml:mo>⋅</mml:mo><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mstyle></mml:math></inline-formula> denotes reconstruction error, <inline-formula><mml:math id="inf4"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi mathvariant="normal">R</mml:mi></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mo>⋅</mml:mo><mml:mo stretchy="false">)</mml:mo></mml:mstyle></mml:math></inline-formula> denotes regularization loss. The regularization constraint on the generated signals <inline-formula><mml:math id="inf5"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mrow><mml:mi mathvariant="normal">R</mml:mi></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi mathvariant="bold-italic">x</mml:mi><mml:mrow><mml:mi>r</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mstyle></mml:math></inline-formula> is crucial for accurately extracting behaviorally relevant signals. However, existing works (<xref ref-type="bibr" rid="bib47">Sani et al., 2021</xref>; <xref ref-type="bibr" rid="bib24">Hurwitz, 2021</xref>; <xref ref-type="bibr" rid="bib62">Zhou, 2020</xref>) have not identified and addressed this key challenge.</p><p>To overcome this challenge, we exploited the trade-off between the similarity of generated signals to raw signals (encoding requirement) and their decoding performance of behaviors (decoding requirement) to extract effective behaviorally relevant signals (for details, see Methods and <xref ref-type="fig" rid="fig1s1">Figure 1—figure supplement 1</xref>). The core assumption of our model is that behaviorally irrelevant signals are noise relative to behaviorally relevant signals, and thereby irrelevant signals would degrade the decoding generalization of generated behaviorally relevant signals. Based on this assumption, we imposed decoding constraints to the generated signals <inline-formula><mml:math id="inf6"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi mathvariant="bold-italic">x</mml:mi><mml:mrow><mml:mi>r</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula> to minimize the inclusion of irrelevant signals, which is the operation used for modeling <inline-formula><mml:math id="inf7"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mrow><mml:mi mathvariant="normal">R</mml:mi></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi mathvariant="bold-italic">x</mml:mi><mml:mrow><mml:mi>r</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mstyle></mml:math></inline-formula>.</p><p>Generally, the distillation model is faced with three cases: a bias toward reconstructing raw signals (<xref ref-type="fig" rid="fig1">Figure 1f</xref>), a bias toward decoding behaviors (<xref ref-type="fig" rid="fig1">Figure 1g</xref>), and a proper trade-off between reconstruction and decoding (<xref ref-type="fig" rid="fig1">Figure 1h</xref>). If the distillation model is biased toward extracting signals similar to raw signals, the distilled behaviorally relevant signals will contain an excessive amount of behaviorally irrelevant information, affecting the decoding generalization of these signals (<xref ref-type="fig" rid="fig1">Figure 1f</xref>). If the model is biased toward extracting parsimonious signals that are discriminative for decoding, the distilled signals will not be similar enough to raw signals, and some redundant but useful signals will be left in the residuals (<xref ref-type="fig" rid="fig1">Figure 1g</xref>), making irrelevant signals contain much behavioral information. Using face recognition as an example, if a model can accurately identify an individual using only the person’s eyes (assuming these are the most useful features), other useful information such as the nose or mouth will be left in the residuals, which could also be used to identify the individual. Neither of these two cases is desirable because the former loses decoding performance, while the latter loses some useful neural signals, which are not conducive to our subsequent analysis of the relationship between behaviorally relevant signals and behaviors. The behaviorally relevant signals we want should be similar to raw signals and preserve the behavioral information maximally, which can be obtained by balancing the encoding and decoding properties of generated behaviorally relevant signals (<xref ref-type="fig" rid="fig1">Figure 1h</xref>).</p></sec><sec id="s2-1-3"><title>How to validate behaviorally relevant signals?</title><p>To validate the effectiveness of the distilled signals, we proposed three criteria. The first criterion is that the decoding performance of the behaviorally relevant signals (red bar, <xref ref-type="fig" rid="fig1">Figure 1</xref>) should surpass that of raw signals (the red dotted line, <xref ref-type="fig" rid="fig1">Figure 1</xref>). Since decoding models, such as deep neural networks, are more prone to overfit noisy raw signals than behaviorally relevant signals, the distilled signals should demonstrate better decoding generalization than the raw signals. The second criterion is that the behaviorally irrelevant signals should contain minimal behavioral information (blue bar, <xref ref-type="fig" rid="fig1">Figure 1</xref>). This criterion can assess whether the distilled signals maximally preserve behavioral information from the opposite perspective and effectively exclude undesirable cases, such as over-generated and under-generated signals. Specifically, in the case of over-generation, suppose <inline-formula><mml:math id="inf8"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>z</mml:mi><mml:mo>=</mml:mo><mml:mi>x</mml:mi><mml:mo>+</mml:mo><mml:mi>y</mml:mi></mml:mstyle></mml:math></inline-formula>, where <inline-formula><mml:math id="inf9"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>z</mml:mi></mml:mstyle></mml:math></inline-formula>, <inline-formula><mml:math id="inf10"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>x</mml:mi></mml:mstyle></mml:math></inline-formula>, and <inline-formula><mml:math id="inf11"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>y</mml:mi></mml:mstyle></mml:math></inline-formula> represent raw, relevant, and irrelevant signals, respectively. If the distilled relevant signals <inline-formula><mml:math id="inf12"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow class="MJX-TeXAtom-ORD"><mml:mover><mml:mi>x</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow></mml:mstyle></mml:math></inline-formula> are added extra signals <inline-formula><mml:math id="inf13"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>m</mml:mi></mml:mstyle></mml:math></inline-formula> which do not exist in the real behaviorally relevant signals, i.e., <inline-formula><mml:math id="inf14"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow class="MJX-TeXAtom-ORD"><mml:mover><mml:mi>x</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mo>=</mml:mo><mml:mi>x</mml:mi><mml:mo>+</mml:mo><mml:mi>m</mml:mi></mml:mstyle></mml:math></inline-formula>, then the corresponding residuals <inline-formula><mml:math id="inf15"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow class="MJX-TeXAtom-ORD"><mml:mover><mml:mi>y</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow></mml:mstyle></mml:math></inline-formula> will be equal to the ideal irrelevant signals <inline-formula><mml:math id="inf16"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>y</mml:mi></mml:mstyle></mml:math></inline-formula> plus the negative extra signals <inline-formula><mml:math id="inf17"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mo>−</mml:mo><mml:mi>m</mml:mi></mml:mstyle></mml:math></inline-formula>, namely, <inline-formula><mml:math id="inf18"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow class="MJX-TeXAtom-ORD"><mml:mover><mml:mi>y</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mo>=</mml:mo><mml:mi>y</mml:mi><mml:mo>−</mml:mo><mml:mi>m</mml:mi></mml:mstyle></mml:math></inline-formula>, thus the residuals <inline-formula><mml:math id="inf19"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow class="MJX-TeXAtom-ORD"><mml:mover><mml:mi>y</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow></mml:mstyle></mml:math></inline-formula> contain the amount of information preserved by negative extra signals <inline-formula><mml:math id="inf20"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mo>−</mml:mo><mml:mi>m</mml:mi></mml:mstyle></mml:math></inline-formula>. Similarly, in the case of under-generation, if the distilled behaviorally relevant signals are incomplete and lose some useful information, this lost information will also be reflected in the residuals. In these cases, the distilled signals are not suitable for analysis. The third criterion is that the distilled behaviorally relevant signals should be similar to raw signals to maintain essential neuronal properties (purple bar, <xref ref-type="fig" rid="fig1">Figure 1</xref>). If the distilled signals do not resemble raw signals, they fail to retain the fundamental characteristics of raw signals, which are not qualified for subsequent analysis. Overall, if the distilled signals satisfy the above three criteria, we consider the distilled signals to be effective.</p></sec></sec><sec id="s2-2"><title>d-VAE extracts effective behaviorally relevant signals</title><p>To demonstrate the effectiveness of our model (distill-variational autoencoder [d-VAE]) in extracting behaviorally relevant signals, we conducted experiments on the synthetic dataset where the ground truth of relevant and irrelevant signals are already known (see Methods) and three benchmark datasets with different paradigms (<xref ref-type="fig" rid="fig2">Figure 2a, e, and i</xref>; see Methods for details), and compared d-VAE with four other distillation models, including pi-VAE (<xref ref-type="bibr" rid="bib62">Zhou, 2020</xref>), PSID (<xref ref-type="bibr" rid="bib47">Sani et al., 2021</xref>), TNDM (<xref ref-type="bibr" rid="bib24">Hurwitz, 2021</xref>), and LFADS (<xref ref-type="bibr" rid="bib42">Pandarinath et al., 2018</xref>). Specifically, we first applied these distillation models to raw signals to obtain the distilled behaviorally relevant signals, considering the residuals as behaviorally irrelevant signals. We then evaluated the decoding <inline-formula><mml:math id="inf21"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msup><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi mathvariant="normal">R</mml:mi></mml:mrow><mml:mrow class="MJX-TeXAtom-ORD"><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:mstyle></mml:math></inline-formula> between the predicted velocity and actual velocity of the two partition signals using a linear Kalman filter (KF) and a nonlinear artificial neural network (ANN) and measured the neural similarity between behaviorally relevant and raw signals.</p><fig-group><fig id="fig2" position="float"><label>Figure 2.</label><caption><title>Evaluation of separated signals.</title><p>(<bold>a–d</bold>) Results for dataset A. (<bold>a</bold>) The obstacle avoidance paradigm. (<bold>b</bold>) The decoding <inline-formula><mml:math id="inf22"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msup><mml:mrow><mml:mi mathvariant="normal">R</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:mstyle></mml:math></inline-formula> between true velocity and predicted velocity of raw signals (purple bars with slash lines) and behaviorally relevant signals obtained by distill-variational autoencoder (d-VAE) (red), PSID (pink), pi-VAE (green), TNDM (blue), and LFADS (light green). Error bars denote mean ± standard deviation (s.d.) across five cross-validation folds. Asterisks represent significance of Wilcoxon rank-sum test with <sup>∗</sup>p&lt;0.05, <sup>∗∗</sup>p&lt;0.01. (<bold>c</bold>) Same as (<bold>b</bold>), but for behaviorally irrelevant signals obtained by five different methods. (<bold>d</bold>) The neural similarity (<inline-formula><mml:math id="inf23"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msup><mml:mrow><mml:mi mathvariant="normal">R</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:mstyle></mml:math></inline-formula>) between raw signals and behaviorally relevant signals extracted by d-VAE, PSID, pi-VAE, TNDM, and LFADS. Error bars represent mean ± s.d. across five cross-validation folds. Asterisks indicate significance of Wilcoxon rank-sum test with <sup>∗∗</sup>p&lt;0.01. (<bold>e–h and i–l</bold>). Same as (<bold>a–d</bold>), but for dataset B with the center-out paradigm (<bold>e</bold>) and dataset C with the self-paced reaching paradigm (<bold>i</bold>). (<bold>m</bold>) The firing rates of raw signals and distilled signals obtained by d-VAE in five held-out trials under the same condition of dataset B.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-87881-fig2-v1.tif"/></fig><fig id="fig2s1" position="float" specific-use="child-fig"><label>Figure 2—figure supplement 1.</label><caption><title>Evaluation of separated signals on the synthetic dataset.</title><p>(<bold>a</bold>) The temporal neuronal activity of raw signals (the purple line) of an example test trial, which is decomposed into relevant (<bold>b</bold>) and irrelevant (<bold>c</bold>) signals. (<bold>b</bold>) Relevant signals (red lines) extracted by distill-variational autoencoder (d-VAE) under three distillation cases, where bold gray lines represent ground truth relevant signals. The hyperparameter <inline-formula><mml:math id="inf24"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>α</mml:mi></mml:mstyle></mml:math></inline-formula> is very important to extracting behaviorally relevant signals, which balances the trade-off between reconstruction loss and decoding loss. Results show that when <inline-formula><mml:math id="inf25"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>α</mml:mi><mml:mo>=</mml:mo><mml:mn>0.09</mml:mn></mml:mstyle></mml:math></inline-formula>, the relevant signals are too similar to raw signals but not similar to ground truth; when <inline-formula><mml:math id="inf26"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>α</mml:mi><mml:mo>=</mml:mo><mml:mn>0.9</mml:mn></mml:mstyle></mml:math></inline-formula>, the relevant signals are well similar to the ground truth; when <inline-formula><mml:math id="inf27"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>α</mml:mi><mml:mo>=</mml:mo><mml:mn>9</mml:mn></mml:mstyle></mml:math></inline-formula>, the relevant signals are not similar to the ground truth. (<bold>c</bold>) Same as (<bold>b</bold>), but for irrelevant signals (blue lines). Notably, when <inline-formula><mml:math id="inf28"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>α</mml:mi><mml:mo>=</mml:mo><mml:mn>9</mml:mn></mml:mstyle></mml:math></inline-formula>, some useful signals are left in irrelevant signals. (<bold>d</bold>) The decoding <inline-formula><mml:math id="inf29"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msup><mml:mrow><mml:mi mathvariant="normal">R</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:mstyle></mml:math></inline-formula> of distilled relevant signals of three cases. Error bars indicate mean ± standard deviation (s.d.) across five cross-validation folds. Results demonstrate that decoding <inline-formula><mml:math id="inf30"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msup><mml:mrow><mml:mi mathvariant="normal">R</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:mstyle></mml:math></inline-formula> increases as <inline-formula><mml:math id="inf31"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>α</mml:mi></mml:mstyle></mml:math></inline-formula> increases. (<bold>e</bold>) Same as (<bold>d</bold>), but for irrelevant signals. Notably, when <inline-formula><mml:math id="inf32"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>α</mml:mi><mml:mo>=</mml:mo><mml:mn>9</mml:mn></mml:mstyle></mml:math></inline-formula>, irrelevant signals will contain large behavioral information. (<bold>f</bold>) The neural similarity between relevant and raw signals. Results show that the neural <inline-formula><mml:math id="inf33"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msup><mml:mrow><mml:mi mathvariant="normal">R</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:mstyle></mml:math></inline-formula> decreases as <inline-formula><mml:math id="inf34"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>α</mml:mi></mml:mstyle></mml:math></inline-formula> increases. (<bold>g</bold>) The neural <inline-formula><mml:math id="inf35"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msup><mml:mrow><mml:mi mathvariant="normal">R</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:mstyle></mml:math></inline-formula> between relevant signals and the ground truth of relevant signals. Results show that d-VAE can utilize a proper trade-off to extract effective relevant signals that are similar to the ground truth. (<bold>h</bold>) The neural <inline-formula><mml:math id="inf36"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msup><mml:mrow><mml:mi mathvariant="normal">R</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:mstyle></mml:math></inline-formula> between irrelevant signals and the ground truth of irrelevant signals. Results show that d-VAE can utilize a proper trade-off to remove effective irrelevant signals that are similar to the ground truth. (<bold>i</bold>) The decoding <inline-formula><mml:math id="inf37"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msup><mml:mrow><mml:mi mathvariant="normal">R</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:mstyle></mml:math></inline-formula> between true velocity and predicted velocity of raw signals (purple bars with slash lines), the ground truth signals (gray) and behaviorally relevant signals obtained by d-VAE (red), PSID (pink), pi-VAE (green), TNDM (blue), and LFADS (light green). Error bars denote mean ± standard deviation (s.d.) across five cross-validation folds. Asterisks represent significance of Wilcoxon rank-sum test with <sup>∗</sup>p&lt;0.01, <sup>∗∗</sup>p&lt;0.01. (<bold>j</bold>) Same as (<bold>i</bold>), but for irrelevant signals. (<bold>k</bold>) The neural <inline-formula><mml:math id="inf38"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msup><mml:mrow><mml:mi mathvariant="normal">R</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:mstyle></mml:math></inline-formula> between generated relevant signals and raw signals. (<bold>l</bold>) Same as (<bold>k</bold>), but for the ground truth of relevant signals.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-87881-fig2-figsupp1-v1.tif"/></fig></fig-group><p>Overall, d-VAE successfully extracts effective behaviorally relevant signals that meet the three criteria outlined above on both synthetic (<xref ref-type="fig" rid="fig2s1">Figure 2—figure supplement 1</xref>) and real data (<xref ref-type="fig" rid="fig2">Figure 2</xref>). On the synthetic data (<xref ref-type="fig" rid="fig2s1">Figure 2—figure supplement 1</xref>), results show that d-VAE can strike an effective balance between the reconstruction and decoding performance of generated signals to extract effective relevant signals that are similar to the ground truth relevant signals, meanwhile removing effective irrelevant signals that resemble the ground truth irrelevant signals (<xref ref-type="fig" rid="fig2s1">Figure 2—figure supplement 1a–g</xref>), and outperforms other distillation models (<xref ref-type="fig" rid="fig2s1">Figure 2—figure supplement 1h–k</xref>). On the real data, specifically in the obstacle avoidance task (<xref ref-type="fig" rid="fig2">Figure 2a</xref>), the monkey is required to move the ball from the start point (blue) to the target point (yellow) without hitting the obstacle. For the decoding performance of behaviorally relevant signals (<xref ref-type="fig" rid="fig2">Figure 2b</xref>), the signals distilled by d-VAE outperform the raw signals (purple bars with slash lines) and the signals distilled by all other distillation models (PSID, pink; pi-VAE, green; TNDM, blue; and LFADS, light green) with the KF as well as the ANN. For the decoding performance of behaviorally irrelevant signals (<xref ref-type="fig" rid="fig2">Figure 2c</xref>), behaviorally irrelevant signals obtained by d-VAE achieves the lowest decoding performance compared with behaviorally irrelevant signals obtained by other approaches. Therefore, the combination of dVAE’s highest decoding performance for behaviorally relevant signals and lowest decoding performance for behaviorally irrelevant signals demonstrate its superior ability to extract behaviorally relevant signals from noisy signals. For the neural similarity between behaviorally relevant and raw signals (<xref ref-type="fig" rid="fig2">Figure 2d</xref>), the distilled signals obtained by d-VAE achieve the highest performance among competitors (p&lt;0.01, Wilcoxon rank-sum test). Similar results were obtained for the center-out task (<xref ref-type="fig" rid="fig2">Figure 2e–h</xref>) and the self-paced reaching task (<xref ref-type="fig" rid="fig2">Figure 2i–l</xref>), indicating the consistency of d-VAE’s distillation ability across a range of motor tasks. To provide a more intuitive illustration of the similarity between raw and distilled signals, we displayed the firing rate of neuronal activity in five trials under the same condition (<xref ref-type="fig" rid="fig2">Figure 2m</xref>), and results clearly show that the firing pattern of distilled signals is similar to the corresponding raw signals.</p><p>In summary, d-VAE distills effective behaviorally relevant signals that preserve behavioral information maximally and are similar to raw signals. Meanwhile, the behaviorally irrelevant signals discarded by d-VAE contain a little behavioral information. Therefore, these signals are reliable for exploring the encoding and decoding mechanisms of relevant signals.</p></sec><sec id="s2-3"><title>How do behaviorally irrelevant signals affect the analysis of neural activity at the single-neuron level?</title><p>Following signal separation, we first explored how behaviorally irrelevant signals affect the analysis of neural activity at the single-neuron level. Specifically, we examined the effect of irrelevant signals on two critical properties of neuronal activity: the preferred direction (PD) (<xref ref-type="bibr" rid="bib19">Georgopoulos et al., 1986</xref>) and trial-to-trial variability. Our objective was to know how irrelevant signals affect the PD of neurons and whether irrelevant signals contribute significantly to neuronal variability.</p><p>To explore how irrelevant signals affect the PD of neurons, we first calculated the PD of both raw and distilled signals separately and then quantified the PD deviation by the angle difference between these two signals. Results show that the PD deviation increases as the neuronal <inline-formula><mml:math id="inf39"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msup><mml:mrow><mml:mi mathvariant="normal">R</mml:mi></mml:mrow><mml:mn>2</mml:mn></mml:msup></mml:mrow></mml:mstyle></mml:math></inline-formula> decreases (red curve, <xref ref-type="fig" rid="fig3">Figure 3a and e</xref> and <xref ref-type="fig" rid="fig3s1">Figure 3—figure supplement 1a</xref>). It is worth noting that when using <inline-formula><mml:math id="inf40"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msup><mml:mrow><mml:mi mathvariant="normal">R</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:mstyle></mml:math></inline-formula> to describe neurons, it indicates the extent to which neuronal activity is explained by the linear encoding model (<xref ref-type="bibr" rid="bib7">Collinger et al., 2013</xref>; <xref ref-type="bibr" rid="bib56">Wodlinger et al., 2015</xref>). Neurons with larger <inline-formula><mml:math id="inf41"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msup><mml:mrow><mml:mi mathvariant="normal">R</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:mstyle></mml:math></inline-formula> (strongly linear-tuned neurons) exhibit stable PDs with signal distillation (see example PDs in the inset), while neurons with smaller <inline-formula><mml:math id="inf42"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msup><mml:mrow><mml:mi mathvariant="normal">R</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:mstyle></mml:math></inline-formula> (weakly linear-tuned neurons) show a larger PD deviation. These results indicate that irrelevant signals have a small effect on strongly tuned neurons but a large effect on weakly tuned neurons. One possible reason for the larger PD deviation in weakly tuned neurons is that they have a lower degree of linear encoding but a higher degree of nonlinear encoding, and highly nonlinear structures are more susceptible to interference from irrelevant signals (<xref ref-type="bibr" rid="bib39">Nogueira et al., 2023</xref>). Moreover, after filtering out the behaviorally irrelevant signals, the cosine tuning fit (<inline-formula><mml:math id="inf43"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msup><mml:mrow><mml:mi mathvariant="normal">R</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:mstyle></mml:math></inline-formula>) of neurons increases (p&lt;10<sup>-20</sup>, Wilcoxon signed-rank test; <xref ref-type="fig" rid="fig3">Figure 3b and f</xref> and <xref ref-type="fig" rid="fig3s1">Figure 3—figure supplement 1b</xref>), indicating that irrelevant signals reduce the neurons’ tuning expression. Notably, even after removing the interference of irrelevant signals, the <inline-formula><mml:math id="inf44"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msup><mml:mrow><mml:mi mathvariant="normal">R</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:mstyle></mml:math></inline-formula> of neurons remains relatively low and varies among neurons. These results demonstrate that the linear encoding model only explains a small fraction of neural responses, and neuronal activity encodes behavioral information in complex nonlinear ways.</p><fig-group><fig id="fig3" position="float"><label>Figure 3.</label><caption><title>The effect of irrelevant signals on analyzing neural activity at the single-neuron level.</title><p>(<bold>a–d</bold>) Results for dataset A. (<bold>a</bold>) The angle difference (AD) of preferred direction (PD) between raw and distilled signals as a function of the <inline-formula><mml:math id="inf45"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msup><mml:mrow><mml:mi mathvariant="normal">R</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:mstyle></mml:math></inline-formula> of raw signals. When employing <inline-formula><mml:math id="inf46"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msup><mml:mrow><mml:mi mathvariant="normal">R</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:mstyle></mml:math></inline-formula> to characterize neurons, it indicates the extent to which neuronal activity is explained by the linear encoding model. Smaller <inline-formula><mml:math id="inf47"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msup><mml:mrow><mml:mi mathvariant="normal">R</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:mstyle></mml:math></inline-formula> neurons have a lower capacity for linearly tuning (encoding) behaviors, while larger <inline-formula><mml:math id="inf48"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msup><mml:mrow><mml:mi mathvariant="normal">R</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:mstyle></mml:math></inline-formula> neurons have a higher capacity for linearly tuning (encoding) behaviors. Each black point represents a neuron (n=90). The red curve is the fitting curve between <inline-formula><mml:math id="inf49"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msup><mml:mrow><mml:mi mathvariant="normal">R</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:mstyle></mml:math></inline-formula> and AD. Five example larger <inline-formula><mml:math id="inf50"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msup><mml:mrow><mml:mi mathvariant="normal">R</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:mstyle></mml:math></inline-formula> neurons’ PDs are shown in the inset plot, where the solid and dotted line arrows represent the PDs of relevant and raw signals, respectively. (<bold>b</bold>) Comparison of the cosine tuning fit (<inline-formula><mml:math id="inf51"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msup><mml:mrow><mml:mi mathvariant="normal">R</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:mstyle></mml:math></inline-formula>) before and after distillation of single neurons (black points), where the x-axis and y-axis represent neurons’ <inline-formula><mml:math id="inf52"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msup><mml:mrow><mml:mi mathvariant="normal">R</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:mstyle></mml:math></inline-formula> of raw and distilled signals, respectively. (<bold>c</bold>) Comparison of neurons’ Fano factor (FF) averaged across conditions of raw (x-axis) and distilled (y-axis) signals, where FF is used to measure the neuronal variability of different trials in the same condition. (<bold>d</bold>) Boxplots of raw (purple) and distilled (red) signals under different conditions for all neurons (12 conditions). Boxplots represent medians (lines), quartiles (boxes), and whiskers extending to ±1.5 times the interquartile range. The broken lines represent the mean FF across all neurons. (<bold>e–h</bold>) Same as (<bold>a–d</bold>), but for dataset B (n=159, 8 conditions). (<bold>i</bold>) Example of three neurons’ raw firing activity decomposed into behaviorally relevant and irrelevant parts using all trials under two conditions (2 of 8 directions) in held-out test sets of dataset B.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-87881-fig3-v1.tif"/></fig><fig id="fig3s1" position="float" specific-use="child-fig"><label>Figure 3—figure supplement 1.</label><caption><title>The effect of irrelevant signals on relevant signals at the single-neuron level.</title><p>(<bold>a, b</bold>) Same as <xref ref-type="fig" rid="fig3">Figure 3</xref>, but for dataset C. (<bold>a</bold>) The angle difference (AD) of preferred direction (PD) between raw and distilled signals as a function of the <inline-formula><mml:math id="inf53"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msup><mml:mrow><mml:mi mathvariant="normal">R</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:mstyle></mml:math></inline-formula> of raw signals. Each black point represents a neuron (n=91). The red curve is the fitting curve between <inline-formula><mml:math id="inf54"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msup><mml:mrow><mml:mi mathvariant="normal">R</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:mstyle></mml:math></inline-formula> and AD. Five example larger <inline-formula><mml:math id="inf55"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msup><mml:mrow><mml:mi mathvariant="normal">R</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:mstyle></mml:math></inline-formula> neurons’ PDs are shown in the inset plot, where the solid line arrows represent the PD of relevant signals, and the dotted line arrows represent the PDs of raw signals. (<bold>b</bold>) Comparison of the cosine tuning fit (<inline-formula><mml:math id="inf56"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msup><mml:mrow><mml:mi mathvariant="normal">R</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:mstyle></mml:math></inline-formula>) before and after distillation of single neurons (black points), where the x-axis and y-axis represent neurons’ <inline-formula><mml:math id="inf57"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msup><mml:mrow><mml:mi mathvariant="normal">R</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:mstyle></mml:math></inline-formula> of raw and distilled signals.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-87881-fig3-figsupp1-v1.tif"/></fig><fig id="fig3s2" position="float" specific-use="child-fig"><label>Figure 3—figure supplement 2.</label><caption><title>The firing activity of example neurons.</title><p>(<bold>a</bold>) Example of three neurons’ raw firing activity decomposed into behaviorally relevant and irrelevant parts using all trials in held-out test sets for four conditions (4 of 8 directions) of center-out reaching task. (<bold>b</bold>) Example of three neurons’ raw firing activity decomposed into behaviorally relevant and irrelevant parts using all trials in held-out test sets for four conditions (4 of 12 conditions) of obstacle avoidance task.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-87881-fig3-figsupp2-v1.tif"/></fig></fig-group><p>To investigate whether irrelevant signals significantly contribute to neuronal variability, we compared the neuronal variability (measured with the Fano factor [FF]; <xref ref-type="bibr" rid="bib5">Churchland et al., 2010</xref>) of relevant and raw signals. Results show that the condition-averaged FF of each neuron of distilled signals is lower than that of raw signals (p&lt;10<sup>-20</sup>, Wilcoxon signed-rank test; <xref ref-type="fig" rid="fig3">Figure 3c and g</xref>), and the mean (broken line) and median FFs of all neurons under different conditions are also significantly lower than those of raw signals (p&lt;0.01, Wilcoxon signed-rank test; <xref ref-type="fig" rid="fig3">Figure 3d and h</xref>), indicating that irrelevant signals significantly contribute to neuronal variability. We then visualized the single-trial neuronal activity of example neurons under different conditions (<xref ref-type="fig" rid="fig3">Figure 3i</xref> and <xref ref-type="fig" rid="fig3s2">Figure 3—figure supplement 2</xref>). Results demonstrate that the patterns of relevant signals are more consistent and stable across different trials than raw signals, and the firing activity of irrelevant signals varies randomly. These results indicate that irrelevant signals significantly contribute to neuronal variability, and eliminating the interference of irrelevant signals enables us to observe the changes in neural pattern more accurately.</p></sec><sec id="s2-4"><title>How do behaviorally irrelevant signals affect the analysis of neural activity at the population level?</title><p>The neural population structure is an essential characteristic of neural activity. Here, we examined how behaviorally irrelevant signals affect the analysis of neural activity at the population level, including four aspects: (1) the population properties of relevant and irrelevant signals, (2) the subspace overlap relationship between the two signal components, (3) how the two partitions contribute to raw signals, and (4) the difference in population properties between raw and distilled signals.</p><p>To explore the population properties of relevant and irrelevant signals, we separately applied principal component analysis (PCA) on each partition to obtain the corresponding cumulative variance curve in a descending variance order. Our results show that the primary subspace (capturing the top 90% variance) of relevant signals (thick red line, <xref ref-type="fig" rid="fig4">Figure 4a and e</xref> and <xref ref-type="fig" rid="fig4s1">Figure 4—figure supplement 1a</xref>) is only explained by a few dimensions (7, 13, and 9 for each dataset), indicating that the primary part of behaviorally relevant signals exists in a low-dimensional subspace. In contrast, the primary subspace of irrelevant signals (thick blue line, <xref ref-type="fig" rid="fig4">Figure 4b and f</xref> and <xref ref-type="fig" rid="fig4s1">Figure 4—figure supplement 1b</xref>) requires more dimensions (46, 81, and 59). The variance distribution of behaviorally irrelevant signals across dimensions (thick blue line, <xref ref-type="fig" rid="fig4">Figure 4b and f</xref> and <xref ref-type="fig" rid="fig4s1">Figure 4—figure supplement 1b</xref>) is more even than behaviorally relevant signals (thick red line, <xref ref-type="fig" rid="fig4">Figure 4a and e</xref> and <xref ref-type="fig" rid="fig4s1">Figure 4—figure supplement 1a</xref>) but not as uniform as Gaussian noise <inline-formula><mml:math id="inf58"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mrow><mml:mi class="mathcal" mathvariant="script">N</mml:mi></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mn mathvariant="bold">0</mml:mn><mml:mo>,</mml:mo><mml:mrow><mml:mi mathvariant="bold-italic">I</mml:mi></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mstyle></mml:math></inline-formula> (thin gray line, <xref ref-type="fig" rid="fig4">Figure 4b and f</xref> and <xref ref-type="fig" rid="fig4s1">Figure 4—figure supplement 1a</xref>), indicating that irrelevant signals are not pure noise but rather bear some significant structure, which may represent information from other irrelevant tasks.</p><fig-group><fig id="fig4" position="float"><label>Figure 4.</label><caption><title>The effect of irrelevant signals on analyzing neural activity at the population level.</title><p>(<bold>a–d</bold>) Results for dataset A. (<bold>a</bold>) The cumulative variance curve for different signals, including relevant signals (red), irrelevant signals (blue), and random Gaussian noise <inline-formula><mml:math id="inf59"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mrow><mml:mi class="mathcal" mathvariant="script">N</mml:mi></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mn mathvariant="bold">0</mml:mn><mml:mo>,</mml:mo><mml:mrow><mml:mi mathvariant="bold-italic">I</mml:mi></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mstyle></mml:math></inline-formula> (gray, representing the chance level), projected onto the principal components (PCs) of relevant signals. Specifically, principal component analysis (PCA) is applied to relevant signals to get relevant PCs. Subsequently, the three types of signals are projected onto these relevant PCs to obtain their respective cumulative variance curves. The thick lines represent the cumulative variance explained for the signals on which PCA has been performed, while the thin lines represent the variance explained by those PCs for other signals. The horizontal dotted lines represent the percentage of variance explained. The vertical lines indicate the number of dimensions that accounted for 90% of the variance in behaviorally relevant (left) and irrelevant (right) signals. For convenience, we defined the PC subspace describing the top 90% variance as the primary subspace and the subspace capturing the last 10% variance as the secondary subspace. (<bold>b</bold>) Same as (<bold>a</bold>), but for irrelevant PCs. (<bold>c</bold>) The composition of raw signals and each raw PC. Specifically, PCA is applied to the raw signals to obtain raw PCs. Then, the relevant and irrelevant signals are projected onto these raw PCs to determine the variance of the raw signals explained by each type of signal. The bar plot shows the composition of each raw PC. The inset pie plot shows the overall proportion of raw signals, where red, blue, and purple colors indicate relevant signals, irrelevant signals, and the correlation between relevant and relevant signals. The PC marked with a red triangle indicates the last PC where the variance of relevant signals is greater than or equal to that of irrelevant signals. (<bold>d</bold>) The cumulative variance explained by raw PCs for different signals, where the thick line represents the cumulative variance explained for raw signals (purple), while the thin line represents the variance explained for relevant (red) and irrelevant (blue) signals. (<bold>e–h</bold>) Same as (<bold>a–d</bold>), but for dataset B.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-87881-fig4-v1.tif"/></fig><fig id="fig4s1" position="float" specific-use="child-fig"><label>Figure 4—figure supplement 1.</label><caption><title>The effect of irrelevant signals on analyzing neural activity at the population level.</title><p>(<bold>a–d</bold>) Same as <xref ref-type="fig" rid="fig4">Figure 4</xref>, but for dataset C. (<bold>a</bold>) The cumulative variance curve for different signals, including relevant signals (red), irrelevant signals (blue), and random Gaussian noise <inline-formula><mml:math id="inf60"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mrow><mml:mi class="mathcal" mathvariant="script">N</mml:mi></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mn mathvariant="bold">0</mml:mn><mml:mo>,</mml:mo><mml:mrow><mml:mi mathvariant="bold-italic">I</mml:mi></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mstyle></mml:math></inline-formula> (gray, representing the chance level), projected onto the principal components (PCs) of relevant signals. Specifically, principal component analysis (PCA) is applied to relevant signals to get relevant PCs. Subsequently, the three types of signals are projected onto these relevant PCs to obtain their respective cumulative variance curves. The thick lines represent the cumulative variance explained for the signals on which PCA has been performed, while the thin lines represent the variance explained by those PCs for other signals. The horizontal dotted lines represent the percentage of variance explained. The vertical lines indicate the number of dimensions that accounted for 90% of the variance in behaviorally relevant (left) and irrelevant (right) signals. For convenience, we defined the PC subspace describing the top 90% variance as the primary subspace and the subspace capturing the last 10% variance as the secondary subspace. (<bold>b</bold>) Same as (a), but for irrelevant PCs. (<bold>c</bold>) The composition of raw signals and each raw PC. Specifically, PCA is applied to the raw signals to obtain raw PCs. Then, the relevant and irrelevant signals are projected onto these raw PCs to determine the variance of the raw signals explained by each type of signal. The bar plot shows the composition of each raw PC. The inset pie plot shows the overall proportion of raw signals, where red, blue, and purple colors indicate relevant signals, irrelevant signals, and the correlation between relevant and relevant signals. The PC marked with a red triangle indicates the last PC where the variance of relevant signals is greater than or equal to that of irrelevant signals. (<bold>d</bold>) The cumulative variance explained by raw PCs for different signals, where the thick line represents the cumulative variance explained for raw signals (purple), while the thin line represents the variance explained for relevant (red) and irrelevant (blue) signals.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-87881-fig4-figsupp1-v1.tif"/></fig><fig id="fig4s2" position="float" specific-use="child-fig"><label>Figure 4—figure supplement 2.</label><caption><title>The effect of irrelevant signals obtained by pi-VAE on analyzing neural activity at the population level.</title><p>(<bold>a–l</bold>) Same as <xref ref-type="fig" rid="fig4">Figure 4</xref> and <xref ref-type="fig" rid="fig4s1">Figure 4—figure supplement 1</xref>, but for pi-VAE. (<bold>a</bold>) The cumulative variance curve for different signals, including relevant signals (red), irrelevant signals (blue), and random Gaussian noise <inline-formula><mml:math id="inf61"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mrow><mml:mi class="mathcal" mathvariant="script">N</mml:mi></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mn mathvariant="bold">0</mml:mn><mml:mo>,</mml:mo><mml:mrow><mml:mi mathvariant="bold-italic">I</mml:mi></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mstyle></mml:math></inline-formula> (gray, representing the chance level), projected onto the principal components (PCs) of relevant signals. Specifically, principal component analysis (PCA) is applied to relevant signals to get relevant PCs. Subsequently, the three types of signals are projected onto these relevant PCs to obtain their respective cumulative variance curves. The thick lines represent the cumulative variance explained for the signals on which PCA has been performed, while the thin lines represent the variance explained by those PCs for other signals. The horizontal dotted lines represent the percentage of variance explained. The vertical lines indicate the number of dimensions that accounted for 90% of the variance in behaviorally relevant (left) and irrelevant (right) signals. For convenience, we defined the PC subspace describing the top 90% variance as the primary subspace and the subspace capturing the last 10% variance as the secondary subspace. (<bold>b</bold>) Same as (a), but for irrelevant PCs. (<bold>c</bold>) The composition of raw signals and each raw PC. Specifically, PCA is applied to the raw signals to obtain raw PCs. Then, the relevant and irrelevant signals are projected onto these raw PCs to determine the variance of the raw signals explained by each type of signal. The bar plot shows the composition of each raw PC. The inset pie plot shows the overall proportion of raw signals, where red, blue, and purple colors indicate relevant signals, irrelevant signals, and the correlation between relevant and relevant signals. The PC marked with a red triangle indicates the last PC where the variance of relevant signals is greater than or equal to that of irrelevant signals. (<bold>d</bold>) The cumulative variance explained by raw PCs for different signals, where the thick line represents the cumulative variance explained for raw signals (purple), while the thin line represents the variance explained for relevant (red) and irrelevant (blue) signals. (<bold>e–h, i–l</bold>) Same as (<bold>a–d</bold>), but for datasets B and C.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-87881-fig4-figsupp2-v1.tif"/></fig><fig id="fig4s3" position="float" specific-use="child-fig"><label>Figure 4—figure supplement 3.</label><caption><title>The rotational dynamics of raw, relevant, and irrelevant signals.</title><p>Datasets A and B have 12 and 8 conditions, respectively. We get the trial-averaged neural responses for each condition, then apply jPCA to raw, relevant, and irrelevant signals to get the top two jPC, respectively. (<bold>a</bold>) The rotational dynamics of raw neural signals. (<bold>b</bold>) The rotational dynamics of relevant signals obtained by distill-variational autoencoder (d-VAE). (<bold>c</bold>) The rotational dynamics of irrelevant signals obtained by d-VAE. We can see that the rotational dynamics of behaviorally relevant signals are similar to that of raw signals, but the rotational dynamics of behaviorally irrelevant signals are irregular. (<bold>d–f</bold>) Same as (<bold>a–c</bold>), but for dataset B.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-87881-fig4-figsupp3-v1.tif"/></fig><fig id="fig4s4" position="float" specific-use="child-fig"><label>Figure 4—figure supplement 4.</label><caption><title>The cumulative variance curve for raw and behaviorally relevant signals.</title><p>(<bold>a</bold>) The cumulative variance curve for raw (purple) and behaviorally relevant (red) signals on their respective principal components (PCs) on dataset A (n=90). Two upper left corner curves denote the variance accumulation from larger to smaller variance PCs. Two lower right corner curves indicate accumulation from smaller to larger variance PCs. The horizontal lines represent the 10% and 90% variance explained. The vertical lines indicate the number of dimensions accounted for the last 10% and top 90% of the variance of behaviorally relevant (red) and raw (purple) signals. Here, we call the subspace composed of PCs capturing the top 90% variance the primary subspace, and the subspace composed of PCs capturing the last 10% variance the secondary subspace. We can see that the dimensionality of the primary subspace of raw signals is significantly higher than that of relevant signals, indicating that irrelevant signals make us overestimate the neural dimensionality. (<bold>b, c</bold>) Same as (a), but for datasets B (n=159) and C (n=91).</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-87881-fig4-figsupp4-v1.tif"/></fig></fig-group><p>To investigate the subspace overlap between relevant and irrelevant signals, we calculated how many variances of irrelevant signals can be captured by relevant PCs by projecting irrelevant signals onto relevant PCs and vice versa (<xref ref-type="bibr" rid="bib11">Elsayed et al., 2016</xref>; <xref ref-type="bibr" rid="bib45">Rouse and Schieber, 2018</xref>; <xref ref-type="bibr" rid="bib26">Jiang et al., 2020</xref>) (see Methods). We found that the variance of irrelevant signals increases relatively uniformly over relevant PCs (thin blue line, <xref ref-type="fig" rid="fig4">Figure 4a and e</xref> and <xref ref-type="fig" rid="fig4s1">Figure 4—figure supplement 1a</xref>), like random noise’s variance accumulation explained by relevant PCs (thin gray line, <xref ref-type="fig" rid="fig4">Figure 4a and e</xref> and <xref ref-type="fig" rid="fig4s1">Figure 4—figure supplement 1a</xref>); similar results are observed for relevant signals explained by irrelevant PCs (thin red line, <xref ref-type="fig" rid="fig4">Figure 4b and f</xref> and <xref ref-type="fig" rid="fig4s1">Figure 4—figure supplement 1b</xref>). These results indicate that relevant PCs cannot match the informative dimensions of irrelevant signals and vice versa, suggesting the dimensions of behaviorally relevant and irrelevant signals are unrelated. It is worth mentioning that the signals obtained by pi-VAE are in contrast to our findings. Its results show that a few relevant PCs can explain a considerable variance of irrelevant signals (thin red line, <xref ref-type="fig" rid="fig4s2">Figure 4—figure supplement 2b, f, j</xref>), which indicates that the relevant and irrelevant PCs are closely related. The possible reason is that the pi-VAE leaves many relevant signals within the irrelevant signals. Notably, <xref ref-type="fig" rid="fig4">Figure 4a and e</xref> and <xref ref-type="fig" rid="fig4s1">Figure 4—figure supplement 1a</xref> show that the behaviorally relevant primary subspace captures only a minor portion of the variance from irrelevant signals when they are projected onto it (9%, 12%, and 9%), indicating that the primary subspace of behaviorally relevant signals is nearly orthogonal to irrelevant space.</p><p>To investigate the composition of raw signals by the two partitions, we performed PCA on raw neural signals to obtain raw PCs, and then projected the relevant and irrelevant signals onto these PCs to assess the proportion of variance of raw signals explained by each partition. First, we analyzed the overall proportion of relevant and irrelevant signals that constitute the raw signals (the inset pie plot, <xref ref-type="fig" rid="fig4">Figure 4c and g</xref> and <xref ref-type="fig" rid="fig4s1">Figure 4—figure supplement 1c</xref>). The variance of the raw signals is composed of three parts: the variance of relevant signals, the variance of irrelevant signals, and the correlation between relevant and irrelevant signals (see Methods). The results demonstrate that the irrelevant signals account for a large proportion of raw signals, suggesting the motor cortex encodes considerable information that is not related to the measured behaviors. In addition, there is only a weak correlation between relevant and irrelevant signals, implying that behaviorally relevant and irrelevant signals are nearly uncorrelated.</p><p>We then examined the proportions of relevant and irrelevant signals in each PC of raw signals. We found that relevant signals (red) occupy the dominant proportions in the larger variance raw PCs (before the PC marked with a red triangle), while irrelevant signals (blue) occupy the dominant proportions in the smaller variance raw PCs (after the PC marked with a red triangle) (<xref ref-type="fig" rid="fig4">Figure 4c and g</xref> and <xref ref-type="fig" rid="fig4s1">Figure 4—figure supplement 1c</xref>). Similar results are observed in the accumulation of each raw PC (<xref ref-type="fig" rid="fig4">Figure 4d and h</xref> and <xref ref-type="fig" rid="fig4s1">Figure 4—figure supplement 1d</xref>). Specifically, the results show that the variance accumulation of raw signals (purple line) in larger variance PCs is mainly contributed by relevant signals (red line), while irrelevant signals (blue line) primarily contribute to the lower variance PCs. These results demonstrate that irrelevant signals have a small effect on larger variance raw PCs but a large effect on smaller variance raw PCs. This finding eliminates the concern that irrelevant signals would significantly affect the top few PCs of raw signals and thus produce inaccurate conclusions. To further validate this finding, we used the top six PCs as jPCA (<xref ref-type="bibr" rid="bib6">Churchland et al., 2012</xref>) did to examine the rotational dynamics of distilled and raw signals (<xref ref-type="fig" rid="fig4s3">Figure 4—figure supplement 3</xref>). Results show that the rotational dynamics of distilled signals are similar to those of raw signals.</p><p>Finally, to directly compare the population properties of raw and relevant signals, we plotted the cumulative variance curves of raw and relevant signals (<xref ref-type="fig" rid="fig4s4">Figure 4—figure supplement 4</xref>). Results (upper left corner curves, <xref ref-type="fig" rid="fig4s4">Figure 4—figure supplement 4</xref>) show that the cumulative variance curve of relevant signals (red line) accumulates faster than that of raw signals (purple line) in the preceding larger variance PCs, indicating that the variance of the relevant signal is more concentrated in the larger variance PCs than that of raw signals. Furthermore, we found that the dimensionality of primary subspace of raw signals (26, 64, and 45 for datasets A, B, and C) is significantly higher than that of behaviorally relevant signals (7, 13, and 9), indicating that using raw signals to estimate the neural dimensionality associated with behaviors leads to an overestimation.</p></sec><sec id="s2-5"><title>Distilled behaviorally relevant signals uncover that smaller <inline-formula><mml:math id="inf62"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msup><mml:mrow><mml:mi mathvariant="normal">R</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:mstyle></mml:math></inline-formula> neurons encode rich behavioral information in complex nonlinear ways</title><p>The results presented above regarding PDs (<xref ref-type="fig" rid="fig3">Figure 3</xref> and <xref ref-type="fig" rid="fig3s1">Figure 3—figure supplement 1</xref>) demonstrate that irrelevant signals significantly impact smaller <inline-formula><mml:math id="inf63"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msup><mml:mrow><mml:mi mathvariant="normal">R</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:mstyle></mml:math></inline-formula> neurons and weakly impact larger <inline-formula><mml:math id="inf64"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msup><mml:mrow><mml:mi mathvariant="normal">R</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:mstyle></mml:math></inline-formula> neurons. Under the interference of irrelevant signals, it is difficult to explore the amount of behavioral information in neuronal activity. Given that we have accurately separated the behaviorally relevant and irrelevant signals, we explored whether irrelevant signals would mask some encoded information of neuronal activity, especially for smaller <inline-formula><mml:math id="inf65"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msup><mml:mrow><mml:mi mathvariant="normal">R</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:mstyle></mml:math></inline-formula> neurons.</p><p>To answer the question, we divided the neurons into two groups of smaller <inline-formula><mml:math id="inf66"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msup><mml:mrow><mml:mi mathvariant="normal">R</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:mstyle></mml:math></inline-formula> (<inline-formula><mml:math id="inf67"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msup><mml:mrow><mml:mi mathvariant="normal">R</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:mstyle></mml:math></inline-formula>&lt;=0.03) and larger <inline-formula><mml:math id="inf68"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msup><mml:mrow><mml:mi mathvariant="normal">R</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:mstyle></mml:math></inline-formula> (<inline-formula><mml:math id="inf69"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msup><mml:mrow><mml:mi mathvariant="normal">R</mml:mi></mml:mrow><mml:mn>2</mml:mn></mml:msup></mml:mrow></mml:mstyle></mml:math></inline-formula>&gt;0.03), and then used decoding models to assess how much information is encoded in raw and distilled signals. As shown in <xref ref-type="fig" rid="fig5">Figure 5a</xref>, for the smaller <inline-formula><mml:math id="inf70"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msup><mml:mrow><mml:mi mathvariant="normal">R</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:mstyle></mml:math></inline-formula> neuron group, both KF and ANN decode behavioral information poorly on raw signals, but achieve high decoding performance using relevant signals. Specifically, the KF decoder (left plot, <xref ref-type="fig" rid="fig5">Figure 5a</xref>) improves the decoding <inline-formula><mml:math id="inf71"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msup><mml:mrow><mml:mi mathvariant="normal">R</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:mstyle></mml:math></inline-formula> significantly from 0.044 to 0.616 (improves by about 1300%, Wilcoxon rank-sum test) after signal distillation; the ANN decoder (right plot, <xref ref-type="fig" rid="fig5">Figure 5a</xref>) improves from 0.374 to 0.753 (improves by about 100%, Wilcoxon rank-sum test). For the larger <inline-formula><mml:math id="inf72"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msup><mml:mrow><mml:mi mathvariant="normal">R</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:mstyle></mml:math></inline-formula> neuron group, the decoding performance of relevant signals with ANN does not improve much compared with the decoding performance of raw signals, but the decoding performance of relevant signals with KF is significantly better than that of raw signals (p&lt;0.01, Wilcoxon rank-sum test). Similar results are obtained with datasets B (<xref ref-type="fig" rid="fig5">Figure 5d</xref>) and C (<xref ref-type="fig" rid="fig5s1">Figure 5—figure supplement 1a</xref>). These results indicate that irrelevant signals mask behavioral information encoded by neuronal populations, especially for smaller <inline-formula><mml:math id="inf73"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msup><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi mathvariant="normal">R</mml:mi></mml:mrow><mml:mrow class="MJX-TeXAtom-ORD"><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:mstyle></mml:math></inline-formula> neurons with a higher degree of nonlinearity, and that smaller <inline-formula><mml:math id="inf74"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msup><mml:mrow><mml:mi mathvariant="normal">R</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:mstyle></mml:math></inline-formula> neurons actually encode rich behavioral information.</p><fig-group><fig id="fig5" position="float"><label>Figure 5.</label><caption><title>Smaller <inline-formula><mml:math id="inf75"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msup><mml:mrow><mml:mi mathvariant="normal">R</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:mstyle></mml:math></inline-formula> neurons encode rich behavioral information in complex nonlinear ways.</title><p>(<bold>a–c</bold>) Results for dataset A. (<bold>a</bold>) The comparison of decoding performance between raw (purple) and distilled signals (red) with different neuron groups, including smaller <inline-formula><mml:math id="inf76"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msup><mml:mrow><mml:mi mathvariant="normal">R</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:mstyle></mml:math></inline-formula> neuron (<inline-formula><mml:math id="inf77"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msup><mml:mrow><mml:mi mathvariant="normal">R</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:mstyle></mml:math></inline-formula>&lt;=0.03), larger <inline-formula><mml:math id="inf78"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msup><mml:mrow><mml:mi mathvariant="normal">R</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:mstyle></mml:math></inline-formula> neuron (<inline-formula><mml:math id="inf79"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msup><mml:mrow><mml:mi mathvariant="normal">R</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:mstyle></mml:math></inline-formula>&gt;0.03), and all neurons. Error bars indicate mean ± standard deviation (s.d.) across five cross-validation folds. Asterisks denote significance of Wilcoxon rank-sum test with <sup>∗</sup>p&lt;0.01, <sup>∗∗</sup>p&lt;0.01. (<bold>b</bold>) The correlation matrix of all neurons of raw (left) and behaviorally relevant (right) signals. Neurons are ordered to highlight correlation structure (details in Methods). (<bold>c</bold>) The decoding performance of Kalman filter (KF) (left) and artificial neural network (ANN) (right) with neurons dropped out from larger to smaller <inline-formula><mml:math id="inf80"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msup><mml:mrow><mml:mi mathvariant="normal">R</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:mstyle></mml:math></inline-formula>. The vertical gray line indicates the number of dropped neurons at which raw and behaviorally relevant signals have the greatest performance difference. (<bold>d–f</bold>) Same as (<bold>a–c</bold>), but for dataset B.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-87881-fig5-v1.tif"/></fig><fig id="fig5s1" position="float" specific-use="child-fig"><label>Figure 5—figure supplement 1.</label><caption><title>Neural responses usually considered to contain little information actually encode rich behavioral information in complex nonlinear ways.</title><p>(<bold>a–c</bold>) Same as <xref ref-type="fig" rid="fig5">Figure 5</xref>, but for dataset C (n=91). (<bold>d–f</bold>) Same as <xref ref-type="fig" rid="fig6">Figure 6</xref>, but for dataset C. (<bold>a</bold>) The comparison of decoding performance between raw (purple) and distilled signals (red) with different neuron groups, including smaller <inline-formula><mml:math id="inf81"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msup><mml:mrow><mml:mi mathvariant="normal">R</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:mstyle></mml:math></inline-formula> neuron (<inline-formula><mml:math id="inf82"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msup><mml:mrow><mml:mi mathvariant="normal">R</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:mstyle></mml:math></inline-formula>&lt;=0.03), larger <inline-formula><mml:math id="inf83"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msup><mml:mrow><mml:mi mathvariant="normal">R</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:mstyle></mml:math></inline-formula> neuron (<inline-formula><mml:math id="inf84"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msup><mml:mrow><mml:mi mathvariant="normal">R</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:mstyle></mml:math></inline-formula>&gt;0.03), and all neurons. Error bars indicate mean ± standard deviation (s.d.) across cross-validation folds. Asterisks denote significance of Wilcoxon rank-sum test with <sup>∗</sup>p&lt;0.05, <sup>∗∗</sup>p&lt;0.01. (<bold>b</bold>) The correlation matrix of all neurons of raw and behaviorally relevant signals. (<bold>c</bold>) The decoding performance of Kalman filter (KF) (left) and artificial neural network (ANN) (right) with neurons dropped out from larger to smaller <inline-formula><mml:math id="inf85"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msup><mml:mrow><mml:mi mathvariant="normal">R</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:mstyle></mml:math></inline-formula>. The vertical gray lines indicate the number of dropped neurons at which raw and behaviorally relevant signals have the greatest performance difference. (<bold>d</bold>) The comparison of decoding performance between raw (purple) and distilled signals (red) composed of different raw-principal component (PC) groups, including smaller variance PCs (the proportion of irrelevant signals that make up raw PCs is higher than that of relevant signals), larger variance PCs (the proportion of irrelevant signals is lower than that of relevant ones). Error bars indicate mean ± s.d. across five cross-validation folds. Asterisks denote significance of Wilcoxon rank-sum test with <sup>∗</sup>p&lt;0.05, <sup>∗∗</sup>p&lt;0.01. (<bold>e</bold>) The cumulative decoding performance of signals composed of cumulative PCs that are ordered from smaller to larger variance using KF (left) and ANN (right). The red patches indicate the decoding ability of the last 10% variance of relevant signals. (<bold>f</bold>) Same as (<bold>e</bold>), but PCs are ordered from larger to smaller variance. The red patches indicate the decoding gain of the last 10% variance signals of relevant signals superimposing on their top 90% variance signals.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-87881-fig5-figsupp1-v1.tif"/></fig><fig id="fig5s2" position="float" specific-use="child-fig"><label>Figure 5—figure supplement 2.</label><caption><title>Using synthetic data to demonstrate that conclusions are not a by-product of distill-variational autoencoder (d-VAE).</title><p>(<bold>a, b</bold>) These results are used to demonstrate that d-VAE can utilize the larger <inline-formula><mml:math id="inf86"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msup><mml:mrow><mml:mi mathvariant="normal">R</mml:mi></mml:mrow><mml:mn>2</mml:mn></mml:msup></mml:mrow></mml:mstyle></mml:math></inline-formula> neurons to help the smaller <inline-formula><mml:math id="inf87"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msup><mml:mrow><mml:mi mathvariant="normal">R</mml:mi></mml:mrow><mml:mn>2</mml:mn></mml:msup></mml:mrow></mml:mstyle></mml:math></inline-formula> neurons restore their original face. (<bold>a</bold>) The decoding <inline-formula><mml:math id="inf88"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msup><mml:mrow><mml:mi mathvariant="normal">R</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:mstyle></mml:math></inline-formula> of the ground truth (gray), raw signals (purple), and distilled relevant signals (red) of smaller <inline-formula><mml:math id="inf89"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msup><mml:mrow><mml:mi mathvariant="normal">R</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:mstyle></mml:math></inline-formula> neurons of synthetic data. Error bars indicate mean ± standard deviation (s.d.) (n=5 folds). Asterisks denote the significance of Wilcoxon rank-sum test with <sup>∗∗</sup>p&lt;0.01. We can see that the ground truth of smaller <inline-formula><mml:math id="inf90"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msup><mml:mrow><mml:mi mathvariant="normal">R</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:mstyle></mml:math></inline-formula> neurons contain a certain amount of behavioral information, but the behavioral information cannot be decoded from raw signals due to being covered by noise; d-VAE can indeed utilize the larger <inline-formula><mml:math id="inf91"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msup><mml:mrow><mml:mi mathvariant="normal">R</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:mstyle></mml:math></inline-formula> neurons to help the smaller <inline-formula><mml:math id="inf92"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msup><mml:mrow><mml:mi mathvariant="normal">R</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:mstyle></mml:math></inline-formula> neurons restore their damaged information. (<bold>b</bold>) The neural similarity of raw signals and relevant signals to ground truth of smaller <inline-formula><mml:math id="inf93"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msup><mml:mrow><mml:mi mathvariant="normal">R</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:mstyle></mml:math></inline-formula> neurons. We can see that d-VAE can obtain effective relevant signals that are more similar to the ground truth compared to raw signals. (<bold>c</bold>) The decoding <inline-formula><mml:math id="inf94"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msup><mml:mrow><mml:mi mathvariant="normal">R</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:mstyle></mml:math></inline-formula> of the ground truth (gray) and distilled relevant signals (red) of smaller <inline-formula><mml:math id="inf95"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msup><mml:mrow><mml:mi mathvariant="normal">R</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:mstyle></mml:math></inline-formula> neurons of synthetic data. These results are used to demonstrate that d-VAE cannot make the linear decoder achieve similar performance as the nonlinear decoder. We can see that Kalman filter (KF) is significantly inferior to artificial neural network (ANN) on ground truth signals. The KF decoding performance of the ground truth signals is notably low, leaving significant room for compensation by d-VAE. However, after processing with d-VAE, the KF decoding performance of distilled signals does not surpass its ground truth performance. The disparity between KF and ANN remains substantial. These results demonstrate that d-VAE cannot make signals that originally require nonlinear decoding linearly decodable.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-87881-fig5-figsupp2-v1.tif"/></fig></fig-group><p>The fact that the smaller <inline-formula><mml:math id="inf96"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msup><mml:mrow><mml:mi mathvariant="normal">R</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:mstyle></mml:math></inline-formula> neurons encode rich information seems unexpected, and interestingly, we cannot obtain this rich information solely by distilling smaller <inline-formula><mml:math id="inf97"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msup><mml:mrow><mml:mi mathvariant="normal">R</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:mstyle></mml:math></inline-formula> neurons. This observation gives rise to two alternative scenarios. The first is that larger <inline-formula><mml:math id="inf98"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msup><mml:mrow><mml:mi mathvariant="normal">R</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:mstyle></mml:math></inline-formula> neurons introduce additional signals to smaller <inline-formula><mml:math id="inf99"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msup><mml:mrow><mml:mi mathvariant="normal">R</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:mstyle></mml:math></inline-formula> neurons, which they do not inherently possess, resulting in an excessive amount of behavioral information within the smaller <inline-formula><mml:math id="inf100"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msup><mml:mrow><mml:mi mathvariant="normal">R</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:mstyle></mml:math></inline-formula> neurons. The second is that the smaller <inline-formula><mml:math id="inf101"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msup><mml:mrow><mml:mi mathvariant="normal">R</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:mstyle></mml:math></inline-formula> neurons inherently possess a substantial amount of information, and larger <inline-formula><mml:math id="inf102"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msup><mml:mrow><mml:mi mathvariant="normal">R</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:mstyle></mml:math></inline-formula> neurons utilize their neural activity, which is correlated with that of small <inline-formula><mml:math id="inf103"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msup><mml:mrow><mml:mi mathvariant="normal">R</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:mstyle></mml:math></inline-formula> neurons, to aid in restoring the small <inline-formula><mml:math id="inf104"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msup><mml:mrow><mml:mi mathvariant="normal">R</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:mstyle></mml:math></inline-formula> neurons’ original appearance; this process is analogous to image denoising, where damaged noisy pixels necessitate the assistance of their correlated, clean neighboring pixels to recover their original appearance. We initially tested the first scenario and found it to be unsupported for two key reasons. First, our model enforces that distilled neuronal activity closely resembles the corresponding original neuronal activity, effectively preventing the generation of arbitrarily shaped neuronal activity, such as that of other neurons. As shown in <xref ref-type="fig" rid="fig3">Figure 3i</xref> and <xref ref-type="fig" rid="fig3s2">Figure 3—figure supplement 2</xref>, our distilled relevant neuronal activity exhibits a high degree of similarity to the corresponding raw neuronal activity. To assess whether the distilled neurons exhibit the highest similarity to the corresponding raw neurons, we compared the neural similarity (<inline-formula><mml:math id="inf105"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msup><mml:mrow><mml:mi mathvariant="normal">R</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:mstyle></mml:math></inline-formula>) of each distilled neuron to all raw neurons. The results indicate that 78/90 (87%, dataset A), 153/159 (96%, dataset B), and 91/91 (100%, dataset C) distilled neurons are most similar to the corresponding neurons. The remaining distilled neurons rank among the top four in similarity to the corresponding neurons, further confirming the close resemblance of distilled neuronal activity to the corresponding raw neuronal activity. Second, as we emphasized in the section on validating behaviorally relevant signals with the second criterion, if this large amount of information is compensated by other neurons, the residuals should also contain a large amount of information. However, as illustrated in <xref ref-type="fig" rid="fig2">Figure 2c, g, and k</xref>, the residuals contain only little information. Therefore, based on these two reasons, the first scenario is rejected. Then, we tested the second scenario. To verify this scenario, we conducted experiments using synthetic data with known ground truth (see Methods). In this dataset, small <inline-formula><mml:math id="inf106"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msup><mml:mrow><mml:mi mathvariant="normal">R</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:mstyle></mml:math></inline-formula> neurons inherently contained a substantial amount of information but were obscured by noise, making them undecodable. We aimed to assess whether d-VAE could recover the lost information and restore the damaged neuronal activity. The results demonstrate that, with the assistance of large <inline-formula><mml:math id="inf107"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msup><mml:mrow><mml:mi mathvariant="normal">R</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:mstyle></mml:math></inline-formula> neurons, d-VAE effectively recovers a significant amount of information that is obscured by noise (<xref ref-type="fig" rid="fig5s2">Figure 5—figure supplement 2a</xref>). Additionally, the distilled signals exhibit a remarkable improvement in neural similarity to the ground truth signals compared to the raw signals (p&lt;0.01, Wilcoxon rank-sum test; <xref ref-type="fig" rid="fig5s2">Figure 5—figure supplement 2b</xref>). Therefore, these results support the second scenario and collectively confirm that smaller <inline-formula><mml:math id="inf108"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msup><mml:mrow><mml:mi mathvariant="normal">R</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:mstyle></mml:math></inline-formula> neurons indeed contain rich behavioral information, and this finding is not a by-product of d-VAE.</p><p>Given that both smaller and larger <inline-formula><mml:math id="inf109"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msup><mml:mrow><mml:mi mathvariant="normal">R</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:mstyle></mml:math></inline-formula> neurons encode rich behavioral information, it is worth noting that the sum of the decoding performance of smaller <inline-formula><mml:math id="inf110"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msup><mml:mrow><mml:mi mathvariant="normal">R</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:mstyle></mml:math></inline-formula> neurons and larger <inline-formula><mml:math id="inf111"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msup><mml:mrow><mml:mi mathvariant="normal">R</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:mstyle></mml:math></inline-formula> neurons is significantly greater than that of all neurons for relevant signals (red bar, <xref ref-type="fig" rid="fig5">Figure 5a and d</xref> and <xref ref-type="fig" rid="fig5s1">Figure 5—figure supplement 1a</xref>), demonstrating that movement parameters are encoded very redundantly in neuronal population. In contrast, we cannot find this degree of neural redundancy in raw signals (purple bar, <xref ref-type="fig" rid="fig5">Figure 5a and d</xref> and <xref ref-type="fig" rid="fig5s1">Figure 5—figure supplement 1a</xref>) because the encoded information of smaller <inline-formula><mml:math id="inf112"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msup><mml:mrow><mml:mi mathvariant="normal">R</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:mstyle></mml:math></inline-formula> neurons are masked by irrelevant signals. Therefore, these smaller <inline-formula><mml:math id="inf113"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msup><mml:mrow><mml:mi mathvariant="normal">R</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:mstyle></mml:math></inline-formula> neurons, which are usually ignored, are actually useful and play a critical role in supporting neural redundancy. Generally, cortical redundancy can arise from neuronal correlations, which are critical for revealing certain aspects of neural circuit organization (<xref ref-type="bibr" rid="bib59">Yatsenko et al., 2015</xref>). Accordingly, we visualized the ordered correlation matrix of neurons (see Methods) for both raw and relevant signals (<xref ref-type="fig" rid="fig5">Figure 5b and e</xref> and <xref ref-type="fig" rid="fig5s1">Figure 5—figure supplement 1b</xref>) and found that the neuronal correlation of relevant signals is stronger than that of raw signals. These results demonstrate that irrelevant signals weaken the neuronal correlation, which may hinder the accurate investigation of neural circuit organization.</p><p>Considering the rich redundancy and strong correlation of neuronal activity, we wondered whether the neuronal population could utilize redundant information from other neurons to exhibit robustness under the perturbation of neuronal destruction. To investigate this question, we evaluated the decoding performance of dropping out neurons from larger <inline-formula><mml:math id="inf114"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msup><mml:mrow><mml:mi mathvariant="normal">R</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:mstyle></mml:math></inline-formula> to smaller <inline-formula><mml:math id="inf115"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msup><mml:mrow><mml:mi mathvariant="normal">R</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:mstyle></mml:math></inline-formula> on raw and relevant signals. The results (<xref ref-type="fig" rid="fig5">Figure 5c and f</xref> and <xref ref-type="fig" rid="fig5s1">Figure 5—figure supplement 1c</xref>) show that the decoding performance of the KF and ANN on raw signals (purple line) decreases steadily before the number of neurons marked (vertical gray line), and the remaining smaller <inline-formula><mml:math id="inf116"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msup><mml:mrow><mml:mi mathvariant="normal">R</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:mstyle></mml:math></inline-formula> neurons decode behavioral information poorly. In contrast, even if many neurons are lost, the decoding performance of KF and ANN on relevant signals (red line) maintains high accuracy. This finding indicates that behaviorally relevant signals are robust to the disturbance of neuron drop-out, and smaller <inline-formula><mml:math id="inf117"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msup><mml:mrow><mml:mi mathvariant="normal">R</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:mstyle></mml:math></inline-formula> neurons play a critical role in compensating for the failure of larger <inline-formula><mml:math id="inf118"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msup><mml:mrow><mml:mi mathvariant="normal">R</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:mstyle></mml:math></inline-formula> neurons. In contrast, this robustness cannot be observed in raw signals because irrelevant signals mask neurons’ information and weaken their correlation. Notably, the ANN outperforms the KF when only smaller <inline-formula><mml:math id="inf119"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msup><mml:mrow><mml:mi mathvariant="normal">R</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:mstyle></mml:math></inline-formula> neurons are left (<xref ref-type="fig" rid="fig5">Figure 5c and f</xref> and <xref ref-type="fig" rid="fig5s1">Figure 5—figure supplement 1c</xref>), suggesting that smaller <inline-formula><mml:math id="inf120"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msup><mml:mrow><mml:mi mathvariant="normal">R</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:mstyle></mml:math></inline-formula> neurons can fully exploit their nonlinear ability to cope with large-scale neuronal destruction.</p></sec><sec id="s2-6"><title>Distilled behaviorally relevant signals uncover that signals composed of smaller variance PCs encode rich behavioral information in complex nonlinear ways</title><p>The results presented above regarding subspace overlap (<xref ref-type="fig" rid="fig4">Figure 4</xref> and <xref ref-type="fig" rid="fig3s1">Figure 3—figure supplement 1</xref>) show that irrelevant signals have a small impact on larger variance PCs but dominate smaller variance PCs. Therefore, we aimed to investigate whether irrelevant signals would mask some encoded information of neural population, especially signals composed of smaller variance PCs.</p><p>To answer the question, we compared the decoding performance of raw and distilled signals with different raw PC groups. Specifically, we first divided the raw PCs into two groups, i.e., smaller variance PCs and larger variance PCs, defined by ratio of relevant to irrelevant signals in the raw PCs (the red triangle, see <xref ref-type="fig" rid="fig4">Figure 4c and g</xref> and <xref ref-type="fig" rid="fig3s1">Figure 3—figure supplement 1c</xref>). Then, we projected raw and distilled signals onto these two PC groups and got the corresponding signals. Results show that, for the smaller variance PC group, both KF and ANN achieve much better performance on distilled signals than raw signals (p&lt;0.01, Wilcoxon rank-sum test, for ANN), whereas for the larger variance PC group, the decoding performance of relevant signals does not improve a lot compared with the decoding performance of raw signals (see <xref ref-type="fig" rid="fig6">Figure 6a and d</xref> and <xref ref-type="fig" rid="fig5s1">Figure 5—figure supplement 1d</xref>). These results demonstrate that irrelevant signals mask the behavioral information encoded by different PC groups, especially for signals composed of smaller variance PCs (smaller variance PC signals), and smaller variance PC signals actually encode rich behavioral information.</p><fig-group><fig id="fig6" position="float"><label>Figure 6.</label><caption><title>Signals composed of smaller variance principal components (PCs) encode rich behavioral information in complex nonlinear ways.</title><p>(<bold>a–c</bold>) Results for dataset A. (<bold>a</bold>) The comparison of decoding performance between raw (purple) and distilled signals (red) composed of different raw PC groups, including smaller variance PCs (the proportion of irrelevant signals that make up raw PCs is higher than that of relevant signals), larger variance PCs (the proportion of irrelevant signals is lower than that of relevant ones). Error bars indicate mean ± standard deviation (s.d.) across five cross-validation folds. Asterisks denote significance of Wilcoxon rank-sum test with <sup>∗</sup>p&lt;0.01, <sup>∗∗</sup>p&lt;0.01. (<bold>b</bold>) The cumulative decoding performance of signals composed of cumulative PCs that are ordered from smaller to larger variance using Kalman filter (KF) (left) and artificial neural network (ANN) (right). The red patches indicate the decoding ability of the last 10% variance of relevant signals. (<bold>c</bold>) The cumulative decoding performance of signals composed of cumulative PCs that are ordered from larger to smaller variance using KF (left) and ANN (right). The red patches indicate the decoding gain of the last 10% variance signals of relevant signals superimposing on their top 90% variance signals. The inset shows the partially enlarged plot for view clearly. (<bold>d–f</bold>) Same as (<bold>a–c</bold>), but for dataset B.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-87881-fig6-v1.tif"/></fig><fig id="fig6s1" position="float" specific-use="child-fig"><label>Figure 6—figure supplement 1.</label><caption><title>Smaller variance principal component (PC) signals preferentially improve lower-speed velocity.</title><p>(<bold>a</bold>) The comparison of absolute improvement ratio between lower-speed (red) and higher-speed (purple) velocity when superimposing secondary signals on primary signals with Kalman filter (KF) on dataset A. Error bars indicate mean ± standard deviation (s.d.) across five cross-validation folds. Asterisks denote significance of Wilcoxon rank-sum test with <sup>∗</sup>p&lt;0.05, <sup>∗∗</sup>p&lt;0.01. (<bold>b, c</bold>) Same as (<bold>a</bold>), but for datasets B and C. (<bold>d</bold>) The comparison of relative improvement ratio between lower-speed (red patch) and higher-speed (no patch) velocity when superimposing secondary signals on primary signals with KF on dataset B. The first-row plot shows five example trials’ speed profile of the decoded velocity using primary signals (light blue line) and full signals (dark blue line; superimposing secondary signals on primary signals) and the true velocity (red line). The black horizontal line denotes the speed threshold. The second and third-row plots are the same as the first-row plot, but for X and Y velocity. The fourth-row plot shows the relative improvement ratio for each point in trials.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-87881-fig6-figsupp1-v1.tif"/></fig></fig-group><p>The above results are based on raw PCs. However, raw PCs are biased by irrelevant signals and thus cannot faithfully reflect the characteristics of relevant signals. As we have successfully separated the behaviorally relevant signals, we aimed to explore how behavioral information of distilled signals is distributed across relevant PCs. To do so, we used decoding models to evaluate the amount of behavioral information contained in cumulative PCs of relevant signals (using raw signals as a comparison). The cumulative variance explained by PCs in descending and ascending order of variance and the dimensionality corresponding to the top 90% variance signals (called primary signals) and the last 10% variance signals (called secondary signals) are shown in <xref ref-type="fig" rid="fig4s4">Figure 4—figure supplement 4</xref>.</p><p>Here, we first investigated secondary signals’ decoding ability solely by accumulating PCs from smaller to larger variance. The results show that, for relevant signals, KF can hardly decode behavioral information solely using secondary signals (red line; left plot, <xref ref-type="fig" rid="fig6">Figure 6b and e</xref> and <xref ref-type="fig" rid="fig5s1">Figure 5—figure supplement 1e</xref>), but ANN can decode rich information (red line; right plot, <xref ref-type="fig" rid="fig6">Figure 6b and e</xref> and <xref ref-type="fig" rid="fig5s1">Figure 5—figure supplement 1e</xref>). These results indicate that smaller variance PC signals encode rich information in complex nonlinear ways. In contrast, when using raw signals composed of the same number of dimensions as the secondary signals (purple line, <xref ref-type="fig" rid="fig6">Figure 6b and e</xref> and <xref ref-type="fig" rid="fig5s1">Figure 5—figure supplement 1e</xref>), the amount of information identified by ANN is significantly smaller than that of relevant secondary signals (p&lt;0.01, Wilcoxon rank-sum test). These results demonstrate that signals composed of these neural dimensions actually encode rich behavioral information, and irrelevant signals make them seem insignificant, indicating that behavioral information is distributed in a higher-dimensional subspace than expected from raw signals.</p><p>We then investigated the effect of superimposing secondary signals on primary signals by accumulating PCs from larger to lower variance. The results (<xref ref-type="fig" rid="fig6">Figure 6c and f</xref> and <xref ref-type="fig" rid="fig5s1">Figure 5—figure supplement 1f</xref>) show that secondary signals improve the decoding performance of ANN a little but improve the decoding performance of KF a lot. The discrepancy between the two decoders reflects their different abilities to utilize the information within the signal. KF cannot use the nonlinear information in primary signals as effectively as ANN can and thus require secondary signals to improve decoding performance. Notably, KF shows steady growth in decoding performance on relevant signals across 10–30 dimensions, and requires approximately 30–40 dimensions to achieve performance saturation. These results demonstrate that these smaller variance PC signals actually encode behavioral information, and suggest that behavioral information exists in a higher-dimensional subspace than anticipated from raw signals. Interestingly, we can find that although secondary signals nonlinearly encode behavioral information and are decoded poorly by linear decoders, they considerably improve KF performance by superimposing on primary signals (left plot, <xref ref-type="fig" rid="fig6">Figure 6c and f</xref> and <xref ref-type="fig" rid="fig5s1">Figure 5—figure supplement 1f</xref>); and the sum of the sole decoding performance of primary and secondary signals is lower than the decoding performance of full signals. These results indicate that the combination of smaller and larger variance PCs produces a synergy effect (<xref ref-type="bibr" rid="bib37">Narayanan et al., 2005</xref>), enabling secondary signals that cannot be linearly decoded to improve the linear decoding performance.</p><p>Finally, considering the substantial enhancement in KF decoding performance when superimposing the secondary signals on the primary ones, we explored which aspect of movement parameters was most improved. In BMIs, directional control has achieved great success (<xref ref-type="bibr" rid="bib19">Georgopoulos et al., 1986</xref>; <xref ref-type="bibr" rid="bib23">Hochberg et al., 2012</xref>), but precise speed control, especially at lower speeds such as hold or stop, has always been challenging (<xref ref-type="bibr" rid="bib56">Wodlinger et al., 2015</xref>; <xref ref-type="bibr" rid="bib25">Inoue et al., 2018</xref>). Thus, we hypothesized that these signals might improve the lower-speed velocity. To test this, we divided samples into lower-speed and higher-speed regions and assessed which region improved the most by superimposing the secondary signals (see details in Methods). After superimposing the secondary signals, the absolute improvement ratio of the lower-speed region is significantly higher than that of the higher-speed region (p&lt;0.05, Wilcoxon rank-sum test; <xref ref-type="fig" rid="fig6s1">Figure 6—figure supplement 1a, b, and c</xref>). Furthermore, we visualized the relative improvement ratio of five example trials for the two regions, and the results (<xref ref-type="fig" rid="fig6s1">Figure 6—figure supplement 1d</xref>) demonstrate that secondary signals significantly improve the estimation of lower speed. These results demonstrate that the secondary signals enhance the lower-speed control, suggesting that smaller variance PC signals may be involved in regulating precise motor control.</p></sec><sec id="s2-7"><title>Distilled behaviorally relevant signals potentially suggest that motor cortex may use a linear readout mechanism to generate movement behaviors</title><p>Understanding the readout mechanism of the motor cortex is crucial for both neuroscience and neural engineering, which remains unclear. By filtering out the interference of behaviorally irrelevant signals, we found a stunning result: the linear decoder KF achieves comparable performance to that of the nonlinear decoder ANN (p=0.10, 0.15, and 0.55 for datasets A, B, and C, Wilcoxon rank-sum test; <xref ref-type="fig" rid="fig2">Figure 2b, f, and j</xref>). Considering the decoding performance and model complexity (the simplicity principle, also called Occam’s razor), movement behaviors are more likely to be generated by the linear readout, suggesting linear readout may be performed in the motor cortex.</p><p>Given the significant improvement in linear decoding performance, one might doubt that it is our distillation model that makes signals that are inherently nonlinearly decodable become linearly decodable. In practice, this situation does not hold for two reasons. First, our criterion that irrelevant signals should contain minimal information can effectively exclude this situation. Specifically, if this situation occurs, the model would significantly modify the structure of the generated signals, causing a deviation from the structure of the ground truth signals. Consequently, these uncharacterized or modified ground truth signals would remain within the residuals, resulting in residuals that contain a substantial amount of information. To illustrate this, consider an example where <inline-formula><mml:math id="inf121"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>z</mml:mi><mml:mo>=</mml:mo><mml:mi>x</mml:mi><mml:mo>+</mml:mo><mml:mi>y</mml:mi><mml:mo>=</mml:mo><mml:msup><mml:mi>n</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mn>2</mml:mn></mml:mrow></mml:msup><mml:mo>+</mml:mo><mml:mi>y</mml:mi></mml:mstyle></mml:math></inline-formula>, with <inline-formula><mml:math id="inf122"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>z</mml:mi></mml:mstyle></mml:math></inline-formula>, <inline-formula><mml:math id="inf123"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>x</mml:mi></mml:mstyle></mml:math></inline-formula>, <inline-formula><mml:math id="inf124"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>y</mml:mi></mml:mstyle></mml:math></inline-formula>, and <inline-formula><mml:math id="inf125"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>n</mml:mi></mml:mstyle></mml:math></inline-formula> representing raw signals, relevant signals, irrelevant signals, and behavioral variables, respectively. If the distilled relevant signals are <inline-formula><mml:math id="inf126"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow class="MJX-TeXAtom-ORD"><mml:mover><mml:mi>x</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mo>=</mml:mo><mml:mi>n</mml:mi></mml:mstyle></mml:math></inline-formula>, the corresponding irrelevant signals are <inline-formula><mml:math id="inf127"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msup><mml:mi>n</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mn>2</mml:mn></mml:mrow></mml:msup><mml:mo>−</mml:mo><mml:mi>n</mml:mi><mml:mo>+</mml:mo><mml:mi>z</mml:mi></mml:mstyle></mml:math></inline-formula>. Clearly, the distilled signal can be linearly decoded, but this results in the residuals containing a large amount of information. However, as demonstrated in <xref ref-type="fig" rid="fig2">Figure 2c, g, and k</xref>, the irrelevant signals obtained by d-VAE only contain little information, thus excluding this situation. Second, our synthetic experiments offer additional evidence supporting the conclusion that d-VAE does not make inherently nonlinearly decodable signals become linearly decodable ones. As depicted in <xref ref-type="fig" rid="fig5s2">Figure 5—figure supplement 2c</xref>, there exists a significant performance gap between KF and ANN when decoding the ground truth signals of smaller <inline-formula><mml:math id="inf128"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msup><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi mathvariant="normal">R</mml:mi></mml:mrow><mml:mrow class="MJX-TeXAtom-ORD"><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:mstyle></mml:math></inline-formula> neurons (p&lt;0.01, Wilcoxon rank-sum test). KF exhibits notably low performance, leaving substantial room for compensation by d-VAE. However, following processing by d-VAE, KF’s performance of distilled signals fails to surpass its already low ground truth performance and remains significantly inferior to ANN’s performance (p&lt;0.01, Wilcoxon rank-sum test). These results collectively confirm that our approach does not convert signals that are inherently nonlinearly decodable into linearly decodable ones.</p><p>In summary, these findings demonstrate that behaviorally irrelevant signals significantly complicate the readout of behavioral information and provide compelling evidence supporting the notion that the motor cortex may use a linear readout mechanism to generate movement behaviors.</p></sec></sec><sec id="s3" sec-type="discussion"><title>Discussion</title><p>In this study, we proposed a new perspective for studying neural mechanisms, namely, using separated accurate behaviorally relevant signals instead of raw signals; and we provided a novel distillation framework to define, extract, and validate behaviorally relevant signals. By separating behaviorally relevant and irrelevant signals, we found that neural responses previously considered to contain little information actually encode rich behavioral information in complex nonlinear ways, and they play an important role in neural encoding and decoding. Furthermore, we found that linear decoders can achieve comparable performance to that of nonlinear decoders, providing compelling evidence for the presence of linear readout in the motor cortex. Overall, our results reveal unexpected complex encoding but simple decoding mechanisms in the motor cortex.</p><sec id="s3-1"><title>Signal separation by d-VAE</title><p>Behaviorally relevant patterns can be extracted either at single-neuron or latent neural population levels. In our study, we focused on the single-neuron level, aiming to preserve the underlying properties of individual neurons. By maintaining the properties of each neuron, researchers can investigate how the neuronal population performs when one of the neurons is destroyed. This kind of analysis is particularly useful in closed-loop stimulation experiments that use electrophysiological (<xref ref-type="bibr" rid="bib52">Sun et al., 2022</xref>) or optogenetic (<xref ref-type="bibr" rid="bib61">Zhang et al., 2023</xref>) interventions. Furthermore, behaviorally relevant signals also allow for population-level analysis and provide clean benchmark signals to test and compare the variance capture ability of different hypothesis-driven models.</p><p>At the single-neuron level, it is common practice to use trial-averaged neuronal responses of the same task parameters to analyze neural mechanisms (<xref ref-type="bibr" rid="bib29">Kobak et al., 2016</xref>; <xref ref-type="bibr" rid="bib45">Rouse and Schieber, 2018</xref>). However, trial averaging sacrifices single-trial information, thereby providing an incomplete characterization of neural activity. Furthermore, trial-averaged responses still contain a significant amount of behaviorally irrelevant signals caused by uninstructed movements (<xref ref-type="bibr" rid="bib35">Musall et al., 2019</xref>), which can lead to a contaminated version of behaviorally relevant signals. In contrast, our model is capable of extracting clean behaviorally relevant neural activity for every single trial. At the latent population level, existing latent variable models (<xref ref-type="bibr" rid="bib47">Sani et al., 2021</xref>; <xref ref-type="bibr" rid="bib42">Pandarinath et al., 2018</xref>; <xref ref-type="bibr" rid="bib60">Yu, 2008</xref>; <xref ref-type="bibr" rid="bib62">Zhou, 2020</xref>; <xref ref-type="bibr" rid="bib24">Hurwitz, 2021</xref>) focus on modeling some specific properties of latent population representations, such as linear or nonlinear dynamics (<xref ref-type="bibr" rid="bib47">Sani et al., 2021</xref>; <xref ref-type="bibr" rid="bib42">Pandarinath et al., 2018</xref>; <xref ref-type="bibr" rid="bib6">Churchland et al., 2012</xref>; <xref ref-type="bibr" rid="bib24">Hurwitz, 2021</xref>), temporal smoothness (<xref ref-type="bibr" rid="bib60">Yu, 2008</xref>), and interpretability (<xref ref-type="bibr" rid="bib62">Zhou, 2020</xref>). Since these models make restrictive assumptions involving characterizing specific neural properties, they fail to capture other parts of behaviorally relevant signals that do not meet their assumptions, providing no guarantee that the generated signals preserve behavioral information maximally. In contrast, our objective is to extract accurate behaviorally relevant signals that closely approximate the ground truth relevant signals as much as possible. To ensure this, we deliberately impose constraints on the model, ensuring that it generates signals that retain neuronal properties while preserving behavioral information to the highest degree possible. Notably, the pivotal operation of striking a balance between the reconstruction and decoding performance of generated signals to extract relevant signals is a distinctive feature absent in other models. At the population level, dimensionality reduction methods aided by task parameters (<xref ref-type="bibr" rid="bib29">Kobak et al., 2016</xref>; <xref ref-type="bibr" rid="bib50">Schneider et al., 2023</xref>) are another important way to discover the latent neural embeddings relevant to task parameters, which may provide new insight into neural representations. In contrast with this class of methods, our model focuses on the signal level, not the latent embedding level.</p><p>Although we made every effort, our model is still not able to perfectly extract behaviorally relevant neural signals, resulting in a small amount of behavioral information leakage in the residuals. Nevertheless, the signals distilled by our model are reliable, and the minor imperfections do not affect the conclusions drawn from our analysis. In the future, better models can be developed to extract behaviorally relevant signals more accurately, such as incorporating multiple time step information (<xref ref-type="bibr" rid="bib42">Pandarinath et al., 2018</xref>; <xref ref-type="bibr" rid="bib47">Sani et al., 2021</xref>; <xref ref-type="bibr" rid="bib24">Hurwitz, 2021</xref>) and contrastive learning (<xref ref-type="bibr" rid="bib50">Schneider et al., 2023</xref>) or metric learning (<xref ref-type="bibr" rid="bib32">Li et al., 2021</xref>) techniques into models.</p></sec><sec id="s3-2"><title>Implications for analyzing neural activity by separation</title><p>Studying neural mechanisms through noisy signals is akin to looking at flowers in a fog, which makes it difficult to discern the truth. Thus, removing the interference of irrelevant signals is necessary and beneficial for analyzing neural activity, whether at the single-neuron level or population level.</p><p>At the single-neuron level, trial-to-trial neuronal variability poses a significant challenge to identifying the actual neuronal pattern changes. The variability can arise from various sources, including meaningless noise (<xref ref-type="bibr" rid="bib13">Faisal et al., 2008</xref>), meaningful but behaviorally irrelevant neural processes (<xref ref-type="bibr" rid="bib35">Musall et al., 2019</xref>), and intrinsic components of neural encoding (<xref ref-type="bibr" rid="bib53">Walker et al., 2020</xref>). However, it is still unclear to what extent each source contributes to the variability (<xref ref-type="bibr" rid="bib13">Faisal et al., 2008</xref>). By separating behaviorally relevant and irrelevant parts, we could roughly determine the extent to which these two parts contribute to the variability and explore which type of variability these two parts may contain. Our results demonstrate that behaviorally irrelevant signals are a significant contributor to variability, which may include both meaningless noise and meaningful but behaviorally irrelevant signals as behaviorally irrelevant signals are not pure noise and may carry some structures (thick blue line, <xref ref-type="fig" rid="fig4">Figure 4b and f</xref> and <xref ref-type="fig" rid="fig4s1">Figure 4—figure supplement 1b</xref>). Notably, behaviorally relevant signals also exhibit some variability, which may arise from intrinsic components of neural encoding and provide the neural basis for motor learning (<xref ref-type="bibr" rid="bib9">Dhawale et al., 2017</xref>). Moreover, eliminating the variability caused by irrelevant signals enables us to better observe and compare actual neuronal pattern changes and may facilitate the study of learning mechanisms (<xref ref-type="bibr" rid="bib46">Sadtler et al., 2014</xref>; <xref ref-type="bibr" rid="bib22">Hennig et al., 2021</xref>).</p><p>At the population level, the dimensionality of neural manifolds quantifies the degrees of freedom required to describe population activity without significant information loss (<xref ref-type="bibr" rid="bib31">Lee and Verleysen, 2007</xref>; <xref ref-type="bibr" rid="bib2">Altan et al., 2021</xref>). However, determining the dimensionality of neural manifolds associated with specific behaviors from raw signals is challenging since it is difficult to discern how many variances correspond to irrelevant signals, which often depend heavily on signal quality. A previous study (<xref ref-type="bibr" rid="bib2">Altan et al., 2021</xref>) demonstrated, through simulation experiments involving different levels of noise, that such noise makes methods overestimate the neural dimensionality. Our results, consistent with theirs, indicate that using raw signals which include many irrelevant signals will cause an overestimation of the neural dimensionality (<xref ref-type="fig" rid="fig4s4">Figure 4—figure supplement 4</xref>). These findings highlight the need to filter out irrelevant signals when estimating the neural dimensionality. Furthermore, this perspective of signal separation has broader implications for other studies. For instance, researchers can isolate neural signals corresponding to different behaviors and explore their shared and exclusive patterns to uncover underlying common and unique mechanisms of different behaviors (<xref ref-type="bibr" rid="bib16">Gallego et al., 2018</xref>).</p></sec><sec id="s3-3"><title>Implications for exploring neural mechanisms by separation</title><p>At the single-neuron level, previous studies (<xref ref-type="bibr" rid="bib4">Carmena et al., 2005</xref>; <xref ref-type="bibr" rid="bib37">Narayanan et al., 2005</xref>) have shown that neuronal ensembles redundantly encode movement behaviors in the motor cortex. However, our results reveal a significantly higher level of redundancy than previously reported. Specifically, prior studies found that the decoding performance steadily declines as neurons drop out, which is consistent with our results drawn from raw signals. In contrast, our results show that decoders maintain high performance on distilled signals even when many neurons drop out. Our findings reinforce the idea that movement behavior is redundantly encoded in the motor cortex and demonstrate that the brain is robust enough to tolerate large-scale neuronal destruction while maintaining brain function (<xref ref-type="bibr" rid="bib1">Alstott et al., 2009</xref>).</p><p>At the population level, previous studies have proposed that motor control is achieved through low-dimensional neural manifolds, with analyses typically using between 6 and 15 PCs (<xref ref-type="bibr" rid="bib6">Churchland et al., 2012</xref>; <xref ref-type="bibr" rid="bib27">Kaufman et al., 2014</xref>; <xref ref-type="bibr" rid="bib11">Elsayed et al., 2016</xref>; <xref ref-type="bibr" rid="bib46">Sadtler et al., 2014</xref>; <xref ref-type="bibr" rid="bib21">Golub et al., 2018</xref>; <xref ref-type="bibr" rid="bib15">Gallego et al., 2017</xref>; <xref ref-type="bibr" rid="bib17">Gallego et al., 2020</xref>). However, our results challenge this idea by showing that signals composed of smaller variance PCs nonlinearly encode a significant amount of behavioral information, and the number of useful PCs ranges from 30 to 40, far exceeding the usual number analyzed. These results suggest that behavioral information is distributed in a higher-dimensional neural space than previously thought. Interestingly, although smaller variance PC signals nonlinearly encode behavioral information, their behavioral information can be linearly decoded by superimposing them onto larger variance PC signals. This result is consistent with the finding that nonlinear mixed selectivity can yield high-dimensional neural responses and thus allow linear readout of behavioral information by downstream neurons (<xref ref-type="bibr" rid="bib44">Rigotti et al., 2013</xref>; <xref ref-type="bibr" rid="bib14">Fusi et al., 2016</xref>). Moreover, we found that smaller variance PC signals can improve precise motor control, such as lower-speed control. Analogously, recent studies have found that smaller variance PCs of hand postures are task-dependent and relate to the precise and complex postures (<xref ref-type="bibr" rid="bib57">Yan et al., 2020</xref>). These findings suggest that neural signals composed of lower variance PCs may be involved in the regulation of precise motor control.</p><p>In the motor cortex, in what form downstream neurons read out behavioral information is still an open question. Previous studies have shown that nonlinear readout is superior to linear readout on raw signals (<xref ref-type="bibr" rid="bib38">Naufel et al., 2019</xref>; <xref ref-type="bibr" rid="bib20">Glaser et al., 2020</xref>; <xref ref-type="bibr" rid="bib55">Willsey et al., 2022</xref>). However, by filtering out the interference of behaviorally irrelevant signals, our study found that accurate decoding performance can be achieved through linear readout, suggesting that the motor cortex may perform linear readout to generate movement behaviors. Similar observations involving raw signals have been reported across various cortices, including the inferotemporal cortex (<xref ref-type="bibr" rid="bib33">Majaj et al., 2015</xref>), perirhinal cortex (<xref ref-type="bibr" rid="bib41">Pagan et al., 2013</xref>), and somatosensory cortex (<xref ref-type="bibr" rid="bib39">Nogueira et al., 2023</xref>). These observations support the hypothesis that linear readout might serve as a general principle in the brain. However, further experiments are needed to verify this hypothesis across a wider range of cortical regions. In motor cortex, different neurons encode behavioral information with varying degrees of nonlinearity, exhibiting complex and heterogeneous response patterns. Despite this complexity of neural encoding, these responses allow for a linear readout of behavioral information. This phenomenon suggests that the complexity of encoding mechanisms may underlie the simplicity of decoding mechanisms.</p><p>About studying decoding mechanisms, recent studies (<xref ref-type="bibr" rid="bib43">Pitkow et al., 2015</xref>; <xref ref-type="bibr" rid="bib18">Ganmor et al., 2015</xref>; <xref ref-type="bibr" rid="bib58">Yang et al., 2021</xref>) have focused on investigating how the brain decodes task information in the presence of noise. Unlike previous works, our research specifically explores the decoding mechanisms of behaviorally relevant signals rather than raw signals. We assume that the brain filters out irrelevant signals before decoding the relevant ones. This leads to the question of whether the brain actually adopts this strategy to access relevant signals. Given the existence of behaviorally relevant signals, it is reasonable to assume that the brain has intrinsic mechanisms to differentiate between relevant and irrelevant signals. There is growing evidence suggesting that the brain utilizes various mechanisms, such as attention and specialized filtering, to suppress irrelevant signals and enhance relevant signals (<xref ref-type="bibr" rid="bib51">Sreenivasan and Fiete, 2011</xref>; <xref ref-type="bibr" rid="bib49">Schneider et al., 2018</xref>; <xref ref-type="bibr" rid="bib36">Nakajima et al., 2019</xref>). Therefore, it is plausible that the brain filters before decoding, thereby effectively accessing behaviorally relevant signals. Furthermore, our study reveals that irrelevant signals are the most critical factor affecting accurate and robust decoding, and achieving accurate and robust linear decoding requires weak neural responses. These findings have two important implications for developing accurate and robust BMIs: designing preprocessing filtering algorithms or developing decoding algorithms that include filtering out behaviorally irrelevant signals, and paying attention to the role of weak neural responses in motor control. More generally, our study provides a powerful framework for separating behaviorally relevant and irrelevant signals, which can be applied to other cortical data to uncover more hidden neural mechanisms.</p></sec></sec><sec id="s4" sec-type="methods"><title>Methods</title><sec id="s4-1"><title>Dataset and preprocessing</title><p>Three datasets with different paradigms are employed, including obstacle avoidance task dataset (<xref ref-type="bibr" rid="bib54">Wang et al., 2017</xref>), center-out reaching task dataset (<xref ref-type="bibr" rid="bib10">Dyer et al., 2017</xref>), and self-paced reaching task dataset (<xref ref-type="bibr" rid="bib40">O’Doherty, 2017</xref>).</p><p>The first dataset (dataset A) is the obstacle avoidance dataset. An adult male Rhesus monkey was trained to use the joystick to move the computer cursor to bypass the obstacle and reach the target. Neural data were recorded from the monkey’s upper limb area of the dorsal premotor (PMd) using a 96-electrode Utah array (Blackrock Microsystems Inc, USA). Multi-unit activity (MUA) signals are used in the present study. The corresponding behavioral data (velocity) were simultaneously collected. There are 2 days of data (20140106 and 20140107), and each day contains 171 trials on average. All animal handling procedures were authorized by the Animal Care Committee at Zhejiang University, China, and conducted following the Guide for Care and Use of Laboratory Animals (China Ministry of Health).</p><p>The second dataset (dataset B) is publicly available and provided by Kording Lab (<xref ref-type="bibr" rid="bib10">Dyer et al., 2017</xref>). The monkey was trained to complete two-dimensional eight-direction center-out reaching tasks. We used 2 days of data from subject C (20161007 and 20161011). Each day contains 190 trials on average. Neural data are spike-sorted PMd signals. The behavioral data were simultaneously collected in instantaneous velocity.</p><p>The third dataset (dataset C) is publicly available and provided by Sabes Lab (Zenodo dataset) (<xref ref-type="bibr" rid="bib40">O’Doherty, 2017</xref>). An adult male Rhesus monkey was trained to finish self-paced reaching tasks within an 8-by-8 square grid. There are no inter-trial intervals during the experiment. Neural data were recorded from the monkey’s primary motor cortex (M1) area with a 96-channel silicon microelectrode array. The neural data are the MUA signals. Hand velocity was obtained from the position through a discrete derivative. The recording period for the data (20170124 01) is about 10 min.</p><p>For all datasets, the neural signals were binned by a 100 ms sliding window without overlap. As a preprocess, we smoothed the neural signals using a moving average filter with three bins. We excluded some electrode activities with low mean firing rates (&lt;0.5 Hz mean firing rates across all bins) and did not perform any other pre-selection to select neurons. For the computation of the FF, we chose 12 and 14 points as the thresholds of trial length for datasets A and B, respectively; trials with a length less than the threshold were discarded (discard about 7% and 2% trials for datasets A and B), trials longer than the threshold were truncated to threshold length from the starting point. Since dataset C has no trial information, FF is not calculated for this dataset. For the analysis of datasets A and B, we selected 1 day of these two datasets for analysis (20140107 for dataset A and 20161011 for dataset B).</p></sec><sec id="s4-2"><title>The synthetic dataset</title><p>The synthetic dataset is used to demonstrate that d-VAE can extract effective behaviorally relevant signals that are similar to the ground truth signals. The specific process of generating synthetic data is as follows. First, we randomly selected nine larger <inline-formula><mml:math id="inf129"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msup><mml:mrow><mml:mi mathvariant="normal">R</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:mstyle></mml:math></inline-formula> neurons from neurons that <inline-formula><mml:math id="inf130"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msup><mml:mrow><mml:mi mathvariant="normal">R</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:mstyle></mml:math></inline-formula> is greater than 0.1, and three smaller <inline-formula><mml:math id="inf131"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msup><mml:mrow><mml:mi mathvariant="normal">R</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:mstyle></mml:math></inline-formula> neurons from neurons that <inline-formula><mml:math id="inf132"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msup><mml:mrow><mml:mi mathvariant="normal">R</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:mstyle></mml:math></inline-formula> is lower than 0.01 of dataset B (20161011). Second, we used deep neural networks to learn the encoding model between movement kinematics (movement velocity of dataset B) and neural signals using onefold train data. The details of the networks are demonstrated as follows. The networks use two hidden layer multilayer perceptron (MLP) with 500 and 500 hidden units. The activation function is ReLU. A SoftPlus activation function follows the last layer of the networks. The reconstruction loss is the Poisson likelihood function. After learning the encoding model, we used the learned encoding model to generate the ground truth of behaviorally relevant signals from all kinematics data of dataset B. Then, we added white Gaussian noise to the behaviorally relevant signals such that the noisy signals have a signal-to-noise ratio of 7 dB. After adding noise, the <inline-formula><mml:math id="inf133"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msup><mml:mrow><mml:mi mathvariant="normal">R</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:mstyle></mml:math></inline-formula> of the three smaller <inline-formula><mml:math id="inf134"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msup><mml:mrow><mml:mi mathvariant="normal">R</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:mstyle></mml:math></inline-formula> neurons is lower than 0.03. We regarded the noisy signals as raw signals and the added Gaussian noise as behaviorally irrelevant signals. Finally, we separated the synthetic data into five folds for cross-validation model evaluation.</p></sec><sec id="s4-3"><title>Distill-VAE</title><p>Notation: <inline-formula><mml:math id="inf135"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi mathvariant="bold-italic">x</mml:mi><mml:mo>∈</mml:mo><mml:msup><mml:mrow><mml:mi mathvariant="double-struck">R</mml:mi></mml:mrow><mml:mrow><mml:mi>n</mml:mi></mml:mrow></mml:msup></mml:mrow></mml:mstyle></mml:math></inline-formula> denotes raw neural signals. <inline-formula><mml:math id="inf136"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi mathvariant="bold-italic">x</mml:mi><mml:mrow><mml:mi>r</mml:mi></mml:mrow></mml:msub><mml:mo>∈</mml:mo><mml:msup><mml:mrow><mml:mi mathvariant="double-struck">R</mml:mi></mml:mrow><mml:mrow><mml:mi>n</mml:mi></mml:mrow></mml:msup></mml:mrow></mml:mstyle></mml:math></inline-formula> represents behaviorally relevant signals. <inline-formula><mml:math id="inf137"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi mathvariant="bold-italic">x</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mi mathvariant="bold-italic">x</mml:mi><mml:mo>−</mml:mo><mml:msub><mml:mi mathvariant="bold-italic">x</mml:mi><mml:mrow><mml:mi>r</mml:mi></mml:mrow></mml:msub><mml:mo>∈</mml:mo><mml:msup><mml:mrow><mml:mi mathvariant="double-struck">R</mml:mi></mml:mrow><mml:mrow><mml:mi>n</mml:mi></mml:mrow></mml:msup></mml:mrow></mml:mstyle></mml:math></inline-formula> represents behaviorally irrelevant signals. <inline-formula><mml:math id="inf138"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi mathvariant="bold-italic">z</mml:mi><mml:mo>∈</mml:mo><mml:msup><mml:mrow><mml:mi mathvariant="double-struck">R</mml:mi></mml:mrow><mml:mrow><mml:mi>d</mml:mi></mml:mrow></mml:msup></mml:mrow></mml:mstyle></mml:math></inline-formula> denotes the latent neural representations. <inline-formula><mml:math id="inf139"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi mathvariant="bold-italic">z</mml:mi><mml:mrow><mml:mi>p</mml:mi><mml:mi>r</mml:mi><mml:mi>i</mml:mi><mml:mi>o</mml:mi><mml:mi>r</mml:mi></mml:mrow></mml:msub><mml:mo>∈</mml:mo><mml:msup><mml:mrow><mml:mi mathvariant="double-struck">R</mml:mi></mml:mrow><mml:mrow><mml:mi>d</mml:mi></mml:mrow></mml:msup></mml:mrow></mml:mstyle></mml:math></inline-formula> denotes the prior latent neural representations. <inline-formula><mml:math id="inf140"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi mathvariant="bold-italic">y</mml:mi><mml:mo>∈</mml:mo><mml:msup><mml:mrow><mml:mi mathvariant="double-struck">R</mml:mi></mml:mrow><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:msup></mml:mrow></mml:mstyle></mml:math></inline-formula> represents kinematics. <inline-formula><mml:math id="inf141"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>f</mml:mi><mml:mo>:</mml:mo><mml:msup><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi mathvariant="double-struck">R</mml:mi></mml:mrow><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>n</mml:mi></mml:mrow></mml:msup><mml:mo stretchy="false">→</mml:mo><mml:msup><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi mathvariant="double-struck">R</mml:mi></mml:mrow><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>d</mml:mi></mml:mrow></mml:msup></mml:mstyle></mml:math></inline-formula> represents the inference model (encoder) of VAE. <inline-formula><mml:math id="inf142"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>g</mml:mi><mml:mo>:</mml:mo><mml:msup><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi mathvariant="double-struck">R</mml:mi></mml:mrow><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>d</mml:mi></mml:mrow></mml:msup><mml:mo stretchy="false">→</mml:mo><mml:msup><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi mathvariant="double-struck">R</mml:mi></mml:mrow><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>n</mml:mi></mml:mrow></mml:msup></mml:mstyle></mml:math></inline-formula> represents the generative model (decoder) of VAE. <inline-formula><mml:math id="inf143"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>m</mml:mi><mml:mo>:</mml:mo><mml:msup><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi mathvariant="double-struck">R</mml:mi></mml:mrow><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>k</mml:mi></mml:mrow></mml:msup><mml:mo stretchy="false">→</mml:mo><mml:msup><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi mathvariant="double-struck">R</mml:mi></mml:mrow><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>d</mml:mi></mml:mrow></mml:msup></mml:mstyle></mml:math></inline-formula> represents the mapping from kinematics to prior latent representations. <inline-formula><mml:math id="inf144"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>h</mml:mi><mml:mo>:</mml:mo><mml:msup><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi mathvariant="double-struck">R</mml:mi></mml:mrow><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>d</mml:mi></mml:mrow></mml:msup><mml:mo stretchy="false">→</mml:mo><mml:msup><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi mathvariant="double-struck">R</mml:mi></mml:mrow><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>k</mml:mi></mml:mrow></mml:msup></mml:mstyle></mml:math></inline-formula> represents an affine mapping from latent representations to kinematics.</p><p>d-VAE is a generative model based on VAEs (<xref ref-type="bibr" rid="bib28">Kingma, 2013</xref>), specially designed to extract behaviorally relevant signals from raw signals. The generative model of d-VAE is<disp-formula id="equ2"><label>(2)</label><mml:math id="m2"><mml:mrow><mml:msub><mml:mi>p</mml:mi><mml:mrow><mml:mi>θ</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi mathvariant="bold-italic">x</mml:mi><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mi mathvariant="bold-italic">y</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:msub><mml:mo>∫</mml:mo><mml:mrow><mml:mi mathvariant="bold-italic">z</mml:mi></mml:mrow></mml:msub><mml:msub><mml:mi>p</mml:mi><mml:mrow><mml:mi>θ</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi mathvariant="bold-italic">x</mml:mi><mml:mo>,</mml:mo><mml:mi mathvariant="bold-italic">z</mml:mi><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mi mathvariant="bold-italic">y</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mrow><mml:mi mathvariant="normal">d</mml:mi></mml:mrow><mml:mi mathvariant="bold-italic">z</mml:mi><mml:mo>=</mml:mo><mml:msub><mml:mo>∫</mml:mo><mml:mrow><mml:mi mathvariant="bold-italic">z</mml:mi></mml:mrow></mml:msub><mml:msub><mml:mi>p</mml:mi><mml:mrow><mml:mi>m</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi mathvariant="bold-italic">z</mml:mi><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mi mathvariant="bold-italic">y</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:msub><mml:mi>p</mml:mi><mml:mrow><mml:mi>g</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi mathvariant="bold-italic">x</mml:mi><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mi mathvariant="bold-italic">z</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mrow><mml:mi mathvariant="normal">d</mml:mi></mml:mrow><mml:mi mathvariant="bold-italic">z</mml:mi><mml:mo>,</mml:mo></mml:mrow></mml:math></disp-formula></p><p>where <inline-formula><mml:math id="inf145"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>p</mml:mi><mml:mrow><mml:mi>m</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi mathvariant="bold-italic">z</mml:mi><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mi mathvariant="bold-italic">y</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mstyle></mml:math></inline-formula> denotes the conditional prior distribution of latent variables given the kinematics parameterized by feedforward neural networks <inline-formula><mml:math id="inf146"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>m</mml:mi></mml:mstyle></mml:math></inline-formula>, <inline-formula><mml:math id="inf147"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>p</mml:mi><mml:mrow><mml:mi>g</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi mathvariant="bold-italic">x</mml:mi><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mi mathvariant="bold-italic">z</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mstyle></mml:math></inline-formula> denotes the conditional prior distribution of raw signals given the latent variables parameterized by feedforward neural networks <inline-formula><mml:math id="inf148"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>g</mml:mi></mml:mstyle></mml:math></inline-formula>, <inline-formula><mml:math id="inf149"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>p</mml:mi><mml:mrow><mml:mi>θ</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi mathvariant="bold-italic">x</mml:mi><mml:mo>,</mml:mo><mml:mi mathvariant="bold-italic">z</mml:mi><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mi mathvariant="bold-italic">y</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mstyle></mml:math></inline-formula> represents the joint distribution of raw signals and latent variables given the kinematics parameterized by parameters <inline-formula><mml:math id="inf150"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>θ</mml:mi><mml:mo>=</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mi>m</mml:mi><mml:mo>,</mml:mo><mml:mi>g</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mstyle></mml:math></inline-formula>, and <inline-formula><mml:math id="inf151"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>p</mml:mi><mml:mrow><mml:mi>θ</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi mathvariant="bold-italic">x</mml:mi><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mi mathvariant="bold-italic">y</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mstyle></mml:math></inline-formula> is the marginal distribution of raw signals parameterized by parameters <inline-formula><mml:math id="inf152"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>θ</mml:mi></mml:mstyle></mml:math></inline-formula>.</p><p>To learn the model, we need to maximize the evidence lower bound (ELBO) of <inline-formula><mml:math id="inf153"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>p</mml:mi><mml:mrow><mml:mi>θ</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi mathvariant="bold-italic">x</mml:mi><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mi mathvariant="bold-italic">y</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mstyle></mml:math></inline-formula>:<disp-formula id="equ3"><label>(3)</label><mml:math id="m3"><mml:mrow><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msub><mml:mrow><mml:mi class="mathcal" mathvariant="script">L</mml:mi></mml:mrow><mml:mrow><mml:mi>E</mml:mi><mml:mi>L</mml:mi><mml:mi>B</mml:mi><mml:mi>O</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi mathvariant="bold-italic">x</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:msub><mml:mrow><mml:mi mathvariant="double-struck">E</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="bold-italic">z</mml:mi><mml:mo>∼</mml:mo><mml:msub><mml:mi>q</mml:mi><mml:mrow><mml:mi>ϕ</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi mathvariant="bold-italic">z</mml:mi><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mi mathvariant="bold-italic">x</mml:mi><mml:mo>,</mml:mo><mml:mi mathvariant="bold-italic">y</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msub><mml:mrow><mml:mo>[</mml:mo><mml:mrow><mml:msub><mml:mi>p</mml:mi><mml:mrow><mml:mi>θ</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi mathvariant="bold-italic">x</mml:mi><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mi mathvariant="bold-italic">z</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>]</mml:mo></mml:mrow><mml:mo>−</mml:mo><mml:msub><mml:mi>D</mml:mi><mml:mrow><mml:mi>K</mml:mi><mml:mi>L</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>q</mml:mi><mml:mrow><mml:mi>ϕ</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi mathvariant="bold-italic">z</mml:mi><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mi mathvariant="bold-italic">x</mml:mi><mml:mo>,</mml:mo><mml:mi mathvariant="bold-italic">y</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mi>p</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi mathvariant="bold-italic">z</mml:mi><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mi mathvariant="bold-italic">y</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo stretchy="false">)</mml:mo><mml:mo>≤</mml:mo><mml:mi>log</mml:mi><mml:mo>⁡</mml:mo><mml:msub><mml:mi>p</mml:mi><mml:mrow><mml:mi>θ</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi mathvariant="bold-italic">x</mml:mi><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mi mathvariant="bold-italic">y</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>,</mml:mo></mml:mstyle></mml:mrow></mml:math></disp-formula></p><p>where the first term on the right-hand side of <xref ref-type="disp-formula" rid="equ3">Equation 3</xref> is called reconstruction term, the second term is called regularization term, <inline-formula><mml:math id="inf154"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>q</mml:mi><mml:mrow><mml:mi>ϕ</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi mathvariant="bold-italic">z</mml:mi><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mi mathvariant="bold-italic">x</mml:mi><mml:mo>,</mml:mo><mml:mi mathvariant="bold-italic">y</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mstyle></mml:math></inline-formula> denotes inference model parameterized by parameters <inline-formula><mml:math id="inf155"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>ϕ</mml:mi></mml:mstyle></mml:math></inline-formula>, and <inline-formula><mml:math id="inf156"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msub><mml:mi>D</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>K</mml:mi><mml:mi>L</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mo>⋅</mml:mo><mml:mrow class="MJX-TeXAtom-ORD"><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mo>⋅</mml:mo><mml:mo stretchy="false">)</mml:mo></mml:mstyle></mml:math></inline-formula> denotes the Kullback-Leibler (KL) divergence. In d-VAE, we set <inline-formula><mml:math id="inf157"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>q</mml:mi><mml:mrow><mml:mi>ϕ</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi mathvariant="bold-italic">z</mml:mi><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mi mathvariant="bold-italic">x</mml:mi><mml:mo>,</mml:mo><mml:mi mathvariant="bold-italic">y</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:msub><mml:mi>q</mml:mi><mml:mrow><mml:mi>f</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi mathvariant="bold-italic">z</mml:mi><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mi mathvariant="bold-italic">x</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mstyle></mml:math></inline-formula>, where <inline-formula><mml:math id="inf158"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>f</mml:mi></mml:mstyle></mml:math></inline-formula> is the inference model parameterized by feedforward neural networks. Because during the test stage, we cannot obtain the ground truth of kinematics, and we need to use only raw signals to extract relevant signals. Note that d-VAE aims to extract behaviorally relevant signals from raw signals, not generate signals that are too similar to raw signals. Therefore, we modified the objective loss function based on <inline-formula><mml:math id="inf159"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mrow><mml:mi class="mathcal" mathvariant="script">L</mml:mi></mml:mrow><mml:mrow><mml:mi>E</mml:mi><mml:mi>L</mml:mi><mml:mi>B</mml:mi><mml:mi>O</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi mathvariant="bold-italic">x</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mstyle></mml:math></inline-formula> (see <xref ref-type="disp-formula" rid="equ10">Equation 10</xref>).</p><p>To distill behaviorally relevant neural signals, d-VAE utilizes the trade-off between the decoding and reconstruction abilities of generated behaviorally relevant signals <inline-formula><mml:math id="inf160"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi mathvariant="bold-italic">x</mml:mi><mml:mrow><mml:mi>r</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula>. The basic assumption is generated behaviorally relevant signals that contain behaviorally irrelevant signals harms their decoding ability. Our approach for distilling behaviorally relevant signals consists of three steps, including identifying latent representations <inline-formula><mml:math id="inf161"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi mathvariant="bold-italic">z</mml:mi></mml:mrow></mml:mstyle></mml:math></inline-formula>, generating behaviorally relevant signals <inline-formula><mml:math id="inf162"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi mathvariant="bold-italic">x</mml:mi><mml:mrow><mml:mi>r</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula>, and decoding behaviorally relevant signals <inline-formula><mml:math id="inf163"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi mathvariant="bold-italic">x</mml:mi><mml:mrow><mml:mi>r</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula>.</p><sec id="s4-3-1"><title>Identifying latent representations</title><p>Identifying latent representations containing behaviorally relevant information is the crucial part because latent representations influence the subsequent generation. Effective representations are more likely to generate proper behaviorally relevant neural signals <inline-formula><mml:math id="inf164"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi mathvariant="bold-italic">x</mml:mi><mml:mrow><mml:mi>r</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula>. d-VAE identifies latent representations with inference model <inline-formula><mml:math id="inf165"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>f</mml:mi></mml:mstyle></mml:math></inline-formula>, i.e., μ, where μ and <inline-formula><mml:math id="inf166"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msup><mml:mi mathvariant="bold-italic">σ</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:mstyle></mml:math></inline-formula> denote the mean and variance of latent representations; thus the posterior distribution is <inline-formula><mml:math id="inf167"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>q</mml:mi><mml:mrow><mml:mi>f</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi mathvariant="bold-italic">z</mml:mi><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mi mathvariant="bold-italic">x</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mrow><mml:mi class="mathcal" mathvariant="script">N</mml:mi></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi mathvariant="bold-italic">z</mml:mi><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mi mathvariant="bold-italic">μ</mml:mi><mml:mo>,</mml:mo><mml:msup><mml:mi mathvariant="bold-italic">σ</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mstyle></mml:math></inline-formula>. Then, we guide latent representations containing behavioral information through an affine map <inline-formula><mml:math id="inf168"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>h</mml:mi><mml:mo>:</mml:mo><mml:msup><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi mathvariant="double-struck">R</mml:mi></mml:mrow><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>d</mml:mi></mml:mrow></mml:msup><mml:mo stretchy="false">→</mml:mo><mml:msup><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi mathvariant="double-struck">R</mml:mi></mml:mrow><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>k</mml:mi></mml:mrow></mml:msup></mml:mstyle></mml:math></inline-formula> under the loss <inline-formula><mml:math id="inf169"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msub><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi class="MJX-tex-caligraphic" mathvariant="script">L</mml:mi></mml:mrow><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>d</mml:mi><mml:mi>e</mml:mi><mml:mi>c</mml:mi><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mstyle></mml:math></inline-formula>,<disp-formula id="equ4"><label>(4)</label><mml:math id="m4"><mml:mrow><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msub><mml:mrow><mml:mi class="mathcal" mathvariant="script">L</mml:mi></mml:mrow><mml:mrow><mml:mi>d</mml:mi><mml:mi>e</mml:mi><mml:mi>c</mml:mi><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mrow><mml:mi mathvariant="normal">M</mml:mi><mml:mi mathvariant="normal">S</mml:mi><mml:mi mathvariant="normal">E</mml:mi></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>h</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi mathvariant="bold-italic">μ</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>,</mml:mo><mml:mi mathvariant="bold-italic">y</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>,</mml:mo></mml:mstyle></mml:mrow></mml:math></disp-formula></p><p>where <inline-formula><mml:math id="inf170"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi mathvariant="normal">M</mml:mi><mml:mi mathvariant="normal">S</mml:mi><mml:mi mathvariant="normal">E</mml:mi></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mo>⋅</mml:mo><mml:mo>,</mml:mo><mml:mo>⋅</mml:mo><mml:mo stretchy="false">)</mml:mo></mml:mstyle></mml:math></inline-formula> denotes mean squared loss. In other words, we encourage latent representations to decode kinematics to distill behaviorally relevant information. Here, we sample from the approximation posterior <inline-formula><mml:math id="inf171"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi mathvariant="bold-italic">x</mml:mi><mml:mrow><mml:mi>r</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mi>g</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi mathvariant="bold-italic">z</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mstyle></mml:math></inline-formula> using <inline-formula><mml:math id="inf172"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi mathvariant="bold-italic">z</mml:mi><mml:mo>∼</mml:mo><mml:mi mathvariant="bold-italic">μ</mml:mi><mml:mo>+</mml:mo><mml:mi mathvariant="bold-italic">σ</mml:mi><mml:mo>⊙</mml:mo><mml:mi mathvariant="bold-italic">ϵ</mml:mi></mml:mrow></mml:mstyle></mml:math></inline-formula>, where <inline-formula><mml:math id="inf173"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi mathvariant="bold-italic">ϵ</mml:mi><mml:mo>∼</mml:mo><mml:mrow><mml:mi class="mathcal" mathvariant="script">N</mml:mi></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mn mathvariant="bold">0</mml:mn><mml:mo>,</mml:mo><mml:mi mathvariant="bold-italic">I</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mstyle></mml:math></inline-formula> and <inline-formula><mml:math id="inf174"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mo>⊙</mml:mo></mml:mstyle></mml:math></inline-formula> denotes element-wise product. This sampling strategy is known as the reparameterization trick.</p></sec><sec id="s4-3-2"><title>Generating behaviorally relevant signals</title><p>After sampling latent representations <inline-formula><mml:math id="inf175"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi mathvariant="bold-italic">z</mml:mi></mml:mrow></mml:mstyle></mml:math></inline-formula>, we send latent representations to the generative model <inline-formula><mml:math id="inf176"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>g</mml:mi></mml:mstyle></mml:math></inline-formula> to generate behaviorally relevant neural signals <inline-formula><mml:math id="inf177"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi mathvariant="bold-italic">x</mml:mi><mml:mrow><mml:mi>r</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula>, i.e., <inline-formula><mml:math id="inf178"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi mathvariant="bold-italic">x</mml:mi><mml:mrow><mml:mi>r</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mi>g</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi mathvariant="bold-italic">z</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mstyle></mml:math></inline-formula>. We use following loss to make behaviorally relevant signals reconstruct raw signals as much as possible:<disp-formula id="equ5"><label>(5)</label><mml:math id="m5"><mml:mrow><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msub><mml:mrow><mml:mi class="mathcal" mathvariant="script">L</mml:mi></mml:mrow><mml:mrow><mml:mi>r</mml:mi><mml:mi>e</mml:mi><mml:mi>c</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mrow><mml:mi mathvariant="normal">P</mml:mi><mml:mi mathvariant="normal">o</mml:mi><mml:mi mathvariant="normal">i</mml:mi><mml:mi mathvariant="normal">s</mml:mi><mml:mi mathvariant="normal">s</mml:mi><mml:mi mathvariant="normal">o</mml:mi><mml:mi mathvariant="normal">n</mml:mi></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi mathvariant="bold-italic">x</mml:mi><mml:mi>r</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:mi mathvariant="bold-italic">x</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>,</mml:mo></mml:mstyle></mml:mrow></mml:math></disp-formula></p><p>where <inline-formula><mml:math id="inf179"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi mathvariant="normal">P</mml:mi><mml:mi mathvariant="normal">o</mml:mi><mml:mi mathvariant="normal">i</mml:mi><mml:mi mathvariant="normal">s</mml:mi><mml:mi mathvariant="normal">s</mml:mi><mml:mi mathvariant="normal">o</mml:mi><mml:mi mathvariant="normal">n</mml:mi></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mo>⋅</mml:mo><mml:mo>,</mml:mo><mml:mo>⋅</mml:mo><mml:mo stretchy="false">)</mml:mo></mml:mstyle></mml:math></inline-formula> denotes Poisson negative log likelihood loss. It is important to note that optimizing the generation of behaviorally relevant signals to accurately reconstruct noisy raw signals may result in the inclusion of many behaviorally irrelevant signals in the generated signals, which deviates from our initial goal of extracting behaviorally relevant signals. In the following subsection, we will introduce how to avoid generating behaviorally irrelevant signals.</p></sec><sec id="s4-3-3"><title>Decoding behaviorally relevant signals</title><p>As mentioned above, if the generation of behaviorally relevant signals <inline-formula><mml:math id="inf180"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi mathvariant="bold-italic">x</mml:mi><mml:mrow><mml:mi>r</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula> is only guided by <inline-formula><mml:math id="inf181"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msub><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi class="MJX-tex-caligraphic" mathvariant="script">L</mml:mi></mml:mrow><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>r</mml:mi><mml:mi>e</mml:mi><mml:mi>c</mml:mi></mml:mrow></mml:msub></mml:mstyle></mml:math></inline-formula>, generated signals may contain more behaviorally irrelevant signals. To avoid generated signals containing behaviorally irrelevant signals, we introduce decoding loss <inline-formula><mml:math id="inf182"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msub><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi class="MJX-tex-caligraphic" mathvariant="script">L</mml:mi></mml:mrow><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>d</mml:mi><mml:mi>e</mml:mi><mml:mi>c</mml:mi><mml:mn>2</mml:mn></mml:mrow></mml:msub></mml:mstyle></mml:math></inline-formula> to constrain <inline-formula><mml:math id="inf183"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi mathvariant="bold-italic">x</mml:mi><mml:mrow><mml:mi>r</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula> to decode behavioral information. The basic assumption is that behaviorally irrelevant signals act like noise for decoding behavioral information and are detrimental to decoding. Thus, there is a trade-off between neural reconstruction and decoding ability of <inline-formula><mml:math id="inf184"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi mathvariant="bold-italic">x</mml:mi><mml:mrow><mml:mi>r</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula>: the more behaviorally irrelevant signals <inline-formula><mml:math id="inf185"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi mathvariant="bold-italic">x</mml:mi><mml:mrow><mml:mi>r</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula> contains, the more decoding performance <inline-formula><mml:math id="inf186"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi mathvariant="bold-italic">x</mml:mi><mml:mrow><mml:mi>r</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula> loses. Then, we send the <inline-formula><mml:math id="inf187"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi mathvariant="bold-italic">x</mml:mi><mml:mrow><mml:mi mathvariant="bold-italic">r</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula> to the encoder <inline-formula><mml:math id="inf188"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>f</mml:mi></mml:mstyle></mml:math></inline-formula> and obtain the mean and variance of latent representations, i.e., <inline-formula><mml:math id="inf189"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mo stretchy="false">[</mml:mo><mml:msub><mml:mi mathvariant="bold-italic">μ</mml:mi><mml:mrow><mml:mi>r</mml:mi></mml:mrow></mml:msub><mml:mo>;</mml:mo><mml:msubsup><mml:mi mathvariant="bold-italic">σ</mml:mi><mml:mrow><mml:mi>r</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup><mml:mo stretchy="false">]</mml:mo><mml:mo>=</mml:mo><mml:mi>f</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi mathvariant="bold-italic">x</mml:mi><mml:mrow><mml:mi>r</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mstyle></mml:math></inline-formula>. The decoding loss <inline-formula><mml:math id="inf190"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msub><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi class="MJX-tex-caligraphic" mathvariant="script">L</mml:mi></mml:mrow><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>d</mml:mi><mml:mi>e</mml:mi><mml:mi>c</mml:mi><mml:mn>2</mml:mn></mml:mrow></mml:msub></mml:mstyle></mml:math></inline-formula> is as follows:<disp-formula id="equ6"><label>(6)</label><mml:math id="m6"><mml:mrow><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msub><mml:mrow><mml:mi class="mathcal" mathvariant="script">L</mml:mi></mml:mrow><mml:mrow><mml:mi>d</mml:mi><mml:mi>e</mml:mi><mml:mi>c</mml:mi><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mrow><mml:mi mathvariant="normal">M</mml:mi><mml:mi mathvariant="normal">S</mml:mi><mml:mi mathvariant="normal">E</mml:mi></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>h</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi mathvariant="bold-italic">μ</mml:mi><mml:mrow><mml:mi>r</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:mo>,</mml:mo><mml:mi mathvariant="bold-italic">y</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>.</mml:mo></mml:mstyle></mml:mrow></mml:math></disp-formula></p><p>We use the same networks <inline-formula><mml:math id="inf191"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>f</mml:mi></mml:mstyle></mml:math></inline-formula> and <inline-formula><mml:math id="inf192"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>h</mml:mi></mml:mstyle></mml:math></inline-formula> for <inline-formula><mml:math id="inf193"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi mathvariant="bold-italic">x</mml:mi><mml:mrow><mml:mi>r</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula> and <inline-formula><mml:math id="inf194"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi mathvariant="bold-italic">x</mml:mi></mml:mrow></mml:mstyle></mml:math></inline-formula> in our experiment, because <inline-formula><mml:math id="inf195"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi mathvariant="bold-italic">x</mml:mi><mml:mrow><mml:mi>r</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula> can act as data augmentation and make <inline-formula><mml:math id="inf196"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>f</mml:mi></mml:mstyle></mml:math></inline-formula> distill robust representations without increasing model parameters. In addition, we combine the two decoding loss as one loss:<disp-formula id="equ7"><label>(7)</label><mml:math id="m7"><mml:mrow><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msub><mml:mrow><mml:mi class="mathcal" mathvariant="script">L</mml:mi></mml:mrow><mml:mrow><mml:mi>d</mml:mi><mml:mi>e</mml:mi><mml:mi>c</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mn>2</mml:mn></mml:mfrac><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mrow><mml:mi class="mathcal" mathvariant="script">L</mml:mi></mml:mrow><mml:mrow><mml:mi>d</mml:mi><mml:mi>e</mml:mi><mml:mi>c</mml:mi><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mrow><mml:mi class="mathcal" mathvariant="script">L</mml:mi></mml:mrow><mml:mrow><mml:mi>d</mml:mi><mml:mi>e</mml:mi><mml:mi>c</mml:mi><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:mo>.</mml:mo></mml:mstyle></mml:mrow></mml:math></disp-formula></p></sec><sec id="s4-3-4"><title>Learning the prior distribution with behavioral information</title><p>The prior distribution of latent representation is crucial because inappropriate prior assumptions can degrade latent representations and generated neural signals. Vanilla VAE uses a Gaussian prior <inline-formula><mml:math id="inf197"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mrow><mml:mi class="mathcal" mathvariant="script">N</mml:mi></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mn mathvariant="bold">0</mml:mn><mml:mo>,</mml:mo><mml:mi mathvariant="bold-italic">I</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mstyle></mml:math></inline-formula> to regularize the space of latent representation <inline-formula><mml:math id="inf198"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi mathvariant="bold-italic">z</mml:mi></mml:mrow></mml:mstyle></mml:math></inline-formula>. However, in neuroscience, the distribution of latent representations is unknown and may exceed the scope of Gaussian. Therefore, we adopt neural networks <inline-formula><mml:math id="inf199"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>m</mml:mi></mml:mstyle></mml:math></inline-formula> to learn the prior distribution with kinematics <inline-formula><mml:math id="inf200"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi mathvariant="bold-italic">y</mml:mi></mml:mrow></mml:mstyle></mml:math></inline-formula>, i.e., <inline-formula><mml:math id="inf201"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mo stretchy="false">[</mml:mo><mml:msub><mml:mi mathvariant="bold-italic">μ</mml:mi><mml:mrow><mml:mi>p</mml:mi><mml:mi>r</mml:mi><mml:mi>i</mml:mi><mml:mi>o</mml:mi><mml:mi>r</mml:mi></mml:mrow></mml:msub><mml:mo>;</mml:mo><mml:msubsup><mml:mi mathvariant="bold-italic">σ</mml:mi><mml:mrow><mml:mi>p</mml:mi><mml:mi>r</mml:mi><mml:mi>i</mml:mi><mml:mi>o</mml:mi><mml:mi>r</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup><mml:mo stretchy="false">]</mml:mo><mml:mo>=</mml:mo><mml:mi>m</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi mathvariant="bold-italic">y</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mstyle></mml:math></inline-formula> and thus <inline-formula><mml:math id="inf202"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>p</mml:mi><mml:mrow><mml:mi>m</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi mathvariant="bold-italic">z</mml:mi><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mi mathvariant="bold-italic">y</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mrow><mml:mi class="mathcal" mathvariant="script">N</mml:mi></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi mathvariant="bold-italic">z</mml:mi><mml:mrow><mml:mi>p</mml:mi><mml:mi>r</mml:mi><mml:mi>i</mml:mi><mml:mi>o</mml:mi><mml:mi>r</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:msub><mml:mi mathvariant="bold-italic">μ</mml:mi><mml:mrow><mml:mi>p</mml:mi><mml:mi>r</mml:mi><mml:mi>i</mml:mi><mml:mi>o</mml:mi><mml:mi>r</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msubsup><mml:mi mathvariant="bold-italic">σ</mml:mi><mml:mrow><mml:mi>p</mml:mi><mml:mi>r</mml:mi><mml:mi>i</mml:mi><mml:mi>o</mml:mi><mml:mi>r</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mstyle></mml:math></inline-formula>. The prior distribution <inline-formula><mml:math id="inf203"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>p</mml:mi><mml:mrow><mml:mi>m</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi mathvariant="bold-italic">z</mml:mi><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mi mathvariant="bold-italic">y</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mstyle></mml:math></inline-formula> and approximation posterior distribution <inline-formula><mml:math id="inf204"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>q</mml:mi><mml:mrow><mml:mi>f</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi mathvariant="bold-italic">z</mml:mi><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mi mathvariant="bold-italic">x</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mstyle></mml:math></inline-formula> are aligned by the KL divergence:<disp-formula id="equ8"><label>(8)</label><mml:math id="m8"><mml:mrow><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msub><mml:mrow><mml:mi class="mathcal" mathvariant="script">L</mml:mi></mml:mrow><mml:mrow><mml:mi>K</mml:mi><mml:mi>L</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:msub><mml:mi>D</mml:mi><mml:mrow><mml:mi>K</mml:mi><mml:mi>L</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>p</mml:mi><mml:mrow><mml:mi>m</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi mathvariant="bold-italic">z</mml:mi><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mi mathvariant="bold-italic">y</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:msub><mml:mi>q</mml:mi><mml:mrow><mml:mi>f</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi mathvariant="bold-italic">z</mml:mi><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mi mathvariant="bold-italic">x</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:msub><mml:mi>D</mml:mi><mml:mrow><mml:mi>K</mml:mi><mml:mi>L</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mi class="mathcal" mathvariant="script">N</mml:mi></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi mathvariant="bold-italic">z</mml:mi><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mi mathvariant="bold-italic">μ</mml:mi><mml:mo>,</mml:mo><mml:msup><mml:mi mathvariant="bold-italic">σ</mml:mi><mml:mn>2</mml:mn></mml:msup><mml:mo stretchy="false">)</mml:mo><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mrow><mml:mi class="mathcal" mathvariant="script">N</mml:mi></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi mathvariant="bold-italic">z</mml:mi><mml:mrow><mml:mi>p</mml:mi><mml:mi>r</mml:mi><mml:mi>i</mml:mi><mml:mi>o</mml:mi><mml:mi>r</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:msub><mml:mi mathvariant="bold-italic">μ</mml:mi><mml:mrow><mml:mi>p</mml:mi><mml:mi>r</mml:mi><mml:mi>i</mml:mi><mml:mi>o</mml:mi><mml:mi>r</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msubsup><mml:mi mathvariant="bold-italic">σ</mml:mi><mml:mrow><mml:mi>p</mml:mi><mml:mi>r</mml:mi><mml:mi>i</mml:mi><mml:mi>o</mml:mi><mml:mi>r</mml:mi></mml:mrow><mml:mn>2</mml:mn></mml:msubsup><mml:mo stretchy="false">)</mml:mo><mml:mo stretchy="false">)</mml:mo><mml:mo>.</mml:mo></mml:mstyle></mml:mrow></mml:math></disp-formula></p><p>In this case, the distribution of <inline-formula><mml:math id="inf205"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>p</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi mathvariant="bold-italic">z</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mstyle></mml:math></inline-formula> is<disp-formula id="equ9"><label>(9)</label><mml:math id="m9"><mml:mrow><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>p</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi mathvariant="bold-italic">z</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mo>∫</mml:mo><mml:mrow><mml:mover><mml:mi>p</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi mathvariant="bold-italic">y</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:msub><mml:mi>p</mml:mi><mml:mrow><mml:mi>m</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi mathvariant="bold-italic">z</mml:mi><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mi mathvariant="bold-italic">y</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mrow><mml:mi mathvariant="normal">d</mml:mi></mml:mrow><mml:mi mathvariant="bold-italic">y</mml:mi><mml:mo>=</mml:mo><mml:munderover><mml:mo>∑</mml:mo><mml:mrow><mml:mi>j</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>N</mml:mi></mml:munderover><mml:mo stretchy="false">(</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mi>N</mml:mi></mml:mfrac><mml:munderover><mml:mo>∑</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>N</mml:mi></mml:mrow></mml:munderover><mml:mi>δ</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msup><mml:mi mathvariant="bold-italic">y</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>j</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup><mml:mo>−</mml:mo><mml:msup><mml:mi mathvariant="bold-italic">y</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>i</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup><mml:mo stretchy="false">)</mml:mo><mml:mo stretchy="false">)</mml:mo><mml:msub><mml:mi>p</mml:mi><mml:mrow><mml:mi>m</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi mathvariant="bold-italic">z</mml:mi><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:msup><mml:mi mathvariant="bold-italic">y</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>j</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup><mml:mo stretchy="false">)</mml:mo><mml:mo>,</mml:mo></mml:mstyle></mml:mrow></mml:math></disp-formula></p><p>where <inline-formula><mml:math id="inf206"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mrow><mml:mover><mml:mi>p</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi mathvariant="bold-italic">y</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mi>N</mml:mi></mml:mfrac><mml:munderover><mml:mo>∑</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>N</mml:mi></mml:mrow></mml:munderover><mml:mi>δ</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi mathvariant="bold-italic">y</mml:mi><mml:mo>−</mml:mo><mml:msup><mml:mi mathvariant="bold-italic">y</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>i</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mstyle></mml:math></inline-formula> represents the empirical distribution of behavioral variables <inline-formula><mml:math id="inf207"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi mathvariant="bold-italic">y</mml:mi></mml:mrow></mml:mstyle></mml:math></inline-formula>, <inline-formula><mml:math id="inf208"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>N</mml:mi></mml:mstyle></mml:math></inline-formula> denotes the number of samples, <inline-formula><mml:math id="inf209"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>δ</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mo>⋅</mml:mo><mml:mo stretchy="false">)</mml:mo></mml:mstyle></mml:math></inline-formula> denotes Dirac delta function. Thus, <inline-formula><mml:math id="inf210"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>p</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi mathvariant="bold-italic">z</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mstyle></mml:math></inline-formula> corresponds to a Gaussian mixture model with <inline-formula><mml:math id="inf211"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>N</mml:mi></mml:mstyle></mml:math></inline-formula> components, which is theoretically a universal approximator of continuous probability densities. Since <inline-formula><mml:math id="inf212"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi mathvariant="bold-italic">z</mml:mi><mml:mrow><mml:mi>p</mml:mi><mml:mi>r</mml:mi><mml:mi>i</mml:mi><mml:mi>o</mml:mi><mml:mi>r</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula> and <inline-formula><mml:math id="inf213"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi mathvariant="bold-italic">z</mml:mi></mml:mrow></mml:mstyle></mml:math></inline-formula> are aligned and the generative network <inline-formula><mml:math id="inf214"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>g</mml:mi></mml:mstyle></mml:math></inline-formula> models the relationship between <inline-formula><mml:math id="inf215"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi mathvariant="bold-italic">z</mml:mi></mml:mrow></mml:mstyle></mml:math></inline-formula> and <inline-formula><mml:math id="inf216"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi mathvariant="bold-italic">x</mml:mi><mml:mrow><mml:mi>r</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula>, this is equivalent to indirectly establishing a neural encoding model from <inline-formula><mml:math id="inf217"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi mathvariant="bold-italic">y</mml:mi></mml:mrow></mml:mstyle></mml:math></inline-formula> to <inline-formula><mml:math id="inf218"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi mathvariant="bold-italic">x</mml:mi><mml:mrow><mml:mi>r</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula>. Thus, we can observe the change of <inline-formula><mml:math id="inf219"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi mathvariant="bold-italic">z</mml:mi><mml:mrow><mml:mi>p</mml:mi><mml:mi>r</mml:mi><mml:mi>i</mml:mi><mml:mi>o</mml:mi><mml:mi>r</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula> and <inline-formula><mml:math id="inf220"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi mathvariant="bold-italic">x</mml:mi><mml:mrow><mml:mi>r</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula> by changing <inline-formula><mml:math id="inf221"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi mathvariant="bold-italic">y</mml:mi></mml:mrow></mml:mstyle></mml:math></inline-formula> and can better understand the encoding mechanism of neural signals.</p></sec><sec id="s4-3-5"><title>End-to-end optimization</title><p>d-VAE is optimized in an end-to-end manner under the following loss:<disp-formula id="equ10"><label>(10)</label><mml:math id="m10"><mml:mrow><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi class="mathcal" mathvariant="script">L</mml:mi></mml:mrow><mml:mo>=</mml:mo><mml:msub><mml:mrow><mml:mi class="mathcal" mathvariant="script">L</mml:mi></mml:mrow><mml:mrow><mml:mi>r</mml:mi><mml:mi>e</mml:mi><mml:mi>c</mml:mi></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:mi>β</mml:mi><mml:msub><mml:mrow><mml:mi class="mathcal" mathvariant="script">L</mml:mi></mml:mrow><mml:mrow><mml:mi>K</mml:mi><mml:mi>L</mml:mi></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:mi>α</mml:mi><mml:msub><mml:mrow><mml:mi class="mathcal" mathvariant="script">L</mml:mi></mml:mrow><mml:mrow><mml:mi>d</mml:mi><mml:mi>e</mml:mi><mml:mi>c</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo></mml:mstyle></mml:mrow></mml:math></disp-formula></p><p>where <inline-formula><mml:math id="inf222"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>β</mml:mi></mml:mstyle></mml:math></inline-formula> and <inline-formula><mml:math id="inf223"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>α</mml:mi></mml:mstyle></mml:math></inline-formula> are hyperparameters, <inline-formula><mml:math id="inf224"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>β</mml:mi></mml:mstyle></mml:math></inline-formula> is used to adjust the weight of KL divergence, and <inline-formula><mml:math id="inf225"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>α</mml:mi></mml:mstyle></mml:math></inline-formula> determines the trade-off between reconstruction loss <inline-formula><mml:math id="inf226"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msub><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi class="MJX-tex-caligraphic" mathvariant="script">L</mml:mi></mml:mrow><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>r</mml:mi><mml:mi>e</mml:mi><mml:mi>c</mml:mi></mml:mrow></mml:msub></mml:mstyle></mml:math></inline-formula> and decoding loss <inline-formula><mml:math id="inf227"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msub><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi class="MJX-tex-caligraphic" mathvariant="script">L</mml:mi></mml:mrow><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>d</mml:mi><mml:mi>e</mml:mi><mml:mi>c</mml:mi></mml:mrow></mml:msub></mml:mstyle></mml:math></inline-formula>. Given that the ground truth of latent variable distribution is unknown, even a learned prior distribution might not accurately reflect the true distribution. We found the pronounced impact of the KL divergence would prove detrimental to the decoding and reconstruction performance. As a result, we opt to reduce the weight of the KL divergence term. Even so, KL divergence can still effectively align the distribution of latent variables with the distribution of prior latent variables (see <xref ref-type="fig" rid="fig1s2">Figure 1—figure supplement 2</xref>).</p><p>In the training stage, we feed raw neural signals into the inference network <inline-formula><mml:math id="inf228"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>f</mml:mi></mml:mstyle></mml:math></inline-formula> to get latent representation <inline-formula><mml:math id="inf229"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi mathvariant="bold-italic">z</mml:mi></mml:mrow></mml:mstyle></mml:math></inline-formula>, which is regularized by <inline-formula><mml:math id="inf230"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi mathvariant="bold-italic">z</mml:mi><mml:mrow><mml:mi>p</mml:mi><mml:mi>r</mml:mi><mml:mi>i</mml:mi><mml:mi>o</mml:mi><mml:mi>r</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula> coming from kinematics <inline-formula><mml:math id="inf231"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi mathvariant="bold-italic">y</mml:mi></mml:mrow></mml:mstyle></mml:math></inline-formula> and network <inline-formula><mml:math id="inf232"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>m</mml:mi></mml:mstyle></mml:math></inline-formula>. Then, we use the mean of <inline-formula><mml:math id="inf233"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi mathvariant="bold-italic">z</mml:mi></mml:mrow></mml:mstyle></mml:math></inline-formula>, i.e., μ, to decode kinematics <inline-formula><mml:math id="inf234"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi mathvariant="bold-italic">y</mml:mi></mml:mrow></mml:mstyle></mml:math></inline-formula> by affine layer <inline-formula><mml:math id="inf235"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>h</mml:mi></mml:mstyle></mml:math></inline-formula> and send <inline-formula><mml:math id="inf236"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi mathvariant="bold-italic">z</mml:mi></mml:mrow></mml:mstyle></mml:math></inline-formula> to the generative networks <inline-formula><mml:math id="inf237"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>g</mml:mi></mml:mstyle></mml:math></inline-formula> to generate neural signals <inline-formula><mml:math id="inf238"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi mathvariant="bold-italic">x</mml:mi><mml:mrow><mml:mi>r</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula>. To ensure that <inline-formula><mml:math id="inf239"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi mathvariant="bold-italic">x</mml:mi><mml:mrow><mml:mi>r</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula> preserves decoding ability, we send <inline-formula><mml:math id="inf240"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi mathvariant="bold-italic">x</mml:mi><mml:mrow><mml:mi>r</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula> to <inline-formula><mml:math id="inf241"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>f</mml:mi></mml:mstyle></mml:math></inline-formula> and <inline-formula><mml:math id="inf242"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>h</mml:mi></mml:mstyle></mml:math></inline-formula> to decode <inline-formula><mml:math id="inf243"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi mathvariant="bold-italic">y</mml:mi></mml:mrow></mml:mstyle></mml:math></inline-formula>. The whole model is trained in an end-to-end manner under the guidance of total loss. Once the model has been trained, we can feed raw neural signals to it to obtain behaviorally relevant neural signals <inline-formula><mml:math id="inf244"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi mathvariant="bold-italic">x</mml:mi><mml:mrow><mml:mi>r</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula>, and we can also generate behaviorally relevant neural signals using the prior distribution of <inline-formula><mml:math id="inf245"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi mathvariant="bold-italic">z</mml:mi><mml:mrow><mml:mi>p</mml:mi><mml:mi>r</mml:mi><mml:mi>i</mml:mi><mml:mi>o</mml:mi><mml:mi>r</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula>.</p></sec><sec id="s4-3-6"><title>Differences from pi-VAE</title><p>pi-VAE lacks the decoding constraint on latent variables (<xref ref-type="disp-formula" rid="equ4">Equation 4</xref>) and the decoding constraint on generated signals (<xref ref-type="disp-formula" rid="equ6">Equation 6</xref>).</p></sec></sec><sec id="s4-4"><title>Cross-validation evaluation of models</title><p>For each model, we use the fivefold cross-validation manner to assess performance. Specifically, we divide the data into five equal folds. In each experiment, we take one fold for testing and use the rest for training (taking three folds as the training set and one as the validation set). The reported performance is averaged over test sets of five experiments. The validation sets are used to choose hyperparameters based on the averaged performance of fivefold validation data. To avoid overfitting, we apply the early stopping strategy. Specifically, we assess the criteria (loss for training distillation methods, <inline-formula><mml:math id="inf246"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msup><mml:mrow><mml:mi mathvariant="normal">R</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:mstyle></mml:math></inline-formula> for training ANN and KF) on the validation set every epoch in the training process. The model is saved when the model achieves better validation performance than the earlier epochs. If the model cannot increase by 1% of the best performance previously obtained within 10 epochs, we stop the training process.</p></sec><sec id="s4-5"><title>The strategy for selecting effective behaviorally relevant signals</title><p>As previously mentioned, the hyperparameter <inline-formula><mml:math id="inf247"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>α</mml:mi></mml:mstyle></mml:math></inline-formula> of d-VAE plays a crucial role in balancing the trade-off between reconstruction and decoding loss. Once the appropriate value of <inline-formula><mml:math id="inf248"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>α</mml:mi></mml:mstyle></mml:math></inline-formula> is determined, we can use this value to obtain accurate behaviorally relevant signals for subsequent analysis. To determine the optimal value of <inline-formula><mml:math id="inf249"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>α</mml:mi></mml:mstyle></mml:math></inline-formula>, we first enumerated different values of <inline-formula><mml:math id="inf250"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>α</mml:mi></mml:mstyle></mml:math></inline-formula> to guide d-VAE in distilling the behaviorally relevant signals. Next, we used ANN to evaluate the decoding <inline-formula><mml:math id="inf251"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msup><mml:mrow><mml:mi mathvariant="normal">R</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:mstyle></mml:math></inline-formula> of behaviorally relevant (<inline-formula><mml:math id="inf252"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msub><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi mathvariant="normal">D</mml:mi></mml:mrow><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi mathvariant="normal">r</mml:mi><mml:mi mathvariant="normal">e</mml:mi></mml:mrow></mml:msub></mml:mstyle></mml:math></inline-formula>) and irrelevant (<inline-formula><mml:math id="inf253"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msub><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi mathvariant="normal">D</mml:mi></mml:mrow><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi mathvariant="normal">i</mml:mi><mml:mi mathvariant="normal">r</mml:mi></mml:mrow></mml:msub></mml:mstyle></mml:math></inline-formula>) signals generated by each <inline-formula><mml:math id="inf254"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>α</mml:mi></mml:mstyle></mml:math></inline-formula> value. Finally, we selected the <inline-formula><mml:math id="inf255"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>α</mml:mi></mml:mstyle></mml:math></inline-formula> value with the criteria formula <inline-formula><mml:math id="inf256"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mn>0.75</mml:mn><mml:mo>×</mml:mo><mml:msub><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi mathvariant="normal">D</mml:mi></mml:mrow><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi mathvariant="normal">r</mml:mi><mml:mi mathvariant="normal">e</mml:mi></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:mn>0.25</mml:mn><mml:mo>×</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:msub><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi mathvariant="normal">D</mml:mi></mml:mrow><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi mathvariant="normal">i</mml:mi><mml:mi mathvariant="normal">r</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mstyle></mml:math></inline-formula>. The <inline-formula><mml:math id="inf257"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>α</mml:mi></mml:mstyle></mml:math></inline-formula> value that obtained the highest criteria score on the validation set was selected as the optimal value.</p><p>Note that we did not use neural similarity between behaviorally relevant and raw signals as a criterion for selecting behaviorally relevant signals. This is because determining the threshold for neural similarity is challenging. However, not using similarity as a criterion does not affect the selection of suitable signals because the decoding performance of behaviorally irrelevant signals can indirectly reflect the degree of similarity between the generated behaviorally relevant signals and the raw signals. Specifically, if the generated behaviorally relevant signals are dissimilar to the raw signals, the behaviorally irrelevant signals will contain many useful signals. In other words, when the neural similarity between behaviorally relevant and raw signals is low, the decoding performance of behaviorally irrelevant signals is high. Therefore, the decoding performance of irrelevant signals is a reasonable alternative to the neural similarity.</p><p>Regarding the ratio between <inline-formula><mml:math id="inf258"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msub><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi mathvariant="normal">D</mml:mi></mml:mrow><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi mathvariant="normal">r</mml:mi><mml:mi mathvariant="normal">e</mml:mi></mml:mrow></mml:msub></mml:mstyle></mml:math></inline-formula> and <inline-formula><mml:math id="inf259"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msub><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi mathvariant="normal">D</mml:mi></mml:mrow><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi mathvariant="normal">i</mml:mi><mml:mi mathvariant="normal">r</mml:mi></mml:mrow></mml:msub></mml:mstyle></mml:math></inline-formula>, any ratio greater than or equal to 3:1 is suitable, and we recommend opting for a higher ratio. This recommendation is based on the observation that when the model is biased toward reconstruction (associated with lower <inline-formula><mml:math id="inf260"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>α</mml:mi></mml:mstyle></mml:math></inline-formula> values), the decoding performance of relevant signals improves as <inline-formula><mml:math id="inf261"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>α</mml:mi></mml:mstyle></mml:math></inline-formula> increases, yet it has not reached saturation. At the same time, the decoding performance of irrelevant signals remains low, but their fluctuations are larger than the improvements in the decoding performance of relevant signals. Consequently, setting the ratio too low poses a risk of selecting an <inline-formula><mml:math id="inf262"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>α</mml:mi></mml:mstyle></mml:math></inline-formula> value where both irrelevant and relevant signals demonstrate low decoding performance. This situation fails to satisfy our requirement that relevant signals should exhibit high decoding performance.</p><p>For other generative models, we iterate through a range of hyperparameters, generating the corresponding behaviorally relevant neural signals, and subsequently evaluate these signals using ANN. The hyperparameter associated with the signals that exhibit the highest ANN decoding performance is then selected. In other words, the signals corresponding to this particular hyperparameter are chosen as the selected behaviorally relevant neural signals.</p></sec><sec id="s4-6"><title>Implementation details for methods</title><p>All the VAE-based models use the Poisson observation function. The details of different methods are demonstrated as follows:</p><list list-type="bullet"><list-item><p>d-VAE. The encoder <inline-formula><mml:math id="inf263"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>f</mml:mi></mml:mstyle></mml:math></inline-formula> of d-VAE uses two hidden layer MLP with 300 and 100 hidden units. The activation function of the hidden layers is ReLU. The dimensionality of the latent variable is set to 50. The decoder <inline-formula><mml:math id="inf264"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>g</mml:mi></mml:mstyle></mml:math></inline-formula> of d-VAE is symmetric with the encoder. The last layer of the decoder is followed by a SoftPlus activation function. The prior networks <inline-formula><mml:math id="inf265"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>m</mml:mi></mml:mstyle></mml:math></inline-formula> use one hidden layer MLP with 300 units. The <inline-formula><mml:math id="inf266"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>β</mml:mi></mml:mstyle></mml:math></inline-formula> is set to 0.001. The <inline-formula><mml:math id="inf267"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>α</mml:mi></mml:mstyle></mml:math></inline-formula> is set to 0.3, 0.4, 0.7, and 0.9 for datasets A, B, and C. We perform a grid search for <inline-formula><mml:math id="inf268"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>α</mml:mi></mml:mstyle></mml:math></inline-formula> in <inline-formula><mml:math id="inf269"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mo>{</mml:mo><mml:mn>0.1</mml:mn><mml:mo>,</mml:mo><mml:mn>0.2</mml:mn><mml:mo>,</mml:mo><mml:mn>0.3</mml:mn><mml:mo>,</mml:mo><mml:mn>0.4</mml:mn><mml:mo>,</mml:mo><mml:mn>0.5</mml:mn><mml:mo>,</mml:mo><mml:mn>0.6</mml:mn><mml:mo>,</mml:mo><mml:mn>0.7</mml:mn><mml:mo>,</mml:mo><mml:mn>0.8</mml:mn><mml:mo>,</mml:mo><mml:mn>0.9</mml:mn><mml:mo>}</mml:mo></mml:mrow></mml:mstyle></mml:math></inline-formula>, and <inline-formula><mml:math id="inf270"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>β</mml:mi></mml:mstyle></mml:math></inline-formula> in <inline-formula><mml:math id="inf271"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mo>{</mml:mo><mml:mn>0.001</mml:mn><mml:mo>,</mml:mo><mml:mn>0.01</mml:mn><mml:mo>,</mml:mo><mml:mn>0.1</mml:mn><mml:mo>,</mml:mo><mml:mn>1</mml:mn><mml:mo>}</mml:mo></mml:mrow></mml:mstyle></mml:math></inline-formula>, and latent variable dimension in <inline-formula><mml:math id="inf272"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mo>{</mml:mo><mml:mn>10</mml:mn><mml:mo>,</mml:mo><mml:mn>20</mml:mn><mml:mo>,</mml:mo><mml:mn>50</mml:mn><mml:mo>}</mml:mo></mml:mrow></mml:mstyle></mml:math></inline-formula>. For the synthetic dataset A and B experiments, the <inline-formula><mml:math id="inf273"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>β</mml:mi></mml:mstyle></mml:math></inline-formula> and the latent variable dimension are directly set to 0.001 and 50. For synthetic dataset the <inline-formula><mml:math id="inf274"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>α</mml:mi></mml:mstyle></mml:math></inline-formula> is set to 0.9, which is grid searched in <inline-formula><mml:math id="inf275"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mo>{</mml:mo><mml:mn>0.01</mml:mn><mml:mtext>--</mml:mtext><mml:mn>0.09</mml:mn><mml:mo>,</mml:mo><mml:mn>0.1</mml:mn><mml:mtext>--</mml:mtext><mml:mn>0.9</mml:mn><mml:mo>,</mml:mo><mml:mn>1</mml:mn><mml:mtext>--</mml:mtext><mml:mn>9</mml:mn><mml:mo>}</mml:mo></mml:mrow></mml:mstyle></mml:math></inline-formula>, with intervals of 0.01, 0.1, and 1, respectively.</p></list-item><list-item><p>pi-VAE. The original paper utilizes label information (as shown in <xref ref-type="disp-formula" rid="equ6">Equation 6</xref>) to approximate the posterior of the latent variable and performs Monte Carlo sampling for decoding during the test stage. However, in our signal generation setting, it is inappropriate to use label information (kinematics) for extracting behaviorally relevant signals during the test stage. As a result, we modified the model to exclude the use of label information in approximating the posterior. The encoder, decoder, and prior networks of our pi-VAE are kept the same as those in d-VAE.</p></list-item><list-item><p>LFADS. The hidden units of the encoder for the generator’s initial conditions, the controller, the generator are set to 200, 200, 200, and 100 for datasets A, B, and C and the synthetic dataset. The dimensionality of latent factor is set to 50 for all datasets. We perform a grid search for hidden units in <inline-formula><mml:math id="inf276"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mo>{</mml:mo><mml:mn>100</mml:mn><mml:mo>,</mml:mo><mml:mn>200</mml:mn><mml:mo>}</mml:mo></mml:mrow></mml:mstyle></mml:math></inline-formula>, and latent factor dimensions in <inline-formula><mml:math id="inf277"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mo>{</mml:mo><mml:mn>10</mml:mn><mml:mo>,</mml:mo><mml:mn>20</mml:mn><mml:mo>,</mml:mo><mml:mn>50</mml:mn><mml:mo>}</mml:mo></mml:mrow></mml:mstyle></mml:math></inline-formula>. The dimensionality of inferred inputs is set to 1. The Poisson likelihood function is used. The training strategy follows the practice of the original paper. For datasets A and B, a trial length of 18 is set. Trials with lengths below the threshold are zero-padded, while trials exceeding the threshold are truncated to the threshold length from their starting point. In dataset A, there are several trials with lengths considerably longer than that of most trials. We found that padding all trials with zeros to reach the maximum length (32) led to poor performance. Consequently, we chose a trial length of 18, effectively encompassing the durations of most trials and leading to the removal of approximately 9% of samples. For dataset B (center-out), the trial lengths are relatively consistent with small variation, and the maximum length across all trials is 18. For dataset C, we set the trial length as 10 because we observed the video of this paradigm and found that the time for completing a single trial was approximately 1 s. The segments are not overlapped.</p></list-item><list-item><p>TNDM. The hidden units of the encoder for the generator’s initial conditions, the controller, and the generator are set to 64, 64, 100, and 64 for datasets A, B, and C and the synthetic dataset. The dimensionality of relevant latent factors is set to 50, 25, 50, and 50 for datasets A, B, and C and the synthetic dataset. We set the dimensionality of irrelevant latent factors as the same as that of relevant latent factors. The behavior weight is set to 5, 5, 0.2, 0.5 for datasets A, B, and C and the synthetic dataset. We perform a grid search for relevant latent factor dimensionality in <inline-formula><mml:math id="inf278"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mo>{</mml:mo><mml:mn>10</mml:mn><mml:mo>,</mml:mo><mml:mn>25</mml:mn><mml:mo>,</mml:mo><mml:mn>50</mml:mn><mml:mo>}</mml:mo></mml:mrow></mml:mstyle></mml:math></inline-formula>, the hidden units in <inline-formula><mml:math id="inf279"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mo>{</mml:mo><mml:mn>64</mml:mn><mml:mo>,</mml:mo><mml:mn>100</mml:mn><mml:mo>,</mml:mo><mml:mn>200</mml:mn><mml:mo>}</mml:mo></mml:mrow></mml:mstyle></mml:math></inline-formula>, and the behavior weight in <inline-formula><mml:math id="inf280"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mo>{</mml:mo><mml:mn>0.2</mml:mn><mml:mo>,</mml:mo><mml:mn>0.5</mml:mn><mml:mo>,</mml:mo><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mn>5</mml:mn><mml:mo>,</mml:mo><mml:mn>10</mml:mn><mml:mo>}</mml:mo></mml:mrow></mml:mstyle></mml:math></inline-formula>. The Poisson likelihood function is used. The other hyperparameter setting and the training strategy follow the practice of the original paper. TNDM uses the same trial length and data as LFADS.</p></list-item><list-item><p>PSID. PSID uses several (horizon size) past neural data to predict behavior at the current time without using neural observations at the current time. For a fair comparison, we let PSID see current neural observations by shifting the neural data one sample into the past relative to the behavior data. We perform a grid search for the horizon hyperparameter in <inline-formula><mml:math id="inf281"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mo>{</mml:mo><mml:mn>2</mml:mn><mml:mo>,</mml:mo><mml:mn>3</mml:mn><mml:mo>,</mml:mo><mml:mn>4</mml:mn><mml:mo>,</mml:mo><mml:mn>5</mml:mn><mml:mo>,</mml:mo><mml:mn>6</mml:mn><mml:mo>,</mml:mo><mml:mn>7</mml:mn><mml:mo>}</mml:mo></mml:mrow></mml:mstyle></mml:math></inline-formula>. Due to the relevant latent dimension should be lower than the horizon times the dimensionality of behavior variables (two-dimensional velocity in this paper), we just set the relevant latent dimension as the maximum. The horizon number of datasets A, B, C, and synthetic datasets is 7, 6, 6, and 5, respectively. And thus the latent variable dimension of datasets A, B, and C and the synthetic dataset is 14, 12, 12, and 10, respectively.</p></list-item><list-item><p>ANN. ANN has two hidden layers with 300 and 100 hidden units. The activation function of the hidden layers is ReLU.</p></list-item><list-item><p>KF. The matrix parameters of observation and state transition process are optimized with the least square algorithm. KF is a linear-Gaussian state-space model designed to provide an optimal estimate of the current state (kinematics in this paper). It does so by considering both the current measurement observations (neural signals in this paper) and the previous state estimate. The KF operates in a recursive and iterative manner, continually updating its state estimate as new observations become available.</p></list-item></list></sec><sec id="s4-7"><title>Percentage of explained variance captured in a subspace</title><p>We applied PCA to behaviorally relevant and irrelevant signals to get relevant PCs and irrelevant PCs. Then, we used the percentage variance captured (also called alignment index) to quantify how many variances of irrelevant signals can be captured by relevant PCs by projecting irrelevant signals onto the subspace composed of some relevant PCs and vice versa. The percentage of variance captured is<disp-formula id="equ11"><label>(11)</label><mml:math id="m11"><mml:mrow><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>A</mml:mi><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mi>Tr</mml:mi><mml:mo>⁡</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msup><mml:mi mathvariant="bold-italic">D</mml:mi><mml:mrow><mml:mrow><mml:mi mathvariant="normal">T</mml:mi></mml:mrow></mml:mrow></mml:msup><mml:mrow><mml:mi mathvariant="bold-italic">C</mml:mi><mml:mi mathvariant="bold-italic">D</mml:mi></mml:mrow></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mrow><mml:mi>Tr</mml:mi><mml:mo>⁡</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mi mathvariant="bold-italic">C</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mfrac><mml:mo>×</mml:mo><mml:mn>100</mml:mn><mml:mi mathvariant="normal">%</mml:mi><mml:mo>,</mml:mo></mml:mstyle></mml:mrow></mml:math></disp-formula></p><p>where <inline-formula><mml:math id="inf282"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi mathvariant="bold-italic">D</mml:mi><mml:mo>∈</mml:mo><mml:msup><mml:mrow><mml:mi mathvariant="double-struck">R</mml:mi></mml:mrow><mml:mrow><mml:mi>N</mml:mi><mml:mo>×</mml:mo><mml:mi>d</mml:mi></mml:mrow></mml:msup></mml:mrow></mml:mstyle></mml:math></inline-formula> is the top <inline-formula><mml:math id="inf283"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>d</mml:mi></mml:mstyle></mml:math></inline-formula> PCs of relevant signals (irrelevant signals). <inline-formula><mml:math id="inf284"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi mathvariant="bold-italic">C</mml:mi><mml:mo>∈</mml:mo><mml:msup><mml:mrow><mml:mi mathvariant="double-struck">R</mml:mi></mml:mrow><mml:mrow><mml:mi>N</mml:mi><mml:mo>×</mml:mo><mml:mi>N</mml:mi></mml:mrow></mml:msup></mml:mrow></mml:mstyle></mml:math></inline-formula> is the covariance matrix of irrelevant signals (relevant signals), and <inline-formula><mml:math id="inf285"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>Tr</mml:mi><mml:mo>⁡</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mi mathvariant="bold-italic">C</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:munderover><mml:mo>∑</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>N</mml:mi></mml:mrow></mml:munderover><mml:msub><mml:mi>λ</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula>, where <inline-formula><mml:math id="inf286"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msub><mml:mi>λ</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:mstyle></mml:math></inline-formula> is the <italic>i</italic>th largest eigenvalue for <inline-formula><mml:math id="inf287"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi mathvariant="bold-italic">C</mml:mi></mml:mrow></mml:mstyle></mml:math></inline-formula>. The percentage variance is a quantity between 0% and 100%.</p></sec><sec id="s4-8"><title>The composition of raw signals’ variance</title><p>Suppose <inline-formula><mml:math id="inf288"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi mathvariant="bold-italic">x</mml:mi><mml:mo>∈</mml:mo><mml:msup><mml:mrow><mml:mi mathvariant="double-struck">R</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn><mml:mo>×</mml:mo><mml:mi>T</mml:mi></mml:mrow></mml:msup></mml:mrow></mml:mstyle></mml:math></inline-formula>, <inline-formula><mml:math id="inf289"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi mathvariant="bold-italic">y</mml:mi><mml:mo>∈</mml:mo><mml:msup><mml:mrow><mml:mi mathvariant="double-struck">R</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn><mml:mo>×</mml:mo><mml:mi>T</mml:mi></mml:mrow></mml:msup></mml:mrow></mml:mstyle></mml:math></inline-formula>, and <inline-formula><mml:math id="inf290"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi mathvariant="bold-italic">z</mml:mi><mml:mo>∈</mml:mo><mml:msup><mml:mrow><mml:mi mathvariant="double-struck">R</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn><mml:mo>×</mml:mo><mml:mi>T</mml:mi></mml:mrow></mml:msup></mml:mrow></mml:mstyle></mml:math></inline-formula> are the random variables for a single neuron of behaviorally relevant signals, behaviorally irrelevant, and raw signals, where <inline-formula><mml:math id="inf291"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi mathvariant="bold-italic">z</mml:mi><mml:mo>=</mml:mo><mml:mi mathvariant="bold-italic">x</mml:mi><mml:mo>+</mml:mo><mml:mi mathvariant="bold-italic">y</mml:mi></mml:mrow></mml:mstyle></mml:math></inline-formula>, <inline-formula><mml:math id="inf292"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>T</mml:mi></mml:mstyle></mml:math></inline-formula> denotes the number of samples. The composition of raw signals’ variance is as follows:<disp-formula id="equ12"><label>(12)</label><mml:math id="m12"><mml:mrow><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mtable columnalign="left left" rowspacing="4pt" columnspacing="1em"><mml:mtr><mml:mtd><mml:mrow><mml:mi mathvariant="normal">V</mml:mi><mml:mi mathvariant="normal">a</mml:mi><mml:mi mathvariant="normal">r</mml:mi></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi mathvariant="bold-italic">z</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mtd><mml:mtd><mml:mo>=</mml:mo><mml:mrow><mml:mi mathvariant="normal">V</mml:mi><mml:mi mathvariant="normal">a</mml:mi><mml:mi mathvariant="normal">r</mml:mi></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi mathvariant="bold-italic">x</mml:mi><mml:mo>+</mml:mo><mml:mi mathvariant="bold-italic">y</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mrow><mml:mi mathvariant="double-struck">E</mml:mi></mml:mrow><mml:msup><mml:mrow><mml:mo>{</mml:mo><mml:mrow><mml:mo stretchy="false">[</mml:mo><mml:mi mathvariant="bold-italic">x</mml:mi><mml:mo>−</mml:mo><mml:mrow><mml:mi mathvariant="double-struck">E</mml:mi></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi mathvariant="bold-italic">x</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo stretchy="false">]</mml:mo><mml:mo>+</mml:mo><mml:mo stretchy="false">[</mml:mo><mml:mi mathvariant="bold-italic">y</mml:mi><mml:mo>−</mml:mo><mml:mrow><mml:mi mathvariant="double-struck">E</mml:mi></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi mathvariant="bold-italic">y</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo stretchy="false">]</mml:mo></mml:mrow><mml:mo>}</mml:mo></mml:mrow><mml:mn>2</mml:mn></mml:msup></mml:mtd></mml:mtr><mml:mtr><mml:mtd/><mml:mtd><mml:mo>=</mml:mo><mml:mrow><mml:mi mathvariant="double-struck">E</mml:mi></mml:mrow><mml:mo stretchy="false">[</mml:mo><mml:mi mathvariant="bold-italic">x</mml:mi><mml:mo>−</mml:mo><mml:mrow><mml:mi mathvariant="double-struck">E</mml:mi></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi mathvariant="bold-italic">x</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:msup><mml:mo stretchy="false">]</mml:mo><mml:mn>2</mml:mn></mml:msup><mml:mo>+</mml:mo><mml:mrow><mml:mi mathvariant="double-struck">E</mml:mi></mml:mrow><mml:mo stretchy="false">[</mml:mo><mml:mi mathvariant="bold-italic">y</mml:mi><mml:mo>−</mml:mo><mml:mrow><mml:mi mathvariant="double-struck">E</mml:mi></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi mathvariant="bold-italic">y</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:msup><mml:mo stretchy="false">]</mml:mo><mml:mn>2</mml:mn></mml:msup><mml:mo>+</mml:mo><mml:mn>2</mml:mn><mml:mrow><mml:mi mathvariant="double-struck">E</mml:mi></mml:mrow><mml:mrow><mml:mo stretchy="false">[</mml:mo><mml:mi mathvariant="bold-italic">x</mml:mi><mml:mo>−</mml:mo><mml:mrow><mml:mi mathvariant="double-struck">E</mml:mi></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi mathvariant="bold-italic">x</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo stretchy="false">]</mml:mo><mml:mo stretchy="false">[</mml:mo><mml:mi mathvariant="bold-italic">y</mml:mi><mml:mo>−</mml:mo><mml:mrow><mml:mi mathvariant="double-struck">E</mml:mi></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi mathvariant="bold-italic">y</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo stretchy="false">]</mml:mo></mml:mrow></mml:mtd></mml:mtr><mml:mtr><mml:mtd/><mml:mtd><mml:mo>=</mml:mo><mml:mrow><mml:mi mathvariant="normal">V</mml:mi><mml:mi mathvariant="normal">a</mml:mi><mml:mi mathvariant="normal">r</mml:mi></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi mathvariant="bold-italic">x</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>+</mml:mo><mml:mrow><mml:mi mathvariant="normal">V</mml:mi><mml:mi mathvariant="normal">a</mml:mi><mml:mi mathvariant="normal">r</mml:mi></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi mathvariant="bold-italic">y</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>+</mml:mo><mml:mn>2</mml:mn><mml:mrow><mml:mi mathvariant="normal">C</mml:mi><mml:mi mathvariant="normal">o</mml:mi><mml:mi mathvariant="normal">v</mml:mi></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi mathvariant="bold-italic">x</mml:mi><mml:mo>,</mml:mo><mml:mi mathvariant="bold-italic">y</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>,</mml:mo></mml:mtd></mml:mtr></mml:mtable></mml:mstyle></mml:mrow></mml:math></disp-formula></p><p>where <inline-formula><mml:math id="inf293"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi mathvariant="double-struck">E</mml:mi></mml:mrow></mml:mstyle></mml:math></inline-formula>, <inline-formula><mml:math id="inf294"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi mathvariant="normal">V</mml:mi><mml:mi mathvariant="normal">a</mml:mi><mml:mi mathvariant="normal">r</mml:mi></mml:mrow></mml:mstyle></mml:math></inline-formula>, and <inline-formula><mml:math id="inf295"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi mathvariant="normal">C</mml:mi><mml:mi mathvariant="normal">o</mml:mi><mml:mi mathvariant="normal">v</mml:mi></mml:mrow></mml:mstyle></mml:math></inline-formula> denote expectation, variance, and covariance, respectively. Thus, the variance of raw signals is composed of the variance of relevant signals <inline-formula><mml:math id="inf296"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mrow><mml:mi mathvariant="normal">V</mml:mi><mml:mi mathvariant="normal">a</mml:mi><mml:mi mathvariant="normal">r</mml:mi></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi mathvariant="bold-italic">x</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mstyle></mml:math></inline-formula>, the variance of irrelevant signals <inline-formula><mml:math id="inf297"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mrow><mml:mi mathvariant="normal">V</mml:mi><mml:mi mathvariant="normal">a</mml:mi><mml:mi mathvariant="normal">r</mml:mi></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi mathvariant="bold-italic">y</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mstyle></mml:math></inline-formula>, and the correlation between relevant and irrelevant signals <inline-formula><mml:math id="inf298"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mn>2</mml:mn><mml:mrow><mml:mi mathvariant="normal">C</mml:mi><mml:mi mathvariant="normal">o</mml:mi><mml:mi mathvariant="normal">v</mml:mi></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi mathvariant="bold-italic">x</mml:mi><mml:mo>,</mml:mo><mml:mi mathvariant="bold-italic">y</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mstyle></mml:math></inline-formula>. If there are <inline-formula><mml:math id="inf299"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>N</mml:mi></mml:mstyle></mml:math></inline-formula> neurons, calculate the composition of each neuron separately and then add it up to get the total composition of raw signals.</p></sec><sec id="s4-9"><title>Reordered correlation matrix of neurons</title><p>The correlation matrix is reordered with a simple group method. The order of reordered neurons is determined from raw neural signals, which is then used for behaviorally relevant signals.</p><p>The steps of the group method are as follows:</p><list list-type="simple"><list-item><p>Step 1: We get the correlation matrix in original neuron order and set a list A that contains all neuron numbers and an empty list B.</p></list-item><list-item><p>Step 2: We select the neuron with the row number of the largest value of the correlation matrix except for the diagonal line and choose nine neurons in list A that are most similar to the selected neuron. We selected the value nine because it offers a good visualization of neuron clusters.</p></list-item><list-item><p>Step 3: Remove these selected neurons from list A, and add these selected neurons in descending order of correlation value in list B.</p></list-item><list-item><p>Step 4: Repeat steps 2 and 3 until list A is empty.</p></list-item></list></sec><sec id="s4-10"><title>The improvement ratio of lower- and higher-speed regions</title><sec id="s4-10-1"><title>Split lower- and higher-speed regions</title><p>Since the speed ranges of different datasets are different, it is hard to determine a common speed threshold to split lower- and higher-speed regions. Here, we used the squared error as a criterion to split the two speed regions. And for the convenience of calculating the absolute improvement ratio, we need a unified benchmark for comparison. Therefore, we use half of the total squared error as the threshold. Specifically, first, we calculated all samples’ total squared error (<inline-formula><mml:math id="inf300"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msub><mml:mi>E</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>p</mml:mi></mml:mrow></mml:msub></mml:mstyle></mml:math></inline-formula>) between actual velocity and predicted velocity obtained by primary signals only. Then, we enumerated the speed from 1 to 50 with a step of 0.1 and calculated the total squared error of selected samples whose speed is less than the enumerated speed. Once the total squared error of selected samples is greater than or equal to the half total squared error of all samples (<inline-formula><mml:math id="inf301"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mn>0.5</mml:mn><mml:msub><mml:mi>E</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>p</mml:mi></mml:mrow></mml:msub></mml:mstyle></mml:math></inline-formula>), the enumerated speed is set as the speed threshold. The samples whose speed is less than or equal to the speed threshold belong to lower-speed regions, and those whose speed is greater than the speed threshold belong to higher-speed regions. The squared error of the lower-speed part (<inline-formula><mml:math id="inf302"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msubsup><mml:mi>E</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>p</mml:mi></mml:mrow><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>l</mml:mi><mml:mi>o</mml:mi><mml:mi>w</mml:mi></mml:mrow></mml:msubsup></mml:mstyle></mml:math></inline-formula>) is approximately equal to that of the higher one <inline-formula><mml:math id="inf303"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msubsup><mml:mi>E</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>p</mml:mi></mml:mrow><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>h</mml:mi><mml:mi>i</mml:mi><mml:mi>g</mml:mi><mml:mi>h</mml:mi></mml:mrow></mml:msubsup></mml:mstyle></mml:math></inline-formula>, i.e., <inline-formula><mml:math id="inf304"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msubsup><mml:mi>E</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>p</mml:mi></mml:mrow><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>l</mml:mi><mml:mi>o</mml:mi><mml:mi>w</mml:mi></mml:mrow></mml:msubsup><mml:mo>≈</mml:mo><mml:msubsup><mml:mi>E</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>p</mml:mi></mml:mrow><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>h</mml:mi><mml:mi>i</mml:mi><mml:mi>g</mml:mi><mml:mi>h</mml:mi></mml:mrow></mml:msubsup><mml:mo>≈</mml:mo><mml:mn>0.5</mml:mn><mml:msub><mml:mi>E</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>p</mml:mi></mml:mrow></mml:msub></mml:mstyle></mml:math></inline-formula> (the difference is negligible).</p></sec><sec id="s4-10-2"><title>The absolute improvement ratio</title><p>After splitting the speed regions, we calculated the improvement of the two regions by superimposing secondary signals to primary signals, and got the squared error of lower <inline-formula><mml:math id="inf305"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msubsup><mml:mi>E</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>p</mml:mi><mml:mo>+</mml:mo><mml:mi>s</mml:mi></mml:mrow><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>l</mml:mi><mml:mi>o</mml:mi><mml:mi>w</mml:mi></mml:mrow></mml:msubsup></mml:mstyle></mml:math></inline-formula> and higher <inline-formula><mml:math id="inf306"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msubsup><mml:mi>E</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>p</mml:mi><mml:mo>+</mml:mo><mml:mi>s</mml:mi></mml:mrow><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>h</mml:mi><mml:mi>i</mml:mi><mml:mi>g</mml:mi><mml:mi>h</mml:mi></mml:mrow></mml:msubsup></mml:mstyle></mml:math></inline-formula> regions. Then, we calculated the absolute improvement ratio (AIR):<disp-formula id="equ13"><label>(13)</label><mml:math id="m13"><mml:mrow><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>A</mml:mi><mml:mi>I</mml:mi><mml:msub><mml:mi>R</mml:mi><mml:mrow><mml:mi>l</mml:mi><mml:mi>o</mml:mi><mml:mi>w</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mo>−</mml:mo><mml:mfrac><mml:mrow><mml:msubsup><mml:mi>E</mml:mi><mml:mrow><mml:mi>p</mml:mi><mml:mo>+</mml:mo><mml:mi>s</mml:mi></mml:mrow><mml:mrow><mml:mi>l</mml:mi><mml:mi>o</mml:mi><mml:mi>w</mml:mi></mml:mrow></mml:msubsup><mml:mo>−</mml:mo><mml:msubsup><mml:mi>E</mml:mi><mml:mrow><mml:mi>p</mml:mi></mml:mrow><mml:mrow><mml:mi>l</mml:mi><mml:mi>o</mml:mi><mml:mi>w</mml:mi></mml:mrow></mml:msubsup></mml:mrow><mml:msubsup><mml:mi>E</mml:mi><mml:mrow><mml:mi>p</mml:mi></mml:mrow><mml:mrow><mml:mi>l</mml:mi><mml:mi>o</mml:mi><mml:mi>w</mml:mi></mml:mrow></mml:msubsup></mml:mfrac><mml:mo>≈</mml:mo><mml:mo>−</mml:mo><mml:mfrac><mml:mrow><mml:msubsup><mml:mi>E</mml:mi><mml:mrow><mml:mi>p</mml:mi><mml:mo>+</mml:mo><mml:mi>s</mml:mi></mml:mrow><mml:mrow><mml:mi>l</mml:mi><mml:mi>o</mml:mi><mml:mi>w</mml:mi></mml:mrow></mml:msubsup><mml:mo>−</mml:mo><mml:mn>0.5</mml:mn><mml:msub><mml:mi>E</mml:mi><mml:mrow><mml:mi>p</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:mn>0.5</mml:mn><mml:msub><mml:mi>E</mml:mi><mml:mrow><mml:mi>p</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfrac></mml:mstyle></mml:mrow></mml:math></disp-formula><disp-formula id="equ14"><label>(14)</label><mml:math id="m14"><mml:mi>A</mml:mi><mml:mi>I</mml:mi><mml:msub><mml:mi>R</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>h</mml:mi><mml:mi>i</mml:mi><mml:mi>g</mml:mi><mml:mi>h</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mo>−</mml:mo><mml:mfrac><mml:mrow><mml:msubsup><mml:mi>E</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>p</mml:mi><mml:mo>+</mml:mo><mml:mi>s</mml:mi></mml:mrow><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>h</mml:mi><mml:mi>i</mml:mi><mml:mi>g</mml:mi><mml:mi>h</mml:mi></mml:mrow></mml:msubsup><mml:mo>−</mml:mo><mml:msubsup><mml:mi>E</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>p</mml:mi></mml:mrow><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>h</mml:mi><mml:mi>i</mml:mi><mml:mi>g</mml:mi><mml:mi>h</mml:mi></mml:mrow></mml:msubsup></mml:mrow><mml:msubsup><mml:mi>E</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>p</mml:mi></mml:mrow><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>h</mml:mi><mml:mi>i</mml:mi><mml:mi>g</mml:mi><mml:mi>h</mml:mi></mml:mrow></mml:msubsup></mml:mfrac><mml:mo>≈</mml:mo><mml:mo>−</mml:mo><mml:mfrac><mml:mrow><mml:msubsup><mml:mi>E</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>p</mml:mi><mml:mo>+</mml:mo><mml:mi>s</mml:mi></mml:mrow><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>h</mml:mi><mml:mi>i</mml:mi><mml:mi>g</mml:mi><mml:mi>h</mml:mi></mml:mrow></mml:msubsup><mml:mo>−</mml:mo><mml:mn>0.5</mml:mn><mml:msub><mml:mi>E</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>p</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:mn>0.5</mml:mn><mml:msub><mml:mi>E</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>p</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfrac></mml:math></disp-formula></p><p>Since the two regions refer to a common standard (<inline-formula><mml:math id="inf307"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mn>0.5</mml:mn><mml:msub><mml:mi>E</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>p</mml:mi></mml:mrow></mml:msub></mml:mstyle></mml:math></inline-formula>), the improvement ratio of the two regions can be directly compared, and that’s why we call it the absolute improvement ratio.</p></sec><sec id="s4-10-3"><title>The relative improvement ratio</title><p>The relative improvement ratio (RIR) measures the improvement ratio of each sample relative to itself before and after superimposing secondary signals. The relative improvement ratio is computed as follows:<disp-formula id="equ15"><label>(15)</label><mml:math id="m15"><mml:mi>R</mml:mi><mml:mi>I</mml:mi><mml:msup><mml:mi>R</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>i</mml:mi></mml:mrow></mml:msup><mml:mo>=</mml:mo><mml:mo>−</mml:mo><mml:mfrac><mml:mrow><mml:msubsup><mml:mi>E</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>p</mml:mi><mml:mo>+</mml:mo><mml:mi>s</mml:mi></mml:mrow><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>i</mml:mi></mml:mrow></mml:msubsup><mml:mo>−</mml:mo><mml:msubsup><mml:mi>E</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>p</mml:mi></mml:mrow><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>i</mml:mi></mml:mrow></mml:msubsup></mml:mrow><mml:msubsup><mml:mi>E</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>p</mml:mi></mml:mrow><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>i</mml:mi></mml:mrow></mml:msubsup></mml:mfrac><mml:mo>,</mml:mo></mml:math></disp-formula></p><p>where <italic>i</italic> denotes the <italic>i</italic>th sample of test data.</p></sec></sec><sec id="s4-11"><title>Code availability</title><p>The code is available at <ext-link ext-link-type="uri" xlink:href="https://github.com/eric0li/d-VAE">https://github.com/eric0li/d-VAE</ext-link>, copy archived at <xref ref-type="bibr" rid="bib12">eric0li, 2024</xref>.</p></sec></sec></body><back><sec sec-type="additional-information" id="s5"><title>Additional information</title><fn-group content-type="competing-interest"><title>Competing interests</title><fn fn-type="COI-statement" id="conf1"><p>No competing interests declared</p></fn></fn-group><fn-group content-type="author-contribution"><title>Author contributions</title><fn fn-type="con" id="con1"><p>Conceptualization, Software, Formal analysis, Visualization, Methodology, Writing – original draft, Writing – review and editing</p></fn><fn fn-type="con" id="con2"><p>Visualization, Writing – original draft, Writing – review and editing</p></fn><fn fn-type="con" id="con3"><p>Supervision, Writing – original draft</p></fn><fn fn-type="con" id="con4"><p>Supervision, Funding acquisition, Writing – review and editing</p></fn></fn-group><fn-group content-type="ethics-information"><title>Ethics</title><fn fn-type="other"><p>All animal handling procedures were authorized by the Animal Care Committee at Zhejiang University, China (No. ZJU20220142), and conducted following the Guide for Care and Use of Laboratory Animals (China Ministry of Health).</p></fn></fn-group></sec><sec sec-type="supplementary-material" id="s6"><title>Additional files</title><supplementary-material id="mdar"><label>MDAR checklist</label><media xlink:href="elife-87881-mdarchecklist1-v1.docx" mimetype="application" mime-subtype="docx"/></supplementary-material></sec><sec sec-type="data-availability" id="s7"><title>Data availability</title><p>All the datasets are publicly accessible.</p><p>The following previously published dataset was used:</p><p><element-citation publication-type="data" specific-use="references" id="dataset1"><person-group person-group-type="author"><name><surname>O'Doherty</surname><given-names>JE</given-names></name><name><surname>Cardoso</surname><given-names>MMB</given-names></name><name><surname>Makin</surname><given-names>JG</given-names></name><name><surname>Sabes</surname><given-names>PN</given-names></name></person-group><year iso-8601-date="2017">2017</year><data-title>Nonhuman Primate Reaching with Multichannel Sensorimotor Cortex Electrophysiology: broadband for indy_20170124_01</data-title><source>Zenodo</source><pub-id pub-id-type="doi">10.5281/zenodo.1163026</pub-id></element-citation></p></sec><ack id="ack"><title>Acknowledgements</title><p>We thank Yiwen Wang for sharing the monkey obstacle avoidance reaching data. We thank Yuxiao Yang and Huaqin Sun for valuable discussions. This work was supported in part by the National Natural Science Foundation of China under Grants 62336007, in part by the Key R&amp;D Program of Zhejiang under Grant 2022C03011, in part by the Starry Night Science Fund of Zhejiang University Shanghai Institute for Advanced Study under Grant SN-ZJU-SIAS-002, and in part by the Fundamental Research Funds for the Central Universities.</p></ack><ref-list><title>References</title><ref id="bib1"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Alstott</surname><given-names>J</given-names></name><name><surname>Breakspear</surname><given-names>M</given-names></name><name><surname>Hagmann</surname><given-names>P</given-names></name><name><surname>Cammoun</surname><given-names>L</given-names></name><name><surname>Sporns</surname><given-names>O</given-names></name></person-group><year iso-8601-date="2009">2009</year><article-title>Modeling the impact of lesions in the human brain</article-title><source>PLOS Computational Biology</source><volume>5</volume><elocation-id>e1000408</elocation-id><pub-id pub-id-type="doi">10.1371/journal.pcbi.1000408</pub-id><pub-id pub-id-type="pmid">19521503</pub-id></element-citation></ref><ref id="bib2"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Altan</surname><given-names>E</given-names></name><name><surname>Solla</surname><given-names>SA</given-names></name><name><surname>Miller</surname><given-names>LE</given-names></name><name><surname>Perreault</surname><given-names>EJ</given-names></name></person-group><year iso-8601-date="2021">2021</year><article-title>Estimating the dimensionality of the manifold underlying multi-electrode neural recordings</article-title><source>PLOS Computational Biology</source><volume>17</volume><elocation-id>e1008591</elocation-id><pub-id pub-id-type="doi">10.1371/journal.pcbi.1008591</pub-id><pub-id pub-id-type="pmid">34843461</pub-id></element-citation></ref><ref id="bib3"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Azouz</surname><given-names>R</given-names></name><name><surname>Gray</surname><given-names>CM</given-names></name></person-group><year iso-8601-date="1999">1999</year><article-title>Cellular mechanisms contributing to response variability of cortical neurons in vivo</article-title><source>The Journal of Neuroscience</source><volume>19</volume><fpage>2209</fpage><lpage>2223</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.19-06-02209.1999</pub-id><pub-id pub-id-type="pmid">10066274</pub-id></element-citation></ref><ref id="bib4"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Carmena</surname><given-names>JM</given-names></name><name><surname>Lebedev</surname><given-names>MA</given-names></name><name><surname>Henriquez</surname><given-names>CS</given-names></name><name><surname>Nicolelis</surname><given-names>MAL</given-names></name></person-group><year iso-8601-date="2005">2005</year><article-title>Stable ensemble performance with single-neuron variability during reaching movements in primates</article-title><source>The Journal of Neuroscience</source><volume>25</volume><fpage>10712</fpage><lpage>10716</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.2772-05.2005</pub-id><pub-id pub-id-type="pmid">16291944</pub-id></element-citation></ref><ref id="bib5"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Churchland</surname><given-names>MM</given-names></name><name><surname>Yu</surname><given-names>BM</given-names></name><name><surname>Cunningham</surname><given-names>JP</given-names></name><name><surname>Sugrue</surname><given-names>LP</given-names></name><name><surname>Cohen</surname><given-names>MR</given-names></name><name><surname>Corrado</surname><given-names>GS</given-names></name><name><surname>Newsome</surname><given-names>WT</given-names></name><name><surname>Clark</surname><given-names>AM</given-names></name><name><surname>Hosseini</surname><given-names>P</given-names></name><name><surname>Scott</surname><given-names>BB</given-names></name><name><surname>Bradley</surname><given-names>DC</given-names></name><name><surname>Smith</surname><given-names>MA</given-names></name><name><surname>Kohn</surname><given-names>A</given-names></name><name><surname>Movshon</surname><given-names>JA</given-names></name><name><surname>Armstrong</surname><given-names>KM</given-names></name><name><surname>Moore</surname><given-names>T</given-names></name><name><surname>Chang</surname><given-names>SW</given-names></name><name><surname>Snyder</surname><given-names>LH</given-names></name><name><surname>Lisberger</surname><given-names>SG</given-names></name><name><surname>Priebe</surname><given-names>NJ</given-names></name><name><surname>Finn</surname><given-names>IM</given-names></name><name><surname>Ferster</surname><given-names>D</given-names></name><name><surname>Ryu</surname><given-names>SI</given-names></name><name><surname>Santhanam</surname><given-names>G</given-names></name><name><surname>Sahani</surname><given-names>M</given-names></name><name><surname>Shenoy</surname><given-names>KV</given-names></name></person-group><year iso-8601-date="2010">2010</year><article-title>Stimulus onset quenches neural variability: a widespread cortical phenomenon</article-title><source>Nature Neuroscience</source><volume>13</volume><fpage>369</fpage><lpage>378</lpage><pub-id pub-id-type="doi">10.1038/nn.2501</pub-id><pub-id pub-id-type="pmid">20173745</pub-id></element-citation></ref><ref id="bib6"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Churchland</surname><given-names>MM</given-names></name><name><surname>Cunningham</surname><given-names>JP</given-names></name><name><surname>Kaufman</surname><given-names>MT</given-names></name><name><surname>Foster</surname><given-names>JD</given-names></name><name><surname>Nuyujukian</surname><given-names>P</given-names></name><name><surname>Ryu</surname><given-names>SI</given-names></name><name><surname>Shenoy</surname><given-names>KV</given-names></name></person-group><year iso-8601-date="2012">2012</year><article-title>Neural population dynamics during reaching</article-title><source>Nature</source><volume>487</volume><fpage>51</fpage><lpage>56</lpage><pub-id pub-id-type="doi">10.1038/nature11129</pub-id><pub-id pub-id-type="pmid">22722855</pub-id></element-citation></ref><ref id="bib7"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Collinger</surname><given-names>JL</given-names></name><name><surname>Wodlinger</surname><given-names>B</given-names></name><name><surname>Downey</surname><given-names>JE</given-names></name><name><surname>Wang</surname><given-names>W</given-names></name><name><surname>Tyler-Kabara</surname><given-names>EC</given-names></name><name><surname>Weber</surname><given-names>DJ</given-names></name><name><surname>McMorland</surname><given-names>AJC</given-names></name><name><surname>Velliste</surname><given-names>M</given-names></name><name><surname>Boninger</surname><given-names>ML</given-names></name><name><surname>Schwartz</surname><given-names>AB</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>High-performance neuroprosthetic control by an individual with tetraplegia</article-title><source>Lancet</source><volume>381</volume><fpage>557</fpage><lpage>564</lpage><pub-id pub-id-type="doi">10.1016/S0140-6736(12)61816-9</pub-id><pub-id pub-id-type="pmid">23253623</pub-id></element-citation></ref><ref id="bib8"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Cunningham</surname><given-names>JP</given-names></name><name><surname>Yu</surname><given-names>BM</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>Dimensionality reduction for large-scale neural recordings</article-title><source>Nature Neuroscience</source><volume>17</volume><fpage>1500</fpage><lpage>1509</lpage><pub-id pub-id-type="doi">10.1038/nn.3776</pub-id><pub-id pub-id-type="pmid">25151264</pub-id></element-citation></ref><ref id="bib9"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Dhawale</surname><given-names>AK</given-names></name><name><surname>Smith</surname><given-names>MA</given-names></name><name><surname>Ölveczky</surname><given-names>BP</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>The role of variability in motor learning</article-title><source>Annual Review of Neuroscience</source><volume>40</volume><fpage>479</fpage><lpage>498</lpage><pub-id pub-id-type="doi">10.1146/annurev-neuro-072116-031548</pub-id><pub-id pub-id-type="pmid">28489490</pub-id></element-citation></ref><ref id="bib10"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Dyer</surname><given-names>EL</given-names></name><name><surname>Gheshlaghi Azar</surname><given-names>M</given-names></name><name><surname>Perich</surname><given-names>MG</given-names></name><name><surname>Fernandes</surname><given-names>HL</given-names></name><name><surname>Naufel</surname><given-names>S</given-names></name><name><surname>Miller</surname><given-names>LE</given-names></name><name><surname>Körding</surname><given-names>KP</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>A cryptography-based approach for movement decoding</article-title><source>Nature Biomedical Engineering</source><volume>1</volume><fpage>967</fpage><lpage>976</lpage><pub-id pub-id-type="doi">10.1038/s41551-017-0169-7</pub-id><pub-id pub-id-type="pmid">31015712</pub-id></element-citation></ref><ref id="bib11"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Elsayed</surname><given-names>GF</given-names></name><name><surname>Lara</surname><given-names>AH</given-names></name><name><surname>Kaufman</surname><given-names>MT</given-names></name><name><surname>Churchland</surname><given-names>MM</given-names></name><name><surname>Cunningham</surname><given-names>JP</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Reorganization between preparatory and movement population responses in motor cortex</article-title><source>Nature Communications</source><volume>7</volume><elocation-id>13239</elocation-id><pub-id pub-id-type="doi">10.1038/ncomms13239</pub-id><pub-id pub-id-type="pmid">27807345</pub-id></element-citation></ref><ref id="bib12"><element-citation publication-type="software"><person-group person-group-type="author"><collab>eric0li</collab></person-group><year iso-8601-date="2024">2024</year><data-title>D-VAE</data-title><version designator="swh:1:rev:e117d8ef0a2a1f66c0e3f9b1ed47423b1211037f">swh:1:rev:e117d8ef0a2a1f66c0e3f9b1ed47423b1211037f</version><source>Software Heritage</source><ext-link ext-link-type="uri" xlink:href="https://archive.softwareheritage.org/swh:1:dir:689f4c1e7a7bdd87b3dff48c001ac3a2bf388b72;origin=https://github.com/eric0li/d-VAE;visit=swh:1:snp:c1ce0ead59ddc57db7275fc4e5017bd8e797ea70;anchor=swh:1:rev:e117d8ef0a2a1f66c0e3f9b1ed47423b1211037f">https://archive.softwareheritage.org/swh:1:dir:689f4c1e7a7bdd87b3dff48c001ac3a2bf388b72;origin=https://github.com/eric0li/d-VAE;visit=swh:1:snp:c1ce0ead59ddc57db7275fc4e5017bd8e797ea70;anchor=swh:1:rev:e117d8ef0a2a1f66c0e3f9b1ed47423b1211037f</ext-link></element-citation></ref><ref id="bib13"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Faisal</surname><given-names>AA</given-names></name><name><surname>Selen</surname><given-names>LPJ</given-names></name><name><surname>Wolpert</surname><given-names>DM</given-names></name></person-group><year iso-8601-date="2008">2008</year><article-title>Noise in the nervous system</article-title><source>Nature Reviews. Neuroscience</source><volume>9</volume><fpage>292</fpage><lpage>303</lpage><pub-id pub-id-type="doi">10.1038/nrn2258</pub-id><pub-id pub-id-type="pmid">18319728</pub-id></element-citation></ref><ref id="bib14"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Fusi</surname><given-names>S</given-names></name><name><surname>Miller</surname><given-names>EK</given-names></name><name><surname>Rigotti</surname><given-names>M</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Why neurons mix: high dimensionality for higher cognition</article-title><source>Current Opinion in Neurobiology</source><volume>37</volume><fpage>66</fpage><lpage>74</lpage><pub-id pub-id-type="doi">10.1016/j.conb.2016.01.010</pub-id></element-citation></ref><ref id="bib15"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Gallego</surname><given-names>JA</given-names></name><name><surname>Perich</surname><given-names>MG</given-names></name><name><surname>Miller</surname><given-names>LE</given-names></name><name><surname>Solla</surname><given-names>SA</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>Neural manifolds for the control of movement</article-title><source>Neuron</source><volume>94</volume><fpage>978</fpage><lpage>984</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2017.05.025</pub-id><pub-id pub-id-type="pmid">28595054</pub-id></element-citation></ref><ref id="bib16"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Gallego</surname><given-names>JA</given-names></name><name><surname>Perich</surname><given-names>MG</given-names></name><name><surname>Naufel</surname><given-names>SN</given-names></name><name><surname>Ethier</surname><given-names>C</given-names></name><name><surname>Solla</surname><given-names>SA</given-names></name><name><surname>Miller</surname><given-names>LE</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>Cortical population activity within a preserved neural manifold underlies multiple motor behaviors</article-title><source>Nature Communications</source><volume>9</volume><elocation-id>4233</elocation-id><pub-id pub-id-type="doi">10.1038/s41467-018-06560-z</pub-id><pub-id pub-id-type="pmid">30315158</pub-id></element-citation></ref><ref id="bib17"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Gallego</surname><given-names>JA</given-names></name><name><surname>Perich</surname><given-names>MG</given-names></name><name><surname>Chowdhury</surname><given-names>RH</given-names></name><name><surname>Solla</surname><given-names>SA</given-names></name><name><surname>Miller</surname><given-names>LE</given-names></name></person-group><year iso-8601-date="2020">2020</year><article-title>Long-term stability of cortical population dynamics underlying consistent behavior</article-title><source>Nature Neuroscience</source><volume>23</volume><fpage>260</fpage><lpage>270</lpage><pub-id pub-id-type="doi">10.1038/s41593-019-0555-4</pub-id><pub-id pub-id-type="pmid">31907438</pub-id></element-citation></ref><ref id="bib18"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ganmor</surname><given-names>E</given-names></name><name><surname>Segev</surname><given-names>R</given-names></name><name><surname>Schneidman</surname><given-names>E</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>A thesaurus for A neural population code</article-title><source>eLife</source><volume>4</volume><elocation-id>e06134</elocation-id><pub-id pub-id-type="doi">10.7554/eLife.06134</pub-id><pub-id pub-id-type="pmid">26347983</pub-id></element-citation></ref><ref id="bib19"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Georgopoulos</surname><given-names>AP</given-names></name><name><surname>Schwartz</surname><given-names>AB</given-names></name><name><surname>Kettner</surname><given-names>RE</given-names></name></person-group><year iso-8601-date="1986">1986</year><article-title>Neuronal population coding of movement direction</article-title><source>Science</source><volume>233</volume><fpage>1416</fpage><lpage>1419</lpage><pub-id pub-id-type="doi">10.1126/science.3749885</pub-id><pub-id pub-id-type="pmid">3749885</pub-id></element-citation></ref><ref id="bib20"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Glaser</surname><given-names>JI</given-names></name><name><surname>Benjamin</surname><given-names>AS</given-names></name><name><surname>Chowdhury</surname><given-names>RH</given-names></name><name><surname>Perich</surname><given-names>MG</given-names></name><name><surname>Miller</surname><given-names>LE</given-names></name><name><surname>Kording</surname><given-names>KP</given-names></name></person-group><year iso-8601-date="2020">2020</year><article-title>Machine learning for neural decoding</article-title><source>eNeuro</source><volume>7</volume><elocation-id>ENEURO.0506-19.2020</elocation-id><pub-id pub-id-type="doi">10.1523/ENEURO.0506-19.2020</pub-id><pub-id pub-id-type="pmid">32737181</pub-id></element-citation></ref><ref id="bib21"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Golub</surname><given-names>MD</given-names></name><name><surname>Sadtler</surname><given-names>PT</given-names></name><name><surname>Oby</surname><given-names>ER</given-names></name><name><surname>Quick</surname><given-names>KM</given-names></name><name><surname>Ryu</surname><given-names>SI</given-names></name><name><surname>Tyler-Kabara</surname><given-names>EC</given-names></name><name><surname>Batista</surname><given-names>AP</given-names></name><name><surname>Chase</surname><given-names>SM</given-names></name><name><surname>Yu</surname><given-names>BM</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>Learning by neural reassociation</article-title><source>Nature Neuroscience</source><volume>21</volume><fpage>607</fpage><lpage>616</lpage><pub-id pub-id-type="doi">10.1038/s41593-018-0095-3</pub-id><pub-id pub-id-type="pmid">29531364</pub-id></element-citation></ref><ref id="bib22"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hennig</surname><given-names>JA</given-names></name><name><surname>Oby</surname><given-names>ER</given-names></name><name><surname>Golub</surname><given-names>MD</given-names></name><name><surname>Bahureksa</surname><given-names>LA</given-names></name><name><surname>Sadtler</surname><given-names>PT</given-names></name><name><surname>Quick</surname><given-names>KM</given-names></name><name><surname>Ryu</surname><given-names>SI</given-names></name><name><surname>Tyler-Kabara</surname><given-names>EC</given-names></name><name><surname>Batista</surname><given-names>AP</given-names></name><name><surname>Chase</surname><given-names>SM</given-names></name><name><surname>Yu</surname><given-names>BM</given-names></name></person-group><year iso-8601-date="2021">2021</year><article-title>Learning is shaped by abrupt changes in neural engagement</article-title><source>Nature Neuroscience</source><volume>24</volume><fpage>727</fpage><lpage>736</lpage><pub-id pub-id-type="doi">10.1038/s41593-021-00822-8</pub-id><pub-id pub-id-type="pmid">33782622</pub-id></element-citation></ref><ref id="bib23"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hochberg</surname><given-names>LR</given-names></name><name><surname>Bacher</surname><given-names>D</given-names></name><name><surname>Jarosiewicz</surname><given-names>B</given-names></name><name><surname>Masse</surname><given-names>NY</given-names></name><name><surname>Simeral</surname><given-names>JD</given-names></name><name><surname>Vogel</surname><given-names>J</given-names></name><name><surname>Haddadin</surname><given-names>S</given-names></name><name><surname>Liu</surname><given-names>J</given-names></name><name><surname>Cash</surname><given-names>SS</given-names></name><name><surname>van der Smagt</surname><given-names>P</given-names></name><name><surname>Donoghue</surname><given-names>JP</given-names></name></person-group><year iso-8601-date="2012">2012</year><article-title>Reach and grasp by people with tetraplegia using a neurally controlled robotic arm</article-title><source>Nature</source><volume>485</volume><fpage>372</fpage><lpage>375</lpage><pub-id pub-id-type="doi">10.1038/nature11076</pub-id><pub-id pub-id-type="pmid">22596161</pub-id></element-citation></ref><ref id="bib24"><element-citation publication-type="confproc"><person-group person-group-type="author"><name><surname>Hurwitz</surname><given-names>C</given-names></name></person-group><year iso-8601-date="2021">2021</year><article-title>Targeted neural dynamical modeling</article-title><conf-name>Advances in Neural Information Processing Systems</conf-name><fpage>29379</fpage><lpage>29392</lpage></element-citation></ref><ref id="bib25"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Inoue</surname><given-names>Y</given-names></name><name><surname>Mao</surname><given-names>H</given-names></name><name><surname>Suway</surname><given-names>SB</given-names></name><name><surname>Orellana</surname><given-names>J</given-names></name><name><surname>Schwartz</surname><given-names>AB</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>Decoding arm speed during reaching</article-title><source>Nature Communications</source><volume>9</volume><elocation-id>5243</elocation-id><pub-id pub-id-type="doi">10.1038/s41467-018-07647-3</pub-id><pub-id pub-id-type="pmid">30531921</pub-id></element-citation></ref><ref id="bib26"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Jiang</surname><given-names>X</given-names></name><name><surname>Saggar</surname><given-names>H</given-names></name><name><surname>Ryu</surname><given-names>SI</given-names></name><name><surname>Shenoy</surname><given-names>KV</given-names></name><name><surname>Kao</surname><given-names>JC</given-names></name></person-group><year iso-8601-date="2020">2020</year><article-title>Structure in neural activity during observed and executed movements is shared at the neural population level, not in single neurons</article-title><source>Cell Reports</source><volume>32</volume><elocation-id>108006</elocation-id><pub-id pub-id-type="doi">10.1016/j.celrep.2020.108006</pub-id><pub-id pub-id-type="pmid">32783934</pub-id></element-citation></ref><ref id="bib27"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kaufman</surname><given-names>MT</given-names></name><name><surname>Churchland</surname><given-names>MM</given-names></name><name><surname>Ryu</surname><given-names>SI</given-names></name><name><surname>Shenoy</surname><given-names>KV</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>Cortical activity in the null space: permitting preparation without movement</article-title><source>Nature Neuroscience</source><volume>17</volume><fpage>440</fpage><lpage>448</lpage><pub-id pub-id-type="doi">10.1038/nn.3643</pub-id><pub-id pub-id-type="pmid">24487233</pub-id></element-citation></ref><ref id="bib28"><element-citation publication-type="preprint"><person-group person-group-type="author"><name><surname>Kingma</surname><given-names>DP</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>Auto-Encoding Variational Bayes</article-title><source>arXiv</source><ext-link ext-link-type="uri" xlink:href="https://arxiv.org/abs/1312.6114">https://arxiv.org/abs/1312.6114</ext-link></element-citation></ref><ref id="bib29"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kobak</surname><given-names>D</given-names></name><name><surname>Brendel</surname><given-names>W</given-names></name><name><surname>Constantinidis</surname><given-names>C</given-names></name><name><surname>Feierstein</surname><given-names>CE</given-names></name><name><surname>Kepecs</surname><given-names>A</given-names></name><name><surname>Mainen</surname><given-names>ZF</given-names></name><name><surname>Qi</surname><given-names>X-L</given-names></name><name><surname>Romo</surname><given-names>R</given-names></name><name><surname>Uchida</surname><given-names>N</given-names></name><name><surname>Machens</surname><given-names>CK</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Demixed principal component analysis of neural population data</article-title><source>eLife</source><volume>5</volume><elocation-id>e10989</elocation-id><pub-id pub-id-type="doi">10.7554/eLife.10989</pub-id><pub-id pub-id-type="pmid">27067378</pub-id></element-citation></ref><ref id="bib30"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kriegeskorte</surname><given-names>N</given-names></name><name><surname>Douglas</surname><given-names>PK</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>Interpreting encoding and decoding models</article-title><source>Current Opinion in Neurobiology</source><volume>55</volume><fpage>167</fpage><lpage>179</lpage><pub-id pub-id-type="doi">10.1016/j.conb.2019.04.002</pub-id><pub-id pub-id-type="pmid">31039527</pub-id></element-citation></ref><ref id="bib31"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Lee</surname><given-names>JA</given-names></name><name><surname>Verleysen</surname><given-names>M</given-names></name></person-group><year iso-8601-date="2007">2007</year><source>Nonlinear Dimensionality Reduction</source><publisher-name>Springer</publisher-name><pub-id pub-id-type="doi">10.1007/978-0-387-39351-3</pub-id></element-citation></ref><ref id="bib32"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Li</surname><given-names>Y</given-names></name><name><surname>Qi</surname><given-names>Y</given-names></name><name><surname>Wang</surname><given-names>Y</given-names></name><name><surname>Wang</surname><given-names>Y</given-names></name><name><surname>Xu</surname><given-names>K</given-names></name><name><surname>Pan</surname><given-names>G</given-names></name></person-group><year iso-8601-date="2021">2021</year><article-title>Robust neural decoding by kernel regression with Siamese representation learning</article-title><source>Journal of Neural Engineering</source><volume>18</volume><elocation-id>056062</elocation-id><pub-id pub-id-type="doi">10.1088/1741-2552/ac2c4e</pub-id><pub-id pub-id-type="pmid">34663771</pub-id></element-citation></ref><ref id="bib33"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Majaj</surname><given-names>NJ</given-names></name><name><surname>Hong</surname><given-names>H</given-names></name><name><surname>Solomon</surname><given-names>EA</given-names></name><name><surname>DiCarlo</surname><given-names>JJ</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>Simple learned weighted sums of inferior temporal neuronal firing rates accurately predict human core object recognition performance</article-title><source>The Journal of Neuroscience</source><volume>35</volume><fpage>13402</fpage><lpage>13418</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.5181-14.2015</pub-id><pub-id pub-id-type="pmid">26424887</pub-id></element-citation></ref><ref id="bib34"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Moreno-Bote</surname><given-names>R</given-names></name><name><surname>Beck</surname><given-names>J</given-names></name><name><surname>Kanitscheider</surname><given-names>I</given-names></name><name><surname>Pitkow</surname><given-names>X</given-names></name><name><surname>Latham</surname><given-names>P</given-names></name><name><surname>Pouget</surname><given-names>A</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>Information-limiting correlations</article-title><source>Nature Neuroscience</source><volume>17</volume><fpage>1410</fpage><lpage>1417</lpage><pub-id pub-id-type="doi">10.1038/nn.3807</pub-id><pub-id pub-id-type="pmid">25195105</pub-id></element-citation></ref><ref id="bib35"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Musall</surname><given-names>S</given-names></name><name><surname>Kaufman</surname><given-names>MT</given-names></name><name><surname>Juavinett</surname><given-names>AL</given-names></name><name><surname>Gluf</surname><given-names>S</given-names></name><name><surname>Churchland</surname><given-names>AK</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>Single-trial neural dynamics are dominated by richly varied movements</article-title><source>Nature Neuroscience</source><volume>22</volume><fpage>1677</fpage><lpage>1686</lpage><pub-id pub-id-type="doi">10.1038/s41593-019-0502-4</pub-id><pub-id pub-id-type="pmid">31551604</pub-id></element-citation></ref><ref id="bib36"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Nakajima</surname><given-names>M</given-names></name><name><surname>Schmitt</surname><given-names>LI</given-names></name><name><surname>Halassa</surname><given-names>MM</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>Prefrontal cortex regulates sensory filtering through a basal ganglia-to-thalamus pathway</article-title><source>Neuron</source><volume>103</volume><fpage>445</fpage><lpage>458</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2019.05.026</pub-id><pub-id pub-id-type="pmid">31202541</pub-id></element-citation></ref><ref id="bib37"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Narayanan</surname><given-names>NS</given-names></name><name><surname>Kimchi</surname><given-names>EY</given-names></name><name><surname>Laubach</surname><given-names>M</given-names></name></person-group><year iso-8601-date="2005">2005</year><article-title>Redundancy and synergy of neuronal ensembles in motor cortex</article-title><source>The Journal of Neuroscience</source><volume>25</volume><fpage>4207</fpage><lpage>4216</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.4697-04.2005</pub-id><pub-id pub-id-type="pmid">15858046</pub-id></element-citation></ref><ref id="bib38"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Naufel</surname><given-names>S</given-names></name><name><surname>Glaser</surname><given-names>JI</given-names></name><name><surname>Kording</surname><given-names>KP</given-names></name><name><surname>Perreault</surname><given-names>EJ</given-names></name><name><surname>Miller</surname><given-names>LE</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>A muscle-activity-dependent gain between motor cortex and EMG</article-title><source>Journal of Neurophysiology</source><volume>121</volume><fpage>61</fpage><lpage>73</lpage><pub-id pub-id-type="doi">10.1152/jn.00329.2018</pub-id><pub-id pub-id-type="pmid">30379603</pub-id></element-citation></ref><ref id="bib39"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Nogueira</surname><given-names>R</given-names></name><name><surname>Rodgers</surname><given-names>CC</given-names></name><name><surname>Bruno</surname><given-names>RM</given-names></name><name><surname>Fusi</surname><given-names>S</given-names></name></person-group><year iso-8601-date="2023">2023</year><article-title>The geometry of cortical representations of touch in rodents</article-title><source>Nature Neuroscience</source><volume>26</volume><fpage>239</fpage><lpage>250</lpage><pub-id pub-id-type="doi">10.1038/s41593-022-01237-9</pub-id><pub-id pub-id-type="pmid">36624277</pub-id></element-citation></ref><ref id="bib40"><element-citation publication-type="software"><person-group person-group-type="author"><name><surname>O’Doherty</surname><given-names>JE</given-names></name></person-group><year iso-8601-date="2017">2017</year><data-title>Nonhuman primate reaching with multichannel sensorimotor cortex electrophysiology</data-title><version designator="v1">v1</version><source>Zenodo</source><ext-link ext-link-type="uri" xlink:href="https://doi.org/10.5281/zenodo.1302867">https://doi.org/10.5281/zenodo.1302867</ext-link></element-citation></ref><ref id="bib41"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Pagan</surname><given-names>M</given-names></name><name><surname>Urban</surname><given-names>LS</given-names></name><name><surname>Wohl</surname><given-names>MP</given-names></name><name><surname>Rust</surname><given-names>NC</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>Signals in inferotemporal and perirhinal cortex suggest an untangling of visual target information</article-title><source>Nature Neuroscience</source><volume>16</volume><fpage>1132</fpage><lpage>1139</lpage><pub-id pub-id-type="doi">10.1038/nn.3433</pub-id><pub-id pub-id-type="pmid">23792943</pub-id></element-citation></ref><ref id="bib42"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Pandarinath</surname><given-names>C</given-names></name><name><surname>O’Shea</surname><given-names>DJ</given-names></name><name><surname>Collins</surname><given-names>J</given-names></name><name><surname>Jozefowicz</surname><given-names>R</given-names></name><name><surname>Stavisky</surname><given-names>SD</given-names></name><name><surname>Kao</surname><given-names>JC</given-names></name><name><surname>Trautmann</surname><given-names>EM</given-names></name><name><surname>Kaufman</surname><given-names>MT</given-names></name><name><surname>Ryu</surname><given-names>SI</given-names></name><name><surname>Hochberg</surname><given-names>LR</given-names></name><name><surname>Henderson</surname><given-names>JM</given-names></name><name><surname>Shenoy</surname><given-names>KV</given-names></name><name><surname>Abbott</surname><given-names>LF</given-names></name><name><surname>Sussillo</surname><given-names>D</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>Inferring single-trial neural population dynamics using sequential auto-encoders</article-title><source>Nature Methods</source><volume>15</volume><fpage>805</fpage><lpage>815</lpage><pub-id pub-id-type="doi">10.1038/s41592-018-0109-9</pub-id><pub-id pub-id-type="pmid">30224673</pub-id></element-citation></ref><ref id="bib43"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Pitkow</surname><given-names>X</given-names></name><name><surname>Liu</surname><given-names>S</given-names></name><name><surname>Angelaki</surname><given-names>DE</given-names></name><name><surname>DeAngelis</surname><given-names>GC</given-names></name><name><surname>Pouget</surname><given-names>A</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>How can single sensory neurons predict behavior?</article-title><source>Neuron</source><volume>87</volume><fpage>411</fpage><lpage>423</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2015.06.033</pub-id><pub-id pub-id-type="pmid">26182422</pub-id></element-citation></ref><ref id="bib44"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Rigotti</surname><given-names>M</given-names></name><name><surname>Barak</surname><given-names>O</given-names></name><name><surname>Warden</surname><given-names>MR</given-names></name><name><surname>Wang</surname><given-names>X-J</given-names></name><name><surname>Daw</surname><given-names>ND</given-names></name><name><surname>Miller</surname><given-names>EK</given-names></name><name><surname>Fusi</surname><given-names>S</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>The importance of mixed selectivity in complex cognitive tasks</article-title><source>Nature</source><volume>497</volume><fpage>585</fpage><lpage>590</lpage><pub-id pub-id-type="doi">10.1038/nature12160</pub-id><pub-id pub-id-type="pmid">23685452</pub-id></element-citation></ref><ref id="bib45"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Rouse</surname><given-names>AG</given-names></name><name><surname>Schieber</surname><given-names>MH</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>Condition-dependent neural dimensions progressively shift during reach to grasp</article-title><source>Cell Reports</source><volume>25</volume><fpage>3158</fpage><lpage>3168</lpage><pub-id pub-id-type="doi">10.1016/j.celrep.2018.11.057</pub-id><pub-id pub-id-type="pmid">30540947</pub-id></element-citation></ref><ref id="bib46"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Sadtler</surname><given-names>PT</given-names></name><name><surname>Quick</surname><given-names>KM</given-names></name><name><surname>Golub</surname><given-names>MD</given-names></name><name><surname>Chase</surname><given-names>SM</given-names></name><name><surname>Ryu</surname><given-names>SI</given-names></name><name><surname>Tyler-Kabara</surname><given-names>EC</given-names></name><name><surname>Yu</surname><given-names>BM</given-names></name><name><surname>Batista</surname><given-names>AP</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>Neural constraints on learning</article-title><source>Nature</source><volume>512</volume><fpage>423</fpage><lpage>426</lpage><pub-id pub-id-type="doi">10.1038/nature13665</pub-id><pub-id pub-id-type="pmid">25164754</pub-id></element-citation></ref><ref id="bib47"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Sani</surname><given-names>OG</given-names></name><name><surname>Abbaspourazad</surname><given-names>H</given-names></name><name><surname>Wong</surname><given-names>YT</given-names></name><name><surname>Pesaran</surname><given-names>B</given-names></name><name><surname>Shanechi</surname><given-names>MM</given-names></name></person-group><year iso-8601-date="2021">2021</year><article-title>Modeling behaviorally relevant neural dynamics enabled by preferential subspace identification</article-title><source>Nature Neuroscience</source><volume>24</volume><fpage>140</fpage><lpage>149</lpage><pub-id pub-id-type="doi">10.1038/s41593-020-00733-0</pub-id></element-citation></ref><ref id="bib48"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Saxena</surname><given-names>S</given-names></name><name><surname>Cunningham</surname><given-names>JP</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>Towards the neural population doctrine</article-title><source>Current Opinion in Neurobiology</source><volume>55</volume><fpage>103</fpage><lpage>111</lpage><pub-id pub-id-type="doi">10.1016/j.conb.2019.02.002</pub-id></element-citation></ref><ref id="bib49"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Schneider</surname><given-names>DM</given-names></name><name><surname>Sundararajan</surname><given-names>J</given-names></name><name><surname>Mooney</surname><given-names>R</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>A cortical filter that learns to suppress the acoustic consequences of movement</article-title><source>Nature</source><volume>561</volume><fpage>391</fpage><lpage>395</lpage><pub-id pub-id-type="doi">10.1038/s41586-018-0520-5</pub-id><pub-id pub-id-type="pmid">30209396</pub-id></element-citation></ref><ref id="bib50"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Schneider</surname><given-names>S</given-names></name><name><surname>Lee</surname><given-names>JH</given-names></name><name><surname>Mathis</surname><given-names>MW</given-names></name></person-group><year iso-8601-date="2023">2023</year><article-title>Learnable latent embeddings for joint behavioural and neural analysis</article-title><source>Nature</source><volume>617</volume><fpage>360</fpage><lpage>368</lpage><pub-id pub-id-type="doi">10.1038/s41586-023-06031-6</pub-id><pub-id pub-id-type="pmid">37138088</pub-id></element-citation></ref><ref id="bib51"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Sreenivasan</surname><given-names>S</given-names></name><name><surname>Fiete</surname><given-names>I</given-names></name></person-group><year iso-8601-date="2011">2011</year><article-title>Grid cells generate an analog error-correcting code for singularly precise neural computation</article-title><source>Nature Neuroscience</source><volume>14</volume><fpage>1330</fpage><lpage>1337</lpage><pub-id pub-id-type="doi">10.1038/nn.2901</pub-id></element-citation></ref><ref id="bib52"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Sun</surname><given-names>G</given-names></name><name><surname>Zeng</surname><given-names>F</given-names></name><name><surname>McCartin</surname><given-names>M</given-names></name><name><surname>Zhang</surname><given-names>Q</given-names></name><name><surname>Xu</surname><given-names>H</given-names></name><name><surname>Liu</surname><given-names>Y</given-names></name><name><surname>Chen</surname><given-names>ZS</given-names></name><name><surname>Wang</surname><given-names>J</given-names></name></person-group><year iso-8601-date="2022">2022</year><article-title>Closed-loop stimulation using a multiregion brain-machine interface has analgesic effects in rodents</article-title><source>Science Translational Medicine</source><volume>14</volume><elocation-id>eabm5868</elocation-id><pub-id pub-id-type="doi">10.1126/scitranslmed.abm5868</pub-id><pub-id pub-id-type="pmid">35767651</pub-id></element-citation></ref><ref id="bib53"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Walker</surname><given-names>EY</given-names></name><name><surname>Cotton</surname><given-names>RJ</given-names></name><name><surname>Ma</surname><given-names>WJ</given-names></name><name><surname>Tolias</surname><given-names>AS</given-names></name></person-group><year iso-8601-date="2020">2020</year><article-title>A neural basis of probabilistic computation in visual cortex</article-title><source>Nature Neuroscience</source><volume>23</volume><fpage>122</fpage><lpage>129</lpage><pub-id pub-id-type="doi">10.1038/s41593-019-0554-5</pub-id></element-citation></ref><ref id="bib54"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wang</surname><given-names>F</given-names></name><name><surname>Wang</surname><given-names>Y</given-names></name><name><surname>Xu</surname><given-names>K</given-names></name><name><surname>Li</surname><given-names>H</given-names></name><name><surname>Liao</surname><given-names>Y</given-names></name><name><surname>Zhang</surname><given-names>Q</given-names></name><name><surname>Zhang</surname><given-names>S</given-names></name><name><surname>Zheng</surname><given-names>X</given-names></name><name><surname>Principe</surname><given-names>JC</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>Quantized attention-gated kernel reinforcement learning for brain-machine interface decoding</article-title><source>IEEE Transactions on Neural Networks and Learning Systems</source><volume>28</volume><fpage>873</fpage><lpage>886</lpage><pub-id pub-id-type="doi">10.1109/TNNLS.2015.2493079</pub-id><pub-id pub-id-type="pmid">26625423</pub-id></element-citation></ref><ref id="bib55"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Willsey</surname><given-names>MS</given-names></name><name><surname>Nason-Tomaszewski</surname><given-names>SR</given-names></name><name><surname>Ensel</surname><given-names>SR</given-names></name><name><surname>Temmar</surname><given-names>H</given-names></name><name><surname>Mender</surname><given-names>MJ</given-names></name><name><surname>Costello</surname><given-names>JT</given-names></name><name><surname>Patil</surname><given-names>PG</given-names></name><name><surname>Chestek</surname><given-names>CA</given-names></name></person-group><year iso-8601-date="2022">2022</year><article-title>Real-time brain-machine interface in non-human primates achieves high-velocity prosthetic finger movements using a shallow feedforward neural network decoder</article-title><source>Nature Communications</source><volume>13</volume><elocation-id>6899</elocation-id><pub-id pub-id-type="doi">10.1038/s41467-022-34452-w</pub-id><pub-id pub-id-type="pmid">36371498</pub-id></element-citation></ref><ref id="bib56"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wodlinger</surname><given-names>B</given-names></name><name><surname>Downey</surname><given-names>JE</given-names></name><name><surname>Tyler-Kabara</surname><given-names>EC</given-names></name><name><surname>Schwartz</surname><given-names>AB</given-names></name><name><surname>Boninger</surname><given-names>ML</given-names></name><name><surname>Collinger</surname><given-names>JL</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>Ten-dimensional anthropomorphic arm control in a human brain-machine interface: difficulties, solutions, and limitations</article-title><source>Journal of Neural Engineering</source><volume>12</volume><elocation-id>016011</elocation-id><pub-id pub-id-type="doi">10.1088/1741-2560/12/1/016011</pub-id><pub-id pub-id-type="pmid">25514320</pub-id></element-citation></ref><ref id="bib57"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Yan</surname><given-names>Y</given-names></name><name><surname>Goodman</surname><given-names>JM</given-names></name><name><surname>Moore</surname><given-names>DD</given-names></name><name><surname>Solla</surname><given-names>SA</given-names></name><name><surname>Bensmaia</surname><given-names>SJ</given-names></name></person-group><year iso-8601-date="2020">2020</year><article-title>Unexpected complexity of everyday manual behaviors</article-title><source>Nature Communications</source><volume>11</volume><elocation-id>3564</elocation-id><pub-id pub-id-type="doi">10.1038/s41467-020-17404-0</pub-id><pub-id pub-id-type="pmid">32678102</pub-id></element-citation></ref><ref id="bib58"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Yang</surname><given-names>Q</given-names></name><name><surname>Walker</surname><given-names>E</given-names></name><name><surname>Cotton</surname><given-names>RJ</given-names></name><name><surname>Tolias</surname><given-names>AS</given-names></name><name><surname>Pitkow</surname><given-names>X</given-names></name></person-group><year iso-8601-date="2021">2021</year><article-title>Revealing nonlinear neural decoding by analyzing choices</article-title><source>Nature Communications</source><volume>12</volume><elocation-id>6557</elocation-id><pub-id pub-id-type="doi">10.1038/s41467-021-26793-9</pub-id><pub-id pub-id-type="pmid">34785652</pub-id></element-citation></ref><ref id="bib59"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Yatsenko</surname><given-names>D</given-names></name><name><surname>Josić</surname><given-names>K</given-names></name><name><surname>Ecker</surname><given-names>AS</given-names></name><name><surname>Froudarakis</surname><given-names>E</given-names></name><name><surname>Cotton</surname><given-names>RJ</given-names></name><name><surname>Tolias</surname><given-names>AS</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>Improved estimation and interpretation of correlations in neural circuits</article-title><source>PLOS Computational Biology</source><volume>11</volume><elocation-id>e1004083</elocation-id><pub-id pub-id-type="doi">10.1371/journal.pcbi.1004083</pub-id><pub-id pub-id-type="pmid">25826696</pub-id></element-citation></ref><ref id="bib60"><element-citation publication-type="confproc"><person-group person-group-type="author"><name><surname>Yu</surname><given-names>BM</given-names></name></person-group><year iso-8601-date="2008">2008</year><article-title>Gaussian-process factor analysis for low-dimensional single-trial analysis of neural population activity</article-title><conf-name>Advances in Neural Information Processing Systems</conf-name></element-citation></ref><ref id="bib61"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Zhang</surname><given-names>J</given-names></name><name><surname>Hughes</surname><given-names>RN</given-names></name><name><surname>Kim</surname><given-names>N</given-names></name><name><surname>Fallon</surname><given-names>IP</given-names></name><name><surname>Bakhurin</surname><given-names>K</given-names></name><name><surname>Kim</surname><given-names>J</given-names></name><name><surname>Severino</surname><given-names>FPU</given-names></name><name><surname>Yin</surname><given-names>HH</given-names></name></person-group><year iso-8601-date="2023">2023</year><article-title>A one-photon endoscope for simultaneous patterned optogenetic stimulation and calcium imaging in freely behaving mice</article-title><source>Nature Biomedical Engineering</source><volume>7</volume><fpage>499</fpage><lpage>510</lpage><pub-id pub-id-type="doi">10.1038/s41551-022-00920-3</pub-id><pub-id pub-id-type="pmid">35970930</pub-id></element-citation></ref><ref id="bib62"><element-citation publication-type="confproc"><person-group person-group-type="author"><name><surname>Zhou</surname><given-names>D</given-names></name></person-group><year iso-8601-date="2020">2020</year><article-title>Learning identifiable and interpretable latent models of high-dimensional neural activity using pi-vae</article-title><conf-name>Advances in Neural Information Processing Systems</conf-name><fpage>7234</fpage><lpage>7247</lpage></element-citation></ref></ref-list></back><sub-article article-type="editor-report" id="sa0"><front-stub><article-id pub-id-type="doi">10.7554/eLife.87881.4.sa0</article-id><title-group><article-title>eLife assessment</article-title></title-group><contrib-group><contrib contrib-type="author"><name><surname>Gallego</surname><given-names>Juan Alvaro</given-names></name><role specific-use="editor">Reviewing Editor</role><aff><institution>Imperial College London</institution><country>United Kingdom</country></aff></contrib></contrib-group><kwd-group kwd-group-type="evidence-strength"><kwd>Incomplete</kwd></kwd-group><kwd-group kwd-group-type="claim-importance"><kwd>Useful</kwd></kwd-group></front-stub><body><p>This study presents a <bold>useful</bold> method for the extraction of behaviour-related activity from neural population recordings based on a specific deep learning architecture, a variational autoencoder. Although the authors performed thorough benchmarking of their method in the context of decoding behavioural variables, the evidence supporting claims about encoding is <bold>incomplete</bold> as the results may stem, in part, from the properties of the method itself.</p></body></sub-article><sub-article article-type="referee-report" id="sa1"><front-stub><article-id pub-id-type="doi">10.7554/eLife.87881.4.sa1</article-id><title-group><article-title>Reviewer #1 (Public Review):</article-title></title-group><contrib-group><contrib contrib-type="author"><anonymous/><role specific-use="referee">Reviewer</role></contrib></contrib-group></front-stub><body><p>This work seeks to understand how behaviour-related information is represented in the neural activity of the primate motor cortex. To this end, a statistical model of neural activity is presented that enables a non-linear separation of behaviour-related from unrelated activity. As a generative model, it enables the separate analysis of these two activity modes, here primarily done by assessing the decoding performance of hand movements the monkeys perform in the experiments. Several lines of analysis are presented to show that while the neurons with significant tuning to movements strongly contribute to the behaviourally-relevant activity subspace, less or un-tuned neurons also carry decodable information. It is further shown that the discovered subspaces enable linear decoding, leading the authors to conclude that motor cortex read-out can be linear.</p><p>Strengths:</p><p>In my opinion, using an expressive generative model to analyse neural state spaces is an interesting approach to understand neural population coding. While potentially sacrificing interpretability, this approach allows capturing both redundancies and synergies in the code as done in this paper. The model presented here is a natural non-linear extension of a previous linear model (PSID) and uses weak supervision in a manner similar to a previous non-linear model (TNDM).</p><p>Weaknesses:</p><p>This revised version provides additional evidence to support the author's claims regarding model performance and interpretation of the structure of the resulting latent spaces, in particular the distributed neural code over the whole recorded population, not just the well-tuned neurons. The improved ability to linearly decode behaviour from the relevant subspace and the analysis of the linear subspace projections in my opinion convincingly demonstrates that the model picks up behaviour-relevant dynamics, and that these are distributed widely across the population. As reviewer 3 also points out, I would, however, caution to interpret this as evidence for linear read-out of the motor system - your model performs a non-linear transformation, and while this is indeed linearly decodable, the motor system would need to do something similar first to achieve the same. In fact to me it seems to show the opposite, that behaviour-related information may not be generally accessible to linear decoders (including to down-stream brain areas).</p><p>As in my initial review, I would also caution against making strong claims about identifiability although this work and TNDM seem to show that in practise such methods work quite well. CEBRA, in contrast, offers some theoretical guarantees, but it is not a generative model, so would not allow the type of analysis done in this paper. In your model there is a para,eter \alpha to balance between neural and behaviour reconstruction. This seems very similar to TNDM and has to be optimised - if this is correct, then there is manual intervention required to identify a good model.</p><p>Somewhat related, I also found that the now comprehensive comparison with related models shows that the using decoding performance (R2) as a metric for model comparison may be problematic: the R2 values reported in Figure 2 (e.g. the MC_RTT dataset) should be compared to the values reported in the neural latent benchmark, which represent well-tuned models (e.g. AutoLFADS). The numbers (difficult to see, a table with numbers in the appendix would be useful, see: https://eval.ai/web/challenges/challenge-page/1256/leaderboard) seem lower than what can be obtained with models without latent space disentanglement. While this does not necessarily invalidate the conclusions drawn here, it shows that decoding performance can depend on a variety of model choices, and may not be ideal to discriminate between models. I'm also surprised by the low neural R2 for LFADS I assume this is condition-averaged - LFADS tends to perform very well on this metric.</p><p>One statement I still cannot follow is how the prior of the variational distribution is modelled. You say you depart from the usual Gaussian prior, but equation 7 seems to suggest there is a normal prior. Are the parameters of this distribution learned? As I pointed out earlier, I however suspect this may not matter much as you give the prior a very low weight. I also still am not sure how you generate a sample from the variational distribution, do you just draw one for each pass?</p><p>Summary:</p><p>This paper presents a very interesting analysis, but some concerns remain that mainly stem from the complexity of deep learning models. It would be good to acknowledge these as readers without relevant background need to understand where the possible caveats are.</p></body></sub-article><sub-article article-type="referee-report" id="sa2"><front-stub><article-id pub-id-type="doi">10.7554/eLife.87881.4.sa2</article-id><title-group><article-title>Reviewer #2 (Public Review):</article-title></title-group><contrib-group><contrib contrib-type="author"><anonymous/><role specific-use="referee">Reviewer</role></contrib></contrib-group></front-stub><body><p>Li et al present a method to extract &quot;behaviorally relevant&quot; signals from neural activity. The method is meant to solve a problem which likely has high utility for neuroscience researchers. There are numerous existing methods to achieve this goal some of which the authors compare their method to-thankfully, the revised version includes one of the major previous omissions (TNDM). However, I still believe that d-VAE is a promising approach that has its own advantages. Still, I have issues with the paper as-is. The authors have made relatively few modifications to the text based on my previous comments, and the responses have largely just dismissed my feedback and restated claims from the paper. Nearly all of my previous comments remain relevant for this revised manuscript. As such, they have done little to assuage my concerns, the most important of which I will restate here using the labels/notation (Q1, Q2, etc) from the reviewer response.</p><p>(Q1) I still remain unconvinced that the core findings of the paper are &quot;unexpected&quot;. In the response to my previous Specific Comment #1, they say &quot;We use the term 'unexpected' due to the disparity between our findings and the prior understanding concerning neural encoding and decoding.&quot; However, they provide no citations or grounding for why they make those claims. What prior understanding makes it unexpected that encoding is more complex than decoding given the entropy, sparseness, and high dimensionality of neural signals (the &quot;encoding&quot;) compared to the smoothness and low dimensionality of typical behavioural signals (the &quot;decoding&quot;)?</p><p>(Q2) I still take issue with the premise that signals in the brain are &quot;irrelevant&quot; simply because they do not correlate with a fixed temporal lag with a particular behavioural feature hand-chosen by the experimenter. In the response to my previous review, the authors say &quot;we employ terms like 'behaviorally-relevant' and 'behaviorally-irrelevant' only regarding behavioral variables of interest measured within a given task, such as arm kinematics during a motor control task.&quot;. This is just a restatement of their definition, not a response to my concern, and does not address my concern that the method requires a fixed temporal lag and continual decoding/encoding. My example of reward signals remains. There is a huge body of literature dating back to the 70s on the linear relationships between neural and activity and arm kinematics; in a sense, the authors have chosen the &quot;variable of interest&quot; that proves their point. This all ties back to the previous comment: this is mostly expected, not unexpected, when relating apparently-stochastic, discrete action potential events to smoothly varying limb kinematics.</p><p>(Q5) The authors seem to have missed the spirit of my critique: to say &quot;linear readout is performed in motor cortex&quot; is an over-interpretation of what their model can show.</p><p>(Q7) Agreeing with my critique is not sufficient; please provide the data or simulations that provides the context for the reference in the fano factor. I believe my critique is still valid.</p><p>(Q8) Thank you for comparing to TNDM, it's a useful benchmark.</p></body></sub-article><sub-article article-type="referee-report" id="sa3"><front-stub><article-id pub-id-type="doi">10.7554/eLife.87881.4.sa3</article-id><title-group><article-title>Reviewer #4 (Public Review):</article-title></title-group><contrib-group><contrib contrib-type="author"><anonymous/><role specific-use="referee">Reviewer</role></contrib></contrib-group></front-stub><body><p>I am a new reviewer for this manuscript, which has been reviewed before. The authors provide a variational autoencoder that has three objectives in the loss: linear reconstruction of behavior from embeddings, reconstruction of neural data, and KL divergence term related to the variational model elements. They take the output of the VAE as the &quot;behaviorally relevant&quot; part of neural data and call the residual &quot;behaviorally irrelevant&quot;. Results aim to inspect the linear versus nonlinear behavior decoding using the original raw neural data versus the inferred behaviorally relevant and irrelevant parts of the signal.</p><p>Overall, studying neural computations that are behaviorally relevant or not is an important problem, which several previous studies have explored (for example PSID in (Sani et al. 2021), TNDM in (Hurwitz et al. 2021), TAME-GP in (Balzani et al. 2023), pi-VAE in (Zhou and Wei 2020), and dPCA in (Kobak et al. 2016), etc). However, this manuscript does not properly put their work in the context of such prior works. For example, the abstract states &quot;One solution is to accurately separate behaviorally-relevant and irrelevant signals, but this approach remains elusive&quot;, which is not the case given that these prior works have done that. The same is true for various claims in the main text, for example &quot;Furthermore, we found that the dimensionality of primary subspace of raw signals (26, 64, and 45 for datasets A, B, and C) is significantly higher than that of behaviorally-relevant signals (7, 13, and 9), indicating that using raw signals to estimate the neural dimensionality of behaviors leads to an overestimation&quot; (line 321). This finding was presented in (Sani et al. 2021) and (Hurwitz et al. 2021), which is not clarified here. This issue of putting the work in context has been brought up by other reviewers previously but seems to remain largely unaddressed. The introduction is inaccurate also in that it mixes up methods that were designed for separation of behaviorally relevant information with those that are unsupervised and do not aim to do so (e.g., LFADS). The introduction should be significantly revised to explicitly discuss prior models/works that specifically formulated this behavior separation and what these prior studies found, and how this study differs.</p><p>Beyond the above, some of the main claims/conclusions made by the manuscript are not properly supported by the analyses and results, which has also been brought up by other reviewers but not fully addressed. First, the analyses here do not support the linear readout from the motor cortex because (i) by construction, the VAE here is trained to have a linear readout from its embedding in its loss, which can bias its outputs toward doing well with a linear decoder/readout, and (ii) the overall mapping from neural data to behavior includes both the VAE and the linear readout and thus is always nonlinear (even when a linear Kalman filter is used for decoding). This claim is also vague as there is no definition of readout from &quot;motor cortex&quot; or what it means. Why is the readout from the bottleneck of this particular VAE the readout of motor cortex? Second, other claims about properties of individual neurons are also confounded because the VAE is a population-level model that extracts the bottleneck from all neurons. Thus, information can leak from any set of neurons to other sets of neurons during the inference of behaviorally relevant parts of signals. Overall, the results do not convincingly support the claims, and thus the claims should be carefully revised and significantly tempered to avoid misinterpretation by readers.</p><p>Below I briefly expand on these as well as other issues, and provide suggestions:</p><p>(1) Claims about linearity of &quot;motor cortex&quot; readout are not supported by results yet stated even in the abstract. Instead, what the results support is that for decoding behavior from the output of the dVAE model -- that is trained specifically to have a linear behavior readout from its embedding -- a nonlinear readout does not help. This result can be biased by the very construction of the dVAE's loss that encourages a linear readout/decoding from embeddings and thus does not imply a finding about motor cortex.</p><p>(2) Related to the above, it is unclear what the manuscript means by readout from motor cortex. A clearer definition of &quot;readout&quot; (a mapping from what to what?) in general is needed. The mapping that the linearity/nonlinearity claims refer to is from the *inferred* behaviorally relevant neural signals, which themselves are inferred nonlinearly using the VAE. This should be explicitly clarified in all claims, i.e., that only the mapping from distilled signals to behavior is linear, not the whole mapping from neural data to behavior. Again, to say the readout from motor cortex is linear is not supported, including in the abstract.</p><p>(3) Claims about individual neurons are also confounded. The d-VAE distilling processing is a population level embedding so the individual distilled neurons are not obtainable on their own without using the population data. This population level approach also raises the possibility that information can leak from one neuron to another during distillation, which is indeed what the authors hope would recover true information about individual neurons that wasn't there in the recording (the pixel denoising example). The authors acknowledge the possibility that information could leak to a neuron that didn't truly have that information and try to rule it out to some extent with some simulations and by comparing the distilled behaviorally relevant signals to the original neural signals. But ultimately, the distilled signals are different enough from the original signals to substantially improve decoding of low information neurons, and one cannot be sure if all of the information in distilled signals from any individual neuron truly belongs to that neuron. It is still quite likely that some of the improved behavior prediction of the distilled version of low-information neurons is due to leakage of behaviorally relevant information from other neurons, not the former's inherent behavioral information. This should be explicitly acknowledged in the manuscript.</p><p>(4) Given the nuances involved in appropriate comparisons across methods and since two of the datasets are public, the authors should provide their complete code (not just the dVAE method code), including the code for data loading, data preprocessing, model fitting and model evaluation for all methods and public datasets. This will alleviate concerns and allow readers to confirm conclusions (e.g., figure 2) for themselves down the line.</p><p>(5) Related to (1) above, the authors should explore the results if the affine network h(.) (from embedding to behavior) was replaced with a nonlinear ANN. Perhaps linear decoders would no longer be as close to nonlinear decoders. Regardless, the claim of linearity should be revised as described in (1) and (2) above, and all caveats should be discussed.</p><p>(6) The beginning of the section on the &quot;smaller R2 neurons&quot; should clearly define what R2 is being discussed. Based on the response to previous reviewers, this R2 &quot;signifies the proportion of neuronal activity variance explained by the linear encoding model, calculated using raw signals&quot;. This should be mentioned and made clear in the main text whenever this R2 is referred to.</p><p>(7) Various terms require clear definitions. The authors sometimes use vague terminology (e.g., &quot;useless&quot;) without a clear definition. Similarly, discussions regarding dimensionality could benefit from more precise definitions. How is neural dimensionality defined? For example, how is &quot;neural dimensionality of specific behaviors&quot; (line 590) defined? Related to this, I agree with Reviewer 2 that a clear definition of irrelevant should be mentioned that clarifies that relevance is roughly taken as &quot;correlated or predictive with a fixed time lag&quot;. The analyses do not explore relevance with arbitrary time lags between neural and behavior data.</p><p>(8) CEBRA itself doesn't provide a neural reconstruction from its embeddings, but one could obtain one via a regression from extracted CEBRA embeddings to neural data. In addition to decoding results of CEBRA (figure S3), the neural reconstruction of CEBRA should be computed and CEBRA should be added to Figure 2 to see how the behaviorally relevant and irrelevant signals from CEBRA compare to other methods.</p><p>References:</p><p>Kobak, Dmitry, Wieland Brendel, Christos Constantinidis, Claudia E Feierstein, Adam Kepecs, Zachary F Mainen, Xue-Lian Qi, Ranulfo Romo, Naoshige Uchida, and Christian K Machens. 2016. &quot;Demixed Principal Component Analysis of Neural Population Data.&quot; Edited by Mark CW van Rossum. eLife 5 (April): e10989. <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.7554/eLife.10989">https://doi.org/10.7554/eLife.10989</ext-link>.</p><p>Sani, Omid G., Hamidreza Abbaspourazad, Yan T. Wong, Bijan Pesaran, and Maryam M. Shanechi. 2021. &quot;Modeling Behaviorally Relevant Neural Dynamics Enabled by Preferential Subspace Identification.&quot; Nature Neuroscience 24 (1): 140-49. <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1038/s41593-020-00733-0">https://doi.org/10.1038/s41593-020-00733-0</ext-link>.</p><p>Zhou, Ding, and Xue-Xin Wei. 2020. &quot;Learning Identifiable and Interpretable Latent Models of High-Dimensional Neural Activity Using Pi-VAE.&quot; In Advances in Neural Information Processing Systems, 33:7234-47. Curran Associates, Inc <ext-link ext-link-type="uri" xlink:href="https://proceedings.neurips.cc/paper/2020/hash/510f2318f324cf07fce24c3a4b89c771-Abstract.html">https://proceedings.neurips.cc/paper/2020/hash/510f2318f324cf07fce24c3a4b89c771-Abstract.html</ext-link>.</p><p>Hurwitz, Cole, Akash Srivastava, Kai Xu, Justin Jude, Matthew Perich, Lee Miller, and Matthias Hennig. 2021. &quot;Targeted Neural Dynamical Modeling.&quot; In Advances in Neural Information Processing Systems. Vol. 34. <ext-link ext-link-type="uri" xlink:href="https://proceedings.neurips.cc/paper/2021/hash/f5cfbc876972bd0d031c8abc37344c28-Abstract.html">https://proceedings.neurips.cc/paper/2021/hash/f5cfbc876972bd0d031c8abc37344c28-Abstract.html</ext-link>.</p><p>Balzani, Edoardo, Jean-Paul G. Noel, Pedro Herrero-Vidal, Dora E. Angelaki, and Cristina Savin. 2023. &quot;A Probabilistic Framework for Task-Aligned Intra- and Inter-Area Neural Manifold Estimation.&quot; In . <ext-link ext-link-type="uri" xlink:href="https://openreview.net/forum?id=kt-dcBQcSA">https://openreview.net/forum?id=kt-dcBQcSA</ext-link>.</p></body></sub-article><sub-article article-type="author-comment" id="sa4"><front-stub><article-id pub-id-type="doi">10.7554/eLife.87881.4.sa4</article-id><title-group><article-title>Author response</article-title></title-group><contrib-group><contrib contrib-type="author"><name><surname>Li</surname><given-names>Yangang</given-names></name><role specific-use="author">Author</role><aff><institution>Zhejiang University</institution><addr-line><named-content content-type="city">Hangzhou</named-content></addr-line><country>China</country></aff></contrib><contrib contrib-type="author"><name><surname>Zhu</surname><given-names>Xinyun</given-names></name><role specific-use="author">Author</role><aff><institution>Zhejiang University</institution><addr-line><named-content content-type="city">Hangzhou</named-content></addr-line><country>China</country></aff></contrib><contrib contrib-type="author"><name><surname>Qi</surname><given-names>Yu</given-names></name><role specific-use="author">Author</role><aff><institution>Zhejiang University</institution><addr-line><named-content content-type="city">Hangzhou</named-content></addr-line><country>China</country></aff></contrib><contrib contrib-type="author"><name><surname>Wang</surname><given-names>Yueming</given-names></name><role specific-use="author">Author</role><aff><institution>Zhejiang University</institution><addr-line><named-content content-type="city">Hangzhou</named-content></addr-line><country>China</country></aff></contrib></contrib-group></front-stub><body><p>The following is the authors’ response to the previous reviews.</p><p>To the Senior Editor and the Reviewing Editor:</p><p>We sincerely appreciate the valuable comments provided by the reviewers, the reviewing editor, and the senior editor. Based on our last response and revision, we are confused by the two limitations noted in the eLife assessment.</p><p>(1) benchmarking against comparable methods is limited.</p><p>In our last revision, we added the comparison experiments with TNDM, as the reviewers requested. Additionally, it is crucial to emphasize that our evaluation of decoding capabilities of behaviorally relevant signals has been benchmarked against the performance of the ANN on raw signals, which, as Reviewer #1 previously noted, nearly represents the upper limit of performance. Consequently, we believe that our benchmarking methods are sufficiently strong.</p><p>(2) some observations may be a byproduct of their method, and may not constitute new scientific observations.</p><p>We believe that our experimental results are sufficient to demonstrate that our conclusions are not byproducts of d-VAE based on three reasons:</p><p>(1) The d-VAE, as a latent variable model, adheres to the population doctrine, which posits that latent variables are responsible for generating the activities of individual neurons. The goal of such models is to maximize the explanation of the raw signals. At the signal level, the only criterion we can rely on is neural reconstruction performance, in which we have achieved unparalleled results. Thus, it is inappropriate to focus on the mixing process during the model's inference stage while overlooking the crucial de-mixing process during the generation stage and dismissing the significance of our neural reconstruction results. For more details, please refer to the first point in our response to Q4 from Reviewer #4.</p><p>(2) The criterion that irrelevant signals should contain minimal information can effectively demonstrate that our conclusions are not by-products of d-VAE. Unfortunately, the reviewers seem to have overlooked this criterion. For more details, please refer to the third point in our response to Q4 from Reviewer #4</p><p>(3) Our synthetic experimental results also substantiate that our conclusions are not byproducts of d-VAE. However, it appears the reviewers did not give these results adequate consideration. For more details, please refer to the fourth point in our response to Q4 from Reviewer #4.</p><p>Furthermore, our work presents not just &quot;a useful method&quot; but a comprehensive framework. Our study proposes, for the first time, a framework for defining, extracting, and validating behaviorally relevant signals. In our current revision, to clearly distinguish between d-VAE and other methods, we have formalized the extraction of behaviorally relevant signals into a mathematical optimization problem. To our knowledge, current methods have not explicitly proposed extracting behaviorally relevant signals, nor have they identified and addressed the key challenges of extracting relevant signals. Similarly, existing research has not yet defined and validated behaviorally relevant signals. For more details, please refer to our response to Q1 from Reviewer #4.</p><p>Based on these considerations, we respectfully request that you reconsider the eLife assessment of our work. We greatly appreciate your time and attention to this matter.</p><p>The main revisions made to the manuscript are as follows:</p><p>(1) We have formalized the extraction of behaviorally relevant signals into a mathematical optimization problem, enabling a clearer distinction between d-VAE and other models.</p><p>(2) We have moderated the assertion about linear readout to highlight its conjectural nature and have broadened the discussion regarding this conclusion.</p><p>(3) We have elaborated on the model details of d-VAE and have removed the identifiability claim.</p><p>To Reviewer #1</p><disp-quote content-type="editor-comment"><p>Q1: “As reviewer 3 also points out, I would, however, caution to interpret this as evidence for linear read-out of the motor system - your model performs a non-linear transformation, and while this is indeed linearly decodable, the motor system would need to do something similar first to achieve the same. In fact to me it seems to show the opposite, that behaviour-related information may not be generally accessible to linear decoders (including to down-stream brain areas).”</p></disp-quote><p>Thank you for your comments. It's important to note that the conclusions we draw are speculative and not definitive. We use terms like &quot;suggest&quot; to reflect this uncertainty. To further emphasize the conjectural nature of our conclusions, we have deliberately moderated our tone.</p><p>The question of whether behaviorally-relevant signals can be accessed by linear decoders or downstream brain regions hinges on the debate over whether the brain employs a strategy of filtering before decoding. If the brain employs such a strategy, the brain can probably access these signals. In our opinion, it is likely that the brain utilizes this strategy.</p><p>Given the existence of behaviorally relevant signals, it is reasonable to assume that the brain has intrinsic mechanisms to differentiate between relevant and irrelevant signals. There is growing evidence suggesting that the brain utilizes various mechanisms, such as attention and specialized filtering, to suppress irrelevant signals and enhance relevant signals [1-3]. Therefore, it is plausible that the brain filters before decoding, thereby effectively accessing behaviorally relevant signals.</p><p>Thank you for your valuable feedback.</p><p>(1) Sreenivasan, Sameet, and Ila Fiete. &quot;Grid cells generate an analog error-correcting code for singularly precise neural computation.&quot; Nature neuroscience 14.10 (2011): 1330-1337.</p><p>(2) Schneider, David M., Janani Sundararajan, and Richard Mooney. &quot;A cortical filter that learns to suppress the acoustic consequences of movement.&quot; Nature 561.7723 (2018): 391-395.</p><p>(3) Nakajima, Miho, L. Ian Schmitt, and Michael M. Halassa. &quot;Prefrontal cortex regulates sensory filtering through a basal ganglia-to-thalamus pathway.&quot; Neuron 103.3 (2019): 445-458.</p><disp-quote content-type="editor-comment"><p>Q2: “As in my initial review, I would also caution against making strong claims about identifiability although this work and TNDM seem to show that in practise such methods work quite well. CEBRA, in contrast, offers some theoretical guarantees, but it is not a generative model, so would not allow the type of analysis done in this paper. In your model there is a para,eter \alpha to balance between neural and behaviour reconstruction. This seems very similar to TNDM and has to be optimised - if this is correct, then there is manual intervention required to identify a good model.”</p></disp-quote><p>Thank you for your comments.</p><p>Considering your concerns about our identifiability claims and the fact that identifiability is not directly relevant to the core of our paper, we have removed content related to identifiability.</p><p>Firstly, our model is based on the pi-VAE, which also has theoretical guarantees. However, it is important to note that all such theoretical guarantees (including pi-VAE and CEBRA) are based on certain assumptions that cannot be validated as the true distribution of latent variables remains unknown.</p><p>Secondly, it is important to clarify that the identifiability of latent variables does not impact the conclusions of this paper, nor does this paper make specific conclusions about the model's latent variables. Identifiability means that distinct latent variables correspond to distinct observations. If multiple latent variables can generate the same observation, it becomes impossible to determine which one is correct given the observation, which leads to the issue of nonidentifiability. Notably, our analysis focuses on the generated signals, not the latent variables themselves, and thus the identifiability of these variables does not affect our findings.</p><p>Our approach, dedicated to extracting these signals, distinctly differs from methods such as TNDM, which focuses on extracting behaviorally relevant latent dynamics. To clearly set apart d-VAE from other models, we have framed the extraction of behaviorally relevant signals as the following mathematical optimization problem:<disp-formula id="sa4equ1"><mml:math id="sa4m1"><mml:mrow><mml:munder><mml:mo movablelimits="true" form="prefix">min</mml:mo><mml:mrow><mml:msub><mml:mi>x</mml:mi><mml:mrow><mml:mi>r</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:munder><mml:mi>E</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="normal">x</mml:mi></mml:mrow><mml:mrow><mml:mrow><mml:mi mathvariant="normal">r</mml:mi></mml:mrow></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:mrow><mml:mi mathvariant="normal">x</mml:mi></mml:mrow></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>+</mml:mo><mml:mrow><mml:mi mathvariant="normal">R</mml:mi></mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:msub><mml:mrow><mml:mi mathvariant="normal">x</mml:mi></mml:mrow><mml:mrow><mml:mrow><mml:mi mathvariant="normal">r</mml:mi></mml:mrow></mml:mrow></mml:msub><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></disp-formula></p><p>where 𝑥# denotes generated behaviorally-relevant signals, 𝑥 denotes raw noisy signals, 𝐸(⋅,⋅) demotes reconstruction loss, and 𝑅(⋅) denotes regularization loss. It is important to note that while both d-VAE and TNDM employ reconstruction loss, relying solely on this term is insufficient for determining the optimal degree of similarity between the generated and raw noisy signals. The key to accurately extracting behaviorally relevant signals lies in leveraging prior knowledge about these signals to determine the optimal similarity degree, encapsulated by 𝑅(𝒙𝒓). Other studies have not explicitly proposed extracting behaviorally-relevant signals, nor have they identified and addressed the key challenges involved in extracting relevant signals. Consequently, our approach is distinct from other methods.</p><p>Thank you for your valuable feedback.</p><disp-quote content-type="editor-comment"><p>Q3: “Somewhat related, I also found that the now comprehensive comparison with related models shows that the using decoding performance (R2) as a metric for model comparison may be problematic: the R2 values reported in Figure 2 (e.g. the MC_RTT dataset) should be compared to the values reported in the neural latent benchmark, which represent well-tuned models (e.g. AutoLFADS). The numbers (difficult to see, a table with numbers in the appendix would be useful, see: https://eval.ai/web/challenges/challenge-page/1256/leaderboard) seem lower than what can be obtained with models without latent space disentanglement. While this does not necessarily invalidate the conclusions drawn here, it shows that decoding performance can depend on a variety of model choices, and may not be ideal to discriminate between models. I'm also surprised by the low neural R2 for LFADS I assume this is condition-averaged - LFADS tends to perform very well on this metric.”</p></disp-quote><p>Thank you for your comments. The dataset we utilized is not from the same day as the neural latent benchmark dataset. Notably, there is considerable variation in the length of trials within the RTT paradigm, and the dataset lacks explicit trial information, rendering trial-averaging unsuitable. Furthermore, behaviorally relevant signals are not static averages devoid of variability; even behavioral data exhibits variability. We computed the neural R2 using individual trials rather than condition-averaged responses.</p><p>Thank you for your valuable feedback.</p><disp-quote content-type="editor-comment"><p>Q4: “One statement I still cannot follow is how the prior of the variational distribution is modelled. You say you depart from the usual Gaussian prior, but equation 7 seems to suggest there is a normal prior. Are the parameters of this distribution learned? As I pointed out earlier, I however suspect this may not matter much as you give the prior a very low weight. I also still am not sure how you generate a sample from the variational distribution, do you just draw one for each pass?”</p></disp-quote><p>Thank you for your questions.</p><p>The conditional distribution of prior latent variables 𝑝%(𝒛|𝒚) is a Gaussian distribution, but the distribution of prior latent variables 𝑝(𝒛) is a mixture Gaussian distribution. The distribution of prior latent variables 𝑝(𝒛) is:<disp-formula id="sa4equ2"><mml:math id="sa4m2"><mml:mrow><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>p</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mi mathvariant="bold">z</mml:mi></mml:mrow><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mo>∫</mml:mo><mml:mrow><mml:mover><mml:mi>p</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi mathvariant="bold-italic">y</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:msub><mml:mi>p</mml:mi><mml:mrow><mml:mi>m</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mi mathvariant="bold">z</mml:mi></mml:mrow><mml:mo>∣</mml:mo><mml:mi mathvariant="bold-italic">y</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mrow><mml:mi mathvariant="normal">d</mml:mi></mml:mrow><mml:mi mathvariant="bold-italic">y</mml:mi><mml:mo>=</mml:mo><mml:munderover><mml:mo>∑</mml:mo><mml:mrow><mml:mi>j</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>N</mml:mi></mml:mrow></mml:munderover><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mfrac><mml:mn>1</mml:mn><mml:mi>N</mml:mi></mml:mfrac><mml:munderover><mml:mo>∑</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>N</mml:mi></mml:mrow></mml:munderover><mml:mi>δ</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msup><mml:mi mathvariant="bold-italic">y</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>j</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup><mml:mo>−</mml:mo><mml:msup><mml:mi mathvariant="bold-italic">y</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>i</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:msub><mml:mi>p</mml:mi><mml:mrow><mml:mi>m</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mrow><mml:mi mathvariant="bold">z</mml:mi></mml:mrow><mml:mo>∣</mml:mo><mml:msup><mml:mi mathvariant="bold-italic">y</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>j</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mstyle></mml:mrow></mml:math></disp-formula></p><p>where <inline-formula><mml:math id="sa4m3"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mrow><mml:mover><mml:mi>p</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi mathvariant="bold-italic">y</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mrow><mml:mtext> </mml:mtext><mml:mi mathvariant="normal">N</mml:mi></mml:mrow></mml:mfrac><mml:munderover><mml:mo>∑</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>N</mml:mi></mml:mrow></mml:munderover><mml:mi>δ</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi mathvariant="bold-italic">y</mml:mi><mml:mo>−</mml:mo><mml:msup><mml:mi mathvariant="bold-italic">y</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>i</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mstyle></mml:math></inline-formula> denotes the empirical distribution of behavioral variables</p><p>𝒚, and 𝑁 denotes the number of samples, 𝒚(𝒊) denotes the 𝒊th sample, δ(⋅) denotes the Dirac delta function, and 𝑝%(𝒛|𝒚) denotes the conditional distribution of prior latent variables given the behavioral variables parameterized by network 𝑚. Based on the above equation, we can see that 𝑝(𝒛) is not a Gaussian distribution, it is a Gaussian mixture model with 𝑁 components, which is theoretically a universal approximator of continuous probability densities.</p><p>Learning this prior is important, as illustrated by our latent variable visualizations, which are not a Gaussian distribution. Upon conducting hypothesis testing for both latent variables and behavioral variables, neither conforms to Gaussian distribution (Lilliefors test and Kolmogorov-Smirnov test). Consequently, imposing a constraint on the latent variables towards N(0,1) is expected to affect performance adversely.</p><p>Regarding sampling, during training process, we draw only one sample from the approximate posterior distribution <inline-formula><mml:math id="sa4m4"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>q</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msup><mml:mrow><mml:mi mathvariant="bold">z</mml:mi></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>i</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup><mml:mo>∣</mml:mo><mml:msup><mml:mi mathvariant="bold-italic">x</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>i</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mstyle></mml:math></inline-formula> . It is worth noting that drawing multiple samples or one sample for each pass does not affect the experimental results. After training, we can generate a sample from the prior by providing input behavioral data 𝒚(𝒊) and then generating corresponding samples via <inline-formula><mml:math id="sa4m5"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>p</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msup><mml:mrow><mml:mi mathvariant="bold">z</mml:mi></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>i</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup><mml:mo>∣</mml:mo><mml:msup><mml:mi mathvariant="bold-italic">y</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>i</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mstyle></mml:math></inline-formula> and <inline-formula><mml:math id="sa4m6"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>p</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msup><mml:mi mathvariant="bold-italic">x</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>i</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup><mml:mo>∣</mml:mo><mml:msup><mml:mrow><mml:mi mathvariant="bold">z</mml:mi></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>i</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mstyle></mml:math></inline-formula> . To extract behaviorally-relevant signals from raw signals, we use <inline-formula><mml:math id="sa4m7"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>q</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msup><mml:mi>z</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>i</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup><mml:mo>∣</mml:mo><mml:msup><mml:mi>x</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>i</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mstyle></mml:math></inline-formula> and <inline-formula><mml:math id="sa4m8"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>p</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msup><mml:mi>x</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>i</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup><mml:mo>∣</mml:mo><mml:msup><mml:mrow><mml:mi mathvariant="bold">z</mml:mi></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>i</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mstyle></mml:math></inline-formula> .</p><p>Thank you for your valuable feedback.</p><disp-quote content-type="editor-comment"><p>Q5: “(1) I found the figures good and useful, but the text is, in places, not easy to follow. I think the manuscript could be shortened somewhat, and in some places more concise focussed explanations would improve readability.</p><p>(2) I would not call the encoding &quot;complex non-linear&quot; - non-linear is a clear term, but complex can mean many things (e.g. is a quadratic function complex?) ”</p></disp-quote><p>Thank you for your recommendation. We have revised the manuscript for enhanced clarity. We call the encoding “complex nonlinear” because neurons encode information with varying degrees of nonlinearity, as illustrated in Fig. 3b, f, and Fig. S3b.</p><p>Thank you for your valuable feedback.</p><p>To Reviewer #2</p><disp-quote content-type="editor-comment"><p>Q1: “I still remain unconvinced that the core findings of the paper are &quot;unexpected&quot;. In the response to my previous Specific Comment #1, they say &quot;We use the term 'unexpected' due to the disparity between our findings and the prior understanding concerning neural encoding and decoding.&quot; However, they provide no citations or grounding for why they make those claims. What prior understanding makes it unexpected that encoding is more complex than decoding given the entropy, sparseness, and high dimensionality of neural signals (the &quot;encoding&quot;) compared to the smoothness and low dimensionality of typical behavioural signals (the &quot;decoding&quot;)?”</p></disp-quote><p>Thank you for your comments. We believe that both the complexity of neural encoding and the simplicity of neural decoding in motor cortex are unexpected.</p><p>The Complexity of Neural Encoding: As noted in the Introduction, neurons with small R2 values were traditionally considered noise and consequently disregarded, as detailed in references [1-3]. However, after filtering out irrelevant signals, we discovered that these neurons actually contain substantial amounts of behavioral information, previously unrecognized. Similarly, in population-level analyses, neural signals composed of small principal components (PCs) are often dismissed as noise, with analyses typically utilizing only between 6 and 18 PCs [4-10]. Yet, the discarded PC signals nonlinearly encode significant amounts of information, with practically useful dimensions found to range between 30 and 40—far exceeding the usual number analyzed. These findings underscore the complexity of neural encoding and are unexpected.</p><p>The Simplicity of Neural Decoding: In the motor cortex, nonlinear decoding of raw signals has been shown to significantly outperform linear decoding, as evidenced in references [11,12]. Interestingly, after separating behaviorally relevant and irrelevant signals, we observed that the linear decoding performance of behaviorally relevant signals is nearly equivalent to that of nonlinear decoding—a phenomenon previously undocumented in the motor cortex. This discovery is also unexpected.</p><p>Thank you for your valuable feedback.</p><p>(1) Georgopoulos, Apostolos P., Andrew B. Schwartz, and Ronald E. Kettner. &quot;Neuronal population coding of movement direction.&quot; Science 233.4771 (1986): 1416-1419.</p><p>(2) Hochberg, Leigh R., et al. &quot;Reach and grasp by people with tetraplegia using a neurally controlled robotic arm.&quot; Nature 485.7398 (2012): 372-375.</p><p>(3) Inoue, Yoh, et al. &quot;Decoding arm speed during reaching.&quot; Nature communications 9.1 (2018): 5243.</p><p>(4) Churchland, Mark M., et al. &quot;Neural population dynamics during reaching.&quot; Nature 487.7405 (2012): 51-56.</p><p>(5) Kaufman, Matthew T., et al. &quot;Cortical activity in the null space: permitting preparation without movement.&quot; Nature neuroscience 17.3 (2014): 440-448.</p><p>(6) Elsayed, Gamaleldin F., et al. &quot;Reorganization between preparatory and movement population responses in motor cortex.&quot; Nature communications 7.1 (2016): 13239.</p><p>(7) Sadtler, Patrick T., et al. &quot;Neural constraints on learning.&quot; Nature 512.7515 (2014): 423426.</p><p>(8) Golub, Matthew D., et al. &quot;Learning by neural reassociation.&quot; Nature neuroscience 21.4 (2018): 607-616.</p><p>(9) Gallego, Juan A., et al. &quot;Cortical population activity within a preserved neural manifold underlies multiple motor behaviors.&quot; Nature communications 9.1 (2018): 4233.</p><p>(10) Gallego, Juan A., et al. &quot;Long-term stability of cortical population dynamics underlying consistent behavior.&quot; Nature neuroscience 23.2 (2020): 260-270.</p><p>(11) Glaser, Joshua I., et al. &quot;Machine learning for neural decoding.&quot; Eneuro 7.4 (2020).</p><p>(12) Willsey, Matthew S., et al. &quot;Real-time brain-machine interface in non-human primates achieves high-velocity prosthetic finger movements using a shallow feedforward neural network decoder.&quot; Nature Communications 13.1 (2022): 6899.</p><disp-quote content-type="editor-comment"><p>Q2: “I still take issue with the premise that signals in the brain are &quot;irrelevant&quot; simply because they do not correlate with a fixed temporal lag with a particular behavioural feature handchosen by the experimenter. In the response to my previous review, the authors say &quot;we employ terms like 'behaviorally-relevant' and 'behaviorally-irrelevant' only regarding behavioral variables of interest measured within a given task, such as arm kinematics during a motor control task.&quot;. This is just a restatement of their definition, not a response to my concern, and does not address my concern that the method requires a fixed temporal lag and continual decoding/encoding. My example of reward signals remains. There is a huge body of literature dating back to the 70s on the linear relationships between neural and activity and arm kinematics; in a sense, the authors have chosen the &quot;variable of interest&quot; that proves their point. This all ties back to the previous comment: this is mostly expected, not unexpected, when relating apparently-stochastic, discrete action potential events to smoothly varying limb kinematics.”</p></disp-quote><p>Thank you for your comments.</p><p>Regarding the experimenter's specification of behavioral variables of interest, we followed common practice in existing studies [1, 2]. Regarding the use of fixed temporal lags, we followed the same practice as papers related to the dataset we use, which assume fixed temporal lags [3-5]. Furthermore, many studies in the motor cortex similarly use fixed temporal lags [68].</p><p>Concerning the issue of rewards, in the paper you mentioned [9], the impact of rewards occurs after the reaching phase. It's important to note that in our experiments, we analyze only the reaching phase, without any post-movement phase.</p><p>If the impact of rewards can be stably reflected in the signals in the reaching phase of the subsequent trial, and if the reward-induced signals do not interfere with decoding—since these signals are harmless for decoding and beneficial for reconstruction—our model is likely to capture these signals. If the signals induced by rewards during the reaching phase are randomly unstable, our model will likely be unable to capture them.</p><p>If the goal is to extract post-movement neural activity from both rewarded and unrewarded trials, and if the neural patterns differ between these conditions, one could replace the d-VAE's regression loss, used for continuous kinematics decoding, with a classification loss tailored to distinguish between rewarded and unrewarded conditions.</p><p>To clarify the definition, we have revised it in the manuscript. Specifically, before a specific definition, we briefly introduce the relevant signals and irrelevant signals. Behaviorally irrelevant signals refer to those not directly associated with the behavioral variables of interest and may include noise or signals from variables of no interest. In contrast, behaviorally relevant signals refer to those directly related to the behavioral variables of interest. For instance, rewards in the post-movement phase are not directly related to behavioral variables (kinematics) in the reaching movement phase.</p><p>It is important to note that our definition of behaviorally relevant signals not only includes decoding capabilities but also specific requirement at the signal level, based on two key requirements:</p><p>(1) they should closely resemble raw signals to preserve the underlying neuronal properties without becoming so similar that they include irrelevant signals. (encoding requirement), and (2) they should contain behavioral information as much as possible (decoding requirement). Signals that meet both requirements are considered effective behaviorally relevant signals. In our study, we assume raw signals are additively composed of behaviorally-relevant and irrelevant signals. We define irrelevant signals as those remaining after subtracting relevant signals from raw signals. Therefore, we believe our definition is clearly articulated.</p><p>Thank you for your valuable feedback.</p><p>(1) Sani, Omid G., et al. &quot;Modeling behaviorally relevant neural dynamics enabled by preferential subspace identification.&quot; Nature Neuroscience 24.1 (2021): 140-149.</p><p>(2) Buetfering, Christina, et al. &quot;Behaviorally relevant decision coding in primary somatosensory cortex neurons.&quot; Nature neuroscience 25.9 (2022): 1225-1236.</p><p>(3) Wang, Fang, et al. &quot;Quantized attention-gated kernel reinforcement learning for brain– machine interface decoding.&quot; IEEE transactions on neural networks and learning systems 28.4 (2015): 873-886.</p><p>(4) Dyer, Eva L., et al. &quot;A cryptography-based approach for movement decoding.&quot; Nature biomedical engineering 1.12 (2017): 967-976.</p><p>(5) Ahmadi, Nur, Timothy G. Constandinou, and Christos-Savvas Bouganis. &quot;Robust and accurate decoding of hand kinematics from entire spiking activity using deep learning.&quot; Journal of Neural Engineering 18.2 (2021): 026011.</p><p>(6) Churchland, Mark M., et al. &quot;Neural population dynamics during reaching.&quot; Nature 487.7405 (2012): 51-56.</p><p>(7) Kaufman, Matthew T., et al. &quot;Cortical activity in the null space: permitting preparation without movement.&quot; Nature neuroscience 17.3 (2014): 440-448.</p><p>(8) Elsayed, Gamaleldin F., et al. &quot;Reorganization between preparatory and movement population responses in motor cortex.&quot; Nature communications 7.1 (2016): 13239.</p><p>(9) Ramkumar, Pavan, et al. &quot;Premotor and motor cortices encode reward.&quot; PloS one 11.8 (2016): e0160851.</p><disp-quote content-type="editor-comment"><p>Q3: “The authors seem to have missed the spirit of my critique: to say &quot;linear readout is performed in motor cortex&quot; is an over-interpretation of what their model can show.”</p></disp-quote><p>Thank you for your comments. It's important to note that the conclusions we draw are speculative and not definitive. We use terms like &quot;suggest&quot; to reflect this uncertainty. To further emphasize the conjectural nature of our conclusions, we have deliberately moderated our tone.</p><p>The question of whether behaviorally-relevant signals can be accessed by downstream brain regions hinges on the debate over whether the brain employs a strategy of filtering before decoding. If the brain employs such a strategy, the brain can probably access these signals. In our view, it is likely that the brain utilizes this strategy.</p><p>Given the existence of behaviorally relevant signals, it is reasonable to assume that the brain has intrinsic mechanisms to differentiate between relevant and irrelevant signals. There is growing evidence suggesting that the brain utilizes various mechanisms, such as attention and specialized filtering, to suppress irrelevant signals and enhance relevant signals [1-3]. Therefore, it is plausible that the brain filters before decoding, thereby effectively accessing behaviorally relevant signals.</p><p>Regarding the question of whether the brain employs linear readout, given the limitations of current observational methods and our incomplete understanding of brain mechanisms, it is challenging to ascertain whether the brain employs a linear readout. In many cortical areas, linear decoders have proven to be sufficiently accurate. Consequently, numerous studies [4, 5, 6], including the one you referenced [4], directly employ linear decoders to extract information and formulate conclusions based on the decoding results. Contrary to these approaches, our research has compared the performance of linear and nonlinear decoders on behaviorally relevant signals and found their decoding performance is comparable. Considering both the decoding accuracy and model complexity, our results suggest that the motor cortex may utilize linear readout to decode information from relevant signals. Given the current technological limitations, we consider it reasonable to analyze collected data to speculate on the potential workings of the brain, an approach that many studies have also embraced [7-10]. For instance, a study [7] deduces strategies the brain might employ to overcome noise by analyzing the structure of recorded data and decoding outcomes for new stimuli.</p><p>Thank you for your valuable feedback.</p><p>(1) Sreenivasan, Sameet, and Ila Fiete. &quot;Grid cells generate an analog error-correcting code for singularly precise neural computation.&quot; Nature neuroscience 14.10 (2011): 1330-1337.</p><p>(2) Schneider, David M., Janani Sundararajan, and Richard Mooney. &quot;A cortical filter that learns to suppress the acoustic consequences of movement.&quot; Nature 561.7723 (2018): 391-395.</p><p>(3) Nakajima, Miho, L. Ian Schmitt, and Michael M. Halassa. &quot;Prefrontal cortex regulates sensory filtering through a basal ganglia-to-thalamus pathway.&quot; Neuron 103.3 (2019): 445-458.</p><p>(4) Jurewicz, Katarzyna, et al. &quot;Irrational choices via a curvilinear representational geometry for value.&quot; bioRxiv (2022): 2022-03.</p><p>(5) Hong, Ha, et al. &quot;Explicit information for category-orthogonal object properties increases along the ventral stream.&quot; Nature neuroscience 19.4 (2016): 613-622.</p><p>(6) Chang, Le, and Doris Y. Tsao. &quot;The code for facial identity in the primate brain.&quot; Cell 169.6 (2017): 1013-1028.</p><p>(7) Ganmor, Elad, Ronen Segev, and Elad Schneidman. &quot;A thesaurus for a neural population code.&quot; Elife 4 (2015): e06134.</p><p>(8) Churchland, Mark M., et al. &quot;Neural population dynamics during reaching.&quot; Nature 487.7405 (2012): 51-56.</p><p>(9) Gallego, Juan A., et al. &quot;Cortical population activity within a preserved neural manifold underlies multiple motor behaviors.&quot; Nature communications 9.1 (2018): 4233.</p><p>(10) Gallego, Juan A., et al. &quot;Long-term stability of cortical population dynamics underlying consistent behavior.&quot; Nature neuroscience 23.2 (2020): 260-270.</p><disp-quote content-type="editor-comment"><p>Q4: “Agreeing with my critique is not sufficient; please provide the data or simulations that provides the context for the reference in the fano factor. I believe my critique is still valid.”</p></disp-quote><p>Thank you for your comments. As we previously replied, Churchland's research examines the variability of neural signals across different stages, including the preparation and execution phases, as well as before and after the target appears. Our study, however, focuses exclusively on the movement execution phase. Consequently, we are unable to produce comparative displays similar to those in his research. Intuitively, one might expect that the variability of behaviorally relevant signals would be lower; however, since no prior studies have accurately extracted such signals, the specific FF values of behaviorally relevant signals remain unknown. Therefore, presenting these values is meaningful, and can provide a reference for future research. While we cannot compare FF across different stages, we can numerically compare the values to the Poisson count process. An FF of 1 indicates a Poisson firing process, and our experimental data reveals that most neurons have an FF less than 1, indicating that the variance in firing counts is below the mean. Thank you for your valuable feedback.</p><p>To Reviewer #4</p><disp-quote content-type="editor-comment"><p>Q1: “Overall, studying neural computations that are behaviorally relevant or not is an important problem, which several previous studies have explored (for example PSID in (Sani et al. 2021), TNDM in (Hurwitz et al. 2021), TAME-GP in (Balzani et al. 2023), pi-VAE in (Zhou and Wei 2020), and dPCA in (Kobak et al. 2016), etc). However, this manuscript does not properly put their work in the context of such prior works. For example, the abstract states &quot;One solution is to accurately separate behaviorally-relevant and irrelevant signals, but this approach remains elusive&quot;, which is not the case given that these prior works have done that. The same is true for various claims in the main text, for example &quot;Furthermore, we found that the dimensionality of primary subspace of raw signals (26, 64, and 45 for datasets A, B, and C) is significantly higher than that of behaviorally-relevant signals (7, 13, and 9), indicating that using raw signals to estimate the neural dimensionality of behaviors leads to an overestimation&quot; (line 321). This finding was presented in (Sani et al. 2021) and (Hurwitz et al. 2021), which is not clarified here. This issue of putting the work in context has been brought up by other reviewers previously but seems to remain largely unaddressed. The introduction is inaccurate also in that it mixes up methods that were designed for separation of behaviorally relevant information with those that are unsupervised and do not aim to do so (e.g., LFADS). The introduction should be significantly revised to explicitly discuss prior models/works that specifically formulated this behavior separation and what these prior studies found, and how this study differs.”</p></disp-quote><p>Thank you for your comments. Our statement about “One solution is to accurately separate behaviorally-relevant and irrelevant signals, but this approach remains elusive” is accurate. To our best knowledge, there is no prior works to do this work--- separating accurate behaviorally relevant neural signals at both single-neuron and single-trial resolution. The works you mentioned have not explicitly proposed extracting behaviorally relevant signals, nor have they identified and addressed the key challenges of extracting relevant signals, namely determining the optimal degree of similarity between the generated relevant signals and raw signals. Those works focus on the latent neural dynamics, rather than signal level.</p><p>To clearly set apart d-VAE from other models, we have framed the extraction of behaviorally relevant signals as the following mathematical optimization problem:<disp-formula id="sa4equ3"><mml:math id="sa4m9"><mml:mrow><mml:munder><mml:mo movablelimits="true" form="prefix">min</mml:mo><mml:mrow><mml:msub><mml:mi mathvariant="bold-italic">x</mml:mi><mml:mrow><mml:mi mathvariant="bold-italic">r</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:munder><mml:mi>E</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi mathvariant="bold-italic">x</mml:mi><mml:mrow><mml:mi mathvariant="bold-italic">r</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:mi mathvariant="bold-italic">x</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>+</mml:mo><mml:mi>R</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:msub><mml:mi mathvariant="bold-italic">x</mml:mi><mml:mrow><mml:mi mathvariant="bold-italic">r</mml:mi></mml:mrow></mml:msub><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></disp-formula></p><p>where 𝒙𝒓 denotes generated behaviorally-relevant signals, 𝒙 denotes raw noisy signals, 𝐸(⋅,⋅) demotes reconstruction loss, and 𝑅(⋅) denotes regularization loss. It is important to note that while both d-VAE and TNDM employ reconstruction loss, relying solely on this term is insufficient for determining the optimal degree of similarity between the generated and raw noisy signals. The key to accurately extracting behaviorally relevant signals lies in leveraging prior knowledge about these signals to determine the optimal similarity degree, encapsulated by 𝑅(𝒙𝒓). All the works you mentioned did not have the key part 𝑅(𝒙𝒓).</p><p>Regarding the dimensionality estimation, the dimensionality of neural manifolds quantifies the degrees of freedom required to describe population activity without significant information loss.</p><p>There are two differences between our work and PSID and TNDM.</p><p>First, the dimensions they refer to are fundamentally different from ours. The dimensionality we describe pertains to a linear subspace, where a neural dimension or neural mode or principal component basis, <inline-formula><mml:math id="sa4m10"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>u</mml:mi><mml:mo>∈</mml:mo><mml:msup><mml:mi>R</mml:mi><mml:mrow><mml:mi>N</mml:mi></mml:mrow></mml:msup></mml:mrow></mml:mstyle></mml:math></inline-formula> , with N representing the number of neurons. However, the vector length of a neural mode of PSID and our approach differs; PSID requires concatenating multiple time steps T, essentially making <inline-formula><mml:math id="sa4m11"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>u</mml:mi><mml:mo>∈</mml:mo><mml:msup><mml:mi>R</mml:mi><mml:mrow><mml:mi>N</mml:mi><mml:mi>T</mml:mi></mml:mrow></mml:msup></mml:mrow></mml:mstyle></mml:math></inline-formula> , TNDM, on the other hand, involves nonlinear dimensionality reduction, which is different from linear dimensionality reduction.</p><p>Second, we estimate neural dimensionality by explaining the variance of neural signals, whereas PSID and TNDM determine dimensionality through decoding performance saturation. It is important to note that the dimensionality at which decoding performance saturates may not accurately reflect the true dimensionality of neural manifolds, as some dimensions may contain redundant information that does not enhance decoding performance.</p><p>We acknowledge that while LFADS can generate signals that contain some behavioral information, it was not specifically designed to do so. Following your suggestion, we have removed this reference from the Introduction.</p><p>Thank you for your valuable feedback.</p><disp-quote content-type="editor-comment"><p>Q2: “Claims about linearity of &quot;motor cortex&quot; readout are not supported by results yet stated even in the abstract. Instead, what the results support is that for decoding behavior from the output of the dVAE model -- that is trained specifically to have a linear behavior readout from its embedding -- a nonlinear readout does not help. This result can be biased by the very construction of the dVAE's loss that encourages a linear readout/decoding from embeddings, and thus does not imply a finding about motor cortex.”</p></disp-quote><p>Thank you for your comments. We respectfully disagree with the notion that the ability of relevant signals to be linearly decoded is due to constraints that allow embedding to be linearly decoded. Embedding involves reorganizing or transforming the structure of original signals, and they can be linearly decoded does not mean the corresponding signals can be decoded linearly.</p><p>Let's clarify this with three intuitive examples:</p><p>Example 1: Image denoising is a well-established field. Whether employing supervised or blind denoising methods [1, 2], both can effectively recover the original image. This denoising process closely resembles the extraction of behaviorally relevant signals from raw signals. Consider if noisy images are not amenable to linear decoding (classification); would removing the noise enable linear decoding? The answer is no. Typically, the noise in images captured under normal conditions is minimal, yet even the clear images remain challenging to decode linearly.</p><p>Example 2: Consider the task of face recognition, where face images are set against various backgrounds, in this context, the pixels representing the face corresponds to relevant signals, while the background pixels are considered irrelevant. Suppose a network is capable of extracting the face pixels and the resulting embedding can be linearly decoded. Can the face pixels themselves be linearly decoded? The answer is no. If linear decoding of face pixels were feasible, the challenging task of face recognition could be easily resolved by merely extracting the face from the background and training a linear classifier.</p><p>Example 3: In the MNIST dataset, the background is uniformly black, and its impact is minimal. However, linear SVM classifiers used directly on the original pixels significantly underperform compared to non-linear SVMs.</p><p>In summary, embedding involves reorganizing the structure of the original signals through a feature transformation function. However, the reconstruction process can recover the structure of the original signals from the embedding. The fact that the structure of the embedding can be linearly decoded does not imply that the structure of the original signals can be linearly decoded in the same way. It is inappropriate to focus on the compression process without equally considering the reconstruction process.</p><p>Thank you for your valuable feedback.</p><p>(1) Mao, Xiao-Jiao, Chunhua Shen, and Yu-Bin Yang. &quot;Image restoration using convolutional auto-encoders with symmetric skip connections.&quot; arXiv preprint arXiv:1606.08921 (2016).</p><p>(2) Lehtinen, Jaakko, et al. &quot;Noise2Noise: Learning image restoration without clean data.&quot; International Conference on Machine Learning. International Machine Learning Society, 2018.</p><disp-quote content-type="editor-comment"><p>Q3: “Related to the above, it is unclear what the manuscript means by readout from motor cortex. A clearer definition of &quot;readout&quot; (a mapping from what to what?) in general is needed. The mapping that the linearity/nonlinearity claims refer to is from the *inferred* behaviorally relevant neural signals, which themselves are inferred nonlinearly using the VAE. This should be explicitly clarified in all claims, i.e., that only the mapping from distilled signals to behavior is linear, not the whole mapping from neural data to behavior. Again, to say the readout from motor cortex is linear is not supported, including in the abstract.”</p></disp-quote><p>Thank you for your comments. We have revised the manuscript to make it more clearly. Thank you for your valuable feedback.</p><disp-quote content-type="editor-comment"><p>Q4: “Claims about individual neurons are also confounded. The d-VAE distilling processing is a population level embedding so the individual distilled neurons are not obtainable on their own without using the population data. This population level approach also raises the possibility that information can leak from one neuron to another during distillation, which is indeed what the authors hope would recover true information about individual neurons that wasn't there in the recording (the pixel denoising example). The authors acknowledge the possibility that information could leak to a neuron that didn't truly have that information and try to rule it out to some extent with some simulations and by comparing the distilled behaviorally relevant signals to the original neural signals. But ultimately, the distilled signals are different enough from the original signals to substantially improve decoding of low information neurons, and one cannot be sure if all of the information in distilled signals from any individual neuron truly belongs to that neuron. It is still quite likely that some of the improved behavior prediction of the distilled version of low-information neurons is due to leakage of behaviorally relevant information from other neurons, not the former's inherent behavioral information. This should be explicitly acknowledged in the manuscript.”</p></disp-quote><p>Thank you for your comments. We value your insights regarding the mixing process. However, we are confident in the robustness of our conclusions. We respectfully disagree with the notion that the small R2 values containing significant information are primarily due to leakage, and we base our disagreement on four key reasons.</p><p>(1) Neural reconstruction performance is a reliable and valid criterion.</p><p>The purpose of latent variable models is to explain neuronal activity as much as possible. Given the fact that the ground truth of behaviorally-relevant signals, the latent variables, and the generative model is unknow, it becomes evident that the only reliable reference at the signal level is the raw signals. A crucial criterion for evaluating the reliability of latent variable models (including latent variables and generated relevant signals) is their capability to effectively explain the raw signals [1]. Consequently, we firmly maintain the belief that if the generated signals closely resemble the raw signals to the greatest extent possible, in accordance with an equivalence principle, we can claim that these obtained signals faithfully retain the inherent properties of single neurons.</p><p>Reviewer #4 appears to focus on the compression (mixing) process without giving equal consideration to the reconstruction (de-mixing) process. Numerous studies have demonstrated that deep autoencoders can reconstruct the original signal very effectively. For example, in the field of image denoising, autoencoders are capable of accurately restoring the original image [2, 3]. If one persistently focuses on the fact of mixing and ignores the reconstruction （demix） process, even if the only criterion that we can rely on at the signal level is high, one still won't acknowledge it. If this were the case, many problems would become unsolvable. For instance, a fundamental criterion for latent variable models is their ability to explain the original data. If the ground truth of the latent variables remains unknown and the reconstruction criterion is disregarded, how can we validate the effectiveness of the model, the validity of the latent variables, or ensure that findings related to latent variables are not merely by-products of the model? Therefore, we disagree with the aforementioned notion. We believe that as long as the reconstruction performance is satisfactory, the extracted signals have successfully retained the characteristics of individual neurons.</p><p>In our paper, we have shown in various ways that our generated signals sufficiently resemble the raw signals, including visualizing neuronal activity (Fig. 2m, Fig. 3i, and Fig. S5), achieving the highest performance among competitors (Fig. 2d, h, l), and conducting control analyses. Therefore, we believe our results are reliable.</p><p>(1) Cunningham, J.P. and Yu, B.M., 2014. Dimensionality reduction for large-scale neural recordings. Nature neuroscience, 17(11), pp.1500-1509.</p><p>(2) Mao, Xiao-Jiao, Chunhua Shen, and Yu-Bin Yang. &quot;Image restoration using convolutional auto-encoders with symmetric skip connections.&quot; arXiv preprint arXiv:1606.08921 (2016).</p><p>(3) Lehtinen, Jaakko, et al. &quot;Noise2Noise: Learning image restoration without clean data.&quot; International Conference on Machine Learning. International Machine Learning Society, 2018.</p><p>(2) There is no reason for d-VAE to add signals that do not exist in the original signals.</p><p>(1) Adding signals that does not exist in the small R2 neurons would decrease the reconstruction performance. This is because if the added signals contain significant information, they will not resemble the irrelevant signals which contain no information, and thus, the generated signals will not resemble the raw signals. The model optimizes towards reducing the reconstruction loss, and this scenario deviates from the model's optimization direction. It is worth mentioning that when the model only has reconstruction loss without the interference of decoding loss, we believe that information leakage does not happen. Because the model can only be optimized in a direction that is similar to the raw signals; adding non-existent signals to the generated signals would increase the reconstruction loss, which is contrary to the objective of optimization.</p><p>(2) Information carried by these additional signals is redundant for larger R2 neurons, thus they do not introduce new information that can enhance the decoding performance of the neural population, which does not benefit the decoding loss.</p><p>Based on these two points, we believe the model would not perform such counterproductive and harmful operations.</p><p>(3) The criterion that irrelevant signals should contain minimal information can effectively rule out the leakage scenario.</p><p>The criterion that irrelevant signals should contain minimal information is very important, but it seems that reviewer #4 has continuously overlooked their significance. If the model's reconstruction is insufficient, or if additional information is added (which we do not believe will happen), the residuals would decode a large amount of information, and this criterion would exclude selecting such signals. To clarify, if we assume that x, y, and z denote the raw, relevant, and irrelevant signals of smaller R2 neurons, with x=y+z, and the extracted relevant signals become y+m, the irrelevant signals become z-m in this case. Consequently, the irrelevant signals contain a significant amount of information.</p><p>We presented the decoding R2 for irrelevant signals in real datasets under three distillation scenarios: a bias towards reconstruction (alpha=0, an extreme case where the model only has reconstruction loss without decoding loss), a balanced trade-off, and a bias towards decoding (alpha=0.9), as detailed in Table 1. If significant information from small R2 neurons leaks from large R2 neurons, the irrelevant signals should contain a large amount of information. However, our results indicate that the irrelevant signals contain only minimal information, and their performance closely resembles that of the model training solely with reconstruction loss, showing no significant differences (P &gt; 0.05, Wilcoxon rank-sum test). When the model leans towards decoding, some useful information will be left in the residuals, and irrelevant signals will contain a substantial amount of information, as observed in Table 1, alpha=0.9. Therefore, we will not choose these signals for analysis.</p><p>In conclusion, the criterion that irrelevant signals should contain minimal information is a very effective measure to exclude undesirable signals.</p><table-wrap id="sa4table1" position="float"><label>Author response table 1.</label><caption><title>Decoding R2 of irrelevant signals.</title></caption><table frame="hsides" rules="groups"><thead><tr><th valign="bottom"/><th valign="bottom">Dataset A</th><th valign="bottom">Dataset B</th><th valign="bottom">Dataset C</th></tr></thead><tbody><tr><td align="left" valign="bottom">Alpha = 0</td><td align="char" char="plus" valign="bottom">0.065+-0.027</td><td align="char" char="plus" valign="bottom">0.098+-0.037</td><td align="char" char="plus" valign="bottom">0.071+-0.034</td></tr><tr><td align="left" valign="bottom">Selected alpha</td><td align="char" char="plus" valign="bottom">0.105+-0.032</td><td align="char" char="plus" valign="bottom">0.067+-0.031</td><td align="char" char="plus" valign="bottom">0.095+-0.037</td></tr><tr><td align="left" valign="bottom">Alpha = 0.9</td><td align="char" char="plus" valign="bottom">0.220+-0.045</td><td align="char" char="plus" valign="bottom">0.106+-0.044</td><td align="char" char="plus" valign="bottom">0.182+-0.056</td></tr></tbody></table></table-wrap><p>(4) Synthetic experiments can effectively rule out the leakage scenario.</p><p>In the absence of ground truth data, synthetic experiments serve as an effective method for validating models and are commonly employed [1-3].</p><p>Our experimental results demonstrate that d-VAE can effectively extract neural signals that more closely resemble actual behaviorally relevant signals (Fig. S2g). If there were information leakage, it would decrease the similarity to the ground truth signals, hence we have ruled out this possibility. Moreover, in synthetic experiments with small R2 neurons (Fig. S10), results also demonstrate that our model could make these neurons more closely resemble ground truth relevant signals and recover their information.</p><p>In summary, synthetic experiments strongly demonstrate that our model can recover obscured neuronal information, rather than adding signals that do not exist.</p><p>(1) Pnevmatikakis, Eftychios A., et al. &quot;Simultaneous denoising, deconvolution, and demixing of calcium imaging data.&quot; Neuron 89.2 (2016): 285-299.</p><p>(2) Schneider, Steffen, Jin Hwa Lee, and Mackenzie Weygandt Mathis. &quot;Learnable latent embeddings for joint behavioural and neural analysis.&quot; Nature 617.7960 (2023): 360-368.</p><p>(3) Zhou, Ding, and Xue-Xin Wei. &quot;Learning identifiable and interpretable latent models of high-dimensional neural activity using pi-VAE.&quot; Advances in Neural Information Processing Systems 33 (2020): 7234-7247.</p><p>Based on these four points, we are confident in the reliability of our results. If Reviewer #4 considers these points insufficient, we would highly appreciate it if specific concerns regarding any of these aspects could be detailed.</p><p>Thank you for your valuable feedback.</p><disp-quote content-type="editor-comment"><p>Q5: “Given the nuances involved in appropriate comparisons across methods and since two of the datasets are public, the authors should provide their complete code (not just the dVAE method code), including the code for data loading, data preprocessing, model fitting and model evaluation for all methods and public datasets. This will alleviate concerns and allow readers to confirm conclusions (e.g., figure 2) for themselves down the line.”</p></disp-quote><p>Thanks for your suggestion.</p><p>Our codes are now available on GitHub at <ext-link ext-link-type="uri" xlink:href="https://github.com/eric0li/d-VAE">https://github.com/eric0li/d-VAE</ext-link>. Thank you for your valuable feedback.</p><disp-quote content-type="editor-comment"><p>Q6: “Related to (1) above, the authors should explore the results if the affine network h(.) (from embedding to behavior) was replaced with a nonlinear ANN. Perhaps linear decoders would no longer be as close to nonlinear decoders. Regardless, the claim of linearity should be revised as described in (1) and (2) above, and all caveats should be discussed.”</p></disp-quote><p>Thank you for your suggestion. We appreciate your feasible proposal that can be empirically tested. Following your suggestion, we have replaced the decoding of the latent variable z to behavior y with a nonlinear neural network, specifically a neural network with a single hidden layer. The modified model is termed d-VAE2. We applied the d-VAE2 to the real data, and selected the optimal alpha through the validation set. As shown in Table 1, results demonstrate that the performance of KF and ANN remains comparable. Therefore, the capacity to linearly decode behaviorally relevant signals does not stem from the linear decoding of embeddings.</p><table-wrap id="sa4table2" position="float"><label>Author response table 2.</label><caption><title>Decoding R2 of behaviorally relevant signals obtained by d-VAE2.</title></caption><table frame="hsides" rules="groups"><thead><tr><th valign="bottom"/><th valign="bottom">Dataset A</th><th valign="bottom">Dataset B</th><th valign="bottom">Dataset C</th></tr></thead><tbody><tr><td align="left" valign="bottom">KF</td><td align="char" char="plus" valign="bottom">0.706+-0.016</td><td align="char" char="plus" valign="bottom">0.704+-0.039</td><td align="char" char="plus" valign="bottom">0.860+-0.012</td></tr><tr><td align="left" valign="bottom">ANN</td><td align="char" char="plus" valign="bottom">0.752+-0.010</td><td align="char" char="plus" valign="bottom">0.738+-0.033</td><td align="char" char="plus" valign="bottom">0.870+-0.009</td></tr></tbody></table></table-wrap><p>Additionally, it is worth noting that this approach is uncommon and is considered somewhat inappropriate according to the Information Bottleneck theory [1]. According to the Information Bottleneck theory, information is progressively compressed in multilayer neural networks, discarding what is irrelevant to the output and retaining what is relevant. This means that as the number of layers increases, the mutual information between each layer's embedding and the model input gradually decreases, while the mutual information between each layer's embedding and the model output gradually increases. For the decoding part, if the embeddings that is not closest to the output (behaviors) is used, then these embeddings might contain behaviorally irrelevant signals. Using these embeddings to generate behaviorally relevant signals could lead to the inclusion of irrelevant signals in the behaviorally relevant signals.</p><p>To demonstrate the above statement, we conducted experiments on the synthetic data. As shown in Table 2, we present the performance (neural R2 between the generated signals and the ground truth signals) of both models at several alpha values around the optimal alpha of dVAE (alpha=0.9) selected by the validation set. The experimental results show that at the same alpha value, the performance of d-VAE2 is consistently inferior to that of d-VAE, and d-VAE2 requires a higher alpha value to achieve performance comparable to d-VAE, and the best performance of d-VAE2 is inferior to that of d-VAE.</p><table-wrap id="sa4table3" position="float"><label>Author response table 3.</label><caption><title>Neural R2 between generated signals and real behaviorally relevant signals.</title></caption><table frame="hsides" rules="groups"><thead><tr><th valign="bottom">Alpha</th><th valign="bottom">0.7</th><th valign="bottom">0.8</th><th valign="bottom">0.9</th><th valign="bottom">1</th><th valign="bottom">2</th><th valign="bottom">3</th></tr></thead><tbody><tr><td align="left" valign="bottom">d-</td><td align="char" char="plus" valign="bottom">0.720+-</td><td align="char" char="plus" valign="bottom">0.716+-</td><td align="char" char="plus" valign="bottom">0.712+-</td><td align="char" char="plus" valign="bottom">0.730+-</td><td align="char" char="plus" valign="bottom">0.736+-</td><td align="char" char="plus" valign="bottom">0.713+-</td></tr><tr><td align="left" valign="bottom">VAE</td><td align="char" char="." valign="bottom">0.014</td><td align="char" char="." valign="bottom">0.028</td><td align="char" char="." valign="bottom">0.023</td><td align="char" char="." valign="bottom">0.021</td><td align="char" char="." valign="bottom">0.009</td><td align="char" char="." valign="bottom">0.013</td></tr><tr><td align="left" valign="bottom">d-</td><td align="char" char="plus" valign="bottom">0.689+-</td><td align="char" char="plus" valign="bottom">0.693+-</td><td align="char" char="plus" valign="bottom">0.703+-</td><td align="char" char="plus" valign="bottom">0.720+-</td><td align="char" char="plus" valign="bottom">0.727+-</td><td align="char" char="plus" valign="bottom">0.679+-</td></tr><tr><td align="left" valign="bottom">VAE2</td><td align="char" char="." valign="bottom">0.033</td><td align="char" char="." valign="bottom">0.051</td><td align="char" char="." valign="bottom">0.006</td><td align="char" char="." valign="bottom">0.019</td><td align="char" char="." valign="bottom">0.015</td><td align="char" char="." valign="bottom">0.027</td></tr></tbody></table></table-wrap><p>Thank you for your valuable feedback.</p><p>(1) Shwartz-Ziv, Ravid, and Naftali Tishby. &quot;Opening the black box of deep neural networks via information.&quot; arXiv preprint arXiv:1703.00810 (2017).</p><disp-quote content-type="editor-comment"><p>Q7: “The beginning of the section on the &quot;smaller R2 neurons&quot; should clearly define what R2 is being discussed. Based on the response to previous reviewers, this R2 &quot;signifies the proportion of neuronal activity variance explained by the linear encoding model, calculated using raw signals&quot;. This should be mentioned and made clear in the main text whenever this R2 is referred to.”</p></disp-quote><p>Thank you for your suggestion. We have made the modifications in the main text. Thank you for your valuable feedback.</p><disp-quote content-type="editor-comment"><p>Q8: “Various terms require clear definitions. The authors sometimes use vague terminology (e.g., &quot;useless&quot;) without a clear definition. Similarly, discussions regarding dimensionality could benefit from more precise definitions. How is neural dimensionality defined? For example, how is &quot;neural dimensionality of specific behaviors&quot; (line 590) defined? Related to this, I agree with Reviewer 2 that a clear definition of irrelevant should be mentioned that clarifies that relevance is roughly taken as &quot;correlated or predictive with a fixed time lag&quot;. The analyses do not explore relevance with arbitrary time lags between neural and behavior data.”</p></disp-quote><p>Thanks for your suggestion. We have removed the “useless” statements and have revised the statement of “the neural dimensionality of specific behaviors” in our revised manuscripts.</p><p>Regarding the use of fixed temporal lags, we followed the same practice as papers related to the dataset we use, which assume fixed temporal lags [1-3]. Furthermore, many studies in the motor cortex similarly use fixed temporal lags [4-6]. To clarify the definition, we have revised the definition in our manuscript. For details, please refer to the response to Q2 of reviewer #2 and our revised manuscript. We believe our definition is clearly articulated.</p><p>Thank you for your valuable feedback.</p><p>(1) Wang, Fang, et al. &quot;Quantized attention-gated kernel reinforcement learning for brain– machine interface decoding.&quot; IEEE transactions on neural networks and learning systems 28.4 (2015): 873-886.</p><p>(2) Dyer, Eva L., et al. &quot;A cryptography-based approach for movement decoding.&quot; Nature biomedical engineering 1.12 (2017): 967-976.</p><p>(3) Ahmadi, Nur, Timothy G. Constandinou, and Christos-Savvas Bouganis. &quot;Robust and accurate decoding of hand kinematics from entire spiking activity using deep learning.&quot; Journal of Neural Engineering 18.2 (2021): 026011.</p><p>(4) Churchland, Mark M., et al. &quot;Neural population dynamics during reaching.&quot; Nature 487.7405 (2012): 51-56.</p><p>(5) Kaufman, Matthew T., et al. &quot;Cortical activity in the null space: permitting preparation without movement.&quot; Nature neuroscience 17.3 (2014): 440-448.</p><p>(6) Elsayed, Gamaleldin F., et al. &quot;Reorganization between preparatory and movement population responses in motor cortex.&quot; Nature communications 7.1 (2016): 13239.</p><disp-quote content-type="editor-comment"><p>Q9: “CEBRA itself doesn't provide a neural reconstruction from its embeddings, but one could obtain one via a regression from extracted CEBRA embeddings to neural data. In addition to decoding results of CEBRA (figure S3), the neural reconstruction of CEBRA should be computed and CEBRA should be added to Figure 2 to see how the behaviorally relevant and irrelevant signals from CEBRA compare to other methods.”</p></disp-quote><p>Thank you for your question. Modifying CEBRA is beyond the scope of our work. As CEBRA is not a generative model, it cannot obtain behaviorally relevant and irrelevant signals, and therefore it lacks the results presented in Fig. 2. To avoid the same confusion encountered by reviewers #3 and #4 among our readers, we have opted to exclude the comparison with CEBRA. It is crucial to note, as previously stated, that our assessment of decoding capabilities has been benchmarked against the performance of the ANN on raw signals, which almost represents the upper limit of performance. Consequently, omitting CEBRA does not affect our conclusions.</p><p>Thank you for your valuable feedback.</p><disp-quote content-type="editor-comment"><p>Q10: “Line 923: &quot;The optimal hyperparameter is selected based on the lowest averaged loss of five-fold training data.&quot; =&gt; why is this explained specifically under CEBRA? Isn't the same criteria used for hyperparameters of other methods? If so, clarify.”</p></disp-quote><p>Thank you for your question. The hyperparameter selection for CEBRA follows the practice of the original CEBRA paper. The hyperparameter selection for generative models is detailed in the Section “The strategy for selecting effective behaviorally-relevant signals”. Thank you for your valuable feedback.</p></body></sub-article></article>