<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD with MathML3 v1.2 20190208//EN"  "JATS-archivearticle1-mathml3.dtd"><article article-type="research-article" dtd-version="1.2" xmlns:ali="http://www.niso.org/schemas/ali/1.0/" xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink"><front><journal-meta><journal-id journal-id-type="nlm-ta">elife</journal-id><journal-id journal-id-type="publisher-id">eLife</journal-id><journal-title-group><journal-title>eLife</journal-title></journal-title-group><issn pub-type="epub" publication-format="electronic">2050-084X</issn><publisher><publisher-name>eLife Sciences Publications, Ltd</publisher-name></publisher></journal-meta><article-meta><article-id pub-id-type="publisher-id">74445</article-id><article-id pub-id-type="doi">10.7554/eLife.74445</article-id><article-categories><subj-group subj-group-type="display-channel"><subject>Research Article</subject></subj-group><subj-group subj-group-type="heading"><subject>Neuroscience</subject></subj-group></article-categories><title-group><article-title>A neural network model of when to retrieve and encode episodic memories</article-title></title-group><contrib-group><contrib contrib-type="author" corresp="yes" id="author-255826"><name><surname>Lu</surname><given-names>Qihong</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">https://orcid.org/0000-0002-0730-5240</contrib-id><email>qlu@princeton.edu</email><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="aff" rid="aff2">2</xref><xref ref-type="fn" rid="con1"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" id="author-16326"><name><surname>Hasson</surname><given-names>Uri</given-names></name><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="aff" rid="aff2">2</xref><xref ref-type="other" rid="fund1"/><xref ref-type="fn" rid="con2"/><xref ref-type="fn" rid="conf2"/></contrib><contrib contrib-type="author" id="author-76997"><name><surname>Norman</surname><given-names>Kenneth A</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">https://orcid.org/0000-0002-5887-9682</contrib-id><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="aff" rid="aff2">2</xref><xref ref-type="other" rid="fund1"/><xref ref-type="fn" rid="con3"/><xref ref-type="fn" rid="conf2"/></contrib><aff id="aff1"><label>1</label><institution-wrap><institution-id institution-id-type="ror">https://ror.org/00hx57361</institution-id><institution>Department of Psychology, Princeton University</institution></institution-wrap><addr-line><named-content content-type="city">Princeton</named-content></addr-line><country>United States</country></aff><aff id="aff2"><label>2</label><institution-wrap><institution-id institution-id-type="ror">https://ror.org/00hx57361</institution-id><institution>Princeton Neuroscience Institute, Princeton University</institution></institution-wrap><addr-line><named-content content-type="city">Princeton</named-content></addr-line><country>United States</country></aff></contrib-group><contrib-group content-type="section"><contrib contrib-type="editor"><name><surname>Badre</surname><given-names>David</given-names></name><role>Reviewing Editor</role><aff><institution-wrap><institution-id institution-id-type="ror">https://ror.org/05gq02987</institution-id><institution>Brown University</institution></institution-wrap><country>United States</country></aff></contrib><contrib contrib-type="senior_editor"><name><surname>Frank</surname><given-names>Michael J</given-names></name><role>Senior Editor</role><aff><institution-wrap><institution-id institution-id-type="ror">https://ror.org/05gq02987</institution-id><institution>Brown University</institution></institution-wrap><country>United States</country></aff></contrib></contrib-group><pub-date date-type="publication" publication-format="electronic"><day>10</day><month>02</month><year>2022</year></pub-date><pub-date pub-type="collection"><year>2022</year></pub-date><volume>11</volume><elocation-id>e74445</elocation-id><history><date date-type="received" iso-8601-date="2021-10-04"><day>04</day><month>10</month><year>2021</year></date><date date-type="accepted" iso-8601-date="2022-02-09"><day>09</day><month>02</month><year>2022</year></date></history><pub-history><event><event-desc>This manuscript was published as a preprint at bioRxiv.</event-desc><date date-type="preprint" iso-8601-date="2020-12-16"><day>16</day><month>12</month><year>2020</year></date><self-uri content-type="preprint" xlink:href="https://doi.org/10.1101/2020.12.15.422882"/></event></pub-history><permissions><copyright-statement>© 2022, Lu et al</copyright-statement><copyright-year>2022</copyright-year><copyright-holder>Lu et al</copyright-holder><ali:free_to_read/><license xlink:href="http://creativecommons.org/licenses/by/4.0/"><ali:license_ref>http://creativecommons.org/licenses/by/4.0/</ali:license_ref><license-p>This article is distributed under the terms of the <ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/licenses/by/4.0/">Creative Commons Attribution License</ext-link>, which permits unrestricted use and redistribution provided that the original author and source are credited.</license-p></license></permissions><self-uri content-type="pdf" xlink:href="elife-74445-v3.pdf"/><abstract><p>Recent human behavioral and neuroimaging results suggest that people are selective in when they encode and retrieve episodic memories. To explain these findings, we trained a memory-augmented neural network to use its episodic memory to support prediction of upcoming states in an environment where past situations sometimes reoccur. We found that the network learned to retrieve selectively as a function of several factors, including its uncertainty about the upcoming state. Additionally, we found that selectively encoding episodic memories at the end of an event (but not mid-event) led to better subsequent prediction performance. In all of these cases, the benefits of selective retrieval and encoding can be explained in terms of reducing the risk of retrieving irrelevant memories. Overall, these modeling results provide a resource-rational account of why episodic retrieval and encoding should be selective and lead to several testable predictions.</p></abstract><abstract abstract-type="executive-summary"><title>eLife digest</title><p>The human brain can record snapshots of details from specific events – such as where and when the event took place – and retrieve this information later. Recalling these ‘episodic memories’ can help us gain a better understanding of our current surroundings and predict what will happen next.</p><p>Studies of episodic memory have typically involved observing volunteers while they perform simple, well-defined tasks, such as learning and recalling lists of random pairs of words. However, it is less clear how episodic memory works ‘in the wild’ when no one is quizzing us, and we are going about everyday activities.</p><p>Recently, researchers have started to study memory in more naturalistic situations, for example, while volunteers watch a movie. Here, Lu et al. have built a computational model that can predict when our brains store and retrieve episodic memories during these experiments.</p><p>The team gave the model a sequence of inputs corresponding to different stages of an event, and asked it to predict what was coming next. Intuitively, one might think that the best use of episodic memory would be to store and retrieve snapshots as frequently as possible. However, Lu et al. found that the model performed best when it was more selective – that is, preferentially storing episodic memories at the end of events and waiting to recover them until there was a gap in the model’s understanding of the current situation. This strategy may help the brain to avoid retrieving irrelevant memories that might (in turn) result in the brain making incorrect predictions with negative outcomes.</p><p>This model makes it possible for researchers to predict when the brain may store and retrieve episodic memories in a particular experiment. Lu et al. have openly shared the code for the model so that other researchers will be able to use it in their studies to understand how the brain uses episodic memory in everyday situations.</p></abstract><kwd-group kwd-group-type="author-keywords"><kwd>episodic memory</kwd><kwd>event cognition</kwd><kwd>neural network</kwd></kwd-group><kwd-group kwd-group-type="research-organism"><title>Research organism</title><kwd>None</kwd></kwd-group><funding-group><award-group id="fund1"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/100000006</institution-id><institution>Office of Naval Research</institution></institution-wrap></funding-source><award-id>Multi-University Research Initiative Grant ONR/DoD N00014-17-1-2961</award-id><principal-award-recipient><name><surname>Norman</surname><given-names>Kenneth A</given-names></name><name><surname>Hasson</surname><given-names>Uri</given-names></name></principal-award-recipient></award-group><funding-statement>The funders had no role in study design, data collection and interpretation, or the decision to submit the work for publication.</funding-statement></funding-group><custom-meta-group><custom-meta specific-use="meta-only"><meta-name>Author impact statement</meta-name><meta-value>A neural network showed better prediction of upcoming states when it was selective in when it encoded and retrieved episodic memories, thereby explaining why humans show this selectivity in studies of naturalistic memory.</meta-value></custom-meta></custom-meta-group></article-meta></front><body><sec id="s1" sec-type="intro"><title>Introduction</title><p>In a natural setting, when should an intelligent agent encode and retrieve episodic memories? For example, suppose I am viewing the BBC television series <italic>Sherlock</italic>. Should I retrieve an episodic memory that I formed when I watched earlier parts of the show, and if so, when should I retrieve this memory? When should I encode information about the ongoing episode?</p><p>Although episodic memory is one of the most studied topics in cognitive psychology and cognitive neuroscience, the answers to these questions are still unclear, in large part because episodic memory research has traditionally focused on experiments using simple, well-controlled stimuli, where participants receive clear instructions about when to encode and retrieve. For example, a typical episodic memory experiment could ask participants to remember a set of random word-pairs; later on, given a word-cue, the participants need to report the associated word (<xref ref-type="bibr" rid="bib77">Kahana, 2012</xref>). In this kind of word-pair experiment, the optimal timing for encoding and retrieval is clear: The participant should encode an episodic memory when they study a word-pair and retrieve the associate when they are prompted by a cue. Existing computational models of human memory have similarly focused on discretized list-learning paradigms like the (hypothetical) word-pair learning study described above – these models (e.g., see <xref ref-type="bibr" rid="bib52">Gillund and Shiffrin, 1984</xref>; <xref ref-type="bibr" rid="bib63">Hasselmo and Wyble, 1997</xref>; <xref ref-type="bibr" rid="bib146">Shiffrin and Steyvers, 1997</xref>; <xref ref-type="bibr" rid="bib143">Sederberg et al., 2008</xref>; <xref ref-type="bibr" rid="bib71">Howard and Kahana, 2002</xref>; <xref ref-type="bibr" rid="bib106">Norman and O’Reilly, 2003</xref>; <xref ref-type="bibr" rid="bib118">Polyn et al., 2009</xref>; <xref ref-type="bibr" rid="bib28">Cox and Criss, 2020</xref>; for reviews, see <xref ref-type="bibr" rid="bib108">Norman et al., 2008</xref>; <xref ref-type="bibr" rid="bib29">Criss and Howard, 2015</xref>) are primarily designed to answer questions about what happens as a result of a particular sequence of encoding and retrieval trials, not questions about when encoding and retrieval should occur in the first place.</p><p>Recently, there has been increasing interest in using naturalistic stimuli such as movies or audio narratives in psychological experiments, to complement results from traditional experiments using simple and well-controlled stimuli (<xref ref-type="bibr" rid="bib149">Sonkusare et al., 2019</xref>; <xref ref-type="bibr" rid="bib105">Nastase et al., 2020</xref>). These experiments have the potential to shed light on when encoding and retrieval take place during event perception in a naturalistic context, where no one is explicitly instructing participants about how to use episodic memory. These studies have found evidence that episodic encoding and retrieval occur <italic>selectively</italic> over time. For example, results from fMRI studies suggest that episodic encoding occurs preferentially at the ends of events (<xref ref-type="bibr" rid="bib9">Baldassano et al., 2017</xref>; <xref ref-type="bibr" rid="bib13">Ben-Yakov et al., 2013</xref>; <xref ref-type="bibr" rid="bib14">Ben-Yakov and Henson, 2018</xref>; <xref ref-type="bibr" rid="bib126">Reagh et al., 2020</xref>), and episodic retrieval happens preferentially when people are uncertain about the ongoing situation (<xref ref-type="bibr" rid="bib24">Chen et al., 2016</xref>). Selectivity effects can also be observed in the realm of more traditional list-learning studies – for example, there is extensive behavioral and neuroscientific evidence that stimuli that trigger strong prediction errors are preferentially encoded into episodic memory (for reviews, see <xref ref-type="bibr" rid="bib45">Frank and Kafkas, 2021a</xref>; <xref ref-type="bibr" rid="bib122">Quent et al., 2021b</xref>).</p><p>The goal of the present work is to develop a computational model that can account for <italic>when episodic encoding and retrieval take place</italic> in naturalistic situations; the model is meant to capture key features of neocortical-hippocampal interactions, as described below. We formalize the task of event processing by assuming that events involve sequences of states drawn from some underlying event schema, and that the agent’s goal is to predict upcoming states. We then seek to identify policies for episodic encoding and retrieval by optimizing a neural network model on the event processing task. We analyze how the optimal policy changes under different environmental regimes, and how well this policy captures human behavioral and neuroimaging data. To the extent that they match, the model can be viewed as providing a <italic>resource-rational</italic> account of those findings (i.e., an explanation of how these encoding and retrieval policies arise as a joint adaptation to the constraints imposed by the human cognitive architecture and the constraints imposed by the task environment; <xref ref-type="bibr" rid="bib58">Griffiths et al., 2015</xref>; <xref ref-type="bibr" rid="bib88">Lieder and Griffiths, 2019</xref>; see also <xref ref-type="bibr" rid="bib4">Anderson and Schooler, 2000</xref>; <xref ref-type="bibr" rid="bib50">Gershman, 2021</xref>).</p><p>Overall, we find that the best-performing policies are selective in when encoding and retrieval take place, and that the types of selectivity identified by the model line up well with types of selectivity identified empirically. The key intuition behind these effects is that – while retrieving episodic memories can help us to predict upcoming states – there are risks to episodic retrieval: If you retrieve an irrelevant memory, you could make confident, wrong predictions that have negative consequences. The selective encoding and retrieval policies identified by the model help it to mitigate these risks while retaining the benefits of episodic memory. In the sections that follow, we describe our neocortical-hippocampal model, how we applied it to the tasks of interest, and the results of our simulations.</p></sec><sec id="s2" sec-type="results"><title>Results</title><sec id="s2-1"><title>A neural network model of neocortical-hippocampal interaction</title><p>Our modeling work leverages recent advances in memory-augmented neural networks (<xref ref-type="bibr" rid="bib55">Graves et al., 2016</xref>; <xref ref-type="bibr" rid="bib129">Ritter et al., 2018</xref>), deep reinforcement learning (<xref ref-type="bibr" rid="bib102">Mnih et al., 2016</xref>; <xref ref-type="bibr" rid="bib152">Sutton and Barto, 2018</xref>), and meta-learning (<xref ref-type="bibr" rid="bib159">Wang et al., 2018</xref>; <xref ref-type="bibr" rid="bib18">Botvinick et al., 2019</xref>) – these advances (collectively) make it possible for neural network models to <italic>learn to use episodic memory</italic> in the service of prediction (for an earlier precedent, see <xref ref-type="bibr" rid="bib168">Zilli and Hasselmo, 2008</xref>).</p><p>Our model (<xref ref-type="fig" rid="fig1">Figure 1A</xref>) has two parts, which are meant to correspond to neocortex and hippocampus, and which collectively implement three key memory systems (working memory, semantic memory, and episodic memory). The neocortical part of the model incorporates a Long-Short-Term Memory module (LSTM; <xref ref-type="bibr" rid="bib69">Hochreiter and Schmidhuber, 1997</xref>), which is a recurrent neural network (RNN) with gating mechanisms. In addition to the LSTM module, the neocortical network also incorporates a nonlinear decision layer (to assist with mapping inputs to next-state predictions) and an episodic memory (EM) gating layer, the function of which is described below. The LSTM module gives the neocortical network the ability to actively maintain and integrate information over time. For terminological convenience, we will refer to this active maintenance ability in the paper as ‘working memory’. However, we should emphasize that – contrary to classic views of working memory (e.g., <xref ref-type="bibr" rid="bib7">Baddeley, 2000</xref>) – our model does not have a working memory buffer that is set apart from other parts of the model that do stimulus processing; rather, active maintenance and integration are accomplished via recurrent activity in the parts of the model that are doing stimulus processing. In this respect, the architecture of our model fits with the <italic>process memory</italic> framework set forth by <xref ref-type="bibr" rid="bib65">Hasson et al., 2015</xref>. In addition to this active maintenance ability, the connection weights of the neocortical network gradually extract regularities from the environment over time; this gradual learning of regularities can be viewed as an implementation of semantic memory (<xref ref-type="bibr" rid="bib94">McClelland and Rumelhart, 1987</xref>; <xref ref-type="bibr" rid="bib96">McClelland and Rogers, 2003</xref>; <xref ref-type="bibr" rid="bib132">Rogers and McClelland, 2004</xref>; <xref ref-type="bibr" rid="bib137">Saxe et al., 2019</xref>).</p><fig id="fig1" position="float"><label>Figure 1.</label><caption><title>Neocortical-hippocampal Model.</title><p>(<bold>A</bold>) At a given moment, the neocortical part of the model (shown in gray) observes the current state and predicts the upcoming state. It incorporates a Long Short Term Memory (LSTM; <xref ref-type="bibr" rid="bib69">Hochreiter and Schmidhuber, 1997</xref>) network, which integrates information over time; the LSTM feeds into a non-linear decision layer. The LSTM and decision layers also project to an episodic memory (EM) gating layer that determines when episodic memories are retrieved (see part C of figure). The entire neocortical network is trained by an advantage-actor-critic (A2C) objective (<xref ref-type="bibr" rid="bib102">Mnih et al., 2016</xref>) to optimize next-state prediction. (<bold>B</bold>) Episodic memory encoding involves copying the current hidden state and appending it to the list of memories stored in the episodic memory system (shown in blue), which is meant to correspond to hippocampus. (<bold>C</bold>) Episodic memory retrieval is implemented using a leaky competing accumulator model (LCA; <xref ref-type="bibr" rid="bib155">Usher and McClelland, 2001</xref>) – each memory receives excitation proportional to its similarity to the current hidden state, and different memories compete with each other via lateral inhibition. The EM gate (whose value is set by the EM gate layer of the neocortical network) scales the level of excitation coming into the network. After a fixed number of time steps, an activation-weighted sum of all memories is added back to the cell state of the LSTM.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-74445-fig1-v3.tif"/></fig><p>The neocortical network is also connected to an episodic memory module (meant to simulate hippocampus) that stores snapshots of neocortical activity patterns (<xref ref-type="fig" rid="fig1">Figure 1B</xref>) and reinstates these patterns to the neocortical network; see the next section for more information on the model’s encoding policy (i.e., when it stores snapshots). Episodic memory retrieval (<xref ref-type="fig" rid="fig1">Figure 1C</xref>) is implemented via a leaky competing accumulator process (LCA; <xref ref-type="bibr" rid="bib155">Usher and McClelland, 2001</xref>; <xref ref-type="bibr" rid="bib118">Polyn et al., 2009</xref>). In the LCA, memories compete to be retrieved according to how well they match the current state of the neocortical network, and the output of this competitive retrieval process is added back into the neocortical network. Crucially, the degree to which memories are activated during the retrieval process is multiplicatively gated by the EM gate layer of the neocortical network – this gives the neocortical network the ability to shape when episodic retrieval occurs (for more details on how EM works in the model, see the <italic>Episodic retrieval</italic> section in the Materials and methods).</p><p>The entire neocortical network (composed of the LSTM, decision, and EM gate layers) is trained via a reinforcement learning algorithm to optimize prediction of the next state given the current state as input; the trainable nature of the EM gate allows the network to learn a policy for when episodic memory retrieval should occur, in order to optimize next-state prediction. Specifically, we used a meta-learning procedure (<xref ref-type="bibr" rid="bib159">Wang et al., 2018</xref>) whereby the model was trained repeatedly on all conditions of interest with modifiable neocortical weights (<italic>meta-training</italic>), before being evaluated in these conditions with neocortical weights frozen (<italic>meta-testing</italic>). This procedure captures the idea that neocortical weights only change gradually (<xref ref-type="bibr" rid="bib95">McClelland et al., 1995</xref>), and thus are unlikely to be modified enough by one experience to support recall of unique aspects of that experience; as such, memory for these unique details depends critically on that information being held in working memory or episodic memory (for more details, see the <italic>Model training and testing</italic> section in the Materials and methods).</p><p>During meta-training, the model is rewarded for correct next-state predictions and punished for incorrect next-state predictions; we also gave the model the option of saying ‘don’t know’ (instead of predicting a specific next state), in which case it receives zero reward. In the real world, there are often different costs associated with making commission errors (wrong predictions) and omission errors (not making a prediction). Having the ‘don’t know’ option gives the model the freedom to choose whether it should make a specific prediction (thereby incurring the risk of making a commission error and receiving a penalty) or whether it should express uncertainty to avoid a possible penalty. Intuitively, this choice should depend on the environment. For example, if the penalty for misprediction is zero, the model should make a prediction even if it has high uncertainty about the upcoming state. In contrast, if the penalty for misprediction is high, the model should only make a prediction if it is certain about what would happen next. Practically speaking, the consequence of including the ‘don’t know’ option is to induce the model to wait longer to retrieve episodic memories (see results below and also Appendix 5).</p></sec><sec id="s2-2"><title>Modeling the contribution of episodic memory to naturalistic event understanding</title><p>Our initial modeling target was a recent study by <xref ref-type="bibr" rid="bib24">Chen et al., 2016</xref>, which explored the role of episodic memory in naturalistic event understanding. In this study, participants viewed an episode from the <italic>Twilight Zone</italic> television series. This episode was divided into two parts (part 1 and part 2). Participants in the recent memory (RM) condition viewed the two parts back-to-back; participants in the distant memory (DM) condition had a 1-day gap in between the two parts of this TV episode; participants in the no memory (NM) condition only watched the second part (<xref ref-type="bibr" rid="bib24">Chen et al., 2016</xref>). In the RM condition, participants can build up a situation model – that is, a representation of the relevant features of the ongoing situation (<xref ref-type="bibr" rid="bib127">Richmond and Zacks, 2017</xref>; <xref ref-type="bibr" rid="bib151">Stawarczyk et al., 2021</xref>; <xref ref-type="bibr" rid="bib166">Zacks, 2020</xref>; <xref ref-type="bibr" rid="bib124">Ranganath and Ritchey, 2012</xref>) – during the first part of the movie and actively maintain it over time; all of that information is still actively represented at the start of part 2. By contrast, in the DM condition, a day has passed between part 1 and part 2, so participants are no longer actively maintaining the relevant situation model at the start of part 2.</p><p>Taken together, these conditions can be viewed as manipulating the <italic>availability</italic> of relevant episodic memories and also the <italic>demand</italic> for episodic retrieval. In the NM condition, at the start of part 2, participants have gaps in their situation model (because they did not view part 1) and thus there is a strong demand to fill those gaps, to better understand what is going on; however, they do not have any relevant episodic memories available to fill those gaps. In the DM condition, because of the 1-day delay, participants also have gaps in their representation of the situation in working memory that need to be filled with information from part 1; however, unlike the NM participants, DM participants can meet this demand by retrieving information about part 1 that was stored in episodic memory. In the RM condition, like the DM condition, participants have relevant information about part 1 available in episodic memory (participants’ experience in part 1 of the DM and RM conditions was identical, so presumably they stored the same episodic memories during part 1), but there is less of a demand to retrieve these episodic memories in the RM condition (because these participants were not interrupted, and thus these participants should have fewer gaps in their understanding of the situation). The comparison of the RM and DM conditions is thus a relatively pure manipulation of demand for episodic memory retrieval. If episodic memory retrieval is sensitive to the need to retrieve (i.e., whether there are gaps to fill in), then more retrieval should take place in the DM condition, but if episodic memory retrieval is automatic, retrieval should occur at similar levels in the RM and DM conditions. The results of the <xref ref-type="bibr" rid="bib24">Chen et al., 2016</xref> study strongly support the former (‘demand-sensitive’) view of episodic retrieval. During the first two minutes of part 2, the researchers found strong hippocampal-neocortical activity coupling measured using inter-subject functional connectivity (ISFC; computed as functional connectivity across participants; <xref ref-type="bibr" rid="bib148">Simony et al., 2016</xref>) for DM participants, while the level of coupling was much weaker for participants in the RM and NM conditions (<xref ref-type="bibr" rid="bib24">Chen et al., 2016</xref>). Notably, neocortical regions that had a strong coupling with the hippocampus (in the DM condition) largely overlapped with the default mode network (DMN), which is believed to actively maintain a situation model (<xref ref-type="bibr" rid="bib151">Stawarczyk et al., 2021</xref>). These results fit with the idea that more information is being communicated between hippocampus and neocortex in the DM (‘high episodic memory demand’) condition than in the RM (‘low episodic memory demand’) condition and the NM condition (where there are no relevant episodic memories to retrieve). This ‘demand sensitive’ view of episodic memory implies that neocortex can be strategic in how it calls upon the hippocampus to support event understanding, and it underlines the importance of the aforementioned goal of characterizing the policy for when retrieval should occur.</p></sec><sec id="s2-3"><title>Training environment</title><p>To simulate the task of event processing, we define an <italic>event</italic> as a sequence of states, sampled from an underlying graph that represents the <italic>event schema</italic>. <xref ref-type="fig" rid="fig2">Figure 2A</xref> shows a ‘coffee shop visit’ event schema graph with three time points; each time point has two possible states. Each instance of an event (here, each visit to the coffee shop) is associated with a <italic>situation</italic> – a collection of features set to particular values; importantly, the features of the current situation deterministically control the transitions between states within the event. For example, in <xref ref-type="fig" rid="fig2">Figure 2A</xref>, the value of the Weather situation feature (sunny or rainy) determines which of the Mood states is visited (happy or angry). That is to say, P(Mood = happy | Weather = sunny) = 1 and P(Mood = sad | Weather = rainy) = 1. At each time point, the model observes the value of a randomly selected feature of the current situation and responds to a query about which state will be visited next. In the example shown in <xref ref-type="fig" rid="fig2">Figure 2A</xref>, the agent first observes that Day = weekday, and then is asked to predict the upcoming Barista state (will the barista be Bob or Eve). Then it observes that Sleepiness = sleepy and is asked to predict the upcoming Mood state (will the barista be happy or angry). Finally, it observes that the Weather = sunny and is asked to predict the upcoming Drink state (will the drink be juice or latte). Note that the order of queries is fixed but the order in which situation features are observed is random.</p><fig id="fig2" position="float"><label>Figure 2.</label><caption><title>A situation-dependent event processing task.</title><p>(<bold>A</bold>) An <italic>event</italic> is a sequence of states, sampled from an event schema and conditioned on a situation. An <italic>event schema</italic> is a graph where each node is a state. A <italic>situation</italic> is a collection of features (e.g., Day, Weather, Sleepiness) set to particular values (e.g., Day = weekday). The features of the current situation deterministically control how the event unfolds (e.g., the value of the Day feature controls which Barista state is observed). At each time point, the network observes the value of a randomly selected feature of the current situation, and responds to a query about what will happen next. Note that the order of queries is fixed but the order in which situation features are observed is random. If a situation feature (Sleepiness) is observed before the state it controls (Drink), the model can answer the query about that state by holding the relevant feature in working memory. However, if the relevant situation feature (Weather) is observed after the state it controls (Mood), the model can not rely on working memory on its own to answer the query. (<bold>B</bold>) We created three task conditions to simulate the design used by <xref ref-type="bibr" rid="bib24">Chen et al., 2016</xref>: recent memory (RM), distant memory (DM), and no memory (NM); see text for details. (<bold>C</bold>) Decoded contents of the model’s working memory for an example trial from the DM condition. Green boxes indicate time points where the value of a particular situation feature was observed. The color of a square indicates whether the correct (i.e., observed) value of that feature can be decoded from the model’s working memory state (white = feature accurately decoded; black = feature not decoded). See text for additional explanation.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-74445-fig2-v3.tif"/></fig><p>Both observations and queries are represented by one-hot vectors (for details, see the Stimulus representation section in the Materials and methods). In our simulations, the length of the event graph is 16 and the number of states for each time point is 4. This means the number of unique ways in which an event can unfold (depending on the features of the current situation) is 4<sup>16</sup> – far too many to memorize. As such, learning an effective representation of the event graph (i.e., which states can occur at which time points, and how the state transitions depend on the values of the situation features) is essential for predicting which state will come next. In our model, this information is learned during the meta-training phase and stored in the neocortical network’s weights (i.e., the model’s semantic memory). As a terminological point, in this paper we use the term <italic>situation</italic> to refer to the ‘ground truth’ of the feature-value pairings for the current event, and we use <italic>situation model</italic> to refer to the model’s internal representation of the current situation in working memory (i.e., in the LSTM cell state).</p><p><xref ref-type="fig" rid="fig2">Figure 2A</xref> also illustrates how the memory demands of the task vary depending on when the situation feature that controls a given state is observed, relative to the query for that state. If the situation feature (Day) that controls a particular state (Barista) is observed on the same time step as the query for that state, no memory is needed to answer the query. If the relevant situation feature (Sleepiness) for controlling a state (Drink) was recently observed (e.g., at an earlier time step in the sequence), the model can answer the query by holding the value of that feature in working memory. If the relevant situation feature (Weather) for controlling a state (Mood) was not recently observed, the model can not use working memory on its own to answer the query; here, the only way the model can respond correctly is by retrieving a stored episodic memory of that situation.</p><p><xref ref-type="fig" rid="fig2">Figure 2B</xref> shows the way we simulated the three conditions from <xref ref-type="bibr" rid="bib24">Chen et al., 2016</xref>. In each of the conditions, the agent processes three events. Importantly, for all of the conditions, we imposed (by hand) an encoding policy where the model stored an episodic memory (reflecting the current contents of working memory – i.e., the LSTM cell state) on the final time point of each event. This encoding policy was based on previous findings suggesting that episodic encoding takes place selectively at the end of an event (<xref ref-type="bibr" rid="bib12">Ben-Yakov and Dudai, 2011</xref>; <xref ref-type="bibr" rid="bib13">Ben-Yakov et al., 2013</xref>; <xref ref-type="bibr" rid="bib9">Baldassano et al., 2017</xref>; <xref ref-type="bibr" rid="bib14">Ben-Yakov and Henson, 2018</xref>; <xref ref-type="bibr" rid="bib126">Reagh et al., 2020</xref>); we critically examine this assumption in the <italic>Benefits of selectively encoding at the end of an event</italic> section below. In both the RM and DM conditions, the agent first processes a distractor event (i.e., event a1), and then processes two related events that are controlled by the same situation (i.e., event b1 and b2). These two related events capture the two-part movie in the study by <xref ref-type="bibr" rid="bib24">Chen et al., 2016</xref>, in the sense that knowing information from the first event (b1) will make the second event (b2) more predictable. Note that, at the start of movie part 2 (b2), models in both the RM and DM conditions have access to a lure episodic memory that was formed during the distractor event (a1), and also a target episodic memory that was formed during movie part 1 (b1). The main difference is that, in the DM condition, the working memory state is flushed between part 1 and part 2 (by resetting the cell state of the LSTM), whereas the flush does not occur in the RM condition; this flush in the DM condition is meant to capture the effects of the one-day delay between part 1 and part 2 in the study by <xref ref-type="bibr" rid="bib24">Chen et al., 2016</xref>. Finally, in the NM condition, the agent processes three events from three different situations. Therefore, during movie part 2, the agent has no information in working memory or episodic memory pertaining to part 1. The model was trained (repeatedly) to predict upcoming states on all three trial types before being tested on each of these trial types (see the <italic>Model training and testing</italic> section in the Materials and methods).</p><p>To summarize, the task environment used in our simulations captures how understanding of naturalistic events and narratives depends on memory: It is necessary to remember observations from the past (possibly from a large number of time points ago) in order to optimally predict the future. For example, in the <italic>Twilight Zone</italic> episode used by <xref ref-type="bibr" rid="bib24">Chen et al., 2016</xref>, learning that the servants are robots early in the episode helps the viewer predict how one character will react when another character suggests killing all of the servants; similarly, in the model, learning that the weather is sunny during event b1 will help the model predict that the barista will be happy during event b2. The model is incentivized to routinely hold observations in working memory, because information that is observed early in an event can sometimes be used to answer queries that are posed later in that same event, or possibly across events (in the RM condition). This should lead to a dynamic where the amount of information held in working memory builds within an event (i.e., with each successive observation, the model builds a more ‘complete’ representation in working memory of the features of the current situation). Episodic memory is incentivized because of the working memory ‘flush’ in the DM condition between events b1 and b2 – information that is relevant to b2 is observed during b1 but flushed from working memory, so the only way to benefit from this information is to store it in episodic memory (at the end of b1) and then retrieve it from episodic memory at the start of b2 (for additional discussion of how episodic memory can help to bridge interruptions, see classic work by <xref ref-type="bibr" rid="bib40">Ericsson and Kintsch, 1995</xref>).</p><p><xref ref-type="fig" rid="fig2">Figure 2C</xref> illustrates these points by showing the decoded contents of the model’s working memory for an example DM trial. To generate this figure, a linear classifier (logistic regression with L2 penalty) was used to decode whether the correct (i.e., observed) value of each situation feature was represented in the working memory state of the model (i.e., the LSTM cell state) at each time point during the trial; see the <italic>Decoding the working memory state</italic> section in the Materials and methods for more details. We found that, once a feature was observed (indicated by a green box in the figure), this feature typically was decodable until the end of the event, which confirms that observed features tend to be actively maintained in the working memory state of the agent. The figure makes it clear how, because of this tendency to maintain information over time, the model’s representation of the situation becomes more complete over time within part 1 of the event. The model then stores an episodic memory snapshot on the final time point in part 1 (indicated by the blue arrow). Between part 1 and part 2, the model’s working memory state is flushed; then, early in part 2, the model retrieves the stored episodic memory snapshot (indicated by the red arrow), which results in many features of the situation becoming decodable before they are actually observed during part 2.</p><p>We acknowledge that our event-processing simulations incorporate several major simplifications. For example, we are modeling the first part of the movie as a single event when, in the <xref ref-type="bibr" rid="bib24">Chen et al., 2016</xref> study, each half of the Twilight Zone episode clearly contains multiple events. We also are assuming that the rate of key situation features being revealed is linear (one per time point) and that feature values stay stable within events. Our goal here was to come up with the simplest possible framework that allowed us to meaningfully engage with questions about encoding and retrieval policies for episodic memory. In the <italic>Discussion</italic>, we talk about ways that the model could be extended to more fully address the complexity of real-world events.</p></sec><sec id="s2-4"><title>The learned retrieval policy is sensitive to uncertainty</title><p><xref ref-type="fig" rid="fig3">Figure 3A</xref> shows the trained model’s prediction performance during movie part 2, with the penalty value for incorrect prediction set to 2. In the recent memory (RM) condition, prediction accuracy is at ceiling starting from the beginning of part 2 – all situation feature values for the ongoing situation were observed during the first part of the sequence, and the model is able to hold on to these features in working memory. In the distant memory (DM) condition, prediction accuracy starts out much lower, but after a few time points the accuracy is almost at ceiling. In the no memory condition (NM), prediction accuracy increases linearly, reflecting the fact that the model is able to observe more situation features as the event unfolds. The fact that prediction accuracy is better in the DM condition than in the NM condition suggests that the model is using episodic memory to support prediction in the DM condition.</p><fig id="fig3" position="float"><label>Figure 3.</label><caption><title>The learned episodic retrieval policy is selective.</title><p>Panels <bold>A, B</bold> and <bold>C</bold> show the model’s behavioral performance, memory activation, and episodic memory gate (EM gate) value during part 2, across the recent memory (RM), distant memory (DM), and no memory (NM) conditions, when the penalty for incorrect prediction is set to two at test. These results show that recall is much stronger in the DM condition (where episodic retrieval is needed to fill in gaps and resolve uncertainty) compared to the RM condition. (<bold>D</bold>) shows that, in the DM condition, the EM gate value is lower if the model has recently (i.e., in the current event) observed the feature that controls the upcoming state transition. (<bold>E</bold>) shows how the average recall time is delayed when the penalty for making incorrect predictions is higher. (<bold>F</bold>) illustrates the definition of the schema strength for a given time point. (<bold>G</bold>) shows how the average EM gate value changes as a function of schema strength (penalty level = 2). The errorbars indicate 1SE across 15 models.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-74445-fig3-v3.tif"/></fig><p>We were particularly interested in whether the model’s learned retrieval policy would be demand-sensitive (i.e., would the model be more prone to retrieve from episodic memory if there were gaps in its situation model, leading it to be uncertain about the upcoming state). To answer this question, we visualized the activation levels of the target and lure memories during part 2, for each of the three conditions (<xref ref-type="fig" rid="fig3">Figure 3B</xref>). Across the three conditions, we found much higher levels of memory activation in the DM condition than the other two conditions. Importantly, the finding (in the model) of greater memory activation in the DM condition than the RM condition qualitatively captures the finding from <xref ref-type="bibr" rid="bib24">Chen et al., 2016</xref> that the putative fMRI signature of episodic retrieval (hippocampal-neocortical coupling) was stronger in the DM condition than the RM condition. Note that, in our simulation, the set of available episodic memories in the RM and the DM condition is the same. The main difference is that, in the RM condition, the network has a fully-specified situation model actively maintained in its working memory (the recurrent activity of the LSTM) during part 2, which is sufficient for the network to predict the upcoming state. In contrast, at the beginning of the DM condition, the network’s ongoing situation model is empty – the values for all features are unknown. Overall, this result suggests that the learned retrieval policy is demand-sensitive (for simulations of other, related findings from this study, see <italic>Appendix 6</italic>).</p><p>To gain further insight into the model’s retrieval policy, we examined the EM gate values in the three conditions (<xref ref-type="fig" rid="fig3">Figure 3C</xref>). We found that the model sets the EM gate to a higher (more ‘open’) value in the DM and NM conditions (where there are gaps in the model’s understanding of the ongoing situation, causing it to be uncertain about what was coming next), and it suppresses episodic retrieval in the RM condition (where there are no gaps). Likewise, within the DM condition, the model sets the EM gate to a higher value when the feature controlling the next transition has not been recently observed (i.e., the feature is not in working memory, causing the model to be uncertain about what was coming next) vs. if the relevant feature has been recently observed and is therefore active in working memory (<xref ref-type="fig" rid="fig3">Figure 3D</xref>). The same principle also explains why, for later time points in part 2, the EM gate is set to a lower value in the DM condition than the NM condition (<xref ref-type="fig" rid="fig3">Figure 3C</xref>) – in the DM condition, episodic retrieval that occurs on earlier time points makes the model more certain on later time points, reducing the demand for episodic retrieval and (consequently) leading to lower EM gate values.</p><p>The fact that the model learned a demand-sensitive retrieval policy can be explained in terms of a simple cost-benefit analysis: When the model is unsure about what will happen next, the potential benefits of episodic retrieval are high. In the absence of episodic retrieval, the model will have to guess or say ‘don’t know’, but if it consults episodic memory, the model could end up recalling the feature of the situation that controls the upcoming state transition, allowing it to make a correct prediction. By contrast, when the feature of the situation that controls the transition is already in working memory (and consequently the model is able to make a specific prediction about what will happen next), there is less of a benefit associated with episodic retrieval – the only way that episodic retrieval will help is if the model is holding the wrong feature in working memory and the episodic memory overwrites it. Furthermore, in this scenario, there is also a potential cost to retrieving from episodic memory: Lures are always present, and if the model recalls a lure this can overwrite the correct information in working memory. Since the potential costs of episodic retrieval outweigh the benefits of episodic retrieval in the ‘high certainty’ scenario, the model learns a policy of waiting to retrieve until it is uncertain about what will happen next.</p><p>Importantly, the model’s ability to <italic>adjust its policy</italic> when it is uncertain is predicated on there being a reliable ‘neural correlate of certainty’ in the model, which can be used as the basis for this differential responding; we investigated this and found that the norm of activity in the decision layer is lower when the model is uncertain vs. certain (for more details, see <italic>Appendix 1</italic>). This (implicit) neural correlate of certainty exists regardless of whether the model is trained to explicitly signal uncertainty via the ‘don’t know’ response. In other simulations (reported in <italic>Appendix 5</italic>), we found that a version of the model without the ‘don’t know’ option can still leverage this implicit neural correlate of certainty to show demand-sensitive retrieval (i.e., more episodic retrieval in the DM condition than the RM condition); the main effect of including the ‘don’t know’ option is to make the model more patient overall, by reducing the cost associated with waiting to retrieve from episodic memory.</p></sec><sec id="s2-5"><title>The effect of penalty on retrieval policy</title><p>A key question is how the model’s policy for prediction and episodic retrieval adapts to different environmental regimes. Toward this end, we explored what happens when we vary the penalty on false recall from 0 to 4 during model meta-testing – that is, can the model flexibly adjust its policy based on the current penalty? (note that the penalty was uniformly sampled from the 0–4 range during meta-training). If learning a selective retrieval policy is driven by the need to manage the costs of false recall, then it stands to reason that varying these costs should affect the model’s policy. Our first finding is that adjusting the penalty at test affects the model’s tendency to give ‘don’t know’ responses: When the penalty is zero, the model makes specific next-state predictions (i.e., it refrains from using the ‘don’t know’ response) even when it can not reliably predict the next state, leading to many errors. In contrast, when the penalty is high, the model makes more ‘don’t know’ responses (in the DM condition, the model responds ‘don’t know’ 15.8% of the time when penalty is set to 4, vs 0.3% of the time when penalty is set to 0). This strategy is rational – when the penalty is zero, the expected reward is larger for randomly guessing an answer than for saying ‘don’t know’, but when the penalty is set to four, the expected reward is larger for saying ‘don’t know’ than for random guessing. We also found that, when the model is tested in an environment where the penalty is high, it waits longer to retrieve from episodic memory, relative to when the penalty at training is lower (<xref ref-type="fig" rid="fig3">Figure 3E</xref>). This delay in recall can be explained in terms of a speed-accuracy trade-off. Waiting longer to retrieve from episodic memory allows the model to observe more features, which helps to disambiguate the present situation from other, related situations and thereby reduces false recall. However, waiting longer also carries an opportunity cost – the model has to forego all of the rewards it would have received (from correct prediction) if it had recalled the correct memory earlier. When the penalty is low, the benefits of retrieving early (in terms of increased correct prediction) outweigh the costs (in terms of increased incorrect prediction due to false recall), but when the penalty is high, the costs outweigh the benefits, so the model is more cautious and it waits to observe more features to be sure that the memory it (eventually) recalls is the right one.</p></sec><sec id="s2-6"><title>The effect of schema regularity on the learned policy</title><p>Next, we examined the effect of schema regularity on the agent’s retrieval policy. In the simulations preceding this one, we imposed a form of schematic structure by teaching the model about which states could be visited at which time points (i.e., the ‘columns’ of <xref ref-type="fig" rid="fig2">Figure 2A</xref>). However, <italic>within</italic> a particular time point, the marginal probabilities of the states that were ‘allowed’ at that time point were equated – put another way, none of the states were more prototypical than any of the other states. In this simulation, we also allowed for some states to be more prototypical (i.e., occur more often) than other states that could occur at that time point. We say that a time point is <italic>schematic</italic> if there is one state that happens with higher probability, compared to other states. Consider the example illustrated in <xref ref-type="fig" rid="fig3">Figure 3F</xref>: If the probability of Bob being angry is much greater than the probability of him being happy, then we say that this is a highly schematic time point. In contrast, if Bob is equally likely to be happy or angry, then the schema strength is low. Intuitively, when there is a strong schema, there is less of a need to rely on episodic memory – in the limiting case, if the schematic state occurs in every sequence, the model will learn to predict this state every time and there is no need to consult episodic memory.</p><p>To explore the effects of schema strength, we ran simulations where half of the time points were schematic. For the other half of the time points (<italic>non-schematic</italic> time points), all of the states associated with that time point were equally probable (given that there were four possible states at each time point, the probability of each state was 0.25). Schematic and non-schematic time points were arranged in an alternating fashion (for half of the models, even time points were schematic and odd time points were non-schematic, and the opposite was true for the other half of the models). For schematic time points, we manipulated the strength of schematic regularity in the environment by manipulating the probability of the ‘prototypical’ state. We varied schema strength values from 0.25 (baseline) to 0.95 in steps of 0.10.</p><p>The results of this analysis when penalty was set to two at test are shown in <xref ref-type="fig" rid="fig3">Figure 3G</xref>, which plots the EM gate value during part 2 as a function of schema strength. The first thing to note about these results is that, for high levels of schema strength, episodic retrieval is suppressed for schematic time points (i.e., time points with a prototypical state) and elevated for non-schematic time points (i.e., time points where there was not a prototypical state). The former finding (suppression of retrieval at time points where there is a strong prototype) fits with the intuition, noted above, that high-schema-strength states are almost fully predictable without episodic memory, and thus there is no need to retrieve from episodic memory. The latter finding (enhanced retrieval at non-schematic time points, when schema strength is high overall) can be explained in terms of the idea that schema-congruent features tend to be shared by both target and lure memories and thus are not diagnostic of which memory is the target; in this situation, the only way to distinguish between targets and lures is to recall non-schematic features, which is why the model tries extra-hard to retrieve them from episodic memory.</p><p>Interestingly, the model shows the opposite pattern of effects when schema strength = .55 or .65: Episodic retrieval is enhanced for schematic time points and suppressed for non-schematic time points. This reversal can be explained as follows: When schema strength = .55 or .65, the model has started to build up a tendency to guess the schema-congruent (prototypical) state, but it is also going to be wrong about 1/3 of the time when it guesses the schema-congruent state, incurring a substantial penalty. To counteract this tendency to make wrong guesses, the model needs to try extra-hard to retrieve the actual feature value for schematic time points (which is why the EM gate value increases for these time points) – and if the model is doing more retrieval in response to schematic states, it needs to do somewhat less retrieval in response to non-schematic states (which is why the EM gate value goes down for these features). As schema strength increases beyond .65, the model will be wrong less often when it guesses the schema-congruent state, so there is less of a need to counteract wrong guesses with episodic retrieval – this makes it safe for the model to reduce the EM gate value for schematic time points at higher levels of schema strength (as described above).</p></sec><sec id="s2-7"><title>Other factors that affect the learned retrieval policy</title><p>In addition to the simulations described above, we also ran simulations exploring the effects of <italic>between-event similarity</italic> and <italic>familiarity</italic> on the learned retrieval policy. With regard to similarity: We found that the model is more cautious about retrieving from episodic memory if trained in environments where memories are highly similar (because the risk of false recall is higher) – see <italic>Appendix 2</italic> for details. With regard to familiarity: When we provided the model with a familiarity signal that is informative about whether a situation was previously encountered, we found that the model learns to exploit this information by retrieving more from episodic memory when the familiarity signal is high and retrieving less from episodic memory when the familiarity signal is low. This result provides a resource-rational account of experimental findings showing that familiar stimuli shift the hippocampus into a ‘retrieval mode’ where it is more likely to (subsequently) retrieve episodic memories (<xref ref-type="bibr" rid="bib34">Duncan et al., 2012</xref>; <xref ref-type="bibr" rid="bib35">Duncan and Shohamy, 2016</xref>; <xref ref-type="bibr" rid="bib37">Duncan et al., 2019</xref>; <xref ref-type="bibr" rid="bib115">Patil and Duncan, 2018</xref>; <xref ref-type="bibr" rid="bib63">Hasselmo and Wyble, 1997</xref>; <xref ref-type="bibr" rid="bib61">Hasselmo et al., 1995</xref>) – see <italic>Appendix 3</italic> for details.</p></sec><sec id="s2-8"><title>Benefits of selective encoding</title><p>Above, we showed that the model learned selective retrieval policies (e.g., avoiding retrieval from episodic memory early on during part 2, or when certain about upcoming states) in order to reduce the risk of recalling irrelevant memories. Here, we shift our focus to the complementary question of <italic>encoding policy</italic>: When is the best time to store episodic memories? In the simulations reported below, we show that a selective encoding policy can benefit performance, by reducing interference at retrieval later on. Note that our model is presently not capable of learning an encoding policy on its own (see <italic>Discussion</italic>), but we can explore the benefits of selective encoding by imposing different encoding policies by hand and seeing how they affect performance.</p></sec><sec id="s2-9"><title>Benefits of selectively encoding at the end of an event</title><p>The simulations presented thus far assumed that episodic memories are selectively encoded at the ends of events. This assumption was based on findings from several recent fMRI studies that measured hippocampal activity during perception of events and related this to later memory for the events. These studies found that the hippocampal response tends to peak at event boundaries (<xref ref-type="bibr" rid="bib12">Ben-Yakov and Dudai, 2011</xref>; <xref ref-type="bibr" rid="bib13">Ben-Yakov et al., 2013</xref>; <xref ref-type="bibr" rid="bib9">Baldassano et al., 2017</xref>; <xref ref-type="bibr" rid="bib14">Ben-Yakov and Henson, 2018</xref>; <xref ref-type="bibr" rid="bib126">Reagh et al., 2020</xref>); this boundary-locked response predicts subsequent memory performance for the just-completed event (<xref ref-type="bibr" rid="bib12">Ben-Yakov and Dudai, 2011</xref>; <xref ref-type="bibr" rid="bib9">Baldassano et al., 2017</xref>; <xref ref-type="bibr" rid="bib126">Reagh et al., 2020</xref>), leading researchers to conclude that it is a neural signature of episodic encoding of the just-completed event.</p><p>While these results suggest that the end of an event may be a particularly important time for episodic encoding, existing studies do not provide a computational account of <italic>why</italic> this should be the case. This ‘why’ question can be broken into two parts: First, why might it be beneficial to encode at the end of an event, and second, why might it be <italic>harmful</italic> to encode at other times within the event? Answering the first question (regarding benefits of encoding at the end of an event) is relatively straightforward. Several researchers have argued that information about the current situation builds up in working memory within an event, and then is ‘flushed out’ at event boundaries (<xref ref-type="bibr" rid="bib123">Radvansky et al., 2011</xref>; <xref ref-type="bibr" rid="bib127">Richmond and Zacks, 2017</xref>; for neural evidence in support of this dynamic, see <xref ref-type="bibr" rid="bib41">Ezzyat and Davachi, 2011</xref>; <xref ref-type="bibr" rid="bib25">Chien and Honey, 2020</xref>; <xref ref-type="bibr" rid="bib42">Ezzyat and Davachi, 2021</xref>). This dynamic (which is illustrated in the model in <xref ref-type="fig" rid="fig2">Figure 2C</xref>) means that the model’s representation of the features of an event will be most complete right before the end of the event, making this a particularly advantageous time to take an episodic memory snapshot of the situation model.</p><p>While it is clear why encoding at the end of an event is useful, it is less clear why encoding at other times might be harmful; naively, one might think that storing more episodic snapshots during an event would lead to <italic>better</italic> memory for the event. To answer this question, we compared models that selectively encode episodic memories at the end of each event to models that encode episodic memories both at the end of each event and also midway through each event. Note that the model did not learn these two encoding policies by itself – we simply configured the model to encode one way or the other and compared their performance. If selectively encoding at the end of an event yields better performance, this would provide a resource-rational justification for the empirical findings reviewed above.</p><p>Our simulation shows that in the DM condition, during part 2, models that encode an additional episodic memory midway through each event performed worse (<xref ref-type="fig" rid="fig4">Figure 4A</xref>). This decrease in performance can be explained in terms of several related factors. First, as shown in <xref ref-type="fig" rid="fig4">Figure 4B</xref>, when midway memories are also stored, midway memories of the target event are recalled more strongly than memories formed at the end of the target event.</p><fig id="fig4" position="float"><label>Figure 4.</label><caption><title>The advantage of selectively encoding episodic memories at the end of an event.</title><p>(<bold>A</bold>) Prediction performance is better for models that selectively encode at the end of each event, compared to models that encode at the end of each event and also midway through each event. (<bold>B</bold>) The model performs worse with midway-encoded memories because midway-encoded target memories are activated more strongly than end-encoded target memories, thereby blocking recall of the (more informative) end-encoded target memories, and also because midway-encoded lure memories are more strongly activated than end-encoded lure memories (see text for additional discussion). (<bold>C</bold>) The cosine similarity between working memory states during part 2 and memories formed midway through part 1 (in orange) or at the end of part 1 (in blue). The result indicates that the midway-encoded memory will dominate the end-encoded memory for most time points. (<bold>D</bold>) The time-point-to-time-point cosine similarity matrix between working memory states from part 1 versus part 2 in the no memory (NM) condition (part C depicts the orange and blue rows from this matrix). (<bold>E</bold>) PCA plot of working memory states as a function of time, for a large number of events. The plot shows that differences in time within events are represented much more strongly than differences across events. The errorbars indicate 1SE across 15 models.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-74445-fig4-v3.tif"/></fig><p>This advantage occurs because the model’s hidden state strongly encodes temporal context: WM states stored at similar times within an event tend to be more similar than WM states stored at different times (this illustrated by <xref ref-type="fig" rid="fig4">Figure 4E</xref>, which shows that time information within an event is more strongly represented than differences across events). This strong temporal coding makes sense, given that the model needs to know where it is in the sequence in order to predict which observations will come next (for evidence for this kind of temporal coding in the brain, see <xref ref-type="bibr" rid="bib112">Pastalkova et al., 2008</xref>; <xref ref-type="bibr" rid="bib93">MacDonald et al., 2011</xref>; <xref ref-type="bibr" rid="bib135">Salz et al., 2016</xref>; <xref ref-type="bibr" rid="bib154">Tiganj et al., 2017</xref>; for reviews, see <xref ref-type="bibr" rid="bib38">Eichenbaum, 2014</xref>; <xref ref-type="bibr" rid="bib72">Howard and Eichenbaum, 2013</xref>; for models of this temporal coding, see <xref ref-type="bibr" rid="bib144">Shankar and Howard, 2012</xref>; <xref ref-type="bibr" rid="bib73">Howard et al., 2014</xref>; <xref ref-type="bibr" rid="bib89">Liu et al., 2019</xref>). One consequence of this time coding is that – early on in part 2 of the event (when the benefits of episodic retrieval are the largest) – the temporal context represented in working memory will be a better match for memories encoded midway through the event than memories encoded at the end of the event (<xref ref-type="fig" rid="fig4">Figure 4C and D</xref>). This temporal context match provides a competitive advantage for the midway memory over the endpoint memory, resulting in the midway memory blocking the endpoint memory from coming strongly to mind. The second key point is that the midway memory is less informative (i.e., it contains fewer features of the situation, because it was stored before the full set of features was observed). As such, recalling the midway target memory confers less of a benefit on future prediction than recalling the endpoint memory would have provided – this is the main reason why prediction is worse in the midway condition. The third key point is that, because midway memories contain less information, they are more confusable across events (i.e., it is harder to determine which event the memory pertains to). As a result, midway lures tend to become more active at retrieval than endpoint lures (<xref ref-type="fig" rid="fig4">Figure 4B</xref>) – this lure retrieval acts to further reduce prediction accuracy.</p><p>A possible alternative explanation of the negative effects of midway encoding is that midway encoding was introduced when we tested the model’s performance but was not present during meta-training (i.e., when the model acquired its retrieval policy); as such, midway encoding can be viewed as ‘out of distribution’ and may be harmful for this reason. To address this concern, we also ran a version of the model where memories were stored both midway and at the end of an event during meta-training, and it was still true that endpoint-only encoding led to better performance than midway-plus-endpoint encoding; this result shows that midway encoding is intrinsically harmful, and it is not just a matter of it being out-of-distribution. In another simulation, we also found that the harmful effect of encoding midway through the sequence qualitatively replicates with more complex event structures (analogous to those in <xref ref-type="bibr" rid="bib17">Botvinick and Plaut, 2004</xref>) where queries are repeated within a sequence and the model has to give a different response to the first vs. second occurrence of a query (e.g., mood is controlled first by weather and later by music).</p><p>To summarize the results from this section, the model does better when we force it to wait until the end of an event to take a snapshot. This pattern arises in our simulations because knowledge of the ongoing situation builds within an event, so memories encoded earlier in the event contain less information about the situation than memories encoded at the end. These less-informative midway memories harm performance by interfering with recall of more-informative endpoint memories, and are themselves more prone to false recall (because they are more confusable across events). Taken together, these simulation results provide a resource-rational justification for the results cited above showing preferential encoding-related hippocampal activity at the end of events (<xref ref-type="bibr" rid="bib12">Ben-Yakov and Dudai, 2011</xref>; <xref ref-type="bibr" rid="bib13">Ben-Yakov et al., 2013</xref>; <xref ref-type="bibr" rid="bib9">Baldassano et al., 2017</xref>; <xref ref-type="bibr" rid="bib14">Ben-Yakov and Henson, 2018</xref>; <xref ref-type="bibr" rid="bib126">Reagh et al., 2020</xref>).</p></sec></sec><sec id="s3" sec-type="discussion"><title>Discussion</title><p>Most of what we know about episodic memory has, by design, come from experiments where performance depends primarily on episodic memory (as opposed to other memory systems), and participants are given clear instructions about when episodic memories should be stored and retrieved (e.g., learning and recalling lists of random word pairs); likewise, most computational models of human memory have focused on explaining findings from these kinds of experiments (e.g., see <xref ref-type="bibr" rid="bib52">Gillund and Shiffrin, 1984</xref>; <xref ref-type="bibr" rid="bib63">Hasselmo and Wyble, 1997</xref>; <xref ref-type="bibr" rid="bib146">Shiffrin and Steyvers, 1997</xref>; <xref ref-type="bibr" rid="bib71">Howard and Kahana, 2002</xref>; <xref ref-type="bibr" rid="bib106">Norman and O’Reilly, 2003</xref>; <xref ref-type="bibr" rid="bib143">Sederberg et al., 2008</xref>; <xref ref-type="bibr" rid="bib118">Polyn et al., 2009</xref>; <xref ref-type="bibr" rid="bib28">Cox and Criss, 2020</xref>; for reviews, see <xref ref-type="bibr" rid="bib108">Norman et al., 2008</xref>; <xref ref-type="bibr" rid="bib29">Criss and Howard, 2015</xref>). However, as noted in the <italic>Introduction</italic>, real-world memory does not adhere to these constraints: In naturalistic learning situations, participants are typically not given any instructions about how episodic memory should be used to support performance, and – even when participants are given instructions about what to remember – performance usually depends on a complex mix of memory systems, with contributions from both working memory and semantic memory in addition to episodic memory.</p><p>The goal of the present work was to gain some theoretical traction on when episodic memories should be stored and retrieved to optimize performance in these more complex situations. Towards this end, we optimized a neural network model that <italic>learned its own policy</italic> for when to consult episodic memory (via an adjustable gate) in order to maximize reward, and we also (by hand) explored the effects of different episodic memory encoding policies on network performance. Our approach is built on the principle of resource rationality, whereby human cognition is viewed as an approximately optimal solution to the learning challenges posed by the environment, subject to constraints imposed by our cognitive architecture (<xref ref-type="bibr" rid="bib58">Griffiths et al., 2015</xref>; <xref ref-type="bibr" rid="bib88">Lieder and Griffiths, 2019</xref>); according to this principle, the approximately optimal solutions obtained by our model can be viewed as hypotheses about (and explanations of) how humans use episodic memory in complex, real-world tasks.</p><p>In the simulations presented here, we identified several ways in which selective policies for episodic memory retrieval and encoding can benefit performance. With regard to retrieval, we showed that the model learns to avoid episodic retrieval in situations where the risks of retrieval (i.e., retrieving the wrong memory, leading to incorrect predictions) outweigh the benefits (i.e., retrieving the correct memory, leading to increased correct predictions). For example, when there is high certainty about what will be observed next (due to the relevant information being maintained in working memory or semantic memory), the marginal benefits of retrieving from episodic memory are too small to outweigh the risks of retrieving the wrong memory. Another example is when too little information has been observed to pinpoint the relevant memory – in this case, the potential benefits of retrieving are high, but the risks of retrieving the wrong memory are also high, leading the model to defer retrieving until more information has been observed. With regard to encoding, we showed that waiting until the end of an event to encode a memory for that event boosts subsequent prediction performance – this performance boost comes from reducing ‘clutter’ (interference) from other memories, thereby making it easier to retrieve the sought-after memory. These modeling results explain a wide range of existing behavioral and neuroimaging results, and also lead to new, testable predictions. With regard to existing results: The model provides a resource-rational account of findings from <xref ref-type="bibr" rid="bib24">Chen et al., 2016</xref> showing the demand-sensitivity of episodic retrieval, as well as results showing that episodic encoding is modulated by event boundaries (<xref ref-type="bibr" rid="bib12">Ben-Yakov and Dudai, 2011</xref>; <xref ref-type="bibr" rid="bib13">Ben-Yakov et al., 2013</xref>; <xref ref-type="bibr" rid="bib9">Baldassano et al., 2017</xref>; <xref ref-type="bibr" rid="bib14">Ben-Yakov and Henson, 2018</xref>; <xref ref-type="bibr" rid="bib126">Reagh et al., 2020</xref>). <italic>Appendix 3</italic> also shows how the model explains effects of familiarity on retrieval policy (<xref ref-type="bibr" rid="bib34">Duncan et al., 2012</xref>; <xref ref-type="bibr" rid="bib35">Duncan and Shohamy, 2016</xref>; <xref ref-type="bibr" rid="bib37">Duncan et al., 2019</xref>; <xref ref-type="bibr" rid="bib115">Patil and Duncan, 2018</xref>; <xref ref-type="bibr" rid="bib63">Hasselmo and Wyble, 1997</xref>). With regard to novel predictions: Our model makes predictions about how episodic retrieval will be modulated by certainty (<xref ref-type="fig" rid="fig3">Figure 3B, C and D</xref>), penalty (<xref ref-type="fig" rid="fig3">Figure 3E</xref>), schema strength (<xref ref-type="fig" rid="fig3">Figure 3G</xref>), and similarity (<xref ref-type="fig" rid="app2fig1">Appendix 2—figure 1</xref>) – all of these predicted relationships could be tested in experiments that measure hippocampal-neocortical information transfer, either using measures like hippocampal-neocortical inter-subject functional connectivity in fMRI (e.g., <xref ref-type="bibr" rid="bib24">Chen et al., 2016</xref>; <xref ref-type="bibr" rid="bib21">Chang et al., 2021</xref>) or time-lagged mutual information in ECoG (e.g., <xref ref-type="bibr" rid="bib100">Michelmann et al., 2021</xref>).</p><p>More broadly, the simulations presented here show how the model can be used to explore interactions between three distinct memory systems: semantic memory (instantiated in the weights in neocortex), working memory (instantiated in the gating policy learned by the neocortical LSTM module, allowing for activation at one time point in neocortex to influence activation at subsequent time points), and episodic memory. In the past, modelers have focused on these memory systems in isolation (see, e.g., <xref ref-type="bibr" rid="bib108">Norman et al., 2008</xref>), in part because of a desire to understand the detailed workings of the systems, but also because of technical limitations: Until very recently, the technology did not exist to automatically optimize the performance of networks containing episodic memory, so researchers interested in simulating interactions between episodic memory and these other systems were put in the position of having to do time-consuming (and frustrating) hand-optimization of the models. Here, we leverage recent progress in the artificial intelligence literature on memory-augmented neural networks (<xref ref-type="bibr" rid="bib55">Graves et al., 2016</xref>; <xref ref-type="bibr" rid="bib120">Pritzel et al., 2017</xref>; <xref ref-type="bibr" rid="bib129">Ritter et al., 2018</xref>; <xref ref-type="bibr" rid="bib160">Wayne et al., 2018</xref>) that makes it possible to automatically optimize the use of episodic memory and its interactions with other memory systems. This technical advance has opened up a new frontier in the cognitive modeling of memory (<xref ref-type="bibr" rid="bib26">Collins, 2019</xref>), making it possible to address both ‘naturalistic memory’ scenarios and controlled experiments that involve interactions between prior knowledge (semantic memory), active maintenance (working memory), and episodic memory.</p><sec id="s3-1"><title>Relation to other models</title><sec id="s3-1-1"><title>Memory-augmented neural networks with a differentiable neural dictionary</title><p>Conceptually, the episodic memory system used in our model is similar to recently-described memory-augmented neural networks with a differentiable neural dictionary (DND) (<xref ref-type="bibr" rid="bib120">Pritzel et al., 2017</xref>; <xref ref-type="bibr" rid="bib129">Ritter et al., 2018</xref>; <xref ref-type="bibr" rid="bib130">Ritter, 2019</xref>). In these models, the data structure of the episodic memory system is dictionary-like: Each memory is a key-value pair. The keys define the similarity metric across all memories, and the values represent the content of these memories. For example, one can use the LSTM cell state patterns as the keys and use the final output of the network as the values (<xref ref-type="bibr" rid="bib120">Pritzel et al., 2017</xref>). <xref ref-type="bibr" rid="bib129">Ritter et al., 2018</xref> is particularly relevant as it was the first paper (to our knowledge) to use the DND for cognitive modeling and – as such – served as a major inspiration for the work presented here (see also <xref ref-type="bibr" rid="bib18">Botvinick et al., 2019</xref>). The way that our model uses the DND mechanism is quite similar to how it was used in <xref ref-type="bibr" rid="bib129">Ritter et al., 2018</xref>; in particular, we took from the <xref ref-type="bibr" rid="bib129">Ritter et al., 2018</xref> paper the idea that the neocortical network learns to control a ‘gate’ on episodic retrieval via reinforcement learning (for an earlier model that also used reinforcement learning to learn a policy for retrieval from episodic memory, see <xref ref-type="bibr" rid="bib168">Zilli and Hasselmo, 2008</xref>). However, there are also some meaningful differences between our model and the model used by <xref ref-type="bibr" rid="bib129">Ritter et al., 2018</xref>.</p><p>The most salient difference regards the placement of the EM gate: In our model, the gate controls the flow of information into the episodic memory module (<italic>pre-gating</italic>), but in the Ritter model the gate controls the flow of information <italic>out</italic> of the episodic memory module (<italic>post-gating</italic>). Practically speaking, the main consequence of having the gate on the output side is that the gate can be controlled based on information coming out of the hippocampus, in addition to all of the neocortical regions that are used to control the gate in our pre-gating model. While this is a major difference, we found that our key simulation results qualitatively replicate in a version of the model that uses post-gating, indicating that the selective encoding and retrieval principles discussed here do not depend on the exact placement of the gate (see <italic>Appendix 4</italic> for simulation results and more discussion of these points).</p><p>Another difference is that our model’s computation of which memories are retrieved (given a particular retrieval cue, assuming that the ‘gate’ on retrieval is open) is more complex. <xref ref-type="bibr" rid="bib129">Ritter et al., 2018</xref> used a one-nearest-neighbor matching algorithm during recall, whereby the stored memory with the highest match to the cue is selected for retrieval (assuming that the gate is open). By contrast, memory activation in our model is computed using a competitive evidence accumulation process, in line with prior cognitive models of retrieval (e.g., <xref ref-type="bibr" rid="bib118">Polyn et al., 2009</xref>; <xref ref-type="bibr" rid="bib143">Sederberg et al., 2008</xref>). While we did not explore the effects of varying the level of competition in our simulations, having this as an adjustable parameter opens the door to future work where the model learns a policy for setting competition in order to optimize performance (just as it presently learns a policy for setting the EM gate).</p><p>A third structural difference between our model and the <xref ref-type="bibr" rid="bib129">Ritter et al., 2018</xref> model is our addition of the ‘don’t know’ output unit, which (when selected) allows the model to avoid both reward and punishment. As discussed above, the primary effect of incorporating this ‘don’t know’ action is to make the model more patient (i.e., more likely to wait to retrieve from episodic memory), by giving it a way to avoid incurring penalties if it decides to wait to retrieve (for more details, see <italic>Appendix 5</italic>).</p><p>Apart from the structural differences noted above, the main difference between our modeling work and the work done by <xref ref-type="bibr" rid="bib129">Ritter et al., 2018</xref> relates to the application domain (i.e., which cognitive phenomena were simulated). Our modeling work in this paper focused on how episodic memory can support incidental prediction of upcoming states, when there is no explicit demand for a decision. By contrast, <xref ref-type="bibr" rid="bib129">Ritter et al., 2018</xref> focused on how episodic memory can be used to support performance in classic decision-making tasks, such as bandit tasks and maze learning, that have been extensively explored in the reinforcement learning literature.</p></sec><sec id="s3-1-2"><title>The structured event memory (SEM) model</title><p>Another highly relevant model is the structured event memory (SEM) model developed by <xref ref-type="bibr" rid="bib47">Franklin et al., 2020</xref>. Like our model, SEM uses RNNs to represent its knowledge of schemas (i.e., how events typically unfold). Also, like our model, SEM records episodic memory traces as it processes events. However, there are several key differences between our model and SEM. First, whereas our model uses a single RNN to represent a single (contextually parameterized) schema, SEM uses multiple RNNs that each represent a distinct schema for how events can unfold. Building on prior work on nonparametric Bayesian inference (<xref ref-type="bibr" rid="bib2">Anderson, 1991</xref>; <xref ref-type="bibr" rid="bib1">Aldous, 1983</xref>; <xref ref-type="bibr" rid="bib117">Pitman, 2006</xref>) and latent cause modeling (<xref ref-type="bibr" rid="bib48">Gershman et al., 2010</xref>; <xref ref-type="bibr" rid="bib49">Gershman et al., 2015</xref>), SEM contains specialized computational machinery that allows it to determine which of its stored schemas (each with its own RNN) is relevant at a particular moment, and also when it is appropriate to instantiate a new schema (with its own, new RNN) to learn about ongoing events. This inference machinery allows SEM to infer when event boundaries (i.e., switches in the relevant schema) have occurred; the <xref ref-type="bibr" rid="bib47">Franklin et al., 2020</xref> paper leverages this to account for data on how people segment events. Our model lacks this inference machinery, so we need to impose event boundaries by fiat, as opposed to having the model identify them on their own.</p><p>Another major difference between the models relates to how episodic memory is used. A key focus of our modeling work in this paper is on how episodic memory can support online prediction. By contrast, in SEM, episodic memory is not used at all for online prediction – online prediction is based purely on the weights of the RNNs (i.e., semantic memory) and the activation patterns in the RNNs (i.e., working memory). The sole use of episodic memory in the <xref ref-type="bibr" rid="bib47">Franklin et al., 2020</xref> paper is to support reconstruction of previously-experienced events. Specifically, in SEM, each time point leaves behind a noisy episodic trace; the <xref ref-type="bibr" rid="bib47">Franklin et al., 2020</xref> paper shows how Bayesian inference can combine these noisy stored episodic memory traces with stored knowledge about how events typically unfold (in the RNNs) to reconstruct an event. Effectively, SEM uses knowledge in the RNNs to ‘de-noise‘ and fill in gaps in the stored episodic traces. The <xref ref-type="bibr" rid="bib47">Franklin et al., 2020</xref> paper uses this process to account for several findings relating to human reconstructive memory.</p></sec></sec><sec id="s3-2"><title>Future directions and limitations</title><p>On the modeling side, our work can be extended in several different ways. As noted above, our model and SEM have complementary strengths: SEM is capable of storing multiple schemas and doing event segmentation, whereas our model only stores a single schema and we impose event boundaries by hand; our model is capable of using episodic memory to support online prediction, whereas SEM is not. It is easy to see how these complementary strengths could be combined into a single model: By adding SEM’s ability to do multi-schema inference to our model, we would be able to simulate both event segmentation and the role of episodic memory in predicting upcoming states, and we would also be able to explore <italic>interactions</italic> between these processes (e.g., using episodic memory to predict could affect when prediction errors occur, which – in turn – could affect how events are segmented; <xref ref-type="bibr" rid="bib165">Zacks et al., 2011</xref>; <xref ref-type="bibr" rid="bib164">Zacks et al., 2007</xref>).</p><p>Another limitation of the current model is that the encoding policy is not learned. In our simulations, we trained models with different (pre-specified) encoding policies and compared their performance. Going forward, we would like to develop models that learn when to encode through experience, instead of imposing encoding policies by hand. Our results show that selective encoding can yield better performance than encoding everything, so – in principle – selective encoding policies should be learnable with RL. The main challenge in learning encoding policies is the long temporal gap between the decision to encode (or not) and learning the consequences of that choice for retrieval. Moreover, a high-quality encoding policy, taken on its own, generally does not lead to high reward when the retrieval policy is bad; that is, encoding policy and retrieval policy have to be learned in a highly coordinated fashion. Recent technical advances in RL (e.g., algorithms that do credit assignment across long temporal gaps; <xref ref-type="bibr" rid="bib125">Raposo et al., 2021</xref>) may make it easier to address these challenges going forward.</p><p>A benefit of being able to learn encoding policies in response to different task demands is that the model could discover other factors that it could use to modulate encoding – for example, surprise. Numerous studies have found improved memory for surprising events (e.g., <xref ref-type="bibr" rid="bib56">Greve et al., 2017</xref>; <xref ref-type="bibr" rid="bib57">Greve et al., 2019</xref>; <xref ref-type="bibr" rid="bib121">Quent et al., 2021a</xref>; <xref ref-type="bibr" rid="bib76">Kafkas and Montaldi, 2018</xref>; <xref ref-type="bibr" rid="bib44">Frank et al., 2020</xref>; <xref ref-type="bibr" rid="bib133">Rouhani et al., 2018</xref>; <xref ref-type="bibr" rid="bib134">Rouhani et al., 2020</xref>; <xref ref-type="bibr" rid="bib22">Chen et al., 2015a</xref>; <xref ref-type="bibr" rid="bib116">Pine et al., 2018</xref>; <xref ref-type="bibr" rid="bib5">Antony et al., 2021</xref>; for reviews, see <xref ref-type="bibr" rid="bib45">Frank and Kafkas, 2021a</xref>; <xref ref-type="bibr" rid="bib122">Quent et al., 2021b</xref>) – these behavioral results converge with a large body of literature showing increased hippocampal engagement in response to prediction error (e.g., <xref ref-type="bibr" rid="bib6">Axmacher et al., 2010</xref>; <xref ref-type="bibr" rid="bib22">Chen et al., 2015a</xref>; <xref ref-type="bibr" rid="bib90">Long et al., 2016</xref>; <xref ref-type="bibr" rid="bib84">Kumaran and Maguire, 2006</xref>; <xref ref-type="bibr" rid="bib85">Kumaran and Maguire, 2007</xref>; <xref ref-type="bibr" rid="bib34">Duncan et al., 2012</xref>; <xref ref-type="bibr" rid="bib31">Davidow et al., 2016</xref>; <xref ref-type="bibr" rid="bib75">Kafkas and Montaldi, 2015</xref>; <xref ref-type="bibr" rid="bib46">Frank et al., 2021b</xref>; for reviews, see <xref ref-type="bibr" rid="bib45">Frank and Kafkas, 2021a</xref>; <xref ref-type="bibr" rid="bib122">Quent et al., 2021b</xref>), and also with a recent fMRI study showing that prediction error biases hippocampal dynamics towards encoding (<xref ref-type="bibr" rid="bib11">Bein et al., 2020</xref>). Given that studies have found a strong relationship between surprise and event segmentation (e.g., <xref ref-type="bibr" rid="bib165">Zacks et al., 2011</xref>; <xref ref-type="bibr" rid="bib164">Zacks et al., 2007</xref>; for a recent example see <xref ref-type="bibr" rid="bib5">Antony et al., 2021</xref>), it seems possible that increased episodic encoding at the ends of events could be driven by peaks in surprise that occur at event boundaries. However, there are complications to this view; in particular, some recent work has argued that not all event boundaries are surprising (<xref ref-type="bibr" rid="bib139">Schapiro et al., 2013</xref>) – in light of this, more research is needed to explore the relationship between these effects.</p><p>In addition to surprise, recent work by <xref ref-type="bibr" rid="bib145">Sherman and Turk-Browne, 2020</xref> suggests that <italic>predictive certainty</italic> may play a role in shaping encoding policy: They found that stimuli that trigger strong predictions (i.e., high certainty about upcoming events) are encoded less well. In keeping with this point, <xref ref-type="bibr" rid="bib16">Bonasia et al., 2018</xref> found that, during episodic encoding, events that were more typical (and thus were associated with more predictive certainty, and less surprise) were associated with lower levels of medial temporal lobe (MTL) activation. Intuitively, it makes sense to focus episodic encoding on time periods where there is high surprise and low predictive certainty – if events in a sequence are unsurprising and associated with high predictive certainty, this means that existing (neocortical) schemas are sufficient to reconstruct that event, and no new learning is necessary (or, if learning is required, it is possible that neocortex could handle this ‘schema-consistent’ learning on its own; <xref ref-type="bibr" rid="bib97">McClelland, 2013</xref>; <xref ref-type="bibr" rid="bib98">McClelland et al., 2020</xref>). Conversely, if events in a sequence do not follow a schema (leading to uncertainty) or violate that schema (leading to surprise), the only way to predict those events later will be to store them in episodic memory. Future work can explore whether a model that represents surprise and certainty (either implicitly or explicitly) can learn to leverage one or both of these factors when deciding when to encode; our present model is a good place to start in this regard, as we have already demonstrated the model’s ability to factor certainty into its retrieval policy.</p><p>Another major simplification in the model’s encoding policy is that it stores each episodic memory as a distinct entity (see <xref ref-type="fig" rid="fig1">Figure 1B</xref>). Old memories are never overwritten or updated. However, a growing literature on memory reconsolidation suggests that memory reminders can result in participants accessing an existing memory and then updating that memory, rather than forming a new memory outright (<xref ref-type="bibr" rid="bib32">Dudai and Eisenberg, 2004</xref>; <xref ref-type="bibr" rid="bib33">Dudai, 2009</xref>; <xref ref-type="bibr" rid="bib60">Hardt et al., 2010</xref>; <xref ref-type="bibr" rid="bib158">Wang and Morris, 2010</xref>). In the future, we would like to develop models that decide whether to encode a new episodic memory or update an old memory. We could implement this by having the model try to retrieve before it encodes a new memory; if it succeeds in retrieving a stored memory above a certain threshold level of activation, the model could update that memory rather than creating a new memory. In future work, we plan to implement this mechanism and use it to simulate memory reconsolidation data.</p><p>Going forward, we also hope to explore more biologically-realistic episodic memory models (e.g., <xref ref-type="bibr" rid="bib63">Hasselmo and Wyble, 1997</xref>; <xref ref-type="bibr" rid="bib141">Schapiro et al., 2017</xref>; <xref ref-type="bibr" rid="bib106">Norman and O’Reilly, 2003</xref>; <xref ref-type="bibr" rid="bib78">Ketz et al., 2013</xref>). Using a more biologically realistic hippocampus could affect the model’s predictions (e.g., if memory traces were allowed to interfere with each other during storage – currently they only interfere at retrieval) and it would also improve our ability to connect the model to neural data on hippocampal codes and how they change with learning (e.g., <xref ref-type="bibr" rid="bib36">Duncan and Schlichting, 2018</xref>; <xref ref-type="bibr" rid="bib19">Brunec et al., 2020</xref>; <xref ref-type="bibr" rid="bib131">Ritvo et al., 2019</xref>; <xref ref-type="bibr" rid="bib43">Favila et al., 2016</xref>; <xref ref-type="bibr" rid="bib20">Chanales et al., 2017</xref>; <xref ref-type="bibr" rid="bib142">Schlichting et al., 2015</xref>; <xref ref-type="bibr" rid="bib161">Whittington et al., 2020</xref>; <xref ref-type="bibr" rid="bib150">Stachenfeld et al., 2017</xref>; <xref ref-type="bibr" rid="bib74">Hulbert and Norman, 2015</xref>; <xref ref-type="bibr" rid="bib79">Kim et al., 2017</xref>; <xref ref-type="bibr" rid="bib138">Schapiro et al., 2012</xref>; <xref ref-type="bibr" rid="bib140">Schapiro et al., 2016</xref>). Similarly, using a more biologically-detailed neocortical model (separated into distinct neocortical sub-regions) could help us to connect to data on how different neocortical regions interact with hippocampus during event processing (e.g., <xref ref-type="bibr" rid="bib124">Ranganath and Ritchey, 2012</xref>; <xref ref-type="bibr" rid="bib27">Cooper and Ritchey, 2020</xref>; <xref ref-type="bibr" rid="bib128">Ritchey and Cooper, 2020</xref>; <xref ref-type="bibr" rid="bib10">Barnett et al., 2020</xref>; <xref ref-type="bibr" rid="bib51">Gilboa and Marlatte, 2017</xref>; <xref ref-type="bibr" rid="bib156">van Kesteren et al., 2012</xref>; <xref ref-type="bibr" rid="bib119">Preston and Eichenbaum, 2013</xref>). More generally, the simplified nature of the present model (e.g., using rate-coded neurons, training with gradient descent) limits its ability to connect to circuit-level data. Including more detailed circuit-level mechanisms would allow us to leverage the wealth of data that exist at this level to constrain the model. For example, work by Hasselmo and colleagues has shown how cholinergic projections from the basal forebrain to the hippocampus can shift hippocampal dynamics between encoding and retrieval based on whether the retrieval cue is novel or familiar (<xref ref-type="bibr" rid="bib61">Hasselmo et al., 1995</xref>; <xref ref-type="bibr" rid="bib62">Hasselmo et al., 1996</xref>; <xref ref-type="bibr" rid="bib63">Hasselmo and Wyble, 1997</xref>); this work could be used to inform our simulations (discussed in <italic>Appendix 3</italic>) of how familiarity signals modulate hippocampal retrieval policy. We have opted to start with the simplified episodic memory system described in this paper both for reasons of scientific parsimony and also for practical reasons – adding additional neurobiological details would make the model run too slowly (the current model takes on the order of hours to run on standard computers; adding more complexity would shift this to days or weeks).</p><p>Just as our model contains some key simplifications, the environment used in the event processing task is relatively simple and do not capture the full richness of naturalistic events. Some recent studies have explored event graphs with more realistic structure (e.g., <xref ref-type="bibr" rid="bib39">Elman and McRae, 2019</xref>). The fact that our model can presently only handle one schema substantially limits the complexity of the sequences it can process; adding the ability to handle multiple schemas (as discussed above) will help to address this limitation. Also, natural events unfold over multiple timescales. For example, going to the parking lot is an event that involves finding the key, getting to the elevator, etc., but this can be viewed as part of a higher-level event, such as going to an airport. In our simulation, events only have one timescale. In general, introducing additional hierarchical structure to the stimuli would enrich the task demands and lead to interesting modeling challenges. For now, we have avoided more complex task environments for computational tractability reasons, but – as computational resources continue to grow – we hope to be able to investigate richer and more realistic task environments going forward. At the same time, we also plan to use the model to address selective retrieval and encoding effects in list-learning studies (e.g., the aforementioned studies showing that surprise boosts encoding; for reviews, see <xref ref-type="bibr" rid="bib45">Frank and Kafkas, 2021a</xref>; <xref ref-type="bibr" rid="bib122">Quent et al., 2021b</xref>).</p><p>Another limitation of the model is that the policies explored here (having to do with when episodic memory snapshots are stored and retrieved) do not encompass the full range of ways in which the use of episodic memory can be optimized. For example, in addition to questions about <italic>when</italic> to encode and retrieve, one can consider optimizations of what is stored in memory and how memory is cued. These kinds of optimizations are evident in mnemonic techniques like the method of loci (<xref ref-type="bibr" rid="bib162">Yates, 1966</xref>), which involve considerable recoding of to-be-learned information (to maximize distinctiveness of stored memories) and also structured cuing strategies (to ensure that these distinctive memory traces can be found after they are stored). We think that the kinds of policies explored in this paper (e.g., retrieving more when uncertain, encoding more at the end of an event) fall more on the ‘automatic’ end of the spectrum, as evidenced by the fact that they require no special training and are deployed even in incidental learning situations (e.g., while people are watching a movie, without specifically trying to remember it; <xref ref-type="bibr" rid="bib24">Chen et al., 2016</xref>; <xref ref-type="bibr" rid="bib9">Baldassano et al., 2017</xref>). As such, these policies seem very different from more complex and deliberate kinds of mnemonic strategies like method of loci that require special training. However, we think that it is best to view our ‘simple’ policies and more complex strategies as falling on a continuum. While the policies we discuss may be deployed automatically in adults, our simulations show that at least some of these policies (e.g., modulating episodic retrieval based on predictive certainty) can be learned through experience, and indeed these strategies might not (yet) be automatic in young children. Furthermore, in principle, there is nothing stopping a model like ours from learning more elaborate strategies given the right kinds of experience and a rich enough action space. Expanding the space of ‘memory use policies’ for our model and exploring how these can be learned is an important future direction for this work (for a resource-rational approach to memory search, see <xref ref-type="bibr" rid="bib167">Zhang et al., 2021</xref>).</p><p>Lastly, although we have focused on cognitive modeling in this paper, we think that some of our results have implications for machine learning more broadly. For example, most memory-augmented neural networks used in machine learning encode at each time point (<xref ref-type="bibr" rid="bib54">Graves et al., 2014</xref>; <xref ref-type="bibr" rid="bib55">Graves et al., 2016</xref>; <xref ref-type="bibr" rid="bib129">Ritter et al., 2018</xref>; <xref ref-type="bibr" rid="bib120">Pritzel et al., 2017</xref>). Our results provide initial evidence that taking episodic ‘snapshots’ too frequently can actually harm performance. Future work can explore the circumstances under which more selective encoding and retrieval policies might lead to improved performance on machine learning benchmarks. Based on our simulations, we expect that these selective policies will be most useful when there is a substantial risk of recalling lure memories that lead to incorrect predictions, and a substantial cost associated with making these incorrect predictions.</p></sec><sec id="s3-3"><title>Summary</title><p>The modeling work presented here builds on a wide range of research showing that episodic memory is a resource that the brain can flexibly draw upon to solve tasks (see, e.g., <xref ref-type="bibr" rid="bib147">Shohamy and Turk-Browne, 2013</xref>; <xref ref-type="bibr" rid="bib111">Palombo et al., 2019</xref>; <xref ref-type="bibr" rid="bib110">Palombo et al., 2015</xref>; <xref ref-type="bibr" rid="bib8">Bakkour et al., 2019</xref>; <xref ref-type="bibr" rid="bib15">Biderman et al., 2020</xref>). This view implies that, in addition to studying episodic memory using tasks that probe this system in isolation, it is also valuable to study how episodic memory is used in more complex situations, in concert with working memory and semantic memory, to solve tasks and make predictions. To engage with findings of these sort, we have leveraged advances in AI that make it possible for models to learn how to use episodic memory – our simulations provide a way of predicting how episodic memory should be deployed to obtain rewards, as a function of the properties of the learning environment. While our understanding of these more complex situations is still at an early stage, our hope is that this model (and others like it, such as the model by <xref ref-type="bibr" rid="bib129">Ritter et al., 2018</xref>) can spur a virtuous cycle of predictions, experiments, and model revision that will bring us to a richer understanding of how the brain uses episodic memory.</p></sec></sec><sec id="s4" sec-type="methods"><title>Methods</title><sec id="s4-1"><title>Episodic retrieval</title><p>Episodic retrieval in our model is content-based. The retrieval process returns a weighted average of all episodic memories, where the weight of each memory is equal to its activation; to calculate the activation for each memory, the model executes an evidence accumulation process using a leaky competing accumulator (LCA; <xref ref-type="bibr" rid="bib155">Usher and McClelland, 2001</xref>), which has been used in other memory models (e.g., <xref ref-type="bibr" rid="bib143">Sederberg et al., 2008</xref>; <xref ref-type="bibr" rid="bib118">Polyn et al., 2009</xref>). The evidence for a given episodic memory is the cosine similarity between that memory and the current neocortical pattern (the cell state of the LSTM). Hence, memories that are similar to the current neocortical pattern will have a larger influence on the pattern that gets reinstated.</p><p>The evidence accumulation process is governed by the episodic memory gate (EM gate) and the level of competition across memories (<xref ref-type="fig" rid="fig1">Figure 1C</xref>), which are stored separately from each other (<xref ref-type="fig" rid="fig1">Figure 1B</xref>). The EM gate is controlled by the neocortical network (<xref ref-type="fig" rid="fig1">Figure 1A and C</xref>). The EM gate, in turn, controls whether episodic retrieval happens – a higher EM gate value increases the activation of all memories, and setting the EM gate value to zero turns off episodic retrieval completely (see <italic>Appendix 4</italic> for discussion of other ways that gating can be configured). The level of competition (i.e., lateral inhibition) adjusts the contrast of activations across all memories; making the level of competition higher or lower interpolates between one-winner-take-all recall versus recalling an average of multiple memories. In all of our simulations, we set the level of competition to be well above zero (0.8, to be exact), given the overwhelming evidence that episodic retrieval is competitive (<xref ref-type="bibr" rid="bib3">Anderson and Reder, 1999</xref>; <xref ref-type="bibr" rid="bib106">Norman and O’Reilly, 2003</xref>; <xref ref-type="bibr" rid="bib109">Norman, 2010</xref>).</p><p>Note that, instead of optimizing the LCA parameters to fit empirical results (e.g., as in the work by <xref ref-type="bibr" rid="bib118">Polyn et al., 2009</xref>), we use a neural network that learns to control the level of the EM gate value. As described below, in the <italic>Model training and testing</italic> section, the model’s goal is to maximize reward by making correct predictions and avoiding incorrect predictions; the network learns a policy for setting the EM gate value that maximizes the reward it receives. We made several simplifications to the original LCA – in our model, the LCA (1) has no leak; (2) has no noise; and (3) uses the same EM gate value and competition value for all accumulators.</p><sec id="s4-1-1"><title>Episodic retrieval - detail</title><p>At time <inline-formula><mml:math id="inf1"><mml:mi>t</mml:mi></mml:math></inline-formula>, assume the model has <inline-formula><mml:math id="inf2"><mml:mi>n</mml:mi></mml:math></inline-formula> memories. The model first computes the evidence for all of the memories. The evidence for the <italic>i</italic>-th memory, <inline-formula><mml:math id="inf3"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>m</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula>, is the cosine similarity between the current LSTM cell state pattern <inline-formula><mml:math id="inf4"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>c</mml:mi><mml:mi>t</mml:mi></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula> and that episodic memory – which is a previously saved LSTM cell state pattern. We denote the evidence for the <italic>i</italic>-th memory as <inline-formula><mml:math id="inf5"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>x</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula>:<disp-formula id="equ1"><mml:math id="m1"><mml:mrow><mml:msub><mml:mi>x</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mtext>cosine</mml:mtext></mml:mstyle><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>c</mml:mi><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>m</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></disp-formula></p><p>The <inline-formula><mml:math id="inf6"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>x</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula>, for all <italic>i</italic>, are the input to the evidence accumulation (LCA) process used in our model; the evidence accumulation process has a timescale <inline-formula><mml:math id="inf7"><mml:mi>τ</mml:mi></mml:math></inline-formula> that is faster than <inline-formula><mml:math id="inf8"><mml:mi>t</mml:mi></mml:math></inline-formula>, such that the accumulation process runs to completion within a single time point of the neocortical model. The computation at time <inline-formula><mml:math id="inf9"><mml:mi>τ</mml:mi></mml:math></inline-formula> (for <inline-formula><mml:math id="inf10"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>τ</mml:mi><mml:mo>&gt;</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:mstyle></mml:math></inline-formula>) is governed by the following formula:<disp-formula id="equ2"><mml:math id="m2"><mml:mrow><mml:msubsup><mml:mi>w</mml:mi><mml:mrow><mml:mi>τ</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msubsup><mml:mo>=</mml:mo><mml:mrow><mml:mi mathvariant="normal">r</mml:mi><mml:mi mathvariant="normal">e</mml:mi><mml:mi mathvariant="normal">l</mml:mi><mml:mi mathvariant="normal">u</mml:mi></mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>α</mml:mi><mml:msub><mml:mi mathvariant="normal">x</mml:mi><mml:mrow><mml:mi mathvariant="normal">i</mml:mi></mml:mrow></mml:msub><mml:mo>−</mml:mo><mml:mi>β</mml:mi><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:munder><mml:mo>∑</mml:mo><mml:mrow><mml:mi mathvariant="normal">j</mml:mi><mml:mo>≠</mml:mo><mml:mi mathvariant="normal">i</mml:mi></mml:mrow></mml:munder><mml:msubsup><mml:mi mathvariant="normal">w</mml:mi><mml:mrow><mml:mi>τ</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">j</mml:mi></mml:mrow></mml:msubsup></mml:mrow></mml:mstyle></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></disp-formula></p><p><inline-formula><mml:math id="inf11"><mml:msubsup><mml:mi>w</mml:mi><mml:mi>τ</mml:mi><mml:mi>i</mml:mi></mml:msubsup></mml:math></inline-formula> is the activation value for the <italic>i</italic>-th memory at time <inline-formula><mml:math id="inf12"><mml:mi>τ</mml:mi></mml:math></inline-formula>; these activations are set to zero initially (<inline-formula><mml:math id="inf13"><mml:mrow><mml:msubsup><mml:mi>w</mml:mi><mml:mn>0</mml:mn><mml:mi>i</mml:mi></mml:msubsup><mml:mo>=</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:math></inline-formula>, for all <italic>i</italic>). The activation for the <italic>i</italic>-th memory is positively related to its evidence, <inline-formula><mml:math id="inf14"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>x</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula>, and is multiplicatively modulated by <inline-formula><mml:math id="inf15"><mml:mi>α</mml:mi></mml:math></inline-formula>, the EM gate value. The <italic>i</italic>-th memory also receives inhibition from all of the other memories, where the level of inhibition is modulated by the level of competition, <inline-formula><mml:math id="inf16"><mml:mi>β</mml:mi></mml:math></inline-formula>. Finally, the retrieved item at time <inline-formula><mml:math id="inf17"><mml:mi>t</mml:mi></mml:math></inline-formula>, denoted by <inline-formula><mml:math id="inf18"><mml:msub><mml:mi>μ</mml:mi><mml:mi>t</mml:mi></mml:msub></mml:math></inline-formula>, is a combination of all memories, weighted by their activation:<disp-formula id="equ3"><mml:math id="m3"><mml:mrow><mml:msub><mml:mi>μ</mml:mi><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:munderover><mml:mo>∑</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>n</mml:mi></mml:mrow></mml:munderover><mml:msub><mml:mi>w</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:msub><mml:mi>m</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:mrow></mml:math></disp-formula></p></sec></sec><sec id="s4-2"><title>Model training and Testing</title><sec id="s4-2-1"><title>Model training</title><p>Before the model is used to simulate any particular experiment, it undergoes a <italic>meta-training</italic> phase that is meant to reflect the experience that a person has prior to the experiment. The goal of this meta-training phase is to let the model learn (1) the structure of the task – how situation features control the transition dynamics across states; and (2) a policy for retrieving episodic memories and for making next-state predictions that maximizes the reward it receives. For every epoch of meta-training, it is trained for all three conditions (recent memory, distant memory, and no memory).</p><p>The model is trained with reinforcement learning. Specifically, the model is rewarded/penalized if its prediction about the next state is correct/incorrect. The model also has the option of saying ‘don’t know’ (implemented as a dedicated output unit) when it is uncertain about what will happen next; if the model says ‘don’t know’, the reward is zero. The inclusion of this ‘don’t know’ unit is what motivated us to use reinforcement learning as opposed to purely supervised training. We expected that the optimal way to deploy this action would vary in complex ways as a function of different parameters (e.g., the penalty on incorrect responding), and we did not want to presume that we knew what the best policy would be. Consequently, we opted to let the model learn its own policy for using the ‘don’t know’ action, rather than imposing a policy through supervised training (see <italic>Appendix 5</italic> for results from a variant of the model where we omit the ‘don’t know’ unit and train the model in a purely supervised fashion; these changes make the model less patient – i.e., retrieval takes place earlier in the sequence – but otherwise the results are qualitatively unchanged).</p><p>The model is trained with the advantage actor-critic (A2C) objective (<xref ref-type="bibr" rid="bib102">Mnih et al., 2016</xref>). At time <inline-formula><mml:math id="inf19"><mml:mi>t</mml:mi></mml:math></inline-formula>, the model outputs its prediction about the next state, <inline-formula><mml:math id="inf20"><mml:msub><mml:mover accent="true"><mml:mi>s</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover><mml:mrow><mml:mi>t</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:math></inline-formula>, and an estimate of the state value, <inline-formula><mml:math id="inf21"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>v</mml:mi><mml:mi>t</mml:mi></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula>. After every event (i.e., a sequence of states of length <inline-formula><mml:math id="inf22"><mml:mi>T</mml:mi></mml:math></inline-formula>), it takes the following policy gradient step to adjust the connection weights for all layers, denoted by <inline-formula><mml:math id="inf23"><mml:mi>θ</mml:mi></mml:math></inline-formula>:<disp-formula id="equ4"><mml:math id="m4"><mml:mrow><mml:msub><mml:mi mathvariant="normal">∇</mml:mi><mml:mrow><mml:mi>θ</mml:mi></mml:mrow></mml:msub><mml:mi>J</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>θ</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi mathvariant="normal">∇</mml:mi><mml:mrow><mml:mo>[</mml:mo><mml:mrow><mml:munderover><mml:mo>∑</mml:mo><mml:mrow><mml:mi>t</mml:mi><mml:mo>=</mml:mo><mml:mn>0</mml:mn></mml:mrow><mml:mrow><mml:mi>T</mml:mi></mml:mrow></mml:munderover><mml:mi>log</mml:mi><mml:mo>⁡</mml:mo><mml:msub><mml:mi>π</mml:mi><mml:mrow><mml:mi>θ</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mover><mml:mi>s</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>t</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:msub><mml:mi>s</mml:mi><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>r</mml:mi><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>−</mml:mo><mml:msub><mml:mi>v</mml:mi><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>−</mml:mo><mml:mi>η</mml:mi><mml:mi>H</mml:mi><mml:mrow><mml:mo maxsize="1.2em" minsize="1.2em">(</mml:mo></mml:mrow><mml:msub><mml:mi>π</mml:mi><mml:mrow><mml:mi>θ</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mrow><mml:mover><mml:mi>s</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>t</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:msub><mml:mi>s</mml:mi><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:mrow><mml:mo maxsize="1.2em" minsize="1.2em">)</mml:mo></mml:mrow></mml:mrow><mml:mo>]</mml:mo></mml:mrow></mml:mrow></mml:mstyle></mml:mrow></mml:math></disp-formula></p><p>where <inline-formula><mml:math id="inf24"><mml:mi>J</mml:mi></mml:math></inline-formula> is the objective function with respect to <inline-formula><mml:math id="inf25"><mml:mi>θ</mml:mi></mml:math></inline-formula> (the network weights). <inline-formula><mml:math id="inf26"><mml:msub><mml:mi>π</mml:mi><mml:mi>θ</mml:mi></mml:msub></mml:math></inline-formula> is the policy represented by the network weights. <inline-formula><mml:math id="inf27"><mml:mi>H</mml:mi></mml:math></inline-formula> is the entropy function that takes a probability distribution and returns its entropy. <inline-formula><mml:math id="inf28"><mml:mi>η</mml:mi></mml:math></inline-formula> controls the strength of entropy regularization.</p><p>The objective function <inline-formula><mml:math id="inf29"><mml:mi>J</mml:mi></mml:math></inline-formula> makes rewarded actions (next-state predictions) more likely to occur; the above equation shows how this process is modulated by the level of reward prediction error – measured as the difference between the predicted value, <inline-formula><mml:math id="inf30"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>v</mml:mi><mml:mi>t</mml:mi></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula>, versus the reward at time <inline-formula><mml:math id="inf31"><mml:mi>t</mml:mi></mml:math></inline-formula>, denoted by <inline-formula><mml:math id="inf32"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>r</mml:mi><mml:mi>t</mml:mi></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula>. We also used entropy regularization on the network output (<xref ref-type="bibr" rid="bib53">Grandvalet and Bengio, 2006</xref>; <xref ref-type="bibr" rid="bib102">Mnih et al., 2016</xref>) to encourage exploration in the early phase of the training process – with a positive <inline-formula><mml:math id="inf33"><mml:mi>η</mml:mi></mml:math></inline-formula>, the objective will encourage weight changes that lead to higher entropy distributions over actions.</p><p>We used the A2C method (<xref ref-type="bibr" rid="bib102">Mnih et al., 2016</xref>) because it is simple and has been widely used in cognitive modeling (<xref ref-type="bibr" rid="bib129">Ritter et al., 2018</xref>; <xref ref-type="bibr" rid="bib159">Wang et al., 2018</xref>). Notably, there is also evidence that an actor-critic style system is implemented in the neocortex and basal ganglia (<xref ref-type="bibr" rid="bib153">Takahashi et al., 2008</xref>). Since pure reinforcement learning is not data-efficient enough, we used supervised initialization during meta-training to help the model develop useful representations (<xref ref-type="bibr" rid="bib101">Misra et al., 2017</xref>; <xref ref-type="bibr" rid="bib103">Nagabandi et al., 2018</xref>). Specifically, the model is first trained for 600 epochs to predict the next state and to minimize the cross-entropy loss between the output and the target. During this supervised pre-training phase, the model is only trained on the recent memory condition and the episodic memory module is turned off, so this supervised pre-training does not influence the network’s retrieval policy. Additionally, the ‘don’t know’ output unit is not trained during the supervised pre-training phase – as noted above, we did this because we want the model to learn its own policy for saying ‘don’t know’, rather than having one imposed by us. Next, the model is switched to the advantage actor-critic (A2C) objective (<xref ref-type="bibr" rid="bib102">Mnih et al., 2016</xref>) and trained for another 400 epochs, allowing all weights to be adjusted. The number of training epochs was picked to ensure the learning curves converge. For both the supervised-pretraining phase and the reinforcement learning phase, we used the Adam optimizer (<xref ref-type="bibr" rid="bib80">Kingma and Ba, 2014</xref>) with learning rate of 7e-4 (for more details, please refer to <italic>Appendix 7</italic>).</p></sec><sec id="s4-2-2"><title>Stimulus representation</title><p>At time <inline-formula><mml:math id="inf34"><mml:mi>t</mml:mi></mml:math></inline-formula>, the model observes a situation feature, and then it gets a query about which state will be visited next. Specifically, the input vector at time <inline-formula><mml:math id="inf35"><mml:mi>t</mml:mi></mml:math></inline-formula> has four components (see <xref ref-type="fig" rid="fig5">Figure 5</xref>): (1) The observed situation feature (sticking with the example in <xref ref-type="fig" rid="fig2">Figure 2</xref>, this could be something like ‘weather’) is encoded as a <inline-formula><mml:math id="inf36"><mml:mi>T</mml:mi></mml:math></inline-formula>-dimensional one-hot vector. <inline-formula><mml:math id="inf37"><mml:mi>T</mml:mi></mml:math></inline-formula> is the total number of situation features, which (in most simulations) is the same as the number of time points in the event. The <inline-formula><mml:math id="inf38"><mml:mi>t</mml:mi></mml:math></inline-formula>-th one-hot indicates the situation feature governing the transition at time <inline-formula><mml:math id="inf39"><mml:mi>t</mml:mi></mml:math></inline-formula>. (2) The value of the observed situation feature (e.g., learning that the weather is sunny) is encoded as a B-dimensional one-hot vector, where <inline-formula><mml:math id="inf40"><mml:mi>B</mml:mi></mml:math></inline-formula> is the number of possible next states at time <inline-formula><mml:math id="inf41"><mml:mi>t</mml:mi></mml:math></inline-formula>. (3) The queried situation feature is encoded as another <inline-formula><mml:math id="inf42"><mml:mi>T</mml:mi></mml:math></inline-formula>-dimensional one-hot vector (note that querying the model about the value of the feature that controls the next-state transition is equivalent to querying the model about the next state, given that there is a 1-to-1 mapping between feature values and states within a time point; see <xref ref-type="fig" rid="fig2">Figure 2A</xref>).(4) Finally, the model also receives the current penalty level for incorrect predictions as a scalar input, which can change across trials. Overall, the input vector at time <inline-formula><mml:math id="inf43"><mml:mi>t</mml:mi></mml:math></inline-formula> is <inline-formula><mml:math id="inf44"><mml:mrow><mml:mrow><mml:mn>2</mml:mn><mml:mo>⁢</mml:mo><mml:mi>T</mml:mi></mml:mrow><mml:mo>+</mml:mo><mml:mi>B</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:math></inline-formula> dimensional. At every time point, there is also a target vector of length <inline-formula><mml:math id="inf45"><mml:mi>B</mml:mi></mml:math></inline-formula> that specifies the value of the queried feature (i.e. the ‘correct answer’ that the model is trying to predict). The model outputs a vector of length <inline-formula><mml:math id="inf46"><mml:mrow><mml:mi>B</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:math></inline-formula>: The first <inline-formula><mml:math id="inf47"><mml:mi>B</mml:mi></mml:math></inline-formula> dimensions correspond to specific predictions about the next state, and the last output dimension corresponds to the ‘don’t know’ response.</p><fig id="fig5" position="float"><label>Figure 5.</label><caption><title>The stimulus representation for the event processing task.</title><p>In the event processing task, situation features are observed in different, random orders during part 1 and part 2, but queries about those features are presented in the same order during part 1 and part 2. The green boxes in panel A indicate time points where the model observed the value of the first feature (time point 13 during part 1, and time point 15 during part 2). The yellow boxes indicate time points where the model was queried about the value of the first feature (time point zero during both part 1 and part 2).</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-74445-fig5-v3.tif"/></fig><p>In our simulation, the length of an event is 16 time points (i.e., <inline-formula><mml:math id="inf48"><mml:mi>T</mml:mi></mml:math></inline-formula> = 16), and the number of possible states at each time point is 4 (i.e., <inline-formula><mml:math id="inf49"><mml:mi>B</mml:mi></mml:math></inline-formula> = 4). Hence the chance level for next-state prediction is 1/4. <xref ref-type="fig" rid="fig5">Figure 5</xref> illustrates the stimuli provided to the model for a single example trial. Note that the queries (about the next state) are always presented in the same order, so there is a diagonal on the queried feature matrix. This captures the sequential structure of events (e.g., ordering food always happens before eating the food). However, the order in which the situation features are observed is random. As a result, sometimes a feature is queried after it was observed, in which case the model can rely on its working memory to produce the correct prediction, and sometimes a feature is queried before it was observed, in which case the model needs to use episodic memory (if a relevant memory is available) to produce the correct prediction.</p><p>As discussed above, the input vector specifies the level of penalty (for incorrect prediction) for the current trial. During meta-training, the penalty value was randomly sampled on each trial from the range between 0 and 4. During meta-testing, we evaluated the model using a penalty value of 2 (the average of the penalty values used during training). To understand the effect of penalty on retrieval policy, we also compared the timing of recall in the model when the penalty during meta-testing was low (penalty = 0) vs. high (penalty = 4; <xref ref-type="fig" rid="fig3">Figure 3F</xref>).</p><p>In our simulations, during meta-training, the model only got to observe 70% of the features of the ongoing situation during part 1 of the sequence. This was operationalized by giving each feature a 30% probability of being removed during part 1; for time points where the to-be-observed feature was removed, the model observed a zero vector instead. This ‘feature removal’ during part 1 of the sequence made the task more realistic, since – in general – past information does not fully inform what will happen in the future (during meta-testing, we did not remove any observations during part 1; this makes the results graphs easier to interpret, but has no effect on the conclusions reported here).</p><p>Finally, we wanted to make sure the model could adjust its retrieval time flexibly, instead of learning to always retrieve at a fixed time point (e.g., always retrieve at the third time point). Therefore, during training, we delayed the prediction demand by a random number of time points (from 0 to 3). For example, if the amount of delay was two in a given trial, then the model observed two situation features before it received the first query.</p></sec><sec id="s4-2-3"><title>Model Testing</title><p>During meta-testing (i.e., model evaluation; when simulating a particular experiment), the weights of the neocortical part of the model (i.e., all weights pertaining to the LSTM, decision layer, and EM gate) were frozen, but the model was allowed to form new episodic memories. In any given trial (where the model observed several events), new learning of information completely relied on working memory (i.e., model’s recurrent dynamics), episodic memory in the episodic module, and semantic memory encoded in the (frozen) neocortical connection weights (instantiating the model’s knowledge of transitions between states and how these transitions are controlled by situation features). The results shown in all the simulations were obtained by testing the model with new, randomly-generated events, after the initial meta-training phase. While it is theoretically possible that these test events could duplicate events that were encountered during meta-training, exact repeats will be very rare due to the combinatorics of the stimuli (as noted earlier, there are 4<sup>16</sup> possible sequences of states within an event). For more information on model parameters, see <italic>Appendix 7</italic>.</p></sec></sec><sec id="s4-3"><title>Decoding the working memory state</title><p>In <xref ref-type="fig" rid="fig2">Figure 2C</xref>, we used a decoding approach to track what information the model was maintaining in working memory over time while it processes an event. This approach allowed us to assess the model’s ability to hold on to observed features after they were observed, and also to detect when features were retrieved from episodic memory and loaded back up into working memory. Our use of decoders here is analogous to the widespread use of multivariate pattern analysis (MVPA) methods to decode the internal states of participants from neuroimaging data (<xref ref-type="bibr" rid="bib66">Haxby et al., 2001</xref>; <xref ref-type="bibr" rid="bib107">Norman et al., 2006</xref>; <xref ref-type="bibr" rid="bib86">Lewis-Peacock and Norman, 2014</xref>) – the only difference is that, here, we applied the decoder to the internal states of the model instead of applying it to brain data.</p><p>Specifically, we trained classifiers on LSTM cell states during part 1 to decode the feature values over time. Each situation feature was given its own classifier (logistic regression with L2 penalty). For example, if ‘weather’ was one of the situation features, we would train a dedicated ‘weather’ classifier that takes the LSTM cell state and predicts the value of the weather feature for a given time point. To set up the targets for these classifiers for part 1, we labeled all time points before the model observed the feature value as ‘don’t know’. After a feature value was revealed, we labeled that time point and the following time points with the value of that feature (e.g., if the weather feature value was observed to be ‘rainy’ on time point 4, then time point four and all of those that followed until the end of part 1 of the sequence were labeled with the value ‘rainy’). For part 2 data, we assumed all features were reinstated to the model’s working memory state after the EM gate value peaked. This labeling scheme assumes that (1) observed features are maintained in working memory and (2) episodic recall brings back previously encoded information. These assumptions can be tested by applying the classifier to held-out data. When decoding working memory states during part 1 of the sequence, we used a fivefold cross-validation procedure, and picked the regularization parameter with an inner-loop cross-validation. All results were generated using held-out test sets. The average decoding accuracy was 91.58%. Note that, as mentioned above, there is no guarantee that features observed earlier in the sequence will be maintained in the model’s working memory. As such, below-ceiling decoding accuracy could reflect either (1) failure to accurately decode the contents of working memory or (2) the decoder accurately detecting a working memory failure (i.e., that the feature in question has ‘dropped out’ of the model’s working memory, despite having been observed earlier in the sequence).</p></sec><sec id="s4-4"><title>Code</title><p>Github repo: <ext-link ext-link-type="uri" xlink:href="https://github.com/qihongl/learn-hippo">https://github.com/qihongl/learn-hippo</ext-link> (<xref ref-type="bibr" rid="bib92">Lu, 2022</xref>; copy archived at <ext-link ext-link-type="uri" xlink:href="https://archive.softwareheritage.org/swh:1:dir:d1b85f3093b5d6c9ba3a84c0a54f4dba8a8b0482;origin=https://github.com/qihongl/learn-hippo;visit=swh:1:snp:dc3599b04a53f31e3ab0987693a392562a42a802;anchor=swh:1:rev:6a4a1be4fd6780d4c8413ffc6b1facade4741135">swh:1:rev:6a4a1be4fd6780d4c8413ffc6b1facade4741135</ext-link>).</p></sec></sec></body><back><sec id="s5" sec-type="additional-information"><title>Additional information</title><fn-group content-type="competing-interest"><title>Competing interests</title><fn fn-type="COI-statement" id="conf1"><p>No competing interests declared</p></fn><fn fn-type="COI-statement" id="conf2"><p>No competing interests declared</p></fn></fn-group><fn-group content-type="author-contribution"><title>Author contributions</title><fn fn-type="con" id="con1"><p>Conceptualization, Formal analysis, Investigation, Methodology, Software, Visualization, Writing – original draft, Writing – review and editing</p></fn><fn fn-type="con" id="con2"><p>Conceptualization, Funding acquisition, Supervision, Writing – review and editing</p></fn><fn fn-type="con" id="con3"><p>Conceptualization, Funding acquisition, Methodology, Project administration, Supervision, Writing – review and editing</p></fn></fn-group></sec><sec id="s6" sec-type="supplementary-material"><title>Additional files</title><supplementary-material id="transrepform"><label>Transparent reporting form</label><media mime-subtype="pdf" mimetype="application" xlink:href="elife-74445-transrepform1-v3.pdf"/></supplementary-material></sec><sec id="s7" sec-type="data-availability"><title>Data availability</title><p>The code is made publicly available here in a git repo: <ext-link ext-link-type="uri" xlink:href="https://github.com/qihongl/learn-hippo">https://github.com/qihongl/learn-hippo</ext-link> (copy archived at <ext-link ext-link-type="uri" xlink:href="https://archive.softwareheritage.org/swh:1:dir:d1b85f3093b5d6c9ba3a84c0a54f4dba8a8b0482;origin=https://github.com/qihongl/learn-hippo;visit=swh:1:snp:dc3599b04a53f31e3ab0987693a392562a42a802;anchor=swh:1:rev:6a4a1be4fd6780d4c8413ffc6b1facade4741135">swh:1:rev:6a4a1be4fd6780d4c8413ffc6b1facade4741135</ext-link>). Users can also use this Code Ocean capsule to play with one example model to qualitatively replicate some results: <ext-link ext-link-type="uri" xlink:href="https://codeocean.com/capsule/3639589/tree">https://codeocean.com/capsule/3639589/tree</ext-link>.</p></sec><ack id="ack"><title>Acknowledgements</title><p>This work was supported by a Multi-University Research Initiative grant awarded to KAN and UH (ONR/DoD N00014-17-1-2961). We are grateful for the feedback we have received from members of the Princeton Computational Memory Lab, the Hasson Lab, and the labs of our MURI collaborators Charan Ranganath, Lucia Melloni, Jeffrey Zacks, and Samuel Gershman.</p></ack><ref-list><title>References</title><ref id="bib1"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Aldous</surname><given-names>DJ</given-names></name></person-group><year iso-8601-date="1983">1983</year><chapter-title>Exchangeability and related topics</chapter-title><person-group person-group-type="editor"><name><surname>Aldous</surname><given-names>DJ</given-names></name><name><surname>Ibragimov</surname><given-names>IA</given-names></name><name><surname>Jacod</surname><given-names>J</given-names></name></person-group><source>École d’Été de Probabilités de Saint-Flour XIII</source><publisher-loc>Berlin Heidelberg</publisher-loc><publisher-name>Springer</publisher-name><fpage>1</fpage><lpage>198</lpage><pub-id pub-id-type="doi">10.1007/BFb0099420</pub-id></element-citation></ref><ref id="bib2"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Anderson</surname><given-names>JR</given-names></name></person-group><year iso-8601-date="1991">1991</year><article-title>The adaptive nature of human categorization</article-title><source>Psychological Review</source><volume>98</volume><fpage>409</fpage><lpage>429</lpage><pub-id pub-id-type="doi">10.1037/0033-295X.98.3.409</pub-id></element-citation></ref><ref id="bib3"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Anderson</surname><given-names>JR</given-names></name><name><surname>Reder</surname><given-names>LM</given-names></name></person-group><year iso-8601-date="1999">1999</year><article-title>The fan effect: New results and new theories</article-title><source>Journal of Experimental Psychology</source><volume>128</volume><fpage>186</fpage><lpage>197</lpage><pub-id pub-id-type="doi">10.1037/0096-3445.128.2.186</pub-id></element-citation></ref><ref id="bib4"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Anderson</surname><given-names>JR</given-names></name><name><surname>Schooler</surname><given-names>LJ</given-names></name></person-group><year iso-8601-date="2000">2000</year><chapter-title>The adaptive nature of memory</chapter-title><person-group person-group-type="editor"><name><surname>Tulving</surname><given-names>E</given-names></name></person-group><source>The Oxford Handbook of Memory</source><publisher-name>Springer</publisher-name><fpage>557</fpage><lpage>570</lpage></element-citation></ref><ref id="bib5"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Antony</surname><given-names>JW</given-names></name><name><surname>Hartshorne</surname><given-names>TH</given-names></name><name><surname>Pomeroy</surname><given-names>K</given-names></name><name><surname>Gureckis</surname><given-names>TM</given-names></name><name><surname>Hasson</surname><given-names>U</given-names></name><name><surname>McDougle</surname><given-names>SD</given-names></name><name><surname>Norman</surname><given-names>KA</given-names></name></person-group><year iso-8601-date="2021">2021</year><article-title>Behavioral, physiological, and neural signatures of surprise during naturalistic sports viewing</article-title><source>Neuron</source><volume>109</volume><fpage>377</fpage><lpage>390</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2020.10.029</pub-id><pub-id pub-id-type="pmid">33242421</pub-id></element-citation></ref><ref id="bib6"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Axmacher</surname><given-names>N</given-names></name><name><surname>Cohen</surname><given-names>MX</given-names></name><name><surname>Fell</surname><given-names>J</given-names></name><name><surname>Haupt</surname><given-names>S</given-names></name><name><surname>Dümpelmann</surname><given-names>M</given-names></name><name><surname>Elger</surname><given-names>CE</given-names></name><name><surname>Schlaepfer</surname><given-names>TE</given-names></name><name><surname>Lenartz</surname><given-names>D</given-names></name><name><surname>Sturm</surname><given-names>V</given-names></name><name><surname>Ranganath</surname><given-names>C</given-names></name></person-group><year iso-8601-date="2010">2010</year><article-title>Intracranial EEG correlates of expectancy and memory formation in the human hippocampus and nucleus accumbens</article-title><source>Neuron</source><volume>65</volume><fpage>541</fpage><lpage>549</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2010.02.006</pub-id><pub-id pub-id-type="pmid">20188658</pub-id></element-citation></ref><ref id="bib7"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Baddeley</surname><given-names>A</given-names></name></person-group><year iso-8601-date="2000">2000</year><article-title>The episodic buffer: a new component of working memory?</article-title><source>Trends in Cognitive Sciences</source><volume>4</volume><fpage>417</fpage><lpage>423</lpage><pub-id pub-id-type="doi">10.1016/S1364-6613(00)01538-2</pub-id><pub-id pub-id-type="pmid">11058819</pub-id></element-citation></ref><ref id="bib8"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bakkour</surname><given-names>A</given-names></name><name><surname>Palombo</surname><given-names>DJ</given-names></name><name><surname>Zylberberg</surname><given-names>A</given-names></name><name><surname>Kang</surname><given-names>YH</given-names></name><name><surname>Reid</surname><given-names>A</given-names></name><name><surname>Verfaellie</surname><given-names>M</given-names></name><name><surname>Shadlen</surname><given-names>MN</given-names></name><name><surname>Shohamy</surname><given-names>D</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>The hippocampus supports deliberation during value-based decisions</article-title><source>eLife</source><volume>8</volume><elocation-id>e46080</elocation-id><pub-id pub-id-type="doi">10.7554/eLife.46080</pub-id><pub-id pub-id-type="pmid">31268419</pub-id></element-citation></ref><ref id="bib9"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Baldassano</surname><given-names>C</given-names></name><name><surname>Chen</surname><given-names>J</given-names></name><name><surname>Zadbood</surname><given-names>A</given-names></name><name><surname>Pillow</surname><given-names>JW</given-names></name><name><surname>Hasson</surname><given-names>U</given-names></name><name><surname>Norman</surname><given-names>KA</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>Discovering event structure in continuous narrative perception and memory</article-title><source>Neuron</source><volume>95</volume><elocation-id>41</elocation-id><pub-id pub-id-type="doi">10.1016/j.neuron.2017.06.041</pub-id></element-citation></ref><ref id="bib10"><element-citation publication-type="preprint"><person-group person-group-type="author"><name><surname>Barnett</surname><given-names>AJ</given-names></name><name><surname>Reilly</surname><given-names>W</given-names></name><name><surname>Dimsdale-Zucker</surname><given-names>HR</given-names></name><name><surname>Mizrak</surname><given-names>E</given-names></name><name><surname>Reagh</surname><given-names>Z</given-names></name><name><surname>Ranganath</surname><given-names>C</given-names></name></person-group><year iso-8601-date="2020">2020</year><article-title>Organization of cortico-hippocampal networks in the human brain</article-title><source>bioRxiv</source><pub-id pub-id-type="doi">10.1101/2020.06.09.142166</pub-id></element-citation></ref><ref id="bib11"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bein</surname><given-names>O</given-names></name><name><surname>Duncan</surname><given-names>K</given-names></name><name><surname>Davachi</surname><given-names>L</given-names></name></person-group><year iso-8601-date="2020">2020</year><article-title>Mnemonic prediction errors bias hippocampal states</article-title><source>Nature Communications</source><volume>11</volume><elocation-id>3451</elocation-id><pub-id pub-id-type="doi">10.1038/s41467-020-17287-1</pub-id><pub-id pub-id-type="pmid">32651370</pub-id></element-citation></ref><ref id="bib12"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ben-Yakov</surname><given-names>A</given-names></name><name><surname>Dudai</surname><given-names>Y</given-names></name></person-group><year iso-8601-date="2011">2011</year><article-title>Constructing realistic engrams: poststimulus activity of hippocampus and dorsal striatum predicts subsequent episodic memory</article-title><source>The Journal of Neuroscience</source><volume>31</volume><fpage>9032</fpage><lpage>9042</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.0702-11.2011</pub-id><pub-id pub-id-type="pmid">21677186</pub-id></element-citation></ref><ref id="bib13"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ben-Yakov</surname><given-names>A</given-names></name><name><surname>Eshel</surname><given-names>N</given-names></name><name><surname>Dudai</surname><given-names>Y</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>Hippocampal immediate poststimulus activity in the encoding of consecutive naturalistic episodes</article-title><source>Journal of Experimental Psychology. General</source><volume>142</volume><fpage>1255</fpage><lpage>1263</lpage><pub-id pub-id-type="doi">10.1037/a0033558</pub-id><pub-id pub-id-type="pmid">23815458</pub-id></element-citation></ref><ref id="bib14"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ben-Yakov</surname><given-names>A</given-names></name><name><surname>Henson</surname><given-names>RN</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>The hippocampal film editor: sensitivity and specificity to event boundaries in continuous experience</article-title><source>The Journal of Neuroscience</source><volume>38</volume><fpage>10057</fpage><lpage>10068</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.0524-18.2018</pub-id><pub-id pub-id-type="pmid">30301758</pub-id></element-citation></ref><ref id="bib15"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Biderman</surname><given-names>N</given-names></name><name><surname>Bakkour</surname><given-names>A</given-names></name><name><surname>Shohamy</surname><given-names>D</given-names></name></person-group><year iso-8601-date="2020">2020</year><article-title>What are memories for? The hippocampus bridges past experience with future decisions</article-title><source>Trends in Cognitive Sciences</source><volume>24</volume><fpage>542</fpage><lpage>556</lpage><pub-id pub-id-type="doi">10.1016/j.tics.2020.04.004</pub-id><pub-id pub-id-type="pmid">32513572</pub-id></element-citation></ref><ref id="bib16"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bonasia</surname><given-names>K</given-names></name><name><surname>Sekeres</surname><given-names>MJ</given-names></name><name><surname>Gilboa</surname><given-names>A</given-names></name><name><surname>Grady</surname><given-names>CL</given-names></name><name><surname>Winocur</surname><given-names>G</given-names></name><name><surname>Moscovitch</surname><given-names>M</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>Prior knowledge modulates the neural substrates of encoding and retrieving naturalistic events at short and long delays</article-title><source>Neurobiology of Learning and Memory</source><volume>153</volume><fpage>26</fpage><lpage>39</lpage><pub-id pub-id-type="doi">10.1016/j.nlm.2018.02.017</pub-id><pub-id pub-id-type="pmid">29474955</pub-id></element-citation></ref><ref id="bib17"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Botvinick</surname><given-names>M</given-names></name><name><surname>Plaut</surname><given-names>DC</given-names></name></person-group><year iso-8601-date="2004">2004</year><article-title>Doing without schema hierarchies: a recurrent connectionist approach to normal and impaired routine sequential action</article-title><source>Psychological Review</source><volume>111</volume><fpage>395</fpage><lpage>429</lpage><pub-id pub-id-type="doi">10.1037/0033-295X.111.2.395</pub-id><pub-id pub-id-type="pmid">15065915</pub-id></element-citation></ref><ref id="bib18"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Botvinick</surname><given-names>M</given-names></name><name><surname>Ritter</surname><given-names>S</given-names></name><name><surname>Wang</surname><given-names>JX</given-names></name><name><surname>Kurth-Nelson</surname><given-names>Z</given-names></name><name><surname>Blundell</surname><given-names>C</given-names></name><name><surname>Hassabis</surname><given-names>D</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>Reinforcement learning, fast and slow</article-title><source>Trends in Cognitive Sciences</source><volume>23</volume><fpage>408</fpage><lpage>422</lpage><pub-id pub-id-type="doi">10.1016/j.tics.2019.02.006</pub-id><pub-id pub-id-type="pmid">31003893</pub-id></element-citation></ref><ref id="bib19"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Brunec</surname><given-names>IK</given-names></name><name><surname>Robin</surname><given-names>J</given-names></name><name><surname>Olsen</surname><given-names>RK</given-names></name><name><surname>Moscovitch</surname><given-names>M</given-names></name><name><surname>Barense</surname><given-names>MD</given-names></name></person-group><year iso-8601-date="2020">2020</year><article-title>Integration and differentiation of hippocampal memory traces</article-title><source>Neuroscience and Biobehavioral Reviews</source><volume>118</volume><fpage>196</fpage><lpage>208</lpage><pub-id pub-id-type="doi">10.1016/j.neubiorev.2020.07.024</pub-id><pub-id pub-id-type="pmid">32712280</pub-id></element-citation></ref><ref id="bib20"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Chanales</surname><given-names>AJH</given-names></name><name><surname>Oza</surname><given-names>A</given-names></name><name><surname>Favila</surname><given-names>SE</given-names></name><name><surname>Kuhl</surname><given-names>BA</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>Overlap among spatial memories triggers repulsion of hippocampal representations</article-title><source>Current Biology</source><volume>27</volume><fpage>2307</fpage><lpage>2317</lpage><pub-id pub-id-type="doi">10.1016/j.cub.2017.06.057</pub-id><pub-id pub-id-type="pmid">28736170</pub-id></element-citation></ref><ref id="bib21"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Chang</surname><given-names>CHC</given-names></name><name><surname>Lazaridi</surname><given-names>C</given-names></name><name><surname>Yeshurun</surname><given-names>Y</given-names></name><name><surname>Norman</surname><given-names>KA</given-names></name><name><surname>Hasson</surname><given-names>U</given-names></name></person-group><year iso-8601-date="2021">2021</year><article-title>Relating the past with the present: Information integration and segregation during ongoing narrative processing</article-title><source>Journal of Cognitive Neuroscience</source><volume>33</volume><fpage>1106</fpage><lpage>1128</lpage><pub-id pub-id-type="doi">10.1162/jocn_a_01707</pub-id><pub-id pub-id-type="pmid">34428791</pub-id></element-citation></ref><ref id="bib22"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Chen</surname><given-names>J</given-names></name><name><surname>Cook</surname><given-names>PA</given-names></name><name><surname>Wagner</surname><given-names>AD</given-names></name></person-group><year iso-8601-date="2015">2015a</year><article-title>Prediction strength modulates responses in human area CA1 to sequence violations</article-title><source>Journal of Neurophysiology</source><volume>114</volume><fpage>1227</fpage><lpage>1238</lpage><pub-id pub-id-type="doi">10.1152/jn.00149.2015</pub-id><pub-id pub-id-type="pmid">26063773</pub-id></element-citation></ref><ref id="bib23"><element-citation publication-type="confproc"><person-group person-group-type="author"><name><surname>Chen</surname><given-names>PH</given-names></name><name><surname>Chen</surname><given-names>J</given-names></name><name><surname>Yeshurun</surname><given-names>Y</given-names></name><name><surname>Hasson</surname><given-names>U</given-names></name><name><surname>Haxby</surname><given-names>J</given-names></name><name><surname>Ramadge</surname><given-names>PJ</given-names></name></person-group><year iso-8601-date="2015">2015b</year><article-title>A reduced-dimension fMRI shared response model</article-title><conf-name>Advances in Neural Information Processing Systems</conf-name></element-citation></ref><ref id="bib24"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Chen</surname><given-names>J</given-names></name><name><surname>Honey</surname><given-names>CJ</given-names></name><name><surname>Simony</surname><given-names>E</given-names></name><name><surname>Arcaro</surname><given-names>MJ</given-names></name><name><surname>Norman</surname><given-names>KA</given-names></name><name><surname>Hasson</surname><given-names>U</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Accessing real-life episodic information from minutes versus hours earlier modulates hippocampal and high-order cortical dynamics</article-title><source>Cerebral Cortex (New York, N.Y</source><volume>26</volume><fpage>3428</fpage><lpage>3441</lpage><pub-id pub-id-type="doi">10.1093/cercor/bhv155</pub-id><pub-id pub-id-type="pmid">26240179</pub-id></element-citation></ref><ref id="bib25"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Chien</surname><given-names>HYS</given-names></name><name><surname>Honey</surname><given-names>CJ</given-names></name></person-group><year iso-8601-date="2020">2020</year><article-title>Constructing and forgetting temporal context in the human cerebral cortex</article-title><source>Neuron</source><volume>106</volume><fpage>675</fpage><lpage>686</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2020.02.013</pub-id><pub-id pub-id-type="pmid">32164874</pub-id></element-citation></ref><ref id="bib26"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Collins</surname><given-names>AGE</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>Reinforcement learning: bringing together computation and cognition</article-title><source>Current Opinion in Behavioral Sciences</source><volume>29</volume><fpage>63</fpage><lpage>68</lpage><pub-id pub-id-type="doi">10.1016/j.cobeha.2019.04.011</pub-id></element-citation></ref><ref id="bib27"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Cooper</surname><given-names>RA</given-names></name><name><surname>Ritchey</surname><given-names>M</given-names></name></person-group><year iso-8601-date="2020">2020</year><article-title>Progression from feature-specific brain activity to hippocampal binding during episodic encoding</article-title><source>The Journal of Neuroscience</source><volume>40</volume><fpage>1701</fpage><lpage>1709</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.1971-19.2019</pub-id><pub-id pub-id-type="pmid">31826947</pub-id></element-citation></ref><ref id="bib28"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Cox</surname><given-names>GE</given-names></name><name><surname>Criss</surname><given-names>AH</given-names></name></person-group><year iso-8601-date="2020">2020</year><article-title>Similarity leads to correlated processing: a dynamic model of encoding and recognition of episodic associations</article-title><source>Psychological Review</source><volume>127</volume><fpage>792</fpage><lpage>828</lpage><pub-id pub-id-type="doi">10.1037/rev0000195</pub-id><pub-id pub-id-type="pmid">32191075</pub-id></element-citation></ref><ref id="bib29"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Criss</surname><given-names>AH</given-names></name><name><surname>Howard</surname><given-names>MW</given-names></name></person-group><year iso-8601-date="2015">2015</year><chapter-title>Models of episodic memory</chapter-title><person-group person-group-type="editor"><name><surname>Busemeyer</surname><given-names>JR</given-names></name><name><surname>Wang</surname><given-names>Z</given-names></name><name><surname>Townsend</surname><given-names>JT</given-names></name><name><surname>Eidels</surname><given-names>A</given-names></name></person-group><source>The Oxford Handbook of Computational and Mathematical Psychology</source><publisher-name>Oxford Press</publisher-name><fpage>165</fpage><lpage>183</lpage></element-citation></ref><ref id="bib30"><element-citation publication-type="preprint"><person-group person-group-type="author"><name><surname>Dauphin</surname><given-names>YN</given-names></name><name><surname>Pascanu</surname><given-names>R</given-names></name><name><surname>Gulcehre</surname><given-names>C</given-names></name><name><surname>Cho</surname><given-names>K</given-names></name><name><surname>Ganguli</surname><given-names>S</given-names></name><name><surname>Bengio</surname><given-names>Y</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>Identifying and attacking the saddle point problem in high-dimensional non-convex optimization</article-title><source>arXiv</source><ext-link ext-link-type="uri" xlink:href="https://arxiv.org/abs/1406.2572">https://arxiv.org/abs/1406.2572</ext-link></element-citation></ref><ref id="bib31"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Davidow</surname><given-names>JY</given-names></name><name><surname>Foerde</surname><given-names>K</given-names></name><name><surname>Galván</surname><given-names>A</given-names></name><name><surname>Shohamy</surname><given-names>D</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>An upside to reward sensitivity: the hippocampus supports enhanced reinforcement learning in adolescence</article-title><source>Neuron</source><volume>92</volume><fpage>93</fpage><lpage>99</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2016.08.031</pub-id><pub-id pub-id-type="pmid">27710793</pub-id></element-citation></ref><ref id="bib32"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Dudai</surname><given-names>Y</given-names></name><name><surname>Eisenberg</surname><given-names>M</given-names></name></person-group><year iso-8601-date="2004">2004</year><article-title>Rites of passage of the engram: reconsolidation and the lingering consolidation hypothesis</article-title><source>Neuron</source><volume>44</volume><fpage>93</fpage><lpage>100</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2004.09.003</pub-id><pub-id pub-id-type="pmid">15450162</pub-id></element-citation></ref><ref id="bib33"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Dudai</surname><given-names>Y</given-names></name></person-group><year iso-8601-date="2009">2009</year><article-title>Predicting not to predict too much: how the cellular machinery of memory anticipates the uncertain future</article-title><source>Philosophical Transactions of the Royal Society B</source><volume>364</volume><fpage>1255</fpage><lpage>1262</lpage><pub-id pub-id-type="doi">10.1098/rstb.2008.0320</pub-id></element-citation></ref><ref id="bib34"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Duncan</surname><given-names>K</given-names></name><name><surname>Sadanand</surname><given-names>A</given-names></name><name><surname>Davachi</surname><given-names>L</given-names></name></person-group><year iso-8601-date="2012">2012</year><article-title>Memory’s penumbra: episodic memory decisions induce lingering mnemonic biases</article-title><source>Science (New York, N.Y.)</source><volume>337</volume><fpage>485</fpage><lpage>487</lpage><pub-id pub-id-type="doi">10.1126/science.1221936</pub-id><pub-id pub-id-type="pmid">22837528</pub-id></element-citation></ref><ref id="bib35"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Duncan</surname><given-names>KD</given-names></name><name><surname>Shohamy</surname><given-names>D</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Memory states influence value-based decisions</article-title><source>Journal of Experimental Psychology. General</source><volume>145</volume><fpage>1420</fpage><lpage>1426</lpage><pub-id pub-id-type="doi">10.1037/xge0000231</pub-id><pub-id pub-id-type="pmid">27797556</pub-id></element-citation></ref><ref id="bib36"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Duncan</surname><given-names>KD</given-names></name><name><surname>Schlichting</surname><given-names>ML</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>Hippocampal representations as a function of time, subregion, and brain state</article-title><source>Neurobiology of Learning and Memory</source><volume>153</volume><fpage>40</fpage><lpage>56</lpage><pub-id pub-id-type="doi">10.1016/j.nlm.2018.03.006</pub-id><pub-id pub-id-type="pmid">29535044</pub-id></element-citation></ref><ref id="bib37"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Duncan</surname><given-names>K</given-names></name><name><surname>Semmler</surname><given-names>A</given-names></name><name><surname>Shohamy</surname><given-names>D</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>Modulating the use of multiple memory systems in value-based decisions with contextual novelty</article-title><source>Journal of Cognitive Neuroscience</source><volume>31</volume><fpage>1455</fpage><lpage>1467</lpage><pub-id pub-id-type="doi">10.1162/jocn_a_01447</pub-id><pub-id pub-id-type="pmid">31322467</pub-id></element-citation></ref><ref id="bib38"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Eichenbaum</surname><given-names>H</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>Time cells in the hippocampus: A new dimension for mapping memories</article-title><source>Nature Reviews. Neuroscience</source><volume>15</volume><fpage>732</fpage><lpage>744</lpage><pub-id pub-id-type="doi">10.1038/nrn3827</pub-id><pub-id pub-id-type="pmid">25269553</pub-id></element-citation></ref><ref id="bib39"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Elman</surname><given-names>JL</given-names></name><name><surname>McRae</surname><given-names>K</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>A model of event knowledge</article-title><source>Psychological Review</source><volume>126</volume><fpage>252</fpage><lpage>291</lpage><pub-id pub-id-type="doi">10.1037/rev0000133</pub-id><pub-id pub-id-type="pmid">30702315</pub-id></element-citation></ref><ref id="bib40"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ericsson</surname><given-names>KA</given-names></name><name><surname>Kintsch</surname><given-names>W</given-names></name></person-group><year iso-8601-date="1995">1995</year><article-title>Long-term working memory</article-title><source>Psychological Review</source><volume>102</volume><fpage>211</fpage><lpage>245</lpage><pub-id pub-id-type="doi">10.1037/0033-295x.102.2.211</pub-id><pub-id pub-id-type="pmid">7740089</pub-id></element-citation></ref><ref id="bib41"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ezzyat</surname><given-names>Y</given-names></name><name><surname>Davachi</surname><given-names>L</given-names></name></person-group><year iso-8601-date="2011">2011</year><article-title>What constitutes an episode in episodic memory?</article-title><source>Psychological Science</source><volume>22</volume><fpage>243</fpage><lpage>252</lpage><pub-id pub-id-type="doi">10.1177/0956797610393742</pub-id><pub-id pub-id-type="pmid">21178116</pub-id></element-citation></ref><ref id="bib42"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ezzyat</surname><given-names>Y</given-names></name><name><surname>Davachi</surname><given-names>L</given-names></name></person-group><year iso-8601-date="2021">2021</year><article-title>Neural evidence for representational persistence within events</article-title><source>The Journal of Neuroscience</source><volume>41</volume><fpage>7909</fpage><lpage>7920</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.0073-21.2021</pub-id><pub-id pub-id-type="pmid">34330773</pub-id></element-citation></ref><ref id="bib43"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Favila</surname><given-names>SE</given-names></name><name><surname>Chanales</surname><given-names>AJH</given-names></name><name><surname>Kuhl</surname><given-names>BA</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Experience-dependent hippocampal pattern differentiation prevents interference during subsequent learning</article-title><source>Nature Communications</source><volume>7</volume><elocation-id>11066</elocation-id><pub-id pub-id-type="doi">10.1038/ncomms11066</pub-id><pub-id pub-id-type="pmid">27925613</pub-id></element-citation></ref><ref id="bib44"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Frank</surname><given-names>D</given-names></name><name><surname>Montemurro</surname><given-names>MA</given-names></name><name><surname>Montaldi</surname><given-names>D</given-names></name></person-group><year iso-8601-date="2020">2020</year><article-title>Pattern separation underpins expectation-modulated memory</article-title><source>The Journal of Neuroscience</source><volume>40</volume><fpage>3455</fpage><lpage>3464</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.2047-19.2020</pub-id><pub-id pub-id-type="pmid">32161140</pub-id></element-citation></ref><ref id="bib45"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Frank</surname><given-names>D</given-names></name><name><surname>Kafkas</surname><given-names>A</given-names></name></person-group><year iso-8601-date="2021">2021a</year><article-title>Expectation-driven novelty effects in episodic memory</article-title><source>Neurobiology of Learning and Memory</source><volume>1</volume><elocation-id>107466</elocation-id><pub-id pub-id-type="doi">10.1016/j.nlm.2021.107466</pub-id></element-citation></ref><ref id="bib46"><element-citation publication-type="preprint"><person-group person-group-type="author"><name><surname>Frank</surname><given-names>D</given-names></name><name><surname>Kafkas</surname><given-names>A</given-names></name><name><surname>Montaldi</surname><given-names>D</given-names></name></person-group><year iso-8601-date="2021">2021b</year><article-title>Experiencing surprise: The temporal dynamics of its impact on memory</article-title><source>bioRxiv</source><pub-id pub-id-type="doi">10.1101/2020.12.15.422817</pub-id></element-citation></ref><ref id="bib47"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Franklin</surname><given-names>NT</given-names></name><name><surname>Norman</surname><given-names>KA</given-names></name><name><surname>Ranganath</surname><given-names>C</given-names></name><name><surname>Zacks</surname><given-names>JM</given-names></name><name><surname>Gershman</surname><given-names>SJ</given-names></name></person-group><year iso-8601-date="2020">2020</year><article-title>Structured event memory: a neuro-symbolic model of event cognition</article-title><source>Psychological Review</source><volume>127</volume><fpage>327</fpage><lpage>361</lpage><pub-id pub-id-type="doi">10.1037/rev0000177</pub-id><pub-id pub-id-type="pmid">32223284</pub-id></element-citation></ref><ref id="bib48"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Gershman</surname><given-names>SJ</given-names></name><name><surname>Blei</surname><given-names>DM</given-names></name><name><surname>Niv</surname><given-names>Y</given-names></name></person-group><year iso-8601-date="2010">2010</year><article-title>Context, learning, and extinction</article-title><source>Psychological Review</source><volume>117</volume><fpage>197</fpage><lpage>209</lpage><pub-id pub-id-type="doi">10.1037/a0017808</pub-id><pub-id pub-id-type="pmid">20063968</pub-id></element-citation></ref><ref id="bib49"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Gershman</surname><given-names>SJ</given-names></name><name><surname>Norman</surname><given-names>KA</given-names></name><name><surname>Niv</surname><given-names>Y</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>Discovering latent causes in reinforcement learning</article-title><source>Current Opinion in Behavioral Sciences</source><volume>5</volume><fpage>43</fpage><lpage>50</lpage><pub-id pub-id-type="doi">10.1016/j.cobeha.2015.07.007</pub-id></element-citation></ref><ref id="bib50"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Gershman</surname><given-names>SJ</given-names></name></person-group><year iso-8601-date="2021">2021</year><chapter-title>The adaptive nature of memory</chapter-title><person-group person-group-type="editor"><name><surname>Kahana</surname><given-names>MJ</given-names></name><name><surname>Wagner</surname><given-names>AD</given-names></name></person-group><source>Oxford Handbook of Human Memory</source><publisher-name>Oxford University Press</publisher-name><fpage>265</fpage><lpage>278</lpage><pub-id pub-id-type="doi">10.1016/B978-0-12-809324-5.21042-0</pub-id></element-citation></ref><ref id="bib51"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Gilboa</surname><given-names>A</given-names></name><name><surname>Marlatte</surname><given-names>H</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>Neurobiology of schemas and schema-mediated memory</article-title><source>Trends in Cognitive Sciences</source><volume>21</volume><fpage>618</fpage><lpage>631</lpage><pub-id pub-id-type="doi">10.1016/j.tics.2017.04.013</pub-id><pub-id pub-id-type="pmid">28551107</pub-id></element-citation></ref><ref id="bib52"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Gillund</surname><given-names>G</given-names></name><name><surname>Shiffrin</surname><given-names>RM</given-names></name></person-group><year iso-8601-date="1984">1984</year><article-title>A retrieval model for both recognition and recall</article-title><source>Psychological Review</source><volume>91</volume><fpage>1</fpage><lpage>67</lpage><pub-id pub-id-type="doi">10.1037/0033-295X.91.1.1</pub-id><pub-id pub-id-type="pmid">6571421</pub-id></element-citation></ref><ref id="bib53"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Grandvalet</surname><given-names>Y</given-names></name><name><surname>Bengio</surname><given-names>Y</given-names></name></person-group><year iso-8601-date="2006">2006</year><chapter-title>Olivier Chapelle</chapter-title><person-group person-group-type="editor"><name><surname>Bernhard</surname><given-names>S</given-names></name><name><surname>Alexander</surname><given-names>Z</given-names></name></person-group><source>Semi-Supervised Learning</source><publisher-name>MIT Press</publisher-name><fpage>1</fpage><lpage>10</lpage><pub-id pub-id-type="doi">10.7551/mitpress/9780262033589.001.0001</pub-id></element-citation></ref><ref id="bib54"><element-citation publication-type="preprint"><person-group person-group-type="author"><name><surname>Graves</surname><given-names>A</given-names></name><name><surname>Wayne</surname><given-names>G</given-names></name><name><surname>Danihelka</surname><given-names>I</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>Neural Turing machines</article-title><source>arXiv</source><ext-link ext-link-type="uri" xlink:href="https://arxiv.org/abs/1410.5401">https://arxiv.org/abs/1410.5401</ext-link></element-citation></ref><ref id="bib55"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Graves</surname><given-names>A</given-names></name><name><surname>Wayne</surname><given-names>G</given-names></name><name><surname>Reynolds</surname><given-names>M</given-names></name><name><surname>Harley</surname><given-names>T</given-names></name><name><surname>Danihelka</surname><given-names>I</given-names></name><name><surname>Grabska-Barwińska</surname><given-names>A</given-names></name><name><surname>Colmenarejo</surname><given-names>SG</given-names></name><name><surname>Grefenstette</surname><given-names>E</given-names></name><name><surname>Ramalho</surname><given-names>T</given-names></name><name><surname>Agapiou</surname><given-names>J</given-names></name><name><surname>Badia</surname><given-names>AP</given-names></name><name><surname>Hermann</surname><given-names>KM</given-names></name><name><surname>Zwols</surname><given-names>Y</given-names></name><name><surname>Ostrovski</surname><given-names>G</given-names></name><name><surname>Cain</surname><given-names>A</given-names></name><name><surname>King</surname><given-names>H</given-names></name><name><surname>Summerfield</surname><given-names>C</given-names></name><name><surname>Blunsom</surname><given-names>P</given-names></name><name><surname>Kavukcuoglu</surname><given-names>K</given-names></name><name><surname>Hassabis</surname><given-names>D</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Hybrid computing using a neural network with dynamic external memory</article-title><source>Nature</source><volume>538</volume><fpage>471</fpage><lpage>476</lpage><pub-id pub-id-type="doi">10.1038/nature20101</pub-id><pub-id pub-id-type="pmid">27732574</pub-id></element-citation></ref><ref id="bib56"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Greve</surname><given-names>A</given-names></name><name><surname>Cooper</surname><given-names>E</given-names></name><name><surname>Kaula</surname><given-names>A</given-names></name><name><surname>Anderson</surname><given-names>MC</given-names></name><name><surname>Henson</surname><given-names>R</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>Does prediction error drive one-shot declarative learning?</article-title><source>Journal of Memory and Language</source><volume>94</volume><fpage>149</fpage><lpage>165</lpage><pub-id pub-id-type="doi">10.1016/j.jml.2016.11.001</pub-id><pub-id pub-id-type="pmid">28579691</pub-id></element-citation></ref><ref id="bib57"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Greve</surname><given-names>A</given-names></name><name><surname>Cooper</surname><given-names>E</given-names></name><name><surname>Tibon</surname><given-names>R</given-names></name><name><surname>Henson</surname><given-names>RN</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>Knowledge is power: Prior knowledge aids memory for both congruent and incongruent events, but in different ways</article-title><source>Journal of Experimental Psychology. General</source><volume>148</volume><fpage>325</fpage><lpage>341</lpage><pub-id pub-id-type="doi">10.1037/xge0000498</pub-id><pub-id pub-id-type="pmid">30394766</pub-id></element-citation></ref><ref id="bib58"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Griffiths</surname><given-names>TL</given-names></name><name><surname>Lieder</surname><given-names>F</given-names></name><name><surname>Goodman</surname><given-names>ND</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>Rational use of cognitive resources: levels of analysis between the computational and the algorithmic</article-title><source>Topics in Cognitive Science</source><volume>7</volume><fpage>217</fpage><lpage>229</lpage><pub-id pub-id-type="doi">10.1111/tops.12142</pub-id><pub-id pub-id-type="pmid">25898807</pub-id></element-citation></ref><ref id="bib59"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hamilton</surname><given-names>LS</given-names></name><name><surname>Huth</surname><given-names>AG</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>The revolution will not be controlled: Natural stimuli in speech neuroscience</article-title><source>Language, Cognition and Neuroscience</source><volume>1</volume><fpage>1</fpage><lpage>10</lpage><pub-id pub-id-type="doi">10.1080/23273798.2018.1499946</pub-id></element-citation></ref><ref id="bib60"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hardt</surname><given-names>O</given-names></name><name><surname>Einarsson</surname><given-names>EO</given-names></name><name><surname>Nader</surname><given-names>K</given-names></name></person-group><year iso-8601-date="2010">2010</year><article-title>A bridge over troubled water: reconsolidation as a link between cognitive and neuroscientific memory research traditions</article-title><source>Annual Review of Psychology</source><volume>61</volume><fpage>141</fpage><lpage>167</lpage><pub-id pub-id-type="doi">10.1146/annurev.psych.093008.100455</pub-id><pub-id pub-id-type="pmid">19575608</pub-id></element-citation></ref><ref id="bib61"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hasselmo</surname><given-names>ME</given-names></name><name><surname>Schnell</surname><given-names>E</given-names></name><name><surname>Barkai</surname><given-names>E</given-names></name></person-group><year iso-8601-date="1995">1995</year><article-title>Dynamics of learning and recall at excitatory recurrent synapses and cholinergic modulation in rat hippocampal region CA3</article-title><source>The Journal of Neuroscience</source><volume>15</volume><fpage>5249</fpage><lpage>5262</lpage><pub-id pub-id-type="pmid">7623149</pub-id></element-citation></ref><ref id="bib62"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hasselmo</surname><given-names>ME</given-names></name><name><surname>Wyble</surname><given-names>BP</given-names></name><name><surname>Wallenstein</surname><given-names>GV</given-names></name></person-group><year iso-8601-date="1996">1996</year><article-title>Encoding and retrieval of episodic memories: role of cholinergic and GABAergic modulation in the hippocampus</article-title><source>Hippocampus</source><volume>6</volume><fpage>693</fpage><lpage>708</lpage><pub-id pub-id-type="doi">10.1002/(SICI)1098-1063(1996)6:6&lt;693::AID-HIPO12&gt;3.0.CO;2-W</pub-id><pub-id pub-id-type="pmid">9034856</pub-id></element-citation></ref><ref id="bib63"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hasselmo</surname><given-names>ME</given-names></name><name><surname>Wyble</surname><given-names>BP</given-names></name></person-group><year iso-8601-date="1997">1997</year><article-title>Free recall and recognition in a network model of the hippocampus: simulating effects of scopolamine on human memory function</article-title><source>Behavioural Brain Research</source><volume>89</volume><fpage>1</fpage><lpage>34</lpage><pub-id pub-id-type="doi">10.1016/s0166-4328(97)00048-x</pub-id><pub-id pub-id-type="pmid">9475612</pub-id></element-citation></ref><ref id="bib64"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hasson</surname><given-names>U</given-names></name><name><surname>Nir</surname><given-names>Y</given-names></name><name><surname>Levy</surname><given-names>I</given-names></name><name><surname>Fuhrmann</surname><given-names>G</given-names></name><name><surname>Malach</surname><given-names>R</given-names></name></person-group><year iso-8601-date="2004">2004</year><article-title>Intersubject synchronization of cortical activity during natural vision</article-title><source>Science (New York, N.Y.)</source><volume>303</volume><fpage>1634</fpage><lpage>1640</lpage><pub-id pub-id-type="doi">10.1126/science.1089506</pub-id><pub-id pub-id-type="pmid">15016991</pub-id></element-citation></ref><ref id="bib65"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hasson</surname><given-names>U</given-names></name><name><surname>Chen</surname><given-names>J</given-names></name><name><surname>Honey</surname><given-names>CJ</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>Hierarchical process memory: memory as an integral component of information processing</article-title><source>Trends in Cognitive Sciences</source><volume>19</volume><fpage>304</fpage><lpage>313</lpage><pub-id pub-id-type="doi">10.1016/j.tics.2015.04.006</pub-id><pub-id pub-id-type="pmid">25980649</pub-id></element-citation></ref><ref id="bib66"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Haxby</surname><given-names>JV</given-names></name><name><surname>Gobbini</surname><given-names>MI</given-names></name><name><surname>Furey</surname><given-names>ML</given-names></name><name><surname>Ishai</surname><given-names>A</given-names></name><name><surname>Schouten</surname><given-names>JL</given-names></name><name><surname>Pietrini</surname><given-names>P</given-names></name></person-group><year iso-8601-date="2001">2001</year><article-title>Distributed and overlapping representations of faces and objects in ventral temporal cortex</article-title><source>Science (New York, N.Y.)</source><volume>293</volume><fpage>2425</fpage><lpage>2430</lpage><pub-id pub-id-type="doi">10.1126/science.1063736</pub-id><pub-id pub-id-type="pmid">11577229</pub-id></element-citation></ref><ref id="bib67"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Haxby</surname><given-names>JV</given-names></name><name><surname>Guntupalli</surname><given-names>JS</given-names></name><name><surname>Connolly</surname><given-names>AC</given-names></name><name><surname>Halchenko</surname><given-names>YO</given-names></name><name><surname>Conroy</surname><given-names>BR</given-names></name><name><surname>Gobbini</surname><given-names>MI</given-names></name><name><surname>Hanke</surname><given-names>M</given-names></name><name><surname>Ramadge</surname><given-names>PJ</given-names></name></person-group><year iso-8601-date="2011">2011</year><article-title>A common, high-dimensional model of the representational space in human ventral temporal cortex</article-title><source>Neuron</source><volume>72</volume><fpage>404</fpage><lpage>416</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2011.08.026</pub-id><pub-id pub-id-type="pmid">22017997</pub-id></element-citation></ref><ref id="bib68"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Haxby</surname><given-names>JV</given-names></name><name><surname>Guntupalli</surname><given-names>JS</given-names></name><name><surname>Nastase</surname><given-names>SA</given-names></name><name><surname>Feilong</surname><given-names>M</given-names></name></person-group><year iso-8601-date="2020">2020</year><article-title>Hyperalignment: Modeling shared information encoded in idiosyncratic cortical topographies</article-title><source>eLife</source><volume>9</volume><elocation-id>e56601</elocation-id><pub-id pub-id-type="doi">10.7554/eLife.56601</pub-id></element-citation></ref><ref id="bib69"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hochreiter</surname><given-names>S</given-names></name><name><surname>Schmidhuber</surname><given-names>J</given-names></name></person-group><year iso-8601-date="1997">1997</year><article-title>Long short-term memory</article-title><source>Neural Computation</source><volume>9</volume><fpage>1735</fpage><lpage>1780</lpage><pub-id pub-id-type="doi">10.1162/neco.1997.9.8.1735</pub-id><pub-id pub-id-type="pmid">9377276</pub-id></element-citation></ref><ref id="bib70"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Holdstock</surname><given-names>JS</given-names></name><name><surname>Mayes</surname><given-names>AR</given-names></name><name><surname>Roberts</surname><given-names>N</given-names></name><name><surname>Cezayirli</surname><given-names>E</given-names></name><name><surname>Isaac</surname><given-names>CL</given-names></name><name><surname>O’Reilly</surname><given-names>RC</given-names></name><name><surname>Norman</surname><given-names>KA</given-names></name></person-group><year iso-8601-date="2002">2002</year><article-title>Under what conditions is recognition spared relative to recall after selective hippocampal damage in humans?</article-title><source>Hippocampus</source><volume>12</volume><fpage>341</fpage><lpage>351</lpage><pub-id pub-id-type="doi">10.1002/hipo.10011</pub-id><pub-id pub-id-type="pmid">12099485</pub-id></element-citation></ref><ref id="bib71"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Howard</surname><given-names>MW</given-names></name><name><surname>Kahana</surname><given-names>MJ</given-names></name></person-group><year iso-8601-date="2002">2002</year><article-title>A distributed representation of temporal context</article-title><source>Journal of Mathematical Psychology</source><volume>46</volume><fpage>269</fpage><lpage>299</lpage><pub-id pub-id-type="doi">10.1006/jmps.2001.1388</pub-id></element-citation></ref><ref id="bib72"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Howard</surname><given-names>MW</given-names></name><name><surname>Eichenbaum</surname><given-names>H</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>The hippocampus, time, and memory across scales</article-title><source>Journal of Experimental Psychology. General</source><volume>142</volume><fpage>1211</fpage><lpage>1230</lpage><pub-id pub-id-type="doi">10.1037/a0033621</pub-id><pub-id pub-id-type="pmid">23915126</pub-id></element-citation></ref><ref id="bib73"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Howard</surname><given-names>MW</given-names></name><name><surname>MacDonald</surname><given-names>CJ</given-names></name><name><surname>Tiganj</surname><given-names>Z</given-names></name><name><surname>Shankar</surname><given-names>KH</given-names></name><name><surname>Du</surname><given-names>Q</given-names></name><name><surname>Hasselmo</surname><given-names>ME</given-names></name><name><surname>Eichenbaum</surname><given-names>H</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>A unified mathematical framework for coding time, space, and sequences in the hippocampal region</article-title><source>The Journal of Neuroscience</source><volume>34</volume><fpage>4692</fpage><lpage>4707</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.5808-12.2014</pub-id><pub-id pub-id-type="pmid">24672015</pub-id></element-citation></ref><ref id="bib74"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hulbert</surname><given-names>JC</given-names></name><name><surname>Norman</surname><given-names>KA</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>Neural differentiation tracks improved recall of competing memories following interleaved study and retrieval practice</article-title><source>Cerebral Cortex (New York, N.Y)</source><volume>25</volume><fpage>3994</fpage><lpage>4008</lpage><pub-id pub-id-type="doi">10.1093/cercor/bhu284</pub-id><pub-id pub-id-type="pmid">25477369</pub-id></element-citation></ref><ref id="bib75"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kafkas</surname><given-names>A</given-names></name><name><surname>Montaldi</surname><given-names>D</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>Striatal and midbrain connectivity with the hippocampus selectively boosts memory for contextual novelty</article-title><source>Hippocampus</source><volume>25</volume><fpage>1262</fpage><lpage>1273</lpage><pub-id pub-id-type="doi">10.1002/hipo.22434</pub-id><pub-id pub-id-type="pmid">25708843</pub-id></element-citation></ref><ref id="bib76"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kafkas</surname><given-names>A</given-names></name><name><surname>Montaldi</surname><given-names>D</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>Expectation affects learning and modulates memory experience at retrieval</article-title><source>Cognition</source><volume>180</volume><fpage>123</fpage><lpage>134</lpage><pub-id pub-id-type="doi">10.1016/j.cognition.2018.07.010</pub-id><pub-id pub-id-type="pmid">30053569</pub-id></element-citation></ref><ref id="bib77"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Kahana</surname><given-names>MJ</given-names></name></person-group><year iso-8601-date="2012">2012</year><source>Foundations of Human Memory</source><publisher-loc>USA</publisher-loc><publisher-name>Oxford University Press</publisher-name></element-citation></ref><ref id="bib78"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ketz</surname><given-names>N</given-names></name><name><surname>Morkonda</surname><given-names>SG</given-names></name><name><surname>O’Reilly</surname><given-names>RC</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>Theta coordinated error-driven learning in the hippocampus</article-title><source>PLOS Computational Biology</source><volume>9</volume><elocation-id>e1003067</elocation-id><pub-id pub-id-type="doi">10.1371/journal.pcbi.1003067</pub-id><pub-id pub-id-type="pmid">23762019</pub-id></element-citation></ref><ref id="bib79"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kim</surname><given-names>G</given-names></name><name><surname>Norman</surname><given-names>KA</given-names></name><name><surname>Turk-Browne</surname><given-names>NB</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>Neural differentiation of incorrectly predicted memories</article-title><source>The Journal of Neuroscience</source><volume>37</volume><fpage>2022</fpage><lpage>2031</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.3272-16.2017</pub-id><pub-id pub-id-type="pmid">28115478</pub-id></element-citation></ref><ref id="bib80"><element-citation publication-type="preprint"><person-group person-group-type="author"><name><surname>Kingma</surname><given-names>DP</given-names></name><name><surname>Ba</surname><given-names>J</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>Adam: A method for stochastic optimization</article-title><source>arXiv</source><ext-link ext-link-type="uri" xlink:href="https://arxiv.org/abs/1412.6980">https://arxiv.org/abs/1412.6980</ext-link></element-citation></ref><ref id="bib81"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Koster</surname><given-names>R</given-names></name><name><surname>Chadwick</surname><given-names>MJ</given-names></name><name><surname>Chen</surname><given-names>Y</given-names></name><name><surname>Berron</surname><given-names>D</given-names></name><name><surname>Banino</surname><given-names>A</given-names></name><name><surname>Düzel</surname><given-names>E</given-names></name><name><surname>Hassabis</surname><given-names>D</given-names></name><name><surname>Kumaran</surname><given-names>D</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>Big-loop recurrence within the hippocampal system supports integration of information across episodes</article-title><source>Neuron</source><volume>99</volume><fpage>1342</fpage><lpage>1354</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2018.08.009</pub-id></element-citation></ref><ref id="bib82"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kumar</surname><given-names>M</given-names></name><name><surname>Antony</surname><given-names>J</given-names></name><name><surname>Baldassano</surname><given-names>C</given-names></name><name><surname>Brooks</surname><given-names>PP</given-names></name><name><surname>Cai</surname><given-names>MB</given-names></name><name><surname>Chen</surname><given-names>PHC</given-names></name><name><surname>Ellis</surname><given-names>CT</given-names></name><name><surname>Henselman-Petrusek</surname><given-names>G</given-names></name><name><surname>Huberdeau</surname><given-names>D</given-names></name><name><surname>Hutchinson</surname><given-names>JB</given-names></name><name><surname>Li</surname><given-names>YP</given-names></name><name><surname>Lu</surname><given-names>Q</given-names></name><name><surname>Manning</surname><given-names>JR</given-names></name><name><surname>Mennen</surname><given-names>AC</given-names></name><name><surname>Nastase</surname><given-names>SA</given-names></name><name><surname>Richard</surname><given-names>H</given-names></name><name><surname>Schapiro</surname><given-names>AC</given-names></name><name><surname>Schuck</surname><given-names>NW</given-names></name><name><surname>Shvartsman</surname><given-names>M</given-names></name><name><surname>Sundaram</surname><given-names>N</given-names></name><name><surname>Suo</surname><given-names>D</given-names></name><name><surname>Turek</surname><given-names>JS</given-names></name><name><surname>Turner</surname><given-names>D</given-names></name><name><surname>Vo</surname><given-names>V</given-names></name><name><surname>Wallace</surname><given-names>G</given-names></name><name><surname>Wang</surname><given-names>Y</given-names></name><name><surname>Williams</surname><given-names>JA</given-names></name><name><surname>Zhang</surname><given-names>H</given-names></name><name><surname>Zhu</surname><given-names>X</given-names></name><name><surname>Capota</surname><given-names>M</given-names></name><name><surname>Cohen</surname><given-names>JD</given-names></name><name><surname>Hasson</surname><given-names>U</given-names></name><name><surname>Li</surname><given-names>K</given-names></name><name><surname>Ramadge</surname><given-names>PJ</given-names></name><name><surname>Turk-Browne</surname><given-names>N</given-names></name><name><surname>Willke</surname><given-names>TL</given-names></name><name><surname>Norman</surname><given-names>KA</given-names></name></person-group><year iso-8601-date="2020">2020a</year><article-title>BrainIAK: the brain imaging analysis kit</article-title><source>Open Science Framework</source><volume>1</volume><elocation-id>db2ev</elocation-id><pub-id pub-id-type="doi">10.31219/osf.io/db2ev</pub-id></element-citation></ref><ref id="bib83"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kumar</surname><given-names>M</given-names></name><name><surname>Ellis</surname><given-names>CT</given-names></name><name><surname>Lu</surname><given-names>Q</given-names></name><name><surname>Zhang</surname><given-names>H</given-names></name><name><surname>Capotă</surname><given-names>M</given-names></name><name><surname>Willke</surname><given-names>TL</given-names></name><name><surname>Ramadge</surname><given-names>PJ</given-names></name><name><surname>Turk-Browne</surname><given-names>NB</given-names></name><name><surname>Norman</surname><given-names>KA</given-names></name><name><surname>Marinazzo</surname><given-names>D</given-names></name></person-group><year iso-8601-date="2020">2020b</year><article-title>BrainIAK tutorials: user-friendly learning materials for advanced fMRI analysis</article-title><source>PLOS Computational Biology</source><volume>16</volume><elocation-id>e1007549</elocation-id><pub-id pub-id-type="doi">10.1371/journal.pcbi.1007549</pub-id><pub-id pub-id-type="pmid">31940340</pub-id></element-citation></ref><ref id="bib84"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kumaran</surname><given-names>D</given-names></name><name><surname>Maguire</surname><given-names>EA</given-names></name></person-group><year iso-8601-date="2006">2006</year><article-title>An unexpected sequence of events: mismatch detection in the human hippocampus</article-title><source>PLOS Biology</source><volume>4</volume><elocation-id>e424</elocation-id><pub-id pub-id-type="doi">10.1371/journal.pbio.0040424</pub-id><pub-id pub-id-type="pmid">17132050</pub-id></element-citation></ref><ref id="bib85"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kumaran</surname><given-names>D</given-names></name><name><surname>Maguire</surname><given-names>EA</given-names></name></person-group><year iso-8601-date="2007">2007</year><article-title>Match mismatch processes underlie human hippocampal responses to associative novelty</article-title><source>The Journal of Neuroscience</source><volume>27</volume><fpage>8517</fpage><lpage>8524</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.1677-07.2007</pub-id><pub-id pub-id-type="pmid">17687029</pub-id></element-citation></ref><ref id="bib86"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Lewis-Peacock</surname><given-names>JA</given-names></name><name><surname>Norman</surname><given-names>KA</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>Competition between items in working memory leads to forgetting</article-title><source>Nature Communications</source><volume>5</volume><elocation-id>5768</elocation-id><pub-id pub-id-type="doi">10.1038/ncomms6768</pub-id><pub-id pub-id-type="pmid">25519874</pub-id></element-citation></ref><ref id="bib87"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Li</surname><given-names>Y</given-names></name><name><surname>Yosinski</surname><given-names>J</given-names></name><name><surname>Clune</surname><given-names>J</given-names></name><name><surname>Lipson</surname><given-names>H</given-names></name><name><surname>Hopcroft</surname><given-names>J</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>Convergent learning: do different neural networks learn the same representations</article-title><source>Proceedings of Machine Learning Research</source><volume>44</volume><fpage>196</fpage><lpage>212</lpage></element-citation></ref><ref id="bib88"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Lieder</surname><given-names>F</given-names></name><name><surname>Griffiths</surname><given-names>TL</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>Resource-rational analysis: understanding human cognition as the optimal use of limited computational resources</article-title><source>The Behavioral and Brain Sciences</source><volume>43</volume><elocation-id>e1</elocation-id><pub-id pub-id-type="doi">10.1017/S0140525X1900061X</pub-id><pub-id pub-id-type="pmid">30714890</pub-id></element-citation></ref><ref id="bib89"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Liu</surname><given-names>Y</given-names></name><name><surname>Tiganj</surname><given-names>Z</given-names></name><name><surname>Hasselmo</surname><given-names>ME</given-names></name><name><surname>Howard</surname><given-names>MW</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>A neural microcircuit model for a scalable scale-invariant representation of time</article-title><source>Hippocampus</source><volume>29</volume><fpage>260</fpage><lpage>274</lpage><pub-id pub-id-type="doi">10.1002/hipo.22994</pub-id><pub-id pub-id-type="pmid">30421473</pub-id></element-citation></ref><ref id="bib90"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Long</surname><given-names>NM</given-names></name><name><surname>Lee</surname><given-names>H</given-names></name><name><surname>Kuhl</surname><given-names>BA</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Hippocampal mismatch signals are modulated by the strength of neural predictions and their similarity to outcomes</article-title><source>The Journal of Neuroscience</source><volume>36</volume><fpage>12677</fpage><lpage>12687</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.1850-16.2016</pub-id><pub-id pub-id-type="pmid">27821577</pub-id></element-citation></ref><ref id="bib91"><element-citation publication-type="preprint"><person-group person-group-type="author"><name><surname>Lu</surname><given-names>Q</given-names></name><name><surname>Chen</surname><given-names>PH</given-names></name><name><surname>Pillow</surname><given-names>JW</given-names></name><name><surname>Ramadge</surname><given-names>PJ</given-names></name><name><surname>Norman</surname><given-names>KA</given-names></name><name><surname>Hasson</surname><given-names>U</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>Shared representational geometry across neural networks</article-title><source>arXiv</source><ext-link ext-link-type="uri" xlink:href="https://arxiv.org/abs/1811.11684">https://arxiv.org/abs/1811.11684</ext-link></element-citation></ref><ref id="bib92"><element-citation publication-type="software"><person-group person-group-type="author"><name><surname>Lu</surname><given-names>Q</given-names></name></person-group><year iso-8601-date="2022">2022</year><data-title>learn-hippo</data-title><version designator="swh:1:rev:6a4a1be4fd6780d4c8413ffc6b1facade4741135">swh:1:rev:6a4a1be4fd6780d4c8413ffc6b1facade4741135</version><source>Software Heritage</source><ext-link ext-link-type="uri" xlink:href="https://archive.softwareheritage.org/swh:1:dir:d1b85f3093b5d6c9ba3a84c0a54f4dba8a8b0482;origin=https://github.com/qihongl/learn-hippo;visit=swh:1:snp:dc3599b04a53f31e3ab0987693a392562a42a802;anchor=swh:1:rev:6a4a1be4fd6780d4c8413ffc6b1facade4741135">https://archive.softwareheritage.org/swh:1:dir:d1b85f3093b5d6c9ba3a84c0a54f4dba8a8b0482;origin=https://github.com/qihongl/learn-hippo;visit=swh:1:snp:dc3599b04a53f31e3ab0987693a392562a42a802;anchor=swh:1:rev:6a4a1be4fd6780d4c8413ffc6b1facade4741135</ext-link></element-citation></ref><ref id="bib93"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>MacDonald</surname><given-names>CJ</given-names></name><name><surname>Lepage</surname><given-names>KQ</given-names></name><name><surname>Eden</surname><given-names>UT</given-names></name><name><surname>Eichenbaum</surname><given-names>H</given-names></name></person-group><year iso-8601-date="2011">2011</year><article-title>Hippocampal “time cells” bridge the gap in memory for discontiguous events</article-title><source>Neuron</source><volume>71</volume><fpage>737</fpage><lpage>749</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2011.07.012</pub-id><pub-id pub-id-type="pmid">21867888</pub-id></element-citation></ref><ref id="bib94"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>McClelland</surname><given-names>JL</given-names></name><name><surname>Rumelhart</surname><given-names>DE</given-names></name></person-group><year iso-8601-date="1987">1987</year><source>Parallel Distributed Processing</source><publisher-name>MIT Press</publisher-name><pub-id pub-id-type="doi">10.7551/mitpress/5237.001.0001</pub-id></element-citation></ref><ref id="bib95"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>McClelland</surname><given-names>JL</given-names></name><name><surname>McNaughton</surname><given-names>BL</given-names></name><name><surname>O’Reilly</surname><given-names>RC</given-names></name></person-group><year iso-8601-date="1995">1995</year><article-title>Why there are complementary learning systems in the hippocampus and neocortex: insights from the successes and failures of connectionist models of learning and memory</article-title><source>Psychological Review</source><volume>102</volume><fpage>419</fpage><lpage>457</lpage><pub-id pub-id-type="doi">10.1037/0033-295X.102.3.419</pub-id><pub-id pub-id-type="pmid">7624455</pub-id></element-citation></ref><ref id="bib96"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>McClelland</surname><given-names>JL</given-names></name><name><surname>Rogers</surname><given-names>TT</given-names></name></person-group><year iso-8601-date="2003">2003</year><article-title>The parallel distributed processing approach to semantic cognition</article-title><source>Nature Reviews. Neuroscience</source><volume>4</volume><fpage>310</fpage><lpage>322</lpage><pub-id pub-id-type="doi">10.1038/nrn1076</pub-id><pub-id pub-id-type="pmid">12671647</pub-id></element-citation></ref><ref id="bib97"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>McClelland</surname><given-names>JL</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>Incorporating rapid neocortical learning of new schema-consistent information into complementary learning systems theory</article-title><source>Journal of Experimental Psychology. General</source><volume>142</volume><fpage>1190</fpage><lpage>1210</lpage><pub-id pub-id-type="doi">10.1037/a0033812</pub-id><pub-id pub-id-type="pmid">23978185</pub-id></element-citation></ref><ref id="bib98"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>McClelland</surname><given-names>JL</given-names></name><name><surname>McNaughton</surname><given-names>BL</given-names></name><name><surname>Lampinen</surname><given-names>AK</given-names></name></person-group><year iso-8601-date="2020">2020</year><article-title>Integration of new information in memory: new insights from a complementary learning systems perspective</article-title><source>Philosophical Transactions of the Royal Society of London. Series B, Biological Sciences</source><volume>375</volume><elocation-id>20190637</elocation-id><pub-id pub-id-type="doi">10.1098/rstb.2019.0637</pub-id><pub-id pub-id-type="pmid">32248773</pub-id></element-citation></ref><ref id="bib99"><element-citation publication-type="preprint"><person-group person-group-type="author"><name><surname>Meng</surname><given-names>Q</given-names></name><name><surname>Chen</surname><given-names>W</given-names></name><name><surname>Zheng</surname><given-names>S</given-names></name><name><surname>Ye</surname><given-names>Q</given-names></name><name><surname>Liu</surname><given-names>TY</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>Learning to optimize neural nets</article-title><source>arXiv</source><ext-link ext-link-type="uri" xlink:href="https://arxiv.org/pdf/1703.00441.pdf">https://arxiv.org/pdf/1703.00441.pdf</ext-link></element-citation></ref><ref id="bib100"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Michelmann</surname><given-names>S</given-names></name><name><surname>Price</surname><given-names>AR</given-names></name><name><surname>Aubrey</surname><given-names>B</given-names></name><name><surname>Strauss</surname><given-names>CK</given-names></name><name><surname>Doyle</surname><given-names>WK</given-names></name><name><surname>Friedman</surname><given-names>D</given-names></name><name><surname>Dugan</surname><given-names>PC</given-names></name><name><surname>Devinsky</surname><given-names>O</given-names></name><name><surname>Devore</surname><given-names>S</given-names></name><name><surname>Flinker</surname><given-names>A</given-names></name><name><surname>Hasson</surname><given-names>U</given-names></name><name><surname>Norman</surname><given-names>KA</given-names></name></person-group><year iso-8601-date="2021">2021</year><article-title>Moment-by-moment tracking of naturalistic learning and its underlying hippocampo-cortical interactions</article-title><source>Nature Communications</source><volume>12</volume><fpage>1</fpage><lpage>15</lpage><pub-id pub-id-type="doi">10.1038/s41467-021-25376-y</pub-id><pub-id pub-id-type="pmid">34518520</pub-id></element-citation></ref><ref id="bib101"><element-citation publication-type="confproc"><person-group person-group-type="author"><name><surname>Misra</surname><given-names>D</given-names></name><name><surname>Langford</surname><given-names>J</given-names></name><name><surname>Artzi</surname><given-names>Y</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>Mapping instructions and visual observations to actions with reinforcement learning</article-title><conf-name>Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing</conf-name><pub-id pub-id-type="doi">10.18653/v1/D17-1106</pub-id></element-citation></ref><ref id="bib102"><element-citation publication-type="preprint"><person-group person-group-type="author"><name><surname>Mnih</surname><given-names>V</given-names></name><name><surname>Badia</surname><given-names>AP</given-names></name><name><surname>Mirza</surname><given-names>M</given-names></name><name><surname>Graves</surname><given-names>A</given-names></name><name><surname>Lillicrap</surname><given-names>TP</given-names></name><name><surname>Harley</surname><given-names>T</given-names></name><name><surname>Silver</surname><given-names>D</given-names></name><name><surname>Kavukcuoglu</surname><given-names>K</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Asynchronous methods for deep reinforcement learning</article-title><source>arXiv</source><ext-link ext-link-type="uri" xlink:href="https://arxiv.org/abs/1602.01783">https://arxiv.org/abs/1602.01783</ext-link></element-citation></ref><ref id="bib103"><element-citation publication-type="confproc"><person-group person-group-type="author"><name><surname>Nagabandi</surname><given-names>A</given-names></name><name><surname>Kahn</surname><given-names>G</given-names></name><name><surname>Fearing</surname><given-names>RS</given-names></name><name><surname>Levine</surname><given-names>S</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>Neural network dynamics for model-based deep reinforcement learning with model-free fine-tuning</article-title><conf-name>2018 IEEE International Conference on Robotics and Automation (ICRA)</conf-name><conf-loc>Brisbane, QLD</conf-loc><pub-id pub-id-type="doi">10.1109/ICRA.2018.8463189</pub-id></element-citation></ref><ref id="bib104"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Nastase</surname><given-names>SA</given-names></name><name><surname>Gazzola</surname><given-names>V</given-names></name><name><surname>Hasson</surname><given-names>U</given-names></name><name><surname>Keysers</surname><given-names>C</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>Measuring shared responses across subjects using intersubject correlation</article-title><source>Social Cognitive and Affective Neuroscience</source><volume>14</volume><fpage>667</fpage><lpage>685</lpage><pub-id pub-id-type="doi">10.1093/scan/nsz037</pub-id><pub-id pub-id-type="pmid">31099394</pub-id></element-citation></ref><ref id="bib105"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Nastase</surname><given-names>SA</given-names></name><name><surname>Goldstein</surname><given-names>A</given-names></name><name><surname>Hasson</surname><given-names>U</given-names></name></person-group><year iso-8601-date="2020">2020</year><article-title>Keep it real: rethinking the primacy of experimental control in cognitive neuroscience</article-title><source>NeuroImage</source><volume>222</volume><elocation-id>117254</elocation-id><pub-id pub-id-type="doi">10.1016/j.neuroimage.2020.117254</pub-id><pub-id pub-id-type="pmid">32800992</pub-id></element-citation></ref><ref id="bib106"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Norman</surname><given-names>KA</given-names></name><name><surname>O’Reilly</surname><given-names>RC</given-names></name></person-group><year iso-8601-date="2003">2003</year><article-title>Modeling hippocampal and neocortical contributions to recognition memory: a complementary-learning-systems approach</article-title><source>Psychological Review</source><volume>110</volume><fpage>611</fpage><lpage>646</lpage><pub-id pub-id-type="doi">10.1037/0033-295X.110.4.611</pub-id><pub-id pub-id-type="pmid">14599236</pub-id></element-citation></ref><ref id="bib107"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Norman</surname><given-names>KA</given-names></name><name><surname>Polyn</surname><given-names>SM</given-names></name><name><surname>Detre</surname><given-names>GJ</given-names></name><name><surname>Haxby</surname><given-names>JV</given-names></name></person-group><year iso-8601-date="2006">2006</year><article-title>Beyond mind-reading: multi-voxel pattern analysis of fMRI data</article-title><source>Trends in Cognitive Sciences</source><volume>10</volume><fpage>424</fpage><lpage>430</lpage><pub-id pub-id-type="doi">10.1016/j.tics.2006.07.005</pub-id><pub-id pub-id-type="pmid">16899397</pub-id></element-citation></ref><ref id="bib108"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Norman</surname><given-names>KA</given-names></name><name><surname>Detre</surname><given-names>G</given-names></name><name><surname>Polyn</surname><given-names>SM</given-names></name></person-group><year iso-8601-date="2008">2008</year><chapter-title>Computational models of episodic memory</chapter-title><person-group person-group-type="editor"><name><surname>Sun</surname><given-names>R</given-names></name></person-group><source>The Cambridge Handbook of Computational Psychology, Cambridge Handbooks in Psychology</source><publisher-name>Cambridge University Press</publisher-name><fpage>1</fpage><lpage>2</lpage><pub-id pub-id-type="doi">10.1017/CBO9780511816772</pub-id></element-citation></ref><ref id="bib109"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Norman</surname><given-names>KA</given-names></name></person-group><year iso-8601-date="2010">2010</year><article-title>How hippocampus and cortex contribute to recognition memory: revisiting the complementary learning systems model</article-title><source>Hippocampus</source><volume>20</volume><fpage>1217</fpage><lpage>1227</lpage><pub-id pub-id-type="doi">10.1002/hipo.20855</pub-id><pub-id pub-id-type="pmid">20857486</pub-id></element-citation></ref><ref id="bib110"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Palombo</surname><given-names>DJ</given-names></name><name><surname>Keane</surname><given-names>MM</given-names></name><name><surname>Verfaellie</surname><given-names>M</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>How does the hippocampus shape decisions?</article-title><source>Neurobiology of Learning and Memory</source><volume>125</volume><fpage>93</fpage><lpage>97</lpage><pub-id pub-id-type="doi">10.1016/j.nlm.2015.08.005</pub-id><pub-id pub-id-type="pmid">26297967</pub-id></element-citation></ref><ref id="bib111"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Palombo</surname><given-names>DJ</given-names></name><name><surname>Hayes</surname><given-names>SM</given-names></name><name><surname>Reid</surname><given-names>AG</given-names></name><name><surname>Verfaellie</surname><given-names>M</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>Hippocampal contributions to value-based learning: Converging evidence from fMRI and amnesia</article-title><source>Cognitive, Affective &amp; Behavioral Neuroscience</source><volume>19</volume><fpage>523</fpage><lpage>536</lpage><pub-id pub-id-type="doi">10.3758/s13415-018-00687-8</pub-id><pub-id pub-id-type="pmid">30767129</pub-id></element-citation></ref><ref id="bib112"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Pastalkova</surname><given-names>E</given-names></name><name><surname>Itskov</surname><given-names>V</given-names></name><name><surname>Amarasingham</surname><given-names>A</given-names></name><name><surname>Buzsáki</surname><given-names>G</given-names></name></person-group><year iso-8601-date="2008">2008</year><article-title>Internally generated cell assembly sequences in the rat hippocampus</article-title><source>Science (New York, N.Y.)</source><volume>321</volume><fpage>1322</fpage><lpage>1327</lpage><pub-id pub-id-type="doi">10.1126/science.1159775</pub-id><pub-id pub-id-type="pmid">18772431</pub-id></element-citation></ref><ref id="bib113"><element-citation publication-type="confproc"><person-group person-group-type="author"><name><surname>Paszke</surname><given-names>A</given-names></name><name><surname>Gross</surname><given-names>S</given-names></name><name><surname>Chintala</surname><given-names>S</given-names></name><name><surname>Chanan</surname><given-names>G</given-names></name><name><surname>Yang</surname><given-names>E</given-names></name><name><surname>DeVito</surname><given-names>Z</given-names></name><name><surname>Lin</surname><given-names>Z</given-names></name><name><surname>Desmaison</surname><given-names>A</given-names></name><name><surname>Antiga</surname><given-names>L</given-names></name><name><surname>Lerer</surname><given-names>A</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>Automatic differentiation in PyTorch</article-title><conf-name>NIPS 2017 Workshop Autodiff Program Chairs</conf-name></element-citation></ref><ref id="bib114"><element-citation publication-type="preprint"><person-group person-group-type="author"><name><surname>Paszke</surname><given-names>A</given-names></name><name><surname>Gross</surname><given-names>S</given-names></name><name><surname>Massa</surname><given-names>F</given-names></name><name><surname>Lerer</surname><given-names>A</given-names></name><name><surname>Bradbury</surname><given-names>J</given-names></name><name><surname>Chanan</surname><given-names>G</given-names></name><name><surname>Killeen</surname><given-names>T</given-names></name><name><surname>Lin</surname><given-names>Z</given-names></name><name><surname>Gimelshein</surname><given-names>N</given-names></name><name><surname>Antiga</surname><given-names>L</given-names></name><name><surname>Desmaison</surname><given-names>A</given-names></name><name><surname>Köpf</surname><given-names>A</given-names></name><name><surname>Yang</surname><given-names>E</given-names></name><name><surname>DeVito</surname><given-names>Z</given-names></name><name><surname>Raison</surname><given-names>M</given-names></name><name><surname>Tejani</surname><given-names>A</given-names></name><name><surname>Chilamkurthy</surname><given-names>S</given-names></name><name><surname>Steiner</surname><given-names>B</given-names></name><name><surname>Fang</surname><given-names>L</given-names></name><name><surname>Bai</surname><given-names>J</given-names></name><name><surname>Chintala</surname><given-names>S</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>PyTorch: An imperative style, high-performance deep learning library</article-title><source>arXiv</source><ext-link ext-link-type="uri" xlink:href="https://arxiv.org/abs/1912.01703">https://arxiv.org/abs/1912.01703</ext-link></element-citation></ref><ref id="bib115"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Patil</surname><given-names>A</given-names></name><name><surname>Duncan</surname><given-names>K</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>Lingering cognitive states shape fundamental mnemonic abilities</article-title><source>Psychological Science</source><volume>29</volume><fpage>45</fpage><lpage>55</lpage><pub-id pub-id-type="doi">10.1177/0956797617728592</pub-id><pub-id pub-id-type="pmid">29116882</pub-id></element-citation></ref><ref id="bib116"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Pine</surname><given-names>A</given-names></name><name><surname>Sadeh</surname><given-names>N</given-names></name><name><surname>Ben-Yakov</surname><given-names>A</given-names></name><name><surname>Dudai</surname><given-names>Y</given-names></name><name><surname>Mendelsohn</surname><given-names>A</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>Knowledge acquisition is governed by striatal prediction errors</article-title><source>Nature Communications</source><volume>9</volume><elocation-id>1673</elocation-id><pub-id pub-id-type="doi">10.1038/s41467-018-03992-5</pub-id><pub-id pub-id-type="pmid">29700377</pub-id></element-citation></ref><ref id="bib117"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Pitman</surname><given-names>J</given-names></name></person-group><year iso-8601-date="2006">2006</year><source>Combinatorial Stochastic Processes: Ecole d’Eté de Probabilités de Saint-Flour XXXII – 2002</source><publisher-loc>Berlin, Heidelberg</publisher-loc><publisher-name>Springer</publisher-name></element-citation></ref><ref id="bib118"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Polyn</surname><given-names>SM</given-names></name><name><surname>Norman</surname><given-names>KA</given-names></name><name><surname>Kahana</surname><given-names>MJ</given-names></name></person-group><year iso-8601-date="2009">2009</year><article-title>A context maintenance and retrieval model of organizational processes in free recall</article-title><source>Psychological Review</source><volume>116</volume><fpage>129</fpage><lpage>156</lpage><pub-id pub-id-type="doi">10.1037/a0014420</pub-id><pub-id pub-id-type="pmid">19159151</pub-id></element-citation></ref><ref id="bib119"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Preston</surname><given-names>AR</given-names></name><name><surname>Eichenbaum</surname><given-names>H</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>Interplay of hippocampus and prefrontal cortex in memory</article-title><source>Current Biology</source><volume>23</volume><fpage>R764</fpage><lpage>R773</lpage><pub-id pub-id-type="doi">10.1016/j.cub.2013.05.041</pub-id><pub-id pub-id-type="pmid">24028960</pub-id></element-citation></ref><ref id="bib120"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Pritzel</surname><given-names>A</given-names></name><name><surname>Uria</surname><given-names>B</given-names></name><name><surname>Srinivasan</surname><given-names>S</given-names></name><name><surname>Badia</surname><given-names>AP</given-names></name><name><surname>Vinyals</surname><given-names>O</given-names></name><name><surname>Hassabis</surname><given-names>D</given-names></name><name><surname>Wierstra</surname><given-names>D</given-names></name><name><surname>Blundell</surname><given-names>C</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>Neural episodic control</article-title><source>Proceedings of Machine Learning Research</source><volume>70</volume><fpage>2827</fpage><lpage>2836</lpage></element-citation></ref><ref id="bib121"><element-citation publication-type="preprint"><person-group person-group-type="author"><name><surname>Quent</surname><given-names>JA</given-names></name><name><surname>Greve</surname><given-names>A</given-names></name><name><surname>Henson</surname><given-names>R</given-names></name></person-group><year iso-8601-date="2021">2021a</year><article-title>Shape of U: The relationship between object-location memory and expectedness</article-title><source>PsyArXiv</source><pub-id pub-id-type="doi">10.31234/osf.io/xq37j</pub-id></element-citation></ref><ref id="bib122"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Quent</surname><given-names>JA</given-names></name><name><surname>Henson</surname><given-names>RN</given-names></name><name><surname>Greve</surname><given-names>A</given-names></name></person-group><year iso-8601-date="2021">2021b</year><article-title>A predictive account of how novelty influences declarative memory</article-title><source>Neurobiology of Learning and Memory</source><volume>179</volume><elocation-id>107382</elocation-id><pub-id pub-id-type="doi">10.1016/j.nlm.2021.107382</pub-id><pub-id pub-id-type="pmid">33476747</pub-id></element-citation></ref><ref id="bib123"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Radvansky</surname><given-names>GA</given-names></name><name><surname>Krawietz</surname><given-names>SA</given-names></name><name><surname>Tamplin</surname><given-names>AK</given-names></name></person-group><year iso-8601-date="2011">2011</year><article-title>Walking through doorways causes forgetting: further explorations</article-title><source>Quarterly Journal of Experimental Psychology</source><volume>64</volume><fpage>1632</fpage><lpage>1645</lpage><pub-id pub-id-type="doi">10.1080/17470218.2011.571267</pub-id><pub-id pub-id-type="pmid">21563019</pub-id></element-citation></ref><ref id="bib124"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ranganath</surname><given-names>C</given-names></name><name><surname>Ritchey</surname><given-names>M</given-names></name></person-group><year iso-8601-date="2012">2012</year><article-title>Two cortical systems for memory-guided behaviour</article-title><source>Nature Reviews. Neuroscience</source><volume>13</volume><fpage>713</fpage><lpage>726</lpage><pub-id pub-id-type="doi">10.1038/nrn3338</pub-id><pub-id pub-id-type="pmid">22992647</pub-id></element-citation></ref><ref id="bib125"><element-citation publication-type="preprint"><person-group person-group-type="author"><name><surname>Raposo</surname><given-names>D</given-names></name><name><surname>Ritter</surname><given-names>S</given-names></name><name><surname>Santoro</surname><given-names>A</given-names></name><name><surname>Wayne</surname><given-names>G</given-names></name><name><surname>Weber</surname><given-names>T</given-names></name><name><surname>Botvinick</surname><given-names>M</given-names></name><name><surname>Hasselt</surname><given-names>H</given-names></name><name><surname>Song</surname><given-names>F</given-names></name></person-group><year iso-8601-date="2021">2021</year><article-title>Synthetic returns for long-term credit assignment</article-title><source>arXiv</source><ext-link ext-link-type="uri" xlink:href="https://arxiv.org/abs/2102.12425">https://arxiv.org/abs/2102.12425</ext-link></element-citation></ref><ref id="bib126"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Reagh</surname><given-names>ZM</given-names></name><name><surname>Delarazan</surname><given-names>AI</given-names></name><name><surname>Garber</surname><given-names>A</given-names></name><name><surname>Ranganath</surname><given-names>C</given-names></name></person-group><year iso-8601-date="2020">2020</year><article-title>Aging alters neural activity at event boundaries in the hippocampus and Posterior Medial network</article-title><source>Nature Communications</source><volume>11</volume><elocation-id>3980</elocation-id><pub-id pub-id-type="doi">10.1038/s41467-020-17713-4</pub-id><pub-id pub-id-type="pmid">32769969</pub-id></element-citation></ref><ref id="bib127"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Richmond</surname><given-names>LL</given-names></name><name><surname>Zacks</surname><given-names>JM</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>Constructing experience: event models from perception to action</article-title><source>Trends in Cognitive Sciences</source><volume>21</volume><fpage>962</fpage><lpage>980</lpage><pub-id pub-id-type="doi">10.1016/j.tics.2017.08.005</pub-id><pub-id pub-id-type="pmid">28899609</pub-id></element-citation></ref><ref id="bib128"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ritchey</surname><given-names>M</given-names></name><name><surname>Cooper</surname><given-names>RA</given-names></name></person-group><year iso-8601-date="2020">2020</year><article-title>Deconstructing the posterior medial episodic network</article-title><source>Trends in Cognitive Sciences</source><volume>24</volume><fpage>451</fpage><lpage>465</lpage><pub-id pub-id-type="doi">10.1016/j.tics.2020.03.006</pub-id><pub-id pub-id-type="pmid">32340798</pub-id></element-citation></ref><ref id="bib129"><element-citation publication-type="confproc"><person-group person-group-type="author"><name><surname>Ritter</surname><given-names>S</given-names></name><name><surname>Wang</surname><given-names>JX</given-names></name><name><surname>Kurth-Nelson</surname><given-names>Z</given-names></name><name><surname>Jayakumar</surname><given-names>SM</given-names></name><name><surname>Blundell</surname><given-names>C</given-names></name><name><surname>Pascanu</surname><given-names>R</given-names></name><name><surname>Botvinick</surname><given-names>M</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>Been there, done that: meta-learning with episodic recall</article-title><conf-name>Proceedings of the International Conference on Machine Learning</conf-name></element-citation></ref><ref id="bib130"><element-citation publication-type="thesis"><person-group person-group-type="author"><name><surname>Ritter</surname><given-names>S</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>Meta-reinforcement learning with episodic recall: an integrative theory of reward-driven learning. PhD thesis</article-title><publisher-name>Princeton University</publisher-name></element-citation></ref><ref id="bib131"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ritvo</surname><given-names>VJH</given-names></name><name><surname>Turk-Browne</surname><given-names>NB</given-names></name><name><surname>Norman</surname><given-names>KA</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>Nonmonotonic plasticity: how memory retrieval drives learning</article-title><source>Trends in Cognitive Sciences</source><volume>23</volume><fpage>726</fpage><lpage>742</lpage><pub-id pub-id-type="doi">10.1016/j.tics.2019.06.007</pub-id><pub-id pub-id-type="pmid">31358438</pub-id></element-citation></ref><ref id="bib132"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Rogers</surname><given-names>TT</given-names></name><name><surname>McClelland</surname><given-names>JL</given-names></name></person-group><year iso-8601-date="2004">2004</year><source>Semantic Cognition</source><publisher-loc>Cambridge, MA, US</publisher-loc><publisher-name>MIT Press Semantic cognition</publisher-name><pub-id pub-id-type="doi">10.7551/mitpress/6161.001.0001</pub-id></element-citation></ref><ref id="bib133"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Rouhani</surname><given-names>N</given-names></name><name><surname>Norman</surname><given-names>KA</given-names></name><name><surname>Niv</surname><given-names>Y</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>Dissociable effects of surprising rewards on learning and memory</article-title><source>Journal of Experimental Psychology. Learning, Memory, and Cognition</source><volume>44</volume><fpage>1430</fpage><lpage>1443</lpage><pub-id pub-id-type="doi">10.1037/xlm0000518</pub-id><pub-id pub-id-type="pmid">29553767</pub-id></element-citation></ref><ref id="bib134"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Rouhani</surname><given-names>N</given-names></name><name><surname>Norman</surname><given-names>KA</given-names></name><name><surname>Niv</surname><given-names>Y</given-names></name><name><surname>Bornstein</surname><given-names>AM</given-names></name></person-group><year iso-8601-date="2020">2020</year><article-title>Reward prediction errors create event boundaries in memory</article-title><source>Cognition</source><volume>203</volume><elocation-id>104269</elocation-id><pub-id pub-id-type="doi">10.1016/j.cognition.2020.104269</pub-id><pub-id pub-id-type="pmid">32563083</pub-id></element-citation></ref><ref id="bib135"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Salz</surname><given-names>DM</given-names></name><name><surname>Tiganj</surname><given-names>Z</given-names></name><name><surname>Khasnabish</surname><given-names>S</given-names></name><name><surname>Kohley</surname><given-names>A</given-names></name><name><surname>Sheehan</surname><given-names>D</given-names></name><name><surname>Howard</surname><given-names>MW</given-names></name><name><surname>Eichenbaum</surname><given-names>H</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Time cells in hippocampal area CA3</article-title><source>The Journal of Neuroscience</source><volume>36</volume><fpage>7476</fpage><lpage>7484</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.0087-16.2016</pub-id><pub-id pub-id-type="pmid">27413157</pub-id></element-citation></ref><ref id="bib136"><element-citation publication-type="confproc"><person-group person-group-type="author"><name><surname>Saxe</surname><given-names>AM</given-names></name><name><surname>McClelland</surname><given-names>JL</given-names></name><name><surname>Ganguli</surname><given-names>S</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>Exact solutions to the nonlinear dynamics of learning in deep linear neural networks</article-title><conf-name>International Conference on Learning Representations</conf-name></element-citation></ref><ref id="bib137"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Saxe</surname><given-names>AM</given-names></name><name><surname>McClelland</surname><given-names>JL</given-names></name><name><surname>Ganguli</surname><given-names>S</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>A mathematical theory of semantic development in deep neural networks</article-title><source>PNAS</source><volume>116</volume><fpage>11537</fpage><lpage>11546</lpage><pub-id pub-id-type="doi">10.1073/pnas.1820226116</pub-id><pub-id pub-id-type="pmid">31101713</pub-id></element-citation></ref><ref id="bib138"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Schapiro</surname><given-names>AC</given-names></name><name><surname>Kustner</surname><given-names>LV</given-names></name><name><surname>Turk-Browne</surname><given-names>NB</given-names></name></person-group><year iso-8601-date="2012">2012</year><article-title>Shaping of object representations in the human medial temporal lobe based on temporal regularities</article-title><source>Current Biology</source><volume>22</volume><fpage>1622</fpage><lpage>1627</lpage><pub-id pub-id-type="doi">10.1016/j.cub.2012.06.056</pub-id><pub-id pub-id-type="pmid">22885059</pub-id></element-citation></ref><ref id="bib139"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Schapiro</surname><given-names>AC</given-names></name><name><surname>Rogers</surname><given-names>TT</given-names></name><name><surname>Cordova</surname><given-names>NI</given-names></name><name><surname>Turk-Browne</surname><given-names>NB</given-names></name><name><surname>Botvinick</surname><given-names>MM</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>Neural representations of events arise from temporal community structure</article-title><source>Nature Neuroscience</source><volume>16</volume><fpage>486</fpage><lpage>492</lpage><pub-id pub-id-type="doi">10.1038/nn.3331</pub-id><pub-id pub-id-type="pmid">23416451</pub-id></element-citation></ref><ref id="bib140"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Schapiro</surname><given-names>AC</given-names></name><name><surname>Turk-Browne</surname><given-names>NB</given-names></name><name><surname>Norman</surname><given-names>KA</given-names></name><name><surname>Botvinick</surname><given-names>MM</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Statistical learning of temporal community structure in the hippocampus</article-title><source>Hippocampus</source><volume>26</volume><fpage>3</fpage><lpage>8</lpage><pub-id pub-id-type="doi">10.1002/hipo.22523</pub-id><pub-id pub-id-type="pmid">26332666</pub-id></element-citation></ref><ref id="bib141"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Schapiro</surname><given-names>AC</given-names></name><name><surname>Turk-Browne</surname><given-names>NB</given-names></name><name><surname>Botvinick</surname><given-names>MM</given-names></name><name><surname>Norman</surname><given-names>KA</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>Complementary learning systems within the hippocampus: a neural network modelling approach to reconciling episodic memory with statistical learning</article-title><source>Philosophical Transactions of the Royal Society of London. Series B, Biological Sciences</source><volume>372</volume><elocation-id>20160049</elocation-id><pub-id pub-id-type="doi">10.1098/rstb.2016.0049</pub-id><pub-id pub-id-type="pmid">27872368</pub-id></element-citation></ref><ref id="bib142"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Schlichting</surname><given-names>ML</given-names></name><name><surname>Mumford</surname><given-names>JA</given-names></name><name><surname>Preston</surname><given-names>AR</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>Learning-related representational changes reveal dissociable integration and separation signatures in the hippocampus and prefrontal cortex</article-title><source>Nature Communications</source><volume>6</volume><elocation-id>8151</elocation-id><pub-id pub-id-type="doi">10.1038/ncomms9151</pub-id></element-citation></ref><ref id="bib143"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Sederberg</surname><given-names>PB</given-names></name><name><surname>Howard</surname><given-names>MW</given-names></name><name><surname>Kahana</surname><given-names>MJ</given-names></name></person-group><year iso-8601-date="2008">2008</year><article-title>A context-based theory of recency and contiguity in free recall</article-title><source>Psychological Review</source><volume>115</volume><fpage>893</fpage><lpage>912</lpage><pub-id pub-id-type="doi">10.1037/a0013396</pub-id><pub-id pub-id-type="pmid">18954208</pub-id></element-citation></ref><ref id="bib144"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Shankar</surname><given-names>KH</given-names></name><name><surname>Howard</surname><given-names>MW</given-names></name></person-group><year iso-8601-date="2012">2012</year><article-title>A scale-invariant internal representation of time</article-title><source>Neural Computation</source><volume>24</volume><fpage>134</fpage><lpage>193</lpage><pub-id pub-id-type="doi">10.1162/NECO_a_00212</pub-id><pub-id pub-id-type="pmid">21919782</pub-id></element-citation></ref><ref id="bib145"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Sherman</surname><given-names>BE</given-names></name><name><surname>Turk-Browne</surname><given-names>NB</given-names></name></person-group><year iso-8601-date="2020">2020</year><article-title>Statistical prediction of the future impairs episodic encoding of the present</article-title><source>PNAS</source><volume>117</volume><fpage>22760</fpage><lpage>22770</lpage><pub-id pub-id-type="doi">10.1073/pnas.2013291117</pub-id><pub-id pub-id-type="pmid">32859755</pub-id></element-citation></ref><ref id="bib146"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Shiffrin</surname><given-names>RM</given-names></name><name><surname>Steyvers</surname><given-names>M</given-names></name></person-group><year iso-8601-date="1997">1997</year><article-title>A model for recognition memory: REM-retrieving effectively from memory</article-title><source>Psychonomic Bulletin &amp; Review</source><volume>4</volume><fpage>145</fpage><lpage>166</lpage><pub-id pub-id-type="doi">10.3758/BF03209391</pub-id><pub-id pub-id-type="pmid">21331823</pub-id></element-citation></ref><ref id="bib147"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Shohamy</surname><given-names>D</given-names></name><name><surname>Turk-Browne</surname><given-names>NB</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>Mechanisms for widespread hippocampal involvement in cognition</article-title><source>Journal of Experimental Psychology. General</source><volume>142</volume><fpage>1159</fpage><lpage>1170</lpage><pub-id pub-id-type="doi">10.1037/a0034461</pub-id><pub-id pub-id-type="pmid">24246058</pub-id></element-citation></ref><ref id="bib148"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Simony</surname><given-names>E</given-names></name><name><surname>Honey</surname><given-names>CJ</given-names></name><name><surname>Chen</surname><given-names>J</given-names></name><name><surname>Lositsky</surname><given-names>O</given-names></name><name><surname>Yeshurun</surname><given-names>Y</given-names></name><name><surname>Wiesel</surname><given-names>A</given-names></name><name><surname>Hasson</surname><given-names>U</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Dynamic reconfiguration of the default mode network during narrative comprehension</article-title><source>Nature Communications</source><volume>7</volume><elocation-id>12141</elocation-id><pub-id pub-id-type="doi">10.1038/ncomms12141</pub-id><pub-id pub-id-type="pmid">27424918</pub-id></element-citation></ref><ref id="bib149"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Sonkusare</surname><given-names>S</given-names></name><name><surname>Breakspear</surname><given-names>M</given-names></name><name><surname>Guo</surname><given-names>C</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>Naturalistic stimuli in neuroscience: critically acclaimed</article-title><source>Trends in Cognitive Sciences</source><volume>23</volume><fpage>699</fpage><lpage>714</lpage><pub-id pub-id-type="doi">10.1016/j.tics.2019.05.004</pub-id><pub-id pub-id-type="pmid">31257145</pub-id></element-citation></ref><ref id="bib150"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Stachenfeld</surname><given-names>KL</given-names></name><name><surname>Botvinick</surname><given-names>MM</given-names></name><name><surname>Gershman</surname><given-names>SJ</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>The hippocampus as a predictive map</article-title><source>Nature Neuroscience</source><volume>20</volume><fpage>1643</fpage><lpage>1653</lpage><pub-id pub-id-type="doi">10.1038/nn.4650</pub-id><pub-id pub-id-type="pmid">28967910</pub-id></element-citation></ref><ref id="bib151"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Stawarczyk</surname><given-names>D</given-names></name><name><surname>Bezdek</surname><given-names>MA</given-names></name><name><surname>Zacks</surname><given-names>JM</given-names></name></person-group><year iso-8601-date="2021">2021</year><article-title>Event representations and predictive processing: the role of the midline default network core</article-title><source>Topics in Cognitive Science</source><volume>13</volume><fpage>164</fpage><lpage>186</lpage><pub-id pub-id-type="doi">10.1111/tops.12450</pub-id><pub-id pub-id-type="pmid">31486286</pub-id></element-citation></ref><ref id="bib152"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Sutton</surname><given-names>RS</given-names></name><name><surname>Barto</surname><given-names>AG</given-names></name></person-group><year iso-8601-date="2018">2018</year><source>Reinforcement Learning: An Introduction</source><publisher-name>MIT press</publisher-name></element-citation></ref><ref id="bib153"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Takahashi</surname><given-names>Y</given-names></name><name><surname>Schoenbaum</surname><given-names>G</given-names></name><name><surname>Niv</surname><given-names>Y</given-names></name></person-group><year iso-8601-date="2008">2008</year><article-title>Silencing the critics: understanding the effects of cocaine sensitization on dorsolateral and ventral striatum in the context of an actor/critic model</article-title><source>Frontiers in Neuroscience</source><volume>2</volume><fpage>86</fpage><lpage>99</lpage><pub-id pub-id-type="doi">10.3389/neuro.01.014.2008</pub-id><pub-id pub-id-type="pmid">18982111</pub-id></element-citation></ref><ref id="bib154"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Tiganj</surname><given-names>Z</given-names></name><name><surname>Jung</surname><given-names>MW</given-names></name><name><surname>Kim</surname><given-names>J</given-names></name><name><surname>Howard</surname><given-names>MW</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>Sequential firing codes for time in rodent medial prefrontal cortex</article-title><source>Cerebral Cortex (New York, N.Y</source><volume>27</volume><fpage>5663</fpage><lpage>5671</lpage><pub-id pub-id-type="doi">10.1093/cercor/bhw336</pub-id><pub-id pub-id-type="pmid">29145670</pub-id></element-citation></ref><ref id="bib155"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Usher</surname><given-names>M</given-names></name><name><surname>McClelland</surname><given-names>JL</given-names></name></person-group><year iso-8601-date="2001">2001</year><article-title>The time course of perceptual choice: the leaky, competing accumulator model</article-title><source>Psychological Review</source><volume>108</volume><fpage>550</fpage><lpage>592</lpage><pub-id pub-id-type="doi">10.1037/0033-295X.108.3.550</pub-id><pub-id pub-id-type="pmid">11488378</pub-id></element-citation></ref><ref id="bib156"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>van Kesteren</surname><given-names>MTR</given-names></name><name><surname>Ruiter</surname><given-names>DJ</given-names></name><name><surname>Fernández</surname><given-names>G</given-names></name><name><surname>Henson</surname><given-names>RN</given-names></name></person-group><year iso-8601-date="2012">2012</year><article-title>How schema and novelty augment memory formation</article-title><source>Trends in Neurosciences</source><volume>35</volume><fpage>211</fpage><lpage>219</lpage><pub-id pub-id-type="doi">10.1016/j.tins.2012.02.001</pub-id><pub-id pub-id-type="pmid">22398180</pub-id></element-citation></ref><ref id="bib157"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>van Strien</surname><given-names>NM</given-names></name><name><surname>Cappaert</surname><given-names>NLM</given-names></name><name><surname>Witter</surname><given-names>MP</given-names></name></person-group><year iso-8601-date="2009">2009</year><article-title>The anatomy of memory: an interactive overview of the parahippocampal–hippocampal network</article-title><source>Nature Reviews Neuroscience</source><volume>10</volume><fpage>272</fpage><lpage>282</lpage><pub-id pub-id-type="doi">10.1038/nrn2614</pub-id><pub-id pub-id-type="pmid">19300446</pub-id></element-citation></ref><ref id="bib158"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wang</surname><given-names>SH</given-names></name><name><surname>Morris</surname><given-names>RGM</given-names></name></person-group><year iso-8601-date="2010">2010</year><article-title>Hippocampal-neocortical interactions in memory formation, consolidation, and reconsolidation</article-title><source>Annual Review of Psychology</source><volume>61</volume><fpage>49</fpage><lpage>79</lpage><pub-id pub-id-type="doi">10.1146/annurev.psych.093008.100523</pub-id><pub-id pub-id-type="pmid">19575620</pub-id></element-citation></ref><ref id="bib159"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wang</surname><given-names>JX</given-names></name><name><surname>Kurth-Nelson</surname><given-names>Z</given-names></name><name><surname>Kumaran</surname><given-names>D</given-names></name><name><surname>Tirumala</surname><given-names>D</given-names></name><name><surname>Soyer</surname><given-names>H</given-names></name><name><surname>Leibo</surname><given-names>JZ</given-names></name><name><surname>Hassabis</surname><given-names>D</given-names></name><name><surname>Botvinick</surname><given-names>M</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>Prefrontal cortex as a meta-reinforcement learning system</article-title><source>Nature Neuroscience</source><volume>21</volume><fpage>860</fpage><lpage>868</lpage><pub-id pub-id-type="doi">10.1038/s41593-018-0147-8</pub-id><pub-id pub-id-type="pmid">29760527</pub-id></element-citation></ref><ref id="bib160"><element-citation publication-type="preprint"><person-group person-group-type="author"><name><surname>Wayne</surname><given-names>G</given-names></name><name><surname>Hung</surname><given-names>CC</given-names></name><name><surname>Amos</surname><given-names>D</given-names></name><name><surname>Mirza</surname><given-names>M</given-names></name><name><surname>Ahuja</surname><given-names>A</given-names></name><name><surname>Grabska-Barwinska</surname><given-names>A</given-names></name><name><surname>Rae</surname><given-names>J</given-names></name><name><surname>Mirowski</surname><given-names>P</given-names></name><name><surname>Leibo</surname><given-names>JZ</given-names></name><name><surname>Santoro</surname><given-names>A</given-names></name><name><surname>Gemici</surname><given-names>M</given-names></name><name><surname>Reynolds</surname><given-names>M</given-names></name><name><surname>Harley</surname><given-names>T</given-names></name><name><surname>Abramson</surname><given-names>J</given-names></name><name><surname>Mohamed</surname><given-names>S</given-names></name><name><surname>Rezende</surname><given-names>D</given-names></name><name><surname>Saxton</surname><given-names>D</given-names></name><name><surname>Cain</surname><given-names>A</given-names></name><name><surname>Hillier</surname><given-names>C</given-names></name><name><surname>Silver</surname><given-names>D</given-names></name><name><surname>Kavukcuoglu</surname><given-names>K</given-names></name><name><surname>Botvinick</surname><given-names>M</given-names></name><name><surname>Hassabis</surname><given-names>D</given-names></name><name><surname>Lillicrap</surname><given-names>T</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>Unsupervised predictive memory in a goal-directed agent</article-title><source>arXiv</source><ext-link ext-link-type="uri" xlink:href="https://arxiv.org/abs/1803.10760">https://arxiv.org/abs/1803.10760</ext-link></element-citation></ref><ref id="bib161"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Whittington</surname><given-names>JCR</given-names></name><name><surname>Muller</surname><given-names>TH</given-names></name><name><surname>Mark</surname><given-names>S</given-names></name><name><surname>Chen</surname><given-names>G</given-names></name><name><surname>Barry</surname><given-names>C</given-names></name><name><surname>Burgess</surname><given-names>N</given-names></name><name><surname>Behrens</surname><given-names>TEJ</given-names></name></person-group><year iso-8601-date="2020">2020</year><article-title>The Tolman-Eichenbaum machine: unifying space and relational memory through generalization in the hippocampal formation</article-title><source>Cell</source><volume>183</volume><fpage>1249</fpage><lpage>1263</lpage><pub-id pub-id-type="doi">10.1016/j.cell.2020.10.024</pub-id><pub-id pub-id-type="pmid">33181068</pub-id></element-citation></ref><ref id="bib162"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Yates</surname><given-names>FA</given-names></name></person-group><year iso-8601-date="1966">1966</year><source>The Art of Memory</source><publisher-loc>Chicago</publisher-loc><publisher-name>University of Chicago Press</publisher-name></element-citation></ref><ref id="bib163"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Yonelinas</surname><given-names>AP</given-names></name></person-group><year iso-8601-date="2002">2002</year><article-title>The Nature of recollection and familiarity: a review of 30 years of research</article-title><source>Journal of Memory and Language</source><volume>46</volume><fpage>441</fpage><lpage>517</lpage><pub-id pub-id-type="doi">10.1006/jmla.2002.2864</pub-id></element-citation></ref><ref id="bib164"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Zacks</surname><given-names>JM</given-names></name><name><surname>Speer</surname><given-names>NK</given-names></name><name><surname>Swallow</surname><given-names>KM</given-names></name><name><surname>Braver</surname><given-names>TS</given-names></name><name><surname>Reynolds</surname><given-names>JR</given-names></name></person-group><year iso-8601-date="2007">2007</year><article-title>Event perception: a mind-brain perspective</article-title><source>Psychological Bulletin</source><volume>133</volume><fpage>273</fpage><lpage>293</lpage><pub-id pub-id-type="doi">10.1037/0033-2909.133.2.273</pub-id><pub-id pub-id-type="pmid">17338600</pub-id></element-citation></ref><ref id="bib165"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Zacks</surname><given-names>JM</given-names></name><name><surname>Kurby</surname><given-names>CA</given-names></name><name><surname>Eisenberg</surname><given-names>ML</given-names></name><name><surname>Haroutunian</surname><given-names>N</given-names></name></person-group><year iso-8601-date="2011">2011</year><article-title>Prediction error associated with the perceptual segmentation of naturalistic events</article-title><source>Journal of Cognitive Neuroscience</source><volume>23</volume><fpage>4057</fpage><lpage>4066</lpage><pub-id pub-id-type="doi">10.1162/jocn_a_00078</pub-id><pub-id pub-id-type="pmid">21671745</pub-id></element-citation></ref><ref id="bib166"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Zacks</surname><given-names>JM</given-names></name></person-group><year iso-8601-date="2020">2020</year><article-title>Event perception and memory</article-title><source>Annual Review of Psychology</source><volume>71</volume><fpage>165</fpage><lpage>191</lpage><pub-id pub-id-type="doi">10.1146/annurev-psych-010419-051101</pub-id><pub-id pub-id-type="pmid">31905113</pub-id></element-citation></ref><ref id="bib167"><element-citation publication-type="preprint"><person-group person-group-type="author"><name><surname>Zhang</surname><given-names>Q</given-names></name><name><surname>Griffiths</surname><given-names>T</given-names></name><name><surname>Norman</surname><given-names>K</given-names></name></person-group><year iso-8601-date="2021">2021</year><article-title>Optimal policies for free recall</article-title><source>PsyArXiv</source><pub-id pub-id-type="doi">10.31234/osf.io/sgepb</pub-id></element-citation></ref><ref id="bib168"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Zilli</surname><given-names>EA</given-names></name><name><surname>Hasselmo</surname><given-names>ME</given-names></name></person-group><year iso-8601-date="2008">2008</year><article-title>Modeling the role of working memory and episodic memory in behavioral tasks</article-title><source>Hippocampus</source><volume>18</volume><fpage>193</fpage><lpage>209</lpage><pub-id pub-id-type="doi">10.1002/hipo.20382</pub-id><pub-id pub-id-type="pmid">17979198</pub-id></element-citation></ref></ref-list><app-group><app id="appendix-1"><title>Appendix 1</title><sec id="s8" sec-type="appendix"><title>The internal representation of the decision layer</title><p>To explore how neural activity patterns in the decision layer differed as a function of certainty, we plotted the activity patterns as a function of the action taken by the model (i.e., whether it predicted one of the four upcoming states, or whether it used the ‘don’t know’ response). <xref ref-type="fig" rid="app1fig1">Appendix 1—figure 1</xref> shows the results of this analysis: Uncertain states are approximately clustered near the center of the activation space (with a lower L2 norm) while other responses are farther away, which indicates that uncertainty in our model is represented by the absence of evidence towards any particular choice. Importantly, this difference in activity patterns is not built-in to the model – it simply emerges during training.</p><fig id="app1fig1" position="float"><label>Appendix 1—figure 1.</label><caption><title>How certainty is represented in the model’s activity patterns.</title><p>Panels A and B show the neural activity patterns from the decision layer in the distant memory (DM) condition, projected onto the first two principal components. Each point corresponds to the pattern of neural activity for a trial at a particular time point. We colored the points based on the output (i.e., ‘choice‘) of the model, which represents the model’s belief about which state will happen next. Patterns that subsequently led to ‘don’t know‘ responses are colored in grey. Panel A shows an early time point with substantial uncertainty (a large number of ‘don’t know‘ responses). Panel B shows the last time point of this event, where the model has lower uncertainty. Panel C shows the average L2 norm of states that led to ‘don’t know‘ responses (uncertain) versus states that led to specific next-state predictions (certain); the errorbars indicate 1SE across 15 models. States corresponding to ‘don’t know‘ responses are clustered in the center of the activation space, with a lower L2 norm.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-74445-app1-fig1-v3.tif"/></fig></sec></app><app id="appendix-2"><title>Appendix 2</title><sec id="s9" sec-type="appendix"><title>Effects of event similarity on retrieval policy</title><p>In this simulation, we studied how the similarity of event memories in the training environment affects retrieval policy. To manipulate memory similarity, we varied the proportion of shared situation feature values across events during training. In the low-similarity condition, the similarity between the distractor situation (i.e., situation A; see <xref ref-type="fig" rid="fig2">Figure 2</xref> in the main text) and the target situation was constrained to be less than 40%, so target memories and lures were relatively easy to distinguish. In the high-similarity condition, the similarity between the distractor situation and the target situation was constrained to fall between 35% and 90%. We used a rejection sampling approach to implement these similarity bounds – during stimulus generation, we kept generating distractor situations until they fell within the similarity bounds with respect to the target sequence. Otherwise, the simulation parameters were the same as the parameters that were used in the main text.</p><p>In the high-similarity condition, target and lure memories were more confusable, and thus the risk of lure recall was higher. In light of this, we expected that the model would adopt a more conservative retrieval policy (i.e., retrieving less) in the high-similarity condition. We also expected that this effect would be stronger when the penalty is high; when the penalty is low, there is less of a cost for recalling the lure memory, and thus less of a reason to refrain from episodic retrieval in the high-similarity condition.</p><p>We compared the model’s behavior as a function of penalty and similarity. For the penalty manipulation, each model was trained on a range of penalty values from 0 to 4, then tested on low (0), moderate (2), and high (4) penalty values. <xref ref-type="fig" rid="app2fig1">Appendix 2—figure 1</xref> shows the average level of memory activation in each of the conditions. As expected, memory activation is lower in the high-similarity condition, especially when the penalty is high. Notably, increasing penalty reduces memory activation in the high-similarity condition (where the risk of false recall is high) but it does not have this effect in the low-similarity condition (where the risk of false recall is low).</p><fig id="app2fig1" position="float"><label>Appendix 2—figure 1.</label><caption><title>Memory activation during part 2 (averaged over time) in the DM condition, for models trained in low vs. high event-similarity environments and tested with penalty values that were low (penalty = 0), moderate (penalty = 2), or high (penalty = 4).</title><p>The model recalls less when similarity is high (vs. low), and this effect is larger for higher penalty values. The errorbars indicate 1SE across 15 models.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-74445-app2-fig1-v3.tif"/></fig></sec></app><app id="appendix-3"><title>Appendix 3</title><sec id="s10" sec-type="appendix"><title>Effects of familiarity on retrieval policy</title><p>Prior work has demonstrated that neocortex is capable of computing a scalar <italic>familiarity signal</italic> that discriminates between previously-encountered and novel stimuli (<xref ref-type="bibr" rid="bib163">Yonelinas, 2002</xref>; <xref ref-type="bibr" rid="bib106">Norman and O’Reilly, 2003</xref>; <xref ref-type="bibr" rid="bib70">Holdstock et al., 2002</xref>); likewise, signals can be extracted from models of the hippocampus that discriminate between novel and familiar stimuli (e.g., <xref ref-type="bibr" rid="bib63">Hasselmo and Wyble, 1997</xref>; see <xref ref-type="bibr" rid="bib109">Norman, 2010</xref> for a comparison of the properties of these neocortical and hippocampal signals). In this section, we study how familiarity signals can support episodic retrieval policy. Relevant to this point, several recent studies in humans have found that encountering a familiar stimulus can temporarily shift the hippocampus into a ‘retrieval mode’ where it is more likely to retrieve episodic memories in response to available retrieval cues (<xref ref-type="bibr" rid="bib34">Duncan et al., 2012</xref>; <xref ref-type="bibr" rid="bib35">Duncan and Shohamy, 2016</xref>; <xref ref-type="bibr" rid="bib37">Duncan et al., 2019</xref>; <xref ref-type="bibr" rid="bib115">Patil and Duncan, 2018</xref>). Here, we assess whether our model can provide a resource-rational account of these ‘retrieval mode’ findings.</p><p>Intuitively, familiarity can guide episodic retrieval policy by providing an indication of whether a relevant episodic memory is available. If an item is unfamiliar, this signals that it is unlikely that relevant episodic memories exist, hence the expected benefit of retrieving from episodic memory is low (if there are no relevant episodic memories, episodic retrieval can only yield irrelevant memories, which lead to incorrect predictions); and if an item is familiar, this signals that relevant episodic memories are likely to exist and hence the benefits of retrieving from episodic memory are higher. These points suggest that the model would benefit from a policy whereby it adopts a more liberal criterion for retrieving from episodic memory when stimuli are familiar as opposed to novel.</p><p>To test this, we ran simulations where we presented a ‘ground truth’ familiarity signal to the model during part 2 of the sequence. The familiarity signal was presented using an additional, dedicated input unit (akin to how we present penalty information to the model). Specifically, during part 2, if the ongoing situation had been observed before (as was the case in the RM and DM conditions), the familiarity signal was set to one. In contrast, if the ongoing situation was novel (as was the case in the NM condition), then the familiarity signal was set to negative one. Before part 2, the familiarity signal was set to zero (an uninformative value). Other than these changes, the parameters of this simulation were the same as the other simulations. The model was tested on penalty value of 2 – the average of the training range. Note that our treatment of the familiarity signal here deliberately glosses over the question of how this signal is generated, as this question is addressed in detail in other models (e.g., <xref ref-type="bibr" rid="bib106">Norman and O’Reilly, 2003</xref>; <xref ref-type="bibr" rid="bib63">Hasselmo and Wyble, 1997</xref>); our intent here is to understand the consequences of having a familiarity signal (however it might be generated) for the model’s episodic retrieval policy.</p><p><xref ref-type="fig" rid="app3fig1">Appendix 3—figure 1</xref> and <xref ref-type="fig" rid="app3fig2">Appendix 3—figure 2</xref> illustrate prediction performance, memory activation, and EM gate values for models with and without the familiarity signal. When the model has access to a veridical familiarity signal ( + 1 for RM and DM, –1 for NM), it opens the EM gate immediately and strongly in the DM condition (<xref ref-type="fig" rid="app3fig2">Appendix 3—figure 2D</xref>), leading to higher activation of both the target memory and the lure (<xref ref-type="fig" rid="app3fig2">Appendix 3—figure 2A</xref>) in the DM condition, relative to models without the familiarity signal (<xref ref-type="fig" rid="app3fig2">Appendix 3—figure 2B</xref>). Behaviorally, models with the familiarity signal show both a higher correct prediction rate and a slightly higher error rate in the DM condition, compared to models without the familiarity signal (<xref ref-type="fig" rid="app3fig1">Appendix 3—figure 1A</xref> vs. B). This slight increase in errors occurs because, when the model retrieves immediately from episodic memory during part 2, the model (in some cases) has not yet made enough observations to distinguish the target and the lure. In the NM condition, with the familiarity signal, the model keeps the EM gate almost completely shut (<xref ref-type="fig" rid="app3fig2">Appendix 3—figure 2D</xref>). Consequently, the level of memory activation stays very low in the NM condition (<xref ref-type="fig" rid="app3fig2">Appendix 3—figure 2A</xref>), which reduces the error rate in the NM condition to zero (<xref ref-type="fig" rid="app3fig1">Appendix 3—figure 1A</xref>). The RM condition is an interesting case: Previously (see <xref ref-type="fig" rid="fig3">Figure 3</xref> in the main text), we found that the model refrained from episodic memory retrieval in the RM condition; we found that the same pattern is present here, even when we make a familiarity signal available to the model: EM gate and memory activation values are both very low (<xref ref-type="fig" rid="app3fig2">Appendix 3—figure 2A and D</xref>), similar to models without access to the familiarity signal (<xref ref-type="fig" rid="app3fig2">Appendix 3—figure 2B and E</xref>). This shows that model does not always retrieve from episodic memory when given a high familiarity signal – in this case, the presence of relevant information in working memory (which suppresses episodic retrieval) ‘overrides’ the presence of the familiarity signal (which enhances episodic retrieval in the DM condition).</p><fig id="app3fig1" position="float"><label>Appendix 3—figure 1.</label><caption><title>The familiarity signal can improve prediction.</title><p>Next-state prediction performance for models with (<bold>A</bold>) vs. without (<bold>B</bold>) access to the familiarity signal. With the familiarity signal (<bold>A</bold>), the model shows (1) higher levels of correct prediction in the DM condition, and (2) a reduced error rate in the NM condition. The errorbars indicate 1SE across 15 models.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-74445-app3-fig1-v3.tif"/></fig><fig id="app3fig2" position="float"><label>Appendix 3—figure 2.</label><caption><title>Episodic retrieval is modulated by familiarity.</title><p>This figure shows the memory activation and EM gate values over time for three conditions: (1) with the familiarity signal (<bold>A, D</bold>), (2) without the familiarity signal (<bold>B, E</bold>), and (3) with a reversed (opposite) familiarity signal at test (<bold>C, F</bold>). With the familiarity signal (<bold>A</bold>), the model shows higher levels of recall in the DM condition, and suppresses recall even further in the NM condition, compared to the model without the familiarity signal (<bold>B</bold>). This is due to the influence of the EM gate – the model with the familiarity signal retrieves immediately in the DM condition, and turns off episodic retrieval almost completely in the NM condition (<bold>D</bold>). Note also that levels of episodic retrieval in the RM condition stay low, even with the familiarity signal (see text for discussion). Finally, parts <bold>C</bold> and <bold>F</bold> show that reversing the familiarity signal at test suppresses recall in the DM condition and boosts recall in the NM condition. The errorbars indicate 1SE across 15 models.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-74445-app3-fig2-v3.tif"/></fig><p>Finally, we can trick the model into reversing its retrieval policy by reversing the familiarity signal at test (<xref ref-type="fig" rid="app3fig2">Appendix 3—figure 2C and F</xref>). In this condition, the (reversed) signal indicates that the ongoing situation is novel (–1) in the RM and the DM condition, and the ongoing situation is familiar (+1) in the NM condition. As a result, the model suppresses episodic retrieval in the RM and DM conditions, and recalls lures in the NM condition.</p><p>Overall, the results of this simulation show that our model is able to use a familiarity signal to inform its retrieval policy in the service of predicting upcoming states. Consistent with empirical results (<xref ref-type="bibr" rid="bib34">Duncan et al., 2012</xref>; <xref ref-type="bibr" rid="bib35">Duncan and Shohamy, 2016</xref>; <xref ref-type="bibr" rid="bib37">Duncan et al., 2019</xref>; <xref ref-type="bibr" rid="bib115">Patil and Duncan, 2018</xref>), we found that the model retrieves more from episodic memory when the ongoing situation is familiar, unless the model has low uncertainty about the upcoming state. These modeling results provide a resource-rational account of why familiarity leads to enhanced episodic retrieval.</p></sec></app><app id="appendix-4"><title>Appendix 4</title><sec id="s11" sec-type="appendix"><title>Alternative configurations of episodic memory gating</title><p>In the simulations described in the main text, the EM gate controls the input into the EM system. An alternative way of accomplishing gating is to place the gate <italic>after</italic> the EM module (LCA), so it controls the flow of activation from the EM module back into the LSTM. <xref ref-type="fig" rid="app4fig1">Appendix 4—figure 1</xref> illustrates the differences between these configurations; for convenience, we will use ‘post-gating’ to refer to the latter mechanism and ‘pre-gating’ to refer to the mechanism used in the simulations described in the main text. As noted in the <italic>Discussion</italic>, the primary consequence of having the gate on the output side is that the gate can be controlled based on information coming out of the hippocampus, in addition to all of the neocortical regions that are used to control the gate in our pre-gating model. The post-gating mechanism has been more widely used in machine learning (<xref ref-type="bibr" rid="bib129">Ritter et al., 2018</xref>; <xref ref-type="bibr" rid="bib130">Ritter, 2019</xref>; <xref ref-type="bibr" rid="bib120">Pritzel et al., 2017</xref>) because it is more powerful – since the gating function has access to activated episodic memories in the LCA, the model can close/open the gate depending on the properties of these activated memories.</p><fig id="app4fig1" position="float"><label>Appendix 4—figure 1.</label><caption><title>Unrolled network diagrams for the pre-gating (<bold>A</bold>) versus the post-gating (<bold>B</bold>) models.</title><p>The EM gate in the pre-gating model controls the degree to which stored memories are activated within the LCA module, but does not control the degree to which the activated memories are transmitted to the neocortex. By contrast, the EM gate in the post-gating model controls the degree to which activated memories in the LCA module are transmitted to the neocortex, but it does not control how these memory activations are computed in the first place.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-74445-app4-fig1-v3.tif"/></fig><p>Since it is still unclear what kinds of episodic memory gating are implemented in the brain (see below for further discussion), we experimented with both mechanisms. We focused on the pre-gating model in the main text since it involves fewer assumptions – critically, it does not assume that the gating mechanism has access to the content of memories that are activated within the hippocampus. That said, the key results for the pre-gating model, reported in the main text, qualitatively hold for the post-gating model (<xref ref-type="fig" rid="app4fig2">Appendix 4—figure 2</xref>). In particular, the post-gating model also (1) retrieves much more from episodic memory in the DM condition, compared to the other two conditions (<xref ref-type="fig" rid="app4fig2">Appendix 4—figure 2A, B and C</xref>); (2) retrieves more when it is uncertain about the upcoming state (<xref ref-type="fig" rid="app4fig2">Appendix 4—figure 2D</xref>); (3) delays its recall time when the penalty is higher (<xref ref-type="fig" rid="app4fig2">Appendix 4—figure 2E</xref>); (4) adjusts its EM gate value as a function of the schema strength in a way that is similar to the pre-gating model (<xref ref-type="fig" rid="app4fig2">Appendix 4—figure 2F</xref>); and( 5) shows the effect that midway-encoded memories hurt next-state prediction performance (<xref ref-type="fig" rid="app4fig2">Appendix 4—figure 2G and H</xref> – note that this also holds true when midway-encoded memories are present during meta-training). Importantly, while the aforementioned patterns replicate across the models, the results are not exactly the same – the retrieval policy for the post-gating model is often more flexible (i.e., it can adapt better to current conditions), since its EM gate can be controlled by the output of the EM module (in addition to the output of other neocortical regions). For example, in the post-gating model, the EM gate layer of the neocortical network is able to detect that relevant memories are not present in the NM condition, and it adapts to this by setting the EM gate to a lower value in the NM condition than the DM condition (<xref ref-type="fig" rid="app4fig2">Appendix 4—figure 2C</xref>) – that is, it learns to suppress retrieval when no memories are coming to mind. By contrast, the pre-gating model actually shows the opposite pattern – here, the EM gate layer can not detect the absence of relevant memories in the NM condition, but it <italic>can</italic> detect higher overall levels of uncertainty in the NM condition than the DM condition, which leads it to set the EM gate to a slightly higher value in the NM condition than the DM condition (see <xref ref-type="fig" rid="fig3">Figure 3C</xref> in the main text).</p><fig id="app4fig2" position="float"><label>Appendix 4—figure 2.</label><caption><title>The post-gating model qualitatively replicates key results obtained from the pre-gating model (compare to <xref ref-type="fig" rid="fig3">Figures 3</xref> and <xref ref-type="fig" rid="fig4">4</xref> in the main text).</title><p>See text in this appendix for discussion. The errorbars indicate 1SE across 15 models.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-74445-app4-fig2-v3.tif"/></fig><p>One exciting future direction is to experimentally investigate how episodic memory gating works in the brain. The pre-gating and post-gating models make different predictions about the hippocampal activity: The post-gating model predicts that candidate episodic memory traces should be activated in the hippocampus at each time point; sometimes these activated traces are blocked (by the gate) from being transmitted to neocortex, and sometimes they are allowed through. The pre-gating model predicts that activation of episodic memory traces in the hippocampus will distributed more sparsely in time; on time points when the gate is closed, no activation should be transmitted from neocortex to hippocampus, resulting in reduced activation of hippocampal memory traces (although there might be activation of these traces via recurrence within the hippocampus). Putting these points together, the pre-gating model appears to predict a large difference in hippocampal activation patterns as a function of whether the gate is closed or open; by contrast, the post-gating model appears to predict a smaller difference in hippocampal activation patterns as a function of whether the gate is closed or open.</p><p>However, this logic is complicated by the fact that the hippocampus is connected in a recurrent ‘big loop’ with neocortex (<xref ref-type="bibr" rid="bib141">Schapiro et al., 2017</xref>; <xref ref-type="bibr" rid="bib85">Kumaran and Maguire, 2007</xref>; <xref ref-type="bibr" rid="bib157">van Strien et al., 2009</xref>; <xref ref-type="bibr" rid="bib81">Koster et al., 2018</xref>) – in the post-gating model, even if the inputs to the hippocampus are the same when the gate is open vs. closed, the outputs to neocortex will be different, which in turn will affect the inputs (from neocortex) that hippocampus receives on the next time point. Thus, we would eventually expect differences in hippocampal activation in these conditions, even in the post-gate model. This suggests that, while it may be challenging to empirically tease apart the pre-gating and post-gating models, time-resolved methods like ECoG that can (in principle) distinguish between the ‘initial wave’ of activity hitting the hippocampus after a stimulus and subsequent (recurrent) waves of activity would be most useful for this purpose. We should also note that the pre-gating and post-gating mechanisms are not mutually exclusive and it is possible that the brain deploys both of them.</p></sec></app><app id="appendix-5"><title>Appendix 5</title><sec id="s12" sec-type="appendix"><title>Training the model without reinforcement learning</title><p>In the simulations shown in the main text, we trained the model using reinforcement learning (after supervised pre-training) and gave the model the option of responding ‘don’t know’, in which case it received no penalty or reward (see <italic>Model training and testing</italic> section above for details). Here, in <xref ref-type="fig" rid="app5fig1">Appendix 5—figure 1</xref>, we report the results from a model variant in which the model was trained in an entirely supervised fashion, without the option of responding ‘don’t know’ – on each time point, the model was forced to predict the next state, and weights were adjusted based on the discrepancy between the predicted and actual states.</p><fig id="app5fig1" position="float"><label>Appendix 5—figure 1.</label><caption><title>Results from a ‘no-RL‘ model that was trained in an entirely supervised fashion, without reinforcement learning and without the option of giving a ‘don’t know‘ response – compare to <xref ref-type="fig" rid="fig3">Figure 3</xref> in the main text; see text in this appendix for discussion.</title><p>The errorbars indicate 1SE across 15 models.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-74445-app5-fig1-v3.tif"/></fig><p>There are two important observations to make based on the results in <xref ref-type="fig" rid="app5fig1">Appendix 5—figure 1</xref>. The first observation is that the model is much less patient (i.e., it retrieves much earlier in part 2) when we take away the option of giving a ‘don’t know’ response. This impatience can be seen by comparing the early time points of <xref ref-type="fig" rid="app5fig1">Appendix 5—figure 1C</xref> to the early time points of <xref ref-type="fig" rid="fig3">Figure 3C</xref> in the main text – EM gate values are much higher at early time points in the no-RL model. It can also be seen by comparing <xref ref-type="fig" rid="app5fig1">Appendix 5—figure 1E</xref> to <xref ref-type="fig" rid="fig3">Figure 3E</xref> in the main text – the average time-to-recall is much lower in the no-RL model. These findings confirm our claim (made in the main text) that the ‘don’t know’ response makes the strategy of waiting to retrieve more viable, by allowing the model to escape being penalized on trials when it is waiting to retrieve from episodic memory.</p><p>The second observation is that, even without the option of responding ‘don’t know’, the learned retrieval policy of the no-RL model is still sensitive to certainty. This is shown in <xref ref-type="fig" rid="app5fig1">Appendix 5—figure 1B and C</xref>: Just like the model in the main text, the no-RL model recalls less information in the RM condition (when it is more certain about what will happen next) vs. the DM condition. The lack of a difference in EM gate value between ‘recently observed’ and ‘not recently observed’ features in <xref ref-type="fig" rid="app5fig1">Appendix 5—figure 1D</xref> suggests that the no-RL model might <italic>not</italic> be sensitive to certainty, but this is an artifact of the no-RL model’s impatience – the EM gate value is very high for early time points in both conditions, making it harder to observe a difference between conditions; in other simulations (not shown here) where we used a stronger penalty manipulation to disincentivize early retrieval, the difference in recall levels between ‘recently observed’ and ‘not recently observed’ features was clearly visible in the no-RL model, reaffirming its sensitivity to certainty.</p><p>Taken together, the results from the no-RL model are very useful in clarifying what, exactly, is gained from the use of RL training with a ‘don’t know’ option. In particular: having a ‘don’t know’ response does not <italic>cause</italic> the model to have qualitatively distinct neural states as a function of certainty – these differences (described in Appendix 1 above) exist regardless of ‘don’t know’ training, and can be used by the no-RL model to modulate its retrieval policy. Rather, the effect of RL training with the ‘don’t know’ response is to make the model more patient, by giving it the option of waiting without penalty when it is uncertain.</p></sec></app><app id="appendix-6"><title>Appendix 6</title><sec id="s13" sec-type="appendix"><title>Simulating inter-subject correlation results from <xref ref-type="bibr" rid="bib24">Chen et al., 2016</xref></title><p>As discussed in the main text, <xref ref-type="bibr" rid="bib24">Chen et al., 2016</xref> found strong hippocampal-neocortical activity coupling measured using inter-subject functional connectivity (ISFC; <xref ref-type="bibr" rid="bib148">Simony et al., 2016</xref>) for DM participants, while the level of coupling was much weaker for participants in the RM and NM conditions (<xref ref-type="bibr" rid="bib24">Chen et al., 2016</xref>). Here, we address some additional findings from this study that used temporal inter-subject correlation (ISC) as a dependent measure; temporal ISC tracks the degree to which the fMRI time series in a particular brain region is correlated across participants (<xref ref-type="bibr" rid="bib64">Hasson et al., 2004</xref>; <xref ref-type="bibr" rid="bib24">Chen et al., 2016</xref>; <xref ref-type="bibr" rid="bib104">Nastase et al., 2019</xref>). Specifically, <xref ref-type="bibr" rid="bib24">Chen et al., 2016</xref> found that – at the start of part 2 – temporal ISC in DMN regions was lower between participants in the DM and RM conditions than between RM participants, suggesting differences in how DM and RM participants were interpreting the story; however, this gap in ISC decreased over the course of part 2, suggesting that these differences in interpretation between DM and RM participants decrease over time (<xref ref-type="fig" rid="app6fig1">Appendix 6—figure 1B</xref>). Furthermore, across participants, the degree to which the gap in ISC narrowed during the second half of part 2 was correlated with the amount of hippocampal-neocortical activity coupling at the start of part 2 (<xref ref-type="fig" rid="app6fig1">Appendix 6—figure 1C</xref>; <xref ref-type="bibr" rid="bib24">Chen et al., 2016</xref>). Taken together, these findings can be interpreted as showing that hippocampus is consulted more (as evidenced by increased hippocampal-neocortical coupling) in the DM condition (where there are gaps in the situation model at the start of part 2) than the RM condition (where the situation model is more complete); the effect of this increased consultation of the hippocampus is to ‘fill in the gaps’ and align the interpretations of the DM and RM participants (as evidenced by DM-RM ISC rising to the level of RM-RM ISC).</p><fig id="app6fig1" position="float"><label>Appendix 6—figure 1.</label><caption><title>Simulating inter-subject correlation results from <xref ref-type="bibr" rid="bib24">Chen et al., 2016</xref>.</title><p>(<bold>A</bold>) Illustration of how we computed inter-subject correlation (ISC) in the model (see text for details). (<bold>B and C</bold>) show the empirical results from <xref ref-type="bibr" rid="bib24">Chen et al., 2016</xref> (reprinted with permission) and (<bold>D and E</bold>) show model results. (<bold>B</bold>) The sliding-window temporal inter-subject correlation (ISC) over time, during part 2 of the movie. The recent memory ISC, or RM-RM ISC, was computed as the average ISC value between two non-overlapping subgroups of the RM participants. The distant memory ISC, or RM-DM ISC, was computed as the average ISC between one sub-group of RM participants and the DM participants. Initially, the RM-DM ISC was lower than RM-RM ISC, but as the movie unfolded, RM-DM ISC rose to the level of RM-RM ISC. (<bold>C</bold>) For the DM participants, the level of hippocampal-neocortical inter-subject functional connectivity at the beginning of part 2 of the movie (minutes 1–4) was correlated with the level of RM-DM ISC later on (minutes 5–10). (<bold>D</bold>) Sliding window temporal ISC in part 2 between the RM models (RM-RM) compared to ISC between the RM and DM models (RM-DM). The convergence between RM-DM ISC and RM-RM ISC shows that activity dynamics in the DM and the RM models become more similar over time (compare to part B of this figure). The errorbars indicate 1SE across 15 models. (<bold>E</bold>) The correlation in the model between memory activation at time <inline-formula><mml:math id="inf50"><mml:mi>t</mml:mi></mml:math></inline-formula> and the change in ISC from time <inline-formula><mml:math id="inf51"><mml:mi>t</mml:mi></mml:math></inline-formula> to time <inline-formula><mml:math id="inf52"><mml:mrow><mml:mi>t</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:math></inline-formula>, for the first 10 time points in part 2. Each point is a subject-subject pair across the two conditions. The 95% bootstrap distribution on the side shows that the correlation between memory activation and the change in RM-DM ISC is significantly larger than the correlation between memory activation and the change in RM-RM ISC (see text for details).</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-74445-app6-fig1-v3.tif"/><permissions><copyright-statement>© 2016, Oxford University Press Permissions</copyright-statement><copyright-year>2016</copyright-year><copyright-holder>Oxford University Press Permissions</copyright-holder><ali:free_to_read/><license><ali:license_ref>http://creativecommons.org/licenses/by/4.0/</ali:license_ref><license-p>panel B is reprinted from Figure 6 <xref ref-type="bibr" rid="bib24">Chen et al., 2016</xref> by permission of Oxford University Press. It is not covered by the <ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/licenses/by/4.0/">CC-BY 4.0 licence and further reproduction of this panel would need permission from the copyright holder</ext-link></license-p></license></permissions><permissions><copyright-statement>© 2016, Oxford University Press Permissions</copyright-statement><copyright-year>2016</copyright-year><copyright-holder>Oxford University Press Permissions</copyright-holder><ali:free_to_read/><license><ali:license_ref>http://creativecommons.org/licenses/by/4.0/</ali:license_ref><license-p>panel C is reprinted from Figure S7 <xref ref-type="bibr" rid="bib24">Chen et al., 2016</xref>, by permission of Oxford University Press. It is not covered by the <ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/licenses/by/4.0/">CC-BY 4.0 licence and further reproduction of this panel would need permission from the copyright holder</ext-link></license-p></license></permissions></fig><p>To simulate these results, we trained 30 neural networks, then we assigned half of them to the RM condition and half to the DM condition. Next, we performed the temporal ISC analysis used in <xref ref-type="bibr" rid="bib24">Chen et al., 2016</xref> by treating hidden-unit activity patterns as multi-voxel brain patterns. An important technical note is that running ISC across networks requires some form of alignment (i.e., so the time series for corresponding parts of the networks can be correlated). Human fMRI data are approximately aligned across subjects, since brain anatomy is highly similar across people. However, when many instances of the same neural network architecture are trained on the same data, they tend to acquire different neural representations, even though they represent highly similar mathematical functions (<xref ref-type="bibr" rid="bib87">Li et al., 2015</xref>; <xref ref-type="bibr" rid="bib30">Dauphin et al., 2014</xref>; <xref ref-type="bibr" rid="bib99">Meng et al., 2018</xref>). That is, the same input can evoke uncorrelated neural responses across different networks, although they produce similar outputs. For our purpose, this means that directly correlating hidden-layer activity patterns across neural networks will underestimate the similarity of representations across networks. Therefore, to simulate effects involving (human) inter-subject analyses, we need a way to align neural networks.</p><p>To accomplish this goal, we used the shared response model (SRM) (<xref ref-type="bibr" rid="bib91">Lu et al., 2018</xref>) – a functional alignment procedure commonly used for multi-subject neuroimaging data (<xref ref-type="bibr" rid="bib23">Chen et al., 2015b</xref>; <xref ref-type="bibr" rid="bib67">Haxby et al., 2011</xref>; <xref ref-type="bibr" rid="bib68">Haxby et al., 2020</xref>). Intuitively, this method applies rigid body transformation to align different network activities into a common space. We have previously shown that neural networks with highly overlapping training experience can be aligned well with SRM (<xref ref-type="bibr" rid="bib91">Lu et al., 2018</xref>). Here, we used the Brain Imaging Analysis Kit (BrainIAK) implementation of SRM (<xref ref-type="bibr" rid="bib83">Kumar et al., 2020b</xref>; <xref ref-type="bibr" rid="bib82">Kumar et al., 2020a</xref>) to align our trained networks before computing ISC (<xref ref-type="fig" rid="app6fig1">Appendix 6—figure 1A</xref>).</p><p>Our simulation results qualitatively capture the findings from <xref ref-type="bibr" rid="bib24">Chen et al., 2016</xref>. During part 2, DM-RM ISC starts lower than RM-RM ISC, but as the event unfolds, they gradually converge (<xref ref-type="fig" rid="app6fig1">Appendix 6—figure 1D</xref>). Moreover, in the DM condition, the level of memory activation at time <inline-formula><mml:math id="inf53"><mml:mi>t</mml:mi></mml:math></inline-formula> is correlated with the increment in DM-RM ISC from time <inline-formula><mml:math id="inf54"><mml:mi>t</mml:mi></mml:math></inline-formula> to time <inline-formula><mml:math id="inf55"><mml:mrow><mml:mi>t</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:math></inline-formula> (<xref ref-type="fig" rid="app6fig1">Appendix 6—figure 1E</xref>). As a comparison point, in the RM condition (where the model is not relying on episodic retrieval to fill in gaps in the situation model), memory activation does not correlate with the change in (RM-RM) ISC. Collectively, these results establish that episodic retrieval accelerates the convergence between model activations in the DM and RM conditions.</p><p>More generally, this result shows that one can capture inter-subject results with computational models. Experiments using inter-subject analyses and natural stimuli are becoming increasingly popular (<xref ref-type="bibr" rid="bib104">Nastase et al., 2019</xref>; <xref ref-type="bibr" rid="bib149">Sonkusare et al., 2019</xref>; <xref ref-type="bibr" rid="bib59">Hamilton and Huth, 2018</xref>; <xref ref-type="bibr" rid="bib105">Nastase et al., 2020</xref>); our simulation results provide a proof-of-concept demonstration of how computational models of memory can engage with this literature.</p></sec></app><app id="appendix-7"><title>Appendix 7</title><sec id="s14" sec-type="appendix"><title>Model parameters</title><p>We implemented the model in PyTorch (<xref ref-type="bibr" rid="bib113">Paszke et al., 2017</xref>; <xref ref-type="bibr" rid="bib114">Paszke et al., 2019</xref>). The numbers of hidden units for the LSTM layer and the decision layer were 194 and 128, respectively. The level of competition in the LCA module was 0.8. The initial cell state of the LSTM was a random vector ∼ isotropic Gaussian(0,.1).</p><p>During the meta-training phase, we used the Adam optimizer (<xref ref-type="bibr" rid="bib80">Kingma and Ba, 2014</xref>). The initial learning rate was 7e-4. The learning rate decayed by 1/2 if the average prediction accuracy minus mistakes stayed within 0.1% from the previous best loss for 30 consecutive epochs. The minimal learning rate was 1e-8. We used orthogonal weight initialization with gain of 1 (<xref ref-type="bibr" rid="bib136">Saxe et al., 2014</xref>), and we used supervised initialization for 600 epochs to help the model develop useful representations (<xref ref-type="bibr" rid="bib101">Misra et al., 2017</xref>; <xref ref-type="bibr" rid="bib103">Nagabandi et al., 2018</xref>). During the supervised initialization phase, the model was trained to predict the upcoming state; episodic memory and the ‘don’t know’ unit were turned-off during this phase. After the supervised initialization phase, the model was trained with A2C (<xref ref-type="bibr" rid="bib102">Mnih et al., 2016</xref>) for another 400 epochs. We used entropy regularization with weight of 0.1 to encourage exploration. For every epoch, the model was trained on 256 events.</p></sec></app></app-group></back><sub-article article-type="editor-report" id="sa0"><front-stub><article-id pub-id-type="doi">10.7554/eLife.74445.sa0</article-id><title-group><article-title>Editor's evaluation</article-title></title-group><contrib-group><contrib contrib-type="author"><name><surname>Badre</surname><given-names>David</given-names></name><role specific-use="editor">Reviewing Editor</role><aff><institution-wrap><institution-id institution-id-type="ror">https://ror.org/05gq02987</institution-id><institution>Brown University</institution></institution-wrap><country>United States</country></aff></contrib></contrib-group><related-object id="sa0ro1" link-type="continued-by" object-id="10.1101/2020.12.15.422882" object-id-type="id" xlink:href="https://sciety.org/articles/activity/10.1101/2020.12.15.422882"/></front-stub><body><p>This paper addresses an important problem in control of episodic memory. This paper develops a computationally-based proposal about how semantic, working memory, and episodic memory systems might learn to interact so that stored episodic memories can optimally contribute to reconstruction of semantic memory for event sequences. This is an understudied area and this present work can make a major theoretical contribution to this domain with new predictions. The reviewers were positive about the contribution in review, and the revisions have clarified the model in a number of important ways, including through some additional simulation and analysis.</p></body></sub-article><sub-article article-type="decision-letter" id="sa1"><front-stub><article-id pub-id-type="doi">10.7554/eLife.74445.sa1</article-id><title-group><article-title>Decision letter</article-title></title-group><contrib-group content-type="section"><contrib contrib-type="editor"><name><surname>Badre</surname><given-names>David</given-names></name><role>Reviewing Editor</role><aff><institution-wrap><institution-id institution-id-type="ror">https://ror.org/05gq02987</institution-id><institution>Brown University</institution></institution-wrap><country>United States</country></aff></contrib></contrib-group><contrib-group><contrib contrib-type="reviewer"><name><surname>Rogers</surname><given-names>Tim</given-names></name><role>Reviewer</role><aff><institution-wrap><institution-id institution-id-type="ror">https://ror.org/01y2jtd41</institution-id><institution>University of Wisconsin-Madison</institution></institution-wrap><country>United States</country></aff></contrib><contrib contrib-type="reviewer"><name><surname>Hasselmo</surname><given-names>Michael E</given-names></name><role>Reviewer</role><aff><institution-wrap><institution-id institution-id-type="ror">https://ror.org/05qwgg493</institution-id><institution>Boston University</institution></institution-wrap><country>United States</country></aff></contrib></contrib-group></front-stub><body><boxed-text id="box1"><p>Our editorial process produces two outputs: i) <ext-link ext-link-type="uri" xlink:href="https://sciety.org/articles/activity/10.1101/2020.12.15.422882">public reviews</ext-link> designed to be posted alongside <ext-link ext-link-type="uri" xlink:href="https://www.biorxiv.org/content/10.1101/2020.12.15.422882v2">the preprint</ext-link> for the benefit of readers; ii) feedback on the manuscript for the authors, including requests for revisions, shown below. We also include an acceptance summary that explains what the editors found interesting or important about the work.</p></boxed-text><p><bold>Decision letter after peer review:</bold></p><p>Thank you for submitting your article ‘When to retrieve and encode episodic memories: a neural network model of hippocampal-cortical interaction’ for consideration by <italic>eLife</italic>. Your article has been reviewed by 2 peer reviewers, and the evaluation has been overseen by David Badre as Reviewing Editor and Michael Frank as the Senior Editor. The following individuals involved in review of your submission have agreed to reveal their identity: Tim Rogers (Reviewer #2); Michael E. Hasselmo (Reviewer #3).</p><p>The reviewers have discussed their reviews with one another, and the Reviewing Editor has drafted this to help you prepare a revised submission.</p><p>Essential revisions:</p><p>The reviewers and editors were in agreement that this paper addresses an important and novel problem using a elegant but powerful approach. There was consensus that this can make a contribution to the literature, pending some revisions for clarify. The major points of clarification raised by the reviewers are provided below.</p><p>1) It is not clear how the sequences were constructed and how these relate to the structure of real schematic events. From the methods it looks like the inputs to the model contain a one-hot label indicating the feature observed (e.g., weather), a second one-hot vector indicating the feature value (e.g., rainy), and a third for the query, which indicates what prediction must be made (e.g., ‘what will the mood be’?). Targets then consist of potential answers to the various queries plus the ‘I don't know’ unit. If this is correct, two things are unclear. First, how does the target output (ie the correct prediction) relate to the prior and current features of the event? Like, is the mood always ‘angry’ when the feature is ‘rainy,’ or is it chosen randomly for each event, or does it depend on prior states? Does the drink ordered depend on whether the day is a weekday or weekend---in which case the LSTM is obviously critical since this occurs much earlier in the sequence---or does it only depend on the observed features of the current moment (e.g., the homework is a paper), in which case it's less clear why an LSTM is needed. Second, the details of the cover story (going to a coffee shop) didn't help to resolve these queries; for instance, Figure 2 seems to suggest that the kind of drink ordered depends on the nature of the homework assigned, which doesn't really make sense and makes reviewers question their understanding of Figure 2. In general this figure, example, and explanation of the model training/testing sequences could be substantially clarified. Maybe a figure showing the full sequence of inputs and outputs for one event, or a transition-probability graph showing how such patterns are generated, would be of help. Some further plain-language exposition of the cover-story and how it relates to the specific features, queries, and predictions shown in Figure 2 could be helpful.</p><p>2) The authors show that their model does a better job of using episodic traces to reinstate the event representation when such traces are stored at the end of an event, rather than when they are stored at both the middle and the end. In explaining why, they show that the model tends to organize its internal representations mainly by time (ie events occurring at a similar point along the sequence are represented as similar). If episodes for the middle of the event are stored, these are preferentially reinstated later as the event continues following distraction, since the start of the ‘continuing’ event looks more like an early-in-time event than a late-in-time event. This analysis is interesting and provides a clear explanation of why the model behaves as it does. However, reviewers want to know if it is mainly due to the highly sequential nature of the events the model is trained on, where prior observed features/queries don't repeat in an event. They wonder if the same phenomenon would be observed with richer sequences such as the coffee/tea-making examples from Botvinick et al., where one stirs the coffee twice (once after sugar, once after cream) and so must remember, for each stirring event, whether it is the first or the second. Does the ’encode only at the end’ phenomenon still persist in such cases? The result is less plausible as an account of the empirical phenomena if it only &quot;works&quot; for strictly linear sequences.</p><p>3) It would be helpful to understand how/why reinforcement learning is preferable to error-correcting learning in this framework. Since the task is simply to predict the upcoming answer to a query given a prior sequence of observed states, it seems likely that plain old backprop could work fine (indeed, the cortical model is pre-trained with backprop already), and that the model could still learn the critical episodic memory gating. Is the reinforcement learning approached used mainly so the model can be connected to the over-arching resource-rational perspective on cognition, or is there some other reason why this approach is preferred?</p><p>4) The details of the simulations provided in the methods section could be clarified. First, on page 20, it is unclear about how w_i is computed. It seems to compute w_i (activation of trace i) you need to first compute activation of all other traces j, but since all such computations depend each other it is not clear how this is carried out. Perhaps you initialize this values for tau=0, but some detail here would help. Second, the specification of the learning algorithm for the A2C objective on page 21 has some terms that aren't explained. Specifically, it is not clear what the capital J denotes and what the /pi denotes. Third, other details about the training sufficient to replicate the work should also be provided--for instance, an explanation of the &quot;entropy regularization&quot; procedure, learning rates, optimizer, etc, for the supervised pre-training, and so on.</p><p>5) Line 566 – &quot;new frontier in the cognitive modeling of memory.&quot; They should qualify this statement with discussion of the shortcomings of these types of models. This model is useful for illustrating the potential functional utility of controlling the timing of episodic memory encoding and retrieval. However, the neural mechanisms for this control of gating is not made clear in these types of models. The authors suggest a portion of a potential mechanism when they mention the potential influence of the pattern of activity in the decision layer on the episodic memory gating (i.e., depending on the level of certainty – line 325), but they should mention that detailed neural circuit mechanisms are not made clear by this type of continuous firing rate model trained by gradient descent. More discussion of the difficulties of relating these types of neural network models to real biological networks is warranted. This is touched upon in lines 713-728, but the shortcomings of the current model in addressing biological mechanisms are not sufficiently highlighted. In particular, more biologically detailed models have addressed how network dynamics could regulate the levels of acetylcholine to shift dynamics between encoding and retrieval (Hasselmo et al., 1995; Hasselmo and Wyble, 1997). There should be more discussion of this prior work.</p><p>6) Figure 1 – &quot;the cortical part of the model&quot; – Line 117 – &quot;cortical weights&quot; and many other references to cortex. The hippocampus is a cortical structure (allocortex), so it is very confusing to see references to cortex used in contrast to hippocampus. The confusing use of references to cortex could be corrected by changing all the uses of &quot;cortex&quot; or &quot;cortical&quot; in this paper to &quot;neocortex&quot; or &quot;neocortical.&quot;</p><p>7) &quot;the encoding policy is not learned&quot; – This came as a surprise in the discussion, so it indicates that this is not made sufficiently clear earlier in the text. This statement should be made in a couple of points earlier where the encoding policy is discussed.</p></body></sub-article><sub-article article-type="reply" id="sa2"><front-stub><article-id pub-id-type="doi">10.7554/eLife.74445.sa2</article-id><title-group><article-title>Author response</article-title></title-group></front-stub><body><disp-quote content-type="editor-comment"><p>1) It is not clear how the sequences were constructed and how these relate to the structure of real schematic events. From the methods it looks like the inputs to the model contain a one-hot label indicating the feature observed (e.g., weather), a second one-hot vector indicating the feature value (e.g., rainy), and a third for the query, which indicates what prediction must be made (e.g., &quot;what will the mood be&quot;?). Targets then consist of potential answers to the various queries plus the &quot;I don't know&quot; unit. If this is correct, two things are unclear. First, how does the target output (ie the correct prediction) relate to the prior and current features of the event? Like, is the mood always &quot;angry&quot; when the feature is &quot;rainy,&quot; or is it chosen randomly for each event, or does it depend on prior states? Does the drink ordered depend on whether the day is a weekday or weekend---in which case the LSTM is obviously critical since this occurs much earlier in the sequence---or does it only depend on the observed features of the current moment (e.g., the homework is a paper), in which case it's less clear why an LSTM is needed. Second, the details of the cover story (going to a coffee shop) didn't help to resolve these queries; for instance, Figure 2 seems to suggest that the kind of drink ordered depends on the nature of the homework assigned, which doesn't really make sense and makes reviewers question their understanding of Figure 2. In general this figure, example, and explanation of the model training/testing sequences could be substantially clarified. Maybe a figure showing the full sequence of inputs and outputs for one event, or a transition-probability graph showing how such patterns are generated, would be of help. Some further plain-language exposition of the cover-story and how it relates to the specific features, queries, and predictions shown in Figure 2 could be helpful.</p></disp-quote><p>We are grateful to the reviewers for pointing out the need for further clarification of how we constructed the stimulus sequences. To answer the questions above: The target output at each time step is deterministically controlled by a particular feature of the situation. For example, the Barista state (Bob or Eve) that occurs at time step 1 is controlled by the Day situation feature – so, P(Barista = Bob |Day = weekday) = 1, and P(Barista = Eve |Day = weekend) = 1; the Mood state (happy or angry) that occurs at time step 2 is controlled by the Weather situation feature, and so on. The order of queries is fixed (the model is always asked about the Barista state on time step 1, the Mood state on time step 2, and so on) but – crucially – the order in which the situation features (Day, Weather, etc) are observed within an event is random. This combination of fixed-order queries but randomly-ordered situation feature observations implies that three possible circumstances can arise: (1) If the situation feature that controls a particular state is observed on the same time step that the state is queried, the model can respond directly without having to use memory. (2) If the situation feature that controls a particular state was observed earlier in the event, then the model can respond correctly by maintaining that feature in working memory. (3) If the situation feature that controls a particular state was not observed recently, the model can not use working memory to respond correctly, but it might be able to respond correctly if it retrieves an episodic memory of this situation.</p><p>In the previous draft, this information was spelled out later in the paper (to some extent in our exposition of Figure 2C, and more thoroughly in the “Stimulus representation” subsection of the Methods), but we agree with the reviewers that it would be more clear if we spelled this out earlier, when we discuss Figure 2A. Toward this end, we have made several changes to the paper:</p><p>First, we updated Figure 2A. We agree with the reviewer that having the Coffee state be controlled by the Homework feature was a bit obscure; we have restructured the example so the Drink that is ordered (juice or latte) is controlled by the Sleepiness feature (whether the protagonist is not sleepy or sleepy). We also modified the figure to address the three circumstances listed above (whether the relevant situation feature is observed before, during, or after the associated query, and the implications of each scenario for which memory systems are relevant).</p><p>We have also updated the caption and the main text to clarify the points made above. :</p><p>1. The caption of Figure 2:</p><p>“Figure 2. A situation-dependent event processing task. (A) An event is a sequence of states, sampled from an event schema and conditioned on a situation. An event schema is a graph where each node is a state. A situation is a collection of features (e.g., Day, Weather, Sleepiness) set to particular values (e.g., Day = weekday). The features of the current situation deterministically control how the event unfolds (e.g., the value of the Day feature controls which Barista state is observed). At each time point, the network observes the value of a randomly selected feature of the current situation, and responds to a query about what will happen next. Note that the order of queries is fixed but the order in which situation features are observed is random. If a situation feature (Sleepiness) is observed before the state it controls (Drink), the model can answer the query about that state by holding the relevant feature in working memory. However, if the relevant situation feature (Weather) is observed after the state it controls (Mood), the model can not rely on working memory on its own to answer the query. (B) We created three task conditions to simulate the design used by Chen et al., (2016): recent memory (RM), distant memory (DM), and no memory (NM); see text for details. (C) Decoded contents of the model’s working memory for an example trial from the DM condition. Green boxes indicate time points where the value of a particular situation feature was observed. The color of a square indicates whether the correct (i.e., observed) value of that feature can be decoded from the model’s working memory state (white = feature accurately decoded; black = feature not decoded). See text for additional explanation.”</p><p>2. Main text:</p><p>“To simulate the task of event processing, we define an event as a sequence of states,</p><p>sampled from an underlying graph that represents the event schema. […] If the relevant situation feature (Weather) for controlling a state (Mood) was not recently observed, the model can not use working memory on its own to answer the query; here, the only way the model can respond correctly is by retrieving a stored episodic memory of that situation.”</p><disp-quote content-type="editor-comment"><p>2) The authors show that their model does a better job of using episodic traces to reinstate the event representation when such traces are stored at the end of an event, rather than when they are stored at both the middle and the end. In explaining why, they show that the model tends to organize its internal representations mainly by time (ie events occurring at a similar point along the sequence are represented as similar). If episodes for the middle of the event are stored, these are preferentially reinstated later as the event continues following distraction, since the start of the &quot;continuing&quot; event looks more like an early-in-time event than a late-in-time event. This analysis is interesting and provides a clear explanation of why the model behaves as it does. However, reviewers want to know if it is mainly due to the highly sequential nature of the events the model is trained on, where prior observed features/queries don't repeat in an event. They wonder if the same phenomenon would be observed with richer sequences such as the coffee/tea-making examples from Botvinick et al., where one stirs the coffee twice (once after sugar, once after cream) and so must remember, for each stirring event, whether it is the first or the second. Does the &quot;encode only at the end&quot; phenomenon still persist in such cases? The result is less plausible as an account of the empirical phenomena if it only &quot;works&quot; for strictly linear sequences.</p></disp-quote><p>Thanks for the suggestion! We agree that this is a very interesting case. To respond to this suggestion, we ran a new simulation – as described in more detail below, we found that the “encode only at the end” phenomenon (i.e., better prediction performance for “encode only at the end” vs. “encode at end and also midway through”) persists even when the mapping between cues and responses is context-sensitive (i.e., the correct response to the first occurrence of a query in the sequence is different from the correct response to the second occurrence of that query).</p><p>In our standard task, each state is controlled by one (and only one) situation feature (e.g., weather, and only weather, controls mood). In our new simulation, each state (e.g., mood) has to be predicted twice in the sequence, and it is controlled by a different situation feature the first time that it occurs vs. the second time (e.g., mood is controlled by weather the first time it is queried in the sequence, and mood is controlled by music the second time it is queried in the sequence). As such, the model has to keep track of where it is in the sequence (i.e., is it being queried about mood for the first time or the second time) to know how to respond – in this key respect, the new simulation resembles the Botvinick and Plaut coffee-making example mentioned by the reviewer.</p><p>Specifically, for each sequence, the model was queried on 8 states that were controlled by 8 features, and then it was queried on the same 8 states again, but this time they were controlled by a different 8 features. In comparison, in our standard task, we had 16 distinct features that uniquely controlled 16 distinct states.</p><p>We found that the model can still learn to predict upcoming states very well with the new stimulus design. The model’s prediction performance and episodic memory gating pattern are qualitatively the same as what we found in the standard task (compare <xref ref-type="fig" rid="sa2fig1">Author response image 1</xref> to Figure 3 in the paper).</p><fig id="sa2fig1" position="float"><label>Author response image 1.</label><caption><title>The model performed well in the task with repeating queries.</title><p>This figure can be compared with Figure 3 in the paper.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-74445-sa2-fig1-v3.tif"/></fig><p>Next, we examined how the new variant of the model performed when memories were encoded at the end of part 1 (only) vs. encoding at the end and also midway through. In the new simulation, as in our previous simulation, the (less informative) midway memory competes at retrieval with the (more informative) endpoint memory, interfering with retrieval of the endpoint memory and impairing prediction performance. The results of the simulation are shown in <xref ref-type="fig" rid="sa2fig2">Author response image 2</xref> (compare to Figure 4 in the paper).</p><fig id="sa2fig2" position="float"><label>Author response image 2.</label><caption><title>Encoding midway through the event (in addition to encoding at the end) still hurts performance in the task with repeating queries.</title><p>This figure can be compared with Figure 4 in the paper.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-74445-sa2-fig2-v3.tif"/></fig><p>There are some subtle differences in the results obtained in the new simulation vs. the previous one: The fact that the same 8 queries are repeated in the first and second halves of the sequence makes the midway and endpoint memories more similar, so they are more evenly matched at retrieval (instead of the midway memory dominating the endpoint memory); because of the increased complexity of the mapping that the model has to learn, retrieving the midway memory blended together with the endpoint memory causes massive interference and results in a larger performance decrement than we observed in the previous simulation. Setting aside these differences, the basic point is unchanged – the extra “midway” memory impairs performance.</p><p>Given that the results of the new simulation lead to the same basic conclusions as the results of the existing simulation in the paper, we think that it is not worth devoting the space in the paper to give a full reporting of the methods and results for the new simulation. Instead, we have modified the main text to make it clear that the results described in the main text generalize to more complex sequences, and we restate the key principle that accounts for these results (starts at line 509):</p><p>“A possible alternative explanation of the negative effects of midway encoding is that midway encoding was introduced when we tested the model’s performance but was not present during meta-training (i.e., when the model acquired its retrieval policy); as such, midway encoding can be viewed as “out of distribution” and may be harmful for this reason. To address this concern, we also ran a version of the model where memories were stored both midway and at the end of an event during meta-training, and it was still true that endpoint-only encoding led to better performance than midway-plus-endpoint encoding; this result shows that midway encoding is intrinsically harmful, and it is not just a matter of it being out-of-distribution. In another simulation, we also found that the harmful effect of encoding midway through the sequence qualitatively replicates with more complex event structures (analogous to those in Botvinick and Plaut, 2004) where queries are repeated within a sequence and the model has to give a different response to the first vs. second occurrence of a query (e.g., mood is controlled first by weather and later by music).</p><p>To summarize the results from this section, the model does better when we force it to wait until the end of an event to take a snapshot. This pattern arises in our simulations because knowledge of the ongoing situation builds within an event, so memories encoded earlier in the event contain less information about the situation than memories encoded at the end. These less-informative midway memories harm performance by interfering with recall of more-informative endpoint memories, and are themselves more prone to false recall (because they are more confusable across events). Taken together, these simulation results provide a resource-rational justification for the results cited above showing preferential encodingrelated hippocampal activity at the end of events (Ben-Yakov and Dudai, 2011; Ben-Yakov et al., 2013; Baldassano et al., 2017; Ben-Yakov and Henson, 2018; Reagh et al., 2020).”</p><disp-quote content-type="editor-comment"><p>3) It would be helpful to understand how/why reinforcement learning is preferable to error-correcting learning in this framework. Since the task is simply to predict the upcoming answer to a query given a prior sequence of observed states, it seems likely that plain old backprop could work fine (indeed, the cortical model is pre-trained with backprop already), and that the model could still learn the critical episodic memory gating. Is the reinforcement learning approached used mainly so the model can be connected to the over-arching resource-rational perspective on cognition, or is there some other reason why this approach is preferred?</p></disp-quote><p>Thanks for pointing out this issue! We opted to use RL instead of purely supervised learning because of the model’s inclusion of a “don’t know” action. We expected that the optimal way to deploy this action would vary in complex ways as a function of different parameters (e.g., the penalty on incorrect responding), and we did not want to presume that we knew what the best policy would be. Consequently, we opted to let the model learn its own policy for using the “don’t know” action, rather than imposing a policy through supervised training. We now emphasize this point in the Model training section of the Methods.</p><p>A closely-related question is how our main model findings depend on the use of RL as opposed to supervised learning. The question is answered in Appendix 5, which shows results from a variant of the model that omitted the “don’t know” action and was trained with purely supervised learning. These simulations show that the primary effect of including the “don’t know” action is to make the model more patient (i.e. with “don’t know”, the model waits longer to initiate episodic retrieval, because the cost of delaying retrieval and saying “don’t know” is less than the cost of retrieving too early and giving the wrong answer) – apart from this, the results are quite similar. We now point the reader to Appendix 5 in the methods (as well as several other places in the text).</p><p>The changes we made to the Methods section are below:</p><p>“The model is trained with reinforcement learning. Specifically, the model is rewarded/penalized if its prediction about the next state is correct/incorrect. The model also has the option of saying “don’t know” (implemented as a dedicated output unit) when it is uncertain about what will happen next; if the model says “don’t know”, the reward is zero. The inclusion of this “don’t know” unit is what motivated us to use reinforcement learning as opposed to purely supervised training. We expected that the optimal way to deploy this action would vary in complex ways as a function of different parameters (e.g., the penalty on incorrect responding), and we did not want to presume that we knew what the best policy would be. Consequently, we opted to let themodel learn its own policy for using the “don’t know” action, rather than imposing a policy through supervised training (see Appendix 5 for results from a variant of the model where we omit the “don’t know” unit and train the model in a purely supervised fashion; these changes make the model less patient – i.e., retrieval takes place earlier in the sequence – but otherwise the results are qualitatively unchanged).</p><p>... Additionally, the “don’t know” output unit is not trained during the supervised pretraining phase – as noted above, we did this because we want the model to learn its own policy for saying “don’t know”, rather than having one imposed by us.”</p><disp-quote content-type="editor-comment"><p>4) The details of the simulations provided in the methods section could be clarified. First, on page 20, it is unclear about how w_i is computed. It seems to compute w_i (activation of trace i) you need to first compute activation of all other traces j, but since all such computations depend each other it is not clear how this is carried out. Perhaps you initialize this values for tau=0, but some detail here would help. Second, the specification of the learning algorithm for the A2C objective on page 21 has some terms that aren't explained. Specifically, it is not clear what the capital J denotes and what the /pi denotes. Third, other details about the training sufficient to replicate the work should also be provided--for instance, an explanation of the &quot;entropy regularization&quot; procedure, learning rates, optimizer, etc, for the supervised pre-training, and so on.</p></disp-quote><p>Thanks for pointing out that the description of the algorithm was unclear! We have now added more details in the Methods section: (1) We now describe the initial condition of w<sub>i</sub>, which is indeed zero for all i; (2) We added an explanation of the A2C objective, including the definitions of J andπ, and the formula for entropy regularization; And (3) we added information about the learning rate and optimizer to the method section. The changes that we made to the Methods section are marked in bold below (quoted passage starts at line 873):</p><p><italic>“w<sup>i</sup><sub>τ</sub></italic> is the activation value for the i-th memory at time τ; these activations are set to zero initially (<italic>w<sup>i</sup></italic><sub>0</sub> = 0, for all i). The activation for the <italic>i</italic>-th memory is positively relatedto its evidence, <italic>x<sub>i</sub></italic>, and is multiplicatively modulated by α, the EM gate value”</p><p>(quoted passage resumes at line 899)</p><p>“The model is trained with the advantage actor-critic (A2C) objective (Mnih et al., 2016). At time <italic>t</italic>, the model outputs its prediction about the next state,. ŝ<italic><sub>t+1</sub></italic>, and an estimate of the state value, <italic>v<sub>t</sub></italic>. After every event (i.e., a sequence of states of length <italic>T</italic>), it takes the following policy gradient step to adjust the connection weights for all layers, denoted by θ:<disp-formula id="sa2equ1"><mml:math id="sa2m1"><mml:mrow><mml:msub><mml:mi mathvariant="normal">∇</mml:mi><mml:mrow><mml:mi>θ</mml:mi></mml:mrow></mml:msub><mml:mi>J</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>θ</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi mathvariant="normal">∇</mml:mi><mml:mrow><mml:mo>[</mml:mo><mml:mrow><mml:munderover><mml:mo>∑</mml:mo><mml:mrow><mml:mi>t</mml:mi><mml:mo>=</mml:mo><mml:mn>0</mml:mn></mml:mrow><mml:mrow><mml:mi>T</mml:mi></mml:mrow></mml:munderover><mml:mi>log</mml:mi><mml:mo>⁡</mml:mo><mml:msub><mml:mi>π</mml:mi><mml:mrow><mml:mi>θ</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mover><mml:mi>s</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>t</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:msub><mml:mi>s</mml:mi><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>r</mml:mi><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>−</mml:mo><mml:msub><mml:mi>v</mml:mi><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>−</mml:mo><mml:mi>η</mml:mi><mml:mi>H</mml:mi><mml:mrow><mml:mo maxsize="1.2em" minsize="1.2em">(</mml:mo></mml:mrow><mml:msub><mml:mi>π</mml:mi><mml:mrow><mml:mi>θ</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mrow><mml:mover><mml:mi>s</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>t</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:msub><mml:mi>s</mml:mi><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:mrow><mml:mo maxsize="1.2em" minsize="1.2em">)</mml:mo></mml:mrow></mml:mrow><mml:mo>]</mml:mo></mml:mrow></mml:mrow></mml:mstyle></mml:mrow></mml:math></disp-formula></p><p>Where J is the objective function with respect to θ(the network weights). π<sub>θ</sub> is the policy represented by the network weights. H is the entropy function that takes a probability distribution and returns its entropy η controls the strength of entropy regularization.</p><p>The objective function J makes rewarded actions (next-state predictions) more likely to occur; the above equation shows how this process is modulated by the level of reward</p><p>prediction error – measured as the difference between the predicted value, vt, versus the reward at time t, denoted by <italic>r<sub>t</sub></italic>. We also used entropy regularization on the network output (Grandvalet and Bengio, 2006; Mnih et al., 2016) to encourage exploration in the early phase of the training process – with a positive η, the objective will encourage weight changes that lead to higher entropy distributions over actions. We used the A2C method (Mnih et al., 2016) because it is simple and has been widely used in cognitive modeling (Ritter et al., 2018; Wang et al., 2018). Notably, there is also evidence that an actor-critic style system is implemented in the neocortex and basal ganglia (Takahashi et al., 2008). Since pure reinforcement learning is not dataefficient enough, we used supervised initialization during meta-training to help the model develop useful representations (Misra et al., 2017; Naga- bandi et al., 2017). Specifically, the model is first trained for 600 epochs to predict the next state and to minimize the cross-entropy loss between the output and the target. During this supervised pre-training phase, the model is only trained on the recent memory condition and the episodic memory module is turned off, so this supervised pre-training does not influence the network’s retrieval policy. Additionally, the “don’t know” output unit is not trained during the supervised pre- training phase – as noted above, we did this because we want the model to learn its own policy for saying “don’t know”, rather than having one imposed by us. Next, the model is switched to the advantage actor-critic (A2C) objective (Mnih et al., 2016) and trained for another 400 epochs, allowing all weights to be adjusted. The number of training epochs was picked to ensure the learn- ing curves converge. For both the supervised-pretraining phase and the reinforcement learning phase, we used the Adam optimizer (Kingma and Ba, 2014) with learning rate of 7e-4 (for more details, please refer to Appendix 7).”</p><disp-quote content-type="editor-comment"><p>5) Line 566 – &quot;new frontier in the cognitive modeling of memory.&quot; They should qualify this statement with discussion of the shortcomings of these types of models. This model is useful for illustrating the potential functional utility of controlling the timing of episodic memory encoding and retrieval. However, the neural mechanisms for this control of gating is not made clear in these types of models. The authors suggest a portion of a potential mechanism when they mention the potential influence of the pattern of activity in the decision layer on the episodic memory gating (i.e., depending on the level of certainty – line 325), but they should mention that detailed neural circuit mechanisms are not made clear by this type of continuous firing rate model trained by gradient descent. More discussion of the difficulties of relating these types of neural network models to real biological networks is warranted. This is touched upon in lines 713-728, but the shortcomings of the current model in addressing biological mechanisms are not sufficiently highlighted. In particular, more biologically detailed models have addressed how network dynamics could regulate the levels of acetylcholine to shift dynamics between encoding and retrieval (Hasselmo et al., 1995; Hasselmo and Wyble, 1997). There should be more discussion of this prior work.</p></disp-quote><p>Thanks for the suggestion! We updated the corresponding paragraph which is copied below (quoted passage starts at line 748):</p><p>“Going forward, we also hope to explore more biologically-realistic episodic memory models (e.g., Hasselmo and Wyble, 1997; Schapiro et al., 2017; Norman and O’Reilly, 2003; Ketz et al., 2013). […] We have opted to start with the simplified episodic memory system described in this paper both for reasons of scientific parsimony and also for practical reasons – adding additional neurobiological details would make the model run too slowly (the current model takes on the order of hours to run on standard computers; adding more complexity would shift this to days or weeks).”</p><disp-quote content-type="editor-comment"><p>6) Figure 1 – &quot;the cortical part of the model&quot; – Line 117 – &quot;cortical weights&quot; and many other references to cortex. The hippocampus is a cortical structure (allocortex), so it is very confusing to see references to cortex used in contrast to hippocampus. The confusing use of references to cortex could be corrected by changing all the uses of &quot;cortex&quot; or &quot;cortical&quot; in this paper to &quot;neocortex&quot; or &quot;neocortical.&quot;</p></disp-quote><p>Thanks for the suggestion! We changed cortical/cortex to neocortex/neocortical throughout the paper.</p><disp-quote content-type="editor-comment"><p>7) &quot;the encoding policy is not learned&quot; – This came as a surprise in the discussion, so it indicates that this is not made sufficiently clear earlier in the text. This statement should be made in a couple of points earlier where the encoding policy is discussed.</p></disp-quote><p>Thanks for pointing out that this is unclear! Now we mention this explicitly at the beginning of the encoding simulation (quoted passage starts at line 473):</p><p>“While it is clear why encoding at the end of an event is useful, it is less clear why encoding at other times might be harmful; naively, one might think that storing more episodic snapshots during an event would lead to better memory for the event. To answer this question, we compared models that selectively encode episodic memories at the end of each event to models that encode episodic memories both at the end of each event and also midway through each event. Note that the model did not learn these two encoding policies by itself – we simply configured the model to encode one way or the other and compared their performance. If selectively encoding at the end of an event yields better performance, this would provide a resource-rational justification for the empirical findings reviewed above.”</p></body></sub-article></article>