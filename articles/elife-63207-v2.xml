<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD v1.1 20151215//EN"  "JATS-archivearticle1.dtd"><article article-type="research-article" dtd-version="1.1" xmlns:ali="http://www.niso.org/schemas/ali/1.0/" xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink"><front><journal-meta><journal-id journal-id-type="nlm-ta">elife</journal-id><journal-id journal-id-type="publisher-id">eLife</journal-id><journal-title-group><journal-title>eLife</journal-title></journal-title-group><issn pub-type="epub" publication-format="electronic">2050-084X</issn><publisher><publisher-name>eLife Sciences Publications, Ltd</publisher-name></publisher></journal-meta><article-meta><article-id pub-id-type="publisher-id">63207</article-id><article-id pub-id-type="doi">10.7554/eLife.63207</article-id><article-categories><subj-group subj-group-type="display-channel"><subject>Research Article</subject></subj-group><subj-group subj-group-type="heading"><subject>Computational and Systems Biology</subject></subj-group><subj-group subj-group-type="heading"><subject>Neuroscience</subject></subj-group></article-categories><title-group><article-title>Action detection using a neural network elucidates the genetics of mouse grooming behavior</article-title></title-group><contrib-group><contrib contrib-type="author" id="author-209654"><name><surname>Geuther</surname><given-names>Brian Q</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">https://orcid.org/0000-0002-7822-486X</contrib-id><xref ref-type="aff" rid="aff1"/><xref ref-type="fn" rid="con1"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" id="author-209655"><name><surname>Peer</surname><given-names>Asaf</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">https://orcid.org/0000-0002-7577-353X</contrib-id><xref ref-type="aff" rid="aff1"/><xref ref-type="fn" rid="con2"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" id="author-209657"><name><surname>He</surname><given-names>Hao</given-names></name><xref ref-type="aff" rid="aff1"/><xref ref-type="fn" rid="con3"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" id="author-209656"><name><surname>Sabnis</surname><given-names>Gautam</given-names></name><xref ref-type="aff" rid="aff1"/><xref ref-type="fn" rid="con4"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" id="author-209658"><name><surname>Philip</surname><given-names>Vivek M</given-names></name><xref ref-type="aff" rid="aff1"/><xref ref-type="fn" rid="con5"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" corresp="yes" id="author-3326"><name><surname>Kumar</surname><given-names>Vivek</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">https://orcid.org/0000-0001-6643-7465</contrib-id><email>Vivek.Kumar@jax.org</email><xref ref-type="aff" rid="aff1"/><xref ref-type="other" rid="fund1"/><xref ref-type="other" rid="fund2"/><xref ref-type="other" rid="fund3"/><xref ref-type="other" rid="fund4"/><xref ref-type="other" rid="fund5"/><xref ref-type="fn" rid="con6"/><xref ref-type="fn" rid="conf1"/></contrib><aff id="aff1"><institution>The Jackson Laboratory</institution><addr-line><named-content content-type="city">Bar Harbor</named-content></addr-line><country>United States</country></aff></contrib-group><contrib-group content-type="section"><contrib contrib-type="editor"><name><surname>Marlin</surname><given-names>Bianca Jones</given-names></name><role>Reviewing Editor</role><aff><institution>Columbia University</institution><country>United States</country></aff></contrib><contrib contrib-type="senior_editor"><name><surname>Taffe</surname><given-names>Michael</given-names></name><role>Senior Editor</role><aff><institution>University of California, San Diego</institution><country>United States</country></aff></contrib></contrib-group><pub-date date-type="publication" publication-format="electronic"><day>17</day><month>03</month><year>2021</year></pub-date><pub-date pub-type="collection"><year>2021</year></pub-date><volume>10</volume><elocation-id>e63207</elocation-id><history><date date-type="received" iso-8601-date="2020-09-17"><day>17</day><month>09</month><year>2020</year></date><date date-type="accepted" iso-8601-date="2021-03-05"><day>05</day><month>03</month><year>2021</year></date></history><permissions><copyright-statement>© 2021, Geuther et al</copyright-statement><copyright-year>2021</copyright-year><copyright-holder>Geuther et al</copyright-holder><ali:free_to_read/><license xlink:href="http://creativecommons.org/licenses/by/4.0/"><ali:license_ref>http://creativecommons.org/licenses/by/4.0/</ali:license_ref><license-p>This article is distributed under the terms of the <ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/licenses/by/4.0/">Creative Commons Attribution License</ext-link>, which permits unrestricted use and redistribution provided that the original author and source are credited.</license-p></license></permissions><self-uri content-type="pdf" xlink:href="elife-63207-v2.pdf"/><abstract><p>Automated detection of complex animal behaviors remains a challenging problem in neuroscience, particularly for behaviors that consist of disparate sequential motions. Grooming is a prototypical stereotyped behavior that is often used as an endophenotype in psychiatric genetics. Here, we used mouse grooming behavior as an example and developed a general purpose neural network architecture capable of dynamic action detection at human observer-level performance and operating across dozens of mouse strains with high visual diversity. We provide insights into the amount of human annotated training data that are needed to achieve such performance. We surveyed grooming behavior in the open field in 2457 mice across 62 strains, determined its heritable components, conducted GWAS to outline its genetic architecture, and performed PheWAS to link human psychiatric traits through shared underlying genetics. Our general machine learning solution that automatically classifies complex behaviors in large datasets will facilitate systematic studies of behavioral mechanisms.</p></abstract><abstract abstract-type="executive-summary"><title>eLife digest</title><p>Behavior is one of the ultimate and most complex outputs of the body’s central nervous system, which controls movement, emotion and mood. It is also influenced by a person’s genetics. Scientists studying the link between behavior and genetics often conduct experiments using animals, whose actions can be more easily characterized than humans. However, this involves recording hours of video footage, typically of mice or flies. Researchers must then add labels to this footage, identifying certain behaviors before further analysis.</p><p>This task of annotating video clips – similar to image captioning – is very time-consuming for investigators. But it could be automated by applying machine learning algorithms, trained with sufficient data. Some computer programs are already in use to detect patterns of behavior, however, there are some limitations. These programs could detect animal behavior (of flies and mice) in trimmed video clips, but not raw footage, and could not always accommodate different lighting conditions or experimental setups. Here, Geuther et al. set out to improve on these previous efforts to automate video annotation.</p><p>To do so, they used over 1,250 video clips annotated by experienced researchers to develop a general-purpose neural network for detecting mouse behaviors. After sufficient training, the computer model could detect mouse grooming behaviors in raw, untrimmed video clips just as well as human observers could. It also worked with mice of different coat colors, body shapes and sizes in open field animal tests.</p><p>Using the new computer model, Geuther et al. also studied the genetics underpinning behavior – far more thoroughly than previously possible – to explain why mice display different grooming behaviors. The algorithm analyzed 2,250 hours of video featuring over 60 kinds of mice and thousands of other animals. It found that mice bred in the laboratory groom less than mice recently collected from the wild do. Further analyses also identified genes linked to grooming traits in mice and found related genes in humans associated with behavioral disorders.</p><p>Automating video annotation using machine learning models could alleviate the costs of running lengthy behavioral experiments and enhance the reproducibility of study results. The latter is vital for translating behavioral research findings in mice to humans. This study has also provided insights into the amount of human-annotated training data needed to develop high-performing computer models, along with new understandings of how genetics shapes behavior.</p></abstract><kwd-group kwd-group-type="author-keywords"><kwd>action detection</kwd><kwd>machine learning</kwd><kwd>grooming</kwd><kwd>neural network</kwd><kwd>GWAS</kwd></kwd-group><kwd-group kwd-group-type="research-organism"><title>Research organism</title><kwd>Mouse</kwd></kwd-group><funding-group><award-group id="fund1"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/100005946</institution-id><institution>Jackson Laboratory</institution></institution-wrap></funding-source><award-id>Director's Innovation Fund</award-id><principal-award-recipient><name><surname>Kumar</surname><given-names>Vivek</given-names></name></principal-award-recipient></award-group><award-group id="fund2"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/100000002</institution-id><institution>National Institutes of Health</institution></institution-wrap></funding-source><award-id>DA041668</award-id><principal-award-recipient><name><surname>Kumar</surname><given-names>Vivek</given-names></name></principal-award-recipient></award-group><award-group id="fund3"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/100000002</institution-id><institution>National Institutes of Health</institution></institution-wrap></funding-source><award-id>DA048634</award-id><principal-award-recipient><name><surname>Kumar</surname><given-names>Vivek</given-names></name></principal-award-recipient></award-group><award-group id="fund4"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/100000001</institution-id><institution>National Science Foundation</institution></institution-wrap></funding-source><award-id>TG-DBS170004</award-id><principal-award-recipient><name><surname>Kumar</surname><given-names>Vivek</given-names></name></principal-award-recipient></award-group><award-group id="fund5"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/100000874</institution-id><institution>Brain and Behavior Research Foundation</institution></institution-wrap></funding-source><principal-award-recipient><name><surname>Kumar</surname><given-names>Vivek</given-names></name></principal-award-recipient></award-group><funding-statement>The funders had no role in study design, data collection and interpretation, or the decision to submit the work for publication.</funding-statement></funding-group><custom-meta-group><custom-meta specific-use="meta-only"><meta-name>Author impact statement</meta-name><meta-value>A machine learning method for action detection is developed and applied toward mouse grooming behavior.</meta-value></custom-meta></custom-meta-group></article-meta></front><body><sec id="s1" sec-type="intro"><title>Introduction</title><p>Behavior, the primary output of the nervous system, is complex, hierarchical, dynamic, and high dimensional (<xref ref-type="bibr" rid="bib25">Gomez-Marin et al., 2014</xref>). Precise approaches to dissect neuronal function require analysis of behavior at high temporal and spatial resolution. Achieving this is a time-consuming task and its automation remains a challenging problem in behavioral neuroscience. In the field of computer vision, modern neural network approaches have presented new solutions to visual tasks that perform just as well as humans (<xref ref-type="bibr" rid="bib13">Ching et al., 2018</xref>; <xref ref-type="bibr" rid="bib2">Angermueller et al., 2016</xref>). Application of these tools to biologically relevant problems could alleviate the costs of behavioral experiments and enhance reproducibility. Despite these enticing advantages, few aspects of behavioral biology research leverages neural network approaches. This lack of application is often attributed to the high cost of organizing and annotating the data sets, or to the stringent performance requirements. Thus, behavior recognition within dynamic environments is an open challenge in the machine learning community and translatability of proposed solutions to behavioral neuroscience remains unaddressed.</p><p>Behavioral action recognition falls under multiple types of computer vision problems, including action classification, event detection, and temporal action localization. Action classification, a task closely related to image captioning, trains a classifier to apply action labels to manually pre-trimmed video clips. This problem has already been largely solved, with the exceptional performance for networks competing in data sets such as Kinetics-400, Moments in Time, Youtube-8M, and many other available benchmark data sets (<xref ref-type="bibr" rid="bib69">Wu et al., 2017</xref>). However, this classification does not determine when an action occurs within an untrimmed video. To address this shortcoming, two other tasks have been designed: event detection (ActivityNet 2019 Task 1) and temporal action localization (ActivityNet 2019 Task 2) (<xref ref-type="bibr" rid="bib28">Heilbron et al., 2015</xref>). The objective of event detection is to identify when an event occurs, whereas the objective of temporal action detection is to identify where, when, and who is performing an action in untrimmed video input. The dominant approach for solving these issues has been extending region proposal methods from single images to video data. This involves proposing video tubelets (<xref ref-type="bibr" rid="bib31">Kalogeiton et al., 2017</xref>; <xref ref-type="bibr" rid="bib20">Feichtenhofer et al., 2019</xref>), a clip of video in both space and time for a single subject performing a single action.</p><p>In behavioral neuroscience, previous attempts to operate directly on visual data have utilized unsupervised behavioral clustering approaches (<xref ref-type="bibr" rid="bib61">Todd et al., 2017</xref>). These include seminal work to convert visual data into frequency domains followed by clustering in <italic>Drosophila</italic> (<xref ref-type="bibr" rid="bib6">Berman et al., 2014</xref>) and autoregressive Hidden Markov Model-based analysis of depth imaging data for mouse behavior (<xref ref-type="bibr" rid="bib68">Wiltschko et al., 2015</xref>). Both approaches rely upon alignment of data from a top-down view and while they cluster similar video segments, interpretation of generated clusters is still dictated by the user. It is also unclear how these approaches will perform on sequences of disparate behaviors.</p><p>Supervised approaches in behavioral neuroscience have abstracted the subject into lower dimensions such as ellipse or key points, followed by feature generation, and classification (<xref ref-type="bibr" rid="bib30">Kabra et al., 2013</xref>; <xref ref-type="bibr" rid="bib64">van den Boom et al., 2017</xref>). While these approaches were a significant advance when they were introduced, they are inherently limited by the measurements available from the abstraction. For instance, standard measurements such as center of mass tracking, limit the types of behaviors that can be classified reliably. The field quickly recognized this issue and moved to integrate new measurements for the algorithms to classify behavior. These new features are highly specific to the organism and behavior that the researcher wishes to observe. In <italic>Drosophila</italic> studies, tracking of individual limbs and wings add new tracking modalities (<xref ref-type="bibr" rid="bib51">Robie et al., 2017</xref>). For mice, modern systems integrate floor vibration measurements and depth imaging techniques to enhance behavior detection (<xref ref-type="bibr" rid="bib50">Quinn et al., 2003</xref>; <xref ref-type="bibr" rid="bib29">Hong et al., 2015</xref>; <xref ref-type="bibr" rid="bib68">Wiltschko et al., 2015</xref>). Vibration measurements set limits to both the environment and the number of animals, while depth imaging restricts the environment. While others have attempted to automate the annotation of mouse grooming using a machine learning classifier, available techniques are not robust for multiple animal coat colors, lighting conditions, and locations of the setup (<xref ref-type="bibr" rid="bib64">van den Boom et al., 2017</xref>). Recent advances in computer vision also provide general purpose solutions for marker-less tracking in lab animals (<xref ref-type="bibr" rid="bib42">Mathis et al., 2018</xref>; <xref ref-type="bibr" rid="bib49">Pereira et al., 2019</xref>). These new techniques provide richer features to extend traditional machine learning techniques for behavioral classification. Human action detection leaderboards suggest that while the approach of pose estimation is powerful, it routinely underperforms compared to end-to-end solutions that utilize raw video input for action classification (<xref ref-type="bibr" rid="bib20">Feichtenhofer et al., 2019</xref>; <xref ref-type="bibr" rid="bib14">Choutas et al., 2018</xref>).</p><p>Here, we use neural networks to directly classify mouse grooming behavior from video. Grooming represents a form of stereotyped or patterned behavior of considerable biological importance consisting of a range of small to large actions. Grooming is an innate behavior conserved across animal species, including mammals (<xref ref-type="bibr" rid="bib57">Spruijt et al., 1992</xref>; <xref ref-type="bibr" rid="bib32">Kalueff et al., 2010</xref>). In rodents, a significant amount of waking behavior, between 20 and 50%, consists of grooming (<xref ref-type="bibr" rid="bib63">Van de Weerd et al., 2001</xref>; <xref ref-type="bibr" rid="bib57">Spruijt et al., 1992</xref>; <xref ref-type="bibr" rid="bib8">Bolles, 1960</xref>). Grooming serves many adaptive functions such as coat and body care, stress reduction, de-arousal, social functions, thermoregulation, nociception, as well as other functions (<xref ref-type="bibr" rid="bib57">Spruijt et al., 1992</xref>; <xref ref-type="bibr" rid="bib32">Kalueff et al., 2010</xref>; <xref ref-type="bibr" rid="bib21">Fentress, 1988</xref>). The neural circuitry that regulates grooming behavior has been studied, although much remains unknown. Importantly, grooming and other patterned behaviors are endophenotypes for many psychiatric illnesses. For instance, a high level of stereotyped behavior is seen in autism spectrum disorder (ASD), while in contrast, Parkinson’s disease shows an inability to generate patterned behaviors (<xref ref-type="bibr" rid="bib32">Kalueff et al., 2010</xref>). Therefore, the accurate and automated analysis of grooming behavior represents important value in behavioral neuroscience. We also reasoned that successful development of a neural network architecture for grooming behavior classification would be transferable to other behaviors by changing the training data.</p><p>We applied a general machine learning solution to mouse grooming and developed a classifier that performs at human level. This classifier performs across 62 inbred and F1 hybrid strains of mice consisting of visually diverse coat colors, body shapes, and sizes. We explored reasons why our network has an upper limit on performance that seems to be concordant with human annotations. Human level performance comes at a cost of a large amount of labeled training data. We identified environmental and genetic regulators of grooming behavior in the open field. Finally, we applied our grooming behavior solution to a genetically diverse mouse population and characterize the grooming pattern of the mouse in an open field. We used these data to carry out a genome wide association study (GWAS) and to identify the genetic architecture that regulates heritable variation in grooming and open-field behaviors in the laboratory mouse. Combined we propose a generalizable solution to complex action detection and apply it toward grooming behavior.</p></sec><sec id="s2" sec-type="results"><title>Results</title><sec id="s2-1"><title>Mouse grooming</title><p>Behavior varies widely on both time and space scales, from fine spatial movements such as whisking, blinking, or tremors to large spatial movements such as turning or walking, and temporally from milliseconds to minutes. We sought to develop a classifier that could observe and predict complex behaviors produced by the mouse. Grooming consists of syntaxes that are small or micro-motions (paw lick) to mid-size movements (unilateral and bilateral face wash) and large movements (flank licking) <xref ref-type="fig" rid="fig1">Figure 1A</xref>. There are also rare syntaxes such as genital and tail grooming. Grooming duration can vary from sub-seconds to minutes.</p><fig-group><fig id="fig1" position="float"><label>Figure 1.</label><caption><title>Annotation of mouse grooming behavior.</title><p>(<bold>A</bold>) Mouse grooming contains a wide variety of postures. Paw licking, face-washing, flank linking, as well as other syntaxes all contribute to this visually diverse behavior. (<bold>B</bold>) We provided synchronized two-view data for observers to annotate. (<bold>C</bold>) Grooming ethograms for six videos by five different trained annotators. Overall, there is very high agreement between human annotators. (<bold>D</bold>) Quantification of the agreement overlap between individual annotators. Average agreement between all annotators is 89.13%.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-63207-fig1-v2.tif"/></fig><fig id="fig1s1" position="float" specific-use="child-fig"><label>Figure 1—figure supplement 1.</label><caption><title>Additional details of annotator disagreements.</title><p>(<bold>A</bold>) We classify the types of annotation disagreement into three classes of errors: missed bouts, misalignment, and skipped breaks. (<bold>B–C</bold>) We quantify the types of errors in <xref ref-type="fig" rid="fig1">Figure 1</xref>. (<bold>B</bold>) The sum of frames that fall into each error category. 37.5% of frames are missed bouts, 50% are misalignment, and 12.4% are skipped breaks. The types of errors are not uniformly distributed across annotators as annotator two accounts for the most missed bout frame counts, annotator four accounts for the most misalignment frame counts, and annotator one accounts for the most skipped break frame counts. (<bold>C</bold>) Counting the number of multi-frame occurrences of errors, we observe a similar distribution. 19.2% of call are missed bouts, 74.6% are misalignment, and 6.3% are skipped breaks.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-63207-fig1-figsupp1-v2.tif"/></fig></fig-group></sec><sec id="s2-2"><title>Annotating grooming</title><p>Our approach to annotating grooming classified each frame in a video as the mouse being in one of two states: grooming or not grooming. We specified that a frame should be annotated as grooming when the mouse is performing any of the syntaxes of grooming, whether or not the mouse is performing a stereotyped syntactic chain of grooming. This included a wide variety of postures and action durations which contribute to a diverse visual appearance. This also explicitly included individual paw licks as grooming, despite isolated paw licks not constituting a bout of grooming. Scratching was excluded from being classified as grooming.</p><p>We investigated the variability in manual grooming annotations by humans by tasking five trained annotators with labeling the same six 5 min videos (30 min total, <xref ref-type="fig" rid="fig1">Figure 1</xref>). To help human scorers, we provided these videos from a top-down and side view of the mouse (<xref ref-type="fig" rid="fig1">Figure 1B</xref>). These videos included C57BL/6J, BTBR and CAST/EiJ mouse strains. We gave each annotator the same instructions to label the behavior (see Methods). We observed a strong agreement (89.1% average) between annotators, which is in concordance with prior work annotating mouse grooming behavior (<xref ref-type="bibr" rid="bib39">Kyzar et al., 2011</xref>). To examine disagreements between annotators, we classified them into three classes: missed bout, skipped break, and misalignment (<xref ref-type="fig" rid="fig1s1">Figure 1—figure supplement 1</xref>). Missed bout calls are made when a disagreement occurs in a not-grooming call. Similarly, skipped break calls are made when a disagreement occurs in a grooming call. Finally, misalignment is called when both annotators agree that grooming is either starting or ending but disagree on the exact frame in which this occurs. The most frequent type of error was misalignment, accounting for 50% of total duration of disagreement frames annotated and 75% of the disagreement calls (<xref ref-type="fig" rid="fig1s1">Figure 1—figure supplement 1</xref>).</p><p>Next, we constructed a large annotation data set to train a machine learning algorithm. While most machine learning contests seeking to solve tasks similar to ours have widely varied data set sizes, we leveraged network performance in these contests for design of our data set. Networks in these contests perform well when an individual class contains at least 10,000 annotated frames (<xref ref-type="bibr" rid="bib24">Girdhar et al., 2019</xref>). As the number of annotations in a class exceeds 100,000, network performance for this task achieves mean average precision (mAP) scores above 0.7 (<xref ref-type="bibr" rid="bib24">Girdhar et al., 2019</xref>; <xref ref-type="bibr" rid="bib72">Zhang et al., 2019</xref>). With deep learning approaches, model performance benefits from additional annotations (<xref ref-type="bibr" rid="bib59">Sun et al., 2017</xref>). To ensure success, we set out to annotate over 2 million frames with either grooming or not grooming. We aimed to balance this data set for grooming behavior by selecting video clips based on tracking heuristics, prioritizing segments with low velocity because a mouse cannot be grooming while walking. We also cropped the video frame to be centered on the mouse to reduce visual clutter using our tracker (<xref ref-type="bibr" rid="bib22">Geuther et al., 2019</xref>). This cropping centered around the mouse follows the video tube approach, as seen in the current state of the art (<xref ref-type="bibr" rid="bib20">Feichtenhofer et al., 2019</xref>). Based on this, we sampled 1253 short video clips from 157 videos. These video clips represent a diverse set of mice including 60 strains and a large range of body weights (<xref ref-type="fig" rid="fig2s1">Figure 2—figure supplement 1A–B</xref>). Using a pool of seven validated annotators, we obtained two annotations for each of the 1253 video clips totaling 2,637,363 frames with 94.3% agreement between annotations (<xref ref-type="fig" rid="fig2">Figure 2A</xref>).</p><fig-group><fig id="fig2" position="float"><label>Figure 2.</label><caption><title>Neural network based action detection.</title><p>(<bold>A</bold>) A total of 2,637,363 frames were annotated across 1253 video clips by two different human annotators to create this data set for training and analyzing our neural network. The outer ring represents the training data set agreement between human annotators while the inner ring represents the validation data set agreement between human annotators. (<bold>B</bold>) A visual description of the classification approach that we implemented. To analyze an entire video, we pass a sliding window of frames into a neural network. (<bold>C</bold>) Our network takes video input and produces a grooming prediction for a single frame.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-63207-fig2-v2.tif"/></fig><fig id="fig2s1" position="float" specific-use="child-fig"><label>Figure 2—figure supplement 1.</label><caption><title>Additional details about the annotated dataset.</title><p>Our training dataset contains 1253 video clips that originate from 157 independent mice across 60 strains. (<bold>A</bold>) Distribution of clip durations by mouse strain. (<bold>B</bold>) Distribution of body weights present in our annotated dataset. Also see <xref ref-type="supplementary-material" rid="supp1">Supplementary file 1</xref> for all associated annotated dataset metadata.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-63207-fig2-figsupp1-v2.tif"/></fig></fig-group></sec><sec id="s2-3"><title>Proposed neural network solution</title><p>We trained a neural network classifier using our large annotated data set. Of the 1253 video clips, we held out 153 for validation. Using this split, we achieved similar distributions of frame-level classifications between training and validation sets (<xref ref-type="fig" rid="fig2">Figure 2A</xref>). Our machine learning approach takes video input data and produces an ethogram output for grooming behavior (<xref ref-type="fig" rid="fig2">Figure 2B</xref>). Functionally, our neural network model takes an input of 16 112 × 112 frames, applies multiple layers of 3D convolutions, 3D pooling, and fully connected layers to produce a prediction for only the last frame (<xref ref-type="fig" rid="fig2">Figure 2C</xref>). To predict a completed ethogram for a video, we slide the 16-frame window across the video.</p><p>We compared our neural network approach to a previously established machine learning approach for annotating lab animal behavior, JAABA (<xref ref-type="bibr" rid="bib30">Kabra et al., 2013</xref>). Our neural network achieved 93.7% accuracy and 91.9% true positive rate (TPR) with a 5% false positive rate (FPR) (<xref ref-type="fig" rid="fig3">Figure 3A,B</xref>, pink line). In comparison, the JAABA trained classifier achieved a lower performance of 84.9% accuracy and 64.2% TPR at a 5% FPR (<xref ref-type="fig" rid="fig3">Figure 3A,B</xref>). Due to memory limitations of JAABA, we could only train it using 20% of our training set. To test whether the training set size accounted for this poorer performance by JAABA, training our neural network using 20% of our training set still led to out-performance of JAABA (<xref ref-type="fig" rid="fig3">Figure 3B</xref>). When training the neural network using different sized training data sets, we observed improved validation performance with increasing data set size (<xref ref-type="fig" rid="fig3s1">Figure 3—figure supplement 1A</xref>). Scaling the training dataset size for JAABA showed that performance saturated when using 10% of our training data (<xref ref-type="fig" rid="fig3s1">Figure 3—figure supplement 1B</xref>). Using an interactive training protocol recommended by the authors of JAABA, we observed decreased performance. This was likely due to the drastic size difference of the annotated data sets used in training (17,000 frames, or 0.7% of our annotated dataset). Interestingly, JAABA using 5% of our training dataset outperformed our neural network using 10% of our training dataset. This suggests that although JAABA may perform better using limited small datasets, both a neural network approach and a larger training dataset are necessary for generalizing on larger and more varied data.</p><fig-group><fig id="fig3" position="float"><label>Figure 3.</label><caption><title>Validation of neural network model.</title><p>(<bold>A</bold>) Agreement between the annotators while creating the data set compared to the accuracy of the algorithms predicting on this data set. We compared the machine learning models against only annotations where the annotators agree. (<bold>B</bold>) Receiver operating characteristic (ROC) curve for three machine learning techniques trained on the training set and applied to the validation set. Our final neural network model approach achieves the highest area under curve (AUC) value of 0.9843402. True positive at 5% False positive is indicated with pink line. (<bold>C</bold>) A visual description of our proposed consensus solution. We use a 32x consensus approach where we trained four separate models and give eight frame viewpoints to each. To combine these predictions, we averaged all 32 predictions. While one viewpoint from one model can be wrong, the mean prediction using this consensus improves accuracy. (<bold>D–E</bold>) Example frames where the model is correctly predicting grooming and not-grooming behavior. Also see <xref ref-type="video" rid="fig3video1">Figure 3—videos 1</xref>–<xref ref-type="video" rid="fig3video9">9</xref>.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-63207-fig3-v2.tif"/></fig><fig id="fig3s1" position="float" specific-use="child-fig"><label>Figure 3—figure supplement 1.</label><caption><title>Additional ROC curve subsets.</title><p>(<bold>A</bold>) Performance of the network using different training data set sizes. As the number of training data samples increases, the ROC curve performance increases up to a point. (<bold>B</bold>) Performance of JAABA using different training data set sizes. Performance stops improving after using 10% of our annotations.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-63207-fig3-figsupp1-v2.tif"/></fig><fig id="fig3s2" position="float" specific-use="child-fig"><label>Figure 3—figure supplement 2.</label><caption><title>Validation performance of algorithm split by video.</title><p>Clusters of validation video ROC performance by machine learning approaches. (<bold>A</bold>) The majority of validation videos have good performance. (<bold>B</bold>) Some validation videos suffer from slightly degraded performance. (<bold>C</bold>) Validation videos where the JAABA approach performs slightly worse than our neural network approach. (<bold>D</bold>) Two validation videos showed poor performance using both machine learning approaches. Upon inspection of these videos, the annotated frames for grooming are visually difficult to classify. (<bold>E</bold>) seven validation videos showed good performance using the neural network but a clear drop in performance using JAABA. All videos that contain no positive grooming annotated frames do not have a ROC curve and were excluded from this figure.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-63207-fig3-figsupp2-v2.tif"/></fig><fig id="fig3s3" position="float" specific-use="child-fig"><label>Figure 3—figure supplement 3.</label><caption><title>Comparison of different consensus modalities and temporal smoothing.</title><p>(<bold>A</bold>) ROC performance using different consensus modalities. All consensus modalities provide approximately the same result. (<bold>B</bold>) Temporal filter analysis.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-63207-fig3-figsupp3-v2.tif"/></fig><media id="fig3video1" mime-subtype="mp4" mimetype="video" xlink:href="elife-63207-fig3-video1.mp4"><label>Figure 3—video 1.</label><caption><title>Sample video of a black coat color mouse.</title><p>The ensemble networks are shown on the upper left (small squares) and consensus is shown in large square. See <xref ref-type="fig" rid="fig3">Figure 3C</xref> - green (negative for grooming) to purple (positive for grooming).</p></caption></media><media id="fig3video2" mime-subtype="mp4" mimetype="video" xlink:href="elife-63207-fig3-video2.mp4"><label>Figure 3—video 2.</label><caption><title>Sample video of an agouti coat color mouse.</title><p>The ensemble networks are shown on the upper left (small squares) and consensus is shown in large square. See <xref ref-type="fig" rid="fig3">Figure 3C</xref> - green (negative for grooming) to purple (positive for grooming).</p></caption></media><media id="fig3video3" mime-subtype="mp4" mimetype="video" xlink:href="elife-63207-fig3-video3.mp4"><label>Figure 3—video 3.</label><caption><title>Sample video of an agouti coat color mouse.</title><p>The ensemble networks are shown on the upper left (small squares) and consensus is shown in large square. See <xref ref-type="fig" rid="fig3">Figure 3C</xref> - green (negative for grooming) to purple (positive for grooming).</p></caption></media><media id="fig3video4" mime-subtype="mp4" mimetype="video" xlink:href="elife-63207-fig3-video4.mp4"><label>Figure 3—video 4.</label><caption><title>Sample video of an albino coat color mouse.</title><p>The ensemble networks are shown on the upper left (small squares) and consensus is shown in large square. See <xref ref-type="fig" rid="fig3">Figure 3C</xref> - green (negative for grooming) to purple (positive for grooming).</p></caption></media><media id="fig3video5" mime-subtype="mp4" mimetype="video" xlink:href="elife-63207-fig3-video5.mp4"><label>Figure 3—video 5.</label><caption><title>Sample video of an off-white coat color mouse.</title><p>The ensemble networks are shown on the upper left (small squares) and consensus is shown in large square. See <xref ref-type="fig" rid="fig3">Figure 3C</xref> - green (negative for grooming) to purple (positive for grooming).</p></caption></media><media id="fig3video6" mime-subtype="mp4" mimetype="video" xlink:href="elife-63207-fig3-video6.mp4"><label>Figure 3—video 6.</label><caption><title>Sample video of a gray coat color mouse.</title><p>The ensemble networks are shown on the upper left (small squares) and consensus is shown in large square. See <xref ref-type="fig" rid="fig3">Figure 3C</xref> - green (negative for grooming) to purple (positive for grooming).</p></caption></media><media id="fig3video7" mime-subtype="mp4" mimetype="video" xlink:href="elife-63207-fig3-video7.mp4"><label>Figure 3—video 7.</label><caption><title>Sample video of a chinchila coat color mouse.</title><p>The ensemble networks are shown on the upper left (small squares) and consensus is shown in large square. See <xref ref-type="fig" rid="fig3">Figure 3C</xref> - green (negative for grooming) to purple (positive for grooming).</p></caption></media><media id="fig3video8" mime-subtype="mp4" mimetype="video" xlink:href="elife-63207-fig3-video8.mp4"><label>Figure 3—video 8.</label><caption><title>Sample video of a nude coat color mouse.</title><p>The ensemble networks are shown on the upper left (small squares) and consensus is shown in large square. See <xref ref-type="fig" rid="fig3">Figure 3C</xref> - green (negative for grooming) to purple (positive for grooming).</p></caption></media><media id="fig3video9" mime-subtype="mp4" mimetype="video" xlink:href="elife-63207-fig3-video9.mp4"><label>Figure 3—video 9.</label><caption><title>Sample video of a kit mouse.</title><p>The ensemble networks are shown on the upper left (small squares) and consensus is shown in large square. See <xref ref-type="fig" rid="fig3">Figure 3C</xref> - green (negative for grooming) to purple (positive for grooming).</p></caption></media></fig-group><p>Our neural network approach was as good as human annotators, given our previous observations in <xref ref-type="fig" rid="fig1">Figure 1B–C</xref> of 89% agreement. We inspected the receiver operating characteristic (ROC) curve performance on a per-video basis and found that performance was not uniform across all videos (<xref ref-type="fig" rid="fig3s2">Figure 3—figure supplement 2</xref>). The majority of the 153 validation videos were adequately annotated by both the neural network and JAABA. However, two videos performed poorly with both algorithms and seven videos showed drastic improvement using a neural network over the JAABA-trained classifier. Manual visual inspection of the two videos where both algorithms performed poorly suggests that they did not provide sufficient visual information to annotate grooming.</p><p>While developing our final neural network solution, we applied two forms of consensus modalities to improve single-model performance (<xref ref-type="fig" rid="fig3">Figure 3C</xref>). Each trained model makes slightly different predictions, due to randomness involved in training. This randomness appears in both network parameter initialization and the order of training batches. By training multiple models and merging the predictions, we achieved a slight improvement on validation performance. Additionally, we also modified the input image for different predictions. Rotating and reflecting the input image appears visually different for neural networks. We achieved 32 separate predictions for every frame by training four models and applying eight rotation and reflection transformations on the input. We merged these individual predictions by averaging the probability predictions. This consensus modality improved the ROC area under the curve (AUC) from 0.975 to 0.978. We attempted other approaches for merging the 32 predictions, including selecting the max value or applying a vote (median prediction). Averaging the prediction probabilities achieved the best performance (<xref ref-type="fig" rid="fig3s3">Figure 3—figure supplement 3A</xref>). Finally, we applied a temporal smoothing filter over 46 frames of prediction. We identified 46 frames to be the optimal window for a rolling average (<xref ref-type="fig" rid="fig3s3">Figure 3—figure supplement 3B</xref>), which results in a final accuracy of 93.7% (ROC AUC of 0.984).</p><p>Our network can only make predictions using half a second worth of information. To ensure our validation performance is indicative of the wide diversity of mouse strains, we investigated the extremes of grooming bout predictions in our large strain survey data set which was not annotated by humans. While most of the long bout (&gt;2 min) predictions were real, there were some false positives in which the mouse was resting in a grooming-like posture. To mitigate these rare false positives, we implemented a heuristic to adjust predictions. We experimentally identified that grooming motion typically causes ellipse-fit shape changes (W/L) to have a standard deviation greater than <inline-formula><mml:math id="inf1"><mml:mrow><mml:mn>2.5</mml:mn><mml:mo>×</mml:mo><mml:msup><mml:mn>10</mml:mn><mml:mrow><mml:mo>-</mml:mo><mml:mn>4</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:math></inline-formula>. When a mouse is resting, the shape changes (W/L) standard deviation does not exceed <inline-formula><mml:math id="inf2"><mml:mrow><mml:mn>2</mml:mn><mml:mo>×</mml:mo><mml:msup><mml:mn>10</mml:mn><mml:mrow><mml:mo>-</mml:mo><mml:mn>5</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:math></inline-formula>. Knowing that a mouse’s posture in resting may be visually similar to a grooming posture, we assigned predictions in time segments where the standard deviation of shape change (W/L) over a 31 frame window was less than <inline-formula><mml:math id="inf3"><mml:mrow><mml:mn>5</mml:mn><mml:mo>×</mml:mo><mml:msup><mml:mn>10</mml:mn><mml:mrow><mml:mo>-</mml:mo><mml:mn>5</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:math></inline-formula> to a ‘not grooming’ prediction. Of all the frames in this difficult to annotate posture, 12% were classified as grooming. This suggests that this is not a failure case for our network, but rather a limitation of the network when only using half a second worth of information to make a prediction.</p><p>This approach handled varying mouse postures and physical appearance well, e.g. coat color and body weight. We observed good performance over a wide variety of postures and coat colors (<xref ref-type="fig" rid="fig3">Figure 3C–D</xref>, <xref ref-type="video" rid="fig3video1">Figure 3—videos 1</xref>–<xref ref-type="video" rid="fig3video9">9</xref>). Even nude mice, which have a drastically different appearance than other mice, achieved good performance. Visually, we observed instances where a small number of frame orientations and models make incorrect predictions. Despite this, the consensus classifier made the correct prediction.</p></sec><sec id="s2-4"><title>Definition of grooming behavioral metrics</title><p>We designed a variety of grooming behavioral metrics that describe both grooming quantity and grooming pattern. Following prior work (<xref ref-type="bibr" rid="bib32">Kalueff et al., 2010</xref>), we defined a single grooming bout as continuous time spent grooming without interruption that exceeds 3 s. We allowed brief pauses (less than 10 s), but did not allow any locomotor activity for this merging of time segments spent grooming. Specifically, a pause occurred when motion of the mouse did not exceed twice its average body length. From this, we obtained a grooming ethogram for each mouse (<xref ref-type="fig" rid="fig4">Figure 4A</xref>). Using the ethogram, we summed the total duration of grooming calls in all grooming bouts to calculate the total duration of grooming.</p><fig id="fig4" position="float"><label>Figure 4.</label><caption><title>Grooming and open field behavioral metrics.</title><p>(<bold>A</bold>) Example grooming ethogram for a single animal. Time is on the x-axis and a blue colored bar signifies that the animal was performing grooming behavior during that time. We calculated summaries at 5, 20, and 55 min ranges. (<bold>B</bold>) A visual description of how we define our grooming pattern phenotypes. (<bold>C</bold>) A table summarizing the 24 behavioral metrics we analyzed. We grouped the phenotypes into four groups, including grooming quantity, grooming pattern, open field anxiety, and open field activity.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-63207-fig4-v2.tif"/></fig><p>Once we had the number of bouts and total duration, we calculated the average bout duration by dividing the two. For measurement purposes, we calculated the 5 min, 20 min, and 55 min summaries of these measurements. We included 5 and 20 min because these are typical open field assay durations.</p><p>Using 1 min binned data, we calculated a variety of grooming pattern metrics (<xref ref-type="fig" rid="fig4">Figure 4B</xref>). We fitted a linear slope to discover temporal patterning of grooming during the 55 min assay (GrTimeSlope55min). Positive slopes for total grooming duration infer that the individual mouse is increasing its time spent grooming the longer it remains in the open field test. Negative slopes for total grooming duration infer that the mouse spends more time grooming at the start of the open field test than at the end. This is typically due to the mouse choosing to spend more time doing another activity over grooming, such as sleeping. Positive slopes for number of bouts inferred that the mouse is initiating more grooming bouts the longer it remains in the open field test. Using 5 min binned data, we designed additional metrics to describe grooming pattern by selecting which 5 min bin a mouse spent the most time grooming (GrPeakMidBin) and the time duration spent grooming (GrPeakVal) in that minute. We also calculated a ratio between these values (GrPeakSlope). Finally, when we looked at strain-level averages of grooming, we identified how long a strain remains at its peak grooming (GrPeakLength).</p><p>We compared a variety of open field measurements including both grooming behavior and classical open field measurements (<xref ref-type="fig" rid="fig4">Figure 4C</xref>). We separated these 24 phenotypes into four groups. Grooming quantity describes how much an animal grooms, while grooming pattern metrics describe how an animal changes its grooming behavior over time. Open field anxiety measurements are traditional phenotypic measurements that have been validated to measure anxiety. Open field activity describes the general activity level of an animal.</p></sec><sec id="s2-5"><title>Sex and environment covariate analysis of grooming behavior</title><p>With this trained classifier, we sought to determine whether sex and environment affected grooming behavior in an open field, specifically grooming duration. We used data collected over 29 months for two strains, C57BL/6J and C57BL/6NJ to carry out this analysis. These two strains are substrains that were identical in 1951 and are two of the most widely used strains in mouse studies (<xref ref-type="bibr" rid="bib12">Bryant et al., 2018</xref>). C57BL/6J is the mouse reference strain and C57BL/6NJ has been used by the International Mouse Phenotyping Consortium (IMPC) to generate a large amount of phenotypic data (<xref ref-type="bibr" rid="bib11">Brown and Moore, 2012</xref>). We analyzed 775 C57BL/6J (317F, 458M) and 563 C57BL/6NJ (240F, 323M) mice tested over a wide variety of experimental conditions and ages. Across all these novel exposures in an open field, we quantified their grooming behavior for the first 30 min (<xref ref-type="fig" rid="fig5">Figure 5</xref>, 669 hr total data). We analyzed the data for effect of sex, season, time of day, age, room origin of the mice, light levels, tester, and white noise. To achieve this, we applied a stepwise linear model selection to model these covariates. Both forward and backward model selection results matched. After identifying significant covariates, we applied a second round of model selection that included sex interaction terms. The model selection identified sex, strain, room of origin, time of day, and season as significant. In contrast, age, weight, presence of white noise, and tester were not significant under our testing conditions. Additionally, the interaction between sex and both room of origin and season were identified as significant covariates.</p><fig id="fig5" position="float"><label>Figure 5.</label><caption><title>Sex and environmental covariate analysis of grooming behavior (total time grooming) in the open field for C57BL/6J and C57BL/6NJ strains.</title><p>Effect of sex (<bold>A</bold>), season (<bold>B</bold>), time of day (<bold>C</bold>), age (<bold>D</bold>), room of origin (<bold>E</bold>), light level (<bold>F</bold>), tester (<bold>G</bold>), and white noise (<bold>H</bold>).</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-63207-fig5-v2.tif"/></fig><p><table-wrap id="inlinetable1" position="anchor"><table frame="hsides" rules="groups"><thead><tr><th>Covariate</th><th>p-value</th></tr></thead><tbody><tr><td>Sex</td><td>&lt;2.2 × 10<sup>−16</sup> ***</td></tr><tr><td>Strain</td><td>0.0267546 *</td></tr><tr><td>RoomOrigin</td><td>5.357 × 10<sup>−13</sup> ***</td></tr><tr><td>Morning</td><td>0.0001506 ***</td></tr><tr><td>Season</td><td>0.0039826 **</td></tr><tr><td>Sex by RoomOrigin</td><td>0.0001568 ***</td></tr><tr><td>Sex by Season</td><td>0.0235954 *</td></tr></tbody></table></table-wrap></p><p>We found an effect of strain (<xref ref-type="fig" rid="fig5">Figure 5A</xref>, <inline-formula><mml:math id="inf4"><mml:mrow><mml:mi>p</mml:mi><mml:mo>=</mml:mo><mml:mn>0.0268</mml:mn></mml:mrow></mml:math></inline-formula> C57BL/6J vs C57BL/6NJ) on grooming duration. Although the effect size was small, C57BL/6NJ groomed more than C57BL/6J. Additionally, we observed a sex difference (<xref ref-type="fig" rid="fig5">Figure 5A</xref>, <inline-formula><mml:math id="inf5"><mml:mrow><mml:mi>p</mml:mi><mml:mo>&lt;</mml:mo><mml:mrow><mml:mn>2.2</mml:mn><mml:mo>×</mml:mo><mml:msup><mml:mn>10</mml:mn><mml:mrow><mml:mo>-</mml:mo><mml:mn>16</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:mrow></mml:math></inline-formula> males vs females). Males groomed more than females in both strains.</p><p>Since sex had a strong effect, we included interaction terms with other covariates in a second pass of our model selection. The model identified season as a significant covariate (<xref ref-type="fig" rid="fig5">Figure 5B</xref>, <inline-formula><mml:math id="inf6"><mml:mrow><mml:mi>p</mml:mi><mml:mo>=</mml:mo><mml:mn>0.004</mml:mn></mml:mrow></mml:math></inline-formula>). Surprisingly, the model also identified an interaction between sex and season (<inline-formula><mml:math id="inf7"><mml:mrow><mml:mi>p</mml:mi><mml:mo>=</mml:mo><mml:mn>0.024</mml:mn></mml:mrow></mml:math></inline-formula>). Female mice for both strains showed an increase in grooming during the summer and a decrease in the winter.</p><p>We carried out testing between 8AM and 4PM. To determine if the time of test affects grooming behavior, we split the data into two groups: morning (8am to noon) and afternoon (noon to 4pm). We observed a clear effect of time of day (<xref ref-type="fig" rid="fig5">Figure 5C</xref>, <inline-formula><mml:math id="inf8"><mml:mrow><mml:mi>p</mml:mi><mml:mo>=</mml:mo><mml:mn>0.00015</mml:mn></mml:mrow></mml:math></inline-formula>). Mice tested in the morning groom more overall. We tested mice of different ages, ranging from 6 weeks to 26 weeks old. At the beginning of every test, we weighed the mice and found them to have a range of 16–42 g. We did not observe any significant effect of age (<xref ref-type="fig" rid="fig5">Figure 5D</xref>, <inline-formula><mml:math id="inf9"><mml:mrow><mml:mi>r</mml:mi><mml:mo>=</mml:mo><mml:mrow><mml:mo>-</mml:mo><mml:mn>0.065</mml:mn></mml:mrow></mml:mrow></mml:math></inline-formula>, <inline-formula><mml:math id="inf10"><mml:mrow><mml:mi>p</mml:mi><mml:mo>=</mml:mo><mml:mn>0.119</mml:mn></mml:mrow></mml:math></inline-formula>) or body weight (<inline-formula><mml:math id="inf11"><mml:mrow><mml:mi>r</mml:mi><mml:mo>=</mml:mo><mml:mn>0.206</mml:mn></mml:mrow></mml:math></inline-formula>, <inline-formula><mml:math id="inf12"><mml:mrow><mml:mi>p</mml:mi><mml:mo>=</mml:mo><mml:mn>0.289</mml:mn></mml:mrow></mml:math></inline-formula>) on grooming duration, although we did not test ‘old’ mice, generally considered to be more than 18 months old.</p><p>We compared the grooming levels of mice that were shipped from production rooms in a nearby building at our institution to our testing room with mice bred and raised in a room adjacent to the testing room (B2B). These production rooms contain a variety of possible confounding variables such as microbiome, noise, and technician-related stress. We specifically note that these room differences should not be due to genetic drift because of JAX’s Genetic Stability Program , which periodically re-derives the strain from frozen embryos (<xref ref-type="bibr" rid="bib60">Taft et al., 2006</xref>). Six production rooms supplied exclusively C57BL/6J (AX4, AX29, AX1, MP23, MP14, MP15), three rooms supplied exclusively C57BL/6NJ (MP13, MP16, AX5), and one room supplied both strains (AX8). All shipped mice were housed in B2B for at least a week prior to testing. We observed a significant effect for room of origin (<xref ref-type="fig" rid="fig5">Figure 5E</xref>, <inline-formula><mml:math id="inf13"><mml:mrow><mml:mi>p</mml:mi><mml:mo>=</mml:mo><mml:mrow><mml:mn>5.357</mml:mn><mml:mo>×</mml:mo><mml:msup><mml:mn>10</mml:mn><mml:mrow><mml:mo>-</mml:mo><mml:mn>13</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:mrow></mml:math></inline-formula>). For instance, C57BL/6J males from AX4 and AX29 were low groomers compared to other rooms, including B2B. Shipped C57BL/6NJ from all rooms seemed to have low levels of grooming compared with B2B. We conclude that room of origin and shipping can both have effects on grooming behaviors.</p><p>We tested two light levels, 350–450 lux and 500–600 lux white light (5600K). We observed significant effects of light levels on grooming behavior (<xref ref-type="fig" rid="fig5">Figure 5F</xref>, <inline-formula><mml:math id="inf14"><mml:mrow><mml:mi>p</mml:mi><mml:mo>=</mml:mo><mml:mn>0.04873</mml:mn></mml:mrow></mml:math></inline-formula>). Females from both strains groomed more in lower light, however males didn’t seem to be affected. Despite this, our model did not include a light-sex interaction, suggesting that other covariates better account for the visual interaction with sex here.</p><p>The open field assays were carried out by one of two male testers, although the majority of tests were carried out by tester 2. Both testers carefully followed a testing protocol designed to minimize tester variation, which only involves weighing the mouse and placing the mouse into the arena. We observed no significant effect (<xref ref-type="fig" rid="fig5">Figure 5G</xref>, <inline-formula><mml:math id="inf15"><mml:mrow><mml:mi>p</mml:mi><mml:mo>=</mml:mo><mml:mn>0.65718</mml:mn></mml:mrow></mml:math></inline-formula>) between testers.</p><p>Finally, white noise is often added to open field assays in order to create a uniform background noise levels and to mask noise created by the experimenter (<xref ref-type="bibr" rid="bib26">Gould, 2009</xref>). Although the effects of white noise have not been extensively studied in mice, existing data indicate that higher levels of white noise increase ambulation (<xref ref-type="bibr" rid="bib67">Weyers et al., 1994</xref>). We tested the effects of white noise (70 db) on grooming behavior of C57BL/6J and C57BL/6NJ mice and found no significant difference in duration spent grooming. Although there appears to be a stratification present for both C57BL/6J and C57BL/6NJ females, other cofactors better account for this.</p><p>Combined, these results indicate that environmental factors such as season, time of day, and room origin of the mice affect grooming behavior and may serve as environmental confounds in any grooming study. We also investigated age, body weight, light level, tester, and white noise and found these cofactors to not influence grooming behavior under our experimental conditions.</p></sec><sec id="s2-6"><title>Strain differences for grooming behavior</title><p>Next, we used the grooming classifier to carry out a survey of grooming behavior in the inbred mouse. We tested 43 classical laboratory and eight wild derived strains and 11 F1 hybrid mice from The Jackson Laboratory (JAX) mouse production facility. These were tested over a 31-month period and in most cases consisted of a single mouse shipment of mice from JAX production. Other than C57BL/6J and C57BL6/NJ, on average we tested eight males and eight females of an average age of 11 weeks for each strain. Each mouse was tested for 55 min in the open field as previously described (<xref ref-type="bibr" rid="bib22">Geuther et al., 2019</xref>). This data set consisted of 2457 animals and 2252 hr of video. Video data were classified for grooming behavior as well as open field activity and anxiety metrics. Behavior metrics were extracted as described in <xref ref-type="fig" rid="fig4">Figure 4</xref>. In order to visualize the variance in phenotypes, we plotted each animal across all strains with corresponding strain mean and one standard deviation range and ethograms of select strains <xref ref-type="fig" rid="fig6">Figure 6</xref>. We distinguish between classical laboratory strains and wild derived inbred strains.</p><fig-group><fig id="fig6" position="float"><label>Figure 6.</label><caption><title>Strain survey of grooming phenotypes with representative ethograms (2457 animals and 2252 hr of data, each dot represents 55 min of a single animal).</title><p>(<bold>A</bold>) Strain survey results for total grooming time. Strains present a smooth gradient of time spent grooming, with wild derived strains (purple) showing enrichment on the high end. (<bold>B</bold>) Representative ethograms showing strains with high and low total grooming time. (<bold>C</bold>) Strain survey results for the number of grooming bouts. (<bold>D</bold>) Comparative ethograms for two strains with different number of bouts, but similar total time spent grooming. (<bold>E</bold>) Strain survey results for average grooming bout duration. (<bold>F</bold>) Comparative ethograms for two strains with different average bout length, but similar total time spent grooming.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-63207-fig6-v2.tif"/></fig><fig id="fig6s1" position="float" specific-use="child-fig"><label>Figure 6—figure supplement 1.</label><caption><title>Grooming in wild-derived vs. classical inbred lines.</title><p>(<bold>A</bold>) Total grooming time of wild derived and classical strains are significantly different (*p&lt;0.05, Mann-Whitney Test). (<bold>B</bold>) Wild derived lines have significantly longer grooming bouts (**p&lt;0.01, Mann-Whitney Test). In both graphs, BtBR strain is indicated in green.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-63207-fig6-figsupp1-v2.tif"/></fig></fig-group></sec><sec id="s2-7"><title>Grooming amount and pattern in genetically diverse mice</title><p>We observed large continuous variance in total grooming time, average length of grooming bouts, and the number of grooming bouts in the 55 min open field assay (<xref ref-type="fig" rid="fig6">Figure 6</xref>). Total grooming time varied from 2 to 3 min in strains such as 129 × 1/SvJ and BALB/cByJ to 12 min in strains such as SJL/J and PWD/PhJ. Strains such as 129 × 1/SvJ and C57BR/cdJ had less than 10 bouts, whereas MA/MyJ had almost 40 bouts. The bout duration also varied from 5 s to approximately 50 s in BALB/cByJ and PWD/PhJ, respectively. In order to visualize relationships between phenotypes, we created strain mean and 1SD range correlation plots (<xref ref-type="fig" rid="fig7">Figure 7</xref>). There was a positive correlation between the total grooming time and the number of bouts as well as the total grooming time and average bout duration. Overall, strains with high total grooming time had increased number of bouts as well as longer duration of bouts. However, there did not seem to be a relationship between the number of bouts and the average bout duration, implying that the bout lengths stay constant regardless of how many may occur (<xref ref-type="fig" rid="fig7">Figure 7</xref>). In general, C57BL/6J and C57BL6/NJ fall roughly in the middle for classical inbred strains.</p><fig id="fig7" position="float"><label>Figure 7.</label><caption><title>Relatedness of grooming phenotypes.</title><p>Points indicate strain-level means. Lines indicate 1SD. (<bold>A</bold>) Strain survey comparing total grooming time and number of bouts. Wild derived strains and BTBR show enrichment for having high grooming but low bout numbers. (<bold>B</bold>) Strain survey comparing total grooming time and average bout duration. Strains that groom more also tend to have a longer average bout length. (<bold>C</bold>) Strain survey comparing number of bouts to average bout duration.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-63207-fig7-v2.tif"/></fig><p>We investigated the pattern of grooming over time by constructing a rate of change in 5 min bins for each strain (<xref ref-type="fig" rid="fig8">Figure 8</xref>). There appeared to be visual structures in the data, so we used k-means to identify clusters. We identified three clusters of grooming patterns based on total grooming level and relative changes in 5 min binned grooming data (<xref ref-type="fig" rid="fig1s1">Figure 1—figure supplement 1</xref>). Type 1 consists of 13 strains with an ‘inverted U’ grooming pattern. These strains escalate grooming quickly once in the open field, reach a peak, and then start to decrease the amount of grooming, usually leading to a negative overall grooming slope. Often, we find animals from these strains are sleeping by the end of the 55 min open field assay. These strains include both high groomers such as CZECHII/EiJ, MOLF/EiJ, and low groomers such as 129 × 1/SvJ and I/LnJ. Type 2 consists of 12 strains that are high grooming strains and do not reduce grooming by the end of the assay. They reach peak grooming early (e.g. PWD/PhJ, SJL/J and BTBR) or late (e.g. DBA/2J, CBA/J) and then remain at or near this peak level for the remainder of the assay. The defining feature of this group is that a high level of grooming is maintained throughout the assay. Type 3 consists of most of the strains (30) and shows steady increase in grooming until the end of the assay. Overall, the strains in this group are medium-to-low groomers with a constant low positive or flat slope. We conclude that under our experimental conditions there are at least three broad, albeit continuous, classes of observable grooming patterns in the mouse.</p><fig-group><fig id="fig8" position="float"><label>Figure 8.</label><caption><title>Three classes of grooming patterns in the open field revealed by clustering.</title><p>Grooming duration in 5 min bins is shown over the course of the open field experiment (blue line) and data from individual mice (gray points).</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-63207-fig8-v2.tif"/></fig><fig id="fig8s1" position="float" specific-use="child-fig"><label>Figure 8—figure supplement 1.</label><caption><title>K-means clustering of grooming patterns Results from the k-means clustering.</title><p>The first two principal components from this clustering accounts for 81.7% of variance. three clusters were identified.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-63207-fig8-figsupp1-v2.tif"/></fig></fig-group></sec><sec id="s2-8"><title>Wild derived vs. classical strain grooming patterns</title><p>We compared grooming patterns between classical and wild derived laboratory strains. Classical laboratory strains are derived from limited genetic stock originating from Japanese and European mouse fanciers (<xref ref-type="bibr" rid="bib35">Keeler, 1931</xref>; <xref ref-type="bibr" rid="bib45">Morse, 1978</xref>; <xref ref-type="bibr" rid="bib53">Silver, 1995</xref>). Classical laboratory inbred mouse lines represent the genome of <italic>Mus musculus domesticus</italic>(<italic>M.m domesticus</italic>) 95% and <italic>Mus musculus musculus</italic> 5% (<xref ref-type="bibr" rid="bib70">Yang et al., 2011</xref>). New wild derived inbred strains were established specifically to overcome the limited genetic diversity of the classical inbred lines (<xref ref-type="bibr" rid="bib27">Guénet and Bonhomme, 2003</xref>; <xref ref-type="bibr" rid="bib36">Koide et al., 2011</xref>). We observed that most wild derived strains groom for significantly higher duration and have longer average bout length than the classical inbred strains. Five of the highest 16 grooming strains are wild derived (PWD/PhJ, WSB/EiJ, CZECHII/EiJ, MSM/MsJ, MOLF/EiJ in <xref ref-type="fig" rid="fig6">Figure 6A</xref>). The wild derived strains also had significantly longer bouts of grooming, with 6 of 16 longest average grooming bout strains from this group. Both the total grooming time and average bout length were significantly different between classical and wild-derived strains (<xref ref-type="fig" rid="fig1s1">Figure 1—figure supplement 1</xref>). These high grooming strains represent <italic>M.m. domesticus</italic> and <italic>M.M. musculus</italic> subspecies, which are the precursors to classical laboratory strains (<xref ref-type="bibr" rid="bib70">Yang et al., 2011</xref>). These wild derived strains also represent much more of the natural genetic diversity of the mouse populations than the larger number of classical strains we tested. This leads us to conclude that the high levels of grooming seen in the wild derived strains better represent the normal levels of grooming behavior in mice. This implies that low grooming behavior may have been selected for in classical laboratory strains, at least as observed in our experimental conditions.</p></sec><sec id="s2-9"><title>BTBR grooming pattern</title><p>We also closely examined the grooming patterns of the BTBR strain, which has been proposed as a model with certain features of autism spectrum disorder (ASD). ASD is a complex neurodevelopmental disorder leading to repetitive behaviors and deficits in communication and social interaction (<xref ref-type="bibr" rid="bib3">Association, 2013</xref>). Compared to C57BL/6J mice, BTBR have been shown to have high levels of repetitive behavior, low sociability, unusual vocalization, and behavioral inflexibility (<xref ref-type="bibr" rid="bib44">McFarlane et al., 2008</xref>; <xref ref-type="bibr" rid="bib54">Silverman et al., 2010</xref>; <xref ref-type="bibr" rid="bib46">Moy et al., 2007</xref>; <xref ref-type="bibr" rid="bib52">Scattoni et al., 2008</xref>). Repetitive behavior is often assessed by self grooming behavior, and drugs with efficacy in alleviating symptoms of repetitive behavior in ASD also reduce grooming in BTBR mice without affecting overall activity levels, which provides some level of construct validity (<xref ref-type="bibr" rid="bib55">Silverman et al., 2012</xref>; <xref ref-type="bibr" rid="bib1">Amodeo et al., 2017</xref>).</p><p>We found that total grooming time in BTBR is high compared with C57BL/6J but is not exceptionally high compared to all strains (<xref ref-type="fig" rid="fig6">Figure 6</xref>), or even among classical inbred strains. C57BL/6J mice groomed approximately 5 min over a 55 min open field session, whereas BTBR groomed approximately 12 min (<xref ref-type="fig" rid="fig6">Figure 6A</xref>). Several classical inbred strains had similar levels of high grooming, including SJL/J, DBA/1J, and CBA/CaJ. The grooming pattern of BTBR belongs to Type 2 which contains 11 other strains (<xref ref-type="fig" rid="fig8">Figure 8</xref>). One distinguishing factor of BTBR mice is that they have longer average bouts of grooming from an early point in the open field (<xref ref-type="fig" rid="fig6s1">Figure 6—figure supplement 1</xref>). However, again they were not exceptionally high in average bout length measure (<xref ref-type="fig" rid="fig6s1">Figure 6—figure supplement 1</xref>). Strains such as SJL/J,PWD/PhJ, MOLF/EiJ, NZB/BINJ had similar long bouts from an early point. We conclude that BTBR display high levels of grooming with long grooming bouts, however, this behavior is similar to several wild derived and classical laboratory inbred strains and is not exceptional. Since we did not measure social interaction and other salient features of ASD, we do not argue against BTBR as an ASD model. In addition to BTBR, perhaps other strains from the type two group could should be explored as ASD models.</p></sec><sec id="s2-10"><title>Grooming mouse GWAS</title><p>Next we wished to understand the underlying genetic architecture of complex mouse grooming behavior and open field behaviors, and to relate these to human traits. We used the data from the 51 inbred strains and 11 F1 hybrid strains to carry out a genome wide association study (GWAS). We did not include the eight wild derived strains because they are highly divergent and can skew mouse GWAS analysis. We analyzed the 24 phenotypes categorized into four categories – open field activity, anxiety, grooming pattern, and quantity (<xref ref-type="fig" rid="fig4">Figure 4</xref>). We used a linear mixed model (LMM) implemented in Genome-wide Efficient Mixed Model Association (GEMMA) for this analysis in order to control for spurious association due to population structure (<xref ref-type="bibr" rid="bib73">Zhou and Stephens, 2012</xref>). We first calculated heritability of each phenotype by determining the proportion of variance in phenotypes explained by the typed genotypes (PVE) <xref ref-type="fig" rid="fig9">Figure 9A</xref>. Heritability ranged from 6% to 68%, and 22/24 traits have heritability estimates greater than 20%, a reasonable estimate for behavioral traits in mice and humans (<xref ref-type="bibr" rid="bib62">Valdar et al., 2006</xref>; <xref ref-type="bibr" rid="bib9">Bouchard, 2004</xref>), and makes them amenable for GWAS analysis (<xref ref-type="fig" rid="fig9">Figure 9A</xref>).</p><fig-group><fig id="fig9" position="float"><label>Figure 9.</label><caption><title>GWAS analysis of grooming and open field behaviors.</title><p>(<bold>A</bold>) Heritability (PVE) estimates of the computed phenotypes. (<bold>B</bold>) Linkage disequilibrium (LD) blocks size, average genotype correlations for SNPs in different genomic distances. (<bold>C</bold>) GWAS results shown as a Manhattan plot of all of the phenotypes combined, colors are according to peak SNPs clusters (from D), all the SNPs in the same LD block are colored according to the peak SNP. Minimal p-value over all of the phenotypes for each SNP (<bold>D</bold>) Heatmap of all the significant peak SNPs for each. Each row (SNP) is colored according to the assigned cluster in the k-means clustering. The color from k-means cluster is used in C.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-63207-fig9-v2.tif"/></fig><fig id="fig9s1" position="float" specific-use="child-fig"><label>Figure 9—figure supplement 1.</label><caption><title>Manhattan plot for individual phenotypes.</title><p>Linear Mixed Model (LMM) results for each SNP genotype using Wald test, part 1 .</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-63207-fig9-figsupp1-v2.tif"/></fig><fig id="fig9s2" position="float" specific-use="child-fig"><label>Figure 9—figure supplement 2.</label><caption><title>Manhattan plot for individual phenotypes.</title><p>Linear Mixed Model (LMM) results for each SNP genotype using Wald test, part 2 .</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-63207-fig9-figsupp2-v2.tif"/></fig><fig id="fig9s3" position="float" specific-use="child-fig"><label>Figure 9—figure supplement 3.</label><caption><title>Manhattan plot for individual phenotypes.</title><p>Linear Mixed Model (LMM) results for each SNP genotype using Wald test, part 3 .</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-63207-fig9-figsupp3-v2.tif"/></fig><fig id="fig9s4" position="float" specific-use="child-fig"><label>Figure 9—figure supplement 4.</label><caption><title>Manhattan plot for individual phenotypes.</title><p>Linear Mixed Model (LMM) results for each SNP genotype using Wald test, part 4 .</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-63207-fig9-figsupp4-v2.tif"/></fig><fig id="fig9s5" position="float" specific-use="child-fig"><label>Figure 9—figure supplement 5.</label><caption><title>Manhattan plot for individual phenotypes.</title><p>Linear Mixed Model (LMM) results for each SNP genotype using Wald test, part 5 .</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-63207-fig9-figsupp5-v2.tif"/></fig><fig id="fig9s6" position="float" specific-use="child-fig"><label>Figure 9—figure supplement 6.</label><caption><title>Manhattan plot for individual phenotypes.</title><p>Linear Mixed Model (LMM) results for each SNP genotype using Wald test, part 6.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-63207-fig9-figsupp6-v2.tif"/></fig></fig-group><p>We analyzed each phenotype using GEMMA, and considered the resulting Wald test p-value. In order to correct for the multiple SNPs we tested (222,966), and to account for the correlations between SNPs genotypes, we obtained an empirical threshold for the p-values by shuffling the values of one normally distributed phenotype (OFDistTraveled20m) and taking the minimal p-value of each permutation. This process resulted in a p-value threshold of <inline-formula><mml:math id="inf16"><mml:mrow><mml:mn>1.4</mml:mn><mml:mo>×</mml:mo><mml:msup><mml:mn>10</mml:mn><mml:mrow><mml:mo>-</mml:mo><mml:mn>5</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:math></inline-formula> that reflects a corrected p-value of 0.05 (<xref ref-type="bibr" rid="bib5">Belmonte and Yurgelun-Todd, 2001</xref>). We defined quantitative trait loci (QTL) in the following manner: adjacent SNPs that have correlated genotypes (<inline-formula><mml:math id="inf17"><mml:mrow><mml:msup><mml:mi>r</mml:mi><mml:mn>2</mml:mn></mml:msup><mml:mo>≥</mml:mo><mml:mn>0.2</mml:mn></mml:mrow></mml:math></inline-formula>) were clustered together in a greedy way, starting with the SNP with the lowest p-value in the genome, assigning it a locus, adding all correlating SNPs and then moving forward to the next SNP with the lowest p-value until all the significant SNPs are assigned to QTL. The genetic architecture of inbred mouse strains dictates large linkage disequilibrium (LD) blocks (<xref ref-type="fig" rid="fig9">Figure 9B</xref>), resulting in QTL that span millions of base-pairs and contain multiple genes (<xref ref-type="supplementary-material" rid="supp2">Supplementary file 2</xref>).</p><p>GWAS analysis of each phenotype resulted in 2 to 22 QTL (<xref ref-type="fig" rid="fig9s1">Figure 9—figure supplement 1</xref>, <xref ref-type="fig" rid="fig9s2">Figure 9—figure supplement 2</xref>, <xref ref-type="fig" rid="fig9s3">Figure 9—figure supplement 3</xref>, <xref ref-type="fig" rid="fig9s4">Figure 9—figure supplement 4</xref>, <xref ref-type="fig" rid="fig9s5">Figure 9—figure supplement 5</xref>, <xref ref-type="fig" rid="fig9s6">Figure 9—figure supplement 6</xref>). Overall, the open field activity had 15 QTL, anxiety 10, grooming pattern 76 and grooming quantity 51 QTL, leading to 130 QTL combined over all the tested phenotypes (<xref ref-type="fig" rid="fig9">Figure 9C</xref>). We observed pleiotropy with the same loci significantly associated with multiple phenotypes. Pleiotropy is expected since many of our phenotypes are correlated and individual traits may be regulated by similar genetic loci. For instance, we expected pleiotropy for grooming time in 55 and 20 min (GrTime55 and GrTime20) since these are correlated traits. We also expected that some loci regulating open field activity phenotypes may regulate grooming. In order to better understand the pleiotropic structure of our GWAS results, we generated a heat map of significant QTL across all phenotypes. We then clustered these, to find sets of QTL that regulate groups of phenotypes (<xref ref-type="fig" rid="fig9">Figure 9D</xref>). The phenotypes were clustered into five subgroups consisting of grooming pattern (I), open field activity (II), open field anxiety (III), grooming length (IV), and grooming number and amount (V) (<xref ref-type="fig" rid="fig9">Figure 9D</xref> top x-axis). We found seven clusters of QTL that regulate combinations of these phenotypes (<xref ref-type="fig" rid="fig9">Figure 9D</xref> y-axis). For instance, clusters A and G are composed of pleiotropic QTL that regulate grooming length (IV) and grooming time but QTL in cluster G also regulate bout number and amount (V). QTL cluster D regulates open field activity and anxiety phenotypes. Cluster E contains QTL that regulate grooming and open field activity and anxiety phenotypes, but most of the SNPs only have significant p-values for either open field phenotypes or grooming phenotypes but not both, indicating that independent genetic loci are largely responsible for these phenotypes. We colored the associated SNPs in the Manhattan plot (<xref ref-type="fig" rid="fig9">Figure 9C</xref>) with colors to mark one of these seven QTL clusters (<xref ref-type="fig" rid="fig9">Figure 9D</xref>). These clusters ranged from 13 to 35 QTL, with the smallest being cluster F which is mostly pleiotropic for grooming number, and the largest cluster, cluster G, is pleiotropic for most of the grooming related phenotypes.</p><p>These highly pleiotropic genes included several genes known to regulate mammalian grooming, striatal function, neuronal development, and even language. Mammalian Phenotype Ontology Enrichment showed ‘nervous system development’ as the most significant module with 178 genes (<inline-formula><mml:math id="inf18"><mml:mrow><mml:mi>p</mml:mi><mml:mo>=</mml:mo><mml:mrow><mml:mn>7.5</mml:mn><mml:mo>×</mml:mo><mml:msup><mml:mn>10</mml:mn><mml:mrow><mml:mo>-</mml:mo><mml:mn>4</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:mrow></mml:math></inline-formula>) followed by preweaning lethality (<inline-formula><mml:math id="inf19"><mml:mrow><mml:mi>p</mml:mi><mml:mo>=</mml:mo><mml:mrow><mml:mn>3.5</mml:mn><mml:mo>×</mml:mo><mml:msup><mml:mn>10</mml:mn><mml:mrow><mml:mo>-</mml:mo><mml:mn>3</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:mrow></mml:math></inline-formula>, 189 genes) and abnormal embryo development (<inline-formula><mml:math id="inf20"><mml:mrow><mml:mi>p</mml:mi><mml:mo>=</mml:mo><mml:mrow><mml:mn>5.5</mml:mn><mml:mo>×</mml:mo><mml:msup><mml:mn>10</mml:mn><mml:mrow><mml:mo>-</mml:mo><mml:mn>3</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:mrow></mml:math></inline-formula>, 62 genes) (<xref ref-type="supplementary-material" rid="supp2">Supplementary file 2</xref>). We carried out pathway analysis using KEGG and Reactome databases (<xref ref-type="bibr" rid="bib48">Ogris et al., 2016</xref>). This analysis showed 14 disease pathways that are enriched including Parkinson’s (<inline-formula><mml:math id="inf21"><mml:mrow><mml:mn>9.68</mml:mn><mml:mo>×</mml:mo><mml:msup><mml:mn>10</mml:mn><mml:mrow><mml:mo>-</mml:mo><mml:mn>9</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:math></inline-formula>), Huntington’s (<inline-formula><mml:math id="inf22"><mml:mrow><mml:mrow><mml:mn>1.07</mml:mn><mml:mo>×</mml:mo><mml:mn>10</mml:mn></mml:mrow><mml:mo>-</mml:mo><mml:mn>6</mml:mn></mml:mrow></mml:math></inline-formula>), non-alcoholic fatty liver disease (<inline-formula><mml:math id="inf23"><mml:mrow><mml:mn>9.31</mml:mn><mml:mo>×</mml:mo><mml:msup><mml:mn>10</mml:mn><mml:mrow><mml:mo>-</mml:mo><mml:mn>6</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:math></inline-formula>), and Alzheimer’s (<inline-formula><mml:math id="inf24"><mml:mrow><mml:mn>1.15</mml:mn><mml:mo>×</mml:mo><mml:msup><mml:mn>10</mml:mn><mml:mrow><mml:mo>-</mml:mo><mml:mn>5</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:math></inline-formula>) as the most significantly enriched. Enriched pathways included oxidative phosphorylation (<inline-formula><mml:math id="inf25"><mml:mrow><mml:mn>6.42</mml:mn><mml:mo>×</mml:mo><mml:msup><mml:mn>10</mml:mn><mml:mrow><mml:mo>-</mml:mo><mml:mn>8</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:math></inline-formula>), ribosome (0.00000102), RNA transport (0.00000315), and ribosome biogenesis (0.00000465). Reactome enriched pathways included mitochondrial translation termination and elongation (<inline-formula><mml:math id="inf26"><mml:mrow><mml:mn>2.50</mml:mn><mml:mo>×</mml:mo><mml:msup><mml:mn>10</mml:mn><mml:mrow><mml:mo>-</mml:mo><mml:mn>19</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:math></inline-formula> and <inline-formula><mml:math id="inf27"><mml:mrow><mml:mn>5.89</mml:mn><mml:mo>×</mml:mo><mml:msup><mml:mn>10</mml:mn><mml:mrow><mml:mo>-</mml:mo><mml:mn>19</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:math></inline-formula>, respectively), and ubiquitin-specific processing proteases (<inline-formula><mml:math id="inf28"><mml:mrow><mml:mn>1.86</mml:mn><mml:mo>×</mml:mo><mml:msup><mml:mn>10</mml:mn><mml:mrow><mml:mo>-</mml:mo><mml:mn>8</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:math></inline-formula>). The most pleiotropic gene was Sox5 which associated with 11 grooming and open field phenotypes. <italic>Sox5</italic> has been extensively linked to neuronal differentiation, patterning, and stem cell maintenance (<xref ref-type="bibr" rid="bib40">Lefebvre, 2010</xref>). Its dysregulation in humans has been implicated in Lamb-Shaffer syndrome and ASD, both neurodevelopmental disorder (<xref ref-type="bibr" rid="bib38">Kwan, 2013</xref>; <xref ref-type="bibr" rid="bib71">Zawerton et al., 2020</xref>). A total of 102 genes were associated with 10 phenotypes, and 105 genes were associated with nine phenotypes. We limited our analysis to genes with at least six significantly associated phenotypes, resulting in 860 genes. Other genes include <italic>FoxP1</italic>, which has been linked to striatal function and regulation of language (<xref ref-type="bibr" rid="bib10">Bowers and Konopka, 2012</xref>). <italic>Ctnnb1</italic>, a regulator of Wnt signaling, and <italic>Grin2b</italic>, a regulator of glutamate signaling. Combined, this analysis indicated genes known to regulate nervous system function and development, and genes known to regulate neurodegenerative diseases as regulators of grooming and open field behaviors. The GWAS also begins to define the genetic architecture of grooming and open field behaviors in mice.</p></sec><sec id="s2-11"><title>PheWAS</title><p>Finally, we wanted to link genes that are associated with open field and grooming phenotypes in the mouse with human phenotypes. We hypothesized that common underlying genetic and neuronal architectures exist between mouse and human, however, they can give rise to disparate phenotypes in each organism. For example, the misregulation of a pathway in the mouse may lead to over-grooming phenotype but in humans the same pathway perturbation may manifest itself as neuroticism or obsessive compulsive disorder. These relationships between phenotypes can be revealed through identification of common underlying genetic architectures. In order to link human and mouse phenotypes, we carried out PheWAS analysis with the 860 mouse grooming and open field genes with at least 6 degrees of pleiotropy identified in the mouse GWAS. We identified 509 human orthologs out of 860 mouse genes and downloaded PheWAS summary statistics from gwasATLAS. The gwasATLAS (Release 2: v20190117) contains 4756 GWAS from 473 unique studies across 3302 unique traits which are classified into 28 general domains and 192 subchapters obtained from either ICD10 or ICF10 (<xref ref-type="bibr" rid="bib66">Watanabe et al., 2019</xref>). For each human ortholog, we focused on the association in the gwasATLAS Psychiatric domain with gene-level p value ≤ 0.001. We then turned the relationships between genes and psychiatric traits into a weighted bipartite network, where the weight of an edge is represented by the association strength (-log10(p value)) between a gene and a trait. We identified eight gene-phenotype modules within this weighted bipartite networks (<xref ref-type="fig" rid="fig10">Figure 10</xref>). These modules contained between 15 and 32 individual phenotypes and between 41 and 103 genes. At the subchapter level, modules were enriched for temperament and personality phenotypes, mental and behavioral disorders (schizophrenia, bipolar, dementia), addiction (alcohol, tobacco, cannabinoid) obsessive-compulsive disorder, anxiety, and sleep.</p><fig-group><fig id="fig10" position="float"><label>Figure 10.</label><caption><title>Human-Mouse trait relations through weighted bipartite network of PheWAS results.</title><p>We identified 509 human orthologs out of 860 mouse genes and focused on their association with traits in the Psychiatric domain of gwasATLAS with gene-level p value ≤ 0.001. We represented the relationships between these genes and Psychiatric traits by a weighted bipartite network. The width of an edge between a gene node (gray color) and a Psychiatric trait node is proportional to the association strength (-log10(p value)). The size of a node is proportional to the number of associated genes or traits and the color of a trait node corresponds to the subchapter level in the Psychiatric domain. Eight modules were identified and visualized using Gephi 0.9.2 software.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-63207-fig10-v2.tif"/></fig><fig id="fig10s1" position="float" specific-use="child-fig"><label>Figure 10—figure supplement 1.</label><caption><title>Box plot of Simes P values in eight modules.</title><p>Simes test was used to combine the p values of genes to obtain an overall p value for the association of each Psychiatric trait. Box plot showed the distribution of Simes p values in eight modules in <xref ref-type="fig" rid="fig10">Figure 10</xref>.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-63207-fig10-figsupp1-v2.tif"/></fig></fig-group><p>Surprisingly, we found orthologs that show high levels of pleiotropy in mouse GWAS and the resulting human PheWAS. FOXP1 is the most pleiotropic gene with 35 human phenotypic associations, while SOX5 is second with 33 associations. In order to prioritize candidate modules for further research, first, we produced a ranked list of modules by calculating modularity score, which measures the strength of division of a network into modules. The high-ranking modules represent most promising candidates for further research (<xref ref-type="bibr" rid="bib47">Newman and Girvan, 2004</xref>). Modularity scores of the modules ranged from 0.028 (module 8) to 0.103 (module 1). Second, we used Simes’ test to combine the p values of genes to obtain an overall p value for the association with each Psychiatric trait. Then the median of association (-log10(Simes p value)) was calculated in each detected module for prioritization. Using this method, module one again ranked at the top of eight modules (median = 5.29) (<xref ref-type="fig" rid="fig10s1">Figure 10—figure supplement 1</xref>). Module one is primarily composed of temperament and personality phenotypes, including neuroticism, mood swings, and irritability traits. Genes in this module have a high level of pleiotropy in both human PheWAS and mouse GWAS. Eight of the 10 most pleiotropic genes from the PheWAS analysis are in this module. Genes in this module include SOX5 noted above, RANGAP1 with 31 associations, and EP300 with 23 significant human phenotypic associations. In conclusion, PheWAS analysis links conserved genes that regulate mouse grooming and other open field behaviors to human psychiatric phenotypes. These human phenotypes include personality traits, addiction, and schizophrenia. This analysis links mouse and human traits through shared underlying genetics and allows us to prioritize gene modules for future work, while serving as a framework for future analysis.</p></sec></sec><sec id="s3" sec-type="discussion"><title>Discussion</title><p>Grooming is an ethologically conserved, neurobiologically important behavior that is often used as an endophenotype for psychiatric illnesses. It is a prototypical stereotyped, patterned behavior with highly variable posture and temporal length. Tools to automatically quantify behaviors such as grooming are needed by the behavioral research community and can be leveraged to gain insight into other complex behaviors (<xref ref-type="bibr" rid="bib57">Spruijt et al., 1992</xref>; <xref ref-type="bibr" rid="bib32">Kalueff et al., 2010</xref>). We present a neural network approach toward automated vertebrate model organism behavioral classification and ethogram generation that achieves human-level performance. This approach is simple, scalable, and can be carried out using standard open field apparatus, and is expected to be of use to the behavioral neuroscience community. Using this grooming behavior classifier, we analyzed a large data set consisting over 2200 hr of video from dozens of mouse strains. We demonstrated environmental effects on grooming, patterns of grooming behavior in the laboratory mouse, carry out a mouse GWAS, and a human PheWAS to understand the underlying human-relevant genetic architecture of grooming and open field behavior in the laboratory mouse.</p><p>While the machine learning community has implemented a wide variety of solutions for human action detection, few applications have been applied to animal behavior. This may be in part due to the wide availability of human action data sets and the stringent performance requirements for human bio-behavioral research. We observed that the cost of achieving this stringent performance is very high, requiring a large quantity of annotations. More often than not, experimental paradigms are limited by cost to be short or small enough to cost less to allow manual annotation of the data.</p><p>Machine learning approaches have been previously applied to automated annotation of behavioral data. We observed that our 3D convolutional neural network outperforms a JAABA classifier when trained on the same training data set. Our neural network achieved 91.9% true positive rate with a 5% false positive rate while thee JAABA classifier achieved 64.2% true positive rate at a 5% false positive rate. This improvement makes the neural network solution usable for application to biological problems. This improvement is not uniform over all samples but is instead localized to certain types of grooming bouts. This suggests that although the JAABA classifier is powerful, it may be most useful for smaller and more uniform data sets. Experimental paradigms and behaviors with diverse expression will require a more powerful machine learning approach.</p><p>With the grooming classifier, we determined the genetic and environmental factors that regulate this behavior. In a large data set collected over an 18-month period using two reference strains, C57BL/6J and C67BL/6N, we assessed effects on grooming of several fixed and dynamic factors including, sex, strain, age, time of day, season, tester, room origin, white noise, and body weight. All mice were housed in identical conditions for at least a week prior to testing. As expected, we observe strong effects of sex, time of day, and season. In many but not all studies, and not in the present study, tester effects have been observed in the open field in both mice and rats (<xref ref-type="bibr" rid="bib65">Walsh and Cummins, 1976</xref>; <xref ref-type="bibr" rid="bib43">McCall et al., 1969</xref>; <xref ref-type="bibr" rid="bib7">Bohlen et al., 2014</xref>; <xref ref-type="bibr" rid="bib41">Lewejohann et al., 2006</xref>). A recent study demonstrated that male experimenters or even clothes of males elicit stress responses from mice leading to increased thigmotaxis (<xref ref-type="bibr" rid="bib56">Sorge et al., 2014</xref>).</p><p>To our surprise, we found that room of origin had a strong effect on grooming behavior of C57BL/6J and C57BL/6N. We did not see a clear directionality of effect between shipping mice and those bred in an adjacent room, and in some cases the effect size was high (z &gt; 1). We hypothesize that this may be due to room-specific stress which has previously been demonstrated to alter grooming (<xref ref-type="bibr" rid="bib33">Kalueff et al., 2016</xref>). Presumably, all external mice had similar experience of shipping from the production rooms to the testing area where they were housed identically for at least 1 week prior to testing. Thus, the potential differential stress experience was in the room of origin where the mouse was born and held until shipping. It is important to note that this shipping was only across buildings on the same campus, and shipping that involves air freight may have more drastic effects. This is a point of caution for use of grooming behavior as an endophenotype. Although we acclimated shipped mice to at least 1 week in an adjacent holding room prior to testing, a longer acclimation period may be required prior to testing.</p><p>We carried out a large strain survey to characterize and account for genetic diversity in grooming behavior in the laboratory mouse. We found three types of grooming patterns under our test conditions. Type 1 consists of mice that escalate and deescalate grooming within the 55 min open field test. Strains in this group are often sleeping by the end of the assay, indicating a low arousal state toward the end of the assay. We hypothesize that these strains use grooming as a form of successful de-arousal, a behavior that has been previously noted in rats, birds, and apes (<xref ref-type="bibr" rid="bib57">Spruijt et al., 1992</xref>; <xref ref-type="bibr" rid="bib16">Delius, 1970</xref>). Similar to Type 1, Type 2 groomers escalate grooming quickly to reach peak grooming; however, this group does not deescalate grooming during our assay. We hypothesize that these strains need a longer time or may have a deficiency in de-arousal under our test conditions. Type 3 strains escalate for the duration of the assay indicating they have not reached peak grooming under our assay conditions. BTBR is a member of the Type 2 group with prolonged high levels of grooming from an early point, perhaps indicating a hyperaroused state, or an inability to de-arouse. BTBR mice have previously been shown to have high arousal states and altered dopamine function which may lead to the sustained high levels of grooming (<xref ref-type="bibr" rid="bib58">Squillace et al., 2014</xref>). We postulate that other strains in the Type 2 grooming class may also show phenotypic features of ASD, warranting further study of ASD-related phenotypes in these strains.</p><p>Wild derived strains have distinct patterns of grooming compared to classical strains. Wild-derived strains groom significantly more and have longer grooming bouts. In our grooming clustering analysis, most of the wild derived strains belong to Type 1 or 2, where as most classical strains belong in Type 3. In addition to <italic>M.m domesticus</italic>, the wild derived inbred lines we tested represent <italic>M.m musculus, M.m castaneous, and M.m molossinus</italic> subspecies. Even though there are dozens of classical inbred strains, there are approximately 5 million SNPs between any two classical inbred laboratory strains such as C57BL/6J and DBA2J (<xref ref-type="bibr" rid="bib34">Keane et al., 2011</xref>). Indeed, over 97% of the genome of classical strains can be explained by fewer than 10 haplotypes indicating small number of classes within which all strains are identical by descent with respect to a common ancestor (<xref ref-type="bibr" rid="bib70">Yang et al., 2011</xref>). Classical laboratory strains are derived from mouse fanciers in China, Japan and Europe before being co-opted for biomedical research (<xref ref-type="bibr" rid="bib45">Morse, 1978</xref>; <xref ref-type="bibr" rid="bib53">Silver, 1995</xref>). Wild derived inbred strains such as CAST/EiJ and PWK/PhJ have over 17 million SNPs compared to B6J. Thus, the seven wild derived strains we tested represent far more of the genetic diversity present in the natural mouse population than the numerous classical inbred laboratory strains. Behaviors seen in the wild-derived strains are more likely to represent behaviors in the natural mouse population.</p><p>Mouse fanciers breed mice for visual and behavioral distinctiveness, and many exhibit them in competitive shows. Mouse fanciers judge mice on ‘condition and temperament’ and suggest that ‘it is useless to show a mouse rough in coat or in anything but the mouse perfect condition’ (<xref ref-type="bibr" rid="bib15">Davies, 1912</xref>). Much like dogs and horses, the ‘best individuals should be mated together regardless of relationship as long as mice are large, hardy, and free from disease’ (<xref ref-type="bibr" rid="bib15">Davies, 1912</xref>). It is plausible that normal levels of grooming behavior seen in wild mice was considered unhygienic or indicative of parasites such as lice, ticks, fleas, or mites. High grooming could be interpreted as poor condition and would lead the mouse fancier to select mouse strains with low grooming behaviors. This selection could account for low grooming seen in the classical laboratory strains.</p><p>We used the strain survey data to conduct a mouse GWAS which identified 130 QTL that regulates heritable variation in open field and grooming behaviors. We found that the majority of the grooming traits are moderately to highly heritable. A previous study using the BXD recombinant inbred panel identified one significant locus on chromosome four that regulates grooming and open field activity (<xref ref-type="bibr" rid="bib17">Delprato et al., 2017</xref>). We closely analyzed 862 genes in the QTL interval that are highly pleiotropic and find enriched pathways that regulate neuronal development and function. We then associated those intervals to one of seven clusters which regulate combinations of open field and grooming phenotypes. Mouse grooming can be used as a model of human grooming disorders such as tricotillomania; however, grooming is regulated by the basal ganglia and other brain regions and can be used more broadly as an endophenotype for many psychiatric traits, including ASD, schizophrenia, and Parkinson’s (<xref ref-type="bibr" rid="bib33">Kalueff et al., 2016</xref>). We conducted a PheWAS with the highly pleiotropic genes and identified human psychiatric traits that are associated with these genes. This approach allowed us to link mouse and human phenotypes through the underlying genetic architecture. This approach linked human temperament, personality traits, schizophrenia, and bipolar disorder to mouse phenotypes. Future research is needed to definitively link mouse genetic variants to altered behavior. Our GWAS results are a starting point for understanding the genetic architecture of grooming behavior and will require functional studies in the future to assign causation.</p><p>In conclusion, we describe a neural network based machine learning approach for action detection in mice and apply it towards grooming behavior. Using this tool, we characterized grooming behavior and its underlying genetic architecture in the laboratory mouse. Our approach to grooming is simple and can be carried out using standard open field apparatus and should be of use to the behavioral neuroscience community.</p></sec><sec id="s4" sec-type="materials|methods"><title>Materials and methods</title><sec id="s4-1"><title>Animals</title><p>All animals were obtained from The Jackson Laboratory production colonies or bred in a room adjacent to the testing room as previously described (<xref ref-type="bibr" rid="bib22">Geuther et al., 2019</xref>; <xref ref-type="bibr" rid="bib37">Kumar et al., 2011</xref>). Partial data of the strain survey was published previously and reanalyzed for grooming behavior (<xref ref-type="bibr" rid="bib22">Geuther et al., 2019</xref>). All behavioral tests were performed in accordance with approved protocols from The Jackson Laboratory Institutional Animal Care and Use Committee guidelines.</p></sec><sec id="s4-2"><title>Data set annotation</title><p>We selected data to annotate by training a preliminary JAABA classifier for grooming, then clipping video chunks based on predictions for a wide variety of videos. The initial JAABA classifier was trained on 13 short clips that were manually enriched for grooming activity. This classifier is intentionally weak, designed simply to prioritize video clips that would be beneficial to select for annotation. We then applied this weak classifier on a larger library of videos. The video clips are a subset of our previously published dataset and include 157 individual mouse videos that represent 60 different mouse strains (<xref ref-type="bibr" rid="bib22">Geuther et al., 2019</xref>). We clipped video time segments with 150 frames surrounding grooming activity prediction to mitigate chances of a highly imbalanced data set. We generated 1253 video clips which total 2,637,363 frames. Each video had variable duration, depending upon the grooming prediction length. The shortest video clip contains 500 frames, while the longest video clip contains 23,922 frames. The median video clip length is 1348 frames. Also see <xref ref-type="supplementary-material" rid="supp1">Supplementary file 1</xref> for additional annotated dataset metadata.</p><p>From here, we trained seven annotators. From this pool of seven trained annotators, we assigned two annotators to annotate each video clip completely. If there was confusion for a specific frame or sequence of frames, we allowed the annotators to request additional opinions. Annotators were required to provide a ‘Grooming’ or ‘Not Grooming’ annotation for each frame, with the intent that difficult frames to annotate would get different annotations from each annotator. We only train and validate using frames in which annotators agree, which reduces the total frames to 2,487,883.</p></sec><sec id="s4-3"><title>Neural network model</title><p>Our neural network follows a typical feature encoder structure except using 3D convolution and pooling layers instead of 2D. We started with a 16 × 112 × 112 × 1 input video frames, where 16 refers to the time dimension of the input and one refers to the color depth (monochrome). Each convolution layer that we applied is zero-padded to maintain the same height and width dimension. Additionally, each convolution layer is followed by batch normalization and ReLU activation. First, we applied two sequential 3D convolution layers with a kernel size of 3 × 3 × 3 and number of filters of 4. Second, we applied a max pooling layer of shape 2 × 2 × 2 to result in a new tensor shape of 8 × 64 × 64 × 4. We repeated this two 3D convolution and max pool, doubling the filter depth each time, an additional three more times which results in a 1 × 8 × 8 × 32 tensor shape. We applied two final 3D convolutions with a 1 × 3 × 3 kernel size and 64 filter depth, resulting in a 1 × 8 × 8 × 64 tensor shape. Here, we flattened the network to produce a 64 × 64 tensor. After flattening we applied two fully connected layers, each with 128 filter depth, batch normalization, and ReLU activations. Finally, we added one more fully connected layer with only two filter depth and a softmax activation. This final layer was used as the output probabilities for not grooming and grooming predictions for the last of the 16 frames.</p></sec><sec id="s4-4"><title>Neural network training</title><p>We trained four individual neural networks using the same training set and four independent initializations. During training, we randomly sample video chunks from the data set where the final frame contains an annotation where the annotators agree. Since we sample a 16 frame duration, this refers to the 16th frame’s annotation. If a frame selected does not have 15 frames of video earlier, the tensor is padded with 0-initialized frames. We apply random rotations and reflections of the data, achieving an 8x increase in effective data set size. The loss function we use in our network is a categorical cross entropy loss, comparing the softmax prediction from the network to a one-hot vector with the correct classification. We use the Adam optimizer with an initial learning rate of <inline-formula><mml:math id="inf29"><mml:msup><mml:mn>10</mml:mn><mml:mrow><mml:mo>-</mml:mo><mml:mn>5</mml:mn></mml:mrow></mml:msup></mml:math></inline-formula>. We apply a decay schedule of learning rate to halve the learning rate if five epochs persist without validation accuracy increase. We also employ a stop criteria if validation accuracy does not improve by 1% after 10 epochs. During training, we assemble a batch size of 128 example video clips. Typical training would be done after 13–15 epochs, running for 23–25 epochs without additional improvement.</p></sec><sec id="s4-5"><title>JAABA training</title><p>We trained JAABA classifiers using two different approaches. Our first approach was using the guidelines provided by the software developers (JAABA Interactive Training). This involves interactively and iteratively training classifiers. The data selection approach is to annotate some data, then prioritize new annotations where the algorithm is unsure or incorrectly making predictions. We continued this interactive training until the algorithm no longer made improvements in a k-fold cross validation.</p><p>Our second approach was to subset our large annotated data set to fit into JAABA and train on the agreeing annotations. Initially, we attempted to utilize the entire training data set, but our machine did not have enough RAM to handle the entire training data set. The workstation we used contained 96 GB of available RAM. We wrote a custom script to convert our annotation format to populate annotations in a JAABA classifier file. To confirm our data was input correctly, we examined the annotations from within the JAABA interface. Once we created this file, we could simply train the JAABA classification using JAABA’s interface. After training, we applied the model to the validation data set to compare with our neural network models. We repeated this with various sizes of training data sets.</p></sec><sec id="s4-6"><title>Definition of grooming behavioral metrics</title><p>Here, we describe a variety of grooming behavioral metrics that we use in following analyses. Following the approach that has previously been proposed, we define a single grooming bout as a duration of continuous time spent grooming without interruption that exceeds 3 s (<xref ref-type="bibr" rid="bib32">Kalueff et al., 2010</xref>). We allow brief pauses (less than 10 s), but do not allow any locomotor activity for this merging of time segments spent grooming. Specifically, a pause occurs when motion of the mouse does not exceed twice its average body length. In order to reduce the complexity of the data, we summarize the grooming duration, number of bouts, and average bout duration into 1 min segments. In order to have a whole number of bouts per time duration, we assign grooming bouts to the time segment when a bout begins. In rare instances where multiple-minute bouts occur, this allows for a 1 min time segment to contain more than 1 min worth of grooming duration.</p><p>From here, we sum the total duration of grooming calls in all grooming bouts to calculate the total duration of grooming. Note that this excludes un-joined grooming segments less than 3 s duration as they are not considered a bout. Additionally, we count the total number of bouts.</p><p>Once we have the number of bouts and total duration, we calculate the average bout duration by dividing the two. Finally, we bin the data into one minute time segments and fit a linear line to the data. Positive slopes for total grooming duration infer that the individual mouse is increasing its time spent grooming the longer it remains in the open field test. Negative slopes for total grooming duration infer that the mouse spends more time grooming at the start of the open field test than at the end. This is typically due to the mouse choosing to spend more time doing another activity over grooming, such as sleeping. Positive slopes for number of bouts infer that the mouse is initiating more grooming bouts the longer it remains in the open field test.</p><p>For k-means clustering of the behavior across strains, we visually inspected the data and decided three clusters was optimal. We z-score transformed grooming features as inputs to the k-means algorithm to determine cluster membership. Finally, we projected the clusters discovered by the k-means to a 2D space formed by principal components (PC).</p></sec><sec id="s4-7"><title>Data collection and reporting</title><p>Protocols for data collection were previously described in <xref ref-type="bibr" rid="bib22">Geuther et al., 2019</xref>. In brief, each animal was video recorded from a top-down viewpoint for 55 min of novel open field exposure. Imaging parameters were held constant across videos, including camera distance, zoom, frame rate, and background conditions. No power analysis was used sample size for C57BL/6NJ vs C57BL/6J data since this data is longitudinal control data. Power analysis for the strain survey data showed that with 16 animals (8M/8F), we have 80% power to detect a effect size of 1 (Cohen’s d). Outliers in the strain survey were removed when individuals measured a value of <inline-formula><mml:math id="inf30"><mml:mrow><mml:mrow><mml:mi>G</mml:mi><mml:mo>⁢</mml:mo><mml:mi>r</mml:mi><mml:mo>⁢</mml:mo><mml:mi>T</mml:mi><mml:mo>⁢</mml:mo><mml:mi>i</mml:mi><mml:mo>⁢</mml:mo><mml:mi>m</mml:mi><mml:mo>⁢</mml:mo><mml:mi>e</mml:mi><mml:mo>⁢</mml:mo><mml:mn>55</mml:mn><mml:mo>⁢</mml:mo><mml:mi>m</mml:mi></mml:mrow><mml:mo>&lt;</mml:mo><mml:mrow><mml:msub><mml:mi>Q</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>-</mml:mo><mml:mrow><mml:mrow><mml:mn>1.5</mml:mn><mml:mo>*</mml:mo><mml:mi>I</mml:mi></mml:mrow><mml:mo>⁢</mml:mo><mml:mi>Q</mml:mi><mml:mo>⁢</mml:mo><mml:mi>R</mml:mi></mml:mrow></mml:mrow></mml:mrow></mml:math></inline-formula> or <inline-formula><mml:math id="inf31"><mml:mrow><mml:mrow><mml:mi>G</mml:mi><mml:mo>⁢</mml:mo><mml:mi>r</mml:mi><mml:mo>⁢</mml:mo><mml:mi>T</mml:mi><mml:mo>⁢</mml:mo><mml:mi>i</mml:mi><mml:mo>⁢</mml:mo><mml:mi>m</mml:mi><mml:mo>⁢</mml:mo><mml:mi>e</mml:mi><mml:mo>⁢</mml:mo><mml:mn>55</mml:mn><mml:mo>⁢</mml:mo><mml:mi>m</mml:mi></mml:mrow><mml:mo>&gt;</mml:mo><mml:mrow><mml:msub><mml:mi>Q</mml:mi><mml:mn>3</mml:mn></mml:msub><mml:mo>+</mml:mo><mml:mrow><mml:mrow><mml:mn>1.5</mml:mn><mml:mo>*</mml:mo><mml:mi>I</mml:mi></mml:mrow><mml:mo>⁢</mml:mo><mml:mi>Q</mml:mi><mml:mo>⁢</mml:mo><mml:mi>R</mml:mi></mml:mrow></mml:mrow></mml:mrow></mml:math></inline-formula>, where <italic>Q</italic><sub>1</sub> is the first quartile, <italic>Q</italic><sub>3</sub> is the third quartile, and <inline-formula><mml:math id="inf32"><mml:mrow><mml:mi>I</mml:mi><mml:mo>⁢</mml:mo><mml:mi>Q</mml:mi><mml:mo>⁢</mml:mo><mml:mi>R</mml:mi></mml:mrow></mml:math></inline-formula> is the interquartile range.</p><p>All behavioral data will be available in the Mouse Phenome Database (MPD), and code and models will be available in Kumar Lab Github account (<ext-link ext-link-type="uri" xlink:href="https://github.com/KumarLabJax">https://github.com/KumarLabJax</ext-link> and <ext-link ext-link-type="uri" xlink:href="https://www.kumarlab.org/data/">https://www.kumarlab.org/data/</ext-link>).</p></sec><sec id="s4-8"><title>Genome wide association study (GWAS)</title><p>The phenotypes obtained by the machine learning algorithm for several strains were used to study the association between the genome and the strains behavior. A subset of ten individuals from each combination of strain and sex were randomly selected from the tested mice to ensure equal within group sample sizes. The genotypes of the different strains were obtained from the mouse phenome database (<ext-link ext-link-type="uri" xlink:href="https://phenome.jax.org/genotypes">https://phenome.jax.org/genotypes</ext-link>). The Mouse Diversity Array (MDA) genotypes were used, di-allele genomes were deduced from parent genomes. SNPs with at least 10% MAF and at most 5% missing data were used, resulting with 222,967 SNPs out of 470,818 SNPs genotyped in the MDA array. LMM method from the GEMMA software package (<xref ref-type="bibr" rid="bib73">Zhou and Stephens, 2012</xref>) was used for GWAS of each phenotype with the Wald test for computing the p-values. A Leave One Chromosome Out (LOCO) approach was used, each chromosome was tested using a kinship matrix computed using the other chromosomes to avoid proximal contamination. Initial results showed a wide peak in chromosome seven around the Tyr gene, a well-known coat-color locus, across most phenotypes. To control for this phenomenon, the genotype at SNP rs32105080 was used as a covariate when running GEMMA. Sex was also used as a covariate. To evaluate SNP heritability, GEMMA was used without the LOCO approach. The kinship matrix was evaluated using all the SNPs in the genome and GEMMA LMM output of the proportion of variance in phenotypes explained – the PVE and the PVESE were used as chip heritability and its standard error.</p><p>To estimate the LD decay, pairs of SNPs that are at most 2.5 Mbp apart had their genotypes correlation computed using Pearson correlation. The pairs of SNPs were divided into bins according to their distance, each bin size being 5000 bp. The average correlation <inline-formula><mml:math id="inf33"><mml:msup><mml:mi>r</mml:mi><mml:mn>2</mml:mn></mml:msup></mml:math></inline-formula> coefficient of pairs of SNPs in each bin were averaged and plotted against the average SNPs distance and smoothed using loess function. Correlation of <inline-formula><mml:math id="inf34"><mml:mrow><mml:msup><mml:mi>r</mml:mi><mml:mn>2</mml:mn></mml:msup><mml:mo>&gt;</mml:mo><mml:mn>0.2</mml:mn></mml:mrow></mml:math></inline-formula> was set as a threshold for assigning SNPs to the same QTL. QTL were determined by sorting the SNPs according to their p-values, then, for each SNP, determining a locus centered at this SNP by adding other SNPs with high correlation (<inline-formula><mml:math id="inf35"><mml:mrow><mml:msup><mml:mi>r</mml:mi><mml:mn>2</mml:mn></mml:msup><mml:mo>&gt;</mml:mo><mml:mn>0.2</mml:mn></mml:mrow></mml:math></inline-formula>) to the peak SNP. Each locus was limited to 10 Mbp from the initial peak SNP selected upstream and downstream. The peak SNPs were aggregated from all the phenotypes and the p-values were used to cluster the peaks into clusters using the k-means algorithm implemented in R. We repeated k-means clustering for a variety of number of clusters and visually decided that seven clusters was appropriate for this data. The GWAS results of phenotypes in each cluster were combined by taking the minimal p-value of all the phenotypes in each cluster, for each SNP. The entire set of phenotypes was also combined in the same manner.</p><p>The GWAS execution was wrapped in an R package called mouseGWAS available on github: <ext-link ext-link-type="uri" xlink:href="https://github.com/TheJacksonLaboratory/mousegwas">https://github.com/TheJacksonLaboratory/mousegwas</ext-link>; <xref ref-type="bibr" rid="bib23">Geuther, 2021</xref>; copy archived at <ext-link ext-link-type="uri" xlink:href="https://archive.softwareheritage.org/swh:1:dir:07f01d98248b9603c2824c6f947f819eeaad3b18;origin=https://github.com/TheJacksonLaboratory/mousegwas;visit=swh:1:snp:ef547bbb13017e0b6df06750bf7ebd5867e100b0;anchor=swh:1:rev:5d2caac2637da442f4b9648ac1eb1f35bd1136cf/">swh:1:rev:5d2caac2637da442f4b9648ac1eb1f35bd1136cf</ext-link> it also includes a singularity container definition file and a nextflow pipeline for regenerating the results. The command used for generating the results is:<code xml:space="preserve">export GH=https://raw.githubusercontent.com/TheJacksonLaboratory/mousegwas/grooming 
nextflow run TheJacksonLaboratory/mousegwas -r grooming \ 
--yaml $GH/example/grooming_nowild.yaml \ 
--shufyaml $GH/example/grooming_shuffle.yaml \ 
--input $GH/example/grooming_paper_strain_survey_2019_11_21.csv \ 
--outdir grooming_output --addpostp=&quot;--loddrop 0&quot; -profile slurm,singularity.</code></p></sec><sec id="s4-9"><title>Human phenome-wide association study (PheWAS)</title><p>In order to carry out such cross-species association and link the mouse genetic circuit of grooming to human phenotypes, we conducted a phenome-wide association study (PheWAS). First, we identified human orthologs of the 860 mouse grooming and open field genes with at least 6 degrees of pleiotropy. For each human ortholog, we downloaded PheWAS summary statistics from gwasATLAS (<ext-link ext-link-type="uri" xlink:href="https://atlas.ctglab.nl/">https://atlas.ctglab.nl/</ext-link>, release 2: v20190117) (<xref ref-type="bibr" rid="bib66">Watanabe et al., 2019</xref>). We focused on the association in the Psychiatric domain with gene-level p value ≤ 0.001. Second, in order to visualize and cluster these associations, we represented the relationships between genes and psychiatric traits by a weighted bipartite network, in which the width of an edge between a gene node and a Psychiatric trait node is proportional to the association strength (-log10(p value)). The size of a node is proportional to the number of associated genes or traits and the color of a trait node corresponds to the subchapter level in the Psychiatric domain. To identify modules within this network, we applied an improved community detection algorithm for maximizing weighted modularity in weighted bipartite networks (<xref ref-type="bibr" rid="bib19">Dormann and Strauss, 2014</xref>), using bipartite R package (<xref ref-type="bibr" rid="bib18">Dormann et al., 2008</xref>). All the networks were visualized using Gephi 0.9.2 software (<xref ref-type="bibr" rid="bib4">Bastian et al., 2009</xref>).</p></sec></sec></body><back><ack id="ack"><title>Acknowledgements</title><p>We thank Drs. Kristin Branson and Mayank Kabra (Janelia Research Campus) for providing initial directions on the project and help with JAABA. We thank Drs. Greg Carter and Daniel Skelly for critical feedback on the manuscript. We thank members of the Kumar Lab for helpful advice and Taneli Helenius for editing. We thank JAX Information Technology team members Edwardo Zaborowski, Shane Sanders, Rich Brey, David McKenzie, and Jason Macklin for infrastructure support. This work was funded by The Jackson Laboratory Directors Innovation Fund, National Institute of Health DA041668 (NIDA), DA048634 (NIDA), and Brain and Behavioral Foundation Young Investigator Award (VK). This work used the National Science Foundation (NSF) Extreme Science and Engineering Discovery Environment (XSEDE) XStream service at Stanford University through allocation TG-DBS170004 (to VK).</p></ack><sec id="s5" sec-type="additional-information"><title>Additional information</title><fn-group content-type="competing-interest"><title>Competing interests</title><fn fn-type="COI-statement" id="conf1"><p>No competing interests declared</p></fn></fn-group><fn-group content-type="author-contribution"><title>Author contributions</title><fn fn-type="con" id="con1"><p>Conceptualization, Data curation, Software, Formal analysis, Validation, Investigation, Visualization, Methodology, Writing - original draft, Writing - review and editing</p></fn><fn fn-type="con" id="con2"><p>Software, Formal analysis, Validation, Visualization, Methodology, Writing - original draft</p></fn><fn fn-type="con" id="con3"><p>Formal analysis, Investigation, Visualization</p></fn><fn fn-type="con" id="con4"><p>Formal analysis, Investigation</p></fn><fn fn-type="con" id="con5"><p>Formal analysis, Supervision, Methodology, Writing - original draft</p></fn><fn fn-type="con" id="con6"><p>Conceptualization, Supervision, Funding acquisition, Methodology, Writing - original draft, Project administration, Writing - review and editing</p></fn></fn-group><fn-group content-type="ethics-information"><title>Ethics</title><fn fn-type="other"><p>Animal experimentation: All studies were performed in accordance with approved protocols from The Jackson Laboratory Institutional Animal Care and Use Committee guidelines (Animal Protocol Number 14010).</p></fn></fn-group></sec><sec id="s6" sec-type="supplementary-material"><title>Additional files</title><supplementary-material id="supp1"><label>Supplementary file 1.</label><caption><title>Full metadata related to the created annotated dataset.</title><p>Metadata columns includes strain, sex, arena, testing date, weight, training/validation split, animal number, starting frame for clip, duration of clip, clip identity in released dataset, and clip identity referenced in this paper.</p></caption><media mime-subtype="xlsx" mimetype="application" xlink:href="elife-63207-supp1-v2.xlsx"/></supplementary-material><supplementary-material id="supp2"><label>Supplementary file 2.</label><caption><title>Full results of the GWAS and PheWAS.</title></caption><media mime-subtype="zip" mimetype="application" xlink:href="elife-63207-supp2-v2.zip"/></supplementary-material><supplementary-material id="transrepform"><label>Transparent reporting form</label><media mime-subtype="docx" mimetype="application" xlink:href="elife-63207-transrepform-v2.docx"/></supplementary-material></sec><sec id="s7" sec-type="data-availability"><title>Data availability</title><p>The all machine learning datasets are available here: <ext-link ext-link-type="uri" xlink:href="https://www.kumarlab.org/2021/03/11/grooming-behavioral-data/">https://www.kumarlab.org/2021/03/11/grooming-behavioral-data/</ext-link>. The code is available here: <ext-link ext-link-type="uri" xlink:href="https://github.com/KumarLabJax/MouseGrooming">https://github.com/KumarLabJax/MouseGrooming</ext-link> (copy archived at <ext-link ext-link-type="uri" xlink:href="https://archive.softwareheritage.org/swh:1:rev:f18b268d7a4aba4cf7f5aad72ae5438dfdb311cf/">https://archive.softwareheritage.org/swh:1:rev:f18b268d7a4aba4cf7f5aad72ae5438dfdb311cf/</ext-link>). Behavioral data has been deposited into Mouse Phenome Database. The access for this data will be <ext-link ext-link-type="uri" xlink:href="https://mpdpreview.jax.org/projects/Project1051">https://mpdpreview.jax.org/projects/Project1051</ext-link>.</p><p>The following datasets were generated:</p><p><element-citation id="dataset1" publication-type="data" specific-use="isSupplementedBy"><person-group person-group-type="author"><name><surname>Geuther</surname><given-names>BQ</given-names></name></person-group><year iso-8601-date="2021">2021</year><data-title>Mouse Grooming Detection Annotated Dataset</data-title><source>Zenodo</source><pub-id assigning-authority="Zenodo" pub-id-type="doi">10.5281/zenodo.4646088</pub-id></element-citation></p><p><element-citation id="dataset2" publication-type="data" specific-use="isSupplementedBy"><person-group person-group-type="author"><name><surname>Geuther</surname><given-names>BQ</given-names></name></person-group><year iso-8601-date="2021">2021</year><data-title>Grooming Behavioral Strain Survey Data</data-title><source>Mouse Phenome Database</source><pub-id assigning-authority="other" pub-id-type="accession" xlink:href="https://phenome.jax.org/projects/Kumar3">Kumar3</pub-id></element-citation></p></sec><ref-list><title>References</title><ref id="bib1"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Amodeo</surname> <given-names>DA</given-names></name><name><surname>Rivera</surname> <given-names>E</given-names></name><name><surname>Cook</surname> <given-names>EH</given-names></name><name><surname>Sweeney</surname> <given-names>JA</given-names></name><name><surname>Ragozzino</surname> <given-names>ME</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>5HT<sub>2A</sub> receptor blockade in Dorsomedial striatum reduces repetitive behaviors in BTBR mice</article-title><source>Genes, Brain and Behavior</source><volume>16</volume><fpage>342</fpage><lpage>351</lpage><pub-id pub-id-type="doi">10.1111/gbb.12343</pub-id><pub-id pub-id-type="pmid">27717169</pub-id></element-citation></ref><ref id="bib2"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Angermueller</surname> <given-names>C</given-names></name><name><surname>Pärnamaa</surname> <given-names>T</given-names></name><name><surname>Parts</surname> <given-names>L</given-names></name><name><surname>Stegle</surname> <given-names>O</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Deep learning for computational biology</article-title><source>Molecular Systems Biology</source><volume>12</volume><elocation-id>878</elocation-id><pub-id pub-id-type="doi">10.15252/msb.20156651</pub-id><pub-id pub-id-type="pmid">27474269</pub-id></element-citation></ref><ref id="bib3"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Association</surname> <given-names>AP</given-names></name></person-group><year iso-8601-date="2013">2013</year><source>Diagnostic and statistical manual of mental disorders (DSM-5)</source><publisher-name>American Psychiatric Pub</publisher-name></element-citation></ref><ref id="bib4"><element-citation publication-type="confproc"><person-group person-group-type="author"><name><surname>Bastian</surname> <given-names>M</given-names></name><name><surname>Heymann</surname> <given-names>S</given-names></name><name><surname>Jacomy</surname> <given-names>M</given-names></name></person-group><year iso-8601-date="2009">2009</year><article-title>Third international AAAI conference on weblogs and social media</article-title><conf-name>Gephi: An Open Source Software for Exploring and Manipulating Networks</conf-name></element-citation></ref><ref id="bib5"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Belmonte</surname> <given-names>M</given-names></name><name><surname>Yurgelun-Todd</surname> <given-names>D</given-names></name></person-group><year iso-8601-date="2001">2001</year><article-title>Permutation testing made practical for functional magnetic resonance image analysis</article-title><source>IEEE Transactions on Medical Imaging</source><volume>20</volume><fpage>243</fpage><lpage>248</lpage><pub-id pub-id-type="doi">10.1109/42.918475</pub-id><pub-id pub-id-type="pmid">11341714</pub-id></element-citation></ref><ref id="bib6"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Berman</surname> <given-names>GJ</given-names></name><name><surname>Choi</surname> <given-names>DM</given-names></name><name><surname>Bialek</surname> <given-names>W</given-names></name><name><surname>Shaevitz</surname> <given-names>JW</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>Mapping the stereotyped behaviour of freely moving fruit flies</article-title><source>Journal of the Royal Society Interface</source><volume>11</volume><elocation-id>20140672</elocation-id><pub-id pub-id-type="doi">10.1098/rsif.2014.0672</pub-id></element-citation></ref><ref id="bib7"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bohlen</surname> <given-names>M</given-names></name><name><surname>Hayes</surname> <given-names>ER</given-names></name><name><surname>Bohlen</surname> <given-names>B</given-names></name><name><surname>Bailoo</surname> <given-names>JD</given-names></name><name><surname>Crabbe</surname> <given-names>JC</given-names></name><name><surname>Wahlsten</surname> <given-names>D</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>Experimenter effects on behavioral test scores of eight inbred mouse strains under the influence of ethanol</article-title><source>Behavioural Brain Research</source><volume>272</volume><fpage>46</fpage><lpage>54</lpage><pub-id pub-id-type="doi">10.1016/j.bbr.2014.06.017</pub-id><pub-id pub-id-type="pmid">24933191</pub-id></element-citation></ref><ref id="bib8"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bolles</surname> <given-names>RC</given-names></name></person-group><year iso-8601-date="1960">1960</year><article-title>Grooming behavior in the rat</article-title><source>Journal of Comparative and Physiological Psychology</source><volume>53</volume><fpage>306</fpage><lpage>310</lpage><pub-id pub-id-type="doi">10.1037/h0045421</pub-id><pub-id pub-id-type="pmid">13802322</pub-id></element-citation></ref><ref id="bib9"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bouchard</surname> <given-names>TJ</given-names></name></person-group><year iso-8601-date="2004">2004</year><article-title>Genetic influence on human psychological traits</article-title><source>Current Directions in Psychological Science</source><volume>13</volume><fpage>148</fpage><lpage>151</lpage><pub-id pub-id-type="doi">10.1111/j.0963-7214.2004.00295.x</pub-id></element-citation></ref><ref id="bib10"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bowers</surname> <given-names>JM</given-names></name><name><surname>Konopka</surname> <given-names>G</given-names></name></person-group><year iso-8601-date="2012">2012</year><article-title>The role of the FOXP family of transcription factors in ASD</article-title><source>Disease Markers</source><volume>33</volume><fpage>251</fpage><lpage>260</lpage><pub-id pub-id-type="doi">10.1155/2012/456787</pub-id><pub-id pub-id-type="pmid">22960337</pub-id></element-citation></ref><ref id="bib11"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Brown</surname> <given-names>SDM</given-names></name><name><surname>Moore</surname> <given-names>MW</given-names></name></person-group><year iso-8601-date="2012">2012</year><article-title>Towards an encyclopaedia of mammalian gene function: the international mouse phenotyping consortium</article-title><source>Disease Models &amp; Mechanisms</source><volume>5</volume><fpage>289</fpage><lpage>292</lpage><pub-id pub-id-type="doi">10.1242/dmm.009878</pub-id></element-citation></ref><ref id="bib12"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Bryant</surname> <given-names>CD</given-names></name><name><surname>Ferris</surname> <given-names>MT</given-names></name><name><surname>De Villena</surname> <given-names>FP</given-names></name><name><surname>Damaj</surname> <given-names>MI</given-names></name><name><surname>Kumar</surname> <given-names>V</given-names></name><name><surname>Mulligan</surname> <given-names>MK</given-names></name></person-group><year iso-8601-date="2018">2018</year><chapter-title>Reduced complexity cross design for behavioral genetics</chapter-title><person-group person-group-type="editor"><name><surname>Bryant</surname> <given-names>C. D</given-names></name></person-group><source>Molecular-Genetic and Statistical Techniques for Behavioral and Neural Research</source><publisher-name>Elsevier</publisher-name><fpage>165</fpage><lpage>190</lpage><pub-id pub-id-type="doi">10.1016/B978-0-12-804078-2.00008-8</pub-id></element-citation></ref><ref id="bib13"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ching</surname> <given-names>T</given-names></name><name><surname>Himmelstein</surname> <given-names>DS</given-names></name><name><surname>Beaulieu-Jones</surname> <given-names>BK</given-names></name><name><surname>Kalinin</surname> <given-names>AA</given-names></name><name><surname>Do</surname> <given-names>BT</given-names></name><name><surname>Way</surname> <given-names>GP</given-names></name><name><surname>Ferrero</surname> <given-names>E</given-names></name><name><surname>Agapow</surname> <given-names>PM</given-names></name><name><surname>Zietz</surname> <given-names>M</given-names></name><name><surname>Hoffman</surname> <given-names>MM</given-names></name><name><surname>Xie</surname> <given-names>W</given-names></name><name><surname>Rosen</surname> <given-names>GL</given-names></name><name><surname>Lengerich</surname> <given-names>BJ</given-names></name><name><surname>Israeli</surname> <given-names>J</given-names></name><name><surname>Lanchantin</surname> <given-names>J</given-names></name><name><surname>Woloszynek</surname> <given-names>S</given-names></name><name><surname>Carpenter</surname> <given-names>AE</given-names></name><name><surname>Shrikumar</surname> <given-names>A</given-names></name><name><surname>Xu</surname> <given-names>J</given-names></name><name><surname>Cofer</surname> <given-names>EM</given-names></name><name><surname>Lavender</surname> <given-names>CA</given-names></name><name><surname>Turaga</surname> <given-names>SC</given-names></name><name><surname>Alexandari</surname> <given-names>AM</given-names></name><name><surname>Lu</surname> <given-names>Z</given-names></name><name><surname>Harris</surname> <given-names>DJ</given-names></name><name><surname>DeCaprio</surname> <given-names>D</given-names></name><name><surname>Qi</surname> <given-names>Y</given-names></name><name><surname>Kundaje</surname> <given-names>A</given-names></name><name><surname>Peng</surname> <given-names>Y</given-names></name><name><surname>Wiley</surname> <given-names>LK</given-names></name><name><surname>Segler</surname> <given-names>MHS</given-names></name><name><surname>Boca</surname> <given-names>SM</given-names></name><name><surname>Swamidass</surname> <given-names>SJ</given-names></name><name><surname>Huang</surname> <given-names>A</given-names></name><name><surname>Gitter</surname> <given-names>A</given-names></name><name><surname>Greene</surname> <given-names>CS</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>Opportunities and obstacles for deep learning in biology and medicine</article-title><source>Journal of the Royal Society Interface</source><volume>15</volume><elocation-id>20170387</elocation-id><pub-id pub-id-type="doi">10.1098/rsif.2017.0387</pub-id><pub-id pub-id-type="pmid">29618526</pub-id></element-citation></ref><ref id="bib14"><element-citation publication-type="confproc"><person-group person-group-type="author"><name><surname>Choutas</surname> <given-names>V</given-names></name><name><surname>Weinzaepfel</surname> <given-names>P</given-names></name><name><surname>Revaud</surname> <given-names>J</given-names></name><name><surname>Schmid</surname> <given-names>C</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>Potion: pose motion representation for action recognition</article-title><conf-name>Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</conf-name><fpage>7024</fpage><lpage>7033</lpage><pub-id pub-id-type="doi">10.1109/CVPR.2018.00734ff.ffhal-01764222f</pub-id></element-citation></ref><ref id="bib15"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Davies</surname> <given-names>C</given-names></name></person-group><year iso-8601-date="1912">1912</year><source>Fancy Mice: Their Varieties and Management as Pets or for Show, Including the Latest Scientific Information as to Breeding for Colour</source><publisher-name>LU Gill</publisher-name></element-citation></ref><ref id="bib16"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Delius</surname> <given-names>JD</given-names></name></person-group><year iso-8601-date="1970">1970</year><article-title>Irrelevant behaviour, information processing and arousal homeostasis</article-title><source>Psychologische Forschung</source><volume>33</volume><fpage>165</fpage><lpage>188</lpage><pub-id pub-id-type="doi">10.1007/BF00424983</pub-id><pub-id pub-id-type="pmid">5515903</pub-id></element-citation></ref><ref id="bib17"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Delprato</surname> <given-names>A</given-names></name><name><surname>Algéo</surname> <given-names>MP</given-names></name><name><surname>Bonheur</surname> <given-names>B</given-names></name><name><surname>Bubier</surname> <given-names>JA</given-names></name><name><surname>Lu</surname> <given-names>L</given-names></name><name><surname>Williams</surname> <given-names>RW</given-names></name><name><surname>Chesler</surname> <given-names>EJ</given-names></name><name><surname>Crusio</surname> <given-names>WE</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>QTL and systems genetics analysis of mouse grooming and behavioral responses to novelty in an open field</article-title><source>Genes, Brain and Behavior</source><volume>16</volume><fpage>790</fpage><lpage>799</lpage><pub-id pub-id-type="doi">10.1111/gbb.12392</pub-id><pub-id pub-id-type="pmid">28544613</pub-id></element-citation></ref><ref id="bib18"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Dormann</surname> <given-names>CF</given-names></name><name><surname>Gruber</surname> <given-names>B</given-names></name><name><surname>Fruend</surname> <given-names>J</given-names></name></person-group><year iso-8601-date="2008">2008</year><article-title>Introducing the bipartite package: Analysing ecological networks</article-title><source>R News</source><volume>8</volume><fpage>8</fpage><lpage>11</lpage></element-citation></ref><ref id="bib19"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Dormann</surname> <given-names>CF</given-names></name><name><surname>Strauss</surname> <given-names>R</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>A method for detecting modules in quantitative bipartite networks</article-title><source>Methods in Ecology and Evolution</source><volume>5</volume><fpage>90</fpage><lpage>98</lpage><pub-id pub-id-type="doi">10.1111/2041-210X.12139</pub-id></element-citation></ref><ref id="bib20"><element-citation publication-type="confproc"><person-group person-group-type="author"><name><surname>Feichtenhofer</surname> <given-names>C</given-names></name><name><surname>Fan</surname> <given-names>H</given-names></name><name><surname>Malik</surname> <given-names>J</given-names></name><name><surname>He</surname> <given-names>K</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>Slowfast networks for video recognition</article-title><conf-name>Proceedings of the IEEE International Conference on Computer Vision</conf-name><fpage>6202</fpage><lpage>6211</lpage><pub-id pub-id-type="doi">10.1109/ICCV.2019.00630</pub-id></element-citation></ref><ref id="bib21"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Fentress</surname> <given-names>JC</given-names></name></person-group><year iso-8601-date="1988">1988</year><article-title>Expressive contexts, fine structure, and central mediation of rodent grooming</article-title><source>Annals of the New York Academy of Sciences</source><volume>525</volume><fpage>18</fpage><lpage>26</lpage><pub-id pub-id-type="doi">10.1111/j.1749-6632.1988.tb38592.x</pub-id><pub-id pub-id-type="pmid">3291664</pub-id></element-citation></ref><ref id="bib22"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Geuther</surname> <given-names>BQ</given-names></name><name><surname>Deats</surname> <given-names>SP</given-names></name><name><surname>Fox</surname> <given-names>KJ</given-names></name><name><surname>Murray</surname> <given-names>SA</given-names></name><name><surname>Braun</surname> <given-names>RE</given-names></name><name><surname>White</surname> <given-names>JK</given-names></name><name><surname>Chesler</surname> <given-names>EJ</given-names></name><name><surname>Lutz</surname> <given-names>CM</given-names></name><name><surname>Kumar</surname> <given-names>V</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>Robust mouse tracking in complex environments using neural networks</article-title><source>Communications Biology</source><volume>2</volume><elocation-id>124</elocation-id><pub-id pub-id-type="doi">10.1038/s42003-019-0362-1</pub-id><pub-id pub-id-type="pmid">30937403</pub-id></element-citation></ref><ref id="bib23"><element-citation publication-type="software"><person-group person-group-type="author"><name><surname>Geuther</surname> <given-names>B</given-names></name></person-group><year iso-8601-date="2021">2021</year><data-title>mousegwas</data-title><source>Software Heritage</source><version designator="swh:1:rev:5d2caac2637da442f4b9648ac1eb1f35bd1136cf">swh:1:rev:5d2caac2637da442f4b9648ac1eb1f35bd1136cf</version><ext-link ext-link-type="uri" xlink:href="https://archive.softwareheritage.org/swh:1:dir:07f01d98248b9603c2824c6f947f819eeaad3b18;origin=https://github.com/TheJacksonLaboratory/mousegwas;visit=swh:1:snp:ef547bbb13017e0b6df06750bf7ebd5867e100b0;anchor=swh:1:rev:5d2caac2637da442f4b9648ac1eb1f35bd1136cf/">https://archive.softwareheritage.org/swh:1:dir:07f01d98248b9603c2824c6f947f819eeaad3b18;origin=https://github.com/TheJacksonLaboratory/mousegwas;visit=swh:1:snp:ef547bbb13017e0b6df06750bf7ebd5867e100b0;anchor=swh:1:rev:5d2caac2637da442f4b9648ac1eb1f35bd1136cf/</ext-link></element-citation></ref><ref id="bib24"><element-citation publication-type="confproc"><person-group person-group-type="author"><name><surname>Girdhar</surname> <given-names>R</given-names></name><name><surname>Carreira</surname> <given-names>J</given-names></name><name><surname>Doersch</surname> <given-names>C</given-names></name><name><surname>Zisserman</surname> <given-names>A</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>Video action transformer network</article-title><conf-name>Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</conf-name><fpage>244</fpage><lpage>253</lpage><pub-id pub-id-type="doi">10.1109/CVPR.2019.00033</pub-id></element-citation></ref><ref id="bib25"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Gomez-Marin</surname> <given-names>A</given-names></name><name><surname>Paton</surname> <given-names>JJ</given-names></name><name><surname>Kampff</surname> <given-names>AR</given-names></name><name><surname>Costa</surname> <given-names>RM</given-names></name><name><surname>Mainen</surname> <given-names>ZF</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>Big behavioral data: psychology, ethology and the foundations of neuroscience</article-title><source>Nature Neuroscience</source><volume>17</volume><fpage>1455</fpage><lpage>1462</lpage><pub-id pub-id-type="doi">10.1038/nn.3812</pub-id><pub-id pub-id-type="pmid">25349912</pub-id></element-citation></ref><ref id="bib26"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Gould</surname> <given-names>T</given-names></name></person-group><year iso-8601-date="2009">2009</year><source>Mood and Anxiety Related Phenotypes in Mice</source><publisher-name>Humana Press</publisher-name><pub-id pub-id-type="doi">10.1007/978-1-60761-303-9</pub-id></element-citation></ref><ref id="bib27"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Guénet</surname> <given-names>JL</given-names></name><name><surname>Bonhomme</surname> <given-names>F</given-names></name></person-group><year iso-8601-date="2003">2003</year><article-title>Wild mice: an ever-increasing contribution to a popular mammalian model</article-title><source>Trends in Genetics</source><volume>19</volume><fpage>24</fpage><lpage>31</lpage><pub-id pub-id-type="doi">10.1016/S0168-9525(02)00007-0</pub-id><pub-id pub-id-type="pmid">12493245</pub-id></element-citation></ref><ref id="bib28"><element-citation publication-type="confproc"><person-group person-group-type="author"><name><surname>Heilbron</surname> <given-names>FC</given-names></name><name><surname>Victor Escorcia</surname> <given-names>BG</given-names></name><name><surname>Niebles</surname> <given-names>JC</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>Activitynet: a large-scale video benchmark for human activity understanding</article-title><conf-name>Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</conf-name><fpage>961</fpage><lpage>970</lpage><pub-id pub-id-type="doi">10.1109/CVPR.2015.7298698</pub-id></element-citation></ref><ref id="bib29"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hong</surname> <given-names>W</given-names></name><name><surname>Kennedy</surname> <given-names>A</given-names></name><name><surname>Burgos-Artizzu</surname> <given-names>XP</given-names></name><name><surname>Zelikowsky</surname> <given-names>M</given-names></name><name><surname>Navonne</surname> <given-names>SG</given-names></name><name><surname>Perona</surname> <given-names>P</given-names></name><name><surname>Anderson</surname> <given-names>DJ</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>Automated measurement of mouse social behaviors using depth sensing, video tracking, and machine learning</article-title><source>PNAS</source><volume>112</volume><fpage>E5351</fpage><lpage>E5360</lpage><pub-id pub-id-type="doi">10.1073/pnas.1515982112</pub-id><pub-id pub-id-type="pmid">26354123</pub-id></element-citation></ref><ref id="bib30"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kabra</surname> <given-names>M</given-names></name><name><surname>Robie</surname> <given-names>AA</given-names></name><name><surname>Rivera-Alba</surname> <given-names>M</given-names></name><name><surname>Branson</surname> <given-names>S</given-names></name><name><surname>Branson</surname> <given-names>K</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>JAABA: interactive machine learning for automatic annotation of animal behavior</article-title><source>Nature Methods</source><volume>10</volume><fpage>64</fpage><lpage>67</lpage><pub-id pub-id-type="doi">10.1038/nmeth.2281</pub-id><pub-id pub-id-type="pmid">23202433</pub-id></element-citation></ref><ref id="bib31"><element-citation publication-type="confproc"><person-group person-group-type="author"><name><surname>Kalogeiton</surname> <given-names>V</given-names></name><name><surname>Weinzaepfel</surname> <given-names>P</given-names></name><name><surname>Ferrari</surname> <given-names>V</given-names></name><name><surname>Schmid</surname> <given-names>C</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>Action tubelet detector for spatio-temporal action localization</article-title><conf-name>Proceedings of the IEEE International Conference on Computer Vision</conf-name><fpage>4405</fpage><lpage>4413</lpage><pub-id pub-id-type="doi">10.1109/ICCV.2017.472</pub-id></element-citation></ref><ref id="bib32"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Kalueff</surname> <given-names>AV</given-names></name><name><surname>La Porte</surname> <given-names>JL</given-names></name><name><surname>Bergner</surname> <given-names>CL</given-names></name></person-group><year iso-8601-date="2010">2010</year><source>Neurobiology of Grooming Behavior</source><publisher-name>Cambridge University Press</publisher-name><pub-id pub-id-type="doi">10.1017/CBO9780511676109</pub-id></element-citation></ref><ref id="bib33"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kalueff</surname> <given-names>AV</given-names></name><name><surname>Stewart</surname> <given-names>AM</given-names></name><name><surname>Song</surname> <given-names>C</given-names></name><name><surname>Berridge</surname> <given-names>KC</given-names></name><name><surname>Graybiel</surname> <given-names>AM</given-names></name><name><surname>Fentress</surname> <given-names>JC</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Neurobiology of rodent self-grooming and its value for translational neuroscience</article-title><source>Nature Reviews Neuroscience</source><volume>17</volume><fpage>45</fpage><lpage>59</lpage><pub-id pub-id-type="doi">10.1038/nrn.2015.8</pub-id><pub-id pub-id-type="pmid">26675822</pub-id></element-citation></ref><ref id="bib34"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Keane</surname> <given-names>TM</given-names></name><name><surname>Goodstadt</surname> <given-names>L</given-names></name><name><surname>Danecek</surname> <given-names>P</given-names></name><name><surname>White</surname> <given-names>MA</given-names></name><name><surname>Wong</surname> <given-names>K</given-names></name><name><surname>Yalcin</surname> <given-names>B</given-names></name><name><surname>Heger</surname> <given-names>A</given-names></name><name><surname>Agam</surname> <given-names>A</given-names></name><name><surname>Slater</surname> <given-names>G</given-names></name><name><surname>Goodson</surname> <given-names>M</given-names></name><name><surname>Furlotte</surname> <given-names>NA</given-names></name><name><surname>Eskin</surname> <given-names>E</given-names></name><name><surname>Nellåker</surname> <given-names>C</given-names></name><name><surname>Whitley</surname> <given-names>H</given-names></name><name><surname>Cleak</surname> <given-names>J</given-names></name><name><surname>Janowitz</surname> <given-names>D</given-names></name><name><surname>Hernandez-Pliego</surname> <given-names>P</given-names></name><name><surname>Edwards</surname> <given-names>A</given-names></name><name><surname>Belgard</surname> <given-names>TG</given-names></name><name><surname>Oliver</surname> <given-names>PL</given-names></name><name><surname>McIntyre</surname> <given-names>RE</given-names></name><name><surname>Bhomra</surname> <given-names>A</given-names></name><name><surname>Nicod</surname> <given-names>J</given-names></name><name><surname>Gan</surname> <given-names>X</given-names></name><name><surname>Yuan</surname> <given-names>W</given-names></name><name><surname>van der Weyden</surname> <given-names>L</given-names></name><name><surname>Steward</surname> <given-names>CA</given-names></name><name><surname>Bala</surname> <given-names>S</given-names></name><name><surname>Stalker</surname> <given-names>J</given-names></name><name><surname>Mott</surname> <given-names>R</given-names></name><name><surname>Durbin</surname> <given-names>R</given-names></name><name><surname>Jackson</surname> <given-names>IJ</given-names></name><name><surname>Czechanski</surname> <given-names>A</given-names></name><name><surname>Guerra-Assunção</surname> <given-names>JA</given-names></name><name><surname>Donahue</surname> <given-names>LR</given-names></name><name><surname>Reinholdt</surname> <given-names>LG</given-names></name><name><surname>Payseur</surname> <given-names>BA</given-names></name><name><surname>Ponting</surname> <given-names>CP</given-names></name><name><surname>Birney</surname> <given-names>E</given-names></name><name><surname>Flint</surname> <given-names>J</given-names></name><name><surname>Adams</surname> <given-names>DJ</given-names></name></person-group><year iso-8601-date="2011">2011</year><article-title>Mouse genomic variation and its effect on phenotypes and gene regulation</article-title><source>Nature</source><volume>477</volume><fpage>289</fpage><lpage>294</lpage><pub-id pub-id-type="doi">10.1038/nature10413</pub-id><pub-id pub-id-type="pmid">21921910</pub-id></element-citation></ref><ref id="bib35"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Keeler</surname> <given-names>CE</given-names></name></person-group><year iso-8601-date="1931">1931</year><source>Laboratory Mouse: Its Origin, Heredity, and Culture</source><publisher-name>Harvard University Press</publisher-name><pub-id pub-id-type="doi">10.4159/harvard.9780674336988</pub-id></element-citation></ref><ref id="bib36"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Koide</surname> <given-names>T</given-names></name><name><surname>Ikeda</surname> <given-names>K</given-names></name><name><surname>Ogasawara</surname> <given-names>M</given-names></name><name><surname>Shiroishi</surname> <given-names>T</given-names></name><name><surname>Moriwaki</surname> <given-names>K</given-names></name><name><surname>Takahashi</surname> <given-names>A</given-names></name></person-group><year iso-8601-date="2011">2011</year><article-title>A new twist on behavioral genetics by incorporating wild-derived mouse strains</article-title><source>Experimental Animals</source><volume>60</volume><fpage>347</fpage><lpage>354</lpage><pub-id pub-id-type="doi">10.1538/expanim.60.347</pub-id><pub-id pub-id-type="pmid">21791874</pub-id></element-citation></ref><ref id="bib37"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kumar</surname> <given-names>V</given-names></name><name><surname>Kim</surname> <given-names>K</given-names></name><name><surname>Joseph</surname> <given-names>C</given-names></name><name><surname>Thomas</surname> <given-names>LC</given-names></name><name><surname>Hong</surname> <given-names>H</given-names></name><name><surname>Takahashi</surname> <given-names>JS</given-names></name></person-group><year iso-8601-date="2011">2011</year><article-title>Second-generation high-throughput forward genetic screen in mice to isolate subtle behavioral mutants</article-title><source>PNAS</source><volume>108 Suppl 3</volume><fpage>15557</fpage><lpage>15564</lpage><pub-id pub-id-type="doi">10.1073/pnas.1107726108</pub-id><pub-id pub-id-type="pmid">21896739</pub-id></element-citation></ref><ref id="bib38"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Kwan</surname> <given-names>KY</given-names></name></person-group><year iso-8601-date="2013">2013</year><chapter-title>Transcriptional dysregulation of neocortical circuit assembly in asd</chapter-title><person-group person-group-type="editor"><name><surname>Kwan</surname> <given-names>K. Y</given-names></name></person-group><source>International Review of Neurobiology</source><publisher-name>Elsevier</publisher-name><fpage>167</fpage><lpage>205</lpage><pub-id pub-id-type="doi">10.1016/B978-0-12-418700-9.00006-X</pub-id></element-citation></ref><ref id="bib39"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kyzar</surname> <given-names>E</given-names></name><name><surname>Gaikwad</surname> <given-names>S</given-names></name><name><surname>Roth</surname> <given-names>A</given-names></name><name><surname>Green</surname> <given-names>J</given-names></name><name><surname>Pham</surname> <given-names>M</given-names></name><name><surname>Stewart</surname> <given-names>A</given-names></name><name><surname>Liang</surname> <given-names>Y</given-names></name><name><surname>Kobla</surname> <given-names>V</given-names></name><name><surname>Kalueff</surname> <given-names>AV</given-names></name></person-group><year iso-8601-date="2011">2011</year><article-title>Towards high-throughput phenotyping of complex patterned behaviors in rodents: focus on mouse self-grooming and its sequencing</article-title><source>Behavioural Brain Research</source><volume>225</volume><fpage>426</fpage><lpage>431</lpage><pub-id pub-id-type="doi">10.1016/j.bbr.2011.07.052</pub-id><pub-id pub-id-type="pmid">21840343</pub-id></element-citation></ref><ref id="bib40"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Lefebvre</surname> <given-names>V</given-names></name></person-group><year iso-8601-date="2010">2010</year><article-title>The SoxD transcription factors--Sox5, Sox6, and Sox13--are key cell fate modulators</article-title><source>The International Journal of Biochemistry &amp; Cell Biology</source><volume>42</volume><fpage>429</fpage><lpage>432</lpage><pub-id pub-id-type="doi">10.1016/j.biocel.2009.07.016</pub-id><pub-id pub-id-type="pmid">19647094</pub-id></element-citation></ref><ref id="bib41"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Lewejohann</surname> <given-names>L</given-names></name><name><surname>Reinhard</surname> <given-names>C</given-names></name><name><surname>Schrewe</surname> <given-names>A</given-names></name><name><surname>Brandewiede</surname> <given-names>J</given-names></name><name><surname>Haemisch</surname> <given-names>A</given-names></name><name><surname>Görtz</surname> <given-names>N</given-names></name><name><surname>Schachner</surname> <given-names>M</given-names></name><name><surname>Sachser</surname> <given-names>N</given-names></name></person-group><year iso-8601-date="2006">2006</year><article-title>Environmental Bias? effects of housing conditions, laboratory environment and experimenter on behavioral tests</article-title><source>Genes, Brain and Behavior</source><volume>5</volume><fpage>64</fpage><lpage>72</lpage><pub-id pub-id-type="doi">10.1111/j.1601-183X.2005.00140.x</pub-id><pub-id pub-id-type="pmid">16436190</pub-id></element-citation></ref><ref id="bib42"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Mathis</surname> <given-names>A</given-names></name><name><surname>Mamidanna</surname> <given-names>P</given-names></name><name><surname>Cury</surname> <given-names>KM</given-names></name><name><surname>Abe</surname> <given-names>T</given-names></name><name><surname>Murthy</surname> <given-names>VN</given-names></name><name><surname>Mathis</surname> <given-names>MW</given-names></name><name><surname>Bethge</surname> <given-names>M</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>DeepLabCut: markerless pose estimation of user-defined body parts with deep learning</article-title><source>Nature Neuroscience</source><volume>21</volume><fpage>1281</fpage><lpage>1289</lpage><pub-id pub-id-type="doi">10.1038/s41593-018-0209-y</pub-id><pub-id pub-id-type="pmid">30127430</pub-id></element-citation></ref><ref id="bib43"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>McCall</surname> <given-names>RB</given-names></name><name><surname>Lester</surname> <given-names>ML</given-names></name><name><surname>Corter</surname> <given-names>CM</given-names></name></person-group><year iso-8601-date="1969">1969</year><article-title>Caretaker effect in rats</article-title><source>Developmental Psychology</source><volume>1</volume><elocation-id>771</elocation-id><pub-id pub-id-type="doi">10.1037/h0028199</pub-id></element-citation></ref><ref id="bib44"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>McFarlane</surname> <given-names>HG</given-names></name><name><surname>Kusek</surname> <given-names>GK</given-names></name><name><surname>Yang</surname> <given-names>M</given-names></name><name><surname>Phoenix</surname> <given-names>JL</given-names></name><name><surname>Bolivar</surname> <given-names>VJ</given-names></name><name><surname>Crawley</surname> <given-names>JN</given-names></name></person-group><year iso-8601-date="2008">2008</year><article-title>Autism-like behavioral phenotypes in BTBR T tf/J mice</article-title><source>Genes, Brain and Behavior</source><volume>7</volume><fpage>152</fpage><lpage>163</lpage><pub-id pub-id-type="doi">10.1111/j.1601-183X.2007.00330.x</pub-id><pub-id pub-id-type="pmid">17559418</pub-id></element-citation></ref><ref id="bib45"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Morse</surname> <given-names>H</given-names></name></person-group><year iso-8601-date="1978">1978</year><source>Origins of Inbred Mice: Proceedings of a Workshop, Bethesda, Maryland</source><publisher-name>Acad. Press</publisher-name></element-citation></ref><ref id="bib46"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Moy</surname> <given-names>SS</given-names></name><name><surname>Nadler</surname> <given-names>JJ</given-names></name><name><surname>Young</surname> <given-names>NB</given-names></name><name><surname>Perez</surname> <given-names>A</given-names></name><name><surname>Holloway</surname> <given-names>LP</given-names></name><name><surname>Barbaro</surname> <given-names>RP</given-names></name><name><surname>Barbaro</surname> <given-names>JR</given-names></name><name><surname>Wilson</surname> <given-names>LM</given-names></name><name><surname>Threadgill</surname> <given-names>DW</given-names></name><name><surname>Lauder</surname> <given-names>JM</given-names></name><name><surname>Magnuson</surname> <given-names>TR</given-names></name><name><surname>Crawley</surname> <given-names>JN</given-names></name></person-group><year iso-8601-date="2007">2007</year><article-title>Mouse behavioral tasks relevant to autism: phenotypes of 10 inbred strains</article-title><source>Behavioural Brain Research</source><volume>176</volume><fpage>4</fpage><lpage>20</lpage><pub-id pub-id-type="doi">10.1016/j.bbr.2006.07.030</pub-id><pub-id pub-id-type="pmid">16971002</pub-id></element-citation></ref><ref id="bib47"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Newman</surname> <given-names>ME</given-names></name><name><surname>Girvan</surname> <given-names>M</given-names></name></person-group><year iso-8601-date="2004">2004</year><article-title>Finding and evaluating community structure in networks</article-title><source>Physical Review E</source><volume>69</volume><elocation-id>026113</elocation-id><pub-id pub-id-type="doi">10.1103/PhysRevE.69.026113</pub-id><pub-id pub-id-type="pmid">14995526</pub-id></element-citation></ref><ref id="bib48"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ogris</surname> <given-names>C</given-names></name><name><surname>Helleday</surname> <given-names>T</given-names></name><name><surname>Sonnhammer</surname> <given-names>EL</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>PathwAX: a web server for network crosstalk based pathway annotation</article-title><source>Nucleic Acids Research</source><volume>44</volume><fpage>W105</fpage><lpage>W109</lpage><pub-id pub-id-type="doi">10.1093/nar/gkw356</pub-id><pub-id pub-id-type="pmid">27151197</pub-id></element-citation></ref><ref id="bib49"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Pereira</surname> <given-names>TD</given-names></name><name><surname>Aldarondo</surname> <given-names>DE</given-names></name><name><surname>Willmore</surname> <given-names>L</given-names></name><name><surname>Kislin</surname> <given-names>M</given-names></name><name><surname>Wang</surname> <given-names>SS</given-names></name><name><surname>Murthy</surname> <given-names>M</given-names></name><name><surname>Shaevitz</surname> <given-names>JW</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>Fast animal pose estimation using deep neural networks</article-title><source>Nature Methods</source><volume>16</volume><fpage>117</fpage><lpage>125</lpage><pub-id pub-id-type="doi">10.1038/s41592-018-0234-5</pub-id><pub-id pub-id-type="pmid">30573820</pub-id></element-citation></ref><ref id="bib50"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Quinn</surname> <given-names>LP</given-names></name><name><surname>Stean</surname> <given-names>TO</given-names></name><name><surname>Trail</surname> <given-names>B</given-names></name><name><surname>Duxon</surname> <given-names>MS</given-names></name><name><surname>Stratton</surname> <given-names>SC</given-names></name><name><surname>Billinton</surname> <given-names>A</given-names></name><name><surname>Upton</surname> <given-names>N</given-names></name></person-group><year iso-8601-date="2003">2003</year><article-title>LABORAS: initial pharmacological validation of a system allowing continuous monitoring of laboratory rodent behaviour</article-title><source>Journal of Neuroscience Methods</source><volume>130</volume><fpage>83</fpage><lpage>92</lpage><pub-id pub-id-type="doi">10.1016/S0165-0270(03)00227-9</pub-id><pub-id pub-id-type="pmid">14583407</pub-id></element-citation></ref><ref id="bib51"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Robie</surname> <given-names>AA</given-names></name><name><surname>Hirokawa</surname> <given-names>J</given-names></name><name><surname>Edwards</surname> <given-names>AW</given-names></name><name><surname>Umayam</surname> <given-names>LA</given-names></name><name><surname>Lee</surname> <given-names>A</given-names></name><name><surname>Phillips</surname> <given-names>ML</given-names></name><name><surname>Card</surname> <given-names>GM</given-names></name><name><surname>Korff</surname> <given-names>W</given-names></name><name><surname>Rubin</surname> <given-names>GM</given-names></name><name><surname>Simpson</surname> <given-names>JH</given-names></name><name><surname>Reiser</surname> <given-names>MB</given-names></name><name><surname>Branson</surname> <given-names>K</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>Mapping the neural substrates of behavior</article-title><source>Cell</source><volume>170</volume><fpage>393</fpage><lpage>406</lpage><pub-id pub-id-type="doi">10.1016/j.cell.2017.06.032</pub-id><pub-id pub-id-type="pmid">28709004</pub-id></element-citation></ref><ref id="bib52"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Scattoni</surname> <given-names>ML</given-names></name><name><surname>Gandhy</surname> <given-names>SU</given-names></name><name><surname>Ricceri</surname> <given-names>L</given-names></name><name><surname>Crawley</surname> <given-names>JN</given-names></name></person-group><year iso-8601-date="2008">2008</year><article-title>Unusual repertoire of vocalizations in the BTBR T tf/J mouse model of autism</article-title><source>PLOS ONE</source><volume>3</volume><elocation-id>e3067</elocation-id><pub-id pub-id-type="doi">10.1371/journal.pone.0003067</pub-id><pub-id pub-id-type="pmid">18728777</pub-id></element-citation></ref><ref id="bib53"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Silver</surname> <given-names>L</given-names></name></person-group><year iso-8601-date="1995">1995</year><source>Mouse Genetics: Concepts and Applications</source><publisher-name>Oxford University Press</publisher-name><pub-id pub-id-type="doi">10.1017/S001667230003411X</pub-id></element-citation></ref><ref id="bib54"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Silverman</surname> <given-names>JL</given-names></name><name><surname>Tolu</surname> <given-names>SS</given-names></name><name><surname>Barkan</surname> <given-names>CL</given-names></name><name><surname>Crawley</surname> <given-names>JN</given-names></name></person-group><year iso-8601-date="2010">2010</year><article-title>Repetitive self-grooming behavior in the BTBR mouse model of autism is blocked by the mGluR5 antagonist MPEP</article-title><source>Neuropsychopharmacology</source><volume>35</volume><fpage>976</fpage><lpage>989</lpage><pub-id pub-id-type="doi">10.1038/npp.2009.201</pub-id><pub-id pub-id-type="pmid">20032969</pub-id></element-citation></ref><ref id="bib55"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Silverman</surname> <given-names>JL</given-names></name><name><surname>Smith</surname> <given-names>DG</given-names></name><name><surname>Rizzo</surname> <given-names>SJ</given-names></name><name><surname>Karras</surname> <given-names>MN</given-names></name><name><surname>Turner</surname> <given-names>SM</given-names></name><name><surname>Tolu</surname> <given-names>SS</given-names></name><name><surname>Bryce</surname> <given-names>DK</given-names></name><name><surname>Smith</surname> <given-names>DL</given-names></name><name><surname>Fonseca</surname> <given-names>K</given-names></name><name><surname>Ring</surname> <given-names>RH</given-names></name><name><surname>Crawley</surname> <given-names>JN</given-names></name></person-group><year iso-8601-date="2012">2012</year><article-title>Negative allosteric modulation of the mGluR5 receptor reduces repetitive behaviors and rescues social deficits in mouse models of autism</article-title><source>Science Translational Medicine</source><volume>4</volume><elocation-id>131ra51</elocation-id><pub-id pub-id-type="doi">10.1126/scitranslmed.3003501</pub-id><pub-id pub-id-type="pmid">22539775</pub-id></element-citation></ref><ref id="bib56"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Sorge</surname> <given-names>RE</given-names></name><name><surname>Martin</surname> <given-names>LJ</given-names></name><name><surname>Isbester</surname> <given-names>KA</given-names></name><name><surname>Sotocinal</surname> <given-names>SG</given-names></name><name><surname>Rosen</surname> <given-names>S</given-names></name><name><surname>Tuttle</surname> <given-names>AH</given-names></name><name><surname>Wieskopf</surname> <given-names>JS</given-names></name><name><surname>Acland</surname> <given-names>EL</given-names></name><name><surname>Dokova</surname> <given-names>A</given-names></name><name><surname>Kadoura</surname> <given-names>B</given-names></name><name><surname>Leger</surname> <given-names>P</given-names></name><name><surname>Mapplebeck</surname> <given-names>JCS</given-names></name><name><surname>McPhail</surname> <given-names>M</given-names></name><name><surname>Delaney</surname> <given-names>A</given-names></name><name><surname>Wigerblad</surname> <given-names>G</given-names></name><name><surname>Schumann</surname> <given-names>AP</given-names></name><name><surname>Quinn</surname> <given-names>T</given-names></name><name><surname>Frasnelli</surname> <given-names>J</given-names></name><name><surname>Svensson</surname> <given-names>CI</given-names></name><name><surname>Sternberg</surname> <given-names>WF</given-names></name><name><surname>Mogil</surname> <given-names>JS</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>Olfactory exposure to males, including men, causes stress and related analgesia in rodents</article-title><source>Nature Methods</source><volume>11</volume><fpage>629</fpage><lpage>632</lpage><pub-id pub-id-type="doi">10.1038/nmeth.2935</pub-id></element-citation></ref><ref id="bib57"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Spruijt</surname> <given-names>BM</given-names></name><name><surname>van Hooff</surname> <given-names>JA</given-names></name><name><surname>Gispen</surname> <given-names>WH</given-names></name></person-group><year iso-8601-date="1992">1992</year><article-title>Ethology and neurobiology of grooming behavior</article-title><source>Physiological Reviews</source><volume>72</volume><fpage>825</fpage><lpage>852</lpage><pub-id pub-id-type="doi">10.1152/physrev.1992.72.3.825</pub-id><pub-id pub-id-type="pmid">1320764</pub-id></element-citation></ref><ref id="bib58"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Squillace</surname> <given-names>M</given-names></name><name><surname>Dodero</surname> <given-names>L</given-names></name><name><surname>Federici</surname> <given-names>M</given-names></name><name><surname>Migliarini</surname> <given-names>S</given-names></name><name><surname>Errico</surname> <given-names>F</given-names></name><name><surname>Napolitano</surname> <given-names>F</given-names></name><name><surname>Krashia</surname> <given-names>P</given-names></name><name><surname>Di Maio</surname> <given-names>A</given-names></name><name><surname>Galbusera</surname> <given-names>A</given-names></name><name><surname>Bifone</surname> <given-names>A</given-names></name><name><surname>Scattoni</surname> <given-names>ML</given-names></name><name><surname>Pasqualetti</surname> <given-names>M</given-names></name><name><surname>Mercuri</surname> <given-names>NB</given-names></name><name><surname>Usiello</surname> <given-names>A</given-names></name><name><surname>Gozzi</surname> <given-names>A</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>Dysfunctional dopaminergic neurotransmission in asocial BTBR mice</article-title><source>Translational Psychiatry</source><volume>4</volume><elocation-id>e427</elocation-id><pub-id pub-id-type="doi">10.1038/tp.2014.69</pub-id></element-citation></ref><ref id="bib59"><element-citation publication-type="confproc"><person-group person-group-type="author"><name><surname>Sun</surname> <given-names>C</given-names></name><name><surname>Shrivastava</surname> <given-names>C</given-names></name><name><surname>Singh, S</surname> <given-names>A</given-names></name><name><surname>Gupta</surname> <given-names>A</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>Revisiting unreasonable effectiveness of data in deep learning era</article-title><conf-name>Proceedings of the IEEE International Conference on Computer Vision</conf-name><fpage>843</fpage><lpage>852</lpage><pub-id pub-id-type="doi">10.1109/ICCV.2017.97</pub-id></element-citation></ref><ref id="bib60"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Taft</surname> <given-names>RA</given-names></name><name><surname>Davisson</surname> <given-names>M</given-names></name><name><surname>Wiles</surname> <given-names>MV</given-names></name></person-group><year iso-8601-date="2006">2006</year><article-title>Know thy mouse</article-title><source>Trends in Genetics</source><volume>22</volume><fpage>649</fpage><lpage>653</lpage><pub-id pub-id-type="doi">10.1016/j.tig.2006.09.010</pub-id><pub-id pub-id-type="pmid">17007958</pub-id></element-citation></ref><ref id="bib61"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Todd</surname> <given-names>JG</given-names></name><name><surname>Kain</surname> <given-names>JS</given-names></name><name><surname>de Bivort</surname> <given-names>BL</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>Systematic exploration of unsupervised methods for mapping behavior</article-title><source>Physical Biology</source><volume>14</volume><elocation-id>015002</elocation-id><pub-id pub-id-type="doi">10.1088/1478-3975/14/1/015002</pub-id><pub-id pub-id-type="pmid">28166059</pub-id></element-citation></ref><ref id="bib62"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Valdar</surname> <given-names>W</given-names></name><name><surname>Solberg</surname> <given-names>LC</given-names></name><name><surname>Gauguier</surname> <given-names>D</given-names></name><name><surname>Cookson</surname> <given-names>WO</given-names></name><name><surname>Rawlins</surname> <given-names>JN</given-names></name><name><surname>Mott</surname> <given-names>R</given-names></name><name><surname>Flint</surname> <given-names>J</given-names></name></person-group><year iso-8601-date="2006">2006</year><article-title>Genetic and environmental effects on complex traits in mice</article-title><source>Genetics</source><volume>174</volume><fpage>959</fpage><lpage>984</lpage><pub-id pub-id-type="doi">10.1534/genetics.106.060004</pub-id><pub-id pub-id-type="pmid">16888333</pub-id></element-citation></ref><ref id="bib63"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Van de Weerd</surname> <given-names>HA</given-names></name><name><surname>Bulthuis</surname> <given-names>RJ</given-names></name><name><surname>Bergman</surname> <given-names>AF</given-names></name><name><surname>Schlingmann</surname> <given-names>F</given-names></name><name><surname>Tolboom</surname> <given-names>J</given-names></name><name><surname>Van Loo</surname> <given-names>PL</given-names></name><name><surname>Remie</surname> <given-names>R</given-names></name><name><surname>Baumans</surname> <given-names>V</given-names></name><name><surname>Van Zutphen</surname> <given-names>LF</given-names></name></person-group><year iso-8601-date="2001">2001</year><article-title>Validation of a new system for the automatic registration of behaviour in mice and rats</article-title><source>Behavioural Processes</source><volume>53</volume><fpage>11</fpage><lpage>20</lpage><pub-id pub-id-type="doi">10.1016/S0376-6357(00)00135-2</pub-id><pub-id pub-id-type="pmid">11254988</pub-id></element-citation></ref><ref id="bib64"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>van den Boom</surname> <given-names>BJG</given-names></name><name><surname>Pavlidi</surname> <given-names>P</given-names></name><name><surname>Wolf</surname> <given-names>CJH</given-names></name><name><surname>Mooij</surname> <given-names>AH</given-names></name><name><surname>Willuhn</surname> <given-names>I</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>Automated classification of self-grooming in mice using open-source software</article-title><source>Journal of Neuroscience Methods</source><volume>289</volume><fpage>48</fpage><lpage>56</lpage><pub-id pub-id-type="doi">10.1016/j.jneumeth.2017.05.026</pub-id><pub-id pub-id-type="pmid">28648717</pub-id></element-citation></ref><ref id="bib65"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Walsh</surname> <given-names>RN</given-names></name><name><surname>Cummins</surname> <given-names>RA</given-names></name></person-group><year iso-8601-date="1976">1976</year><article-title>The Open-Field test: a critical review</article-title><source>Psychological Bulletin</source><volume>83</volume><fpage>482</fpage><lpage>504</lpage><pub-id pub-id-type="doi">10.1037/0033-2909.83.3.482</pub-id><pub-id pub-id-type="pmid">17582919</pub-id></element-citation></ref><ref id="bib66"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Watanabe</surname> <given-names>K</given-names></name><name><surname>Stringer</surname> <given-names>S</given-names></name><name><surname>Frei</surname> <given-names>O</given-names></name><name><surname>Umićević Mirkov</surname> <given-names>M</given-names></name><name><surname>de Leeuw</surname> <given-names>C</given-names></name><name><surname>Polderman</surname> <given-names>TJC</given-names></name><name><surname>van der Sluis</surname> <given-names>S</given-names></name><name><surname>Andreassen</surname> <given-names>OA</given-names></name><name><surname>Neale</surname> <given-names>BM</given-names></name><name><surname>Posthuma</surname> <given-names>D</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>A global overview of pleiotropy and genetic architecture in complex traits</article-title><source>Nature Genetics</source><volume>51</volume><fpage>1339</fpage><lpage>1348</lpage><pub-id pub-id-type="doi">10.1038/s41588-019-0481-0</pub-id><pub-id pub-id-type="pmid">31427789</pub-id></element-citation></ref><ref id="bib67"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Weyers</surname> <given-names>P</given-names></name><name><surname>Janke</surname> <given-names>W</given-names></name><name><surname>Macht</surname> <given-names>M</given-names></name><name><surname>Weijers</surname> <given-names>HG</given-names></name></person-group><year iso-8601-date="1994">1994</year><article-title>Social and non-social open field behaviour of rats under light and noise stimulation</article-title><source>Behavioural Processes</source><volume>31</volume><fpage>257</fpage><lpage>267</lpage><pub-id pub-id-type="doi">10.1016/0376-6357(94)90011-6</pub-id><pub-id pub-id-type="pmid">24924938</pub-id></element-citation></ref><ref id="bib68"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wiltschko</surname> <given-names>AB</given-names></name><name><surname>Johnson</surname> <given-names>MJ</given-names></name><name><surname>Iurilli</surname> <given-names>G</given-names></name><name><surname>Peterson</surname> <given-names>RE</given-names></name><name><surname>Katon</surname> <given-names>JM</given-names></name><name><surname>Pashkovski</surname> <given-names>SL</given-names></name><name><surname>Abraira</surname> <given-names>VE</given-names></name><name><surname>Adams</surname> <given-names>RP</given-names></name><name><surname>Datta</surname> <given-names>SR</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>Mapping Sub-Second structure in mouse behavior</article-title><source>Neuron</source><volume>88</volume><fpage>1121</fpage><lpage>1135</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2015.11.031</pub-id><pub-id pub-id-type="pmid">26687221</pub-id></element-citation></ref><ref id="bib69"><element-citation publication-type="confproc"><person-group person-group-type="author"><name><surname>Wu</surname> <given-names>D</given-names></name><name><surname>Sharma</surname> <given-names>N</given-names></name><name><surname>Blumenstein</surname> <given-names>M</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>Recent advances in video-based human action recognition using deep learning: a review</article-title><conf-name>IEEE 2017 International Joint Conference on Neural Networks (IJCNN)</conf-name><fpage>2865</fpage><lpage>2872</lpage><pub-id pub-id-type="doi">10.1109/IJCNN.2017.7966210</pub-id></element-citation></ref><ref id="bib70"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Yang</surname> <given-names>H</given-names></name><name><surname>Wang</surname> <given-names>JR</given-names></name><name><surname>Didion</surname> <given-names>JP</given-names></name><name><surname>Buus</surname> <given-names>RJ</given-names></name><name><surname>Bell</surname> <given-names>TA</given-names></name><name><surname>Welsh</surname> <given-names>CE</given-names></name><name><surname>Bonhomme</surname> <given-names>F</given-names></name><name><surname>Yu</surname> <given-names>AH</given-names></name><name><surname>Nachman</surname> <given-names>MW</given-names></name><name><surname>Pialek</surname> <given-names>J</given-names></name><name><surname>Tucker</surname> <given-names>P</given-names></name><name><surname>Boursot</surname> <given-names>P</given-names></name><name><surname>McMillan</surname> <given-names>L</given-names></name><name><surname>Churchill</surname> <given-names>GA</given-names></name><name><surname>de Villena</surname> <given-names>FP</given-names></name></person-group><year iso-8601-date="2011">2011</year><article-title>Subspecific origin and haplotype diversity in the laboratory mouse</article-title><source>Nature Genetics</source><volume>43</volume><fpage>648</fpage><lpage>655</lpage><pub-id pub-id-type="doi">10.1038/ng.847</pub-id><pub-id pub-id-type="pmid">21623374</pub-id></element-citation></ref><ref id="bib71"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Zawerton</surname> <given-names>A</given-names></name><name><surname>Mignot</surname> <given-names>C</given-names></name><name><surname>Sigafoos</surname> <given-names>A</given-names></name><name><surname>Blackburn</surname> <given-names>PR</given-names></name><name><surname>Haseeb</surname> <given-names>A</given-names></name><name><surname>McWalter</surname> <given-names>K</given-names></name><name><surname>Ichikawa</surname> <given-names>S</given-names></name><name><surname>Nava</surname> <given-names>C</given-names></name><name><surname>Keren</surname> <given-names>B</given-names></name><name><surname>Charles</surname> <given-names>P</given-names></name><name><surname>Marey</surname> <given-names>I</given-names></name><name><surname>Tabet</surname> <given-names>AC</given-names></name><name><surname>Levy</surname> <given-names>J</given-names></name><name><surname>Perrin</surname> <given-names>L</given-names></name><name><surname>Hartmann</surname> <given-names>A</given-names></name><name><surname>Lesca</surname> <given-names>G</given-names></name><name><surname>Schluth-Bolard</surname> <given-names>C</given-names></name><name><surname>Monin</surname> <given-names>P</given-names></name><name><surname>Dupuis-Girod</surname> <given-names>S</given-names></name><name><surname>Guillen Sacoto</surname> <given-names>MJ</given-names></name><name><surname>Schnur</surname> <given-names>RE</given-names></name><name><surname>Zhu</surname> <given-names>Z</given-names></name><name><surname>Poisson</surname> <given-names>A</given-names></name><name><surname>El Chehadeh</surname> <given-names>S</given-names></name><name><surname>Alembik</surname> <given-names>Y</given-names></name><name><surname>Bruel</surname> <given-names>AL</given-names></name><name><surname>Lehalle</surname> <given-names>D</given-names></name><name><surname>Nambot</surname> <given-names>S</given-names></name><name><surname>Moutton</surname> <given-names>S</given-names></name><name><surname>Odent</surname> <given-names>S</given-names></name><name><surname>Jaillard</surname> <given-names>S</given-names></name><name><surname>Dubourg</surname> <given-names>C</given-names></name><name><surname>Hilhorst-Hofstee</surname> <given-names>Y</given-names></name><name><surname>Barbaro-Dieber</surname> <given-names>T</given-names></name><name><surname>Ortega</surname> <given-names>L</given-names></name><name><surname>Bhoj</surname> <given-names>EJ</given-names></name><name><surname>Masser-Frye</surname> <given-names>D</given-names></name><name><surname>Bird</surname> <given-names>LM</given-names></name><name><surname>Lindstrom</surname> <given-names>K</given-names></name><name><surname>Ramsey</surname> <given-names>KM</given-names></name><name><surname>Narayanan</surname> <given-names>V</given-names></name><name><surname>Fassi</surname> <given-names>E</given-names></name><name><surname>Willing</surname> <given-names>M</given-names></name><name><surname>Cole</surname> <given-names>T</given-names></name><name><surname>Salter</surname> <given-names>CG</given-names></name><name><surname>Akilapa</surname> <given-names>R</given-names></name><name><surname>Vandersteen</surname> <given-names>A</given-names></name><name><surname>Canham</surname> <given-names>N</given-names></name><name><surname>Rump</surname> <given-names>P</given-names></name><name><surname>Gerkes</surname> <given-names>EH</given-names></name><name><surname>Klein Wassink-Ruiter</surname> <given-names>JS</given-names></name><name><surname>Bijlsma</surname> <given-names>E</given-names></name><name><surname>Hoffer</surname> <given-names>MJV</given-names></name><name><surname>Vargas</surname> <given-names>M</given-names></name><name><surname>Wojcik</surname> <given-names>A</given-names></name><name><surname>Cherik</surname> <given-names>F</given-names></name><name><surname>Francannet</surname> <given-names>C</given-names></name><name><surname>Rosenfeld</surname> <given-names>JA</given-names></name><name><surname>Machol</surname> <given-names>K</given-names></name><name><surname>Scott</surname> <given-names>DA</given-names></name><name><surname>Bacino</surname> <given-names>CA</given-names></name><name><surname>Wang</surname> <given-names>X</given-names></name><name><surname>Clark</surname> <given-names>GD</given-names></name><name><surname>Bertoli</surname> <given-names>M</given-names></name><name><surname>Zwolinski</surname> <given-names>S</given-names></name><name><surname>Thomas</surname> <given-names>RH</given-names></name><name><surname>Akay</surname> <given-names>E</given-names></name><name><surname>Chang</surname> <given-names>RC</given-names></name><name><surname>Bressi</surname> <given-names>R</given-names></name><name><surname>Sanchez Russo</surname> <given-names>R</given-names></name><name><surname>Srour</surname> <given-names>M</given-names></name><name><surname>Russell</surname> <given-names>L</given-names></name><name><surname>Goyette</surname> <given-names>AE</given-names></name><name><surname>Dupuis</surname> <given-names>L</given-names></name><name><surname>Mendoza-Londono</surname> <given-names>R</given-names></name><name><surname>Karimov</surname> <given-names>C</given-names></name><name><surname>Joseph</surname> <given-names>M</given-names></name><name><surname>Nizon</surname> <given-names>M</given-names></name><name><surname>Cogné</surname> <given-names>B</given-names></name><name><surname>Kuechler</surname> <given-names>A</given-names></name><name><surname>Piton</surname> <given-names>A</given-names></name><name><surname>Klee</surname> <given-names>EW</given-names></name><name><surname>Lefebvre</surname> <given-names>V</given-names></name><name><surname>Clark</surname> <given-names>KJ</given-names></name><name><surname>Depienne</surname> <given-names>C</given-names></name><collab>Deciphering Developmental DisorderStudy</collab></person-group><year iso-8601-date="2020">2020</year><article-title>Widening of the genetic and clinical spectrum of Lamb-Shaffer syndrome, a neurodevelopmental disorder due to SOX5 haploinsufficiency</article-title><source>Genetics in Medicine</source><volume>22</volume><fpage>524</fpage><lpage>537</lpage><pub-id pub-id-type="doi">10.1038/s41436-019-0657-0</pub-id><pub-id pub-id-type="pmid">31578471</pub-id></element-citation></ref><ref id="bib72"><element-citation publication-type="preprint"><person-group person-group-type="author"><name><surname>Zhang</surname> <given-names>Y</given-names></name><name><surname>Tokmakov</surname> <given-names>P</given-names></name><name><surname>Hebert</surname> <given-names>M</given-names></name><name><surname>Schmid</surname> <given-names>C</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>A study on action detection in the wild</article-title><source>arXiv</source><ext-link ext-link-type="uri" xlink:href="https://arxiv.org/abs/1904.12993">https://arxiv.org/abs/1904.12993</ext-link></element-citation></ref><ref id="bib73"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Zhou</surname> <given-names>X</given-names></name><name><surname>Stephens</surname> <given-names>M</given-names></name></person-group><year iso-8601-date="2012">2012</year><article-title>Genome-wide efficient mixed-model analysis for association studies</article-title><source>Nature Genetics</source><volume>44</volume><fpage>821</fpage><lpage>824</lpage><pub-id pub-id-type="doi">10.1038/ng.2310</pub-id><pub-id pub-id-type="pmid">22706312</pub-id></element-citation></ref></ref-list></back><sub-article article-type="decision-letter" id="sa1"><front-stub><article-id pub-id-type="doi">10.7554/eLife.63207.sa1</article-id><title-group><article-title>Decision letter</article-title></title-group><contrib-group><contrib contrib-type="editor"><name><surname>Marlin</surname><given-names>Bianca Jones</given-names></name><role>Reviewing Editor</role><aff><institution>Columbia University</institution><country>United States</country></aff></contrib></contrib-group><contrib-group><contrib contrib-type="reviewer"><name><surname>Carcea</surname><given-names>Ioana</given-names> </name><role>Reviewer</role><aff><institution>Rutgers New Jersey Medical Mecdical School</institution><country>United States</country></aff></contrib><contrib contrib-type="reviewer"><name><surname>Padilla</surname><given-names>Nancy</given-names> </name><role>Reviewer</role><aff><institution/></aff></contrib></contrib-group></front-stub><body><boxed-text><p>In the interests of transparency, eLife publishes the most substantive revision requests and the accompanying author responses.</p></boxed-text><p><bold>Acceptance summary:</bold></p><p>We congratulate you on your development of a neural network that automatically identifies grooming in mice. Your work to characterize grooming behavior across strains, sex and conditions for C57 mice (e.g. lighting, season), to identify loci and genes linked to grooming and open field behavior and to identify human homologs for genes linked to grooming in mice will have sustained influence on the field.</p><p><bold>Decision letter after peer review:</bold></p><p>Thank you for submitting your article &quot;Action detection using a neural network elucidates the genetics of mouse grooming behavior&quot; for consideration by <italic>eLife</italic>. Your article has been reviewed by two peer reviewers, and the evaluation has been overseen by a Reviewing Editor and Michael Taffe as the Senior Editor. The following individuals involved in review of your submission have agreed to reveal their identity: Ioana Carcea (Reviewer #2); Nancy Padilla (Reviewer #3).</p><p>The reviewers have discussed the reviews with one another and the Reviewing Editor has drafted this decision to help you prepare a revised submission.</p><p>We would like to draw your attention to changes in our revision policy that we have made in response to COVID-19 (https://elifesciences.org/articles/57162). Specifically, we are asking editors to accept without delay manuscripts, like yours, that they judge can stand as <italic>eLife</italic> papers without additional data, even if they feel that they would make the manuscript stronger. Thus the revisions requested below only address clarity and presentation.</p><p>Summary:</p><p>In summary, Geuther et al. demonstrate the use of machine learning to identify and classify grooming behaviors in an impressively varied cohort of mice species. Using a 3D convolutional neural network that automatically identifies grooming in mice, they conducted a genome-wide association study (GWAS) to identify loci and genes linked to grooming and open-field behavior. Finally, the authors performed analyses to identify human homologs for genes linked to grooming in mice, with a focus on loci associated with psychiatric illness in humans. Novel findings include the identification of gene-phenotype modules that identify genes linked to both human and mouse phenotypes.</p><p>Essential revisions:</p><p>1) It is unclear how robust the grooming algorithm is to new videos/new animals. Were the training video clips all from a small subset of videos? The authors say 2M frames were annotated from 1,253 video segments, but it is unclear how many strains/mice/videos (not video clips or segments) they came from in total. In the Materials and methods, they mention that the training data comes from 1,253 video clips but there are no additional details. How many animals were represented in the training dataset and in the testing dataset? How robust is the algorithm to differences in animal size (which can be affected by camera distance) and to video frame rate? Where all videos used with this network taken at identical camera distances, video frame rates, and backgrounds (e.g. home cage vs. white background)? Since the training dataset needed for good performance is so large (2M frames) understanding the flexibility of the network is crucial for the community to adopt it successfully. When using and implementing the network, the devil is on the details.</p><p>2) The authors train JAABA with 20% of their dataset and show in Figure 3A and supplementary figure that it performs worse than the new network with the same 20%, but AUCs are relatively similar. But to be sure that this is not a fluke of the specific subset of the data used and to have statistical power to claim the superiority the authors should subsample the training data and repeat the comparison more times. This way they can determine if there the network with 20% of the data outperforms JAABA in every case or with X probability.</p><p>3) The authors use k-means clustering for different analyses, but there are no details on how the different clustering procedures were done.</p><p>4) Reviewers have concerns related to the robustness of the 3D convolutional neural network. We believe that in order for the scientific community to take advantage of this tool the authors need to provide more information.</p></body></sub-article><sub-article article-type="reply" id="sa2"><front-stub><article-id pub-id-type="doi">10.7554/eLife.63207.sa2</article-id><title-group><article-title>Author response</article-title></title-group></front-stub><body><disp-quote content-type="editor-comment"><p>Essential revisions:</p><p>1) It is unclear how robust the grooming algorithm is to new videos/new animals. Were the training video clips all from a small subset of videos? The authors say 2M frames were annotated from 1,253 video segments, but it is unclear how many strains/mice/videos (not video clips or segments) they came from in total. In the Materials and methods, they mention that the training data comes from 1,253 video clips but there are no additional details. How many animals were represented in the training dataset and in the testing dataset? How robust is the algorithm to differences in animal size (which can be affected by camera distance) and to video frame rate? Where all videos used with this network taken at identical camera distances, video frame rates, and backgrounds (e.g. home cage vs. white background)? Since the training dataset needed for good performance is so large (2M frames) understanding the flexibility of the network is crucial for the community to adopt it successfully. When using and implementing the network, the devil is on the details.</p></disp-quote><p>We thank the reviewers for pointing these out and we agree that it is important to provide detailed information about the training data. The annotated video data were sampled from our published strain survey dataset (Geuther, 2019). All videos in this dataset were imaged using nearly identical hardware and as such frame rate, camera distance, and a white open field arena background are held constant. We expect that it is necessary to utilize techniques such as transfer learning to allow this network to generalize well outside these environmental conditions.</p><p>As per the reviewers’ request, we have expanded the details on the training dataset. In the new supplementary figure for Figure 2 (Figure 2—figure supplement 1), we provide visual descriptions for training dataset metadata. Additionally, we now include a table containing metadata for the entire annotated dataset (TrainingDatasetMeta_SupTable.zip). The 1253 video clips were sampled from 157 videos each which contained a different mouse. These 157 mice represent 60 different strains and a wide range of body weights (11g – 44g). While all validation clips also had training clips sampled from the same video, they were non-overlapping and separated in time.</p><p>We have added details of the video data collection and new supplementary data to the text of the paper.</p><disp-quote content-type="editor-comment"><p>2) The authors train JAABA with 20% of their dataset and show in Figure 3A and supplementary figure that it performs worse than the new network with the same 20%, but AUCs are relatively similar. But to be sure that this is not a fluke of the specific subset of the data used and to have statistical power to claim the superiority the authors should subsample the training data and repeat the comparison more times. This way they can determine if there the network with 20% of the data outperforms JAABA in every case or with X probability.</p></disp-quote><p>We have added an additional supplementary figure panel to address this concern. Figure 3—figure supplement 1 now contains a second panel to show how the performance of JAABA scales with different training dataset sizes. Additionally, we also now report AUC values for all ROC plots. We observe that performance saturates for JAABA when using 10% of our annotated data, by only achieving an increase of 0.005 AUC (from 0.925 to 0.93) while doubling the size of training data. Interestingly, JAABA using 5% outperforms our neural network using 10%. This data shows that although JAABA may perform better using limited small datasets, both a neural network approach and a larger training dataset is necessary for generalizing on larger and more varied data.</p><p>Related edits are located in the subsection “Proposed Neural Network Solution” and the new panel B for Figure 3—figure supplement 1 in the figure legend. We have also added indicator to Figure 3B, to indicate the True Positive at 5% False Positive for JAABA and Neural Network solution. The improvement seen in the neural network solution is large (62% to 92% TP at 5% FP, Figure 3B pink line).</p><disp-quote content-type="editor-comment"><p>3) The authors use k-means clustering for different analyses, but there are no details on how the different clustering procedures were done.</p></disp-quote><p>We have added text in the Materials and methods to describe methods surrounding Figure 8’s clustering. Briefly, we visually inspected the data and decided there should be 3 clusters. Then, we used zscore transformed features as inputs to the k-means algorithm to determine cluster membership. We projected the clusters discovered by the k-means to a 2D space formed by principal components (PC).</p><p>We have adjusted the Materials and methods text of Figure 9D to better describe the clustering of grouped SNPs. Briefly, we ran the analysis for a variety of clusters and visually selected the results which looked to cluster the best visually.</p><disp-quote content-type="editor-comment"><p>4) Reviewers have concerns related to the robustness of the 3D convolutional neural network. We believe that in order for the scientific community to take advantage of this tool the authors need to provide more information.</p></disp-quote><p>We interpret “robustness” and “need to provide more information” at two levels. As in critique 1, robustness implies how well does the network work on visual diversity (small and large animals, light vs. dark animals). The network we train is one of the most robust in the field since it recognizes behavior across high visual diversity of the mouse. The network we have trained provides accurate classification across a diversity of mouse visual appearance (coat color, size etc). In fact we are not aware of another work that attempts to operate across all diverse mouse strains for action detection. Furthermore, the network can always be improved for new strains or environments by adding examples to the training data.</p><p>The comment could also refer to whether the architecture of the network has been optimized. This could be done by adding more layers or modifying the structure of the architecture. If we added more layers or made the network larger or smaller would we still obtain the same level of accuracy? We already achieve human observer level performance and don’t expect to exceed that performance, a limitation set by the human generated training data. We believe that identifying a more efficient network is important, but also outside the scope of this paper. The field of machine learning network optimization which seeks to maintain accuracy while minimizing compute is a subfield of machine learning and will require further research. These are important future work.</p></body></sub-article></article>