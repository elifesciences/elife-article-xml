<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD v1.1 20151215//EN"  "JATS-archivearticle1.dtd"><article article-type="research-article" dtd-version="1.1" xmlns:ali="http://www.niso.org/schemas/ali/1.0/" xmlns:xlink="http://www.w3.org/1999/xlink"><front><journal-meta><journal-id journal-id-type="nlm-ta">elife</journal-id><journal-id journal-id-type="publisher-id">eLife</journal-id><journal-title-group><journal-title>eLife</journal-title></journal-title-group><issn pub-type="epub" publication-format="electronic">2050-084X</issn><publisher><publisher-name>eLife Sciences Publications, Ltd</publisher-name></publisher></journal-meta><article-meta><article-id pub-id-type="publisher-id">34789</article-id><article-id pub-id-type="doi">10.7554/eLife.34789</article-id><article-categories><subj-group subj-group-type="display-channel"><subject>Research Article</subject></subj-group><subj-group subj-group-type="heading"><subject>Neuroscience</subject></subj-group></article-categories><title-group><article-title>Spatial cell firing during virtual navigation of open arenas by head-restrained mice</article-title></title-group><contrib-group><contrib contrib-type="author" equal-contrib="yes" id="author-104653"><name><surname>Chen</surname><given-names>Guifen</given-names></name><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="aff" rid="aff2">2</xref><xref ref-type="fn" rid="equal-contrib1">†</xref><xref ref-type="other" rid="fund2"/><xref ref-type="fn" rid="con1"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" equal-contrib="yes" id="author-104654"><name><surname>King</surname><given-names>John Andrew</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">http://orcid.org/0000-0002-0269-3790</contrib-id><email>john.king@ucl.ac.uk</email><xref ref-type="aff" rid="aff3">3</xref><xref ref-type="fn" rid="equal-contrib1">†</xref><xref ref-type="fn" rid="con2"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" equal-contrib="yes" id="author-104655"><name><surname>Lu</surname><given-names>Yi</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">http://orcid.org/0000-0002-4320-675X</contrib-id><email>y.lu.15@ucl.ac.uk</email><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="aff" rid="aff2">2</xref><xref ref-type="fn" rid="equal-contrib1">†</xref><xref ref-type="other" rid="fund5"/><xref ref-type="fn" rid="con3"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" corresp="yes" id="author-49475"><name><surname>Cacucci</surname><given-names>Francesca</given-names></name><email>f.cacucci@ucl.ac.uk</email><xref ref-type="aff" rid="aff2">2</xref><xref ref-type="other" rid="fund2"/><xref ref-type="other" rid="fund3"/><xref ref-type="other" rid="fund4"/><xref ref-type="fn" rid="con4"/><xref ref-type="fn" rid="conf1"/><xref ref-type="other" rid="dataset1"/></contrib><contrib contrib-type="author" corresp="yes" id="author-14649"><name><surname>Burgess</surname><given-names>Neil</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">http://orcid.org/0000-0003-0646-6584</contrib-id><email>n.burgess@ucl.ac.uk</email><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="aff" rid="aff4">4</xref><xref ref-type="other" rid="fund1"/><xref ref-type="other" rid="fund2"/><xref ref-type="fn" rid="con5"/><xref ref-type="fn" rid="conf2"/><xref ref-type="other" rid="dataset1"/></contrib><aff id="aff1"><label>1</label><institution content-type="dept">UCL Institute of Cognitive Neuroscience</institution><institution>University College London</institution><addr-line><named-content content-type="city">London</named-content></addr-line><country>United Kingdom</country></aff><aff id="aff2"><label>2</label><institution content-type="dept">Department of Neuroscience Physiology and Pharmacology</institution><institution>University College London</institution><addr-line><named-content content-type="city">London</named-content></addr-line><country>United Kingdom</country></aff><aff id="aff3"><label>3</label><institution content-type="dept">Department of Clinical Educational Health Psychology</institution><institution>University College London</institution><addr-line><named-content content-type="city">London</named-content></addr-line><country>United Kingdom</country></aff><aff id="aff4"><label>4</label><institution content-type="dept">UCL Institute of Neurology</institution><institution>University College London</institution><addr-line><named-content content-type="city">London</named-content></addr-line><country>United Kingdom</country></aff></contrib-group><contrib-group content-type="section"><contrib contrib-type="editor" id="author-16452"><name><surname>Colgin</surname><given-names>Laura</given-names></name><role>Reviewing Editor</role><aff id="aff5"><institution>The University of Texas at Austin, Center for Learning and Memory</institution><country>United States</country></aff></contrib></contrib-group><author-notes><fn fn-type="equal" id="fn1"><p><sup>*</sup>equal contribution</p></fn><fn fn-type="con" id="equal-contrib1"><label>†</label><p>These authors contributed equally to this work</p></fn></author-notes><pub-date date-type="publication" publication-format="electronic"><day>18</day><month>06</month><year>2018</year></pub-date><pub-date pub-type="collection"><year>2018</year></pub-date><volume>7</volume><elocation-id>e34789</elocation-id><history><date date-type="received" iso-8601-date="2018-01-03"><day>03</day><month>01</month><year>2018</year></date><date date-type="accepted" iso-8601-date="2018-06-11"><day>11</day><month>06</month><year>2018</year></date></history><permissions><copyright-statement>© 2018, Chen et al</copyright-statement><copyright-year>2018</copyright-year><copyright-holder>Chen et al</copyright-holder><ali:free_to_read/><license xlink:href="http://creativecommons.org/licenses/by/4.0/"><ali:license_ref>http://creativecommons.org/licenses/by/4.0/</ali:license_ref><license-p>This article is distributed under the terms of the <ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/licenses/by/4.0/">Creative Commons Attribution License</ext-link>, which permits unrestricted use and redistribution provided that the original author and source are credited.</license-p></license></permissions><self-uri content-type="pdf" xlink:href="elife-34789-v2.pdf"/><abstract><object-id pub-id-type="doi">10.7554/eLife.34789.001</object-id><p>We present a mouse virtual reality (VR) system which restrains head-movements to horizontal rotations, compatible with multi-photon imaging. This system allows expression of the spatial navigation and neuronal firing patterns characteristic of real open arenas (R). Comparing VR to R: place and grid, but not head-direction, cell firing had broader spatial tuning; place, but not grid, cell firing was more directional; theta frequency increased less with running speed, whereas increases in firing rates with running speed and place and grid cells' theta phase precession were similar. These results suggest that the omni-directional place cell firing in R may require local-cues unavailable in VR, and that the scale of grid and place cell firing patterns, and theta frequency, reflect translational motion inferred from both virtual (visual and proprioceptive) and real (vestibular translation and extra-maze) cues. By contrast, firing rates and theta phase precession appear to reflect visual and proprioceptive cues alone.</p></abstract><kwd-group kwd-group-type="author-keywords"><kwd>place cell</kwd><kwd>grid cell</kwd><kwd>head-direction cell</kwd><kwd>memory</kwd><kwd>hippocampal formation</kwd><kwd>virtual reality</kwd></kwd-group><kwd-group kwd-group-type="research-organism"><title>Research organism</title><kwd>Mouse</kwd></kwd-group><funding-group><award-group id="fund1"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/100004440</institution-id><institution>Wellcome</institution></institution-wrap></funding-source><award-id>202805/Z/16/Z</award-id><principal-award-recipient><name><surname>Burgess</surname><given-names>Neil</given-names></name></principal-award-recipient></award-group><award-group id="fund2"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/100010661</institution-id><institution>Horizon 2020 Framework Programme</institution></institution-wrap></funding-source><award-id>Research and Innovation program 720270</award-id><principal-award-recipient><name><surname>Chen</surname><given-names>Guifen</given-names></name><name><surname>Cacucci</surname><given-names>Francesca</given-names></name><name><surname>Burgess</surname><given-names>Neil</given-names></name></principal-award-recipient></award-group><award-group id="fund3"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/501100000268</institution-id><institution>Biotechnology and Biological Sciences Research Council</institution></institution-wrap></funding-source><award-id>BB/I021221/1</award-id><principal-award-recipient><name><surname>Cacucci</surname><given-names>Francesca</given-names></name></principal-award-recipient></award-group><award-group id="fund4"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/100010663</institution-id><institution>H2020 European Research Council</institution></institution-wrap></funding-source><award-id>DEVSPACE Starting grant</award-id><principal-award-recipient><name><surname>Cacucci</surname><given-names>Francesca</given-names></name></principal-award-recipient></award-group><award-group id="fund5"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/501100004543</institution-id><institution>China Scholarship Council</institution></institution-wrap></funding-source><award-id>201509110138</award-id><principal-award-recipient><name><surname>Lu</surname><given-names>Yi</given-names></name></principal-award-recipient></award-group><funding-statement>The funders had no role in study design, data collection and interpretation, or the decision to submit the work for publication.</funding-statement></funding-group><custom-meta-group><custom-meta specific-use="meta-only"><meta-name>Author impact statement</meta-name><meta-value>A mouse virtual reality system is presented which allows normal spatial behavior and place, grid and head-direction cell firing patterns in 2-D arenas, and is compatible with electrophysiology and multi-photon imaging.</meta-value></custom-meta></custom-meta-group></article-meta></front><body><sec id="s1" sec-type="intro"><title>Introduction</title><p>Virtual reality (VR) offers a powerful tool for investigating spatial cognition, allowing experimental control and environmental manipulations that are impossible in the real world. For example, uncontrolled real-world cues cannot contribute to determining location within the virtual environment, while the relative influences of motoric movement signals and visual environmental signals can be assessed by decoupling one from the other (<xref ref-type="bibr" rid="bib35">Tcheang et al., 2011</xref>; <xref ref-type="bibr" rid="bib5">Chen et al., 2013</xref>). In addition, the ability to study (virtual) spatial navigation in head-fixed mice allows the use of intracellular recording and two photon microscopy (<xref ref-type="bibr" rid="bib10">Dombeck et al., 2010</xref>; <xref ref-type="bibr" rid="bib14">Harvey et al., 2009</xref>; <xref ref-type="bibr" rid="bib30">Royer et al., 2012</xref>; <xref ref-type="bibr" rid="bib11">Domnisoru et al., 2013</xref>; <xref ref-type="bibr" rid="bib33">Schmidt-Hieber and Häusser, 2013</xref>; <xref ref-type="bibr" rid="bib15">Heys et al., 2014</xref>; <xref ref-type="bibr" rid="bib20">Low et al., 2014</xref>; <xref ref-type="bibr" rid="bib37">Villette et al., 2015</xref>; <xref ref-type="bibr" rid="bib9">Danielson et al., 2016</xref>; <xref ref-type="bibr" rid="bib7">Cohen et al., 2017</xref>). However, the utility of these approaches depends on the extent to which the neural processes in question can be instantiated within the virtual reality (for a recent example of this debate see <xref ref-type="bibr" rid="bib24">Minderer et al., [2016]</xref>).</p><p>The modulation of firing of place cells or grid cells along a single dimension, such as distance travelled along a specific trajectory or path, can be observed as virtual environments are explored by head-fixed mice (<xref ref-type="bibr" rid="bib5">Chen et al., 2013</xref>; <xref ref-type="bibr" rid="bib10">Dombeck et al., 2010</xref>; <xref ref-type="bibr" rid="bib14">Harvey et al., 2009</xref>; <xref ref-type="bibr" rid="bib11">Domnisoru et al., 2013</xref>; <xref ref-type="bibr" rid="bib33">Schmidt-Hieber and Häusser, 2013</xref>; <xref ref-type="bibr" rid="bib15">Heys et al., 2014</xref>; <xref ref-type="bibr" rid="bib20">Low et al., 2014</xref>; <xref ref-type="bibr" rid="bib7">Cohen et al., 2017</xref>) or body-fixed rats (<xref ref-type="bibr" rid="bib28">Ravassard et al., 2013</xref>; <xref ref-type="bibr" rid="bib1">Acharya et al., 2016</xref>; <xref ref-type="bibr" rid="bib2">Aghajan et al., 2015</xref>). However, the two-dimensional firing patterns of place, grid and head-direction cells in real-world open arenas are not seen in these systems, in which the animal cannot physically rotate through 360°.</p><p>By contrast, the two-dimensional (2-d) spatial firing patterns of place, head direction, grid and border cells have been observed in VR systems in which rats can physically rotate through 360°(<xref ref-type="bibr" rid="bib3">Aronov and Tank, 2014</xref>; <xref ref-type="bibr" rid="bib16">Hölscher et al., 2005</xref>). Minor differences with free exploration remain, for example the frequency of the movement-related theta rhythm is reduced (<xref ref-type="bibr" rid="bib3">Aronov and Tank, 2014</xref>), perhaps due to the absence of translational vestibular acceleration signals (<xref ref-type="bibr" rid="bib28">Ravassard et al., 2013</xref>; <xref ref-type="bibr" rid="bib31">Russell et al., 2006</xref>). However, the coding of 2-d space by neuronal firing can clearly be studied. These VR systems constrain a rat to run on top of an air-suspended Styrofoam ball, wearing a ‘jacket’ attached to a jointed arm on a pivot. This allows the rat to run in any direction, its head is free to look around while its body is maintained over the centre of the ball.</p><p>These 2-d VR systems retain a disadvantage of the real-world freely moving paradigm in that the head movement precludes use with multi-photon microscopy. In addition, some training is required for rodents to tolerate wearing a jacket. Here, we present a VR system for mice in which a chronically implanted head-plate enables use of a holder that constrains head movements to rotations in the horizontal plane while the animal runs on a Styrofoam ball. Screens and projectors project a virtual environment in all horizontal directions around the mouse, and onto the floor below it, from a viewpoint that moves with the rotation of the ball, following <xref ref-type="bibr" rid="bib3">Aronov and Tank (2014)</xref> and <xref ref-type="bibr" rid="bib16">Hölscher et al. (2005)</xref> (see <xref ref-type="fig" rid="fig1">Figure 1</xref> and Materials and methods).</p><fig-group><fig id="fig1" position="float"><object-id pub-id-type="doi">10.7554/eLife.34789.002</object-id><label>Figure 1.</label><caption><title>Virtual reality setup and behavior within it.</title><p>(<bold>A</bold>) Schematic of the VR setup (VR square). (<bold>B</bold>) A rotating head-holder. (<bold>C</bold>) A mouse attached to the head-holder. (<bold>D–E</bold>) Side views of the VR environment. (<bold>F–G</bold>) Average running speeds of all trained mice (n = 11) across training trials in real (‘R’; <bold>F</bold>) and virtual reality (‘VR’; <bold>G</bold>) environments in the main experiment. (<bold>H</bold>) Comparisons of the average running speeds between the first five trials and the last five trials in both VR and R environments, showing a significant increase in both (n = 11, p&lt;0.001, F(1,10)=40.11). (<bold>I–J</bold>) Average Rayleigh vector lengths of running direction across training trials in R (<bold>I</bold>) and VR (<bold>J</bold>). (<bold>K</bold>) Comparisons of the average Rayleigh vector lengths of running direction between the first five trials and the last five trials in both VR and R. Directionality was marginally higher in VR than in R (n = 11, p=0.053, F(1,10)=4.82) and did not change significantly with experience. (<bold>L–M</bold>) Average changes of running direction (absolute difference in direction between position samples) across training trials in R (<bold>L</bold>) and VR (<bold>M</bold>). (<bold>N</bold>) Comparisons of the changes of running direction between the first five and last five trials in both R and VR. Animals took straighter paths in VR than R (n = 11, p&lt;0.001, F(1,10)=300.93), and paths became straighter with experience (n = 11, p&lt;0.001, F(1,10)=26.82). Positions were sampled at 2.5 Hz with 400 ms boxcar smoothing in (<bold>I–N</bold>). All error bars show s.e.m.</p></caption><graphic mime-subtype="x-tiff" mimetype="image" xlink:href="elife-34789-fig1-v2"/></fig><fig id="fig1s1" position="float" specific-use="child-fig"><object-id pub-id-type="doi">10.7554/eLife.34789.003</object-id><label>Figure 1—figure supplement 1.</label><caption><title>Example paths in the three training stages and the recording stage.</title><p>(<bold>A</bold>) A view of the VR narrow linear track at training stage 1. (<bold>B</bold>) A view of the VR wide linear track at training stage 2. (<bold>C</bold>) An example running trajectory in the narrow linear track. Circles indicate reward locations, triangles indicate start points where animals get teleported after getting rewards. The start points were associated with the reward positions with matching colors (dotted lines). For example, a mouse gets teleported back to the position indicated by the blue triangle from the reward position indicated by the blue cycle. (<bold>D</bold>) An example running trajectory in the wide linear track. Circles indicate reward locations, bars indicate end points of the track, triangles indicate start points where animals get teleported after getting rewards or reaching the ends of the track. (<bold>E</bold>) A view of the virtual square at training stage 3 – the ‘fading beacon’ task. (<bold>F</bold>) An example trajectory when a mouse performing a ‘fading beacon’ task in the VR square. The dotted blue circle indicates the fixed location of every fourth reward. (<bold>G</bold>) A view of the virtual square during the recording stage – random foraging. (<bold>H</bold>) An example trajectory from a mouse foraging for randomly-positioned rewards in the VR square.</p></caption><graphic mime-subtype="x-tiff" mimetype="image" xlink:href="elife-34789-fig1-figsupp1-v2"/></fig><fig id="fig1s2" position="float" specific-use="child-fig"><object-id pub-id-type="doi">10.7554/eLife.34789.004</object-id><label>Figure 1—figure supplement 2.</label><caption><title>Directional polar plots of running directions in the VR square environment (n = 11 mice).</title><p>(<bold>A–B</bold>) Average polar plot of running directions over the first five training trials in R (left column) and VR (right column). (<bold>C–D</bold>) Average polar plot of running directions over last five training trials in R (left column) and VR (right column). Each color represents one animal from the main experiment.</p></caption><graphic mime-subtype="x-tiff" mimetype="image" xlink:href="elife-34789-fig1-figsupp2-v2"/></fig><fig id="fig1s3" position="float" specific-use="child-fig"><object-id pub-id-type="doi">10.7554/eLife.34789.005</object-id><label>Figure 1—figure supplement 3.</label><caption><title>Nissl-stained brain sections from the 11 mice in the main experiment.</title><p>(<bold>A</bold>) Eight sections from mice with tetrodes aimed at dorsomedial Entorhinal Cortex and (<bold>B</bold>) seven sections from mice with tetrodes aimed at dorsal CA1. The red arrows indicated the electrode tracks and the red dots marked the end points of the tracks. We note some technical difficulties with processing (e.g. A 1015, B 969).</p></caption><graphic mime-subtype="x-tiff" mimetype="image" xlink:href="elife-34789-fig1-figsupp3-v2"/></fig></fig-group><p>We demonstrate that mice can navigate to an unmarked location within an open virtual arena, in a task like a continuous Morris Water Maze task (<xref ref-type="bibr" rid="bib25">Morris et al., 1982</xref>), combining reference memory for an unmarked location with foraging designed to optimize environmental coverage for recording spatial firing patterns. That is, the mice can perceive and remember locations defined by the virtual space. We also show that the system allows expression of the characteristic 2-d firing patterns of place cells, head-direction cells and grid cells in electrophysiological recordings, making their underlying mechanisms accessible to investigation by manipulations of the VR.</p></sec><sec id="s2" sec-type="results"><title>Results</title><sec id="s2-1"><title>Navigation in VR</title><p>Eleven mice were trained in the virtual reality system (see <xref ref-type="fig" rid="fig1">Figure 1</xref> and <xref ref-type="fig" rid="fig1s1">Figure 1—figure supplement 1</xref>, and Materials and methods). All training trials in the VR and the real square environments from the 11 mice were included in the behavioral analyses below. The mice displayed an initially lower running speed when first experiencing the real-world recording environment (a 60 × 60 cm square), but reached a higher average speed after 20 or so training trials. The increase in running speed with experience was similar in the virtual environments (<xref ref-type="fig" rid="fig1">Figure 1F–H</xref>). Running speeds did not differ between the 60 cm and 90 cm virtual environments used for recording in seven and four of the mice, respectively (12.01 ± 2.77 in 60 cm VR, 14.33 ± 4.19 cm/s in 90 cm VR, p=0.29). Running directions in the VR environment showed a marginally greater unimodal bias compared to the real environment (R; <xref ref-type="fig" rid="fig1">Figure 1K</xref>). Mice displayed a greater tendency to run parallel to the four walls in VR, a tendency which reduced with experience (<xref ref-type="fig" rid="fig1s2">Figure 1—figure supplement 2</xref>). They also took straighter, less tortuous, paths in VR than in R, as would be expected from their head-fixation (<xref ref-type="fig" rid="fig1">Figure 1L–N</xref>).</p><p>In the fading beacon task, performance steadily improved across 2–3 weeks of training (<xref ref-type="fig" rid="fig2">Figure 2D</xref>, one trial per day). They learned to approach the fixed reward location and could do so even after it became completely unmarked (fully faded, see <xref ref-type="fig" rid="fig2">Figure 2</xref> and <xref ref-type="video" rid="video1">Video 1</xref> of a mouse performing the task, and Materials and methods for details of the training regime).</p><fig id="fig2" position="float"><object-id pub-id-type="doi">10.7554/eLife.34789.006</object-id><label>Figure 2.</label><caption><title>Performance on the ‘fading beacon’ task.</title><p>(<bold>A</bold>) An example heat map showing the distribution of locations between the third and the fourth rewards during a 40 min trial (mouse#987, trial#24). The dotted circle in the first quadrant shows the location of the faded reward. (<bold>B</bold>) Average time spent (as % of total time) in each quadrant of the VR square (numbered in A) showed a clear bias (n = 11, p&lt;0.001, F(3,30)=39.03), with time spent in the first quadrant was significantly higher than in the others (*** denotes significance at p&lt;0.001, ** at p&lt;0.01). (<bold>C</bold>) Average durations between the third and the fourth rewards across training trials. (<bold>D</bold>) Average path excess ratios between the third and the fourth rewards across training trials (means ± s.e.m). Note that in each set of four rewards, the first, second and third rewards appeared at random locations in the virtual square, marked by visual beacons, the fourth reward was located at a fixed location. Grey lines show trials when the fixed-location rewards were marked by visual beacons. Blue lines show trials when the fixed rewards were not marked. See Supplementary video.</p></caption><graphic mime-subtype="x-tiff" mimetype="image" xlink:href="elife-34789-fig2-v2"/></fig><media id="video1" mime-subtype="mp4" mimetype="video" xlink:href="elife-34789-video1.mp4"><object-id pub-id-type="doi">10.7554/eLife.34789.007</object-id><label>Video 1.</label><caption><title>example of a mouse performing the ‘fading beacon’ task.</title></caption></media></sec><sec id="s2-2"><title>Electrophysiology</title><p>We recorded a total of 231 CA1 cells from seven mice: 179 cells were classified as place cells in the real environment, 185 cells in the virtual environment, and 154 cells were classified as place cells in both real and virtual environments (see Materials and methods).</p><p>We recorded 141 cells in dorsomedial Entorhinal Cortex (dmEC) from eight mice, 82 of them were classified as grid cells in the real environment, 65 of them grid cells in the virtual environment, and 61 were classified as grid cells in both real and virtual environments. Among these 141 recorded cells, 16 cells were quantified as head-direction cells (HDCs) in R, 20 cells were HDCs in VR, with 12 cells classified as HDCs in both real (‘R’) and virtual reality (‘VR’) environments. All cells were recorded while animals randomly foraged in both R and VR environments (see Materials and methods).</p><p>Place cells recorded from CA1 showed spatially localized firing in the virtual environment, with similar firing rates in the virtual and real square environments. Place cells had larger firing fields in VR than in R, by a factor 1.44 (field size in VR/field size in R). The spatial information content of firing fields in VR was lower than in R. In addition, the firing of place cells was more strongly directionally modulated in VR than in R (see <xref ref-type="fig" rid="fig3">Figure 3</xref>). Similar results were seen irrespective of whether recordings took place in the 60 × 60 cm or 90 × 90 cm VR environments (e.g. the place field expansion factor being 1.44 in 90 cm, 1.43 in 60 cm, p=0.66, see <xref ref-type="fig" rid="fig4s1">Figure 4—figure supplement 1</xref>).</p><fig-group><fig id="fig3" position="float"><object-id pub-id-type="doi">10.7554/eLife.34789.008</object-id><label>Figure 3.</label><caption><title>Place cell firing in real and virtual environments.</title><p>(<bold>A–B</bold>) The same five place cells recorded in a 60 × 60 cm virtual square (<bold>A</bold>) and in a 60 × 60 cm real square (B, one cell per column). Top row: 40 min running trajectory (black line) with red dots showing the locations of spikes; 2nd row, firing rate maps, maximum firing rate (Hz) shown at top right, spatial information (bits/spike) bottom right; third and fourth row: polar plots of directional firing rates (third row: standard binning; fourth row: after fitting a joint ‘pxd’ model to account for in homogeneous sampling), maximum firing rate top right, directional information bottom right. (<bold>C–F</bold>) Comparison between R (grey bars) and VR (blue bars): (<bold>C</bold>) Mean firing rates, higher in R than VR but not significantly so (n = 154, t(153)=1.67, p=0.10); (<bold>D</bold>) Spatial information, significantly higher in R than in VR (n = 154, t(153)=8.90, p&lt;0.001); (<bold>E</bold>) Directional information rates using standard (solid bars) and pxd binning (open bars), greater in VR than in R (standard n = 154, t(153)=6.45, p&lt;0.001; pxd, n = 154, t(153)=7.61, p&lt;0.001). (<bold>F</bold>) Field sizes (bins with firing above 50% of peak firing rate, as a proportion to the size of the test environment), were larger in VR than in R (n = 154, t(153)=4.38, p&lt;0.001).</p></caption><graphic mime-subtype="x-tiff" mimetype="image" xlink:href="elife-34789-fig3-v2"/></fig><fig id="fig3s1" position="float" specific-use="child-fig"><object-id pub-id-type="doi">10.7554/eLife.34789.009</object-id><label>Figure 3—figure supplement 1.</label><caption><title>Directional information of place cell firing (bits/spike) as a function of the distance from the nearest wall (as % of the width of environment) in real (<bold>A</bold>) and virtual (<bold>B</bold>) environments (154 place cells from 11 animals).</title></caption><graphic mime-subtype="x-tiff" mimetype="image" xlink:href="elife-34789-fig3-figsupp1-v2"/></fig><fig id="fig3s2" position="float" specific-use="child-fig"><object-id pub-id-type="doi">10.7554/eLife.34789.010</object-id><label>Figure 3—figure supplement 2.</label><caption><title>VR and R trials in square and cylindrical environments.</title><p>(<bold>A</bold>) Pictures taken for the environments used for recordings (see <xref ref-type="fig" rid="fig1">Figure 1</xref> for the VR square). (<bold>B</bold>) Comparison of place cell properties in different environments (using two-way ANOVAs with factors VR vs R and cylinder vs square). Place cells had lower spatial information in VR, especially in the square environments (main effect of VR, n = 90, F(1,89)=25.20, p&lt;0.001; interaction, F(1,89)=34.99, p&lt;0.001; VR vs R square t(89)=-6.93, p&lt;0.001; VR vs R cylinder t(89)=-1.73, p=0.09). Field size was larger in VR, and more so in the square environments (main effect, n = 90, F(1,89)=22.11, p&lt;0.001; interaction, F(1,89)=4.24, p&lt;0.05; VR vs R square: t(89)=5.07, p&lt;0.001; VR vs R cylinder, t(89)=2.95, p&lt;0.01). Directional information was higher in VR irrespective of environment shape (main effect VR vs R: n = 90, F(1,89)=12.16, p&lt;0.001; interaction, n = 90, F(1,90)=1.10, p=0.30). (<bold>C</bold>) Comparison of grid cell properties in different environments. Grid cells had larger grid scale in VR irrespective of environment shape (main effect, n = 9, F(1,8)=63.74, p&lt;0.001; interaction, n = 9, F(1,8)=3.47, p=0.10). Gridness score was lower in the VR square than the R square but higher in the VR cylinder than the R cylinder (n = 9, t(8)=2.33, p=0.05; interaction, n = 9, F(1,8)=13.35, p&lt;0.01; VR vs R square: t(8)=-2.87, p&lt;0.05; VR vs R cylinder: t(8)=2.33, p=0.05).</p></caption><graphic mime-subtype="x-tiff" mimetype="image" xlink:href="elife-34789-fig3-figsupp2-v2"/></fig></fig-group><p>One possible contribution to apparent directionality in place cell firing could be inhomogeneous sampling of direction within the (locational) firing field. This can be controlled for by explicitly estimating the parameters of a joint place and direction (‘pxd’) model from the firing rate distribution (<xref ref-type="bibr" rid="bib4">Burgess et al., 2005</xref>). However, using this procedure did not ameliorate the directionality in firing (see <xref ref-type="fig" rid="fig3">Figure 3</xref>). Further analyses showed that firing directionality increased near to the boundaries in both virtual and real environments (where sampling of direction is particularly inhomogeneous), but that the additional directionality in VR compared to R was apparent also away from the boundaries (see <xref ref-type="fig" rid="fig3s1">Figure 3—figure supplement 1</xref>). We investigated further whether the increased directionality of place cell firing in VR was specific to the square VR environment, by performing additional recordings of both place and grid cells while animals foraged in (visually similar) cylindrical and square R and VR environments (in four mice, three new to the experiment, yielding a total of 90 place and nine grid cells). The increased directionality of place cells but not grid cells in VR was present in both cylinder and square environments, supporting the generality of the result (see <xref ref-type="fig" rid="fig3s2">Figure 3—figure supplement 2</xref>).</p><p>Grid cells recorded in dmEC, showed similar grid-like firing patterns in VR as in R, with similar firing rates and ‘gridness’ scores. The spatial scale of the grids was larger in VR than in R, with an average increase of 1.42 (grid scale in VR/grid scale in R, n = 6 mice). The spatial information content of grid cell firing was lower in VR than R, as with the place cells. Unlike the place cells, the grid cells showed a slight decrease in directionality from R to VR, although this appears to reflect inhomogeneous sampling of directions within firing fields, as the effect was not seen when controlling for this in a joint ‘pxd’ model (see <xref ref-type="fig" rid="fig4">Figure 4</xref>). Similar results were seen irrespective of whether recordings took place in the 60 × 60 cm or 90 × 90 cm VR environments (e.g. the grid scale expansion factor being 1.43 in 60 cm, 1.36 in 90 cm, p=0.78), although there were minor differences (the reduction in spatial information only reaching significance in the 60 × 60 cm VR and that in directional information only reaching significance in the 90 × 90 cm VR, see <xref ref-type="fig" rid="fig4s1">Figure 4—figure supplement 1</xref>).</p><fig-group><fig id="fig4" position="float"><object-id pub-id-type="doi">10.7554/eLife.34789.011</object-id><label>Figure 4.</label><caption><title>Grid cell firing in real and virtual environments.</title><p>(<bold>A–B</bold>) The same five grid cells simultaneously recorded in a 60 × 60 cm virtual square (<bold>A</bold>) and in a 60 × 60 cm real square (B, one cell per column). Top row: 40 min running trajectory (black line) with red dots showing the locations of spikes; second row, firing rate maps, maximum firing rate (Hz) shown top right, spatial information (bits/spike) bottom right; third row: spatial autocorrelations, gridness scores top right; fourth and fifth rows: polar plots of directional firing rates (fourth row: standard binning; fifth row: ‘pxd’ binning to account for inhomogeneous sampling), maximum firing rate top right, directional information bottom right. (<bold>C–H</bold>) Comparison between R (grey bars) and VR (blue bars): (<bold>C</bold>) Mean firing rates, higher in R than VR but not significantly so (n = 61, t(60)=1.71, p=0.09); (<bold>D</bold>) Gridness scores, higher in R than VR but not significantly so (n = 61, t(60)=1.67, p=0.10); (<bold>E</bold>) Grid scales, larger in VR than in R (n = 61, t(60)=15.52, p&lt;0.001); (<bold>F</bold>) Spatial information in bits/spike, higher in R than VR (n = 61, t(60)=4.12, p&lt;0.001); (<bold>G</bold>) Directional information. Grid cell firing was slightly more directional in VR than in R (n = 61, t(60)=2.04, p&lt;0.05), but the difference disappeared when calculated using pxd plots (open bars, n = 61, t(60)=0.32, p=0.75); (<bold>H</bold>) Directional information in individual grid firing fields, not significant difference between the R and VR trials based on pxd plots (n = 61, t(60)=0.53, p=0.60).</p></caption><graphic mime-subtype="x-tiff" mimetype="image" xlink:href="elife-34789-fig4-v2"/></fig><fig id="fig4s1" position="float" specific-use="child-fig"><object-id pub-id-type="doi">10.7554/eLife.34789.012</object-id><label>Figure 4—figure supplement 1.</label><caption><title>Breakdown of spatial firing properties in 60 × 60 cm or 90 × 90 cm VR environments.</title><p>(<bold>A</bold>) Place cell properties in 60 cm VR compared to 60 cm R square. Spatial information was lower (n = 87, t(86)=7.31, p&lt;0.001), directional information higher (n = 87, t(86)=-4.71, p&lt;0.001) and field size larger (n = 87, t(86)=-3.06, p&lt;0.001). (<bold>B</bold>) Comparison of place cell properties in 90 cm VR compared to 60 cm R. Spatial information was lower (n = 67, t(66)=5.20, p&lt;0.001), directional information higher (n = 67, t(66)=-4.52, p&lt;0.001) and field size larger (n = 67, t(66)=-3.13, p&lt;0.01). (<bold>C</bold>) Grid cell properties in 60 cm VR compared to 60 cm R square. Mean firing rates were lower (n = 43, t(42)=3.19, p&lt;0.01), grid scale larger (n = 43, t(42)=-11.53, p&lt;0.001) and spatial information lower (n = 43, t(42)=2.41, p&lt;0.05). Directional information was similar with standard (solid bars) and pxd binning (open bars). (<bold>D</bold>) Grid cell properties in 90 cm VR compared to 60 cm R square. Grid scales were larger (n = 18, t(17)=-22.72, p&lt;0.001) and directional information was lower for both standard (solid bars, n = 18, t(17)=2.62, p&lt;0.05) and pxd binning (open bars, n = 18, t(17)=2.76, p&lt;0.05). (<bold>E</bold>) Head direction cell properties in 60 cm VR and 60 cm R square. None of the measures showed significant difference between R and VR (n = 10).</p></caption><graphic mime-subtype="x-tiff" mimetype="image" xlink:href="elife-34789-fig4-figsupp1-v2"/></fig><fig id="fig4s2" position="float" specific-use="child-fig"><object-id pub-id-type="doi">10.7554/eLife.34789.013</object-id><label>Figure 4—figure supplement 2.</label><caption><title>Trial order and trial length effects on comparing firing properties across VR and R environments in additional data from four mice.</title><p>Two-way ANOVAs with factors of environment (VR vs R) and trial order (VR first vs R first) were performed. (<bold>A</bold>) Place cell firing properties comparing 20 min R trials with 40 min VR trials. Irrespective of trial order, spatial information was lower in VR (main effect, n = 85, F(1,84)=72.61, p&lt;0.001; interaction, F(1,84)=0.03, p=0.85), field sizes were larger (main effect, F(1,84)=38.5, p&lt;0.001; interaction, F(1,84)=0.47, p=0.49). Directional information was higher for both standard (solid bars, main effect, F(1,84)=33.25, p&lt;0.001) and pxd binning (open bars; main effect, F(1,84)=25.90, p&lt;0.001), with a greater difference when VR trials preceded R trials for both standard (interaction, F(1,84)=6.44, p&lt;0.05) and pxd binning (interaction, F(1,84)=17.95, p&lt;0.001). (<bold>B</bold>) Place cell firing properties comparing 20 min R trials with the first 20 min of VR trials. Irrespective of trial order, spatial information was lower in VR (main effect, n = 85, F(1,84)=47.04, p&lt;0.001; interaction, F(1,84)=0.19, p=0.66) and field sizes were larger (main effect, F(1,84)=20.74, p&lt;0.001; interaction, F(1,84)=0.53, p=0.47). Directional information was higher in VR for both standard (main effect, F(1,84)=44.82, p&lt;0.001) and pxd binning (main effect, F(1,84)=36.50, p&lt;0.001) and more so when VR trials preceded R trials (standard binning: interaction, F(1,84)=3.92, p=0.051; pxd binning: interaction, F(1,84)=13.01, p&lt;0.001). (<bold>C</bold>) Grid cell firing properties comparing 20 min R trials with 40 min VR trials. Irrespective of the order of trials, gridness scores were lower in VR (main effect, n = 20, F(1,19)=34.82, p&lt;0.001; interaction, F(1,19)=1.14, p=0.30) and grid scale was larger (main effect, F(1,19)=74.41, p&lt;0.001; interaction F(1,19)=1.97, p=0.18). (<bold>D</bold>) Grid cell firing properties comparing 20 min R trials with the first 20 min of VR trials. Irrespective of order, gridness scores were lower in VR (main effect, n = 20, F(1,19)=102.90, p&lt;0.001; interaction, F(1,19)=0.80, p=0.38), grid scale was larger (main effect, F(1,19)=75.91, p&lt;0.001; interaction, F(1,19)=0.14, p=0.72) and directional information was higher in both standard binning (main effect, F(1,19)=9.58, p&lt;0.01; interaction, F(1,19)=0.01, p=0.91) and pxd binning (main effect, F(1,19)=8.18, p=0.01; interaction, F(1,19)=4.09, p=0.06).</p></caption><graphic mime-subtype="x-tiff" mimetype="image" xlink:href="elife-34789-fig4-figsupp2-v2"/></fig></fig-group><p>It is possible that low directional modulation of the firing of a grid cell could reflect directionally modulated firing fields with different directional tuning. Accordingly, we checked the directional information in the firing of each field, without finding any difference between R and VR (<xref ref-type="fig" rid="fig4">Figure 4H</xref>).</p><p>To check whether any differences between R and VR could reflect the trial order (VR before R), we recorded additional data from place and grid cells in R and VR on days in which R trials both preceded and followed VR trials (in four mice, three new to the experiment). We also included analysis of the first 20 mins of VR trials (matching the length of R trials, see <xref ref-type="fig" rid="fig4s2">Figure 4—figure supplement 2</xref>). Under these conditions, the differences in firing properties between R and VR are similar to those shown in <xref ref-type="fig" rid="fig3">Figures 3</xref> and <xref ref-type="fig" rid="fig4">4</xref>, again indicating generality. However, the 20 grid cells in this group did show lower gridness scores in VR than R, and 43 cells were classified as grid cells in R but only 24 as grid cells in VR. Thus, grid cell firing patterns can be sensitive to the use of VR and the inherent conflict between virtual and uncontrolled cues to translation. The extra sensitivity in the second group of animals might reflect their greater age at test (mice with grid cells, main experiment: n = 8, age = 25.4 ± 4.3 weeks; additional experiment: n = 3, age = 40.1 ± 11.2 weeks; t(9)=-3.34, p&lt;0.01) but this would require further verification.</p><p>We also recorded head-direction cells in the dmEC, as previously reported in rats (<xref ref-type="bibr" rid="bib32">Sargolini et al., 2006</xref>) and mice (<xref ref-type="bibr" rid="bib12">Fyhn et al., 2008</xref>). These cells showed similar firing rates in VR and R, with similar tuning widths (see <xref ref-type="fig" rid="fig5">Figure 5</xref>). The relative differences in the tuning directions of simultaneously recorded directional cells was maintained between R and VR, even though the absolute tuning direction was not (see <xref ref-type="fig" rid="fig5s1">Figure 5—figure supplement 1</xref>).</p><fig-group><fig id="fig5" position="float"><object-id pub-id-type="doi">10.7554/eLife.34789.014</object-id><label>Figure 5.</label><caption><title>Head direction cell firing in real and virtual environments.</title><p>(<bold>A–B</bold>) Polar plots of the same five HD cells in dmEC simultaneously recorded in R (<bold>A</bold>) and VR (B, one cell per column). Maximum firing rates are shown top right, Rayleigh vector length bottom right. (<bold>C–F</bold>) Comparisons of basic properties of HD cells in dmEC between R and VR. There were no significant differences in peak firing rates (t(11)=0.65, p=0.53; (<bold>C</bold>); directional information (t(11)=1.38, p=0.19; <bold>D</bold>); Rayleigh vector length (t(11)=1.69, p=0.12; <bold>E</bold>); and tuning width (t(11)=0.48, p=0.64; <bold>F</bold>).</p></caption><graphic mime-subtype="x-tiff" mimetype="image" xlink:href="elife-34789-fig5-v2"/></fig><fig id="fig5s1" position="float" specific-use="child-fig"><object-id pub-id-type="doi">10.7554/eLife.34789.015</object-id><label>Figure 5—figure supplement 1.</label><caption><title>Eleven directional cells recorded in dmEC.</title><p>(<bold>A</bold>) Polar plots (left column) and firing rate maps (right column) of seven cells found in mouse 1. (<bold>B</bold>) Two conjunctive grid cells found in mouse 2. (<bold>C</bold>) Two cells found in mouse 3. Numbers on the top right show maximum firing rates, and on the bottom show Rayleigh vector length (left columns) and spatial information (right columns). (<bold>D</bold>) The relative directional tuning difference of simultaneously recorded head-direction cells between VR and R: Mouse 1 (blue), 337.71 ± 8.28; Mouse 2 (red), 138.0 ± 0.00; Mouse 3 (green), 258.00 ± 16.97. The dots represent the relative directional tuning difference of individual cells between VR and R. The lines represent the mean tuning difference within the animals. Each dot represents one cell, and each color represents one animal.</p></caption><graphic mime-subtype="x-tiff" mimetype="image" xlink:href="elife-34789-fig5-figsupp1-v2"/></fig></fig-group><p>The translational movement defining location within the virtual environment purely reflects feedback (visual, motoric and proprioceptive) from the virtual reality system, as location within the real world does not change. However, the animal’s sense of orientation might reflect both virtual and real-world inputs, as the animal rotates in both the real and virtual world. To check for the primacy of the controlled virtual inputs versus potentially uncontrolled real-world inputs (e.g. auditory or olfactory), we performed a 180<sup>o</sup> rotation of the virtual environment and the mouse’s entry to it between trials. Note that the geometry of the apparatus itself (square configuration of screens, overhead projectors on either side) would conflict with rotations other than 180<sup>o</sup>. In separate trials, we observed a corresponding rotation of the virtual firing patterns of place, grid and head-direction cells, indicating the primacy of the virtual environment over non-controlled real world cues (see <xref ref-type="fig" rid="fig6">Figure 6</xref>). While all the grid and head direction cells followed the rotation of VR cues (and entry point), a small percentage of place cells (7/141; 5%) did not. These place cells show much lower spatial information scores in both the R and VR conditions (see <xref ref-type="fig" rid="fig6s1">Figure 6—figure supplement 1</xref>), indicating that their lack of rotation might be the result of their weaker or less stable spatial tuning to the proximal environmental cues that were rotated.</p><fig-group><fig id="fig6" position="float"><object-id pub-id-type="doi">10.7554/eLife.34789.016</object-id><label>Figure 6.</label><caption><title>Effect of rotating the virtual environment on spatial firing patterns.</title><p>(<bold>A–C</bold>) Three simultaneously recorded CA1 place cells (<bold>A</bold>), dmEC grid cells (<bold>B</bold>) and dmEC head-direction cells (<bold>C</bold>). Upper rows show firing patterns in baseline trials, lower rows show the rotated probe trials. Schematic (far let) shows the manipulation: virtual cues and entry point were rotated 180<sup>o</sup> relative to the real environment (marked by a red star). Maximum firing rates are shown top right, spatial information (<bold>A</bold>), gridness (<bold>B</bold>) or Rayleigh vector length (<bold>C</bold>) bottom right. (<bold>D–F</bold>) Spatial correlations between probe and baseline trials were significantly higher when the probe trial rate map was rotated 180<sup>o</sup> than when it was not (spatial correlations for place cells, n = 123, t(122)=19.44, p&lt;0.001; grid cells, n = 18, t(17)=9.41, p&lt;0.001; HD cells, n = 17, t(16)=24.77, p&lt;0.001).</p></caption><graphic mime-subtype="x-tiff" mimetype="image" xlink:href="elife-34789-fig6-v2"/></fig><fig id="fig6s1" position="float" specific-use="child-fig"><object-id pub-id-type="doi">10.7554/eLife.34789.017</object-id><label>Figure 6—figure supplement 1.</label><caption><title>Spatial information of place cells that did not follow the 180 degree rotation of VR environment (n = 7, spatial information were 0.32 ± 0.23, 0.14 ± 0.07, 0.15 ± 0.07 and 0.16 ± 0.09 in R, VR control, VR rotated and VR control trials respectively).</title></caption><graphic mime-subtype="x-tiff" mimetype="image" xlink:href="elife-34789-fig6-figsupp1-v2"/></fig></fig-group><p>The animal’s running speed is known to correlate with the firing rates of cells, including place cells, grid cells and (by definition) speed cells (<xref ref-type="bibr" rid="bib32">Sargolini et al., 2006</xref>; <xref ref-type="bibr" rid="bib22">McNaughton et al., 1983</xref>; <xref ref-type="bibr" rid="bib19">Kropff et al., 2015</xref>), and with the frequency of the local field potential theta rhythm (<xref ref-type="bibr" rid="bib21">McFarland et al., 1975</xref>; <xref ref-type="bibr" rid="bib29">Rivas et al., 1996</xref>; <xref ref-type="bibr" rid="bib34">Sławińska and Kasicki, 1998</xref>). So these experimental measures can give us an independent insight into perceived running speed. We found that the slope of the relationship between theta frequency and running speed was reduced within the VR compared to R, while this was not the case for the firing rates of place, grid and speed cells (see <xref ref-type="fig" rid="fig7">Figure 7</xref>). However, the changes in grid scale and theta frequency in virtual versus real environments did not correlate with each other significantly across animals. There was an effect of running speed on the sizes of place and grid fields that was similar in R and VR, but was not the monotonic relationship that would be predicted by an effect of (speed-related) theta frequency on field size (see <xref ref-type="fig" rid="fig7s1">Figure 7—figure supplement 1</xref>).</p><fig-group><fig id="fig7" position="float"><object-id pub-id-type="doi">10.7554/eLife.34789.018</object-id><label>Figure 7.</label><caption><title>Effect of running speed on theta frequency and firing rates in real and virtual environments.</title><p>Relationship between running speed in VR (blue) and R (black) on instantaneous LFP theta frequency in CA1 (A, n = 6); instantaneous LFP theta frequency in dmEC (B, n = 5); firing rates of place cells in CA1 (C, n = 154); firing rates of grid cells in dmEC (D, n = 61); speed-modulated cells in CA1 (E, n = 55); firing rates of speed-modulated cells in dmEC (F, n = 26). Lines show the mean (±s.e.m) theta frequency in each running speed bin (2.5 cm/s to 30 cm/s).</p></caption><graphic mime-subtype="x-tiff" mimetype="image" xlink:href="elife-34789-fig7-v2"/></fig><fig id="fig7s1" position="float" specific-use="child-fig"><object-id pub-id-type="doi">10.7554/eLife.34789.019</object-id><label>Figure 7—figure supplement 1.</label><caption><title>Spatial cell field size was modulated by running speed in a similar way in R and VR environments.</title><p>(<bold>A</bold>) Comparison of grid field size when sampled in different speed ranges. Field size (as a percentage of the area of the environment) were significantly different across the three speed ranges (n = 61, F(2, 120)=7.06, p&lt;0.01) and between VR and R environments (n = 61, F(1, 60)=21.28, p&lt;0.001) but there was no interaction between effects of speed and environment on size (n = 61, F(2, 120)=0.52, p=0.60). (<bold>B</bold>) Comparison of place cell field size when sampled in different speed ranges. Field sizes were different across speed ranges (n = 154, F(2, 306)=11.13, p&lt;0.001), the effect of environment approached significance (F(1,153)=3.50, p=0.06) and there was no interaction between effects of environment and speed (F(2, 306)=1.98, p=0.14).</p></caption><graphic mime-subtype="x-tiff" mimetype="image" xlink:href="elife-34789-fig7-figsupp1-v2"/></fig></fig-group><p>Finally, an important aspect of place and grid cell firing is the temporal coding seen in the theta phase precession of firing in 1-d (<xref ref-type="bibr" rid="bib27">O'Keefe and Recce, 1993</xref>; <xref ref-type="bibr" rid="bib13">Hafting et al., 2008</xref>) and 2-d (<xref ref-type="bibr" rid="bib6">Climer et al., 2015</xref>; <xref ref-type="bibr" rid="bib17">Jeewajee et al., 2014</xref>) environments. We calculated the theta-band frequency modulation of firing of theta-modulated cells (see Materials and methods for details) and compared it to the LFP theta frequency in R and VR. This analysis shows that, despite the lower overall frequencies in VR, theta modulated firing frequency is slightly higher than the LFP frequency in both R and VR, consistent with theta phase precession (see <xref ref-type="fig" rid="fig8">Figure 8A</xref>). In addition, we directly analysed phase precession in place and grid cells with clear theta-modulation, finding normal 2-d phase precession in both VR and in R (as in 1-d VR [<xref ref-type="bibr" rid="bib14">Harvey et al., 2009</xref>]). The phase precession slope is lower in VR, consistent with larger firing fields overall in VR environments, but correlations between slope and field size only reached significance for place cells in R (n = 38, r = 0.46, p&lt;0.01; all other p&gt;0.3, see <xref ref-type="fig" rid="fig8">Figure 8B–E</xref>). These results indicate that theta phase precession in place and grid cells is independent of linear vestibular acceleration signals and the absolute value of theta frequency.</p><fig id="fig8" position="float"><object-id pub-id-type="doi">10.7554/eLife.34789.020</object-id><label>Figure 8.</label><caption><title>Theta phase precession.</title><p>(<bold>A</bold>) Theta frequency modulation of firing rate versus LFP theta frequency (175 theta modulated cells recorded from EC and CA1, including 20 grid cells and 38 place cells). (<bold>B</bold>) Example of a grid cell’s theta phase precession in real (left) and virtual environments (right), showing the detection of peaks in the smoothed firing rate map (above), division of data into separate firing fields (middle) and firing phase with respect to LFP theta plotted against distance through field along the current direction of motion (pdcd). (<bold>C</bold>) Example of a place cell’s theta phase precession in real (left) and virtual environments (right), shown as in B). (<bold>D</bold>) Comparison of grid cell theta phase precession in R and in VR. Precession slope is lower in absolute value in VR than in R (n = 20, t(19)=-2.55, p&lt;0.05). Phase-pdcd correlation strengths were comparable in VR and in R (n = 20, t(19)=0.02, p=0.98). (<bold>E</bold>) Comparison of place cell theta phase precession in R and VR. Precession slope is lower in absolute value in VR than in R (n = 38, t(37)=-2.19, p&lt;0.05). Phase-pdcd correlation strengths were not different in VR and in R (n = 38, t(37)=-0.24, p=0.82).</p></caption><graphic mime-subtype="x-tiff" mimetype="image" xlink:href="elife-34789-fig8-v2"/></fig></sec></sec><sec id="s3" sec-type="discussion"><title>Discussion</title><p>We have demonstrated the ability of a novel mouse virtual reality (VR) system to allow expression of spatial learning and memory in open environments, following related work in rats (<xref ref-type="bibr" rid="bib3">Aronov and Tank, 2014</xref>; <xref ref-type="bibr" rid="bib16">Hölscher et al., 2005</xref>; <xref ref-type="bibr" rid="bib8">Cushman et al., 2013</xref>). Specifically, in the fading-beacon task, mice learned to return to a rewarded spatial location from multiple novel starting locations which (once the beacon had faded) was not marked by any proximal sensory stimulus, that is requiring allocentric spatial memory.</p><p>Importantly, we also demonstrated that the VR system allows expression of the characteristic spatially modulated firing patterns of place, grid and head-direction cells in open arenas. Thus, it passes the first pre-requisite as a tool for studying the mechanisms behind the two dimensional firing patterns of these spatial cells, following previous systems for rats that also allow physical rotation of the animal (<xref ref-type="bibr" rid="bib3">Aronov and Tank, 2014</xref>; <xref ref-type="bibr" rid="bib16">Hölscher et al., 2005</xref>). Head-fixed or body-fixed VR systems have been very successful for investigating the one-dimensional spatial firing patterns of place cells (<xref ref-type="bibr" rid="bib5">Chen et al., 2013</xref>; <xref ref-type="bibr" rid="bib10">Dombeck et al., 2010</xref>; <xref ref-type="bibr" rid="bib14">Harvey et al., 2009</xref>; <xref ref-type="bibr" rid="bib7">Cohen et al., 2017</xref>; <xref ref-type="bibr" rid="bib28">Ravassard et al., 2013</xref>; <xref ref-type="bibr" rid="bib1">Acharya et al., 2016</xref>; <xref ref-type="bibr" rid="bib2">Aghajan et al., 2015</xref>) or grid cells (<xref ref-type="bibr" rid="bib11">Domnisoru et al., 2013</xref>; <xref ref-type="bibr" rid="bib33">Schmidt-Hieber and Häusser, 2013</xref>; <xref ref-type="bibr" rid="bib15">Heys et al., 2014</xref>; <xref ref-type="bibr" rid="bib20">Low et al., 2014</xref>), for example, modulation of firing rate by the distance along a linear trajectory. But the two-dimensional firing patterns of place, grid or head direction cells are not seen in these systems.</p><p>Although the characteristic firing patterns of spatial cells were expressed within our VR system, there were also some potentially instructive differences in their more detailed properties between VR and a similar real environment (R), which we discuss below.</p><p>The spatial scale of the firing patterns of both place cells and grid cells was approximately 1.4 times larger in VR compared to the real environment (‘R’, <xref ref-type="fig" rid="fig3">Figures 3</xref> and <xref ref-type="fig" rid="fig4">4</xref>; see also <xref ref-type="bibr" rid="bib3">Aronov and Tank, [2014</xref>]). Along with the increased scale of place and grid cell responses in VR, there was a reduction in the dependence of theta frequency on running speed. The LFP theta frequency reflects a contribution from vestibular translational acceleration signals (<xref ref-type="bibr" rid="bib28">Ravassard et al., 2013</xref>; <xref ref-type="bibr" rid="bib31">Russell et al., 2006</xref>) which will be absent in our VR system. However, there was no change in the increasing firing rates of place, grid and speed cells with running speed in VR (<xref ref-type="fig" rid="fig7">Figure 7</xref>), indicating an independence from vestibular translational acceleration cues. Thus, it is possible that the absence of linear acceleration signals affects both LFP theta rhythmicity and the spatial scale of firing patterns, but there was no evidence that the two were directly related.</p><p>Finally, uncontrolled distal cues, such as sounds and smells, and the visual appearance of the apparatus aside from the screens (the edge of the ball, the edges of the screens) will conflict with virtual cues indicating self-motion. Thus, increased firing field size could also reflect broader tuning or reduced precision due to absent or conflicting inputs, consistent with the reduced spatial information seen in place and grid cell firing patterns (<xref ref-type="fig" rid="fig3">Figures 3</xref> and <xref ref-type="fig" rid="fig4">4</xref>), and potentially a response to spatial uncertainty (<xref ref-type="bibr" rid="bib36">Towse et al., 2014</xref>). Nonetheless, more grid cells met the spatial firing criteria in R than in VR, which was not true for place or head-direction cells, and lower gridness scores were observed in VR in a group of four older mice (<xref ref-type="fig" rid="fig4s2">Figure 4—figure supplement 2</xref>). This would be consistent with the presence of conflict in translational cues in VR (e.g. vestibular versus optic flow) if grid cell firing specifically reflects translational self-motion (<xref ref-type="bibr" rid="bib23">McNaughton et al., 2006</xref>).</p><p>The head direction cells do not show broader tuning in the VR (<xref ref-type="fig" rid="fig5">Figure 5</xref>), probably because there is no absence of vestibular rotation cues and no conflict with distal real-world cues, as the mice rotate similarly in the virtual and real world. We note however, that spatial firing patterns follow the virtual cues when the virtual cues and entry point are put into conflict with uncontrolled real-world cues (<xref ref-type="fig" rid="fig6">Figure 6</xref>).</p><p>Place cell firing in VR showed an increased directionality compared to the real environment. One possible explanation, that the apparent directionality reflected inhomogeneous sampling of directions in the firing field, was not supported by further analyses (<xref ref-type="fig" rid="fig3">Figure 3E</xref>). Another possible explanation, that differences in directionality reflected the specific features of the VR square, was not supported by further experiments in a second virtual environment (see <xref ref-type="fig" rid="fig3s2">Figure 3—figure supplement 2</xref>). A potential benefit of VR is an absence of local sensory cues to location. Experimenters typically work hard to remove consistent uncontrolled cues from real-world experiments (e.g. cleaning and rotating the walls and floor between trials), but reliable within-trial local cues (e.g. olfactory, tactile) may contribute to localization of firing nonetheless (<xref ref-type="bibr" rid="bib28">Ravassard et al., 2013</xref>). Thus uncontrolled local cues in real experiments may be useful for supporting an orientation-independent locational response that can be bound to the distinct visual scenes observed in different directions, see also <xref ref-type="bibr" rid="bib1">Acharya et al., (2016)</xref>. In this case, by removing these local cues, the use of VR leaves the locational responses of place cells more prone to modulation by the remaining (directionally specific) visual cues. We note that grid cells did not show an increase in directional modulation. This may indicate that place cell firing is more influenced by environmental sensory inputs (directional visual cues in VR), whereas grid cell firing might be more influenced by self-motion, and thus less influenced by directional visual cues. However, this would need to be verified in future work.</p><p>In conclusion, by using VR, the system presented here offers advantages over traditional paradigms by enabling manipulations that are impossible in the real-world, allowing visual projection of an environment that need not directly reflect a physical reality or the animals’ movements. Differences between the firing patterns in VR and R suggest broader spatial tuning as a possible response to under-estimated translation or spatial uncertainty caused by missing or conflicting inputs, a role for local cues in supporting directionally independent place cell firing and potentially for self-motion cues in supporting directionally independent grid cell firing. Finally, the effect of moving from R to VR in reducing the dependence on running speed of the LFP theta frequency but not of neuronal firing rates suggests two distinct mechanisms for speed coding, potentially reflecting a differential dependence on linear vestibular acceleration cues. However, the temporal coding seen in theta phase precession of place (<xref ref-type="bibr" rid="bib27">O'Keefe and Recce, 1993</xref>) and grid (<xref ref-type="bibr" rid="bib13">Hafting et al., 2008</xref>) cell firing appeared to be fully present in VR despite the reduced theta frequency and absent linear acceleration cues (<xref ref-type="fig" rid="fig8">Figure 8</xref>).</p><p>Previous body-rotation VR systems for rats (<xref ref-type="bibr" rid="bib3">Aronov and Tank, 2014</xref>; <xref ref-type="bibr" rid="bib16">Hölscher et al., 2005</xref>) also allow expression of the two dimensional firing patterns of place, grid and head-direction cells. However, by working for mice and by constraining the head to rotation in the horizontal plane, our system has the potential for future use with multi-photon imaging using genetically encoded calcium indicators. The use of multiple screens and floor projectors is not as elegant as the single projector systems (<xref ref-type="bibr" rid="bib3">Aronov and Tank, 2014</xref>; <xref ref-type="bibr" rid="bib16">Hölscher et al., 2005</xref>) but allows the possible future inclusion of a two photon microscope above the head without interrupting the visual projection, while the effects of in-plane rotation on acquired images should be correctable in software (<xref ref-type="bibr" rid="bib38">Voigts and Harnett, 2018</xref>).</p></sec><sec id="s4" sec-type="materials|methods"><title>Materials and methods</title><sec id="s4-1"><title>Virtual reality</title><p>A circular head-plate made of plastic (Stratasys Endur photopolymer) is chronically attached to the skull, with a central opening allowing the implant of tetrodes for electrophysiological recording (see Surgery). The head-plate makes a self-centring joint with a holder mounted in a bearing (Kaydon reali-slim bearing KA020XP0) and is clipped into place by a slider. The bearing is held over the centre of an air-supported Styrofoam ball. Four LCD screens placed vertically around the ball and two projectors onto a horizontal floor provide the projection of a virtual environment. The ball is prevented from yaw rotation to give the mouse traction to turn and to prevent any rotation of the ball about its vertical axis, following <xref ref-type="bibr" rid="bib3">Aronov and Tank (2014)</xref>, (see <xref ref-type="fig" rid="fig1">Figure 1A–E</xref>).</p><p>The virtual environment runs on a Dell Precision T7500 workstation PC running Windows 7 64-bit on a Xeon X5647 2.93 GHz CPU, displayed using a combination of four Acer B236HL LCD monitors mounted vertically in a square array plus two LCD projectors (native resolution 480 × 320, 150 lumens) mounted above to project floor texture. The head-holder is at the centre of the square and 60 mm from the bottom edge of the screens, and 9500 mm below the projectors. The LCD panels are 514 mm x 293 mm, plus bezels of 15 mm all around. These six video feeds are fed by an Asus AMD Radeon 6900 graphics card and combined into a single virtual display of size 5760 × 2160 px using AMD Radeon Eyefinity software. The VR is programmed using Unity3d v5.0.2f1 which allows virtual cameras to draw on specific regions of the virtual display, with projection matrices adjusted (see Kooima, 2008 <ext-link ext-link-type="uri" xlink:href="http://csc.lsu.edu/~kooima/articles/genperspective/index.html">http://csc.lsu.edu/~kooima/articles/genperspective/index.html</ext-link>) to the physical dimensions and distances of the screens and to offset the vanishing point from the centre. For example, a virtual camera facing the X-positive direction renders its output to a portion of the virtual display which is known to correspond to the screen area of the physical monitor facing the X-negative direction.</p><p>Translation in the virtual space is controlled by two optical mice (Logitech G700s gaming mouse) mounted with orthogonal orientations at the front and side of a 200 mm diameter hollow polystyrene sphere, which floats under positive air pressure in a hemispherical well. The optical mice drive X and Y inputs respectively by dint of their offset orientations, and gain can be controlled within the Unity software. Gain is adjusted such that real-world rotations of the sphere are calibrated so that a desired environmental size (e.g. 600 mm across) corresponds to the appropriate movement of the surface of the sphere under the mouse (i.e. moving 600 mm, or just under one rotation, on the sphere takes the mouse across the environment). Mouse pointer acceleration is disabled at operating system level to ensure movement of the sphere is detected in a linear fashion independent of running speed.</p><p>The mouse is able to freely rotate in the horizontal plane, which has no effect on the VR display (but brings different screens into view). Rotation is detected and recorded for later analysis using an Axona dacqUSB tracker which records the position of two LEDs mounted at ~25 mm offset to left and right of the head stage amplifier (see Surgery). Rotation is sampled at 50 Hz by detection of the LED locations using an overhead video camera, while virtual location is sampled and logged at 50 Hz.</p><p>Behavior is motivated by the delivery of milk rewards (SMA, Wysoy) controlled by a Labjack U3HD USB Data Acquisition device. A digital-to-analogue channel applies 5V DC to a control circuit driving a 12V Cole-Parmer 1/16’ solenoid pinch valve, which is opened for 100 ms for each reward, allowing for the formation of a single drop of milk (5 uL) under gravity feed at the end of a 1/32’ bore tube held within licking distance of the animal’s mouth.</p><p>Control of the Labjack and of reward locations in the VR is via UDP network packets between the VR PC and a second experimenter PC, to which the Labjack is connected by USB. Software written in Python 2.7 using the Labjack, tk (graphics) and twistd (networking) libraries provide a plan-view graphical interface in which the location of the animal and reward cues in the VE can be easily monitored and reward locations manipulated with mouse clicks (see <xref ref-type="fig" rid="fig1">Figure 1</xref>).</p></sec><sec id="s4-2"><title>Animals</title><p>Subjects (14 male C57Bl/6 mice) were aged 11–14 weeks and weighed 25–30 grams at the time of surgery. Mice were housed under 12:12 inverted light-dark cycle, with lights on at 10am. All work was carried out under the Animals (Scientific Procedures) Act 1986 and according to Home Office and institutional guidelines.</p></sec><sec id="s4-3"><title>Surgery</title><p>Throughout surgery, mice were anesthetized with 2–3% isoflurane in O<sub>2</sub>. Analgesia was provided pre-operatively with 0.1 mg/20 g Carprofen, and post-operatively with 0.1 mg/20 g Metacam. Custom-made head plates were affixed to the skulls using dental cement (Kemdent Simplex Rapid). Mice were implanted with custom-made microdrives (Axona, UK), loaded with 17 μm platinum-iridium tetrodes, and providing buffer amplification. Two mice were implanted with eight tetrodes in CA1 (ML: 1.8 mm, AP: 2.1 mm posterior to bregma), three mice with eight tetrodes in the dorsomedial entorhinal cortex (dmEC, ML = 3.1 mm. AP = 0.2 mm anterior to the transverse sinus, angled 4° posteriorly), and nine mice received a dual implant with one microdrive in right CA1 and one in left dmEC (each mircrodrive carried four tetrodes). After surgery, mice were placed in a heated chamber until fully recovered from the anesthetic (normally about 1 hr), and then returned to their home cages. Mice were given at least 1 week of post-operative recovery before cell screening and behavioral training started.</p><p>After experiments ended the 11 mice that had participated in the main experiment were killed with an overdose of sodium pentobarbital and perfused transcardially with saline followed by formalin solution. Brains were stored in formalin overnight before transferred to 30% sucrose solution for 2 days. Slicing were then done coronally for CA1 implanted hemisphere and sagittally for dmEC implanted hemisphere into 30-um-thick sections, which were mounted and stained using Thionin solution (<xref ref-type="fig" rid="fig1s3">Figure 1—figure supplement 3</xref>).</p></sec><sec id="s4-4"><title>Behavioral training</title><p>Behavioral training in the virtual reality setup started while tetrodes were approaching target brain areas (see Screening for spatial cells). Behavioral training involved four phases, VR trials lasted 40 min. Firstly, mice experienced an infinitely long 10 cm-wide virtual linear track, with 5 μL milk drops delivered as rewards. Reward locations were indicated by virtual beacons (high striped cylinders with a black circular base, see <xref ref-type="fig" rid="fig1s1">Figure 1—figure supplement 1A</xref>), which were evenly placed along the track (see <xref ref-type="fig" rid="fig1s1">Figure 1—figure supplement 1C</xref>). When the mouse contacted the area of the base, milk was released and the beacon disappeared (reappearing in another location). The lateral movement of the mice was not registered in this phase. The aim of this training phase was to habituate the mice to being head restrained and train them to run smoothly on the air-cushioned ball. It took 3 days, on average, for mice to achieve this criterion and move to the next training phase.</p><p>During the second training phase mice experienced a similar virtual linear track (see <xref ref-type="fig" rid="fig1s1">Figure 1—figure supplement 1B</xref>), which was wider than the first one (30 cm wide). During this phase, reward beacons were evenly spaced along the long axis of the track, as before, but placed pseudo-randomly in one of three pre-defined positions on the lateral axis (middle, left or right). The aim of this training phase was to strengthen the association between rewards and virtual beacons, and to train animals to navigate towards rewarded locations via appropriate rotations on top of the ball. This training phase also took three days, on average.</p><p>During the third training phase, mice were introduced into a virtual square arena placed in the middle of a larger virtual room (see <xref ref-type="fig" rid="fig1">Figure 1</xref> and <xref ref-type="fig" rid="fig1s1">Figure 1—figure supplement 1</xref>). The virtual arena had size 60 × 60 cm or 90 x 90 cm for different mice. Reward beacons had a base of diameter that equalled to 10% of the arena width. Mice were trained on a ‘random foraging’ task, during which visible beacons were placed in the square box at random locations (at any given time only one beacon was visible).</p><p>The last training phase was the ‘fading beacon’ task. During this task, every fourth beacon occurred in a fixed location (the three intervening beacons being randomly placed within the square enclosure; see <xref ref-type="fig" rid="fig1s1">Figure 1—figure supplement 1D</xref>). At the beginning of this training phase the ‘fixed location beacon’ slowly faded from view over 10 contacts with decreasing opacity. The beacon would remain invisible as long as mice could find it, but would became visible again if mice could not locate it after 2 min of active searching. Once mice showed consistent navigation toward the fading fixed beacon, they were moved to the ‘faded beacon’ phase of the task where the ‘fixed location beacon’ was invisible from the start of the trial and remained invisible throughout the trial, with two drops of milk given as reward for contact. This trial phase therefore requires mice to navigate to an unmarked virtual location starting from different starting points (random locations where the third visible beacon was placed). As such, the ‘fading beacon’ task serves like a continuous version of a Morris Water Maze task (<xref ref-type="bibr" rid="bib38">Voigts and Harnett, 2018</xref>), combining reference memory for an unmarked location with a foraging task designed to optimise environmental coverage for the assessment of spatial firing patterns. Mice typically experienced one trial per day.</p></sec><sec id="s4-5"><title>Behavioral analyses</title><p>During electrophysiological recording in the real environment (R), the mouse’s position and head orientation were tracked by an overhead camera (50 Hz sampling rate) using two infra-red LEDs attached to the micro-drive at a fixed angle and spacing (5 cm apart). Brief losses of LED data due to cable obstruction (typically affecting a single LED for &lt;500 ms) were corrected with linear interpolation between known position values. Interpolation was carried out for each LED separately. The position values for each LED were then smoothed, separately, using a 400 ms boxcar filter. During electrophysiological recording in VR, head orientation was tracked as in R, the path, running speed and running direction was inferred from the VR log at 50 Hz (movements of VR location being driven by the computer mice tracking the rotation of the ball, see above).</p><p>Path excess ratio was defined as the ratio between the length of the actual path that an animal takes to run from one reward location to another, and the distance between the two reward locations. All training trials in the VR square and the real (R) square environments from the 11 mice in the main experiment were included in the behavioral analyses in <xref ref-type="fig" rid="fig1">Figures 1</xref>–<xref ref-type="fig" rid="fig2">2</xref>.</p></sec><sec id="s4-6"><title>Screening for spatial cells</title><p>Following recovery, mice were food restricted to 85% of their free-feeding body weight. They were then exposed to a recording arena every day (20 min/day) and screening for neural activity took place. The recording arena was a 60 × 60 cm square box placed on a black Trespa ‘Toplab’ surface (Trespa International B.V., Weert, Netherlands), and surrounded by a circular set of black curtains. A white cue-card (A0, 84 × 119 cm), illuminated by a 40 W lamp, was the only directionally polarizing cue within the black curtains. Milk (SMA Wysoy) was delivered as drops on the floor from a syringe as rewards to encourage foraging behavior. Tetrodes were lowered by 62.5 μm each day, until grid or place cell activity was identified, in dmEC or CA1 respectively. Neural activity was recorded using DACQ (Axona Ltd., UK) while animals were foraging in the square environment. For further details see <xref ref-type="bibr" rid="bib5">Chen et al. (2013</xref>).</p></sec><sec id="s4-7"><title>Recording spatial cell activity</title><p>Each recording session consisted of at least one 40 min random-foraging trial in a virtual reality (VR) square environment (see above for behavioral training). For seven mice, the virtual environment had size 60 × 60 cm and for 4 mice 90 × 90 cm when recording took place. After one (or more) 40-min random-foraging trials in the virtual square, mice were placed in a real-world square (‘R’, 60 × 60 cm square, similar to the screening environment, see <xref ref-type="fig" rid="fig3s2">Figure 3—figure supplement 2A</xref>) for a 20-min random-foraging trial in real world.</p><p>Additionally, four mice also underwent a virtual cue rotation experiment, which consisted of two 40-min random-foraging VR trial (one baseline VR trial and one rotated VR trial) and one 20-min R trial. Two mice navigating 60 × 60 cm VR squares and two 90 × 90 cm squares participated in this experiment. In the rotated VR trials, all cues in the virtual reality environment rotated 180 degrees compared to the baseline trial, as was the entry point mice were carried into the VR rig from.</p><p>In order to control for sequential effect between VR and R trials, we performed additional recordings from four mice (three new to the experiment, one that had performed the main experiment). On one day they experienced a trial in the R square before a trial in the VR square (60 × 60 cm) environment. On the next day the VR trial preceded the R trial. We also introduced those four mice to a novel cylindrical VR and cylindrical R environment which shared similar wall and floor visual patterns. Four trials were recorded on the same day in the order: VR cylinder, VR square, R cylinder and R square. All VR trials were 40 min and R trials 20 min in length (see <xref ref-type="fig" rid="fig3s2">Figure 3—figure supplement 2</xref> and <xref ref-type="fig" rid="fig4s2">Figure 4—figure supplement 2</xref>).</p></sec><sec id="s4-8"><title>Firing rate map construction and spatial cell classification</title><p>Spike sorting was performed offline using an automated clustering algorithm (KlustaKwik [<xref ref-type="bibr" rid="bib18">Kadir et al., 2014</xref>]) followed by a manual review and editing step using an interactive graphical tool (waveform, Daniel Manson, <ext-link ext-link-type="uri" xlink:href="http://d1manson.github.io/waveform/">http://d1manson.github.io/waveform/</ext-link>). After spike sorting, firing rate maps were constructed by binning animals’ positions into 1.5 × 1.5 cm bins, assigning spikes to each bin, smoothing both position maps and spike maps separately using a 5 × 5 boxcar filter, and finally dividing the smoothed spike maps by the smoothed position maps.</p><p>Cells were classified as place cells if their spatial information in baseline trials exceeded the 99th percentile of a 1000 shuffled distribution of spatial information scores calculated from rate maps where spike times were randomly offset relative to position by at least 4 s. Cells were classified as grid cells if their gridness scores in baseline trials exceeded the 99th percentile of a shuffled distribution of 1000 gridness scores (<xref ref-type="bibr" rid="bib4">Burgess et al., 2005</xref>). Place and grid cells additionally required a peak firing rate above 2 Hz for clarity of classification. Cells were classified as head direction cells if their Rayleigh vector lengths in baseline trials exceeded the threshold of the 99th percentile population shuffling (this sample included two conjunctive grid x direction cells (<xref ref-type="bibr" rid="bib32">Sargolini et al., 2006</xref>, see <xref ref-type="fig" rid="fig5s1">Figure 5—figure supplement 1B</xref>).</p><p>Speed-modulated cells were classified from the general population of the recorded cells following <xref ref-type="bibr" rid="bib22">McNaughton et al. (1983)</xref>. Briefly, the degree of speed modulation for each cell was characterized by first defining the instantaneous firing rate of the cell as the number of spikes occurring in each position bin divided by the sampling duration (0.02 s). Then, a linear correlation was computed between the running speeds and firing rates across all position samples in a trial, and the resulting r-value was taken to characterize the degree of speed modulation for the cell. To be defined as speed-modulated, the r-value for a cell had to exceed the 99th percentile of a distribution of 1000 r-values obtained from spike shuffled data.</p><p>When assessing the directional modulation of place and grid cell firing (<xref ref-type="fig" rid="fig3">Figures 3</xref> and <xref ref-type="fig" rid="fig4">4</xref>), apparent directional modulation can arise in binned firing rate data from heterogenous sampling of directions within the spatial firing field (<xref ref-type="bibr" rid="bib4">Burgess et al., 2005</xref>; <xref ref-type="bibr" rid="bib27">O'Keefe and Recce, 1993</xref>). Accordingly we fit a joint (‘pxd’) model of combined place and directional modulation to the data (maximising the likelihood of the data [<xref ref-type="bibr" rid="bib4">Burgess et al., 2005</xref>]) and perform analyses on the directional model in addition to the binned firing rate data.</p><p>Theta modulation of cell firing during the main experiment were computed using Maximum likelihood estimation of the distribution of lags, following <xref ref-type="bibr" rid="bib6">Climer et al. (2015)</xref>. Cells with theta index higher than the confidence interval of 95% were classified as theta rhythmic cells. Among that population, two-dimensional phase precession was estimated for cells that were also classified as place cells or grid cells, following <xref ref-type="bibr" rid="bib6">Climer et al. (2015)</xref>. In brief, each running trajectory passing through the defined place field was normalized and mapped radially on an unit circle so that the proportional distance of the animal between the field edge and peak was preserved and so that the average running direction was zero (from left to right). The distance of the animal from the peak projected onto the instantaneous running direction (‘Pdcd') was calculated, representing the distance the animal has travelled through the field (range −1 to 1). The theta phase of each spike was computed using the Hilbert transform of the smoothed LFP.</p></sec></sec></body><back><ack id="ack"><title>Acknowledgements</title><p>We acknowledge support from the Wellcome Trust, European Union’s Horizon 2020 research and innovation programme (grant agreement No. 720270, Human Brain Project SGA1), Biotechnology and Biological Sciences Research Council, European Research Council and China Scholarship Council, and technical help from Peter Bryan, Duncan Farquharson, Daniel Bush and Daniel Manson.</p></ack><sec id="s5" sec-type="additional-information"><title>Additional information</title><fn-group content-type="competing-interest"><title>Competing interests</title><fn fn-type="COI-statement" id="conf2"><p>Reviewing editor, <italic>eLife</italic></p></fn><fn fn-type="COI-statement" id="conf1"><p>No competing interests declared</p></fn></fn-group><fn-group content-type="author-contribution"><title>Author contributions</title><fn fn-type="con" id="con1"><p>Conceptualization, Formal analysis, Supervision, Investigation, Visualization, Methodology, Writing—review and editing</p></fn><fn fn-type="con" id="con2"><p>Conceptualization, Resources, Software, Supervision, Methodology, Project administration, Writing—review and editing</p></fn><fn fn-type="con" id="con3"><p>Formal analysis, Investigation, Visualization, Methodology, Writing—review and editing</p></fn><fn fn-type="con" id="con4"><p>Conceptualization, Resources, Software, Supervision, Methodology, Project administration, Writing—review and editing</p></fn><fn fn-type="con" id="con5"><p>Conceptualization, Resources, Formal analysis, Supervision, Funding acquisition, Investigation, Visualization, Methodology, Writing—original draft, Project administration, Writing—review and editing, Physical design and construction</p></fn></fn-group><fn-group content-type="ethics-information"><title>Ethics</title><fn fn-type="other"><p>Animal experimentation: All work was carried out under the Animals (Scientific Procedures) Act 1986 and according to Home Office and institutional guidelines.</p></fn></fn-group></sec><sec id="s6" sec-type="supplementary-material"><title>Additional files</title><supplementary-material id="transrepform"><object-id pub-id-type="doi">10.7554/eLife.34789.021</object-id><label>Transparent reporting form</label><media mime-subtype="pdf" mimetype="application" xlink:href="elife-34789-transrepform-v2.pdf"/></supplementary-material><sec id="s7" sec-type="data-availability"><title>Data availability</title><p>Data have been made available via the Open Science Framework platform (<ext-link ext-link-type="uri" xlink:href="https://osf.io/yvmf4/">https://osf.io/yvmf4/</ext-link>)</p><p>The following dataset was generated:</p><p><related-object content-type="generated-dataset" id="dataset1" source-id="https://osf.io/yvmf4/" source-id-type="uri"><collab collab-type="author">Francesca Cacucci</collab><collab collab-type="author">Neil Burgess</collab><year>2018</year><source>Data from Spatial cell firing during virtual navigation of open arenas by head-restrained mice</source><ext-link ext-link-type="uri" xlink:href="https://osf.io/yvmf4/">https://osf.io/yvmf4/</ext-link><comment>Publicly available on the Open Science Framework</comment></related-object></p></sec></sec><ref-list><title>References</title><ref id="bib1"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Acharya</surname> <given-names>L</given-names></name><name><surname>Aghajan</surname> <given-names>ZM</given-names></name><name><surname>Vuong</surname> <given-names>C</given-names></name><name><surname>Moore</surname> <given-names>JJ</given-names></name><name><surname>Mehta</surname> <given-names>MR</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Causal influence of visual cues on hippocampal directional selectIvity</article-title><source>Cell</source><volume>164</volume><fpage>197</fpage><lpage>207</lpage><pub-id pub-id-type="doi">10.1016/j.cell.2015.12.015</pub-id><pub-id pub-id-type="pmid">26709045</pub-id></element-citation></ref><ref id="bib2"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Aghajan</surname> <given-names>ZM</given-names></name><name><surname>Acharya</surname> <given-names>L</given-names></name><name><surname>Moore</surname> <given-names>JJ</given-names></name><name><surname>Cushman</surname> <given-names>JD</given-names></name><name><surname>Vuong</surname> <given-names>C</given-names></name><name><surname>Mehta</surname> <given-names>MR</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>Impaired spatial selectivity and intact phase precession in two-dimensional virtual reality</article-title><source>Nature Neuroscience</source><volume>18</volume><fpage>121</fpage><lpage>128</lpage><pub-id pub-id-type="doi">10.1038/nn.3884</pub-id><pub-id pub-id-type="pmid">25420065</pub-id></element-citation></ref><ref id="bib3"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Aronov</surname> <given-names>D</given-names></name><name><surname>Tank</surname> <given-names>DW</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>Engagement of neural circuits underlying 2D spatial navigation in a rodent virtual reality system</article-title><source>Neuron</source><volume>84</volume><fpage>442</fpage><lpage>456</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2014.08.042</pub-id><pub-id pub-id-type="pmid">25374363</pub-id></element-citation></ref><ref id="bib4"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Burgess</surname> <given-names>N</given-names></name><name><surname>Cacucci</surname> <given-names>F</given-names></name><name><surname>Lever</surname> <given-names>C</given-names></name><name><surname>O'keefe</surname> <given-names>J</given-names></name></person-group><year iso-8601-date="2005">2005</year><article-title>Characterizing multiple independent behavioral correlates of cell firing in freely moving animals</article-title><source>Hippocampus</source><volume>15</volume><fpage>149</fpage><lpage>153</lpage><pub-id pub-id-type="doi">10.1002/hipo.20058</pub-id><pub-id pub-id-type="pmid">15558542</pub-id></element-citation></ref><ref id="bib5"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Chen</surname> <given-names>G</given-names></name><name><surname>King</surname> <given-names>JA</given-names></name><name><surname>Burgess</surname> <given-names>N</given-names></name><name><surname>O'Keefe</surname> <given-names>J</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>How vision and movement combine in the hippocampal place code</article-title><source>PNAS</source><volume>110</volume><fpage>378</fpage><lpage>383</lpage><pub-id pub-id-type="doi">10.1073/pnas.1215834110</pub-id><pub-id pub-id-type="pmid">23256159</pub-id></element-citation></ref><ref id="bib6"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Climer</surname> <given-names>JR</given-names></name><name><surname>DiTullio</surname> <given-names>R</given-names></name><name><surname>Newman</surname> <given-names>EL</given-names></name><name><surname>Hasselmo</surname> <given-names>ME</given-names></name><name><surname>Eden</surname> <given-names>UT</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>Examination of rhythmicity of extracellularly recorded neurons in the entorhinal cortex</article-title><source>Hippocampus</source><volume>25</volume><fpage>460</fpage><lpage>473</lpage><pub-id pub-id-type="doi">10.1002/hipo.22383</pub-id><pub-id pub-id-type="pmid">25331248</pub-id></element-citation></ref><ref id="bib7"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Cohen</surname> <given-names>JD</given-names></name><name><surname>Bolstad</surname> <given-names>M</given-names></name><name><surname>Lee</surname> <given-names>AK</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>Experience-dependent shaping of hippocampal CA1 intracellular activity in novel and familiar environments</article-title><source>eLife</source><volume>6</volume><elocation-id>e23040</elocation-id><pub-id pub-id-type="doi">10.7554/eLife.23040</pub-id><pub-id pub-id-type="pmid">28742496</pub-id></element-citation></ref><ref id="bib8"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Cushman</surname> <given-names>JD</given-names></name><name><surname>Aharoni</surname> <given-names>DB</given-names></name><name><surname>Willers</surname> <given-names>B</given-names></name><name><surname>Ravassard</surname> <given-names>P</given-names></name><name><surname>Kees</surname> <given-names>A</given-names></name><name><surname>Vuong</surname> <given-names>C</given-names></name><name><surname>Popeney</surname> <given-names>B</given-names></name><name><surname>Arisaka</surname> <given-names>K</given-names></name><name><surname>Mehta</surname> <given-names>MR</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>Multisensory control of multimodal behavior: do the legs know what the tongue is doing?</article-title><source>PLoS One</source><volume>8</volume><elocation-id>e80465</elocation-id><pub-id pub-id-type="doi">10.1371/journal.pone.0080465</pub-id><pub-id pub-id-type="pmid">24224054</pub-id></element-citation></ref><ref id="bib9"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Danielson</surname> <given-names>NB</given-names></name><name><surname>Zaremba</surname> <given-names>JD</given-names></name><name><surname>Kaifosh</surname> <given-names>P</given-names></name><name><surname>Bowler</surname> <given-names>J</given-names></name><name><surname>Ladow</surname> <given-names>M</given-names></name><name><surname>Losonczy</surname> <given-names>A</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Sublayer-Specific coding dynamics during spatial navigation and learning in hippocampal area CA1</article-title><source>Neuron</source><volume>91</volume><fpage>652</fpage><lpage>665</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2016.06.020</pub-id><pub-id pub-id-type="pmid">27397517</pub-id></element-citation></ref><ref id="bib10"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Dombeck</surname> <given-names>DA</given-names></name><name><surname>Harvey</surname> <given-names>CD</given-names></name><name><surname>Tian</surname> <given-names>L</given-names></name><name><surname>Looger</surname> <given-names>LL</given-names></name><name><surname>Tank</surname> <given-names>DW</given-names></name></person-group><year iso-8601-date="2010">2010</year><article-title>Functional imaging of hippocampal place cells at cellular resolution during virtual navigation</article-title><source>Nature Neuroscience</source><volume>13</volume><fpage>1433</fpage><lpage>1440</lpage><pub-id pub-id-type="doi">10.1038/nn.2648</pub-id><pub-id pub-id-type="pmid">20890294</pub-id></element-citation></ref><ref id="bib11"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Domnisoru</surname> <given-names>C</given-names></name><name><surname>Kinkhabwala</surname> <given-names>AA</given-names></name><name><surname>Tank</surname> <given-names>DW</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>Membrane potential dynamics of grid cells</article-title><source>Nature</source><volume>495</volume><fpage>199</fpage><lpage>204</lpage><pub-id pub-id-type="doi">10.1038/nature11973</pub-id><pub-id pub-id-type="pmid">23395984</pub-id></element-citation></ref><ref id="bib12"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Fyhn</surname> <given-names>M</given-names></name><name><surname>Hafting</surname> <given-names>T</given-names></name><name><surname>Witter</surname> <given-names>MP</given-names></name><name><surname>Moser</surname> <given-names>EI</given-names></name><name><surname>Moser</surname> <given-names>MB</given-names></name></person-group><year iso-8601-date="2008">2008</year><article-title>Grid cells in mice</article-title><source>Hippocampus</source><volume>18</volume><fpage>1230</fpage><lpage>1238</lpage><pub-id pub-id-type="doi">10.1002/hipo.20472</pub-id><pub-id pub-id-type="pmid">18683845</pub-id></element-citation></ref><ref id="bib13"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hafting</surname> <given-names>T</given-names></name><name><surname>Fyhn</surname> <given-names>M</given-names></name><name><surname>Bonnevie</surname> <given-names>T</given-names></name><name><surname>Moser</surname> <given-names>MB</given-names></name><name><surname>Moser</surname> <given-names>EI</given-names></name></person-group><year iso-8601-date="2008">2008</year><article-title>Hippocampus-independent phase precession in entorhinal grid cells</article-title><source>Nature</source><volume>453</volume><fpage>1248</fpage><lpage>1252</lpage><pub-id pub-id-type="doi">10.1038/nature06957</pub-id><pub-id pub-id-type="pmid">18480753</pub-id></element-citation></ref><ref id="bib14"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Harvey</surname> <given-names>CD</given-names></name><name><surname>Collman</surname> <given-names>F</given-names></name><name><surname>Dombeck</surname> <given-names>DA</given-names></name><name><surname>Tank</surname> <given-names>DW</given-names></name></person-group><year iso-8601-date="2009">2009</year><article-title>Intracellular dynamics of hippocampal place cells during virtual navigation</article-title><source>Nature</source><volume>461</volume><fpage>941</fpage><lpage>946</lpage><pub-id pub-id-type="doi">10.1038/nature08499</pub-id><pub-id pub-id-type="pmid">19829374</pub-id></element-citation></ref><ref id="bib15"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Heys</surname> <given-names>JG</given-names></name><name><surname>Rangarajan</surname> <given-names>KV</given-names></name><name><surname>Dombeck</surname> <given-names>DA</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>The functional micro-organization of grid cells revealed by cellular-resolution imaging</article-title><source>Neuron</source><volume>84</volume><fpage>1079</fpage><lpage>1090</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2014.10.048</pub-id><pub-id pub-id-type="pmid">25467986</pub-id></element-citation></ref><ref id="bib16"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hölscher</surname> <given-names>C</given-names></name><name><surname>Schnee</surname> <given-names>A</given-names></name><name><surname>Dahmen</surname> <given-names>H</given-names></name><name><surname>Setia</surname> <given-names>L</given-names></name><name><surname>Mallot</surname> <given-names>HA</given-names></name></person-group><year iso-8601-date="2005">2005</year><article-title>Rats are able to navigate in virtual environments</article-title><source>Journal of Experimental Biology</source><volume>208</volume><fpage>561</fpage><lpage>569</lpage><pub-id pub-id-type="doi">10.1242/jeb.01371</pub-id><pub-id pub-id-type="pmid">15671344</pub-id></element-citation></ref><ref id="bib17"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Jeewajee</surname> <given-names>A</given-names></name><name><surname>Barry</surname> <given-names>C</given-names></name><name><surname>Douchamps</surname> <given-names>V</given-names></name><name><surname>Manson</surname> <given-names>D</given-names></name><name><surname>Lever</surname> <given-names>C</given-names></name><name><surname>Burgess</surname> <given-names>N</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>Theta phase precession of grid and place cell firing in open environments</article-title><source>Philosophical Transactions of the Royal Society B: Biological Sciences</source><volume>369</volume><elocation-id>20120532</elocation-id><pub-id pub-id-type="doi">10.1098/rstb.2012.0532</pub-id><pub-id pub-id-type="pmid">24366140</pub-id></element-citation></ref><ref id="bib18"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kadir</surname> <given-names>SN</given-names></name><name><surname>Goodman</surname> <given-names>DF</given-names></name><name><surname>Harris</surname> <given-names>KD</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>High-dimensional cluster analysis with the masked EM algorithm</article-title><source>Neural Computation</source><volume>26</volume><fpage>2379</fpage><lpage>2394</lpage><pub-id pub-id-type="doi">10.1162/NECO_a_00661</pub-id><pub-id pub-id-type="pmid">25149694</pub-id></element-citation></ref><ref id="bib19"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kropff</surname> <given-names>E</given-names></name><name><surname>Carmichael</surname> <given-names>JE</given-names></name><name><surname>Moser</surname> <given-names>MB</given-names></name><name><surname>Moser</surname> <given-names>EI</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>Speed cells in the medial entorhinal cortex</article-title><source>Nature</source><volume>523</volume><fpage>419</fpage><lpage>424</lpage><pub-id pub-id-type="doi">10.1038/nature14622</pub-id><pub-id pub-id-type="pmid">26176924</pub-id></element-citation></ref><ref id="bib20"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Low</surname> <given-names>RJ</given-names></name><name><surname>Gu</surname> <given-names>Y</given-names></name><name><surname>Tank</surname> <given-names>DW</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>Cellular resolution optical access to brain regions in fissures: imaging medial prefrontal cortex and grid cells in entorhinal cortex</article-title><source>PNAS</source><volume>111</volume><fpage>18739</fpage><lpage>18744</lpage><pub-id pub-id-type="doi">10.1073/pnas.1421753111</pub-id><pub-id pub-id-type="pmid">25503366</pub-id></element-citation></ref><ref id="bib21"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>McFarland</surname> <given-names>WL</given-names></name><name><surname>Teitelbaum</surname> <given-names>H</given-names></name><name><surname>Hedges</surname> <given-names>EK</given-names></name></person-group><year iso-8601-date="1975">1975</year><article-title>Relationship between hippocampal theta activity and running speed in the rat</article-title><source>Journal of Comparative and Physiological Psychology</source><volume>88</volume><fpage>324</fpage><lpage>328</lpage><pub-id pub-id-type="doi">10.1037/h0076177</pub-id><pub-id pub-id-type="pmid">1120805</pub-id></element-citation></ref><ref id="bib22"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>McNaughton</surname> <given-names>BL</given-names></name><name><surname>Barnes</surname> <given-names>CA</given-names></name><name><surname>O'Keefe</surname> <given-names>J</given-names></name></person-group><year iso-8601-date="1983">1983</year><article-title>The contributions of position, direction, and velocity to single unit activity in the Hippocampus of freely-moving rats</article-title><source>Experimental Brain Research</source><volume>52</volume><fpage>41</fpage><lpage>49</lpage><pub-id pub-id-type="doi">10.1007/BF00237147</pub-id><pub-id pub-id-type="pmid">6628596</pub-id></element-citation></ref><ref id="bib23"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>McNaughton</surname> <given-names>BL</given-names></name><name><surname>Battaglia</surname> <given-names>FP</given-names></name><name><surname>Jensen</surname> <given-names>O</given-names></name><name><surname>Moser</surname> <given-names>EI</given-names></name><name><surname>Moser</surname> <given-names>M-B</given-names></name></person-group><year iso-8601-date="2006">2006</year><article-title>Path integration and the neural basis of the 'cognitive map'</article-title><source>Nature Reviews Neuroscience</source><volume>7</volume><fpage>663</fpage><lpage>678</lpage><pub-id pub-id-type="doi">10.1038/nrn1932</pub-id></element-citation></ref><ref id="bib24"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Minderer</surname> <given-names>M</given-names></name><name><surname>Harvey</surname> <given-names>CD</given-names></name><name><surname>Donato</surname> <given-names>F</given-names></name><name><surname>Moser</surname> <given-names>EI</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Neuroscience: Virtual reality explored</article-title><source>Nature</source><volume>533</volume><fpage>324</fpage><lpage>325</lpage><pub-id pub-id-type="doi">10.1038/nature17899</pub-id><pub-id pub-id-type="pmid">27193673</pub-id></element-citation></ref><ref id="bib25"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Morris</surname> <given-names>RG</given-names></name><name><surname>Garrud</surname> <given-names>P</given-names></name><name><surname>Rawlins</surname> <given-names>JN</given-names></name><name><surname>O'Keefe</surname> <given-names>J</given-names></name></person-group><year iso-8601-date="1982">1982</year><article-title>Place navigation impaired in rats with hippocampal lesions</article-title><source>Nature</source><volume>297</volume><fpage>681</fpage><lpage>683</lpage><pub-id pub-id-type="doi">10.1038/297681a0</pub-id><pub-id pub-id-type="pmid">7088155</pub-id></element-citation></ref><ref id="bib26"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Muller</surname> <given-names>RU</given-names></name><name><surname>Bostock</surname> <given-names>E</given-names></name><name><surname>Taube</surname> <given-names>JS</given-names></name><name><surname>Kubie</surname> <given-names>JL</given-names></name></person-group><year iso-8601-date="1994">1994</year><article-title>On the directional firing properties of hippocampal place cells</article-title><source>The Journal of Neuroscience</source><volume>14</volume><fpage>7235</fpage><lpage>7251</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.14-12-07235.1994</pub-id><pub-id pub-id-type="pmid">7996172</pub-id></element-citation></ref><ref id="bib27"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>O'Keefe</surname> <given-names>J</given-names></name><name><surname>Recce</surname> <given-names>ML</given-names></name></person-group><year iso-8601-date="1993">1993</year><article-title>Phase relationship between hippocampal place units and the EEG theta rhythm</article-title><source>Hippocampus</source><volume>3</volume><fpage>317</fpage><lpage>330</lpage><pub-id pub-id-type="doi">10.1002/hipo.450030307</pub-id><pub-id pub-id-type="pmid">8353611</pub-id></element-citation></ref><ref id="bib28"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ravassard</surname> <given-names>P</given-names></name><name><surname>Kees</surname> <given-names>A</given-names></name><name><surname>Willers</surname> <given-names>B</given-names></name><name><surname>Ho</surname> <given-names>D</given-names></name><name><surname>Aharoni</surname> <given-names>DA</given-names></name><name><surname>Cushman</surname> <given-names>J</given-names></name><name><surname>Aghajan</surname> <given-names>ZM</given-names></name><name><surname>Mehta</surname> <given-names>MR</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>Multisensory control of hippocampal spatiotemporal selectivity</article-title><source>Science</source><volume>340</volume><fpage>1342</fpage><lpage>1346</lpage><pub-id pub-id-type="doi">10.1126/science.1232655</pub-id><pub-id pub-id-type="pmid">23641063</pub-id></element-citation></ref><ref id="bib29"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Rivas</surname> <given-names>J</given-names></name><name><surname>Gaztelu</surname> <given-names>JM</given-names></name><name><surname>García-Austt</surname> <given-names>E</given-names></name></person-group><year iso-8601-date="1996">1996</year><article-title>Changes in hippocampal cell discharge patterns and theta rhythm spectral properties as a function of walking velocity in the guinea pig</article-title><source>Experimental Brain Research</source><volume>108</volume><fpage>113</fpage><lpage>118</lpage><pub-id pub-id-type="doi">10.1007/BF00242908</pub-id><pub-id pub-id-type="pmid">8721159</pub-id></element-citation></ref><ref id="bib30"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Royer</surname> <given-names>S</given-names></name><name><surname>Zemelman</surname> <given-names>BV</given-names></name><name><surname>Losonczy</surname> <given-names>A</given-names></name><name><surname>Kim</surname> <given-names>J</given-names></name><name><surname>Chance</surname> <given-names>F</given-names></name><name><surname>Magee</surname> <given-names>JC</given-names></name><name><surname>Buzsáki</surname> <given-names>G</given-names></name></person-group><year iso-8601-date="2012">2012</year><article-title>Control of timing, rate and bursts of hippocampal place cells by dendritic and somatic inhibition</article-title><source>Nature Neuroscience</source><volume>15</volume><fpage>769</fpage><lpage>775</lpage><pub-id pub-id-type="doi">10.1038/nn.3077</pub-id><pub-id pub-id-type="pmid">22446878</pub-id></element-citation></ref><ref id="bib31"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Russell</surname> <given-names>NA</given-names></name><name><surname>Horii</surname> <given-names>A</given-names></name><name><surname>Smith</surname> <given-names>PF</given-names></name><name><surname>Darlington</surname> <given-names>CL</given-names></name><name><surname>Bilkey</surname> <given-names>DK</given-names></name></person-group><year iso-8601-date="2006">2006</year><article-title>Lesions of the vestibular system disrupt hippocampal theta rhythm in the rat</article-title><source>Journal of Neurophysiology</source><volume>96</volume><fpage>4</fpage><lpage>14</lpage><pub-id pub-id-type="doi">10.1152/jn.00953.2005</pub-id><pub-id pub-id-type="pmid">16772515</pub-id></element-citation></ref><ref id="bib32"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Sargolini</surname> <given-names>F</given-names></name><name><surname>Fyhn</surname> <given-names>M</given-names></name><name><surname>Hafting</surname> <given-names>T</given-names></name><name><surname>McNaughton</surname> <given-names>BL</given-names></name><name><surname>Witter</surname> <given-names>MP</given-names></name><name><surname>Moser</surname> <given-names>MB</given-names></name><name><surname>Moser</surname> <given-names>EI</given-names></name></person-group><year iso-8601-date="2006">2006</year><article-title>Conjunctive representation of position, direction, and velocity in entorhinal cortex</article-title><source>Science</source><volume>312</volume><fpage>758</fpage><lpage>762</lpage><pub-id pub-id-type="doi">10.1126/science.1125572</pub-id><pub-id pub-id-type="pmid">16675704</pub-id></element-citation></ref><ref id="bib33"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Schmidt-Hieber</surname> <given-names>C</given-names></name><name><surname>Häusser</surname> <given-names>M</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>Cellular mechanisms of spatial navigation in the medial entorhinal cortex</article-title><source>Nature Neuroscience</source><volume>16</volume><fpage>325</fpage><lpage>331</lpage><pub-id pub-id-type="doi">10.1038/nn.3340</pub-id><pub-id pub-id-type="pmid">23396102</pub-id></element-citation></ref><ref id="bib34"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Sławińska</surname> <given-names>U</given-names></name><name><surname>Kasicki</surname> <given-names>S</given-names></name></person-group><year iso-8601-date="1998">1998</year><article-title>The frequency of rat's hippocampal theta rhythm is related to the speed of locomotion</article-title><source>Brain Research</source><volume>796</volume><fpage>327</fpage><lpage>331</lpage><pub-id pub-id-type="doi">10.1016/S0006-8993(98)00390-4</pub-id><pub-id pub-id-type="pmid">9689489</pub-id></element-citation></ref><ref id="bib35"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Tcheang</surname> <given-names>L</given-names></name><name><surname>Bülthoff</surname> <given-names>HH</given-names></name><name><surname>Burgess</surname> <given-names>N</given-names></name></person-group><year iso-8601-date="2011">2011</year><article-title>Visual influence on path integration in darkness indicates a multimodal representation of large-scale space</article-title><source>PNAS</source><volume>108</volume><fpage>1152</fpage><lpage>1157</lpage><pub-id pub-id-type="doi">10.1073/pnas.1011843108</pub-id><pub-id pub-id-type="pmid">21199934</pub-id></element-citation></ref><ref id="bib36"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Towse</surname> <given-names>BW</given-names></name><name><surname>Barry</surname> <given-names>C</given-names></name><name><surname>Bush</surname> <given-names>D</given-names></name><name><surname>Burgess</surname> <given-names>N</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>Optimal configurations of spatial scale for grid cell firing under noise and uncertainty</article-title><source>Philosophical transactions of the Royal Society of London. Series B, Biological sciences</source><volume>369</volume><elocation-id>20130290</elocation-id><pub-id pub-id-type="doi">10.1098/rstb.2013.0290</pub-id><pub-id pub-id-type="pmid">24366144</pub-id></element-citation></ref><ref id="bib37"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Villette</surname> <given-names>V</given-names></name><name><surname>Malvache</surname> <given-names>A</given-names></name><name><surname>Tressard</surname> <given-names>T</given-names></name><name><surname>Dupuy</surname> <given-names>N</given-names></name><name><surname>Cossart</surname> <given-names>R</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>Internally Recurring Hippocampal Sequences as a Population Template of Spatiotemporal Information</article-title><source>Neuron</source><volume>88</volume><fpage>357</fpage><lpage>366</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2015.09.052</pub-id><pub-id pub-id-type="pmid">26494280</pub-id></element-citation></ref><ref id="bib38"><element-citation publication-type="preprint"><person-group person-group-type="author"><name><surname>Voigts</surname> <given-names>J</given-names></name><name><surname>Harnett</surname> <given-names>M</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>An animal-actuated rotational head-fixation system for 2-photon imaging during 2-d navigation</article-title><source>bioRxiv</source><pub-id pub-id-type="doi">10.1101/262543</pub-id></element-citation></ref></ref-list></back><sub-article article-type="decision-letter" id="SA1"><front-stub><article-id pub-id-type="doi">10.7554/eLife.34789.025</article-id><title-group><article-title>Decision letter</article-title></title-group><contrib-group><contrib contrib-type="editor"><name><surname>Colgin</surname><given-names>Laura</given-names></name><role>Reviewing Editor</role><aff id="aff6"><institution>The University of Texas at Austin, Center for Learning and Memory</institution><country>United States</country></aff></contrib></contrib-group></front-stub><body><boxed-text><p>In the interests of transparency, eLife includes the editorial decision letter and accompanying author responses. A lightly edited version of the letter sent to the authors after peer review is shown, indicating the most substantive concerns; minor comments are not usually included.</p></boxed-text><p>Thank you for sending your article entitled &quot;Spatial cell firing during virtual navigation of open arenas by head-restrained mice&quot; for peer review at <italic>eLife</italic>. Your article is being evaluated by three peer reviewers, and the evaluation is being overseen by a Reviewing Editor and Michael Frank as the Senior Editor.</p><p>Given the list of essential revisions, including new experiments, the editors and reviewers invite you to respond within the next two weeks with an action plan and timetable for the completion of the additional work. We plan to share your responses with the reviewers and then issue a binding recommendation.</p><p>All reviewers found many positive aspects about the paper. However, the reviewers raised major concerns about your claims regarding neural activity differences between virtual reality and real world environments, an important and crucial component of the work. Reviewers felt that the reported differences are not strongly supported by the results (in their present form) because of potential confounds such as fixed sequence of the two experiences (i.e., virtual reality was always experienced before real world), richness of cues in the testing environments (i.e., virtual reality was a cue-rich environment; real world was surrounded by curtains and only included a single cue), etc. A complete list of reviewers' concerns is provided below.</p><p><italic>Reviewer #1:</italic> </p><p>In the current manuscript, the authors demonstrate a mouse virtual reality (VR) system, which allows head-restrained mice to navigate in a two-dimensional (2D) environment. The key new feature is a bearing attached to an implanted head-plate that allows the mouse's head to be restrained, but able to rotate around a vertical axis on the surface of a spherical treadmill; self-induced rotations in space are possible using this system, while maintaining a level of head restraint that would facilitate the use of optical measurements of neural activity in the future. The authors successfully recorded characteristic firing patterns of place cells in the hippocampus and grid and head direction cells in the medial entorhinal cortex (MEC), and they compared the activity features of these cells with those in real (R) environments. Overall, the development of the mouse 2D VR is an advance for the field, as it allows precise control of animal's environment and is potentially compatible with two-photon based calcium imaging of neural population activity. However, some conclusions of the study, in particular the comparisons between R and VR, are less supported and require more analyses. In addition, the writing of the manuscript needs to be improved, as explained below.</p><p>1) Analysis of VR electrophysiology during behavior</p><p>The behaviors studied in the R and VR environments are distinct. In R, animals are randomly foraging based on visual and olfactory cues, whereas in VR animals are either randomly foraging based on visual cues or simply navigating to a fixed location. Random foraging and navigating to a fixed location are very different behaviors. It is surprising that the electrophysiology from these two VR behavioral modes was not analyzed separately, given that distinct computations might support distinct behaviors. It is possible that if analyzed separately, the two similar behaviors (random foraging in R vs. VR) would have more similar electrophysiological profiles, and that the non-random navigation in VR accounts for the entirety of the difference in R vs. VR. In addition, the authors should make clear in the Results what behavioral paradigm is being used. Is it random foraging + morris water maze in VR, or just random foraging, etc.?</p><p>Finally, authors should motivate the choice to use two differently-sized boxes for recording and clarify when data were pooled from both boxes or separately analyzed?</p><p>2) VR vs. R interpretation</p><p>The authors suggest different mechanisms for the observed differences in activity between R and VR in the Abstract. However, there are at least three types of concerns about R vs. VR comparisons, detailed below:</p><p>Visual differences between R and VR</p><p>The virtual reality and real environments are visually completely different (VR: Cue-rich square with multiple wall textures, colors, and encompassing environment vs. R: square box with black curtains and white cue card as only polarizing feature, subsection “Screening for spatial cells”). How do the authors know that the differing behavioral and electrophysiological results are due to VR vs. R, or translational vestibular inputs, rather than the large difference in visual environments? The authors should specify in the Abstract that the observed phenomenological differences apply to this particular R vs. VR setup. Additionally, the authors should discuss the possibility of confounds in their interpretation (e.g. due to visual differences in their R vs. VR environments) in the Discussion.</p><p>Residual impact of real world on VR recordings</p><p>For example, if expansion of field sizes reflected spatial uncertainty caused by the conflict between uncontrolled distal cues with virtual cues, was there any clue in the current data suggesting this conflict? It would be interesting to know during virtual navigation what percentages of cells in hippocampus and dmEC were still responding to cues in the real environment (classified as place or grid cells using the coordinates of the real environment). For the place/grid/head direction cells, which were classified in the real environment but not the virtual environment, what did their activity patterns in the virtual environment look like? When the virtual environment was rotated 180°, what percentage of cells followed and did not follow this rotation? Conclusions of these analyses may reveal the potential conflict.</p><p>Missing local cues in VR</p><p>The authors state that 'omni-directional place cell firing in R reflects local cues unavailable in VR'. This conclusion would be much more believable if this directionality were observed in at least a different, additional VR environment. If the authors recorded cells in a different VR, did they see the same increase of directionality of place cells? Otherwise, is it possible that the directionality in VR was due to this particular VR design? Furthermore, could the authors clarify what they mean by 'local cues' – do they refer to olfactory or tactile cues?</p><p>In light of these potential caveats, it appears inappropriate to state the suggested mechanisms comprising the second half of the Abstract without further analysis. The authors should either provide more evidence, or temper/remove these claims from the Abstract.</p><p>3) Tetrode placement</p><p>Histological data verifying tetrode placement is the standard for this type of experiment, but it is not provided in the manuscript.</p><p>4) Fraction of place cells</p><p>The fraction of place cells in CA1 in this manuscript is ~75%, which seems unusually high. Could the authors provide commentary about the reasons for this?</p><p><italic>Reviewer #2:</italic> </p><p>This manuscript demonstrates that place/grid cells can be recorded from head-fixed mice in a virtual reality preparation, provided that the animal can rotate its head on a linear plane. They compared the place/firing fields of these place/grid cells with those recorded in equivalent real environments. They observed two major differences. Firstly, the place/firing fields of both place and grid cells expanded to a similar degree, approximately 1.4 times relative to the real environment. Although the speed of the animals modulated the firing rate these cells, the frequency of theta oscillations exhibited a weaker speed modulation in the virtual environment. Therefore, the vestibular inputs related to linear acceleration affected the theta oscillatory system whereas the spatially firing cells used other means for speed coding. As the authors point out, it is possible that spatial expansion is related to the weaker speed modulation of theta oscillations. The work is important for two reasons: firstly it introduces a new technique to study the activity of place coding cells in virtual two-dimensional environments with a potential to use it in head-fixed imaging preparations as well. Secondly, it demonstrates that speed encoding mechanism of spatial firing cells and those of theta oscillations are different and it implies that the lack of linear acceleratory vestibular inputs leads to the expansion of firing fields of both place and grid cells. Both of these are important for the understanding the mechanism behind the firing of place/grid cells. I have only a few questions and suggestions.</p><p>1) Not sure whether place/firing field sizes of place/grid cells is modulated by speed in either the real or virtual environments. If so, comparing firing fields at speed ranges associated with similar theta frequency in both preparations could give more insight as to whether place field expansion and theta frequency speed modulation are related.</p><p>2) The firing of place and grid cells are influenced to a large degree by theta oscillation. In particular, they fire periodically with a slightly faster frequency than theta oscillations, a property enabling theta phase precession. Given that in speed modulation these cells acted differently from theta oscillation, one may wonder whether their periodic firing may also be different in a virtual environment to that of the field oscillations. So it is possible that their periodic modulation may not follow the theta frequency fluctuations with a consistently faster periodicity. I understand that cells may not fire a sufficient number of action potentials for such an analysis but perhaps the analysis could be performed for some broader speed ranges or simply checking whether the periodicity difference of the autocorrelations and those of detected theta waves on average show similar consistent differences for the real and virtual environments. If so, this would imply impairment in two-dimensional phase precession and suggest that place cells can be modulated with both vestibular dependent and independent inputs.</p><p><italic>Reviewer #3:</italic> </p><p>The authors demonstrate a new head-fixed method that can be used with mice to study behavior in VR with the freedom of horizontal head and body movement. This is a novel set up, and in many ways is an improvement on traditional head-fixed methods in VR. For example, the authors show they can observe head-direction cells and 2D place fields that are similar to real worlds. As the authors discuss, VR brings many benefits to experimenters, by providing greater control over the animal's experience. The author's novel head-fixed method brings the VR experience closer to a real-world experience, without any loss in experimenter control. For these reasons, I believe this is a useful method for the study of spatial representations, and other processes, during well-controlled behavior. But I do have some concerns that I believe should be addressed before publication of this paper (see below).</p><p>In their Materials and methods section it is reported that on each recording day mice always experienced VR followed by R (subsection “Recording spatial cell activity”). This is a potential confound. It would be a good idea to reverse the order to determine whether any differences in spatial representations that are reported in this paper are caused by the sequence of the two experiences. This is important, as a major component of this paper is that certain measures of place and grid fields are different in VR vs R. Fatigue and attention could affect spatial representations, and these processes change over time. Therefore the time relationship should be taken into consideration before any major conclusions are made. On this note, the authors also state that the VR session was always twice as long as the R session (40 min vs. 20 min, respectively). To avoid any potential confounds that differences in session length might bring to the data, it would be best to compare data from the first 20 min in VR to the 20 min session in R.</p><p>Could this setup really be used with multi photon imaging? It's hard to imagine this would work given the major rotational movement of the brain. In theory, it is possible, but in practice it would be very difficult. It is potentially misleading to make this claim without evidence. The authors do say &quot;potentially compatible with 2P imaging&quot;, which is good, but I think they should discuss how to implement it in more detail than they have, maybe by discussing the problems that would need to be overcome, in lieu of showing evidence that it works.</p><p>The% of place cells reported by the authors in CA1 is very high: 186/231 in VR is 81%, and 175/231 in R is 76%. Most studies have found approximately 30% of CA1 cells have significant place fields. Why is the% reported here so different? This should be discussed.</p><p>What about phase precession in R vs. VR? The authors show that running speed vs. theta frequency is different in R vs. VR, but spike rates in PFs vs. running speed are similar in R vs. VR, which would suggest differences in phase precession between the two experiences. The authors should have this data, so it would be a nice addition to the paper if they analyzed it and presented here. I think readers of this paper would want to know about this.</p><p>[Editors' note: the authors’ plan for revisions was approved and the authors made a formal revised submission.]</p></body></sub-article><sub-article article-type="reply" id="SA2"><front-stub><article-id pub-id-type="doi">10.7554/eLife.34789.026</article-id><title-group><article-title>Author response</article-title></title-group></front-stub><body><disp-quote content-type="editor-comment"><p>Reviewer #1:</p><p>[…] However, some conclusions of the study, in particular the comparisons between R and VR, are less supported and require more analyses. In addition, the writing of the manuscript needs to be improved, as explained below.</p><p>1) Analysis of VR electrophysiology during behavior</p><p>The behaviors studied in the R and VR environments are distinct. In R, animals are randomly foraging based on visual and olfactory cues, whereas in VR animals are either randomly foraging based on visual cues or simply navigating to a fixed location. Random foraging and navigating to a fixed location are very different behaviors. It is surprising that the electrophysiology from these two VR behavioral modes was not analyzed separately, given that distinct computations might support distinct behaviors. It is possible that if analyzed separately, the two similar behaviors (random foraging in R vs. VR) would have more similar electrophysiological profiles, and that the non-random navigation in VR accounts for the entirety of the difference in R vs. VR. In addition, the authors should make clear in the Results what behavioral paradigm is being used. Is it random foraging + morris water maze in VR, or just random foraging, etc.?</p></disp-quote><p>All recordings presented were from the random foraging task (in R and in VR) – this was mentioned in the Materials and methods (subsections “Screening for spatial cells” and “Recording spatial cell activity”, first paragraph) and is now clarified in the second paragraph of the subsection “Electrophysiology”.</p><disp-quote content-type="editor-comment"><p>Finally, authors should motivate the choice to use two differently-sized boxes for recording and clarify when data were pooled from both boxes or separately analyzed?</p></disp-quote><p>We explored different sizes for the virtual environment during development of the paradigm. All data were presented pooled across sizes. We have now performed separate analyses for trials in 60x60cm and 90x90cm VR environments and their respective within-session real-world (R) trials (Figure 4—figure supplement 1). For place cells, similar results were seen irrespective of whether recordings took place in the 60x60cm or 90x90cm VR environments (e.g., the place field expansion factor being 1.44 in 90cm, 1.43 in 60cm, p=0.66), referred to in the third paragraph of the subsection “Electrophysiology”. For grid cells, similar results were also seen irrespective of whether recordings took place in the 60x60cm or 90x90cm VR environments (e.g., the grid scale expansion factor being 1.43 in 60cm, 1.36 in 90cm, p=0.78), although there were minor differences (the reduction in spatial information only reaching significance in the 60x60cm VR and that in directional information only reaching significance in the 90x90cm VR), referred to in the fifth paragraph of the aforementioned subsection.</p><disp-quote content-type="editor-comment"><p>2) VR vs. R interpretation</p><p>The authors suggest different mechanisms for the observed differences in activity between R and VR in the Abstract. However, there are at least three types of concerns about R vs. VR comparisons, detailed below:</p><p>Visual differences between R and VR</p><p>The virtual reality and real environments are visually completely different (VR: Cue-rich square with multiple wall textures, colors, and encompassing environment vs. R: square box with black curtains and white cue card as only polarizing feature, subsection “Screening for spatial cells”). How do the authors know that the differing behavioral and electrophysiological results are due to VR vs. R, or translational vestibular inputs, rather than the large difference in visual environments? The authors should specify in the Abstract that the observed phenomenological differences apply to this particular R vs. VR setup. Additionally, the authors should discuss the possibility of confounds in their interpretation (e.g. due to visual differences in their R vs. VR environments) in the Discussion.</p></disp-quote><p>The walls of the R square box was patterned and coloured similarly to the VR environment, we apologise for the lack of clarity. A picture has been added (Figure 3—figure supplement 2A). However, the point remains valid that other (visual) differences between the R and VR environments could contribute to the differences observed in neural firing. To address this we performed further recordings in a second pair of (cylindrical) virtual and real environments – to check that differences between virtual and real environments are general to both square and cylindrical environments (Figure 3—figure supplement 2). This has been acknowledged, and discussed in the fourth paragraph of the subsection “Electrophysiology” and in the seventh paragraph of the Discussion.</p><disp-quote content-type="editor-comment"><p>Residual impact of real world on VR recordings</p><p>For example, if expansion of field sizes reflected spatial uncertainty caused by the conflict between uncontrolled distal cues with virtual cues, was there any clue in the current data suggesting this conflict? It would be interesting to know during virtual navigation what percentages of cells in hippocampus and dmEC were still responding to cues in the real environment (classified as place or grid cells using the coordinates of the real environment). For the place/grid/head direction cells, which were classified in the real environment but not the virtual environment, what did their activity patterns in the virtual environment look like? When the virtual environment was rotated 180°, what percentage of cells followed and did not follow this rotation? Conclusions of these analyses may reveal the potential conflict.</p></disp-quote><p>We have examined the virtual firing patterns of cells classified as place, grid or head-direction cells in R but not in VR. In general, they have weaker spatial tuning in VR than R (as would be expected given the classifications) but we saw no specific pattern to this. For example it is not that the spatial tuning is present on a time-windowed spatial auto-correlogram but drifts over time and so does not appear in the full rate map. We have also investigated the firing of cells in the 180° rotation of the virtual environment (and the entry point to it). All head-direction cells and grid cells did follow the rotation. For place cells, 7/141 (5%), failed to follow the rotation. These place cells show much lower spatial information scores in both the R and VR conditions (see Figure 6—figure supplement 1), indicating that their lack of rotation might be the result of their weaker or less stable spatial tuning to the proximal environmental cues that were rotated. We have added reference to these results in the ninth paragraph of the subsection “Electrophysiology”.</p><p>We were not able to classify firing in VR trials as place or grid cells using the coordinates of the real environment, because the mouse’s head only occupies one real-world location during these trials (and this location was within the real recording environment).</p><disp-quote content-type="editor-comment"><p>Missing local cues in VR</p><p>The authors state that 'omni-directional place cell firing in R reflects local cues unavailable in VR'. This conclusion would be much more believable if this directionality were observed in at least a different, additional VR environment. If the authors recorded cells in a different VR, did they see the same increase of directionality of place cells? Otherwise, is it possible that the directionality in VR was due to this particular VR design? Furthermore, could the authors clarify what they mean by 'local cues' – do they refer to olfactory or tactile cues?</p></disp-quote><p>We investigated further whether the increased directionality of place cell firing in VR was specific to the square VR environment, by performing additional recordings of both place and grid cells while animals foraged in (visually similar) cylindrical and square R and VR environments (in 4 mice, 3 new to the experiment, yielding a total of 90 place and 9 grid cells). The increased directionality of place cells but not grid cells in VR was present in both cylinder and square environments, supporting the generality of the result (see Figure 3—figure supplement 2). Referred to in the fourth paragraph of the subsection “Electrophysiology”.</p><p>We have clarified the intended meaning of local cues (Discussion, seventh paragraph) – uncontrolled cues to location that are stable within one trial (but may well not be from trial to trial, as the apparatus is often cleaned and</p><p>swapped/rotated between trials): olfactory, tactile. Notably, these local cues can be sensed independently of the orientation of the animal, unlike visual cues.</p><disp-quote content-type="editor-comment"><p>In light of these potential caveats, it appears inappropriate to state the suggested mechanisms comprising the second half of the Abstract without further analysis. The authors should either provide more evidence, or temper/remove these claims from the Abstract.</p></disp-quote><p>We appreciate this point and have clarified the meaning of local cues (Discussion, seventh paragraph), added the data from cylindrical trials (Figure 3—figure supplement 2), and tempered our claims (‘may require’ – Abstract, ‘may indicate’ – Discussion).</p><disp-quote content-type="editor-comment"><p>3) Tetrode placement</p><p>Histological data verifying tetrode placement is the standard for this type of experiment, but it is not provided in the manuscript.</p></disp-quote><p>We now provide histological verification of electrode locations in all the 11 animals in the main experiment (Figure 5—figure supplement 1). As noted in our plan of action, we are not able to provide histology for the 3 new animals used.</p><disp-quote content-type="editor-comment"><p>4) Fraction of place cells</p><p>The fraction of place cells in CA1 in this manuscript is ~75%, which seems unusually high. Could the authors provide commentary about the reasons for this?</p></disp-quote><p>The proportion of 75% place cells is fairly usual as a proportion of the active cells recorded in dorsal CA1 during foraging in a specific environment. See e.g. (Wills et al., 2010; Langston et al., 2010) for similar proportions in adult rats. It is also true that the proportion of place cells that are active in any specific environment is around 30% of all cells (e.g. Guzowski et al., 1999) – but the other 70% of cells are not active (and thus we cannot estimate their number on the basis of in vivo electrophysiology).</p><disp-quote content-type="editor-comment"><p>Reviewer #2:</p><p>[…] 1) Not sure whether place/firing field sizes of place/grid cells is modulated by speed in either the real or virtual environments. If so, comparing firing fields at speed ranges associated with similar theta frequency in both preparations could give more insight as to whether place field expansion and theta frequency speed modulation are related.</p></disp-quote><p>We have investigated the size of place and grid cell firing fields as a function of running speed in R and VR (Figure 7—figure supplement 1). There is a modulation of field size by running speed, which is similar in R and VR environments.</p><p>However this modulation is too small and non-monotonic to be able to explain differences in field size across R and VR in terms of differences in theta frequency. Thus, although theta frequency at 3-13 cm/s in R is approximately the same as theta frequency at 23-33cm/s in VR, field sizes are larger in VR than in R in both low and high speed bands. This is referred to in the tenth paragraph of the subsection “Electrophysiology”.</p><disp-quote content-type="editor-comment"><p>2) The firing of place and grid cells are influenced to a large degree by theta oscillation. In particular, they fire periodically with a slightly faster frequency than theta oscillations, a property enabling theta phase precession. Given that in speed modulation these cells acted differently from theta oscillation, one may wonder whether their periodic firing may also be different in a virtual environment to that of the field oscillations. So it is possible that their periodic modulation may not follow the theta frequency fluctuations with a consistently faster periodicity. I understand that cells may not fire a sufficient number of action potentials for such an analysis but perhaps the analysis could be performed for some broader speed ranges or simply checking whether the periodicity difference of the autocorrelations and those of detected theta waves on average show similar consistent differences for the real and virtual environments. If so, this would imply impairment in two-dimensional phase precession and suggest that place cells can be modulated with both vestibular dependent and independent inputs.</p></disp-quote><p>We have determined the theta-band frequency modulation of firing of theta-modulated cells and compared them to the LFP theta frequency in R and VR (new Figure 8A). This shows that firing frequency is slightly higher than the LFP the frequency, in R and VR despite the lower overall frequencies in VR, consistent with theta phase precession. We also analysed phase precession in theta-modulated place and grid cells – showing normal phase precession in VR as in R (with a lower slope consistent with the larger firing fields in VR, but the correlation between slope and field size only reaching significance for place fields in R). These results indicate that theta phase precession in place and grid cells is independent of linear vestibular acceleration signals and the absolute value of theta frequency. Text has been added in the last paragraph of the Results subsection “Electrophysiology”, in the eighth paragraph of the Discussion, and in the Abstract. Methods are included in the last paragraph of the subsection “Firing rate map construction and spatial cell classification”.</p><disp-quote content-type="editor-comment"><p>Reviewer #3:</p><p>[…] In their Materials and methods section it is reported that on each recording day mice always experienced VR followed by R (subsection “Recording spatial cell activity”). This is a potential confound. It would be a good idea to reverse the order to determine whether any differences in spatial representations that are reported in this paper are caused by the sequence of the two experiences. This is important, as a major component of this paper is that certain measures of place and grid fields are different in VR vs R. Fatigue and attention could affect spatial representations, and these processes change over time. Therefore the time relationship should be taken into consideration before any major conclusions are made. On this note, the authors also state that the VR session was always twice as long as the R session (40 min vs. 20 min, respectively). To avoid any potential confounds that differences in session length might bring to the data, it would be best to compare data from the first 20 min in VR to the 20 min session in R.</p></disp-quote><p>We ran VR trials first as we were anxious to have well-motived animals in our initial attempts to get 2d VR to work, and because previous experiments, including our own, show that effects of trial order on spatial firing patterns are small (see e.g. grid cells in mice, Brun et al., 2008; Carpenter et al., 2017; place cells in mice Nakazawa et al., 2002).</p><p>To check whether any differences between R and VR could reflect the trial order (VR before R), we have now recorded additional data from place and grid cells in R and VR on days in which R trials both preceded and followed VR trials (in 4 mice, 3 new to the experiment). We also included analysis of the first 20 mins of VR trials (matching the length of R trials, see Figure 4—figure supplement 2). Under these conditions, the firing properties of grid and place cells are broadly similar to those shown in Figures 3 and 4, indicating the generality of these findings (subsection “Electrophysiology”, seventh paragraph).</p><p>However, the 20 grid cells in this group did show lower gridness scores in VR than R, and 43 cells were classified as grid cells in R but only 24 as grid cells in VR. Thus grid cell firing patterns can be sensitive to the use of VR and the inherent conflict between virtual and uncontrolled cues to translation. The extra sensitivity in the second group of animals might reflect their greater age at test (mice with grid cells, main experiment: n=8, age=25.4 ± 4.3 weeks; additional experiment: n=3, age=40.1 ± 11.2 weeks; t(9)=-3.34, p&lt;.01) but this would require further verification (see the aforementioned paragraph)).</p><disp-quote content-type="editor-comment"><p>Could this setup really be used with multi photon imaging? It's hard to imagine this would work given the major rotational movement of the brain. In theory, it is possible, but in practice it would be very difficult. It is potentially misleading to make this claim without evidence. The authors do say &quot;potentially compatible with 2P imaging&quot;, which is good, but I think they should discuss how to implement it in more detail than they have, maybe by discussing the problems that would need to be overcome, in lieu of showing evidence that it works.</p></disp-quote><p>We agree that the issue of feasibility could be discussed further. The problem is to build rotation correction into the processing pipeline in the same way that translation (both rigid body and locally varying) is corrected (e.g. Pnevmatikakis et al., 2016; Pachitariu et al., 2017). However, by recording the mouse’s head rotation directly, it is straightforward to remove the rigid body rotation, so that the remaining motion can be attacked with existing methods. A reasonably standard setup for 2 photon calcium imaging would be acquisition of 200μm square images at 30Hz. So the problem comes down to how much rotation occurs within the acquisition of each frame. The mean rotation rate (Figure 1N) is 25<sup>o</sup>/s or &lt; 1<sup>o</sup>/frame, equivalent to a systematic displacement of each scan line that is &lt; 2μm (~ 100μm x π/180 rads towards the ends). As this is well within the brain movement currently compensated for (e.g. Kong et al., 2016) we see this as feasible. Indeed a recent paper on bioRxiv (Voigts and Harnett, 2018) demonstrates a solution to exactly this problem – we have now added a reference to the end of the Discussion to point this out.</p><disp-quote content-type="editor-comment"><p>The% of place cells reported by the authors in CA1 is very high: 186/231 in VR is 81%, and 175/231 in R is 76%. Most studies have found approximately 30% of CA1 cells have significant place fields. Why is the% reported here so different? This should be discussed.</p></disp-quote><p>Please see answer to reviewer 1’s point 4.</p><disp-quote content-type="editor-comment"><p>What about phase precession in R vs. VR? The authors show that running speed vs. theta frequency is different in R vs. VR, but spike rates in PFs vs. running speed are similar in R vs. VR, which would suggest differences in phase precession between the two experiences. The authors should have this data, so it would be a nice addition to the paper if they analyzed it and presented here. I think readers of this paper would want to know about this.</p></disp-quote><p>Phase precession in 2d is relatively hard to analyse even in rats, requiring lots of spikes, clear LFP theta and a rule for combining data from different types of trajectories. And the theta modulation of firing is weaker in mice than in rats in our experience. However, we have now also analysed phase precession place and grid cells with clear in theta-modulation – showing normal phase precession in VR as in R (with a lower slope consistent with the larger firing fields in VR, but the correlation between slope and field size only reaching significance for place fields in R). These results indicate that theta phase precession in place and grid cells is independent of linear vestibular acceleration signals and the absolute value of theta frequency. Text has been added to the last paragraph of the Results subsection “Electrophysiology”, to the eighth paragraph of the Discussion, and in the Abstract. Methods are included in the last paragraph of the subsection “Firing rate map construction and spatial cell classification”.</p></body></sub-article></article>