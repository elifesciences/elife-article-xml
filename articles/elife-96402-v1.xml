<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD with MathML3 v1.3 20210610//EN"  "JATS-archivearticle1-3-mathml3.dtd"><article xmlns:ali="http://www.niso.org/schemas/ali/1.0/" xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" article-type="research-article" dtd-version="1.3"><front><journal-meta><journal-id journal-id-type="nlm-ta">elife</journal-id><journal-id journal-id-type="publisher-id">eLife</journal-id><journal-title-group><journal-title>eLife</journal-title></journal-title-group><issn publication-format="electronic" pub-type="epub">2050-084X</issn><publisher><publisher-name>eLife Sciences Publications, Ltd</publisher-name></publisher></journal-meta><article-meta><article-id pub-id-type="publisher-id">96402</article-id><article-id pub-id-type="doi">10.7554/eLife.96402</article-id><article-id pub-id-type="doi" specific-use="version">10.7554/eLife.96402.3</article-id><article-version article-version-type="publication-state">version of record</article-version><article-categories><subj-group subj-group-type="display-channel"><subject>Research Article</subject></subj-group><subj-group subj-group-type="heading"><subject>Neuroscience</subject></subj-group></article-categories><title-group><article-title>Nonlinear feedback modulation contributes to the optimization of flexible decision-making</article-title></title-group><contrib-group><contrib contrib-type="author"><name><surname>Wu</surname><given-names>Xuanyu</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">https://orcid.org/0009-0009-8607-9381</contrib-id><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="fn" rid="con1"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" corresp="yes"><name><surname>Zhou</surname><given-names>Yang</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">https://orcid.org/0000-0002-4517-1052</contrib-id><email>yangzhou1@pku.edu.cn</email><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="aff" rid="aff2">2</xref><xref ref-type="aff" rid="aff3">3</xref><xref ref-type="aff" rid="aff4">4</xref><xref ref-type="other" rid="fund1"/><xref ref-type="other" rid="fund2"/><xref ref-type="fn" rid="con2"/><xref ref-type="fn" rid="conf1"/></contrib><aff id="aff1"><label>1</label><institution-wrap><institution-id institution-id-type="ror">https://ror.org/02v51f717</institution-id><institution>Peking-Tsinghua Center for Life Sciences, Peking University</institution></institution-wrap><addr-line><named-content content-type="city">Beijing</named-content></addr-line><country>China</country></aff><aff id="aff2"><label>2</label><institution-wrap><institution-id institution-id-type="ror">https://ror.org/02v51f717</institution-id><institution>School of Psychological and Cognitive Sciences, Peking University</institution></institution-wrap><addr-line><named-content content-type="city">Beijing</named-content></addr-line><country>China</country></aff><aff id="aff3"><label>3</label><institution-wrap><institution-id institution-id-type="ror">https://ror.org/02v51f717</institution-id><institution>PKU-IDG/McGovern Institute for Brain Research, Peking University</institution></institution-wrap><addr-line><named-content content-type="city">Beijing</named-content></addr-line><country>China</country></aff><aff id="aff4"><label>4</label><institution-wrap><institution-id institution-id-type="ror">https://ror.org/024mw5h28</institution-id><institution>Department of Neurobiology, The University of Chicago</institution></institution-wrap><addr-line><named-content content-type="city">Chicago</named-content></addr-line><country>United States</country></aff></contrib-group><contrib-group content-type="section"><contrib contrib-type="editor"><name><surname>Bi</surname><given-names>Yanchao</given-names></name><role>Reviewing Editor</role><aff><institution-wrap><institution-id institution-id-type="ror">https://ror.org/02v51f717</institution-id><institution>Peking University</institution></institution-wrap><country>China</country></aff></contrib><contrib contrib-type="senior_editor"><name><surname>Bi</surname><given-names>Yanchao</given-names></name><role>Senior Editor</role><aff><institution-wrap><institution-id institution-id-type="ror">https://ror.org/02v51f717</institution-id><institution>Peking University</institution></institution-wrap><country>China</country></aff></contrib></contrib-group><pub-date publication-format="electronic" date-type="publication"><day>30</day><month>09</month><year>2025</year></pub-date><volume>13</volume><elocation-id>RP96402</elocation-id><history><date date-type="sent-for-review" iso-8601-date="2024-02-05"><day>05</day><month>02</month><year>2024</year></date></history><pub-history><event><event-desc>This manuscript was published as a preprint.</event-desc><date date-type="preprint" iso-8601-date="2024-03-25"><day>25</day><month>03</month><year>2024</year></date><self-uri content-type="preprint" xlink:href="https://doi.org/10.1101/2023.07.15.549136"/></event><event><event-desc>This manuscript was published as a reviewed preprint.</event-desc><date date-type="reviewed-preprint" iso-8601-date="2024-06-13"><day>13</day><month>06</month><year>2024</year></date><self-uri content-type="reviewed-preprint" xlink:href="https://doi.org/10.7554/eLife.96402.1"/></event><event><event-desc>The reviewed preprint was revised.</event-desc><date date-type="reviewed-preprint" iso-8601-date="2025-07-14"><day>14</day><month>07</month><year>2025</year></date><self-uri content-type="reviewed-preprint" xlink:href="https://doi.org/10.7554/eLife.96402.2"/></event></pub-history><permissions><copyright-statement>© 2024, Wu and Zhou</copyright-statement><copyright-year>2024</copyright-year><copyright-holder>Wu and Zhou</copyright-holder><ali:free_to_read/><license xlink:href="http://creativecommons.org/licenses/by/4.0/"><ali:license_ref>http://creativecommons.org/licenses/by/4.0/</ali:license_ref><license-p>This article is distributed under the terms of the <ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/licenses/by/4.0/">Creative Commons Attribution License</ext-link>, which permits unrestricted use and redistribution provided that the original author and source are credited.</license-p></license></permissions><self-uri content-type="pdf" xlink:href="elife-96402-v1.pdf"/><self-uri content-type="figures-pdf" xlink:href="elife-96402-figures-v1.pdf"/><abstract><p>Neural activity in the primate brain correlates with both sensory evaluation and action selection aspects of decision-making. However, the intricate interaction between these distinct neural processes and their impact on decision behaviors remains unexplored. Here, we examined the interplay of these decision processes in posterior parietal cortex (PPC) when monkeys performed a flexible decision task. We found that the PPC activity related to monkeys’ abstract decisions about visual stimuli was nonlinearly modulated by monkeys’ following saccade choices directed outside each neuron’s response field. Recurrent neural network modeling indicated that the feedback connections, matching the learned stimuli-response associations during the task, might mediate such feedback modulation. Further analysis on network dynamics revealed that selectivity-specific feedback connectivity intensified the attractor basins of population activity underlying saccade choices, thereby increasing the reliability of flexible decisions. These results highlight an iterative computation between different decision processes, mediated primarily by precise feedback connectivity, contributing to the optimization of flexible decision-making.</p></abstract><kwd-group kwd-group-type="author-keywords"><kwd>decision-making</kwd><kwd>monkey electrophysiology</kwd><kwd>posterior parietal cortex</kwd><kwd>feedback modulation</kwd><kwd>artificial neural network</kwd><kwd>attractor basin</kwd></kwd-group><kwd-group kwd-group-type="research-organism"><title>Research organism</title><kwd>Rhesus macaque</kwd></kwd-group><funding-group><award-group id="fund1"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/501100002855</institution-id><institution>Ministry of Science and Technology of the People's Republic of China</institution></institution-wrap></funding-source><award-id>STI2030-Major Projects (2021ZD0203800)</award-id><principal-award-recipient><name><surname>Zhou</surname><given-names>Yang</given-names></name></principal-award-recipient></award-group><award-group id="fund2"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/501100001809</institution-id><institution>National Natural Science Foundation of China</institution></institution-wrap></funding-source><award-id>NSFC32171036</award-id><principal-award-recipient><name><surname>Zhou</surname><given-names>Yang</given-names></name></principal-award-recipient></award-group><funding-statement>The funders had no role in study design, data collection and interpretation, or the decision to submit the work for publication.</funding-statement></funding-group><custom-meta-group><custom-meta specific-use="meta-only"><meta-name>Author impact statement</meta-name><meta-value>Precise feedback connections in posterior parietal cortex enable iterative computation between decision processes, optimizing flexible decision-making reliability.</meta-value></custom-meta><custom-meta specific-use="meta-only"><meta-name>publishing-route</meta-name><meta-value>prc</meta-value></custom-meta></custom-meta-group></article-meta></front><body><sec id="s1" sec-type="intro"><title>Introduction</title><p>Perceptual decisions typically involve the transformation of sensory inputs to discrete motor responses. Consequently, sensory evaluation and action selection emerge as two fundamental processes essential for implementing perceptual decision behavior (<xref ref-type="bibr" rid="bib42">O’Connell et al., 2018</xref>; <xref ref-type="bibr" rid="bib18">Freedman and Assad, 2016</xref>; <xref ref-type="bibr" rid="bib22">Gold and Shadlen, 2007</xref>; <xref ref-type="bibr" rid="bib27">Huk et al., 2017</xref>; <xref ref-type="bibr" rid="bib23">Hanks and Summerfield, 2017</xref>; <xref ref-type="bibr" rid="bib51">Shadlen and Kiani, 2013</xref>; <xref ref-type="bibr" rid="bib17">Freedman and Assad, 2011</xref>). Neural activity associated with either the sensory or motor aspects of decision-making is widely distributed across different brain areas, such as PPC (<xref ref-type="bibr" rid="bib44">Platt and Glimcher, 1999</xref>; <xref ref-type="bibr" rid="bib47">Roitman and Shadlen, 2002</xref>; <xref ref-type="bibr" rid="bib49">Shadlen and Newsome, 1996</xref>; <xref ref-type="bibr" rid="bib50">Shadlen and Newsome, 2001</xref>; <xref ref-type="bibr" rid="bib55">Sugrue et al., 2004</xref>; <xref ref-type="bibr" rid="bib64">Yates et al., 2017</xref>; <xref ref-type="bibr" rid="bib65">Zhou and Freedman, 2019</xref>; <xref ref-type="bibr" rid="bib15">Freedman and Assad, 2006</xref>; <xref ref-type="bibr" rid="bib16">Freedman and Assad, 2009</xref>; <xref ref-type="bibr" rid="bib2">Bennur and Gold, 2011</xref>; <xref ref-type="bibr" rid="bib56">Swaminathan and Freedman, 2012</xref>; <xref ref-type="bibr" rid="bib67">Zhou et al., 2022</xref>; <xref ref-type="bibr" rid="bib30">Kiani and Shadlen, 2009</xref>; <xref ref-type="bibr" rid="bib29">Katz et al., 2016</xref>; <xref ref-type="bibr" rid="bib68">Zhou et al., 2023</xref>), frontal cortex (<xref ref-type="bibr" rid="bib56">Swaminathan and Freedman, 2012</xref>; <xref ref-type="bibr" rid="bib31">Kim and Shadlen, 1999</xref>; <xref ref-type="bibr" rid="bib48">Rossi-Pool et al., 2017</xref>; <xref ref-type="bibr" rid="bib10">Ding and Gold, 2012</xref>; <xref ref-type="bibr" rid="bib13">Ferrera et al., 2009</xref>; <xref ref-type="bibr" rid="bib25">Heitz and Schall, 2012</xref>; <xref ref-type="bibr" rid="bib66">Zhou et al., 2021</xref>), superior colliculus (<xref ref-type="bibr" rid="bib26">Horwitz and Newsome, 1999</xref>; <xref ref-type="bibr" rid="bib43">Peysakhovich et al., 2023</xref>), and caudate (<xref ref-type="bibr" rid="bib9">Ding and Gold, 2010</xref>). A recent inactivation study has shown that the lateral intraparietal area (LIP), a subregion of PPC, plays a causal role in flexible visuomotor decisions, with preferential involvement in sensory evaluation rather than action selection (<xref ref-type="bibr" rid="bib65">Zhou and Freedman, 2019</xref>). Meanwhile, areas outside PPC, like frontal eye field and superior colliculus, have been shown to be causally involved in the action selection aspect of decision-making (<xref ref-type="bibr" rid="bib21">Gold and Shadlen, 2000</xref>; <xref ref-type="bibr" rid="bib28">Jun et al., 2021</xref>). These findings suggest that sensory evaluation and action selection likely involve distinct neural processing in the primate brain during flexible decision-making.</p><p>However, previous reports have also shown that neural activity related to sensory evaluation and action selection overlaps temporally and spatially in the brain (<xref ref-type="bibr" rid="bib53">Shushruth et al., 2018</xref>). This leaves open the possibility of interplay between these distinct processes during decision-making. From the perspective of information processing, the abstract result of sensory evaluation should be transmitted to the motor planning circuits to guide the action selection process in a feedforward manner, although both processes could proceed in parallel in the brain. However, whether and how action selection processes might exert a feedback influence on sensory evaluation have not been explicitly studied.</p><p>In this study, we examined the activities of single LIP neurons during a flexible decision task in which monkeys needed to report their decisions about a motion stimulus with a saccade to one of two color targets. Specifically, we arranged the motion stimuli inside each neuron’s response field (RF) and positioned the saccade targets in the direction perpendicular to the axis of neural RFs. We found that LIP activity responding to visual motion was nonlinearly modulated by the monkeys’ following saccade choice direction relative to the recorded brain hemisphere. Notably, this modulation was aligned precisely with the functional properties of each neuron, as well as specifically impacted the decision-correlated but not the stimulus-correlated activity of LIP neurons. This suggests a precise ‘feedback’ modulation from action selection process to the neural processing of sensory evaluation during decision-making.</p><p>RNN models trained on complex behavioral tasks have shown promise for understanding neural computations and circuit mechanisms underlying cognitive functions (<xref ref-type="bibr" rid="bib11">Engel et al., 2015</xref>; <xref ref-type="bibr" rid="bib35">Masse et al., 2019</xref>; <xref ref-type="bibr" rid="bib54">Song et al., 2016</xref>). To further explore how action selection can modulate sensory evaluation during decision-making, we trained multi-module RNNs, which consist of different hemispheres and RF structures, to perform the same decision task and analyzed the activity of network units during task performance. These RNNs exhibited similar behavioral performance and neural activity patterns as observed in the monkey electrophysiology experiment, including patterns of nonlinear feedback modulation from action selection to sensory evaluation. Combining analysis on network activity and connectivity with projection-specific inactivation experiments in the RNNs, we further showed that the precise feedback connections between units that showed matched functional properties within different network modules were the key circuit mechanism for mediating the modulation of sensory evaluation by action selection. Such feedback modulation significantly enhanced the consistency of the RNNs’ decisions by strengthening the attractor basins of network dynamics underlying saccade choices.</p></sec><sec id="s2" sec-type="results"><title>Results</title><sec id="s2-1"><title>Nonlinear modulation of saccade choice on visual motion selectivity in LIP</title><p>To test the mechanisms underlying the feedback modulation of action selection on sensory evaluation, we trained two monkeys to perform a reaction-time version of the flexible visual-motion discrimination (FVMD) task, in which they needed to choose one of two colored saccade targets based on their decisions about the motion direction of a sample stimulus shown at different coherence levels (<xref ref-type="fig" rid="fig1">Figure 1A</xref>). Monkeys learned the mappings between the two motion directions (315° and 135°) and two target colors (red and green) at the start of training, and the mappings were fixed across the study. Because the locations of the red and green targets were randomly interleaved across trials, neither of the motion directions was directly linked with one specific saccade direction. Both the performance accuracy and the reaction time (RT) changed systematically as a function of motion coherence levels (<xref ref-type="fig" rid="fig1">Figure 1B–E</xref>): as the motion coherence increased, both monkeys chose the correct target more frequently and more rapidly.</p><fig id="fig1" position="float"><label>Figure 1.</label><caption><title>Behavioral task.</title><p>(<bold>A</bold>) The flexible visual-motion discrimination (FVMD) task. Monkeys needed to report their decision about the direction of the visual motion stimuli by choosing either the green or red saccade target. The appearance of the two color targets preceded that of the visual-motion stimulus, and the target positions were randomly chosen on each trial to avoid fixed mapping between motion stimulus and saccade direction. Monkeys could initiate their saccade as soon as they had made their decision. (<bold>B–C</bold>) Psychometric curves for the two monkeys. The averaged performance accuracy from all recording sessions (N=125) for each monkey is plotted as the proportion of trials in which 315° was chosen as a function of the directions and coherence levels of the motion stimuli. Error bar denote ± SEM. (<bold>D–E</bold>) Chronometric curves are shown separately for the two monkeys. (<bold>F–G</bold>) Two trial conditions, contralateral (<bold>F</bold>) and ipsilateral (<bold>G</bold>), defined according to the spatial configurations of task stimuli during neural recording.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-96402-fig1-v1.tif"/></fig><p>We recorded single-neuron activity from the LIP while the monkeys performed the FVMD task. We used the memory-guided saccade (MGS) task, which is commonly employed in LIP studies, to map the receptive fields (RFs) of all isolated LIP neurons. Specifically, we mapped both the visual and memory RFs of each neuron by analyzing their activity during the target presentation and delay periods of the MGS task (see Materials and methods). To examine the neural activity related to the evaluation of stimulus motion, we presented the motion stimuli within the RF of each neuron, while positioning the saccade targets at locations orthogonal to the line connecting the center of the RF (which also marks the center of the motion stimulus) and the fixation dot. In total, 104 of 194 visually responsive LIP neurons (monkey M: 50/78; monkey B: 54/116) showed significant direction selectivity (DS) to the motion stimuli (one-way ANOVA, p&lt;0.01). To examine the influence of action selection on sensory evaluation, we analyzed data from the subset of sessions in which the saccade targets were aligned more closely with the horizontal direction than the vertical direction (83 of 104 neurons). In these sessions, the motor planning corresponding to a saccade to either target would be mediated primarily by one brain hemisphere. We therefore defined the conditions under which the correct target was contralateral or ipsilateral to the recorded hemisphere as the contralateral target (CT) condition or ipsilateral target (IT) condition, respectively (<xref ref-type="fig" rid="fig1">Figure 1F and G</xref>).</p><p><xref ref-type="fig" rid="fig2">Figure 2A–F</xref> shows three example LIP neurons that exhibited significant motion coherence correlated DS. Surprisingly, LIP neurons showed greater DS in the CT condition than in the IT condition, even though the same motion stimuli were used in the same spatial location for both conditions. The averaged population activity showed this DS difference between CT and IT conditions for all four coherence levels (<xref ref-type="fig" rid="fig2">Figure 2G, H</xref>). During the presentation of their preferred motion direction, LIP neurons showed significantly elevated activity in the CT relative to the IT at all coherence levels (<xref ref-type="fig" rid="fig2s1">Figure 2—figure supplement 1A, B</xref>, nested ANOVA: P<sub>(high)</sub>=0.0326, <italic>F</italic>=4.65; P<sub>(medium)</sub>=0.0088, <italic>F</italic>=7.03; P<sub>(low)</sub>=0.0076, <italic>F</italic>=7.32; P<sub>(zero)</sub>=0.0124, <italic>F</italic>=6.4), and a trend toward lower activity to the nonpreferred direction for CT vs. IT (<xref ref-type="fig" rid="fig2s1">Figure 2—figure supplement 1C, D</xref>, nested ANOVA: P<sub>(high)</sub>=0.0994, <italic>F</italic>=2.75; P<sub>(medium)</sub>=0.0649, <italic>F</italic>=3.12; P<sub>(low)</sub>=0.0311, <italic>F</italic>=4.73; P<sub>(zero)</sub>=0.0273, <italic>F</italic>=4.96). Most of the LIP neurons (48 of 83) showed such opposing trends in activity modulation between the preferred and nonpreferred directions (<xref ref-type="fig" rid="fig2">Figure 2I</xref>). These results indicated a nonlinear modulation of saccade choice on motion DS in LIP, aligned precisely with the response property of each neuron. This is unlikely to be driven by a linear gain modulation of saccade DS. Receiver operating characteristic (ROC) analysis further confirmed significantly greater motion DS in the CT condition than in the IT condition (<xref ref-type="fig" rid="fig2">Figure 2J, K</xref>; nested ANOVA: P<sub>(high)</sub>=5.0e-4, <italic>F</italic>=12.44; P<sub>(medium)</sub>=9.53e-6, <italic>F</italic>=20.91; P<sub>(low)</sub>=9.33e-7, <italic>F</italic>=26.03; P<sub>(zero)</sub>=2.56e-8, <italic>F</italic>=34.3). Such DS differences were observed even before stimulus onset. Moreover, LIP neurons exhibited similar levels of mean activity between different saccade directions (CT vs. IT) before monkeys’ saccade choice (<xref ref-type="fig" rid="fig2">Figure 2L</xref>), further supporting that saccade DS did not significantly contribute to the observed modulation of LIP neurons’ responses to motion stimuli.</p><fig-group><fig id="fig2" position="float"><label>Figure 2.</label><caption><title>Nonlinear feedback modulation of saccade choice on sensory evaluation in LIP.</title><p>(<bold>A</bold>) The activity of one example neuron in the CT condition of the FVMD task is shown for each motion-coherence level. The zero-coherence trials were grouped based on the monkey’s choices. The two vertical dashed lines denote the time of target and motion stimulus onset, respectively. (<bold>B</bold>) The same example neuron’s activity in the IT condition of the FVMD task. (<bold>C–F</bold>) The activities of two more example neurons. (<bold>G–H</bold>) The averaged population activities of all direction-selective neurons (N=83) that were collected during the recording sessions in which the saccade targets were arranged in either horizontal or oblique directions. The activity to each motion direction and coherence level is shown separately for the CT condition (<bold>G</bold>) and IT condition (<bold>H</bold>). (<bold>I</bold>) The activity differences between CT and IT conditions (CT minus IT) of single LIP neurons were plotted for both preferred and nonpreferred motion directions. Each dot represents the activity of a single neuron. The histograms in the horizontal and vertical axes represent the distribution of activity difference between CT and IT conditions for preferred and nonpreferred motion directions, respectively. (<bold>J</bold>) An ROC analysis was used for quantifying the motion DS for both CT (solid) and IT (dashed) conditions. The colored dots denote the time points for which there was a significant difference between the CT and IT conditions (paired t-test: p&lt;0.01). (<bold>K</bold>) The average DS for low- and zero-coherence trials is shown as in (<bold>J</bold>). (<bold>L</bold>) The mean activity (averaged across all motion directions and coherence levels, shaded area denotes ± SEM) was compared between the two saccade directions (CT vs. IT) at the population level. Activity was aligned to either motion stimulus onset (left panel) or saccade onset (right panel). There was no significant difference between CT and IT conditions before monkeys made saccade choices. (<bold>M</bold>) Variance in LIP population activity as explained by the individual demixed principal components. Each bar shows the proportion of total explained variance that was contributed by the four task variables. The pie chart shows the total variance explained by each task variable. H, high; M, medium; L, low; 0, zero; P, preferred; NP, nonpreferred.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-96402-fig2-v1.tif"/></fig><fig id="fig2s1" position="float" specific-use="child-fig"><label>Figure 2—figure supplement 1.</label><caption><title>The comparisons of LIP activity between the CT and IT conditions.</title><p>The averaged population activity responded to motion stimuli in both CT and IT conditions is shown separately for different motion coherence levels. The averaged LIP activity to the preferred (<bold>A–B</bold>) and nonpreferred (<bold>C–D</bold>) motion directions was shown separately. Different colors denote different motion coherence levels. The two vertical dashed lines denote the time of target and motion stimulus onset, respectively.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-96402-fig2-figsupp1-v1.tif"/></fig><fig id="fig2s2" position="float" specific-use="child-fig"><label>Figure 2—figure supplement 2.</label><caption><title>There was no systematic relationship between direction preference and saccade-related modulation in LIP neurons’ responses to motion stimuli.</title><p>A modulation index was computed for each neuron to quantify differences in motion direction selectivity between the CT and IT conditions. The distribution of modulation indices was then compared between neurons preferring 315° motion direction (red) and those preferring 135° motion direction (blue).</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-96402-fig2-figsupp2-v1.tif"/></fig><fig id="fig2s3" position="float" specific-use="child-fig"><label>Figure 2—figure supplement 3.</label><caption><title>The comparison of LIP activity between the CT and IT conditions.</title><p>This figure only includes the data sessions in which the saccade targets were aligned close to the vertical direction. (<bold>A–B</bold>) The averaged population activities in both the CT (<bold>A</bold>) and IT (<bold>B</bold>) conditions are shown separately for each motion direction and coherence level. (<bold>C–D</bold>) The comparisons of LIP activity responded to the preferred motion direction between the CT and IT conditions are shown for different coherence levels. (<bold>E–F</bold>). The comparisons of LIP activity responded to the nonpreferred motion direction between the CT and IT conditions.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-96402-fig2-figsupp3-v1.tif"/></fig><fig id="fig2s4" position="float" specific-use="child-fig"><label>Figure 2—figure supplement 4.</label><caption><title>The motion and saccade representations in LIP shown by dPCA analysis.</title><p>LIP population activity was decomposed into four task-related variables: motion direction, saccade direction, motion-saccade interaction, and timing (condition-independent). (<bold>A</bold>) Cumulative variance explained by PCA (black) and dPCA (red) for LIP population activity responded to motion stimuli. Only the first 15 principal components (PCs) were shown. dPCA explains almost the same amount of variance as standard PCA. (<bold>B–E</bold>) Demixed principal components. The upper row: the first demixed PCs of LIP population activity corresponding to the four variables. The lower row: the second demixed PCs of LIP population activity. In each subplot, LIP population activity is projected onto the respective dPCA decoder axis, so that there are 16 lines corresponding to 16 conditions (2 motion directions x 4 coherence levels x 2 saccade directions). Different colors represent different motion directions. Solid and dashed lines represent CT condition and IT condition, respectively. The two vertical dashed lines mark the time of target and motion stimulus onset, respectively.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-96402-fig2-figsupp4-v1.tif"/></fig><fig id="fig2s5" position="float" specific-use="child-fig"><label>Figure 2—figure supplement 5.</label><caption><title>Modulation of sensory evaluation by saccade selection is unlikely to be an artifact of saccade direction selectivity.</title><p>(<bold>A</bold>) The modulation index is plotted against the RF position for each LIP neuron with identifiable RF, the size and the color of each dot denotes the value of the modulation index. (<bold>B</bold>) The average of the mean firing rate divided by saccade direction for all neurons that did not show clear RF in the MGS task, aligned to the direction with the strongest neural response. Error bar indicates standard deviation. (<bold>C</bold>) Comparison of the mean saccadic responses to the MGS targets that are closest to the contralateral and ipsilateral targets in the mean task of all LIP neurons.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-96402-fig2-figsupp5-v1.tif"/></fig></fig-group><p>To better quantify the influence of saccade direction on neuronal responses to motion stimuli, we calculated a modulation index for each neuron (STAR Methods). We then compared the modulation indices across neurons with different direction preferences and found no systematic relationship between direction preference and saccade-related modulation in LIP neurons at the population level (<xref ref-type="fig" rid="fig2s2">Figure 2—figure supplement 2</xref>). Furthermore, a demixed principal component analysis on the pseudo-population activity (STAR Methods) revealed that the saccade direction related representation was a substantial component of LIP activity, as the saccade direction and motion–saccade interaction together explained a similar amount of variance in the population activity as the stimulus motion direction did (<xref ref-type="fig" rid="fig2">Figure 2M</xref>, <xref ref-type="fig" rid="fig2s3">Figure 2—figure supplement 3</xref>). In contrast, we did not observe significant DS differences between the CT and IT conditions in the data sessions in which the saccade targets were aligned close to the vertical direction (21 of 104 neurons, <xref ref-type="fig" rid="fig2s4">Figure 2—figure supplement 4</xref>).</p><p>We further investigated whether there was a systematic relationship between neurons’ RF positions and the influence of saccade direction on motion DS. This was motivated by the intuitive expectation that CTs were more likely to fall within the RFs of LIP neurons than ITs. To examine this, we first quantified the RF centers of all LIP neurons with identifiable RFs during the MGS task (see Materials and methods) and plotted their modulation indices against RF positions (<xref ref-type="fig" rid="fig2s5">Figure 2—figure supplement 5A</xref>). We found that neurons with RFs located farther from the horizontal meridian exhibited stronger modulation by saccade direction, whereas those with RFs closer to the meridian showed weaker and more inconsistent modulation. This pattern aligns with the results shown in <xref ref-type="fig" rid="fig2s3">Figure 2—figure supplement 3</xref>, which also demonstrated minimal differences between CT and IT conditions when saccade targets were positioned near the vertical axis. Next, for neurons that did not exhibit a clear RF in the MGS task, we aligned their responses based on the saccade direction that evoked the highest mean firing rate and plotted mean responses across all directions (<xref ref-type="fig" rid="fig2s5">Figure 2—figure supplement 5B</xref>). These neurons did not show significant differences across directions, confirming the absence of a clear RF structure. Finally, we identified the two saccade targets in the MGS task that were spatially closest to those used in the main task, labeled them as CT and ITs (following the same convention as in the main task), and compared the mean firing rates across all neurons. No significant difference was found between CT and IT conditions (<xref ref-type="fig" rid="fig2s5">Figure 2—figure supplement 5C</xref>; mean<sub>(ipsi)</sub>&gt;mean<sub>(contra)</sub>, paired t-test, p=0.053). Together, these results suggest that the nonlinear modulation of sensory evaluation by saccade selection is unlikely to be an artifact of basic saccade DS’.</p></sec><sec id="s2-2"><title>Decision-correlated but not stimulus-correlated activity was modulated in LIP</title><p>We then examined the impact of nonlinear feedback modulation on the correlation between LIP DS and monkeys' choice behavior. We found that LIP DS was more decision-correlated in the CT condition than in the IT condition. Illustrated in <xref ref-type="fig" rid="fig2">Figure 2K</xref>, the LIP DS on zero-coherence trials, which reflected monkeys’ trial-by-trial categorical choice, was significantly greater in the CT condition than in the IT condition (nested ANOVA: p=2.56e-8, <italic>F</italic>=34.3). We also quantified the correlation between LIP neural activity and the trial-by-trial categorical choice or the physical motion direction by comparing LIP neural activity on correct versus incorrect trials. We used low-coherence trials, as monkeys made enough errors in these trials. In the CT condition but not the IT condition, LIP DS at the population level was significantly reversed in sign on incorrect trials as compared to correct trials (<xref ref-type="fig" rid="fig3">Figure 3A and B</xref>; nested ANOVA: P<sub>(CT)</sub>=0.0045, <italic>F</italic>=8.32). Accordingly, in the CT condition but not in the IT condition, LIP activity correlated more closely with the monkeys’ trial-by-trial abstract decisions about motion direction, as opposed to the physical motion direction (<xref ref-type="fig" rid="fig3">Figure 3C and D</xref>; nested ANOVA, P<sub>(CT)</sub>=0.0016, <italic>F</italic>=10.31; P<sub>(IT)</sub>=0.443, <italic>F</italic>=0.59). Meanwhile, LIP activity correlated more closely with the trial-by-trial abstract decisions during the CT condition relative to the IT condition on the low coherence trials (nested ANOVA: p=1.95e-8, <italic>F</italic>=34.94). Furthermore, we used partial correlation analysis to examine decision- and stimulus-related components of DS (i.e. r-decision and r-stimulus, <xref ref-type="fig" rid="fig3">Figure 3E and F</xref>) using all four coherence levels. The decision-related component of LIP DS was significantly greater in the CT condition than in the IT condition (<xref ref-type="fig" rid="fig3">Figure 3E</xref>; nested ANOVA: p=1.07e-6, <italic>F</italic>=25.72), and this difference emerged even before motion stimulus onset. This suggests that the LIP DS was more closely correlated with monkeys’ decisions in the CT condition than in the IT condition. The upregulation in r-decision for contralateral choices may reflect the monkeys’ internal choice bias or expectation (choice between two motion directions) prior to stimulus presentation, which could influence their subsequent decisions more in the CT condition. However, the stimulus-related component of the LIP DS was similar at the population level between the two conditions (<xref ref-type="fig" rid="fig3">Figure 3F</xref>; nested ANOVA: p=0.7606, <italic>F</italic>=0.09), suggesting that the modulation of LIP DS by the later saccade choice was primarily related to a decision process rather than basic sensory processing.</p><fig-group><fig id="fig3" position="float"><label>Figure 3.</label><caption><title>Feedback modulation specifically impacted the decision-correlated activity.</title><p>(<bold>A–B</bold>) Averaged population activities on low-coherence trials in the CT condition (<bold>A</bold>) and IT condition (<bold>B</bold>) are shown separately for correct (corr) and error (err) trials. (<bold>C–D</bold>) An ROC analysis quantified the stimulus-related and decision-related LIP DS on low-coherence trials. The correlations between LIP neural activity and the monkeys’ decisions about motion direction (red) or the physical direction of the motion stimulus (blue) in both the CT (<bold>C</bold>) and IT (<bold>D</bold>) conditions are shown over time. (<bold>E–F</bold>) Partial correlation analysis revealed the decision-related and stimulus-related components of LIP activity. The values for r-decision (<bold>E</bold>) (the partial correlation between neuronal activity and monkeys’ choice, given the stimulus direction) and r-stimulus (<bold>F</bold>) (partial correlation between neuronal activity and stimulus direction, given the monkeys’ choices) were compared between the IT and CT conditions. (<bold>G–H</bold>) Correlation between LIP DS and the monkeys’ RTs on zero-coherence trials. The choice selectivity on zero-coherence trials is shown for the faster RT and slower RT trials. Shaded areas denote ± SEM. The black stars indicate time periods in which there was a significant difference (paired t-test: p&lt;0.01).</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-96402-fig3-v1.tif"/></fig><fig id="fig3s1" position="float" specific-use="child-fig"><label>Figure 3—figure supplement 1.</label><caption><title>The comparison of LIP activity to the preferred motion direction between the faster and slower RT trials in the CT condition.</title><p>Data from each coherence level is shown separately. Each dot denotes the averaged activity of a single neuron.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-96402-fig3-figsupp1-v1.tif"/></fig><fig id="fig3s2" position="float" specific-use="child-fig"><label>Figure 3—figure supplement 2.</label><caption><title>The comparisons of LIP activity to the preferred motion direction between the faster and slower RT trials in the IT condition, which are shown in the same format as in <xref ref-type="fig" rid="fig2s4">Figure 2—figure supplement 4</xref>.</title></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-96402-fig3-figsupp2-v1.tif"/></fig></fig-group><p>We further examined the impact of nonlinear feedback modulation on the correlation between LIP DS and the monkeys’ RTs. Shortly after motion stimulus onset, LIP neurons showed greater population response to their preferred motion direction on shorter versus longer RT trials for all motion coherence levels in the CT condition (<xref ref-type="fig" rid="fig3s1">Figure 3—figure supplement 1</xref>) but not in the IT condition (<xref ref-type="fig" rid="fig3s2">Figure 3—figure supplement 2</xref>). On zero-coherence trials (<xref ref-type="fig" rid="fig3">Figure 3G and H</xref>), DS evolved more rapidly on shorter vs. longer RT trials in the CT condition but not in the IT condition (bootstrap: P<sub>(CT)</sub>&lt;0.01, P<sub>(IT)</sub>=0.87). Together, these results indicated that the feedback modulation of saccade choice on sensory evaluation predominantly impacted the decision-correlated activity in LIP.</p></sec><sec id="s2-3"><title>Trained multi-module RNNs replicated the nonlinear feedback modulation</title><p>Our electrophysiology data show that action selection nonlinearly modulates the neural processing of sensory evaluation, which indicates a complex, iterative computation for flexible decision-making. Training RNNs on behavioral tasks used in experimental neurophysiological studies has proven to be helpful for exploring putative circuit computations underlying cognitive tasks (<xref ref-type="bibr" rid="bib66">Zhou et al., 2021</xref>; <xref ref-type="bibr" rid="bib35">Masse et al., 2019</xref>; <xref ref-type="bibr" rid="bib54">Song et al., 2016</xref>). Therefore, we trained multi-module RNNs to perform the FVMD task to examine the circuits and computation mechanisms underlying the interplay of different decision processes. We adopted simple neurobiological principles to constrain the connection structure but not the functional roles to generate recurrently connected modules (STAR Methods). Because our neurophysiological results showed that the modulation effect of action selection on sensory evaluation depended on the saccade direction relative to the recorded brain hemisphere, we implemented RNNs composed of two main modules organized in parallel to simulate two brain hemispheres. Each main module consisted of two nominal modules, with each nominal module receiving the visual motion input (motion module) or the target color input (target module), corresponding to the two neuron populations whose RFs covered the motion stimulus or saccade targets, respectively (<xref ref-type="fig" rid="fig4">Figure 4A</xref>).</p><fig-group><fig id="fig4" position="float"><label>Figure 4.</label><caption><title>Multi-module RNNs trained with the FVMD task.</title><p>(<bold>A</bold>) Model schematic of the RNNs. Each RNN consists of nine motion direction tuned input units, eight color tuned target input units, 200 hidden units, and two response units. The hidden layer of each RNN consists of two main modules. Each main module consists of two nominal modules, each of which receives either the visual motion input (motion module) or the target color input (target module). Only the target modules project to the two response units, and each main module projects primarily to one response unit. All four nominal modules were assigned with an equal number of units (25%) in the network, which consisted of 80% excitatory and 20% inhibitory units. (<bold>B–C</bold>) The performance accuracies (<bold>B</bold>) and RTs (<bold>C</bold>) of all 50 trained RNNs are shown separately for each motion coherence level. (<bold>D–E</bold>) Two example units from an example RNN. (<bold>D</bold>) The neural activity of an example unit from the motion module is shown for each motion direction and coherence level. (<bold>E</bold>) The neural activity of an example unit from the target module is shown for each saccade direction and coherence level. (<bold>F–G</bold>) The motion DS for the motion module (<bold>F</bold>) and saccade DS for the target module (<bold>G</bold>) for the example RNN. (<bold>H–I</bold>) The averaged population activities of all direction-selective units in the motion module of the example RNN are shown for the CT condition (<bold>H</bold>) and IT condition (<bold>I</bold>). (<bold>J–K</bold>) The averaged motion DS in the motion module of the example RNN for both the CT (solid) and IT (dashed) conditions was quantified by ROC analysis. (<bold>L–M</bold>) Partial correlation analysis. The values for r-decision (<bold>L</bold>) and r-stimulus (<bold>M</bold>) are compared between the IT and CT conditions for the example RNN. (<bold>N</bold>) A comparison of the motion DS in the motion module of all trained RNNs between the CT and IT conditions is shown for each coherence level. (<bold>O</bold>) A comparison of the r-decision and r-stimulus between the IT and CT conditions is shown for all trained RNNs. (Paired t-test: ***, p&lt;0.001).</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-96402-fig4-v1.tif"/></fig><fig id="fig4s1" position="float" specific-use="child-fig"><label>Figure 4—figure supplement 1.</label><caption><title>Examples of unit activity in the example network.</title><p>The two upper rows show the activities of 6 example units in the motion module. Different colors denote different motion directions, and different shades denote different coherence levels. The zero coherence trials were grouped based on the network’s choices. The two lower rows show the activities of 6 example units in the target module. Different colors denote different saccade directions.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-96402-fig4-figsupp1-v1.tif"/></fig><fig id="fig4s2" position="float" specific-use="child-fig"><label>Figure 4—figure supplement 2.</label><caption><title>Population level unit activity across all trained RNNs.</title><p>(<bold>A</bold>) The averaged population activity of all motion direction selective units in the motion module of the example RNN. (<bold>B</bold>) The averaged population activity of units in the target module of the same example RNN is shown for different saccade directions and motion coherence levels. (<bold>C–D</bold>) The averaged population activity of all 50 trained RNNs is shown in the same format as in a-b. (<bold>E–F</bold>) An ROC analysis was used for quantifying the motion DS for the motion module (h) and saccade DS in the target module for all 50 trained RNNs.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-96402-fig4-figsupp2-v1.tif"/></fig><fig id="fig4s3" position="float" specific-use="child-fig"><label>Figure 4—figure supplement 3.</label><caption><title>The motion direction selectivity in the motion module was significantly modulated by later saccade choice in the RNNs.</title><p>Only the units in the motion module were included, and data from all the trained RNNs was pulled together. (<bold>A–B</bold>) The averaged population activities of all direction-selective units in all the trained RNNs are shown separately for CT condition (<bold>A</bold>) and IT conditions (<bold>B</bold>). (<bold>C–D</bold>) The motion DS in the motion module of all the trained RNNs was quantified by ROC analysis for all four motion coherence levels. Solid and dashed lines denote data in the CT and IT conditions, respectively. The color dots denote the time points for which there was significant difference between CT and IT conditions (p&lt;0.01, paired t-test). (<bold>E–F</bold>) Partial correlation analysis. The averaged value of r-decision (<bold>E</bold>) and r-stimulus (<bold>F</bold>) across all the trained RNNs is compared between IT and CT conditions. Shaded areas denote ± SEM.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-96402-fig4-figsupp3-v1.tif"/></fig><fig id="fig4s4" position="float" specific-use="child-fig"><label>Figure 4—figure supplement 4.</label><caption><title>The comparison of unit activity in the motion module of the RNNs between the CT and IT conditions.</title><p>(<bold>A–B</bold>) The averaged population activities of the example RNNs responded to the preferred (<bold>A</bold>) and nonpreferred (<bold>B</bold>) motion directions are shown separately for the CT (solid) and IT (dashed) conditions. (<bold>C–D</bold>) The comparisons of unit activity averaged across all the trained RNNs between the CT and IT conditions are shown for different coherence levels.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-96402-fig4-figsupp4-v1.tif"/></fig></fig-group><p>We independently trained 50 such networks with randomly initialized weights and identical hyperparameters to perform the FVMD task. The FVMD task setup used for training RNNs was tailored to match the monkey experiments. Specifically, the RNNs were trained using motion stimuli with two high-coherence levels and were tested using stimuli with another four different coherence levels (high, medium, low, and zero). After training, all 50 networks converged to perform the FVMD task with high accuracies (&gt;99%) on the training coherence and exhibited coherence-dependent performances when tested with untrained stimuli (<xref ref-type="fig" rid="fig4">Figure 4B and C</xref>): accuracy increased and RT decreased with motion coherence.</p><p>We then analyzed the unit activity in different modules when the trained RNNs were tested with untrained motion stimuli. Across all networks, the units in the motion module and target modules exhibited activity corresponding to sensory evaluation and action selection, respectively. Specifically, units in the motion modules showed coherence-correlated motion DS (<xref ref-type="fig" rid="fig4">Figure 4D, F</xref>, <xref ref-type="fig" rid="fig4s1">Figure 4—figure supplements 1</xref> and <xref ref-type="fig" rid="fig4s2">2</xref>; mean <italic>r</italic>=0.29; one-sample t-test: p=4.09e-42, t(49) = 46.31), and neuronal activity on zero-coherence motion trials reflected the trial-by-trial abstract decisions of the networks (t-test: P<sub>(example RNN)</sub>=5.97e-27, t(91) = 15.33; P<sub>(population)</sub>=1.05e-31, t(49) = 27.86). Such motion DS resembled our electrophysiology data when the motion stimuli were presented within the RFs of the LIP neurons. Meanwhile, units in the target modules showed coherence-correlated saccade DS (<xref ref-type="fig" rid="fig4">Figure 4E, F</xref>, <xref ref-type="fig" rid="fig4s1">Figure 4—figure supplements 1</xref> and <xref ref-type="fig" rid="fig4s2">2</xref>), and the neuronal activity on zero-coherence motion trials also showed significant choice probability (t-test: P<sub>(example RNN)</sub>=7.06e-8, t(68) = 15.83; P<sub>(population)</sub>=2.08e-22, t(49) = 17.21). Such saccade DS was consistent with the commonly observed decision-related activity in previous studies in which the saccade target was presented within the RFs of LIP neurons (<xref ref-type="bibr" rid="bib47">Roitman and Shadlen, 2002</xref>; <xref ref-type="bibr" rid="bib49">Shadlen and Newsome, 1996</xref>; <xref ref-type="bibr" rid="bib50">Shadlen and Newsome, 2001</xref>).</p><p>Furthermore, we found that the motion DS of units in the motion modules was significantly greater in the CT condition than in the IT condition for the majority of RNNs (<xref ref-type="fig" rid="fig4">Figure 4H and I</xref> and <xref ref-type="fig" rid="fig4s3">Figure 4—figure supplement 3A, B</xref>): in the CT condition relative to the IT condition, activity was significantly greater for the preferred motion direction but weaker for the nonpreferred direction (<xref ref-type="fig" rid="fig4s4">Figure 4—figure supplement 4</xref>). ROC analysis confirmed that the motion DS in the motion module was significantly greater for all four coherence levels in the CT vs. IT conditions in most RNNs (<xref ref-type="fig" rid="fig4">Figure 4J, K and N</xref> and <xref ref-type="fig" rid="fig4s3">Figure 4—figure supplement 3C, D</xref>; two-way ANOVA: P<sub>(example RNN)</sub>=1.53e-11, <italic>F</italic>=47.49; P<sub>(population)</sub>=3.50e-77, <italic>F</italic>=660.84). Similar to the monkey electrophysiology data, the decision-correlated motion DS (r-decision) in the motion module was dramatically reduced in the IT versus CT condition (paired t-test: p=6.84e-17, t(49) = –12.53), and this difference was substantially greater than the difference in the stimulus-related (r-stimulus) motion DS between the two conditions (paired t-test: p=2.02e-14, t(49) = –10.70; <xref ref-type="fig" rid="fig4">Figure 4L, M and O</xref>, <xref ref-type="fig" rid="fig4s3">Figure 4—figure supplement 3F</xref>). These results indicated that action selection also nonlinearly modulated the neural processing of sensory evaluation during decision-making in the RNNs.</p></sec><sec id="s2-4"><title>Selectivity-specific feedback connections mediate the modulation of sensory evaluation by action selection</title><p>Our multi-module RNNs showed a remarkable similarity to both the behavioral performances and the neural activity patterns in the monkey electrophysiology data, suggesting that these networks may have adopted mechanisms similar to those in the monkey brain to mediate the decision processes in the FVMD task. Therefore, we explored the potential circuit mechanisms underlying the modulation of action selection on sensory evaluation in RNNs. We hypothesized that this modulation might result from the feedback connections from the target module to the motion module. To test this hypothesis, we examined the recurrent weights of the cross-module connections (STAR Methods). Both the feedback and feedforward cross-module connection weights were significantly greater between the selectivity-matched unit pairs (e.g. units in the motion module preferred to encode 315° and units in the target module preferred to encode red) than the selectivity-nonmatched unit pairs (e.g. units in the motion module preferred to encode 315° while units in the target module preferred to encode green; <xref ref-type="fig" rid="fig5">Figure 5A</xref>; paired t-test: P<sub>(feedforward)</sub>=7.18e-16, t(49) = –11.76; P<sub>(feedback)</sub>=5.26e-18, t(49) = –13.40). In particular, the average feedback connectivity was primarily excitatory between the selectivity-matched unit pairs but was inhibitory on average between the selectivity-nonmatched unit pairs. Furthermore, most of the networks exhibited positive correlations between the connection weight and the match extent of the neural selectivity of each cross-module unit pair (<xref ref-type="fig" rid="fig5">Figure 5B</xref>; mean <italic>r</italic>=0.11; one-sample t-test: p=6.39e-16; t(49) = 11.79; STAR Methods), indicating that units that exhibited stronger encoding preference to one motion direction in the motion module were more likely to receive more extensive feedback projections from the units that exhibited stronger encoding on the matched target color in the target module. These results suggested precise feedback connections between RNN modules that were aligned with the functional properties of different units.</p><fig-group><fig id="fig5" position="float"><label>Figure 5.</label><caption><title>The circuit mechanisms underlying the nonlinear feedback modulation in RNNs.</title><p>(<bold>A</bold>) The averaged cross-module connection weights are shown for both feedforward and feedback connections. Units in the motion module (M) and target module (T) were grouped based on their preferences for motion DS (315° vs. 135°) and target color selectivity (red [r] vs. green [g]), respectively. (<bold>B</bold>) The correlation between the match extent of the neural encoding between units in the motion module and those in target modules and the connection weights between them. Each dot denotes data from one RNN (N=50). (<bold>C–D</bold>) A comparison of the performance accuracy (<bold>C</bold>) and RT (<bold>D</bold>) of the full-model RNNs, RNNs without feedback connections, and RNNs with shuffled feedback connections. (<bold>E–F</bold>) The averaged activity of units in the motion module of the example RNN after the feedback connections were ablated is shown for CT (<bold>E</bold>) and IT (<bold>F</bold>) conditions. (<bold>G</bold>) The comparison of the averaged motion DS between CT and IT conditions for all trained RNNs after feedback connections were ablated. An ROC analysis was used to quantify the motion DS. (<bold>H</bold>) The differences in motion DS between CT and IT conditions were compared between full-model RNNs and RNNs with shuffled feedback connectivity.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-96402-fig5-v1.tif"/></fig><fig id="fig5s1" position="float" specific-use="child-fig"><label>Figure 5—figure supplement 1.</label><caption><title>The motion DS in the motion module of the trained RNNs did not decrease after inactivating feedback connectivity.</title><p>(<bold>A</bold>) The averaged population activity of units in the motion module of all RNNs (N=50) after ablating feedback connections was shown separately for different motion directions and coherence. (<bold>B</bold>) The averaged population activity of units in the motion module of all RNNs after disrupting feedback connections was shown in the same format as in a. (<bold>C</bold>) The averaged motion DS in motion module of the full-model RNNs, RNNs without feedback connections, and RNNs with disrupted feedback connections were compared separately for different motion coherence. An ROC analysis was used for quantifying the motion DS. (Paired t-test: **, p&lt;0.01; ***, p&lt;0.001; n.s., not significant).</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-96402-fig5-figsupp1-v1.tif"/></fig><fig id="fig5s2" position="float" specific-use="child-fig"><label>Figure 5—figure supplement 2.</label><caption><title>The averaged population activity of all trained RNNs without feedback connections.</title><p>(<bold>A–B</bold>) The averaged population activity of all direction-selective units in the motion module of all the trained RNNs (N=50) after ablating the feedback connections is shown for different motion directions and coherence levels. Data from both CT condition (<bold>A</bold>) and IT conditions (<bold>B</bold>) were shown separately. (<bold>C</bold>) The averaged population activity of units in the target module of all the trained RNNs after ablating feedback connections is shown for different saccade directions and motion coherence levels.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-96402-fig5-figsupp2-v1.tif"/></fig><fig id="fig5s3" position="float" specific-use="child-fig"><label>Figure 5—figure supplement 3.</label><caption><title>The effects of pattern-specific ablation of the feedback connections on the RNNs’ behavior performance.</title><p>The feedback connections in either the specialized group or nonspecialized group were ablated separately when tested with the untrained motion stimuli. (<bold>A</bold>) The comparison of the numbers of feedback connections between selectivity-specialized and nonspecialized groups. The distributions of the total number of feedback connections for all 50 RNNs were shown separately for specialized and nonspecialized groups. The blue and brown vertical dashed lines denote the mean values across all 50 RNNs for specialized connections and nonspecialized connections, respectively. (<bold>B</bold>) The comparison of the mean weights of feedback connections between selectivity-specialized and nonspecialized groups. (<bold>C</bold>) The comparison of the networks’ performance accuracy. The performance accuracies of the full-model RNNs, RNNs without selectivity-specialized feedback connections, and RNNs without nonspecialized feedback connections were shown separately for different motion coherence. (<bold>D</bold>) The comparison of the networks’ RTs. The RTs of the full-model RNNs, RNNs without selectivity-specialized feedback connections, and RNNs without nonspecialized feedback connections were shown separately. (Paired t-test: *, p&lt;0.05; **, p&lt;0.01; ***, p&lt;0.001; n.s., not significant).</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-96402-fig5-figsupp3-v1.tif"/></fig><fig id="fig5s4" position="float" specific-use="child-fig"><label>Figure 5—figure supplement 4.</label><caption><title>The averaged activity of RNNs with disrupted feedback connectivity.</title><p>(<bold>A–B</bold>) The averaged activity of units in the motion module of the example RNN after disrupting the feedback connectivity is shown for different motion directions and coherence levels. Data in both IT (<bold>A</bold>) and CT (<bold>B</bold>) conditions were shown separately. (<bold>C</bold>) The averaged activity of units in the target module of the example RNN after disrupting the feedback connectivity is shown separately for different saccade directions and motion coherence levels. (<bold>D–E</bold>) The averaged population activity of all direction-selective units in the motion module of all the trained RNNs (N=50) after disrupting the feedback connectivity is shown separately for both IT condition (<bold>D</bold>) and CT conditions (<bold>E</bold>). (<bold>F</bold>) The averaged population activity of units in the target module of all the trained RNNs after disrupting feedback connectivity is shown for different saccade directions and motion coherence levels.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-96402-fig5-figsupp4-v1.tif"/></fig><fig id="fig5s5" position="float" specific-use="child-fig"><label>Figure 5—figure supplement 5.</label><caption><title>The behavioral performance and unit activity in the RNNs that were initialized without feedback connectivity.</title><p>(<bold>A–B</bold>) The performance accuracies (<bold>A</bold>) and reaction times (<bold>B</bold>) of all 50 trained RNNs are shown separately for each motion coherence level. (<bold>C</bold>) The averaged population activity of all motion direction selective units in the motion module is shown for each motion direction and coherence level. Data from all 50 networks were averaged. (<bold>D</bold>) The averaged population activity of all saccade direction selective units in the target module is shown for each saccade direction and coherence level. (<bold>E–F</bold>) The averaged population activities of all direction-selective units in the motion module of all 50 RNNs were shown separately for CT (<bold>E</bold>) and IT conditions (<bold>F</bold>). (<bold>G</bold>) The comparisons of the motion DS between the CT and IT conditions (quantified by ROC analysis) in the motion module of all 50 RNNs are shown separately for different coherence levels. (<bold>H</bold>) The comparisons of the performance accuracies between full-model RNNs and RNNs trained without feedback connections (Paired t-test: **, p&lt;0.01; ***, p&lt;0.001; n.s., not significant).</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-96402-fig5-figsupp5-v1.tif"/></fig><fig id="fig5s6" position="float" specific-use="child-fig"><label>Figure 5—figure supplement 6.</label><caption><title>The performance accuracies of the additional RNNs trained without feedback connectivity are shown separately for each motion coherence level.</title><p>These RNNs were initialized with greater recurrent connection probabilities than the full-model RNNs, so that the number of the total trainable connection weights matched that in the full-model RNNs. (Paired t-test: **, p&lt;0.01; ***, p&lt;0.001; n.s., not significant).</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-96402-fig5-figsupp6-v1.tif"/></fig></fig-group><p>To test the causal contribution of the selectivity-specific feedback connections to the modulation of action selection on sensory evaluation, we conducted three projection-specific inactivation experiments in the RNNs (STAR Methods). First, we performed nonspecific ablation of all the feedback projections from the target module to the motion module when testing with untrained motion stimuli. In most of the tested RNNs, this caused a dramatic reduction in their performance in all nonzero-coherence stimulus conditions (<xref ref-type="fig" rid="fig5">Figure 5C</xref>; two-way ANOVA: p=4.74e-80, <italic>F</italic>=704.65) as well as significantly prolonged RTs for high- and medium-coherence stimulus conditions (<xref ref-type="fig" rid="fig5">Figure 5D</xref>; two-way ANOVA: p=2.45e-4, <italic>F</italic>=13.79). The mean RTs became more dispersed across all the trained RNNs and did not differ among different motion coherences after ablation (one-way ANOVA: p=0.68, <italic>F</italic>=0.50). Ablating feedback connections significantly affected the motion DS in the motion module. On average, although the averaged motion DS did not decrease after ablation (<xref ref-type="fig" rid="fig5s1">Figure 5—figure supplement 1A, C</xref>), the difference in the motion DS between the CT and IT conditions vanished (<xref ref-type="fig" rid="fig5">Figure 5E–G</xref> and <xref ref-type="fig" rid="fig5s2">Figure 5—figure supplement 2A, B</xref>; two-way ANOVA: P<sub>(CT vs. IT)</sub>=0.14, <italic>F</italic>=2.21). These results indicated a dramatic reduction in the nonlinear feedback modulation on sensory evaluation by action selection in the RNNs. To further test the importance of different patterns of feedback connectivity for the RNNs to solve the FVDM task, we next performed pattern-specific ablation of the feedback connections in RNNs. We separated the feedback projections in each RNN into specific (i.e. the feedback connection weights were positive or negative between the selectivity-matched or selectivity-nonmatched unit pairs, respectively) and nonspecific groups. Despite similar numbers and weights of the feedback connections in these two groups (<xref ref-type="fig" rid="fig5s3">Figure 5—figure supplement 3A, B</xref>), ablating the feedback connection in the specific group versus the nonspecific group resulted in much more severe impairments in the RNNs’ behavior performance (<xref ref-type="fig" rid="fig5s3">Figure 5—figure supplement 3C, D</xref>). These results indicated that the feedback connections that reflected the learned stimulus–response association were crucial for the RNNs to solve the FVDM task.</p><p>Second, we disrupted the selectivity-specific feedback connectivity without changing the total strength of the feedback connections by randomly rearranging the feedback connection weights. This also resulted in a significant reduction in the RNNs’ performance accuracy for nonzero-coherence motion stimuli (<xref ref-type="fig" rid="fig5">Figure 5C</xref>; two-way ANOVA: p=1.38e-90, <italic>F</italic>=883.61) and prolonged RTs for high- and medium-coherence motion stimuli (<xref ref-type="fig" rid="fig5">Figure 5D</xref>; two-way ANOVA: p=1.94e-12, <italic>F</italic>=54.06). The changes of RNN units’ activity patterns after scrambling feedback connections were similar to the effects after feedback connectivity was fully ablated (<xref ref-type="fig" rid="fig5s1">Figure 5—figure supplements 1B, C</xref> and <xref ref-type="fig" rid="fig5s4">4A, B, D and E</xref>). Particularly, the levels of nonlinear modulation of sensory evaluation by saccade selection dramatically decreased, as evident by the diminished difference in the motion DS between the CT and IT conditions (<xref ref-type="fig" rid="fig5">Figure 5H</xref>, two-way ANOVA: p=5.81e-12, <italic>F</italic>=51.52).</p><p>Third, we trained another 50 RNNs without feedback connectivity to learn the FVMD task. Similar to the full-model RNNs, all 50 networks converged to perform the FVMD task with high accuracies (&gt;99%) after training and exhibited coherence-dependent performances when tested with untrained stimuli (<xref ref-type="fig" rid="fig5s5">Figure 5—figure supplement 5A, B</xref>). Meanwhile, units in the motion module and target modules exhibited coherence-dependent motion DS and saccade DS, respectively (<xref ref-type="fig" rid="fig5s5">Figure 5—figure supplement 5C, D</xref>). Consistent with the above connectivity ablation experiment, units in the motion module of these RNNs did not exhibit different levels of motion DS between CT and IT conditions (<xref ref-type="fig" rid="fig5s5">Figure 5—figure supplement 5E–G</xref>; two-way ANOVA: p=0.63, <italic>F</italic>=0.24), indicating no noticeable nonlinear feedback modulation on sensory evaluation by action selection. Importantly, the performance accuracies of these RNNs decreased significantly when tested with untrained nonzero-coherence stimuli (<xref ref-type="fig" rid="fig5s5">Figure 5—figure supplement 5H</xref>; two-way ANOVA: p=1.46e-14, <italic>F</italic>=65.64), as compared to the full-model RNNs. Furthermore, we trained an additional 50 RNNs without feedback connections to learn the FVMD task. These RNNs were initialized with greater recurrent connection probabilities than the full-model RNNs, such that the number of total trainable connection weights matched that in the full-model RNNs. Interestingly, these RNNs still exhibited significantly lower performance accuracies when tested with high- and medium-coherence stimuli relative to the full-model RNNs (<xref ref-type="fig" rid="fig5s6">Figure 5—figure supplement 6</xref>; two-way ANOVA: p=8.24e-6, <italic>F</italic>=20.60). Together, these results suggested that the nonlinear feedback modulation, which was mediated by the selectivity-specific feedback connections, was important for the RNNs to efficiently solve flexible decision tasks.</p></sec><sec id="s2-5"><title>Nonlinear feedback modulation enhanced the decision consistency by strengthening the attractor basins of network dynamics</title><p>Our RNN modeling indicates a crucial role for nonlinear feedback modulation in optimizing flexible decision-making. Subsequently, we delved into the computational mechanisms embodied by nonlinear feedback modulation during the decision-making process. Specifically, we examined the unit activity in the target module, a direct contributor to the decision outputs of RNNs. Strikingly, the projection-specific inactivation experiments led to a significant reduction in the magnitude of saccade DS in the nonzero-coherence trials (<xref ref-type="fig" rid="fig6">Figure 6A–C</xref>, P<sub>(ablating feedback)</sub>=6.90e-5, <italic>F</italic>=16.29; P<sub>(shuffling feedback)</sub>=1.2e-19, <italic>F</italic>=95.08; two-way ANOVA). Additionally, saccade DS emerged earlier than the motion stimulus onset in the nonzero-coherence trials, and its positive correlation with the motion coherence levels diminished after the projection-specific inactivation (<xref ref-type="fig" rid="fig6">Figure 6A–C</xref> and <xref ref-type="fig" rid="fig5s2">Figure 5—figure supplements 2C</xref> and <xref ref-type="fig" rid="fig5s4">4C, F</xref>; mean r<sub>(ablating feedback)</sub>=–0.034; mean r<sub>(shuffling feedback)</sub> = –0.030). These disrupted patterns of saccade DS observed in the target module following projection-specific inactivation aligned with the decreased decision consistency of RNNs, where decision consistency reflects the degree of agreement in the model’s choices under specific task conditions. This suggests a diminished reliance on sensory input and an increased dependence on internal noise in the decision-making process.</p><fig id="fig6" position="float"><label>Figure 6.</label><caption><title>The computational mechanisms underlying the nonlinear feedback modulation in decision-making.</title><p>(<bold>A</bold>) The averaged activity of units in the target module of the example RNN, after the feedback connections were ablated, is shown separately for different saccade directions and coherence levels. (<bold>B</bold>) The averaged saccade DS in the target module of the example RNN after full feedback ablation. (<bold>C</bold>) The averaged saccade DS in the target module of the full-model RNNs, RNNs without feedback connections, and RNNs with shuffled feedback connections. (Paired t-test: *, p&lt;0.05; **, p&lt;0.01; ***, p&lt;0.001; n.s., not significant). (<bold>D–G</bold>) The evolution of the averaged energy landscapes was shown over time. A numerical approximation of the energy landscape in the 1-D decision (saccade choice) subspace is constructed for both full-model RNNs and RNNs with various types of projection-specific inactivation. Each plot represents the averaged results of 50 RNNs, where Position 0 signifies the SVM decision boundary, and the vertical dashed line marks the time of motion stimulus onset. Unvisited portions of the state space are left blank as there is no gradient or potential estimate. (<bold>H–K</bold>) Averaged numerical estimate of energy landscapes for trials with different task difficulty levels (motion coherence) (N=50). Results from two different saccade choices were averaged together. Only the potential values at positions continuously visited by four or more models were retained. Shaded areas denote ± SEM.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-96402-fig6-v1.tif"/></fig><p>Previous studies have demonstrated that attractor dynamics in networks can explain choice consistency, with steeper landscapes around attractor basins reflecting consistent decisions (<xref ref-type="bibr" rid="bib8">Deco et al., 2013</xref>; <xref ref-type="bibr" rid="bib14">Finkelstein et al., 2021</xref>; <xref ref-type="bibr" rid="bib59">Wang et al., 2023</xref>; <xref ref-type="bibr" rid="bib57">Wang, 2002</xref>; <xref ref-type="bibr" rid="bib62">Wong et al., 2007</xref>). Consequently, we investigated attractor dynamics in the state space of network activity that underlies decision-making variability in RNNs with different types of feedback connectivity. Similar to prior studies (<xref ref-type="bibr" rid="bib59">Wang et al., 2023</xref>), we examined the neural dynamics underlying decisions in a 1-D neural subspace using unit activity in the target module responsible for saccade choices (see Materials and methods). Beginning with the reconstruction of a numerical approximation of the energy landscape in this 1-D subspace, we explored changes in this landscape after different types of projection-specific inactivation. This revealed a dramatic reduction in the depth of attractor basins in the energy landscape of population activity after ablating all feedback connectivity (<xref ref-type="fig" rid="fig6">Figure 6D–E</xref>, paired t-test: p=2.28e-11, t(49) = –8.61). Moreover, ablating the feedback connections led to a more severe reduction in the depth of attractor basins in the network dynamics within the specific group compared to the nonspecific groups (<xref ref-type="fig" rid="fig6">Figure 6F–G</xref>, paired t-test: p=1.59e-6, t(49) = -5.46).</p><p>We further examined how the energy landscape in the 1-D subspace changed in relation to task difficulty (motion coherence). Consistent with prior findings (<xref ref-type="bibr" rid="bib59">Wang et al., 2023</xref>), trials with lower decision consistency (trials using lower motion coherence) exhibited shallower attractor basins at the time of decision for all types of RNNs (<xref ref-type="fig" rid="fig6">Figure 6H–K</xref>). However, both the depth and the positional separation of attractor basins in the network dynamics significantly decreased for all non-zero motion coherence levels after the ablation of all feedback connections (comparing <xref ref-type="fig" rid="fig6">Figure 6I</xref> with <xref ref-type="fig" rid="fig6">Figure 6H</xref>; P<sub>(depth)</sub>=5.20e-25, <italic>F</italic>=122.80; P<sub>(position)</sub>=1.82e-27, <italic>F</italic>=137.75; two-way ANOVA). Notably, this reduction in basin depth and separation was more pronounced in the specific group compared to the nonspecific groups after ablating the feedback connections (comparing <xref ref-type="fig" rid="fig6">Figure 6J</xref> with <xref ref-type="fig" rid="fig6">Figure 6K</xref>; P<sub>(depth)</sub>=2.65e-13, <italic>F</italic>=57.35; P<sub>(position)</sub>=3.73e-14, <italic>F</italic>=61.79; two-way ANOVA). These results might underlie the computational mechanisms that explain the observed reduction in the decision consistency of RNNs following projection-specific inactivation: the shallower and closer attractor basins after ablating feedback connections resulted in less consistent decisions. This happened because the variability in neural activity made it more likely for population activity to stochastically shift out of the shallower basins and into nearby alternative ones.</p></sec></sec><sec id="s3" sec-type="discussion"><title>Discussion</title><p>Here, we show that primate LIP activity related to evaluating the visual motion stimulus was nonlinearly modulated by an impending saccade choice that was used to report decisions during a FVMD task, even though the saccades were toward non-RF locations. This suggests that the sensory evaluation and action selection may proceed iteratively during decision-making. This view is also consistent with the common observation that action selection-related activity arises at the early stage of evidence accumulation during decision-making (<xref ref-type="bibr" rid="bib22">Gold and Shadlen, 2007</xref>; <xref ref-type="bibr" rid="bib47">Roitman and Shadlen, 2002</xref>; <xref ref-type="bibr" rid="bib53">Shushruth et al., 2018</xref>), as well as our observation that the modulation of action selection on sensory evaluation emerged during the early task period even before motion stimulus onset in the FVMD task. Brain areas that are related to different decision processes, although spatially separated (<xref ref-type="bibr" rid="bib65">Zhou and Freedman, 2019</xref>; <xref ref-type="bibr" rid="bib29">Katz et al., 2016</xref>; <xref ref-type="bibr" rid="bib28">Jun et al., 2021</xref>), likely form a real-time associated network to solve current decision tasks. The instantaneous result of sensory evaluation may be transmitted to the brain areas responsible for action selection during decision-making in a feedforward manner, and the action selection process may also exert a real-time modulation on the neural processing of sensory evaluation in a feedback manner.</p><p>The feedback modulation we observed during decision-making was distinct from the modulation of feature-based attention in early sensory cortex. Although both modulation effects match the stimulus tuning of recipient cells (<xref ref-type="bibr" rid="bib39">Motter, 1994a</xref>; <xref ref-type="bibr" rid="bib40">Motter, 1994b</xref>; <xref ref-type="bibr" rid="bib34">Martinez-Trujillo and Treue, 2004</xref>; <xref ref-type="bibr" rid="bib3">Bichot et al., 2005</xref>; <xref ref-type="bibr" rid="bib36">Maunsell and Treue, 2006</xref>), only the feedback modulation observed in the current study reflects the neural processing of decision-making. This is because only the decision-related component, not the stimulus-related component, of LIP activity was modulated by the monkeys’ later saccade choice during the FVMD task (<xref ref-type="fig" rid="fig3">Figure 3</xref>). This suggests that the feedback modulation from action selection to LIP activity was primarily related to the decision process rather than low-level sensory processing.</p><p>A recent study demonstrated that neurons in the middle temporal area responded more strongly to motion stimuli when monkeys saccaded toward their RFs in a standard decision task with a fixed mapping between motion stimuli and saccade directions (<xref ref-type="bibr" rid="bib33">Laamerad et al., 2024</xref>). This modulation emerged through the training process and contributed causally to the monkeys' following saccade choices. Consistently, we found that the response of LIP neurons to motion stimuli was more strongly correlated with the monkeys' decisions in the CT condition (saccades toward RFs) than in the IT condition, in a more flexible decision task. Together, these results suggest that the modulation of action selection on sensory processing may be a general process in perceptual decision-making. However, the observed modulation of saccade direction on LIP neurons' responses to motion stimuli cannot be simply explained by saccade DS. Several lines of evidence argue against this possibility. First, the modulation effect was nonlinear; specifically, neuronal firing rates increased for preferred motion directions but decreased for non-preferred directions (<xref ref-type="fig" rid="fig2">Figure 2I</xref>, <xref ref-type="fig" rid="fig2s1">Figure 2—figure supplement 1</xref>). This pattern is unlikely to be driven by a linear gain modulation based on saccade directions. Second, we found that LIP neurons exhibited similar levels of activity in both the CT and IT conditions (<xref ref-type="fig" rid="fig2">Figure 2M</xref>), which is inconsistent with the presence of clear saccade DS.</p><p>The selectivity-specific feedback modulation from action selection to sensory evaluation emerged in our multi-module RNNs during training, although the cross-module connections were randomly initialized before training. Importantly, our causal in-silico experiments demonstrated that these precise feedback connections played an essential role in mediating the modulation of action selection on sensory evaluation while solving the FVDM task. Previous studies showed that both the corticocortical feedback from the secondary visual cortex to the primary visual cortex and the corticogeniculate feedback in primates are organized into parallel streams resembling the reciprocal feedforward pathways (<xref ref-type="bibr" rid="bib12">Federer et al., 2021</xref>; <xref ref-type="bibr" rid="bib6">Briggs and Usrey, 2009</xref>; <xref ref-type="bibr" rid="bib7">Briggs, 2020</xref>), suggesting a potential functionally specific feedback connection in visual processing. However, to the best of our knowledge, a similar segregation of feedback that reflects the encoding properties of the target neurons has not been evident in the decision network in vivo. Therefore, it will be important for future studies to examine the connectivity and correlation of neural activity among neural groups related to different decision processes through sophisticated anatomical experimental approaches as well as multi-channel recordings in vivo.</p><p>Our brain includes extensive feedback connections across different brain areas, which, in some cases, even outnumber the feedforward connections (<xref ref-type="bibr" rid="bib7">Briggs, 2020</xref>; <xref ref-type="bibr" rid="bib24">Harris and Mrsic-Flogel, 2013</xref>). However, compared to the feedforward connections, much less is known about the function of feedback connections. Feedback modulation has been implicated in top-down modulation of neuronal responses in the early sensory cortex, such as attention and expectation, which facilitate the processing of important stimuli and suppress distractors (<xref ref-type="bibr" rid="bib38">Moore and Armstrong, 2003</xref>; <xref ref-type="bibr" rid="bib20">Gilbert and Li, 2013</xref>; <xref ref-type="bibr" rid="bib37">McManus et al., 2011</xref>). Furthermore, both experimental and computational studies have shown that weak decision-correlated neural activity (i.e. choice probability) as well as the correlated firing of pairs of neurons (i.e. noise correlation) in the early sensory cortex might partially result from feedback input in decision tasks (<xref ref-type="bibr" rid="bib41">Nienborg and Cumming, 2009</xref>; <xref ref-type="bibr" rid="bib4">Bondy et al., 2018</xref>; <xref ref-type="bibr" rid="bib60">Wimmer et al., 2015</xref>), suggesting a potential role for feedback connection in modulating early sensory processing during decision-making. Consistently, the nonlinear feedback modulation, mediated primarily by selectivity-specific feedback connections, was important for our multi-module RNNs to efficiently solve the FVMD task, as the RNNs’ decision behavior became more stochastic following ablating/disrupting the feedback connectivity. This was evident not only in the diminished behavioral performance of the RNNs but also in the disrupted patterns of activity related to saccade choice in the target module. Notably, the nonlinear feedback modulation intensified the attractor basins of the population activity associated with saccade choice, led to more reliable decisions based on sensory input. Our results unveil a novel pattern of feedback modulation during the neural processing of decision-making and suggest a potentially critical role that feedback modulation plays in increasing the consistency of flexible sensorimotor decisions.</p><p>Two-state attractor models have been widely employed to elucidate two-alternative forced decision-making processes (<xref ref-type="bibr" rid="bib8">Deco et al., 2013</xref>; <xref ref-type="bibr" rid="bib14">Finkelstein et al., 2021</xref>; <xref ref-type="bibr" rid="bib59">Wang et al., 2023</xref>; <xref ref-type="bibr" rid="bib57">Wang, 2002</xref>; <xref ref-type="bibr" rid="bib62">Wong et al., 2007</xref>; <xref ref-type="bibr" rid="bib45">Prat-Ortega et al., 2021</xref>; <xref ref-type="bibr" rid="bib61">Wong and Wang, 2006</xref>). In these models, decisions arise when network activity falls into one of two attractor basins. Previous studies have posited that decision consistency is influenced by the configuration of the energy landscape surrounding these attractor basins (<xref ref-type="bibr" rid="bib59">Wang et al., 2023</xref>; <xref ref-type="bibr" rid="bib62">Wong et al., 2007</xref>; <xref ref-type="bibr" rid="bib61">Wong and Wang, 2006</xref>). Essentially, steep-sided and deep-basin energy landscapes contribute to consistent decision-making, as it becomes challenging for internal noise to shift activity between basins. Conversely, when energy landscapes are relatively flat and attractor basins are shallow, decisions are generated more stochastically, as it is easier for internal noise to drive activity out of the attractor basins and into alternative ones. Consistently, our RNNs modeling showed that shallower and less separated attractor basins were associated with decreased decision consistency in more difficult trials. Building upon previous research, our results provide in silico evidence supporting the notion that the energy landscape within the state space of population activity causally influences decision consistency. Moreover, our findings present the initial circuit mechanism through which the configuration of the energy landscape for decision-related activity is modulated by feedback modulation, to our knowledge. Future studies are needed to explore the connections between different types of circuit connectivity and population activity dynamics in cognitive processing in vivo.</p><p>Our results are consistent with predictive coding theories of feedback function, which propose that an internal model of the world is generated in the brain based on sensory data and prior experience and is refined by incoming sensory data (<xref ref-type="bibr" rid="bib46">Rao and Ballard, 1999</xref>; <xref ref-type="bibr" rid="bib19">Friston and Kiebel, 2009</xref>; <xref ref-type="bibr" rid="bib1">Bastos et al., 2012</xref>; <xref ref-type="bibr" rid="bib52">Shipp, 2016</xref>). In terms of the architecture of hierarchical predictive coding schemes, different neuronal ensembles encode different attributes/choices in either the action selection or sensory evaluation process at each level of the cortical hierarchy during flexible decision-making. Meanwhile, the conditionally independent expectations are functionally segregated, so that descending predictions from the action selection process are limited to the sensory evaluation process on the matched/associated stimulus attribute but not the opposite attribute. The selectivity-specific feedback connectivity in our RNNs fits the functional segregation of expectation very well during the interplay between distinct neural processes of decision-making. Specifically, the neural ensembles related to either sensory evaluation or action selection processes for the same choice might form precise recurrently connected loops. The prediction signal carried by the precise feedback connections might facilitate sensory evaluation of the associated stimulus but prohibit evaluation of the nonmatched stimulus. This could, in turn, amplify the task-relevant sensory input, facilitate the sensorimotor transformation, and ultimately result in faster and more accurate action choice in flexible decisions. In future work, it will be important to use techniques such as projection-specific inactivation and microstimulation in vivo to test the causal contribution of feedback connectivity in decision-making and other cognitive functions.</p></sec><sec id="s4" sec-type="materials|methods"><title>Materials and methods</title><sec id="s4-1"><title>Behavioral task, stimulus display, and animal preparation</title><p>The flexible visual motion discrimination (FVMD) task (<xref ref-type="fig" rid="fig1">Figure 1A</xref>) has been reported previously (<xref ref-type="bibr" rid="bib65">Zhou and Freedman, 2019</xref>) and is briefly summarized below. In this task, monkeys were required to saccade to either the green or red targets based on the direction of the visual motion stimulus. Two motion directions (135°, 315°) were used, each with four different coherence levels (0%, 9%, 18%, 36% for monkey M; and 0%, 13%, 25%, 50% for monkey B) were tested. If the sample direction was 135°, the monkeys must saccade to the green target to receive a juice reward, whereas the 315° direction was associated with the red target. The rewarded target (red or green) was randomly chosen (with 50% probability) on each zero-coherence trial. The positions of red and green targets were randomly chosen between the two positions on each trial at each recording session. Therefore, there is no fixed mapping between motion stimulus and saccade direction.</p><p>To initiate each trial, monkeys must hold a touch bar and acquire gaze fixation. They then need to maintain fixation within a 2.0–2.5° window throughout the trial before their saccade choice. After a 500ms fixation period, two colored saccade targets appeared simultaneously at opposite positions relative to the fixation point with equal eccentricities (8° and 9° for Monkey M and B, respectively). 400ms later, a sample motion stimulus was presented at a location orthogonal to the axis of, but at the same eccentricity as, the saccade targets. We used motion stimuli that were full contrast, 8° diameter, random-dot movies composed of 190 dots per frame, and the dots moved at 10°/s. Monkeys needed to saccade to either red or green targets within a 60–2000ms window after sample stimulus onset. The two saccade targets were equidistant from the stimulus, with the distance typically ranging from 12 to 15 degrees. A juice reward would be delivered to the monkeys if they made correct saccade choice.</p><p>Two male monkeys (<italic>Macaca mulatta</italic>, 15–16 years old, 8–14 kg) were trained on the FVMD task and implanted with a head post as well as a recording chamber positioned over PPC. Our surgical, behavioral, and neurophysiological approach has been described in detail in a previous study (<xref ref-type="bibr" rid="bib65">Zhou and Freedman, 2019</xref>). Stereotaxic coordinates for chamber placement were determined from magnetic resonance imaging (MRI) scans obtained before chamber implantation. LIP chambers were centered on the intraparietal sulcus (IPS), 4.0 mm posterior to the intra-aural line and 1.0 mm lateral from the midline for monkey M, and 0 mm anterior to the intra-aural line and 15.0 mm lateral from the midline for monkey B. Monkeys were housed in individual cages under a 12 hr light/dark cycle. Behavioral training and experimental recordings were conducted during the light portion of the cycle. Monkeys sat comfortably while head-fixed in a custom-made primate chair inside a dark experiment rig. The task stimuli were displayed on a 21-inch color CRT monitor (1280*1024 resolution, 75 Hz refresh rate, 57 cm viewing distance). Both monkeys were tested with identical stimuli and timing. A solenoid-operated reward system was used to deliver juice reward to the monkeys. Monkeys’ eye positions were monitored by an optical eye tracker (SR Research) at a sampling rate of 1 kHz and stored for offline analysis. Stimulus presentation, task events, rewards, and behavioral data acquisition were accomplished using an Intel-based PC equipped with MonkeyLogic software running in MATLAB (<ext-link ext-link-type="uri" xlink:href="http://www.monkeylogic.net">http://www.monkeylogic.net</ext-link>). All experimental and surgical procedures were performed in strict accordance with the recommendations in the Guide for the Care and Use of Laboratory Animals of the National Institutes of Health. All of the animals were handled according to approved institutional animal care and use committee (IACUC) protocol #71887 of The University of Chicago.</p></sec><sec id="s4-2"><title>Electrophysiological recording</title><p>We used either 75 μm tungsten microelectrodes (FHC, ~1 MΩ) or 16-channel V-Probes (Plexon) to record single neuron activity in LIP. Neurophysiological signals were amplified, digitized, and stored for offline spike sorting (Plexon) to verify the quality and stability of neuronal isolations. We recorded neuronal activity in an MGS task to map LIP RF locations before each FVMD recording session.</p><p>Our LIP recordings targeted different hemispheres in the two monkeys (monkey M: left hemisphere; monkey Q: right hemisphere). Therefore, the CT condition and IT conditions in <xref ref-type="fig" rid="fig1">Figure 1F and G</xref> referred to opposite saccade directions (target locations) between the two monkeys. For monkey M, the CT condition corresponded to the trials in which the correct saccade target was on the right visual field, whereas the CT condition for monkey Q referred to the trials in which the correct saccade was toward the left visual field. We localized LIP in each monkey according to the patterns of neuronal activity in the MGS task (i.e. spatial selectivity during stimulus presentation and delay). All neurons included in the dataset were recorded from the same locations (the same grid holes and similar depths: ~5–10 mm from the cortical surface) where we encountered spatial selectivity in the MGS task. LIP neurons were also identified based on anatomical criteria, such as the location of each electrode track relative to that expected from the MRI scans, the pattern of gray–white matter transitions encountered on each electrode penetration, and the relative depths of each neuron.</p><p>We aimed to present the visual motion stimulus inside the RFs of the identified neurons during each recording session. For single-channel electrode recording, only neurons that exhibited visual responses to the motion stimuli during prescreening (tested with the FVMD task) were recorded with sufficient trials (~300–600) of the FVDM task. For neurons exhibiting clear spatial RFs during the MGS task, we presented the motion stimulus inside LIP neurons’ RFs, while for those neurons that did not show a clear RF during the MGS task, we presented motion stimuli in the positions (always in the visual field contralateral to the recorded hemisphere) in which neurons exhibited the strongest response to the motion stimuli. For the multi-channel recordings, we recorded all neurons isolated across all channels and presented the motion stimulus inside one of the isolated neurons’ RFs. Because adjacent recording sites were located 100 µm apart, nearby neurons typically showed similar RF locations.</p></sec><sec id="s4-3"><title>Data analysis</title><sec id="s4-3-1"><title>Neuronal pre-screening</title><p>While part of the neural data was presented in a previous report (<xref ref-type="bibr" rid="bib65">Zhou and Freedman, 2019</xref>), the current analysis focuses on a different phenomenon which was not examined previously. We included all neurons recorded from single-channel electrodes for the analysis. For multi-channel recordings, we only included the neurons which showed significant modulation (different from fixation period activity, one-way ANOVA, p&lt;0.01) of their averaged activity across all motion stimuli because the stimulus could not always be presented within the RF of all the recorded neurons. The low-firing neurons whose maximum firing rates were less than 2.0 spikes/s (to the direction producing greater average responses) during stimulus presentation were also excluded for further analysis. We then applied a one-way ANOVA test to compare activity between the two different motion directions during the period following motion stimulus onset (50–250ms after motion stimulus onset) to select neurons that showed significant motion DS during the decision period. Only neurons that showed significant (p&lt;0.01) DS were used for further analysis.</p></sec><sec id="s4-3-2"><title>Determination of RF</title><p>To determine each neuron’s RF, we analyzed the average firing rates during both the target presentation and delay periods of the MGS task. The RF centers of neurons with significant RFs were determined through a two-step process. First, we selected neurons that exhibited significant RFs in the MGS based on the following criteria: (1) there must be a significant activity difference across the eight target locations and (2) the mean activity during the selected periods should be significantly greater than the baseline activity during the fixation period. Second, for neurons meeting these criteria, we fitted their responses across the eight conditions to a Gaussian function, using the center of the fitted distribution as the RF center.</p></sec><sec id="s4-3-3"><title>ROC analysis</title><p>To quantify each neuron’s DS in the FVMD task, we applied an ROC analysis to the distribution of firing rates within sliding windows (100ms width, 5ms steps). The ROC value, which ranges between 0.0 and 1.0, indicates the performance of an ideal observer in assigning motion direction based on each neuron’s trial-by-trial firing rates. Values of 1.0 and 0.0 correspond to perfect classification (i.e. strong DS), while a value of 0.5 indicates chance-level classification performance (i.e. no DS). For trials with zero coherence motion, we assigned direction labels on each trial based on the monkey’s choice.</p><p>In <xref ref-type="fig" rid="fig3">Figure 3</xref>, in order to test whether DS reflected monkeys’ trial-by-trial choices, we used an ROC analysis to quantify whether LIP activity correlated with monkeys’ trial-by-trial categorical choices more than the physical direction of motion stimulus by analyzing both correct and error trials. We only included low coherence trials in this analysis because there were sufficient numbers of error trials (average performance: Monkey M: 74% correct, Monkey B: 67% correct). LIP neuronal activity was analyzed by ROC according to either the monkey’s trial-by-trial categorical choices or the direction of the sample stimulus on each trial. Furthermore, for this analysis, we only used neurons for which we recorded sufficient trials (for both correct and error trials, N&gt;4) for the low coherence condition of each motion direction (n=45).</p></sec><sec id="s4-3-4"><title>Partial correlation analysis</title><p>We performed a partial correlation analysis to quantify the correlation between LIP neural activity and the monkeys’ trial-by-trial categorical choices or the physical motion direction of the stimulus using all trials. For each trial, we obtained three parameters for the calculation: the stimulus direction, the pre-choice neuronal activity, and the monkeys’ choice. We assigned the stimulus directions with different values for different directions and coherence levels: positive and negative values were used for preferred and nonpreferred directions, respectively, while 4, 2, 1, and 0 are used for coding the high, medium, low, and zero coherence levels. We also assigned different values to different choice directions (−2 for choosing the preferred direction, and +2 for choosing the nonpreferred direction). Two measures were then calculated: r stimulus = r (neuronal activity, stimulus direction| choice direction), the partial correlation between neuronal activity and stimulus direction given the monkeys’ choices; and r choice = r (neuronal activity, choice direction | stimulus direction), the partial correlation between neuronal activity and the monkeys’ categorical choice given the stimulus direction. In <xref ref-type="fig" rid="fig3">Figure 3</xref>, we used the mean activity within a sliding window (100ms width, sliding with 5ms steps) for each neuron to perform the partial correlation analysis.</p></sec><sec id="s4-3-5"><title>Modulation index</title><p>We have calculated a modulation index for each neuron to reflect the influence of saccade direction on neuron’s response to visual stimuli. The modulation index is calculated as:<disp-formula id="equ1"><alternatives><mml:math id="m1"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>δ</mml:mi><mml:mrow><mml:mi>c</mml:mi><mml:mi>o</mml:mi><mml:mi>n</mml:mi><mml:mi>t</mml:mi><mml:mi>r</mml:mi><mml:mi>a</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:msubsup><mml:mi>r</mml:mi><mml:mrow><mml:mi>p</mml:mi><mml:mi>r</mml:mi><mml:mi>e</mml:mi><mml:mi>f</mml:mi></mml:mrow><mml:mrow><mml:mi>c</mml:mi><mml:mi>o</mml:mi><mml:mi>n</mml:mi><mml:mi>t</mml:mi><mml:mi>r</mml:mi><mml:mi>a</mml:mi></mml:mrow></mml:msubsup><mml:mo>−</mml:mo><mml:msubsup><mml:mi>r</mml:mi><mml:mrow><mml:mi>n</mml:mi><mml:mi>o</mml:mi><mml:mi>n</mml:mi><mml:mo>−</mml:mo><mml:mi>p</mml:mi><mml:mi>r</mml:mi><mml:mi>e</mml:mi><mml:mi>f</mml:mi></mml:mrow><mml:mrow><mml:mi>c</mml:mi><mml:mi>o</mml:mi><mml:mi>n</mml:mi><mml:mi>t</mml:mi><mml:mi>r</mml:mi><mml:mi>a</mml:mi></mml:mrow></mml:msubsup></mml:mrow></mml:mstyle></mml:math><tex-math id="t1">\begin{document}$$\displaystyle \delta_{contra}=r_{pref}^{contra}-r_{non-pref}^{contra}$$\end{document}</tex-math></alternatives></disp-formula><disp-formula id="equ2"><alternatives><mml:math id="m2"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>δ</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>p</mml:mi><mml:mi>s</mml:mi><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:msubsup><mml:mi>r</mml:mi><mml:mrow><mml:mi>p</mml:mi><mml:mi>r</mml:mi><mml:mi>e</mml:mi><mml:mi>f</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mi>p</mml:mi><mml:mi>s</mml:mi><mml:mi>i</mml:mi></mml:mrow></mml:msubsup><mml:mo>−</mml:mo><mml:msubsup><mml:mi>r</mml:mi><mml:mrow><mml:mi>n</mml:mi><mml:mi>o</mml:mi><mml:mi>n</mml:mi><mml:mo>−</mml:mo><mml:mi>p</mml:mi><mml:mi>r</mml:mi><mml:mi>e</mml:mi><mml:mi>f</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mi>p</mml:mi><mml:mi>s</mml:mi><mml:mi>i</mml:mi></mml:mrow></mml:msubsup></mml:mrow></mml:mstyle></mml:math><tex-math id="t2">\begin{document}$$\displaystyle \delta_{ipsi}=r_{pref}^{ipsi}-r_{non-pref}^{ipsi}$$\end{document}</tex-math></alternatives></disp-formula><disp-formula id="equ3"><alternatives><mml:math id="m3"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mrow><mml:mi mathvariant="normal">M</mml:mi><mml:mi mathvariant="normal">I</mml:mi></mml:mrow><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:msub><mml:mi>δ</mml:mi><mml:mrow><mml:mi>c</mml:mi><mml:mi>o</mml:mi><mml:mi>n</mml:mi><mml:mi>t</mml:mi><mml:mi>r</mml:mi><mml:mi>a</mml:mi></mml:mrow></mml:msub><mml:mo>−</mml:mo><mml:msub><mml:mi>δ</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>p</mml:mi><mml:mi>s</mml:mi><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:msub><mml:mi>δ</mml:mi><mml:mrow><mml:mi>c</mml:mi><mml:mi>o</mml:mi><mml:mi>n</mml:mi><mml:mi>t</mml:mi><mml:mi>r</mml:mi><mml:mi>a</mml:mi></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mi>δ</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>p</mml:mi><mml:mi>s</mml:mi><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfrac><mml:mo>,</mml:mo></mml:mrow></mml:mstyle></mml:math><tex-math id="t3">\begin{document}$$\displaystyle {\rm MI} = \frac{\delta_{contra}-\delta_{ipsi}}{\delta_{contra}+\delta_{ipsi}},$$\end{document}</tex-math></alternatives></disp-formula></p><p>where <inline-formula><alternatives><mml:math id="inf1"><mml:msubsup><mml:mrow><mml:mi>r</mml:mi></mml:mrow><mml:mrow><mml:mi>p</mml:mi><mml:mi>r</mml:mi><mml:mi>e</mml:mi><mml:mi>f</mml:mi></mml:mrow><mml:mrow><mml:mi>c</mml:mi><mml:mi>o</mml:mi><mml:mi>n</mml:mi><mml:mi>t</mml:mi><mml:mi>r</mml:mi><mml:mi>a</mml:mi></mml:mrow></mml:msubsup></mml:math><tex-math id="inft1">\begin{document}$r_{pref}^{contra}$\end{document}</tex-math></alternatives></inline-formula> represents the average firing rate from 50ms to 250ms after sample onset for all contralateral saccade trials with a neuron’s preferred moving direction of visual stimuli. The naming conventions are the same for <inline-formula><alternatives><mml:math id="inf2"><mml:msubsup><mml:mrow><mml:mi>r</mml:mi></mml:mrow><mml:mrow><mml:mi>n</mml:mi><mml:mi>o</mml:mi><mml:mi>n</mml:mi><mml:mo>-</mml:mo><mml:mi>p</mml:mi><mml:mi>r</mml:mi><mml:mi>e</mml:mi><mml:mi>f</mml:mi></mml:mrow><mml:mrow><mml:mi>c</mml:mi><mml:mi>o</mml:mi><mml:mi>n</mml:mi><mml:mi>t</mml:mi><mml:mi>r</mml:mi><mml:mi>a</mml:mi></mml:mrow></mml:msubsup></mml:math><tex-math id="inft2">\begin{document}$r_{non-pref}^{contra}$\end{document}</tex-math></alternatives></inline-formula>, <inline-formula><alternatives><mml:math id="inf3"><mml:msubsup><mml:mrow><mml:mi>r</mml:mi></mml:mrow><mml:mrow><mml:mi>p</mml:mi><mml:mi>r</mml:mi><mml:mi>e</mml:mi><mml:mi>f</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mi>p</mml:mi><mml:mi>s</mml:mi><mml:mi>i</mml:mi></mml:mrow></mml:msubsup></mml:math><tex-math id="inft3">\begin{document}$r_{pref}^{ipsi}$\end{document}</tex-math></alternatives></inline-formula> , and <inline-formula><alternatives><mml:math id="inf4"><mml:mstyle><mml:mrow><mml:msubsup><mml:mi>r</mml:mi><mml:mrow><mml:mi>n</mml:mi><mml:mi>o</mml:mi><mml:mi>n</mml:mi><mml:mo>−</mml:mo><mml:mi>p</mml:mi><mml:mi>r</mml:mi><mml:mi>e</mml:mi><mml:mi>f</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mi>p</mml:mi><mml:mi>s</mml:mi><mml:mi>i</mml:mi></mml:mrow></mml:msubsup></mml:mrow></mml:mstyle></mml:math><tex-math id="inft4">\begin{document}$r_{non-pref}^{ipsi}$\end{document}</tex-math></alternatives></inline-formula>. An MI value between 0 and 1 indicates higher modulation in contralateral saccade trials, and an MI value between –1 and 0 indicates higher modulation in ipsilateral saccade trials.</p></sec><sec id="s4-3-6"><title>dPCA analysis</title><p>We conducted demixed principal component analysis using the methodology and the <ext-link ext-link-type="uri" xlink:href="https://github.com/machenslab/dPCA">code</ext-link> from a previous study (<xref ref-type="bibr" rid="bib32">Kobak et al., 2016</xref>; <xref ref-type="bibr" rid="bib5">Brendel et al., 2020</xref>) to reduce the dimensionality of the population activity as the standard PCA and demixes all task variables. Specifically, we tested how much each task variable (motion direction of sample stimuli, saccade direction, motion-saccade interaction, timing) contributes to the LIP population activity during the DMC task.</p><p>As demonstrated in the previous study, the dPCA finds separate decoder (F) and encoder (D) matrices for each task variable (∅) by minimizing the loss function:<disp-formula id="equ4"><alternatives><mml:math id="m4"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msub><mml:mi>L</mml:mi><mml:mrow><mml:mi>d</mml:mi><mml:mi>P</mml:mi><mml:mi>C</mml:mi><mml:mi>A</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:munder><mml:mo>∑</mml:mo><mml:mn>0</mml:mn></mml:munder><mml:mo fence="false" stretchy="false">‖</mml:mo><mml:msub><mml:mi>X</mml:mi><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msub><mml:mo>−</mml:mo><mml:msub><mml:mi>F</mml:mi><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msub><mml:msub><mml:mi>D</mml:mi><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msub><mml:mi>X</mml:mi><mml:msup><mml:mo fence="false" stretchy="false">‖</mml:mo><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:mstyle></mml:mrow></mml:mstyle></mml:math><tex-math id="t4">\begin{document}$$\displaystyle  L_{dPCA}=\underset{0}{\sum }\| X_{0}- F_{0}D_{0}X\| ^{2}$$\end{document}</tex-math></alternatives></disp-formula></p><p>where X is a linear decomposition of the data matrix, which contains the instantaneous firing rate of the recorded neurons, into variable-specific averages:<disp-formula id="equ5"><alternatives><mml:math id="m5"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>X</mml:mi><mml:mo>=</mml:mo><mml:munder><mml:mo>∑</mml:mo><mml:mn>0</mml:mn></mml:munder><mml:msub><mml:mi>X</mml:mi><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mi>X</mml:mi><mml:mrow><mml:mi>n</mml:mi><mml:mi>o</mml:mi><mml:mi>i</mml:mi><mml:mi>s</mml:mi><mml:mi>e</mml:mi></mml:mrow></mml:msub></mml:mstyle></mml:mrow></mml:mstyle></mml:math><tex-math id="t5">\begin{document}$$\displaystyle  X=\underset{0}{\sum }X_{0}+X_{noise}$$\end{document}</tex-math></alternatives></disp-formula></p><p>Here, we decomposed the neural activities into four parts: condition-independent, stimulus-dependent (two motion directions with four coherence levels), saccade-dependent (two saccade directions), dependent on the stimulus-saccade interaction, and noise. The decoder and encoder axes permit us to reduce the data into a few components capturing the majority of the variance of the data dependent on each task variable.</p></sec></sec><sec id="s4-4"><title>Recurrent neural network (RNN) training</title><sec id="s4-4-1"><title>Network implementation</title><p>We trained biologically inspired networks to perform the FVMD task using methodology similar to previous studies (<xref ref-type="bibr" rid="bib66">Zhou et al., 2021</xref>; <xref ref-type="bibr" rid="bib35">Masse et al., 2019</xref>). We implemented multiple modules in the networks through constraints on the input/output structure and the initial recurrent connectivity of the hidden layer. Specifically, we built excitatory-inhibitory networks with 200 hidden units divided into two equal-size main modules to simulate two brain hemispheres. Each main module was further divided into two nominal modules, with each one only receiving the visual motion input (motion module) or target color input (target module), respectively. This design was intended to simulate the two neuron populations whose RFs covered the motion stimulus or saccade target in the monkey electrophysiology experiment (<xref ref-type="fig" rid="fig4">Figure 4A</xref>). Every nominal module was allocated one quarter of the excitatory units (40) and one quarter of the inhibitory units (10) in the overall network to ensure that the modules did not differ in their balance of excitation/inhibition prior to training. Meanwhile, in order to simulate the local and long-range connection structures in the brain, we set different levels of recurrent connectivity within and between different modules: the local (connectivity within each nominal module) recurrent connection density (probability) was the highest (50%); the across-RF (connectivity between the two nominal modules within the same main module) connection density was set to be in the medium level (25%); the cross-hemisphere (connectivity between either the motion modules or the target modules across different main modules) connection density was the lowest (10%). Only excitatory neurons could have ‘cross-hemisphere’ projections to the corresponding nominal module (e.g. from the motion module of the ‘left hemisphere’ to the motion module of the ‘right hemisphere’). Only the connection weight within the hidden layer was updated during training following methods described previously (<xref ref-type="bibr" rid="bib66">Zhou et al., 2021</xref>). In addition, the connection weights between network units are endowed with short-term synaptic plasticity, which is aimed to provide connection weights with activity-dependent fluctuation over short timescales within each trial.</p><p>The input to the network consisted of two parts: 9 motion input units and 8 target color input units. The preferred directions of motion input units were evenly spaced across 360°, with response tuning distributed according to a von Mises function. The value of the nth motion input unit was set to<disp-formula id="equ6"><alternatives><mml:math id="m6"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>r</mml:mi><mml:mrow><mml:mi>n</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mfrac><mml:mn>2</mml:mn><mml:mn>3</mml:mn></mml:mfrac><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mrow><mml:mi mathvariant="normal">a</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">c</mml:mi></mml:mrow><mml:msup><mml:mi>e</mml:mi><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>κ</mml:mi><mml:mrow><mml:mi mathvariant="normal">c</mml:mi><mml:mi mathvariant="normal">o</mml:mi><mml:mi mathvariant="normal">s</mml:mi></mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mrow><mml:mi>θ</mml:mi></mml:mrow><mml:mo>−</mml:mo><mml:msub><mml:mrow><mml:mi>θ</mml:mi></mml:mrow><mml:mrow><mml:mi>p</mml:mi><mml:mi>r</mml:mi><mml:mi>e</mml:mi><mml:mi>f</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:msup><mml:mo>+</mml:mo><mml:mi>b</mml:mi><mml:mrow><mml:mi class="mathcal" mathvariant="script">N</mml:mi></mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:mn>2</mml:mn></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>+</mml:mo><mml:msqrt><mml:mfrac><mml:mn>2</mml:mn><mml:mi>α</mml:mi></mml:mfrac><mml:mrow><mml:mi class="mathcal" mathvariant="script">N</mml:mi></mml:mrow></mml:msqrt><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>σ</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mi>n</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>+</mml:mo><mml:mrow><mml:mi mathvariant="normal">d</mml:mi></mml:mrow><mml:mo>,</mml:mo></mml:mrow></mml:mstyle></mml:math><tex-math id="t6">\begin{document}$$\displaystyle r_{n}=\frac{2}{3}\left (\mathrm{a}\mathrm{c}e^{\left (\kappa{\rm cos} \left (\mathrm{\theta }-\mathrm{\theta }_{pref}\right)\right)}+b\mathcal{N}\left (0,2\right)+\sqrt{\frac{2}{\alpha}\mathcal{N}}\left (0,\mathrm{\sigma }_{in}\right)\right) + \mathrm{d},$$\end{document}</tex-math></alternatives></disp-formula></p><p>where <inline-formula><alternatives><mml:math id="inf5"><mml:mi mathvariant="normal">α</mml:mi><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mi mathvariant="normal">Δ</mml:mi><mml:mi>t</mml:mi></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="normal">τ</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">m</mml:mi><mml:mi mathvariant="normal">e</mml:mi><mml:mi mathvariant="normal">m</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfrac></mml:math><tex-math id="inft5">\begin{document}$\mathrm{\alpha }=\frac{\mathrm{\Delta }t}{\mathrm{\tau }_{\mathrm{m}\mathrm{e}\mathrm{m}}}$\end{document}</tex-math></alternatives></inline-formula> , <inline-formula><alternatives><mml:math id="inf6"><mml:mi mathvariant="normal">θ</mml:mi></mml:math><tex-math id="inft6">\begin{document}$\mathrm{\theta }$\end{document}</tex-math></alternatives></inline-formula> is the direction of motion stimulus in radian, <inline-formula><alternatives><mml:math id="inf7"><mml:msub><mml:mrow><mml:mi mathvariant="normal">θ</mml:mi></mml:mrow><mml:mrow><mml:mi>p</mml:mi><mml:mi>r</mml:mi><mml:mi>e</mml:mi><mml:mi>f</mml:mi></mml:mrow></mml:msub></mml:math><tex-math id="inft7">\begin{document}$\mathrm{\theta }_{pref}$\end{document}</tex-math></alternatives></inline-formula> is the preferred direction of this motion input unit, <inline-formula><alternatives><mml:math id="inf8"><mml:mi mathvariant="normal">a</mml:mi><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mn>4</mml:mn></mml:mrow><mml:mrow><mml:msup><mml:mrow><mml:mi>e</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">κ</mml:mi></mml:mrow></mml:msup></mml:mrow></mml:mfrac></mml:math><tex-math id="inft8">\begin{document}$\mathrm{a}=\frac{4}{e^{\mathrm{\kappa }}}$\end{document}</tex-math></alternatives></inline-formula> after stimulus onset but 0 elsewhere, <inline-formula><alternatives><mml:math id="inf9"><mml:mstyle><mml:mrow><mml:mrow><mml:mi mathvariant="normal">c</mml:mi></mml:mrow><mml:mo>∈</mml:mo><mml:mrow><mml:mo>[</mml:mo><mml:mrow><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mo>]</mml:mo></mml:mrow></mml:mrow></mml:mstyle></mml:math><tex-math id="inft9">\begin{document}${\rm c}\in \left [0,1\right ]$\end{document}</tex-math></alternatives></inline-formula> is the coherence of the dot motion stimulus, <inline-formula><alternatives><mml:math id="inf10"><mml:mi>b</mml:mi></mml:math><tex-math id="inft10">\begin{document}$b$\end{document}</tex-math></alternatives></inline-formula> is a binary value that equals 0 before stimulus onset and 1 after that, and <inline-formula><alternatives><mml:math id="inf11"><mml:mi>d</mml:mi></mml:math><tex-math id="inft11">\begin{document}$d$\end{document}</tex-math></alternatives></inline-formula> is a constant visual input signal with an amplitude of 2 that decays with time. Specifically, for zero-coherence input, since <inline-formula><alternatives><mml:math id="inf12"><mml:mi>a</mml:mi><mml:mi>c</mml:mi><mml:msup><mml:mrow><mml:mi>e</mml:mi></mml:mrow><mml:mrow><mml:mfenced separators="|"><mml:mrow><mml:mi>κ</mml:mi><mml:mi>c</mml:mi><mml:mi>o</mml:mi><mml:mi>s</mml:mi><mml:mfenced separators="|"><mml:mrow><mml:mi>θ</mml:mi><mml:mo>-</mml:mo><mml:msub><mml:mrow><mml:mi>θ</mml:mi></mml:mrow><mml:mrow><mml:mi>p</mml:mi><mml:mi>r</mml:mi><mml:mi>e</mml:mi><mml:mi>f</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfenced></mml:mrow></mml:mfenced></mml:mrow></mml:msup></mml:math><tex-math id="inft12">\begin{document}$ace^{\left (\kappa cos\left (\theta -\theta _{pref}\right)\right)}$\end{document}</tex-math></alternatives></inline-formula> would be zero, we set this term as <inline-formula><alternatives><mml:math id="inf13"><mml:mn>0.4</mml:mn><mml:mi>m</mml:mi><mml:mi>a</mml:mi><mml:mi>x</mml:mi><mml:mfenced separators="|"><mml:mrow><mml:mi>c</mml:mi></mml:mrow></mml:mfenced></mml:math><tex-math id="inft13">\begin{document}$0.4max\left (c\right)$\end{document}</tex-math></alternatives></inline-formula>.</p><p>The target input units were initially evenly divided into two groups projected to the two target modules of hidden units. Each group was further divided into red and green subgroups. The color subgroup was set as active with an amplitude of 4/3 to represent the color within the projected target module, while the other color group remained silent (amplitude =0). An exponential decay filter was also used to fit the activity of sensory neurons in the early sensory cortex across time:<disp-formula id="equ7"><alternatives><mml:math id="m7"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mrow><mml:mi mathvariant="normal">f</mml:mi></mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mi>x</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:msup><mml:mrow><mml:mo>(</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mn>3</mml:mn></mml:mfrac><mml:mo>)</mml:mo></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msup><mml:mrow><mml:mi mathvariant="normal">x</mml:mi></mml:mrow><mml:mo>,</mml:mo></mml:mrow></mml:mstyle></mml:math><tex-math id="t7">\begin{document}$$\displaystyle \mathrm{f}\left (x\right)=\left (\frac{1}{3}\right)^{t}\mathrm{x},$$\end{document}</tex-math></alternatives></disp-formula></p><p>where <inline-formula><alternatives><mml:math id="inf14"><mml:mi>x</mml:mi></mml:math><tex-math id="inft14">\begin{document}$x$\end{document}</tex-math></alternatives></inline-formula> is the constant visual input for motion input and the color signal for color input, <inline-formula><alternatives><mml:math id="inf15"><mml:mi>t</mml:mi></mml:math><tex-math id="inft15">\begin{document}$t$\end{document}</tex-math></alternatives></inline-formula> is time in miliseconds.</p><p>The two output units of the network simulate two different saccade directions. In order to simulate the oculomotor control in the brain, each brain hemisphere (main module) projects much more densely to the contralateral response units (probability = 0.32) than the ipsilateral response units (probability = 0.08). To generate a probability distribution over output values at each time point, we also applied a softmax function to scale the response unit activities in the output layer.</p><p>To reduce the stochasticity of the network activity brought by input and output connections, we randomly sampled input and output weights from a normal distribution (<inline-formula><alternatives><mml:math id="inf16"><mml:mstyle><mml:mrow><mml:mrow><mml:mi mathvariant="fraktur">N</mml:mi></mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mn>0.2</mml:mn><mml:mo>,</mml:mo><mml:mspace width="thinmathspace"/><mml:mn>0.05</mml:mn></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mstyle></mml:math><tex-math id="inft16">\begin{document}$\mathfrak{N}\left (0.2,\, 0.05\right)$\end{document}</tex-math></alternatives></inline-formula>). In addition, the input weights were re-initialized if there were extreme values (the minimum value was smaller than ¾ of the maximum value) after multiplying the stimulus signal and weight of motion or target input. Similarly, the output weights were re-initialized if there were extreme values in the output weight values. The input units had excitatory and random projections to the recurrent units with a probability of 0.32. However, only the excitatory units in the target modules of each “hemisphere” could project to the output units. Both the input and output weights were fixed for each network during task training.</p></sec><sec id="s4-4-2"><title>Network training</title><p>The networks were trained using BrainPy <xref ref-type="bibr" rid="bib58">Wang et al., 2022</xref> on an Intel(R) Core(TM) i9-9900K CPU (3.60 GHz, 8 cores). The network was optimized using backpropagation through time (BPTT) and stochastic gradient descent with an Adam optimizer (default setting, first moment estimates decay rate = 0.9, second moment estimates decay rate = 0.999) to minimize a loss function. The network parameters (recurrent weights/biases) were optimized to minimize a loss function with three parts as in a previous study <xref ref-type="bibr" rid="bib66">Zhou et al., 2021</xref>: (a) a performance loss; (b) a metabolic cost on mean neuronal activity; and (c) a metabolic cost on connectivity. The gradient was clipped to a maximum L2 value of 0.1 to avoid the exploding gradient problem. During training, only the hidden unit-related parameters (weights, bias, and initial activities) were updated. The training process was terminated when the network’s performance accuracy reached 99% or until the maximum number of iterations (2000).</p><p>During each trial of the training and testing of the FVMD task, networks were first presented with two color targets through the target input units, and then presented with the motion direction through the motion input units. Both the motion and target inputs persisted until the end of each trial. A short time after the motion input (100ms, 5 time steps), the networks were required to report the direction of the stimulus motion by choosing the saccade target with the appropriate color. Specifically, each element of the task design in the FVMD task that the models were trained to perform was tailored to match those used in the monkey experiments: the directions of the motion stimuli, the target colors, as well as the task (stimulus) durations were the same as those used in monkey electrophysiology experiments. Trials were programmatically generated by constructing motion/target inputs to the networks at each timestep and the desired response (left saccade, right saccade) at each timestep. In total, we trained 50 networks to perform the FVDM task. All networks were first trained using motion directions with two coherence levels (60% and 90%) and were then tested using motion stimuli with another four different coherence levels (75%, 55%, 35%, and zero), which had never been presented during training. Besides the difference in the coherence of motion input, the color inputs remained the same during the testing period. All the networks achieved consistently high performance by the end of training (&gt;99% accuracy). All the important model hyperparameters were listed in <xref ref-type="supplementary-material" rid="supp1">Supplementary file 1</xref>.</p></sec><sec id="s4-4-3"><title>Quantification of the networks’ behavioral performance</title><p>To test whether our multi-module RNNs exhibited decision behavior similar to monkey subjects, we examined their performance accuracies and RTs when tested by novel stimuli with different coherence levels. The performance accuracy was defined as whether the output of the response units (starting from 100ms after stimulus onset to the trial end) matched the desired output. Furthermore, we defined the networks’ RTs as the time point from which the differences between two output units were greater than a threshold (0.8) for three consecutive time points after the stimulus onset. During some trials, the threshold was never reached until the end of the trial (500ms after the motion stimulus onset). In these cases, we artificially set the RT to be 600ms in these trials for further analysis.</p></sec><sec id="s4-4-4"><title>Analysis of RNN activity</title><p>We performed the same analyses on the RNN units as we did on the neurophysiology data. In <xref ref-type="fig" rid="fig4">Figures 4</xref>–<xref ref-type="fig" rid="fig5">5</xref>, data from both the example network and averaged results across all the networks were shown. For every network, we only included the units which exhibited at least one kind of task-related modulation during the test period (i.e. motion DS or saccade DS, one-way ANOVA test, p&lt;0.01). In order to quantify the activity related to evaluating motion stimulus, we analyzed the motion DS only including the units in the motion modules, whereas only the saccade DS of units in the target modules was calculated to quantify the activity related to saccade selection during the decision-making.</p></sec><sec id="s4-4-5"><title>Analysis of RNN connectivity</title><p>To examine the potential circuit mechanisms underlying the modulation of action selection on sensory evaluation during decision-making in the RNNs, we examined the cross-module connection weights in the trained networks. Specifically, we defined the feedforward connection as the projection from units in the motion module to units in the target module within the same main module (hemisphere). We also defined the feedback connection as the projection from units in the target module to units in the motion module within the same main module. Furthermore, we grouped the cross-module connections into the selectivity-matched and selectivity-mismatched groups based on the preferences of the neural encoding of units in the motion and target modules. The selectivity-matched group included two types of unit pairs: (1) units in the motion module preferred to encode 315° and units in the target module preferred to encode red, (2) units in the motion module preferred to encode 135° and units in the target module preferred to encode green. The selectivity-mismatched group includes the other two types of unit pairs: (3) units in the motion module preferred to encode 315° while units in the target module preferred to encode green, and (4) units in the motion module preferred to encode 135° while units in the target module preferred to encode red. The values of connection weights projected from excitatory and inhibitory units were set as positive and negative, respectively.</p><p>We also examined the correlation between the similarity of neural selectivity and connection strength for different unit pairs in the RNNs based on the following steps: First, both the preference and strength of motion direction encoding or target color encoding were quantified for units in the motion module or target module, respectively. This was done by calculating the averaged differential activity to the 315° and 135° motion stimuli after motion stimulus onset or calculating the averaged differential activity to the red and green targets after target onset. In this case, the unit pairs that exhibited matched selectivity would show selectivity values with the same sign (positive or negative), whereas the unit pairs that exhibited mismatched selectivity would show selectivity values with the opposite signs. Second, the units in both the motion module and target modules were ranked based on selectivity values. Third, the selectivity similarity of each cross-module unit pair was quantified by calculating the reverse value of the absolute differences between the target color selectivity rank and the motion DS rank. The rank of the weight value of each pair was calculated and then reversed to give the lower weight value a higher rank score. Finally, we calculated the Pearson correlation between weight rank and selectivity similarity. A positive correlation indicates that units that exhibited stronger encoding preference to one motion direction in the motion module were more likely to connect with the units in the target module that exhibited stronger encoding on the matched target color.</p></sec><sec id="s4-4-6"><title>Inactivation experiments in silico</title><p>Our examination of the network connectivity within the hidden layer of the RNNs revealed that the selectivity-specific top-down connections originated from the target module to the motion module. To assess the causal contribution of such precise feedback connections to the modulation of action selection on sensory evaluation, we performed two in silico analogues of neuronal inactivation experiments similar to a previous study (<xref ref-type="bibr" rid="bib66">Zhou et al., 2021</xref>). We hypothesized that ablating or disrupting the precise feedback connection from the target module to the motion module would significantly impact the activity patterns of the units in the motion module. Specifically, such inactivation on connectivity was expected to reduce the difference in motion DS in the notion module between CT and IT conditions. To test this hypothesis, we performed the projection-specific inactivation experiments in the RNNs in three different ways. First, we ablated all the feedback projections from the target module to the motion module while keeping all the other network parameters unchanged after the networks were fully trained. We then tested the networks with the untrained motion stimuli used in the normal experiment. The connectivity ablation was implemented by directly setting the connection weights from units in the target module to units in the motion module to zero. Second, we randomly rearranged the connection weights from the target module to the motion module after the network was fully trained by shuffling the corresponding weights in the weight matrix. Then, we tested the networks with the testing motion stimuli. This was aimed to disrupt the selectivity-specific feedback connection without changing the total strength of the feedback connection. We repeated this random feedback weight rearrangement process 100 times for each of the 50 trained networks. Subsequently, we measured the impact on the networks’ behavior performance and the activity patterns in both the motion and saccade modules. In particular, for each network, we tested whether there were still different levels of motion DS of units in the motion module between CT and IT conditions after inactivating the feedback connectivity.</p><p>We further performed pattern-specific ablation of the feedback connections in the RNNs, in order to examine the causal roles of different patterns of feedback connectivity in solving the FVDM task. Specifically, we separated the feedback projections in each RNN into the specific group and the nonspecific group. The specific group included two conditions: (1) the feedback connection weight was positive between the selectivity-matched unit pairs and (2) the feedback connection weight was negative between the selectivity-nonmatched unit pairs, whereas the nonspecific group included the rest of the feedback conditions in each RNN. We then tested the effects of the pattern-specific connectivity inactivation on the RNNs’ behavior performance when tested with the untrained motion stimuli.</p><p>In the third inactivation experiment, we trained 50 additional RNNs without feedback connections to learn the FVMD task, in order to test the importance of feedback connectivity in solving the flexible decision task. These networks were initialized using identical hyperparameters and trained with the same methodology as the normal RNNs, except that the feedback connections from the target module to the motion module were ablated before training. We then examined these RNNs’ behavior performance and unit activity when testing with the untrained motion stimuli used in the normal experiment. Furthermore, we trained another 50 RNNs without feedback connection to learn the FVMD task. These RNNs were initialized with higher recurrent connection probabilities than the full-model RNNs to keep the number of the total trainable connection weight comparable to that in the full-model RNNs. We raised the recurrent connection probability by a factor of 1.176 after removing feedback connections (average number of connections in 50 normal RNNs = 8193, average number of connections in 50 networks without feedback = 8184, p=0.53, independent sample t-test). Except for the recurrent connection probability, all the other hyperparameters and the training methodology were the same as the normal RNNs. We then compared the behavior performance of these RNNs with that of the normal RNNs when testing with the untrained motion stimuli.</p></sec><sec id="s4-4-7"><title>Analysis of neural landscape</title><p>For each network, we adopted a methodology similar to a previous study (cite) to reconstruct the energy landscape of population activity within the target module. Initially, units in the target module exhibiting saccade DS were identified. Subsequently, we employed principal component analysis (PCA) to reduce the dimensionality of the population activity. Specifically, PCA was performed on the average activity across these units, considering each stimulus motion direction, coherence level, and choice. We retained the first five principal components (PCs) for further analysis, as they explained over 90% of the total variance in population activity. Following this, the trial-by-trial population activities were transformed into five-dimensional data using the aforementioned five PCs.</p><p>To predict trial-by-trial choice, we employed a linear Support Vector Machine (SVM) classifier with 10-fold cross-validation. Specifically, we utilized the average activity of the last 100ms of each trial as input for the classifier. The choice axis was determined by selecting the normal vector of the separating hyperplane from the SVM classifier that demonstrated the best performance. Subsequently, the five-dimensional data points were projected onto the choice axis, resulting in one-dimensional projections. These projections represented the positions along the choice axis, with the intersection between the normal vector and the hyperplane serving as the zero point.</p><p>The potential in this context is determined by integrating the spatial component of the time derivative of the population activity, denoted as <inline-formula><alternatives><mml:math id="inf17"><mml:msub><mml:mrow><mml:mi>X</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub></mml:math><tex-math id="inft17">\begin{document}$X_{t}$\end{document}</tex-math></alternatives></inline-formula> , for a given condition. To be more precise, we began by computing the expected value across trials of the time derivative of the unit activities for each choice. Subsequently, we employed the potential function <inline-formula><alternatives><mml:math id="inf18"><mml:mstyle><mml:mrow><mml:mi>V</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>x</mml:mi><mml:mo>,</mml:mo><mml:mspace width="thinmathspace"/><mml:mi>t</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mstyle></mml:math><tex-math id="inft18">\begin{document}$V\left (x,\,t\right)$\end{document}</tex-math></alternatives></inline-formula> to evaluate the potential at position x and time t,<disp-formula id="equ8"><alternatives><mml:math id="m8"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>V</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>x</mml:mi><mml:mo>,</mml:mo><mml:mspace width="thinmathspace"/><mml:mi>t</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:munder><mml:mo>∑</mml:mo><mml:mrow><mml:mrow><mml:mi mathvariant="normal">p</mml:mi></mml:mrow><mml:mo>&lt;</mml:mo><mml:mrow><mml:mi mathvariant="normal">x</mml:mi></mml:mrow></mml:mrow></mml:munder><mml:mfrac><mml:mrow><mml:mi>d</mml:mi><mml:msub><mml:mi>X</mml:mi><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:mi>d</mml:mi><mml:mi>t</mml:mi></mml:mrow></mml:mfrac><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:msub><mml:mi>X</mml:mi><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mi>p</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mspace width="thinmathspace"/><mml:mo>⋅</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mo>−</mml:mo><mml:mrow><mml:mi mathvariant="normal">Δ</mml:mi></mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mstyle></mml:mrow></mml:mstyle></mml:math><tex-math id="t8">\begin{document}$$\displaystyle  V\left (x,\,t\right)=\left (\underset{\mathrm{p} \lt \mathrm{x}}{\sum }\frac{dX_{t}}{dt}|X_{t}=p\right)\,\cdot \left (-\mathrm{\Delta }x\right)$$\end{document}</tex-math></alternatives></disp-formula></p><p>Crucially, we computed the potential separately for each choice, establishing the potential at position 0 as the zero-potential reference. To provide a holistic evaluation of the potential landscape, we combined the potentials of both choices at position 0.</p><p>Furthermore, we expanded the computation of potentials to encompass each stimulus coherence level using the aforementioned approach. Similar to the prior analysis, the time derivatives were still derived from the 1-D projections of each data point onto the choice axis. However, in this instance, the conditions were based on the stimulus coherence level rather than the choice. For a representative potential value for each model, we averaged the potentials at the time point of 300ms after the stimulus onset. Additionally, recognizing that the positions visited by each model might differ, we ensured the accuracy of standard error estimation by retaining only the potential values at positions continuously visited by four or more models.</p></sec></sec></sec></body><back><sec sec-type="additional-information" id="s5"><title>Additional information</title><fn-group content-type="competing-interest"><title>Competing interests</title><fn fn-type="COI-statement" id="conf1"><p>No competing interests declared</p></fn></fn-group><fn-group content-type="author-contribution"><title>Author contributions</title><fn fn-type="con" id="con1"><p>Formal analysis, Visualization, Methodology, Writing – review and editing</p></fn><fn fn-type="con" id="con2"><p>Conceptualization, Resources, Data curation, Formal analysis, Supervision, Funding acquisition, Validation, Investigation, Visualization, Methodology, Writing - original draft, Project administration, Writing – review and editing</p></fn></fn-group><fn-group content-type="ethics-information"><title>Ethics</title><fn fn-type="other"><p>All experimental and surgical procedures were performed in strict accordance with the recommendations in the Guide for the Care and Use of Laboratory Animals of the National Institutes of Health. All of the animals were handled according to approved institutional animal care and use committee (IACUC) protocol #71887 of The University of Chicago.</p></fn></fn-group></sec><sec sec-type="supplementary-material" id="s6"><title>Additional files</title><supplementary-material id="mdar"><label>MDAR checklist</label><media xlink:href="elife-96402-mdarchecklist1-v1.docx" mimetype="application" mime-subtype="docx"/></supplementary-material><supplementary-material id="supp1"><label>Supplementary file 1.</label><caption><title>Table S1.</title></caption><media xlink:href="elife-96402-supp1-v1.docx" mimetype="application" mime-subtype="docx"/></supplementary-material></sec><sec sec-type="data-availability" id="s7"><title>Data availability</title><p>The electrophysiology data is available on <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.5061/dryad.n8pk0p37z">Dryad</ext-link>. The code for Training RNN and the relative analysis is available on <ext-link ext-link-type="uri" xlink:href="https://github.com/xuanyuw/TD-modulation-model">GitHub</ext-link> (copy archived at <xref ref-type="bibr" rid="bib63">Wu, 2025</xref>).</p><p>The following dataset was generated:</p><p><element-citation publication-type="data" specific-use="isSupplementedBy" id="dataset1"><person-group person-group-type="author"><name><surname>Wu</surname><given-names>X</given-names></name><name><surname>Zhou</surname><given-names>Y</given-names></name></person-group><year iso-8601-date="2025">2025</year><data-title>Recorded neural data from: Nonlinear feedback modulation contributes to the optimization of flexible decision-making</data-title><source>Dryad Digital Repository</source><pub-id pub-id-type="doi">10.5061/dryad.n8pk0p37z</pub-id></element-citation></p></sec><ack id="ack"><title>Acknowledgements</title><p>We thank Tianming Yang, Matthew Rosen, Siyu Wang, Cheng Xue, Gongcheng Yu, Mingze Li and Ou Zhu for their comments on an earlier version of this manuscript. We also thank the veterinary staff at The University of Chicago Animal Resources Center for expert assistance. This study was supported by STI2030-Major Projects (2021ZD0203800), NSFC32171036.</p></ack><ref-list><title>References</title><ref id="bib1"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bastos</surname><given-names>AM</given-names></name><name><surname>Usrey</surname><given-names>WM</given-names></name><name><surname>Adams</surname><given-names>RA</given-names></name><name><surname>Mangun</surname><given-names>GR</given-names></name><name><surname>Fries</surname><given-names>P</given-names></name><name><surname>Friston</surname><given-names>KJ</given-names></name></person-group><year iso-8601-date="2012">2012</year><article-title>Canonical microcircuits for predictive coding</article-title><source>Neuron</source><volume>76</volume><fpage>695</fpage><lpage>711</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2012.10.038</pub-id><pub-id pub-id-type="pmid">23177956</pub-id></element-citation></ref><ref id="bib2"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bennur</surname><given-names>S</given-names></name><name><surname>Gold</surname><given-names>JI</given-names></name></person-group><year iso-8601-date="2011">2011</year><article-title>Distinct representations of a perceptual decision and the associated oculomotor plan in the monkey lateral intraparietal area</article-title><source>The Journal of Neuroscience</source><volume>31</volume><fpage>913</fpage><lpage>921</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.4417-10.2011</pub-id><pub-id pub-id-type="pmid">21248116</pub-id></element-citation></ref><ref id="bib3"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bichot</surname><given-names>NP</given-names></name><name><surname>Rossi</surname><given-names>AF</given-names></name><name><surname>Desimone</surname><given-names>R</given-names></name></person-group><year iso-8601-date="2005">2005</year><article-title>Parallel and serial neural mechanisms for visual search in macaque area V4</article-title><source>Science</source><volume>308</volume><fpage>529</fpage><lpage>534</lpage><pub-id pub-id-type="doi">10.1126/science.1109676</pub-id><pub-id pub-id-type="pmid">15845848</pub-id></element-citation></ref><ref id="bib4"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bondy</surname><given-names>AG</given-names></name><name><surname>Haefner</surname><given-names>RM</given-names></name><name><surname>Cumming</surname><given-names>BG</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>Feedback determines the structure of correlated variability in primary visual cortex</article-title><source>Nature Neuroscience</source><volume>21</volume><fpage>598</fpage><lpage>606</lpage><pub-id pub-id-type="doi">10.1038/s41593-018-0089-1</pub-id><pub-id pub-id-type="pmid">29483663</pub-id></element-citation></ref><ref id="bib5"><element-citation publication-type="software"><person-group person-group-type="author"><name><surname>Brendel</surname><given-names>W</given-names></name><name><surname>Kobak</surname><given-names>D</given-names></name><name><surname>Boulay</surname><given-names>C</given-names></name><name><surname>Guan</surname><given-names>C</given-names></name><name><surname>Williams</surname><given-names>A</given-names></name></person-group><year iso-8601-date="2020">2020</year><data-title>Demixed principal component analysis (dPCA)</data-title><source>GitHub</source><ext-link ext-link-type="uri" xlink:href="https://github.com/machenslab/dPCA">https://github.com/machenslab/dPCA</ext-link></element-citation></ref><ref id="bib6"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Briggs</surname><given-names>F</given-names></name><name><surname>Usrey</surname><given-names>WM</given-names></name></person-group><year iso-8601-date="2009">2009</year><article-title>Parallel processing in the corticogeniculate pathway of the macaque monkey</article-title><source>Neuron</source><volume>62</volume><fpage>135</fpage><lpage>146</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2009.02.024</pub-id><pub-id pub-id-type="pmid">19376073</pub-id></element-citation></ref><ref id="bib7"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Briggs</surname><given-names>F</given-names></name></person-group><year iso-8601-date="2020">2020</year><article-title>Role of feedback connections in central visual processing</article-title><source>Annual Review of Vision Science</source><volume>6</volume><fpage>313</fpage><lpage>334</lpage><pub-id pub-id-type="doi">10.1146/annurev-vision-121219-081716</pub-id><pub-id pub-id-type="pmid">32552571</pub-id></element-citation></ref><ref id="bib8"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Deco</surname><given-names>G</given-names></name><name><surname>Rolls</surname><given-names>ET</given-names></name><name><surname>Albantakis</surname><given-names>L</given-names></name><name><surname>Romo</surname><given-names>R</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>Brain mechanisms for perceptual and reward-related decision-making</article-title><source>Progress in Neurobiology</source><volume>103</volume><fpage>194</fpage><lpage>213</lpage><pub-id pub-id-type="doi">10.1016/j.pneurobio.2012.01.010</pub-id><pub-id pub-id-type="pmid">22326926</pub-id></element-citation></ref><ref id="bib9"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ding</surname><given-names>L</given-names></name><name><surname>Gold</surname><given-names>JI</given-names></name></person-group><year iso-8601-date="2010">2010</year><article-title>Caudate encodes multiple computations for perceptual decisions</article-title><source>The Journal of Neuroscience</source><volume>30</volume><fpage>15747</fpage><lpage>15759</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.2894-10.2010</pub-id><pub-id pub-id-type="pmid">21106814</pub-id></element-citation></ref><ref id="bib10"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ding</surname><given-names>L</given-names></name><name><surname>Gold</surname><given-names>JI</given-names></name></person-group><year iso-8601-date="2012">2012</year><article-title>Neural correlates of perceptual decision making before, during, and after decision commitment in monkey frontal eye field</article-title><source>Cerebral Cortex</source><volume>22</volume><fpage>1052</fpage><lpage>1067</lpage><pub-id pub-id-type="doi">10.1093/cercor/bhr178</pub-id><pub-id pub-id-type="pmid">21765183</pub-id></element-citation></ref><ref id="bib11"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Engel</surname><given-names>TA</given-names></name><name><surname>Chaisangmongkon</surname><given-names>W</given-names></name><name><surname>Freedman</surname><given-names>DJ</given-names></name><name><surname>Wang</surname><given-names>XJ</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>Choice-correlated activity fluctuations underlie learning of neuronal category representation</article-title><source>Nature Communications</source><volume>6</volume><elocation-id>6454</elocation-id><pub-id pub-id-type="doi">10.1038/ncomms7454</pub-id><pub-id pub-id-type="pmid">25759251</pub-id></element-citation></ref><ref id="bib12"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Federer</surname><given-names>F</given-names></name><name><surname>Ta’afua</surname><given-names>S</given-names></name><name><surname>Merlin</surname><given-names>S</given-names></name><name><surname>Hassanpour</surname><given-names>MS</given-names></name><name><surname>Angelucci</surname><given-names>A</given-names></name></person-group><year iso-8601-date="2021">2021</year><article-title>Stream-specific feedback inputs to the primate primary visual cortex</article-title><source>Nature Communications</source><volume>12</volume><elocation-id>228</elocation-id><pub-id pub-id-type="doi">10.1038/s41467-020-20505-5</pub-id><pub-id pub-id-type="pmid">33431862</pub-id></element-citation></ref><ref id="bib13"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ferrera</surname><given-names>VP</given-names></name><name><surname>Yanike</surname><given-names>M</given-names></name><name><surname>Cassanello</surname><given-names>C</given-names></name></person-group><year iso-8601-date="2009">2009</year><article-title>Frontal eye field neurons signal changes in decision criteria</article-title><source>Nature Neuroscience</source><volume>12</volume><fpage>1458</fpage><lpage>1462</lpage><pub-id pub-id-type="doi">10.1038/nn.2434</pub-id><pub-id pub-id-type="pmid">19855389</pub-id></element-citation></ref><ref id="bib14"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Finkelstein</surname><given-names>A</given-names></name><name><surname>Fontolan</surname><given-names>L</given-names></name><name><surname>Economo</surname><given-names>MN</given-names></name><name><surname>Li</surname><given-names>N</given-names></name><name><surname>Romani</surname><given-names>S</given-names></name><name><surname>Svoboda</surname><given-names>K</given-names></name></person-group><year iso-8601-date="2021">2021</year><article-title>Attractor dynamics gate cortical information flow during decision-making</article-title><source>Nature Neuroscience</source><volume>24</volume><fpage>843</fpage><lpage>850</lpage><pub-id pub-id-type="doi">10.1038/s41593-021-00840-6</pub-id><pub-id pub-id-type="pmid">33875892</pub-id></element-citation></ref><ref id="bib15"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Freedman</surname><given-names>DJ</given-names></name><name><surname>Assad</surname><given-names>JA</given-names></name></person-group><year iso-8601-date="2006">2006</year><article-title>Experience-dependent representation of visual categories in parietal cortex</article-title><source>Nature</source><volume>443</volume><fpage>85</fpage><lpage>88</lpage><pub-id pub-id-type="doi">10.1038/nature05078</pub-id><pub-id pub-id-type="pmid">16936716</pub-id></element-citation></ref><ref id="bib16"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Freedman</surname><given-names>DJ</given-names></name><name><surname>Assad</surname><given-names>JA</given-names></name></person-group><year iso-8601-date="2009">2009</year><article-title>Distinct encoding of spatial and nonspatial visual information in parietal cortex</article-title><source>The Journal of Neuroscience</source><volume>29</volume><fpage>5671</fpage><lpage>5680</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.2878-08.2009</pub-id><pub-id pub-id-type="pmid">19403833</pub-id></element-citation></ref><ref id="bib17"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Freedman</surname><given-names>DJ</given-names></name><name><surname>Assad</surname><given-names>JA</given-names></name></person-group><year iso-8601-date="2011">2011</year><article-title>A proposed common neural mechanism for categorization and perceptual decisions</article-title><source>Nature Neuroscience</source><volume>14</volume><fpage>143</fpage><lpage>146</lpage><pub-id pub-id-type="doi">10.1038/nn.2740</pub-id><pub-id pub-id-type="pmid">21270782</pub-id></element-citation></ref><ref id="bib18"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Freedman</surname><given-names>DJ</given-names></name><name><surname>Assad</surname><given-names>JA</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Neuronal mechanisms of visual categorization: An abstract view on decision making</article-title><source>Annual Review of Neuroscience</source><volume>39</volume><fpage>129</fpage><lpage>147</lpage><pub-id pub-id-type="doi">10.1146/annurev-neuro-071714-033919</pub-id><pub-id pub-id-type="pmid">27070552</pub-id></element-citation></ref><ref id="bib19"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Friston</surname><given-names>K</given-names></name><name><surname>Kiebel</surname><given-names>S</given-names></name></person-group><year iso-8601-date="2009">2009</year><article-title>Predictive coding under the free-energy principle</article-title><source>Philosophical Transactions of the Royal Society of London. Series B, Biological Sciences</source><volume>364</volume><fpage>1211</fpage><lpage>1221</lpage><pub-id pub-id-type="doi">10.1098/rstb.2008.0300</pub-id><pub-id pub-id-type="pmid">19528002</pub-id></element-citation></ref><ref id="bib20"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Gilbert</surname><given-names>CD</given-names></name><name><surname>Li</surname><given-names>W</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>Top-down influences on visual processing</article-title><source>Nature Reviews. Neuroscience</source><volume>14</volume><fpage>350</fpage><lpage>363</lpage><pub-id pub-id-type="doi">10.1038/nrn3476</pub-id><pub-id pub-id-type="pmid">23595013</pub-id></element-citation></ref><ref id="bib21"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Gold</surname><given-names>JI</given-names></name><name><surname>Shadlen</surname><given-names>MN</given-names></name></person-group><year iso-8601-date="2000">2000</year><article-title>Representation of a perceptual decision in developing oculomotor commands</article-title><source>Nature</source><volume>404</volume><fpage>390</fpage><lpage>394</lpage><pub-id pub-id-type="doi">10.1038/35006062</pub-id><pub-id pub-id-type="pmid">10746726</pub-id></element-citation></ref><ref id="bib22"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Gold</surname><given-names>JI</given-names></name><name><surname>Shadlen</surname><given-names>MN</given-names></name></person-group><year iso-8601-date="2007">2007</year><article-title>The neural basis of decision making</article-title><source>Annual Review of Neuroscience</source><volume>30</volume><fpage>535</fpage><lpage>574</lpage><pub-id pub-id-type="doi">10.1146/annurev.neuro.29.051605.113038</pub-id><pub-id pub-id-type="pmid">17600525</pub-id></element-citation></ref><ref id="bib23"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hanks</surname><given-names>TD</given-names></name><name><surname>Summerfield</surname><given-names>C</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>Perceptual decision making in rodents, monkeys, and humans</article-title><source>Neuron</source><volume>93</volume><fpage>15</fpage><lpage>31</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2016.12.003</pub-id><pub-id pub-id-type="pmid">28056343</pub-id></element-citation></ref><ref id="bib24"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Harris</surname><given-names>KD</given-names></name><name><surname>Mrsic-Flogel</surname><given-names>TD</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>Cortical connectivity and sensory coding</article-title><source>Nature</source><volume>503</volume><fpage>51</fpage><lpage>58</lpage><pub-id pub-id-type="doi">10.1038/nature12654</pub-id><pub-id pub-id-type="pmid">24201278</pub-id></element-citation></ref><ref id="bib25"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Heitz</surname><given-names>RP</given-names></name><name><surname>Schall</surname><given-names>JD</given-names></name></person-group><year iso-8601-date="2012">2012</year><article-title>Neural mechanisms of speed-accuracy tradeoff</article-title><source>Neuron</source><volume>76</volume><fpage>616</fpage><lpage>628</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2012.08.030</pub-id><pub-id pub-id-type="pmid">23141072</pub-id></element-citation></ref><ref id="bib26"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Horwitz</surname><given-names>GD</given-names></name><name><surname>Newsome</surname><given-names>WT</given-names></name></person-group><year iso-8601-date="1999">1999</year><article-title>Separate signals for target selection and movement specification in the superior colliculus</article-title><source>Science</source><volume>284</volume><fpage>1158</fpage><lpage>1161</lpage><pub-id pub-id-type="doi">10.1126/science.284.5417.1158</pub-id><pub-id pub-id-type="pmid">10325224</pub-id></element-citation></ref><ref id="bib27"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Huk</surname><given-names>AC</given-names></name><name><surname>Katz</surname><given-names>LN</given-names></name><name><surname>Yates</surname><given-names>JL</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>The role of the lateral intraparietal area in (the study of) decision making</article-title><source>Annual Review of Neuroscience</source><volume>40</volume><fpage>349</fpage><lpage>372</lpage><pub-id pub-id-type="doi">10.1146/annurev-neuro-072116-031508</pub-id><pub-id pub-id-type="pmid">28772104</pub-id></element-citation></ref><ref id="bib28"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Jun</surname><given-names>EJ</given-names></name><name><surname>Bautista</surname><given-names>AR</given-names></name><name><surname>Nunez</surname><given-names>MD</given-names></name><name><surname>Allen</surname><given-names>DC</given-names></name><name><surname>Tak</surname><given-names>JH</given-names></name><name><surname>Alvarez</surname><given-names>E</given-names></name><name><surname>Basso</surname><given-names>MA</given-names></name></person-group><year iso-8601-date="2021">2021</year><article-title>Causal role for the primate superior colliculus in the computation of evidence for perceptual decisions</article-title><source>Nature Neuroscience</source><volume>24</volume><fpage>1121</fpage><lpage>1131</lpage><pub-id pub-id-type="doi">10.1038/s41593-021-00878-6</pub-id><pub-id pub-id-type="pmid">34183869</pub-id></element-citation></ref><ref id="bib29"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Katz</surname><given-names>LN</given-names></name><name><surname>Yates</surname><given-names>JL</given-names></name><name><surname>Pillow</surname><given-names>JW</given-names></name><name><surname>Huk</surname><given-names>AC</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Dissociated functional significance of decision-related activity in the primate dorsal stream</article-title><source>Nature</source><volume>535</volume><fpage>285</fpage><lpage>288</lpage><pub-id pub-id-type="doi">10.1038/nature18617</pub-id><pub-id pub-id-type="pmid">27376476</pub-id></element-citation></ref><ref id="bib30"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kiani</surname><given-names>R</given-names></name><name><surname>Shadlen</surname><given-names>MN</given-names></name></person-group><year iso-8601-date="2009">2009</year><article-title>Representation of confidence associated with a decision by neurons in the parietal cortex</article-title><source>Science</source><volume>324</volume><fpage>759</fpage><lpage>764</lpage><pub-id pub-id-type="doi">10.1126/science.1169405</pub-id><pub-id pub-id-type="pmid">19423820</pub-id></element-citation></ref><ref id="bib31"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kim</surname><given-names>JN</given-names></name><name><surname>Shadlen</surname><given-names>MN</given-names></name></person-group><year iso-8601-date="1999">1999</year><article-title>Neural correlates of a decision in the dorsolateral prefrontal cortex of the macaque</article-title><source>Nature Neuroscience</source><volume>2</volume><fpage>176</fpage><lpage>185</lpage><pub-id pub-id-type="doi">10.1038/5739</pub-id><pub-id pub-id-type="pmid">10195203</pub-id></element-citation></ref><ref id="bib32"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kobak</surname><given-names>D</given-names></name><name><surname>Brendel</surname><given-names>W</given-names></name><name><surname>Constantinidis</surname><given-names>C</given-names></name><name><surname>Feierstein</surname><given-names>CE</given-names></name><name><surname>Kepecs</surname><given-names>A</given-names></name><name><surname>Mainen</surname><given-names>ZF</given-names></name><name><surname>Qi</surname><given-names>X-L</given-names></name><name><surname>Romo</surname><given-names>R</given-names></name><name><surname>Uchida</surname><given-names>N</given-names></name><name><surname>Machens</surname><given-names>CK</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Demixed principal component analysis of neural population data</article-title><source>eLife</source><volume>5</volume><elocation-id>e10989</elocation-id><pub-id pub-id-type="doi">10.7554/eLife.10989</pub-id><pub-id pub-id-type="pmid">27067378</pub-id></element-citation></ref><ref id="bib33"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Laamerad</surname><given-names>P</given-names></name><name><surname>Liu</surname><given-names>LD</given-names></name><name><surname>Pack</surname><given-names>CC</given-names></name></person-group><year iso-8601-date="2024">2024</year><article-title>Decision-related activity and movement selection in primate visual cortex</article-title><source>Science Advances</source><volume>10</volume><elocation-id>eadk7214</elocation-id><pub-id pub-id-type="doi">10.1126/sciadv.adk7214</pub-id><pub-id pub-id-type="pmid">38809984</pub-id></element-citation></ref><ref id="bib34"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Martinez-Trujillo</surname><given-names>JC</given-names></name><name><surname>Treue</surname><given-names>S</given-names></name></person-group><year iso-8601-date="2004">2004</year><article-title>Feature-based attention increases the selectivity of population responses in primate visual cortex</article-title><source>Current Biology</source><volume>14</volume><fpage>744</fpage><lpage>751</lpage><pub-id pub-id-type="doi">10.1016/j.cub.2004.04.028</pub-id><pub-id pub-id-type="pmid">15120065</pub-id></element-citation></ref><ref id="bib35"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Masse</surname><given-names>NY</given-names></name><name><surname>Yang</surname><given-names>GR</given-names></name><name><surname>Song</surname><given-names>HF</given-names></name><name><surname>Wang</surname><given-names>XJ</given-names></name><name><surname>Freedman</surname><given-names>DJ</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>Circuit mechanisms for the maintenance and manipulation of information in working memory</article-title><source>Nature Neuroscience</source><volume>22</volume><fpage>1159</fpage><lpage>1167</lpage><pub-id pub-id-type="doi">10.1038/s41593-019-0414-3</pub-id><pub-id pub-id-type="pmid">31182866</pub-id></element-citation></ref><ref id="bib36"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Maunsell</surname><given-names>JHR</given-names></name><name><surname>Treue</surname><given-names>S</given-names></name></person-group><year iso-8601-date="2006">2006</year><article-title>Feature-based attention in visual cortex</article-title><source>Trends in Neurosciences</source><volume>29</volume><fpage>317</fpage><lpage>322</lpage><pub-id pub-id-type="doi">10.1016/j.tins.2006.04.001</pub-id><pub-id pub-id-type="pmid">16697058</pub-id></element-citation></ref><ref id="bib37"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>McManus</surname><given-names>JNJ</given-names></name><name><surname>Li</surname><given-names>W</given-names></name><name><surname>Gilbert</surname><given-names>CD</given-names></name></person-group><year iso-8601-date="2011">2011</year><article-title>Adaptive shape processing in primary visual cortex</article-title><source>PNAS</source><volume>108</volume><fpage>9739</fpage><lpage>9746</lpage><pub-id pub-id-type="doi">10.1073/pnas.1105855108</pub-id><pub-id pub-id-type="pmid">21571645</pub-id></element-citation></ref><ref id="bib38"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Moore</surname><given-names>T</given-names></name><name><surname>Armstrong</surname><given-names>KM</given-names></name></person-group><year iso-8601-date="2003">2003</year><article-title>Selective gating of visual signals by microstimulation of frontal cortex</article-title><source>Nature</source><volume>421</volume><fpage>370</fpage><lpage>373</lpage><pub-id pub-id-type="doi">10.1038/nature01341</pub-id><pub-id pub-id-type="pmid">12540901</pub-id></element-citation></ref><ref id="bib39"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Motter</surname><given-names>BC</given-names></name></person-group><year iso-8601-date="1994">1994a</year><article-title>Neural correlates of attentive selection for color or luminance in extrastriate area V4</article-title><source>The Journal of Neuroscience</source><volume>14</volume><fpage>2178</fpage><lpage>2189</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.14-04-02178.1994</pub-id><pub-id pub-id-type="pmid">8158264</pub-id></element-citation></ref><ref id="bib40"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Motter</surname><given-names>BC</given-names></name></person-group><year iso-8601-date="1994">1994b</year><article-title>Neural correlates of feature selective memory and pop-out in extrastriate area V4</article-title><source>The Journal of Neuroscience</source><volume>14</volume><fpage>2190</fpage><lpage>2199</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.14-04-02190.1994</pub-id><pub-id pub-id-type="pmid">8158265</pub-id></element-citation></ref><ref id="bib41"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Nienborg</surname><given-names>H</given-names></name><name><surname>Cumming</surname><given-names>BG</given-names></name></person-group><year iso-8601-date="2009">2009</year><article-title>Decision-related activity in sensory neurons reflects more than a neuron’s causal effect</article-title><source>Nature</source><volume>459</volume><fpage>89</fpage><lpage>92</lpage><pub-id pub-id-type="doi">10.1038/nature07821</pub-id><pub-id pub-id-type="pmid">19270683</pub-id></element-citation></ref><ref id="bib42"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>O’Connell</surname><given-names>RG</given-names></name><name><surname>Shadlen</surname><given-names>MN</given-names></name><name><surname>Wong-Lin</surname><given-names>K</given-names></name><name><surname>Kelly</surname><given-names>SP</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>Bridging neural and computational viewpoints on perceptual decision-making</article-title><source>Trends in Neurosciences</source><volume>41</volume><fpage>838</fpage><lpage>852</lpage><pub-id pub-id-type="doi">10.1016/j.tins.2018.06.005</pub-id><pub-id pub-id-type="pmid">30007746</pub-id></element-citation></ref><ref id="bib43"><element-citation publication-type="preprint"><person-group person-group-type="author"><name><surname>Peysakhovich</surname><given-names>B</given-names></name><name><surname>Tetrick</surname><given-names>SM</given-names></name><name><surname>Silva</surname><given-names>AA</given-names></name><name><surname>Li</surname><given-names>S</given-names></name><name><surname>Zhu</surname><given-names>O</given-names></name><name><surname>Ibos</surname><given-names>G</given-names></name><name><surname>Johnston</surname><given-names>WJ</given-names></name><name><surname>Freedman</surname><given-names>DJ</given-names></name></person-group><year iso-8601-date="2023">2023</year><article-title>Primate superior colliculus is engaged in abstract higher-order cognition</article-title><source>bioRxiv</source><pub-id pub-id-type="doi">10.1101/2023.01.17.524416</pub-id></element-citation></ref><ref id="bib44"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Platt</surname><given-names>ML</given-names></name><name><surname>Glimcher</surname><given-names>PW</given-names></name></person-group><year iso-8601-date="1999">1999</year><article-title>Neural correlates of decision variables in parietal cortex</article-title><source>Nature</source><volume>400</volume><fpage>233</fpage><lpage>238</lpage><pub-id pub-id-type="doi">10.1038/22268</pub-id><pub-id pub-id-type="pmid">10421364</pub-id></element-citation></ref><ref id="bib45"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Prat-Ortega</surname><given-names>G</given-names></name><name><surname>Wimmer</surname><given-names>K</given-names></name><name><surname>Roxin</surname><given-names>A</given-names></name><name><surname>de la Rocha</surname><given-names>J</given-names></name></person-group><year iso-8601-date="2021">2021</year><article-title>Flexible categorization in perceptual decision making</article-title><source>Nature Communications</source><volume>12</volume><elocation-id>1283</elocation-id><pub-id pub-id-type="doi">10.1038/s41467-021-21501-z</pub-id><pub-id pub-id-type="pmid">33627643</pub-id></element-citation></ref><ref id="bib46"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Rao</surname><given-names>RP</given-names></name><name><surname>Ballard</surname><given-names>DH</given-names></name></person-group><year iso-8601-date="1999">1999</year><article-title>Predictive coding in the visual cortex: a functional interpretation of some extra-classical receptive-field effects</article-title><source>Nature Neuroscience</source><volume>2</volume><fpage>79</fpage><lpage>87</lpage><pub-id pub-id-type="doi">10.1038/4580</pub-id><pub-id pub-id-type="pmid">10195184</pub-id></element-citation></ref><ref id="bib47"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Roitman</surname><given-names>JD</given-names></name><name><surname>Shadlen</surname><given-names>MN</given-names></name></person-group><year iso-8601-date="2002">2002</year><article-title>Response of neurons in the lateral intraparietal area during a combined visual discrimination reaction time task</article-title><source>The Journal of Neuroscience</source><volume>22</volume><fpage>9475</fpage><lpage>9489</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.22-21-09475.2002</pub-id><pub-id pub-id-type="pmid">12417672</pub-id></element-citation></ref><ref id="bib48"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Rossi-Pool</surname><given-names>R</given-names></name><name><surname>Zainos</surname><given-names>A</given-names></name><name><surname>Alvarez</surname><given-names>M</given-names></name><name><surname>Zizumbo</surname><given-names>J</given-names></name><name><surname>Vergara</surname><given-names>J</given-names></name><name><surname>Romo</surname><given-names>R</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>Decoding a decision process in the neuronal population of dorsal premotor cortex</article-title><source>Neuron</source><volume>96</volume><fpage>1432</fpage><lpage>1446</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2017.11.023</pub-id><pub-id pub-id-type="pmid">29224726</pub-id></element-citation></ref><ref id="bib49"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Shadlen</surname><given-names>MN</given-names></name><name><surname>Newsome</surname><given-names>WT</given-names></name></person-group><year iso-8601-date="1996">1996</year><article-title>Motion perception: seeing and deciding</article-title><source>PNAS</source><volume>93</volume><fpage>628</fpage><lpage>633</lpage><pub-id pub-id-type="doi">10.1073/pnas.93.2.628</pub-id><pub-id pub-id-type="pmid">8570606</pub-id></element-citation></ref><ref id="bib50"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Shadlen</surname><given-names>MN</given-names></name><name><surname>Newsome</surname><given-names>WT</given-names></name></person-group><year iso-8601-date="2001">2001</year><article-title>Neural basis of a perceptual decision in the parietal cortex (area LIP) of the rhesus monkey</article-title><source>Journal of Neurophysiology</source><volume>86</volume><fpage>1916</fpage><lpage>1936</lpage><pub-id pub-id-type="doi">10.1152/jn.2001.86.4.1916</pub-id><pub-id pub-id-type="pmid">11600651</pub-id></element-citation></ref><ref id="bib51"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Shadlen</surname><given-names>MN</given-names></name><name><surname>Kiani</surname><given-names>R</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>Decision making as a window on cognition</article-title><source>Neuron</source><volume>80</volume><fpage>791</fpage><lpage>806</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2013.10.047</pub-id><pub-id pub-id-type="pmid">24183028</pub-id></element-citation></ref><ref id="bib52"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Shipp</surname><given-names>S</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Neural elements for predictive coding</article-title><source>Frontiers in Psychology</source><volume>7</volume><elocation-id>1792</elocation-id><pub-id pub-id-type="doi">10.3389/fpsyg.2016.01792</pub-id><pub-id pub-id-type="pmid">27917138</pub-id></element-citation></ref><ref id="bib53"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Shushruth</surname><given-names>S</given-names></name><name><surname>Mazurek</surname><given-names>M</given-names></name><name><surname>Shadlen</surname><given-names>MN</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>Comparison of decision-related signals in sensory and motor preparatory responses of neurons in area LIP</article-title><source>The Journal of Neuroscience</source><volume>38</volume><fpage>6350</fpage><lpage>6365</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.0668-18.2018</pub-id><pub-id pub-id-type="pmid">29899029</pub-id></element-citation></ref><ref id="bib54"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Song</surname><given-names>HF</given-names></name><name><surname>Yang</surname><given-names>GR</given-names></name><name><surname>Wang</surname><given-names>XJ</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Training excitatory-inhibitory recurrent neural networks for cognitive tasks: A simple and flexible framework</article-title><source>PLOS Computational Biology</source><volume>12</volume><elocation-id>e1004792</elocation-id><pub-id pub-id-type="doi">10.1371/journal.pcbi.1004792</pub-id><pub-id pub-id-type="pmid">26928718</pub-id></element-citation></ref><ref id="bib55"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Sugrue</surname><given-names>LP</given-names></name><name><surname>Corrado</surname><given-names>GS</given-names></name><name><surname>Newsome</surname><given-names>WT</given-names></name></person-group><year iso-8601-date="2004">2004</year><article-title>Matching behavior and the representation of value in the parietal cortex</article-title><source>Science</source><volume>304</volume><fpage>1782</fpage><lpage>1787</lpage><pub-id pub-id-type="doi">10.1126/science.1094765</pub-id><pub-id pub-id-type="pmid">15205529</pub-id></element-citation></ref><ref id="bib56"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Swaminathan</surname><given-names>SK</given-names></name><name><surname>Freedman</surname><given-names>DJ</given-names></name></person-group><year iso-8601-date="2012">2012</year><article-title>Preferential encoding of visual categories in parietal cortex compared with prefrontal cortex</article-title><source>Nature Neuroscience</source><volume>15</volume><fpage>315</fpage><lpage>320</lpage><pub-id pub-id-type="doi">10.1038/nn.3016</pub-id><pub-id pub-id-type="pmid">22246435</pub-id></element-citation></ref><ref id="bib57"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wang</surname><given-names>XJ</given-names></name></person-group><year iso-8601-date="2002">2002</year><article-title>Probabilistic decision making by slow reverberation in cortical circuits</article-title><source>Neuron</source><volume>36</volume><fpage>955</fpage><lpage>968</lpage><pub-id pub-id-type="doi">10.1016/s0896-6273(02)01092-9</pub-id><pub-id pub-id-type="pmid">12467598</pub-id></element-citation></ref><ref id="bib58"><element-citation publication-type="preprint"><person-group person-group-type="author"><name><surname>Wang</surname><given-names>C</given-names></name><name><surname>Chen</surname><given-names>X</given-names></name><name><surname>Zhang</surname><given-names>T</given-names></name><name><surname>Wu</surname><given-names>S</given-names></name></person-group><year iso-8601-date="2022">2022</year><article-title>BrainPy: a flexible, integrative, efficient, and extensible framework towards general-purpose brain dynamics programming</article-title><source>bioRxiv</source><pub-id pub-id-type="doi">10.1101/2022.10.28.514024</pub-id></element-citation></ref><ref id="bib59"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wang</surname><given-names>S</given-names></name><name><surname>Falcone</surname><given-names>R</given-names></name><name><surname>Richmond</surname><given-names>B</given-names></name><name><surname>Averbeck</surname><given-names>BB</given-names></name></person-group><year iso-8601-date="2023">2023</year><article-title>Attractor dynamics reflect decision confidence in macaque prefrontal cortex</article-title><source>Nature Neuroscience</source><volume>26</volume><fpage>1970</fpage><lpage>1980</lpage><pub-id pub-id-type="doi">10.1038/s41593-023-01445-x</pub-id><pub-id pub-id-type="pmid">37798412</pub-id></element-citation></ref><ref id="bib60"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wimmer</surname><given-names>K</given-names></name><name><surname>Compte</surname><given-names>A</given-names></name><name><surname>Roxin</surname><given-names>A</given-names></name><name><surname>Peixoto</surname><given-names>D</given-names></name><name><surname>Renart</surname><given-names>A</given-names></name><name><surname>de la Rocha</surname><given-names>J</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>Sensory integration dynamics in a hierarchical network explains choice probabilities in cortical area MT</article-title><source>Nature Communications</source><volume>6</volume><elocation-id>6177</elocation-id><pub-id pub-id-type="doi">10.1038/ncomms7177</pub-id><pub-id pub-id-type="pmid">25649611</pub-id></element-citation></ref><ref id="bib61"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wong</surname><given-names>KF</given-names></name><name><surname>Wang</surname><given-names>XJ</given-names></name></person-group><year iso-8601-date="2006">2006</year><article-title>A recurrent network mechanism of time integration in perceptual decisions</article-title><source>The Journal of Neuroscience</source><volume>26</volume><fpage>1314</fpage><lpage>1328</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.3733-05.2006</pub-id><pub-id pub-id-type="pmid">16436619</pub-id></element-citation></ref><ref id="bib62"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wong</surname><given-names>KF</given-names></name><name><surname>Huk</surname><given-names>AC</given-names></name><name><surname>Shadlen</surname><given-names>MN</given-names></name><name><surname>Wang</surname><given-names>XJ</given-names></name></person-group><year iso-8601-date="2007">2007</year><article-title>Neural circuit dynamics underlying accumulation of time-varying evidence during perceptual decision making</article-title><source>Frontiers in Computational Neuroscience</source><volume>1</volume><elocation-id>6</elocation-id><pub-id pub-id-type="doi">10.3389/neuro.10.006.2007</pub-id><pub-id pub-id-type="pmid">18946528</pub-id></element-citation></ref><ref id="bib63"><element-citation publication-type="software"><person-group person-group-type="author"><name><surname>Wu</surname><given-names>X</given-names></name></person-group><year iso-8601-date="2025">2025</year><data-title>TD-modulation-model</data-title><version designator="swh:1:rev:c6e3198fbff7de1388a93c6b2c258e6e82323c09">swh:1:rev:c6e3198fbff7de1388a93c6b2c258e6e82323c09</version><source>Software Heritage</source><ext-link ext-link-type="uri" xlink:href="https://archive.softwareheritage.org/swh:1:dir:bcdc8e25cf78f378253079b95fdc168322f6633f;origin=https://github.com/xuanyuw/TD-modulation-model;visit=swh:1:snp:446cd1a0411bd16bae6f42c4e809e6bd22e5ab96;anchor=swh:1:rev:c6e3198fbff7de1388a93c6b2c258e6e82323c09">https://archive.softwareheritage.org/swh:1:dir:bcdc8e25cf78f378253079b95fdc168322f6633f;origin=https://github.com/xuanyuw/TD-modulation-model;visit=swh:1:snp:446cd1a0411bd16bae6f42c4e809e6bd22e5ab96;anchor=swh:1:rev:c6e3198fbff7de1388a93c6b2c258e6e82323c09</ext-link></element-citation></ref><ref id="bib64"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Yates</surname><given-names>JL</given-names></name><name><surname>Park</surname><given-names>IM</given-names></name><name><surname>Katz</surname><given-names>LN</given-names></name><name><surname>Pillow</surname><given-names>JW</given-names></name><name><surname>Huk</surname><given-names>AC</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>Functional dissection of signal and noise in MT and LIP during decision-making</article-title><source>Nature Neuroscience</source><volume>20</volume><fpage>1285</fpage><lpage>1292</lpage><pub-id pub-id-type="doi">10.1038/nn.4611</pub-id><pub-id pub-id-type="pmid">28758998</pub-id></element-citation></ref><ref id="bib65"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Zhou</surname><given-names>Y</given-names></name><name><surname>Freedman</surname><given-names>DJ</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>Posterior parietal cortex plays a causal role in perceptual and categorical decisions</article-title><source>Science</source><volume>365</volume><fpage>180</fpage><lpage>185</lpage><pub-id pub-id-type="doi">10.1126/science.aaw8347</pub-id><pub-id pub-id-type="pmid">31296771</pub-id></element-citation></ref><ref id="bib66"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Zhou</surname><given-names>Y</given-names></name><name><surname>Rosen</surname><given-names>MC</given-names></name><name><surname>Swaminathan</surname><given-names>SK</given-names></name><name><surname>Masse</surname><given-names>NY</given-names></name><name><surname>Zhu</surname><given-names>O</given-names></name><name><surname>Freedman</surname><given-names>DJ</given-names></name></person-group><year iso-8601-date="2021">2021</year><article-title>Distributed functions of prefrontal and parietal cortices during sequential categorical decisions</article-title><source>eLife</source><volume>10</volume><elocation-id>e58782</elocation-id><pub-id pub-id-type="doi">10.7554/eLife.58782</pub-id><pub-id pub-id-type="pmid">34491201</pub-id></element-citation></ref><ref id="bib67"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Zhou</surname><given-names>Y</given-names></name><name><surname>Mohan</surname><given-names>K</given-names></name><name><surname>Freedman</surname><given-names>DJ</given-names></name></person-group><year iso-8601-date="2022">2022</year><article-title>Abstract encoding of categorical decisions in medial superior temporal and lateral intraparietal cortices</article-title><source>The Journal of Neuroscience</source><volume>42</volume><fpage>9069</fpage><lpage>9081</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.0017-22.2022</pub-id><pub-id pub-id-type="pmid">36261285</pub-id></element-citation></ref><ref id="bib68"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Zhou</surname><given-names>Y</given-names></name><name><surname>Zhu</surname><given-names>O</given-names></name><name><surname>Freedman</surname><given-names>DJ</given-names></name></person-group><year iso-8601-date="2023">2023</year><article-title>Posterior parietal cortex plays a causal role in abstract memory-based visual categorical decisions</article-title><source>The Journal of Neuroscience</source><volume>43</volume><fpage>4315</fpage><lpage>4328</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.2241-22.2023</pub-id><pub-id pub-id-type="pmid">37137703</pub-id></element-citation></ref></ref-list></back><sub-article article-type="editor-report" id="sa0"><front-stub><article-id pub-id-type="doi">10.7554/eLife.96402.3.sa0</article-id><title-group><article-title>eLife Assessment</article-title></title-group><contrib-group><contrib contrib-type="author"><name><surname>Bi</surname><given-names>Yanchao</given-names></name><role specific-use="editor">Reviewing Editor</role><aff><institution>Peking University</institution><country>China</country></aff></contrib></contrib-group><kwd-group kwd-group-type="evidence-strength"><kwd>Incomplete</kwd></kwd-group><kwd-group kwd-group-type="claim-importance"><kwd>Valuable</kwd></kwd-group></front-stub><body><p>This <bold>valuable</bold> study by Wu and Zhou combines neurophysiological recordings and computational modelling to address an interesting question regarding the sequence of events from sensing to action. Neurophysiological evidence remains <bold>incomplete</bold>: explicit mapping of saccade-related activity in the same neurons and a better understanding of the influence of the spatial configuration of stimulus and targets would be required to pinpoint whether such activity might contribute, even partially, to the observed results and interpretations. These results are of interest for neuroscientists investigating decision-making.</p></body></sub-article><sub-article article-type="referee-report" id="sa1"><front-stub><article-id pub-id-type="doi">10.7554/eLife.96402.3.sa1</article-id><title-group><article-title>Reviewer #2 (Public review):</article-title></title-group><contrib-group><contrib contrib-type="author"><anonymous/><role specific-use="referee">Reviewer</role></contrib></contrib-group></front-stub><body><p>Summary:</p><p>In this manuscript, the authors recorded activity in the posterior parietal cortex (PPC) of monkeys performing a perceptual decision-making task. The monkeys were first shown two choice dots of two different colors. Then, they saw a random dot motion stimulus. They had to learn to categorize the direction of motion as referring to either the right or left dot. However, the rule was based on the color of the dot and not its location. So, the red dot could either be to the right or left, but the rule itself remained the same. It is known from past work that PPC neurons would code the learned categorization. Here, the authors showed that the categorization signal depended on whether the executed saccade was in the same hemifield as the recorded PPC neuron or in the opposite one. That is, if a neuron categorized the two motion directions such that it responded stronger for one than the other, then this differential motion direction coding effect was amplified if the subsequent choice saccade was in the same hemifield. The authors then built a computational RNN to replicate the results and make further tests by simulated &quot;lesions&quot;.</p><p>Strengths:</p><p>Linking the results to RNN simulations and simulated lesions.</p><p>Weaknesses:</p><p>Potential interpretational issues due to a lack of explicit evidence on the sizes and locations of the response fields of the neurons. For example, is the contra/ipsi effect explained by the fact that in the contra condition, the response target and the saccade might have infringed on the outer edges of the response fields?</p></body></sub-article><sub-article article-type="author-comment" id="sa2"><front-stub><article-id pub-id-type="doi">10.7554/eLife.96402.3.sa2</article-id><title-group><article-title>Author response</article-title></title-group><contrib-group><contrib contrib-type="author"><name><surname>Wu</surname><given-names>Xuanyu</given-names></name><role specific-use="author">Author</role><aff><institution>Peking University</institution><addr-line><named-content content-type="city">Beijing</named-content></addr-line><country>China</country></aff></contrib><contrib contrib-type="author"><name><surname>Zhou</surname><given-names>Yang</given-names></name><role specific-use="author">Author</role><aff><institution>Peking University</institution><addr-line><named-content content-type="city">Beijing</named-content></addr-line><country>China</country></aff></contrib></contrib-group></front-stub><body><p>The following is the authors’ response to the original reviews</p><disp-quote content-type="editor-comment"><p><bold>Reviewer #1 (Public Review):</bold></p><p>Summary:</p><p>This valuable study by Wu and Zhou combined neurophysiological recordings and computational modelling to investigate the neural mechanisms that underpin the interaction between sensory evaluation and action selection. The neurophysiological results suggest non-linear modulation of decision-related LIP activity by action selection, but some further analysis would be helpful in order to understand whether these results can be generalised to LIP circuitry or might be dependent on specific spatial task configurations. The authors present solid computational evidence that this might be due to projections from choice target representations. These results are of interest for neuroscientists investigating decision-making.</p><p>Strengths:</p><p>Wu and Zhou combine awake behaving neurophysiology for a sophisticated, flexible visual-motion discrimination task and a recurrent network model to disentangle the contribution of sensory evaluation and action selection to LIP firing patterns. The correct saccade response direction for preferred motion direction choices is randomly interleaved between contralateral and ipsilateral response targets, which allows the dissociation of perceptual choice from saccade direction.</p><p>The neurophysiological recordings from area LIP indicate non-linear interaction between motion categorisation decisions and saccade choice direction.</p><p>The careful investigation of a recurrent network model suggests that feedback from choice target representations to an earlier sensory evaluation stage might be the source for this non-linear modulation and that it is an important circuit component for behavioural performance.</p><p>The paper presents a possible solution to a central controversy about the role of LIP in perceptual decision-making, but see below.</p><p>Weaknesses:</p><p>The paper presents a possible solution to a central controversy about the role of LIP in perceptual decision-making. However, the authors could be more clear and upfront about their interpretational framework and potential alternative interpretations.</p><p>Centrally, the authors' model and experimental data appears to test only that LIP carries out sensory evaluation in its RFs. The model explicitly parks the representation of choice targets outside the &quot;LIP&quot; module receiving sensory input. The feedback from this separate target representation provides then the non-linear modulation that matches the neurophysiology. However, they ignore the neurophysiological results that LIP neurons can also represent motor planning to a saccade target.</p><p>The neurophysiological results with a modulation of the direction tuning by choice direction (contralateral vs ipsilateral) are intriguing. However, the evaluation of the neurophysiological results are difficult, because some of the necessary information is missing to exclude alternative explanations. It would be good to see the actual distributions and sizes of the RF, which were determined based on visual responses not with a delayed saccade task. There might be for example a simple spatial configuration, for example, RF and preferred choice target in the same (contralateral) hemifield, for which there is an increase in firing. It is a shame that we do not see what these neurons would do if only a choice target would be put in the RF, as has been done in so many previous LIP experiments. The authors exclude also some spatial task configurations (vertical direction decisions), which makes it difficult to judge whether these data and models can be generalised. The whole section is difficult to follow, partly also because it appears to mix reporting results with interpretation (e.g. &quot;feedback&quot;).</p><p>The model and its investigation is very interesting and thorough, but given the neurophysiological literature on LIP, it is not clear that the target module would need to be in a separate brain area, but could be local circuitry within LIP between different neuron types.</p><p><bold>Reviewer #2 (Public Review):</bold></p><p>Summary:</p><p>In this manuscript, the authors recorded activity in the posterior parietal cortex (PPC) of monkeys performing a perceptual decision-making task. The monkeys were first shown two choice dots of two different colors. Then, they saw a random dot motion stimulus. They had to learn to categorize the direction of motion as referring to either the right or left dot. However, the rule was based on the color of the dot and not its location. So, the red dot could either be to the right or left, but the rule itself remained the same. It is known from past work that PPC neurons would code the learned categorization. Here, the authors showed that the categorization signal depended on whether the executed saccade was in the same hemifield as the recorded PPC neuron or in the opposite one. That is, if a neuron categorized the two motion directions such that it responded stronger for one than the other, then this differential motion direction coding effect was amplified if the subsequent choice saccade was in the same hemifield. The authors then built a computational RNN to replicate the results and make further tests by simulated &quot;lesions&quot;.</p><p>Strengths:</p><p>Linking the results to RNN simulations and simulated lesions.</p><p>Weaknesses:</p><p>Potential interpretational issues due to a lack of evidence on what happens at the time of the saccades.</p><p><bold>Recommendations for the authors:</bold></p><p><bold>Reviewer #1 (Recommendations For The Authors):</bold></p><p>(1) The neurophysiological results with a modulation of the direction tuning by choice direction are intriguing. However, the evaluation of the neurophysiological results are difficult because some of the necessary information is missing to exclude alternative explanations.</p></disp-quote><p>We thank the reviewer for the helpful comments. We have addressed this point in detail in the following response.</p><disp-quote content-type="editor-comment"><p>(a) Clearly state in the results how the response field &quot;RF&quot;, where the stimulus was placed, was mapped. The methods give as &quot;MGS&quot;&quot; (i.e., spatial selectivity during stimulus presentation and delay)&quot; task rather than the standard delayed saccade. And also &quot;while for those neurons which did not show a clear RF during the MGS task, we presented motion stimuli in the positions (always in the visual field contralateral to the recorded hemisphere) in which neurons exhibited the strongest response to the motion stimuli.&quot; All this sounds more like a sensory receptive field not an eye movement response filed&quot;. What was the exact task and criterion?</p></disp-quote><p>We agree with the reviewer that the original description of how we mapped the response fields (RFs) of LIP neurons lacked sufficient detail. In this study, we used the memory-guided saccade (MGS) task to map the RFs of all isolated LIP neurons. Both MGS and delayed saccade tasks are commonly used to map a neuron's response field in previous decision-making studies.</p><p>In the MGS task, monkeys initially fixate on the center of the screen. Subsequently, a dot randomly flashes at one of the eight possible locations surrounding the fixation dot with an eccentricity of 8 degree, requiring the monkeys to memorize the location of the flashed dot. After a delay of 1000 ms, the monkeys are instructed to saccade to the remembered location once the fixation dot disappears. The MGS task is a standard behavior task for mapping visual, memory, and motor RFs, particularly in brain regions involved in eye movement planning and control, such as LIP, FEF, and the superior colliculus.</p><p>We believe the reviewer's confusion may stem from whether we mapped the visual, memory, or motor RFs of LIP neurons in the current study, as these &quot;RFs&quot; are not always consistent across individual neurons. In our study, we primarily mapped the visual and memory RFs of each LIP neuron by analyzing their activity during both the target presentation and delay periods. To focus on sensory evaluation-related activity, we presented the visual motion stimulus within the visual-memory RF of each neuron. For neurons that did not show a significant visual-memory RF, we used a different approach: we tested the neurons with the main task by altering the spatial configuration of the task stimuli to identify the visual field that elicited the strongest response when the motion stimulus was presented within it. This approach was used to guide the placement of the stimulus during the recording sessions.</p><p>Following the reviewer’s suggestion, we have added the following clarification to the results section to better describe how we mapped the RF of LIP neurons:</p><p>‘We used the memory-guided saccade (MGS) task, which is commonly employed in LIP studies, to map the receptive fields (RFs) of all isolated LIP neurons. Specifically, we mapped both the visual and memory RFs of each neuron by analyzing their activity during the target presentation and delay periods of the MGS task (see Methods).’.</p><disp-quote content-type="editor-comment"><p>(b) l.85 / l126: What do you mean by &quot;orthogonal to the axis of the neural RF&quot; - was the RF shape asymmetric, if so how did you determine this? OR do you mean the motion direction axis? Please explain.</p></disp-quote><p>We realized that the original description of this point may have been unclear and could lead to confusion. The axis of the neural RF refers to the line connecting the center of the RF (which coincides with the center of the motion stimulus) to the fixation dot. We have revised this sentence in the revised manuscript as follows:</p><p>‘To examine the neural activity related to the evaluation of stimulus motion, we presented the motion stimuli within the RF of each neuron, while positioning the saccade targets at locations orthogonal to the line connecting the center of the RF (which also marks the center of the motion stimulus) and the fixation dot.’</p><disp-quote content-type="editor-comment"><p>(c) Behavioural task. Figure 1 - are these example session? Please state this clearly. Can you show the examples (psychometric function and reaction times) separated for trials where correct choice direction aligning with the motion preference (within 90 degrees) and those that did not?</p></disp-quote><p>Figure 1 shows the averaged behavioral results from all recording sessions. We have added this detail in the revised legend of Figure 1.</p><p>We are uncertain about the reviewer’s reference to the “correct choice direction aligning with the motion preference,” as the term “motion preference” is specific to the neuron response, which are different for different neurons recorded simultaneously using multichannel recording probe.</p><p>Nonetheless, following the reviewer’s suggestion, we grouped the trials in each recording session into two groups based on the relationship between the saccade direction and the preferred motion direction of the identified LIP neuron during one example single-channel recording. Both the RT and the performance accuracy during one example session were shown in the following figure.</p><fig id="sa2fig1" position="float"><label>Author response image 1.</label><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-96402-sa2-fig1-v1.tif"/></fig><disp-quote content-type="editor-comment"><p>Give also the performance averaged across all sites included in this study and range.</p><p>If performance does differ for different configuration, please, show that the main modulatory effect does not align with this distinction.</p></disp-quote><p>To clarify this point, we have plotted performance accuracy and RTs for horizontal, oblique, and vertical target position configurations separately, which are shown for both monkeys in the following figures. We did not observe any systematic influences of task configurations on the monkeys' performance accuracy. While the RTs did differ across different configurations, we believe these differences are likely attributable to several factors, such as varying levels of familiarity introduced by our training process and the intrinsic RT difference between different saccade directions.</p><fig id="sa2fig2" position="float"><label>Author response image 2.</label><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-96402-sa2-fig2-v1.tif"/></fig><disp-quote content-type="editor-comment"><p>(d) Show the distribution of RF positions and the direction preferences for the recording sites included in the quantitative analysis of this study. (And if available, separately those excluded).</p></disp-quote><p>Following the reviewer’s suggestion, we have plotted the centers of the RFs for all neurons with identifiable RFs, categorizing them by their preferred motion directions. To determine each neuron’s RF, we analyzed the average firing rates from both the target presentation and delay periods during each trial of the memory-guided saccade (MGS) task. The RF centers of neurons with significant RFs were determined through a two-step process. First, we selected neurons that exhibited significant RFs in the MGS based on the following criteria: (1) there must be a significant activity difference between the eight target locations, and (2) the mean activity during the selected periods should be significantly greater than the baseline activity during the fixation period. Second, we fitted the activity data from the eight conditions to a Gaussian distribution, using the center of the fitted distribution as the RF center. A significant proportion of neurons from both monkeys that exhibited significant response to motion stimuli did not exhibited notable RFs based our current method. The following figures show the distributions of RFs and motion direction preference for all LIP neurons with identifiable RFs separately for each monkey. Since this is not the focus of the current study, we are not planning to include this result in the revised manuscript.</p><fig id="sa2fig3" position="float"><label>Author response image 3.</label><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-96402-sa2-fig3-v1.tif"/></fig><disp-quote content-type="editor-comment"><p>(e) Following on from (d), was there a systematic relationship between RF position or direction preference and modulation by choice direction? For instance could the responses be simply explained by an increase in modulation for choices into the same (contralateral) hemifield as where the stimulus was placed?</p></disp-quote><p>The reviewer raised a good point. To address whether there was a systematic relationship between RF position or direction preference and modulation by choice direction, we calculated a modulation index for each neuron to quantify the influence of saccade direction on neuronal responses to motion stimuli. We then plotted the modulation index against the RF position for each LIP neuron, shown as following:</p><fig id="sa2fig4" position="float"><label>Author response image 4.</label><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-96402-sa2-fig4-v1.tif"/></fig><p>As shown in the figures above, neurons with RFs farther from the horizontal meridian were more likely to exhibit stronger modulation by the saccade direction, while neurons with RFs closer to the horizontal meridian showed inconsistent and weaker modulation. This is because when the RFs was on the horizontal meridian, saccade directions were aligned with the vertical axis (with no contralateral or ipsilateral directions). This is consistent with the finding in Figure S3—no significant differences in direction selectivity between the CT and IT conditions in the data sessions where the saccade targets were aligned close to the vertical direction. Since fewer than half of the identified neurons showed clear receptive fields using our method, the figure above did not include all the neurons used in the analysis in the manuscript. Therefore, we chose not to include this figure in the revised manuscript.</p><p>Additionally, we quantified the relationship between the modulation index and direction preference for neurons in sessions where the monkeys’ saccades were aligned to either horizontal or oblique directions. As shown in the following figure, no systematic relationship was found between direction preference and modulation by the choice direction for LIP neurons at the population level.</p><fig id="sa2fig5" position="float"><label>Author response image 5.</label><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-96402-sa2-fig5-v1.tif"/></fig><p>We have added this result as Figure S 2 in the revised manuscript.</p><p>Notably, the observed modulation of saccade direction on LIP neurons’ response to motion stimuli cannot be simply explained by saccade direction selectivity. We presented two more evidence to rule out such possibility in the original manuscript. First, the modulation effect we observed was nonlinear; specifically, the firing rate of neurons increased for the preferred motion direction but decreased for the non-preferred motion direction (Figure 2i and Figure S1A-D). This phenomenon is unlikely to be attributed to a linear gain modulation driven by saccade directions. Second, we plotted the averaged neural activity for contralateral and ipsilateral saccade directions separately, and found that LIP neurons showed similar levels of activity between two saccade directions (revised Figure 2L).</p><p>Additionally, we added a paragraph in the Methods section to describe the way we calculated modulation index as follows:</p><p>“We have calculated a modulation index for each neuron to reflect the influence of saccade direction on neuron’s response to visual stimuli. The modulation index is calculated as:<disp-formula id="sa2equ1"><alternatives><mml:math id="sa2m1"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>δ</mml:mi><mml:mrow><mml:mtext>contra </mml:mtext></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:msubsup><mml:mi>r</mml:mi><mml:mrow><mml:mtext>pref </mml:mtext></mml:mrow><mml:mrow><mml:mtext>contra </mml:mtext></mml:mrow></mml:msubsup><mml:mo>−</mml:mo><mml:msubsup><mml:mi>r</mml:mi><mml:mrow><mml:mtext>non-pref </mml:mtext></mml:mrow><mml:mrow><mml:mtext>contra </mml:mtext></mml:mrow></mml:msubsup></mml:mrow></mml:mstyle></mml:math><tex-math id="t9">\begin{document}$$\displaystyle \delta_{\text {contra }}=r_{\text {pref }}^{\text {contra }}-r_{\text {non-pref }}^{\text {contra }}$$\end{document}</tex-math></alternatives></disp-formula><disp-formula id="sa2equ2"><alternatives><mml:math id="sa2m2"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>δ</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>p</mml:mi><mml:mi>s</mml:mi><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:msubsup><mml:mi>r</mml:mi><mml:mrow><mml:mi>p</mml:mi><mml:mi>r</mml:mi><mml:mi>e</mml:mi><mml:mi>f</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mi>p</mml:mi><mml:mi>s</mml:mi><mml:mi>i</mml:mi></mml:mrow></mml:msubsup><mml:mo>−</mml:mo><mml:msubsup><mml:mi>r</mml:mi><mml:mrow><mml:mi>n</mml:mi><mml:mi>o</mml:mi><mml:mi>n</mml:mi><mml:mo>−</mml:mo><mml:mi>p</mml:mi><mml:mi>r</mml:mi><mml:mi>e</mml:mi><mml:mi>f</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mi>p</mml:mi><mml:mi>s</mml:mi><mml:mi>i</mml:mi></mml:mrow></mml:msubsup></mml:mrow></mml:mstyle></mml:math><tex-math id="t10">\begin{document}$$\displaystyle \delta_{i p s i}=r_{p r e f}^{i p s i}-r_{n o n-p r e f}^{i p s i}$$\end{document}</tex-math></alternatives></disp-formula><disp-formula id="sa2equ3"><alternatives><mml:math id="sa2m3"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mrow><mml:mi mathvariant="normal">M</mml:mi><mml:mi mathvariant="normal">I</mml:mi></mml:mrow><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:msub><mml:mi>δ</mml:mi><mml:mrow><mml:mtext>contra </mml:mtext></mml:mrow></mml:msub><mml:mo>−</mml:mo><mml:msub><mml:mi>δ</mml:mi><mml:mrow><mml:mrow><mml:mi mathvariant="normal">i</mml:mi><mml:mi mathvariant="normal">p</mml:mi><mml:mi mathvariant="normal">s</mml:mi><mml:mi mathvariant="normal">i</mml:mi></mml:mrow></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:msub><mml:mi>δ</mml:mi><mml:mrow><mml:mtext>contra </mml:mtext></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mi>δ</mml:mi><mml:mrow><mml:mrow><mml:mi mathvariant="normal">i</mml:mi><mml:mi mathvariant="normal">p</mml:mi><mml:mi mathvariant="normal">s</mml:mi><mml:mi mathvariant="normal">i</mml:mi></mml:mrow></mml:mrow></mml:msub></mml:mrow></mml:mfrac></mml:mrow></mml:mstyle></mml:math><tex-math id="t11">\begin{document}$$\displaystyle \mathrm{MI}=\frac{\delta_{\text {contra }}-\delta_{\mathrm{ipsi}}}{\delta_{\text {contra }}+\delta_{\mathrm{ipsi}}}$$\end{document}</tex-math></alternatives></disp-formula></p><p>where <inline-formula><alternatives><mml:math id="sa2m4"><mml:mstyle><mml:mrow><mml:msubsup><mml:mi>r</mml:mi><mml:mrow><mml:mtext>pref </mml:mtext></mml:mrow><mml:mrow><mml:mtext>contra </mml:mtext></mml:mrow></mml:msubsup></mml:mrow></mml:mstyle></mml:math><tex-math id="inft19">\begin{document}$r_{\text {pref }}^{\text {contra }}$\end{document}</tex-math></alternatives></inline-formula> represents the average firing rate from 50ms to 250ms after sample onset for all contralateral saccade trails with a neuron’s preferred moving direction of visual stimuli. The naming conventions are the same for <inline-formula><alternatives><mml:math id="sa2m5"><mml:mstyle><mml:mrow><mml:msubsup><mml:mi>r</mml:mi><mml:mrow><mml:mtext>non-pref </mml:mtext></mml:mrow><mml:mrow><mml:mtext>contra </mml:mtext></mml:mrow></mml:msubsup></mml:mrow></mml:mstyle></mml:math><tex-math id="inft20">\begin{document}$r_{\text {non-pref }}^{\text {contra }}$\end{document}</tex-math></alternatives></inline-formula>, <inline-formula><alternatives><mml:math id="sa2m6"><mml:mstyle><mml:mrow><mml:msubsup><mml:mi>r</mml:mi><mml:mrow><mml:mtext>pref </mml:mtext></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mi>p</mml:mi><mml:mi>s</mml:mi><mml:mi>i</mml:mi></mml:mrow></mml:msubsup></mml:mrow></mml:mstyle></mml:math><tex-math id="inft21">\begin{document}$r_{\text {pref }}^{i p s i}$\end{document}</tex-math></alternatives></inline-formula>, and <inline-formula><alternatives><mml:math id="sa2m7"><mml:mstyle><mml:mrow><mml:msubsup><mml:mi>r</mml:mi><mml:mrow><mml:mtext>non-pref </mml:mtext></mml:mrow><mml:mrow><mml:mtext>ipsi </mml:mtext></mml:mrow></mml:msubsup></mml:mrow></mml:mstyle></mml:math><tex-math id="inft22">\begin{document}$r_{\text {non-pref }}^{\text {ipsi }}$\end{document}</tex-math></alternatives></inline-formula>. An MI value between 0 and 1 indicate higher modulation in contralateral saccade trials, and an MI value between -1 and 0 indicates higher modulation in ipsilateral saccade trials.”</p><disp-quote content-type="editor-comment"><p>Please split Figures 2G,H,I J,K, by whether the RF was located contralaterally or ipsilaterally. If there are only a small number of ipsilateral RFs, please show these examples, perhaps in an appendix.</p></disp-quote><p>This is a reasonable suggestion; however, it is not applicable to our study. Among all the neurons included in our analysis, only one neuron from each monkey exhibited ipsilateral receptive fields (RFs). Therefore, we believe it may not be necessary to plot the result for this outlier.</p><disp-quote content-type="editor-comment"><p>(f) Were the choice targets always equi-distant from the stimulus and at what distance was this? Please give quantitative details in methods.</p></disp-quote><p>The review was correct that the choice targets were always equidistant form the stimulus. The distance between the motion stimulus and the target was typically 12-15 degree. We have added the details in the revised Methods section as follows:</p><p>‘Therefore, the two saccade targets were equidistant from the stimulus, with the distance typically ranging from 12 to 15 degrees.</p><disp-quote content-type="editor-comment"><p>(2) For Figure 3E, how do you explain that there is an up regulation of for contralateral choices before the stimulus onset, i.e. before the animal can make a decision? Is this difference larger for error trials?</p></disp-quote><p>This is a good question, which we have attempted to clarify in the revised manuscript. We believe that the observed upregulation in neural activity for contralateral choices may reflect the monkeys’ internal choice bias or expectation (choice between two motion directions) prior to stimulus presentation, which could influence their subsequent decisions. In Figure 3E, we calculated the r-choice to assess the correlation between the neuron’s direction selectivity and the monkeys’ decisions on motion stimuli, separately for contralateral and ipsilateral choice conditions. The increased r-decision during the pre-stimulus period indicates stronger neural activity for trials in which the monkeys later reported that the upcoming stimulus was in the preferred direction, and weaker activity for trials where the stimulus was judged to be in the non-preferred direction. This correlation was more pronounced for contralateral choices than for ipsilateral ones. It is important to note that while the monkeys cannot predict the upcoming stimulus direction with greater-than-chance accuracy, these results suggest that pre-stimulus neural activity in LIP is correlated with the monkeys’ eventual decision for that trial. Furthermore, LIP neural activity was more strongly correlated with the monkeys’ decisions in the contralateral choice condition compared to the ipsilateral one.</p><p>Additionally, we clarify that the r-decision was calculated using both correct and error trials. When comparing Figure 2J with Figure 2K, the correlation between neural activity and the monkeys’ upcoming decision during the pre-stimulus period was most prominent in low- and zero-coherence trials, where the monkeys either made more errors or based decisions on guesswork. We infer that the monkeys' confidence in these decisions was likely lower compared to high-coherence trials. Thus, the decision process appears to be influenced by pre-stimulus neural activity, particularly in low-coherence and zero-coherence trials.</p><p>Although it is unclear precisely what covert process this pre-stimulus activity reflects, similar patterns of choice-predictive pre-stimulus activity have been observed in LIP and other brain areas (Shadlen, M.N. and Newsome,T.W., 2001; Coe, B., at al. 2002; Baso, M.A. and Wurtz, R.H., 1998; Z. M. Williams at al. 2003). We have clarified this point in the revised manuscript, including a revision of the relevant sentence in the Results section for clarity, shown as follows:</p><p>“Furthermore, we used partial correlation analysis to examine decision- and stimulus-related components of DS (i.e., r-decision and r-stimulus, Figure 3E and 3F) using all four coherence levels. The decision-related component of LIP DS was significantly greater in the CT condition than in the IT condition (Figure 3E; nested ANOVA: P = 1.07e-6, F = 25.72), and this difference emerged even before motion stimulus onset. This suggests that the LIP DS was more closely correlated with monkeys’ decisions in the CT condition than in the IT condition. The upregulation in r-decision for contralateral choices may reflect the monkeys’ internal choice bias or expectation (choice between two motion directions) prior to stimulus presentation, which could influence their subsequent decisions more in the CT condition”</p><disp-quote content-type="editor-comment"><p>(3) Figure 2K: what is the very large condition-independent contribution? It almost seems as most of what these neurons code for is neither saccade or motion related.</p></disp-quote><p>The condition-independent contribution is the time-dependent component that is unrelated to saccade, motion, or their interaction. Our findings are consistent with previous methodological studies, where this time-dependent component was shown to account for a significant portion of the variance in population activity (Kobak, D. et al., 2016)</p><disp-quote content-type="editor-comment"><p>(4) Abstract:</p><p>a) &quot;We found that the PPC activity related to monkeys' abstract decisions about visual stimuli was nonlinearly modulated by monkeys' following saccade choices directing outside each neuron's response field.&quot;</p><p>This sentence is not clear/precise in two regards:</p><p>Should &quot;directing&quot; be &quot;directed&quot;?</p><p>Also, it is not just saccades directed outside the RF, but towards the contralateral hemifield.</p></disp-quote><p>We thank the reviewer for the suggestion. We agree that ‘directing’ should be ‘directed’ and revised it accordingly. However, we do not believe that ‘directed outside each neuron's response field’ should be replaced with “towards the contralateral hemifield”. There are two major reasons. First, the modulation effect was identified as the difference between contralateral and ipsilateral saccade directions. We cannot conclude that the modulation mainly happened in the contralateral saccade direction. Second, we used ‘directed outside each neuron's response field’ to emphasize that this modulation cannot be simply explained by saccade direction selectivity, whereas ‘towards the contralateral hemifield’ cannot fulfill this purpose.</p><disp-quote content-type="editor-comment"><p>(b) &quot; Recurrent neural network modeling indicated that the feedback connections, matching the learned stimuli-response associations during the task, mediated such feedback modulation.&quot;</p><p>- should be &quot;that feedback connection .... might mediate&quot;. A model can only ever give a possible explanation.</p></disp-quote><p>Thanks for the help on the writing again! We have revised this sentence as following: “Recurrent neural network modeling indicated that the feedback connections, matching the learned stimuli-response associations during the task, might mediate such feedback modulation.”</p><disp-quote content-type="editor-comment"><p>(c) &quot;thereby increasing the consistency of flexible decisions.&quot; I am not sure what is really meant by increasing the consistency of flexible decisions? More correct or more the same?</p></disp-quote><p>We apologize for the confusion. In the manuscript, &quot;decision consistency&quot; refers to the degree of agreement in the model's decisions under specific conditions. A higher decision consistency indicates that the model is more likely to produce the same choice when encountering encounters a stimulus in that condition. We have incorporated your suggestion and revise this sentence as “thereby increasing the reliability of flexible decisions”. We also clarified the definition of consistency in the main text as follows:</p><p>“These disrupted patterns of saccade DS observed in the target module following projection-specific inactivation aligned with the decreased decision consistency of RNNs, where decision consistency reflects the degree of agreement in the model's choices under specific task conditions. This suggests a diminished reliance on sensory input and an increased dependence on internal noise in the decision-making process.”.</p><disp-quote content-type="editor-comment"><p>(5) Results: headers should be changed to reflect the actual results, not the interpretation:</p><p>&quot;Nonlinear feedback modulation of saccade choice on visual motion selectivity in LIP&quot;</p><p>&quot;Feedback modulation specifically impacted the decision-correlated activity in LIP&quot;</p><p>These first parts of the results describe neurophysiological modulations of LIP activity, the source cannot be known from the presented data alone. I thought that this feedback is suggested by the modelling results in the last part of the results. It is confusing to the reader that the titles already refer to the source of the modulation as &quot;feedback&quot;. The titles should more accurelty describe what is found, not pre-judge the interpretation.</p></disp-quote><p>We thank the reviewer for those valuable suggestions. We have updated the subtitles to: “Nonlinear modulation of saccade choice on visual motion selectivity in LIP” and “Decision-correlated but not stimulus-correlated activity was modulated in LIP.”</p><disp-quote content-type="editor-comment"><p>(6) page 8, l366-380. Can you link the statements more directly to panels in Figure 6. For Figure 6H-K, it needs to be clarified that the headers for 6D-G also apply to H-K.</p></disp-quote><p>­We have added headers for Figure 6H-K in the revised version, and revised the corresponding results section as follows.</p><p>‘We further examined how the energy landscape in the 1-D subspace changed in relation to task difficulty (motion coherence). Consistent with prior findings, trials with lower decision consistency (trials using lower motion coherence) exhibited shallower attractor basins at the time of decision for all types of RNNs (Fig. 6H-K). However, both the depth and the positional separation of attractor basins in the network dynamics significantly decreased for all non-zero motion coherence levels after the ablation of all feedback connections (comparing Figure 6I with Figure 6H; P(depth) = 5.20e-25, F = 122.80; P(position) = 1.82e-27, F = 137.75; two-way ANOVA). Notably, this reduction in basin depth and separation was more pronounced in the specific group compared to the nonspecific groups after ablating the feedback connections (comparing Figure 6J with Figure 6K; P(depth) = 2.65e-13, F = 57.35; P(position) = 3.73e-14, F = 61.79; two-way ANOVA). These results might underlie the computational mechanisms that explain the observed reduction in the decision consistency of RNNs following projection-specific inactivation: the shallower and closer attractor basins after ablating feedback connections resulted in less consistent decisions. This happened because the variability in neural activity made it more likely for population activity to stochastically shift out of the shallower basins and into nearby alternative ones.’</p><disp-quote content-type="editor-comment"><p>(7) line 556-557: Please provide a reference or data for the assertion that nearby recording sites in LIP (100 microns apart) have similar RFs.</p></disp-quote><p>The reviewer raised an interesting question that we are unable to address in depth with the current data, as we lack information on the specific cortical location for each recording session. In the original manuscript, we suggested that nearby recording sites in LIP have similar receptive fields (RFs), based on both our own experience with LIP recordings and previous studies. Specifically, we observed that neurons recorded within a single penetration using a single-channel electrode typically exhibited similar RFs. Similarly, the majority of neurons recorded from the same multichannel linear probe within a single session also showed comparable RFs. Additionally, several studies (both electrophysiological and fMRI) have reported topographic organization of RFs in LIP (Gaurav H. Patel et al., 2010; S. Ben Hamed et al., 2001; Gene J. Blatt et al., 1990).</p><disp-quote content-type="editor-comment"><p>(8) Line 568, Methods: a response criterion of a maximum firing rate of 2 spikes/s seems very low, especially for LIP. How do the results change if this lifted to something more realistic like 5 spikes/s or 10 spikes/s?</p></disp-quote><p>We chose this criterion to ensure we included as many neurons as possible in our analysis. To further clarify, we have plotted the distribution of maximum firing rates across all neurons. Based on our findings, relaxing this criterion is unlikely to affect the results, as the majority of neurons exhibit maximum firing rates well above 5 spikes/s, and many exceed 10 spikes/s. We hope this explanation addresses the concern.</p><fig id="sa2fig6" position="float"><label>Author response image 6.</label><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-96402-sa2-fig6-v1.tif"/></fig><disp-quote content-type="editor-comment"><p><bold>Reviewer #2 (Recommendations For The Authors):</bold></p><p>In this manuscript, the authors recorded activity in the posterior parietal cortex (PPC) of monkeys performing a perceptual decision-making task. The monkeys were first shown two choice dots of two different colors. Then, they saw a random dot motion stimulus. They had to learn to categorize the direction of motion as referring to either the right or left dot. However, the rule was based on the color of the dot and not its location. So, the red dot could either be to the right or left, but the rule itself remained the same. It is known from past work that PPC neurons would code the learned categorization. Here, the authors showed that the categorization signal depended on whether the executed saccade was in the same hemifield as the recorded PPC neuron or in the opposite one. That is, if a neuron categorized the two motion directions such that it responded stronger for one than the other, then this differential motion direction coding effect was amplified if the subsequent choice saccade was in the same hemifield. The authors then built a computational RNN to replicate the results and make further tests by simulated &quot;lesions&quot;.</p><p>The data are generally interesting, and the manuscript is generally well written (but see some specific comments below on where I was confused). However, I'm still not sure about the conclusions. The way the experiment is setup, the &quot;contra&quot; saccade target is essentially in the same hemifield as the motion patch stimulus. Given that the RF's can be quite large, isn't it important to try to check whether the saccade itself contributed to the effects? i.e. if the RF is on the left side, and the &quot;contra&quot; saccade is to the left, then even if it is orthogonal to the location of the stimulus motion patch itself, couldn't the saccade still be part of a residual edge of the RF? This could potentially contribute to elevating the firing rate on the preferred motion direction trials. I think it would help to align the data on saccade onset to see what happens. It would also help to have fully mapped the neurons' movement fields by asking the monkeys to generate saccades to all screen locations in the monitor. The authors mention briefly that they used a memory-guided saccade task to map RF's, but it is also important to map with a visual target. And, in any case, it would be important to show the mapping results aligned on saccade onset.</p><p>Another comment is that the authors might want to mention this other recent related paper by the Pack group: <ext-link ext-link-type="uri" xlink:href="https://www.biorxiv.org/content/10.1101/2023.08.03.551852v2.full.pdf">https://www.biorxiv.org/content/10.1101/2023.08.03.551852v2.full.pdf</ext-link></p></disp-quote><p>We thank the reviewer for the comments and realized that we did not explain our results clearly in the original manuscript. We agree with the reviewer that saccade direction selectivity might be a confounding factor for the modulation of the saccade choice direction onto LIP neurons’ activity responded to visual motion stimuli. Because the RFs of LIP neurons might be large and the saccade target might be presented within the edge of the RFs. However, we believe that the observed modulation of saccade direction on LIP neurons’ response to motion stimuli cannot be simply explained by saccade direction selectivity. We presented several pieces of evidence to rule out such possibility. First, the modulation effect we observed was not linear; specifically, the firing rate of neurons increased for the preferred motion direction but decreased for the non-preferred motion direction (Figure 2i and Figure S1A-D). This phenomenon is unlikely to be attributed to a linear gain modulation driven by saccade directions. Second, we plotted the averaged neural activity for contralateral and ipsilateral saccade directions separately, aligned the activity to either motion stimulus onset or saccade onset, and found that LIP neurons showed similar levels of activity between the contralateral and ipsilateral directions (revised Figure 2L), which is not consistent with obvious saccade direction selectivity.</p><p>To better control for this confound, we have added figures plotting the mean neural activity aligned to saccade onset for both contralateral and ipsilateral saccades, which are now included in the revised main Figure 2. These figures are presented in the detailed response below. Additionally, we have revised the corresponding results section to clarify our points, as outlined below:</p><p>“Figure 2A-2F shows three example LIP neurons that exhibited significant motion coherence correlated DS. Surprisingly, LIP neurons showed greater DS in the CT condition than in the IT condition, even though the same motion stimuli were used in the same spatial location for both conditions. The averaged population activity showed this DS difference between CT and IT conditions for all four coherence levels (Figure 2G, 2H). During presentation of their preferred motion direction, LIP neurons showed significantly elevated activity in the CT relative to the IT at all coherence levels (Figure S1A, S1B, nested ANOVA: P(high) = 0.0326, F = 4.65; P(medium) = 0.0088, 142 F = 7.03; P(low) = 0.0076, F = 7.32; P(zero) = 0.0124, F = 6.4), and a trend toward lower activity to the nonpreferred direction for CT vs. IT (Figure S1C, S1D, nested ANOVA: P(high) = 0.0994, F = 2.75; P(medium) = 0.0649, F = 3.12; P(low) = 0.0311, F = 4.73; P(zero) = 0.0273, F = 4.96). Most of the LIP neurons (48 of 83) showed such opposing trends in activity modulation between the preferred and nonpreferred directions (Figure 2I). These results indicated a nonlinear modulation of saccade choice on motion DS in LIP, aligned precisely with the response property of each neuron. This is unlikely to be driven by a linear gain modulation of saccade direction selectivity. Receiver operating characteristic (ROC) analysis further confirmed significantly greater motion DS in the CT condition than in the IT condition (Figure 2J 148 and 2K; nested ANOVA: P(high) = 5.0e-4, F = 12.44; P(medium) = 9.53e-6, F = 20.91; P(low) = 9.33e-7, F 149 = 26.03; P(zero) = 2.56e-8, F = 34.3). Such DS differences were observed even before stimulus onset. Moreover, LIP neurons exhibited similar levels of mean activity between different saccade directions (CT vs. IT) before monkeys’ saccade choice (Figure 2L), further supporting that saccade direction selectivity did not significantly contribute to the observed modulation of LIP neurons’ responses to motion stimuli.</p><p>We also thank the reviewer for pointing out the missing of this relevant study, we have added the suggested refence in the revised discussion section as follows:</p><p>‘A recent study demonstrated that neurons in the middle temporal area responded more strongly to motion stimuli when monkeys saccaded toward their RFs in a standard decision task with a fixed mapping between motion stimuli and saccade directions. This modulation emerged through the training process and contributed causally to the monkeys' following saccade choices. Consistently, we found that the response of LIP neurons to motion stimuli was more strongly correlated with the monkeys' decisions in the CT condition (saccades toward RFs) than in the IT condition, in a more flexible decision task. Together, these results suggest that the modulation of action selection on sensory processing may be a general process in perceptual decision-making. However, the observed modulation of saccade direction on LIP neurons' responses to motion stimuli cannot be simply explained by saccade direction selectivity. Several lines of evidence argue against this possibility. First, the modulation effect was nonlinear; specifically, neuronal firing rates increased for preferred motion directions but decreased for non-preferred directions (Figure 2I and Figure S1). This pattern is unlikely to be driven by a linear gain modulation based on saccade directions. Second, we found that LIP neurons exhibited similar levels of activity in both the CT and IT conditions (Figure 2L), which is inconsistent with the presence of clear saccade direction selectivity.</p><disp-quote content-type="editor-comment"><p>Some more specific comments are below:</p><p>- I had a bit of a hard time with the abstract. It does not appear to be crystal clear to me, and it is the first thing that I am reading after the title. For example, if there is a claim about both perceptual decision-making and later target selection, then I feel that the task should be explained a bit more clearly than saying &quot;flexible decision&quot; task. Also, &quot;..modulated by monkeys' following saccade choices directing outside each neuron's response field&quot; was hard to read. It needs to be rewritten. Maybe just say &quot;...modulated by the subsequent eye movement choices, even when these eye movement choices always directed the eyes away from the recorded neuron's response field&quot;. Also, I don't fully understand what &quot;selectivity-specific feedback&quot; means. Then, the concept of &quot;consistency&quot; in flexible decisions is brought up, again without much context. The above are examples of why I had a hard time with the abstract.</p></disp-quote><p>We realize that our original statement may have been unclear and potentially caused confusion for the readers. Following the reviewer’s suggestions, we have revised the abstract as follows:</p><p>‘Neural activity in the primate brain correlates with both sensory evaluation and action selection aspects of decision-making. However, the intricate interaction between these distinct neural processes and their impact on decision behaviors remains unexplored. Here, we examined the interplay of these decision processes in posterior parietal cortex (PPC) when monkeys performed a flexible decision task, in which they chose between two color targets based on a visual motion stimulus. We found that the PPC activity related to monkeys’ abstract decisions about visual stimuli was nonlinearly modulated by their subsequent saccade choices, which were directed outside each neuron’s response field. Recurrent neural network modeling indicated that the feedback connections, matching the learned stimuli-response associations during the task, might mediate such feedback modulation. Further analysis on network dynamics revealed that selectivity-specific feedback connectivity intensified the attractor basins of population activity underlying saccade choices, thereby increasing the reliability of flexible decisions. These results highlight an iterative computation between different decision processes, mediated primarily by precise feedback connectivity, contributing to the optimization of flexible decision-making.’</p><p>Specifically, selectivity-specific feedback refers to the feedback connections with positive or negative weights between selectivity-matched and selectivity-nonmatched unit pairs, respectively.</p><p>Regarding &quot;decision consistency,&quot; we define it as the degree to which the model’s decisions remain congruent under specific conditions. A higher level of decision consistency indicates that the model is more likely to produce the same choice each time it is presented with a stimulus under those conditions, in another words, decision reliability. We have revised the corresponding results section to make these concepts clearer.</p><disp-quote content-type="editor-comment"><p>- Line 69: I'm not fully sure, but I think that some people might suggest that superior colliculus is also involved in the sensory aspect of the evaluation. But, I guess the sentence itself is correct as you write it. So, I don't think anyone should argue with it. However, if someone does argue with it, then they would flag the next sentence, since if the colliculus does both, then do the sensory and motor parts really employ distinct neural processes? Anyway, I think this is very minor.</p></disp-quote><p>This is an interesting point. We have also noticed a recent study that demonstrates that the superior colliculus is causally involved in the sensory aspect of decision-making, specifically in visual categorization. However, the study also distinguishes between neural activity related to categorical decisions and that related to saccade planning. This suggests that the sensory and motor aspects of decision-making likely involve distinct neural processing, even within the same brain region—potentially reflecting separate populations of neurons. Therefore, we stand by our statement in the ‘next sentence’.</p><disp-quote content-type="editor-comment"><p>- Line 79-80: you might want to look at this work because I feel that it is relevant to cite here: <ext-link ext-link-type="uri" xlink:href="https://www.biorxiv.org/content/10.1101/2023.08.03.551852v2">https://www.biorxiv.org/content/10.1101/2023.08.03.551852v2</ext-link></p></disp-quote><p>We have discussed this reference in the revised discussion section of the manuscript, please refer to the above response.</p><disp-quote content-type="editor-comment"><p>- For a result like that shown in Fig. 2, I feel that it is important to show RF mapping with a saccade task alone. i.e. for the same neurons, have a monkey make a delayed visually guided saccade task to all possible locations on the display, and demonstrate that there is no modulation by saccades to the targets. Otherwise, the result in Fig. 2 could reflect first an onset response by a motion, and then the saccade-related response that would happen anyway, even without the decision task. So, I feel that now, it is not entirely clear whether the result reflects this so-called feedback modulation, or whether simply planning the saccade to the target itself activates the neurons. With large RF's, this is a distinct possibility in my opinion.</p><p>- Line 174: this would also be predicted if the neuron's were responding based on the saccade target plan independent of the motion stimulus</p><p>- On a related note, I would recommend plotting all data also aligned on saccade onset. This can help establish what the cause of the effects described is</p></disp-quote><p>We understand the reviewer’s concern that the modulation might be related to saccade planning, and we acknowledge that the original manuscript might not adequately address this potential confound. Unfortunately, we did not map the LIP neurons' receptive fields (RFs) using a saccade-only task. However, as mentioned earlier, we believe that the modulation of LIP neurons' responses to motion stimuli based on saccade choice direction cannot be simply attributed to saccade direction selectivity. Several lines of evidence support this conclusion. First, the modulation we observed was nonlinear: the firing rate of neurons increased for the preferred motion direction but decreased for the non-preferred motion direction (Figure 2i and Figure S1A-D). This pattern is inconsistent with a simple linear gain modulation driven by saccade direction selectivity. Second, we directly compared LIP neuronal activity for contralateral and ipsilateral target conditions, and found no significant differences between the two. This suggests that saccade direction selectivity is unlikely to be the primary contributor to the observed modulation. In the revised figure, we added a plot (Figure 2L) that aligns neural activity to saccade onset, in addition to the original alignment to motion stimulus onset (Figure S1E). This new analysis further supports our interpretation.</p><fig id="sa2fig7" position="float"><label>Author response image 7.</label><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-96402-sa2-fig7-v1.tif"/></fig><disp-quote content-type="editor-comment"><p>- Even when reading the simulation results, I'm still not 100% sure I understand what is meant by this idea of &quot;consistency&quot; of flexible decision-making</p></disp-quote><p>We have addressed this issue in a previous comment and please refer to the response above.</p></body></sub-article></article>