<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD with MathML3 v1.3 20210610//EN"  "JATS-archivearticle1-3-mathml3.dtd"><article xmlns:ali="http://www.niso.org/schemas/ali/1.0/" xmlns:xlink="http://www.w3.org/1999/xlink" article-type="research-article" dtd-version="1.3"><front><journal-meta><journal-id journal-id-type="nlm-ta">elife</journal-id><journal-id journal-id-type="publisher-id">eLife</journal-id><journal-title-group><journal-title>eLife</journal-title></journal-title-group><issn publication-format="electronic" pub-type="epub">2050-084X</issn><publisher><publisher-name>eLife Sciences Publications, Ltd</publisher-name></publisher></journal-meta><article-meta><article-id pub-id-type="publisher-id">94902</article-id><article-id pub-id-type="doi">10.7554/eLife.94902</article-id><article-id pub-id-type="doi" specific-use="version">10.7554/eLife.94902.3</article-id><article-version article-version-type="publication-state">version of record</article-version><article-categories><subj-group subj-group-type="display-channel"><subject>Research Article</subject></subj-group><subj-group subj-group-type="heading"><subject>Neuroscience</subject></subj-group></article-categories><title-group><article-title>A double dissociation between semantic and spatial cognition in visual to default network pathways</article-title></title-group><contrib-group><contrib contrib-type="author" corresp="yes"><name><surname>Gonzalez Alam</surname><given-names>Tirso RJ</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">https://orcid.org/0000-0003-4510-2441</contrib-id><email>t.gonzalezalam@bangor.ac.uk</email><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="aff" rid="aff2">2</xref><xref ref-type="aff" rid="aff3">3</xref><xref ref-type="fn" rid="con1"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author"><name><surname>Krieger-Redwood</surname><given-names>Katya</given-names></name><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="aff" rid="aff2">2</xref><xref ref-type="fn" rid="con2"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author"><name><surname>Varga</surname><given-names>Dominika</given-names></name><xref ref-type="aff" rid="aff4">4</xref><xref ref-type="fn" rid="con3"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author"><name><surname>Gao</surname><given-names>Zhiyao</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">https://orcid.org/0000-0002-8909-8096</contrib-id><xref ref-type="aff" rid="aff5">5</xref><xref ref-type="fn" rid="con4"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author"><name><surname>Horner</surname><given-names>Aidan J</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">https://orcid.org/0000-0003-0882-9756</contrib-id><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="aff" rid="aff2">2</xref><xref ref-type="fn" rid="con5"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author"><name><surname>Hartley</surname><given-names>Tom</given-names></name><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="aff" rid="aff2">2</xref><xref ref-type="fn" rid="con6"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author"><name><surname>Thiebaut de Schotten</surname><given-names>Michel</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">https://orcid.org/0000-0002-0329-1814</contrib-id><xref ref-type="aff" rid="aff6">6</xref><xref ref-type="aff" rid="aff7">7</xref><xref ref-type="other" rid="fund2"/><xref ref-type="fn" rid="con7"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author"><name><surname>Sliwinska</surname><given-names>Magdalena</given-names></name><xref ref-type="aff" rid="aff8">8</xref><xref ref-type="fn" rid="con8"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author"><name><surname>Pitcher</surname><given-names>David</given-names></name><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="aff" rid="aff2">2</xref><xref ref-type="fn" rid="con9"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author"><name><surname>Margulies</surname><given-names>Daniel S</given-names></name><xref ref-type="aff" rid="aff9">9</xref><xref ref-type="other" rid="fund3"/><xref ref-type="fn" rid="con10"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author"><name><surname>Smallwood</surname><given-names>Jonathan</given-names></name><xref ref-type="aff" rid="aff10">10</xref><xref ref-type="fn" rid="con11"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author"><name><surname>Jefferies</surname><given-names>Elizabeth</given-names></name><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="aff" rid="aff2">2</xref><xref ref-type="other" rid="fund1"/><xref ref-type="fn" rid="con12"/><xref ref-type="fn" rid="conf1"/></contrib><aff id="aff1"><label>1</label><institution-wrap><institution-id institution-id-type="ror">https://ror.org/04m01e293</institution-id><institution>Department of Psychology, University of York</institution></institution-wrap><addr-line><named-content content-type="city">North Yorkshire</named-content></addr-line><country>United Kingdom</country></aff><aff id="aff2"><label>2</label><institution-wrap><institution-id institution-id-type="ror">https://ror.org/04m01e293</institution-id><institution>York Neuroimaging Centre, Innovation Way, Heslington</institution></institution-wrap><addr-line><named-content content-type="city">North Yorkshire</named-content></addr-line><country>United Kingdom</country></aff><aff id="aff3"><label>3</label><institution-wrap><institution-id institution-id-type="ror">https://ror.org/006jb1a24</institution-id><institution>School of Human and Behavioural Sciences, Bangor University, Gwynedd, Wales, UK</institution></institution-wrap><addr-line><named-content content-type="city">York</named-content></addr-line><country>United Kingdom</country></aff><aff id="aff4"><label>4</label><institution>Sussex Neuroscience, School of Psychology, University of Sussex</institution><addr-line><named-content content-type="city">Brighton and Hove</named-content></addr-line><country>United States</country></aff><aff id="aff5"><label>5</label><institution>Department of Psychiatry and Behavioral Sciences, Stanford University School of Medicine Stanford</institution><addr-line><named-content content-type="city">Stanford</named-content></addr-line><country>United Kingdom</country></aff><aff id="aff6"><label>6</label><institution-wrap><institution-id institution-id-type="ror">https://ror.org/057qpr032</institution-id><institution>University of Bordeaux, CNRS, CEA, IMN</institution></institution-wrap><addr-line><named-content content-type="city">Bordeaux</named-content></addr-line><country>France</country></aff><aff id="aff7"><label>7</label><institution-wrap><institution-id institution-id-type="ror">https://ror.org/02en5vm52</institution-id><institution>Brain Connectivity and Behaviour Laboratory, Sorbonne Universities</institution></institution-wrap><addr-line><named-content content-type="city">Paris</named-content></addr-line><country>France</country></aff><aff id="aff8"><label>8</label><institution-wrap><institution-id institution-id-type="ror">https://ror.org/04zfme737</institution-id><institution>Department of Psychology, Liverpool John Moores University</institution></institution-wrap><addr-line><named-content content-type="city">Liverpool</named-content></addr-line><country>United Kingdom</country></aff><aff id="aff9"><label>9</label><institution-wrap><institution-id institution-id-type="ror">https://ror.org/02fgakj19</institution-id><institution>Integrative Neuroscience and Cognition Center (UMR 8002), Centre National de la Recherche Scientifique (CNRS) and Université de Paris</institution></institution-wrap><addr-line><named-content content-type="city">Paris</named-content></addr-line><country>France</country></aff><aff id="aff10"><label>10</label><institution-wrap><institution-id institution-id-type="ror">https://ror.org/02y72wh86</institution-id><institution>Department of Psychology, Queen’s University, Kingston</institution></institution-wrap><addr-line><named-content content-type="city">Kingston</named-content></addr-line><country>Canada</country></aff></contrib-group><contrib-group content-type="section"><contrib contrib-type="editor"><name><surname>Peelle</surname><given-names>Jonathan Erik</given-names></name><role>Reviewing Editor</role><aff><institution-wrap><institution-id institution-id-type="ror">https://ror.org/04t5xt781</institution-id><institution>Northeastern University</institution></institution-wrap><country>United States</country></aff></contrib><contrib contrib-type="senior_editor"><name><surname>Bi</surname><given-names>Yanchao</given-names></name><role>Senior Editor</role><aff><institution-wrap><institution-id institution-id-type="ror">https://ror.org/022k4wk35</institution-id><institution>Beijing Normal University</institution></institution-wrap><country>China</country></aff></contrib></contrib-group><pub-date publication-format="electronic" date-type="publication"><day>22</day><month>01</month><year>2025</year></pub-date><volume>13</volume><elocation-id>RP94902</elocation-id><history><date date-type="sent-for-review" iso-8601-date="2024-01-11"><day>11</day><month>01</month><year>2024</year></date></history><pub-history><event><event-desc>This manuscript was published as a preprint.</event-desc><date date-type="preprint" iso-8601-date="2023-11-28"><day>28</day><month>11</month><year>2023</year></date><self-uri content-type="preprint" xlink:href="https://doi.org/10.1101/2023.11.28.568861"/></event><event><event-desc>This manuscript was published as a reviewed preprint.</event-desc><date date-type="reviewed-preprint" iso-8601-date="2024-05-17"><day>17</day><month>05</month><year>2024</year></date><self-uri content-type="reviewed-preprint" xlink:href="https://doi.org/10.7554/eLife.94902.1"/></event><event><event-desc>The reviewed preprint was revised.</event-desc><date date-type="reviewed-preprint" iso-8601-date="2024-09-12"><day>12</day><month>09</month><year>2024</year></date><self-uri content-type="reviewed-preprint" xlink:href="https://doi.org/10.7554/eLife.94902.2"/></event></pub-history><permissions><copyright-statement>© 2024, Gonzalez Alam et al</copyright-statement><copyright-year>2024</copyright-year><copyright-holder>Gonzalez Alam et al</copyright-holder><ali:free_to_read/><license xlink:href="http://creativecommons.org/licenses/by/4.0/"><ali:license_ref>http://creativecommons.org/licenses/by/4.0/</ali:license_ref><license-p>This article is distributed under the terms of the <ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/licenses/by/4.0/">Creative Commons Attribution License</ext-link>, which permits unrestricted use and redistribution provided that the original author and source are credited.</license-p></license></permissions><self-uri content-type="pdf" xlink:href="elife-94902-v1.pdf"/><self-uri content-type="figures-pdf" xlink:href="elife-94902-figures-v1.pdf"/><abstract><p>Processing pathways between sensory and default mode network (DMN) regions support recognition, navigation, and memory but their organisation is not well understood. We show that functional subdivisions of visual cortex and DMN sit at opposing ends of parallel streams of information processing that support visually mediated semantic and spatial cognition, providing convergent evidence from univariate and multivariate task responses, intrinsic functional and structural connectivity. Participants learned virtual environments consisting of buildings populated with objects, drawn from either a single semantic category or multiple categories. Later, they made semantic and spatial context decisions about these objects and buildings during functional magnetic resonance imaging. A lateral ventral occipital to fronto-temporal DMN pathway was primarily engaged by semantic judgements, while a medial visual to medial temporal DMN pathway supported spatial context judgements. These pathways had distinctive locations in functional connectivity space: the semantic pathway was both further from unimodal systems and more balanced between visual and auditory-motor regions compared with the spatial pathway. When semantic and spatial context information could be integrated (in buildings containing objects from a single category), regions at the intersection of these pathways responded, suggesting that parallel processing streams interact at multiple levels of the cortical hierarchy to produce coherent memory-guided cognition.</p></abstract><kwd-group kwd-group-type="author-keywords"><kwd>default mode network</kwd><kwd>fMRI</kwd><kwd>networks</kwd><kwd>vision</kwd><kwd>semantic</kwd><kwd>DMN</kwd></kwd-group><kwd-group kwd-group-type="research-organism"><title>Research organism</title><kwd>Human</kwd></kwd-group><funding-group><award-group id="fund1"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/501100000781</institution-id><institution>European Research Council</institution></institution-wrap></funding-source><award-id>Project ID: 771863 - FLEXSEM</award-id><principal-award-recipient><name><surname>Jefferies</surname><given-names>Elizabeth</given-names></name></principal-award-recipient></award-group><award-group id="fund2"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/501100000781</institution-id><institution>European Research Council</institution></institution-wrap></funding-source><award-id>Project ID: 818521 - DISCONNECTOME</award-id><principal-award-recipient><name><surname>Thiebaut de Schotten</surname><given-names>Michel</given-names></name></principal-award-recipient></award-group><award-group id="fund3"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/501100000781</institution-id><institution>European Research Council</institution></institution-wrap></funding-source><award-id>Project ID: 866533</award-id><principal-award-recipient><name><surname>Margulies</surname><given-names>Daniel S</given-names></name></principal-award-recipient></award-group><funding-statement>The funders had no role in study design, data collection and interpretation, or the decision to submit the work for publication.</funding-statement></funding-group><custom-meta-group><custom-meta specific-use="meta-only"><meta-name>Author impact statement</meta-name><meta-value>Default mode network and visual cortex are connected via two parallel pathways that differentially respond to the processing of visual scenes and semantic information about objects, reflecting domain-specific organisation.</meta-value></custom-meta><custom-meta specific-use="meta-only"><meta-name>publishing-route</meta-name><meta-value>prc</meta-value></custom-meta></custom-meta-group></article-meta></front><body><sec id="s1" sec-type="intro"><title>Introduction</title><p>The default mode network (DMN) is involved in higher-order cognition including in semantic cognition, mental time travel, and scene construction (<xref ref-type="bibr" rid="bib6">Andrews-Hanna et al., 2010b</xref>; <xref ref-type="bibr" rid="bib5">Andrews-Hanna et al., 2010a</xref>; <xref ref-type="bibr" rid="bib78">Ralph et al., 2017</xref>; <xref ref-type="bibr" rid="bib91">Spreng et al., 2009</xref>). Its functions and architecture are plagued by apparent contradictions: it often deactivates in response to visual inputs yet it is connected to visual cortex (<xref ref-type="bibr" rid="bib47">Knapen, 2021</xref>; <xref ref-type="bibr" rid="bib53">Leech et al., 2012</xref>; <xref ref-type="bibr" rid="bib96">Szinte and Knapen, 2020</xref>). In addition, this network is associated with both abstraction from sensory-motor features (; <xref ref-type="bibr" rid="bib17">Chiou et al., 2019</xref>; <xref ref-type="bibr" rid="bib35">Gonzalez Alam et al., 2021</xref>; <xref ref-type="bibr" rid="bib82">Rice et al., 2015b</xref>; <xref ref-type="bibr" rid="bib81">Rice et al., 2015a</xref>) and internally generated states like imagery and autobiographical memory (<xref ref-type="bibr" rid="bib72">Philippi et al., 2015</xref>; <xref ref-type="bibr" rid="bib83">Ritchey and Cooper, 2020</xref>; <xref ref-type="bibr" rid="bib92">Spreng and Grady, 2010</xref>; <xref ref-type="bibr" rid="bib122">Zhang et al., 2022</xref>). A recent perspective suggests these diverse functions are facilitated by the topographical location of DMN on the cortical mantle (<xref ref-type="bibr" rid="bib88">Smallwood et al., 2021</xref>). DMN is maximally separated from sensory-motor regions – both in terms of its physical location and in connectivity space. It is at one end of the principal gradient of intrinsic connectivity that captures the separation of unimodal and heteromodal cortex (<xref ref-type="bibr" rid="bib61">Margulies et al., 2016</xref>) and this location is thought to allow DMN to sustain representations that are distinct from sensory-motor features and at odds with the current state of the external world (<xref ref-type="bibr" rid="bib68">Murphy et al., 2019</xref>; <xref ref-type="bibr" rid="bib67">Murphy et al., 2018</xref>).</p><p>Despite these common functional characteristics of DMN, parcellations of intrinsic connectivity reveal subdivisions (<xref ref-type="bibr" rid="bib6">Andrews-Hanna et al., 2010b</xref>; <xref ref-type="bibr" rid="bib85">Schaefer et al., 2018</xref>; <xref ref-type="bibr" rid="bib109">Wen et al., 2020</xref>; <xref ref-type="bibr" rid="bib120">Yeo et al., 2011</xref>). Lateral fronto-temporal (FT) DMN regions are associated with semantic cognition, including the abstraction of heteromodal meanings from sensory-motor features and the ability to access these meanings from sensory inputs in a task-appropriate way (; <xref ref-type="bibr" rid="bib17">Chiou et al., 2019</xref>; <xref ref-type="bibr" rid="bib78">Ralph et al., 2017</xref>; <xref ref-type="bibr" rid="bib107">Wang et al., 2020</xref>). In contrast, scene construction, thought to be a key component of episodic recollection, is associated with a medial temporal (MT) subsystem (<xref ref-type="bibr" rid="bib6">Andrews-Hanna et al., 2010b</xref>; <xref ref-type="bibr" rid="bib19">D’Argembeau et al., 2010</xref>; <xref ref-type="bibr" rid="bib40">Hassabis et al., 2007</xref>; <xref ref-type="bibr" rid="bib122">Zhang et al., 2022</xref>). FT and MT-DMN subnetworks are interdigitated in regions of core DMN (<xref ref-type="bibr" rid="bib13">Braga and Buckner, 2017</xref>) and they are assumed to work together but little is known about how information within them is integrated. One hypothesis is that the spatial adjacency of DMN subsystems allows their common recruitment and coordination when semantic and scene-based information is aligned; e.g., when semantically similar objects are found in a common location, or spatial position predicts the meanings of items that are found there.</p><p>FT and MT-DMN support heteromodal representations and yet can be accessed by visual inputs, raising the question of how neural pathways between vision and DMN are organised. Visual neuroscience has revealed different responses associated with recognising objects and scenes (<xref ref-type="bibr" rid="bib49">Kravitz et al., 2013</xref>; <xref ref-type="bibr" rid="bib48">Kravitz et al., 2011</xref>). Objects engage a ventral pathway extending laterally and anteriorly through ventral lateral occipital cortex (LOC) and the fusiform gyrus towards the anterior temporal lobes (ATL), thought to be a key heteromodal hub for conceptual representation. This pathway might act as input to FT-DMN (<xref ref-type="bibr" rid="bib7">Andrews-Hanna et al., 2014</xref>; <xref ref-type="bibr" rid="bib8">Andrews-Hanna and Grilli, 2021</xref>; <xref ref-type="bibr" rid="bib23">DiCarlo et al., 2012</xref>; <xref ref-type="bibr" rid="bib49">Kravitz et al., 2013</xref>; <xref ref-type="bibr" rid="bib58">Malach et al., 2002</xref>). Navigating visuospatial environments and scene construction, on the other hand, involves the occipital place area, posterior cingulate, retrosplenial, entorhinal, and parahippocampal cortex, before this pathway terminates in hippocampus. These regions are associated with the MT-DMN subnetwork (<xref ref-type="bibr" rid="bib7">Andrews-Hanna et al., 2014</xref>; <xref ref-type="bibr" rid="bib8">Andrews-Hanna and Grilli, 2021</xref>; <xref ref-type="bibr" rid="bib29">Epstein and Baker, 2019</xref>; <xref ref-type="bibr" rid="bib48">Kravitz et al., 2011</xref>; <xref ref-type="bibr" rid="bib80">Reagh and Yassa, 2014</xref>). This work suggests that visual and DMN subsystems may be linked. For example, during memory for people and places, medial parietal cortex mirrors the well-established medial-lateral organisation of ventral temporal cortex during the perception of scenes and faces; medial parietal regions also show differential connectivity to these visual regions (<xref ref-type="bibr" rid="bib60">Margulies et al., 2009</xref>; <xref ref-type="bibr" rid="bib87">Silson et al., 2019</xref>; <xref ref-type="bibr" rid="bib93">Steel et al., 2021</xref>). Yet these past studies did not examine whole-brain connectivity or semantic cognition beyond the social domain and were also unable to explore the interaction of these pathways.</p><p>Here, we used multiple neuroscientific methods to delineate the pathways from visual cortex to DMN, providing convergent evidence for two parallel streams supporting semantic and spatial cognition. In Study 1, participants learned about virtual environments (buildings) populated with objects belonging to diverse semantic categories, both man-made (tools, musical instruments, sports equipment) and natural (land animals, marine animals, birds). We then used functional MRI (fMRI) to examine neural activity as participants viewed object and scene probes and made semantic and spatial context decisions. Some buildings were associated with a specific semantic category (e.g. a building filled with musical instruments), while others included a mix of categories, allowing us to examine the interaction between semantic and spatial cognition. We identified dissociable pathways of connectivity between different parts of visual cortex and DMN subsystems; these overlapped with visual localiser responses for objects and scenes (in Study 2), as well as previously described DMN subsystems, and showed different patterns of functional and structural connectivity (in Study 3). These pathways refer to regions that are coupled, functionally or structurally, together, providing the potential for communication between them. They also had distinctive locations in a functional space defined using whole-brain gradients of connectivity: the semantic pathway was further from unimodal systems and more balanced between visual and auditory-motor regions compared with the spatial pathway. Moreover, when semantic and spatial context information could be combined (e.g. when the objects in a building were from the same semantic category), regions at the intersection of these pathways responded, in both DMN and visual cortex, suggesting these parallel processing streams can interact at multiple levels of the cortical hierarchy to produce coherent memory-guided cognition.</p></sec><sec id="s2" sec-type="results"><title>Results</title><sec id="s2-1"><title>Behavioural results</title><p>To examine task accuracy, we performed a 2×2 repeated-measures ANOVA using task (2 levels: semantic, spatial context) and condition (2 levels: mixed-category building [MCB], and same-category building [SCB]) as factors. There was a main effect of task (F(1,26)=76.52, p&lt;0.001), condition (F(1,26)=11.31, p=0.002) and a task by condition interaction (F(1,26)=14.51, p&lt;0.001). Participants showed poorer accuracy in the spatial context task relative to the semantic task and in the MCB relative to the SCB condition. Participants were significantly less accurate in the MCB trials relative to the SCB trials of the spatial context task (t(26)=4.08, p&lt;0.001); this difference was not observed in the semantic task (t(26)=0.74, p=0.47).</p><p>Response times showed the same pattern, with main effects of task (F(1,26)=51.37, p&lt;0.001), condition (F(1,26)=31.14, p&lt;0.001), and their interaction (F(1,26)=29.48, p&lt;0.001). Participants had slower reaction times in the spatial context task than the semantic task and in the MCB relative to the SCB condition. Post hoc comparisons confirmed that participants were significantly slower in MCB than SCB trials of the spatial context task (t(26)=6.08, p&lt;0.001), but this difference was not observed in the semantic task (t(26)=0.1, p=0.92). These results are shown in <xref ref-type="fig" rid="fig1">Figure 1</xref>.</p><fig id="fig1" position="float"><label>Figure 1.</label><caption><title>Behavioural results for the semantic and spatial context tasks inside the scanner.</title><p>SCB = same-category buildings: all the items in the building were taken from the same semantic category. MCB = mixed-category buildings: the items in the buildings were drawn from different semantic categories.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-94902-fig1-v1.tif"/></fig></sec><sec id="s2-2"><title>Neuroimaging results</title><p>To probe the organisation of streams of information between visual cortex and DMN, our neuroimaging analysis strategy consisted of a combination of task-based and connectivity approaches. We first delineated the regions in visual cortex that are engaged by the viewing of probes during our task (<xref ref-type="fig" rid="fig2">Figure 2</xref>), as well as the DMN regions that respond when making decisions about those probes (<xref ref-type="fig" rid="fig3">Figure 3</xref>): we characterised both by comparing the activation maps with well-established DMN and object/scene perception regions, analysed the pattern of activation within them, their functional connectivity and task associations. Having characterised these dissociable visual and DMN regions, we proceeded to ask whether they are differentially linked: are the visual regions activated by object probe perception more strongly linked to DMN regions that are activated when making semantic decisions about object probes, relative to other DMN regions? Is the same true for visual regions associated with scene perception and DMN regions responding to spatial decisions about which rooms were in the same building? We answered this question through a series of connectivity analyses (<xref ref-type="fig" rid="fig4">Figure 4</xref>) that examined: (1) if the functional connectivity of visual-to-DMN regions (and DMN-to-visual regions) shows a dissociation, suggesting there are object semantic and spatial cognition processing ‘pathways’; (2) if this pattern was replicated in structural connectivity; (3) if it was present at the level of individual participants, and (4) we characterised the spatial layout, network composition (using influential RS networks), and cognitive decoding of these pathways. Having found dissociable pathways for semantic (object) and spatial context (scene) processing, we then examined their position in a high-dimensional connectivity space (<xref ref-type="fig" rid="fig5">Figure 5</xref>) that allowed us to document that the semantic pathway is less reliant on unimodal regions (i.e. more abstract) while the spatial context pathway is more allied to the visual system. Finally, we used uni- and multivariate approaches to examine how integration between these pathways takes place when semantic and spatial information is aligned (<xref ref-type="fig" rid="fig6">Figure 6</xref>).</p><fig-group><fig id="fig2" position="float"><label>Figure 2.</label><caption><title>Probe responses.</title><p>Warm colours = semantic &gt; spatial context probes. Cool colours = spatial context &gt; semantic probes. Left panel: Univariate results from Study 1, contrasting semantic and spatial context probes. Right panel: Intrinsic connectivity results from Study 3 using semantic and spatial context probe activation within visual networks as seeds. (<bold>a</bold>) Brain maps depicting the suprathreshold univariate activation results for the probe phase of the semantic and spatial context tasks. (<bold>b and c</bold>) Axial slices showing the overlap of these univariate results with scene and object localiser maps from Study 2 (the localiser maps are in green, and the univariate results maps are in warm and cool colours; the localiser maps are shown in <xref ref-type="fig" rid="fig2s1">Figure 2—figure supplement 1</xref>). (<bold>d</bold>) Region of interest (ROI) analysis examining the activation in the three default mode subnetworks of the Yeo 17 parcellation during the probe phase of the semantic and spatial context tasks. The error bars in the bar plots depict the standard error of the mean (Note: ***p&lt;0.001); the ROIs are shown to the right of the bar plots. (<bold>e</bold>) Brain maps depicting the seeds and intrinsic connectivity results for the semantic and spatial context probe regions. (<bold>f</bold>) Word clouds depicting the cognitive decoding of unthresholded connectivity maps for semantic and spatial context probe seeds using Neurosynth (bigger words reflect stronger correlation of the functional maps with the terms); the colour code follows that of the brain maps. (<bold>g</bold>) Brain maps showing the overlap of these intrinsic connectivity maps for semantic and spatial context probes with the default mode network from the 7-network parcellation from <xref ref-type="bibr" rid="bib120">Yeo et al., 2011</xref>.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-94902-fig2-v1.tif"/></fig><fig id="fig2s1" position="float" specific-use="child-fig"><label>Figure 2—figure supplement 1.</label><caption><title>Left panel: Areas associated with the passive viewing of objects are shown in red, and those associated with the passive viewing of scenes are shown in blue; areas that responded to both objects and scenes are shown in purple.</title><p>Right panel: The results of the localiser shown in the left panel were further constrained to contain only voxels that overlapped with the visual networks in Yeo’s 17-network parcellation. Common voxels (the ones that responded to both objects and scenes) have been removed.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-94902-fig2-figsupp1-v1.tif"/></fig></fig-group><fig id="fig3" position="float"><label>Figure 3.</label><caption><title>Decision responses.</title><p>Warm colours = semantic &gt; spatial context decisions. Cool colours = spatial context &gt; semantic decisions. Left panel: Univariate results from Study 1 contrasting semantic and spatial context decisions. Right panel: Intrinsic connectivity results from Study 3 using semantic and spatial context decision activation within default mode network (DMN) as seeds. (<bold>a</bold>) Brain maps depicting the suprathreshold univariate activation results for the decision phase of the semantic and spatial context tasks. (<bold>b and c</bold>) Axial slices showing the overlap of these univariate results with the fronto-temporal (FT) and medial temporal (MT) default mode subnetworks of the Yeo’s 17-network parcellation (the default mode maps are in green, and the univariate results maps are in warm and cool colours). (<bold>d</bold>) Region of interest (ROI) analysis examining the activation in the scene and object localiser maps from Study 2 during the decision phase of the semantic and spatial context tasks. The error bars in the bar plots depict the standard error of the mean (Note: ***p&lt;0.001, *p&lt;0.05); the ROIs are shown in <xref ref-type="fig" rid="fig2s1">Figure 2—figure supplement 1</xref>. (<bold>e</bold>) Brain maps depicting the seeds and intrinsic connectivity results for the semantic and spatial context decision regions. (<bold>f</bold>) Word clouds depicting the cognitive decoding of unthresholded connectivity maps for semantic and spatial context decision seeds using Neurosynth (bigger words reflect stronger correlation of the functional maps with the terms); the colour code follows that of the brain maps. (<bold>g</bold>) Brain maps showing the overlap of these intrinsic connectivity maps with the visual network from the 7-network parcellation from <xref ref-type="bibr" rid="bib120">Yeo et al., 2011</xref>.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-94902-fig3-v1.tif"/></fig><fig-group><fig id="fig4" position="float"><label>Figure 4.</label><caption><title>Visual to Default Network Pathways.</title><p>(<bold>a–c</bold>) These panels depict the seeds, regions of interest (ROIs), and their connectivity. The bar plots in (<bold>b and c</bold>) show the connectivity between default mode network (DMN) decision regions and probe visual regions. (d) Warm colours = common regions showing stronger intrinsic connectivity to semantic decision regions in DMN and semantic probe regions in visual cortex; cool colours = common regions showing stronger intrinsic connectivity to spatial context decision regions in DMN and spatial context probe regions in visual cortex. (<bold>e</bold>) The cognitive decoding of these spatial maps using Neurosynth following the same colour code as (<bold>d</bold>). (<bold>f</bold>) Network composition showing the percentage of each pathway map overlapping with the three DMN and two visual subnetworks defined by the <xref ref-type="bibr" rid="bib120">Yeo et al., 2011</xref>, 17-network parcellation. (<bold>g</bold>) Results of spatial correlation analysis comparing the semantic and spatial context pathways with non-pathway maps (derived from the conjunction of the connectivity of probe and decision seeds across different tasks, e.g., probe spatial context ∩ decision semantic connectivity). We assessed the spatial similarity of these pathway and non-pathway maps to the univariate activation during the probe and decision phases for each task and each participant. (<bold>h</bold>) Results of the structural connectivity analysis. Tracts displayed are a conjunction of streamlines between the probe and decision seeds of each task. The y axis of the bar plots shows the percentage of streamlines from each visual seed that terminate in each DMN ROI (shown in the x axis). The error bars depict the standard error of the mean. ***p&lt;0.001, *p&lt;0.05.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-94902-fig4-v1.tif"/></fig><fig id="fig4s1" position="float" specific-use="child-fig"><label>Figure 4—figure supplement 1.</label><caption><title>Results of the re-analysis of intrinsic connectivity between semantic and context visual probe and default mode network (DMN) decision regions.</title></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-94902-fig4-figsupp1-v1.tif"/></fig><fig id="fig4s2" position="float" specific-use="child-fig"><label>Figure 4—figure supplement 2.</label><caption><title>Connectivity of the default mode network (DMN) decision regions to the object/scene localiser from Study 2, and that of the visual probe regions to fronto-temporal (FT), medial temporal (MT), and core DMN of Yeo’s 17-network parcellation.</title></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-94902-fig4-figsupp2-v1.tif"/></fig><fig id="fig4s3" position="float" specific-use="child-fig"><label>Figure 4—figure supplement 3.</label><caption><title>The y axis of the bar plots shows the percentage of streamlines from each default mode network (DMN) seed that terminate in each visual region of interest (ROI) (shown in the x axis).</title><p>Seeds and ROIs can be consulted in <xref ref-type="fig" rid="fig4">Figure 4a</xref>. The error bars depict the standard error of the mean.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-94902-fig4-figsupp3-v1.tif"/></fig><fig id="fig4s4" position="float" specific-use="child-fig"><label>Figure 4—figure supplement 4.</label><caption><title>Psychophysiological interaction analysis of the connectivity from the spatial context and semantic probe regions to fronto-temporal (FT) and medial temporal (MT)-default mode network (DMN) subnetworks.</title><p>This analysis collapses the same-category building (SCB) and mixed-category building (MCB) conditions, which showed no significant differences. Note: *=p&lt;0.05, **=p&lt;0.01.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-94902-fig4-figsupp4-v1.tif"/></fig></fig-group><fig-group><fig id="fig5" position="float"><label>Figure 5.</label><caption><title>Analysis situating the position of the pathways in a whole-brain connectivity gradient space (<xref ref-type="bibr" rid="bib61">Margulies et al., 2016</xref>).</title><p>The scatterplots depict the position of each participant’s peak response to the semantic and context task in this gradient space (the big circles represent the mean of each task for that phase). The bar plots compare the mean of each gradient across tasks. The inset on the bottom left of the panel displays <xref ref-type="bibr" rid="bib61">Margulies et al., 2016</xref>, original gradient space.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-94902-fig5-v1.tif"/></fig><fig id="fig5s1" position="float" specific-use="child-fig"><label>Figure 5—figure supplement 1.</label><caption><title>Location in the two principal gradients of the peak response per participant for semantic and spatial context decisions.</title><p>Dashed lines highlight the cases that contradict the pattern found in the group-level analysis.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-94902-fig5-figsupp1-v1.tif"/></fig></fig-group><fig-group><fig id="fig6" position="float"><label>Figure 6.</label><caption><title>Univariate results for the probe phase contrasting same-category versus mixed-category trials separately for the semantic and spatial context tasks.</title><p>(<bold>a</bold>) Contrast of spatial context same- &gt; mixed-category building trials during the probe phase. (<bold>b</bold>) Task by condition (same/mixed-category building) interaction. (<bold>c</bold>) Contrast of semantic same- &gt; mixed-category building trials during the probe phase. (<bold>d</bold>) Spatial relations of the same &gt; mixed spatial context cluster with the semantic and spatial context pathways outlined in <xref ref-type="fig" rid="fig4">Figure 4</xref>. (<bold>e</bold>) Intrinsic connectivity seed-to-region of interest (ROI) results using the three univariate results clusters shown in the top panel as seeds and the pathways as ROIs. The error bars depict the standard error of the mean. ***p&lt;0.001.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-94902-fig6-v1.tif"/></fig><fig id="fig6s1" position="float" specific-use="child-fig"><label>Figure 6—figure supplement 1.</label><caption><title>Results of the representational similarity analysis (RSA).</title><p>Top left panel: Within-task RSA results correlating BOLD activity from the probe phase of semantic mixed-category building trials with the semantic similarity matrix described in the Methods section, and BOLD activity from the probe phase of context mixed-category building trials with the context similarity matrix. Top right panel: Cross-task similarity analysis correlating BOLD activity from semantic trials with the context similarity matrix. Bottom panel: The left part depicts the spatial relations of the cross-task similarity analysis cluster with the semantic and context pathways outlined in <xref ref-type="fig" rid="fig4">Figure 4</xref>; the right part shows intrinsic connectivity seed-to-region of interest (ROI) results using the within- and cross-task RSA clusters shown in the top panel as seeds and the pathways as ROIs. The error bars depict the standard error of the mean. ***p&lt;0.001, **p&lt;0.01.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-94902-fig6-figsupp1-v1.tif"/></fig><fig id="fig6s2" position="float" specific-use="child-fig"><label>Figure 6—figure supplement 2.</label><caption><title>Representational similarity analysis results for the same-category building trials of the probe phase of the semantic task.</title><p>No significant voxels were identified for the spatial context task.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-94902-fig6-figsupp2-v1.tif"/></fig></fig-group><sec id="s2-2-1"><title>Probe phase</title><p>We began our exploration of the streams of information between visual cortex and DMN by characterising their visual end. To accomplish this, we first analysed the whole-brain activation observed during the probe phase of our semantic and spatial context tasks, when participants were viewing objects and scenes, and related these responses to previously established visual regions for object and scene perception. We then linked the visual regions engaged by our task to the DMN by describing their patterns of intrinsic connectivity, their functional involvement, and activation found within DMN regions during the probe phase of our task.</p><p>We examined differences in neural responses to probe images of objects in the semantic task, and scenes in the spatial context task in Study 1 (<xref ref-type="fig" rid="fig2">Figure 2</xref>). Semantic probes elicited greater activation in bilateral ventral LOC, extending to fusiform cortex and supramarginal gyrus in the left hemisphere. Spatial context probes elicited a stronger response in bilateral dorsal LOC, medial occipital lobe, precuneus, parahippocampal cortex and supplementary motor areas (SMA), as well as insula and middle frontal gyrus and frontal pole regions in the left hemisphere, and precentral regions in the right hemisphere (<xref ref-type="fig" rid="fig2">Figure 2a</xref>). Details of peak activations for all univariate results from Study 1 are in <xref ref-type="supplementary-material" rid="supp1">Supplementary file 1</xref> – Cluster information for neuroimaging results from Study 1.</p><p>To confirm these distinctive responses to semantic and spatial context probes were related to well-established categorical effects within visual cortex, we examined their overlap with object and scene localisers (i.e. passive viewing) in Study 2 (<xref ref-type="fig" rid="fig2">Figure 2b and c</xref>). Regions engaged by the spatial context probes resembled scene perception regions, while semantic probes overlapped with object perception regions.</p><p>We next analysed the probe responses exploring the strength of activation during this phase within three DMN subdivisions defined by <xref ref-type="bibr" rid="bib120">Yeo et al., 2011</xref>. [The Yeo et al. parcellation labels these subnetworks of the DMN as core DMN = DMN-A, FT-DMN=DMN-B, MT-DMN=DMN-C. A two-way repeated-measures ANOVA using task (semantic, spatial context) and region of interest (ROI) (core DMN, FT-DMN, MT-DMN) as factors revealed a significant main effect of ROI (F(1.281,33.306)=50.42, p&lt;0.001) and an interaction (F(1.64,42.65)=12.44, p&lt;0.001; Greenhouse-Geisser corrected).] Post hoc comparisons showed a significantly stronger response within MT-DMN to spatial context relative to semantic probes (t(26)=4.1, p=0.001). No significant difference between tasks was observed for core or FT-DMN (both p&gt;0.05, <xref ref-type="fig" rid="fig2">Figure 2d</xref>).</p><p>Finally, we examined the intrinsic connectivity of activation regions in <xref ref-type="fig" rid="fig2">Figure 2a</xref>, masked by <xref ref-type="bibr" rid="bib120">Yeo et al., 2011</xref>, visual networks (combining central and peripheral networks), using data from Study 3. Visual areas responding to semantic and spatial context probes showed differential connectivity, including to regions of DMN (posterior cingulate, medial prefrontal cortex, portions of anterior and dorsal prefrontal cortex, and anterior temporal cortex; <xref ref-type="fig" rid="fig2">Figure 2e</xref>). Cognitive decoding using Neurosynth revealed that semantic probe connectivity was associated with perceptual and somatomotor terms, while spatial context probe connectivity was associated with navigation, visuospatial and episodic memory terms (<xref ref-type="fig" rid="fig2">Figure 2f</xref>). Semantic probe regions showed preferential overlap with FT-DMN, whilst spatial context probe regions showed greater overlap with MT-DMN, followed by core DMN (<xref ref-type="fig" rid="fig2">Figure 2g</xref>).</p></sec><sec id="s2-2-2"><title>Decision phase</title><p>Having characterised the visual end of the visual-DMN pathways in our previous analysis, we next turned our attention to the DMN end. Following the same logic, we first analysed the whole-brain activation during the decision phase of our task, where participants had to judge the relationship between objects and scenes respectively. We compared this activation to classic DMN regions described by <xref ref-type="bibr" rid="bib120">Yeo et al., 2011</xref>, and linked the regions engaged within this network to visual regions in terms of their task activation and functional connectivity.</p><p>We characterised regions responsive to semantic and spatial context decisions in Study 1. <xref ref-type="fig" rid="fig3">Figure 3a</xref> shows that semantic decisions elicited stronger engagement within dorsolateral prefrontal, lateral occipital, posterior temporal, and occipital cortex, as well as pre-SMA. These regions overlapped with FT-DMN (<xref ref-type="fig" rid="fig3">Figure 3b</xref>). Spatial context decisions produced stronger activation within a predominantly medial set of occipital, ventromedial temporal (including parahippocampal gyrus), retrosplenial, and precuneus regions that overlapped with MT-DMN (<xref ref-type="fig" rid="fig3">Figure 3c</xref>).</p><p>Given our hypothesis of dissociable pathways between visual cortex and DMN subsystems, we examined responses to semantic and spatial contextual decisions in visual cortex, using the object and scene localiser ROIs from Study 2. A two-way repeated-measures ANOVA including task (semantic, spatial context decisions) and visual ROI (scene and object regions) revealed main effects of task (F(1,26)=14.02, p&lt;0.001), visual ROI (F(1,26)=9.91, p=0.004), and their interaction (F(1,26)=24.65, p&lt;0.001). Post hoc comparisons showed a stronger response to spatial context decisions, relative to semantic decisions, in the visual ROI sensitive to scenes (t(26)=3.63, p&lt;0.001), but not in the object-selective region (t(26)=1.88 p=0.071; <xref ref-type="fig" rid="fig3">Figure 3d</xref>).</p><p>We investigated differences in the intrinsic connectivity of the distinct DMN decision regions activated during the semantic and spatial context tasks (shown in <xref ref-type="fig" rid="fig3">Figure 3a</xref>) in independent data from Study 3. We seeded the decision regions that intersected with DMN (combining core, FT and MT-DMN from Yeo et al.’s 2011 parcellation). The results, in <xref ref-type="fig" rid="fig3">Figure 3e</xref>, revealed differences in the functional networks of these DMN regions that extended to visual cortex. Semantic decision regions showed stronger connectivity to lateral visual regions along with lateral temporal cortex, inferior frontal gyrus, angular gyrus, and dorsomedial prefrontal cortex. Spatial decision regions were more connected to medial visual regions, ventro-medial temporal regions, medial parietal cortex, ventral parts of medial prefrontal cortex, motor cortex and dorsal parts of LOC. Since resting-state analysis is sensitive to the choice of threshold, we repeated this analysis with a stricter cluster-forming threshold and found that the resulting maps were virtually identical (with a spatial correlation of r=0.99 between maps generated with both thresholds), for both the probe and decision phases (see Supplementary analysis: resting-state maps with stricter thresholding).</p><p>Cognitive decoding of these connectivity maps using Neurosynth (<xref ref-type="fig" rid="fig3">Figure 3f</xref>) revealed that the semantic decision network was associated with terms related to language, semantic processing, and reading, while the spatial context decision network was associated with navigation, episodic, and autobiographical memory. The decision DMN seeds also showed differential connectivity to visual regions (<xref ref-type="fig" rid="fig3">Figure 3g</xref>). Semantic decision regions were more connected with lateral and ventral occipital cortex, whilst spatial context decision regions showed more connectivity with medial occipital, ventromedial temporal (including parahippocampal), and dorsal LOC.</p></sec><sec id="s2-2-3"><title>Pathways analysis</title><p>The analysis above identified regions of visual cortex showing a differential response to semantic and spatial context probes, related to category effects for objects versus scenes. We also found distinct DMN subnetworks which supported semantic and spatial context decisions respectively. Next, we considered if these effects are linked: Do FT-DMN regions have stronger connectivity to object perception areas of visual cortex, while MT-DMN regions connect to scene perception regions? To answer this question, we analysed the functional and structural connectivity from the visual regions that were responsive to viewing probes during our tasks to those DMN regions activated during decisions about those probes. We characterised the spatial layout of these pathways in the brain as well as their large-scale network composition, their functional involvement, and verified their presence in individual participants.</p><p>Using resting-state data from Study 3, we performed a series of seed-to-ROI analyses to examine differential visual-to-DMN connectivity. We seeded the visual regions in <xref ref-type="fig" rid="fig2">Figure 2e</xref> (i.e. probe responses to objects and scenes masked by Yeo et al.’s visual networks) and extracted their intrinsic connectivity to DMN, using ROIs showing differential activation to semantic and spatial context decisions (corresponding to the seeds in <xref ref-type="fig" rid="fig3">Figure 3e</xref>). In a second analysis, we examined the reverse (i.e. seeded DMN regions and extracted their connectivity to visual regions). The seeds and ROIs for this analysis can be consulted in <xref ref-type="fig" rid="fig4">Figure 4a</xref>. These effects were analysed using repeated-measures ANOVAs examining the interaction between seed and ROI (<xref ref-type="fig" rid="fig4">Figure 4b and c</xref>). The visual-to-DMN ANOVA showed main effects of seed (F(1,190)=226.23, p&lt;0.001), ROI (F(1,190)=85.21, p&lt;0.001), and a seed by ROI interaction (F(1,190)=322.83, p&lt;0.001). Post hoc contrasts confirmed there was stronger connectivity between object probe regions and semantic versus spatial context decision regions (t(190)=3.98, p&lt;0.001), and between scene probe regions and spatial context versus semantic decision regions (t(190)=20.07, p&lt;0.001). The DMN-to-visual ANOVA confirmed this pattern: again, there was a main effect of ROI (F(1,190)=36.91, p&lt;0.001) and a seed by ROI interaction (F(1,190)=218.42, p&lt;0.001), with post hoc contrasts confirming stronger intrinsic connectivity between DMN regions implicated in semantic decisions and object probe regions (t(190)=11.63, p&lt;0.001), and between DMN regions engaged by spatial context decisions and scene probe regions (t(190)=6.17, p&lt;0.001). To ensure that these results were not artificially inflated due to spatial mixing of the resting-state signals arising from proximal visual peripheral and DMN-C networks (<xref ref-type="bibr" rid="bib87">Silson et al., 2019</xref>; <xref ref-type="bibr" rid="bib93">Steel et al., 2021</xref>), we conducted a supplementary analysis eroding the visual probe and DMN decision ROIs for the spatial context task until the minimum gap between them exceeded the size of our smoothing kernel (see Supplementary analysis: eroded masks replication analysis and <xref ref-type="fig" rid="fig4s1">Figure 4—figure supplement 1</xref>). The results replicated the pattern described above. Supplementary analyses using the same seeds and task-independent ROIs also revealed the same pattern: these ROIs were based on the visual localiser masks from Study 2 and the complete DMN subnetworks defined by the <xref ref-type="bibr" rid="bib120">Yeo et al., 2011</xref>, 17-network parcellation (see Supplementary analysis: replicating resting-state connectivity pathways with task-independent ROIs and <xref ref-type="fig" rid="fig4s2">Figure 4—figure supplement 2</xref>).</p><p>These pathways, specialised for semantic and spatial cognition, link dissociable visual regions to DMN subsystems, consistent with the suggestion that functional differentiation in DMN partly reflects the strength of different inputs. <xref ref-type="fig" rid="fig4">Figure 4d</xref> provides a visualisation of these pathways using the intersection of connectivity from object over scene probe regions and semantic versus spatial context decisions to identify the semantic pathway (warm colours) and the reverse contrasts for the spatial pathway (cool colours). Cognitive decoding revealed terms related to object, action, motion, social, and face perception, as well as language and reading for the semantic pathway, and terms related to navigation, place processing and memory for the spatial context pathway (<xref ref-type="fig" rid="fig4">Figure 4e</xref>). The semantic pathway was predominantly characterised by FT-DMN and visual central regions in the <xref ref-type="bibr" rid="bib120">Yeo et al., 2011</xref>, 17-network parcellation, whilst the spatial context pathway reflected core and MT-DMN, and visual peripheral networks (<xref ref-type="fig" rid="fig4">Figure 4f</xref>).</p><p>A complementary analysis examined the spatial correlation of these semantic and spatial pathways (<xref ref-type="fig" rid="fig4">Figure 4d</xref>) with participants’ univariate activation when viewing semantic and spatial context probes, and when making semantic and spatial context decisions. We compared spatial correlations between our hypothesised pathways and ‘non-pathway conjunctions’, defined as conjunctions of visual object probe and DMN spatial context decision connectivity, and visual scene probe and DMN semantic decision connectivity with these univariate activation maps. We obtained Pearson r values for each participant reflecting spatial similarity of their activation patterns with these pathway and non-pathway maps and compared these correlations using one-way ANOVAs (<xref ref-type="fig" rid="fig4">Figure 4g</xref>). There was a significant effect of pathway for each of the four task phases (spatial context decision: F(2.32,441.45)=2741.68, p&lt;0.001; semantic decision: F(1.90,361.29)=521.94, p&lt;0.001; spatial context probe: F(2.09,396.96)=424.98, p&lt;0.001; semantic probe: F(2.07,393.80)=117.88, p&lt;0.001; Greenhouse-Geisser correction applied). In follow-up contrasts using paired t-tests, we compared the average Pearson r correlation of each phase to its relevant pathway, contrasted with the two non-pathway conjunctions. Correlations between the semantic probe and decision phases’ univariate activation and the semantic pathway were higher than non-pathway correlations and an equivalent pattern was seen for the spatial context pathway (<xref ref-type="fig" rid="fig4">Figure 4g</xref>; for exact t and p values associated with these comparisons see <xref ref-type="supplementary-material" rid="supp2">Supplementary file 2</xref>– Paired t-tests contrasting spatial similarity of participant-level activation with group-level context and semantic pathways and non-pathways), confirming that dissociable visual-to-DMN responses associated with semantic and spatial cognition are reliably present for individual participants.</p><p>Next, we examined if these pathways were reflected in the strength of white matter tracts connecting visual and DMN regions (seeds in <xref ref-type="fig" rid="fig4">Figure 4a</xref>). We examined structural connectivity in a subset of the Human Connectome Project (HCP) dataset (n=164), asking if object probe visual regions showed a greater proportion of white matter tracts terminating in semantic DMN regions, and if scene probe visual regions showed stronger structural connectivity to spatial context DMN regions (<xref ref-type="fig" rid="fig4">Figure 4h</xref>). A 2×2 repeated-measures ANOVA with visual regions as seeds and DMN regions as ROIs revealed a significant main effect of seed (F(1,163)=5.13, p=0.025), ROI (F(1,163)=82.46, p&lt;0.001), and their interaction (F(1,163)=664.57, p&lt;0.001). Post hoc comparisons confirmed stronger structural connectivity from the semantic probe visual regions to the semantic decision DMN regions; likewise, the spatial context probe visual regions showed stronger structural connectivity to the spatial context decision DMN regions (semantic probe visual: t(163)=8.25, p&lt;0.001; context probe visual: t(163)=478.66, p&lt;0.001). Repeating this analysis using the decision DMN regions as seeds and the probe visual regions as ROIs revealed a similar pattern (see Supplementary analysis: replicating pathways’ structural connectivity from the DMN end and <xref ref-type="fig" rid="fig4s3">Figure 4—figure supplement 3</xref>).</p><p>Finally, we examined how connectivity within the pathways changes depending on task demands in a psychophysiological interaction (PPI) analysis (see supplementary materials). We took the visual regions showing differential activation to object and scene probes as seeds (shown in <xref ref-type="fig" rid="fig2">Figures 2e</xref> and <xref ref-type="fig" rid="fig4">4a</xref>), while the ROIs were regions sensitive to semantic and spatial context decisions within the DMN (shown in <xref ref-type="fig" rid="fig3">Figures 3e</xref> and <xref ref-type="fig" rid="fig4">4a</xref>). The results, shown in <xref ref-type="fig" rid="fig4s4">Figure 4—figure supplement 4</xref>, showed that the object seed was more connected to both semantic and spatial context DMN decision regions during the semantic task, while the scene probe regions were more connected to spatial context decision regions during the spatial context task than object probe regions.</p></sec><sec id="s2-2-4"><title>Location of pathways in whole-brain gradients</title><p>Having found evidence for dissociable semantic and spatial context pathways, we analysed their location in a functional state space defined by the first two gradients of intrinsic connectivity (<xref ref-type="bibr" rid="bib61">Margulies et al., 2016</xref>). The principal gradient relates to connectivity differences between unimodal and heteromodal cortex, while the second gradient captures connectivity differences between visual and auditory/somatomotor cortex. By locating the ends of the two visual-to-DMN pathways within gradient space, we can establish if DMN regions supporting semantic and spatial cognition are equally distant in connectivity from sensory-motor cortex: semantic cognition is arguably more abstract than spatial cognition and might be supported by DMN regions that are more isolated from sensory-motor systems on the principal gradient (<xref ref-type="bibr" rid="bib61">Margulies et al., 2016</xref>; <xref ref-type="bibr" rid="bib88">Smallwood et al., 2021</xref>). We can also establish if semantic and spatial DMN regions differ in the balance of connectivity to visual versus auditory-motor regions on the second gradient: heteromodal concepts are thought to be constructed from diverse sensory-motor features (<xref ref-type="bibr" rid="bib78">Ralph et al., 2017</xref>), while spatial representations might draw more strongly on visual information (<xref ref-type="bibr" rid="bib29">Epstein and Baker, 2019</xref>). We tested these predictions by locating individual unthresholded peak response coordinates for semantic and spatial context probes (within visual networks) and decisions (within the DMN) in gradient space (masked by Yeo et al.’s 7-network parcellation). We then asked if there are significant differences in the gradient locations of these tasks across participants.</p><p>The results (<xref ref-type="fig" rid="fig5">Figure 5a</xref>) showed that there were no differences between the two tasks during the probe phase, while the decision phase was associated with task effects: DMN peaks for semantic decisions were more distant from sensory-motor cortex on the principal gradient, compared with spatial context decisions (t(1,26)=2.34, p=0.027), consistent with the view that semantic cognition draws on more abstract and heteromodal representations in DMN. In addition, responses for the spatial context task were closer to the visual end of the second gradient, while responses for the semantic task were somewhat more balanced across visual and auditory-motor ends of this gradient (t(1,26)=3.31, p=0.003). [An ANOVA including task and condition (MCB versus SCB) replicated these task effects and found no effects of condition on the position of peak responses in gradient space.] Since the scatterplots in <xref ref-type="fig" rid="fig5">Figure 5</xref> do not distinguish whether these effects took place at the individual level (the data points are not linked across tasks), we plotted the same data comparing the gradient values for the peak responses in each of our tasks at the participant level in the supplementary materials (see <xref ref-type="fig" rid="fig5s1">Figure 5—figure supplement 1</xref>). This plot shows that in the majority of individual cases, the pattern of group-level results shown in <xref ref-type="fig" rid="fig5">Figure 5</xref> held.</p></sec><sec id="s2-2-5"><title>Cross-pathway integration of semantic and spatial cognition: response to SCB versus MCB</title><p>Having identified dissociable semantic and spatial context pathways, and examined how these are differentially recruited across tasks, we investigated the integration of semantic and spatial context information across these processing streams. We compared responses in SCB and MCB trials, since semantic and spatial information are aligned when buildings contain items from a single semantic category, but not in MCB. In these analyses, there were differences between conditions in the probe but not the decision-making phase (perhaps because many probes were presented without decisions, increasing statistical power).</p><p>First, we performed univariate contrasts of MCB and SCB trials (<xref ref-type="fig" rid="fig6">Figure 6a–c</xref>). For scene probes in the spatial context task, the MCB&gt;SCB contrast elicited a stronger response in dorsal LOC and retrosplenial cortex (<xref ref-type="fig" rid="fig6">Figure 6a</xref>). In these circumstances, spatial context probes could only activate spatial and not semantic information. The SCB&gt;MCB contrast activated an adjacent region of right angular gyrus (<xref ref-type="fig" rid="fig6">Figure 6b</xref>). For semantic probes, the contrast of MCB&gt;SCB identified greater engagement in distributed parietal, occipital, and temporal regions, associated with the multiple-demand network (<xref ref-type="fig" rid="fig6">Figure 6c</xref>). There were no clusters that showed a stronger response to SCB than MCB probes for the semantic task. There was also an interaction between task and condition, which was driven by the SCB&gt;MCB effect in right angular gyrus in the spatial context task exceeding this effect in the semantic task.</p><p>To interpret these results, we conducted seed-to-ROI intrinsic connectivity analysis using independent data from Study 3, taking these clusters as seeds and the semantic and spatial context pathways masks (shown in <xref ref-type="fig" rid="fig4">Figures 4d</xref> and <xref ref-type="fig" rid="fig6">6d</xref>) as ROIs. A two-way repeated-measures ANOVA examined seed (spatial context SCB&gt;MCB and MCB&gt;SCB; semantic MCB&gt;SCB) and ROI (semantic and spatial context pathways) as factors. The results can be seen in <xref ref-type="fig" rid="fig6">Figure 6e</xref>. There were significant effects of seed (F(1.92,364.1)=211.48, p&lt;0.001), ROI (F(1,190)=182.67, p&lt;0.001) and an interaction (F(1.84,349.66)=723.412, p&lt;0.001). Post hoc comparisons showed the context pathway was most connected to the spatial context MCB&gt;SCB clusters, less connected to the spatial context SCB&gt;MCB (when semantic information was also relevant to the response), and least connected to the semantic MCB&gt;SCB regions (context MCB&gt;context SCB: t(1,190)=34.91, p&lt;0.001; context SCB&gt;semantic MCB: t(1,190)=5.18, p&lt;0.001). The opposite pattern of connectivity was found for the semantic pathway, which was most connected to the semantic MCB&gt;SCB regions, less connected to the spatial context SCB&gt;MCB, and least connected to the spatial context MCB&gt;SCB clusters (semantic MCB&gt;context SCB: t(1,190)=16.93, p&lt;0.001; context SCB&gt;context MCB: t(1,190)=10.59, p&lt;0.001). In this way, spatial context SCB&gt;MCB regions, which reflected the engagement of semantic information in a spatial context task, showed an intermediate pattern of connectivity to both pathways.</p><p>A supplementary analysis of the task using multivariate approaches (see supplementary materials ‘Supplementary analysis: multivariate response to SCB versus MCB’) found a similar pattern. We performed representational similarity analysis (RSA) using a searchlight approach, which allowed us to detect regions sensitive to semantic and spatial context information. The results of this analysis in the MCB trials, where information could not be integrated, showed regions sensitive to category in the semantic task in bilateral ventral LOC, as well as regions sensitive to location in the spatial context task, dorsally in left LOC (see <xref ref-type="fig" rid="fig6s1">Figure 6—figure supplement 1</xref>). A cross-task RSA of the SCB trials, where semantic and spatial information were aligned, allowing integration, identified a separate set of regions in right LOC, topographically situated between the two pathways, that captured spatial context information during the semantic task. An intrinsic connectivity analysis in data from Study 3 using the RSA regions as seeds and the pathways as ROIs showed that the regions sensitive to semantic and spatial context information during MCB trials were maximally connected to the semantic and spatial context pathways, respectively. On the other hand, the regions where spatial information could be decoded during the SCB trials of the semantic task showed an intermediate pattern of connectivity to both pathways (especially to the semantic pathway), suggesting a role in integrating information between them (see <xref ref-type="fig" rid="fig6s1">Figure 6—figure supplement 1</xref>).</p></sec></sec></sec><sec id="s3" sec-type="discussion"><title>Discussion</title><p>Functional subdivisions of visual cortex and DMN sit at opposing ends of parallel processing streams supporting visually mediated object-centric semantic and spatial cognition; moreover, regions with intermediate patterns of connectivity are implicated in the integration of these streams into coherent experience. Viewing object probes in a semantic task and location probes in a spatial context task activated different parts of visual cortex, functionally related to the passive viewing of objects and scenes. Semantic and spatial context decisions about these probes engaged FT and MT-DMN subsystems. Visual regions sensitive to object probes showed stronger intrinsic functional connectivity and structural connectivity to FT-DMN, while scene probe regions were more connected to MT-DMN. In a functional space defined by whole-brain connectivity patterns, the object-centric semantic pathway was more distant from unimodal regions on a unimodal-to-heteromodal connectivity gradient, and it had a more balanced influence of visual and auditory-motor systems, while the spatial context pathway was more visual. Finally, we found evidence that both heteromodal and visual regions integrate information about meaning and spatial context. When all the items in a building were drawn from a particular semantic category, there was greater recruitment of right angular gyrus; multivariate pattern analysis similarly found a cluster in LOC that represented spatial context information during the semantic task. When there was no opportunity to integrate object-centric semantic information with spatial context, regions that responded showed higher pathway-specific connectivity. In contrast, when integration was facilitated by the structure of the task, response regions had an intermediate pattern of connectivity.</p><p>Our study has important implications for the organisation of DMN into specialised subsystems, and for how these subsystems get their input from perceptual regions. Previous literature has robustly established distinct FT and MT subsystems (<xref ref-type="bibr" rid="bib7">Andrews-Hanna et al., 2014</xref>; <xref ref-type="bibr" rid="bib8">Andrews-Hanna and Grilli, 2021</xref>; <xref ref-type="bibr" rid="bib88">Smallwood et al., 2021</xref>; <xref ref-type="bibr" rid="bib120">Yeo et al., 2011</xref>); however, the way in which this architecture reflects differences in visual inputs remains contentious. One proposal is that different DMN subnetworks are differently engaged by tasks that are externally versus internally oriented. For example, (<xref ref-type="bibr" rid="bib18">Chiou et al., 2020</xref>) propose that there is a basic distinction between parts of the network that process semantic information accessed from words and images, and between DMN regions that sustain internally focussed cognition. Other work has called into question whether semantic responses in FT-DMN are specific to external tasks: e.g., <xref ref-type="bibr" rid="bib122">Zhang et al., 2022</xref>, found that lateral temporal regions changed their patterns of connectivity depending on the task, with more visual connectivity in externally oriented tasks like reading, and more DMN connectivity in internally orientated conceptual states like mind-wandering and autobiographical memory. This work suggests FT-DMN might support object-centric semantic cognition across internal and external modes of cognition. Our findings also suggest that the distinction between these subsystems is not organised according to visual coupling; instead, DMN organisation arises from differential connectivity between distinct visual and DMN regions that gives rise to partially segregated pathways that process information about locations and meanings. Visual responses to scenes and objects reflect entry points to these processing pathways such that the key distinction between FT-DMN and MT-DMN relates to the type of information being processed, as opposed to how the information is accessed.</p><p>Our observed dissociation between semantic and spatial context pathways echoes a similar domain-specific organisation for working memory in prefrontal cortex (<xref ref-type="bibr" rid="bib55">Levy and Goldman-Rakic, 2000</xref>; <xref ref-type="bibr" rid="bib84">Romanski, 2004</xref>), in which there are dorsal and ventral streams associated with the maintenance of item location and identity respectively. This organising principle has been extended to long-term memory more recently. <xref ref-type="bibr" rid="bib20">Deen and Freiwald, 2021</xref>, found a similar dissociation between places and people (instead of objects) in the DMN and other areas of association cortex. This was not tied to a specific input modality or task, indicative of parallel, domain-specific networks, at the top of the cortical hierarchy. Here, we extend this approach to consider whether functional divisions within DMN and visual cortex are connected, giving rise to pathways which are differentially situated in a connectivity state space defined by whole-brain dimensions of intrinsic connectivity, and we ask how these pathways might be integrated, and how they might be flexibly recruited according to task demands.</p><p>Although our research suggests a <italic>domain</italic>-specific view of brain organisation within visual-to-DMN pathways linked to object-centric semantic and spatial cognition, there may be different <italic>processes</italic> within meaning and spatial context tasks that drive these effects. The FT subsystem is thought to rely on the abstraction of information from sensory-motor inputs (; <xref ref-type="bibr" rid="bib88">Smallwood et al., 2021</xref>; <xref ref-type="bibr" rid="bib107">Wang et al., 2020</xref>). The MT subsystem, on the other hand, uses a relational code that can capture spatial relations to successfully navigate complex environments (<xref ref-type="bibr" rid="bib25">Eichenbaum, 2004</xref>; <xref ref-type="bibr" rid="bib26">Eichenbaum and Cohen, 2014</xref>; <xref ref-type="bibr" rid="bib121">Zeidman et al., 2015</xref>). One possibility is that, at the visual end of these pathways, spatial location is more dependent on peripheral vision, while object recognition is dependent on central fixation (<xref ref-type="bibr" rid="bib41">Hasson et al., 2002</xref>; <xref ref-type="bibr" rid="bib56">Levy et al., 2001</xref>); consequently, the distinct visual-to-DMN pathways we have recovered may reflect a basic property of how peripheral and central visual regions project to DMN. Our findings mirror and extend the results of <xref ref-type="bibr" rid="bib87">Silson et al., 2019</xref>; <xref ref-type="bibr" rid="bib93">Steel et al., 2021</xref>, since we identify dissociable pathways between visual cortex and DMN; however, we extend this work to cover fully distributed networks that support object-centric semantic and spatial decision-making, and locate these pathways in a whole-brain gradient space relating to variation in patterns of intrinsic connectivity, as well as considering how these pathways can be integrated.</p><p>One question remains: how does the brain generate a coherent, seamlessly integrated experience of place and the identity of objects from these segregated, specialised streams of processing? The response we identified in right angular gyrus when object semantic and spatial context information was aligned is consistent with earlier studies implicating this brain region in the integration of information from multiple domains into a rich, meaningful context that can guide ongoing cognition (<xref ref-type="bibr" rid="bib52">Lanzoni et al., 2020</xref>). One recent proposal suggests that neurons in this area represent high-dimensional inputs on a low-dimensional manifold encoding the relative position of items in physical space and abstract conceptual space (<xref ref-type="bibr" rid="bib95">Summerfield et al., 2020</xref>). This region, which is maximally distant from sensory-motor cortex and equidistant from visual and motor cortex, might have the capacity to form representations that are not dominated by one type of input or code. We found a region of the right AG that was potentially important for integrating semantic and spatial context information. Previous research has established a key role of the AG in context integration (<xref ref-type="bibr" rid="bib12">Bonnici et al., 2016</xref>; <xref ref-type="bibr" rid="bib14">Branzi et al., 2020</xref>; <xref ref-type="bibr" rid="bib79">Ramanan et al., 2018</xref>) and specifically, in guiding multimodal decisions and behaviour (<xref ref-type="bibr" rid="bib42">Humphreys et al., 2021</xref>; <xref ref-type="bibr" rid="bib117">Xu et al., 2017</xref>; <xref ref-type="bibr" rid="bib119">Yazar et al., 2017</xref>). Although some recent proposals suggest a causal role of right AG in the early establishment of meaningful contexts, allowing semantic integration across modalities (<xref ref-type="bibr" rid="bib11">Bocca et al., 2015</xref>; <xref ref-type="bibr" rid="bib64">Muggleton et al., 2008</xref>; <xref ref-type="bibr" rid="bib70">Olk et al., 2015</xref>; <xref ref-type="bibr" rid="bib71">Petitet et al., 2015</xref>; <xref ref-type="bibr" rid="bib86">Seghier, 2023</xref>), the majority of this research points to left, rather than right, AG as a key region for integration. We might have observed involvement of the right AG in our study since people were integrating semantic and spatial information, and visuospatial memory processes might be somewhat right lateralised (cf. <xref ref-type="bibr" rid="bib90">Sormaz et al., 2017</xref>) and more strongly connected to right than left AG. We are not aware of a literature on right AG lesions impairing the integration of semantic and spatial information but, in the face of our findings, this might be a promising new direction. Patients with damage to right AG should be examined with specific tasks aimed at probing this type of integration. We also found evidence of information integration in occipital regions that were closer to the input regions of the visual-to-DMN pathways. These different levels of integration shared a common characteristic: in both cases, the region implicated in integration was spatially interposed between the pathways, consistent with the view that topography is highly relevant to information integration since adjacent brain regions tend to share a high degree of functional connectivity and represent similar information.</p><p>While we might assume that common visual-to-DMN pathways support memory access from vision (as in this study), and subserve the generation of visual features when imagining objects versus scenes, this hypothesis awaits empirical investigation. Moreover, our pathways are vision-specific, and it remains unclear if there are analogous pathways from auditory or somatomotor cortex to DMN. The generality of these pathways must be confirmed across tasks, since spatial representations are likely to interact with other representational codes, including emotion and social information – the interdigitated pathways highlighted in these circumstances (<xref ref-type="bibr" rid="bib13">Braga and Buckner, 2017</xref>; <xref ref-type="bibr" rid="bib24">DiNicola et al., 2020</xref>) might show anatomical differences or be broadly the same as the pathways uncovered here.</p><p>Likewise, further research should be carried out on memory-visual interactions for alternative domains. Our study focussed on spatial location and semantic object processing and therefore cannot address how other categories of stimuli, such as faces, are processed by the visual-to-memory pathways that we have identified. Previous work has suggested some overlap in the neurobiological mechanisms for semantic and social processing (; <xref ref-type="bibr" rid="bib18">Chiou et al., 2020</xref>), suggesting that the FT-DMN pathway may be highlighted when contrasting both social faces and semantic objects with spatial scenes. On the other hand, some researchers have argued for a ‘third pathway’ for aspects of social visual cognition (<xref ref-type="bibr" rid="bib75">Pitcher, 2023</xref>; <xref ref-type="bibr" rid="bib74">Pitcher and Ungerleider, 2021</xref>). Future studies that probe other categories will be able to confirm the generality (or specificity) of the pathways we described.</p><p>One important caveat is that we have not investigated the spatiotemporal dynamics of neural propagation along the pathways we identified between visual cortex and DMN. The dissociations we found in task responses, intrinsic functional connectivity, and white matter connections all support the view that there are at least two distinct routes between visual and heteromodal DMN regions, yet this does not necessarily imply that there is a continuous sequence of cortical areas that extend from visual cortex to DMN – and given our findings of structural connectivity differences that relate to the functional subdivisions we observe, this is unlikely to be the sole mechanism underpinning our findings. It would be interesting in future work to characterise the spatiotemporal dynamics of neural propagation along visual-DMN pathways using methods optimised for studying the dynamics of information transmission, like Granger causality or travelling wave analysis.</p><p>Moreover, many questions remain about information integration across the semantic and spatial domains; does spatial juxtaposition promote the emergence of an integrated code, and are neural representations that emerge at the intersection of these pathways more than the sum of their parts? Although further research is needed, the current study highlights how subdivisions within visual and DMN are related to types of information, giving rise to distinct processing streams that capture different unimodal to heteromodal transformations relevant to object-centric semantic and spatial context processing, and shows how these pathways might interact at multiple levels of the cortical hierarchy to produce coherent cognition.</p></sec><sec id="s4" sec-type="methods"><title>Methods</title><sec id="s4-1"><title>Study 1: Task-based fMRI</title><sec id="s4-1-1"><title>Study 1: Participants</title><p>Thirty native English speakers (mean age = 22.6 ± 2.7 years, age-range 18–34 years, 8 males) with normal or corrected-to-normal vision and no history of language disorders participated in this study. Ethical approval was obtained from the Research Ethics Committees of the Department of Psychology and York Neuroimaging Centre, University of York. Written informed consent was obtained from all subjects prior to testing.</p></sec><sec id="s4-1-2"><title>Study 1: Materials</title><p>The learning phase employed videos showing a walk-through for 12 different buildings (one per video), shot from a first-person perspective. The videos and buildings were created using an interior design program (Sweet Home 3D). Each building consisted of two rooms: a bedroom and a living room/office, with an ajar door connecting the two rooms. The order of the rooms (first and second) was counterbalanced across participants. Each room was distinctive, with different wallpaper/wall colour and furniture arrangements. The building contexts created by these rooms were arbitrary, containing furniture that did not reflect usual room distributions (i.e. a kitchen next to a dining room), to avoid engaging further conceptual knowledge about frequently encountered spatial contexts in the real world. Within each room, there were three framed images of objects and animals, towards the start, middle, and end of each video (see top panel of <xref ref-type="fig" rid="fig7s1">Figure 7—figure supplement 1</xref>), each at the same distance from its neighbour (across the two rooms); 72 images were presented overall. The images represented single items from six semantic categories: musical instruments, gardening tools, sports equipment, mammals, fish, and birds (12 pictures from each category). Half of the buildings contained images from the same semantic category (SCB), and the other half contained images from different semantic categories (‘MCB). The presentation of items within each room in MCB was controlled such that: (1) no item from the same category was presented at the same location twice, and (2) no three categories were grouped together more than once.</p><p>A full list of pictures of the object and location stimuli employed in this task as well as the videos watched by the participants can be consulted in the OSF collection associated with this project under the components OSF &gt; Tasks &gt; Training.</p></sec><sec id="s4-1-3"><title>Study 1: Design and procedure</title><sec id="s4-1-3-1"><title>Training task</title><p>Subjects participated in a training session the day before the MRI scan, where they watched the walk-through videos, each lasting 49 s (<xref ref-type="fig" rid="fig7">Figure 7</xref> and top panel of <xref ref-type="fig" rid="fig7s1">Figure 7—figure supplement 1</xref>). Participants watched each video at least six times in three rounds (twice per round). Each round consisted of four mini-blocks of videos containing three videos. After each mini-block, participants were given a test in Psychopy3: they were asked to choose the room that each item was presented in, responding via button press. Items were pictured at the top of the screen, with the correct room and another room below (<xref ref-type="fig" rid="fig7s1">Figure 7—figure supplement 1</xref>, left half of bottom panel). Screenshots were taken of the location of each framed image and the rooms themselves (from the entrance way), with the images and their frames removed (see bottom panel of <xref ref-type="fig" rid="fig7s1">Figure 7—figure supplement 1</xref>). They had 5 s to respond, after which the correct room was presented as feedback for a further 5 s. Following each round, there was a matching task, which reinforced participants’ memory of which rooms belonged together. Two rooms from the same building were presented, with two items from that building (one from each room) below. Participants were instructed to drag the objects into the correct room of the building (<xref ref-type="fig" rid="fig7s1">Figure 7—figure supplement 1</xref>, right half of bottom panel). Feedback showed the correct object in each room. Finally, to establish how well the item-location pairs were learned, participants were given a final test on all the rooms and items: this followed the structure of the mini-block tests, except that materials from the entire session were included. If accuracy was below 80%, participants watched the videos again until this threshold was reached. In total, participants spent approximately 2 hr on the training. The amount of training required was established in pilot testing with nine participants who did not take part in the main study. This also confirmed the items were easily nameable.</p><fig-group><fig id="fig7" position="float"><label>Figure 7.</label><caption><title>Top panel: the layout of two buildings is shown, one of them contains semantically related items (same-category building [SCB]), the other contains unrelated items (mixed-category building [MCB]).</title><p>These items and locations are shown in the example trials below. Bottom panel: Trial procedure for semantic and spatial context decisions. The phases of a trial are shown (probe, dots, decision, arrow task, fixation), and the red square indicates the correct response (not shown to participants). Participants were required to press ‘left’ or ‘right’ buttons in the decision phase. No-decision trials omitted the dots and decision phases. The videos and tests used during the training session for this task as well as the stimuli used in the task of Study 2 can be consulted in <xref ref-type="fig" rid="fig7s1">Figure 7—figure supplements 1</xref> and <xref ref-type="fig" rid="fig7s2">2</xref>.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-94902-fig7-v1.tif"/></fig><fig id="fig7s1" position="float" specific-use="child-fig"><label>Figure 7—figure supplement 1.</label><caption><title>Top panel: An example of what was seen during the training videos.</title><p>This is a ‘mixed-category building’ that contains items from different semantic categories. An example walk-through video of this building can be watched following this link: <ext-link ext-link-type="uri" xlink:href="https://www.youtube.com/watch?v=XVHhOh3BF74">https://www.youtube.com/watch?v=XVHhOh3BF74</ext-link>. Bottom panel: Example of training tests. On the left is an example of the mini-block test depicting the probe item at the top and two room screenshots below. The target screenshot is the room the object was presented in at training (left). The distractor screenshot (right) is from a different building, which the object did not belong to. On the right is an example of the matching task depicting two rooms from the same building and two items that belong to each room (rake-right room, goose-left room) which participants needed to match.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-94902-fig7-figsupp1-v1.tif"/></fig><fig id="fig7s2" position="float" specific-use="child-fig"><label>Figure 7—figure supplement 2.</label><caption><title>Examples of the dynamic images taken from the 3 s movie clips depicting faces, bodies, scenes, objects, and scrambled objects.</title><p>Still images taken from the beginning, middle, and end of the corresponding movie clip. The stimuli corresponding to the ‘faces’ condition were changed to line drawings to make this material suitable for hosting in bioRxiv preprint server. The actual stimuli shown can be consulted in the OSF collection associated with this paper (<ext-link ext-link-type="uri" xlink:href="https://osf.io/sh79m/">https://osf.io/sh79m/</ext-link>).</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-94902-fig7-figsupp2-v1.tif"/></fig></fig-group></sec><sec id="s4-1-3-2"><title>fMRI task</title><p>On the day of the scan, participants repeated the final test from the training day to establish how well they retained the information. They then watched all 12 videos once again, in a counterbalanced order, and performed the test phase a second time. The mean accuracy on the first day was 95.1% (SD = 5.7%) while on the second day it was 97.1% (SD = 3.8%). Two participants were excluded from the mean accuracy calculation for day 2 due to data loss.</p><p>Inside the scanner, participants performed a semantic and spatial context memory task, using a slow event-related design (<xref ref-type="fig" rid="fig7">Figure 7</xref>). The semantic task involved judgements about the semantic category of objects and animals (using the same images that have been presented in the buildings), while the spatial context task involved matching rooms that belonged to the same building. Both tasks consisted of ‘no-decision’ and ‘decision’ trials. No-decision trials were optimised for RSA and included an image of the probe item (for 2 s) followed by an ‘arrow task’ in which participants pressed ‘left’ or ‘right’ to match the direction of a series of chevrons (‘&lt;’ ‘&gt;’) presented on the screen (for 3 s), ending with a red fixation cross (1 s). The probe in the semantic task was an object or animal from the training; for the spatial context task, it was a screenshot of an item’s location within a room (excluding the item itself). In decision trials, the same types of probes were presented but they were followed by three central dots (for 4 s) indicating a decision would be made (<xref ref-type="fig" rid="fig7">Figure 7</xref>). In the decision phase, a target image (from the same category or building as the probe) was presented together with a distractor image, creating a two-alternative forced-choice judgement. In the spatial context task, the distractor was a room from a different building, while in the semantic task, the distractor was an item from a different category. On SCB trials, semantic and spatial information were aligned in the sense that the target and probe were from the same category and the same building. On MCB trials, semantic and spatial information did not converge: semantic targets were in a different building from the probe, while spatial context targets were from a different semantic category from the probe (see <xref ref-type="fig" rid="fig7">Figure 7</xref> for the structure of semantic and spatial context trials). Decisions were required within 4 s, and then the task progressed to the next trial. Participants made their responses using a button box, pressing with their right index finger to indicate whether the target image was on the left or right side of the screen. Participants were encouraged to respond as quickly and accurately as possible. After the decision was made, participants carried out the arrow task again (for 6.5 s minus their response time) followed by a red fixation cross (1 s) indicating the end of the trial. The arrow task served as a non-memory baseline and was included to increase separation of the BOLD signal between trials.</p><p>During the fMRI scan, there were four runs of the spatial context task and four runs of the semantic task. Each run contained 36 trials and lasted approximately 6 min. All 72 objects were presented as stimuli across blocks 1 and 2, and across blocks 3 and 4. Each run included 18 decision and 18 no-decision trials. The decision trials in each run were further subdivided into nine SCB and nine MCB decision trials. The decision trials in run 1 and run 2 became the no-decision trials in runs 3 and 4, and vice versa. Spatial context runs preceded semantic runs. The order of trials within each run was counterbalanced between participants. Prior to scanning, participants were given formal instructions for the tasks and shown how to use the response box.</p></sec></sec></sec><sec id="s4-2"><title>Study 1: Task-based fMRI</title><sec id="s4-2-1"><title>MRI data acquisition</title><p>Whole-brain structural and fMRI data were acquired using a 3T Siemens MRI scanner utilising a 64-channel head coil, tuned to 123 MHz at York Neuroimaging Centre, University of York. A Localiser scan and eight whole-brain functional runs (four of the semantic task, four of the spatial context task) were acquired using a multi-band multi-echo (MBME) EPI sequence, each approximately 6 min long (repetition time [TR] = 1.5 s; echo time [TEs] = 12, 24.83, 37.66 ms; 48 interleaved slices per volume with slice thickness of 3 mm [no slice gap]; FoV = 24 cm [resolution matrix = 3 × 3 × 3; 80×80]; 75° flip angle; 705 volumes per run [235 TRs with each TR collecting 3 volumes]; 7/8 partial Fourier encoding and GRAPPA [acceleration factor = 3, 36 ref lines; multi-band acceleration factor = 2]). Structural T1-weighted images were acquired using an MPRAGE sequence (TR = 2.3 s, TE = 2.26 s; voxel size = 1 × 1 × 1 isotropic; matrix size = 256 × 256, 176 slices; flip angle = 8°; FoV = 256 mm; ascending slice acquisition ordering).</p></sec><sec id="s4-2-2"><title>Multi-echo data pre-processing</title><p>This study used an MBME scanning sequence to optimise signal from MT regions (e.g. ATL, MTL) while also maintaining optimal signal across the whole brain (<xref ref-type="bibr" rid="bib39">Halai et al., 2014</xref>). We used TE Dependent ANAlysis (TEDANA, version 0.0.10, <ext-link ext-link-type="uri" xlink:href="https://zenodo.org/records/5461803">https://zenodo.org/records/5461803</ext-link>, <ext-link ext-link-type="uri" xlink:href="https://tedana.readthedocs.io/">https://tedana.readthedocs.io/</ext-link>) to combine the images (<xref ref-type="bibr" rid="bib51">Kundu et al., 2013</xref>; <xref ref-type="bibr" rid="bib77">Posse et al., 1999</xref>). Before images were combined, some pre-processing was performed. FSL_anat (<ext-link ext-link-type="uri" xlink:href="https://fsl.fmrib.ox.ac.uk/fsl/fslwiki/fsl_anat">https://fsl.fmrib.ox.ac.uk/fsl/fslwiki/fsl_anat</ext-link>) was used to process the anatomical images, including re-orientation to standard (Montreal Neurological Institute [MNI]) space (fslreorient2std), automatic cropping (robustfov), bias-field correction (RF/B1 – inhomogeneity-correction, using FAST), linear and nonlinear registration to standard-space (using FLIRT and FNIRT), brain extraction (using FNIRT, BET), tissue-type and subcortical structure segmentation (using FAST). The multi-echo data were pre-processed using AFNI (<ext-link ext-link-type="uri" xlink:href="https://afni.nimh.nih.gov/">https://afni.nimh.nih.gov/</ext-link>), including de-spiking (3dDespike), slice timing correction (3dTshift; heptic interpolation), and motion correction of all echoes aligned to the first echo (with a cubic interpolation; 3dvolreg was applied to the first echo to realign all images to the first volume; these transformation parameters were then applied to echoes 2 and 3). The pre-processing script is available at OSF (<ext-link ext-link-type="uri" xlink:href="https://osf.io/sh79m/">https://osf.io/sh79m/</ext-link>).</p></sec><sec id="s4-2-3"><title>Task-based fMRI data analysis</title><p>Further pre-processing of the functional and structural data was carried out using FSL version 6.0 (<xref ref-type="bibr" rid="bib44">Jenkinson et al., 2002</xref>; <xref ref-type="bibr" rid="bib89">Smith et al., 2004</xref>; <xref ref-type="bibr" rid="bib115">Woolrich et al., 2009</xref>). Functional data were pre-processed using FSL’s FMRI Expert Analysis Tool (FEAT). The TEDANA outputs (denoised optimally combined time series) registered to the participants’ native space were submitted to FSL’s FEAT. The first volume of each functional scan was deleted to negate T1 saturation effects. Pre-processing included high-pass temporal filtering (Gaussian-weighted least-squares straight line fitting, with sigma = 50 s), linear co-registration to the corresponding T1-weighted image followed by linear co-registration to MNI152 2 mm standard space (<xref ref-type="bibr" rid="bib43">Jenkinson and Smith, 2001</xref>), which was then further refined using FSL’s FNIRT nonlinear registration (<xref ref-type="bibr" rid="bib3">Andersson et al., 2007a</xref>; <xref ref-type="bibr" rid="bib4">Andersson et al., 2007b</xref>) with 10 mm warp resolution, spatial smoothing using a Gaussian kernel with full-width-half-maximum (FWHM) of 5 mm, and grand-mean intensity normalisation of the entire 4D dataset by a single multiplicative factor.</p></sec><sec id="s4-2-4"><title>Task GLM</title><p>Second and group-level analyses were also conducted using FSL’s FEAT version 6. Pre-processed time series data were modelled using a general linear model (GLM) in FSL, using FILM correcting for local autocorrelation (<xref ref-type="bibr" rid="bib112">Woolrich et al., 2001</xref>). We used an event-related design. Our aim was twofold: (1) to characterise differential activation between the semantic and spatial context tasks at each phase of the trials, and (2) to document any potential differences of activation in response to MCB and SCB trials in probe and decision phases, in each task. To this end, the following eight EVs were entered into a GLM, convolved with a double-gamma haemodynamic response function: the probe, dots and decision phases (only correct responses) were modelled for both MCB and SCB trials (3×2 EVs). Correct decisions made during the arrow task were modelled in a separate EV to use as an explicit baseline. Incorrect and omitted responses in the decision phase, as well as errors made during the arrow task, were combined into a regressor of no interest. The fixation crosses between trials were not explicitly modelled. Probe and dots phases were modelled as fixed-duration epochs, while semantic, spatial context and arrow decisions were modelled using a variable epoch approach, based on each participant’s reaction time on that trial. At the first level, the semantic and spatial context tasks were entered into separate models for each run performed by all participants. We then combined all valid runs for each participant into a participant-level analysis, again separately for each task, at the second level (see ‘Data exclusions’ below for details).</p><p>At the group level, we performed two separate univariate analyses. First, we compared activation for the two tasks, contrasting semantic and spatial context models. Inputs for this analysis were lower-level contrasts of the probe phase of each task against the implicit baseline, and the decision phase of each task contrasted against the explicit baseline of arrow decisions. In our second analysis, we used the same lower-level contrasts but examined the semantic and spatial context tasks separately, examining within-task differences between MCB and SCB trials in the probe and decision phases. This also allowed us to explore interactions between MCB/SCB trials and task. We did not include any motion parameters in the model as the data submitted to these first level analyses had already been denoised as part of the TEDANA pipeline (<xref ref-type="bibr" rid="bib50">Kundu et al., 2012</xref>). At the group level, analyses were carried out using FMRIB’s local analysis of mixed effects (FLAME1) stage 1 with automatic outlier detection (<xref ref-type="bibr" rid="bib9">Beckmann et al., 2003</xref>; <xref ref-type="bibr" rid="bib114">Woolrich, 2008</xref>; <xref ref-type="bibr" rid="bib113">Woolrich et al., 2004</xref>), using a (corrected) cluster significance threshold of p = 0.05, with a z-statistic threshold of 2.6 (<xref ref-type="bibr" rid="bib27">Eklund et al., 2016</xref>) to define contiguous clusters.</p></sec><sec id="s4-2-5"><title>Data exclusions</title><p>We excluded three participants: one due to excessive motion (mean framewise displacement &gt;0.3 mm) in more than 50% of functional runs, another due to misunderstanding the task (0% accuracy in MCB decisions in three out of four runs of the semantic task), and one due to low SCB accuracy in three out of four runs of the spatial context task, with less than 50% of usable data. We also excluded any individual runs where the decision accuracy was equal or below chance level (50%) in the SCB condition. [This threshold was not applied to the MCB condition, which was expected to elicit interference between semantic and spatial context information.] This led to the removal of four runs across three participants in the semantic task, and twelve runs across eight participants in the spatial context task. Two runs were removed due to data loss (a corrupted EV file and data transfer failure from the MRI scanner). 92.5% of the runs acquired were included in the analysis.</p></sec></sec><sec id="s4-3"><title>Study 1: Psychophysiological interaction analysis</title><p>In order to test for distinct semantic and spatial memory pathways that connect visual regions to distinct subnetworks of the DMN, we conducted a PPI supplementary analysis. In short, we created semantic and spatial context seeds from the visual regions activated to object and scene probes, and examined their connectivity to the DMN regions activated during the decision phase of the tasks, using two separate models (one for each seed) which examined the main effect of the task. We describe the methods in detail in the relevant section of the supplementary materials (Supplementary analysis: effects of task demands on pathway connectivity).</p></sec><sec id="s4-4"><title>Study 1: Representational similarity analysis</title><p>Since distinct but adjacent regions were associated with semantic and spatial context decisions, we asked what they represented during probe presentation using RSA. We constructed semantic similarity matrices where trials that shared a specific category (e.g. birds) were assigned the strongest value, and spatial context similarity matrices where pairs of trials belonging to the same room were assigned the strongest value. After single-trial estimation using a least square-single (LSS) approach, we carried out second-order RSA using a searchlight approach to compare semantic and spatial context similarity matrices with neural similarity matrices. This allowed us to identify voxels that were sensitive to semantic and spatial relationships between probes in each of our tasks. We also performed cross-task similarity analysis, correlating semantic similarity to the neural similarity matrix from the spatial context task (and vice versa), to identify regions sensitive to semantic and spatial context information across tasks. We report the methods in detail in the section for this analysis in the supplementary materials (Supplementary analysis: multivariate response to SCB versus MCB).</p></sec><sec id="s4-5"><title>Study 2. Passive viewing of objects and scenes</title><p>We examined passive viewing of objects and scenes in a sample of 52 healthy volunteers, providing independent ROIs for the analyses of Studies 1 and 3.</p><sec id="s4-5-1"><title>Study 2: Participants</title><p>Fifty-two participants with normal, or corrected-to-normal, vision gave informed consent. The study was approved by the Research Ethics Committee at York Neuroimaging Centre.</p></sec><sec id="s4-5-2"><title>Study 2: Stimuli</title><p>Dynamic stimuli were 3 s movie clips of faces, bodies, scenes, objects, and scrambled objects (see <xref ref-type="fig" rid="fig7s2">Figure 7—figure supplement 2</xref>) designed to localise category-selective visual areas (<xref ref-type="bibr" rid="bib73">Pitcher et al., 2011</xref>). Only the scenes and object stimuli were used in the present study. There were 60 movie clips for each category in which distinct exemplars appeared multiple times. Fifteen different locations were used for the scene stimuli which were mostly pastoral scenes shot from a car window while driving slowly through leafy suburbs, along with films flying through canyons or walking through tunnels that were included for variety. Fifteen different moving objects were selected that minimised any suggestion of animacy of the object itself or of a hidden actor pushing the object (these included mobiles, windup toys, toy planes and tractors, balls rolling down sloped inclines). Within each block, stimuli were randomly selected from within the entire set for that stimulus category (faces, bodies, scenes, objects, scrambled objects).</p></sec><sec id="s4-5-3"><title>Study 2: Procedure and data acquisition</title><p>Functional data were acquired over six block-design functional runs lasting 234 s each. Each functional run contained three 18 s rest blocks, at the beginning, middle, and end of the run, during which a series of six uniform colour fields were presented for 3 s. Participants were instructed to watch the movies but were not asked to perform any overt task.</p><p>Imaging data were acquired using a 3T Siemens Magnetom Prisma MRI scanner (Siemens Healthcare, Erlangen, Germany) at the University of York. Functional images were acquired with a 20-channel phased array head coil and a gradient-echo EPI sequence (38 interleaved slices, TR=3 s, TE=30 ms, flip angle = 90%; voxel size 3 mm isotropic; matrix size = 128 × 128) providing whole-brain coverage. Slices were aligned with the anterior to posterior commissure line. Structural images were acquired using the same head coil and a high-resolution T1-weighted 3D fast spoilt gradient (SPGR) sequence (176 interleaved slices, TR=7.8 s, TE=3 ms, flip angle = 20°; voxel size 1 mm isotropic; matrix size = 256 × 256).</p></sec><sec id="s4-5-4"><title>Study 2: Imaging analysis</title><p>fMRI data were analysed using AFNI (<ext-link ext-link-type="uri" xlink:href="http://afni.nimh.nih.gov/afni">http://afni.nimh.nih.gov/afni</ext-link>). Images were slice-time corrected and realigned to the third volume of the first functional run and to the corresponding anatomical scan. All data were motion-corrected and any TRs in which a participant moved more than 0.3 mm in relation to the previous TR were discarded from further analysis. The volume-registered data were spatially smoothed with a 4 mm FWHM Gaussian kernel. Signal intensity was normalised to the mean signal value within each run and multiplied by 100 so that the data represented percent signal change from the mean signal value before analysis.</p><p>Data from all runs were entered into a GLM by convolving the standard haemodynamic response function with the regressors of interest (faces, bodies, scenes, objects, and scrambled objects) for dynamic and static functional runs. Regressors of no interest (e.g. six head movement parameters obtained during volume registration and AFNI’s baseline estimates) were also included in the GLM. Data from all 52 participants were entered in a group whole-brain analysis. Group whole-brain contrasts were generated to quantify the neural responses across the experimental conditions. Scene-selective areas were defined using a contrast of dynamic scenes greater than dynamic objects, and object-selective areas were defined using a contrast of dynamic objects greater than scrambled objects, following convention (<xref ref-type="bibr" rid="bib28">Epstein and Kanwisher, 1998</xref>; <xref ref-type="bibr" rid="bib57">Malach et al., 1995</xref>). Activation maps were calculated using a t-statistical threshold of p=0.001 and a cluster correction of 50 contiguous voxels as these thresholds have been successfully used in other studies to characterise activation in the visual perception literature (e.g. <xref ref-type="bibr" rid="bib69">Nikel et al., 2022</xref>; <xref ref-type="bibr" rid="bib123">Zimmermann et al., 2018</xref>). The whole-brain results are presented in <xref ref-type="fig" rid="fig2s1">Figure 2—figure supplement 1</xref>.</p></sec></sec><sec id="s4-6"><title>Study 3. Analysis of intrinsic functional connectivity using resting-state fMRI</title><p>The results of Study 1 suggested separate visual-DMN pathways recruited by semantic and spatial context tasks. To provide converging evidence for this ‘dual pathway’ architecture, we examined the intrinsic connectivity of sites identified in the univariate and RSA in a separate sample.</p><sec id="s4-6-1"><title>Study 3: Participants</title><p>One hundred and ninety-one student volunteers (mean age = 20.1 ± 2.25 years, range 18–31; 123 females) with normal or corrected-to-normal vision and no history of neurological disorders participated in this study. Written informed consent was obtained from all subjects prior to the resting-state scan. The study was approved by the ethics committees of the Department of Psychology and York Neuroimaging Centre, University of York. This data has been used in previous studies to examine the neural basis of memory and mind-wandering, including ROI-based connectivity analysis and cortical thickness investigations (<xref ref-type="bibr" rid="bib105">Wang et al., 2018a</xref>; <xref ref-type="bibr" rid="bib30">Evans et al., 2020</xref>; <xref ref-type="bibr" rid="bib33">Gonzalez Alam et al., 2018</xref>; <xref ref-type="bibr" rid="bib34">Gonzalez Alam et al., 2019</xref>; <xref ref-type="bibr" rid="bib36">Gonzalez Alam et al., 2022</xref>; <xref ref-type="bibr" rid="bib35">Gonzalez Alam et al., 2021</xref>; <xref ref-type="bibr" rid="bib45">Karapanagiotidis et al., 2017</xref>; <xref ref-type="bibr" rid="bib76">Poerio et al., 2017</xref>; <xref ref-type="bibr" rid="bib98">Turnbull et al., 2019</xref>; <xref ref-type="bibr" rid="bib100">Vatansever et al., 2017</xref>; <xref ref-type="bibr" rid="bib107">Wang et al., 2020</xref>).</p></sec><sec id="s4-6-2"><title>Study 3: Pre-processing</title><p>Pre-processing and statistical analyses of resting-state data were performed using the CONN functional connectivity toolbox V.20a (<ext-link ext-link-type="uri" xlink:href="http://www.nitrc.org/projects/conn">http://www.nitrc.org/projects/conn</ext-link>; <xref ref-type="bibr" rid="bib110">Whitfield-Gabrieli and Nieto-Castanon, 2012</xref>) implemented through SPM (version 12.0) and MATLAB (version 19a). For pre-processing, functional volumes were slice-time (bottom-up, interleaved) and motion-corrected, skull-stripped, and co-registered to the high-resolution structural image, spatially normalised to the MNI space using the unified-segmentation algorithm, smoothed with a 6 mm FWHM Gaussian kernel, and band-pass filtered (0.008–0.09 Hz) to reduce low-frequency drift and noise effects. A pre-processing pipeline of nuisance regression included motion (twelve parameters: the six translation and rotation parameters and their temporal derivatives), scrubbing (outlier volumes were identified through the composite artefact detection algorithm ART in CONN with conservative settings, including scan-by-scan change in global signal z-value threshold = 3; subject motion threshold = 5 mm; differential motion and composite motion exceeding 95% percentile in the normative sample), and CompCor components (the first five) attributable to the signal from white matter and CSF (<xref ref-type="bibr" rid="bib10">Behzadi et al., 2007</xref>), as well as a linear detrending term, eliminating the need for global signal normalisation (<xref ref-type="bibr" rid="bib16">Chai et al., 2012</xref>; <xref ref-type="bibr" rid="bib66">Murphy et al., 2009</xref>).</p></sec><sec id="s4-6-3"><title>Seed selection and analysis</title><p>Intrinsic connectivity seeds were binarised masks derived from: (1) significant univariate clusters; and (2) significant effects identified in RSA. For semantic and spatial probe effects, which characterised effects of visual perception, we created ROIs within <xref ref-type="bibr" rid="bib120">Yeo et al., 2011</xref>, visual central and peripheral networks combined. For semantic and spatial context decisions, we identified regions within <xref ref-type="bibr" rid="bib120">Yeo et al., 2011</xref>, combined DMN subnetworks. We also examined the intrinsic connectivity of regions activated by SCB versus MCB probes in Study 1. For representational similarity analyses, all voxels that survived thresholding at p&lt;0.05 in the MCB conditions for the semantic and context task, as well as the cross-task analyses were binarised and used as seeds. We excluded all non-grey matter voxels that fell within these masks.</p></sec><sec id="s4-6-4"><title>Spatial maps and seed-to-ROI analysis</title><p>We performed seed-to-voxel analyses convolved with a canonical haemodynamic response function for each of these seeds. At the group level, analyses were carried out using CONN with cluster correction at p&lt;0.05, and a threshold of p-FDR=0.001 (two-tailed) to define contiguous clusters. Seed-to-ROI connectivity was extracted for each participant and seed using REX implemented in CONN (<xref ref-type="bibr" rid="bib110">Whitfield-Gabrieli and Nieto-Castanon, 2012</xref>), with percentage signal change as units. These values were then entered into a series of repeated-measures ANOVAs.</p></sec><sec id="s4-6-5"><title>Cognitive decoding</title><p>Connectivity maps were uploaded to Neurovault (<xref ref-type="bibr" rid="bib37">Gorgolewski et al., 2015</xref>; <ext-link ext-link-type="uri" xlink:href="https://neurovault.org/collections/13821/">https://neurovault.org/collections/13821/</ext-link>) and decoded using Neurosynth (<xref ref-type="bibr" rid="bib118">Yarkoni et al., 2011</xref>). Neurosynth is an automated meta-analysis tool that uses text-mining approaches to extract terms from neuroimaging articles that typically co-occur with specific peak coordinates of activation. It can be used to generate a set of terms frequently associated with a spatial map. The results of cognitive decoding were rendered as word clouds using in-house scripts implemented in R. We excluded terms referring to neuroanatomy (e.g. ‘inferior’ or ‘sulcus’), as well as the second occurrence of repeated terms (e.g. ‘semantic’ and ‘semantics’). The size of each word in the word cloud relates to the frequency of that term across studies.</p></sec></sec><sec id="s4-7"><title>Structural connectivity analysis</title><p>To provide converging evidence for parallel visual-to-DMN pathways, we performed tractography analysis using DTI data from an independent sample derived from the HCP.</p><sec id="s4-7-1"><title>DTI pre-processing</title><p>We used data from a subgroup of 164 HCP participants who underwent diffusion-weighted imaging at 3 T (<xref ref-type="bibr" rid="bib99">Uğurbil et al., 2013</xref>; <ext-link ext-link-type="uri" xlink:href="http://www.humanconnectome.org/study/hcp-young-adult/">http://www.humanconnectome.org/study/hcp-young-adult/</ext-link>). The imaging parameters were previously described in <xref ref-type="bibr" rid="bib99">Uğurbil et al., 2013</xref>, involved acquiring 111 near-axial slices with an acceleration factor of 32, an isotropic resolution of 1.25 mm<sup>3</sup>, and coverage of the entire head. The diffusion-weighted images were obtained using 90 uniformly distributed gradients in multiple Q-space shells (<xref ref-type="bibr" rid="bib15">Caruyer et al., 2013</xref>), and this process was repeated three times with different b-values and phase-encoding directions. We used a pre-processed version of this dataset, previously described (<xref ref-type="bibr" rid="bib46">Karolis et al., 2019</xref>; <xref ref-type="bibr" rid="bib97">Thiebaut de Schotten et al., 2020</xref>; <xref ref-type="bibr" rid="bib102">Vu et al., 2015</xref>), that included steps to correct for susceptibility-induced off-resonance field, motion, and geometrical distortion.</p><p>We used StarTrack software (<ext-link ext-link-type="uri" xlink:href="https://www.mr-startrack.com">https://www.mr-startrack.com</ext-link>) to perform whole-brain deterministic tractography in the native DWI space. We applied an algorithm for spherical deconvolutions (damped Richardson-Lucy), with a fixed fibre response corresponding to a shape factor of α=1.5 × 10<sup>–3</sup> mm<sup>2</sup>·s<sup>−1</sup> and a geometric damping parameter of 8. We ran 200 algorithm iterations. The absolute threshold was set at three times the spherical fibre orientation distribution (FOD) of a grey matter isotropic voxel, and the relative threshold was set at 8% of the maximum amplitude of the FOD (<xref ref-type="bibr" rid="bib21">de Schotten et al., 2011</xref>). To perform the whole-brain streamline tractography, we used a modified Euler algorithm (<xref ref-type="bibr" rid="bib22">Dell’Acqua et al., 2013</xref>) with an angle threshold of 45°, a step size of 0.625 mm, and a minimum streamline length of 15 mm.</p><p>To standardise the structural connectome data, we followed these steps: first, we converted the whole-brain streamline tractography into streamline density volumes, with the intensity corresponding to the number of streamlines crossing each voxel. Second, we generated a study-specific template of streamline density volumes using the Greedy symmetric diffeomorphic normalisation pipeline provided by ANTs. This average template was created for all subjects. Third, we co-registered the template with a standard 1 mm MNI152 template using the FLIRT tool in FSL to produce a streamline density template in the MNI152 space. Finally, we registered individual streamline density volumes to the template and applied the same transformation to the individual whole-brain streamline tractography using ANTs GreedySyn and the Trackmath tool in the Tract Querier software package (<xref ref-type="bibr" rid="bib108">Wassermann et al., 2016</xref>). This produced whole-brain streamline tractography in the standard MNI152 space.</p></sec><sec id="s4-7-2"><title>Tract extractions and ROI analysis</title><p>Our starting point for extracting semantic and spatial context pathway tracts was each participant’s whole-brain streamline tractography in MNI (1 mm) space. We used the same univariate regions described in Section 2.3.3 as seeds (i.e. the seeds in the intrinsic connectivity analysis): these consisted of regions that were activated during the probe phase of each task, masked by Yeo’s visual networks, and regions that were activated during the decision phase of each task, masked by Yeo’s DMN. For each of our seeds, we used Trackvis (<xref ref-type="bibr" rid="bib104">Wang and Benner, 2007</xref>) to extract all streamlines emerging from these regions as a volume, yielding one streamline group per seed per participant. Then, for each probe visual seed, we calculated what percentage of streamlines touched one decision DMN ROI or the other (activated by semantic and spatial context decisions; percentages adding to 100%); likewise, for each decision DMN seed, we calculated what percentage of streamlines touched either visual probe ROI (activated by object and scene probes; again adding to 100%). This allowed us to examine if the object probe regions were more connected to the semantic decision DMN regions, and if the scene probe regions were more connected to the spatial context DMN regions, in line with dual pathways.</p></sec></sec><sec id="s4-8"><title>Situating the pathways in whole-brain gradients</title><p>We examined the position of the semantic and context pathways in a functional connectivity space defined by the first two dimensions of whole-brain intrinsic connectivity patterns, frequently referred to as ‘gradients’. The first dimension of this space relates to the distinction between the connectivity patterns of unimodal and heteromodal cortical regions, while the second dimension captures the separation of visual and auditory/somatomotor regions (<xref ref-type="bibr" rid="bib61">Margulies et al., 2016</xref>). This analysis can reveal whether the semantic pathway shows more of a balance between visual and somatosensory/auditory modalities than the spatial context pathway, in line with view that concepts are heteromodal, abstracted from multiple sensory-motor features (<xref ref-type="bibr" rid="bib78">Ralph et al., 2017</xref>). The analysis can also show whether the spatial context pathway is anchored in more visual portions of this functional space, in line with this modality’s importance for scene processing (<xref ref-type="bibr" rid="bib29">Epstein and Baker, 2019</xref>).</p><p>First, we examined the univariate BOLD activation for each participant during the probe and decision phases of each task. The decision phase was contrasted with the arrow task baseline to control for low-level motor responses. Next, we identified the MNI voxel location of the peak response for each participant: for activation during the decision phase, this was done within a mask of the DMN from the <xref ref-type="bibr" rid="bib120">Yeo et al., 2011</xref>, 7-network parcellation, while for probe responses, we performed this analysis within the visual network of the same parcellation. We then fitted a sphere with a 5 mm radius around this peak and used it as a ROI to extract the mean value in <xref ref-type="bibr" rid="bib61">Margulies et al., 2016</xref> maps for the two dimensions or gradients described above. The results were entered into a repeated-measures 2×2 ANOVA with task and gradient as factors to establish whether the semantic and spatial context pathways differed in their location in this functional space.</p></sec><sec id="s4-9"><title>ROI-based ANOVAs</title><p>ROI-based analyses of activation and intrinsic connectivity in Studies 1 and 3 were performed using FSL’s ‘Featquery’ tool for Study 1 and REX for Study 3, which we used to extract the percentage signal change within unweighted, binarised masks. The ANOVAs were carried out using IBM SPSS Statistics version 27. The results of post hoc tests to interpret significant interactions were corrected for multiple comparisons using the Holm-Bonferroni method (<xref ref-type="bibr" rid="bib1">Aickin and Gensler, 1996</xref>). All the p values reported in the Results section are Holm-Bonferroni adjusted p values.</p></sec><sec id="s4-10"><title>Visualisations of neural results</title><p>Brain maps were produced in BrainNet (<xref ref-type="bibr" rid="bib116">Xia et al., 2013</xref>) using the extremum voxel algorithm, with the exception of slices depicted in <xref ref-type="fig" rid="fig2">Figures 2</xref>—<xref ref-type="fig" rid="fig4">4</xref>, which were produced in FSL Eyes (<xref ref-type="fig" rid="fig2">Figures 2</xref> and <xref ref-type="fig" rid="fig3">3</xref>) and MRIcroGL (<xref ref-type="fig" rid="fig4">Figure 4</xref>). Maps are provided in the following Neurovault collection: <ext-link ext-link-type="uri" xlink:href="https://neurovault.org/collections/13821/">https://neurovault.org/collections/13821/</ext-link>.</p></sec></sec></body><back><sec sec-type="additional-information" id="s5"><title>Additional information</title><fn-group content-type="competing-interest"><title>Competing interests</title><fn fn-type="COI-statement" id="conf1"><p>No competing interests declared</p></fn></fn-group><fn-group content-type="author-contribution"><title>Author contributions</title><fn fn-type="con" id="con1"><p>Conceptualization, Resources, Data curation, Software, Formal analysis, Investigation, Visualization, Methodology, Writing – original draft, Project administration, Writing – review and editing</p></fn><fn fn-type="con" id="con2"><p>Data curation, Formal analysis, Methodology</p></fn><fn fn-type="con" id="con3"><p>Conceptualization, Resources, Data curation, Formal analysis, Investigation, Methodology, Writing – original draft</p></fn><fn fn-type="con" id="con4"><p>Conceptualization, Resources, Data curation, Formal analysis, Investigation, Methodology, Writing – original draft, Writing – review and editing</p></fn><fn fn-type="con" id="con5"><p>Conceptualization, Writing – review and editing</p></fn><fn fn-type="con" id="con6"><p>Conceptualization, Writing – review and editing</p></fn><fn fn-type="con" id="con7"><p>Resources, Formal analysis, Investigation, Methodology, Writing – original draft, Writing – review and editing</p></fn><fn fn-type="con" id="con8"><p>Resources, Formal analysis, Investigation, Writing – review and editing</p></fn><fn fn-type="con" id="con9"><p>Resources, Formal analysis, Investigation, Writing – review and editing</p></fn><fn fn-type="con" id="con10"><p>Conceptualization, Resources, Writing – review and editing</p></fn><fn fn-type="con" id="con11"><p>Conceptualization, Resources, Supervision, Writing – review and editing</p></fn><fn fn-type="con" id="con12"><p>Conceptualization, Resources, Formal analysis, Supervision, Funding acquisition, Investigation, Visualization, Methodology, Writing – original draft, Project administration, Writing – review and editing</p></fn></fn-group><fn-group content-type="ethics-information"><title>Ethics</title><fn fn-type="other"><p>Human subjects: Ethical approval was obtained from the Research Ethics Committees of the Department of Psychology and York Neuroimaging Centre, University of York (P1391). Written informed consent was obtained from all subjects prior to testing.</p></fn></fn-group></sec><sec sec-type="supplementary-material" id="s6"><title>Additional files</title><supplementary-material id="mdar"><label>MDAR checklist</label><media xlink:href="elife-94902-mdarchecklist1-v1.docx" mimetype="application" mime-subtype="docx"/></supplementary-material><supplementary-material id="supp1"><label>Supplementary file 1.</label><caption><title>Cluster Information for Neuroimaging Results from Study 1.</title></caption><media xlink:href="elife-94902-supp1-v1.docx" mimetype="application" mime-subtype="docx"/></supplementary-material><supplementary-material id="supp2"><label>Supplementary file 2.</label><caption><title>Paired t-tests contrasting spatial similarity of participant-level activation with group-level context and semantic pathways and non-pathways.</title></caption><media xlink:href="elife-94902-supp2-v1.docx" mimetype="application" mime-subtype="docx"/></supplementary-material></sec><sec sec-type="data-availability" id="s7"><title>Data availability</title><p>The scripts used in the presentation of the task, the analysis of the neuroimaging data and the visualisation of the results reported here can be consulted in the OSF collection associated with this paper (<ext-link ext-link-type="uri" xlink:href="https://osf.io/sh79m/">https://osf.io/sh79m/</ext-link>). We do not have sufficient consent for the public release of individual-level data; researchers wanting access to these data should contact the Research Ethics Committee of the York Neuroimaging Centre (rec-submission@ynic.york.ac.uk). Data will be released when this is possible under the terms of the UK and EU General Data Protection Regulations. Group-level brain maps used to produce the figures are available from the following Neurovault collection: <ext-link ext-link-type="uri" xlink:href="https://neurovault.org/collections/13821/">https://neurovault.org/collections/13821/</ext-link>.</p><p>The following dataset was generated:</p><p><element-citation publication-type="data" specific-use="isSupplementedBy" id="dataset1"><person-group person-group-type="author"><name><surname>Gonzalez-Alam</surname><given-names>TR</given-names></name><name><surname>Jefferies</surname><given-names>B</given-names></name></person-group><year iso-8601-date="2023">2023</year><data-title>Visual to default network pathways: A double dissociation between semantic and spatial cognition</data-title><source>Open Science Framework</source><pub-id pub-id-type="accession" xlink:href="https://osf.io/sh79m/">sh79m</pub-id></element-citation></p></sec><ack id="ack"><title>Acknowledgements</title><p>This project was funded by the European Research Council (ERC) under the European Union’s Horizon 2020 research and innovation programme (Project ID: 771863 – FLEXSEM to EJ; Project ID: 818521 – DISCONNECTOME to MTS; Project ID: 866533 to DSM). Additionally, this work was conducted in the framework of the University of Bordeaux’s IHU ‘Precision &amp; Global Vascular Brain Health Institute – VBHI’, IdEx ‘Investments for the Future’ program RRI 'IMPACT', which received financial support from the France 2030 program.</p></ack><ref-list><title>References</title><ref id="bib1"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Aickin</surname><given-names>M</given-names></name><name><surname>Gensler</surname><given-names>H</given-names></name></person-group><year iso-8601-date="1996">1996</year><article-title>Adjusting for multiple testing when reporting research results: the Bonferroni vs Holm methods</article-title><source>American Journal of Public Health</source><volume>86</volume><fpage>726</fpage><lpage>728</lpage><pub-id pub-id-type="doi">10.2105/ajph.86.5.726</pub-id><pub-id pub-id-type="pmid">8629727</pub-id></element-citation></ref><ref id="bib2"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Anderson</surname><given-names>MJ</given-names></name><name><surname>Robinson</surname><given-names>J</given-names></name></person-group><year iso-8601-date="2001">2001</year><article-title>Permutation tests for linear models</article-title><source>Australian &amp; New Zealand Journal of Statistics</source><volume>43</volume><fpage>75</fpage><lpage>88</lpage><pub-id pub-id-type="doi">10.1111/1467-842X.00156</pub-id></element-citation></ref><ref id="bib3"><element-citation publication-type="report"><person-group person-group-type="author"><name><surname>Andersson</surname><given-names>JLR</given-names></name><name><surname>Jenkinson</surname><given-names>M</given-names></name><name><surname>Smith</surname><given-names>S</given-names></name></person-group><year iso-8601-date="2007">2007a</year><source>Non-linear registration, aka spatial normalization FMRIB technical report TR07JA2</source><publisher-name>FMRIB</publisher-name></element-citation></ref><ref id="bib4"><element-citation publication-type="report"><person-group person-group-type="author"><name><surname>Andersson</surname><given-names>JLR</given-names></name><name><surname>Jenkinson</surname><given-names>M</given-names></name><name><surname>Smith</surname><given-names>SM</given-names></name></person-group><year iso-8601-date="2007">2007b</year><source>Non-linear registration aka spatial normalisation Internal Technical Report TR07JA1</source><publisher-name>Oxford Centre for Functional Magnetic Resonance Imaging of the Brain, Department of Clinical Neurology, Oxford University</publisher-name></element-citation></ref><ref id="bib5"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Andrews-Hanna</surname><given-names>JR</given-names></name><name><surname>Reidler</surname><given-names>JS</given-names></name><name><surname>Huang</surname><given-names>C</given-names></name><name><surname>Buckner</surname><given-names>RL</given-names></name></person-group><year iso-8601-date="2010">2010a</year><article-title>Evidence for the default network’s role in spontaneous cognition</article-title><source>Journal of Neurophysiology</source><volume>104</volume><fpage>322</fpage><lpage>335</lpage><pub-id pub-id-type="doi">10.1152/jn.00830.2009</pub-id><pub-id pub-id-type="pmid">20463201</pub-id></element-citation></ref><ref id="bib6"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Andrews-Hanna</surname><given-names>JR</given-names></name><name><surname>Reidler</surname><given-names>JS</given-names></name><name><surname>Sepulcre</surname><given-names>J</given-names></name><name><surname>Poulin</surname><given-names>R</given-names></name><name><surname>Buckner</surname><given-names>RL</given-names></name></person-group><year iso-8601-date="2010">2010b</year><article-title>Functional-anatomic fractionation of the brain’s default network</article-title><source>Neuron</source><volume>65</volume><fpage>550</fpage><lpage>562</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2010.02.005</pub-id><pub-id pub-id-type="pmid">20188659</pub-id></element-citation></ref><ref id="bib7"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Andrews-Hanna</surname><given-names>JR</given-names></name><name><surname>Smallwood</surname><given-names>J</given-names></name><name><surname>Spreng</surname><given-names>RN</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>The default network and self-generated thought: component processes, dynamic control, and clinical relevance</article-title><source>Annals of the New York Academy of Sciences</source><volume>1316</volume><fpage>29</fpage><lpage>52</lpage><pub-id pub-id-type="doi">10.1111/nyas.12360</pub-id><pub-id pub-id-type="pmid">24502540</pub-id></element-citation></ref><ref id="bib8"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Andrews-Hanna</surname><given-names>JR</given-names></name><name><surname>Grilli</surname><given-names>MD</given-names></name></person-group><year iso-8601-date="2021">2021</year><article-title>Mapping the imaginative mind: charting new paths forward</article-title><source>Current Directions in Psychological Science</source><volume>30</volume><fpage>82</fpage><lpage>89</lpage><pub-id pub-id-type="doi">10.1177/0963721420980753</pub-id></element-citation></ref><ref id="bib9"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Beckmann</surname><given-names>CF</given-names></name><name><surname>Jenkinson</surname><given-names>M</given-names></name><name><surname>Smith</surname><given-names>SM</given-names></name></person-group><year iso-8601-date="2003">2003</year><article-title>General multilevel linear modeling for group analysis in FMRI</article-title><source>NeuroImage</source><volume>20</volume><fpage>1052</fpage><lpage>1063</lpage><pub-id pub-id-type="doi">10.1016/S1053-8119(03)00435-X</pub-id><pub-id pub-id-type="pmid">14568475</pub-id></element-citation></ref><ref id="bib10"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Behzadi</surname><given-names>Y</given-names></name><name><surname>Restom</surname><given-names>K</given-names></name><name><surname>Liau</surname><given-names>J</given-names></name><name><surname>Liu</surname><given-names>TT</given-names></name></person-group><year iso-8601-date="2007">2007</year><article-title>A component based noise correction method (CompCor) for BOLD and perfusion based fMRI</article-title><source>NeuroImage</source><volume>37</volume><fpage>90</fpage><lpage>101</lpage><pub-id pub-id-type="doi">10.1016/j.neuroimage.2007.04.042</pub-id><pub-id pub-id-type="pmid">17560126</pub-id></element-citation></ref><ref id="bib11"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bocca</surname><given-names>F</given-names></name><name><surname>Töllner</surname><given-names>T</given-names></name><name><surname>Müller</surname><given-names>HJ</given-names></name><name><surname>Taylor</surname><given-names>PC</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>The right angular gyrus combines perceptual and response-related expectancies in visual search: TMS-EEG Evidence</article-title><source>Brain Stimulation</source><volume>8</volume><fpage>816</fpage><lpage>822</lpage><pub-id pub-id-type="doi">10.1016/j.brs.2015.02.001</pub-id><pub-id pub-id-type="pmid">25753177</pub-id></element-citation></ref><ref id="bib12"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bonnici</surname><given-names>HM</given-names></name><name><surname>Richter</surname><given-names>FR</given-names></name><name><surname>Yazar</surname><given-names>Y</given-names></name><name><surname>Simons</surname><given-names>JS</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Multimodal feature integration in the angular gyrus during episodic and semantic retrieval</article-title><source>The Journal of Neuroscience</source><volume>36</volume><fpage>5462</fpage><lpage>5471</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.4310-15.2016</pub-id><pub-id pub-id-type="pmid">27194327</pub-id></element-citation></ref><ref id="bib13"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Braga</surname><given-names>RM</given-names></name><name><surname>Buckner</surname><given-names>RL</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>Parallel interdigitated distributed networks within the individual estimated by intrinsic functional connectivity</article-title><source>Neuron</source><volume>95</volume><fpage>457</fpage><lpage>471</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2017.06.038</pub-id></element-citation></ref><ref id="bib14"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Branzi</surname><given-names>FM</given-names></name><name><surname>Humphreys</surname><given-names>GF</given-names></name><name><surname>Hoffman</surname><given-names>P</given-names></name><name><surname>Lambon Ralph</surname><given-names>MA</given-names></name></person-group><year iso-8601-date="2020">2020</year><article-title>Revealing the neural networks that extract conceptual gestalts from continuously evolving or changing semantic contexts</article-title><source>NeuroImage</source><volume>220</volume><elocation-id>116802</elocation-id><pub-id pub-id-type="doi">10.1016/j.neuroimage.2020.116802</pub-id></element-citation></ref><ref id="bib15"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Caruyer</surname><given-names>E</given-names></name><name><surname>Lenglet</surname><given-names>C</given-names></name><name><surname>Sapiro</surname><given-names>G</given-names></name><name><surname>Deriche</surname><given-names>R</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>Design of multishell sampling schemes with uniform coverage in diffusion MRI</article-title><source>Magnetic Resonance in Medicine</source><volume>69</volume><fpage>1534</fpage><lpage>1540</lpage><pub-id pub-id-type="doi">10.1002/mrm.24736</pub-id></element-citation></ref><ref id="bib16"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Chai</surname><given-names>XJ</given-names></name><name><surname>Castañón</surname><given-names>AN</given-names></name><name><surname>Ongür</surname><given-names>D</given-names></name><name><surname>Whitfield-Gabrieli</surname><given-names>S</given-names></name></person-group><year iso-8601-date="2012">2012</year><article-title>Anticorrelations in resting state networks without global signal regression</article-title><source>NeuroImage</source><volume>59</volume><fpage>1420</fpage><lpage>1428</lpage><pub-id pub-id-type="doi">10.1016/j.neuroimage.2011.08.048</pub-id><pub-id pub-id-type="pmid">21889994</pub-id></element-citation></ref><ref id="bib17"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Chiou</surname><given-names>R</given-names></name><name><surname>Lambon Ralph</surname><given-names>MA</given-names></name><name><surname>Ralph</surname><given-names>MAL</given-names></name><name><surname>Lambon Ralph</surname><given-names>MA</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>Unveiling the dynamic interplay between the hub- and spoke-components of the brain’s semantic system and its impact on human behaviour</article-title><source>NeuroImage</source><volume>199</volume><fpage>114</fpage><lpage>126</lpage><pub-id pub-id-type="doi">10.1016/j.neuroimage.2019.05.059</pub-id><pub-id pub-id-type="pmid">31132452</pub-id></element-citation></ref><ref id="bib18"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Chiou</surname><given-names>R</given-names></name><name><surname>Humphreys</surname><given-names>GF</given-names></name><name><surname>Lambon Ralph</surname><given-names>MA</given-names></name></person-group><year iso-8601-date="2020">2020</year><article-title>Bipartite functional fractionation within the default network supports disparate forms of internally oriented cognition</article-title><source>Cerebral Cortex</source><volume>30</volume><fpage>5484</fpage><lpage>5501</lpage></element-citation></ref><ref id="bib19"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>D’Argembeau</surname><given-names>A</given-names></name><name><surname>Stawarczyk</surname><given-names>D</given-names></name><name><surname>Majerus</surname><given-names>S</given-names></name><name><surname>Collette</surname><given-names>F</given-names></name><name><surname>Van der Linden</surname><given-names>M</given-names></name><name><surname>Feyers</surname><given-names>D</given-names></name><name><surname>Maquet</surname><given-names>P</given-names></name><name><surname>Salmon</surname><given-names>E</given-names></name></person-group><year iso-8601-date="2010">2010</year><article-title>The neural basis of personal goal processing when envisioning future events</article-title><source>Journal of Cognitive Neuroscience</source><volume>22</volume><fpage>1701</fpage><lpage>1713</lpage><pub-id pub-id-type="doi">10.1162/jocn.2009.21314</pub-id><pub-id pub-id-type="pmid">19642887</pub-id></element-citation></ref><ref id="bib20"><element-citation publication-type="preprint"><person-group person-group-type="author"><name><surname>Deen</surname><given-names>B</given-names></name><name><surname>Freiwald</surname><given-names>WA</given-names></name></person-group><year iso-8601-date="2021">2021</year><article-title>Parallel systems for social and spatial reasoning within the cortical apex</article-title><source>bioRxiv</source><pub-id pub-id-type="doi">10.1101/2021.09.23.461550</pub-id></element-citation></ref><ref id="bib21"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>de Schotten</surname><given-names>MT</given-names></name><name><surname>Dell’Acqua</surname><given-names>F</given-names></name><name><surname>Forkel</surname><given-names>SJ</given-names></name><name><surname>Simmons</surname><given-names>A</given-names></name><name><surname>Vergani</surname><given-names>F</given-names></name><name><surname>Murphy</surname><given-names>DGM</given-names></name><name><surname>Catani</surname><given-names>M</given-names></name></person-group><year iso-8601-date="2011">2011</year><article-title>A lateralized brain network for visuospatial attention</article-title><source>Nature Neuroscience</source><volume>14</volume><fpage>1245</fpage><lpage>1246</lpage><pub-id pub-id-type="doi">10.1038/nn.2905</pub-id></element-citation></ref><ref id="bib22"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Dell’Acqua</surname><given-names>F</given-names></name><name><surname>Simmons</surname><given-names>A</given-names></name><name><surname>Williams</surname><given-names>SCR</given-names></name><name><surname>Catani</surname><given-names>M</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>Can spherical deconvolution provide more information than fiber orientations? Hindrance modulated orientational anisotropy, a true-tract specific index to characterize white matter diffusion</article-title><source>Human Brain Mapping</source><volume>34</volume><fpage>2464</fpage><lpage>2483</lpage><pub-id pub-id-type="doi">10.1002/hbm.22080</pub-id><pub-id pub-id-type="pmid">22488973</pub-id></element-citation></ref><ref id="bib23"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>DiCarlo</surname><given-names>JJ</given-names></name><name><surname>Zoccolan</surname><given-names>D</given-names></name><name><surname>Rust</surname><given-names>NC</given-names></name></person-group><year iso-8601-date="2012">2012</year><article-title>How does the brain solve visual object recognition?</article-title><source>Neuron</source><volume>73</volume><fpage>415</fpage><lpage>434</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2012.01.010</pub-id><pub-id pub-id-type="pmid">22325196</pub-id></element-citation></ref><ref id="bib24"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>DiNicola</surname><given-names>LM</given-names></name><name><surname>Braga</surname><given-names>RM</given-names></name><name><surname>Buckner</surname><given-names>RL</given-names></name></person-group><year iso-8601-date="2020">2020</year><article-title>Parallel distributed networks dissociate episodic and social functions within the individual</article-title><source>Journal of Neurophysiology</source><volume>123</volume><fpage>1144</fpage><lpage>1179</lpage><pub-id pub-id-type="doi">10.1152/jn.00529.2019</pub-id></element-citation></ref><ref id="bib25"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Eichenbaum</surname><given-names>H</given-names></name></person-group><year iso-8601-date="2004">2004</year><article-title>Hippocampus: cognitive processes and neural representations that underlie declarative memory</article-title><source>Neuron</source><volume>44</volume><fpage>109</fpage><lpage>120</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2004.08.028</pub-id><pub-id pub-id-type="pmid">15450164</pub-id></element-citation></ref><ref id="bib26"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Eichenbaum</surname><given-names>H</given-names></name><name><surname>Cohen</surname><given-names>NJ</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>Can we reconcile the declarative memory and spatial navigation views on hippocampal function?</article-title><source>Neuron</source><volume>83</volume><fpage>764</fpage><lpage>770</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2014.07.032</pub-id></element-citation></ref><ref id="bib27"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Eklund</surname><given-names>A</given-names></name><name><surname>Nichols</surname><given-names>TE</given-names></name><name><surname>Knutsson</surname><given-names>H</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Cluster failure: Why fMRI inferences for spatial extent have inflated false-positive rates</article-title><source>PNAS</source><volume>113</volume><fpage>7900</fpage><lpage>7905</lpage><pub-id pub-id-type="doi">10.1073/pnas.1602413113</pub-id></element-citation></ref><ref id="bib28"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Epstein</surname><given-names>R</given-names></name><name><surname>Kanwisher</surname><given-names>N</given-names></name></person-group><year iso-8601-date="1998">1998</year><article-title>A cortical representation of the local visual environment</article-title><source>Nature</source><volume>392</volume><fpage>598</fpage><lpage>601</lpage><pub-id pub-id-type="doi">10.1038/33402</pub-id><pub-id pub-id-type="pmid">9560155</pub-id></element-citation></ref><ref id="bib29"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Epstein</surname><given-names>RA</given-names></name><name><surname>Baker</surname><given-names>CI</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>Scene perception in the human brain</article-title><source>Annual Review of Vision Science</source><volume>5</volume><fpage>373</fpage><lpage>397</lpage><pub-id pub-id-type="doi">10.1146/annurev-vision-091718-014809</pub-id><pub-id pub-id-type="pmid">31226012</pub-id></element-citation></ref><ref id="bib30"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Evans</surname><given-names>M</given-names></name><name><surname>Krieger-Redwood</surname><given-names>K</given-names></name><name><surname>Gonzalez Alam</surname><given-names>TRJ</given-names></name><name><surname>Smallwood</surname><given-names>J</given-names></name><name><surname>Jefferies</surname><given-names>E</given-names></name></person-group><year iso-8601-date="2020">2020</year><article-title>Controlled semantic summation correlates with intrinsic connectivity between default mode and control networks</article-title><source>Cortex; a Journal Devoted to the Study of the Nervous System and Behavior</source><volume>129</volume><fpage>356</fpage><lpage>375</lpage><pub-id pub-id-type="doi">10.1016/j.cortex.2020.04.032</pub-id><pub-id pub-id-type="pmid">32569945</pub-id></element-citation></ref><ref id="bib31"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Fairhall</surname><given-names>SL</given-names></name><name><surname>Caramazza</surname><given-names>A</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>Brain regions that represent amodal conceptual knowledge</article-title><source>The Journal of Neuroscience</source><volume>33</volume><fpage>10552</fpage><lpage>10558</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.0051-13.2013</pub-id><pub-id pub-id-type="pmid">23785167</pub-id></element-citation></ref><ref id="bib32"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Gao</surname><given-names>Z</given-names></name><name><surname>Zheng</surname><given-names>L</given-names></name><name><surname>Gouws</surname><given-names>A</given-names></name><name><surname>Krieger-Redwood</surname><given-names>K</given-names></name><name><surname>Wang</surname><given-names>X</given-names></name><name><surname>Varga</surname><given-names>D</given-names></name><name><surname>Smallwood</surname><given-names>J</given-names></name><name><surname>Jefferies</surname><given-names>E</given-names></name></person-group><year iso-8601-date="2022">2022</year><article-title>Context free and context-dependent conceptual representation in the brain</article-title><source>Cerebral Cortex</source><volume>33</volume><fpage>152</fpage><lpage>166</lpage><pub-id pub-id-type="doi">10.1093/cercor/bhac058</pub-id><pub-id pub-id-type="pmid">35196710</pub-id></element-citation></ref><ref id="bib33"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Gonzalez Alam</surname><given-names>T</given-names></name><name><surname>Murphy</surname><given-names>C</given-names></name><name><surname>Smallwood</surname><given-names>J</given-names></name><name><surname>Jefferies</surname><given-names>E</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>Meaningful inhibition: exploring the role of meaning and modality in response inhibition</article-title><source>NeuroImage</source><volume>181</volume><fpage>108</fpage><lpage>119</lpage><pub-id pub-id-type="doi">10.1016/j.neuroimage.2018.06.074</pub-id><pub-id pub-id-type="pmid">29964188</pub-id></element-citation></ref><ref id="bib34"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Gonzalez Alam</surname><given-names>TR</given-names></name><name><surname>Karapanagiotidis</surname><given-names>T</given-names></name><name><surname>Smallwood</surname><given-names>J</given-names></name><name><surname>Jefferies</surname><given-names>E</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>Degrees of lateralisation in semantic cognition: evidence from intrinsic connectivity</article-title><source>NeuroImage</source><volume>202</volume><elocation-id>116089</elocation-id><pub-id pub-id-type="doi">10.1016/j.neuroimage.2019.116089</pub-id></element-citation></ref><ref id="bib35"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Gonzalez Alam</surname><given-names>TRJ</given-names></name><name><surname>Krieger-Redwood</surname><given-names>K</given-names></name><name><surname>Evans</surname><given-names>M</given-names></name><name><surname>Rice</surname><given-names>GE</given-names></name><name><surname>Smallwood</surname><given-names>J</given-names></name><name><surname>Jefferies</surname><given-names>E</given-names></name></person-group><year iso-8601-date="2021">2021</year><article-title>Intrinsic connectivity of anterior temporal lobe relates to individual differences in semantic retrieval for landmarks</article-title><source>Cortex</source><volume>134</volume><fpage>76</fpage><lpage>91</lpage><pub-id pub-id-type="doi">10.1016/j.cortex.2020.10.007</pub-id></element-citation></ref><ref id="bib36"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Gonzalez Alam</surname><given-names>TRDJ</given-names></name><name><surname>Mckeown</surname><given-names>BLA</given-names></name><name><surname>Gao</surname><given-names>Z</given-names></name><name><surname>Bernhardt</surname><given-names>B</given-names></name><name><surname>Vos de Wael</surname><given-names>R</given-names></name><name><surname>Margulies</surname><given-names>DS</given-names></name><name><surname>Smallwood</surname><given-names>J</given-names></name><name><surname>Jefferies</surname><given-names>E</given-names></name></person-group><year iso-8601-date="2022">2022</year><article-title>A tale of two gradients: differences between the left and right hemispheres predict semantic cognition</article-title><source>Brain Structure &amp; Function</source><volume>227</volume><fpage>631</fpage><lpage>654</lpage><pub-id pub-id-type="doi">10.1007/s00429-021-02374-w</pub-id><pub-id pub-id-type="pmid">34510282</pub-id></element-citation></ref><ref id="bib37"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Gorgolewski</surname><given-names>KJ</given-names></name><name><surname>Varoquaux</surname><given-names>G</given-names></name><name><surname>Rivera</surname><given-names>G</given-names></name><name><surname>Schwarz</surname><given-names>Y</given-names></name><name><surname>Ghosh</surname><given-names>SS</given-names></name><name><surname>Maumet</surname><given-names>C</given-names></name><name><surname>Sochat</surname><given-names>VV</given-names></name><name><surname>Nichols</surname><given-names>TE</given-names></name><name><surname>Poldrack</surname><given-names>RA</given-names></name><name><surname>Poline</surname><given-names>JB</given-names></name><name><surname>Yarkoni</surname><given-names>T</given-names></name><name><surname>Margulies</surname><given-names>DS</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>NeuroVault.org: a web-based repository for collecting and sharing unthresholded statistical maps of the human brain</article-title><source>Frontiers in Neuroinformatics</source><volume>9</volume><elocation-id>8</elocation-id><pub-id pub-id-type="doi">10.3389/fninf.2015.00008</pub-id><pub-id pub-id-type="pmid">25914639</pub-id></element-citation></ref><ref id="bib38"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Gronau</surname><given-names>N</given-names></name><name><surname>Neta</surname><given-names>M</given-names></name><name><surname>Bar</surname><given-names>M</given-names></name></person-group><year iso-8601-date="2008">2008</year><article-title>Integrated contextual representation for objects’ identities and their locations</article-title><source>Journal of Cognitive Neuroscience</source><volume>20</volume><fpage>371</fpage><lpage>388</lpage><pub-id pub-id-type="doi">10.1162/jocn.2008.20027</pub-id><pub-id pub-id-type="pmid">18004950</pub-id></element-citation></ref><ref id="bib39"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Halai</surname><given-names>AD</given-names></name><name><surname>Welbourne</surname><given-names>SR</given-names></name><name><surname>Embleton</surname><given-names>K</given-names></name><name><surname>Parkes</surname><given-names>LM</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>A comparison of dual gradient-echo and spin-echo fMRI of the inferior temporal lobe</article-title><source>Human Brain Mapping</source><volume>35</volume><fpage>4118</fpage><lpage>4128</lpage><pub-id pub-id-type="doi">10.1002/hbm.22463</pub-id><pub-id pub-id-type="pmid">24677506</pub-id></element-citation></ref><ref id="bib40"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hassabis</surname><given-names>D</given-names></name><name><surname>Kumaran</surname><given-names>D</given-names></name><name><surname>Maguire</surname><given-names>EA</given-names></name></person-group><year iso-8601-date="2007">2007</year><article-title>Using imagination to understand the neural basis of episodic memory</article-title><source>The Journal of Neuroscience</source><volume>27</volume><fpage>14365</fpage><lpage>14374</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.4549-07.2007</pub-id><pub-id pub-id-type="pmid">18160644</pub-id></element-citation></ref><ref id="bib41"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hasson</surname><given-names>U</given-names></name><name><surname>Levy</surname><given-names>I</given-names></name><name><surname>Behrmann</surname><given-names>M</given-names></name><name><surname>Hendler</surname><given-names>T</given-names></name><name><surname>Malach</surname><given-names>R</given-names></name></person-group><year iso-8601-date="2002">2002</year><article-title>Eccentricity bias as an organizing principle for human high-order object areas</article-title><source>Neuron</source><volume>34</volume><fpage>479</fpage><lpage>490</lpage><pub-id pub-id-type="doi">10.1016/s0896-6273(02)00662-1</pub-id><pub-id pub-id-type="pmid">11988177</pub-id></element-citation></ref><ref id="bib42"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Humphreys</surname><given-names>GF</given-names></name><name><surname>Lambon Ralph</surname><given-names>MA</given-names></name><name><surname>Simons</surname><given-names>JS</given-names></name></person-group><year iso-8601-date="2021">2021</year><article-title>A unifying account of angular gyrus contributions to episodic and semantic cognition</article-title><source>Trends in Neurosciences</source><volume>44</volume><fpage>452</fpage><lpage>463</lpage><pub-id pub-id-type="doi">10.1016/j.tins.2021.01.006</pub-id><pub-id pub-id-type="pmid">33612312</pub-id></element-citation></ref><ref id="bib43"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Jenkinson</surname><given-names>M</given-names></name><name><surname>Smith</surname><given-names>S</given-names></name></person-group><year iso-8601-date="2001">2001</year><article-title>A global optimisation method for robust affine registration of brain images</article-title><source>Medical Image Analysis</source><volume>5</volume><fpage>143</fpage><lpage>156</lpage><pub-id pub-id-type="doi">10.1016/s1361-8415(01)00036-6</pub-id><pub-id pub-id-type="pmid">11516708</pub-id></element-citation></ref><ref id="bib44"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Jenkinson</surname><given-names>M</given-names></name><name><surname>Bannister</surname><given-names>P</given-names></name><name><surname>Brady</surname><given-names>M</given-names></name><name><surname>Smith</surname><given-names>S</given-names></name></person-group><year iso-8601-date="2002">2002</year><article-title>Improved optimization for the robust and accurate linear registration and motion correction of brain images</article-title><source>NeuroImage</source><volume>17</volume><fpage>825</fpage><lpage>841</lpage><pub-id pub-id-type="doi">10.1016/s1053-8119(02)91132-8</pub-id><pub-id pub-id-type="pmid">12377157</pub-id></element-citation></ref><ref id="bib45"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Karapanagiotidis</surname><given-names>T</given-names></name><name><surname>Bernhardt</surname><given-names>BC</given-names></name><name><surname>Jefferies</surname><given-names>E</given-names></name><name><surname>Smallwood</surname><given-names>J</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>Tracking thoughts: Exploring the neural architecture of mental time travel during mind-wandering</article-title><source>NeuroImage</source><volume>147</volume><fpage>272</fpage><lpage>281</lpage><pub-id pub-id-type="doi">10.1016/j.neuroimage.2016.12.031</pub-id></element-citation></ref><ref id="bib46"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Karolis</surname><given-names>VR</given-names></name><name><surname>Corbetta</surname><given-names>M</given-names></name><name><surname>Thiebaut de Schotten</surname><given-names>M</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>The architecture of functional lateralisation and its relationship to callosal connectivity in the human brain</article-title><source>Nature Communications</source><volume>10</volume><elocation-id>1417</elocation-id><pub-id pub-id-type="doi">10.1038/s41467-019-09344-1</pub-id><pub-id pub-id-type="pmid">30926845</pub-id></element-citation></ref><ref id="bib47"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Knapen</surname><given-names>T</given-names></name></person-group><year iso-8601-date="2021">2021</year><article-title>Topographic connectivity reveals task-dependent retinotopic processing throughout the human brain</article-title><source>PNAS</source><volume>118</volume><fpage>1</fpage><lpage>6</lpage><pub-id pub-id-type="doi">10.1073/pnas.2017032118</pub-id></element-citation></ref><ref id="bib48"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kravitz</surname><given-names>DJ</given-names></name><name><surname>Saleem</surname><given-names>KS</given-names></name><name><surname>Baker</surname><given-names>CI</given-names></name><name><surname>Mishkin</surname><given-names>M</given-names></name></person-group><year iso-8601-date="2011">2011</year><article-title>A new neural framework for visuospatial processing</article-title><source>Nature Reviews. Neuroscience</source><volume>12</volume><fpage>217</fpage><lpage>230</lpage><pub-id pub-id-type="doi">10.1038/nrn3008</pub-id><pub-id pub-id-type="pmid">21415848</pub-id></element-citation></ref><ref id="bib49"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kravitz</surname><given-names>DJ</given-names></name><name><surname>Saleem</surname><given-names>KS</given-names></name><name><surname>Baker</surname><given-names>CI</given-names></name><name><surname>Ungerleider</surname><given-names>LG</given-names></name><name><surname>Mishkin</surname><given-names>M</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>The ventral visual pathway: an expanded neural framework for the processing of object quality</article-title><source>Trends in Cognitive Sciences</source><volume>17</volume><fpage>26</fpage><lpage>49</lpage><pub-id pub-id-type="doi">10.1016/j.tics.2012.10.011</pub-id><pub-id pub-id-type="pmid">23265839</pub-id></element-citation></ref><ref id="bib50"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kundu</surname><given-names>P</given-names></name><name><surname>Inati</surname><given-names>SJ</given-names></name><name><surname>Evans</surname><given-names>JW</given-names></name><name><surname>Luh</surname><given-names>WM</given-names></name><name><surname>Bandettini</surname><given-names>PA</given-names></name></person-group><year iso-8601-date="2012">2012</year><article-title>Differentiating BOLD and non-BOLD signals in fMRI time series using multi-echo EPI</article-title><source>NeuroImage</source><volume>60</volume><fpage>1759</fpage><lpage>1770</lpage><pub-id pub-id-type="doi">10.1016/j.neuroimage.2011.12.028</pub-id><pub-id pub-id-type="pmid">22209809</pub-id></element-citation></ref><ref id="bib51"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kundu</surname><given-names>P</given-names></name><name><surname>Brenowitz</surname><given-names>ND</given-names></name><name><surname>Voon</surname><given-names>V</given-names></name><name><surname>Worbe</surname><given-names>Y</given-names></name><name><surname>Vértes</surname><given-names>PE</given-names></name><name><surname>Inati</surname><given-names>SJ</given-names></name><name><surname>Saad</surname><given-names>ZS</given-names></name><name><surname>Bandettini</surname><given-names>PA</given-names></name><name><surname>Bullmore</surname><given-names>ET</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>Integrated strategy for improving functional connectivity mapping using multiecho fMRI</article-title><source>PNAS</source><volume>110</volume><fpage>16187</fpage><lpage>16192</lpage><pub-id pub-id-type="doi">10.1073/pnas.1301725110</pub-id><pub-id pub-id-type="pmid">24038744</pub-id></element-citation></ref><ref id="bib52"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Lanzoni</surname><given-names>L</given-names></name><name><surname>Ravasio</surname><given-names>D</given-names></name><name><surname>Thompson</surname><given-names>H</given-names></name><name><surname>Vatansever</surname><given-names>D</given-names></name><name><surname>Margulies</surname><given-names>D</given-names></name><name><surname>Smallwood</surname><given-names>J</given-names></name><name><surname>Jefferies</surname><given-names>E</given-names></name></person-group><year iso-8601-date="2020">2020</year><article-title>The role of default mode network in semantic cue integration</article-title><source>NeuroImage</source><volume>219</volume><elocation-id>117019</elocation-id><pub-id pub-id-type="doi">10.1016/j.neuroimage.2020.117019</pub-id></element-citation></ref><ref id="bib53"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Leech</surname><given-names>R</given-names></name><name><surname>Braga</surname><given-names>R</given-names></name><name><surname>Sharp</surname><given-names>DJ</given-names></name></person-group><year iso-8601-date="2012">2012</year><article-title>Echoes of the brain within the posterior cingulate cortex</article-title><source>The Journal of Neuroscience</source><volume>32</volume><fpage>215</fpage><lpage>222</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.3689-11.2012</pub-id><pub-id pub-id-type="pmid">22219283</pub-id></element-citation></ref><ref id="bib54"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Leshinskaya</surname><given-names>A</given-names></name><name><surname>Contreras</surname><given-names>JM</given-names></name><name><surname>Caramazza</surname><given-names>A</given-names></name><name><surname>Mitchell</surname><given-names>JP</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>Neural representations of belief concepts: a representational similarity approach to social semantics</article-title><source>Cerebral Cortex</source><volume>27</volume><fpage>344</fpage><lpage>357</lpage><pub-id pub-id-type="doi">10.1093/cercor/bhw401</pub-id><pub-id pub-id-type="pmid">28108495</pub-id></element-citation></ref><ref id="bib55"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Levy</surname><given-names>R</given-names></name><name><surname>Goldman-Rakic</surname><given-names>PS</given-names></name></person-group><year iso-8601-date="2000">2000</year><chapter-title>Segregation of working memory functions within the dorsolateral prefrontal cortex BT - executive control and the frontal lobe: current issues</chapter-title><person-group person-group-type="editor"><name><surname>Schneider</surname><given-names>WX</given-names></name><name><surname>Owen</surname><given-names>AM</given-names></name><name><surname>Duncan</surname><given-names>J</given-names></name></person-group><source>Section of Neurobiology</source><publisher-name>Springer</publisher-name><fpage>23</fpage><lpage>32</lpage><pub-id pub-id-type="doi">10.1007/978-3-642-59794-7_4</pub-id></element-citation></ref><ref id="bib56"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Levy</surname><given-names>I</given-names></name><name><surname>Hasson</surname><given-names>U</given-names></name><name><surname>Avidan</surname><given-names>G</given-names></name><name><surname>Hendler</surname><given-names>T</given-names></name><name><surname>Malach</surname><given-names>R</given-names></name></person-group><year iso-8601-date="2001">2001</year><article-title>Center-periphery organization of human object areas</article-title><source>Nature Neuroscience</source><volume>4</volume><fpage>533</fpage><lpage>539</lpage><pub-id pub-id-type="doi">10.1038/87490</pub-id><pub-id pub-id-type="pmid">11319563</pub-id></element-citation></ref><ref id="bib57"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Malach</surname><given-names>R</given-names></name><name><surname>Reppas</surname><given-names>JB</given-names></name><name><surname>Benson</surname><given-names>RR</given-names></name><name><surname>Kwong</surname><given-names>KK</given-names></name><name><surname>Jiang</surname><given-names>H</given-names></name><name><surname>Kennedy</surname><given-names>WA</given-names></name><name><surname>Ledden</surname><given-names>PJ</given-names></name><name><surname>Brady</surname><given-names>TJ</given-names></name><name><surname>Rosen</surname><given-names>BR</given-names></name><name><surname>Tootell</surname><given-names>RBH</given-names></name></person-group><year iso-8601-date="1995">1995</year><article-title>Object-related activity revealed by functional magnetic resonance imaging in human occipital cortex</article-title><source>PNAS</source><volume>92</volume><fpage>8135</fpage><lpage>8139</lpage><pub-id pub-id-type="doi">10.1073/pnas.92.18.8135</pub-id><pub-id pub-id-type="pmid">7667258</pub-id></element-citation></ref><ref id="bib58"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Malach</surname><given-names>R</given-names></name><name><surname>Levy</surname><given-names>I</given-names></name><name><surname>Hasson</surname><given-names>U</given-names></name></person-group><year iso-8601-date="2002">2002</year><article-title>The topography of high-order human object areas</article-title><source>Trends in Cognitive Sciences</source><volume>6</volume><fpage>176</fpage><lpage>184</lpage><pub-id pub-id-type="doi">10.1016/s1364-6613(02)01870-3</pub-id><pub-id pub-id-type="pmid">11912041</pub-id></element-citation></ref><ref id="bib59"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Malone</surname><given-names>PS</given-names></name><name><surname>Glezer</surname><given-names>LS</given-names></name><name><surname>Kim</surname><given-names>J</given-names></name><name><surname>Jiang</surname><given-names>X</given-names></name><name><surname>Riesenhuber</surname><given-names>M</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Multivariate pattern analysis reveals category-related organization of semantic representations in anterior temporal cortex</article-title><source>The Journal of Neuroscience</source><volume>36</volume><fpage>10089</fpage><lpage>10096</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.1599-16.2016</pub-id><pub-id pub-id-type="pmid">27683905</pub-id></element-citation></ref><ref id="bib60"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Margulies</surname><given-names>DS</given-names></name><name><surname>Vincent</surname><given-names>JL</given-names></name><name><surname>Kelly</surname><given-names>C</given-names></name><name><surname>Lohmann</surname><given-names>G</given-names></name><name><surname>Uddin</surname><given-names>LQ</given-names></name><name><surname>Biswal</surname><given-names>BB</given-names></name><name><surname>Villringer</surname><given-names>A</given-names></name><name><surname>Castellanos</surname><given-names>FX</given-names></name><name><surname>Milham</surname><given-names>MP</given-names></name><name><surname>Petrides</surname><given-names>M</given-names></name></person-group><year iso-8601-date="2009">2009</year><article-title>Precuneus shares intrinsic functional architecture in humans and monkeys</article-title><source>PNAS</source><volume>106</volume><fpage>20069</fpage><lpage>20074</lpage><pub-id pub-id-type="doi">10.1073/pnas.0905314106</pub-id><pub-id pub-id-type="pmid">19903877</pub-id></element-citation></ref><ref id="bib61"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Margulies</surname><given-names>DS</given-names></name><name><surname>Ghosh</surname><given-names>SS</given-names></name><name><surname>Goulas</surname><given-names>A</given-names></name><name><surname>Falkiewicz</surname><given-names>M</given-names></name><name><surname>Huntenburg</surname><given-names>JM</given-names></name><name><surname>Langs</surname><given-names>G</given-names></name><name><surname>Bezgin</surname><given-names>G</given-names></name><name><surname>Eickhoff</surname><given-names>SB</given-names></name><name><surname>Castellanos</surname><given-names>FX</given-names></name><name><surname>Petrides</surname><given-names>M</given-names></name><name><surname>Jefferies</surname><given-names>E</given-names></name><name><surname>Smallwood</surname><given-names>J</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Situating the default-mode network along a principal gradient of macroscale cortical organization</article-title><source>PNAS</source><volume>113</volume><fpage>12574</fpage><lpage>12579</lpage><pub-id pub-id-type="doi">10.1073/pnas.1608282113</pub-id></element-citation></ref><ref id="bib62"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>McKyton</surname><given-names>A</given-names></name><name><surname>Zohary</surname><given-names>E</given-names></name></person-group><year iso-8601-date="2007">2007</year><article-title>Beyond retinotopic mapping: the spatial representation of objects in the human lateral occipital complex</article-title><source>Cerebral Cortex</source><volume>17</volume><fpage>1164</fpage><lpage>1172</lpage><pub-id pub-id-type="doi">10.1093/cercor/bhl027</pub-id><pub-id pub-id-type="pmid">16818474</pub-id></element-citation></ref><ref id="bib63"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>McLaren</surname><given-names>DG</given-names></name><name><surname>Ries</surname><given-names>ML</given-names></name><name><surname>Xu</surname><given-names>G</given-names></name><name><surname>Johnson</surname><given-names>SC</given-names></name></person-group><year iso-8601-date="2012">2012</year><article-title>A generalized form of context-dependent psychophysiological interactions (gPPI): A comparison to standard approaches</article-title><source>NeuroImage</source><volume>61</volume><fpage>1277</fpage><lpage>1286</lpage><pub-id pub-id-type="doi">10.1016/j.neuroimage.2012.03.068</pub-id><pub-id pub-id-type="pmid">22484411</pub-id></element-citation></ref><ref id="bib64"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Muggleton</surname><given-names>NG</given-names></name><name><surname>Cowey</surname><given-names>A</given-names></name><name><surname>Walsh</surname><given-names>V</given-names></name></person-group><year iso-8601-date="2008">2008</year><article-title>The role of the angular gyrus in visual conjunction search investigated using signal detection analysis and transcranial magnetic stimulation</article-title><source>Neuropsychologia</source><volume>46</volume><fpage>2198</fpage><lpage>2202</lpage><pub-id pub-id-type="doi">10.1016/j.neuropsychologia.2008.02.016</pub-id><pub-id pub-id-type="pmid">18394659</pub-id></element-citation></ref><ref id="bib65"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Mumford</surname><given-names>JA</given-names></name><name><surname>Turner</surname><given-names>BO</given-names></name><name><surname>Ashby</surname><given-names>FG</given-names></name><name><surname>Poldrack</surname><given-names>RA</given-names></name></person-group><year iso-8601-date="2012">2012</year><article-title>Deconvolving BOLD activation in event-related designs for multivoxel pattern classification analyses</article-title><source>NeuroImage</source><volume>59</volume><fpage>2636</fpage><lpage>2643</lpage><pub-id pub-id-type="doi">10.1016/j.neuroimage.2011.08.076</pub-id><pub-id pub-id-type="pmid">21924359</pub-id></element-citation></ref><ref id="bib66"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Murphy</surname><given-names>K</given-names></name><name><surname>Birn</surname><given-names>RM</given-names></name><name><surname>Handwerker</surname><given-names>DA</given-names></name><name><surname>Jones</surname><given-names>TB</given-names></name><name><surname>Bandettini</surname><given-names>PA</given-names></name></person-group><year iso-8601-date="2009">2009</year><article-title>The impact of global signal regression on resting state correlations: are anti-correlated networks introduced?</article-title><source>NeuroImage</source><volume>44</volume><fpage>893</fpage><lpage>905</lpage><pub-id pub-id-type="doi">10.1016/j.neuroimage.2008.09.036</pub-id><pub-id pub-id-type="pmid">18976716</pub-id></element-citation></ref><ref id="bib67"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Murphy</surname><given-names>C</given-names></name><name><surname>Jefferies</surname><given-names>E</given-names></name><name><surname>Rueschemeyer</surname><given-names>S-A</given-names></name><name><surname>Sormaz</surname><given-names>M</given-names></name><name><surname>Wang</surname><given-names>H-T</given-names></name><name><surname>Margulies</surname><given-names>DS</given-names></name><name><surname>Smallwood</surname><given-names>J</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>Distant from input: evidence of regions within the default mode network supporting perceptually-decoupled and conceptually-guided cognition</article-title><source>NeuroImage</source><volume>171</volume><fpage>393</fpage><lpage>401</lpage><pub-id pub-id-type="doi">10.1016/j.neuroimage.2018.01.017</pub-id><pub-id pub-id-type="pmid">29339310</pub-id></element-citation></ref><ref id="bib68"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Murphy</surname><given-names>C</given-names></name><name><surname>Wang</surname><given-names>HT</given-names></name><name><surname>Konu</surname><given-names>D</given-names></name><name><surname>Lowndes</surname><given-names>R</given-names></name><name><surname>Margulies</surname><given-names>DS</given-names></name><name><surname>Jefferies</surname><given-names>E</given-names></name><name><surname>Smallwood</surname><given-names>J</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>Modes of operation: A topographic neural gradient supporting stimulus dependent and independent cognition</article-title><source>NeuroImage</source><volume>186</volume><fpage>487</fpage><lpage>496</lpage><pub-id pub-id-type="doi">10.1016/j.neuroimage.2018.11.009</pub-id><pub-id pub-id-type="pmid">30447291</pub-id></element-citation></ref><ref id="bib69"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Nikel</surname><given-names>L</given-names></name><name><surname>Sliwinska</surname><given-names>MW</given-names></name><name><surname>Kucuk</surname><given-names>E</given-names></name><name><surname>Ungerleider</surname><given-names>LG</given-names></name><name><surname>Pitcher</surname><given-names>D</given-names></name></person-group><year iso-8601-date="2022">2022</year><article-title>Measuring the response to visually presented faces in the human lateral prefrontal cortex</article-title><source>Cerebral Cortex Communications</source><volume>3</volume><elocation-id>tgac036</elocation-id><pub-id pub-id-type="doi">10.1093/texcom/tgac036</pub-id><pub-id pub-id-type="pmid">36159205</pub-id></element-citation></ref><ref id="bib70"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Olk</surname><given-names>B</given-names></name><name><surname>Peschke</surname><given-names>C</given-names></name><name><surname>Hilgetag</surname><given-names>CC</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>Attention and control of manual responses in cognitive conflict: findings from TMS perturbation studies</article-title><source>Neuropsychologia</source><volume>74</volume><fpage>7</fpage><lpage>20</lpage><pub-id pub-id-type="doi">10.1016/j.neuropsychologia.2015.02.008</pub-id><pub-id pub-id-type="pmid">25661841</pub-id></element-citation></ref><ref id="bib71"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Petitet</surname><given-names>P</given-names></name><name><surname>Noonan</surname><given-names>MP</given-names></name><name><surname>Bridge</surname><given-names>H</given-names></name><name><surname>O’Reilly</surname><given-names>JX</given-names></name><name><surname>O’Shea</surname><given-names>J</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>Testing the inter-hemispheric competition account of visual extinction with combined TMS/fMRI</article-title><source>Neuropsychologia</source><volume>74</volume><fpage>63</fpage><lpage>73</lpage><pub-id pub-id-type="doi">10.1016/j.neuropsychologia.2015.04.021</pub-id><pub-id pub-id-type="pmid">25911128</pub-id></element-citation></ref><ref id="bib72"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Philippi</surname><given-names>CL</given-names></name><name><surname>Tranel</surname><given-names>D</given-names></name><name><surname>Duff</surname><given-names>M</given-names></name><name><surname>Rudrauf</surname><given-names>D</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>Damage to the default mode network disrupts autobiographical memory retrieval</article-title><source>Social Cognitive and Affective Neuroscience</source><volume>10</volume><fpage>318</fpage><lpage>326</lpage><pub-id pub-id-type="doi">10.1093/scan/nsu070</pub-id><pub-id pub-id-type="pmid">24795444</pub-id></element-citation></ref><ref id="bib73"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Pitcher</surname><given-names>D</given-names></name><name><surname>Dilks</surname><given-names>DD</given-names></name><name><surname>Saxe</surname><given-names>RR</given-names></name><name><surname>Triantafyllou</surname><given-names>C</given-names></name><name><surname>Kanwisher</surname><given-names>N</given-names></name></person-group><year iso-8601-date="2011">2011</year><article-title>Differential selectivity for dynamic versus static information in face-selective cortical regions</article-title><source>NeuroImage</source><volume>56</volume><fpage>2356</fpage><lpage>2363</lpage><pub-id pub-id-type="doi">10.1016/j.neuroimage.2011.03.067</pub-id><pub-id pub-id-type="pmid">21473921</pub-id></element-citation></ref><ref id="bib74"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Pitcher</surname><given-names>D</given-names></name><name><surname>Ungerleider</surname><given-names>LG</given-names></name></person-group><year iso-8601-date="2021">2021</year><article-title>Evidence for a third visual pathway specialized for social perception</article-title><source>Trends in Cognitive Sciences</source><volume>25</volume><fpage>100</fpage><lpage>110</lpage><pub-id pub-id-type="doi">10.1016/j.tics.2020.11.006</pub-id><pub-id pub-id-type="pmid">33334693</pub-id></element-citation></ref><ref id="bib75"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Pitcher</surname><given-names>D</given-names></name></person-group><year iso-8601-date="2023">2023</year><article-title>Visual neuroscience: a specialised neural pathway for social perception</article-title><source>Current Biology</source><volume>33</volume><fpage>R1222</fpage><lpage>R1224</lpage><pub-id pub-id-type="doi">10.1016/j.cub.2023.10.020</pub-id><pub-id pub-id-type="pmid">38052168</pub-id></element-citation></ref><ref id="bib76"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Poerio</surname><given-names>GL</given-names></name><name><surname>Sormaz</surname><given-names>M</given-names></name><name><surname>Wang</surname><given-names>HT</given-names></name><name><surname>Margulies</surname><given-names>D</given-names></name><name><surname>Jefferies</surname><given-names>E</given-names></name><name><surname>Smallwood</surname><given-names>J</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>The role of the default mode network in component processes underlying the wandering mind</article-title><source>Social Cognitive and Affective Neuroscience</source><volume>12</volume><fpage>1047</fpage><lpage>1062</lpage><pub-id pub-id-type="doi">10.1093/scan/nsx041</pub-id><pub-id pub-id-type="pmid">28402561</pub-id></element-citation></ref><ref id="bib77"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Posse</surname><given-names>S</given-names></name><name><surname>Wiese</surname><given-names>S</given-names></name><name><surname>Gembris</surname><given-names>D</given-names></name><name><surname>Mathiak</surname><given-names>K</given-names></name><name><surname>Kessler</surname><given-names>C</given-names></name><name><surname>Grosse-Ruyken</surname><given-names>ML</given-names></name><name><surname>Elghahwagi</surname><given-names>B</given-names></name><name><surname>Richards</surname><given-names>T</given-names></name><name><surname>Dager</surname><given-names>SR</given-names></name><name><surname>Kiselev</surname><given-names>VG</given-names></name></person-group><year iso-8601-date="1999">1999</year><article-title>Enhancement of BOLD-contrast sensitivity by single-shot multi-echo functional MR imaging</article-title><source>Magnetic Resonance in Medicine</source><volume>42</volume><fpage>87</fpage><lpage>97</lpage><pub-id pub-id-type="doi">10.1002/(SICI)1522-2594(199907)42:1&lt;87::AID-MRM13&gt;3.0.CO;2-O</pub-id></element-citation></ref><ref id="bib78"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ralph</surname><given-names>MAL</given-names></name><name><surname>Jefferies</surname><given-names>E</given-names></name><name><surname>Patterson</surname><given-names>K</given-names></name><name><surname>Rogers</surname><given-names>TT</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>The neural and computational bases of semantic cognition</article-title><source>Nature Reviews Neuroscience</source><volume>18</volume><fpage>42</fpage><lpage>55</lpage><pub-id pub-id-type="doi">10.1038/nrn.2016.150</pub-id></element-citation></ref><ref id="bib79"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ramanan</surname><given-names>S</given-names></name><name><surname>Piguet</surname><given-names>O</given-names></name><name><surname>Irish</surname><given-names>M</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>Rethinking the role of the angular gyrus in remembering the past and imagining the future: the contextual integration model</article-title><source>The Neuroscientist</source><volume>24</volume><fpage>342</fpage><lpage>352</lpage><pub-id pub-id-type="doi">10.1177/1073858417735514</pub-id><pub-id pub-id-type="pmid">29283042</pub-id></element-citation></ref><ref id="bib80"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Reagh</surname><given-names>ZM</given-names></name><name><surname>Yassa</surname><given-names>MA</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>Object and spatial mnemonic interference differentially engage lateral and medial entorhinal cortex in humans</article-title><source>PNAS</source><volume>111</volume><fpage>E4264</fpage><lpage>E4273</lpage><pub-id pub-id-type="doi">10.1073/pnas.1411250111</pub-id><pub-id pub-id-type="pmid">25246569</pub-id></element-citation></ref><ref id="bib81"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Rice</surname><given-names>GE</given-names></name><name><surname>Hoffman</surname><given-names>P</given-names></name><name><surname>Lambon Ralph</surname><given-names>MA</given-names></name></person-group><year iso-8601-date="2015">2015a</year><article-title>Graded specialization within and between the anterior temporal lobes</article-title><source>Annals of the New York Academy of Sciences</source><volume>1359</volume><fpage>84</fpage><lpage>97</lpage><pub-id pub-id-type="doi">10.1111/nyas.12951</pub-id><pub-id pub-id-type="pmid">26502375</pub-id></element-citation></ref><ref id="bib82"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Rice</surname><given-names>GE</given-names></name><name><surname>Lambon Ralph</surname><given-names>MA</given-names></name><name><surname>Hoffman</surname><given-names>Paul</given-names></name></person-group><year iso-8601-date="2015">2015b</year><article-title>The roles of left versus right anterior temporal lobes in conceptual knowledge: an ALE meta-analysis of 97 functional neuroimaging studies</article-title><source>Cerebral Cortex</source><volume>25</volume><fpage>4374</fpage><lpage>4391</lpage><pub-id pub-id-type="doi">10.1093/cercor/bhv024</pub-id><pub-id pub-id-type="pmid">25771223</pub-id></element-citation></ref><ref id="bib83"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ritchey</surname><given-names>M</given-names></name><name><surname>Cooper</surname><given-names>RA</given-names></name></person-group><year iso-8601-date="2020">2020</year><article-title>Deconstructing the posterior medial episodic network</article-title><source>Trends in Cognitive Sciences</source><volume>24</volume><fpage>451</fpage><lpage>465</lpage><pub-id pub-id-type="doi">10.1016/j.tics.2020.03.006</pub-id><pub-id pub-id-type="pmid">32340798</pub-id></element-citation></ref><ref id="bib84"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Romanski</surname><given-names>LM</given-names></name></person-group><year iso-8601-date="2004">2004</year><article-title>Domain specificity in the primate prefrontal cortex</article-title><source>Cognitive, Affective, &amp; Behavioral Neuroscience</source><volume>4</volume><fpage>421</fpage><lpage>429</lpage><pub-id pub-id-type="doi">10.3758/CABN.4.4.421</pub-id></element-citation></ref><ref id="bib85"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Schaefer</surname><given-names>A</given-names></name><name><surname>Kong</surname><given-names>R</given-names></name><name><surname>Gordon</surname><given-names>EM</given-names></name><name><surname>Laumann</surname><given-names>TO</given-names></name><name><surname>Zuo</surname><given-names>XN</given-names></name><name><surname>Holmes</surname><given-names>AJ</given-names></name><name><surname>Eickhoff</surname><given-names>SB</given-names></name><name><surname>Yeo</surname><given-names>BTT</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>Local-global parcellation of the human cerebral cortex from intrinsic functional connectivity MRI</article-title><source>Cerebral Cortex</source><volume>28</volume><fpage>3095</fpage><lpage>3114</lpage><pub-id pub-id-type="doi">10.1093/cercor/bhx179</pub-id><pub-id pub-id-type="pmid">28981612</pub-id></element-citation></ref><ref id="bib86"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Seghier</surname><given-names>ML</given-names></name></person-group><year iso-8601-date="2023">2023</year><source>Multiple Functions of the Angular Gyrus at High Temporal Resolution, Brain Structure and Function</source><publisher-name>Springer</publisher-name></element-citation></ref><ref id="bib87"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Silson</surname><given-names>EH</given-names></name><name><surname>Steel</surname><given-names>A</given-names></name><name><surname>Kidder</surname><given-names>A</given-names></name><name><surname>Gilmore</surname><given-names>AW</given-names></name><name><surname>Baker</surname><given-names>CI</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>Distinct subdivisions of human medial parietal cortex support recollection of people and places</article-title><source>eLife</source><volume>8</volume><elocation-id>47391</elocation-id><pub-id pub-id-type="doi">10.7554/eLife.47391</pub-id><pub-id pub-id-type="pmid">31305238</pub-id></element-citation></ref><ref id="bib88"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Smallwood</surname><given-names>J</given-names></name><name><surname>Bernhardt</surname><given-names>BC</given-names></name><name><surname>Leech</surname><given-names>R</given-names></name><name><surname>Bzdok</surname><given-names>D</given-names></name><name><surname>Jefferies</surname><given-names>E</given-names></name><name><surname>Margulies</surname><given-names>DS</given-names></name></person-group><year iso-8601-date="2021">2021</year><article-title>The default mode network in cognition: a topographical perspective</article-title><source>Nature Reviews. Neuroscience</source><volume>22</volume><fpage>503</fpage><lpage>513</lpage><pub-id pub-id-type="doi">10.1038/s41583-021-00474-4</pub-id><pub-id pub-id-type="pmid">34226715</pub-id></element-citation></ref><ref id="bib89"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Smith</surname><given-names>SM</given-names></name><name><surname>Jenkinson</surname><given-names>M</given-names></name><name><surname>Woolrich</surname><given-names>MW</given-names></name><name><surname>Beckmann</surname><given-names>CF</given-names></name><name><surname>Behrens</surname><given-names>TEJ</given-names></name><name><surname>Johansen-Berg</surname><given-names>H</given-names></name><name><surname>Bannister</surname><given-names>PR</given-names></name><name><surname>De Luca</surname><given-names>M</given-names></name><name><surname>Drobnjak</surname><given-names>I</given-names></name><name><surname>Flitney</surname><given-names>DE</given-names></name><name><surname>Niazy</surname><given-names>RK</given-names></name><name><surname>Saunders</surname><given-names>J</given-names></name><name><surname>Vickers</surname><given-names>J</given-names></name><name><surname>Zhang</surname><given-names>Y</given-names></name><name><surname>De Stefano</surname><given-names>N</given-names></name><name><surname>Brady</surname><given-names>JM</given-names></name><name><surname>Matthews</surname><given-names>PM</given-names></name></person-group><year iso-8601-date="2004">2004</year><article-title>Advances in functional and structural MR image analysis and implementation as FSL</article-title><source>NeuroImage</source><volume>23</volume><fpage>S208</fpage><lpage>S219</lpage><pub-id pub-id-type="doi">10.1016/j.neuroimage.2004.07.051</pub-id><pub-id pub-id-type="pmid">15501092</pub-id></element-citation></ref><ref id="bib90"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Sormaz</surname><given-names>M</given-names></name><name><surname>Jefferies</surname><given-names>E</given-names></name><name><surname>Bernhardt</surname><given-names>BC</given-names></name><name><surname>Karapanagiotidis</surname><given-names>T</given-names></name><name><surname>Mollo</surname><given-names>G</given-names></name><name><surname>Bernasconi</surname><given-names>N</given-names></name><name><surname>Bernasconi</surname><given-names>A</given-names></name><name><surname>Hartley</surname><given-names>T</given-names></name><name><surname>Smallwood</surname><given-names>J</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>Knowing what from where: Hippocampal connectivity with temporoparietal cortex at rest is linked to individual differences in semantic and topographic memory</article-title><source>NeuroImage</source><volume>152</volume><fpage>400</fpage><lpage>410</lpage><pub-id pub-id-type="doi">10.1016/j.neuroimage.2017.02.071</pub-id><pub-id pub-id-type="pmid">28246034</pub-id></element-citation></ref><ref id="bib91"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Spreng</surname><given-names>RN</given-names></name><name><surname>Mar</surname><given-names>RA</given-names></name><name><surname>Kim</surname><given-names>ASN</given-names></name></person-group><year iso-8601-date="2009">2009</year><article-title>The common neural basis of autobiographical memory, prospection, navigation, theory of mind, and the default mode: A quantitative meta-analysis</article-title><source>Journal of Cognitive Neuroscience</source><volume>21</volume><fpage>489</fpage><lpage>510</lpage><pub-id pub-id-type="doi">10.1162/jocn.2008.21029</pub-id><pub-id pub-id-type="pmid">18510452</pub-id></element-citation></ref><ref id="bib92"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Spreng</surname><given-names>RN</given-names></name><name><surname>Grady</surname><given-names>CL</given-names></name></person-group><year iso-8601-date="2010">2010</year><article-title>Patterns of brain activity supporting autobiographical memory, prospection, and theory of mind, and their relationship to the default mode network</article-title><source>Journal of Cognitive Neuroscience</source><volume>22</volume><fpage>1112</fpage><lpage>1123</lpage><pub-id pub-id-type="doi">10.1162/jocn.2009.21282</pub-id><pub-id pub-id-type="pmid">19580387</pub-id></element-citation></ref><ref id="bib93"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Steel</surname><given-names>A</given-names></name><name><surname>Billings</surname><given-names>MM</given-names></name><name><surname>Silson</surname><given-names>EH</given-names></name><name><surname>Robertson</surname><given-names>CE</given-names></name></person-group><year iso-8601-date="2021">2021</year><article-title>A network linking scene perception and spatial memory systems in posterior cerebral cortex</article-title><source>Nature Communications</source><volume>12</volume><elocation-id>2632</elocation-id><pub-id pub-id-type="doi">10.1038/s41467-021-22848-z</pub-id><pub-id pub-id-type="pmid">33976141</pub-id></element-citation></ref><ref id="bib94"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Stolier</surname><given-names>RM</given-names></name><name><surname>Freeman</surname><given-names>JB</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Neural pattern similarity reveals the inherent intersection of social categories</article-title><source>Nature Neuroscience</source><volume>19</volume><fpage>795</fpage><lpage>797</lpage><pub-id pub-id-type="doi">10.1038/nn.4296</pub-id><pub-id pub-id-type="pmid">27135216</pub-id></element-citation></ref><ref id="bib95"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Summerfield</surname><given-names>C</given-names></name><name><surname>Luyckx</surname><given-names>F</given-names></name><name><surname>Sheahan</surname><given-names>H</given-names></name></person-group><year iso-8601-date="2020">2020</year><article-title>Structure learning and the posterior parietal cortex</article-title><source>Progress in Neurobiology</source><volume>184</volume><elocation-id>101717</elocation-id><pub-id pub-id-type="doi">10.1016/j.pneurobio.2019.101717</pub-id><pub-id pub-id-type="pmid">31669186</pub-id></element-citation></ref><ref id="bib96"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Szinte</surname><given-names>M</given-names></name><name><surname>Knapen</surname><given-names>T</given-names></name></person-group><year iso-8601-date="2020">2020</year><article-title>Visual organization of the default network</article-title><source>Cerebral Cortex</source><volume>30</volume><fpage>3518</fpage><lpage>3527</lpage><pub-id pub-id-type="doi">10.1093/cercor/bhz323</pub-id><pub-id pub-id-type="pmid">32031204</pub-id></element-citation></ref><ref id="bib97"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Thiebaut de Schotten</surname><given-names>M</given-names></name><name><surname>Foulon</surname><given-names>C</given-names></name><name><surname>Nachev</surname><given-names>P</given-names></name></person-group><year iso-8601-date="2020">2020</year><article-title>Brain disconnections link structural connectivity with function and behaviour</article-title><source>Nature Communications</source><volume>11</volume><elocation-id>18920-9</elocation-id><pub-id pub-id-type="doi">10.1038/s41467-020-18920-9</pub-id></element-citation></ref><ref id="bib98"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Turnbull</surname><given-names>A</given-names></name><name><surname>Wang</surname><given-names>HT</given-names></name><name><surname>Schooler</surname><given-names>JW</given-names></name><name><surname>Jefferies</surname><given-names>E</given-names></name><name><surname>Margulies</surname><given-names>DS</given-names></name><name><surname>Smallwood</surname><given-names>J</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>The ebb and flow of attention: Between-subject variation in intrinsic connectivity and cognition associated with the dynamics of ongoing experience</article-title><source>NeuroImage</source><volume>185</volume><fpage>286</fpage><lpage>299</lpage><pub-id pub-id-type="doi">10.1016/j.neuroimage.2018.09.069</pub-id><pub-id pub-id-type="pmid">30266263</pub-id></element-citation></ref><ref id="bib99"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Uğurbil</surname><given-names>K</given-names></name><name><surname>Xu</surname><given-names>J</given-names></name><name><surname>Auerbach</surname><given-names>EJ</given-names></name><name><surname>Moeller</surname><given-names>S</given-names></name><name><surname>Vu</surname><given-names>AT</given-names></name><name><surname>Duarte-Carvajalino</surname><given-names>JM</given-names></name><name><surname>Lenglet</surname><given-names>C</given-names></name><name><surname>Wu</surname><given-names>X</given-names></name><name><surname>Schmitter</surname><given-names>S</given-names></name><name><surname>Van de Moortele</surname><given-names>PF</given-names></name><name><surname>Strupp</surname><given-names>J</given-names></name><name><surname>Sapiro</surname><given-names>G</given-names></name><name><surname>De Martino</surname><given-names>F</given-names></name><name><surname>Wang</surname><given-names>D</given-names></name><name><surname>Harel</surname><given-names>N</given-names></name><name><surname>Garwood</surname><given-names>M</given-names></name><name><surname>Chen</surname><given-names>L</given-names></name><name><surname>Feinberg</surname><given-names>DA</given-names></name><name><surname>Smith</surname><given-names>SM</given-names></name><name><surname>Miller</surname><given-names>KL</given-names></name><name><surname>Sotiropoulos</surname><given-names>SN</given-names></name><name><surname>Jbabdi</surname><given-names>S</given-names></name><name><surname>Andersson</surname><given-names>JLR</given-names></name><name><surname>Behrens</surname><given-names>TEJ</given-names></name><name><surname>Glasser</surname><given-names>MF</given-names></name><name><surname>Van Essen</surname><given-names>DC</given-names></name><name><surname>Yacoub</surname><given-names>E</given-names></name><collab>WU-Minn HCP Consortium</collab></person-group><year iso-8601-date="2013">2013</year><article-title>Pushing spatial and temporal resolution for functional and diffusion MRI in the Human Connectome Project</article-title><source>NeuroImage</source><volume>80</volume><fpage>80</fpage><lpage>104</lpage><pub-id pub-id-type="doi">10.1016/j.neuroimage.2013.05.012</pub-id><pub-id pub-id-type="pmid">23702417</pub-id></element-citation></ref><ref id="bib100"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Vatansever</surname><given-names>D</given-names></name><name><surname>Bzdok</surname><given-names>D</given-names></name><name><surname>Wang</surname><given-names>H-T</given-names></name><name><surname>Mollo</surname><given-names>G</given-names></name><name><surname>Sormaz</surname><given-names>M</given-names></name><name><surname>Murphy</surname><given-names>C</given-names></name><name><surname>Karapanagiotidis</surname><given-names>T</given-names></name><name><surname>Smallwood</surname><given-names>J</given-names></name><name><surname>Jefferies</surname><given-names>E</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>Varieties of semantic cognition revealed through simultaneous decomposition of intrinsic brain connectivity and behaviour</article-title><source>NeuroImage</source><volume>158</volume><fpage>1</fpage><lpage>11</lpage><pub-id pub-id-type="doi">10.1016/j.neuroimage.2017.06.067</pub-id><pub-id pub-id-type="pmid">28655631</pub-id></element-citation></ref><ref id="bib101"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Viganò</surname><given-names>S</given-names></name><name><surname>Piazza</surname><given-names>M</given-names></name></person-group><year iso-8601-date="2020">2020</year><article-title>Distance and direction codes underlie navigation of a novel semantic space in the human brain</article-title><source>The Journal of Neuroscience</source><volume>40</volume><fpage>2727</fpage><lpage>2736</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.1849-19.2020</pub-id><pub-id pub-id-type="pmid">32060171</pub-id></element-citation></ref><ref id="bib102"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Vu</surname><given-names>AT</given-names></name><name><surname>Auerbach</surname><given-names>E</given-names></name><name><surname>Lenglet</surname><given-names>C</given-names></name><name><surname>Moeller</surname><given-names>S</given-names></name><name><surname>Sotiropoulos</surname><given-names>SN</given-names></name><name><surname>Jbabdi</surname><given-names>S</given-names></name><name><surname>Andersson</surname><given-names>J</given-names></name><name><surname>Yacoub</surname><given-names>E</given-names></name><name><surname>Ugurbil</surname><given-names>K</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>High resolution whole brain diffusion imaging at 7T for the Human Connectome Project</article-title><source>NeuroImage</source><volume>122</volume><fpage>318</fpage><lpage>331</lpage><pub-id pub-id-type="doi">10.1016/j.neuroimage.2015.08.004</pub-id><pub-id pub-id-type="pmid">26260428</pub-id></element-citation></ref><ref id="bib103"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Walther</surname><given-names>A</given-names></name><name><surname>Nili</surname><given-names>H</given-names></name><name><surname>Ejaz</surname><given-names>N</given-names></name><name><surname>Alink</surname><given-names>A</given-names></name><name><surname>Kriegeskorte</surname><given-names>N</given-names></name><name><surname>Diedrichsen</surname><given-names>J</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Reliability of dissimilarity measures for multi-voxel pattern analysis</article-title><source>NeuroImage</source><volume>137</volume><fpage>188</fpage><lpage>200</lpage><pub-id pub-id-type="doi">10.1016/j.neuroimage.2015.12.012</pub-id><pub-id pub-id-type="pmid">26707889</pub-id></element-citation></ref><ref id="bib104"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wang</surname><given-names>R</given-names></name><name><surname>Benner</surname><given-names>T</given-names></name></person-group><year iso-8601-date="2007">2007</year><article-title>Diffusion toolkit: a software package for diffusion imaging data processing and tractography</article-title><source>Proc Intl Soc Mag Reson Med</source><volume>15</volume><elocation-id>3720</elocation-id></element-citation></ref><ref id="bib105"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wang</surname><given-names>HT</given-names></name><name><surname>Poerio</surname><given-names>G</given-names></name><name><surname>Murphy</surname><given-names>C</given-names></name><name><surname>Bzdok</surname><given-names>D</given-names></name><name><surname>Jefferies</surname><given-names>E</given-names></name><name><surname>Smallwood</surname><given-names>J</given-names></name></person-group><year iso-8601-date="2018">2018a</year><article-title>Dimensions of experience: exploring the heterogeneity of the wandering mind</article-title><source>Psychological Science</source><volume>29</volume><fpage>56</fpage><lpage>71</lpage><pub-id pub-id-type="doi">10.1177/0956797617728727</pub-id><pub-id pub-id-type="pmid">29131720</pub-id></element-citation></ref><ref id="bib106"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wang</surname><given-names>XX</given-names></name><name><surname>Wu</surname><given-names>W</given-names></name><name><surname>Ling</surname><given-names>Z</given-names></name><name><surname>Xu</surname><given-names>Y</given-names></name><name><surname>Fang</surname><given-names>Y</given-names></name><name><surname>Wang</surname><given-names>XX</given-names></name><name><surname>Binder</surname><given-names>JR</given-names></name><name><surname>Men</surname><given-names>W</given-names></name><name><surname>Gao</surname><given-names>JH</given-names></name><name><surname>Bi</surname><given-names>Y</given-names></name></person-group><year iso-8601-date="2018">2018b</year><article-title>Organizational principles of abstract words in the human brain</article-title><source>Cerebral Cortex</source><volume>28</volume><fpage>4305</fpage><lpage>4318</lpage><pub-id pub-id-type="doi">10.1093/cercor/bhx283</pub-id></element-citation></ref><ref id="bib107"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wang</surname><given-names>X</given-names></name><name><surname>Margulies</surname><given-names>DS</given-names></name><name><surname>Smallwood</surname><given-names>J</given-names></name><name><surname>Jefferies</surname><given-names>E</given-names></name></person-group><year iso-8601-date="2020">2020</year><article-title>A gradient from long-term memory to novel cognition: Transitions through default mode and executive cortex</article-title><source>NeuroImage</source><volume>220</volume><elocation-id>117074</elocation-id><pub-id pub-id-type="doi">10.1016/j.neuroimage.2020.117074</pub-id><pub-id pub-id-type="pmid">32574804</pub-id></element-citation></ref><ref id="bib108"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wassermann</surname><given-names>D</given-names></name><name><surname>Makris</surname><given-names>N</given-names></name><name><surname>Rathi</surname><given-names>Y</given-names></name><name><surname>Shenton</surname><given-names>M</given-names></name><name><surname>Kikinis</surname><given-names>R</given-names></name><name><surname>Kubicki</surname><given-names>M</given-names></name><name><surname>Westin</surname><given-names>CF</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>The white matter query language: a novel approach for describing human white matter anatomy</article-title><source>Brain Structure and Function</source><volume>221</volume><fpage>4705</fpage><lpage>4721</lpage><pub-id pub-id-type="doi">10.1007/s00429-015-1179-4</pub-id></element-citation></ref><ref id="bib109"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wen</surname><given-names>T</given-names></name><name><surname>Mitchell</surname><given-names>DJ</given-names></name><name><surname>Duncan</surname><given-names>J</given-names></name></person-group><year iso-8601-date="2020">2020</year><article-title>The functional convergence and heterogeneity of social, episodic, and self-referential thought in the default mode network</article-title><source>Cerebral Cortex</source><volume>30</volume><fpage>5915</fpage><lpage>5929</lpage><pub-id pub-id-type="doi">10.1093/cercor/bhaa166</pub-id><pub-id pub-id-type="pmid">32572493</pub-id></element-citation></ref><ref id="bib110"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Whitfield-Gabrieli</surname><given-names>S</given-names></name><name><surname>Nieto-Castanon</surname><given-names>A</given-names></name></person-group><year iso-8601-date="2012">2012</year><article-title>Conn: a functional connectivity toolbox for correlated and anticorrelated brain networks</article-title><source>Brain Connectivity</source><volume>2</volume><fpage>125</fpage><lpage>141</lpage><pub-id pub-id-type="doi">10.1089/brain.2012.0073</pub-id><pub-id pub-id-type="pmid">22642651</pub-id></element-citation></ref><ref id="bib111"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Winkler</surname><given-names>AM</given-names></name><name><surname>Ridgway</surname><given-names>GR</given-names></name><name><surname>Webster</surname><given-names>MA</given-names></name><name><surname>Smith</surname><given-names>SM</given-names></name><name><surname>Nichols</surname><given-names>TE</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>Permutation inference for the general linear model</article-title><source>NeuroImage</source><volume>92</volume><fpage>381</fpage><lpage>397</lpage><pub-id pub-id-type="doi">10.1016/j.neuroimage.2014.01.060</pub-id></element-citation></ref><ref id="bib112"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Woolrich</surname><given-names>MW</given-names></name><name><surname>Ripley</surname><given-names>BD</given-names></name><name><surname>Brady</surname><given-names>M</given-names></name><name><surname>Smith</surname><given-names>SM</given-names></name></person-group><year iso-8601-date="2001">2001</year><article-title>Temporal autocorrelation in univariate linear modeling of FMRI data</article-title><source>NeuroImage</source><volume>14</volume><fpage>1370</fpage><lpage>1386</lpage><pub-id pub-id-type="doi">10.1006/nimg.2001.0931</pub-id><pub-id pub-id-type="pmid">11707093</pub-id></element-citation></ref><ref id="bib113"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Woolrich</surname><given-names>MW</given-names></name><name><surname>Behrens</surname><given-names>TEJ</given-names></name><name><surname>Beckmann</surname><given-names>CF</given-names></name><name><surname>Jenkinson</surname><given-names>M</given-names></name><name><surname>Smith</surname><given-names>SM</given-names></name></person-group><year iso-8601-date="2004">2004</year><article-title>Multilevel linear modelling for FMRI group analysis using Bayesian inference</article-title><source>NeuroImage</source><volume>21</volume><fpage>1732</fpage><lpage>1747</lpage><pub-id pub-id-type="doi">10.1016/j.neuroimage.2003.12.023</pub-id><pub-id pub-id-type="pmid">15050594</pub-id></element-citation></ref><ref id="bib114"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Woolrich</surname><given-names>M</given-names></name></person-group><year iso-8601-date="2008">2008</year><article-title>Robust group analysis using outlier inference</article-title><source>NeuroImage</source><volume>41</volume><fpage>286</fpage><lpage>301</lpage><pub-id pub-id-type="doi">10.1016/j.neuroimage.2008.02.042</pub-id></element-citation></ref><ref id="bib115"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Woolrich</surname><given-names>MW</given-names></name><name><surname>Jbabdi</surname><given-names>S</given-names></name><name><surname>Patenaude</surname><given-names>B</given-names></name><name><surname>Chappell</surname><given-names>M</given-names></name><name><surname>Makni</surname><given-names>S</given-names></name><name><surname>Behrens</surname><given-names>T</given-names></name><name><surname>Beckmann</surname><given-names>C</given-names></name><name><surname>Jenkinson</surname><given-names>M</given-names></name><name><surname>Smith</surname><given-names>SM</given-names></name></person-group><year iso-8601-date="2009">2009</year><article-title>Bayesian analysis of neuroimaging data in FSL</article-title><source>NeuroImage</source><volume>45</volume><fpage>S173</fpage><lpage>S176</lpage><pub-id pub-id-type="doi">10.1016/j.neuroimage.2008.10.055</pub-id><pub-id pub-id-type="pmid">19059349</pub-id></element-citation></ref><ref id="bib116"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Xia</surname><given-names>M</given-names></name><name><surname>Wang</surname><given-names>J</given-names></name><name><surname>He</surname><given-names>Y</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>BrainNet Viewer: A network visualization tool for human brain connectomics</article-title><source>PLOS ONE</source><volume>8</volume><elocation-id>e68910</elocation-id><pub-id pub-id-type="doi">10.1371/journal.pone.0068910</pub-id><pub-id pub-id-type="pmid">23861951</pub-id></element-citation></ref><ref id="bib117"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Xu</surname><given-names>Y</given-names></name><name><surname>He</surname><given-names>Y</given-names></name><name><surname>Bi</surname><given-names>Y</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>A tri-network model of human semantic processing</article-title><source>Frontiers in Psychology</source><volume>8</volume><elocation-id>01538</elocation-id><pub-id pub-id-type="doi">10.3389/fpsyg.2017.01538</pub-id></element-citation></ref><ref id="bib118"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Yarkoni</surname><given-names>T</given-names></name><name><surname>Poldrack</surname><given-names>RA</given-names></name><name><surname>Nichols</surname><given-names>TE</given-names></name><name><surname>Van Essen</surname><given-names>DC</given-names></name><name><surname>Wager</surname><given-names>TD</given-names></name></person-group><year iso-8601-date="2011">2011</year><article-title>Large-scale automated synthesis of human functional neuroimaging data</article-title><source>Nature Methods</source><volume>8</volume><fpage>665</fpage><lpage>670</lpage><pub-id pub-id-type="doi">10.1038/nmeth.1635</pub-id><pub-id pub-id-type="pmid">21706013</pub-id></element-citation></ref><ref id="bib119"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Yazar</surname><given-names>Y</given-names></name><name><surname>Bergström</surname><given-names>ZM</given-names></name><name><surname>Simons</surname><given-names>JS</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>Reduced multimodal integration of memory features following continuous theta burst stimulation of angular gyrus</article-title><source>Brain Stimulation</source><volume>10</volume><fpage>624</fpage><lpage>629</lpage><pub-id pub-id-type="doi">10.1016/j.brs.2017.02.011</pub-id><pub-id pub-id-type="pmid">28283370</pub-id></element-citation></ref><ref id="bib120"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Yeo</surname><given-names>BTT</given-names></name><name><surname>Krienen</surname><given-names>FM</given-names></name><name><surname>Sepulcre</surname><given-names>J</given-names></name><name><surname>Sabuncu</surname><given-names>MR</given-names></name><name><surname>Lashkari</surname><given-names>D</given-names></name><name><surname>Hollinshead</surname><given-names>M</given-names></name><name><surname>Roffman</surname><given-names>JL</given-names></name><name><surname>Smoller</surname><given-names>JW</given-names></name><name><surname>Zöllei</surname><given-names>L</given-names></name><name><surname>Polimeni</surname><given-names>JR</given-names></name><name><surname>Fischl</surname><given-names>B</given-names></name><name><surname>Liu</surname><given-names>H</given-names></name><name><surname>Buckner</surname><given-names>RL</given-names></name></person-group><year iso-8601-date="2011">2011</year><article-title>The organization of the human cerebral cortex estimated by intrinsic functional connectivity</article-title><source>Journal of Neurophysiology</source><volume>106</volume><fpage>1125</fpage><lpage>1165</lpage><pub-id pub-id-type="doi">10.1152/jn.00338.2011</pub-id><pub-id pub-id-type="pmid">21653723</pub-id></element-citation></ref><ref id="bib121"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Zeidman</surname><given-names>P</given-names></name><name><surname>Mullally</surname><given-names>SL</given-names></name><name><surname>Maguire</surname><given-names>EA</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>Constructing, perceiving, and maintaining scenes: hippocampal activity and connectivity</article-title><source>Cerebral Cortex</source><volume>25</volume><fpage>3836</fpage><lpage>3855</lpage><pub-id pub-id-type="doi">10.1093/cercor/bhu266</pub-id><pub-id pub-id-type="pmid">25405941</pub-id></element-citation></ref><ref id="bib122"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Zhang</surname><given-names>M</given-names></name><name><surname>Bernhardt</surname><given-names>BC</given-names></name><name><surname>Wang</surname><given-names>X</given-names></name><name><surname>Varga</surname><given-names>D</given-names></name><name><surname>Krieger-Redwood</surname><given-names>K</given-names></name><name><surname>Royer</surname><given-names>J</given-names></name><name><surname>Rodríguez-Cruces</surname><given-names>R</given-names></name><name><surname>Vos de Wael</surname><given-names>R</given-names></name><name><surname>Margulies</surname><given-names>DS</given-names></name><name><surname>Smallwood</surname><given-names>J</given-names></name><name><surname>Jefferies</surname><given-names>E</given-names></name></person-group><year iso-8601-date="2022">2022</year><article-title>Perceptual coupling and decoupling of the default mode network during mind-wandering and reading</article-title><source>eLife</source><volume>11</volume><elocation-id>e74011</elocation-id><pub-id pub-id-type="doi">10.7554/eLife.74011</pub-id><pub-id pub-id-type="pmid">35311643</pub-id></element-citation></ref><ref id="bib123"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Zimmermann</surname><given-names>M</given-names></name><name><surname>Mars</surname><given-names>RB</given-names></name><name><surname>de Lange</surname><given-names>FP</given-names></name><name><surname>Toni</surname><given-names>I</given-names></name><name><surname>Verhagen</surname><given-names>L</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>Is the extrastriate body area part of the dorsal visuomotor stream?</article-title><source>Brain Structure &amp; Function</source><volume>223</volume><fpage>31</fpage><lpage>46</lpage><pub-id pub-id-type="doi">10.1007/s00429-017-1469-0</pub-id><pub-id pub-id-type="pmid">28702735</pub-id></element-citation></ref></ref-list><app-group><app id="appendix-1"><title>Appendix 1</title><sec sec-type="appendix" id="s8"><title>Supporting materials</title><sec sec-type="appendix" id="s8-1"><title>Supplementary analysis: resting-state maps with stricter thresholding</title><p>Since the pattern of results obtained from resting-state analysis can be sensitive to threshold decisions, we reproduced the group-level maps depicted in <xref ref-type="fig" rid="fig2">Figures 2E</xref> and <xref ref-type="fig" rid="fig3">3E</xref> using a stricter threshold. We originally thresholded these results using the default of the CONN software package (cluster-forming threshold of p=0.05, equivalent to T=1.65). For increased rigour, we reproduced the thresholded maps from <xref ref-type="fig" rid="fig2">Figures 2E</xref> and <xref ref-type="fig" rid="fig3">3E</xref> further increasing the threshold from p=0.05, equivalent to T=1.65, to p=0.001, equivalent to T=3.1. The resulting maps were very similar, showing minimal change, with a spatial correlation of r&gt;0.99 between the strict and lax threshold versions of the maps for both the probe and decision seeds. These maps can be downloaded from the OSF collection associated with this project.</p></sec><sec sec-type="appendix" id="s8-2"><title>Supplementary analysis: eroded masks replication analysis</title><p>The proximity of visual peripheral and DMN-C network borders is a property of the organisation of these networks (<xref ref-type="bibr" rid="bib87">Silson et al., 2019</xref>; <xref ref-type="bibr" rid="bib93">Steel et al., 2021</xref>). However, this could give rise to the potential for spatial mixing of the resting-state signal during intrinsic connectivity analysis due to smoothing, falsely inflating the strength of connectivity, since our visual and DMN masks for the spatial context task showed spatial adjacency. To address this concern, we re-analysed the resting-state data presented in <xref ref-type="fig" rid="fig4">Figure 4b and c</xref> (connectivity from DMN decision regions to visual probe regions and vice versa) by eroding the visual probe and DMN decision ROIs for the spatial context task using fslmaths. We eroded the masks until the smallest gap between them exceeded the size of our 6 mm FWHM smoothing kernel, which eliminates the potential for spatial mixing of signals due to ROI adjacency. The eroded ROIs can be consulted in the OSF collection associated with this project. We repeated the ANOVAs associated with these analyses. The results, presented in <xref ref-type="fig" rid="fig4s1">Figure 4—figure supplement 1</xref> below, confirmed the pattern of findings reported in the main analysis. We did not erode the respective ROIs for the semantic task, given that adjacency is not an issue for the ROIs derived from that task.</p><p>The visual-to-DMN ANOVA showed main effects of seed (F(1,190)=22.82, p&lt;0.001), ROI (F(1,190)=9.48, p=0.002) and a seed by ROI interaction (F(1,190)=67.02, p&lt;0.001). Post hoc contrasts confirmed there was stronger connectivity between object probe regions and semantic versus spatial context decision regions (t(190)=3.38, p&lt;0.001), and between scene probe regions and spatial context versus semantic decision regions (t(190)=–7.66, p&lt;0.001).</p><p>The DMN-to-visual ANOVA confirmed this pattern: again, there was a main effect of ROI (F(1,190)=4.3, p=0.039) and a seed by ROI interaction (F(1,190)=57.59, p&lt;0.001), with post hoc contrasts confirming stronger intrinsic connectivity between DMN regions implicated in sematic decisions and object probe regions (t(190)=5.06, p&lt;0.001), and between DMN regions engaged by spatial context decisions and scene probe regions (t(190)=3.25, p=0.001).</p></sec><sec sec-type="appendix" id="s8-3"><title>Supplementary analysis: replicating resting-state connectivity pathways with task-independent ROIs</title><p>We performed a supplementary analysis using task-independent ROIs to confirm that the intrinsic connectivity-based pathways could be identified even when the seeds and ROIs were not derived from the same task. In this analysis, we used the same seeds as the main analysis (<xref ref-type="fig" rid="fig4">Figure 4a</xref>; the conjunction of semantic and context decision activation within DMN and object and scene probes within visual networks), while the ROIs were either visual localiser masks for objects and scenes, or DMN subsystems from the <xref ref-type="bibr" rid="bib120">Yeo et al., 2011</xref>, parcellation. The results can be consulted in <xref ref-type="fig" rid="fig4s2">Figure 4—figure supplement 2</xref>. The DMN-to-visual ANOVA revealed main effects of DMN seed (F(1,190)=137.72, p&lt;0.001), visual ROI based on the localisers from Study 2 (F(1,190)=23.87, p&lt;0.001) and their interaction (F(1,190)=20.92, p&lt;0.001). Post hoc tests revealed that DMN regions associated with spatial context decisions showed stronger connectivity to both visual regions associated with viewing scenes, and visual regions associated with viewing objects, relative to DMN regions associated with semantic decisions (scenes: t(190)=11.57, p&lt;0.001; objects: t(190)=7.35, p&lt;0.001). The significant interaction term reveals that this difference between context and semantic seeds was more pronounced for the scene than the object localiser regions, confirming a greater importance of the context pathway for making decisions based on visual scene information.</p><p>The visual-to-DMN ANOVA revealed main effects of visual seed (F(1,190)=33.98, p&lt;0.001), DMN ROI (F(1,190)=65.46, p&lt;0.001) and their interaction (F(2,380)=119.14, p&lt;0.001). Post hoc tests revealed that visual regions associated with viewing object probes showed stronger connectivity to FT-DMN regions relative to regions associated with viewing spatial context probes (t(190)=3.22, p=0.002), while regions associated with viewing spatial context probes showed stronger connectivity to core and MT-DMN regions than regions associated with viewing object probes (core DMN: t(190)=4.41, p&lt;0.001; MT-DMN: t(190)=11.7, p&lt;0.001).</p></sec><sec sec-type="appendix" id="s8-4"><title>Supplementary analysis: replicating pathways’ structural connectivity from the DMN end</title><p>To confirm dissociable pathways based on structural connectivity can be identified not only when examining visual-to-DMN regions, but also the reverse, we performed a supplementary analysis seeding the DMN, and examined the strength of connections to visual ROIs (defined using activation to object and scene probes in Study 1 masked by visual networks). The results can be consulted on <xref ref-type="fig" rid="fig4s3">Figure 4—figure supplement 3</xref>. The DMN-to-visual ANOVA showed a main effect of visual ROI (F(1,163)=506.5, p&lt;0.001) and a seed by ROI interaction (F(1,163)=215.27, p&lt;0.001). Post hoc tests revealed that both DMN seeds, associated with semantic and spatial context decisions, showed stronger connectivity to visual regions responding more to scenes than to objects. However, this connectivity difference was greater for DMN regions activated by spatial context than semantic decisions (semantic DMN: t(163)=3.92, p&lt;0.001; spatial context DMN: t(163)=2381.12, p&lt;0.001).</p></sec><sec sec-type="appendix" id="s8-5"><title>Supplementary analysis: effects of task demands on pathway connectivity</title><sec sec-type="appendix" id="s8-5-1"><title>Methods</title><p>In order to test for distinct semantic and spatial memory pathways that connect visual regions to distinct subnetworks of the DMN, we conducted a PPI analysis. Semantic and spatial context visual seeds were created from the univariate activation to object and scene probes in the semantic and spatial tasks respectively, masked by <xref ref-type="bibr" rid="bib120">Yeo et al., 2011</xref>, 7-network parcellation visual network. The time series of these seeds were then extracted after pre-processing. We then ran two separate models (one for each seed), which examined the main effect of the experimental condition (i.e. <italic>SCB trials of the semantic task, MCB trials of the semantic task, SCB trials of the spatial context task, and MCB trials of the spatial context task</italic>). These models included all eight regressors from the basic task model of Study 1 described in Section: Task GLM, a PPI term for each of the seven conditions and phases of the task (SCB/MCB trials of the probe, dots and decision phases, and the arrow task), as well as the time series of the visual probe seeds, using the generalised psychophysiological interaction approach (<xref ref-type="bibr" rid="bib63">McLaren et al., 2012</xref>). The regressors were not orthogonalised. All runs of each task were combined using fixed-effects analyses for each participant, which allowed us to extract the connectivity parameters for each experimental condition for each participant in each seed model.</p></sec></sec><sec sec-type="appendix" id="s8-6"><title>Results and discussion</title><p>We examined how connectivity within the pathways changes depending on task demands in a PPI analysis. We took the visual regions showing differential activation to object and scene probes as seeds (shown in <xref ref-type="fig" rid="fig2">Figures 2e</xref> and <xref ref-type="fig" rid="fig4">4a</xref>), while the ROIs were regions sensitive to semantic and spatial context decisions within the DMN (shown in <xref ref-type="fig" rid="fig3">Figures 3e</xref> and <xref ref-type="fig" rid="fig4">4a</xref>). We anticipated that the scene probe regions would increase their connectivity to spatial context decision regions during the decision phase of the spatial context task, whilst the object probe regions would increase their connectivity to semantic decision regions during the decision phase of the semantic task. A repeated-measures ANOVA including task (semantic/spatial context), seed (object/scene probe), ROI (semantic/spatial context decision), and condition (SCB/MCB) as factors revealed two-way interactions for task by seed (F(1,26)=10.85, p=0.003) and seed by ROI (F(1,26)=8.57, p=0.007), as well as a three-way interaction for task by seed by ROI (F(1,26)=5.2, p=0.031). Since we found no effect of condition, we averaged across this factor for the following analyses. The results are shown in <xref ref-type="fig" rid="fig4s4">Figure 4—figure supplement 4</xref>. To understand the three-way interaction, separate two-way ANOVAs using seed (object/scene probe regions) and ROI (semantic/spatial context decision regions) as factors were computed for the spatial context and semantic tasks. The semantic task showed a main effect of seed (F(1,26)=6.97, p=0.014), but no effect of ROI or interaction: the object seed was more connected to both semantic and spatial context DMN decision regions during the semantic task. The spatial context task showed a main effect of seed (F(1,26)=5.89, p=0.022), and a seed by ROI interaction (F(1,26)=10.25, p=0.004). Post hoc t-tests showed that the scene probe regions were more connected to spatial context decision regions during the spatial context task than object probe regions (t(26)=3.52, p=0.002). In contrast, there was no difference in connectivity between these two seeds and the semantic decision regions.</p><p>In sum, the PPI models characterised how inputs to the pathways are flexibly configured to suit our current goals. The visual ends of the pathways showed opposing patterns of connectivity to spatial context DMN regions depending on the task.</p></sec><sec sec-type="appendix" id="s8-7"><title>Supplementary analysis: individual location of pathways in whole-brain gradients</title><p>Our analysis of the location of the pathways in whole-brain gradient connectivity space showed that peak responses during semantic decisions occurred in more abstract, less visual regions of the DMN relative to spatial context decisions. However, the scatterplots in the top panel of <xref ref-type="fig" rid="fig5">Figure 5</xref> do not allow to distinguish whether these effects took place at the individual level, since the data points are not linked across tasks. In light of this, we plotted the same data comparing the gradient values for the peak responses in each of our tasks at the participant level. The peaks for each participant across tasks are linked with a line. Cases where the pattern was reversed are highlighted with dashed lines (7/27 participants in each gradient, see <xref ref-type="fig" rid="fig5s1">Figure 5—figure supplement 1</xref>). This analysis showed that in the majority of cases, at the individual level, the pattern of group-level results held.</p></sec><sec sec-type="appendix" id="s8-8"><title>Supplementary analysis: multivariate response to SCB versus MCB</title><sec sec-type="appendix" id="s8-8-1"><title>Methods</title><p>Since distinct but adjacent regions were associated with semantic and spatial context decisions, we asked what they represented during probe presentation in MCB and SCB trials using RSA. Probes were presented across decision and no-decision trials, allowing a large number of probe responses to be included in the analysis. We examined the voxels that responded to contrasts between semantic and spatial context decisions (including all significant, suprathreshold voxels at the group level within a single ROI). We constructed semantic similarity matrices for each participant using all pairs of trials from the semantic task, encoding category similarity on a scale of 0–2. Pairs of trials that shared a specific category (e.g. birds) were assigned the strongest value (2), while those that shared only their superordinate category (animals versus man-made objects) were assigned the middle value (1); pairs of trials from different superordinate categories were assigned the weakest value (0). We also constructed spatial context similarity matrices for each participant, encoding the relationships between rooms and buildings on a scale of 0–2. Pairs of trials belonging to the same room were assigned the strongest value (2), while those belonging to different rooms of the same building were assigned a middle value (1); trials that belonged to different buildings were assigned the lowest value (0).</p></sec></sec><sec sec-type="appendix" id="s8-9"><title>Single-trial estimation</title><p>GLMs were performed separately to estimate the activation pattern for each of 144 trials during the probe phase in the two tasks. An LSS approach was used, in which the trial of interest was modelled as one regressor, with all other trials modelled as separate regressors (<xref ref-type="bibr" rid="bib65">Mumford et al., 2012</xref>). These models included eight regressors: (1) the probe phase of interest (SCB or MCB); (2 and 3) all other probe phases (SCB and MCB); (4) dots SCB; (5) dots MCB; (6) decision SCB; (7) decision MCB; (8) arrow trials. Since the analysis focussed on probe presentation rather than decisions, incorrect trials were not excluded. Each event was modelled at the time of stimulus onset and convolved with a canonical haemodynamic response function (double gamma), whereas the fixations were treated as an implicit baseline. Pre-whitening was applied. The same pre-processing procedure as in the univariate analysis was used except that no spatial smoothing was applied. This voxel-wise GLM was used to compute the activation associated with each trial, using the t-map for RSA to increase reliability by normalising for noise (<xref ref-type="bibr" rid="bib103">Walther et al., 2016</xref>).</p></sec><sec sec-type="appendix" id="s8-10"><title>Second-order representational similarity analysis</title><p>A searchlight approach compared semantic and spatial context similarity matrices with neural similarity matrices. Neural pattern similarity was estimated for cubic ROIs within t-maps for each trial, containing 125 voxels surrounding a central voxel (<xref ref-type="bibr" rid="bib31">Fairhall and Caramazza, 2013</xref>; <xref ref-type="bibr" rid="bib32">Gao et al., 2022</xref>; <xref ref-type="bibr" rid="bib54">Leshinskaya et al., 2017</xref>; <xref ref-type="bibr" rid="bib59">Malone et al., 2016</xref>; <xref ref-type="bibr" rid="bib94">Stolier and Freeman, 2016</xref>; <xref ref-type="bibr" rid="bib101">Viganò and Piazza, 2020</xref>; <xref ref-type="bibr" rid="bib106">Wang et al., 2018b</xref>). In each of these cubes, we derived a neural similarity matrix from Pearson correlations of pairs of trials. We excluded any pairs presented in the same run to avoid any autocorrelation. Spearman’s rank correlation was used to measure the alignment between task and brain-based models during the probe phase. The resulting coefficients were Fisher’s z-transformed and then entered into a group-level analysis carried out using FSL’s Randomise (<xref ref-type="bibr" rid="bib2">Anderson and Robinson, 2001</xref>; <xref ref-type="bibr" rid="bib111">Winkler et al., 2014</xref>) (5000 permutations with threshold-free cluster enhancement), thresholding the results at p&lt;0.05.</p><p>We also performed cross-task similarity analysis, correlating semantic similarity to the neural similarity matrix from the spatial context task (and vice versa). If participants use semantic information learned during training to guide spatial context decisions, or spatial context information from training to facilitate semantic decisions, we might be able to identify regions sensitive to semantic and spatial context information across tasks. This should only be the case in SCB and not MCB trials.</p></sec><sec sec-type="appendix" id="s8-11"><title>Results and discussion</title><p>The univariate analysis in the main text shows that when there is no alignment between spatial context and semantic information (in MCB trials), the heteromodal areas that are activated by the task show higher pathway-specific connectivity. In contrast, when information integration across space and meaning is facilitated by the structure of the task, spatial context trials show more activation in regions with lower connectivity to the spatial context pathway, but higher connectivity to the semantic pathway. In this way, right angular gyrus was found to have a potential role in integrating the visual-to-DMN pathways.</p><p>A follow-up analysis used a multivariate approach to establish how neural patterns related to the task reflected information integration. We performed RSA using a searchlight approach within a mask that combined semantic and spatial context task decision maps, using data acquired during the probe phase (since there were more probe than decision time-points). This method allowed us to select regions sensitive to semantic and spatial context information, while ensuring that the search space was not derived from the same data used for the RSA. First, we asked if we could detect regions sensitive to category during the semantic task and sensitive to location during the spatial context task, in the MCB trials. There were regions that represented semantic and spatial context similarity in bilateral and left LOC respectively (<xref ref-type="fig" rid="fig6s1">Figure 6—figure supplement 1a</xref>). Next, we performed a cross-task RSA in the SCB trials to identify areas that represented information relevant to one task in the other (e.g. areas that represented semantic information during the spatial context task and vice versa). The results of this analysis revealed right LOC regions that captured spatial context information during the semantic task (<xref ref-type="fig" rid="fig6s1">Figure 6—figure supplement 1b</xref>). No medial regions were found in these analyses.</p><p>Finally, we investigated the intrinsic connectivity of these multivariate clusters to the semantic and spatial context pathways (<xref ref-type="fig" rid="fig4">Figure 4d</xref>, <xref ref-type="fig" rid="fig6s1">Figure 6—figure supplement 1c</xref>), to establish whether cross-task RSA regions thought to support integration have an intermediate pattern of connectivity to both pathways. We used the MCB semantic and spatial context RSA clusters and the cross-task RSA result from <xref ref-type="fig" rid="fig6s1">Figure 6—figure supplement 1a–c</xref> as seeds in a seed-to-ROI analysis of intrinsic connectivity using independent data from Study 3. We performed a 2 two-way repeated-measures ANOVA, using a 3×2 design, entering seed (semantic, spatial context and cross-similarity RSA results), and pathway (ROIs in <xref ref-type="fig" rid="fig6s1">Figure 6—figure supplement 1c</xref>) as factors. The results can be seen in <xref ref-type="fig" rid="fig6s1">Figure 6—figure supplement 1d</xref>. There were main effects of seed (F(1.54,293.32)=194.24, p&lt;0.001), ROI (F(1,190)=290.07, p&lt;0.001) and their interaction (F(1.58,300.36)=123.36, p&lt;0.001). Post hoc comparisons confirmed that the spatial context pathway was equally connected to the spatial context RSA cluster and to the cross-task RSA cluster (spatial context &gt; cross-task: t(190)=–0.155, p&gt;0.05), with both of these clusters being significantly more connected than the semantic RSA cluster (spatial context &gt; semantic: t(190)=3.34, p=0.002; cross-task &gt; semantic: t(190)=4.41, p&lt;0.001). The semantic pathway was most connected to the semantic RSA cluster, less connected to the cross-task RSA cluster, and least connected to the spatial context RSA cluster (semantic &gt; cross-task: t(190)=9.2, p&lt;0.001; cross-task &gt; spatial context: t(190)=16.31, p&lt;0.001). In this way, the cross-task representation of spatial context information in visual regions during the semantic task showed an intermediate pattern of connectivity (particularly to the semantic pathway).</p><p>These cross-talk regions, in right LOC, have been implicated in the integration of objects with their spatial location, allowing object coherence in space in the face of saccadic movements that occur in natural vision while navigating environments (<xref ref-type="bibr" rid="bib62">McKyton and Zohary, 2007</xref>). Another fMRI study investigating the structure of identity-related and location-related representations in visual regions found an interaction effect of these aspects of knowledge for objects positioned in expected spatial locations, in a similar fashion to our study (<xref ref-type="bibr" rid="bib38">Gronau et al., 2008</xref>).</p><p>For completion, we present the results of RSA of SCB trials in <xref ref-type="fig" rid="fig6s2">Figure 6—figure supplement 2</xref> below.</p></sec><sec sec-type="appendix" id="s8-12"><title>Study 1. Training and test materials</title><p>In the training session, participants navigated virtual environments populated with objects, with the aim of learning these objects’ location in the environments. During this training, their memory was tested in a two-alternative forced-choice test and a matching task. <xref ref-type="fig" rid="fig7s1">Figure 7—figure supplement 1</xref> shows some example screenshots from videos used by participants to learn the environments, and the tests used during the training session to probe participants’ memory.</p></sec><sec sec-type="appendix" id="s8-13"><title>Study 2: Materials and results</title><p><xref ref-type="fig" rid="fig7s2">Figure 7—figure supplement 2</xref> shows example stimuli used in Study 2. Our localisers focussed on the scenes and objects conditions.</p><p>As shown in the left panel of <xref ref-type="fig" rid="fig2s1">Figure 2—figure supplement 1</xref>, the objects over scrambled objects contrast revealed activation in areas associated with the processing of objects and grasping, such as bilateral LOC, fusiform, parietal and precuneal cortex. The scenes over objects contrast showed activation in medial occipital and retrosplenial cortex, associated with scene processing. Since we were interested in using these activation maps as masks to determine relevant regions of the visual end of our pathways, we masked these effect maps by large-scale subnetworks implicated in vision from an influential parcellation (<xref ref-type="bibr" rid="bib120">Yeo et al., 2011</xref>; visual central and visual peripheral networks combined). The resulting masks showed some voxels in common, and since the aim of this analysis was to identify areas that preferentially respond to objects or scenes, we excluded these voxels in a final step (i.e. we removed all voxels from the objects mask that were also part of the scenes mask, and vice versa). These results can be consulted on the right panel of <xref ref-type="fig" rid="fig2s1">Figure 2—figure supplement 1</xref>.</p></sec></sec></app></app-group></back><sub-article article-type="editor-report" id="sa0"><front-stub><article-id pub-id-type="doi">10.7554/eLife.94902.3.sa0</article-id><title-group><article-title>eLife assessment</article-title></title-group><contrib-group><contrib contrib-type="author"><name><surname>Peelle</surname><given-names>Jonathan Erik</given-names></name><role specific-use="editor">Reviewing Editor</role><aff><institution>Northeastern University</institution><country>United States</country></aff></contrib></contrib-group><kwd-group kwd-group-type="evidence-strength"><kwd>Solid</kwd></kwd-group><kwd-group kwd-group-type="claim-importance"><kwd>Useful</kwd></kwd-group></front-stub><body><p>This <bold>useful</bold> experiment seeks to better understand how memory interacts with incoming visual information to effectively guide human behavior. Using several methods, the authors identify two distinct pathways relating visual processing to the default mode network: one that emphasizes semantic cognition, and the other, spatial cognition. The evidence presented is <bold>solid</bold> and will be of interest to cognitive and systems neuroscientists.</p></body></sub-article><sub-article article-type="referee-report" id="sa1"><front-stub><article-id pub-id-type="doi">10.7554/eLife.94902.3.sa1</article-id><title-group><article-title>Reviewer #2 (Public review):</article-title></title-group><contrib-group><contrib contrib-type="author"><anonymous/><role specific-use="referee">Reviewer</role></contrib></contrib-group></front-stub><body><p>Summary:</p><p>In this manuscript, Gonzalez Alam et al. sought to understand how memory interacts with incoming visual information to effectively guide human behavior by using a task that combines spatial contexts (houses) with objects of one or more other semantic categories. Three additional datasets (all from separate participants) were also employed: one that functionally localized regions of interest (ROIs) based on subtractions of different visually presented category types (in this case, scenes, objects, and scrambled objects); another consisting of resting-state functional connectivity scans, and a section of the Human Connectome Project that employed DTI data for structural connectivity analysis. Across multiple analyses, the authors identify dissociations between regions preferentially activated during scene or other object judgments, between the functional connectivity of regions demonstrating such preferences, and in the anatomical connectivity of these same regions. The authors conclude that the processing streams that take in visual information and support semantic or spatial processing are largely parallel and distinct.</p><p>Strengths:</p><p>(1) Recent work has reconceptualized the classic default mode network as parallel and interdigitated systems (e.g., Braga &amp; Buckner, 2017; DiNicola et al., 2021). The current manuscript is timely in that it attempts to describe how information is differentially processed by two streams that appear to begin in visual cortex and connect to different default subnetworks. Even at a group level where neuroanatomy is necessarily blurred across individuals, these results provide clear evidence of stimulus-based processing dissociation.</p><p>(2) The manuscript analyzes data from multiple independent datasets. It is therefore unlikely that a single experimenter choice in any given analysis would spuriously produce the general convergence of the results reported in this manuscript.</p><p>Weaknesses:</p><p>(1) The manuscript makes strong distinctions between spatial processing and other forms of semantic processing. However, it is not clear if scenes are uniquely different from other stimulus categories, such as faces or tools. As is noted by the authors in their revised discussion section, the design of the experiment does not allow for a category-level generalization beyond scenes. The dichotomization of semantic and spatial information invoked throughout the manuscript should be read with this limitation in mind.</p><p>(2) Although the term &quot;objects&quot; is used by the authors to refer to the stimuli placed in scenes, it is a mixture of other stimulus categories, including various types of animals, tools, and other manmade objects. Different regions along the ventral stream are thought to process these different types of stimuli (e.g., Martin, 2007, Ann Rev Psychol), but as they are not being modeled separately, the responses associated with &quot;object&quot; processing in this manuscript are necessarily blurring across known distinctions in functional neuroanatomy.</p></body></sub-article><sub-article article-type="author-comment" id="sa2"><front-stub><article-id pub-id-type="doi">10.7554/eLife.94902.3.sa2</article-id><title-group><article-title>Author response</article-title></title-group><contrib-group><contrib contrib-type="author"><name><surname>Gonzalez Alam</surname><given-names>Tirso RJ</given-names></name><role specific-use="author">Author</role><aff><institution>Bangor University</institution><addr-line><named-content content-type="city">Bangor</named-content></addr-line><country>United Kingdom</country></aff></contrib><contrib contrib-type="author"><name><surname>Krieger-Redwood</surname><given-names>Katya</given-names></name><role specific-use="author">Author</role><aff><institution>University of York</institution><addr-line><named-content content-type="city">York</named-content></addr-line><country>United Kingdom</country></aff></contrib><contrib contrib-type="author"><name><surname>Varga</surname><given-names>Dominika</given-names></name><role specific-use="author">Author</role><aff><institution>University of York</institution><addr-line><named-content content-type="city">York</named-content></addr-line><country>United Kingdom</country></aff></contrib><contrib contrib-type="author"><name><surname>Gao</surname><given-names>Zhiyao</given-names></name><role specific-use="author">Author</role><aff><institution>Stanford University</institution><addr-line><named-content content-type="city">Palo Alto</named-content></addr-line><country>United States</country></aff></contrib><contrib contrib-type="author"><name><surname>Horner</surname><given-names>Aidan J</given-names></name><role specific-use="author">Author</role><aff><institution>UCL Institute of Cognitive Neuroscience</institution><addr-line><named-content content-type="city">London</named-content></addr-line><country>United Kingdom</country></aff></contrib><contrib contrib-type="author"><name><surname>Hartley</surname><given-names>Tom</given-names></name><role specific-use="author">Author</role><aff><institution>University of York</institution><addr-line><named-content content-type="city">York</named-content></addr-line><country>United Kingdom</country></aff></contrib><contrib contrib-type="author"><name><surname>Thiebaut de Schotten</surname><given-names>Michel</given-names></name><role specific-use="author">Author</role><aff><institution>University of Bordeaux</institution><addr-line><named-content content-type="city">Paris</named-content></addr-line><country>France</country></aff></contrib><contrib contrib-type="author"><name><surname>Sliwinska</surname><given-names>Magdalena</given-names></name><role specific-use="author">Author</role><aff><institution>Liverpool John Moores University</institution><addr-line><named-content content-type="city">Liverpool</named-content></addr-line><country>United Kingdom</country></aff></contrib><contrib contrib-type="author"><name><surname>Pitcher</surname><given-names>David</given-names></name><role specific-use="author">Author</role><aff><institution>University of York</institution><addr-line><named-content content-type="city">York</named-content></addr-line><country>United Kingdom</country></aff></contrib><contrib contrib-type="author"><name><surname>Margulies</surname><given-names>Daniel</given-names></name><role specific-use="author">Author</role><aff><institution>Université de Paris</institution><addr-line><named-content content-type="city">Paris</named-content></addr-line><country>France</country></aff></contrib><contrib contrib-type="author"><name><surname>Smallwood</surname><given-names>Jonathan</given-names></name><role specific-use="author">Author</role><aff><institution>Queens University</institution><addr-line><named-content content-type="city">Kingston</named-content></addr-line><country>Canada</country></aff></contrib><contrib contrib-type="author"><name><surname>Jefferies</surname><given-names>Elizabeth</given-names></name><role specific-use="author">Author</role><aff><institution>University of York</institution><addr-line><named-content content-type="city">York</named-content></addr-line><country>United Kingdom</country></aff></contrib></contrib-group></front-stub><body><p>The following is the authors’ response to the original reviews.</p><disp-quote content-type="editor-comment"><p><bold>Public Reviews:</bold></p><p><bold>Reviewer #1 (Public Review):</bold></p><p>In this study, Gonzalez Alam et al. report a series of functional MRI results about the neural processing from the visual cortex to high-order regions in the default-mode network (DMN), compiling evidence from task-based functional MRI, resting-state connectivity, and diffusionweighted imaging. Their participants were first trained to learn the association between objects and rooms/buildings in a virtual reality experiment; after the training was completed, in the task-based MRI experiment, participants viewed the objects from the earlier training session and judged if the objects were in the semantic category (semantic task) or if they were previously shown in the same spatial context (spatial context task). Based on the task data, the authors utilised resting-state data from their previous studies, visual localiser data also from previous studies, as well as structural connectivity data from the Human Connectome Project, to perform various seed-based connectivity analysis. They found that the semantic task causes more activation of various regions involved in object perception while the spatial context task causes more activation in various regions for place perception, respectively. They further showed that those object perception regions are more connected with the frontotemporal subnetwork of the DMN while those place perception regions are more connected with the medial-temporal subnetwork of the DMN. Based on these results, the authors argue that there are two main pathways connecting the visual system to highlevel regions in the DMN, one linking object perception regions (e.g., LOC) leading to semantic regions (e.g., IFG, pMTG), the other linking place perception regions (e.g., parahippocampal gyri) to the entorhinal cortex and hippocampus.</p><p>Below I provide my takes on (1) the significance of the findings and the strength of evidence, (2) my guidance for readers regarding how to interpret the data, as well as several caveats that apply to their results, and finally (3) my suggestions for the authors.</p><p>(1) Significance of the results and strength of the evidence</p><p>I would like to praise the authors for, first of all, trying to associate visual processing with high-order regions in the DMN. While many vision scientists focus specifically on the macroscale organisation of the visual cortex, relatively few efforts are made to unravel how neural processing in the visual system goes on to engage representations in regions higher up in the hierarchy (a nice precedent study that looks at this issue is by Konkle and Caramazza, 2017). We all know that visual processing goes beyond the visual cortex, potentially further into the DMN, but there's no direct evidence. So, in this regard, the authors made a nice try to look at this issue.</p></disp-quote><p>We thank the reviewer for their positive feedback and for their very thoughtful and thorough comments, which have helped us to improve the quality of the paper.</p><disp-quote content-type="editor-comment"><p>Having said this, the authors' characterisation of the organisation of the visual cortex (object perception/semantics vs. place perception/spatial contexts) does not go beyond what has been known for many decades by vision neuroscience. Specifically, over the past two decades, numerous proposals have been put forward to explain the macroscale organisation of the visual system, particularly the ventrolateral occipitotemporal cortex. A lateral-medial division has been reliably found in numerous studies. For example, some researchers found that the visual cortex is organised along the separation of foveal vision (lateral) vs. peripheral vision (medial), while others found that it is structured according to faces (lateral) vs. places (medial). Such a bipartite division is also found in animate (lateral) vs. inanimate (medial), small objects (lateral) vs. big objects (medial), as well as various cytoarchitectonic and connectomic differences between the medial side and the lateral side of the visual cortex. Some more recent studies even demonstrate a tripartite division (small objects, animals, big objects; see Konkle and Caramazza, 2013). So, in terms of their characterisation of the visual cortex, I think Gonzalez Alam et al. do not add any novel evidence to what the community of neuroscience has already known.</p></disp-quote><p>The aim of our study was not to provide novel evidence about visual organisation, but rather to understand how these well-known visual subdivisions are related to functional divisions in memory-related systems, like the DMN. We agree that our study confirms the pattern observed by numerous other studies in visual neuroscience.</p><disp-quote content-type="editor-comment"><p>However, the authors' effort to link visual processing with various regions of the DMN is certainly novel, and their attempt to gather converging evidence with different methodologies is commendable. The authors are able to show that, in an independent sample of restingstate data, object-related regions are more connected with semantic regions in the DMN while place-related regions are more connected with navigation-related regions in the DMN, respectively. Such patterns reveal a consistent spatial overlap with their Kanwisher-type face/house localiser data and also concur with the HCP white-matter tractography data. Overall, I think the two pathways explanation that the authors seek to argue is backed by converging evidence. The lack of travelling wave type of analysis to show the spatiotemporal dynamics across the cortex from the visual cortex to high-level regions is disappointing though because I was expecting this type of analysis would provide the most convincing evidence of a 'pathway' going from one point to another. Dynamic caudal modelling or Granger causality may also buttress the authors' claim of pathway because many readers, like me, would feel that there is not enough evidence to convincingly prove the existence of a 'pathway'.</p></disp-quote><p>By ‘pathway’ we are referring to a pattern of differential connectivity between subregions of visual cortex and subregions of DMN, suggesting there are at least two distinct routes between visual and heteromodal regions. However, these routes don’t have to reflect a continuous sequence of cortical areas that extend from visual cortex to DMN – and given our findings of structural connectivity differences that relate to the functional subdivisions we observe, this is unlikely to be the sole mechanism underpinning our findings. We have now clarified this in the discussion section of the manuscript. We agree it would be interesting to characterise the spatiotemporal dynamics of neural propagation along our pathways, and we have incorporated this proposal into the future directions section.</p><p>“One important caveat is that we have not investigated the spatiotemporal dynamics of neural propagation along the pathways we identified between visual cortex and DMN. The dissociations we found in task responses, intrinsic functional connectivity and white matter connections all support the view that there are at least two distinct routes between visual and heteromodal DMN regions, yet this does not necessarily imply that there is a continuous sequence of cortical areas that extend from visual cortex to DMN – and given our findings of structural connectivity differences that relate to the functional subdivisions we observe, this is unlikely to be the sole mechanism underpinning our findings. It would be interesting in future work to characterise the spatiotemporal dynamics of neural propagation along visualDMN pathways using methods optimised for studying the dynamics of information transmission, like Granger causality or travelling wave analysis.”</p><p>We have also edited the wording of sentences in the introduction and discussion that we thought might imply directionality or transmission of information along these pathways, or to clarify the nature of the pathways (please see a couple of examples below):</p><p>In the Introduction:</p><p>“We identified dissociable pathways of connectivity between from different parts of visual cortex to and DMN subsystems “</p><p>In the Discussion:</p><p>“…pathways from visual cortex to DMN -&gt; …pathways between visual cortex and DMN“.</p><disp-quote content-type="editor-comment"><p>(2) Guidance to the readers about interpretation of the data</p><p>The organisation of the visual cortex and the organisation of the DMN historically have been studied in parallel with little crosstalk between different communities of researchers. Thus, the work by Gonzalez Alam et al. has made a nice attempt to look at how visual processing goes beyond the realm of the visual cortex and continues into different subregions of the DMN.</p></disp-quote><p>While the authors of this study have utilised multiple methods to obtain converging evidence, there are several important caveats in the interpretation of their results:</p><p>(1) While the authors choose to use the term 'pathway' to call the inter-dependence between a set of visual regions and default-mode regions, their results have not convincingly demonstrated a definitive route of neural processing or travelling. Instead, the findings reveal a set of DMN regions are functionally more connected with object-related regions compared to place-related regions. The results are very much dependent on masking and thresholding, and the patterns can change drastically if different masks or thresholds are used.</p><p>We would like to qualify that our findings do not only reveal a set of <italic>any</italic> “DMN regions that are functionally more connected with object-related regions compared to place-related regions”. Instead, we show a double dissociation based on our functional task responses: DMN regions that were more responsive to semantic decisions about objects are more functionally and structurally connected to visual regions more activated by perceiving objects, while DMN regions that were more responsive to spatial decisions are more connected to visual regions activated by the contrast of scene over object perception.</p><p>We do not believe that the thresholding or masking involved in generating seeds strongly affected our results. We are reassured of this by two facts:</p><p>(1) We re-analysed the resting-state data using a stricter clustering threshold and this did not change the pattern of results (see response below).</p><p>(2) In response to a point by reviewer #2, we re-analysed the data eroding the masks of the MT-DMN, and this also didn’t change the pattern of results (please see response to reviewer 2).</p><p>In this way, our results are robust to variations in mask shape/size and thresholding.</p><disp-quote content-type="editor-comment"><p>(2) Ideally, if the authors could demonstrate the dynamics between the visual cortex and DMN in the primary task data, it would be very convincing evidence for characterising the journey from the visual cortex to DMN. Instead, the current connectivity results are derived from a separate set of resting state data. While the advantage of the authors' approach is that they are able to verify certain visual regions are more connected with certain DMN regions even under a task-free situation, it falls short of explaining how these regions dynamically interact to convert vision into semantic/spatial decision.</p></disp-quote><p>We agree that a valuable future direction would be to collect evidence of spatiotemporal dynamics of propagation of information along these pathways. This could be the focus of future studies designed to this aim, and we have suggested this in the manuscript based on the reviewer’s suggestion. Furthermore, as stated above, we have now qualified our use of the term ‘pathway’ in the manuscript to avoid confusion.</p><p>“These pathways refer to regions that are coupled, functionally or structurally, together, providing the potential for communication between them.”</p><disp-quote content-type="editor-comment"><p>(3) There are several results that are difficult to interpret, such as their psychophysiological interactions (PPI), representational similarity analysis, and gradient analysis. For example, typically for PPI analysis, researchers interrogate the whole brain to look for PPI connectivity. Their use of targeted ROI is unusual, and their use of spatially extensive clusters that encompass fairly large cortical zones in both occipital and temporal lobes as the PPI seeds is also an unusual approach. As for the gradient analysis, the argument that the semantic task is higher on Gradient 1 than the spatial task based on the statistics of p-value = 0.027 is not a very convincing claim (unhelpfully, the figure on the top just shows quite a few blue 'spatial dots' on the hetero-modal end which can make readers wonder if the spatial context task is really closer to the unimodal end or it is simply the authors' statistical luck that they get a p-value under 0.05). While it is statistically significant, it is weak evidence (and it is not pertinent to the main points the authors try to make).</p></disp-quote><p>To streamline the manuscript, we have moved the PPI and RSA results to the</p><p>Supplementary Materials. However, we believe the gradient analysis is highly pertinent to understanding the functional separation of these pathways. In the revision, we show that not only was the contrast between the Semantic and Spatial tasks significant, in addition, the majority of participants exhibited a pattern consistent with the result we report. To show the results more clearly, we have added a supplementary figure (Figure S8) focussed on comparisons at the participant level.</p><p>This figure shows the position in the gradient for each peak per participant per task. The peaks for each participant across tasks are linked with a line. Cases where the pattern was reversed are highlighted with dashed lines (7/27 participants in each gradient). This allows the reader and reviewer to verify in how many cases, at the individual level, the pattern of results reported in the text held (see “Supplementary Analysis: Individual Location of pathways in whole-brain gradients”).</p><disp-quote content-type="editor-comment"><p>(3) My suggestion for the authors</p><p>There are several conceptual-level suggestions that I would like to offer to the authors:</p><p>(1) If the pathway explanation is the key argument that you wish to convey to the readers, an effective connectivity type of analysis, such as Granger causality or dynamic caudal modelling, would be helpful in revealing there is a starting point and end point in the pathway as well as revealing the directionality of neural processing. While both of these methods have their issues (e.g., Granger causality is not suitable for haemodynamic data, DCM's selection of seeds is susceptible to bias, etc), they can help you get started to test if the path during task performance does exist. Alternatively, travelling wave type of analysis (such as the results by Raut et al. 2021 published in Science Advances) can also be useful to support your claims of the pathway.</p></disp-quote><p>As we have stated above, we agree with the reviewer that, given the pattern of results obtained in our work, analyses that characterise the spatiotemporal dynamics of transmission of information along the pathways would be of interest. However, we are concerned that our data is not well-optimised for these analyses.</p><disp-quote content-type="editor-comment"><p>(2) I think the thresholding for resting state data needs to be explained - by the look of Figure 2E and 3E, it looks like whole-brain un-thresholded results, and then you went on to compute the conjunction between these un-thresholded maps with network templates of the visual system and DMN. This does not seem statistically acceptable, and I wonder if the conjunction that you found would disappear and reappear if you used different thresholds. Thus, for example, if the left IFG cluster (which you have shown to be connected with the visual object regions) would disappear when you apply a conventional threshold, this means that you need to seriously consider the robustness of the pathway that you seek to claim... it may be just a wild goose that you are chasing.</p></disp-quote><p>We believe the reviewer might be confused regarding the procedure we followed to generate the ROIs used in the pathways connectivity analysis. As stated in the last paragraph of the “Probe phase” and “Decision phase” results subsections, the maps the reviewer is referring to (Fig. 3E, for example) were generated by seeding the intersection of our thresholded univariate analysis (Fig. 3A) with network templates. In the case of Fig 3E, these are the Semantic&gt;Spatial decision results after thresholding, intersected with Yeo DMN (MT, FT and Core, combined). These seeds were then entered into a whole-brain seed-based spatial correlation analysis, which was thresholded and cluster-corrected using the defaults of CONN. The same is true for Fig. 2E, but using the thresholded Probe phase</p><p>Semantic&gt;Context regions. Thus, we do not believe the objections to statistical rigour the reviewer is raising apply to our results.</p><p>The thresholding of the resting-state data itself was explained in the Methods (Spatial Maps and Seed-to-ROI Analysis). As stated above, we thresholded using the default of the CONN software package we used (cluster-forming threshold of p=.05, equivalent to T=1.65). For increased rigour, we reproduced the thresholded maps from Figs 2E and 3E further increasing the threshold from p=.05, equivalent to T=1.65, to p=.001, equivalent to T=3.1. The resulting maps were very similar, showing minimal change with a spatial correlation of r &gt; .99 between the strict and lax threshold versions of the maps for both the probe and decision seeds. This can be seen in Figure 2E and Figure 33E, which depict the maps produced with stricter thresholding. These maps can also be downloaded from the Neurovault collection, and the re-analysis is now reported in the Supplementary Materials (see section “Supplementary Analysis: Resting-state maps with stricter thresholding”) Probe phase (compare with Fig. 2E):</p><disp-quote content-type="editor-comment"><p>(3) There are several analyses that are hard to interpret and you can consider only reporting them in the supplementary materials, such as the PPI results and representational similarity analysis, as none of these are convincing. These analyses do not seem to add much value to make your argument more convincing and may elicit more methodological critiques, such as statistical issues, the set-up of your representational theory matrix, and so on.</p></disp-quote><p>We have moved the PPI and RSA results to the supplementary materials. We agree this will help us streamline the manuscript.</p><disp-quote content-type="editor-comment"><p><bold>Reviewer #2 (Public Review):</bold></p><p>Summary:</p><p>In this manuscript, Alam et al. sought to understand how memory interacts with incoming visual information to effectively guide human behavior by using a task that combines spatial contexts (houses) with objects of one or multiple semantic categories. Three additional datasets (all from separate participants) were also employed: one that functionally localized regions of interest (ROIs) based on subtractions of different visually presented category types (in this case, scenes, objects, and scrambled objects); another consisting of restingstate functional connectivity scans, and a section of the Human Connectome Project that employed DTI data for structural connectivity analysis. Across multiple analyses, the authors identify dissociations between regions preferentially activated during scene or object judgments, between the functional connectivity of regions demonstrating such preferences, and in the anatomical connectivity of these same regions. The authors conclude that the processing streams that take in visual information and support semantic or spatial processing are largely parallel and distinct.</p><p>Strengths:</p><p>(1) Recent work has reconceptualized the classic default mode network as two parallel and interdigitated systems (e.g., Braga &amp; Buckner, 2017; DiNicola et al., 2021). The current manuscript is timely in that it attempts to describe how information is differentially processed by two streams that appear to begin in visual cortex and connect to different default subnetworks. Even at a group level where neuroanatomy is necessarily blurred across individuals, these results provide clear evidence of stimulus-based dissociation.</p><p>(2) The manuscript contains a large number of analyses across multiple independent datasets. It is therefore unlikely that a single experimenter choice in any given analysis would spuriously produce the overall pattern of results reported in this work.</p></disp-quote><p>We thank the reviewer for their remarks on the strengths of our manuscript.</p><disp-quote content-type="editor-comment"><p>Weaknesses:</p><p>(1) Throughout the manuscript, a strong distinction is drawn between semantic and spatial processing. However, given that only objects and spatial contexts were employed in the primary experiment, it is not clear that a broader conceptual distinction is warranted between &quot;semantic&quot; and &quot;spatial&quot; cognition. There are multiple grounds for concern regarding this basic premise of the manuscript.</p><p>a. One can have conceptual knowledge of different types of scenes or spatial contexts. A city street will consistently differ from a beach in predictable ways, and a kitchen context provides different expectations than a living room. Such distinctions reflect semantic knowledge of scene-related concepts, but in the present work spatial and &quot;all other&quot; semantic information are considered and discussed as distinct and separate.</p></disp-quote><p>The “building” contexts we created were arbitrary, containing beds, desks and an assortment of furniture that did not reflect usual room distributions, i.e., a kitchen next to a dining room. We have made this aspect of our stimuli clearer in the Materials section of the task.</p><p>“The learning phase employed videos showing a walk-through for twelve different buildings (one per video), shot from a first-person perspective. The videos and buildings were created using an interior design program (Sweet Home 3D). Each building consisted of two rooms: a bedroom and a living room/office, with an ajar door connecting the two rooms. The order of the rooms (1st and 2nd) was counterbalanced across participants. Each room was distinctive, with different wallpaper/wall colour and furniture arrangements. The building contexts created by these rooms were arbitrary, containing furniture that did not reflect usual room distributions (i.e., a kitchen next to a dining room), to avoid engaging further conceptual knowledge about frequently-encountered spatial contexts in the real world.”</p><p>To help the reviewer and readers to verify this and come to their own conclusions, we have also added the videos watched by the participants to the OSF collection.</p><p>“A full list of pictures of the object and location stimuli employed in this task, as well as the videos watched by the participants can be consulted in the OSF collection associated with this project under the components OSF&gt;Tasks&gt;Training. “</p><p>We agree that scenes or spatial contexts have conceptual characteristics, and we actually manipulated conceptual information about the buildings in our task, in order to assess the neural underpinnings of this effect. In half of the buildings, the rooms/contexts were linked through the presence of items that shared a common semantic category (our “same category building” condition): this presented some conceptual scaffolding that enabled participants to link two rooms together. These buildings could then be contrasted with “mixed category buildings” where this conceptual link between rooms was not available. We found that right angular gyrus was important in the linking together of conceptual and spatial information, in the contrast of same versus mixed category buildings.</p><disp-quote content-type="editor-comment"><p>b. As a related question, are scenes uniquely different from all other types of semantic/category information? If faces were used instead of scenes, could one expect to see different regions of the visual cortex coupling with task-defined face &gt; object ROIs? The current data do not speak to this possibility, but as written the manuscript suggests that all (non-spatial) semantic knowledge should be processed by the FT-DMN.</p></disp-quote><p>Thanks for raising this important point. Previous work suggests that the human visual system (and possibly the memory system, as suggested by Deen and Freiwald, 2021) is sensitive to perceptual categories important to human behaviour, including spatial, object and social information. Previous work (Silson et al., 2019; Steel et al., 2021) has shown domain-specific regions in visual regions (ventral temporal cortex; VTC) whose topological organisation is replicated in memory regions in medial parietal cortex (MPC) for faces and places. In these studies, adding objects to the analyses revealed regions sensitive to this category sandwiched between those responsive to people and places in VTC, but not in MPC. However, consistent with our work, the authors find regions sensitive to memory tasks for places and objects (as well as people) in the lateral surface of the brain.</p><p>Our study was not designed to probe every category in the human visual system, and therefore we cannot say what would happen if we contrasted social judgments about faces with semantic judgments about objects. We have added this point as a limitation and future direction for research:</p><p>“Likewise, further research should be carried out on memory-visual interactions for alternative domains. Our study focused on spatial location and semantic object processing and therefore cannot address how other categories of stimuli, such as faces, are processed by the visual-tomemory pathways that we have identified. Previous work has suggested some overlap in the neurobiological mechanisms for semantic and social processing (Andrews-Hanna et al., 2014; Andrews-Hanna &amp; Grilli, 2021; Chiou et al., 2020), suggesting that the FT-DMN pathway may be highlighted when contrasting both social faces and semantic objects with spatial scenes. On the other hand, some researchers have argued for a ‘third pathway’ for aspects of social visual cognition (Pitcher &amp; Ungerleider, 2021; Pitcher, 2023). Future studies that probe other categories will be able to confirm the generality (or specificity) of the pathways we described.”</p><disp-quote content-type="editor-comment"><p>c. Recent precision fMRI studies characterizing networks corresponding to the FT-DMN and MTL-DMN have associated the former with social cognition and the latter with scene construction/spatial processing (DiNicola et al., 2020; 2021; 2023). This is only briefly mentioned by the authors in the current manuscript (p. 28), and when discussed, the authors draw a distinction between semantic and social or emotional &quot;codes&quot; when noting that future work is necessary to support the generality of the current claims. However, if generality is a concern, then emphasizing the distinction between object-centric and spatial cognition, rather than semantic and spatial cognition, would represent a more conservative and bettersupported theoretical point in the current manuscript.</p></disp-quote><p>We appreciate this comment and we have spent quite a bit of time considering what the most appropriate terminology would be. The distinction between object and spatial cognition is largely appropriate to our probe phase, although we feel this label is still misleading for two reasons:</p><p>First, we used a range of items from different semantic categories, not just “objects”, although we have used that term as a shorthand to refer to the picture stimuli we presented. The stimuli include both animals (land animals, marine animals and birds) and man-made objects (tools, musical instruments and sports equipment). This category information is now more prominent in the rationale (Introduction) and the Methods to avoid confusion.</p><p>Interested readers can also review our “object” stimuli in the OSF collection associated with this manuscript:</p><p>Introduction: “…participants learned about virtual environments (buildings) populated with objects belonging to different, heterogeneous, semantic categories, both man-made (tools, musical instruments, sports equipment) and natural (land animals, marine animals, birds).”</p><p>Methods:</p><p>“A full list of pictures of the object and location stimuli employed in this task can be consulted in the OSF collection associated with this project under the components OSF&gt;Tasks&gt;Training.”</p><p>Secondly, we manipulated the task demands so that participants were making semantic judgments about whether two items were in the same category, or spatial judgments about whether two rooms had been presented in the same building. Our use of the terms “semantic” and “spatial” was largely guided by the tasks that participants were asked to perform.</p><p>We have revised the terminology used in the discussion to reflect this more conservative term. However, since the task performed was semantic in nature (participants had to judge whether items belonged to semantic categories), we have modified the term proposed by the reviewer to “object-centric semantics”, which we hope will avoid confusion.</p><disp-quote content-type="editor-comment"><p>(2) Both the retrosplenial/parieto-occipital sulcus and parahippocampal regions are adjacent to the visual network as defined using the Yeo et al. atlas, and spatial smoothness of the data could be impacting connectivity metrics here in a way that qualitatively differs from the (non-adjacent) FT-DMN ROIs. Although this proximity is a basic property of network locations on the cortical surface, the authors have several tools at their disposal that could be employed to help rule out this possibility. They might, for instance, reduce the smoothing in their multi-echo data, as the current 5 mm kernel is larger than the kernel used in Experiment 2's single-echo resting-state data. Spatial smoothing is less necessary in multiecho data, as thermal noise can be attenuated by averaging over time (echoes) instead of space (see Gonzalez-Castillo et al., 2016 for discussion). Some multi-echo users have eschewed explicit spatial smoothing entirely (e.g., Ramot et al., 2021), just as the authors of the current paper did for their RSA analysis. Less smoothing of E1 data, combined with a local erosion of either the MTL-DMN and VIS masks (or both) near their points of overlap in the RSFC data, would improve confidence that the current results are not driven, at least in part, by spatial mixing of otherwise distinct network signals.</p></disp-quote><p>A: The proximity of visual peripheral and DMN-C networks is a property of these networks’ organisation (Silson et al., 2019; Steel et al., 2021), and we agree the potential for spatial mixing of the signal due to this adjacency is a valid concern. Altering the smoothing kernel of the multi-echo data would not address this issue though, since no connectivity analyses were performed in task data. The reviewer is right about the kernel size for task data (5mm), but not about the single echo RS data, which actually has lower spatial resolution (6mm).</p><p>Since this objection is largely about the connectivity analysis, we re-analysed the RS data by shrinking the size of the visual probe and DMN decision ROIs for the context task using fslmaths. We eroded the masks until the smallest gap between them exceeded the size of our 6mm FWHM smoothing kernel, which eliminates the potential for spatial mixing of signals due to ROI adjacency. The eroded ROIs can be consulted in the OSF collection associated with this project see component “ROI Analysis/Revision_ErodedMasks”. The results, presented in the supplementary materials as “Eroded masks replication analysis”, confirmed the pattern of findings reported in the manuscript (see SM analysis below). We did not erode the respective ROIs for the semantic task, given that adjacency is not an issue there.</p><p>“Eroded masks replication analysis:</p><p>The Visual-to-DMN ANOVA showed main effects of seed (F(1,190)=22.82, p&lt;.001), ROI (F(1,190)=9.48, p=.002) and a seed by ROI interaction (F(1,190)=67.02, p&lt;.001). Post-hoc contrasts confirmed there was stronger connectivity between object probe regions and semantic versus spatial context decision regions (t(190)=3.38, p&lt;.001), and between scene probe regions and spatial context versus semantic decision regions (t(190)=-7.66, p&lt;.001).</p><p>The DMN-to-Visual ANOVA confirmed this pattern: again, there was a main effect of ROI (F(1,190)=4.3, p=.039) and a seed by ROI interaction (F(1,190)=57.59, p&lt;.001), with posthoc contrasts confirming stronger intrinsic connectivity between DMN regions implicated in semantic decisions and object probe regions (t(190)=5.06, p&lt;.001), and between DMN regions engaged by spatial context decisions and scene probe regions (t(190)=3.25, p=.001).”</p><disp-quote content-type="editor-comment"><p>(3) The authors identify a region of the right angular gyrus as demonstrating a &quot;potential role in integrating the visual-to-DMN pathways.&quot; This would seem to imply that lesion damage to right AG should produce difficulties in integrating &quot;semantic&quot; and &quot;spatial&quot; knowledge. Are the authors aware of such a literature? If so, this would be an important point to make in the manuscript as it would tie in yet another independent source of information relevant to the framework being presented. The closest of which I am aware involves deficits in cued recall performance when associates consisted of auditory-visual pairings (Ben-Zvi et al., 2015), but that form of multi-modal pairing is distinct from the &quot;spatial-semantic&quot; integration forwarded in the current manuscript.</p></disp-quote><p>This is a very interesting observation. There is a body of literature pointing to AG (more often left than right) as an integrator of multimodal information: It has been shown to integrate semantic and episodic memory, contextual information and cross-modality content.</p><p>The Contextual Integration Model (Ramanan et al., 2017) proposes that AG plays a crucial role in multimodal integration to build context. Within this model, information that is essential for the representation of rich, detailed recollection and construction (like <italic>who, when,</italic> and, crucially for our findings, <italic>what and where</italic>) is processed elsewhere, but integrated and represented in the AG. In line with this view, Bonnici et al (2016) found AG engagement during retrieval of multimodal episodic memories, and that multivariate classifiers could differentiate multimodal memories in AG, while unimodal memories were represented in their respective sensory areas only. Recent work examining semantic processing in temporallyextended narratives using multivariate approaches concurs with a key role of left AG in context integration (Branzi et al., 2020).</p><p>In addition to context integration, other lines of work suggest a role of AG as an integrator across modalities, more specifically. Recent perspectives suggest a role of AG as a dynamic buffer that allows combining distinct forms of information into multimodal representations (Humphreys et al., 2021), which is consistent with the result in our study of a region that brings together semantic and spatial representations in line with task demands. Others have proposed a role of the AG as a central connector hub that links three semantic subsystems, including multimodal experiential representation (Xu et al., 2017). Causal evidence of the role of AG in integrating multimodal features has been provided by Yazar et al (2017), who studied participants performing memory judgements of visual objects embedded in scenes, where the name of the object was presented auditorily. TMS to AG impaired participants’ ability to retrieve context features across multiple modalities. However, these studies do not single out specifically right AG.</p><p>Some recent proposals suggest a causal role of right AG as a key region in the early definition of a context for the purpose of sensemaking, for which integrating semantic information with many other modalities, including vision, may be a crucial part (Seghier, 2023). TMS studies suggest a causal role for the right AG in visual attention across space</p><p>(Olk et al. 2015, Petitet et al. 2015), including visual search and the binding of stimulus- and response-characteristics that can optimise it (Bocca et al. 2015). TMS over the right AG disrupts the ability to search for a target defined by a conjunction of features (Muggleton et al. 2008) and affects decision-making when visuospatial attention is required (Studer et al. 2014). This suggests that the AG might contribute to perceptual decision-making by guiding attention to relevant information in the visual environment (Studer et al. 2014). These, taken together, suggest a causal role of right AG in controlling attention across space and integrating content across modalities in order to search for relevant information.</p><p>Most of this body of research points to left, rather than right, AG as a key region for integration, but we found regions of right AG to be important when semantic and spatial information could be integrated. We might have observed involvement of the right AG in our study, as opposed to the more-often reported left, given that people have to integrate semantic information with spatial context, which relies heavily on visuospatial processes predominantly located in right hemisphere regions (cf. Sormaz et al., 2017), which might be more strongly connected to right than left AG.</p><p>Lastly, we are not aware of a literature on right AG lesions impairing the integration of semantic and spatial information but, in the face of our findings, this might be a promising new direction. We have added as a recommendation that patients with damage to right AG should be examined with specific tasks aimed at probing this type of integration. We have added the following to the discussion:</p><p>“We found a region of the right AG that was potentially important for integrating semantic and spatial context information. Previous research has established a key role of the AG in context integration (Ramanan et al., 2017; Bonnici et al., 2016; Branzi et al., 2020) and specifically, in guiding multimodal decisions and behaviour (Humphreys et al., 2021; Xu et al., 2017; Yazar et al., 2017). Although some recent proposals suggest a causal role of right AG in the early establishment of meaningful contexts, allowing semantic integration across modalities (Seghier, 2023; Olk et al., 2015, Petitet et al., 2015; Bocca et al., 2015; Muggleton et al. 2008), the majority of this research points to left, rather than right, AG as a key region for integration. However, we might have observed involvement of the right AG in our study given that people were integrating semantic information with spatial context, and right-lateralised visuospatial processes (cf. Sormaz et al., 2017) might be more strongly connected to right than left AG. We are not aware of a literature on right AG lesions impairing the integration of semantic and spatial information but, in the face of our findings, this might be a promising new direction. Patients with damage to right AG should be examined with specific tasks aimed at probing this type of integration.”</p><disp-quote content-type="editor-comment"><p><bold>Recommendations for the authors:</bold></p><p><bold>Reviewer #2 (Recommendations For The Authors):</bold></p><p>(1) I mentioned the numerous converging analyses reported in this manuscript as a strength. However, in practice, it also makes results in numerous dense figures (routinely hitting 7-8 sub-panels) and results paragraphs which, as currently presented, are internally coherent but are not assembled into a &quot;bigger picture&quot; until the discussion. Readers may have an easier time with the paper if introductions to the different analyses (&quot;probe phase&quot;, &quot;decision phase&quot;, etc.) also include a bigger-picture summary of how the specific analysis is contributing to the larger argument that is being constructed throughout the manuscript. This may also help readers to understand why so many different analysis approaches and decisions were employed throughout the manuscript, why so many different masks were used, etc.</p></disp-quote><p>Thank you for this suggestion. We agree that the range of analyses and their presentation can make digesting them difficult. To address this, we have outlined our analyses rationale at the beginning of the results as a sort of “big picture” summary that links all analyses together, and added introductory paragraphs to each analysis that needed them (namely, the probe, decision, and pathway connectivity analyses, as the gradient and integration analyses already had introductory paragraphs describing their rationale, and the PPI/RSA analyses were moved to supplementary materials), linking them to the summary, which we reproduce below:</p><p>“To probe the organisation of streams of information between visual cortex and DMN, our neuroimaging analysis strategy consisted of a combination of task-based and connectivity approaches. We first delineated the regions in visual cortex that are engaged by the viewing of probes during our task (Figure 2), as well as the DMN regions that respond when making decisions about those probes (Figure 3): we characterised both by comparing the activation maps with well-established DMN and object/scene perception regions, analysed the pattern of activation within them, their functional connectivity and task associations. Having characterised the two ends of the stream, we proceeded to ask whether they are differentially linked: are the regions activated by object probe perception more strongly linked to DMN regions that are activated when making semantic decisions about object probes, relative to other DMN regions? Is the same true for the spatial context probe and decision regions? We answered this question through a series of connectivity analyses (Figure 4) that examined: (1) if the functional connectivity of visual-to-DMN regions (and DMN-to-visual regions) showed a dissociation, suggesting there are object semantic and spatial cognition processing ‘pathways’; (2) if this pattern was replicated in structural connectivity; (3) if it was present at the level of individual participants, and, (4) we characterised the spatial layout, network composition (using influential RS networks) and cognitive decoding of these pathways. Having found dissociable pathways for semantic (object) and spatial context (scene) processing, we then examined their position in a high-dimensional connectivity space (Figure 5) that allowed us to document that the semantic pathway is less reliant on unimodal regions (i.e., more abstract) while the spatial context pathway is more allied to the visual system. Finally, we used uni- and multivariate approaches to examine how integration between these pathways takes place when semantic and spatial information is aligned (Figure 6).”</p><disp-quote content-type="editor-comment"><p>(2) At various points, figures are arranged out of sequence (e.g., panel d is referenced after panel g in Figure 2) or are missing descriptions of what certain colors mean (e.g., what yellow represents in Figure 6d). This is a minor issue, but one that's important and easy to address in future revisions.</p></disp-quote><p>We thank the reviewer for bringing this issue to our attention. We have added descriptions for the yellow colour to the figure legends of Figures 6 and 7 (now in supplementary materials, Figure S9).</p><p>We have also edited the text to follow a logical sequence with respect to referencing the panels in Figures 2 and 3, where panel d is now referenced after panel c. Lastly, we reorganised the layout of Figure 4 to follow the description of the results in the text.</p></body></sub-article></article>