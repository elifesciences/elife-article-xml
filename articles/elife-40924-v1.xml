<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD v1.1 20151215//EN"  "JATS-archivearticle1.dtd"><article article-type="research-article" dtd-version="1.1" xmlns:ali="http://www.niso.org/schemas/ali/1.0/" xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink"><front><journal-meta><journal-id journal-id-type="nlm-ta">elife</journal-id><journal-id journal-id-type="publisher-id">eLife</journal-id><journal-title-group><journal-title>eLife</journal-title></journal-title-group><issn pub-type="epub" publication-format="electronic">2050-084X</issn><publisher><publisher-name>eLife Sciences Publications, Ltd</publisher-name></publisher></journal-meta><article-meta><article-id pub-id-type="publisher-id">40924</article-id><article-id pub-id-type="doi">10.7554/eLife.40924</article-id><article-categories><subj-group subj-group-type="display-channel"><subject>Research Article</subject></subj-group><subj-group subj-group-type="heading"><subject>Computational and Systems Biology</subject></subj-group><subj-group subj-group-type="heading"><subject>Neuroscience</subject></subj-group></article-categories><title-group><article-title>Contrast sensitivity reveals an oculomotor strategy for temporally encoding space</article-title></title-group><contrib-group><contrib contrib-type="author" corresp="yes" id="author-103536"><name><surname>Casile</surname><given-names>Antonino</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">http://orcid.org/0000-0002-7824-9274</contrib-id><email>antonino.casile@iit.it</email><email>toninocasile@gmail.com</email><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="aff" rid="aff2">2</xref><xref ref-type="aff" rid="aff3">3</xref><xref ref-type="other" rid="fund5"/><xref ref-type="fn" rid="con1"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" id="author-52343"><name><surname>Victor</surname><given-names>Jonathan D</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">http://orcid.org/0000-0002-9293-0111</contrib-id><email>jdvicto@med.cornell.edu</email><xref ref-type="aff" rid="aff4">4</xref><xref ref-type="aff" rid="aff5">5</xref><xref ref-type="other" rid="fund3"/><xref ref-type="fn" rid="con2"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" corresp="yes" id="author-119234"><name><surname>Rucci</surname><given-names>Michele</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">http://orcid.org/0000-0002-3066-1964</contrib-id><email>rucci.michele@gmail.com</email><xref ref-type="aff" rid="aff6">6</xref><xref ref-type="aff" rid="aff7">7</xref><xref ref-type="other" rid="fund1"/><xref ref-type="other" rid="fund2"/><xref ref-type="other" rid="fund4"/><xref ref-type="fn" rid="con3"/><xref ref-type="fn" rid="conf1"/></contrib><aff id="aff1"><label>1</label><institution content-type="dept">Center for Translational Neurophysiology</institution><institution>Istituto Italiano di Tecnologia</institution><addr-line><named-content content-type="city">Ferrara</named-content></addr-line><country>Italy</country></aff><aff id="aff2"><label>2</label><institution>Center for Neuroscience and Cognitive Systems</institution><addr-line><named-content content-type="city">Rovereto</named-content></addr-line><country>Italy</country></aff><aff id="aff3"><label>3</label><institution content-type="dept">Department of Neurobiology</institution><institution>Harvard Medical School</institution><addr-line><named-content content-type="city">Boston</named-content></addr-line><country>United States</country></aff><aff id="aff4"><label>4</label><institution content-type="dept">Brain and Mind Research Institute</institution><institution>Weill Cornell Medical College</institution><addr-line><named-content content-type="city">New York</named-content></addr-line><country>United States</country></aff><aff id="aff5"><label>5</label><institution content-type="dept">Department of Neurology</institution><institution>Weill Cornell Medical College</institution><addr-line><named-content content-type="city">New York</named-content></addr-line><country>United States</country></aff><aff id="aff6"><label>6</label><institution content-type="dept">Brain and Cognitive Sciences</institution><institution>University of Rochester</institution><addr-line><named-content content-type="city">Rochester</named-content></addr-line><country>United States</country></aff><aff id="aff7"><label>7</label><institution content-type="dept">Center for Visual Science</institution><institution>University of Rochester</institution><addr-line><named-content content-type="city">Rochester</named-content></addr-line><country>United States</country></aff></contrib-group><contrib-group content-type="section"><contrib contrib-type="editor"><name><surname>Rieke</surname><given-names>Fred</given-names></name><role>Reviewing Editor</role><aff><institution>University of Washington</institution><country>United States</country></aff></contrib><contrib contrib-type="senior_editor"><name><surname>Behrens</surname><given-names>Timothy E</given-names></name><role>Senior Editor</role><aff><institution>University of Oxford</institution><country>United Kingdom</country></aff></contrib></contrib-group><pub-date date-type="publication" publication-format="electronic"><day>08</day><month>01</month><year>2019</year></pub-date><pub-date pub-type="collection"><year>2019</year></pub-date><volume>8</volume><elocation-id>e40924</elocation-id><history><date date-type="received" iso-8601-date="2018-08-09"><day>09</day><month>08</month><year>2018</year></date><date date-type="accepted" iso-8601-date="2018-12-03"><day>03</day><month>12</month><year>2018</year></date></history><permissions><copyright-statement>© 2019, Casile et al</copyright-statement><copyright-year>2019</copyright-year><copyright-holder>Casile et al</copyright-holder><ali:free_to_read/><license xlink:href="http://creativecommons.org/licenses/by/4.0/"><ali:license_ref>http://creativecommons.org/licenses/by/4.0/</ali:license_ref><license-p>This article is distributed under the terms of the <ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/licenses/by/4.0/">Creative Commons Attribution License</ext-link>, which permits unrestricted use and redistribution provided that the original author and source are credited.</license-p></license></permissions><self-uri content-type="pdf" xlink:href="elife-40924-v1.pdf"/><abstract><object-id pub-id-type="doi">10.7554/eLife.40924.001</object-id><p>The contrast sensitivity function (CSF), how sensitivity varies with the frequency of the stimulus, is a fundamental assessment of visual performance. The CSF is generally assumed to be determined by low-level sensory processes. However, the spatial sensitivities of neurons in the early visual pathways, as measured in experiments with immobilized eyes, diverge from psychophysical CSF measurements in primates. Under natural viewing conditions, as in typical psychophysical measurements, humans continually move their eyes even when looking at a fixed point. Here, we show that the resulting transformation of the spatial scene into temporal modulations on the retina constitutes a processing stage that reconciles human CSF and the response characteristics of retinal ganglion cells under a broad range of conditions. Our findings suggest a fundamental integration between perception and action: eye movements work synergistically with the spatio-temporal sensitivities of retinal neurons to encode spatial information.</p></abstract><kwd-group kwd-group-type="author-keywords"><kwd>retina</kwd><kwd>contrast sensitivity</kwd><kwd>systems modeling</kwd><kwd>eye movements</kwd></kwd-group><kwd-group kwd-group-type="research-organism"><title>Research organism</title><kwd>Human</kwd><kwd>Rhesus macaque</kwd></kwd-group><funding-group><award-group id="fund1"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/100000053</institution-id><institution>National Eye Institute</institution></institution-wrap></funding-source><award-id>EY018363</award-id><principal-award-recipient><name><surname>Rucci</surname><given-names>Michele</given-names></name></principal-award-recipient></award-group><award-group id="fund2"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/100000001</institution-id><institution>National Science Foundation</institution></institution-wrap></funding-source><award-id>BCS-1457238</award-id><principal-award-recipient><name><surname>Rucci</surname><given-names>Michele</given-names></name></principal-award-recipient></award-group><award-group id="fund3"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/100000053</institution-id><institution>National Eye Institute</institution></institution-wrap></funding-source><award-id>NEI 07977</award-id><principal-award-recipient><name><surname>Victor</surname><given-names>Jonathan D</given-names></name></principal-award-recipient></award-group><award-group id="fund4"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/100000001</institution-id><institution>National Science Foundation</institution></institution-wrap></funding-source><award-id>1420212</award-id><principal-award-recipient><name><surname>Rucci</surname><given-names>Michele</given-names></name></principal-award-recipient></award-group><award-group id="fund5"><funding-source><institution-wrap><institution>Harvard/MIT Joint Research Program</institution></institution-wrap></funding-source><principal-award-recipient><name><surname>Casile</surname><given-names>Antonino</given-names></name></principal-award-recipient></award-group><funding-statement>The funders had no role in study design, data collection and interpretation, or the decision to submit the work for publication.</funding-statement></funding-group><custom-meta-group><custom-meta specific-use="meta-only"><meta-name>Author impact statement</meta-name><meta-value>Fixational eye movements transform the spatial scene into temporal modulations on the retina, which, together with the known sensitivities of retinal neurons, provide a comprehensive account of human spatial sensitivity.</meta-value></custom-meta></custom-meta-group></article-meta></front><body><sec id="s1" sec-type="intro"><title>Introduction</title><p>Contrast sensitivity, the ability to distinguish a patterned input from a uniform background, is one of the most important measures of visual function (<xref ref-type="bibr" rid="bib57">Robson, 1966</xref>; <xref ref-type="bibr" rid="bib14">Campbell and Robson, 1968</xref>; <xref ref-type="bibr" rid="bib20">De Valois et al., 1974</xref>; <xref ref-type="bibr" rid="bib49">Owsley and sensitivity, 2003</xref>). Elucidation of its underlying mechanisms is, thus, essential for understanding how the visual system operates both in health and disease.</p><p>It has long been established that sensitivity varies in a specific manner with the spatial frequency of the stimulus, yielding the so-called contrast sensitivity function (henceforth CSF). Under photopic conditions, the CSF measured with stationary gratings exhibits a well-known band-pass shape that typically peaks around 3–5 cycles/deg and sharply declines at higher and lower spatial frequencies. The mechanisms responsible for this dependence on spatial frequency are not fully understood. At high frequency, a decline in sensitivity is expected for several reasons, including the filtering of the eyes’ optics (<xref ref-type="bibr" rid="bib13">Campbell and Green, 1965</xref>) and the spatial limits in sampling imposed by the cone mosaic on the retina (<xref ref-type="bibr" rid="bib31">Hirsch and Miller, 1987</xref>; <xref ref-type="bibr" rid="bib58">Rossi and Roorda, 2010</xref>). At low frequencies, however, the reasons for a reduced sensitivity have remained less clear.</p><p>A popular theory directly links the low-frequency attenuation in visual sensitivity to the neural mechanisms of early visual encoding (<xref ref-type="bibr" rid="bib2">Atick and Redlich, 1990</xref>; <xref ref-type="bibr" rid="bib3">Atick and Redlich, 1992</xref>). Building on theories of efficient coding (<xref ref-type="bibr" rid="bib5">Barlow, 1961</xref>), it has been argued that this attenuation reflects a form of matching between the characteristics of the natural visual world and the response tuning of neurons in the retina: retinal ganglion cells (henceforth RGCs) respond less strongly at low spatial frequencies so as to counterbalance the spectral distribution of natural scenes. According to this proposal, this filtering eliminates part of the redundancy intrinsic in natural scenes and enables more efficient (i.e. more compact) visual representations.</p><p>Although very influential, this proposal conflicts with experimental data. Neurophysiological recordings have long shown that the way the responses of retinal ganglion cells vary with spatial frequency deviates sharply from the CSF. The CSF of macaques is very similar to that of humans (<xref ref-type="bibr" rid="bib20">De Valois et al., 1974</xref>); yet neurons in the macaque retina respond much more strongly at low spatial frequencies than one would expect from behavioral measurements of the CSF (<xref ref-type="fig" rid="fig1">Figure 1A</xref>). This deviation cannot be reconciled with standard models of retinal ganglion cells. It persists even when one takes into account obvious differences in the stimuli often used in neurophysiological and behavioral measurements (i.e. drifting gratings vs. temporally modulated gratings), as well as the nonlinear attenuation in responsiveness at low spatial frequencies exhibited by some retinal ganglion cells (<xref ref-type="bibr" rid="bib21">Derrington and Lennie, 1984</xref>; <xref ref-type="bibr" rid="bib19">Croner and Kaplan, 1995</xref>; <xref ref-type="bibr" rid="bib6">Benardete and Kaplan, 1997a</xref>). This mismatch between neuronal and behavioral sensitivity indicates that additional mechanisms contribute to the CSF.</p><fig-group><fig id="fig1" position="float"><object-id pub-id-type="doi">10.7554/eLife.40924.002</object-id><label>Figure 1.</label><caption><title>Contrast sensitivity and fixational eye movements.</title><p>(<bold>A</bold>) Behavioral and neurophysiological measurements of contrast sensitivity. The contrast sensitivity functions (CSF) of humans and macaques (black curves; <xref ref-type="bibr" rid="bib20">De Valois et al., 1974</xref>) are compared to the receptive fields profiles of magno- (M) and parvo-cellular (P) retinal ganglion cells (red curves; <xref ref-type="bibr" rid="bib19">Croner and Kaplan, 1995</xref>). (<bold>B</bold>) Fixational eye movements (FEMs; red curve in magnified inset and black and gray traces in Cartesian graph), which include small saccades (microsaccades; red-shaded interval) and fixational drift (green), continually displace the stimulus on the retina.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-40924-fig1-v1.tif"/></fig><fig id="fig1s1" position="float" specific-use="child-fig"><object-id pub-id-type="doi">10.7554/eLife.40924.003</object-id><label>Figure 1—figure supplement 1.</label><caption><title>Parametric analysis of the spatial sensitivity of magno- and parvo-cellular neurons.</title><p>(<bold>A,B</bold>) Spatial sensitivity of magno- (<bold>A</bold>) and parvo-cellular neurons (<bold>B</bold>) as a function of the ratio between the strengths of their center and surround. The responses of both M and P cells were re-normalized to the maximum of the behavioral CSF (curve labeled &quot;Human&quot;, replotted from ) <xref ref-type="fig" rid="fig1">Figure 1A</xref> for comparison purposes. 'DL' and 'CK' label the ratios measured experimentally by <xref ref-type="bibr" rid="bib21">Derrington and Lennie (1984)</xref> and <xref ref-type="bibr" rid="bib19">Croner and Kaplan (1995)</xref> respectively, from the medians of their reported values. All other parameters were set as described in the Materials and methods section. (<bold>C, D</bold>) Full parametric analysis of the difference in slope at low spatial frequencies between the human CSF and the spatial sensitivity of difference-of-Gaussians models. Each point in the map shows the slope deviation resulting from a particular ratio between surround and center amplitudes (<inline-formula><mml:math id="inf1"><mml:mrow><mml:msub><mml:mi>A</mml:mi><mml:mi>s</mml:mi></mml:msub><mml:mo>/</mml:mo><mml:msub><mml:mi>A</mml:mi><mml:mi>c</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula>, horizontal axis) and between radii (<inline-formula><mml:math id="inf2"><mml:mrow><mml:msub><mml:mi>r</mml:mi><mml:mi>s</mml:mi></mml:msub><mml:mo>/</mml:mo><mml:msub><mml:mi>r</mml:mi><mml:mi>c</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula>, vertical axis) in the models (<xref ref-type="disp-formula" rid="equ3">Equation 3</xref>). A value of zero represents perfect matching between the CSF and the receptive fields profile; negative/positive values indicate that the neuronal filter is less/more attenuated than the CSF. Values of the parameters for which the slope could not be computed because the receptive field did not exhibit a band-pass behavior are indicated by white. The magenta and greed dots mark parameters measured experimentally by <xref ref-type="bibr" rid="bib19">Croner and Kaplan (1995)</xref> and <xref ref-type="bibr" rid="bib21">Derrington and Lennie (1984)</xref> respectively (dashed lines). (<bold>D</bold>) Ratio between center/surround excitation and inhibition. A value of 1 indicates that center and surround have the same strength. Legends and symbols are as in C. Comparison of panels C and D shows that a slope similar to that of the human CSF can only be obtained for close balance between excitation and inhibition. These values differ greatly from those measured experimentally (magenta dot).</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-40924-fig1-figsupp1-v1.tif"/></fig></fig-group><p>A fundamental difference between neurophysiological and behavioral measurements of contrast sensitivity is the presence of eye movements in the latter. Under natural viewing conditions, humans and other primates incessantly move their eyes (<xref ref-type="bibr" rid="bib38">Kowler, 2011</xref>; <xref ref-type="bibr" rid="bib17">Cherici et al., 2012</xref>). Small movements, known as fixational eye movements (FEMs), occur, even when attempting to maintain steady gaze on a single point (<xref ref-type="fig" rid="fig1">Figure 1B</xref>). Although humans often tend to suppress saccades of all sizes, including microsaccades, during measurements of contrast sensitivity (<xref ref-type="bibr" rid="bib47">Mostofi et al., 2016</xref>), ocular drift—the seemingly erratic motion in between saccades/microsaccades—keeps the stimulus on the retina always in motion and may cover an area as large as that of the foveola (<xref ref-type="bibr" rid="bib60">Rucci and Poletti, 2015a</xref>). Critically, this retinal image motion is completely eliminated or markedly attenuated in many neurophysiological preparations, where the retina is studied in a dish, or eye muscles are paralyzed as a result of anesthesia and/or neuromuscular blockade.</p><p>In previous work, we have shown that eye drift profoundly reshapes visual input signals, redistributing the 0 Hz (DC) power of the external static stimulus to non-zero temporal frequencies on the retina (<xref ref-type="bibr" rid="bib15">Casile and Rucci, 2006</xref>; <xref ref-type="bibr" rid="bib16">Casile and Rucci, 2009</xref>; <xref ref-type="bibr" rid="bib39">Kuang et al., 2012</xref>; <xref ref-type="bibr" rid="bib4">Aytekin et al., 2014</xref>). These modulations appear to be used by humans for the fine spatial discrimination (<xref ref-type="bibr" rid="bib59">Rucci et al., 2007</xref>; <xref ref-type="bibr" rid="bib9">Boi et al., 2017</xref>; <xref ref-type="bibr" rid="bib54">Ratnam et al., 2017</xref>), providing new support to the long-standing proposal that the visual system uses oculo-motor induced luminance fluctuations for encoding spatial information in a temporal format (see <xref ref-type="bibr" rid="bib61">Rucci and Victor, 2015b</xref> and <xref ref-type="bibr" rid="bib62">Rucci et al., 2018</xref> for reviews). Building upon this previous work, here, we investigate whether this temporal encoding strategy, coupled with the known response characteristics of retinal neurons, accounts for the most fundamental properties of human spatial sensitivity.</p><p>In addition to the properties described above, it is well established that contrast sensitivity is affected by temporal modulations in the stimulus. Although the CSF exhibits a strong attenuation at low spatial frequencies when tested with stationary gratings, the shape of this function changes when gratings are modulated in time, transitioning from band-pass to low-pass as the temporal frequency of the stimulus increases (<xref ref-type="bibr" rid="bib57">Robson, 1966</xref>). Furthermore, although strongly attenuated, sensitivity also tends to shift to higher spatial frequencies when retinal image motion is strongly reduced, as in experiments of retinal stabilization (<xref ref-type="bibr" rid="bib35">Kelly, 1979</xref>). In both these conditions, the temporal modulations impinging onto retinal receptors differ drastically from those generated by normal eye drift over stationary gratings.</p><p>Does a temporal strategy of spatial encoding reconcile neurophysiological and behavioral measurements of contrast sensitivity? And does this strategy explain the differences in the CSF measured in various experimental conditions? More broadly, does the oculomotor-driven dynamics of retinal ganglion cells provide a unified account of human spatial sensitivity? Answers to these questions are not only critical for advancing our comprehension of the mechanisms of visual encoding but also for understanding the consequences of abnormal retinal image motion and their clinical implications. In the following, we use neuronal models to quantitatively examine the impact of eye drift on neural activity and compare the responses of retinal ganglion cells to the CSF of primates.</p></sec><sec id="s2" sec-type="results"><title>Results</title><p><xref ref-type="fig" rid="fig1">Figure 1A</xref> compares the mean receptive fields of ganglion cells in the primate retina, as estimated by <xref ref-type="bibr" rid="bib19">Croner and Kaplan (1995)</xref>, with the contrast sensitivity of alert and behaving macaques (<xref ref-type="bibr" rid="bib20">De Valois et al., 1974</xref>). The two sets of data deviate considerably, especially at low spatial frequencies. In this range, unlike the CSF, neural sensitivity is not strongly attenuated, a trend reported by multiple neurophysiological studies (e.g., <xref ref-type="bibr" rid="bib34">Kaplan and Shapley, 1982</xref>; <xref ref-type="bibr" rid="bib30">Hicks et al., 1983</xref>; <xref ref-type="bibr" rid="bib21">Derrington and Lennie, 1984</xref>). This deviation is not simply the outcome of incorrectly extrapolating receptive-field measurements, as neural responses have been directly measured at very low spatial frequencies (down to 0.07 cpd in <xref ref-type="bibr" rid="bib19">Croner and Kaplan, 1995</xref>; <xref ref-type="fig" rid="fig1">Figure 1A</xref>).</p><p>While a difference-of-Gaussians model can yield reduced responses at low spatial frequencies, attenuation similar to that observed in the CSF can only be achieved at the expense of highly unrealistic model parameters. As shown in <xref ref-type="fig" rid="fig1s1">Figure 1—figure supplement 1A–B</xref>, for both M and P cells, matching the physiological CSF requires a surround strength that is more than twice the value found in physiological measurements, a condition that gives an almost perfect balance between excitation and inhibition. Even small deviations from this balance lead to marked departures from the CSF (<xref ref-type="fig" rid="fig1s1">Figure 1—figure supplement 1C–D</xref>). Thus, contrary to previous proposals, the spatial sensitivity of retinal ganglion cells appears to be quantitatively incompatible with the characteristics of the CSF. A greater attenuation of neural sensitivity is required at low spatial frequencies to counterbalance the large power of natural scenes in this range.</p><p>The response of a neuron, however, does depend not only on the cell’s spatial preference but also on its temporal sensitivity. Temporal transients are always present in the input signals to the retina during behavioral measurements of contrast sensitivity. Experimenters often take great care to minimize these transients, for example by slowly ramping up the stimulus at the beginning and down at the end of a trial and by enforcing fixation to prevent visual changes caused by saccadic eye movements (<xref ref-type="fig" rid="fig2">Figure 2A</xref>). Yet, despite these precautions, fixational eye movements are always present and modulate the visual flow impinging on the retina even when the stimulus does not change on the monitor. Could sensitivity to these oculomotor fluctuations reconcile neurophysiological and behavioral measurements of spatial sensitivity?</p><fig-group><fig id="fig2" position="float"><object-id pub-id-type="doi">10.7554/eLife.40924.004</object-id><label>Figure 2.</label><caption><title>Input transients during measurement of contrast sensitivity.</title><p>(<bold>A</bold>) Temporal modulations in the stimulus. Measurements of contrast sensitivity often change gradually the contrast of the stimulus during the course of the trial. In this case, the stimulus is a static grating. (<bold>B</bold>) Fixational jitter modulates input signals in a way that depends on the spatial frequency of the stimulus. The same amount of fixational drift yields larger temporal fluctuations with gratings at higher spatial frequencies (vertical arrows). (<bold>C</bold>) Input power with gratings at 1 and 8 cycles/deg (left panel). Higher spatial frequencies lead to broader temporal distributions (right panel). (<bold>D</bold>) Total power available at non-zero temporal frequencies with and without fixational drift. In this latter case, temporal modulations are only caused by the temporal contrast envelope of stimulus presentation. Shaded regions represents one standard deviation (see inset). Data represent averages over <inline-formula><mml:math id="inf3"><mml:mrow><mml:mi>N</mml:mi><mml:mo>=</mml:mo><mml:mn>5</mml:mn></mml:mrow></mml:math></inline-formula> observers. (<bold>E</bold>) Temporal sensitivities of modeled retinal ganglion cells. Model parameters are reported in <xref ref-type="table" rid="table1">Tables 1</xref> and <xref ref-type="table" rid="table2">2</xref> in Materials and methods.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-40924-fig2-v1.tif"/></fig><fig id="fig2s1" position="float" specific-use="child-fig"><object-id pub-id-type="doi">10.7554/eLife.40924.005</object-id><label>Figure 2—figure supplement 1.</label><caption><title>Total power available in the retinal input at 0 Hz (static) with and without fixational drift.</title><p>Data represent averages over <inline-formula><mml:math id="inf4"><mml:mrow><mml:mi>N</mml:mi><mml:mo>=</mml:mo><mml:mn>5</mml:mn></mml:mrow></mml:math></inline-formula> observers. Symbols are as in <xref ref-type="fig" rid="fig2">Figure 2D</xref>.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-40924-fig2-figsupp1-v1.tif"/></fig></fig-group><p>To investigate this question, we recorded eye movements in human observers, as they carried out a grating detection task at threshold and exposed spatiotemporal filters approximating the receptive fields of retinal ganglion cells to the luminance signals experienced by the retina in each individual trial. <xref ref-type="fig" rid="fig2">Figure 2B</xref> shows the temporal modulations impinging onto retinal neurons during a typical measurement of contrast sensitivity. In the absence of any transient, the power of a stationary visual stimulus would be confined to the DC (0 Hz) temporal frequency axis. In practice, however, both eye drift and the turning of the stimulus on and off on the display introduce temporal modulations. These modulations effectively redistribute part of the stimulus DC power to nonzero temporal frequencies, that is they transform static power (the original power at 0 Hz) into dynamic power (power at non-zero temporal frequencies).</p><p>As shown in <xref ref-type="fig" rid="fig2">Figure 2C–D</xref>, because of the characteristics of ocular drift, the resulting dynamic power increases with spatial frequency, up to approximately 30 cpd (magenta line in <xref ref-type="fig" rid="fig2">Figure 2D</xref>), which, interestingly, roughly corresponds to the frequency limit given by the spatial resolution of photoreceptors in the fovea. In contrast, unlike drift, contrast modulations due to the onset/offset of the stimulus on the display cause power redistributions that do not depend on the spatial frequency of the stimulus (black line in <xref ref-type="fig" rid="fig2">Figure 2D</xref>). It is important to keep in mind that eye movements do not generate new power in the retinal input. They only redistribute the original DC power of the stimulus, so that a complementary frequency-dependent attenuation of power occurs along the 0 Hz axis (<xref ref-type="fig" rid="fig2s1">Figure 2—figure supplement 1</xref>).</p><p>Both eye drift and contrast changes yield temporal modulations that are well within the range of temporal sensitivity of retinal ganglion cells (cfg. <xref ref-type="fig" rid="fig2">Figure 2C and E</xref>). However, in simulations that replicated the standard conditions of contrast sensitivity measurements, drift modulations predominated. Since drift modulations convey little power at low spatial frequencies, the responses of standard ganglion cells were attenuated in this frequency range (<xref ref-type="fig" rid="fig3">Figure 3B–C</xref>). This happened for both M and P cells, despite the well-known differences in their spatio-temporal sensitivity. As a consequence of this effect, a simple linear combination of the resulting M and P responses accurately predicted human contrast sensitivity with stationary stimuli over the entire range of relevant spatial frequencies (solid line in <xref ref-type="fig" rid="fig3">Figure 3A</xref>).</p><fig id="fig3" position="float"><object-id pub-id-type="doi">10.7554/eLife.40924.008</object-id><label>Figure 3.</label><caption><title>Influence of fixational drift on contrast sensitivity.</title><p>Predicted CSFs in the presence (Drift; solid line) and absence (No Drift; dashed line) of eye movements. Stimuli were stationary gratings. (<bold>A</bold>) A linear combination of the responses of M and P cells closely matches classical measurements (circles; data from <xref ref-type="bibr" rid="bib20">De Valois et al., 1974</xref>) only when eye drift occurs. (<bold>B–C</bold>) CSFs predicted separately from the responses of M (panel B) and P (panel C) cells.</p><p><supplementary-material id="fig3sdata1"><object-id pub-id-type="doi">10.7554/eLife.40924.009</object-id><label>Figure 3—source data 1.</label><caption><title>Source data for <xref ref-type="fig" rid="fig3">Figures 3</xref> and <xref ref-type="fig" rid="fig4">4</xref> loaded by <xref ref-type="supplementary-material" rid="scode1">Source code 1</xref> and <xref ref-type="supplementary-material" rid="scode2">2</xref>.</title></caption><media mime-subtype="octet-stream" mimetype="application" xlink:href="elife-40924-fig3-data1-v1.mat"/></supplementary-material></p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-40924-fig3-v1.tif"/></fig><p>In contrast, in the absence of eye movements, when the only temporal modulations were those given by the onset/offset of the stimulus on the monitor, the CSF predicted by the same linear combination of neural responses exhibited a low-pass behavior that deviated considerably from human contrast sensitivity, especially at low spatial frequencies (dashed lines in <xref ref-type="fig" rid="fig3">Figure 3</xref>). In fact, no linear combination of modeled responses could approximate the CSF in this condition. This happened because, unlike the luminance modulations resulting from ocular drift, the amplitude of the contrast modulations of the stimulus on the display does not depend on the spatial frequency of the stimulus (black line in <xref ref-type="fig" rid="fig2">Figure 2D</xref>). Thus, without taking ocular drift into account, neuronal models exhibit a higher level of response at low spatial frequencies, as dictated by the spatial sensitivity of their kernels — and this strongly deviates from the CSF (<xref ref-type="fig" rid="fig1">Figure 1A</xref>).</p><p>In sum, standard models of the responses of M and P RGCs well predict the shape of the human CSF as measured with stationary gratings, but only when one considers sensitivity to the temporal modulations caused on the retina by fixational drift.</p><p>Contrast sensitivity is a function not only of the spatial frequency of the stimulus but also of its temporal frequency. Measurements with gratings modulated in time have long shown that the CSF in humans is not space-time separable: the way contrast sensitivity varies with spatial frequency depends on the temporal frequency of the modulation (<xref ref-type="bibr" rid="bib57">Robson, 1966</xref>). As the temporal frequency increases, the CSF changes its shape, transitioning from band-pass to low-pass (<xref ref-type="fig" rid="fig4">Figure 4A</xref>).</p><fig-group><fig id="fig4" position="float"><object-id pub-id-type="doi">10.7554/eLife.40924.010</object-id><label>Figure 4.</label><caption><title>Contributions of fixational drift to contrast sensitivity with temporally modulated gratings.</title><p>(<bold>A</bold>) Human CSFs measured with static (0 Hz; data from <xref ref-type="bibr" rid="bib20">De Valois et al., 1974</xref> and sinusoidally modulated (6 Hz; data from <xref ref-type="bibr" rid="bib57">Robson, 1966</xref>) gratings. (<bold>B</bold>) Contrast sensitivity functions predicted by our model in the presence of temporally modulated gratings are compared with measurements from <xref ref-type="bibr" rid="bib57">Robson (1966)</xref>. See <xref ref-type="fig" rid="fig4s3">Figure 4—figure supplement 3</xref> for the separate contributions of M and P cells. (<bold>C</bold>) Power spectra of the response of modeled retinal ganglion cells during viewing of gratings temporally modulated at 6 Hz. Each point in the map represents the amount of power at a given temporal frequency resulting from translating the modeled receptive fields over a grating at the corresponding spatial frequency following the recorded eye drift trajectories.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-40924-fig4-v1.tif"/></fig><fig id="fig4s1" position="float" specific-use="child-fig"><object-id pub-id-type="doi">10.7554/eLife.40924.011</object-id><label>Figure 4—figure supplement 1.</label><caption><title>Predicted CSF during normal viewing of temporally modulated gratings.</title><p>With respect to <xref ref-type="fig" rid="fig4">Figure 4B</xref>, this figure shows a finer sampling of temporal frequencies.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-40924-fig4-figsupp1-v1.tif"/></fig><fig id="fig4s2" position="float" specific-use="child-fig"><object-id pub-id-type="doi">10.7554/eLife.40924.012</object-id><label>Figure 4—figure supplement 2.</label><caption><title>Robustness of the model to the specific implementation of the reduction in sensitivity at low temporal frequencies.</title><p>(<bold>A</bold>) Predicted CSF for two different temporal frequency thresholds. Results in the main text were obtained by discarding temporal power below 0.63 Hz. Results vary little when this threshold is lowered to 0.55 Hz (left panel) or 0.39 Hz (right panel). (<bold>B</bold>) Predicted CSF when the temporal sensitivity of P cells below 2 Hz was modeled as a power law and power was integrated across all temporal frequencies (no low-frequency threshold). Results are robust with respect to the slope of the power law (1 and 0.7 in the left and right panel, respectively) and virtually identical to those obtained with different integration ranges (cfg. panel (<bold>A</bold>)).</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-40924-fig4-figsupp2-v1.tif"/></fig><fig id="fig4s3" position="float" specific-use="child-fig"><object-id pub-id-type="doi">10.7554/eLife.40924.013</object-id><label>Figure 4—figure supplement 3.</label><caption><title>CSF predicted separately from the responses of M and P cells.</title><p>Legends and symbols are as in <xref ref-type="fig" rid="fig4">Figure 4B</xref>.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-40924-fig4-figsupp3-v1.tif"/></fig></fig-group><p>To investigate whether our model also accounts for this change in shape, we repeated our simulations using gratings modulated at various temporal frequencies. The same linear combination of the responses of M and P cells as in <xref ref-type="fig" rid="fig3">Figure 3</xref> continued to closely match human performance when the stimulus was temporally modulated on the display, and the predicted CSF replicated the low-pass to band-pass transition observed in primates, as the frequency of the modulation increased (<xref ref-type="fig" rid="fig4">Figure 4B</xref>).</p><p>This change in shape was the consequence of the different amount of dynamic power that the combination of fixational drift and temporal modulations of the stimulus delivered within the range of neuronal sensitivity. Since we assume that there is no sensitivity to unchanging stimuli, the DC power does not contribute to cells’ responses. However, flickering a grating has the effect of shifting the 0 Hz power of the grating to the temporal frequency of the modulation (<xref ref-type="fig" rid="fig4">Figure 4C</xref>). As a consequence, as the frequency of the modulation increased, this DC power was progressively moved into the sensitivity range of modeled neurons. At low temporal modulating frequencies (e.g. 1 Hz or below), only a small fraction of this power was within the region of neuronal sensitivity, and the temporal redistribution resulting from eye drift continued to exert a strong influence, forcing the CSF to maintain its band-pass shape. However, at higher temporal frequencies (e.g. 6 Hz and higher), the power restricted to the 0 Hz axis in the absence of stimulus’ modulations now became fully available within the cells’ peak sensitivity region. Since this static power is predominantly at low spatial frequencies (<xref ref-type="fig" rid="fig2s1">Figure 2—figure supplement 1</xref>), it caused a transition from band-pass to low-pass behavior in the responses of simulated M and P neurons, as well as in the shape of the CSF. Estimates of the CSF at intermediate frequencies between 0 Hz and 6 Hz (<xref ref-type="fig" rid="fig4s1">Figure 4—figure supplement 1</xref>) suggest that this transition occurs around 3 Hz, which is in agreement with psychophysical results (<xref ref-type="bibr" rid="bib10">Bowker and Tulunay-Keesey, 1983</xref>).</p><p>In sum, our model attributes the space-time inseparability of the CSF to the structure of the temporal modulations delivered within the range of sensitivity of retinal ganglion cells. Modulations resulting from eye drift yield a band-pass CSF, whereas sinusoidally modulated gratings yield a low-pass CSF. The interplay between these two components of the retinal input explains not only contrast sensitivity with stationary gratings, but also the band-pass to low-pass transition that occurs with temporally modulated gratings. Notably, it correctly predicts the temporal frequency range at which this transition takes place. Our results, thus, suggest a functional link between the physiological instability of visual fixation and the characteristics of the CSF.</p><p>A natural question then emerges: how is contrast sensitivity affected by elimination of the luminance modulations caused by ocular drift? Ideally, in the complete absence of eye movements, neural responses in our model would only be driven by the modulations present in the external stimulus. Under such conditions, the model predicts that sensitivity to a stationary grating would be greatly attenuated and the CSF would shift toward a low-pass shape, as it would lack the frequency-dependent amplification operated by ocular drift.</p><p>In real experiments, however, elimination of oculomotor-induced luminance modulations is impossible. Retinal stabilization — a laboratory procedure that attempts to immobilize an image on the retina (<xref ref-type="bibr" rid="bib56">Riggs et al., 1953</xref>; <xref ref-type="bibr" rid="bib74">Yarbus, 1957</xref>) — is always affected by noise in the oculomotor recordings as well as imperfections in gaze-contingent display control, which leave some residual motion on the retina. Under these conditions, contrast sensitivity has indeed been found to be attenuated, but it maintains its band-pass shape and peaks at higher spatial frequencies (<xref ref-type="bibr" rid="bib35">Kelly, 1979</xref>).</p><p>To examine whether sensitivity to temporal transients accounts for the changes in the CSF measured under retinal stabilization, we exposed modeled neurons to reconstructions of the visual input signals experienced in these experiments. Previous studies have established that a Brownian model well captures the characteristics of retinal image motion during fixation (<xref ref-type="bibr" rid="bib39">Kuang et al., 2012</xref>; <xref ref-type="bibr" rid="bib50">Poletti et al., 2015</xref>). Building on this previous finding, we modeled the residual motion of the retinal image in stabilization experiments as a Brownian process, but with greatly reduced diffusion coefficients relative to that present during normal, unstabilized fixation.</p><p><xref ref-type="fig" rid="fig5">Figure 5A</xref> shows how the spatial frequency content of the luminance fluctuations experienced by retinal receptors (the power available at nonzero temporal frequencies) varies with the scale of the Brownian motion process (i.e. its diffusion coefficient, <inline-formula><mml:math id="inf5"><mml:mi>D</mml:mi></mml:math></inline-formula>). Changing the amount of retinal image motion has interesting repercussions on the characteristics of temporal modulations. As expected, a smaller diffusion constant delivers less dynamic power to the retina within the range of neural sensitivity, a direct consequence of the fact that luminance modulations are now smaller. However, a smaller <inline-formula><mml:math id="inf6"><mml:mi>D</mml:mi></mml:math></inline-formula> also has the effect of shifting the range of amplification to higher spatial frequencies by a factor of <inline-formula><mml:math id="inf7"><mml:msqrt><mml:mi>D</mml:mi></mml:msqrt></mml:math></inline-formula>. This happens because reducing the scale of retinal image motion is functionally equivalent to spatially stretching the stimulus, which translates, in the Fourier domain, to a compression of the axis of spatial frequencies that moves the amplification range toward higher spatial frequencies.</p><fig-group><fig id="fig5" position="float"><object-id pub-id-type="doi">10.7554/eLife.40924.014</object-id><label>Figure 5.</label><caption><title>Consequences of retinal stabilization.</title><p>(<bold>A</bold>) Spatial spectral density of the luminance modulations resulting from a Brownian model of retinal image motion with different diffusion constants. Lowering <inline-formula><mml:math id="inf8"><mml:mi>D</mml:mi></mml:math></inline-formula> both attenuates the power available at each spatial frequency (vertical arrow) and shifts the distribution to higher spatial frequencies (horizontal arrow). (<bold>B</bold>) Predicted contrast sensitivity under retinal stabilization. Sensitivity is reduced and shifted to higher spatial frequencies. Dashed vertical lines mark the maxima of the two curves (color coded according to their <inline-formula><mml:math id="inf9"><mml:mi>D</mml:mi></mml:math></inline-formula> in panel A). Results quantitatively match classical experimental data from <xref ref-type="bibr" rid="bib35">Kelly (1979)</xref>. CSFs predicted separately from the responses of M and P neurons are shown in <xref ref-type="fig" rid="fig5s1">Figure 5—figure supplement 1</xref>.</p><p><supplementary-material id="fig5sdata1"><object-id pub-id-type="doi">10.7554/eLife.40924.015</object-id><label>Figure 5—source data 1.</label><caption><title>Source data loaded by <xref ref-type="supplementary-material" rid="scode3">Source code 3</xref></title></caption><media mime-subtype="octet-stream" mimetype="application" xlink:href="elife-40924-fig5-data1-v1.mat"/></supplementary-material></p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-40924-fig5-v1.tif"/></fig><fig id="fig5s1" position="float" specific-use="child-fig"><object-id pub-id-type="doi">10.7554/eLife.40924.016</object-id><label>Figure 5—figure supplement 1.</label><caption><title>CSF predicted separately from the responses of M and P cells.</title><p>Legends and symbols are as <xref ref-type="fig" rid="fig5">Figure 5B</xref>, respectively.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-40924-fig5-figsupp1-v1.tif"/></fig></fig-group><p>These effects in the spectral distributions of the retinal flow well match the changes in contrast sensitivity observed in retinal stabilization experiments. <xref ref-type="fig" rid="fig5">Figure 5B</xref> compares classical retinal stabilization data from <xref ref-type="bibr" rid="bib35">Kelly (1979)</xref> to the sensitivity predicted by our model when the diffusion constant of the retinal image motion was attenuated by a factor of 125, which corresponds to shrinking the spatial scale of eye movements by approximately one order of magnitude. Model predictions closely followed psychophysical measurements: a reduction in the amount of retinal image motion attenuated contrast sensitivity while maintaining its band-pass shape and shifted its peak sensitivity to higher spatial frequencies from 4 Hz to 5.5 Hz (<xref ref-type="fig" rid="fig5">Figure 5B</xref>).</p><p>These data show that consideration of the luminance modulations resulting from the motion of the stimulus on the retina accounts not only for behavioral sensitivity measurements performed in the presence of normal eye movements, but also for measurements made under conditions of retinal stabilization, when retinal image motion is greatly reduced.</p></sec><sec id="s3" sec-type="discussion"><title>Discussion</title><p>Contrast sensitivity is a fundamental descriptor of visual functions. In many species, including humans, sensitivity strongly depends on the spatial and temporal frequency of the stimulus. Here, we show that a temporal scheme of spatial encoding, a scheme in which spatial vision is driven by temporal changes, predicts such dependencies when the temporal modulations introduced by incessant eye movements are taken into account. In contrast, when these consequences of fixational drift are ignored, the known response characteristics of retinal ganglion cells fail to account for human CSF. As described below, these results are highly robust, bear multiple consequences, and lead to important predictions.</p><p>An important consequence of our results regards the strategies by which the visual system encodes spatial information. Existing theories of visual processing have attributed the shape of the CSF to the characteristics of early visual processing. In an influential study (<xref ref-type="bibr" rid="bib3">Atick and Redlich, 1992</xref>) found that the theoretical filter that optimally decorrelates natural images closely matches the CSF. Since decorrelated responses enable compact neural representations, these authors assumed that the CSF reflects the average spatial selectivity of ganglion cells in the retina. However, experimental measurements have long shown that the response selectivity of RGCs differs considerably from the CSF, particularly at low spatial frequencies, where decorrelation would be most beneficial (<xref ref-type="bibr" rid="bib30">Hicks et al., 1983</xref>; <xref ref-type="bibr" rid="bib34">Kaplan and Shapley, 1982</xref>; <xref ref-type="bibr" rid="bib21">Derrington and Lennie, 1984</xref>; <xref ref-type="bibr" rid="bib19">Croner and Kaplan, 1995</xref>). As expected from this deviation, broad spatial correlations in RGCs responses have been found in preparations in which natural images are displayed in the absence of eye movements (<xref ref-type="bibr" rid="bib51">Puchalla et al., 2005</xref>; <xref ref-type="bibr" rid="bib64">Segal et al., 2015</xref>). These findings are consistent with our model: when the transients in stimulus presentation override the consequences of eye drift, spatial sensitivity follows the spatial kernels of modeled receptive fields. For this reason, responses to low spatial frequencies are enhanced relative to the level that would be needed for decorrelating activity.</p><p>The same principle also provides an explanation for the band-pass to low-pass transition of the CSF as the temporal frequency of the stimulus increases. This transition is the consequence of the spectral characteristics of the signals that the combination of fixational drift and stimulus transients delivers within the range of neuronal temporal sensitivity. With stationary gratings, temporal modulations in the retinal input are heavily influenced by ocular drift, which enhances high spatial frequencies imposing a band-pass sensitivity (<xref ref-type="fig" rid="fig3">Figure 3</xref>). With temporally modulated gratings, neuronal responses are also affected by the contrast modulation imposed to the stimulus on the display. Above a frequency of a few Hz, the impact of external modulations outweighs the effects of eye movements, removes the space-time inseparability in cell responses caused by ocular drift, and enhances again sensitivity to low spatial frequencies (<xref ref-type="fig" rid="fig4">Figure 4B</xref>).</p><p>Rather than attributing spatial sensitivity solely to the spatial selectivity of RGCs, our analysis shows that the CSF is shaped by the joint <italic>spatial</italic> and <italic>temporal</italic> characteristics of retinal responses and how they interact with oculomotor transients. It predicts the complex way contrast sensitivity varies with the spatial and temporal frequency of the stimulus by a linear combination of the space-time separable functions of P and M channels. While our study cannot exclude that other mechanisms, at various stages of visual processing, may also play a role in shaping the CSF (e.g. the number of neurons in different frequency channels), it suggests that these other contributions are minimal. Consideration of RGCs temporal sensitivity provides a parsimonious unifying framework for a wide range of experimental measurements of the CSF with only a minimal set of assumptions.</p><p>In our model, we assumed that retinal ganglion cells possess negligible sensitivity below the frequencies at which sensitivity can practically be measured (~0.2–0.3 Hz). This hypothesis may appear to conflict with the neurophysiological data reported in the low temporal frequency range by several studies. However, in both neurophysiological and psychophysical experiments, measuring sensitivity in this range is challenging because it requires trials with long durations, consideration of the visual stimuli present before and after each trial, and estimation of long impulse responses. Typically, the transfer functions reported at low temporal frequencies are extrapolations outside of the range of measured values based on models that were not designed for this purpose (e.g. the linear cascade model (<xref ref-type="bibr" rid="bib72">Victor, 1987</xref>) in <xref ref-type="bibr" rid="bib7">Benardete and Kaplan, 1997b</xref>; <xref ref-type="bibr" rid="bib6">Benardete and Kaplan, 1997a</xref>; a difference of exponential in <xref ref-type="bibr" rid="bib21">Derrington and Lennie, 1984</xref>, etc.). These extrapolations must be interpreted with great caution, as they merely reflect untested model assumptions.</p><p>The few studies that specifically examined retinal ganglion cells’ responses at low temporal frequencies found a decline in sensitivity up to the limit that they could measure (<xref ref-type="bibr" rid="bib72">Victor, 1987</xref>; <xref ref-type="bibr" rid="bib52">Purpura et al., 1990</xref>). These studies suggest that the response attenuation takes the form of an approximately linear decrease in log-log scale. Such behavior is expected from theoretical considerations based on the characteristics of adaptation (<xref ref-type="bibr" rid="bib70">Thorson and Biederman-Thorson, 1974</xref>), considerations that appear to apply to the responses of cones in the retina of the macaque (<xref ref-type="bibr" rid="bib11">Boynton and Whitten, 1970</xref>) and therefore will limit the low-frequency behavior of retinal ganglion cells. Furthermore, temporal signals at frequencies below ~0.3 Hz, even if present, are not likely to be useful to an observer in a psychophysical experiment, as they will contain noise power due to visual stimulation on previous trials and during the intertrial interval (such as eye-blinks and glances around the lab). Our results are robust to the specifics of how this low-frequency attenuation in sensitivity was implemented. The curves presented in <xref ref-type="fig" rid="fig3">Figures 3</xref>, <xref ref-type="fig" rid="fig4">4</xref> and <xref ref-type="fig" rid="fig5">5</xref> were obtained by simply discarding responses below 0.6 Hz. Results were, however, virtually identical when we used different frequency thresholds (<xref ref-type="fig" rid="fig4s2">Figure 4—figure supplement 2A</xref>), or when we modeled sensitivity as a power law function in the low-frequency range, as in <xref ref-type="bibr" rid="bib52">Purpura et al. (1990)</xref> and <xref ref-type="bibr" rid="bib70">Thorson and Biederman-Thorson (1974)</xref> (<xref ref-type="fig" rid="fig4s2">Figure 4—figure supplement 2B</xref>).</p><p>We specifically focused on fixational drift both because of its ubiquitous presence and its known influence on fine pattern vision (<xref ref-type="bibr" rid="bib53">Ratliff and Riggs, 1950</xref>; <xref ref-type="bibr" rid="bib22">Ditchburn, 1955</xref>; <xref ref-type="bibr" rid="bib68">Steinman et al., 1973</xref>; <xref ref-type="bibr" rid="bib59">Rucci et al., 2007</xref>; <xref ref-type="bibr" rid="bib54">Ratnam et al., 2017</xref>). Other types of eye movements, like saccades and microsaccades, tend to be suppressed during measurements of contrast sensitivity (<xref ref-type="bibr" rid="bib47">Mostofi et al., 2016</xref>) and were not considered in this study. The transients from these movements, however, differ in their spectra from those from eye drift, as they provide equal temporal power across a broad range of spatial frequencies. Thus, during normal viewing, the visual system could benefit from different types of modulations. In keeping with this idea, it has been argued that the stereotypical alternation of oculomotor transients resulting from the natural saccade/drift cycle contributes to a coarse-to-fine processing dynamics at each visual fixation (<xref ref-type="bibr" rid="bib9">Boi et al., 2017</xref>).</p><p>It is worth emphasizing that our results are very robust and do not depend on fitting model parameters. With regard to oculomotor activity, we did not model eye movements, but used real traces recorded from human subjects during measurements of contrast sensitivity. With regard to neuronal properties, we implemented standard M and P filters obtained from the neurophysiological literature and frequently adopted by modeling studies (<xref ref-type="bibr" rid="bib19">Croner and Kaplan, 1995</xref>; <xref ref-type="bibr" rid="bib6">Benardete and Kaplan, 1997a</xref>; <xref ref-type="bibr" rid="bib8">Benardete and Kaplan, 1999</xref>). We chose to estimate the CSF by linearly combining M and P responses in fixed ratio, because this was the simplest model. But we note that other ways of combining M and P signals will yield very similar conclusions, since the space-time inseparability originate from the visual input rather than the neuronal models. Our two parameters (the global gain at a given temporal frequency and the ratio of M-P contributions, see <xref ref-type="disp-formula" rid="equ7">Equation 7</xref> in the Materials and methods section) were merely used to quantitatively align the modeled CSF with the experimental data. They have no role in explaining the shape of the CSF and its band- to low-pass transition.</p><p>In addition to providing a comprehensive explanation of the CSF, our study makes important predictions at different levels. At the neural level, our results predict that the response selectivity of RGCs will change when measured in the presence and absence of the fixational motion of the retinal image. Neurophysiological studies already suggest that fixational eye movements are an important component of visual encoding (<xref ref-type="bibr" rid="bib27">Gur et al., 1997</xref>; <xref ref-type="bibr" rid="bib40">Leopold and Logothetis, 1998</xref>; <xref ref-type="bibr" rid="bib44">Martinez-Conde et al., 2000</xref>; <xref ref-type="bibr" rid="bib48">Olveczky et al., 2003</xref>; <xref ref-type="bibr" rid="bib33">Kagan et al., 2008</xref>; <xref ref-type="bibr" rid="bib46">Meirovithz et al., 2012</xref>; <xref ref-type="bibr" rid="bib45">McFarland et al., 2016</xref>). Eye jitter has been found to reduce redundancy in the responses of retinal neurons (<xref ref-type="bibr" rid="bib64">Segal et al., 2015</xref>) and to synchronize them, enhancing visual features (<xref ref-type="bibr" rid="bib26">Greschner et al., 2002</xref>) even beyond the physiological limitations imposed by photoreceptors spacing (<xref ref-type="bibr" rid="bib32">Juusola et al., 2016</xref>). Furthermore, retinal ganglion cells have been found that may distinguish between the global motion given by fixational eye movements and the local motion of objects (<xref ref-type="bibr" rid="bib48">Olveczky et al., 2003</xref>). Yet, retinal responses are traditionally measured with the eyes immobilized, a condition in which RGCs tend to exhibit relatively strong responses at low spatial frequencies (<xref ref-type="bibr" rid="bib19">Croner and Kaplan, 1995</xref>). Our model predicts that the spatial frequency amplification produced by fixational drift in the retinal input (<xref ref-type="fig" rid="fig2">Figure 2D</xref>) will enhance neuronal sensitivity to higher spatial frequencies and will reduce sensitivity to low spatial frequencies. As a consequence, RGCs’ spatial sensitivity should exhibit a more pronounced band-pass behavior and its peak should shift toward higher frequencies. This prediction is difficult to test in vivo, because of the need to completely stabilize the retinal input, but it can be thoroughly investigated in vitro, where the motion of the retinal image is under full experimental control.</p><p>At the perceptual level, an interesting observation comes from the changes in the frequency content of the retinal input shown in <xref ref-type="fig" rid="fig5"><xref ref-type="fig" rid="fig5">Figure 5A</xref></xref>. The amplitude of fixational instability regulates the power available in different spatial frequency bands. Specifically, the smaller the amount of retinal image motion, the more the range of amplification shifts to higher spatial frequencies. The visual system could, in principle, exploit this relationship by dynamically matching the spatial scale of eye drift to the frequency content of the visual scene, or the frequency range that is task-relevant. Within a certain range, smaller drifts would optimize information accrual when foveating on regions rich in high spatial frequencies. This effect could not only be directly driven by the stimulus in a bottom-up fashion, but also be used to meet top-down demands in high-acuity tasks. Indeed, several studies support the idea that humans can control the amount of their ocular drift (<xref ref-type="bibr" rid="bib68">Steinman et al., 1973</xref>; <xref ref-type="bibr" rid="bib17">Cherici et al., 2012</xref>; <xref ref-type="bibr" rid="bib50">Poletti et al., 2015</xref>). In the same vein, the relationship between fixational drift and the frequency content of the retinal input may also explain individual perceptual differences. Subjects with relatively smaller drifts are expected to perform better in tasks in which high spatial frequencies are critical. Studies that quantitatively relate the characteristics of fixational eye drift to visual perception are needed to investigate these predictions.</p><p>Furthermore, our model predicts that manipulating temporal modulations from eye drift will affect performance. We have shown that reducing the amount of the retinal jitter well matches the overall reduction in contrast sensitivity as well as the shift to higher spatial frequencies observed in experiments of retinal stabilization. In the other direction, enlarging fixational jitter increases the amount of power available at low spatial frequencies predicting an improvement in contrast sensitivity in this range. This prediction is consistent with the improvements in word and object recognition reported in patients with central visual loss, when images or text are jittered or scrolled (<xref ref-type="bibr" rid="bib73">Watson et al., 2012</xref>; <xref ref-type="bibr" rid="bib29">Harvey and Walker, 2014</xref>; <xref ref-type="bibr" rid="bib28">Gustafsson and Inde, 2004</xref>). The spatial frequency band of retinal ganglion cells decreases with eccentricity and enlarging retinal image motion has the effect of bringing more power in their range of sensitivity.</p><p>Our study also has clinical implications, as it predicts that disturbances in fixational oculomotor control will affect visual sensitivity. Oculomotor anomalies and impaired sensitivity co-occur in a variety of disorders, including conditions as diverse as dyslexia (<xref ref-type="bibr" rid="bib66">Stein and Fowler, 1981</xref>; <xref ref-type="bibr" rid="bib67">Stein and Fowler, 1993</xref>) and schizophrenia (<xref ref-type="bibr" rid="bib23">Dowiasch et al., 2016</xref>; <xref ref-type="bibr" rid="bib25">Egaña et al., 2013</xref>). Patients with these conditions exhibit similar visual deficits including reduced sensitivity (<xref ref-type="bibr" rid="bib42">Lovegrove et al., 1980a</xref>; <xref ref-type="bibr" rid="bib43">Lovegrove et al., 1980b</xref>; <xref ref-type="bibr" rid="bib65">Slaghuis, 1998</xref>), low-level visual impairments (<xref ref-type="bibr" rid="bib24">Eden et al., 1996</xref>; <xref ref-type="bibr" rid="bib41">Li, 2002</xref>; <xref ref-type="bibr" rid="bib12">Butler et al., 2001</xref>; <xref ref-type="bibr" rid="bib36">Kim et al., 2006</xref>) and reading disabilities (<xref ref-type="bibr" rid="bib55">Revheim et al., 2006</xref>) possibly caused by the disturbances in low-level vision (<xref ref-type="bibr" rid="bib55">Revheim et al., 2006</xref>; <xref ref-type="bibr" rid="bib42">Lovegrove et al., 1980a</xref>). Our results suggest a potential link between fine-scale eye movements and these visual deficits, which has not yet been investigated and which may inspire novel therapeutic approaches.</p></sec><sec id="s4" sec-type="materials|methods"><title>Materials and methods</title><sec id="s4-1"><title>Data collection and analysis</title><p>To examine the influences of eye movements on visual sensitivity, neuronal models were exposed to reconstructions of the input signals typically experienced by observers in experiments of contrast sensitivity. To this end, we used oculomotor traces recorded in measurements of contrast sensitivity to move the stimuli presented as input to the models. Methods for the collection and analysis of eye movements data, as well as perceptual results have already been described in previous publications and are only briefly summarized here (see <xref ref-type="bibr" rid="bib47">Mostofi et al., 2016</xref> and <xref ref-type="bibr" rid="bib9">Boi et al., 2017</xref>). This section focuses on the methods that are novel to this study.</p><sec id="s4-1-1"><title>Subjects</title><p>Eye movements were recorded from five observers (all females, age range 21–31). To optimize the precision of the recordings, only subjects with normal, uncorrected vision took part in the study. Informed consent was obtained from all participants following the procedures approved by the Boston University Charles River Campus Institutional Review Board (protocol number 1062E).</p></sec><sec id="s4-1-2"><title>Apparatus</title><p>Stimuli were displayed on a gamma-corrected fast-phosphor CRT monitor (Iyama HM204DT) in a dimly-illuminated room. They were observed monocularly with the left eye patched, while movements of the right eye were recorded by means of a Dual Purkinje Image eyetracker (Fourward Technology) and sampled at 1 KHz. This system has a resolution – measured by means of an artificial eye – of approximately <inline-formula><mml:math id="inf10"><mml:msup><mml:mn>1</mml:mn><mml:mo>′</mml:mo></mml:msup></mml:math></inline-formula>(<xref ref-type="bibr" rid="bib18">Crane and Steele, 1985</xref>; <xref ref-type="bibr" rid="bib37">Ko et al., 2016</xref>). A dental imprint bite bar and a head-rest prevented head movements. Stimuli were rendered by means of EyeRIS, a custom system that enables precise synchronization between oculomotor events and the refresh of the image on the monitor (<xref ref-type="bibr" rid="bib63">Santini et al., 2007</xref>).</p></sec><sec id="s4-1-3"><title>Stimuli and procedure</title><p>As in typical psychophysical CSF measurements, we used a standard grating-detection paradigm (see <xref ref-type="bibr" rid="bib47">Mostofi et al., 2016</xref> for the behavioral data). In a forced-choice procedure, observers detected 2D Gabor patterns oriented at <inline-formula><mml:math id="inf11"><mml:mrow><mml:mo>±</mml:mo><mml:msup><mml:mn>45</mml:mn><mml:mo>∘</mml:mo></mml:msup></mml:mrow></mml:math></inline-formula>. Their contrast varied across trials following PEST (<xref ref-type="bibr" rid="bib69">Taylor and Creelman, 1967</xref>). The frequency and standard deviation of the Gabor were 10 cycles/deg and <inline-formula><mml:math id="inf12"><mml:msup><mml:mn>2.25</mml:mn><mml:mo>∘</mml:mo></mml:msup></mml:math></inline-formula> respectively. Stimuli were displayed over a uniform field with luminance of 21 <inline-formula><mml:math id="inf13"><mml:mrow><mml:mrow><mml:mi>c</mml:mi><mml:mo>⁢</mml:mo><mml:mi>d</mml:mi></mml:mrow><mml:mo>/</mml:mo><mml:msup><mml:mi>m</mml:mi><mml:mn>2</mml:mn></mml:msup></mml:mrow></mml:math></inline-formula>. Oculomotor traces were segmented in complementary periods of drift and saccades based on a speed threshold of <inline-formula><mml:math id="inf14"><mml:msup><mml:mn>2</mml:mn><mml:mi>o</mml:mi></mml:msup></mml:math></inline-formula>/s (<xref ref-type="bibr" rid="bib47">Mostofi et al., 2016</xref>). Only oculomotor traces collected around threshold levels of sensitivity and that contained no saccades, microsaccades or blinks were used in this study.</p><p>Modeled neurons were exposed to the same retinal input experienced by human participants, identically replicated at all spatial frequencies. Gratings were presented for 3.2 s. They were smoothly ramped up and down in contrast at the beginning and end of the trial by means of the modulating function <inline-formula><mml:math id="inf15"><mml:mrow><mml:mi>M</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> and also modulated in time at frequency <inline-formula><mml:math id="inf16"><mml:msub><mml:mi>ω</mml:mi><mml:mi>t</mml:mi></mml:msub></mml:math></inline-formula> (<inline-formula><mml:math id="inf17"><mml:msub><mml:mi>ω</mml:mi><mml:mi>t</mml:mi></mml:msub></mml:math></inline-formula> = 0, 1, 6, 16, or 22 Hz). The reconstructed retinal input was thus given by:<disp-formula id="equ1"><label>(1)</label><mml:math id="m1"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>I</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi mathvariant="bold-italic">x</mml:mi><mml:mo>,</mml:mo><mml:mi>t</mml:mi><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:msub><mml:mi>f</mml:mi><mml:mrow><mml:mi>s</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>ω</mml:mi><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>α</mml:mi><mml:mrow><mml:mi>s</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>ϕ</mml:mi><mml:mrow><mml:mi>s</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mi>s</mml:mi><mml:mi>i</mml:mi><mml:mi>n</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mn>2</mml:mn><mml:mi>π</mml:mi><mml:msub><mml:mi mathvariant="bold-italic">f</mml:mi><mml:mrow><mml:mi mathvariant="bold-italic">s</mml:mi></mml:mrow></mml:msub><mml:mo>⋅</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mi mathvariant="bold-italic">x</mml:mi><mml:mo>−</mml:mo><mml:mrow><mml:mi mathvariant="bold-italic">ξ</mml:mi><mml:mo mathvariant="bold" stretchy="false">(</mml:mo><mml:mi mathvariant="bold-italic">t</mml:mi><mml:mo mathvariant="bold" stretchy="false">)</mml:mo></mml:mrow><mml:msup><mml:mo stretchy="false">)</mml:mo><mml:mrow><mml:mi>T</mml:mi></mml:mrow></mml:msup><mml:mo>+</mml:mo><mml:msub><mml:mi>ϕ</mml:mi><mml:mrow><mml:mi>s</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:mo>⋅</mml:mo><mml:mi>s</mml:mi><mml:mi>i</mml:mi><mml:mi>n</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mn>2</mml:mn><mml:mi>π</mml:mi><mml:msub><mml:mi>ω</mml:mi><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>⋅</mml:mo><mml:mi>M</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mstyle></mml:math></disp-formula>where <inline-formula><mml:math id="inf18"><mml:mrow><mml:mrow><mml:mi mathvariant="bold-italic">𝝃</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo mathvariant="bold" stretchy="false">(</mml:mo><mml:mi mathvariant="bold-italic">𝒕</mml:mi><mml:mo mathvariant="bold" stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mo>=</mml:mo><mml:mrow><mml:mo stretchy="false">[</mml:mo><mml:mrow><mml:msub><mml:mi>ξ</mml:mi><mml:mi>x</mml:mi></mml:msub><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mo>,</mml:mo><mml:mrow><mml:msub><mml:mi>ξ</mml:mi><mml:mi>y</mml:mi></mml:msub><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mo stretchy="false">]</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> represents eye movements and <inline-formula><mml:math id="inf19"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mrow><mml:msub><mml:mi mathvariant="bold-italic">f</mml:mi><mml:mrow><mml:mi>s</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mo stretchy="false">[</mml:mo><mml:msub><mml:mi>f</mml:mi><mml:mrow><mml:mi>s</mml:mi></mml:mrow></mml:msub><mml:mi>c</mml:mi><mml:mi>o</mml:mi><mml:mi>s</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>α</mml:mi><mml:mrow><mml:mi>s</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:mo>,</mml:mo><mml:msub><mml:mi>f</mml:mi><mml:mrow><mml:mi>s</mml:mi></mml:mrow></mml:msub><mml:mi>s</mml:mi><mml:mi>i</mml:mi><mml:mi>n</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>α</mml:mi><mml:mrow><mml:mi>s</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:mo stretchy="false">]</mml:mo></mml:mrow></mml:mrow></mml:mstyle></mml:math></inline-formula> the stimulus frequency (0.1–60 cycles/deg). The orientation <inline-formula><mml:math id="inf20"><mml:msub><mml:mi>α</mml:mi><mml:mi>s</mml:mi></mml:msub></mml:math></inline-formula> and the phase <inline-formula><mml:math id="inf21"><mml:msub><mml:mi>ϕ</mml:mi><mml:mi>s</mml:mi></mml:msub></mml:math></inline-formula> uniformly spanned the range <inline-formula><mml:math id="inf22"><mml:mrow><mml:mo stretchy="false">[</mml:mo><mml:mrow><mml:mn>0 2</mml:mn><mml:mo>⁢</mml:mo><mml:mi>π</mml:mi></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></inline-formula>.</p></sec><sec id="s4-1-4"><title>Neural models</title><p>The mean instantaneous rate of retinal ganglion cells (RGCs) were simulated by means of standard space-time separable linear filters with transfer function:<disp-formula id="equ2"><label>(2)</label><mml:math id="m2"><mml:mrow><mml:mrow><mml:mi>R</mml:mi><mml:mo>⁢</mml:mo><mml:mi>F</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi mathvariant="bold-italic">𝒇</mml:mi><mml:mo>,</mml:mo><mml:mi>ω</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mo>=</mml:mo><mml:mrow><mml:mrow><mml:mrow><mml:mi>K</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi mathvariant="bold-italic">𝒇</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mo>⋅</mml:mo><mml:mi>H</mml:mi></mml:mrow><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>ω</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:math></disp-formula>where <inline-formula><mml:math id="inf23"><mml:mi mathvariant="bold-italic">𝒇</mml:mi></mml:math></inline-formula> and <inline-formula><mml:math id="inf24"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>ω</mml:mi></mml:mrow></mml:mstyle></mml:math></inline-formula> indicate spatial and temporal frequencies respectively. The spatial kernel <inline-formula><mml:math id="inf25"><mml:mrow><mml:mi>K</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi mathvariant="bold-italic">𝒇</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> was modeled as in <xref ref-type="bibr" rid="bib19">Croner and Kaplan (1995)</xref> with a standard difference of Gaussians:<disp-formula id="equ3"><label>(3)</label><mml:math id="m3"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>K</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi mathvariant="bold-italic">f</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mi>C</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>K</mml:mi><mml:mrow><mml:mi>c</mml:mi></mml:mrow></mml:msub><mml:mi>π</mml:mi><mml:msubsup><mml:mi>r</mml:mi><mml:mrow><mml:mi>c</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup><mml:msup><mml:mi>e</mml:mi><mml:mrow><mml:mo>−</mml:mo><mml:mi>π</mml:mi><mml:msub><mml:mi>r</mml:mi><mml:mrow><mml:mi>c</mml:mi></mml:mrow></mml:msub><mml:mo fence="false" stretchy="false">|</mml:mo><mml:mi>γ</mml:mi><mml:mi mathvariant="bold-italic">f</mml:mi><mml:msup><mml:mo fence="false" stretchy="false">|</mml:mo><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:msup><mml:mo>−</mml:mo><mml:msub><mml:mi>K</mml:mi><mml:mrow><mml:mi>s</mml:mi></mml:mrow></mml:msub><mml:mi>π</mml:mi><mml:msubsup><mml:mi>r</mml:mi><mml:mrow><mml:mi>s</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup><mml:msup><mml:mi>e</mml:mi><mml:mrow><mml:mo>−</mml:mo><mml:mi>π</mml:mi><mml:msub><mml:mi>r</mml:mi><mml:mrow><mml:mi>s</mml:mi></mml:mrow></mml:msub><mml:mo fence="false" stretchy="false">|</mml:mo><mml:mi>γ</mml:mi><mml:mi mathvariant="bold-italic">f</mml:mi><mml:msup><mml:mo fence="false" stretchy="false">|</mml:mo><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:msup><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mstyle></mml:math></disp-formula>with parameters adjusted based on neurophysiological recordings from macaques (<xref ref-type="table" rid="table1">Table 1</xref> in <xref ref-type="bibr" rid="bib19">Croner and Kaplan, 1995</xref>). The scaling factor <inline-formula><mml:math id="inf26"><mml:mi>γ</mml:mi></mml:math></inline-formula> was set to <inline-formula><mml:math id="inf27"><mml:mn>0.5</mml:mn></mml:math></inline-formula> to model the smaller receptive fields of the fovea following cortical magnification (Eq.8 in <xref ref-type="bibr" rid="bib71">Van Essen et al., 1984</xref>).</p><table-wrap id="table1" position="float"><object-id pub-id-type="doi">10.7554/eLife.40924.006</object-id><label>Table 1.</label><caption><title>Parameters used in <xref ref-type="disp-formula" rid="equ3">Equation 3</xref> to model the spatial kernels of magno- (upper row) and parvo-cellular (bottom row) neurons.</title><p>Data are from <xref ref-type="bibr" rid="bib19">Croner and Kaplan (1995)</xref>.</p></caption><table frame="hsides" rules="groups"><thead><tr><th/><th><inline-formula><mml:math id="inf28"><mml:msub><mml:mi>r</mml:mi><mml:mi>c</mml:mi></mml:msub></mml:math></inline-formula></th><th><inline-formula><mml:math id="inf29"><mml:msub><mml:mi>K</mml:mi><mml:mi>c</mml:mi></mml:msub></mml:math></inline-formula></th><th><inline-formula><mml:math id="inf30"><mml:msub><mml:mi>r</mml:mi><mml:mi>s</mml:mi></mml:msub></mml:math></inline-formula></th><th><inline-formula><mml:math id="inf31"><mml:msub><mml:mi>K</mml:mi><mml:mi>s</mml:mi></mml:msub></mml:math></inline-formula></th></tr></thead><tbody><tr><th>M cells</th><td>0.10</td><td>148</td><td>0.72</td><td>1.1</td></tr><tr><th>P cells</th><td>0.03</td><td>353.2</td><td>0.18</td><td>4.4</td></tr></tbody></table></table-wrap><p>The temporal sensitivity function <inline-formula><mml:math id="inf32"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>H</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>ω</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mstyle></mml:math></inline-formula> consisted of a series of low-pass filters and a high-pass stage as propose by <xref ref-type="bibr" rid="bib72">Victor (1987)</xref>:<disp-formula id="equ4"><label>(4)</label><mml:math id="m4"><mml:mrow><mml:mrow><mml:mi>H</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>ω</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mo>=</mml:mo><mml:mrow><mml:mi>A</mml:mi><mml:mo>⁢</mml:mo><mml:msup><mml:mi>e</mml:mi><mml:mrow><mml:mo>-</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>⁢</mml:mo><mml:mi>ρ</mml:mi><mml:mo>⁢</mml:mo><mml:mn>2</mml:mn><mml:mo>⁢</mml:mo><mml:mi>π</mml:mi><mml:mo>⁢</mml:mo><mml:mi>ω</mml:mi><mml:mo>⁢</mml:mo><mml:mi>D</mml:mi></mml:mrow></mml:mrow></mml:msup><mml:mo>⁢</mml:mo><mml:mrow><mml:mo maxsize="210%" minsize="210%">(</mml:mo><mml:mrow><mml:mn>1</mml:mn><mml:mo>-</mml:mo><mml:mfrac><mml:msub><mml:mi>H</mml:mi><mml:mi>s</mml:mi></mml:msub><mml:mrow><mml:mn>1</mml:mn><mml:mo>+</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>⁢</mml:mo><mml:mi>ρ</mml:mi><mml:mo>⁢</mml:mo><mml:mn>2</mml:mn><mml:mo>⁢</mml:mo><mml:mi>π</mml:mi><mml:mo>⁢</mml:mo><mml:mi>ω</mml:mi><mml:mo>⁢</mml:mo><mml:msub><mml:mi>τ</mml:mi><mml:mi>S</mml:mi></mml:msub></mml:mrow></mml:mrow></mml:mfrac></mml:mrow><mml:mo maxsize="210%" minsize="210%">)</mml:mo></mml:mrow><mml:mo>⁢</mml:mo><mml:msup><mml:mrow><mml:mo maxsize="210%" minsize="210%">(</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mrow><mml:mn>1</mml:mn><mml:mo>+</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>⁢</mml:mo><mml:mi>ρ</mml:mi><mml:mo>⁢</mml:mo><mml:mn>2</mml:mn><mml:mo>⁢</mml:mo><mml:mi>π</mml:mi><mml:mo>⁢</mml:mo><mml:mi>ω</mml:mi><mml:mo>⁢</mml:mo><mml:msub><mml:mi>τ</mml:mi><mml:mi>L</mml:mi></mml:msub></mml:mrow></mml:mrow></mml:mfrac><mml:mo maxsize="210%" minsize="210%">)</mml:mo></mml:mrow><mml:mi>N</mml:mi></mml:msup></mml:mrow></mml:mrow></mml:math></disp-formula></p><p>Parameters were taken from neurophysiological studies that fitted this model to recorded neurons (M cells: median values in <xref ref-type="table" rid="table2">Table 2</xref> in <xref ref-type="bibr" rid="bib8">Benardete and Kaplan, 1999</xref>; P cells: median values in <xref ref-type="table" rid="table2">Table 2</xref> in <xref ref-type="bibr" rid="bib6">Benardete and Kaplan, 1997a</xref>). The scaling factor <inline-formula><mml:math id="inf33"><mml:mi>ρ</mml:mi></mml:math></inline-formula> was set to 1/1.6 to include the effects of large stimuli on retinal responses (Figure 7B in <xref ref-type="bibr" rid="bib1">Alitto and Usrey, 2015</xref>).</p><table-wrap id="table2" position="float"><object-id pub-id-type="doi">10.7554/eLife.40924.007</object-id><label>Table 2.</label><caption><title>Parameters used in <xref ref-type="disp-formula" rid="equ4">Equation 4</xref> to model the temporal kernels of magno- (upper row) and parvo-cellular (bottom row) neurons.</title><p>Data are from <xref ref-type="bibr" rid="bib6">Benardete and Kaplan (1997a)</xref>; <xref ref-type="bibr" rid="bib8">Benardete and Kaplan (1999)</xref>.</p></caption><table frame="hsides" rules="groups"><thead><tr><th/><th><inline-formula><mml:math id="inf34"><mml:mi>N</mml:mi></mml:math></inline-formula></th><th><inline-formula><mml:math id="inf35"><mml:mi>A</mml:mi></mml:math></inline-formula></th><th><inline-formula><mml:math id="inf36"><mml:mi>D</mml:mi></mml:math></inline-formula></th><th><inline-formula><mml:math id="inf37"><mml:msub><mml:mi>H</mml:mi><mml:mi>s</mml:mi></mml:msub></mml:math></inline-formula></th><th><inline-formula><mml:math id="inf38"><mml:msub><mml:mi>τ</mml:mi><mml:mi>L</mml:mi></mml:msub></mml:math></inline-formula></th><th><inline-formula><mml:math id="inf39"><mml:msub><mml:mi>τ</mml:mi><mml:mi>S</mml:mi></mml:msub></mml:math></inline-formula></th></tr></thead><tbody><tr><th>M cells</th><th>30</th><td>499.77</td><td>2</td><td>1</td><td>1.1</td><td>2.23</td></tr><tr><th>P cells</th><th>38</th><td>67.59</td><td>3.5</td><td>0.69</td><td>1.27</td><td>29.36</td></tr></tbody></table></table-wrap></sec><sec id="s4-1-5"><title>Estimating contrast sensitivity</title><p>The main hypothesis of our study is that the visual system is insensitive to temporal stimulation at 0 Hz so that spatial sensitivity is entirely driven by temporal transients. For this reason, we estimated the predicted CSF on the basis of cell responses to input changes.</p><p>For each spatial frequency <inline-formula><mml:math id="inf40"><mml:msub><mml:mi>f</mml:mi><mml:mi>s</mml:mi></mml:msub></mml:math></inline-formula> of the grating, we first estimated the space-time power spectrum of the retinal input <inline-formula><mml:math id="inf41"><mml:mrow><mml:msub><mml:mi>P</mml:mi><mml:mi>I</mml:mi></mml:msub><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi mathvariant="bold-italic">𝒇</mml:mi><mml:mo>,</mml:mo><mml:mi>ω</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> by averaging the square of the absolute value of the Fourier transform of <xref ref-type="disp-formula" rid="equ1">Equation 1</xref> across trials, stimulus’ orientations <inline-formula><mml:math id="inf42"><mml:msub><mml:mi>α</mml:mi><mml:mi>s</mml:mi></mml:msub></mml:math></inline-formula> and phases <inline-formula><mml:math id="inf43"><mml:msub><mml:mi>ϕ</mml:mi><mml:mi>s</mml:mi></mml:msub></mml:math></inline-formula>. Since both <inline-formula><mml:math id="inf44"><mml:mrow><mml:msub><mml:mi>P</mml:mi><mml:mi>I</mml:mi></mml:msub><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi mathvariant="bold-italic">𝒇</mml:mi><mml:mo>,</mml:mo><mml:mi>ω</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> and the spatial kernels <inline-formula><mml:math id="inf45"><mml:mrow><mml:mi>K</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi mathvariant="bold-italic">𝒇</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> possess circular symmetry in spatial frequency, we reduced the spatial dimensionality from 2D to 1D by radial averaging. We then computed the power spectrum of neuronal responses <inline-formula><mml:math id="inf46"><mml:mrow><mml:mi>O</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>f</mml:mi><mml:mo>,</mml:mo><mml:mi>ω</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> by multiplying the space-time power spectrum of the retinal input <inline-formula><mml:math id="inf47"><mml:mrow><mml:msub><mml:mi>P</mml:mi><mml:mi>I</mml:mi></mml:msub><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>f</mml:mi><mml:mo>,</mml:mo><mml:mi>ω</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> by the transfer functions of the cells’ filters:<disp-formula id="equ5"><label>(5)</label><mml:math id="m5"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>O</mml:mi><mml:mrow><mml:mi>ζ</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>f</mml:mi><mml:mo>,</mml:mo><mml:mi>ω</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:msub><mml:mi>P</mml:mi><mml:mrow><mml:mi>I</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>f</mml:mi><mml:mo>,</mml:mo><mml:mi>ω</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>⋅</mml:mo><mml:mo fence="false" stretchy="false">|</mml:mo><mml:mi>R</mml:mi><mml:msub><mml:mi>F</mml:mi><mml:mrow><mml:mi>ζ</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>f</mml:mi><mml:mo>,</mml:mo><mml:mi>ω</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:msup><mml:mo fence="false" stretchy="false">|</mml:mo><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:mstyle></mml:math></disp-formula>where <inline-formula><mml:math id="inf48"><mml:mrow><mml:mi>R</mml:mi><mml:mo>⁢</mml:mo><mml:msub><mml:mi>F</mml:mi><mml:mi>ζ</mml:mi></mml:msub><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>f</mml:mi><mml:mo>,</mml:mo><mml:mi>ω</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula>, with <inline-formula><mml:math id="inf49"><mml:mrow><mml:mi>ζ</mml:mi><mml:mo>=</mml:mo><mml:mi>M</mml:mi></mml:mrow></mml:math></inline-formula> or <inline-formula><mml:math id="inf50"><mml:mi>P</mml:mi></mml:math></inline-formula>, represents the Fourier transform of M or P cells’ receptive fields (<xref ref-type="disp-formula" rid="equ2">Equation2</xref>).</p><p>Finally, we evaluated the CSF at each spatial frequency <inline-formula><mml:math id="inf51"><mml:mi>f</mml:mi></mml:math></inline-formula>, by computing the square root of the integrated temporal power across all non-zero temporal frequencies:<disp-formula id="equ6"><label>(6)</label><mml:math id="m6"><mml:mrow><mml:mrow><mml:mi>C</mml:mi><mml:mo>⁢</mml:mo><mml:mi>S</mml:mi><mml:mo>⁢</mml:mo><mml:msub><mml:mi>F</mml:mi><mml:mi>ζ</mml:mi></mml:msub><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>f</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mo>=</mml:mo><mml:msqrt><mml:mrow><mml:msubsup><mml:mo largeop="true" symmetric="true">∫</mml:mo><mml:msup><mml:mi>o</mml:mi><mml:mo>+</mml:mo></mml:msup><mml:mi mathvariant="normal">∞</mml:mi></mml:msubsup><mml:mrow><mml:msub><mml:mi>O</mml:mi><mml:mi>ζ</mml:mi></mml:msub><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>f</mml:mi><mml:mo>,</mml:mo><mml:mi>ω</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>⁢</mml:mo><mml:mi>d</mml:mi><mml:mo>⁢</mml:mo><mml:mi>ω</mml:mi></mml:mrow></mml:mrow></mml:msqrt></mml:mrow></mml:math></disp-formula>where <inline-formula><mml:math id="inf52"><mml:msub><mml:mi>O</mml:mi><mml:mi>ζ</mml:mi></mml:msub></mml:math></inline-formula> represents the power spectrum of M or P responses. The integral in <xref ref-type="disp-formula" rid="equ6">Equation 6</xref> was computed numerically. To avoid artifacts from finite bandwidth, the first two temporal samples of the spectrum were discarded so that integral over temporal frequency started from <inline-formula><mml:math id="inf53"><mml:mrow><mml:mi>ω</mml:mi><mml:mo>=</mml:mo><mml:mrow><mml:mpadded width="+5pt"><mml:mn>0.63</mml:mn></mml:mpadded><mml:mo>⁢</mml:mo><mml:mi>H</mml:mi><mml:mo>⁢</mml:mo><mml:mi>z</mml:mi></mml:mrow></mml:mrow></mml:math></inline-formula>. However, virtually identical results were obtained when we used lower thresholds or when we modeled the low-frequency range of temporal sensitivity as a power law (<xref ref-type="fig" rid="fig4s2">Figure 4—figure supplement 2</xref>).</p><p>The predicted CSF was then estimated, for each condition, by a linear combination of the contrast sensitivities of the two types of neurons, <inline-formula><mml:math id="inf54"><mml:mrow><mml:mi>C</mml:mi><mml:mo>⁢</mml:mo><mml:mi>S</mml:mi><mml:mo>⁢</mml:mo><mml:msub><mml:mi>F</mml:mi><mml:mi>M</mml:mi></mml:msub><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>f</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> and <inline-formula><mml:math id="inf55"><mml:mrow><mml:mi>C</mml:mi><mml:mo>⁢</mml:mo><mml:mi>S</mml:mi><mml:mo>⁢</mml:mo><mml:msub><mml:mi>F</mml:mi><mml:mi>P</mml:mi></mml:msub><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>f</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> :<disp-formula id="equ7"><label>(7)</label><mml:math id="m7"><mml:mrow><mml:mrow><mml:mi>C</mml:mi><mml:mo>⁢</mml:mo><mml:mi>S</mml:mi><mml:mo>⁢</mml:mo><mml:msub><mml:mi>F</mml:mi><mml:mrow><mml:mi>e</mml:mi><mml:mo>⁢</mml:mo><mml:mi>s</mml:mi><mml:mo>⁢</mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>f</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mo>=</mml:mo><mml:mrow><mml:mi>A</mml:mi><mml:mo>⋅</mml:mo><mml:mrow><mml:mo stretchy="false">[</mml:mo><mml:mrow><mml:mrow><mml:mi>λ</mml:mi><mml:mo>⁢</mml:mo><mml:mi>C</mml:mi><mml:mo>⁢</mml:mo><mml:mi>S</mml:mi><mml:mo>⁢</mml:mo><mml:msub><mml:mi>F</mml:mi><mml:mi>M</mml:mi></mml:msub><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>f</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mo>+</mml:mo><mml:mrow><mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mn>1</mml:mn><mml:mo>-</mml:mo><mml:mi>λ</mml:mi></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>⋅</mml:mo><mml:mi>C</mml:mi></mml:mrow><mml:mo>⁢</mml:mo><mml:mi>S</mml:mi><mml:mo>⁢</mml:mo><mml:msub><mml:mi>F</mml:mi><mml:mi>P</mml:mi></mml:msub><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>f</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:mrow><mml:mo stretchy="false">]</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:math></disp-formula>where <inline-formula><mml:math id="inf56"><mml:mi>λ</mml:mi></mml:math></inline-formula> (<inline-formula><mml:math id="inf57"><mml:mrow><mml:mi>λ</mml:mi><mml:mo>=</mml:mo><mml:mn>0.57</mml:mn></mml:mrow></mml:math></inline-formula> for all conditions) weighs the contributions of the M and P populations and <inline-formula><mml:math id="inf58"><mml:mi>A</mml:mi></mml:math></inline-formula> is a global rescaling coefficient.</p><p>Note that the parameters <inline-formula><mml:math id="inf59"><mml:mi>A</mml:mi></mml:math></inline-formula> and <inline-formula><mml:math id="inf60"><mml:mi>λ</mml:mi></mml:math></inline-formula> were merely used to quantitatively align model predictions with classical data, but had no role in explaining our findings. That is, the emergence of a space-time inseparability in the CSF, was neither caused by the specific value of <inline-formula><mml:math id="inf61"><mml:mi>λ</mml:mi></mml:math></inline-formula> (both M and P cells show this transition; <xref ref-type="fig" rid="fig4s3">Figure 4—figure supplement 3</xref>) nor by the global scaling factor <inline-formula><mml:math id="inf62"><mml:mi>A</mml:mi></mml:math></inline-formula>, which had no effect on the shape of the predicted CSF. We chose to linearly combine the contributions of M and P neurons because this was the simplest model. However, use of other models (e.g. the maximum of either population at each spatial frequency <inline-formula><mml:math id="inf63"><mml:mi>f</mml:mi></mml:math></inline-formula>) produced virtually the same results given the robustness of the underlying phenomenon.</p><p>The same procedure was used to estimate the CSF in the case of no eye movements and retinal stabilization (<xref ref-type="fig" rid="fig3">Figures 3</xref>, <xref ref-type="fig" rid="fig4">4</xref> and <xref ref-type="fig" rid="fig5">5</xref>). In the former condition (no eye movements), <inline-formula><mml:math id="inf64"><mml:mrow><mml:mi mathvariant="bold-italic">𝝃</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo mathvariant="bold" stretchy="false">(</mml:mo><mml:mi mathvariant="bold-italic">𝒕</mml:mi><mml:mo mathvariant="bold" stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> was set to zero in <xref ref-type="disp-formula" rid="equ1">Equation 1</xref>. In the latter condition (retinal stabilization), we modeled the retinal image motion by means of a 2D random walk process, but with reduced diffusion coefficient (<inline-formula><mml:math id="inf65"><mml:mi>D</mml:mi></mml:math></inline-formula> = 2 rather than the normal value <inline-formula><mml:math id="inf66"><mml:mi>D</mml:mi></mml:math></inline-formula> = 250). Brownian motion, with <inline-formula><mml:math id="inf67"><mml:mi>D</mml:mi></mml:math></inline-formula> in the range 100–350, is known to be a good model for the normal retinal image motion when the head is not immobilized (<xref ref-type="bibr" rid="bib4">Aytekin et al., 2014</xref>).</p></sec></sec></sec></body><back><sec id="s6" sec-type="additional-information"><title>Additional information</title><fn-group content-type="competing-interest"><title>Competing interests</title><fn fn-type="COI-statement" id="conf1"><p>No competing interests declared</p></fn></fn-group><fn-group content-type="author-contribution"><title>Author contributions</title><fn fn-type="con" id="con1"><p>Conceptualization, Data curation, Software, Supervision, Investigation, Methodology, Writing—original draft, Writing—review and editing</p></fn><fn fn-type="con" id="con2"><p>Conceptualization, Methodology, Writing—review and editing</p></fn><fn fn-type="con" id="con3"><p>Conceptualization, Supervision, Methodology, Writing—review and editing</p></fn></fn-group><fn-group content-type="ethics-information"><title>Ethics</title><fn fn-type="other"><p>Human subjects: Informed consent was obtained from all participants following the procedures approved by the Boston University Charles River Campus Institutional Review Board (protocol number 1062E).</p></fn></fn-group></sec><sec id="s5" sec-type="supplementary-material"><title>Additional files</title><supplementary-material id="scode1"><object-id pub-id-type="doi">10.7554/eLife.40924.017</object-id><label>Source code 1.</label><caption><title>Source Matlab code to generate <xref ref-type="fig" rid="fig3">Figures 3A–C</xref> in the manuscript.</title></caption><media mime-subtype="x-m" mimetype="text" xlink:href="elife-40924-code1-v1.m"/></supplementary-material><supplementary-material id="scode2"><object-id pub-id-type="doi">10.7554/eLife.40924.018</object-id><label>Source code 2.</label><caption><title>Source Matlab code to generate <xref ref-type="fig" rid="fig4">Figures 4B</xref> in the manuscript.</title></caption><media mime-subtype="x-m" mimetype="text" xlink:href="elife-40924-code2-v1.m"/></supplementary-material><supplementary-material id="scode3"><object-id pub-id-type="doi">10.7554/eLife.40924.019</object-id><label>Source code 3.</label><caption><title>Source Matlab code to generate <xref ref-type="fig" rid="fig5">Figures 5B</xref> in the manuscript.</title></caption><media mime-subtype="x-m" mimetype="text" xlink:href="elife-40924-code3-v1.m"/></supplementary-material><supplementary-material id="transrepform"><object-id pub-id-type="doi">10.7554/eLife.40924.020</object-id><label>Transparent reporting form</label><media mime-subtype="docx" mimetype="application" xlink:href="elife-40924-transrepform-v1.docx"/></supplementary-material><sec id="s7" sec-type="data-availability"><title>Data availability</title><p>All data generated or analysed during this study are included in the manuscript and supporting files.</p></sec></sec><ref-list><title>References</title><ref id="bib1"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Alitto</surname> <given-names>HJ</given-names></name><name><surname>Usrey</surname> <given-names>WM</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>Surround suppression and temporal processing of visual signals</article-title><source>Journal of Neurophysiology</source><volume>113</volume><fpage>2605</fpage><lpage>2617</lpage><pub-id pub-id-type="doi">10.1152/jn.00480.2014</pub-id><pub-id pub-id-type="pmid">25652919</pub-id></element-citation></ref><ref id="bib2"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Atick</surname> <given-names>JJ</given-names></name><name><surname>Redlich</surname> <given-names>AN</given-names></name></person-group><year iso-8601-date="1990">1990</year><article-title>Towards a theory of early visual processing</article-title><source>Neural Computation</source><volume>2</volume><fpage>308</fpage><lpage>320</lpage><pub-id pub-id-type="doi">10.1162/neco.1990.2.3.308</pub-id></element-citation></ref><ref id="bib3"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Atick</surname> <given-names>JJ</given-names></name><name><surname>Redlich</surname> <given-names>AN</given-names></name></person-group><year iso-8601-date="1992">1992</year><article-title>What does the retina know about natural scenes?</article-title><source>Neural Computation</source><volume>4</volume><fpage>196</fpage><lpage>210</lpage><pub-id pub-id-type="doi">10.1162/neco.1992.4.2.196</pub-id></element-citation></ref><ref id="bib4"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Aytekin</surname> <given-names>M</given-names></name><name><surname>Victor</surname> <given-names>JD</given-names></name><name><surname>Rucci</surname> <given-names>M</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>The visual input to the retina during natural head-free fixation</article-title><source>Journal of Neuroscience</source><volume>34</volume><fpage>12701</fpage><lpage>12715</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.0229-14.2014</pub-id><pub-id pub-id-type="pmid">25232108</pub-id></element-citation></ref><ref id="bib5"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Barlow</surname> <given-names>HB</given-names></name></person-group><year iso-8601-date="1961">1961</year><chapter-title>Possible principles underlying the transformations of sensory messages</chapter-title><person-group person-group-type="editor"><name><surname>Rosenblith</surname> <given-names>W</given-names></name></person-group><source>Sensory Communication</source><publisher-loc>Cambride, USA</publisher-loc><publisher-name>MIT Press</publisher-name><fpage>217</fpage><lpage>234</lpage></element-citation></ref><ref id="bib6"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Benardete</surname> <given-names>EA</given-names></name><name><surname>Kaplan</surname> <given-names>E</given-names></name></person-group><year iso-8601-date="1997">1997a</year><article-title>The receptive field of the primate P retinal ganglion cell, I: Linear dynamics</article-title><source>Visual Neuroscience</source><volume>14</volume><fpage>169</fpage><lpage>185</lpage><pub-id pub-id-type="doi">10.1017/S0952523800008853</pub-id><pub-id pub-id-type="pmid">9057278</pub-id></element-citation></ref><ref id="bib7"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Benardete</surname> <given-names>EA</given-names></name><name><surname>Kaplan</surname> <given-names>E</given-names></name></person-group><year iso-8601-date="1997">1997b</year><article-title>The receptive field of the primate P retinal ganglion cell, II: Nonlinear dynamics</article-title><source>Visual Neuroscience</source><volume>14</volume><fpage>187</fpage><lpage>205</lpage><pub-id pub-id-type="doi">10.1017/S0952523800008865</pub-id><pub-id pub-id-type="pmid">9057279</pub-id></element-citation></ref><ref id="bib8"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Benardete</surname> <given-names>EA</given-names></name><name><surname>Kaplan</surname> <given-names>E</given-names></name></person-group><year iso-8601-date="1999">1999</year><article-title>The dynamics of primate M retinal ganglion cells</article-title><source>Visual Neuroscience</source><volume>16</volume><fpage>355</fpage><lpage>368</lpage><pub-id pub-id-type="doi">10.1017/S0952523899162151</pub-id><pub-id pub-id-type="pmid">10367969</pub-id></element-citation></ref><ref id="bib9"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Boi</surname> <given-names>M</given-names></name><name><surname>Poletti</surname> <given-names>M</given-names></name><name><surname>Victor</surname> <given-names>JD</given-names></name><name><surname>Rucci</surname> <given-names>M</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>Consequences of the oculomotor cycle for the dynamics of perception</article-title><source>Current Biology</source><volume>27</volume><fpage>1268</fpage><lpage>1277</lpage><pub-id pub-id-type="doi">10.1016/j.cub.2017.03.034</pub-id></element-citation></ref><ref id="bib10"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bowker</surname> <given-names>DO</given-names></name><name><surname>Tulunay-Keesey</surname> <given-names>U</given-names></name></person-group><year iso-8601-date="1983">1983</year><article-title>Sensitivity to countermodulating gratings following spatiotemporal adaptation</article-title><source>Journal of the Optical Society of America</source><volume>73</volume><fpage>427</fpage><lpage>435</lpage><pub-id pub-id-type="doi">10.1364/JOSA.73.000427</pub-id><pub-id pub-id-type="pmid">6864355</pub-id></element-citation></ref><ref id="bib11"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Boynton</surname> <given-names>RM</given-names></name><name><surname>Whitten</surname> <given-names>DN</given-names></name></person-group><year iso-8601-date="1970">1970</year><article-title>Visual adaptation in monkey cones: recordings of late receptor potentials</article-title><source>Science</source><volume>170</volume><fpage>1423</fpage><lpage>1426</lpage><pub-id pub-id-type="doi">10.1126/science.170.3965.1423</pub-id><pub-id pub-id-type="pmid">4991522</pub-id></element-citation></ref><ref id="bib12"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Butler</surname> <given-names>PD</given-names></name><name><surname>Schechter</surname> <given-names>I</given-names></name><name><surname>Zemon</surname> <given-names>V</given-names></name><name><surname>Schwartz</surname> <given-names>SG</given-names></name><name><surname>Greenstein</surname> <given-names>VC</given-names></name><name><surname>Gordon</surname> <given-names>J</given-names></name><name><surname>Schroeder</surname> <given-names>CE</given-names></name><name><surname>Javitt</surname> <given-names>DC</given-names></name></person-group><year iso-8601-date="2001">2001</year><article-title>Dysfunction of early-stage visual processing in schizophrenia</article-title><source>American Journal of Psychiatry</source><volume>158</volume><fpage>1126</fpage><lpage>1133</lpage><pub-id pub-id-type="doi">10.1176/appi.ajp.158.7.1126</pub-id><pub-id pub-id-type="pmid">11431235</pub-id></element-citation></ref><ref id="bib13"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Campbell</surname> <given-names>FW</given-names></name><name><surname>Green</surname> <given-names>DG</given-names></name></person-group><year iso-8601-date="1965">1965</year><article-title>Optical and retinal factors affecting visual resolution</article-title><source>The Journal of Physiology</source><volume>181</volume><fpage>576</fpage><lpage>593</lpage><pub-id pub-id-type="doi">10.1113/jphysiol.1965.sp007784</pub-id><pub-id pub-id-type="pmid">5880378</pub-id></element-citation></ref><ref id="bib14"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Campbell</surname> <given-names>FW</given-names></name><name><surname>Robson</surname> <given-names>JG</given-names></name></person-group><year iso-8601-date="1968">1968</year><article-title>Application of Fourier analysis to the visibility of gratings</article-title><source>The Journal of Physiology</source><volume>197</volume><fpage>551</fpage><lpage>566</lpage><pub-id pub-id-type="doi">10.1113/jphysiol.1968.sp008574</pub-id><pub-id pub-id-type="pmid">5666169</pub-id></element-citation></ref><ref id="bib15"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Casile</surname> <given-names>A</given-names></name><name><surname>Rucci</surname> <given-names>M</given-names></name></person-group><year iso-8601-date="2006">2006</year><article-title>A theoretical analysis of the influence of fixational instability on the development of thalamocortical connectivity</article-title><source>Neural Computation</source><volume>18</volume><fpage>569</fpage><lpage>590</lpage><pub-id pub-id-type="doi">10.1162/neco.2006.18.3.569</pub-id><pub-id pub-id-type="pmid">16483408</pub-id></element-citation></ref><ref id="bib16"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Casile</surname> <given-names>A</given-names></name><name><surname>Rucci</surname> <given-names>M</given-names></name></person-group><year iso-8601-date="2009">2009</year><article-title>A theory of the influence of eye movements on the refinement of direction selectivity in the cat's primary visual cortex</article-title><source>Network: Computation in Neural Systems</source><volume>20</volume><fpage>197</fpage><lpage>232</lpage><pub-id pub-id-type="doi">10.3109/09548980903314204</pub-id><pub-id pub-id-type="pmid">19919281</pub-id></element-citation></ref><ref id="bib17"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Cherici</surname> <given-names>C</given-names></name><name><surname>Kuang</surname> <given-names>X</given-names></name><name><surname>Poletti</surname> <given-names>M</given-names></name><name><surname>Rucci</surname> <given-names>M</given-names></name></person-group><year iso-8601-date="2012">2012</year><article-title>Precision of sustained fixation in trained and untrained observers</article-title><source>Journal of Vision</source><volume>12</volume><elocation-id>31</elocation-id><pub-id pub-id-type="doi">10.1167/12.6.31</pub-id><pub-id pub-id-type="pmid">22728680</pub-id></element-citation></ref><ref id="bib18"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Crane</surname> <given-names>HD</given-names></name><name><surname>Steele</surname> <given-names>CM</given-names></name></person-group><year iso-8601-date="1985">1985</year><article-title>Generation-V dual-Purkinje-image eyetracker</article-title><source>Applied Optics</source><volume>24</volume><fpage>527</fpage><lpage>537</lpage><pub-id pub-id-type="doi">10.1364/AO.24.000527</pub-id><pub-id pub-id-type="pmid">18216982</pub-id></element-citation></ref><ref id="bib19"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Croner</surname> <given-names>LJ</given-names></name><name><surname>Kaplan</surname> <given-names>E</given-names></name></person-group><year iso-8601-date="1995">1995</year><article-title>Receptive fields of P and M ganglion cells across the primate retina</article-title><source>Vision Research</source><volume>35</volume><fpage>7</fpage><lpage>24</lpage><pub-id pub-id-type="doi">10.1016/0042-6989(94)E0066-T</pub-id><pub-id pub-id-type="pmid">7839612</pub-id></element-citation></ref><ref id="bib20"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>De Valois</surname> <given-names>RL</given-names></name><name><surname>Morgan</surname> <given-names>H</given-names></name><name><surname>Snodderly</surname> <given-names>DM</given-names></name></person-group><year iso-8601-date="1974">1974</year><article-title>Psychophysical studies of monkey vision. 3. Spatial luminance contrast sensitivity tests of macaque and human observers</article-title><source>Vision Research</source><volume>14</volume><fpage>75</fpage><lpage>81</lpage><pub-id pub-id-type="doi">10.1016/0042-6989(74)90118-7</pub-id><pub-id pub-id-type="pmid">4204839</pub-id></element-citation></ref><ref id="bib21"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Derrington</surname> <given-names>AM</given-names></name><name><surname>Lennie</surname> <given-names>P</given-names></name></person-group><year iso-8601-date="1984">1984</year><article-title>Spatial and temporal contrast sensitivities of neurones in lateral geniculate nucleus of macaque</article-title><source>The Journal of Physiology</source><volume>357</volume><fpage>219</fpage><lpage>240</lpage><pub-id pub-id-type="doi">10.1113/jphysiol.1984.sp015498</pub-id><pub-id pub-id-type="pmid">6512690</pub-id></element-citation></ref><ref id="bib22"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ditchburn</surname> <given-names>RW</given-names></name></person-group><year iso-8601-date="1955">1955</year><article-title>Eye-Movements in relation to retinal action</article-title><source>Optica Acta: International Journal of Optics</source><volume>1</volume><fpage>171</fpage><lpage>176</lpage><pub-id pub-id-type="doi">10.1080/713818684</pub-id></element-citation></ref><ref id="bib23"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Dowiasch</surname> <given-names>S</given-names></name><name><surname>Backasch</surname> <given-names>B</given-names></name><name><surname>Einhäuser</surname> <given-names>W</given-names></name><name><surname>Leube</surname> <given-names>D</given-names></name><name><surname>Kircher</surname> <given-names>T</given-names></name><name><surname>Bremmer</surname> <given-names>F</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Eye movements of patients with schizophrenia in a natural environment</article-title><source>European Archives of Psychiatry and Clinical Neuroscience</source><volume>266</volume><fpage>43</fpage><lpage>54</lpage><pub-id pub-id-type="doi">10.1007/s00406-014-0567-8</pub-id><pub-id pub-id-type="pmid">25472882</pub-id></element-citation></ref><ref id="bib24"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Eden</surname> <given-names>GF</given-names></name><name><surname>VanMeter</surname> <given-names>JW</given-names></name><name><surname>Rumsey</surname> <given-names>JM</given-names></name><name><surname>Zeffiro</surname> <given-names>TA</given-names></name></person-group><year iso-8601-date="1996">1996</year><article-title>The visual deficit theory of developmental dyslexia</article-title><source>NeuroImage</source><volume>4</volume><fpage>S108</fpage><lpage>S117</lpage><pub-id pub-id-type="doi">10.1006/nimg.1996.0061</pub-id><pub-id pub-id-type="pmid">9345535</pub-id></element-citation></ref><ref id="bib25"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Egaña</surname> <given-names>JI</given-names></name><name><surname>Devia</surname> <given-names>C</given-names></name><name><surname>Mayol</surname> <given-names>R</given-names></name><name><surname>Parrini</surname> <given-names>J</given-names></name><name><surname>Orellana</surname> <given-names>G</given-names></name><name><surname>Ruiz</surname> <given-names>A</given-names></name><name><surname>Maldonado</surname> <given-names>PE</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>Small Saccades and Image Complexity during Free Viewing of Natural Images in Schizophrenia</article-title><source>Frontiers in Psychiatry</source><volume>4</volume><elocation-id>37</elocation-id><pub-id pub-id-type="doi">10.3389/fpsyt.2013.00037</pub-id><pub-id pub-id-type="pmid">23730291</pub-id></element-citation></ref><ref id="bib26"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Greschner</surname> <given-names>M</given-names></name><name><surname>Bongard</surname> <given-names>M</given-names></name><name><surname>Rujan</surname> <given-names>P</given-names></name><name><surname>Ammermüller</surname> <given-names>J</given-names></name></person-group><year iso-8601-date="2002">2002</year><article-title>Retinal ganglion cell synchronization by fixational eye movements improves feature estimation</article-title><source>Nature Neuroscience</source><volume>5</volume><fpage>341</fpage><lpage>347</lpage><pub-id pub-id-type="doi">10.1038/nn821</pub-id><pub-id pub-id-type="pmid">11914721</pub-id></element-citation></ref><ref id="bib27"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Gur</surname> <given-names>M</given-names></name><name><surname>Beylin</surname> <given-names>A</given-names></name><name><surname>Snodderly</surname> <given-names>DM</given-names></name></person-group><year iso-8601-date="1997">1997</year><article-title>Response variability of neurons in primary visual cortex (V1) of alert monkeys</article-title><source>The Journal of Neuroscience</source><volume>17</volume><fpage>2914</fpage><lpage>2920</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.17-08-02914.1997</pub-id><pub-id pub-id-type="pmid">9092612</pub-id></element-citation></ref><ref id="bib28"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Gustafsson</surname> <given-names>J</given-names></name><name><surname>Inde</surname> <given-names>K</given-names></name></person-group><year iso-8601-date="2004">2004</year><article-title>The MoviText method: Efficient pre-optical reading training in persons with central visual field loss</article-title><source>Technology and Disability</source><volume>6</volume><fpage>211</fpage><lpage>221</lpage></element-citation></ref><ref id="bib29"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Harvey</surname> <given-names>H</given-names></name><name><surname>Walker</surname> <given-names>R</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>Reading with peripheral vision: a comparison of reading dynamic scrolling and static text with a simulated central scotoma</article-title><source>Vision Research</source><volume>98</volume><fpage>54</fpage><lpage>60</lpage><pub-id pub-id-type="doi">10.1016/j.visres.2014.03.009</pub-id><pub-id pub-id-type="pmid">24680772</pub-id></element-citation></ref><ref id="bib30"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hicks</surname> <given-names>TP</given-names></name><name><surname>Lee</surname> <given-names>BB</given-names></name><name><surname>Vidyasagar</surname> <given-names>TR</given-names></name></person-group><year iso-8601-date="1983">1983</year><article-title>The responses of cells in macaque lateral geniculate nucleus to sinusoidal gratings</article-title><source>The Journal of Physiology</source><volume>337</volume><fpage>183</fpage><lpage>200</lpage><pub-id pub-id-type="doi">10.1113/jphysiol.1983.sp014619</pub-id><pub-id pub-id-type="pmid">6875927</pub-id></element-citation></ref><ref id="bib31"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hirsch</surname> <given-names>J</given-names></name><name><surname>Miller</surname> <given-names>WH</given-names></name></person-group><year iso-8601-date="1987">1987</year><article-title>Does cone positional disorder limit resolution?</article-title><source>Journal of the Optical Society of America A</source><volume>4</volume><fpage>1481</fpage><lpage>1492</lpage><pub-id pub-id-type="doi">10.1364/JOSAA.4.001481</pub-id><pub-id pub-id-type="pmid">3625328</pub-id></element-citation></ref><ref id="bib32"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Juusola</surname> <given-names>M</given-names></name><name><surname>Dau</surname> <given-names>A</given-names></name><name><surname>Song</surname> <given-names>Z</given-names></name><name><surname>Solanki</surname> <given-names>N</given-names></name><name><surname>Rien</surname> <given-names>D</given-names></name><name><surname>Jaciuch</surname> <given-names>D</given-names></name><name><surname>Dongre</surname> <given-names>SA</given-names></name><name><surname>Blanchard</surname> <given-names>F</given-names></name><name><surname>de Polavieja</surname> <given-names>GG</given-names></name><name><surname>Hardie</surname> <given-names>RC</given-names></name><name><surname>Takalo</surname> <given-names>J</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Microsaccadic sampling of moving image information provides Drosophila hyperacute vision</article-title><source>eLife</source><volume>6</volume><elocation-id>e26117</elocation-id><pub-id pub-id-type="doi">10.7554/eLife.26117</pub-id></element-citation></ref><ref id="bib33"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kagan</surname> <given-names>I</given-names></name><name><surname>Gur</surname> <given-names>M</given-names></name><name><surname>Snodderly</surname> <given-names>DM</given-names></name></person-group><year iso-8601-date="2008">2008</year><article-title>Saccades and drifts differentially modulate neuronal activity in V1: effects of retinal image motion, position, and extraretinal influences</article-title><source>Journal of Vision</source><volume>8</volume><fpage>19</fpage><lpage>25</lpage><pub-id pub-id-type="doi">10.1167/8.14.19</pub-id><pub-id pub-id-type="pmid">19146320</pub-id></element-citation></ref><ref id="bib34"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kaplan</surname> <given-names>E</given-names></name><name><surname>Shapley</surname> <given-names>RM</given-names></name></person-group><year iso-8601-date="1982">1982</year><article-title>X and Y cells in the lateral geniculate nucleus of macaque monkeys</article-title><source>The Journal of Physiology</source><volume>330</volume><fpage>125</fpage><lpage>143</lpage><pub-id pub-id-type="doi">10.1113/jphysiol.1982.sp014333</pub-id><pub-id pub-id-type="pmid">7175738</pub-id></element-citation></ref><ref id="bib35"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kelly</surname> <given-names>DH</given-names></name></person-group><year iso-8601-date="1979">1979</year><article-title>Motion and vision. I. Stabilized images of stationary gratings</article-title><source>Journal of the Optical Society of America</source><volume>69</volume><fpage>1266</fpage><lpage>1274</lpage><pub-id pub-id-type="doi">10.1364/JOSA.69.001266</pub-id><pub-id pub-id-type="pmid">521857</pub-id></element-citation></ref><ref id="bib36"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kim</surname> <given-names>D</given-names></name><name><surname>Wylie</surname> <given-names>G</given-names></name><name><surname>Pasternak</surname> <given-names>R</given-names></name><name><surname>Butler</surname> <given-names>PD</given-names></name><name><surname>Javitt</surname> <given-names>DC</given-names></name></person-group><year iso-8601-date="2006">2006</year><article-title>Magnocellular contributions to impaired motion processing in schizophrenia</article-title><source>Schizophrenia Research</source><volume>82</volume><fpage>1</fpage><lpage>8</lpage><pub-id pub-id-type="doi">10.1016/j.schres.2005.10.008</pub-id><pub-id pub-id-type="pmid">16325377</pub-id></element-citation></ref><ref id="bib37"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ko</surname> <given-names>HK</given-names></name><name><surname>Snodderly</surname> <given-names>DM</given-names></name><name><surname>Poletti</surname> <given-names>M</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Eye movements between saccades: Measuring ocular drift and tremor</article-title><source>Vision research</source><volume>122</volume><fpage>93</fpage><lpage>104</lpage><pub-id pub-id-type="doi">10.1016/j.visres.2016.03.006</pub-id><pub-id pub-id-type="pmid">27068415</pub-id></element-citation></ref><ref id="bib38"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kowler</surname> <given-names>E</given-names></name></person-group><year iso-8601-date="2011">2011</year><article-title>Eye movements: the past 25 years</article-title><source>Vision Research</source><volume>51</volume><fpage>1457</fpage><lpage>1483</lpage><pub-id pub-id-type="doi">10.1016/j.visres.2010.12.014</pub-id><pub-id pub-id-type="pmid">21237189</pub-id></element-citation></ref><ref id="bib39"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kuang</surname> <given-names>X</given-names></name><name><surname>Poletti</surname> <given-names>M</given-names></name><name><surname>Victor</surname> <given-names>JD</given-names></name><name><surname>Rucci</surname> <given-names>M</given-names></name></person-group><year iso-8601-date="2012">2012</year><article-title>Temporal encoding of spatial information during active visual fixation</article-title><source>Current Biology</source><volume>22</volume><fpage>510</fpage><lpage>514</lpage><pub-id pub-id-type="doi">10.1016/j.cub.2012.01.050</pub-id><pub-id pub-id-type="pmid">22342751</pub-id></element-citation></ref><ref id="bib40"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Leopold</surname> <given-names>DA</given-names></name><name><surname>Logothetis</surname> <given-names>NK</given-names></name></person-group><year iso-8601-date="1998">1998</year><article-title>Microsaccades differentially modulate neural activity in the striate and extrastriate visual cortex</article-title><source>Experimental Brain Research</source><volume>123</volume><fpage>341</fpage><lpage>345</lpage><pub-id pub-id-type="doi">10.1007/s002210050577</pub-id><pub-id pub-id-type="pmid">9860273</pub-id></element-citation></ref><ref id="bib41"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Li</surname> <given-names>CS</given-names></name></person-group><year iso-8601-date="2002">2002</year><article-title>Impaired detection of visual motion in schizophrenia patients</article-title><source>Progress in Neuro-Psychopharmacology &amp; Biological Psychiatry</source><volume>26</volume><fpage>929</fpage><lpage>934</lpage><pub-id pub-id-type="pmid">12369268</pub-id></element-citation></ref><ref id="bib42"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Lovegrove</surname> <given-names>WJ</given-names></name><name><surname>Bowling</surname> <given-names>A</given-names></name><name><surname>Badcock</surname> <given-names>D</given-names></name><name><surname>Blackwood</surname> <given-names>M</given-names></name></person-group><year iso-8601-date="1980">1980a</year><article-title>Specific reading disability: differences in contrast sensitivity as a function of spatial frequency</article-title><source>Science</source><volume>210</volume><fpage>439</fpage><lpage>440</lpage><pub-id pub-id-type="doi">10.1126/science.7433985</pub-id><pub-id pub-id-type="pmid">7433985</pub-id></element-citation></ref><ref id="bib43"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Lovegrove</surname> <given-names>WJ</given-names></name><name><surname>Heddle</surname> <given-names>M</given-names></name><name><surname>Slaghuis</surname> <given-names>W</given-names></name></person-group><year iso-8601-date="1980">1980b</year><article-title>Reading disability: spatial frequency specific deficits in visual information store</article-title><source>Neuropsychologia</source><volume>18</volume><fpage>111</fpage><lpage>115</lpage><pub-id pub-id-type="doi">10.1016/0028-3932(80)90093-7</pub-id><pub-id pub-id-type="pmid">7366819</pub-id></element-citation></ref><ref id="bib44"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Martinez-Conde</surname> <given-names>S</given-names></name><name><surname>Macknik</surname> <given-names>SL</given-names></name><name><surname>Hubel</surname> <given-names>DH</given-names></name></person-group><year iso-8601-date="2000">2000</year><article-title>Microsaccadic eye movements and firing of single cells in the striate cortex of macaque monkeys</article-title><source>Nature Neuroscience</source><volume>3</volume><fpage>251</fpage><lpage>258</lpage><pub-id pub-id-type="doi">10.1038/72961</pub-id></element-citation></ref><ref id="bib45"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>McFarland</surname> <given-names>JM</given-names></name><name><surname>Cumming</surname> <given-names>BG</given-names></name><name><surname>Butts</surname> <given-names>DA</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Variability and correlations in primary visual cortical neurons driven by fixational eye movements</article-title><source>The Journal of Neuroscience</source><volume>36</volume><fpage>6225</fpage><lpage>6241</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.4660-15.2016</pub-id><pub-id pub-id-type="pmid">27277801</pub-id></element-citation></ref><ref id="bib46"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Meirovithz</surname> <given-names>E</given-names></name><name><surname>Ayzenshtat</surname> <given-names>I</given-names></name><name><surname>Werner-Reiss</surname> <given-names>U</given-names></name><name><surname>Shamir</surname> <given-names>I</given-names></name><name><surname>Slovin</surname> <given-names>H</given-names></name></person-group><year iso-8601-date="2012">2012</year><article-title>Spatiotemporal effects of microsaccades on population activity in the visual cortex of monkeys during fixation</article-title><source>Cerebral Cortex</source><volume>22</volume><fpage>294</fpage><lpage>307</lpage><pub-id pub-id-type="doi">10.1093/cercor/bhr102</pub-id><pub-id pub-id-type="pmid">21653284</pub-id></element-citation></ref><ref id="bib47"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Mostofi</surname> <given-names>N</given-names></name><name><surname>Boi</surname> <given-names>M</given-names></name><name><surname>Rucci</surname> <given-names>M</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Are the visual transients from microsaccades helpful? Measuring the influences of small saccades on contrast sensitivity</article-title><source>Vision Research</source><volume>118</volume><fpage>60</fpage><lpage>69</lpage><pub-id pub-id-type="doi">10.1016/j.visres.2015.01.003</pub-id><pub-id pub-id-type="pmid">25687189</pub-id></element-citation></ref><ref id="bib48"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Olveczky</surname> <given-names>BP</given-names></name><name><surname>Baccus</surname> <given-names>SA</given-names></name><name><surname>Meister</surname> <given-names>M</given-names></name></person-group><year iso-8601-date="2003">2003</year><article-title>Segregation of object and background motion in the retina</article-title><source>Nature</source><volume>423</volume><fpage>401</fpage><lpage>408</lpage><pub-id pub-id-type="doi">10.1038/nature01652</pub-id><pub-id pub-id-type="pmid">12754524</pub-id></element-citation></ref><ref id="bib49"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Owsley</surname> <given-names>C</given-names></name><name><surname>sensitivity</surname> <given-names>C</given-names></name></person-group><year iso-8601-date="2003">2003</year><article-title>Contrast sensitivity</article-title><source>Ophthalmology Clinics of North America</source><volume>16</volume><fpage>171</fpage><lpage>177</lpage><pub-id pub-id-type="doi">10.1016/S0896-1549(03)00003-8</pub-id></element-citation></ref><ref id="bib50"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Poletti</surname> <given-names>M</given-names></name><name><surname>Aytekin</surname> <given-names>M</given-names></name><name><surname>Rucci</surname> <given-names>M</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>Head-Eye coordination at a microscopic scale</article-title><source>Current Biology</source><volume>25</volume><fpage>3253</fpage><lpage>3259</lpage><pub-id pub-id-type="doi">10.1016/j.cub.2015.11.004</pub-id><pub-id pub-id-type="pmid">26687623</pub-id></element-citation></ref><ref id="bib51"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Puchalla</surname> <given-names>JL</given-names></name><name><surname>Schneidman</surname> <given-names>E</given-names></name><name><surname>Harris</surname> <given-names>RA</given-names></name><name><surname>Berry</surname> <given-names>MJ</given-names></name></person-group><year iso-8601-date="2005">2005</year><article-title>Redundancy in the population code of the retina</article-title><source>Neuron</source><volume>46</volume><fpage>493</fpage><lpage>504</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2005.03.026</pub-id><pub-id pub-id-type="pmid">15882648</pub-id></element-citation></ref><ref id="bib52"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Purpura</surname> <given-names>K</given-names></name><name><surname>Tranchina</surname> <given-names>D</given-names></name><name><surname>Kaplan</surname> <given-names>E</given-names></name><name><surname>Shapley</surname> <given-names>RM</given-names></name></person-group><year iso-8601-date="1990">1990</year><article-title>Light adaptation in the primate retina: analysis of changes in gain and dynamics of monkey retinal ganglion cells</article-title><source>Visual Neuroscience</source><volume>4</volume><fpage>75</fpage><lpage>93</lpage><pub-id pub-id-type="doi">10.1017/S0952523800002789</pub-id><pub-id pub-id-type="pmid">2176096</pub-id></element-citation></ref><ref id="bib53"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ratliff</surname> <given-names>F</given-names></name><name><surname>Riggs</surname> <given-names>LA</given-names></name></person-group><year iso-8601-date="1950">1950</year><article-title>Involuntary motions of the eye during monocular fixation</article-title><source>Journal of Experimental Psychology</source><volume>40</volume><fpage>687</fpage><lpage>701</lpage><pub-id pub-id-type="doi">10.1037/h0057754</pub-id><pub-id pub-id-type="pmid">14803643</pub-id></element-citation></ref><ref id="bib54"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ratnam</surname> <given-names>K</given-names></name><name><surname>Domdei</surname> <given-names>N</given-names></name><name><surname>Harmening</surname> <given-names>WM</given-names></name><name><surname>Roorda</surname> <given-names>A</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>Benefits of retinal image motion at the limits of spatial vision</article-title><source>Journal of Vision</source><volume>17</volume><elocation-id>30</elocation-id><pub-id pub-id-type="doi">10.1167/17.1.30</pub-id><pub-id pub-id-type="pmid">28129414</pub-id></element-citation></ref><ref id="bib55"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Revheim</surname> <given-names>N</given-names></name><name><surname>Butler</surname> <given-names>PD</given-names></name><name><surname>Schechter</surname> <given-names>I</given-names></name><name><surname>Jalbrzikowski</surname> <given-names>M</given-names></name><name><surname>Silipo</surname> <given-names>G</given-names></name><name><surname>Javitt</surname> <given-names>DC</given-names></name></person-group><year iso-8601-date="2006">2006</year><article-title>Reading impairment and visual processing deficits in schizophrenia</article-title><source>Schizophrenia Research</source><volume>87</volume><fpage>238</fpage><lpage>245</lpage><pub-id pub-id-type="doi">10.1016/j.schres.2006.06.022</pub-id><pub-id pub-id-type="pmid">16890409</pub-id></element-citation></ref><ref id="bib56"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Riggs</surname> <given-names>LA</given-names></name><name><surname>Ratliff</surname> <given-names>F</given-names></name><name><surname>Cornsweet</surname> <given-names>JC</given-names></name><name><surname>Cornsweet</surname> <given-names>TN</given-names></name></person-group><year iso-8601-date="1953">1953</year><article-title>The disappearance of steadily fixated visual test objects</article-title><source>Journal of the Optical Society of America</source><volume>43</volume><fpage>495</fpage><lpage>501</lpage><pub-id pub-id-type="doi">10.1364/JOSA.43.000495</pub-id><pub-id pub-id-type="pmid">13070111</pub-id></element-citation></ref><ref id="bib57"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Robson</surname> <given-names>JG</given-names></name></person-group><year iso-8601-date="1966">1966</year><article-title>Spatial and temporal contrast-sensitivity functions of the visual system</article-title><source>Journal of the Optical Society of America</source><volume>56</volume><fpage>1141</fpage><lpage>1142</lpage><pub-id pub-id-type="doi">10.1364/JOSA.56.001141</pub-id></element-citation></ref><ref id="bib58"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Rossi</surname> <given-names>EA</given-names></name><name><surname>Roorda</surname> <given-names>A</given-names></name></person-group><year iso-8601-date="2010">2010</year><article-title>The relationship between visual resolution and cone spacing in the human fovea</article-title><source>Nature Neuroscience</source><volume>13</volume><fpage>156</fpage><lpage>157</lpage><pub-id pub-id-type="doi">10.1038/nn.2465</pub-id><pub-id pub-id-type="pmid">20023654</pub-id></element-citation></ref><ref id="bib59"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Rucci</surname> <given-names>M</given-names></name><name><surname>Iovin</surname> <given-names>R</given-names></name><name><surname>Poletti</surname> <given-names>M</given-names></name><name><surname>Santini</surname> <given-names>F</given-names></name></person-group><year iso-8601-date="2007">2007</year><article-title>Miniature eye movements enhance fine spatial detail</article-title><source>Nature</source><volume>447</volume><fpage>852</fpage><lpage>855</lpage><pub-id pub-id-type="doi">10.1038/nature05866</pub-id><pub-id pub-id-type="pmid">17568745</pub-id></element-citation></ref><ref id="bib60"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Rucci</surname> <given-names>M</given-names></name><name><surname>Poletti</surname> <given-names>M</given-names></name></person-group><year iso-8601-date="2015">2015a</year><article-title>Control and functions of fixational eye movements</article-title><source>Annual Review of Vision Science</source><volume>1</volume><fpage>499</fpage><lpage>518</lpage><pub-id pub-id-type="doi">10.1146/annurev-vision-082114-035742</pub-id><pub-id pub-id-type="pmid">27795997</pub-id></element-citation></ref><ref id="bib61"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Rucci</surname> <given-names>M</given-names></name><name><surname>Victor</surname> <given-names>JD</given-names></name></person-group><year iso-8601-date="2015">2015b</year><article-title>The unsteady eye: an information-processing stage, not a bug</article-title><source>Trends in Neurosciences</source><volume>38</volume><fpage>195</fpage><lpage>206</lpage><pub-id pub-id-type="doi">10.1016/j.tins.2015.01.005</pub-id><pub-id pub-id-type="pmid">25698649</pub-id></element-citation></ref><ref id="bib62"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Rucci</surname> <given-names>M</given-names></name><name><surname>Ahissar</surname> <given-names>E</given-names></name><name><surname>Burr</surname> <given-names>D</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>Temporal coding of visual space</article-title><source>Trends in Cognitive Sciences</source><volume>22</volume><fpage>883</fpage><lpage>895</lpage><pub-id pub-id-type="doi">10.1016/j.tics.2018.07.009</pub-id><pub-id pub-id-type="pmid">30266148</pub-id></element-citation></ref><ref id="bib63"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Santini</surname> <given-names>F</given-names></name><name><surname>Redner</surname> <given-names>G</given-names></name><name><surname>Iovin</surname> <given-names>R</given-names></name><name><surname>Rucci</surname> <given-names>M</given-names></name></person-group><year iso-8601-date="2007">2007</year><article-title>EyeRIS: a general-purpose system for eye-movement-contingent display control</article-title><source>Behavior Research Methods</source><volume>39</volume><fpage>350</fpage><lpage>364</lpage><pub-id pub-id-type="doi">10.3758/BF03193003</pub-id><pub-id pub-id-type="pmid">17958145</pub-id></element-citation></ref><ref id="bib64"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Segal</surname> <given-names>IY</given-names></name><name><surname>Giladi</surname> <given-names>C</given-names></name><name><surname>Gedalin</surname> <given-names>M</given-names></name><name><surname>Rucci</surname> <given-names>M</given-names></name><name><surname>Ben-Tov</surname> <given-names>M</given-names></name><name><surname>Kushinsky</surname> <given-names>Y</given-names></name><name><surname>Mokeichev</surname> <given-names>A</given-names></name><name><surname>Segev</surname> <given-names>R</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>Decorrelation of retinal response to natural scenes by fixational eye movements</article-title><source>PNAS</source><volume>112</volume><fpage>3110</fpage><lpage>3115</lpage><pub-id pub-id-type="doi">10.1073/pnas.1412059112</pub-id><pub-id pub-id-type="pmid">25713370</pub-id></element-citation></ref><ref id="bib65"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Slaghuis</surname> <given-names>WL</given-names></name></person-group><year iso-8601-date="1998">1998</year><article-title>Contrast sensitivity for stationary and drifting spatial frequency gratings in positive- and negative-symptom schizophrenia</article-title><source>Journal of Abnormal Psychology</source><volume>107</volume><fpage>49</fpage><lpage>62</lpage><pub-id pub-id-type="doi">10.1037/0021-843X.107.1.49</pub-id><pub-id pub-id-type="pmid">9505038</pub-id></element-citation></ref><ref id="bib66"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Stein</surname> <given-names>J</given-names></name><name><surname>Fowler</surname> <given-names>S</given-names></name></person-group><year iso-8601-date="1981">1981</year><article-title>Visual dyslexia</article-title><source>Trends in Neurosciences</source><volume>4</volume><fpage>77</fpage><lpage>80</lpage><pub-id pub-id-type="doi">10.1016/0166-2236(81)90026-6</pub-id></element-citation></ref><ref id="bib67"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Stein</surname> <given-names>JF</given-names></name><name><surname>Fowler</surname> <given-names>MS</given-names></name></person-group><year iso-8601-date="1993">1993</year><article-title>Unstable binocular control in dyslexic children</article-title><source>Journal of Research in Reading</source><volume>16</volume><fpage>30</fpage><lpage>45</lpage><pub-id pub-id-type="doi">10.1111/j.1467-9817.1993.tb00033.x</pub-id></element-citation></ref><ref id="bib68"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Steinman</surname> <given-names>RM</given-names></name><name><surname>Haddad</surname> <given-names>GM</given-names></name><name><surname>Skavenski</surname> <given-names>AA</given-names></name><name><surname>Wyman</surname> <given-names>D</given-names></name><name><surname>Movement</surname> <given-names>ME</given-names></name></person-group><year iso-8601-date="1973">1973</year><article-title>Miniature eye movement</article-title><source>Science</source><volume>181</volume><fpage>810</fpage><lpage>819</lpage><pub-id pub-id-type="doi">10.1126/science.181.4102.810</pub-id></element-citation></ref><ref id="bib69"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Taylor</surname> <given-names>MM</given-names></name><name><surname>Creelman</surname> <given-names>CD</given-names></name></person-group><year iso-8601-date="1967">1967</year><article-title>PEST: Efficient estimates on probability functions</article-title><source>The Journal of the Acoustical Society of America</source><volume>41</volume><fpage>782</fpage><lpage>787</lpage><pub-id pub-id-type="doi">10.1121/1.1910407</pub-id></element-citation></ref><ref id="bib70"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Thorson</surname> <given-names>J</given-names></name><name><surname>Biederman-Thorson</surname> <given-names>M</given-names></name></person-group><year iso-8601-date="1974">1974</year><article-title>Distributed relaxation processes in sensory adaptation</article-title><source>Science</source><volume>183</volume><fpage>161</fpage><lpage>172</lpage><pub-id pub-id-type="pmid">4587440</pub-id></element-citation></ref><ref id="bib71"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Van Essen</surname> <given-names>DC</given-names></name><name><surname>Newsome</surname> <given-names>WT</given-names></name><name><surname>Maunsell</surname> <given-names>JH</given-names></name></person-group><year iso-8601-date="1984">1984</year><article-title>The visual field representation in striate cortex of the macaque monkey: asymmetries, anisotropies, and individual variability</article-title><source>Vision Research</source><volume>24</volume><fpage>429</fpage><lpage>448</lpage><pub-id pub-id-type="doi">10.1016/0042-6989(84)90041-5</pub-id><pub-id pub-id-type="pmid">6740964</pub-id></element-citation></ref><ref id="bib72"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Victor</surname> <given-names>JD</given-names></name></person-group><year iso-8601-date="1987">1987</year><article-title>The dynamics of the cat retinal X cell centre</article-title><source>The Journal of Physiology</source><volume>386</volume><fpage>219</fpage><lpage>246</lpage><pub-id pub-id-type="doi">10.1113/jphysiol.1987.sp016531</pub-id><pub-id pub-id-type="pmid">3681707</pub-id></element-citation></ref><ref id="bib73"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Watson</surname> <given-names>LM</given-names></name><name><surname>Strang</surname> <given-names>NC</given-names></name><name><surname>Scobie</surname> <given-names>F</given-names></name><name><surname>Love</surname> <given-names>GD</given-names></name><name><surname>Seidel</surname> <given-names>D</given-names></name><name><surname>Manahilov</surname> <given-names>V</given-names></name></person-group><year iso-8601-date="2012">2012</year><article-title>Image jitter enhances visual performance when spatial resolution is impaired</article-title><source>Investigative Opthalmology &amp; Visual Science</source><volume>53</volume><fpage>6004</fpage><lpage>6010</lpage><pub-id pub-id-type="doi">10.1167/iovs.11-9157</pub-id><pub-id pub-id-type="pmid">22879420</pub-id></element-citation></ref><ref id="bib74"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Yarbus</surname> <given-names>AL</given-names></name></person-group><year iso-8601-date="1957">1957</year><article-title>The perception of an image fixed with respect to the retina</article-title><source>Biophysics</source><volume>2</volume><fpage>683</fpage><lpage>690</lpage></element-citation></ref></ref-list></back><sub-article article-type="decision-letter" id="SA1"><front-stub><article-id pub-id-type="doi">10.7554/eLife.40924.022</article-id><title-group><article-title>Decision letter</article-title></title-group><contrib-group><contrib contrib-type="editor"><name><surname>Rieke</surname><given-names>Fred</given-names></name><role>Reviewing Editor</role><aff><institution>University of Washington</institution><country>United States</country></aff></contrib></contrib-group></front-stub><body><boxed-text><p>In the interests of transparency, eLife includes the editorial decision letter and accompanying author responses. A lightly edited version of the letter sent to the authors after peer review is shown, indicating the most substantive concerns; minor comments are not usually included.</p></boxed-text><p>[Editors’ note: a previous version of this study was rejected after peer review, but the authors submitted for reconsideration. The first decision letter after peer review is shown below.]</p><p>Thank you for submitting your work entitled &quot;Changes in visual sensitivity reveal an active strategy for temporally encoding space&quot; for consideration by <italic>eLife</italic>. Your article has been reviewed by three peer reviewers, one of whom is a member of our Board of Reviewing Editors, and the evaluation has been overseen by a Senior Editor. The reviewers have opted to remain anonymous.</p><p>Our decision has been reached after consultation between the reviewers. Based on these discussions and the individual reviews below, we regret to inform you that your work cannot be considered further, at least in present form. We would be willing to consider a revised paper if you thoroughly deal with the reviewers’ concerns.</p><p>All three reviewers agreed that the work was of broad interest. We also agreed that several issues needed to be strengthened before considering the paper further. These and several other issues are detailed in the individual reviews. The two most pressing issues follow:</p><p>1) Recent work from some of the same authors has deepened understanding of the relation between FEM and neural coding. The relation between the present work and this past work is not as clear as it needs to be in the Introduction, and as a result the advance that the present work represents is difficult to appreciate immediately.</p><p>2) At the heart of the paper is the discrepancy between physiological and psychophysical CSFs. But the ganglion cell examples in the first figure appear not to accurately reflect ganglion cell behavior since they do not include points at low frequencies (with instead a horizontal line from the lowest spatial frequency point plotted). Most ganglion cell measurements show some low frequency roll-off. A thorough justification of the properties used to represent measured ganglion cell CSFs is needed.</p><p><italic>Reviewer #1:</italic> </p><p>This paper describes the interaction between eye movements and spatial coding. The paper starts by describing a discrepancy between spatial contrast sensitivity as measured behaviorally and as measured in responses of retinal or geniculate cells. It then proposes that this discrepancy originates because the neural recordings were made in the absence of eye movements, and that the discrepancy can be resolved when eye movements are taken into account. The case for the importance of eye movements, made here and in previous work from some of the same authors, is compelling. There are several issues with the present paper, however, that limit my enthusiasm:</p><p>1) M and P cell models. The literature contains numerous measurements of M and P cell spatial contrast sensitivity. From a scan of these papers (e.g. Derrington and Lennie, 1984; Kaplan and Shapley, 1982), measured spatial contrast sensitivity curves for both M and P cells fall, sometimes sharply, at low spatial frequencies. This fall is not evident in the responses depicted in Figure 1. Even the Cronor and Kaplan (1995) paper cited as the basis of Figure 1 shows a clear falloff at low spatial frequencies, and describes properties of the associated surround (related, the Benardete and Kaplan, 1997 reference in the text is about M sequences and temporal properties, so not immediately clear how it is relevant). I am not clear on why the red curves in Figure 1 should be extrapolated from their peak to a 0 spatial frequency asymptote; this extrapolation appears to be inconsistent with most experimental results. More generally, I think it is critical that the paper contains a thorough summary of the measured M and P properties across studies, and a clear justification of the M and P models used. Figure 1 presently undermines confidence in the central motivation for the paper.</p><p>2) Overlap with previous work. The content of Figures 1 and 2 is a review of previous work. Of particular importance, previous work from some of the same authors has established that eye movements decrease responses to low spatial frequencies in natural images. I am concerned, given that, about the intellectual advance of the present paper. Specifically, I think the paper would benefit from more experimental tests of the proposal. For example, are there measurements of spatial contrast sensitivity in awake behaving monkeys (i.e. with eye movements)? Recognizing that eye movements cannot be fully suppressed, can they still be manipulated to test the proposal (e.g. can they be increased)? Are there differences across eccentricity that could be exploited to provide additional tests?</p><p><italic>Reviewer #2:</italic> </p><p>The contrast sensitivity function (CSF) is a fundamental characteristic of vision – it describes how the ability to see depends on the spatial frequency of the input. The CSF is believed to be due to processing limitations at the earliest stages of processing (i.e., at the retina). However, there is a long-known discrepancy between the CSF (measured by having subjects report) and the properties of retinal output signals (measured physiologically) – subjects are less sensitive to low spatial frequencies than you would expect from the signals recorded in the retina. This paper puts forward and tests a specific explanation for this discrepancy – subjects make small eye movements during fixation, and this introduces temporal modulations that shift the power spectrum of the visual input. The paper convincingly demonstrates that this explanation is adequate to explain the discrepancy, using high-quality measurements of eye movements in human subjects combined with computational modeling of retinal ganglion cell responses. Moreover, they extend this approach to show that reducing fixational eye movements would be expected to shift the CSF in ways that are consistent with previous studies using retinal stabilization.</p><p>Overall, this is an expertly conducted combination of computational modeling and eye movement recording that provides an elegant solution to a long-standing problem in vision science. My comments are aimed mainly at clarifying the presentation.</p><p>The paper refers to &quot;fixational eye movements&quot; or &quot;FEMs&quot; throughout, but what is meant by this is the slow drift component of fixational eye movements, and not microsaccades or oscillatory movements. A few points. First, the paper is reasonably clear on this point, but not completely and not everywhere. For example, the casual reader who only looks at the Abstract and skims the details (including the Results where the focus on drift is pointed out) might conclude that this applies to microsaccades, since they are the best-known component of FEMs. Is there a reason to avoid using the more specific term &quot;ocular drift&quot; rather than &quot;FEMs&quot; throughout, or at least, more often? Second, what is the impact of microsaccades? Would these also be expected to affect the CSF or is the scale of their temporal modulation too high to affect responses? This point should be clarified. Third, if ocular drift and microsaccades have distinguishable effects on CSF, then the authors should be especially careful with the use of the term &quot;FEMs&quot;, especially in the Discussion, where it seems that the conclusions based on ocular drift appear to be generalized to all types of fixational eye movements.</p><p>In several places – starting with the title – the manuscript implies that there is an active strategy behind these effects of FEMs, rather than it being an incidental effect. To me, &quot;active strategy&quot; implies some reliable relationship between the circumstance and the subject's behavior. For example, the needle-threading task shows that microsaccades appear to be generated based on some sort of active strategy. For ocular drift, it is not clear that such a relationship has been established. Do you have some basis of this claim, or is it simply a speculation? If it is a speculation, the text should be written more conservatively to match.</p><p>Another plausible explanation for why the behavioral CSF does not match the properties of the retinal output is that some part of the rest of the visual system is responsible. Is there a basis for excluding this possibility?</p><p><italic>Reviewer #3:</italic> </p><p>This paper explores how non-separable spatio-temporal frequency tuning of M and P cells combines with measured fixational eye movements to account for observed behaviorally measured visual contrast sensitivity. A minimal model agrees well with a range of experimental data (free viewing of gratings at different temporal frequencies as well as retinal stabilization experiments) and suggests that eye movements have been optimized for neuronal contrast sensitivity curves (this work) as well as the content of natural scenes (previous work from the same groups). Experimental tests are suggested, particularly for retina-in-a-dish style experiments, where movements typical of FEMs are rarely added to visual stimuli. Experiments are also suggested for human subjects and for some clinical applications.</p><p>1) The paper is clearly presented and the work is thorough and interesting, but there should be more emphasis in the Introduction on why it's so important to understand the discrepancies between neuronal and behavioral CSFs for stationary stimuli. This could be addressed with a bit of text that previews some of the Discussion points about the neural coding and potential clinical applications of these findings.</p><p>2) Some recap of existing retinal recordings with FEM-like perturbations (e.g. Greschner et al., 2002) should be added to the Discussion.</p><p>3) Figure 1A – no data points are apparent below about 2Hz for the P and M cells, right around where the neuronal and behavioral CSFs diverge. It would be nice to include some data points there, perhaps from other studies. If data points do exist at 0Hz, they should be made more apparent.</p><p>[Editors’ note: what now follows is the decision letter after the authors submitted for further consideration.]</p><p>Thank you for submitting your article &quot;Contrast sensitivity reveals an oculomotor strategy for temporally encoding space&quot; for consideration by <italic>eLife</italic>. Your article has been reviewed by three peer reviewers, one of whom is a member of our Board of Reviewing Editors, and the evaluation has been overseen by Timothy Behrens as the Senior Editor. The reviewers have opted to remain anonymous.</p><p>The reviewers have discussed the reviews with one another and the Reviewing Editor has drafted this decision to help you prepare a revised submission.</p><p>The revisions have improved the paper substantially. There is one outstanding point remaining about the ganglion cell model (see reviews for details). In consultation all of the reviewers agreed this was important to resolve.</p><p><italic>Reviewer #1:</italic> </p><p>This is a revision of a paper about the relationship between fixational eye movements and spatial contrast sensitivity. The paper centers around the observation that the spatial contrast sensitivity function measured behaviorally in primates differs from that of retinal ganglion cells, particularly at low spatial frequencies. The paper argues that eye movements and the temporal sensitivity of ganglion cells account for this difference.</p><p>The paper has improved in revision. In particular, I found the Introduction more compelling, and the connection of the spatial ganglion cell models to past work is much less confusing with Figure 1 fixed. An issue that became clearer in the revised version of the paper is that the temporal model for the ganglion cells needs to be described more thoroughly. This and some smaller points follow.</p><p>The crux of the paper is how the dynamics of eye movements make nominally static spatial inputs dynamic, and this shifts static inputs into a temporal region where the ganglion cells are more responsive. The ganglion cell model in Equation 4 is taken straight from prior measurements, and hence is well supported in the literature (see suggestion below about including relevant parameters). However, this model does not predict a complete lack of response at a temporal frequency of 0 Hz, as assumed in the paper. There are several issues with how this is treated in the paper. First, the temporal model is central to the paper, and should not be relegated entirely to the Materials and methods (one suggestion would be to add a figure between the current Figure 2 and 3 showing the temporal response of the ganglion cell model). Second, is there experimental evidence that static components of the stimulus do not modulate the ganglion cell responses? This assumption should be clarified earlier (in reference to Figure 3) and needs to be justified, especially as it introduces an abrupt discontinuity in the ganglion cell model between 0 and nonzero temporal frequencies. Related to this point, the Robson measurements shown in Figure 4 show a marked attenuation of the CSF at low spatial frequencies for stimuli modulated at 1 Hz – such that the 1 Hz CSF is not very different from that shown for static gratings by DeValois. This suggests that the static/dynamic separation is not completely correct. Third, temporal sensitivity measured behaviorally depends strongly on spatial frequency (e.g. see Robson paper). Shouldn't this affect the argument presented in the paper – i.e. that gratings of different spatial frequencies are subject to quite different temporal filtering apparently? Some discussion of this is needed.</p><p>Unless the lack of ganglion cell responses to static images can be justified based on past experiments, the paper needs to be much more careful in asserting that known ganglion cell models can account for the discrepancy between CSFs measured behaviorally and in ganglion cells. Statements to this effect are made in many places in the paper – starting in the Abstract, Results, seventh paragraph, Discussion, fourth paragraph, etc.</p><p><italic>Reviewer #2:</italic> </p><p>The authors have thoroughly revised the paper and, to my mind, have satisfied the reviewers' concerns and questions. The manuscript is much clearer and is now suitable for publication in <italic>eLife</italic>.</p><p>One small point that may further improve the clarity of the presentation:</p><p>In Figure 4 and Figure 4—figure supplement 1 results are presented linking model predictions to CSFs measured during the presentation of temporally modulated gratings. From the Results and Discussion, it's clear that the effects of drift are more apparent at low temporal frequency. It would be useful to see an array of curves from the model without drift, pinpointing the transition around a few Hz where transients from the stimulus override the effects of eye movements. At the very least, it would be useful to label the Figure 4—figure supplement 1 model lines with &quot;drift&quot;.</p><p><italic>Reviewer #3:</italic> </p><p>I thought the original submission was interesting and excellent. In the revised manuscript, the authors have done a thorough job of responding to both my comments and those of the other reviewers.</p></body></sub-article><sub-article article-type="reply" id="SA2"><front-stub><article-id pub-id-type="doi">10.7554/eLife.40924.023</article-id><title-group><article-title>Author response</article-title></title-group></front-stub><body><p>[Editors’ note: the author responses to the first round of peer review follow.]</p><disp-quote content-type="editor-comment"><p>All three reviewers agreed that the work was of broad interest. We also agreed that several issues needed to be strengthened before considering the paper further. These and several other issues are detailed in the individual reviews. The two most pressing issues follow:</p><p>1) Recent work from some of the same authors has deepened understanding of the relation between FEM and neural coding. The relation between the present work and this past work is not as clear as it needs to be in the Introduction, and as a result the advance that the present work represents is difficult to appreciate immediately.</p></disp-quote><p>We have carefully revised Abstract, Introduction, and Discussion to make sure that the novel contributions of this study are clear. A detailed reply to this point is provided in our letter to reviewer 1, who raised this issue (see section “Overlap with previous work”). In brief, whereas our previous work focused on how eye movements affect visual input signals (i.e., that they result in a whitening of the input), here we combine measurements of eye movements with models of retinal ganglion cell responses to bridge the gap between neuronal mechanisms and psychophysics. We show that consideration of the influences of oculomotor transients on retinal responses provides a unifying account of a large range of experimental findings on human visual sensitivity. As we now better explain in the manuscript, this finding carries important implications.</p><disp-quote content-type="editor-comment"><p>2) At the heart of the paper is the discrepancy between physiological and psychophysical CSFs. But the ganglion cell examples in the first figure appear not to accurately reflect ganglion cell behavior since they do not include points at low frequencies (with instead a horizontal line from the lowest spatial frequency point plotted). Most ganglion cell measurements show some low frequency roll-off. A thorough justification of the properties used to represent measured ganglion cell CSFs is needed.</p></disp-quote><p>We apologize for this issue. The low-frequency properties of RGCs were incorrectly displayed in the original Figure 1A, as we had inadvertently plotted the Fourier transform of a 1D section of the receptive field, rather than a section of the 2D Fourier Transform. This led to the lack of a roll-off in the receptive field profile, which triggered the reviewers’ question. When correctly plotted, we find the standard roll-off in responses reported by many studies (see section on “M and P models”, in our reply to reviewer 1). We corrected this error in the resubmitted manuscript and now emphasize that the plots are not based on an extrapolation. We have also added additional material, including new Figure 1—figure supplement 1, to support the point that this response attenuation in physiological sensitivity falls far short of what is needed to account for psychophysical measurements of contrast sensitivity, unless eye movements are explicitly taken into account.</p><disp-quote content-type="editor-comment"><p>Reviewer #1:</p><p>This paper describes the interaction between eye movements and spatial coding. The paper starts by describing a discrepancy between spatial contrast sensitivity as measured behaviorally and as measured in responses of retinal or geniculate cells. It then proposes that this discrepancy originates because the neural recordings were made in the absence of eye movements, and that the discrepancy can be resolved when eye movements are taken into account. The case for the importance of eye movements, made here and in previous work from some of the same authors, is compelling. There are several issues with the present paper, however, that limit my enthusiasm:</p><p>1) M and P cell models. The literature contains numerous measurements of M and P cell spatial contrast sensitivity. From a scan of these papers (e.g. Derrington and Lennie, 1984; Kaplan and Shapley, 1982), measured spatial contrast sensitivity curves for both M and P cells fall, sometimes sharply, at low spatial frequencies. This fall is not evident in the responses depicted in Figure 1. Even the Cronor and Kaplan (1995) paper cited as the basis of Figure 1 shows a clear falloff at low spatial frequencies, and describes properties of the associated surround (related, the Benardete and Kaplan, 1997 reference in the text is about M sequences and temporal properties, so not immediately clear how it is relevant).</p></disp-quote><p>As mentioned above, we inadvertently plotted the 1D Fourier Transform of a section of the receptive field, rather than a section of the 2D Fourier Transform. This made the curves deviate from the receptive fields that were actually used in the simulations and appear considerably flatter at low spatial frequencies. When properly plotted (as in the revised Figure 1A), the expected low-frequency attenuation is seen. Crucially, as we show in the main text and Figure 1—figure supplement 1, this attenuation is not nearly enough to account for psychophysical CSFs. We apologize for this error and the confusion that it generated.</p><disp-quote content-type="editor-comment"><p>I am not clear on why the red curves in Figure 1 should be extrapolated from their peak to a 0 spatial frequency asymptote; this extrapolation appears to be inconsistent with most experimental results.</p></disp-quote><p>We now clarify that these are not extrapolations; they are the values determined by the receptive fields models measured by Croner and Kaplan (1995). As we now mention in the text, these curves were determined by the difference-of-Gaussian fits of these authors, based on measurements at spatial frequencies down to 0.07 cycles/deg, which goes beyond the range plotted. We have modified both the legend and the caption to avoid possible misunderstandings.</p><disp-quote content-type="editor-comment"><p>More generally, I think it is critical that the paper contains a thorough summary of the measured M and P properties across studies, and a clear justification of the M and P models used. Figure 1 presently undermines confidence in the central motivation for the paper.</p></disp-quote><p>We used the models of retinal ganglion cells (RGCs) reported by Croner and Kaplan (1995) because this study provides one of the most thorough investigations of receptive fields parameters that we could find in the literature. Unlike the few “typical” receptive fields reported by other articles, this study contains detailed lists of model parameters estimated over sizeable neuronal populations.</p><p>The degree of roll-off at low spatial frequencies reported by Croner and Kaplan is very similar to that found by other studies in macaques. See, for example, Figure 9 in Kaplan and Shapley, 1982, Figure 6 in Hicks et al., 1983, Figure 3 in Derrington and Lennie, 1984. These studies did not report parameters that we could use for modeling cell responses, except for Derrington and Lennie, who reported the spatial receptive fields’ parameters of the six P cells their Figure 3 (Table 1 in Derrington and Lennie, 1984). We have now included in the manuscript also the spatial sensitivity estimated from these parameters, which is very similar to those obtained with the data from Croner and Kaplan (Figure 1—figure supplement 1B in the resubmitted manuscript). Crucially, although the response attenuation exhibited by neurons in the low spatial frequency range is in the same direction of the attenuation in contrast sensitivity measured in humans, it falls far short of accounting for the attenuation in psychophysically-measured CSFs. In addition to the difference in the amount of attenuation, there is also a difference in the shape of the curves – a leveling-off for physiological sensitivities, compared to psychophysical measurements. These elements are clearly visible in all the figures listed above and in the new data in Figure 1—figure supplement 1.</p><p>Following the reviewer’s comments, we revised the Introduction to make clear that the deviation between neural and psychophysical measurements requires additional mechanisms. As we now discuss in the first paragraph of the Results, the only way in which Croner and Kaplan’s models could be modified to match contrast sensitivity functions is by doubling the ratio between the area of the center and surround – from the measured 0.5-0.6 values to close to 1. That is, receptive fields with highly unrealistic characteristics would be necessary to match behavioral functions. We have added a figure (Figure 1—figure supplement 1) to explain this point. Since the effect in our model originates from the redistribution of power resulting from eye movements, rather than the specific shape of the spatial receptive field of modeled neurons, our results are instead very robust.</p><p><italic>“related, the Benardete and Kaplan, 1997 reference in the text is about M sequences and temporal properties, so not immediately clear how it is relevant.”</italic></p><p>We thank the reviewer for pointing out this issue. The relevant article here is Croner and Kaplan, (1995). We corrected the reference in the revised manuscript.</p><disp-quote content-type="editor-comment"><p>2) Overlap with previous work. The content of Figures 1 and 2 is a review of previous work. Of particular importance, previous work from some of the same authors has established that eye movements decrease responses to low spatial frequencies in natural images. I am concerned, given that, about the intellectual advance of the present paper.</p></disp-quote><p>We extensively modified both the Introduction and the Discussion to clarify the significance of the present study and better explain how it goes beyond our previous work. In brief, our previous studies focused on the consequences of eye movements for visual input signals, while here, we build on these previous results to bridge between neuronal mechanisms and psychophysics. We show that standard models of retinal neurons <italic>quantitatively</italic> account for the way human contrast sensitivity depends on both spatial and temporal frequency, <italic>but only</italic> when one takes into account the temporal sensitivity of ganglion cells and their interaction with oculomotor luminance modulations. These results challenge widely accepted hypotheses about retinal functions (Atick and Redlich, 1992), which rely on the assumption that spatial filtering is sufficient to account for the shape of the CSF, and show that the proposal that space is encoded via oculomotor transients provides a unifying account of a large range of experimental findings on human visual sensitivity. As we describe in the revised manuscript, these conclusions have important consequences at the neural, perceptual, and clinical levels (Discussion).</p><disp-quote content-type="editor-comment"><p>Specifically, I think the paper would benefit from more experimental tests of the proposal. For example, are there measurements of spatial contrast sensitivity in awake behaving monkeys (i.e. with eye movements)? Recognizing that eye movements cannot be fully suppressed, can they still be manipulated to test the proposal (e.g. can they be increased)? Are there differences across eccentricity that could be exploited to provide additional tests?</p></disp-quote><p>While our framework makes novel predictions, we think that including further experimental tests would not improve the focus of the manuscript, as our goal here is to show that there is a logical explanation for a gap between well-established sets of measurements across many labs. However, we fully agree with the reviewer that experiments with controlled retinal image motion at selected eccentricities are highly interesting, and we have been working in this direction. We recently reported preliminary results consistent with the predictions of this work at the recent annual meeting of the Vision Sciences Society (Intoy et al., 2018). Given the reviewer’s comment, we expanded the Discussion to mention the improvements in word and object recognition reported in patients with central visual loss, when images or text are jittered or scrolled (Gustafsson and Inde, 2004; Watson et al., 2012; Harvey and Walker, 2014). These results are consistent with our prediction that a larger fixational instability should enhance sensitivity at low spatial frequencies, because of larger power available in this range (Figure 5A).</p><p>Finally, contrast sensitivity measurements have been performed in awake behaving monkeys (De Valois et al., 1974), and are included in Figure 1A, so that the reader can directly compare neurophysiological and behavioral measurements in the same species. These measurements are very similar to those reported in humans (also shown in the same figure for comparison purposes).</p><disp-quote content-type="editor-comment"><p>Reviewer #2:</p><p>[…] Overall, this is an expertly conducted combination of computational modeling and eye movement recording that provides an elegant solution to a long-standing problem in vision science. My comments are aimed mainly at clarifying the presentation.</p><p>The paper refers to &quot;fixational eye movements&quot; or &quot;FEMs&quot; throughout, but what is meant by this is the slow drift component of fixational eye movements, and not microsaccades or oscillatory movements. A few points. First, the paper is reasonably clear on this point, but not completely and not everywhere. For example, the casual reader who only looks at the Abstract and skims the details (including the Results where the focus on drift is pointed out) might conclude that this applies to microsaccades, since they are the best-known component of FEMs. Is there a reason to avoid using the more specific term &quot;ocular drift&quot; rather than &quot;FEMs&quot; throughout, or at least, more often?</p></disp-quote><p>The only reason for using “fixational eye movements” was to adopt a terminology with which readers may be more familiar. But we fully agree with the reviewer that this may lead to ambiguity, and in the revised manuscript we replaced this term with “fixational drift” (or, in many cases, simply “drift”) both in the text and figures.</p><disp-quote content-type="editor-comment"><p>Second, what is the impact of microsaccades? Would these also be expected to affect the CSF or is the scale of their temporal modulation too high to affect responses? This point should be clarified. Third, if ocular drift and microsaccades have distinguishable effects on CSF, then the authors should be especially careful with the use of the term &quot;FEMs&quot;, especially in the Discussion, where it seems that the conclusions based on ocular drift appear to be generalized to all types of fixational eye movements.</p></disp-quote><p>This manuscript specifically focuses on eye drift not only because its consideration is by itself sufficient to account for experimental data, but also because humans tend to suppress microsaccades during contrast sensitivity measurements (see Mostofi et al., 2016). But we agree, microsaccades are interesting and important, and we now comment on them, as summarized below.</p><p>Briefly, microsaccades and, in general, saccades redistribute the spatiotemporal power of the retinal stimulus in a highly different manner than ocular drift, providing significantly more temporal power at low spatial frequencies. This difference leads to the prediction that microsaccades and saccades should enhance visual sensitivity at low spatial frequencies. This prediction has been recently confirmed for larger saccades (see Boi et al., 2017), but not for saccades smaller than 1 degree (Mostofi et al., 2016). A possibility, discussed in Mostofi et al., 2016 is that perhaps for microsaccades, the beneficial consequences of luminance transients and the negative consequences of saccadic suppression (a reduction in sensitivity before and during saccade) may more evenly counterbalance each other. In the resubmitted manuscript, we now comment on the possible function of microsaccades and how their input reformatting differs from drift in the Discussion (fifth paragraph).</p><disp-quote content-type="editor-comment"><p>In several places – starting with the title – the manuscript implies that there is an active strategy behind these effects of FEMs, rather than it being an incidental effect. To me, &quot;active strategy&quot; implies some reliable relationship between the circumstance and the subject's behavior. For example, the needle-threading task shows that microsaccades appear to be generated based on some sort of active strategy. For ocular drift, it is not clear that such a relationship has been established. Do you have some basis of this claim, or is it simply a speculation? If it is a speculation, the text should be written more conservatively to match.</p></disp-quote><p>Our use of the term “active” was simply intended to convey the notion that contrast sensitivity is not merely the outcome of sensory processes, but it also includes oculomotor contributions. To avoid ambiguity, we changed the title by replacing the word “active” with “oculomotor” and revised the text similarly. However, there is some evidence that humans do in fact actively control the overall amount of drift, and we now comment on this in the Discussion (eighth paragraph) in the context of the predictions of our study.</p><disp-quote content-type="editor-comment"><p>Another plausible explanation for why the behavioral CSF does not match the properties of the retinal output is that some part of the rest of the visual system is responsible. Is there a basis for excluding this possibility?</p></disp-quote><p>This is a reasonable possibility that we cannot exclude; we added a comment about this in the fourth paragraph of the Discussion. However, while one might expect contributions from multiple stages of the visual system, our results show that retinal sensitivity and fixational drift suffice to account for the CSF over a broad spatiotemporal range, without a further downstream reshaping. This is a further reason why we think our results are significant, as we also now comment.</p><disp-quote content-type="editor-comment"><p>Reviewer #3:</p><p>This paper explores how non-separable spatio-temporal frequency tuning of M and P cells combines with measured fixational eye movements to account for observed behaviorally measured visual contrast sensitivity. A minimal model agrees well with a range of experimental data (free viewing of gratings at different temporal frequencies as well as retinal stabilization experiments) and suggests that eye movements have been optimized for neuronal contrast sensitivity curves (this work) as well as the content of natural scenes (previous work from the same groups). Experimental tests are suggested, particularly for retina-in-a-dish style experiments, where movements typical of FEMs are rarely added to visual stimuli. Experiments are also suggested for human subjects and for some clinical applications.</p><p>1) The paper is clearly presented and the work is thorough and interesting, but there should be more emphasis in the Introduction on why it's so important to understand the discrepancies between neuronal and behavioral CSFs for stationary stimuli. This could be addressed with a bit of text that previews some of the Discussion points about the neural coding and potential clinical applications of these findings.</p></disp-quote><p>We rewrote large sections of the Introduction to better explain the rationale for our work. As suggested by the reviewer, we now start by reviewing the relation between the shape of the CSF and theories of efficient encoding and mention that an explanation of contrast sensitivity in humans has important conceptual consequences and potential clinical implications. While the discrepancies fundamentally come down to quantitative measurements, there are two main qualitative points about function: whether the physiologically-measured low-frequency attenuation in neural responses accounts for spatial decorrelation of natural images (as theorized by Atick and Redlich), and whether the physiologically-measured spatiotemporal properties of ganglion cell receptive fields account for the spatiotemporal inseparability present in the human CSF. In both cases, we show that the effects of FEMs – and not just neuronal filtering characteristics – are critical. The Introduction section has been modified extensively to explain these points, see the third and seventh paragraphs.</p><disp-quote content-type="editor-comment"><p>2) Some recap of existing retinal recordings with FEM-like perturbations (e.g. Greschner et al., 2002) should be added to the Discussion.</p></disp-quote><p>We expanded discussion of previous physiological studies in which stimuli included temporal modulations like those resulting from fixational eye movements. These studies, most of them performed in vitro, provide support to our proposal that FEMs are an integral component of the retinal neural code. The relevant text is in the seventh paragraph of the Discussion.</p><disp-quote content-type="editor-comment"><p>3) Figure 1A – no data points are apparent below about 2Hz for the P and M cells, right around where the neuronal and behavioral CSFs diverge. It would be nice to include some data points there, perhaps from other studies. If data points do exist at 0Hz, they should be made more apparent.</p></disp-quote><p>If we understand correctly, the reviewer is referring to 2cpd, not 2Hz, as this is what was plotted on the abscissa of Figure 1A. As mentioned above, this figure was problematic in several respects, all of which have now been fixed. Specifically, the physiological data are not extrapolations; they are the receptive fields of retinal ganglion cells given by standard difference of Gaussians models, as measured by Croner and Kaplan (1995). The symbols previously on these curves were simply markers used to distinguish the curves. We can see how they could be misinterpreted as data points, so we now distinguish the curves by line styles. The parameters for these models were experimentally estimated by Croner and Kaplan by presenting gratings at different spatial frequencies, with a minimum of 0.07 cpd (Croner and Kaplan, 1995), which extends below the range plotted.</p><p>[Editors' note: the author responses to the re-review follow.]</p><disp-quote content-type="editor-comment"><p>The revisions have improved the paper substantially. There is one outstanding point remaining about the ganglion cell model (see reviews for details). In consultation all of the reviewers agreed this was important to resolve.</p><p>Reviewer #1:</p><p>This is a revision of a paper about the relationship between fixational eye movements and spatial contrast sensitivity. The paper centers around the observation that the spatial contrast sensitivity function measured behaviorally in primates differs from that of retinal ganglion cells, particularly at low spatial frequencies. The paper argues that eye movements and the temporal sensitivity of ganglion cells account for this difference.</p><p>The paper has improved in revision. In particular, I found the Introduction more compelling, and the connection of the spatial ganglion cell models to past work is much less confusing with Figure 1 fixed. An issue that became clearer in the revised version of the paper is that the temporal model for the ganglion cells needs to be described more thoroughly. This and some smaller points follow.</p><p>The crux of the paper is how the dynamics of eye movements make nominally static spatial inputs dynamic, and this shifts static inputs into a temporal region where the ganglion cells are more responsive. The ganglion cell model in Equation 4 is taken straight from prior measurements, and hence is well supported in the literature (see suggestion below about including relevant parameters). However, this model does not predict a complete lack of response at a temporal frequency of 0 Hz, as assumed in the paper.</p></disp-quote><p>We think we see where some of the difficulties have arisen. It is impossible to measure responses that are truly at 0 Hz, as it would require an infinitely long experiment to do so – and this holds not only for physiological measurements, but also for psychophysical ones. As a practical matter, the lowest frequency measurable is comparable to the reciprocal of the duration of a trial (i.e., 0.2 or 0.3 Hz); any attempt to infer behavior at lower frequencies would be confounded by the visual input on adjacent trials (or between trials). With this in mind, we had intended our statements about insensitivity to 0 Hz as shorthand for the more legalistic, “negligible sensitivity below the frequencies at which sensitivity can practically be measured.” As explained in detail below, this hypothesis is well justified from the data available in the literature, and our results are robust to the specifics of how exactly this hypothesis is incorporated into the neural models. We now make our point of view explicit in the paper and better explain how the model relates to physiological data at low temporal frequencies.</p><disp-quote content-type="editor-comment"><p>There are several issues with how this is treated in the paper. First, the temporal model is central to the paper, and should not be relegated entirely to the Materials and methods (one suggestion would be to add a figure between the current Figure 2 and 3 showing the temporal response of the ganglion cell model).</p></disp-quote><p>We fully agree with the reviewer and added a panel in Figure 2. This new panel (Figure 2E) shows the temporal profiles of both M and P cells. We also provide two new tables (Table 1 and 2), in which we report the values of the parameters used to model both spatial (Table 1) and temporal kernels (Table 2).</p><disp-quote content-type="editor-comment"><p>Second, is there experimental evidence that static components of the stimulus do not modulate the ganglion cell responses? This assumption should be clarified earlier (in reference to Figure 3) and needs to be justified, especially as it introduces an abrupt discontinuity in the ganglion cell model between 0 and nonzero temporal frequencies.</p></disp-quote><p>Strictly speaking, 0 Hz is a mathematical abstraction, and measuring sensitivity at this frequency is not physically possible. We therefore focus here on the broader question of sensitivity of retinal ganglion cells to low temporal frequencies, an issue that regards primarily P cells. These are the neurons with more sustained responses (Figure 2E). There is considerable experimental evidence in support of the way we handle the low-frequency limit, and we have added two paragraphs to the Discussion as well as a figure (Figure 4—figure supplement 3) to comment on this issue.</p><p>It is first important to realize that, in most neurophysiological (and psychophysical) studies, the data reported in the low temporal frequency range do not provide reliable estimation of sensitivity. This happens for multiple reasons, including: the too short duration of the experimental trial; the lack of consideration of the visual stimuli present before and after each trial, and the length of the estimated impulse response.</p><p>Typically, the transfer functions reported at low temporal frequencies are extrapolations outside of the range of measured values based on models that were not designed for this purpose (e.g., the linear cascade model (Victor, 1987) in Benardete and Kaplan, 1997 and 1999; a difference of exponential in Derrington and Lennie, 1984). Both of these models use functional forms that flatten out at very low temporal frequencies, but this flattening occurs below the frequencies at which data are acquired to fit the model. These extrapolations must be interpreted with great caution, as they merely reflect untested model assumptions. Victor’s (1987) linear cascade model estimated by Kaplan and colleagues, which we used in our study (Figure 2E), was never meant to serve as an extrapolation to frequencies outside of the range used to fit it, and this is why we don’t merely use model values down to DC. Benardete and Kaplan, for example, only measured impulse responses for ~0.5 sec, so the frequencies in the Fourier transform of the impulse response, which they used to fit the model, did not go below 2 Hz.</p><p>So, rather than use these extrapolations, we turn to the very few studies that specifically examined low temporal frequencies in retinal ganglion cells. These studies found a decline in sensitivity up to the limit that they could measure. This applies both to the more sustained X channel in the cat (Frishman et al., 1987; Victor, 1987), as well as P cells in the macaque, as shown in Figure 12A-B in Purpura et al., 1990. These studies suggest that the response attenuation takes the form of an approximately linear decrease in loglog scale. Such behavior is also expected from theoretical considerations based on the characteristics of adaptation (Thorson and Biederman-Thorson, 1974), considerations that seem to apply to the responses of cones in the retina of the macaque (Boynton and Whitten, 1970) and therefore will limit the low-frequency behavior of retinal ganglion cells.</p><p>Independently, any retinal sensitivity at frequencies ~0.3 Hz and below is likely to be virtually useless in a psychophysical experiment in trials of 2-3 sec or less – because whatever low-TF signal is present is likely to be masked by low-TF noise contributed by visual input on adjacent trials, or what the subject does between trials (e.g., looks around the lab, blinks, etc.).</p><p>Our model is highly robust to the specifics of how this reduction in sensitivity at low temporal frequencies is implemented in the simulations. In the manuscript, we simply discarded responses below a frequency threshold of 0.63Hz. But results were virtually identical when we used different frequency thresholds, or when we modeled sensitivity as a power law function of temporal frequency in the low-frequency range (as in Purpura et al., 1990, and Thorson and Biederman-Thorson, 1974, respectively).In the latter case, results are also robust with respect to the slope of the power-law function. We comment on these results in the Discussion and refer the interested reader to a new supplementary figure (Figure 4—figure supplement 3).</p><disp-quote content-type="editor-comment"><p>Related to this point, the Robson measurements shown in Figure 4 show a marked attenuation of the CSF at low spatial frequencies for stimuli modulated at 1 Hz – such that the 1 Hz CSF is not very different from that shown for static gratings by DeValois. This suggests that the static/dynamic separation is not completely correct.</p></disp-quote><p>We do not follow the reviewer here: our model correctly predicts the gradual change in spatial sensitivity shown in the Robson data, as the temporal frequency of the grating is increased (see Figure 4). There is no abrupt transition in the predicted CSF, which is consistent with the smooth transition between dynamic and static power in the retinal input (see Figure 2C).</p><p>Perhaps, confusion occurred here between the temporal modulation of the stimulus on the monitor (0 Hz for a static grating) and the temporal fluctuations in the responses of our models (where 0 Hz indicates a constant response). The two things are not equivalent: we always use model responses at all non-zero temporal frequencies – rather than just at the temporal frequency of the grating – to estimate contrast sensitivity. We think part of this confusion was generated by the previous version of Figure 2, which was giving the false impression of a dichotomy in the visual input by showing next to each other the spatial distributions of power on the retina at 0 Hz and the power integrated across all non-zero temporal frequencies (panels D and E respectively). These two curves were only meant to show that the power distributions differ at different temporal frequencies (already evident from the map in Figure 2B), not to imply the presence of a discontinuity.</p><p>In the revised manuscript, we have modified Figure 2 to eliminate possible ambiguity. We also added a supplementary figure (Figure 4—figure supplement 2) in which we show the predicted CSF at temporal modulations of the gratings not present in the Robson data in Figure 4, so to further highlight that the model well captures the smooth low-pass to band-pass transition in the CSF.</p><disp-quote content-type="editor-comment"><p>Third, temporal sensitivity measured behaviorally depends strongly on spatial frequency (e.g. see Robson paper). Shouldn't this affect the argument presented in the paper – i.e. that gratings of different spatial frequencies are subject to quite different temporal filtering apparently? Some discussion of this is needed.</p></disp-quote><p>A strength of our study is that it explains the way human temporal sensitivity varies across spatial frequencies (a space-time inseparable function) on the basis of space-time separable neural filters, like the ones of retinal ganglion cells. In other words, our model captures the full spatiotemporal pattern of contrast sensitivity by means of a linear combination of the sensitivity of P and M cells, without requiring additional temporal filters to process different ranges of spatial frequencies, as one may think. We have added a paragraph to the Discussion to comment on this point.</p><disp-quote content-type="editor-comment"><p>Unless the lack of ganglion cell responses to static images can be justified based on past experiments, the paper needs to be much more careful in asserting that known ganglion cell models can account for the discrepancy between CSFs measured behaviorally and in ganglion cells. Statements to this effect are made in many places in the paper – starting in the Abstract, Results, seventh paragraph, Discussion, fourth paragraph, etc.</p></disp-quote><p>As explained above, our model is well justified by the literature. We have carefully revised the text, including the points highlighted by the reviewer, to eliminate confusion and make sure that our claims are clear.</p><disp-quote content-type="editor-comment"><p>Reviewer #2:</p><p>The authors have thoroughly revised the paper and, to my mind, have satisfied the reviewers' concerns and questions. The manuscript is much clearer and is now suitable for publication in eLife.</p><p>One small point that may further improve the clarity of the presentation:</p><p>In Figure 4 and Figure 4—figure supplement 1, results are presented linking model predictions to CSFs measured during the presentation of temporally modulated gratings. From the Results and Discussion, it's clear that the effects of drift are more apparent at low temporal frequency. It would be useful to see an array of curves from the model without drift, pinpointing the transition around a few Hz where transients from the stimulus override the effects of eye movements. At the very least, it would be useful to label the Figure 4—figure supplement 1 model lines with &quot;drift&quot;.</p></disp-quote><p>We thank reviewer 2 for the nice comments. We added the suggested new figure (Figure 4—figure supplement 2), which plots the CSF predicted by our model at two additional intermediate temporal modulating frequencies: 2 Hz and 3 Hz. This figure shows that the transition from a band- to a low-pass behavior of the CSF occurs around 3 Hz. This result is consistent with psychophysical results; see, for example, the data from Bowker and Tulunay-Keesey, 1983, reported in their Figure 1, as we now mention in the eleventh paragraph of the Results section. We also re-labelled the curves in Figure 4—figure supplement 1 and Figure 5—figure supplement 1 with “Drift”, as suggested by the reviewer.</p></body></sub-article></article>