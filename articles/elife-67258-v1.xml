<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD with MathML3 v1.2 20190208//EN"  "JATS-archivearticle1-mathml3.dtd"><article article-type="research-article" dtd-version="1.2" xmlns:ali="http://www.niso.org/schemas/ali/1.0/" xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink"><front><journal-meta><journal-id journal-id-type="nlm-ta">elife</journal-id><journal-id journal-id-type="publisher-id">eLife</journal-id><journal-title-group><journal-title>eLife</journal-title></journal-title-group><issn pub-type="epub" publication-format="electronic">2050-084X</issn><publisher><publisher-name>eLife Sciences Publications, Ltd</publisher-name></publisher></journal-meta><article-meta><article-id pub-id-type="publisher-id">67258</article-id><article-id pub-id-type="doi">10.7554/eLife.67258</article-id><article-categories><subj-group subj-group-type="display-channel"><subject>Research Article</subject></subj-group><subj-group subj-group-type="heading"><subject>Neuroscience</subject></subj-group></article-categories><title-group><article-title>A general decoding strategy explains the relationship between behavior and correlated variability</article-title></title-group><contrib-group><contrib contrib-type="author" corresp="yes" id="author-225375"><name><surname>Ni</surname><given-names>Amy M</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">https://orcid.org/0000-0002-1746-9206</contrib-id><email>amn75@pitt.edu</email><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="aff" rid="aff2">2</xref><xref ref-type="other" rid="fund1"/><xref ref-type="other" rid="fund2"/><xref ref-type="fn" rid="con1"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" id="author-166301"><name><surname>Huang</surname><given-names>Chengcheng</given-names></name><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="aff" rid="aff2">2</xref><xref ref-type="aff" rid="aff3">3</xref><xref ref-type="other" rid="fund2"/><xref ref-type="other" rid="fund3"/><xref ref-type="fn" rid="con2"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" id="author-199771"><name><surname>Doiron</surname><given-names>Brent</given-names></name><xref ref-type="aff" rid="aff2">2</xref><xref ref-type="aff" rid="aff3">3</xref><xref ref-type="other" rid="fund2"/><xref ref-type="other" rid="fund4"/><xref ref-type="other" rid="fund5"/><xref ref-type="other" rid="fund6"/><xref ref-type="fn" rid="con3"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" id="author-12185"><name><surname>Cohen</surname><given-names>Marlene R</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">https://orcid.org/0000-0001-8583-4300</contrib-id><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="aff" rid="aff2">2</xref><xref ref-type="other" rid="fund2"/><xref ref-type="other" rid="fund7"/><xref ref-type="other" rid="fund8"/><xref ref-type="other" rid="fund9"/><xref ref-type="other" rid="fund10"/><xref ref-type="other" rid="fund11"/><xref ref-type="other" rid="fund12"/><xref ref-type="other" rid="fund13"/><xref ref-type="fn" rid="con4"/><xref ref-type="fn" rid="conf1"/></contrib><aff id="aff1"><label>1</label><institution-wrap><institution-id institution-id-type="ror">https://ror.org/01an3r305</institution-id><institution>Department of Neuroscience,University of Pittsburgh</institution></institution-wrap><addr-line><named-content content-type="city">Pittsburgh</named-content></addr-line><country>United States</country></aff><aff id="aff2"><label>2</label><institution-wrap><institution-id institution-id-type="ror">https://ror.org/00jfeg660</institution-id><institution>Center for the Neural Basis of Cognition</institution></institution-wrap><addr-line><named-content content-type="city">Pittsburgh</named-content></addr-line><country>United States</country></aff><aff id="aff3"><label>3</label><institution-wrap><institution-id institution-id-type="ror">https://ror.org/01an3r305</institution-id><institution>Department of Mathematics, University of Pittsburgh</institution></institution-wrap><addr-line><named-content content-type="city">Pittsburgh</named-content></addr-line><country>United States</country></aff></contrib-group><contrib-group content-type="section"><contrib contrib-type="editor"><name><surname>Ostojic</surname><given-names>Srdjan</given-names></name><role>Reviewing Editor</role><aff><institution-wrap><institution-id institution-id-type="ror">https://ror.org/05a0dhs15</institution-id><institution>Ecole Normale Superieure Paris</institution></institution-wrap><country>France</country></aff></contrib><contrib contrib-type="senior_editor"><name><surname>Moore</surname><given-names>Tirin</given-names></name><role>Senior Editor</role><aff><institution-wrap><institution-id institution-id-type="ror">https://ror.org/00f54p054</institution-id><institution>Stanford University</institution></institution-wrap><country>United States</country></aff></contrib></contrib-group><pub-date date-type="publication" publication-format="electronic"><day>06</day><month>06</month><year>2022</year></pub-date><pub-date pub-type="collection"><year>2022</year></pub-date><volume>11</volume><elocation-id>e67258</elocation-id><history><date date-type="received" iso-8601-date="2021-02-05"><day>05</day><month>02</month><year>2021</year></date><date date-type="accepted" iso-8601-date="2022-05-11"><day>11</day><month>05</month><year>2022</year></date></history><pub-history><event><event-desc>This manuscript was published as a preprint at bioRxiv.</event-desc><date date-type="preprint" iso-8601-date="2020-10-08"><day>08</day><month>10</month><year>2020</year></date><self-uri content-type="preprint" xlink:href="https://doi.org/10.1101/2020.10.08.331850"/></event></pub-history><permissions><copyright-statement>© 2022, Ni et al</copyright-statement><copyright-year>2022</copyright-year><copyright-holder>Ni et al</copyright-holder><ali:free_to_read/><license xlink:href="http://creativecommons.org/licenses/by/4.0/"><ali:license_ref>http://creativecommons.org/licenses/by/4.0/</ali:license_ref><license-p>This article is distributed under the terms of the <ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/licenses/by/4.0/">Creative Commons Attribution License</ext-link>, which permits unrestricted use and redistribution provided that the original author and source are credited.</license-p></license></permissions><self-uri content-type="pdf" xlink:href="elife-67258-v1.pdf"/><self-uri content-type="figures-pdf" xlink:href="elife-67258-figures-v1.pdf"/><abstract><p>Improvements in perception are frequently accompanied by decreases in correlated variability in sensory cortex. This relationship is puzzling because overall changes in correlated variability should minimally affect optimal information coding. We hypothesize that this relationship arises because instead of using optimal strategies for decoding the specific stimuli at hand, observers prioritize <italic>generality</italic>: a single set of neuronal weights to decode any stimuli. We tested this using a combination of multineuron recordings in the visual cortex of behaving rhesus monkeys and a cortical circuit model. We found that general decoders optimized for broad rather than narrow sets of visual stimuli better matched the animals’ decoding strategy, and that their performance was more related to the magnitude of correlated variability. In conclusion, the inverse relationship between perceptual performance and correlated variability can be explained by observers using a general decoding strategy, capable of decoding neuronal responses to the variety of stimuli encountered in natural vision.</p></abstract><kwd-group kwd-group-type="author-keywords"><kwd>noise correlations</kwd><kwd>visual attention</kwd><kwd>neural coding</kwd><kwd>perception</kwd></kwd-group><kwd-group kwd-group-type="research-organism"><title>Research organism</title><kwd>Rhesus macaque</kwd></kwd-group><funding-group><award-group id="fund1"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/100000002</institution-id><institution>National Institutes of Health</institution></institution-wrap></funding-source><award-id>1K99NS118117-01</award-id><principal-award-recipient><name><surname>Ni</surname><given-names>Amy M</given-names></name></principal-award-recipient></award-group><award-group id="fund2"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/100000893</institution-id><institution>Simons Foundation</institution></institution-wrap></funding-source><principal-award-recipient><name><surname>Ni</surname><given-names>Amy M</given-names></name><name><surname>Huang</surname><given-names>Chengcheng</given-names></name><name><surname>Doiron</surname><given-names>Brent</given-names></name><name><surname>Cohen</surname><given-names>Marlene R</given-names></name></principal-award-recipient></award-group><award-group id="fund3"><funding-source><institution-wrap><institution>Swartz Foundation</institution></institution-wrap></funding-source><award-id>Fellowship #2017-7</award-id><principal-award-recipient><name><surname>Huang</surname><given-names>Chengcheng</given-names></name></principal-award-recipient></award-group><award-group id="fund4"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/100000002</institution-id><institution>National Institutes of Health</institution></institution-wrap></funding-source><award-id>1U19NS107613-01</award-id><principal-award-recipient><name><surname>Doiron</surname><given-names>Brent</given-names></name></principal-award-recipient></award-group><award-group id="fund5"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/100000002</institution-id><institution>National Institutes of Health</institution></institution-wrap></funding-source><award-id>R01EB026953</award-id><principal-award-recipient><name><surname>Doiron</surname><given-names>Brent</given-names></name></principal-award-recipient></award-group><award-group id="fund6"><funding-source><institution-wrap><institution>Vannevar Bush faculty fellowship</institution></institution-wrap></funding-source><award-id>N00014-18-1-2002</award-id><principal-award-recipient><name><surname>Doiron</surname><given-names>Brent</given-names></name></principal-award-recipient></award-group><award-group id="fund7"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/100000002</institution-id><institution>National Institutes of Health</institution></institution-wrap></funding-source><award-id>4R00EY020844-03</award-id><principal-award-recipient><name><surname>Cohen</surname><given-names>Marlene R</given-names></name></principal-award-recipient></award-group><award-group id="fund8"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/100000002</institution-id><institution>National Institutes of Health</institution></institution-wrap></funding-source><award-id>R01 EY022930</award-id><principal-award-recipient><name><surname>Cohen</surname><given-names>Marlene R</given-names></name></principal-award-recipient></award-group><award-group id="fund9"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/100000002</institution-id><institution>National Institutes of Health</institution></institution-wrap></funding-source><award-id>Core Grant P30 EY008098s</award-id><principal-award-recipient><name><surname>Cohen</surname><given-names>Marlene R</given-names></name></principal-award-recipient></award-group><award-group id="fund10"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/100001391</institution-id><institution>Whitehall Foundation</institution></institution-wrap></funding-source><principal-award-recipient><name><surname>Cohen</surname><given-names>Marlene R</given-names></name></principal-award-recipient></award-group><award-group id="fund11"><funding-source><institution-wrap><institution>Klingenstein-Simons Fellowship</institution></institution-wrap></funding-source><principal-award-recipient><name><surname>Cohen</surname><given-names>Marlene R</given-names></name></principal-award-recipient></award-group><award-group id="fund12"><funding-source><institution-wrap><institution>Sloan Research Fellowship</institution></institution-wrap></funding-source><principal-award-recipient><name><surname>Cohen</surname><given-names>Marlene R</given-names></name></principal-award-recipient></award-group><award-group id="fund13"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/100005270</institution-id><institution>McKnight Foundation</institution></institution-wrap></funding-source><principal-award-recipient><name><surname>Cohen</surname><given-names>Marlene R</given-names></name></principal-award-recipient></award-group><funding-statement>The funders had no role in study design, data collection and interpretation, or the decision to submit the work for publication.</funding-statement></funding-group><custom-meta-group><custom-meta specific-use="meta-only"><meta-name>Author impact statement</meta-name><meta-value>The frequently observed relationship between perceptual performance and correlated variability in sensory cortex can be explained by observers using a decoding strategy that prioritizes generality for many stimuli over precision.</meta-value></custom-meta></custom-meta-group></article-meta></front><body><sec id="s1" sec-type="intro"><title>Introduction</title><p>Many studies have demonstrated that increases in perceptual performance correspond to decreases in a very simple measure of shared variability in a population of sensory neurons: the mean correlation between the responses of a pair of neurons to repeated presentations of the same stimulus (termed spike count or noise correlations, or r<sub>SC</sub>; <xref ref-type="bibr" rid="bib8">Cohen and Kohn, 2011</xref>; <xref ref-type="bibr" rid="bib39">Nirenberg and Latham, 2003</xref>; <xref ref-type="bibr" rid="bib7">Cohen and Maunsell, 2009</xref>; <xref ref-type="bibr" rid="bib9">Cohen and Maunsell, 2011</xref>; <xref ref-type="bibr" rid="bib14">Gregoriou et al., 2014</xref>; <xref ref-type="bibr" rid="bib15">Gu et al., 2011</xref>; <xref ref-type="bibr" rid="bib17">Herrero et al., 2013</xref>; <xref ref-type="bibr" rid="bib32">Luo and Maunsell, 2015</xref>; <xref ref-type="bibr" rid="bib33">Mayo and Maunsell, 2016</xref>; <xref ref-type="bibr" rid="bib34">Mitchell et al., 2009</xref>; <xref ref-type="bibr" rid="bib36">Nandy et al., 2017</xref>; <xref ref-type="bibr" rid="bib37">Ni et al., 2018</xref>; <xref ref-type="bibr" rid="bib45">Ruff and Cohen, 2014a</xref>; <xref ref-type="bibr" rid="bib46">Ruff and Cohen, 2014b</xref>; <xref ref-type="bibr" rid="bib47">Ruff and Cohen, 2016</xref>; <xref ref-type="bibr" rid="bib49">Ruff and Cohen, 2019</xref>; <xref ref-type="bibr" rid="bib57">Yan et al., 2014</xref>; <xref ref-type="bibr" rid="bib58">Zénon and Krauzlis, 2012</xref>). We recently found that the axis in neuronal population space that explains the most mean correlated variability explains virtually all of the choice-predictive signals in visual area V4 (<xref ref-type="bibr" rid="bib37">Ni et al., 2018</xref>).</p><p>These observations comprise a paradox because changes in this simple measure should have a minimal effect on information coding. Recent theoretical work shows that neuronal population decoders that extract the maximum amount of sensory information for the specific task at hand can easily ignore mean correlated noise (<xref ref-type="bibr" rid="bib23">Kafashan et al., 2021</xref>; <xref ref-type="bibr" rid="bib26">Kanitscheider et al., 2015b</xref>; <xref ref-type="bibr" rid="bib35">Moreno-Bote et al., 2014</xref>; <xref ref-type="bibr" rid="bib42">Pitkow et al., 2015</xref>; <xref ref-type="bibr" rid="bib50">Rumyantsev et al., 2020</xref>; for review, see <xref ref-type="bibr" rid="bib29">Kohn et al., 2016</xref>). Decoders for the specific task at hand can ignore mean correlated variability because it does not corrupt the dimensions of neuronal population space that are most informative about the stimulus (<xref ref-type="bibr" rid="bib35">Moreno-Bote et al., 2014</xref>).</p><p>We propose a hypothesis that reconciles the numerous experimental observations of an inverse relationship between performance and mean correlated variability and these seemingly contradictory theoretical predictions. The theoretical predictions are predicated on the assumption that observers (and their neuronal population decoding mechanisms) use a decoding strategy that maximizes the amount of information extracted for the specific task at hand. We hypothesize that instead, observers use a <italic>general</italic> decoding strategy: one set of neuronal population decoding weights to extract sensory information about any visual stimuli.</p><p>Stimuli in the visual environment vary in many task-irrelevant as well as -relevant features. Our idea is that the dimensions of the neural code that are optimal for the general decoding of any stimuli might be very similar to the axes that account for the mean correlated variability, because mean correlated variability is well known to depend on all of the stimulus features for which the population of neurons is tuned (<xref ref-type="bibr" rid="bib8">Cohen and Kohn, 2011</xref>). If observers used this kind of general decoding strategy, their perceptual performance might be inextricably linked to mean correlated variability (<xref ref-type="bibr" rid="bib48">Ruff et al., 2018</xref>). This decoding mechanism would explain the much-observed relationship between behavior and correlated variability.</p><p>Here, we report the results of an initial test of this overarching hypothesis, based on a single stimulus dimension. We used a simple, well-studied behavioral task to test whether a more-general decoder (optimized for a broader range of stimulus values along a single dimension) better explained the relationship between behavior and mean correlated variability than a more-specific decoder (optimized for a narrower range of stimulus values along a single dimension). Specifically, we used a well-studied orientation change detection task (<xref ref-type="bibr" rid="bib7">Cohen and Maunsell, 2009</xref>) to test whether a general decoder for the full range of stimulus orientations better explained the relationship between behavior and mean correlated variability than a specific decoder for the orientation change presented in the behavioral trial at hand.</p><p>This test based on a single stimulus dimension is an important initial test of the general decoder hypothesis because many of the studies that found that performance increased when mean correlated variability decreased used a change detection task (<xref ref-type="bibr" rid="bib7">Cohen and Maunsell, 2009</xref>; <xref ref-type="bibr" rid="bib9">Cohen and Maunsell, 2011</xref>; <xref ref-type="bibr" rid="bib17">Herrero et al., 2013</xref>; <xref ref-type="bibr" rid="bib32">Luo and Maunsell, 2015</xref>; <xref ref-type="bibr" rid="bib33">Mayo and Maunsell, 2016</xref>; <xref ref-type="bibr" rid="bib36">Nandy et al., 2017</xref>; <xref ref-type="bibr" rid="bib37">Ni et al., 2018</xref>; <xref ref-type="bibr" rid="bib47">Ruff and Cohen, 2016</xref>; <xref ref-type="bibr" rid="bib49">Ruff and Cohen, 2019</xref>; <xref ref-type="bibr" rid="bib57">Yan et al., 2014</xref>; <xref ref-type="bibr" rid="bib58">Zénon and Krauzlis, 2012</xref>). This task has been studied frequently because it is a simple laboratory version of a real-life scenario: the observer must report that a stimulus changed, regardless of the magnitude of the change.</p><p>For this test, we used a combination of experiments and theory. We used multineuron recordings in two rhesus monkeys to directly compare the effects of modulating visual attention on the mean correlated variability of the neuronal population to the effects of attention on the monkeys’ neuronal decoding strategy. We then used a cortical circuit model to compare the effects of attention on the monkeys’ decoding strategy to the effects of attention on an ideal general decoder for all orientations.</p><p>Our combined electrophysiological and theoretical results support our general decoder hypothesis. They demonstrate that using a single set of neuronal weights to decode sensory neuron population responses to any stimulus change can explain the frequently observed relationship between performance and mean correlated variability.</p></sec><sec id="s2" sec-type="results"><title>Results</title><sec id="s2-1"><title>A behavioral framework for studying the general decoder hypothesis</title><p>We designed a behavioral task for two rhesus monkeys that allowed us to test the hypothesis that the relationship between perceptual performance and correlated variability is better explained by a more-general decoding strategy. This test required two main components. First, we used an orientation change detection task with multiple potential orientation changes (<xref ref-type="fig" rid="fig1">Figure 1A</xref>; different aspects of these data were presented previously, <xref ref-type="bibr" rid="bib37">Ni et al., 2018</xref>). This allowed us to analyze decoders optimized for narrower versus broader ranges of stimulus orientations. Two Gabor stimuli of the same orientation flashed on and off until, at a random time, the orientation of one of the stimuli changed. The changed orientation was randomly selected from five options (<xref ref-type="fig" rid="fig1">Figure 1B</xref>). The monkey could not predict which orientation change was to be detected on any given trial and was rewarded for responding to any orientation change.</p><fig id="fig1" position="float"><label>Figure 1.</label><caption><title>Electrophysiological data collection and decoders.</title><p>(<bold>A</bold>) Orientation change detection task with cued attention. After the monkey fixated the central spot, two Gabor stimuli synchronously flashed on (200 ms) and off (randomized 200–400 ms period) at the starting orientation until, at a random time, the orientation of one stimulus changed. To manipulate attention, the monkey was cued in blocks of 125 trials as to which of the two stimuli would change in 80% of the trials in the block, with the change occurring at the uncued location in the other 20%. (<bold>B</bold>) A cued changed orientation was randomly assigned per trial from five potential orientations. An uncued changed orientation was randomly either the median (20 trials) or largest change amount (5 trials). To compare cued to uncued changes, median orientation change trials were analyzed. (<bold>C</bold>) The activity of a neuronal population in V4 was recorded simultaneously. Plotted for Monkey 1: the location of Stimulus 2 (red circle) relative to fixation (red cross) overlapped the receptive field (RF) centers of the recorded units (black circles). A representative RF size is illustrated (dashed circle). Only orientation changes at the RF location were analyzed. Stimulus 1 was located in the opposite hemifield (gray circle). (<bold>D</bold>) Schematic of the specific decoder, a linear classifier with leave-one-out cross-validation, which was trained to best differentiate the V4 neuronal population responses to the median changed orientation from the V4 responses to the starting orientation presented immediately before it (first and second principal components [PC] shown for illustrative purposes). (<bold>E</bold>) Schematic of the monkey’s decoder, which was based on the same neuronal population responses as in (<bold>D</bold>) but was trained to best differentiate the V4 responses when the monkey made a saccade (indicating it detected an orientation change) from the V4 responses when the monkey did not choose to make a saccade.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-67258-fig1-v1.tif"/></fig><p>Second, we made a manipulation designed to create a larger dynamic range of perceptual performance. We manipulated visual attention within the task (<xref ref-type="fig" rid="fig1">Figure 1A</xref>) using a classic Posner cueing paradigm (<xref ref-type="bibr" rid="bib43">Posner, 1980</xref>). Cued trials were collected for all five change amounts and uncued trials were collected mainly for the median change amount (<xref ref-type="fig" rid="fig1">Figure 1B</xref>). Our attention analyses focused on this median change amount, for which we had both cued and uncued trials.</p><p>For each monkey, we used a chronically implanted microelectrode array to record from a population of V4 neurons while the monkey performed the behavioral task (<xref ref-type="fig" rid="fig1">Figure 1C</xref>). These electrophysiological recordings allowed us to measure the effects of attention on the mean correlated variability of the V4 population. They also allowed us to measure the effects of attention on the performance of two linear decoders of the V4 population activity: a specific decoder (<xref ref-type="fig" rid="fig1">Figure 1D</xref>) and the monkey’s decoder (<xref ref-type="fig" rid="fig1">Figure 1E</xref>).</p><p>We tasked both decoders with differentiating the V4 neuronal population responses to the median changed orientation from the V4 responses to the starting orientation presented immediately before it. We first estimated the neuronal decoding weights that best performed this specific task (<xref ref-type="fig" rid="fig1">Figure 1D</xref>). Theoretical studies have found that mean correlated variability should not affect the performance of such an optimal linear decoder (<xref ref-type="bibr" rid="bib23">Kafashan et al., 2021</xref>; <xref ref-type="bibr" rid="bib26">Kanitscheider et al., 2015b</xref>; <xref ref-type="bibr" rid="bib35">Moreno-Bote et al., 2014</xref>; <xref ref-type="bibr" rid="bib42">Pitkow et al., 2015</xref>; <xref ref-type="bibr" rid="bib50">Rumyantsev et al., 2020</xref>; reviewed by <xref ref-type="bibr" rid="bib29">Kohn et al., 2016</xref>).</p><p>To compare the monkey’s strategy to the performance of the specific decoder, we estimated the neuronal decoding weights that best predicted the monkey’s pattern of choices on this same task (<xref ref-type="fig" rid="fig1">Figure 1E</xref>). This allowed us to directly compare the performance of the monkey’s decoder to that of the specific decoder on the same task. Using leave-one-out cross-validation, we calculated the ability of each decoder to correctly identify whether each left-out orientation was the median changed orientation or the starting orientation.</p></sec><sec id="s2-2"><title>A mechanistic circuit model to test the general decoder hypothesis</title><p>Here, we describe a circuit model that we designed to allow us to compare the specific and monkey’s decoders from our electrophysiological dataset to modeled ideal specific and general decoders. The primary benefit of our model is that it can take actual images as inputs and produce neuronal tuning and covariance that are compatible with each other because of constraints from the simulated network that processed the inputs (<xref ref-type="bibr" rid="bib19">Huang et al., 2019</xref>). Parametric models in which tuning and covariance can be manipulated independently would not provide such constraints. In our model, the mean correlated variability of the population activity is restricted to very few dimensions, matching experimentally recorded data from visual cortex demonstrating that mean correlated variability occupies a low-dimensional subset of the full neuronal population space (<xref ref-type="bibr" rid="bib12">Ecker et al., 2014</xref>; <xref ref-type="bibr" rid="bib13">Goris et al., 2014</xref>; <xref ref-type="bibr" rid="bib19">Huang et al., 2019</xref>; <xref ref-type="bibr" rid="bib24">Kanashiro et al., 2017</xref>; <xref ref-type="bibr" rid="bib30">Lin et al., 2015</xref>; <xref ref-type="bibr" rid="bib44">Rabinowitz et al., 2015</xref>; <xref ref-type="bibr" rid="bib52">Semedo et al., 2019</xref>; <xref ref-type="bibr" rid="bib56">Williamson et al., 2016</xref>).</p><p>For our electrophysiological dataset, the behavioral task was designed to allow us to compare the specific and monkey’s decoders for an attention task with a range of orientation change amounts. To collect the necessary number of repetitions of behavioral trials per stimulus condition (with the limited total number of behavioral trials collected per day), we limited the number of different orientation change amounts to five (<xref ref-type="fig" rid="fig1">Figure 1B</xref>) and focused our uncued trials on the median orientation change. Our modeled dataset is critical to addressing our general decoder hypothesis as it allows us to step beyond the restraints of physiological data to model multiple attentional modulation levels for the full range of stimulus orientations. While the main purpose of the electrophysiological data was to analyze the monkey’s decoder, which could only be determined using the neuronal responses recorded from a behaving animal, the purpose of our modeled data is to compare the monkey’s decoder to an ideal general decoder, which can only be determined here using a model.</p><p>Our circuit model is an extension of our previously published excitatory/inhibitory cortical network model of attention (<xref ref-type="bibr" rid="bib19">Huang et al., 2019</xref>). We improved this model to allow us to calculate the network’s responses to the full range of stimulus orientations by extending the three-layer model of V1 and V4 neuronal populations (<xref ref-type="bibr" rid="bib19">Huang et al., 2019</xref>; <xref ref-type="bibr" rid="bib20">Huang et al., 2020</xref>) to mimic realistic orientation tuning and organization in the V1 layer (<xref ref-type="fig" rid="fig2">Figure 2A</xref>).</p><fig-group><fig id="fig2" position="float"><label>Figure 2.</label><caption><title>Mechanistic circuit model of attention effects.</title><p>(<bold>A</bold>) Schematic of an excitatory and inhibitory neuronal network model of attention (<xref ref-type="bibr" rid="bib19">Huang et al., 2019</xref>) that extends the three-layer, spatially ordered network to include the orientation tuning and organization of V1. The network models the hierarchical connectivity between layer 4 of V1, layers 2 and 3 of V1, and V4. In this model, attention depolarizes the inhibitory neurons in V4 and increases the feedforward projection strength from layers 2 and 3 of V1 to V4. (<bold>B, C</bold>) We mapped the <italic>n</italic>-dimensional neuronal activity of our model to a two-dimensional space (a ring). Each dot represents the neuronal activity of the simulated population on a single trial and each color represents the trials for a given orientation. These fluctuations are more elongated in the (<bold>B</bold>) unattended state than in the (<bold>C</bold>) attended state. We then calculated the effects of these attentional changes on the performance of specific and general decoders (see Materials and methods). The axes are arbitrary units. (<bold>D–F</bold>) Comparisons of the modeled versus electrophysiologically recorded effects of attention on V4 population activity. (<bold>D</bold>) Firing rates of excitatory neurons increased, (<bold>E</bold>) mean correlated variability decreased, and (<bold>F</bold>) as illustrated with the first five largest eigenvalues of the shared component of the spike count covariance matrix from the V4 neurons, attention largely reduced the eigenvalue of the first mode. Attentional state denoted by marker color for the model (yellow: most attended; green: least attended) and electrophysiological data (yellow: cued; green: uncued). For the model: 30 samplings of <italic>n</italic>=50 neurons. Monkey 1 data illustrated for the electrophysiological data: <italic>n</italic>=46 days of recorded data. SEM error bars. Also see <xref ref-type="fig" rid="fig2s1">Figure 2—figure supplement 1</xref>.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-67258-fig2-v1.tif"/></fig><fig id="fig2s1" position="float" specific-use="child-fig"><label>Figure 2—figure supplement 1.</label><caption><title>The model reproduces the relationship between noise and signal correlations that is key to the general decoder hypothesis.</title><p>(<bold>A</bold>) As previously observed in electrophysiological data (<xref ref-type="bibr" rid="bib7">Cohen and Maunsell, 2009</xref>; <xref ref-type="bibr" rid="bib8">Cohen and Kohn, 2011</xref>), we observe a strong relationship between noise and signal correlations. During additional recordings collected during most recording sessions (for Monkey 1 illustrated here, <italic>n</italic>=37 days with additional recordings), the monkey was rewarded for passively fixating the center of the monitor while Gabors with randomly interleaved orientations were flashed at the receptive field location (‘Stim 2’ location in <xref ref-type="fig" rid="fig1">Figure 1C</xref>). The presented orientations spanned the full range of stimulus orientations (12 equally spaced orientations from 0° to 330°). We calculated the signal correlation for each pair of units based on their mean responses to each of the 12 orientations. We define the noise correlation for each pair of units as the average noise correlation for each orientation. The plot depicts signal correlation as a function of noise correlation across all recording sessions, binned into eight equally sized sets of unit pairs. Error bars represent SEM. (<bold>B</bold>) The model reproduces the relationship between noise and signal correlations. Signal correlation is plotted as a function of noise correlation, binned into 20 equally sized sets of unit pairs (<italic>n</italic>=2000 neurons), for each attentional modulation strength (green: least attended; yellow: most attended). The results were averaged over 50 tested orientations. (<bold>C</bold>) The slope of the relationship between noise and signal correlations (<italic>y</italic>-axis) decreases with increasing attentional modulation (<italic>x</italic>-axis). This suggests that noise is less aligned with signal correlation with increasing attentional modulation.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-67258-fig2-figsupp1-v1.tif"/></fig></fig-group><p>This model is key to this initial test of the general decoder hypothesis because it allowed us to test an ideal general decoder that used the same set of neuronal weights to estimate the full range of orientations (see Materials and methods). Further, this specific model is key to our study because it is the only model (to our knowledge) that captures the effects of attention on correlated variability that have been frequently observed in electrophysiological data (<xref ref-type="bibr" rid="bib19">Huang et al., 2019</xref>).</p><p>As the basis for our modeled general decoder, we first mapped the <italic>n</italic>-dimensional neuronal activity of our model in response to the full range of orientations to a two-dimensional space. Because the neurons were tuned for orientation, we could map the <italic>n</italic>-dimensional population responses to a ring (<xref ref-type="fig" rid="fig2">Figure 2B, C</xref>). The orientation of correlations (the shape of each color cloud in <xref ref-type="fig" rid="fig2">Figure 2B</xref>) was not an assumed parameter, and illustrates the outcome of the correlation structure and dimensionality modeled by our data. In <xref ref-type="fig" rid="fig2">Figure 2B</xref>, we can see that the fluctuations along the radial directions are much larger than those along other directions for a given orientation. This is consistent with the low-dimensional structure of the modeled neuronal activity. In our model, the fluctuations of the neurons, mapped to the radial direction on the ring, were more elongated in the unattended state (<xref ref-type="fig" rid="fig2">Figure 2B</xref>) than in the attended state (<xref ref-type="fig" rid="fig2">Figure 2C</xref>).</p><p>Importantly, this model reproduces the correlation between noise and signal correlations (<xref ref-type="fig" rid="fig2s1">Figure 2—figure supplement 1</xref>) observed in electrophysiological data (<xref ref-type="bibr" rid="bib7">Cohen and Maunsell, 2009</xref>; <xref ref-type="bibr" rid="bib8">Cohen and Kohn, 2011</xref>). This correlation between the shared noise and the shared tuning is a key component of the general decoder hypothesis. We observed this strong relationship between noise and signal correlations in our recorded neurons (<xref ref-type="fig" rid="fig2s1">Figure 2—figure supplement 1A</xref>) as well as in our modeled data (<xref ref-type="fig" rid="fig2s1">Figure 2—figure supplement 1B</xref>). Using this model, we were able to measure the relationship between noise and signal correlations for varying strengths of attentional modulation. Consistent with the predictions of the general decoder hypothesis, attention weakened the relationship between noise and signal correlations (<xref ref-type="fig" rid="fig2s1">Figure 2—figure supplement 1C</xref>).</p><p>Next, we calculated the effect of this attentional change on the performances of modeled ideal specific and general decoders, which we will compare to our electrophysiological results in the next section. The specific decoder used optimal neuronal weights (for <italic>n</italic> neurons in the population) based on the <italic>n</italic>-dimensional discrimination of two orientations (<italic>θ</italic><sub>1</sub> and <italic>θ</italic><sub>2</sub> in <xref ref-type="fig" rid="fig2">Figure 2B</xref>). The general decoder was also tested on the discrimination of those same two orientations (<italic>θ</italic><sub>1</sub> and <italic>θ</italic><sub>2</sub> in <xref ref-type="fig" rid="fig2">Figure 2B</xref>), but the neuronal weights of the general decoder were based on the neuronal population responses to all of the orientations in the ring (see Materials and methods for details). Finally, the model more than captured our electrophysiologically recorded attentional changes in V4 firing rates (<xref ref-type="fig" rid="fig2">Figure 2D</xref>), mean correlated variability (<xref ref-type="fig" rid="fig2">Figure 2E</xref>), and covariance eigenspectrum (<xref ref-type="fig" rid="fig2">Figure 2F</xref>).</p></sec><sec id="s2-3"><title>A general decoding strategy may clarify the role of mean correlated variability</title><p>First, we analyzed whether the relationship between attention, behavior, and mean correlated variability could be explained by a specific decoding strategy. This is an important first step because theoretical studies, which do not predict a relationship between mean correlated variability and performance, typically model decision-making as based on an optimal decoding strategy that maximizes the sensory information extracted from the neuronal population activity (<xref ref-type="bibr" rid="bib23">Kafashan et al., 2021</xref>; <xref ref-type="bibr" rid="bib26">Kanitscheider et al., 2015b</xref>; <xref ref-type="bibr" rid="bib35">Moreno-Bote et al., 2014</xref>; <xref ref-type="bibr" rid="bib42">Pitkow et al., 2015</xref>; <xref ref-type="bibr" rid="bib50">Rumyantsev et al., 2020</xref>). A resolution to the apparent conflict between theoretical predictions and empirical results would be that perceptual performance is not based on a specific decoding strategy.</p><p>Indeed, we found that the effects of attention on the performance of the monkey’s decoder did not match the effects of attention on the performance of the specific decoder (<xref ref-type="fig" rid="fig3">Figure 3A</xref>). Manipulating attention affected the performance of each decoder differently: the performance of the specific decoder was little affected by attention, while that of the monkey’s decoder was strongly affected by attention.</p><fig-group><fig id="fig3" position="float"><label>Figure 3.</label><caption><title>The monkey’s decoding strategy was most closely matched by a general decoding strategy.</title><p>(<bold>A</bold>) Physiological data for Monkey 1 and Monkey 2: the effect of attention on decoder performance was larger for the monkey’s decoder than for the specific decoder. Left plots: decoder performance (<italic>y</italic>-axis; leave-one-out cross-validated proportion of trials in which the orientation was correctly identified: starting versus median changed orientation) for each neuronal population size (<italic>x</italic>-axis) is plotted for the specific (thin lines) and monkey’s (thick lines) decoders in the cued (yellow) and uncued (green) attention conditions. Right plots: the ratio of the decoder performance in the cued versus uncued conditions is plotted for each neuronal population size. SEM error bars (Monkey 1: <italic>n</italic>=46 days; Monkey 2: <italic>n</italic>=28 days). (<bold>B</bold>) Modeled data: the effect of attention on decoder performance was larger for the general decoder than for the specific decoder. Left plot: the inverse of the variance of the estimation of theta (<italic>y</italic>-axis; equivalent to linear Fisher information for the specific decoder) for each neuronal population size (<italic>x</italic>-axis) is plotted for the specific decoder (small markers; Equation 1, see Materials and methods) and for the general decoder (large markers; Equation 3, see Materials and methods) in the attended (yellow) and unattended (green) conditions. Right plot: the ratio of Fisher information in the attended versus unattended conditions is plotted for each neuronal population size. (<bold>C</bold>) Physiological data for Monkey 1 and Monkey 2: the performance of the monkey’s decoder was more related to mean correlated variability (left plots, gray lines of best fit; Monkey 1 correlation coefficient: <italic>n</italic>=86, or 44 days with two attention conditions plotted per day and two data points excluded – see Materials and methods, <italic>r</italic>=–0.38, p=5.9 × 10<sup>–4</sup>; Monkey 2: <italic>n</italic>=54, or 27 days with two attention conditions plotted per day, <italic>r</italic>=–0.30, p=0.03) than the performance of the specific decoder (right plots; Monkey 1 correlation coefficient: <italic>r</italic>=–0.07, p=0.53; Monkey 2: <italic>r</italic>=0.13, p=0.36). For both monkeys, the correlation coefficients associated with the two decoders were significantly different from each other (Williams’ procedure; Monkey 1: <italic>t</italic>=3.7, p=2.3 × 10<sup>–4</sup>; Monkey 2: <italic>t</italic>=3.2, p=1.4 × 10<sup>–3</sup>). Also see <xref ref-type="fig" rid="fig3s1">Figure 3—figure supplement 1</xref>. (<bold>D</bold>) Modeled data: the performance of the general decoder was more related to mean correlated variability (left plot) than the performance of the specific decoder (right plot; number of neurons fixed at 100 and attentional state denoted by marker color, yellow to green: most attended to least attended). (<bold>E</bold>) An example plot of the first versus second principal component (PC) of the V4 population responses to each of the six orientations presented in the session, to justify a linear decoding strategy for the more-general decoders (starting orientation illustrated in black, five changed orientations illustrated with a red-blue color gradient from smallest to largest). Though the brain may use nonlinear decoding methods, the neuronal population representations of the small range of orientations tested per day were reasonably approximated by a line; thus, linear methods were sufficient to capture decoder performance for the physiological dataset. (<bold>F</bold>) Physiological data for Monkey 1 (orange) and Monkey 2 (purple): the more general the decoder (<italic>x</italic>-axis; number of orientation changes used to determine the decoder weights, with the decoder that best differentiated the V4 responses to the starting orientation from those to one changed orientation on the far left, and the decoder that best differentiated V4 responses to the starting orientation from those to four different changed orientations on the far right), the more correlated its performance to the performance of the monkey’s decoder (<italic>y</italic>-axis; the across-days correlation between the performance of the monkey’s decoder and the performance of the decoder specified by the <italic>x</italic>-axis). Mean across all points in a column illustrated by a black horizontal line (see Materials and methods for <italic>n</italic> values). There was a significant correlation between decoder specificity level (<italic>x</italic>-axis) and the correlation with the performance of the monkey’s decoder (<italic>y</italic>-axis; correlation coefficient: <italic>r</italic>=0.25, p=0.016). (<bold>G</bold>) The more general the decoder (<italic>x</italic>-axis), the better its performance predicting the monkey’s choices on the median changed orientation trials (<italic>y</italic>-axis; the proportion of leave-one-out trials in which the decoder correctly predicted the monkey’s decision as to whether the orientation was the starting orientation or the median changed orientation). Conventions as in (<bold>F</bold>) (see Materials and methods for <italic>n</italic> values). There was a significant correlation between decoder specificity level (<italic>x</italic>-axis) and performance predicting the monkey’s choices (<italic>y</italic>-axis; correlation coefficient: <italic>r</italic>=0.44, p=0.016).</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-67258-fig3-v1.tif"/></fig><fig id="fig3s1" position="float" specific-use="child-fig"><label>Figure 3—figure supplement 1.</label><caption><title>Based on the electrophysiological data, the performance of the monkey’s decoder was more related to mean correlated variability than the performance of the specific decoder within each attention condition.</title><p>(<bold>A</bold>) Within the cued attention condition, the performance of the monkey’s decoder was more related to mean correlated variability (left plot; correlation coefficient: <italic>n</italic>=71 days, <italic>r</italic>=–0.23, p=0.058) than the performance of the specific decoder (right plot; correlation coefficient: <italic>r</italic>=0.038, p=0.75). The correlation coefficients associated with the two decoders were significantly different from each other (Williams’ procedure: <italic>t</italic>=3.8, p=1.5 × 10<sup>–4</sup>). Best fit lines plotted in gray. Data from both monkeys combined (Monkey 1 data shown in orange: <italic>n</italic>=44 days; Monkey 2 data shown in purple: <italic>n</italic>=27 days) with mean correlated variability z-scored within monkey. (<bold>B</bold>) The data within the uncued attention condition showed a similar pattern, with the performance of the monkey’s decoder more related to mean correlated variability (<italic>n</italic>=69 days, <italic>r</italic>=–0.20, p=0.14) than the performance of the specific decoder (<italic>r</italic>=0.085, p=0.51; Williams’ procedure: <italic>t</italic>=2.0, p=0.049). Conventions as in (<bold>A</bold>) (Monkey 1: <italic>n</italic>=42 days – see Materials and methods for data exclusions as in <xref ref-type="fig" rid="fig3">Figure 3C</xref>; Monkey 2: <italic>n</italic>=27 days).</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-67258-fig3-figsupp1-v1.tif"/></fig><fig id="fig3s2" position="float" specific-use="child-fig"><label>Figure 3—figure supplement 2.</label><caption><title>After shuffling trials, the performances of the modeled general and specific decoders and their relationships to the amount of correlated variability removed by the shuffling become indistinguishable.</title><p>(<bold>A</bold>) Randomly shuffling the trial order per neuron resulted in the Fisher information for the modeled general decoder increasing linearly with the log of the number of neurons (dashed lines) in both the attended (yellow) and unattended (green) conditions. Shuffling removes differential correlations (<xref ref-type="bibr" rid="bib35">Moreno-Bote et al., 2014</xref>); thus, the Fisher information based on the trial-shuffled data does not saturate. (<bold>B</bold>) The trial-shuffled data resulted in the Fisher information for the modeled specific decoder increasing linearly with the log of the number of neurons (dashed lines) as well. (<bold>C</bold>) The superposition of (<bold>A</bold>) and (<bold>B</bold>) illustrates that with shuffled data, the general decoder (large markers) and the specific decoder (small markers) behave very similarly. (<bold>D</bold>) After shuffling the trials, the performances of the general decoder (<bold>E</bold>) and of the specific decoder based on the trial-shuffled data had very similar relationships to the amount of correlated variability removed by the trial shuffling (number of neurons fixed at 100 and attentional state denoted by marker color, yellow to green: most attended to least attended).</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-67258-fig3-figsupp2-v1.tif"/></fig></fig-group><p>Second, we used our circuit model of attention to test whether a modeled ideal general decoder was a better match to the physiological monkey’s decoder than a modeled ideal specific decoder. The model allowed us to generate a large dataset with an experimentally unfeasible number of trials per stimulus orientation for a full ring of stimulus orientations, in multiple attention conditions (<xref ref-type="fig" rid="fig2">Figure 2B and C</xref>).</p><p>We found that the large effects of attention on the physiological monkey’s decoder (<xref ref-type="fig" rid="fig3">Figure 3A</xref>) were better matched by the similarly large effects of attention on the modeled general decoder (<xref ref-type="fig" rid="fig3">Figure 3B</xref>) than by the small effects of attention on the modeled specific decoder (<xref ref-type="fig" rid="fig3">Figure 3B</xref>). In other words, the monkey’s decoding strategy was most qualitatively matched to the modeled general decoder.</p><p>We note that the effects of attention on the modeled general decoder (<xref ref-type="fig" rid="fig3">Figure 3B</xref>) matched the effects of attention on the physiological monkey’s decoder (<xref ref-type="fig" rid="fig3">Figure 3A</xref>) in the neuronal population size range recorded in the physiological data. But we also observed that the difference in the attentional effects on the two modeled decoders decreased with larger population sizes (right plot of <xref ref-type="fig" rid="fig3">Figure 3B</xref>). This is not noteworthy in and of itself because the attentional effects necessarily decreased as the decoders reached their information saturation points, as defined by the parameters of the modeled neurons. What we do want to note, however, is that the large attentional effects on the physiological monkey’s decoders suggest that the monkeys were not working in the optimal regime near the saturation point. Instead, the monkeys appear to have been working at an inner regime that allowed them to demonstrate large effects of attention on their performance.</p><p>Third, we tested the crux of our hypothesis: that a general decoding strategy underlies the frequently reported relationship between perceptual performance and mean correlated variability. This was our most critical test toward understanding the much debated role of mean correlated variability. It would be difficult to interpret a relationship between the performance of a decoder and mean correlated variability in isolation, because a correlation between these two factors could come about through an indirect relationship. But here, we tested the explicit hypothesis that the modeled general decoder would be more related to mean correlated variability than the modeled specific decoder, just as the physiological monkey’s decoder would be more strongly related to mean correlated variability than the physiological specific decoder. Such a finding would indicate that a more-general decoding strategy better explained the relationship between behavior and mean correlated variability than a more-specific decoding strategy.</p><p>Indeed, we found that just as the performance of the physiological monkey’s decoder was more strongly related to mean correlated variability than the performance of the physiological specific docoder (<xref ref-type="fig" rid="fig3">Figure 3C</xref>; see <xref ref-type="fig" rid="fig3s1">Figure 3—figure supplement 1</xref> for analyses per attention condition), the performance of the modeled general decoder was more strongly related to mean correlated variability than the performance of the modeled specific decoder (<xref ref-type="fig" rid="fig3">Figure 3D</xref>; see <xref ref-type="fig" rid="fig3s2">Figure 3—figure supplement 2</xref> for trial-shuffled analyses). We modeled much stronger relationships to correlated variability (<xref ref-type="fig" rid="fig3">Figure 3D</xref>) than observed with our physiological data (<xref ref-type="fig" rid="fig3">Figure 3C</xref>). We observed that the correlation with specific decoder performance was significant with the modeled data but not with the physiological data. This is not surprising as we saw attentional effects, albeit small ones, on specific decoder performance with both the physiological and the modeled data (<xref ref-type="fig" rid="fig3">Figure 3A, B</xref>). Even small attentional effects would result in a correlation between decoder performance and mean correlated variability with a large enough range of mean correlated variability values. It is possible that with enough electrophysiological data, the performance of the specific decoder would be significantly related to correlated variability, as well. As described above, our focus is not on whether the performance of any one decoder is significantly correlated with mean correlated variability, but on which decoder provides a better explanation of the frequently observed relationship between performance and mean correlated variability. The performance of the general decoder was more strongly related to mean correlated variability than the performance of the specific decoder.</p><p>Finally, while the circuit model allowed us to analyze an ideal general decoder for the full range of stimulus orientations in multiple attention conditions (<xref ref-type="fig" rid="fig2">Figure 2B, C</xref>; a full ring of orientations in both unattended and attended conditions), as a sanity check, we used the physiological data from the cued attention condition only (a limited set of five orientation change amounts as illustrated in <xref ref-type="fig" rid="fig1">Figure 1B</xref>, in the cued condition only as the uncued condition focused on the median orientation change amount only) to test whether more-general decoders were more related to the monkey’s decoder than more-specific decoders. Would a decoder based on more stimulus orientations be more related to the monkey’s decoder than a decoder based on fewer stimulus orientations?</p><p>For the physiological data, we again used linear decoders as illustrated in <xref ref-type="fig" rid="fig1">Figure 1D and E</xref>, as the V4 neuronal population representations of the limited range of stimulus orientations tested in our behavioral task (<xref ref-type="fig" rid="fig1">Figure 1B</xref>) were reasonably approximated by a line (<xref ref-type="fig" rid="fig3">Figure 3E</xref>; while a complex linear estimator was required for the modeled data based on the full range of orientations, linear methods were sufficient to capture decoder performance for the physiological dataset). First, for each monkey, we calculated the across-days correlation between the performance of the monkey’s decoder and the performance of a decoder based on a single orientation change amount (<xref ref-type="fig" rid="fig3">Figure 3F</xref>, ‘1 ori’; see Materials and methods for more details). Next, we calculated the across-days correlation between the performance of the monkey’s decoder and the performance of decoders based on two, three, or four orientation change amounts (<xref ref-type="fig" rid="fig3">Figure 3F</xref>, ‘2 oris’ through ‘4 oris’). We found that the more general the decoder, the more its performance was correlated with that of the monkey’s decoder. Further, the more general the decoder, the better it predicted the monkey’s trial-by-trial choices on the median changed orientation trials (<xref ref-type="fig" rid="fig3">Figure 3G</xref>).</p></sec></sec><sec id="s3" sec-type="discussion"><title>Discussion</title><p>Our results suggest that the relationship between behavior and mean correlated variability is more consistent with observers using a more-general strategy that employs the same neuronal weights for decoding any stimulus change. The modeled general decoder better matched the attentional effects on the electrophysiological monkey’s decoder and, most importantly, was more strongly related to mean correlated variability than the specific decoder. Further, based on our electrophysiological data, the more general the decoder (the more orientation change amounts used to determine the decoder weights), the more its performance was correlated with that of the monkey’s decoder. Together, these results support the hypothesis that observers use a more-general decoding strategy in scenarios that require flexibility to changing stimulus conditions.</p><p>Our study also demonstrates the utility of combining electrophysiological and circuit modeling approaches to studying neural coding. Our model mimicked the correlated variability and effects of attention in our physiological data. Critically, our model produced neuronal tuning and covariance based on the constraints of an actual network capable of processing images as inputs. Using a circuit model allowed us to test a full range of stimulus orientations in multiple attention conditions, allowing us to test the effects of attention on a true general decoder for orientation.</p><sec id="s3-1"><title>A fixed readout mechanism</title><p>A prior study from our lab found that attention, rather than changing the neuronal weights of the observer’s decoder, reshaped neuronal population activity to better align with a fixed readout mechanism (<xref ref-type="bibr" rid="bib49">Ruff and Cohen, 2019</xref>). To test whether the neuronal weights of the monkey’s decoder changed across attention conditions (attended versus unattended), Ruff and Cohen switched the neuronal weights across conditions, testing the stimulus information in one attention condition with the neuronal weights from the other. They found that even with the switched weights, the performance of the monkey’s decoder was still higher in the attended condition. The results of this study support the conclusion that attention reshapes neuronal activity so that a fixed readout mechanism can better read out stimulus information. In other words, differences in the performance of the monkey’s decoder across attention conditions may be due to differences in how well the neuronal activity aligns with a fixed decoder.</p><p>Our study extends the findings of Ruff and Cohen to test whether that fixed readout mechanism is determined by a general decoding strategy. Our findings support the hypothesis that observers use a general decoding strategy in the face of changing stimulus and task conditions. Our findings do not exclude other potential explanations for the suboptimality of the monkey’s decoder, nor do they exclude the possibility that attention modulates decoder neuronal weights. However, our findings together with those of Ruff and Cohen shed light on why neuronal decoders are suboptimal in a manner that aligns the fixed decoder axis with the correlated variability axis (<xref ref-type="bibr" rid="bib37">Ni et al., 2018</xref>; <xref ref-type="bibr" rid="bib48">Ruff et al., 2018</xref>).</p></sec><sec id="s3-2"><title>A general decoding strategy in the face of unpredictable stimuli</title><p>We performed this initial test of the overarching general decoder hypothesis in the context of a change detection task along a single stimulus dimension because this type of task was used in many of the studies that reported a relationship between perceptual performance and mean correlated variability (<xref ref-type="bibr" rid="bib7">Cohen and Maunsell, 2009</xref>; <xref ref-type="bibr" rid="bib9">Cohen and Maunsell, 2011</xref>; <xref ref-type="bibr" rid="bib17">Herrero et al., 2013</xref>; <xref ref-type="bibr" rid="bib32">Luo and Maunsell, 2015</xref>; <xref ref-type="bibr" rid="bib33">Mayo and Maunsell, 2016</xref>; <xref ref-type="bibr" rid="bib36">Nandy et al., 2017</xref>; <xref ref-type="bibr" rid="bib37">Ni et al., 2018</xref>; <xref ref-type="bibr" rid="bib47">Ruff and Cohen, 2016</xref>; <xref ref-type="bibr" rid="bib49">Ruff and Cohen, 2019</xref>; <xref ref-type="bibr" rid="bib55">Verhoef and Maunsell, 2017</xref>; <xref ref-type="bibr" rid="bib57">Yan et al., 2014</xref>; <xref ref-type="bibr" rid="bib58">Zénon and Krauzlis, 2012</xref>). This simple and well-studied task provided an ideal initial test of our general decoder hypothesis.</p><p>This initial test of the general decoder hypothesis suggests that a more-general decoding strategy may explain observations in studies that use a variety of behavioral and stimulus conditions. Studies using a variety of tasks have also demonstrated a relationship between perceptual performance and mean correlated variability. These tasks include heading (<xref ref-type="bibr" rid="bib15">Gu et al., 2011</xref>), orientation (<xref ref-type="bibr" rid="bib14">Gregoriou et al., 2014</xref>), and contrast (<xref ref-type="bibr" rid="bib45">Ruff and Cohen, 2014a</xref>; <xref ref-type="bibr" rid="bib46">Ruff and Cohen, 2014b</xref>) discrimination tasks, in which the observer must respond to certain stimulus values or compare stimulus values. Some studies of discrimination tasks suggest that the relationship between perceptual performance and mean correlated variability cannot be explained by a specific decoding strategy that maximizes the amount of sensory information extracted for the task (<xref ref-type="bibr" rid="bib6">Clery et al., 2017</xref>; <xref ref-type="bibr" rid="bib15">Gu et al., 2011</xref>). It will be interesting to determine whether general decoders for linearly varying stimulus dimensions such as contrast (or speed, direction of motion, etc.) also provide a better explanation of the relationship between behavior and mean correlated variability than specific decoders.</p><p>On the other hand, other studies of perceptual performance have found that observers can achieve high levels of perceptual precision under certain circumstances (<xref ref-type="bibr" rid="bib5">Burgess et al., 1981</xref>; <xref ref-type="bibr" rid="bib28">Kersten, 1987</xref>). Such studies suggest that decoding strategies that maximize the amount of extracted sensory information might be used in certain situations. Further tests of decoding strategies in a variety of stimulus conditions and behavioral contexts will be necessary to determine when sensory information decoding prioritizes accuracy and when decoding prioritizes flexibility, or generality, over accuracy. Of particular interest is the potential role of perceptual learning (<xref ref-type="bibr" rid="bib51">Seitz and Watanabe, 2005</xref>) in determining the extent to which decoding is specific (<xref ref-type="bibr" rid="bib15">Gu et al., 2011</xref>; <xref ref-type="bibr" rid="bib21">Jeanne et al., 2013</xref>; <xref ref-type="bibr" rid="bib37">Ni et al., 2018</xref>).</p></sec><sec id="s3-3"><title>General decoders of all features would be inextricably linked to mean correlated variability</title><p>Our results address a paradox in the literature. Electrophysiological and theoretical evidence supports that there is a relationship between mean correlated variability and perceptual performance (<xref ref-type="bibr" rid="bib1">Abbott and Dayan, 1999</xref>; <xref ref-type="bibr" rid="bib6">Clery et al., 2017</xref>; <xref ref-type="bibr" rid="bib16">Haefner et al., 2013</xref>; <xref ref-type="bibr" rid="bib22">Jin et al., 2019</xref>; <xref ref-type="bibr" rid="bib37">Ni et al., 2018</xref>; <xref ref-type="bibr" rid="bib49">Ruff and Cohen, 2019</xref>; reviewed by <xref ref-type="bibr" rid="bib48">Ruff et al., 2018</xref>). Yet, a specific decoding strategy in which different sets of neuronal weights are used to decode different stimulus changes cannot easily explain this relationship (<xref ref-type="bibr" rid="bib23">Kafashan et al., 2021</xref>; <xref ref-type="bibr" rid="bib26">Kanitscheider et al., 2015b</xref>; <xref ref-type="bibr" rid="bib35">Moreno-Bote et al., 2014</xref>; <xref ref-type="bibr" rid="bib42">Pitkow et al., 2015</xref>; <xref ref-type="bibr" rid="bib50">Rumyantsev et al., 2020</xref>; reviewed by <xref ref-type="bibr" rid="bib29">Kohn et al., 2016</xref>). This is because specific decoders of neuronal population activity can easily ignore changes in mean correlated noise (<xref ref-type="bibr" rid="bib35">Moreno-Bote et al., 2014</xref>).</p><p>The general decoder hypothesis offers a resolution to this paradox. As a decoder becomes more general to more stimulus features, its weights will have to depend on more and more tuning properties of the neuronal population. A fully general decoder of stimuli that vary along many feature dimensions would be one whose neuronal weights depend on the tuning properties of the neurons to all stimulus features to which they are selective. For example, two V4 neurons may both prefer vertical orientations. If they also share a color tuning preference for red, a large response from both neurons might indicate vertical orientation, the color red, or a combination of both features. A fully general decoder would need to resolve this discrepancy by choosing weights for these and other neurons that take not only their tuning for orientation but also their tuning for color into account.</p><p>Therefore, the weights of a fully general decoder would depend on the tuning of all neurons to all of the stimulus features to which they are selective. A large number of studies have shown that mean correlated variability depends on tuning similarity for all stimulus features (for review, see <xref ref-type="bibr" rid="bib8">Cohen and Kohn, 2011</xref>; <xref ref-type="bibr" rid="bib48">Ruff et al., 2018</xref>). The implication is that the decoding weights for a fully general decoder would depend on exactly the same properties as mean correlated variability.</p><p>This initial study of the general decoder hypothesis tested this idea in the context of a visual environment in which stimulus values only changed along a single dimension. However, our overarching hypothesis is that observers use a general decoding strategy in the complex and feature-rich visual scenes encountered in natural environments. In everyday environments, visual stimuli can change rapidly and unpredictably along many stimulus dimensions. The hypothesis that such a truly general decoder explains the relationship between perceptual performance and mean correlated variability is suggested by our finding that the modeled general decoder for orientation was more strongly related to mean correlated variability than the modeled specific decoder (<xref ref-type="fig" rid="fig3">Figure 3D</xref>). Future tests of a general decoder for multiple stimulus features would be needed to determine if this decoding strategy is used in the face of multiple changing stimulus features. Further, such tests would need to consider alternative hypotheses for how sensory information is decoded when observing multiple aspects of a stimulus (<xref ref-type="bibr" rid="bib3">Berkes et al., 2009</xref>; <xref ref-type="bibr" rid="bib11">Deneve, 2012</xref>; <xref ref-type="bibr" rid="bib31">Lorteije et al., 2015</xref>). Studies that use complex or naturalistic visual stimuli may be ideal for further investigations of this hypothesis.</p><p>The purpose of this study was to investigate the relationship between mean correlated variability and a general decoder. We made an initial test of the overarching hypothesis that observers use a general decoding strategy in feature-rich environments by testing whether a decoder optimized for a broader range of stimulus values better matched the decoder actually used by the monkeys than a specific decoder optimized for a narrower range of stimulus values. We purposefully did not make claims about the utility of correlated variability relative to hypothetical situations in which correlated variability does not exist in the responses of a group of neurons, as we suspect that this is not a physiologically realistic condition. Studies that causally manipulate the level of correlated variability in neuronal populations to measure the true physiological and behavioral effects of increasing or decreasing correlated variability levels, through pharmacological or genetic means, may provide important insights into the impact of correlated variability on various decoding strategies.</p><p>In our model, which was designed to mimic real data, attention changed many aspects of neural responses besides just correlated variability. It is therefore possible that any relationship between decoding performance and correlated variability is mostly caused by those concomitant changes. Thus, we used the many trials in our modeled data to test the effects of randomly shuffling the trial order per modeled neuron. These shuffled data resulted in the modeled general and specific decoders becoming essentially indistinguishable in their relationships with the removed correlated variability (<xref ref-type="fig" rid="fig3s2">Figure 3—figure supplement 2</xref>), with those removed correlations essentially representing attention condition. The effects of attention on many aspects of neuronal population activity have been well documented, including effects on neuronal firing rates and on both individual and shared trial-to-trial response variability (<xref ref-type="bibr" rid="bib7">Cohen and Maunsell, 2009</xref>; <xref ref-type="bibr" rid="bib9">Cohen and Maunsell, 2011</xref>; <xref ref-type="bibr" rid="bib17">Herrero et al., 2013</xref>; <xref ref-type="bibr" rid="bib32">Luo and Maunsell, 2015</xref>; <xref ref-type="bibr" rid="bib33">Mayo and Maunsell, 2016</xref>; <xref ref-type="bibr" rid="bib34">Mitchell et al., 2009</xref>; <xref ref-type="bibr" rid="bib36">Nandy et al., 2017</xref>; <xref ref-type="bibr" rid="bib37">Ni et al., 2018</xref>; <xref ref-type="bibr" rid="bib45">Ruff and Cohen, 2014a</xref>; <xref ref-type="bibr" rid="bib46">Ruff and Cohen, 2014b</xref>; <xref ref-type="bibr" rid="bib47">Ruff and Cohen, 2016</xref>; <xref ref-type="bibr" rid="bib49">Ruff and Cohen, 2019</xref>; <xref ref-type="bibr" rid="bib58">Zénon and Krauzlis, 2012</xref>). The simulated neurons in our model captured many of these attention effects (<xref ref-type="fig" rid="fig2">Figure 2D–F</xref>; <xref ref-type="bibr" rid="bib19">Huang et al., 2019</xref>). Much theoretical work has supported that in the presence of correlations between neuronal responses, specifically differential or information-limiting correlations, limits on decoding performance will be dominated by these correlations (<xref ref-type="bibr" rid="bib35">Moreno-Bote et al., 2014</xref>; for review, see <xref ref-type="bibr" rid="bib29">Kohn et al., 2016</xref>). Removing these correlations by shuffling the trials results in many changes; in particular, our trial-shuffled data demonstrate the well-documented linear growth in Fisher information that is expected with increasing numbers of neurons (<xref ref-type="fig" rid="fig3s2">Figure 3—figure supplement 2A–C</xref>; <xref ref-type="bibr" rid="bib2">Averbeck et al., 2006</xref>; <xref ref-type="bibr" rid="bib29">Kohn et al., 2016</xref>; <xref ref-type="bibr" rid="bib53">Shadlen et al., 1996</xref>). Our trial-shuffled analysis illustrates that removing correlations results in decoder performance being dominated by other effects of attention on neuronal activity, such as the firing rates (gains) of the neurons. Our model reproduces the gain effects of attention on neuronal firing rates observed in electrophysiological data (<xref ref-type="fig" rid="fig2">Figure 2D</xref>) which, in the absence of correlations, increases the sensitivity of the population (<xref ref-type="bibr" rid="bib2">Averbeck et al., 2006</xref>; <xref ref-type="bibr" rid="bib29">Kohn et al., 2016</xref>; <xref ref-type="bibr" rid="bib53">Shadlen et al., 1996</xref>). In summary, general and specific decoder performances had indistinguishable relationships with the amount of correlated variability removed by the trial shuffling (<xref ref-type="fig" rid="fig3s2">Figure 3—figure supplement 2D, E</xref>), suggesting that decoder performance became dominated by attention-related firing rate gains intrinsic to our model.</p><p>In conclusion, the findings of this study support the usefulness of a framework that relates sensory information decoding to behavior (for review, see <xref ref-type="bibr" rid="bib40">Panzeri et al., 2017</xref>). By first determining the decoder that guided each monkey’s behavioral choices, we were able to compare the monkey’s decoder to modeled specific and general decoders to test our hypothesis. These results demonstrate that constraining analyses of neuronal data by behavior can provide important insights into the neurobiological mechanisms underlying perception and cognition.</p></sec></sec><sec id="s4" sec-type="materials|methods"><title>Materials and methods</title><sec id="s4-1"><title>Electrophysiological recordings</title><p>The subjects were two adult male rhesus monkeys (<italic>Macaca mulatta</italic>, 8 and 10 kg). All animal procedures were approved by the Institutional Animal Care and Use Committees of the University of Pittsburgh and Carnegie Mellon University (Protocol #17071123). Different aspects of these data were presented previously (<xref ref-type="bibr" rid="bib37">Ni et al., 2018</xref>). We recorded extracellularly from single units and sorted multiunit clusters (the term ‘unit’ refers to either; see <xref ref-type="bibr" rid="bib37">Ni et al., 2018</xref>) in V4 of the left hemisphere using chronically implanted 96-channel microelectrode arrays (Blackrock Microsystems) with 1 mm long electrodes. We performed all spiking sorting manually using Plexon’s Offline Sorter (version 3.3.5, Plexon).</p><p>We only included a recorded unit if its stimulus-driven firing rate was both greater than 10 Hz and significantly higher than the baseline firing rate (baseline calculated as the firing rate in the 100 ms window immediately prior to the onset of the first stimulus per trial; two-sided Wilcoxon signed rank test: p&lt;10<sup>–10</sup>). The population size of simultaneously recorded units was 8–45 units (mean 39) per day for Monkey 1 and 7–31 units (mean 19) per day for Monkey 2.</p><p>No statistical methods were used to predetermine our sample sizes of subjects or recorded units, but our sample sizes are similar to those used in previous publications that analyzed neuronal and behavioral data similar to the data analyzed here (<xref ref-type="bibr" rid="bib7">Cohen and Maunsell, 2009</xref>; <xref ref-type="bibr" rid="bib37">Ni et al., 2018</xref>).</p></sec><sec id="s4-2"><title>Behavioral task</title><p>The monkeys performed a change detection task (<xref ref-type="fig" rid="fig1">Figure 1A</xref>; <xref ref-type="bibr" rid="bib7">Cohen and Maunsell, 2009</xref>) with multiple orientation change options (<xref ref-type="fig" rid="fig1">Figure 1B</xref>) and cued attention (<xref ref-type="bibr" rid="bib43">Posner, 1980</xref>) while we recorded electrophysiological data. We presented visual stimuli on a CRT monitor (calibrated to linearize intensity; 1024×768 pixels; 120 Hz refresh rate) placed 52 cm from the monkey, using custom software written in MATLAB (Psychophysics Toolbox; <xref ref-type="bibr" rid="bib4">Brainard, 1997</xref>; <xref ref-type="bibr" rid="bib41">Pelli, 1997</xref>). We monitored each monkey’s eye position using an infrared eye tracker (Eyelink 1000; SR Research) and recorded eye position, neuronal responses (30,000 samples/s), and the signal from a photodiode to align neuronal responses to stimulus presentation times (30,000 samples/s) using Ripple hardware.</p><p>A trial began when a monkey fixed its gaze on a small, central spot on the video display while two peripheral Gabor stimuli (one overlapping the RFs of the recorded neurons, the other in the opposite visual hemifield; <xref ref-type="fig" rid="fig1">Figure 1C</xref>) synchronously flashed on (for 200 ms) and off (for a randomized period between 200 and 400 ms) at the same starting orientation until at a random, unsignaled time the orientation of one of the stimuli changed. The monkey received a liquid reward for making a saccade to the changed stimulus within 400 ms of its onset.</p><p>Attention was cued in blocks of trials, with each block preceded by 10 instruction trials that cued one of the two stimulus locations by only presenting stimuli at that location. Each block consisted of approximately 125 orientation change trials. In each block, the orientation change occurred at the cued location in 80% of the change trials and at the uncued location in 20% of the change trials. Catch trials were intermixed, in which no orientation change occurred within the maximum of 12 stimulus presentations. In catch trials, the monkeys were rewarded for maintaining fixation. Blocks of trials with attention cued to the left hemifield location or to the right hemifield location were presented in alternating order within a recording day.</p><p>The changed orientation at the cued location was randomly selected per trial from one of five changed orientations (with the constraint of required numbers of presentations per changed orientation per block; <xref ref-type="fig" rid="fig1">Figure 1B</xref>) such that the monkeys could not predict which orientation change amount was to be detected on any given trial. The changed orientation at the uncued location was randomly either the median (20 trials per block) or the largest orientation change amount (5 trials per block). Uncued changes were collected mainly for the median change amount to maximize the number of uncued trials collected for one change amount. All analyses of the effects of attention analyzed the cued versus uncued median change amounts.</p><p>The size, location, and spatial frequency of the Gabor stimuli were fixed across all recording days. These three parameters were determined in advance of recording the data presented here, using a receptive field mapping task. These parameters were set to maximize the neuronal responses recorded by the array.</p><p>The starting orientation (<xref ref-type="fig" rid="fig1">Figure 1A, B</xref>) was identical for all trials within a day. We changed the starting orientation by 15° for each new day of recording. We also changed the five changed orientation options (<xref ref-type="fig" rid="fig1">Figure 1B</xref>) for each new day of recording, to maintain the task at approximately the same level of difficulty across days. The five changed orientation options were always the same within one session of trials, with one session equaling two blocks of trials: one block of trials with the left stimulus cued, and one block of trials with the right stimulus cued (<xref ref-type="fig" rid="fig1">Figure 1C</xref>). We sometimes changed the five orientation options between sessions within a day, again to maintain a consistent level of task difficulty. For those days, we binned the orientation change amounts into five bins based on their log distribution.</p></sec><sec id="s4-3"><title>Electrophysiological data analysis</title><p>The data presented are from 46 days of recording for Monkey 1 and 28 days of recording for Monkey 2. Instruction trials were not included in any analyses. Only trials in which the orientation changes occurred at the RF location (<xref ref-type="fig" rid="fig1">Figure 1C</xref>) and catch trials were analyzed (see below for specific inclusions per analysis). The first stimulus presentation of each trial was excluded from all analyses to minimize temporal non-stationarities due to adaptation.</p><p>Firing rates (<xref ref-type="fig" rid="fig2">Figure 2D</xref>), mean correlated variability (<xref ref-type="fig" rid="fig2">Figures 2E</xref> and <xref ref-type="fig" rid="fig3">3C</xref>), and covariance eigenspectrum analyses (<xref ref-type="fig" rid="fig2">Figure 2F</xref>) were calculated based on orientation change trials on which the monkey correctly detected the change as well as on catch trials. From these trials, only the starting orientation stimulus presentations were included in the analyses. The firing rate per stimulus presentation was based on the spike count response between 60 and 260 ms after stimulus onset to account for V4 latency. These analyses were performed per recording day (such that all starting orientation stimuli analyzed together were identical). Data were presented as the mean per day (<xref ref-type="fig" rid="fig3">Figure 3C</xref>) or across days (<xref ref-type="fig" rid="fig2">Figure 2D–F</xref>) per attention condition (cued or uncued).</p><p>We defined the mean correlated variability of each pair of simultaneously recorded units (quantified as the noise correlation or spike count correlation; <xref ref-type="bibr" rid="bib8">Cohen and Kohn, 2011</xref>) as the correlation between the firing rates of the two units in response to repeated presentations of the same stimulus (the starting orientation). This measure of mean correlated variability represents correlations in noise rather than in signal because the visual stimulus was always the same.</p><p>For <xref ref-type="fig" rid="fig3">Figure 3C</xref>, we used Williams’ procedure for comparing correlated correlation coefficients (<xref ref-type="bibr" rid="bib18">Howell, 2007</xref>) to compare the across-days correlation between the performance of the monkey’s decoder and the mean correlated variability of the V4 population to the across-days correlation between the performance of the specific decoder and the mean correlated variability of the V4 population.</p><p>For Monkey 1, two outlier points (uncued trials for each of 2 days) with mean correlated variability values greater than 0.35 were excluded from analysis based on the Tukey method (see <xref ref-type="fig" rid="fig3">Figure 3C</xref> for the range of included correlated variability values for Monkey 1). For <xref ref-type="fig" rid="fig3">Figure 3C</xref>, with the excluded points included, the correlation coefficients were qualitatively unchanged: for the monkey’s decoder, <italic>n</italic>=88, or 44 days (see below for data included in decoder analyses) with two attention conditions plotted per day, <italic>r</italic>=–0.34, p=1.7 × 10<sup>–3</sup>; for the specific decoder, <italic>r</italic>=–0.22, p=0.05.</p></sec><sec id="s4-4"><title>V4 population specific decoder</title><p>For <xref ref-type="fig" rid="fig3">Figure 3A and C</xref>, we calculated the performance of a specific decoder based on the electrophysiologically recorded V4 neuronal population data (<xref ref-type="bibr" rid="bib37">Ni et al., 2018</xref>). To avoid artifacts in neuronal firing rates due to eye movements in response to the changed orientation, all V4 population decoder analyses were based on neuronal firing rates during an abbreviated time window: 60–130 ms after stimulus onset.</p><p>The specific decoder was a linear classifier trained to best differentiate the V4 population responses to the median changed orientation from the V4 responses to the starting orientation presented immediately before it (<xref ref-type="fig" rid="fig1">Figure 1D</xref>; first and second principal components shown for illustrative purposes only – analyses were based on neuronal population firing rates). The neuronal weights were calculated per day and per attention condition.</p><p>Decoder performance was quantified as the leave-one-out cross-validated proportion of correctly identified orientations (median changed orientation or starting orientation). For <xref ref-type="fig" rid="fig3">Figure 3A</xref>, decoder performance was analyzed per number of neurons (<italic>x</italic>-axis). Per neuronal population size, the most responsive neurons (ranked by evoked response: stimulus-evoked firing rate minus baseline firing rate) were analyzed.</p><p>For <xref ref-type="fig" rid="fig3">Figure 3C</xref>, decoder performance was illustrated for a set number of neurons (Monkey 1: 20 units, Monkey 2: 10 units). The number of neurons analyzed for these plots was selected to maximize the number of included neurons and recording days (Monkey 1: <italic>n</italic>=44 days, 2 days with 8 and 19 recorded units excluded; Monkey 2: <italic>n</italic>=27 days, 1 day with 7 recorded units excluded).</p></sec><sec id="s4-5"><title>V4 population monkey’s decoder</title><p>For <xref ref-type="fig" rid="fig3">Figure 3A, C</xref>, we calculated the performance of the monkey’s choice decoder as well (<xref ref-type="fig" rid="fig1">Figure 1E</xref>). The monkey’s decoder was a linear classifier trained on the same set of V4 population responses as the specific decoder described above (the neuronal population firing rates in response to the median changed orientation and in response to the starting orientation presented immediately before it). However, unlike the specific decoder, the monkey’s decoder was trained to best differentiate the V4 population responses when the monkey made a saccade indicating it detected the orientation change from the V4 responses when the monkey did not make a saccade (both correctly in response to the starting orientation and incorrectly when the monkey missed the changed orientation).</p><p>Decoder performance was quantified just as it was for the specific decoder described above: as the leave-one-out cross-validated proportion of correctly identified orientations (median changed orientation or starting orientation). <xref ref-type="fig" rid="fig3">Figure 3A, C</xref> was calculated as described above for the specific decoder.</p><p>In summary, the physiological specific and monkey’s decoders were trained on different classifications of the same set of V4 responses and thus had different neuronal weights. However, everything else about how they were analyzed was the same, including that their performance was tested on the same task of correctly identifying whether each left-out orientation was the median changed orientation or the starting orientation.</p></sec><sec id="s4-6"><title>V4 population more-general versus more-specific decoders</title><p>For <xref ref-type="fig" rid="fig3">Figure 3F</xref>, we calculated decoders that were increasingly more general, to compare their performance to that of the monkey’s decoder. As described above, due to the limited number of behavioral trials collected per day, we could not calculate an ideal general decoder for orientation based on the physiological data as we could based on the modeled data. However, as a sanity check, we wanted to check whether more-general decoders were more strongly related to the monkey’s decoder than more-specific decoders. Additionally, we only analyzed trials from the cued attention condition (uncued trials were mainly collected for the median orientation change amount, which is why the median orientation change trials were analyzed in the attention analyses illustrated in <xref ref-type="fig" rid="fig3">Figure 3A, C</xref>). As with <xref ref-type="fig" rid="fig3">Figure 3C</xref> as described above, decoder performance was illustrated for a set number of neurons (Monkey 1: 20 units, Monkey 2: 10 units).</p><p>As above, the monkey’s decoder was trained on the median (third; <xref ref-type="fig" rid="fig1">Figure 1B</xref>) orientation change trials. The monkey’s decoder was trained to best differentiate the V4 population responses when the monkey made a saccade (indicating it detected the orientation change) from the V4 responses when the monkey did not make a saccade. Importantly, we sought to avoid the relationship that would be inherent between the monkey’s decoder and any decoder based on those same median (third) orientation change trials. Thus, only the neuronal weights for the monkey’s decoder were based on the median (third) orientation change trials. The weights of all of the other decoders in <xref ref-type="fig" rid="fig3">Figure 3F</xref> were based on trials other than the median orientation change trials.</p><p>The most specific decoder tested in <xref ref-type="fig" rid="fig3">Figure 3F</xref> was trained to best differentiate the V4 population responses to one changed orientation from the V4 responses to the starting orientation presented immediately before it. The performance of this specific decoder was quantified as the leave-one-out cross-validated proportion of trials on which the decoder correctly identified whether the left-out orientation was that one changed orientation or the starting orientation. The one changed orientation that was tested was either the first, second, fourth, or fifth largest changed orientation (all but the median changed orientation, which was excluded from this analysis due to the inherent relationship between any decoder that included this orientation and the monkey’s decoder which was based on this orientation, as noted above). We calculated the performance of each decoder on each day of recording. We then calculated the across-days correlation between the performance of this specific decoder and the performance of the monkey’s decoder (described above). The correlation coefficient was plotted in the ‘1 ori’ column of <xref ref-type="fig" rid="fig3">Figure 3F</xref> for each monkey (<italic>n</italic>=8 decoders; 1 decoder for each of the 4 included changed orientations, for each of the 2 monkeys).</p><p>We performed this same procedure for increasingly more-general decoders. The decoders illustrated in the ‘2 oris’ column were trained to best differentiate the V4 responses to two changed orientations from the V4 responses to the starting orientation. The two changed orientations used for each ‘2 oris’ decoder were chosen from the four possibilities: the first, second, fourth, and fifth (max) largest changed orientations (<italic>n</italic>=48 decoders; 1 decoder for each of the 6 combinations of 2 changed orientations, tested on each of the 4 included changed orientations, for each of the 2 monkeys). We calculated the performance of each ‘2 oris’ decoder on the same task as above: identifying whether the orientation was the changed orientation (the first, second, fourth, or fifth largest changed orientation) or the starting orientation. Again, we calculated the across-days correlation between the performance of each ‘2 oris’ decoder and the performance of the monkey’s decoder.</p><p>Each ‘3 oris’ decoder was trained to best differentiate the V4 responses to three changed orientations from the V4 responses to the starting orientation (<italic>n</italic>=32 decoders; 1 decoder for each of the 4 combinations of 3 changed orientations, tested on each of the 4 included changed orientations, for each of the 2 monkeys). The ‘4 oris’ decoder for each monkey was trained to best differentiate the V4 responses to four changed orientations from the V4 responses to the starting orientation (<italic>n</italic>=8 decoders; 1 decoder for the 1 combination of 4 changed orientations, tested on each of the 4 included changed orientations, for each of the 2 monkeys).</p><p>For <xref ref-type="fig" rid="fig3">Figure 3G</xref>, we performanced analyses similar to those performed for <xref ref-type="fig" rid="fig3">Figure 3F</xref>, in that we tested each stimulus decoder: ‘1 ori’ decoders (<italic>n</italic>=8 decoders; 1 specific decoder for either the first, second, fourth, or fifth largest changed orientation, for each of the 2 monkeys), ‘2 oris’ decoders (<italic>n</italic>=12 decoders; 1 decoder for each of the 6 combinations of 2 changed orientations, for each of the 2 monkeys), ‘3 oris’ decoders (<italic>n</italic>=8 decoders; 1 decoder for each of the 4 combinations of 3 changed orientations, for each of the 2 monkeys), and ‘4 oris’ decoders (<italic>n</italic>=2 decoders; 1 decoder for the 1 combination of 4 changed orientations, for each of the 2 monkeys). However, unlike in <xref ref-type="fig" rid="fig3">Figure 3F</xref>, where the performance of the stimulus decoders was compared to the performance of the monkey’s decoder on the median orientation change trials, here, we calculated the performance of the stimulus decoder when tasked with predicting the trial-by-trial choices that the monkey made on the median orientation change trials. We plotted the proportion of leave-one-out trials in which each decoder correctly predicted the monkey’s choice as to whether the orientation was the starting orientation or the median changed orientation.</p></sec><sec id="s4-7"><title>Network model description</title><p>The network model is similar to the one in <xref ref-type="bibr" rid="bib19">Huang et al., 2019</xref>. Briefly, the network consists of three modeled stages: (1) layer (L) 4 neurons of V1, (2) L2/3 neurons of V1, and (3) L2/3 neurons of V4 (<xref ref-type="fig" rid="fig2">Figure 2A</xref>). Neurons from each area are arranged on a uniform grid covering a unit square <inline-formula><mml:math id="inf1"><mml:mrow><mml:mi mathvariant="normal">Γ</mml:mi><mml:mo>=</mml:mo><mml:mrow><mml:mrow><mml:mo stretchy="false">[</mml:mo><mml:mrow><mml:mo>-</mml:mo><mml:mn>0.5</mml:mn></mml:mrow><mml:mo>,</mml:mo><mml:mn>0.5</mml:mn><mml:mo stretchy="false">]</mml:mo></mml:mrow><mml:mo>×</mml:mo><mml:mrow><mml:mo stretchy="false">[</mml:mo><mml:mrow><mml:mo>-</mml:mo><mml:mn>0.5</mml:mn></mml:mrow><mml:mo>,</mml:mo><mml:mn>0.5</mml:mn><mml:mo stretchy="false">]</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:math></inline-formula>. The L4 neurons of V1 are modeled as a population of excitatory neurons, the spikes of which are taken as inhomogeneous Poisson processes with rates determined as below. The L2/3 of V1 and V4 populations are recurrently coupled networks with excitatory and inhibitory neurons. Each neuron is modeled as an exponential integrate-and-fire (EIF) neuron. The connection probability between neurons decays with distance. The network model captures many attention-mediated changes on neuronal responses, such as the reduction of correlated variability within each visual area, increase in correlated variability between visual areas, and the quenching of the low-dimensional correlated variability by attention. The network parameters are the same as those used in <xref ref-type="bibr" rid="bib19">Huang et al., 2019</xref> except the following. The feedforward projection width from V1 (L2/3) to V4 is <inline-formula><mml:math id="inf2"><mml:mrow><mml:msubsup><mml:mi>α</mml:mi><mml:mi>ffwd</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mn>3</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup><mml:mo>=</mml:mo><mml:mn>0.05</mml:mn></mml:mrow></mml:math></inline-formula>. The feedforward strength from V1 (L2/3) to V4 is <inline-formula><mml:math id="inf3"><mml:mrow><mml:mrow><mml:mo stretchy="false">[</mml:mo><mml:msubsup><mml:mi>J</mml:mi><mml:mi>eF</mml:mi><mml:mn>3</mml:mn></mml:msubsup><mml:mo>,</mml:mo><mml:msubsup><mml:mi>J</mml:mi><mml:mi>iF</mml:mi><mml:mn>3</mml:mn></mml:msubsup><mml:mo stretchy="false">]</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mrow><mml:mi>γ</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">[</mml:mo><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mn>0.4</mml:mn><mml:mo stretchy="false">]</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:math></inline-formula>. From the most unattended state to the most attended state (attentional modulation scale from 0 to 1), <inline-formula><mml:math id="inf4"><mml:mi>γ</mml:mi></mml:math></inline-formula> varies from 20 to 23 mV, and the depolarizing current to the inhibitory neurons in V4, <inline-formula><mml:math id="inf5"><mml:msub><mml:mi>μ</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:math></inline-formula>, varies from 0 to 0.5 mV/ms (<xref ref-type="fig" rid="fig2">Figure 2</xref>, <xref ref-type="fig" rid="fig3">Figure 3B, D</xref>).</p><p>The model differs from the previous model (<xref ref-type="bibr" rid="bib19">Huang et al., 2019</xref>) in the following ways. We modeled the V1 (L4) neurons as orientation selective filters with static nonlinearity and Poisson spike generation (<xref ref-type="bibr" rid="bib26">Kanitscheider et al., 2015b</xref>). The firing rate of each neuron <italic>i</italic> is <inline-formula><mml:math id="inf6"><mml:mrow><mml:mrow><mml:msub><mml:mi>r</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>θ</mml:mi><mml:mo>,</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mo>=</mml:mo><mml:msub><mml:mrow><mml:mo stretchy="false">[</mml:mo><mml:mrow><mml:mrow><mml:msub><mml:mi>F</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>×</mml:mo><mml:mover accent="true"><mml:mi>I</mml:mi><mml:mo stretchy="false">~</mml:mo></mml:mover></mml:mrow><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>θ</mml:mi><mml:mo>,</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mo stretchy="false">]</mml:mo></mml:mrow><mml:mo>+</mml:mo></mml:msub></mml:mrow></mml:math></inline-formula>, where <inline-formula><mml:math id="inf7"><mml:msub><mml:mi>F</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:math></inline-formula> is a Gabor filter and <inline-formula><mml:math id="inf8"><mml:mrow><mml:mover accent="true"><mml:mi>I</mml:mi><mml:mo stretchy="false">~</mml:mo></mml:mover><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>θ</mml:mi><mml:mo>,</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> is a Gabor image corrupted by independent noise following the Ornstein-Uhlenbeck process,<disp-formula id="equ1"><mml:math id="m1"><mml:mrow><mml:mrow><mml:mrow><mml:mrow><mml:mover accent="true"><mml:mi>I</mml:mi><mml:mo stretchy="false">~</mml:mo></mml:mover><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>θ</mml:mi><mml:mo>,</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mo>=</mml:mo><mml:mrow><mml:mrow><mml:mrow><mml:mi>I</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>θ</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mo>+</mml:mo><mml:mrow><mml:mi>η</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:mrow><mml:mo mathvariant="italic" separator="true"> </mml:mo><mml:mi>and</mml:mi></mml:mrow></mml:mrow><mml:mo mathvariant="italic" separator="true"> </mml:mo><mml:mrow><mml:mrow><mml:msub><mml:mi>τ</mml:mi><mml:mi>n</mml:mi></mml:msub><mml:mo>⁢</mml:mo><mml:mi>d</mml:mi><mml:mo>⁢</mml:mo><mml:msub><mml:mi>η</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow><mml:mo>=</mml:mo><mml:mrow><mml:mrow><mml:mo>-</mml:mo><mml:mrow><mml:msub><mml:mi>η</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>⁢</mml:mo><mml:mi>d</mml:mi><mml:mo>⁢</mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:mrow><mml:mo>+</mml:mo><mml:mrow><mml:msub><mml:mi>σ</mml:mi><mml:mi>n</mml:mi></mml:msub><mml:mo>⁢</mml:mo><mml:mi>d</mml:mi><mml:mo>⁢</mml:mo><mml:mi>W</mml:mi></mml:mrow></mml:mrow></mml:mrow></mml:mrow><mml:mo>,</mml:mo></mml:mrow></mml:math></disp-formula></p><p>with <inline-formula><mml:math id="inf9"><mml:mrow><mml:msub><mml:mi>τ</mml:mi><mml:mi>n</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mn>40</mml:mn></mml:mrow></mml:math></inline-formula> ms and <inline-formula><mml:math id="inf10"><mml:mrow><mml:msub><mml:mi>σ</mml:mi><mml:mi>n</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mn>3.5</mml:mn></mml:mrow></mml:math></inline-formula>. The Gabor filters were normalized such that the mean firing rate of V1 (L4) neurons was 10 Hz. Spike trains of V1 (L4) neurons were generated as inhomogeneous Poisson processes with rate <inline-formula><mml:math id="inf11"><mml:mrow><mml:msub><mml:mi>r</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>θ</mml:mi><mml:mo>,</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula>. The Gabor image is defined on <inline-formula><mml:math id="inf12"><mml:mi mathvariant="normal">Γ</mml:mi></mml:math></inline-formula> with <inline-formula><mml:math id="inf13"><mml:mrow><mml:mn>25</mml:mn><mml:mo>×</mml:mo><mml:mn>25</mml:mn></mml:mrow></mml:math></inline-formula> pixels with spatial Gaussian envelope width <inline-formula><mml:math id="inf14"><mml:mrow><mml:mi>σ</mml:mi><mml:mo>=</mml:mo><mml:mn>0.2</mml:mn></mml:mrow></mml:math></inline-formula>, spatial wavelength <inline-formula><mml:math id="inf15"><mml:mrow><mml:mi>λ</mml:mi><mml:mo>=</mml:mo><mml:mn>0.6</mml:mn></mml:mrow></mml:math></inline-formula> and phase <inline-formula><mml:math id="inf16"><mml:mrow><mml:mi>ϕ</mml:mi><mml:mo>=</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:math></inline-formula> (<xref ref-type="bibr" rid="bib26">Kanitscheider et al., 2015b</xref>, Supp Equation 6 ). The Gabor filters of V1 (L4) neurons had the same <inline-formula><mml:math id="inf17"><mml:mi>σ</mml:mi></mml:math></inline-formula>, <inline-formula><mml:math id="inf18"><mml:mi>λ</mml:mi></mml:math></inline-formula> and <inline-formula><mml:math id="inf19"><mml:mi>ϕ</mml:mi></mml:math></inline-formula> as the image (<xref ref-type="bibr" rid="bib26">Kanitscheider et al., 2015b</xref>, Supp Equation 5 ). The orientation <inline-formula><mml:math id="inf20"><mml:mi>θ</mml:mi></mml:math></inline-formula> was normalized between 0 and 1. The orientation preference map of L4 neurons in V1 was generated using the formula from <xref ref-type="bibr" rid="bib27">Kaschube et al., 2010</xref> (Supp Equation 20) with average column spacing <inline-formula><mml:math id="inf21"><mml:mrow><mml:mi mathvariant="normal">Λ</mml:mi><mml:mo>=</mml:mo><mml:mn>0.2</mml:mn></mml:mrow></mml:math></inline-formula>.</p><p>Each network simulation was 20 sec long consisting of alternating OFF (300 ms) and ON (200 ms) intervals. During OFF intervals, spike trains of Layer 1 neurons were independent Poisson processes with rate <inline-formula><mml:math id="inf22"><mml:mrow><mml:msub><mml:mi>r</mml:mi><mml:mi>X</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mn>5</mml:mn></mml:mrow></mml:math></inline-formula> Hz. An image with a randomly selected orientation was presented during ON intervals. Spike counts during the ON intervals were used to compute the performance of different decoders and correlated variability. The first spike count in each simulation was excluded. For each parameter condition, the connectivity matrices were fixed for all simulations. The initial states of each neuron’s membrane potential were randomized in each simulation. All simulations were performed on the CNBC Cluster in the University of Pittsburgh. All simulations were written in a combination of C and Matlab (Matlab R 2015a, Mathworks). The differential equations of the neuron model were solved using the forward Euler method with time step <inline-formula><mml:math id="inf23"><mml:mn>0.01</mml:mn></mml:math></inline-formula> ms.</p></sec><sec id="s4-8"><title>Network model specific decoder</title><p>Let <inline-formula><mml:math id="inf24"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mrow><mml:mi mathvariant="bold">r</mml:mi></mml:mrow></mml:mrow></mml:mstyle></mml:math></inline-formula> be a vector of spike counts from all neurons on a single trial, <inline-formula><mml:math id="inf25"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mrow><mml:mi mathvariant="bold">f</mml:mi></mml:mrow></mml:mrow></mml:mstyle></mml:math></inline-formula> be the tuning curve function, and <inline-formula><mml:math id="inf26"><mml:mi mathvariant="normal">Σ</mml:mi></mml:math></inline-formula> be the covariance matrix. Consider a fine discrimination task of two orientations <inline-formula><mml:math id="inf27"><mml:mrow><mml:msup><mml:mi>θ</mml:mi><mml:mo>+</mml:mo></mml:msup><mml:mo>=</mml:mo><mml:mrow><mml:msub><mml:mi>θ</mml:mi><mml:mn>0</mml:mn></mml:msub><mml:mo>+</mml:mo><mml:mrow><mml:mi>d</mml:mi><mml:mo>⁢</mml:mo><mml:mi>θ</mml:mi></mml:mrow></mml:mrow></mml:mrow></mml:math></inline-formula> and <inline-formula><mml:math id="inf28"><mml:mrow><mml:msup><mml:mi>θ</mml:mi><mml:mo>-</mml:mo></mml:msup><mml:mo>=</mml:mo><mml:mrow><mml:msub><mml:mi>θ</mml:mi><mml:mn>0</mml:mn></mml:msub><mml:mo>-</mml:mo><mml:mrow><mml:mi>d</mml:mi><mml:mo>⁢</mml:mo><mml:mi>θ</mml:mi></mml:mrow></mml:mrow></mml:mrow></mml:math></inline-formula>. The specific decoder is a local linear estimator:<disp-formula id="equ2"><mml:math id="m2"><mml:mrow><mml:mrow><mml:mrow><mml:mover><mml:mi>θ</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow></mml:mrow><mml:mo>=</mml:mo><mml:msub><mml:mi>θ</mml:mi><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msup><mml:mrow><mml:mi mathvariant="bold">w</mml:mi></mml:mrow><mml:mrow><mml:mi>T</mml:mi></mml:mrow></mml:msup><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mi mathvariant="bold">r</mml:mi></mml:mrow><mml:mo>−</mml:mo><mml:mfrac><mml:mrow><mml:mrow><mml:mi mathvariant="bold">f</mml:mi></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msup><mml:mi>θ</mml:mi><mml:mrow><mml:mo>+</mml:mo></mml:mrow></mml:msup><mml:mo stretchy="false">)</mml:mo><mml:mo>+</mml:mo><mml:mrow><mml:mi mathvariant="bold">f</mml:mi></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msup><mml:mi>θ</mml:mi><mml:mrow><mml:mo>−</mml:mo></mml:mrow></mml:msup><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mn>2</mml:mn></mml:mfrac><mml:mo stretchy="false">)</mml:mo><mml:mo>.</mml:mo></mml:mrow></mml:math></disp-formula></p><p>The optimal weight to minimize the mean squared error over all trials, <inline-formula><mml:math id="inf29"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>E</mml:mi><mml:mo>=</mml:mo><mml:mo fence="false" stretchy="false">⟨</mml:mo><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mrow><mml:mover><mml:mi>θ</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mo>−</mml:mo><mml:mi>θ</mml:mi><mml:msup><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup><mml:mo fence="false" stretchy="false">⟩</mml:mo></mml:mrow></mml:mstyle></mml:math></inline-formula>, is<disp-formula id="equ3"><mml:math id="m3"><mml:mrow><mml:msubsup><mml:mrow><mml:mi mathvariant="bold">w</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">o</mml:mi><mml:mi mathvariant="normal">p</mml:mi><mml:mi mathvariant="normal">t</mml:mi></mml:mrow><mml:mrow><mml:mi>s</mml:mi></mml:mrow></mml:msubsup><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:msup><mml:mi mathvariant="normal">Σ</mml:mi><mml:mrow><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msup><mml:msup><mml:mrow><mml:mi mathvariant="bold">f</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">′</mml:mi></mml:mrow></mml:msup></mml:mrow><mml:mrow><mml:msup><mml:mrow><mml:mi mathvariant="bold">f</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">′</mml:mi></mml:mrow></mml:msup><mml:msup><mml:mi mathvariant="normal">Σ</mml:mi><mml:mrow><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msup><mml:msup><mml:mrow><mml:mi mathvariant="bold">f</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">′</mml:mi></mml:mrow></mml:msup></mml:mrow></mml:mfrac><mml:mo>.</mml:mo></mml:mrow></mml:math></disp-formula></p><p>The linear Fisher information is equivalent to the inverse of the variance of the optimal specific decoder:<disp-formula id="equ4"><mml:math id="m4"><mml:mrow><mml:mi>I</mml:mi><mml:mo>=</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mrow><mml:mrow><mml:mi mathvariant="normal">V</mml:mi><mml:mi mathvariant="normal">a</mml:mi><mml:mi mathvariant="normal">r</mml:mi></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mrow><mml:mrow><mml:mover><mml:mi>θ</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow></mml:mrow><mml:mrow><mml:mi>o</mml:mi><mml:mi>p</mml:mi><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:msup><mml:mi>θ</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msup><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mfrac><mml:mo>=</mml:mo><mml:msup><mml:mrow><mml:mi mathvariant="bold">f</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">′</mml:mi></mml:mrow></mml:msup><mml:msup><mml:mi mathvariant="normal">Σ</mml:mi><mml:mrow><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msup><mml:msup><mml:mrow><mml:mi mathvariant="bold">f</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">′</mml:mi></mml:mrow></mml:msup><mml:mo>.</mml:mo></mml:mrow></mml:math></disp-formula></p><p>The linear Fisher information is estimated with bias-correction (<xref ref-type="fig" rid="fig3">Figure 3B</xref>; <xref ref-type="bibr" rid="bib25">Kanitscheider et al., 2015a</xref>):<disp-formula id="equ5"><label>(1)</label><mml:math id="m5"><mml:mrow><mml:mrow><mml:mover><mml:mi>I</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msup><mml:mrow><mml:mi mathvariant="bold">f</mml:mi></mml:mrow><mml:mrow><mml:mo>+</mml:mo></mml:mrow></mml:msup><mml:mo>−</mml:mo><mml:msup><mml:mrow><mml:mi mathvariant="bold">f</mml:mi></mml:mrow><mml:mrow><mml:mo>−</mml:mo></mml:mrow></mml:msup><mml:msup><mml:mo stretchy="false">)</mml:mo><mml:mrow><mml:mi>T</mml:mi></mml:mrow></mml:msup></mml:mrow><mml:mrow><mml:mi>d</mml:mi><mml:mi>θ</mml:mi></mml:mrow></mml:mfrac><mml:msup><mml:mrow><mml:mo>(</mml:mo><mml:mfrac><mml:mrow><mml:msup><mml:mi mathvariant="normal">Σ</mml:mi><mml:mrow><mml:mo>+</mml:mo></mml:mrow></mml:msup><mml:mo>+</mml:mo><mml:msup><mml:mi mathvariant="normal">Σ</mml:mi><mml:mrow><mml:mo>−</mml:mo></mml:mrow></mml:msup></mml:mrow><mml:mn>2</mml:mn></mml:mfrac><mml:mo>)</mml:mo></mml:mrow><mml:mrow><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msup><mml:mfrac><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msup><mml:mrow><mml:mi mathvariant="bold">f</mml:mi></mml:mrow><mml:mrow><mml:mo>+</mml:mo></mml:mrow></mml:msup><mml:mo>−</mml:mo><mml:msup><mml:mrow><mml:mi mathvariant="bold">f</mml:mi></mml:mrow><mml:mrow><mml:mo>−</mml:mo></mml:mrow></mml:msup><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mrow><mml:mi>d</mml:mi><mml:mi>θ</mml:mi></mml:mrow></mml:mfrac><mml:mrow><mml:mo>(</mml:mo><mml:mfrac><mml:mrow><mml:mn>2</mml:mn><mml:msub><mml:mi>N</mml:mi><mml:mrow><mml:mi mathvariant="normal">t</mml:mi><mml:mi mathvariant="normal">r</mml:mi></mml:mrow></mml:msub><mml:mo>−</mml:mo><mml:mi>N</mml:mi><mml:mo>−</mml:mo><mml:mn>3</mml:mn></mml:mrow><mml:mrow><mml:mn>2</mml:mn><mml:msub><mml:mi>N</mml:mi><mml:mrow><mml:mi mathvariant="normal">t</mml:mi><mml:mi mathvariant="normal">r</mml:mi></mml:mrow></mml:msub><mml:mo>−</mml:mo><mml:mn>2</mml:mn></mml:mrow></mml:mfrac><mml:mo>)</mml:mo></mml:mrow><mml:mo>−</mml:mo><mml:mfrac><mml:mrow><mml:mn>2</mml:mn><mml:mi>N</mml:mi></mml:mrow><mml:mrow><mml:msub><mml:mi>N</mml:mi><mml:mrow><mml:mi mathvariant="normal">t</mml:mi><mml:mi mathvariant="normal">r</mml:mi></mml:mrow></mml:msub><mml:mi>d</mml:mi><mml:msup><mml:mi>θ</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:mfrac><mml:mo>,</mml:mo></mml:mrow></mml:math></disp-formula></p><p>where <inline-formula><mml:math id="inf30"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msup><mml:mrow><mml:mi mathvariant="bold">f</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msup></mml:mrow></mml:mstyle></mml:math></inline-formula> and <inline-formula><mml:math id="inf31"><mml:msup><mml:mi mathvariant="normal">Σ</mml:mi><mml:mi>i</mml:mi></mml:msup></mml:math></inline-formula> are the empirical mean and covariance, respectively, for <inline-formula><mml:math id="inf32"><mml:msup><mml:mi>θ</mml:mi><mml:mi>i</mml:mi></mml:msup></mml:math></inline-formula>, <inline-formula><mml:math id="inf33"><mml:mrow><mml:mi>i</mml:mi><mml:mo>∈</mml:mo><mml:mrow><mml:mo stretchy="false">{</mml:mo><mml:mo>+</mml:mo><mml:mo>,</mml:mo><mml:mo>-</mml:mo><mml:mo stretchy="false">}</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula>. The number of neurons sampled is <inline-formula><mml:math id="inf34"><mml:mi>N</mml:mi></mml:math></inline-formula>, and the number of trials for each <inline-formula><mml:math id="inf35"><mml:msup><mml:mi>θ</mml:mi><mml:mi>i</mml:mi></mml:msup></mml:math></inline-formula> is <inline-formula><mml:math id="inf36"><mml:msub><mml:mi>N</mml:mi><mml:mi>tr</mml:mi></mml:msub></mml:math></inline-formula>. In simulations, we used <inline-formula><mml:math id="inf37"><mml:mrow><mml:msub><mml:mi>θ</mml:mi><mml:mn>0</mml:mn></mml:msub><mml:mo>=</mml:mo><mml:mn>0.5</mml:mn></mml:mrow></mml:math></inline-formula> and <inline-formula><mml:math id="inf38"><mml:mrow><mml:mrow><mml:mi>d</mml:mi><mml:mo>⁢</mml:mo><mml:mi>θ</mml:mi></mml:mrow><mml:mo>=</mml:mo><mml:mn>0.01</mml:mn></mml:mrow></mml:math></inline-formula>. There were 58,500 spike counts in total for <inline-formula><mml:math id="inf39"><mml:msup><mml:mi>θ</mml:mi><mml:mo>+</mml:mo></mml:msup></mml:math></inline-formula> and <inline-formula><mml:math id="inf40"><mml:msup><mml:mi>θ</mml:mi><mml:mo>-</mml:mo></mml:msup></mml:math></inline-formula>.</p></sec><sec id="s4-9"><title>Network model general decoder</title><p>The general decoder is a complex linear estimator <inline-formula><mml:math id="inf41"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mrow><mml:mover><mml:mi>z</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mo>=</mml:mo><mml:msup><mml:mrow><mml:mi mathvariant="bold">w</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="bold">T</mml:mi></mml:mrow></mml:msup><mml:mrow><mml:mi mathvariant="bold">r</mml:mi></mml:mrow></mml:mrow></mml:mstyle></mml:math></inline-formula> (<xref ref-type="bibr" rid="bib54">Shamir and Sompolinsky, 2006</xref>) where <inline-formula><mml:math id="inf42"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mrow><mml:mi mathvariant="bold">w</mml:mi></mml:mrow></mml:mrow></mml:mstyle></mml:math></inline-formula> is fixed for all <inline-formula><mml:math id="inf43"><mml:mi>θ</mml:mi></mml:math></inline-formula>. The estimator <inline-formula><mml:math id="inf44"><mml:mover accent="true"><mml:mi>z</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:math></inline-formula> maps the population activity <inline-formula><mml:math id="inf45"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mrow><mml:mi mathvariant="bold">r</mml:mi></mml:mrow></mml:mrow></mml:mstyle></mml:math></inline-formula> in response to all orientations to a circle (<inline-formula><mml:math id="inf46"><mml:mrow><mml:mi>z</mml:mi><mml:mo>=</mml:mo><mml:msup><mml:mi>e</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo>⁢</mml:mo><mml:mi>θ</mml:mi></mml:mrow></mml:msup></mml:mrow></mml:math></inline-formula> in complex domain). The estimation of orientation is <inline-formula><mml:math id="inf47"><mml:mrow><mml:mover accent="true"><mml:mi>θ</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover><mml:mo>=</mml:mo><mml:mrow><mml:mtext>arg</mml:mtext><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mover accent="true"><mml:mi>z</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:math></inline-formula>. The optimal weight <inline-formula><mml:math id="inf48"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msubsup><mml:mrow><mml:mi mathvariant="bold">w</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">o</mml:mi><mml:mi mathvariant="normal">p</mml:mi><mml:mi mathvariant="normal">t</mml:mi></mml:mrow><mml:mrow><mml:mi>g</mml:mi></mml:mrow></mml:msubsup></mml:mrow></mml:mstyle></mml:math></inline-formula> that minimizes the mean squared error, <inline-formula><mml:math id="inf49"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>E</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mi mathvariant="bold">w</mml:mi></mml:mrow><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mo fence="false" stretchy="false">⟨</mml:mo><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mrow><mml:mover><mml:mi>z</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mo>−</mml:mo><mml:mi>z</mml:mi><mml:msup><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup><mml:msub><mml:mo fence="false" stretchy="false">⟩</mml:mo><mml:mrow><mml:mi>θ</mml:mi><mml:mo>,</mml:mo><mml:mrow><mml:mi mathvariant="bold">r</mml:mi></mml:mrow></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula>, averaged over all <inline-formula><mml:math id="inf50"><mml:mi>θ</mml:mi></mml:math></inline-formula> and trials of <inline-formula><mml:math id="inf51"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mrow><mml:mi mathvariant="bold">r</mml:mi></mml:mrow></mml:mrow></mml:mstyle></mml:math></inline-formula>, is<disp-formula id="equ6"><label>(2)</label><mml:math id="m6"><mml:mrow><mml:msubsup><mml:mrow><mml:mi mathvariant="bold">w</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">o</mml:mi><mml:mi mathvariant="normal">p</mml:mi><mml:mi mathvariant="normal">t</mml:mi></mml:mrow><mml:mrow><mml:mi>g</mml:mi></mml:mrow></mml:msubsup><mml:mo>=</mml:mo><mml:mo fence="false" stretchy="false">⟨</mml:mo><mml:mi mathvariant="normal">Σ</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>θ</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>+</mml:mo><mml:msup><mml:mrow><mml:mi mathvariant="bold">f</mml:mi><mml:mi mathvariant="bold">f</mml:mi></mml:mrow><mml:mrow><mml:mi>T</mml:mi></mml:mrow></mml:msup><mml:msubsup><mml:mo fence="false" stretchy="false">⟩</mml:mo><mml:mrow><mml:mi>θ</mml:mi></mml:mrow><mml:mrow><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msubsup><mml:mo fence="false" stretchy="false">⟨</mml:mo><mml:mrow><mml:mi mathvariant="bold">f</mml:mi></mml:mrow><mml:msup><mml:mi>e</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>θ</mml:mi></mml:mrow></mml:msup><mml:msub><mml:mo fence="false" stretchy="false">⟩</mml:mo><mml:mrow><mml:mi>θ</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo></mml:mrow></mml:math></disp-formula></p><p>The mean squared error of the optimal general decoder is<disp-formula id="equ7"><mml:math id="m7"><mml:mrow><mml:mi>E</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msubsup><mml:mrow><mml:mi mathvariant="bold">w</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">o</mml:mi><mml:mi mathvariant="normal">p</mml:mi><mml:mi mathvariant="normal">t</mml:mi></mml:mrow><mml:mrow><mml:mi>g</mml:mi></mml:mrow></mml:msubsup><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mo fence="false" stretchy="false">⟨</mml:mo><mml:mrow><mml:mi mathvariant="bold">f</mml:mi></mml:mrow><mml:msup><mml:mi>e</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>θ</mml:mi></mml:mrow></mml:msup><mml:msub><mml:mo fence="false" stretchy="false">⟩</mml:mo><mml:mrow><mml:mi>θ</mml:mi></mml:mrow></mml:msub><mml:msup><mml:mo stretchy="false">)</mml:mo><mml:mrow><mml:mo>∗</mml:mo></mml:mrow></mml:msup><mml:mo fence="false" stretchy="false">⟨</mml:mo><mml:mi mathvariant="normal">Σ</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>θ</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>+</mml:mo><mml:msup><mml:mrow><mml:mi mathvariant="bold">f</mml:mi><mml:mi mathvariant="bold">f</mml:mi></mml:mrow><mml:mrow><mml:mi>T</mml:mi></mml:mrow></mml:msup><mml:msubsup><mml:mo fence="false" stretchy="false">⟩</mml:mo><mml:mrow><mml:mi>θ</mml:mi></mml:mrow><mml:mrow><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msubsup><mml:mo stretchy="false">(</mml:mo><mml:mo fence="false" stretchy="false">⟨</mml:mo><mml:mrow><mml:mi mathvariant="bold">f</mml:mi></mml:mrow><mml:msup><mml:mi>e</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>θ</mml:mi></mml:mrow></mml:msup><mml:msub><mml:mo fence="false" stretchy="false">⟩</mml:mo><mml:mrow><mml:mi>θ</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:mo>,</mml:mo></mml:mrow></mml:math></disp-formula></p><p>where <inline-formula><mml:math id="inf52"><mml:mo>*</mml:mo></mml:math></inline-formula> denotes the conjugate transpose. Hence, the estimation error of <inline-formula><mml:math id="inf53"><mml:mover accent="true"><mml:mi>z</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:math></inline-formula> depends on both the covariance matrix, <inline-formula><mml:math id="inf54"><mml:mi mathvariant="normal">Σ</mml:mi></mml:math></inline-formula>, and tuning similarity, <inline-formula><mml:math id="inf55"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msup><mml:mrow><mml:mi mathvariant="bold">f</mml:mi><mml:mi mathvariant="bold">f</mml:mi></mml:mrow><mml:mrow><mml:mi>T</mml:mi></mml:mrow></mml:msup></mml:mrow></mml:mstyle></mml:math></inline-formula>. The performance of the general decoder is measured as <inline-formula><mml:math id="inf56"><mml:mrow><mml:msub><mml:mi>I</mml:mi><mml:mi mathvariant="normal">g</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mrow><mml:mrow><mml:mn>1</mml:mn><mml:mo>/</mml:mo><mml:mi>Var</mml:mi></mml:mrow><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mover accent="true"><mml:mi>θ</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:math></inline-formula> (<xref ref-type="fig" rid="fig3">Figure 3B</xref>). The estimation of <inline-formula><mml:math id="inf57"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>I</mml:mi><mml:mrow><mml:mi mathvariant="normal">g</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula> is<disp-formula id="equ8"><label>(3)</label><mml:math id="m8"><mml:mrow><mml:msub><mml:mrow><mml:mover><mml:mi>I</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi mathvariant="normal">g</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mrow><mml:mrow><mml:mi mathvariant="normal">V</mml:mi><mml:mi mathvariant="normal">a</mml:mi><mml:mi mathvariant="normal">r</mml:mi></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mi mathvariant="normal">a</mml:mi><mml:mi mathvariant="normal">r</mml:mi><mml:mi mathvariant="normal">g</mml:mi></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:msubsup><mml:mrow><mml:mi mathvariant="bold">w</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">o</mml:mi><mml:mi mathvariant="normal">p</mml:mi><mml:mi mathvariant="normal">t</mml:mi></mml:mrow><mml:mrow><mml:mi>g</mml:mi></mml:mrow></mml:msubsup><mml:msup><mml:mo stretchy="false">)</mml:mo><mml:mrow><mml:mi>T</mml:mi></mml:mrow></mml:msup><mml:mrow><mml:mi mathvariant="bold">r</mml:mi></mml:mrow><mml:mo stretchy="false">)</mml:mo><mml:mo>−</mml:mo><mml:mi>θ</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mfrac><mml:mfrac><mml:mrow><mml:msub><mml:mi>N</mml:mi><mml:mrow><mml:mi mathvariant="normal">t</mml:mi><mml:mi mathvariant="normal">r</mml:mi></mml:mrow></mml:msub><mml:mo>−</mml:mo><mml:mi>N</mml:mi><mml:mo>−</mml:mo><mml:mn>2</mml:mn></mml:mrow><mml:mrow><mml:msub><mml:mi>N</mml:mi><mml:mrow><mml:mi mathvariant="normal">t</mml:mi><mml:mi mathvariant="normal">r</mml:mi></mml:mrow></mml:msub><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:mfrac><mml:mo>,</mml:mo></mml:mrow></mml:math></disp-formula></p><p>where <inline-formula><mml:math id="inf58"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>N</mml:mi><mml:mrow><mml:mi mathvariant="normal">t</mml:mi><mml:mi mathvariant="normal">r</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula> is the total number of trials for all <inline-formula><mml:math id="inf59"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>θ</mml:mi></mml:mrow></mml:mstyle></mml:math></inline-formula>’s. In simulations, we used 50 <inline-formula><mml:math id="inf60"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>θ</mml:mi></mml:mrow></mml:mstyle></mml:math></inline-formula>’s uniformly spaced between 0 and 1. There were 117,000 trials in total for all <inline-formula><mml:math id="inf61"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>θ</mml:mi></mml:mrow></mml:mstyle></mml:math></inline-formula>’s.</p></sec><sec id="s4-10"><title>Dependence of network model decoders’ performance on correlated variability (<xref ref-type="fig" rid="fig3">Figure 3D</xref>)</title><p>We trained specific and general decoders on the same spike count dataset (<inline-formula><mml:math id="inf62"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mrow><mml:mi mathvariant="bold">r</mml:mi></mml:mrow></mml:mrow></mml:mstyle></mml:math></inline-formula>) in response to pairs of orientations, <inline-formula><mml:math id="inf63"><mml:msub><mml:mi>θ</mml:mi><mml:mn>1</mml:mn></mml:msub></mml:math></inline-formula> and <inline-formula><mml:math id="inf64"><mml:msub><mml:mi>θ</mml:mi><mml:mn>2</mml:mn></mml:msub></mml:math></inline-formula> (with difference <inline-formula><mml:math id="inf65"><mml:mrow><mml:mrow><mml:mi mathvariant="normal">Δ</mml:mi><mml:mo>⁢</mml:mo><mml:mi>θ</mml:mi></mml:mrow><mml:mo>=</mml:mo><mml:mn>0.04</mml:mn></mml:mrow></mml:math></inline-formula>). The specific decoder was trained on the <inline-formula><mml:math id="inf66"><mml:mi>N</mml:mi></mml:math></inline-formula>-dimensional space of neural responses, using a support vector machine model with two-fold cross-validation to linearly classify <inline-formula><mml:math id="inf67"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mrow><mml:mi mathvariant="bold">r</mml:mi></mml:mrow></mml:mrow></mml:mstyle></mml:math></inline-formula> for the two orientations. The general decoder first maps <inline-formula><mml:math id="inf68"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mrow><mml:mi mathvariant="bold">r</mml:mi></mml:mrow></mml:mrow></mml:mstyle></mml:math></inline-formula> to a two-dimensional plane <inline-formula><mml:math id="inf69"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mrow><mml:mover><mml:mi>z</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mo>=</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:msubsup><mml:mrow><mml:mi mathvariant="bold">w</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">o</mml:mi><mml:mi mathvariant="normal">p</mml:mi><mml:mi mathvariant="normal">t</mml:mi></mml:mrow><mml:mrow><mml:mi>g</mml:mi></mml:mrow></mml:msubsup><mml:msup><mml:mo stretchy="false">)</mml:mo><mml:mrow><mml:mi>T</mml:mi></mml:mrow></mml:msup><mml:mrow><mml:mi mathvariant="bold">r</mml:mi></mml:mrow></mml:mrow></mml:mstyle></mml:math></inline-formula> using the optimal weight <inline-formula><mml:math id="inf70"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msubsup><mml:mrow><mml:mi mathvariant="bold">w</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">o</mml:mi><mml:mi mathvariant="normal">p</mml:mi><mml:mi mathvariant="normal">t</mml:mi></mml:mrow><mml:mrow><mml:mi>g</mml:mi></mml:mrow></mml:msubsup></mml:mrow></mml:mstyle></mml:math></inline-formula> (<xref ref-type="disp-formula" rid="equ6">Equation 2</xref>) computed with the spike counts of all orientations. Then a two-dimensional support vector machine model with two-fold cross-validation was trained to linearly classify <inline-formula><mml:math id="inf71"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mrow><mml:mover><mml:mi>z</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow></mml:mrow></mml:mstyle></mml:math></inline-formula> for <inline-formula><mml:math id="inf72"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>θ</mml:mi><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula> and <inline-formula><mml:math id="inf73"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>θ</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula>. The correlated variability was computed from the spike counts data for <inline-formula><mml:math id="inf74"><mml:msub><mml:mi>θ</mml:mi><mml:mn>1</mml:mn></mml:msub></mml:math></inline-formula> of each pair. There were 200 samplings of <inline-formula><mml:math id="inf75"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>N</mml:mi><mml:mo>=</mml:mo><mml:mn>100</mml:mn></mml:mrow></mml:mstyle></mml:math></inline-formula> excitatory neurons from the V4 network, and 10 orientation pairs varying between 0 and 1. There were on average 2,340 trials for each <inline-formula><mml:math id="inf76"><mml:mi>θ</mml:mi></mml:math></inline-formula>.</p></sec><sec id="s4-11"><title>Factor analysis for network model</title><p>Let <inline-formula><mml:math id="inf77"><mml:mrow><mml:mi>x</mml:mi><mml:mo>∈</mml:mo><mml:msup><mml:mi>ℝ</mml:mi><mml:mrow><mml:mi>n</mml:mi><mml:mo>×</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:math></inline-formula> be the spike counts from <inline-formula><mml:math id="inf78"><mml:mi>n</mml:mi></mml:math></inline-formula> simultaneously recorded neurons. Factor analysis assumes that <inline-formula><mml:math id="inf79"><mml:mi>x</mml:mi></mml:math></inline-formula> is a multi-variable Gaussian process:<disp-formula id="equ9"><mml:math id="m9"><mml:mrow><mml:mi>x</mml:mi><mml:mo>∼</mml:mo><mml:mrow><mml:mi mathvariant="script">N</mml:mi></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>μ</mml:mi><mml:mo>,</mml:mo><mml:mi>L</mml:mi><mml:msup><mml:mi>L</mml:mi><mml:mrow><mml:mi>T</mml:mi></mml:mrow></mml:msup><mml:mo>+</mml:mo><mml:mi mathvariant="normal">Ψ</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></disp-formula></p><p>where <inline-formula><mml:math id="inf80"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>μ</mml:mi><mml:mo>∈</mml:mo><mml:msup><mml:mrow><mml:mi mathvariant="double-struck">R</mml:mi></mml:mrow><mml:mrow><mml:mi>n</mml:mi><mml:mo>×</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:mstyle></mml:math></inline-formula> is the mean spike counts, <inline-formula><mml:math id="inf81"><mml:mrow><mml:mi>L</mml:mi><mml:mo>∈</mml:mo><mml:msup><mml:mi>ℝ</mml:mi><mml:mrow><mml:mi>n</mml:mi><mml:mo>×</mml:mo><mml:mi>m</mml:mi></mml:mrow></mml:msup></mml:mrow></mml:math></inline-formula> is the loading matrix of the <inline-formula><mml:math id="inf82"><mml:mi>m</mml:mi></mml:math></inline-formula> latent variables and <inline-formula><mml:math id="inf83"><mml:mrow><mml:mi mathvariant="normal">Ψ</mml:mi><mml:mo>∈</mml:mo><mml:msup><mml:mi>ℝ</mml:mi><mml:mrow><mml:mi>n</mml:mi><mml:mo>×</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:math></inline-formula> is a diagonal matrix of independent variances for each neuron (<xref ref-type="bibr" rid="bib10">Cunningham and Yu, 2014</xref>). We chose <inline-formula><mml:math id="inf84"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>m</mml:mi><mml:mo>=</mml:mo><mml:mn>5</mml:mn></mml:mrow></mml:mstyle></mml:math></inline-formula> and computed the eigenvalues of <inline-formula><mml:math id="inf85"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>L</mml:mi><mml:msup><mml:mi>L</mml:mi><mml:mrow><mml:mi>T</mml:mi></mml:mrow></mml:msup></mml:mrow></mml:mstyle></mml:math></inline-formula>, <inline-formula><mml:math id="inf86"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>λ</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mspace width="thickmathspace"/><mml:mo stretchy="false">(</mml:mo><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mn>2</mml:mn><mml:mo>,</mml:mo><mml:mo>.</mml:mo><mml:mo>.</mml:mo><mml:mo>.</mml:mo><mml:mo>,</mml:mo><mml:mi>m</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mstyle></mml:math></inline-formula>, ranked in descending order. Spike counts were collected using a 200 ms window. There were on average 2,340 trials per attentional condition.</p></sec><sec id="s4-12"><title>Code availability</title><p>Computer code for all simulations and analysis of the resulting data will be available at <ext-link ext-link-type="uri" xlink:href="https://github.com/hcc11/GeneralDecoder">https://github.com/hcc11/GeneralDecoder</ext-link>; <ext-link ext-link-type="uri" xlink:href="https://archive.softwareheritage.org/swh:1:dir:62cad2827d02e9a8182868add2e8611d3057fef3;origin=https://github.com/hcc11/GeneralDecoder;visit=swh:1:snp:5be99563d03f04243ef8b8b4c47887f09bb1aab5;anchor=swh:1:rev:5056b409f2d943736b0478ff7ff38dd247b468b5">swh:1:rev:5056b409f2d943736b0478ff7ff38dd247b468b5</ext-link>, <xref ref-type="bibr" rid="bib38">Ni et al., 2022</xref>.</p></sec></sec></body><back><sec id="s5" sec-type="additional-information"><title>Additional information</title><fn-group content-type="competing-interest"><title>Competing interests</title><fn fn-type="COI-statement" id="conf1"><p>No competing interests declared</p></fn></fn-group><fn-group content-type="author-contribution"><title>Author contributions</title><fn fn-type="con" id="con1"><p>Conceptualization, Data curation, Formal analysis, Funding acquisition, Investigation, Methodology, Visualization, Writing – original draft, Writing – review and editing</p></fn><fn fn-type="con" id="con2"><p>Conceptualization, Formal analysis, Funding acquisition, Investigation, Methodology, Resources, Software, Visualization, Writing – original draft, Writing – review and editing</p></fn><fn fn-type="con" id="con3"><p>Conceptualization, Funding acquisition, Investigation, Methodology, Resources, Supervision, Writing – original draft, Writing – review and editing</p></fn><fn fn-type="con" id="con4"><p>Conceptualization, Funding acquisition, Investigation, Methodology, Resources, Supervision, Writing – original draft, Writing – review and editing</p></fn></fn-group><fn-group content-type="ethics-information"><title>Ethics</title><fn fn-type="other"><p>All animal procedures were approved by the Institutional Animal Care and Use Committees of the University of Pittsburgh and Carnegie Mellon University (Protocol #17071123).</p></fn></fn-group></sec><sec id="s6" sec-type="supplementary-material"><title>Additional files</title><supplementary-material id="transrepform"><label>Transparent reporting form</label><media mime-subtype="docx" mimetype="application" xlink:href="elife-67258-transrepform1-v1.docx"/></supplementary-material></sec><sec id="s7" sec-type="data-availability"><title>Data availability</title><p>Electrophysiological data analyzed in this manuscript are freely and publicly available at the Open Science Framework at <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.17605/OSF.IO/RN7TU">https://doi.org/10.17605/OSF.IO/RN7TU</ext-link>. Computer code for all simulations and analysis of the resulting data are freely and publicly available at <ext-link ext-link-type="uri" xlink:href="https://github.com/hcc11/GeneralDecoder">https://github.com/hcc11/GeneralDecoder</ext-link> (copy archived at <ext-link ext-link-type="uri" xlink:href="https://archive.softwareheritage.org/swh:1:dir:62cad2827d02e9a8182868add2e8611d3057fef3;origin=https://github.com/hcc11/GeneralDecoder;visit=swh:1:snp:5be99563d03f04243ef8b8b4c47887f09bb1aab5;anchor=swh:1:rev:5056b409f2d943736b0478ff7ff38dd247b468b5">swh:1:rev:5056b409f2d943736b0478ff7ff38dd247b468b5</ext-link>).</p><p>The following dataset was generated:</p><p><element-citation id="dataset1" publication-type="data" specific-use="isSupplementedBy"><person-group person-group-type="author"><name><surname>Ni</surname><given-names>Amy</given-names></name></person-group><year iso-8601-date="2022">2022</year><data-title>NiHuangDoironCohen2022</data-title><source>Open Science Framework</source><pub-id pub-id-type="doi">10.17605/OSF.IO/RN7TU</pub-id></element-citation></p></sec><ack id="ack"><title>Acknowledgements</title><p>We thank Douglas A Ruff, Joshua J Alberts, and Jen Symmonds for assistance with data collection. We thank Karen McCracken for technical assistance. We thank Alexandre Pouget and Douglas A Ruff for comments on a previous version of the manuscript.</p></ack><ref-list><title>References</title><ref id="bib1"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Abbott</surname><given-names>LF</given-names></name><name><surname>Dayan</surname><given-names>P</given-names></name></person-group><year iso-8601-date="1999">1999</year><article-title>The effect of correlated variability on the accuracy of a population code</article-title><source>Neural Computation</source><volume>11</volume><fpage>91</fpage><lpage>101</lpage><pub-id pub-id-type="doi">10.1162/089976699300016827</pub-id><pub-id pub-id-type="pmid">9950724</pub-id></element-citation></ref><ref id="bib2"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Averbeck</surname><given-names>BB</given-names></name><name><surname>Latham</surname><given-names>PE</given-names></name><name><surname>Pouget</surname><given-names>A</given-names></name></person-group><year iso-8601-date="2006">2006</year><article-title>Neural correlations, population coding and computation</article-title><source>Nature Reviews. Neuroscience</source><volume>7</volume><fpage>358</fpage><lpage>366</lpage><pub-id pub-id-type="doi">10.1038/nrn1888</pub-id><pub-id pub-id-type="pmid">16760916</pub-id></element-citation></ref><ref id="bib3"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Berkes</surname><given-names>P</given-names></name><name><surname>Turner</surname><given-names>RE</given-names></name><name><surname>Sahani</surname><given-names>M</given-names></name></person-group><year iso-8601-date="2009">2009</year><article-title>A structured model of video reproduces primary visual cortical organisation</article-title><source>PLOS Computational Biology</source><volume>5</volume><elocation-id>e1000495</elocation-id><pub-id pub-id-type="doi">10.1371/journal.pcbi.1000495</pub-id><pub-id pub-id-type="pmid">19730679</pub-id></element-citation></ref><ref id="bib4"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Brainard</surname><given-names>DH</given-names></name></person-group><year iso-8601-date="1997">1997</year><article-title>The psychophysics toolbox</article-title><source>Spatial Vision</source><volume>10</volume><fpage>433</fpage><lpage>436</lpage><pub-id pub-id-type="doi">10.1163/156856897X00357</pub-id><pub-id pub-id-type="pmid">9176952</pub-id></element-citation></ref><ref id="bib5"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Burgess</surname><given-names>AE</given-names></name><name><surname>Wagner</surname><given-names>RF</given-names></name><name><surname>Jennings</surname><given-names>RJ</given-names></name><name><surname>Barlow</surname><given-names>HB</given-names></name></person-group><year iso-8601-date="1981">1981</year><article-title>Efficiency of human visual signal discrimination</article-title><source>Science (New York, N.Y.)</source><volume>214</volume><fpage>93</fpage><lpage>94</lpage><pub-id pub-id-type="doi">10.1126/science.7280685</pub-id><pub-id pub-id-type="pmid">7280685</pub-id></element-citation></ref><ref id="bib6"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Clery</surname><given-names>S</given-names></name><name><surname>Cumming</surname><given-names>BG</given-names></name><name><surname>Nienborg</surname><given-names>H</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>Decision-related activity in macaque V2 for fine disparity discrimination is not compatible with optimal linear readout</article-title><source>The Journal of Neuroscience</source><volume>37</volume><fpage>715</fpage><lpage>725</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.2445-16.2016</pub-id><pub-id pub-id-type="pmid">28100751</pub-id></element-citation></ref><ref id="bib7"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Cohen</surname><given-names>MR</given-names></name><name><surname>Maunsell</surname><given-names>JHR</given-names></name></person-group><year iso-8601-date="2009">2009</year><article-title>Attention improves performance primarily by reducing interneuronal correlations</article-title><source>Nature Neuroscience</source><volume>12</volume><fpage>1594</fpage><lpage>1600</lpage><pub-id pub-id-type="doi">10.1038/nn.2439</pub-id><pub-id pub-id-type="pmid">19915566</pub-id></element-citation></ref><ref id="bib8"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Cohen</surname><given-names>MR</given-names></name><name><surname>Kohn</surname><given-names>A</given-names></name></person-group><year iso-8601-date="2011">2011</year><article-title>Measuring and interpreting neuronal correlations</article-title><source>Nature Neuroscience</source><volume>14</volume><fpage>811</fpage><lpage>819</lpage><pub-id pub-id-type="doi">10.1038/nn.2842</pub-id><pub-id pub-id-type="pmid">21709677</pub-id></element-citation></ref><ref id="bib9"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Cohen</surname><given-names>MR</given-names></name><name><surname>Maunsell</surname><given-names>JHR</given-names></name></person-group><year iso-8601-date="2011">2011</year><article-title>Using neuronal populations to study the mechanisms underlying spatial and feature attention</article-title><source>Neuron</source><volume>70</volume><fpage>1192</fpage><lpage>1204</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2011.04.029</pub-id><pub-id pub-id-type="pmid">21689604</pub-id></element-citation></ref><ref id="bib10"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Cunningham</surname><given-names>JP</given-names></name><name><surname>Yu</surname><given-names>BM</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>Dimensionality reduction for large-scale neural recordings</article-title><source>Nature Neuroscience</source><volume>17</volume><fpage>1500</fpage><lpage>1509</lpage><pub-id pub-id-type="doi">10.1038/nn.3776</pub-id><pub-id pub-id-type="pmid">25151264</pub-id></element-citation></ref><ref id="bib11"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Deneve</surname><given-names>S</given-names></name></person-group><year iso-8601-date="2012">2012</year><article-title>Making decisions with unknown sensory reliability</article-title><source>Frontiers in Neuroscience</source><volume>6</volume><elocation-id>75</elocation-id><pub-id pub-id-type="doi">10.3389/fnins.2012.00075</pub-id><pub-id pub-id-type="pmid">22679418</pub-id></element-citation></ref><ref id="bib12"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ecker</surname><given-names>AS</given-names></name><name><surname>Berens</surname><given-names>P</given-names></name><name><surname>Cotton</surname><given-names>RJ</given-names></name><name><surname>Subramaniyan</surname><given-names>M</given-names></name><name><surname>Denfield</surname><given-names>GH</given-names></name><name><surname>Cadwell</surname><given-names>CR</given-names></name><name><surname>Smirnakis</surname><given-names>SM</given-names></name><name><surname>Bethge</surname><given-names>M</given-names></name><name><surname>Tolias</surname><given-names>AS</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>State dependence of noise correlations in macaque primary visual cortex</article-title><source>Neuron</source><volume>82</volume><fpage>235</fpage><lpage>248</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2014.02.006</pub-id><pub-id pub-id-type="pmid">24698278</pub-id></element-citation></ref><ref id="bib13"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Goris</surname><given-names>RLT</given-names></name><name><surname>Movshon</surname><given-names>JA</given-names></name><name><surname>Simoncelli</surname><given-names>EP</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>Partitioning neuronal variability</article-title><source>Nature Neuroscience</source><volume>17</volume><fpage>858</fpage><lpage>865</lpage><pub-id pub-id-type="doi">10.1038/nn.3711</pub-id><pub-id pub-id-type="pmid">24777419</pub-id></element-citation></ref><ref id="bib14"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Gregoriou</surname><given-names>GG</given-names></name><name><surname>Rossi</surname><given-names>AF</given-names></name><name><surname>Ungerleider</surname><given-names>LG</given-names></name><name><surname>Desimone</surname><given-names>R</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>Lesions of prefrontal cortex reduce attentional modulation of neuronal responses and synchrony in V4</article-title><source>Nature Neuroscience</source><volume>17</volume><fpage>1003</fpage><lpage>1011</lpage><pub-id pub-id-type="doi">10.1038/nn.3742</pub-id><pub-id pub-id-type="pmid">24929661</pub-id></element-citation></ref><ref id="bib15"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Gu</surname><given-names>Y</given-names></name><name><surname>Liu</surname><given-names>S</given-names></name><name><surname>Fetsch</surname><given-names>CR</given-names></name><name><surname>Yang</surname><given-names>Y</given-names></name><name><surname>Fok</surname><given-names>S</given-names></name><name><surname>Sunkara</surname><given-names>A</given-names></name><name><surname>DeAngelis</surname><given-names>GC</given-names></name><name><surname>Angelaki</surname><given-names>DE</given-names></name></person-group><year iso-8601-date="2011">2011</year><article-title>Perceptual learning reduces interneuronal correlations in macaque visual cortex</article-title><source>Neuron</source><volume>71</volume><fpage>750</fpage><lpage>761</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2011.06.015</pub-id><pub-id pub-id-type="pmid">21867889</pub-id></element-citation></ref><ref id="bib16"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Haefner</surname><given-names>RM</given-names></name><name><surname>Gerwinn</surname><given-names>S</given-names></name><name><surname>Macke</surname><given-names>JH</given-names></name><name><surname>Bethge</surname><given-names>M</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>Inferring decoding strategies from choice probabilities in the presence of correlated variability</article-title><source>Nature Neuroscience</source><volume>16</volume><fpage>235</fpage><lpage>242</lpage><pub-id pub-id-type="doi">10.1038/nn.3309</pub-id><pub-id pub-id-type="pmid">23313912</pub-id></element-citation></ref><ref id="bib17"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Herrero</surname><given-names>JL</given-names></name><name><surname>Gieselmann</surname><given-names>MA</given-names></name><name><surname>Sanayei</surname><given-names>M</given-names></name><name><surname>Thiele</surname><given-names>A</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>Attention-induced variance and noise correlation reduction in macaque V1 is mediated by NMDA receptors</article-title><source>Neuron</source><volume>78</volume><fpage>729</fpage><lpage>739</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2013.03.029</pub-id><pub-id pub-id-type="pmid">23719166</pub-id></element-citation></ref><ref id="bib18"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Howell</surname><given-names>DC</given-names></name></person-group><year iso-8601-date="2007">2007</year><source>Statistical Methods for Psychology</source><publisher-loc>Belmont, CA</publisher-loc><publisher-name>Thomson Wadsworth</publisher-name></element-citation></ref><ref id="bib19"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Huang</surname><given-names>C</given-names></name><name><surname>Ruff</surname><given-names>DA</given-names></name><name><surname>Pyle</surname><given-names>R</given-names></name><name><surname>Rosenbaum</surname><given-names>R</given-names></name><name><surname>Cohen</surname><given-names>MR</given-names></name><name><surname>Doiron</surname><given-names>B</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>Circuit models of low-dimensional shared variability in cortical networks</article-title><source>Neuron</source><volume>101</volume><fpage>337</fpage><lpage>348</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2018.11.034</pub-id><pub-id pub-id-type="pmid">30581012</pub-id></element-citation></ref><ref id="bib20"><element-citation publication-type="preprint"><person-group person-group-type="author"><name><surname>Huang</surname><given-names>C</given-names></name><name><surname>Pouget</surname><given-names>A</given-names></name><name><surname>Doiron</surname><given-names>B</given-names></name></person-group><year iso-8601-date="2020">2020</year><article-title>Internally Generated Population Activity in Cortical Networks Hinders Information Transmission</article-title><source>bioRxiv</source><pub-id pub-id-type="doi">10.1101/2020.02.03.932723</pub-id></element-citation></ref><ref id="bib21"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Jeanne</surname><given-names>JM</given-names></name><name><surname>Sharpee</surname><given-names>TO</given-names></name><name><surname>Gentner</surname><given-names>TQ</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>Associative learning enhances population coding by inverting interneuronal correlation patterns</article-title><source>Neuron</source><volume>78</volume><fpage>352</fpage><lpage>363</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2013.02.023</pub-id><pub-id pub-id-type="pmid">23622067</pub-id></element-citation></ref><ref id="bib22"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Jin</surname><given-names>M</given-names></name><name><surname>Beck</surname><given-names>JM</given-names></name><name><surname>Glickfeld</surname><given-names>LL</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>Neuronal adaptation reveals a suboptimal decoding of orientation tuned populations in the mouse visual cortex</article-title><source>The Journal of Neuroscience</source><volume>39</volume><fpage>3867</fpage><lpage>3881</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.3172-18.2019</pub-id><pub-id pub-id-type="pmid">30833509</pub-id></element-citation></ref><ref id="bib23"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kafashan</surname><given-names>M</given-names></name><name><surname>Jaffe</surname><given-names>AW</given-names></name><name><surname>Chettih</surname><given-names>SN</given-names></name><name><surname>Nogueira</surname><given-names>R</given-names></name><name><surname>Arandia-Romero</surname><given-names>I</given-names></name><name><surname>Harvey</surname><given-names>CD</given-names></name><name><surname>Moreno-Bote</surname><given-names>R</given-names></name><name><surname>Drugowitsch</surname><given-names>J</given-names></name></person-group><year iso-8601-date="2021">2021</year><article-title>Scaling of sensory information in large neural populations shows signatures of information-limiting correlations</article-title><source>Nature Communications</source><volume>12</volume><elocation-id>473</elocation-id><pub-id pub-id-type="doi">10.1038/s41467-020-20722-y</pub-id><pub-id pub-id-type="pmid">33473113</pub-id></element-citation></ref><ref id="bib24"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kanashiro</surname><given-names>T</given-names></name><name><surname>Ocker</surname><given-names>GK</given-names></name><name><surname>Cohen</surname><given-names>MR</given-names></name><name><surname>Doiron</surname><given-names>B</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>Attentional modulation of neuronal variability in circuit models of cortex</article-title><source>eLife</source><volume>6</volume><elocation-id>e23978</elocation-id><pub-id pub-id-type="doi">10.7554/eLife.23978</pub-id><pub-id pub-id-type="pmid">28590902</pub-id></element-citation></ref><ref id="bib25"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kanitscheider</surname><given-names>I</given-names></name><name><surname>Coen-Cagli</surname><given-names>R</given-names></name><name><surname>Kohn</surname><given-names>A</given-names></name><name><surname>Pouget</surname><given-names>A</given-names></name></person-group><year iso-8601-date="2015">2015a</year><article-title>Measuring fisher information accurately in correlated neural populations</article-title><source>PLOS Computational Biology</source><volume>11</volume><elocation-id>e1004218</elocation-id><pub-id pub-id-type="doi">10.1371/journal.pcbi.1004218</pub-id><pub-id pub-id-type="pmid">26030735</pub-id></element-citation></ref><ref id="bib26"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kanitscheider</surname><given-names>I</given-names></name><name><surname>Coen-Cagli</surname><given-names>R</given-names></name><name><surname>Pouget</surname><given-names>A</given-names></name></person-group><year iso-8601-date="2015">2015b</year><article-title>Origin of information-limiting noise correlations</article-title><source>PNAS</source><volume>112</volume><fpage>E6973</fpage><lpage>E6982</lpage><pub-id pub-id-type="doi">10.1073/pnas.1508738112</pub-id><pub-id pub-id-type="pmid">26621747</pub-id></element-citation></ref><ref id="bib27"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kaschube</surname><given-names>M</given-names></name><name><surname>Schnabel</surname><given-names>M</given-names></name><name><surname>Lowel</surname><given-names>S</given-names></name><name><surname>Coppola</surname><given-names>DM</given-names></name><name><surname>White</surname><given-names>LE</given-names></name><name><surname>Wolf</surname><given-names>F</given-names></name></person-group><year iso-8601-date="2010">2010</year><article-title>Universality in the evolution of orientation columns in the visual cortex</article-title><source>Science (New York, N.Y.)</source><volume>330</volume><fpage>1113</fpage><lpage>1116</lpage><pub-id pub-id-type="doi">10.1126/science.1194869</pub-id></element-citation></ref><ref id="bib28"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kersten</surname><given-names>D</given-names></name></person-group><year iso-8601-date="1987">1987</year><article-title>Statistical efficiency for the detection of visual noise</article-title><source>Vision Research</source><volume>27</volume><fpage>1029</fpage><lpage>1040</lpage><pub-id pub-id-type="doi">10.1016/0042-6989(87)90016-2</pub-id></element-citation></ref><ref id="bib29"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kohn</surname><given-names>A</given-names></name><name><surname>Coen-Cagli</surname><given-names>R</given-names></name><name><surname>Kanitscheider</surname><given-names>I</given-names></name><name><surname>Pouget</surname><given-names>A</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Correlations and neuronal population information</article-title><source>Annual Review of Neuroscience</source><volume>39</volume><fpage>237</fpage><lpage>256</lpage><pub-id pub-id-type="doi">10.1146/annurev-neuro-070815-013851</pub-id></element-citation></ref><ref id="bib30"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Lin</surname><given-names>IC</given-names></name><name><surname>Okun</surname><given-names>M</given-names></name><name><surname>Carandini</surname><given-names>M</given-names></name><name><surname>Harris</surname><given-names>KD</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>The nature of shared cortical variability</article-title><source>Neuron</source><volume>87</volume><fpage>644</fpage><lpage>656</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2015.06.035</pub-id><pub-id pub-id-type="pmid">26212710</pub-id></element-citation></ref><ref id="bib31"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Lorteije</surname><given-names>JAM</given-names></name><name><surname>Zylberberg</surname><given-names>A</given-names></name><name><surname>Ouellette</surname><given-names>BG</given-names></name><name><surname>De Zeeuw</surname><given-names>CI</given-names></name><name><surname>Sigman</surname><given-names>M</given-names></name><name><surname>Roelfsema</surname><given-names>PR</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>The formation of hierarchical decisions in the visual cortex</article-title><source>Neuron</source><volume>87</volume><fpage>1344</fpage><lpage>1356</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2015.08.015</pub-id><pub-id pub-id-type="pmid">26365766</pub-id></element-citation></ref><ref id="bib32"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Luo</surname><given-names>TZ</given-names></name><name><surname>Maunsell</surname><given-names>JHR</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>Neuronal modulations in visual cortex are associated with only one of multiple components of attention</article-title><source>Neuron</source><volume>86</volume><fpage>1182</fpage><lpage>1188</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2015.05.007</pub-id><pub-id pub-id-type="pmid">26050038</pub-id></element-citation></ref><ref id="bib33"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Mayo</surname><given-names>JP</given-names></name><name><surname>Maunsell</surname><given-names>JHR</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Graded neuronal modulations related to visual spatial attention</article-title><source>The Journal of Neuroscience</source><volume>36</volume><fpage>5353</fpage><lpage>5361</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.0192-16.2016</pub-id><pub-id pub-id-type="pmid">27170131</pub-id></element-citation></ref><ref id="bib34"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Mitchell</surname><given-names>JF</given-names></name><name><surname>Sundberg</surname><given-names>KA</given-names></name><name><surname>Reynolds</surname><given-names>JH</given-names></name></person-group><year iso-8601-date="2009">2009</year><article-title>Spatial attention decorrelates intrinsic activity fluctuations in macaque area V4</article-title><source>Neuron</source><volume>63</volume><fpage>879</fpage><lpage>888</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2009.09.013</pub-id><pub-id pub-id-type="pmid">19778515</pub-id></element-citation></ref><ref id="bib35"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Moreno-Bote</surname><given-names>R</given-names></name><name><surname>Beck</surname><given-names>J</given-names></name><name><surname>Kanitscheider</surname><given-names>I</given-names></name><name><surname>Pitkow</surname><given-names>X</given-names></name><name><surname>Latham</surname><given-names>P</given-names></name><name><surname>Pouget</surname><given-names>A</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>Information-limiting correlations</article-title><source>Nature Neuroscience</source><volume>17</volume><fpage>1410</fpage><lpage>1417</lpage><pub-id pub-id-type="doi">10.1038/nn.3807</pub-id><pub-id pub-id-type="pmid">25195105</pub-id></element-citation></ref><ref id="bib36"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Nandy</surname><given-names>AS</given-names></name><name><surname>Nassi</surname><given-names>JJ</given-names></name><name><surname>Reynolds</surname><given-names>JH</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>Laminar organization of attentional modulation in macaque visual area V4</article-title><source>Neuron</source><volume>93</volume><fpage>235</fpage><lpage>246</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2016.11.029</pub-id><pub-id pub-id-type="pmid">27989456</pub-id></element-citation></ref><ref id="bib37"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ni</surname><given-names>AM</given-names></name><name><surname>Ruff</surname><given-names>DA</given-names></name><name><surname>Alberts</surname><given-names>JJ</given-names></name><name><surname>Symmonds</surname><given-names>J</given-names></name><name><surname>Cohen</surname><given-names>MR</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>Learning and attention reveal a general relationship between population activity and behavior</article-title><source>Science (New York, N.Y.)</source><volume>359</volume><fpage>463</fpage><lpage>465</lpage><pub-id pub-id-type="doi">10.1126/science.aao0284</pub-id><pub-id pub-id-type="pmid">29371470</pub-id></element-citation></ref><ref id="bib38"><element-citation publication-type="software"><person-group person-group-type="author"><name><surname>Ni</surname><given-names>AM</given-names></name><name><surname>Huang</surname><given-names>C</given-names></name><name><surname>Doiron</surname><given-names>B</given-names></name><name><surname>Cohen</surname><given-names>MR</given-names></name></person-group><year iso-8601-date="2022">2022</year><data-title>GeneralDecoder</data-title><version designator="swh:1:rev:5056b409f2d943736b0478ff7ff38dd247b468b5">swh:1:rev:5056b409f2d943736b0478ff7ff38dd247b468b5</version><source>Software Heritage</source><ext-link ext-link-type="uri" xlink:href="https://archive.softwareheritage.org/swh:1:dir:62cad2827d02e9a8182868add2e8611d3057fef3;origin=https://github.com/hcc11/GeneralDecoder;visit=swh:1:snp:5be99563d03f04243ef8b8b4c47887f09bb1aab5;anchor=swh:1:rev:5056b409f2d943736b0478ff7ff38dd247b468b5">https://archive.softwareheritage.org/swh:1:dir:62cad2827d02e9a8182868add2e8611d3057fef3;origin=https://github.com/hcc11/GeneralDecoder;visit=swh:1:snp:5be99563d03f04243ef8b8b4c47887f09bb1aab5;anchor=swh:1:rev:5056b409f2d943736b0478ff7ff38dd247b468b5</ext-link></element-citation></ref><ref id="bib39"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Nirenberg</surname><given-names>S</given-names></name><name><surname>Latham</surname><given-names>PE</given-names></name></person-group><year iso-8601-date="2003">2003</year><article-title>Decoding neuronal spike trains: how important are correlations?</article-title><source>PNAS</source><volume>100</volume><fpage>7348</fpage><lpage>7353</lpage><pub-id pub-id-type="doi">10.1073/pnas.1131895100</pub-id><pub-id pub-id-type="pmid">12775756</pub-id></element-citation></ref><ref id="bib40"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Panzeri</surname><given-names>S</given-names></name><name><surname>Harvey</surname><given-names>CD</given-names></name><name><surname>Piasini</surname><given-names>E</given-names></name><name><surname>Latham</surname><given-names>PE</given-names></name><name><surname>Fellin</surname><given-names>T</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>Cracking the neural code for sensory perception by combining statistics, intervention, and behavior</article-title><source>Neuron</source><volume>93</volume><fpage>491</fpage><lpage>507</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2016.12.036</pub-id><pub-id pub-id-type="pmid">28182905</pub-id></element-citation></ref><ref id="bib41"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Pelli</surname><given-names>DG</given-names></name></person-group><year iso-8601-date="1997">1997</year><article-title>The VideoToolbox software for visual psychophysics: transforming numbers into movies</article-title><source>Spatial Vision</source><volume>10</volume><fpage>437</fpage><lpage>442</lpage><pub-id pub-id-type="pmid">9176953</pub-id></element-citation></ref><ref id="bib42"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Pitkow</surname><given-names>X</given-names></name><name><surname>Liu</surname><given-names>S</given-names></name><name><surname>Angelaki</surname><given-names>DE</given-names></name><name><surname>DeAngelis</surname><given-names>GC</given-names></name><name><surname>Pouget</surname><given-names>A</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>How can single sensory neurons predict behavior?</article-title><source>Neuron</source><volume>87</volume><fpage>411</fpage><lpage>423</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2015.06.033</pub-id><pub-id pub-id-type="pmid">26182422</pub-id></element-citation></ref><ref id="bib43"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Posner</surname><given-names>MI</given-names></name></person-group><year iso-8601-date="1980">1980</year><article-title>Orienting of attention</article-title><source>The Quarterly Journal of Experimental Psychology</source><volume>32</volume><fpage>3</fpage><lpage>25</lpage><pub-id pub-id-type="doi">10.1080/00335558008248231</pub-id><pub-id pub-id-type="pmid">7367577</pub-id></element-citation></ref><ref id="bib44"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Rabinowitz</surname><given-names>NC</given-names></name><name><surname>Goris</surname><given-names>RL</given-names></name><name><surname>Cohen</surname><given-names>M</given-names></name><name><surname>Simoncelli</surname><given-names>EP</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>Attention stabilizes the shared gain of V4 populations</article-title><source>eLife</source><volume>4</volume><elocation-id>e08998</elocation-id><pub-id pub-id-type="doi">10.7554/eLife.08998</pub-id><pub-id pub-id-type="pmid">26523390</pub-id></element-citation></ref><ref id="bib45"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ruff</surname><given-names>DA</given-names></name><name><surname>Cohen</surname><given-names>MR</given-names></name></person-group><year iso-8601-date="2014">2014a</year><article-title>Attention can either increase or decrease spike count correlations in visual cortex</article-title><source>Nature Neuroscience</source><volume>17</volume><fpage>1591</fpage><lpage>1597</lpage><pub-id pub-id-type="doi">10.1038/nn.3835</pub-id><pub-id pub-id-type="pmid">25306550</pub-id></element-citation></ref><ref id="bib46"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ruff</surname><given-names>DA</given-names></name><name><surname>Cohen</surname><given-names>MR</given-names></name></person-group><year iso-8601-date="2014">2014b</year><article-title>Global cognitive factors modulate correlated response variability between V4 neurons</article-title><source>The Journal of Neuroscience</source><volume>34</volume><fpage>16408</fpage><lpage>16416</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.2750-14.2014</pub-id><pub-id pub-id-type="pmid">25471578</pub-id></element-citation></ref><ref id="bib47"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ruff</surname><given-names>DA</given-names></name><name><surname>Cohen</surname><given-names>MR</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Stimulus dependence of correlated variability across cortical areas</article-title><source>The Journal of Neuroscience</source><volume>36</volume><fpage>7546</fpage><lpage>7556</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.0504-16.2016</pub-id><pub-id pub-id-type="pmid">27413163</pub-id></element-citation></ref><ref id="bib48"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ruff</surname><given-names>DA</given-names></name><name><surname>Ni</surname><given-names>AM</given-names></name><name><surname>Cohen</surname><given-names>MR</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>Cognition as a window into neuronal population space</article-title><source>Annual Review of Neuroscience</source><volume>41</volume><fpage>77</fpage><lpage>97</lpage><pub-id pub-id-type="doi">10.1146/annurev-neuro-080317-061936</pub-id><pub-id pub-id-type="pmid">29799773</pub-id></element-citation></ref><ref id="bib49"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ruff</surname><given-names>DA</given-names></name><name><surname>Cohen</surname><given-names>MR</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>Simultaneous multi-area recordings suggest that attention improves performance by reshaping stimulus representations</article-title><source>Nature Neuroscience</source><volume>22</volume><fpage>1669</fpage><lpage>1676</lpage><pub-id pub-id-type="doi">10.1038/s41593-019-0477-1</pub-id><pub-id pub-id-type="pmid">31477898</pub-id></element-citation></ref><ref id="bib50"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Rumyantsev</surname><given-names>OI</given-names></name><name><surname>Lecoq</surname><given-names>JA</given-names></name><name><surname>Hernandez</surname><given-names>O</given-names></name><name><surname>Zhang</surname><given-names>Y</given-names></name><name><surname>Savall</surname><given-names>J</given-names></name><name><surname>Chrapkiewicz</surname><given-names>R</given-names></name><name><surname>Li</surname><given-names>J</given-names></name><name><surname>Zeng</surname><given-names>H</given-names></name><name><surname>Ganguli</surname><given-names>S</given-names></name><name><surname>Schnitzer</surname><given-names>MJ</given-names></name></person-group><year iso-8601-date="2020">2020</year><article-title>Fundamental bounds on the fidelity of sensory cortical coding</article-title><source>Nature</source><volume>580</volume><fpage>100</fpage><lpage>105</lpage><pub-id pub-id-type="doi">10.1038/s41586-020-2130-2</pub-id><pub-id pub-id-type="pmid">32238928</pub-id></element-citation></ref><ref id="bib51"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Seitz</surname><given-names>A</given-names></name><name><surname>Watanabe</surname><given-names>T</given-names></name></person-group><year iso-8601-date="2005">2005</year><article-title>A unified model for perceptual learning</article-title><source>Trends in Cognitive Sciences</source><volume>9</volume><fpage>329</fpage><lpage>334</lpage><pub-id pub-id-type="doi">10.1016/j.tics.2005.05.010</pub-id><pub-id pub-id-type="pmid">15955722</pub-id></element-citation></ref><ref id="bib52"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Semedo</surname><given-names>JD</given-names></name><name><surname>Zandvakili</surname><given-names>A</given-names></name><name><surname>Machens</surname><given-names>CK</given-names></name><name><surname>Yu</surname><given-names>BM</given-names></name><name><surname>Kohn</surname><given-names>A</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>Cortical areas interact through a communication subspace</article-title><source>Neuron</source><volume>102</volume><fpage>249</fpage><lpage>259</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2019.01.026</pub-id><pub-id pub-id-type="pmid">30770252</pub-id></element-citation></ref><ref id="bib53"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Shadlen</surname><given-names>MN</given-names></name><name><surname>Britten</surname><given-names>KH</given-names></name><name><surname>Newsome</surname><given-names>WT</given-names></name><name><surname>Movshon</surname><given-names>JA</given-names></name></person-group><year iso-8601-date="1996">1996</year><article-title>A computational analysis of the relationship between neuronal and behavioral responses to visual motion</article-title><source>The Journal of Neuroscience</source><volume>16</volume><fpage>1486</fpage><lpage>1510</lpage><pub-id pub-id-type="pmid">8778300</pub-id></element-citation></ref><ref id="bib54"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Shamir</surname><given-names>M</given-names></name><name><surname>Sompolinsky</surname><given-names>H</given-names></name></person-group><year iso-8601-date="2006">2006</year><article-title>Implications of neuronal diversity on population coding</article-title><source>Neural Computation</source><volume>18</volume><fpage>1951</fpage><lpage>1986</lpage><pub-id pub-id-type="doi">10.1162/neco.2006.18.8.1951</pub-id><pub-id pub-id-type="pmid">16771659</pub-id></element-citation></ref><ref id="bib55"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Verhoef</surname><given-names>BE</given-names></name><name><surname>Maunsell</surname><given-names>JHR</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>Attention-related changes in correlated neuronal activity arise from normalization mechanisms</article-title><source>Nature Neuroscience</source><volume>20</volume><fpage>969</fpage><lpage>977</lpage><pub-id pub-id-type="doi">10.1038/nn.4572</pub-id><pub-id pub-id-type="pmid">28553943</pub-id></element-citation></ref><ref id="bib56"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Williamson</surname><given-names>RC</given-names></name><name><surname>Cowley</surname><given-names>BR</given-names></name><name><surname>Litwin-Kumar</surname><given-names>A</given-names></name><name><surname>Doiron</surname><given-names>B</given-names></name><name><surname>Kohn</surname><given-names>A</given-names></name><name><surname>Smith</surname><given-names>MA</given-names></name><name><surname>Yu</surname><given-names>BM</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Scaling properties of dimensionality reduction for neural populations and network models</article-title><source>PLOS Computational Biology</source><volume>12</volume><elocation-id>e1005141</elocation-id><pub-id pub-id-type="doi">10.1371/journal.pcbi.1005141</pub-id><pub-id pub-id-type="pmid">27926936</pub-id></element-citation></ref><ref id="bib57"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Yan</surname><given-names>Y</given-names></name><name><surname>Rasch</surname><given-names>MJ</given-names></name><name><surname>Chen</surname><given-names>M</given-names></name><name><surname>Xiang</surname><given-names>X</given-names></name><name><surname>Huang</surname><given-names>M</given-names></name><name><surname>Wu</surname><given-names>S</given-names></name><name><surname>Li</surname><given-names>W</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>Perceptual training continuously refines neuronal population codes in primary visual cortex</article-title><source>Nature Neuroscience</source><volume>17</volume><fpage>1380</fpage><lpage>1387</lpage><pub-id pub-id-type="doi">10.1038/nn.3805</pub-id><pub-id pub-id-type="pmid">25195103</pub-id></element-citation></ref><ref id="bib58"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Zénon</surname><given-names>A</given-names></name><name><surname>Krauzlis</surname><given-names>RJ</given-names></name></person-group><year iso-8601-date="2012">2012</year><article-title>Attention deficits without cortical neuronal deficits</article-title><source>Nature</source><volume>489</volume><fpage>434</fpage><lpage>437</lpage><pub-id pub-id-type="doi">10.1038/nature11497</pub-id><pub-id pub-id-type="pmid">22972195</pub-id></element-citation></ref></ref-list></back><sub-article article-type="editor-report" id="sa0"><front-stub><article-id pub-id-type="doi">10.7554/eLife.67258.sa0</article-id><title-group><article-title>Editor's evaluation</article-title></title-group><contrib-group><contrib contrib-type="author"><name><surname>Ostojic</surname><given-names>Srdjan</given-names></name><role specific-use="editor">Reviewing Editor</role><aff><institution-wrap><institution-id institution-id-type="ror">https://ror.org/05a0dhs15</institution-id><institution>Ecole Normale Superieure Paris</institution></institution-wrap><country>France</country></aff></contrib></contrib-group><related-object id="sa0ro1" link-type="continued-by" object-id="10.1101/2020.10.08.331850" object-id-type="id" xlink:href="https://sciety.org/articles/activity/10.1101/2020.10.08.331850"/></front-stub><body><p>Empirical findings have established that experimental manipulations which increase perceptual accuracy also generally reduce the amount of shared variability between neurons in the visual cortex. To explain this observation, this study combines neurophysiology data and a network model of visual cortex and tests the hypothesis that perception relies on a &quot;general&quot; decoding strategy. The results suggest that the brain seeks to decode arbitrary changes in stimuli that appear in the environment.</p></body></sub-article><sub-article article-type="decision-letter" id="sa1"><front-stub><article-id pub-id-type="doi">10.7554/eLife.67258.sa1</article-id><title-group><article-title>Decision letter</article-title></title-group><contrib-group content-type="section"><contrib contrib-type="editor"><name><surname>Ostojic</surname><given-names>Srdjan</given-names></name><role>Reviewing Editor</role><aff><institution-wrap><institution-id institution-id-type="ror">https://ror.org/05a0dhs15</institution-id><institution>Ecole Normale Superieure Paris</institution></institution-wrap><country>France</country></aff></contrib></contrib-group></front-stub><body><boxed-text id="sa2-box1"><p>Our editorial process produces two outputs: i) <ext-link ext-link-type="uri" xlink:href="https://sciety.org/articles/activity/10.1101/2020.10.08.331850">public reviews</ext-link> designed to be posted alongside <ext-link ext-link-type="uri" xlink:href="https://www.biorxiv.org/content/10.1101/2020.10.08.331850v1">the preprint</ext-link> for the benefit of readers; ii) feedback on the manuscript for the authors, including requests for revisions, shown below. We also include an acceptance summary that explains what the editors found interesting or important about the work.</p></boxed-text><p><bold>Decision letter after peer review:</bold></p><p>Thank you for submitting your article &quot;A general decoding strategy explains the relationship between behavior and correlated variability&quot; for consideration by <italic>eLife</italic>. Your article has been reviewed by 3 peer reviewers, one of whom is a member of our Board of Reviewing Editors, and the evaluation has been overseen by Tirin Moore as the Senior Editor. The reviewers have opted to remain anonymous.</p><p>The reviewers have discussed their reviews with one another, and the Reviewing Editor has drafted this to help you prepare a revised submission.</p><p>Essential revisions:</p><p>A highly robust result when investigating how neural population activity is impacted by performance in a task is that the trial to trial correlations (noise correlations) between neurons is reduced as performance increases. However, the theoretical and experimental literature so far has failed to account for this robust link since reduced noise correlations do not systematically contribute to improved availability or transmission of information (often measured using decoding of stimulus identity). This paper sets out to address this discrepancy by proposing that the key to linking noise correlations to decoding and thus bridging the gap with performance is to rethink the decoders we use : instead of decoders optimized to the specific task imposed on the animal on any given trial (A vs B / B vs C / A vs C), they hypothesize that we should favor a decoder optimized for a general readout of stimulus properties (A vs B vs C).</p><p>To test this hypothesis, the authors use a combination of quantitative data analysis and mechanistic network modeling. Data were recorded from neuronal populations in area V4 of two monkeys trained to perform an orientation change detection task, where the magnitude of orientation change could vary across trials, and the change could happen at cued (attended) or uncued (unattended) locations in the visual field. The model, which extends previous work by the authors, reproduces many basic features of the data, and both the model and data offer support (with one exception, details below) for the hypothesis.</p><p>The reviewers agreed that this is a potentially important contribution, that addresses a widely observed, but puzzling, relation between perceptual performance and noise correlations. The clarity of the hypothesis, and the combination of data analysis and computational modelling are two essential strengths of the paper. Nonetheless, as detailed below, the reviewers believe the manuscript clarity could be further improved in several points, and some additional analysis of the data would provide more straightforward test of the hypothesis.</p><p>Essential revisions:</p><p>1. it would be important to verify that the model reproduces the correlation between noise and signal correlations since this is really a key argument leading to the author's hypothesis. One possibility would be to make a scatterplot of these two correlations for all neurons for both neural data and the model and for example compare slopes. The slope for the model could be shown for a range of levels of attentional modulation and for the neural data in attended vs unattended as they already do in fig2d of Fig2e. The authors could provide insight into the difference between the specific and general decoder by directly assessing the alignment between the decoders and the noise dimension. This could perhaps (depending on data noise) also be assessed for their physiological decoders of increasing generality (Fig3e).</p><p>2. Testing the hypothesis of the general decoder:</p><p>2.1 In the data, the authors compare mainly the specific (stimulus) decoder and the monkey's choice decoder. The general stimulus decoder is only considered in Figure 3f, because data across multiple orientations are available only for the cued condition, and therefore the general and specific decoders cannot be compared for changes between cued and uncued. Fair enough, though this could be stated more explicitly around Line 160. However, the hypothesized relation between mean correlations and performance should also be true within a fixed attention condition (cued), comparing sessions with larger vs. smaller correlation. In other words, if the hypothesis is correct, you should find that performance of the &quot;most general&quot; decoder (as in Figure 3f) correlates negatively with average noise correlations, across sessions, more so than the &quot;most specific&quot; decoder. If there is enough data to identify this trend, it could strengthen the conclusions, because Figure 3c per se is not particularly overwhelming, and this reviewer is not sure that the correlation is significant for cued alone or uncued alone data, despite the fact that the range of noise correlation values within each condition is comparable to the range across conditions.</p><p>2.2 The analysis in fig3F provides a strong second line of argument in favor of the hypothesis. However, a lot hangs on the two points for &quot;1 ori&quot;. This is because the authors restricted analysis to using the 4th orientation as a reference. It seems possible that this analysis could be repeated for other orientations apart from the 3rd on which the monkey data is trained so as to augment the number of points and bring out the relation more clearly.</p><p>2.3 In figure 3f, a more straightforward and precise comparison is to use the stimulus decoders to predict the choice, and test whether the more specific or the more general can predict choices more accurately.</p><p>3. The main goal of the manuscript is to determine the impact of noise correlations on various decoding schemes. The figures however only show how decoding co-varies with correlations, but a direct, more causal analysis of the effect of correlations on decoding seems to be missing. Such an analysis can be obtained by comparing decoding on simultaneously recorded activity with decoding on trial-shuffled activity, in which noise-correlations are removed. Related to this, the manuscript starts by stating that theoretical studies predict optimal decoding is independent of correlations. Yet, it is apparently never shown (using shuffles) that this prediction actually holds for the &quot;specific&quot; decoder. Conversely, it is not shown that the monkeys' or the general decoder are actually sensitive to removing correlations by shuffling.</p><p>4. Figure 3a: Why is the performance of the &quot;monkey's decoder&quot; so low on uncued trials? Is this fully explained by a change in the magnitude of correlations (ie would shuffling single trials in the cued trials lead to such a large decrease)? Or is it due to some other mechanism?</p><p>On a related note, how different are the four different decoders (specific/monkey, cued/uncued)? It would be interesting to see how much they overlap. More generally, the authors should discuss the alternative that attention modulates also the readout/decoding weights, rather than or in addition to modulating V4 activity. And also, that the decoder is just suboptimal, not suboptimal locally because optimized for generality. For instance, Figure 3a suggests that in the uncued condition there is lots of information in the neural activity, but the monkeys do not use it. In contrast, the general decoder in the model extracts a large fraction of the information (Figure 3b).</p><p>5. Quantifying the link between model and data:</p><p>5.1 the text providing motivation for the model could be improved. The motivation used in the manuscript is, essentially, that the model allows to extrapolate beyond the data (more stimuli, more repetitions, more neurons). That sounds weak, as the dangers of extrapolation beyond the range of the data are well known. A model that extrapolates beyond existing data is useful to design new experiments and test predictions, but this is not done here. Because the manuscript is about information and decoding, a better motivation is the fact that this model takes an actual image as input and produces tuning and covariance compatible with each other because they are constrained by an actual network that processes the input (as opposed to parametric models where tuning and covariance can be manipulated independently).</p><p>5.2 The ring structure, and the orientation of correlations (Figure 2b) seem to be key ingredients of the model, but are they based on data, or ad-hoc assumptions? L'179-181:&quot;we first mapped the neuronal activity to a 2d space&quot; – how was this done? What are the axes in Figure 2b? The correlation structure appears to be organized in 2d, how can one then understand the 1d changes in Figure 2f?</p><p>5.3 In the model, the specific decoder is quite strongly linked to correlated variability and the improvement of the general decoder is clear but incremental (0.66 vs 0.83) whereas in the data there really is no correlation at all (Figure 3c). This is a bit problematic because the authors begin by stating that specific decoders cannot explain the link between noise correlations and accuracy but their specific decoder clearly shows a link.</p><p>It may be that the comparison is a bit unfair on the author's hypothesis precisely because of the huge power provided by the model. In order to compare the magnitude of the effect with physiological data, the authors could down sample the results from their model to the range of correlated variability from the monkey data. This may be revealing because the correlation does not seem quite linear and plateaus out close to the monkey's range.</p><p>5.4 Quantitative mismatch between model and data: the model is intended to offer only qualitative predictions, and this is fine. But the reviewers did not understand the argument (eg. Line 191 and Line 320) that a quantitative mismatch is a good thing… after all, if the range of changes in noise correlations is small for the data, isn't that the relevant range?</p><p>6. General decoder: Some parts of the text (eg. Line 60, Line 413) refer to a decoder that accounts for discrimination along different stimulus dimensions (eg. different values of orientation, or different color of the visual input). But the results of the manuscripts are about a general decoder for multiple values along a single stimulus dimension. The disconnect should be discussed, and the relation between these two scenarios explained.</p><p>7. Some statements in the discussion such as l 354 &quot;the relationship between behavior and mean correlated variability is explained by the hypothesis that observers use a general strategy&quot; should be qualified: the authors clearly show that the general decoder amplifies the relationship but in their own data the relationship exists already with a specific decoder.</p><p>8. Low-Dimensionality, beginning of Introduction and end of Discussion: experimentally, cortical activity is low-dimensional, and the proposed model captures that. But this reviewer does not understand the argument offered for why this matters for the relation between average correlations and performance. It seems that the dimensionality of the population covariance is not relevant: The point instead is that a change in amplitude of fluctuations along the f'f' direction necessarily impact performance of a &quot;specific&quot; decoder, whereas changes in all other dimensions can be accounted for by the appropriate weights of the &quot;specific&quot; decoder. On the other hand, changes in fluctuation strength along multiple directions may impact the performance of the &quot;general&quot; decoder. Please revise the text to clarify.</p><p>[Editors' note: further revisions were suggested prior to acceptance, as described below.]</p><p>Thank you for resubmitting your work entitled &quot;A general decoding strategy explains the relationship between behavior and correlated variability&quot; for further consideration by <italic>eLife</italic>. Your revised article has been evaluated by Tirin Moore (Senior Editor) and a Reviewing Editor.</p><p>The manuscript has been improved but there are some remaining issues that need to be addressed, as outlined below.</p><p>The authors declined to investigate the impact of shuffling data on their results and the reason given (they are not making claims whether correlations vs no correlation is better) doesn't seem relevant to the point raised. The key issue is that the text suggests a causal, mechanistic link between correlations and the decoder, but this need not to be the case. For instance, in the model, the authors manipulate noise correlations via the modulation of simulated top-down feedback. This may impact other aspects of network activity rather than only correlations, and these other aspects may be responsible for the modified decoding. Similarly, changes in attention levels may indirectly lead to changes in both correlations and decoding, without the two being in a direct causal relation.</p><p>It seems like an easy and straight-forward sanity check to see if the accuracy of the two decoders correlates with attention level after shuffling both training and test sets. If shuffling has no effect on the results, the causal statements would need to be amended and/or discussed.</p></body></sub-article><sub-article article-type="reply" id="sa2"><front-stub><article-id pub-id-type="doi">10.7554/eLife.67258.sa2</article-id><title-group><article-title>Author response</article-title></title-group></front-stub><body><disp-quote content-type="editor-comment"><p>Essential revisions:</p><p>A highly robust result when investigating how neural population activity is impacted by performance in a task is that the trial to trial correlations (noise correlations) between neurons is reduced as performance increases. However, the theoretical and experimental literature so far has failed to account for this robust link since reduced noise correlations do not systematically contribute to improved availability or transmission of information (often measured using decoding of stimulus identity). This paper sets out to address this discrepancy by proposing that the key to linking noise correlations to decoding and thus bridging the gap with performance is to rethink the decoders we use : instead of decoders optimized to the specific task imposed on the animal on any given trial (A vs B / B vs C / A vs C), they hypothesize that we should favor a decoder optimized for a general readout of stimulus properties (A vs B vs C).</p><p>To test this hypothesis, the authors use a combination of quantitative data analysis and mechanistic network modeling. Data were recorded from neuronal populations in area V4 of two monkeys trained to perform an orientation change detection task, where the magnitude of orientation change could vary across trials, and the change could happen at cued (attended) or uncued (unattended) locations in the visual field. The model, which extends previous work by the authors, reproduces many basic features of the data, and both the model and data offer support (with one exception, details below) for the hypothesis.</p><p>The reviewers agreed that this is a potentially important contribution, that addresses a widely observed, but puzzling, relation between perceptual performance and noise correlations. The clarity of the hypothesis, and the combination of data analysis and computational modelling are two essential strengths of the paper. Nonetheless, as detailed below, the reviewers believe the manuscript clarity could be further improved in several points, and some additional analysis of the data would provide more straightforward test of the hypothesis.</p><p>Essential revisions:</p><p>1. it would be important to verify that the model reproduces the correlation between noise and signal correlations since this is really a key argument leading to the author's hypothesis. One possibility would be to make a scatterplot of these two correlations for all neurons for both neural data and the model and for example compare slopes. The slope for the model could be shown for a range of levels of attentional modulation and for the neural data in attended vs unattended as they already do in fig2d of Fig2e. The authors could provide insight into the difference between the specific and general decoder by directly assessing the alignment between the decoders and the noise dimension. This could perhaps (depending on data noise) also be assessed for their physiological decoders of increasing generality (Fig3e).</p></disp-quote><p>We agree and we have incorporated this verification of the model into the manuscript. We modified the Results text as below to describe the new analysis and figures (lines 209 – 218 of the redlined manuscript; please see the redlined manuscript for all additions/deletions marked in red/strikethrough):</p><p>“Importantly, this model reproduces the correlation between noise and signal correlations (Figure 2—figure supplement 1) observed in electrophysiological data (Cohen and Maunsell, 2009; Cohen and Kohn, 2011). This correlation between the shared noise and the shared tuning is a key component of the general decoder hypothesis. We observed this strong relationship between noise and signal correlations in our recorded neurons (Figure 2—figure supplement 1A) as well as in our modeled data (Figure 2—figure supplement 1B). Using this model, we were able to measure the relationship between noise and signal correlations for varying strengths of attentional modulation. Consistent with the predictions of the general decoder hypothesis, attention weakened the relationship between noise and signal correlations (Figure 2—figure supplement 1C).”</p><p>As predicted by our published simulations (Ruff, Ni, and Cohen, 2019), neither the model nor the electrophysiological data provided insights into the difference between the specific and general decoder through a direct assessment of the alignment between the decoders and the noise dimension. The intuition is that recording from small subsets of a population provides only weak constraints on the actual weightings of each neuron (which determine the decoding dimensions). We therefore test predictions of these dimensions such as these relationships between signal and noise correlations and the decoding performance using different decoding strategies.</p><disp-quote content-type="editor-comment"><p>2. Testing the hypothesis of the general decoder:</p><p>2.1 In the data, the authors compare mainly the specific (stimulus) decoder and the monkey's choice decoder. The general stimulus decoder is only considered in Figure 3f, because data across multiple orientations are available only for the cued condition, and therefore the general and specific decoders cannot be compared for changes between cued and uncued. Fair enough, though this could be stated more explicitly around Line 160. However, the hypothesized relation between mean correlations and performance should also be true within a fixed attention condition (cued), comparing sessions with larger vs. smaller correlation. In other words, if the hypothesis is correct, you should find that performance of the &quot;most general&quot; decoder (as in Figure 3f) correlates negatively with average noise correlations, across sessions, more so than the &quot;most specific&quot; decoder. If there is enough data to identify this trend, it could strengthen the conclusions, because Figure 3c per se is not particularly overwhelming, and this reviewer is not sure that the correlation is significant for cued alone or uncued alone data, despite the fact that the range of noise correlation values within each condition is comparable to the range across conditions.</p></disp-quote><p>We appreciate this idea, but we did not have enough data to determine if the most general decoder that we could calculate with our current electrophysiological dataset was more negatively correlated with average noise correlations than our most specific decoder. We modified the manuscript to include additional analyses of Figure 3C within each individual attention condition, now illustrated in Figure 3—figure supplement 1. We also modified the manuscript to clarify what we could and could not address using our electrophysiological data alone, and to be more explicit about the critical role of our modeled data in addressing our hypothesis (this point is addressed further below in response to point 5.1). The manuscript modifications that address these points are noted below.</p><p>New text in the Results section (lines 361 – 364):</p><p>“Indeed, we found that just as the performance of the physiological monkey’s decoder was more strongly related to mean correlated variability than the performance of the physiological specific docoder (Figure 3C; see Figure 3—figure supplement 1 for analyses per attention condition)…”</p><p>New text in the Results section to clarify the limits of the electrophysiological data and the importance of our modeled data (lines 173 – 187):</p><p>“For our electrophysiological dataset, the behavioral task was designed to allow us to compare the specific and monkey’s decoders for an attention task with a range of orientation change amounts. To collect the necessary number of repetitions of behavioral trials per stimulus condition (with the limited total number of behavioral trials collected per day), we limited the number of different orientation change amounts to five (Figure 1B) and focused our uncued trials on the median orientation change. Our modeled dataset is critical to addressing our general decoder hypothesis as it allows us to step beyond the restraints of physiological data to model multiple attentional modulation levels for the full range of stimulus orientations. While the main purpose of the electrophysiological data was to analyze the monkey’s decoder, which could only be determined using the neuronal responses recorded from a behaving animal, the purpose of our modeled data is to compare the monkey’s decoder to an ideal general decoder, which can only be determined here using a model.”</p><p>Modified text in the Result section to state more explicitly that the more-general decoders could not be calculated for the uncued condition (lines 382 – 390):</p><p>“Finally, while the circuit model allowed us to analyze an ideal general decoder for the full range of stimulus orientations in multiple attention conditions (Figure 2B, C; a full ring of orientations in both unattended and attended conditions), as a sanity check, we used the physiological data from the cued attention condition only (a limited set of five orientation change amounts as illustrated in Figure 1B, in the cued condition only as the uncued condition focused on the median orientation change amount only) to test whether more-general decoders were more related to the monkey’s decoder than more-specific decoders. Would a decoder based on more stimulus orientations be more related to the monkey’s decoder than a decoder based on fewer stimulus orientations?”</p><disp-quote content-type="editor-comment"><p>2.2 The analysis in fig3F provides a strong second line of argument in favor of the hypothesis. However, a lot hangs on the two points for &quot;1 ori&quot;. This is because the authors restricted analysis to using the 4th orientation as a reference. It seems possible that this analysis could be repeated for other orientations apart from the 3rd on which the monkey data is trained so as to augment the number of points and bring out the relation more clearly.</p></disp-quote><p>We thank the reviewers for this idea and we have replaced our original Figure 3F with an updated plot that follows this suggestion exactly, performing the analysis for each of the other orientations apart from the third orientation:</p><p>We have updated the Methods to describe the new analysis, as below (lines 701 – 735):</p><p>“The most specific decoder tested in Figure 3F was trained to best differentiate the V4 population responses to one changed orientation from the V4 responses to the starting orientation presented immediately before it. The performance of this specific decoder was quantified as the leave-one-out cross-validated proportion of trials on which the decoder correctly identified whether the left-out orientation was that one changed orientation or the starting orientation. The one changed orientation that was tested was either the first, second, fourth, or fifth largest changed orientation (all but the median changed orientation, which was excluded from this analysis due to the inherent relationship between any decoder that included this orientation and the monkey’s decoder which was based on this orientation, as noted above). We calculated the performance of each decoder on each day of recording. We then calculated the across-days correlation between the performance of this specific decoder and the performance of the monkey’s decoder (described above). The correlation coefficient was plotted in the ‘1 ori’ column of Figure 3F for each monkey (<italic>n</italic> = 8 decoders; 1 decoder for each of the 4 included changed orientations, for each of the 2 monkeys).</p><p>We performed this same procedure for increasingly more-general decoders. The decoders illustrated in the ‘2 oris’ column were trained to best differentiate the V4 responses to two changed orientations from the V4 responses to the starting orientation. The two changed orientations used for each ‘2 oris’ decoder were chosen from the four possibilities: the first, second, fourth, and fifth (max) largest changed orientations (<italic>n</italic> = 48 decoders; 1 decoder for each of the 6 combinations of 2 changed orientations, tested on each of the 4 included changed orientations, for each of the 2 monkeys). We calculated the performance of each ‘2 oris’ decoder on the same task as above: identifying whether the orientation was the changed orientation (the first, second, fourth, or fifth largest changed orientation) or the starting orientation. Again, we calculated the across-days correlation between the performance of each ‘2 oris’ decoder and the performance of the monkey’s decoder.</p><p>Each ‘3 oris’ decoder was trained to best differentiate the V4 responses to three changed orientations from the V4 responses to the starting orientation (<italic>n</italic> = 32 decoders; 1 decoder for each of the 4 combinations of 3 changed orientations, tested on each of the 4 included changed orientations, for each of the 2 monkeys). The ‘4 oris’ decoder for each monkey was trained to best differentiate the V4 responses to four changed orientations from the V4 responses to the starting orientation (<italic>n</italic> = 8 decoders; 1 decoder for the 1 combination of 4 changed orientations, tested on each of the 4 included changed orientations, for each of the 2 monkeys).”</p><disp-quote content-type="editor-comment"><p>2.3 In figure 3f, a more straightforward and precise comparison is to use the stimulus decoders to predict the choice, and test whether the more specific or the more general can predict choices more accurately.</p></disp-quote><p>We thank the reviewers for this suggestion and have added a new figure (Figure 3G) that illustrates the results of this analysis comparing whether the specific or more-general decoders predict the monkey’s trial-by-trial choices more accurately:</p><p>The Figure 3G legend is as below (lines 343 – 347):</p><p>“Figure 3… (G) The more general the decoder (<italic>x</italic>-axis), the better its performance predicting the monkey’s choices on the median changed orientation trials (<italic>y</italic>-axis; the proportion of leave-one-out trials in which the decoder correctly predicted the monkey’s decision as to whether the orientation was the starting orientation or the median changed orientation). Conventions as in (F) (see Methods for <italic>n</italic> values).”</p><p>We added the following to the Results section (lines 402 – 404):</p><p>“Further, the more general the decoder, the better it predicted the monkey’s trial-by-trial choices on the median changed orientation trials (Figure 3G).”</p><p>We have updated the Methods section of the manuscript to describe this modified analysis, as below (lines 736 – 749):</p><p>“For Figure 3G, we performed analyses similar to those performed for Figure 3F, in that we tested each stimulus decoder: ‘1 ori’ decoders (<italic>n</italic> = 8 decoders; 1 specific decoder for either the first, second, fourth, or fifth largest changed orientation, for each of the 2 monkeys), ‘2 oris’ decoders (<italic>n</italic> = 12 decoders; 1 decoder for each of the 6 combinations of 2 changed orientations, for each of the 2 monkeys), ‘3 oris’ decoders (<italic>n</italic> = 8 decoders; 1 decoder for each of the 4 combinations of 3 changed orientations, for each of the 2 monkeys), and ‘4 oris’ decoders (<italic>n</italic> = 2 decoders; 1 decoder for the 1 combination of 4 changed orientations, for each of the 2 monkeys). However, unlike in Figure 3F, where the performance of the stimulus decoders was compared to the performance of the monkey’s decoder on the median orientation-change trials, here we calculated the performance of the stimulus decoder when tasked with predicting the trial-by-trial choices that the monkey made on the median orientation-change trials. We plotted the proportion of leave-one-out trials in which each decoder correctly predicted the monkey’s choice as to whether the orientation was the starting orientation or the median changed orientation.”</p><disp-quote content-type="editor-comment"><p>3. The main goal of the manuscript is to determine the impact of noise correlations on various decoding schemes. The figures however only show how decoding co-varies with correlations, but a direct, more causal analysis of the effect of correlations on decoding seems to be missing. Such an analysis can be obtained by comparing decoding on simultaneously recorded activity with decoding on trial-shuffled activity, in which noise-correlations are removed. Related to this, the manuscript starts by stating that theoretical studies predict optimal decoding is independent of correlations. Yet, it is apparently never shown (using shuffles) that this prediction actually holds for the &quot;specific&quot; decoder. Conversely, it is not shown that the monkeys' or the general decoder are actually sensitive to removing correlations by shuffling.</p></disp-quote><p>We understand the spirit of this suggestion. But, we do feel that the goal of this study is to understand implications of the relationship between noise correlations and decoder performance. We purposely do not make claims about the utility of noise correlations relative to hypothetical situations in which there are no correlations, because we suspect those are physiologically impossible (and are also impossible in the current incarnation of our model).</p><p>We have added the following Discussion section to address this point (lines 525 – 536):</p><p>“The purpose of this study was to investigate the relationship between mean correlated variability and a general decoder. We made an initial test of the overarching hypothesis that observers use a general decoding strategy in feature-rich environments by testing whether a decoder optimized for a broader range of stimulus values better matched the decoder actually used by the monkeys than a specific decoder optimized for a narrower range of stimulus values. We purposefully did not make claims about the utility of correlated variability relative to hypothetical situations in which correlated variability does not exist in the responses of a group of neurons, as we suspect that this is not a physiologically realistic condition. Studies that causally manipulate the level of correlated variability in neuronal populations to measure the true physiological and behavioral effects of increasing or decreasing correlated variability levels, through pharmacological or genetic means, may provide important insights into the impact of correlated variability on various decoding strategies.”</p><disp-quote content-type="editor-comment"><p>4. Figure 3a: Why is the performance of the &quot;monkey's decoder&quot; so low on uncued trials? Is this fully explained by a change in the magnitude of correlations (ie would shuffling single trials in the cued trials lead to such a large decrease)? Or is it due to some other mechanism?</p><p>On a related note, how different are the four different decoders (specific/monkey, cued/uncued)? It would be interesting to see how much they overlap. More generally, the authors should discuss the alternative that attention modulates also the readout/decoding weights, rather than or in addition to modulating V4 activity. And also, that the decoder is just suboptimal, not suboptimal locally because optimized for generality. For instance, Figure 3a suggests that in the uncued condition there is lots of information in the neural activity, but the monkeys do not use it. In contrast, the general decoder in the model extracts a large fraction of the information (Figure 3b).</p></disp-quote><p>We have added the section below to the Discussion to better address these points, and have noted other possible explanations for the suboptimality of the monkey’s decoder (lines 428 – 447):</p><p>“A fixed readout mechanism</p><p>A prior study from our lab found that attention, rather than changing the neuronal weights of the observer’s decoder, reshaped neuronal population activity to better align with a fixed readout mechanism (Ruff and Cohen, 2019). To test whether the neuronal weights of the monkey’s decoder changed across attention conditions (attended versus unattended), Ruff and Cohen switched the neuronal weights across conditions, testing the stimulus information in one attention condition with the neuronal weights from the other. They found that even with the switched weights, the performance of the monkey’s decoder was still higher in the attended condition. The results of this study support the conclusion that attention reshapes neuronal activity so that a fixed readout mechanism can better read out stimulus information. In other words, differences in the performance of the monkey’s decoder across attention conditions may be due to differences in how well the neuronal activity aligns with a fixed decoder.</p><p>Our study extends the findings of Ruff and Cohen to test whether that fixed readout mechanism is determined by a general decoding strategy. Our findings support the hypothesis that observers use a general decoding strategy in the face of changing stimulus and task conditions. Our findings do not exclude other potential explanations for the suboptimality of the monkey’s decoder, nor do they exclude the possibility that attention modulates decoder neuronal weights. However, our findings together with those of Ruff and Cohen shed light on why neuronal decoders are suboptimal in a manner that aligns the fixed decoder axis with the correlated variability axis (Ni et al., 2018; Ruff et al., 2018).”</p><p>The section above references the following paper: Ruff DA and Cohen MR (2019) <italic>Nat Neurosci</italic> 22:1669-1676. Ruff and Cohen found similar levels of cued and uncued performance for area MT stimulus decoders and monkey decoders as the levels we found in area V4 (their Figure 3A) and concluded that the monkey decoder’s performance was so low in the uncued versus cued condition because attention reshapes neuronal activity so that more of the existing stimulus information can be used to guide behavior (their Figure 3B; also see their Figure 4B for similar results in V4).</p><disp-quote content-type="editor-comment"><p>5. Quantifying the link between model and data:</p><p>5.1 the text providing motivation for the model could be improved. The motivation used in the manuscript is, essentially, that the model allows to extrapolate beyond the data (more stimuli, more repetitions, more neurons). That sounds weak, as the dangers of extrapolation beyond the range of the data are well known. A model that extrapolates beyond existing data is useful to design new experiments and test predictions, but this is not done here. Because the manuscript is about information and decoding, a better motivation is the fact that this model takes an actual image as input and produces tuning and covariance compatible with each other because they are constrained by an actual network that processes the input (as opposed to parametric models where tuning and covariance can be manipulated independently).</p></disp-quote><p>We appreciate this point and have updated our manuscript as below.</p><p>We added the following section in the Results (lines 161 – 172):</p><p>“Here, we describe a circuit model that we designed to allow us to compare the specific and monkey’s decoders from our electrophysiological dataset to modeled ideal specific and general decoders. The primary benefit of our model is that it can take actual images as inputs and produce neuronal tuning and covariance that are compatible with each other because of constraints from the simulated network that processed the inputs (Huang et al., 2019). Parametric models in which tuning and covariance can be manipulated independently would not provide such constraints. In our model, the mean correlated variability of the population activity is restricted to very few dimensions, matching experimentally recorded data from visual cortex demonstrating that mean correlated variability occupies a low-dimensional subset of the full neuronal population space (Ecker et al., 2014; Goris et al., 2014; Huang et al., 2019; Kanashiro et al., 2017; Lin et al., 2015; Rabinowitz et al., 2015; Semedo et al., 2019; Williamson et al., 2016).”</p><p>We also removed the Results sections that suggested that the model allowed us to extrapolate beyond the data.</p><p>We modified the following section of the Discussion (lines 417 – 423):</p><p>“Our study also demonstrates the utility of combining electrophysiological and circuit modeling approaches to studying neural coding. Our model mimicked the correlated variability and effects of attention in our physiological data. Critically, our model produced neuronal tuning and covariance based on the constraints of an actual network capable of processing images as inputs. Using a circuit model allowed us to test a full range of stimulus orientations in multiple attention conditions, allowing us to test the effects of attention on a true general decoder for orientation.”</p><p>We also removed the Discussion section that suggested that a benefit of the model was extrapolating beyond the data.</p><disp-quote content-type="editor-comment"><p>5.2 The ring structure, and the orientation of correlations (Figure 2b) seem to be key ingredients of the model, but are they based on data, or ad-hoc assumptions? L'179-181:&quot;we first mapped the neuronal activity to a 2d space&quot; – how was this done? What are the axes in Figure 2b? The correlation structure appears to be organized in 2d, how can one then understand the 1d changes in Figure 2f?</p></disp-quote><p>We have modified the manuscript to clarify the above points, as below.</p><p>In the Results section (lines 198 – 208):</p><p>“As the basis for our modeled general decoder, we first mapped the <italic>n</italic>-dimensional neuronal activity of our model in response to the full range of orientations to a 2-dimensional space. Because the neurons were tuned for orientation, we could map the <italic>n</italic>-dimensional population responses to a ring (Figure 2B, C). The orientation of correlations (the shape of each color cloud in Figure 2B) was not an assumed parameter, and illustrates the outcome of the correlation structure and dimensionality modeled by our data. In Figure 2B, we can see that the fluctuations along the radial directions are much larger than those along other directions for a given orientation. This is consistent with the low-dimensional structure of the modeled neuronal activity. In our model, the fluctuations of the neurons, mapped to the radial direction on the ring, were more elongated in the unattended state (Figure 2B) than in the attended state (Figure 2C).”</p><p>The mapping was done by minimizing the distance between a linear readout, w<sup>T</sup> r, and a position on a ring with radius 1, (cos(theta), sin(theta)), for a given orientation theta. In the Methods section (lines 804 – 808):</p><p>We have modifed the Figure 2 legend and added that the axes in Figure 2B and C are arbitrary units (lines 242 – 248):</p><p>“Figure 2…(B, C) We mapped the <italic>n</italic>-dimensional neuronal activity of our model to a 2-dimensional space (a ring). Each dot represents the neuronal activity of the simulated population on a single trial and each color represents the trials for a given orientation. These fluctuations are more elongated in the (B) unattended state than in the (C) attended state. We then calculated the effects of these attentional changes on the performance of specific and general decoders (see Methods). The axes are arbitrary units.”</p><disp-quote content-type="editor-comment"><p>5.3 In the model, the specific decoder is quite strongly linked to correlated variability and the improvement of the general decoder is clear but incremental (0.66 vs 0.83) whereas in the data there really is no correlation at all (Figure 3c). This is a bit problematic because the authors begin by stating that specific decoders cannot explain the link between noise correlations and accuracy but their specific decoder clearly shows a link.</p><p>It may be that the comparison is a bit unfair on the author's hypothesis precisely because of the huge power provided by the model. In order to compare the magnitude of the effect with physiological data, the authors could down sample the results from their model to the range of correlated variability from the monkey data. This may be revealing because the correlation does not seem quite linear and plateaus out close to the monkey's range.</p></disp-quote><p>We appreciate this point and we have modified our manuscript to clarify that our focus is on whether the general decoder is more strongly linked to correlated variability than the specific decoder. We have modified the manuscript as below.</p><p>In the Results (lines 361 – 381):</p><p>“Indeed, we found that just as the performance of the physiological monkey’s decoder was more strongly related to mean correlated variability than the performance of the physiological specific docoder (Figure 3C; see Figure 3—figure supplement 1 for analyses per attention condition), the performance of the modeled general decoder was more strongly related to mean correlated variability than the performance of the modeled specific decoder (Figure 3D). We modeled much stronger relationships to correlated variability (Figure 3D) than observed with our physiological data (Figure 3C). We observed that the correlation with specific decoder performance was significant with the modeled data but not with the physiological data. This is not surprising as we saw attentional effects, albeit small ones, on specific decoder performance with both the physiological and the modeled data (Figure 3A, B). Even small attentional effects would result in a correlation between decoder performance and mean correlated variability with a large enough range of mean correlated variability values. It is possible that with enough electrophysiological data, the performance of the specific decoder would be significantly related to correlated variability, as well. As described above, our focus is not on whether the performance of any one decoder is significantly correlated with mean correlated variability, but on which decoder provides a better explanation of the frequently observed relationship between performance and mean correlated variability. The performance of the general decoder was more strongly related to mean correlated variability than the performance of the specific decoder.”</p><p>In the Discussion (lines 407 – 409):</p><p>“Our results suggest that the relationship between behavior and mean correlated variability is more consistent with observers using a more general strategy that employs the same neuronal weights for decoding any stimulus change.”</p><p>Additionally, we have analyzed just two attention conditions from Figure 3D and have plotted the results in <xref ref-type="fig" rid="sa2fig1">Author response image 1</xref>. We are happy to add <xref ref-type="fig" rid="sa2fig1">Author response image 1</xref> to the manuscript, but have not included it for now as we believe that our adjusted manuscript texts above better highlight that our goal was not to make a match between the electrophysiological and modeled datasets, but to illustrate that the general decoder is more strongly related to correlated variability than the specific decoder. In <xref ref-type="fig" rid="sa2fig1">Author response image 1</xref> are the results of our model analysis based on two attention conditions only:</p><fig id="sa2fig1" position="float"><label>Author response image 1.</label><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-67258-sa2-fig1-v1.tif"/></fig><disp-quote content-type="editor-comment"><p>5.4 Quantitative mismatch between model and data: the model is intended to offer only qualitative predictions, and this is fine. But the reviewers did not understand the argument (eg. Line 191 and Line 320) that a quantitative mismatch is a good thing… after all, if the range of changes in noise correlations is small for the data, isn't that the relevant range?</p></disp-quote><p>We agree with this point and we have modified the manuscript to focus on the primary benefits of the model. We have made the following changes.</p><p>We removed the section of text that argued that the quantitative mismatch was a good thing.</p><p>We removed the text that described the benefits of a quantitative mismatch.</p><disp-quote content-type="editor-comment"><p>6. General decoder: Some parts of the text (eg. Line 60, Line 413) refer to a decoder that accounts for discrimination along different stimulus dimensions (eg. different values of orientation, or different color of the visual input). But the results of the manuscripts are about a general decoder for multiple values along a single stimulus dimension. The disconnect should be discussed, and the relation between these two scenarios explained.</p></disp-quote><p>We thank the reviewers for this helpful suggestion. We have modified the manuscript to better clarify the relationship between our current study, which is an initial test of the general decoder hypothesis based on a single stimulus dimension, and the overarching idea of a general decoder for multiple stimulus dimensions.</p><p>In the Introduction (lines 71 – 82):</p><p>“Here, we report the results of an initial test of this overarching hypothesis, based on a single stimulus dimension. We used a simple, well-studied behavioral task to test whether a more-general decoder (optimized for a broader range of stimulus values along a single dimension) better explained the relationship between behavior and mean correlated variability than a more-specific decoder (optimized for a narrower range of stimulus values along a single dimension). Specifically, we used a well-studied orientation change-detection task (Cohen and Maunsell, 2009) to test whether a general decoder for the full range of stimulus orientations better explained the relationship between behavior and mean correlated variability than a specific decoder for the orientation change presented in the behavioral trial at hand.</p><p>This test based on a single stimulus dimension is an important initial test of the general decoder hypothesis because many of the studies that found that performance increased when mean correlated variability decreased used a change-detection task…”</p><p>In the Discussion (lines 450 – 459):</p><p>“We performed this initial test of the overarching general decoder hypothesis in the context of a change-detection task along a single stimulus dimension because this type of task was used in many of the studies that reported a relationship between perceptual performance and mean correlated variability (Cohen and Maunsell, 2009; 2011; Herrero et al., 2013; Luo and Maunsell, 2015; Mayo and Maunsell, 2016; Nandy et al., 2017; Ni et al., 2018; Ruff and Cohen, 2016; 2019; Verhoef and Maunsell, 2017; Yan et al., 2014; Zénon and Krauzlis, 2012). This simple and well-studied task provided an ideal initial test of our general decoder hypothesis.</p><p>This initial test of the general decoder hypothesis suggests that a more general decoding strategy may explain observations in studies that use a variety of behavioral and stimulus conditions.”</p><p>In the Discussion (lines 511 – 524):</p><p>“This initial study of the general decoder hypothesis tested this idea in the context of a visual environment in which stimulus values only changed along a single dimension. However, our overarching hypothesis is that observers use a general decoding strategy in the complex and feature-rich visual scenes encountered in natural environments. In everyday environments, visual stimuli can change rapidly and unpredictably along many stimulus dimensions. The hypothesis that such a truly general decoder explains the relationship between perceptual performance and mean correlated variability is suggested by our finding that the modeled general decoder for orientation was more strongly related to mean correlated variability than the modeled specific decoder (Figure 3D). Future tests of a general decoder for multiple stimulus features would be needed to determine if this decoding strategy is used in the face of multiple changing stimulus features. Further, such tests would need to consider alternative hypotheses for how sensory information is decoded when observing multiple aspects of a stimulus (Berkes et al., 2009; Deneve, 2012; Lorteije et al., 2015). Studies that use complex or naturalistic visual stimuli may be ideal for further investigations of this hypothesis.”</p><disp-quote content-type="editor-comment"><p>7. Some statements in the discussion such as l 354 &quot;the relationship between behavior and mean correlated variability is explained by the hypothesis that observers use a general strategy&quot; should be qualified: the authors clearly show that the general decoder amplifies the relationship but in their own data the relationship exists already with a specific decoder.</p></disp-quote><p>We have updated the Discussion section of the manuscript in several places to better qualify our conclusions, as described below.</p><p>In lines 407 – 409 (previously line 354 – 356):</p><p>“Our results suggest that the relationship between behavior and mean correlated variability is more consistent with observers using a more general strategy that employs the same neuronal weights for decoding any stimulus change.</p><p>In lines 414 – 416:</p><p>“Together, these results support the hypothesis that observers use a more general decoding strategy in scenarios that require flexibility to changing stimulus conditions.”</p><p>In lines 457 – 459:</p><p>“This initial test of the general decoder hypothesis suggests that a more general decoding strategy may explain observations in studies that use a variety of behavioral and stimulus conditions.”</p><disp-quote content-type="editor-comment"><p>8. Low-Dimensionality, beginning of Introduction and end of Discussion: experimentally, cortical activity is low-dimensional, and the proposed model captures that. But this reviewer does not understand the argument offered for why this matters for the relation between average correlations and performance. It seems that the dimensionality of the population covariance is not relevant: The point instead is that a change in amplitude of fluctuations along the f'f' direction necessarily impact performance of a &quot;specific&quot; decoder, whereas changes in all other dimensions can be accounted for by the appropriate weights of the &quot;specific&quot; decoder. On the other hand, changes in fluctuation strength along multiple directions may impact the performance of the &quot;general&quot; decoder. Please revise the text to clarify.</p></disp-quote><p>We appreciate this point and have updated the manuscript Introduction and Discussion to better explain our motivation for using a low-dimensional model. We clarify that our low-dimensional model is beneficial because experimentally recorded cortical activity is low-dimensional. Our changes are as below.</p><p>We modified the following text in the Introduction (lines 44 – 55):</p><p>“These observations comprise a paradox because changes in this simple measure should have a minimal effect on information coding. Recent theoretical work shows that neuronal population decoders that extract the maximum amount of sensory information for the specific task at hand can easily ignore mean correlated noise (Kafashan et al., 2021; Kanitscheider et al., 2015b; Moreno-Bote et al., 2014; Pitkow et al., 2015; Rumyantsev et al., 2020; for review, see Kohn et al., 2016). Decoders for the specific task at hand can ignore mean correlated variability because it does not corrupt the dimensions of neuronal population space that are most informative about the stimulus (Moreno-Bote et al., 2014).”</p><p>We added the following text describing that the model captures the low-dimensional nature of cortical activity, thus placing the emphasis on the fact that the model captures the low dimensionality, instead of on the relevance of this low dimensionality to the relationship between average correlations and performance (lines 163 – 172):</p><p>“The primary benefit of our model is that it can take actual images as inputs and produce neuronal tuning and covariance that are compatible with each other because of constraints from the simulated network that processed the inputs (Huang et al., 2019). Parametric models in which tuning and covariance can be manipulated independently would not provide such constraints. In our model, the mean correlated variability of the population activity is restricted to very few dimensions, matching experimentally recorded data from visual cortex demonstrating that mean correlated variability occupies a low-dimensional subset of the full neuronal population space (Ecker et al., 2014; Goris et al., 2014; Huang et al., 2019; Kanashiro et al., 2017; Lin et al., 2015; Rabinowitz et al., 2015; Semedo et al., 2019; Williamson et al., 2016).”</p><p>We modified the end of the Discussion as follows (lines 481 – 492):</p><p>“Our results address a paradox in the literature. Electrophysiological and theoretical evidence supports that there is a relationship between mean correlated variability and perceptual performance (Abbott and Dayan, 1999; Clery et al., 2017; Haefner et al., 2013; Jin et al., 2019; Ni et al., 2018; Ruff and Cohen, 2019; reviewed by Ruff et al., 2018). Yet, a specific decoding strategy in which different sets of neuronal weights are used to decode different stimulus changes cannot easily explain this relationship (Kafashan et al., 2021; Kanitscheider et al., 2015b; Moreno-Bote et al., 2014; Pitkow et al., 2015; Rumyantsev et al., 2020; reviewed by Kohn et al., 2016). This is because specific decoders of neuronal population activity can easily ignore changes in mean correlated noise (Moreno-Bote et al., 2014).”</p><p>[Editors' note: further revisions were suggested prior to acceptance, as described below.]</p><disp-quote content-type="editor-comment"><p>The manuscript has been improved but there are some remaining issues that need to be addressed, as outlined below.</p><p>The authors declined to investigate the impact of shuffling data on their results and the reason given (they are not making claims whether correlations vs no correlation is better) doesn't seem relevant to the point raised. The key issue is that the text suggests a causal, mechanistic link between correlations and the decoder, but this need not to be the case. For instance, in the model, the authors manipulate noise correlations via the modulation of simulated top-down feedback. This may impact other aspects of network activity rather than only correlations, and these other aspects may be responsible for the modified decoding. Similarly, changes in attention levels may indirectly lead to changes in both correlations and decoding, without the two being in a direct causal relation.</p><p>It seems like an easy and straight-forward sanity check to see if the accuracy of the two decoders correlates with attention level after shuffling both training and test sets. If shuffling has no effect on the results, the causal statements would need to be amended and/or discussed.</p></disp-quote><p>We have performed the shuffling analysis described above and have added a new figure, Figure 3—figure supplement 2.</p><p>We have added text to the Results section to describe the new figure, as below:</p><p>“… the performance of the modeled general decoder was more strongly related to mean correlated variability than the performance of the modeled specific decoder (Figure 3D; see Figure 3—figure supplement 2 for trial-shuffled analyses).”</p><p>Finally, we have added text to the Discussion section to describe the new shuffling analyses, as below:</p><p>“In our model, which was designed to mimic real data, attention changed many aspects of neural responses besides just correlated variability. It is therefore possible that any relationship between decoding performance and correlated variability is mostly caused by those concomitant changes. Therefore, we used the many trials in our modeled data to test the effects of randomly shuffling the trial order per modeled neuron. These shuffled data resulted in the modeled general and specific decoders becoming essentially indistinguishable in their relationships with the removed correlated variability (Figure 3—figure supplement 2), with those removed correlations essentially representing attention condition. The effects of attention on many aspects of neuronal population activity have been well documented, including effects on neuronal firing rates and on both individual and shared trial-to-trial response variability (Cohen and Maunsell, 2009; 2011; Herrero et al., 2013; Luo and Maunsell, 2015; Mayo and Maunsell, 2016; Mitchell et al., 2009; Nandy et al., 2017; Ni et al., 2018; Ruff and Cohen, 2014a; 2014b; 2016; 2019; Zénon and Krauzlis, 2012). The simulated neurons in our model captured many of these attention effects (Figure 2D-F; Huang et al., 2019). Much theoretical work has supported that in the presence of correlations between neuronal responses, specifically differential or information-limiting correlations, limits on decoding performance will be dominated by these correlations (Moreno-Bote et al., 2014; for review, see Kohn et al., 2016). Removing these correlations by shuffling the trials results in many changes; in particular, our trial-shuffled data demonstrate the well-documented linear growth in Fisher information that is expected with increasing numbers of neurons (Figure 3—figure supplement 2A-C; Averbeck et al., 2006; Kohn et al., 2016; Shadlen et al., 1996). Our trial-shuffled analysis illustrates that removing correlations results in decoder performance being dominated by other effects of attention on neuronal activity, such as the firing rates (gains) of the neurons. Our model reproduces the gain effects of attention on neuronal firing rates observed in electrophysiological data (Figure 2D) which, in the absence of correlations, increases the sensitivity of the population (Averbeck et al., 2006; Kohn et al., 2016; Shadlen et al., 1996). In summary, general and specific decoder performances had indistinguishable relationships with the amount of correlated variability removed by the trial shuffling (Figure 3—figure supplement 2D, E), suggesting that decoder performance became dominated by attention-related firing rate gains intrinsic to our model.</p></body></sub-article></article>