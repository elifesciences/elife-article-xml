<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD v1.2 20190208//EN"  "JATS-archivearticle1.dtd"><article article-type="research-article" dtd-version="1.2" xmlns:ali="http://www.niso.org/schemas/ali/1.0/" xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink"><front><journal-meta><journal-id journal-id-type="nlm-ta">elife</journal-id><journal-id journal-id-type="publisher-id">eLife</journal-id><journal-title-group><journal-title>eLife</journal-title></journal-title-group><issn pub-type="epub" publication-format="electronic">2050-084X</issn><publisher><publisher-name>eLife Sciences Publications, Ltd</publisher-name></publisher></journal-meta><article-meta><article-id pub-id-type="publisher-id">61927</article-id><article-id pub-id-type="doi">10.7554/eLife.61927</article-id><article-categories><subj-group subj-group-type="display-channel"><subject>Tools and Resources</subject></subj-group><subj-group subj-group-type="heading"><subject>Computational and Systems Biology</subject></subj-group><subj-group subj-group-type="heading"><subject>Evolutionary Biology</subject></subj-group></article-categories><title-group><article-title>Fast and flexible estimation of effective migration surfaces</article-title></title-group><contrib-group><contrib contrib-type="author" corresp="yes" equal-contrib="yes" id="author-201538"><name><surname>Marcus</surname><given-names>Joseph</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">https://orcid.org/0000-0002-0923-9881</contrib-id><email>jhmarcus@uchicago.edu</email><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="fn" rid="equal-contrib1">†</xref><xref ref-type="other" rid="fund1"/><xref ref-type="other" rid="fund2"/><xref ref-type="fn" rid="con1"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" corresp="yes" equal-contrib="yes" id="author-203042"><name><surname>Ha</surname><given-names>Wooseok</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">https://orcid.org/0000-0002-9069-854X</contrib-id><email>haywse@berkeley.edu</email><xref ref-type="aff" rid="aff2">2</xref><xref ref-type="fn" rid="equal-contrib1">†</xref><xref ref-type="other" rid="fund4"/><xref ref-type="other" rid="fund5"/><xref ref-type="fn" rid="con2"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" corresp="yes" equal-contrib="yes" id="author-203043"><name><surname>Barber</surname><given-names>Rina Foygel</given-names></name><email>rina@uchicago.edu</email><xref ref-type="aff" rid="aff3">3</xref><xref ref-type="fn" rid="equal-contrib2">‡</xref><xref ref-type="other" rid="fund6"/><xref ref-type="other" rid="fund7"/><xref ref-type="fn" rid="con3"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" corresp="yes" equal-contrib="yes" id="author-8412"><name><surname>Novembre</surname><given-names>John</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">https://orcid.org/0000-0001-5345-0214</contrib-id><email>jnovembre@uchicago.edu</email><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="aff" rid="aff4">4</xref><xref ref-type="fn" rid="equal-contrib2">‡</xref><xref ref-type="other" rid="fund3"/><xref ref-type="fn" rid="con4"/><xref ref-type="fn" rid="conf1"/></contrib><aff id="aff1"><label>1</label><institution>Department of Human Genetics, University of Chicago</institution><addr-line><named-content content-type="city">Chicago</named-content></addr-line><country>United States</country></aff><aff id="aff2"><label>2</label><institution>Department of Statistics, University of California, Berkeley</institution><addr-line><named-content content-type="city">Berkeley</named-content></addr-line><country>United States</country></aff><aff id="aff3"><label>3</label><institution>Department of Statistics, University of Chicago</institution><addr-line><named-content content-type="city">Chicago</named-content></addr-line><country>United States</country></aff><aff id="aff4"><label>4</label><institution>Department of Ecology and Evolution, University of Chicago</institution><addr-line><named-content content-type="city">Chicago</named-content></addr-line><country>United States</country></aff></contrib-group><contrib-group content-type="section"><contrib contrib-type="editor"><name><surname>Perry</surname><given-names>George H</given-names></name><role>Reviewing Editor</role><aff><institution>Pennsylvania State University</institution><country>United States</country></aff></contrib><contrib contrib-type="senior_editor"><name><surname>Perry</surname><given-names>George H</given-names></name><role>Senior Editor</role><aff><institution>Pennsylvania State University</institution><country>United States</country></aff></contrib></contrib-group><author-notes><fn fn-type="con" id="equal-contrib1"><label>†</label><p>These authors contributed equally to this work</p></fn><fn fn-type="con" id="equal-contrib2"><label>‡</label><p>These authors also contributed equally to this work</p></fn></author-notes><pub-date date-type="publication" publication-format="electronic"><day>30</day><month>07</month><year>2021</year></pub-date><pub-date pub-type="collection"><year>2021</year></pub-date><volume>10</volume><elocation-id>e61927</elocation-id><history><date date-type="received" iso-8601-date="2020-08-08"><day>08</day><month>08</month><year>2020</year></date><date date-type="accepted" iso-8601-date="2021-06-07"><day>07</day><month>06</month><year>2021</year></date></history><permissions><copyright-statement>© 2021, Marcus et al</copyright-statement><copyright-year>2021</copyright-year><copyright-holder>Marcus et al</copyright-holder><ali:free_to_read/><license xlink:href="http://creativecommons.org/licenses/by/4.0/"><ali:license_ref>http://creativecommons.org/licenses/by/4.0/</ali:license_ref><license-p>This article is distributed under the terms of the <ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/licenses/by/4.0/">Creative Commons Attribution License</ext-link>, which permits unrestricted use and redistribution provided that the original author and source are credited.</license-p></license></permissions><self-uri content-type="pdf" xlink:href="elife-61927-v1.pdf"/><abstract><p>Spatial population genetic data often exhibits ‘isolation-by-distance,’ where genetic similarity tends to decrease as individuals become more geographically distant. The rate at which genetic similarity decays with distance is often spatially heterogeneous due to variable population processes like genetic drift, gene flow, and natural selection. Petkova et al., 2016 developed a statistical method called Estimating Effective Migration Surfaces (EEMS) for visualizing spatially heterogeneous isolation-by-distance on a geographic map. While EEMS is a powerful tool for depicting spatial population structure, it can suffer from slow runtimes. Here, we develop a related method called Fast Estimation of Effective Migration Surfaces (FEEMS). FEEMS uses a Gaussian Markov Random Field model in a penalized likelihood framework that allows for efficient optimization and output of effective migration surfaces. Further, the efficient optimization facilitates the inference of migration parameters per edge in the graph, rather than per node (as in EEMS). With simulations, we show conditions under which FEEMS can accurately recover effective migration surfaces with complex gene-flow histories, including those with anisotropy. We apply FEEMS to population genetic data from North American gray wolves and show it performs favorably in comparison to EEMS, with solutions obtained orders of magnitude faster. Overall, FEEMS expands the ability of users to quickly visualize and interpret spatial structure in their data.</p></abstract><kwd-group kwd-group-type="author-keywords"><kwd>population genetics</kwd><kwd>graph learning</kwd><kwd>effective migration</kwd><kwd>optimization</kwd><kwd>spatial smoothing</kwd><kwd>data visualization</kwd></kwd-group><kwd-group kwd-group-type="research-organism"><title>Research organism</title><kwd>None</kwd></kwd-group><funding-group><award-group id="fund1"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/100000001</institution-id><institution>National Science Foundation</institution></institution-wrap></funding-source><award-id>DGE-1746045</award-id><principal-award-recipient><name><surname>Marcus</surname><given-names>Joseph</given-names></name></principal-award-recipient></award-group><award-group id="fund2"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/100000057</institution-id><institution>National Institute of General Medical Sciences</institution></institution-wrap></funding-source><award-id>T32GM007197</award-id><principal-award-recipient><name><surname>Marcus</surname><given-names>Joseph</given-names></name></principal-award-recipient></award-group><award-group id="fund3"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/100000057</institution-id><institution>National Institute of General Medical Sciences</institution></institution-wrap></funding-source><award-id>R01GM132383</award-id><principal-award-recipient><name><surname>Novembre</surname><given-names>John</given-names></name></principal-award-recipient></award-group><award-group id="fund4"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/100000001</institution-id><institution>National Science Foundation</institution></institution-wrap></funding-source><award-id>TRIPODS Program</award-id><principal-award-recipient><name><surname>Ha</surname><given-names>Wooseok</given-names></name></principal-award-recipient></award-group><award-group id="fund5"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/100006978</institution-id><institution>University of California Berkeley</institution></institution-wrap></funding-source><award-id>Institute for Data Science</award-id><principal-award-recipient><name><surname>Ha</surname><given-names>Wooseok</given-names></name></principal-award-recipient></award-group><award-group id="fund6"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/100000001</institution-id><institution>National Science Foundation</institution></institution-wrap></funding-source><award-id>DMS-1654076</award-id><principal-award-recipient><name><surname>Barber</surname><given-names>Rina Foygel</given-names></name></principal-award-recipient></award-group><award-group id="fund7"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/100000006</institution-id><institution>Office of Naval Research</institution></institution-wrap></funding-source><award-id>N00014-20-1-2337</award-id><principal-award-recipient><name><surname>Barber</surname><given-names>Rina Foygel</given-names></name></principal-award-recipient></award-group><funding-statement>The funders had no role in study design, data collection and interpretation, or the decision to submit the work for publication.</funding-statement></funding-group><custom-meta-group><custom-meta specific-use="meta-only"><meta-name>Author impact statement</meta-name><meta-value>Fast and flexible estimation of effective migration surfaces (FEEMS) is a new statistical method that can quickly infer and visualize patterns of migration from genetic data with spatial coordinates.</meta-value></custom-meta></custom-meta-group></article-meta></front><body><sec id="s1" sec-type="intro"><title>Introduction</title><p>The relationship between geography and genetics has had enduring importance in evolutionary biology (see <xref ref-type="bibr" rid="bib16">Felsenstein, 1982</xref>). One fundamental consideration is that individuals who live near one another tend to be more genetically similar than those who live far apart (<xref ref-type="bibr" rid="bib56">Wright, 1943</xref>; <xref ref-type="bibr" rid="bib57">Wright, 1946</xref>; <xref ref-type="bibr" rid="bib27">Malécot, 1948</xref>; <xref ref-type="bibr" rid="bib21">Kimura, 1953</xref>; <xref ref-type="bibr" rid="bib22">Kimura and Weiss, 1964</xref>). This phenomenon is often referred to as ‘isolation-by-distance’ (IBD) and has been shown to be a pervasive feature in spatial population genetic data across many species (<xref ref-type="bibr" rid="bib52">Slatkin, 1985</xref>; <xref ref-type="bibr" rid="bib11">Dobzhansky and Wright, 1943</xref>; <xref ref-type="bibr" rid="bib34">Meirmans, 2012</xref>). Statistical methods that use both measures of genetic variation and geographic coordinates to understand patterns of IBD have been widely applied (<xref ref-type="bibr" rid="bib7">Bradburd and Ralph, 2019</xref>; <xref ref-type="bibr" rid="bib3">Battey et al., 2020</xref>). One major challenge in these approaches is that the relationship between geography and genetics can be complex. Particularly, geographic features can influence migration in localized regions leading to spatially heterogeneous patterns of IBD (<xref ref-type="bibr" rid="bib7">Bradburd and Ralph, 2019</xref>).</p><p>Multiple approaches have been introduced to model spatially non-homogeneous IBD in population genetic data (<xref ref-type="bibr" rid="bib33">McRae, 2006</xref>; <xref ref-type="bibr" rid="bib14">Duforet‐Frebourg and Blum, 2014</xref>; <xref ref-type="bibr" rid="bib19">Hanks and Hooten, 2013</xref>; <xref ref-type="bibr" rid="bib42">Petkova et al., 2016</xref>; <xref ref-type="bibr" rid="bib6">Bradburd et al., 2018</xref>; <xref ref-type="bibr" rid="bib1">Al-Asadi et al., 2019</xref>; <xref ref-type="bibr" rid="bib49">Safner et al., 2011</xref>; <xref ref-type="bibr" rid="bib47">Ringbauer et al., 2018</xref>). Particularly relevant to our proposed approach is the work of <xref ref-type="bibr" rid="bib42">Petkova et al., 2016</xref> and <xref ref-type="bibr" rid="bib19">Hanks and Hooten, 2013</xref>. Both approaches model genetic distance using the ‘resistance distance’ on a weighted graph. This distance metric is inspired by concepts of effective resistance in circuit theory models, or alternatively understood as the commute time of a random walk on a weighted graph or as a Gaussian graphical model (specifically a conditional auto-regressive process) (<xref ref-type="bibr" rid="bib10">Chandra et al., 1996</xref>; <xref ref-type="bibr" rid="bib19">Hanks and Hooten, 2013</xref>; <xref ref-type="bibr" rid="bib48">Rue and Held, 2005</xref>). Additionally, the resistance distance approach is a computationally convenient and accurate approximation to spatial coalescent models (<xref ref-type="bibr" rid="bib33">McRae, 2006</xref>), although it has limitations in asymmetric migration settings (<xref ref-type="bibr" rid="bib26">Lundgren and Ralph, 2019</xref>).</p><p><xref ref-type="bibr" rid="bib19">Hanks and Hooten, 2013</xref> introduced a Bayesian model that uses measured ecological covariates, such as elevation, to predict genetic distances across sub-populations. Specifically, they use a graph-based model for genotypes observed at different spatial locations. Expected genetic distances across sub-populations in their model are given by resistance distances computed from the edge weights. They parameterize the edge weights of the graph to be a function of known biogeographic covariates, linking local geographic features to genetic variation across the landscape.</p><p>Concurrently, the Estimating Effective Migration Surfaces (EEMS) method was developed to help interpret and visualize non-homogeneous gene-flow on a geographic map (<xref ref-type="bibr" rid="bib41">Petkova, 2013</xref>; <xref ref-type="bibr" rid="bib42">Petkova et al., 2016</xref>). EEMS uses resistance distances to approximate the between-sub-population component of pairwise coalescent times in a ‘stepping-stone’ model of migration and genetic drift (<xref ref-type="bibr" rid="bib21">Kimura, 1953</xref>; <xref ref-type="bibr" rid="bib22">Kimura and Weiss, 1964</xref>). EEMS models the within-sub-population component of pairwise coalescent times, with a node-specific parameter. Instead of using known biogeographic covariates to connect geographic features to genetic variation as in <xref ref-type="bibr" rid="bib19">Hanks and Hooten, 2013</xref>, EEMS infers a set of edge weights (and diversity parameters) that explain the genetic distance data. The inference is based on a hierarchical Bayesian model and a Voronoi-tessellation-based prior to encourage piece-wise constant spatial smoothness in the fitted edge weights.</p><p>EEMS uses Markov Chain Monte Carlo (MCMC) and outputs a visualization of the posterior mean for effective migration and a measure of genetic diversity for every spatial position of the focal habitat. Regions with relatively low effective migration can be interpreted to have reduced gene-flow over time, whereas regions with relatively high migration can be interpreted as having elevated gene-flow. EEMS has been applied to multiple systems to describe spatial genetic structure, but despite EEMS’s advances in formulating a tractable solution to investigate spatial heterogeneity in IBD, the MCMC algorithm it uses can be slow to converge, in some cases leading to days of computation time for large datasets (<xref ref-type="bibr" rid="bib40">Peter et al., 2020</xref>).</p><p>The inference problems faced by EEMS and Hanks and Hooten are related to a growing area referred to as ‘graph learning’ (<xref ref-type="bibr" rid="bib13">Dong et al., 2019</xref>; <xref ref-type="bibr" rid="bib30">Mateos et al., 2019</xref>). In graph learning, a noisy signal is measured as a scalar value at a set of nodes from the graph, and the aim is then to infer non-negative edge weights that reflect how spatially ‘smooth’ the signal is with respect to the graph topology (<xref ref-type="bibr" rid="bib20">Kalofolias, 2016</xref>). In population genetic settings, this scalar could be an allele frequency measured at locations in a discrete spatial habitat with effective migration rates between sub-populations. Like the approach taken by <xref ref-type="bibr" rid="bib19">Hanks and Hooten, 2013</xref>, one widely used representation of smooth graph signals is to associate the smoothness property with a Gaussian graphical model where the precision matrix has the form of a graph Laplacian (<xref ref-type="bibr" rid="bib12">Dong et al., 2016</xref>; <xref ref-type="bibr" rid="bib15">Egilmez et al., 2016</xref>). The probabilistic model defined on the graph signal then naturally gives rise to a likelihood for the observed samples, and thus much of the literature in this area focuses on developing specialized algorithms to efficiently solve optimization problems that allow reconstruction of the underlying latent graph. For more information about graph learning and signal processing in general see the survey papers of <xref ref-type="bibr" rid="bib13">Dong et al., 2019</xref> and <xref ref-type="bibr" rid="bib30">Mateos et al., 2019</xref>.</p><p>To position the present work in comparison to the ‘graph learning’ literature, our contributions are twofold. First, in population genetics, it is impossible to collect individual genotypes across all the geographic locations and, as a result, we often work with many, often the majority, of nodes having missing data. As far as we are aware, none of the work in graph signal processing considers this scenario and thus their algorithms are not directly applicable to our setting. In addition, if the number of the observed nodes is much smaller than the number of nodes of a graph, one can project the large matrices associated with the graph to the space of observed nodes, therefore allowing for fast and efficient computation. Second, highly missing nodes in the observed signals can result in significant degradation of the quality of the reconstructed graph unless it is regularized properly. Motivated by the Voronoi-tessellation-based prior adopted in EEMS (<xref ref-type="bibr" rid="bib42">Petkova et al., 2016</xref>), we propose regularization that encourages spatial smoothness in the edge weights.</p><p>Building on advances in graph learning, we introduce a method, Fast Estimation of Effective Migration Surfaces (FEEMS), that uses optimization to obtain penalized-likelihood-based estimates of effective migration parameters. In contrast to EEMS which uses a node-specific parameterization of effective migration, we optimize over edge-specific parameters allowing for more flexible migration processes to be fit, such as spatial anisotropy, in which the migration process is not invariant to rotation of the coordinate system (e.g. migration is more extensive along a particular axis). Although we developed this model as a Gaussian Markov Random Field, the resulting likelihood has key similarities to the EEMS model, in that it is a Wishart-distribution that is a function of a genetic distance matrix. Expected genetic distances in both models can be interpreted as ‘resistance distances’ (<xref ref-type="bibr" rid="bib33">McRae, 2006</xref>).</p><p>To fit the model, rather than using MCMC, we develop a fast quasi-Newton optimization algorithm (<xref ref-type="bibr" rid="bib36">Nocedal and Wright, 2006</xref>) and a cross-validation approach for choosing the penalty parameter used in the penalized likelihood. We demonstrate the method using coalescent simulations and an application to a dataset of gray wolves from North America. The output is comparable to the results of EEMS but is provided in orders of magnitude less time. With this improvement in speed, FEEMS opens up the ability to perform fast exploratory data analysis of spatial population structure.</p></sec><sec id="s2" sec-type="results"><title>Results</title><sec id="s2-1"><title>Overview of FEEMS</title><p><xref ref-type="fig" rid="fig1">Figure 1</xref> shows a visual schematic of the FEEMS method. The input data are genotypes and spatial locations (e.g. latitudes and longitudes) for a set of individuals sampled across a geographic region. We construct a dense spatial grid embedded in geographic space where nodes represent sub-populations, and we assign individuals to nodes based on spatial proximity (see <xref ref-type="fig" rid="app1fig1">Appendix 1—figure 1</xref> for a visualization of the grid construction and node assignment procedure). The density of the grid is user defined and must be explored to appropriately balance model mis-specification and computational burden. As the density of the lattice increases, the model is similar to discrete approximations used for continuous spatial processes, but the increased density comes at the cost of computational complexity.</p><fig id="fig1" position="float"><label>Figure 1.</label><caption><title>Schematic of the FEEMS model: The full panel shows a schematic of going from the raw data (spatial coordinates and genotypes) through optimization of the edge weights, representing effective migration, to convergence of FEEMS to a local optima.</title><p>(<bold>A</bold>) Map of sample coordinates (black points) from a dataset of gray wolves from North America (<xref ref-type="bibr" rid="bib51">Schweizer et al., 2016</xref>). The input to FEEMS are latitude and longitude coordinates as well as genotype data for each sample. (<bold>B</bold>) The spatial graph edge weights after random initialization uniformly over the graph to begin the optimization algorithm. (<bold>C</bold>) The edge weights after 10 iterations of running FEEMS, when the algorithm has not converged yet. (<bold>D</bold>) The final output of FEEMS after the algorithm has fully converged. The output is annotated with important features of the visualization.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-61927-fig1-v1.tif"/></fig><p>Details on the FEEMS model are described in the Materials and methods section, however at a high level, we assume exchangeability of individuals within each sub-population and estimate allele frequencies, <inline-formula><mml:math id="inf1"><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi mathsize="80%">f</mml:mi><mml:mo mathsize="80%" stretchy="false">^</mml:mo></mml:mover><mml:mi mathsize="80%">j</mml:mi></mml:msub><mml:mo>⁢</mml:mo><mml:mrow><mml:mo maxsize="80%" minsize="80%">(</mml:mo><mml:mi mathsize="80%">k</mml:mi><mml:mo maxsize="80%" minsize="80%">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula>, for each sub-population, indexed by <inline-formula><mml:math id="inf2"><mml:mi mathsize="80%">k</mml:mi></mml:math></inline-formula>, and single nucleotide polymorphism (SNP), indexed by <inline-formula><mml:math id="inf3"><mml:mi mathsize="80%">j</mml:mi></mml:math></inline-formula>, under a simple Binomial sampling model. We also use the recorded sample sizes at each node to model the precision of the estimated allele frequency. With the estimated allele frequencies in hand, we model the data at each SNP using an approximate Gaussian model whose covariance is, up to constant factors, shared across all SNPs—in other words, after rescaling by SNP-specific variation factors, we assume that the set of observed frequencies at each SNP is an independent realization of the same spatial process. The latent frequency variables, <inline-formula><mml:math id="inf4"><mml:mrow><mml:msub><mml:mi mathsize="80%">f</mml:mi><mml:mi mathsize="80%">j</mml:mi></mml:msub><mml:mo>⁢</mml:mo><mml:mrow><mml:mo maxsize="80%" minsize="80%">(</mml:mo><mml:mi mathsize="80%">k</mml:mi><mml:mo maxsize="80%" minsize="80%">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula>, are modeled as a Gaussian Markov Random Field (GMRF) with a sparse precision matrix determined by the graph Laplacian and a set of residual variances that vary across SNPs. The pseudo-inverse of the graph Laplacian in a GMRF is inherently connected to the notion of resistance distance in an electrical circuit (<xref ref-type="bibr" rid="bib19">Hanks and Hooten, 2013</xref>) that is often used in population genetics to model the genetic differentiation between sub-populations (<xref ref-type="bibr" rid="bib33">McRae, 2006</xref>). The graph’s weighted edges, denoted by <inline-formula><mml:math id="inf5"><mml:msub><mml:mi mathsize="80%">w</mml:mi><mml:mrow><mml:mi mathsize="80%">i</mml:mi><mml:mo>⁢</mml:mo><mml:mi mathsize="80%">j</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> between nodes <inline-formula><mml:math id="inf6"><mml:mi mathsize="80%">i</mml:mi></mml:math></inline-formula> and <inline-formula><mml:math id="inf7"><mml:mi mathsize="80%">j</mml:mi></mml:math></inline-formula>, represent gene-flow between the sub-populations (<xref ref-type="bibr" rid="bib17">Friedman et al., 2008</xref>; <xref ref-type="bibr" rid="bib19">Hanks and Hooten, 2013</xref>; <xref ref-type="bibr" rid="bib42">Petkova et al., 2016</xref>). The Gaussian approximation has the advantage that we can analytically marginalize out the latent frequency variables. The resulting likelihood of the observed frequencies shares a number of similarities to that of EEMS (see Materials and methods).</p><p>To prevent over-fitting we use penalized maximum likelihood to estimate the edge weights of the graph. Our overall goal is thus to solve the following optimization problem:<disp-formula id="equ1"><mml:math id="m1"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mover><mml:mi mathvariant="bold-italic">w</mml:mi><mml:mo>^</mml:mo></mml:mover></mml:mrow><mml:mo>=</mml:mo><mml:munder><mml:mrow><mml:mi mathvariant="normal">a</mml:mi><mml:mi mathvariant="normal">r</mml:mi><mml:mi mathvariant="normal">g</mml:mi><mml:mi mathvariant="normal">m</mml:mi><mml:mi mathvariant="normal">i</mml:mi><mml:mi mathvariant="normal">n</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="bold-italic">l</mml:mi><mml:mo>≤</mml:mo><mml:mi mathvariant="bold-italic">w</mml:mi><mml:mo>≤</mml:mo><mml:mi mathvariant="bold-italic">u</mml:mi></mml:mrow></mml:munder><mml:mtext> </mml:mtext><mml:mi>ℓ</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi mathvariant="bold-italic">w</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>+</mml:mo><mml:msub><mml:mi>ϕ</mml:mi><mml:mrow><mml:mi>λ</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi mathvariant="bold-italic">w</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>,</mml:mo></mml:mstyle></mml:mrow></mml:mstyle></mml:math></disp-formula>where <inline-formula><mml:math id="inf8"><mml:mi mathsize="80%" mathvariant="bold-italic">𝒘</mml:mi></mml:math></inline-formula> is a vector that stores all the unique elements of the weighted adjacency matrix, <inline-formula><mml:math id="inf9"><mml:mi mathsize="80%" mathvariant="bold-italic">𝒍</mml:mi></mml:math></inline-formula> and <inline-formula><mml:math id="inf10"><mml:mi mathsize="80%" mathvariant="bold-italic">𝒖</mml:mi></mml:math></inline-formula> are element-wise non-negative lower and upper bounds for <inline-formula><mml:math id="inf11"><mml:mi mathsize="80%" mathvariant="bold-italic">𝒘</mml:mi></mml:math></inline-formula>, <inline-formula><mml:math id="inf12"><mml:mrow><mml:mi mathsize="80%" mathvariant="normal">ℓ</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo maxsize="80%" minsize="80%">(</mml:mo><mml:mi mathsize="80%" mathvariant="bold-italic">𝒘</mml:mi><mml:mo maxsize="80%" minsize="80%">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> is the negative log-likelihood function that comes from the GMRF model described above, and <inline-formula><mml:math id="inf13"><mml:mrow><mml:msub><mml:mi mathsize="80%">ϕ</mml:mi><mml:mi mathsize="80%">λ</mml:mi></mml:msub><mml:mo>⁢</mml:mo><mml:mrow><mml:mo maxsize="80%" minsize="80%">(</mml:mo><mml:mi mathsize="80%" mathvariant="bold-italic">𝒘</mml:mi><mml:mo maxsize="80%" minsize="80%">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> is a penalty that controls how constant or smooth the output migration surface will be and is controlled by the hyperparameter <inline-formula><mml:math id="inf14"><mml:mrow><mml:mi mathsize="80%">λ</mml:mi><mml:mo mathsize="80%" stretchy="false">&gt;</mml:mo><mml:mn mathsize="80%">0</mml:mn></mml:mrow></mml:math></inline-formula>. Writing <inline-formula><mml:math id="inf15"><mml:mi class="ltx_font_mathcaligraphic" mathsize="80%">𝒱</mml:mi></mml:math></inline-formula> to denote the set of nodes in the graph and <inline-formula><mml:math id="inf16"><mml:mrow><mml:mrow><mml:mi class="ltx_font_mathcaligraphic" mathsize="80%">ℰ</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo maxsize="80%" minsize="80%">(</mml:mo><mml:mi mathsize="80%">i</mml:mi><mml:mo maxsize="80%" minsize="80%">)</mml:mo></mml:mrow></mml:mrow><mml:mo mathsize="80%" stretchy="false">⊂</mml:mo><mml:mi class="ltx_font_mathcaligraphic" mathsize="80%">𝒱</mml:mi></mml:mrow></mml:math></inline-formula> to denote the subset of nodes that have edges connected to node <inline-formula><mml:math id="inf17"><mml:mi mathsize="80%">i</mml:mi></mml:math></inline-formula>, our penalty is given by<disp-formula id="equ2"><mml:math id="m2"><mml:mrow><mml:mrow><mml:mrow><mml:msub><mml:mi mathsize="80%">ϕ</mml:mi><mml:mi mathsize="80%">λ</mml:mi></mml:msub><mml:mo>⁢</mml:mo><mml:mrow><mml:mo maxsize="80%" minsize="80%">(</mml:mo><mml:mi mathsize="80%">𝒘</mml:mi><mml:mo maxsize="80%" minsize="80%">)</mml:mo></mml:mrow></mml:mrow><mml:mo mathsize="80%" stretchy="false">=</mml:mo><mml:mrow><mml:mfrac><mml:mi mathsize="80%">λ</mml:mi><mml:mn mathsize="80%">2</mml:mn></mml:mfrac><mml:mo>⁢</mml:mo><mml:mrow><mml:munder><mml:mo largeop="true" mathsize="80%" movablelimits="false" stretchy="false" symmetric="true">∑</mml:mo><mml:mrow><mml:mi mathsize="80%">i</mml:mi><mml:mo mathsize="80%" stretchy="false">∈</mml:mo><mml:mi class="ltx_font_mathcaligraphic" mathsize="80%">𝒱</mml:mi></mml:mrow></mml:munder><mml:mrow><mml:munder><mml:mo largeop="true" mathsize="80%" movablelimits="false" stretchy="false" symmetric="true">∑</mml:mo><mml:mrow><mml:mrow><mml:mi mathsize="80%">k</mml:mi><mml:mo mathsize="80%" stretchy="false">,</mml:mo><mml:mi mathsize="80%" mathvariant="normal">ℓ</mml:mi></mml:mrow><mml:mo mathsize="80%" stretchy="false">∈</mml:mo><mml:mrow><mml:mi class="ltx_font_mathcaligraphic" mathsize="80%">ℰ</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo maxsize="80%" minsize="80%">(</mml:mo><mml:mi mathsize="80%">i</mml:mi><mml:mo maxsize="80%" minsize="80%">)</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:munder><mml:msup><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mrow><mml:mi mathsize="80%">log</mml:mi><mml:mo>⁡</mml:mo><mml:mrow><mml:mo maxsize="80%" minsize="80%">(</mml:mo><mml:mrow><mml:msup><mml:mi mathsize="80%">e</mml:mi><mml:mrow><mml:msub><mml:mi mathsize="80%">w</mml:mi><mml:mrow><mml:mi mathsize="80%">i</mml:mi><mml:mo>⁢</mml:mo><mml:mi mathsize="80%">k</mml:mi></mml:mrow></mml:msub><mml:mo mathsize="80%" stretchy="false">/</mml:mo><mml:msub><mml:mover accent="true"><mml:mi mathsize="80%">w</mml:mi><mml:mo mathsize="80%" stretchy="false">^</mml:mo></mml:mover><mml:mn mathsize="80%">0</mml:mn></mml:msub></mml:mrow></mml:msup><mml:mo mathsize="80%" stretchy="false">-</mml:mo><mml:mn mathsize="80%">1</mml:mn></mml:mrow><mml:mo maxsize="80%" minsize="80%">)</mml:mo></mml:mrow></mml:mrow><mml:mo mathsize="80%" stretchy="false">-</mml:mo><mml:mrow><mml:mi mathsize="80%">log</mml:mi><mml:mo>⁡</mml:mo><mml:mrow><mml:mo maxsize="80%" minsize="80%">(</mml:mo><mml:mrow><mml:msup><mml:mi mathsize="80%">e</mml:mi><mml:mrow><mml:msub><mml:mi mathsize="80%">w</mml:mi><mml:mrow><mml:mi mathsize="80%">i</mml:mi><mml:mo>⁢</mml:mo><mml:mi mathsize="80%" mathvariant="normal">ℓ</mml:mi></mml:mrow></mml:msub><mml:mo mathsize="80%" stretchy="false">/</mml:mo><mml:msub><mml:mover accent="true"><mml:mi mathsize="80%">w</mml:mi><mml:mo mathsize="80%" stretchy="false">^</mml:mo></mml:mover><mml:mn mathsize="80%">0</mml:mn></mml:msub></mml:mrow></mml:msup><mml:mo mathsize="80%" stretchy="false">-</mml:mo><mml:mn mathsize="80%">1</mml:mn></mml:mrow><mml:mo maxsize="80%" minsize="80%">)</mml:mo></mml:mrow></mml:mrow></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mn mathsize="80%">2</mml:mn></mml:msup></mml:mrow></mml:mrow></mml:mrow></mml:mrow><mml:mo mathsize="80%" stretchy="false">.</mml:mo></mml:mrow></mml:math></disp-formula></p><p>This function serves to penalize large differences between the weights <inline-formula><mml:math id="inf18"><mml:msub><mml:mi mathsize="80%">w</mml:mi><mml:mrow><mml:mi mathsize="80%">i</mml:mi><mml:mo>⁢</mml:mo><mml:mi mathsize="80%">k</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> and <inline-formula><mml:math id="inf19"><mml:msub><mml:mi mathsize="80%">w</mml:mi><mml:mrow><mml:mi mathsize="80%">i</mml:mi><mml:mo>⁢</mml:mo><mml:mi mathsize="80%" mathvariant="normal">ℓ</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> on edges that are adjacent, that is, penalizing differences for any pair of edges that share a common node. The tuning parameter λ controls the overall strength of the penalization placed on the output of the migration surface—if λ is large, the fitted surface will favor a homogeneous set of inferred migration weights on the graph, while if λ is low, more flexible graphs can be fitted to recover richer local structure, but this suffers from the potential for over-fitting. The tuning parameter λ is selected by evaluating the model’s performance at predicting allele frequencies at held out locations using leave-one-out cross-validation (see Materials and methods ‘<italic>Leave-one-out cross-validation to select tuning parameters</italic>’).</p><p>The scale parameter <inline-formula><mml:math id="inf20"><mml:msub><mml:mover accent="true"><mml:mi mathsize="80%">w</mml:mi><mml:mo mathsize="80%" stretchy="false">^</mml:mo></mml:mover><mml:mn mathsize="80%">0</mml:mn></mml:msub></mml:math></inline-formula> is chosen first fitting a ‘constant <inline-formula><mml:math id="inf21"><mml:mi mathsize="80%">w</mml:mi></mml:math></inline-formula>’ model, which is a spatially homogeneous isolation-by-distance model constrained to have a single <inline-formula><mml:math id="inf22"><mml:mi mathsize="80%">w</mml:mi></mml:math></inline-formula> value for all edges. In the <inline-formula><mml:math id="inf23"><mml:msub><mml:mi mathsize="80%">ϕ</mml:mi><mml:mi mathsize="80%">λ</mml:mi></mml:msub></mml:math></inline-formula> penalty, for adjacent edges <inline-formula><mml:math id="inf24"><mml:mrow><mml:mo maxsize="80%" minsize="80%">(</mml:mo><mml:mi mathsize="80%">i</mml:mi><mml:mo mathsize="80%" stretchy="false">,</mml:mo><mml:mi mathsize="80%">k</mml:mi><mml:mo maxsize="80%" minsize="80%">)</mml:mo></mml:mrow></mml:math></inline-formula> and <inline-formula><mml:math id="inf25"><mml:mrow><mml:mo maxsize="80%" minsize="80%">(</mml:mo><mml:mi mathsize="80%">i</mml:mi><mml:mo mathsize="80%" stretchy="false">,</mml:mo><mml:mi mathsize="80%" mathvariant="normal">ℓ</mml:mi><mml:mo maxsize="80%" minsize="80%">)</mml:mo></mml:mrow></mml:math></inline-formula>, if <inline-formula><mml:math id="inf26"><mml:msub><mml:mi mathsize="80%">w</mml:mi><mml:mrow><mml:mi mathsize="80%">i</mml:mi><mml:mo>⁢</mml:mo><mml:mi mathsize="80%">k</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> and <inline-formula><mml:math id="inf27"><mml:msub><mml:mi mathsize="80%">w</mml:mi><mml:mrow><mml:mi mathsize="80%">i</mml:mi><mml:mo>⁢</mml:mo><mml:mi mathsize="80%" mathvariant="normal">ℓ</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> are large (relative to <inline-formula><mml:math id="inf28"><mml:msub><mml:mover accent="true"><mml:mi mathsize="80%">w</mml:mi><mml:mo mathsize="80%" stretchy="false">^</mml:mo></mml:mover><mml:mn mathsize="80%">0</mml:mn></mml:msub></mml:math></inline-formula>) then the corresponding term of the penalty is approximately proportional to <inline-formula><mml:math id="inf29"><mml:msup><mml:mrow><mml:mo maxsize="80%" minsize="80%">(</mml:mo><mml:mrow><mml:msub><mml:mi mathsize="80%">w</mml:mi><mml:mrow><mml:mi mathsize="80%">i</mml:mi><mml:mo>⁢</mml:mo><mml:mi mathsize="80%">k</mml:mi></mml:mrow></mml:msub><mml:mo mathsize="80%" stretchy="false">-</mml:mo><mml:msub><mml:mi mathsize="80%">w</mml:mi><mml:mrow><mml:mi mathsize="80%">i</mml:mi><mml:mo>⁢</mml:mo><mml:mi mathsize="80%" mathvariant="normal">ℓ</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo maxsize="80%" minsize="80%">)</mml:mo></mml:mrow><mml:mn mathsize="80%">2</mml:mn></mml:msup></mml:math></inline-formula>, penalizing differences among neighboring edges on a linear scale; if instead <inline-formula><mml:math id="inf30"><mml:msub><mml:mi mathsize="80%">w</mml:mi><mml:mrow><mml:mi mathsize="80%">i</mml:mi><mml:mo>⁢</mml:mo><mml:mi mathsize="80%">k</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> and <inline-formula><mml:math id="inf31"><mml:msub><mml:mi mathsize="80%">w</mml:mi><mml:mrow><mml:mi mathsize="80%">i</mml:mi><mml:mo>⁢</mml:mo><mml:mi mathsize="80%" mathvariant="normal">ℓ</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> are small relative to <inline-formula><mml:math id="inf32"><mml:msub><mml:mover accent="true"><mml:mi mathsize="80%">w</mml:mi><mml:mo mathsize="80%" stretchy="false">^</mml:mo></mml:mover><mml:mn mathsize="80%">0</mml:mn></mml:msub></mml:math></inline-formula>, then the penalty is approximately proportional to <inline-formula><mml:math id="inf33"><mml:msup><mml:mrow><mml:mo maxsize="80%" minsize="80%">(</mml:mo><mml:mrow><mml:mrow><mml:mi mathsize="80%">log</mml:mi><mml:mo>⁡</mml:mo><mml:mrow><mml:mo maxsize="80%" minsize="80%">(</mml:mo><mml:msub><mml:mi mathsize="80%">w</mml:mi><mml:mrow><mml:mi mathsize="80%">i</mml:mi><mml:mo>⁢</mml:mo><mml:mi mathsize="80%">k</mml:mi></mml:mrow></mml:msub><mml:mo maxsize="80%" minsize="80%">)</mml:mo></mml:mrow></mml:mrow><mml:mo mathsize="80%" stretchy="false">-</mml:mo><mml:mrow><mml:mi mathsize="80%">log</mml:mi><mml:mo>⁡</mml:mo><mml:mrow><mml:mo maxsize="80%" minsize="80%">(</mml:mo><mml:msub><mml:mi mathsize="80%">w</mml:mi><mml:mrow><mml:mi mathsize="80%">i</mml:mi><mml:mo>⁢</mml:mo><mml:mi mathsize="80%" mathvariant="normal">ℓ</mml:mi></mml:mrow></mml:msub><mml:mo maxsize="80%" minsize="80%">)</mml:mo></mml:mrow></mml:mrow></mml:mrow><mml:mo maxsize="80%" minsize="80%">)</mml:mo></mml:mrow><mml:mn mathsize="80%">2</mml:mn></mml:msup></mml:math></inline-formula>, penalizing differences on a logarithmic scale. In fact, it is also possible to consider treating this scale parameter as a second tuning parameter—we can define a penalty function <inline-formula><mml:math id="inf34"><mml:mrow><mml:mrow><mml:msub><mml:mi mathsize="80%">ϕ</mml:mi><mml:mrow><mml:mi mathsize="80%">λ</mml:mi><mml:mo mathsize="80%" stretchy="false">,</mml:mo><mml:mi mathsize="80%">α</mml:mi></mml:mrow></mml:msub><mml:mo>⁢</mml:mo><mml:mrow><mml:mo maxsize="80%" minsize="80%">(</mml:mo><mml:mi mathsize="80%" mathvariant="bold-italic">𝒘</mml:mi><mml:mo maxsize="80%" minsize="80%">)</mml:mo></mml:mrow></mml:mrow><mml:mo mathsize="80%" stretchy="false">=</mml:mo><mml:mrow><mml:mfrac><mml:mi mathsize="80%">λ</mml:mi><mml:mn mathsize="80%">2</mml:mn></mml:mfrac><mml:mo>⁢</mml:mo><mml:mrow><mml:msub><mml:mo largeop="true" mathsize="80%" stretchy="false" symmetric="true">∑</mml:mo><mml:mrow><mml:mi mathsize="80%">i</mml:mi><mml:mo mathsize="80%" stretchy="false">∈</mml:mo><mml:mi class="ltx_font_mathcaligraphic" mathsize="80%">𝒱</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:msub><mml:mo largeop="true" mathsize="80%" stretchy="false" symmetric="true">∑</mml:mo><mml:mrow><mml:mrow><mml:mi mathsize="80%">k</mml:mi><mml:mo mathsize="80%" stretchy="false">,</mml:mo><mml:mi mathsize="80%" mathvariant="normal">ℓ</mml:mi></mml:mrow><mml:mo mathsize="80%" stretchy="false">∈</mml:mo><mml:mrow><mml:mi class="ltx_font_mathcaligraphic" mathsize="80%">ℰ</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo maxsize="80%" minsize="80%">(</mml:mo><mml:mi mathsize="80%">i</mml:mi><mml:mo maxsize="80%" minsize="80%">)</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:msub><mml:msup><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mrow><mml:mi mathsize="80%">log</mml:mi><mml:mo>⁡</mml:mo><mml:mrow><mml:mo maxsize="80%" minsize="80%">(</mml:mo><mml:mrow><mml:msup><mml:mi mathsize="80%">e</mml:mi><mml:mrow><mml:mi mathsize="80%">α</mml:mi><mml:mo>⁢</mml:mo><mml:msub><mml:mi mathsize="80%">w</mml:mi><mml:mrow><mml:mi mathsize="80%">i</mml:mi><mml:mo>⁢</mml:mo><mml:mi mathsize="80%">k</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:msup><mml:mo mathsize="80%" stretchy="false">-</mml:mo><mml:mn mathsize="80%">1</mml:mn></mml:mrow><mml:mo maxsize="80%" minsize="80%">)</mml:mo></mml:mrow></mml:mrow><mml:mo mathsize="80%" stretchy="false">-</mml:mo><mml:mrow><mml:mi mathsize="80%">log</mml:mi><mml:mo>⁡</mml:mo><mml:mrow><mml:mo maxsize="80%" minsize="80%">(</mml:mo><mml:mrow><mml:msup><mml:mi mathsize="80%">e</mml:mi><mml:mrow><mml:mi mathsize="80%">α</mml:mi><mml:mo>⁢</mml:mo><mml:msub><mml:mi mathsize="80%">w</mml:mi><mml:mrow><mml:mi mathsize="80%">i</mml:mi><mml:mo>⁢</mml:mo><mml:mi mathsize="80%" mathvariant="normal">ℓ</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:msup><mml:mo mathsize="80%" stretchy="false">-</mml:mo><mml:mn mathsize="80%">1</mml:mn></mml:mrow><mml:mo maxsize="80%" minsize="80%">)</mml:mo></mml:mrow></mml:mrow></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mn mathsize="80%">2</mml:mn></mml:msup></mml:mrow></mml:mrow></mml:mrow></mml:mrow></mml:math></inline-formula>, and explore the solution across different values of both λ and α. However, we find that empirically choosing <inline-formula><mml:math id="inf35"><mml:mrow><mml:mi mathsize="80%">α</mml:mi><mml:mo mathsize="80%" stretchy="false">=</mml:mo><mml:mrow><mml:mn mathsize="80%">1</mml:mn><mml:mo mathsize="80%" stretchy="false">/</mml:mo><mml:msub><mml:mover accent="true"><mml:mi mathsize="80%">w</mml:mi><mml:mo mathsize="80%" stretchy="false">^</mml:mo></mml:mover><mml:mn mathsize="80%">0</mml:mn></mml:msub></mml:mrow></mml:mrow></mml:math></inline-formula> offers good performance as well as an intuitive interpretation (i.e. scaling edge weights <inline-formula><mml:math id="inf36"><mml:msub><mml:mi mathsize="80%">w</mml:mi><mml:mrow><mml:mi mathsize="80%">i</mml:mi><mml:mo>⁢</mml:mo><mml:mi mathsize="80%">k</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> with reference to the constant-<inline-formula><mml:math id="inf37"><mml:mi mathsize="80%">w</mml:mi></mml:math></inline-formula> model), and allows us to avoid the computational burden of searching a two-dimensional tuning parameter space.</p><p>We use sparse linear algebra routines to efficiently compute the objective function and gradient of our parameters, allowing for the use of widely applied quasi-Newton optimization algorithms (<xref ref-type="bibr" rid="bib36">Nocedal and Wright, 2006</xref>) implemented in standard numerical computing libraries like <monospace>scipy</monospace> (<xref ref-type="bibr" rid="bib53">Virtanen et al., 2020</xref>) (<monospace>RRID:<ext-link ext-link-type="uri" xlink:href="https://scicrunch.org/resolver/SCR_008058">SCR_008058</ext-link></monospace>). See the Materials and methods section for a detailed description of the statistical models and algorithms used.</p></sec><sec id="s2-2"><title>Evaluating FEEMS on ‘out of model’ coalescent simulations</title><p>While our statistical model is not directly based on a population genetic process, it is useful to see how it performs on simulated data under the coalescent stepping stone model (<xref ref-type="fig" rid="fig2">Figure 2</xref>, also see <xref ref-type="fig" rid="app1fig2">Appendix 1—figure 2</xref> for additional scenarios). In these simulations we know, by construction, the model we fit (FEEMS) is different from the true model we simulate data under (the coalescent), allowing us to assess the robustness of the fit to a controlled form of model mis-specification.</p><fig id="fig2" position="float"><label>Figure 2.</label><caption><title>FEEMS fit to coalescent simulations: We run FEEMS on coalescent simulations, varying the migration history (columns) and sampling design (rows).</title><p>In each simulation, we used leave-one-out cross-validation (at the level of sampled nodes) to select the smoothness parameter λ. The first column (<bold>A–C</bold>) shows the ground-truth and fit of FEEMS to coalescent simulations with a homogeneous migration history that is, a single migration parameter for all edge weights. Note that the ground-truth simulation figures (<bold>A,D,G</bold>) display coalescent migration rates, not fitted effective migration rates output by FEEMS. The second column (<bold>D–F</bold>) shows the ground truth and fit of FEEMS to simulations with a heterogeneous migration history that is, reduced gene-flow, with 10-fold lower migration, in the center of the habitat. The third column (<bold>G–I</bold>) shows the ground truth and fit of FEEMS to an anisotropic migration history with edge weights facing east-west having five fold higher migration than north-south. The second row (<bold>B,E,H</bold>) shows a sampling design with no missing observations on the graph. The final row (<bold>C,F,I</bold>) shows a sampling design with 80% of nodes missing at random.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-61927-fig2-v1.tif"/></fig><p>The first migration scenario (<xref ref-type="fig" rid="fig2">Figure 2A–C</xref>) is a spatially homogeneous model where all the migration rates are set to be a constant value on the graph, this is equivalent to simulating data under an homogeneous isolation-by-distance model. In the second migration scenario (<xref ref-type="fig" rid="fig2">Figure 2D–E</xref>), we simulate a non-homogeneous process by representing a geographic barrier to migration, lowering the migration rates by a factor of 10 in the center of the habitat relative to the left and right regions of the graph. Finally, in the third migration scenario (<xref ref-type="fig" rid="fig2">Figure 2G–I</xref>), we simulate a pattern which corresponds to anisotropic migration with edges that point east/west being assigned to a fivefold higher migration rate than edges pointing north/south. For each migration scenario, we simulate two sampling designs. In the first ‘dense-sampling’ design (<xref ref-type="fig" rid="fig2">Figure 2B,E,I</xref>) we sample individuals for every node of the graph. Next, in the ‘sparse-sampling’ design (<xref ref-type="fig" rid="fig2">Figure 2C,F,J</xref>) we sample individuals for only a randomly selected 20% of the nodes.</p><p>For each coalescent simulation, we used leave-one-out cross-validation (at the level of sampled nodes) to select the smoothness parameter λ. In the homogeneous migration simulations, the best value for the smoothness parameter, as determined by the grid value with the lowest leave-one-out cross-validation error, is <inline-formula><mml:math id="inf38"><mml:mrow><mml:msub><mml:mi mathsize="80%">λ</mml:mi><mml:mtext mathsize="80%">cv</mml:mtext></mml:msub><mml:mo mathsize="80%" stretchy="false">=</mml:mo><mml:mn mathsize="80%">100</mml:mn></mml:mrow></mml:math></inline-formula> in both sampling scenarios with complete and missing data. In the heterogeneous migration simulations <inline-formula><mml:math id="inf39"><mml:mrow><mml:msub><mml:mi mathsize="80%">λ</mml:mi><mml:mtext mathsize="80%">cv</mml:mtext></mml:msub><mml:mo mathsize="80%" stretchy="false">=</mml:mo><mml:mn mathsize="80%">0.298</mml:mn></mml:mrow></mml:math></inline-formula> with no missing data and <inline-formula><mml:math id="inf40"><mml:mrow><mml:msub><mml:mi mathsize="80%">λ</mml:mi><mml:mtext mathsize="80%">cv</mml:mtext></mml:msub><mml:mo mathsize="80%" stretchy="false">=</mml:mo><mml:mn mathsize="80%">37.927</mml:mn></mml:mrow></mml:math></inline-formula> with missing data. Finally, in the anisotropic simulations with no missing data <inline-formula><mml:math id="inf41"><mml:mrow><mml:msub><mml:mi mathsize="80%">λ</mml:mi><mml:mtext mathsize="80%">cv</mml:mtext></mml:msub><mml:mo mathsize="80%" stretchy="false">=</mml:mo><mml:mn mathsize="80%">0.298</mml:mn></mml:mrow></mml:math></inline-formula> and with missing data <inline-formula><mml:math id="inf42"><mml:mrow><mml:msub><mml:mi mathsize="80%">λ</mml:mi><mml:mtext mathsize="80%">cv</mml:mtext></mml:msub><mml:mo mathsize="80%" stretchy="false">=</mml:mo><mml:mn mathsize="80%">0.042</mml:mn></mml:mrow></mml:math></inline-formula>. We note the magnitude of the selected λ depends on the scale of the loss function so comparisons across different datasets are not generally interpretable.</p><p>With regard to the visualizations of effective migration, FEEMS performs best when all the nodes are sampled on the graph, that is, when there is no missing data (<xref ref-type="fig" rid="fig2">Figure 2B,E,H</xref>). Interestingly, in the simulated scenarios with many missing nodes, FEEMS can still partly recover the migration history, including the presence of anisotropic migration (<xref ref-type="fig" rid="fig2">Figure 2I</xref>). A sampling scheme with a central gap leads to a slightly narrower barrier in the heterogeneous migration scenario (<xref ref-type="fig" rid="app1fig2">Appendix 1—figure 2I</xref>) and for the anisotropic scenario, a degree of over-smoothness in the northern and southern regions of the center of the graph (<xref ref-type="fig" rid="app1fig2">Appendix 1—figure 2N</xref>). For the missing at random sampling design, FEEMS is able to recover the relative edge weights surprisingly well for all scenarios, with the inference being the most challenging when there is anisotropic migration. The potential for FEEMS to recover anisotropic migration is novel relative to EEMS, which was parameterized for fitting non-stationary isotropic migration histories and produces banding patterns perpendicular to the axis of migration when applied to data from anisotropic coalescent simulations (<xref ref-type="bibr" rid="bib42">Petkova et al., 2016</xref>, Supplementary Figure 2; see also Appendix 1 ‘<italic>Edge versus node parameterization</italic>’ for a related discussion). Overall, even with sparsely sampled graphs, FEEMS is able to produce visualizations that qualitatively capture the migration history in coalescent simulations.</p></sec><sec id="s2-3"><title>Application of FEEMS to genotype data from North American gray wolves</title><p>To assess the performance of FEEMS on real data, we used a previously published dataset of 111 gray wolves sampled across North America typed at 17,729 SNPs (<xref ref-type="bibr" rid="bib51">Schweizer et al., 2016</xref>; <xref ref-type="fig" rid="app1fig5">Appendix 1—figure 5</xref>). This dataset has a number of advantageous features that make it a useful test case for evaluating FEEMS: (1) The broad sampling range across North America includes a number of relevant geographic features that, a priori, could conceivably lead to restricted gene-flow averaged throughout the population history. These geographic features include mountain ranges, lakes, and islands. (2) The scale of the data is consistent with many studies for non-model systems whose spatial population structure is of interest. For instance, the relatively sparse sampling leads to a challenging statistical problem where there is the potential for many unobserved nodes (sub-populations), depending the density of the grid chosen.</p><p>Before applying FEEMS, we confirmed a signature of spatial structure in the data through regressing genetic distances on geographic distances and top genetic PCs against geographic coordinates (<xref ref-type="fig" rid="app1fig6">Appendix 1—figures 6</xref>, <xref ref-type="fig" rid="app1fig7">7</xref>, <xref ref-type="fig" rid="app1fig8">8</xref>, <xref ref-type="fig" rid="app1fig9">9</xref>). We also ran multiple replicates of ADMIXTURE for <inline-formula><mml:math id="inf43"><mml:mrow><mml:mi mathsize="80%">K</mml:mi><mml:mo mathsize="80%" stretchy="false">=</mml:mo><mml:mn mathsize="80%">2</mml:mn></mml:mrow></mml:math></inline-formula> to <inline-formula><mml:math id="inf44"><mml:mrow><mml:mi mathsize="80%">K</mml:mi><mml:mo mathsize="80%" stretchy="false">=</mml:mo><mml:mn mathsize="80%">8</mml:mn></mml:mrow></mml:math></inline-formula>, selecting for each <inline-formula><mml:math id="inf45"><mml:mi mathsize="80%">K</mml:mi></mml:math></inline-formula> the highest likelihood run among replicates to visualize (<xref ref-type="fig" rid="app1fig10">Appendix 1—figure 10</xref>). As expected in a spatial genetic dataset, nearby samples have similar admixture proportions and continuous gradients of changing ancestries are spread throughout the map (<xref ref-type="bibr" rid="bib6">Bradburd et al., 2018</xref>). Whether such gradients in admixture coefficients are due to isolation by distance or specific geographic features that enhance or diminish the levels of genetic differentiation is an interpretive challenge. Explicitly modeling the spatial locations and genetic distance jointly using a method like EEMS or FEEMS is exactly designed to explore these types of questions in the data (<xref ref-type="bibr" rid="bib41">Petkova, 2013</xref>; <xref ref-type="bibr" rid="bib42">Petkova et al., 2016</xref>).</p><p>We first show FEEMS results for four different values of the smoothness parameter, λ from large <inline-formula><mml:math id="inf46"><mml:mrow><mml:mi mathsize="80%">λ</mml:mi><mml:mo mathsize="80%" stretchy="false">=</mml:mo><mml:mn mathsize="80%">100</mml:mn></mml:mrow></mml:math></inline-formula> to small <inline-formula><mml:math id="inf47"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>λ</mml:mi><mml:mo>=</mml:mo><mml:mn>0.0008</mml:mn></mml:mrow></mml:mstyle></mml:math></inline-formula> (<xref ref-type="fig" rid="fig3">Figure 3</xref>). One interpretation of our regularization penalty is that it encourages fitting models of homogeneous and isotropic migration. When λ is very large (<xref ref-type="fig" rid="fig3">Figure 3A</xref>), we see FEEMS fits a model where all of the edge weights on the graph nearly equal the mean value, hence all the edge weights are colored white in the relative log-scale. In this case, FEEMS is fitting a relatively homogeneous migration model where all the estimated edge weights get assigned nearly the same value on the graph. As we sequentially lower the penalty parameter, (<xref ref-type="fig" rid="fig3">Figure 3B,C,D</xref>) the fitted graph begins to appear more complex and heterogeneous as expected (discussed further below). <xref ref-type="fig" rid="fig3">Figure 3E</xref> shows the cross-validation error for a pre-defined grid of λ values (also see <xref ref-type="fig" rid="app1fig6">Appendix 1—figure 6</xref> for visualizations of the fitted versus genetic distance on the full dataset).</p><fig id="fig3" position="float"><label>Figure 3.</label><caption><title>The fit of FEEMS to the North American gray wolf dataset for different choices of the smoothing regularization parameter λ: (<bold>A</bold>) <inline-formula><mml:math id="inf48"><mml:mrow><mml:mi>λ</mml:mi><mml:mo>=</mml:mo><mml:mn>100</mml:mn></mml:mrow></mml:math></inline-formula>, (<bold>B</bold>) <inline-formula><mml:math id="inf49"><mml:mrow><mml:mi>λ</mml:mi><mml:mo>=</mml:mo><mml:mn>2.06</mml:mn></mml:mrow></mml:math></inline-formula>, (<bold>C</bold>) <inline-formula><mml:math id="inf50"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>λ</mml:mi><mml:mo>=</mml:mo><mml:mn>0.04</mml:mn></mml:mrow></mml:mstyle></mml:math></inline-formula>, and (<bold>D</bold>) <inline-formula><mml:math id="inf51"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>λ</mml:mi><mml:mo>=</mml:mo><mml:mn>0.0008</mml:mn></mml:mrow></mml:mstyle></mml:math></inline-formula>.</title><p>As expected, when λ decreases from large to small (<bold>A–D</bold>), the fitted graph becomes less smooth and eventually over-fits to the data, revealing a patchy surface in (<bold>D</bold>), whereas earlier in the regularization path FEEMS fits a homogeneous surface with all edge weights having nearly the same fitted value, as in (<bold>A</bold>). (<bold>E</bold>) shows the mean square error between predicted and held-out allele frequencies output by running leave-one-out cross-validation to select the smoothness parameter λ. The cross-validation error is minimized over a pre-selected grid at an intermediate value of <inline-formula><mml:math id="inf52"><mml:mrow><mml:mi>λ</mml:mi><mml:mo>=</mml:mo><mml:mn>2.06</mml:mn></mml:mrow></mml:math></inline-formula> as shown in (<bold>B</bold>).</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-61927-fig3-v1.tif"/></fig><p>The cross-validation approach finds the optimal value of λ to be 2.06. This solution visually appears to have a moderate level of regularization and aligns with several known landscape features (<xref ref-type="fig" rid="fig4">Figure 4</xref>). Spatial features in the FEEMS visualization qualitatively matches the structure plot output from ADMIXTURE using <inline-formula><mml:math id="inf53"><mml:mrow><mml:mi mathsize="80%">K</mml:mi><mml:mo mathsize="80%" stretchy="false">=</mml:mo><mml:mn mathsize="80%">6</mml:mn></mml:mrow></mml:math></inline-formula> (<xref ref-type="fig" rid="app1fig10">Appendix 1—figure 10</xref>). We add labels on the figure to highlight a number of pertinent features: (A) St. Lawrence Island, (B) the coastal islands and mountain ranges in British Columbia, (C) the boundary of Boreal Forest and Tundra eco-regions in the Shield Taiga, (D) Queen Elizabeth Islands, (E) Hudson Bay, and (F) Baffin Island. Many of these features were described in <xref ref-type="bibr" rid="bib51">Schweizer et al., 2016</xref> by interpretation of ADMIXTURE, PCA, and <inline-formula><mml:math id="inf54"><mml:msub><mml:mi mathsize="80%">F</mml:mi><mml:mrow><mml:mi mathsize="80%">S</mml:mi><mml:mo>⁢</mml:mo><mml:mi mathsize="80%">T</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> statistics. FEEMS is able to succinctly provide an interpretable view of these data in a single visualization. Indeed many of these geographic features plausibly impact gray wolf dispersal and population history (<xref ref-type="bibr" rid="bib51">Schweizer et al., 2016</xref>).</p><fig id="fig4" position="float"><label>Figure 4.</label><caption><title>FEEMS applied to a population genetic dataset of North American gray wolves: We show the fit of FEEMS applied to a previously published dataset of North American gray wolves.</title><p>Leave-one-out cross-validation (at the level of sampled nodes) was used to select the smoothness parameter <inline-formula><mml:math id="inf55"><mml:mrow><mml:mi>λ</mml:mi><mml:mo>=</mml:mo><mml:mn>2.06</mml:mn></mml:mrow></mml:math></inline-formula>. We show the fitted parameters in log-scale with lower effective migration shown in orange and higher effective migration shown in blue. The bold text letters highlights a number of known geographic features that could have plausibly influenced wolf migration over time: (<bold>A</bold>) St. Lawrence Island, (<bold>B</bold>) Coastal mountain ranges in British Columbia, (<bold>C</bold>) The boundary of Boreal Forest and Tundra eco-regions in the Shield Taiga, (<bold>D</bold>) Queen Elizabeth Islands, (<bold>E</bold>) Hudson Bay, and (<bold>F</bold>) Baffin Island. We also display two insets to help interpret the results and compare them to EEMS. In the top left inset we show a map of sample coordinates colored by an ecotype label provided by <xref ref-type="bibr" rid="bib51">Schweizer et al., 2016</xref>. These labels were devised using a combination of genetic and ecological information for 94 ‘un-admixed’ gray wolf samples, and the remaining samples were labeled ‘Other’. We can see these ecotype labels align well with the visualization output provided by FEEMS. In the right inset, we display a visualization of the posterior mean effective migration rates from EEMS.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-61927-fig4-v1.tif"/></fig></sec><sec id="s2-4"><title>Comparison to EEMS</title><p>We also ran EEMS on the same gray wolf dataset. We used default parameters provided by EEMS but set the number of burn-in iterations to <inline-formula><mml:math id="inf56"><mml:mrow><mml:mn mathsize="80%">20</mml:mn><mml:mo mathsize="80%" stretchy="false">×</mml:mo><mml:msup><mml:mn mathsize="80%">10</mml:mn><mml:mn mathsize="80%">6</mml:mn></mml:msup></mml:mrow></mml:math></inline-formula>, MCMC iterations to <inline-formula><mml:math id="inf57"><mml:mrow><mml:mn mathsize="80%">50</mml:mn><mml:mo mathsize="80%" stretchy="false">×</mml:mo><mml:msup><mml:mn mathsize="80%">10</mml:mn><mml:mn mathsize="80%">6</mml:mn></mml:msup></mml:mrow></mml:math></inline-formula>, and thinning intervals to 2000. We were unable to run EEMS in a reasonable run time (<inline-formula><mml:math id="inf58"><mml:mrow><mml:mi/><mml:mo mathsize="80%" stretchy="false">≤</mml:mo><mml:mn mathsize="80%">3</mml:mn></mml:mrow></mml:math></inline-formula> days) for the dense spatial grid of 1207 nodes so we ran EEMS and FEEMS on a sparser graph with 307 nodes.</p><p>We find that FEEMS is multiple orders of magnitude faster than EEMS, even when running multiple runs of FEEMS for different regularization settings on both the sparse and dense graphs (<xref ref-type="table" rid="table1">Table 1</xref>). We note that constructing the graph and fitting the model with very low regularization parameters are the most computationally demanding steps in running FEEMS.</p><table-wrap id="table1" position="float"><label>Table 1.</label><caption><title>Runtimes for FEEMS and EEMS on the North American gray wolf dataset.</title><p>We show a table of runtimes for FEEMS and EEMS for two different grid densities, a sparse grid with 307 nodes and a dense grid with 1207 nodes. The second row shows the FEEMS run-times for applying leave-one-out cross-validation to select λ. The third row shows the run-times when applying FEEMS at the best λ value selected using cross-validation. FEEMS is orders of magnitude faster than EEMS, even when using cross-validation to select λ. Runtimes are based on computation using Intel Xeon E5-2680v4 2.4 GHz CPUs with 5 Gb RAM reserved using the University of Chicago Midway2 cluster.</p></caption><table frame="hsides" rules="groups"><thead><tr><th>Method</th><th>Sparse grid (run-time)</th><th>Dense grid (run-time)</th></tr></thead><tbody><tr><td>EEMS</td><td>27.43 hr</td><td>N/A</td></tr><tr><td>FEEMS (Cross-validation)</td><td>10 min 32 s</td><td>1.03 hr</td></tr><tr><td>FEEMS (Best λ)</td><td>1.23 s</td><td>4.08 s</td></tr></tbody></table></table-wrap><p>We find that many of the same geographic features that have reduced or enhanced gene-flow are concordant between the two methods. The EEMS visualization, qualitatively, best matches solutions of FEEMS with lower λ values (<xref ref-type="fig" rid="fig4">Figure 4</xref>, <xref ref-type="fig" rid="app1fig11">Appendix 1—figure 11</xref>); however, based on the ADMIXTURE results, visual inspection in relation to known geographical features and inspection of the observed vs fitted dissimilarity values (<xref ref-type="fig" rid="app1fig14">Appendix 1—figures 14</xref>, <xref ref-type="fig" rid="app1fig22">22</xref>), we find these solutions to be less satisfying compared to the FEEMS solution found with λ chosen by leave-one-out cross-validation. We note that in many of the EEMS runs the MCMC appears to not have converged (based on visual inspection of trace plots) even after a large number of iterations.</p></sec></sec><sec id="s3" sec-type="discussion"><title>Discussion</title><p>FEEMS is a fast approach that provides an interpretable view of spatial population structure in real datasets and simulations. We want to emphasize that beyond being a fast optimization approach for inferring population structure, our parameterization of the likelihood opens up a number of exciting new directions for improving spatial population genetic inference. Notably, one major difference between EEMS and FEEMS is that in FEEMS each edge weight is assigned its own parameter to be estimated, whereas in EEMS each node is assigned a parameter and each edge is constrained to be the average effective migration between the nodes it connects (see Materials and methods and Appendix 1 ‘<italic>Edge versus node parameterization</italic>’ for details). The node-based parameterization in EEMS makes it difficult to incorporate anisotropy and asymmeteric migration (<xref ref-type="bibr" rid="bib26">Lundgren and Ralph, 2019</xref>). As we have shown here, FEEMS’s simple and novel parameterization already has potential to fit anisotropic migration (as shown in coalescent simulations) and may be extendable to other more complex migration processes (such as long-range migration, see below).</p><p>One general challenge, which is not unique to this method, is selecting the tuning parameters controlling the strength of regularization (λ in our case). A natural approach is to use cross-validation, which estimates the out-of-sample fit of FEEMS for a particular choice of λ. We used leave-one-out cross-validation, leaving one sampled population out at a time, and find such an approach works well based on the coalescent simulations and application to the North American wolf data. That said, we sometimes found high variability in the selected solution when we used cross-validation with fewer folds (e.g. five-fold versus leave-one-out, results not shown). We expect this happens when the number of sampled populations is small relative to the complexity of the gene flow landscape, and we recommend using leave-one-out cross-validation in general. We also find it useful to fit FEEMS to a sequential grid of regularization parameters and to look at what features are consistent or vary across multiple fits. Informally, one can gain an indication of the strongest features in the data by looking at the order they appear in the regularization path that is, what features overcome the strong penalization of smoothness in the data and that are highly supported by the likelihood. For example, early in the regularization path, we see regions of reduced gene-flow occurring in the west coast of Canada that presumably correspond to Coastal mountain ranges and islands in British Columbia (<xref ref-type="fig" rid="fig3">Figure 3B</xref>) and this reduced gene-flow appears throughout more flexible fits with lower λ.</p><p>An important caveat is that the objective function we optimize is non-convex so any visualization output by FEEMS should be considered a local optimum and, keeping in mind that with different initialization one could get different results. That said, for the datasets investigated, we found the output visualizations were not sensitive to initialization, and thus our default setting is constant initialization fitted under an homogeneous isolation by distance model (See Materials and methods).</p><p>When comparing to EEMS, we found FEEMS to be much faster (<xref ref-type="table" rid="table1">Table 1</xref>). While this is encouraging, care must be taken because the goals and outputs of FEEMS and EEMS have a number of differences. FEEMS fits a sequential grid of solutions for different regularization parameters, whereas EEMS infers a posterior distribution and outputs the posterior mean as a point estimate. FEEMS is not a Bayesian method and unlike EEMS, which explores the entire landscape of the posterior distribution, FEEMS returns a particular point estimate: a local minimum point of the optimization landscape. Setting the prior hyper-parameters in EEMS act somewhat like a choice of the tuning parameter λ, except that EEMS uses hierarchical priors that in principle allow for exploration of multiple scales of spatial structure in a single run, but requires potentially long computation times for adequate MCMC convergence.</p><p>Like EEMS, FEEMS is based on an assumed underlying spatial graph of populations exchanging gene flow with neighboring populations. While the inferred migration rates explain the data under an assumed model, it is important for users and readers of FEEMS results to keep in mind the range and density of the chosen grid when interpreting results. We note that using a denser grid has the two potential advantages of providing improved approximation for continuously distributed species, as well as a more flexible model space to fit the data.</p><p>Depending on the scale of the analysis and the life history of the species, the process of assuming and assigning a single geographic location for each individual is a potential limitation of the modeling framework used here. For instance, the North American wolves studied here are understood to be generally territorial with individual ranges that are on the scale of 10<sup>3</sup> km<sup>2</sup> (<xref ref-type="bibr" rid="bib8">Burch et al., 2005</xref>), which is small relative to the greater than 10<sup>6</sup> km<sup>2</sup> scale of our analysis. Thus, modeling individual wolves with single locations may not generally be problematic. However, at the boundary of the Boreal forest and Tundra, there are wolves with larger annual ranges and seasonal migrations that track caribou herds roughly north-south over distances of 1000 km (<xref ref-type="bibr" rid="bib35">Musiani et al., 2007</xref>), and the wolves in the study were sampled in the winter (<xref ref-type="bibr" rid="bib35">Musiani et al., 2007</xref>; <xref ref-type="bibr" rid="bib51">Schweizer et al., 2016</xref>). If the samples were instead obtained in the summer, the position of the inferred low migration feature near the boundary of the Boreal Forest (marked 'C' in <xref ref-type="fig" rid="fig4">Figure 4</xref>) would presumably shift northward. The general cautionary lesson is that one must be careful when interpreting these maps to consider the life history of dispersal for the organism under study during the interpretation of results. Extending the methodology to incorporate knowledge of uncertainty in position or known dispersal may be an interesting direction for future work.</p><p>One natural extension to FEEMS, pertinent to a number of biological systems, is incorporating long-range migration (<xref ref-type="bibr" rid="bib43">Pickrell and Pritchard, 2012</xref>; <xref ref-type="bibr" rid="bib5">Bradburd et al., 2016</xref>). In this work, we have used a triangular lattice embedded in geographic space and enforced smoothness in nearby edge weights through penalizing their squared differences (see Materials and methods). We could imagine changing the structure of the graph by adding edges to allow for long-range connections; however, our current regularization scheme would not be appropriate for this setting. Instead, we could imagine adding an additional penalty to the objective, which would only allow a few long range connections to be tolerated. This could be considered to be a combination of two existing approaches for graph-based inference, graphical lasso (GLASSO) and graph Laplacian smoothing, combining the smoothness assumption for nearby connections and the sparsity assumption for long-range connections (<xref ref-type="bibr" rid="bib17">Friedman et al., 2008</xref>; <xref ref-type="bibr" rid="bib55">Wang et al., 2016</xref>). Another potential methodological avenue to incorporate long-range migration is to use a ‘greedy’ approach. We could imagine adding long-range edges one a time, guided by re-fitting the spatial model and taking a data-driven approach to select particular long-range edges to include. The proposed greedy approach could be considered to be a spatial graph analog of TreeMix (<xref ref-type="bibr" rid="bib43">Pickrell and Pritchard, 2012</xref>).</p><p>Another interesting extension would be to incorporate asymmetric migration into the framework of resistance distance and Gaussian Markov Random Field based models. FEEMS, like EEMS, used a likelihood that is based on resistance distances, which are limited in their ability to model asymmetric migration (<xref ref-type="bibr" rid="bib26">Lundgren and Ralph, 2019</xref>). Recently, <xref ref-type="bibr" rid="bib18">Hanks, 2015</xref> developed a promising new framework for deriving the stationary distribution of a continuous time stochastic process with asymmetric migration on a spatial graph. Interestingly, the expected distance of this process has similarities to the resistance distance-based models, in that it depends on the pseudo-inverse of a function of the graph Laplacian. <xref ref-type="bibr" rid="bib18">Hanks, 2015</xref> used MCMC to estimate the effect of known covariates on the edge weights of the spatial graph. Future work could adapt this framework into the penalized optimization approach we have considered here, where adjacent edge weights are encouraged to be smooth.</p><p>Finally, when interpreted as mechanistic rather than statistical models, both EEMS and FEEMS implicitly assume time-stationarity, so the estimated migration parameters should be considered to be ‘effective’ in the sense of being averaged over time in a reality where migration rates are dynamic and changing (<xref ref-type="bibr" rid="bib44">Pickrell and Reich, 2014</xref>). The MAPS method is one recent advance that utilizes long stretches of shared haplotypes between pairs of individuals to perform Bayesian inference of time varying migration rates and population sizes (<xref ref-type="bibr" rid="bib1">Al-Asadi et al., 2019</xref>). With the growing ability to extract high quality DNA from ancient samples, another exciting future direction would be to apply FEEMS to ancient DNA datasets over different time transects in the same focal geographic region to elucidate changing migration histories (<xref ref-type="bibr" rid="bib31">Mathieson et al., 2018</xref>). There are a number of technical challenges in ancient DNA data that make this a difficult problem, particularly high levels of missing and low-coverage data. Our modeling approach could be potentially more robust, in that it takes allele frequencies as input, which may be estimable from dozens of ancient samples at the same spatial location, in spite of high degrees of missingness (<xref ref-type="bibr" rid="bib24">Korneliussen et al., 2014</xref>).</p><p>In closing, we look back to a review titled ‘How Can We Infer Geography and History from Gene Frequencies?’ published in 1982 (<xref ref-type="bibr" rid="bib16">Felsenstein, 1982</xref>). In this review, Felsenstein laid out fundamental open problems in statistical inference in population genetic data, a few of which we restate as they are particularly motivating for our work:</p><list list-type="bullet"><list-item><p><italic>For any given covariance matrix, is there a corresponding migration matrix which would be expected to lead to it? If so, how can we find it?</italic></p> </list-item><list-item><p><italic>How can we characterize the set of possible migration matrices which are compatible with a given set of observed covariances?</italic></p> </list-item><list-item><p><italic>How can we confine our attention to migration patterns which are consistent with the known geometric co-ordinates of the populations?</italic></p> </list-item><list-item><p>How can we make valid statistical estimates of parameters of stepping stone models?</p></list-item></list><p>The methods developed here aim to help address these longstanding problems in statistical population genetics and to provide a foundation for future work to elucidate the role of geography and dispersal in ecological and evolutionary processes.</p></sec><sec id="s4" sec-type="materials|methods"><title>Materials and methods</title><sec id="s4-1"><title>Model description</title><p>See Appendix 1 ‘<italic>Mathematical notation</italic>’ for a detailed description of the notation used to describe the model. To visualize and model spatial patterns in a given population genetic dataset, FEEMS uses an undirected graph, <inline-formula><mml:math id="inf59"><mml:mrow><mml:mi class="ltx_font_mathcaligraphic" mathsize="80%">𝒢</mml:mi><mml:mo mathsize="80%" stretchy="false">=</mml:mo><mml:mrow><mml:mo maxsize="80%" minsize="80%">(</mml:mo><mml:mi class="ltx_font_mathcaligraphic" mathsize="80%">𝒱</mml:mi><mml:mo mathsize="80%" stretchy="false">,</mml:mo><mml:mi class="ltx_font_mathcaligraphic" mathsize="80%">ℰ</mml:mi><mml:mo maxsize="80%" minsize="80%">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> with <inline-formula><mml:math id="inf60"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mrow><mml:mo>|</mml:mo><mml:mrow><mml:mi mathvariant="script">𝒱</mml:mi></mml:mrow><mml:mo>|</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mi>d</mml:mi></mml:mrow></mml:mstyle></mml:math></inline-formula>, where nodes represent sub-populations and edge weights <inline-formula><mml:math id="inf61"><mml:msub><mml:mrow><mml:mo maxsize="80%" minsize="80%">(</mml:mo><mml:msub><mml:mi mathsize="80%">w</mml:mi><mml:mrow><mml:mi mathsize="80%">k</mml:mi><mml:mo>⁢</mml:mo><mml:mi mathsize="80%" mathvariant="normal">ℓ</mml:mi></mml:mrow></mml:msub><mml:mo maxsize="80%" minsize="80%">)</mml:mo></mml:mrow><mml:mrow><mml:mrow><mml:mo maxsize="80%" minsize="80%">(</mml:mo><mml:mi mathsize="80%">k</mml:mi><mml:mo mathsize="80%" stretchy="false">,</mml:mo><mml:mi mathsize="80%" mathvariant="normal">ℓ</mml:mi><mml:mo maxsize="80%" minsize="80%">)</mml:mo></mml:mrow><mml:mo mathsize="80%" stretchy="false">∈</mml:mo><mml:mi class="ltx_font_mathcaligraphic" mathsize="80%">ℰ</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> represent the level of gene-flow between sub-populations <inline-formula><mml:math id="inf62"><mml:mi mathsize="80%">k</mml:mi></mml:math></inline-formula> and <inline-formula><mml:math id="inf63"><mml:mi mathsize="80%" mathvariant="normal">ℓ</mml:mi></mml:math></inline-formula>. For computational convenience, we assume <inline-formula><mml:math id="inf64"><mml:mi class="ltx_font_mathcaligraphic" mathsize="80%">𝒢</mml:mi></mml:math></inline-formula> is a highly sparse graph, specifically a triangular grid that is embedded in geographic space around the sample coordinates. We observe a genotype matrix, <inline-formula><mml:math id="inf65"><mml:mrow><mml:mi mathsize="80%" mathvariant="bold-italic">𝒀</mml:mi><mml:mo mathsize="80%" stretchy="false">∈</mml:mo><mml:msup><mml:mi mathsize="80%">ℝ</mml:mi><mml:mrow><mml:mi mathsize="80%">n</mml:mi><mml:mo mathsize="80%" stretchy="false">×</mml:mo><mml:mi mathsize="80%">p</mml:mi></mml:mrow></mml:msup></mml:mrow></mml:math></inline-formula>, with <inline-formula><mml:math id="inf66"><mml:mi mathsize="80%">n</mml:mi></mml:math></inline-formula> rows representing individuals and <inline-formula><mml:math id="inf67"><mml:mi mathsize="80%">p</mml:mi></mml:math></inline-formula> columns representing SNPs. We imagine diploid individuals are sampled on the nodes of <inline-formula><mml:math id="inf68"><mml:mi class="ltx_font_mathcaligraphic" mathsize="80%">𝒢</mml:mi></mml:math></inline-formula> so that <inline-formula><mml:math id="inf69"><mml:mrow><mml:mrow><mml:msub><mml:mi mathsize="80%">y</mml:mi><mml:mrow><mml:mi mathsize="80%">i</mml:mi><mml:mo>⁢</mml:mo><mml:mi mathsize="80%">j</mml:mi></mml:mrow></mml:msub><mml:mo>⁢</mml:mo><mml:mrow><mml:mo maxsize="80%" minsize="80%">(</mml:mo><mml:mi mathsize="80%">k</mml:mi><mml:mo maxsize="80%" minsize="80%">)</mml:mo></mml:mrow></mml:mrow><mml:mo mathsize="80%" stretchy="false">∈</mml:mo><mml:mrow><mml:mo maxsize="80%" minsize="80%">{</mml:mo><mml:mn mathsize="80%">0</mml:mn><mml:mo mathsize="80%" stretchy="false">,</mml:mo><mml:mn mathsize="80%">1</mml:mn><mml:mo mathsize="80%" stretchy="false">,</mml:mo><mml:mn mathsize="80%">2</mml:mn><mml:mo maxsize="80%" minsize="80%">}</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> records the count of some arbitrarily predefined allele in individual <inline-formula><mml:math id="inf70"><mml:mi mathsize="80%">i</mml:mi></mml:math></inline-formula>, SNP <inline-formula><mml:math id="inf71"><mml:mi mathsize="80%">j</mml:mi></mml:math></inline-formula>, on node <inline-formula><mml:math id="inf72"><mml:mrow><mml:mi mathsize="80%">k</mml:mi><mml:mo mathsize="80%" stretchy="false">∈</mml:mo><mml:mi class="ltx_font_mathcaligraphic" mathsize="80%">𝒱</mml:mi></mml:mrow></mml:math></inline-formula>. We assume a commonly used simple Binomial sampling model for the genotypes:<disp-formula id="equ3"><label>(1)</label><mml:math id="m3"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>y</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>k</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mtext> </mml:mtext><mml:msub><mml:mi>f</mml:mi><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>k</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>∼</mml:mo><mml:mtext>Binomial</mml:mtext><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mn>2</mml:mn><mml:mo>,</mml:mo><mml:msub><mml:mi>f</mml:mi><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>k</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>,</mml:mo></mml:mrow></mml:mstyle></mml:math></disp-formula>where conditional on <inline-formula><mml:math id="inf73"><mml:mrow><mml:msub><mml:mi mathsize="80%">f</mml:mi><mml:mi mathsize="80%">j</mml:mi></mml:msub><mml:mo>⁢</mml:mo><mml:mrow><mml:mo maxsize="80%" minsize="80%">(</mml:mo><mml:mi mathsize="80%">k</mml:mi><mml:mo maxsize="80%" minsize="80%">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> for all <inline-formula><mml:math id="inf74"><mml:mrow><mml:mi mathsize="80%">j</mml:mi><mml:mo mathsize="80%" stretchy="false">,</mml:mo><mml:mi mathsize="80%">k</mml:mi></mml:mrow></mml:math></inline-formula>, the <inline-formula><mml:math id="inf75"><mml:mrow><mml:msub><mml:mi mathsize="80%">y</mml:mi><mml:mrow><mml:mi mathsize="80%">i</mml:mi><mml:mo>⁢</mml:mo><mml:mi mathsize="80%">j</mml:mi></mml:mrow></mml:msub><mml:mo>⁢</mml:mo><mml:mrow><mml:mo maxsize="80%" minsize="80%">(</mml:mo><mml:mi mathsize="80%">k</mml:mi><mml:mo maxsize="80%" minsize="80%">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula>’s are independent. We then estimate an allele frequency at each node and SNP by maximum likelihood:<disp-formula id="equ4"><mml:math id="m4"><mml:mrow><mml:mrow><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi mathsize="80%">f</mml:mi><mml:mo mathsize="80%" stretchy="false">^</mml:mo></mml:mover><mml:mi mathsize="80%">j</mml:mi></mml:msub><mml:mo>⁢</mml:mo><mml:mrow><mml:mo maxsize="80%" minsize="80%">(</mml:mo><mml:mi mathsize="80%">k</mml:mi><mml:mo maxsize="80%" minsize="80%">)</mml:mo></mml:mrow></mml:mrow><mml:mo mathsize="80%" stretchy="false">=</mml:mo><mml:mfrac><mml:mrow><mml:msubsup><mml:mo largeop="true" mathsize="80%" stretchy="false" symmetric="true">∑</mml:mo><mml:mrow><mml:mi mathsize="80%">i</mml:mi><mml:mo mathsize="80%" stretchy="false">=</mml:mo><mml:mn mathsize="80%">1</mml:mn></mml:mrow><mml:msub><mml:mi mathsize="80%">n</mml:mi><mml:mi mathsize="80%">k</mml:mi></mml:msub></mml:msubsup><mml:mrow><mml:msub><mml:mi mathsize="80%">y</mml:mi><mml:mrow><mml:mi mathsize="80%">i</mml:mi><mml:mo>⁢</mml:mo><mml:mi mathsize="80%">j</mml:mi></mml:mrow></mml:msub><mml:mo>⁢</mml:mo><mml:mrow><mml:mo maxsize="80%" minsize="80%">(</mml:mo><mml:mi mathsize="80%">k</mml:mi><mml:mo maxsize="80%" minsize="80%">)</mml:mo></mml:mrow></mml:mrow></mml:mrow><mml:mrow><mml:mn mathsize="80%">2</mml:mn><mml:mo>⁢</mml:mo><mml:msub><mml:mi mathsize="80%">n</mml:mi><mml:mi mathsize="80%">k</mml:mi></mml:msub></mml:mrow></mml:mfrac></mml:mrow><mml:mo mathsize="80%" stretchy="false">,</mml:mo></mml:mrow></mml:math></disp-formula>where <inline-formula><mml:math id="inf76"><mml:msub><mml:mi mathsize="80%">n</mml:mi><mml:mi mathsize="80%">k</mml:mi></mml:msub></mml:math></inline-formula> is the number of individuals sampled at node <inline-formula><mml:math id="inf77"><mml:mi mathsize="80%">k</mml:mi></mml:math></inline-formula>. We estimate allele frequencies at <inline-formula><mml:math id="inf78"><mml:mi mathsize="80%">o</mml:mi></mml:math></inline-formula> of the observed nodes out of <inline-formula><mml:math id="inf79"><mml:mi mathsize="80%">d</mml:mi></mml:math></inline-formula> total nodes on the graph. From <xref ref-type="disp-formula" rid="equ3">Equation (1)</xref>, the estimated frequency in a particular sub-population, conditional on the latent allele frequency, will approximately follow a Gaussian distribution:<disp-formula id="equ5"><mml:math id="m5"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mrow><mml:mover><mml:mi>f</mml:mi><mml:mo>^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>k</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mtext> </mml:mtext><mml:msub><mml:mi>f</mml:mi><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>k</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>∼</mml:mo><mml:mrow><mml:mi mathvariant="script">𝒩</mml:mi></mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>f</mml:mi><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>k</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>,</mml:mo><mml:mfrac><mml:mrow><mml:msub><mml:mi>f</mml:mi><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>k</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:msub><mml:mi>f</mml:mi><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>k</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mrow><mml:mn>2</mml:mn><mml:msub><mml:mi>n</mml:mi><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfrac></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>.</mml:mo></mml:mrow></mml:mstyle></mml:math></disp-formula></p><p>Using vector notation, we represent the joint model of estimated allele frequencies as:<disp-formula id="equ6"><label>(2)</label><mml:math id="m6"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mrow><mml:mover><mml:mi mathvariant="bold-italic">f</mml:mi><mml:mo>^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mtext> </mml:mtext><mml:msub><mml:mi mathvariant="bold-italic">f</mml:mi><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>∼</mml:mo><mml:msub><mml:mrow><mml:mi mathvariant="script">𝒩</mml:mi></mml:mrow><mml:mrow><mml:mi>o</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi mathvariant="bold-italic">A</mml:mi><mml:msub><mml:mi mathvariant="bold-italic">f</mml:mi><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:mtext>diag</mml:mtext><mml:mrow><mml:mo>(</mml:mo><mml:msub><mml:mi mathvariant="bold-italic">d</mml:mi><mml:mrow><mml:mi mathvariant="bold-italic">f</mml:mi><mml:mo mathvariant="bold">,</mml:mo><mml:mi mathvariant="bold-italic">n</mml:mi></mml:mrow></mml:msub><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>,</mml:mo></mml:mrow></mml:mstyle></mml:math></disp-formula>where <inline-formula><mml:math id="inf80"><mml:msub><mml:mover accent="true"><mml:mi mathsize="80%" mathvariant="bold-italic">𝒇</mml:mi><mml:mo mathsize="80%" stretchy="false">^</mml:mo></mml:mover><mml:mi mathsize="80%">j</mml:mi></mml:msub></mml:math></inline-formula> is a <inline-formula><mml:math id="inf81"><mml:mrow><mml:mi mathsize="80%">o</mml:mi><mml:mo mathsize="80%" stretchy="false">×</mml:mo><mml:mn mathsize="80%">1</mml:mn></mml:mrow></mml:math></inline-formula> vector of estimated allele frequencies at observed nodes, <inline-formula><mml:math id="inf82"><mml:msub><mml:mi mathsize="80%" mathvariant="bold-italic">𝒇</mml:mi><mml:mi mathsize="80%">j</mml:mi></mml:msub></mml:math></inline-formula> is a <inline-formula><mml:math id="inf83"><mml:mrow><mml:mi mathsize="80%">d</mml:mi><mml:mo mathsize="80%" stretchy="false">×</mml:mo><mml:mn mathsize="80%">1</mml:mn></mml:mrow></mml:math></inline-formula> vector of latent allele frequencies at all the nodes (both observed and unobserved), and <inline-formula><mml:math id="inf84"><mml:mi mathsize="80%" mathvariant="bold-italic">𝑨</mml:mi></mml:math></inline-formula> is a <inline-formula><mml:math id="inf85"><mml:mrow><mml:mi mathsize="80%">o</mml:mi><mml:mo mathsize="80%" stretchy="false">×</mml:mo><mml:mi mathsize="80%">d</mml:mi></mml:mrow></mml:math></inline-formula> node assignment matrix where <inline-formula><mml:math id="inf86"><mml:mrow><mml:msub><mml:mi mathsize="80%" mathvariant="bold-italic">𝑨</mml:mi><mml:mrow><mml:mi mathsize="80%">k</mml:mi><mml:mo>⁢</mml:mo><mml:mi mathsize="80%" mathvariant="normal">ℓ</mml:mi></mml:mrow></mml:msub><mml:mo mathsize="80%" stretchy="false">=</mml:mo><mml:mn mathsize="80%">1</mml:mn></mml:mrow></mml:math></inline-formula> if the <italic>k</italic>th estimated allele frequency comes from sub-population <inline-formula><mml:math id="inf87"><mml:mi mathsize="80%" mathvariant="normal">ℓ</mml:mi></mml:math></inline-formula> and <inline-formula><mml:math id="inf88"><mml:mrow><mml:msub><mml:mi mathsize="80%" mathvariant="bold-italic">𝑨</mml:mi><mml:mrow><mml:mi mathsize="80%">k</mml:mi><mml:mo>⁢</mml:mo><mml:mi mathsize="80%" mathvariant="normal">ℓ</mml:mi></mml:mrow></mml:msub><mml:mo mathsize="80%" stretchy="false">=</mml:mo><mml:mn mathsize="80%">0</mml:mn></mml:mrow></mml:math></inline-formula> otherwise; and <inline-formula><mml:math id="inf89"><mml:mrow><mml:mtext mathsize="80%">diag</mml:mtext><mml:mo>⁢</mml:mo><mml:mrow><mml:mo maxsize="80%" minsize="80%">(</mml:mo><mml:msub><mml:mi mathsize="80%" mathvariant="bold-italic">𝒅</mml:mi><mml:mrow><mml:mi mathsize="80%" mathvariant="bold-italic">𝒇</mml:mi><mml:mo mathsize="80%" mathvariant="bold" stretchy="false">,</mml:mo><mml:mi mathsize="80%" mathvariant="bold-italic">𝒏</mml:mi></mml:mrow></mml:msub><mml:mo maxsize="80%" minsize="80%">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> denotes a <inline-formula><mml:math id="inf90"><mml:mrow><mml:mi mathsize="80%">o</mml:mi><mml:mo mathsize="80%" stretchy="false">×</mml:mo><mml:mi mathsize="80%">o</mml:mi></mml:mrow></mml:math></inline-formula> diagonal matrix whose diagonal elements corresponds to the appropriate variance term at observed nodes.</p><p>To summarize, we estimate allele frequencies from a subset of nodes on the graph and define latent allele frequencies for all the nodes of the graph. The assignment matrix <inline-formula><mml:math id="inf91"><mml:mi mathsize="80%" mathvariant="bold-italic">𝑨</mml:mi></mml:math></inline-formula> maps these latent allele frequencies to our observations. Our summary statistics (the data) are thus <inline-formula><mml:math id="inf92"><mml:mrow><mml:mo maxsize="80%" minsize="80%">(</mml:mo><mml:mover accent="true"><mml:mi mathsize="80%" mathvariant="bold-italic">𝑭</mml:mi><mml:mo mathsize="80%" stretchy="false">^</mml:mo></mml:mover><mml:mo mathsize="80%" stretchy="false">,</mml:mo><mml:mi mathsize="80%" mathvariant="bold-italic">𝒏</mml:mi><mml:mo maxsize="80%" minsize="80%">)</mml:mo></mml:mrow></mml:math></inline-formula> where <inline-formula><mml:math id="inf93"><mml:mover accent="true"><mml:mi mathsize="80%" mathvariant="bold-italic">𝑭</mml:mi><mml:mo mathsize="80%" stretchy="false">^</mml:mo></mml:mover></mml:math></inline-formula> is a <inline-formula><mml:math id="inf94"><mml:mrow><mml:mi mathsize="80%">o</mml:mi><mml:mo mathsize="80%" stretchy="false">×</mml:mo><mml:mi mathsize="80%">p</mml:mi></mml:mrow></mml:math></inline-formula> matrix of estimated allele frequencies and <inline-formula><mml:math id="inf95"><mml:mi mathsize="80%" mathvariant="bold-italic">𝒏</mml:mi></mml:math></inline-formula> is a <inline-formula><mml:math id="inf96"><mml:mrow><mml:mi mathsize="80%">o</mml:mi><mml:mo mathsize="80%" stretchy="false">×</mml:mo><mml:mn mathsize="80%">1</mml:mn></mml:mrow></mml:math></inline-formula> vector of sample sizes for every observed node. We assume the latent allele frequencies come from a Gaussian Markov Random Field:<disp-formula id="equ7"><label>(3)</label><mml:math id="m7"><mml:mrow><mml:mrow><mml:msub><mml:mi mathsize="80%">𝒇</mml:mi><mml:mi mathsize="80%">j</mml:mi></mml:msub><mml:mo mathsize="80%" stretchy="false">∼</mml:mo><mml:mrow><mml:msub><mml:mi class="ltx_font_mathcaligraphic" mathsize="80%">𝒩</mml:mi><mml:mi mathsize="80%">d</mml:mi></mml:msub><mml:mo>⁢</mml:mo><mml:mrow><mml:mo maxsize="160%" minsize="160%">(</mml:mo><mml:mrow><mml:msub><mml:mi mathsize="80%">μ</mml:mi><mml:mi mathsize="80%">j</mml:mi></mml:msub><mml:mo>⁢</mml:mo><mml:mn mathsize="80%">𝟏</mml:mn></mml:mrow><mml:mo mathsize="80%" stretchy="false">,</mml:mo><mml:mrow><mml:msub><mml:mi mathsize="80%">μ</mml:mi><mml:mi mathsize="80%">j</mml:mi></mml:msub><mml:mo>⁢</mml:mo><mml:mrow><mml:mo maxsize="80%" minsize="80%">(</mml:mo><mml:mrow><mml:mn mathsize="80%">1</mml:mn><mml:mo mathsize="80%" stretchy="false">-</mml:mo><mml:msub><mml:mi mathsize="80%">μ</mml:mi><mml:mi mathsize="80%">j</mml:mi></mml:msub></mml:mrow><mml:mo maxsize="80%" minsize="80%">)</mml:mo></mml:mrow><mml:mo>⁢</mml:mo><mml:msup><mml:mi mathsize="80%">𝑳</mml:mi><mml:mo mathsize="80%" stretchy="false">†</mml:mo></mml:msup></mml:mrow><mml:mo maxsize="160%" minsize="160%">)</mml:mo></mml:mrow></mml:mrow></mml:mrow><mml:mo mathsize="80%" stretchy="false">,</mml:mo></mml:mrow></mml:math></disp-formula>where <inline-formula><mml:math id="inf97"><mml:mi mathsize="80%" mathvariant="bold-italic">𝑳</mml:mi></mml:math></inline-formula> is the graph Laplacian, † represents the pseudo-inverse operator, and <inline-formula><mml:math id="inf98"><mml:msub><mml:mi mathsize="80%">μ</mml:mi><mml:mi mathsize="80%">j</mml:mi></mml:msub></mml:math></inline-formula> represents the average allele frequency across all of the sub-populations. Note that the multiplication by the SNP-specific factor <inline-formula><mml:math id="inf99"><mml:mrow><mml:msub><mml:mi mathsize="80%">μ</mml:mi><mml:mi mathsize="80%">j</mml:mi></mml:msub><mml:mo>⁢</mml:mo><mml:mrow><mml:mo maxsize="80%" minsize="80%">(</mml:mo><mml:mrow><mml:mn mathsize="80%">1</mml:mn><mml:mo mathsize="80%" stretchy="false">-</mml:mo><mml:msub><mml:mi mathsize="80%">μ</mml:mi><mml:mi mathsize="80%">j</mml:mi></mml:msub></mml:mrow><mml:mo maxsize="80%" minsize="80%">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> ensures that the variance of the latent allele frequencies vanishes as the average allele frequency approaches to 0 or 1. One interpretation of this model is that the expected squared Euclidean distance between latent allele frequencies on the graph, after being re-scaled by <inline-formula><mml:math id="inf100"><mml:mrow><mml:msub><mml:mi mathsize="80%">μ</mml:mi><mml:mi mathsize="80%">j</mml:mi></mml:msub><mml:mo>⁢</mml:mo><mml:mrow><mml:mo maxsize="80%" minsize="80%">(</mml:mo><mml:mrow><mml:mn mathsize="80%">1</mml:mn><mml:mo mathsize="80%" stretchy="false">-</mml:mo><mml:msub><mml:mi mathsize="80%">μ</mml:mi><mml:mi mathsize="80%">j</mml:mi></mml:msub></mml:mrow><mml:mo maxsize="80%" minsize="80%">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula>, is exactly the resistance distance of an electrical circuit (<xref ref-type="bibr" rid="bib33">McRae, 2006</xref>; <xref ref-type="bibr" rid="bib19">Hanks and Hooten, 2013</xref>):<disp-formula id="equ8"><mml:math id="m8"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mfrac><mml:mrow><mml:mrow><mml:mi mathvariant="double-struck">E</mml:mi></mml:mrow><mml:mrow><mml:mo>[</mml:mo><mml:msup><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>f</mml:mi><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>k</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>−</mml:mo><mml:msub><mml:mi>f</mml:mi><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>ℓ</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup><mml:mo>]</mml:mo></mml:mrow></mml:mrow><mml:mrow><mml:msub><mml:mi>μ</mml:mi><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:msub><mml:mi>μ</mml:mi><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mfrac><mml:mo>=</mml:mo><mml:msub><mml:mi>r</mml:mi><mml:mrow><mml:mi>k</mml:mi><mml:mi>ℓ</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:mrow><mml:mspace width="1em"/><mml:mi mathvariant="normal">w</mml:mi><mml:mi mathvariant="normal">h</mml:mi><mml:mi mathvariant="normal">e</mml:mi><mml:mi mathvariant="normal">r</mml:mi><mml:mi mathvariant="normal">e</mml:mi></mml:mrow><mml:mtext> </mml:mtext><mml:msub><mml:mi>r</mml:mi><mml:mrow><mml:mi>k</mml:mi><mml:mi>ℓ</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi mathvariant="bold-italic">o</mml:mi><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:msub><mml:mo>−</mml:mo><mml:msub><mml:mi mathvariant="bold-italic">o</mml:mi><mml:mrow><mml:mi>ℓ</mml:mi></mml:mrow></mml:msub><mml:msup><mml:mo stretchy="false">)</mml:mo><mml:mrow><mml:mi mathvariant="normal">⊤</mml:mi></mml:mrow></mml:msup><mml:msup><mml:mi mathvariant="bold-italic">L</mml:mi><mml:mrow><mml:mo>†</mml:mo></mml:mrow></mml:msup><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi mathvariant="bold-italic">o</mml:mi><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:msub><mml:mo>−</mml:mo><mml:msub><mml:mi mathvariant="bold-italic">o</mml:mi><mml:mrow><mml:mi>ℓ</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:msubsup><mml:mi mathvariant="bold-italic">L</mml:mi><mml:mrow><mml:mi>k</mml:mi><mml:mi>k</mml:mi></mml:mrow><mml:mrow><mml:mo>†</mml:mo></mml:mrow></mml:msubsup><mml:mo>−</mml:mo><mml:mn>2</mml:mn><mml:msubsup><mml:mi mathvariant="bold-italic">L</mml:mi><mml:mrow><mml:mi>k</mml:mi><mml:mi>ℓ</mml:mi></mml:mrow><mml:mrow><mml:mo>†</mml:mo></mml:mrow></mml:msubsup><mml:mo>+</mml:mo><mml:msubsup><mml:mi mathvariant="bold-italic">L</mml:mi><mml:mrow><mml:mi>ℓ</mml:mi><mml:mi>ℓ</mml:mi></mml:mrow><mml:mrow><mml:mo>†</mml:mo></mml:mrow></mml:msubsup><mml:mo>,</mml:mo></mml:mrow></mml:mstyle></mml:math></disp-formula>where <inline-formula><mml:math id="inf101"><mml:msub><mml:mi mathsize="80%" mathvariant="bold-italic">𝒐</mml:mi><mml:mi mathsize="80%">i</mml:mi></mml:msub></mml:math></inline-formula> is a one-hot vector (i.e. storing a 1 in element <inline-formula><mml:math id="inf102"><mml:mi mathsize="80%">i</mml:mi></mml:math></inline-formula> and zeros elsewhere). It is known that the resistance distance <inline-formula><mml:math id="inf103"><mml:msub><mml:mi mathsize="80%">r</mml:mi><mml:mrow><mml:mi mathsize="80%">k</mml:mi><mml:mo>⁢</mml:mo><mml:mi mathsize="80%" mathvariant="normal">ℓ</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> is equivalent to the expected commute time between nodes <inline-formula><mml:math id="inf104"><mml:mi mathsize="80%">k</mml:mi></mml:math></inline-formula> and <inline-formula><mml:math id="inf105"><mml:mi mathsize="80%" mathvariant="normal">ℓ</mml:mi></mml:math></inline-formula> of a random walker on the weighted graph <inline-formula><mml:math id="inf106"><mml:mi class="ltx_font_mathcaligraphic" mathsize="80%">𝒢</mml:mi></mml:math></inline-formula> (<xref ref-type="bibr" rid="bib10">Chandra et al., 1996</xref>). Additionally, the model (<xref ref-type="disp-formula" rid="equ7">Equation 3</xref>) forms a Markov random field, and thus any latent allele frequency <inline-formula><mml:math id="inf107"><mml:mrow><mml:msub><mml:mi mathsize="80%">f</mml:mi><mml:mi mathsize="80%">j</mml:mi></mml:msub><mml:mo>⁢</mml:mo><mml:mrow><mml:mo maxsize="80%" minsize="80%">(</mml:mo><mml:mi mathsize="80%">k</mml:mi><mml:mo maxsize="80%" minsize="80%">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> is conditionally independent of all other allele frequencies given its neighbors which are encoded by nonzero elements of <inline-formula><mml:math id="inf108"><mml:mi mathsize="80%" mathvariant="bold-italic">𝑳</mml:mi></mml:math></inline-formula> (<xref ref-type="bibr" rid="bib25">Lauritzen, 1996</xref>; <xref ref-type="bibr" rid="bib23">Koller and Friedman, 2009</xref>). Since we use a triangular grid embedded in geographic space to define the graph <inline-formula><mml:math id="inf109"><mml:mi class="ltx_font_mathcaligraphic" mathsize="80%">𝒢</mml:mi></mml:math></inline-formula>, the pattern of nonzero elements is prefixed by the structure of the sparse traingular grid.</p><p>Using the law of total variance formula, we can derive from (<xref ref-type="disp-formula" rid="equ6 equ7">Equations 2, 3</xref>) an analytic form for the marginal likelihood. Before proceeding, however, we further approximate the model by assuming <inline-formula><mml:math id="inf110"><mml:mrow><mml:mrow><mml:mfrac><mml:mn mathsize="80%">1</mml:mn><mml:mn mathsize="80%">2</mml:mn></mml:mfrac><mml:mo>⁢</mml:mo><mml:msub><mml:mi mathsize="80%">f</mml:mi><mml:mi mathsize="80%">j</mml:mi></mml:msub><mml:mo>⁢</mml:mo><mml:mrow><mml:mo maxsize="80%" minsize="80%">(</mml:mo><mml:mi mathsize="80%">k</mml:mi><mml:mo maxsize="80%" minsize="80%">)</mml:mo></mml:mrow><mml:mo>⁢</mml:mo><mml:mrow><mml:mo maxsize="80%" minsize="80%">(</mml:mo><mml:mrow><mml:mn mathsize="80%">1</mml:mn><mml:mo mathsize="80%" stretchy="false">-</mml:mo><mml:mrow><mml:msub><mml:mi mathsize="80%">f</mml:mi><mml:mi mathsize="80%">j</mml:mi></mml:msub><mml:mo>⁢</mml:mo><mml:mrow><mml:mo maxsize="80%" minsize="80%">(</mml:mo><mml:mi mathsize="80%">k</mml:mi><mml:mo maxsize="80%" minsize="80%">)</mml:mo></mml:mrow></mml:mrow></mml:mrow><mml:mo maxsize="80%" minsize="80%">)</mml:mo></mml:mrow></mml:mrow><mml:mo mathsize="80%" stretchy="false">≈</mml:mo><mml:mrow><mml:msup><mml:mi mathsize="80%">σ</mml:mi><mml:mn mathsize="80%">2</mml:mn></mml:msup><mml:mo>⁢</mml:mo><mml:msub><mml:mi mathsize="80%">μ</mml:mi><mml:mi mathsize="80%">j</mml:mi></mml:msub><mml:mo>⁢</mml:mo><mml:mrow><mml:mo maxsize="80%" minsize="80%">(</mml:mo><mml:mrow><mml:mn mathsize="80%">1</mml:mn><mml:mo mathsize="80%" stretchy="false">-</mml:mo><mml:msub><mml:mi mathsize="80%">μ</mml:mi><mml:mi mathsize="80%">j</mml:mi></mml:msub></mml:mrow><mml:mo maxsize="80%" minsize="80%">)</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:math></inline-formula> for all <inline-formula><mml:math id="inf111"><mml:mi mathsize="80%">j</mml:mi></mml:math></inline-formula> and <inline-formula><mml:math id="inf112"><mml:mi mathsize="80%">k</mml:mi></mml:math></inline-formula> (see Appendix 1 ‘<italic>Estimating the edge weights under the exact likelihood model</italic>’ for the data model without this approximation). This assumption is mainly for computational purposes and may be a coarse approximation in general. On the other hand, the assumption is not too strong if we exclude SNPs with extremely rare allele frequencies, and more importantly, we find it leads to a good empirical performance, both statistically and computationally. With this approximation, the residual variance parameter <inline-formula><mml:math id="inf113"><mml:msup><mml:mi mathsize="80%">σ</mml:mi><mml:mn mathsize="80%">2</mml:mn></mml:msup></mml:math></inline-formula> is still unknown and needs to be estimated.</p><p>Under (<xref ref-type="disp-formula" rid="equ6 equ7">Equation 2, 3</xref>), the law of total variance formula leads to specific formulas for the mean and variance structure as given in (<xref ref-type="disp-formula" rid="equ9">Equation 4</xref>). With those results, we arrive at the following approximate marginal likelihood:<disp-formula id="equ9"><label>(4)</label><mml:math id="m9"><mml:mrow><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi mathsize="80%">𝒇</mml:mi><mml:mo mathsize="80%" stretchy="false">^</mml:mo></mml:mover><mml:mi mathsize="80%">j</mml:mi></mml:msub><mml:mo mathsize="80%" stretchy="false">∼</mml:mo><mml:mrow><mml:msub><mml:mi class="ltx_font_mathcaligraphic" mathsize="80%">𝒩</mml:mi><mml:mi mathsize="80%">o</mml:mi></mml:msub><mml:mo>⁢</mml:mo><mml:mrow><mml:mo maxsize="160%" minsize="160%">(</mml:mo><mml:mrow><mml:msub><mml:mi mathsize="80%">μ</mml:mi><mml:mi mathsize="80%">j</mml:mi></mml:msub><mml:mo>⁢</mml:mo><mml:mn mathsize="80%">𝟏</mml:mn></mml:mrow><mml:mo mathsize="80%" stretchy="false">,</mml:mo><mml:mrow><mml:mrow><mml:msub><mml:mi mathsize="80%">μ</mml:mi><mml:mi mathsize="80%">j</mml:mi></mml:msub><mml:mo>⁢</mml:mo><mml:mrow><mml:mo maxsize="80%" minsize="80%">(</mml:mo><mml:mrow><mml:mn mathsize="80%">1</mml:mn><mml:mo mathsize="80%" stretchy="false">-</mml:mo><mml:msub><mml:mi mathsize="80%">μ</mml:mi><mml:mi mathsize="80%">j</mml:mi></mml:msub></mml:mrow><mml:mo maxsize="80%" minsize="80%">)</mml:mo></mml:mrow></mml:mrow><mml:mo mathsize="80%" stretchy="false">⋅</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mrow><mml:mi mathsize="80%">𝑨</mml:mi><mml:mo>⁢</mml:mo><mml:msup><mml:mi mathsize="80%">𝑳</mml:mi><mml:mo mathsize="80%" stretchy="false">†</mml:mo></mml:msup><mml:mo>⁢</mml:mo><mml:msup><mml:mi mathsize="80%">𝑨</mml:mi><mml:mo mathsize="80%" stretchy="false">⊤</mml:mo></mml:msup></mml:mrow><mml:mo mathsize="80%" stretchy="false">+</mml:mo><mml:mrow><mml:msup><mml:mi mathsize="80%">σ</mml:mi><mml:mn mathsize="80%">2</mml:mn></mml:msup><mml:mo>⁢</mml:mo><mml:mtext mathsize="80%">diag</mml:mtext><mml:mo>⁢</mml:mo><mml:mrow><mml:mo maxsize="120%" minsize="120%">(</mml:mo><mml:msup><mml:mi mathsize="80%">𝒏</mml:mi><mml:mrow><mml:mo mathsize="80%" stretchy="false">-</mml:mo><mml:mn mathsize="80%">1</mml:mn></mml:mrow></mml:msup><mml:mo maxsize="120%" minsize="120%">)</mml:mo></mml:mrow></mml:mrow></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo maxsize="160%" minsize="160%">)</mml:mo></mml:mrow></mml:mrow></mml:mrow><mml:mo mathsize="80%" stretchy="false">,</mml:mo></mml:mrow></mml:math></disp-formula>where <inline-formula><mml:math id="inf114"><mml:mrow><mml:mtext mathsize="80%">diag</mml:mtext><mml:mo>⁢</mml:mo><mml:mrow><mml:mo maxsize="80%" minsize="80%">(</mml:mo><mml:msup><mml:mi mathsize="80%" mathvariant="bold-italic">𝒏</mml:mi><mml:mrow><mml:mo mathsize="80%" stretchy="false">-</mml:mo><mml:mn mathsize="80%">1</mml:mn></mml:mrow></mml:msup><mml:mo maxsize="80%" minsize="80%">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> is a <inline-formula><mml:math id="inf115"><mml:mrow><mml:mi mathsize="80%">o</mml:mi><mml:mo mathsize="80%" stretchy="false">×</mml:mo><mml:mi mathsize="80%">o</mml:mi></mml:mrow></mml:math></inline-formula> diagonal matrix computed from the sample sizes at observed nodes. We note the marginal distribution of <inline-formula><mml:math id="inf116"><mml:msub><mml:mover accent="true"><mml:mi mathsize="80%">f</mml:mi><mml:mo mathsize="80%" stretchy="false">^</mml:mo></mml:mover><mml:mi mathsize="80%">j</mml:mi></mml:msub></mml:math></inline-formula> is not necessarily a Gaussian distribution; however, we use a Gaussian approximation to facilitate computation.</p><p>To remove the SNP means we transform the estimated frequencies by a contrast matrix, <inline-formula><mml:math id="inf117"><mml:mrow><mml:mi mathsize="80%" mathvariant="bold-italic">𝑪</mml:mi><mml:mo mathsize="80%" stretchy="false">∈</mml:mo><mml:msup><mml:mi mathsize="80%">ℝ</mml:mi><mml:mrow><mml:mrow><mml:mo maxsize="80%" minsize="80%">(</mml:mo><mml:mrow><mml:mi mathsize="80%">o</mml:mi><mml:mo mathsize="80%" stretchy="false">-</mml:mo><mml:mn mathsize="80%">1</mml:mn></mml:mrow><mml:mo maxsize="80%" minsize="80%">)</mml:mo></mml:mrow><mml:mo mathsize="80%" stretchy="false">×</mml:mo><mml:mi mathsize="80%">o</mml:mi></mml:mrow></mml:msup></mml:mrow></mml:math></inline-formula>, that is orthogonal to the one-vector:<disp-formula id="equ10"><label>(5)</label><mml:math id="m10"><mml:mrow><mml:mrow><mml:mrow><mml:mi mathsize="80%">𝑪</mml:mi><mml:mo>⁢</mml:mo><mml:msub><mml:mover accent="true"><mml:mi mathsize="80%">𝒇</mml:mi><mml:mo mathsize="80%" stretchy="false">^</mml:mo></mml:mover><mml:mi mathsize="80%">j</mml:mi></mml:msub></mml:mrow><mml:mo mathsize="80%" stretchy="false">∼</mml:mo><mml:mrow><mml:mrow><mml:msqrt><mml:mrow><mml:msub><mml:mi mathsize="80%">μ</mml:mi><mml:mi mathsize="80%">j</mml:mi></mml:msub><mml:mo>⁢</mml:mo><mml:mrow><mml:mo maxsize="80%" minsize="80%">(</mml:mo><mml:mrow><mml:mn mathsize="80%">1</mml:mn><mml:mo mathsize="80%" stretchy="false">-</mml:mo><mml:msub><mml:mi mathsize="80%">μ</mml:mi><mml:mi mathsize="80%">j</mml:mi></mml:msub></mml:mrow><mml:mo maxsize="80%" minsize="80%">)</mml:mo></mml:mrow></mml:mrow></mml:msqrt><mml:mo mathsize="80%" stretchy="false">⋅</mml:mo><mml:msub><mml:mi class="ltx_font_mathcaligraphic" mathsize="80%">𝒩</mml:mi><mml:mrow><mml:mi mathsize="80%">o</mml:mi><mml:mo mathsize="80%" stretchy="false">-</mml:mo><mml:mn mathsize="80%">1</mml:mn></mml:mrow></mml:msub></mml:mrow><mml:mo>⁢</mml:mo><mml:mrow><mml:mo maxsize="260%" minsize="260%">(</mml:mo><mml:mn mathsize="80%"/><mml:mo mathsize="80%" stretchy="false">,</mml:mo><mml:mrow><mml:mrow><mml:mi mathsize="80%">𝑪</mml:mi><mml:mo>⁢</mml:mo><mml:mi mathsize="80%">𝑨</mml:mi><mml:mo>⁢</mml:mo><mml:msup><mml:mi mathsize="80%">𝑳</mml:mi><mml:mo mathsize="80%" stretchy="false">†</mml:mo></mml:msup><mml:mo>⁢</mml:mo><mml:msup><mml:mi mathsize="80%">𝑨</mml:mi><mml:mo mathsize="80%" stretchy="false">⊤</mml:mo></mml:msup><mml:mo>⁢</mml:mo><mml:msup><mml:mi mathsize="80%">𝑪</mml:mi><mml:mo mathsize="80%" stretchy="false">⊤</mml:mo></mml:msup></mml:mrow><mml:mo mathsize="80%" stretchy="false">+</mml:mo><mml:mrow><mml:msup><mml:mi mathsize="80%">σ</mml:mi><mml:mn mathsize="80%">2</mml:mn></mml:msup><mml:mo>⁢</mml:mo><mml:mi mathsize="80%">𝑪</mml:mi><mml:mo>⁢</mml:mo><mml:mtext mathsize="80%">diag</mml:mtext><mml:mo>⁢</mml:mo><mml:mrow><mml:mo maxsize="120%" minsize="120%">(</mml:mo><mml:msup><mml:mi mathsize="80%">𝒏</mml:mi><mml:mrow><mml:mo mathsize="80%" stretchy="false">-</mml:mo><mml:mn mathsize="80%">1</mml:mn></mml:mrow></mml:msup><mml:mo maxsize="120%" minsize="120%">)</mml:mo></mml:mrow><mml:mo>⁢</mml:mo><mml:msup><mml:mi mathsize="80%">𝑪</mml:mi><mml:mo mathsize="80%" stretchy="false">⊤</mml:mo></mml:msup></mml:mrow></mml:mrow><mml:mo maxsize="260%" minsize="260%">)</mml:mo></mml:mrow></mml:mrow></mml:mrow><mml:mo mathsize="80%" stretchy="false">.</mml:mo></mml:mrow></mml:math></disp-formula></p><p>Let <inline-formula><mml:math id="inf118"><mml:mrow><mml:mover accent="true"><mml:mi mathsize="80%" mathvariant="bold">𝚺</mml:mi><mml:mo mathsize="80%" stretchy="false">^</mml:mo></mml:mover><mml:mo mathsize="80%" stretchy="false">=</mml:mo><mml:mrow><mml:mfrac><mml:mn mathsize="80%">1</mml:mn><mml:mi mathsize="80%">p</mml:mi></mml:mfrac><mml:mo>⁢</mml:mo><mml:msub><mml:mover accent="true"><mml:mi mathsize="80%" mathvariant="bold-italic">𝑭</mml:mi><mml:mo mathsize="80%" stretchy="false">^</mml:mo></mml:mover><mml:mtext mathsize="80%">s</mml:mtext></mml:msub><mml:mo>⁢</mml:mo><mml:msubsup><mml:mover accent="true"><mml:mi mathsize="80%" mathvariant="bold-italic">𝑭</mml:mi><mml:mo mathsize="80%" stretchy="false">^</mml:mo></mml:mover><mml:mtext mathsize="80%">s</mml:mtext><mml:mo mathsize="80%" stretchy="false">⊤</mml:mo></mml:msubsup></mml:mrow></mml:mrow></mml:math></inline-formula> be the <inline-formula><mml:math id="inf119"><mml:mrow><mml:mi mathsize="80%">o</mml:mi><mml:mo mathsize="80%" stretchy="false">×</mml:mo><mml:mi mathsize="80%">o</mml:mi></mml:mrow></mml:math></inline-formula> sample covariance matrix of estimated allele frequencies after re-scaling, that is, <inline-formula><mml:math id="inf120"><mml:msub><mml:mover accent="true"><mml:mi mathsize="80%" mathvariant="bold-italic">𝑭</mml:mi><mml:mo mathsize="80%" stretchy="false">^</mml:mo></mml:mover><mml:mtext mathsize="80%">s</mml:mtext></mml:msub></mml:math></inline-formula> is a matrix formed by rescaling the columns of <inline-formula><mml:math id="inf121"><mml:mover accent="true"><mml:mi mathsize="80%" mathvariant="bold-italic">𝑭</mml:mi><mml:mo mathsize="80%" stretchy="false">^</mml:mo></mml:mover></mml:math></inline-formula> by <inline-formula><mml:math id="inf122"><mml:msqrt><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi mathsize="80%">μ</mml:mi><mml:mo mathsize="80%" stretchy="false">^</mml:mo></mml:mover><mml:mi mathsize="80%">j</mml:mi></mml:msub><mml:mo>⁢</mml:mo><mml:mrow><mml:mo maxsize="80%" minsize="80%">(</mml:mo><mml:mrow><mml:mn mathsize="80%">1</mml:mn><mml:mo mathsize="80%" stretchy="false">-</mml:mo><mml:msub><mml:mover accent="true"><mml:mi mathsize="80%">μ</mml:mi><mml:mo mathsize="80%" stretchy="false">^</mml:mo></mml:mover><mml:mi mathsize="80%">j</mml:mi></mml:msub></mml:mrow><mml:mo maxsize="80%" minsize="80%">)</mml:mo></mml:mrow></mml:mrow></mml:msqrt></mml:math></inline-formula>, where <inline-formula><mml:math id="inf123"><mml:msub><mml:mover accent="true"><mml:mi mathsize="80%">μ</mml:mi><mml:mo mathsize="80%" stretchy="false">^</mml:mo></mml:mover><mml:mi mathsize="80%">j</mml:mi></mml:msub></mml:math></inline-formula> is an estimate of the average allele frequency (see above). We can then express the model in terms of the transformed sample covariance matrix:<disp-formula id="equ11"><label>(6)</label><mml:math id="m11"><mml:mrow><mml:mrow><mml:mrow><mml:mrow><mml:mi mathsize="80%">p</mml:mi><mml:mo mathsize="80%" stretchy="false">⋅</mml:mo><mml:mi mathsize="80%">𝑪</mml:mi></mml:mrow><mml:mo>⁢</mml:mo><mml:mover accent="true"><mml:mi mathsize="80%">𝚺</mml:mi><mml:mo mathsize="80%" stretchy="false">^</mml:mo></mml:mover><mml:mo>⁢</mml:mo><mml:msup><mml:mi mathsize="80%">𝑪</mml:mi><mml:mo mathsize="80%" stretchy="false">⊤</mml:mo></mml:msup></mml:mrow><mml:mo mathsize="80%" stretchy="false">∼</mml:mo><mml:mrow><mml:msub><mml:mi class="ltx_font_mathcaligraphic" mathsize="80%">𝒲</mml:mi><mml:mrow><mml:mi mathsize="80%">o</mml:mi><mml:mo mathsize="80%" stretchy="false">-</mml:mo><mml:mn mathsize="80%">1</mml:mn></mml:mrow></mml:msub><mml:mo>⁢</mml:mo><mml:mrow><mml:mo maxsize="260%" minsize="260%">(</mml:mo><mml:mrow><mml:mrow><mml:mi mathsize="80%">𝑪</mml:mi><mml:mo>⁢</mml:mo><mml:mi mathsize="80%">𝑨</mml:mi><mml:mo>⁢</mml:mo><mml:msup><mml:mi mathsize="80%">𝑳</mml:mi><mml:mo mathsize="80%" stretchy="false">†</mml:mo></mml:msup><mml:mo>⁢</mml:mo><mml:msup><mml:mi mathsize="80%">𝑨</mml:mi><mml:mo mathsize="80%" stretchy="false">⊤</mml:mo></mml:msup><mml:mo>⁢</mml:mo><mml:msup><mml:mi mathsize="80%">𝑪</mml:mi><mml:mo mathsize="80%" stretchy="false">⊤</mml:mo></mml:msup></mml:mrow><mml:mo mathsize="80%" stretchy="false">+</mml:mo><mml:mrow><mml:msup><mml:mi mathsize="80%">σ</mml:mi><mml:mn mathsize="80%">2</mml:mn></mml:msup><mml:mo>⁢</mml:mo><mml:mi mathsize="80%">𝑪</mml:mi><mml:mo>⁢</mml:mo><mml:mtext mathsize="80%">diag</mml:mtext><mml:mo>⁢</mml:mo><mml:mrow><mml:mo maxsize="120%" minsize="120%">(</mml:mo><mml:msup><mml:mi mathsize="80%">𝒏</mml:mi><mml:mrow><mml:mo mathsize="80%" stretchy="false">-</mml:mo><mml:mn mathsize="80%">1</mml:mn></mml:mrow></mml:msup><mml:mo maxsize="120%" minsize="120%">)</mml:mo></mml:mrow><mml:mo>⁢</mml:mo><mml:msup><mml:mi mathsize="80%">𝑪</mml:mi><mml:mo mathsize="80%" stretchy="false">⊤</mml:mo></mml:msup></mml:mrow></mml:mrow><mml:mo mathsize="80%" stretchy="false">,</mml:mo><mml:mi mathsize="80%">p</mml:mi><mml:mo maxsize="260%" minsize="260%">)</mml:mo></mml:mrow></mml:mrow></mml:mrow><mml:mo mathsize="80%" stretchy="false">,</mml:mo></mml:mrow></mml:math></disp-formula>where <inline-formula><mml:math id="inf124"><mml:msub><mml:mi class="ltx_font_mathcaligraphic" mathsize="80%">𝒲</mml:mi><mml:mi mathsize="80%">p</mml:mi></mml:msub></mml:math></inline-formula> denotes a Wishart distribution with <inline-formula><mml:math id="inf125"><mml:mi mathsize="80%">p</mml:mi></mml:math></inline-formula> degrees of freedom. Note we can equivalently use the sample squared Euclidean distance (often refereed to as a genetic distance) as a summary statistic: letting <inline-formula><mml:math id="inf126"><mml:mover accent="true"><mml:mi mathsize="80%" mathvariant="bold-italic">𝑫</mml:mi><mml:mo mathsize="80%" stretchy="false">^</mml:mo></mml:mover></mml:math></inline-formula> be the genetic distance matrix with <inline-formula><mml:math id="inf127"><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi mathsize="80%" mathvariant="bold-italic">𝑫</mml:mi><mml:mo mathsize="80%" stretchy="false">^</mml:mo></mml:mover><mml:mrow><mml:mi mathsize="80%">k</mml:mi><mml:mo>⁢</mml:mo><mml:mi mathsize="80%" mathvariant="normal">ℓ</mml:mi></mml:mrow></mml:msub><mml:mo mathsize="80%" stretchy="false">=</mml:mo><mml:mrow><mml:msubsup><mml:mo largeop="true" mathsize="80%" stretchy="false" symmetric="true">∑</mml:mo><mml:mrow><mml:mi mathsize="80%">j</mml:mi><mml:mo mathsize="80%" stretchy="false">=</mml:mo><mml:mn mathsize="80%">1</mml:mn></mml:mrow><mml:mi mathsize="80%">p</mml:mi></mml:msubsup><mml:mrow><mml:mrow><mml:mrow><mml:msup><mml:mrow><mml:mo maxsize="80%" minsize="80%">(</mml:mo><mml:mrow><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi mathsize="80%">f</mml:mi><mml:mo mathsize="80%" stretchy="false">^</mml:mo></mml:mover><mml:mi mathsize="80%">j</mml:mi></mml:msub><mml:mo>⁢</mml:mo><mml:mrow><mml:mo maxsize="80%" minsize="80%">(</mml:mo><mml:mi mathsize="80%">k</mml:mi><mml:mo maxsize="80%" minsize="80%">)</mml:mo></mml:mrow></mml:mrow><mml:mo mathsize="80%" stretchy="false">-</mml:mo><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi mathsize="80%">f</mml:mi><mml:mo mathsize="80%" stretchy="false">^</mml:mo></mml:mover><mml:mi mathsize="80%">j</mml:mi></mml:msub><mml:mo>⁢</mml:mo><mml:mrow><mml:mo maxsize="80%" minsize="80%">(</mml:mo><mml:mi mathsize="80%" mathvariant="normal">ℓ</mml:mi><mml:mo maxsize="80%" minsize="80%">)</mml:mo></mml:mrow></mml:mrow></mml:mrow><mml:mo maxsize="80%" minsize="80%">)</mml:mo></mml:mrow><mml:mn mathsize="80%">2</mml:mn></mml:msup><mml:mo mathsize="80%" stretchy="false">/</mml:mo><mml:mi mathsize="80%">p</mml:mi></mml:mrow><mml:mo mathsize="80%" stretchy="false">⋅</mml:mo><mml:msub><mml:mover accent="true"><mml:mi mathsize="80%">μ</mml:mi><mml:mo mathsize="80%" stretchy="false">^</mml:mo></mml:mover><mml:mi mathsize="80%">j</mml:mi></mml:msub></mml:mrow><mml:mo>⁢</mml:mo><mml:mrow><mml:mo maxsize="80%" minsize="80%">(</mml:mo><mml:mrow><mml:mn mathsize="80%">1</mml:mn><mml:mo mathsize="80%" stretchy="false">-</mml:mo><mml:msub><mml:mover accent="true"><mml:mi mathsize="80%">μ</mml:mi><mml:mo mathsize="80%" stretchy="false">^</mml:mo></mml:mover><mml:mi mathsize="80%">j</mml:mi></mml:msub></mml:mrow><mml:mo maxsize="80%" minsize="80%">)</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:mrow></mml:math></inline-formula>, we have<disp-formula id="equ12"><mml:math id="m12"><mml:mrow><mml:mrow><mml:mover accent="true"><mml:mi mathsize="80%">𝑫</mml:mi><mml:mo mathsize="80%" stretchy="false">^</mml:mo></mml:mover><mml:mo mathsize="80%" stretchy="false">=</mml:mo><mml:mrow><mml:mrow><mml:mrow><mml:mn mathsize="80%">𝟏</mml:mn><mml:mo>⁢</mml:mo><mml:mtext mathsize="80%">diag</mml:mtext><mml:mo>⁢</mml:mo><mml:msup><mml:mrow><mml:mo maxsize="80%" minsize="80%">(</mml:mo><mml:mover accent="true"><mml:mi mathsize="80%">𝚺</mml:mi><mml:mo mathsize="80%" stretchy="false">^</mml:mo></mml:mover><mml:mo maxsize="80%" minsize="80%">)</mml:mo></mml:mrow><mml:mo mathsize="80%" stretchy="false">⊤</mml:mo></mml:msup></mml:mrow><mml:mo mathsize="80%" stretchy="false">+</mml:mo><mml:mrow><mml:mtext mathsize="80%">diag</mml:mtext><mml:mo>⁢</mml:mo><mml:mrow><mml:mo maxsize="80%" minsize="80%">(</mml:mo><mml:mover accent="true"><mml:mi mathsize="80%">𝚺</mml:mi><mml:mo mathsize="80%" stretchy="false">^</mml:mo></mml:mover><mml:mo maxsize="80%" minsize="80%">)</mml:mo></mml:mrow><mml:mo>⁢</mml:mo><mml:msup><mml:mn mathsize="80%">𝟏</mml:mn><mml:mo mathsize="80%" stretchy="false">⊤</mml:mo></mml:msup></mml:mrow></mml:mrow><mml:mo mathsize="80%" stretchy="false">-</mml:mo><mml:mrow><mml:mn mathsize="80%">2</mml:mn><mml:mo>⁢</mml:mo><mml:mover accent="true"><mml:mi mathsize="80%">𝚺</mml:mi><mml:mo mathsize="80%" stretchy="false">^</mml:mo></mml:mover></mml:mrow></mml:mrow></mml:mrow><mml:mo mathsize="80%" stretchy="false">,</mml:mo></mml:mrow></mml:math></disp-formula>and so<disp-formula id="equ13"><mml:math id="m13"><mml:mrow><mml:mrow><mml:mrow><mml:mi mathsize="80%">𝑪</mml:mi><mml:mo>⁢</mml:mo><mml:mover accent="true"><mml:mi mathsize="80%">𝑫</mml:mi><mml:mo mathsize="80%" stretchy="false">^</mml:mo></mml:mover><mml:mo>⁢</mml:mo><mml:msup><mml:mi mathsize="80%">𝑪</mml:mi><mml:mo mathsize="80%" stretchy="false">⊤</mml:mo></mml:msup></mml:mrow><mml:mo mathsize="80%" stretchy="false">=</mml:mo><mml:mrow><mml:mo mathsize="80%" stretchy="false">-</mml:mo><mml:mrow><mml:mn mathsize="80%">2</mml:mn><mml:mo>⁢</mml:mo><mml:mi mathsize="80%">𝑪</mml:mi><mml:mo>⁢</mml:mo><mml:mover accent="true"><mml:mi mathsize="80%">𝚺</mml:mi><mml:mo mathsize="80%" stretchy="false">^</mml:mo></mml:mover><mml:mo>⁢</mml:mo><mml:msup><mml:mi mathsize="80%">𝑪</mml:mi><mml:mo mathsize="80%" stretchy="false">⊤</mml:mo></mml:msup></mml:mrow></mml:mrow></mml:mrow><mml:mo mathsize="80%" stretchy="false">,</mml:mo></mml:mrow></mml:math></disp-formula>using the fact that the contrast matrix <inline-formula><mml:math id="inf128"><mml:mi mathsize="80%" mathvariant="bold-italic">𝑪</mml:mi></mml:math></inline-formula> is orthogonal to the one-vector. Thus, we can use the same spatial covariance model implied by the allele frequencies once we project the distances on to the space of contrasts:<disp-formula id="equ14"><mml:math id="m14"><mml:mrow><mml:mrow><mml:mrow><mml:mo mathsize="80%" stretchy="false">-</mml:mo><mml:mrow><mml:mrow><mml:mfrac><mml:mi mathsize="80%">p</mml:mi><mml:mn mathsize="80%">2</mml:mn></mml:mfrac><mml:mo mathsize="80%" stretchy="false">⋅</mml:mo><mml:mi mathsize="80%">𝑪</mml:mi></mml:mrow><mml:mo>⁢</mml:mo><mml:mover accent="true"><mml:mi mathsize="80%">𝑫</mml:mi><mml:mo mathsize="80%" stretchy="false">^</mml:mo></mml:mover><mml:mo>⁢</mml:mo><mml:msup><mml:mi mathsize="80%">𝑪</mml:mi><mml:mo mathsize="80%" stretchy="false">⊤</mml:mo></mml:msup></mml:mrow></mml:mrow><mml:mo mathsize="80%" stretchy="false">∼</mml:mo><mml:mrow><mml:msub><mml:mi class="ltx_font_mathcaligraphic" mathsize="80%">𝒲</mml:mi><mml:mrow><mml:mi mathsize="80%">o</mml:mi><mml:mo mathsize="80%" stretchy="false">-</mml:mo><mml:mn mathsize="80%">1</mml:mn></mml:mrow></mml:msub><mml:mo>⁢</mml:mo><mml:mrow><mml:mo maxsize="260%" minsize="260%">(</mml:mo><mml:mrow><mml:mrow><mml:mi mathsize="80%">𝑪</mml:mi><mml:mo>⁢</mml:mo><mml:mi mathsize="80%">𝑨</mml:mi><mml:mo>⁢</mml:mo><mml:msup><mml:mi mathsize="80%">𝑳</mml:mi><mml:mo mathsize="80%" stretchy="false">†</mml:mo></mml:msup><mml:mo>⁢</mml:mo><mml:msup><mml:mi mathsize="80%">𝑨</mml:mi><mml:mo mathsize="80%" stretchy="false">⊤</mml:mo></mml:msup><mml:mo>⁢</mml:mo><mml:msup><mml:mi mathsize="80%">𝑪</mml:mi><mml:mo mathsize="80%" stretchy="false">⊤</mml:mo></mml:msup></mml:mrow><mml:mo mathsize="80%" stretchy="false">+</mml:mo><mml:mrow><mml:msup><mml:mi mathsize="80%">σ</mml:mi><mml:mn mathsize="80%">2</mml:mn></mml:msup><mml:mo>⁢</mml:mo><mml:mi mathsize="80%">𝑪</mml:mi><mml:mo>⁢</mml:mo><mml:mtext mathsize="80%">diag</mml:mtext><mml:mo>⁢</mml:mo><mml:mrow><mml:mo maxsize="120%" minsize="120%">(</mml:mo><mml:msup><mml:mi mathsize="80%">𝒏</mml:mi><mml:mrow><mml:mo mathsize="80%" stretchy="false">-</mml:mo><mml:mn mathsize="80%">1</mml:mn></mml:mrow></mml:msup><mml:mo maxsize="120%" minsize="120%">)</mml:mo></mml:mrow><mml:mo>⁢</mml:mo><mml:msup><mml:mi mathsize="80%">𝑪</mml:mi><mml:mo mathsize="80%" stretchy="false">⊤</mml:mo></mml:msup></mml:mrow></mml:mrow><mml:mo mathsize="80%" stretchy="false">,</mml:mo><mml:mi mathsize="80%">p</mml:mi><mml:mo maxsize="260%" minsize="260%">)</mml:mo></mml:mrow></mml:mrow></mml:mrow><mml:mo mathsize="80%" stretchy="false">.</mml:mo></mml:mrow></mml:math></disp-formula></p><p>Overall, the negative log-likelihood function implied by our spatial model is the following (ignoring constant terms):<disp-formula id="equ15"><label>(7)</label><mml:math id="m15"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mtable columnalign="left left" columnspacing="1em" rowspacing="4pt"><mml:mtr><mml:mtd><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>ℓ</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi mathvariant="bold-italic">w</mml:mi><mml:mo>,</mml:mo><mml:msup><mml:mi>σ</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup><mml:mo>;</mml:mo><mml:mi mathvariant="bold-italic">C</mml:mi><mml:mrow><mml:mover><mml:mi mathvariant="bold">Σ</mml:mi><mml:mo>^</mml:mo></mml:mover></mml:mrow><mml:msup><mml:mi mathvariant="bold-italic">C</mml:mi><mml:mrow><mml:mi mathvariant="normal">⊤</mml:mi></mml:mrow></mml:msup><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mi>p</mml:mi><mml:mo>⋅</mml:mo><mml:mtext>tr</mml:mtext><mml:mrow><mml:mo maxsize="2.470em" minsize="2.470em">(</mml:mo></mml:mrow><mml:mrow><mml:mo maxsize="1.623em" minsize="1.623em">(</mml:mo></mml:mrow><mml:mi mathvariant="bold-italic">C</mml:mi><mml:mi mathvariant="bold-italic">A</mml:mi><mml:msup><mml:mi mathvariant="bold-italic">L</mml:mi><mml:mrow><mml:mo>†</mml:mo></mml:mrow></mml:msup><mml:msup><mml:mi mathvariant="bold-italic">A</mml:mi><mml:mrow><mml:mi mathvariant="normal">⊤</mml:mi></mml:mrow></mml:msup><mml:msup><mml:mi mathvariant="bold-italic">C</mml:mi><mml:mrow><mml:mi mathvariant="normal">⊤</mml:mi></mml:mrow></mml:msup><mml:mo>+</mml:mo><mml:msup><mml:mi>σ</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup><mml:mi mathvariant="bold-italic">C</mml:mi><mml:mtext>diag</mml:mtext><mml:mo stretchy="false">(</mml:mo><mml:msup><mml:mi mathvariant="bold-italic">n</mml:mi><mml:mrow><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msup><mml:mo stretchy="false">)</mml:mo><mml:msup><mml:mi mathvariant="bold-italic">C</mml:mi><mml:mrow><mml:mi mathvariant="normal">⊤</mml:mi></mml:mrow></mml:msup><mml:msup><mml:mrow><mml:mo maxsize="1.623em" minsize="1.623em">)</mml:mo></mml:mrow><mml:mrow><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msup><mml:mi mathvariant="bold-italic">C</mml:mi><mml:mrow><mml:mover><mml:mi mathvariant="bold">Σ</mml:mi><mml:mo>^</mml:mo></mml:mover></mml:mrow><mml:msup><mml:mi mathvariant="bold-italic">C</mml:mi><mml:mrow><mml:mi mathvariant="normal">⊤</mml:mi></mml:mrow></mml:msup><mml:mrow><mml:mo maxsize="2.470em" minsize="2.470em">)</mml:mo></mml:mrow></mml:mstyle></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mspace width="2em"/><mml:mspace width="2em"/><mml:mspace width="2em"/><mml:mspace width="2em"/><mml:mspace width="2em"/><mml:mspace width="2em"/><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mo>−</mml:mo><mml:mi>p</mml:mi><mml:mo>⋅</mml:mo><mml:mi>log</mml:mi><mml:mo>⁡</mml:mo><mml:mo form="prefix" movablelimits="true">det</mml:mo><mml:mrow><mml:mo maxsize="2.470em" minsize="2.470em">(</mml:mo></mml:mrow><mml:mi mathvariant="bold-italic">C</mml:mi><mml:mi mathvariant="bold-italic">A</mml:mi><mml:msup><mml:mi mathvariant="bold-italic">L</mml:mi><mml:mrow><mml:mo>†</mml:mo></mml:mrow></mml:msup><mml:msup><mml:mi mathvariant="bold-italic">A</mml:mi><mml:mrow><mml:mi mathvariant="normal">⊤</mml:mi></mml:mrow></mml:msup><mml:msup><mml:mi mathvariant="bold-italic">C</mml:mi><mml:mrow><mml:mi mathvariant="normal">⊤</mml:mi></mml:mrow></mml:msup><mml:mo>+</mml:mo><mml:msup><mml:mi>σ</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup><mml:mi mathvariant="bold-italic">C</mml:mi><mml:mtext>diag</mml:mtext><mml:mo stretchy="false">(</mml:mo><mml:msup><mml:mi mathvariant="bold-italic">n</mml:mi><mml:mrow><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msup><mml:mo stretchy="false">)</mml:mo><mml:msup><mml:mi mathvariant="bold-italic">C</mml:mi><mml:mrow><mml:mi mathvariant="normal">⊤</mml:mi></mml:mrow></mml:msup><mml:msup><mml:mrow><mml:mo maxsize="2.470em" minsize="2.470em">)</mml:mo></mml:mrow><mml:mrow><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msup><mml:mo>,</mml:mo></mml:mstyle></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:mstyle></mml:math></disp-formula>where <inline-formula><mml:math id="inf129"><mml:mrow><mml:mi mathsize="80%" mathvariant="bold-italic">𝒘</mml:mi><mml:mo mathsize="80%" stretchy="false">∈</mml:mo><mml:msup><mml:mi mathsize="80%">ℝ</mml:mi><mml:mi mathsize="80%">m</mml:mi></mml:msup></mml:mrow></mml:math></inline-formula> is a vectorized form of the non-zero lower-triangular entries of the weighted adjacency matrix <inline-formula><mml:math id="inf130"><mml:mi mathsize="80%" mathvariant="bold-italic">𝑾</mml:mi></mml:math></inline-formula> (recall that the graph Laplacian is completely defined by the edge weights, <inline-formula><mml:math id="inf131"><mml:mrow><mml:mi mathsize="80%" mathvariant="bold-italic">𝑳</mml:mi><mml:mo mathsize="80%" stretchy="false">=</mml:mo><mml:mrow><mml:mrow><mml:mtext mathsize="80%">diag</mml:mtext><mml:mo>⁢</mml:mo><mml:mrow><mml:mo maxsize="80%" minsize="80%">(</mml:mo><mml:mrow><mml:mi mathsize="80%" mathvariant="bold-italic">𝑾</mml:mi><mml:mo>⁢</mml:mo><mml:mn mathsize="80%">𝟏</mml:mn></mml:mrow><mml:mo maxsize="80%" minsize="80%">)</mml:mo></mml:mrow></mml:mrow><mml:mo mathsize="80%" stretchy="false">-</mml:mo><mml:mi mathsize="80%" mathvariant="bold-italic">𝑾</mml:mi></mml:mrow></mml:mrow></mml:math></inline-formula>, so there is an implicit dependency here). Since the graph is a triangular lattice, we only need to consider the non-zero entries to save computational time, that is, not all sub-populations are connected to each other.</p><p>We note our model (<xref ref-type="disp-formula" rid="equ11">Equation 6</xref>) assumes that the <inline-formula><mml:math id="inf132"><mml:mi mathsize="80%">p</mml:mi></mml:math></inline-formula> SNPs are independent. This assumption is unlikely to hold when datasets are analyzed with SNPs that statistically covary (linkage disequilibrium). However, we note that the degree of freedom parameter does not affect the point estimate produced by FEEMS because it is treated as a constant term in the log-likelihood function.</p><p>One key difference between EEMS (<xref ref-type="bibr" rid="bib42">Petkova et al., 2016</xref>) and FEEMS is how the edge weights are parameterized. In EEMS, each node is given an effective migration parameter <inline-formula><mml:math id="inf133"><mml:msub><mml:mi mathsize="80%">m</mml:mi><mml:mi mathsize="80%">k</mml:mi></mml:msub></mml:math></inline-formula> for node <inline-formula><mml:math id="inf134"><mml:mrow><mml:mi mathsize="80%">k</mml:mi><mml:mo mathsize="80%" stretchy="false">∈</mml:mo><mml:mi class="ltx_font_mathcaligraphic" mathsize="80%">𝒱</mml:mi></mml:mrow></mml:math></inline-formula> and the edge weight is parameterized as the average between the nodes it connects, that is, <inline-formula><mml:math id="inf135"><mml:mrow><mml:msub><mml:mi mathsize="80%">w</mml:mi><mml:mrow><mml:mi mathsize="80%">k</mml:mi><mml:mo>⁢</mml:mo><mml:mi mathsize="80%" mathvariant="normal">ℓ</mml:mi></mml:mrow></mml:msub><mml:mo mathsize="80%" stretchy="false">=</mml:mo><mml:mrow><mml:mrow><mml:mo maxsize="80%" minsize="80%">(</mml:mo><mml:mrow><mml:msub><mml:mi mathsize="80%">m</mml:mi><mml:mi mathsize="80%">k</mml:mi></mml:msub><mml:mo mathsize="80%" stretchy="false">+</mml:mo><mml:msub><mml:mi mathsize="80%">m</mml:mi><mml:mi mathsize="80%" mathvariant="normal">ℓ</mml:mi></mml:msub></mml:mrow><mml:mo maxsize="80%" minsize="80%">)</mml:mo></mml:mrow><mml:mo mathsize="80%" stretchy="false">/</mml:mo><mml:mn mathsize="80%">2</mml:mn></mml:mrow></mml:mrow></mml:math></inline-formula> for <inline-formula><mml:math id="inf136"><mml:mrow><mml:mrow><mml:mo maxsize="80%" minsize="80%">(</mml:mo><mml:mi mathsize="80%">k</mml:mi><mml:mo mathsize="80%" stretchy="false">,</mml:mo><mml:mi mathsize="80%" mathvariant="normal">ℓ</mml:mi><mml:mo maxsize="80%" minsize="80%">)</mml:mo></mml:mrow><mml:mo mathsize="80%" stretchy="false">∈</mml:mo><mml:mi class="ltx_font_mathcaligraphic" mathsize="80%">ℰ</mml:mi></mml:mrow></mml:math></inline-formula>. FEEMS, on the other hand, assigns a parameter to every nonzero edge-weight. The former has fewer parameters, with the specific consequence that it only allows isotropy and imposes an additional degree of similarity among edge weights; instead, in the latter, the edge weights are free to vary apart from the regularization imposed by the penalty. See Appendix 1 ‘<italic>Edge versus node parameterization</italic>’ and <xref ref-type="fig" rid="app1fig15">Appendix 1—figures 15</xref>, <xref ref-type="fig" rid="app1fig17">17</xref> for more details.</p></sec><sec id="s4-2"><title>Penalty description</title><p>As mentioned previously, we would like to encourage that nearby edge weights on the graph have similar values to each other. This can be performed by penalizing differences between all edges connected to the same node, that is, spatially adjacent edges:<disp-formula id="equ16"><mml:math id="m16"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>ϕ</mml:mi><mml:mrow><mml:mi>λ</mml:mi><mml:mo>,</mml:mo><mml:mi>α</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi mathvariant="bold-italic">w</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mfrac><mml:mi>λ</mml:mi><mml:mn>2</mml:mn></mml:mfrac><mml:munder><mml:mo>∑</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>∈</mml:mo><mml:mrow><mml:mi mathvariant="script">𝒱</mml:mi></mml:mrow></mml:mrow></mml:munder><mml:munder><mml:mo>∑</mml:mo><mml:mrow><mml:mi>k</mml:mi><mml:mo>,</mml:mo><mml:mi>ℓ</mml:mi><mml:mo>∈</mml:mo><mml:mrow><mml:mi mathvariant="script">ℰ</mml:mi></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>i</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:munder><mml:msup><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>log</mml:mi><mml:mo>⁡</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:msup><mml:mi>e</mml:mi><mml:mrow><mml:mi>α</mml:mi><mml:msub><mml:mi>w</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>k</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:msup><mml:mo>−</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">)</mml:mo><mml:mo>−</mml:mo><mml:mi>log</mml:mi><mml:mo>⁡</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:msup><mml:mi>e</mml:mi><mml:mrow><mml:mi>α</mml:mi><mml:msub><mml:mi>w</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>ℓ</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:msup><mml:mo>−</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup><mml:mo>,</mml:mo></mml:mrow></mml:mstyle></mml:math></disp-formula>where, as before, <inline-formula><mml:math id="inf137"><mml:mrow><mml:mi class="ltx_font_mathcaligraphic" mathsize="80%">ℰ</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo maxsize="80%" minsize="80%">(</mml:mo><mml:mi mathsize="80%">i</mml:mi><mml:mo maxsize="80%" minsize="80%">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> denotes the set of edges that is connected to node <inline-formula><mml:math id="inf138"><mml:mi mathsize="80%">i</mml:mi></mml:math></inline-formula>. (As mentioned earlier, in practice we choose <inline-formula><mml:math id="inf139"><mml:mrow><mml:mi mathsize="80%">α</mml:mi><mml:mo mathsize="80%" stretchy="false">=</mml:mo><mml:mrow><mml:mn mathsize="80%">1</mml:mn><mml:mo mathsize="80%" stretchy="false">/</mml:mo><mml:msub><mml:mover accent="true"><mml:mi mathsize="80%">w</mml:mi><mml:mo mathsize="80%" stretchy="false">^</mml:mo></mml:mover><mml:mn mathsize="80%">0</mml:mn></mml:msub></mml:mrow></mml:mrow></mml:math></inline-formula>, where <inline-formula><mml:math id="inf140"><mml:msub><mml:mover accent="true"><mml:mi mathsize="80%">w</mml:mi><mml:mo mathsize="80%" stretchy="false">^</mml:mo></mml:mover><mml:mn mathsize="80%">0</mml:mn></mml:msub></mml:math></inline-formula> is the solution for the ‘constant-<inline-formula><mml:math id="inf141"><mml:mi mathsize="80%">w</mml:mi></mml:math></inline-formula>’ model, but we use the free parameter α here for full generality.) The function <inline-formula><mml:math id="inf142"><mml:mrow><mml:mi mathsize="80%">x</mml:mi><mml:mo mathsize="80%" stretchy="false">↦</mml:mo><mml:mrow><mml:mi mathsize="80%">log</mml:mi><mml:mo>⁡</mml:mo><mml:mrow><mml:mo maxsize="80%" minsize="80%">(</mml:mo><mml:mrow><mml:msup><mml:mi mathsize="80%">e</mml:mi><mml:mi mathsize="80%">x</mml:mi></mml:msup><mml:mo mathsize="80%" stretchy="false">-</mml:mo><mml:mn mathsize="80%">1</mml:mn></mml:mrow><mml:mo maxsize="80%" minsize="80%">)</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:math></inline-formula> (on positive values <inline-formula><mml:math id="inf143"><mml:mrow><mml:mi mathsize="80%">x</mml:mi><mml:mo mathsize="80%" stretchy="false">∈</mml:mo><mml:mrow><mml:mo maxsize="80%" minsize="80%">(</mml:mo><mml:mn mathsize="80%">0</mml:mn><mml:mo mathsize="80%" stretchy="false">,</mml:mo><mml:mi mathsize="80%" mathvariant="normal">∞</mml:mi><mml:mo maxsize="80%" minsize="80%">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula>) is approximately equal to <inline-formula><mml:math id="inf144"><mml:mi mathsize="80%">x</mml:mi></mml:math></inline-formula>, for <inline-formula><mml:math id="inf145"><mml:mi mathsize="80%">x</mml:mi></mml:math></inline-formula> much larger than 1, and is approximately equal to <inline-formula><mml:math id="inf146"><mml:mrow><mml:mi mathsize="80%">log</mml:mi><mml:mo>⁡</mml:mo><mml:mrow><mml:mo maxsize="80%" minsize="80%">(</mml:mo><mml:mi mathsize="80%">x</mml:mi><mml:mo maxsize="80%" minsize="80%">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula>, for <inline-formula><mml:math id="inf147"><mml:mi mathsize="80%">x</mml:mi></mml:math></inline-formula> much smaller than 1. This means that our penalty function effectively penalizes differences on the log scale for edges <inline-formula><mml:math id="inf148"><mml:mrow><mml:mo maxsize="80%" minsize="80%">(</mml:mo><mml:mi mathsize="80%">i</mml:mi><mml:mo mathsize="80%" stretchy="false">,</mml:mo><mml:mi mathsize="80%">k</mml:mi><mml:mo maxsize="80%" minsize="80%">)</mml:mo></mml:mrow></mml:math></inline-formula> and <inline-formula><mml:math id="inf149"><mml:mrow><mml:mo maxsize="80%" minsize="80%">(</mml:mo><mml:mi mathsize="80%">i</mml:mi><mml:mo mathsize="80%" stretchy="false">,</mml:mo><mml:mi mathsize="80%" mathvariant="normal">ℓ</mml:mi><mml:mo maxsize="80%" minsize="80%">)</mml:mo></mml:mrow></mml:math></inline-formula> with very small weights, but penalizes differences on the original non-log scale for edges with large weights. Using a logarithmic-scale penalty for edges with low weights (rather than simply penalizing <inline-formula><mml:math id="inf150"><mml:msup><mml:mrow><mml:mo maxsize="80%" minsize="80%">(</mml:mo><mml:mrow><mml:msub><mml:mi mathsize="80%">w</mml:mi><mml:mrow><mml:mi mathsize="80%">i</mml:mi><mml:mo>⁢</mml:mo><mml:mi mathsize="80%">k</mml:mi></mml:mrow></mml:msub><mml:mo mathsize="80%" stretchy="false">-</mml:mo><mml:msub><mml:mi mathsize="80%">w</mml:mi><mml:mrow><mml:mi mathsize="80%">i</mml:mi><mml:mo>⁢</mml:mo><mml:mi mathsize="80%" mathvariant="normal">ℓ</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo maxsize="80%" minsize="80%">)</mml:mo></mml:mrow><mml:mn mathsize="80%">2</mml:mn></mml:msup></mml:math></inline-formula>) leads to smooth graphs for small edge values, and thus allow for an additional degree of flexibility across orders of magnitude of edge weights. The penalty parameter, λ, controls the overall contribution of the penalty to the objective function. It is convenient to write the penalty in matrix-vector form which we will use throughout:<disp-formula id="equ17"><label>(8)</label><mml:math id="m17"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>ϕ</mml:mi><mml:mrow><mml:mi>λ</mml:mi><mml:mo>,</mml:mo><mml:mi>α</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi mathvariant="bold-italic">w</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mfrac><mml:mi>λ</mml:mi><mml:mn>2</mml:mn></mml:mfrac><mml:msubsup><mml:mrow><mml:mo symmetric="true">‖</mml:mo><mml:mrow><mml:mi mathvariant="bold">Δ</mml:mi><mml:mi>log</mml:mi><mml:mo>⁡</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:msup><mml:mi>e</mml:mi><mml:mrow><mml:mi>α</mml:mi><mml:mi mathvariant="bold-italic">w</mml:mi></mml:mrow></mml:msup><mml:mo>−</mml:mo><mml:mn mathvariant="bold">1</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo symmetric="true">‖</mml:mo></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup><mml:mo>,</mml:mo></mml:mrow></mml:mstyle></mml:math></disp-formula>where <inline-formula><mml:math id="inf151"><mml:mi mathsize="80%" mathvariant="bold">𝚫</mml:mi></mml:math></inline-formula> is a signed graph incidence matrix derived from a unweighted graph denoting if pairs of edges are connected to the same node. Specifically, in this expression, we treat <inline-formula><mml:math id="inf152"><mml:mi mathsize="80%" mathvariant="bold-italic">𝒘</mml:mi></mml:math></inline-formula> as a vector of length <inline-formula><mml:math id="inf153"><mml:mrow><mml:mo maxsize="80%" minsize="80%">|</mml:mo><mml:mi class="ltx_font_mathcaligraphic" mathsize="80%">ℰ</mml:mi><mml:mo maxsize="80%" minsize="80%">|</mml:mo></mml:mrow></mml:math></inline-formula> (i.e. the number of edges), and apply the function <inline-formula><mml:math id="inf154"><mml:mrow><mml:mi mathsize="80%">w</mml:mi><mml:mo mathsize="80%" stretchy="false">↦</mml:mo><mml:mrow><mml:mi mathsize="80%">log</mml:mi><mml:mo>⁡</mml:mo><mml:mrow><mml:mo maxsize="80%" minsize="80%">(</mml:mo><mml:mrow><mml:msup><mml:mi mathsize="80%">e</mml:mi><mml:mrow><mml:mi mathsize="80%">α</mml:mi><mml:mo>⁢</mml:mo><mml:mi mathsize="80%">w</mml:mi></mml:mrow></mml:msup><mml:mo mathsize="80%" stretchy="false">-</mml:mo><mml:mn mathsize="80%">1</mml:mn></mml:mrow><mml:mo maxsize="80%" minsize="80%">)</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:math></inline-formula> entrywise to this vector. For each pair adjacent edges <inline-formula><mml:math id="inf155"><mml:mrow><mml:mo maxsize="80%" minsize="80%">(</mml:mo><mml:mi mathsize="80%">i</mml:mi><mml:mo mathsize="80%" stretchy="false">,</mml:mo><mml:mi mathsize="80%">k</mml:mi><mml:mo maxsize="80%" minsize="80%">)</mml:mo></mml:mrow></mml:math></inline-formula> and <inline-formula><mml:math id="inf156"><mml:mrow><mml:mo maxsize="80%" minsize="80%">(</mml:mo><mml:mi mathsize="80%">i</mml:mi><mml:mo mathsize="80%" stretchy="false">,</mml:mo><mml:mi mathsize="80%" mathvariant="normal">ℓ</mml:mi><mml:mo maxsize="80%" minsize="80%">)</mml:mo></mml:mrow></mml:math></inline-formula> in the graph, there is a corresponding row of <inline-formula><mml:math id="inf157"><mml:mi mathsize="80%" mathvariant="bold">𝚫</mml:mi></mml:math></inline-formula> with the value +1 in the entry corresponding to edge <inline-formula><mml:math id="inf158"><mml:mrow><mml:mo maxsize="80%" minsize="80%">(</mml:mo><mml:mi mathsize="80%">i</mml:mi><mml:mo mathsize="80%" stretchy="false">,</mml:mo><mml:mi mathsize="80%">k</mml:mi><mml:mo maxsize="80%" minsize="80%">)</mml:mo></mml:mrow></mml:math></inline-formula>, a −1 in the entry corresponding to edge <inline-formula><mml:math id="inf159"><mml:mrow><mml:mo maxsize="80%" minsize="80%">(</mml:mo><mml:mi mathsize="80%">i</mml:mi><mml:mo mathsize="80%" stretchy="false">,</mml:mo><mml:mi mathsize="80%" mathvariant="normal">ℓ</mml:mi><mml:mo maxsize="80%" minsize="80%">)</mml:mo></mml:mrow></mml:math></inline-formula>, and 0’s elsewhere.</p><p>One might wonder whether it is possible to use the <inline-formula><mml:math id="inf160"><mml:msub><mml:mi mathsize="80%" mathvariant="normal">ℓ</mml:mi><mml:mn mathsize="80%">1</mml:mn></mml:msub></mml:math></inline-formula> norm in the penalty form <xref ref-type="disp-formula" rid="equ17">Equation (8)</xref> in place of the <inline-formula><mml:math id="inf161"><mml:msub><mml:mi mathsize="80%" mathvariant="normal">ℓ</mml:mi><mml:mn mathsize="80%">2</mml:mn></mml:msub></mml:math></inline-formula> norm. While it is known that the <inline-formula><mml:math id="inf162"><mml:msub><mml:mi mathsize="80%" mathvariant="normal">ℓ</mml:mi><mml:mn mathsize="80%">1</mml:mn></mml:msub></mml:math></inline-formula> norm might increase local adaptivity and better capture the sharp changes of the underlying structure of the latent allele frequencies (e.g. <xref ref-type="bibr" rid="bib55">Wang et al., 2016</xref>), in our case, we found an inferior performance when using the <inline-formula><mml:math id="inf163"><mml:msub><mml:mi mathsize="80%" mathvariant="normal">ℓ</mml:mi><mml:mn mathsize="80%">1</mml:mn></mml:msub></mml:math></inline-formula> norm over the <inline-formula><mml:math id="inf164"><mml:msub><mml:mi mathsize="80%" mathvariant="normal">ℓ</mml:mi><mml:mn mathsize="80%">2</mml:mn></mml:msub></mml:math></inline-formula> norm—in particular, our primary application of interest is the regime of highly missing nodes, that is, <inline-formula><mml:math id="inf165"><mml:mrow><mml:mi mathsize="80%">o</mml:mi><mml:mo mathsize="80%" stretchy="false">≪</mml:mo><mml:mi mathsize="80%">d</mml:mi></mml:mrow></mml:math></inline-formula>, in which case the global smoothing seems somewhat necessary to encourage stable recovery of the edge weights at regions with sparsely observed nodes (see Appendix 1 ‘<italic>Smooth penalty with</italic> <inline-formula><mml:math id="inf166"><mml:msub><mml:mi mathvariant="normal">ℓ</mml:mi><mml:mn mathvariant="normal">1</mml:mn></mml:msub></mml:math></inline-formula><italic>norm</italic>’). In addition, adding the penalty <inline-formula><mml:math id="inf167"><mml:mrow><mml:msub><mml:mi mathsize="80%">ϕ</mml:mi><mml:mrow><mml:mi mathsize="80%">λ</mml:mi><mml:mo mathsize="80%" stretchy="false">,</mml:mo><mml:mi mathsize="80%">α</mml:mi></mml:mrow></mml:msub><mml:mo>⁢</mml:mo><mml:mrow><mml:mo maxsize="80%" minsize="80%">(</mml:mo><mml:mi mathsize="80%" mathvariant="bold-italic">𝒘</mml:mi><mml:mo maxsize="80%" minsize="80%">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> allows us to implement faster algorithms to solve the optimization problem due to the differentiability of the <inline-formula><mml:math id="inf168"><mml:msub><mml:mi mathsize="80%" mathvariant="normal">ℓ</mml:mi><mml:mn mathsize="80%">2</mml:mn></mml:msub></mml:math></inline-formula> norm, and as a result, it leads to better overall computational savings and a simpler implementation.</p></sec><sec id="s4-3"><title>Optimization</title><p>Putting <xref ref-type="disp-formula" rid="equ15">Equation (7)</xref> and <xref ref-type="disp-formula" rid="equ17">Equation (8)</xref> together, we infer the migration edge weights <inline-formula><mml:math id="inf169"><mml:mover accent="true"><mml:mi mathsize="80%" mathvariant="bold-italic">𝒘</mml:mi><mml:mo mathsize="80%" stretchy="false">^</mml:mo></mml:mover></mml:math></inline-formula> by minimizing the following penalized negative log-likelihood function:<disp-formula id="equ18"><label>(9)</label><mml:math id="m18"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mtable columnalign="left left" columnspacing="1em" rowspacing="4pt"><mml:mtr><mml:mtd><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mover><mml:mi mathvariant="bold-italic">w</mml:mi><mml:mo>^</mml:mo></mml:mover></mml:mrow></mml:mstyle></mml:mtd><mml:mtd><mml:mo>=</mml:mo><mml:munder><mml:mrow><mml:mi mathvariant="normal">a</mml:mi><mml:mi mathvariant="normal">r</mml:mi><mml:mi mathvariant="normal">g</mml:mi><mml:mi mathvariant="normal">m</mml:mi><mml:mi mathvariant="normal">i</mml:mi><mml:mi mathvariant="normal">n</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="bold-italic">l</mml:mi><mml:mo>≤</mml:mo><mml:mi mathvariant="bold-italic">w</mml:mi><mml:mo>≤</mml:mo><mml:mi mathvariant="bold-italic">u</mml:mi></mml:mrow></mml:munder><mml:mtext> </mml:mtext><mml:mi>ℓ</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi mathvariant="bold-italic">w</mml:mi><mml:mo>,</mml:mo><mml:msup><mml:mi>σ</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup><mml:mo>;</mml:mo><mml:mi mathvariant="bold-italic">C</mml:mi><mml:mrow><mml:mover><mml:mi mathvariant="bold">Σ</mml:mi><mml:mo>^</mml:mo></mml:mover></mml:mrow><mml:msup><mml:mi mathvariant="bold-italic">C</mml:mi><mml:mrow><mml:mi mathvariant="normal">⊤</mml:mi></mml:mrow></mml:msup><mml:mo stretchy="false">)</mml:mo><mml:mo>+</mml:mo><mml:msub><mml:mi>ϕ</mml:mi><mml:mrow><mml:mi>λ</mml:mi><mml:mo>,</mml:mo><mml:mi>α</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi mathvariant="bold-italic">w</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mtd></mml:mtr><mml:mtr><mml:mtd/><mml:mtd><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mo>=</mml:mo><mml:munder><mml:mrow><mml:mi mathvariant="normal">a</mml:mi><mml:mi mathvariant="normal">r</mml:mi><mml:mi mathvariant="normal">g</mml:mi><mml:mi mathvariant="normal">m</mml:mi><mml:mi mathvariant="normal">i</mml:mi><mml:mi mathvariant="normal">n</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="bold-italic">l</mml:mi><mml:mo>≤</mml:mo><mml:mi mathvariant="bold-italic">w</mml:mi><mml:mo>≤</mml:mo><mml:mi mathvariant="bold-italic">u</mml:mi></mml:mrow></mml:munder><mml:mtext> </mml:mtext><mml:mrow><mml:mo>[</mml:mo><mml:mrow><mml:mi>p</mml:mi><mml:mo>⋅</mml:mo><mml:mtext>tr</mml:mtext><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msup><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi mathvariant="bold-italic">C</mml:mi><mml:mi mathvariant="bold-italic">A</mml:mi><mml:msup><mml:mi mathvariant="bold-italic">L</mml:mi><mml:mrow><mml:mo>†</mml:mo></mml:mrow></mml:msup><mml:msup><mml:mi mathvariant="bold-italic">A</mml:mi><mml:mrow><mml:mi mathvariant="normal">⊤</mml:mi></mml:mrow></mml:msup><mml:msup><mml:mi mathvariant="bold-italic">C</mml:mi><mml:mrow><mml:mi mathvariant="normal">⊤</mml:mi></mml:mrow></mml:msup><mml:mo>+</mml:mo><mml:msup><mml:mi>σ</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup><mml:mi mathvariant="bold-italic">C</mml:mi><mml:mtext>diag</mml:mtext><mml:mo stretchy="false">(</mml:mo><mml:msup><mml:mi mathvariant="bold-italic">n</mml:mi><mml:mrow><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msup><mml:mo stretchy="false">)</mml:mo><mml:msup><mml:mi mathvariant="bold-italic">C</mml:mi><mml:mrow><mml:mi mathvariant="normal">⊤</mml:mi></mml:mrow></mml:msup></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mrow><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msup><mml:mi mathvariant="bold-italic">C</mml:mi><mml:mrow><mml:mover><mml:mi mathvariant="bold">Σ</mml:mi><mml:mo>^</mml:mo></mml:mover></mml:mrow><mml:msup><mml:mi mathvariant="bold-italic">C</mml:mi><mml:mrow><mml:mi mathvariant="normal">⊤</mml:mi></mml:mrow></mml:msup></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo fence="true" stretchy="true" symmetric="true"/></mml:mrow></mml:mstyle></mml:mtd></mml:mtr><mml:mtr><mml:mtd/><mml:mtd><mml:mspace width="2em"/><mml:mspace width="2em"/><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mo fence="true" stretchy="true" symmetric="true"/><mml:mrow><mml:mo>−</mml:mo><mml:mi>p</mml:mi><mml:mo>⋅</mml:mo><mml:mi>log</mml:mi><mml:mo>⁡</mml:mo><mml:mo form="prefix" movablelimits="true">det</mml:mo><mml:msup><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi mathvariant="bold-italic">C</mml:mi><mml:mi mathvariant="bold-italic">A</mml:mi><mml:msup><mml:mi mathvariant="bold-italic">L</mml:mi><mml:mrow><mml:mo>†</mml:mo></mml:mrow></mml:msup><mml:msup><mml:mi mathvariant="bold-italic">A</mml:mi><mml:mrow><mml:mi mathvariant="normal">⊤</mml:mi></mml:mrow></mml:msup><mml:msup><mml:mi mathvariant="bold-italic">C</mml:mi><mml:mrow><mml:mi mathvariant="normal">⊤</mml:mi></mml:mrow></mml:msup><mml:mo>+</mml:mo><mml:msup><mml:mi>σ</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup><mml:mi mathvariant="bold-italic">C</mml:mi><mml:mtext>diag</mml:mtext><mml:mo stretchy="false">(</mml:mo><mml:msup><mml:mi mathvariant="bold-italic">n</mml:mi><mml:mrow><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msup><mml:mo stretchy="false">)</mml:mo><mml:msup><mml:mi mathvariant="bold-italic">C</mml:mi><mml:mrow><mml:mi mathvariant="normal">⊤</mml:mi></mml:mrow></mml:msup></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mrow><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msup><mml:mo>+</mml:mo><mml:mfrac><mml:mi>λ</mml:mi><mml:mn>2</mml:mn></mml:mfrac><mml:msubsup><mml:mrow><mml:mo symmetric="true">‖</mml:mo><mml:mrow><mml:mi mathvariant="bold">Δ</mml:mi><mml:mi>log</mml:mi><mml:mo>⁡</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:msup><mml:mi>e</mml:mi><mml:mrow><mml:mi>α</mml:mi><mml:mi mathvariant="bold-italic">w</mml:mi></mml:mrow></mml:msup><mml:mo>−</mml:mo><mml:mn mathvariant="bold">1</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo symmetric="true">‖</mml:mo></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup></mml:mrow><mml:mo>]</mml:mo></mml:mrow><mml:mo>,</mml:mo></mml:mstyle></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:mstyle></mml:math></disp-formula>where <inline-formula><mml:math id="inf170"><mml:mrow><mml:mrow><mml:mi mathsize="80%" mathvariant="bold-italic">𝒍</mml:mi><mml:mo mathsize="80%" stretchy="false">,</mml:mo><mml:mi mathsize="80%" mathvariant="bold-italic">𝒖</mml:mi></mml:mrow><mml:mo mathsize="80%" stretchy="false">∈</mml:mo><mml:msubsup><mml:mi mathsize="80%">ℝ</mml:mi><mml:mo mathsize="80%" stretchy="false">+</mml:mo><mml:mi mathsize="80%">m</mml:mi></mml:msubsup></mml:mrow></mml:math></inline-formula> represent respectively the entrywise lower- and upper bounds on <inline-formula><mml:math id="inf171"><mml:mi mathsize="80%" mathvariant="bold-italic">𝒘</mml:mi></mml:math></inline-formula>, that is, we constrain the lower- and upper bound of the edge weights to <inline-formula><mml:math id="inf172"><mml:mi mathsize="80%" mathvariant="bold-italic">𝒍</mml:mi></mml:math></inline-formula> and <inline-formula><mml:math id="inf173"><mml:mi mathsize="80%" mathvariant="bold-italic">𝒖</mml:mi></mml:math></inline-formula> throughout the optimization. When no prior information is available on the range of the edge weights, we often set <inline-formula><mml:math id="inf174"><mml:mrow><mml:mi mathsize="80%" mathvariant="bold-italic">𝒍</mml:mi><mml:mo mathsize="80%" stretchy="false">=</mml:mo><mml:mn mathsize="80%"/></mml:mrow></mml:math></inline-formula> and <inline-formula><mml:math id="inf175"><mml:mrow><mml:mi mathsize="80%" mathvariant="bold-italic">𝒖</mml:mi><mml:mo mathsize="80%" stretchy="false">=</mml:mo><mml:mrow><mml:mo mathsize="80%" stretchy="false">+</mml:mo><mml:mi mathsize="80%" mathvariant="normal">∞</mml:mi></mml:mrow></mml:mrow></mml:math></inline-formula>.</p><p>One advantage of the formulation of <xref ref-type="disp-formula" rid="equ18">Equation 9</xref> is the use of the vector form parameterization <inline-formula><mml:math id="inf176"><mml:mrow><mml:mi mathsize="80%" mathvariant="bold-italic">𝒘</mml:mi><mml:mo mathsize="80%" stretchy="false">∈</mml:mo><mml:msubsup><mml:mi mathsize="80%">ℝ</mml:mi><mml:mo mathsize="80%" stretchy="false">+</mml:mo><mml:mi mathsize="80%">m</mml:mi></mml:msubsup></mml:mrow></mml:math></inline-formula> of the symmetric weighted adjacency matrix <inline-formula><mml:math id="inf177"><mml:mrow><mml:mi mathsize="80%" mathvariant="bold-italic">𝑾</mml:mi><mml:mo mathsize="80%" stretchy="false">∈</mml:mo><mml:msubsup><mml:mi mathsize="80%">ℝ</mml:mi><mml:mo mathsize="80%" stretchy="false">+</mml:mo><mml:mrow><mml:mi mathsize="80%">d</mml:mi><mml:mo mathsize="80%" stretchy="false">×</mml:mo><mml:mi mathsize="80%">d</mml:mi></mml:mrow></mml:msubsup></mml:mrow></mml:math></inline-formula>. In our triangular graph <inline-formula><mml:math id="inf178"><mml:mrow><mml:mi class="ltx_font_mathcaligraphic" mathsize="80%">𝒢</mml:mi><mml:mo mathsize="80%" stretchy="false">=</mml:mo><mml:mrow><mml:mo maxsize="80%" minsize="80%">(</mml:mo><mml:mi class="ltx_font_mathcaligraphic" mathsize="80%">𝒱</mml:mi><mml:mo mathsize="80%" stretchy="false">,</mml:mo><mml:mi class="ltx_font_mathcaligraphic" mathsize="80%">ℰ</mml:mi><mml:mo maxsize="80%" minsize="80%">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula>, the number of non-zero lower-triangular entries is <inline-formula><mml:math id="inf179"><mml:mrow><mml:mi mathsize="80%">m</mml:mi><mml:mo mathsize="80%" stretchy="false">=</mml:mo><mml:mrow><mml:mi class="ltx_font_mathcaligraphic" mathsize="80%">𝒪</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo maxsize="80%" minsize="80%">(</mml:mo><mml:mi mathsize="80%">d</mml:mi><mml:mo maxsize="80%" minsize="80%">)</mml:mo></mml:mrow></mml:mrow><mml:mo mathsize="80%" stretchy="false">≪</mml:mo><mml:msup><mml:mi mathsize="80%">d</mml:mi><mml:mn mathsize="80%">2</mml:mn></mml:msup></mml:mrow></mml:math></inline-formula>, so working directly on the space of vector parameterization saves computational cost. In addition, this avoids the symmetry constraint imposed on the adjacency matrix <inline-formula><mml:math id="inf180"><mml:mi mathsize="80%" mathvariant="bold-italic">𝑾</mml:mi></mml:math></inline-formula>, hence making optimization easier (<xref ref-type="bibr" rid="bib20">Kalofolias, 2016</xref>).</p><p>We solve the optimization problem using a constrained quasi-Newton optimization algorithm, specifically L-BFGS implemented in <monospace>scipy</monospace> (<xref ref-type="bibr" rid="bib9">Byrd et al., 1995</xref>; <xref ref-type="bibr" rid="bib53">Virtanen et al., 2020</xref>) (<monospace>RRID:<ext-link ext-link-type="uri" xlink:href="https://scicrunch.org/resolver/SCR_008058">SCR_008058</ext-link></monospace>). Since our objective <xref ref-type="disp-formula" rid="equ18">Equation 9</xref> is non-convex, the L-BFGS algorithm is guaranteed to converge only to a local minimum. Even so, we empirically observe that local minima starting from different initial points are qualitatively similar to each other across many datasets. The L-BFGS algorithm requires gradient and objective values as inputs. Note the naive computation of the objective <xref ref-type="disp-formula" rid="equ18">Equation 9</xref> is computationally prohibitive because inverting the graph Laplacian has complexity <inline-formula><mml:math id="inf181"><mml:mrow><mml:mi class="ltx_font_mathcaligraphic" mathsize="80%">𝒪</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo maxsize="80%" minsize="80%">(</mml:mo><mml:msup><mml:mi mathsize="80%">d</mml:mi><mml:mn mathsize="80%">3</mml:mn></mml:msup><mml:mo maxsize="80%" minsize="80%">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula>. We take advantage of the sparsity of the graph and specific structure of the problem to efficiently compute gradient and objective values. In theory, our implementation has computational complexity of <inline-formula><mml:math id="inf182"><mml:mrow><mml:mi class="ltx_font_mathcaligraphic" mathsize="80%">𝒪</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo maxsize="80%" minsize="80%">(</mml:mo><mml:mrow><mml:mrow><mml:mi mathsize="80%">d</mml:mi><mml:mo>⁢</mml:mo><mml:mi mathsize="80%">o</mml:mi></mml:mrow><mml:mo mathsize="80%" stretchy="false">+</mml:mo><mml:msup><mml:mi mathsize="80%">o</mml:mi><mml:mn mathsize="80%">3</mml:mn></mml:msup></mml:mrow><mml:mo maxsize="80%" minsize="80%">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> per iteration which, in the setting of <inline-formula><mml:math id="inf183"><mml:mrow><mml:mi mathsize="80%">o</mml:mi><mml:mo mathsize="80%" stretchy="false">≪</mml:mo><mml:mi mathsize="80%">d</mml:mi></mml:mrow></mml:math></inline-formula>, is substantially smaller than <inline-formula><mml:math id="inf184"><mml:mrow><mml:mi class="ltx_font_mathcaligraphic" mathsize="80%">𝒪</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo maxsize="80%" minsize="80%">(</mml:mo><mml:msup><mml:mi mathsize="80%">d</mml:mi><mml:mn mathsize="80%">3</mml:mn></mml:msup><mml:mo maxsize="80%" minsize="80%">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula>. It is possible to achieve <inline-formula><mml:math id="inf185"><mml:mrow><mml:mi class="ltx_font_mathcaligraphic" mathsize="80%">𝒪</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo maxsize="80%" minsize="80%">(</mml:mo><mml:mrow><mml:mrow><mml:mi mathsize="80%">d</mml:mi><mml:mo>⁢</mml:mo><mml:mi mathsize="80%">o</mml:mi></mml:mrow><mml:mo mathsize="80%" stretchy="false">+</mml:mo><mml:msup><mml:mi mathsize="80%">o</mml:mi><mml:mn mathsize="80%">3</mml:mn></mml:msup></mml:mrow><mml:mo maxsize="80%" minsize="80%">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> per-iteration complexity by using a solver that is specially designed for a sparse Laplacian system. In our work, we use sparse Cholesky factorization which may slightly slow down the per-iteration complexity (See Appendix Material for the details of the gradient and objective computation).</p></sec><sec id="s4-4"><title>Estimating the residual variance and edge weights under the null model</title><p>For estimating the residual variance parameter <inline-formula><mml:math id="inf186"><mml:msup><mml:mi mathsize="80%">σ</mml:mi><mml:mn mathsize="80%">2</mml:mn></mml:msup></mml:math></inline-formula>, we first estimate it via maximum likelihood assuming homogeneous isolation by distance. This corresponds to the scenario where every edge-weight in the graph is given the exact same unknown parameter value <inline-formula><mml:math id="inf187"><mml:msub><mml:mi mathsize="80%">w</mml:mi><mml:mn mathsize="80%">0</mml:mn></mml:msub></mml:math></inline-formula>. Under this model, we only have two unknown parameters <inline-formula><mml:math id="inf188"><mml:msub><mml:mi mathsize="80%">w</mml:mi><mml:mn mathsize="80%">0</mml:mn></mml:msub></mml:math></inline-formula> and the residual variance <inline-formula><mml:math id="inf189"><mml:msup><mml:mi mathsize="80%">σ</mml:mi><mml:mn mathsize="80%">2</mml:mn></mml:msup></mml:math></inline-formula>. We estimate these two parameters by jointly optimizing the marginal likelihood using a Nelder-Mead algorithm implemented in <monospace>scipy</monospace> (<xref ref-type="bibr" rid="bib53">Virtanen et al., 2020</xref>) (<monospace>RRID:<ext-link ext-link-type="uri" xlink:href="https://scicrunch.org/resolver/SCR_008058">SCR_008058</ext-link></monospace>). This requires only likelihood computations which are efficient due to the sparse nature of the graph. This optimization routine outputs an estimate of the residual variance <inline-formula><mml:math id="inf190"><mml:msup><mml:mover accent="true"><mml:mi mathsize="80%">σ</mml:mi><mml:mo mathsize="80%" stretchy="false">^</mml:mo></mml:mover><mml:mn mathsize="80%">2</mml:mn></mml:msup></mml:math></inline-formula> and the null edge weight <inline-formula><mml:math id="inf191"><mml:msub><mml:mover accent="true"><mml:mi mathsize="80%">w</mml:mi><mml:mo mathsize="80%" stretchy="false">^</mml:mo></mml:mover><mml:mn mathsize="80%">0</mml:mn></mml:msub></mml:math></inline-formula>, which can be used to construct <inline-formula><mml:math id="inf192"><mml:mrow><mml:mi mathsize="80%" mathvariant="bold-italic">𝑾</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo maxsize="80%" minsize="80%">(</mml:mo><mml:msub><mml:mover accent="true"><mml:mi mathsize="80%">w</mml:mi><mml:mo mathsize="80%" stretchy="false">^</mml:mo></mml:mover><mml:mn mathsize="80%">0</mml:mn></mml:msub><mml:mo maxsize="80%" minsize="80%">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> and in turn <inline-formula><mml:math id="inf193"><mml:mrow><mml:mi mathsize="80%" mathvariant="bold-italic">𝑳</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo maxsize="80%" minsize="80%">(</mml:mo><mml:msub><mml:mover accent="true"><mml:mi mathsize="80%">w</mml:mi><mml:mo mathsize="80%" stretchy="false">^</mml:mo></mml:mover><mml:mn mathsize="80%">0</mml:mn></mml:msub><mml:mo maxsize="80%" minsize="80%">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula>.</p><p>One strategy we found effective is to fit the model of homogeneous isolation by distance and then fix the estimated residual variance <inline-formula><mml:math id="inf194"><mml:msup><mml:mover accent="true"><mml:mi mathsize="80%">σ</mml:mi><mml:mo mathsize="80%" stretchy="false">^</mml:mo></mml:mover><mml:mn mathsize="80%">2</mml:mn></mml:msup></mml:math></inline-formula> throughout later fits of the more flexible penalized models—See Appendix 1 ‘<italic>Jointly estimating the residual variance and edge weights</italic>’. Additionally, we find that initializing the edge weights to <inline-formula><mml:math id="inf195"><mml:msub><mml:mover accent="true"><mml:mi mathsize="80%">w</mml:mi><mml:mo mathsize="80%" stretchy="false">^</mml:mo></mml:mover><mml:mn mathsize="80%">0</mml:mn></mml:msub></mml:math></inline-formula> to be a useful and intuitive strategy to set the initial values for the entries of <inline-formula><mml:math id="inf196"><mml:mi mathsize="80%" mathvariant="bold-italic">𝒘</mml:mi></mml:math></inline-formula> to the correct scale.</p></sec><sec id="s4-5"><title>Leave-one-out cross-validation to select tuning parameters</title><p>FEEMS estimates one set of graph edge weights for each setting of the tuning parameters λ and α which control the smoothness of the fitted edge weights. <xref ref-type="fig" rid="fig3">Figure 3</xref> shows that the estimated migration surfaces vary substantially depending on the particular choices of the tuning parameters, and indeed, due to the large fraction of unobserved nodes, it can highly over-fit the observed data unless regularized accordingly. To address the issue of selecting the tuning parameters, we propose using leave-one-out cross-validation to assess each fitted model’s generalization ability at held out locations.</p><p>To simplify the notation, we write the model <xref ref-type="disp-formula" rid="equ9">Equation 4</xref> for the estimated allele frequencies in SNP <inline-formula><mml:math id="inf197"><mml:mi mathsize="80%">j</mml:mi></mml:math></inline-formula> as<disp-formula id="equ19"><mml:math id="m19"><mml:mrow><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi mathsize="80%">𝒇</mml:mi><mml:mo mathsize="80%" stretchy="false">^</mml:mo></mml:mover><mml:mi mathsize="80%">j</mml:mi></mml:msub><mml:mo mathsize="80%" stretchy="false">∼</mml:mo><mml:mrow><mml:msub><mml:mi class="ltx_font_mathcaligraphic" mathsize="80%">𝒩</mml:mi><mml:mi mathsize="80%">o</mml:mi></mml:msub><mml:mo>⁢</mml:mo><mml:mrow><mml:mo maxsize="160%" minsize="160%">(</mml:mo><mml:msub><mml:mi mathsize="80%">𝝁</mml:mi><mml:mi mathsize="80%">j</mml:mi></mml:msub><mml:mo mathsize="80%" stretchy="false">,</mml:mo><mml:msub><mml:mi mathsize="80%">𝚺</mml:mi><mml:mi mathsize="80%">j</mml:mi></mml:msub><mml:mo maxsize="160%" minsize="160%">)</mml:mo></mml:mrow></mml:mrow></mml:mrow><mml:mo mathsize="80%" stretchy="false">,</mml:mo></mml:mrow></mml:math></disp-formula>where<disp-formula id="equ20"><label>(10)</label><mml:math id="m20"><mml:mrow><mml:mrow><mml:msub><mml:mi mathsize="80%">𝝁</mml:mi><mml:mi mathsize="80%">j</mml:mi></mml:msub><mml:mo mathsize="80%" stretchy="false">=</mml:mo><mml:mrow><mml:msub><mml:mi mathsize="80%">μ</mml:mi><mml:mi mathsize="80%">j</mml:mi></mml:msub><mml:mo>⁢</mml:mo><mml:mpadded width="+5pt"><mml:mn mathsize="80%">𝟏</mml:mn></mml:mpadded><mml:mo>⁢</mml:mo><mml:mpadded width="+5pt"> <mml:mtext mathsize="80%">and </mml:mtext></mml:mpadded><mml:mo>⁢</mml:mo><mml:msub><mml:mi mathsize="80%">𝚺</mml:mi><mml:mi mathsize="80%">j</mml:mi></mml:msub></mml:mrow><mml:mo mathsize="80%" stretchy="false">=</mml:mo><mml:mrow><mml:mrow><mml:msub><mml:mi mathsize="80%">μ</mml:mi><mml:mi mathsize="80%">j</mml:mi></mml:msub><mml:mo>⁢</mml:mo><mml:mrow><mml:mo maxsize="80%" minsize="80%">(</mml:mo><mml:mrow><mml:mn mathsize="80%">1</mml:mn><mml:mo mathsize="80%" stretchy="false">-</mml:mo><mml:msub><mml:mi mathsize="80%">μ</mml:mi><mml:mi mathsize="80%">j</mml:mi></mml:msub></mml:mrow><mml:mo maxsize="80%" minsize="80%">)</mml:mo></mml:mrow></mml:mrow><mml:mo mathsize="80%" stretchy="false">⋅</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mrow><mml:mi mathsize="80%">𝑨</mml:mi><mml:mo>⁢</mml:mo><mml:msup><mml:mi mathsize="80%">𝑳</mml:mi><mml:mo mathsize="80%" stretchy="false">†</mml:mo></mml:msup><mml:mo>⁢</mml:mo><mml:msup><mml:mi mathsize="80%">𝑨</mml:mi><mml:mo mathsize="80%" stretchy="false">⊤</mml:mo></mml:msup></mml:mrow><mml:mo mathsize="80%" stretchy="false">+</mml:mo><mml:mrow><mml:msup><mml:mi mathsize="80%">σ</mml:mi><mml:mn mathsize="80%">2</mml:mn></mml:msup><mml:mo>⁢</mml:mo><mml:mtext mathsize="80%">diag</mml:mtext><mml:mo>⁢</mml:mo><mml:mrow><mml:mo maxsize="120%" minsize="120%">(</mml:mo><mml:msup><mml:mi mathsize="80%">𝒏</mml:mi><mml:mrow><mml:mo mathsize="80%" stretchy="false">-</mml:mo><mml:mn mathsize="80%">1</mml:mn></mml:mrow></mml:msup><mml:mo maxsize="120%" minsize="120%">)</mml:mo></mml:mrow></mml:mrow></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mrow><mml:mo mathsize="80%" stretchy="false">.</mml:mo></mml:mrow></mml:math></disp-formula></p><p>For each fold, we hold out one node from the set of observed nodes in the graph and use the rest of the nodes to fit FEEMS across a sequential grid of regularization parameters. Note that our objective function is non-convex, so the algorithm converges to different local minima for different regularization parameters, even with the same initial value <inline-formula><mml:math id="inf198"><mml:msub><mml:mover accent="true"><mml:mi mathsize="80%">w</mml:mi><mml:mo mathsize="80%" stretchy="false">^</mml:mo></mml:mover><mml:mn mathsize="80%">0</mml:mn></mml:msub></mml:math></inline-formula>. To stabilize the cross-validation procedure, we recommend using a warm start strategy in which one solves the problem for the largest value of regularization parameters first and use this solution to initialize the algorithm at the next largest value of regularization parameters, and so on. Empirically, we find that using warm starts gives far more reliable model selection than with cold starts, where the problems over the sequence of parameters are solved independently with same initial value <inline-formula><mml:math id="inf199"><mml:msub><mml:mover accent="true"><mml:mi mathsize="80%">w</mml:mi><mml:mo mathsize="80%" stretchy="false">^</mml:mo></mml:mover><mml:mn mathsize="80%">0</mml:mn></mml:msub></mml:math></inline-formula>. We suspect that the poor performance of leave-one-out cross-validation without warm starts is attributed to spatial dependency of allele frequencies and the large fraction of unobserved nodes. Without loss of generality, we assume that the last node has been held out. Re-writing the distribution of the observed frequencies according to the split of observed nodes,<disp-formula id="equ21"><mml:math id="m21"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mrow><mml:mover><mml:mi mathvariant="bold-italic">f</mml:mi><mml:mo>^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mtable columnspacing="1em" rowspacing="4pt"><mml:mtr><mml:mtd><mml:msubsup><mml:mrow><mml:mover><mml:mi mathvariant="bold-italic">f</mml:mi><mml:mo>^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow><mml:mrow><mml:mtext>tr</mml:mtext></mml:mrow></mml:msubsup></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:msubsup><mml:mrow><mml:mover><mml:mi>f</mml:mi><mml:mo>^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow><mml:mrow><mml:mtext>val</mml:mtext></mml:mrow></mml:msubsup></mml:mtd></mml:mtr></mml:mtable><mml:mo>)</mml:mo></mml:mrow><mml:mo>∼</mml:mo><mml:msub><mml:mrow><mml:mi mathvariant="script">𝒩</mml:mi></mml:mrow><mml:mrow><mml:mi>o</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mtable columnspacing="1em" rowspacing="4pt"><mml:mtr><mml:mtd><mml:msubsup><mml:mrow><mml:mi mathvariant="bold-italic">μ</mml:mi></mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow><mml:mrow><mml:mtext>tr</mml:mtext></mml:mrow></mml:msubsup></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:msubsup><mml:mrow><mml:mi>μ</mml:mi></mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow><mml:mrow><mml:mtext>val</mml:mtext></mml:mrow></mml:msubsup></mml:mtd></mml:mtr></mml:mtable><mml:mo>)</mml:mo></mml:mrow><mml:mo>,</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mtable columnalign="left left" columnspacing="1em" rowspacing="4pt"><mml:mtr><mml:mtd><mml:msubsup><mml:mi mathvariant="bold">Σ</mml:mi><mml:mrow><mml:mi>j</mml:mi></mml:mrow><mml:mrow><mml:mtext>tr</mml:mtext></mml:mrow></mml:msubsup></mml:mtd><mml:mtd><mml:msubsup><mml:mi mathvariant="bold">Σ</mml:mi><mml:mrow><mml:mi>j</mml:mi></mml:mrow><mml:mrow><mml:mtext>cov</mml:mtext></mml:mrow></mml:msubsup></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:msubsup><mml:mi mathvariant="bold">Σ</mml:mi><mml:mrow><mml:mi>j</mml:mi></mml:mrow><mml:mrow><mml:mtext>cov</mml:mtext><mml:mi mathvariant="normal">⊤</mml:mi></mml:mrow></mml:msubsup></mml:mtd><mml:mtd><mml:msubsup><mml:mi mathvariant="normal">Σ</mml:mi><mml:mrow><mml:mi>j</mml:mi></mml:mrow><mml:mrow><mml:mtext>val</mml:mtext></mml:mrow></mml:msubsup></mml:mtd></mml:mtr></mml:mtable><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>,</mml:mo></mml:mrow></mml:mstyle></mml:math></disp-formula>the conditional mean of the observed frequency <inline-formula><mml:math id="inf200"><mml:msubsup><mml:mover accent="true"><mml:mi mathsize="80%">f</mml:mi><mml:mo mathsize="80%" stretchy="false">^</mml:mo></mml:mover><mml:mi mathsize="80%">j</mml:mi><mml:mtext mathsize="80%">val</mml:mtext></mml:msubsup></mml:math></inline-formula> on the held out node, given the rest, is given by<disp-formula id="equ22"><mml:math id="m22"><mml:mrow><mml:msubsup><mml:mover accent="true"><mml:mi mathsize="80%">f</mml:mi><mml:mo mathsize="80%" stretchy="false">^</mml:mo></mml:mover><mml:mi mathsize="80%">j</mml:mi><mml:mtext mathsize="80%">val,pred</mml:mtext></mml:msubsup><mml:mo mathsize="80%" stretchy="false">=</mml:mo><mml:mi mathsize="80%">𝔼</mml:mi><mml:mrow><mml:mo>[</mml:mo><mml:mpadded width="+5pt"><mml:msubsup><mml:mover accent="true"><mml:mi mathsize="80%">f</mml:mi><mml:mo mathsize="80%" stretchy="false">^</mml:mo></mml:mover><mml:mi mathsize="80%">j</mml:mi><mml:mtext mathsize="80%">val</mml:mtext></mml:msubsup></mml:mpadded><mml:mo rspace="7.5pt">|</mml:mo><mml:msubsup><mml:mover accent="true"><mml:mi mathsize="80%">𝒇</mml:mi><mml:mo mathsize="80%" stretchy="false">^</mml:mo></mml:mover><mml:mi mathsize="80%">j</mml:mi><mml:mtext mathsize="80%">tr</mml:mtext></mml:msubsup><mml:mo>]</mml:mo></mml:mrow><mml:mo mathsize="80%" stretchy="false">=</mml:mo><mml:msubsup><mml:mi mathsize="80%">μ</mml:mi><mml:mi mathsize="80%">j</mml:mi><mml:mtext mathsize="80%">val</mml:mtext></mml:msubsup><mml:mo mathsize="80%" stretchy="false">+</mml:mo><mml:msubsup><mml:mi mathsize="80%">𝚺</mml:mi><mml:mi mathsize="80%">j</mml:mi><mml:mtext mathsize="80%">cov</mml:mtext></mml:msubsup><mml:mmultiscripts><mml:mi mathsize="80%">𝚺</mml:mi><mml:mi mathsize="80%">j</mml:mi><mml:mtext mathsize="80%">tr</mml:mtext><mml:mprescripts/><mml:none/><mml:mo mathsize="80%" stretchy="false">⊤</mml:mo></mml:mmultiscripts><mml:mmultiscripts><mml:mrow><mml:mo maxsize="80%" minsize="80%">(</mml:mo><mml:msubsup><mml:mover accent="true"><mml:mi mathsize="80%">𝒇</mml:mi><mml:mo mathsize="80%" stretchy="false">^</mml:mo></mml:mover><mml:mi mathsize="80%">j</mml:mi><mml:mtext mathsize="80%">tr</mml:mtext></mml:msubsup><mml:mo mathsize="80%" stretchy="false">-</mml:mo><mml:msubsup><mml:mi mathsize="80%">𝝁</mml:mi><mml:mi mathsize="80%">j</mml:mi><mml:mtext mathsize="80%">tr</mml:mtext></mml:msubsup><mml:mo maxsize="80%" minsize="80%">)</mml:mo></mml:mrow><mml:mprescripts/><mml:none/><mml:mrow><mml:mo mathsize="80%" stretchy="false">-</mml:mo><mml:mn mathsize="80%">1</mml:mn></mml:mrow></mml:mmultiscripts><mml:mo mathsize="80%" stretchy="false">.</mml:mo></mml:mrow></mml:math></disp-formula></p><p>Using this formula, we can predict allele frequencies at held out locations using the fitted graph <inline-formula><mml:math id="inf201"><mml:mrow><mml:mover accent="true"><mml:mi mathsize="80%" mathvariant="bold-italic">𝑳</mml:mi><mml:mo mathsize="80%" stretchy="false">^</mml:mo></mml:mover><mml:mo mathsize="80%" stretchy="false">=</mml:mo><mml:mrow><mml:mover accent="true"><mml:mi mathsize="80%" mathvariant="bold-italic">𝑳</mml:mi><mml:mo mathsize="80%" stretchy="false">^</mml:mo></mml:mover><mml:mo>⁢</mml:mo><mml:mrow><mml:mo maxsize="80%" minsize="80%">(</mml:mo><mml:mi mathsize="80%">λ</mml:mi><mml:mo mathsize="80%" stretchy="false">,</mml:mo><mml:mi mathsize="80%">α</mml:mi><mml:mo maxsize="80%" minsize="80%">)</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:math></inline-formula> for each setting of tuning parameters λ and α. Note that in <xref ref-type="disp-formula" rid="equ20">Equation (10)</xref>, the parameters <inline-formula><mml:math id="inf202"><mml:msub><mml:mi mathsize="80%">μ</mml:mi><mml:mi mathsize="80%">j</mml:mi></mml:msub></mml:math></inline-formula> and σ are also unknown, and we use an estimate of the average allele frequency <inline-formula><mml:math id="inf203"><mml:msub><mml:mover accent="true"><mml:mi mathsize="80%">μ</mml:mi><mml:mo mathsize="80%" stretchy="false">^</mml:mo></mml:mover><mml:mi mathsize="80%">j</mml:mi></mml:msub></mml:math></inline-formula> and the estimated residual variance <inline-formula><mml:math id="inf204"><mml:mover accent="true"><mml:mi mathsize="80%">σ</mml:mi><mml:mo mathsize="80%" stretchy="false">^</mml:mo></mml:mover></mml:math></inline-formula> from the ‘constant-<inline-formula><mml:math id="inf205"><mml:mi mathsize="80%">w</mml:mi></mml:math></inline-formula>’ model (they are not dependent on λ and α). Then we select the tuning parameters λ and α that output the minimum prediction error averaged over all SNPs <inline-formula><mml:math id="inf206"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mfrac><mml:mn>1</mml:mn><mml:mi>p</mml:mi></mml:mfrac><mml:munder><mml:mo>∑</mml:mo><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:munder><mml:msubsup><mml:mrow><mml:mo symmetric="true">‖</mml:mo><mml:mrow><mml:msubsup><mml:mrow><mml:mover><mml:mi>f</mml:mi><mml:mo>^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow><mml:mrow><mml:mtext>val,pred</mml:mtext></mml:mrow></mml:msubsup><mml:mo>−</mml:mo><mml:msubsup><mml:mrow><mml:mover><mml:mi>f</mml:mi><mml:mo>^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow><mml:mrow><mml:mtext>val</mml:mtext></mml:mrow></mml:msubsup></mml:mrow><mml:mo symmetric="true">‖</mml:mo></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup></mml:mrow></mml:mstyle></mml:math></inline-formula>, averaged over all the held out nodes (with <inline-formula><mml:math id="inf207"><mml:mi mathsize="80%">o</mml:mi></mml:math></inline-formula> observed nodes in total). As mentioned earlier, in practice we choose <inline-formula><mml:math id="inf208"><mml:mrow><mml:mi mathsize="80%">α</mml:mi><mml:mo mathsize="80%" stretchy="false">=</mml:mo><mml:mrow><mml:mn mathsize="80%">1</mml:mn><mml:mo mathsize="80%" stretchy="false">/</mml:mo><mml:msub><mml:mover accent="true"><mml:mi mathsize="80%">w</mml:mi><mml:mo mathsize="80%" stretchy="false">^</mml:mo></mml:mover><mml:mn mathsize="80%">0</mml:mn></mml:msub></mml:mrow></mml:mrow></mml:math></inline-formula> and hence we can use the leave-one-out cross-validation to search for λ only, which allows us to avoid the computational cost of searching over the two-dimensional parameter space.</p></sec><sec id="s4-6"><title>Comparison between FEEMS and EEMS models</title><p>At a high level, we can summarize the differences between FEEMS and EEMS as follows: (1) the likelihood functions of FEEMS and EEMS are slightly different as a function of the graph Laplacian <inline-formula><mml:math id="inf209"><mml:mi mathsize="80%" mathvariant="bold-italic">𝑳</mml:mi></mml:math></inline-formula>; (2) the migration rates are parameterized in terms of edge weights or in terms of node weights; and (3) EEMS is based on Bayesian inference and thus chooses a prior and studies the posterior distribution, while FEEMS is an optimization-based approach and thus chooses a penalty function and minimizes the penalized log-likelihood (in particular, the EEMS prior and the FEEMS penalty are both aiming for locally constant type migration surfaces). The last two points were already discussed in the above sections, so here we focus on the difference of the likelihoods between the two methods.</p><p>FEEMS develops the spatial model for the genetic differentiation through Gaussian Markov Random Field, but the resulting likelihood has similarities to EEMS (<xref ref-type="bibr" rid="bib42">Petkova et al., 2016</xref>) which considers the pairwise coalescent times. Using our notation, we can write the EEMS model as<disp-formula id="equ23"><label>(11)</label><mml:math id="m23"><mml:mrow><mml:mrow><mml:mrow><mml:mo mathsize="80%" stretchy="false">-</mml:mo><mml:mrow><mml:mrow><mml:mfrac><mml:mi mathsize="80%">ν</mml:mi><mml:mn mathsize="80%">2</mml:mn></mml:mfrac><mml:mo mathsize="80%" stretchy="false">⋅</mml:mo><mml:mi mathsize="80%">𝑪</mml:mi></mml:mrow><mml:mo>⁢</mml:mo><mml:msup><mml:mover accent="true"><mml:mi mathsize="80%">𝑫</mml:mi><mml:mo mathsize="80%" stretchy="false">^</mml:mo></mml:mover><mml:mo mathsize="80%" stretchy="false">*</mml:mo></mml:msup><mml:mo>⁢</mml:mo><mml:msup><mml:mi mathsize="80%">𝑪</mml:mi><mml:mo mathsize="80%" stretchy="false">⊤</mml:mo></mml:msup></mml:mrow></mml:mrow><mml:mo mathsize="80%" stretchy="false">∼</mml:mo><mml:mrow><mml:msub><mml:mi class="ltx_font_mathcaligraphic" mathsize="80%">𝒲</mml:mi><mml:mrow><mml:mi mathsize="80%">o</mml:mi><mml:mo mathsize="80%" stretchy="false">-</mml:mo><mml:mn mathsize="80%">1</mml:mn></mml:mrow></mml:msub><mml:mo>⁢</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mrow><mml:msup><mml:mi mathsize="80%">σ</mml:mi><mml:mo mathsize="80%" stretchy="false">*</mml:mo></mml:msup><mml:mo mathsize="80%" stretchy="false">⋅</mml:mo><mml:mi mathsize="80%">𝑪</mml:mi></mml:mrow><mml:mo>⁢</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mrow><mml:mfrac><mml:mn mathsize="80%">1</mml:mn><mml:mn mathsize="80%">2</mml:mn></mml:mfrac><mml:mo>⁢</mml:mo><mml:mi mathsize="80%">𝑨</mml:mi><mml:mo>⁢</mml:mo><mml:msup><mml:mi mathsize="80%">𝑳</mml:mi><mml:mo mathsize="80%" stretchy="false">†</mml:mo></mml:msup><mml:mo>⁢</mml:mo><mml:msup><mml:mi mathsize="80%">𝑨</mml:mi><mml:mo mathsize="80%" stretchy="false">⊤</mml:mo></mml:msup></mml:mrow><mml:mo mathsize="80%" stretchy="false">+</mml:mo><mml:mrow><mml:mtext mathsize="80%">diag</mml:mtext><mml:mo>⁢</mml:mo><mml:mrow><mml:mo maxsize="120%" minsize="120%">(</mml:mo><mml:mrow><mml:mi mathsize="80%">𝑨</mml:mi><mml:mo>⁢</mml:mo><mml:mi mathsize="80%">𝒒</mml:mi></mml:mrow><mml:mo maxsize="120%" minsize="120%">)</mml:mo></mml:mrow></mml:mrow></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>⁢</mml:mo><mml:msup><mml:mi mathsize="80%">𝑪</mml:mi><mml:mo mathsize="80%" stretchy="false">⊤</mml:mo></mml:msup></mml:mrow><mml:mo mathsize="80%" stretchy="false">,</mml:mo><mml:mi mathsize="80%">ν</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mrow><mml:mo mathsize="80%" stretchy="false">,</mml:mo></mml:mrow></mml:math></disp-formula>where <inline-formula><mml:math id="inf210"><mml:mrow><mml:mi mathsize="80%">ν</mml:mi><mml:mo mathsize="80%" stretchy="false">∈</mml:mo><mml:mrow><mml:mo maxsize="80%" minsize="80%">[</mml:mo><mml:mrow><mml:mi mathsize="80%">o</mml:mi><mml:mo mathsize="80%" stretchy="false">-</mml:mo><mml:mn mathsize="80%">1</mml:mn></mml:mrow><mml:mo mathsize="80%" stretchy="false">,</mml:mo><mml:mi mathsize="80%">p</mml:mi><mml:mo maxsize="80%" minsize="80%">]</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> is the effective degree of freedom, <inline-formula><mml:math id="inf211"><mml:mrow><mml:msup><mml:mi mathsize="80%">σ</mml:mi><mml:mo mathsize="80%" stretchy="false">*</mml:mo></mml:msup><mml:mo mathsize="80%" stretchy="false">&gt;</mml:mo><mml:mn mathsize="80%">0</mml:mn></mml:mrow></mml:math></inline-formula> is the scale nuisance parameter, and <inline-formula><mml:math id="inf212"><mml:mi mathsize="80%" mathvariant="bold-italic">𝒒</mml:mi></mml:math></inline-formula> is a <inline-formula><mml:math id="inf213"><mml:mrow><mml:mi mathsize="80%">d</mml:mi><mml:mo mathsize="80%" stretchy="false">×</mml:mo><mml:mn mathsize="80%">1</mml:mn></mml:mrow></mml:math></inline-formula> vector of the within-sub-population coalescent rates. <inline-formula><mml:math id="inf214"><mml:msup><mml:mover accent="true"><mml:mi mathsize="80%" mathvariant="bold-italic">𝑫</mml:mi><mml:mo mathsize="80%" stretchy="false">^</mml:mo></mml:mover><mml:mo mathsize="80%" stretchy="false">*</mml:mo></mml:msup></mml:math></inline-formula> represents the genetic distance matrix without re-scaling, where the <inline-formula><mml:math id="inf215"><mml:mrow><mml:mo maxsize="80%" minsize="80%">(</mml:mo><mml:mi mathsize="80%">k</mml:mi><mml:mo mathsize="80%" stretchy="false">,</mml:mo><mml:mi mathsize="80%" mathvariant="normal">ℓ</mml:mi><mml:mo maxsize="80%" minsize="80%">)</mml:mo></mml:mrow></mml:math></inline-formula>-th element is given by <inline-formula><mml:math id="inf216"><mml:mrow><mml:msubsup><mml:mover accent="true"><mml:mi mathsize="80%" mathvariant="bold-italic">𝑫</mml:mi><mml:mo mathsize="80%" stretchy="false">^</mml:mo></mml:mover><mml:mrow><mml:mi mathsize="80%">k</mml:mi><mml:mo>⁢</mml:mo><mml:mi mathsize="80%" mathvariant="normal">ℓ</mml:mi></mml:mrow><mml:mo mathsize="80%" stretchy="false">⋆</mml:mo></mml:msubsup><mml:mo mathsize="80%" stretchy="false">=</mml:mo><mml:mrow><mml:msubsup><mml:mo largeop="true" mathsize="80%" stretchy="false" symmetric="true">∑</mml:mo><mml:mrow><mml:mi mathsize="80%">j</mml:mi><mml:mo mathsize="80%" stretchy="false">=</mml:mo><mml:mn mathsize="80%">1</mml:mn></mml:mrow><mml:mi mathsize="80%">p</mml:mi></mml:msubsup><mml:mrow><mml:msup><mml:mrow><mml:mo maxsize="80%" minsize="80%">(</mml:mo><mml:mrow><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi mathsize="80%">f</mml:mi><mml:mo mathsize="80%" stretchy="false">^</mml:mo></mml:mover><mml:mi mathsize="80%">j</mml:mi></mml:msub><mml:mo>⁢</mml:mo><mml:mrow><mml:mo maxsize="80%" minsize="80%">(</mml:mo><mml:mi mathsize="80%">k</mml:mi><mml:mo maxsize="80%" minsize="80%">)</mml:mo></mml:mrow></mml:mrow><mml:mo mathsize="80%" stretchy="false">-</mml:mo><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi mathsize="80%">f</mml:mi><mml:mo mathsize="80%" stretchy="false">^</mml:mo></mml:mover><mml:mi mathsize="80%">j</mml:mi></mml:msub><mml:mo>⁢</mml:mo><mml:mrow><mml:mo maxsize="80%" minsize="80%">(</mml:mo><mml:mi mathsize="80%" mathvariant="normal">ℓ</mml:mi><mml:mo maxsize="80%" minsize="80%">)</mml:mo></mml:mrow></mml:mrow></mml:mrow><mml:mo maxsize="80%" minsize="80%">)</mml:mo></mml:mrow><mml:mn mathsize="80%">2</mml:mn></mml:msup><mml:mo mathsize="80%" stretchy="false">/</mml:mo><mml:mi mathsize="80%">p</mml:mi></mml:mrow></mml:mrow></mml:mrow></mml:math></inline-formula>. That is, unlike FEEMS, EEMS does not consider the SNP-specific re-scaling factor <inline-formula><mml:math id="inf217"><mml:mrow><mml:msub><mml:mi mathsize="80%">μ</mml:mi><mml:mi mathsize="80%">j</mml:mi></mml:msub><mml:mo>⁢</mml:mo><mml:mrow><mml:mo maxsize="80%" minsize="80%">(</mml:mo><mml:mrow><mml:mn mathsize="80%">1</mml:mn><mml:mo mathsize="80%" stretchy="false">-</mml:mo><mml:msub><mml:mi mathsize="80%">μ</mml:mi><mml:mi mathsize="80%">j</mml:mi></mml:msub></mml:mrow><mml:mo maxsize="80%" minsize="80%">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> to account for the vanishing variance of the observed allele frequencies as the average allele frequency approaches to 0 or 1.</p><p>In <xref ref-type="disp-formula" rid="equ23">Equation (11)</xref>, the effective degree of freedom ν is introduced to account for the dependency across SNPs in close proximity. Because EEMS uses a hierarchical Bayesian model to infer the effective migration rates, ν is being estimated alongside other model parameters. On the other hand, FEEMS uses an optimization-based approach and the degrees of freedom has no influence on the point estimate of the migration rates. Besides the effective degree of freedom and the SNP-specific re-scaling by <inline-formula><mml:math id="inf218"><mml:mrow><mml:msub><mml:mi mathsize="80%">μ</mml:mi><mml:mi mathsize="80%">j</mml:mi></mml:msub><mml:mo>⁢</mml:mo><mml:mrow><mml:mo maxsize="80%" minsize="80%">(</mml:mo><mml:mrow><mml:mn mathsize="80%">1</mml:mn><mml:mo mathsize="80%" stretchy="false">-</mml:mo><mml:msub><mml:mi mathsize="80%">μ</mml:mi><mml:mi mathsize="80%">j</mml:mi></mml:msub></mml:mrow><mml:mo maxsize="80%" minsize="80%">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula>, the EEMS and FEEMS likelihoods are equivalent up to constant factors, as long as only one individual is observed per node and the residual variance <inline-formula><mml:math id="inf219"><mml:msup><mml:mi mathsize="80%">σ</mml:mi><mml:mn mathsize="80%">2</mml:mn></mml:msup></mml:math></inline-formula> is allowed to vary across nodes—See Appendix 1 ‘<italic>Jointly estimating the residual variance and edge weights</italic>’ for details. The constant factors, such as <inline-formula><mml:math id="inf220"><mml:msup><mml:mi mathsize="80%">σ</mml:mi><mml:mo mathsize="80%" stretchy="false">*</mml:mo></mml:msup></mml:math></inline-formula>, can be effectively absorbed into the unknown model parameters <inline-formula><mml:math id="inf221"><mml:mi mathsize="80%" mathvariant="bold-italic">𝑳</mml:mi></mml:math></inline-formula> and <inline-formula><mml:math id="inf222"><mml:mi mathsize="80%" mathvariant="bold-italic">𝒒</mml:mi></mml:math></inline-formula> and therefore they do not affect the estimation of effective migration rates, up to constant factors.</p></sec><sec id="s4-7"><title>Data description and quality control</title><p>We analyzed a population genetic dataset of North American gray wolves previously published in <xref ref-type="bibr" rid="bib51">Schweizer et al., 2016</xref>. For this, we downloaded plink (<monospace>RRID:<ext-link ext-link-type="uri" xlink:href="https://scicrunch.org/resolver/SCR_001757">SCR_001757</ext-link></monospace>) formatted files and spatial coordinates from <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.5061/dryad.c9b25">https://doi.org/10.5061/dryad.c9b25</ext-link>. We removed all SNPs with minor allele frequency less than 5% and with missingness greater then 10%, resulting in a final set of 111 individuals and 17,729 SNPs.</p></sec><sec id="s4-8"><title>Population structure analyses</title><p>We fit the Pritchard, Donnelly, and Stephens model (PSD) and ran principal components analysis on the genotype matrix of North American gray wolves (<xref ref-type="bibr" rid="bib45">Price et al., 2006</xref>; <xref ref-type="bibr" rid="bib46">Pritchard et al., 2000</xref>). For the PSD model, we used the ADMIXTURE software (<monospace>RRID:<ext-link ext-link-type="uri" xlink:href="https://scicrunch.org/resolver/SCR_001263">SCR_001263</ext-link></monospace>) on the un-normalized genotypes, running five replicates per choice of <inline-formula><mml:math id="inf223"><mml:mi mathsize="80%">K</mml:mi></mml:math></inline-formula>, from <inline-formula><mml:math id="inf224"><mml:mrow><mml:mi mathsize="80%">K</mml:mi><mml:mo mathsize="80%" stretchy="false">=</mml:mo><mml:mn mathsize="80%">2</mml:mn></mml:mrow></mml:math></inline-formula> to <inline-formula><mml:math id="inf225"><mml:mrow><mml:mi mathsize="80%">K</mml:mi><mml:mo mathsize="80%" stretchy="false">=</mml:mo><mml:mn mathsize="80%">8</mml:mn></mml:mrow></mml:math></inline-formula> (<xref ref-type="bibr" rid="bib2">Alexander et al., 2009</xref>). For each <inline-formula><mml:math id="inf226"><mml:mi mathsize="80%">K</mml:mi></mml:math></inline-formula>, we choose the one that achieved the highest likelihood to visualize. For PCA, we centered and scaled the genotype matrix and then ran <monospace>sklearn</monospace> (<monospace>RRID:<ext-link ext-link-type="uri" xlink:href="https://scicrunch.org/resolver/SCR_019053">SCR_019053</ext-link></monospace>) implementation of PCA, truncated to compute 50 eigenvectors.</p></sec><sec id="s4-9"><title>Grid construction</title><p>To create a dense triangular lattice around the sample locations, we first define an outer boundary polygon. As a default, we construct the lattice by creating a convex hull around the sample points and manually trimming the polygon to adhere to the geography of the study organism and balancing the sample point range with the extent of local geography using the following website <ext-link ext-link-type="uri" xlink:href="https://www.keene.edu/campus/maps/tool/">https://www.keene.edu/campus/maps/tool/</ext-link>. We often do not exclude internal ‘holes’ in the habitat (e.g. water features for terrestrial animals), and let the model instead fit effective migration rates for those features to the extent they lead to elevated differentiation. We also emphasize the importance of defining the lattice for FEEMS as well as EEMS and suggest this should be carefully curated with prior biological knowledge about the system.</p><p>To ensure edges cover an equal area over the entire region, we downloaded and intersected a uniform grid defined on the spherical shape of earth (<xref ref-type="bibr" rid="bib50">Sahr et al., 2003</xref>). These defined grids are pre-computed at a number of different resolutions, allowing a user to test FEEMS at different grid densities which is an important feature to explore.</p></sec><sec id="s4-10"><title>Code availability</title><p>The code to reproduce the results of this paper and more can be found at <ext-link ext-link-type="uri" xlink:href="https://github.com/jhmarcus/feems-analysis">https://github.com/jhmarcus/feems-analysis</ext-link> (<xref ref-type="bibr" rid="bib28">Marcus and Ha, 2021a</xref>, copy archived at <ext-link ext-link-type="uri" xlink:href="https://archive.softwareheritage.org/swh:1:dir:9061bbaa188e0f2f680f366f2cf1cfe4d2a7f7f6;origin=https://github.com/jhmarcus/feems-analysis;visit=swh:1:snp:163e11d3fdf9458b4b1114080f004ab83bc8dd9f;anchor=swh:1:rev:f2d7330f25f8a11124db09000918ae38ae00d4a7">swh:1:rev:f2d7330f25f8a11124db09000918ae38ae00d4a7</ext-link>, <xref ref-type="bibr" rid="bib29">Marcus and Ha, 2021b</xref>). A <monospace>python</monospace> (<monospace>RRID:<ext-link ext-link-type="uri" xlink:href="https://scicrunch.org/resolver/SCR_008394">SCR_008394</ext-link></monospace>) package implementing the method can be found at <ext-link ext-link-type="uri" xlink:href="https://github.com/Novembrelab/feems">https://github.com/Novembrelab/feems</ext-link>.</p></sec></sec></body><back><ack id="ack"><title>Acknowledgements</title><p>We thank Rena Schweizer for helping us download and process the gray wolf dataset used in the paper, Ben Peter for providing feedback and code for helping to construct the discrete global grids and preparing the human genetic dataset, and Hussein Al-Asadi, Peter Carbonetto, Dan Rice for helpful conversations about the optimization and modeling approach. We also acknowledge helpful feedback from Arjun Biddanda, Anna Di Rienzo, Matthew Stephens, the Stephens Lab, the Novembre Lab, and the University of Chicago 4th floor Cummings Life Science Center computational biology community. This study was supported in part by the National Science Foundation via fellowship DGE-1746045 and the National Institute of General Medical Sciences via training grant T32GM007197 to JHM and R01GM132383 to JN. WH was partially supported by the NSF via the TRIPODS program and by the Berkeley Institute for Data Science. RFB was supported by the National Science Foundation via grant DMS–1654076, and by the Office of Naval Research via grant N00014-20-1-2337.</p></ack><sec id="s5" sec-type="additional-information"><title>Additional information</title><fn-group content-type="competing-interest"><title>Competing interests</title><fn fn-type="COI-statement" id="conf1"><p>No competing interests declared</p></fn></fn-group><fn-group content-type="author-contribution"><title>Author contributions</title><fn fn-type="con" id="con1"><p>Conceptualization, Software, Formal analysis, Visualization, Methodology, Writing - original draft, Writing - review and editing</p></fn><fn fn-type="con" id="con2"><p>Software, Formal analysis, Visualization, Methodology, Writing - original draft, Writing - review and editing</p></fn><fn fn-type="con" id="con3"><p>Formal analysis, Supervision, Methodology, Writing - review and editing</p></fn><fn fn-type="con" id="con4"><p>Conceptualization, Formal analysis, Supervision, Visualization, Writing - review and editing</p></fn></fn-group></sec><sec id="s6" sec-type="supplementary-material"><title>Additional files</title><supplementary-material id="transrepform"><label>Transparent reporting form</label><media mime-subtype="docx" mimetype="application" xlink:href="elife-61927-transrepform-v1.docx"/></supplementary-material></sec><sec id="s7" sec-type="data-availability"><title>Data availability</title><p>Genotyping data can be found at <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.5061/dryad.c9b25">https://doi.org/10.5061/dryad.c9b25</ext-link> and stored in the FEEMS python package at <ext-link ext-link-type="uri" xlink:href="https://github.com/Novembrelab/feems">https://github.com/Novembrelab/feems</ext-link> (copy archived at <ext-link ext-link-type="uri" xlink:href="https://archive.softwareheritage.org/swh:1:rev:2df82f92ba690f5fd98aee6612b155d973ffb12d">https://archive.softwareheritage.org/swh:1:rev:2df82f92ba690f5fd98aee6612b155d973ffb12d</ext-link>).</p><p>The following previously published dataset was used:</p><p><element-citation id="dataset1" publication-type="data" specific-use="references"><person-group person-group-type="author"><name><surname>Schweizer</surname><given-names>RM</given-names></name><name><surname>vonHoldt</surname><given-names>JC</given-names></name><collab>R</collab><collab>BM</collab><collab>Harrigan</collab><collab>Knowles</collab><name><surname>Musiani</surname><given-names>M</given-names></name><name><surname>Coltman</surname><given-names>D</given-names></name><name><surname>Novembre</surname><given-names>J</given-names></name><name><surname>Wayne</surname><given-names>RK</given-names></name></person-group><year iso-8601-date="2016">2016</year><data-title>Genetic subdivision and candidate genes under selection in North American grey wolves</data-title><source>Dryad Digital Repository</source><pub-id assigning-authority="Dryad" pub-id-type="doi">10.5061/dryad.c9b25</pub-id></element-citation></p></sec><ref-list><title>References</title><ref id="bib1"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Al-Asadi</surname> <given-names>H</given-names></name><name><surname>Petkova</surname> <given-names>D</given-names></name><name><surname>Stephens</surname> <given-names>M</given-names></name><name><surname>Novembre</surname> <given-names>J</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>Estimating recent migration and population-size surfaces</article-title><source>PLOS Genetics</source><volume>15</volume><elocation-id>e1007908</elocation-id><pub-id pub-id-type="doi">10.1371/journal.pgen.1007908</pub-id><pub-id pub-id-type="pmid">30640906</pub-id></element-citation></ref><ref id="bib2"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Alexander</surname> <given-names>DH</given-names></name><name><surname>Novembre</surname> <given-names>J</given-names></name><name><surname>Lange</surname> <given-names>K</given-names></name></person-group><year iso-8601-date="2009">2009</year><article-title>Fast model-based estimation of ancestry in unrelated individuals</article-title><source>Genome Research</source><volume>19</volume><fpage>1655</fpage><lpage>1664</lpage><pub-id pub-id-type="doi">10.1101/gr.094052.109</pub-id><pub-id pub-id-type="pmid">19648217</pub-id></element-citation></ref><ref id="bib3"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Battey</surname> <given-names>CJ</given-names></name><name><surname>Ralph</surname> <given-names>PL</given-names></name><name><surname>Kern</surname> <given-names>AD</given-names></name></person-group><year iso-8601-date="2020">2020</year><article-title>Space is the place: effects of continuous spatial structure on analysis of population genetic data</article-title><source>Genetics</source><volume>215</volume><fpage>193</fpage><lpage>214</lpage><pub-id pub-id-type="doi">10.1534/genetics.120.303143</pub-id><pub-id pub-id-type="pmid">32209569</pub-id></element-citation></ref><ref id="bib4"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Boyd</surname> <given-names>S</given-names></name></person-group><year iso-8601-date="2010">2010</year><article-title>Distributed optimization and statistical learning via the alternating direction method of multipliers</article-title><source>Foundations and Trends in Machine Learning</source><volume>3</volume><fpage>1</fpage><lpage>122</lpage><pub-id pub-id-type="doi">10.1561/2200000016</pub-id></element-citation></ref><ref id="bib5"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bradburd</surname> <given-names>GS</given-names></name><name><surname>Ralph</surname> <given-names>PL</given-names></name><name><surname>Coop</surname> <given-names>GM</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>A spatial framework for understanding population structure and admixture</article-title><source>PLOS Genetics</source><volume>12</volume><elocation-id>e1005703</elocation-id><pub-id pub-id-type="doi">10.1371/journal.pgen.1005703</pub-id><pub-id pub-id-type="pmid">26771578</pub-id></element-citation></ref><ref id="bib6"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bradburd</surname> <given-names>GS</given-names></name><name><surname>Coop</surname> <given-names>GM</given-names></name><name><surname>Ralph</surname> <given-names>PL</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>Inferring continuous and discrete population genetic structure across space</article-title><source>Genetics</source><volume>210</volume><fpage>33</fpage><lpage>52</lpage><pub-id pub-id-type="doi">10.1534/genetics.118.301333</pub-id><pub-id pub-id-type="pmid">30026187</pub-id></element-citation></ref><ref id="bib7"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bradburd</surname> <given-names>GS</given-names></name><name><surname>Ralph</surname> <given-names>PL</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>Spatial population genetics: it's about time</article-title><source>Annual Review of Ecology, Evolution, and Systematics</source><volume>50</volume><fpage>427</fpage><lpage>449</lpage><pub-id pub-id-type="doi">10.1146/annurev-ecolsys-110316-022659</pub-id></element-citation></ref><ref id="bib8"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Burch</surname> <given-names>JW</given-names></name><name><surname>Adams</surname> <given-names>LG</given-names></name><name><surname>Follmann</surname> <given-names>EH</given-names></name><name><surname>Rexstad</surname> <given-names>EA</given-names></name></person-group><year iso-8601-date="2005">2005</year><article-title>Evaluation of wolf density estimation from radiotelemetry data</article-title><source>Wildlife Society Bulletin</source><volume>33</volume><fpage>1225</fpage><lpage>1236</lpage><pub-id pub-id-type="doi">10.2193/0091-7648(2005)33[1225:EOWDEF]2.0.CO;2</pub-id></element-citation></ref><ref id="bib9"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Byrd</surname> <given-names>RH</given-names></name><name><surname>Lu</surname> <given-names>P</given-names></name><name><surname>Nocedal</surname> <given-names>J</given-names></name><name><surname>Zhu</surname> <given-names>C</given-names></name></person-group><year iso-8601-date="1995">1995</year><article-title>A limited memory algorithm for bound constrained optimization</article-title><source>SIAM Journal on Scientific Computing</source><volume>16</volume><fpage>1190</fpage><lpage>1208</lpage><pub-id pub-id-type="doi">10.1137/0916069</pub-id></element-citation></ref><ref id="bib10"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Chandra</surname> <given-names>AK</given-names></name><name><surname>Raghavan</surname> <given-names>P</given-names></name><name><surname>Ruzzo</surname> <given-names>WL</given-names></name><name><surname>Smolensky</surname> <given-names>R</given-names></name><name><surname>Tiwari</surname> <given-names>P</given-names></name></person-group><year iso-8601-date="1996">1996</year><article-title>The electrical resistance of a graph captures its commute and cover times</article-title><source>Computational Complexity</source><volume>6</volume><fpage>312</fpage><lpage>340</lpage><pub-id pub-id-type="doi">10.1007/BF01270385</pub-id></element-citation></ref><ref id="bib11"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Dobzhansky</surname> <given-names>T</given-names></name><name><surname>Wright</surname> <given-names>S</given-names></name></person-group><year iso-8601-date="1943">1943</year><article-title>Genetics of Natural Populations. X. Dispersion rates in <italic>Drosophila pseudoobscura</italic></article-title><source>Genetics</source><volume>28</volume><fpage>304</fpage><lpage>340</lpage><pub-id pub-id-type="doi">10.1093/genetics/28.4.304</pub-id><pub-id pub-id-type="pmid">17247091</pub-id></element-citation></ref><ref id="bib12"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Dong</surname> <given-names>X</given-names></name><name><surname>Thanou</surname> <given-names>D</given-names></name><name><surname>Frossard</surname> <given-names>P</given-names></name><name><surname>Vandergheynst</surname> <given-names>P</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Learning Laplacian matrix in smooth graph signal representations</article-title><source>IEEE Transactions on Signal Processing</source><volume>64</volume><fpage>6160</fpage><lpage>6173</lpage><pub-id pub-id-type="doi">10.1109/TSP.2016.2602809</pub-id></element-citation></ref><ref id="bib13"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Dong</surname> <given-names>X</given-names></name><name><surname>Thanou</surname> <given-names>D</given-names></name><name><surname>Rabbat</surname> <given-names>M</given-names></name><name><surname>Frossard</surname> <given-names>P</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>Learning graphs from data: a signal representation perspective</article-title><source>IEEE Signal Processing Magazine</source><volume>36</volume><fpage>44</fpage><lpage>63</lpage><pub-id pub-id-type="doi">10.1109/MSP.2018.2887284</pub-id></element-citation></ref><ref id="bib14"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Duforet‐Frebourg</surname> <given-names>N</given-names></name><name><surname>Blum</surname> <given-names>MGB</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>Nonstationary patterns of isolation‐by‐distance: inferring measures of local genetic differentiation with Bayesian kriging</article-title><source>Evolution</source><volume>68</volume><fpage>1110</fpage><lpage>1123</lpage><pub-id pub-id-type="doi">10.1111/evo.12342</pub-id></element-citation></ref><ref id="bib15"><element-citation publication-type="preprint"><person-group person-group-type="author"><name><surname>Egilmez</surname> <given-names>HE</given-names></name><name><surname>Pavez</surname> <given-names>E</given-names></name><name><surname>Ortega</surname> <given-names>A</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Graph learning from data under structural and Laplacian constraints</article-title><source>arXiv</source><ext-link ext-link-type="uri" xlink:href="https://arxiv.org/abs/1611.05181">https://arxiv.org/abs/1611.05181</ext-link></element-citation></ref><ref id="bib16"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Felsenstein</surname> <given-names>J</given-names></name></person-group><year iso-8601-date="1982">1982</year><article-title>How can we infer geography and history from gene frequencies?</article-title><source>Journal of Theoretical Biology</source><volume>96</volume><fpage>9</fpage><lpage>20</lpage><pub-id pub-id-type="doi">10.1016/0022-5193(82)90152-7</pub-id><pub-id pub-id-type="pmid">7109659</pub-id></element-citation></ref><ref id="bib17"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Friedman</surname> <given-names>J</given-names></name><name><surname>Hastie</surname> <given-names>T</given-names></name><name><surname>Tibshirani</surname> <given-names>R</given-names></name></person-group><year iso-8601-date="2008">2008</year><article-title>Sparse inverse covariance estimation with the graphical lasso</article-title><source>Biostatistics</source><volume>9</volume><fpage>432</fpage><lpage>441</lpage><pub-id pub-id-type="doi">10.1093/biostatistics/kxm045</pub-id><pub-id pub-id-type="pmid">18079126</pub-id></element-citation></ref><ref id="bib18"><element-citation publication-type="preprint"><person-group person-group-type="author"><name><surname>Hanks</surname> <given-names>EM</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>A constructive spatio-temporal approach to modeling spatial covariance</article-title><source>arXiv</source><ext-link ext-link-type="uri" xlink:href="https://arxiv.org/abs/1506.03824">https://arxiv.org/abs/1506.03824</ext-link></element-citation></ref><ref id="bib19"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hanks</surname> <given-names>EM</given-names></name><name><surname>Hooten</surname> <given-names>MB</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>Circuit theory and model-based inference for landscape connectivity</article-title><source>Journal of the American Statistical Association</source><volume>108</volume><fpage>22</fpage><lpage>33</lpage><pub-id pub-id-type="doi">10.1080/01621459.2012.724647</pub-id></element-citation></ref><ref id="bib20"><element-citation publication-type="confproc"><person-group person-group-type="author"><name><surname>Kalofolias</surname> <given-names>V</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>How to learn a graph from smooth signals</article-title><conf-name>Proceedings of the 19th International Conference on Artificial Intelligence and Statistics</conf-name><fpage>920</fpage><lpage>929</lpage></element-citation></ref><ref id="bib21"><element-citation publication-type="confproc"><person-group person-group-type="author"><name><surname>Kimura</surname> <given-names>M</given-names></name></person-group><year iso-8601-date="1953">1953</year><article-title>Stepping stone model of population</article-title><conf-name>Annual Report of the National Institute of Genetics Japan</conf-name><fpage>62</fpage><lpage>63</lpage></element-citation></ref><ref id="bib22"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kimura</surname> <given-names>M</given-names></name><name><surname>Weiss</surname> <given-names>GH</given-names></name></person-group><year iso-8601-date="1964">1964</year><article-title>The stepping stone model of population structure and the decrease of genetic correlation with distance</article-title><source>Genetics</source><volume>49</volume><fpage>561</fpage><lpage>576</lpage><pub-id pub-id-type="doi">10.1093/genetics/49.4.561</pub-id><pub-id pub-id-type="pmid">17248204</pub-id></element-citation></ref><ref id="bib23"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Koller</surname> <given-names>D</given-names></name><name><surname>Friedman</surname> <given-names>N</given-names></name></person-group><year iso-8601-date="2009">2009</year><source>Probabilistic Graphical Models: Principles and Techniques</source><publisher-name>MIT Press</publisher-name></element-citation></ref><ref id="bib24"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Korneliussen</surname> <given-names>TS</given-names></name><name><surname>Albrechtsen</surname> <given-names>A</given-names></name><name><surname>Nielsen</surname> <given-names>R</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>ANGSD: analysis of next generation sequencing data</article-title><source>BMC Bioinformatics</source><volume>15</volume><elocation-id>356</elocation-id><pub-id pub-id-type="doi">10.1186/s12859-014-0356-4</pub-id><pub-id pub-id-type="pmid">25420514</pub-id></element-citation></ref><ref id="bib25"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Lauritzen</surname> <given-names>SL</given-names></name></person-group><year iso-8601-date="1996">1996</year><source>Graphical Models</source><publisher-name>Clarendon Press</publisher-name></element-citation></ref><ref id="bib26"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Lundgren</surname> <given-names>E</given-names></name><name><surname>Ralph</surname> <given-names>PL</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>Are populations like a circuit? Comparing isolation by resistance to a new coalescent-based method</article-title><source>Molecular Ecology Resources</source><volume>19</volume><fpage>1388</fpage><lpage>1406</lpage><pub-id pub-id-type="doi">10.1111/1755-0998.13035</pub-id><pub-id pub-id-type="pmid">31099173</pub-id></element-citation></ref><ref id="bib27"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Malécot</surname> <given-names>G</given-names></name></person-group><year iso-8601-date="1948">1948</year><source>Les mathématiques de L’hérédité</source><publisher-loc>Paris, France</publisher-loc><publisher-name>Masson et cie</publisher-name></element-citation></ref><ref id="bib28"><element-citation publication-type="software"><person-group person-group-type="author"><name><surname>Marcus</surname> <given-names>J</given-names></name><name><surname>Ha</surname> <given-names>W</given-names></name></person-group><year iso-8601-date="2021">2021a</year><data-title>feems-analysis</data-title><source>GitHub</source><version designator="f2d7330">f2d7330</version><ext-link ext-link-type="uri" xlink:href="https://github.com/jhmarcus/feems-analysis">https://github.com/jhmarcus/feems-analysis</ext-link></element-citation></ref><ref id="bib29"><element-citation publication-type="software"><person-group person-group-type="author"><name><surname>Marcus</surname> <given-names>J</given-names></name><name><surname>Ha</surname> <given-names>W</given-names></name></person-group><year iso-8601-date="2021">2021b</year><data-title>Feems-analysis</data-title><source>Software Heritage</source><version designator="swh:1:rev:f2d7330f25f8a11124db09000918ae38ae00d4a7">swh:1:rev:f2d7330f25f8a11124db09000918ae38ae00d4a7</version><ext-link ext-link-type="uri" xlink:href="https://archive.softwareheritage.org/swh:1:rev:f2d7330f25f8a11124db09000918ae38ae00d4a7">https://archive.softwareheritage.org/swh:1:rev:f2d7330f25f8a11124db09000918ae38ae00d4a7</ext-link></element-citation></ref><ref id="bib30"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Mateos</surname> <given-names>G</given-names></name><name><surname>Segarra</surname> <given-names>S</given-names></name><name><surname>Marques</surname> <given-names>AG</given-names></name><name><surname>Ribeiro</surname> <given-names>A</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>Connecting the dots: identifying network structure via graph signal processing</article-title><source>IEEE Signal Processing Magazine</source><volume>36</volume><fpage>16</fpage><lpage>43</lpage><pub-id pub-id-type="doi">10.1109/MSP.2018.2890143</pub-id></element-citation></ref><ref id="bib31"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Mathieson</surname> <given-names>I</given-names></name><name><surname>Alpaslan-Roodenberg</surname> <given-names>S</given-names></name><name><surname>Posth</surname> <given-names>C</given-names></name><name><surname>Szécsényi-Nagy</surname> <given-names>A</given-names></name><name><surname>Rohland</surname> <given-names>N</given-names></name><name><surname>Mallick</surname> <given-names>S</given-names></name><name><surname>Olalde</surname> <given-names>I</given-names></name><name><surname>Broomandkhoshbacht</surname> <given-names>N</given-names></name><name><surname>Candilio</surname> <given-names>F</given-names></name><name><surname>Cheronet</surname> <given-names>O</given-names></name><name><surname>Fernandes</surname> <given-names>D</given-names></name><name><surname>Ferry</surname> <given-names>M</given-names></name><name><surname>Gamarra</surname> <given-names>B</given-names></name><name><surname>Fortes</surname> <given-names>GG</given-names></name><name><surname>Haak</surname> <given-names>W</given-names></name><name><surname>Harney</surname> <given-names>E</given-names></name><name><surname>Jones</surname> <given-names>E</given-names></name><name><surname>Keating</surname> <given-names>D</given-names></name><name><surname>Krause-Kyora</surname> <given-names>B</given-names></name><name><surname>Kucukkalipci</surname> <given-names>I</given-names></name><name><surname>Michel</surname> <given-names>M</given-names></name><name><surname>Mittnik</surname> <given-names>A</given-names></name><name><surname>Nägele</surname> <given-names>K</given-names></name><name><surname>Novak</surname> <given-names>M</given-names></name><name><surname>Oppenheimer</surname> <given-names>J</given-names></name><name><surname>Patterson</surname> <given-names>N</given-names></name><name><surname>Pfrengle</surname> <given-names>S</given-names></name><name><surname>Sirak</surname> <given-names>K</given-names></name><name><surname>Stewardson</surname> <given-names>K</given-names></name><name><surname>Vai</surname> <given-names>S</given-names></name><name><surname>Alexandrov</surname> <given-names>S</given-names></name><name><surname>Alt</surname> <given-names>KW</given-names></name><name><surname>Andreescu</surname> <given-names>R</given-names></name><name><surname>Antonović</surname> <given-names>D</given-names></name><name><surname>Ash</surname> <given-names>A</given-names></name><name><surname>Atanassova</surname> <given-names>N</given-names></name><name><surname>Bacvarov</surname> <given-names>K</given-names></name><name><surname>Gusztáv</surname> <given-names>MB</given-names></name><name><surname>Bocherens</surname> <given-names>H</given-names></name><name><surname>Bolus</surname> <given-names>M</given-names></name><name><surname>Boroneanţ</surname> <given-names>A</given-names></name><name><surname>Boyadzhiev</surname> <given-names>Y</given-names></name><name><surname>Budnik</surname> <given-names>A</given-names></name><name><surname>Burmaz</surname> <given-names>J</given-names></name><name><surname>Chohadzhiev</surname> <given-names>S</given-names></name><name><surname>Conard</surname> <given-names>NJ</given-names></name><name><surname>Cottiaux</surname> <given-names>R</given-names></name><name><surname>Čuka</surname> <given-names>M</given-names></name><name><surname>Cupillard</surname> <given-names>C</given-names></name><name><surname>Drucker</surname> <given-names>DG</given-names></name><name><surname>Elenski</surname> <given-names>N</given-names></name><name><surname>Francken</surname> <given-names>M</given-names></name><name><surname>Galabova</surname> <given-names>B</given-names></name><name><surname>Ganetsovski</surname> <given-names>G</given-names></name><name><surname>Gély</surname> <given-names>B</given-names></name><name><surname>Hajdu</surname> <given-names>T</given-names></name><name><surname>Handzhyiska</surname> <given-names>V</given-names></name><name><surname>Harvati</surname> <given-names>K</given-names></name><name><surname>Higham</surname> <given-names>T</given-names></name><name><surname>Iliev</surname> <given-names>S</given-names></name><name><surname>Janković</surname> <given-names>I</given-names></name><name><surname>Karavanić</surname> <given-names>I</given-names></name><name><surname>Kennett</surname> <given-names>DJ</given-names></name><name><surname>Komšo</surname> <given-names>D</given-names></name><name><surname>Kozak</surname> <given-names>A</given-names></name><name><surname>Labuda</surname> <given-names>D</given-names></name><name><surname>Lari</surname> <given-names>M</given-names></name><name><surname>Lazar</surname> <given-names>C</given-names></name><name><surname>Leppek</surname> <given-names>M</given-names></name><name><surname>Leshtakov</surname> <given-names>K</given-names></name><name><surname>Vetro</surname> <given-names>DL</given-names></name><name><surname>Los</surname> <given-names>D</given-names></name><name><surname>Lozanov</surname> <given-names>I</given-names></name><name><surname>Malina</surname> <given-names>M</given-names></name><name><surname>Martini</surname> <given-names>F</given-names></name><name><surname>McSweeney</surname> <given-names>K</given-names></name><name><surname>Meller</surname> <given-names>H</given-names></name><name><surname>Menđušić</surname> <given-names>M</given-names></name><name><surname>Mirea</surname> <given-names>P</given-names></name><name><surname>Moiseyev</surname> <given-names>V</given-names></name><name><surname>Petrova</surname> <given-names>V</given-names></name><name><surname>Price</surname> <given-names>TD</given-names></name><name><surname>Simalcsik</surname> <given-names>A</given-names></name><name><surname>Sineo</surname> <given-names>L</given-names></name><name><surname>Šlaus</surname> <given-names>M</given-names></name><name><surname>Slavchev</surname> <given-names>V</given-names></name><name><surname>Stanev</surname> <given-names>P</given-names></name><name><surname>Starović</surname> <given-names>A</given-names></name><name><surname>Szeniczey</surname> <given-names>T</given-names></name><name><surname>Talamo</surname> <given-names>S</given-names></name><name><surname>Teschler-Nicola</surname> <given-names>M</given-names></name><name><surname>Thevenet</surname> <given-names>C</given-names></name><name><surname>Valchev</surname> <given-names>I</given-names></name><name><surname>Valentin</surname> <given-names>F</given-names></name><name><surname>Vasilyev</surname> <given-names>S</given-names></name><name><surname>Veljanovska</surname> <given-names>F</given-names></name><name><surname>Venelinova</surname> <given-names>S</given-names></name><name><surname>Veselovskaya</surname> <given-names>E</given-names></name><name><surname>Viola</surname> <given-names>B</given-names></name><name><surname>Virag</surname> <given-names>C</given-names></name><name><surname>Zaninović</surname> <given-names>J</given-names></name><name><surname>Zäuner</surname> <given-names>S</given-names></name><name><surname>Stockhammer</surname> <given-names>PW</given-names></name><name><surname>Catalano</surname> <given-names>G</given-names></name><name><surname>Krauß</surname> <given-names>R</given-names></name><name><surname>Caramelli</surname> <given-names>D</given-names></name><name><surname>Zariņa</surname> <given-names>G</given-names></name><name><surname>Gaydarska</surname> <given-names>B</given-names></name><name><surname>Lillie</surname> <given-names>M</given-names></name><name><surname>Nikitin</surname> <given-names>AG</given-names></name><name><surname>Potekhina</surname> <given-names>I</given-names></name><name><surname>Papathanasiou</surname> <given-names>A</given-names></name><name><surname>Borić</surname> <given-names>D</given-names></name><name><surname>Bonsall</surname> <given-names>C</given-names></name><name><surname>Krause</surname> <given-names>J</given-names></name><name><surname>Pinhasi</surname> <given-names>R</given-names></name><name><surname>Reich</surname> <given-names>D</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>The genomic history of southeastern Europe</article-title><source>Nature</source><volume>555</volume><fpage>197</fpage><lpage>203</lpage><pub-id pub-id-type="doi">10.1038/nature25778</pub-id><pub-id pub-id-type="pmid">29466330</pub-id></element-citation></ref><ref id="bib32"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>McCullagh</surname> <given-names>P</given-names></name></person-group><year iso-8601-date="2009">2009</year><article-title>Marginal likelihood for distance matrices</article-title><source>Statistica Sinica</source><volume>19</volume><fpage>631</fpage><lpage>649</lpage></element-citation></ref><ref id="bib33"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>McRae</surname> <given-names>BH</given-names></name></person-group><year iso-8601-date="2006">2006</year><article-title>Isolation by resistance</article-title><source>Evolution</source><volume>60</volume><fpage>1551</fpage><lpage>1561</lpage><pub-id pub-id-type="doi">10.1554/05-321.1</pub-id></element-citation></ref><ref id="bib34"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Meirmans</surname> <given-names>PG</given-names></name></person-group><year iso-8601-date="2012">2012</year><article-title>The trouble with isolation by distance</article-title><source>Molecular Ecology</source><volume>21</volume><fpage>2839</fpage><lpage>2846</lpage><pub-id pub-id-type="doi">10.1111/j.1365-294X.2012.05578.x</pub-id><pub-id pub-id-type="pmid">22574758</pub-id></element-citation></ref><ref id="bib35"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Musiani</surname> <given-names>M</given-names></name><name><surname>Leonard</surname> <given-names>JA</given-names></name><name><surname>Cluff</surname> <given-names>HD</given-names></name><name><surname>Gates</surname> <given-names>CC</given-names></name><name><surname>Mariani</surname> <given-names>S</given-names></name><name><surname>Paquet</surname> <given-names>PC</given-names></name><name><surname>Vilà</surname> <given-names>C</given-names></name><name><surname>Wayne</surname> <given-names>RK</given-names></name></person-group><year iso-8601-date="2007">2007</year><article-title>Differentiation of tundra/taiga and boreal coniferous forest wolves: genetics, coat colour and association with migratory caribou</article-title><source>Molecular Ecology</source><volume>16</volume><fpage>4149</fpage><lpage>4170</lpage><pub-id pub-id-type="doi">10.1111/j.1365-294X.2007.03458.x</pub-id><pub-id pub-id-type="pmid">17725575</pub-id></element-citation></ref><ref id="bib36"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Nocedal</surname> <given-names>J</given-names></name><name><surname>Wright</surname> <given-names>S</given-names></name></person-group><year iso-8601-date="2006">2006</year><source>Numerical Optimization</source><publisher-name>Springer Science &amp; Business Media</publisher-name></element-citation></ref><ref id="bib37"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Novembre</surname> <given-names>J</given-names></name><name><surname>Peter</surname> <given-names>BM</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Recent advances in the study of fine-scale population structure in humans</article-title><source>Current Opinion in Genetics &amp; Development</source><volume>41</volume><fpage>98</fpage><lpage>105</lpage><pub-id pub-id-type="doi">10.1016/j.gde.2016.08.007</pub-id><pub-id pub-id-type="pmid">27662060</pub-id></element-citation></ref><ref id="bib38"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Patterson</surname> <given-names>N</given-names></name><name><surname>Price</surname> <given-names>AL</given-names></name><name><surname>Reich</surname> <given-names>D</given-names></name></person-group><year iso-8601-date="2006">2006</year><article-title>Population structure and eigenanalysis</article-title><source>PLOS Genetics</source><volume>2</volume><elocation-id>e190</elocation-id><pub-id pub-id-type="doi">10.1371/journal.pgen.0020190</pub-id><pub-id pub-id-type="pmid">17194218</pub-id></element-citation></ref><ref id="bib39"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Patterson</surname> <given-names>N</given-names></name><name><surname>Moorjani</surname> <given-names>P</given-names></name><name><surname>Luo</surname> <given-names>Y</given-names></name><name><surname>Mallick</surname> <given-names>S</given-names></name><name><surname>Rohland</surname> <given-names>N</given-names></name><name><surname>Zhan</surname> <given-names>Y</given-names></name><name><surname>Genschoreck</surname> <given-names>T</given-names></name><name><surname>Webster</surname> <given-names>T</given-names></name><name><surname>Reich</surname> <given-names>D</given-names></name></person-group><year iso-8601-date="2012">2012</year><article-title>Ancient admixture in human history</article-title><source>Genetics</source><volume>192</volume><fpage>1065</fpage><lpage>1093</lpage><pub-id pub-id-type="doi">10.1534/genetics.112.145037</pub-id><pub-id pub-id-type="pmid">22960212</pub-id></element-citation></ref><ref id="bib40"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Peter</surname> <given-names>BM</given-names></name><name><surname>Petkova</surname> <given-names>D</given-names></name><name><surname>Novembre</surname> <given-names>J</given-names></name></person-group><year iso-8601-date="2020">2020</year><article-title>Genetic landscapes reveal how human genetic diversity aligns with geography</article-title><source>Molecular Biology and Evolution</source><volume>37</volume><fpage>943</fpage><lpage>951</lpage><pub-id pub-id-type="doi">10.1093/molbev/msz280</pub-id><pub-id pub-id-type="pmid">31778174</pub-id></element-citation></ref><ref id="bib41"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Petkova</surname> <given-names>D</given-names></name></person-group><year iso-8601-date="2013">2013</year><source>Inferring Effective Migration From Geographically Indexed Genetic Data</source><publisher-loc>Chicago, United States</publisher-loc><publisher-name>The University of Chicago Press</publisher-name></element-citation></ref><ref id="bib42"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Petkova</surname> <given-names>D</given-names></name><name><surname>Novembre</surname> <given-names>J</given-names></name><name><surname>Stephens</surname> <given-names>M</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Visualizing spatial population structure with estimated effective migration surfaces</article-title><source>Nature Genetics</source><volume>48</volume><fpage>94</fpage><lpage>100</lpage><pub-id pub-id-type="doi">10.1038/ng.3464</pub-id><pub-id pub-id-type="pmid">26642242</pub-id></element-citation></ref><ref id="bib43"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Pickrell</surname> <given-names>JK</given-names></name><name><surname>Pritchard</surname> <given-names>JK</given-names></name></person-group><year iso-8601-date="2012">2012</year><article-title>Inference of population splits and mixtures from genome-wide allele frequency data</article-title><source>PLOS Genetics</source><volume>8</volume><elocation-id>e1002967</elocation-id><pub-id pub-id-type="doi">10.1371/journal.pgen.1002967</pub-id><pub-id pub-id-type="pmid">23166502</pub-id></element-citation></ref><ref id="bib44"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Pickrell</surname> <given-names>JK</given-names></name><name><surname>Reich</surname> <given-names>D</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>Toward a new history and geography of human genes informed by ancient DNA</article-title><source>Trends in Genetics</source><volume>30</volume><fpage>377</fpage><lpage>389</lpage><pub-id pub-id-type="doi">10.1016/j.tig.2014.07.007</pub-id><pub-id pub-id-type="pmid">25168683</pub-id></element-citation></ref><ref id="bib45"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Price</surname> <given-names>AL</given-names></name><name><surname>Patterson</surname> <given-names>NJ</given-names></name><name><surname>Plenge</surname> <given-names>RM</given-names></name><name><surname>Weinblatt</surname> <given-names>ME</given-names></name><name><surname>Shadick</surname> <given-names>NA</given-names></name><name><surname>Reich</surname> <given-names>D</given-names></name></person-group><year iso-8601-date="2006">2006</year><article-title>Principal components analysis corrects for stratification in genome-wide association studies</article-title><source>Nature Genetics</source><volume>38</volume><fpage>904</fpage><lpage>909</lpage><pub-id pub-id-type="doi">10.1038/ng1847</pub-id><pub-id pub-id-type="pmid">16862161</pub-id></element-citation></ref><ref id="bib46"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Pritchard</surname> <given-names>JK</given-names></name><name><surname>Stephens</surname> <given-names>M</given-names></name><name><surname>Donnelly</surname> <given-names>P</given-names></name></person-group><year iso-8601-date="2000">2000</year><article-title>Inference of population structure using multilocus genotype data</article-title><source>Genetics</source><volume>155</volume><fpage>945</fpage><lpage>959</lpage><pub-id pub-id-type="doi">10.1093/genetics/155.2.945</pub-id><pub-id pub-id-type="pmid">10835412</pub-id></element-citation></ref><ref id="bib47"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ringbauer</surname> <given-names>H</given-names></name><name><surname>Kolesnikov</surname> <given-names>A</given-names></name><name><surname>Field</surname> <given-names>DL</given-names></name><name><surname>Barton</surname> <given-names>NH</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>Estimating barriers to gene flow from distorted Isolation-by-Distance patterns</article-title><source>Genetics</source><volume>208</volume><fpage>1231</fpage><lpage>1245</lpage><pub-id pub-id-type="doi">10.1534/genetics.117.300638</pub-id><pub-id pub-id-type="pmid">29311149</pub-id></element-citation></ref><ref id="bib48"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Rue</surname> <given-names>H</given-names></name><name><surname>Held</surname> <given-names>L</given-names></name></person-group><year iso-8601-date="2005">2005</year><source>Gaussian Markov Random Fields: Theory and Applications</source><publisher-name>CRC press</publisher-name></element-citation></ref><ref id="bib49"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Safner</surname> <given-names>T</given-names></name><name><surname>Miller</surname> <given-names>MP</given-names></name><name><surname>McRae</surname> <given-names>BH</given-names></name><name><surname>Fortin</surname> <given-names>MJ</given-names></name><name><surname>Manel</surname> <given-names>S</given-names></name></person-group><year iso-8601-date="2011">2011</year><article-title>Comparison of Bayesian clustering and edge detection methods for inferring boundaries in landscape genetics</article-title><source>International Journal of Molecular Sciences</source><volume>12</volume><fpage>865</fpage><lpage>889</lpage><pub-id pub-id-type="doi">10.3390/ijms12020865</pub-id><pub-id pub-id-type="pmid">21541031</pub-id></element-citation></ref><ref id="bib50"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Sahr</surname> <given-names>K</given-names></name><name><surname>White</surname> <given-names>D</given-names></name><name><surname>Kimerling</surname> <given-names>AJ</given-names></name></person-group><year iso-8601-date="2003">2003</year><article-title>Geodesic discrete global grid systems</article-title><source>Cartography and Geographic Information Science</source><volume>30</volume><fpage>121</fpage><lpage>134</lpage><pub-id pub-id-type="doi">10.1559/152304003100011090</pub-id></element-citation></ref><ref id="bib51"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Schweizer</surname> <given-names>RM</given-names></name><name><surname>vonHoldt</surname> <given-names>BM</given-names></name><name><surname>Harrigan</surname> <given-names>R</given-names></name><name><surname>Knowles</surname> <given-names>JC</given-names></name><name><surname>Musiani</surname> <given-names>M</given-names></name><name><surname>Coltman</surname> <given-names>D</given-names></name><name><surname>Novembre</surname> <given-names>J</given-names></name><name><surname>Wayne</surname> <given-names>RK</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Genetic subdivision and candidate genes under selection in North American grey wolves</article-title><source>Molecular Ecology</source><volume>25</volume><fpage>380</fpage><lpage>402</lpage><pub-id pub-id-type="doi">10.1111/mec.13364</pub-id><pub-id pub-id-type="pmid">26333947</pub-id></element-citation></ref><ref id="bib52"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Slatkin</surname> <given-names>M</given-names></name></person-group><year iso-8601-date="1985">1985</year><article-title>Gene flow in natural populations</article-title><source>Annual Review of Ecology and Systematics</source><volume>16</volume><fpage>393</fpage><lpage>430</lpage><pub-id pub-id-type="doi">10.1146/annurev.es.16.110185.002141</pub-id></element-citation></ref><ref id="bib53"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Virtanen</surname> <given-names>P</given-names></name><name><surname>Gommers</surname> <given-names>R</given-names></name><name><surname>Oliphant</surname> <given-names>TE</given-names></name><name><surname>Haberland</surname> <given-names>M</given-names></name><name><surname>Reddy</surname> <given-names>T</given-names></name><name><surname>Cournapeau</surname> <given-names>D</given-names></name><name><surname>Burovski</surname> <given-names>E</given-names></name><name><surname>Peterson</surname> <given-names>P</given-names></name><name><surname>Weckesser</surname> <given-names>W</given-names></name><name><surname>Bright</surname> <given-names>J</given-names></name><name><surname>van der Walt</surname> <given-names>SJ</given-names></name><name><surname>Brett</surname> <given-names>M</given-names></name><name><surname>Wilson</surname> <given-names>J</given-names></name><name><surname>Millman</surname> <given-names>KJ</given-names></name><name><surname>Mayorov</surname> <given-names>N</given-names></name><name><surname>Nelson</surname> <given-names>ARJ</given-names></name><name><surname>Jones</surname> <given-names>E</given-names></name><name><surname>Kern</surname> <given-names>R</given-names></name><name><surname>Larson</surname> <given-names>E</given-names></name><name><surname>Carey</surname> <given-names>CJ</given-names></name><name><surname>Polat</surname> <given-names>İ</given-names></name><name><surname>Feng</surname> <given-names>Y</given-names></name><name><surname>Moore</surname> <given-names>EW</given-names></name><name><surname>VanderPlas</surname> <given-names>J</given-names></name><name><surname>Laxalde</surname> <given-names>D</given-names></name><name><surname>Perktold</surname> <given-names>J</given-names></name><name><surname>Cimrman</surname> <given-names>R</given-names></name><name><surname>Henriksen</surname> <given-names>I</given-names></name><name><surname>Quintero</surname> <given-names>EA</given-names></name><name><surname>Harris</surname> <given-names>CR</given-names></name><name><surname>Archibald</surname> <given-names>AM</given-names></name><name><surname>Ribeiro</surname> <given-names>AH</given-names></name><name><surname>Pedregosa</surname> <given-names>F</given-names></name><name><surname>van Mulbregt</surname> <given-names>P</given-names></name><collab>SciPy 1.0 Contributors</collab></person-group><year iso-8601-date="2020">2020</year><article-title>SciPy 1.0: fundamental algorithms for scientific computing in Python</article-title><source>Nature Methods</source><volume>17</volume><fpage>261</fpage><lpage>272</lpage><pub-id pub-id-type="doi">10.1038/s41592-019-0686-2</pub-id><pub-id pub-id-type="pmid">32015543</pub-id></element-citation></ref><ref id="bib54"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Vishnoi</surname> <given-names>NK</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>Lx = b</article-title><source>Foundations and Trends in Theoretical Computer Science</source><volume>8</volume><fpage>1</fpage><lpage>141</lpage><pub-id pub-id-type="doi">10.1561/0400000054</pub-id></element-citation></ref><ref id="bib55"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wang</surname> <given-names>Y-X</given-names></name><name><surname>Sharpnack</surname> <given-names>J</given-names></name><name><surname>Smola</surname> <given-names>AJ</given-names></name><name><surname>Tibshirani</surname> <given-names>RJ</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Trend filtering on graphs</article-title><source>The Journal of Machine Learning Research</source><volume>17</volume><fpage>3651</fpage><lpage>3691</lpage></element-citation></ref><ref id="bib56"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wright</surname> <given-names>S</given-names></name></person-group><year iso-8601-date="1943">1943</year><article-title>Isolation by distance</article-title><source>Genetics</source><volume>28</volume><fpage>114</fpage><lpage>138</lpage><pub-id pub-id-type="doi">10.1093/genetics/28.2.114</pub-id><pub-id pub-id-type="pmid">17247074</pub-id></element-citation></ref><ref id="bib57"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wright</surname> <given-names>S</given-names></name></person-group><year iso-8601-date="1946">1946</year><article-title>Isolation by distance under diverse systems of mating</article-title><source>Genetics</source><volume>31</volume><fpage>39</fpage><lpage>59</lpage><pub-id pub-id-type="doi">10.1093/genetics/31.1.39</pub-id><pub-id pub-id-type="pmid">21009706</pub-id></element-citation></ref><ref id="bib58"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Zou</surname> <given-names>H</given-names></name><name><surname>Hastie</surname> <given-names>T</given-names></name></person-group><year iso-8601-date="2005">2005</year><article-title>Regularization and variable selection via the elastic net</article-title><source>Journal of the Royal Statistical Society: Series B</source><volume>67</volume><fpage>301</fpage><lpage>320</lpage><pub-id pub-id-type="doi">10.1111/j.1467-9868.2005.00503.x</pub-id></element-citation></ref></ref-list><app-group><app id="appendix-1"><title>Appendix 1</title><boxed-text><sec id="s8" sec-type="appendix"><title>Mathematical notation</title><p>We denote matrices using bold capital letters <inline-formula><mml:math id="inf227"><mml:mi mathsize="80%" mathvariant="bold-italic">𝑨</mml:mi></mml:math></inline-formula>. Bold lowercase letters are vectors <inline-formula><mml:math id="inf228"><mml:mi mathsize="80%" mathvariant="bold-italic">𝒂</mml:mi></mml:math></inline-formula>, and non-bold lowercase letters are scalars <inline-formula><mml:math id="inf229"><mml:mi mathsize="80%">a</mml:mi></mml:math></inline-formula>. We denote by <inline-formula><mml:math id="inf230"><mml:msup><mml:mi mathsize="80%" mathvariant="bold-italic">𝑨</mml:mi><mml:mrow><mml:mo mathsize="80%" stretchy="false">-</mml:mo><mml:mn mathsize="80%">1</mml:mn></mml:mrow></mml:msup></mml:math></inline-formula> and <inline-formula><mml:math id="inf231"><mml:msup><mml:mi mathsize="80%" mathvariant="bold-italic">𝑨</mml:mi><mml:mo mathsize="80%" stretchy="false">†</mml:mo></mml:msup></mml:math></inline-formula> the inverse and (Moore-Penrose) pseudo-inverse of <inline-formula><mml:math id="inf232"><mml:mi mathsize="80%" mathvariant="bold-italic">𝑨</mml:mi></mml:math></inline-formula>, respectively. We use <inline-formula><mml:math id="inf233"><mml:mrow><mml:mi mathsize="80%" mathvariant="bold-italic">𝒚</mml:mi><mml:mo mathsize="80%" stretchy="false">∼</mml:mo><mml:mrow><mml:msub><mml:mi mathsize="80%">N</mml:mi><mml:mi mathsize="80%">p</mml:mi></mml:msub><mml:mo>⁢</mml:mo><mml:mrow><mml:mo maxsize="80%" minsize="80%">(</mml:mo><mml:mi mathsize="80%" mathvariant="bold-italic">𝝁</mml:mi><mml:mo mathsize="80%" stretchy="false">,</mml:mo><mml:mi mathsize="80%" mathvariant="bold">𝚺</mml:mi><mml:mo maxsize="80%" minsize="80%">)</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:math></inline-formula> to express that the random vector <inline-formula><mml:math id="inf234"><mml:mi mathsize="80%" mathvariant="bold-italic">𝒚</mml:mi></mml:math></inline-formula> is modeled as a <inline-formula><mml:math id="inf235"><mml:mi mathsize="80%">p</mml:mi></mml:math></inline-formula>-dimensional multivariate Gaussian distribution with fixed parameters <inline-formula><mml:math id="inf236"><mml:mi mathsize="80%" mathvariant="bold-italic">𝝁</mml:mi></mml:math></inline-formula> and <inline-formula><mml:math id="inf237"><mml:mi mathsize="80%" mathvariant="bold">𝚺</mml:mi></mml:math></inline-formula> and use the conditional notation <inline-formula><mml:math id="inf238"><mml:mrow><mml:mrow><mml:mi mathsize="80%" mathvariant="bold-italic">𝒚</mml:mi><mml:mo lspace="2.5pt" mathsize="80%" rspace="2.5pt" stretchy="false">|</mml:mo><mml:mi mathsize="80%" mathvariant="bold-italic">𝝁</mml:mi></mml:mrow><mml:mo mathsize="80%" stretchy="false">∼</mml:mo><mml:mrow><mml:msub><mml:mi mathsize="80%">N</mml:mi><mml:mi mathsize="80%">p</mml:mi></mml:msub><mml:mo>⁢</mml:mo><mml:mrow><mml:mo maxsize="80%" minsize="80%">(</mml:mo><mml:mi mathsize="80%" mathvariant="bold-italic">𝝁</mml:mi><mml:mo mathsize="80%" stretchy="false">,</mml:mo><mml:mi mathsize="80%" mathvariant="bold">𝚺</mml:mi><mml:mo maxsize="80%" minsize="80%">)</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:math></inline-formula> if <inline-formula><mml:math id="inf239"><mml:mi mathsize="80%" mathvariant="bold-italic">𝝁</mml:mi></mml:math></inline-formula> is random.</p><p>A graph is a pair <inline-formula><mml:math id="inf240"><mml:mrow><mml:mi class="ltx_font_mathcaligraphic" mathsize="80%">𝒢</mml:mi><mml:mo mathsize="80%" stretchy="false">=</mml:mo><mml:mrow><mml:mo maxsize="80%" minsize="80%">(</mml:mo><mml:mi class="ltx_font_mathcaligraphic" mathsize="80%">𝒱</mml:mi><mml:mo mathsize="80%" stretchy="false">,</mml:mo><mml:mi class="ltx_font_mathcaligraphic" mathsize="80%">ℰ</mml:mi><mml:mo maxsize="80%" minsize="80%">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula>, where <inline-formula><mml:math id="inf241"><mml:mi class="ltx_font_mathcaligraphic" mathsize="80%">𝒱</mml:mi></mml:math></inline-formula> denotes a set of nodes or vertices and <inline-formula><mml:math id="inf242"><mml:mrow><mml:mi class="ltx_font_mathcaligraphic" mathsize="80%">ℰ</mml:mi><mml:mo mathsize="80%" stretchy="false">⊆</mml:mo><mml:mrow><mml:mi class="ltx_font_mathcaligraphic" mathsize="80%">𝒱</mml:mi><mml:mo mathsize="80%" stretchy="false">×</mml:mo><mml:mi class="ltx_font_mathcaligraphic" mathsize="80%">𝒱</mml:mi></mml:mrow></mml:mrow></mml:math></inline-formula> denotes a set of edges. Throughout we assume the graph <inline-formula><mml:math id="inf243"><mml:mi class="ltx_font_mathcaligraphic" mathsize="80%">𝒢</mml:mi></mml:math></inline-formula> is undirected, weighted, and contains no self loops, that is, <inline-formula><mml:math id="inf244"><mml:mrow><mml:mrow><mml:mrow><mml:mo maxsize="80%" minsize="80%">(</mml:mo><mml:mi mathsize="80%">k</mml:mi><mml:mo mathsize="80%" stretchy="false">,</mml:mo><mml:mi mathsize="80%" mathvariant="normal">ℓ</mml:mi><mml:mo maxsize="80%" minsize="80%">)</mml:mo></mml:mrow><mml:mo mathsize="80%" stretchy="false">∈</mml:mo><mml:mi class="ltx_font_mathcaligraphic" mathsize="80%">ℰ</mml:mi></mml:mrow><mml:mo mathsize="80%" stretchy="false">⇔</mml:mo><mml:mrow><mml:mrow><mml:mo maxsize="80%" minsize="80%">(</mml:mo><mml:mi mathsize="80%" mathvariant="normal">ℓ</mml:mi><mml:mo mathsize="80%" stretchy="false">,</mml:mo><mml:mi mathsize="80%">k</mml:mi><mml:mo maxsize="80%" minsize="80%">)</mml:mo></mml:mrow><mml:mo mathsize="80%" stretchy="false">∈</mml:mo><mml:mi class="ltx_font_mathcaligraphic" mathsize="80%">ℰ</mml:mi></mml:mrow></mml:mrow></mml:math></inline-formula> and <inline-formula><mml:math id="inf245"><mml:mrow><mml:mrow><mml:mo maxsize="80%" minsize="80%">(</mml:mo><mml:mi mathsize="80%">k</mml:mi><mml:mo mathsize="80%" stretchy="false">,</mml:mo><mml:mi mathsize="80%">k</mml:mi><mml:mo maxsize="80%" minsize="80%">)</mml:mo></mml:mrow><mml:mo mathsize="80%" stretchy="false">∉</mml:mo><mml:mi class="ltx_font_mathcaligraphic" mathsize="80%">ℰ</mml:mi></mml:mrow></mml:math></inline-formula> and each edge <inline-formula><mml:math id="inf246"><mml:mrow><mml:mrow><mml:mo maxsize="80%" minsize="80%">(</mml:mo><mml:mi mathsize="80%">k</mml:mi><mml:mo mathsize="80%" stretchy="false">,</mml:mo><mml:mi mathsize="80%" mathvariant="normal">ℓ</mml:mi><mml:mo maxsize="80%" minsize="80%">)</mml:mo></mml:mrow><mml:mo mathsize="80%" stretchy="false">∈</mml:mo><mml:mi class="ltx_font_mathcaligraphic" mathsize="80%">ℰ</mml:mi></mml:mrow></mml:math></inline-formula> is given a weight <inline-formula><mml:math id="inf247"><mml:mrow><mml:msub><mml:mi mathsize="80%">w</mml:mi><mml:mrow><mml:mi mathsize="80%">k</mml:mi><mml:mo>⁢</mml:mo><mml:mi mathsize="80%" mathvariant="normal">ℓ</mml:mi></mml:mrow></mml:msub><mml:mo mathsize="80%" stretchy="false">=</mml:mo><mml:msub><mml:mi mathsize="80%">w</mml:mi><mml:mrow><mml:mi mathsize="80%" mathvariant="normal">ℓ</mml:mi><mml:mo>⁢</mml:mo><mml:mi mathsize="80%">k</mml:mi></mml:mrow></mml:msub><mml:mo mathsize="80%" stretchy="false">&gt;</mml:mo><mml:mn mathsize="80%">0</mml:mn></mml:mrow></mml:math></inline-formula>. We write <inline-formula><mml:math id="inf248"><mml:mi mathsize="80%" mathvariant="bold-italic">𝑾</mml:mi></mml:math></inline-formula> to indicate the symmetric weighted adjacency matrix, that is,<disp-formula id="equ24"><mml:math id="m24"><mml:mrow><mml:msub><mml:mi mathsize="80%">𝑾</mml:mi><mml:mrow><mml:mi mathsize="80%">k</mml:mi><mml:mo>⁢</mml:mo><mml:mi mathsize="80%" mathvariant="normal">ℓ</mml:mi></mml:mrow></mml:msub><mml:mo mathsize="80%" stretchy="false">=</mml:mo><mml:mrow><mml:mo>{</mml:mo><mml:mtable columnspacing="5pt" displaystyle="true" rowspacing="0pt"><mml:mtr><mml:mtd columnalign="left"><mml:mrow><mml:msub><mml:mi mathsize="80%">w</mml:mi><mml:mrow><mml:mi mathsize="80%">k</mml:mi><mml:mo>⁢</mml:mo><mml:mi mathsize="80%" mathvariant="normal">ℓ</mml:mi></mml:mrow></mml:msub><mml:mo mathsize="80%" stretchy="false">,</mml:mo></mml:mrow></mml:mtd><mml:mtd columnalign="left"><mml:mrow><mml:mtext mathsize="80%">if </mml:mtext><mml:mrow><mml:mrow><mml:mo maxsize="80%" minsize="80%">(</mml:mo><mml:mi mathsize="80%">k</mml:mi><mml:mo mathsize="80%" stretchy="false">,</mml:mo><mml:mi mathsize="80%" mathvariant="normal">ℓ</mml:mi><mml:mo maxsize="80%" minsize="80%">)</mml:mo></mml:mrow><mml:mo mathsize="80%" stretchy="false">∈</mml:mo><mml:mi class="ltx_font_mathcaligraphic" mathsize="80%">ℰ</mml:mi></mml:mrow><mml:mtext mathsize="80%">,</mml:mtext></mml:mrow></mml:mtd></mml:mtr><mml:mtr><mml:mtd columnalign="left"><mml:mrow><mml:mn mathsize="80%">0</mml:mn><mml:mo mathsize="80%" stretchy="false">,</mml:mo></mml:mrow></mml:mtd><mml:mtd columnalign="left"><mml:mtext mathsize="80%">otherwise.</mml:mtext></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:mrow></mml:math></disp-formula></p><p><inline-formula><mml:math id="inf249"><mml:mrow><mml:mi mathsize="80%" mathvariant="bold-italic">𝒘</mml:mi><mml:mo mathsize="80%" stretchy="false">∈</mml:mo><mml:msup><mml:mi mathsize="80%">ℝ</mml:mi><mml:mi mathsize="80%">m</mml:mi></mml:msup></mml:mrow></mml:math></inline-formula> is a vectorized form of the non-zero lower-triangular entries of <inline-formula><mml:math id="inf250"><mml:mi mathsize="80%" mathvariant="bold-italic">𝑾</mml:mi></mml:math></inline-formula> where <inline-formula><mml:math id="inf251"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>m</mml:mi><mml:mo>=</mml:mo><mml:mrow><mml:mo>|</mml:mo><mml:mrow><mml:mi mathvariant="script">ℰ</mml:mi></mml:mrow><mml:mo>|</mml:mo></mml:mrow><mml:mrow><mml:mo>/</mml:mo></mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:mstyle></mml:math></inline-formula> is the number of non-zero lower triangular elements. We denote by <inline-formula><mml:math id="inf252"><mml:mrow><mml:mi mathsize="80%" mathvariant="bold-italic">𝑳</mml:mi><mml:mo mathsize="80%" stretchy="false">=</mml:mo><mml:mrow><mml:mrow><mml:mtext mathsize="80%">diag</mml:mtext><mml:mo>⁢</mml:mo><mml:mrow><mml:mo maxsize="80%" minsize="80%">(</mml:mo><mml:mrow><mml:mi mathsize="80%" mathvariant="bold-italic">𝑾</mml:mi><mml:mo>⁢</mml:mo><mml:mn mathsize="80%">𝟏</mml:mn></mml:mrow><mml:mo maxsize="80%" minsize="80%">)</mml:mo></mml:mrow></mml:mrow><mml:mo mathsize="80%" stretchy="false">-</mml:mo><mml:mi mathsize="80%" mathvariant="bold-italic">𝑾</mml:mi></mml:mrow></mml:mrow></mml:math></inline-formula> the graph Laplacian.</p></sec><sec id="s9" sec-type="appendix"><title>Gradient computation</title><p>In practice, we make a change of variable from <inline-formula><mml:math id="inf253"><mml:mrow><mml:mi mathsize="80%" mathvariant="bold-italic">𝒘</mml:mi><mml:mo mathsize="80%" stretchy="false">∈</mml:mo><mml:msubsup><mml:mi mathsize="80%">ℝ</mml:mi><mml:mo mathsize="80%" stretchy="false">+</mml:mo><mml:mi mathsize="80%">m</mml:mi></mml:msubsup></mml:mrow></mml:math></inline-formula> to <inline-formula><mml:math id="inf254"><mml:mrow><mml:mi mathsize="80%" mathvariant="bold-italic">𝒛</mml:mi><mml:mo mathsize="80%" stretchy="false">=</mml:mo><mml:mrow><mml:mi mathsize="80%">log</mml:mi><mml:mo>⁡</mml:mo><mml:mrow><mml:mo maxsize="80%" minsize="80%">(</mml:mo><mml:mi mathsize="80%" mathvariant="bold-italic">𝒘</mml:mi><mml:mo maxsize="80%" minsize="80%">)</mml:mo></mml:mrow></mml:mrow><mml:mo mathsize="80%" stretchy="false">∈</mml:mo><mml:msup><mml:mi mathsize="80%">ℝ</mml:mi><mml:mi mathsize="80%">m</mml:mi></mml:msup></mml:mrow></mml:math></inline-formula> and the algorithm is applied to the transformed objective function:<disp-formula id="equ25"><mml:math id="m25"><mml:mrow><mml:mrow><mml:mrow><mml:mrow><mml:mi mathsize="80%" mathvariant="normal">ℓ</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo maxsize="80%" minsize="80%">(</mml:mo><mml:mrow><mml:mi mathsize="80%">exp</mml:mi><mml:mo>⁡</mml:mo><mml:mrow><mml:mo maxsize="80%" minsize="80%">(</mml:mo><mml:mi mathsize="80%">𝒛</mml:mi><mml:mo maxsize="80%" minsize="80%">)</mml:mo></mml:mrow></mml:mrow><mml:mo mathsize="80%" stretchy="false">,</mml:mo><mml:msup><mml:mi mathsize="80%">σ</mml:mi><mml:mn mathsize="80%">2</mml:mn></mml:msup><mml:mo mathsize="80%" stretchy="false">;</mml:mo><mml:mrow><mml:mi mathsize="80%">𝑪</mml:mi><mml:mo>⁢</mml:mo><mml:mover accent="true"><mml:mi mathsize="80%">𝚺</mml:mi><mml:mo mathsize="80%" stretchy="false">^</mml:mo></mml:mover><mml:mo>⁢</mml:mo><mml:msup><mml:mi mathsize="80%">𝑪</mml:mi><mml:mo mathsize="80%" stretchy="false">⊤</mml:mo></mml:msup></mml:mrow><mml:mo maxsize="80%" minsize="80%">)</mml:mo></mml:mrow></mml:mrow><mml:mo mathsize="80%" stretchy="false">+</mml:mo><mml:mrow><mml:msub><mml:mi mathsize="80%">ϕ</mml:mi><mml:mrow><mml:mi mathsize="80%">λ</mml:mi><mml:mo mathsize="80%" stretchy="false">,</mml:mo><mml:mi mathsize="80%">α</mml:mi></mml:mrow></mml:msub><mml:mo>⁢</mml:mo><mml:mrow><mml:mo maxsize="80%" minsize="80%">(</mml:mo><mml:mrow><mml:mi mathsize="80%">exp</mml:mi><mml:mo>⁡</mml:mo><mml:mrow><mml:mo maxsize="80%" minsize="80%">(</mml:mo><mml:mi mathsize="80%">𝒛</mml:mi><mml:mo maxsize="80%" minsize="80%">)</mml:mo></mml:mrow></mml:mrow><mml:mo maxsize="80%" minsize="80%">)</mml:mo></mml:mrow></mml:mrow></mml:mrow><mml:mo mathsize="80%" stretchy="false">=</mml:mo><mml:mrow><mml:mrow><mml:mover accent="true"><mml:mi mathsize="80%" mathvariant="normal">ℓ</mml:mi><mml:mo mathsize="80%" stretchy="false">~</mml:mo></mml:mover><mml:mo>⁢</mml:mo><mml:mrow><mml:mo maxsize="80%" minsize="80%">(</mml:mo><mml:mi mathsize="80%">𝒛</mml:mi><mml:mo mathsize="80%" stretchy="false">,</mml:mo><mml:msup><mml:mi mathsize="80%">σ</mml:mi><mml:mn mathsize="80%">2</mml:mn></mml:msup><mml:mo mathsize="80%" stretchy="false">;</mml:mo><mml:mrow><mml:mi mathsize="80%">𝑪</mml:mi><mml:mo>⁢</mml:mo><mml:mover accent="true"><mml:mi mathsize="80%">𝚺</mml:mi><mml:mo mathsize="80%" stretchy="false">^</mml:mo></mml:mover><mml:mo>⁢</mml:mo><mml:msup><mml:mi mathsize="80%">𝑪</mml:mi><mml:mo mathsize="80%" stretchy="false">⊤</mml:mo></mml:msup></mml:mrow><mml:mo maxsize="80%" minsize="80%">)</mml:mo></mml:mrow></mml:mrow><mml:mo mathsize="80%" stretchy="false">+</mml:mo><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi mathsize="80%">ϕ</mml:mi><mml:mo mathsize="80%" stretchy="false">~</mml:mo></mml:mover><mml:mrow><mml:mi mathsize="80%">λ</mml:mi><mml:mo mathsize="80%" stretchy="false">,</mml:mo><mml:mi mathsize="80%">α</mml:mi></mml:mrow></mml:msub><mml:mo>⁢</mml:mo><mml:mrow><mml:mo maxsize="80%" minsize="80%">(</mml:mo><mml:mi mathsize="80%">𝒛</mml:mi><mml:mo maxsize="80%" minsize="80%">)</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:mrow><mml:mo mathsize="80%" stretchy="false">.</mml:mo></mml:mrow></mml:math></disp-formula></p><p>After the change of variable, the objective value remains the same, whereas it follows from the chain rule that <inline-formula><mml:math id="inf255"><mml:mrow><mml:mrow><mml:mo mathsize="80%" stretchy="false">∇</mml:mo><mml:mo>⁡</mml:mo><mml:mrow><mml:mo maxsize="80%" minsize="80%">(</mml:mo><mml:mrow><mml:mrow><mml:mover accent="true"><mml:mi mathsize="80%" mathvariant="normal">ℓ</mml:mi><mml:mo mathsize="80%" stretchy="false">~</mml:mo></mml:mover><mml:mo>⁢</mml:mo><mml:mrow><mml:mo maxsize="80%" minsize="80%">(</mml:mo><mml:mi mathsize="80%" mathvariant="bold-italic">𝒛</mml:mi><mml:mo maxsize="80%" minsize="80%">)</mml:mo></mml:mrow></mml:mrow><mml:mo mathsize="80%" stretchy="false">+</mml:mo><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi mathsize="80%">ϕ</mml:mi><mml:mo mathsize="80%" stretchy="false">~</mml:mo></mml:mover><mml:mrow><mml:mi mathsize="80%">λ</mml:mi><mml:mo mathsize="80%" stretchy="false">,</mml:mo><mml:mi mathsize="80%">α</mml:mi></mml:mrow></mml:msub><mml:mo>⁢</mml:mo><mml:mrow><mml:mo maxsize="80%" minsize="80%">(</mml:mo><mml:mi mathsize="80%" mathvariant="bold-italic">𝒛</mml:mi><mml:mo maxsize="80%" minsize="80%">)</mml:mo></mml:mrow></mml:mrow></mml:mrow><mml:mo maxsize="80%" minsize="80%">)</mml:mo></mml:mrow></mml:mrow><mml:mo mathsize="80%" stretchy="false">=</mml:mo><mml:mrow><mml:mrow><mml:mo mathsize="80%" stretchy="false">∇</mml:mo><mml:mo>⁡</mml:mo><mml:mrow><mml:mo maxsize="80%" minsize="80%">(</mml:mo><mml:mrow><mml:mrow><mml:mi mathsize="80%" mathvariant="normal">ℓ</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo maxsize="80%" minsize="80%">(</mml:mo><mml:mi mathsize="80%" mathvariant="bold-italic">𝒘</mml:mi><mml:mo maxsize="80%" minsize="80%">)</mml:mo></mml:mrow></mml:mrow><mml:mo mathsize="80%" stretchy="false">+</mml:mo><mml:mrow><mml:msub><mml:mi mathsize="80%">ϕ</mml:mi><mml:mrow><mml:mi mathsize="80%">λ</mml:mi><mml:mo mathsize="80%" stretchy="false">,</mml:mo><mml:mi mathsize="80%">α</mml:mi></mml:mrow></mml:msub><mml:mo>⁢</mml:mo><mml:mrow><mml:mo maxsize="80%" minsize="80%">(</mml:mo><mml:mi mathsize="80%" mathvariant="bold-italic">𝒘</mml:mi><mml:mo maxsize="80%" minsize="80%">)</mml:mo></mml:mrow></mml:mrow></mml:mrow><mml:mo maxsize="80%" minsize="80%">)</mml:mo></mml:mrow></mml:mrow><mml:mo mathsize="80%" stretchy="false">⊙</mml:mo><mml:mi mathsize="80%" mathvariant="bold-italic">𝒘</mml:mi></mml:mrow></mml:mrow></mml:math></inline-formula> where <inline-formula><mml:math id="inf256"><mml:mo mathsize="80%" stretchy="false">⊙</mml:mo></mml:math></inline-formula> indicates the Hadamard product or elementwise product—for notational convenience, we drop the dependency of <inline-formula><mml:math id="inf257"><mml:mi mathsize="80%" mathvariant="normal">ℓ</mml:mi></mml:math></inline-formula> on the quantities <inline-formula><mml:math id="inf258"><mml:msup><mml:mi mathsize="80%">σ</mml:mi><mml:mn mathsize="80%">2</mml:mn></mml:msup></mml:math></inline-formula> and <inline-formula><mml:math id="inf259"><mml:mrow><mml:mi mathsize="80%" mathvariant="bold-italic">𝑪</mml:mi><mml:mo>⁢</mml:mo><mml:mover accent="true"><mml:mi mathsize="80%" mathvariant="bold">𝚺</mml:mi><mml:mo mathsize="80%" stretchy="false">^</mml:mo></mml:mover><mml:mo>⁢</mml:mo><mml:msup><mml:mi mathsize="80%" mathvariant="bold-italic">𝑪</mml:mi><mml:mo mathsize="80%" stretchy="false">⊤</mml:mo></mml:msup></mml:mrow></mml:math></inline-formula>. Furthermore, the computation of <inline-formula><mml:math id="inf260"><mml:mrow><mml:mrow><mml:mo mathsize="80%" stretchy="false">∇</mml:mo><mml:mo>⁡</mml:mo><mml:msub><mml:mi mathsize="80%">ϕ</mml:mi><mml:mrow><mml:mi mathsize="80%">λ</mml:mi><mml:mo mathsize="80%" stretchy="false">,</mml:mo><mml:mi mathsize="80%">α</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>⁢</mml:mo><mml:mrow><mml:mo maxsize="80%" minsize="80%">(</mml:mo><mml:mi mathsize="80%" mathvariant="bold-italic">𝒘</mml:mi><mml:mo maxsize="80%" minsize="80%">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> is relatively straightforward, so in the rest of this section, we discuss only the computation of the gradient of the negative log-likelihood function with respect to <inline-formula><mml:math id="inf261"><mml:mi mathsize="80%" mathvariant="bold-italic">𝒘</mml:mi></mml:math></inline-formula>, that is, <inline-formula><mml:math id="inf262"><mml:mrow><mml:mrow><mml:mo mathsize="80%" stretchy="false">∇</mml:mo><mml:mo>⁡</mml:mo><mml:mi mathsize="80%" mathvariant="normal">ℓ</mml:mi></mml:mrow><mml:mo>⁢</mml:mo><mml:mrow><mml:mo maxsize="80%" minsize="80%">(</mml:mo><mml:mi mathsize="80%" mathvariant="bold-italic">𝒘</mml:mi><mml:mo maxsize="80%" minsize="80%">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula>.</p><p>Recall, by definition, the graph Laplacian <inline-formula><mml:math id="inf263"><mml:mi mathsize="80%" mathvariant="bold-italic">𝑳</mml:mi></mml:math></inline-formula> implicitly depends on the variable <inline-formula><mml:math id="inf264"><mml:mi mathsize="80%" mathvariant="bold-italic">𝒘</mml:mi></mml:math></inline-formula> through <inline-formula><mml:math id="inf265"><mml:mrow><mml:mi mathsize="80%" mathvariant="bold-italic">𝑳</mml:mi><mml:mo mathsize="80%" stretchy="false">=</mml:mo><mml:mrow><mml:mrow><mml:mtext mathsize="80%">diag</mml:mtext><mml:mo>⁢</mml:mo><mml:mrow><mml:mo maxsize="80%" minsize="80%">(</mml:mo><mml:mrow><mml:mi mathsize="80%" mathvariant="bold-italic">𝑾</mml:mi><mml:mo>⁢</mml:mo><mml:mn mathsize="80%">𝟏</mml:mn></mml:mrow><mml:mo maxsize="80%" minsize="80%">)</mml:mo></mml:mrow></mml:mrow><mml:mo mathsize="80%" stretchy="false">-</mml:mo><mml:mi mathsize="80%" mathvariant="bold-italic">𝑾</mml:mi></mml:mrow></mml:mrow></mml:math></inline-formula>. Throughout we assume the first <inline-formula><mml:math id="inf266"><mml:mi mathsize="80%">o</mml:mi></mml:math></inline-formula> rows and columns of <inline-formula><mml:math id="inf267"><mml:mi mathsize="80%" mathvariant="bold-italic">𝑳</mml:mi></mml:math></inline-formula> correspond to the observed nodes. With this assumption, our node assignment matrix has block structure <inline-formula><mml:math id="inf268"><mml:mrow><mml:mi mathsize="80%" mathvariant="bold-italic">𝑨</mml:mi><mml:mo mathsize="80%" stretchy="false">=</mml:mo><mml:mrow><mml:mo maxsize="80%" minsize="80%">[</mml:mo><mml:mrow><mml:mpadded width="+2.8pt"><mml:msub><mml:mi mathsize="80%" mathvariant="bold">𝐈</mml:mi><mml:mrow><mml:mi mathsize="80%">o</mml:mi><mml:mo mathsize="80%" stretchy="false">×</mml:mo><mml:mi mathsize="80%">o</mml:mi></mml:mrow></mml:msub></mml:mpadded><mml:mo lspace="2.5pt" mathsize="80%" rspace="2.5pt" stretchy="false">|</mml:mo><mml:msub><mml:mn mathsize="80%" mathvariant="bold"> 0</mml:mn><mml:mrow><mml:mi mathsize="80%">o</mml:mi><mml:mo mathsize="80%" stretchy="false">×</mml:mo><mml:mrow><mml:mo maxsize="80%" minsize="80%">(</mml:mo><mml:mrow><mml:mi mathsize="80%">d</mml:mi><mml:mo mathsize="80%" stretchy="false">-</mml:mo><mml:mi mathsize="80%">o</mml:mi></mml:mrow><mml:mo maxsize="80%" minsize="80%">)</mml:mo></mml:mrow></mml:mrow></mml:msub></mml:mrow><mml:mo maxsize="80%" minsize="80%">]</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula>. To simplify some of the equations appearing later, we introduce the notation: we define<disp-formula id="equ26"><label>(12)</label><mml:math id="m26"><mml:mrow><mml:mrow><mml:mrow><mml:msub><mml:mi mathsize="80%">𝑳</mml:mi><mml:mtext mathsize="80%">full</mml:mtext></mml:msub><mml:mo mathsize="80%" stretchy="false">:=</mml:mo><mml:mrow><mml:mi mathsize="80%">𝑳</mml:mi><mml:mo mathsize="80%" stretchy="false">+</mml:mo><mml:mfrac><mml:msup><mml:mn mathsize="80%">𝟏𝟏</mml:mn><mml:mo mathsize="80%" stretchy="false">⊤</mml:mo></mml:msup><mml:mi mathsize="80%">d</mml:mi></mml:mfrac></mml:mrow></mml:mrow><mml:mo mathsize="80%" rspace="8.1pt" stretchy="false">,</mml:mo><mml:mrow><mml:mi mathsize="80%">𝚺</mml:mi><mml:mo mathsize="80%" stretchy="false">:=</mml:mo><mml:mrow><mml:mrow><mml:mi mathsize="80%">𝑨</mml:mi><mml:mo>⁢</mml:mo><mml:msubsup><mml:mi mathsize="80%">𝑳</mml:mi><mml:mtext mathsize="80%">full</mml:mtext><mml:mrow><mml:mo mathsize="80%" stretchy="false">-</mml:mo><mml:mn mathsize="80%">1</mml:mn></mml:mrow></mml:msubsup><mml:mo>⁢</mml:mo><mml:msup><mml:mi mathsize="80%">𝑨</mml:mi><mml:mo mathsize="80%" stretchy="false">⊤</mml:mo></mml:msup></mml:mrow><mml:mo mathsize="80%" stretchy="false">+</mml:mo><mml:mrow><mml:msup><mml:mi mathsize="80%">σ</mml:mi><mml:mn mathsize="80%">2</mml:mn></mml:msup><mml:mo>⁢</mml:mo><mml:mtext mathsize="80%">diag</mml:mtext><mml:mo>⁢</mml:mo><mml:mrow><mml:mo maxsize="80%" minsize="80%">(</mml:mo><mml:msup><mml:mi mathsize="80%">𝒏</mml:mi><mml:mrow><mml:mo mathsize="80%" stretchy="false">-</mml:mo><mml:mn mathsize="80%">1</mml:mn></mml:mrow></mml:msup><mml:mo maxsize="80%" minsize="80%">)</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:mrow></mml:mrow><mml:mo mathsize="80%" stretchy="false">,</mml:mo></mml:mrow></mml:math></disp-formula>and<disp-formula id="equ27"><mml:math id="m27"><mml:mrow><mml:mrow><mml:mi mathsize="80%">𝑴</mml:mi><mml:mo mathsize="80%" stretchy="false">:=</mml:mo><mml:mrow><mml:msup><mml:mi mathsize="80%">𝑪</mml:mi><mml:mo mathsize="80%" stretchy="false">⊤</mml:mo></mml:msup><mml:mo>⁢</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mrow><mml:msup><mml:mrow><mml:mo maxsize="80%" minsize="80%">(</mml:mo><mml:mrow><mml:mi mathsize="80%">𝑪</mml:mi><mml:mo>⁢</mml:mo><mml:mi mathsize="80%">𝚺</mml:mi><mml:mo>⁢</mml:mo><mml:mi mathsize="80%">𝑪</mml:mi></mml:mrow><mml:mo maxsize="80%" minsize="80%">)</mml:mo></mml:mrow><mml:mrow><mml:mo mathsize="80%" stretchy="false">-</mml:mo><mml:mn mathsize="80%">1</mml:mn></mml:mrow></mml:msup><mml:mo>⁢</mml:mo><mml:mrow><mml:mo maxsize="80%" minsize="80%">(</mml:mo><mml:mrow><mml:mi mathsize="80%">𝑪</mml:mi><mml:mo>⁢</mml:mo><mml:mover accent="true"><mml:mi mathsize="80%">𝚺</mml:mi><mml:mo mathsize="80%" mathvariant="bold" stretchy="false">^</mml:mo></mml:mover><mml:mo>⁢</mml:mo><mml:mi mathsize="80%">𝑪</mml:mi></mml:mrow><mml:mo maxsize="80%" minsize="80%">)</mml:mo></mml:mrow><mml:mo>⁢</mml:mo><mml:msup><mml:mrow><mml:mo maxsize="80%" minsize="80%">(</mml:mo><mml:mrow><mml:mi mathsize="80%">𝑪</mml:mi><mml:mo>⁢</mml:mo><mml:mi mathsize="80%">𝚺</mml:mi><mml:mo>⁢</mml:mo><mml:mi mathsize="80%">𝑪</mml:mi></mml:mrow><mml:mo maxsize="80%" minsize="80%">)</mml:mo></mml:mrow><mml:mrow><mml:mo mathsize="80%" stretchy="false">-</mml:mo><mml:mn mathsize="80%">1</mml:mn></mml:mrow></mml:msup></mml:mrow><mml:mo mathsize="80%" stretchy="false">-</mml:mo><mml:msup><mml:mrow><mml:mo maxsize="80%" minsize="80%">(</mml:mo><mml:mrow><mml:mi mathsize="80%">𝑪</mml:mi><mml:mo>⁢</mml:mo><mml:mi mathsize="80%">𝚺</mml:mi><mml:mo>⁢</mml:mo><mml:mi mathsize="80%">𝑪</mml:mi></mml:mrow><mml:mo maxsize="80%" minsize="80%">)</mml:mo></mml:mrow><mml:mrow><mml:mo mathsize="80%" stretchy="false">-</mml:mo><mml:mn mathsize="80%">1</mml:mn></mml:mrow></mml:msup></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>⁢</mml:mo><mml:mi mathsize="80%">𝑪</mml:mi></mml:mrow></mml:mrow><mml:mo mathsize="80%" stretchy="false">.</mml:mo></mml:mrow></mml:math></disp-formula></p><p>Applying the chain rule and matrix derivatives, we can calculate:<disp-formula id="equ28"><mml:math id="m28"><mml:mrow><mml:mrow><mml:mrow><mml:mrow><mml:mo mathsize="80%" stretchy="false">∇</mml:mo><mml:mo>⁡</mml:mo><mml:mi mathsize="80%" mathvariant="normal">ℓ</mml:mi></mml:mrow><mml:mo>⁢</mml:mo><mml:mrow><mml:mo maxsize="80%" minsize="80%">(</mml:mo><mml:mi mathsize="80%">𝒘</mml:mi><mml:mo maxsize="80%" minsize="80%">)</mml:mo></mml:mrow></mml:mrow><mml:mo mathsize="80%" stretchy="false">=</mml:mo><mml:mrow><mml:mfrac><mml:mrow><mml:mrow><mml:mo mathsize="80%" stretchy="false">∂</mml:mo><mml:mo>⁡</mml:mo><mml:mi mathsize="80%" mathvariant="normal">ℓ</mml:mi></mml:mrow><mml:mo>⁢</mml:mo><mml:mrow><mml:mo maxsize="80%" minsize="80%">(</mml:mo><mml:mi mathsize="80%">𝒘</mml:mi><mml:mo maxsize="80%" minsize="80%">)</mml:mo></mml:mrow></mml:mrow><mml:mrow><mml:mrow><mml:mo mathsize="80%" stretchy="false">∂</mml:mo><mml:mo>⁡</mml:mo><mml:mtext mathsize="80%">vec</mml:mtext></mml:mrow><mml:mo>⁢</mml:mo><mml:mrow><mml:mo maxsize="80%" minsize="80%">(</mml:mo><mml:mi mathsize="80%">𝑳</mml:mi><mml:mo maxsize="80%" minsize="80%">)</mml:mo></mml:mrow></mml:mrow></mml:mfrac><mml:mo mathsize="80%" stretchy="false">⋅</mml:mo><mml:mfrac><mml:mrow><mml:mrow><mml:mo mathsize="80%" stretchy="false">∂</mml:mo><mml:mo>⁡</mml:mo><mml:mtext mathsize="80%">vec</mml:mtext></mml:mrow><mml:mo>⁢</mml:mo><mml:mrow><mml:mo maxsize="80%" minsize="80%">(</mml:mo><mml:mi mathsize="80%">𝑳</mml:mi><mml:mo maxsize="80%" minsize="80%">)</mml:mo></mml:mrow></mml:mrow><mml:mrow><mml:mo mathsize="80%" stretchy="false">∂</mml:mo><mml:mo>⁡</mml:mo><mml:msup><mml:mi mathsize="80%">𝒘</mml:mi><mml:mo mathsize="80%" stretchy="false">⊤</mml:mo></mml:msup></mml:mrow></mml:mfrac></mml:mrow></mml:mrow><mml:mo mathsize="80%" stretchy="false">,</mml:mo></mml:mrow></mml:math></disp-formula>where vec is the vectorization operator and <inline-formula><mml:math id="inf269"><mml:mrow><mml:mrow><mml:mrow><mml:mo mathsize="80%" stretchy="false">∂</mml:mo><mml:mo>⁡</mml:mo><mml:mi mathsize="80%" mathvariant="normal">ℓ</mml:mi></mml:mrow><mml:mo mathsize="80%" stretchy="false">/</mml:mo><mml:mrow><mml:mo mathsize="80%" stretchy="false">∂</mml:mo><mml:mo>⁡</mml:mo><mml:mtext mathsize="80%">vec</mml:mtext></mml:mrow></mml:mrow><mml:mo>⁢</mml:mo><mml:mrow><mml:mo maxsize="80%" minsize="80%">(</mml:mo><mml:mi mathsize="80%" mathvariant="bold-italic">𝑳</mml:mi><mml:mo maxsize="80%" minsize="80%">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> and <inline-formula><mml:math id="inf270"><mml:mrow><mml:mrow><mml:mrow><mml:mo mathsize="80%" stretchy="false">∂</mml:mo><mml:mo>⁡</mml:mo><mml:mtext mathsize="80%">vec</mml:mtext></mml:mrow><mml:mo>⁢</mml:mo><mml:mrow><mml:mo maxsize="80%" minsize="80%">(</mml:mo><mml:mi mathsize="80%" mathvariant="bold-italic">𝑳</mml:mi><mml:mo maxsize="80%" minsize="80%">)</mml:mo></mml:mrow></mml:mrow><mml:mo mathsize="80%" stretchy="false">/</mml:mo><mml:mrow><mml:mo mathsize="80%" stretchy="false">∂</mml:mo><mml:mo>⁡</mml:mo><mml:msup><mml:mi mathsize="80%" mathvariant="bold-italic">𝒘</mml:mi><mml:mo mathsize="80%" stretchy="false">⊤</mml:mo></mml:msup></mml:mrow></mml:mrow></mml:math></inline-formula> are <inline-formula><mml:math id="inf271"><mml:mrow><mml:mn mathsize="80%">1</mml:mn><mml:mo mathsize="80%" stretchy="false">×</mml:mo><mml:msup><mml:mi mathsize="80%">d</mml:mi><mml:mn mathsize="80%">2</mml:mn></mml:msup></mml:mrow></mml:math></inline-formula> vector and <inline-formula><mml:math id="inf272"><mml:mrow><mml:msup><mml:mi mathsize="80%">d</mml:mi><mml:mn mathsize="80%">2</mml:mn></mml:msup><mml:mo mathsize="80%" stretchy="false">×</mml:mo><mml:mi mathsize="80%">d</mml:mi></mml:mrow></mml:math></inline-formula> matrix, respectively, given by<disp-formula id="equ29"><label>(13)</label><mml:math id="m29"><mml:mstyle displaystyle="true"><mml:mfrac><mml:mrow><mml:mrow><mml:mo mathsize="80%" stretchy="false">∂</mml:mo><mml:mo>⁡</mml:mo><mml:mi mathsize="80%" mathvariant="normal">ℓ</mml:mi></mml:mrow><mml:mo>⁢</mml:mo><mml:mrow><mml:mo maxsize="80%" minsize="80%">(</mml:mo><mml:mi mathsize="80%">𝒘</mml:mi><mml:mo maxsize="80%" minsize="80%">)</mml:mo></mml:mrow></mml:mrow><mml:mrow><mml:mrow><mml:mo mathsize="80%" stretchy="false">∂</mml:mo><mml:mo>⁡</mml:mo><mml:mtext mathsize="80%">vec</mml:mtext></mml:mrow><mml:mo>⁢</mml:mo><mml:mrow><mml:mo maxsize="80%" minsize="80%">(</mml:mo><mml:mi mathsize="80%">𝑳</mml:mi><mml:mo maxsize="80%" minsize="80%">)</mml:mo></mml:mrow></mml:mrow></mml:mfrac></mml:mstyle><mml:mrow><mml:mrow><mml:mrow><mml:mi/><mml:mo mathsize="80%" stretchy="false">=</mml:mo><mml:mrow><mml:mrow><mml:mi mathsize="80%">p</mml:mi><mml:mo mathsize="80%" stretchy="false">⋅</mml:mo><mml:mtext mathsize="80%">vec</mml:mtext></mml:mrow><mml:mo>⁢</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msubsup><mml:mi mathsize="80%">𝑳</mml:mi><mml:mtext mathsize="80%">full</mml:mtext><mml:mrow><mml:mo mathsize="80%" stretchy="false">-</mml:mo><mml:mn mathsize="80%">1</mml:mn></mml:mrow></mml:msubsup><mml:mo>⁢</mml:mo><mml:msup><mml:mi mathsize="80%">𝑨</mml:mi><mml:mo mathsize="80%" stretchy="false">⊤</mml:mo></mml:msup><mml:mo>⁢</mml:mo><mml:mi mathsize="80%">𝑴</mml:mi><mml:mo>⁢</mml:mo><mml:mi mathsize="80%">𝑨</mml:mi><mml:mo>⁢</mml:mo><mml:msubsup><mml:mi mathsize="80%">𝑳</mml:mi><mml:mtext mathsize="80%">full</mml:mtext><mml:mrow><mml:mrow><mml:mo mathsize="80%" stretchy="false">-</mml:mo><mml:mn mathsize="80%">1</mml:mn></mml:mrow><mml:mo mathsize="80%" stretchy="false">,</mml:mo><mml:mo mathsize="80%" stretchy="false">⊤</mml:mo></mml:mrow></mml:msubsup></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mrow><mml:mo mathsize="80%" rspace="8.1pt" stretchy="false">,</mml:mo><mml:mrow><mml:mstyle displaystyle="true"><mml:mfrac><mml:mrow><mml:mrow><mml:mo mathsize="80%" stretchy="false">∂</mml:mo><mml:mo>⁡</mml:mo><mml:mtext mathsize="80%">vec</mml:mtext></mml:mrow><mml:mo>⁢</mml:mo><mml:mrow><mml:mo maxsize="80%" minsize="80%">(</mml:mo><mml:mi mathsize="80%">𝑳</mml:mi><mml:mo maxsize="80%" minsize="80%">)</mml:mo></mml:mrow></mml:mrow><mml:mrow><mml:mo mathsize="80%" stretchy="false">∂</mml:mo><mml:mo>⁡</mml:mo><mml:msup><mml:mi mathsize="80%">𝒘</mml:mi><mml:mo mathsize="80%" stretchy="false">⊤</mml:mo></mml:msup></mml:mrow></mml:mfrac></mml:mstyle><mml:mo mathsize="80%" stretchy="false">=</mml:mo><mml:mrow><mml:mi mathsize="80%">𝑺</mml:mi><mml:mo mathsize="80%" stretchy="false">-</mml:mo><mml:mi mathsize="80%">𝑻</mml:mi></mml:mrow></mml:mrow></mml:mrow><mml:mo mathsize="80%" stretchy="false">.</mml:mo></mml:mrow></mml:math></disp-formula></p><p>Here, <inline-formula><mml:math id="inf273"><mml:mi mathsize="80%" mathvariant="bold-italic">𝑺</mml:mi></mml:math></inline-formula> and <inline-formula><mml:math id="inf274"><mml:mi mathsize="80%" mathvariant="bold-italic">𝑻</mml:mi></mml:math></inline-formula> are linear operators that satisfy <inline-formula><mml:math id="inf275"><mml:mrow><mml:mrow><mml:mi mathsize="80%" mathvariant="bold-italic">𝑺</mml:mi><mml:mo>⁢</mml:mo><mml:mi mathsize="80%" mathvariant="bold-italic">𝒘</mml:mi></mml:mrow><mml:mo mathsize="80%" stretchy="false">=</mml:mo><mml:mrow><mml:mtext mathsize="80%">diag</mml:mtext><mml:mo>⁢</mml:mo><mml:mrow><mml:mo maxsize="80%" minsize="80%">(</mml:mo><mml:mrow><mml:mi mathsize="80%" mathvariant="bold-italic">𝑾</mml:mi><mml:mo>⁢</mml:mo><mml:mn mathsize="80%">𝟏</mml:mn></mml:mrow><mml:mo maxsize="80%" minsize="80%">)</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:math></inline-formula> and <inline-formula><mml:math id="inf276"><mml:mrow><mml:mrow><mml:mi mathsize="80%" mathvariant="bold-italic">𝑻</mml:mi><mml:mo>⁢</mml:mo><mml:mi mathsize="80%" mathvariant="bold-italic">𝒘</mml:mi></mml:mrow><mml:mo mathsize="80%" stretchy="false">=</mml:mo><mml:mi mathsize="80%" mathvariant="bold-italic">𝑾</mml:mi></mml:mrow></mml:math></inline-formula>. Note <inline-formula><mml:math id="inf277"><mml:mi mathsize="80%" mathvariant="bold-italic">𝑺</mml:mi></mml:math></inline-formula> and <inline-formula><mml:math id="inf278"><mml:mi mathsize="80%" mathvariant="bold-italic">𝑻</mml:mi></mml:math></inline-formula> both have <inline-formula><mml:math id="inf279"><mml:mrow><mml:mi class="ltx_font_mathcaligraphic" mathsize="80%">𝒪</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo maxsize="80%" minsize="80%">(</mml:mo><mml:mi mathsize="80%">d</mml:mi><mml:mo maxsize="80%" minsize="80%">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> many nonzero entries, so we can perform sparse matrix multiplication to efficiently compute the matrix-vector multiplication <inline-formula><mml:math id="inf280"><mml:mrow><mml:mrow><mml:mrow><mml:mrow><mml:mo mathsize="80%" stretchy="false">∂</mml:mo><mml:mo>⁡</mml:mo><mml:mi mathsize="80%" mathvariant="normal">ℓ</mml:mi></mml:mrow><mml:mo mathsize="80%" stretchy="false">/</mml:mo><mml:mrow><mml:mo mathsize="80%" stretchy="false">∂</mml:mo><mml:mo>⁡</mml:mo><mml:mtext mathsize="80%">vec</mml:mtext></mml:mrow></mml:mrow><mml:mo>⁢</mml:mo><mml:mrow><mml:mo maxsize="80%" minsize="80%">(</mml:mo><mml:mi mathsize="80%" mathvariant="bold-italic">𝑳</mml:mi><mml:mo maxsize="80%" minsize="80%">)</mml:mo></mml:mrow></mml:mrow><mml:mo mathsize="80%" stretchy="false">⋅</mml:mo><mml:mrow><mml:mo maxsize="80%" minsize="80%">(</mml:mo><mml:mrow><mml:mi mathsize="80%" mathvariant="bold-italic">𝑺</mml:mi><mml:mo mathsize="80%" stretchy="false">-</mml:mo><mml:mi mathsize="80%" mathvariant="bold-italic">𝑻</mml:mi></mml:mrow><mml:mo maxsize="80%" minsize="80%">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula>. On the other hand, the computation of <inline-formula><mml:math id="inf281"><mml:mrow><mml:mrow><mml:mrow><mml:mo mathsize="80%" stretchy="false">∂</mml:mo><mml:mo>⁡</mml:mo><mml:mi mathsize="80%" mathvariant="normal">ℓ</mml:mi></mml:mrow><mml:mo mathsize="80%" stretchy="false">/</mml:mo><mml:mrow><mml:mo mathsize="80%" stretchy="false">∂</mml:mo><mml:mo>⁡</mml:mo><mml:mtext mathsize="80%">vec</mml:mtext></mml:mrow></mml:mrow><mml:mo>⁢</mml:mo><mml:mrow><mml:mo maxsize="80%" minsize="80%">(</mml:mo><mml:mi mathsize="80%" mathvariant="bold-italic">𝑳</mml:mi><mml:mo maxsize="80%" minsize="80%">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> is more challenging as it requires inverting the full <inline-formula><mml:math id="inf282"><mml:mrow><mml:mi mathsize="80%">d</mml:mi><mml:mo mathsize="80%" stretchy="false">×</mml:mo><mml:mi mathsize="80%">d</mml:mi></mml:mrow></mml:math></inline-formula> matrix <inline-formula><mml:math id="inf283"><mml:msub><mml:mi mathsize="80%" mathvariant="bold-italic">𝑳</mml:mi><mml:mtext mathsize="80%">full</mml:mtext></mml:msub></mml:math></inline-formula>. Next, we develop a procedure that efficiently computes <inline-formula><mml:math id="inf284"><mml:mrow><mml:mrow><mml:mrow><mml:mo mathsize="80%" stretchy="false">∂</mml:mo><mml:mo>⁡</mml:mo><mml:mi mathsize="80%" mathvariant="normal">ℓ</mml:mi></mml:mrow><mml:mo mathsize="80%" stretchy="false">/</mml:mo><mml:mrow><mml:mo mathsize="80%" stretchy="false">∂</mml:mo><mml:mo>⁡</mml:mo><mml:mtext mathsize="80%">vec</mml:mtext></mml:mrow></mml:mrow><mml:mo>⁢</mml:mo><mml:mrow><mml:mo maxsize="80%" minsize="80%">(</mml:mo><mml:mi mathsize="80%" mathvariant="bold-italic">𝑳</mml:mi><mml:mo maxsize="80%" minsize="80%">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula>. We proceed by dividing the task into multiple steps.</p><sec id="s9-1"><title>1. Computing <inline-formula><mml:math id="inf285"><mml:msup><mml:mi mathvariant="bold">𝚺</mml:mi><mml:mrow><mml:mo>-</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msup></mml:math></inline-formula></title><p>Recalling the block structure <inline-formula><mml:math id="inf286"><mml:mrow><mml:mi mathsize="80%" mathvariant="bold-italic">𝑨</mml:mi><mml:mo mathsize="80%" stretchy="false">=</mml:mo><mml:mrow><mml:mo maxsize="80%" minsize="80%">[</mml:mo><mml:mrow><mml:mpadded width="+2.8pt"><mml:msub><mml:mi mathsize="80%" mathvariant="bold">𝐈</mml:mi><mml:mrow><mml:mi mathsize="80%">o</mml:mi><mml:mo mathsize="80%" stretchy="false">×</mml:mo><mml:mi mathsize="80%">o</mml:mi></mml:mrow></mml:msub></mml:mpadded><mml:mo lspace="2.5pt" mathsize="80%" rspace="2.5pt" stretchy="false">|</mml:mo><mml:msub><mml:mn mathsize="80%" mathvariant="bold"> 0</mml:mn><mml:mrow><mml:mi mathsize="80%">o</mml:mi><mml:mo mathsize="80%" stretchy="false">×</mml:mo><mml:mrow><mml:mo maxsize="80%" minsize="80%">(</mml:mo><mml:mrow><mml:mi mathsize="80%">d</mml:mi><mml:mo mathsize="80%" stretchy="false">-</mml:mo><mml:mi mathsize="80%">o</mml:mi></mml:mrow><mml:mo maxsize="80%" minsize="80%">)</mml:mo></mml:mrow></mml:mrow></mml:msub></mml:mrow><mml:mo maxsize="80%" minsize="80%">]</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> of the node assignment matrix, we can write <inline-formula><mml:math id="inf287"><mml:mi mathsize="80%" mathvariant="bold">𝚺</mml:mi></mml:math></inline-formula> as:<disp-formula id="equ30"><mml:math id="m30"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi mathvariant="bold">Σ</mml:mi><mml:mo>=</mml:mo><mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:msubsup><mml:mi mathvariant="bold-italic">L</mml:mi><mml:mrow><mml:mtext>full</mml:mtext></mml:mrow><mml:mrow><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msubsup><mml:mo>)</mml:mo></mml:mrow><mml:mrow><mml:mi>o</mml:mi><mml:mo>×</mml:mo><mml:mi>o</mml:mi></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msup><mml:mi>σ</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup><mml:mtext>diag</mml:mtext><mml:mo stretchy="false">(</mml:mo><mml:msup><mml:mi mathvariant="bold-italic">n</mml:mi><mml:mrow><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msup><mml:mo stretchy="false">)</mml:mo><mml:mo>,</mml:mo></mml:mrow></mml:mstyle></mml:math></disp-formula>where <inline-formula><mml:math id="inf288"><mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:msubsup><mml:mi mathsize="80%" mathvariant="bold-italic">𝑳</mml:mi><mml:mtext mathsize="80%">full</mml:mtext><mml:mrow><mml:mo mathsize="80%" stretchy="false">-</mml:mo><mml:mn mathsize="80%">1</mml:mn></mml:mrow></mml:msubsup><mml:mo>)</mml:mo></mml:mrow><mml:mrow><mml:mi mathsize="80%">o</mml:mi><mml:mo mathsize="80%" stretchy="false">×</mml:mo><mml:mi mathsize="80%">o</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> denotes the <inline-formula><mml:math id="inf289"><mml:mrow><mml:mi mathsize="80%">o</mml:mi><mml:mo mathsize="80%" stretchy="false">×</mml:mo><mml:mi mathsize="80%">o</mml:mi></mml:mrow></mml:math></inline-formula> upper-left block of <inline-formula><mml:math id="inf290"><mml:msubsup><mml:mi mathsize="80%" mathvariant="bold-italic">𝑳</mml:mi><mml:mtext mathsize="80%">full</mml:mtext><mml:mrow><mml:mo mathsize="80%" stretchy="false">-</mml:mo><mml:mn mathsize="80%">1</mml:mn></mml:mrow></mml:msubsup></mml:math></inline-formula>. Following <xref ref-type="bibr" rid="bib42">Petkova et al., 2016</xref>, the inverse <inline-formula><mml:math id="inf291"><mml:msup><mml:mi mathsize="80%" mathvariant="bold">𝚺</mml:mi><mml:mrow><mml:mo mathsize="80%" stretchy="false">-</mml:mo><mml:mn mathsize="80%">1</mml:mn></mml:mrow></mml:msup></mml:math></inline-formula> has the form<disp-formula id="equ31"><label>(14)</label><mml:math id="m31"><mml:mrow><mml:mrow><mml:msup><mml:mi mathsize="80%">𝚺</mml:mi><mml:mrow><mml:mo mathsize="80%" stretchy="false">-</mml:mo><mml:mn mathsize="80%">1</mml:mn></mml:mrow></mml:msup><mml:mo mathsize="80%" stretchy="false">=</mml:mo><mml:mrow><mml:mi mathsize="80%">𝑿</mml:mi><mml:mo mathsize="80%" stretchy="false">+</mml:mo><mml:mrow><mml:msup><mml:mi mathsize="80%">σ</mml:mi><mml:mrow><mml:mo mathsize="80%" stretchy="false">-</mml:mo><mml:mn mathsize="80%">2</mml:mn></mml:mrow></mml:msup><mml:mo>⁢</mml:mo><mml:mtext mathsize="80%">diag</mml:mtext><mml:mo>⁢</mml:mo><mml:mrow><mml:mo maxsize="80%" minsize="80%">(</mml:mo><mml:mi mathsize="80%">𝒏</mml:mi><mml:mo maxsize="80%" minsize="80%">)</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:mrow><mml:mo mathsize="80%" stretchy="false">,</mml:mo></mml:mrow></mml:math></disp-formula>for some matrix <inline-formula><mml:math id="inf292"><mml:mrow><mml:mi mathsize="80%" mathvariant="bold-italic">𝑿</mml:mi><mml:mo mathsize="80%" stretchy="false">∈</mml:mo><mml:msup><mml:mi mathsize="80%">ℝ</mml:mi><mml:mrow><mml:mi mathsize="80%">o</mml:mi><mml:mo mathsize="80%" stretchy="false">×</mml:mo><mml:mi mathsize="80%">o</mml:mi></mml:mrow></mml:msup></mml:mrow></mml:math></inline-formula>. Equating <inline-formula><mml:math id="inf293"><mml:mrow><mml:mrow><mml:mi mathsize="80%" mathvariant="bold">𝚺</mml:mi><mml:mo>⁢</mml:mo><mml:msup><mml:mi mathsize="80%" mathvariant="bold">𝚺</mml:mi><mml:mrow><mml:mo mathsize="80%" stretchy="false">-</mml:mo><mml:mn mathsize="80%">1</mml:mn></mml:mrow></mml:msup></mml:mrow><mml:mo mathsize="80%" stretchy="false">=</mml:mo><mml:mi mathsize="80%" mathvariant="bold">𝐈</mml:mi></mml:mrow></mml:math></inline-formula>, it follows that<disp-formula id="equ32"><label>(15)</label><mml:math id="m32"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mtable columnalign="left left" columnspacing="1em" rowspacing="4pt"><mml:mtr><mml:mtd><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mo>[</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:msubsup><mml:mi mathvariant="bold-italic">L</mml:mi><mml:mrow><mml:mi mathvariant="normal">f</mml:mi><mml:mi mathvariant="normal">u</mml:mi><mml:mi mathvariant="normal">l</mml:mi><mml:mi mathvariant="normal">l</mml:mi></mml:mrow><mml:mrow><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msubsup><mml:mo>)</mml:mo></mml:mrow><mml:mrow><mml:mi>o</mml:mi><mml:mo>×</mml:mo><mml:mi>o</mml:mi></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msup><mml:mi>σ</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup><mml:mtext>diag</mml:mtext><mml:mo stretchy="false">(</mml:mo><mml:msup><mml:mi mathvariant="bold-italic">n</mml:mi><mml:mrow><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msup><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>]</mml:mo></mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi mathvariant="bold-italic">X</mml:mi><mml:mo>+</mml:mo><mml:msup><mml:mi>σ</mml:mi><mml:mrow><mml:mo>−</mml:mo><mml:mn>2</mml:mn></mml:mrow></mml:msup><mml:mtext>diag</mml:mtext><mml:mo stretchy="false">(</mml:mo><mml:mi mathvariant="bold-italic">n</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mrow><mml:mi mathvariant="bold">I</mml:mi></mml:mrow></mml:mstyle></mml:mtd></mml:mtr><mml:mtr><mml:mtd/></mml:mtr><mml:mtr><mml:mtd><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mspace width="thickmathspace"/><mml:mo stretchy="false">⟺</mml:mo><mml:mspace width="thickmathspace"/><mml:mrow><mml:mo>[</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:msubsup><mml:mi mathvariant="bold-italic">L</mml:mi><mml:mrow><mml:mtext>full</mml:mtext></mml:mrow><mml:mrow><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msubsup><mml:mo>)</mml:mo></mml:mrow><mml:mrow><mml:mi>o</mml:mi><mml:mo>×</mml:mo><mml:mi>o</mml:mi></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msup><mml:mi>σ</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup><mml:mtext>diag</mml:mtext><mml:mo stretchy="false">(</mml:mo><mml:msup><mml:mi mathvariant="bold-italic">n</mml:mi><mml:mrow><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msup><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>]</mml:mo></mml:mrow><mml:mi mathvariant="bold-italic">X</mml:mi><mml:mo>=</mml:mo><mml:mo>−</mml:mo><mml:msup><mml:mi>σ</mml:mi><mml:mrow><mml:mo>−</mml:mo><mml:mn>2</mml:mn></mml:mrow></mml:msup><mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:msubsup><mml:mi mathvariant="bold-italic">L</mml:mi><mml:mrow><mml:mtext>full</mml:mtext></mml:mrow><mml:mrow><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msubsup><mml:mo>)</mml:mo></mml:mrow><mml:mrow><mml:mi>o</mml:mi><mml:mo>×</mml:mo><mml:mi>o</mml:mi></mml:mrow></mml:msub><mml:mtext>diag</mml:mtext><mml:mo stretchy="false">(</mml:mo><mml:mi mathvariant="bold-italic">n</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>.</mml:mo></mml:mstyle></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:mstyle></mml:math></disp-formula></p><p>Therefore, <inline-formula><mml:math id="inf294"><mml:msup><mml:mi mathsize="80%" mathvariant="bold">𝚺</mml:mi><mml:mrow><mml:mo mathsize="80%" stretchy="false">-</mml:mo><mml:mn mathsize="80%">1</mml:mn></mml:mrow></mml:msup></mml:math></inline-formula> can be obtained by solving the <inline-formula><mml:math id="inf295"><mml:mrow><mml:mi mathsize="80%">o</mml:mi><mml:mo mathsize="80%" stretchy="false">×</mml:mo><mml:mi mathsize="80%">o</mml:mi></mml:mrow></mml:math></inline-formula> linear system <xref ref-type="disp-formula" rid="equ32">Equation (15)</xref> and plugging the solution into <xref ref-type="disp-formula" rid="equ31">Equation (14)</xref>. The challenge here is to compute <inline-formula><mml:math id="inf296"><mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:msubsup><mml:mi mathsize="80%" mathvariant="bold-italic">𝑳</mml:mi><mml:mtext mathsize="80%">full</mml:mtext><mml:mrow><mml:mo mathsize="80%" stretchy="false">-</mml:mo><mml:mn mathsize="80%">1</mml:mn></mml:mrow></mml:msubsup><mml:mo>)</mml:mo></mml:mrow><mml:mrow><mml:mi mathsize="80%">o</mml:mi><mml:mo mathsize="80%" stretchy="false">×</mml:mo><mml:mi mathsize="80%">o</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> without matrix inversion of the full-dimensional <inline-formula><mml:math id="inf297"><mml:msub><mml:mi mathsize="80%" mathvariant="bold-italic">𝑳</mml:mi><mml:mtext mathsize="80%">full</mml:mtext></mml:msub></mml:math></inline-formula>.</p></sec><sec id="s9-2"><title>2. Computing <inline-formula><mml:math id="inf298"><mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:msubsup><mml:mi mathvariant="bold-italic">𝑳</mml:mi><mml:mtext>full</mml:mtext><mml:mrow><mml:mo>-</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msubsup><mml:mo>)</mml:mo></mml:mrow><mml:mrow><mml:mi>o</mml:mi><mml:mo>×</mml:mo><mml:mi>o</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula></title><p>Let <inline-formula><mml:math id="inf299"><mml:msub><mml:mi mathsize="80%" mathvariant="bold-italic">𝑳</mml:mi><mml:mrow><mml:mtext mathsize="80%">full</mml:mtext><mml:mo mathsize="80%" stretchy="false">,</mml:mo><mml:mrow><mml:mi mathsize="80%">o</mml:mi><mml:mo mathsize="80%" stretchy="false">×</mml:mo><mml:mi mathsize="80%">o</mml:mi></mml:mrow></mml:mrow></mml:msub></mml:math></inline-formula> be the <inline-formula><mml:math id="inf300"><mml:mrow><mml:mi mathsize="80%">o</mml:mi><mml:mo mathsize="80%" stretchy="false">×</mml:mo><mml:mi mathsize="80%">o</mml:mi></mml:mrow></mml:math></inline-formula> block matrix corresponding to the observed nodes of <inline-formula><mml:math id="inf301"><mml:msub><mml:mi mathsize="80%" mathvariant="bold-italic">𝑳</mml:mi><mml:mtext mathsize="80%">full</mml:mtext></mml:msub></mml:math></inline-formula>, and similarly let <inline-formula><mml:math id="inf302"><mml:msub><mml:mi mathsize="80%" mathvariant="bold-italic">𝑳</mml:mi><mml:mrow><mml:mtext mathsize="80%">full</mml:mtext><mml:mo mathsize="80%" stretchy="false">,</mml:mo><mml:mrow><mml:mrow><mml:mo maxsize="80%" minsize="80%">(</mml:mo><mml:mrow><mml:mi mathsize="80%">d</mml:mi><mml:mo mathsize="80%" stretchy="false">-</mml:mo><mml:mi mathsize="80%">o</mml:mi></mml:mrow><mml:mo maxsize="80%" minsize="80%">)</mml:mo></mml:mrow><mml:mo mathsize="80%" stretchy="false">×</mml:mo><mml:mrow><mml:mo maxsize="80%" minsize="80%">(</mml:mo><mml:mrow><mml:mi mathsize="80%">d</mml:mi><mml:mo mathsize="80%" stretchy="false">-</mml:mo><mml:mi mathsize="80%">o</mml:mi></mml:mrow><mml:mo maxsize="80%" minsize="80%">)</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:msub></mml:math></inline-formula> and <inline-formula><mml:math id="inf303"><mml:mrow><mml:msub><mml:mi mathsize="80%" mathvariant="bold-italic">𝑳</mml:mi><mml:mrow><mml:mtext mathsize="80%">full</mml:mtext><mml:mo mathsize="80%" stretchy="false">,</mml:mo><mml:mrow><mml:mi mathsize="80%">o</mml:mi><mml:mo mathsize="80%" stretchy="false">×</mml:mo><mml:mrow><mml:mo maxsize="80%" minsize="80%">(</mml:mo><mml:mrow><mml:mi mathsize="80%">d</mml:mi><mml:mo mathsize="80%" stretchy="false">-</mml:mo><mml:mi mathsize="80%">o</mml:mi></mml:mrow><mml:mo maxsize="80%" minsize="80%">)</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:msub><mml:mo mathsize="80%" stretchy="false">=</mml:mo><mml:msubsup><mml:mi mathsize="80%" mathvariant="bold-italic">𝑳</mml:mi><mml:mrow><mml:mtext mathsize="80%">full</mml:mtext><mml:mo mathsize="80%" stretchy="false">,</mml:mo><mml:mrow><mml:mrow><mml:mo maxsize="80%" minsize="80%">(</mml:mo><mml:mrow><mml:mi mathsize="80%">d</mml:mi><mml:mo mathsize="80%" stretchy="false">-</mml:mo><mml:mi mathsize="80%">o</mml:mi></mml:mrow><mml:mo maxsize="80%" minsize="80%">)</mml:mo></mml:mrow><mml:mo mathsize="80%" stretchy="false">×</mml:mo><mml:mi mathsize="80%">o</mml:mi></mml:mrow></mml:mrow><mml:mo mathsize="80%" stretchy="false">⊤</mml:mo></mml:msubsup></mml:mrow></mml:math></inline-formula> be the corresponding block matrices of <inline-formula><mml:math id="inf304"><mml:msub><mml:mi mathsize="80%" mathvariant="bold-italic">𝑳</mml:mi><mml:mtext mathsize="80%">full</mml:mtext></mml:msub></mml:math></inline-formula>, respectively. The inverse of <inline-formula><mml:math id="inf305"><mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:msubsup><mml:mi mathsize="80%" mathvariant="bold-italic">𝑳</mml:mi><mml:mtext mathsize="80%">full</mml:mtext><mml:mrow><mml:mo mathsize="80%" stretchy="false">-</mml:mo><mml:mn mathsize="80%">1</mml:mn></mml:mrow></mml:msubsup><mml:mo>)</mml:mo></mml:mrow><mml:mrow><mml:mi mathsize="80%">o</mml:mi><mml:mo mathsize="80%" stretchy="false">×</mml:mo><mml:mi mathsize="80%">o</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> is then given by the Schur complement of <inline-formula><mml:math id="inf306"><mml:msub><mml:mi mathsize="80%" mathvariant="bold-italic">𝑳</mml:mi><mml:mrow><mml:mtext mathsize="80%">full</mml:mtext><mml:mo mathsize="80%" stretchy="false">,</mml:mo><mml:mrow><mml:mrow><mml:mo maxsize="80%" minsize="80%">(</mml:mo><mml:mrow><mml:mi mathsize="80%">d</mml:mi><mml:mo mathsize="80%" stretchy="false">-</mml:mo><mml:mi mathsize="80%">o</mml:mi></mml:mrow><mml:mo maxsize="80%" minsize="80%">)</mml:mo></mml:mrow><mml:mo mathsize="80%" stretchy="false">×</mml:mo><mml:mrow><mml:mo maxsize="80%" minsize="80%">(</mml:mo><mml:mrow><mml:mi mathsize="80%">d</mml:mi><mml:mo mathsize="80%" stretchy="false">-</mml:mo><mml:mi mathsize="80%">o</mml:mi></mml:mrow><mml:mo maxsize="80%" minsize="80%">)</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:msub></mml:math></inline-formula> in <inline-formula><mml:math id="inf307"><mml:mi mathsize="80%" mathvariant="bold-italic">𝑳</mml:mi></mml:math></inline-formula>:<disp-formula id="equ33"><label>(16)</label><mml:math id="m33"><mml:mrow><mml:mrow><mml:msup><mml:mrow><mml:mo>[</mml:mo><mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:msubsup><mml:mi mathsize="80%">𝑳</mml:mi><mml:mtext mathsize="80%">full</mml:mtext><mml:mrow><mml:mo mathsize="80%" stretchy="false">-</mml:mo><mml:mn mathsize="80%">1</mml:mn></mml:mrow></mml:msubsup><mml:mo>)</mml:mo></mml:mrow><mml:mrow><mml:mi mathsize="80%">o</mml:mi><mml:mo mathsize="80%" stretchy="false">×</mml:mo><mml:mi mathsize="80%">o</mml:mi></mml:mrow></mml:msub><mml:mo>]</mml:mo></mml:mrow><mml:mrow><mml:mo mathsize="80%" stretchy="false">-</mml:mo><mml:mn mathsize="80%">1</mml:mn></mml:mrow></mml:msup><mml:mo mathsize="80%" stretchy="false">=</mml:mo><mml:mrow><mml:msub><mml:mi mathsize="80%">𝑳</mml:mi><mml:mrow><mml:mtext mathsize="80%">full</mml:mtext><mml:mo mathsize="80%" stretchy="false">,</mml:mo><mml:mrow><mml:mi mathsize="80%">o</mml:mi><mml:mo mathsize="80%" stretchy="false">×</mml:mo><mml:mi mathsize="80%">o</mml:mi></mml:mrow></mml:mrow></mml:msub><mml:mo mathsize="80%" stretchy="false">-</mml:mo><mml:mrow><mml:msub><mml:mi mathsize="80%">𝑳</mml:mi><mml:mrow><mml:mtext mathsize="80%">full</mml:mtext><mml:mo mathsize="80%" stretchy="false">,</mml:mo><mml:mrow><mml:mi mathsize="80%">o</mml:mi><mml:mo mathsize="80%" stretchy="false">×</mml:mo><mml:mrow><mml:mo maxsize="80%" minsize="80%">(</mml:mo><mml:mrow><mml:mi mathsize="80%">d</mml:mi><mml:mo mathsize="80%" stretchy="false">-</mml:mo><mml:mi mathsize="80%">o</mml:mi></mml:mrow><mml:mo maxsize="80%" minsize="80%">)</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:msub><mml:mo>⁢</mml:mo><mml:msup><mml:mrow><mml:mo>(</mml:mo><mml:msub><mml:mi mathsize="80%">𝑳</mml:mi><mml:mrow><mml:mtext mathsize="80%">full</mml:mtext><mml:mo mathsize="80%" stretchy="false">,</mml:mo><mml:mrow><mml:mrow><mml:mo maxsize="80%" minsize="80%">(</mml:mo><mml:mrow><mml:mi mathsize="80%">d</mml:mi><mml:mo mathsize="80%" stretchy="false">-</mml:mo><mml:mi mathsize="80%">o</mml:mi></mml:mrow><mml:mo maxsize="80%" minsize="80%">)</mml:mo></mml:mrow><mml:mo mathsize="80%" stretchy="false">×</mml:mo><mml:mrow><mml:mo maxsize="80%" minsize="80%">(</mml:mo><mml:mrow><mml:mi mathsize="80%">d</mml:mi><mml:mo mathsize="80%" stretchy="false">-</mml:mo><mml:mi mathsize="80%">o</mml:mi></mml:mrow><mml:mo maxsize="80%" minsize="80%">)</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:msub><mml:mo>)</mml:mo></mml:mrow><mml:mrow><mml:mo mathsize="80%" stretchy="false">-</mml:mo><mml:mn mathsize="80%">1</mml:mn></mml:mrow></mml:msup><mml:mo>⁢</mml:mo><mml:msub><mml:mi mathsize="80%">𝑳</mml:mi><mml:mrow><mml:mtext mathsize="80%">full</mml:mtext><mml:mo mathsize="80%" stretchy="false">,</mml:mo><mml:mrow><mml:mrow><mml:mo maxsize="80%" minsize="80%">(</mml:mo><mml:mrow><mml:mi mathsize="80%">d</mml:mi><mml:mo mathsize="80%" stretchy="false">-</mml:mo><mml:mi mathsize="80%">o</mml:mi></mml:mrow><mml:mo maxsize="80%" minsize="80%">)</mml:mo></mml:mrow><mml:mo mathsize="80%" stretchy="false">×</mml:mo><mml:mi mathsize="80%">o</mml:mi></mml:mrow></mml:mrow></mml:msub></mml:mrow></mml:mrow></mml:mrow><mml:mo mathsize="80%" stretchy="false">.</mml:mo></mml:mrow></mml:math></disp-formula></p><p>See also <xref ref-type="bibr" rid="bib19">Hanks and Hooten, 2013</xref>, <xref ref-type="bibr" rid="bib42">Petkova et al., 2016</xref>. Since every term in <xref ref-type="disp-formula" rid="equ33">Equation (16)</xref> has sparse + rank-1 structure, the matrix multiplications can be performed fast. In addition, for the term <inline-formula><mml:math id="inf308"><mml:msup><mml:mrow><mml:mo>(</mml:mo><mml:msub><mml:mi mathsize="80%" mathvariant="bold-italic">𝑳</mml:mi><mml:mrow><mml:mtext mathsize="80%">full</mml:mtext><mml:mo mathsize="80%" stretchy="false">,</mml:mo><mml:mrow><mml:mrow><mml:mo maxsize="80%" minsize="80%">(</mml:mo><mml:mrow><mml:mi mathsize="80%">d</mml:mi><mml:mo mathsize="80%" stretchy="false">-</mml:mo><mml:mi mathsize="80%">o</mml:mi></mml:mrow><mml:mo maxsize="80%" minsize="80%">)</mml:mo></mml:mrow><mml:mo mathsize="80%" stretchy="false">×</mml:mo><mml:mrow><mml:mo maxsize="80%" minsize="80%">(</mml:mo><mml:mrow><mml:mi mathsize="80%">d</mml:mi><mml:mo mathsize="80%" stretchy="false">-</mml:mo><mml:mi mathsize="80%">o</mml:mi></mml:mrow><mml:mo maxsize="80%" minsize="80%">)</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:msub><mml:mo>)</mml:mo></mml:mrow><mml:mrow><mml:mo mathsize="80%" stretchy="false">-</mml:mo><mml:mn mathsize="80%">1</mml:mn></mml:mrow></mml:msup></mml:math></inline-formula>, we can use the Sherman-Morrison formula so that the inverse is given explicitly by<disp-formula id="equ34"><mml:math id="m34"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mtable columnalign="left left" columnspacing="1em" rowspacing="4pt"><mml:mtr><mml:mtd><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msup><mml:mrow><mml:mo>(</mml:mo><mml:msub><mml:mi mathvariant="bold-italic">L</mml:mi><mml:mrow><mml:mtext>full</mml:mtext><mml:mo>,</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mi>d</mml:mi><mml:mo>−</mml:mo><mml:mi>o</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>×</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mi>d</mml:mi><mml:mo>−</mml:mo><mml:mi>o</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msub><mml:mo>)</mml:mo></mml:mrow><mml:mrow><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msup></mml:mstyle></mml:mtd><mml:mtd><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mo>=</mml:mo><mml:msup><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi mathvariant="bold-italic">L</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>d</mml:mi><mml:mo>−</mml:mo><mml:mi>o</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>×</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mi>d</mml:mi><mml:mo>−</mml:mo><mml:mi>o</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:mfrac><mml:mrow><mml:mn mathvariant="bold">1</mml:mn><mml:msup><mml:mn mathvariant="bold">1</mml:mn><mml:mrow><mml:mi mathvariant="normal">⊤</mml:mi></mml:mrow></mml:msup></mml:mrow><mml:mi>d</mml:mi></mml:mfrac></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mrow><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msup></mml:mstyle></mml:mtd></mml:mtr><mml:mtr><mml:mtd/><mml:mtd><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mo>=</mml:mo><mml:msubsup><mml:mi mathvariant="bold-italic">L</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>d</mml:mi><mml:mo>−</mml:mo><mml:mi>o</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>×</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mi>d</mml:mi><mml:mo>−</mml:mo><mml:mi>o</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mrow><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msubsup><mml:mo>−</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mrow><mml:mi>d</mml:mi><mml:mo>+</mml:mo><mml:msup><mml:mn mathvariant="bold">1</mml:mn><mml:mrow><mml:mi mathvariant="normal">⊤</mml:mi></mml:mrow></mml:msup><mml:msubsup><mml:mi mathvariant="bold-italic">L</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>d</mml:mi><mml:mo>−</mml:mo><mml:mi>o</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>×</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mi>d</mml:mi><mml:mo>−</mml:mo><mml:mi>o</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mrow><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msubsup><mml:mn mathvariant="bold">1</mml:mn></mml:mrow></mml:mfrac><mml:msubsup><mml:mi mathvariant="bold-italic">L</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>d</mml:mi><mml:mo>−</mml:mo><mml:mi>o</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>×</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mi>d</mml:mi><mml:mo>−</mml:mo><mml:mi>o</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mrow><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msubsup><mml:mn mathvariant="bold">1</mml:mn><mml:msup><mml:mn mathvariant="bold">1</mml:mn><mml:mrow><mml:mi mathvariant="normal">⊤</mml:mi></mml:mrow></mml:msup><mml:msubsup><mml:mi mathvariant="bold-italic">L</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>d</mml:mi><mml:mo>−</mml:mo><mml:mi>o</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>×</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mi>d</mml:mi><mml:mo>−</mml:mo><mml:mi>o</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mrow><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msubsup><mml:mo>.</mml:mo></mml:mstyle></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:mstyle></mml:math></disp-formula></p><p>Hence, in order to compute <inline-formula><mml:math id="inf309"><mml:mrow><mml:msup><mml:mrow><mml:mo>(</mml:mo><mml:msub><mml:mi mathsize="80%" mathvariant="bold-italic">𝑳</mml:mi><mml:mrow><mml:mtext mathsize="80%">full</mml:mtext><mml:mo mathsize="80%" stretchy="false">,</mml:mo><mml:mrow><mml:mrow><mml:mo maxsize="80%" minsize="80%">(</mml:mo><mml:mrow><mml:mi mathsize="80%">d</mml:mi><mml:mo mathsize="80%" stretchy="false">-</mml:mo><mml:mi mathsize="80%">o</mml:mi></mml:mrow><mml:mo maxsize="80%" minsize="80%">)</mml:mo></mml:mrow><mml:mo mathsize="80%" stretchy="false">×</mml:mo><mml:mrow><mml:mo maxsize="80%" minsize="80%">(</mml:mo><mml:mrow><mml:mi mathsize="80%">d</mml:mi><mml:mo mathsize="80%" stretchy="false">-</mml:mo><mml:mi mathsize="80%">o</mml:mi></mml:mrow><mml:mo maxsize="80%" minsize="80%">)</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:msub><mml:mo>)</mml:mo></mml:mrow><mml:mrow><mml:mo mathsize="80%" stretchy="false">-</mml:mo><mml:mn mathsize="80%">1</mml:mn></mml:mrow></mml:msup><mml:mo>⁢</mml:mo><mml:msub><mml:mi mathsize="80%" mathvariant="bold-italic">𝑳</mml:mi><mml:mrow><mml:mtext mathsize="80%">full</mml:mtext><mml:mo mathsize="80%" stretchy="false">,</mml:mo><mml:mrow><mml:mrow><mml:mo maxsize="80%" minsize="80%">(</mml:mo><mml:mrow><mml:mi mathsize="80%">d</mml:mi><mml:mo mathsize="80%" stretchy="false">-</mml:mo><mml:mi mathsize="80%">o</mml:mi></mml:mrow><mml:mo maxsize="80%" minsize="80%">)</mml:mo></mml:mrow><mml:mo mathsize="80%" stretchy="false">×</mml:mo><mml:mi mathsize="80%">o</mml:mi></mml:mrow></mml:mrow></mml:msub></mml:mrow></mml:math></inline-formula>, we need to solve two systems of linear equations:<disp-formula id="equ35"><mml:math id="m35"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi mathvariant="bold-italic">L</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>d</mml:mi><mml:mo>−</mml:mo><mml:mi>o</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>×</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mi>d</mml:mi><mml:mo>−</mml:mo><mml:mi>o</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msub><mml:mi mathvariant="bold-italic">U</mml:mi><mml:mo>=</mml:mo><mml:msub><mml:mi mathvariant="bold-italic">L</mml:mi><mml:mrow><mml:mtext>full</mml:mtext><mml:mo>,</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mi>d</mml:mi><mml:mo>−</mml:mo><mml:mi>o</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>×</mml:mo><mml:mi>o</mml:mi></mml:mrow></mml:msub><mml:mtext> and </mml:mtext><mml:msub><mml:mi mathvariant="bold-italic">L</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>d</mml:mi><mml:mo>−</mml:mo><mml:mi>o</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>×</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mi>d</mml:mi><mml:mo>−</mml:mo><mml:mi>o</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msub><mml:mi mathvariant="bold-italic">u</mml:mi><mml:mo>=</mml:mo><mml:mn mathvariant="bold">1</mml:mn><mml:mo>.</mml:mo></mml:mrow></mml:mstyle></mml:math></disp-formula></p><p>Note that the matrix <inline-formula><mml:math id="inf310"><mml:msub><mml:mi mathsize="80%" mathvariant="bold-italic">𝑳</mml:mi><mml:mrow><mml:mrow><mml:mo maxsize="80%" minsize="80%">(</mml:mo><mml:mrow><mml:mi mathsize="80%">d</mml:mi><mml:mo mathsize="80%" stretchy="false">-</mml:mo><mml:mi mathsize="80%">o</mml:mi></mml:mrow><mml:mo maxsize="80%" minsize="80%">)</mml:mo></mml:mrow><mml:mo mathsize="80%" stretchy="false">×</mml:mo><mml:mrow><mml:mo maxsize="80%" minsize="80%">(</mml:mo><mml:mrow><mml:mi mathsize="80%">d</mml:mi><mml:mo mathsize="80%" stretchy="false">-</mml:mo><mml:mi mathsize="80%">o</mml:mi></mml:mrow><mml:mo maxsize="80%" minsize="80%">)</mml:mo></mml:mrow></mml:mrow></mml:msub></mml:math></inline-formula> is sparse, so both systems can be solved efficiently by performing sparse Cholesky factorization on <inline-formula><mml:math id="inf311"><mml:msub><mml:mi mathsize="80%" mathvariant="bold-italic">𝑳</mml:mi><mml:mrow><mml:mrow><mml:mo maxsize="80%" minsize="80%">(</mml:mo><mml:mrow><mml:mi mathsize="80%">d</mml:mi><mml:mo mathsize="80%" stretchy="false">-</mml:mo><mml:mi mathsize="80%">o</mml:mi></mml:mrow><mml:mo maxsize="80%" minsize="80%">)</mml:mo></mml:mrow><mml:mo mathsize="80%" stretchy="false">×</mml:mo><mml:mrow><mml:mo maxsize="80%" minsize="80%">(</mml:mo><mml:mrow><mml:mi mathsize="80%">d</mml:mi><mml:mo mathsize="80%" stretchy="false">-</mml:mo><mml:mi mathsize="80%">o</mml:mi></mml:mrow><mml:mo maxsize="80%" minsize="80%">)</mml:mo></mml:mrow></mml:mrow></mml:msub></mml:math></inline-formula> (<xref ref-type="bibr" rid="bib19">Hanks and Hooten, 2013</xref>). Alternatively, one can implement fast Laplacian solvers (<xref ref-type="bibr" rid="bib54">Vishnoi, 2013</xref>) that solve the Laplacian system in time nearly linear in the dimension <inline-formula><mml:math id="inf312"><mml:mrow><mml:mi class="ltx_font_mathcaligraphic" mathsize="80%">𝒪</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo maxsize="80%" minsize="80%">(</mml:mo><mml:mi mathsize="80%">d</mml:mi><mml:mo maxsize="80%" minsize="80%">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula>. After we obtain <inline-formula><mml:math id="inf313"><mml:msup><mml:mrow><mml:mo>[</mml:mo><mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:msubsup><mml:mi mathsize="80%" mathvariant="bold-italic">𝑳</mml:mi><mml:mtext mathsize="80%">full</mml:mtext><mml:mrow><mml:mo mathsize="80%" stretchy="false">-</mml:mo><mml:mn mathsize="80%">1</mml:mn></mml:mrow></mml:msubsup><mml:mo>)</mml:mo></mml:mrow><mml:mrow><mml:mi mathsize="80%">o</mml:mi><mml:mo mathsize="80%" stretchy="false">×</mml:mo><mml:mi mathsize="80%">o</mml:mi></mml:mrow></mml:msub><mml:mo>]</mml:mo></mml:mrow><mml:mrow><mml:mo mathsize="80%" stretchy="false">-</mml:mo><mml:mn mathsize="80%">1</mml:mn></mml:mrow></mml:msup></mml:math></inline-formula> via sparse + rank-1 matrix multiplication and sparse Cholesky factorization, we can invert the <inline-formula><mml:math id="inf314"><mml:mrow><mml:mi mathsize="80%">o</mml:mi><mml:mo mathsize="80%" stretchy="false">×</mml:mo><mml:mi mathsize="80%">o</mml:mi></mml:mrow></mml:math></inline-formula> matrix to get <inline-formula><mml:math id="inf315"><mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:msubsup><mml:mi mathsize="80%" mathvariant="bold-italic">𝑳</mml:mi><mml:mtext mathsize="80%">full</mml:mtext><mml:mrow><mml:mo mathsize="80%" stretchy="false">-</mml:mo><mml:mn mathsize="80%">1</mml:mn></mml:mrow></mml:msubsup><mml:mo>)</mml:mo></mml:mrow><mml:mrow><mml:mi mathsize="80%">o</mml:mi><mml:mo mathsize="80%" stretchy="false">×</mml:mo><mml:mi mathsize="80%">o</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula>.</p></sec><sec id="s9-3"><title>3. Computing <inline-formula><mml:math id="inf316"><mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:msubsup><mml:mi mathvariant="bold-italic">𝑳</mml:mi><mml:mtext>full</mml:mtext><mml:mrow><mml:mo>-</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msubsup><mml:mo>)</mml:mo></mml:mrow><mml:mrow><mml:mi>d</mml:mi><mml:mo>×</mml:mo><mml:mi>o</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula></title><p>We write<disp-formula id="equ36"><mml:math id="m36"><mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:msubsup><mml:mi mathsize="80%">𝑳</mml:mi><mml:mtext mathsize="80%">full</mml:mtext><mml:mrow><mml:mo mathsize="80%" stretchy="false">-</mml:mo><mml:mn mathsize="80%">1</mml:mn></mml:mrow></mml:msubsup><mml:mo>)</mml:mo></mml:mrow><mml:mrow><mml:mi mathsize="80%">d</mml:mi><mml:mo mathsize="80%" stretchy="false">×</mml:mo><mml:mi mathsize="80%">o</mml:mi></mml:mrow></mml:msub><mml:mo mathsize="80%" stretchy="false">=</mml:mo><mml:mrow><mml:mo>[</mml:mo><mml:mtable displaystyle="true" rowspacing="0pt"><mml:mtr><mml:mtd columnalign="center"><mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:msubsup><mml:mi mathsize="80%">𝑳</mml:mi><mml:mtext mathsize="80%">full</mml:mtext><mml:mrow><mml:mo mathsize="80%" stretchy="false">-</mml:mo><mml:mn mathsize="80%">1</mml:mn></mml:mrow></mml:msubsup><mml:mo>)</mml:mo></mml:mrow><mml:mrow><mml:mi mathsize="80%">o</mml:mi><mml:mo mathsize="80%" stretchy="false">×</mml:mo><mml:mi mathsize="80%">o</mml:mi></mml:mrow></mml:msub></mml:mtd></mml:mtr><mml:mtr><mml:mtd columnalign="center"><mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:msubsup><mml:mi mathsize="80%">𝑳</mml:mi><mml:mtext mathsize="80%">full</mml:mtext><mml:mrow><mml:mo mathsize="80%" stretchy="false">-</mml:mo><mml:mn mathsize="80%">1</mml:mn></mml:mrow></mml:msubsup><mml:mo>)</mml:mo></mml:mrow><mml:mrow><mml:mrow><mml:mo maxsize="80%" minsize="80%">(</mml:mo><mml:mrow><mml:mi mathsize="80%">d</mml:mi><mml:mo mathsize="80%" stretchy="false">-</mml:mo><mml:mi mathsize="80%">o</mml:mi></mml:mrow><mml:mo maxsize="80%" minsize="80%">)</mml:mo></mml:mrow><mml:mo mathsize="80%" stretchy="false">×</mml:mo><mml:mi mathsize="80%">o</mml:mi></mml:mrow></mml:msub></mml:mtd></mml:mtr></mml:mtable><mml:mo>]</mml:mo></mml:mrow></mml:mrow><mml:mo mathsize="80%" stretchy="false">.</mml:mo></mml:mrow></mml:math></disp-formula></p><p>Using the inversion of the matrix in a block form, the <inline-formula><mml:math id="inf317"><mml:mrow><mml:mrow><mml:mo maxsize="80%" minsize="80%">(</mml:mo><mml:mrow><mml:mi mathsize="80%">d</mml:mi><mml:mo mathsize="80%" stretchy="false">-</mml:mo><mml:mi mathsize="80%">o</mml:mi></mml:mrow><mml:mo maxsize="80%" minsize="80%">)</mml:mo></mml:mrow><mml:mo mathsize="80%" stretchy="false">×</mml:mo><mml:mi mathsize="80%">o</mml:mi></mml:mrow></mml:math></inline-formula> block component is given by<disp-formula id="equ37"><label>(17)</label><mml:math id="m37"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:msubsup><mml:mi mathvariant="bold-italic">L</mml:mi><mml:mrow><mml:mtext>full</mml:mtext></mml:mrow><mml:mrow><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msubsup><mml:mo>)</mml:mo></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>d</mml:mi><mml:mo>−</mml:mo><mml:mi>o</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>×</mml:mo><mml:mi>o</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mo>−</mml:mo><mml:munder><mml:mrow><mml:munder><mml:mrow><mml:msup><mml:mrow><mml:mo>(</mml:mo><mml:msub><mml:mi mathvariant="bold-italic">L</mml:mi><mml:mrow><mml:mtext>full</mml:mtext><mml:mo>,</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mi>d</mml:mi><mml:mo>−</mml:mo><mml:mi>o</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>×</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mi>d</mml:mi><mml:mo>−</mml:mo><mml:mi>o</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msub><mml:mo>)</mml:mo></mml:mrow><mml:mrow><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msup><mml:msub><mml:mi mathvariant="bold-italic">L</mml:mi><mml:mrow><mml:mtext>full</mml:mtext><mml:mo>,</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mi>d</mml:mi><mml:mo>−</mml:mo><mml:mi>o</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>×</mml:mo><mml:mi>o</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo stretchy="true">⏟</mml:mo></mml:munder></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi mathvariant="normal">A</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:munder><mml:munder><mml:mrow><mml:munder><mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:msubsup><mml:mi mathvariant="bold-italic">L</mml:mi><mml:mrow><mml:mtext>full</mml:mtext></mml:mrow><mml:mrow><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msubsup><mml:mo>)</mml:mo></mml:mrow><mml:mrow><mml:mi>o</mml:mi><mml:mo>×</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:msub><mml:mo stretchy="true">⏟</mml:mo></mml:munder></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi mathvariant="normal">B</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:munder></mml:mrow></mml:mstyle></mml:math></disp-formula></p><p>Since each of the two terms (A) and (B) has been already computed in the previous step, there is no need to recompute them. In total, it requires a <inline-formula><mml:math id="inf318"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>d</mml:mi><mml:mo>−</mml:mo><mml:mi>o</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>×</mml:mo><mml:mi>o</mml:mi></mml:mrow></mml:mstyle></mml:math></inline-formula> matrix and <inline-formula><mml:math id="inf319"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>o</mml:mi><mml:mo>×</mml:mo><mml:mi>o</mml:mi></mml:mrow></mml:mstyle></mml:math></inline-formula> matrix multiplication.</p></sec><sec id="s9-4"><title>4. Computing the full gradient</title><p>Going back to the expression of <inline-formula><mml:math id="inf320"><mml:mrow><mml:mrow><mml:mo mathsize="80%" stretchy="false">∇</mml:mo><mml:mo>⁡</mml:mo><mml:mi mathsize="80%" mathvariant="normal">ℓ</mml:mi></mml:mrow><mml:mo>⁢</mml:mo><mml:mrow><mml:mo maxsize="80%" minsize="80%">(</mml:mo><mml:mi mathsize="80%" mathvariant="bold-italic">𝒘</mml:mi><mml:mo maxsize="80%" minsize="80%">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> in <xref ref-type="disp-formula" rid="equ29">Equation (13)</xref>, and noting the block structure of the assignment matrix <inline-formula><mml:math id="inf321"><mml:mi mathsize="80%" mathvariant="bold-italic">𝑨</mml:mi></mml:math></inline-formula>, we have:<disp-formula id="equ38"><mml:math id="m38"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mfrac><mml:mrow><mml:mi mathvariant="normal">∂</mml:mi><mml:mi>ℓ</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi mathvariant="bold-italic">w</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mrow><mml:mi mathvariant="normal">∂</mml:mi><mml:mtext>vec</mml:mtext><mml:mo stretchy="false">(</mml:mo><mml:mi mathvariant="bold-italic">L</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mfrac><mml:mo>=</mml:mo><mml:mi>p</mml:mi><mml:mo>⋅</mml:mo><mml:mtext>vec</mml:mtext><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:msubsup><mml:mi mathvariant="bold-italic">L</mml:mi><mml:mrow><mml:mtext>full</mml:mtext></mml:mrow><mml:mrow><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msubsup><mml:mo>)</mml:mo></mml:mrow><mml:mrow><mml:mi>d</mml:mi><mml:mo>×</mml:mo><mml:mi>o</mml:mi></mml:mrow></mml:msub><mml:mi mathvariant="bold-italic">M</mml:mi><mml:msubsup><mml:mrow><mml:mo>(</mml:mo><mml:msubsup><mml:mi mathvariant="bold-italic">L</mml:mi><mml:mrow><mml:mtext>full</mml:mtext></mml:mrow><mml:mrow><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msubsup><mml:mo>)</mml:mo></mml:mrow><mml:mrow><mml:mi>d</mml:mi><mml:mo>×</mml:mo><mml:mi>o</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">⊤</mml:mi></mml:mrow></mml:msubsup></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>.</mml:mo></mml:mrow></mml:mstyle></mml:math></disp-formula></p><p>Define <inline-formula><mml:math id="inf322"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi mathvariant="normal">Π</mml:mi><mml:mrow><mml:mn mathvariant="bold">1</mml:mn></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mn mathvariant="bold">1</mml:mn><mml:msup><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msup><mml:mn mathvariant="bold">1</mml:mn><mml:mrow><mml:mi mathvariant="normal">⊤</mml:mi></mml:mrow></mml:msup><mml:msup><mml:mi mathvariant="bold">Σ</mml:mi><mml:mrow><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msup><mml:mn mathvariant="bold">1</mml:mn></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mrow><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msup><mml:msup><mml:mn mathvariant="bold">1</mml:mn><mml:mrow><mml:mi mathvariant="normal">⊤</mml:mi></mml:mrow></mml:msup><mml:msup><mml:mi mathvariant="bold">Σ</mml:mi><mml:mrow><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:mstyle></mml:math></inline-formula> which acts as a sort of projection to the space of constant vectors with respect to the inner product <inline-formula><mml:math id="inf323"><mml:mrow><mml:mrow><mml:mo maxsize="80%" minsize="80%">⟨</mml:mo><mml:mi mathsize="80%" mathvariant="bold-italic">𝒙</mml:mi><mml:mo mathsize="80%" stretchy="false">,</mml:mo><mml:mi mathsize="80%" mathvariant="bold-italic">𝒚</mml:mi><mml:mo maxsize="80%" minsize="80%">⟩</mml:mo></mml:mrow><mml:mo mathsize="80%" stretchy="false">=</mml:mo><mml:mrow><mml:msup><mml:mi mathsize="80%" mathvariant="bold-italic">𝒙</mml:mi><mml:mo mathsize="80%" stretchy="false">⊤</mml:mo></mml:msup><mml:mo>⁢</mml:mo><mml:msup><mml:mi mathsize="80%" mathvariant="bold">𝚺</mml:mi><mml:mrow><mml:mo mathsize="80%" stretchy="false">-</mml:mo><mml:mn mathsize="80%">1</mml:mn></mml:mrow></mml:msup><mml:mo>⁢</mml:mo><mml:mi mathsize="80%" mathvariant="bold-italic">𝒚</mml:mi></mml:mrow></mml:mrow></mml:math></inline-formula>. Using the identity <inline-formula><mml:math id="inf324"><mml:mrow><mml:mrow><mml:mi mathsize="80%" mathvariant="bold">𝐈</mml:mi><mml:mo mathsize="80%" stretchy="false">-</mml:mo><mml:msub><mml:mi mathsize="80%" mathvariant="bold">𝚷</mml:mi><mml:mn mathsize="80%">𝟏</mml:mn></mml:msub></mml:mrow><mml:mo mathsize="80%" stretchy="false">=</mml:mo><mml:mrow><mml:mi mathsize="80%" mathvariant="bold">𝚺</mml:mi><mml:mo>⁢</mml:mo><mml:msup><mml:mi mathsize="80%" mathvariant="bold-italic">𝑪</mml:mi><mml:mo mathsize="80%" stretchy="false">⊤</mml:mo></mml:msup><mml:mo>⁢</mml:mo><mml:msup><mml:mrow><mml:mo maxsize="80%" minsize="80%">(</mml:mo><mml:mrow><mml:mi mathsize="80%" mathvariant="bold-italic">𝑪</mml:mi><mml:mo>⁢</mml:mo><mml:mi mathsize="80%" mathvariant="bold">𝚺</mml:mi><mml:mo>⁢</mml:mo><mml:msup><mml:mi mathsize="80%" mathvariant="bold-italic">𝑪</mml:mi><mml:mo mathsize="80%" stretchy="false">⊤</mml:mo></mml:msup></mml:mrow><mml:mo maxsize="80%" minsize="80%">)</mml:mo></mml:mrow><mml:mrow><mml:mo mathsize="80%" stretchy="false">-</mml:mo><mml:mn mathsize="80%">1</mml:mn></mml:mrow></mml:msup><mml:mo>⁢</mml:mo><mml:mi mathsize="80%" mathvariant="bold-italic">𝑪</mml:mi></mml:mrow></mml:mrow></mml:math></inline-formula> (<xref ref-type="bibr" rid="bib32">McCullagh, 2009</xref>), then we can write <inline-formula><mml:math id="inf325"><mml:mi mathsize="80%" mathvariant="bold-italic">𝑴</mml:mi></mml:math></inline-formula> in terms of <inline-formula><mml:math id="inf326"><mml:msub><mml:mi mathsize="80%" mathvariant="bold">𝚷</mml:mi><mml:mn mathsize="80%">𝟏</mml:mn></mml:msub></mml:math></inline-formula>:<disp-formula id="equ39"><label>(18)</label><mml:math id="m39"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi mathvariant="bold-italic">M</mml:mi><mml:mo>=</mml:mo><mml:msup><mml:mi mathvariant="bold">Σ</mml:mi><mml:mrow><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msup><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mrow><mml:mi mathvariant="bold">I</mml:mi></mml:mrow><mml:mo>−</mml:mo><mml:msub><mml:mi mathvariant="bold">Π</mml:mi><mml:mrow><mml:mn mathvariant="bold">1</mml:mn></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mrow><mml:mover><mml:mi mathvariant="bold">Σ</mml:mi><mml:mo>^</mml:mo></mml:mover></mml:mrow><mml:msup><mml:mi mathvariant="bold">Σ</mml:mi><mml:mrow><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msup><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mrow><mml:mi mathvariant="bold">I</mml:mi></mml:mrow><mml:mo>−</mml:mo><mml:msub><mml:mi mathvariant="bold">Π</mml:mi><mml:mrow><mml:mn mathvariant="bold">1</mml:mn></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>−</mml:mo><mml:msup><mml:mi mathvariant="bold">Σ</mml:mi><mml:mrow><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msup><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mrow><mml:mi mathvariant="bold">I</mml:mi></mml:mrow><mml:mo>−</mml:mo><mml:msub><mml:mi mathvariant="bold">Π</mml:mi><mml:mrow><mml:mn mathvariant="bold">1</mml:mn></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>.</mml:mo></mml:mstyle></mml:mrow></mml:mstyle></mml:math></disp-formula></p><p>Since <inline-formula><mml:math id="inf327"><mml:msub><mml:mi mathsize="80%" mathvariant="normal">Π</mml:mi><mml:mn mathsize="80%">𝟏</mml:mn></mml:msub></mml:math></inline-formula> is a rank-1 matrix, this expression of <inline-formula><mml:math id="inf328"><mml:mi mathsize="80%" mathvariant="bold-italic">𝑴</mml:mi></mml:math></inline-formula> allows easier computation. Finally we can put together <xref ref-type="disp-formula" rid="equ31">Equation (14)</xref>, <xref ref-type="disp-formula" rid="equ32">Equation (15)</xref>, <xref ref-type="disp-formula" rid="equ37">Equation (17)</xref>, and <xref ref-type="disp-formula" rid="equ39">Equation (18)</xref>, to compute the gradient of the negative log-likelihood function with respect to the graph Laplacian.</p></sec></sec><sec id="s10" sec-type="appendix"><title>Objective computation</title><p>The graph Laplacian <inline-formula><mml:math id="inf329"><mml:mi mathsize="80%" mathvariant="bold-italic">𝑳</mml:mi></mml:math></inline-formula> is orthogonal to the one vector 1, so using the notation introduced in <xref ref-type="disp-formula" rid="equ26">Equation (12)</xref>, we can express our objective function as<disp-formula id="equ40"><mml:math id="m40"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>ℓ</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi mathvariant="bold-italic">w</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>+</mml:mo><mml:msub><mml:mi>ϕ</mml:mi><mml:mrow><mml:mi>λ</mml:mi><mml:mo>,</mml:mo><mml:mi>α</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi mathvariant="bold-italic">w</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mi>p</mml:mi><mml:mo>⋅</mml:mo><mml:mtext>tr</mml:mtext><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msup><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi mathvariant="bold-italic">C</mml:mi><mml:mi mathvariant="bold">Σ</mml:mi><mml:msup><mml:mi mathvariant="bold-italic">C</mml:mi><mml:mrow><mml:mi mathvariant="normal">⊤</mml:mi></mml:mrow></mml:msup></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mrow><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msup><mml:mi mathvariant="bold-italic">C</mml:mi><mml:mrow><mml:mover><mml:mi mathvariant="bold">Σ</mml:mi><mml:mo>^</mml:mo></mml:mover></mml:mrow><mml:msup><mml:mi mathvariant="bold-italic">C</mml:mi><mml:mrow><mml:mi mathvariant="normal">⊤</mml:mi></mml:mrow></mml:msup></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>−</mml:mo><mml:mi>p</mml:mi><mml:mo>⋅</mml:mo><mml:mi>log</mml:mi><mml:mo>⁡</mml:mo><mml:mo form="prefix" movablelimits="true">det</mml:mo><mml:msup><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi mathvariant="bold-italic">C</mml:mi><mml:mi mathvariant="bold">Σ</mml:mi><mml:mi mathvariant="bold-italic">C</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mrow><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msup><mml:mo>+</mml:mo><mml:mfrac><mml:mi>λ</mml:mi><mml:mn>2</mml:mn></mml:mfrac><mml:msubsup><mml:mrow><mml:mo symmetric="true">‖</mml:mo><mml:mrow><mml:mi mathvariant="bold">Δ</mml:mi><mml:mi>log</mml:mi><mml:mo>⁡</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:msup><mml:mi>e</mml:mi><mml:mrow><mml:mi>α</mml:mi><mml:mi mathvariant="bold-italic">w</mml:mi></mml:mrow></mml:msup><mml:mo>−</mml:mo><mml:mn mathvariant="bold">1</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo symmetric="true">‖</mml:mo></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup><mml:mo>.</mml:mo></mml:mrow></mml:mstyle></mml:math></disp-formula></p><p>With the identity <inline-formula><mml:math id="inf330"><mml:mrow><mml:mrow><mml:mi mathsize="80%" mathvariant="bold">𝐈</mml:mi><mml:mo mathsize="80%" stretchy="false">-</mml:mo><mml:msub><mml:mi mathsize="80%" mathvariant="bold">𝚷</mml:mi><mml:mn mathsize="80%">𝟏</mml:mn></mml:msub></mml:mrow><mml:mo mathsize="80%" stretchy="false">=</mml:mo><mml:mrow><mml:mi mathsize="80%" mathvariant="bold">𝚺</mml:mi><mml:mo>⁢</mml:mo><mml:msup><mml:mi mathsize="80%" mathvariant="bold-italic">𝑪</mml:mi><mml:mo mathsize="80%" stretchy="false">⊤</mml:mo></mml:msup><mml:mo>⁢</mml:mo><mml:msup><mml:mrow><mml:mo maxsize="80%" minsize="80%">(</mml:mo><mml:mrow><mml:mi mathsize="80%" mathvariant="bold-italic">𝑪</mml:mi><mml:mo>⁢</mml:mo><mml:mi mathsize="80%" mathvariant="bold">𝚺</mml:mi><mml:mo>⁢</mml:mo><mml:msup><mml:mi mathsize="80%" mathvariant="bold-italic">𝑪</mml:mi><mml:mo mathsize="80%" stretchy="false">⊤</mml:mo></mml:msup></mml:mrow><mml:mo maxsize="80%" minsize="80%">)</mml:mo></mml:mrow><mml:mrow><mml:mo mathsize="80%" stretchy="false">-</mml:mo><mml:mn mathsize="80%">1</mml:mn></mml:mrow></mml:msup><mml:mo>⁢</mml:mo><mml:mi mathsize="80%" mathvariant="bold-italic">𝑪</mml:mi></mml:mrow></mml:mrow></mml:math></inline-formula>, the trace term is:<disp-formula id="equ41"><mml:math id="m41"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mtext>tr</mml:mtext><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msup><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi mathvariant="bold-italic">C</mml:mi><mml:mi mathvariant="bold">Σ</mml:mi><mml:msup><mml:mi mathvariant="bold-italic">C</mml:mi><mml:mrow><mml:mi mathvariant="normal">⊤</mml:mi></mml:mrow></mml:msup></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mrow><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msup><mml:mi mathvariant="bold-italic">C</mml:mi><mml:mrow><mml:mover><mml:mi mathvariant="bold">Σ</mml:mi><mml:mo>^</mml:mo></mml:mover></mml:mrow><mml:msup><mml:mi mathvariant="bold-italic">C</mml:mi><mml:mrow><mml:mi mathvariant="normal">⊤</mml:mi></mml:mrow></mml:msup></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mtext>tr</mml:mtext><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msup><mml:mi mathvariant="bold-italic">C</mml:mi><mml:mrow><mml:mi mathvariant="normal">⊤</mml:mi></mml:mrow></mml:msup><mml:msup><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi mathvariant="bold-italic">C</mml:mi><mml:mi mathvariant="bold">Σ</mml:mi><mml:msup><mml:mi mathvariant="bold-italic">C</mml:mi><mml:mrow><mml:mi mathvariant="normal">⊤</mml:mi></mml:mrow></mml:msup></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mrow><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msup><mml:mi mathvariant="bold-italic">C</mml:mi><mml:mrow><mml:mover><mml:mi mathvariant="bold">Σ</mml:mi><mml:mo>^</mml:mo></mml:mover></mml:mrow></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mtext>tr</mml:mtext><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msup><mml:mi mathvariant="bold">Σ</mml:mi><mml:mrow><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msup><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mi mathvariant="bold">I</mml:mi></mml:mrow><mml:mo>−</mml:mo><mml:msub><mml:mi mathvariant="bold">Π</mml:mi><mml:mrow><mml:mn mathvariant="bold">1</mml:mn></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:mrow><mml:mover><mml:mi mathvariant="bold">Σ</mml:mi><mml:mo>^</mml:mo></mml:mover></mml:mrow></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>.</mml:mo></mml:mstyle></mml:mrow></mml:mstyle></mml:math></disp-formula></p><p>The matrix inside the trace has been constructed in the gradient computation, see <xref ref-type="disp-formula" rid="equ39">Equation (18)</xref>. In terms of the determinant, we use the same approach considered in <xref ref-type="bibr" rid="bib42">Petkova et al., 2016</xref>—in particular, concatenating <inline-formula><mml:math id="inf331"><mml:msup><mml:mi mathsize="80%" mathvariant="bold-italic">𝑪</mml:mi><mml:mo mathsize="80%" stretchy="false">⊤</mml:mo></mml:msup></mml:math></inline-formula> and <inline-formula><mml:math id="inf332"><mml:mn mathsize="80%">𝟏</mml:mn></mml:math></inline-formula>, the matrix <inline-formula><mml:math id="inf333"><mml:mrow><mml:mo maxsize="80%" minsize="80%">[</mml:mo><mml:mrow><mml:mpadded width="+2.8pt"><mml:msup><mml:mi mathsize="80%" mathvariant="bold-italic">𝑪</mml:mi><mml:mo mathsize="80%" stretchy="false">⊤</mml:mo></mml:msup></mml:mpadded><mml:mo lspace="2.5pt" mathsize="80%" rspace="2.5pt" stretchy="false">|</mml:mo><mml:mn mathsize="80%" mathvariant="bold"> 1</mml:mn></mml:mrow><mml:mo maxsize="80%" minsize="80%">]</mml:mo></mml:mrow></mml:math></inline-formula> is orthogonal, so it can be shown that<disp-formula id="equ42"><mml:math id="m42"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mo form="prefix" movablelimits="true">det</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mi mathvariant="bold">Σ</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mo form="prefix" movablelimits="true">det</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:msup><mml:mn mathvariant="bold">1</mml:mn><mml:mrow><mml:mi mathvariant="normal">⊤</mml:mi></mml:mrow></mml:msup><mml:mn mathvariant="bold">1</mml:mn><mml:mo stretchy="false">)</mml:mo><mml:mo form="prefix" movablelimits="true">det</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mi mathvariant="bold-italic">C</mml:mi><mml:mi mathvariant="bold">Σ</mml:mi><mml:msup><mml:mi mathvariant="bold-italic">C</mml:mi><mml:mrow><mml:mi mathvariant="normal">⊤</mml:mi></mml:mrow></mml:msup><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mrow><mml:mo form="prefix" movablelimits="true">det</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mi mathvariant="bold-italic">C</mml:mi><mml:msup><mml:mi mathvariant="bold-italic">C</mml:mi><mml:mrow><mml:mi mathvariant="normal">⊤</mml:mi></mml:mrow></mml:msup><mml:mo stretchy="false">)</mml:mo><mml:mo form="prefix" movablelimits="true">det</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:msup><mml:mn mathvariant="bold">1</mml:mn><mml:mrow><mml:mi mathvariant="normal">⊤</mml:mi></mml:mrow></mml:msup><mml:msup><mml:mi mathvariant="bold">Σ</mml:mi><mml:mrow><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msup><mml:mn mathvariant="bold">1</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mfrac><mml:mo>.</mml:mo></mml:mrow></mml:mstyle></mml:math></disp-formula></p><p>Rearranging terms and using the fact <inline-formula><mml:math id="inf334"><mml:mrow><mml:mrow><mml:mo mathsize="80%" stretchy="false">det</mml:mo><mml:mo>⁡</mml:mo><mml:mrow><mml:mo maxsize="80%" minsize="80%">(</mml:mo><mml:msup><mml:mi mathsize="80%" mathvariant="bold-italic">𝑼</mml:mi><mml:mrow><mml:mo mathsize="80%" stretchy="false">-</mml:mo><mml:mn mathsize="80%">1</mml:mn></mml:mrow></mml:msup><mml:mo maxsize="80%" minsize="80%">)</mml:mo></mml:mrow></mml:mrow><mml:mo mathsize="80%" stretchy="false">=</mml:mo><mml:mrow><mml:mo mathsize="80%" stretchy="false">det</mml:mo><mml:mo>⁡</mml:mo><mml:msup><mml:mrow><mml:mo maxsize="80%" minsize="80%">(</mml:mo><mml:mi mathsize="80%" mathvariant="bold-italic">𝑼</mml:mi><mml:mo maxsize="80%" minsize="80%">)</mml:mo></mml:mrow><mml:mrow><mml:mo mathsize="80%" stretchy="false">-</mml:mo><mml:mn mathsize="80%">1</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:mrow></mml:math></inline-formula> for any matrix <inline-formula><mml:math id="inf335"><mml:mi mathsize="80%" mathvariant="bold-italic">𝑼</mml:mi></mml:math></inline-formula>, we obtain:<disp-formula id="equ43"><mml:math id="m43"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mo form="prefix" movablelimits="true">det</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mi mathvariant="bold-italic">C</mml:mi><mml:mi mathvariant="bold">Σ</mml:mi><mml:msup><mml:mi mathvariant="bold-italic">C</mml:mi><mml:mrow><mml:mi mathvariant="normal">⊤</mml:mi></mml:mrow></mml:msup><mml:msup><mml:mo stretchy="false">)</mml:mo><mml:mrow><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msup><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mo form="prefix" movablelimits="true">det</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:msup><mml:mn mathvariant="bold">1</mml:mn><mml:mrow><mml:mi mathvariant="normal">⊤</mml:mi></mml:mrow></mml:msup><mml:mn mathvariant="bold">1</mml:mn><mml:mo stretchy="false">)</mml:mo><mml:mo form="prefix" movablelimits="true">det</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:msup><mml:mi mathvariant="bold">Σ</mml:mi><mml:mrow><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msup><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mrow><mml:mo form="prefix" movablelimits="true">det</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mi mathvariant="bold-italic">C</mml:mi><mml:msup><mml:mi mathvariant="bold-italic">C</mml:mi><mml:mrow><mml:mi mathvariant="normal">⊤</mml:mi></mml:mrow></mml:msup><mml:mo stretchy="false">)</mml:mo><mml:mo form="prefix" movablelimits="true">det</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:msup><mml:mn mathvariant="bold">1</mml:mn><mml:mrow><mml:mi mathvariant="normal">⊤</mml:mi></mml:mrow></mml:msup><mml:msup><mml:mi mathvariant="bold">Σ</mml:mi><mml:mrow><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msup><mml:mn mathvariant="bold">1</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mfrac><mml:mo>=</mml:mo><mml:mfrac><mml:mi>o</mml:mi><mml:mrow><mml:msup><mml:mn mathvariant="bold">1</mml:mn><mml:mrow><mml:mi mathvariant="normal">⊤</mml:mi></mml:mrow></mml:msup><mml:msup><mml:mi mathvariant="bold">Σ</mml:mi><mml:mrow><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msup><mml:mn mathvariant="bold">1</mml:mn></mml:mrow></mml:mfrac><mml:mo form="prefix" movablelimits="true">det</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:msup><mml:mi mathvariant="bold">Σ</mml:mi><mml:mrow><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msup><mml:mo stretchy="false">)</mml:mo><mml:mo>.</mml:mo></mml:mrow></mml:mstyle></mml:math></disp-formula></p><p>We have computed <inline-formula><mml:math id="inf336"><mml:msup><mml:mi mathsize="80%" mathvariant="bold">𝚺</mml:mi><mml:mrow><mml:mo mathsize="80%" stretchy="false">-</mml:mo><mml:mn mathsize="80%">1</mml:mn></mml:mrow></mml:msup></mml:math></inline-formula> in <xref ref-type="disp-formula" rid="equ31">Equation (14)</xref>, so each of the terms above can be computed without any additional matrix multiplications. Finally, the signed graph incidence matrix <inline-formula><mml:math id="inf337"><mml:mi mathsize="80%" mathvariant="bold">𝚫</mml:mi></mml:math></inline-formula> defined on the edges of the graph is, by construction, highly sparse with <inline-formula><mml:math id="inf338"><mml:mrow><mml:mi class="ltx_font_mathcaligraphic" mathsize="80%">𝒪</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo maxsize="80%" minsize="80%">(</mml:mo><mml:mi mathsize="80%">d</mml:mi><mml:mo maxsize="80%" minsize="80%">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> many nonzero entries. Hence we implement sparse matrix multiplication to evaluate the penalty function <inline-formula><mml:math id="inf339"><mml:mrow><mml:msub><mml:mi mathsize="80%">ϕ</mml:mi><mml:mrow><mml:mi mathsize="80%">λ</mml:mi><mml:mo mathsize="80%" stretchy="false">,</mml:mo><mml:mi mathsize="80%">α</mml:mi></mml:mrow></mml:msub><mml:mo>⁢</mml:mo><mml:mrow><mml:mo maxsize="80%" minsize="80%">(</mml:mo><mml:mi mathsize="80%" mathvariant="bold-italic">𝒘</mml:mi><mml:mo maxsize="80%" minsize="80%">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> while avoiding the full-dimensional matrix-vector product.</p></sec><sec id="s11" sec-type="appendix"><title>Estimating the edge weights under the exact likelihood model</title><p>When we developed the FEEMS model, we used the approximation <inline-formula><mml:math id="inf340"><mml:mrow><mml:mrow><mml:mfrac><mml:mn mathsize="80%">1</mml:mn><mml:mn mathsize="80%">2</mml:mn></mml:mfrac><mml:mo>⁢</mml:mo><mml:msub><mml:mi mathsize="80%">f</mml:mi><mml:mi mathsize="80%">j</mml:mi></mml:msub><mml:mo>⁢</mml:mo><mml:mrow><mml:mo maxsize="80%" minsize="80%">(</mml:mo><mml:mi mathsize="80%">k</mml:mi><mml:mo maxsize="80%" minsize="80%">)</mml:mo></mml:mrow><mml:mo>⁢</mml:mo><mml:mrow><mml:mo maxsize="80%" minsize="80%">(</mml:mo><mml:mrow><mml:mn mathsize="80%">1</mml:mn><mml:mo mathsize="80%" stretchy="false">-</mml:mo><mml:mrow><mml:msub><mml:mi mathsize="80%">f</mml:mi><mml:mi mathsize="80%">j</mml:mi></mml:msub><mml:mo>⁢</mml:mo><mml:mrow><mml:mo maxsize="80%" minsize="80%">(</mml:mo><mml:mi mathsize="80%">k</mml:mi><mml:mo maxsize="80%" minsize="80%">)</mml:mo></mml:mrow></mml:mrow></mml:mrow><mml:mo maxsize="80%" minsize="80%">)</mml:mo></mml:mrow></mml:mrow><mml:mo mathsize="80%" stretchy="false">≈</mml:mo><mml:mrow><mml:msup><mml:mi mathsize="80%">σ</mml:mi><mml:mn mathsize="80%">2</mml:mn></mml:msup><mml:mo>⁢</mml:mo><mml:msub><mml:mi mathsize="80%">μ</mml:mi><mml:mi mathsize="80%">j</mml:mi></mml:msub><mml:mo>⁢</mml:mo><mml:mrow><mml:mo maxsize="80%" minsize="80%">(</mml:mo><mml:mrow><mml:mn mathsize="80%">1</mml:mn><mml:mo mathsize="80%" stretchy="false">-</mml:mo><mml:msub><mml:mi mathsize="80%">μ</mml:mi><mml:mi mathsize="80%">j</mml:mi></mml:msub></mml:mrow><mml:mo maxsize="80%" minsize="80%">)</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:math></inline-formula> for all SNPs <inline-formula><mml:math id="inf341"><mml:mi mathsize="80%">j</mml:mi></mml:math></inline-formula> and all nodes <inline-formula><mml:math id="inf342"><mml:mi mathsize="80%">k</mml:mi></mml:math></inline-formula> (see <xref ref-type="disp-formula" rid="equ9">Equation 4</xref>) and estimated the residual variance <inline-formula><mml:math id="inf343"><mml:msup><mml:mi mathsize="80%">σ</mml:mi><mml:mn mathsize="80%">2</mml:mn></mml:msup></mml:math></inline-formula> under the homogeneous isolation by distance model. The primary reason of using this approximation was primarily computational. While the approximation is not too strong if SNPs with rare allele frequencies are excluded, it is also critical that the estimation quality of the migration rates is not affected. In this subsection we introduce the inferring procedure of the migration rates under the exact likellihood model and compare it with FEEMS.</p><p>Note that without approximation, we can calculate the exact analytical form for the marginal likelihood of the estimated frequency as follows (after removing the SNP means):<disp-formula id="equ44"><label>(19)</label><mml:math id="m44"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi mathvariant="bold-italic">C</mml:mi><mml:msub><mml:mrow><mml:mover><mml:mi mathvariant="bold-italic">f</mml:mi><mml:mo>^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>∼</mml:mo><mml:msqrt><mml:msub><mml:mi>μ</mml:mi><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:msub><mml:mi>μ</mml:mi><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:msqrt><mml:mo>⋅</mml:mo><mml:msub><mml:mrow><mml:mi mathvariant="script">𝒩</mml:mi></mml:mrow><mml:mrow><mml:mi>o</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mn mathvariant="bold">0</mml:mn><mml:mo>,</mml:mo><mml:mi mathvariant="bold-italic">C</mml:mi><mml:mi mathvariant="bold-italic">A</mml:mi><mml:msup><mml:mi mathvariant="bold-italic">L</mml:mi><mml:mrow><mml:mo>†</mml:mo></mml:mrow></mml:msup><mml:msup><mml:mi mathvariant="bold-italic">A</mml:mi><mml:mrow><mml:mi mathvariant="normal">⊤</mml:mi></mml:mrow></mml:msup><mml:msup><mml:mi mathvariant="bold-italic">C</mml:mi><mml:mrow><mml:mi mathvariant="normal">⊤</mml:mi></mml:mrow></mml:msup><mml:mo>+</mml:mo><mml:mi mathvariant="bold-italic">C</mml:mi><mml:mtext>diag</mml:mtext><mml:mo stretchy="false">(</mml:mo><mml:msup><mml:mi mathvariant="bold-italic">n</mml:mi><mml:mrow><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msup><mml:mo stretchy="false">)</mml:mo><mml:mi mathvariant="bold-italic">A</mml:mi><mml:mtext>diag</mml:mtext><mml:mrow><mml:mo>(</mml:mo><mml:msubsup><mml:mrow><mml:mo>{</mml:mo><mml:mfrac><mml:mrow><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:msubsup><mml:mi>L</mml:mi><mml:mrow><mml:mi>k</mml:mi><mml:mi>k</mml:mi></mml:mrow><mml:mrow><mml:mo>†</mml:mo></mml:mrow></mml:msubsup></mml:mrow><mml:mn>2</mml:mn></mml:mfrac><mml:mo>}</mml:mo></mml:mrow><mml:mrow><mml:mi>k</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>d</mml:mi></mml:mrow></mml:msubsup><mml:mo>)</mml:mo></mml:mrow><mml:msup><mml:mi mathvariant="bold-italic">A</mml:mi><mml:mrow><mml:mi mathvariant="normal">⊤</mml:mi></mml:mrow></mml:msup><mml:msup><mml:mi mathvariant="bold-italic">C</mml:mi><mml:mrow><mml:mi mathvariant="normal">⊤</mml:mi></mml:mrow></mml:msup></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>,</mml:mo></mml:mrow></mml:mstyle></mml:math></disp-formula>where <inline-formula><mml:math id="inf344"><mml:msubsup><mml:mrow><mml:mo maxsize="80%" minsize="80%">{</mml:mo><mml:msub><mml:mi mathsize="80%">a</mml:mi><mml:mi mathsize="80%">k</mml:mi></mml:msub><mml:mo maxsize="80%" minsize="80%">}</mml:mo></mml:mrow><mml:mrow><mml:mi mathsize="80%">k</mml:mi><mml:mo mathsize="80%" stretchy="false">=</mml:mo><mml:mn mathsize="80%">1</mml:mn></mml:mrow><mml:mi mathsize="80%">d</mml:mi></mml:msubsup></mml:math></inline-formula> represents the vector <inline-formula><mml:math id="inf345"><mml:mrow><mml:mi mathsize="80%" mathvariant="bold-italic">𝒂</mml:mi><mml:mo mathsize="80%" stretchy="false">=</mml:mo><mml:mrow><mml:mo maxsize="80%" minsize="80%">(</mml:mo><mml:msub><mml:mi mathsize="80%">a</mml:mi><mml:mn mathsize="80%">1</mml:mn></mml:msub><mml:mo mathsize="80%" stretchy="false">,</mml:mo><mml:mi mathsize="80%" mathvariant="normal">…</mml:mi><mml:mo mathsize="80%" stretchy="false">,</mml:mo><mml:msub><mml:mi mathsize="80%">a</mml:mi><mml:mi mathsize="80%">d</mml:mi></mml:msub><mml:mo maxsize="80%" minsize="80%">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula>. Compared to the model <xref ref-type="disp-formula" rid="equ10">Equation (5)</xref>, this expression does not introduce the unknown residual variance parameter <inline-formula><mml:math id="inf346"><mml:msup><mml:mi mathsize="80%">σ</mml:mi><mml:mn mathsize="80%">2</mml:mn></mml:msup></mml:math></inline-formula> and instead each node has its own residual parameter given by <inline-formula><mml:math id="inf347"><mml:mrow><mml:mrow><mml:mo maxsize="80%" minsize="80%">(</mml:mo><mml:mrow><mml:mn mathsize="80%">1</mml:mn><mml:mo mathsize="80%" stretchy="false">-</mml:mo><mml:msubsup><mml:mi mathsize="80%">L</mml:mi><mml:mrow><mml:mi mathsize="80%">k</mml:mi><mml:mo>⁢</mml:mo><mml:mi mathsize="80%">k</mml:mi></mml:mrow><mml:mo mathsize="80%" stretchy="false">†</mml:mo></mml:msubsup></mml:mrow><mml:mo maxsize="80%" minsize="80%">)</mml:mo></mml:mrow><mml:mo mathsize="80%" stretchy="false">/</mml:mo><mml:mn mathsize="80%">2</mml:mn></mml:mrow></mml:math></inline-formula>. Because the residual parameters must be positive, this means that we have to search for the graphs that ensure <inline-formula><mml:math id="inf348"><mml:mrow><mml:msubsup><mml:mi mathsize="80%">L</mml:mi><mml:mrow><mml:mi mathsize="80%">k</mml:mi><mml:mo>⁢</mml:mo><mml:mi mathsize="80%">k</mml:mi></mml:mrow><mml:mo mathsize="80%" stretchy="false">†</mml:mo></mml:msubsup><mml:mo mathsize="80%" stretchy="false">≤</mml:mo><mml:mn mathsize="80%">1</mml:mn></mml:mrow></mml:math></inline-formula> for all nodes <inline-formula><mml:math id="inf349"><mml:mi mathsize="80%">k</mml:mi></mml:math></inline-formula>. With that said, we can consider the following constrained optimization problem:<disp-formula id="equ45"><label>(20)</label><mml:math id="m45"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mover><mml:mi mathvariant="bold-italic">w</mml:mi><mml:mo>^</mml:mo></mml:mover></mml:mrow><mml:mo>=</mml:mo><mml:munder><mml:mrow><mml:mi mathvariant="normal">a</mml:mi><mml:mi mathvariant="normal">r</mml:mi><mml:mi mathvariant="normal">g</mml:mi><mml:mi mathvariant="normal">m</mml:mi><mml:mi mathvariant="normal">i</mml:mi><mml:mi mathvariant="normal">n</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="bold-italic">l</mml:mi><mml:mo>≤</mml:mo><mml:mi mathvariant="bold-italic">w</mml:mi><mml:mo>≤</mml:mo><mml:mi mathvariant="bold-italic">u</mml:mi></mml:mrow></mml:munder><mml:mspace width="thickmathspace"/><mml:mrow><mml:mo>{</mml:mo><mml:mrow><mml:msub><mml:mi>ℓ</mml:mi><mml:mrow><mml:mrow><mml:mtext mathvariant="sans-serif">exact</mml:mtext></mml:mrow></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi mathvariant="bold-italic">w</mml:mi><mml:mo>;</mml:mo><mml:mi mathvariant="bold-italic">C</mml:mi><mml:mrow><mml:mover><mml:mi mathvariant="bold">Σ</mml:mi><mml:mo>^</mml:mo></mml:mover></mml:mrow><mml:msup><mml:mi mathvariant="bold-italic">C</mml:mi><mml:mrow><mml:mi mathvariant="normal">⊤</mml:mi></mml:mrow></mml:msup><mml:mo stretchy="false">)</mml:mo><mml:mo>+</mml:mo><mml:msub><mml:mi>ϕ</mml:mi><mml:mrow><mml:mi>λ</mml:mi><mml:mo>,</mml:mo><mml:mi>α</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi mathvariant="bold-italic">w</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>:</mml:mo><mml:msubsup><mml:mrow><mml:mi>L</mml:mi></mml:mrow><mml:mrow><mml:mi>k</mml:mi><mml:mi>k</mml:mi></mml:mrow><mml:mrow><mml:mo>†</mml:mo></mml:mrow></mml:msubsup><mml:mo>≤</mml:mo><mml:mn>1</mml:mn><mml:mtext> </mml:mtext><mml:mrow><mml:mi mathvariant="normal">f</mml:mi><mml:mi mathvariant="normal">o</mml:mi><mml:mi mathvariant="normal">r</mml:mi><mml:mtext> </mml:mtext><mml:mi mathvariant="normal">a</mml:mi><mml:mi mathvariant="normal">l</mml:mi><mml:mi mathvariant="normal">l</mml:mi><mml:mtext> </mml:mtext></mml:mrow><mml:mi>k</mml:mi><mml:mo>∈</mml:mo><mml:mrow><mml:mi mathvariant="script">𝒱</mml:mi></mml:mrow></mml:mrow><mml:mo>}</mml:mo></mml:mrow><mml:mo>,</mml:mo></mml:mstyle></mml:mrow></mml:mstyle></mml:math></disp-formula>where <inline-formula><mml:math id="inf350"><mml:msub><mml:mi mathsize="80%" mathvariant="normal">ℓ</mml:mi><mml:mtext mathsize="80%">𝖾𝗑𝖺𝖼𝗍</mml:mtext></mml:msub></mml:math></inline-formula> is the negative log-likelihood function based on <xref ref-type="disp-formula" rid="equ44">Equation (19)</xref> and <inline-formula><mml:math id="inf351"><mml:msub><mml:mi mathsize="80%">ϕ</mml:mi><mml:mrow><mml:mi mathsize="80%">λ</mml:mi><mml:mo mathsize="80%" stretchy="false">,</mml:mo><mml:mi mathsize="80%">α</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> is the smooth penalty function defined earlier. The main difficulty of solving <xref ref-type="disp-formula" rid="equ45">Equation (20)</xref> is that enforcing the constraint <inline-formula><mml:math id="inf352"><mml:mrow><mml:msubsup><mml:mi mathsize="80%">L</mml:mi><mml:mrow><mml:mi mathsize="80%">k</mml:mi><mml:mo>⁢</mml:mo><mml:mi mathsize="80%">k</mml:mi></mml:mrow><mml:mo mathsize="80%" stretchy="false">†</mml:mo></mml:msubsup><mml:mo mathsize="80%" stretchy="false">≤</mml:mo><mml:mn mathsize="80%">1</mml:mn></mml:mrow></mml:math></inline-formula> for all nodes <inline-formula><mml:math id="inf353"><mml:mrow><mml:mi mathsize="80%">k</mml:mi><mml:mo mathsize="80%" stretchy="false">∈</mml:mo><mml:mi class="ltx_font_mathcaligraphic" mathsize="80%">𝒱</mml:mi></mml:mrow></mml:math></inline-formula>, requires full computation of the pseudo-inverse of a <inline-formula><mml:math id="inf354"><mml:mrow><mml:mi mathsize="80%">d</mml:mi><mml:mo mathsize="80%" stretchy="false">×</mml:mo><mml:mi mathsize="80%">d</mml:mi></mml:mrow></mml:math></inline-formula> matrix <inline-formula><mml:math id="inf355"><mml:mi mathsize="80%" mathvariant="bold-italic">𝑳</mml:mi></mml:math></inline-formula> which is computationally demanding. We instead relax the constraint and consider the following form as a proxy for optimization <xref ref-type="disp-formula" rid="equ45">Equation (20)</xref>:<disp-formula id="equ46"><label>(21)</label><mml:math id="m46"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mover><mml:mi mathvariant="bold-italic">w</mml:mi><mml:mo>^</mml:mo></mml:mover></mml:mrow><mml:mo>=</mml:mo><mml:munder><mml:mrow><mml:mi mathvariant="normal">a</mml:mi><mml:mi mathvariant="normal">r</mml:mi><mml:mi mathvariant="normal">g</mml:mi><mml:mi mathvariant="normal">m</mml:mi><mml:mi mathvariant="normal">i</mml:mi><mml:mi mathvariant="normal">n</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="bold-italic">l</mml:mi><mml:mo>≤</mml:mo><mml:mi mathvariant="bold-italic">w</mml:mi><mml:mo>≤</mml:mo><mml:mi mathvariant="bold-italic">u</mml:mi></mml:mrow></mml:munder><mml:mtext> </mml:mtext><mml:mrow><mml:mo>{</mml:mo><mml:mrow><mml:msub><mml:mi>ℓ</mml:mi><mml:mrow><mml:mrow><mml:mtext mathvariant="sans-serif">exact</mml:mtext></mml:mrow></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi mathvariant="bold-italic">w</mml:mi><mml:mo>;</mml:mo><mml:mi mathvariant="bold-italic">C</mml:mi><mml:mrow><mml:mover><mml:mi mathvariant="bold">Σ</mml:mi><mml:mo>^</mml:mo></mml:mover></mml:mrow><mml:msup><mml:mi mathvariant="bold-italic">C</mml:mi><mml:mrow><mml:mi mathvariant="normal">⊤</mml:mi></mml:mrow></mml:msup><mml:mo stretchy="false">)</mml:mo><mml:mo>+</mml:mo><mml:msub><mml:mi>ϕ</mml:mi><mml:mrow><mml:mi>λ</mml:mi><mml:mo>,</mml:mo><mml:mi>α</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi mathvariant="bold-italic">w</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>:</mml:mo><mml:msubsup><mml:mrow><mml:mi>L</mml:mi></mml:mrow><mml:mrow><mml:mi>k</mml:mi><mml:mi>k</mml:mi></mml:mrow><mml:mrow><mml:mo>†</mml:mo></mml:mrow></mml:msubsup><mml:mo>≤</mml:mo><mml:mn>1</mml:mn><mml:mtext> </mml:mtext><mml:mrow><mml:mi mathvariant="normal">f</mml:mi><mml:mi mathvariant="normal">o</mml:mi><mml:mi mathvariant="normal">r</mml:mi><mml:mtext> </mml:mtext><mml:mi mathvariant="normal">a</mml:mi><mml:mi mathvariant="normal">l</mml:mi><mml:mi mathvariant="normal">l</mml:mi><mml:mtext> </mml:mtext><mml:mi mathvariant="normal">o</mml:mi><mml:mi mathvariant="normal">b</mml:mi><mml:mi mathvariant="normal">s</mml:mi><mml:mi mathvariant="normal">e</mml:mi><mml:mi mathvariant="normal">r</mml:mi><mml:mi mathvariant="normal">v</mml:mi><mml:mi mathvariant="normal">e</mml:mi><mml:mi mathvariant="normal">d</mml:mi><mml:mtext> </mml:mtext><mml:mi mathvariant="normal">n</mml:mi><mml:mi mathvariant="normal">o</mml:mi><mml:mi mathvariant="normal">d</mml:mi><mml:mi mathvariant="normal">e</mml:mi><mml:mi mathvariant="normal">s</mml:mi><mml:mtext> </mml:mtext></mml:mrow><mml:mi>k</mml:mi></mml:mrow><mml:mo>}</mml:mo></mml:mrow><mml:mo>.</mml:mo></mml:mstyle></mml:mrow></mml:mstyle></mml:math></disp-formula></p><p>Note that the constraint <inline-formula><mml:math id="inf356"><mml:mrow><mml:msubsup><mml:mi mathsize="80%">L</mml:mi><mml:mrow><mml:mi mathsize="80%">k</mml:mi><mml:mo>⁢</mml:mo><mml:mi mathsize="80%">k</mml:mi></mml:mrow><mml:mo mathsize="80%" stretchy="false">†</mml:mo></mml:msubsup><mml:mo mathsize="80%" stretchy="false">≤</mml:mo><mml:mn mathsize="80%">1</mml:mn></mml:mrow></mml:math></inline-formula> is now placed at the observed nodes only, which can lead to computational savings if <inline-formula><mml:math id="inf357"><mml:mrow><mml:mi mathsize="80%">o</mml:mi><mml:mo mathsize="80%" stretchy="false">≪</mml:mo><mml:mi mathsize="80%">d</mml:mi></mml:mrow></mml:math></inline-formula>. The problem <xref ref-type="disp-formula" rid="equ46">Equation (21)</xref> can be solved efficiently using any gradient-based algorithms where we can calculate the gradient of <inline-formula><mml:math id="inf358"><mml:msub><mml:mi mathsize="80%" mathvariant="normal">ℓ</mml:mi><mml:mtext mathsize="80%">𝖾𝗑𝖺𝖼𝗍</mml:mtext></mml:msub></mml:math></inline-formula> with respect to <inline-formula><mml:math id="inf359"><mml:mi mathsize="80%" mathvariant="bold-italic">𝑳</mml:mi></mml:math></inline-formula> as<disp-formula id="equ47"><mml:math id="m47"><mml:mrow><mml:mrow><mml:mfrac><mml:mrow><mml:mrow><mml:mo mathsize="80%" stretchy="false">∂</mml:mo><mml:mo>⁡</mml:mo><mml:msub><mml:mi mathsize="80%" mathvariant="normal">ℓ</mml:mi><mml:mtext mathsize="80%">𝖾𝗑𝖺𝖼𝗍</mml:mtext></mml:msub></mml:mrow><mml:mo>⁢</mml:mo><mml:mrow><mml:mo maxsize="80%" minsize="80%">(</mml:mo><mml:mi mathsize="80%">𝒘</mml:mi><mml:mo maxsize="80%" minsize="80%">)</mml:mo></mml:mrow></mml:mrow><mml:mrow><mml:mrow><mml:mo mathsize="80%" stretchy="false">∂</mml:mo><mml:mo>⁡</mml:mo><mml:mtext mathsize="80%">vec</mml:mtext></mml:mrow><mml:mo>⁢</mml:mo><mml:mrow><mml:mo maxsize="80%" minsize="80%">(</mml:mo><mml:mi mathsize="80%">𝑳</mml:mi><mml:mo maxsize="80%" minsize="80%">)</mml:mo></mml:mrow></mml:mrow></mml:mfrac><mml:mo mathsize="80%" stretchy="false">=</mml:mo><mml:mrow><mml:mrow><mml:mrow><mml:mi mathsize="80%">p</mml:mi><mml:mo mathsize="80%" stretchy="false">⋅</mml:mo><mml:mtext mathsize="80%">vec</mml:mtext></mml:mrow><mml:mo>⁢</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msubsup><mml:mi mathsize="80%">𝑳</mml:mi><mml:mtext mathsize="80%">full</mml:mtext><mml:mrow><mml:mo mathsize="80%" stretchy="false">-</mml:mo><mml:mn mathsize="80%">1</mml:mn></mml:mrow></mml:msubsup><mml:mo>⁢</mml:mo><mml:msup><mml:mi mathsize="80%">𝑨</mml:mi><mml:mo mathsize="80%" stretchy="false">⊤</mml:mo></mml:msup><mml:mo>⁢</mml:mo><mml:mi mathsize="80%">𝑴</mml:mi><mml:mo>⁢</mml:mo><mml:mi mathsize="80%">𝑨</mml:mi><mml:mo>⁢</mml:mo><mml:msubsup><mml:mi mathsize="80%">𝑳</mml:mi><mml:mtext mathsize="80%">full</mml:mtext><mml:mrow><mml:mrow><mml:mo mathsize="80%" stretchy="false">-</mml:mo><mml:mn mathsize="80%">1</mml:mn></mml:mrow><mml:mo mathsize="80%" stretchy="false">,</mml:mo><mml:mo mathsize="80%" stretchy="false">⊤</mml:mo></mml:mrow></mml:msubsup></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo mathsize="80%" stretchy="false">-</mml:mo><mml:mrow><mml:mrow><mml:mi mathsize="80%">p</mml:mi><mml:mo mathsize="80%" stretchy="false">⋅</mml:mo><mml:mtext mathsize="80%">diag</mml:mtext></mml:mrow><mml:mo>⁢</mml:mo><mml:msup><mml:mrow><mml:mo maxsize="80%" minsize="80%">(</mml:mo><mml:mi mathsize="80%">𝑴</mml:mi><mml:mo maxsize="80%" minsize="80%">)</mml:mo></mml:mrow><mml:mo mathsize="80%" stretchy="false">⊤</mml:mo></mml:msup><mml:mo>⁢</mml:mo><mml:mtext mathsize="80%">diag</mml:mtext><mml:mo>⁢</mml:mo><mml:mrow><mml:mo maxsize="80%" minsize="80%">(</mml:mo><mml:msup><mml:mrow><mml:mo maxsize="80%" minsize="80%">(</mml:mo><mml:mrow><mml:mn mathsize="80%">2</mml:mn><mml:mo>⁢</mml:mo><mml:mi mathsize="80%">𝒏</mml:mi></mml:mrow><mml:mo maxsize="80%" minsize="80%">)</mml:mo></mml:mrow><mml:mrow><mml:mo mathsize="80%" stretchy="false">-</mml:mo><mml:mn mathsize="80%">1</mml:mn></mml:mrow></mml:msup><mml:mo maxsize="80%" minsize="80%">)</mml:mo></mml:mrow><mml:mo>⁢</mml:mo><mml:mi mathsize="80%">𝑵</mml:mi></mml:mrow></mml:mrow></mml:mrow><mml:mo mathsize="80%" stretchy="false">,</mml:mo></mml:mrow></mml:math></disp-formula>where <inline-formula><mml:math id="inf360"><mml:mi mathsize="80%" mathvariant="bold-italic">𝑴</mml:mi></mml:math></inline-formula> is a <inline-formula><mml:math id="inf361"><mml:mrow><mml:mi mathsize="80%">o</mml:mi><mml:mo mathsize="80%" stretchy="false">×</mml:mo><mml:mi mathsize="80%">o</mml:mi></mml:mrow></mml:math></inline-formula> matrix defined in <xref ref-type="disp-formula" rid="equ39">Equation (18)</xref>, and <inline-formula><mml:math id="inf362"><mml:mi mathsize="80%" mathvariant="bold-italic">𝑵</mml:mi></mml:math></inline-formula> is a <inline-formula><mml:math id="inf363"><mml:mrow><mml:mi mathsize="80%">o</mml:mi><mml:mo mathsize="80%" stretchy="false">×</mml:mo><mml:msup><mml:mi mathsize="80%">d</mml:mi><mml:mn mathsize="80%">2</mml:mn></mml:msup></mml:mrow></mml:math></inline-formula> matrix whose rows correspond to the observed subsets of the rows of the <inline-formula><mml:math id="inf364"><mml:mrow><mml:msup><mml:mi mathsize="80%">d</mml:mi><mml:mn mathsize="80%">2</mml:mn></mml:msup><mml:mo mathsize="80%" stretchy="false">×</mml:mo><mml:msup><mml:mi mathsize="80%">d</mml:mi><mml:mn mathsize="80%">2</mml:mn></mml:msup></mml:mrow></mml:math></inline-formula> matrix <inline-formula><mml:math id="inf365"><mml:mrow><mml:msubsup><mml:mi mathsize="80%" mathvariant="bold-italic">𝑳</mml:mi><mml:mtext mathsize="80%">full</mml:mtext><mml:mrow><mml:mo mathsize="80%" stretchy="false">-</mml:mo><mml:mn mathsize="80%">1</mml:mn></mml:mrow></mml:msubsup><mml:mo mathsize="80%" stretchy="false">⊗</mml:mo><mml:msubsup><mml:mi mathsize="80%" mathvariant="bold-italic">𝑳</mml:mi><mml:mtext mathsize="80%">full</mml:mtext><mml:mrow><mml:mo mathsize="80%" stretchy="false">-</mml:mo><mml:mn mathsize="80%">1</mml:mn></mml:mrow></mml:msubsup></mml:mrow></mml:math></inline-formula>.</p><p><xref ref-type="fig" rid="app1fig12">Appendix 1—figure 12</xref> shows the result when the penalized maximum likelihood <xref ref-type="disp-formula" rid="equ46">Equation (21)</xref> is applied to the North American wolf dataset with a setting of <inline-formula><mml:math id="inf366"><mml:mrow><mml:mi mathsize="80%">λ</mml:mi><mml:mo mathsize="80%" stretchy="false">=</mml:mo><mml:mn mathsize="80%">2.06</mml:mn></mml:mrow></mml:math></inline-formula> (the same value of λ as given in <xref ref-type="fig" rid="fig4">Figure 4</xref>) and <inline-formula><mml:math id="inf367"><mml:mrow><mml:mi mathsize="80%">α</mml:mi><mml:mo mathsize="80%" stretchy="false">=</mml:mo><mml:mrow><mml:mn mathsize="80%">1</mml:mn><mml:mo mathsize="80%" stretchy="false">/</mml:mo><mml:msub><mml:mover accent="true"><mml:mi mathsize="80%">w</mml:mi><mml:mo mathsize="80%" stretchy="false">^</mml:mo></mml:mover><mml:mn mathsize="80%">0</mml:mn></mml:msub></mml:mrow></mml:mrow></mml:math></inline-formula>, where <inline-formula><mml:math id="inf368"><mml:msub><mml:mover accent="true"><mml:mi mathsize="80%">w</mml:mi><mml:mo mathsize="80%" stretchy="false">^</mml:mo></mml:mover><mml:mn mathsize="80%">0</mml:mn></mml:msub></mml:math></inline-formula> is the solution for the ‘constant-<inline-formula><mml:math id="inf369"><mml:mi mathsize="80%">w</mml:mi></mml:math></inline-formula>’ model. We can see that the resulting estimated migration surfaces are qualitatively similar to that shown in <xref ref-type="fig" rid="fig4">Figure 4</xref>. We also observed similar results between FEEMS and the penalized maximum likelihood <xref ref-type="disp-formula" rid="equ46">Equation (21)</xref> across multiple datasets. On the other hand, we found that at the fitted surface the residual variances <inline-formula><mml:math id="inf370"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:msubsup><mml:mrow><mml:mi>L</mml:mi></mml:mrow><mml:mrow><mml:mi>k</mml:mi><mml:mi>k</mml:mi></mml:mrow><mml:mrow><mml:mo>†</mml:mo></mml:mrow></mml:msubsup></mml:mrow></mml:mstyle></mml:math></inline-formula> are not always positive because the constraints are enforced only at the observed nodes. This is problematic because it can cause the model to be ill-defined at the unobserved nodes and make the algorithm numerically unstable. Note that FEEMS avoids this issue by decoupling the residual variance parameter <inline-formula><mml:math id="inf371"><mml:msup><mml:mi mathsize="80%">σ</mml:mi><mml:mn mathsize="80%">2</mml:mn></mml:msup></mml:math></inline-formula> from the graph-related parameters <inline-formula><mml:math id="inf372"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi mathvariant="bold-italic">w</mml:mi></mml:mrow></mml:mstyle></mml:math></inline-formula>. The resulting model <xref ref-type="disp-formula" rid="equ11">Equation (6)</xref> also has more resemblance to spatial coalescent model used in EEMS (<xref ref-type="bibr" rid="bib42">Petkova et al., 2016</xref>), and we thus recommend using FEEMS as a primary method for inferring migration rates.</p></sec><sec id="s12" sec-type="appendix"><title>Jointly estimating the residual variance and edge weights</title><p>One simple strategy we have used throughout the paper was to fit <inline-formula><mml:math id="inf373"><mml:msup><mml:mi mathsize="80%">σ</mml:mi><mml:mn mathsize="80%">2</mml:mn></mml:msup></mml:math></inline-formula> first under a model of homogeneous isolation by distance and prefix the estimated residual variance to the resulting <inline-formula><mml:math id="inf374"><mml:msup><mml:mover accent="true"><mml:mi mathsize="80%">σ</mml:mi><mml:mo mathsize="80%" stretchy="false">^</mml:mo></mml:mover><mml:mn mathsize="80%">2</mml:mn></mml:msup></mml:math></inline-formula> for later fits of the effective migration rates. Alternatively, we can consider estimating the unknown residual variance simultaneously with the edge weights, instead of prefixing it from the estimation of the null model—the hope here is to simultaneously correct the model misspecification and allow for improving model fit to the data. To develop the framework for simultaneous estimation of the residual variance and edge weights, let us consider a model that generalizes both <xref ref-type="disp-formula" rid="equ11">Equation (6)</xref> and <xref ref-type="disp-formula" rid="equ44">Equation (19)</xref>, that is,<disp-formula id="equ48"><label>(22)</label><mml:math id="m48"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>p</mml:mi><mml:mo>⋅</mml:mo><mml:mi mathvariant="bold-italic">C</mml:mi><mml:mrow><mml:mover><mml:mi mathvariant="bold">Σ</mml:mi><mml:mo>^</mml:mo></mml:mover></mml:mrow><mml:msup><mml:mi mathvariant="bold-italic">C</mml:mi><mml:mrow><mml:mi mathvariant="normal">⊤</mml:mi></mml:mrow></mml:msup><mml:mo>∼</mml:mo><mml:msub><mml:mrow><mml:mi mathvariant="script">𝒲</mml:mi></mml:mrow><mml:mrow><mml:mi>o</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi mathvariant="bold-italic">C</mml:mi><mml:mi mathvariant="bold-italic">A</mml:mi><mml:msup><mml:mi mathvariant="bold-italic">L</mml:mi><mml:mrow><mml:mo>†</mml:mo></mml:mrow></mml:msup><mml:msup><mml:mi mathvariant="bold-italic">A</mml:mi><mml:mrow><mml:mi mathvariant="normal">⊤</mml:mi></mml:mrow></mml:msup><mml:msup><mml:mi mathvariant="bold-italic">C</mml:mi><mml:mrow><mml:mi mathvariant="normal">⊤</mml:mi></mml:mrow></mml:msup><mml:mo>+</mml:mo><mml:mi mathvariant="bold-italic">C</mml:mi><mml:mtext>diag</mml:mtext><mml:mo stretchy="false">(</mml:mo><mml:msup><mml:mi mathvariant="bold-italic">n</mml:mi><mml:mrow><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msup><mml:mo stretchy="false">)</mml:mo><mml:mi mathvariant="bold-italic">A</mml:mi><mml:mtext>diag</mml:mtext><mml:mrow><mml:mo>(</mml:mo><mml:msup><mml:mi mathvariant="bold-italic">σ</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup><mml:mo>)</mml:mo></mml:mrow><mml:msup><mml:mi mathvariant="bold-italic">A</mml:mi><mml:mrow><mml:mi mathvariant="normal">⊤</mml:mi></mml:mrow></mml:msup><mml:msup><mml:mi mathvariant="bold-italic">C</mml:mi><mml:mrow><mml:mi mathvariant="normal">⊤</mml:mi></mml:mrow></mml:msup><mml:mo>,</mml:mo><mml:mi>p</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>,</mml:mo></mml:mrow></mml:mstyle></mml:math></disp-formula>where <inline-formula><mml:math id="inf375"><mml:msup><mml:mi mathsize="80%" mathvariant="bold-italic">𝝈</mml:mi><mml:mn mathsize="80%">2</mml:mn></mml:msup></mml:math></inline-formula> is a <inline-formula><mml:math id="inf376"><mml:mrow><mml:mi mathsize="80%">d</mml:mi><mml:mo mathsize="80%" stretchy="false">×</mml:mo><mml:mn mathsize="80%">1</mml:mn></mml:mrow></mml:math></inline-formula> vector of node specific residual variance parameters, that is, each deme has its own residual parameter <inline-formula><mml:math id="inf377"><mml:msub><mml:mi mathsize="80%">σ</mml:mi><mml:mi mathsize="80%">k</mml:mi></mml:msub></mml:math></inline-formula>. If the parameters <inline-formula><mml:math id="inf378"><mml:msub><mml:mi mathsize="80%">σ</mml:mi><mml:mi mathsize="80%">k</mml:mi></mml:msub></mml:math></inline-formula>’s are assumed to be the same across nodes, this reduces to the FEEMS model <xref ref-type="disp-formula" rid="equ11">Equation (6)</xref> while setting <inline-formula><mml:math id="inf379"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>σ</mml:mi><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:msubsup><mml:mi mathvariant="bold-italic">L</mml:mi><mml:mrow><mml:mi>k</mml:mi><mml:mi>k</mml:mi></mml:mrow><mml:mrow><mml:mo>†</mml:mo></mml:mrow></mml:msubsup><mml:mo stretchy="false">)</mml:mo><mml:mrow><mml:mo>/</mml:mo></mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:mstyle></mml:math></inline-formula> gives the model <xref ref-type="disp-formula" rid="equ44">Equation (19)</xref>. Then we solve the following optimization problem<disp-formula id="equ49"><mml:math id="m49"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mover><mml:mi mathvariant="bold-italic">w</mml:mi><mml:mo>^</mml:mo></mml:mover></mml:mrow><mml:mo>,</mml:mo><mml:msup><mml:mrow><mml:mover><mml:mi mathvariant="bold-italic">σ</mml:mi><mml:mo>^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup><mml:mo>=</mml:mo><mml:munder><mml:mrow><mml:mi mathvariant="normal">a</mml:mi><mml:mi mathvariant="normal">r</mml:mi><mml:mi mathvariant="normal">g</mml:mi><mml:mspace width="thinmathspace"/><mml:mi mathvariant="normal">m</mml:mi><mml:mi mathvariant="normal">i</mml:mi><mml:mi mathvariant="normal">n</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="bold-italic">l</mml:mi><mml:mo>≤</mml:mo><mml:mi mathvariant="bold-italic">w</mml:mi><mml:mo>≤</mml:mo><mml:mi mathvariant="bold-italic">u</mml:mi><mml:mo>,</mml:mo><mml:msup><mml:mi mathvariant="bold-italic">σ</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup><mml:mo>&gt;</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:munder><mml:mspace width="thickmathspace"/><mml:msub><mml:mi>ℓ</mml:mi><mml:mrow><mml:mrow><mml:mtext mathvariant="sans-serif">joint</mml:mtext></mml:mrow></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi mathvariant="bold-italic">w</mml:mi><mml:mo>,</mml:mo><mml:msup><mml:mi mathvariant="bold-italic">σ</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup><mml:mo>;</mml:mo><mml:mi mathvariant="bold-italic">C</mml:mi><mml:mrow><mml:mover><mml:mi mathvariant="bold">Σ</mml:mi><mml:mo>^</mml:mo></mml:mover></mml:mrow><mml:msup><mml:mi mathvariant="bold-italic">C</mml:mi><mml:mrow><mml:mi mathvariant="normal">⊤</mml:mi></mml:mrow></mml:msup><mml:mo stretchy="false">)</mml:mo><mml:mo>+</mml:mo><mml:msub><mml:mi>ϕ</mml:mi><mml:mrow><mml:mi>λ</mml:mi><mml:mo>,</mml:mo><mml:mi>α</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi mathvariant="bold-italic">w</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>,</mml:mo></mml:mstyle></mml:mrow></mml:mstyle></mml:math></disp-formula>where <inline-formula><mml:math id="inf380"><mml:msub><mml:mi mathsize="80%" mathvariant="normal">ℓ</mml:mi><mml:mtext mathsize="80%">𝗃𝗈𝗂𝗇𝗍</mml:mtext></mml:msub></mml:math></inline-formula> is the negative log-likelihood function based on <xref ref-type="disp-formula" rid="equ48">Equation (22)</xref>. Note that the residual variances and edge weights are both searched in the optimization for finding the optimal solutions. To solve the problem, we can use the quasi-newton algorithm for optimizing the objective function.</p><p><xref ref-type="fig" rid="app1fig13">Appendix 1—figure 13</xref> shows the fitted graphs with different strategies of estimating the residual variances. <xref ref-type="fig" rid="app1fig13">Appendix 1—figure 13A</xref> shows the result when the model has a single residual variance <inline-formula><mml:math id="inf381"><mml:msup><mml:mi mathsize="80%">σ</mml:mi><mml:mn mathsize="80%">2</mml:mn></mml:msup></mml:math></inline-formula>, and <xref ref-type="fig" rid="app1fig13">Appendix 1—figure 13B</xref> shows the result when the residual variances are allowed to vary across nodes. In both cases, estimating the residual variances jointly with the edge weights yields similar and comparable outputs to the default setting of prefixing it from the null model (<xref ref-type="fig" rid="fig4">Figure 4</xref>), except that we can further observe reduced effective migration around Queen Elizabeth Islands as shown in <xref ref-type="fig" rid="app1fig13">Appendix 1—figure 13B</xref>. In EEMS, in order to estimate the genetic diversity parameters for every spatial location, which play a similar role as the residual variances in FEEMS, a Voronoi-tessellation prior is placed to encourage sharing of information across adjacent nodes and prevent over-fitting. Similarly, we can place the spatial smooth penalty on the residual variances (i.e. <inline-formula><mml:math id="inf382"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>ϕ</mml:mi><mml:mrow><mml:mi>λ</mml:mi><mml:mo>,</mml:mo><mml:mi>α</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula> defined on the variable <inline-formula><mml:math id="inf383"><mml:mrow><mml:msup><mml:mi mathsize="80%" mathvariant="bold-italic">𝝈</mml:mi><mml:mn mathsize="80%">2</mml:mn></mml:msup><mml:mo maxsize="80%" minsize="80%">)</mml:mo></mml:mrow></mml:math></inline-formula>, but it introduces additional hyperparameters to tune, without substantially improving the model’s fit to the data. In this work, we choose to fit the single residual variance <inline-formula><mml:math id="inf384"><mml:msup><mml:mi mathsize="80%">σ</mml:mi><mml:mn mathsize="80%">2</mml:mn></mml:msup></mml:math></inline-formula> under the null model and prefix it as a simple but effective strategy with apparent good empirical performance.</p></sec><sec id="s13" sec-type="appendix"><title>Edge versus node parameterization</title><p>One of the novel features of FEEMS is its ability to directly fit the edge weights of the graph that best suit the data. This direct edge parameterization may increase the risk of model’s overfitting, but also allows for more flexible estimation of migration histories. Furthermore, as seen in <xref ref-type="fig" rid="fig2">Figure 2</xref> and <xref ref-type="fig" rid="app1fig2">Appendix 1—figure 2</xref>, it has potential to recover anisotropic migration processes. This is in contrast to EEMS wherein every spatial node is assigned an effective migration parameter <inline-formula><mml:math id="inf385"><mml:msub><mml:mi mathsize="80%">m</mml:mi><mml:mi mathsize="80%">k</mml:mi></mml:msub></mml:math></inline-formula> and a migration rate on each edge joining nodes <inline-formula><mml:math id="inf386"><mml:mi mathsize="80%">k</mml:mi></mml:math></inline-formula> and <inline-formula><mml:math id="inf387"><mml:mi mathsize="80%" mathvariant="normal">ℓ</mml:mi></mml:math></inline-formula> is given by the average effective migration <inline-formula><mml:math id="inf388"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>w</mml:mi><mml:mrow><mml:mi>k</mml:mi><mml:mi>ℓ</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>m</mml:mi><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mi>m</mml:mi><mml:mrow><mml:mi>ℓ</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:mrow><mml:mo>/</mml:mo></mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:mstyle></mml:math></inline-formula>. Not surprisingly, by assigning each edge to be the average of connected nodes, a form of implicit spatial regularization is imposed because multiple edges connected to the same node would average that node’s parameter value. In some cases, this has the desirable property of imposing an additional degree of similarity across edge weights, but at the same time it also restricts the model’s capacity to capture a richer set of structure present in the data (e.g. <xref ref-type="bibr" rid="bib42">Petkova et al., 2016</xref>, Supplementary Figure 2). To be concrete, <xref ref-type="fig" rid="app1fig15">Appendix 1—figure 15</xref> displays two different fits of FEEMS based on edge parameterization (<xref ref-type="fig" rid="app1fig15">Appendix 1—figure 15A</xref>) and node parameterization (<xref ref-type="fig" rid="app1fig15">Appendix 1—figure 15B</xref>), run on a previously published dataset of human genetic variation from Africa (see <xref ref-type="bibr" rid="bib40">Peter et al., 2020</xref> for details on the description of the dataset). Running FEEMS with a node-based parameterization is straightforward in our framework—all we have to do is to reparameterize the edge weights by the average effective migration and solve the corresponding optimization problem (Optimization) with respect to <inline-formula><mml:math id="inf389"><mml:mi mathsize="80%" mathvariant="bold-italic">𝒎</mml:mi></mml:math></inline-formula>. It is evident from the results that FEEMS with edge parameterization exhibits subtle correlations that exist between the annotated demes in the figure, whereas node parameterization fails to recover them. We also compare the model fit of FEEMS to the observed genetic distance (<xref ref-type="fig" rid="app1fig16">Appendix 1—figure 16</xref>) and find that edge-based parameterization provides a better fit to the African dataset. <xref ref-type="fig" rid="app1fig17">Appendix 1—figure 17</xref> further demonstrates that in the coalescent simulations with anisotropic migration, the node parameterization is unable to recover the ground truth of the underlying migration rates even when the nodes are fully observed.</p></sec><sec id="s14" sec-type="appendix"><title>Smooth penalty with <inline-formula><mml:math id="inf390"><mml:msub><mml:mi mathvariant="normal">ℓ</mml:mi><mml:mn>1</mml:mn></mml:msub></mml:math></inline-formula> norm</title><p>FEEMS’s primary optimization objective (see <xref ref-type="disp-formula" rid="equ18">Equation 9</xref>) is:<disp-formula id="equ50"><mml:math id="m50"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:munder><mml:mtext>Minimize</mml:mtext><mml:mrow><mml:mi mathvariant="bold-italic">l</mml:mi><mml:mo>≤</mml:mo><mml:mi mathvariant="bold-italic">w</mml:mi><mml:mo>≤</mml:mo><mml:mi mathvariant="bold-italic">u</mml:mi></mml:mrow></mml:munder><mml:mspace width="thickmathspace"/><mml:mi>ℓ</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi mathvariant="bold-italic">w</mml:mi><mml:mo>,</mml:mo><mml:msup><mml:mi>σ</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup><mml:mo>;</mml:mo><mml:mi mathvariant="bold-italic">C</mml:mi><mml:mrow><mml:mover><mml:mi mathvariant="bold">Σ</mml:mi><mml:mo>^</mml:mo></mml:mover></mml:mrow><mml:msup><mml:mi mathvariant="bold-italic">C</mml:mi><mml:mrow><mml:mi mathvariant="normal">⊤</mml:mi></mml:mrow></mml:msup><mml:mo stretchy="false">)</mml:mo><mml:mo>+</mml:mo><mml:msub><mml:mi>ϕ</mml:mi><mml:mrow><mml:mi>λ</mml:mi><mml:mo>,</mml:mo><mml:mi>α</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi mathvariant="bold-italic">w</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>,</mml:mo></mml:mrow></mml:mstyle></mml:math></disp-formula>where the spatial smoothness penalty is given by an <inline-formula><mml:math id="inf391"><mml:msub><mml:mi mathsize="80%" mathvariant="normal">ℓ</mml:mi><mml:mn mathsize="80%">2</mml:mn></mml:msub></mml:math></inline-formula>-based penalty function: <inline-formula><mml:math id="inf392"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>ϕ</mml:mi><mml:mrow><mml:mi>λ</mml:mi><mml:mo>,</mml:mo><mml:mi>α</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi mathvariant="bold-italic">w</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mfrac><mml:mi>λ</mml:mi><mml:mn>2</mml:mn></mml:mfrac><mml:msubsup><mml:mrow><mml:mo symmetric="true">‖</mml:mo><mml:mrow><mml:mi mathvariant="bold">Δ</mml:mi><mml:mi>log</mml:mi><mml:mo>⁡</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:msup><mml:mi>e</mml:mi><mml:mrow><mml:mi>α</mml:mi><mml:mi mathvariant="bold-italic">w</mml:mi></mml:mrow></mml:msup><mml:mo>−</mml:mo><mml:mn mathvariant="bold">1</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo symmetric="true">‖</mml:mo></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup></mml:mrow></mml:mstyle></mml:math></inline-formula>. It is well known that an <inline-formula><mml:math id="inf393"><mml:msub><mml:mi mathsize="80%" mathvariant="normal">ℓ</mml:mi><mml:mn mathsize="80%">1</mml:mn></mml:msub></mml:math></inline-formula>-based penalty can lead to a better local adaptive fitting and structural recovery than <inline-formula><mml:math id="inf394"><mml:msub><mml:mi mathsize="80%" mathvariant="normal">ℓ</mml:mi><mml:mn mathsize="80%">2</mml:mn></mml:msub></mml:math></inline-formula>-based penaltyies (<xref ref-type="bibr" rid="bib55">Wang et al., 2016</xref>), but at the cost of handling non-smooth objective functions that are often computationally more challenging. In a spatial genetic dataset, one major challenge is to deal with the relatively sparse sampling design where there are many unobserved nodes on the graph. In this statistically challenging scenario, we found that an <inline-formula><mml:math id="inf395"><mml:msub><mml:mi mathsize="80%" mathvariant="normal">ℓ</mml:mi><mml:mn mathsize="80%">2</mml:mn></mml:msub></mml:math></inline-formula>-based penalty allows for more accurate and reliable estimation of the geographic features.</p><p>Specifically, writing <inline-formula><mml:math id="inf396"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msubsup><mml:mi>ϕ</mml:mi><mml:mrow><mml:mi>λ</mml:mi><mml:mo>,</mml:mo><mml:mi>α</mml:mi></mml:mrow><mml:mrow><mml:msub><mml:mi>ℓ</mml:mi><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:msubsup><mml:mo stretchy="false">(</mml:mo><mml:mi mathvariant="bold-italic">w</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mrow><mml:mi>λ</mml:mi></mml:mrow><mml:msub><mml:mrow><mml:mo symmetric="true">‖</mml:mo><mml:mrow><mml:mi mathvariant="bold">Δ</mml:mi><mml:mi>log</mml:mi><mml:mo>⁡</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:msup><mml:mi>e</mml:mi><mml:mrow><mml:mi>α</mml:mi><mml:mi mathvariant="bold-italic">w</mml:mi></mml:mrow></mml:msup><mml:mo>−</mml:mo><mml:mn mathvariant="bold">1</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo symmetric="true">‖</mml:mo></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula>, we considered the alternate following composite objective function:<disp-formula id="equ51"><label>(23)</label><mml:math id="m51"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>ℓ</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi mathvariant="bold-italic">w</mml:mi><mml:mo>,</mml:mo><mml:msup><mml:mi>σ</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup><mml:mo>;</mml:mo><mml:mi mathvariant="bold-italic">C</mml:mi><mml:mrow><mml:mover><mml:mi mathvariant="bold">Σ</mml:mi><mml:mo>^</mml:mo></mml:mover></mml:mrow><mml:msup><mml:mi mathvariant="bold-italic">C</mml:mi><mml:mrow><mml:mi mathvariant="normal">⊤</mml:mi></mml:mrow></mml:msup><mml:mo stretchy="false">)</mml:mo><mml:mo>+</mml:mo><mml:msubsup><mml:mi>ϕ</mml:mi><mml:mrow><mml:mi>λ</mml:mi><mml:mo>,</mml:mo><mml:mi>α</mml:mi></mml:mrow><mml:mrow><mml:msub><mml:mi>ℓ</mml:mi><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:msubsup><mml:mo stretchy="false">(</mml:mo><mml:mi mathvariant="bold-italic">w</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>.</mml:mo></mml:mrow></mml:mstyle></mml:math></disp-formula></p><p>To solve <xref ref-type="disp-formula" rid="equ51">Equation (23)</xref>, we apply linearized alternating direction method of multipliers (ADMM) (<xref ref-type="bibr" rid="bib4">Boyd, 2010</xref>), a variant of the standard ADMM algorithm, that iteratively optimizes the augmented Lagrangian over the primal and dual variables. The derivation of the algorithm is a standard calculation so we omit the detailed description of the algorithm. As opposed to the common belief about the effectiveness of the <inline-formula><mml:math id="inf397"><mml:msub><mml:mi mathsize="80%" mathvariant="normal">ℓ</mml:mi><mml:mn mathsize="80%">1</mml:mn></mml:msub></mml:math></inline-formula> norm for structural recovery, the recovered graph of FEEMS using <inline-formula><mml:math id="inf398"><mml:msub><mml:mi mathsize="80%" mathvariant="normal">ℓ</mml:mi><mml:mn mathsize="80%">1</mml:mn></mml:msub></mml:math></inline-formula>-based smooth penalty shows less accurate reconstruction of the migration patterns, especially when the sampling design has many locations with missing data on the graph (<xref ref-type="fig" rid="app1fig18">Appendix 1—figure 18A</xref>, <xref ref-type="fig" rid="app1fig19">Appendix 1—figure 19H</xref>). We can see that the <inline-formula><mml:math id="inf399"><mml:msub><mml:mi mathsize="80%" mathvariant="normal">ℓ</mml:mi><mml:mn mathsize="80%">1</mml:mn></mml:msub></mml:math></inline-formula>-based penalty function is not able to accurately estimate edge weights at regions with little data, partially due to its local adaptation, in contrast to the <inline-formula><mml:math id="inf400"><mml:msub><mml:mi mathsize="80%" mathvariant="normal">ℓ</mml:mi><mml:mn mathsize="80%">2</mml:mn></mml:msub></mml:math></inline-formula>-based method that considers regularization more globally. This suggests that in order to use the <inline-formula><mml:math id="inf401"><mml:msub><mml:mi mathsize="80%" mathvariant="normal">ℓ</mml:mi><mml:mn mathsize="80%">1</mml:mn></mml:msub></mml:math></inline-formula> penalty <inline-formula><mml:math id="inf402"><mml:mrow><mml:msubsup><mml:mi mathsize="80%">ϕ</mml:mi><mml:mrow><mml:mi mathsize="80%">λ</mml:mi><mml:mo mathsize="80%" stretchy="false">,</mml:mo><mml:mi mathsize="80%">α</mml:mi></mml:mrow><mml:msub><mml:mi mathsize="80%" mathvariant="normal">ℓ</mml:mi><mml:mn mathsize="80%">1</mml:mn></mml:msub></mml:msubsup><mml:mo>⁢</mml:mo><mml:mrow><mml:mo maxsize="80%" minsize="80%">(</mml:mo><mml:mi mathsize="80%" mathvariant="bold-italic">𝒘</mml:mi><mml:mo maxsize="80%" minsize="80%">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> in the presence of many missing nodes, one may need an additional degree of regularization that encourages global smoothness of the graph’s edge weights, such as a combination of <inline-formula><mml:math id="inf403"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msubsup><mml:mi>ϕ</mml:mi><mml:mrow><mml:mi>λ</mml:mi><mml:mo>,</mml:mo><mml:mi>α</mml:mi></mml:mrow><mml:mrow><mml:msub><mml:mi>ℓ</mml:mi><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:msubsup><mml:mo stretchy="false">(</mml:mo><mml:mi mathvariant="bold-italic">w</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mstyle></mml:math></inline-formula> and <inline-formula><mml:math id="inf404"><mml:mrow><mml:msub><mml:mi mathsize="80%">ϕ</mml:mi><mml:mrow><mml:mi mathsize="80%">λ</mml:mi><mml:mo mathsize="80%" stretchy="false">,</mml:mo><mml:mi mathsize="80%">α</mml:mi></mml:mrow></mml:msub><mml:mo>⁢</mml:mo><mml:mrow><mml:mo maxsize="80%" minsize="80%">(</mml:mo><mml:mi mathsize="80%" mathvariant="bold-italic">𝒘</mml:mi><mml:mo maxsize="80%" minsize="80%">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> (in the same spirit as elastic net [<xref ref-type="bibr" rid="bib58">Zou and Hastie, 2005</xref>]), or <inline-formula><mml:math id="inf405"><mml:mrow><mml:msubsup><mml:mi mathsize="80%">ϕ</mml:mi><mml:mrow><mml:mi mathsize="80%">λ</mml:mi><mml:mo mathsize="80%" stretchy="false">,</mml:mo><mml:mi mathsize="80%">α</mml:mi></mml:mrow><mml:msub><mml:mi mathsize="80%" mathvariant="normal">ℓ</mml:mi><mml:mn mathsize="80%">1</mml:mn></mml:msub></mml:msubsup><mml:mo>⁢</mml:mo><mml:mrow><mml:mo maxsize="80%" minsize="80%">(</mml:mo><mml:mi mathsize="80%" mathvariant="bold-italic">𝒘</mml:mi><mml:mo maxsize="80%" minsize="80%">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> on top of node-based parameterization (see <xref ref-type="fig" rid="app1fig18">Appendix 1—figure 18B</xref>).</p></sec><sec id="s15" sec-type="appendix"><title>Coalescent simulations with weak migration</title><p>In <xref ref-type="fig" rid="fig2">Figure 2</xref>, we evaluated FEEMS by applying it to ‘out-of-model’ coalescent simulations. In these simulations, we generated genotype data under a coalescent model with structured meta-populations organized on a spatial triangular lattice. In a relatively ‘strong’ heterogeneous migration scenario (<xref ref-type="fig" rid="fig2">Figure 2D,E,F</xref>), we set the coalescent migration rate to be an order of magnitude lower (10-fold) in the center of the spatial grid than on the left and right regions, emulating a depression in gene-flow caused, for example, by a mountain range or body of water. The variation in migration rates should create a spatially varying covariance structure in the genetic variation data. To get a sense of the level of genetic divergence implied by this simulation setting, we visualized Wright’s fixation index (<inline-formula><mml:math id="inf406"><mml:msub><mml:mi mathsize="80%">F</mml:mi><mml:mrow><mml:mi mathsize="80%">S</mml:mi><mml:mo>⁢</mml:mo><mml:mi mathsize="80%">T</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula>, Patterson’s estimator [<xref ref-type="bibr" rid="bib39">Patterson et al., 2012</xref>]) plotted against the geographic distance between nodes (<xref ref-type="fig" rid="app1fig20">Appendix 1—figure 20</xref>). We see in the strong heterogeneous migration simulation there is a clear signal of two clusters of data points (<xref ref-type="fig" rid="app1fig20">Appendix 1—figure 20B</xref>). These clusters correspond to pairwise <inline-formula><mml:math id="inf407"><mml:msub><mml:mi mathsize="80%">F</mml:mi><mml:mrow><mml:mi mathsize="80%">S</mml:mi><mml:mo>⁢</mml:mo><mml:mi mathsize="80%">T</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> comparisons of two nodes on the same side of the central depression in gene flow, where gene-flow roughly follows a homogeneous ‘isolation-by-distance’ like pattern, or two nodes across the central depression where gene-flow is reduced, hence increasing the expected <inline-formula><mml:math id="inf408"><mml:msub><mml:mi mathsize="80%">F</mml:mi><mml:mrow><mml:mi mathsize="80%">S</mml:mi><mml:mo>⁢</mml:mo><mml:mi mathsize="80%">T</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> between such nodes.</p><p>While simulating this strong reduction of gene-flow provides an illustrative and clear example where FEEMS has a lot of signal for accurate inference, we wanted to understand the qualitative performance of FEEMS in an less idealized scenario with weaker signal. To this end, we performed coalescent simulations with only a 25% reduction of gene-flow in the center of the habitat (<xref ref-type="fig" rid="app1fig21">Appendix 1—figure 21</xref>). In <xref ref-type="fig" rid="app1fig21">Appendix 1—figure 21A</xref>, when all the nodes are observed on the spatial graph, FEEMS is still able to detect this subtle reduction of gene-flow. While FEEMS is able to detect this signal, there remain particularly erroneous estimates among the lower than average edge weights, implying the fit could benefit from additional smoothing by increasing the level regularization on the smoothness penalty. In contrast to the strong heterogeneous migration simulations, we see that the pairwise <inline-formula><mml:math id="inf409"><mml:msub><mml:mi mathsize="80%">F</mml:mi><mml:mrow><mml:mi mathsize="80%">S</mml:mi><mml:mo>⁢</mml:mo><mml:mi mathsize="80%">T</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> in this weak migration scenario does not obviously show a ‘clustering’ like effect in the data (<xref ref-type="fig" rid="app1fig20">Appendix 1—figure 20A</xref>). The average <inline-formula><mml:math id="inf410"><mml:msub><mml:mi mathsize="80%">F</mml:mi><mml:mrow><mml:mi mathsize="80%">S</mml:mi><mml:mo>⁢</mml:mo><mml:mi mathsize="80%">T</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> between all pairs of demes is approximately three times lower (mean <inline-formula><mml:math id="inf411"><mml:mrow><mml:msub><mml:mi mathsize="80%">F</mml:mi><mml:mrow><mml:mi mathsize="80%">S</mml:mi><mml:mo>⁢</mml:mo><mml:mi mathsize="80%">T</mml:mi></mml:mrow></mml:msub><mml:mo mathsize="80%" stretchy="false">=</mml:mo><mml:mn mathsize="80%">.1175</mml:mn></mml:mrow></mml:math></inline-formula> for the weak heterogeneity simulation versus mean <inline-formula><mml:math id="inf412"><mml:msub><mml:mi mathsize="80%">F</mml:mi><mml:mrow><mml:mi mathsize="80%">S</mml:mi><mml:mo>⁢</mml:mo><mml:mi mathsize="80%">T</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> = 0.3411 for the strong heterogeneity simulation). When the nodes are sparsely observed on the graph in this weak migration simulation, we see that the FEEMS output is overly smooth (<xref ref-type="fig" rid="app1fig21">Appendix 1—figure 21B</xref>). In the absence of data and thus a weak signal for spatial variation in migration, a smooth visualization is arguably a sensible outcome given the regularization acts like a prior distribution favoring spatial homogeneity in levels of effective migration.</p><p>In practice, weak population structure can be more accurately dissected when increasing the number of informative SNPs included in the analysis (<xref ref-type="bibr" rid="bib37">Novembre and Peter, 2016</xref>). In conjunction with running FEEMS, we recommend for users to create exploratory visualizations such as variograms and PCA bi-plots to assess the level of population structure in their data, and to consider the number of SNPs used in the analysis.</p><fig id="app1fig1" position="float"><label>Appendix 1—figure 1.</label><caption><title>Visualization of grid construction and node assignment: (<bold>A</bold>) Map of sample coordinates (black points) from a dataset of gray wolves from North America.</title><p>The input to FEEMS are latitude and longitude coordinates as well as genotype data for each sample. (<bold>B</bold>) Map of sample coordinates with an example dense spatial grid. The nodes of the grid represent sub-populations and the edges represent local gene-flow between adjacent sub-populations. (<bold>C</bold>) Individuals are assigned to nearby nodes (sub-populations) and summary statistics (e.g. allele frequencies) are computed for each observed location.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-61927-app1-fig1-v1.tif"/></fig><fig id="app1fig2" position="float"><label>Appendix 1—figure 2.</label><caption><title>Application of FEEMS to an extended set of coalescent simulations: We display an extended set of coalescent simulations with multiple migration scenarios and sampling designs.</title><p>The sample sizes across the grid are represented by the size of the gray dots at each node. The migration rates are obtained by solving FEEMS objective function <xref ref-type="disp-formula" rid="equ18">Equation 9</xref> where the the smoothness parameter λ was selected using leave-one-out cross-validation. (<bold>A, F, K</bold>) display the ground truth of the underlying migration rates. (<bold>B, G, L</bold>) shows simulations where there is no missing data on the graph. (<bold>C, H, M</bold>) shows simulations with sparse observations and nodes missing at random. (<bold>D, I, N</bold>) shows simulations of biased sampling where there are no samples from the center of the simulated habitat. (<bold>E, J, O</bold>) shows simulations of biased sampling where there are only samples on the right side of the habitat.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-61927-app1-fig2-v1.tif"/></fig><fig id="app1fig3" position="float"><label>Appendix 1—figure 3.</label><caption><title>Application of FEEMS to a heterogeneous migration scenario with a ‘missing at random’ sampling design: We run FEEMS on coalescent simulation with a non-homogeneous process while varying hyperparameters λ (rows) and α (columns).</title><p>We randomly sample individuals for 20% of nodes. When λ grows, the fitted graph becomes overall smoother, whereas α effectively controls the degree of similarity among low migration rates.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-61927-app1-fig3-v1.tif"/></fig><fig id="app1fig4" position="float"><label>Appendix 1—figure 4.</label><caption><title>Application of FEEMS to an anisotropic migration scenario with a ‘missing at random’ sampling design: We run FEEMS on coalescent simulation with an anisotropic process while varying hyperparameters λ (rows) and α (columns).</title><p>We randomly sample individuals for 20% of nodes. When λ grows, the fitted graph becomes overall smoother, whereas α effectively controls the degree of similarity among low migration rates.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-61927-app1-fig4-v1.tif"/></fig><fig id="app1fig5" position="float"><label>Appendix 1—figure 5.</label><caption><title>SNP and individual quality control.</title><p>(<bold>A</bold>) displays a visualization of the sample site frequency spectrum. Specifically, we display a histogram of minor allele frequencies across all SNPs. We see a relatively uniform histogram which reflects the ascertainment of common SNPs on the array that was designed to genotype gray wolf samples. (<bold>B</bold>) visualization of allele frequencies plotted against genotype frequencies. Each point represents a different SNP and the colors represent the three possible genotype values. The black dashed lines display the expectation as predicted from a simple binomial sampling model i.e., Hardy-Weinberg equilibrium. (<bold>C</bold>) displays a histogram of the missingness fraction per SNP. We observe the missingness tends to be relatively low for each SNP. (<bold>D</bold>) displays a histogram of the missingness fraction per sample. Generally, the missingness tends to be low for each sample.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-61927-app1-fig5-v1.tif"/></fig><fig id="app1fig6" position="float"><label>Appendix 1—figure 6.</label><caption><title>Comparing predictions of observed genetic distances: We display different predictions of observed genetic distances using geographic distance or the fitted genetic distance output by FEEMS.</title><p>(<bold>A</bold>) The x-axis displays the geographic distance between two individuals, as measured by the great circle distance (haversine distance). The y-axis displays the squared Euclidean distance between two individuals averaged over all SNPs. (<bold>B–D</bold>) The x-axis displays the fitted genetic distance as predicted by the FEEMS model and y-axis displays the squared Euclidean distance between two sub-populations averaged over all SNPs. For (<bold>B–D</bold>), we display the fit of λ getting subsequently smaller, <inline-formula><mml:math id="inf413"><mml:mrow><mml:mi>λ</mml:mi><mml:mo>=</mml:mo><mml:mrow><mml:mn>100</mml:mn><mml:mo>,</mml:mo><mml:mn>2.06</mml:mn><mml:mo>,</mml:mo><mml:mn>0.04</mml:mn></mml:mrow></mml:mrow></mml:math></inline-formula> (the same values of λ used in <xref ref-type="fig" rid="fig3">Figure 3A,B,C</xref>), and as expected the fit appears better because we tolerate more complex surfaces and we are not evaluating the fit on out-of-sample data.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-61927-app1-fig6-v1.tif"/></fig><fig id="app1fig7" position="float"><label>Appendix 1—figure 7.</label><caption><title>Summary of top axes of genotypic variation: We display a visual summary of Principal Components Analysis (PCA) applied to the normalized genotype matrix from the North American gray wolf dataset.</title><p>(<bold>A–D</bold>) displays PC bi-plots of the top seven PCs plotted against each other. The colors represent predefined ecotypes defined in <xref ref-type="bibr" rid="bib51">Schweizer et al., 2016</xref>. We can see that the top PCs delineate these predefined ecotypes. (<bold>E</bold>) shows a ‘scree’ plot with the proportion of variance explained for each of the top 50 PCs. As expected by genetic data (<xref ref-type="bibr" rid="bib38">Patterson et al., 2006</xref>), the eigenvalues of the genotype matrix tend to be spread over many PCs.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-61927-app1-fig7-v1.tif"/></fig><fig id="app1fig8" position="float"><label>Appendix 1—figure 8.</label><caption><title>Relationship between top axes of genetic variation and latitude: In each sub-panel, we plot the PC value against latitude for each sample in gray the wolf dataset.</title><p>We see many of the top PCs are significantly correlated with latitude as tested by linear regression.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-61927-app1-fig8-v1.tif"/></fig><fig id="app1fig9" position="float"><label>Appendix 1—figure 9.</label><caption><title>Relationship between top axes of genetic variation and longitude: In each sub-panel, we plot the PC value against longitude for each sample in the gray wolf dataset.</title><p>We see many of the top PCs are significantly correlated with longitude as tested by linear regression.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-61927-app1-fig9-v1.tif"/></fig><fig id="app1fig10" position="float"><label>Appendix 1—figure 10.</label><caption><title>Summary of ADMIXTURE results: (<bold>A–G</bold>) Visualization of ADMIXTURE results for <inline-formula><mml:math id="inf414"><mml:mrow><mml:mi>K</mml:mi><mml:mo>=</mml:mo><mml:mn>2</mml:mn></mml:mrow></mml:math></inline-formula> to <inline-formula><mml:math id="inf415"><mml:mrow><mml:mi>K</mml:mi><mml:mo>=</mml:mo><mml:mn>8</mml:mn></mml:mrow></mml:math></inline-formula>.</title><p>We display admixture fractions for each sample as colored slices of the pie chart on the map. For each <inline-formula><mml:math id="inf416"><mml:mi>K</mml:mi></mml:math></inline-formula>, we ran five replicate runs of ADMIXTURE and in this visualization, we display the solution that achieves the highest likelihood amongst the replicates. The ADMIXTURE results qualitatively reveal a spatial signal in the data as admixture fractions tend to be spatially clustered.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-61927-app1-fig10-v1.tif"/></fig><fig id="app1fig11" position="float"><label>Appendix 1—figure 11.</label><caption><title>Application of EEMS to the North American gray wolf dataset: We display a visualization of EEMS applied to the North American gray wolf dataset.</title><p>The more orange colors represent lower than average effective migration on the log-scale and the more blue colors represent higher than average effective migration on the log-scale. The results of EEMS are qualitatively similar to FEEMS when lower regularization penalties are applied.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-61927-app1-fig11-v1.tif"/></fig><fig id="app1fig12" position="float"><label>Appendix 1—figure 12.</label><caption><title>Application of FEEMS on the North American gray wolf dataset with an exact likelihood model: We display the fit of FEEMS based on the formulation <xref ref-type="disp-formula" rid="equ46">Equation (21)</xref> to the North American gray wolf dataset.</title><p>This fit corresponds to a setting of tuning parameters at <inline-formula><mml:math id="inf417"><mml:mrow><mml:mi>λ</mml:mi><mml:mo>=</mml:mo><mml:mn>2.06</mml:mn></mml:mrow></mml:math></inline-formula> and <inline-formula><mml:math id="inf418"><mml:mrow><mml:mi>α</mml:mi><mml:mo>=</mml:mo><mml:mrow><mml:mn>1</mml:mn><mml:mo>/</mml:mo><mml:msub><mml:mover accent="true"><mml:mi>w</mml:mi><mml:mo>^</mml:mo></mml:mover><mml:mn>0</mml:mn></mml:msub></mml:mrow></mml:mrow></mml:math></inline-formula>. Additionally, we set the lower bound of the edge weights to <inline-formula><mml:math id="inf419"><mml:mrow><mml:mi mathvariant="bold-italic">𝒍</mml:mi><mml:mo>=</mml:mo><mml:msup><mml:mn>10</mml:mn><mml:mrow><mml:mo>-</mml:mo><mml:mn>6</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:math></inline-formula>, to ensure that the diagonal elements of <inline-formula><mml:math id="inf420"><mml:mi mathvariant="bold-italic">𝑳</mml:mi></mml:math></inline-formula> does not become too small—this has an implicit effect on <inline-formula><mml:math id="inf421"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msubsup><mml:mi>L</mml:mi><mml:mrow><mml:mi>k</mml:mi><mml:mi>k</mml:mi></mml:mrow><mml:mrow><mml:mo>†</mml:mo></mml:mrow></mml:msubsup></mml:mrow></mml:mstyle></mml:math></inline-formula>, preventing it from blowing up at unobserved nodes. The more orange colors represent lower than average effective migration on the log-scale and the more blue colors represent higher than average effective migration on the log-scale. Visually, the result is comparable to that of the FEEMS fit (<xref ref-type="fig" rid="fig4">Figure 4</xref>) based on the approximate formulation (Optimization).</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-61927-app1-fig12-v1.tif"/></fig><fig id="app1fig13" position="float"><label>Appendix 1—figure 13.</label><caption><title>Application of FEEMS on the North American gray wolf dataset with joint estimation of the residual variances and graph’s edge weights: We show visualizations of fits of FEEMS to the North American gray wolf dataset when the residual variances and edge weights of the graph are jointly estimated.</title><p>Both fits correspond to a setting of tuning parameters at <inline-formula><mml:math id="inf422"><mml:mrow><mml:mi>λ</mml:mi><mml:mo>=</mml:mo><mml:mn>2.06</mml:mn></mml:mrow></mml:math></inline-formula> and <inline-formula><mml:math id="inf423"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>α</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn><mml:mrow><mml:mo>/</mml:mo></mml:mrow><mml:msub><mml:mrow><mml:mover><mml:mi>w</mml:mi><mml:mo>^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula>. (<bold>A</bold>) displays the estimated effective migration surfaces where every deme shares a single residual parameter σ. (<bold>B</bold>) displays the estimated effective migration surfaces where each node has its own residual parameter <inline-formula><mml:math id="inf424"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>σ</mml:mi><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula>. Both approaches yield similar results to the procedure that prefixes σ from the homogeneous isolation by distance model (<xref ref-type="fig" rid="fig4">Figure 4</xref>). The node-specific residual parameters may allow for more flexible graphs to be fitted, and we can further observe reduced effective migration around C (Queen Elizabeth Islands) in (<bold>B</bold>).</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-61927-app1-fig13-v1.tif"/></fig><fig id="app1fig14" position="float"><label>Appendix 1—figure 14.</label><caption><title>Relationship between fitted versus observed genetic dissimilarities on the North American gray wolf dataset: We display scatter plots of fitted genetic distance versus observed genetic distance from FEEMS fits on the gray wolf dataset.</title><p>(<bold>A</bold>) Corresponds to the result shown in <xref ref-type="fig" rid="fig4">Figure 4</xref>. (<bold>B</bold>) Corresponds to the result shown in <xref ref-type="fig" rid="app1fig13">Appendix 1—figure 13B</xref>. The x-axis displays the fitted genetic distance as predicted by the FEEMS model and y-axis displays the squared Euclidean distance between two sub-populations averaged over all SNPs. The simple linear regression fit is shown in orange dashed lines and <inline-formula><mml:math id="inf425"><mml:msup><mml:mi>R</mml:mi><mml:mn>2</mml:mn></mml:msup></mml:math></inline-formula> is given.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-61927-app1-fig14-v1.tif"/></fig><fig id="app1fig15" position="float"><label>Appendix 1—figure 15.</label><caption><title>Application of FEEMS to a dataset of human genetic variation from Africa with different parameterization: We display visualizations of FEEMS to a dataset of human genetic variation from Africa with different parameterization of the graph’s edge weights.</title><p>See <xref ref-type="bibr" rid="bib40">Peter et al., 2020</xref> for the description of the dataset. (<bold>A</bold>) displays the recovered graph under the edge parameterization. (<bold>B</bold>) displays the recovered graph under the node parameterization. Both parameterization have their own regularization parameters λ and α, but these parameters are not on the same scale. We set <inline-formula><mml:math id="inf426"><mml:mrow><mml:mi>λ</mml:mi><mml:mo>=</mml:mo><mml:mn>0.2</mml:mn></mml:mrow></mml:math></inline-formula> and <inline-formula><mml:math id="inf427"><mml:mrow><mml:mi>α</mml:mi><mml:mo>=</mml:mo><mml:mn>0.02</mml:mn></mml:mrow></mml:math></inline-formula> for the node parameterization which is seen to yield similar results to those in <xref ref-type="bibr" rid="bib40">Peter et al., 2020</xref>. For the edge parameterization, we set <inline-formula><mml:math id="inf428"><mml:mrow><mml:mi>λ</mml:mi><mml:mo>=</mml:mo><mml:mn>0.5</mml:mn></mml:mrow></mml:math></inline-formula> and <inline-formula><mml:math id="inf429"><mml:mrow><mml:mi>α</mml:mi><mml:mo>=</mml:mo><mml:mn>0.05</mml:mn></mml:mrow></mml:math></inline-formula> so that the resulting graph reveals similar geographic structure to the node parameterization. We also set the lower bound <inline-formula><mml:math id="inf430"><mml:mrow><mml:mi mathvariant="bold-italic">𝒍</mml:mi><mml:mo>=</mml:mo><mml:msup><mml:mn>10</mml:mn><mml:mrow><mml:mo>-</mml:mo><mml:mn>6</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:math></inline-formula>. From the plots, it is worth noting two important distinctions: (1) We see the migration surfaces shown in (<bold>B</bold>) recover sharper edge features while the migration surfaces in (<bold>A</bold>) are overall smoother. This is attributed to the fact that node parameterization has its own additional regularization effect on the edge weights, and in order to achieve similar degree of regularization strength for the edge parameterization, it needs a higher regularization parameters, which results in more blurring edges than the node parameterization. (2) When measuring correlation of the estimated allele frequencies among nodes, we find that Deme B is the node with the second highest correlation to Deme A, whereas Deme C (and nearby demes) is not as much correlated to Deme A compared to Deme B. Panel (<bold>A</bold>) reflects this feature by exhibiting a corridor between Deme A and Deme B and reduced gene-flow beneath that corridor. This reduced gene-flow disappears in (<bold>B</bold>), even if the regularization parameters are varied over a range of values. Additionally, Deme D is most highly correlated to Deme E, F, and G, and this is implicated by a long-range corridor connecting those demes appearing in Panel (<bold>A</bold>) while not shown in (<bold>B</bold>). These results suggest that the form of the node parameterization is perhaps too strong and in this case limits the model’s ability to capture desirable geographic features that are subtle to detect.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-61927-app1-fig15-v1.tif"/></fig><fig id="app1fig16" position="float"><label>Appendix 1—figure 16.</label><caption><title>Relationship between fitted versus observed genetic dissimilarities on a dataset of human genetic variation from Africa: We display scatter plots of fitted genetic distance versus observed genetic distance from FEEMS fits on the African dataset.</title><p>(<bold>A</bold>) Corresponds to the result shown in <xref ref-type="fig" rid="app1fig15">Appendix 1—figure 15A</xref>. (<bold>B</bold>) Corresponds to the result shown in <xref ref-type="fig" rid="app1fig15">Appendix 1—figure 15B</xref>. The x-axis displays the fitted genetic distance as predicted by the FEEMS model and y-axis displays the squared Euclidean distance between two sub-populations averaged over all SNPs. The simple linear regression fit is shown in orange dashed lines and <inline-formula><mml:math id="inf431"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msup><mml:mi>R</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:mstyle></mml:math></inline-formula> is given.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-61927-app1-fig16-v1.tif"/></fig><fig id="app1fig17" position="float"><label>Appendix 1—figure 17.</label><caption><title>Application of FEEMS based on node parameterization to an extended set of coalescent simulations: We display an extended set of coalescent simulations with the same migration scenarios and sampling designs as <xref ref-type="fig" rid="app1fig2">Appendix 1—figure 2</xref>.</title><p>The sample sizes across the grid are represented by the size of the gray dots at each node. The migration rates are obtained by solving the FEEMS objective function (Optimization) with node parameterization where the regularization parameters are specified at <inline-formula><mml:math id="inf432"><mml:mrow><mml:mi>λ</mml:mi><mml:mo>=</mml:mo><mml:mn>5</mml:mn></mml:mrow></mml:math></inline-formula> and <inline-formula><mml:math id="inf433"><mml:mrow><mml:mi>α</mml:mi><mml:mo>=</mml:mo><mml:mn>0.01</mml:mn></mml:mrow></mml:math></inline-formula>. (<bold>A, F, K</bold>) display the ground truth of the underlying migration rates. (<bold>B, G, L</bold>) shows simulations where there is no missing data on the graph. (<bold>C, H, M</bold>) shows simulations with sparse observations and nodes missing at random. (<bold>D, I, N</bold>) shows simulations of biased sampling where there are no samples from the center of the simulated habitat. (<bold>E, J, O</bold>) shows simulations of biased sampling where there are only samples on the right side of the habitat.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-61927-app1-fig17-v1.tif"/></fig><fig id="app1fig18" position="float"><label>Appendix 1—figure 18.</label><caption><title>Application of <inline-formula><mml:math id="inf434"><mml:msub><mml:mi mathvariant="normal">ℓ</mml:mi><mml:mn mathvariant="normal">1</mml:mn></mml:msub></mml:math></inline-formula>-norm-based FEEMS to a dataset of human genetic variation from Africa: We display visualizations of FEEMS to a dataset of human genetic variation from Africa with the <inline-formula><mml:math id="inf435"><mml:msub><mml:mi mathvariant="normal">ℓ</mml:mi><mml:mn>1</mml:mn></mml:msub></mml:math></inline-formula>-based penalty function.</title><p>See <xref ref-type="bibr" rid="bib40">Peter et al., 2020</xref> for the description of the dataset. (<bold>A</bold>) displays the recovered graph under the edge parameterization with <inline-formula><mml:math id="inf436"><mml:msub><mml:mi mathvariant="normal">ℓ</mml:mi><mml:mn>1</mml:mn></mml:msub></mml:math></inline-formula> norm based penalty where the regularization parameters are specified at <inline-formula><mml:math id="inf437"><mml:mrow><mml:mi>λ</mml:mi><mml:mo>=</mml:mo><mml:mn>0.05</mml:mn></mml:mrow></mml:math></inline-formula> and <inline-formula><mml:math id="inf438"><mml:mrow><mml:mi>α</mml:mi><mml:mo>=</mml:mo><mml:mn>5</mml:mn></mml:mrow></mml:math></inline-formula>. (<bold>B</bold>) displays the recovered graph under the node parameterization with <inline-formula><mml:math id="inf439"><mml:msub><mml:mi mathvariant="normal">ℓ</mml:mi><mml:mn>1</mml:mn></mml:msub></mml:math></inline-formula> norm-based penalty where the regularization parameters are specified at <inline-formula><mml:math id="inf440"><mml:mrow><mml:mi>λ</mml:mi><mml:mo>=</mml:mo><mml:mn>0.05</mml:mn></mml:mrow></mml:math></inline-formula> and <inline-formula><mml:math id="inf441"><mml:mrow><mml:mi>α</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:math></inline-formula>. To minimize the objective <xref ref-type="disp-formula" rid="equ51">Equation (23)</xref>, linearized ADMM is applied with 20,000 number of iterations. The lower bound is set to be <inline-formula><mml:math id="inf442"><mml:mrow><mml:mi mathvariant="bold-italic">𝒍</mml:mi><mml:mo>=</mml:mo><mml:msup><mml:mn>10</mml:mn><mml:mrow><mml:mo>-</mml:mo><mml:mn>6</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:math></inline-formula> for both parameterizations. Note that due to the high degrees of missingness, the estimated effective migration surfaces using solely <inline-formula><mml:math id="inf443"><mml:msub><mml:mi mathvariant="normal">ℓ</mml:mi><mml:mn>1</mml:mn></mml:msub></mml:math></inline-formula>-based penalty exhibit many likely artifacts (e.g. high migration edges forming long paths, seen in panel A) unless an additional regularization is added to encourage global smoothness of the edge weights, such as a combination of <inline-formula><mml:math id="inf444"><mml:msub><mml:mi mathvariant="normal">ℓ</mml:mi><mml:mn>1</mml:mn></mml:msub></mml:math></inline-formula> norm penalty function and node parameterization as shown in (<bold>B</bold>).</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-61927-app1-fig18-v1.tif"/></fig><fig id="app1fig19" position="float"><label>Appendix 1—figure 19.</label><caption><title>Application of <inline-formula><mml:math id="inf445"><mml:msub><mml:mi mathvariant="normal">ℓ</mml:mi><mml:mn mathvariant="normal">1</mml:mn></mml:msub></mml:math></inline-formula>-norm-based FEEMS to an extended set of coalescent simulations: We display an extended set of coalescent simulations with the same migration scenarios and sampling designs as <xref ref-type="fig" rid="app1fig2">Appendix 1—figure 2</xref>.</title><p>The sample sizes across the grid are represented by the size of the gray dots at each node. The migration rates are obtained by solving <inline-formula><mml:math id="inf446"><mml:msub><mml:mi mathvariant="normal">ℓ</mml:mi><mml:mn>1</mml:mn></mml:msub></mml:math></inline-formula> norm based FEEMS objective <xref ref-type="disp-formula" rid="equ51">Equation (23)</xref> where the regularization parameters are specified at <inline-formula><mml:math id="inf447"><mml:mrow><mml:mi>λ</mml:mi><mml:mo>=</mml:mo><mml:mn>5</mml:mn></mml:mrow></mml:math></inline-formula> and <inline-formula><mml:math id="inf448"><mml:mrow><mml:mi>α</mml:mi><mml:mo>=</mml:mo><mml:mn>0.01</mml:mn></mml:mrow></mml:math></inline-formula>. (<bold>A, F, K</bold>) display the ground truth of the underlying migration rates. (<bold>B, G, L</bold>) shows simulations where there is no missing data on the graph. (<bold>C, H, M</bold>) shows simulations with sparse observations and nodes missing at random. (<bold>D, I, N</bold>) shows simulations of biased sampling where there are no samples from the center of the simulated habitat. (<bold>E, J, O</bold>) shows simulations of biased sampling where there are only samples on the right side of the habitat.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-61927-app1-fig19-v1.tif"/></fig><fig id="app1fig20" position="float"><label>Appendix 1—figure 20.</label><caption><title>Comparing pairwise <inline-formula><mml:math id="inf449"><mml:msub><mml:mi>F</mml:mi><mml:mrow><mml:mi>s</mml:mi><mml:mo mathvariant="bold">⁢</mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> between strong and weak heterogeneous migration coalescent simulations: We visualize of the relationship between geographic distance and estimated pairwise <inline-formula><mml:math id="inf450"><mml:msub><mml:mi>F</mml:mi><mml:mrow><mml:mi>s</mml:mi><mml:mo>⁢</mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> (genetic distance) between nodes on the spatial grid for a weak heterogeneous migration simulation (<bold>A</bold>) and a strong heterogeneous migration (<bold>B</bold>).</title><p>As expected the average <inline-formula><mml:math id="inf451"><mml:msub><mml:mi>F</mml:mi><mml:mrow><mml:mi>s</mml:mi><mml:mo>⁢</mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> is lower for the weak migration setting, and we observe a clear clustering like effect in the data for the strong heterogeneous migration simulation. This strong clustering effect can be attributed to pairwise comparisons of nodes across the region of reduced gene flow. Distances between nodes were set to one in the simulation, and so the units of geographic distance here are in units of the inter-node distance.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-61927-app1-fig20-v1.tif"/></fig><fig id="app1fig21" position="float"><label>Appendix 1—figure 21.</label><caption><title>Applications of FEEMS to weak migration coalescent simulations: We visualize the FEEMS fit to coalescent simulations with weak heterogeneous migration.</title><p>The coalescent migration rate in the center of the habitat is set to be 25% lower than the left or right regions. Note that the color-scale limits are set to <inline-formula><mml:math id="inf452"><mml:msup><mml:mn>10</mml:mn><mml:mrow><mml:mo>-</mml:mo><mml:mn>.15</mml:mn></mml:mrow></mml:msup></mml:math></inline-formula> and <inline-formula><mml:math id="inf453"><mml:msup><mml:mn>10</mml:mn><mml:mn>.15</mml:mn></mml:msup></mml:math></inline-formula>, respectively. The top panel shows the fit when all the nodes of the spatial graph are observed, whereas the bottom panel shows the fit when a sparse subset of nodes are observed. We see that FEEMS can still detect a signal of heterogeneity by displaying reduced gene-flow in the center of the habitat in the top panel. When we observe only a few nodes, in this weak migration setting, the FEEMS visualization looks overly smooth.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-61927-app1-fig21-v1.tif"/></fig><fig id="app1fig22" position="float"><label>Appendix 1—figure 22.</label><caption><title>EEMS fitted versus observed genetic dissimilarities from the North American gray wolf dataset: We visualize fitted versus observed genetic dissimilarities corresponding to the EEMS visualization run on the North American gray wolf dataset in <xref ref-type="fig" rid="fig4">Figure 4</xref>.</title><p>EEMS was run on a sparse grid with 307 nodes due to long run-times on the dense grid. Generally there is good concordance between the fitted and observed dissimilarities except for a small set of points whose fitted genetic dissimilarity over-estimates the observed dissimilarity, implying a relatively poorly fit for these points. Note, we do not see these poorly fit points in visualizations of the fitted versus observed distances when using FEEMS (see <xref ref-type="fig" rid="app1fig6">Appendix 1—figure 6</xref>).</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-61927-app1-fig22-v1.tif"/></fig></sec></boxed-text></app></app-group></back><sub-article article-type="decision-letter" id="sa1"><front-stub><article-id pub-id-type="doi">10.7554/eLife.61927.sa1</article-id><title-group><article-title>Decision letter</article-title></title-group><contrib-group><contrib contrib-type="editor"><name><surname>Perry</surname><given-names>George H</given-names></name><role>Reviewing Editor</role><aff><institution>Pennsylvania State University</institution><country>United States</country></aff></contrib></contrib-group><contrib-group><contrib contrib-type="reviewer"><name><surname>Alves</surname><given-names>Isabel</given-names> </name><role>Reviewer</role><aff><institution>University of Nantes</institution><country>France</country></aff></contrib><contrib contrib-type="reviewer"><name><surname>Tansey</surname><given-names>Wesley</given-names> </name><role>Reviewer</role><aff><institution/></aff></contrib></contrib-group></front-stub><body><boxed-text><p>In the interests of transparency, eLife publishes the most substantive revision requests and the accompanying author responses.</p></boxed-text><p><bold>Acceptance summary:</bold></p><p>The authors of the manuscript present a new implementation of the previously developed statistical method called &quot;Estimating Effective Migration Surfaces&quot;, which displays on geographical map regions of low or high effective migration under a broad model of isolation by distance. In this new implementation migration surfaces are estimated under a penalized-likelihood approach coupled with optimization instead of MCMC leading to faster running times. The new implementation facilitates faster running times to make its usage computationally possible for a wider range of research groups and likely be applied to an even larger number of species/populations.</p><p><bold>Decision letter after peer review:</bold></p><p>Thank you for submitting your article &quot;Fast and Flexible Estimation of Effective Migration Surfaces&quot; for consideration by <italic>eLife</italic>. Your article has been reviewed by 2 peer reviewers, and the evaluation has been overseen by George Perry as the Senior and Reviewing Editor. The following individuals involved in review of your submission have agreed to reveal their identity: Isabel Alves (Reviewer #1); Wesley Tansey (Reviewer #2).</p><p>The reviewers have discussed the reviews with one another and the Reviewing Editor has drafted this decision to help you prepare a revised submission.</p><p>As the editors have judged that your manuscript is of interest, but as described below that additional analyses are required before it is published, we would like to draw your attention to changes in our revision policy that we have made in response to COVID-19 (https://elifesciences.org/articles/57162). First, because many researchers have temporarily lost access to the labs, we will give authors as much time as they need to submit revised manuscripts. We are also offering, if you choose, to post the manuscript to bioRxiv (if it is not already there) along with this decision letter and a formal designation that the manuscript is &quot;in revision at <italic>eLife</italic>&quot;. Please let us know if you would like to pursue this option. (If your work is more suitable for medRxiv, you will need to post the preprint yourself, as the mechanisms for us to do so are still in development.)</p><p>Summary:</p><p>The authors of the manuscript present a new implementation of the previously developed statistical method called &quot;Estimating Effective Migration Surfaces&quot;, which displays on a geographical map regions of low or high effective migration under a broad model of isolation by distance. In this new implementation migration surfaces are estimated under a penalized-likelihood approach coupled with optimization instead of MCMC leading to faster running times. The new implementation appears very promising as faster running times will make its usage computationally possible for a wider range of research groups and likely be applied to an even larger number of species/populations. Overall, we value the approach for its pragmatism but felt that it falls short at the very end by failing to provide any quantitative, objective way to choose the hyperparameters, which needs to be addressed as per the essential revisions detailed below.</p><p>Essential revisions:</p><p>1. The authors need to provide principled (or at least reproducible) ways to select the hyperparameters. Specific reviewer comments include:</p><p>&quot;This is a major benefit of the L1 penalty. You can use BIC as the model selection criterion in the L1 case since the degrees of freedom are well-described. In the squared L2 case, it's not really possible. The authors discuss the issue and note LOOCV did not produce stable results, but they do not provide any data or examples. A more thorough investigation of hyperparameter settings is needed along with a recommendation that does not rely on biologists' subjective preference of the results on each dataset.&quot;</p><p>&quot;FEEMS outcomes are very sensitive to user-based settings such as grid density and tuning parameters, as well as to aspects of the real data (eg. sampling design) that may result in an arbitrary choice of the outcome and lead to over-interpretations. I know the authors recommend to explore several combinations of regularization parameters and then compare FEEMS results with clustering/differentiation patterns based on approaches like ADMIXTURE or FST distances in order to support the results, nevertheless it is still difficult to grasp what's the best strategy to assess if a fitted graph is over-fitting the observed data or instead is pointing out to a real area of, let's say, low effective migration rate. Sentences like: &quot;…, while setting up the tuning parameter ɑ to a value that we found that worked for multiple data applications.…&quot; (lines: 225-226) or &quot;it is helpful to look more closely at particular solutions that find balance between spatial homogeneity and complexity…&quot; (lines: 243-245) are confusing and make difficult the choice of the final regularization parameters.&quot;</p><p>&quot;The grid design is another arbitrary aspect of the method whose influence on the identification of regions of low or high migration isn't clear. Imagining one has the computational power to construct a very dense grid, is it worth doing it once there is observed data in 1% of the nodes? Is there a good relationship between density and number of sampled points? Does it affect the outcome?&quot;</p><p>&quot;I think the points above would be clearer if the authors would provide for instance, step-by-step guidelines to help future users of FEEMS and referring to specific examples in the manuscript in order to more clearly justify their parameter choice (eg ɑ = 50 line 226).&quot;</p><p>2. Please clarify the modeling decision and its comparison to the L1 approach. For instance, isn't smoothing over nodes vs edges really just the same thing with different penalties? The authors form a lifted graph, where edges are now nodes and they penalize differences between neighboring edges. In the L1 penalty case with a squared error loss, the fused lasso / total variation penalty on neighboring edges is equivalent to linear trend filtering on the nodes. The choice then of linear trend filtering could have been replaced with a higher order trend filtering step to achieve the smoothness that the authors seem to say is lacking in the L1 model.</p><p>3. Are the data points we observe actually sampled at random? Is some sort of latent confounding likely? For example, maybe wolves migrate based on the season and the scientists collecting the data only look in one spot in one particular time of year?</p><p>4. Please clarify the simulation results in Supp Fig19, panels I and J. Without any data points in the orange regions for panel I, the model somehow infers that there is a band of different edge weights. How? In the 1d case, it's as if someone showed you: [5, 5, 5, missing, missing, missing, 5 ,5 5], and you come back and told me [5, 5, 5, -3, -3, -3, 5, 5, 5]. Is this possible?</p><p>5. At present, there is no real quantitative assessment of how good the FEEMS solutions are relative to the EEMS solution. This should be provided.</p><p>6. It would be useful to provide another example of a heterogeneous migration scenario where the reduction in migration is less than one order of magnitude in order to give an idea to the user of how the method performs in a less heterogeneous scenario (ie the lower bound).</p></body></sub-article><sub-article article-type="reply" id="sa2"><front-stub><article-id pub-id-type="doi">10.7554/eLife.61927.sa2</article-id><title-group><article-title>Author response</article-title></title-group></front-stub><body><disp-quote content-type="editor-comment"><p>Essential revisions:</p><p>1. The authors need to provide principled (or at least reproducible) ways to select the hyperparameters. Specific reviewer comments include:</p><p>&quot;This is a major benefit of the L1 penalty. You can use BIC as the model selection criterion in the L1 case since the degrees of freedom are well-described. In the squared L2 case, it's not really possible. The authors discuss the issue and note LOOCV did not produce stable results, but they do not provide any data or examples. A more thorough investigation of hyperparameter settings is needed along with a recommendation that does not rely on biologists' subjective preference of the results on each dataset.&quot;</p><p>&quot;FEEMS outcomes are very sensitive to user-based settings such as grid density and tuning parameters, as well as to aspects of the real data (eg. sampling design) that may result in an arbitrary choice of the outcome and lead to over-interpretations. I know the authors recommend to explore several combinations of regularization parameters and then compare FEEMS results with clustering/differentiation patterns based on approaches like ADMIXTURE or FST distances in order to support the results, nevertheless it is still difficult to grasp what's the best strategy to assess if a fitted graph is over-fitting the observed data or instead is pointing out to a real area of, let's say, low effective migration rate. Sentences like: &quot;…, while setting up the tuning parameter ɑ to a value that we found that worked for multiple data applications.…&quot; (lines: 225-226) or &quot;it is helpful to look more closely at particular solutions that find balance between spatial homogeneity and complexity…&quot; (lines: 243-245) are confusing and make difficult the choice of the final regularization parameters.&quot;</p><p>&quot;The grid design is another arbitrary aspect of the method whose influence on the identification of regions of low or high migration isn't clear. Imagining one has the computational power to construct a very dense grid, is it worth doing it once there is observed data in 1% of the nodes? Is there a good relationship between density and number of sampled points? Does it affect the outcome?&quot;</p><p>&quot;I think the points above would be clearer if the authors would provide for instance, step-by-step guidelines to help future users of FEEMS and referring to specific examples in the manuscript in order to more clearly justify their parameter choice (eg ɑ = 50 line 226).&quot;</p></disp-quote><p>We thank the reviewers for these helpful comments in regards to selecting the hyper-parameters of the penalty and agree that an automated selection procedure would help improve the interpretability and usability of FEEMS. To this end, we have made a number of updates to our modeling approach that have allowed for fully automated hyper-parameter selection and have proven to work well in practice. These developments were yielded through a simple but effective update of the parameterization of our penalty that allows for a cross-validation approach over just the smoothness parameter lambda alone. Specifically, we utilize the solution of the edge weights fitted under a homogenous migration model to penalize differences in neighboring edge weights on both the linear and log scale relative to a homogeneous fitted parameter which we call w<sub>0</sub>. This natural parameterization of the penalty and pre-estimation of w<sub>0</sub> under a simple homogenous null model, allowed us to effectively remove the alpha parameter from the original penalty, allowing an one-dimensional cross-validation algorithm for selecting lambda in a computationally efficient and reliable manner. For more details please see the updated “Overview of FEEMS” in the Results section and “Penalty description” in the Materials and methods section.</p><p>With this new penalty in hand we used leave-one-out cross-validation to select the smoothness parameter lambda. In the cross-validation algorithm, for each grid value of lambda, we held-out an individual observed node (population) on the graph and then predicted underlying allele frequencies at these held-out nodes under our fitted spatial model from the rest of the training-set nodes (see the new section “Leave-one-out cross-validation to select tuning parameters” in Materials and methods for details). We found leave-one-out cross-validation over lambda to provide satisfactory results that recovered true migration histories in coalescent simulations and aligned with biological expectations in real datasets.</p><p>We have updated all of the text with descriptions of the new penalty and have reanalyzed and reproduced the figures using leave-one-out cross-validation to select lambda. This greatly simplifies the text and we hope this helps to alleviate the comments posed by the reviewers in regards to hyper-parameter selection. Figure 3 now shows fitted FEEMS visualizations across the grid points of lambda that were used in leave-one-out cross-validation. We added a new panel Figure 3E which shows the cross-validation error for the full grid and highlights the visualized maps for a subset of lambda values. In Figure 4, we now display the solution that achieves the minimum cross-validation error. All coalescent simulation figures have been updated as well. In general, the interpretation and results have not changed using this new penalty and cross-validation procedure but the ease of use and clarity of FEEMS has greatly improved.</p><p>We also thank the reviewers for the suggestion on using the BIC for model selection under the L1 penalty. As mentioned above, for our new penalty – which is still the L2 distance between migration weights on neighboring edges, we have found leave-one-out cross-validation to perform well. Because cross-validation, in principle, can work for both the L1 and L2 penalties we prefer to use a method that works more &quot;universally&quot; for any penalty whether it induces exact sparsity or not. We also prefer the L2 penalty for other statistical and computational reasons and expand upon this point in our response in the next section.</p><p>In terms of concerns about the grid density, we do not have new solutions for this problem which is also a caveat in the original EEMS method (see Petkova et al. 2016 discussion); however we highlight this issue more prominently with a new paragraph in the discussion.</p><disp-quote content-type="editor-comment"><p>2. Please clarify the modeling decision and its comparison to the L1 approach. For instance, isn't smoothing over nodes vs edges really just the same thing with different penalties? The authors form a lifted graph, where edges are now nodes and they penalize differences between neighboring edges. In the L1 penalty case with a squared error loss, the fused lasso / total variation penalty on neighboring edges is equivalent to linear trend filtering on the nodes. The choice then of linear trend filtering could have been replaced with a higher order trend filtering step to achieve the smoothness that the authors seem to say is lacking in the L1 model.</p></disp-quote><p>In a sense, yes, “smoothing over nodes vs edges is the same thing with different penalties”; however the penalties differ in key ways. In the original parameterization of EEMS, each node was given a parameter and the edge weights were deterministically computed as the average of adjacent connected nodes. While this node-level parameterization reduces the number of parameters needed to be estimated, the edge-level parameterization has two advantages in our view:</p><p>1. Each edge is free to take a unique value and that allows for a wider range of anisotropic migration scenarios to be modeled (e.g. spatially homogeneous anisotropy as in Figure 2 right hand column). That was the main driver for the decision for this new smoothing scheme.</p><p>2. By assigning each edge to be the average of connected nodes, a form of implicit spatial regularization is imposed because multiple edges connected to the same node would average that node’s parameter value. We found it more natural to separate out the regularization from the parameterization of the model. This preference led us to adding a smoothness penalty on edge-level parameters.</p><p>We thank the reviewer for the suggestion of using higher order trend filtering. We tested a L1 penalization approach on the edge weights and find it often fails to give satisfactory results (e.g. Supplementary Materials “Smooth penalty with L1 norm’’ and Supplementary Figure 18), primarily because the L1 penalty is too locally adaptive to regions with many unobserved locations. In the regime where there is a high degree of missingness in the graph, the global consideration of smoothing the unobserved locations seems to be necessary and this is the primary driver for using the L2 penalty. We believe that using the higher order trend filtering with the L1 penalty may suffer a similar issue. The smoothness of the L2 penalty also allowed us to employ a quasi-newton algorithm for optimizing our objective function which decreased our runtime more than 10 fold when compared to first order methods such as proximal gradient descent and ADMM when using the L1 formulation of our objective function. In addition we were able to utilize a widely used and tested implementation of L-BFGS in scipy which worked well out of the box and had few algorithmic parameters to tune. Given we observed satisfactory results with the L2 penalty in addition to the fast convergence and runtime of the quasi-newton algorithm we preferred it over the L1 penalization approach.</p><disp-quote content-type="editor-comment"><p>3. Are the data points we observe actually sampled at random? Is some sort of latent confounding likely? For example, maybe wolves migrate based on the season and the scientists collecting the data only look in one spot in one particular time of year?</p></disp-quote><p>For (a), in our model we treat the geographic locations of each sample as fixed but the distribution of genetic data as random. We find the method is relatively robust to non-random sampling, as long as it is not so sparse as to lose the key signals of differentiation in the data (e.g. Supplementary Figure 2).</p><p>Regarding (b), we have expanded the discussion with a paragraph that addresses how a form of confounding between seasonal migration and the sample collection process could be problematic in some datasets. Specifically, we discuss variation in the wolf migratory behavior to illustrate the point, and the suggestion helped us add nuance to our discussion of the results.</p><disp-quote content-type="editor-comment"><p>4. Please clarify the simulation results in Supp Fig19, panels I and J. Without any data points in the orange regions for panel I, the model somehow infers that there is a band of different edge weights. How? In the 1d case, it's as if someone showed you: [5, 5, 5, missing, missing, missing, 5 ,5 5], and you come back and told me [5, 5, 5, -3, -3, -3, 5, 5, 5]. Is this possible?</p></disp-quote><p>It is possible – and there are a few ways to understand where the signal for the inference derives from. (1) Consider that in sampled regions one can “learn” a relationship between geographic and genetic distance, and then with that in hand recognize that the observed covariances across a gap of unobserved locations are too large or too small relative to what is seen in the observed data. Regarding the reviewer’s analogy, let’s define a spatial position of each node as its index in the 1-D array. Let's further suppose we collected a dataset of samples from nodes 1,2,3 and 7,8,9. First, assume we see that the observed allele frequency covariance within pairs of nodes 1,2,3 and 7,8,9 decays some constant amount for every unit of geographic distance. Then, if the covariance between pairs nodes 1,2,3 and 7,8,9 is lower than what would be expected given the geographic distance between them, it would provide a signal that the migration rates should be higher for edges connecting 1,2,3 and 7,8,9 and lower for edges connecting 4,5,6. In contrast, if pairwise covariances between all of the observed nodes decayed over geographic space at a constant level, we would infer homogenous migration rates for edges connecting both the missing and non-missing nodes. Our likelihood uses the migration rate parameters to match expected covariances at all nodes to observed covariances, whereas our penalty encourages the migration rates to be smooth which helps inference in regions with high levels of missing nodes. As a simple one-locus example, consider the allele frequency data observed at the same 1-D array of 9 populations: [0.02,0.01,0.03, missing, missing, missing, 0.99,0.98,0.985]. From such allele frequency data, one can infer migration rates are unlikely to be homogeneous, and moreover, likely are lower in the region with no observed data. (2) In a population genetic model, the key determinant of variation in genetic data observed today is where and when the ancestors of the sampled data “coalesce” (i.e. have common ancestry). The genetic ancestors of the present sample can occupy locations where there is no data today, and when they coalesce with each other will be impacted by local migration rates at unsampled locations. That is to say, migration rates at locations where there are no samples today can still impact the genetic data observed. Surprisingly, this implies that, to some extent, one can learn about migration rates even outside the convex hull of the sampled points.</p><disp-quote content-type="editor-comment"><p>5. At present, there is no real quantitative assessment of how good the FEEMS solutions are relative to the EEMS solution. This should be provided.</p></disp-quote><p>We now include a new supplemental figure 22 with the observed vs fitted dissimilarities output by EEMS when applied to the North American gray wolf dataset. This can be compared to the analogous results for FEEMS already presented in supplemental figure 14. The results show that EEMS fits the data relatively well, though there is a collection of points that seem to be poorly fit as illustrated by a systematically higher fitted dissimilarity to what is observed. FEEMS, in contrast, does not seem to have the same cluster of poor fitting samples.</p><disp-quote content-type="editor-comment"><p>6. It would be useful to provide another example of a heterogeneous migration scenario where the reduction in migration is less than one order of magnitude in order to give an idea to the user of how the method performs in a less heterogeneous scenario (ie the lower bound).</p></disp-quote><p>We now include such an example. To assess the performance of FEEMS in a less heterogeneous migration scenario, we applied FEEMS to coalescent simulations where the migration in the center of the habitat (spatial grid) was only reduced by 25% relative to the edges. In Supplementary Figure 21, we can see that FEEMS is still able to recover this reduction of gene-flow but the output visualization is slightly noisier than the strong heterogeneous migration simulations in Figure 2. Please refer to a new supplementary section titled “Coalescent simulations with weak migration” for a detailed discussion of the results.</p></body></sub-article></article>