<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD with MathML3 v1.3 20210610//EN"  "JATS-archivearticle1-3-mathml3.dtd"><article xmlns:ali="http://www.niso.org/schemas/ali/1.0/" xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" article-type="research-article" dtd-version="1.3"><front><journal-meta><journal-id journal-id-type="nlm-ta">elife</journal-id><journal-id journal-id-type="publisher-id">eLife</journal-id><journal-title-group><journal-title>eLife</journal-title></journal-title-group><issn publication-format="electronic" pub-type="epub">2050-084X</issn><publisher><publisher-name>eLife Sciences Publications, Ltd</publisher-name></publisher></journal-meta><article-meta><article-id pub-id-type="publisher-id">89025</article-id><article-id pub-id-type="doi">10.7554/eLife.89025</article-id><article-id pub-id-type="doi" specific-use="version">10.7554/eLife.89025.4</article-id><article-categories><subj-group subj-group-type="display-channel"><subject>Research Article</subject></subj-group><subj-group subj-group-type="heading"><subject>Neuroscience</subject></subj-group></article-categories><title-group><article-title>Distance and grid-like codes support the navigation of abstract social space in the human brain</article-title></title-group><contrib-group><contrib contrib-type="author" id="author-317646"><name><surname>Liang</surname><given-names>Zilu</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">https://orcid.org/0009-0009-3446-5117</contrib-id><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="fn" rid="con1"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" id="author-322931"><name><surname>Wu</surname><given-names>Simeng</given-names></name><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="fn" rid="con2"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" id="author-308013"><name><surname>Wu</surname><given-names>Jie</given-names></name><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="fn" rid="con3"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" id="author-132258"><name><surname>Wang</surname><given-names>Wen-Xu</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">https://orcid.org/0000-0002-4170-8676</contrib-id><xref ref-type="aff" rid="aff2">2</xref><xref ref-type="fn" rid="con4"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" corresp="yes" id="author-134213"><name><surname>Qin</surname><given-names>Shaozheng</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">https://orcid.org/0000-0002-1859-2150</contrib-id><email>szqin@bnu.edu.cn</email><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="other" rid="fund2"/><xref ref-type="fn" rid="con5"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" corresp="yes" id="author-176674"><name><surname>Liu</surname><given-names>Chao</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">https://orcid.org/0000-0003-1149-2314</contrib-id><email>liuchao@bnu.edu.cn</email><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="other" rid="fund1"/><xref ref-type="other" rid="fund3"/><xref ref-type="other" rid="fund4"/><xref ref-type="other" rid="fund5"/><xref ref-type="other" rid="fund6"/><xref ref-type="fn" rid="con6"/><xref ref-type="fn" rid="conf1"/></contrib><aff id="aff1"><label>1</label><institution-wrap><institution-id institution-id-type="ror">https://ror.org/022k4wk35</institution-id><institution>State Key Laboratory of Cognitive Neuroscience and Learning &amp; IDG/McGovern Institute for Brain Research, Beijing Normal University</institution></institution-wrap><addr-line><named-content content-type="city">Beijing</named-content></addr-line><country>China</country></aff><aff id="aff2"><label>2</label><institution-wrap><institution-id institution-id-type="ror">https://ror.org/022k4wk35</institution-id><institution>School of Systems Science, Beijing Normal University</institution></institution-wrap><addr-line><named-content content-type="city">Beijing</named-content></addr-line><country>China</country></aff></contrib-group><contrib-group content-type="section"><contrib contrib-type="editor"><name><surname>de Lange</surname><given-names>Floris P</given-names></name><role>Reviewing Editor</role><aff><institution>Donders Institute for Brain, Cognition and Behaviour</institution><country>Netherlands</country></aff></contrib><contrib contrib-type="senior_editor"><name><surname>de Lange</surname><given-names>Floris P</given-names></name><role>Senior Editor</role><aff><institution>Donders Institute for Brain, Cognition and Behaviour</institution><country>Netherlands</country></aff></contrib></contrib-group><pub-date publication-format="electronic" date-type="publication"><day>14</day><month>06</month><year>2024</year></pub-date><volume>12</volume><elocation-id>RP89025</elocation-id><history><date date-type="sent-for-review" iso-8601-date="2023-06-24"><day>24</day><month>06</month><year>2023</year></date></history><pub-history><event><event-desc>This manuscript was published as a preprint.</event-desc><date date-type="preprint" iso-8601-date="2023-06-10"><day>10</day><month>06</month><year>2023</year></date><self-uri content-type="preprint" xlink:href="https://doi.org/10.1101/2023.05.12.538784"/></event><event><event-desc>This manuscript was published as a reviewed preprint.</event-desc><date date-type="reviewed-preprint" iso-8601-date="2023-08-31"><day>31</day><month>08</month><year>2023</year></date><self-uri content-type="reviewed-preprint" xlink:href="https://doi.org/10.7554/eLife.89025.1"/></event><event><event-desc>The reviewed preprint was revised.</event-desc><date date-type="reviewed-preprint" iso-8601-date="2024-02-28"><day>28</day><month>02</month><year>2024</year></date><self-uri content-type="reviewed-preprint" xlink:href="https://doi.org/10.7554/eLife.89025.2"/></event><event><event-desc>The reviewed preprint was revised.</event-desc><date date-type="reviewed-preprint" iso-8601-date="2024-05-15"><day>15</day><month>05</month><year>2024</year></date><self-uri content-type="reviewed-preprint" xlink:href="https://doi.org/10.7554/eLife.89025.3"/></event></pub-history><permissions><copyright-statement>© 2023, Liang et al</copyright-statement><copyright-year>2023</copyright-year><copyright-holder>Liang et al</copyright-holder><ali:free_to_read/><license xlink:href="http://creativecommons.org/licenses/by/4.0/"><ali:license_ref>http://creativecommons.org/licenses/by/4.0/</ali:license_ref><license-p>This article is distributed under the terms of the <ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/licenses/by/4.0/">Creative Commons Attribution License</ext-link>, which permits unrestricted use and redistribution provided that the original author and source are credited.</license-p></license></permissions><self-uri content-type="pdf" xlink:href="elife-89025-v1.pdf"/><self-uri content-type="figures-pdf" xlink:href="elife-89025-figures-v1.pdf"/><abstract><p>People form impressions about others during daily social encounters and infer personality traits from others' behaviors. Such trait inference is thought to rely on two universal dimensions: competence and warmth. These two dimensions can be used to construct a ‘social cognitive map’ organizing massive information obtained from social encounters efficiently. Originating from spatial cognition, the neural codes supporting the representation and navigation of spatial cognitive maps have been widely studied. Recent studies suggest similar neural mechanism subserves the map-like architecture in social cognition as well. Here we investigated how spatial codes operate beyond the physical environment and support the representation and navigation of social cognitive map. We designed a social value space defined by two dimensions of competence and warmth. Behaviorally, participants were able to navigate to a learned location from random starting locations in this abstract social space. At the neural level, we identified the representation of distance in the precuneus, fusiform gyrus, and middle occipital gyrus. We also found partial evidence of grid-like representation patterns in the medial prefrontal cortex and entorhinal cortex. Moreover, the intensity of grid-like response scaled with the performance of navigating in social space and social avoidance trait scores. Our findings suggest a neurocognitive mechanism by which social information can be organized into a structured representation, namely cognitive map and its relevance to social well-being.</p></abstract><kwd-group kwd-group-type="author-keywords"><kwd>social cognition</kwd><kwd>cognitive map</kwd><kwd>prefrontal cortex</kwd><kwd>precunes</kwd><kwd>entorhinal cortex</kwd></kwd-group><kwd-group kwd-group-type="research-organism"><title>Research organism</title><kwd>Human</kwd></kwd-group><funding-group><award-group id="fund1"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/501100002855</institution-id><institution>Ministry of Science and Technology of the People's Republic of China</institution></institution-wrap></funding-source><award-id>2021ZD0200500</award-id><principal-award-recipient><name><surname>Liu</surname><given-names>Chao</given-names></name></principal-award-recipient></award-group><award-group id="fund2"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/501100001809</institution-id><institution>National Natural Science Foundation of China</institution></institution-wrap></funding-source><award-id>32130045</award-id><principal-award-recipient><name><surname>Qin</surname><given-names>Shaozheng</given-names></name></principal-award-recipient></award-group><award-group id="fund3"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/501100001809</institution-id><institution>National Natural Science Foundation of China</institution></institution-wrap></funding-source><award-id>32271092</award-id><principal-award-recipient><name><surname>Liu</surname><given-names>Chao</given-names></name></principal-award-recipient></award-group><award-group id="fund4"><funding-source><institution-wrap><institution>the Major Project of National Social Science Foundation</institution></institution-wrap></funding-source><award-id>19ZDA363</award-id><principal-award-recipient><name><surname>Liu</surname><given-names>Chao</given-names></name></principal-award-recipient></award-group><award-group id="fund5"><funding-source><institution-wrap><institution>the Beijing Municipal Science and Technology Commission</institution></institution-wrap></funding-source><award-id>Z151100003915122</award-id><principal-award-recipient><name><surname>Liu</surname><given-names>Chao</given-names></name></principal-award-recipient></award-group><award-group id="fund6"><funding-source><institution-wrap><institution>National Program for Support of Top-notch Young Professionals</institution></institution-wrap></funding-source><principal-award-recipient><name><surname>Liu</surname><given-names>Chao</given-names></name></principal-award-recipient></award-group><funding-statement>The funders had no role in study design, data collection and interpretation, or the decision to submit the work for publication.</funding-statement></funding-group><custom-meta-group><custom-meta specific-use="meta-only"><meta-name>Author impact statement</meta-name><meta-value>New data provides partial evidence that abstract social knowledge adopts a similar encoding scheme as spatial cognitive maps in the human brain.</meta-value></custom-meta><custom-meta specific-use="meta-only"><meta-name>publishing-route</meta-name><meta-value>prc</meta-value></custom-meta></custom-meta-group></article-meta></front><body><sec id="s1" sec-type="intro"><title>Introduction</title><p>Countless daily social encounters pose people with the need to organize information about social encounters efficiently. Though people may ascribe a variety of traits to others, these inferences have been identified to rely on a few universal dimensions (<xref ref-type="bibr" rid="bib14">Fiske et al., 2007</xref>; <xref ref-type="bibr" rid="bib50">Stolier et al., 2020</xref>). The most widely recognized dimensions are warmth, which concerns others’ intentions, and competence, which concerns others’ capability and possession of resources (<xref ref-type="bibr" rid="bib10">Cuddy, 2008</xref>). These universal dimensions can be used to construct a structured representation organizing impressions of other people or other social information alike, just like how one would specify a location in a plane using orthogonal dimensions for spatial navigation. Analogous to Tolman’s original concept (<xref ref-type="bibr" rid="bib52">Tolman, 1948</xref>), here we termed this structured representation of social information about other people as ‘social cognitive map’, which may form the basis for social cognition. Having such a cognitive map for social perception is crucial. It helps us organize various experiences, track updates, and guide novel inferences efficiently (<xref ref-type="bibr" rid="bib48">Son et al., 2021</xref>). Despite its importance in navigating the social world, its neural underpinning remains underinvestigated.</p><p>The resemblance between social and spatial cognitive maps has led to the proposition that social cognitive map is also supported by similar mechanisms that map physical space (<xref ref-type="bibr" rid="bib47">Schafer and Schiller, 2018</xref>). In the domain of spatial navigation, it has been demonstrated that entorhinal grid cell activity supports representational coding of cognitive map. Direct recordings in rodents (<xref ref-type="bibr" rid="bib16">Hafting et al., 2005</xref>) and humans <xref ref-type="bibr" rid="bib20">Jacobs et al., 2013</xref> have found that the firing locations of grid cells form periodic triangular that covers the entire available arena during spatial navigation task. In this sense, grid cells form the basic units of a neural map of the spatial environment. One of the prominent properties of grid cells is their consistent grid orientation (i.e., the orientation of the grid relative to the environment) shared by neighboring grid cells (<xref ref-type="bibr" rid="bib16">Hafting et al., 2005</xref>; <xref ref-type="bibr" rid="bib46">Sargolini et al., 2006</xref>). Moreover, the overlapping population formed by grid cells and head direction cells as well as conjunctive grid × head-direction cells in deeper layers of the entorhinal cortex (EC) enables directional as well as positional tuning of the firing rate (<xref ref-type="bibr" rid="bib46">Sargolini et al., 2006</xref>). It has been proposed that this conjunctive representation at a population level can yield a directionally modulated firing pattern with hexagonal periodicity in which population activity is enhanced when an agent’s moving direction is aligned to the grid axes (<xref ref-type="bibr" rid="bib24">Kriegeskorte and Storrs, 2016</xref>; <xref ref-type="bibr" rid="bib27">Kunz et al., 2019</xref>). Human studies using noninvasive neuroimaging techniques rely on this directional preference of populational conjunctive grid × head-direction cell activity to detect evidence of grid-like code in functional MRI (fMRI) BOLD signals during spatial navigation (<xref ref-type="bibr" rid="bib13">Doeller et al., 2010</xref>). Follow-up studies have reported entorhinal grid code during virtual as well as imagined navigation (<xref ref-type="bibr" rid="bib18">Horner et al., 2016</xref>), and even mental simulation (<xref ref-type="bibr" rid="bib4">Bellmund et al., 2016</xref>). More importantly, pioneering studies showed that the function of grid-like code goes beyond the scope of spatial navigation. Grid-like codes in EC and prefrontal cortex (PFC) have been observed during nonspatial navigation such as perceptual (<xref ref-type="bibr" rid="bib2">Aronov et al., 2017</xref>; <xref ref-type="bibr" rid="bib3">Bao et al., 2019</xref>; <xref ref-type="bibr" rid="bib23">Killian et al., 2012</xref>; <xref ref-type="bibr" rid="bib35">Nau et al., 2018</xref>), conceptual (<xref ref-type="bibr" rid="bib9">Constantinescu et al., 2016</xref>), semantic space (<xref ref-type="bibr" rid="bib54">Viganò and Piazza, 2020</xref>; <xref ref-type="bibr" rid="bib55">Viganò et al., 2021</xref>), and, more recently, discrete social hierarchy (<xref ref-type="bibr" rid="bib41">Park et al., 2021</xref>). Evidence from the above studies converges into a domain-general role of grid-like codes in organizing cognitive maps of various types, including spatial and nonspatial domains (<xref ref-type="bibr" rid="bib5">Bellmund et al., 2018</xref>).</p><p>In this study, we tested the above hypothesis that the social cognitive map is supported by a grid cell-like coding mechanism observed in spatial navigation. First, leveraging the theoretical framework of the stereotype content model, we set up an abstract two-dimensional social value map composed of competence and trustworthiness dimensions of social perception. Next, we adapted paradigms used in human fMRI grid-code study to test the hypothesis that grid-like codes and distance codes resembling those underpinning spatial navigation are involved in navigation in this abstract social space. Finally, to complete the argument that neural codes for social navigation subserve social cognition, we explored the link between neural codes during social navigation and social skills measured by navigational performance and social trait scores.</p></sec><sec id="s2" sec-type="results"><title>Results</title><p>To look for neural underpinnings of navigation in an abstract social space, we adapted a set of tasks from previous studies illustrating the relevance of grid-like code in navigating abstract concept space (<xref ref-type="bibr" rid="bib9">Constantinescu et al., 2016</xref>). Participants received intensive training on navigating in this abstract social space with precision. They completed a learning session, a review session during behavioral training on the first day, and a scanning session on the second day (<xref ref-type="fig" rid="fig1s1">Figure 1—figure supplement 1F</xref>).</p><p>We designed the social value map, an abstract social space structuring one’s social perception of other people’s social values. It was defined by two ecologically important dimensions: competence and trustworthiness. A visualization with two adjacent bars enclosed by a square box was designed to represent the location on this social value map, with the height of each bar representing the value of each dimension. We operationally defined these two dimensions under the framework of an investment game, in which the trustee’s social value is determined by the ability to earn a profit (i.e., profit rate as competence) and the proportion of earnings returned to the investor (i.e., return rate as trustworthiness). The range of competence and trustworthiness was limited to between 0 and 1 to make sure that they are realistic (i.e., it is unlikely that trustees will return you more than they have gained), and more importantly, orthogonal and share the same metric system. Participants played the role of an investor in this investment task (<xref ref-type="fig" rid="fig1s1">Figure 1—figure supplement 1A</xref>) at the very beginning of the experiment to develop a concrete understanding of the visual analog and the quantitative meaning of these two dimensions.</p><p>Six avatars with different levels of competence and trustworthiness (<xref ref-type="fig" rid="fig1">Figure 1A</xref>), analogous to landmarks in the physical environment, were placed on the social value map of size 1 unit × 1 unit in accordance with the range of competence and trustworthiness. The current spatial arrangement aimed to make avatars distinguishable on both dimensions while spreading widely across the whole space. Specifically, each participant’s set of avatars' coordinates was sampled within circles of 1/30-unit radius around center coordinates (<xref ref-type="fig" rid="fig1">Figure 1B</xref>). In the experiment, avatars were represented by passport-style photos of the faces of volunteers taken against a plain blue background. Photographs were matched on competence and trustworthiness ratings based on data from an independent online sample. Additionally, scanned participants completed ratings on the selected faces before and after the experiment to reassure that there was no pre-existing bias in social perception of the avatars and to test whether they updated social perception according to learned characteristics of the avatars.</p><fig-group><fig id="fig1" position="float"><label>Figure 1.</label><caption><title>Experimental design and behavioral performance.</title><p>(<bold>A</bold>) Visual analogs illustrating each avatar’s social values. The height of the left bars signals values on the competence dimension, while the height of the right bars signals trustworthiness. Labels for each of the two bars are omitted for illustration purposes. (<bold>B</bold>) Corresponding layout of the social value map and example trajectory in the recall task. Scattered dots indicate the actual sets of positions generated for participants. (<bold>C</bold>) Positions of the avatars indicated by participants at the end of the whole experiment. (<bold>D</bold>) Trial timeline of the recall task. Participants first watched the bars morphing for 1 s according to a predefined competence-trustworthiness ratio (i.e., the first half of a trajectory in <bold>B</bold>). After the bars stopped morphing, they were instructed to imagine the bars continue to morph according to the same ratio, at the same speed, and for the same amount of time (i.e., the second half of a trajectory in <bold>B</bold>). (<bold>E</bold>) Color-coded trajectory map of the explore task during the learning and review session. Color indicates the percentage of time spent in each pixel of the social value map during the explore task in the learning (left panel) and review (right panel) session. A pattern emerged that participants spent more time at avatars and less time at the edge during review. (<bold>F</bold>) Memory test performance of the collect and recall task in learning, review, and scan-day sessions. Collect (&lt;15°): percentage of trials where the deviation of first transition from ideal trajectory was smaller than 15°; Collect (&lt;0.01): percentage of trials where the distance between response location and correct location was smaller than 0.01 units; Recall (correct): percentage of trials where the response was correct. (<bold>G</bold>) The distance effect in comparison task across the review and scan-day session. Colored dots indicate the estimates of distance effect regressor while error bars indicate standard error of the estimates. (<bold>H</bold>) Ratings became predictable from the avatars’ social value after the experiment. Icons of avatars are for illustration and retrieved from <ext-link ext-link-type="uri" xlink:href="https://pixabay.com/vectors/avatar-flat-modern-minimal-5261900/">https://pixabay.com/vectors/avatar-flat-modern-minimal-5261900/</ext-link>, <ext-link ext-link-type="uri" xlink:href="https://pixabay.com/vectors/avatar-flat-modern-minimal-5261896/">https://pixabay.com/vectors/avatar-flat-modern-minimal-5261896/</ext-link>.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-89025-fig1-v1.tif"/></fig><fig id="fig1s1" position="float" specific-use="child-fig"><label>Figure 1—figure supplement 1.</label><caption><title>Behavioral training tasks.</title><p>(<bold>A</bold>) Schematic illustration of the investment game and its relation to the competence and trustworthiness dimensions. (<bold>B–D</bold>) Example screenshot of match, explore, and collect task. (<bold>E</bold>) Timeline of compare task. (<bold>F</bold>) Timeline of the experiment and tasks completed by participants in each session.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-89025-fig1-figsupp1-v1.tif"/></fig><fig id="fig1s2" position="float" specific-use="child-fig"><label>Figure 1—figure supplement 2.</label><caption><title>Distribution of trajectory direction (theta) in the recall task in the scanner.</title><p>Trajectory directions from all four runs were divided into 20 bins to plot histogram. The angle of polar plot indicates the trajectory direction, and the distance from the center indicates the number of trials in the bin.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-89025-fig1-figsupp2-v1.tif"/></fig><fig id="fig1s3" position="float" specific-use="child-fig"><label>Figure 1—figure supplement 3.</label><caption><title>Distribution of trajectory length (travelled distance) in the recall task in the scanner.</title><p>Trajectory lengths from all four runs were divided into 20 bins to plot histogram.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-89025-fig1-figsupp3-v1.tif"/></fig><media id="fig1video1" mimetype="video" mime-subtype="gif" xlink:href="elife-89025-fig1-video1.gif"><label>Figure 1—animation 1.</label><caption><title>Recall task morph stage<italic>.</italic></title></caption></media></fig-group><p>In the training, participants explored the social space by morphing the bars with different competence:trustworthiness ratio using the nonspatial controller to look for the six avatars (<xref ref-type="fig" rid="fig1s1">Figure 1—figure supplement 1C</xref>). Morphing the bars resembles making a transition in the social space in that it was done in two steps: (1) deciding a trajectory to follow by changing the competence:trustworthiness ratio using the nonspatial controller, and (2) how further along to follow that trajectory. No prior information about the characteristics of the avatars was provided to the participants. Thus, participants could only explore social space as if they were looking for landmarks in a newly introduced physical environment. An avatar would pop out when the visualization matched his/her characteristics. Specifically, the avatar would pop out when participants’ current location fell within a 0.01-unit radius of the correct location on the social value map. In this way, participants not only learned the characteristics of each avatar but also became familiar with the whole space even though this map-like structure was never revealed to them.</p><p>After participants were fully acquainted with the avatars and the social space, a set of memory tasks were used to test whether participants learned the avatars, and, more importantly, if they formed an internal representation of the social value map, even though the map-like structure was never directly revealed to them. Participants never received feedback on these memory test tasks, so they had to rely on knowledge learned in the explore task. The first one was the collect task (<xref ref-type="fig" rid="fig1s1">Figure 1—figure supplement 1D</xref>), which required participants to navigate to the location of the avatars from random starting locations in the abstract space. In each trial, they were instructed to morph the box on the left to match the characteristic of the avatar shown on the right. Specifically, we asked participants to make as few transitions as possible. Two performance indices were calculated: (1) the deviation of participants’ first transition from the ideal trajectory, and (2) the Euclidean distance between the location corresponding to participants’ morphed bars and the avatar’s actual location in the abstract space. The second one was the recall task, which required participants to mentally traverse the abstract social space according to a half-seen trajectory and identify the destination that follows (<xref ref-type="fig" rid="fig1">Figure 1D</xref>, <xref ref-type="video" rid="fig1video1">Figure 1—animation 1</xref>). In each trial, participants were first shown the two bars morphing according to a predefined competence:trustworthiness ratio for 1 s. The bars then stopped morphing, and participants were instructed to imagine the bars keep morphing according to the same ratio, at the same speed, and for the same amount of time. After this, participants had to choose which of the three given options matched the bars after imagination. Essentially, each trial is a trajectory vector defined by moving direction (i.e., morphing ratio) and traveled distance on the social value map. We specifically sample the trajectories from a uniform distribution (<xref ref-type="fig" rid="fig1s2">Figure 1—figure supplement 2</xref>). We investigated the neural representation of the trajectories while participants performed this task. The third one was the compare task (<xref ref-type="fig" rid="fig1s1">Figure 1—figure supplement 1E</xref>), which required participants to compare different pairs of avatars on one given dimension (competence and trustworthiness) or by a fair combination of both dimensions (willingness to cooperate). Assuming distance is a measure of similarity between two avatars, the closer two avatars are, the more similar they are, hence distinguishing them will be harder, which results in less accurate response and longer reaction time (similar to the inferential distance effect in ordered relationships; <xref ref-type="bibr" rid="bib44">Potts, 1974</xref>). If participants had map-like representations, then their response in this task would show such a correlation pattern with distance in the 2D social space. The final one was a map task at the end of the experiment in which participants were informed about the map-like structure and were asked to indicate the location of each avatar on an empty social value map using a mouse click.</p><sec id="s2-1"><title>Participants construct a social value map after associative learning of avatars and corresponding characteristics</title><p>Participants were successful in reconstructing the designed layout of avatars in a map task at the end of the experiment (<xref ref-type="fig" rid="fig1">Figure 1C</xref>). Linear mixed effect models revealed that participants’ performance in tasks significantly improved over sessions. In the explore task, it took them significantly less time to find all avatars in the review session compared to the learning session (β<sub>session</sub> = –67.589, <italic>t</italic> = –37.604, p&lt;0.001). They also spent much less time at the edge (<italic>β</italic> = –0.104, <italic>t</italic> = –9.070, p&lt;0.001) and more time at avatars (β<sub>session</sub> = 0.023, <italic>t</italic> = 7.367, p&lt;0.001) during exploration in the review session compared to the learning session (<xref ref-type="fig" rid="fig1">Figure 1E</xref>). Likewise, there was evident improvement in collect and recall task as training progressed (<xref ref-type="fig" rid="fig1">Figure 1F</xref>, percentage of first transition deviation &lt; 15° in collect task: β<sub>session</sub> = 0.050411, <italic>t</italic> = 3.2187, p=0.002; percentage of distance &lt; 0.01 in collect task: β<sub>session</sub> = 0.047, <italic>t</italic> = 3.002, p=0.003; accuracy in the recall task: β<sub>session</sub> = 0.020, <italic>t</italic> = 4.213, p&lt;0.001). Furthermore, participants were able to form an implicit map-like structure and integrate both dimensions when making decisions between avatars. In the compare task, linear mixed effect models revealed a significant effect of distance between avatars in the compared dimension on response time and accuracy as predicted (<xref ref-type="fig" rid="fig2">Figure 2G</xref>, all p&lt;0.001). Lastly, learning-induced changes in participants’ ratings of avatars on all rating items (competence, trustworthiness, and attractiveness) (<xref ref-type="fig" rid="fig2">Figure 2H</xref>, <xref ref-type="table" rid="table1">Table 1A</xref>). There was no preference over the six presented faces when participants were naïve to the social value of different avatars (<xref ref-type="table" rid="table1">Table 1B</xref>, all p&gt;0.890), but their ratings became significantly dissociable according to the learned social value at the end of the experiment (<xref ref-type="table" rid="table1">Table 1B</xref>, all p&lt;0.001). These results indicated the successful formation of a 2D social map by associating each avatar with its respective social value.</p><fig id="fig2" position="float"><label>Figure 2.</label><caption><title>Neural representation of Euclidean distance on the social value map.</title><p>(<bold>A</bold>) Activity in the bilateral precuneus positively correlated with traveled Euclidean distance. (<bold>B</bold>) Activity in bilateral fusiform and the right middle occipital gyrus negatively correlated with traveled Euclidean distance. Display threshold: cluster-defining threshold p&lt;0.001.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-89025-fig2-v1.tif"/></fig><table-wrap id="table1" position="float"><label>Table 1.</label><caption><title>Related to <xref ref-type="fig" rid="fig1">Figure 1H</xref>.</title></caption><table frame="hsides" rules="groups"><thead><tr><th align="left" valign="bottom" colspan="6">A. Linear mixed effect model for different rating items</th></tr><tr><th align="left" valign="bottom"/><th align="left" valign="bottom">Competence</th><th align="left" valign="bottom">Trustworthiness</th><th align="left" valign="bottom" colspan="3">Attractiveness</th></tr></thead><tbody><tr><td align="left" valign="bottom">(Intercept)</td><td align="left" valign="bottom">5.157 <sup>***</sup> [4.775, 5.539]</td><td align="left" valign="bottom">5.614 <sup>***</sup> [5.276, 5.951]</td><td align="left" valign="bottom" colspan="3">4.590 <sup>***</sup> [4.168, 5.011]</td></tr><tr><td align="left" valign="bottom">Post vs pre</td><td align="left" valign="bottom">–2.173 <sup>***</sup> [–2.707, –1.639]</td><td align="left" valign="bottom">–1.998 <sup>***</sup> [-2.469,–1.527]</td><td align="left" valign="bottom" colspan="3">–0.828 ** [–1.364, –0.292]</td></tr><tr><td align="left" valign="bottom">Avatar</td><td align="left" valign="bottom">–0.395 [–1.024, 0.234]</td><td align="left" valign="bottom">–0.637 * [–1.240, –0.034]</td><td align="left" valign="bottom" colspan="3">–0.281 [–0.710, 0.149]</td></tr><tr><td align="left" valign="bottom">avatar * (post vs pre)</td><td align="left" valign="bottom">4.812 <sup>***</sup> [3.923, 5.702]</td><td align="left" valign="bottom">5.185 <sup>***</sup> [4.333, 6.038]</td><td align="left" valign="bottom" colspan="3">1.964 <sup>***</sup> [1.357, 2.572]</td></tr><tr><td align="left" valign="bottom">N (observation)</td><td align="left" valign="bottom">456</td><td align="left" valign="bottom">456</td><td align="left" valign="bottom" colspan="3">456</td></tr><tr><td align="left" valign="bottom">N (id)</td><td align="left" valign="bottom">38</td><td align="left" valign="bottom">38</td><td align="left" valign="bottom" colspan="3">38</td></tr><tr><td align="left" valign="bottom">AIC</td><td align="left" valign="bottom">1600.834</td><td align="left" valign="bottom">1589.456</td><td align="left" valign="bottom" colspan="3">1808.221</td></tr><tr><td align="left" valign="bottom">BIC</td><td align="left" valign="bottom">1625.569</td><td align="left" valign="bottom">1614.191</td><td align="left" valign="bottom" colspan="3">1832.956</td></tr><tr><td align="left" valign="bottom">R2 (fixed)</td><td align="left" valign="bottom">0.302</td><td align="left" valign="bottom">0.337</td><td align="left" valign="bottom" colspan="3">0.129</td></tr><tr><td align="left" valign="bottom">R2 (total)</td><td align="left" valign="bottom">0.313</td><td align="left" valign="bottom">0.347</td><td align="left" valign="bottom" colspan="3">0.223</td></tr><tr><th align="left" valign="bottom" colspan="6">B. Follow-up analysis of interaction term in mixed effect models: simple slope of avatars in different sessions</th></tr><tr><th align="left" valign="bottom">Rating item</th><th align="left" valign="bottom">Moderator levels session</th><th align="left" valign="bottom">Estimate [lower CI, upper CI]</th><th align="left" valign="bottom">SE</th><th align="left" valign="bottom"><italic>t</italic> (415)</th><th align="left" valign="bottom">p</th></tr><tr><td align="left" valign="bottom" rowspan="2">Competence</td><td align="left" valign="bottom">Pre-experiment</td><td align="left" valign="bottom">–0.395 [-1.026, 0.236]</td><td align="left" valign="bottom">0.321</td><td align="left" valign="bottom">–1.231</td><td align="left" valign="bottom">0.89</td></tr><tr><td align="left" valign="bottom">Post-experiment</td><td align="left" valign="bottom">4.417 [3.786, 5.048]</td><td align="left" valign="bottom">0.321</td><td align="left" valign="bottom">13.766</td><td align="left" valign="bottom">&lt;0.001</td></tr><tr><td align="left" valign="bottom" rowspan="2">Trustworthiness</td><td align="left" valign="bottom">Pre-experiment</td><td align="left" valign="bottom">–0.637 [-1.241, 0.032]</td><td align="left" valign="bottom">0.308</td><td align="left" valign="bottom">–2.069</td><td align="left" valign="bottom">0.98</td></tr><tr><td align="left" valign="bottom">Post-experiment</td><td align="left" valign="bottom">4.549 [3.944, 5.154]</td><td align="left" valign="bottom">0.308</td><td align="left" valign="bottom">14.787</td><td align="left" valign="bottom">&lt;0.001</td></tr><tr><td align="left" valign="bottom" rowspan="2">Attractiveness</td><td align="left" valign="bottom">Pre-experiment</td><td align="left" valign="bottom">–0.281 [-0.711, 0.150]</td><td align="left" valign="bottom">0.219</td><td align="left" valign="bottom">–1.281</td><td align="left" valign="bottom">0.9</td></tr><tr><td align="left" valign="bottom">Post-experiment</td><td align="left" valign="bottom">1.684 [1.253, 2.114]</td><td align="left" valign="bottom">0.219</td><td align="left" valign="bottom">7.684</td><td align="left" valign="bottom">&lt;0.001</td></tr></tbody></table><table-wrap-foot><fn><p>Statistic results for right-sided <italic>t</italic>-test against zero (noninferiority).</p></fn><fn><p>AIC=Akaike Information Criterion；MNI=Montreal Neurological Institute；ACC=Anterior Cingulate Cortex；FWE=Family Wise Error；DMN=Default Mode Network，SAD=Social Anxiety Disorder；BIC=Bayesian Information Criterion.</p></fn><fn><p>*p&lt;0.05; **p&lt;0.01; ***p&lt;0.001.</p></fn></table-wrap-foot></table-wrap></sec><sec id="s2-2"><title>Precuneus and fusiform jointly encode Euclidean distance during social navigation</title><p>Next, we investigated the neural representations supporting the social cognitive map. To examine the neural code for distance information, we conducted whole-brain analysis with a GLM with two regressors modeling the morph stage and choice stage. Traveled Euclidean distance (i.e., the length of each trial’s trajectory vector) was entered as a parametric modulator of the morph stage regressor. Even though we did not specifically control for the distribution of traveled distance, there was quite a lot trial-wise variability that allowed us to conduct this test (<xref ref-type="fig" rid="fig1s3">Figure 1—figure supplement 3</xref>).</p><p>This analysis revealed two marginally significant clusters in the precuneus whose activity positively correlated with traveled distance on the social value map (<xref ref-type="fig" rid="fig2">Figure 2A</xref>, <xref ref-type="table" rid="table2">Table 2A</xref>, right precuneus: peak coordinate [<italic>x, y, z</italic>] = [12, –56, 26], <italic>t</italic>(37) = 4.952, p=0.056 FWE-corrected; left precuneus: peak coordinate [<italic>x, y, z</italic>] = [-12, –54, 18], <italic>t</italic>(37) = 4.530, p=0.058 FWE-corrected; cluster-defining threshold p&lt;0.001 FWE-corrected). Interestingly, we also observed negative correlation between traveled distance and activity of clusters in several regions, including bilateral fusiform gyrus (<xref ref-type="fig" rid="fig2">Figure 2B</xref>, <xref ref-type="table" rid="table2">Table 2B</xref>, right fusiform: peak coordinate [<italic>x, y, z</italic>] = [36, –48, –20], <italic>t</italic>(37) = 5.912, p&lt;0.001 FWE-corrected; left fusiform: peak coordinate [<italic>x, y, z</italic>] = [–38, –56, –10], <italic>t</italic>(37) = 4.724, p=0.008 FWE-corrected) and the right middle occipital gyrus (<xref ref-type="fig" rid="fig2">Figure 2B</xref>, <xref ref-type="table" rid="table2">Table 2B</xref>, peak coordinate [<italic>x, y, z</italic>] = [34, –68, 20], <italic>t</italic>(37) = 4.649, p=0.018 FWE-corrected; cluster-defining threshold p&lt;0.001).</p><table-wrap id="table2" position="float"><label>Table 2.</label><caption><title>Related to <xref ref-type="fig" rid="fig2">Figure 2</xref>.</title><p>Neural codes represent traveled distance on the social value map.</p></caption><table frame="hsides" rules="groups"><thead><tr><th align="left" valign="bottom" rowspan="2">Anatomical description</th><th align="left" valign="bottom" rowspan="2">Hemisphere</th><th align="center" valign="bottom" colspan="3">Peak MNI coordinates</th><th align="left" valign="bottom" rowspan="2">Peak <italic>t</italic>-value</th><th align="center" valign="bottom" colspan="2">Cluster</th></tr><tr><th align="left" valign="bottom"><italic>x</italic></th><th align="left" valign="bottom"><italic>y</italic></th><th align="left" valign="bottom"><italic>z</italic></th><th align="left" valign="bottom">Size</th><th align="left" valign="bottom">p<sub>FWE</sub></th></tr></thead><tbody><tr><td align="left" valign="bottom" colspan="8"><bold>A. Regions positively correlated with traveled distance</bold></td></tr><tr><td align="left" valign="bottom">Precuneus</td><td align="left" valign="bottom">R</td><td align="left" valign="bottom">12</td><td align="left" valign="bottom">–56</td><td align="left" valign="bottom">26</td><td align="left" valign="bottom">4.53</td><td align="left" valign="bottom">151</td><td align="left" valign="bottom">0.054</td></tr><tr><td align="left" valign="bottom">Precuneus</td><td align="left" valign="bottom">L</td><td align="left" valign="bottom">–12</td><td align="left" valign="bottom">–54</td><td align="left" valign="bottom">18</td><td align="left" valign="bottom">4.952</td><td align="left" valign="bottom">134</td><td align="left" valign="bottom">0.082</td></tr><tr><td align="left" valign="bottom" colspan="8"><bold>B. Regions negatively correlated with traveled distance</bold></td></tr><tr><td align="left" valign="bottom">Fusiform</td><td align="left" valign="bottom">R</td><td align="left" valign="bottom">36</td><td align="left" valign="bottom">–48</td><td align="left" valign="bottom">20</td><td align="left" valign="bottom">4.53</td><td align="left" valign="bottom">766</td><td align="left" valign="bottom">&lt;0.001</td></tr><tr><td align="left" valign="bottom">Fusiform</td><td align="left" valign="bottom">L</td><td align="left" valign="bottom">–38</td><td align="left" valign="bottom">–56</td><td align="left" valign="bottom">–10</td><td align="left" valign="bottom">4.952</td><td align="left" valign="bottom">234</td><td align="left" valign="bottom">0.008</td></tr><tr><td align="left" valign="bottom">Middle occipital gyrus</td><td align="left" valign="bottom">R</td><td align="left" valign="bottom">42</td><td align="left" valign="bottom">–80</td><td align="left" valign="bottom">8</td><td align="left" valign="bottom">4.952</td><td align="left" valign="bottom">196</td><td align="left" valign="bottom">0.018</td></tr></tbody></table><table-wrap-foot><fn><p>L, left; R, right.</p></fn></table-wrap-foot></table-wrap></sec><sec id="s2-3"><title>Grid-like activity aligned to prefrontal and entorhinal grid orientation</title><p>To look for grid-like activity, we implemented the orientation-estimation approach (<xref ref-type="bibr" rid="bib5">Bellmund et al., 2018</xref>; <xref ref-type="bibr" rid="bib13">Doeller et al., 2010</xref>) based on univariate analysis. First, a whole-brain quadrature filter analysis was conducted, which served as a functional localizer to identify the regions sensitive to hexagonal modulation, independent of grid orientation (‘Materials and methods’). This GLM had two regressors modeling the morph stage and choice stage. For the morph stage regressor, we included two parametric modulators corresponding to the sixfold sinusoidal sixfold modulation of trajectory direction (i.e., sin6θ and cos6θ, θ is the direction). Next, we defined spherical region of interest (ROI) with a 5 mm radius centered at the peak coordinate of each significant cluster (<xref ref-type="table" rid="table3">Table 3</xref>) to estimate the grid orientation of each ROI. As no region in the EC survived this analysis, we additionally defined four entorhinal ROIs based on subdivisions of EC (left/right and posterior–medial/anterior–lateral, i.e., pmEC/alEC) from an anatomical mask (<xref ref-type="bibr" rid="bib28">Maass et al., 2015</xref>). Finally, we conducted the leave-one-out cross-validation analysis to test for hexagonal modulation aligned to grid orientation of the ROIs for each participant, that is, the grid orientation consistency effect (‘Materials and methods’). In this cross-validation approach, we estimated grid orientation using data from three runs and tested the grid orientation consistency effect in the held-out run. Grid consistency effect was tested using a GLM that classified trials into 12 bins according to its trajectory direction offset from the estimated grid orientation and built a contrast to test whether activity is stronger in aligned trials than in misaligned trials (<xref ref-type="fig" rid="fig3">Figure 3A</xref>).</p><fig-group><fig id="fig3" position="float"><label>Figure 3.</label><caption><title>Evidence of grid-like activity aligned to putative grid orientation in the right frontal pole and the right posterior–medial entorhinal cortex.</title><p>(<bold>A</bold>) Theoretical prediction of grid-like activity. (<bold>B, C</bold>) Regions of interest (ROIs) for deriving putative grid orientations: (<bold>B</bold>) right FP ROI from quadrature filter analysis showing sensitivity to hexagonal modulation. A 5 mm sphere was defined around the peak coordinate to compute grid angle. Display threshold: voxel-level p&lt;0.001, cluster-level p&lt;0.05 FWE-corrected. (<bold>C</bold>) Anatomically defined right pmEC ROI used to compute grid angle. (<bold>D–G</bold>) Grid-like activity aligned to putative grid orientations in the right FP ROI (<bold>D, E</bold>) and right pmEC (<bold>F, G</bold>) ROI, respectively. Left panels: clusters from whole-brain hexagonal consistency analysis. Color indicates <italic>T</italic> statistics as shown in the colorbar in (<bold>B</bold>). Display threshold: voxel-level p&lt;0.005, cluster-level p&lt;0.05 FWE-corrected. Middle panels: hexagonal consistency effects plotted as contrast estimates of the 12 trial-bin regressors extracted from corresponding cluster in the left panel; To illustrate the effect in EC in (<bold>E</bold>), estimates were extracted from the intersection of the suprathreshold cluster and anatomical mask of the EC. Right panels: such effects were specific to sixfold. n.s., p&gt;0.05, *p&lt;0.05, **p&lt;0.01, ***p&lt;0.001. FP, frontal pole; pmEC, EC, entorhinal cortex; posterior–medial entorhinal cortex; vmPFC, ventral medial prefrontal cortex; STP, superior temporal pole.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-89025-fig3-v1.tif"/></fig><fig id="fig3s1" position="float" specific-use="child-fig"><label>Figure 3—figure supplement 1.</label><caption><title>Analysis pipeline of multivariate pattern analysis in entorhinal region of interest (ROI).</title><p>(<bold>A</bold>) Signals from four subregions of entorhinal cortex were extracted. (<bold>B</bold>) Model-based analysis hexagonal consistency effect in the entorhinal subregions. (<bold>C</bold>) Model-free analysis (angle independent) representational similarity analysis (RSA) results in the whole entorhinal cortex and different entorhinal subregions.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-89025-fig3-figsupp1-v1.tif"/></fig><fig id="fig3s2" position="float" specific-use="child-fig"><label>Figure 3—figure supplement 2.</label><caption><title>Region of interest (ROI) analysis of univariate and multivariate grid-like code in the entorhinal cortex.</title><p>(<bold>A</bold>) Z-transformed <italic>F</italic> statistics of hexagonal modulation effect in the entorhinal subregions in comparison with the frontal pole ROI. (<bold>B</bold>) Hexagonal consistency effect in the entorhinal subregions. (<bold>C</bold>) Model-based (orientation-independent) representational similarity analysis (RSA) results in the whole entorhinal cortex and different entorhinal subregions. (<bold>D</bold>) Model-free (orientation-dependent) RSA results in the entorhinal subregions. Pattern similarity difference between aligned and misaligned trials based on putative grid orientations from different entorhinal subregions. FP, frontal pole; pmEC, posterior–medial entorhinal cortex; alEC, anterior–lateral entorhinal cortex.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-89025-fig3-figsupp2-v1.tif"/></fig><fig id="fig3s3" position="float" specific-use="child-fig"><label>Figure 3—figure supplement 3.</label><caption><title>Distribution of voxel-wise grid orientation of example participants (voxel-wise distribution plot of all participants can be viewed at <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.57760/sciencedb.08637">https://doi.org/10.57760/sciencedb.08637</ext-link>).</title><p>(A) in the right Frontal Pole ROI; (B) in the right posterior-medial EC ROI. Blue number indicates voxel count in the bin with most voxels.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-89025-fig3-figsupp3-v1.tif"/></fig><fig id="fig3s4" position="float" specific-use="child-fig"><label>Figure 3—figure supplement 4.</label><caption><title>Distribution of grid orientation across participants.</title><p>Each point is the estimated grid orientation in a given estimating set in a given region of interest (ROI) for one participant.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-89025-fig3-figsupp4-v1.tif"/></fig><fig id="fig3s5" position="float" specific-use="child-fig"><label>Figure 3—figure supplement 5.</label><caption><title>Relationship between temporal signal-to-noise ratio (tSNR) and the strength of evidence of hexagonal modulation effect in frontal pole and entorhinal regions of interest (ROIs).</title><p>(<bold>A</bold>) Across participants, mean tSNR in the right frontal pole ROI is higher than all four subregions of entorhinal cortex. (<bold>B</bold>) Across participants, in each of the five ROIs, its mean tSNR is not correlated with the <italic>Z</italic>-statistics of hexagonal modulation effect. (<bold>C</bold>) Within participants, in each of the five ROIs, voxel-wise tSNR is not correlated with the <italic>Z</italic>-statistics of hexagonal modulation effect.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-89025-fig3-figsupp5-v1.tif"/></fig></fig-group><table-wrap id="table3" position="float"><label>Table 3.</label><caption><title>Regions showing hexagonal modulation (GLM1).</title></caption><table frame="hsides" rules="groups"><thead><tr><th align="left" valign="bottom" rowspan="2">Anatomical description</th><th align="left" valign="bottom" rowspan="2">Hemisphere</th><th align="left" valign="bottom" colspan="3">Peak coordinates (MNI)</th><th align="left" valign="bottom" rowspan="2">Peak<italic>t</italic>-value</th><th align="left" valign="bottom" colspan="2">Cluster</th></tr><tr><th align="left" valign="bottom"><italic>x</italic></th><th align="left" valign="bottom"><italic>y</italic></th><th align="left" valign="bottom"><italic>z</italic></th><th align="left" valign="bottom">Size</th><th align="left" valign="bottom">p<sub>FWE</sub></th></tr></thead><tbody><tr><td align="left" valign="bottom">Superior parietal gyrus</td><td align="left" valign="bottom">R</td><td align="left" valign="bottom">28</td><td align="left" valign="bottom">–66</td><td align="left" valign="bottom">56</td><td align="left" valign="bottom">5.021</td><td align="left" valign="bottom">522</td><td align="left" valign="bottom">&lt;0.001</td></tr><tr><td align="left" valign="bottom">Precuneus</td><td align="left" valign="bottom">L</td><td align="left" valign="bottom">-6</td><td align="left" valign="bottom">–46</td><td align="left" valign="bottom">38</td><td align="left" valign="bottom">5.707</td><td align="left" valign="bottom">426</td><td align="left" valign="bottom">&lt;0.001</td></tr><tr><td align="left" valign="bottom">Middle frontal gyrus</td><td align="left" valign="bottom">R</td><td align="left" valign="bottom">42</td><td align="left" valign="bottom">24</td><td align="left" valign="bottom">34</td><td align="left" valign="bottom">5.221</td><td align="left" valign="bottom">271</td><td align="left" valign="bottom">&lt;0.001</td></tr><tr><td align="left" valign="bottom">Paracentral Lobule</td><td align="left" valign="bottom">R</td><td align="left" valign="bottom">10</td><td align="left" valign="bottom">–36</td><td align="left" valign="bottom">68</td><td align="left" valign="bottom">4.835</td><td align="left" valign="bottom">120</td><td align="left" valign="bottom">&lt;0.001</td></tr><tr><td align="left" valign="bottom">Middle frontal gyrus</td><td align="left" valign="bottom">R</td><td align="left" valign="bottom">38</td><td align="left" valign="bottom">42</td><td align="left" valign="bottom">30</td><td align="left" valign="bottom">4.849</td><td align="left" valign="bottom">103</td><td align="left" valign="bottom">0.001</td></tr><tr><td align="left" valign="bottom">Frontal pole</td><td align="left" valign="bottom">L</td><td align="left" valign="bottom">–26</td><td align="left" valign="bottom">50</td><td align="left" valign="bottom">0</td><td align="left" valign="bottom">4.269</td><td align="left" valign="bottom">71</td><td align="left" valign="bottom">0.014</td></tr><tr><td align="left" valign="bottom">Frontal pole</td><td align="left" valign="bottom">R</td><td align="left" valign="bottom">26</td><td align="left" valign="bottom">52</td><td align="left" valign="bottom">-2</td><td align="left" valign="bottom">4.494</td><td align="left" valign="bottom">69</td><td align="left" valign="bottom">0.017</td></tr><tr><td align="left" valign="bottom">Angular</td><td align="left" valign="bottom">L</td><td align="left" valign="bottom">–52</td><td align="left" valign="bottom">–60</td><td align="left" valign="bottom">26</td><td align="left" valign="bottom">4.718</td><td align="left" valign="bottom">58</td><td align="left" valign="bottom">0.041</td></tr></tbody></table><table-wrap-foot><fn><p>L, left; R, right.</p></fn></table-wrap-foot></table-wrap><p>Of all the grid orientations derived from the above ROIs, we only found grid consistency effect aligned to the grid orientation of the ROI in the right frontal pole (right FP) cluster (<xref ref-type="fig" rid="fig3">Figure 3B</xref>, peak coordinate [<italic>x, y, z</italic>] = [26, 52, –2], <italic>t</italic>(37) = 4.494, cluster-level p=0.017 FWE-corrected, cluster-defining threshold p&lt;0.001) and the grid orientation of the anatomically defined right posterior–medial EC (right pmEC, <xref ref-type="fig" rid="fig3">Figure 3C</xref>). For the right FP grid orientation, whole-brain analysis revealed consistency effect in bilateral ventral medial PFC (vmPFC, <xref ref-type="fig" rid="fig3">Figure 3D</xref>, left and middle panels, peak coordinate [<italic>x, y, z</italic>] = [–14, 56, –12], <italic>t</italic>(37) = 4.245, cluster-level p=0.033 FWE-corrected, cluster-defining threshold p&lt;0.005) and the left EC (left EC) extending to the parahippocampus (<xref ref-type="fig" rid="fig3">Figure 3E</xref>, left and middle panels, peak coordinate [<italic>x, y, z</italic>] = [–16, –22, –26], <italic>t</italic>(37) = 4.563, cluster-level p=0.024 FWE-corrected, cluster-defining threshold p&lt;0.005). For the right pmEC grid orientation, significant consistency effect was found in two clusters in bilateral vmPFC (<xref ref-type="fig" rid="fig3">Figure 3F</xref>, left and middle panels, right rectus: peak coordinate [<italic>x, y, z</italic>] = [10, 34, –18], <italic>t</italic>(37) = 4.908, cluster-level p=0.033 FWE-corrected; left ACC: peak coordinate [<italic>x, y, z</italic>] = [–8, 32, 6], <italic>t</italic>(37) = 4.810, cluster-level p=0.009 FWE-corrected; cluster-defining threshold p&lt;0.005) and one cluster in right superior temporal pole (right STP, <xref ref-type="fig" rid="fig3">Figure 3G</xref>, left and middle panels, peak coordinate [<italic>x, y, z</italic>] = [36, 20, –30], <italic>t</italic>(37) = 4.962, cluster-level p=0.018 FWE-corrected, cluster-defining threshold p&lt;0.005). The above analysis did not identify grid-like pattern in EC that is aligned to the grid orientation of itself. It could be that the signal-to-noise ratio is too low in EC to pass the stringent whole-brain test. Another possibility is that a distributed coding scheme is employed by the EC. However, in the more statistically lenient ROI-based analysis, we failed to find evidence of grid-like code in the EC aligned to its own putative grid orientation either with this orientation estimation approach or with the representation similarity analysis (RSA) approach (‘Materials and methods’, <xref ref-type="fig" rid="fig3s1">Figure 3—figure supplements 1</xref> and <xref ref-type="fig" rid="fig3s2">2</xref>).</p><p>One important assumption underlying the univariate analysis for grid-like code in human fMRI data is that neighboring grid cells share similar grid orientation. Consistent with previous studies, we examined this assumption in our dataset by testing the distribution of putative voxel-wise grid orientations in the right FP ROI and in the right pmEC ROI for each participant (‘Materials and methods’). This revealed a clustered distribution of voxel-wise grid orientations in FP ROI (<italic>V</italic>-test, all p&lt;0.011, except in one participant’s estimating set p=0.176; see <xref ref-type="fig" rid="fig3s3">Figure 3—figure supplement 3A</xref> for representative participants). Previous studies using a similar approach in fMRI have also shown that grid orientations across participants tend to distribute uniformly (<xref ref-type="bibr" rid="bib3">Bao et al., 2019</xref>). This has been replicated in the right FP ROI in our dataset (<xref ref-type="fig" rid="fig3s4">Figure 3—figure supplement 4</xref>, top, Rayleigh’s tests for nonuniformity, all p&gt;0.782). However, in the pmEC ROI, these results are less consistent. With regard to voxel-wise orientations, 31 participants show the above clustered distribution (<italic>V</italic>-test, all p&lt;0.040; see <xref ref-type="fig" rid="fig3s3">Figure 3—figure supplement 3B</xref> for representative participants), but there are seven participants each of whom has at least one estimating set that did not pass the statistical test (<italic>V</italic>-test, all p&gt;0.068). Across participants, only grid orientations from two estimating sets conformed to the uniform distribution (<xref ref-type="fig" rid="fig3s4">Figure 3—figure supplement 4</xref>, bottom panel, Rayleigh’s tests for nonuniformity, run 1,2,3: p=0.010, run 1,2,4: p=0.019).</p><p>For completeness, we tested the specificity of hexagonal modulation. That is, the identified alignment effect only exists with sixfold periodicity. The above orientation estimation and cross-validation procedure was repeated for each of the four controlled periodicity (i.e., fourfold, fivefold, sevenfold, and eightfold). Signals were extracted from the clusters that showed significant hexagonal consistency. One-sample <italic>t</italic>-tests showed that signals within these clusters were not modulated by any of the controlled periodicities, and paired <italic>t</italic>-test showed that sixfold periodicity in general showed greater alignment effect (<xref ref-type="fig" rid="fig3">Figure 3D–G</xref>, right panels). In sum, our univariate analysis revealed that the vmPFC and left EC showed sixfold-specific grid-like code aligned to the right FP’s grid orientation and that the vmPFC and right STP showed sixfold-specific grid-like code aligned to the right pmEC’s grid orientation.</p></sec><sec id="s2-4"><title>Behavioral relevance of spatial codes for the social value map</title><p>Next, we want to address whether the identified distance or grid-like code could have any behavioral relevance. Previous studies have found that hexagonal modulation effect and hexagonal consistency effect positively correlate with accuracy in the recall task in the scanner (<xref ref-type="bibr" rid="bib9">Constantinescu et al., 2016</xref>). However, we did not find such a correlation in our data (<xref ref-type="fig" rid="fig4s1">Figure 4—figure supplement 1</xref>). Then, we explored if there is any correlation between neural indices of map-like representation and behavior performance outside the scanner as well as individual differences. The covariates we explored can be classified into two categories. The first category reflects participants’ ability to make decisions based on the social value map, that is, the distance effect in the compare task. Specifically, we focused on the distance effect during the cooperation block when participants choose the avatar they are more willing to cooperate with by taking into account both dimensions. This is essentially the beta weight of the distance regressor in predicting participants’ accuracy and log-transformed response time. The second category reflects participants’ social trait, including social anxiety and social avoidance scores. The covariates were entered into the second-level analysis of the consistency effect GLM separately.</p><p>Whole-brain analysis revealed significant clusters in the temporal lobe whose consistency effect scaled with distance effect in response time. For grid orientation of right FP ROI (<xref ref-type="fig" rid="fig4">Figure 4A</xref>), hexagonal consistency effect in the left middle temporal gyrus and right lingual gyrus correlated with the distance effect (left middle temporal gyrus: peak coordinate [<italic>x, y, z</italic>] = [–36, –70, 8], <italic>t</italic>(37) = 4.528, cluster-level p&lt;0.001 FWE-corrected; right lingual gyrus: peak coordinate [<italic>x, y, z</italic>] = [–38, –66, 4], <italic>t</italic>(37) = 4.369, cluster-level p&lt;0.001 FWE-corrected; cluster-defining threshold p&lt;0.005). For grid orientation of right pmEC ROI (<xref ref-type="fig" rid="fig4">Figure 4B</xref>), hexagonal consistency effect in bilateral lingual correlated with the distance effect (left lingual gyrus: peak coordinate [<italic>x, y, z</italic>] = [–12, –68, –2], <italic>t</italic>(37) = 4.355, cluster-level p=0.077 FWE-corrected; right lingual gyrus: peak coordinate [<italic>x, y, z</italic>] = [16, –62, –2], <italic>t</italic>(37) = 3.934, cluster-level p=0.032 FWE-corrected; cluster-defining threshold p&lt;0.005). In general, greater distance effect in the comparison task correlated with greater hexagonal consistency in temporal lobe aligned to both prefrontal and entorhinal grid orientations. In addition, this analysis also revealed a cluster in the left precuneus/posterior cingulate cortex (left PCC, <xref ref-type="fig" rid="fig4">Figure 4C</xref>, peak coordinate [<italic>x, y, z</italic>] = [0, –64, 28], <italic>t</italic>(37) = 4.965, cluster-level p&lt;0.001 FWE-corrected, cluster-defining threshold p&lt;0.001). Its consistency effect aligned to the right FP grid orientation was negatively correlated with social avoidance score.</p><fig-group><fig id="fig4" position="float"><label>Figure 4.</label><caption><title>Behavioral relevance of hexagonal consistency effect.</title><p>(<bold>A, B</bold>) Higher hexagonal consistency in temporal lobe aligned to grid orientation of (<bold>A</bold>) right FP region of interest (ROI) and (<bold>B</bold>) right pmEC significantly correlated with stronger distance effect in compare task when choosing preferred partners for cooperation. Display threshold: voxel-level p&lt;0.005, cluster-level p&lt;0.05 FWE-corrected. (<bold>C</bold>) Hexagonal consistency effect in left precuneus aligned to grid orientation of right FP ROI significantly correlated with social avoidance score. Display threshold: voxel-level p&lt;0.001, cluster-level p&lt;0.05 FWE-corrected. n.s., p&gt;0.05, *p&lt;0.05, **p&lt;0.01, ***p&lt;0.001. FP, frontal pole; pmEC, posterior–medial entorhinal cortex; MTG, middle temporal gyrus; LING, lingual gyrus.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-89025-fig4-v1.tif"/></fig><fig id="fig4s1" position="float" specific-use="child-fig"><label>Figure 4—figure supplement 1.</label><caption><title>No evidence of correlation between grid-like (<bold>A</bold>) and distance (<bold>B</bold>) representation and performance in the scanner.</title><p>The number in each grid indicates Pearson correlation coefficient between a pair of behavioral and neural variable, and color indicates p-value result from statistical test (false discovery rate [FDR]-corrected).</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-89025-fig4-figsupp1-v1.tif"/></fig></fig-group></sec></sec><sec id="s3" sec-type="discussion"><title>Discussion</title><p>In this study, we investigated whether cognitive map in social cognition domain recruits the neural processing mechanism similar to its spatial counterpart. We identified distance representation in the precuneus, fusiform gyrus, and middle occipital gyrus. In addition, we demonstrated some evidence of grid-like activity in PFC and EC. Furthermore, we explored the behavioral relevance of grid-like activity in temporal pole and precuneus.</p><p>When participants were mentally traversing a predefined social value map, we found that activities in the bilateral precuneus were positively correlated with traveled distance, while activities in bilateral FFG and right MOG were negatively correlated with traveled distance. In spatial navigation literature, though intracranial electroencephalography studies have shown the relevance of hippocampal theta oscillation in encoding traveled distance, neural correlates of traveled distance at the macroscopic level using fMRI are relatively sparsely investigated (<xref ref-type="bibr" rid="bib27">Kunz et al., 2019</xref>). <xref ref-type="bibr" rid="bib42">Patai et al., 2019</xref> showed that retrosplenial cortex positively correlated with path distance in that greater distance is associated with increased precuneus activity and that this effect remained robust after controlling for Euclidean distance. Likewise, we showed that precuneus activity was positively correlated with traveled Euclidean distance during implicit navigation in the abstract social space. Moreover, the present peak coordinates coincide with those reported in a previous study by <xref ref-type="bibr" rid="bib40">Park et al., 2020</xref>. In their study, participants learned 2D social hierarchy (competence and popularity) of two groups of agents and were asked to perform a transitive inference task in which they compared a pair of agents on their competence or popularity. The authors found that bilateral precuneus represented pairwise difference in the task-relevant dimension instead of pairwise Euclidean distance in the 2D space. Another study reported that posterior cingulate cortex/precuneus tracks the length of the vector of social relationship change, that is, an egocentric distance (<xref ref-type="bibr" rid="bib51">Tavares et al., 2015</xref>). Taken together, we speculate that precuneus may encode the distance of the route, either on a concrete or an abstract map, that participants trespass under task demand. Less clear is the negative correlation we observed between traveled distance and activity in fusiform as well as middle occipital gyrus. Both FFG and MOG are involved in human spatial navigation (<xref ref-type="bibr" rid="bib8">Boccia et al., 2014</xref>). In particular, fusiform gyrus extending into the parahippocampal place area has been shown to be involved in processing spatial information such as landmark and orientation cues (<xref ref-type="bibr" rid="bib45">Qiu et al., 2019</xref>). However, to our knowledge, there is no study that reports such negative distance coding in these occipitotemporal regions during navigation.</p><p>Apart from the distance code, another focus of the current study was to test whether grid-like codes support the organization of social knowledge. Previous studies on reporting grid-like codes mostly report hexagonal modulated pattern in the EC and medial prefrontal regions aligned to putative grid orientation from both regions (<xref ref-type="bibr" rid="bib9">Constantinescu et al., 2016</xref>). The current study partly replicated these findings, most of which are in the prefrontal region. In terms of prefrontal orientation, whole-brain analysis revealed alignment effects in the bilateral vmPFC and left EC. In terms of entorhinal orientation, however, alignment effect was found in the bilateral vmPFC and right superior temporal pole, but not in the EC. Though we found evidence of prefrontal grid-like codes subserving social navigation, its origin remains elusive. To date, there has been no significant evidence of grid-like neuronal tuning in this area (<xref ref-type="bibr" rid="bib56">Wikenheiser et al., 2021</xref>). <xref ref-type="bibr" rid="bib20">Jacobs et al., 2013</xref> examined grid-like cells in a variety of brain regions, including the frontal cortex in neurosurgical patients during a virtual navigation task, but the proportion of significant grid-like cells in the frontal cortex did not exceed type I error rate (they did identify grid-like cells in cingulate cortex, which is posterior to the prefrontal regions). Therefore, it is less likely that the prefrontal grid-like codes reported in our study and previous literature come from grid cells in the PFC. A more plausible explanation is that the anatomically and functionally connected medial- and orbitofrontal cortex and EC (<xref ref-type="bibr" rid="bib36">Navarro Schröder et al., 2015</xref>; <xref ref-type="bibr" rid="bib43">Peng et al., 2018</xref>; <xref ref-type="bibr" rid="bib49">Squire and Zola, 1996</xref>) coordinated together to support flexible decision-making. However, adopting both univariate and multivariate approaches, the current study did not find the reliable effect of hexagonal grid-like code in the entorhinal region aligned to its own grid orientation, which should be evident if such hypothesis stands. Previous studies postulated that the lack of univariate evidence of grid-like code may have to do with a low signal-to-noise ratio (tSNR) in data from the EC (<xref ref-type="bibr" rid="bib3">Bao et al., 2019</xref>). Indeed, analysis (‘Materials and methods’) revealed lower tSNR in all four entorhinal subregions compared to the frontal pole cluster from the quadrature filter analysis (<xref ref-type="fig" rid="fig3s5">Figure 3—figure supplement 5A</xref>). But we did not identify a significant relationship between tSNR and the <italic>Z</italic>-transformed <italic>F</italic> statistics of hexagonal modulation either across participants or within participants (<xref ref-type="fig" rid="fig3s5">Figure 3—figure supplement 5B and C</xref>, <xref ref-type="table" rid="table4">Table 4</xref>). Thus, we cannot conclude that a low signal-to-noise ratio in EC led to this null finding in our study.</p><table-wrap id="table4" position="float"><label>Table 4.</label><caption><title>Related to <xref ref-type="fig" rid="fig3s5">Figure 3—figure supplement 5C</xref>.</title><p>Group-level Wilcoxon signed-rank test of correlation between voxel-wise temporal signal-to-noise ratio (tSNR) and the <italic>Z</italic>-statistics of hexagonal modulation effect in frontal pole and entorhinal regions of interest (ROIs).</p></caption><table frame="hsides" rules="groups"><thead><tr><th align="left" valign="bottom">ROIs</th><th align="left" valign="bottom">N</th><th align="left" valign="bottom">Test statistics</th><th align="left" valign="bottom">p</th></tr></thead><tbody><tr><td align="left" valign="bottom">Right frontal pole</td><td align="left" valign="bottom">38</td><td align="left" valign="bottom">268.000</td><td align="left" valign="bottom">0.140</td></tr><tr><td align="left" valign="bottom">Left anterior–lateral entorhinal cortex</td><td align="left" valign="bottom">38</td><td align="left" valign="bottom">331.000</td><td align="left" valign="bottom">0.572</td></tr><tr><td align="left" valign="bottom">Right anterior–lateral entorhinal cortex</td><td align="left" valign="bottom">38</td><td align="left" valign="bottom">415.000</td><td align="left" valign="bottom">0.528</td></tr><tr><td align="left" valign="bottom">Left posterior–medial entorhinal cortex</td><td align="left" valign="bottom">38</td><td align="left" valign="bottom">396.500</td><td align="left" valign="bottom">0.712</td></tr><tr><td align="left" valign="bottom">Right posterior–medial entorhinal cortex</td><td align="left" valign="bottom">38</td><td align="left" valign="bottom">433.000</td><td align="left" valign="bottom">0.369</td></tr></tbody></table></table-wrap><p>Nonetheless, our study did provide some incomplete evidence of grid-like activity in the EC and prefrontal region while participants were mentally trespassing an abstract social space. Grid codes are proposed to provide a metric of space (<xref ref-type="bibr" rid="bib32">Moser and Moser, 2008</xref>) and underlie the process of path integration (<xref ref-type="bibr" rid="bib30">McNaughton et al., 2006</xref>). Previous studies have suggested that entorhinal grid codes are capable of representing space even at a higher level of abstraction that goes beyond spatial navigation to support cognitive flexibility in general (<xref ref-type="bibr" rid="bib5">Bellmund et al., 2018</xref>). Existing literature revealed correlation between entorhinal and prefrontal grid-like code and performance in spatial, perceptual, and conceptual space. Indeed, our exploratory analysis showed that the univariate hexagonal consistency effect in temporal lobe scaled with the distance effect in a comparison task block when participants chose their preferred partner for future cooperation. The distance effect reflected the extent to which participants relied on their preference judgment on the pairwise distance between the given pair of avatars. As we explicitly required participants to take both dimensions into consideration, it reflected participants’ ability to plan a route between landmarks (which represents the retained impression of social encounters) in the abstract social space. This is very similar to what <xref ref-type="bibr" rid="bib41">Park et al., 2021</xref> reported in their recent study. In this study, participants were trained on the rankings of 16 individuals on two dimensions (competence and popularity) separately, then they were asked to make comparisons between novel pairings unseen during training. Replicating their previous findings (<xref ref-type="bibr" rid="bib40">Park et al., 2020</xref>), the authors found that the entorhinal and hippocampus system successfully reconstruct the unseen whole spectrum of social hierarchies as a 2D cognitive map. Moreover, they found that grid-like representations support trajectories of novel inferences on this 2D cognitive map that underpins decision-making. Park’s study and ours differed in that they focused on discrete relational structures whilst we constructed a continuous social space. Collectively, this evidence supports the notion that grid-like codes underpin navigation in an abstract social cognitive map, be it discrete or continuous.</p><p>Intriguingly, our study found that the intensity of hexagonal modulation in the precuneus aligned to estimated grid orientation of the prefrontal region is negatively correlated with participants’ social avoidance tendency. While previous studies mainly reported grid-like codes in the EC and PFC and its relevance to spatial navigation deficit in a clinically risky population (<xref ref-type="bibr" rid="bib26">Kunz et al., 2015</xref>), to the best of our knowledge, no report has shown the psychological relevance of grid-like code outside these classical regions to potential social deficit. One study of direct neuronal recording revealed grid-like neuronal activity in patients’ cingulate cortex during virtual spatial navigation task (<xref ref-type="bibr" rid="bib20">Jacobs et al., 2013</xref>), implying that the human grid-cell network previously focused around the entorhinal and prefrontal regions also extends to the cingulate cortex. However, our study did not find evidence of grid-like pattern in the precuneus. Thus, we cannot conclude that our result points to a direct relationship between precuneus grid-like code and social functionality. Meanwhile, precuneus, as a core node of the DMN, has abundant neuroanatomical connections with prefrontal regions (<xref ref-type="bibr" rid="bib15">Greicius et al., 2009</xref>; <xref ref-type="bibr" rid="bib22">Khalsa et al., 2014</xref>; <xref ref-type="bibr" rid="bib37">Oane et al., 2020</xref>). Precuneus has also been reported to show a decrease in resting-state connectivity to parahippocampal gyrus and medial PFC in patients with SAD (<xref ref-type="bibr" rid="bib57">Yuan et al., 2018</xref>). Therefore, it is likely that downstream projections from the OFC/vmPFC motivated the observed correlation pattern in our study.</p><p>In conclusion, the present study demonstrates that navigating in a continuous social space recruited distance codes and grid-like codes in brain regions reported by spatial navigation studies and their behavioral and psychological relevance. Our findings further strengthen the notion that neural mechanisms involved in spatial cognitive map may play a domain-general role in maintaining an abstract, structured representation of knowledge that supports flexible cognitive behavior.</p><p>Our study has a few limitations. First, as we used a visual analog to guide participants to imagine moving in this abstract social space, grid-like coding could reflect the processing of both the sensory information and the abstract social concept. It would be better to control for this as in <xref ref-type="bibr" rid="bib3">Bao et al., 2019</xref>. Second, to make our study comparable to those investigating the representation of abstract nonsocial knowledge, our scanner task investigates social navigation in a static environment and no social interaction or social decision is involved. Further studies should be conducted to investigate how such a structured representation of social knowledge is reused and updated during social decisions and social interactions. Third, we specifically designed the abstract social value map to be formed by two orthogonal dimensions that have the same scale. This allows us to examine grid-like activity pattern with sixfold periodicity unambiguously. But this set-up may lack generality. For one thing, it is unlikely that all parts of the whole social value space span by the warmth and competence dimension are equally important. Social ties are more likely to be formed among humans alike (<xref ref-type="bibr" rid="bib31">McPherson et al., 2001</xref>) and humans show the tendency to represent ingroup members more differentially than outgroup members (<xref ref-type="bibr" rid="bib19">Hugenberg et al., 2010</xref>; <xref ref-type="bibr" rid="bib39">Ostrom et al., 1993</xref>), so it is likely that some area of the social value space is represented in finer granularity than the other. In spatial navigation, entorhinal grid cells showed sensitivity to geometric and environmental features, and the resulting distorted grid fields no longer form a regular hexagonal lattice and fail to show sixfold periodicity (<xref ref-type="bibr" rid="bib12">Derdikman et al., 2009</xref>; <xref ref-type="bibr" rid="bib17">He and Brown, 2019</xref>; <xref ref-type="bibr" rid="bib25">Krupic et al., 2015</xref>). For instance, grid fields have been found to sometimes warp toward reward (<xref ref-type="bibr" rid="bib7">Boccara et al., 2019</xref>). In this sense, spontaneous social value space may bear more resemblance to such kind of reward map covered by distorted grid fields rather than a regular, uniform square/circular open arena where sixfold symmetric grid-like coding was originally identified. For another, the geometric properties of social and nonsocial cognitive space in real life can be very different from that of the physical space in navigation. Our knowledge of other people in real life is often high-dimensional integrating multimodal information from sensory features (face, voice, etc.) to social cognitive information (hobbies, social status, etc.). Moreover, while dimensions of physical space (the cartesian axes) are orthogonal and their metrics are on the same scale, the dimensions of social perception in real life may not be orthogonal and may be incomparable. The stereotype content model predicted that there is a weak but low correlation between warmth and competence (<xref ref-type="bibr" rid="bib11">Cuddy et al., 2009</xref>) and other studies have found there exists compensation between these dimensions (<xref ref-type="bibr" rid="bib21">Kervyn et al., 2010</xref>). To the best of our knowledge, it remains elusive whether and how grid cells can represent such high-dimensional space with a non-orthonormal basis and how the univariate and multivariate analyses pipeline used to identify grid-like coding in fMRI signal could be revised to address these concerns. Taken together, the intrinsic social cognitive map in which humans structure their knowledge of others may be nonuniform, high-dimensional, and have non-orthonormal dimensions. Future studies would need to take this into account and explore beyond the sixfold grid-like activity pattern in regular 2D space.</p></sec><sec id="s4" sec-type="materials|methods"><title>Materials and methods</title><sec id="s4-1"><title>Participants</title><p>No power analysis was done to predetermine the sample size. Instead, we tried to achieve a sample size comparable to previous studies investigating grid-like representations using fMRI (<xref ref-type="bibr" rid="bib13">Doeller et al., 2010</xref>). Forty-four participants (18 males, mean age ± SD: 21.59 ± 2.56) recruited from surrounding universities finished all behavioral training and fMRI scanning in the current study at the Beijing Normal University Imaging Center for Brain Research. Each participant underwent intensive behavioral training (including one learning session and one review session) and one fMRI scanning session (<xref ref-type="fig" rid="fig1s1">Figure 1—figure supplement 1F</xref>). Three participants were excluded from all further analyses due to excessive head motion in the scanner (framewise displacement &gt;3 mm). Another three participants failing to achieve satisfactory behavioral accuracies (&lt;60%) in the scanning session were excluded from all further analyses. The remaining 38 participants' data were included in the behavioral and fMRI analysis reported in the main text (15 males, mean age ± SD: 21.47 ± 2.64).</p><p>The study was approved by the ethics committee of the National Key Laboratory of Cognitive Neuroscience and Learning at Beijing Normal University (ICBIR_A_0071_011). All regulations were followed, and participants signed paper-form informed consent before the experiment. Participants received monetary compensation for their participation in the current study.</p></sec><sec id="s4-2"><title>Data acquisition</title><sec id="s4-2-1"><title>Behavioral data acquisition</title><p>Behavioral tasks were programmed using Psychophysics Toolbox-3 in MATLAB or E-prime 2.0. Online pilot rating study, pre- and post-experiment questionnaires were collected via Qualtrics.</p><sec id="s4-2-1-1"><title>Pre-rating of experiment stimuli</title><p>Avatars were represented by standard photographs of volunteers who consented to the use of their photographs in the experiment. To make sure the photographs did not induce prior perception of competence and trustworthiness, we conducted a pilot rating experiment online via Qualtrics in an independent sample of 39 participants (17 males, age: 22.56 ± 2.41). In each trial, participants were shown one face and were asked to indicate their rating of the face on a 9-point Likert scale. Rating items were selected to reflect participants' perception of each face’s competence, trustworthiness, and attractiveness based solely on first impressions. Items reflecting competence included ability, efficacy, and creativity. Items reflecting trustworthiness included morality, friendliness, trustworthiness, and sincerity. Attractiveness was also included as an additional rating item. The order of rating items was randomized across trials to avoid habitual responses. We selected 6 (three from each gender) out of 48 faces that received middling ratings on all three dimensions (competence, trustworthiness, plus attractiveness) to serve as the stimuli in the current study. One-sample <italic>t</italic>-tests revealed that ratings on all three dimensions of these six faces were not significantly different from five (the midpoint of the rating scale).</p></sec><sec id="s4-2-1-2"><title>Investment task</title><p>At the beginning of the experiment, participants completed an investment task to develop a concrete understanding of the quantitative meaning of the two dimensions of the social value map (<xref ref-type="fig" rid="fig1s1">Figure 1—figure supplement 1A</xref>). The task is modified from the classic trust game. The investor is endowed with 1000 points and must allocate them between two agents. Competence is operationalized as how much more an agent can multiply his/her received investment while the return rate signals trustworthiness. The expectation of profit (the number of points) an investor can earn from one agent is thus formulated by:<disp-formula id="equ1"><label>(1)</label><mml:math id="m1"><mml:mrow><mml:mi>E</mml:mi><mml:mrow><mml:mo>[</mml:mo><mml:mrow><mml:mi>P</mml:mi><mml:mi>r</mml:mi><mml:mi>o</mml:mi><mml:mi>f</mml:mi><mml:mi>i</mml:mi><mml:mi>t</mml:mi></mml:mrow><mml:mo>]</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mi>i</mml:mi><mml:mi>n</mml:mi><mml:mi>v</mml:mi><mml:mi>e</mml:mi><mml:mi>s</mml:mi><mml:mi>t</mml:mi><mml:mi>m</mml:mi><mml:mi>e</mml:mi><mml:mi>n</mml:mi><mml:mi>t</mml:mi><mml:mo>×</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mn>1</mml:mn><mml:mo>+</mml:mo><mml:mi>c</mml:mi><mml:mi>o</mml:mi><mml:mi>m</mml:mi><mml:mi>p</mml:mi><mml:mi>e</mml:mi><mml:mi>t</mml:mi><mml:mi>e</mml:mi><mml:mi>n</mml:mi><mml:mi>c</mml:mi><mml:mi>e</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>×</mml:mo><mml:mi>t</mml:mi><mml:mi>r</mml:mi><mml:mi>u</mml:mi><mml:mi>s</mml:mi><mml:mi>t</mml:mi><mml:mi>w</mml:mi><mml:mi>o</mml:mi><mml:mi>r</mml:mi><mml:mi>t</mml:mi><mml:mi>h</mml:mi><mml:mi>i</mml:mi><mml:mi>n</mml:mi><mml:mi>e</mml:mi><mml:mi>s</mml:mi><mml:mi>s</mml:mi></mml:mrow></mml:math></disp-formula></p><p>Participants were all assigned the role of an investor. The two agents' competence and trustworthiness levels were preset by the experiment program and remained the same across participants.</p></sec><sec id="s4-2-1-3"><title>Match task</title><p>After the investment task, participants completed 30 trials of the match task to learn to use a nonspatial controller to morph the visualization (<xref ref-type="fig" rid="fig1s1">Figure 1—figure supplement 1B</xref>). One box with two bars appeared on the left side of the screen, and the participants were asked to use the controller to morph it to match the target box on the right side of the screen. The two boxes varied in the height of their enclosed bars, that is, the competence and trustworthiness dimensions. The controller consisted of two horizontal thick black chunks, which signified how much the respective dimension would change. The closer to the top boundary, the more that dimension would change and vice versa. If placed on the midline, then the corresponding dimension would not change. Together, the controller’s two chunks represented the ratio between how much the heights of two bars (i.e., values on two dimensions) changed relative to each other. To encourage participants to integrate two dimensions simultaneously, we instructed them to morph the bars by making as few transitions as possible and as accurate as possible. The morphing was continuous, with bars in the left box shrinking or stretching in height.</p></sec><sec id="s4-2-1-4"><title>Explore task</title><p>After participants learned how to use the controller, they explored the vast social space by morphing the bars with different competence: trustworthiness ratio using the nonspatial controller to look for the six avatars (<xref ref-type="fig" rid="fig1s1">Figure 1—figure supplement 1C</xref>). No prior information about the characteristics of the avatars was provided to the participants. Thus, participants could only explore social space as if they were looking for landmarks in a newly introduced physical environment. An avatar would pop out when the visualization matched his/her characteristics. Specifically, the avatar would pop out when participants’ current location fell within a 0.01-unit radius of the correct location on the social value map. In this way, participants not only learned the characteristics of each avatar but also became familiar with the whole space even though this map-like structure was never revealed to them.</p></sec><sec id="s4-2-1-5"><title>Collect task</title><p>After participants were fully acquainted with the avatars and the social space, they completed the collect task (<xref ref-type="fig" rid="fig1s1">Figure 1—figure supplement 1D</xref>). The task resembles the match task, except that instead of a target box, a target avatar appeared on the right side of the screen. Participants were instructed to morph the box on the left to match the characteristic of the avatar. Again, we instructed them to morph the bars by making as few transitions as possible and as accurate as possible. Each avatar was tested five times in each block, yielding 30 trials. Trials were presented randomly. Participants completed one block of collect task in each session.</p></sec><sec id="s4-2-1-6"><title>Recall task</title><p>Participants completed the recall task both outside and inside the scanner (<xref ref-type="fig" rid="fig1">Figure 1D</xref>, <xref ref-type="video" rid="fig1video1">Figure 1—animation 1</xref>). On each trial of the recall task, participants were first shown a visualization morphing according to a predefined competence: trustworthiness ratio for 1 s. The bars then stopped morphing, and participants were instructed to imagine the bars keep morphing according to the same ratio, at the same speed, and for the same amount of time. After this, participants had to choose which of the three given options matched the bars after imagination.</p><p>Each block has 80 trials, each defined by a trajectory. To make sure trajectory directions were sampled uniformly on [0,2π), we divided the whole range into 80 bins and each trial sampled a direction from one bin. Half of the trajectories led to learned avatars while the other half led to locations not associated with any avatar in the abstract space. Outside the scanner, participants completed two blocks of recall task in each session, resulting in 160 trials in total. In the scanner, participants completed four blocks of recall task, one in each run, resulting in 320 trials in total.</p></sec><sec id="s4-2-1-7"><title>Rank task</title><p>We asked participants to rank the six learned avatars based on competence, trustworthiness, and willingness to cooperate with the avatar. When asking participants to rank based on willingness to cooperate, we specifically asked them to consider the two dimensions simultaneously and with the same weight.</p></sec><sec id="s4-2-1-8"><title>Compare task</title><p>The compare task was designed to test whether participants formed an internal representation of the social value map, even though the map-like structure was never directly revealed to them during the experiment (<xref ref-type="fig" rid="fig1s1">Figure 1—figure supplement 1E</xref>). Participants were asked to compare two avatars on a given dimension and indicate which face had a higher value on the respective dimension using a key press. The hypothesis was that if internal representation were formed, then it would take participants longer time to compare avatars with closer distance on the given dimension than to compare avatars far apart. Each possible combination of avatars was tested four times on each of the two dimensions. This yields 120 trials presented randomly. After that, an additional block on willingness to cooperate with 60 trials (four repetitions per combination) followed. Again, we specifically asked participants to give the two dimensions equal consideration when deciding their willingness to cooperate.</p></sec><sec id="s4-2-1-9"><title>Pre- and post-experiment face rating</title><p>To reassure that the used face stimuli did not elicit biased social perception in the current sample, we asked our participants to rate the six avatars on a 9-point Likert scale when they signed up for the experiment (at least 1 day before the experiment). The rating items were identical to those in the online rating pilot experiment. To test whether participants learned each avatar’s characteristics and updated their perception of the avatars, we asked our participants to rate the six avatars again after the fMRI scan.</p></sec><sec id="s4-2-1-10"><title>Map task</title><p>At the end of the post-experiment questionnaire, participants were informed about the map-like structure and were asked to indicate the location of each avatar on an empty social value map using a mouse click. We instructed them that the locations of avatars were defined by his/her level of competence and trustworthiness. We also asked participants whether they were aware of such a map-like structure and whether their strategy resembled this map-like organization.</p></sec></sec></sec><sec id="s4-3"><title>MRI data acquisition</title><p>We acquired T2-weighted functional images on a 3T SIEMENS MAGNETOM Prisma scanner with a 64-channel head coil. We acquired 33 slices, 3 mm thick with repetition time (TR) = 2000 ms, echo time (TE) = 30 ms, flip angle = 90°, field of view (FoV) = 224 mm, voxel size = 3.5 × 3.5 × 3.5 mm<sup>3</sup>. To correct for spatial distortion, a field map was acquired with dual echo-time images covering the whole brain with the following parameters: TR = 400 ms, TE1 = 4.92 ms, TE2 = 7.38 ms, flip angle = 60°, FoV = 224 mm, voxel size = 3.5 × 3.5 × 3.5 mm<sup>3</sup>. A T1-weighted structural image was acquired with the following parameters: TR = 2530 ms, TE = 2.98 ms, flip angle = 7°, FoV = 256 mm, voxel size = 0.5 × 0.5 ×1 mm<sup>3</sup>.</p></sec><sec id="s4-4"><title>Data analysis</title><p>All analyses were performed with custom code in MATLAB and R.</p><sec id="s4-4-1"><title>Behavioral data analysis</title><p>Different performance indices were calculated for each task to test whether performance improved over sessions. To test whether performance improved over sessions, we built linear mixed effect models with random intercept for each participant and entered session as fixed effect otherwise specified.</p><p>In the explore task, we first computed the time participants spent exploring the social space to find all six avatars. We predicted that participants would spend much less time in the review session than the learning session had they been fully acquainted with the space and the avatars. Next, the social space was divided into 15 × 15 subregions and we computed the amount of time spent in each subregion and plotted the corresponding color-coded trajectory maps (<xref ref-type="fig" rid="fig1">Figure 1E</xref>). The top/bottom rows and leftmost/rightmost columns of subregions were classified as edges, yielding the index of ‘time at edges’. In addition, ‘time at avatars’ was computed based on the time the avatars were on screen. Note that all these timing indices were computed as a percentage of the total time spent navigating in the explore task in a given session. If participants were well acquainted with the space and avatars, ‘time at edges’ would decrease and ‘time at avatars’ would increase in the review session compared to the learning session. We built linear mixed effect models to examine these hypotheses.</p><p>In the collect task, we computed the following metrics:</p><list list-type="order"><list-item><p>The mean number of transitions participants needed to morph the visualization to match the target avatar.</p></list-item><list-item><p>the deviation from ideal trajectory, which is the angle difference between participants' first transition and the ideal trajectory in each trial. We computed the mean deviation and the percentage of trials where participants deviated less than 15°.</p></list-item><list-item><p>The mean distance between the target avatar and participants’ response.</p></list-item></list><p>Greater memory performance should be signaled by a lower mean number of transitions, a higher percentage of trials with deviation less than 15°, and a shorter mean distance from the target avatar.</p><p>In the recall task, we computed the percentage of correct responses.</p><p>In the compare task, we focused on the effect of distance between compared pairs on accuracy and response time. We defined task-relevant distance as the distance between avatar pairs on the compared dimension. Specifically, for the two social value map dimensions, this was the distance on the competence/trustworthiness axis. For the willingness to cooperate block, this was the difference between the expected profit calculated in formula 1. We concatenated data from the review session and the scanning session and built linear mixed effect models. Session and task-relevant distance between avatar pairs was entered as fixed effect. We included random intercept for each participant. We also included a random slope term for the task-relevant distance. The random slopes were extracted from the mixed effect model as indices for distance effect when exploring the behavioral relevance of spatial codes for the social value map.</p><p>For the pre- and post-experiment face ratings. we built three separate linear mixed effect models with random intercept to test whether participants’ ratings on competence, trustworthiness, and attractiveness became more aligned with the avatars’ social characteristic after the experiment. Three regressors were included as fixed effect: (1) time, that is, post- vs pre-experiment; (2) avatar’s social characteristic; and (3) interaction between time and avatar. Specifically, avatar’s social characteristic was defined in alignment with the rating item entered as the dependent variable. That is, in the competence rating regression model, social characteristic referred to the location on competence axis. Similarly, in the trustworthiness rating regression model, social characteristic referred to the location on the trustworthiness axis. Finally, in the attractiveness rating regression model, expected profit was entered as a social characteristic.</p></sec><sec id="s4-4-2"><title>Preprocessing of fMRI data</title><p>Preprocessing of fMRI data was done with SPM12. Functional images were spatially realigned to the first image in the time series and corrected for slice-timing. Spatial distortion was based on a field map. The T1-weighted structure image was co-registered to the mean aligned functional image, segmented, and normalized to MNI space. The derived transformation parameters from structural image normalization were applied to normalize realigned functional images. Finally, smoothing was done with a 6 mm full-width half-maximum Gaussian kernel.</p></sec><sec id="s4-4-3"><title>Whole-brain univariate analysis</title><p>All whole-brain univariate analyses were conducted in SPM12 following routine procedure. In particular, we switched off SPM12’s implicit threshold during model estimation and used an explicit mask from SPM12’s default repository (the ‘mask_ICV.nii’ file) that included all intracranial volumes instead. This specific treatment was done as we observed susceptible signal loss in the frontal and entorhinal regions after applying the implicit threshold. Following routines from previous literature, the explicit mask was used instead. In all univariate analyses, boxcar functions were used and the boxcar duration corresponds to the duration of the modelled stage.</p><sec id="s4-4-3-1"><title>A functional localizer for hexagonal modulation: GLM1</title><p>GLM1 consisted of two regressors, one modeling the morph stage and one modeling the choice stage. The aim of GLM1 was to identify the regions sensitive to hexagonal modulation. Let <inline-formula><mml:math id="inf1"><mml:mi>φ</mml:mi></mml:math></inline-formula> denote the hypothetical grid orientation of a region, and <inline-formula><mml:math id="inf2"><mml:mi>θ</mml:mi></mml:math></inline-formula> the trajectory (moving direction). If neural activity in a region is hexagonally modulated, then its activity should be a waveform of <inline-formula><mml:math id="inf3"><mml:mi>c</mml:mi><mml:mi>o</mml:mi><mml:mi>s</mml:mi><mml:mo>⁡</mml:mo><mml:mfenced open="[" close="]" separators="|"><mml:mrow><mml:mn>6</mml:mn><mml:mi>*</mml:mi><mml:mfenced separators="|"><mml:mrow><mml:mi>θ</mml:mi><mml:mo>-</mml:mo><mml:mi>φ</mml:mi></mml:mrow></mml:mfenced></mml:mrow></mml:mfenced></mml:math></inline-formula> . Omitting error and intercept, this hypothesis can be expressed using the following formula:<disp-formula id="equ2"><mml:math id="m2"><mml:mi>A</mml:mi><mml:mi>c</mml:mi><mml:mi>t</mml:mi><mml:mi>i</mml:mi><mml:mi>v</mml:mi><mml:mi>i</mml:mi><mml:mi>t</mml:mi><mml:mi>y</mml:mi><mml:mo>=</mml:mo><mml:mi>ω</mml:mi><mml:mi>*</mml:mi><mml:mi>c</mml:mi><mml:mi>o</mml:mi><mml:mi>s</mml:mi><mml:mfenced open="[" close="]" separators="|"><mml:mrow><mml:mn>6</mml:mn><mml:mi>*</mml:mi><mml:mfenced separators="|"><mml:mrow><mml:mi>θ</mml:mi><mml:mo>-</mml:mo><mml:mi>φ</mml:mi></mml:mrow></mml:mfenced></mml:mrow></mml:mfenced></mml:math></disp-formula><disp-formula id="equ3"><label>(2)</label><mml:math id="m3"><mml:mrow><mml:mi>ω</mml:mi><mml:mo>∗</mml:mo><mml:mi>c</mml:mi><mml:mi>o</mml:mi><mml:mi>s</mml:mi><mml:mn>6</mml:mn><mml:mi>φ</mml:mi><mml:mi>c</mml:mi><mml:mi>o</mml:mi><mml:mi>s</mml:mi><mml:mn>6</mml:mn><mml:mi>θ</mml:mi><mml:mo>+</mml:mo><mml:mi>ω</mml:mi><mml:mo>∗</mml:mo><mml:mi>s</mml:mi><mml:mi>i</mml:mi><mml:mi>n</mml:mi><mml:mn>6</mml:mn><mml:mi>φ</mml:mi><mml:mi>s</mml:mi><mml:mi>i</mml:mi><mml:mi>n</mml:mi><mml:mn>6</mml:mn><mml:mi>θ</mml:mi></mml:mrow></mml:math></disp-formula><disp-formula id="equ4"><label>(3)</label><mml:math id="m4"><mml:mrow><mml:msub><mml:mi>β</mml:mi><mml:mrow><mml:mi>c</mml:mi><mml:mi>o</mml:mi><mml:mi>s</mml:mi><mml:mn>6</mml:mn><mml:mi>θ</mml:mi></mml:mrow></mml:msub><mml:mi>c</mml:mi><mml:mi>o</mml:mi><mml:mi>s</mml:mi><mml:mn>6</mml:mn><mml:mi>θ</mml:mi><mml:mo>+</mml:mo><mml:msub><mml:mi>β</mml:mi><mml:mrow><mml:mi>s</mml:mi><mml:mi>i</mml:mi><mml:mi>n</mml:mi><mml:mn>6</mml:mn><mml:mi>θ</mml:mi></mml:mrow></mml:msub><mml:mi>s</mml:mi><mml:mi>i</mml:mi><mml:mi>n</mml:mi><mml:mn>6</mml:mn><mml:mi>θ</mml:mi></mml:mrow></mml:math></disp-formula></p><p>where: <inline-formula><mml:math id="inf4"><mml:msub><mml:mrow><mml:mi>β</mml:mi></mml:mrow><mml:mrow><mml:mi>c</mml:mi><mml:mi>o</mml:mi><mml:mi>s</mml:mi><mml:mn>6</mml:mn><mml:mi>θ</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mi>ω</mml:mi><mml:mi>*</mml:mi><mml:mi>c</mml:mi><mml:mi>o</mml:mi><mml:mi>s</mml:mi><mml:mn>6</mml:mn><mml:mi>φ</mml:mi></mml:math></inline-formula><disp-formula id="equ5"><mml:math id="m5"><mml:msub><mml:mrow><mml:mi>β</mml:mi></mml:mrow><mml:mrow><mml:mi>s</mml:mi><mml:mi>i</mml:mi><mml:mi>n</mml:mi><mml:mn>6</mml:mn><mml:mi>θ</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mi>ω</mml:mi><mml:mi>*</mml:mi><mml:mi>s</mml:mi><mml:mi>i</mml:mi><mml:mi>n</mml:mi><mml:mn>6</mml:mn><mml:mi>φ</mml:mi></mml:math></disp-formula></p><p>If the theoretical prediction that there is an effect of hexagonal modulation is true, <inline-formula><mml:math id="inf5"><mml:mi>ω</mml:mi></mml:math></inline-formula> should be significantly different from zero.</p><p>Based on this, a pair of sine and cosine regressors were used as parametric modulators for the morph stage. In this way, testing against the null hypothesis of <inline-formula><mml:math id="inf6"><mml:msub><mml:mrow><mml:mi>β</mml:mi></mml:mrow><mml:mrow><mml:mi>c</mml:mi><mml:mi>o</mml:mi><mml:mi>s</mml:mi><mml:mn>6</mml:mn><mml:mi>θ</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:msub><mml:mrow><mml:mi>β</mml:mi></mml:mrow><mml:mrow><mml:mi>s</mml:mi><mml:mi>i</mml:mi><mml:mi>n</mml:mi><mml:mn>6</mml:mn><mml:mi>θ</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mn>0</mml:mn></mml:math></inline-formula> is essentially testing against the null hypothesis of <inline-formula><mml:math id="inf7"><mml:mi>ω</mml:mi><mml:mo>=</mml:mo><mml:mn>0</mml:mn></mml:math></inline-formula>. Therefore, at the individual level, <italic>F</italic>-test was used to search for potential regions modulated by a linear combination of <inline-formula><mml:math id="inf8"><mml:msub><mml:mrow><mml:mi>β</mml:mi></mml:mrow><mml:mrow><mml:mi>c</mml:mi><mml:mi>o</mml:mi><mml:mi>s</mml:mi><mml:mn>6</mml:mn><mml:mi>θ</mml:mi></mml:mrow></mml:msub><mml:mi>c</mml:mi><mml:mi>o</mml:mi><mml:mi>s</mml:mi><mml:mn>6</mml:mn><mml:mi>θ</mml:mi><mml:mo>+</mml:mo><mml:msub><mml:mrow><mml:mi>β</mml:mi></mml:mrow><mml:mrow><mml:mi>s</mml:mi><mml:mi>i</mml:mi><mml:mi>n</mml:mi><mml:mn>6</mml:mn><mml:mi>θ</mml:mi></mml:mrow></mml:msub><mml:mi>s</mml:mi><mml:mi>i</mml:mi><mml:mi>n</mml:mi><mml:mn>6</mml:mn><mml:mi>θ</mml:mi></mml:math></inline-formula>. These individual <italic>F</italic>-statistics were transformed into <italic>Z</italic>-statistics before entering group-level one-sample <italic>t</italic>-test. In future correlation analyses, the <italic>Z</italic>-statistics were extracted as an index for hexagonal modulation effect.</p></sec><sec id="s4-4-3-2"><title>Iterative cross-validation analysis for hexagonal consistency: GLM2</title><p>By binning trials according to trajectory’s alignment to a putative grid orientation <inline-formula><mml:math id="inf9"><mml:mi>φ</mml:mi></mml:math></inline-formula>, GLM2 aimed to test for hexagonal consistency.</p><p>In this cross-validation procedure, we separated each participant’s data into two sets, an estimating set with three runs and a testing set with one run. The estimating set was used to calculate the grid orientation of the ROIs. The remaining one run then served as the testing set where the alignment effect was tested with the inferred grid orientation. The theoretical prediction for hexagonal consistent grid-like code is that neural signal should be stronger in trials aligned than misaligned to the grid orientation.</p><p>To estimate grid orientation, GLM1 was applied to the estimating set yielding beta estimates for the sine and cosine regressors (<inline-formula><mml:math id="inf10"><mml:msub><mml:mrow><mml:mi>β</mml:mi></mml:mrow><mml:mrow><mml:mi>s</mml:mi><mml:mi>i</mml:mi><mml:mi>n</mml:mi><mml:mn>6</mml:mn><mml:mi>θ</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> and <inline-formula><mml:math id="inf11"><mml:msub><mml:mrow><mml:mi>β</mml:mi></mml:mrow><mml:mrow><mml:mi>c</mml:mi><mml:mi>o</mml:mi><mml:mi>s</mml:mi><mml:mn>6</mml:mn><mml:mi>θ</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula>) in each voxel. We extracted these beta estimates from ROI masks. Then, within a given ROI, beta estimates were averaged across all voxels within this region for sine and cosine regressors, respectively. The averaged beta estimates (<inline-formula><mml:math id="inf12"><mml:mover accent="false"><mml:mrow><mml:msub><mml:mrow><mml:mi>β</mml:mi></mml:mrow><mml:mrow><mml:mi>s</mml:mi><mml:mi>i</mml:mi><mml:mi>n</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>¯</mml:mo></mml:mover></mml:math></inline-formula> and <inline-formula><mml:math id="inf13"><mml:mover accent="false"><mml:mrow><mml:msub><mml:mrow><mml:mi>β</mml:mi></mml:mrow><mml:mrow><mml:mi>c</mml:mi><mml:mi>o</mml:mi><mml:mi>s</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>¯</mml:mo></mml:mover></mml:math></inline-formula>) were used to calculate the grid orientation for this region (grid orientation <inline-formula><mml:math id="inf14"><mml:mi>φ</mml:mi><mml:mo>=</mml:mo><mml:mrow><mml:mrow><mml:mfenced open="[" close="]" separators="|"><mml:mrow><mml:mi>a</mml:mi><mml:mi>r</mml:mi><mml:mi>t</mml:mi><mml:mi>a</mml:mi><mml:mi>n</mml:mi><mml:mfenced separators="|"><mml:mrow><mml:mfrac><mml:mrow><mml:mover accent="false"><mml:mrow><mml:msub><mml:mrow><mml:mi>β</mml:mi></mml:mrow><mml:mrow><mml:mi>s</mml:mi><mml:mi>i</mml:mi><mml:mi>n</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>¯</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mover accent="false"><mml:mrow><mml:msub><mml:mrow><mml:mi>β</mml:mi></mml:mrow><mml:mrow><mml:mi>c</mml:mi><mml:mi>o</mml:mi><mml:mi>s</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>¯</mml:mo></mml:mover></mml:mrow></mml:mfrac></mml:mrow></mml:mfenced></mml:mrow></mml:mfenced></mml:mrow><mml:mo>/</mml:mo><mml:mrow><mml:mn>6</mml:mn></mml:mrow></mml:mrow></mml:math></inline-formula>).</p><p>To test for the prediction of consistency effect, we classified trials according to <inline-formula><mml:math id="inf15"><mml:mi>θ</mml:mi></mml:math></inline-formula>’s (trajectory direction) offset from <inline-formula><mml:math id="inf16"><mml:mi>φ</mml:mi></mml:math></inline-formula> into 12 bins of 30° (<xref ref-type="fig" rid="fig3">Figure 3A</xref>, left panel), yielding six bins of aligned trials (0° modulo 60°) and six bins of misaligned trials (30° modulo 60°).</p><p>The above steps yielded the grid orientation applied to classify trials in the testing set. Each run acted as an estimating set three times and received putative grid orientation as a testing set once. Eventually, the four testing sets were fitted with GLM2. GLM2 consisted of 12 regressors, each modeling the morph stage of one bin of trials. At the individual level, contrast was built to test the activity difference between aligned and misaligned trials (align &gt; misalign). These first-level contrasts were entered into second-level one-sample <italic>t</italic>-test to look for the regions that show hexagonal consistency.</p></sec><sec id="s4-4-3-3"><title>Identifying distance code with parametric modulation: GLM3</title><p>GLM3 resembled GLM1, which also consisted of two regressors, one modeling the morph stage and one modeling the choice stage. The aim of GLM3 was to identify the regions sensitive to distance modulation. Thus, we entered the traveled Euclidean distance during the morph stage as a parametric modulator for the morph-stage regressor. At the individual level, <italic>t</italic>-contrast was built to search for potential regions modulated by the distance parametric modulator. These contrasts were entered into second-level one-sample <italic>t</italic>-test to look for the regions that represent distance during social navigation.</p></sec></sec></sec><sec id="s4-5"><title>Behavioral relevance of spatial codes</title><p>To specifically test the effect of grid-like code in regions that survive correction in GLM2 on behavior, we extracted the beta estimates of align &gt; misalign contrast for each region and each participant. Then we computed Pearson correlation between these beta estimates and accuracy as well as response time in the recall task in the scanner. This procedure was applied to the regions demonstrating distance representation (GLM3) as well. As multiple tests were performed, we adopted false discovery rate (FDR) correction to p-values to lower FDR. No significant correlation was found (<xref ref-type="fig" rid="fig4s1">Figure 4—figure supplement 1</xref>).</p><p>For whole-brain analyses to explore whether there is any correlation between neural indices of map-like representation and behavior performance outside the scanner as well as individual differences, we calculated two categories of behavioral indices to explore the relevance of the spatial codes calculated above. The first category of indices reflects participants’ ability to make decision based on the social value map. Specifically, we considered the distance effect during the cooperation block when participants decide the avatar they are more willing to cooperate with when taking into account both dimensions. Distance effect indices were extracted from the linear mixed effect model estimates specified in the behavioral data analysis section. The second category of indices reflects participants’ social trait, including social anxiety and social avoidance scores. We explored the behavioral relevance of grid-like code by entering the above indices as covariates into the second-level analysis when testing the grid orientation consistency effect (GLM2), and all covariates were tested in separate regression models.</p></sec><sec id="s4-6"><title>Univariate and multivariate analyses in EC ROI</title><p>As we failed to find evidence of grid-like activity in EC aligned to its own putative grid orientation using the first approach, we took the anatomical masks of EC (<xref ref-type="bibr" rid="bib28">Maass et al., 2015</xref>) and explored grid-like activity using both the orientation-estimation and RSA approach.</p><sec id="s4-6-1"><title>Univariate analyses</title><p>For the univariate analysis in ROI, we looked at both the quadrature filter analysis and the hexagonal consistency analysis. For the former, we extracted the <italic>Z</italic>-statistics in GLM1 from different subregions of EC for each participants and conducted one-sample <italic>t</italic>-test to see whether it is above zero in any of the subregions. For the hexagonal consistency effect, we extracted the contrast estimate for align &gt; misalign in GLM2 from different subregions of EC for each participants and conducted one-sample <italic>t</italic>-test to see whether it is above zero in any of the subregions. We looked at both within-subregion consistency (i.e., contrast estimates extracted from the same subregion as the orientation estimation subregion) and across-subregion consistency (i.e., contrast estimates extracted from another subregion). As multiple tests were performed, we adopted FDR correction to p-values to lower FDR.</p></sec><sec id="s4-6-2"><title>Multivariate analyses</title><p>The second approach leverages RSA and is widely adopted based on the assumption that a distributed coding scheme is employed by the EC. We conducted conventional representational similarity analysis on the unsmoothed data as implemented by CosmoMVPA toolbox (<xref ref-type="bibr" rid="bib38">Oosterhof et al., 2016</xref>) in MATLAB.</p><p>First, we estimated trial-specific activation for each trial in each run. As trajectories were drawn randomly in the social space, each trial was defined by a unique trajectory, yielding a rich-condition design. It has been suggested that in such fast event-related (fast ER) designs, signal for nearby trials tend to overlap in time. Conventional approach in block or slow ER design that includes each trial as a separate regressor in a large model may be problematic under fast ER settings as estimates can become unstable due to collinearity between the trial-specific regressors. To obtain a more accurate estimate of trial-specific activation, we leveraged the ‘least squares separate’ (LSS) approach (<xref ref-type="bibr" rid="bib1">Abdulrahman and Henson, 2016</xref>; <xref ref-type="bibr" rid="bib33">Mumford et al., 2012</xref>). This approach built separate GLMs for each trial, with one target regressor modeling the current trial of interest and a second nuisance regressor modeling the rest. After that, we took the beta estimate of the target regressor as the estimation of trial-specific activation. Signals were extracted from the entorhinal ROIs (from entorhinal as a whole or from four subregions) as trial-specific activity pattern for each of the 320 trials (<xref ref-type="fig" rid="fig3s1">Figure 3—figure supplement 1A</xref>).</p><p>We then tested whether this multivariate pattern is hexagonally modulated. Though the exact implementations varied slightly across studies, they fell into the following two categories according to their dependence on the estimated putative grid orientation.</p><p>The ‘orientation-independent’ approach (<xref ref-type="fig" rid="fig3s1">Figure 3—figure supplement 1B</xref>) tested the hypothesis that multivariate pattern similarity between trajectory pairs is proportional to the angular difference between their moving direction modulated by 60° (<xref ref-type="bibr" rid="bib4">Bellmund et al., 2016</xref>; <xref ref-type="bibr" rid="bib54">Viganò and Piazza, 2020</xref>; <xref ref-type="bibr" rid="bib55">Viganò et al., 2021</xref>). We first calculated the representational similarity between all possible pairs of trials, yielding a 320 × 320 dissimilarity matrix (DSM) for neural data (<xref ref-type="fig" rid="fig3s1">Figure 3—figure supplement 1A</xref>). Then, we derived model DSM from theoretical prediction (<xref ref-type="fig" rid="fig3s1">Figure 3—figure supplement 1B</xref>). Finally, we computed Spearman’s rank correlation between neural DSM and model DSM for each participant. One-sample <italic>t</italic>-test was conducted across participants on the Fisher <italic>Z</italic>-transformed correlation coefficients to test whether the correlation was significantly above zero.</p><p>The ‘orientation-dependent’ approach (<xref ref-type="fig" rid="fig3s1">Figure 3—figure supplement 1C</xref>) leveraged the assumption that if activity in a given ROI is aligned to a preferred orientation, the similarity of multivoxel patterns in this region should be higher for aligned trial pairs than that between aligned and misaligned trial pairs (<xref ref-type="bibr" rid="bib3">Bao et al., 2019</xref>). We computed the grid orientation in each entorhinal subregion using the same leave-one-out cross-validation procedure as in the univariate analysis. Trials were then classified into aligned and misaligned trials according to the angular difference between trajectories and the estimated grid orientation. We then computed the similarities between aligned-aligned trial pairs (AA) and aligned-misaligned trial pairs (AM). By subtracting the similarity between AM pairs from the similarity between AA pairs, we yield a pattern similarity difference index for each participant (<xref ref-type="fig" rid="fig3s1">Figure 3—figure supplement 1C</xref>). Paired <italic>t</italic>-tests were conducted to test whether the differences were significantly greater than zero. As multiple tests were performed, we adopted FDR correction to p-values to lower FD.</p></sec></sec><sec id="s4-7"><title>Testing distribution of grid orientation</title><p>All tests in this section are circular statistics (<xref ref-type="bibr" rid="bib29">Mardia and Jupp, 1999</xref>) implemented by the MATLAB toolbox <italic>CircStat</italic> (<xref ref-type="bibr" rid="bib6">Berens, 2009</xref>).</p><p>To test whether the grid orientations within an ROI are similar, we calculated the putative grid orientations for each voxel in an ROI using voxel-wise beta estimates of the sine and cosine regressors from GLM1. Then the vector of putative voxel-wise grid orientations is entered into a <italic>V</italic>-test to test whether the distribution of the orientations is clustered. We specifically used the <italic>V</italic>-test instead of Rayleigh’s test because the alternative hypothesis in <italic>V</italic>-test assumed that data have a known mean direction. This is more in line with the hypothesis that neighboring grid cells share similar grid orientation. As the cross-validation procedure yields three estimating sets for each participant, this procedure is repeated for all estimating sets and all participants.</p><p>To test the distribution of grid orientation in the population, for one ROI, we calculated the grid orientation for each participant using the averaged beta estimates of the sine and cosine regressors from GLM1 in this ROI. This vector of grid orientation is entered into Rayleigh’s test. Following the previous study, we assume that the grid orientations across participants would be uniformly distributed.</p></sec><sec id="s4-8"><title>Relationship between temporal signal-to-noise ratio (tSNR) and hexagonal modulation effect</title><p>Following previous literature (<xref ref-type="bibr" rid="bib34">Murphy et al., 2007</xref>; <xref ref-type="bibr" rid="bib53">Triantafyllou et al., 2005</xref>), we calculated the voxel-wise tSNR of a time series, that is, the tSNR for a single voxel in a single run of one participant, as<disp-formula id="equ6"><mml:math id="m6"><mml:mi>t</mml:mi><mml:mi>S</mml:mi><mml:mi>N</mml:mi><mml:mi>R</mml:mi><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mi>μ</mml:mi></mml:mrow><mml:mrow><mml:mi>σ</mml:mi></mml:mrow></mml:mfrac></mml:math></disp-formula></p><p>where µ is the mean activity of the timeseries, and <inline-formula><mml:math id="inf17"><mml:mi>σ</mml:mi></mml:math></inline-formula> is its standard deviation.</p><p>The tSNR of each voxel is calculated as the mean across four runs, and the tSNR for each ROI is calculated as the averaged tSNR of all voxels in the ROI.</p><p>To test the relationship between tSNR and hexagonal modulation effect, we conducted correlation analysis across participants and within each participant. For the across-participant analysis, we tested the correlation between the mean hexagonal modulation effect in an ROI and its mean tSNR across all participants. For the within-participants analysis, for each participant, in an ROI, we calculated the correlation coefficient between voxel-wise hexagonal modulation effect and voxel-wise tSNR. Then, after Fisher <italic>Z</italic> transformation, we tested whether the participant-level correlation coefficients were significantly different from zero using Wilcoxon signed-rank test at group level.</p></sec></sec></body><back><sec sec-type="additional-information" id="s5"><title>Additional information</title><fn-group content-type="competing-interest"><title>Competing interests</title><fn fn-type="COI-statement" id="conf1"><p>No competing interests declared</p></fn></fn-group><fn-group content-type="author-contribution"><title>Author contributions</title><fn fn-type="con" id="con1"><p>Conceptualization, Formal analysis, Investigation, Visualization, Writing - original draft, Writing - review and editing</p></fn><fn fn-type="con" id="con2"><p>Investigation</p></fn><fn fn-type="con" id="con3"><p>Investigation</p></fn><fn fn-type="con" id="con4"><p>Conceptualization</p></fn><fn fn-type="con" id="con5"><p>Conceptualization, Supervision, Funding acquisition, Writing - review and editing</p></fn><fn fn-type="con" id="con6"><p>Conceptualization, Supervision, Funding acquisition, Writing - review and editing</p></fn></fn-group></sec><sec sec-type="supplementary-material" id="s6"><title>Additional files</title><supplementary-material id="mdar"><label>MDAR checklist</label><media xlink:href="elife-89025-mdarchecklist1-v1.docx" mimetype="application" mime-subtype="docx"/></supplementary-material></sec><sec sec-type="data-availability" id="s7"><title>Data availability</title><p>We have published preprocessed smoothed and unsmoothed functional MRI data, the code to run the experiment and the code to run the univariate analysis reported in the main text. Dataset and code are publicly available at <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.57760/sciencedb.08637">https://doi.org/10.57760/sciencedb.08637</ext-link>.</p><p>The following dataset was generated:</p><p><element-citation publication-type="data" specific-use="isSupplementedBy" id="dataset1"><person-group person-group-type="author"><name><surname>Liang</surname><given-names>Z</given-names></name><name><surname>Wu</surname><given-names>S</given-names></name><name><surname>Wu</surname><given-names>J</given-names></name><name><surname>Wang</surname><given-names>W</given-names></name><name><surname>Qin</surname><given-names>S</given-names></name><name><surname>Liu</surname><given-names>C</given-names></name></person-group><year iso-8601-date="2023">2023</year><data-title>Social navigation: distance and grid-like codes support navigation of abstract social space in human brain</data-title><source>Science Data Bank</source><pub-id pub-id-type="doi">10.57760/sciencedb.08637</pub-id></element-citation></p></sec><ack id="ack"><title>Acknowledgements</title><p>We are grateful for the volunteers who participated in this study. We thank Alexandra Constantinescu for providing helpful information regarding the experiment design in their previous study. We thank Kelou Jin for his hard work and help when conducting pilot experiments. We thank Shen Zhang and Huagen Wang for their help in data analysis. This work was supported by the Scientific and Technological Innovation (STl) 2030-Major Projects (2021ZD0200500), the National Natural Science Foundation of China (32130045 and 32271092), the Major Project of National Social Science Foundation (19ZDA363), the Beijing Municipal Science and Technology Commission (Z151100003915122), and the National Program for Support of Top-notch Young Professionals.</p></ack><ref-list><title>References</title><ref id="bib1"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Abdulrahman</surname><given-names>H</given-names></name><name><surname>Henson</surname><given-names>RN</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Effect of trial-to-trial variability on optimal event-related fMRI design: Implications for Beta-series correlation and multi-voxel pattern analysis</article-title><source>NeuroImage</source><volume>125</volume><fpage>756</fpage><lpage>766</lpage><pub-id pub-id-type="doi">10.1016/j.neuroimage.2015.11.009</pub-id><pub-id pub-id-type="pmid">26549299</pub-id></element-citation></ref><ref id="bib2"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Aronov</surname><given-names>D</given-names></name><name><surname>Nevers</surname><given-names>R</given-names></name><name><surname>Tank</surname><given-names>DW</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>Mapping of a non-spatial dimension by the hippocampal-entorhinal circuit</article-title><source>Nature</source><volume>543</volume><fpage>719</fpage><lpage>722</lpage><pub-id pub-id-type="doi">10.1038/nature21692</pub-id><pub-id pub-id-type="pmid">28358077</pub-id></element-citation></ref><ref id="bib3"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bao</surname><given-names>X</given-names></name><name><surname>Gjorgieva</surname><given-names>E</given-names></name><name><surname>Shanahan</surname><given-names>LK</given-names></name><name><surname>Howard</surname><given-names>JD</given-names></name><name><surname>Kahnt</surname><given-names>T</given-names></name><name><surname>Gottfried</surname><given-names>JA</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>Grid-like neural representations support olfactory navigation of a two-dimensional odor space</article-title><source>Neuron</source><volume>102</volume><fpage>1066</fpage><lpage>1075</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2019.03.034</pub-id><pub-id pub-id-type="pmid">31023509</pub-id></element-citation></ref><ref id="bib4"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bellmund</surname><given-names>JL</given-names></name><name><surname>Deuker</surname><given-names>L</given-names></name><name><surname>Navarro Schröder</surname><given-names>T</given-names></name><name><surname>Doeller</surname><given-names>CF</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Grid-cell representations in mental simulation</article-title><source>eLife</source><volume>5</volume><elocation-id>e17089</elocation-id><pub-id pub-id-type="doi">10.7554/eLife.17089</pub-id><pub-id pub-id-type="pmid">27572056</pub-id></element-citation></ref><ref id="bib5"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bellmund</surname><given-names>JLS</given-names></name><name><surname>Gärdenfors</surname><given-names>P</given-names></name><name><surname>Moser</surname><given-names>EI</given-names></name><name><surname>Doeller</surname><given-names>CF</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>Navigating cognition: Spatial codes for human thinking</article-title><source>Science</source><volume>362</volume><elocation-id>eaat6766</elocation-id><pub-id pub-id-type="doi">10.1126/science.aat6766</pub-id><pub-id pub-id-type="pmid">30409861</pub-id></element-citation></ref><ref id="bib6"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Berens</surname><given-names>P</given-names></name></person-group><year iso-8601-date="2009">2009</year><article-title>CircStat: AMATLABToolbox for circular statistics</article-title><source>Journal of Statistical Software</source><volume>31</volume><elocation-id>10</elocation-id><pub-id pub-id-type="doi">10.18637/jss.v031.i10</pub-id></element-citation></ref><ref id="bib7"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Boccara</surname><given-names>CN</given-names></name><name><surname>Nardin</surname><given-names>M</given-names></name><name><surname>Stella</surname><given-names>F</given-names></name><name><surname>O’Neill</surname><given-names>J</given-names></name><name><surname>Csicsvari</surname><given-names>J</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>The entorhinal cognitive map is attracted to goals</article-title><source>Science</source><volume>363</volume><fpage>1443</fpage><lpage>1447</lpage><pub-id pub-id-type="doi">10.1126/science.aav4837</pub-id><pub-id pub-id-type="pmid">30923221</pub-id></element-citation></ref><ref id="bib8"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Boccia</surname><given-names>M</given-names></name><name><surname>Nemmi</surname><given-names>F</given-names></name><name><surname>Guariglia</surname><given-names>C</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>Neuropsychology of environmental navigation in humans: review and meta-analysis of FMRI studies in healthy participants</article-title><source>Neuropsychology Review</source><volume>24</volume><fpage>236</fpage><lpage>251</lpage><pub-id pub-id-type="doi">10.1007/s11065-014-9247-8</pub-id><pub-id pub-id-type="pmid">24488500</pub-id></element-citation></ref><ref id="bib9"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Constantinescu</surname><given-names>AO</given-names></name><name><surname>O’Reilly</surname><given-names>JX</given-names></name><name><surname>Behrens</surname><given-names>TEJ</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Organizing conceptual knowledge in humans with a gridlike code</article-title><source>Science</source><volume>352</volume><fpage>1464</fpage><lpage>1468</lpage><pub-id pub-id-type="doi">10.1126/science.aaf0941</pub-id><pub-id pub-id-type="pmid">27313047</pub-id></element-citation></ref><ref id="bib10"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Cuddy</surname><given-names>AJC</given-names></name></person-group><year iso-8601-date="2008">2008</year><article-title>Warmth and competence as universal dimensions of social perception: the stereotype content model and the BIAS Map</article-title><source>Advances in Experimental Social Psychology</source><volume>01</volume><fpage>61</fpage><lpage>149</lpage><pub-id pub-id-type="doi">10.1016/s0065-2601(07)00002-0</pub-id></element-citation></ref><ref id="bib11"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Cuddy</surname><given-names>AJC</given-names></name><name><surname>Fiske</surname><given-names>ST</given-names></name><name><surname>Kwan</surname><given-names>VSY</given-names></name><name><surname>Glick</surname><given-names>P</given-names></name><name><surname>Demoulin</surname><given-names>S</given-names></name><name><surname>Leyens</surname><given-names>JP</given-names></name><name><surname>Bond</surname><given-names>MH</given-names></name><name><surname>Croizet</surname><given-names>JC</given-names></name><name><surname>Ellemers</surname><given-names>N</given-names></name><name><surname>Sleebos</surname><given-names>E</given-names></name><name><surname>Htun</surname><given-names>TT</given-names></name><name><surname>Kim</surname><given-names>HJ</given-names></name><name><surname>Maio</surname><given-names>G</given-names></name><name><surname>Perry</surname><given-names>J</given-names></name><name><surname>Petkova</surname><given-names>K</given-names></name><name><surname>Todorov</surname><given-names>V</given-names></name><name><surname>Rodríguez-Bailón</surname><given-names>R</given-names></name><name><surname>Morales</surname><given-names>E</given-names></name><name><surname>Moya</surname><given-names>M</given-names></name><name><surname>Palacios</surname><given-names>M</given-names></name><name><surname>Smith</surname><given-names>V</given-names></name><name><surname>Perez</surname><given-names>R</given-names></name><name><surname>Vala</surname><given-names>J</given-names></name><name><surname>Ziegler</surname><given-names>R</given-names></name></person-group><year iso-8601-date="2009">2009</year><article-title>Stereotype content model across cultures: towards universal similarities and some differences</article-title><source>The British Journal of Social Psychology</source><volume>48</volume><fpage>1</fpage><lpage>33</lpage><pub-id pub-id-type="doi">10.1348/014466608X314935</pub-id><pub-id pub-id-type="pmid">19178758</pub-id></element-citation></ref><ref id="bib12"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Derdikman</surname><given-names>D</given-names></name><name><surname>Whitlock</surname><given-names>JR</given-names></name><name><surname>Tsao</surname><given-names>A</given-names></name><name><surname>Fyhn</surname><given-names>M</given-names></name><name><surname>Hafting</surname><given-names>T</given-names></name><name><surname>Moser</surname><given-names>MB</given-names></name><name><surname>Moser</surname><given-names>EI</given-names></name></person-group><year iso-8601-date="2009">2009</year><article-title>Fragmentation of grid cell maps in a multicompartment environment</article-title><source>Nature Neuroscience</source><volume>12</volume><fpage>1325</fpage><lpage>1332</lpage><pub-id pub-id-type="doi">10.1038/nn.2396</pub-id><pub-id pub-id-type="pmid">19749749</pub-id></element-citation></ref><ref id="bib13"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Doeller</surname><given-names>CF</given-names></name><name><surname>Barry</surname><given-names>C</given-names></name><name><surname>Burgess</surname><given-names>N</given-names></name></person-group><year iso-8601-date="2010">2010</year><article-title>Evidence for grid cells in a human memory network</article-title><source>Nature</source><volume>463</volume><fpage>657</fpage><lpage>661</lpage><pub-id pub-id-type="doi">10.1038/nature08704</pub-id><pub-id pub-id-type="pmid">20090680</pub-id></element-citation></ref><ref id="bib14"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Fiske</surname><given-names>ST</given-names></name><name><surname>Cuddy</surname><given-names>AJC</given-names></name><name><surname>Glick</surname><given-names>P</given-names></name></person-group><year iso-8601-date="2007">2007</year><article-title>Universal dimensions of social cognition: warmth and competence</article-title><source>Trends in Cognitive Sciences</source><volume>11</volume><fpage>77</fpage><lpage>83</lpage><pub-id pub-id-type="doi">10.1016/j.tics.2006.11.005</pub-id><pub-id pub-id-type="pmid">17188552</pub-id></element-citation></ref><ref id="bib15"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Greicius</surname><given-names>MD</given-names></name><name><surname>Supekar</surname><given-names>K</given-names></name><name><surname>Menon</surname><given-names>V</given-names></name><name><surname>Dougherty</surname><given-names>RF</given-names></name></person-group><year iso-8601-date="2009">2009</year><article-title>Resting-state functional connectivity reflects structural connectivity in the default mode network</article-title><source>Cerebral Cortex</source><volume>19</volume><fpage>72</fpage><lpage>78</lpage><pub-id pub-id-type="doi">10.1093/cercor/bhn059</pub-id><pub-id pub-id-type="pmid">18403396</pub-id></element-citation></ref><ref id="bib16"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hafting</surname><given-names>T</given-names></name><name><surname>Fyhn</surname><given-names>M</given-names></name><name><surname>Molden</surname><given-names>S</given-names></name><name><surname>Moser</surname><given-names>MB</given-names></name><name><surname>Moser</surname><given-names>EI</given-names></name></person-group><year iso-8601-date="2005">2005</year><article-title>Microstructure of a spatial map in the entorhinal cortex</article-title><source>Nature</source><volume>436</volume><fpage>801</fpage><lpage>806</lpage><pub-id pub-id-type="doi">10.1038/nature03721</pub-id><pub-id pub-id-type="pmid">15965463</pub-id></element-citation></ref><ref id="bib17"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>He</surname><given-names>Q</given-names></name><name><surname>Brown</surname><given-names>TI</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>Environmental barriers disrupt grid-like representations in humans during navigation</article-title><source>Current Biology</source><volume>29</volume><fpage>2718</fpage><lpage>2722</lpage><pub-id pub-id-type="doi">10.1016/j.cub.2019.06.072</pub-id><pub-id pub-id-type="pmid">31378608</pub-id></element-citation></ref><ref id="bib18"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Horner</surname><given-names>AJ</given-names></name><name><surname>Bisby</surname><given-names>JA</given-names></name><name><surname>Zotow</surname><given-names>E</given-names></name><name><surname>Bush</surname><given-names>D</given-names></name><name><surname>Burgess</surname><given-names>N</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Grid-like processing of imagined navigation</article-title><source>Current Biology</source><volume>26</volume><fpage>842</fpage><lpage>847</lpage><pub-id pub-id-type="doi">10.1016/j.cub.2016.01.042</pub-id><pub-id pub-id-type="pmid">26972318</pub-id></element-citation></ref><ref id="bib19"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hugenberg</surname><given-names>K</given-names></name><name><surname>Young</surname><given-names>SG</given-names></name><name><surname>Bernstein</surname><given-names>MJ</given-names></name><name><surname>Sacco</surname><given-names>DF</given-names></name></person-group><year iso-8601-date="2010">2010</year><article-title>The categorization-individuation model: an integrative account of the other-race recognition deficit</article-title><source>Psychological Review</source><volume>117</volume><fpage>1168</fpage><lpage>1187</lpage><pub-id pub-id-type="doi">10.1037/a0020463</pub-id><pub-id pub-id-type="pmid">20822290</pub-id></element-citation></ref><ref id="bib20"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Jacobs</surname><given-names>J</given-names></name><name><surname>Weidemann</surname><given-names>CT</given-names></name><name><surname>Miller</surname><given-names>JF</given-names></name><name><surname>Solway</surname><given-names>A</given-names></name><name><surname>Burke</surname><given-names>JF</given-names></name><name><surname>Wei</surname><given-names>XX</given-names></name><name><surname>Suthana</surname><given-names>N</given-names></name><name><surname>Sperling</surname><given-names>MR</given-names></name><name><surname>Sharan</surname><given-names>AD</given-names></name><name><surname>Fried</surname><given-names>I</given-names></name><name><surname>Kahana</surname><given-names>MJ</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>Direct recordings of grid-like neuronal activity in human spatial navigation</article-title><source>Nature Neuroscience</source><volume>16</volume><fpage>1188</fpage><lpage>1190</lpage><pub-id pub-id-type="doi">10.1038/nn.3466</pub-id><pub-id pub-id-type="pmid">23912946</pub-id></element-citation></ref><ref id="bib21"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kervyn</surname><given-names>N</given-names></name><name><surname>Yzerbyt</surname><given-names>V</given-names></name><name><surname>Judd</surname><given-names>CM</given-names></name></person-group><year iso-8601-date="2010">2010</year><article-title>Compensation between warmth and competence: Antecedents and consequences of a negative relation between the two fundamental dimensions of social perception</article-title><source>European Review of Social Psychology</source><volume>21</volume><fpage>155</fpage><lpage>187</lpage><pub-id pub-id-type="doi">10.1080/13546805.2010.517997</pub-id></element-citation></ref><ref id="bib22"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Khalsa</surname><given-names>S</given-names></name><name><surname>Mayhew</surname><given-names>SD</given-names></name><name><surname>Chechlacz</surname><given-names>M</given-names></name><name><surname>Bagary</surname><given-names>M</given-names></name><name><surname>Bagshaw</surname><given-names>AP</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>The structural and functional connectivity of the posterior cingulate cortex: comparison between deterministic and probabilistic tractography for the investigation of structure-function relationships</article-title><source>NeuroImage</source><volume>102 Pt 1</volume><fpage>118</fpage><lpage>127</lpage><pub-id pub-id-type="doi">10.1016/j.neuroimage.2013.12.022</pub-id><pub-id pub-id-type="pmid">24365673</pub-id></element-citation></ref><ref id="bib23"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Killian</surname><given-names>NJ</given-names></name><name><surname>Jutras</surname><given-names>MJ</given-names></name><name><surname>Buffalo</surname><given-names>EA</given-names></name></person-group><year iso-8601-date="2012">2012</year><article-title>A map of visual space in the primate entorhinal cortex</article-title><source>Nature</source><volume>491</volume><fpage>761</fpage><lpage>764</lpage><pub-id pub-id-type="doi">10.1038/nature11587</pub-id><pub-id pub-id-type="pmid">23103863</pub-id></element-citation></ref><ref id="bib24"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kriegeskorte</surname><given-names>N</given-names></name><name><surname>Storrs</surname><given-names>KR</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Grid cells for conceptual spaces?</article-title><source>Neuron</source><volume>92</volume><fpage>280</fpage><lpage>284</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2016.10.006</pub-id><pub-id pub-id-type="pmid">27764662</pub-id></element-citation></ref><ref id="bib25"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Krupic</surname><given-names>J</given-names></name><name><surname>Bauza</surname><given-names>M</given-names></name><name><surname>Burton</surname><given-names>S</given-names></name><name><surname>Barry</surname><given-names>C</given-names></name><name><surname>O’Keefe</surname><given-names>J</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>Grid cell symmetry is shaped by environmental geometry</article-title><source>Nature</source><volume>518</volume><fpage>232</fpage><lpage>235</lpage><pub-id pub-id-type="doi">10.1038/nature14153</pub-id><pub-id pub-id-type="pmid">25673417</pub-id></element-citation></ref><ref id="bib26"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kunz</surname><given-names>L</given-names></name><name><surname>Schröder</surname><given-names>TN</given-names></name><name><surname>Lee</surname><given-names>H</given-names></name><name><surname>Montag</surname><given-names>C</given-names></name><name><surname>Lachmann</surname><given-names>B</given-names></name><name><surname>Sariyska</surname><given-names>R</given-names></name><name><surname>Reuter</surname><given-names>M</given-names></name><name><surname>Stirnberg</surname><given-names>R</given-names></name><name><surname>Stöcker</surname><given-names>T</given-names></name><name><surname>Messing-Floeter</surname><given-names>PC</given-names></name><name><surname>Fell</surname><given-names>J</given-names></name><name><surname>Doeller</surname><given-names>CF</given-names></name><name><surname>Axmacher</surname><given-names>N</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>Reduced grid-cell-like representations in adults at genetic risk for Alzheimer’s disease</article-title><source>Science</source><volume>350</volume><fpage>430</fpage><lpage>433</lpage><pub-id pub-id-type="doi">10.1126/science.aac8128</pub-id><pub-id pub-id-type="pmid">26494756</pub-id></element-citation></ref><ref id="bib27"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kunz</surname><given-names>L</given-names></name><name><surname>Maidenbaum</surname><given-names>S</given-names></name><name><surname>Chen</surname><given-names>D</given-names></name><name><surname>Wang</surname><given-names>L</given-names></name><name><surname>Jacobs</surname><given-names>J</given-names></name><name><surname>Axmacher</surname><given-names>N</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>Mesoscopic neural representations in spatial navigation</article-title><source>Trends in Cognitive Sciences</source><volume>23</volume><fpage>615</fpage><lpage>630</lpage><pub-id pub-id-type="doi">10.1016/j.tics.2019.04.011</pub-id><pub-id pub-id-type="pmid">31130396</pub-id></element-citation></ref><ref id="bib28"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Maass</surname><given-names>A</given-names></name><name><surname>Berron</surname><given-names>D</given-names></name><name><surname>Libby</surname><given-names>LA</given-names></name><name><surname>Ranganath</surname><given-names>C</given-names></name><name><surname>Düzel</surname><given-names>E</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>Functional subregions of the human entorhinal cortex</article-title><source>eLife</source><volume>4</volume><elocation-id>e06426</elocation-id><pub-id pub-id-type="doi">10.7554/eLife.06426</pub-id><pub-id pub-id-type="pmid">26052749</pub-id></element-citation></ref><ref id="bib29"><element-citation publication-type="web"><person-group person-group-type="author"><name><surname>Mardia</surname><given-names>KV</given-names></name><name><surname>Jupp</surname><given-names>PE</given-names></name></person-group><year iso-8601-date="1999">1999</year><article-title>Directional Statistics</article-title><ext-link ext-link-type="uri" xlink:href="https://onlinelibrary.wiley.com/doi/book/10.1002/9780470316979">https://onlinelibrary.wiley.com/doi/book/10.1002/9780470316979</ext-link><date-in-citation iso-8601-date="1999-01-03">January 3, 1999</date-in-citation></element-citation></ref><ref id="bib30"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>McNaughton</surname><given-names>BL</given-names></name><name><surname>Battaglia</surname><given-names>FP</given-names></name><name><surname>Jensen</surname><given-names>O</given-names></name><name><surname>Moser</surname><given-names>EI</given-names></name><name><surname>Moser</surname><given-names>MB</given-names></name></person-group><year iso-8601-date="2006">2006</year><article-title>Path integration and the neural basis of the “cognitive map.”</article-title><source>Nature Reviews. Neuroscience</source><volume>7</volume><fpage>663</fpage><lpage>678</lpage><pub-id pub-id-type="doi">10.1038/nrn1932</pub-id><pub-id pub-id-type="pmid">16858394</pub-id></element-citation></ref><ref id="bib31"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>McPherson</surname><given-names>M</given-names></name><name><surname>Smith-Lovin</surname><given-names>L</given-names></name><name><surname>Cook</surname><given-names>JM</given-names></name></person-group><year iso-8601-date="2001">2001</year><article-title>Birds of a feather: homophily in social networks</article-title><source>Annual Review of Sociology</source><volume>27</volume><fpage>415</fpage><lpage>444</lpage><pub-id pub-id-type="doi">10.1146/annurev.soc.27.1.415</pub-id></element-citation></ref><ref id="bib32"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Moser</surname><given-names>EI</given-names></name><name><surname>Moser</surname><given-names>MB</given-names></name></person-group><year iso-8601-date="2008">2008</year><article-title>A metric for space</article-title><source>Hippocampus</source><volume>18</volume><fpage>1142</fpage><lpage>1156</lpage><pub-id pub-id-type="doi">10.1002/hipo.20483</pub-id><pub-id pub-id-type="pmid">19021254</pub-id></element-citation></ref><ref id="bib33"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Mumford</surname><given-names>JA</given-names></name><name><surname>Turner</surname><given-names>BO</given-names></name><name><surname>Ashby</surname><given-names>FG</given-names></name><name><surname>Poldrack</surname><given-names>RA</given-names></name></person-group><year iso-8601-date="2012">2012</year><article-title>Deconvolving BOLD activation in event-related designs for multivoxel pattern classification analyses</article-title><source>NeuroImage</source><volume>59</volume><fpage>2636</fpage><lpage>2643</lpage><pub-id pub-id-type="doi">10.1016/j.neuroimage.2011.08.076</pub-id><pub-id pub-id-type="pmid">21924359</pub-id></element-citation></ref><ref id="bib34"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Murphy</surname><given-names>K</given-names></name><name><surname>Bodurka</surname><given-names>J</given-names></name><name><surname>Bandettini</surname><given-names>PA</given-names></name></person-group><year iso-8601-date="2007">2007</year><article-title>How long to scan? The relationship between fMRI temporal signal to noise ratio and necessary scan duration</article-title><source>NeuroImage</source><volume>34</volume><fpage>565</fpage><lpage>574</lpage><pub-id pub-id-type="doi">10.1016/j.neuroimage.2006.09.032</pub-id><pub-id pub-id-type="pmid">17126038</pub-id></element-citation></ref><ref id="bib35"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Nau</surname><given-names>M</given-names></name><name><surname>Navarro Schröder</surname><given-names>T</given-names></name><name><surname>Bellmund</surname><given-names>JLS</given-names></name><name><surname>Doeller</surname><given-names>CF</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>Hexadirectional coding of visual space in human entorhinal cortex</article-title><source>Nature Neuroscience</source><volume>21</volume><fpage>188</fpage><lpage>190</lpage><pub-id pub-id-type="doi">10.1038/s41593-017-0050-8</pub-id><pub-id pub-id-type="pmid">29311746</pub-id></element-citation></ref><ref id="bib36"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Navarro Schröder</surname><given-names>T</given-names></name><name><surname>Haak</surname><given-names>KV</given-names></name><name><surname>Zaragoza Jimenez</surname><given-names>NI</given-names></name><name><surname>Beckmann</surname><given-names>CF</given-names></name><name><surname>Doeller</surname><given-names>CF</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>Functional topography of the human entorhinal cortex</article-title><source>eLife</source><volume>4</volume><elocation-id>e06738</elocation-id><pub-id pub-id-type="doi">10.7554/eLife.06738</pub-id><pub-id pub-id-type="pmid">26052748</pub-id></element-citation></ref><ref id="bib37"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Oane</surname><given-names>I</given-names></name><name><surname>Barborica</surname><given-names>A</given-names></name><name><surname>Chetan</surname><given-names>F</given-names></name><name><surname>Donos</surname><given-names>C</given-names></name><name><surname>Maliia</surname><given-names>MD</given-names></name><name><surname>Arbune</surname><given-names>AA</given-names></name><name><surname>Daneasa</surname><given-names>A</given-names></name><name><surname>Pistol</surname><given-names>C</given-names></name><name><surname>Nica</surname><given-names>AE</given-names></name><name><surname>Bajenaru</surname><given-names>OA</given-names></name><name><surname>Mindruta</surname><given-names>I</given-names></name></person-group><year iso-8601-date="2020">2020</year><article-title>Cingulate cortex function and multi-modal connectivity mapped using intracranial stimulation</article-title><source>NeuroImage</source><volume>220</volume><elocation-id>117059</elocation-id><pub-id pub-id-type="doi">10.1016/j.neuroimage.2020.117059</pub-id><pub-id pub-id-type="pmid">32562780</pub-id></element-citation></ref><ref id="bib38"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Oosterhof</surname><given-names>NN</given-names></name><name><surname>Connolly</surname><given-names>AC</given-names></name><name><surname>Haxby</surname><given-names>JV</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>CoSMoMVPA: multi-modal multivariate pattern analysis of neuroimaging data in Matlab/GNU Octave</article-title><source>Frontiers in Neuroinformatics</source><volume>10</volume><elocation-id>27</elocation-id><pub-id pub-id-type="doi">10.3389/fninf.2016.00027</pub-id><pub-id pub-id-type="pmid">27499741</pub-id></element-citation></ref><ref id="bib39"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ostrom</surname><given-names>TM</given-names></name><name><surname>Carpenter</surname><given-names>SL</given-names></name><name><surname>Sedikides</surname><given-names>C</given-names></name><name><surname>Li</surname><given-names>F</given-names></name></person-group><year iso-8601-date="1993">1993</year><article-title>Differential processing of in-group and out-group information</article-title><source>Journal of Personality and Social Psychology</source><volume>64</volume><fpage>21</fpage><lpage>34</lpage><pub-id pub-id-type="doi">10.1037/0022-3514.64.1.21</pub-id></element-citation></ref><ref id="bib40"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Park</surname><given-names>SA</given-names></name><name><surname>Miller</surname><given-names>DS</given-names></name><name><surname>Nili</surname><given-names>H</given-names></name><name><surname>Ranganath</surname><given-names>C</given-names></name><name><surname>Boorman</surname><given-names>ED</given-names></name></person-group><year iso-8601-date="2020">2020</year><article-title>Map making: constructing, combining, and inferring on abstract cognitive maps</article-title><source>Neuron</source><volume>107</volume><fpage>1226</fpage><lpage>1238</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2020.06.030</pub-id><pub-id pub-id-type="pmid">32702288</pub-id></element-citation></ref><ref id="bib41"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Park</surname><given-names>SA</given-names></name><name><surname>Miller</surname><given-names>DS</given-names></name><name><surname>Boorman</surname><given-names>ED</given-names></name></person-group><year iso-8601-date="2021">2021</year><article-title>Inferences on a multidimensional social hierarchy use a grid-like code</article-title><source>Nature Neuroscience</source><volume>24</volume><fpage>1292</fpage><lpage>1301</lpage><pub-id pub-id-type="doi">10.1038/s41593-021-00916-3</pub-id><pub-id pub-id-type="pmid">34465915</pub-id></element-citation></ref><ref id="bib42"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Patai</surname><given-names>EZ</given-names></name><name><surname>Javadi</surname><given-names>AH</given-names></name><name><surname>Ozubko</surname><given-names>JD</given-names></name><name><surname>O’Callaghan</surname><given-names>A</given-names></name><name><surname>Ji</surname><given-names>S</given-names></name><name><surname>Robin</surname><given-names>J</given-names></name><name><surname>Grady</surname><given-names>C</given-names></name><name><surname>Winocur</surname><given-names>G</given-names></name><name><surname>Rosenbaum</surname><given-names>RS</given-names></name><name><surname>Moscovitch</surname><given-names>M</given-names></name><name><surname>Spiers</surname><given-names>HJ</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>Hippocampal and retrosplenial goal distance coding after long-term consolidation of a real-world environment</article-title><source>Cerebral Cortex</source><volume>29</volume><fpage>2748</fpage><lpage>2758</lpage><pub-id pub-id-type="doi">10.1093/cercor/bhz044</pub-id><pub-id pub-id-type="pmid">30916744</pub-id></element-citation></ref><ref id="bib43"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Peng</surname><given-names>L</given-names></name><name><surname>Zeng</surname><given-names>LL</given-names></name><name><surname>Liu</surname><given-names>Q</given-names></name><name><surname>Wang</surname><given-names>L</given-names></name><name><surname>Qin</surname><given-names>J</given-names></name><name><surname>Xu</surname><given-names>H</given-names></name><name><surname>Shen</surname><given-names>H</given-names></name><name><surname>Li</surname><given-names>H</given-names></name><name><surname>Hu</surname><given-names>D</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>Functional connectivity changes in the entorhinal cortex of taxi drivers</article-title><source>Brain and Behavior</source><volume>8</volume><elocation-id>e01022</elocation-id><pub-id pub-id-type="doi">10.1002/brb3.1022</pub-id><pub-id pub-id-type="pmid">30112812</pub-id></element-citation></ref><ref id="bib44"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Potts</surname><given-names>GR</given-names></name></person-group><year iso-8601-date="1974">1974</year><article-title>Storing and retrieving information about ordered relationships</article-title><source>Journal of Experimental Psychology</source><volume>103</volume><fpage>431</fpage><lpage>439</lpage><pub-id pub-id-type="doi">10.1037/h0037408</pub-id></element-citation></ref><ref id="bib45"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Qiu</surname><given-names>Y</given-names></name><name><surname>Wu</surname><given-names>Y</given-names></name><name><surname>Liu</surname><given-names>R</given-names></name><name><surname>Wang</surname><given-names>J</given-names></name><name><surname>Huang</surname><given-names>H</given-names></name><name><surname>Huang</surname><given-names>R</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>Representation of human spatial navigation responding to input spatial information and output navigational strategies: An ALE meta-analysis</article-title><source>Neuroscience and Biobehavioral Reviews</source><volume>103</volume><fpage>60</fpage><lpage>72</lpage><pub-id pub-id-type="doi">10.1016/j.neubiorev.2019.06.012</pub-id><pub-id pub-id-type="pmid">31201830</pub-id></element-citation></ref><ref id="bib46"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Sargolini</surname><given-names>F</given-names></name><name><surname>Fyhn</surname><given-names>M</given-names></name><name><surname>Hafting</surname><given-names>T</given-names></name><name><surname>McNaughton</surname><given-names>BL</given-names></name><name><surname>Witter</surname><given-names>MP</given-names></name><name><surname>Moser</surname><given-names>MB</given-names></name><name><surname>Moser</surname><given-names>EI</given-names></name></person-group><year iso-8601-date="2006">2006</year><article-title>Conjunctive representation of position, direction, and velocity in entorhinal cortex</article-title><source>Science</source><volume>312</volume><fpage>758</fpage><lpage>762</lpage><pub-id pub-id-type="doi">10.1126/science.1125572</pub-id><pub-id pub-id-type="pmid">16675704</pub-id></element-citation></ref><ref id="bib47"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Schafer</surname><given-names>M</given-names></name><name><surname>Schiller</surname><given-names>D</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>Navigating Social Space</article-title><source>Neuron</source><volume>100</volume><fpage>476</fpage><lpage>489</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2018.10.006</pub-id><pub-id pub-id-type="pmid">30359610</pub-id></element-citation></ref><ref id="bib48"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Son</surname><given-names>JY</given-names></name><name><surname>Bhandari</surname><given-names>A</given-names></name><name><surname>FeldmanHall</surname><given-names>O</given-names></name></person-group><year iso-8601-date="2021">2021</year><article-title>Cognitive maps of social features enable flexible inference in social networks</article-title><source>PNAS</source><volume>118</volume><elocation-id>e2021699118</elocation-id><pub-id pub-id-type="doi">10.1073/pnas.2021699118</pub-id><pub-id pub-id-type="pmid">34518372</pub-id></element-citation></ref><ref id="bib49"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Squire</surname><given-names>LR</given-names></name><name><surname>Zola</surname><given-names>SM</given-names></name></person-group><year iso-8601-date="1996">1996</year><article-title>Structure and function of declarative and nondeclarative memory systems</article-title><source>PNAS</source><volume>93</volume><fpage>13515</fpage><lpage>13522</lpage><pub-id pub-id-type="doi">10.1073/pnas.93.24.13515</pub-id><pub-id pub-id-type="pmid">8942965</pub-id></element-citation></ref><ref id="bib50"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Stolier</surname><given-names>RM</given-names></name><name><surname>Hehman</surname><given-names>E</given-names></name><name><surname>Freeman</surname><given-names>JB</given-names></name></person-group><year iso-8601-date="2020">2020</year><article-title>Trait knowledge forms a common structure across social cognition</article-title><source>Nature Human Behaviour</source><volume>4</volume><fpage>361</fpage><lpage>371</lpage><pub-id pub-id-type="doi">10.1038/s41562-019-0800-6</pub-id><pub-id pub-id-type="pmid">31932689</pub-id></element-citation></ref><ref id="bib51"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Tavares</surname><given-names>RM</given-names></name><name><surname>Mendelsohn</surname><given-names>A</given-names></name><name><surname>Grossman</surname><given-names>Y</given-names></name><name><surname>Williams</surname><given-names>CH</given-names></name><name><surname>Shapiro</surname><given-names>M</given-names></name><name><surname>Trope</surname><given-names>Y</given-names></name><name><surname>Schiller</surname><given-names>D</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>A map for social navigation in the human brain</article-title><source>Neuron</source><volume>87</volume><fpage>231</fpage><lpage>243</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2015.06.011</pub-id><pub-id pub-id-type="pmid">26139376</pub-id></element-citation></ref><ref id="bib52"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Tolman</surname><given-names>EC</given-names></name></person-group><year iso-8601-date="1948">1948</year><article-title>Cognitive maps in rats and men</article-title><source>Psychological Review</source><volume>55</volume><fpage>189</fpage><lpage>208</lpage><pub-id pub-id-type="doi">10.1037/h0061626</pub-id><pub-id pub-id-type="pmid">18870876</pub-id></element-citation></ref><ref id="bib53"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Triantafyllou</surname><given-names>C</given-names></name><name><surname>Hoge</surname><given-names>RD</given-names></name><name><surname>Krueger</surname><given-names>G</given-names></name><name><surname>Wiggins</surname><given-names>CJ</given-names></name><name><surname>Potthast</surname><given-names>A</given-names></name><name><surname>Wiggins</surname><given-names>GC</given-names></name><name><surname>Wald</surname><given-names>LL</given-names></name></person-group><year iso-8601-date="2005">2005</year><article-title>Comparison of physiological noise at 1.5 T, 3 T and 7 T and optimization of fMRI acquisition parameters</article-title><source>NeuroImage</source><volume>26</volume><fpage>243</fpage><lpage>250</lpage><pub-id pub-id-type="doi">10.1016/j.neuroimage.2005.01.007</pub-id><pub-id pub-id-type="pmid">15862224</pub-id></element-citation></ref><ref id="bib54"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Viganò</surname><given-names>S</given-names></name><name><surname>Piazza</surname><given-names>M</given-names></name></person-group><year iso-8601-date="2020">2020</year><article-title>Distance and direction codes underlie navigation of a novel semantic space in the human brain</article-title><source>The Journal of Neuroscience</source><volume>40</volume><fpage>2727</fpage><lpage>2736</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.1849-19.2020</pub-id><pub-id pub-id-type="pmid">32060171</pub-id></element-citation></ref><ref id="bib55"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Viganò</surname><given-names>S</given-names></name><name><surname>Rubino</surname><given-names>V</given-names></name><name><surname>Soccio</surname><given-names>AD</given-names></name><name><surname>Buiatti</surname><given-names>M</given-names></name><name><surname>Piazza</surname><given-names>M</given-names></name></person-group><year iso-8601-date="2021">2021</year><article-title>Grid-like and distance codes for representing word meaning in the human brain</article-title><source>NeuroImage</source><volume>232</volume><elocation-id>117876</elocation-id><pub-id pub-id-type="doi">10.1016/j.neuroimage.2021.117876</pub-id><pub-id pub-id-type="pmid">33636346</pub-id></element-citation></ref><ref id="bib56"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wikenheiser</surname><given-names>AM</given-names></name><name><surname>Gardner</surname><given-names>MPH</given-names></name><name><surname>Mueller</surname><given-names>LE</given-names></name><name><surname>Schoenbaum</surname><given-names>G</given-names></name></person-group><year iso-8601-date="2021">2021</year><article-title>Spatial representations in rat orbitofrontal cortex</article-title><source>The Journal of Neuroscience</source><volume>41</volume><fpage>6933</fpage><lpage>6945</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.0830-21.2021</pub-id><pub-id pub-id-type="pmid">34210776</pub-id></element-citation></ref><ref id="bib57"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Yuan</surname><given-names>C</given-names></name><name><surname>Zhu</surname><given-names>H</given-names></name><name><surname>Ren</surname><given-names>Z</given-names></name><name><surname>Yuan</surname><given-names>M</given-names></name><name><surname>Gao</surname><given-names>M</given-names></name><name><surname>Zhang</surname><given-names>Y</given-names></name><name><surname>Li</surname><given-names>Y</given-names></name><name><surname>Meng</surname><given-names>Y</given-names></name><name><surname>Gong</surname><given-names>Q</given-names></name><name><surname>Lui</surname><given-names>S</given-names></name><name><surname>Qiu</surname><given-names>C</given-names></name><name><surname>Zhang</surname><given-names>W</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>Precuneus-related regional and network functional deficits in social anxiety disorder: a resting-state functional MRI study</article-title><source>Comprehensive Psychiatry</source><volume>82</volume><fpage>22</fpage><lpage>29</lpage><pub-id pub-id-type="doi">10.1016/j.comppsych.2017.12.002</pub-id><pub-id pub-id-type="pmid">29367059</pub-id></element-citation></ref></ref-list></back><sub-article article-type="editor-report" id="sa0"><front-stub><article-id pub-id-type="doi">10.7554/eLife.89025.4.sa0</article-id><title-group><article-title>eLife assessment</article-title></title-group><contrib-group><contrib contrib-type="author"><name><surname>de Lange</surname><given-names>Floris P</given-names></name><role specific-use="editor">Reviewing Editor</role><aff><institution>Donders Institute for Brain, Cognition and Behaviour</institution><country>Netherlands</country></aff></contrib></contrib-group><kwd-group kwd-group-type="evidence-strength"><kwd>Solid</kwd></kwd-group><kwd-group kwd-group-type="claim-importance"><kwd>Useful</kwd></kwd-group></front-stub><body><p>This study tackles a significant question: Does the brain apply spatial navigation systems to evaluate decision options in conceptual social spaces? The investigation is <bold>useful</bold> as it seeks to address this intriguing hypothesis. The findings offer partial support: a <bold>solid</bold> analysis revealed characteristic grid-like patterns associated with decision-making directions. However, it remains uncertain whether these effects are genuinely due to navigating a conceptual social space or potentially confounded by changes in visual stimuli. The experimental design may not be capable of definitively resolving this issue.</p></body></sub-article><sub-article article-type="referee-report" id="sa1"><front-stub><article-id pub-id-type="doi">10.7554/eLife.89025.4.sa1</article-id><title-group><article-title>Reviewer #1 (Public Review):</article-title></title-group><contrib-group><contrib contrib-type="author"><anonymous/><role specific-use="referee">Reviewer</role></contrib></contrib-group></front-stub><body><p>The study offers intriguing insights, yet interpretations warrant caution, as the authors themselves acknowledged in their discussion of limitations.</p><p>The observed grid-like neural activity might not signify navigating a social landscape but rather a sensory feature space. The study's design had participants associate each face with a pair of bar lengths, with the purported 'navigation' being merely a response to the morphing of bar graph images. Crucially, the task did not necessitate any social cognitive processing to estimate grid-like activity. When making social decisions in a separate task, it is unclear whether participants were actually traversing a social space mentally or simply recalling the bar graphs linked to each face to calculate decision values. Notably, during the trust game, competence and trustworthiness did not equally influence decision-making (as illustrated by Equation 1), implying the possibility that the space represented may be more perceptual than social in nature.</p><p>The existence of a universal brain representation for faces within a social context is still debatable. Participants were not required to form a cognitive map of the six faces based on social traits; they could simply remember each face's trait values. While the study suggests that reaction times correlated with the perceived social distances between faces hint at the creation of internal representations, this phenomenon could occur without a true cognitive map of the face relationships. To convincingly argue for such internal representations in the brain, additional multivariate pattern analysis would be necessary to demonstrate that these are not merely the result of perceptual differences in the bar graphs associated with each face.</p></body></sub-article><sub-article article-type="referee-report" id="sa2"><front-stub><article-id pub-id-type="doi">10.7554/eLife.89025.4.sa2</article-id><title-group><article-title>Reviewer #3 (Public Review):</article-title></title-group><contrib-group><contrib contrib-type="author"><anonymous/><role specific-use="referee">Reviewer</role></contrib></contrib-group></front-stub><body><p>Liang and colleagues set out to test whether the human brain uses distance and grid-like codes in social knowledge using a design where participants had to navigate in a two-dimensional social space based on competence and warmth during an fMRI scan. They showed that participants were able to navigate the social space and found distance-based codes as well as grid-like codes in various brain regions, and the grid-like code correlated with behavior (reaction times).</p><p>On the whole, the experiment is designed appropriately for testing for distant-based and grid-like codes, and is relatively well powered for this type of study, with a large amount of behavioral training per participant. They revealed that a number of brain regions correlated positively or negatively with distance in the social space, and found grid-like codes in the frontal polar cortex and posterior medial entorhinal cortex, the latter in line with prior findings on grid-like activity in entorhinal cortex. The current paper seems quite similar conceptually and in design to previous work, most notably Park et al., 2021, Nature Neuroscience.</p><p>(1) The authors claim that this study provides evidence that humans use a spatial / grid code for abstract knowledge like social knowledge.</p><p>This data does specifically not add anything new to this argument. As with almost all studies that test for a grid code in a similar &quot;conceptual&quot; space (not only the current study), the problem is that, when the space is not a uniform, square/circular space, and 2-dimensional then there is no reason the code will be perfectly grid like, i.e., show six-fold symmetry. In real world scenarios of social space (as well as navigation, semantic concepts), it must be higher dimensional - or at least more than two dimensional. It is unclear if this generalizes to larger spaces where not all part of the space is relevant. Modelling work from Tim Behrens' lab (e.g., Whittington et al., 2020) and Bradley Love's lab (e.g., Mok &amp; Love, 2019) have shown/argued this to be the case. In experimental work, like in mazes from the Mosers' labs (e.g., Derdikman et al., 2009), or trapezoid environments from the O'Keefe lab (Krupic et al., 2015), there are distortions in mEC cells, and would not pass as grid cells in terms of the six-fold symmetry criterion.</p><p>After revision, the authors now discuss some of this and the limitations and notes that future work is required to address the problem.</p></body></sub-article><sub-article article-type="author-comment" id="sa3"><front-stub><article-id pub-id-type="doi">10.7554/eLife.89025.4.sa3</article-id><title-group><article-title>Author response</article-title></title-group><contrib-group><contrib contrib-type="author"><name><surname>Liang</surname><given-names>Zilu</given-names></name><role specific-use="author">Author</role><aff><institution>Beijing Normal University</institution><addr-line><named-content content-type="city">Beijing</named-content></addr-line><country>China</country></aff></contrib><contrib contrib-type="author"><name><surname>Wu</surname><given-names>Simeng</given-names></name><role specific-use="author">Author</role><aff><institution>State Key Laboratory of Cognitive Neuroscience and Learning &amp; IDG/McGovern Institute for Brain Research, Beijing Normal University</institution><addr-line><named-content content-type="city">Beijing</named-content></addr-line><country>China</country></aff></contrib><contrib contrib-type="author"><name><surname>Wu</surname><given-names>Jie</given-names></name><role specific-use="author">Author</role><aff><institution>Beijing Normal University</institution><addr-line><named-content content-type="city">Beijing</named-content></addr-line><country>China</country></aff></contrib><contrib contrib-type="author"><name><surname>Wang</surname><given-names>Wen-Xu</given-names></name><role specific-use="author">Author</role><aff><institution>Beijing Normal University</institution><addr-line><named-content content-type="city">Beijing</named-content></addr-line><country>China</country></aff></contrib><contrib contrib-type="author"><name><surname>Qin</surname><given-names>Shaozheng</given-names></name><role specific-use="author">Author</role><aff><institution>Beijing Normal University</institution><addr-line><named-content content-type="city">Beijing</named-content></addr-line><country>China</country></aff></contrib><contrib contrib-type="author"><name><surname>Liu</surname><given-names>Chao</given-names></name><role specific-use="author">Author</role><aff><institution>Beijing Normal University</institution><addr-line><named-content content-type="city">Beijing</named-content></addr-line><country>China</country></aff></contrib></contrib-group></front-stub><body><p>The following is the authors’ response to the previous reviews.</p><p>We would like to first thank the Editor as well as the three reviewers for their enthusiasm and conducting another careful evaluation of our manuscript. We appreciate their thoughtful and constructive comments and suggestions. Some concerns regarding experimental design, data analysis, and over-interpretation of our findings still remains unresolved after the initial revision. Here we endeavored to address these remaining concerns through further refinement of our writing, and inclusion of these concerns in the discussion session. We hope our response can better explain the rationale of our experimental design and data interpretation. In addition, we also acknowledge the limitations of our present study, so that it will benefit future investigations into this topic. Our detail responses are provided below.</p><disp-quote content-type="editor-comment"><p><bold>Reviewer #1 (Public Review):</bold></p><p>This study examines whether the human brain uses a hexagonal grid-like representation to navigate in a non-spatial space constructed by competence and trustworthiness. To test this, the authors asked human participants to learn the levels of competence and trustworthiness for six faces by associating them with specific lengths of bar graphs that indicate their levels in each trait. After learning, participants were asked to extrapolate the location from the partially observed morphing bar graphs. Using fMRI, the authors identified brain areas where activity is modulated by the angles of morphing trajectories in six-fold symmetry. The strength of this paper lies in the question it attempts to address. Specifically, the question of whether and how the human brain uses grid-like representations not only for spatial navigation but also for navigating abstract concepts, such as social space, and guiding everyday decision-making. This question is of emerging importance.</p><p>I acknowledge the authors' efforts to address the comments received. However, my concerns persist:</p></disp-quote><p>Thanks very much again for the re-evaluation and comments. Please find our revision plans to each comment below.</p><disp-quote content-type="editor-comment"><p>(1) The authors contend that shorter reaction times correlated with increased distances between individuals in social space imply that participants construct and utilize two-dimensional representations. This method is adapted from a previous study by Park et al. Yet, there is a fundamental distinction between the two studies. In the prior work, participants learned relationships between adjacent individuals, receiving feedback on their decisions, akin to learning spatial locations during navigation. This setup leads to two different predictions: If participants rely on memory to infer relationships, recalling more pairs would be necessary for distant individuals than for closer ones. Conversely, if participants can directly gauge distances using a cognitive map, they would estimate distances between far individuals as quickly as for closer ones. Consequently, as the authors suggest, reaction times ought to decrease with increasing decision value, which, in this context, corresponds to distances. However, the current study allowed participants to compare all possible pairs without restricting learning experiences, rendering the application of the same methodology for testing two-dimensional representations inappropriate. In this study, the results could be interpreted as participants not forming and utilizing two-dimensional representations.</p></disp-quote><p>We apologize for not being clear enough about our task design, we have made relevant changes in the methodology section in the manuscript to make it clearer. The reviewer’s concern is that participants learned about all the pairs in the comparison task which makes the distance effect invalid. We would like to clarify that during all the memory test tasks (the comparison task, the collect task and the recall task outside and inside scanner), participants never received feedback on whether their responses were correct or not. Therefore, the comparison task in our study is similar to the previous study by Park et al. (2021). Participants do not have access to correct responses for all possible pairs of comparison prior to or during this task, they would need to make inference based on memory retrieval.</p><disp-quote content-type="editor-comment"><p>(2) The confounding of visual features with the value of social decision-making complicates the interpretation of this study's results. It remains unclear whether the observed grid-like effects are due to visual features or are genuinely indicative of value-based decision-making, as argued by the authors. Contrary to the authors' argument, this issue was not present in the previous study (Constantinescu et al.). In that study, participants associated specific stimuli with the identities of hidden items, but these stimuli were not linked to decision-making values (i.e., no image was considered superior to another). The current study's paradigm is more akin to that of Bao et al., which the authors mention in the context of RSA analysis. Indeed, Bao et al. controlled the length of the bars specifically to address the problem highlighted here. Regrettably, in the current paradigm, this conflation remains inseparable.</p></disp-quote><p>We’d like to thank the reviewer for facilitating the discussion on the question of ‘social space’ vs. ‘sensory space’. The task in scanner did not require value-based decision making. It is akin to both the Bao et al. (2019) study and Constantinescu et al. (2016) study in a sense that all three tasks are trying to ask participants to imagine moving along a trajectory in an abstract, non-physical space and the trajectory is grounded in sensory cue. Participants were trained to associate the sensory cue with abstract (social/nonsocial) concepts. We think that the paradigm is a relatively faithful replication of the study by Constantinescu et al. Nonetheless, we agreed that a design similar to Bao et al. (2019) which controls for sensory confounds would be more ideal to address this concern, or adopting a value-based decision-making task in the scanner similar to that by Park et al. (2021), and we have included this limitation in the discussion section.</p><disp-quote content-type="editor-comment"><p>(3) While the authors have responded to comments in the public review, my concerns noted in the Recommendation section remain unaddressed. As indicated in my recommendations, there are aspects of the authors' methodology and results that I find difficult to comprehend. Resolving these issues is imperative to facilitate an appropriate review in subsequent stages.</p><p>Considering that the issues raised in the previous comments remain unresolved, I have retained my earlier comments below for review.</p></disp-quote><p>We apologize for not addressing the recommendations properly, please find detailed our response and plans for revision.</p><disp-quote content-type="editor-comment"><p>I have some comments. I hope that these can help.</p><p>(1) While the explanation of Fig.4A-C is lacking in both the main text and figure legend, I am not sure if I understand this finding correctly. Did the authors find the effects of hexagonal modulation in the medial temporal gyrus and lingual gyrus correlate with the individual differences in the extent to which their reaction times were associated with the distances between faces when choosing a better collaborator? If so, I am not sure what argument the authors try to draw from these findings. Do the authors argue that these brain areas show hexagonal modulation, which was not supported in the previous analysis (Fig.3)? What is the level of correlation between these behavioral measures and the grid consistency effects in the vmPFC and EC, where the authors found actual grid-like activity? How do the authors interpret this finding? More importantly, how does this finding associate with other findings and the argument of the study?</p></disp-quote><p>We apologize for not being clear enough in the manuscript and we will improve the clarity in our revision. This exploratory analysis reported in Figure 4 aims to use whole-brain analysis to examine: (1) if there is any correlation between the strength of grid-like representation of social value map and behavioral indicators of map-like representation; and (2) if there are any correlation between the strength of grid-like representation of this social value map and participants’ social trait.</p><p>To be more specific, for the behavioral indicator, we used the distance effect in the reaction time of the comparison task outside the scanner. We interpreted stronger distance effect as a behavioral index of having better internal map-like representation. We interpreted stronger grid consistency effect as a neural index of better representation of the 2D social space. Therefore, we’d like to see if there exists correlation between behavioral and neural indices of map-like representation.</p><p>To achieve this goal, behavioral indicators are entered as covariates in second-level analysis of the GLM testing grid consistency effect (GLM2). Figure3 showed results from GLM2 without the covariates. Figure4 showed results of clusters whose neural indices of map-like representation covaried with that from behavior and survived multiple-comparison correction. Indeed, in these regions, the grid consistency effect was not significant at group level (so not shown in Figure 3). We tried to interpret this finding in our discussion (line 374-289 for temporal lobe correlation, line 395-404 for precuneus correlation).</p><p>Finally, we would like to point out that including the covariates in GLM2 did not change results in Figure3, the clusters in Figure3 still survives correction. Meanwhile, these clusters in Figure 3 did not show correlation with behavioral indicators of map-like representation.</p><fig id="sa3fig1" position="float"><label>Author response image 1.</label><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-89025-sa3-fig1-v1.tif"/></fig><disp-quote content-type="editor-comment"><p>(2) There are no behavioral results provided. How accurately did participants perform each of the tasks? How are the effects of grid consistency associated with the level of accuracy in the map test?</p><p>Why did participants perform the recall task again outside the scanner?</p></disp-quote><p>We will endeavor to improve signposting the corresponding figures in the main text. For the behavioral results, we reported the stats in section “Participants construct social value map after associative learning of avatars and corresponding characteristics” in the main text, and the plots are shown in Figure 1. Particularly, figure 1F showed accuracy of tasks in training, as well as the recall task in the scanner. For the correlation, we did not find significant correlation between behavioural accuracy and grid consistency effect. We will make it clearer in the result section.</p><disp-quote content-type="editor-comment"><p>(3) The methods did not explain how the grid orientation was estimated and what the regressors were in GLM2. I don't think equations 2 and 3 are quite right.</p></disp-quote><p>For the grid orientation estimation method, we provided detailed description in the Supplementary methods 2.2.2. We will add links to this section in the main text.</p><p>Equation 2 and 3 describes how the parametric regressors entered into GLM2 were formed and provided prerequisites on calculation of grid orientations. Equation 2 was the results of directly applying the angle addition and subtraction theorems so they should be correct. We will try to make the rationale clearer in the supplementary text.</p><disp-quote content-type="editor-comment"><p>(4) With the increase in navigation distances, more grid cells would activate. Therefore, in theory, the activity in the entorhinal cortex should increase with the Euclidean distances, which has not been found here. I wonder if there was enough variability in the Euclidean distances that can be captured by neural correlates. This would require including the distributions of Euclidean distances according to their trajectory angles. Regarding how Fig.1E is generated, I don't understand what this heat map indicates. Additionally, it needs to be confirmed if the grid effects remain while controlling for the Euclidean distances of navigation trajectories.</p></disp-quote><p>We did not specifically control for the trajectory length, we only controlled for the distribution of trajectory to be uniform. We have included a figure of the distribution of Euclidean distances in Figure S9 and the distribution of trajectory direction in Figure S8.</p><fig id="sa3fig2" position="float"><label>Author response image 2.</label><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-89025-sa3-fig2-v1.tif"/></fig><p>As for Figure 1E, we aim to reproduce the findings from Figure 1F in Constantinescu et al. (2016) where they showed that participants progressively refined the locations of the outcomes through training. We divided the space into 15×15 subregions and computed the amount of time spent in each subregion and plotted Figure 1E. Brighter color in Figure 1E indicate greater amount of time spent in the corresponding subregion. Note that all these timing indices were computed as a percentage of the total time spent in the explore task in a given session. If participants were well-acquainted with the space and avatars, they would spend more time at the avatar (brighter color in avatar locations) in the review session compared to the learning session.</p><p>As for the effect of distances on grid-like representation, we did not include the distance as a parametric modulator in grid consistency effect GLM (GLM2) due to insufficient trials in each bin (6-8 trials). But there is side evidence that could potentially rule out this confound. In the distance representation analysis, we did not find distance representation in any of the clusters that have significant grid-like representation (regions in Figure 2).</p><disp-quote content-type="editor-comment"><p><bold>Reviewer #2 (Public Review):</bold></p><p>Summary:</p><p>In this work, Liang et al. investigate whether an abstract social space is neurally represented by agrid-like code. They trained participants to 'navigate' around a two-dimensional space of social agents characterized by the traits warmth and competence, then measured neural activity as participants imagined navigating through this space. The primary neural analysis consisted of three procedures: (1) identifying brain regions exhibiting the hexagonal modulation characteristic of a grid-like code, (2) estimating the orientation of each region's grid, and (3) testing whether the strength of the univariate neural signal increases when a participant is navigating in a direction aligned with the grid, compared to a direction that is misaligned with the grid. From these analyses, the authors find the clearest evidence of a grid-like code in the prefrontal cortex and weaker evidence in the entorhinal cortex.</p><p>Strengths:</p><p>The work demonstrates the existence of a grid-like neural code for a socially-relevant task, providing evidence that such coding schemes may be relevant for a variety of two-dimensional task spaces.</p><p>Weaknesses:</p><p>In the revised manuscript, the authors soften their claims about finding a grid code in the entorhinal cortex and provide additional caveats about limitations in their findings. It seems that the authors and reviewers are in agreement about the following weaknesses, which were part of my original review: Claims about a grid code in the entorhinal cortex are not well-supported by the analyses presented. The whole-brain analysis does not suggest that the entorhinal cortex exhibits hexagonal modulation; the strength of the entorhinal BOLD signal does not track the putative alignment of the grid code there; multivariate analyses do not reveal any evidence of a grid-like representational geometry.</p><p>In the authors' response to reviews, they provide additional clarification about their exploratory analyses examining whether behavior (i.e., reaction times) and individual difference measures (i.e., social anxiety and avoidance) can be predicted by the hexagonal modulation strength in some region X, conditional on region X having a similar estimated grid alignment with some other region Y. My guess is that readers would find it useful if some of this language were included in the main text, especially with regard to an explanation regarding the rationale for these exploratory studies.</p></disp-quote><p>Thank you very much again for your careful re-evaluation and suggestions. We have tried to improve our writing and incorporate the suggestions in the new revision.</p><disp-quote content-type="editor-comment"><p><bold>Reviewer #3 (Public Review):</bold></p><p>Liang and colleagues set out to test whether the human brain uses distance and grid-like codes in social knowledge using a design where participants had to navigate in a two-dimensional social space based on competence and warmth during an fMRI scan. They showed that participants were able to navigate the social space and found distance-based codes as well as grid-like codes in various brain regions, and the grid-like code correlated with behavior (reaction times).</p><p>On the whole, the experiment is designed appropriately for testing for distant-based and grid-like codes, and is relatively well powered for this type of study, with a large amount of behavioral training per participant. They revealed that a number of brain regions correlated positively or negatively with distance in the social space, and found grid-like codes in the frontal polar cortex and posterior medial entorhinal cortex, the latter in line with prior findings on grid-like activity in entorhinal cortex. The current paper seems quite similar conceptually and in design to previous work, most notably Park et al., 2021, Nature Neuroscience.</p><p>(1) The authors claim that this study provides evidence that humans use a spatial / grid code for abstract knowledge like social knowledge.</p><p>This data does specifically not add anything new to this argument. As with almost all studies that test for a grid code in a similar &quot;conceptual&quot; space (not only the current study), the problem is that, when the space is not a uniform, square/circular space, and 2-dimensional then there is no reason the code will be perfectly grid like, i.e., show six-fold symmetry. In real world scenarios of social space (as well as navigation, semantic concepts), it must be higher dimensional - or at least more than two dimensional. It is unclear if this generalizes to larger spaces where not all part of the space is relevant. Modelling work from Tim Behrens' lab (e.g., Whittington et al., 2020) and Bradley Love's lab (e.g., Mok &amp; Love, 2019) have shown/argued this to be the case. In experimental work, like in mazes from the Mosers' labs (e.g., Derdikman et al., 2009), or trapezoid environments from the O'Keefe lab (Krupic et al., 2015), there are distortions in mEC cells, and would not pass as grid cells in terms of the six-fold symmetry criterion.</p><p>The authors briefly discuss the limitations of this at the very end but do not really say how this speaks to the goal of their study and the claim that social space or knowledge is organized as a grid code and if it is in fact used in the brain in their study and beyond. This issue deserves to be discussed in more depth, possibly referring to prior work that addressed this, and raise the issue for future work to address the problem - or if the authors think it is a problem at all.</p></disp-quote><p>Thanks very much again for your careful re-evaluation and comments. We have tried to incorporate some of the suggested papers into our discussion. In summary, we agree that there is more to six-fold symmetric code that can be utilized to represent “conceptual space”. We think that the next step for a stronger claim would be to find the representation of more spontaneous non-spatial maps.</p><p>References</p><p>Bao, X., Gjorgieva, E., Shanahan, L. K., Howard, J. D., Kahnt, T., &amp; Gottfried, J. A. (2019). Grid-like Neural Representations Support Olfactory Navigation of a Two-Dimensional Odor Space. Neuron, 102(5), 1066-1075 e1065. <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1016/j.neuron.2019.03.034">https://doi.org/10.1016/j.neuron.2019.03.034</ext-link></p><p>Constantinescu, A. O., O'Reilly, J. X., &amp; Behrens, T. E. J. (2016). Organizing conceptual knowledge in humans with a gridlike code. Science, 352(6292), 1464-1468. <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1126/science.aaf0941">https://doi.org/10.1126/science.aaf0941</ext-link></p><p>Park, S. A., Miller, D. S., &amp; Boorman, E. D. (2021). Inferences on a multidimensional social hierarchy use a grid-like code. Nat Neurosci, 24(9), 1292-1301. <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1038/s41593-02100916-3">https://doi.org/10.1038/s41593-02100916-3</ext-link></p></body></sub-article></article>