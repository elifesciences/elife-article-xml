<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD with MathML3 v1.3 20210610//EN"  "JATS-archivearticle1-3-mathml3.dtd"><article xmlns:ali="http://www.niso.org/schemas/ali/1.0/" xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" article-type="research-article" dtd-version="1.3"><front><journal-meta><journal-id journal-id-type="nlm-ta">elife</journal-id><journal-id journal-id-type="publisher-id">eLife</journal-id><journal-title-group><journal-title>eLife</journal-title></journal-title-group><issn publication-format="electronic" pub-type="epub">2050-084X</issn><publisher><publisher-name>eLife Sciences Publications, Ltd</publisher-name></publisher></journal-meta><article-meta><article-id pub-id-type="publisher-id">101413</article-id><article-id pub-id-type="doi">10.7554/eLife.101413</article-id><article-id pub-id-type="doi" specific-use="version">10.7554/eLife.101413.3</article-id><article-version article-version-type="publication-state">version of record</article-version><article-categories><subj-group subj-group-type="display-channel"><subject>Research Article</subject></subj-group><subj-group subj-group-type="heading"><subject>Neuroscience</subject></subj-group></article-categories><title-group><article-title>Methamphetamine-induced adaptation of learning rate dynamics depend on baseline performance</article-title></title-group><contrib-group><contrib contrib-type="author" corresp="yes"><name><surname>Kirschner</surname><given-names>Hans</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">https://orcid.org/0000-0001-9747-1746</contrib-id><email>hans.kirschner@ovgu.de</email><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="fn" rid="con1"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author"><name><surname>Molla</surname><given-names>Hanna M</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">https://orcid.org/0000-0002-2971-4512</contrib-id><xref ref-type="aff" rid="aff2">2</xref><xref ref-type="fn" rid="con2"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author"><name><surname>Nassar</surname><given-names>Matthew R</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">https://orcid.org/0000-0002-5397-535X</contrib-id><xref ref-type="aff" rid="aff3">3</xref><xref ref-type="aff" rid="aff4">4</xref><xref ref-type="fn" rid="con3"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" equal-contrib="yes"><name><surname>de Wit</surname><given-names>Harriet</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">https://orcid.org/0000-0002-7211-8994</contrib-id><xref ref-type="aff" rid="aff2">2</xref><xref ref-type="fn" rid="equal-contrib1">†</xref><xref ref-type="other" rid="fund2"/><xref ref-type="fn" rid="con4"/><xref ref-type="fn" rid="conf2"/></contrib><contrib contrib-type="author" equal-contrib="yes"><name><surname>Ullsperger</surname><given-names>Markus</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">https://orcid.org/0000-0003-3970-1982</contrib-id><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="aff" rid="aff5">5</xref><xref ref-type="aff" rid="aff6">6</xref><xref ref-type="fn" rid="equal-contrib1">†</xref><xref ref-type="other" rid="fund4"/><xref ref-type="fn" rid="con5"/><xref ref-type="fn" rid="conf1"/></contrib><aff id="aff1"><label>1</label><institution-wrap><institution-id institution-id-type="ror">https://ror.org/00ggpsq73</institution-id><institution>Institute of Psychology, Otto-von-Guericke University</institution></institution-wrap><addr-line><named-content content-type="city">Magdeburg</named-content></addr-line><country>Germany</country></aff><aff id="aff2"><label>2</label><institution-wrap><institution-id institution-id-type="ror">https://ror.org/024mw5h28</institution-id><institution>Department of Psychiatry and Behavioral Neuroscience, University of Chicago</institution></institution-wrap><addr-line><named-content content-type="city">Chicago</named-content></addr-line><country>United States</country></aff><aff id="aff3"><label>3</label><institution-wrap><institution-id institution-id-type="ror">https://ror.org/05gq02987</institution-id><institution>Robert J. and Nancy D. Carney Institute for Brain Science, Brown University</institution></institution-wrap><addr-line><named-content content-type="city">Providence</named-content></addr-line><country>United States</country></aff><aff id="aff4"><label>4</label><institution-wrap><institution-id institution-id-type="ror">https://ror.org/05gq02987</institution-id><institution>Department of Neuroscience, Brown University</institution></institution-wrap><addr-line><named-content content-type="city">Providence</named-content></addr-line><country>United States</country></aff><aff id="aff5"><label>5</label><institution-wrap><institution-id institution-id-type="ror">https://ror.org/03d1zwe41</institution-id><institution>Center for Behavioral Brain Sciences</institution></institution-wrap><addr-line><named-content content-type="city">Magdeburg</named-content></addr-line><country>Germany</country></aff><aff id="aff6"><label>6</label><institution>German Center for Mental Health (DZPG), Center for Intervention and Research on Adaptive and Maladaptive Brain Circuits Underlying Mental Health (C-I-R-C)</institution><addr-line><named-content content-type="city">Halle-Jena-Magdeburg</named-content></addr-line><country>Germany</country></aff></contrib-group><contrib-group content-type="section"><contrib contrib-type="editor"><name><surname>Cools</surname><given-names>Roshan</given-names></name><role>Reviewing Editor</role><aff><institution-wrap><institution-id institution-id-type="ror">https://ror.org/016xsfp80</institution-id><institution>Donders Institute for Brain, Cognition and Behaviour, Radboud University Nijmegen</institution></institution-wrap><country>Netherlands</country></aff></contrib><contrib contrib-type="senior_editor"><name><surname>Roiser</surname><given-names>Jonathan</given-names></name><role>Senior Editor</role><aff><institution-wrap><institution-id institution-id-type="ror">https://ror.org/02jx3x895</institution-id><institution>University College London</institution></institution-wrap><country>United Kingdom</country></aff></contrib></contrib-group><author-notes><fn fn-type="con" id="equal-contrib1"><label>†</label><p>These authors contributed equally to this work</p></fn></author-notes><pub-date publication-format="electronic" date-type="publication"><day>21</day><month>07</month><year>2025</year></pub-date><volume>13</volume><elocation-id>RP101413</elocation-id><history><date date-type="sent-for-review" iso-8601-date="2024-07-18"><day>18</day><month>07</month><year>2024</year></date></history><pub-history><event><event-desc>This manuscript was published as a preprint.</event-desc><date date-type="preprint" iso-8601-date="2024-07-08"><day>08</day><month>07</month><year>2024</year></date><self-uri content-type="preprint" xlink:href="https://doi.org/10.1101/2024.07.04.602054"/></event><event><event-desc>This manuscript was published as a reviewed preprint.</event-desc><date date-type="reviewed-preprint" iso-8601-date="2024-10-02"><day>02</day><month>10</month><year>2024</year></date><self-uri content-type="reviewed-preprint" xlink:href="https://doi.org/10.7554/eLife.101413.1"/></event><event><event-desc>The reviewed preprint was revised.</event-desc><date date-type="reviewed-preprint" iso-8601-date="2025-06-24"><day>24</day><month>06</month><year>2025</year></date><self-uri content-type="reviewed-preprint" xlink:href="https://doi.org/10.7554/eLife.101413.2"/></event></pub-history><permissions><copyright-statement>© 2024, Kirschner et al</copyright-statement><copyright-year>2024</copyright-year><copyright-holder>Kirschner et al</copyright-holder><ali:free_to_read/><license xlink:href="http://creativecommons.org/licenses/by/4.0/"><ali:license_ref>http://creativecommons.org/licenses/by/4.0/</ali:license_ref><license-p>This article is distributed under the terms of the <ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/licenses/by/4.0/">Creative Commons Attribution License</ext-link>, which permits unrestricted use and redistribution provided that the original author and source are credited.</license-p></license></permissions><self-uri content-type="pdf" xlink:href="elife-101413-v1.pdf"/><self-uri content-type="figures-pdf" xlink:href="elife-101413-figures-v1.pdf"/><abstract><p>The ability to calibrate learning according to new information is a fundamental component of an organism’s ability to adapt to changing conditions. Yet, the exact neural mechanisms guiding dynamic learning rate adjustments remain unclear. Catecholamines appear to play a critical role in adjusting the degree to which we use new information over time, but individuals vary widely in the manner in which they adjust to changes. Here, we studied the effects of a low dose of methamphetamine (MA), and individual differences in these effects, on probabilistic reversal learning dynamics in a within-subject, double-blind, randomized design. Participants first completed a reversal learning task during a drug-free baseline session to provide a measure of baseline performance. Then they completed the task during two sessions, one with MA (20 mg oral) and one with placebo (PL). First, we showed that, relative to PL, MA modulates the ability to dynamically adjust learning from prediction errors. Second, this effect was more pronounced in participants who performed moderately low at baseline. These results present novel evidence for the involvement of catecholaminergic transmission on learning flexibility and highlights that baseline performance modulates the effect of the drug.</p></abstract><kwd-group kwd-group-type="author-keywords"><kwd>learning</kwd><kwd>computational neuroscience</kwd><kwd>catecholamines</kwd></kwd-group><kwd-group kwd-group-type="research-organism"><title>Research organism</title><kwd>Human</kwd></kwd-group><funding-group><award-group id="fund1"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/100000026</institution-id><institution>National Institute on Drug Abuse</institution></institution-wrap></funding-source><award-id>DA02812</award-id><principal-award-recipient><name><surname>de Wit</surname><given-names>Harriet</given-names></name></principal-award-recipient></award-group><award-group id="fund2"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/100000002</institution-id><institution>National Institutes of Health</institution></institution-wrap></funding-source><award-id>T32 GM07019</award-id><principal-award-recipient><name><surname>de Wit</surname><given-names>Harriet</given-names></name></principal-award-recipient></award-group><award-group id="fund3"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/501100000781</institution-id><institution>European Research Council</institution></institution-wrap></funding-source><award-id award-id-type="doi">10.3030/101018805</award-id><principal-award-recipient><name><surname>Ullsperger</surname><given-names>Markus</given-names></name></principal-award-recipient></award-group><award-group id="fund4"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/501100001659</institution-id><institution>Deutsche Forschungsgemeinschaft</institution></institution-wrap></funding-source><award-id>SFB 1436</award-id><principal-award-recipient><name><surname>Ullsperger</surname><given-names>Markus</given-names></name></principal-award-recipient></award-group><funding-statement>The funders had no role in study design, data collection, and interpretation, or the decision to submit the work for publication.</funding-statement></funding-group><custom-meta-group><custom-meta specific-use="meta-only"><meta-name>Author impact statement</meta-name><meta-value>In individuals with moderately low baseline performance, methamphetamine reduces the tendency to misinterpret high outcome noise.</meta-value></custom-meta><custom-meta specific-use="meta-only"><meta-name>publishing-route</meta-name><meta-value>prc</meta-value></custom-meta></custom-meta-group></article-meta></front><body><sec id="s1" sec-type="intro"><title>Introduction</title><p>Goal-directed behavior requires organisms to continually update predictions about the world to select actions in the light of new information. In environments that include discontinuities (changepoints) and noise (probabilistic errors), optimal learning requires increased weighting of surprising information during periods of change and ignoring surprising events during periods of stability. A burgeoning literature suggests that humans are able to calibrate learning rates according to the statistical content of new information (<xref ref-type="bibr" rid="bib7">Behrens et al., 2007</xref>; <xref ref-type="bibr" rid="bib14">Cook et al., 2019</xref>; <xref ref-type="bibr" rid="bib17">Diederen et al., 2016</xref>; <xref ref-type="bibr" rid="bib57">Nassar et al., 2019</xref>; <xref ref-type="bibr" rid="bib54">Nassar et al., 2010</xref>; <xref ref-type="bibr" rid="bib67">Razmi and Nassar, 2022</xref>), albeit to varying degrees (<xref ref-type="bibr" rid="bib40">Kirschner et al., 2022</xref>; <xref ref-type="bibr" rid="bib41">Kirschner et al., 2024</xref>; <xref ref-type="bibr" rid="bib56">Nassar et al., 2016</xref>; <xref ref-type="bibr" rid="bib55">Nassar et al., 2012</xref>; <xref ref-type="bibr" rid="bib58">Nassar et al., 2021</xref>).</p><p>Although the exact neural mechanisms guiding dynamic learning adjustments are unclear, several neuro-computational models have been put forward to characterize adaptive learning. While these models differ in their precise computational mechanisms, they share the hypothesis that catecholamines play a critical role in adjusting the degree to which we use new information over time. For example, a class of models assumes that striatal dopaminergic prediction errors act as a teaching signal in cortico–striatal circuits to learn task structure and rules (<xref ref-type="bibr" rid="bib3">Badre and Frank, 2012</xref>; <xref ref-type="bibr" rid="bib11">Collins and Frank, 2013</xref>; <xref ref-type="bibr" rid="bib12">Collins and Frank, 2016</xref>; <xref ref-type="bibr" rid="bib46">Lieder et al., 2018</xref>; <xref ref-type="bibr" rid="bib60">Pasupathy and Miller, 2005</xref>; <xref ref-type="bibr" rid="bib72">Schultz et al., 1997</xref>). Another line of research highlights the role of dopamine in tracking the reward history with multiple learning rates (<xref ref-type="bibr" rid="bib20">Doya, 2002</xref>; <xref ref-type="bibr" rid="bib43">Kolling et al., 2016</xref>; <xref ref-type="bibr" rid="bib50">Meder et al., 2017</xref>; <xref ref-type="bibr" rid="bib74">Schweighofer and Doya, 2003</xref>). This integration of reward history over multiple time scales enables people to estimate trends in the environment through past and recent experiences and adjust actions accordingly (<xref ref-type="bibr" rid="bib88">Wilson et al., 2013</xref>). Within the broader literature of cognitive control, it has been suggested that dopamine in the prefrontal cortex and basal ganglia is involved in modulating computational tradeoffs such as cognitive stability–flexibility balance (<xref ref-type="bibr" rid="bib15">Cools, 2008</xref>; <xref ref-type="bibr" rid="bib21">Dreisbach et al., 2005</xref>; <xref ref-type="bibr" rid="bib26">Floresco, 2013</xref>; <xref ref-type="bibr" rid="bib29">Goschke, 2013</xref>; <xref ref-type="bibr" rid="bib30">Goschke and Bolte, 2014</xref>; <xref ref-type="bibr" rid="bib31">Goschke and Bolte, 2018</xref>). In particular, it has been proposed that dopamine plays a crucial role in the regulation of meta-control parameters that facilitate dynamic switching between complementary control modes (i.e., shielding goals from distracting information vs. switching goals in response to significant changes in the environment) (<xref ref-type="bibr" rid="bib29">Goschke, 2013</xref>; <xref ref-type="bibr" rid="bib30">Goschke and Bolte, 2014</xref>; <xref ref-type="bibr" rid="bib31">Goschke and Bolte, 2018</xref>). Finally, other theories highlight the importance of the locus coeruleus/norepinephrine system in facilitating adaptive learning and structure learning (<xref ref-type="bibr" rid="bib67">Razmi and Nassar, 2022</xref>; <xref ref-type="bibr" rid="bib77">Silvetti et al., 2018</xref>; <xref ref-type="bibr" rid="bib90">Yu et al., 2021</xref>). Consistent with these neuro-computational models catecholaminergic drugs are known to affect cognitive performance including probabilistic reversal learning (<xref ref-type="bibr" rid="bib14">Cook et al., 2019</xref>; <xref ref-type="bibr" rid="bib18">Dodds et al., 2008</xref>; <xref ref-type="bibr" rid="bib68">Repantis et al., 2010</xref>; <xref ref-type="bibr" rid="bib70">Rostami Kandroodi et al., 2021</xref>; <xref ref-type="bibr" rid="bib81">van den Bosch et al., 2022</xref>; <xref ref-type="bibr" rid="bib86">Westbrook et al., 2020</xref>). Indeed, psychostimulants, such as methamphetamine (MA), that increase extracellular catecholamine availability, can enhance cognition (<xref ref-type="bibr" rid="bib2">Arria et al., 2017</xref>; <xref ref-type="bibr" rid="bib33">Husain and Mehta, 2011</xref>; <xref ref-type="bibr" rid="bib78">Smith and Farah, 2011</xref>) and are used to remediate cognitive deficits in attention deficit hyperactivity disorder (<xref ref-type="bibr" rid="bib1">Arnsten and Pliszka, 2011</xref>; <xref ref-type="bibr" rid="bib66">Prince, 2008</xref>). However, the cognitive enhancements vary across tasks and across individuals (<xref ref-type="bibr" rid="bib8">Bowman et al., 2023</xref>; <xref ref-type="bibr" rid="bib14">Cook et al., 2019</xref>; <xref ref-type="bibr" rid="bib16">Cools and D’Esposito, 2011</xref>; <xref ref-type="bibr" rid="bib28">Garrett et al., 2015</xref>; <xref ref-type="bibr" rid="bib70">Rostami Kandroodi et al., 2021</xref>; <xref ref-type="bibr" rid="bib81">van den Bosch et al., 2022</xref>; <xref ref-type="bibr" rid="bib82">van der Schaaf et al., 2013</xref>) and the mechanisms underlying this variability remain poorly understood.</p><p>There is evidence that the effects of catecholaminergic drugs depend on an individual’s baseline dopamine levels in the prefrontal cortex and striatum (<xref ref-type="bibr" rid="bib9">Cohen and Servan-Schreiber, 1992</xref>; <xref ref-type="bibr" rid="bib16">Cools and D’Esposito, 2011</xref>; <xref ref-type="bibr" rid="bib18">Dodds et al., 2008</xref>; <xref ref-type="bibr" rid="bib22">Durstewitz and Seamans, 2008</xref>; <xref ref-type="bibr" rid="bib70">Rostami Kandroodi et al., 2021</xref>; <xref ref-type="bibr" rid="bib81">van den Bosch et al., 2022</xref>). Depending on individual baseline dopamine levels the administration of catecholaminergic drugs can promote states of cognitive flexibility or stability. For example, pushing dopamine from low to optimal (medium) levels may increase update thresholds in the light of new information (i.e., facilitating shielding/stability), whereas if a drug pushes dopamine either too high or too low may decrease update thresholds (i.e., facilitating shifting/flexibility) (<xref ref-type="bibr" rid="bib22">Durstewitz and Seamans, 2008</xref>; <xref ref-type="bibr" rid="bib31">Goschke and Bolte, 2018</xref>).</p><p>Here, we argue that baseline performance should be considered when studying the behavioral effects of catecholaminergic drugs effects. For example, <xref ref-type="bibr" rid="bib70">Rostami Kandroodi et al., 2021</xref> reported that the re-uptake blocker methylphenidate did not alter reversal learning overall, but preferentially improved performance in participants with higher working memory capacity. To investigate the role of baseline performance in drug challenge studies, it is important to control for several factors. First, the order of drug and placebo (PL) sessions must be balanced to control for practice effects (<xref ref-type="bibr" rid="bib6">Bartels et al., 2010</xref>; <xref ref-type="bibr" rid="bib28">Garrett et al., 2015</xref>; <xref ref-type="bibr" rid="bib47">MacRae et al., 1988</xref>; <xref ref-type="bibr" rid="bib75">Servan-Schreiber et al., 1998</xref>). Second, it is desirable to obtain an independent measure of baseline performance that is not confounded with the drug vs. PL comparison. Thus, participants may be stratified based on their performance on an independent session.</p><p>In the present study, we studied the effects of MA, a stimulant that increases monoaminergic transmission, on probabilistic reversal learning dynamics in a within-subject, double-blind, randomized design. The effects of the drug on a reversal learning task were examined in relation to participants’ baseline level of performance. Baseline performance was determined during an initial drug-free session. Then, participants completed the task during two sessions after receiving PL and 20 mg of MA (order counterbalanced) (<xref ref-type="fig" rid="fig1">Figure 1</xref>).</p><fig id="fig1" position="float"><label>Figure 1.</label><caption><title>Subjective drug effects post-capsule administration.</title><p>Methamphetamine (MA) increased ‘feel drug effect’ ratings compared to placebo. The scale for the ratings of Feeling a drug effect range from 0 to 100. The vertical black line indicates the time at which the task was started. Ratings of ‘feeling’ a drug effect did not differ significantly between low vs. high baseline performers (all p &gt; 0.05). DEQ = Drug Effects Questionnaire (<xref ref-type="bibr" rid="bib51">Morean et al., 2013</xref>). Mean/SEM = line/shading.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-101413-fig1-v1.tif"/></fig><p>The task used to study adaptive learning dynamics was a reversal variant of an established probabilistic learning task (<xref ref-type="bibr" rid="bib25">Fischer and Ullsperger, 2013</xref>; <xref ref-type="bibr" rid="bib38">Jocham et al., 2014</xref>; <xref ref-type="bibr" rid="bib40">Kirschner et al., 2022</xref>; <xref ref-type="bibr" rid="bib41">Kirschner et al., 2024</xref>). On each trial, subjects made a choice to either gamble or avoid gambling on a probabilistic outcome, in response to a stimulus presented in the middle of the screen (see <xref ref-type="fig" rid="fig2">Figure 2A</xref>). A gamble could result in a gain or loss of 10 points, depending on the reward contingency associated with that stimulus. In choosing not to gamble, subjects avoided losing or winning points, but they were informed what would have happened if they had chosen to gamble. The reward contingency changed every 30–35 trials. By learning which symbols to choose and which to avoid, participants could maximize total points. A novel feature of this modified version of the task is that we introduced different levels of noise (probability) to the reward contingencies. Here, reward probabilities could be less predictable (30% or 70%, i.e., high outcome noise) or more certain (20% or 80%; i.e., low outcome noise). This manipulation allowed us to study the effect of MA on the dynamic balancing of updating and shielding beliefs about reward contingencies within different levels of noise in the task environment. To estimate learning rate adjustments, we fit a nested set of reinforcement learning models, that allowed for trial-by-trial learning rate adjustments.</p><fig id="fig2" position="float"><label>Figure 2.</label><caption><title>Methamphetamine improved performance in a modified probabilistic reversal learning task only in participants who performed the task poorly at baseline.</title><p>(<bold>A</bold>) Schematic of the learning task. Each trial began with the presentation of a random jitter between 300 and 500 ms. Hereafter, a fixation cross was presented together with two response options (choose – green tick mark or avoid – red no-parking sign). After the fixation cross, the stimulus was shown centrally until the participant responded or for a maximum duration of 2000 ms. Thereafter, participants’ choices were confirmed by a white rectangle surrounding the chosen option for 500 ms. Finally, the outcome was presented for 750 ms. If subjects chose to gamble on the presented stimuli, they received either a green smiling face and a reward of 10 points or a red frowning face and a loss of 10 points. When subjects avoided a symbol, they received the same feedback but with a slightly paler color and the points that could have been received were crossed out to indicate that the feedback was fictive and had no effect on the total score. A novel feature of this modified version of the task is that we introduced different levels of noise (probability) to the reward contingencies. Here, reward probabilities could be less predictable (30% or 70%), more certain (20% or 80%), or random (50%). (<bold>B</bold>) Total points earned in the task split up in sessions (baseline, drug sessions 1 and 2) and drug condition (PL vs. MA). Results show practice effects but no differences between the two drug sessions (baseline vs. drug session 1: 595.85 (39.81) vs. 708.62 (36.93); <italic>t</italic>(93) = –4.21, p = 5.95<sup>–05</sup>, <italic>d</italic> = 0.30; baseline vs. drug session 2: 595.85 (39.81) vs. 730.00 (38.53); <italic>t</italic>(93) = –4.77, p = 6.66<sup>–06</sup>, <italic>d</italic> = 0.35; session 1 vs. session 2: <italic>t</italic>(93) = –0.85, p = 0.399, <italic>d</italic> = 0.05). (<bold>C</bold>) Interestingly, when we stratified drug effects by baseline performance (using median split on total points at baseline), we found that there was a trend toward better performance under MA in the low baseline performance group (<italic>n</italic> = 47, p = 0.07). (<bold>D</bold>) Overall performance in drug sessions 1 and 2 stratified by baseline performance. Here, baseline performance appears not to affect performance in drug session 1 or 2. <italic>Note</italic>. IQR = inter quartile range; PL = placebo; MA = methamphetamine. ** = significant difference (p &lt; .05); * = marginally significant difference (p = .07).</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-101413-fig2-v1.tif"/></fig><p>We found that MA improved participants’ performance in the task, but this effect was driven mainly by a greater improvement in performance in those participants who performed poorly during the baseline session. Modeling results suggested that MA helps performance by adaptively shifting the relative weighting of surprising outcomes based on their statistical context. Specifically, MA facilitates down-weighting of probabilistic errors in stages of less predictable reward contingencies. Together, these results reveal novel insights into the role of catecholamines in adaptive learning behavior and highlights the importance to consider individual difference at baseline.</p></sec><sec id="s2" sec-type="results"><title>Results</title><p>Ninety-four healthy young adults completed the probabilistic learning task (<xref ref-type="fig" rid="fig2">Figure 2</xref>; <xref ref-type="bibr" rid="bib25">Fischer and Ullsperger, 2013</xref>; <xref ref-type="bibr" rid="bib38">Jocham et al., 2014</xref>; <xref ref-type="bibr" rid="bib40">Kirschner et al., 2022</xref>; <xref ref-type="bibr" rid="bib41">Kirschner et al., 2024</xref>) on three separate sessions, an initial drug-free session, and after PL and MA. The study followed a double-blinded cross-over design, whereby 50% of participants received MA first, and 50% of participants PL first. <xref ref-type="table" rid="table1">Table 1</xref> shows the demographic characteristics of the participants grouped by their task performance during the baseline session. The groups did not differ significantly on any of the variables measured. In a first analysis, we checked for general practice effects across the three task completions based on the total points earned in the task. We found a strong practice effect (<italic>F</italic>(2,186) = 14.53, p &lt; 0.001) with better performance on session two and three compared to session one (baseline). There was no difference in the total scores between session two and three (see <xref ref-type="fig" rid="fig2">Figure 2B</xref>). These results suggest that the baseline session may have minimized order effects between MA and PL sessions (see also results and discussion). The key findings detailed below are summarized in a schematic figure presented in the discussion section (Figure 10).</p><table-wrap id="table1" position="float"><label>Table 1.</label><caption><title>Demographics and drug use characteristics of study participants (<italic>n</italic> = 94).</title></caption><table frame="hsides" rules="groups"><thead><tr><th align="left" valign="bottom">Demographic categories</th><th align="left" valign="bottom">Low baseline performers, <italic>n</italic> (%) or mean (SD)</th><th align="left" valign="bottom">high baseline performers, <italic>n</italic> (%) or mean (SD)</th></tr></thead><tbody><tr><td align="left" valign="bottom">Sex (M/F)</td><td align="left" valign="bottom">17/30</td><td align="left" valign="bottom">29/18</td></tr><tr><td align="left" valign="bottom"/><td align="left" valign="bottom">(36/64%)</td><td align="left" valign="bottom">(62/38%)</td></tr><tr><td align="left" valign="bottom">Age (years)</td><td align="left" valign="bottom">24.3 (±3.9)</td><td align="left" valign="bottom">24.7 (±4.1)</td></tr><tr><td align="left" valign="bottom">BMI</td><td align="left" valign="bottom">23.1 (±2.6)</td><td align="left" valign="bottom">23.3 (±2.3)</td></tr><tr><td align="left" valign="bottom">Education (years)</td><td align="left" valign="bottom">15.8 (±1.6)</td><td align="left" valign="bottom">15.7 (±1.6)</td></tr><tr><td align="left" valign="bottom"><italic>Race/ethnicity</italic></td><td align="left" valign="bottom"/><td align="left" valign="bottom"/></tr><tr><td align="left" valign="bottom">American Indian/Alaskan</td><td align="left" valign="bottom">1 (2%)</td><td align="left" valign="bottom">0 (0%)</td></tr><tr><td align="left" valign="bottom">Asian</td><td align="left" valign="bottom">10 (22%)</td><td align="left" valign="bottom">8 (17%)</td></tr><tr><td align="left" valign="bottom">Black or African American</td><td align="left" valign="bottom">2 (4%)</td><td align="left" valign="bottom">0 (0%)</td></tr><tr><td align="left" valign="bottom">Hispanic</td><td align="left" valign="bottom">7 (15%)</td><td align="left" valign="bottom">6 (13%)</td></tr><tr><td align="left" valign="bottom">White</td><td align="left" valign="bottom">24 (51%)</td><td align="left" valign="bottom">26 (55%)</td></tr><tr><td align="left" valign="bottom">More than one race</td><td align="left" valign="bottom">1 (2%)</td><td align="left" valign="bottom">6 (13%)</td></tr><tr><td align="left" valign="bottom">Not reported</td><td align="left" valign="bottom">2 (4%)</td><td align="left" valign="bottom">1 (2%)</td></tr><tr><td align="left" valign="bottom"><italic>Drug use (past month)</italic></td><td align="left" valign="bottom"/><td align="left" valign="bottom"/></tr><tr><td align="left" valign="bottom">Caffeinated drinks/day</td><td align="left" valign="bottom">1.0 (±0.8)</td><td align="left" valign="bottom">1.3 (±1.2)</td></tr><tr><td align="left" valign="bottom">Alcoholic drinks/week</td><td align="left" valign="bottom">3.8 (±3.0)</td><td align="left" valign="bottom">3.9 (±2.6)</td></tr><tr><td align="left" valign="bottom">Cannabis uses/month</td><td align="left" valign="bottom">4.2 (±6.7)</td><td align="left" valign="bottom">2.5 (±4.6)</td></tr><tr><td align="left" valign="bottom">Daily nicotine users</td><td align="left" valign="bottom">2 (4%)</td><td align="left" valign="bottom">1 (2%)</td></tr><tr><td align="left" valign="bottom"><italic>Lifetime stimulant use</italic></td><td align="left" valign="bottom"/><td align="left" valign="bottom"/></tr><tr><td align="left" valign="bottom">People who previously used at least once (prescription)</td><td align="left" valign="bottom">3 (6%)</td><td align="left" valign="bottom">2 (4%)</td></tr><tr><td align="left" valign="bottom">People who previously used at least once (recreationally)</td><td align="left" valign="bottom">8 (17%)</td><td align="left" valign="bottom">9 (19%)</td></tr><tr><td align="left" valign="bottom"><italic>Other lifetime drug use (median number of times used)</italic></td><td align="left" valign="bottom"/><td align="left" valign="bottom"/></tr><tr><td align="left" valign="bottom">Cannabis</td><td align="left" valign="bottom">30.5</td><td align="left" valign="bottom">20</td></tr><tr><td align="left" valign="bottom">Opiates</td><td align="left" valign="bottom">0</td><td align="left" valign="bottom">0</td></tr><tr><td align="left" valign="bottom">Hallucinogens</td><td align="left" valign="bottom">1</td><td align="left" valign="bottom">0</td></tr></tbody></table></table-wrap><sec id="s2-1"><title>Subjective drug effects</title><p>MA administration significantly increased ‘feel drug effect’ ratings compared to PL, at 30, 50, 135, 180, and 210 min post-capsule administration (see <xref ref-type="fig" rid="fig1">Figure 1</xref>; Drug × Time interaction <italic>F</italic>(5,555) = 38.46, p &lt; 0.001). In the MA session, no differences in the ‘feel drug effect’ were observed between low and high baseline performer, including peak change-from-baseline ratings (rating at 50 min post-capsule: low baseline performer: 48.36 (4.29) vs. high baseline performer: 47.21 (4.44); <italic>t</italic>(91) = 0.18, p = 0.85, <italic>d</italic> = 0.03; rating at 135 min post-capsule: low baseline performer: 37.27 (4.15) vs. high baseline performer: 45.38 (3.84); <italic>t</italic>(91) = 1.42, p = 0.15, <italic>d</italic> = 0.29).</p><sec id="s2-1-1"><title>Drug effects on overall performance and RT</title><p>In general, participants learned the task well, based on the observation that their choice behavior largely followed the underlying reward probabilities of the stimuli across the sessions (see Figure 4D-F). When all subjects were considered together, we did not find a performance benefit under MA quantified by the total points scored in the task (MA: 736.59 (37.11) vs. PL: 702.02 (38.305); <italic>t</italic>(93) = 1.38, p = 0.17, <italic>d</italic> = 0.10). When participants were stratified by their baseline performance (median spilt on total points at baseline), we found a marginally significant Drug × Baseline Performance Group interaction (Drug × Baseline Performance Group interaction: <italic>F</italic>(1,92) = 3.20, p = 0.07; see <xref ref-type="fig" rid="fig2">Figure 2C</xref> and 7A). Post hoc <italic>t</italic>-tests revealed that compared to PL, MA improved performance marginally in participants with poor baseline performance (total points MA: 522.55 (53.79) vs. PL: 443.61 (47.81); <italic>t</italic>(46) = 1.85, p = 0.071, <italic>d</italic> = 0.23). MA did not, however, improve performance in the high baseline performance group (total points MA: 950.63 (26.15) vs. PL: 960.42 (27.26); <italic>t</italic>(46) = –0.38, p = 0.698, <italic>d</italic> = 0.05). In control analyses, we ensured that these effects are not driven by session-order effects (see also section on session control analyses). Results showed no effect of Session (<italic>F</italic>(1,92) = 0.71, p = 0.40) and no Session × Baseline Performance Group interaction (<italic>F</italic>(1,92) = 0.59, p = 0.44; see <xref ref-type="fig" rid="fig1">Figure 1C</xref>). There was a trend for slightly faster RTs under MA (PL: 544.67 ms (9.87) vs. MA: 533.84 ms (11.51); <italic>t</italic>(93) = 1.75, p = 0.08, <italic>d</italic> = 0.10). This speed effect appeared to be independent of baseline performance (Drug × Baseline Performance Group interaction: <italic>F</italic>(1,92) = 0.45, p = 0.50). Moreover, MA was associated with reduced RT variability (average individual SD of RTs: PL: 193.74 (6.44) vs. MA: 178.98 (5.47); <italic>t</italic>(93) = 2.54, p = 0.012, <italic>d</italic> = 0.25). Reduced RT variability has previously been associated with increased attention and performance (<xref ref-type="bibr" rid="bib23">Esterman et al., 2013</xref>; <xref ref-type="bibr" rid="bib39">Karamacoska et al., 2018</xref>). Two-way ANOVA on RT variability revealed an effect of baseline performance (<italic>F</italic>(1,92) = 4.52, p = 0.03), with increased RT variability in low baseline performers across the drug sessions (low baseline performance: 197.27 (6.48) vs. high baseline performance: 175.45 (5.29)). Moreover, there was an effect of Drug (<italic>F</italic>(1,92) = 6.87, p = 0.01), and a Drug × Baseline Performance Group interaction (<italic>F</italic>(1,92) = 6.97, p = 0.009). Post hoc <italic>t</italic>-tests indicated that the MA-related reduction in RT variability was specific to low baseline performers (PL: 212.07 (9.84) vs. MA: 182.46 (7.98); <italic>t</italic>(46) = 3.04, p = 0.003, <italic>d</italic> = 0.48), whereas MA did not affect high baseline performers RT variability (PL: 175.40 (7.51) vs. MA: 175.50 (7.55); <italic>t</italic>(46) = –0.02, p = 0.98, <italic>d</italic> &lt; 0.01).</p><sec id="s2-1-1-1"><title>MA improves learning performance when reward contingencies are less predictable</title><p>Next, to get a better understanding of how MA affects learning dynamics, we investigated the probability of correct choice (i.e., choosing the advantageous stimuli and avoiding disadvantageous stimuli) across successive reversals. As shown in <xref ref-type="fig" rid="fig3">Figure 3</xref>, the drug did not affect initial learning. However, the drug improved performance later in learning, particularly for stimuli with less predictable reward probabilities (see <xref ref-type="fig" rid="fig3">Figure 3B</xref>) and in subjects with low baseline performance. To quantify this observation, we first applied the Bai–Perron multiple break point test (see Methods) to find systematic breaks in the learning curves allowing us to divide learning into early and late stages. We applied the test to the reversal learning data across subjects. One break point was identified at 10 trials after a reversal (indexed by the vertical lines in <xref ref-type="fig" rid="fig3">Figure 3</xref>). We did not find drug differences when considering all reversals (PL: 0.84 (0.01) vs. MA: 0.85 (0.01); <italic>t</italic>(93) = –1.14, p = 0.25, <italic>d</italic> = 0.07) and reversals to stimuli with high reward probability certainty (PL: 0.86 (0.01) vs. MA: 0.87 (0.01); <italic>t</italic>(93) = –0.25, p = 0.80, <italic>d</italic> = 0.02). Interestingly, we found a trend for increased learning under MA for stimuli with less predictable rewards (PL: 0.80 (0.01) vs. 0.82 (0.01); <italic>t</italic>(93) = –1.80, p = 0.07, <italic>d</italic> = 0.14). Two-way ANOVA on the averaged probability of correct choice during the late stage of learning revealed a Drug × Baseline Performance Group interaction (<italic>F</italic>(1,92) = 4.85, p = 0.03; see Figure 7B). Post hoc <italic>t</italic>-tests revealed that subjects performing lower at baseline appeared to benefit from MA (average accuracy late learning PL: 0.69 (0.02) vs. MA: 0.74 (0.02); <italic>t</italic>(46) = –2.59, p = 0.01, <italic>d</italic> = 0.32), whereas there was no difference between MA and PL in the high baseline performance group (PL: 0.91 (0.01) vs. MA: 0.91 (0.01); <italic>t</italic>(46) = 0.29, p = 0.77, <italic>d</italic> = 0.04). We did not find other differences in reversal learning (all p &gt; 0.1). In control analyses we split the learning curves into other possible learning situations in the task (i.e., acquisition, first reversal learning, etc.). Here, no drug-related effects emerged (see <xref ref-type="fig" rid="fig3s1">Figure 3—figure supplement 1</xref>).</p><fig-group><fig id="fig3" position="float"><label>Figure 3.</label><caption><title>Learning curves after reversals suggest that methamphetamine improves learning performance in phases of less predictable reward contingencies in low baseline performer.</title><p>Top panel of the figure shows learning curves after all reversals (<bold>A</bold>), reversals to stimuli with less predictable reward contingencies (<bold>B</bold>), and reversals to stimuli with high reward probability certainty (<bold>C</bold>). Bottom panel displays the learning curves stratified by baseline performance for all reversals (<bold>D</bold>), reversals to stimuli with less predictable reward probabilities (<bold>E</bold>), and reversals to stimuli with high reward probability certainty (<bold>F</bold>). Vertical black lines divide learning into early and late stages as suggested by the Bai–Perron multiple break point test. Results suggest no clear differences in the initial learning between MA and PL. However, learning curves diverged later in the learning, particular for stimuli with less predictable rewards (<bold>B</bold>) and in subjects with low baseline performance (<bold>E</bold>). <italic>Note</italic>. PL = placebo; MA = methamphetamine; Mean/SEM = line/shading. Data plots are smoothed with a running average (±2 trials), leading to slightly overestimated values after reversals. Additional analyses confirm that the probability of choosing the correct response after reversals is not above chance level (<italic>t</italic>-test against chance: all reversals: <italic>t</italic>(93) = 1.64, p = 0.10, <italic>d</italic> = 0.17, 99% CI [0.49,0.55]; reversal to low outcome noise: <italic>t</italic>(93) = 1.67, p = 0.10, <italic>d</italic> = 0.17, 99% CI [0.49,0.56]; reversal to high outcome noise: <italic>t</italic>(93) = 0.87, p = 0.38, <italic>d</italic> = 0.09, 99% CI [0.47,0.56]).</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-101413-fig3-v1.tif"/></fig><fig id="fig3s1" position="float" specific-use="child-fig"><label>Figure 3—figure supplement 1.</label><caption><title>Learning curves for different reversal types.</title><p>Top part shows learning curves quantified as the probability to select the correct choice (choosing the advantageous stimuli and avoiding disadvantageous stimuli) stratified by orientation performance. Two-way ANOVAs with the factors Drug (two levels) and Baseline Performance (two levels) on the averaged probability of correct choice during the early and late stage of learning were used to investigate drug effects. (<bold>A</bold>) No differences in the learning curves between MA and PL became evident when considering all reversals (all p &gt; 0.1). (<bold>B</bold>) There was no drug-related difference in the acquisition phase of the task between (all p &gt; 0.05) or (<bold>C</bold>) in the first reversal learning (all p &gt; 0.1). In the bottom part of the figure, learning curves are defined as the probability to select a stimulus. (<bold>D</bold>) No drug effect emerged for reversal learning from a bad stimulus to a good stimulus (all p &gt; 0.09) or (<bold>E</bold>) good to bad stimuli (all p &gt; 0.09). Moreover, there was no difference in reversal learning to neutral stimuli (<bold>F, G</bold>). <italic>Note</italic>. PL = placebo; MA = methamphetamine; Mean/SEM = line/shading.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-101413-fig3-figsupp1-v1.tif"/></fig></fig-group></sec><sec id="s2-1-1-2"><title>Computational modeling results</title><p>To gain a better mechanistical understanding of the trial-to-trial learning dynamics we constructed a nested model set built from RL models (see methods) that included the following features: (1) an inverse temperature parameter of the softmax function used to convert trial expected values to action probabilities (<italic>β</italic>), (2) a play bias term that indicates a tendency to attribute higher value to gambling behavior, and (3) an intercept term for the effect of learning rate on choice behavior. Additional parameters controlled trial-by-trial modulations of the learning rate including feedback confirmation (confirmatory feedback was defined as factual wins and counterfactual losses, disconfirmatory feedback was defined as factual losses and counterfactual wins), feedback modality (factual vs. counterfactual) and weighting of the learning rate as a function of the absolute value of previous prediction error (parameter Eta, determining the influence of surprise about the outcome on learning; <xref ref-type="bibr" rid="bib45">Li et al., 2011</xref>). The winning model (as measured by lowest Bayesian information criterion [BIC] and achieving protected exceedance probabilities of 100%) was one that allowed the learning rate to vary based on whether the feedback was confirmatory or not and the level of surprise of the outcome (see <xref ref-type="fig" rid="fig4">Figure 4A</xref>). Sufficiency of the model was evaluated through posterior predictive checks that matched behavioral choice data (see <xref ref-type="fig" rid="fig4">Figures 4D–F</xref>–<xref ref-type="fig" rid="fig5">5</xref>) and model validation analyses (see <xref ref-type="fig" rid="fig4s1">Figure 4—figure supplement 1</xref>). Specifically, using individual maximum likelihood parameter estimates, we simulated task performance and confirmed that MA increases performance later in learning for stimuli with less predictable reward probabilities, particularly in subjects with low baseline performance (<xref ref-type="fig" rid="fig5">Figure 5A</xref>; mean ± SD: simPL low performance: 0.69 ± 0.01 vs. simMA low performance: 0.72 ± 0.01; <italic>t</italic>(46) = 2.00, p = 0.03, <italic>d</italic> = 0.23). We did not find evidence for differences in model fit between the groups (avg. BIC PL: 596.77 (21.63) vs. MA: 599.66 (19.85); <italic>t</italic>(93) = –0.25, p = 0.80, <italic>d</italic> = 0.01).</p><fig-group><fig id="fig4" position="float"><label>Figure 4.</label><caption><title>Computational modeling results reveal that methamphetamine affects the model parameter controlling dynamic adjustments of learning rate.</title><p>(<bold>A</bold>) Model comparison. Bayesian model selection was performed using –0.5*BIC as a proxy for model evidence (<xref ref-type="bibr" rid="bib79">Stephan et al., 2009</xref>). The best-fitting mixture model assigned proportions to each model based on the frequency with which they provided the ‘best’ fit to the observed participant data (Mixture proportion; blue bars) and estimated the probability with which the true population mixture proportion for a given model exceeded that of all others (Exceedance probability; black bars). The hybrid model plus learning rate modulation by feedback confirmatory (model 3) provided the best fit to the majority of participants and had an exceedance probability near one in our model set. (<bold>B, C</bold>) Comparison of parameter estimates from the winning model on-/off-drug. Stars indicate significant difference for the respective parameter. Results suggest that only the parameter controlling dynamic adjustments of learning rate according to recent prediction errors, eta, was affected by our pharmacological manipulation. (<bold>D–F</bold>) Modeled and choice behavior of the participants in the task, stretched out for all stimuli. Note that in the task the different animal stimuli were presented in an intermixed and randomized fashion, but this visualization allows to see that participants’ choices followed the reward probabilities of the stimuli. Data plots are smoothed with a running average (±2 trials). Ground truth corresponds to the reward probability of the respective stimuli (good: 70/80%; neutral: 50%; bad: 20/30%). Dashed black lines represent 95% confidence intervals derived from 1000 simulated agents with parameters that were best fit to participants in each group. Model predictions appear to capture the transitions in choice behavior well. Mean/SEM = line/shading. <italic>Note</italic>. IQR = inter quartile range; PL = placebo; MA = methamphetamine.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-101413-fig4-v1.tif"/></fig><fig id="fig4s1" position="float" specific-use="child-fig"><label>Figure 4—figure supplement 1.</label><caption><title>Validation of model selection and parameter recovery.</title><p>After model-fitting, each model was used to simulate data for each participant using the best-fitting parameters for that participant. Each model was fit to each synthetic dataset and Bayesian information criterion (BIC) was used to determine which model provided best fit to synthetic data. (<bold>A</bold>) Inverse confusion matrix. The frequency with which a recovered model (abscissa, determined by lowest BIC) corresponded to a given simulation model (ordinate) is depicted in color. Recovered models correspond to the same models labeled on the ordinate, with recovered model 1 corresponding to the base model, and so on. The results of the model recover analyses suggest that the recovered model typically corresponded to a synthetic dataset produced by that model. (<bold>B</bold>) Parameter values that were used to simulate data from the hybrid model with additional modulation of the learning rate by feedback confirmatory (ordinate) tended to correlate (color) with the parameter values best fit to those synthetic datasets (abscissa). Recovered parameter values correspond to the labels on the ordinate, with parameter 1 reflecting temperature parameter of the softmax function, and so on.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-101413-fig4-figsupp1-v1.tif"/></fig></fig-group><fig id="fig5" position="float"><label>Figure 5.</label><caption><title>Simulated task performance based on individual maximum likelihood parameter estimates reflects drug-induced behavioral differences.</title><p>Simulated performance (<italic>y</italic>-axis) is plotted against trials after reversals (<italic>x-</italic>axis) for low (blue) and high (yellow) baseline performers. Using each participant’s estimated parameters, 100 artificial agents were simulated playing the task, and their choices were averaged to represent each participant’s behavior. The simulation shows that methamphetamine (MA) increases performance later in learning for stimuli with high outcome noise, particularly in subjects with low baseline performance (<bold>A</bold>). In contrast, no drug effect was observed for stimuli with low outcome noise (<bold>B</bold>). Note: Mean/SEM = line/shading.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-101413-fig5-v1.tif"/></fig><p>Next, we compared MAs effect on best-fitting parameters of the winning model (see <xref ref-type="fig" rid="fig4">Figure 4B, C</xref>). We found that eta (the parameter controlling dynamic adjustments of learning rate according to recent absolute prediction errors) was reduced under MA (eta MA: 0.24 (0.01) vs. PL: 0.30 (0.01); <italic>t</italic>(93) = –3.005, p = 0.003, <italic>d</italic> = 0.43). When we stratified drug effects by baseline performance, we found a marginally significant Drug × Baseline Performance Group interaction (<italic>F</italic>(1,92) = 3.09, p = 0.08; see Figure 7C). Post hoc t tests revealed that compared to PL, MA affected eta depending on baseline performance in the task. Here, subjects performing less well at baseline showed smaller eta’s (eta MA: 0.24 (0.01) vs. 0.33 (0.02); <italic>t</italic>(46) = –3.06, p = 0.003, <italic>d</italic> = 0.67), whereas there was no difference between MA and PL in the high baseline performance group MA: 0.23 (0.01) vs. 0.26 (0.01); <italic>t</italic>(46) = –1.03, p = 0.31, <italic>d</italic> = 0.18. We did not find drug-related differences in any other model parameters (all p &gt; 0.1).</p></sec><sec id="s2-1-1-3"><title>MA affects learning rate dynamics</title><p>Next, we investigated how the model parameters fit with trial-by-trial modulations of the learning rate. Learning rates in our best-fitting model were dynamic and affected by both model parameters and their interaction with feedback. Learning rate trajectories after reversals are depicted in <xref ref-type="fig" rid="fig6">Figure 6</xref>. As suggested by lower eta scores, MA appears to be associated with reduced learning rate dynamics in low baseline performers. In contrast, low baseline performers in the PL condition exhibited greater variability in learning rate (and average LR throughout) rendering their choices more erratic. Consistent with this, on many trials their choices were driven by the most recent feedback, as their learning rates on a large subset of trials in later learning stages (on average 9 out of 11; <xref ref-type="fig" rid="fig6">Figure 6H</xref>) were greater than 0.5. Specifically, variability in learning rate (average individual SD of learning rate) was reduced in both early and late stages of learning across all reversals (early PL: 0.20 (0.01) vs. MA: 0.17 (0.01); <italic>t</italic>(93) = 2.72, p = 0.007, <italic>d</italic> = 0.36; late PL: 0.18 (0.01) vs. MA: 0.15 (0.01); <italic>t</italic>(93) = 2.51, p = 0.01, <italic>d</italic> = 0.33), as were reversals to stimuli with less predictable rewards (early PL: 0.19 (0.01) vs. 0.16 (0.01); <italic>t</italic>(93) = 2.98, p = 0.003, <italic>d</italic> = 0.39; late PL: 0.18 (0.01) vs. MA: 0.16 (0.01); <italic>t</italic>(93) = 2.66, p = 0.009, <italic>d</italic>=0.35). Reversals to stimuli with high outcome certainty were also associated with decreased learning rate variability after MA administration (early PL: 0.18 (0.01) vs. MA: 0.15 (0.01); <italic>t</italic>(93) = 2.57, p = 0.01, <italic>d</italic> = 0.34; late PL: 0.18 (0.01) vs. MA: 0.15 (0.01); <italic>t</italic>(93) = 2.63, p = 0.009, <italic>d</italic> = 0.35). Two-way ANOVA revealed that this effect depended on baseline performance across all reversals (Drug × Baseline performance: <italic>F</italic>(1,92) = 3.47, p = 0.06), reversals to stimuli with less predictable rewards (Drug × Baseline performance: <italic>F</italic>(1,92) = 4.97, p = 0.02), and stimuli with high outcome certainty (Drug × Baseline performance: <italic>F</italic>(1,92) = 5.26, p = 0.03). Here, reduced variability under MA was observed in low baseline performers (all p &lt; 0.006, all <italic>d</italic> &gt; 0.51) but not in high baseline performers (all p &gt; 0.1). Together, these patterns of results suggest that people with high baseline performance show a large difference in learning rates after true reversals and during the rest of the task including misleading feedback. Specifically, they show a peak in learning after reversals and reduced learning rates in later periods of a learning block, when choice preferences should ideally be stabilized (see <xref ref-type="fig" rid="fig6">Figure 6C</xref>). This results in a better signal-to-noise ratio (SNR) between real reversals and misleading feedback (i.e., surprising outcomes in the late learning stage). In low baseline performers the SNR is improved after the administration of MA. This effect was particularly visible in stages of the task where rewards were less predictable. To quantify the SNR for less predictable reward contingencies for low baseline performers, we computed the difference between learning rate peaks on true reversals (signal) vs. learning rate peaks after probabilistic feedback later in learning (noise; SNR). The results of this analysis revealed that MA significantly increased the SNR for low baseline performers (PL: 0.01 (0.01) vs. MA: 0.04 (0.01); <italic>t</italic>(46) = –2.81, p = 0.007, <italic>d</italic> = 0.49). Moreover, learning rates were generally higher in later stages of learning, when choice preferences should ideally have stabilized (avg. learning rate during late learning for less predictable rewards: PL: 0.48 (0.01) vs. MA: 0.42 (0.01); <italic>t</italic>(46) = 3.36, p = 0.001, <italic>d</italic> = 0.56).</p><fig id="fig6" position="float"><label>Figure 6.</label><caption><title>Methamphetamine boosts signal-to-noise ratio (SNR) between real reversals and misleading feedback in late learning stages.</title><p>Learning rate trajectories after reversal derived from the computational model. First column depicts learning rates across all subjects for all reversals (<bold>A</bold>), reversal to stimuli with high reward probability certainty (<bold>D</bold>), and reversal to stimuli with noisy outcomes (<bold>G</bold>). Middle and right column shows learning rate trajectories for subjects stratified by baseline performance (<bold>B, E, H</bold> – low baseline performance; <bold>C, F, I</bold> – high baseline performance). Results suggest that people with high baseline performance show a large difference in learning rates after true reversals and during the rest of the task including misleading feedback. Specifically, they show a peak in learning after reversals and reduced learning rates in later periods of a learning block, when choice preferences should ideally be stabilized (<bold>C</bold>). This results in a better SNR between real reversals and misleading feedback (i.e., surprising outcomes in the late learning stage). In low baseline performers the SNR is improved after the administration of MA. This effect was particularly visible in stages of the task where rewards were less predictable (<bold>H</bold>). <italic>Note</italic>. PL = placebo; MA = methamphetamine; Mean/SEM = line/shading.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-101413-fig6-v1.tif"/></fig><p>Thus far, our results suggest that (1) MA improved performance in subjects who performed poorly at baseline, and (2) MA reduced learning rate variability in subjects with low baseline performance (driven by significantly lower eta parameter estimates, which improved the SNR between true reversals and misleading feedback particularly for less predictable rewards). Next, we aimed to test how these differences relate to each other. Given that eta causes increased learning after surprising feedback and that we found the biggest drug differences in later stages of learning for stimuli that have less predictable rewards, we tested the association between the probability of making the correct choice after two consecutive probabilistic errors (wins for bad stimuli and losses for good stimuli; in total this happened eight times in the late learning stage for stimuli with 30/70% reward probability) and eta. We found a significant correlation across participants (see <xref ref-type="fig" rid="fig7">Figure 7</xref>), whereby higher etas scores were associated with fewer correct choices (<italic>r</italic> = 0.29, p = &lt;0.001). There was a trend toward a drug effect, with subjects in MA condition being more likely to make the correct choice after two misleading feedbacks (PL: 0.82 (0.02) vs. 0.84 (0.01); <italic>t</italic>(93) = –1.92, p = 0.06, <italic>d</italic> = 0.13). Two-way ANOVA revealed, that this effect depended on baseline performance (Drug × Baseline performance: <italic>F</italic>(1,92) = 4.27, p = 0.04). Post hoc <italic>t</italic>-tests indicated higher correct choice probabilities under MA in low baseline performers (PL: 0.70 (0.02) vs. MA: 0.75 (0.02); <italic>t</italic>(46) = –2.41, p = 0.02, <italic>d</italic> = 0.30) but not in high baseline performers (PL: 0.92 (0.01234) vs. MA: 0.92 (0.01); <italic>t</italic>(46) = 0.11, p = 0.91, <italic>d</italic> = 0.01).</p><fig id="fig7" position="float"><label>Figure 7.</label><caption><title>Misleading feedback effects on choice accuracy are modulated by eta and methamphetamine in low baseline performers.</title><p>This figure shows the association between receiving misleading feedback later in learning (i.e., reward or losses that do not align with a stimulus’ underlying reward probability) and the probability of making the correct choice during the next encounter of the same stimulus. Results indicate a negative correlation between the probability of a correct choice after double-misleading feedback and eta (<bold>A</bold>). Here, the probability of a correct choice after double-misleading feedback decreases with increasing eta. There was a trend (p = 0.06) that subjects under MA were more likely to make the correct choice after two misleading feedback as compared to PL (<bold>B</bold>). (<bold>C</bold>) This effect appeared to be dependent on baseline performance, whereby only subjects with low baseline performance seem to benefit from MA (p = 0.02). <italic>Note</italic>. IQR = inter quartile range; PL = placebo; MA = methamphetamine; MFB = misleading feedback; * = significant difference (p &lt; .05).</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-101413-fig7-v1.tif"/></fig></sec><sec id="s2-1-1-4"><title>MA shifts learning rate dynamics closer to the optimum for low baseline performers</title><p>To better understand the computational mechanism through which MA improved performance in low baseline performers, we first examined how performance in the task related to model parameters from our fits. To do so, we regressed task performance onto an explanatory matrix containing model parameter estimates across all conditions (see <xref ref-type="fig" rid="fig8">Figure 8A</xref>). The results of this analysis revealed that variability in several of the parameters was related to overall task performance, with the overall learning rate, feedback confirmation LR adjustments, and inverse temperature all positively predicting performance and eta and the play bias term negatively predicting it.</p><fig id="fig8" position="float"><label>Figure 8.</label><caption><title>Changes in learning rate adjustment explain drug-induced performance benefits in low baseline performers.</title><p>(<bold>A</bold>) Regression coefficients and 95% confidence intervals (points and lines; sorted by value) stipulating the contribution of each model parameter estimate to overall participants task performance (i.e., scored points in the task). Play bias and eta (the parameter governing the influence of surprise on learning rate) both made a significant negative contribution to overall task performance, whereas inverse temperature and learning rates were positively related to performance. (<bold>B</bold>) Differences in parameter values for on- and off-drug sessions as quantified by regression coefficients and 95% confidence intervals are plotted separately for high (red) and low (yellow) baseline performers. Note that the drug predominately affected the eta parameter and did so to a greater extent in low baseline performers. (<bold>C</bold>) eta estimates on-drug (<italic>y</italic>-axis) are plotted against eta estimates off-drug (<italic>x</italic>-axis) for high baseline performer (yellow points) and low baseline performer (red points). Note that a majority of subjects showed a reduction in eta on- vs. off-drug (67.02%). This effect was more pronounced in low baseline performers (low baseline performers: 74.47%; low baseline performers: 59.57%). (<bold>D</bold>) To better understand how changes in eta might have affected overall performance we conducted a set of simulations using the parameters best fit to human subjects, except that we equipped the model with a range of randomly chosen eta values to examine how altering that parameter might affect performance (<italic>n</italic> = 1000 agents). The results revealed that simulated agents with low-to-intermediate levels of eta achieved the best task performance, with models equipped with the highest etas performing particularly poorly. To illustrate how this relationship between eta and performance could have driven improved performance for some participants under the methamphetamine condition, we highlight four participants with low–moderate eta values under methamphetamine, but who differ dramatically in their eta values in the placebo condition (<bold>D</bold>, inset). PL = placebo; MA = methamphetamine.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-101413-fig8-v1.tif"/></fig><p>While each of these parameters explained unique variance in overall performance levels, only the parameter controlling dynamic adjustments of learning rate according to recent prediction errors, eta, was affected by our pharmacological manipulation (<xref ref-type="fig" rid="fig6">Figure 6B</xref>). In particular, eta was reduced in the MA condition, specifically in the low baseline group, albeit to an extent that differed across individuals (<xref ref-type="fig" rid="fig8">Figure 8C</xref>). To better understand how changes in eta might have affected overall performance we conducted a set of simulations using the parameters best fit to human subjects, except that we equipped the model with a range of randomly chosen eta values, to examine how altering that parameter might affect performance. The results revealed that simulated agents with low to intermediate levels of eta achieved the best task performance, with models equipped with the highest etas performing particularly poorly (<xref ref-type="fig" rid="fig8">Figure 8D</xref>). To illustrate how this relationship between eta and performance could have driven improved performance for some participants under the MA condition, we highlight four participants with low–moderate eta values under MA, but who differ dramatically in their eta values in the PL condition (<xref ref-type="fig" rid="fig8">Figure 8D</xref>, inset). Note that the participants who have the largest decreases in eta under the MAs, resulting from the highest PL levels of eta, would be expected to have the largest improvements in performance. It is noteworthy that low baseline performers tended to have particularly high values of eta under the baseline condition (low baseline performers: 0.33 (0.02) vs. high baseline performers: 0.25 (0.01); <italic>t</italic>(46) = 2.59, p = 0.01, <italic>d</italic> = 0.53), explaining why these individuals saw the largest improvements under the MA condition. Taken together, these results suggest that MA alters performance by changing the degree to which learning rates are adjusted according to recent prediction errors (eta), in particular by reducing the strength of such adjustments in low baseline performers to push them closer to task-specific optimal values.</p><p>While eta seemed to account for the differences in the effects of MA on performance in our low and high performance groups, it did not fully account for performance differences across the two groups (see <xref ref-type="fig" rid="fig1">Figure 1C</xref> and 10A, B). When comparing other model parameters between low and high baseline performer across drug sessions, we found that high baseline performer displayed higher overall inverse temperatures (2.97 (0.05) vs. 2.11 (0.08); <italic>t</italic>(93) = 7.94, p &lt; 0.001, <italic>d</italic> = 1.33). This suggests that high baseline performers displayed higher transfer of stimulus values to actions leading to better performance (as also indicated by the positive contribution of this parameter to overall performance in the GLM). Moreover, they tended to show a reduced play bias (–0.01 (0.01) vs. 0.04 (0.03); <italic>t</italic>(93) = –1.77, p = 0.08, <italic>d</italic> = 0.26) and increased intercepts in their learning rate term (–2.38 (0.364) to –6.48 (0.70); <italic>t</italic>(93) = 5.03, p &lt; 0.001, <italic>d</italic> = 0.76). Both of these parameters have been associated with overall performance (see <xref ref-type="fig" rid="fig8">Figure 8A</xref>). Thus, overall performance difference between high and low baseline performed can be attributed to differences in model parameters other than eta. However, as described in the previous paragraph, differential effects of MA on performance on the two groups were driven by eta.</p><p>This pattern of results suggests that MA specifically affects the eta parameter while leaving other parameters, such as the inverse temperature, unaffected. This points to a selective influence on a single computational mechanism. To verify this conclusion, we extended the winning model by allowing each parameter, in turn, to be differentially estimated for MA and PL, while keeping the other parameters fixed at the group (low and high baseline performance) mean estimates of the winning model for the PL session. These control analyses confirmed that MA affects only the eta parameter in the low-performer group (see <xref ref-type="table" rid="app3table1">Appendix 3—table 1</xref>) and that parameters did not tradeoff in our model. A similar effect was observed in a previous study investigating the effects of catecholaminergic drug administration on a probabilistic reversal learning task (<xref ref-type="bibr" rid="bib70">Rostami Kandroodi et al., 2021</xref>). In that study, methylphenidate was shown to influence the inverse learning rate parameter as a function of working memory span, assessed through a baseline cognitive task. Consistent with our findings, no drug effects were observed on other parameters in their model, including the inverse temperature.</p></sec><sec id="s2-1-1-5"><title>MA may reduce misinterpretation of high outcome noise in low performer</title><p>In our task, outcomes are influenced by two distinct sources of noise: process noise (volatility) and outcome noise (stochasticity). Optimal learning rate should increase with volatility and decrease with stochasticity. Volatility was fairly constant in our task (change points around every 30–35 trials). However, misleading feedback (i.e., outcome noise) could be misinterpreted as indicating another change point because participants do not know the volatility beforehand. Strongly overinterpreting outcome noise as change points will hinder building a correct estimate of volatility and understanding the true structure of the task. Simultaneously estimating poses a challenge, as both contribute to greater outcome variance, making outcomes more surprising. A critical distinction, however, lies in their impact on generated outcomes: volatility increases the autocorrelation between consecutive outcomes, whereas stochasticity reduces it. Recent computational approaches have successfully utilized this fundamental difference to formulate a model of learning based on the joint estimation of stochasticity and volatility (<xref ref-type="bibr" rid="bib63">Piray and Daw, 2021</xref>; <xref ref-type="bibr" rid="bib64">Piray and Daw, 2024</xref>). They report evidence that humans successfully dissociate between volatility and stochasticity with contrasting and adaptive effects on learning rates, albeit to varying degrees. Interestingly, they show that hypersensitivity to outcome noise, often observed in anxiety disorders, might arise from a misattribution of the outcome noise to volatility instead of stochasticity resulting in increased learning rates and overadjustments to misleading outcomes. It is noteworthy, that we observed a similar hypersensitivity to high outcome noise in low performer in our task that is partly reduced by MA. In an exploratory analysis, we fit two models to our task structure using modified code provided by <xref ref-type="bibr" rid="bib63">Piray and Daw, 2021</xref> (see Methods for formal Description of the model). The control model made inference about both the volatility and stochasticity. The lesioned model assumed stochasticity to be small and constant. We show the results of this analyses in <xref ref-type="fig" rid="fig9">Figure 9</xref>, <xref ref-type="fig" rid="fig9s1">Figure 9—figure supplements 1</xref> and <xref ref-type="fig" rid="fig9s2">2</xref>. We found that the inability to make inference about stochasticity, leads to misestimation of volatility, particularly for high outcome noise phases (<xref ref-type="fig" rid="fig9">Figure 9A, B</xref>). Consistently, this led to reduced sensitivity of the learning rate to volatility (i.e., the first 10 trials after reversals). The model shows similar behavior to our low-performer group, with reduced accuracy in later learnings stages for stimuli with high outcome noise (<xref ref-type="fig" rid="fig9">Figure 9D</xref>). Finally, when we fit simulated data from the two models to our model, we see increased eta parameter estimates for the lesioned model. Together, these results may hint toward an overinterpretation of stochasticity in low performer of our task and that MA has beneficial effects for those individuals as it reduced the oversensitivity to volatility. It should be noted however, that we did not fit these models to our choice behavior directly as this implementation is beyond the scope of our current study. Yet, our exploratory analyses make testable predictions for future research into the effect of catecholamines on the inference of volatility and stochasticity.</p><fig-group><fig id="fig9" position="float"><label>Figure 9.</label><caption><title>The stochasticity lesion model shows a pattern of learning deficits associated low performer in our task.</title><p>Behavior of the lesioned model, in which stochasticity is assumed to be small and constant, is shown along the control model that jointly estimates stochasticity and volatility. (<bold>A, B</bold>) The inability to make inference about stochasticity, leads to misestimation of volatility, particularly for high outcome noise phases (gray patches show trials with high outcome noise 30/70% reward probability). (<bold>C</bold>) This led to reduced sensitivity of the learning rate to volatility (i.e., the first 10 trials after reversals). (<bold>D</bold>) The lesioned model shows similar behavior to our low-performer group, with reduced accuracy in later learnings stages for stimuli with high outcome noise. (<bold>E</bold>) When we fit simulated data (n = 100) from the two models to our model, we see increased eta parameter estimates for the lesioned model. Errorbars reflect standard error of the mean over 100 simulations.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-101413-fig9-v1.tif"/></fig><fig id="fig9s1" position="float" specific-use="child-fig"><label>Figure 9—figure supplement 1.</label><caption><title>Full model results.</title><p>Behavior of the lesioned model, in which stochasticity is assumed to be small and constant, is shown along the control model that jointly estimates stochasticity and volatility. An example of estimated reward by the models shows that the stochasticity lesion model is more sensitive to noisy outcomes (<bold>A</bold>). This reduces sensitivity of the learning rate to volatility (i.e., first 10 trials after a reversal) (<bold>B</bold>). This, however, is primarily related to inability to make inference about stochasticity, which leads to misestimation of volatility (<bold>C, D</bold>). Simulations reveal that this is accompanied by reduced performance, particularly for high outcome noise stimuli (gray patches) later in learning (<bold>E</bold>). Errorbars reflect standard error of the mean over 100 simulations.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-101413-fig9-figsupp1-v1.tif"/></fig><fig id="fig9s2" position="float" specific-use="child-fig"><label>Figure 9—figure supplement 2.</label><caption><title>Simulated data from the stochasticity lesion model shows increased eta parameters compared to the control model.</title><p>Here, we fit simulated data from the control and stochasticity lesion model (100 simulations for each model) to our task model. Data from the control model reveal increased inverse temperature (<bold>A</bold>; 2.57 (0.04) vs. 3.54 (0.07); <italic>t</italic>(198) = –11.09, p = 0, <italic>d</italic> = 1.71); increased play bias (<bold>B</bold>; 0.24 (0.01) vs. 0.28 (0.01); <italic>t</italic>(198) = –2.56, p = 0.01, <italic>d</italic> = 0.39), and decreased eta’s (<bold>C</bold>; 0.18 (0.01) vs. 0.14 (0.01); <italic>t</italic>(198) = 2.21, p = 0.02, <italic>d</italic> = 0.34). There was no difference in the intercept term of the learning rate (<bold>D</bold>) or the feedback confirmation term of the learning rate (<bold>E</bold>).</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-101413-fig9-figsupp2-v1.tif"/></fig></fig-group></sec><sec id="s2-1-1-6"><title>Control analyses</title><p>To control for the potentially confounding factor session order (i.e., PL first vs. MA first), we repeated the two-way mixed ANOVAs with significant Drug x Baseline Session interactions with session order as a between subject factors. Including session order did not alter the significance of the observed effects and did not interact with the effects of interest (all p &gt; 0.24).</p></sec></sec></sec></sec><sec id="s3" sec-type="discussion"><title>Discussion</title><p>To study learning dynamics participants completed a reversal variant of an established probabilistic learning task (<xref ref-type="bibr" rid="bib25">Fischer and Ullsperger, 2013</xref>; <xref ref-type="bibr" rid="bib38">Jocham et al., 2014</xref>; <xref ref-type="bibr" rid="bib40">Kirschner et al., 2022</xref>; <xref ref-type="bibr" rid="bib41">Kirschner et al., 2024</xref>). Participants completed the task three times: in a baseline session without drug, and after PL and after oral MA (20 mg) administration. We observed a trend toward a drug effect on overall performance, with improved task performance (total points scored in the task) selectively in low baseline performers. Follow-up analyses revealed that MA performance benefits were mainly driven by significantly better choices (i.e., choosing the advantageous stimuli and avoiding disadvantageous stimuli) at later stages after reversals for less predictable reward contingencies. Modeling results suggest that MA is helping performance by adaptively shifting the relative weighting of surprising outcomes based on their statistical context. Specifically, MA facilitated down-weighting of probabilistic errors in phases of less predictable reward contingencies. In other words, in low baseline performers the SNR between true reversals and misleading feedback is improved after the administration of MA. Moreover, although existing literature has linked catecholamines to volatility-based learning rate adjustments (<xref ref-type="bibr" rid="bib14">Cook et al., 2019</xref>), we show that these adjustments also relate to other context-dependent adjustments like levels of probabilistic noise. The key findings of this study are summarized in <xref ref-type="fig" rid="fig10">Figure 10</xref>.</p><fig id="fig10" position="float"><label>Figure 10.</label><caption><title>Summary of key findings.</title><p>Mean (SEM) scores on three measures of task performance after PL and methamphetamine (MA), in participants stratified on low (n = 47) or high (n = 47) baseline performance. (<bold>A</bold>) There was a trend toward a drug effect, with boosted task performance (total points scored in the task) in low baseline performers (subjects were stratified via median split on baseline performance) after MA (20 mg) administration. (<bold>B</bold>) Follow-up analyses revealed that on-drug performance benefits were mainly driven by significantly better choices (i.e., choosing the advantageous stimuli and avoiding disadvantageous stimuli) at later stages after reversals for less predictable reward contingencies (30/70% reward probability). (<bold>C</bold>) To understand the computational mechanism through which MA improved performance in low baseline performers we investigated how performance in the task related to model parameters from our fits. Our results suggest that MA alters performance by changing the degree to which learning rates are adjusted according to recent prediction errors (eta), in particular by reducing the strength of such adjustments in low baseline performers to push them closer to task-specific optimal values.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-101413-fig10-v1.tif"/></fig><sec id="s3-1"><title>MA affects the relative weighting of reward prediction errors</title><p>A key finding of the current study is that MA affected the relative weighting of reward prediction errors. In our model, adjustments in learning rate are afforded by weighting the learning rate as a function of the absolute value of the previous prediction error (<xref ref-type="bibr" rid="bib45">Li et al., 2011</xref>). This associability-gated learning mechanism is empirically well supported (<xref ref-type="bibr" rid="bib44">Le Pelley, 2004</xref>) and facilitates decreasing learning rates in periods of stability and increasing learning rates in periods of change. MA was associated with lower weighting of prediction errors (quantified by lower eta parameters under MA). Our results comprise an important next step in understanding the neurochemical underpinnings of learning rate adjustments.</p><p>Neuro-computational models suggest that catecholamines play a critical role in adjusting the degree to which we use new information. One class of models highlights the role of striatal dopaminergic prediction errors as a teaching signal in cortico-striatal circuits to learn task structure and rules (<xref ref-type="bibr" rid="bib3">Badre and Frank, 2012</xref>; <xref ref-type="bibr" rid="bib11">Collins and Frank, 2013</xref>; <xref ref-type="bibr" rid="bib12">Collins and Frank, 2016</xref>; <xref ref-type="bibr" rid="bib46">Lieder et al., 2018</xref>; <xref ref-type="bibr" rid="bib60">Pasupathy and Miller, 2005</xref>; <xref ref-type="bibr" rid="bib72">Schultz et al., 1997</xref>). The implication of such models is that learning the structure of a task results in appropriate adjustments in learning rates. Optimal learning in our task with high level of noise in reward probabilities in combination with changing reward contingencies required increased learning from surprising events during periods of change (reversals) and reduced learning from probabilistic errors. Thus, neither too low learning adjustments after surprising outcomes (low eta) nor too high learning adjustments after surprising outcomes (high eta) are beneficial in our task structure. Interestingly, MA appears to shift eta closer to the optimum. Exploratory simulation studies using a model that jointly estimates stochasticity and volatility (<xref ref-type="bibr" rid="bib63">Piray and Daw, 2021</xref>; <xref ref-type="bibr" rid="bib64">Piray and Daw, 2024</xref>), revealed that MA might reduce the oversensitivity to volatility. In terms of the neurobiological implementation of this effect, MA may prolong the impact of phasic dopamine signals, which in turn facilitates better learning of the task structure and learning rate adjustments (<xref ref-type="bibr" rid="bib14">Cook et al., 2019</xref>; <xref ref-type="bibr" rid="bib49">Marshall et al., 2016</xref>; <xref ref-type="bibr" rid="bib84">Volkow et al., 2002</xref>). Our data, in broad strokes, are consistent with the idea that dopamine in the prefrontal cortex and basal ganglia is involved in modulating meta-control parameters that facilitated dynamic switching between complementary control modes (i.e., shielding goals from distracting information vs. shifting goals in response to significant changes in the environment) (<xref ref-type="bibr" rid="bib15">Cools, 2008</xref>; <xref ref-type="bibr" rid="bib21">Dreisbach et al., 2005</xref>; <xref ref-type="bibr" rid="bib26">Floresco, 2013</xref>; <xref ref-type="bibr" rid="bib29">Goschke, 2013</xref>; <xref ref-type="bibr" rid="bib30">Goschke and Bolte, 2014</xref>; <xref ref-type="bibr" rid="bib31">Goschke and Bolte, 2018</xref>). A key challenge in our task is differentiating real reward reversals from probabilistic misleading feedback which is a clear shielding/shifting dilemma described in the meta-control literature. Our data suggest that MA might improve meta-control of when to shield and when to shift beliefs in low baseline performers.</p><p>Moreover, it is possible that MA’s effect on learning rate adjustments is driven by its influence on the noradrenaline system. Indeed, a line of research is highlighting the importance of the locus coeruleus/norepinephrine system in facilitating adaptive learning and structure learning (<xref ref-type="bibr" rid="bib67">Razmi and Nassar, 2022</xref>; <xref ref-type="bibr" rid="bib77">Silvetti et al., 2018</xref>; <xref ref-type="bibr" rid="bib90">Yu et al., 2021</xref>). In particular, evidence from experimental studies, together with pharmacological manipulations and lesion studies of the noradrenergic system suggest that noradrenaline is important for change detection (<xref ref-type="bibr" rid="bib52">Muller et al., 2019</xref>; <xref ref-type="bibr" rid="bib55">Nassar et al., 2012</xref>; <xref ref-type="bibr" rid="bib65">Preuschoff et al., 2011</xref>; <xref ref-type="bibr" rid="bib76">Set et al., 2014</xref>). Thus, the administration of MA may have increased participants’ synaptic noradrenaline levels and, therefore, increased the sensitivity to salient events indicating true change points in the task.</p><p>It should be noted that other neuromodulators, such as acetylcholine (<xref ref-type="bibr" rid="bib49">Marshall et al., 2016</xref>; <xref ref-type="bibr" rid="bib89">Yu and Dayan, 2005</xref>) and serotonin (<xref ref-type="bibr" rid="bib32">Grossman et al., 2022</xref>; <xref ref-type="bibr" rid="bib34">Iigaya et al., 2018</xref>), have also been associated with dynamic learning rate adjustment. Future studies should compare the effects of neuromodulator-specific drugs for example a dopaminergic modulator, a noradrenergic modulator, a cholinergic modulator, and a serotonin modulator to make neuromodulator-specific claims (e.g., see <xref ref-type="bibr" rid="bib49">Marshall et al., 2016</xref>). Taken together, it is likely that in our study MA effects on learning rate adjustments are driven by multiple processes that perhaps also work in concert. Moreover, because we only administered a single pharmacological agent, our results could reflect general effects of neuromodulation.</p><p>Our results are in line with recent studies that show improved performance under methylphenidate (MPH) by making learning more robust against misleading information. For example, <xref ref-type="bibr" rid="bib24">Fallon et al., 2017</xref> showed that MPH helped participants to ignore irrelevant information but impaired the ability to flexibly update items held in working memory. Another study showed that MPH improved performance by adaptively reducing the effective learning rate in participants with higher working memory capacity (<xref ref-type="bibr" rid="bib70">Rostami Kandroodi et al., 2021</xref>). These studies highlight the complex effects of MPH on working memory and the role of working memory in reinforcement learning (<xref ref-type="bibr" rid="bib10">Collins and Frank, 2012</xref>; <xref ref-type="bibr" rid="bib13">Collins and Frank, 2018</xref>). It could be that the effect of MA on learning rate dynamics reflect a modulation of interactions between working memory and reinforcement learning strategies. However, it should be acknowledged that our task was not designed to parse out specific contributions of the reinforcement learning system and working memory to performance.</p><sec id="s3-1-1"><title>MA performance enhancement depends on initial task performance</title><p>Another key finding of the current study is that the benefits of MA on performance depend on the baseline task performance. Specifically, we found that MA selectively improved performance in participants that performed poorly in the baseline session. However, it should be noted, that all drug x baseline performance interactions, including for the key computational eta parameter did not reach the statistical threshold, and only tended toward significance. We used a binary discretization of baseline performance to simplify the analysis and presentation. To parse out the relationship between MA effects and baseline performance into finer level of detail, we conducted additional linear mixed-effects model (LMM) analyses using a sliding window regression approach (see Appendix 2). A key thing to notice in the sliding regression results is that, while each regression reveals that drug effects depend on baseline performance, they do so nonlinearly, with most variables of interest showing a saturating effect at low baseline performance levels and the strongest slope (dependence on baseline) at or near the median level of baseline performance, explaining why our median splits were able to successfully pick up on these baseline-dependent effects. Together, these results suggest that MA primarily affects moderately low baseline performer. It is noteworthy to highlight again that we had a separate baseline measurement from the PL session, allowing us to investigate baseline-dependent changes while avoiding typical concerns in such analyses like regression to the mean (<xref ref-type="bibr" rid="bib5">Barnett et al., 2005</xref>). This design enhances the robustness of our baseline-dependent effects. It is important to note, that MA did not bring performance of low baseline performers to the level of performance of high baseline performers. We speculate that high performers gained a good representation of the task structure during the orientation practice session, taking specific features of the task into account (change point probabilities, noise in the reward probabilities). This is reflected in a large SNR between real reversals and misleading feedback. Because the high performers already perform the task at a near-optimal level, MA may not further enhance performance (see Appendix 4 for additional evidence for this claim). Intriguingly, the data do not support an inverted-U-shaped effect of catecholaminergic action (<xref ref-type="bibr" rid="bib22">Durstewitz and Seamans, 2008</xref>; <xref ref-type="bibr" rid="bib31">Goschke and Bolte, 2018</xref>) given that performance of high performers did not decrease with MA. One could speculate that catecholamines are not the only factor determining eta and performance. Perhaps high performers have a generally more robust/resilient decision-making system which cannot be perturbed easily. Probably one would need even higher doses of MA (with higher side effects) to impair their performance.</p><p>These results have several interesting implications. First, a novel aspect of our design is that, in contrast to most pharmacological studies, participants completed the task during a baseline session before they took part in the two drug sessions. Drug order and practice effects are typical nuisance regressors in pharmacological imaging research. Yet, although practice effects are well acknowledged in the broader neuromodulator and cognitive literature (<xref ref-type="bibr" rid="bib6">Bartels et al., 2010</xref>; <xref ref-type="bibr" rid="bib47">MacRae et al., 1988</xref>; <xref ref-type="bibr" rid="bib75">Servan-Schreiber et al., 1998</xref>), our understanding of these effects is limited. One of the few studies that report on drug administration effects, showed that d-amphetamine (AMPH) driven increases in functional-MRI-based blood oxygen level-dependent (BOLD) signal variability (SD<sub>BOLD</sub>) and performance depended greatly on drug administration order (<xref ref-type="bibr" rid="bib28">Garrett et al., 2015</xref>). In this study, only older subjects who received AMPH first improved in performance and SD<sub>BOLD</sub>. Based on research in rats, demonstrating that dopamine release increases linearly with reward-based lever press practice (<xref ref-type="bibr" rid="bib59">Owesson-White et al., 2008</xref>), the authors speculate that practice may have shifted participants along an inverted-U-shaped dopamine performance curve (<xref ref-type="bibr" rid="bib16">Cools and D’Esposito, 2011</xref>) by increasing baseline dopamine release (<xref ref-type="bibr" rid="bib28">Garrett et al., 2015</xref>). Interestingly, we did not see a modulation of the MA effects by drug session order (PL first vs. MA first). Thus, the inclusion of an orientation session might be a good strategy to control for practice and drug order effects.</p><p>Our results also illustrate the large interindividual variability of MA effects. Recently a large pharmacological fMRI/PET study (<italic>n</italic> = 100) presented strong evidence that interindividual differences in striatal dopamine synthesis capacity explain variability in effects of methylphenidate on reversal learning (<xref ref-type="bibr" rid="bib81">van den Bosch et al., 2022</xref>). They demonstrated that methylphenidate improved reversal learning performance to a greater degree in participants with higher dopamine synthesis capacity, thus establishing the baseline dependency principle for methylphenidate. These results are in line with previous research showing that methylphenidate improved reversal learning to a greater degree in participants with higher baseline working memory capacity, an index that is commonly used as an indirect proxy of dopamine synthesis capacity (<xref ref-type="bibr" rid="bib70">Rostami Kandroodi et al., 2021</xref>; <xref ref-type="bibr" rid="bib82">van der Schaaf et al., 2013</xref>; <xref ref-type="bibr" rid="bib83">van der Schaaf et al., 2014</xref>). In the current study, we did not collect working memory capacity related information. However, our result that initial task performance strongly affected the effect of MA is in line with the pattern of results showing that individual baseline differences strongly influence drug effects and thus should be considered in pharmacological studies (<xref ref-type="bibr" rid="bib16">Cools and D’Esposito, 2011</xref>; <xref ref-type="bibr" rid="bib22">Durstewitz and Seamans, 2008</xref>; <xref ref-type="bibr" rid="bib81">van den Bosch et al., 2022</xref>). Indeed, there is evidence from the broader literature on the effects of psychostimulants on cognitive performance, that suggest that stimulants improve performance only in low performers (<xref ref-type="bibr" rid="bib35">Ilieva et al., 2013</xref>). Consistent with this, there is evidence in rats, that poor baseline performance was associated with greater response to amphetamine and increased performance in signal detection task (<xref ref-type="bibr" rid="bib80">Turner et al., 2017</xref>).</p><p>Our findings can be contrasted to those of <xref ref-type="bibr" rid="bib70">Rostami Kandroodi et al., 2021</xref>, who examined the effects of methylphenidate on a reversal learning task, in relation to baseline differences on a cognitive task. Whereas <xref ref-type="bibr" rid="bib70">Rostami Kandroodi et al., 2021</xref> found that methylphenidate improved performance mainly in participants with higher baseline working memory performance, we found that MA improved the ability to dynamically adjust learning from prediction errors to a greater extent in participants who performed poorly to medium at baseline. There are several possible reasons for these apparently different findings. First, MA and methylphenidate differ in their primary mechanisms of action: MPH acts mainly as a reuptake blocker, whereas MA increases synaptic levels of catecholamines by inhibiting the vesicular monoamine transporter 2 and inhibiting the enzyme monoamine oxidase. These differences in action could account for differential effects on cognitive tasks. Second, the tasks used by <xref ref-type="bibr" rid="bib70">Rostami Kandroodi et al., 2021</xref> and the present study differ in several ways. The <xref ref-type="bibr" rid="bib70">Rostami Kandroodi et al., 2021</xref> task assessed responses to a single reversal event during the session, whereas the present study used repeated reversals with probabilistic outcomes. Third, the measures of baseline function differed in the two studies: <xref ref-type="bibr" rid="bib70">Rostami Kandroodi et al., 2021</xref> used a working memory task that was not used in the drug sessions, whereas we used the probabilistic learning task as both the baseline measure and the measure of drug effects. Further research is needed to determine which of these factors influenced the outcomes.</p></sec></sec><sec id="s3-2"><title>Conclusion</title><p>The current data provide evidence that relative to PL, MA facilitates the ability to dynamically adjust learning from prediction errors. This observation was seen to a greater degree in those participants who performed moderately low at baseline. These results advance existing literature by presenting evidence for a causal link between catecholaminergic modulation and learning flexibility and further highlight a baseline dependency principle for catecholaminergic modulation.</p></sec></sec><sec id="s4" sec-type="materials|methods"><title>Materials and methods</title><sec id="s4-1"><title>Design</title><p>The results presented here were obtained from the first two sessions of a larger four-session study (<ext-link ext-link-type="uri" xlink:href="https://clinicaltrials.gov/">clinicaltrials.gov</ext-link> ID number NCT04642820). During the latter two sessions of the larger study, not reported here, participants participated in two fMRI scans. During the two 4 hr laboratory sessions presented here, healthy adults received MA (20 mg oral) or PL, in mixed order under double-blind conditions. One hour after ingesting the capsule, they completed the 30 min reinforcement reversal learning task. The primary comparisons were on acquisition and reversal learning parameters of reinforcement learning after MA vs. PL. Secondary measures included subjective and cardiovascular responses to the drug.</p></sec><sec id="s4-2"><title>Orientation session</title><p>Participants attended an initial orientation session to provide informed consent and to complete personality questionnaires. They were told that the purpose of the study was to investigate the effects of psychoactive drugs on mood, brain, and behavior. To reduce expectancies, they were told that they might receive a PL, stimulant, or sedative/tranquilizer. However, participants only received MA and PL. They agreed not to use any drugs except for their normal amounts of caffeine for 24 hr before and 6 hr following each session. Women who were not on oral contraceptives were tested only during the follicular phase (1–12 days from menstruation) because responses to stimulant drugs are dampened during the luteal phase of the cycle (<xref ref-type="bibr" rid="bib87">White et al., 2002</xref>). Most participants (<italic>N</italic> = 97 out of 113) completed the reinforcement learning task during the orientation session as a baseline measurement. This measure was added after the study began. Participants who did not complete the baseline measurement were omitted from the analyses presented in the main text. We run the key analyses on the full sample (<italic>n</italic> = 109). This sample included participants who completed the task only on the drug sessions. When controlling for session order and number (two vs. three sessions) effects, we see no drug effect on overall performance and learning. Yet, we found that eta was also reduced under MA in the full sample, which also resulted in reduced variability in the learning rate (see Appendix 5 for more details).</p></sec><sec id="s4-3"><title>Drug sessions</title><p>The two drug sessions were conducted in a comfortable laboratory environment, from 9 am to 1 pm, at least 72 hr apart. Upon arrival, participants provided breath and urine samples to test for recent alcohol or drug use and pregnancy (CLIAwaived Inc, Carlsbad, CA Alcosensor III, Intoximeters; AimStickPBD, hCG professional, Craig Medical Distribution). Positive tests lead to rescheduling or dismissal from the study. After drug testing, subjects completed baseline mood measures, and heart rate and blood pressure were measured. At 9:30 am, they ingested capsules (PL or MA 20 mg, in color-coded capsules) under double-blind conditions. Oral MA (Desoxyn, 5 mg per tablet) was placed in opaque size 00 capsules with dextrose filler. PL capsules contained only dextrose. Subjects completed the reinforcement learning task 60 min after capsule ingestion. Drug Effects Questionnaires (DEQs) were obtained at multiple intervals during the session. They completed four other cognitive tasks not reported here. Participants were tested individually and were permitted to relax, read, or watch neutral movies when they were not completing study measures.</p></sec><sec id="s4-4"><title>Dependent measures</title><sec id="s4-4-1"><title>Reinforcement learning task</title><p>Participants performed a reversal variant of an established probabilistic learning task (<xref ref-type="bibr" rid="bib25">Fischer and Ullsperger, 2013</xref>; <xref ref-type="bibr" rid="bib38">Jocham et al., 2014</xref>; <xref ref-type="bibr" rid="bib40">Kirschner et al., 2022</xref>; <xref ref-type="bibr" rid="bib41">Kirschner et al., 2024</xref>). On each trial, participants were presented with one of three different stimuli and decided to either gamble or avoid gambling with that stimulus with the goal to maximize the final reward (see <xref ref-type="fig" rid="fig2">Figure 2A</xref>). A gamble resulted in winning or losing points, depending on reward contingencies associated with the particular stimulus. If participants decided not to gamble, they avoided any consequences but were still able to observe what would have happened if they had gambled by receiving counterfactual feedback. The three stimuli—white line drawings of animals on a black background—were presented in a pseudo-random series that was the same for all participants. Reward contingencies for every stimulus could be 20%, 30%, 50%, 70%, or 80% and stayed constant within one block of 30–35 trials. After every block, the reward contingency changed without notice. The experiment consisted of 7 blocks per stimulus, leading to 18 reversals and 714 trials in total (see Appendix 1 for additional information on time-on-task effects). Presentation 22.0 (Neurobehavioral Systems) was used for task presentation. Every trial of the task began with a central fixation cross, presented for a variable time between 300 and 500 ms. After fixation, the stimulus was presented together with the two choice alternatives (a green checkmark for choosing and a red no-go sign for avoiding, sides counterbalanced across subjects) for a maximum of 2000 ms or until a response was given. If participants failed to respond in time, a question mark was shown, and the trial was repeated at the end of the block. When a response was made, the stimulus stayed on screen, and feedback was given after 500 ms. The outcome was then presented for 750 ms depending on the subject’s choice. Choosing to gamble led to either a green smiley face and a reward of 10 points or a red frowning face and a loss of 10 points according to the reward probability of the stimulus. An avoided gamble had no monetary consequences: the outcome was always 0. Counterfactual/fictive outcomes, indicating what would have happened had the participant chosen to gamble, were shown on screen using the same smileys in a paler color, but the reward or punishment was crossed out to indicate that the outcome was fictive.</p></sec><sec id="s4-4-2"><title>Drug Effects Questionnaire (<xref ref-type="bibr" rid="bib51">Morean et al., 2013</xref>)</title><p>The DEQ consists of five questions in total. In this paper, we only reported the ratings of the ‘Do you feel any drug effect?’ question which was rated on a 100-mm visual analog scale. Participants completed this at regular intervals throughout the session.</p></sec><sec id="s4-4-3"><title>Reinforcement learning model fitting</title><p>We fit variants of reinforcement learning models to participants’ choice behavior using a constrained search algorithm (fmincon in MATLAB 2021b), which computed a set of parameters that maximized the total log posterior probability of choice behavior. The base model (M1) was a standard Q-learning model with three parameters: (1) an inverse temperature parameter of the softmax function used to convert trial expected values to action probabilities, (2) a play bias term that indicates a tendency to attribute higher value to gambling behavior (<xref ref-type="bibr" rid="bib36">Jang et al., 2019</xref>), and (3) an intercept term for the effect of learning rate on choice behavior (<xref ref-type="bibr" rid="bib36">Jang et al., 2019</xref>). On each trial, the expected value (<inline-formula><alternatives><mml:math id="inf1"><mml:msub><mml:mrow><mml:mi>Q</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub></mml:math><tex-math id="inft1">\begin{document}$Q_{t}$\end{document}</tex-math></alternatives></inline-formula>) of a stimulus (<inline-formula><alternatives><mml:math id="inf2"><mml:msub><mml:mrow><mml:mi>X</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub></mml:math><tex-math id="inft2">\begin{document}$X_{t}$\end{document}</tex-math></alternatives></inline-formula>) was calculated according to the following formula:<disp-formula id="equ1"><alternatives><mml:math id="m1"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>Q</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:msub><mml:mi>X</mml:mi><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:msub><mml:mi>Q</mml:mi><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:msub><mml:mi>X</mml:mi><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>)</mml:mo></mml:mrow><mml:mo>+</mml:mo><mml:mi>α</mml:mi><mml:mo>∗</mml:mo><mml:msub><mml:mi>δ</mml:mi><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mspace width="thinmathspace"/><mml:mi>w</mml:mi><mml:mi>i</mml:mi><mml:mi>t</mml:mi><mml:mi>h</mml:mi><mml:mspace width="thinmathspace"/><mml:msub><mml:mi>δ</mml:mi><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:msub><mml:mi>R</mml:mi><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>−</mml:mo><mml:msub><mml:mi>Q</mml:mi><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:msub><mml:mi>X</mml:mi><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mstyle></mml:math><tex-math id="t1">\begin{document}$$\displaystyle Q_{t+1}\left (X_{t}\right)=Q_{t}\left (X_{t}\right)+\alpha \ast \delta _{t}\,with\,\delta _{t}=R_{t}- Q_{t}\left (X_{t}\right)$$\end{document}</tex-math></alternatives></disp-formula></p><p><italic>Q</italic> values represent the expected value of an action at trial <italic>t</italic>. <italic>α</italic> reflects the learning rate. <inline-formula><alternatives><mml:math id="inf3"><mml:msub><mml:mrow><mml:mi>δ</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub></mml:math><tex-math id="inft3">\begin{document}$\delta _{t}$\end{document}</tex-math></alternatives></inline-formula> represents the prediction error with <inline-formula><alternatives><mml:math id="inf4"><mml:msub><mml:mrow><mml:mi>R</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub></mml:math><tex-math id="inft4">\begin{document}$R_{t}$\end{document}</tex-math></alternatives></inline-formula> being the reward magnitude of that trial. On each trial, this value term was transferred into a ‘biased’ value term (<inline-formula><alternatives><mml:math id="inf5"><mml:msub><mml:mrow><mml:mi>V</mml:mi></mml:mrow><mml:mrow><mml:mi>B</mml:mi></mml:mrow></mml:msub><mml:mo>(</mml:mo><mml:msub><mml:mrow><mml:mi>X</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>)</mml:mo><mml:mo>=</mml:mo><mml:msub><mml:mrow><mml:mi>B</mml:mi></mml:mrow><mml:mrow><mml:mi>p</mml:mi><mml:mi>l</mml:mi><mml:mi>a</mml:mi><mml:mi>y</mml:mi></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mrow><mml:mi>Q</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>(</mml:mo><mml:msub><mml:mrow><mml:mi>X</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>)</mml:mo></mml:math><tex-math id="inft5">\begin{document}$V_{B}\left (X_{t}\right)=B_{play}+Q_{t}\left (X_{t}\right)$\end{document}</tex-math></alternatives></inline-formula>, where <inline-formula><alternatives><mml:math id="inf6"><mml:msub><mml:mrow><mml:mi>B</mml:mi></mml:mrow><mml:mrow><mml:mi>p</mml:mi><mml:mi>l</mml:mi><mml:mi>a</mml:mi><mml:mi>y</mml:mi></mml:mrow></mml:msub></mml:math><tex-math id="inft6">\begin{document}$B_{play}$\end{document}</tex-math></alternatives></inline-formula> is the play bias term) and converted into action probabilities <inline-formula><alternatives><mml:math id="inf7"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mrow><mml:mi mathvariant="normal">P</mml:mi></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mi mathvariant="normal">p</mml:mi><mml:mi mathvariant="normal">l</mml:mi><mml:mi mathvariant="normal">a</mml:mi><mml:mi mathvariant="normal">y</mml:mi></mml:mrow><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:msub><mml:mi>V</mml:mi><mml:mrow><mml:mi>B</mml:mi><mml:mspace width="thinmathspace"/><mml:mi>p</mml:mi><mml:mi>l</mml:mi><mml:mi>a</mml:mi><mml:mi>y</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>X</mml:mi><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mstyle></mml:math><tex-math id="inft7">\begin{document}${\rm P}({\rm play}|V_{B\,play}(t)(X_{t}))$\end{document}</tex-math></alternatives></inline-formula>; <inline-formula><alternatives><mml:math id="inf8"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>P</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mi mathvariant="normal">p</mml:mi><mml:mi mathvariant="normal">a</mml:mi><mml:mi mathvariant="normal">s</mml:mi><mml:mi mathvariant="normal">s</mml:mi></mml:mrow><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:msub><mml:mi>V</mml:mi><mml:mrow><mml:mi>B</mml:mi><mml:mspace width="thinmathspace"/><mml:mi>p</mml:mi><mml:mi>a</mml:mi><mml:mi>s</mml:mi><mml:mi>s</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>X</mml:mi><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mstyle></mml:math><tex-math id="inft8">\begin{document}$P({\rm pass}|V_{B\, pass}(t)(X_{t}))$\end{document}</tex-math></alternatives></inline-formula> using a softmax function with an inverse temperature <inline-formula><alternatives><mml:math id="inf9"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>β</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mstyle></mml:math><tex-math id="inft9">\begin{document}$(\beta )$\end{document}</tex-math></alternatives></inline-formula>:<disp-formula id="equ2"><alternatives><mml:math id="m2"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>P</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mrow><mml:mi mathvariant="normal">p</mml:mi><mml:mi mathvariant="normal">l</mml:mi><mml:mi mathvariant="normal">a</mml:mi><mml:mi mathvariant="normal">y</mml:mi></mml:mrow><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mspace width="thinmathspace"/><mml:msub><mml:mi>V</mml:mi><mml:mrow><mml:mi>B</mml:mi><mml:mi>p</mml:mi><mml:mi>l</mml:mi><mml:mi>a</mml:mi><mml:mi>y</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:msub><mml:mi>X</mml:mi><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mrow><mml:mi mathvariant="normal">e</mml:mi><mml:mi mathvariant="normal">x</mml:mi><mml:mi mathvariant="normal">p</mml:mi></mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>V</mml:mi><mml:mrow><mml:mtext>B play</mml:mtext></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:msub><mml:mi>X</mml:mi><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>)</mml:mo></mml:mrow><mml:mo>⋅</mml:mo><mml:mi>β</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mrow><mml:mrow><mml:mi mathvariant="normal">e</mml:mi><mml:mi mathvariant="normal">x</mml:mi><mml:mi mathvariant="normal">p</mml:mi></mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>V</mml:mi><mml:mrow><mml:mtext>play</mml:mtext></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:msub><mml:mi>X</mml:mi><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>)</mml:mo></mml:mrow><mml:mo>⋅</mml:mo><mml:mi>β</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>+</mml:mo><mml:mrow><mml:mi mathvariant="normal">e</mml:mi><mml:mi mathvariant="normal">x</mml:mi><mml:mi mathvariant="normal">p</mml:mi></mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>V</mml:mi><mml:mrow><mml:mtext>pass</mml:mtext></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:msub><mml:mi>X</mml:mi><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>)</mml:mo></mml:mrow><mml:mo>⋅</mml:mo><mml:mi>β</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mfrac><mml:mo>,</mml:mo></mml:mrow></mml:mstyle></mml:math><tex-math id="t2">\begin{document}$$\displaystyle P\left ({\rm play}|\,V_{Bplay}\left (t\right)\left (X_{t}\right)\right)=\frac{{\rm exp}\left (V_{\text{B play}}\left (t\right)\left (X_{t}\right)\cdot \beta \right)}{{\rm exp}\left (V_{\text{play}}\left (t\right)\left (X_{t}\right)\cdot \beta \right)+{\rm exp}\left (V_{\text{pass}}\left (t\right)\left (X_{t}\right)\cdot \beta \right)},$$\end{document}</tex-math></alternatives></disp-formula><disp-formula id="equ3"><alternatives><mml:math id="m3"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>P</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mrow><mml:mi mathvariant="normal">p</mml:mi><mml:mi mathvariant="normal">a</mml:mi><mml:mi mathvariant="normal">s</mml:mi><mml:mi mathvariant="normal">s</mml:mi></mml:mrow><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:msub><mml:mi>V</mml:mi><mml:mrow><mml:mi>B</mml:mi><mml:mi>p</mml:mi><mml:mi>a</mml:mi><mml:mi>s</mml:mi><mml:mi>s</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:msub><mml:mi>X</mml:mi><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mi>e</mml:mi><mml:mi>x</mml:mi><mml:mi>p</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>V</mml:mi><mml:mrow><mml:mtext>pass</mml:mtext></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:msub><mml:mi>X</mml:mi><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>)</mml:mo></mml:mrow><mml:mo>⋅</mml:mo><mml:mi>β</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mrow><mml:mi>e</mml:mi><mml:mi>x</mml:mi><mml:mi>p</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>V</mml:mi><mml:mrow><mml:mtext>play</mml:mtext></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:msub><mml:mi>X</mml:mi><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>)</mml:mo></mml:mrow><mml:mo>⋅</mml:mo><mml:mi>β</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>+</mml:mo><mml:mi>e</mml:mi><mml:mi>x</mml:mi><mml:mi>p</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>V</mml:mi><mml:mrow><mml:mtext>pass</mml:mtext></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:msub><mml:mi>X</mml:mi><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>)</mml:mo></mml:mrow><mml:mo>⋅</mml:mo><mml:mi>β</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mfrac><mml:mo>.</mml:mo></mml:mrow></mml:mstyle></mml:math><tex-math id="t3">\begin{document}$$\displaystyle P\left ({\rm pass}| V_{Bpass}\left (t\right)\left (X_{t}\right)\right)=\frac{exp\left (V_{\text{pass}}\left (t\right)\left (X_{t}\right)\cdot \beta \right)}{exp\left (V_{\text{play}}\left (t\right)\left (X_{t}\right)\cdot \beta \right)+exp\left (V_{\text{pass}}\left (t\right)\left (X_{t}\right)\cdot \beta \right)}.$$\end{document}</tex-math></alternatives></disp-formula></p><p>This was our base model (M1). Next, we fit further reinforcement models by complementing the base model with additional parameters. These additional parameters controlled trial-by-trial modulations of the learning rate. Note that our base model treats the learning rate for value updates as a constant. However, previous studies have shown that people are able to adjust their learning rate according to the volatility of the environment (<xref ref-type="bibr" rid="bib7">Behrens et al., 2007</xref>; <xref ref-type="bibr" rid="bib54">Nassar et al., 2010</xref>). In the Pearce–Hall hybrid model, adjustments in learning rate are afforded by weighting the learning rate as a function of the absolute value of previous prediction error (<xref ref-type="bibr" rid="bib45">Li et al., 2011</xref>). This associability-gated learning mechanism is empirically well supported (<xref ref-type="bibr" rid="bib44">Le Pelley, 2004</xref>) and facilitates decreasing learning rates in periods of stability and increasing learning rates in periods of change. Previous work has shown that the hybrid model can approximate normative learning rate adjustments (<xref ref-type="bibr" rid="bib45">Li et al., 2011</xref>; <xref ref-type="bibr" rid="bib61">Piray et al., 2019</xref>). In this hybrid model, the learning rate is updated as follows:<disp-formula id="equ4"><alternatives><mml:math id="m4"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>α</mml:mi><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mi>κ</mml:mi><mml:msub><mml:mi>A</mml:mi><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo></mml:mrow></mml:mstyle></mml:math><tex-math id="t4">\begin{document}$$\displaystyle \alpha _{t}=\kappa A_{t},$$\end{document}</tex-math></alternatives></disp-formula><disp-formula id="equ5"><alternatives><mml:math id="m5"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>A</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:msub><mml:mi>X</mml:mi><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mi>η</mml:mi><mml:mo>∗</mml:mo><mml:mrow><mml:mo>|</mml:mo><mml:msub><mml:mi>δ</mml:mi><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>|</mml:mo></mml:mrow><mml:mo>+</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:mi>η</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>∗</mml:mo><mml:msub><mml:mi>A</mml:mi><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:msub><mml:mi>X</mml:mi><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>)</mml:mo></mml:mrow><mml:mo>.</mml:mo></mml:mrow></mml:mstyle></mml:math><tex-math id="t5">\begin{document}$$\displaystyle A_{t+1}\left (X_{t}\right)=\eta \ast \left |\delta _{t}\right |+\left (1- \eta \right)\ast A_{t}\left (X_{t}\right).$$\end{document}</tex-math></alternatives></disp-formula></p><p>Here, <inline-formula><alternatives><mml:math id="inf10"><mml:mi>κ</mml:mi></mml:math><tex-math id="inft10">\begin{document}$\kappa $\end{document}</tex-math></alternatives></inline-formula> is scale of learning rate (<inline-formula><alternatives><mml:math id="inf11"><mml:msub><mml:mrow><mml:mi>α</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>)</mml:mo></mml:math><tex-math id="inft11">\begin{document}$\alpha _{t}\right)$\end{document}</tex-math></alternatives></inline-formula> and <inline-formula><alternatives><mml:math id="inf12"><mml:mi>η</mml:mi></mml:math><tex-math id="inft12">\begin{document}$\eta $\end{document}</tex-math></alternatives></inline-formula>) determines the step size for updating associability <inline-formula><alternatives><mml:math id="inf13"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>A</mml:mi><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mstyle></mml:math><tex-math id="inft13">\begin{document}$(A_{t})$\end{document}</tex-math></alternatives></inline-formula> as a function of the absolute RPE (<inline-formula><alternatives><mml:math id="inf14"><mml:mfenced open="|" close="|" separators="|"><mml:mrow><mml:msub><mml:mrow><mml:mi>δ</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfenced></mml:math><tex-math id="inft14">\begin{document}$\left |\delta _{t}\right |$\end{document}</tex-math></alternatives></inline-formula>). On each trial, the learning rate <inline-formula><alternatives><mml:math id="inf15"><mml:msub><mml:mrow><mml:mi>α</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>)</mml:mo></mml:math><tex-math id="inft15">\begin{document}$\alpha _{t}\right)$\end{document}</tex-math></alternatives></inline-formula> depends on the absolute RPE from the past trial. Note that the initial learning rate is defined by <inline-formula><alternatives><mml:math id="inf16"><mml:mi>κ</mml:mi></mml:math><tex-math id="inft16">\begin{document}$\kappa $\end{document}</tex-math></alternatives></inline-formula>, whereby <inline-formula><alternatives><mml:math id="inf17"><mml:mi>κ</mml:mi></mml:math><tex-math id="inft17">\begin{document}$\kappa $\end{document}</tex-math></alternatives></inline-formula> is determined by a logistic function of a weighted predictor matrix that could include an intercept term (Pearce–Hall hybrid model (M2)) and task variables that may additionally affect trial-by-trial learning rate adjustments. In the Pearce–Hall hybrid feedback confirmatory model (M3), the predictor matrix included an intercept term and feedback confirmatory information (i.e., was the feedback on a given trial confirmatory (factual wins and counterfactual losses) or disconfirmatory (factual losses and counterfactual wins)). Finally, in the Pearce–Hall hybrid feedback confirmatory and modality model (M4), the predictor matrix included an intercept term, feedback confirmatory information, and feedback modality (factual vs. counterfactual feedback) information. Two additional learning rate terms—feedback confirmation and modality—were added to the model set, as these factors have been shown to influence learning in similar tasks (<xref ref-type="bibr" rid="bib41">Kirschner et al., 2024</xref>; <xref ref-type="bibr" rid="bib71">Schüller et al., 2020</xref>). The best-fitting model was determined by computing the BIC for each model (<xref ref-type="bibr" rid="bib73">Schwarz, 1978</xref>). Moreover, we computed protected exceedance probabilities, which give the probability that one model was more likely than any other model of the model space (<xref ref-type="bibr" rid="bib69">Rigoux et al., 2014</xref>). To compare participant behavior to model-predicted behavior, we simulated choice behavior using the best-fitting model (Pearce–Hall hybrid feedback confirmatory model; see <xref ref-type="fig" rid="fig3">Figure 3A</xref>). For each trial, we used the expected trial value (<inline-formula><alternatives><mml:math id="inf18"><mml:msub><mml:mrow><mml:mi>Q</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>(</mml:mo><mml:msub><mml:mrow><mml:mi>X</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>)</mml:mo></mml:math><tex-math id="inft18">\begin{document}$Q_{t}\left (X_{t}\right)$\end{document}</tex-math></alternatives></inline-formula>) computed above, and the parameter estimates of the temperature variable as inputs to a softmax function to generate choices. Validation of model selection and parameter recovery is reported in <xref ref-type="fig" rid="fig4s1">Figure 4—figure supplement 1</xref>.</p><sec id="s4-4-3-1"><title>Description of the joint estimation of stochasticity and volatility model</title><p>In an exploratory analysis, we fit two models to our task structure using modified code provided by <xref ref-type="bibr" rid="bib63">Piray and Daw, 2021</xref>. The following description of the model is adapted therefrom.</p><p>In this model, the outcome on trial t, denoted as <inline-formula><alternatives><mml:math id="inf19"><mml:msub><mml:mrow><mml:mi>o</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub></mml:math><tex-math id="inft19">\begin{document}$o_{t}$\end{document}</tex-math></alternatives></inline-formula>, is determined by three latent variables: reward probability rate, stochasticity, and volatility. The reward rate on trial t, represented as <inline-formula><alternatives><mml:math id="inf20"><mml:msub><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub></mml:math><tex-math id="inft20">\begin{document}$x_{t}$\end{document}</tex-math></alternatives></inline-formula>, follows a Markov process with the following dynamics:<disp-formula id="equ6"><alternatives><mml:math id="m6"><mml:msub><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:msub><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mrow><mml:mi>ϵ</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub></mml:math><tex-math id="t6">\begin{document}$$\displaystyle x_{t}=x_{t- 1}+\epsilon _{t}$$\end{document}</tex-math></alternatives></disp-formula></p><p>where <inline-formula><alternatives><mml:math id="inf21"><mml:msub><mml:mrow><mml:mi>ϵ</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub></mml:math><tex-math id="inft21">\begin{document}$\epsilon _{t}$\end{document}</tex-math></alternatives></inline-formula> is Gaussian noise with zero mean and a variance governed by volatility. Consequently, the probability distribution of <inline-formula><alternatives><mml:math id="inf22"><mml:msub><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub></mml:math><tex-math id="inft22">\begin{document}$x_{t}$\end{document}</tex-math></alternatives></inline-formula> given <inline-formula><alternatives><mml:math id="inf23"><mml:msub><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:math><tex-math id="inft23">\begin{document}$x_{t- 1}$\end{document}</tex-math></alternatives></inline-formula> and volatility <inline-formula><alternatives><mml:math id="inf24"><mml:msub><mml:mrow><mml:mi>v</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub></mml:math><tex-math id="inft24">\begin{document}$v_{t}$\end{document}</tex-math></alternatives></inline-formula> is:<disp-formula id="equ7"><alternatives><mml:math id="m7"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>p</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>x</mml:mi><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:msub><mml:mi>x</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>v</mml:mi><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mi>N</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>x</mml:mi><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:msub><mml:mi>x</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>v</mml:mi><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>,</mml:mo></mml:mrow></mml:mstyle></mml:math><tex-math id="t7">\begin{document}$$\displaystyle p\left (x_{t}|x_{t- 1},v_{t}\right)=N\left (x_{t}|x_{t- 1},v_{t}\right),$$\end{document}</tex-math></alternatives></disp-formula></p><p>where <inline-formula><alternatives><mml:math id="inf25"><mml:msub><mml:mrow><mml:mi>v</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub></mml:math><tex-math id="inft25">\begin{document}$v_{t}$\end{document}</tex-math></alternatives></inline-formula> represents the volatility. For analytical convenience, the inverse volatility is defined as:<disp-formula id="equ8"><alternatives><mml:math id="m8"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>z</mml:mi><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:msubsup><mml:mi>v</mml:mi><mml:mrow><mml:mi>t</mml:mi></mml:mrow><mml:mrow><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msubsup><mml:mo>,</mml:mo></mml:mrow></mml:mstyle></mml:math><tex-math id="t8">\begin{document}$$\displaystyle z_{t}=v_{t}^{- 1},$$\end{document}</tex-math></alternatives></disp-formula></p><p>a formulation commonly used in previous studies due to its computational advantages (<xref ref-type="bibr" rid="bib62">Piray and Daw, 2020</xref>). Outcome values are generated based on the reward rate and stochasticity, following a Gaussian distribution:<disp-formula id="equ9"><alternatives><mml:math id="m9"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>p</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>o</mml:mi><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:msub><mml:mi>x</mml:mi><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>s</mml:mi><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mi>N</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>o</mml:mi><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:msub><mml:mi>x</mml:mi><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>s</mml:mi><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>,</mml:mo></mml:mrow></mml:mstyle></mml:math><tex-math id="t9">\begin{document}$$\displaystyle p\left (o_{t}|x_{t},s_{t}\right)=N\left (o_{t}|x_{t},s_{t}\right),$$\end{document}</tex-math></alternatives></disp-formula></p><p>where <inline-formula><alternatives><mml:math id="inf26"><mml:msub><mml:mrow><mml:mi>s</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub></mml:math><tex-math id="inft26">\begin{document}$s_{t}$\end{document}</tex-math></alternatives></inline-formula> represents stochasticity, and the inverse stochasticity is denoted as:<disp-formula id="equ10"><alternatives><mml:math id="m10"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>y</mml:mi><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:msubsup><mml:mi>s</mml:mi><mml:mrow><mml:mi>t</mml:mi></mml:mrow><mml:mrow><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msubsup><mml:mo>.</mml:mo></mml:mrow></mml:mstyle></mml:math><tex-math id="t10">\begin{document}$$\displaystyle y_{t}=s_{t}^{- 1}.$$\end{document}</tex-math></alternatives></disp-formula></p><p>For volatility and stochasticity, a multiplicative noise model was applied to their inverse, an approach previously shown to facilitate analytical inference when considered in isolation (<xref ref-type="bibr" rid="bib27">Gamerman et al., 2013</xref>; <xref ref-type="bibr" rid="bib85">West, 1987</xref>). Specifically, the dynamics governing these variables follow:<disp-formula id="equ11"><alternatives><mml:math id="m11"><mml:msub><mml:mrow><mml:mi>z</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:msubsup><mml:mrow><mml:mi>η</mml:mi></mml:mrow><mml:mrow><mml:mi>v</mml:mi></mml:mrow><mml:mrow><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msubsup><mml:msub><mml:mrow><mml:mi>z</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:msub><mml:mrow><mml:mi>ϵ</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub></mml:math><tex-math id="t11">\begin{document}$$\displaystyle z_{t}=\eta _{v}^{- 1}z_{t- 1}\epsilon _{t}$$\end{document}</tex-math></alternatives></disp-formula></p><p>where 0 &lt;<inline-formula><alternatives><mml:math id="inf27"><mml:msub><mml:mrow><mml:mi>η</mml:mi></mml:mrow><mml:mrow><mml:mi>v</mml:mi></mml:mrow></mml:msub></mml:math><tex-math id="inft27">\begin{document}$\eta _{v}$\end{document}</tex-math></alternatives></inline-formula>&lt; 1 is a constant, and <inline-formula><alternatives><mml:math id="inf28"><mml:msub><mml:mrow><mml:mi>ϵ</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub></mml:math><tex-math id="inft28">\begin{document}$\epsilon _{t}$\end{document}</tex-math></alternatives></inline-formula> is a random variable within the unit range, following a Beta distribution:<disp-formula id="equ12"><alternatives><mml:math id="m12"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>p</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:msub><mml:mi>ϵ</mml:mi><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mi>B</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>ϵ</mml:mi><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mi>j</mml:mi><mml:mo>,</mml:mo><mml:mn>0.5</mml:mn><mml:msub><mml:mi>η</mml:mi><mml:mrow><mml:mi>v</mml:mi></mml:mrow></mml:msub><mml:msup><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:msub><mml:mi>η</mml:mi><mml:mrow><mml:mi>v</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mrow><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msup><mml:mo>,</mml:mo><mml:mn>0.5</mml:mn></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>.</mml:mo></mml:mrow></mml:mstyle></mml:math><tex-math id="t12">\begin{document}$$\displaystyle p\left (\epsilon _{t}\right)=B\left (\epsilon _{t}|j,0.5\eta _{v}\left (1- \eta _{v}\right)^{- 1},0.5\right).$$\end{document}</tex-math></alternatives></disp-formula></p><p>The conditional expectation of <inline-formula><alternatives><mml:math id="inf29"><mml:msub><mml:mrow><mml:mi>z</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub></mml:math><tex-math id="inft29">\begin{document}$z_{t}$\end{document}</tex-math></alternatives></inline-formula> is given by <inline-formula><alternatives><mml:math id="inf30"><mml:msub><mml:mrow><mml:mi>z</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:math><tex-math id="inft30">\begin{document}$z_{t- 1}$\end{document}</tex-math></alternatives></inline-formula>, since <inline-formula><alternatives><mml:math id="inf31"><mml:mi>E</mml:mi><mml:mfenced separators="|"><mml:mrow><mml:msub><mml:mrow><mml:mi>ϵ</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfenced><mml:mo>=</mml:mo><mml:msub><mml:mrow><mml:mi>η</mml:mi></mml:mrow><mml:mrow><mml:mi>v</mml:mi></mml:mrow></mml:msub></mml:math><tex-math id="inft31">\begin{document}$E\left (\epsilon _{t}\right)=\eta _{v}$\end{document}</tex-math></alternatives></inline-formula>. A similar and independent dynamic is assumed for <inline-formula><alternatives><mml:math id="inf32"><mml:mi>y</mml:mi></mml:math><tex-math id="inft32">\begin{document}$y$\end{document}</tex-math></alternatives></inline-formula>, parameterized by the constant <inline-formula><alternatives><mml:math id="inf33"><mml:msub><mml:mrow><mml:mi>η</mml:mi></mml:mrow><mml:mrow><mml:mi>s</mml:mi></mml:mrow></mml:msub></mml:math><tex-math id="inft33">\begin{document}$\eta _{s}$\end{document}</tex-math></alternatives></inline-formula>, such that:<disp-formula id="equ13"><alternatives><mml:math id="m13"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>y</mml:mi><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:msubsup><mml:mi>η</mml:mi><mml:mrow><mml:mi>s</mml:mi></mml:mrow><mml:mrow><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msubsup><mml:msub><mml:mi>y</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:msub><mml:mi>ε</mml:mi><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo></mml:mrow></mml:mstyle></mml:math><tex-math id="t13">\begin{document}$$\displaystyle y_{t}=\eta _{s}^{- 1}y_{t- 1}\varepsilon _{t},$$\end{document}</tex-math></alternatives></disp-formula></p><p>where <inline-formula><alternatives><mml:math id="inf34"><mml:msub><mml:mrow><mml:mi>ε</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub></mml:math><tex-math id="inft34">\begin{document}$\varepsilon _{t}$\end{document}</tex-math></alternatives></inline-formula> follows a distribution similar to <inline-formula><alternatives><mml:math id="inf35"><mml:msub><mml:mrow><mml:mi>ε</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub></mml:math><tex-math id="inft35">\begin{document}$\varepsilon _{t}$\end{document}</tex-math></alternatives></inline-formula>, parameterized by <inline-formula><alternatives><mml:math id="inf36"><mml:msub><mml:mrow><mml:mi>η</mml:mi></mml:mrow><mml:mrow><mml:mi>s</mml:mi></mml:mrow></mml:msub></mml:math><tex-math id="inft36">\begin{document}$\eta _{s}$\end{document}</tex-math></alternatives></inline-formula>.</p><p>In this implementation, the model was parameterized using <inline-formula><alternatives><mml:math id="inf37"><mml:msub><mml:mrow><mml:mi>λ</mml:mi></mml:mrow><mml:mrow><mml:mi>v</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:msub><mml:mrow><mml:mi>η</mml:mi></mml:mrow><mml:mrow><mml:mi>v</mml:mi></mml:mrow></mml:msub></mml:math><tex-math id="inft37">\begin{document}$\lambda _{v}=1- \eta _{v}$\end{document}</tex-math></alternatives></inline-formula> and <inline-formula><alternatives><mml:math id="inf38"><mml:msub><mml:mrow><mml:mi>λ</mml:mi></mml:mrow><mml:mrow><mml:mi>s</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:msub><mml:mrow><mml:mi>η</mml:mi></mml:mrow><mml:mrow><mml:mi>s</mml:mi></mml:mrow></mml:msub></mml:math><tex-math id="inft38">\begin{document}$\lambda _{s}=1- \eta _{s}$\end{document}</tex-math></alternatives></inline-formula>, respectively. These parameters are interpreted as the update rate for volatility and stochasticity. In other words, larger values of <inline-formula><alternatives><mml:math id="inf39"><mml:msub><mml:mrow><mml:mi>λ</mml:mi></mml:mrow><mml:mrow><mml:mi>v</mml:mi></mml:mrow></mml:msub></mml:math><tex-math id="inft39">\begin{document}$\lambda _{v}$\end{document}</tex-math></alternatives></inline-formula> and <inline-formula><alternatives><mml:math id="inf40"><mml:msub><mml:mrow><mml:mi>λ</mml:mi></mml:mrow><mml:mrow><mml:mi>s</mml:mi></mml:mrow></mml:msub></mml:math><tex-math id="inft40">\begin{document}$\lambda _{s}$\end{document}</tex-math></alternatives></inline-formula> lead to faster updates of volatility and stochasticity. Intuitively, a smaller <inline-formula><alternatives><mml:math id="inf41"><mml:msub><mml:mrow><mml:mi>λ</mml:mi></mml:mrow><mml:mrow><mml:mi>v</mml:mi></mml:mrow></mml:msub></mml:math><tex-math id="inft41">\begin{document}$\lambda _{v}$\end{document}</tex-math></alternatives></inline-formula> increases the mean of <inline-formula><alternatives><mml:math id="inf42"><mml:msub><mml:mrow><mml:mi>ε</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub></mml:math><tex-math id="inft42">\begin{document}$\varepsilon _{t}$\end{document}</tex-math></alternatives></inline-formula>, resulting in a larger update of <inline-formula><alternatives><mml:math id="inf43"><mml:msub><mml:mrow><mml:mi>z</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub></mml:math><tex-math id="inft43">\begin{document}$z_{t}$\end{document}</tex-math></alternatives></inline-formula>. Since volatility is the inverse of <inline-formula><alternatives><mml:math id="inf44"><mml:msub><mml:mrow><mml:mi>z</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub></mml:math><tex-math id="inft44">\begin{document}$z_{t}$\end{document}</tex-math></alternatives></inline-formula>, a smaller <inline-formula><alternatives><mml:math id="inf45"><mml:msub><mml:mrow><mml:mi>λ</mml:mi></mml:mrow><mml:mrow><mml:mi>v</mml:mi></mml:mrow></mml:msub></mml:math><tex-math id="inft45">\begin{document}$\lambda _{v}$\end{document}</tex-math></alternatives></inline-formula> consequently leads to a slower update of volatility. This relationship has been formally demonstrated in recent work (<xref ref-type="bibr" rid="bib62">Piray and Daw, 2020</xref>). In addition to these two parameters, the generative process depends on the initial values of volatility and stochasticity, denoted as <inline-formula><alternatives><mml:math id="inf46"><mml:msub><mml:mrow><mml:mi>v</mml:mi></mml:mrow><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msub></mml:math><tex-math id="inft46">\begin{document}$v_{0}$\end{document}</tex-math></alternatives></inline-formula> and <inline-formula><alternatives><mml:math id="inf47"><mml:msub><mml:mrow><mml:mi>s</mml:mi></mml:mrow><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msub></mml:math><tex-math id="inft47">\begin{document}$s_{0}$\end{document}</tex-math></alternatives></inline-formula>. For our simulations, we assumed  <inline-formula><alternatives><mml:math id="inf48"><mml:msub><mml:mrow><mml:mi>v</mml:mi></mml:mrow><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msub></mml:math><tex-math id="inft48">\begin{document}$v_{0}$\end{document}</tex-math></alternatives></inline-formula> = 0.1 and <inline-formula><alternatives><mml:math id="inf49"><mml:msub><mml:mrow><mml:mi>s</mml:mi></mml:mrow><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msub></mml:math><tex-math id="inft49">\begin{document}$s_{0}$\end{document}</tex-math></alternatives></inline-formula> = 0.1. For inference, a Rao-Blackwellized Particle Filtering approach (<xref ref-type="bibr" rid="bib53">Murphy and Russell, 2001</xref>) was employed, where inference about <inline-formula><alternatives><mml:math id="inf50"><mml:msub><mml:mrow><mml:mi>v</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub></mml:math><tex-math id="inft50">\begin{document}$v_{t}$\end{document}</tex-math></alternatives></inline-formula> and <inline-formula><alternatives><mml:math id="inf51"><mml:msub><mml:mrow><mml:mi>s</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub></mml:math><tex-math id="inft51">\begin{document}$s_{t}$\end{document}</tex-math></alternatives></inline-formula> was performed using a particle filter (<xref ref-type="bibr" rid="bib19">Doucet and Johansen, 2011</xref>), and conditional on these, inference over <inline-formula><alternatives><mml:math id="inf52"><mml:msub><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub></mml:math><tex-math id="inft52">\begin{document}$x_{t}$\end{document}</tex-math></alternatives></inline-formula> was carried out using the Kalman filter.</p><p>The Kalman filter maintains beliefs about the reward probability at each trial in the form of a Gaussian distribution, characterized by a mean <inline-formula><alternatives><mml:math id="inf53"><mml:msub><mml:mrow><mml:mi>m</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub></mml:math><tex-math id="inft53">\begin{document}$m_{t}$\end{document}</tex-math></alternatives></inline-formula> and a variance <inline-formula><alternatives><mml:math id="inf54"><mml:msub><mml:mrow><mml:mi>w</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub></mml:math><tex-math id="inft54">\begin{document}$w_{t}$\end{document}</tex-math></alternatives></inline-formula>, which represents uncertainty about the true value. On each trial, the update is driven by a prediction error signal <inline-formula><alternatives><mml:math id="inf55"><mml:msub><mml:mrow><mml:mi>δ</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub></mml:math><tex-math id="inft55">\begin{document}$\delta _{t}$\end{document}</tex-math></alternatives></inline-formula> and a learning rate <inline-formula><alternatives><mml:math id="inf56"><mml:msub><mml:mrow><mml:mi>α</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub></mml:math><tex-math id="inft56">\begin{document}$\alpha _{t}$\end{document}</tex-math></alternatives></inline-formula>. This results in the following update rules upon observing the outcome <inline-formula><alternatives><mml:math id="inf57"><mml:msub><mml:mrow><mml:mi>o</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub></mml:math><tex-math id="inft57">\begin{document}$o_{t}$\end{document}</tex-math></alternatives></inline-formula>:<disp-formula id="equ14"><alternatives><mml:math id="m14"><mml:msub><mml:mrow><mml:mi>δ</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:msub><mml:mrow><mml:mi>o</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>−</mml:mo><mml:msub><mml:mrow><mml:mi>m</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub></mml:math><tex-math id="t14">\begin{document}$$\displaystyle \delta _{t}=o_{t}- m_{t}$$\end{document}</tex-math></alternatives></disp-formula><disp-formula id="equ15"><alternatives><mml:math id="m15"><mml:msub><mml:mrow><mml:mi>α</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:msub><mml:mrow><mml:mi>w</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mrow><mml:mi>v</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>w</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mrow><mml:mi>v</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mrow><mml:mi>s</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfrac></mml:math><tex-math id="t15">\begin{document}$$\displaystyle \alpha _{t}=\frac{w_{t}+v_{t}}{w_{t}+v_{t}+s_{t}}$$\end{document}</tex-math></alternatives></disp-formula><disp-formula id="equ16"><alternatives><mml:math id="m16"><mml:msub><mml:mrow><mml:mi>m</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:msub><mml:mrow><mml:mi>m</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mrow><mml:mi>α</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:msub><mml:mrow><mml:mi>δ</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub></mml:math><tex-math id="t16">\begin{document}$$\displaystyle m_{t+1}=m_{t}+\alpha _{t}\delta _{t}$$\end{document}</tex-math></alternatives></disp-formula><disp-formula id="equ17"><alternatives><mml:math id="m17"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>w</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:msub><mml:mi>α</mml:mi><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>w</mml:mi><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mi>v</mml:mi><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mstyle></mml:math><tex-math id="t17">\begin{document}$$\displaystyle w_{t+1}=\left (1- \alpha _{t}\right)\left (w_{t}+v_{t}\right)$$\end{document}</tex-math></alternatives></disp-formula></p><p>These equations describe how the belief about the reward rate is adjusted dynamically based on observed outcomes and the associated uncertainty.</p><p>The particle filter is a Monte Carlo sequential importance sampling method that maintains a set of particles (i.e., samples). The algorithm consists of three steps per trial. First, in the prediction step, each particle transitions to the next state based on the generative process. Second, the weight of each particle is updated based on the probability of the observed outcome:<disp-formula id="equ18"><alternatives><mml:math id="m18"><mml:msubsup><mml:mrow><mml:mi>b</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow><mml:mrow><mml:mi>l</mml:mi></mml:mrow></mml:msubsup><mml:mo>∝</mml:mo><mml:mi>N</mml:mi><mml:mfenced separators="|"><mml:mrow><mml:msub><mml:mrow><mml:mi>o</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>|</mml:mo><mml:msubsup><mml:mrow><mml:mi>m</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>l</mml:mi></mml:mrow></mml:msubsup><mml:mo>,</mml:mo><mml:msubsup><mml:mrow><mml:mi>w</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>l</mml:mi></mml:mrow></mml:msubsup><mml:mo>+</mml:mo><mml:msubsup><mml:mrow><mml:mi>v</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow><mml:mrow><mml:mi>l</mml:mi></mml:mrow></mml:msubsup><mml:mo>+</mml:mo><mml:msubsup><mml:mrow><mml:mi>s</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow><mml:mrow><mml:mi>l</mml:mi></mml:mrow></mml:msubsup></mml:mrow></mml:mfenced></mml:math><tex-math id="t18">\begin{document}$$\displaystyle b_{t}^{l}\propto N\left (o_{t}|m_{t- 1}^{l},w_{t- 1}^{l}+v_{t}^{l}+s_{t}^{l}\right)$$\end{document}</tex-math></alternatives></disp-formula></p><p>where <inline-formula><alternatives><mml:math id="inf58"><mml:msubsup><mml:mrow><mml:mi>b</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow><mml:mrow><mml:mi>l</mml:mi></mml:mrow></mml:msubsup></mml:math><tex-math id="inft58">\begin{document}$b_{t}^{l}$\end{document}</tex-math></alternatives></inline-formula> is the weight of particle <inline-formula><alternatives><mml:math id="inf59"><mml:mi>l</mml:mi></mml:math><tex-math id="inft59">\begin{document}$l$\end{document}</tex-math></alternatives></inline-formula> on trial <inline-formula><alternatives><mml:math id="inf60"><mml:mi>t</mml:mi></mml:math><tex-math id="inft60">\begin{document}$t$\end{document}</tex-math></alternatives></inline-formula>, and <inline-formula><alternatives><mml:math id="inf61"><mml:msubsup><mml:mrow><mml:mi>m</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>l</mml:mi></mml:mrow></mml:msubsup></mml:math><tex-math id="inft61">\begin{document}$m_{t- 1}^{l}$\end{document}</tex-math></alternatives></inline-formula> and <inline-formula><alternatives><mml:math id="inf62"><mml:msubsup><mml:mrow><mml:mi>w</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>l</mml:mi></mml:mrow></mml:msubsup></mml:math><tex-math id="inft62">\begin{document}$w_{t- 1}^{l}$\end{document}</tex-math></alternatives></inline-formula> are the estimated mean and variance from the Kalman filter on the previous trial. The terms <inline-formula><alternatives><mml:math id="inf63"><mml:msubsup><mml:mrow><mml:mi>v</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow><mml:mrow><mml:mi>l</mml:mi></mml:mrow></mml:msubsup></mml:math><tex-math id="inft63">\begin{document}$v_{t}^{l}$\end{document}</tex-math></alternatives></inline-formula> and <inline-formula><alternatives><mml:math id="inf64"><mml:msubsup><mml:mrow><mml:mi>s</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow><mml:mrow><mml:mi>l</mml:mi></mml:mrow></mml:msubsup></mml:math><tex-math id="inft64">\begin{document}$s_{t}^{l}$\end{document}</tex-math></alternatives></inline-formula> represent the sampled values of volatility and stochasticity (i.e., the inverse of <inline-formula><alternatives><mml:math id="inf65"><mml:msubsup><mml:mrow><mml:mi>z</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow><mml:mrow><mml:mi>l</mml:mi></mml:mrow></mml:msubsup></mml:math><tex-math id="inft65">\begin{document}$z_{t}^{l}$\end{document}</tex-math></alternatives></inline-formula> and <inline-formula><alternatives><mml:math id="inf66"><mml:msubsup><mml:mrow><mml:mi>y</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow><mml:mrow><mml:mi>l</mml:mi></mml:mrow></mml:msubsup></mml:math><tex-math id="inft66">\begin{document}$y_{t}^{l}$\end{document}</tex-math></alternatives></inline-formula>). During this step, particles are resampled using the systematic resampling procedure if the ratio of effective to total particles falls below 0.5. In the third step, the Kalman filter updates the mean and variance. Specifically, for every particle, the equations of the Kalman filter are used to define <inline-formula><alternatives><mml:math id="inf67"><mml:mi>a</mml:mi><mml:mi>l</mml:mi><mml:mi>p</mml:mi><mml:mi>h</mml:mi><mml:msubsup><mml:mrow><mml:mi>a</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow><mml:mrow><mml:mi>l</mml:mi></mml:mrow></mml:msubsup></mml:math><tex-math id="inft67">\begin{document}$alpha_{t}^{l}$\end{document}</tex-math></alternatives></inline-formula> and update <inline-formula><alternatives><mml:math id="inf68"><mml:msubsup><mml:mrow><mml:mi>m</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow><mml:mrow><mml:mi>l</mml:mi></mml:mrow></mml:msubsup></mml:math><tex-math id="inft68">\begin{document}$m_{t}^{l}$\end{document}</tex-math></alternatives></inline-formula> and <inline-formula><alternatives><mml:math id="inf69"><mml:msubsup><mml:mrow><mml:mi>w</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow><mml:mrow><mml:mi>l</mml:mi></mml:mrow></mml:msubsup></mml:math><tex-math id="inft69">\begin{document}$w_{t}^{l}$\end{document}</tex-math></alternatives></inline-formula>. The learning rate and estimated reward probability on trial <italic>t</italic> are then computed as the weighted average of all particles, with the weights given by <inline-formula><alternatives><mml:math id="inf70"><mml:msubsup><mml:mrow><mml:mi>b</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow><mml:mrow><mml:mi>l</mml:mi></mml:mrow></mml:msubsup></mml:math><tex-math id="inft70">\begin{document}$b_{t}^{l}$\end{document}</tex-math></alternatives></inline-formula>.</p><p>In the simulations, the reward probability followed those of our task with outcome variance set to 0.01 for low outcome noise (20/80% reward probability), 0.02 for high outcome noise (30/70% reward probability), and 0.05 for random reward probabilities. The stochasticity for the lesioned models in the simulations was assumed to be 0.001. For simulating choice, we used the softmax with a decision noise of 3.</p></sec></sec></sec><sec id="s4-5"><title>Data analysis</title><p>We analyzed drug effects on behavioral performance and model parameters using paired <italic>t</italic> tests. Given the effects of initial performance and practice in pharmacological imaging research (<xref ref-type="bibr" rid="bib28">Garrett et al., 2015</xref>), we additionally stratified MA effects by task performance in the orientation using median split. These data were analyzed using a two-way repeated-measures ANOVA with the factors Drug (two levels) and Baseline Performance (two levels). Paired <italic>t</italic>-tests were used as post hoc tests. Moreover, we investigated reversal learning by calculating learning curves. Post hoc, we observed that drug effects on learning became only apparent in the second phase of learning. We therefore used the Bai–Perrin multiple breakpoint test (<xref ref-type="bibr" rid="bib4">Bai and Perron, 2003</xref>) to identify the number and location of structural breaks in the learning curves. In broad strokes, the test detects whether breaks in a curve exist, and if so, how many there are, based on the regression slope in predefined segments (here, we set the segment length to five trials). In our case, the test could reveal between 0 and 5 breaks (number of trials/segment length − 1). We run this test using data from all subjects and all sessions. The test detected one break that cut the learning curves into two segments (see results). We then calculated an index of learning performance after reversals by averaging the number of correct choices over the second learning phase. The index was then subjected to a two-way repeated ANOVA with the factors Drug (two levels) and Baseline Performance (two levels).</p></sec></sec></body><back><sec sec-type="additional-information" id="s5"><title>Additional information</title><fn-group content-type="competing-interest"><title>Competing interests</title><fn fn-type="COI-statement" id="conf1"><p>No competing interests declared</p></fn><fn fn-type="COI-statement" id="conf2"><p>is on the Board of Directors of PharmAla Biotech, and on scientific advisory committees of Gilgamesh Pharmaceuticals and MIND Foundation. These activities are unrelated to the present study</p></fn></fn-group><fn-group content-type="author-contribution"><title>Author contributions</title><fn fn-type="con" id="con1"><p>Conceptualization, Formal analysis, Visualization, Writing – original draft, Writing – review and editing</p></fn><fn fn-type="con" id="con2"><p>Conceptualization, Visualization, Writing – original draft, Project administration, Writing – review and editing</p></fn><fn fn-type="con" id="con3"><p>Supervision, Methodology, Writing – original draft, Writing – review and editing</p></fn><fn fn-type="con" id="con4"><p>Conceptualization, Resources, Supervision, Funding acquisition, Methodology, Writing – original draft, Project administration, Writing – review and editing</p></fn><fn fn-type="con" id="con5"><p>Conceptualization, Resources, Supervision, Methodology, Writing – original draft, Writing – review and editing</p></fn></fn-group><fn-group content-type="ethics-information"><title>Ethics</title><fn fn-type="other"><p>Clinical trial registration <ext-link ext-link-type="uri" xlink:href="https://clinicaltrials.gov/">clinicaltrials.gov</ext-link> ID number NCT04642820.</p></fn><fn fn-type="other"><p>Informed consent, including consent to publish, was obtained from all participants. The study was approved by the Institutional Review Board of the University of Chicago.</p></fn></fn-group></sec><sec sec-type="supplementary-material" id="s6"><title>Additional files</title><supplementary-material id="mdar"><label>MDAR checklist</label><media xlink:href="elife-101413-mdarchecklist1-v1.docx" mimetype="application" mime-subtype="docx"/></supplementary-material></sec><sec sec-type="data-availability" id="s7"><title>Data availability</title><p>All raw data and analysis scripts can be accessed at: <ext-link ext-link-type="uri" xlink:href="https://github.com/HansKirschner/REFIT_Chicago_public">https://github.com/HansKirschner/REFIT_Chicago_public</ext-link> (copy archived at <xref ref-type="bibr" rid="bib42">Kirschner, 2025</xref>).</p></sec><ack id="ack"><title>Acknowledgements</title><p>We thank all our participants who took part in this research for the generosity of their time and commitment. This research was supported by the National Institute on Drug Abuse DA02812. HdW was supported by the National Institutes of Health T32 GM07019. MU was supported by the Deutsche Forschungsgemeinschaft, Grant/Award Number: SFB 1436; and the European Research Council, Grant/Award Number: 101018805.</p></ack><ref-list><title>References</title><ref id="bib1"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Arnsten</surname><given-names>AFT</given-names></name><name><surname>Pliszka</surname><given-names>SR</given-names></name></person-group><year iso-8601-date="2011">2011</year><article-title>Catecholamine influences on prefrontal cortical function: relevance to treatment of attention deficit/hyperactivity disorder and related disorders</article-title><source>Pharmacology, Biochemistry, and Behavior</source><volume>99</volume><fpage>211</fpage><lpage>216</lpage><pub-id pub-id-type="doi">10.1016/j.pbb.2011.01.020</pub-id><pub-id pub-id-type="pmid">21295057</pub-id></element-citation></ref><ref id="bib2"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Arria</surname><given-names>AM</given-names></name><name><surname>Caldeira</surname><given-names>KM</given-names></name><name><surname>Vincent</surname><given-names>KB</given-names></name><name><surname>O’Grady</surname><given-names>KE</given-names></name><name><surname>Cimini</surname><given-names>MD</given-names></name><name><surname>Geisner</surname><given-names>IM</given-names></name><name><surname>Fossos-Wong</surname><given-names>N</given-names></name><name><surname>Kilmer</surname><given-names>JR</given-names></name><name><surname>Larimer</surname><given-names>ME</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>Do college students improve their grades by using prescription stimulants nonmedically?</article-title><source>Addictive Behaviors</source><volume>65</volume><fpage>245</fpage><lpage>249</lpage><pub-id pub-id-type="doi">10.1016/j.addbeh.2016.07.016</pub-id><pub-id pub-id-type="pmid">27469455</pub-id></element-citation></ref><ref id="bib3"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Badre</surname><given-names>D</given-names></name><name><surname>Frank</surname><given-names>MJ</given-names></name></person-group><year iso-8601-date="2012">2012</year><article-title>Mechanisms of hierarchical reinforcement learning in cortico-striatal circuits 2: evidence from fMRI</article-title><source>Cerebral Cortex</source><volume>22</volume><fpage>527</fpage><lpage>536</lpage><pub-id pub-id-type="doi">10.1093/cercor/bhr117</pub-id><pub-id pub-id-type="pmid">21693491</pub-id></element-citation></ref><ref id="bib4"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bai</surname><given-names>J</given-names></name><name><surname>Perron</surname><given-names>P</given-names></name></person-group><year iso-8601-date="2003">2003</year><article-title>Computation and analysis of multiple structural change models</article-title><source>Journal of Applied Econometrics</source><volume>18</volume><fpage>1</fpage><lpage>22</lpage><pub-id pub-id-type="doi">10.1002/jae.659</pub-id></element-citation></ref><ref id="bib5"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Barnett</surname><given-names>AG</given-names></name><name><surname>van der Pols</surname><given-names>JC</given-names></name><name><surname>Dobson</surname><given-names>AJ</given-names></name></person-group><year iso-8601-date="2005">2005</year><article-title>Regression to the mean: what it is and how to deal with it</article-title><source>International Journal of Epidemiology</source><volume>34</volume><fpage>215</fpage><lpage>220</lpage><pub-id pub-id-type="doi">10.1093/ije/dyh299</pub-id><pub-id pub-id-type="pmid">15333621</pub-id></element-citation></ref><ref id="bib6"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bartels</surname><given-names>C</given-names></name><name><surname>Wegrzyn</surname><given-names>M</given-names></name><name><surname>Wiedl</surname><given-names>A</given-names></name><name><surname>Ackermann</surname><given-names>V</given-names></name><name><surname>Ehrenreich</surname><given-names>H</given-names></name></person-group><year iso-8601-date="2010">2010</year><article-title>Practice effects in healthy adults: a longitudinal study on frequent repetitive cognitive testing</article-title><source>BMC Neuroscience</source><volume>11</volume><elocation-id>118</elocation-id><pub-id pub-id-type="doi">10.1186/1471-2202-11-118</pub-id><pub-id pub-id-type="pmid">20846444</pub-id></element-citation></ref><ref id="bib7"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Behrens</surname><given-names>TEJ</given-names></name><name><surname>Woolrich</surname><given-names>MW</given-names></name><name><surname>Walton</surname><given-names>ME</given-names></name><name><surname>Rushworth</surname><given-names>MFS</given-names></name></person-group><year iso-8601-date="2007">2007</year><article-title>Learning the value of information in an uncertain world</article-title><source>Nature Neuroscience</source><volume>10</volume><fpage>1214</fpage><lpage>1221</lpage><pub-id pub-id-type="doi">10.1038/nn1954</pub-id><pub-id pub-id-type="pmid">17676057</pub-id></element-citation></ref><ref id="bib8"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bowman</surname><given-names>E</given-names></name><name><surname>Coghill</surname><given-names>D</given-names></name><name><surname>Murawski</surname><given-names>C</given-names></name><name><surname>Bossaerts</surname><given-names>P</given-names></name></person-group><year iso-8601-date="2023">2023</year><article-title>Not so smart? “Smart” drugs increase the level but decrease the quality of cognitive effort</article-title><source>Science Advances</source><volume>9</volume><elocation-id>eadd4165</elocation-id><pub-id pub-id-type="doi">10.1126/sciadv.add4165</pub-id><pub-id pub-id-type="pmid">37315143</pub-id></element-citation></ref><ref id="bib9"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Cohen</surname><given-names>JD</given-names></name><name><surname>Servan-Schreiber</surname><given-names>D</given-names></name></person-group><year iso-8601-date="1992">1992</year><article-title>Context, cortex, and dopamine: a connectionist approach to behavior and biology in schizophrenia</article-title><source>Psychological Review</source><volume>99</volume><fpage>45</fpage><lpage>77</lpage><pub-id pub-id-type="doi">10.1037/0033-295x.99.1.45</pub-id><pub-id pub-id-type="pmid">1546118</pub-id></element-citation></ref><ref id="bib10"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Collins</surname><given-names>AGE</given-names></name><name><surname>Frank</surname><given-names>MJ</given-names></name></person-group><year iso-8601-date="2012">2012</year><article-title>How much of reinforcement learning is working memory, not reinforcement learning? A behavioral, computational, and neurogenetic analysis</article-title><source>The European Journal of Neuroscience</source><volume>35</volume><fpage>1024</fpage><lpage>1035</lpage><pub-id pub-id-type="doi">10.1111/j.1460-9568.2011.07980.x</pub-id><pub-id pub-id-type="pmid">22487033</pub-id></element-citation></ref><ref id="bib11"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Collins</surname><given-names>AGE</given-names></name><name><surname>Frank</surname><given-names>MJ</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>Cognitive control over learning: creating, clustering, and generalizing task-set structure</article-title><source>Psychological Review</source><volume>120</volume><fpage>190</fpage><lpage>229</lpage><pub-id pub-id-type="doi">10.1037/a0030852</pub-id><pub-id pub-id-type="pmid">23356780</pub-id></element-citation></ref><ref id="bib12"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Collins</surname><given-names>AGE</given-names></name><name><surname>Frank</surname><given-names>MJ</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Neural signature of hierarchically structured expectations predicts clustering and transfer of rule sets in reinforcement learning</article-title><source>Cognition</source><volume>152</volume><fpage>160</fpage><lpage>169</lpage><pub-id pub-id-type="doi">10.1016/j.cognition.2016.04.002</pub-id><pub-id pub-id-type="pmid">27082659</pub-id></element-citation></ref><ref id="bib13"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Collins</surname><given-names>AGE</given-names></name><name><surname>Frank</surname><given-names>MJ</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>Within- and across-trial dynamics of human EEG reveal cooperative interplay between reinforcement learning and working memory</article-title><source>PNAS</source><volume>115</volume><fpage>2502</fpage><lpage>2507</lpage><pub-id pub-id-type="doi">10.1073/pnas.1720963115</pub-id><pub-id pub-id-type="pmid">29463751</pub-id></element-citation></ref><ref id="bib14"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Cook</surname><given-names>JL</given-names></name><name><surname>Swart</surname><given-names>JC</given-names></name><name><surname>Froböse</surname><given-names>MI</given-names></name><name><surname>Diaconescu</surname><given-names>AO</given-names></name><name><surname>Geurts</surname><given-names>DE</given-names></name><name><surname>den Ouden</surname><given-names>HE</given-names></name><name><surname>Cools</surname><given-names>R</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>Catecholaminergic modulation of meta-learning</article-title><source>eLife</source><volume>8</volume><elocation-id>e51439</elocation-id><pub-id pub-id-type="doi">10.7554/eLife.51439</pub-id><pub-id pub-id-type="pmid">31850844</pub-id></element-citation></ref><ref id="bib15"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Cools</surname><given-names>R</given-names></name></person-group><year iso-8601-date="2008">2008</year><article-title>Role of dopamine in the motivational and cognitive control of behavior</article-title><source>The Neuroscientist</source><volume>14</volume><fpage>381</fpage><lpage>395</lpage><pub-id pub-id-type="doi">10.1177/1073858408317009</pub-id><pub-id pub-id-type="pmid">18660464</pub-id></element-citation></ref><ref id="bib16"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Cools</surname><given-names>R</given-names></name><name><surname>D’Esposito</surname><given-names>M</given-names></name></person-group><year iso-8601-date="2011">2011</year><article-title>Inverted-U-shaped dopamine actions on human working memory and cognitive control</article-title><source>Biological Psychiatry</source><volume>69</volume><fpage>e113</fpage><lpage>e125</lpage><pub-id pub-id-type="doi">10.1016/j.biopsych.2011.03.028</pub-id><pub-id pub-id-type="pmid">21531388</pub-id></element-citation></ref><ref id="bib17"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Diederen</surname><given-names>KMJ</given-names></name><name><surname>Spencer</surname><given-names>T</given-names></name><name><surname>Vestergaard</surname><given-names>MD</given-names></name><name><surname>Fletcher</surname><given-names>PC</given-names></name><name><surname>Schultz</surname><given-names>W</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Adaptive prediction error coding in the human midbrain and striatum facilitates behavioral adaptation and learning efficiency</article-title><source>Neuron</source><volume>90</volume><fpage>1127</fpage><lpage>1138</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2016.04.019</pub-id><pub-id pub-id-type="pmid">27181060</pub-id></element-citation></ref><ref id="bib18"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Dodds</surname><given-names>CM</given-names></name><name><surname>Müller</surname><given-names>U</given-names></name><name><surname>Clark</surname><given-names>L</given-names></name><name><surname>van Loon</surname><given-names>A</given-names></name><name><surname>Cools</surname><given-names>R</given-names></name><name><surname>Robbins</surname><given-names>TW</given-names></name></person-group><year iso-8601-date="2008">2008</year><article-title>Methylphenidate has differential effects on blood oxygenation level-dependent signal related to cognitive subprocesses of reversal learning</article-title><source>The Journal of Neuroscience</source><volume>28</volume><fpage>5976</fpage><lpage>5982</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.1153-08.2008</pub-id><pub-id pub-id-type="pmid">18524902</pub-id></element-citation></ref><ref id="bib19"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Doucet</surname><given-names>A</given-names></name><name><surname>Johansen</surname><given-names>AM</given-names></name></person-group><year iso-8601-date="2011">2011</year><source>A Tutorial on Particle Filtering and Smoothing: Fifteen Years Later</source><publisher-name>Oxford University Press</publisher-name><pub-id pub-id-type="doi">10.1093/oxfordhb/9780199571888.013.0010</pub-id></element-citation></ref><ref id="bib20"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Doya</surname><given-names>K</given-names></name></person-group><year iso-8601-date="2002">2002</year><article-title>Metalearning and neuromodulation</article-title><source>Neural Networks</source><volume>15</volume><fpage>495</fpage><lpage>506</lpage><pub-id pub-id-type="doi">10.1016/s0893-6080(02)00044-8</pub-id><pub-id pub-id-type="pmid">12371507</pub-id></element-citation></ref><ref id="bib21"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Dreisbach</surname><given-names>G</given-names></name><name><surname>Müller</surname><given-names>J</given-names></name><name><surname>Goschke</surname><given-names>T</given-names></name><name><surname>Strobel</surname><given-names>A</given-names></name><name><surname>Schulze</surname><given-names>K</given-names></name><name><surname>Lesch</surname><given-names>KP</given-names></name><name><surname>Brocke</surname><given-names>B</given-names></name></person-group><year iso-8601-date="2005">2005</year><article-title>Dopamine and cognitive control: the influence of spontaneous eyeblink rate and dopamine gene polymorphisms on perseveration and distractibility</article-title><source>Behavioral Neuroscience</source><volume>119</volume><fpage>483</fpage><lpage>490</lpage><pub-id pub-id-type="doi">10.1037/0735-7044.119.2.483</pub-id><pub-id pub-id-type="pmid">15839794</pub-id></element-citation></ref><ref id="bib22"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Durstewitz</surname><given-names>D</given-names></name><name><surname>Seamans</surname><given-names>JK</given-names></name></person-group><year iso-8601-date="2008">2008</year><article-title>The dual-state theory of prefrontal cortex dopamine function with relevance to catechol-o-methyltransferase genotypes and schizophrenia</article-title><source>Biological Psychiatry</source><volume>64</volume><fpage>739</fpage><lpage>749</lpage><pub-id pub-id-type="doi">10.1016/j.biopsych.2008.05.015</pub-id><pub-id pub-id-type="pmid">18620336</pub-id></element-citation></ref><ref id="bib23"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Esterman</surname><given-names>M</given-names></name><name><surname>Noonan</surname><given-names>SK</given-names></name><name><surname>Rosenberg</surname><given-names>M</given-names></name><name><surname>Degutis</surname><given-names>J</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>In the zone or zoning out? Tracking behavioral and neural fluctuations during sustained attention</article-title><source>Cerebral Cortex</source><volume>23</volume><fpage>2712</fpage><lpage>2723</lpage><pub-id pub-id-type="doi">10.1093/cercor/bhs261</pub-id><pub-id pub-id-type="pmid">22941724</pub-id></element-citation></ref><ref id="bib24"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Fallon</surname><given-names>SJ</given-names></name><name><surname>van der Schaaf</surname><given-names>ME</given-names></name><name><surname>Ter Huurne</surname><given-names>N</given-names></name><name><surname>Cools</surname><given-names>R</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>The neurocognitive cost of enhancing cognition with methylphenidate: improved distractor resistance but impaired updating</article-title><source>Journal of Cognitive Neuroscience</source><volume>29</volume><fpage>652</fpage><lpage>663</lpage><pub-id pub-id-type="doi">10.1162/jocn_a_01065</pub-id><pub-id pub-id-type="pmid">27779907</pub-id></element-citation></ref><ref id="bib25"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Fischer</surname><given-names>AG</given-names></name><name><surname>Ullsperger</surname><given-names>M</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>Real and fictive outcomes are processed differently but converge on a common adaptive mechanism</article-title><source>Neuron</source><volume>79</volume><fpage>1243</fpage><lpage>1255</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2013.07.006</pub-id><pub-id pub-id-type="pmid">24050408</pub-id></element-citation></ref><ref id="bib26"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Floresco</surname><given-names>SB</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>Prefrontal dopamine and behavioral flexibility: shifting from an “inverted-U” toward a family of functions</article-title><source>Frontiers in Neuroscience</source><volume>7</volume><elocation-id>62</elocation-id><pub-id pub-id-type="doi">10.3389/fnins.2013.00062</pub-id><pub-id pub-id-type="pmid">23626521</pub-id></element-citation></ref><ref id="bib27"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Gamerman</surname><given-names>D</given-names></name><name><surname>dos Santos</surname><given-names>TR</given-names></name><name><surname>Franco</surname><given-names>GC</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>A non‐gaussian family of state‐space models with exact marginal likelihood</article-title><source>Journal of Time Series Analysis</source><volume>34</volume><fpage>625</fpage><lpage>645</lpage><pub-id pub-id-type="doi">10.1111/jtsa.12039</pub-id></element-citation></ref><ref id="bib28"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Garrett</surname><given-names>DD</given-names></name><name><surname>Nagel</surname><given-names>IE</given-names></name><name><surname>Preuschhof</surname><given-names>C</given-names></name><name><surname>Burzynska</surname><given-names>AZ</given-names></name><name><surname>Marchner</surname><given-names>J</given-names></name><name><surname>Wiegert</surname><given-names>S</given-names></name><name><surname>Jungehülsing</surname><given-names>GJ</given-names></name><name><surname>Nyberg</surname><given-names>L</given-names></name><name><surname>Villringer</surname><given-names>A</given-names></name><name><surname>Li</surname><given-names>SC</given-names></name><name><surname>Heekeren</surname><given-names>HR</given-names></name><name><surname>Bäckman</surname><given-names>L</given-names></name><name><surname>Lindenberger</surname><given-names>U</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>Amphetamine modulates brain signal variability and working memory in younger and older adults</article-title><source>PNAS</source><volume>112</volume><fpage>7593</fpage><lpage>7598</lpage><pub-id pub-id-type="doi">10.1073/pnas.1504090112</pub-id><pub-id pub-id-type="pmid">26034283</pub-id></element-citation></ref><ref id="bib29"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Goschke</surname><given-names>T</given-names></name></person-group><year iso-8601-date="2013">2013</year><chapter-title>Volition in action: intentions, control dilemmas, and the dynamic regulation of cognitive control</chapter-title><person-group person-group-type="editor"><name><surname>Prinz</surname><given-names>W</given-names></name><name><surname>Beisert</surname><given-names>M</given-names></name><name><surname>Herwig</surname><given-names>A</given-names></name></person-group><source>Action Science: Foundations of an Emerging Discipline</source><publisher-name>The MIT Press</publisher-name><fpage>409</fpage><lpage>434</lpage><pub-id pub-id-type="doi">10.7551/mitpress/9780262018555.003.0024</pub-id></element-citation></ref><ref id="bib30"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Goschke</surname><given-names>T</given-names></name><name><surname>Bolte</surname><given-names>A</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>Emotional modulation of control dilemmas: the role of positive affect, reward, and dopamine in cognitive stability and flexibility</article-title><source>Neuropsychologia</source><volume>62</volume><fpage>403</fpage><lpage>423</lpage><pub-id pub-id-type="doi">10.1016/j.neuropsychologia.2014.07.015</pub-id><pub-id pub-id-type="pmid">25068705</pub-id></element-citation></ref><ref id="bib31"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Goschke</surname><given-names>T</given-names></name><name><surname>Bolte</surname><given-names>A</given-names></name></person-group><year iso-8601-date="2018">2018</year><chapter-title>A dynamic perspective on intention, conflict, and volition: adaptive regulation and emotional modulation of cognitive control dilemmas</chapter-title><person-group person-group-type="editor"><name><surname>Goschke</surname><given-names>T</given-names></name></person-group><source>Why People Do the Things They Do: Building on Julius Kuhl’s Contributions to the Psychology of Motivation and Volition</source><publisher-name>Hogrefe</publisher-name><fpage>111</fpage><lpage>129</lpage><pub-id pub-id-type="doi">10.1027/00540-000</pub-id></element-citation></ref><ref id="bib32"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Grossman</surname><given-names>CD</given-names></name><name><surname>Bari</surname><given-names>BA</given-names></name><name><surname>Cohen</surname><given-names>JY</given-names></name></person-group><year iso-8601-date="2022">2022</year><article-title>Serotonin neurons modulate learning rate through uncertainty</article-title><source>Current Biology</source><volume>32</volume><fpage>586</fpage><lpage>599</lpage><pub-id pub-id-type="doi">10.1016/j.cub.2021.12.006</pub-id><pub-id pub-id-type="pmid">34936883</pub-id></element-citation></ref><ref id="bib33"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Husain</surname><given-names>M</given-names></name><name><surname>Mehta</surname><given-names>MA</given-names></name></person-group><year iso-8601-date="2011">2011</year><article-title>Cognitive enhancement by drugs in health and disease</article-title><source>Trends in Cognitive Sciences</source><volume>15</volume><fpage>28</fpage><lpage>36</lpage><pub-id pub-id-type="doi">10.1016/j.tics.2010.11.002</pub-id><pub-id pub-id-type="pmid">21146447</pub-id></element-citation></ref><ref id="bib34"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Iigaya</surname><given-names>K</given-names></name><name><surname>Fonseca</surname><given-names>MS</given-names></name><name><surname>Murakami</surname><given-names>M</given-names></name><name><surname>Mainen</surname><given-names>ZF</given-names></name><name><surname>Dayan</surname><given-names>P</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>An effect of serotonergic stimulation on learning rates for rewards apparent after long intertrial intervals</article-title><source>Nature Communications</source><volume>9</volume><elocation-id>2477</elocation-id><pub-id pub-id-type="doi">10.1038/s41467-018-04840-2</pub-id><pub-id pub-id-type="pmid">29946069</pub-id></element-citation></ref><ref id="bib35"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ilieva</surname><given-names>I</given-names></name><name><surname>Boland</surname><given-names>J</given-names></name><name><surname>Farah</surname><given-names>MJ</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>Objective and subjective cognitive enhancing effects of mixed amphetamine salts in healthy people</article-title><source>Neuropharmacology</source><volume>64</volume><fpage>496</fpage><lpage>505</lpage><pub-id pub-id-type="doi">10.1016/j.neuropharm.2012.07.021</pub-id><pub-id pub-id-type="pmid">22884611</pub-id></element-citation></ref><ref id="bib36"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Jang</surname><given-names>AI</given-names></name><name><surname>Nassar</surname><given-names>MR</given-names></name><name><surname>Dillon</surname><given-names>DG</given-names></name><name><surname>Frank</surname><given-names>MJ</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>Positive reward prediction errors during decision-making strengthen memory encoding</article-title><source>Nature Human Behaviour</source><volume>3</volume><fpage>719</fpage><lpage>732</lpage><pub-id pub-id-type="doi">10.1038/s41562-019-0597-3</pub-id><pub-id pub-id-type="pmid">31061490</pub-id></element-citation></ref><ref id="bib37"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Jenkins</surname><given-names>DG</given-names></name><name><surname>Quintana-Ascencio</surname><given-names>PF</given-names></name></person-group><year iso-8601-date="2020">2020</year><article-title>A solution to minimum sample size for regressions</article-title><source>PLOS ONE</source><volume>15</volume><elocation-id>e0229345</elocation-id><pub-id pub-id-type="doi">10.1371/journal.pone.0229345</pub-id><pub-id pub-id-type="pmid">32084211</pub-id></element-citation></ref><ref id="bib38"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Jocham</surname><given-names>G</given-names></name><name><surname>Klein</surname><given-names>TA</given-names></name><name><surname>Ullsperger</surname><given-names>M</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>Differential modulation of reinforcement learning by D2 dopamine and NMDA glutamate receptor antagonism</article-title><source>The Journal of Neuroscience</source><volume>34</volume><fpage>13151</fpage><lpage>13162</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.0757-14.2014</pub-id><pub-id pub-id-type="pmid">25253860</pub-id></element-citation></ref><ref id="bib39"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Karamacoska</surname><given-names>D</given-names></name><name><surname>Barry</surname><given-names>RJ</given-names></name><name><surname>Steiner</surname><given-names>GZ</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>Electrophysiological underpinnings of response variability in the Go/NoGo task</article-title><source>International Journal of Psychophysiology</source><volume>134</volume><fpage>159</fpage><lpage>167</lpage><pub-id pub-id-type="doi">10.1016/j.ijpsycho.2018.09.008</pub-id><pub-id pub-id-type="pmid">30266622</pub-id></element-citation></ref><ref id="bib40"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kirschner</surname><given-names>H</given-names></name><name><surname>Fischer</surname><given-names>AG</given-names></name><name><surname>Ullsperger</surname><given-names>M</given-names></name></person-group><year iso-8601-date="2022">2022</year><article-title>Feedback-related EEG dynamics separately reflect decision parameters, biases, and future choices</article-title><source>NeuroImage</source><volume>259</volume><elocation-id>119437</elocation-id><pub-id pub-id-type="doi">10.1016/j.neuroimage.2022.119437</pub-id><pub-id pub-id-type="pmid">35788041</pub-id></element-citation></ref><ref id="bib41"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kirschner</surname><given-names>H</given-names></name><name><surname>Nassar</surname><given-names>MR</given-names></name><name><surname>Fischer</surname><given-names>AG</given-names></name><name><surname>Frodl</surname><given-names>T</given-names></name><name><surname>Meyer-Lotz</surname><given-names>G</given-names></name><name><surname>Froböse</surname><given-names>S</given-names></name><name><surname>Seidenbecher</surname><given-names>S</given-names></name><name><surname>Klein</surname><given-names>TA</given-names></name><name><surname>Ullsperger</surname><given-names>M</given-names></name></person-group><year iso-8601-date="2024">2024</year><article-title>Transdiagnostic inflexible learning dynamics explain deficits in depression and schizophrenia</article-title><source>Brain</source><volume>147</volume><fpage>201</fpage><lpage>214</lpage><pub-id pub-id-type="doi">10.1093/brain/awad362</pub-id><pub-id pub-id-type="pmid">38058203</pub-id></element-citation></ref><ref id="bib42"><element-citation publication-type="software"><person-group person-group-type="author"><name><surname>Kirschner</surname><given-names>H</given-names></name></person-group><year iso-8601-date="2025">2025</year><data-title>REFIT_Chicago_public</data-title><version designator="swh:1:rev:53f8636e474bb001629e4e991aac87ddec167ab0">swh:1:rev:53f8636e474bb001629e4e991aac87ddec167ab0</version><source>Software Heritage</source><ext-link ext-link-type="uri" xlink:href="https://archive.softwareheritage.org/swh:1:dir:0ff554a29158e10a402e7070d1c37f9ec73ef0b3;origin=https://github.com/HansKirschner/REFIT_Chicago_public;visit=swh:1:snp:e14f277ca29101652ebc021cf1d35c4fb4e8aa99;anchor=swh:1:rev:53f8636e474bb001629e4e991aac87ddec167ab0">https://archive.softwareheritage.org/swh:1:dir:0ff554a29158e10a402e7070d1c37f9ec73ef0b3;origin=https://github.com/HansKirschner/REFIT_Chicago_public;visit=swh:1:snp:e14f277ca29101652ebc021cf1d35c4fb4e8aa99;anchor=swh:1:rev:53f8636e474bb001629e4e991aac87ddec167ab0</ext-link></element-citation></ref><ref id="bib43"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kolling</surname><given-names>N</given-names></name><name><surname>Wittmann</surname><given-names>MK</given-names></name><name><surname>Behrens</surname><given-names>TEJ</given-names></name><name><surname>Boorman</surname><given-names>ED</given-names></name><name><surname>Mars</surname><given-names>RB</given-names></name><name><surname>Rushworth</surname><given-names>MFS</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Value, search, persistence and model updating in anterior cingulate cortex</article-title><source>Nature Neuroscience</source><volume>19</volume><fpage>1280</fpage><lpage>1285</lpage><pub-id pub-id-type="doi">10.1038/nn.4382</pub-id><pub-id pub-id-type="pmid">27669988</pub-id></element-citation></ref><ref id="bib44"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Le Pelley</surname><given-names>ME</given-names></name></person-group><year iso-8601-date="2004">2004</year><article-title>The role of associative history in models of associative learning: a selective review and a hybrid model</article-title><source>The Quarterly Journal of Experimental Psychology Section B</source><volume>57</volume><fpage>193</fpage><lpage>243</lpage><pub-id pub-id-type="doi">10.1080/02724990344000141</pub-id></element-citation></ref><ref id="bib45"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Li</surname><given-names>J</given-names></name><name><surname>Schiller</surname><given-names>D</given-names></name><name><surname>Schoenbaum</surname><given-names>G</given-names></name><name><surname>Phelps</surname><given-names>EA</given-names></name><name><surname>Daw</surname><given-names>ND</given-names></name></person-group><year iso-8601-date="2011">2011</year><article-title>Differential roles of human striatum and amygdala in associative learning</article-title><source>Nature Neuroscience</source><volume>14</volume><fpage>1250</fpage><lpage>1252</lpage><pub-id pub-id-type="doi">10.1038/nn.2904</pub-id><pub-id pub-id-type="pmid">21909088</pub-id></element-citation></ref><ref id="bib46"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Lieder</surname><given-names>F</given-names></name><name><surname>Shenhav</surname><given-names>A</given-names></name><name><surname>Musslick</surname><given-names>S</given-names></name><name><surname>Griffiths</surname><given-names>TL</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>Rational metareasoning and the plasticity of cognitive control</article-title><source>PLOS Computational Biology</source><volume>14</volume><elocation-id>e1006043</elocation-id><pub-id pub-id-type="doi">10.1371/journal.pcbi.1006043</pub-id><pub-id pub-id-type="pmid">29694347</pub-id></element-citation></ref><ref id="bib47"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>MacRae</surname><given-names>PG</given-names></name><name><surname>Spirduso</surname><given-names>WW</given-names></name><name><surname>Wilcox</surname><given-names>RE</given-names></name></person-group><year iso-8601-date="1988">1988</year><article-title>Reaction time and nigrostriatal dopamine function: the effects of age and practice</article-title><source>Brain Research</source><volume>451</volume><fpage>139</fpage><lpage>146</lpage><pub-id pub-id-type="doi">10.1016/0006-8993(88)90758-5</pub-id><pub-id pub-id-type="pmid">3251581</pub-id></element-citation></ref><ref id="bib48"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Maris</surname><given-names>E</given-names></name><name><surname>Oostenveld</surname><given-names>R</given-names></name></person-group><year iso-8601-date="2007">2007</year><article-title>Nonparametric statistical testing of EEG- and MEG-data</article-title><source>Journal of Neuroscience Methods</source><volume>164</volume><fpage>177</fpage><lpage>190</lpage><pub-id pub-id-type="doi">10.1016/j.jneumeth.2007.03.024</pub-id><pub-id pub-id-type="pmid">17517438</pub-id></element-citation></ref><ref id="bib49"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Marshall</surname><given-names>L</given-names></name><name><surname>Mathys</surname><given-names>C</given-names></name><name><surname>Ruge</surname><given-names>D</given-names></name><name><surname>de Berker</surname><given-names>AO</given-names></name><name><surname>Dayan</surname><given-names>P</given-names></name><name><surname>Stephan</surname><given-names>KE</given-names></name><name><surname>Bestmann</surname><given-names>S</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Pharmacological fingerprints of contextual uncertainty</article-title><source>PLOS Biology</source><volume>14</volume><elocation-id>e1002575</elocation-id><pub-id pub-id-type="doi">10.1371/journal.pbio.1002575</pub-id><pub-id pub-id-type="pmid">27846219</pub-id></element-citation></ref><ref id="bib50"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Meder</surname><given-names>D</given-names></name><name><surname>Kolling</surname><given-names>N</given-names></name><name><surname>Verhagen</surname><given-names>L</given-names></name><name><surname>Wittmann</surname><given-names>MK</given-names></name><name><surname>Scholl</surname><given-names>J</given-names></name><name><surname>Madsen</surname><given-names>KH</given-names></name><name><surname>Hulme</surname><given-names>OJ</given-names></name><name><surname>Behrens</surname><given-names>TEJ</given-names></name><name><surname>Rushworth</surname><given-names>MFS</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>Simultaneous representation of a spectrum of dynamically changing value estimates during decision making</article-title><source>Nature Communications</source><volume>8</volume><elocation-id>1942</elocation-id><pub-id pub-id-type="doi">10.1038/s41467-017-02169-w</pub-id><pub-id pub-id-type="pmid">29208968</pub-id></element-citation></ref><ref id="bib51"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Morean</surname><given-names>ME</given-names></name><name><surname>de Wit</surname><given-names>H</given-names></name><name><surname>King</surname><given-names>AC</given-names></name><name><surname>Sofuoglu</surname><given-names>M</given-names></name><name><surname>Rueger</surname><given-names>SY</given-names></name><name><surname>O’Malley</surname><given-names>SS</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>The drug effects questionnaire: psychometric support across three drug types</article-title><source>Psychopharmacology</source><volume>227</volume><fpage>177</fpage><lpage>192</lpage><pub-id pub-id-type="doi">10.1007/s00213-012-2954-z</pub-id><pub-id pub-id-type="pmid">23271193</pub-id></element-citation></ref><ref id="bib52"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Muller</surname><given-names>TH</given-names></name><name><surname>Mars</surname><given-names>RB</given-names></name><name><surname>Behrens</surname><given-names>TE</given-names></name><name><surname>O’Reilly</surname><given-names>JX</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>Control of entropy in neural models of environmental state</article-title><source>eLife</source><volume>8</volume><elocation-id>e39404</elocation-id><pub-id pub-id-type="doi">10.7554/eLife.39404</pub-id><pub-id pub-id-type="pmid">30816090</pub-id></element-citation></ref><ref id="bib53"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Murphy</surname><given-names>K</given-names></name><name><surname>Russell</surname><given-names>S</given-names></name></person-group><year iso-8601-date="2001">2001</year><chapter-title>Rao-blackwellised particle filtering for dynamic bayesian networks</chapter-title><person-group person-group-type="editor"><name><surname>Russell</surname><given-names>S</given-names></name></person-group><source>Sequential Monte Carlo Methods in Practice</source><publisher-name>Springer</publisher-name><fpage>499</fpage><lpage>515</lpage><pub-id pub-id-type="doi">10.1007/978-1-4757-3437-9_24</pub-id></element-citation></ref><ref id="bib54"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Nassar</surname><given-names>MR</given-names></name><name><surname>Wilson</surname><given-names>RC</given-names></name><name><surname>Heasly</surname><given-names>B</given-names></name><name><surname>Gold</surname><given-names>JI</given-names></name></person-group><year iso-8601-date="2010">2010</year><article-title>An approximately Bayesian delta-rule model explains the dynamics of belief updating in a changing environment</article-title><source>The Journal of Neuroscience</source><volume>30</volume><fpage>12366</fpage><lpage>12378</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.0822-10.2010</pub-id><pub-id pub-id-type="pmid">20844132</pub-id></element-citation></ref><ref id="bib55"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Nassar</surname><given-names>MR</given-names></name><name><surname>Rumsey</surname><given-names>KM</given-names></name><name><surname>Wilson</surname><given-names>RC</given-names></name><name><surname>Parikh</surname><given-names>K</given-names></name><name><surname>Heasly</surname><given-names>B</given-names></name><name><surname>Gold</surname><given-names>JI</given-names></name></person-group><year iso-8601-date="2012">2012</year><article-title>Rational regulation of learning dynamics by pupil-linked arousal systems</article-title><source>Nature Neuroscience</source><volume>15</volume><fpage>1040</fpage><lpage>1046</lpage><pub-id pub-id-type="doi">10.1038/nn.3130</pub-id><pub-id pub-id-type="pmid">22660479</pub-id></element-citation></ref><ref id="bib56"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Nassar</surname><given-names>MR</given-names></name><name><surname>Bruckner</surname><given-names>R</given-names></name><name><surname>Gold</surname><given-names>JI</given-names></name><name><surname>Li</surname><given-names>SC</given-names></name><name><surname>Heekeren</surname><given-names>HR</given-names></name><name><surname>Eppinger</surname><given-names>B</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Age differences in learning emerge from an insufficient representation of uncertainty in older adults</article-title><source>Nature Communications</source><volume>7</volume><elocation-id>11609</elocation-id><pub-id pub-id-type="doi">10.1038/ncomms11609</pub-id><pub-id pub-id-type="pmid">27282467</pub-id></element-citation></ref><ref id="bib57"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Nassar</surname><given-names>MR</given-names></name><name><surname>Bruckner</surname><given-names>R</given-names></name><name><surname>Frank</surname><given-names>MJ</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>Statistical context dictates the relationship between feedback-related EEG signals and learning</article-title><source>eLife</source><volume>8</volume><elocation-id>e46975</elocation-id><pub-id pub-id-type="doi">10.7554/eLife.46975</pub-id><pub-id pub-id-type="pmid">31433294</pub-id></element-citation></ref><ref id="bib58"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Nassar</surname><given-names>MR</given-names></name><name><surname>Waltz</surname><given-names>JA</given-names></name><name><surname>Albrecht</surname><given-names>MA</given-names></name><name><surname>Gold</surname><given-names>JM</given-names></name><name><surname>Frank</surname><given-names>MJ</given-names></name></person-group><year iso-8601-date="2021">2021</year><article-title>All or nothing belief updating in patients with schizophrenia reduces precision and flexibility of beliefs</article-title><source>Brain</source><volume>144</volume><fpage>1013</fpage><lpage>1029</lpage><pub-id pub-id-type="doi">10.1093/brain/awaa453</pub-id><pub-id pub-id-type="pmid">33434284</pub-id></element-citation></ref><ref id="bib59"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Owesson-White</surname><given-names>CA</given-names></name><name><surname>Cheer</surname><given-names>JF</given-names></name><name><surname>Beyene</surname><given-names>M</given-names></name><name><surname>Carelli</surname><given-names>RM</given-names></name><name><surname>Wightman</surname><given-names>RM</given-names></name></person-group><year iso-8601-date="2008">2008</year><article-title>Dynamic changes in accumbens dopamine correlate with learning during intracranial self-stimulation</article-title><source>PNAS</source><volume>105</volume><fpage>11957</fpage><lpage>11962</lpage><pub-id pub-id-type="doi">10.1073/pnas.0803896105</pub-id><pub-id pub-id-type="pmid">18689678</pub-id></element-citation></ref><ref id="bib60"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Pasupathy</surname><given-names>A</given-names></name><name><surname>Miller</surname><given-names>EK</given-names></name></person-group><year iso-8601-date="2005">2005</year><article-title>Different time courses of learning-related activity in the prefrontal cortex and striatum</article-title><source>Nature</source><volume>433</volume><fpage>873</fpage><lpage>876</lpage><pub-id pub-id-type="doi">10.1038/nature03287</pub-id><pub-id pub-id-type="pmid">15729344</pub-id></element-citation></ref><ref id="bib61"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Piray</surname><given-names>P</given-names></name><name><surname>Ly</surname><given-names>V</given-names></name><name><surname>Roelofs</surname><given-names>K</given-names></name><name><surname>Cools</surname><given-names>R</given-names></name><name><surname>Toni</surname><given-names>I</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>Emotionally aversive cues suppress neural systems underlying optimal learning in socially anxious individuals</article-title><source>The Journal of Neuroscience</source><volume>39</volume><fpage>1445</fpage><lpage>1456</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.1394-18.2018</pub-id><pub-id pub-id-type="pmid">30559152</pub-id></element-citation></ref><ref id="bib62"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Piray</surname><given-names>P</given-names></name><name><surname>Daw</surname><given-names>ND</given-names></name></person-group><year iso-8601-date="2020">2020</year><article-title>A simple model for learning in volatile environments</article-title><source>PLOS Computational Biology</source><volume>16</volume><elocation-id>e1007963</elocation-id><pub-id pub-id-type="doi">10.1371/journal.pcbi.1007963</pub-id><pub-id pub-id-type="pmid">32609755</pub-id></element-citation></ref><ref id="bib63"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Piray</surname><given-names>P</given-names></name><name><surname>Daw</surname><given-names>ND</given-names></name></person-group><year iso-8601-date="2021">2021</year><article-title>A model for learning based on the joint estimation of stochasticity and volatility</article-title><source>Nature Communications</source><volume>12</volume><elocation-id>6587</elocation-id><pub-id pub-id-type="doi">10.1038/s41467-021-26731-9</pub-id><pub-id pub-id-type="pmid">34782597</pub-id></element-citation></ref><ref id="bib64"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Piray</surname><given-names>P</given-names></name><name><surname>Daw</surname><given-names>ND</given-names></name></person-group><year iso-8601-date="2024">2024</year><article-title>Computational processes of simultaneous learning of stochasticity and volatility in humans</article-title><source>Nature Communications</source><volume>15</volume><elocation-id>9073</elocation-id><pub-id pub-id-type="doi">10.1038/s41467-024-53459-z</pub-id><pub-id pub-id-type="pmid">39433765</pub-id></element-citation></ref><ref id="bib65"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Preuschoff</surname><given-names>K</given-names></name><name><surname>’t Hart</surname><given-names>BM</given-names></name><name><surname>Einhäuser</surname><given-names>W</given-names></name></person-group><year iso-8601-date="2011">2011</year><article-title>Pupil dilation signals surprise: evidence for noradrenaline’s role in decision making</article-title><source>Frontiers in Neuroscience</source><volume>5</volume><elocation-id>115</elocation-id><pub-id pub-id-type="doi">10.3389/fnins.2011.00115</pub-id><pub-id pub-id-type="pmid">21994487</pub-id></element-citation></ref><ref id="bib66"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Prince</surname><given-names>J</given-names></name></person-group><year iso-8601-date="2008">2008</year><article-title>Catecholamine dysfunction in attention-deficit/hyperactivity disorder: an update</article-title><source>Journal of Clinical Psychopharmacology</source><volume>28</volume><fpage>S39</fpage><lpage>S45</lpage><pub-id pub-id-type="doi">10.1097/JCP.0b013e318174f92a</pub-id><pub-id pub-id-type="pmid">18480676</pub-id></element-citation></ref><ref id="bib67"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Razmi</surname><given-names>N</given-names></name><name><surname>Nassar</surname><given-names>MR</given-names></name></person-group><year iso-8601-date="2022">2022</year><article-title>Adaptive learning through temporal dynamics of state representation</article-title><source>The Journal of Neuroscience</source><volume>42</volume><fpage>2524</fpage><lpage>2538</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.0387-21.2022</pub-id><pub-id pub-id-type="pmid">35105677</pub-id></element-citation></ref><ref id="bib68"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Repantis</surname><given-names>D</given-names></name><name><surname>Schlattmann</surname><given-names>P</given-names></name><name><surname>Laisney</surname><given-names>O</given-names></name><name><surname>Heuser</surname><given-names>I</given-names></name></person-group><year iso-8601-date="2010">2010</year><article-title>Modafinil and methylphenidate for neuroenhancement in healthy individuals: A systematic review</article-title><source>Pharmacological Research</source><volume>62</volume><fpage>187</fpage><lpage>206</lpage><pub-id pub-id-type="doi">10.1016/j.phrs.2010.04.002</pub-id><pub-id pub-id-type="pmid">20416377</pub-id></element-citation></ref><ref id="bib69"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Rigoux</surname><given-names>L</given-names></name><name><surname>Stephan</surname><given-names>KE</given-names></name><name><surname>Friston</surname><given-names>KJ</given-names></name><name><surname>Daunizeau</surname><given-names>J</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>Bayesian model selection for group studies - revisited</article-title><source>NeuroImage</source><volume>84</volume><fpage>971</fpage><lpage>985</lpage><pub-id pub-id-type="doi">10.1016/j.neuroimage.2013.08.065</pub-id><pub-id pub-id-type="pmid">24018303</pub-id></element-citation></ref><ref id="bib70"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Rostami Kandroodi</surname><given-names>M</given-names></name><name><surname>Cook</surname><given-names>JL</given-names></name><name><surname>Swart</surname><given-names>JC</given-names></name><name><surname>Froböse</surname><given-names>MI</given-names></name><name><surname>Geurts</surname><given-names>DEM</given-names></name><name><surname>Vahabie</surname><given-names>A-H</given-names></name><name><surname>Nili Ahmadabadi</surname><given-names>M</given-names></name><name><surname>Cools</surname><given-names>R</given-names></name><name><surname>den Ouden</surname><given-names>HEM</given-names></name></person-group><year iso-8601-date="2021">2021</year><article-title>Effects of methylphenidate on reinforcement learning depend on working memory capacity</article-title><source>Psychopharmacology</source><volume>238</volume><fpage>3569</fpage><lpage>3584</lpage><pub-id pub-id-type="doi">10.1007/s00213-021-05974-w</pub-id><pub-id pub-id-type="pmid">34676440</pub-id></element-citation></ref><ref id="bib71"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Schüller</surname><given-names>T</given-names></name><name><surname>Fischer</surname><given-names>AG</given-names></name><name><surname>Gruendler</surname><given-names>TOJ</given-names></name><name><surname>Baldermann</surname><given-names>JC</given-names></name><name><surname>Huys</surname><given-names>D</given-names></name><name><surname>Ullsperger</surname><given-names>M</given-names></name><name><surname>Kuhn</surname><given-names>J</given-names></name></person-group><year iso-8601-date="2020">2020</year><article-title>Decreased transfer of value to action in Tourette syndrome</article-title><source>Cortex; a Journal Devoted to the Study of the Nervous System and Behavior</source><volume>126</volume><fpage>39</fpage><lpage>48</lpage><pub-id pub-id-type="doi">10.1016/j.cortex.2019.12.027</pub-id><pub-id pub-id-type="pmid">32062469</pub-id></element-citation></ref><ref id="bib72"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Schultz</surname><given-names>W</given-names></name><name><surname>Dayan</surname><given-names>P</given-names></name><name><surname>Montague</surname><given-names>PR</given-names></name></person-group><year iso-8601-date="1997">1997</year><article-title>A neural substrate of prediction and reward</article-title><source>Science</source><volume>275</volume><fpage>1593</fpage><lpage>1599</lpage><pub-id pub-id-type="doi">10.1126/science.275.5306.1593</pub-id><pub-id pub-id-type="pmid">9054347</pub-id></element-citation></ref><ref id="bib73"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Schwarz</surname><given-names>G</given-names></name></person-group><year iso-8601-date="1978">1978</year><article-title>Estimating the dimension of a model</article-title><source>The Annals of Statistics</source><volume>6</volume><fpage>461</fpage><lpage>464</lpage><pub-id pub-id-type="doi">10.1214/aos/1176344136</pub-id></element-citation></ref><ref id="bib74"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Schweighofer</surname><given-names>N</given-names></name><name><surname>Doya</surname><given-names>K</given-names></name></person-group><year iso-8601-date="2003">2003</year><article-title>Meta-learning in reinforcement learning</article-title><source>Neural Networks</source><volume>16</volume><fpage>5</fpage><lpage>9</lpage><pub-id pub-id-type="doi">10.1016/s0893-6080(02)00228-9</pub-id><pub-id pub-id-type="pmid">12576101</pub-id></element-citation></ref><ref id="bib75"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Servan-Schreiber</surname><given-names>D</given-names></name><name><surname>Carter</surname><given-names>CS</given-names></name><name><surname>Bruno</surname><given-names>RM</given-names></name><name><surname>Cohen</surname><given-names>JD</given-names></name></person-group><year iso-8601-date="1998">1998</year><article-title>Dopamine and the mechanisms of cognition: Part II. D-amphetamine effects in human subjects performing a selective attention task</article-title><source>Biological Psychiatry</source><volume>43</volume><fpage>723</fpage><lpage>729</lpage><pub-id pub-id-type="doi">10.1016/s0006-3223(97)00449-6</pub-id><pub-id pub-id-type="pmid">9606525</pub-id></element-citation></ref><ref id="bib76"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Set</surname><given-names>E</given-names></name><name><surname>Saez</surname><given-names>I</given-names></name><name><surname>Zhu</surname><given-names>L</given-names></name><name><surname>Houser</surname><given-names>DE</given-names></name><name><surname>Myung</surname><given-names>N</given-names></name><name><surname>Zhong</surname><given-names>S</given-names></name><name><surname>Ebstein</surname><given-names>RP</given-names></name><name><surname>Chew</surname><given-names>SH</given-names></name><name><surname>Hsu</surname><given-names>M</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>Dissociable contribution of prefrontal and striatal dopaminergic genes to learning in economic games</article-title><source>PNAS</source><volume>111</volume><fpage>9615</fpage><lpage>9620</lpage><pub-id pub-id-type="doi">10.1073/pnas.1316259111</pub-id><pub-id pub-id-type="pmid">24979760</pub-id></element-citation></ref><ref id="bib77"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Silvetti</surname><given-names>M</given-names></name><name><surname>Vassena</surname><given-names>E</given-names></name><name><surname>Abrahamse</surname><given-names>E</given-names></name><name><surname>Verguts</surname><given-names>T</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>Dorsal anterior cingulate-brainstem ensemble as a reinforcement meta-learner</article-title><source>PLOS Computational Biology</source><volume>14</volume><elocation-id>e1006370</elocation-id><pub-id pub-id-type="doi">10.1371/journal.pcbi.1006370</pub-id><pub-id pub-id-type="pmid">30142152</pub-id></element-citation></ref><ref id="bib78"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Smith</surname><given-names>ME</given-names></name><name><surname>Farah</surname><given-names>MJ</given-names></name></person-group><year iso-8601-date="2011">2011</year><article-title>Are prescription stimulants “smart pills”? The epidemiology and cognitive neuroscience of prescription stimulant use by normal healthy individuals</article-title><source>Psychological Bulletin</source><volume>137</volume><fpage>717</fpage><lpage>741</lpage><pub-id pub-id-type="doi">10.1037/a0023825</pub-id><pub-id pub-id-type="pmid">21859174</pub-id></element-citation></ref><ref id="bib79"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Stephan</surname><given-names>KE</given-names></name><name><surname>Penny</surname><given-names>WD</given-names></name><name><surname>Daunizeau</surname><given-names>J</given-names></name><name><surname>Moran</surname><given-names>RJ</given-names></name><name><surname>Friston</surname><given-names>KJ</given-names></name></person-group><year iso-8601-date="2009">2009</year><article-title>Bayesian model selection for group studies</article-title><source>NeuroImage</source><volume>46</volume><fpage>1004</fpage><lpage>1017</lpage><pub-id pub-id-type="doi">10.1016/j.neuroimage.2009.03.025</pub-id><pub-id pub-id-type="pmid">19306932</pub-id></element-citation></ref><ref id="bib80"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Turner</surname><given-names>KM</given-names></name><name><surname>Peak</surname><given-names>J</given-names></name><name><surname>Burne</surname><given-names>THJ</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>Baseline-dependent effects of amphetamine on attention are associated with striatal dopamine metabolism</article-title><source>Scientific Reports</source><volume>7</volume><elocation-id>297</elocation-id><pub-id pub-id-type="doi">10.1038/s41598-017-00437-9</pub-id><pub-id pub-id-type="pmid">28331177</pub-id></element-citation></ref><ref id="bib81"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>van den Bosch</surname><given-names>R</given-names></name><name><surname>Lambregts</surname><given-names>B</given-names></name><name><surname>Määttä</surname><given-names>J</given-names></name><name><surname>Hofmans</surname><given-names>L</given-names></name><name><surname>Papadopetraki</surname><given-names>D</given-names></name><name><surname>Westbrook</surname><given-names>A</given-names></name><name><surname>Verkes</surname><given-names>RJ</given-names></name><name><surname>Booij</surname><given-names>J</given-names></name><name><surname>Cools</surname><given-names>R</given-names></name></person-group><year iso-8601-date="2022">2022</year><article-title>Striatal dopamine dissociates methylphenidate effects on value-based versus surprise-based reversal learning</article-title><source>Nature Communications</source><volume>13</volume><elocation-id>4962</elocation-id><pub-id pub-id-type="doi">10.1038/s41467-022-32679-1</pub-id><pub-id pub-id-type="pmid">36002446</pub-id></element-citation></ref><ref id="bib82"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>van der Schaaf</surname><given-names>ME</given-names></name><name><surname>Fallon</surname><given-names>SJ</given-names></name><name><surname>Ter Huurne</surname><given-names>N</given-names></name><name><surname>Buitelaar</surname><given-names>J</given-names></name><name><surname>Cools</surname><given-names>R</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>Working memory capacity predicts effects of methylphenidate on reversal learning</article-title><source>Neuropsychopharmacology</source><volume>38</volume><fpage>2011</fpage><lpage>2018</lpage><pub-id pub-id-type="doi">10.1038/npp.2013.100</pub-id><pub-id pub-id-type="pmid">23612436</pub-id></element-citation></ref><ref id="bib83"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>van der Schaaf</surname><given-names>ME</given-names></name><name><surname>van Schouwenburg</surname><given-names>MR</given-names></name><name><surname>Geurts</surname><given-names>DEM</given-names></name><name><surname>Schellekens</surname><given-names>AFA</given-names></name><name><surname>Buitelaar</surname><given-names>JK</given-names></name><name><surname>Verkes</surname><given-names>RJ</given-names></name><name><surname>Cools</surname><given-names>R</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>Establishing the dopamine dependency of human striatal signals during reward and punishment reversal learning</article-title><source>Cerebral Cortex</source><volume>24</volume><fpage>633</fpage><lpage>642</lpage><pub-id pub-id-type="doi">10.1093/cercor/bhs344</pub-id><pub-id pub-id-type="pmid">23183711</pub-id></element-citation></ref><ref id="bib84"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Volkow</surname><given-names>ND</given-names></name><name><surname>Wang</surname><given-names>GJ</given-names></name><name><surname>Fowler</surname><given-names>JS</given-names></name><name><surname>Logan</surname><given-names>J</given-names></name><name><surname>Franceschi</surname><given-names>D</given-names></name><name><surname>Maynard</surname><given-names>L</given-names></name><name><surname>Ding</surname><given-names>YS</given-names></name><name><surname>Gatley</surname><given-names>SJ</given-names></name><name><surname>Gifford</surname><given-names>A</given-names></name><name><surname>Zhu</surname><given-names>W</given-names></name><name><surname>Swanson</surname><given-names>JM</given-names></name></person-group><year iso-8601-date="2002">2002</year><article-title>Relationship between blockade of dopamine transporters by oral methylphenidate and the increases in extracellular dopamine: therapeutic implications</article-title><source>Synapse</source><volume>43</volume><fpage>181</fpage><lpage>187</lpage><pub-id pub-id-type="doi">10.1002/syn.10038</pub-id><pub-id pub-id-type="pmid">11793423</pub-id></element-citation></ref><ref id="bib85"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>West</surname><given-names>M</given-names></name></person-group><year iso-8601-date="1987">1987</year><article-title>On scale mixtures of normal distributions</article-title><source>Biometrika</source><volume>74</volume><fpage>646</fpage><lpage>648</lpage><pub-id pub-id-type="doi">10.1093/biomet/74.3.646</pub-id></element-citation></ref><ref id="bib86"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Westbrook</surname><given-names>A</given-names></name><name><surname>van den Bosch</surname><given-names>R</given-names></name><name><surname>Määttä</surname><given-names>JI</given-names></name><name><surname>Hofmans</surname><given-names>L</given-names></name><name><surname>Papadopetraki</surname><given-names>D</given-names></name><name><surname>Cools</surname><given-names>R</given-names></name><name><surname>Frank</surname><given-names>MJ</given-names></name></person-group><year iso-8601-date="2020">2020</year><article-title>Dopamine promotes cognitive effort by biasing the benefits versus costs of cognitive work</article-title><source>Science</source><volume>367</volume><fpage>1362</fpage><lpage>1366</lpage><pub-id pub-id-type="doi">10.1126/science.aaz5891</pub-id><pub-id pub-id-type="pmid">32193325</pub-id></element-citation></ref><ref id="bib87"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>White</surname><given-names>TL</given-names></name><name><surname>Justice</surname><given-names>AJH</given-names></name><name><surname>de Wit</surname><given-names>H</given-names></name></person-group><year iso-8601-date="2002">2002</year><article-title>Differential subjective effects of D-amphetamine by gender, hormone levels and menstrual cycle phase</article-title><source>Pharmacology, Biochemistry, and Behavior</source><volume>73</volume><fpage>729</fpage><lpage>741</lpage><pub-id pub-id-type="doi">10.1016/s0091-3057(02)00818-3</pub-id><pub-id pub-id-type="pmid">12213517</pub-id></element-citation></ref><ref id="bib88"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wilson</surname><given-names>RC</given-names></name><name><surname>Nassar</surname><given-names>MR</given-names></name><name><surname>Gold</surname><given-names>JI</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>A mixture of delta-rules approximation to bayesian inference in change-point problems</article-title><source>PLOS Computational Biology</source><volume>9</volume><elocation-id>e1003150</elocation-id><pub-id pub-id-type="doi">10.1371/journal.pcbi.1003150</pub-id><pub-id pub-id-type="pmid">23935472</pub-id></element-citation></ref><ref id="bib89"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Yu</surname><given-names>AJ</given-names></name><name><surname>Dayan</surname><given-names>P</given-names></name></person-group><year iso-8601-date="2005">2005</year><article-title>Uncertainty, neuromodulation, and attention</article-title><source>Neuron</source><volume>46</volume><fpage>681</fpage><lpage>692</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2005.04.026</pub-id><pub-id pub-id-type="pmid">15944135</pub-id></element-citation></ref><ref id="bib90"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Yu</surname><given-names>LQ</given-names></name><name><surname>Wilson</surname><given-names>RC</given-names></name><name><surname>Nassar</surname><given-names>MR</given-names></name></person-group><year iso-8601-date="2021">2021</year><article-title>Adaptive learning is structure learning in time</article-title><source>Neuroscience and Biobehavioral Reviews</source><volume>128</volume><fpage>270</fpage><lpage>281</lpage><pub-id pub-id-type="doi">10.1016/j.neubiorev.2021.06.024</pub-id><pub-id pub-id-type="pmid">34144114</pub-id></element-citation></ref></ref-list><app-group><app id="appendix-1"><title>Appendix 1</title><sec sec-type="appendix" id="s8"><title>Time-on-task effects</title><p>Given the length of our task, we investigated whether fatigue effects or changes in behavior occurred over time. Specifically, we regressed each participant’s single-trial log-scaled reaction times (RT) and accuracy (a binary variable reflecting whether participants displayed stimulus-appropriate behavior on each trial) onto trial number, which served as a proxy for time on task. The resulting <italic>t</italic>-values for the time-on-task regressor were analyzed at the group level using two-sided <italic>t</italic>-tests against zero and compared across sessions and baseline performance groups. The results of these regression models are presented in <xref ref-type="table" rid="app1table1">Appendix 1—table 1</xref>, with raw data splits shown in <xref ref-type="fig" rid="app1fig1">Appendix 1—figure 1</xref>.</p><p>Our findings indicate that choice behavior was not systematically affected over the course of the task. This effect did not differ between low and high baseline performers and was not influenced by the drug. In contrast, reaction times decreased over the course of the task, with this speeding effect being enhanced by MA, particularly in the low performance group.</p><table-wrap id="app1table1" position="float"><label>Appendix 1—table 1.</label><caption><title>Time-on-task effect on choice and reaction time.</title></caption><table frame="hsides" rules="groups"><thead><tr><th align="left" valign="bottom">Model</th><th align="left" valign="bottom">ToT Coefficient PLMean (SD)</th><th align="left" valign="bottom">ToT Coefficient MAMean (SD)</th><th align="left" valign="bottom">Group comparison</th></tr></thead><tbody><tr><td align="left" valign="bottom">Logistic regression on accuracy</td><td align="left" valign="bottom"/><td align="left" valign="bottom"/><td align="left" valign="bottom"/></tr><tr><td align="left" valign="bottom">All</td><td align="char" char="." valign="bottom">-0.05(0.17)</td><td align="char" char="." valign="bottom">-0.31(0.23)</td><td align="left" valign="bottom">t(93)=0.90, <italic>P</italic>=0.37</td></tr><tr><td align="left" valign="bottom">Low performer</td><td align="char" char="." valign="bottom">-0.18(0.35)</td><td align="char" char="." valign="bottom">0.41(0.25)</td><td align="left" valign="bottom">t(46)=1.61, <italic>P</italic>=0.11</td></tr><tr><td align="left" valign="bottom">High performer</td><td align="char" char="." valign="bottom">-0.43(0.32)</td><td align="char" char="." valign="bottom">-0.51(0.22)</td><td align="left" valign="bottom">t(46)=0.16, <italic>P</italic>=0.86</td></tr><tr><td align="left" valign="bottom">Regression on log(RT)</td><td align="left" valign="bottom"/><td align="left" valign="bottom"/><td align="left" valign="bottom"/></tr><tr><td align="left" valign="bottom">All</td><td align="char" char="." valign="bottom">-1.77(0.42)<xref ref-type="table-fn" rid="app1table1fn2">*</xref></td><td align="char" char="." valign="bottom">-3.09 (0.48)<xref ref-type="table-fn" rid="app1table1fn2">*</xref></td><td align="left" valign="bottom">t(93)=2.28, <italic>P</italic>=0.02</td></tr><tr><td align="left" valign="bottom">Low performer</td><td align="char" char="." valign="bottom">-2.11(0.65)<xref ref-type="table-fn" rid="app1table1fn2">*</xref></td><td align="char" char="." valign="bottom">-4.32(0.65)<xref ref-type="table-fn" rid="app1table1fn2">*</xref></td><td align="left" valign="bottom">t(46)=–2.59, <italic>P</italic>=0.01</td></tr><tr><td align="left" valign="bottom">High performer</td><td align="char" char="." valign="bottom">-1.43(0.54)<xref ref-type="table-fn" rid="app1table1fn2">*</xref></td><td align="char" char="." valign="bottom">-1.85(0.64)<xref ref-type="table-fn" rid="app1table1fn2">*</xref></td><td align="left" valign="bottom">t(46)=–0.55, <italic>P</italic>=0.58</td></tr></tbody></table><table-wrap-foot><fn><p>Note: ToT = time-on-task.</p></fn><fn id="app1table1fn2"><label>*</label><p>average within participant <italic>t</italic>-values significantly differ from zero.</p></fn></table-wrap-foot></table-wrap><fig id="app1fig1" position="float"><label>Appendix 1—figure 1.</label><caption><title>Speeding over the course of the task is enhanced by methamphetamine.</title><p>This figure shows raw data splits for the effect of time on task (i.e., trial number) on accuracy (panels <bold>A</bold> and <bold>B</bold>; a binary variable indicating stimulus-appropriate behavior on each trial) and log-scaled reaction times (RT; panels <bold>C</bold> and <bold>D</bold>) across different drug sessions. Results indicate that overall choice accuracy was not affected by time on task. However, participants exhibited faster reaction times over the course of the task, with this speeding effect being more pronounced in the methamphetamine condition. Errorbars reflect standard error of the mean over 94 subjects.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-101413-app1-fig1-v1.tif"/></fig></sec></app><app id="appendix-2"><title>Appendix 2</title><sec sec-type="appendix" id="s9"><title>Linear mixed-effects model analyses for key findings</title><p>In the manuscript, we used a binary discretization of baseline performance to simplify the analysis and presentation. To parse out the relationship between methamphetamine effects and baseline performance into finer level of detail, we conducted additional linear mixed-effects model (LMM) analyses, focusing on the key findings reported in the manuscript. Specifically, we examined drug effects:</p><list list-type="bullet" id="list1"><list-item><p>On overall total points.</p></list-item><list-item><p>On the probability of correct choice in the late learning phase under high outcome noise.</p></list-item><list-item><p>On the learning rate parameter eta.</p></list-item><list-item><p>On learning rate variability.</p></list-item><list-item><p>On choices following double-misleading feedback.</p></list-item><list-item><p>On the signal-to-noise ratio in high outcome noise conditions.</p></list-item></list><p>We first fit the following model:<disp-formula id="equ19"><alternatives><mml:math id="m19"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="normal">O</mml:mi><mml:mi mathvariant="normal">u</mml:mi><mml:mi mathvariant="normal">t</mml:mi><mml:mi mathvariant="normal">c</mml:mi><mml:mi mathvariant="normal">o</mml:mi><mml:mi mathvariant="normal">m</mml:mi><mml:mi mathvariant="normal">e</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:msub><mml:mi>β</mml:mi><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mi>β</mml:mi><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:msub><mml:mrow><mml:mi mathvariant="normal">S</mml:mi><mml:mi mathvariant="normal">e</mml:mi><mml:mi mathvariant="normal">s</mml:mi><mml:mi mathvariant="normal">s</mml:mi><mml:mi mathvariant="normal">i</mml:mi><mml:mi mathvariant="normal">o</mml:mi><mml:mi mathvariant="normal">n</mml:mi><mml:mi mathvariant="normal">O</mml:mi><mml:mi mathvariant="normal">r</mml:mi><mml:mi mathvariant="normal">d</mml:mi><mml:mi mathvariant="normal">e</mml:mi><mml:mi mathvariant="normal">r</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mi>β</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:msub><mml:mrow><mml:mi mathvariant="normal">D</mml:mi><mml:mi mathvariant="normal">r</mml:mi><mml:mi mathvariant="normal">u</mml:mi><mml:mi mathvariant="normal">g</mml:mi><mml:mi mathvariant="normal">S</mml:mi><mml:mi mathvariant="normal">e</mml:mi><mml:mi mathvariant="normal">s</mml:mi><mml:mi mathvariant="normal">s</mml:mi><mml:mi mathvariant="normal">i</mml:mi><mml:mi mathvariant="normal">o</mml:mi><mml:mi mathvariant="normal">n</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mi>β</mml:mi><mml:mrow><mml:mn>3</mml:mn></mml:mrow></mml:msub><mml:msub><mml:mrow><mml:mi mathvariant="normal">B</mml:mi><mml:mi mathvariant="normal">L</mml:mi><mml:mi mathvariant="normal">P</mml:mi><mml:mi mathvariant="normal">e</mml:mi><mml:mi mathvariant="normal">r</mml:mi><mml:mi mathvariant="normal">f</mml:mi><mml:mi mathvariant="normal">o</mml:mi><mml:mi mathvariant="normal">r</mml:mi><mml:mi mathvariant="normal">m</mml:mi><mml:mi mathvariant="normal">a</mml:mi><mml:mi mathvariant="normal">n</mml:mi><mml:mi mathvariant="normal">c</mml:mi><mml:mi mathvariant="normal">e</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mi>β</mml:mi><mml:mrow><mml:mn>4</mml:mn></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="normal">D</mml:mi><mml:mi mathvariant="normal">r</mml:mi><mml:mi mathvariant="normal">u</mml:mi><mml:mi mathvariant="normal">g</mml:mi><mml:mi mathvariant="normal">S</mml:mi><mml:mi mathvariant="normal">e</mml:mi><mml:mi mathvariant="normal">s</mml:mi><mml:mi mathvariant="normal">s</mml:mi><mml:mi mathvariant="normal">i</mml:mi><mml:mi mathvariant="normal">o</mml:mi><mml:mi mathvariant="normal">n</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>×</mml:mo><mml:msub><mml:mrow><mml:mi mathvariant="normal">B</mml:mi><mml:mi mathvariant="normal">L</mml:mi><mml:mi mathvariant="normal">P</mml:mi><mml:mi mathvariant="normal">e</mml:mi><mml:mi mathvariant="normal">r</mml:mi><mml:mi mathvariant="normal">f</mml:mi><mml:mi mathvariant="normal">o</mml:mi><mml:mi mathvariant="normal">r</mml:mi><mml:mi mathvariant="normal">m</mml:mi><mml:mi mathvariant="normal">a</mml:mi><mml:mi mathvariant="normal">n</mml:mi><mml:mi mathvariant="normal">c</mml:mi><mml:mi mathvariant="normal">e</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>+</mml:mo><mml:msub><mml:mi>u</mml:mi><mml:mrow><mml:mi>s</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>i</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mi>ε</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math><tex-math id="t19">\begin{document}$$\displaystyle {\rm Outcome}_{i}=\beta_{0}+\beta_{1}{\rm SessionOrder}_{i}+\beta_{2}{\rm DrugSession}_{i}+\beta_{3}{\rm BLPerformance}_{i}+\beta_{4}\left ({\rm DrugSession}_{i}\times {\rm BLPerformance}_{i}\right)+u_{s\left (i\right)}+\varepsilon_{i}$$\end{document}</tex-math></alternatives></disp-formula></p><p>where:</p><list list-type="bullet" id="list2"><list-item><p><inline-formula><alternatives><mml:math id="inf71"><mml:msub><mml:mrow><mml:mi>O</mml:mi><mml:mi>u</mml:mi><mml:mi>t</mml:mi><mml:mi>c</mml:mi><mml:mi>o</mml:mi><mml:mi>m</mml:mi><mml:mi>e</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:math><tex-math id="inft71">\begin{document}$Outcome_{i}$\end{document}</tex-math></alternatives></inline-formula> is the dependent variable (i.e., total points, <italic>P</italic>(correct choice) late learning phase high outcome noise; parameter estimate for eta; learning rate variance; <italic>P</italic>(correct choice) after double-misleading outcomes; signal-to-noise ratio high outcome noise).</p></list-item><list-item><p><inline-formula><alternatives><mml:math id="inf72"><mml:msub><mml:mrow><mml:mi>β</mml:mi></mml:mrow><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msub></mml:math><tex-math id="inft72">\begin{document}$\beta _{0}$\end{document}</tex-math></alternatives></inline-formula> is the fixed intercept.</p></list-item><list-item><p><inline-formula><alternatives><mml:math id="inf73"><mml:msub><mml:mrow><mml:mi>β</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:math><tex-math id="inft73">\begin{document}$\beta _{1}$\end{document}</tex-math></alternatives></inline-formula> and <inline-formula><alternatives><mml:math id="inf74"><mml:msub><mml:mrow><mml:mi>β</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub></mml:math><tex-math id="inft74">\begin{document}$\beta _{2}$\end{document}</tex-math></alternatives></inline-formula> are the fixed-effect coefficients.</p></list-item><list-item><p><inline-formula><alternatives><mml:math id="inf75"><mml:msub><mml:mrow><mml:mtext>Session Order</mml:mtext></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:math><tex-math id="inft75">\begin{document}$\text{Session Order}_{i}$\end{document}</tex-math></alternatives></inline-formula> (drug first vs. placebo first) is a fixed effect to control for possible session-order effects.</p></list-item><list-item><p><inline-formula><alternatives><mml:math id="inf76"><mml:msub><mml:mrow><mml:mtext>Drug Session</mml:mtext></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:math><tex-math id="inft76">\begin{document}$\text{Drug Session}_{i}$\end{document}</tex-math></alternatives></inline-formula> is a fixed effect for drug session.</p></list-item><list-item><p><inline-formula><alternatives><mml:math id="inf77"><mml:msub><mml:mrow><mml:mi>u</mml:mi></mml:mrow><mml:mrow><mml:mi>s</mml:mi><mml:mfenced separators="|"><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:mfenced></mml:mrow></mml:msub><mml:mo>∼</mml:mo><mml:mi>N</mml:mi><mml:mfenced separators="|"><mml:mrow><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:msubsup><mml:mrow><mml:mi>σ</mml:mi></mml:mrow><mml:mrow><mml:mi>u</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup></mml:mrow></mml:mfenced></mml:math><tex-math id="inft77">\begin{document}$u_{s\left (i\right)}\sim N\left (0,\sigma _{u}^{2}\right)$\end{document}</tex-math></alternatives></inline-formula> is the random intercept for subject <inline-formula><alternatives><mml:math id="inf78"><mml:mi>s</mml:mi><mml:mo>(</mml:mo><mml:mi>i</mml:mi><mml:mo>)</mml:mo></mml:math><tex-math id="inft78">\begin{document}$s\left (i\right)$\end{document}</tex-math></alternatives></inline-formula>.</p></list-item><list-item><p><inline-formula><alternatives><mml:math id="inf79"><mml:msub><mml:mrow><mml:mi>ε</mml:mi></mml:mrow><mml:mrow><mml:mi>s</mml:mi><mml:mfenced separators="|"><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:mfenced></mml:mrow></mml:msub><mml:mo>∼</mml:mo><mml:mi>N</mml:mi><mml:mfenced separators="|"><mml:mrow><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:msubsup><mml:mrow><mml:mi>σ</mml:mi></mml:mrow><mml:mrow><mml:mi>u</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup></mml:mrow></mml:mfenced></mml:math><tex-math id="inft79">\begin{document}$\varepsilon _{s\left (i\right)}\sim N\left (0,\sigma _{u}^{2}\right)$\end{document}</tex-math></alternatives></inline-formula> is the residual error term.</p></list-item></list><p>To our surprise, none of these models revealed a significant drug × baseline performance interaction. To further investigate this, we plotted the difference scores (i.e., the outcome variable under the drug condition minus placebo condition) against baseline performance scores. To better visualize potential nonlinearities, we applied a sliding window approach (step size of one subject and a window size of 25 subjects based on recent recommendations <xref ref-type="bibr" rid="bib37">Jenkins and Quintana-Ascencio, 2020</xref>). This revealed nonlinear relationships between baseline performance and outcome variables (see <xref ref-type="fig" rid="app2fig1">Appendix 2—figure 1</xref>). Specifically, we observed that drug effects were maximal in moderately low baseline performers.</p><p>To formally test this pattern, we applied the same sliding window regression approach, fitting a set of LMMs separately for each step size. These models followed the same structure as before but excluded the baseline performance term, allowing us to examine within-window effects:<disp-formula id="equ20"><alternatives><mml:math id="m20"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>O</mml:mi><mml:mi>u</mml:mi><mml:mi>t</mml:mi><mml:mi>c</mml:mi><mml:mi>o</mml:mi><mml:mi>m</mml:mi><mml:mi>e</mml:mi><mml:mi>V</mml:mi><mml:mi>a</mml:mi><mml:mi>r</mml:mi><mml:mi>i</mml:mi><mml:mi>a</mml:mi><mml:mi>b</mml:mi><mml:mi>l</mml:mi><mml:msub><mml:mi>e</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:msub><mml:mi>β</mml:mi><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mi>β</mml:mi><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:msub><mml:mtext>SessionOrder</mml:mtext><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mi>β</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:msub><mml:mtext>DrugSession</mml:mtext><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mi>u</mml:mi><mml:mrow><mml:mi>s</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>i</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mi>ε</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo></mml:mrow></mml:mstyle></mml:math><tex-math id="t20">\begin{document}$$\displaystyle OutcomeVariable_{i}=\beta _{0}+\beta _{1}\text{SessionOrder}_{i}+\beta _{2}\text{DrugSession}_{i}+u_{s\left (i\right)}+\varepsilon _{i},$$\end{document}</tex-math></alternatives></disp-formula></p><p>where</p><list list-type="bullet" id="list3"><list-item><p><inline-formula><alternatives><mml:math id="inf80"><mml:msub><mml:mrow><mml:mi>O</mml:mi><mml:mi>u</mml:mi><mml:mi>t</mml:mi><mml:mi>c</mml:mi><mml:mi>o</mml:mi><mml:mi>m</mml:mi><mml:mi>e</mml:mi><mml:mi>V</mml:mi><mml:mi>a</mml:mi><mml:mi>r</mml:mi><mml:mi>i</mml:mi><mml:mi>a</mml:mi><mml:mi>b</mml:mi><mml:mi>l</mml:mi><mml:mi>e</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:math><tex-math id="inft80">\begin{document}$OutcomeVariable_{i}$\end{document}</tex-math></alternatives></inline-formula> is the same as described above.</p></list-item><list-item><p><inline-formula><alternatives><mml:math id="inf81"><mml:msub><mml:mrow><mml:mi>β</mml:mi></mml:mrow><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msub></mml:math><tex-math id="inft81">\begin{document}$\beta _{0}$\end{document}</tex-math></alternatives></inline-formula> is the fixed intercept.</p></list-item><list-item><p><inline-formula><alternatives><mml:math id="inf82"><mml:msub><mml:mrow><mml:mi>β</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:math><tex-math id="inft82">\begin{document}$\beta _{1}$\end{document}</tex-math></alternatives></inline-formula> and <inline-formula><alternatives><mml:math id="inf83"><mml:msub><mml:mrow><mml:mi>β</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub></mml:math><tex-math id="inft83">\begin{document}$\beta _{2}$\end{document}</tex-math></alternatives></inline-formula> are the fixed-effect coefficients.</p></list-item><list-item><p><inline-formula><alternatives><mml:math id="inf84"><mml:msub><mml:mrow><mml:mtext>Session Order</mml:mtext></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:math><tex-math id="inft84">\begin{document}$\text{Session Order}_{i}$\end{document}</tex-math></alternatives></inline-formula> and <inline-formula><alternatives><mml:math id="inf85"><mml:msub><mml:mrow><mml:mtext>Drug Session</mml:mtext></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:math><tex-math id="inft85">\begin{document}$\text{Drug Session}_{i}$\end{document}</tex-math></alternatives></inline-formula> remain as fixed effects.</p></list-item><list-item><p><inline-formula><alternatives><mml:math id="inf86"><mml:msub><mml:mrow><mml:mi>u</mml:mi></mml:mrow><mml:mrow><mml:mi>s</mml:mi><mml:mfenced separators="|"><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:mfenced></mml:mrow></mml:msub><mml:mo>∼</mml:mo><mml:mi>N</mml:mi><mml:mfenced separators="|"><mml:mrow><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:msubsup><mml:mrow><mml:mi>σ</mml:mi></mml:mrow><mml:mrow><mml:mi>u</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup></mml:mrow></mml:mfenced></mml:math><tex-math id="inft86">\begin{document}$u_{s\left (i\right)}\sim N\left (0,\sigma _{u}^{2}\right)$\end{document}</tex-math></alternatives></inline-formula> is the random intercept for subject <inline-formula><alternatives><mml:math id="inf87"><mml:mi>s</mml:mi><mml:mo>(</mml:mo><mml:mi>i</mml:mi><mml:mo>)</mml:mo></mml:math><tex-math id="inft87">\begin{document}$s\left (i\right)$\end{document}</tex-math></alternatives></inline-formula>.</p></list-item><list-item><p><inline-formula><alternatives><mml:math id="inf88"><mml:msub><mml:mrow><mml:mi>ε</mml:mi></mml:mrow><mml:mrow><mml:mi>s</mml:mi><mml:mfenced separators="|"><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:mfenced></mml:mrow></mml:msub><mml:mo>∼</mml:mo><mml:mi>N</mml:mi><mml:mfenced separators="|"><mml:mrow><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:msubsup><mml:mrow><mml:mi>σ</mml:mi></mml:mrow><mml:mrow><mml:mi>u</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup></mml:mrow></mml:mfenced></mml:math><tex-math id="inft88">\begin{document}$\varepsilon _{s\left (i\right)}\sim N\left (0,\sigma _{u}^{2}\right)$\end{document}</tex-math></alternatives></inline-formula> is the residual error term.</p></list-item></list><p>The results of these models (see <xref ref-type="fig" rid="app2fig2">Appendix 2—figure 2</xref>) indicate that indeed the drug effect is strongest in moderately low baseline performers. A key thing to notice in the sliding regression results is that, while each regression reveals that drug effects depend on baseline performance, they do so nonlinearly, with most variables of interest showing a saturating effect at low baseline performance levels and the strongest slope (dependence on baseline) at or near the median level of baseline performance, explaining why our median splits were able to successfully pick up on these baseline-dependent effects.</p><p>Together, these results suggest that methamphetamine primarily affects individuals with medium-to-low baseline performance.</p><fig id="app2fig1" position="float"><label>Appendix 2—figure 1.</label><caption><title>The effect of methamphetamine depends on baseline performance.</title><p>To examine the relationship between methamphetamine effects and baseline performance, we plotted difference scores (i.e., the outcome variable under the drug condition minus placebo condition) against baseline performance. (<bold>A–F</bold>) show nonlinear relationships between baseline performance and outcome variables ((<bold>A</bold>) total points, (<bold>B</bold>) probability of a correct choice (<italic>P</italic>(correct choice)) in the late learning phase with high outcome noise, (<bold>C</bold>) parameter estimate for eta, (<bold>D</bold>) learning rate variance, (<bold>E</bold>) probability of a correct choice (<italic>P</italic>(correct choice)), and (<bold>F</bold>) signal-to-noise ratio in high outcome noise). Specifically, we show that drug effects were maximal in moderately low baseline performers. It is noteworthy that these subjects had particularly high eta’s on placebo (inset in <bold>C</bold>), which may have allowed the drug effects to have a larger impact on their performance. This is in line with our key finding, that methamphetamine brings eta (parameter controlling dynamic adjustments of learning rate according to recent prediction errors) closer to optimal levels. Vertical dashed line indicates medium baseline performance. MFB = misleading feedback. Mean/SEM = line/shading.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-101413-app2-fig1-v1.tif"/></fig><fig id="app2fig2" position="float"><label>Appendix 2—figure 2.</label><caption><title>The effect of methamphetamine is strongest in moderately low baseline performers.</title><p>This figure shows the drug effect from the sliding window linear mixed-effects model analysis plotted against baseline performance for a set of dependent variables: (<bold>A</bold>) total points, (<bold>B</bold>) probability of a correct choice (<italic>P</italic>(correct choice)) in the late learning phase with high outcome noise, (<bold>C</bold>) parameter estimate for eta, (<bold>D</bold>) learning rate variance, (<bold>E</bold>) probability of a correct choice (<italic>P</italic>(correct choice)), and (<bold>F</bold>) signal-to-noise ratio in high outcome noise. Gray areas indicate clusters with significant drug effects after correcting for multiple comparisons using a permutation test for cluster mass (<xref ref-type="bibr" rid="bib48">Maris and Oostenveld, 2007</xref>).</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-101413-app2-fig2-v1.tif"/></fig></sec></app><app id="appendix-3"><title>Appendix 3</title><sec sec-type="appendix" id="s10"><title>Analysis of parameter differences between methamphetamine (MA) and placebo (PL)</title><table-wrap id="app3table1" position="float"><label>Appendix 3—table 1.</label><caption><title>Analysis of parameter differences between MA and PL.</title></caption><table frame="hsides" rules="groups"><thead><tr><th align="left" valign="bottom">Model</th><th align="left" valign="top">Parameter PL Mean (SD)</th><th align="left" valign="top">Parameter MA Mean (SD)</th><th align="left" valign="top">Inferential statistic</th><th align="left" valign="top">Signed-Rank Test</th></tr></thead><tbody><tr><td align="left" valign="bottom">Model ∆<sub>inverse temperature</sub></td><td align="left" valign="top"/><td align="left" valign="top"/><td align="left" valign="top"/><td align="left" valign="top"/></tr><tr><td align="left" valign="bottom"> Low performer</td><td align="char" char="." valign="top">1.90 (0.16)</td><td align="char" char="." valign="top">1.83 (0.11)</td><td align="left" valign="top"><italic>t</italic>(46) = 0.60, p=0.55</td><td align="left" valign="top">p = 0.899</td></tr><tr><td align="left" valign="bottom"> High performer</td><td align="char" char="." valign="top">3.12 (0.08)</td><td align="char" char="." valign="top">3.06 (0.08)</td><td align="left" valign="top"><italic>t</italic>(46) = 1.00, p=0.32</td><td align="left" valign="top">p = 0.088</td></tr><tr><td align="left" valign="bottom">Model ∆<sub>play bias</sub></td><td align="left" valign="top"/><td align="left" valign="top"/><td align="left" valign="top"/><td align="left" valign="top"/></tr><tr><td align="left" valign="bottom"> Low performer</td><td align="char" char="." valign="top">0.04 (0.05)</td><td align="char" char="." valign="top">0.02 (0.03)</td><td align="left" valign="top"><italic>t</italic>(46) = 0.26, p = 0.79</td><td align="left" valign="top">p = 0.168</td></tr><tr><td align="left" valign="bottom"> High performer</td><td align="char" char="." valign="top">–0.03 (0.01)</td><td align="char" char="." valign="top">–0.01 (0.02)</td><td align="left" valign="top"><italic>t</italic>(46) = –1.03, p = 0.30</td><td align="left" valign="top">p = 0.189</td></tr><tr><td align="left" valign="bottom">Model ∆<sub>LR intercept</sub></td><td align="left" valign="top"/><td align="left" valign="top"/><td align="left" valign="top"/><td align="left" valign="top"/></tr><tr><td align="left" valign="bottom"> Low performer</td><td align="char" char="." valign="top">–7.17 (0.58)</td><td align="char" char="." valign="top">–7.24 (0.64)</td><td align="left" valign="top"><italic>t</italic>(46) = 0.17, p = 0.86</td><td align="left" valign="top">p = 0.611</td></tr><tr><td align="left" valign="bottom"> High performer</td><td align="char" char="." valign="top">–4.86 (0.15)</td><td align="char" char="." valign="top">–4.92 (0.15)</td><td align="left" valign="top"><italic>t</italic>(46) = 0.47, p = 0.63</td><td align="left" valign="top">p = 0.227</td></tr><tr><td align="left" valign="bottom">Model ∆<sub>eta</sub></td><td align="left" valign="top"/><td align="left" valign="top"/><td align="left" valign="top"/><td align="left" valign="top"/></tr><tr><td align="left" valign="bottom"> Low performer</td><td align="char" char="." valign="top">0.35 (0.02)</td><td align="char" char="." valign="top">0.28 (0.02)</td><td align="left" valign="top"><italic>t</italic>(46) = 2.90, p = 0.005</td><td align="left" valign="top">p = 0.006</td></tr><tr><td align="left" valign="bottom"> High performer</td><td align="char" char="." valign="top">0.26 (0.02)</td><td align="char" char="." valign="top">0.24 (0.01)</td><td align="left" valign="top"><italic>t</italic>(46) = 1.55, p = 0.12</td><td align="left" valign="top">p = 0.114</td></tr></tbody></table><table-wrap-foot><fn><p>Here, we extended the winning model by allowing each parameter, in turn, to be differentially estimated for MA and PL, while keeping the other parameters fixed at the group (low and high baseline performance) mean estimates of the winning model for the placebo session.</p></fn></table-wrap-foot></table-wrap></sec></app><app id="appendix-4"><title>Appendix 4</title><sec sec-type="appendix" id="s11"><title>Near-optimal performance</title><fig id="app4fig1" position="float"><label>Appendix 4—figure 1.</label><caption><title>High baseline performers reach near-optimal levels in both test sessions, limiting potential drug-induced performance enhancement.</title><p>(<bold>A</bold>) Overall task performance and (<bold>B</bold>) the probability of correct choices in the high outcome noise condition—the condition with the strongest observed drug effect—are plotted against normalized baseline performance. In both testing sessions, high baseline performers cluster around optimal performance. Furthermore, performance simulations using (<bold>a</bold>) optimal eta values and (<bold>b</bold>) observed eta values from the high baseline performance group reveal only a small, non-significant performance difference (points optimal eta: 701.91 (21.66) vs. points high performer: 694.47 (21.71); <italic>t</italic>(46) = 2.84, p = 0.07, <italic>d</italic> = 0.059; <italic>t</italic>(46) = 2.84, p = 0.07, <italic>d</italic> = 0.059). These results suggest that high baseline performers are already at or near their performance ceiling, limiting the potential for further drug-induced improvements.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-101413-app4-fig1-v1.tif"/></fig></sec></app><app id="appendix-5"><title>Appendix 5</title><sec sec-type="appendix" id="s12"><title>Full Sample results</title><fig id="app5fig1" position="float"><label>Appendix 5—figure 1.</label><caption><title>Overall points full sample.</title><p>When comparing overall points in the whole sample (<italic>n</italic> = 109), we do not see a difference between MPH vs. PLA (705.68 (36.27) vs. 685.77 (35.78); <italic>t</italic>(108) = 0.81, p = 0.42, <italic>d</italic> = 0.05). Repeated mixed ANOVAs suggested that drug effects did not depend on session order (MPH first vs. PLA first), or whether subjects performed the orientation session. Yet, participants who completed the orientation tended to perform better during the drug sessions (<italic>F</italic>(1,107) = 3.09, p = 0.08; 719.31 (26.6264) vs. 548.00 (75.09)). <italic>Note</italic>. PL = placebo; MA = methamphetamine.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-101413-app5-fig1-v1.tif"/></fig><fig id="app5fig2" position="float"><label>Appendix 5—figure 2.</label><caption><title>Learning curves after reversals full sample.</title><p>Figure shows learning curves after all reversals (<bold>A</bold>), reversals to high reward probability uncertainty (<bold>B</bold>), and reversals to low reward probability uncertainty (<bold>C</bold>) for the whole sample. Vertical black lines divide learning into early and late stages as suggested by the Bai–Perron multiple break point test. Paired-sample <italic>t</italic>-test revealed no drug-related difference for all reversals during early learning (0.72 (0.01) vs. 0.72 (0.01); <italic>t</italic>(108) = –0.02, p = 0.98, <italic>d</italic> &lt; 0.01) and late learning (0.83 (0.01) vs. 0.84 (0.01); <italic>t</italic>(108) = –0.80, p = 0.42, <italic>d</italic> = 0.04). Similarly, there were no significant differences in both learning stages for reversals to low reward probability certainty stimuli (early learning PLA vs. MPH: 0.68 (0.01) vs. 0.69 (0.01); <italic>t</italic>(108) = –0.92, p = 0.35, <italic>d</italic> = 0.08; late learning PLA vs. MPH: 0.80 (0.01) vs. 0.81 (0.01); <italic>t</italic>(108) = –1.48, p = 0.14, <italic>d</italic> = 0.10) or to low reward probability certainty stimuli (early learning PLA vs. MPH: 0.74 (0.01) vs. 0.73 (0.01); <italic>t</italic>(108) = 0.87, p = 0.38, <italic>d</italic> = 0.06; late learning PLA vs. MPH: 0.85 (0.01) vs. 0.85 (0.01); <italic>t</italic>(108) = –0.02, p = 0.97, <italic>d</italic> &lt; 0.01). Mixed-effects ANOVAs that controlled for session-order effects and whether participants performed the orientation session revealed no significant effects (all p &gt; 0.06). <italic>Note</italic>. PL = placebo; MA = methamphetamine.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-101413-app5-fig2-v1.tif"/></fig><fig id="app5fig3" position="float"><label>Appendix 5—figure 3.</label><caption><title>Model parameter comparison and learning rate trajectories full sample.</title><p>(<bold>A</bold>) Here, we compare MPHs effect on best-fitting parameters of the winning model in the full sample (<italic>n</italic> = 109). We found that eta (i.e., the weighting of the effect of the abs. reward prediction error on learning) was reduced under MPHs (eta MPH: 0.23 (0.01) vs. PLA 0.29 (0.01); <italic>t</italic>(108) = –3.05, p = 0.002, <italic>d</italic> = 0.40). Mixed-effects ANOVAs that controlled for session-order effects and whether participants performed the orientation session revealed this effect did not depend on these cofactors. No other condition differences emerged. (<bold>B</bold>) Learning rate trajectories after reversal derived from the computational model. As in the reduced sample, MPH appears to be associated with reduced learning rate dynamics in the full sample too. Specifically, variability in learning rate (average individual SD of learning rate) tended to be reduced in the MPH condition both during early and late stages of learning across all reversals (early PLA: 0.19 (0.01) vs. 0.18 (0.01); <italic>t</italic>(108) = 1.89, p = 0.06, <italic>d</italic> = 0.24; late PLA: 0.17 (0.01) vs. MPH: 0.16 (0.01); <italic>t</italic>(108) = 1.77, p = 0.08, <italic>d</italic> = 0.23) and reversals to high reward probability uncertainty (early PLA: 0.18 (0.01) vs. 0.16 (0.01); <italic>t</italic>(108) = 1.74, p = 0.08, <italic>d</italic> = 0.22; late PLA: 0.18 (0.01) vs. MPH: 0.16 (0.01); <italic>t</italic>(108) = 1.82, p = 0.07, <italic>d</italic> = 0.24). Condition differences became most evident in reversals to low reward probability uncertainty (early PLA: 0.19 (0.01) vs. MPH: 0.16 (0.01); <italic>t</italic>(108) = 2.18, p = 0.03, <italic>d</italic> = 0.28; late PLA: 0.18 (0.01) vs. MPH: 0.16 (0.01); <italic>t</italic>(108) = 1.93, p = 0.05, <italic>d</italic> = 0.24). Control analyses revealed that these effects were independent of session order and orientation session. <italic>Note</italic>. PL = placebo; MA = methamphetamine.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-101413-app5-fig3-v1.tif"/></fig></sec></app></app-group></back><sub-article article-type="editor-report" id="sa0"><front-stub><article-id pub-id-type="doi">10.7554/eLife.101413.3.sa0</article-id><title-group><article-title>eLife Assessment</article-title></title-group><contrib-group><contrib contrib-type="author"><name><surname>Cools</surname><given-names>Roshan</given-names></name><role specific-use="editor">Reviewing Editor</role><aff><institution>Donders Institute for Brain, Cognition and Behaviour, Radboud University Nijmegen</institution><country>Netherlands</country></aff></contrib></contrib-group><kwd-group kwd-group-type="evidence-strength"><kwd>Convincing</kwd></kwd-group><kwd-group kwd-group-type="claim-importance"><kwd>Important</kwd></kwd-group></front-stub><body><p>This manuscript reports effects of a single dose of methamphetamine vs placebo on a probabilistic reversal learning task with different levels of noise, in a large group of young healthy volunteers. The paper is well written and the methods are rigorous. The findings are <bold>important</bold> and have theoretical or practical implications beyond a single a subfield. The strength of the evidence is <bold>convincing</bold>, with the methods, data, and analyses broadly supporting the claims in the paper, which are sufficiently qualified given the lack of a significant effect of the binary baseline performance variable, and the nonlinear effect of individual differences in baseline performance.</p></body></sub-article><sub-article article-type="referee-report" id="sa1"><front-stub><article-id pub-id-type="doi">10.7554/eLife.101413.3.sa1</article-id><title-group><article-title>Reviewer #1 (Public review):</article-title></title-group><contrib-group><contrib contrib-type="author"><anonymous/><role specific-use="referee">Reviewer</role></contrib></contrib-group></front-stub><body><p>The authors examine how probabilistic reversal learning is affected by dopamine by studying the effects of methamphetamine (MA) administration. Based on prior evidence that the effects of pharmacological manipulation depend on baseline neurotransmitter levels, they hypothesized that MA would improve learning in people with low baseline performance. They found this effect, and specifically found that MA administration improved learning in noisy blocks, by reducing learning from misleading performance, in participants with lower baseline performance. The authors then fit participants' behavior to a computational learning model and found that an eta parameter, responsible for scaling learning rate based on previously surprising outcomes, differed in participants with low baseline performance on and off MA.</p><p>Questions:</p><p>(1) It would be helpful to confirm that the observed effect of MA on the eta parameter is responsible for better performance in low baseline performers. If performance on the task is simulated for parameters estimated for high and low baseline performers on and off MA, does the simulated behavior capture the main behavioral differences shown in Figure 3?</p><p>(2) In Figure 4C, it appears that the main parameter difference between low and high baseline performance is inverse temperature, not eta. If MA is effective in people with lower baseline DA, why is the effect of MA on eta and not IT?</p><p>Also, this parameter is noted as temperature but appears to be inverse temperature as higher values are related to better performance. The exact model for the choice function is not described in the methods.</p><p>Comments on revisions:</p><p>Thanks to the authors for their thorough responses and revisions.One typo to note: in the Methods, the &quot;drug effects&quot; paragraph is repeated.</p></body></sub-article><sub-article article-type="referee-report" id="sa2"><front-stub><article-id pub-id-type="doi">10.7554/eLife.101413.3.sa2</article-id><title-group><article-title>Reviewer #2 (Public review):</article-title></title-group><contrib-group><contrib contrib-type="author"><anonymous/><role specific-use="referee">Reviewer</role></contrib></contrib-group></front-stub><body><p>Summary:</p><p>Kirschner and colleagues test whether methamphetamine (MA) alters learning rate dynamics in a validated reversal learning task. They find evidence that MA can enhance performance for low-performers, and that the enhancement reflects a reduction in the degree to which these low-performers dynamically up-regulate their learning rates when they encounter unexpected outcomes. The net effect is that poor performers show more volatile learning rates (e.g. jumping up when they receive misleading feedback), when the environment is actually stable, undermining their performance over trials.</p><p>Strengths:</p><p>The study has multiple strengths, including a large sample size, placebo control, double-blind randomized design, and rigorous computational modeling of a validated task. Additionally, the analytic methods are rigorous and offer new types of analyses for people interested in exploring learning as a function of dynamically changing volatility.</p><p>Weaknesses:</p><p>The limitations, which are acknowledged, include that the drug they use, methamphetamine, can influence multiple neuromodulatory systems including catecholamines and acetylcholine, all of which have been implicated in learning rate dynamics. They also do not have any independent measures of any of these systems, so it is impossible to know which is having an effect.</p><p>Another limitation which they should acknowledge is that the fact that participants were aware of having different experiences in the drug sessions means that their blinding was effectively single-blind (to the experimenters) and not double-blind. That said, the authors do provide some evidence that subjective effects of drugs (e.g. arousal, mood, etc.) did not drive differences in performance.</p><p>Comments on revisions:</p><p>The authors have done an outstanding job responding to, and allaying my prior concerns about their analyses.</p></body></sub-article><sub-article article-type="author-comment" id="sa3"><front-stub><article-id pub-id-type="doi">10.7554/eLife.101413.3.sa3</article-id><title-group><article-title>Author response</article-title></title-group><contrib-group><contrib contrib-type="author"><name><surname>Kirschner</surname><given-names>Hans</given-names></name><role specific-use="author">Author</role><aff><institution>Otto-von-Guericke University Magdeburg</institution><addr-line><named-content content-type="city">Magdeburg</named-content></addr-line><country>Germany</country></aff></contrib><contrib contrib-type="author"><name><surname>Molla</surname><given-names>Hanna</given-names></name><role specific-use="author">Author</role><aff><institution>University of Chicago</institution><addr-line><named-content content-type="city">Chicago</named-content></addr-line><country>United States</country></aff></contrib><contrib contrib-type="author"><name><surname>Nassar</surname><given-names>Matthew R</given-names></name><role specific-use="author">Author</role><aff><institution>Brown University</institution><addr-line><named-content content-type="city">Providence</named-content></addr-line><country>United States</country></aff></contrib><contrib contrib-type="author"><name><surname>de Wit</surname><given-names>Harriet</given-names></name><role specific-use="author">Author</role><aff><institution>University of Chicago</institution><addr-line><named-content content-type="city">Chicago</named-content></addr-line><country>United States</country></aff></contrib><contrib contrib-type="author"><name><surname>Ullsperger</surname><given-names>Markus</given-names></name><role specific-use="author">Author</role><aff><institution>Otto-von-Guericke University Magdeburg</institution><addr-line><named-content content-type="city">Magdeburg</named-content></addr-line><country>Germany</country></aff></contrib></contrib-group></front-stub><body><p>The following is the authors’ response to the original reviews.</p><disp-quote content-type="editor-comment"><p><bold>Public Reviews:</bold></p><p><bold>Reviewer #1 (Public review):</bold></p><p>The authors examine how probabilistic reversal learning is affected by dopamine by studying the effects of methamphetamine (MA) administration. Based on prior evidence that the effects of pharmacological manipulation depend on baseline neurotransmitter levels, they hypothesized that MA would improve learning in people with low baseline performance. They found this effect, and specifically found that MA administration improved learning in noisy blocks, by reducing learning from misleading performance, in participants with lower baseline performance. The authors then fit participants' behavior to a computational learning model and found that an eta parameter, responsible for scaling learning rate based on previously surprising outcomes, differed in participants with low baseline performance on and off MA.</p><p>Questions:</p><p>(1) It would be helpful to confirm that the observed effect of MA on the eta parameter is responsible for better performance in low baseline performers. If performance on the task is simulated for parameters estimated for high and low baseline performers on and off MA, does the simulated behavior capture the main behavioral differences shown in Figure 3?</p></disp-quote><p>We thank the reviewer for this suggestion. We agree that the additional simulation provides valuable confirmation of the effect of methamphetamine (MA) on the eta parameter and subsequent choice behavior. Using individual maximum likelihood parameter estimates, we simulated task performance and confirmed that the simulated behavior reflects the observed mean behavioral differences. Specifically, the simulation demonstrates that MA increases performance later in learning for stimuli with less predictable reward probabilities, particularly in subjects with low baseline performance (mean ± SD: simPL low performance: 0.69 ± 0.01 vs. simMA low performance: 0.72 ± 0.01; t(46) = -2.00, p = 0.03, d = 0.23).</p><p>We have incorporated this analysis into the manuscript. Specifically, we added a new figure to illustrate these findings and updated the text accordingly. Below, we detail the changes made to the manuscript.</p><p>From the manuscript page 12, line 25:</p><p>“Sufficiency of the model was evaluated through posterior predictive checks that matched behavioral choice data (see Figure 4D-F and Figure 5) and model validation analyses (see Supplementary Figure 2). Specifically, using individual maximum likelihood parameter estimates, we simulated task performance and confirmed that MA increases performance later in learning for stimuli with less predictable reward probabilities, particularly in subjects with low baseline performance (Figure 5A; mean ± SD: simPL low performance: 0.69 ± 0.01 vs. simMA low performance: 0.72 ± 0.01; t(46) = -2.00, p = 0.03, d = 0.23).”</p><disp-quote content-type="editor-comment"><p>(2) In Figure 4C, it appears that the main parameter difference between low and high baseline performance is inverse temperature, not eta. If MA is effective in people with lower baseline DA, why is the effect of MA on eta and not IT?</p></disp-quote><p>Thank you for raising this important point. It is correct that the primary difference between the low and high baseline performance groups in the placebo session lies in the inverse temperature (mean(SD); low baseline performance: 2.07 (0.11) vs. high baseline performance: 2.95 (0.07); t(46) = -5.79, p = 5.8442e-07, d = 1.37). However, there is also a significant difference in the eta parameter between these groups during the placebo session (low baseline performance: 0.33 (0.02) vs. baseline performance: 2.07 (0.11243) vs. high baseline performance: 0.25 (0.02); t(46) = 2.59, p = 0.01, d = 0.53).</p><p>Interestingly, the difference in eta is resolved by MA (mean(SD); low baseline performance: 0.24 (0.02) vs. high baseline performance: 0.23 (0.02); t(46) = 0.39, p = 0.70, d = 0.08), while the difference in inverse temperature remains unaffected (mean(SD); low baseline performance: 2.16 (0.11) vs. high baseline performance: 2.99 (0.08); t(46) = -5.38, p &lt; .001, d = 1.29). Moreover, we checked the distribution of the inverse temperature estimates on/offdrug to ensure the absent drug effect is not driven by outliers. Here, we do not observe any descriptive drug effect (see Author response image 1). Additionally, non-parametric tests indicate no drug effect (Wilcoxon signed-rank test; across groups: zval = -0.59; p = 0.55; low baseline performance: zval = -0.54; p = 0.58; high baseline performance: zval = -0.21; p = 0.83).</p><fig id="sa3fig1" position="float"><label>Author response image 1.</label><caption><title>Inverse temperature distribution on/off drug suggest that this parameter is not affected by the drug.</title><p>Inverse temperature for low (blue points) and high (yellow points) baseline performer tended to be not affected by the drug effect (Wilcoxon signed-rank test; across groups: zval = -0.59; p = 0.55; low baseline performance: zval = -0.54; p = 0.58; high baseline performance: zval = -0.21; p = 0.83).</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-101413-sa3-fig1-v1.tif"/></fig><p>This pattern of results might suggests that MA specifically affects eta but not other parameters like the inverse temperature, pointing to a selective influence on a single computational mechanism. To verify this conclusion, we extended the winning model by allowing each parameter in turn to be differentially estimated for MA and placebo, while keeping other parameters fixed to the group (low and high baseline performance) mean estimates of the winning model fit to chocie behaviour of the placebo session.</p><p>These control analyses confirmed that MA does not affect inverse temperature in either the low baseline performance group or the high baseline performance group. Similarly, MA did not affect the play bias or learning rate intercept parameter. Yet, it did affect eta in the low performer group (see supplementary table 1 reproduced below).</p><p>Taken together, our data suggest that only the parameter controlling dynamic adjustments of the learning rate based on recent prediction errors, eta, was affected by our pharmacological manipulation and that the paremeters of our models did not trade off. A similar effect has been observed in a previous study investigating the effects of catecholaminergic drug administration in a probabilistic reversal learning task (Rostami Kandroodi et al., 2021). In that study, the authors demonstrated that methylphenidate influenced the inverse learning rate parameter as a function of working memory span, assessed through a baseline cognitive task. Similar to our findings, they did not observe drug effects on other parameters in their model including the inverse temperature.</p><p>We have updated the section of the manuscript where we discuss the difference in inverse temperature between low and high performers in the task. From the manuscript (page 19, line 13):</p><p>“While eta seemed to account for the differences in the effects of MA on performance in our low and high performance groups, it did not fully explain all performance differences across the two groups (see Figure 1C and Figure 7A/B). When comparing other model parameters between low and high baseline performers across drug sessions, we found that high baseline performers displayed higher overall inverse temperatures (2.97(0.05) vs. 2.11 (0.08); t(93) = 7.94, p &lt; .001, d = 1.33). This suggests that high baseline performers displayed higher transfer of stimulus values to actions leading to better performance (as also indicated by the positive contribution of this parameter to overall performance in the GLM). Moreover, they tended to show a reduced play bias (-0.01 (0.01) vs. 0.04 (0.03); t(93) = -1.77, p = 0.08, d = 0.26) and increased intercepts in their learning rate term (-2.38 (0.364) vs. -6.48 (0.70); t(93) = 5.03, p &lt; .001, d = 0.76). Both of these parameters have been associated with overall performance (see Figure 6A). Thus, overall performance difference between high and low baseline performers can be attributed to differences in model parameters other than eta. However, as described in the previous paragraph, differential effects of MA on performance on the two groups were driven by eta.</p><p>This pattern of results suggests that MA specifically affects the eta parameter while leaving other parameters, such as the inverse temperature, unaffected. This points to a selective influence on a single computational mechanism. To verify this conclusion, we extended the winning model by allowing each parameter, in turn, to be differentially estimated for MA and PL, while keeping the other parameters fixed at the group (low and high baseline performance) mean estimates of the winning model for the placebo session. These control analyses confirmed that MA affects only the eta parameter in the low-performer group and that there is no parameter-trade off in our model (see Supplementary Table 1). A similar effect was observed in a previous study investigating the effects of catecholaminergic drug administration on a probabilistic reversal learning task (Rostami Kandroodi et al., 2021). In that study, methylphenidate was shown to influence the inverse learning rate parameter (i.e., decay factor for previous payoffs) as a function of working memory span, assessed through a baseline cognitive task. Consistent with our findings, no drug effects were observed on other parameters in their model, including the inverse temperature.”</p><p>Additionally, we summarized the results in a supplementary table:</p><disp-quote content-type="editor-comment"><p>Also, this parameter is noted as temperature but appears to be inverse temperature as higher values are related to better performance. The exact model for the choice function is not described in the methods.</p></disp-quote><p>We thank the reviewer for bringing this to our attention. The reviewer is correct that we intended to refer to the inverse temperature. We have corrected this mistake throughout the manuscript and added information about the choice function to the methods section.</p><p>From the manuscript (page 37, line 3):</p><p>On each trial, this value term was transferred into a “biased” value term (<italic>𝑉𝐵</italic>(<italic>𝑋𝑡</italic>) = <italic>𝐵𝑝𝑙𝑎𝑦</italic> + <italic>𝑄𝑡</italic>(<italic>𝑋𝑡</italic>), where <italic>𝐵𝑝𝑙𝑎𝑦</italic> is the play bias term) and converted into action probabilities (P(play|(<italic>𝑉𝐵 play)</italic>(<italic>𝑡</italic>)(<italic>𝑋𝑡</italic>); P(pass|<italic>𝑉𝐵 pass)</italic>(<italic>𝑡</italic>)(<italic>𝑋𝑡</italic>)) using a softmax function with an inverse temperature (𝛽):<disp-formula id="sa3equ1"><alternatives><mml:math id="sa3m1"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mrow><mml:mo fence="true" stretchy="true" symmetric="true"/><mml:mrow><mml:mo stretchy="false">∣</mml:mo><mml:msub><mml:mi>V</mml:mi><mml:mrow><mml:mi>B</mml:mi><mml:mtext> play </mml:mtext></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:msub><mml:mi>X</mml:mi><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mi>exp</mml:mi><mml:mo>⁡</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>V</mml:mi><mml:mrow><mml:mrow><mml:mi mathvariant="normal">B</mml:mi></mml:mrow><mml:mtext> play </mml:mtext></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:msub><mml:mi>X</mml:mi><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>)</mml:mo></mml:mrow><mml:mo>⋅</mml:mo><mml:mi>β</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mrow><mml:mi>exp</mml:mi><mml:mo>⁡</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>V</mml:mi><mml:mrow><mml:mtext>play </mml:mtext></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:msub><mml:mi>X</mml:mi><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>)</mml:mo></mml:mrow><mml:mo>⋅</mml:mo><mml:mi>β</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>+</mml:mo><mml:mi>exp</mml:mi><mml:mo>⁡</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>V</mml:mi><mml:mrow><mml:mtext>pass </mml:mtext></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:msub><mml:mi>X</mml:mi><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>)</mml:mo></mml:mrow><mml:mo>⋅</mml:mo><mml:mi>β</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mfrac></mml:mrow></mml:mstyle></mml:math><tex-math id="t21">\begin{document}$$\displaystyle \left.\mid V_{B \text { play }}(t)\left(X_{t}\right)\right)=\frac{\exp \left(V_{\mathrm{B} \text { play }}(t)\left(X_{t}\right) \cdot \beta\right)}{\exp \left(V_{\text {play }}(t)\left(X_{t}\right) \cdot \beta\right)+\exp \left(V_{\text {pass }}(t)\left(X_{t}\right) \cdot \beta\right)}$$\end{document}</tex-math></alternatives></disp-formula><disp-formula id="sa3equ2"><alternatives><mml:math id="sa3m2"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mrow><mml:mi mathvariant="normal">P</mml:mi></mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>pass</mml:mi><mml:mo>∣</mml:mo><mml:msub><mml:mi>V</mml:mi><mml:mrow><mml:mi>B</mml:mi><mml:mtext> pass </mml:mtext></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:msub><mml:mi>X</mml:mi><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mi>exp</mml:mi><mml:mo>⁡</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>V</mml:mi><mml:mrow><mml:mtext>pass </mml:mtext></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:msub><mml:mi>X</mml:mi><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>)</mml:mo></mml:mrow><mml:mo>⋅</mml:mo><mml:mi>β</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mrow><mml:mi>exp</mml:mi><mml:mo>⁡</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>V</mml:mi><mml:mrow><mml:mtext>play </mml:mtext></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:msub><mml:mi>X</mml:mi><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>)</mml:mo></mml:mrow><mml:mo>⋅</mml:mo><mml:mi>β</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>+</mml:mo><mml:mi>exp</mml:mi><mml:mo>⁡</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>V</mml:mi><mml:mrow><mml:mtext>pass </mml:mtext></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:msub><mml:mi>X</mml:mi><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>)</mml:mo></mml:mrow><mml:mo>⋅</mml:mo><mml:mi>β</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mfrac></mml:mrow></mml:mstyle></mml:math><tex-math id="t22">\begin{document}$$\displaystyle \mathrm{P}\left(\operatorname{pass} \mid V_{B \text { pass }}(t)\left(X_{t}\right)\right)=\frac{\exp \left(V_{\text {pass }}(t)\left(X_{t}\right) \cdot \beta\right)}{\exp \left(V_{\text {play }}(t)\left(X_{t}\right) \cdot \beta\right)+\exp \left(V_{\text {pass }}(t)\left(X_{t}\right) \cdot \beta\right)}$$\end{document}</tex-math></alternatives></disp-formula></p><disp-quote content-type="editor-comment"><p><bold>Reviewer #1 (Recommendations for the authors):</bold></p><p>(1) Given that the task was quite long (700+ trials), were there any fatigue effects or changes in behavior over the course of the task?</p></disp-quote><p>To address the reviewer comment, we regressed each participant single-trial log-scaled RT and accuracy (binary variable reflecting whether a participant displayed stimulus-appropriate behavior on each trial) onto the trial number as a proxy of time on task. Individual participants’ t-values for the time on task regressor were then tested on group level via two-sided t-tests against zero and compared across sessions and baseline performance groups. The results of these two regression models are shown in the supplementary table 2 and raw data splits in supplementary figure S7. Results demonstrate that the choice behavior was not systematically affected over the course of the task. This effect was not different between low and high baseline performers and not affected by the drug. In contrast, participants’ reaction time decreased over the course of the task and this speeding was enhanced by MA, particularly in the low performance group.</p><p>We added the following section to the supplementary materials and refer to this information in the task description section of the manuscript (page 35, line 26):</p><p>“Time-on-Task Effects</p><p>Given the length of our task, we investigated whether fatigue effects or changes in behavior occurred over time. Specifically, we regressed each participant's single-trial log-scaled reaction times (RT) and accuracy (a binary variable reflecting whether participants displayed stimulus-appropriate behavior on each trial) onto trial number, which served as a proxy for time on task. The resulting t-values for the time-on-task regressor were analyzed at the group level using two-sided t-tests against zero and compared across sessions and baseline performance groups. The results of these regression models are presented in Supplementary Table S2, with raw data splits shown in Supplementary Figure S3.</p><p>Our findings indicate that choice behavior was not systematically affected over the course of the task. This effect did not differ between low and high baseline performers and was not influenced by the drug. In contrast, reaction times decreased over the course of the task, with this speeding effect being enhanced by MA, particularly in the low-performance group.”</p><disp-quote content-type="editor-comment"><p>(2) Figure 5J is hard to understand given the lack of axis labels on some of the plots. Also, the scatter plot is on the left, not the right, as stated in the legend.</p></disp-quote><p>We agree that this part of the figure was difficult to understand. To address this issue, we have separated it from Figure 5, added axis labels for clarity, and reworked the figure caption.</p><disp-quote content-type="editor-comment"><p>(3) The data and code were not available for review.</p></disp-quote><p>Thank you for pointing this out. The data and code are now made publicly available onGitHub: <ext-link ext-link-type="uri" xlink:href="https://github.com/HansKirschner/REFIT_Chicago_public.git">https://github.com/HansKirschner/REFIT_Chicago_public.git</ext-link></p><p>We updated the respective section in the manuscript:</p><p>Data Availability StatementAll raw data and analysis scripts can be accessed at:<ext-link ext-link-type="uri" xlink:href="https://github.com/HansKirschner/REFIT_Chicago_public.git">https://github.com/HansKirschner/REFIT_Chicago_public.git</ext-link></p><disp-quote content-type="editor-comment"><p><bold>Reviewer #2 (Public review):</bold></p><p>Summary:</p><p>Kirschner and colleagues test whether methamphetamine (MA) alters learning rate dynamics in a validated reversal learning task. They find evidence that MA can enhance performance for low-performers and that the enhancement reflects a reduction in the degree to which these low-performers dynamically up-regulate their learning rates when they encounter unexpected outcomes. The net effect is that poor performers show more volatile learning rates (e.g. jumping up when they receive misleading feedback), when the environment is actually stable, undermining their performance over trials.</p><p>Strengths:</p><p>The study has multiple strengths including large sample size, placebo control, double-blind randomized design, and rigorous computational modeling of a validated task.</p><p>Weaknesses:</p><p>The limitations, which are acknowledged, include that the drug they use, methamphetamine, can influence multiple neuromodulatory systems including catecholamines and acetylcholine, all of which have been implicated in learning rate dynamics. They also do not have any independent measures of any of these systems, so it is impossible to know which is having an effect.</p><p>Another limitation that the authors should acknowledge is that the fact that participants were aware of having different experiences in the drug sessions means that their blinding was effectively single-blind (to the experimenters) and not double-blind. Relatedly, it is difficult to know whether subjective effects of drugs (e.g. arousal, mood, etc.) might have driven differences in attention, causing performance enhancements in the low-performing group. Do the authors have measures of these subjective effects that they could include as covariates of no interest in their analyses?</p></disp-quote><p>We thank the reviewer for highlighting this complex issue. ‘Double blind’ may refer to masking the identity of the drug before administration, or to the subjects’ stated identifications after any effects have been experienced. In our study, the participants were told that they might receive a stimulant, sedative or placebo on any session, so before the sessions their expectations were blinded. After receiving the drug, most participants reported feeling stimulant-like effects on the drug session, but not all of them correctly identified the substance as a stimulant. We note that many subjects identified placebo as ‘sedative’. The Author response image 2 indicates how the participants identified the substance they received.</p><fig id="sa3fig2" position="float"><label>Author response image 2.</label><caption><title>Substance identification.</title></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-101413-sa3-fig2-v1.tif"/></fig><p>We share the reviewer’s interest in the extent to which mood effects of drugs are correlated with the drugs’ other effects, including cognitive function. To address this in the present study, we compared the subjective responses to the drug in participants who were low- or highperformers at baseline on the task. The low- and high baseline performers did not differ in their subjective drug effects, including ‘feel drug’ or stimulant-like effects (see Figure 1 from the mansucript reproduced below; peak change from baseline scores for feel drug ratings ondrug: low baseline performer: 48.36(4.29) vs. high baseline performer: 47.21 (4.44); t(91) = 0.18, p = 0.85, d = 0.03; ARCI-A score: low baseline performer: 4.87 (0.43) vs. high baseline performer: 4.00 (0.418); t(91) = 1.43, p = 0.15, d = 0.30). Moreover, task performance in the drug session was not correlated with the subjective effects (peak “feel drug” effect: r(94) = 0.09, p = 0.41; peak “stimulant like” effect: r(94) = -0.18, p = 0.07).</p><p>We have added details of these additional analyses to the manuscript. Since there were no significant differences in subjective drug effects between low- and high-baseline performers, and these effects were not systematically associated with task performance, we did not include these measurements as covariates in our analyses. Furthermore, as both subjective measurements indicate a similar pattern, we have chosen not to report the ARCI-A effects in the manuscript.</p><p>From the manuscript (page 6, line 5ff):</p><p>“Subjective drug effectsMA administration significantly increased ‘feel drug effect’ ratings compared to PL, at 30, 50, 135, 180, and 210 min post-capsule administration (see Figure 1; Drug x Time interaction F(5,555) = 38.46, p &lt; 0.001). In the MA session, no differences in the ‘feel drug effect’ were observed between low and high baseline performer, including peak change-from-baseline ratings (rating at 50 min post-capsule: low baseline performer: 48.36(4.29) vs. high baseline performer: 47.21 (4.44); t(91) = 0.18, p = 0.85, d = 0.03; rating at 135 min post-capsule: low baseline performer: 37.27 (4.15) vs. high baseline performer: 45.38 (3.84); t(91) = 1.42, p = 0.15, d = 0.29).”</p><disp-quote content-type="editor-comment"><p><bold>Reviewer #2 (Recommendations for the authors):</bold></p><p>I was also concerned about the distinctions between the low- and high-performing groups. It is unclear why, except for simplicity of presentation, they chose to binarize the sample into high and low performers. I would like to know if the effects held up if they analyzed interactions with individual differences in performance and not just a binarized high/low group membership. If the individual difference interactions do not hold up, I would like to know the authors' thoughts on why they do not.</p></disp-quote><p>Thank you for raising this important issue. We chose a binary discretization of baseline performance to simplify the analysis and presentation. However, we acknowledge that this simplification may limit the interpretability of the results.</p><p>To address the reviewer’s concern, we conducted additional linear mixed-effects model (LMM) analyses, focusing on the key findings reported in the manuscript. See supplementary materials section “Linear mixed effects model analyses for key findings”</p><p>From the manuscript (page 30, line 4ff):</p><p>“Methamphetamine performance enhancement depends on initial task performance</p><p>Another key finding of the current study is that the benefits of MA on performance depend on the baseline task performance. Specifically, we found that MA selectively improved performance in participants that performed poorly in the baseline session. However, it should be noted, that all the drug x baseline performance interactions, including for the key computational eta parameter did not reach the statistical threshold, and only tended towards significance. We used a binary discretization of baseline performance to simplify the analysis and presentation. To parse out the relationship between methamphetamine effects and baseline performance into finer level of detail, we conducted additional linear mixed-effects model (LMM) analyses using a sliding window regression approach (see supplementary results and supplementary figure S4 and S5). A key thing to notice in the sliding regression results is that, while each regression reveals that drug effects depend on baseline performance, they do so non-linearly, with most variables of interest showing a saturating effect at low baseline performance levels and the strongest slope (dependence on baseline) at or near the median level of baseline performance, explaining why our median splits were able to successfully pick up on these baseline-dependent effects. Together, these results suggest that methamphetamine primarily affects moderately low baseline performer. It is noteworthy to highlight again that we had a separate baseline measurement from the placebo session, allowing us to investigate baseline-dependent changes while avoiding typical concerns in such analyses like regression to the mean (Barnett et al., 2004). This design enhances the robustness of our baseline-dependent effects.”</p><p>See supplementary materials section “Linear mixed effects model analyses for key findings”</p><disp-quote content-type="editor-comment"><p>Perhaps relatedly, in multiple analyses, the authors point out that there are drug effects for the low-performance group, but not the high-performance group. This could reflect the well-documented baseline-dependency effect of catecholamergic drugs. However, it might also reflect the fact that the high-performance group is closer to their ceiling. So, a performance-enhancement drug might not have any room to make them better. Note that their results are not consistent with inverted-U-like effects, previously described, where high performers actually get worse on catecholaminergic drugs.</p><p>Given that the authors have the capacity to simulate performance as a function of parameter values, they could specifically simulate how much better performance could get if their high-performance group all moved proportionally closer to optimal levels of the parameter eta. On the basis of that analysis do they have any evidence that they had the power to detect an effect in the high performance group? If not, they should just acknowledge that ceiling effects might have played a role for high performers.</p></disp-quote><p>We agree with the reviewer's interpretation of the results. First, when plotting overall task performance and the probability of correct choices in the high outcome noise condition—the condition where we observe the strongest drug-induced performance enhancement—we find minimal performance variation among high baseline performers. In both testing sessions, high baseline performers cluster around optimal performance, with little evidence of drug-induced changes (see Supplementary Figure 6).</p><p>Furthermore, performance simulations using (a) optimal eta values and (b) observed eta values from the high baseline performance group reveal only a small, non-significant performance difference (points optimal eta: 701.91 (21.66) vs. points high performer: 694.47 (21.71); t(46) = 2.84, p = 0.07, d = 0.059).</p><p>These results suggest that high baseline performers are already near optimal performance, limiting the potential for drug-related performance improvements. We have incorporated this information into the manuscript (page 30, line 24ff).</p><p>“It is important to note, that MA did not bring performance of low baseline performers to the level of performance of high baseline performers. We speculate that high performers gained a good representation of the task structure during the orientation practice session, taking specific features of the task into account (change point probabilities, noise in the reward probabilities). This is reflected in a large signal to noise ratio between real reversals and misleading feedback. Because the high performers already perform the task at a near-optimal level, MA may not further enhance performance (see Supplementary Figure S6 for additional evidence for this claim). Intriguingly, the data do not support an inverted-u-shaped effect of catecholaminergic action (Durstewitz &amp; Seamans, 2008; Goschke &amp; Bolte, 2018) given that performance of high performers did not decrease with MA. One could speculate that catecholamines are not the only factor determining eta and performance. Perhaps high performers have a generally more robust/resilient decision-making system which cannot be perturbed easily. Probably one would need even higher doses of MA (with higher side effects) to impair their performance.”</p><disp-quote content-type="editor-comment"><p>Finally, I am confused about why participants are choosing correctly at higher than 50% on the first trial after a reversal (see Figure 3)? How could that be right? If it is not, does this mean that there is a pervasive error in the analysis pipeline?</p></disp-quote><p>Thank you for pointing this out. The observed pattern is an artifact of the smoothing (±2 trials) applied to the learning curves in Figure 3. Below, we reproduce the figure without smoothing.</p><p>Additionally, we confirm that the probability of choosing the correct response is not above chance level (t-test against chance):• All reversals: t(93)=1.64,p=0.10,d=0.17, 99% CI[0.49,0.55]• Reversal to low outcome noise: t(93)=1.67,p=0.10,d=0.17, 99% CI [0.49,0.56]• Reversal to high outcome noise: t(93)=0.87,p=0.38,d=0.09, 99% CI [0.47,0.56]</p><p>We have amended the caption of Figure 3 accordingly. Moreover, we included an additional figure in this revision letter (Author response image 4) showing a clear performance drop to approximately 50% correct choices across all sessions, indicating random-choice behavior at the point of reversal. Notably, this performance is slightly better than expected (i.e., the inverse of pre-reversal performance). One possible explanation is that participants developed an expectation of the reversal, leading to increased reversal behaviour around reversals.</p><fig id="sa3fig3" position="float"><label>Author response image 3.</label><caption><title>Learning curves after reversals suggest that methamphetamine improves learning performance in phases of less predictable reward contingencies in low baseline performer.</title><p>Top panel of the Figure shows learning curves after all reversals (A), reversals to stimuli with less predictable reward contingencies (B), and reversals to stimuli with high reward probability certainty (C). Bottom panel displays the learning curves stratified by baseline performance for all reversals (D), reversals to stimuli with less predictable reward probabilities (E), and reversals to stimuli with high reward probability certainty (F). Vertical black lines divide learning into early and late stages as suggested by the Bai-Perron multiple break point test. Results suggest no clear differences in the initial learning between MA and PL. However, learning curves diverged later in the learning, particular for stimuli with less predictable rewards (B) and in subjects with low baseline performance (E). Note. PL = Placebo; MA = methamphetamine; Mean/SEM = line/shading.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-101413-sa3-fig3-v1.tif"/></fig><fig id="sa3fig4" position="float"><label>Author response image 4.</label><caption><title>Adaptive behavior following reversals.</title><p>Each graph shows participants' performance (i.e., stimulus-appropriate behavior: playing good stimuli with 70/80% reward probability and passing on bad stimuli with 20/30% reward probability) around reversals for the (A) orientation session, (B) placebo session, and (C) methamphetamine session. Trial 0 corresponds to the trial when reversals occurred, unbeknownst to participants. Participants' performance exhibited a fast initial adaptation to reversals, followed by a slower, late-stage adjustment to the new stimulus-reward contingencies, eventually reaching a performance plateau. Notably, we observe a clear performance drop to approximately 50% correct choices across all sessions, indicating random-choice behavior at the point of reversal. This performance is slightly better than expected (i.e., the inverse of pre-reversal performance). One possible explanation is that participants developed an expectation of the reversal, leading to increased reversal behaviour around reversals.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-101413-sa3-fig4-v1.tif"/></fig><disp-quote content-type="editor-comment"><p>Minor comments:</p><p>(1) I'm unclear on what the analysis in 6E tells us. What does it mean that the marginal effect of eta on performance predicts changes in performance? Also, if multiple parameters besides eta (e.g. learning rate) are strongly related to actual performance, why should it be that only marginal adjustments to eta in the model anticipate actual performance improvements when marginal adjustments to other model parameters do not?</p></disp-quote><p>We agree that these simulations are somewhat difficult to interpret and have therefore decided to omit these analyses from the manuscript. Our key point was that individuals who benefited the most from methamphetamine were those who exhibited the most advantageous eta adjustments in response to it. We believe this is effectively illustrated by the example individual shown in Figure 8D.</p><disp-quote content-type="editor-comment"><p>(2) Does the vertical black line in Figure 1 show when the tasks were completed, as it says in the caption, or when the task starts, as it indicates in the figure itself?</p></disp-quote><p>Apologies for the confusion. There was a mistake in the figure caption—the vertical line indicates the time when the task started (60 minutes post-capsule intake). We have corrected this in the figure caption.</p><disp-quote content-type="editor-comment"><p>(3) The marginally significant drug x baseline performance group interaction does not support strong inferences about differences in drug effects on eta between groups...</p></disp-quote><p>We agree and have added information on this limitation to the Discussion. Additionally, we have addressed the complex relationship between drug effects and baseline performance in the supplementary analyses, as detailed in our previous response regarding the binary discretization of baseline performance.</p><disp-quote content-type="editor-comment"><p>(4) Should lines 10-11 on page 12 say &quot;We did not find drug-related differences in any other model parameters...&quot;?</p></disp-quote><p>Thank you for bringing this grammatical error to our attention. We have corrected it.</p><disp-quote content-type="editor-comment"><p>(5) It would be good to confirm that the effect of MA on p(Correct after single MFB) does not have an opposite sign from the effect of MA on p(Correct after double MFB). I'm guessing the effect after single is just weak, but it would be good to confirm they are in the same direction so that we can be confident the result is not picking up on spurious relationships after two misleading instances of feedback.</p></disp-quote><p>We confirm that the direction of the effect between eta and p(Correct after single MFB) is similar to p(Correct after double MFB). First, we see a similar negative association between p(Correct after single MFB) and eta (r(94) = -.26, p = 0.01). Similarly there was a descriptive increase in p(Correct after single MFB) for low baseline performer on- vs. off-drug (p(Correct after single MFB): low baseline performance PL: 0.71 (0.02) vs. low baseline performance MA:0.73 (0.02); t(46) = 1.27, p = 0.20, d = 0.17).</p><disp-quote content-type="editor-comment"><p>(6) &quot;implemented equipped&quot; seems like a typo on page 16, line 26</p></disp-quote><p>Thank you for bringing this typo to our attention. We have corrected it.</p><disp-quote content-type="editor-comment"><p><bold>Reviewing Editor (Public Review):</bold></p><p>Summary:</p><p>In this well-written paper, a pharmacological experiment is described in which a large group of volunteers is tested on a novel probabilistic reversal learning task with different levels of noise, once after intake of methamphetamine and once after intake of placebo. The design includes a separate baseline session, during which performance is measured. The key result is that drug effects on learning rate variability depend on performance in this separate baseline session.</p><p>The approach and research question are important, the results will have an impact, and the study is executed according to current standards in the field. Strengths include the interventional pharmacological design, the large sample size, the computational modeling, and the use of a reversal-learning task with different levels of noise.</p><p>(i) One novel and valuable feature of the task is the variation of noise (having 70-30 and 8020 conditions). This nice feature is currently not fully exploited in the modeling of the task and the data. For example, recently reported new modeling approaches for disentangling two types of uncertainty (stochasticity vs volatility) could be usefully leveraged here (by Piray and Daw, 2021, Nat Comm). The current 'signal to noise ratio' analysis that is targeting this issue relies on separately assessing learning rates on true reversals and learning rates after misleading feedback, in a way that is experimenter-driven. As a result, this analysis cannot capture a latent characteristic of the subject's computational capacity.</p></disp-quote><p>We thank the reviewing editor for the positive evaluation of our work and the suggestion to leverage new modeling approaches. In the light of the Piray/Daw paper, it is noteworthy, that the choice behavior of the low performance group in our sample mimics the behavior of their lesioned model, in which stochasticity is assumed to be small and constant. Specifically, low performers displayed higher learning rates, particularly in high outcome noise phases in our task. One possible interpretation of this choice pattern is that they have problems to distinguish volatility and noise. Consistently, surprising outcomes may get misattributed to volatility instead of stochasticity resulting in increased learning rates and overadjustments to misleading outcomes. This issue particularly surfaces in phases of high stochasticity in our task. Interestingly, methamphetamine seems to reduce this misattribution. In an exploratory analysis, we fit two models to our task structure using modified code provided by the Piray and Daw paper. The control model made inference about both the volatility and stochasticity. A key assumption of the model is, that the optimal learning rate increases with volatility and decreases with stochasticity. This is because greater volatility raises the likelihood that the underlying reward probability has changed since the last observation, increasing the necessity of relying on new information. In contrast, higher stochasticity reduces the relative informativeness of the new observation compared to prior beliefs about the underlying reward probability. The lesioned model assumed stochasticity to be small and constant. We show the results of this analyses in Figure 9 and Supplementary Figure S5 and S6. Interestingly, we found that the inability to make inference about stochasticity leads to misestimation of volatility, particularly for high outcome noise phases (Figure 9A-B). Consistently, this led to reduced sensitivity of the learning rate to volatility (i.e., the first ten trials after reversals). The model shows similar behaviour to our low performer group, with reduced accuracy in later learnings stages for stimuli with high outcome noise (Figure 9D). Finally, when we fit simulated data from the two models to our model, we see increased eta parameter estimates for the lesioned model. Together, these results may hint towards an overinterpretation of stochasticity in low performers of our task and that methamphetamine has beneficial effects for those individuals as it reduced the oversensitivity to volatility. It should be noted however, that we did not fit these models to our choice behaviour directly as this implementation is beyond the scope of our current study. Yet, our exploratory analyses make testable predictions for future research into the effect of catecholamines on the inference of volatility and stochasticity.</p><p>We incorporated information on these explorative analyses to the manuscript and supplementary material.</p><p>Form the result section (page 23, line 12ff):</p><p>“Methamphetamine may reduce misinterpretation of high outcome noise in low performers</p><p>In our task, outcomes are influenced by two distinct sources of noise: process noise (volatility) and outcome noise (stochasticity). Optimal learning rate should increase with volatility and decrease with stochasticity. Volatility was fairly constant in our task (change points around every 30-35 trials). However, misleading feedback (i.e., outcome noise) could be misinterpreted as indicating another change point because participants don’t know the volatility beforehand. Strongly overinterpreting outcome noise as change points will hinder building a correct estimate of volatility and understanding the true structure of the task. Simultaneously estimating volatility and stochasticity poses a challenge, as both contribute to greater outcome variance, making outcomes more surprising. A critical distinction, however, lies in their impact on generated outcomes: volatility increases the autocorrelation between consecutive outcomes, whereas stochasticity reduces it. Recent computational approaches have successfully utilised this fundamental difference to formulate a model of learning based on the joint estimation of stochasticity and volatility (Piray &amp; Daw, 2021; Piray &amp; Daw, 2024). They report evidence that humans successfully dissociate between volatility and stochasticity with contrasting and adaptive effects on learning rates, albeit to varying degrees. Interestingly they show that hypersensitivity to outcome noise, often observed in anxiety disorders, might arise from a misattribution of the outcome noise to volatility instead of stochasticity resulting in increased learning rates and overadjustments to misleading outcomes. It is noteworthy, that we observed a similar hypersensitivity to high outcome noise in low performers in our task that is partly reduced by MA. In an exploratory analysis, we fit two models to our task structure using modified code provided by Piray and Daw (2021) (see Methods for formal Description of the model). The control model inferred both the volatility and stochasticity. The lesioned model assumed stochasticity to be small and constant. We show the results of this analyses in Figure 9 and Supplementary Figure S7 and S8. We found that the inability to make inference about stochasticity, leads to misestimation of volatility, particularly for high outcome noise phases (Figure 9A-B). Consistently, this led to reduced sensitivity of the learning rate to volatility (i.e., the first ten trials after reversals). The model shows similar behaviour to our low performer group, with reduced accuracy in later learning stages for stimuli with high outcome noise (Figure 9D). Finally, when we fit simulated data from the two models to our model, we see increased eta parameter estimates for the lesioned model. Together, these results may hint towards an overinterpretation of stochasticity in low performer of our task and that MA has beneficial effects for those individuals as it reduced the oversensitivity to volatility. It should be noted however, that we did not fit these models to our choice behaviour directly as this implementation is beyond the scope of our current study. Yet, our exploratory analyses make testable predictions for future research into the effect of catecholamines on the inference of volatility and stochasticity.”</p><p>From the discussion (page 28, line 15ff):</p><p>“Exploratory simulation studies using a model that jointly estimates stochasticity and volatility (Piray &amp; Daw, 2021; Piray &amp; Daw, 2024), revealed that MA might reduce the oversensitivity to volatility.”</p><p>See methods section “Description of the joint estimation of stochasticity and volatility model “</p><disp-quote content-type="editor-comment"><p>(ii) An important caveat is that all the drug x baseline performance interactions, including for the key computational eta parameter did not reach the statistical threshold, and only tended towards significance.</p></disp-quote><p>We agree and have added additional analyses on the issue. See also our response to reviewer 2. There is a consistent effect for low-medium baseline performance. We toned done the reference to low baseline performance but still see strong evidence for a baseline dependency of the drug effect.</p><p>From the manuscript (page 30, line 4ff):</p><p>“Methamphetamine performance enhancement depends on initial task performance</p><p>Another key finding of the current study is that the benefits of MA on performance depend on the baseline task performance. Specifically, we found that MA selectively improved performance in participants that performed poorly in the baseline session. However, it should be noted, that all the drug x baseline performance interactions, including for the key computational eta parameter did not reach the statistical threshold, and only tended towards significance. We used a binary discretization of baseline performance to simplify the analysis and presentation. To parse out the relationship between methamphetamine effects and baseline performance into finer level of detail, we conducted additional linear mixed-effects model (LMM) analyses using a sliding window regression approach (see supplementary results and supplementary figure S4 and S5). A key thing to notice in the sliding regression results is that, while each regression reveals that drug effects depend on baseline performance, they do so non-linearly, with most variables of interest showing a saturating effect at low baseline performance levels and the strongest slope (dependence on baseline) at or near the median level of baseline performance, explaining why our median splits were able to successfully pick up on these baseline-dependent effects. Together, these results suggest that methamphetamine primarily affects moderately low baseline performer. It is noteworthy to highlight again that we had a separate baseline measurement from the placebo session, allowing us to investigate baseline-dependent changes while avoiding typical concerns in such analyses like regression to the mean (Barnett et al., 2004). This design enhances the robustness of our baseline-dependent effects.”</p><disp-quote content-type="editor-comment"><p>(iii) Both the overlap and the differences between the current study and previous relevant work (that is, how this goes beyond prior studies in particular Rostami Kandroodi et al, which also assessed effects of catecholaminergic drug administration as a function of baseline task performance using a probabilistic reversal learning task) are not made explicit, particularly in the introduction.</p></disp-quote><p>Thank you for raising this point. We have added information of the overlap and differences between our paper and the Rostami Kondoodi et al paper to the introduction and disscussion.</p><p>In the intoduction we added a sentence to higlight the Kondoordi findings (page 3, line 24ff).</p><disp-quote content-type="editor-comment"><p>For example, Rostami Kandroodi et al. (2021) reported that the re-uptake blocker methylphenidate did not alter reversal learning overall, but preferentially improved performance in participants with higher working memory capacity.”</p></disp-quote><p>In our Discussion, we go back to this paper, and say how our findings are and are not consistent with their findings (page 32, line 16ff).</p><disp-quote content-type="editor-comment"><p>Our findings can be contrasted to those of Rostami Kandroodi et al. (2021), who examined effects of methylphenidate on a reversal learning task, in relation to baseline differences on a cognitive task. Whereas Rostami Kandroodi et al. (2021) found that the methylphenidate improved performance mainly in participants with higher baseline working memory performance, we found that methamphetamine improved the ability to dynamically adjust learning from prediction errors to a greater extent in participants who performed poorly-tomedium at baseline. There are several possible reasons for these apparently different findings. First, MA and methylphenidate differ in their primary mechanisms of action: MPH acts mainly as a reuptake blocker whereas MA increases synaptic levels of catecholamines by inhibiting the vesicular monoamine transporter 2 (VMAT2) and inhibiting the enzyme monoamine oxidase (MAO). These differences in action could account for differential effects on cognitive tasks. Second, the tasks used by Rostami Kandroodi et al. (2021) and the present study differ in several ways. The Rostami Kandroodi et al. (2021) task assessed responses to a single reversal event during the session whereas the present study used repeated reversals with probabilistic outcomes. Third, the measures of baseline function differed in the two studies: Rostami Kandroodi et al. (2021) used a working memory task that was not used in the drug sessions, whereas we used the probabilistic learning task as both the baseline measure and the measure of drug effects. Further research is needed to determine which of these factors influenced the outcomes.”</p><p>performance effects, but this is not true in the general sense, given that an accumulating number of studies have shown that the effects of drugs like MA depend on baseline performance on working memory tasks, which often but certainly not always correlates positively with performance on the task under study.</p></disp-quote><p>We recognize that there is a large body of research reporting that the effects of stimulant drugs are related to baseline performance, and we have adjusted our wording in the Discussion accordingly. At the same time, numerous published studies report acute effects of drugs without considering individual differences in responses, including baseline differences in task performance.</p><disp-quote content-type="editor-comment"><p><bold>Reviewing Editor (Recommendations for the Authors):</bold></p><p>(i) To leverage recently reported new modeling approaches for disentangling two types of uncertainty (stochasticity vs volatility) might be usefully leveraged (Piray and Daw, 2021, Nat Comm) to help overcome the shortcomings of the 'signal-to-noise ratio' analysis performed here (learning rates on true reversals minus learning rates after misleading feedback) which is experimenter-driven, and thus cannot capture a latent characteristic of the subject's computational capacity.</p></disp-quote><p>Please see our previous response.</p><disp-quote content-type="editor-comment"><p>(ii) To highlight more explicitly the fact that various of the key drug x baseline performance interactions did not reach the statistical threshold.</p></disp-quote><p>Please see our previous responses to this issue.</p><disp-quote content-type="editor-comment"><p>(iii) To make more explicit, in the introduction, both the overlap and the differences between the current study and previous relevant work (that is, how this goes beyond prior study in particular Rostami Kandroodi et al, which also assessed effects of catecholaminergic drug administration as a function of baseline task performance using a probabilistic reversal learning task).</p></disp-quote><p>Please see our previous response.</p><disp-quote content-type="editor-comment"><p>(iv) To revise and tone down, in the discussion section, the statement about novelty, that the existing literature has, to date, overlooked baseline performance effects.</p></disp-quote><p>Please see our previous response.</p><disp-quote content-type="editor-comment"><p>(v) It is unclear why the data from the 4th session (under some other sedative drug, which is not mentioned) are not reported. I recommend justifying the details of this manipulation and the decision to omit the report of those results. By analogy 4 other tasks were administered in the current study, but not described. Is there a protocol paper, describing the full procedure?</p></disp-quote><p>Thank you for pointing this out. We added additional information to the method section. We are analysing the other cognitive measures in relation to the brain imaging data obtained on sessions 3 and 4. Therefore we argue, that these are beyond the scope of the present paper. We did not administer any sedative drug. However, participants were informed during orientation that they might receive a stimulant, sedative, or placebo on any testing session to maintain blinding of their expectations before each session.</p><p>“Design. The results presented here were obtained from the first two sessions of a larger foursession study (<ext-link ext-link-type="uri" xlink:href="https://clinicaltrials.gov/">https://clinicaltrials.gov/</ext-link> ID number NCT04642820). During the latter two sessions of the larger study, not reported here, participants participated in two fMRI scans. During the two 4-h laboratory sessions presented here, healthy adults received methamphetamine (20 mg oral; MA) or placebo (PL), in mixed order under double-blind conditions. One hour after ingesting the capsule they completed the 30-min reinforcement reversal learning task. The primary comparisons were on acquisition and reversal learning parameters of reinforcement learning after MA vs PL. Secondary measures included subjective and cardiovascular responses to the drug.”</p><p>“Orientation session. Participants attended an initial orientation session to provide informed consent, and to complete personality questionnaires. They were told that the purpose of the study was to investigate the effects of psychoactive drugs on mood, brain, and behavior. To reduce expectancies, they were told that they might receive a placebo, stimulant, or sedative/tranquilizer. However, participants only received methamphetamine and placebo. They agreed not to use any drugs except for their normal amounts of caffeine for 24 hours before and 6 hours following each session. Women who were not on oral contraceptives were tested only during the follicular phase (1-12 days from menstruation) because responses to stimulant drugs are dampened during the luteal phase of the cycle (White et al., 2002). Most participants (N=97 out of 113) completed the reinforcement learning task during the orientation session as a baseline measurement. This measure was added after the study began. Participants who did not complete the baseline measurement were omitted from the analyses presented in the main text. We run the key analyses on the full sample (n=109). This sample included participants who completed the task only on the drug sessions. When controlling for session order and number (two vs. three sessions) effects, we see no drug effect on overall performance and learning. Yet, we found that eta was also reduced under MA in the full sample, which also resulted in reduced variability in the learning rate (see supplementary results for more details).”</p><p>“Drug sessions. The two drug sessions were conducted in a comfortable laboratory environment, from 9 am to 1 pm, at least 72 hours apart. Upon arrival, participants provided breath and urine samples to test for recent alcohol or drug use and pregnancy (CLIAwaived Inc,Carlsbad, CAAlcosensor III, Intoximeters; AimStickPBD, hCG professional, Craig Medical Distribution). Positive tests lead to rescheduling or dismissal from the study. After drug testing, subjects completed baseline mood measures, and heart rate and blood pressure were measured. At 9:30 am they ingested capsules (PL or MA 20 mg, in color-coded capsules) under double-blind conditions. Oral MA (Desoxyn, 5 mg per tablet) was placed in opaque size 00 capsules with dextrose filler. PL capsules contained only dextrose. Subjects completed the reinforcement learning task 60 minutes after capsule ingestion. Drug effects questionnaires were obtained at multiple intervals during the session. They completed other cognitive tasks not reported here. Participants were tested individually and were permitted to relax, read or watch neutral movies when they were not completing study measures.”</p><disp-quote content-type="editor-comment"><p>(vi) Some features of the model including the play bias parameter require justification, at least by referring to prior work exploring these features.</p></disp-quote><p>We have added information to justify the features of the model.</p><p>Form the method section:</p><p>“The base model (M1) was a standard Q-learning model with three parameters: (1) an inverse temperature parameter of the softmax function used to convert trial expected values to action probabilities, (2) a play bias term that indicates a tendency to attribute higher value to gambling behavior (Jang et al., 2019), ….</p><p>The two additional learning rate terms—feedback confirmation and modality—were added to the model set, as these factors have been shown to influence learning in similar tasks (Kirschner et al., 2023; Schüller et al., 2020).”</p><p>Literature</p><p>Doucet, A., &amp; Johansen, A. M. (2011). A tutorial on particle filtering and smoothing: fifteen years later. Oxford University Press.</p><p>Durstewitz, D., &amp; Seamans, J. K. (2008). The dual-state theory of prefrontal cortex dopamine function with relevance to catechol-o-methyltransferase genotypes and schizophrenia. Biol Psychiatry, 64(9), 739-749. <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1016/j.biopsych.2008.05.015">https://doi.org/10.1016/j.biopsych.2008.05.015</ext-link></p><p>Gamerman, D., dos Santos, T. R., &amp; Franco, G. C. (2013). A NON-GAUSSIAN FAMILY OF STATE-SPACE MODELS WITH EXACT MARGINAL LIKELIHOOD. Journal of Time Series Analysis, 34(6), 625-645.</p><p><ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1111/jtsa.12039">https://doi.org/10.1111/jtsa.12039</ext-link></p><p>Goschke, T., &amp; Bolte, A. (2018). A dynamic perspective on intention, conflict, and volition: Adaptive regulation and emotional modulation of cognitive control dilemmas. In Why people do the things they do: Building on Julius Kuhl’s contributions to the psychology of motivation and volition. (pp. 111-129). Hogrefe. <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1027/00540-000">https://doi.org/10.1027/00540-000</ext-link></p><p>Jang, A. I., Nassar, M. R., Dillon, D. G., &amp; Frank, M. J. (2019). Positive reward prediction errors during decision-making strengthen memory encoding. Nature Human Behaviour, 3(7), 719-732. <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1038/s41562-019-0597-3">https://doi.org/10.1038/s41562-019-0597-3</ext-link></p><p>Jenkins, D. G., &amp; Quintana-Ascencio, P. F. (2020). A solution to minimum sample size for regressions. PLoS One, 15(2), e0229345. <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1371/journal.pone.0229345">https://doi.org/10.1371/journal.pone.0229345</ext-link></p><p>Kirschner, H., Nassar, M. R., Fischer, A. G., Frodl, T., Meyer-Lotz, G., Froböse, S., Seidenbecher, S., Klein, T. A., &amp; Ullsperger, M. (2023). Transdiagnostic inflexible learning dynamics explain deficits in depression and schizophrenia. Brain, 147(1), 201-214. <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1093/brain/awad362">https://doi.org/10.1093/brain/awad362</ext-link></p><p>Maris, E., &amp; Oostenveld, R. (2007). Nonparametric statistical testing of EEG- and MEG-data. Journal of Neuroscience Methods, 164(1), 177-190.</p><p><ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1016/j.jneumeth.2007.03.024">https://doi.org/10.1016/j.jneumeth.2007.03.024</ext-link></p><p>Morean, M. E., de Wit, H., King, A. C., Sofuoglu, M., Rueger, S. Y., &amp; O'Malley, S. S. (2013). The drug effects questionnaire: psychometric support across three drug types. Psychopharmacology (Berl), 227(1), 177-192. <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1007/s00213-0122954-z">https://doi.org/10.1007/s00213-0122954-z</ext-link></p><p>Murphy, K., &amp; Russell, S. (2001). Rao-Blackwellised particle filtering for dynamic Bayesian networks. In Sequential Monte Carlo methods in practice (pp. 499-515). Springer. Piray, P., &amp; Daw, N. D. (2020). A simple model for learning in volatile environments. PLoS Comput Biol, 16(7), e1007963. <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1371/journal.pcbi.1007963">https://doi.org/10.1371/journal.pcbi.1007963</ext-link></p><p>Piray, P., &amp; Daw, N. D. (2021). A model for learning based on the joint estimation of stochasticity and volatility. Nature Communications, 12(1), 6587. <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1038/s41467-021-26731-9">https://doi.org/10.1038/s41467-021-26731-9</ext-link></p><p>Piray, P., &amp; Daw, N. D. (2024). Computational processes of simultaneous learning of stochasticity and volatility in humans. Nat Commun, 15(1), 9073. <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1038/s41467-024-53459-z">https://doi.org/10.1038/s41467-024-53459-z</ext-link></p><p>Rostami Kandroodi, M., Cook, J. L., Swart, J. C., Froböse, M. I., Geurts, D. E. M., Vahabie, A. H., Nili Ahmadabadi, M., Cools, R., &amp; den Ouden, H. E. M. (2021). Effects of methylphenidate on reinforcement learning depend on working memory capacity. Psychopharmacology (Berl), 238(12), 3569-3584. <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1007/s00213021-05974-w">https://doi.org/10.1007/s00213021-05974-w</ext-link></p><p>Schüller, T., Fischer, A. G., Gruendler, T. O. J., Baldermann, J. C., Huys, D., Ullsperger, M., &amp; Kuhn, J. (2020). Decreased transfer of value to action in Tourette syndrome. Cortex, 126, 39-48. <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1016/j.cortex.2019.12.027">https://doi.org/10.1016/j.cortex.2019.12.027</ext-link></p><p>West, M. (1987). On scale mixtures of normal distributions. Biometrika, 74(3), 646-648. <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1093/biomet/74.3.646">https://doi.org/10.1093/biomet/74.3.646</ext-link></p><p>White, T. L., Justice, A. J., &amp; de Wit, H. (2002). Differential subjective effects of Damphetamine by gender, hormone levels and menstrual cycle phase. Pharmacol Biochem Behav, 73(4), 729-741.</p></body></sub-article></article>