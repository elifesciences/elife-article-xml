<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD with MathML3 v1.3 20210610//EN"  "JATS-archivearticle1-3-mathml3.dtd"><article xmlns:ali="http://www.niso.org/schemas/ali/1.0/" xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" article-type="research-article" dtd-version="1.3"><front><journal-meta><journal-id journal-id-type="nlm-ta">elife</journal-id><journal-id journal-id-type="publisher-id">eLife</journal-id><journal-title-group><journal-title>eLife</journal-title></journal-title-group><issn publication-format="electronic" pub-type="epub">2050-084X</issn><publisher><publisher-name>eLife Sciences Publications, Ltd</publisher-name></publisher></journal-meta><article-meta><article-id pub-id-type="publisher-id">107163</article-id><article-id pub-id-type="doi">10.7554/eLife.107163</article-id><article-id pub-id-type="doi" specific-use="version">10.7554/eLife.107163.3</article-id><article-version article-version-type="publication-state">version of record</article-version><article-categories><subj-group subj-group-type="display-channel"><subject>Research Article</subject></subj-group><subj-group subj-group-type="heading"><subject>Computational and Systems Biology</subject></subj-group><subj-group subj-group-type="heading"><subject>Neuroscience</subject></subj-group></article-categories><title-group><article-title>Predicting human decision-making across task conditions via individuality transfer</article-title></title-group><contrib-group><contrib contrib-type="author" corresp="yes"><name><surname>Higashi</surname><given-names>Hiroshi</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">https://orcid.org/0000-0001-8880-3411</contrib-id><email>higashi@comm.eng.osaka-u.ac.jp</email><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="fn" rid="pa1">†</xref><xref ref-type="other" rid="fund3"/><xref ref-type="fn" rid="con1"/><xref ref-type="fn" rid="conf1"/></contrib><aff id="aff1"><label>1</label><institution-wrap><institution-id institution-id-type="ror">https://ror.org/035t8zc32</institution-id><institution>The University of Osaka</institution></institution-wrap><addr-line><named-content content-type="city">Osaka</named-content></addr-line><country>Japan</country></aff></contrib-group><contrib-group content-type="section"><contrib contrib-type="editor"><name><surname>Li</surname><given-names>Jian</given-names></name><role>Reviewing Editor</role><aff><institution-wrap><institution-id institution-id-type="ror">https://ror.org/02v51f717</institution-id><institution>Peking University</institution></institution-wrap><country>China</country></aff></contrib><contrib contrib-type="senior_editor"><name><surname>Frank</surname><given-names>Michael J</given-names></name><role>Senior Editor</role><aff><institution-wrap><institution-id institution-id-type="ror">https://ror.org/05gq02987</institution-id><institution>Brown University</institution></institution-wrap><country>United States</country></aff></contrib></contrib-group><author-notes><fn fn-type="present-address" id="pa1"><label>†</label><p>Graduate School of Engineering, The University of Osaka, Suita, Japan</p></fn></author-notes><pub-date publication-format="electronic" date-type="publication"><day>19</day><month>01</month><year>2026</year></pub-date><volume>14</volume><elocation-id>RP107163</elocation-id><history><date date-type="sent-for-review" iso-8601-date="2025-04-30"><day>30</day><month>04</month><year>2025</year></date></history><pub-history><event><event-desc>This manuscript was published as a preprint.</event-desc><date date-type="preprint" iso-8601-date="2025-04-09"><day>09</day><month>04</month><year>2025</year></date><self-uri content-type="preprint" xlink:href="https://doi.org/10.1101/2025.03.25.645375"/></event><event><event-desc>This manuscript was published as a reviewed preprint.</event-desc><date date-type="reviewed-preprint" iso-8601-date="2025-06-27"><day>27</day><month>06</month><year>2025</year></date><self-uri content-type="reviewed-preprint" xlink:href="https://doi.org/10.7554/eLife.107163.1"/></event><event><event-desc>The reviewed preprint was revised.</event-desc><date date-type="reviewed-preprint" iso-8601-date="2025-12-22"><day>22</day><month>12</month><year>2025</year></date><self-uri content-type="reviewed-preprint" xlink:href="https://doi.org/10.7554/eLife.107163.2"/></event></pub-history><permissions><copyright-statement>© 2025, Higashi</copyright-statement><copyright-year>2025</copyright-year><copyright-holder>Higashi</copyright-holder><ali:free_to_read/><license xlink:href="http://creativecommons.org/licenses/by/4.0/"><ali:license_ref>http://creativecommons.org/licenses/by/4.0/</ali:license_ref><license-p>This article is distributed under the terms of the <ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/licenses/by/4.0/">Creative Commons Attribution License</ext-link>, which permits unrestricted use and redistribution provided that the original author and source are credited.</license-p></license></permissions><self-uri content-type="pdf" xlink:href="elife-107163-v1.pdf"/><abstract><p>Predicting an individual's behavior in one task condition based on their behavior in a different condition is a key challenge in modeling individual decision-making tendencies. We propose a novel framework that addresses this challenge by leveraging neural networks and introducing a concept we term the ‘individual latent representation’. This representation, extracted from behavior in a ‘source’ task condition via an encoder network, captures an individual's unique decision-making tendencies. A decoder network then utilizes this representation to generate the weights of a task-specific neural network (a ‘task solver’), which predicts the individual's behavior in a ‘target' task condition. We demonstrate the effectiveness of our approach in two distinct decision-making tasks: a value-guided task and a perceptual task. Our framework offers a robust and generalizable approach for parameterizing individual variability, providing a promising pathway toward computational modeling at the individual level—replicating individuals in silico.</p></abstract><kwd-group kwd-group-type="author-keywords"><kwd>decision making</kwd><kwd>individuality</kwd><kwd>latent representation</kwd></kwd-group><kwd-group kwd-group-type="research-organism"><title>Research organism</title><kwd>Human</kwd></kwd-group><funding-group><award-group id="fund1"><funding-source><institution-wrap><institution-id institution-id-type="ror">https://ror.org/00hhkn466</institution-id><institution>Japan Society for the Promotion of Science</institution></institution-wrap></funding-source><award-id>22H05163</award-id><principal-award-recipient><name><surname>Higashi</surname><given-names>Hiroshi</given-names></name></principal-award-recipient></award-group><award-group id="fund2"><funding-source><institution-wrap><institution-id institution-id-type="ror">https://ror.org/00097mb19</institution-id><institution>Japan Science and Technology Agency</institution></institution-wrap></funding-source><award-id award-id-type="doi">10.52926/jpmjkb2307</award-id><principal-award-recipient><name><surname>Higashi</surname><given-names>Hiroshi</given-names></name></principal-award-recipient></award-group><award-group id="fund3"><funding-source><institution-wrap><institution-id institution-id-type="ror">https://ror.org/00hhkn466</institution-id><institution>Japan Society for the Promotion of Science</institution></institution-wrap></funding-source><award-id>24K15047</award-id><principal-award-recipient><name><surname>Higashi</surname><given-names>Hiroshi</given-names></name></principal-award-recipient></award-group><funding-statement>The funders had no role in study design, data collection and interpretation, or the decision to submit the work for publication.</funding-statement></funding-group><custom-meta-group><custom-meta specific-use="meta-only"><meta-name>Author impact statement</meta-name><meta-value>Encoding individual behavioral traits into a low-dimensional latent representation enables the accurate prediction of decision-making patterns across distinct task conditions.</meta-value></custom-meta><custom-meta specific-use="meta-only"><meta-name>publishing-route</meta-name><meta-value>prc</meta-value></custom-meta></custom-meta-group></article-meta></front><body><sec id="s1" sec-type="intro"><title>Introduction</title><p>Humans (and other animals) exhibit substantial commonalities in their decision-making processes. However, considerable variability is also frequently observed in how individuals perform perceptual and cognitive decision-making tasks (<xref ref-type="bibr" rid="bib5">Carroll and Maxwell, 1979</xref>; <xref ref-type="bibr" rid="bib1">Boogert et al., 2018</xref>). This variability arises from differences in underlying cognitive mechanisms. For example, individuals may vary in their ability or tendency to retain past experiences (<xref ref-type="bibr" rid="bib12">Duncan and Shohamy, 2016</xref>; <xref ref-type="bibr" rid="bib8">Collins and Frank, 2012</xref>), respond to events with both speed and accuracy (<xref ref-type="bibr" rid="bib53">Wagenmakers and Brown, 2007</xref>; <xref ref-type="bibr" rid="bib46">Spoerer et al., 2020</xref>), or explore novel actions (<xref ref-type="bibr" rid="bib17">Frank et al., 2009</xref>). If these factors can be meaningfully disentangled, they would enable a concise characterization of individual decision-making processes, yielding a low-dimensional, parameterized representation of individuality. Such a representation could, in turn, be leveraged to predict future behaviors at an individual level. Shifting from population-level predictions to an individual-based approach would mark a significant advancement in domains where precise behavior prediction is essential, such as social and cognitive sciences. Beyond prediction, this approach offers a framework for parameterizing and clustering individuals, thereby facilitating the visualization of behavioral heterogeneity, which has applications in psychiatric analysis (<xref ref-type="bibr" rid="bib32">Pedersen et al., 2017</xref>; <xref ref-type="bibr" rid="bib10">Dezfouli et al., 2019a</xref>). Furthermore, this parameterization offers a promising pathway toward computational modeling at the individual level—replicating the cognitive and functional characteristics of individuals in silico (<xref ref-type="bibr" rid="bib42">Shengli, 2021</xref>).</p><p>Cognitive modeling is a standard approach for reproducing and predicting human behavior (<xref ref-type="bibr" rid="bib30">Navarro et al., 2006</xref>; <xref ref-type="bibr" rid="bib3">Busemeyer and Stout, 2002</xref>; <xref ref-type="bibr" rid="bib58">Yechiam et al., 2005</xref>), often implemented within a reinforcement learning framework (e.g. <xref ref-type="bibr" rid="bib31">O’Doherty et al., 2007</xref>; <xref ref-type="bibr" rid="bib9">Daw et al., 2011</xref>; <xref ref-type="bibr" rid="bib55">Wilson and Collins, 2019</xref>). However, because these cognitive models are manually designed by researchers, their ability to accurately fit behavioral data may be limited (<xref ref-type="bibr" rid="bib16">Fintz et al., 2022</xref>; <xref ref-type="bibr" rid="bib45">Song et al., 2021</xref>; <xref ref-type="bibr" rid="bib29">Miller et al., 2023</xref>; <xref ref-type="bibr" rid="bib13">Eckstein et al., 2022</xref>). A data-driven approach using artificial neural networks (ANNs) offers an alternative (<xref ref-type="bibr" rid="bib11">Dezfouli et al., 2019b</xref>; <xref ref-type="bibr" rid="bib34">Radev et al., 2022</xref>; <xref ref-type="bibr" rid="bib40">Schaeffer et al., 2020</xref>). Unlike cognitive models, which rely on predefined behavioral assumptions (<xref ref-type="bibr" rid="bib38">Rmus et al., 2024</xref>), ANNs require minimal prior assumptions and can learn complex patterns directly from data. For instance, convolutional neural networks (CNNs) have successfully replicated human choices and reaction times in various visual tasks (<xref ref-type="bibr" rid="bib26">Kriegeskorte, 2015</xref>; <xref ref-type="bibr" rid="bib36">Rajalingham et al., 2018</xref>; <xref ref-type="bibr" rid="bib15">Fel et al., 2022</xref>). Similarly, recurrent neural networks (RNNs; <xref ref-type="bibr" rid="bib43">Siegelmann and Sontag, 1995</xref>; <xref ref-type="bibr" rid="bib7">Cho et al., 2014</xref>) have been applied to model value-guided decision-making tasks such as the multi-armed bandit problem (<xref ref-type="bibr" rid="bib57">Yang et al., 2019</xref>; <xref ref-type="bibr" rid="bib10">Dezfouli et al., 2019a</xref>). A promising approach to capturing individual decision-making tendencies while preserving behavioral consistency is to tune ANN weights using a parameterized representation of individuality.</p><p>This idea was first proposed by <xref ref-type="bibr" rid="bib10">Dezfouli et al., 2019a</xref>, who employed an RNN to solve a two-armed bandit task. Their study utilized an autoencoder framework (<xref ref-type="bibr" rid="bib39">Rumelhart and McClelland, 1987</xref>; <xref ref-type="bibr" rid="bib49">Tolstikhin et al., 2017</xref>), in which behavioral recordings from a single session of the bandit task, performed by an individual, were fed into an encoder. The encoder produced a low-dimensional vector, interpreted as a latent representation of the individual. Similar to hypernetworks (<xref ref-type="bibr" rid="bib20">Ha et al., 2016</xref>; <xref ref-type="bibr" rid="bib23">Karaletsos et al., 2018</xref>), a decoder then took this low-dimensional vector as input and generated the weights of the RNN. This framework successfully reproduced behavioral recordings from other sessions of the same bandit task while preserving individual characteristics. However, since this individuality transfer has only been validated within the bandit task, it remains unclear whether the extracted latent representation captures an individual’s intrinsic tendencies across a variety of task conditions.</p><p>To address this question, we aim to make the low-dimensional representation—referred to as the <italic>individual latent representation</italic>—robust to variations across individuals and task conditions, thereby enhancing its generalizability. Specifically, we propose a framework that predicts an individual’s behaviors, not only in the same condition but also in similar yet distinct task conditions and environments. If the individual latent representation serves as a low-dimensional representation of an individual’s decision-making process, then extracting it from one condition could facilitate the prediction of that individual’s behaviors in another.</p><p>In this study, we define the problem of <italic>individuality transfer across task conditions</italic> as follows (also illustrated in <xref ref-type="fig" rid="fig1">Figure 1</xref>). We assume access to a behavioral dataset from multiple individuals performing two task conditions: a <italic>source task condition</italic> and a <italic>target task condition</italic>. We train an encoder that takes behavioral data from the source task condition as input and outputs an individual latent representation. This representation is then fed into a decoder, which generates the weights of an ANN, referred to as a <italic>task solver</italic>, that reproduces behaviors in the target task condition. For testing, a new individual provides behavioral data from the source task condition, allowing us to infer his/her individual latent representation. Using this representation, a task solver is constructed to predict how the test individual will behave in the target task condition. Importantly, this prediction does not require any behavioral data from the test individual performing the target task condition. We refer to this framework as <italic>EIDT</italic>, an acronym for encoder, individual latent representation, decoder, and task solver.</p><fig id="fig1" position="float"><label>Figure 1.</label><caption><title>The EIDT (encoder, individual latent representation, decoder, and task solver) framework for individuality transfer across task conditions.</title><p>The encoder maps action(s) <italic>α</italic>, provided by an individual <inline-formula><alternatives><mml:math id="inf1"><mml:mi>K</mml:mi></mml:math><tex-math id="inft1">\begin{document}$K$\end{document}</tex-math></alternatives></inline-formula> performing a specific problem <inline-formula><alternatives><mml:math id="inf2"><mml:mi>ϕ</mml:mi></mml:math><tex-math id="inft2">\begin{document}$\phi$\end{document}</tex-math></alternatives></inline-formula> in the source task condition <inline-formula><alternatives><mml:math id="inf3"><mml:mi>A</mml:mi></mml:math><tex-math id="inft3">\begin{document}$A$\end{document}</tex-math></alternatives></inline-formula>, into an individual latent representation (represented as a point in the two-dimensional space in the center). The individual latent representation is then fed into the decoder, which generates the weights for a task solver. The task solver predicts the behavior of the same individual <inline-formula><alternatives><mml:math id="inf4"><mml:mi>K</mml:mi></mml:math><tex-math id="inft4">\begin{document}$K$\end{document}</tex-math></alternatives></inline-formula> in the target task condition <inline-formula><alternatives><mml:math id="inf5"><mml:mi>B</mml:mi></mml:math><tex-math id="inft5">\begin{document}$B$\end{document}</tex-math></alternatives></inline-formula>. During the training, a loss function evaluates the discrepancy between the predicted behavior <inline-formula><alternatives><mml:math id="inf6"><mml:mstyle><mml:mrow><mml:mstyle displaystyle="false"><mml:mrow><mml:mover><mml:mi>β</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow></mml:mstyle></mml:mrow></mml:mstyle></mml:math><tex-math id="inft6">\begin{document}$\hat{\beta}$\end{document}</tex-math></alternatives></inline-formula> and the actual recorded behavior <italic>β</italic> of individual <inline-formula><alternatives><mml:math id="inf7"><mml:mstyle><mml:mrow><mml:mstyle displaystyle="false"><mml:mi>K</mml:mi></mml:mstyle></mml:mrow></mml:mstyle></mml:math><tex-math id="inft7">\begin{document}$K$\end{document}</tex-math></alternatives></inline-formula>. The encoder’s input is referred to as an <italic>action sequence</italic>, the form of which depends on task. For example, in a sequential Markov decision process (MDP) task, an action sequence consists of an environment (state transition probabilities) and a sequence of actions over multiple episodes. For a digit recognition task, it consists of a stimulus digit image and the corresponding chosen response.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-107163-fig1-v1.tif"/></fig><p>We evaluated whether the proposed EIDT framework can effectively transfer individuality in both value-guided sequential decision-making tasks and perceptual decision-making tasks. To assess its generalizability across individuals, meaning its ability to predict the behavior of previously unseen individuals, we tested the framework using a test participant pool that was not included in the dataset used for model training. To determine how well our framework captures each individual’s unique behavioral patterns, we compared the prediction performance of a task solver specifically designed for a given individual with the performance of task solvers designed for other individuals. Our results indicate that the proposed framework successfully mimics decision-making while accounting for individual differences.</p></sec><sec id="s2" sec-type="results"><title>Results</title><p>We evaluated our EIDT framework using two distinct experimental paradigms: a value-guided sequential decision-making task (MDP task) and a perceptual decision-making task (MNIST task). For each paradigm, we assessed model performance in two scenarios. The first, <italic>Within-Condition Prediction</italic>, tested a model’s ability to predict behavior within a single task condition without individuality transfer. In this scenario, a model was trained on data from a pool of participants to predict the behavior of a held-out individual in that same condition. The second, <italic>Cross-Condition Transfer</italic>, tested the core hypothesis of individuality transfer. Here, a model used behavioral data from a participant in ‘source’ condition to predict that same participant’s behavior in a different ‘target’ condition.</p><p>The prediction performance was evaluated using two metrics: the negative log-likelihood on a trial-by-trial basis, and the rate for behavior matched. The negative log-likelihood is based on the probability the model assigned to the specific action that the human participant actually took on that trial. The rate for behavior-matched measures the proportion of trials where the model’s most likely action (deterministically predicted by sampling from the output probabilities) matched the participant’s actual choice.</p><sec id="s2-1"><title>Markov decision process (MDP) task</title><p>The dataset consisted of behavioral data from 81 participants who performed both 2-step and 3-step MDP tasks. Each participant completed three blocks of 50 episodes for each condition, resulting in 486 action sequences in total. All analyses were performed using a leave-one-participant-out cross-validation procedure. For each fold, the model was trained on 80 participants, with 90% used for training updates and 10% for validation-based early stopping.</p><sec id="s2-1-1"><title>Task solver accurately predicts average behavior</title><p>First, we validated our core neural network architecture in Within-Condition Prediction. We trained a standard task solver, using the architecture defined in the EIDT model, on the training/validation pool (<inline-formula><alternatives><mml:math id="inf8"><mml:mi>N</mml:mi><mml:mo>=</mml:mo><mml:mn>80</mml:mn></mml:math><tex-math id="inft8">\begin{document}$N=80$\end{document}</tex-math></alternatives></inline-formula>) to predict the behavior of the held-out participant. We compared its performance against a standard cognitive model (a Q-learning model, Cognitive model) whose parameters were averaged from fits to the same training/validation pool.</p><p>As shown in <xref ref-type="fig" rid="fig2">Figure 2</xref>, the neural network-based task solver significantly outperformed the cognitive model. A two-way (model: cognitive model/task solver, task condition: 2-step/3-step) repeated-measures (RM) ANOVA with Greenhouse-Geisser correction (significant level was 0.05) revealed a significant effect of the model on both negative log-likelihood (model: <inline-formula><alternatives><mml:math id="inf9"><mml:msub><mml:mi>F</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mn>80</mml:mn></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mn>148.828</mml:mn></mml:math><tex-math id="inft9">\begin{document}$F_{1,80}=148.828$\end{document}</tex-math></alternatives></inline-formula>, <inline-formula><alternatives><mml:math id="inf10"><mml:mi>p</mml:mi><mml:mo>&lt;</mml:mo><mml:mn>0.001</mml:mn></mml:math><tex-math id="inft10">\begin{document}$p \lt 0.001$\end{document}</tex-math></alternatives></inline-formula>, <inline-formula><alternatives><mml:math id="inf11"><mml:msubsup><mml:mi>η</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>G</mml:mi></mml:mrow><mml:mrow class="MJX-TeXAtom-ORD"><mml:mn>2</mml:mn></mml:mrow></mml:msubsup><mml:mo>=</mml:mo><mml:mn>0.143</mml:mn></mml:math><tex-math id="inft11">\begin{document}$\eta_{G}^{2}=0.143$\end{document}</tex-math></alternatives></inline-formula>, task condition: <inline-formula><alternatives><mml:math id="inf12"><mml:msub><mml:mi>F</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mn>80</mml:mn></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mn>1.107</mml:mn></mml:math><tex-math id="inft12">\begin{document}$F_{1,80}=1.107$\end{document}</tex-math></alternatives></inline-formula>, <inline-formula><alternatives><mml:math id="inf13"><mml:mi>p</mml:mi><mml:mo>=</mml:mo><mml:mn>0.296</mml:mn></mml:math><tex-math id="inft13">\begin{document}$p=0.296$\end{document}</tex-math></alternatives></inline-formula>, <inline-formula><alternatives><mml:math id="inf14"><mml:msubsup><mml:mi>η</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>G</mml:mi></mml:mrow><mml:mrow class="MJX-TeXAtom-ORD"><mml:mn>2</mml:mn></mml:mrow></mml:msubsup><mml:mo>=</mml:mo><mml:mn>0.002</mml:mn></mml:math><tex-math id="inft14">\begin{document}$\eta_{G}^{2}=0.002$\end{document}</tex-math></alternatives></inline-formula>, interaction: <inline-formula><alternatives><mml:math id="inf15"><mml:msub><mml:mi>F</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mn>80</mml:mn></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mn>0.240</mml:mn></mml:math><tex-math id="inft15">\begin{document}$F_{1,80}=0.240$\end{document}</tex-math></alternatives></inline-formula>, <inline-formula><alternatives><mml:math id="inf16"><mml:mi>p</mml:mi><mml:mo>=</mml:mo><mml:mn>0.626</mml:mn></mml:math><tex-math id="inft16">\begin{document}$p=0.626$\end{document}</tex-math></alternatives></inline-formula>, <inline-formula><alternatives><mml:math id="inf17"><mml:msubsup><mml:mi>η</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>G</mml:mi></mml:mrow><mml:mrow class="MJX-TeXAtom-ORD"><mml:mn>2</mml:mn></mml:mrow></mml:msubsup><mml:mo>&lt;</mml:mo><mml:mn>0.001</mml:mn></mml:math><tex-math id="inft17">\begin{document}$\eta_{G}^{2} \lt 0.001$\end{document}</tex-math></alternatives></inline-formula>) and the rate for behavior matched (model: <inline-formula><alternatives><mml:math id="inf18"><mml:msub><mml:mi>F</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mn>80</mml:mn></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mn>110.684</mml:mn></mml:math><tex-math id="inft18">\begin{document}$F_{1,80}=110.684$\end{document}</tex-math></alternatives></inline-formula>, <inline-formula><alternatives><mml:math id="inf19"><mml:mi>p</mml:mi><mml:mo>&lt;</mml:mo><mml:mn>0.001</mml:mn></mml:math><tex-math id="inft19">\begin{document}$p \lt 0.001$\end{document}</tex-math></alternatives></inline-formula>, <inline-formula><alternatives><mml:math id="inf20"><mml:msubsup><mml:mi>η</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>G</mml:mi></mml:mrow><mml:mrow class="MJX-TeXAtom-ORD"><mml:mn>2</mml:mn></mml:mrow></mml:msubsup><mml:mo>=</mml:mo><mml:mn>0.165</mml:mn></mml:math><tex-math id="inft20">\begin{document}$\eta_{G}^{2}=0.165$\end{document}</tex-math></alternatives></inline-formula>, task condition: <inline-formula><alternatives><mml:math id="inf21"><mml:msub><mml:mi>F</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mn>80</mml:mn></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mn>3.914</mml:mn></mml:math><tex-math id="inft21">\begin{document}$F_{1,80}=3.914$\end{document}</tex-math></alternatives></inline-formula>, <inline-formula><alternatives><mml:math id="inf22"><mml:mi>p</mml:mi><mml:mo>=</mml:mo><mml:mn>0.051</mml:mn></mml:math><tex-math id="inft22">\begin{document}$p=0.051$\end{document}</tex-math></alternatives></inline-formula>, <inline-formula><alternatives><mml:math id="inf23"><mml:msubsup><mml:mi>η</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>G</mml:mi></mml:mrow><mml:mrow class="MJX-TeXAtom-ORD"><mml:mn>2</mml:mn></mml:mrow></mml:msubsup><mml:mo>=</mml:mo><mml:mn>0.009</mml:mn></mml:math><tex-math id="inft23">\begin{document}$\eta_{G}^{2}=0.009$\end{document}</tex-math></alternatives></inline-formula>, interaction: <inline-formula><alternatives><mml:math id="inf24"><mml:msub><mml:mi>F</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mn>80</mml:mn></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mn>19.059</mml:mn></mml:math><tex-math id="inft24">\begin{document}$F_{1,80}=19.059$\end{document}</tex-math></alternatives></inline-formula>, <inline-formula><alternatives><mml:math id="inf25"><mml:mi>p</mml:mi><mml:mo>&lt;</mml:mo><mml:mn>0.001</mml:mn></mml:math><tex-math id="inft25">\begin{document}$p \lt 0.001$\end{document}</tex-math></alternatives></inline-formula>, <inline-formula><alternatives><mml:math id="inf26"><mml:msubsup><mml:mi>η</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>G</mml:mi></mml:mrow><mml:mrow class="MJX-TeXAtom-ORD"><mml:mn>2</mml:mn></mml:mrow></mml:msubsup><mml:mo>=</mml:mo><mml:mn>0.014</mml:mn></mml:math><tex-math id="inft26">\begin{document}$\eta_{G}^{2}=0.014$\end{document}</tex-math></alternatives></inline-formula>). This result confirms that our RNN-based architecture serves as a strong foundation for modeling decision-making in this task.</p><fig id="fig2" position="float"><label>Figure 2.</label><caption><title>Comparison of prediction performance in Within-Condition Prediction for the MDP task.</title><p>The plots show the negative log-likelihood (left) and the rate for behavior matched (right) for the average-participant cognitive model and the task solver for 2-step and 3-step conditions. Box plots indicate the median and interquartile range. Whiskers extend to the minimum and maximum values. Each connected pair of dots represents a single participant’s data. The task solver demonstrates significantly better performance.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-107163-fig2-v1.tif"/></fig></sec><sec id="s2-1-2"><title>EIDT enables accurate individuality transfer</title><p>Next, we tested our main hypothesis in Cross-Condition Transfer. We used the full EIDT framework to predict a participant’s behavior in a target condition (e.g. 3-step MDP) using their behavioral data from a source condition (e.g. 2-step MDP). We compared the performance of two models:</p><sec id="s2-1-2-1"><title>Cognitive model</title><p>A Q-learning model whose parameters (<inline-formula><alternatives><mml:math id="inf27"><mml:msub><mml:mi>q</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi mathvariant="normal">l</mml:mi><mml:mi mathvariant="normal">r</mml:mi></mml:mrow></mml:mrow></mml:msub></mml:math><tex-math id="inft27">\begin{document}$q_{\mathrm{lr}}$\end{document}</tex-math></alternatives></inline-formula>, <inline-formula><alternatives><mml:math id="inf28"><mml:msub><mml:mi>q</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi mathvariant="normal">i</mml:mi><mml:mi mathvariant="normal">n</mml:mi><mml:mi mathvariant="normal">i</mml:mi><mml:mi mathvariant="normal">t</mml:mi></mml:mrow></mml:mrow></mml:msub></mml:math><tex-math id="inft28">\begin{document}$q_{\mathrm{init}}$\end{document}</tex-math></alternatives></inline-formula>, <inline-formula><alternatives><mml:math id="inf29"><mml:msub><mml:mi>q</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi mathvariant="normal">d</mml:mi><mml:mi mathvariant="normal">r</mml:mi></mml:mrow></mml:mrow></mml:msub></mml:math><tex-math id="inft29">\begin{document}$q_{\mathrm{dr}}$\end{document}</tex-math></alternatives></inline-formula>, and <inline-formula><alternatives><mml:math id="inf30"><mml:msub><mml:mi>q</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi mathvariant="normal">i</mml:mi><mml:mi mathvariant="normal">t</mml:mi></mml:mrow></mml:mrow></mml:msub></mml:math><tex-math id="inft30">\begin{document}$q_{\mathrm{it}}$\end{document}</tex-math></alternatives></inline-formula>) were individually fitted for each participant using their data from the source condition and then applied to predict behavior in the target condition.</p></sec><sec id="s2-1-2-2"><title>EIDT</title><p>Our framework, trained on the training and validation pool using data from both source and target conditions (see <xref ref-type="fig" rid="app1fig2">Appendix 1—figure 2</xref>, Appendix 1 for representative training and validation curves). To predict behavior for a test participant, their individual latent representation was computed by averaging the encoder’s output across all of their behavioral sequences from the source condition, and this representation was fed to the decoder to generate the task solver weights. For reference, the averaged individual latent representations are visualized in <xref ref-type="fig" rid="app1fig3">Appendix 1—figure 3</xref>, Appendix 1.</p><p>The EIDT framework demonstrated significantly better prediction accuracy than the individualized cognitive model (<xref ref-type="fig" rid="fig3">Figure 3</xref>). A two-way (model: cognitive model/EIDT, transfer direction: 2→3/3→2) RM ANOVA confirmed a significant effect of the model on negative log-likelihood (model: <inline-formula><alternatives><mml:math id="inf31"><mml:msub><mml:mi>F</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mn>80</mml:mn></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mn>95.705</mml:mn></mml:math><tex-math id="inft31">\begin{document}$F_{1,80}=95.705$\end{document}</tex-math></alternatives></inline-formula>, <inline-formula><alternatives><mml:math id="inf32"><mml:mi>p</mml:mi><mml:mo>&lt;</mml:mo><mml:mn>0.001</mml:mn></mml:math><tex-math id="inft32">\begin{document}$p \lt 0.001$\end{document}</tex-math></alternatives></inline-formula>, <inline-formula><alternatives><mml:math id="inf33"><mml:msubsup><mml:mi>η</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>G</mml:mi></mml:mrow><mml:mrow class="MJX-TeXAtom-ORD"><mml:mn>2</mml:mn></mml:mrow></mml:msubsup><mml:mo>=</mml:mo><mml:mn>0.142</mml:mn></mml:math><tex-math id="inft33">\begin{document}$\eta_{G}^{2}=0.142$\end{document}</tex-math></alternatives></inline-formula>, transfer direction: <inline-formula><alternatives><mml:math id="inf34"><mml:msub><mml:mi>F</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mn>80</mml:mn></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mn>14.255</mml:mn></mml:math><tex-math id="inft34">\begin{document}$F_{1,80}=14.255$\end{document}</tex-math></alternatives></inline-formula>, <inline-formula><alternatives><mml:math id="inf35"><mml:mi>p</mml:mi><mml:mo>&lt;</mml:mo><mml:mn>0.001</mml:mn></mml:math><tex-math id="inft35">\begin{document}$p \lt 0.001$\end{document}</tex-math></alternatives></inline-formula>, <inline-formula><alternatives><mml:math id="inf36"><mml:msubsup><mml:mi>η</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>G</mml:mi></mml:mrow><mml:mrow class="MJX-TeXAtom-ORD"><mml:mn>2</mml:mn></mml:mrow></mml:msubsup><mml:mo>=</mml:mo><mml:mn>0.019</mml:mn></mml:math><tex-math id="inft36">\begin{document}$\eta_{G}^{2}=0.019$\end{document}</tex-math></alternatives></inline-formula>, interaction: <inline-formula><alternatives><mml:math id="inf37"><mml:msub><mml:mi>F</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mn>80</mml:mn></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mn>0.008</mml:mn></mml:math><tex-math id="inft37">\begin{document}$F_{1,80}=0.008$\end{document}</tex-math></alternatives></inline-formula>, <inline-formula><alternatives><mml:math id="inf38"><mml:mi>p</mml:mi><mml:mo>=</mml:mo><mml:mn>0.012</mml:mn></mml:math><tex-math id="inft38">\begin{document}$p=0.012$\end{document}</tex-math></alternatives></inline-formula>, <inline-formula><alternatives><mml:math id="inf39"><mml:msubsup><mml:mi>η</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>G</mml:mi></mml:mrow><mml:mrow class="MJX-TeXAtom-ORD"><mml:mn>2</mml:mn></mml:mrow></mml:msubsup><mml:mo>=</mml:mo><mml:mn>0.002</mml:mn></mml:math><tex-math id="inft39">\begin{document}$\eta_{G}^{2}=0.002$\end{document}</tex-math></alternatives></inline-formula>) and the rate for behavior matched (model: <inline-formula><alternatives><mml:math id="inf40"><mml:msub><mml:mi>F</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mn>80</mml:mn></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mn>100.843</mml:mn></mml:math><tex-math id="inft40">\begin{document}$F_{1,80}=100.843$\end{document}</tex-math></alternatives></inline-formula>, <inline-formula><alternatives><mml:math id="inf41"><mml:mi>p</mml:mi><mml:mo>&lt;</mml:mo><mml:mn>0.001</mml:mn></mml:math><tex-math id="inft41">\begin{document}$p \lt 0.001$\end{document}</tex-math></alternatives></inline-formula>, <inline-formula><alternatives><mml:math id="inf42"><mml:msubsup><mml:mi>η</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>G</mml:mi></mml:mrow><mml:mrow class="MJX-TeXAtom-ORD"><mml:mn>2</mml:mn></mml:mrow></mml:msubsup><mml:mo>=</mml:mo><mml:mn>0.132</mml:mn></mml:math><tex-math id="inft42">\begin{document}$\eta_{G}^{2}=0.132$\end{document}</tex-math></alternatives></inline-formula>, transfer direction: <inline-formula><alternatives><mml:math id="inf43"><mml:msub><mml:mi>F</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mn>80</mml:mn></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mn>13.021</mml:mn></mml:math><tex-math id="inft43">\begin{document}$F_{1,80}=13.021$\end{document}</tex-math></alternatives></inline-formula>, <inline-formula><alternatives><mml:math id="inf44"><mml:mi>p</mml:mi><mml:mo>=</mml:mo><mml:mn>0.001</mml:mn></mml:math><tex-math id="inft44">\begin{document}$p=0.001$\end{document}</tex-math></alternatives></inline-formula>, <inline-formula><alternatives><mml:math id="inf45"><mml:msubsup><mml:mi>η</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>G</mml:mi></mml:mrow><mml:mrow class="MJX-TeXAtom-ORD"><mml:mn>2</mml:mn></mml:mrow></mml:msubsup><mml:mo>=</mml:mo><mml:mn>0.011</mml:mn></mml:math><tex-math id="inft45">\begin{document}$\eta_{G}^{2}=0.011$\end{document}</tex-math></alternatives></inline-formula>, interaction: <inline-formula><alternatives><mml:math id="inf46"><mml:msub><mml:mi>F</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mn>80</mml:mn></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mn>0.964</mml:mn></mml:math><tex-math id="inft46">\begin{document}$F_{1,80}=0.964$\end{document}</tex-math></alternatives></inline-formula>, <inline-formula><alternatives><mml:math id="inf47"><mml:mi>p</mml:mi><mml:mo>=</mml:mo><mml:mn>0.329</mml:mn></mml:math><tex-math id="inft47">\begin{document}$p=0.329$\end{document}</tex-math></alternatives></inline-formula>, <inline-formula><alternatives><mml:math id="inf48"><mml:msubsup><mml:mi>η</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>G</mml:mi></mml:mrow><mml:mrow class="MJX-TeXAtom-ORD"><mml:mn>2</mml:mn></mml:mrow></mml:msubsup><mml:mo>&lt;</mml:mo><mml:mn>0.001</mml:mn></mml:math><tex-math id="inft48">\begin{document}$\eta_{G}^{2} \lt 0.001$\end{document}</tex-math></alternatives></inline-formula>). This result indicates that EIDT successfully captures and transfers individual-specific behavioral patterns more effectively than a traditional parameter-based transfer approach.</p><fig id="fig3" position="float"><label>Figure 3.</label><caption><title>Individuality transfer performance in Cross-Condition Transfer for the MDP task.</title><p>The plots compare the EIDT framework against an individualized cognitive model on negative log-likelihood (left) and rate for behavior matched (right) for both 2-step to 3-step and 3-step to 2-step transfer. Box plots indicate the median and interquartile range. Whiskers extend to the minimum and maximum values. Each connected pair of dots represents a single participant’s data. The EIDT model shows superior prediction accuracy.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-107163-fig3-v1.tif"/></fig></sec></sec></sec><sec id="s2-2"><title>Latent space distance predicts transfer performance</title><p>To verify that the individual latent representation meaningfully captures individuality, we conducted a ‘cross-individual’ analysis. We generated a task solver using the latent representation of one participant (Participant <italic>l</italic>) and used it to predict the behavior of another participant (Participant <italic>k</italic>). We then measured the relationship between the prediction performance (<inline-formula><alternatives><mml:math id="inf49"><mml:msub><mml:mi>y</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>k</mml:mi><mml:mo>,</mml:mo><mml:mi>l</mml:mi></mml:mrow></mml:msub></mml:math><tex-math id="inft49">\begin{document}$y_{k,l}$\end{document}</tex-math></alternatives></inline-formula>) and the Euclidean distance (<inline-formula><alternatives><mml:math id="inf50"><mml:msub><mml:mi>d</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>k</mml:mi><mml:mo>,</mml:mo><mml:mi>l</mml:mi></mml:mrow></mml:msub></mml:math><tex-math id="inft50">\begin{document}$d_{k,l}$\end{document}</tex-math></alternatives></inline-formula>) between the latent representations of Participants <italic>k</italic> and <italic>l</italic>.</p><p>As hypothesized, prediction performance was strongly dependent on this distance (<xref ref-type="fig" rid="fig4">Figure 4</xref>). We fitted the data using a generalized linear model (GLM): <inline-formula><alternatives><mml:math id="inf51"><mml:mstyle><mml:mrow><mml:mstyle displaystyle="false"><mml:msub><mml:mi>y</mml:mi><mml:mrow><mml:mi>k</mml:mi><mml:mo>,</mml:mo><mml:mi>l</mml:mi></mml:mrow></mml:msub><mml:mo>∼</mml:mo><mml:mrow><mml:mi mathvariant="normal">G</mml:mi><mml:mi mathvariant="normal">a</mml:mi><mml:mi mathvariant="normal">m</mml:mi><mml:mi mathvariant="normal">m</mml:mi><mml:mi mathvariant="normal">a</mml:mi></mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi mathvariant="normal">l</mml:mi><mml:mi mathvariant="normal">o</mml:mi><mml:mi mathvariant="normal">g</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>β</mml:mi><mml:mrow><mml:mi mathvariant="normal">p</mml:mi><mml:mi mathvariant="normal">a</mml:mi><mml:mi mathvariant="normal">r</mml:mi><mml:mi mathvariant="normal">t</mml:mi><mml:mi mathvariant="normal">i</mml:mi><mml:mi mathvariant="normal">c</mml:mi><mml:mi mathvariant="normal">i</mml:mi><mml:mi mathvariant="normal">p</mml:mi><mml:mi mathvariant="normal">a</mml:mi><mml:mi mathvariant="normal">n</mml:mi><mml:msub><mml:mi mathvariant="normal">t</mml:mi><mml:mrow><mml:mi mathvariant="normal">k</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mi>β</mml:mi><mml:mrow><mml:mi mathvariant="normal">d</mml:mi></mml:mrow></mml:msub><mml:msub><mml:mi mathvariant="normal">d</mml:mi><mml:mrow><mml:mi mathvariant="normal">k</mml:mi><mml:mo>,</mml:mo><mml:mi mathvariant="normal">l</mml:mi></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mi>β</mml:mi><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mstyle></mml:mrow></mml:mstyle></mml:math><tex-math id="inft51">\begin{document}$y_{k,l}\thicksim \rm {Gamma}\left(log\left(\beta _{participant_{k}}+\beta _{d}d_{k,l}+\beta _{0}\right) \right) $\end{document}</tex-math></alternatives></inline-formula>. The fitting confirmed that distance (<inline-formula><alternatives><mml:math id="inf52"><mml:msub><mml:mi>d</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>k</mml:mi><mml:mo>,</mml:mo><mml:mi>l</mml:mi></mml:mrow></mml:msub></mml:math><tex-math id="inft52">\begin{document}$d_{k,l}$\end{document}</tex-math></alternatives></inline-formula>) was a significant predictor: the coefficient <inline-formula><alternatives><mml:math id="inf53"><mml:msub><mml:mi>β</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>d</mml:mi></mml:mrow></mml:msub></mml:math><tex-math id="inft53">\begin{document}$\beta_{d}$\end{document}</tex-math></alternatives></inline-formula> was significantly positive for negative log-likelihood (transfer direction 3→2: <inline-formula><alternatives><mml:math id="inf54"><mml:msub><mml:mi>β</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>d</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mn>0.176</mml:mn></mml:math><tex-math id="inft54">\begin{document}$\beta_{d}=0.176$\end{document}</tex-math></alternatives></inline-formula>, <inline-formula><alternatives><mml:math id="inf55"><mml:mi>p</mml:mi><mml:mo>&lt;</mml:mo><mml:mn>0.001</mml:mn></mml:math><tex-math id="inft55">\begin{document}$p \lt 0.001$\end{document}</tex-math></alternatives></inline-formula>, 2→3: <inline-formula><alternatives><mml:math id="inf56"><mml:msub><mml:mi>β</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>d</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mn>0.316</mml:mn></mml:math><tex-math id="inft56">\begin{document}$\beta_{d}=0.316$\end{document}</tex-math></alternatives></inline-formula>, <inline-formula><alternatives><mml:math id="inf57"><mml:mi>p</mml:mi><mml:mo>&lt;</mml:mo><mml:mn>0.001</mml:mn></mml:math><tex-math id="inft57">\begin{document}$p \lt 0.001$\end{document}</tex-math></alternatives></inline-formula>) and significantly negative for the rate for behavior matched (3→2: <inline-formula><alternatives><mml:math id="inf58"><mml:msub><mml:mi>β</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>d</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mn>0.106</mml:mn></mml:math><tex-math id="inft58">\begin{document}$\beta_{d}=0.106$\end{document}</tex-math></alternatives></inline-formula>, <inline-formula><alternatives><mml:math id="inf59"><mml:mi>p</mml:mi><mml:mo>&lt;</mml:mo><mml:mn>0.001</mml:mn></mml:math><tex-math id="inft59">\begin{document}$p \lt 0.001$\end{document}</tex-math></alternatives></inline-formula>, 2→3: <inline-formula><alternatives><mml:math id="inf60"><mml:msub><mml:mi>β</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>d</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mo>−</mml:mo><mml:mn>0.149</mml:mn></mml:math><tex-math id="inft60">\begin{document}$\beta_{d}=-0.149$\end{document}</tex-math></alternatives></inline-formula>, <inline-formula><alternatives><mml:math id="inf61"><mml:mi>p</mml:mi><mml:mo>&lt;</mml:mo><mml:mn>0.001</mml:mn></mml:math><tex-math id="inft61">\begin{document}$p \lt 0.001$\end{document}</tex-math></alternatives></inline-formula>). This indicates that prediction performance degrades as the behavioral dissimilarity (represented by distance in the latent space) between the source and target individual increases, providing direct evidence that the latent space organizes individuals by behavioral similarity.</p><fig id="fig4" position="float"><label>Figure 4.</label><caption><title>Prediction performances as functions of latent space distance in the MDP task.</title><p>This cross-individual analysis shows the result of using a task solver generated from one participant to predict the behavior of another participant. The horizontal axis is the Euclidean distance between the latent representation of the two participants. The vertical axis shows the negative log-likelihood (left) and rate for behavior matched (right). Each dot represents one participant pair. Performance degrades as the distance between individuals increases, with the solid line showing the GLM fit. (<bold>A</bold>) 3-step to 2-step transfer. (<bold>B</bold>) 2-step to 3-step transfer.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-107163-fig4-v1.tif"/></fig></sec><sec id="s2-3"><title>On-policy simulations generate human-like behavior</title><p>To assess if our model could generate realistic behavior, we conducted on-policy simulations. Task solvers specialized to each individual via EIDT performed the MDP task using the same environments as the human participants. We compared the model behavior to human behavior on two metrics: total reward per block and the rate of highly rewarding action selected in the final step.</p><p>The model-generated behaviors closely mirrored human behaviors (<xref ref-type="fig" rid="fig5">Figure 5</xref>). We found significant correlations between humans and their corresponding models in both total rewards (3→2: <inline-formula><alternatives><mml:math id="inf62"><mml:mi>R</mml:mi><mml:mo>=</mml:mo><mml:mn>0.667</mml:mn></mml:math><tex-math id="inft62">\begin{document}$R=0.667$\end{document}</tex-math></alternatives></inline-formula>, <inline-formula><alternatives><mml:math id="inf63"><mml:mi>p</mml:mi><mml:mo>&lt;</mml:mo><mml:mn>0.001</mml:mn></mml:math><tex-math id="inft63">\begin{document}$p \lt 0.001$\end{document}</tex-math></alternatives></inline-formula>; 2→3: <inline-formula><alternatives><mml:math id="inf64"><mml:mi>R</mml:mi><mml:mo>=</mml:mo><mml:mn>0.593</mml:mn></mml:math><tex-math id="inft64">\begin{document}$R=0.593$\end{document}</tex-math></alternatives></inline-formula>, <inline-formula><alternatives><mml:math id="inf65"><mml:mi>p</mml:mi><mml:mo>&lt;</mml:mo><mml:mn>0.001</mml:mn></mml:math><tex-math id="inft65">\begin{document}$p \lt 0.001$\end{document}</tex-math></alternatives></inline-formula>) and the rate of highly-rewarding action selected (3→2: <inline-formula><alternatives><mml:math id="inf66"><mml:mi>R</mml:mi><mml:mo>=</mml:mo><mml:mn>0.889</mml:mn></mml:math><tex-math id="inft66">\begin{document}$R=0.889$\end{document}</tex-math></alternatives></inline-formula>, <inline-formula><alternatives><mml:math id="inf67"><mml:mi>p</mml:mi><mml:mo>&lt;</mml:mo><mml:mn>0.001</mml:mn></mml:math><tex-math id="inft67">\begin{document}$p \lt 0.001$\end{document}</tex-math></alternatives></inline-formula>; 2→3: <inline-formula><alternatives><mml:math id="inf68"><mml:mi>R</mml:mi><mml:mo>=</mml:mo><mml:mn>0.835</mml:mn></mml:math><tex-math id="inft68">\begin{document}$R=0.835$\end{document}</tex-math></alternatives></inline-formula>, <inline-formula><alternatives><mml:math id="inf69"><mml:mi>p</mml:mi><mml:mo>&lt;</mml:mo><mml:mn>0.001</mml:mn></mml:math><tex-math id="inft69">\begin{document}$p \lt 0.001$\end{document}</tex-math></alternatives></inline-formula>). This demonstrates that the EIDT framework captures individual tendencies that generalize to active, sequential behavior generation.</p><fig id="fig5" position="float"><label>Figure 5.</label><caption><title>Comparison of on-policy behavior between humans and EIDT-generated task solvers.</title><p>Each dot represents the performance of a single human participant (horizontal axis) versus their corresponding model (vertical axis) for one block. Plots show the total reward (left) and the rate of highly-rewarding action selected (right). (<bold>A</bold>) 3-step to 2-step transfer. (<bold>B</bold>) 2-step to 3-step transfer.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-107163-fig5-v1.tif"/></fig></sec><sec id="s2-4"><title>Individual latent representations reflect cognitive parameters</title><p>To better interpret the latent space, we applied our EIDT model (trained only on human data) to simulated data from 1000 Q-learning agents. The agents had known learning rates (<inline-formula><alternatives><mml:math id="inf70"><mml:msub><mml:mi>q</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi mathvariant="normal">l</mml:mi><mml:mi mathvariant="normal">r</mml:mi></mml:mrow></mml:mrow></mml:msub></mml:math><tex-math id="inft70">\begin{document}$q_{\mathrm{lr}}$\end{document}</tex-math></alternatives></inline-formula>) and inverse temperatures (<inline-formula><alternatives><mml:math id="inf71"><mml:msub><mml:mi>q</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi mathvariant="normal">i</mml:mi><mml:mi mathvariant="normal">t</mml:mi></mml:mrow></mml:mrow></mml:msub></mml:math><tex-math id="inft71">\begin{document}$q_{\mathrm{it}}$\end{document}</tex-math></alternatives></inline-formula>) sampled from distributions matched to human fits (<xref ref-type="fig" rid="app1fig1">Appendix 1—figure 1</xref>, Appendix 1). A cross-individual analysis on these agents confirmed that latent space distance predicted performance, mirroring the results from human data (<xref ref-type="fig" rid="app1fig5">Appendix 1—figure 5</xref>, Appendix 1).</p><p>The results revealed a systematic mapping between the cognitive parameters and the coordinates of the individual latent representation (<xref ref-type="fig" rid="fig6">Figure 6</xref> and <xref ref-type="fig" rid="app1fig4">Appendix 1—figure 4</xref> , Appendix 1). A GLM analysis (<xref ref-type="table" rid="app1table1">Appendix 1—table 1</xref>, Appendix 1) showed that both <inline-formula><alternatives><mml:math id="inf72"><mml:msub><mml:mi>q</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi mathvariant="normal">r</mml:mi><mml:mi mathvariant="normal">l</mml:mi></mml:mrow></mml:mrow></mml:msub></mml:math><tex-math id="inft72">\begin{document}$q_{\mathrm{rl}}$\end{document}</tex-math></alternatives></inline-formula> and <inline-formula><alternatives><mml:math id="inf73"><mml:msub><mml:mi>q</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi mathvariant="normal">i</mml:mi><mml:mi mathvariant="normal">t</mml:mi></mml:mrow></mml:mrow></mml:msub></mml:math><tex-math id="inft73">\begin{document}$q_{\mathrm{it}}$\end{document}</tex-math></alternatives></inline-formula> (and their interaction) were significant predictors of the latent dimensions (<inline-formula><alternatives><mml:math id="inf74"><mml:msub><mml:mi>z</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:math><tex-math id="inft74">\begin{document}$z_{1}$\end{document}</tex-math></alternatives></inline-formula> and <inline-formula><alternatives><mml:math id="inf75"><mml:msub><mml:mi>z</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mn>2</mml:mn></mml:mrow></mml:msub></mml:math><tex-math id="inft75">\begin{document}$z_{2}$\end{document}</tex-math></alternatives></inline-formula>). This indicates that our data-driven representation captures core computational properties defined in classic reinforcement learning theory.</p><fig id="fig6" position="float"><label>Figure 6.</label><caption><title>Mapping of Q-learning parameters to the individual latent space for the 3-step MDP task.</title><p>Each plot shows one dimension of the latent representation (<inline-formula><alternatives><mml:math id="inf76"><mml:msub><mml:mi>z</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:math><tex-math id="inft76">\begin{document}$z_{1}$\end{document}</tex-math></alternatives></inline-formula> (left) or <inline-formula><alternatives><mml:math id="inf77"><mml:msub><mml:mi>z</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mn>2</mml:mn></mml:mrow></mml:msub></mml:math><tex-math id="inft77">\begin{document}$z_{2}$\end{document}</tex-math></alternatives></inline-formula> (right)) as a function of either the learning rate (<inline-formula><alternatives><mml:math id="inf78"><mml:mstyle><mml:mrow><mml:mstyle displaystyle="false"><mml:msub><mml:mi>q</mml:mi><mml:mrow><mml:mrow><mml:mi mathvariant="normal">l</mml:mi><mml:mi mathvariant="normal">r</mml:mi></mml:mrow></mml:mrow></mml:msub></mml:mstyle></mml:mrow></mml:mstyle></mml:math><tex-math id="inft78">\begin{document}$q_{\rm{lr}}$\end{document}</tex-math></alternatives></inline-formula>, <bold>A</bold>) or the inverse temperature (<inline-formula><alternatives><mml:math id="inf79"><mml:mstyle><mml:mrow><mml:mstyle displaystyle="false"><mml:msub><mml:mi>q</mml:mi><mml:mrow><mml:mrow><mml:mi mathvariant="normal">i</mml:mi><mml:mi mathvariant="normal">t</mml:mi></mml:mrow></mml:mrow></mml:msub></mml:mstyle></mml:mrow></mml:mstyle></mml:math><tex-math id="inft79">\begin{document}$q_{\rm{it}}$\end{document}</tex-math></alternatives></inline-formula>, <bold>B</bold>) of simulated Q-learning agents. Black dots represent the latent representation produced by the encoder from the agent’s behavior. Blue dots show the fit from a GLM.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-107163-fig6-v1.tif"/></fig></sec><sec id="s2-5"><title>Handwritten digit recognition (MNIST) task</title><p>We then sought to replicate our findings in a different domain: perceptual decision-making. We used data from <xref ref-type="bibr" rid="bib35">Rafiei et al., 2024</xref>, where 60 participants identified noisy images of digits under four conditions varying in difficulty and speed-accuracy focus (EA: easy, accuracy focus, ES: easy, speed focus, DA: difficult, accuracy focus, and DS: difficult, speed focus). Analyses were again conducted using leave-one-participant-out cross-validation.</p><sec id="s2-5-1"><title>Task solver outperforms RTNet</title><p>First, in Within-Condition Prediction, our base task solver demonstrated task performance (rate of correct responses indicating how accurately a human participant or model responded to the stimulus digit) comparable to human participants and established RTNet model (<xref ref-type="bibr" rid="bib35">Rafiei et al., 2024</xref>; <xref ref-type="fig" rid="fig7">Figure 7</xref>). A two-way (model: human/RTNet/Task solver, task condition: EA/ES/DA/DS) RM ANOVA showed no significant effect of model type (<inline-formula><alternatives><mml:math id="inf80"><mml:msub><mml:mi>F</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mn>2</mml:mn><mml:mo>,</mml:mo><mml:mn>118</mml:mn></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mn>1.546</mml:mn></mml:math><tex-math id="inft80">\begin{document}$F_{2,118}=1.546$\end{document}</tex-math></alternatives></inline-formula>, <inline-formula><alternatives><mml:math id="inf81"><mml:mi>p</mml:mi><mml:mo>=</mml:mo><mml:mn>0.219</mml:mn></mml:math><tex-math id="inft81">\begin{document}$p=0.219$\end{document}</tex-math></alternatives></inline-formula>, <inline-formula><alternatives><mml:math id="inf82"><mml:msubsup><mml:mi>η</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>G</mml:mi></mml:mrow><mml:mrow class="MJX-TeXAtom-ORD"><mml:mn>2</mml:mn></mml:mrow></mml:msubsup><mml:mo>=</mml:mo><mml:mn>0.008</mml:mn></mml:math><tex-math id="inft82">\begin{document}$\eta_{G}^{2}=0.008$\end{document}</tex-math></alternatives></inline-formula>), while the task condition had a significant effect (<inline-formula><alternatives><mml:math id="inf83"><mml:msub><mml:mi>F</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mn>3</mml:mn><mml:mo>,</mml:mo><mml:mn>177</mml:mn></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mn>866.322</mml:mn></mml:math><tex-math id="inft83">\begin{document}$F_{3,177}=866.322$\end{document}</tex-math></alternatives></inline-formula>, <inline-formula><alternatives><mml:math id="inf84"><mml:mi>p</mml:mi><mml:mo>&lt;</mml:mo><mml:mn>0.001</mml:mn></mml:math><tex-math id="inft84">\begin{document}$p \lt 0.001$\end{document}</tex-math></alternatives></inline-formula>, <inline-formula><alternatives><mml:math id="inf85"><mml:msubsup><mml:mi>η</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>G</mml:mi></mml:mrow><mml:mrow class="MJX-TeXAtom-ORD"><mml:mn>2</mml:mn></mml:mrow></mml:msubsup><mml:mo>=</mml:mo><mml:mn>0.684</mml:mn></mml:math><tex-math id="inft85">\begin{document}$\eta_{G}^{2}=0.684$\end{document}</tex-math></alternatives></inline-formula>). This confirms similar task-solving ability.</p><fig id="fig7" position="float"><label>Figure 7.</label><caption><title>Task performance (rate of correct responses) in Within-Condition Prediction for the MNIST tasks.</title><p>Box plots indicate the median and interquartile range. Whiskers extend to the minimum and maximum values. Performance is compared across human participants, the RTNet model, and our task solver for the four experimental conditions (EA, ES, DA, and DS). All three show similar performance patterns.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-107163-fig7-v1.tif"/></fig><p>However, the task solver significantly outperformed RTNet in predicting participants’ trial-by-trial choices (<xref ref-type="fig" rid="fig8">Figure 8</xref>). A two-way RM ANOVA revealed significant effects on both negative log-likelihood (model: <inline-formula><alternatives><mml:math id="inf86"><mml:msub><mml:mi>F</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mn>59</mml:mn></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mn>1312.328</mml:mn></mml:math><tex-math id="inft86">\begin{document}$F_{1,59}=1312.328$\end{document}</tex-math></alternatives></inline-formula>, <inline-formula><alternatives><mml:math id="inf87"><mml:mi>p</mml:mi><mml:mo>&lt;</mml:mo><mml:mn>0.001</mml:mn></mml:math><tex-math id="inft87">\begin{document}$p \lt 0.001$\end{document}</tex-math></alternatives></inline-formula>, <inline-formula><alternatives><mml:math id="inf88"><mml:msubsup><mml:mi>η</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>G</mml:mi></mml:mrow><mml:mrow class="MJX-TeXAtom-ORD"><mml:mn>2</mml:mn></mml:mrow></mml:msubsup><mml:mo>=</mml:mo><mml:mn>0.731</mml:mn></mml:math><tex-math id="inft88">\begin{document}$\eta_{G}^{2}=0.731$\end{document}</tex-math></alternatives></inline-formula>, task condition: <inline-formula><alternatives><mml:math id="inf89"><mml:msub><mml:mi>F</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mn>3</mml:mn><mml:mo>,</mml:mo><mml:mn>177</mml:mn></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mn>460.535</mml:mn></mml:math><tex-math id="inft89">\begin{document}$F_{3,177}=460.535$\end{document}</tex-math></alternatives></inline-formula>, <inline-formula><alternatives><mml:math id="inf90"><mml:mi>p</mml:mi><mml:mo>&lt;</mml:mo><mml:mn>0.001</mml:mn></mml:math><tex-math id="inft90">\begin{document}$p \lt 0.001$\end{document}</tex-math></alternatives></inline-formula>, <inline-formula><alternatives><mml:math id="inf91"><mml:msubsup><mml:mi>η</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>G</mml:mi></mml:mrow><mml:mrow class="MJX-TeXAtom-ORD"><mml:mn>2</mml:mn></mml:mrow></mml:msubsup><mml:mo>=</mml:mo><mml:mn>0.682</mml:mn></mml:math><tex-math id="inft91">\begin{document}$\eta_{G}^{2}=0.682$\end{document}</tex-math></alternatives></inline-formula>, their interaction: <inline-formula><alternatives><mml:math id="inf92"><mml:msub><mml:mi>F</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mn>3</mml:mn><mml:mo>,</mml:mo><mml:mn>177</mml:mn></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mn>24.476</mml:mn></mml:math><tex-math id="inft92">\begin{document}$F_{3,177}=24.476$\end{document}</tex-math></alternatives></inline-formula>, <inline-formula><alternatives><mml:math id="inf93"><mml:mi>p</mml:mi><mml:mo>&lt;</mml:mo><mml:mn>0.001</mml:mn></mml:math><tex-math id="inft93">\begin{document}$p \lt 0.001$\end{document}</tex-math></alternatives></inline-formula>, <inline-formula><alternatives><mml:math id="inf94"><mml:msubsup><mml:mi>η</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>G</mml:mi></mml:mrow><mml:mrow class="MJX-TeXAtom-ORD"><mml:mn>2</mml:mn></mml:mrow></mml:msubsup><mml:mo>=</mml:mo><mml:mn>0.026</mml:mn></mml:math><tex-math id="inft94">\begin{document}$\eta_{G}^{2}=0.026$\end{document}</tex-math></alternatives></inline-formula>) and the rate for behavior matched (model: <inline-formula><alternatives><mml:math id="inf95"><mml:msub><mml:mi>F</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mn>59</mml:mn></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mn>43.544</mml:mn></mml:math><tex-math id="inft95">\begin{document}$F_{1,59}=43.544$\end{document}</tex-math></alternatives></inline-formula>, <inline-formula><alternatives><mml:math id="inf96"><mml:mi>p</mml:mi><mml:mo>&lt;</mml:mo><mml:mn>0.001</mml:mn></mml:math><tex-math id="inft96">\begin{document}$p \lt 0.001$\end{document}</tex-math></alternatives></inline-formula>, <inline-formula><alternatives><mml:math id="inf97"><mml:msubsup><mml:mi>η</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>G</mml:mi></mml:mrow><mml:mrow class="MJX-TeXAtom-ORD"><mml:mn>2</mml:mn></mml:mrow></mml:msubsup><mml:mo>=</mml:mo><mml:mn>0.005</mml:mn></mml:math><tex-math id="inft97">\begin{document}$\eta_{G}^{2}=0.005$\end{document}</tex-math></alternatives></inline-formula>, task condition: <inline-formula><alternatives><mml:math id="inf98"><mml:msub><mml:mi>F</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mn>3</mml:mn><mml:mo>,</mml:mo><mml:mn>177</mml:mn></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mn>455.728</mml:mn></mml:math><tex-math id="inft98">\begin{document}$F_{3,177}=455.728$\end{document}</tex-math></alternatives></inline-formula>, <inline-formula><alternatives><mml:math id="inf99"><mml:mi>p</mml:mi><mml:mo>&lt;</mml:mo><mml:mn>0.001</mml:mn></mml:math><tex-math id="inft99">\begin{document}$p \lt 0.001$\end{document}</tex-math></alternatives></inline-formula>, <inline-formula><alternatives><mml:math id="inf100"><mml:msubsup><mml:mi>η</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>G</mml:mi></mml:mrow><mml:mrow class="MJX-TeXAtom-ORD"><mml:mn>2</mml:mn></mml:mrow></mml:msubsup><mml:mo>=</mml:mo><mml:mn>0.701</mml:mn></mml:math><tex-math id="inft100">\begin{document}$\eta_{G}^{2}=0.701$\end{document}</tex-math></alternatives></inline-formula>, their interaction: <inline-formula><alternatives><mml:math id="inf101"><mml:msub><mml:mi>F</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mn>3</mml:mn><mml:mo>,</mml:mo><mml:mn>177</mml:mn></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mn>11.052</mml:mn></mml:math><tex-math id="inft101">\begin{document}$F_{3,177}=11.052$\end{document}</tex-math></alternatives></inline-formula>, <inline-formula><alternatives><mml:math id="inf102"><mml:mi>p</mml:mi><mml:mo>&lt;</mml:mo><mml:mn>0.001</mml:mn></mml:math><tex-math id="inft102">\begin{document}$p \lt 0.001$\end{document}</tex-math></alternatives></inline-formula>, <inline-formula><alternatives><mml:math id="inf103"><mml:msubsup><mml:mi>η</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>G</mml:mi></mml:mrow><mml:mrow class="MJX-TeXAtom-ORD"><mml:mn>2</mml:mn></mml:mrow></mml:msubsup><mml:mo>=</mml:mo><mml:mn>0.002</mml:mn></mml:math><tex-math id="inft103">\begin{document}$\eta_{G}^{2}=0.002$\end{document}</tex-math></alternatives></inline-formula>). This confirms the task solver’s suitability for modeling individual behavior in this task.</p><fig id="fig8" position="float"><label>Figure 8.</label><caption><title>Comparison of prediction performance in Within-Condition Prediction for the MNIST task.</title><p>The plots show the negative log-likelihood (left) and the rate for behavior matched (right) for the RTNet model and our task solver. Each connected pair of dots represents a single participant’s data. Box plots indicate the median and interquartile range. Whiskers extend to the minimum and maximum values. The task solver achieves significantly better prediction accuracy.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-107163-fig8-v1.tif"/></fig></sec><sec id="s2-5-2"><title>EIDT accurately transfers individuality</title><p>Next, in Cross-Condition Transfer, we tested individuality transfer across all 12 pairs of experimental conditions. The full EIDT framework was compared against a baseline: a task solver (source) model trained directly on a test participant’s source condition data.</p><p>The EIDT framework consistently and significantly outperformed this baseline across all transfer sets (<xref ref-type="fig" rid="fig9">Figure 9</xref>). A two-way (model: task solver/EIDT, transfer direction: 12 sets (see horizontal axis)) RM ANOVA confirmed a significant effect of the model on negative log-likelihood (model: <inline-formula><alternatives><mml:math id="inf104"><mml:msub><mml:mi>F</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mn>3</mml:mn><mml:mo>,</mml:mo><mml:mn>177</mml:mn></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mn>2440.373</mml:mn></mml:math><tex-math id="inft104">\begin{document}$F_{3,177}=2440.373$\end{document}</tex-math></alternatives></inline-formula>, <inline-formula><alternatives><mml:math id="inf105"><mml:mi>p</mml:mi><mml:mo>&lt;</mml:mo><mml:mn>0.001</mml:mn></mml:math><tex-math id="inft105">\begin{document}$p \lt 0.001$\end{document}</tex-math></alternatives></inline-formula>, <inline-formula><alternatives><mml:math id="inf106"><mml:msubsup><mml:mi>η</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>G</mml:mi></mml:mrow><mml:mrow class="MJX-TeXAtom-ORD"><mml:mn>2</mml:mn></mml:mrow></mml:msubsup><mml:mo>=</mml:mo><mml:mn>0.800</mml:mn></mml:math><tex-math id="inft106">\begin{document}$\eta_{G}^{2}=0.800$\end{document}</tex-math></alternatives></inline-formula>, transfer direction: <inline-formula><alternatives><mml:math id="inf107"><mml:msub><mml:mi>F</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mn>11</mml:mn><mml:mo>,</mml:mo><mml:mn>649</mml:mn></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mn>347.850</mml:mn></mml:math><tex-math id="inft107">\begin{document}$F_{11,649}=347.850$\end{document}</tex-math></alternatives></inline-formula>, <inline-formula><alternatives><mml:math id="inf108"><mml:mi>p</mml:mi><mml:mo>&lt;</mml:mo><mml:mn>0.001</mml:mn></mml:math><tex-math id="inft108">\begin{document}$p \lt 0.001$\end{document}</tex-math></alternatives></inline-formula>, <inline-formula><alternatives><mml:math id="inf109"><mml:msubsup><mml:mi>η</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>G</mml:mi></mml:mrow><mml:mrow class="MJX-TeXAtom-ORD"><mml:mn>2</mml:mn></mml:mrow></mml:msubsup><mml:mo>=</mml:mo><mml:mn>0.616</mml:mn></mml:math><tex-math id="inft109">\begin{document}$\eta_{G}^{2}=0.616$\end{document}</tex-math></alternatives></inline-formula>, interaction: <inline-formula><alternatives><mml:math id="inf110"><mml:msub><mml:mi>F</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mn>33</mml:mn><mml:mo>,</mml:mo><mml:mn>1947</mml:mn></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mn>336.968</mml:mn></mml:math><tex-math id="inft110">\begin{document}$F_{33,1947}=336.968$\end{document}</tex-math></alternatives></inline-formula>, <inline-formula><alternatives><mml:math id="inf111"><mml:mi>p</mml:mi><mml:mo>&lt;</mml:mo><mml:mn>0.001</mml:mn></mml:math><tex-math id="inft111">\begin{document}$p \lt 0.001$\end{document}</tex-math></alternatives></inline-formula>, <inline-formula><alternatives><mml:math id="inf112"><mml:msubsup><mml:mi>η</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>G</mml:mi></mml:mrow><mml:mrow class="MJX-TeXAtom-ORD"><mml:mn>2</mml:mn></mml:mrow></mml:msubsup><mml:mo>=</mml:mo><mml:mn>0.573</mml:mn></mml:math><tex-math id="inft112">\begin{document}$\eta_{G}^{2}=0.573$\end{document}</tex-math></alternatives></inline-formula>) and rate for behavior matched (model: <inline-formula><alternatives><mml:math id="inf113"><mml:msub><mml:mi>F</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mn>3</mml:mn><mml:mo>,</mml:mo><mml:mn>177</mml:mn></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mn>2318.456</mml:mn></mml:math><tex-math id="inft113">\begin{document}$F_{3,177}=2318.456$\end{document}</tex-math></alternatives></inline-formula>, <inline-formula><alternatives><mml:math id="inf114"><mml:mi>p</mml:mi><mml:mo>&lt;</mml:mo><mml:mn>0.001</mml:mn></mml:math><tex-math id="inft114">\begin{document}$p \lt 0.001$\end{document}</tex-math></alternatives></inline-formula>, <inline-formula><alternatives><mml:math id="inf115"><mml:msubsup><mml:mi>η</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>G</mml:mi></mml:mrow><mml:mrow class="MJX-TeXAtom-ORD"><mml:mn>2</mml:mn></mml:mrow></mml:msubsup><mml:mo>=</mml:mo><mml:mn>0.798</mml:mn></mml:math><tex-math id="inft115">\begin{document}$\eta_{G}^{2}=0.798$\end{document}</tex-math></alternatives></inline-formula>, transfer direction: <inline-formula><alternatives><mml:math id="inf116"><mml:msub><mml:mi>F</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mn>11</mml:mn><mml:mo>,</mml:mo><mml:mn>649</mml:mn></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mn>394.753</mml:mn></mml:math><tex-math id="inft116">\begin{document}$F_{11,649}=394.753$\end{document}</tex-math></alternatives></inline-formula>, <inline-formula><alternatives><mml:math id="inf117"><mml:mi>p</mml:mi><mml:mo>&lt;</mml:mo><mml:mn>0.001</mml:mn></mml:math><tex-math id="inft117">\begin{document}$p \lt 0.001$\end{document}</tex-math></alternatives></inline-formula>, <inline-formula><alternatives><mml:math id="inf118"><mml:msubsup><mml:mi>η</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>G</mml:mi></mml:mrow><mml:mrow class="MJX-TeXAtom-ORD"><mml:mn>2</mml:mn></mml:mrow></mml:msubsup><mml:mo>=</mml:mo><mml:mn>0.591</mml:mn></mml:math><tex-math id="inft118">\begin{document}$\eta_{G}^{2}=0.591$\end{document}</tex-math></alternatives></inline-formula>, interaction: <inline-formula><alternatives><mml:math id="inf119"><mml:msub><mml:mi>F</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mn>33</mml:mn><mml:mo>,</mml:mo><mml:mn>1947</mml:mn></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mn>355.577</mml:mn></mml:math><tex-math id="inft119">\begin{document}$F_{33,1947}=355.577$\end{document}</tex-math></alternatives></inline-formula>, <inline-formula><alternatives><mml:math id="inf120"><mml:mi>p</mml:mi><mml:mo>&lt;</mml:mo><mml:mn>0.001</mml:mn></mml:math><tex-math id="inft120">\begin{document}$p \lt 0.001$\end{document}</tex-math></alternatives></inline-formula>, <inline-formula><alternatives><mml:math id="inf121"><mml:msubsup><mml:mi>η</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>G</mml:mi></mml:mrow><mml:mrow class="MJX-TeXAtom-ORD"><mml:mn>2</mml:mn></mml:mrow></mml:msubsup><mml:mo>=</mml:mo><mml:mn>0.628</mml:mn></mml:math><tex-math id="inft121">\begin{document}$\eta_{G}^{2}=0.628$\end{document}</tex-math></alternatives></inline-formula>). The model was also able to reproduce idiosyncratic error patterns of individual participants, such as Participant #23’s lower accuracy for digit 1 and Participant #56’s difficulty with digits 6 and 7 (<xref ref-type="fig" rid="fig10">Figure 10</xref>).</p><fig id="fig9" position="float"><label>Figure 9.</label><caption><title>Individuality transfer performance in Cross-Condition Transfer for the MNIST task.</title><p>The plots compare the EIDT framework against the task solver (source) baseline across all 12 transfer directions on negative log-likelihood (top) and rate for behavior matched (bottom). Each connected pair of dots represents a single participant’s data. Box plots indicate the median and interquartile range. Whiskers extend to the minimum and maximum values. EIDT consistently demonstrates superior prediction accuracy.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-107163-fig9-v1.tif"/></fig><fig id="fig10" position="float"><label>Figure 10.</label><caption><title>EIDT captures individual-specific error patterns in the MNIST task.</title><p>The plots show the percentage of correct responses for each digit for four representative participants (blue bars) and their corresponding EIDT-generated models (gray bars). Data shown is for the ES target condition, with transfer from EA.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-107163-fig10-v1.tif"/></fig></sec><sec id="s2-5-3"><title>Latent space reflects behavioral tendencies</title><p>Similar to the MDP task, a cross-individual analysis showed that the distance in the latent space was a significant predictor of prediction performance for all transfer directions (<xref ref-type="fig" rid="fig11">Figure 11</xref>; see <xref ref-type="fig" rid="app1fig8">Appendix 1—figures 8</xref> and <xref ref-type="fig" rid="app1fig9">9</xref> and <xref ref-type="table" rid="app1table2">Appendix 1—table 2</xref>, Appendix 1, for full results). This confirms that, in the perceptual domain as well, the individual latent representation captures meaningful behavioral differences that are critical for accurate prediction.</p><fig id="fig11" position="float"><label>Figure 11.</label><caption><title>Prediction performance as a function of latent space distance in the MNIST task (transfer direction EA→DA).</title><p>This cross-individual analysis shows the result of using a task solver generated from one participant to predict the behavior of another participant. The horizontal axis is the Euclidean distance between the latent representation of the two participants. The vertical axis shows the negative log-likelihood (left) and rate for behavior matched (right). Each dot represents one participant pair. Performance degrades as the distance between individuals increases, with the solid line showing the GLM fit.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-107163-fig11-v1.tif"/></fig></sec></sec></sec><sec id="s3" sec-type="discussion"><title>Discussion</title><p>We proposed an EIDT framework for modeling the unique decision-making process of each individual. This framework enables the transfer of an individual latent representation from a (source) task condition to a different (target) task condition, allowing a task solver to predict behaviors in the target task condition. Several neural network techniques, such as autoencoders (<xref ref-type="bibr" rid="bib39">Rumelhart and McClelland, 1987</xref>; <xref ref-type="bibr" rid="bib49">Tolstikhin et al., 2017</xref>), hypernetworks (<xref ref-type="bibr" rid="bib20">Ha et al., 2016</xref>), and learning-to-learn (<xref ref-type="bibr" rid="bib54">Wang et al., 2017</xref>; <xref ref-type="bibr" rid="bib44">Song et al., 2017</xref>), facilitate this transfer. Our experiments, conducted on both value-guided sequential and perceptual decision-making tasks, demonstrated the potential of the proposed framework in individuality transfer across task conditions.</p><sec id="s3-1"><title>EIDT framework extends prior work on individuality transfer</title><p>The core concept of using an encoder-decoder architecture to capture individuality builds on the work of <xref ref-type="bibr" rid="bib10">Dezfouli et al., 2019a</xref>, who applied a similar model to a bandit task. We extended this idea in three key ways. First, we validated that the framework is effective for previously unseen individuals who were not included in model training. Although these individuals provided behavioral data in the source task condition to identify their individual latent representations, their data were not used for model training. Second, we established that this transfer is effective across different experimental conditions (e.g. changes in task rules or difficulty), not just across sessions of the same task. Third, while the original work focused on value-guided tasks, we validated the framework’s applicability to perceptual decision-making tasks, specifically the MNIST task. These findings establish that EIDT effectively captures individual differences across both task conditions and individuals.</p></sec><sec id="s3-2"><title>Interpreting the individual latent representation remains challenging</title><p>Although we found that Q-learning parameters were reflected in the individual latent representation, the interpretation of this representation remains an open question. Since interpretation often requires task-condition-specific considerations (<xref ref-type="bibr" rid="bib13">Eckstein et al., 2022</xref>), it falls outside the primary scope of this study, whose aim is to develop a general framework for individuality transfer. Previous research (<xref ref-type="bibr" rid="bib29">Miller et al., 2023</xref>; <xref ref-type="bibr" rid="bib18">Ger et al., 2024a</xref>) has explored associating neural network parameters with cognitive or functional meanings. Approaches such as disentangling techniques (<xref ref-type="bibr" rid="bib2">Burgess et al., 2018</xref>) and cognitive model integration (<xref ref-type="bibr" rid="bib19">Ger et al., 2024b</xref>; <xref ref-type="bibr" rid="bib50">Tuzsus et al., 2024</xref>; <xref ref-type="bibr" rid="bib45">Song et al., 2021</xref>; <xref ref-type="bibr" rid="bib14">Eckstein et al., 2023</xref>) could aid in better understanding the cognitive and functional significance of the individual latent representation.</p><p>Regarding the individual latent representation, disentanglement and separation losses (<xref ref-type="bibr" rid="bib10">Dezfouli et al., 2019a</xref>) during the model training could enhance interpretability. However, we used only the reproduction loss, as defined in <xref ref-type="disp-formula" rid="equ5">Equation 5</xref>, because interpretable parameters in cognitive models (e.g. <xref ref-type="bibr" rid="bib9">Daw et al., 2011</xref>) are not necessarily independent (e.g. an individual with a high learning rate may also have a high inverse temperature <xref ref-type="bibr" rid="bib28">Lin et al., 2023</xref>, resulting in these two parameters being represented with one variable).</p></sec><sec id="s3-3"><title>Why can the encoder extract individuality for unseen individuals?</title><p>Our experiments, which divided participants into training and test participant pools, demonstrated that the framework successfully extracts individuality for completely new individuals. This generalization likely relies on the fact that individuals with similar behavioral patterns result in similar individual latent representation and individuals similar to new participants exist in the training participant pool (<xref ref-type="bibr" rid="bib58">Yechiam et al., 2005</xref>). This hypothesis suggests that individuals can be clustered based on behavioral patterns. Behavioral clustering has been widely discussed in relation to psychiatric conditions, medication effects, and gender-based differences (e.g. <xref ref-type="bibr" rid="bib32">Pedersen et al., 2017</xref>; <xref ref-type="bibr" rid="bib51">van den Bos et al., 2013</xref>; <xref ref-type="bibr" rid="bib41">Sevy et al., 2007</xref>). Our results could contribute to a deeper discussion of behavioral characteristics by clustering not only these groups but also healthy controls.</p></sec><sec id="s3-4"><title>Which processes contribute to individuality?</title><p>In the MNIST task, we assumed that individuality emerged primarily from the decision-making process (implemented by an RNN <xref ref-type="bibr" rid="bib46">Spoerer et al., 2020</xref>; <xref ref-type="bibr" rid="bib6">Cheng et al., 2024</xref>), rather than from the visual processing system (implemented by a CNN <xref ref-type="bibr" rid="bib56">Yamins and DiCarlo, 2016</xref>). The CNN was pretrained, and the decoder did not tune its weights. Our results do not rule out the possibility that the visual system also exhibits individuality (<xref ref-type="bibr" rid="bib25">Koivisto et al., 2011</xref>; <xref ref-type="bibr" rid="bib48">Tang et al., 2018</xref>); however, they imply that individual differences in perceptual decision-making can be explained primarily by variations in the decision-making system (<xref ref-type="bibr" rid="bib37">Ratcliff and McKoon, 2008</xref>; <xref ref-type="bibr" rid="bib52">Vickers, 1970</xref>; <xref ref-type="bibr" rid="bib58">Yechiam et al., 2005</xref>; <xref ref-type="bibr" rid="bib22">Kar et al., 2019</xref>). This assumption provides valuable insights for research on human perception.</p></sec><sec id="s3-5"><title>Limitations</title><p>One limitation is that the source and target behaviors were performed on different conditions, but within the same task. Thus, our findings do not fully evaluate the generalizability of individuality transfer across diverse task domains. However, our framework has the potential to be applied to diverse tasks since it connects the source and target tasks via the individual latent representation and accepts completely different tasks for the source and target. A key to realizing this transfer might be ensuring that the cognitive functions, such as memory, required for solving the source and target tasks are (partially) shared. The latent representation is expected to represent individual features of these functions. Conversely, if source and target tasks require completely different functions to solve them, the transfer by EIDT would not work.</p><p>The effectiveness of individuality transfer may be influenced by dataset volume. As discussed earlier, prediction performance may depend on whether similar individuals exist in the training participant pool. In our study, 100 participants were sufficient for effective transfer. However, tasks involving greater behavioral diversity may require a substantially larger dataset.</p><p>As discussed earlier, the interpretability of the individual latent representation requires further investigation. Furthermore, the optimal dimensionality of the individual latent representation remains unclear. This likely depends on the complexity of tasks involved—specifically, the number of factors needed to represent the diversity of behavior observed in those tasks. While these factors have been explored in cognitive modeling research (e.g., <xref ref-type="bibr" rid="bib24">Katahira, 2015</xref>; <xref ref-type="bibr" rid="bib13">Eckstein et al., 2022</xref>), a clear understanding at the individual level is still lacking. Integrating cognitive modeling with data-driven neural network approaches (<xref ref-type="bibr" rid="bib10">Dezfouli et al., 2019a</xref>; <xref ref-type="bibr" rid="bib19">Ger et al., 2024b</xref>) could help identify key factors underlying individual differences in decision-making.</p></sec><sec id="s3-6"><title>Future directions</title><p>To further generalize our framework, a large-scale dataset is necessary, as discussed in the limitations. This dataset should include a large number of participants to ensure prediction performance for diverse individuals (<xref ref-type="bibr" rid="bib33">Peterson et al., 2021</xref>). All participants should perform the same set of tasks, which should include a variety of tasks (<xref ref-type="bibr" rid="bib57">Yang et al., 2019</xref>). Building upon our framework, where the encoder currently accepts action sequences from only a single task, a more generalizable encoder should be able to process behavioral data from multiple tasks to generate a more robust individual latent representation. To enhance the encoder, a multi-head neural network architecture (<xref ref-type="bibr" rid="bib4">Canizo et al., 2019</xref>) could be utilized. An individual latent representation would enable transfer to a wider variety of tasks and allow accurate and detailed parameterization of individuals using data from only a single task.</p><p>Robust and generalizable parameterization of individuality enables computational modeling at the individual level. This approach, in turn, makes it possible to replicate individuals’ cognitive and functional characteristics in silico (<xref ref-type="bibr" rid="bib42">Shengli, 2021</xref>). We anticipate that it offers a promising pathway toward a new frontier: artificial intelligence endowed with individuality.</p></sec></sec><sec id="s4" sec-type="methods"><title>Methods</title><sec id="s4-1"><title>General framework for individuality transfer across task conditions</title><p>We formulate the problem of individuality transfer, which involves extracting an individual latent representation from a source task condition and predicting behavior in a target task condition while preserving individuality. We consider two task conditions, <inline-formula><alternatives><mml:math id="inf122"><mml:mi>A</mml:mi></mml:math><tex-math id="inft122">\begin{document}$A$\end{document}</tex-math></alternatives></inline-formula> and <inline-formula><alternatives><mml:math id="inf123"><mml:mi>B</mml:mi></mml:math><tex-math id="inft123">\begin{document}$B$\end{document}</tex-math></alternatives></inline-formula>, which are different but related. For example, condition <inline-formula><alternatives><mml:math id="inf124"><mml:mi>A</mml:mi></mml:math><tex-math id="inft124">\begin{document}$A$\end{document}</tex-math></alternatives></inline-formula> might be a 2-step MDP, while condition <inline-formula><alternatives><mml:math id="inf125"><mml:mstyle><mml:mrow><mml:mstyle displaystyle="false"><mml:mi>B</mml:mi></mml:mstyle></mml:mrow></mml:mstyle></mml:math><tex-math id="inft125">\begin{document}$B$\end{document}</tex-math></alternatives></inline-formula> is a 3-step MDP.</p><p>The individuality transfer across task conditions is defined as follows. An individual <inline-formula><alternatives><mml:math id="inf126"><mml:mi>K</mml:mi></mml:math><tex-math id="inft126">\begin{document}$K$\end{document}</tex-math></alternatives></inline-formula> performs a problem within condition <inline-formula><alternatives><mml:math id="inf127"><mml:mi>A</mml:mi></mml:math><tex-math id="inft127">\begin{document}$A$\end{document}</tex-math></alternatives></inline-formula>, with their behavior recorded as <inline-formula><alternatives><mml:math id="inf128"><mml:msub><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi class="MJX-tex-caligraphic" mathvariant="script">A</mml:mi></mml:mrow><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>K</mml:mi></mml:mrow></mml:msub></mml:math><tex-math id="inft128">\begin{document}$\mathcal{A}_{K}$\end{document}</tex-math></alternatives></inline-formula>. Our objective is to predict <inline-formula><alternatives><mml:math id="inf129"><mml:msub><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi class="MJX-tex-caligraphic" mathvariant="script">B</mml:mi></mml:mrow><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>K</mml:mi></mml:mrow></mml:msub></mml:math><tex-math id="inft129">\begin{document}$\mathcal{B}_{K}$\end{document}</tex-math></alternatives></inline-formula>, which represents <inline-formula><alternatives><mml:math id="inf130"><mml:mi>K</mml:mi></mml:math><tex-math id="inft130">\begin{document}$K$\end{document}</tex-math></alternatives></inline-formula>’s behavior when performing a task with condition <inline-formula><alternatives><mml:math id="inf131"><mml:mi>B</mml:mi></mml:math><tex-math id="inft131">\begin{document}$B$\end{document}</tex-math></alternatives></inline-formula>. To achieve this, we extract an individual latent representation <inline-formula><alternatives><mml:math id="inf132"><mml:mstyle><mml:mrow><mml:mstyle displaystyle="false"><mml:mi mathvariant="bold-italic">z</mml:mi></mml:mstyle></mml:mrow></mml:mstyle></mml:math><tex-math id="inft132">\begin{document}$\boldsymbol{z}$\end{document}</tex-math></alternatives></inline-formula> from <inline-formula><alternatives><mml:math id="inf133"><mml:msub><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi class="MJX-tex-caligraphic" mathvariant="script">A</mml:mi></mml:mrow><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>K</mml:mi></mml:mrow></mml:msub></mml:math><tex-math id="inft133">\begin{document}$\mathcal{A}_{K}$\end{document}</tex-math></alternatives></inline-formula>, capturing the individual’s behavioral characteristics. This representation <inline-formula><alternatives><mml:math id="inf134"><mml:mstyle><mml:mrow><mml:mstyle displaystyle="false"><mml:mi mathvariant="bold-italic">z</mml:mi></mml:mstyle></mml:mrow></mml:mstyle></mml:math><tex-math id="inft134">\begin{document}$\boldsymbol{z}$\end{document}</tex-math></alternatives></inline-formula> is then used to construct a task solver, enabling it to mimic <inline-formula><alternatives><mml:math id="inf135"><mml:mi>K</mml:mi></mml:math><tex-math id="inft135">\begin{document}$K$\end{document}</tex-math></alternatives></inline-formula>’s behavior in condition <inline-formula><alternatives><mml:math id="inf136"><mml:mi>B</mml:mi></mml:math><tex-math id="inft136">\begin{document}$B$\end{document}</tex-math></alternatives></inline-formula>. Since condition <inline-formula><alternatives><mml:math id="inf137"><mml:mi>A</mml:mi></mml:math><tex-math id="inft137">\begin{document}$A$\end{document}</tex-math></alternatives></inline-formula> provides data for estimating the individual latent representation and condition <inline-formula><alternatives><mml:math id="inf138"><mml:mi>B</mml:mi></mml:math><tex-math id="inft138">\begin{document}$B$\end{document}</tex-math></alternatives></inline-formula> is the target of behavior prediction, we refer to them as the source task condition and target task condition, respectively.</p><p>Our proposed framework for the individuality transfer consists of three modules:</p><p><bold>Task solver</bold> predicts behavior in the target condition <inline-formula><alternatives><mml:math id="inf139"><mml:mi>B</mml:mi></mml:math><tex-math id="inft139">\begin{document}$B$\end{document}</tex-math></alternatives></inline-formula>.</p><p><bold>Encoder</bold> extracts the individual latent representation from the source condition <inline-formula><alternatives><mml:math id="inf140"><mml:mi>A</mml:mi></mml:math><tex-math id="inft140">\begin{document}$A$\end{document}</tex-math></alternatives></inline-formula>.</p><p><bold>Decoder</bold> generates the weights of the task solver based on the individual latent representation.</p><p>These modules are illustrated in <xref ref-type="fig" rid="fig1">Figure 1</xref>. We refer to this framework as EIDT, an acronym for encoder, individual latent representation, decoder, and task solver.</p><sec id="s4-1-1"><title>Data representation</title><p>For training, we assume that behavior data from a participant pool <inline-formula><alternatives><mml:math id="inf141"><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi class="MJX-tex-caligraphic" mathvariant="script">P</mml:mi></mml:mrow></mml:math><tex-math id="inft141">\begin{document}$\mathcal{P}$\end{document}</tex-math></alternatives></inline-formula> (<inline-formula><alternatives><mml:math id="inf142"><mml:mi>K</mml:mi><mml:mo>∉</mml:mo><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi class="MJX-tex-caligraphic" mathvariant="script">P</mml:mi></mml:mrow></mml:math><tex-math id="inft142">\begin{document}$K\notin\mathcal{P}$\end{document}</tex-math></alternatives></inline-formula>), where each participant has performed both conditions <inline-formula><alternatives><mml:math id="inf143"><mml:mi>A</mml:mi></mml:math><tex-math id="inft143">\begin{document}$A$\end{document}</tex-math></alternatives></inline-formula> and <inline-formula><alternatives><mml:math id="inf144"><mml:mi>B</mml:mi></mml:math><tex-math id="inft144">\begin{document}$B$\end{document}</tex-math></alternatives></inline-formula>. These datasets are represented as <inline-formula><alternatives><mml:math id="inf145"><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi class="MJX-tex-caligraphic" mathvariant="script">A</mml:mi></mml:mrow><mml:mo>=</mml:mo><mml:mo fence="false" stretchy="false">{</mml:mo><mml:msub><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi class="MJX-tex-caligraphic" mathvariant="script">A</mml:mi></mml:mrow><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>n</mml:mi></mml:mrow></mml:msub><mml:msub><mml:mo fence="false" stretchy="false">}</mml:mo><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>n</mml:mi><mml:mo>∈</mml:mo><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi class="MJX-tex-caligraphic" mathvariant="script">P</mml:mi></mml:mrow></mml:mrow></mml:msub></mml:math><tex-math id="inft145">\begin{document}$\mathcal{A}=\{\mathcal{A}_{n}\}_{n\in\mathcal{P}}$\end{document}</tex-math></alternatives></inline-formula> and <inline-formula><alternatives><mml:math id="inf146"><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi class="MJX-tex-caligraphic" mathvariant="script">B</mml:mi></mml:mrow><mml:mo>=</mml:mo><mml:mo fence="false" stretchy="false">{</mml:mo><mml:msub><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi class="MJX-tex-caligraphic" mathvariant="script">B</mml:mi></mml:mrow><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>n</mml:mi></mml:mrow></mml:msub><mml:msub><mml:mo fence="false" stretchy="false">}</mml:mo><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>n</mml:mi><mml:mo>∈</mml:mo><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi class="MJX-tex-caligraphic" mathvariant="script">P</mml:mi></mml:mrow></mml:mrow></mml:msub></mml:math><tex-math id="inft146">\begin{document}$\mathcal{B}=\{\mathcal{B}_{n}\}_{n\in\mathcal{P}}$\end{document}</tex-math></alternatives></inline-formula>.</p><p>For each individual <italic>n</italic>, the set <inline-formula><alternatives><mml:math id="inf147"><mml:msub><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi class="MJX-tex-caligraphic" mathvariant="script">A</mml:mi></mml:mrow><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>n</mml:mi></mml:mrow></mml:msub></mml:math><tex-math id="inft147">\begin{document}$\mathcal{A}_{n}$\end{document}</tex-math></alternatives></inline-formula> consists of one or more sets, each containing a problem instance <inline-formula><alternatives><mml:math id="inf148"><mml:mi>ϕ</mml:mi></mml:math><tex-math id="inft148">\begin{document}$\phi$\end{document}</tex-math></alternatives></inline-formula> (stimuli, task settings, or environment in condition <inline-formula><alternatives><mml:math id="inf149"><mml:mi>A</mml:mi></mml:math><tex-math id="inft149">\begin{document}$A$\end{document}</tex-math></alternatives></inline-formula>) and a sequence of action(s) <italic>α</italic> (recorded behavioral responses). For example, in an MDP task, <inline-formula><alternatives><mml:math id="inf150"><mml:mi>ϕ</mml:mi></mml:math><tex-math id="inft150">\begin{document}$\phi$\end{document}</tex-math></alternatives></inline-formula> represents the Markov process (state-action-reward transition) and <italic>α</italic> consists of choices over multiple trials. In a simple object recognition task, <inline-formula><alternatives><mml:math id="inf151"><mml:mi>ϕ</mml:mi></mml:math><tex-math id="inft151">\begin{document}$\phi$\end{document}</tex-math></alternatives></inline-formula> is a visual stimulus and <italic>α</italic> is the participant’s response to the stimulus. Similarly, <inline-formula><alternatives><mml:math id="inf152"><mml:msub><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi class="MJX-tex-caligraphic" mathvariant="script">B</mml:mi></mml:mrow><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>n</mml:mi></mml:mrow></mml:msub></mml:math><tex-math id="inft152">\begin{document}$\mathcal{B}_{n}$\end{document}</tex-math></alternatives></inline-formula> consists of a problem instance <inline-formula><alternatives><mml:math id="inf153"><mml:mi>ψ</mml:mi></mml:math><tex-math id="inft153">\begin{document}$\psi$\end{document}</tex-math></alternatives></inline-formula> and an action sequence <italic>β</italic>.</p></sec><sec id="s4-1-2"><title>Task solver</title><p>The task solver predicts the action sequence for condition <inline-formula><alternatives><mml:math id="inf154"><mml:mi>B</mml:mi></mml:math><tex-math id="inft154">\begin{document}$B$\end{document}</tex-math></alternatives></inline-formula> as<disp-formula id="equ1"><label>(1)</label><alternatives><mml:math id="m1"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow class="MJX-TeXAtom-ORD"><mml:mover><mml:mi>β</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mo>=</mml:mo><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi mathvariant="normal">T</mml:mi><mml:mi mathvariant="normal">S</mml:mi></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>ψ</mml:mi><mml:mo>;</mml:mo><mml:msub><mml:mi mathvariant="normal">Θ</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi mathvariant="normal">T</mml:mi><mml:mi mathvariant="normal">S</mml:mi></mml:mrow></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:mo>,</mml:mo></mml:mstyle></mml:math><tex-math id="t1">\begin{document}$$\displaystyle  \hat{\beta}= \mathrm{TS}(\psi; \Theta_{\mathrm{TS}}),$$\end{document}</tex-math></alternatives></disp-formula></p><p>where <inline-formula><alternatives><mml:math id="inf155"><mml:mi>ψ</mml:mi></mml:math><tex-math id="inft155">\begin{document}$\psi$\end{document}</tex-math></alternatives></inline-formula> is a specific problem in condition <inline-formula><alternatives><mml:math id="inf156"><mml:mi>B</mml:mi></mml:math><tex-math id="inft156">\begin{document}$B$\end{document}</tex-math></alternatives></inline-formula> and <inline-formula><alternatives><mml:math id="inf157"><mml:msub><mml:mi mathvariant="normal">Θ</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi mathvariant="normal">T</mml:mi><mml:mi mathvariant="normal">S</mml:mi></mml:mrow></mml:mrow></mml:msub></mml:math><tex-math id="inft157">\begin{document}$\Theta_{\mathrm{TS}}$\end{document}</tex-math></alternatives></inline-formula> represents the solver’s weights. The task solver architecture is tailored to condition <inline-formula><alternatives><mml:math id="inf158"><mml:mi>B</mml:mi></mml:math><tex-math id="inft158">\begin{document}$B$\end{document}</tex-math></alternatives></inline-formula>. For example, in an MDP task, the task solver outputs a sequence of actions in response to <inline-formula><alternatives><mml:math id="inf159"><mml:mi>ψ</mml:mi></mml:math><tex-math id="inft159">\begin{document}$\psi$\end{document}</tex-math></alternatives></inline-formula>. In a simple object recognition task, it produces an action based on a visual stimulus <inline-formula><alternatives><mml:math id="inf160"><mml:mi>ψ</mml:mi></mml:math><tex-math id="inft160">\begin{document}$\psi$\end{document}</tex-math></alternatives></inline-formula>.</p></sec><sec id="s4-1-3"><title>Encoder</title><p>The encoder processes an action sequence(s) <inline-formula><alternatives><mml:math id="inf161"><mml:mi>α</mml:mi></mml:math><tex-math id="inft161">\begin{document}$\alpha$\end{document}</tex-math></alternatives></inline-formula> and generates an individual latent representation <inline-formula><alternatives><mml:math id="inf162"><mml:mstyle><mml:mrow><mml:mstyle displaystyle="false"><mml:mi mathvariant="bold-italic">z</mml:mi><mml:mo>∈</mml:mo><mml:msup><mml:mrow><mml:mi mathvariant="double-struck">R</mml:mi></mml:mrow><mml:mrow><mml:mi>M</mml:mi></mml:mrow></mml:msup></mml:mstyle></mml:mrow></mml:mstyle></mml:math><tex-math id="inft162">\begin{document}$\boldsymbol{z}\in\mathbb{R}^{M}$\end{document}</tex-math></alternatives></inline-formula> as<disp-formula id="equ2"><label>(2)</label><alternatives><mml:math id="m2"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi mathvariant="bold-italic">z</mml:mi><mml:mo>=</mml:mo><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi mathvariant="normal">E</mml:mi><mml:mi mathvariant="normal">N</mml:mi><mml:mi mathvariant="normal">C</mml:mi></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>α</mml:mi><mml:mo>,</mml:mo><mml:mi>ϕ</mml:mi><mml:mo>;</mml:mo><mml:msub><mml:mi mathvariant="normal">Θ</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi mathvariant="normal">E</mml:mi><mml:mi mathvariant="normal">N</mml:mi><mml:mi mathvariant="normal">C</mml:mi></mml:mrow></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:mo>,</mml:mo></mml:mstyle></mml:math><tex-math id="t2">\begin{document}$$\displaystyle  \boldsymbol{z}= \mathrm{ENC}(\alpha, \phi; \Theta_{\mathrm{ENC}}),$$\end{document}</tex-math></alternatives></disp-formula></p><p>where <inline-formula><alternatives><mml:math id="inf163"><mml:mi>ϕ</mml:mi></mml:math><tex-math id="inft163">\begin{document}$\phi$\end{document}</tex-math></alternatives></inline-formula> is a problem in condition <inline-formula><alternatives><mml:math id="inf164"><mml:mi>A</mml:mi></mml:math><tex-math id="inft164">\begin{document}$A$\end{document}</tex-math></alternatives></inline-formula>, <inline-formula><alternatives><mml:math id="inf165"><mml:msub><mml:mi mathvariant="normal">Θ</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi mathvariant="normal">E</mml:mi><mml:mi mathvariant="normal">N</mml:mi><mml:mi mathvariant="normal">C</mml:mi></mml:mrow></mml:mrow></mml:msub></mml:math><tex-math id="inft165">\begin{document}$\Theta_{\mathrm{ENC}}$\end{document}</tex-math></alternatives></inline-formula> represents the encoder’s weights, and <inline-formula><alternatives><mml:math id="inf166"><mml:mi>M</mml:mi></mml:math><tex-math id="inft166">\begin{document}$M$\end{document}</tex-math></alternatives></inline-formula> is the dimensionality of the individual latent representation. The encoder architecture is task-condition-specific and designed for condition <inline-formula><alternatives><mml:math id="inf167"><mml:mi>A</mml:mi></mml:math><tex-math id="inft167">\begin{document}$A$\end{document}</tex-math></alternatives></inline-formula>.</p></sec><sec id="s4-1-4"><title>Decoder</title><p>The decoder receives the individual latent representation <inline-formula><alternatives><mml:math id="inf168"><mml:mstyle><mml:mrow><mml:mstyle displaystyle="false"><mml:mi mathvariant="bold-italic">z</mml:mi></mml:mstyle></mml:mrow></mml:mstyle></mml:math><tex-math id="inft168">\begin{document}$\boldsymbol{z}$\end{document}</tex-math></alternatives></inline-formula> and generates the task solver’s weights as<disp-formula id="equ3"><label>(3)</label><alternatives><mml:math id="m3"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msub><mml:mi mathvariant="normal">Θ</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi mathvariant="normal">T</mml:mi><mml:mi mathvariant="normal">S</mml:mi></mml:mrow></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi mathvariant="normal">D</mml:mi><mml:mi mathvariant="normal">E</mml:mi><mml:mi mathvariant="normal">C</mml:mi></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi mathvariant="bold-italic">z</mml:mi><mml:mo>;</mml:mo><mml:msub><mml:mi mathvariant="normal">Θ</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi mathvariant="normal">D</mml:mi><mml:mi mathvariant="normal">E</mml:mi><mml:mi mathvariant="normal">C</mml:mi></mml:mrow></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:mo>,</mml:mo></mml:mstyle></mml:math><tex-math id="t3">\begin{document}$$\displaystyle  \Theta_{\mathrm{TS}}= \mathrm{DEC}(\boldsymbol{z}; \Theta_{\mathrm{DEC}}),$$\end{document}</tex-math></alternatives></disp-formula></p><p>where <inline-formula><alternatives><mml:math id="inf169"><mml:msub><mml:mi mathvariant="normal">Θ</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi mathvariant="normal">D</mml:mi><mml:mi mathvariant="normal">E</mml:mi><mml:mi mathvariant="normal">C</mml:mi></mml:mrow></mml:mrow></mml:msub></mml:math><tex-math id="inft169">\begin{document}$\Theta_{\mathrm{DEC}}$\end{document}</tex-math></alternatives></inline-formula> represents the decoder’s weights. Since the decoder determines the task solver’s weights, it functions as a hypernetwork (<xref ref-type="bibr" rid="bib20">Ha et al., 2016</xref>; <xref ref-type="bibr" rid="bib23">Karaletsos et al., 2018</xref>).</p></sec><sec id="s4-1-5"><title>Training objective</title><p>Although conditions <inline-formula><alternatives><mml:math id="inf170"><mml:mi>A</mml:mi></mml:math><tex-math id="inft170">\begin{document}$A$\end{document}</tex-math></alternatives></inline-formula> and <inline-formula><alternatives><mml:math id="inf171"><mml:mi>B</mml:mi></mml:math><tex-math id="inft171">\begin{document}$B$\end{document}</tex-math></alternatives></inline-formula> differ, an individual’s decision-making system remains consistent across task conditions. We model this using the individual latent representation <inline-formula><alternatives><mml:math id="inf172"><mml:mstyle><mml:mrow><mml:mstyle displaystyle="false"><mml:mi mathvariant="bold-italic">z</mml:mi></mml:mstyle></mml:mrow></mml:mstyle></mml:math><tex-math id="inft172">\begin{document}$\boldsymbol{z}$\end{document}</tex-math></alternatives></inline-formula>, linking it to the task solver via the encoder and decoder. For training, we use a behavioral dataset <inline-formula><alternatives><mml:math id="inf173"><mml:mo fence="false" stretchy="false">{</mml:mo><mml:msub><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi class="MJX-tex-caligraphic" mathvariant="script">A</mml:mi></mml:mrow><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>n</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi class="MJX-tex-caligraphic" mathvariant="script">B</mml:mi></mml:mrow><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>n</mml:mi></mml:mrow></mml:msub><mml:msub><mml:mo fence="false" stretchy="false">}</mml:mo><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>n</mml:mi><mml:mo>∈</mml:mo><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi class="MJX-tex-caligraphic" mathvariant="script">P</mml:mi></mml:mrow></mml:mrow></mml:msub></mml:math><tex-math id="inft173">\begin{document}$\{\mathcal{A}_{n},\mathcal{B}_{n}\}_{n\in\mathcal{P}}$\end{document}</tex-math></alternatives></inline-formula> from an individual pool <inline-formula><alternatives><mml:math id="inf174"><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi class="MJX-tex-caligraphic" mathvariant="script">P</mml:mi></mml:mrow></mml:math><tex-math id="inft174">\begin{document}$\mathcal{P}$\end{document}</tex-math></alternatives></inline-formula>.</p><p>Let <inline-formula><alternatives><mml:math id="inf175"><mml:mi>α</mml:mi></mml:math><tex-math id="inft175">\begin{document}$\alpha$\end{document}</tex-math></alternatives></inline-formula> be an action sequence representing individual <inline-formula><alternatives><mml:math id="inf176"><mml:mi>n</mml:mi></mml:math><tex-math id="inft176">\begin{document}$n$\end{document}</tex-math></alternatives></inline-formula>’s behavior on the source task condition, that is <inline-formula><alternatives><mml:math id="inf177"><mml:mo stretchy="false">(</mml:mo><mml:mi>α</mml:mi><mml:mo>,</mml:mo><mml:mi>ϕ</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>∈</mml:mo><mml:msub><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi class="MJX-tex-caligraphic" mathvariant="script">A</mml:mi></mml:mrow><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>n</mml:mi></mml:mrow></mml:msub></mml:math><tex-math id="inft177">\begin{document}$(\alpha,\phi)\in\mathcal{A}_{n}$\end{document}</tex-math></alternatives></inline-formula>, <inline-formula><alternatives><mml:math id="inf178"><mml:mi>n</mml:mi><mml:mo>∈</mml:mo><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi class="MJX-tex-caligraphic" mathvariant="script">P</mml:mi></mml:mrow></mml:math><tex-math id="inft178">\begin{document}$n\in\mathcal{P}$\end{document}</tex-math></alternatives></inline-formula>. The individual latent representation is derived by <inline-formula><alternatives><mml:math id="inf179"><mml:mstyle><mml:mrow><mml:mstyle displaystyle="false"><mml:mi mathvariant="bold-italic">z</mml:mi><mml:mo>=</mml:mo><mml:mrow><mml:mi mathvariant="normal">E</mml:mi><mml:mi mathvariant="normal">N</mml:mi><mml:mi mathvariant="normal">C</mml:mi></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>α</mml:mi><mml:mo>,</mml:mo><mml:mi>ϕ</mml:mi><mml:mo>;</mml:mo><mml:msub><mml:mi mathvariant="normal">Θ</mml:mi><mml:mrow><mml:mrow><mml:mi mathvariant="normal">E</mml:mi><mml:mi mathvariant="normal">N</mml:mi><mml:mi mathvariant="normal">C</mml:mi></mml:mrow></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mstyle></mml:mrow></mml:mstyle></mml:math><tex-math id="inft179">\begin{document}$\boldsymbol{z}=\mathrm{ENC}(\alpha,\phi;\Theta_{\mathrm{ENC}})$\end{document}</tex-math></alternatives></inline-formula>. The weights of the task solver are then given by <inline-formula><alternatives><mml:math id="inf180"><mml:mstyle><mml:mrow><mml:mstyle displaystyle="false"><mml:msub><mml:mi mathvariant="normal">Θ</mml:mi><mml:mrow><mml:mrow><mml:mi mathvariant="normal">T</mml:mi><mml:mi mathvariant="normal">S</mml:mi></mml:mrow></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mrow><mml:mi mathvariant="normal">D</mml:mi><mml:mi mathvariant="normal">E</mml:mi><mml:mi mathvariant="normal">C</mml:mi></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi mathvariant="bold-italic">z</mml:mi><mml:mo>;</mml:mo><mml:msub><mml:mi mathvariant="normal">Θ</mml:mi><mml:mrow><mml:mrow><mml:mi mathvariant="normal">D</mml:mi><mml:mi mathvariant="normal">E</mml:mi><mml:mi mathvariant="normal">C</mml:mi></mml:mrow></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mstyle></mml:mrow></mml:mstyle></mml:math><tex-math id="inft180">\begin{document}$\Theta_{\mathrm{TS}}=\mathrm{DEC}(\boldsymbol{z};\Theta_{\mathrm{DEC}})$\end{document}</tex-math></alternatives></inline-formula>. Subsequently, the task solver, with the given weights, predicts an action sequence for condition <inline-formula><alternatives><mml:math id="inf181"><mml:mi>B</mml:mi></mml:math><tex-math id="inft181">\begin{document}$B$\end{document}</tex-math></alternatives></inline-formula> as <inline-formula><alternatives><mml:math id="inf182"><mml:mrow class="MJX-TeXAtom-ORD"><mml:mover><mml:mi>β</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mo>=</mml:mo><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi mathvariant="normal">T</mml:mi><mml:mi mathvariant="normal">S</mml:mi></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>ψ</mml:mi><mml:mo>;</mml:mo><mml:msub><mml:mi mathvariant="normal">Θ</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi mathvariant="normal">T</mml:mi><mml:mi mathvariant="normal">S</mml:mi></mml:mrow></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:math><tex-math id="inft182">\begin{document}$\hat{\beta}=\mathrm{TS}(\psi;\Theta_{\mathrm{TS}})$\end{document}</tex-math></alternatives></inline-formula>, where <inline-formula><alternatives><mml:math id="inf183"><mml:mo stretchy="false">(</mml:mo><mml:mi>β</mml:mi><mml:mo>,</mml:mo><mml:mi>ψ</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>∈</mml:mo><mml:msub><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi class="MJX-tex-caligraphic" mathvariant="script">B</mml:mi></mml:mrow><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>n</mml:mi></mml:mrow></mml:msub></mml:math><tex-math id="inft183">\begin{document}$(\beta,\psi)\in\mathcal{B}_{n}$\end{document}</tex-math></alternatives></inline-formula>. We then measure the prediction error between <inline-formula><alternatives><mml:math id="inf184"><mml:mrow class="MJX-TeXAtom-ORD"><mml:mover><mml:mi>β</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow></mml:math><tex-math id="inft184">\begin{document}$\hat{\beta}$\end{document}</tex-math></alternatives></inline-formula> and <inline-formula><alternatives><mml:math id="inf185"><mml:mi>β</mml:mi></mml:math><tex-math id="inft185">\begin{document}$\beta$\end{document}</tex-math></alternatives></inline-formula> as:<disp-formula id="equ4"><label>(4)</label><alternatives><mml:math id="m4"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msub><mml:mi>L</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>p</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>α</mml:mi><mml:mo>,</mml:mo><mml:mi>ϕ</mml:mi><mml:mo>,</mml:mo><mml:mi>β</mml:mi><mml:mo>,</mml:mo><mml:mi>ψ</mml:mi><mml:mo>,</mml:mo><mml:msub><mml:mi mathvariant="normal">Θ</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi mathvariant="normal">E</mml:mi><mml:mi mathvariant="normal">N</mml:mi><mml:mi mathvariant="normal">C</mml:mi></mml:mrow></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi mathvariant="normal">Θ</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi mathvariant="normal">D</mml:mi><mml:mi mathvariant="normal">E</mml:mi><mml:mi mathvariant="normal">C</mml:mi></mml:mrow></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mi>O</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>β</mml:mi><mml:mo>,</mml:mo><mml:mrow class="MJX-TeXAtom-ORD"><mml:mover><mml:mi>β</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mo stretchy="false">)</mml:mo><mml:mo>,</mml:mo></mml:mstyle></mml:math><tex-math id="t4">\begin{document}$$\displaystyle  L_{p}(\alpha, \phi, \beta, \psi, \Theta_{\mathrm{ENC}}, \Theta_{\mathrm{DEC}}) = O(\beta, \hat{\beta}),$$\end{document}</tex-math></alternatives></disp-formula></p><p>where <italic>β</italic> is an action sequence in <inline-formula><alternatives><mml:math id="inf186"><mml:msub><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi class="MJX-tex-caligraphic" mathvariant="script">B</mml:mi></mml:mrow><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>n</mml:mi></mml:mrow></mml:msub></mml:math><tex-math id="inft186">\begin{document}$\mathcal{B}_{n}$\end{document}</tex-math></alternatives></inline-formula> recorded along with the problem <inline-formula><alternatives><mml:math id="inf187"><mml:mi>ψ</mml:mi></mml:math><tex-math id="inft187">\begin{document}$\psi$\end{document}</tex-math></alternatives></inline-formula>, and <inline-formula><alternatives><mml:math id="inf188"><mml:mi>O</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mo>⋅</mml:mo><mml:mo>,</mml:mo><mml:mo>⋅</mml:mo><mml:mo stretchy="false">)</mml:mo></mml:math><tex-math id="inft188">\begin{document}$O(\cdot,\cdot)$\end{document}</tex-math></alternatives></inline-formula> is a suitable loss function (e.g. likelihood-based loss for probabilistic outputs). Using the datasets containing the behavior of the individual pool <inline-formula><alternatives><mml:math id="inf189"><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi class="MJX-tex-caligraphic" mathvariant="script">P</mml:mi></mml:mrow></mml:math><tex-math id="inft189">\begin{document}$\mathcal{P}$\end{document}</tex-math></alternatives></inline-formula>, the weights of the encoder and decoders, <inline-formula><alternatives><mml:math id="inf190"><mml:msub><mml:mi mathvariant="normal">Θ</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi mathvariant="normal">E</mml:mi><mml:mi mathvariant="normal">N</mml:mi><mml:mi mathvariant="normal">C</mml:mi></mml:mrow></mml:mrow></mml:msub></mml:math><tex-math id="inft190">\begin{document}$\Theta_{\mathrm{ENC}}$\end{document}</tex-math></alternatives></inline-formula> and <inline-formula><alternatives><mml:math id="inf191"><mml:msub><mml:mi mathvariant="normal">Θ</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi mathvariant="normal">D</mml:mi><mml:mi mathvariant="normal">E</mml:mi><mml:mi mathvariant="normal">C</mml:mi></mml:mrow></mml:mrow></mml:msub></mml:math><tex-math id="inft191">\begin{document}$\Theta_{\mathrm{DEC}}$\end{document}</tex-math></alternatives></inline-formula>, are optimized by minimizing the total loss:<disp-formula id="equ5"><label>(5)</label><alternatives><mml:math id="m5"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>L</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi mathvariant="normal">Θ</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi mathvariant="normal">E</mml:mi><mml:mi mathvariant="normal">N</mml:mi><mml:mi mathvariant="normal">C</mml:mi></mml:mrow></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi mathvariant="normal">Θ</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi mathvariant="normal">D</mml:mi><mml:mi mathvariant="normal">E</mml:mi><mml:mi mathvariant="normal">C</mml:mi></mml:mrow></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mrow><mml:mrow class="MJX-TeXAtom-ORD"><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi class="MJX-tex-caligraphic" mathvariant="script">P</mml:mi></mml:mrow><mml:mrow class="MJX-TeXAtom-ORD"><mml:mo stretchy="false">|</mml:mo></mml:mrow></mml:mrow></mml:mfrac><mml:munder><mml:mo>∑</mml:mo><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>n</mml:mi><mml:mo>∈</mml:mo><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi class="MJX-tex-caligraphic" mathvariant="script">P</mml:mi></mml:mrow></mml:mrow></mml:munder><mml:mfrac><mml:mn>1</mml:mn><mml:mrow><mml:mrow class="MJX-TeXAtom-ORD"><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:msub><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi class="MJX-tex-caligraphic" mathvariant="script">A</mml:mi></mml:mrow><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>n</mml:mi></mml:mrow></mml:msub><mml:mrow class="MJX-TeXAtom-ORD"><mml:mo stretchy="false">|</mml:mo></mml:mrow></mml:mrow></mml:mfrac><mml:munder><mml:mo>∑</mml:mo><mml:mrow class="MJX-TeXAtom-ORD"><mml:mo stretchy="false">(</mml:mo><mml:mi>α</mml:mi><mml:mo>,</mml:mo><mml:mi>ϕ</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>∈</mml:mo><mml:msub><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi class="MJX-tex-caligraphic" mathvariant="script">A</mml:mi></mml:mrow><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>n</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:munder><mml:mfrac><mml:mn>1</mml:mn><mml:mrow><mml:mrow class="MJX-TeXAtom-ORD"><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:msub><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi class="MJX-tex-caligraphic" mathvariant="script">B</mml:mi></mml:mrow><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>n</mml:mi></mml:mrow></mml:msub><mml:mrow class="MJX-TeXAtom-ORD"><mml:mo stretchy="false">|</mml:mo></mml:mrow></mml:mrow></mml:mfrac><mml:munder><mml:mo>∑</mml:mo><mml:mrow class="MJX-TeXAtom-ORD"><mml:mrow class="MJX-TeXAtom-ORD"><mml:mo stretchy="false">(</mml:mo><mml:mi>β</mml:mi><mml:mo>,</mml:mo><mml:mi>ψ</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>∈</mml:mo><mml:msub><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi class="MJX-tex-caligraphic" mathvariant="script">B</mml:mi></mml:mrow><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>n</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mrow></mml:munder><mml:msub><mml:mi>L</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>p</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>α</mml:mi><mml:mo>,</mml:mo><mml:mi>ϕ</mml:mi><mml:mo>,</mml:mo><mml:mi>β</mml:mi><mml:mo>,</mml:mo><mml:mi>ψ</mml:mi><mml:mo>,</mml:mo><mml:msub><mml:mi mathvariant="normal">Θ</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi mathvariant="normal">E</mml:mi><mml:mi mathvariant="normal">N</mml:mi><mml:mi mathvariant="normal">C</mml:mi></mml:mrow></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi mathvariant="normal">Θ</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi mathvariant="normal">D</mml:mi><mml:mi mathvariant="normal">E</mml:mi><mml:mi mathvariant="normal">C</mml:mi></mml:mrow></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:mo>.</mml:mo></mml:mstyle></mml:math><tex-math id="t5">\begin{document}$$\displaystyle  L(\Theta_{\mathrm{ENC}}, \Theta_{\mathrm{DEC}}) = \frac{1}{|\mathcal{P}|}\sum_{n \in \mathcal{P}}\frac{1}{|\mathcal{A}_{n}|}\sum_{(\alpha, \phi) \in \mathcal{A}_{n}}\frac{1}{|\mathcal{B}_{n}|}\sum_{{(\beta, \psi) \in \mathcal{B}_{n}}}L_{p}(\alpha, \phi, \beta, \psi, \Theta_{\mathrm{ENC}}, \Theta_{\mathrm{DEC}}).$$\end{document}</tex-math></alternatives></disp-formula></p><p>This section provides a general formulation of individuality transfer across two task conditions. For specific details on task architectures and loss functions, see Experiment on MDP task and Experiment on MNIST task.</p></sec></sec><sec id="s4-2"><title>Experiment on MDP task</title><p>We validated our individuality transfer framework using two different decision-making tasks: the MDP task and the MNIST task. This section focuses on the MDP tasks, a dynamic multi-step decision-making task.</p><sec id="s4-2-1"><title>Task</title><p>At the beginning of each episode, an initial state-cue is presented to the participant. For human participants, the state cue is represented by animal images (<xref ref-type="fig" rid="fig12">Figure 12</xref>). For the cognitive model (Q-learning agent) and neural network-based model, the state-cue is represented numerically (e.g. (2, 1) for the first task state in the second choice). The participant makes a binary decision (denoted as action <inline-formula><alternatives><mml:math id="inf192"><mml:msub><mml:mi>C</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:math><tex-math id="inft192">\begin{document}$C_{1}$\end{document}</tex-math></alternatives></inline-formula> or <inline-formula><alternatives><mml:math id="inf193"><mml:msub><mml:mi>C</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mn>2</mml:mn></mml:mrow></mml:msub></mml:math><tex-math id="inft193">\begin{document}$C_{2}$\end{document}</tex-math></alternatives></inline-formula>) for each step. In the human experiment, these actions correspond to pressing the left or right cursor key. With a certain probability (either 0.8/0.2 or 0.6/0.4), known as the state-action transition probability, the participant transitions to one of two subsequent task states. This process repeats two times for the 2-step MDP and three times in the 3-step MDP. After the final step, the participant receives an outcome: either a reward (<inline-formula><alternatives><mml:math id="inf194"><mml:mi>r</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:math><tex-math id="inft194">\begin{document}$r=1$\end{document}</tex-math></alternatives></inline-formula>) or no reward (<inline-formula><alternatives><mml:math id="inf195"><mml:mi>r</mml:mi><mml:mo>=</mml:mo><mml:mn>0</mml:mn></mml:math><tex-math id="inft195">\begin{document}$r=0$\end{document}</tex-math></alternatives></inline-formula>). For human participants, rewards were displayed as symbols, as shown in <xref ref-type="fig" rid="fig12">Figure 12</xref>. Each sequence from initial state-cue presentation to reward delivery constitutes an <italic>episode</italic>.</p><fig id="fig12" position="float"><label>Figure 12.</label><caption><title>The 3-step MDP task.</title><p>(<bold>A</bold>) Tree diagram illustrating state-action transitions. (<bold>B</bold>) Flow of a single episode in the behavioral experiment for human participants.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-107163-fig12-v1.tif"/></fig><p>The state-action transition probability <inline-formula><alternatives><mml:math id="inf196"><mml:mi>T</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>s</mml:mi><mml:mo>,</mml:mo><mml:mi>a</mml:mi><mml:mo>,</mml:mo><mml:msup><mml:mi>s</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi class="MJX-variant" mathvariant="normal">′</mml:mi></mml:mrow></mml:msup><mml:mo stretchy="false">)</mml:mo></mml:math><tex-math id="inft196">\begin{document}$T(s,a,s^{\prime})$\end{document}</tex-math></alternatives></inline-formula> from a task state <italic>s</italic> to a preceding state <inline-formula><alternatives><mml:math id="inf197"><mml:msup><mml:mi>s</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi class="MJX-variant" mathvariant="normal">′</mml:mi></mml:mrow></mml:msup></mml:math><tex-math id="inft197">\begin{document}$s^{\prime}$\end{document}</tex-math></alternatives></inline-formula> given an action <inline-formula><alternatives><mml:math id="inf198"><mml:mi>a</mml:mi></mml:math><tex-math id="inft198">\begin{document}$a$\end{document}</tex-math></alternatives></inline-formula> varies gradually across episodes. With probability <inline-formula><alternatives><mml:math id="inf199"><mml:msub><mml:mi>p</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi mathvariant="normal">t</mml:mi><mml:mi mathvariant="normal">r</mml:mi><mml:mi mathvariant="normal">a</mml:mi><mml:mi mathvariant="normal">n</mml:mi><mml:mi mathvariant="normal">s</mml:mi></mml:mrow></mml:mrow></mml:msub></mml:math><tex-math id="inft199">\begin{document}$p_{\mathrm{trans}}$\end{document}</tex-math></alternatives></inline-formula>, one of the transition probabilities switches to a new set chosen from {(0.8, 0.2), (0.2, 0.8), (0.6, 0.4), (0.4, 0.6)}. Consequently, participants must adjust their decision-making strategy in response to these shifts in transition probabilities to maintain reward maximization.</p></sec><sec id="s4-2-2"><title>Behavioral data collection</title><p>We recruited 123 participants via Prolific. All participants provided their informed consent online. This study was approved by the Committee for Human Research at the Graduate School of Engineering, The University of Osaka (Approval number: 5-4-1), and complied with the Declaration of Helsinki. Participants received a base compensation of £4 for completing the entire experiment. A performance-based bonus (£0 to £2, average: £1) was awarded based on rewards earned in the MDP task.</p><p>Each participant completed 3 sequences for each step condition (2-step and 3-step MDP tasks), with each sequence comprising 50 episodes. The order of the 2-step and 3-step MDP tasks was randomized across sequences. State-cue assignment (animal images) was randomly determined for each sequence. Participants took a mandatory break (≥1 min) between sequences.</p><p>To ensure data quality, we applied exclusion criteria based on average reward, action bias, and response time. Thresholds for these metrics were systematically determined using the interquartile range method on statistics from the initial dataset. Participants were removed from the analysis entirely if their data from any single block fell outside these established ranges. This procedure led to the exclusion of one participant for low average reward (below 0.387 for the 2-step MDP and 0.382 for the 3-step MDP), 23 participants for excessive action bias (outside the 26.3–73.3% range), and 18 for outlier response times (outside the 0.260–1.983 s range). In total, 42 participants (approximately 34%) were excluded, resulting in a final sample of 81 participants for analysis.</p></sec><sec id="s4-2-3"><title>Cognitive model</title><p>To model decision-making in the MDP task, we employed a Q-learning agent (<xref ref-type="bibr" rid="bib47">Sutton and Barto, 1998</xref>). At each step <italic>t</italic>, the agent was presented with the current task state <inline-formula><alternatives><mml:math id="inf200"><mml:msub><mml:mi>s</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>t</mml:mi></mml:mrow></mml:msub></mml:math><tex-math id="inft200">\begin{document}$s_{t}$\end{document}</tex-math></alternatives></inline-formula> and selected an action <inline-formula><alternatives><mml:math id="inf201"><mml:msub><mml:mi>a</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>t</mml:mi></mml:mrow></mml:msub></mml:math><tex-math id="inft201">\begin{document}$a_{t}$\end{document}</tex-math></alternatives></inline-formula>. The agent maintained <inline-formula><alternatives><mml:math id="inf202"><mml:mi>Q</mml:mi></mml:math><tex-math id="inft202">\begin{document}$Q$\end{document}</tex-math></alternatives></inline-formula>-values, denoted as <inline-formula><alternatives><mml:math id="inf203"><mml:mi>Q</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>s</mml:mi><mml:mo>,</mml:mo><mml:mi>a</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:math><tex-math id="inft203">\begin{document}$Q(s,a)$\end{document}</tex-math></alternatives></inline-formula>, for all state-action pairs, where <italic>s</italic> was a state of the set of all possible task states <inline-formula><alternatives><mml:math id="inf204"><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi class="MJX-tex-caligraphic" mathvariant="script">S</mml:mi></mml:mrow></mml:math><tex-math id="inft204">\begin{document}$\mathcal{S}$\end{document}</tex-math></alternatives></inline-formula> and <italic>a</italic> was an action of the set of available actions in that state <inline-formula><alternatives><mml:math id="inf205"><mml:msub><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi class="MJX-tex-caligraphic" mathvariant="script">C</mml:mi></mml:mrow><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>s</mml:mi></mml:mrow></mml:msub></mml:math><tex-math id="inft205">\begin{document}$\mathcal{C}_{s}$\end{document}</tex-math></alternatives></inline-formula>. The probability of selecting action <italic>a</italic> was determined by a softmax policy:<disp-formula id="equ6"><label>(6)</label><alternatives><mml:math id="m6"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>π</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>a</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mi>exp</mml:mi><mml:mo>⁡</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>q</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi mathvariant="normal">i</mml:mi><mml:mi mathvariant="normal">t</mml:mi></mml:mrow></mml:mrow></mml:msub><mml:mi>Q</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>s</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:mi>a</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mrow><mml:munder><mml:mo>∑</mml:mo><mml:mrow class="MJX-TeXAtom-ORD"><mml:msup><mml:mi>a</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi class="MJX-variant" mathvariant="normal">′</mml:mi></mml:mrow></mml:msup><mml:mo>∈</mml:mo><mml:msub><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi class="MJX-tex-caligraphic" mathvariant="script">C</mml:mi></mml:mrow><mml:mrow class="MJX-TeXAtom-ORD"><mml:msub><mml:mi>s</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>t</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:msub></mml:mrow></mml:munder><mml:mi>exp</mml:mi><mml:mo>⁡</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>q</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi mathvariant="normal">i</mml:mi><mml:mi mathvariant="normal">t</mml:mi></mml:mrow></mml:mrow></mml:msub><mml:mi>Q</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>s</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msup><mml:mi>a</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi class="MJX-variant" mathvariant="normal">′</mml:mi></mml:mrow></mml:msup><mml:mo stretchy="false">)</mml:mo><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mfrac><mml:mo>,</mml:mo></mml:mstyle></mml:math><tex-math id="t6">\begin{document}$$\displaystyle  \pi(a) = \frac{\exp(q_{\mathrm{it}}Q(s_{t}, a))}{\sum_{a^{\prime} \in \mathcal{C}_{s_{t}}}\exp(q_{\mathrm{it}}Q(s_{t}, a^{\prime}))},$$\end{document}</tex-math></alternatives></disp-formula></p><p>where <inline-formula><alternatives><mml:math id="inf206"><mml:msub><mml:mi>q</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi mathvariant="normal">i</mml:mi><mml:mi mathvariant="normal">t</mml:mi></mml:mrow></mml:mrow></mml:msub><mml:mo>&gt;</mml:mo><mml:mn>0</mml:mn></mml:math><tex-math id="inft206">\begin{document}$q_{\mathrm{it}} \gt 0$\end{document}</tex-math></alternatives></inline-formula> was a parameter called the inverse temperature or reward sensitivity, controlling the balance between exploration and exploitation.</p><p>After selecting action <inline-formula><alternatives><mml:math id="inf207"><mml:msub><mml:mi>a</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>t</mml:mi></mml:mrow></mml:msub></mml:math><tex-math id="inft207">\begin{document}$a_{t}$\end{document}</tex-math></alternatives></inline-formula>, the agent received an outcome <inline-formula><alternatives><mml:math id="inf208"><mml:msub><mml:mi>r</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>∈</mml:mo><mml:mo fence="false" stretchy="false">{</mml:mo><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:mn>1</mml:mn><mml:mo fence="false" stretchy="false">}</mml:mo></mml:math><tex-math id="inft208">\begin{document}$r_{t}\in\{0,1\}$\end{document}</tex-math></alternatives></inline-formula> and transitioned to a new state <inline-formula><alternatives><mml:math id="inf209"><mml:msub><mml:mi>s</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>t</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:math><tex-math id="inft209">\begin{document}$s_{t+1}$\end{document}</tex-math></alternatives></inline-formula>. The <inline-formula><alternatives><mml:math id="inf210"><mml:mi>Q</mml:mi></mml:math><tex-math id="inft210">\begin{document}$Q$\end{document}</tex-math></alternatives></inline-formula>-value for the selected action was updated by<disp-formula id="equ7"><label>(7)</label><alternatives><mml:math id="m7"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>Q</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>s</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>a</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:mo stretchy="false">←</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:msub><mml:mi>q</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi mathvariant="normal">l</mml:mi><mml:mi mathvariant="normal">r</mml:mi></mml:mrow></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:mi>Q</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>s</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>a</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:mo>+</mml:mo><mml:msub><mml:mi>q</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi mathvariant="normal">l</mml:mi><mml:mi mathvariant="normal">r</mml:mi></mml:mrow></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>r</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mi>q</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi mathvariant="normal">d</mml:mi><mml:mi mathvariant="normal">r</mml:mi></mml:mrow></mml:mrow></mml:msub><mml:munder><mml:mo movablelimits="true" form="prefix">max</mml:mo><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>a</mml:mi><mml:mo>∈</mml:mo><mml:msub><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi class="MJX-tex-caligraphic" mathvariant="script">C</mml:mi></mml:mrow><mml:mrow class="MJX-TeXAtom-ORD"><mml:msub><mml:mi>s</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>t</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:msub></mml:mrow></mml:munder><mml:mi>Q</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>s</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>t</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:mi>a</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo stretchy="false">)</mml:mo><mml:mo>,</mml:mo></mml:mstyle></mml:math><tex-math id="t7">\begin{document}$$\displaystyle  Q(s_{t}, a_{t}) \leftarrow (1 - q_{\mathrm{lr}}) Q(s_{t}, a_{t}) + q_{\mathrm{lr}}(r_{t}+ q_{\mathrm{dr}}\max_{a \in \mathcal{C}_{s_{t+1}}}Q(s_{t+1}, a)),$$\end{document}</tex-math></alternatives></disp-formula></p><p>where <inline-formula><alternatives><mml:math id="inf211"><mml:msub><mml:mi>q</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi mathvariant="normal">l</mml:mi><mml:mi mathvariant="normal">r</mml:mi></mml:mrow></mml:mrow></mml:msub><mml:mo>∈</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:math><tex-math id="inft211">\begin{document}$q_{\mathrm{lr}}\in(0,1)$\end{document}</tex-math></alternatives></inline-formula> was the learning rate, determining how much newly acquired information replaced existing knowledge, and <inline-formula><alternatives><mml:math id="inf212"><mml:msub><mml:mi>q</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi mathvariant="normal">d</mml:mi><mml:mi mathvariant="normal">r</mml:mi></mml:mrow></mml:mrow></mml:msub><mml:mo>∈</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:math><tex-math id="inft212">\begin{document}$q_{\mathrm{dr}}\in(0,1)$\end{document}</tex-math></alternatives></inline-formula> was the discount rate, governing the extent to which future rewards influenced current decision. The <inline-formula><alternatives><mml:math id="inf213"><mml:mi>Q</mml:mi></mml:math><tex-math id="inft213">\begin{document}$Q$\end{document}</tex-math></alternatives></inline-formula>-values are initialized as <inline-formula><alternatives><mml:math id="inf214"><mml:msub><mml:mi>q</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi mathvariant="normal">i</mml:mi><mml:mi mathvariant="normal">n</mml:mi><mml:mi mathvariant="normal">i</mml:mi><mml:mi mathvariant="normal">t</mml:mi></mml:mrow></mml:mrow></mml:msub></mml:math><tex-math id="inft214">\begin{document}$q_{\mathrm{init}}$\end{document}</tex-math></alternatives></inline-formula> before an agent starts the first episode.</p></sec><sec id="s4-2-4"><title>EIDT model</title><p>This section describes the specific models used for individuality transfer in the MDP task.</p><sec id="s4-2-4-1"><title>Data representation</title><p>Since MDP tasks involve sequential decision-making, each action sequence consists of multiple actions within a single session. In our experiment, each participant completed <inline-formula><alternatives><mml:math id="inf215"><mml:mi>L</mml:mi></mml:math><tex-math id="inft215">\begin{document}$L$\end{document}</tex-math></alternatives></inline-formula> trials per session, with <inline-formula><alternatives><mml:math id="inf216"><mml:mi>L</mml:mi><mml:mo>=</mml:mo><mml:mn>100</mml:mn></mml:math><tex-math id="inft216">\begin{document}$L=100$\end{document}</tex-math></alternatives></inline-formula> for the 2-step MDP and <inline-formula><alternatives><mml:math id="inf217"><mml:mi>L</mml:mi><mml:mo>=</mml:mo><mml:mn>150</mml:mn></mml:math><tex-math id="inft217">\begin{document}$L=150$\end{document}</tex-math></alternatives></inline-formula> for the 3-step MDP. The action sequence is represented as <inline-formula><alternatives><mml:math id="inf218"><mml:mo stretchy="false">[</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>s</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>a</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>r</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:mo>,</mml:mo><mml:mo>…</mml:mo><mml:mo>,</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>s</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>L</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>a</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>L</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>r</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>L</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:mo stretchy="false">]</mml:mo></mml:math><tex-math id="inft218">\begin{document}$[(s_{1},a_{1},r_{1}),\ldots,(s_{L},a_{L},r_{L})]$\end{document}</tex-math></alternatives></inline-formula>, where, <inline-formula><alternatives><mml:math id="inf219"><mml:msub><mml:mi>s</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>t</mml:mi></mml:mrow></mml:msub></mml:math><tex-math id="inft219">\begin{document}$s_{t}$\end{document}</tex-math></alternatives></inline-formula> denotes the task state at trial <inline-formula><alternatives><mml:math id="inf220"><mml:mi>t</mml:mi></mml:math><tex-math id="inft220">\begin{document}$t$\end{document}</tex-math></alternatives></inline-formula>, <inline-formula><alternatives><mml:math id="inf221"><mml:msub><mml:mi>a</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>∈</mml:mo><mml:mi>C</mml:mi></mml:math><tex-math id="inft221">\begin{document}$a_{t}\in C$\end{document}</tex-math></alternatives></inline-formula> represents the action selected from the set <inline-formula><alternatives><mml:math id="inf222"><mml:mi>C</mml:mi><mml:mo>≡</mml:mo><mml:mo fence="false" stretchy="false">{</mml:mo><mml:msub><mml:mi>C</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>k</mml:mi></mml:mrow></mml:msub><mml:msubsup><mml:mo fence="false" stretchy="false">}</mml:mo><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>k</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>K</mml:mi></mml:mrow></mml:msubsup></mml:math><tex-math id="inft222">\begin{document}$C\equiv\{C_{k}\}_{k=1}^{K}$\end{document}</tex-math></alternatives></inline-formula> (with <inline-formula><alternatives><mml:math id="inf223"><mml:mi>K</mml:mi><mml:mo>=</mml:mo><mml:mn>2</mml:mn></mml:math><tex-math id="inft223">\begin{document}$K=2$\end{document}</tex-math></alternatives></inline-formula> in our task), and <inline-formula><alternatives><mml:math id="inf224"><mml:msub><mml:mi>r</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>∈</mml:mo><mml:mo fence="false" stretchy="false">{</mml:mo><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:mn>1</mml:mn><mml:mo fence="false" stretchy="false">}</mml:mo></mml:math><tex-math id="inft224">\begin{document}$r_{t}\in\{0,1\}$\end{document}</tex-math></alternatives></inline-formula> indicates whether a reward was received. In the <inline-formula><alternatives><mml:math id="inf225"><mml:mi>M</mml:mi></mml:math><tex-math id="inft225">\begin{document}$M$\end{document}</tex-math></alternatives></inline-formula>-step MDP described in <xref ref-type="fig" rid="fig12">Figure 12</xref>, each task state is represented as <inline-formula><alternatives><mml:math id="inf226"><mml:mo stretchy="false">(</mml:mo><mml:mi>m</mml:mi><mml:mo>,</mml:mo><mml:msub><mml:mi>c</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>m</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:math><tex-math id="inft226">\begin{document}$(m,c_{m})$\end{document}</tex-math></alternatives></inline-formula>, where <inline-formula><alternatives><mml:math id="inf227"><mml:mi>m</mml:mi></mml:math><tex-math id="inft227">\begin{document}$m$\end{document}</tex-math></alternatives></inline-formula> denotes the current step within the episode (<inline-formula><alternatives><mml:math id="inf228"><mml:mi>m</mml:mi><mml:mo>∈</mml:mo><mml:mo fence="false" stretchy="false">{</mml:mo><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mo>…</mml:mo><mml:mo>,</mml:mo><mml:mi>M</mml:mi><mml:mo fence="false" stretchy="false">}</mml:mo></mml:math><tex-math id="inft228">\begin{document}$m\in\{1,\ldots,M\}$\end{document}</tex-math></alternatives></inline-formula>) and <inline-formula><alternatives><mml:math id="inf229"><mml:msub><mml:mi>c</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>m</mml:mi></mml:mrow></mml:msub></mml:math><tex-math id="inft229">\begin{document}$c_{m}$\end{document}</tex-math></alternatives></inline-formula> corresponds to the cue presented to the participant. The action sequence, denoted as <italic>α</italic> or <italic>β</italic>, consists of a sequence of selected actions <inline-formula><alternatives><mml:math id="inf230"><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>a</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:mo>…</mml:mo><mml:mo>,</mml:mo><mml:msub><mml:mi>a</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>L</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:math><tex-math id="inft230">\begin{document}$(a_{1},\ldots,a_{L})$\end{document}</tex-math></alternatives></inline-formula>, while a problem, denoted as <inline-formula><alternatives><mml:math id="inf231"><mml:mi>ϕ</mml:mi></mml:math><tex-math id="inft231">\begin{document}$\phi$\end{document}</tex-math></alternatives></inline-formula> or <inline-formula><alternatives><mml:math id="inf232"><mml:mi>ψ</mml:mi></mml:math><tex-math id="inft232">\begin{document}$\psi$\end{document}</tex-math></alternatives></inline-formula>, is represented as <inline-formula><alternatives><mml:math id="inf233"><mml:mo stretchy="false">(</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>s</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:mo>…</mml:mo><mml:mo>,</mml:mo><mml:msub><mml:mi>s</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>L</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:mo>,</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>r</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:mo>…</mml:mo><mml:mo>,</mml:mo><mml:msub><mml:mi>r</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>L</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:mo stretchy="false">)</mml:mo></mml:math><tex-math id="inft233">\begin{document}$((s_{1},\ldots,s_{L}),(r_{1},\ldots,r_{L}))$\end{document}</tex-math></alternatives></inline-formula>.</p></sec><sec id="s4-2-4-2"><title>Task solver</title><p>Before describing the encoder and decoder, we define the architecture of the task solver, which generates actions for the <inline-formula><alternatives><mml:math id="inf234"><mml:mi>M</mml:mi></mml:math><tex-math id="inft234">\begin{document}$M$\end{document}</tex-math></alternatives></inline-formula>-step MDP task. The task solver is implemented using a gated recurrent unit (GRU) (<xref ref-type="bibr" rid="bib7">Cho et al., 2014</xref>) with <inline-formula><alternatives><mml:math id="inf235"><mml:mi>Q</mml:mi></mml:math><tex-math id="inft235">\begin{document}$Q$\end{document}</tex-math></alternatives></inline-formula> cells, where <inline-formula><alternatives><mml:math id="inf236"><mml:mi>Q</mml:mi><mml:mo>=</mml:mo><mml:mn>4</mml:mn></mml:math><tex-math id="inft236">\begin{document}$Q=4$\end{document}</tex-math></alternatives></inline-formula> for the 2-step task and <inline-formula><alternatives><mml:math id="inf237"><mml:mstyle><mml:mrow><mml:mstyle displaystyle="false"><mml:mi>Q</mml:mi><mml:mo>=</mml:mo><mml:mn>8</mml:mn></mml:mstyle></mml:mrow></mml:mstyle></mml:math><tex-math id="inft237">\begin{document}$Q=8$\end{document}</tex-math></alternatives></inline-formula> for the 3-step task. At time-step <italic>t</italic>, the GRU takes as input the previous hidden state <inline-formula><alternatives><mml:math id="inf238"><mml:mstyle><mml:mrow><mml:mstyle displaystyle="false"><mml:msub><mml:mi mathvariant="bold-italic">h</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>∈</mml:mo><mml:msup><mml:mrow><mml:mi mathvariant="double-struck">R</mml:mi></mml:mrow><mml:mrow><mml:mi>Q</mml:mi></mml:mrow></mml:msup></mml:mstyle></mml:mrow></mml:mstyle></mml:math><tex-math id="inft238">\begin{document}$\boldsymbol{h}_{t-1}\in\mathbb{R}^{Q}$\end{document}</tex-math></alternatives></inline-formula>, the previous task state <inline-formula><alternatives><mml:math id="inf239"><mml:msub><mml:mi>s</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>t</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:math><tex-math id="inft239">\begin{document}$s_{t-1}$\end{document}</tex-math></alternatives></inline-formula>, the previous action <inline-formula><alternatives><mml:math id="inf240"><mml:msub><mml:mi>a</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>t</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:math><tex-math id="inft240">\begin{document}$a_{t-1}$\end{document}</tex-math></alternatives></inline-formula>, the previous reward <inline-formula><alternatives><mml:math id="inf241"><mml:msub><mml:mi>r</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>t</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:math><tex-math id="inft241">\begin{document}$r_{t-1}$\end{document}</tex-math></alternatives></inline-formula>, and the current task state <inline-formula><alternatives><mml:math id="inf242"><mml:msub><mml:mi>s</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>t</mml:mi></mml:mrow></mml:msub></mml:math><tex-math id="inft242">\begin{document}$s_{t}$\end{document}</tex-math></alternatives></inline-formula>. It then updates the hidden state as<disp-formula id="equ8"><label>(8)</label><alternatives><mml:math id="m8"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msub><mml:mi mathvariant="bold-italic">h</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi mathvariant="normal">G</mml:mi><mml:mi mathvariant="normal">R</mml:mi><mml:mi mathvariant="normal">U</mml:mi></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>s</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>t</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>a</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>t</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>r</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>t</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>s</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi mathvariant="bold-italic">h</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>t</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>;</mml:mo><mml:mi mathvariant="normal">Φ</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>,</mml:mo></mml:mstyle></mml:math><tex-math id="t8">\begin{document}$$\displaystyle  \boldsymbol{h}_{t}= \mathrm{GRU}(s_{t-1}, a_{t-1}, r_{t-1}, s_{t}, \boldsymbol{h}_{t-1}; \Phi),$$\end{document}</tex-math></alternatives></disp-formula></p><p>where <inline-formula><alternatives><mml:math id="inf243"><mml:mi mathvariant="normal">Φ</mml:mi></mml:math><tex-math id="inft243">\begin{document}$\Phi$\end{document}</tex-math></alternatives></inline-formula> represents the GRU’s weights. The updated hidden state is then used to predict the probability of selecting each action through a fully-connected feed-forward layer:<disp-formula id="equ9"><label>(9)</label><alternatives><mml:math id="m9"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msub><mml:mi mathvariant="bold-italic">v</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mi mathvariant="bold-italic">W</mml:mi><mml:msub><mml:mi mathvariant="bold-italic">h</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo></mml:mstyle></mml:math><tex-math id="t9">\begin{document}$$\displaystyle  \boldsymbol{v}_{t}= \boldsymbol{W}\boldsymbol{h}_{t},$$\end{document}</tex-math></alternatives></disp-formula></p><p>where <inline-formula><alternatives><mml:math id="inf244"><mml:mstyle><mml:mrow><mml:mstyle displaystyle="false"><mml:mstyle><mml:msub><mml:mi mathvariant="bold-italic">v</mml:mi><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub></mml:mstyle></mml:mstyle></mml:mrow></mml:mstyle></mml:math><tex-math id="inft244">\begin{document}$ \boldsymbol{v}_{t}$\end{document}</tex-math></alternatives></inline-formula> represents the logit scores for each action (unnormalized probabilities), and <inline-formula><alternatives><mml:math id="inf245"><mml:mstyle><mml:mrow><mml:mstyle displaystyle="false"><mml:mi mathvariant="bold-italic">W</mml:mi><mml:mo>∈</mml:mo><mml:msup><mml:mrow><mml:mi mathvariant="double-struck">R</mml:mi></mml:mrow><mml:mrow><mml:mi>K</mml:mi><mml:mo>×</mml:mo><mml:mi>Q</mml:mi></mml:mrow></mml:msup></mml:mstyle></mml:mrow></mml:mstyle></mml:math><tex-math id="inft245">\begin{document}$\boldsymbol{W}\in\mathbb{R}^{K\times Q}$\end{document}</tex-math></alternatives></inline-formula> is the weight matrix. The probabilities of each action are computed using a softmax layer:<disp-formula id="equ10"><label>(10)</label><alternatives><mml:math id="m10"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>π</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>a</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:msub><mml:mi>C</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>k</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mfrac><mml:msup><mml:mi>e</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mo stretchy="false">[</mml:mo><mml:msub><mml:mi mathvariant="bold-italic">v</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:msub><mml:mo stretchy="false">]</mml:mo><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>k</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:msup><mml:mrow><mml:munder><mml:mo>∑</mml:mo><mml:mrow class="MJX-TeXAtom-ORD"><mml:msup><mml:mi>k</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi class="MJX-variant" mathvariant="normal">′</mml:mi></mml:mrow></mml:msup><mml:mo>=</mml:mo><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mo>…</mml:mo><mml:mo>,</mml:mo><mml:mi>K</mml:mi></mml:mrow></mml:munder><mml:msup><mml:mi>e</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mo stretchy="false">[</mml:mo><mml:msub><mml:mi mathvariant="bold-italic">v</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:msub><mml:mo stretchy="false">]</mml:mo><mml:mrow class="MJX-TeXAtom-ORD"><mml:msup><mml:mi>k</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi class="MJX-variant" mathvariant="normal">′</mml:mi></mml:mrow></mml:msup></mml:mrow></mml:msub></mml:mrow></mml:msup></mml:mrow></mml:mfrac><mml:mo>,</mml:mo></mml:mstyle></mml:math><tex-math id="t10">\begin{document}$$\displaystyle  \pi(a_{t}=C_{k}) = \frac{e^{[\boldsymbol{v}_{t}]_{k} }}{\sum_{k^{\prime}=1, \ldots, K}e^{[\boldsymbol{v}_{t}]_{k^{\prime}}}},$$\end{document}</tex-math></alternatives></disp-formula></p><p>where <inline-formula><alternatives><mml:math id="inf246"><mml:mi>π</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>a</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:msub><mml:mi>C</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>k</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:math><tex-math id="inft246">\begin{document}$\pi(a_{t}=C_{k})$\end{document}</tex-math></alternatives></inline-formula> represents the probability of selecting action <inline-formula><alternatives><mml:math id="inf247"><mml:msub><mml:mi>C</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>k</mml:mi></mml:mrow></mml:msub></mml:math><tex-math id="inft247">\begin{document}$C_{k}$\end{document}</tex-math></alternatives></inline-formula> at time <italic>t</italic>, and <inline-formula><alternatives><mml:math id="inf248"><mml:mstyle><mml:mrow><mml:mstyle displaystyle="false"><mml:msub><mml:mrow><mml:mo>[</mml:mo><mml:msub><mml:mi mathvariant="bold-italic">v</mml:mi><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>]</mml:mo></mml:mrow><mml:mi>i</mml:mi></mml:msub></mml:mstyle></mml:mrow></mml:mstyle></mml:math><tex-math id="inft248">\begin{document}$\left[ \boldsymbol{v}_{t}\right]_i$\end{document}</tex-math></alternatives></inline-formula> denotes the <inline-formula><alternatives><mml:math id="inf249"><mml:mi>i</mml:mi></mml:math><tex-math id="inft249">\begin{document}$i$\end{document}</tex-math></alternatives></inline-formula>-th element of <inline-formula><alternatives><mml:math id="inf250"><mml:mstyle><mml:mrow><mml:mstyle displaystyle="false"><mml:msub><mml:mi mathvariant="bold-italic">v</mml:mi><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub></mml:mstyle></mml:mrow></mml:mstyle></mml:math><tex-math id="inft250">\begin{document}$\boldsymbol{v}_{t}$\end{document}</tex-math></alternatives></inline-formula>.</p><p>For input encoding, we used a 1-of-K scheme. The step of the MDP task is encoded as [1, 0, 0] for step 1, [0, 1, 0] for step 2, and [0, 0, 1] for step 3. Each task state <inline-formula><alternatives><mml:math id="inf251"><mml:msub><mml:mi>s</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>m</mml:mi></mml:mrow></mml:msub></mml:math><tex-math id="inft251">\begin{document}$s_{m}$\end{document}</tex-math></alternatives></inline-formula> is represented as [1, 0] or [0, 1] to distinguish the two state cues at each step. The participant’s action is encoded as <inline-formula><alternatives><mml:math id="inf252"><mml:mstyle><mml:mrow><mml:mstyle displaystyle="false"><mml:msub><mml:mi>C</mml:mi><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>:</mml:mo><mml:mrow><mml:mo>[</mml:mo><mml:mrow><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mn>0</mml:mn></mml:mrow><mml:mo>]</mml:mo></mml:mrow></mml:mstyle></mml:mrow></mml:mstyle></mml:math><tex-math id="inft252">\begin{document}$C_{1}:\left[1,0\right]$\end{document}</tex-math></alternatives></inline-formula> or <inline-formula><alternatives><mml:math id="inf253"><mml:mstyle><mml:mrow><mml:mstyle displaystyle="false"><mml:msub><mml:mi>C</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:mo>:</mml:mo><mml:mrow><mml:mo>[</mml:mo><mml:mrow><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mo>]</mml:mo></mml:mrow></mml:mstyle></mml:mrow></mml:mstyle></mml:math><tex-math id="inft253">\begin{document}$C_{2}:\left[0,1\right] $\end{document}</tex-math></alternatives></inline-formula>, while the reward is represented as 0: [1, 0] or 1: [0, 1]. These encodings are concatenated to form input sequences.</p><p>The task solver <inline-formula><alternatives><mml:math id="inf254"><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi mathvariant="normal">T</mml:mi><mml:mi mathvariant="normal">S</mml:mi></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>ψ</mml:mi><mml:mo>;</mml:mo><mml:msub><mml:mi mathvariant="normal">Θ</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi mathvariant="normal">T</mml:mi><mml:mi mathvariant="normal">S</mml:mi></mml:mrow></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:math><tex-math id="inft254">\begin{document}$\mathrm{TS}(\psi;\Theta_{\mathrm{TS}})$\end{document}</tex-math></alternatives></inline-formula> generates a sequence of predicted action probabilities <inline-formula><alternatives><mml:math id="inf255"><mml:mo fence="false" stretchy="false">{</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mi>π</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>a</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:msub><mml:mi>C</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:mo>,</mml:mo><mml:mo>…</mml:mo><mml:mo>,</mml:mo><mml:mi>π</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>a</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:msub><mml:mi>C</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>K</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:mo stretchy="false">)</mml:mo><mml:msubsup><mml:mo fence="false" stretchy="false">}</mml:mo><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>t</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>L</mml:mi></mml:mrow></mml:msubsup></mml:math><tex-math id="inft255">\begin{document}$\{(\pi(a_{t}=C_{1}),\ldots,\pi(a_{t}=C_{K}))\}_{t=1}^{L}$\end{document}</tex-math></alternatives></inline-formula>, using the GRU, the fully-connected layer <bold><italic>W</italic></bold>, and the softmax layer. The problem <inline-formula><alternatives><mml:math id="inf256"><mml:mi>ψ</mml:mi></mml:math><tex-math id="inft256">\begin{document}$\psi$\end{document}</tex-math></alternatives></inline-formula> defines the MDP environment, specifying state transitions and reward outcomes in response to selected action.</p><p>To evaluate prediction accuracy, the loss function <inline-formula><alternatives><mml:math id="inf257"><mml:mi>O</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>β</mml:mi><mml:mo>,</mml:mo><mml:mrow class="MJX-TeXAtom-ORD"><mml:mover><mml:mi>β</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:math><tex-math id="inft257">\begin{document}$O(\beta,\hat{\beta})$\end{document}</tex-math></alternatives></inline-formula>, defined in <xref ref-type="disp-formula" rid="equ4">Equation 4</xref>, compares human-performed action <inline-formula><alternatives><mml:math id="inf258"><mml:mo fence="false" stretchy="false">{</mml:mo><mml:mi>β</mml:mi><mml:mo>,</mml:mo><mml:mi>ψ</mml:mi><mml:mo fence="false" stretchy="false">}</mml:mo></mml:math><tex-math id="inft258">\begin{document}$\{\beta,\psi\}$\end{document}</tex-math></alternatives></inline-formula> with those predicted by the task solver, <inline-formula><alternatives><mml:math id="inf259"><mml:mo fence="false" stretchy="false">{</mml:mo><mml:mrow class="MJX-TeXAtom-ORD"><mml:mover><mml:mi>β</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mo>,</mml:mo><mml:mi>ψ</mml:mi><mml:mo fence="false" stretchy="false">}</mml:mo></mml:math><tex-math id="inft259">\begin{document}$\{\hat{\beta},\psi\}$\end{document}</tex-math></alternatives></inline-formula>. Notably, the problem <inline-formula><alternatives><mml:math id="inf260"><mml:mi>ψ</mml:mi></mml:math><tex-math id="inft260">\begin{document}$\psi$\end{document}</tex-math></alternatives></inline-formula> is not executed with the task solver; instead, the task solver predicts action probabilities based on the same task state and reward history as in the human behavioral data.</p></sec><sec id="s4-2-4-3"><title>Encoder and decoder</title><p>The encoder <inline-formula><alternatives><mml:math id="inf261"><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi mathvariant="normal">E</mml:mi><mml:mi mathvariant="normal">N</mml:mi><mml:mi mathvariant="normal">C</mml:mi></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>α</mml:mi><mml:mo>,</mml:mo><mml:mi>ϕ</mml:mi><mml:mo>;</mml:mo><mml:msub><mml:mi mathvariant="normal">Θ</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi mathvariant="normal">E</mml:mi><mml:mi mathvariant="normal">N</mml:mi><mml:mi mathvariant="normal">C</mml:mi></mml:mrow></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:math><tex-math id="inft261">\begin{document}$\mathrm{ENC}(\alpha,\phi;\Theta_{\mathrm{ENC}})$\end{document}</tex-math></alternatives></inline-formula> extracts an individual latent representation <inline-formula><alternatives><mml:math id="inf262"><mml:mstyle><mml:mrow><mml:mstyle displaystyle="false"><mml:mi mathvariant="bold-italic">z</mml:mi></mml:mstyle></mml:mrow></mml:mstyle></mml:math><tex-math id="inft262">\begin{document}$\boldsymbol{z}$\end{document}</tex-math></alternatives></inline-formula> from a sequence of actions <italic>α</italic> corresponding to a given environment <inline-formula><alternatives><mml:math id="inf263"><mml:mi>ϕ</mml:mi></mml:math><tex-math id="inft263">\begin{document}$\phi$\end{document}</tex-math></alternatives></inline-formula>. The first module of the encoder is a GRU, similar to the task solver, with <inline-formula><alternatives><mml:math id="inf264"><mml:mi>R</mml:mi><mml:mo>=</mml:mo><mml:mn>32</mml:mn></mml:math><tex-math id="inft264">\begin{document}$R=32$\end{document}</tex-math></alternatives></inline-formula> cells. The final hidden state <inline-formula><alternatives><mml:math id="inf265"><mml:mstyle><mml:mrow><mml:mstyle displaystyle="false"><mml:msub><mml:mi mathvariant="bold-italic">h</mml:mi><mml:mrow><mml:mi>L</mml:mi></mml:mrow></mml:msub><mml:mo>∈</mml:mo><mml:msup><mml:mrow><mml:mi mathvariant="double-struck">R</mml:mi></mml:mrow><mml:mrow><mml:mi>R</mml:mi></mml:mrow></mml:msup></mml:mstyle></mml:mrow></mml:mstyle></mml:math><tex-math id="inft265">\begin{document}$\boldsymbol{h}_{L}\in\mathbb{R}^{R}$\end{document}</tex-math></alternatives></inline-formula> serves as the basis for computing the individual latent representation <inline-formula><alternatives><mml:math id="inf266"><mml:mstyle><mml:mrow><mml:mstyle displaystyle="false"><mml:mi mathvariant="bold-italic">z</mml:mi><mml:mo>∈</mml:mo><mml:msup><mml:mrow><mml:mi mathvariant="double-struck">R</mml:mi></mml:mrow><mml:mrow><mml:mi>M</mml:mi></mml:mrow></mml:msup></mml:mstyle></mml:mrow></mml:mstyle></mml:math><tex-math id="inft266">\begin{document}$\boldsymbol{z}\in\mathbb{R}^{M}$\end{document}</tex-math></alternatives></inline-formula> using a fully-connected feed-forward network with four layers <inline-formula><alternatives><mml:math id="inf267"><mml:mi>d</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mo>⋅</mml:mo><mml:mo stretchy="false">)</mml:mo></mml:math><tex-math id="inft267">\begin{document}$d(\cdot)$\end{document}</tex-math></alternatives></inline-formula> as <inline-formula><alternatives><mml:math id="inf268"><mml:mstyle><mml:mrow><mml:mstyle displaystyle="false"><mml:mi mathvariant="bold-italic">z</mml:mi><mml:mo>=</mml:mo><mml:mi>d</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi mathvariant="bold-italic">h</mml:mi><mml:mrow><mml:mi>L</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mstyle></mml:mrow></mml:mstyle></mml:math><tex-math id="inft268">\begin{document}$\boldsymbol{z}=d(\boldsymbol{h}_{L})$\end{document}</tex-math></alternatives></inline-formula>.</p><p>The decoder takes the individual latent representation <inline-formula><alternatives><mml:math id="inf269"><mml:mstyle><mml:mrow><mml:mstyle displaystyle="false"><mml:mi mathvariant="bold-italic">z</mml:mi></mml:mstyle></mml:mrow></mml:mstyle></mml:math><tex-math id="inft269">\begin{document}$\boldsymbol{z}$\end{document}</tex-math></alternatives></inline-formula> as input and generates the weights for the task solver by <inline-formula><alternatives><mml:math id="inf270"><mml:mstyle><mml:mrow><mml:mstyle displaystyle="false"><mml:msub><mml:mi mathvariant="normal">Θ</mml:mi><mml:mrow><mml:mrow><mml:mi mathvariant="normal">T</mml:mi><mml:mi mathvariant="normal">S</mml:mi></mml:mrow></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mrow><mml:mi mathvariant="normal">D</mml:mi><mml:mi mathvariant="normal">E</mml:mi><mml:mi mathvariant="normal">C</mml:mi></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi mathvariant="bold-italic">z</mml:mi><mml:mo>;</mml:mo><mml:msub><mml:mi mathvariant="normal">Θ</mml:mi><mml:mrow><mml:mrow><mml:mi mathvariant="normal">D</mml:mi><mml:mi mathvariant="normal">E</mml:mi><mml:mi mathvariant="normal">C</mml:mi></mml:mrow></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mstyle></mml:mrow></mml:mstyle></mml:math><tex-math id="inft270">\begin{document}$\Theta_{\mathrm{TS}}=\mathrm{DEC}(\boldsymbol{z};\Theta_{\mathrm{DEC}})$\end{document}</tex-math></alternatives></inline-formula>. The decoder is implemented as a single-layer linear network.</p></sec></sec></sec><sec id="s4-3"><title>Experiment on MNIST task</title><p>This section describes the specific models used for individuality transfer in handwritten digit recognition (MNIST) task.</p><sec id="s4-3-1"><title>Task</title><p>The dataset used in this experiment was originally collected and published by <xref ref-type="bibr" rid="bib35">Rafiei et al., 2024</xref>. In this task, participants were presented with a stimulus image depicting a handwritten digit and were required to respond by pressing the corresponding number key, as illustrated in <xref ref-type="fig" rid="fig1">Figure 1</xref>. For further details regarding the task design and data collection, refer to <xref ref-type="bibr" rid="bib35">Rafiei et al., 2024</xref>.</p></sec><sec id="s4-3-2"><title>EIDT model</title><sec id="s4-3-2-1"><title>Data representation</title><p>An action sequence, denoted as <italic>α</italic> or <italic>β</italic>, consists of a single action <inline-formula><alternatives><mml:math id="inf271"><mml:mi>a</mml:mi></mml:math><tex-math id="inft271">\begin{document}$a$\end{document}</tex-math></alternatives></inline-formula> and its corresponding response time <italic>b</italic>. The associated problem, represented as <inline-formula><alternatives><mml:math id="inf272"><mml:mi>ϕ</mml:mi></mml:math><tex-math id="inft272">\begin{document}$\phi$\end{document}</tex-math></alternatives></inline-formula> or <inline-formula><alternatives><mml:math id="inf273"><mml:mi>ψ</mml:mi></mml:math><tex-math id="inft273">\begin{document}$\psi$\end{document}</tex-math></alternatives></inline-formula>, corresponds to a stimulus image. The action <italic>a</italic> is selected from a set <inline-formula><alternatives><mml:math id="inf274"><mml:mo fence="false" stretchy="false">{</mml:mo><mml:msub><mml:mi>C</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:mo>…</mml:mo><mml:msub><mml:mi>C</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>K</mml:mi></mml:mrow></mml:msub><mml:mo fence="false" stretchy="false">}</mml:mo></mml:math><tex-math id="inft274">\begin{document}$\{C_{1},\ldots C_{K}\}$\end{document}</tex-math></alternatives></inline-formula>. Since the task involves recognizing digits ranging from 0 to 9, the number of possible actions is <inline-formula><alternatives><mml:math id="inf275"><mml:mi>K</mml:mi><mml:mo>=</mml:mo><mml:mn>10</mml:mn></mml:math><tex-math id="inft275">\begin{document}$K=10$\end{document}</tex-math></alternatives></inline-formula>. The stimulus image, <inline-formula><alternatives><mml:math id="inf276"><mml:mi>ϕ</mml:mi></mml:math><tex-math id="inft276">\begin{document}$\phi$\end{document}</tex-math></alternatives></inline-formula> or <inline-formula><alternatives><mml:math id="inf277"><mml:mi>ψ</mml:mi></mml:math><tex-math id="inft277">\begin{document}$\psi$\end{document}</tex-math></alternatives></inline-formula>, is an image of size <inline-formula><alternatives><mml:math id="inf278"><mml:mi>H</mml:mi><mml:mo>×</mml:mo><mml:mi>W</mml:mi></mml:math><tex-math id="inft278">\begin{document}$H\times W$\end{document}</tex-math></alternatives></inline-formula>. In this experiment, we adopted the same resolution as (<xref ref-type="bibr" rid="bib35">Rafiei et al., 2024</xref>), setting <inline-formula><alternatives><mml:math id="inf279"><mml:mi>H</mml:mi><mml:mo>=</mml:mo><mml:mi>W</mml:mi><mml:mo>=</mml:mo><mml:mn>227</mml:mn></mml:math><tex-math id="inft279">\begin{document}$H=W=227$\end{document}</tex-math></alternatives></inline-formula>.</p></sec><sec id="s4-3-2-2"><title>Task solver</title><p>The task solver for the handwritten digit recognition task is based on the model proposed by <xref ref-type="bibr" rid="bib35">Rafiei et al., 2024</xref>. Their model consists of a CNN and an evidence accumulation module. However, since their model represents average human behavior and does not account for individuality differences, we replace the accumulation module with a GRU (<xref ref-type="bibr" rid="bib6">Cheng et al., 2024</xref>) to capture individuality. The CNN module processes the input image and produces an evidence vector <inline-formula><alternatives><mml:math id="inf280"><mml:mstyle><mml:mrow><mml:mstyle displaystyle="false"><mml:mi mathvariant="bold-italic">e</mml:mi><mml:mo>=</mml:mo><mml:mrow><mml:mi mathvariant="normal">C</mml:mi><mml:mi mathvariant="normal">N</mml:mi><mml:mi mathvariant="normal">N</mml:mi></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>ψ</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mstyle></mml:mrow></mml:mstyle></mml:math><tex-math id="inft280">\begin{document}$\boldsymbol{e}=\mathrm{CNN}(\psi)$\end{document}</tex-math></alternatives></inline-formula>, where <inline-formula><alternatives><mml:math id="inf281"><mml:mstyle><mml:mrow><mml:mstyle displaystyle="false"><mml:mi mathvariant="bold-italic">e</mml:mi><mml:mo>∈</mml:mo><mml:msup><mml:mrow><mml:mi mathvariant="double-struck">R</mml:mi></mml:mrow><mml:mrow><mml:mi>K</mml:mi></mml:mrow></mml:msup></mml:mstyle></mml:mrow></mml:mstyle></mml:math><tex-math id="inft281">\begin{document}$\boldsymbol{e}\in\mathbb{R}^{K}$\end{document}</tex-math></alternatives></inline-formula> and <inline-formula><alternatives><mml:math id="inf282"><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi mathvariant="normal">C</mml:mi><mml:mi mathvariant="normal">N</mml:mi><mml:mi mathvariant="normal">N</mml:mi></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mo>⋅</mml:mo><mml:mo stretchy="false">)</mml:mo></mml:math><tex-math id="inft282">\begin{document}$\mathrm{CNN}(\cdot)$\end{document}</tex-math></alternatives></inline-formula> is based on the AlexNet architecture (<xref ref-type="bibr" rid="bib27">Krizhevsky et al., 2012</xref>). The weights of the CNN are sampled from a Bayesian neural network (BNN), introducing stochasticity in the output. This stochasticity enables the models to generate human-like, probabilistic decisions.</p><p>The stimulus image is fed into the CNN <italic><bold>S</bold></italic> times, generating <bold><italic>S</italic></bold> evidence distributions <inline-formula><alternatives><mml:math id="inf283"><mml:mrow><mml:msub><mml:mi mathvariant="bold-italic">𝒆</mml:mi><mml:mi>t</mml:mi></mml:msub><mml:mo>∈</mml:mo><mml:msup><mml:mi>ℝ</mml:mi><mml:mi>K</mml:mi></mml:msup></mml:mrow></mml:math><tex-math id="inft283">\begin{document}$\boldsymbol{e}_{t}\in\mathbb{R}^{K}$\end{document}</tex-math></alternatives></inline-formula> at each time step <inline-formula><alternatives><mml:math id="inf284"><mml:mi>t</mml:mi><mml:mo>=</mml:mo><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:mo>…</mml:mo><mml:mo>,</mml:mo><mml:mi>S</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:math><tex-math id="inft284">\begin{document}$t=0,\ldots,S-1$\end{document}</tex-math></alternatives></inline-formula>. In this study, we set <inline-formula><alternatives><mml:math id="inf285"><mml:mstyle><mml:mrow><mml:mstyle displaystyle="false"><mml:mi>S</mml:mi><mml:mo>=</mml:mo><mml:mn>16</mml:mn></mml:mstyle></mml:mrow></mml:mstyle></mml:math><tex-math id="inft285">\begin{document}$S=16$\end{document}</tex-math></alternatives></inline-formula> to match the maximum response time, as described later. Since the CNN weights are stochastically sampled from the BNN, the CNN’s output varies even when the same image is input multiple times. To model individuality in decision-making, we introduce a GRU with <inline-formula><alternatives><mml:math id="inf286"><mml:mi>Q</mml:mi></mml:math><tex-math id="inft286">\begin{document}$Q$\end{document}</tex-math></alternatives></inline-formula> cells (<inline-formula><alternatives><mml:math id="inf287"><mml:mi>Q</mml:mi><mml:mo>=</mml:mo><mml:mn>4</mml:mn></mml:math><tex-math id="inft287">\begin{document}$Q=4$\end{document}</tex-math></alternatives></inline-formula> in our setup). The GRU receives as input the previous hidden state <inline-formula><alternatives><mml:math id="inf288"><mml:mstyle><mml:mrow><mml:mstyle displaystyle="false"><mml:msub><mml:mi mathvariant="bold-italic">h</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>∈</mml:mo><mml:msup><mml:mrow><mml:mi mathvariant="double-struck">R</mml:mi></mml:mrow><mml:mrow><mml:mi>Q</mml:mi></mml:mrow></mml:msup></mml:mstyle></mml:mrow></mml:mstyle></mml:math><tex-math id="inft288">\begin{document}$\boldsymbol{h}_{t-1}\in\mathbb{R}^{Q}$\end{document}</tex-math></alternatives></inline-formula> and the current evidence <inline-formula><alternatives><mml:math id="inf289"><mml:mstyle><mml:mrow><mml:mstyle displaystyle="false"><mml:msub><mml:mi mathvariant="bold-italic">e</mml:mi><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub></mml:mstyle></mml:mrow></mml:mstyle></mml:math><tex-math id="inft289">\begin{document}$\boldsymbol{e}_{t}$\end{document}</tex-math></alternatives></inline-formula>, updating its hidden state as<disp-formula id="equ11"><label>(11)</label><alternatives><mml:math id="m11"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msub><mml:mi mathvariant="bold-italic">h</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi mathvariant="normal">G</mml:mi><mml:mi mathvariant="normal">R</mml:mi><mml:mi mathvariant="normal">U</mml:mi></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi mathvariant="bold-italic">e</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi mathvariant="bold-italic">h</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>t</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>;</mml:mo><mml:mi mathvariant="normal">Φ</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>,</mml:mo></mml:mstyle></mml:math><tex-math id="t11">\begin{document}$$\displaystyle  \boldsymbol{h}_{t}= \mathrm{GRU}(\boldsymbol{e}_{t}, \boldsymbol{h}_{t-1}; \Phi),$$\end{document}</tex-math></alternatives></disp-formula></p><p>where <inline-formula><alternatives><mml:math id="inf290"><mml:mi mathvariant="normal">Φ</mml:mi></mml:math><tex-math id="inft290">\begin{document}$\Phi$\end{document}</tex-math></alternatives></inline-formula> represents the GRU’s network weights. The updated hidden state is passed through a dense layer (as defined in <xref ref-type="disp-formula" rid="equ9">Equation 9</xref>) and a softmax layer (as defined in <xref ref-type="disp-formula" rid="equ10">Equation 10</xref>) to generate the probability distribution over possible digit classifications <inline-formula><alternatives><mml:math id="inf291"><mml:mo stretchy="false">[</mml:mo><mml:msub><mml:mi>P</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>C</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:mo>,</mml:mo><mml:mo>…</mml:mo><mml:mo>,</mml:mo><mml:msub><mml:mi>P</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>C</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>K</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:mo stretchy="false">]</mml:mo></mml:math><tex-math id="inft291">\begin{document}$[P_{t}(C_{1}),\ldots,P_{t}(C_{K})]$\end{document}</tex-math></alternatives></inline-formula> at each time step <italic>t</italic>.</p><p>To evaluate the prediction error, we compare the action sequences generated by human participants <inline-formula><alternatives><mml:math id="inf292"><mml:mo fence="false" stretchy="false">{</mml:mo><mml:mi>β</mml:mi><mml:mo>,</mml:mo><mml:mi>ψ</mml:mi><mml:mo fence="false" stretchy="false">}</mml:mo></mml:math><tex-math id="inft292">\begin{document}$\{\beta,\psi\}$\end{document}</tex-math></alternatives></inline-formula> with those predicted by the task solver <inline-formula><alternatives><mml:math id="inf293"><mml:mo fence="false" stretchy="false">{</mml:mo><mml:mrow class="MJX-TeXAtom-ORD"><mml:mover><mml:mi>β</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mo>,</mml:mo><mml:mi>ψ</mml:mi><mml:mo fence="false" stretchy="false">}</mml:mo></mml:math><tex-math id="inft293">\begin{document}$\{\hat{\beta},\psi\}$\end{document}</tex-math></alternatives></inline-formula>, incorporating response times into these analyses. The actual response time <italic>b</italic> is converted into an integer time step <inline-formula><alternatives><mml:math id="inf294"><mml:mrow class="MJX-TeXAtom-ORD"><mml:mover><mml:mi>t</mml:mi><mml:mo stretchy="false">~</mml:mo></mml:mover></mml:mrow></mml:math><tex-math id="inft294">\begin{document}$\tilde{t}$\end{document}</tex-math></alternatives></inline-formula> using the formula: <inline-formula><alternatives><mml:math id="inf295"><mml:mrow class="MJX-TeXAtom-ORD"><mml:mover><mml:mi>t</mml:mi><mml:mo stretchy="false">~</mml:mo></mml:mover></mml:mrow><mml:mo>=</mml:mo><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi mathvariant="normal">r</mml:mi><mml:mi mathvariant="normal">o</mml:mi><mml:mi mathvariant="normal">u</mml:mi><mml:mi mathvariant="normal">n</mml:mi><mml:mi mathvariant="normal">d</mml:mi></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mn>10</mml:mn><mml:mi>b</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:math><tex-math id="inft295">\begin{document}$\tilde{t}=\mathrm{round}(10b)$\end{document}</tex-math></alternatives></inline-formula>. For example, a response time of <inline-formula><alternatives><mml:math id="inf296"><mml:mi>b</mml:mi><mml:mo>=</mml:mo><mml:mn>0.765</mml:mn></mml:math><tex-math id="inft296">\begin{document}$b=0.765$\end{document}</tex-math></alternatives></inline-formula> s is converted to <inline-formula><alternatives><mml:math id="inf297"><mml:mrow class="MJX-TeXAtom-ORD"><mml:mover><mml:mi>t</mml:mi><mml:mo stretchy="false">~</mml:mo></mml:mover></mml:mrow><mml:mo>=</mml:mo><mml:mn>8</mml:mn></mml:math><tex-math id="inft297">\begin{document}$\tilde{t}=8$\end{document}</tex-math></alternatives></inline-formula>. The likelihood of observed decision is then calculated as <inline-formula><alternatives><mml:math id="inf298"><mml:msub><mml:mi>P</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mrow class="MJX-TeXAtom-ORD"><mml:mover><mml:mi>t</mml:mi><mml:mo stretchy="false">~</mml:mo></mml:mover></mml:mrow></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>a</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:math><tex-math id="inft298">\begin{document}$P_{\tilde{t}}(a)$\end{document}</tex-math></alternatives></inline-formula>, where <italic>a</italic> is the actual digit chosen by the participant.</p><p>In this task solver, the CNN (driven by BNN) models a visual processing system, while the RNN represents the decision-making system. We assume that the visual system (implemented by CNN and BNN) is shared across all individuals, whereas the decision-making system (implemented by RNN) captures individual differences. Based on this assumption, the CNN and BNN are pretrained using the MNIST dataset (<xref ref-type="bibr" rid="bib27">Krizhevsky et al., 2012</xref>), and their weight distributions are fixed across individuals. The pretraining procedure followed the original methodology (<xref ref-type="bibr" rid="bib35">Rafiei et al., 2024</xref>).</p></sec><sec id="s4-3-2-3"><title>Encoder and decoder</title><p>Since each action sequence contains only a single action, it does not form a true ‘sequence’. This makes it challenging to extract individuality from a single data point. To address this, the encoder takes a set of single action sequences as input rather than a single sequence. Specifically, the encoder <inline-formula><alternatives><mml:math id="inf299"><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi mathvariant="normal">E</mml:mi><mml:mi mathvariant="normal">N</mml:mi><mml:mi mathvariant="normal">C</mml:mi></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mo fence="false" stretchy="false">{</mml:mo><mml:msub><mml:mi>α</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>u</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>ϕ</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>u</mml:mi></mml:mrow></mml:msub><mml:msubsup><mml:mo fence="false" stretchy="false">}</mml:mo><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>u</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>U</mml:mi></mml:mrow></mml:msubsup><mml:mo>;</mml:mo><mml:msub><mml:mi mathvariant="normal">Θ</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi mathvariant="normal">E</mml:mi><mml:mi mathvariant="normal">N</mml:mi><mml:mi mathvariant="normal">C</mml:mi></mml:mrow></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:math><tex-math id="inft299">\begin{document}$\mathrm{ENC}(\{\alpha_{u},\phi_{u}\}_{u=1}^{U};\Theta_{\mathrm{ENC}})$\end{document}</tex-math></alternatives></inline-formula> extracts the individual latent representation <inline-formula><alternatives><mml:math id="inf300"><mml:mstyle><mml:mrow><mml:mstyle displaystyle="false"><mml:mi mathvariant="bold-italic">z</mml:mi></mml:mstyle></mml:mrow></mml:mstyle></mml:math><tex-math id="inft300">\begin{document}$\boldsymbol{z}$\end{document}</tex-math></alternatives></inline-formula> from <italic><bold>U</bold></italic> sets of stimulus images <inline-formula><alternatives><mml:math id="inf301"><mml:msub><mml:mi>ϕ</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>u</mml:mi></mml:mrow></mml:msub></mml:math><tex-math id="inft301">\begin{document}$\phi_{u}$\end{document}</tex-math></alternatives></inline-formula> and their corresponding responses <inline-formula><alternatives><mml:math id="inf302"><mml:msub><mml:mi>α</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>u</mml:mi></mml:mrow></mml:msub></mml:math><tex-math id="inft302">\begin{document}$\alpha_{u}$\end{document}</tex-math></alternatives></inline-formula>, where <inline-formula><alternatives><mml:math id="inf303"><mml:mi>u</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mo>…</mml:mo><mml:mo>,</mml:mo><mml:mi>U</mml:mi></mml:math><tex-math id="inft303">\begin{document}$u=1,\ldots,U$\end{document}</tex-math></alternatives></inline-formula>. Here, <inline-formula><alternatives><mml:math id="inf304"><mml:msub><mml:mi>ϕ</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>u</mml:mi></mml:mrow></mml:msub></mml:math><tex-math id="inft304">\begin{document}$\phi_{u}$\end{document}</tex-math></alternatives></inline-formula> represent the stimulus presented in the <italic>u</italic>-th trial, and <inline-formula><alternatives><mml:math id="inf305"><mml:msub><mml:mi>α</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>u</mml:mi></mml:mrow></mml:msub></mml:math><tex-math id="inft305">\begin{document}$\alpha_{u}$\end{document}</tex-math></alternatives></inline-formula> represents the corresponding response. The number of action sequences <italic><bold>U</bold></italic> corresponds to the number of samples available for each individual in the dataset. Since the outputs for these action sequences are just averaged, <italic><bold>U</bold></italic> can be adjusted flexibly.</p><p>The encoder architecture consists of a single CNN module, a single GRU, and a fully connected feed-forward network. The CNN module is identical to the one used in the task solver. Given an input <inline-formula><alternatives><mml:math id="inf306"><mml:msub><mml:mi>ϕ</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>u</mml:mi></mml:mrow></mml:msub></mml:math><tex-math id="inft306">\begin{document}$\phi_{u}$\end{document}</tex-math></alternatives></inline-formula>, let <inline-formula><alternatives><mml:math id="inf307"><mml:mstyle><mml:mrow><mml:mstyle displaystyle="false"><mml:msub><mml:mi mathvariant="bold-italic">e</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mo>,</mml:mo><mml:mi>u</mml:mi></mml:mrow></mml:msub></mml:mstyle></mml:mrow></mml:mstyle></mml:math><tex-math id="inft307">\begin{document}$\boldsymbol{e}_{t,u}$\end{document}</tex-math></alternatives></inline-formula> represent the evidence output from the CNN at time step <italic>t</italic>. The GRU, which consists of <bold><italic>R</italic></bold> cells (<inline-formula><alternatives><mml:math id="inf308"><mml:mi>R</mml:mi><mml:mo>=</mml:mo><mml:mn>16</mml:mn></mml:math><tex-math id="inft308">\begin{document}$R=16$\end{document}</tex-math></alternatives></inline-formula> in our setup), updates its hidden state based on the previous state, the current CNN evidence, and an encoding of the response action by<disp-formula id="equ12"><label>(12)</label><alternatives><mml:math id="m12"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msub><mml:mi mathvariant="bold-italic">h</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>t</mml:mi><mml:mo>,</mml:mo><mml:mi>u</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi mathvariant="normal">G</mml:mi><mml:mi mathvariant="normal">R</mml:mi><mml:mi mathvariant="normal">U</mml:mi></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi mathvariant="bold-italic">e</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>t</mml:mi><mml:mo>,</mml:mo><mml:mi>u</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:mi>k</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>a</mml:mi><mml:mo>,</mml:mo><mml:mi>t</mml:mi><mml:mo>,</mml:mo><mml:mrow class="MJX-TeXAtom-ORD"><mml:mover><mml:mi>t</mml:mi><mml:mo stretchy="false">~</mml:mo></mml:mover></mml:mrow><mml:mo stretchy="false">)</mml:mo><mml:mo>,</mml:mo><mml:msub><mml:mi mathvariant="bold-italic">h</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>t</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mi>u</mml:mi></mml:mrow></mml:msub><mml:mo>;</mml:mo><mml:mi mathvariant="normal">Ψ</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>,</mml:mo></mml:mstyle></mml:math><tex-math id="t12">\begin{document}$$\displaystyle  \boldsymbol{h}_{t,u}= \mathrm{GRU}(\boldsymbol{e}_{t,u}, k(a, t, \tilde{t}), \boldsymbol{h}_{t-1,u}; \Psi),$$\end{document}</tex-math></alternatives></disp-formula></p><p>where <inline-formula><alternatives><mml:math id="inf309"><mml:mi mathvariant="normal">Ψ</mml:mi></mml:math><tex-math id="inft309">\begin{document}$\Psi$\end{document}</tex-math></alternatives></inline-formula> represents the network weights. The function <inline-formula><alternatives><mml:math id="inf310"><mml:mi>k</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>a</mml:mi><mml:mo>,</mml:mo><mml:mi>t</mml:mi><mml:mo>,</mml:mo><mml:mrow class="MJX-TeXAtom-ORD"><mml:mover><mml:mi>t</mml:mi><mml:mo stretchy="false">~</mml:mo></mml:mover></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:math><tex-math id="inft310">\begin{document}$k(a,t,\tilde{t})$\end{document}</tex-math></alternatives></inline-formula> outputs the one-hot encoded action <italic>a</italic> if <inline-formula><alternatives><mml:math id="inf311"><mml:mi>t</mml:mi><mml:mo>=</mml:mo><mml:mrow class="MJX-TeXAtom-ORD"><mml:mover><mml:mi>t</mml:mi><mml:mo stretchy="false">~</mml:mo></mml:mover></mml:mrow></mml:math><tex-math id="inft311">\begin{document}$t=\tilde{t}$\end{document}</tex-math></alternatives></inline-formula>, and zeros otherwise. The value <inline-formula><alternatives><mml:math id="inf312"><mml:mrow class="MJX-TeXAtom-ORD"><mml:mover><mml:mi>t</mml:mi><mml:mo stretchy="false">~</mml:mo></mml:mover></mml:mrow></mml:math><tex-math id="inft312">\begin{document}$\tilde{t}$\end{document}</tex-math></alternatives></inline-formula> represents the converted response time, obtained from the original response time <bold><italic>b</italic></bold> in the action sequence <inline-formula><alternatives><mml:math id="inf313"><mml:msub><mml:mi>α</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>u</mml:mi></mml:mrow></mml:msub></mml:math><tex-math id="inft313">\begin{document}$\alpha_{u}$\end{document}</tex-math></alternatives></inline-formula>. After processing all <bold><italic>U</italic></bold> sequences, the final hidden states are averaged across sequences: <inline-formula><alternatives><mml:math id="inf314"><mml:mstyle><mml:mrow><mml:mstyle displaystyle="false"><mml:mi mathvariant="bold-italic">h</mml:mi><mml:mo>=</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mi>U</mml:mi></mml:mfrac><mml:munderover><mml:mo>∑</mml:mo><mml:mrow><mml:mi>u</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>U</mml:mi></mml:mrow></mml:munderover><mml:msub><mml:mi mathvariant="bold-italic">h</mml:mi><mml:mrow><mml:mi>L</mml:mi><mml:mo>,</mml:mo><mml:mi>u</mml:mi></mml:mrow></mml:msub></mml:mstyle></mml:mrow></mml:mstyle></mml:math><tex-math id="inft314">\begin{document}$\boldsymbol{h}=\frac{1}{U}\sum_{u=1}^{U}\boldsymbol{h}_{L,u}$\end{document}</tex-math></alternatives></inline-formula>. The individual latent representation is then computed as <inline-formula><alternatives><mml:math id="inf315"><mml:mstyle><mml:mrow><mml:mstyle displaystyle="false"><mml:mi mathvariant="bold-italic">z</mml:mi><mml:mo>=</mml:mo><mml:mi>d</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi mathvariant="bold-italic">h</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mstyle></mml:mrow></mml:mstyle></mml:math><tex-math id="inft315">\begin{document}$\boldsymbol{z}=d(\boldsymbol{h})$\end{document}</tex-math></alternatives></inline-formula>, where <inline-formula><alternatives><mml:math id="inf316"><mml:mi>d</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mo>⋅</mml:mo><mml:mo stretchy="false">)</mml:mo></mml:math><tex-math id="inft316">\begin{document}$d(\cdot)$\end{document}</tex-math></alternatives></inline-formula> represents a single-layer fully-connected feed-forward network. The decoder, implemented as a single linear layer, takes the individual latent representation <inline-formula><alternatives><mml:math id="inf317"><mml:mstyle><mml:mrow><mml:mstyle displaystyle="false"><mml:mi mathvariant="bold-italic">z</mml:mi></mml:mstyle></mml:mrow></mml:mstyle></mml:math><tex-math id="inft317">\begin{document}$\boldsymbol{z}$\end{document}</tex-math></alternatives></inline-formula> as input and outputs the weights for the task solver.</p></sec></sec></sec></sec></body><back><sec sec-type="additional-information" id="s5"><title>Additional information</title><fn-group content-type="competing-interest"><title>Competing interests</title><fn fn-type="COI-statement" id="conf1"><p>No competing interests declared</p></fn></fn-group><fn-group content-type="author-contribution"><title>Author contributions</title><fn fn-type="con" id="con1"><p>Conceptualization, Data curation, Software, Formal analysis, Funding acquisition, Investigation, Visualization, Methodology, Writing – original draft, Project administration, Writing – review and editing</p></fn></fn-group><fn-group content-type="ethics-information"><title>Ethics</title><fn fn-type="other"><p>All participants provided their informed consent online. This study was approved by the Committee for Human Research at the Graduate School of Engineering, The University of Osaka (Approval number: 5-4-1), and compiled with the Declaration of Helsinki.</p></fn></fn-group></sec><sec sec-type="supplementary-material" id="s6"><title>Additional files</title><supplementary-material id="mdar"><label>MDAR checklist</label><media xlink:href="elife-107163-mdarchecklist1-v1.docx" mimetype="application" mime-subtype="docx"/></supplementary-material></sec><sec sec-type="data-availability" id="s7"><title>Data availability</title><p>The behavioural data for the MDP task has been made publicly available at <ext-link ext-link-type="uri" xlink:href="https://github.com/hgshrs/indiv_trans">https://github.com/hgshrs/indiv_trans</ext-link> (copy archived at <xref ref-type="bibr" rid="bib21">Higashi, 2026</xref>). All code and trained models have been made publicly available at <ext-link ext-link-type="uri" xlink:href="https://github.com/hgshrs/indiv_trans">https://github.com/hgshrs/indiv_trans</ext-link> (copy archived at <xref ref-type="bibr" rid="bib21">Higashi, 2026</xref>).</p></sec><ack id="ack"><title>Acknowledgements</title><p>This work was supported in part by the Japan Society for the Promotion of Science (JSPS) KAKENHI, grant number 22H05163 and 24K15047, and Japan Science and Technology Agency (JST) Advanced International Collaborative Research Program (AdCORP), grant number JPMJKB2307. We appreciate Kaede Hashiguchi and Yuichi Tanaka, Graduate School of Engineering, The University of Osaka, who gave useful comments for this research.</p></ack><ref-list><title>References</title><ref id="bib1"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Boogert</surname><given-names>NJ</given-names></name><name><surname>Madden</surname><given-names>JR</given-names></name><name><surname>Morand-Ferron</surname><given-names>J</given-names></name><name><surname>Thornton</surname><given-names>A</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>Measuring and understanding individual differences in cognition</article-title><source>Philosophical Transactions of the Royal Society B</source><volume>373</volume><elocation-id>20170280</elocation-id><pub-id pub-id-type="doi">10.1098/rstb.2017.0280</pub-id></element-citation></ref><ref id="bib2"><element-citation publication-type="preprint"><person-group person-group-type="author"><name><surname>Burgess</surname><given-names>CP</given-names></name><name><surname>Higgins</surname><given-names>I</given-names></name><name><surname>Pal</surname><given-names>A</given-names></name><name><surname>Matthey</surname><given-names>L</given-names></name><name><surname>Watters</surname><given-names>N</given-names></name><name><surname>Desjardins</surname><given-names>G</given-names></name><name><surname>Lerchner</surname><given-names>A</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>Understanding disentangling in Beta-VAE</article-title><source>arXiv</source><ext-link ext-link-type="uri" xlink:href="https://doi.org/10.48550/arXiv.1804.03599">https://doi.org/10.48550/arXiv.1804.03599</ext-link></element-citation></ref><ref id="bib3"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Busemeyer</surname><given-names>JR</given-names></name><name><surname>Stout</surname><given-names>JC</given-names></name></person-group><year iso-8601-date="2002">2002</year><article-title>A contribution of cognitive decision models to clinical assessment: decomposing performance on the Bechara gambling task</article-title><source>Psychological Assessment</source><volume>14</volume><fpage>253</fpage><lpage>262</lpage><pub-id pub-id-type="doi">10.1037/1040-3590.14.3.253</pub-id></element-citation></ref><ref id="bib4"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Canizo</surname><given-names>M</given-names></name><name><surname>Triguero</surname><given-names>I</given-names></name><name><surname>Conde</surname><given-names>A</given-names></name><name><surname>Onieva</surname><given-names>E</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>Multi-head CNN–RNN for multi-time series anomaly detection: an industrial case study</article-title><source>Neurocomputing</source><volume>363</volume><fpage>246</fpage><lpage>260</lpage><pub-id pub-id-type="doi">10.1016/j.neucom.2019.07.034</pub-id></element-citation></ref><ref id="bib5"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Carroll</surname><given-names>JB</given-names></name><name><surname>Maxwell</surname><given-names>SE</given-names></name></person-group><year iso-8601-date="1979">1979</year><article-title>Individual differences in cognitive abilities</article-title><source>Annual Review of Psychology</source><volume>30</volume><fpage>603</fpage><lpage>640</lpage><pub-id pub-id-type="doi">10.1146/annurev.ps.30.020179.003131</pub-id><pub-id pub-id-type="pmid">20738189</pub-id></element-citation></ref><ref id="bib6"><element-citation publication-type="confproc"><person-group person-group-type="author"><name><surname>Cheng</surname><given-names>YA</given-names></name><name><surname>Felipe Rodriguez</surname><given-names>I</given-names></name><name><surname>Chen</surname><given-names>S</given-names></name><name><surname>Kar</surname><given-names>K</given-names></name><name><surname>Watanabe</surname><given-names>T</given-names></name><name><surname>Serre</surname><given-names>T</given-names></name></person-group><year iso-8601-date="2024">2024</year><article-title>RTify: aligning deep neural networks with human behavioral decisions</article-title><conf-name>Advances in Neural Information Processing Systems</conf-name></element-citation></ref><ref id="bib7"><element-citation publication-type="confproc"><person-group person-group-type="author"><name><surname>Cho</surname><given-names>K</given-names></name><name><surname>van Merrienboer</surname><given-names>B</given-names></name><name><surname>Gulcehre</surname><given-names>C</given-names></name><name><surname>Bahdanau</surname><given-names>D</given-names></name><name><surname>Bougares</surname><given-names>F</given-names></name><name><surname>Schwenk</surname><given-names>H</given-names></name><name><surname>Bengio</surname><given-names>Y</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>Learning phrase representations using RNN Encoder–Decoder for Statistical machine translation</article-title><conf-name>Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP)</conf-name><fpage>1724</fpage><lpage>1734</lpage><pub-id pub-id-type="doi">10.3115/v1/D14-1179</pub-id></element-citation></ref><ref id="bib8"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Collins</surname><given-names>AGE</given-names></name><name><surname>Frank</surname><given-names>MJ</given-names></name></person-group><year iso-8601-date="2012">2012</year><article-title>How much of reinforcement learning is working memory, not reinforcement learning? A behavioral, computational, and neurogenetic analysis</article-title><source>The European Journal of Neuroscience</source><volume>35</volume><fpage>1024</fpage><lpage>1035</lpage><pub-id pub-id-type="doi">10.1111/j.1460-9568.2011.07980.x</pub-id><pub-id pub-id-type="pmid">22487033</pub-id></element-citation></ref><ref id="bib9"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Daw</surname><given-names>ND</given-names></name><name><surname>Gershman</surname><given-names>SJ</given-names></name><name><surname>Seymour</surname><given-names>B</given-names></name><name><surname>Dayan</surname><given-names>P</given-names></name><name><surname>Dolan</surname><given-names>RJ</given-names></name></person-group><year iso-8601-date="2011">2011</year><article-title>Model-based influences on humans’ choices and striatal prediction errors</article-title><source>Neuron</source><volume>69</volume><fpage>1204</fpage><lpage>1215</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2011.02.027</pub-id><pub-id pub-id-type="pmid">21435563</pub-id></element-citation></ref><ref id="bib10"><element-citation publication-type="confproc"><person-group person-group-type="author"><name><surname>Dezfouli</surname><given-names>A</given-names></name><name><surname>Ashtiani</surname><given-names>H</given-names></name><name><surname>Ghattas</surname><given-names>O</given-names></name><name><surname>Nock</surname><given-names>R</given-names></name><name><surname>Dayan</surname><given-names>P</given-names></name><name><surname>Ong</surname><given-names>CS</given-names></name></person-group><year iso-8601-date="2019">2019a</year><article-title>Disentangled behavioral representations</article-title><conf-name>Advances in Neural Information Processing Systems</conf-name></element-citation></ref><ref id="bib11"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Dezfouli</surname><given-names>A</given-names></name><name><surname>Griffiths</surname><given-names>K</given-names></name><name><surname>Ramos</surname><given-names>F</given-names></name><name><surname>Dayan</surname><given-names>P</given-names></name><name><surname>Balleine</surname><given-names>BW</given-names></name></person-group><year iso-8601-date="2019">2019b</year><article-title>Models that learn how humans learn: the case of decision-making and its disorders</article-title><source>PLOS Computational Biology</source><volume>15</volume><elocation-id>e1006903</elocation-id><pub-id pub-id-type="doi">10.1371/journal.pcbi.1006903</pub-id><pub-id pub-id-type="pmid">31185008</pub-id></element-citation></ref><ref id="bib12"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Duncan</surname><given-names>KD</given-names></name><name><surname>Shohamy</surname><given-names>D</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Memory states influence value-based decisions</article-title><source>Journal of Experimental Psychology. General</source><volume>145</volume><fpage>1420</fpage><lpage>1426</lpage><pub-id pub-id-type="doi">10.1037/xge0000231</pub-id><pub-id pub-id-type="pmid">27797556</pub-id></element-citation></ref><ref id="bib13"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Eckstein</surname><given-names>MK</given-names></name><name><surname>Master</surname><given-names>SL</given-names></name><name><surname>Xia</surname><given-names>L</given-names></name><name><surname>Dahl</surname><given-names>RE</given-names></name><name><surname>Wilbrecht</surname><given-names>L</given-names></name><name><surname>Collins</surname><given-names>AGE</given-names></name></person-group><year iso-8601-date="2022">2022</year><article-title>The interpretation of computational model parameters depends on the context</article-title><source>eLife</source><volume>11</volume><elocation-id>e75474</elocation-id><pub-id pub-id-type="doi">10.7554/eLife.75474</pub-id><pub-id pub-id-type="pmid">36331872</pub-id></element-citation></ref><ref id="bib14"><element-citation publication-type="confproc"><person-group person-group-type="author"><name><surname>Eckstein</surname><given-names>MK</given-names></name><name><surname>Summerfield</surname><given-names>C</given-names></name><name><surname>Daw</surname><given-names>ND</given-names></name><name><surname>Miller</surname><given-names>KJ</given-names></name></person-group><year iso-8601-date="2023">2023</year><article-title>Predictive and interpretable: combining artificial neural networks and classic cognitive models to understand human learning and decision making</article-title><conf-name>Proceedings of the 45th Annual Conference of the Cognitive Science Society</conf-name><fpage>928</fpage><lpage>935</lpage></element-citation></ref><ref id="bib15"><element-citation publication-type="confproc"><person-group person-group-type="author"><name><surname>Fel</surname><given-names>T</given-names></name><name><surname>Felipe</surname><given-names>I</given-names></name><name><surname>Linsley</surname><given-names>D</given-names></name><name><surname>Serre</surname><given-names>T</given-names></name></person-group><year iso-8601-date="2022">2022</year><article-title>Harmonizing the object recognition strategies of deep neural networks with humans</article-title><conf-name>Advances in Neural Information Processing Systems</conf-name></element-citation></ref><ref id="bib16"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Fintz</surname><given-names>M</given-names></name><name><surname>Osadchy</surname><given-names>M</given-names></name><name><surname>Hertz</surname><given-names>U</given-names></name></person-group><year iso-8601-date="2022">2022</year><article-title>Using deep learning to predict human decisions and using cognitive models to explain deep learning models</article-title><source>Scientific Reports</source><volume>12</volume><elocation-id>4736</elocation-id><pub-id pub-id-type="doi">10.1038/s41598-022-08863-0</pub-id><pub-id pub-id-type="pmid">35304572</pub-id></element-citation></ref><ref id="bib17"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Frank</surname><given-names>MJ</given-names></name><name><surname>Doll</surname><given-names>BB</given-names></name><name><surname>Oas-Terpstra</surname><given-names>J</given-names></name><name><surname>Moreno</surname><given-names>F</given-names></name></person-group><year iso-8601-date="2009">2009</year><article-title>Prefrontal and striatal dopaminergic genes predict individual differences in exploration and exploitation</article-title><source>Nature Neuroscience</source><volume>12</volume><fpage>1062</fpage><lpage>1068</lpage><pub-id pub-id-type="doi">10.1038/nn.2342</pub-id><pub-id pub-id-type="pmid">19620978</pub-id></element-citation></ref><ref id="bib18"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ger</surname><given-names>Y</given-names></name><name><surname>Nachmani</surname><given-names>E</given-names></name><name><surname>Wolf</surname><given-names>L</given-names></name><name><surname>Shahar</surname><given-names>N</given-names></name></person-group><year iso-8601-date="2024">2024a</year><article-title>Harnessing the flexibility of neural networks to predict dynamic theoretical parameters underlying human choice behavior</article-title><source>PLOS Computational Biology</source><volume>20</volume><elocation-id>e1011678</elocation-id><pub-id pub-id-type="doi">10.1371/journal.pcbi.1011678</pub-id><pub-id pub-id-type="pmid">38175848</pub-id></element-citation></ref><ref id="bib19"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ger</surname><given-names>Y</given-names></name><name><surname>Shahar</surname><given-names>M</given-names></name><name><surname>Shahar</surname><given-names>N</given-names></name></person-group><year iso-8601-date="2024">2024b</year><article-title>Using recurrent neural network to estimate irreducible stochasticity in human choice behavior</article-title><source>eLife</source><volume>13</volume><elocation-id>13</elocation-id><pub-id pub-id-type="doi">10.7554/eLife.90082</pub-id></element-citation></ref><ref id="bib20"><element-citation publication-type="preprint"><person-group person-group-type="author"><name><surname>Ha</surname><given-names>D</given-names></name><name><surname>Dai</surname><given-names>A</given-names></name><name><surname>Le</surname><given-names>QV</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Hypernetworks</article-title><source>arXiv</source><ext-link ext-link-type="uri" xlink:href="https://doi.org/10.48550/arXiv.1609.09106">https://doi.org/10.48550/arXiv.1609.09106</ext-link></element-citation></ref><ref id="bib21"><element-citation publication-type="software"><person-group person-group-type="author"><name><surname>Higashi</surname><given-names>H</given-names></name></person-group><year iso-8601-date="2026">2026</year><data-title>Indiv_trans</data-title><version designator="swh:1:rev:f13b3cf1ba7e713979bc61d13edf05ccdaa902c2">swh:1:rev:f13b3cf1ba7e713979bc61d13edf05ccdaa902c2</version><source>Software Heritage</source><ext-link ext-link-type="uri" xlink:href="https://archive.softwareheritage.org/swh:1:dir:a58a52ac76c5d775eb3aeaedf8e0cc337dad1e93;origin=https://github.com/hgshrs/indiv_trans;visit=swh:1:snp:ef3ee4561011aa26b1d9d6baaebd7bc1303aa2d2;anchor=swh:1:rev:f13b3cf1ba7e713979bc61d13edf05ccdaa902c2">https://archive.softwareheritage.org/swh:1:dir:a58a52ac76c5d775eb3aeaedf8e0cc337dad1e93;origin=https://github.com/hgshrs/indiv_trans;visit=swh:1:snp:ef3ee4561011aa26b1d9d6baaebd7bc1303aa2d2;anchor=swh:1:rev:f13b3cf1ba7e713979bc61d13edf05ccdaa902c2</ext-link></element-citation></ref><ref id="bib22"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kar</surname><given-names>K</given-names></name><name><surname>Kubilius</surname><given-names>J</given-names></name><name><surname>Schmidt</surname><given-names>K</given-names></name><name><surname>Issa</surname><given-names>EB</given-names></name><name><surname>DiCarlo</surname><given-names>JJ</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>Evidence that recurrent circuits are critical to the ventral stream’s execution of core object recognition behavior</article-title><source>Nature Neuroscience</source><volume>22</volume><fpage>974</fpage><lpage>983</lpage><pub-id pub-id-type="doi">10.1038/s41593-019-0392-5</pub-id><pub-id pub-id-type="pmid">31036945</pub-id></element-citation></ref><ref id="bib23"><element-citation publication-type="preprint"><person-group person-group-type="author"><name><surname>Karaletsos</surname><given-names>T</given-names></name><name><surname>Dayan</surname><given-names>P</given-names></name><name><surname>Ghahramani</surname><given-names>Z</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>Probabilistic meta-representations of neural networks</article-title><source>arXiv</source><ext-link ext-link-type="uri" xlink:href="https://doi.org/10.48550/arXiv.1810.00555">https://doi.org/10.48550/arXiv.1810.00555</ext-link></element-citation></ref><ref id="bib24"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Katahira</surname><given-names>K</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>The relation between reinforcement learning parameters and the influence of reinforcement history on choice behavior</article-title><source>Journal of Mathematical Psychology</source><volume>66</volume><fpage>59</fpage><lpage>69</lpage><pub-id pub-id-type="doi">10.1016/j.jmp.2015.03.006</pub-id></element-citation></ref><ref id="bib25"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Koivisto</surname><given-names>M</given-names></name><name><surname>Railo</surname><given-names>H</given-names></name><name><surname>Revonsuo</surname><given-names>A</given-names></name><name><surname>Vanni</surname><given-names>S</given-names></name><name><surname>Salminen-Vaparanta</surname><given-names>N</given-names></name></person-group><year iso-8601-date="2011">2011</year><article-title>Recurrent processing in V1/V2 contributes to categorization of natural scenes</article-title><source>The Journal of Neuroscience</source><volume>31</volume><fpage>2488</fpage><lpage>2492</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.3074-10.2011</pub-id><pub-id pub-id-type="pmid">21325516</pub-id></element-citation></ref><ref id="bib26"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kriegeskorte</surname><given-names>N</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>Deep neural networks: a new framework for modeling biological vision and brain information processing</article-title><source>Annual Review of Vision Science</source><volume>1</volume><fpage>417</fpage><lpage>446</lpage><pub-id pub-id-type="doi">10.1146/annurev-vision-082114-035447</pub-id><pub-id pub-id-type="pmid">28532370</pub-id></element-citation></ref><ref id="bib27"><element-citation publication-type="confproc"><person-group person-group-type="author"><name><surname>Krizhevsky</surname><given-names>A</given-names></name><name><surname>Sutskever</surname><given-names>I</given-names></name><name><surname>Hinton</surname><given-names>GE</given-names></name></person-group><year iso-8601-date="2012">2012</year><article-title>ImageNet classification with deep convolutional neural networks</article-title><conf-name>Advances in Neural Information Processing Systems</conf-name></element-citation></ref><ref id="bib28"><element-citation publication-type="preprint"><person-group person-group-type="author"><name><surname>Lin</surname><given-names>WH</given-names></name><name><surname>Clarke</surname><given-names>AM</given-names></name><name><surname>Pilz</surname><given-names>KS</given-names></name><name><surname>Herzog</surname><given-names>MH</given-names></name><name><surname>Kunchulia</surname><given-names>M</given-names></name></person-group><year iso-8601-date="2023">2023</year><article-title>Intact reinforcement learning in healthy ageing</article-title><source>bioRxiv</source><pub-id pub-id-type="doi">10.1101/2023.05.25.542104</pub-id></element-citation></ref><ref id="bib29"><element-citation publication-type="confproc"><person-group person-group-type="author"><name><surname>Miller</surname><given-names>KJ</given-names></name><name><surname>Eckstein</surname><given-names>M</given-names></name><name><surname>Botvinick</surname><given-names>MM</given-names></name><name><surname>Kurth-Nelson</surname><given-names>Z</given-names></name></person-group><year iso-8601-date="2023">2023</year><article-title>Cognitive model discovery via disentangled RNNs</article-title><conf-name>Advances in Neural Information Processing Systems</conf-name><fpage>61377</fpage><lpage>61394</lpage></element-citation></ref><ref id="bib30"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Navarro</surname><given-names>DJ</given-names></name><name><surname>Griffiths</surname><given-names>TL</given-names></name><name><surname>Steyvers</surname><given-names>M</given-names></name><name><surname>Lee</surname><given-names>MD</given-names></name></person-group><year iso-8601-date="2006">2006</year><article-title>Modeling individual differences using Dirichlet processes</article-title><source>Journal of Mathematical Psychology</source><volume>50</volume><fpage>101</fpage><lpage>122</lpage><pub-id pub-id-type="doi">10.1016/j.jmp.2005.11.006</pub-id></element-citation></ref><ref id="bib31"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>O’Doherty</surname><given-names>JP</given-names></name><name><surname>Hampton</surname><given-names>A</given-names></name><name><surname>Kim</surname><given-names>H</given-names></name></person-group><year iso-8601-date="2007">2007</year><article-title>Model-based fMRI and its application to reward learning and decision making</article-title><source>Annals of the New York Academy of Sciences</source><volume>1104</volume><fpage>35</fpage><lpage>53</lpage><pub-id pub-id-type="doi">10.1196/annals.1390.022</pub-id><pub-id pub-id-type="pmid">17416921</pub-id></element-citation></ref><ref id="bib32"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Pedersen</surname><given-names>ML</given-names></name><name><surname>Frank</surname><given-names>MJ</given-names></name><name><surname>Biele</surname><given-names>G</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>The drift diffusion model as the choice rule in reinforcement learning</article-title><source>Psychonomic Bulletin &amp; Review</source><volume>24</volume><fpage>1234</fpage><lpage>1251</lpage><pub-id pub-id-type="doi">10.3758/s13423-016-1199-y</pub-id><pub-id pub-id-type="pmid">27966103</pub-id></element-citation></ref><ref id="bib33"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Peterson</surname><given-names>JC</given-names></name><name><surname>Bourgin</surname><given-names>DD</given-names></name><name><surname>Agrawal</surname><given-names>M</given-names></name><name><surname>Reichman</surname><given-names>D</given-names></name><name><surname>Griffiths</surname><given-names>TL</given-names></name></person-group><year iso-8601-date="2021">2021</year><article-title>Using large-scale experiments and machine learning to discover theories of human decision-making</article-title><source>Science</source><volume>372</volume><fpage>1209</fpage><lpage>1214</lpage><pub-id pub-id-type="doi">10.1126/science.abe2629</pub-id><pub-id pub-id-type="pmid">34112693</pub-id></element-citation></ref><ref id="bib34"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Radev</surname><given-names>ST</given-names></name><name><surname>Mertens</surname><given-names>UK</given-names></name><name><surname>Voss</surname><given-names>A</given-names></name><name><surname>Ardizzone</surname><given-names>L</given-names></name><name><surname>Kothe</surname><given-names>U</given-names></name></person-group><year iso-8601-date="2022">2022</year><article-title>BayesFlow: learning complex stochastic models with invertible neural networks</article-title><source>IEEE Transactions on Neural Networks and Learning Systems</source><volume>33</volume><fpage>1452</fpage><lpage>1466</lpage><pub-id pub-id-type="doi">10.1109/TNNLS.2020.3042395</pub-id><pub-id pub-id-type="pmid">33338021</pub-id></element-citation></ref><ref id="bib35"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Rafiei</surname><given-names>F</given-names></name><name><surname>Shekhar</surname><given-names>M</given-names></name><name><surname>Rahnev</surname><given-names>D</given-names></name></person-group><year iso-8601-date="2024">2024</year><article-title>The neural network RTNet exhibits the signatures of human perceptual decision-making</article-title><source>Nature Human Behaviour</source><volume>8</volume><fpage>1752</fpage><lpage>1770</lpage><pub-id pub-id-type="doi">10.1038/s41562-024-01914-8</pub-id><pub-id pub-id-type="pmid">38997452</pub-id></element-citation></ref><ref id="bib36"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Rajalingham</surname><given-names>R</given-names></name><name><surname>Issa</surname><given-names>EB</given-names></name><name><surname>Bashivan</surname><given-names>P</given-names></name><name><surname>Kar</surname><given-names>K</given-names></name><name><surname>Schmidt</surname><given-names>K</given-names></name><name><surname>DiCarlo</surname><given-names>JJ</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>Large-scale, high-resolution comparison of the core visual object recognition behavior of humans, monkeys, and state-of-the-art deep artificial neural networks</article-title><source>The Journal of Neuroscience</source><volume>38</volume><fpage>7255</fpage><lpage>7269</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.0388-18.2018</pub-id><pub-id pub-id-type="pmid">30006365</pub-id></element-citation></ref><ref id="bib37"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ratcliff</surname><given-names>R</given-names></name><name><surname>McKoon</surname><given-names>G</given-names></name></person-group><year iso-8601-date="2008">2008</year><article-title>The diffusion decision model: theory and data for two-choice decision tasks</article-title><source>Neural Computation</source><volume>20</volume><fpage>873</fpage><lpage>922</lpage><pub-id pub-id-type="doi">10.1162/neco.2008.12-06-420</pub-id><pub-id pub-id-type="pmid">18085991</pub-id></element-citation></ref><ref id="bib38"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Rmus</surname><given-names>M</given-names></name><name><surname>Pan</surname><given-names>TF</given-names></name><name><surname>Xia</surname><given-names>L</given-names></name><name><surname>Collins</surname><given-names>AGE</given-names></name></person-group><year iso-8601-date="2024">2024</year><article-title>Artificial neural networks for model identification and parameter estimation in computational cognitive models</article-title><source>PLOS Computational Biology</source><volume>20</volume><elocation-id>e1012119</elocation-id><pub-id pub-id-type="doi">10.1371/journal.pcbi.1012119</pub-id><pub-id pub-id-type="pmid">38748770</pub-id></element-citation></ref><ref id="bib39"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Rumelhart</surname><given-names>DE</given-names></name><name><surname>McClelland</surname><given-names>JL</given-names></name></person-group><year iso-8601-date="1987">1987</year><chapter-title>Learning internal representations by error propagation</chapter-title><person-group person-group-type="editor"><name><surname>Rumelhart</surname><given-names>DE</given-names></name><name><surname>McClelland</surname><given-names>JL</given-names></name></person-group><source>Parallel Distributed Processing: Explorations in the Microstructure of Cognition: Foundations</source><publisher-name>MIT Press</publisher-name><fpage>318</fpage><lpage>362</lpage><pub-id pub-id-type="doi">10.7551/mitpress/4943.003.0128</pub-id></element-citation></ref><ref id="bib40"><element-citation publication-type="confproc"><person-group person-group-type="author"><name><surname>Schaeffer</surname><given-names>R</given-names></name><name><surname>Khona</surname><given-names>M</given-names></name><name><surname>Meshulam</surname><given-names>L</given-names></name><name><surname>Fiete</surname><given-names>IR</given-names></name></person-group><year iso-8601-date="2020">2020</year><article-title>Reverse-engineering recurrent neural network solutions to a hierarchical inference task for mice</article-title><conf-name>Advances in Neural Information Processing Systems</conf-name></element-citation></ref><ref id="bib41"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Sevy</surname><given-names>S</given-names></name><name><surname>Burdick</surname><given-names>KE</given-names></name><name><surname>Visweswaraiah</surname><given-names>H</given-names></name><name><surname>Abdelmessih</surname><given-names>S</given-names></name><name><surname>Lukin</surname><given-names>M</given-names></name><name><surname>Yechiam</surname><given-names>E</given-names></name><name><surname>Bechara</surname><given-names>A</given-names></name></person-group><year iso-8601-date="2007">2007</year><article-title>Iowa gambling task in schizophrenia: a review and new data in patients with schizophrenia and co-occurring cannabis use disorders</article-title><source>Schizophrenia Research</source><volume>92</volume><fpage>74</fpage><lpage>84</lpage><pub-id pub-id-type="doi">10.1016/j.schres.2007.01.005</pub-id><pub-id pub-id-type="pmid">17379482</pub-id></element-citation></ref><ref id="bib42"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Shengli</surname><given-names>W</given-names></name></person-group><year iso-8601-date="2021">2021</year><article-title>Is human digital twin possible?</article-title><source>Computer Methods and Programs in Biomedicine Update</source><volume>1</volume><elocation-id>100014</elocation-id><pub-id pub-id-type="doi">10.1016/j.cmpbup.2021.100014</pub-id></element-citation></ref><ref id="bib43"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Siegelmann</surname><given-names>HT</given-names></name><name><surname>Sontag</surname><given-names>ED</given-names></name></person-group><year iso-8601-date="1995">1995</year><article-title>On the computational power of neural nets</article-title><source>Journal of Computer and System Sciences</source><volume>50</volume><fpage>132</fpage><lpage>150</lpage><pub-id pub-id-type="doi">10.1006/jcss.1995.1013</pub-id></element-citation></ref><ref id="bib44"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Song</surname><given-names>HF</given-names></name><name><surname>Yang</surname><given-names>GR</given-names></name><name><surname>Wang</surname><given-names>XJ</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>Reward-based training of recurrent neural networks for cognitive and value-based tasks</article-title><source>eLife</source><volume>6</volume><elocation-id>e21492</elocation-id><pub-id pub-id-type="doi">10.7554/eLife.21492</pub-id><pub-id pub-id-type="pmid">28084991</pub-id></element-citation></ref><ref id="bib45"><element-citation publication-type="confproc"><person-group person-group-type="author"><name><surname>Song</surname><given-names>M</given-names></name><name><surname>Niv</surname><given-names>Y</given-names></name><name><surname>Bo Cai</surname><given-names>M</given-names></name></person-group><year iso-8601-date="2021">2021</year><article-title>Using recurrent neural networks to understand human reward learning</article-title><conf-name>Proceedings of the Annual Meeting of the Cognitive Science Society</conf-name><fpage>1388</fpage><lpage>1394</lpage></element-citation></ref><ref id="bib46"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Spoerer</surname><given-names>CJ</given-names></name><name><surname>Kietzmann</surname><given-names>TC</given-names></name><name><surname>Mehrer</surname><given-names>J</given-names></name><name><surname>Charest</surname><given-names>I</given-names></name><name><surname>Kriegeskorte</surname><given-names>N</given-names></name></person-group><year iso-8601-date="2020">2020</year><article-title>Recurrent neural networks can explain flexible trading of speed and accuracy in biological vision</article-title><source>PLOS Computational Biology</source><volume>16</volume><elocation-id>e1008215</elocation-id><pub-id pub-id-type="doi">10.1371/journal.pcbi.1008215</pub-id><pub-id pub-id-type="pmid">33006992</pub-id></element-citation></ref><ref id="bib47"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Sutton</surname><given-names>RS</given-names></name><name><surname>Barto</surname><given-names>AG</given-names></name></person-group><year iso-8601-date="1998">1998</year><source>Reinforcement Learning: An Introduction. Adaptive Computation and Machine Learning</source><publisher-name>MIT Press</publisher-name></element-citation></ref><ref id="bib48"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Tang</surname><given-names>H</given-names></name><name><surname>Schrimpf</surname><given-names>M</given-names></name><name><surname>Lotter</surname><given-names>W</given-names></name><name><surname>Moerman</surname><given-names>C</given-names></name><name><surname>Paredes</surname><given-names>A</given-names></name><name><surname>Ortega Caro</surname><given-names>J</given-names></name><name><surname>Hardesty</surname><given-names>W</given-names></name><name><surname>Cox</surname><given-names>D</given-names></name><name><surname>Kreiman</surname><given-names>G</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>Recurrent computations for visual pattern completion</article-title><source>PNAS</source><volume>115</volume><fpage>8835</fpage><lpage>8840</lpage><pub-id pub-id-type="doi">10.1073/pnas.1719397115</pub-id></element-citation></ref><ref id="bib49"><element-citation publication-type="preprint"><person-group person-group-type="author"><name><surname>Tolstikhin</surname><given-names>I</given-names></name><name><surname>Bousquet</surname><given-names>O</given-names></name><name><surname>Gelly</surname><given-names>S</given-names></name><name><surname>Schoelkopf</surname><given-names>B</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>Wasserstein auto-encoders</article-title><source>arXiv</source><ext-link ext-link-type="uri" xlink:href="https://doi.org/10.48550/arXiv.1711.01558">https://doi.org/10.48550/arXiv.1711.01558</ext-link></element-citation></ref><ref id="bib50"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Tuzsus</surname><given-names>D</given-names></name><name><surname>Brands</surname><given-names>A</given-names></name><name><surname>Pappas</surname><given-names>I</given-names></name><name><surname>Peters</surname><given-names>J</given-names></name></person-group><year iso-8601-date="2024">2024</year><article-title>Exploration–exploitation mechanisms in recurrent neural networks and human learners in restless bandit problems</article-title><source>Computational Brain &amp; Behavior</source><volume>7</volume><fpage>314</fpage><lpage>356</lpage><pub-id pub-id-type="doi">10.1007/s42113-024-00202-y</pub-id></element-citation></ref><ref id="bib51"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>van den Bos</surname><given-names>R</given-names></name><name><surname>Homberg</surname><given-names>J</given-names></name><name><surname>de Visser</surname><given-names>L</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>A critical review of sex differences in decision-making tasks: focus on the Iowa Gambling Task</article-title><source>Behavioural Brain Research</source><volume>238</volume><fpage>95</fpage><lpage>108</lpage><pub-id pub-id-type="doi">10.1016/j.bbr.2012.10.002</pub-id><pub-id pub-id-type="pmid">23078950</pub-id></element-citation></ref><ref id="bib52"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Vickers</surname><given-names>D</given-names></name></person-group><year iso-8601-date="1970">1970</year><article-title>Evidence for an accumulator model of psychophysical discrimination</article-title><source>Ergonomics</source><volume>13</volume><fpage>37</fpage><lpage>58</lpage><pub-id pub-id-type="doi">10.1080/00140137008931117</pub-id><pub-id pub-id-type="pmid">5416868</pub-id></element-citation></ref><ref id="bib53"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wagenmakers</surname><given-names>EJ</given-names></name><name><surname>Brown</surname><given-names>S</given-names></name></person-group><year iso-8601-date="2007">2007</year><article-title>On the linear relation between the mean and the standard deviation of a response time distribution</article-title><source>Psychological Review</source><volume>114</volume><fpage>830</fpage><lpage>841</lpage><pub-id pub-id-type="doi">10.1037/0033-295X.114.3.830</pub-id><pub-id pub-id-type="pmid">17638508</pub-id></element-citation></ref><ref id="bib54"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wang</surname><given-names>R</given-names></name><name><surname>Shen</surname><given-names>Y</given-names></name><name><surname>Tino</surname><given-names>P</given-names></name><name><surname>Welchman</surname><given-names>AE</given-names></name><name><surname>Kourtzi</surname><given-names>Z</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>Learning predictive statistics: strategies and brain mechanisms</article-title><source>The Journal of Neuroscience</source><volume>37</volume><fpage>8412</fpage><lpage>8427</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.0144-17.2017</pub-id><pub-id pub-id-type="pmid">28760866</pub-id></element-citation></ref><ref id="bib55"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wilson</surname><given-names>RC</given-names></name><name><surname>Collins</surname><given-names>AGE</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>Ten simple rules for the computational modeling of behavioral data</article-title><source>eLife</source><volume>8</volume><elocation-id>e49547</elocation-id><pub-id pub-id-type="doi">10.7554/eLife.49547</pub-id><pub-id pub-id-type="pmid">31769410</pub-id></element-citation></ref><ref id="bib56"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Yamins</surname><given-names>DLK</given-names></name><name><surname>DiCarlo</surname><given-names>JJ</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Using goal-driven deep learning models to understand sensory cortex</article-title><source>Nature Neuroscience</source><volume>19</volume><fpage>356</fpage><lpage>365</lpage><pub-id pub-id-type="doi">10.1038/nn.4244</pub-id><pub-id pub-id-type="pmid">26906502</pub-id></element-citation></ref><ref id="bib57"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Yang</surname><given-names>GR</given-names></name><name><surname>Joglekar</surname><given-names>MR</given-names></name><name><surname>Song</surname><given-names>HF</given-names></name><name><surname>Newsome</surname><given-names>WT</given-names></name><name><surname>Wang</surname><given-names>XJ</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>Task representations in neural networks trained to perform many cognitive tasks</article-title><source>Nature Neuroscience</source><volume>22</volume><fpage>297</fpage><lpage>306</lpage><pub-id pub-id-type="doi">10.1038/s41593-018-0310-2</pub-id><pub-id pub-id-type="pmid">30643294</pub-id></element-citation></ref><ref id="bib58"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Yechiam</surname><given-names>E</given-names></name><name><surname>Busemeyer</surname><given-names>JR</given-names></name><name><surname>Stout</surname><given-names>JC</given-names></name><name><surname>Bechara</surname><given-names>A</given-names></name></person-group><year iso-8601-date="2005">2005</year><article-title>Using cognitive models to map relations between neuropsychological disorders and human decision-making deficits</article-title><source>Psychological Science</source><volume>16</volume><fpage>973</fpage><lpage>978</lpage><pub-id pub-id-type="doi">10.1111/j.1467-9280.2005.01646.x</pub-id><pub-id pub-id-type="pmid">16313662</pub-id></element-citation></ref></ref-list><app-group><app id="appendix-1"><title>Appendix 1</title><sec sec-type="appendix" id="s8"><title>Additional results on MDP task</title><sec sec-type="appendix" id="s8-1"><title>Parameter fitting of Q-learning for human behaviors</title><p><xref ref-type="fig" rid="app1fig1">Appendix 1—figure 1</xref> shows the parameters for the Q-learning model estimated from the behavioral data of human participants. The parameters were estimated separately for the 2-step and 3-step tasks. While the learning rate (<inline-formula><alternatives><mml:math id="inf318"><mml:msub><mml:mi>q</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi mathvariant="normal">l</mml:mi><mml:mi mathvariant="normal">r</mml:mi></mml:mrow></mml:mrow></mml:msub></mml:math><tex-math id="inft318">\begin{document}$q_{\mathrm{lr}}$\end{document}</tex-math></alternatives></inline-formula>) and inverse temperature (<inline-formula><alternatives><mml:math id="inf319"><mml:msub><mml:mi>q</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi mathvariant="normal">i</mml:mi><mml:mi mathvariant="normal">t</mml:mi></mml:mrow></mml:mrow></mml:msub></mml:math><tex-math id="inft319">\begin{document}$q_{\mathrm{it}}$\end{document}</tex-math></alternatives></inline-formula>) were distributed across a range of values, the discount rate (<inline-formula><alternatives><mml:math id="inf320"><mml:msub><mml:mi>q</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi mathvariant="normal">d</mml:mi><mml:mi mathvariant="normal">r</mml:mi></mml:mrow></mml:mrow></mml:msub></mml:math><tex-math id="inft320">\begin{document}$q_{\mathrm{dr}}$\end{document}</tex-math></alternatives></inline-formula>) and the initial Q-value <inline-formula><alternatives><mml:math id="inf321"><mml:msub><mml:mi>q</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi mathvariant="normal">i</mml:mi><mml:mi mathvariant="normal">n</mml:mi><mml:mi mathvariant="normal">i</mml:mi><mml:mi mathvariant="normal">t</mml:mi></mml:mrow></mml:mrow></mml:msub></mml:math><tex-math id="inft321">\begin{document}$q_{\mathrm{init}}$\end{document}</tex-math></alternatives></inline-formula> were concentrated near 1 and 0, respectively.</p><fig id="app1fig1" position="float"><label>Appendix 1—figure 1.</label><caption><title>Histograms of Q-learning parameters estimated from human participants’ behaviors in the MDP tasks.</title><p>The distributions for the learning rate (<bold>A</bold>) and inverse temperature (<bold>B</bold>) show considerable inter-individual variability, whereas the discount rate (<bold>C</bold>) and initial Q-value (<bold>D</bold>) are relatively consistent across participants.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-107163-app1-fig1-v1.tif"/></fig></sec><sec sec-type="appendix" id="s8-2"><title>EIDT training</title><p>The losses for the training and validation samples during the EIDT network training are shown in <xref ref-type="fig" rid="app1fig2">Appendix 1—figure 2</xref>. Since we adopted a leave-one-participant-out cross-validation, which results in many training runs, the displayed curves are representatives from a training run that used all participants as training data to illustrate the general convergence pattern. Training was stopped when the validation loss reached its minimum.</p><fig id="app1fig2" position="float"><label>Appendix 1—figure 2.</label><caption><title>Representative training and validation curves for the EIDT model in the MDP task.</title><p>The plots show the negative log-likelihood loss over training epochs for (<bold>A</bold>) 3-step to 2-step transfer and (<bold>B</bold>) 2-step to 3-step transfer. The star marker indicates the point of early stopping, where the validation loss was minimal.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-107163-app1-fig2-v1.tif"/></fig></sec><sec sec-type="appendix" id="s8-3"><title>Individual latent representation</title><p><xref ref-type="fig" rid="app1fig3">Appendix 1—figure 3</xref> visualizes the individual latent representations computed from the behaviors of human participants (squares) and simulated Q-learning agents (dots). Because a different encoder was trained for each fold of the leave-one-participant-out cross-validation, the displayed representations are from a model trained on all participants’ data for illustrative purposes.</p><fig id="app1fig3" position="float"><label>Appendix 1—figure 3.</label><caption><title>Individual latent representations for the MDP task.</title><p>The plots show the two-dimensional latent space derived from behaviors in (<bold>A</bold>) the 3-step task and (<bold>B</bold>) the 2-step task. Square markers represent human participants, and dot markers represent simulated Q-learning agents.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-107163-app1-fig3-v1.tif"/></fig></sec><sec sec-type="appendix" id="s8-4"><title>Analysis of individual latent representation with a cognitive model</title><p>To interpret the latent space, we analyzed the relationship between the Q-learning parameters of simulated agents and their corresponding individual latent representations. We fitted each dimension of the latent representation (<inline-formula><alternatives><mml:math id="inf322"><mml:msub><mml:mi>z</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:math><tex-math id="inft322">\begin{document}$z_{i}$\end{document}</tex-math></alternatives></inline-formula>) using a generalized linear model (GLM) with the agents’ learning rate (<inline-formula><alternatives><mml:math id="inf323"><mml:msub><mml:mi>q</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi mathvariant="normal">l</mml:mi><mml:mi mathvariant="normal">r</mml:mi></mml:mrow></mml:mrow></mml:msub></mml:math><tex-math id="inft323">\begin{document}$q_{\mathrm{lr}}$\end{document}</tex-math></alternatives></inline-formula>) and inverse temperature (<inline-formula><alternatives><mml:math id="inf324"><mml:msub><mml:mi>q</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi mathvariant="normal">i</mml:mi><mml:mi mathvariant="normal">t</mml:mi></mml:mrow></mml:mrow></mml:msub></mml:math><tex-math id="inft324">\begin{document}$q_{\mathrm{it}}$\end{document}</tex-math></alternatives></inline-formula>) as predictors:<disp-formula id="equ13"><label>(13)</label><alternatives><mml:math id="m13"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msub><mml:mi>z</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>∼</mml:mo><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi mathvariant="normal">N</mml:mi><mml:mi mathvariant="normal">o</mml:mi><mml:mi mathvariant="normal">r</mml:mi><mml:mi mathvariant="normal">m</mml:mi><mml:mi mathvariant="normal">a</mml:mi><mml:mi mathvariant="normal">l</mml:mi></mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:msub><mml:mi>β</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mn>0</mml:mn></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mi>β</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mi>log</mml:mi><mml:mo>⁡</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>q</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi mathvariant="normal">r</mml:mi><mml:mi mathvariant="normal">l</mml:mi></mml:mrow></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:mo>+</mml:mo><mml:msub><mml:mi>β</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:mi>log</mml:mi><mml:mo>⁡</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>q</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi mathvariant="normal">i</mml:mi><mml:mi mathvariant="normal">t</mml:mi></mml:mrow></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:mo>+</mml:mo><mml:msub><mml:mi>β</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mn>3</mml:mn></mml:mrow></mml:msub><mml:mi>log</mml:mi><mml:mo>⁡</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>q</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi mathvariant="normal">l</mml:mi><mml:mi mathvariant="normal">r</mml:mi></mml:mrow></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:mi>log</mml:mi><mml:mo>⁡</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>q</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi mathvariant="normal">i</mml:mi><mml:mi mathvariant="normal">t</mml:mi></mml:mrow></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:mo>)</mml:mo></mml:mrow><mml:mo>,</mml:mo></mml:mstyle></mml:math><tex-math id="t13">\begin{document}$$\displaystyle  z_{i}\sim \mathrm{Normal}\left(\beta_{0}+ \beta_{1}\log(q_{\mathrm{rl}}) + \beta_{2}\log(q_{\mathrm{it}}) + \beta_{3}\log(q_{\mathrm{lr}})\log(q_{\mathrm{it}}) \right),$$\end{document}</tex-math></alternatives></disp-formula></p><p>The fitted coefficients are summarized in <xref ref-type="table" rid="app1table1">Appendix 1—table 1</xref>, and the mapping for the 2-step MDP task is visualized in <xref ref-type="fig" rid="app1fig4">Appendix 1—figure 4</xref>. This analysis complements <xref ref-type="fig" rid="app1fig6">Appendix 1—figure 6</xref> in the main text, which shows the same mapping for the 3-step task.</p><table-wrap id="app1table1" position="float"><label>Appendix 1—table 1.</label><caption><title>GLM fitting coefficients for the relationship between Q-learning parameters and the individual latent representation.</title><p>An asterisk (*) denotes statistical significance (<inline-formula><alternatives><mml:math id="inf325"><mml:mi>p</mml:mi><mml:mo>&lt;</mml:mo><mml:mn>0.05</mml:mn></mml:math><tex-math id="inft325">\begin{document}$p \lt 0.05$\end{document}</tex-math></alternatives></inline-formula>).</p></caption><table frame="hsides" rules="groups"><thead><tr><th align="left" valign="bottom"/><th align="left" valign="bottom"/><th align="left" valign="bottom" colspan="4">Coefficients</th></tr><tr><th align="left" valign="bottom">Source</th><th align="left" valign="bottom">Variable</th><th align="left" valign="bottom"><inline-formula><alternatives><mml:math id="inf326"><mml:msub><mml:mi>β</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mn>0</mml:mn></mml:mrow></mml:msub></mml:math><tex-math id="inft326">\begin{document}$\beta_{0}$\end{document}</tex-math></alternatives></inline-formula>(bias)</th><th align="left" valign="bottom"><inline-formula><alternatives><mml:math id="inf327"><mml:msub><mml:mi>β</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:math><tex-math id="inft327">\begin{document}$\beta_{1}$\end{document}</tex-math></alternatives></inline-formula>(<inline-formula><alternatives><mml:math id="inf328"><mml:msub><mml:mi>q</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi mathvariant="normal">l</mml:mi><mml:mi mathvariant="normal">r</mml:mi></mml:mrow></mml:mrow></mml:msub></mml:math><tex-math id="inft328">\begin{document}$q_{\mathrm{lr}}$\end{document}</tex-math></alternatives></inline-formula>)</th><th align="left" valign="bottom"><inline-formula><alternatives><mml:math id="inf329"><mml:msub><mml:mi>β</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mn>2</mml:mn></mml:mrow></mml:msub></mml:math><tex-math id="inft329">\begin{document}$\beta_{2}$\end{document}</tex-math></alternatives></inline-formula>(<inline-formula><alternatives><mml:math id="inf330"><mml:msub><mml:mi>q</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi mathvariant="normal">i</mml:mi><mml:mi mathvariant="normal">t</mml:mi></mml:mrow></mml:mrow></mml:msub></mml:math><tex-math id="inft330">\begin{document}$q_{\mathrm{it}}$\end{document}</tex-math></alternatives></inline-formula>)</th><th align="left" valign="bottom"><inline-formula><alternatives><mml:math id="inf331"><mml:msub><mml:mi>β</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mn>3</mml:mn></mml:mrow></mml:msub></mml:math><tex-math id="inft331">\begin{document}$\beta_{3}$\end{document}</tex-math></alternatives></inline-formula>(<inline-formula><alternatives><mml:math id="inf332"><mml:msub><mml:mi>q</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi mathvariant="normal">l</mml:mi><mml:mi mathvariant="normal">r</mml:mi></mml:mrow></mml:mrow></mml:msub><mml:mo>×</mml:mo><mml:msub><mml:mi>q</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi mathvariant="normal">i</mml:mi><mml:mi mathvariant="normal">t</mml:mi></mml:mrow></mml:mrow></mml:msub></mml:math><tex-math id="inft332">\begin{document}$q_{\mathrm{lr}}\times q_{\mathrm{it}}$\end{document}</tex-math></alternatives></inline-formula>)</th></tr></thead><tbody><tr><td align="char" char="hyphen" valign="bottom">2-step</td><td align="left" valign="bottom"><inline-formula><alternatives><mml:math id="inf333"><mml:msub><mml:mi>z</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:math><tex-math id="inft333">\begin{document}$z_{1}$\end{document}</tex-math></alternatives></inline-formula></td><td align="char" char="." valign="bottom">−0.613*</td><td align="char" char="." valign="bottom">0.096*</td><td align="char" char="." valign="bottom">0.064*</td><td align="char" char="." valign="bottom">−0.035*</td></tr><tr><td align="left" valign="bottom"/><td align="left" valign="bottom"><inline-formula><alternatives><mml:math id="inf334"><mml:msub><mml:mi>z</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mn>2</mml:mn></mml:mrow></mml:msub></mml:math><tex-math id="inft334">\begin{document}$z_{2}$\end{document}</tex-math></alternatives></inline-formula></td><td align="char" char="." valign="bottom">0.634*</td><td align="char" char="." valign="bottom">−0.079*</td><td align="char" char="." valign="bottom">−0.066*</td><td align="char" char="." valign="bottom">0.028</td></tr><tr><td align="char" char="hyphen" valign="bottom">3-step</td><td align="left" valign="bottom"><inline-formula><alternatives><mml:math id="inf335"><mml:msub><mml:mi>z</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:math><tex-math id="inft335">\begin{document}$z_{1}$\end{document}</tex-math></alternatives></inline-formula></td><td align="char" char="." valign="bottom">1.157*</td><td align="char" char="." valign="bottom">−0.388*</td><td align="char" char="." valign="bottom">−0.121*</td><td align="char" char="." valign="bottom">−0.148*</td></tr><tr><td align="left" valign="bottom"/><td align="left" valign="bottom"><inline-formula><alternatives><mml:math id="inf336"><mml:msub><mml:mi>z</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mn>2</mml:mn></mml:mrow></mml:msub></mml:math><tex-math id="inft336">\begin{document}$z_{2}$\end{document}</tex-math></alternatives></inline-formula></td><td align="char" char="." valign="bottom">−0.646*</td><td align="char" char="." valign="bottom">0.183*</td><td align="char" char="." valign="bottom">0.061*</td><td align="char" char="." valign="bottom">−0.071*</td></tr></tbody></table></table-wrap><fig id="app1fig4" position="float"><label>Appendix 1—figure 4.</label><caption><title>Mapping of Q-learning parameters to the individual latent space for the 2-step MDP task.</title><p>Each plot shows one dimension of the latent representation (<inline-formula><alternatives><mml:math id="inf337"><mml:msub><mml:mi>z</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:math><tex-math id="inft337">\begin{document}$z_{1}$\end{document}</tex-math></alternatives></inline-formula> or <inline-formula><alternatives><mml:math id="inf338"><mml:msub><mml:mi>z</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mn>2</mml:mn></mml:mrow></mml:msub></mml:math><tex-math id="inft338">\begin{document}$z_{2}$\end{document}</tex-math></alternatives></inline-formula>) as a function of either the learning rate (<inline-formula><alternatives><mml:math id="inf339"><mml:mstyle><mml:mrow><mml:mstyle displaystyle="false"><mml:msub><mml:mi>q</mml:mi><mml:mrow><mml:mrow><mml:mi mathvariant="normal">l</mml:mi><mml:mi mathvariant="normal">r</mml:mi></mml:mrow></mml:mrow></mml:msub></mml:mstyle></mml:mrow></mml:mstyle></mml:math><tex-math id="inft339">\begin{document}$q_{\rm{lr}}$\end{document}</tex-math></alternatives></inline-formula>, left) or the inverse temperature (<inline-formula><alternatives><mml:math id="inf340"><mml:mstyle><mml:mrow><mml:mstyle displaystyle="false"><mml:msub><mml:mi>q</mml:mi><mml:mrow><mml:mrow><mml:mi mathvariant="normal">i</mml:mi><mml:mi mathvariant="normal">t</mml:mi></mml:mrow></mml:mrow></mml:msub></mml:mstyle></mml:mrow></mml:mstyle></mml:math><tex-math id="inft340">\begin{document}$q_{\rm{it}}$\end{document}</tex-math></alternatives></inline-formula>, right) of simulated Q-learning agents. Black dots represent the latent representation from the agent’s behavior, while blue dots show the GLM fit.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-107163-app1-fig4-v1.tif"/></fig></sec><sec sec-type="appendix" id="s8-5"><title>Relationship between prediction performance and latent space for Q-learning agents</title><p>We evaluated how the individual latent representation influenced prediction performance for the simulated Q-learning agents. Similar to the analysis on human data, <xref ref-type="fig" rid="app1fig5">Appendix 1—figure 5</xref> illustrates the prediction performance as a function of the distance in the individual latent representation space in a cross-individual scenario. Using a GLM, we found that the distance was a significant predictor of both negative log-likelihood (transfer direction 3→2: <inline-formula><alternatives><mml:math id="inf341"><mml:msub><mml:mi>β</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>d</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mn>0.094</mml:mn></mml:math><tex-math id="inft341">\begin{document}$\beta_{d}=0.094$\end{document}</tex-math></alternatives></inline-formula>, <inline-formula><alternatives><mml:math id="inf342"><mml:mi>p</mml:mi><mml:mo>&lt;</mml:mo><mml:mn>0.001</mml:mn></mml:math><tex-math id="inft342">\begin{document}$p \lt 0.001$\end{document}</tex-math></alternatives></inline-formula>, 2→3: <inline-formula><alternatives><mml:math id="inf343"><mml:msub><mml:mi>β</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>d</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mn>0.164</mml:mn></mml:math><tex-math id="inft343">\begin{document}$\beta_{d}=0.164$\end{document}</tex-math></alternatives></inline-formula>, <inline-formula><alternatives><mml:math id="inf344"><mml:mi>p</mml:mi><mml:mo>&lt;</mml:mo><mml:mn>0.001</mml:mn></mml:math><tex-math id="inft344">\begin{document}$p \lt 0.001$\end{document}</tex-math></alternatives></inline-formula>) and the rate for behavior matched (3→2: <inline-formula><alternatives><mml:math id="inf345"><mml:msub><mml:mi>β</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>d</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mo>−</mml:mo><mml:mn>0.069</mml:mn></mml:math><tex-math id="inft345">\begin{document}$\beta_{d}=-0.069$\end{document}</tex-math></alternatives></inline-formula>, <inline-formula><alternatives><mml:math id="inf346"><mml:mi>p</mml:mi><mml:mo>&lt;</mml:mo><mml:mn>0.001</mml:mn></mml:math><tex-math id="inft346">\begin{document}$p \lt 0.001$\end{document}</tex-math></alternatives></inline-formula>, 2→3: <inline-formula><alternatives><mml:math id="inf347"><mml:msub><mml:mi>β</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>d</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mo>−</mml:mo><mml:mn>0.097</mml:mn></mml:math><tex-math id="inft347">\begin{document}$\beta_{d}=-0.097$\end{document}</tex-math></alternatives></inline-formula>, <inline-formula><alternatives><mml:math id="inf348"><mml:mi>p</mml:mi><mml:mo>&lt;</mml:mo><mml:mn>0.001</mml:mn></mml:math><tex-math id="inft348">\begin{document}$p \lt 0.001$\end{document}</tex-math></alternatives></inline-formula>). This result shows that, as with human data, prediction performance for an agent degrades as the latent distance to the source agent increases, confirming that the latent space captures the behavioral tendencies of the simulated agents.</p><fig id="app1fig5" position="float"><label>Appendix 1—figure 5.</label><caption><title>Prediction performances for Q-learning agents as a function of latent space distance.</title><p>The plots show negative log-likelihood (left) and rate for behavior matched (right) in a cross-individual scenario. (<bold>A</bold>) 3-step to 2-step transfer. (<bold>B</bold>) 2-step to 3-step transfer.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-107163-app1-fig5-v1.tif"/></fig></sec></sec><sec sec-type="appendix" id="s9"><title>Additional results on the MNIST task</title><sec sec-type="appendix" id="s9-1"><title>EIDT training</title><p><xref ref-type="fig" rid="app1fig6">Appendix 1—figure 6</xref> shows representative training and validation loss curves for the EIDT models in the MNIST task. As with the MDP task, these curves are from a model trained from all participants’ data for illustrative purposes, showing the typical convergence behavior.</p><fig id="app1fig6" position="float"><label>Appendix 1—figure 6.</label><caption><title>Representatives training and validation curves for EIDT models in the MNIST task for each of the 12 transfer directions.</title><p>Training was stopped at the epoch with the minimum validation loss, indicated by the start marker.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-107163-app1-fig6-v1.tif"/></fig></sec><sec sec-type="appendix" id="s9-2"><title>Individual latent representation</title><p><xref ref-type="fig" rid="app1fig7">Appendix 1—figure 7</xref> shows the individual latent representations computed from participants’ behaviors for each of the 12 transfer directions in the MNIST task. As we adopted a leave-one-participant-out cross-validation, there were several encoders for each training run. The displayed representations are representatives from a training run using all participants’ data.</p><fig id="app1fig7" position="float"><label>Appendix 1—figure 7.</label><caption><title>Individual latent representations derived from human participants’ behaviors in the MNIST task.</title><p>Each panel shows the two-dimensional latent space generated when using a different experimental condition as the source.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-107163-app1-fig7-v1.tif"/></fig></sec><sec sec-type="appendix" id="s9-3"><title>Relationship between prediction performance and individual latent representation</title><p>We performed a cross-individual analysis for the MNIST task, identical to the one conducted for the MDP task. The prediction performance of a task solver derived from one participant (Participant <italic>l</italic>) was evaluated on the data of another participant (Participant <italic>k</italic>), and this performance was analyzed as a function of the distance between their latent representations (<inline-formula><alternatives><mml:math id="inf349"><mml:msub><mml:mi>d</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>k</mml:mi><mml:mo>,</mml:mo><mml:mi>l</mml:mi></mml:mrow></mml:msub></mml:math><tex-math id="inft349">\begin{document}$d_{k,l}$\end{document}</tex-math></alternatives></inline-formula>).</p><p>The results are shown in <xref ref-type="fig" rid="app1fig8">Appendix 1—figure 8</xref> (for negative log-likelihood) and <xref ref-type="fig" rid="app1fig9">Appendix 1—figure 9</xref> (for rate for behavior matched). In all 12 transfer directions, prediction performance degraded significantly as the distance in the latent space increased. This was confirmed by fitting a GLM:<disp-formula id="equ14"><label>(14)</label><alternatives><mml:math id="m14"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msub><mml:mi>y</mml:mi><mml:mrow><mml:mi>k</mml:mi><mml:mo>,</mml:mo><mml:mi>l</mml:mi></mml:mrow></mml:msub><mml:mo>∼</mml:mo><mml:mtext>Gamma</mml:mtext><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>log</mml:mi><mml:mo>⁡</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>β</mml:mi><mml:mrow><mml:msub><mml:mtext>participant</mml:mtext><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mi>β</mml:mi><mml:mrow><mml:mi>d</mml:mi></mml:mrow></mml:msub><mml:msub><mml:mi>d</mml:mi><mml:mrow><mml:mi>k</mml:mi><mml:mo>,</mml:mo><mml:mi>l</mml:mi></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mi>β</mml:mi><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mstyle></mml:mrow></mml:mstyle></mml:math><tex-math id="t14">\begin{document}$$\displaystyle y_{k,l}\sim\text{Gamma}\left(\log(\beta_{\text{participant}_{k}}+\beta_{d}d_{k,l}+\beta_{0})\right)$$\end{document}</tex-math></alternatives></disp-formula></p><fig id="app1fig8" position="float"><label>Appendix 1—figure 8.</label><caption><title>Prediction performance (negative log-likelihood) as a function of latent space distance in the MNIST task.</title><p>Each panel shows the results for one of the 12 transfer directions. The negative log-likelihood (vertical axis) increases as the distance between the source and target individuals’ latent representations (horizontal axis) increases, indicating worse prediction performance. The solid line is the GLM fit.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-107163-app1-fig8-v1.tif"/></fig><fig id="app1fig9" position="float"><label>Appendix 1—figure 9.</label><caption><title>Prediction performance (rate for behavior matched) as a function of latent space distance in the MNIST task.</title><p>Each panel shows the results for one of the 12 transfer directions. The rate for behavior matched (vertical axis) decreases as the distance between individuals’ latent representations (horizontal axis) increases. The solid line is the GLM fit.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-107163-app1-fig9-v1.tif"/></fig><p>The fitted coefficients for the distance term (<inline-formula><alternatives><mml:math id="inf350"><mml:msub><mml:mi>β</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>d</mml:mi></mml:mrow></mml:msub></mml:math><tex-math id="inft350">\begin{document}$\beta_{d}$\end{document}</tex-math></alternatives></inline-formula>), shown in <xref ref-type="table" rid="app1table2">Appendix 1—table 2</xref>, were significant for all transfer directions (<inline-formula><alternatives><mml:math id="inf351"><mml:mi>p</mml:mi><mml:mo>&lt;</mml:mo><mml:mn>0.001</mml:mn></mml:math><tex-math id="inft351">\begin{document}$p \lt 0.001$\end{document}</tex-math></alternatives></inline-formula>), reinforcing the conclusion that the latent space captures meaningful individual differences.</p><table-wrap id="app1table2" position="float"><label>Appendix 1—table 2.</label><caption><title>GLM fitting coefficients (<inline-formula><alternatives><mml:math id="inf352"><mml:msub><mml:mi>β</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>d</mml:mi></mml:mrow></mml:msub></mml:math><tex-math id="inft352">\begin{document}$\beta_{d}$\end{document}</tex-math></alternatives></inline-formula>) for the effect of latent space distance on prediction performance in the MNIST task.</title><p>All coefficients are statistically significant (<inline-formula><alternatives><mml:math id="inf353"><mml:mi>p</mml:mi><mml:mo>&lt;</mml:mo><mml:mn>0.001</mml:mn></mml:math><tex-math id="inft353">\begin{document}$p \lt 0.001$\end{document}</tex-math></alternatives></inline-formula>).</p></caption><table frame="hsides" rules="groups"><thead><tr><th align="left" valign="bottom" colspan="6">Negative log-likelihood</th></tr></thead><tbody><tr><td align="left" valign="bottom"/><td align="left" valign="bottom"/><td align="left" valign="bottom" colspan="4">Target</td></tr><tr><td align="left" valign="bottom"/><td align="left" valign="bottom"/><td align="left" valign="bottom">EA</td><td align="left" valign="bottom">ES</td><td align="left" valign="bottom">DA</td><td align="left" valign="bottom">DS</td></tr><tr><td align="left" valign="bottom" rowspan="4">Source</td><td align="left" valign="bottom">EA</td><td align="left" valign="bottom">—</td><td align="left" valign="bottom">0.202</td><td align="left" valign="bottom">0.102</td><td align="left" valign="bottom">0.110</td></tr><tr><td align="left" valign="bottom">ES</td><td align="left" valign="bottom">0.117</td><td align="left" valign="bottom">—</td><td align="left" valign="bottom">0.185</td><td align="left" valign="bottom">0.111</td></tr><tr><td align="left" valign="bottom">DA</td><td align="left" valign="bottom">0.199</td><td align="left" valign="bottom">0.158</td><td align="left" valign="bottom">—</td><td align="left" valign="bottom">0.076</td></tr><tr><td align="left" valign="bottom">DS</td><td align="left" valign="bottom">0.201</td><td align="left" valign="bottom">0.186</td><td align="left" valign="bottom">0.174</td><td align="left" valign="bottom">—</td></tr><tr><th align="left" valign="bottom" colspan="6">Rate for behavior matched</th></tr><tr><td align="left" valign="bottom"/><td align="left" valign="bottom"/><td align="left" valign="bottom" colspan="4">Target</td></tr><tr><td align="left" valign="bottom"/><td align="left" valign="bottom"/><td align="left" valign="bottom">EA</td><td align="left" valign="bottom">ES</td><td align="left" valign="bottom">DA</td><td align="left" valign="bottom">DS</td></tr><tr><td align="left" valign="bottom" rowspan="4">Source</td><td align="left" valign="bottom">EA</td><td align="left" valign="bottom">—</td><td align="left" valign="bottom">−0.142</td><td align="left" valign="bottom">−0.103</td><td align="left" valign="bottom">−0.187</td></tr><tr><td align="left" valign="bottom">ES</td><td align="left" valign="bottom">−0.053</td><td align="left" valign="bottom">—</td><td align="left" valign="bottom">−0.193</td><td align="left" valign="bottom">−0.214</td></tr><tr><td align="left" valign="bottom">DA</td><td align="left" valign="bottom">−0.076</td><td align="left" valign="bottom">−0.115</td><td align="left" valign="bottom">—</td><td align="left" valign="bottom">−0.118</td></tr><tr><td align="left" valign="bottom">DS</td><td align="left" valign="bottom">−0.086</td><td align="left" valign="bottom">−0.270</td><td align="left" valign="bottom">−0.185</td><td align="left" valign="bottom">—</td></tr></tbody></table></table-wrap></sec></sec></app></app-group></back><sub-article article-type="editor-report" id="sa0"><front-stub><article-id pub-id-type="doi">10.7554/eLife.107163.3.sa0</article-id><title-group><article-title>eLife Assessment</article-title></title-group><contrib-group><contrib contrib-type="author"><name><surname>Li</surname><given-names>Jian</given-names></name><role specific-use="editor">Reviewing Editor</role><aff><institution>Peking University</institution><country>China</country></aff></contrib></contrib-group><kwd-group kwd-group-type="evidence-strength"><kwd>Solid</kwd></kwd-group><kwd-group kwd-group-type="claim-importance"><kwd>Valuable</kwd></kwd-group></front-stub><body><p>This revised paper provides a <bold>valuable</bold> and novel neural network-based framework for parameterizing individual differences and predicting individual decision-making across task conditions. The methods and analyses are <bold>solid</bold> yet could benefit from further validation of the superiority of the proposed framework against other baseline models. With these concerns addressed, this study would offer a proof-of-concept neural network approach to scientists working on the generalization of cognitive skills across contexts.</p></body></sub-article><sub-article article-type="referee-report" id="sa1"><front-stub><article-id pub-id-type="doi">10.7554/eLife.107163.3.sa1</article-id><title-group><article-title>Reviewer #1 (Public review):</article-title></title-group><contrib-group><contrib contrib-type="author"><anonymous/><role specific-use="referee">Reviewer</role></contrib></contrib-group></front-stub><body><p>Summary</p><p>The manuscript presents EIDT, a framework that extracts an &quot;individuality index&quot; from a source task to predict a participant's behaviour in a related target task under different conditions. However, the evidence that it truly enables cross-task individuality transfer is not convincing.</p><p>Strengths</p><p>The EIDT framework is clearly explained, and the experimental design and results are generally well-described. The performance of the proposed method is tested on two distinct paradigms: a Markov Decision Process (MDP) task (comparing 2-step and 3-step versions) and a handwritten digit recognition (MNIST) task under various conditions of difficulty and speed pressure. The results indicate that the EIDT framework generally achieved lower prediction error compared to baseline models and that it was better at predicting a specific individual's behaviour when using their own individuality index compared to using indices from others.</p><p>Furthermore, the individuality index appeared to form distinct clusters for different individuals, and the framework was better at predicting a specific individual's behaviour when using their own derived index compared to using indices from other individuals.</p><p>Comments on revisions:</p><p>I thank the author for the additional analyses. They have fully addressed all of my previous concerns, and I have no further recommendations.</p></body></sub-article><sub-article article-type="referee-report" id="sa2"><front-stub><article-id pub-id-type="doi">10.7554/eLife.107163.3.sa2</article-id><title-group><article-title>Reviewer #2 (Public review):</article-title></title-group><contrib-group><contrib contrib-type="author"><anonymous/><role specific-use="referee">Reviewer</role></contrib></contrib-group></front-stub><body><p>This paper introduces a framework for modeling individual differences in decision-making by learning a low-dimensional representation (the &quot;individuality index&quot;) from one task and using it to predict behaviour in a different task. The approach is evaluated on two types of tasks: a sequential value-based decision-making task and a perceptual decision task (MNIST). The model shows improved prediction accuracy when incorporating this learned representation compared to baseline models.</p><p>The motivation is solid, and the modelling approach is interesting, especially the use of individual embeddings to enable cross-task generalization. That said, several aspects of the evaluation and analysis could be strengthened.</p><p>(1) The MNIST SX baseline appears weak. RTNet isn't directly comparable in structure or training. A stronger baseline would involve training the GRU directly on the task without using the individuality index-e.g., by fixing the decoder head. This would provide a clearer picture of what the index contributes.</p><p>(2) Although the focus is on prediction, the framework could offer more insight into how behaviour in one task generalizes to another. For example, simulating predicted behaviours while varying the individuality index might help reveal what behavioural traits it encodes.</p><p>(3) It's not clear whether the model can reproduce human behaviour when acting on-policy. Simulating behaviour using the trained task solver and comparing it with actual participant data would help assess how well the model captures individual decision tendencies.</p><p>(4) Figures 3 and S1 aim to show that individuality indices from the same participant are closer together than those from different participants. However, this isn't fully convincing from the visualizations alone. Including a quantitative presentation would help support the claim.</p><p>(5) The transfer scenarios are often between very similar task conditions (e.g., different versions of MNIST or two-step vs three-step MDP). This limits the strength of the generalization claims. In particular, the effects in the MNIST experiment appear relatively modest, and the transfer is between experimental conditions within the same perceptual task. To better support the idea of generalizing behavioural traits across tasks, it would be valuable to include transfers across more structurally distinct tasks.</p><p>(6) For both experiments, it would help to show basic summaries of participants' behavioural performance. For example, in the MDP task, first-stage choice proportions based on transition types are commonly reported. These kinds of benchmarks provide useful context.</p><p>(7) For the MDP task, consider reporting the number or proportion of correct choices in addition to negative log-likelihood. This would make the results more interpretable.</p><p>(8) In Figure 5, what is the difference between the &quot;% correct&quot; and &quot;% match to behaviour&quot;? If so, it would help to clarify the distinction in the text or figure captions.</p><p>(9) For the cognitive model, it would be useful to report the fitted parameters (e.g., learning rate, inverse temperature) per individual. This can offer insight into what kinds of behavioural variability the individuality index might be capturing.</p><p>(10) A few of the terms and labels in the paper could be made more intuitive. For example, the name &quot;individuality index&quot; might give the impression of a scalar value rather than a latent vector, and the labels &quot;SX&quot; and &quot;SY&quot; are somewhat arbitrary. You might consider whether clearer or more descriptive alternatives would help readers follow the paper more easily.</p><p>(11) Please consider including training and validation curves for your models. These would help readers assess convergence, overfitting, and general training stability, especially given the complexity of the encoder-decoder architecture.</p><p>Comments on revisions:</p><p>Thank you to the authors for the updated manuscript. The authors have addressed the majority of my concerns, and the paper is now in a much better form.</p><p>Regarding my previous Comment 6, I still believe it would be helpful to include a graph similar to what is typically reported for these tasks-specifically, a breakdown of choices based on rare versus common transitions (see Model-Based Influences on Humans' Choices and Striatal Prediction Errors, Figure 2). Presenting this for both the actual behaviour and the simulated data would strengthen the paper and allow for clearer comparison.</p></body></sub-article><sub-article article-type="referee-report" id="sa3"><front-stub><article-id pub-id-type="doi">10.7554/eLife.107163.3.sa3</article-id><title-group><article-title>Reviewer #3 (Public review):</article-title></title-group><contrib-group><contrib contrib-type="author"><anonymous/><role specific-use="referee">Reviewer</role></contrib></contrib-group></front-stub><body><p>Summary:</p><p>This work presents a novel neural network-based framework for parameterizing individual differences in human behavior. Using two distinct decision-making experiments, the author demonstrates the approach's potential and claims it can predict individual behavior (1) within the same task, (2) across different tasks, and (3) across individuals. While the goal of capturing individual variability is compelling and the potential applications are promising, the claims are weakly supported, and I find that the underlying problem is conceptually ill-defined.</p><p>Strengths:</p><p>The idea of using neural networks for parameterizing individual differences in human behavior is novel, and the potential applications can be impactful.</p><p>Weaknesses:</p><p>(1) To demonstrate the effectiveness of the approach, the authors compare a Q-learning cognitive model (for the MDP task) and RTNet (for the MNIST task) against the proposed framework. However, as I understand it, neither the cognitive model nor RTNet is designed to fit or account for individual variability. If that is the case, it is unclear why these models serve as appropriate baselines. Isn't it expected that a model explicitly fitted to individual data would outperform models that do not? If so, does the observed superiority of the proposed framework simply reflect the unsurprising benefit of fitting individual variability? I think the authors should either clarify why these models constitute fair control or validate the proposed approach against stronger and more appropriate baselines.</p><p>(2) It's not very clear in the results section what it means by having a shorter within-individual distance than between-individual distances. Related to the comment above, is there any control analysis performed for this? Also, this analysis appears to have nothing to do with predicting individual behavior. Is this evidence toward successfully parameterizing individual differences? Could this be task-dependent, especially since the transfer is evaluated on exceedingly similar tasks in both experiments? I think a bit more discussion of the motivation and implications of these results will help the reader in making sense of this analysis.</p><p>(3) The authors have to better define what exactly he meant by transferring across different &quot;tasks&quot; and testing the framework in &quot;more distinctive tasks&quot;. All presented evidence, taken at face value, demonstrated transferring across different &quot;conditions&quot; of the same task within the same experiment. It is unclear to me how generalizable the framework will be when applied to different tasks.</p><p>(4) Conceptually, it is also unclear to me how plausible it is that the framework could generalize across tasks spanning multiple cognitive domains (if that's what is meant by more distinctive). For instance, how can an individual's task performance on a Posner task predict task performance on the Cambridge face memory test? Which part of the framework could have enabled such a cross-domain prediction of task performance? I think these have to be at least discussed to some extent, since without it the future direction is meaningless.</p><p>(5) How is the negative log-likelihood, which seems to be the main metric for comparison, computed? Is this based on trial-by-trial response prediction or probability of responses, as what usually performed in cognitive modelling?</p><p>(6) None of the presented evidence is cross-validated. The authors should consider performing K-fold cross-validation on the train, test, and evaluation split of subjects to ensure robustness of the findings.</p><p>(7) The authors excluded 25 subjects (20% of the data) for different reasons. This is a substantial proportion, especially by the standards of what is typically observed in behavioral experiments. The authors should provide a clear justification for these exclusion criteria and, if possible, cite relevant studies that support the use of such stringent thresholds.</p><p>(8) The authors should do a better job of creating the figures and writing the figure captions. It is unclear which specific claim the authors are addressing with the figure. For example, what is the key message of Figure 2C regarding transfer within and across participants? Why are the stats presentation different between the Cognitive model and the EIDT framework plots? In Figure 3, it's unclear what these dots and clusters represent and how they support the authors' claim that the same individual forms clusters. And isn't this experiment have 98 subjects after exclusion, this plot has way less than 98 dots as far as I can tell. Furthermore, I find Figure 5 particularly confusing, as the underlying claim it is meant to illustrate is unclear. Clearer figures and more informative captions are needed to guide the reader effectively.</p><p>(9) I also find the writing somewhat difficult to follow. The subheadings are confusing, and it's often unclear which specific claim the authors are addressing. The presentation of results feels disorganized, making it hard to trace the evidence supporting each claim. Also, the excessive use of acronyms (e.g., SX, SY, CG, EA, ES, DA, DS) makes the text harder to parse. I recommend restructuring the results section to be clearer and significantly reducing the use of unnecessary acronyms.</p><p>Comments on revisions:</p><p>The authors have addressed my previous comments with great care and detail. I appreciate the additional analyses and edits. I have no further comments.</p></body></sub-article><sub-article article-type="author-comment" id="sa4"><front-stub><article-id pub-id-type="doi">10.7554/eLife.107163.3.sa4</article-id><title-group><article-title>Author response</article-title></title-group><contrib-group><contrib contrib-type="author"><name><surname>Higashi</surname><given-names>Hiroshi</given-names></name><role specific-use="author">Author</role><aff><institution>The University of Osaka</institution><addr-line><named-content content-type="city">Suita</named-content></addr-line><country>Japan</country></aff></contrib></contrib-group></front-stub><body><p>The following is the authors’ response to the original reviews.</p><disp-quote content-type="editor-comment"><p><bold>Public Reviews:</bold></p><p><bold>Reviewer #1 (Public review):</bold></p><p>Because the &quot;source&quot; and &quot;target&quot; tasks are merely parameter variations of the same paradigm, it is unclear whether EIDT achieves true crosstask transfer. The manuscript provides no measure of how consistent each participant's behaviour is across these variants (e.g., two- vs threestep MDP; easy vs difficult MNIST). Without this measure, the transfer results are hard to interpret. In fact, Figure 5 shows a notable drop in accuracy when transferring between the easy and difficult MNIST conditions, compared to transfers between accuracy-focused and speedfocused conditions. Does this discrepancy simply reflect larger withinparticipant behavioural differences between the easy and difficult settings? A direct analysis of intra-individual similarity for each task pair and how that similarity is related to EIDT's transfer performance is needed.</p></disp-quote><p>Thank you for your insightful comment. We agree that the tasks used in our study are variations of the same paradigm. Accordingly, we have revised the manuscript to consistently frame our findings as demonstrating individuality transfer &quot;across task conditions&quot; rather than &quot;across distinct tasks.&quot;</p><p>In response to your suggestion, we have conducted a new analysis to directly investigate the relationship between individual behavioural patterns and transfer performance. As show in the new Figures 4, 11, S8, and S9, we found a clear relationship between the distance in the space of individual latent representation (called individuality index in the previous manuscript) and prediction performance. Specifically, prediction accuracy for a given individual's behaviour degrades as the latent representation of the model's source individual becomes more distant. This result directly demonstrates that our framework captures meaningful individual differences that are predictive of transfer performance across conditions.</p><p>We have also expanded the Discussion (Lines 332--343) to address the potential for applying this framework to more structurally distinct tasks, hypothesizing that this would rely on shared underlying cognitive functions.</p><disp-quote content-type="editor-comment"><p>Related to the previous comment, the individuality index is central to the framework, yet remains hard to interpret. It shows much greater within-participant variability in the MNIST experiment (Figure S1) than in the MDP experiment (Figure 3). Is such a difference meaningful? It is hard to know whether it reflects noisier data, greater behavioural flexibility, or limitations of the model.</p></disp-quote><p>Thank you for raising this important point about interpretability. To enhance the interpretability of the individual latent representation, we have added a new analysis for the MDP task (see Figures 6 and S4). By applying our trained encoder to data from simulated Q-learning agents with known parameters, we demonstrate that the dimensions of the latent space systematically map onto the agents' underlying cognitive parameters (learning rate and inverse temperature). This analysis provides a clearer interpretation by linking our model's data-driven representation to established theoretical constructs.</p><p>Regarding the greater within-participant variability observed in the MNIST task (visualized now in Figure S7), this could be attributed to several factors, such as greater behavioural flexibility in the perceptual task. However, disentangling these potential factors is complex and falls outside the primary scope of the current study, which prioritizes demonstrating robust prediction accuracy across different task conditions.</p><disp-quote content-type="editor-comment"><p>The authors suggests that the model's ability to generalize to new participants &quot;likely relies on the fact that individuality indices form clusters and individuals similar to new participants exist in the training participant pool&quot;. It would be helpful to directly test this hypothesis by quantifying the similarity (or distance) of each test participant's individuality index to the individuals or identified clusters within the training set, and assessing whether greater similarity (or closer proximity) to the clusters in the training set is associated with higher prediction accuracy for those individuals in the test set.</p></disp-quote><p>Thank you for this excellent suggestion. We have performed the analysis you proposed to directly test this hypothesis. Our new results, presented in Figures 4, 11, S5, S8, and S9, quantify the distance between the latent representation of a test participant and that of the source participant used to generate the prediction model.</p><p>The results show a significant negative correlation: prediction accuracy consistently decreases as the distance in the latent space increases. This confirms that generalization performance is directly tied to the similarity of behavioural patterns as captured by our latent representation, strongly supporting our hypothesis.</p><disp-quote content-type="editor-comment"><p><bold>Reviewer #2 (Public review):</bold></p><p>The MNIST SX baseline appears weak. RTNet isn't directly comparable in structure or training. A stronger baseline would involve training the GRU directly on the task without using the individuality index-e.g., by fixing the decoder head. This would provide a clearer picture of what the index contributes.</p></disp-quote><p>We agree that a more direct baseline is crucial for evaluating the contribution of our transfer mechanism. For the Within-Condition Prediction scenario, the comparison with RTNet was intended only to validate that our task solver architecture could achieve average humanlevel task performance (Figure 7).</p><p>For the critical Cross-Condition Transfer scenario, we have now implemented a stronger and more appropriate baseline, which we call ``task solver (source).'' This model has the same architecture as our EIDT task solver but is trained directly on the source task data of the specific test participant. As shown in revised Figure 9, our EIDT framework significantly outperforms this direct-training approach, clearly demonstrating the benefit of the individuality transfer mechanism.</p><disp-quote content-type="editor-comment"><p>Although the focus is on prediction, the framework could offer more insight into how behaviour in one task generalizes to another. For example, simulating predicted behaviours while varying the individuality index might help reveal what behavioural traits it encodes.</p></disp-quote><p>Thank you for this valuable suggestion. To provide more insight into the encoded behavioural traits, we have conducted a new analysis linking the individual latent representation to a theoretical cognitive model. As detailed in the revised manuscript (Figures 6 and S4), we applied our encoder to simulated data from Q-learning agents with varying parameters. The results show a systematic relationship between the latent space coordinates and the agents' learning rates and inverse temperatures, providing a clearer interpretation of what the representation captures.</p><disp-quote content-type="editor-comment"><p>It's not clear whether the model can reproduce human behaviour when acting on-policy. Simulating behaviour using the trained task solver and comparing it with actual participant data would help assess how well the model captures individual decision tendencies.</p></disp-quote><p>We have added the suggested on-policy evaluation (Lines 195--207). In the revised manuscript (Figure 5), we present results from simulations where the trained task solvers performed the MDP task. We compared their performance (total reward and rate of the highly-rewarding action selected) against their corresponding human participants. The strong correlations observed demonstrate that our model successfully captures and reproduces individual-specific behavioural tendencies in an onpolicy setting.</p><disp-quote content-type="editor-comment"><p>Figures 3 and S1 aim to show that individuality indices from the same participant are closer together than those from different participants. However, this isn't fully convincing from the visualizations alone. Including a quantitative presentation would help support the claim.</p></disp-quote><p>We agree that the original visualizations of inter- and intraparticipant distances was not sufficiently convincing. We have therefore removed that analysis. In its place, we have introduced a more direct and quantitative analysis that explicitly links the individual latent representation to prediction performance (see Figures 4, 11, S5, S8, and S9). This new analysis demonstrates that prediction error for an individual is a function of distance in the latent space, providing stronger evidence that the representation captures meaningful, individual-specific information.</p><disp-quote content-type="editor-comment"><p>The transfer scenarios are often between very similar task conditions (e.g., different versions of MNIST or two-step vs three-step MDP). This limits the strength of the generalization claims. In particular, the effects in the MNIST experiment appear relatively modest, and the transfer is between experimental conditions within the same perceptual task. To better support the idea of generalizing behavioural traits across tasks, it would be valuable to include transfers across more structurally distinct tasks.</p></disp-quote><p>We agree with this limitation and have revised the manuscript to be more precise. We now frame our contribution as &quot;individuality transfer across task conditions&quot; rather than &quot;across tasks&quot; to accurately reflect the scope of our experiments. We have also expanded the Discussion section (Line 332-343) to address the potential and challenges of applying this framework to more structurally distinct tasks, noting that it would likely depend on shared underlying cognitive functions.</p><disp-quote content-type="editor-comment"><p>For both experiments, it would help to show basic summaries of participants' behavioural performance. For example, in the MDP task, first-stage choice proportions based on transition types are commonly reported. These kinds of benchmarks provide useful context.</p></disp-quote><p>We have added behavioral performance summaries as requested. For the MDP task, Figure 5 now compares the total reward and rate of highlyrewarding action selected between humans and our model. For the MNIST task, Figure 7 shows the rate of correct responses for humans, RTNet, and our task solver across all conditions. These additions provide better context for the model's performance.</p><disp-quote content-type="editor-comment"><p>For the MDP task, consider reporting the number or proportion of correct choices in addition to negative log-likelihood. This would make the results more interpretable.</p></disp-quote><p>Thank you for the suggestion. To make the results more interpretable, we have added a new prediction performance metric: the rate for behaviour matched. This metric measures the proportion of trials where the model's predicted action matches the human's actual choice. This is now included alongside the negative log-likelihood in Figures 2, 3, 4, 8, 9, and 11.</p><disp-quote content-type="editor-comment"><p>In Figure 5, what is the difference between the &quot;% correct&quot; and &quot;% match to behaviour&quot;? If so, it would help to clarify the distinction in the text or figure captions.</p></disp-quote><p>We have clarified these terms in the revised manuscript. As defined in the Result section (Lines 116--122, 231), &quot;%correct&quot; (now &quot;rate of correct responses&quot;) is a measure of task performance, whereas &quot;%match to behaviour&quot; (now &quot;rate for behaviour matched&quot;) is a measure of prediction accuracy.</p><disp-quote content-type="editor-comment"><p>For the cognitive model, it would be useful to report the fitted parameters (e.g., learning rate, inverse temperature) per individual. This can offer insight into what kinds of behavioural variability the individual latent representation might be capturing.</p></disp-quote><p>We have added histograms of the fitted Q-learning parameters for the human participants in Supplementary Materials (Figure S1). This analysis revealed which parameters varied most across the population and directly informed the design of our subsequent simulation study with Q-learning agents (see response to Comment 2-2), where we linked these parameters to the individual latent representation (Lines 208--223).</p><disp-quote content-type="editor-comment"><p>A few of the terms and labels in the paper could be made more intuitive. For example, the name &quot;individuality index&quot; might give the impression of a scalar value rather than a latent vector, and the labels &quot;SX&quot; and &quot;SY&quot; are somewhat arbitrary. You might consider whether clearer or more descriptive alternatives would help readers follow the paper more easily.</p></disp-quote><p>We have adopted the suggested changes for clarity.</p><p>&quot;Individuality index&quot; has been changed to &quot;individual latent representation&quot;.</p><p>&quot;Situation SX&quot; and &quot;Situation SY&quot; have been renamed to the more descriptive &quot;Within-Condition Prediction&quot; and &quot;Cross-Condition Transfer&quot;, respectively.</p><p>We have also added a table in Figure 7 to clarify the MNIST condition acronyms (EA/ES/DA/DS).</p><disp-quote content-type="editor-comment"><p>Please consider including training and validation curves for your models. These would help readers assess convergence, overfitting, and general training stability, especially given the complexity of the encoder-decoder architecture.</p></disp-quote><p>Training and validation curves for both the MDP and MNIST tasks have been added to Supplementary Materials (Figure S2 and S6) to show model convergence and stability.</p><disp-quote content-type="editor-comment"><p><bold>Reviewer #3 (Public review):</bold></p><p>To demonstrate the effectiveness of the approach, the authors compare a Q-learning cognitive model (for the MDP task) and RTNet (for the MNIST task) against the proposed framework. However, as I understand it, neither the cognitive model nor RTNet is designed to fit or account for individual variability. If that is the case, it is unclear why these models serve as appropriate baselines. Isn't it expected that a model explicitly fitted to individual data would outperform models that do not? If so, does the observed superiority of the proposed framework simply reflect the unsurprising benefit of fitting individual variability? I think the authors should either clarify why these models constitute fair control or validate the proposed approach against stronger and more appropriate baselines.</p></disp-quote><p>Thank you for raising this critical point. We wish to clarify the nature of our baselines:</p><p>For the MDP task, the cognitive model baseline was indeed designed to account for individual variability. We estimated its parameters (e.g., learning rate) from each individual's source task behaviour and then used those specific parameters to predict their behaviour in the target task. This makes it a direct, parameter-based transfer model and thus a fair and appropriate baseline for individuality transfer.</p><p>For the MNIST task, we agree that the RTNet baseline was insufficient for evaluating individual-level transfer in the &quot;Cross-Condition Transfer&quot; scenario. We have now introduced a much stronger baseline, the &quot;task solver (source),&quot; which is trained specifically on the source task data of each test participant. Our results (Figure 9) show that the EIDT framework significantly outperforms this more appropriate, individualized baseline, highlighting the value of our transfer method over direct, within-condition fitting.</p><disp-quote content-type="editor-comment"><p>It's not very clear in the results section what it means by having a shorter within-individual distance than between-individual distances. Related to the comment above, is there any control analysis performed for this? Also, this analysis appears to have nothing to do with predicting individual behavior. Is this evidence toward successfully parameterizing individual differences? Could this be task-dependent, especially since the transfer is evaluated on exceedingly similar tasks in both experiments? I think a bit more discussion of the motivation and implications of these results will help the reader in making sense of this analysis.</p></disp-quote><p>We agree that the previous analysis on inter- and intra-participant distances was not sufficiently clear or directly linked to the model's predictive power. We have removed this analysis from the manuscript. In its place, we have introduced a new, more direct analysis (Figures 4, 11, S5, S8, and S9) that demonstrates a quantitative relationship between the distance in the latent space and prediction accuracy. This new analysis shows that prediction error for an individual increases as a function of this distance, providing much stronger and clearer evidence that our framework successfully parameterizes meaningful individual differences.</p><disp-quote content-type="editor-comment"><p>The authors have to better define what exactly he meant by transferring across different &quot;tasks&quot; and testing the framework in &quot;more distinctive tasks&quot;. All presented evidence, taken at face value, demonstrated transferring across different &quot;conditions&quot; of the same task within the same experiment. It is unclear to me how generalizable the framework will be when applied to different tasks.</p><p>Conceptually, it is also unclear to me how plausible it is that the framework could generalize across tasks spanning multiple cognitive domains (if that's what is meant by more distinctive). For instance, how can an individual's task performance on a Posner task predict task performance on the Cambridge face memory test? Which part of the framework could have enabled such a cross-domain prediction of task performance? I think these have to be at least discussed to some extent, since without it the future direction is meaningless.</p></disp-quote><p>We agree with your assessment and have corrected our terminology throughout the manuscript. We now consistently refer to the transfer as being &quot;across task conditions&quot; to accurately describe the scope of our findings.</p><p>We have also expanded our Discussion (Line 332-343) to address the important conceptual point about cross-domain transfer. We hypothesize that such transfer would be possible if the tasks, even if structurally different, rely on partially shared underlying cognitive functions (e.g., working memory). In such a scenario, the individual latent representation would capture an individual's specific characteristics related to that shared function, enabling transfer. Conversely, we state that transfer between tasks with no shared cognitive basis would not be expected to succeed with our current framework.</p><disp-quote content-type="editor-comment"><p>How is the negative log-likelihood, which seems to be the main metric for comparison, computed? Is this based on trial-by-trial response prediction or probability of responses, as what usually performed in cognitive modelling?</p></disp-quote><p>The negative log-likelihood is computed on a trial-by-trial basis. It is based on the probability the model assigned to the specific action that the human participant actually took on that trial. This calculation is applied consistently across all models (cognitive models, RTNet, and EIDT). We have added sentences to the Results section to clarify this point (Lines 116--122).</p><disp-quote content-type="editor-comment"><p>None of the presented evidence is cross-validated. The authors should consider performing K-fold cross-validation on the train, test, and evaluation split of subjects to ensure robustness of the findings.</p></disp-quote><p>All prediction performance results reported in the revised manuscript are now based on a rigorous leave-one-participant-out cross-validation procedure to ensure the robustness of our findings. We have updated the</p><p>Methods section to reflect this (Lines 127--129 and 229).</p><p>For some purely illustrative visualizations (e.g., plotting the entire latent space in Figures S3 and S7), we used a model trained on all participants' data to provide a single, representative example and avoid clutter. We have explicitly noted this in the relevant figure captions.</p><disp-quote content-type="editor-comment"><p>The authors excluded 25 subjects (20% of the data) for different reasons. This is a substantial proportion, especially by the standards of what is typically observed in behavioral experiments. The authors should provide a clear justification for these exclusion criteria and, if possible, cite relevant studies that support the use of such stringent thresholds.</p></disp-quote><p>We acknowledge the concern regarding the exclusion rate. The previous criteria were indeed empirical. We have now implemented more systematic exclusion procedure based on the interquartile range of performance metrics, which is detailed in Section 4.2.2 (Lines 489--498). This revised, objective criterion resulted in the exclusion of 42 participants (34% of the initial sample). While this rate is high, we attribute it to the online nature of the data collection, where participant engagement can be more variable. We believe applying these strict criteria was necessary to ensure the quality and reliability of the behavioural data used for modeling.</p><disp-quote content-type="editor-comment"><p>The authors should do a better job of creating the figures and writing the figure captions. It is unclear which specific claim the authors are addressing with the figure. For example, what is the key message of Figure 2C regarding transfer within and across participants? Why are the stats presentation different between the Cognitive model and the EIDT framework plots? In Figure 3, it's unclear what these dots and clusters represent and how they support the authors' claim that the same individual forms clusters. And isn't this experiment have 98 subjects after exclusion, this plot has way less than 98 dots as far as I can tell. Furthermore, I find Figure 5 particularly confusing, as the underlying claim it is meant to illustrate is unclear. Clearer figures and more informative captions are needed to guide the reader effectively.</p></disp-quote><p>We agree that several figures and analyses in the original manuscript were unclear, and we have thoroughly revised our figures and their captions to improve clarity.</p><p>The confusing analysis in the old Figures 2C and 5 (Original/Others comparison) have been completely removed. The unclear visualization of the latent space for the test pool (old Figure 3 showing representations only from test participants) has also been removed to avoid confusion. For visualization of the overall latent space, we now use models trained on all data (Figures S3 and S7) and have clarified this in the captions. In place of these removed analyses, we have introduced a new, more intuitive &quot;cross-individual&quot; analysis (presented in Figures 4, 11, S5, S8, and S9). As explained in the new, more detailed captions, this analysis directly plots prediction performance as a function of the distance in latent space, providing a much clearer demonstration of how the latent representation relates to predictive accuracy.</p><disp-quote content-type="editor-comment"><p>I also find the writing somewhat difficult to follow. The subheadings are confusing, and it's often unclear which specific claim the authors are addressing. The presentation of results feels disorganized, making it hard to trace the evidence supporting each claim. Also, the excessive use of acronyms (e.g., SX, SY, CG, EA, ES, DA, DS) makes the text harder to parse. I recommend restructuring the results section to be clearer and significantly reducing the use of unnecessary acronyms.</p></disp-quote><p>Thank you for this feedback. We have made significant revisions to improve the clarity and organization of the manuscript. We have renamed confusing acronyms: &quot;Situation SX&quot; is now &quot;Within- Condition Prediction,&quot; and &quot;Situation SY&quot; is now &quot;Cross-Condition Transfer.&quot; We also added a table to clarify the MNIST condition acronyms (EA/ES/DA/DS) in Figure 7.</p><p>The Results section has been substantially restructured with clearer subheadings.</p></body></sub-article></article>