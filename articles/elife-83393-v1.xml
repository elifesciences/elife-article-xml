<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD v1.1d3 20150301//EN"  "JATS-archivearticle1.dtd"><article xmlns:xlink="http://www.w3.org/1999/xlink" article-type="research-article" dtd-version="1.1d3"><front><journal-meta><journal-id journal-id-type="nlm-ta">elife</journal-id><journal-id journal-id-type="publisher-id">eLife</journal-id><journal-title-group><journal-title>eLife</journal-title></journal-title-group><issn publication-format="electronic">2050-084X</issn><publisher><publisher-name>eLife Sciences Publications, Ltd</publisher-name></publisher></journal-meta><article-meta><article-id pub-id-type="publisher-id">83393</article-id><article-id pub-id-type="doi">10.7554/eLife.83393</article-id><article-categories><subj-group subj-group-type="display-channel"><subject>Research Article</subject></subj-group><subj-group subj-group-type="heading"><subject>Computational and Systems Biology</subject></subj-group><subj-group subj-group-type="heading"><subject>Neuroscience</subject></subj-group></article-categories><title-group><article-title>High-resolution volumetric imaging constrains compartmental models to explore synaptic integration and temporal processing by cochlear nucleus globular bushy cells</article-title></title-group><contrib-group><contrib contrib-type="author" corresp="yes" id="author-280280"><name><surname>Spirou</surname><given-names>George A</given-names></name><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="corresp" rid="cor1">*</xref><xref ref-type="other" rid="par-1"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" id="author-294261"><name><surname>Kersting</surname><given-names>Matthew G</given-names></name><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" id="author-294262"><name><surname>Carr</surname><given-names>Sean</given-names></name><contrib-id contrib-id-type="orcid">http://orcid.org/0000-0002-6757-9104</contrib-id><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" id="author-294260"><name><surname>Razzaq</surname><given-names>Bayan</given-names></name><xref ref-type="aff" rid="aff2">2</xref><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" id="author-294263"><name><surname>Yamamoto Alves Pinto</surname><given-names>Carolyna</given-names></name><contrib-id contrib-id-type="orcid">http://orcid.org/0000-0001-6735-045X</contrib-id><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" id="author-294264"><name><surname>Dawson</surname><given-names>Mariah</given-names></name><xref ref-type="aff" rid="aff2">2</xref><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" id="author-294265"><name><surname>Ellisman</surname><given-names>Mark H</given-names></name><xref ref-type="aff" rid="aff3">3</xref><xref ref-type="other" rid="par-1"/><xref ref-type="other" rid="par-3"/><xref ref-type="other" rid="par-4"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" corresp="yes" id="author-3954"><name><surname>Manis</surname><given-names>Paul B</given-names></name><contrib-id contrib-id-type="orcid">http://orcid.org/0000-0003-0131-8961</contrib-id><xref ref-type="aff" rid="aff4">4</xref><xref ref-type="corresp" rid="cor2">*</xref><xref ref-type="other" rid="par-1"/><xref ref-type="other" rid="par-2"/><xref ref-type="fn" rid="conf1"/></contrib><aff id="aff1"><institution content-type="dept">Department of Medical Engineering</institution>, <institution>University of South Florida</institution>, <addr-line><named-content content-type="city">Tampa</named-content></addr-line>, <country>United States</country></aff><aff id="aff2"><institution content-type="dept">Department of Otolaryngology, Head and Neck Surgery</institution>, <institution>West Virginia University</institution>, <addr-line><named-content content-type="city">Morgantown</named-content></addr-line>, <country>United States</country></aff><aff id="aff3"><institution content-type="dept">Department of Neurosciences</institution>, <institution>University of California, San Diego</institution>, <addr-line><named-content content-type="city">San Diego</named-content></addr-line>, <country>United States</country></aff><aff id="aff4"><institution content-type="dept">Department of Otolaryngology/Head and Neck Surgery</institution>, <institution>University of North Carolina at Chapel Hill</institution>, <addr-line><named-content content-type="city">Chapel Hill</named-content></addr-line>, <country>United States</country></aff></contrib-group><contrib-group content-type="section"><contrib contrib-type="editor" id="author-6872"><name><surname>Carr</surname><given-names>Catherine Emily</given-names></name><role>Reviewing editor</role><aff><institution>University of Maryland</institution>, <country>United States</country></aff></contrib></contrib-group><author-notes><corresp id="cor1"><label>*</label>For correspondence: <email>gspirou@usf.edu</email> (GS);</corresp><corresp id="cor2"><label>*</label>For correspondence: <email>pmanis@med.unc.edu</email> (PM);</corresp></author-notes><pub-date date-type="pub" publication-format="electronic"><day>08</day><month>06</month><year>2023</year></pub-date><volume>12</volume><elocation-id>e83393</elocation-id><history><date date-type="received"><day>14</day><month>09</month><year>2022</year></date><date date-type="accepted"><day>07</day><month>06</month><year>2023</year></date></history><permissions><copyright-statement>Â© 2023, Spirou et al</copyright-statement><copyright-year>2023</copyright-year><copyright-holder>Spirou et al</copyright-holder><license xlink:href="http://creativecommons.org/licenses/by/4.0/"><license-p>This article is distributed under the terms of the <ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/licenses/by/4.0/">Creative Commons Attribution License</ext-link> permitting unrestricted use and redistribution provided that the original author and source are credited.</license-p></license></permissions><self-uri content-type="pdf" xlink:href="elife-83393-v1.pdf"/><abstract><p>Globular bushy cells (GBCs) of the cochlear nucleus play central roles in the temporal processing of sound. Despite investigation over many decades, fundamental questions remain about their dendrite structure, afferent innervation, and integration of synaptic inputs. Here, we use volume electron microscopy (EM) of the mouse cochlear nucleus to construct synaptic maps that precisely specify convergence ratios and synaptic weights for auditory- nerve innervation and accurate surface areas of all postsynaptic compartments. Detailed biophysically-based compartmental models can help develop hypotheses regarding how GBCs integrate inputs to yield their recorded responses to sound. We established a pipeline to export a precise reconstruction of auditory nerve axons and their endbulb terminals together with high-resolution dendrite, soma, and axon reconstructions into biophysically-detailed compartmental models that could be activated by a standard cochlear transduction model. With these constraints, the models predict auditory nerve input profiles whereby all endbulbs onto a GBC are subthreshold (coincidence detection mode), or one or two inputs are suprathreshold (mixed mode). The models also predict the relative importance of dendrite geometry, soma size, and axon initial segment length in setting action potential threshold and generating heterogeneity in sound-evoked responses, and thereby propose mechanisms by which GBCs may homeostatically adjust their excitability. Volume EM also reveals new dendritic structures and dendrites that lack innervation. This framework defines a pathway from subcellular morphology to synaptic connectivity, and facilitates investigation into the roles of specific cellular features in sound encoding. We also clarify the need for new experimental measurements to provide missing cellular parameters, and predict responses to sound for further in vivo studies, thereby serving as a template for investigation of other neuron classes.</p></abstract><kwd-group kwd-group-type="research-organism"><title>Research organism</title><kwd>Mouse</kwd></kwd-group><funding-group><award-group id="par-1"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/100000055</institution-id><institution>National Institute on Deafness and Other Communication Disorders</institution></institution-wrap></funding-source><award-id>R01 DC015901</award-id><principal-award-recipient><name><surname>Spirou</surname><given-names>George A</given-names></name><name><surname>Ellisman</surname><given-names>Mark H</given-names></name><name><surname>Manis</surname><given-names>Paul B</given-names></name></principal-award-recipient></award-group><award-group id="par-2"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/100000055</institution-id><institution>National Institute on Deafness and Other Communication Disorders</institution></institution-wrap></funding-source><award-id>R01 DC004551</award-id><principal-award-recipient><name><surname>Manis</surname><given-names>Paul B</given-names></name></principal-award-recipient></award-group><award-group id="par-3"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/100000057</institution-id><institution>National Institute of General Medical Sciences</institution></institution-wrap></funding-source><award-id>R01 GM082949</award-id><principal-award-recipient><name><surname>Ellisman</surname><given-names>Mark H</given-names></name></principal-award-recipient></award-group><award-group id="par-4"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/100000065</institution-id><institution>National Institute of Neurological Disorders and Stroke</institution></institution-wrap></funding-source><award-id>U24 NS120055</award-id><principal-award-recipient><name><surname>Ellisman</surname><given-names>Mark H</given-names></name></principal-award-recipient></award-group><funding-statement>The content is solely the responsibility of the authors and does not necessarily represent the official views of the National Institutes of Health.</funding-statement></funding-group></article-meta></front><back><sec id="s1" sec-type="additional-information"><title>Additional information</title><fn-group content-type="competing-interest"><title>Competing interest</title><fn fn-type="conflict" id="conf1"><p>The authors declare that no competing interests exist.</p></fn></fn-group><fn-group content-type="ethics-information"><title>Ethics</title><fn fn-type="other"><p>Animal experimentation: All procedures involving animals were approved by the West Virginia University (WVU) InstitutionalAnimal Care and Use Committee, protocol #15-1201 (G.A. Spirou, PI)  and were in accordance with policies of the United States Public Health Service. No animal procedures in this study were performed at other institutions. The perfusion of the mouse was performed under avertin anesthesia.</p></fn></fn-group></sec><sec id="s2" sec-type="supplementary-material"><title>Additional Files</title><sec id="s3" sec-type="data-availability"><title>Data availability</title><p>The serial blockface electron microscope volume will be uploaded to BossDB (bossdb.org).The modeling code is publicly available on GitHub (https://github.com/pbmanis/vcnmodel; https://github.com/cnmodel).The main Simulation result files used to generate the figures in this manuscript have been uploaded to Dryad, and can be accessed at https://doi.org/10.5061/dryad.4j0zpc8g1. This repository includes:Simulation figures and figure panels can be generated using the DataTables script in the VCNModel package after downloading the simulation result files.  All simulations shown in the paper, and/or their analyses, are included in the  Dryad repository. They can be regenerated from the VCNModel package (above, on GitHub) using supplied scripts.Code and Data for Figure2-Figure Supplement 1 is in the file Figure2_Suppl1.py in the VCNModel GitHub repository.Code and data for Figure5-Figure Supplement 2 is in pattern_summary.py in the VCNModel GitHub repository.Figures 1E, F, 2C, D, 3C,D,F,G, 7H and K, 8H were generated using Matlab code. The tables (Excel) and Matlab code are at www.github.com/gaspirou/pub_file_share.</p><p>The following datasets were generated:</p><p><element-citation id="dataset1" publication-type="data" specific-use="isSupplementedBy"><person-group person-group-type="author"><collab>Manis PB</collab><collab>et al</collab></person-group><year iso-8601-date="2023">2023</year><source>Data from: High-resolution volumetric imaging constrains compartmental models to explore synaptic integration and temporal processing by cochlear nucleus globular bushy cells</source><ext-link ext-link-type="uri" xlink:href="https://dx.doi.org/10.5061/dryad.4j0zpc8g1">https://dx.doi.org/10.5061/dryad.4j0zpc8g1</ext-link><comment>Dryad Digital Repository, doi:10.5061/dryad.4j0zpc8g1</comment></element-citation></p></sec><supplementary-material><ext-link xlink:href="elife-83393-supp-v1.zip">Download zip</ext-link><p>Any figures and tables for this article are included in the PDF. The zip folder contains additional supplemental files.</p></supplementary-material></sec></back></article>