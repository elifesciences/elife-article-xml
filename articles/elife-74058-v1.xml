<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD with MathML3 v1.2 20190208//EN"  "JATS-archivearticle1-mathml3.dtd"><article xmlns:ali="http://www.niso.org/schemas/ali/1.0/" xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" article-type="research-article" dtd-version="1.2"><front><journal-meta><journal-id journal-id-type="nlm-ta">elife</journal-id><journal-id journal-id-type="publisher-id">eLife</journal-id><journal-title-group><journal-title>eLife</journal-title></journal-title-group><issn publication-format="electronic" pub-type="epub">2050-084X</issn><publisher><publisher-name>eLife Sciences Publications, Ltd</publisher-name></publisher></journal-meta><article-meta><article-id pub-id-type="publisher-id">74058</article-id><article-id pub-id-type="doi">10.7554/eLife.74058</article-id><article-categories><subj-group subj-group-type="display-channel"><subject>Research Article</subject></subj-group><subj-group subj-group-type="heading"><subject>Neuroscience</subject></subj-group></article-categories><title-group><article-title>Sampling motion trajectories during hippocampal theta sequences</article-title></title-group><contrib-group><contrib contrib-type="author" corresp="yes" id="author-254081"><name><surname>Ujfalussy</surname><given-names>Balazs B</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">https://orcid.org/0000-0002-2295-3828</contrib-id><email>ujfalussy.balazs@koki.hu</email><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="aff" rid="aff2">2</xref><xref ref-type="fn" rid="fn1">†</xref><xref ref-type="other" rid="fund1"/><xref ref-type="other" rid="fund2"/><xref ref-type="other" rid="fund4"/><xref ref-type="fn" rid="con1"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" id="author-255557"><name><surname>Orbán</surname><given-names>Gergő</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">https://orcid.org/0000-0002-2406-5912</contrib-id><xref ref-type="aff" rid="aff3">3</xref><xref ref-type="fn" rid="fn1">†</xref><xref ref-type="other" rid="fund3"/><xref ref-type="other" rid="fund5"/><xref ref-type="fn" rid="con2"/><xref ref-type="fn" rid="conf1"/></contrib><aff id="aff1"><label>1</label><institution-wrap><institution-id institution-id-type="ror">https://ror.org/01jsgmp44</institution-id><institution>Laboratory of Biological Computation, Institute of Experimental Medicine</institution></institution-wrap><addr-line><named-content content-type="city">Budapest</named-content></addr-line><country>Hungary</country></aff><aff id="aff2"><label>2</label><institution-wrap><institution-id institution-id-type="ror">https://ror.org/01jsgmp44</institution-id><institution>Laboratory of Neuronal Signalling, Institute of Experimental Medicine, Budapest</institution></institution-wrap><addr-line><named-content content-type="city">Budapest</named-content></addr-line><country>Hungary</country></aff><aff id="aff3"><label>3</label><institution-wrap><institution-id institution-id-type="ror">https://ror.org/035dsb084</institution-id><institution>Computational Systems Neuroscience Lab, Wigner Research Center for Physics, Budapest</institution></institution-wrap><addr-line><named-content content-type="city">Budapest</named-content></addr-line><country>Hungary</country></aff></contrib-group><contrib-group content-type="section"><contrib contrib-type="editor"><name><surname>Peyrache</surname><given-names>Adrien</given-names></name><role>Reviewing Editor</role><aff><institution-wrap><institution-id institution-id-type="ror">https://ror.org/01pxwe438</institution-id><institution>McGill University</institution></institution-wrap><country>Canada</country></aff></contrib><contrib contrib-type="senior_editor"><name><surname>Colgin</surname><given-names>Laura L</given-names></name><role>Senior Editor</role><aff><institution-wrap><institution-id institution-id-type="ror">https://ror.org/00hj54h04</institution-id><institution>University of Texas at Austin</institution></institution-wrap><country>United States</country></aff></contrib></contrib-group><author-notes><fn fn-type="other" id="fn1"><label>†</label><p>Co-senior author</p></fn></author-notes><pub-date publication-format="electronic" date-type="publication"><day>08</day><month>11</month><year>2022</year></pub-date><pub-date pub-type="collection"><year>2022</year></pub-date><volume>11</volume><elocation-id>e74058</elocation-id><history><date date-type="received" iso-8601-date="2021-09-20"><day>20</day><month>09</month><year>2021</year></date><date date-type="accepted" iso-8601-date="2022-09-28"><day>28</day><month>09</month><year>2022</year></date></history><pub-history><event><event-desc>This manuscript was published as a preprint at bioRxiv.</event-desc><date date-type="preprint" iso-8601-date="2021-12-16"><day>16</day><month>12</month><year>2021</year></date><self-uri content-type="preprint" xlink:href="https://doi.org/10.1101/2021.12.14.472575"/></event></pub-history><permissions><copyright-statement>© 2022, Ujfalussy and Orbán</copyright-statement><copyright-year>2022</copyright-year><copyright-holder>Ujfalussy and Orbán</copyright-holder><ali:free_to_read/><license xlink:href="http://creativecommons.org/licenses/by/4.0/"><ali:license_ref>http://creativecommons.org/licenses/by/4.0/</ali:license_ref><license-p>This article is distributed under the terms of the <ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/licenses/by/4.0/">Creative Commons Attribution License</ext-link>, which permits unrestricted use and redistribution provided that the original author and source are credited.</license-p></license></permissions><self-uri content-type="pdf" xlink:href="elife-74058-v1.pdf"/><self-uri content-type="figures-pdf" xlink:href="elife-74058-figures-v1.pdf"/><abstract><p>Efficient planning in complex environments requires that uncertainty associated with current inferences and possible consequences of forthcoming actions is represented. Representation of uncertainty has been established in sensory systems during simple perceptual decision making tasks but it remains unclear if complex cognitive computations such as planning and navigation are also supported by probabilistic neural representations. Here, we capitalized on gradually changing uncertainty along planned motion trajectories during hippocampal theta sequences to capture signatures of uncertainty representation in population responses. In contrast with prominent theories, we found no evidence of encoding parameters of probability distributions in the momentary population activity recorded in an open-field navigation task in rats. Instead, uncertainty was encoded sequentially by sampling motion trajectories randomly and efficiently in subsequent theta cycles from the distribution of potential trajectories. Our analysis is the first to demonstrate that the hippocampus is well equipped to contribute to optimal planning by representing uncertainty.</p></abstract><kwd-group kwd-group-type="author-keywords"><kwd>navigation</kwd><kwd>planning</kwd><kwd>uncertainty</kwd><kwd>neural coding</kwd><kwd>probabilistic representations</kwd></kwd-group><kwd-group kwd-group-type="research-organism"><title>Research organism</title><kwd>Rat</kwd></kwd-group><funding-group><award-group id="fund1"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/501100012550</institution-id><institution>National Research, Development and Innovation Fund</institution></institution-wrap></funding-source><award-id>PD-125386</award-id><principal-award-recipient><name><surname>Ujfalussy</surname><given-names>Balazs B</given-names></name></principal-award-recipient></award-group><award-group id="fund2"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/501100012550</institution-id><institution>National Research, Development and Innovation Fund</institution></institution-wrap></funding-source><award-id>FK-125324</award-id><principal-award-recipient><name><surname>Ujfalussy</surname><given-names>Balazs B</given-names></name></principal-award-recipient></award-group><award-group id="fund3"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/501100005863</institution-id><institution>National Brain Research Centre</institution></institution-wrap></funding-source><award-id>2017-1.2.1-NKP-2017-00002</award-id><principal-award-recipient><name><surname>Orbán</surname><given-names>Gergő</given-names></name></principal-award-recipient></award-group><award-group id="fund4"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/501100005863</institution-id><institution>National Brain Research Centre</institution></institution-wrap></funding-source><award-id>KTIA-NAP-12-2-201</award-id><principal-award-recipient><name><surname>Ujfalussy</surname><given-names>Balazs B</given-names></name></principal-award-recipient></award-group><award-group id="fund5"><funding-source><institution-wrap><institution>Artificial Intelligence National Laboratory</institution></institution-wrap></funding-source><award-id>RRF-2.3.1-21-2022-00004</award-id><principal-award-recipient><name><surname>Orbán</surname><given-names>Gergő</given-names></name></principal-award-recipient></award-group><funding-statement>The funders had no role in study design, data collection and interpretation, or the decision to submit the work for publication.</funding-statement></funding-group><custom-meta-group><custom-meta specific-use="meta-only"><meta-name>Author impact statement</meta-name><meta-value>The rodent brain represents uncertainty associated with short-term predictions during naturalistic navigation tasks sequentially by sampling hypothetical future trajectories in every ~100 ms, corresponding to successive theta cycles.</meta-value></custom-meta></custom-meta-group></article-meta></front><body><sec id="s1" sec-type="intro"><title>Introduction</title><p>Model-based planning and predictions are necessary for flexible behavior in a range of cognitive tasks. In particular, navigation is a domain that is ecologically highly relevant not only for humans but for rodents as well, which established a field for parallel investigation of the theory of planning, the underlying cognitive computations, and their neural underpinnings (<xref ref-type="bibr" rid="bib20">Hunt et al., 2021</xref>; <xref ref-type="bibr" rid="bib34">Mattar and Lengyel, 2022</xref>). Importantly, predictions extending into the future have to cope with uncertainty coming from multiple sources: uncertainty in the current state of the environment (our current location relative to a dangerous spot, the satiety of a predator or the actual geometry of the environment) and the availability of multiple future options when evaluating upcoming choices (<xref ref-type="bibr" rid="bib17">Glimcher, 2003</xref>; <xref ref-type="bibr" rid="bib45">Redish, 2016</xref>). Whether and how this planning-related uncertainty is represented in the brain is not known.</p><p>The hippocampus has been established as one of the brain areas critically involved in both spatial navigation and more abstract planning (<xref ref-type="bibr" rid="bib40">O’Keefe and Nadel, 1978</xref>; <xref ref-type="bibr" rid="bib36">Miller et al., 2017</xref>). Recent progress in recording techniques and analysis methods largely contributed to understanding of the neuronal mechanisms underlying such computations (<xref ref-type="bibr" rid="bib42">Pfeiffer and Foster, 2013</xref>; <xref ref-type="bibr" rid="bib25">Kay et al., 2020</xref>). A crucial insight gained about the neural code underlying navigation is that neuron populations in the hippocampus represent the trajectory of the animal on multiple time scales: Not only the current position of the animal can be read out at the behavioral time scale (<xref ref-type="bibr" rid="bib40">O’Keefe and Nadel, 1978</xref>; <xref ref-type="bibr" rid="bib64">Wilson and McNaughton, 1993</xref>), but also trajectories starting in the past and ending in the near future are repeatedly expressed on a shorter time scale at accelerated speed during individual cycles of the 6–10 Hz theta oscillation (theta sequences, <xref ref-type="bibr" rid="bib15">Foster and Wilson, 2007</xref>, <xref ref-type="fig" rid="fig1">Figure 1a</xref>). Moreover, features characteristic of planning can be identified in the properties of encoded trajectories, such as their dependence on the immediate context the animal is in, and on the span of the current run, future choices and rewards (<xref ref-type="bibr" rid="bib23">Johnson and Redish, 2007</xref>; <xref ref-type="bibr" rid="bib19">Gupta et al., 2012</xref>; <xref ref-type="bibr" rid="bib63">Wikenheiser and Redish, 2015</xref>; <xref ref-type="bibr" rid="bib54">Tang et al., 2021</xref>; <xref ref-type="bibr" rid="bib68">Zheng et al., 2020</xref>). These data provide strong support for a computational framework where planning relies on sequential activity patterns in the hippocampus delineating future locations based on the current beliefs of the animal (<xref ref-type="bibr" rid="bib52">Stachenfeld et al., 2017</xref>; <xref ref-type="bibr" rid="bib36">Miller et al., 2017</xref>). Whether hippocampal computations also take into account the uncertainty associated with planning and thus the population activity represents the uncertainty of the encoded trajectories has not been studied yet.</p><fig id="fig1" position="float"><label>Figure 1.</label><caption><title>Theta sequences, uncertainty and variability.</title><p>(<bold>a</bold>) Schematic showing the way hippocampal place cell activity represents possible trajectories in subsequent theta cycles during navigation. (<bold>b-f</bold>) Schemes for representing a target probability distribution (b, bottom) by the activity of a population of neurons each associated with an encoding basis function (related to their place field, Methods; b, top). (<bold>c</bold>) In the mean scheme the firing rates of the neurons (right, colored bars) are defined as the value of their basis functions at the mean of the target distribution (left, cross). (<bold>d</bold>) Similar to other schemes, the product scheme also defines a mapping between the probability distribution and the activity of the neuron population but it is easier to understand this mapping in the reverse direction (arrow): from the spike counts (right) to the represented distribution (left). The spike count of each neuron (right) can be considered as its vote for the contribution of their tuning curves to the represented distribution and ultimately the target distribution is approximated as the weighted product of these tuning curves (left). (<bold>e</bold>) In the DDC scheme the firing rate of each neuron (right) is defined by the overlap between the target distribution and the basis function (left). (<bold>f</bold>) In the sampling scheme the firing rate of the neurons at each point in time (right) equals the value of their basis functions at the location sampled from the target distribution (left, asterisks).</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-74058-fig1-v1.tif"/></fig><p>Neuronal representations of uncertainty have been extensively studied in sensory systems (<xref ref-type="bibr" rid="bib29">Ma et al., 2006</xref>; <xref ref-type="bibr" rid="bib41">Orbán et al., 2016</xref>; <xref ref-type="bibr" rid="bib56">Vértes and Sahani, 2018</xref>; <xref ref-type="bibr" rid="bib60">Walker et al., 2020</xref>). Schemes for representing uncertainty fall into three broad categories (<xref ref-type="fig" rid="fig1">Figure 1d–f</xref>). In the first two categories (<italic>product</italic> and Distributed Distributional Code, <italic>DDC</italic>, schemes), the firing rate of a population encodes a complete probability distribution over spatial locations <italic>instantaneously</italic> at any given time by representing the parameters of the distribution (<xref ref-type="bibr" rid="bib59">Wainwright and Jordan, 2007</xref>, Methods). In the <italic>product scheme,</italic> the firing rate of neurons encode a probability distribution through taking the product of the tuning functions (basis functions, Methods) of the coactive neurons (<xref ref-type="bibr" rid="bib29">Ma et al., 2006</xref>; <xref ref-type="bibr" rid="bib44">Pouget et al., 2013</xref>, <xref ref-type="fig" rid="fig1">Figure 1d</xref>). In contrast, in the <italic>DDC scheme</italic> a population of neurons represents a probability distribution by signalling the overlap between the distribution and the basis function of individual neurons (<xref ref-type="bibr" rid="bib65">Zemel et al., 1998</xref>; <xref ref-type="bibr" rid="bib56">Vértes and Sahani, 2018</xref>, <xref ref-type="fig" rid="fig1">Figure 1e</xref>). In the third category, the <italic>sampling scheme</italic>, the population activity represents a single value sampled stochastically from the target distribution. In this case uncertainty is represented <italic>sequentially</italic> by the across-time variability of the neuronal activity (<xref ref-type="bibr" rid="bib14">Fiser et al., 2010</xref>, <xref ref-type="fig" rid="fig1">Figure 1f</xref>). These coding schemes provide a firm theoretical background to investigate the representation of uncertainty in hippocampus. Importantly, all these schemes have been developed for static features, where the represented features do not change in time (<xref ref-type="bibr" rid="bib29">Ma et al., 2006</xref>; <xref ref-type="bibr" rid="bib41">Orbán et al., 2016</xref>; but see <xref ref-type="bibr" rid="bib27">Kutschireiter et al., 2017</xref>). In contrast, trajectories represented in the hippocampus encode the temporally changing position of the animal. Here, we extend the coding schemes to be able to accommodate the encoding of uncertainty associated with dynamic motion trajectories and investigate their neuronal signatures in rats while navigating an open environment.</p><p>Probabilistic planning in an open field entails the representation of subjective beliefs about the past, present, and future states, which requires that a continuous probability distribution over possible locations is represented. Previous studies investigated prospective codes during theta sequences in a constrained setting, in which binary decisions were required in a spatial navigation task (<xref ref-type="bibr" rid="bib23">Johnson and Redish, 2007</xref>; <xref ref-type="bibr" rid="bib25">Kay et al., 2020</xref>; <xref ref-type="bibr" rid="bib54">Tang et al., 2021</xref>). These studies found that alternative choices were encoded sequentially in distinct theta cycles suggesting a sampling based representation. However, the dominant source of future uncertainty in these tasks is directly associated with the binary choice of the animal (left or right) and it remains unclear whether this generalizes to other sources of uncertainty relevant in open field navigation. In particular, it has been widely reported that the hippocampal spatial code has different properties in linear tracks, where the physical movement of the animal is constrained by the environment, than during open-field navigation (<xref ref-type="bibr" rid="bib3">Buzsáki, 2005</xref>). Moreover, these previous studies did not attempt to test the consistency of the hippocampal code with alternative schemes for representing uncertainty. Thus, the way hippocampal populations contribute to probabilistic planning during general open-field navigation remains an open question.</p><p>In the present paper, we propose that the hippocampus is performing probabilistic inference in a model that represents the temporal dependencies between spatial locations. Using a computational model, we demonstrate that key features of the hippocampal single neuron and population activity are compatible with representing uncertainty of motion trajectories in the population activity during theta sequences. Further, by developing novel computational measures, we pitch three alternative schemes of uncertainty representation and a scheme that lacks the capacity to represent uncertainty, the <italic>mean</italic> scheme (<xref ref-type="fig" rid="fig1">Figure 1c</xref>), against each other and demonstrate that hippocampal activity does not show the hallmarks of schemes encoding probability distributions instantaneously. Instead, we demonstrate that the large and structured trial to trial variability between subsequent theta cycles is consistent with stochastic sampling from potential future trajectories but not with a scheme ignoring the uncertainty by representing only the most likely trajectory. Finally we confirm previous results in simpler mazes by showing that the trajectories sampled in subsequent theta cycles tend to be anti-correlated, a signature of efficient sampling algorithms. These results demonstrate that the brain employs probabilistic computations not only in sensory areas during perceptual decision making but also in associative cortices during naturalistic, high-level cognitive processes.</p></sec><sec id="s2" sec-type="results"><title>Results</title><sec id="s2-1"><title>Neural variability increases within theta cycle</title><p>A key insight of probabilistic computations is that during planning uncertainty increases as trajectories proceed into more distant future (<xref ref-type="bibr" rid="bib37">Murphy, 2012</xref>; <xref ref-type="bibr" rid="bib50">Sezener et al., 2019</xref>). As a consequence, if planned trajectories are encoded in individual theta sequences, the uncertainty associated with the represented positions increases within a theta cycle (<xref ref-type="fig" rid="fig1">Figure 1a</xref>). This systematic change in the uncertainty of the represented position during theta cycles is a crucial observation that enabled us to investigate the neuronal signatures of uncertainty during hippocampal theta sequences. For this, we analyzed a previously published dataset (<xref ref-type="bibr" rid="bib42">Pfeiffer and Foster, 2013</xref>). Briefly, rats were trained to collect food reward in a 2×2 m large open arena from one of the 36 uniformly distributed food wells alternating between random foraging and spatial memory task (<xref ref-type="bibr" rid="bib42">Pfeiffer and Foster, 2013</xref>). Position of the animal was recorded via a pair of distinctly coloured head-mounted LED light. Goal directed navigation in an open arena requires continuous monitoring and online correction of the deviations between the intended and actual motion trajectories. While sequences during both sharp waves and theta oscillations have been implicated in planning, here we focused on theta sequences as they are more strongly tied to the current position and thus averaging over many thousands of theta cycles can provide the necessary statistical power to identify the neuronal correlate of uncertainty representation.</p><p>Activity of hippocampal neurons was recorded by 20 tetrodes targeted to dorsal hippocampal area CA1 (<xref ref-type="bibr" rid="bib42">Pfeiffer and Foster, 2013</xref>). Individual neurons typically had location-related activity (<xref ref-type="fig" rid="fig2">Figure 2b</xref>, see also <xref ref-type="fig" rid="fig4s1">Figure 4—figure supplement 1a</xref>), but their spike trains were highly variable (<xref ref-type="bibr" rid="bib51">Skaggs et al., 1996</xref>; <xref ref-type="bibr" rid="bib12">Fenton and Muller, 1998</xref>, <xref ref-type="fig" rid="fig2">Figure 2a</xref>). We used the empirical tuning curves (i.e., place fields) and a Bayesian decoder (<xref ref-type="bibr" rid="bib66">Zhang et al., 1998</xref>) to estimate the represented spatial position from the spike trains of the recorded population in overlapping 20ms time bins. Theta oscillations partition time into discrete segments and analysis was performed in these cycles separately (<xref ref-type="fig" rid="fig2">Figure 2c</xref>). Despite the large number of recorded neurons (68–242 putative excitatory cells in 8 sessions from 4 rats), position decoding had a limited accuracy (Fisher lower bound on the decoding error in 20ms bins: 16–30 cm vs. typical trajectory length ∼20 cm). Yet, in high spike count cycles we could approximately reconstruct the trajectories encoded in individual theta cycles (<xref ref-type="fig" rid="fig2">Figure 2c</xref>). We then compared the reconstructed trajectories to the actual trajectory of the animal. We observed substantial deviation between the decoded trajectories and the motion trajectory of the animal: decoded trajectories typically started near the actual location of the animal and then proceeded forward (<xref ref-type="bibr" rid="bib15">Foster and Wilson, 2007</xref>) often departing in both directions from the actual motion trajectory (<xref ref-type="bibr" rid="bib25">Kay et al., 2020</xref>; <xref ref-type="fig" rid="fig2">Figure 2c</xref>).</p><fig id="fig2" position="float"><label>Figure 2.</label><caption><title>Neural variability increases within theta cycle.</title><p>(<bold>a</bold>) Example spiking activity of 250 cells (top) and raw (black) and theta filtered (green) local field potential (bottom) for 6 consecutive theta cycles (vertical lines). (<bold>b</bold>) Place fields of 6 selected cells in a 2x2 m large open arena. Gray line indicates the motion trajectory during the run episode analysed in a-c. (<bold>c</bold>) Position decoded in overlapping 20ms time bins with 5ms shift (circles) during the 6 theta cycles shown in a. Time within theta cycle is color coded, gray indicates bins on the border of two cycles. Gray line shows the motion trajectory during the run episode, green crosses indicate the location of the animal in each cycle. (<bold>d</bold>) Decoding error for early, mid and late phase spikes (inset, top) calculated as a function of the time shift of the animal’s position along its motion trajectory (inset, right). For the analysis in panels d-e each theta cycle was divided into 3 parts with equal spike counts. (<bold>e</bold>) Relative place field size in late versus early theta spikes for the eight sessions (error bars: SD across n=80-263 cells). Gray bar: average and SD across all sessions (n=1264 cells). Inset: Place field size (ratemap area above 10% of the max firing rate) estimated from late vs. early theta spikes in an example session (individual dots correspond to individual place cells, blue cross: median). Only putative excitatory cells are included. To estimate the ratemaps, we shifted the reference positions with <inline-formula><mml:math id="inf1"><mml:mrow><mml:mi mathvariant="normal">Δ</mml:mi><mml:mo>⁢</mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:math></inline-formula> that minimized decoding error for the given theta phase (see panel d). (<bold>f</bold>) Decoded positions (dots, in 20 ms bins with 5 ms shift) relative to the instantaneous position and motion direction (cross), and 0.5 confidence interval (CI) ellipses for six different theta phases (color, as in panel g). (<bold>g</bold>) Bias (bottom, mean of the decoded positions) and spread (top, see Methods) of decoded positions as a function of theta phase for an example session. Panels d,f,g show data from theta cycles with the highest 10% of spike counts.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-74058-fig2-v1.tif"/></fig><p>To systematically analyse how this deviation depends on the theta phase, we sorted spikes into three classes (early, mid and late). For any given class, we decoded position from the spikes and compared it to the position of the animal shifted forward and backward along the motion trajectory. Time shift dependence of the accuracy of the decoders reveals the most likely portion of the trajectory the given class encodes (<xref ref-type="fig" rid="fig2">Figure 2d</xref>, see also <xref ref-type="fig" rid="fig4s2">Figure 4—figure supplement 2</xref>). For early spikes, the minimum of the average decoding error was shifted backward by ∼100ms, while for late spikes +500ms forward shift minimized the decoding error. Note that the position identified by the minima can only establish positions relative to the LED used to record the position of the animal. The relative shifts in the minima of the decoding error across different phases of theta are not affected by the arbitrariness of the positioning of the LED sources. The observed systematic biases indicate that theta sequences tended to start slightly behind the animal and extended into the near future (<xref ref-type="bibr" rid="bib15">Foster and Wilson, 2007</xref>; <xref ref-type="bibr" rid="bib19">Gupta et al., 2012</xref>).</p><p>Further, the minima of the decoding errors showed a clear tendency: position decoded from later phases displayed larger average deviation from the motion trajectory of the animal (<xref ref-type="fig" rid="fig2">Figure 2d</xref>). At the single neuron level, increased deviations at late theta phases resulted in the expansion of place fields (<xref ref-type="bibr" rid="bib51">Skaggs et al., 1996</xref>): Place fields were more compact when estimated from early-phase spikes than those calculated from late-phase activity (<xref ref-type="fig" rid="fig2">Figure 2e</xref>). At the population level, larger deviation between the motion trajectory and the late phase-decoded future positions can be attributed to the increased variability in encoded possible future locations. Indeed, when we aligned the decoded locations relative to the current location and motion direction of the animal, we observed that the spread of the decoded locations increased in parallel with the forward progress of their mean within theta cycles (<xref ref-type="fig" rid="fig2">Figure 2f, g</xref>). Taken together, this analysis demonstrated that the variability of the decoded positions is larger at the end of the theta cycle when encoding more uncertain future locations than at the beginning of the cycle when representing the past position.</p><p>The observed increase of the variability across theta cycles could be a direct consequence of encoding variable two-dimensional trajectories (<xref ref-type="fig" rid="fig4s2">Figure 4—figure supplement 2a, b</xref>) or it may be a signature of the neuronal representation of uncertainty. In the next sections, we set up a synthetic dataset to investigate the theta sequences and their variability in the four alternative coding schemes.</p></sec><sec id="s2-2"><title>Synthetic data: testbed for discriminating the encoding schemes</title><p>To analyse the distinctive properties of the different coding schemes and to develop specific measures capable of discriminating them, we generated a synthetic dataset in which both the behavioral component and the neural component could be precisely controlled. The behavioral component was matched to the natural movement statistics of rats during navigating a 2D environment. The neural component was constructed such that it could accommodate the alternative encoding schemes for prospective representations during navigation.</p><p>Our synthetic dataset had three consecutive levels. First, we simulated a planned trajectory for the rat in a two dimensional open arena by allowing smooth changes in the speed and motion direction (Methods, <xref ref-type="fig" rid="fig3s1">Figure 3—figure supplement 1a, b</xref>). Second, similar to the real situation, the simulated animal did not have access to its true position, <inline-formula><mml:math id="inf2"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>x</mml:mi><mml:mi>n</mml:mi></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula>, in theta cycle <inline-formula><mml:math id="inf3"><mml:mi>n</mml:mi></mml:math></inline-formula>, but had to infer it from the sensory inputs it had observed in the past, <inline-formula><mml:math id="inf4"><mml:msub><mml:mi>y</mml:mi><mml:mrow><mml:mn>1</mml:mn><mml:mo>:</mml:mo><mml:mi>n</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> (Methods). To perform this inference and predict its future position, the animal used a model of its own movements in the environment. In this dynamical generative model, the result of the inference is a posterior distribution over possible trajectories starting <inline-formula><mml:math id="inf5"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>n</mml:mi><mml:mi>p</mml:mi></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula> steps back in the past and ending <italic>n</italic><sub><italic>f</italic></sub> steps forward in the future. To generate the motion trajectory of the animal noisy motor commands were calculated from the difference between its planned trajectory and its inferred current position (Methods, <xref ref-type="fig" rid="fig3s1">Figure 3—figure supplement 1a, b</xref>). The kinematics was matched between simulation and experimental animals (<xref ref-type="fig" rid="fig3s2">Figure 3—figure supplement 2</xref>).</p><p>Third, in our simulations the hippocampal population activity encoded an inferred trajectory at an accelerated speed in each theta cycle such that the trajectory started in the past at the beginning of the simulated theta cycle and led to the predicted future states (locations) by the end of the theta cycle (<xref ref-type="fig" rid="fig3">Figure 3a–c</xref>). To approximately match the size of the synthetic and experimental data, we simulated the activity of 200 hippocampal pyramidal cells (<italic>place cells</italic>). Firing rates of pyramidal cells depended on the encoded spatial location using either of the four different coding schemes (Methods): In the <italic>mean</italic> code, the population encoded the single most likely trajectory without representing uncertainty. In <italic>product</italic> and <italic>DDC</italic> schemes, a snapshot of the population activity at any given theta phase encoded the estimated past or predicted future part of the trajectory in the form of a probability distribution (Methods). Finally, in the sampling scheme, in each theta cycle a single trajectory was sampled stochastically form the distribution of possible trajectories (<xref ref-type="fig" rid="fig3s1">Figure 3—figure supplement 1</xref>). Spikes were generated from the firing rates independently across neurons via an inhomogenous Poisson process. The posterior distribution was updated in every ∼100ms matching the length of theta cycles. Importantly, all of the four encoding schemes yielded single neuron and population activity dynamics consistent with the known features of hippocampal population activity including spatial tuning, phase precession (<xref ref-type="fig" rid="fig3">Figure 3d</xref>) and theta sequences (<xref ref-type="fig" rid="fig3">Figure 3e</xref>, see also <xref ref-type="fig" rid="fig3s3">Figure 3—figure supplement 3</xref>).</p><fig-group><fig id="fig3" position="float"><label>Figure 3.</label><caption><title>Theta sequences in simulated data.</title><p>(<bold>a</bold>) Motion trajectory of the simulated rat (gray, 10 s) together with its own inferred and predicted most likely (mean) trajectory segments (colored arrows) in five locations separated by 2 s (filled circles). These trajectories were represented in theta cycles using one of the four alternative schemes. (<bold>b</bold>) Same as panel a, but trajectories sampled from the posterior distribution. (<bold>c</bold>) Example represented trajectories aligned to the instantaneous position and direction of the simulated animal in the mean (top) and in the sampling (bottom) scheme. Ellipses indicate 50% CI of all theta cycles. Color code indicates start (red), mid (orange) and end (yellow) of the trajectories. (<bold>d</bold>) Simulated activity of 200 place cells sorted according to the location of their place fields on a linear track (200x10 cm) during an idealized 10 Hz theta oscillation using the mean encoding scheme. Red lines show the 1-dimensional trajectories represented in each theta cycle. Note that the overlap between trajectories is larger here than in panels a-b, because, for clarity, only trajectories at every 20th theta cycle are shown there. (<bold>e</bold>) Theta phase of spikes of an example simulated neuron (arrowhead in panel d) as a function of the animal’s position in the four coding schemes. (<bold>f</bold>) Decoding error from early, mid and late phase spikes (highest 5% spike count cycles) as a function of the time shift of the simulated animal’s position in a mean, product, DDC and sampling schemes. (<bold>g</bold>) Relative place field size in late versus early theta spikes for the four different encoding schemes (error bars: SD over 200 cells). Inset: place field size estimated from late vs. early theta spikes in the mean scheme. Median is indicated with red cross. (<bold>h</bold>) Decoding bias (bottom) and spread (top) as a function of theta phase for the four different encoding schemes. Decoding was performed in 120° bins with 45° shifts. All theta cycles are included in this analysis, as focusing on the highest spike count cycles highly influences these quantities in the product model.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-74058-fig3-v1.tif"/></fig><fig id="fig3s1" position="float" specific-use="child-fig"><label>Figure 3—figure supplement 1.</label><caption><title>Inference and movement in the generative model.</title><p>(<bold>a</bold>) Graphical model of the processes underlying the generation of the simulated animal’s trajectory. Arrows represent the individual steps in the generative process, orange arrows highlight sensory and motor noise and purple arrows show the steps of the inference process <inline-formula><mml:math id="inf6"><mml:mrow><mml:mi>P</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:msub><mml:mi>x</mml:mi><mml:mi>t</mml:mi></mml:msub><mml:mo lspace="2.5pt" rspace="2.5pt" stretchy="false">|</mml:mo><mml:mrow><mml:msub><mml:mi>y</mml:mi><mml:mrow><mml:mn>1</mml:mn><mml:mo>:</mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>u</mml:mi><mml:mrow><mml:mn>1</mml:mn><mml:mo>:</mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula>. At the unknown true location, <inline-formula><mml:math id="inf7"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>x</mml:mi><mml:mi>t</mml:mi></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula>, the animal receives a noisy sensory input, <inline-formula><mml:math id="inf8"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>y</mml:mi><mml:mi>t</mml:mi></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula>, and combines it with the previous motor command, <inline-formula><mml:math id="inf9"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>u</mml:mi><mml:mi>t</mml:mi></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula>, to update its current estimate of its location <inline-formula><mml:math id="inf10"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>P</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:msub><mml:mi>y</mml:mi><mml:mrow><mml:mn>1</mml:mn><mml:mo>:</mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>u</mml:mi><mml:mrow><mml:mn>1</mml:mn><mml:mo>:</mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mrow><mml:mi mathvariant="script">N</mml:mi></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>μ</mml:mi><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi mathvariant="normal">Σ</mml:mi><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mstyle></mml:math></inline-formula>. Based on its current position estimate and the intended position for the next time step, <inline-formula><mml:math id="inf11"><mml:msub><mml:mover accent="true"><mml:mi>x</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover><mml:mrow><mml:mi>t</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:math></inline-formula>, it calculates the next motor command, <inline-formula><mml:math id="inf12"><mml:msub><mml:mi>u</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:math></inline-formula>, that is used to generate the new position <inline-formula><mml:math id="inf13"><mml:msub><mml:mi>x</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:math></inline-formula>. Neuronal activity <inline-formula><mml:math id="inf14"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>s</mml:mi><mml:mi>t</mml:mi></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula> depends on the estimated position. (<bold>b</bold>) A 4 s segment of planned trajectory (gray) and motion trajectory (blue) together with the true, planned and inferred positions and the sensory input at 3 different time points separated by 1 s (colors). (<bold>c</bold>) The motion trajectory of the simulated animal (blue line) with its inferred past (dark gray) and predicted future (yellow) positions (points) represented as 25 trajectories sampled at position <inline-formula><mml:math id="inf15"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>x</mml:mi><mml:mi>t</mml:mi></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula> (triangle). (<bold>d</bold>) Same as panel b, except that distribution of trajectories are represented by covariance ellipses. (<bold>e</bold>) True trajectory (blue) and posterior mean trajectories at two subsequent timesteps (theta cycles, brown and orange). (<bold>f</bold>) Similar to panel e, but with trajectories sampled independently from the corresponding posterior distribution. Trajectory encoding error(<italic>TEE</italic>) denotes the difference between the true and the sampled trajectory, whereas cycle-to-cycle variability (<italic>CCV</italic>) is the difference between trajectories sampled in subsequent theta cycles. (<bold>g</bold>) Posterior variance (<inline-formula><mml:math id="inf16"><mml:msup><mml:mi>σ</mml:mi><mml:mn>2</mml:mn></mml:msup></mml:math></inline-formula>) and change in the mean trajectory (<inline-formula><mml:math id="inf17"><mml:msup><mml:mi>ζ</mml:mi><mml:mn>2</mml:mn></mml:msup></mml:math></inline-formula>) as a function of the time shift (sensory inputs and motor commands are observed till <inline-formula><mml:math id="inf18"><mml:mrow><mml:mi>n</mml:mi><mml:mo>=</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:math></inline-formula>). Shaded region shows SD. Trajectories with time shift <inline-formula><mml:math id="inf19"><mml:mrow><mml:mrow><mml:mo>-</mml:mo><mml:mn>10</mml:mn></mml:mrow><mml:mo>≤</mml:mo><mml:mi>n</mml:mi><mml:mo>≤</mml:mo><mml:mn>10</mml:mn></mml:mrow></mml:math></inline-formula> (corresponding to <inline-formula><mml:math id="inf20"><mml:mrow><mml:mrow><mml:mo>-</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mo>≤</mml:mo><mml:mrow><mml:mi mathvariant="normal">Δ</mml:mi><mml:mo>⁢</mml:mo><mml:mi>t</mml:mi></mml:mrow><mml:mo>≤</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:math></inline-formula> s) are encoded in each theta cycle between <inline-formula><mml:math id="inf21"><mml:mrow><mml:msup><mml:mn>0</mml:mn><mml:mo>∘</mml:mo></mml:msup><mml:mo>≤</mml:mo><mml:mi>φ</mml:mi><mml:mo>≤</mml:mo><mml:msup><mml:mn>360</mml:mn><mml:mo>∘</mml:mo></mml:msup></mml:mrow></mml:math></inline-formula>. Dashed line shows the linear fit, <inline-formula><mml:math id="inf22"><mml:mrow><mml:msup><mml:mi>ζ</mml:mi><mml:mn>2</mml:mn></mml:msup><mml:mo>≈</mml:mo><mml:mrow><mml:mi>α</mml:mi><mml:mo>⁢</mml:mo><mml:msup><mml:mi>σ</mml:mi><mml:mn>2</mml:mn></mml:msup></mml:mrow></mml:mrow></mml:math></inline-formula>.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-74058-fig3-figsupp1-v1.tif"/></fig><fig id="fig3s2" position="float" specific-use="child-fig"><label>Figure 3—figure supplement 2.</label><caption><title>Comparison of the motion profile of the simulated animal and one of the analysed experimental sessions.</title><p>(<bold>a-h</bold>) Motion profile of the simulated animal. (<bold>a</bold>) Histogram of the running speed. Orange vertical line indicates the mean of the distribution. (<bold>b</bold>) Auto-correlation of the running speed. Orange line shows the exponential fit with the corresponding time constant indicated. (<bold>c</bold>) Histogram of the acceleration. Orange line shows the fit with a Gaussian distribution with the fitted SD indicated. (<bold>d</bold>) Auto-correlation of the acceleration.Orange line shows the exponential fit with the fitted time constant. (<bold>e</bold>) Polar histogram of the running directions. (<bold>f</bold>) Auto-correlation of the head direction. Green line shows the exponential fit and the fitted time constant. (<bold>g</bold>) Histogram of the head direction change per time step (1/30 s). (<bold>h</bold>) Auto-correlation of the head direction change. Orange line shows the exponential fit and the fitted time constant. (<bold>i-q</bold>) Same as a-h for experimental session rat 1 day 2. Note, that for the experimental data we only analysed continuous running periods, where <inline-formula><mml:math id="inf23"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>v</mml:mi><mml:mo>&gt;</mml:mo><mml:mn>5</mml:mn></mml:mrow></mml:mstyle></mml:math></inline-formula> cm/s.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-74058-fig3-figsupp2-v1.tif"/></fig><fig id="fig3s3" position="float" specific-use="child-fig"><label>Figure 3—figure supplement 3.</label><caption><title>Place cell firing in the synthetic and in the experimental data.</title><p>(<bold>a-e</bold>) Place cell activity in the simulated data using mean encoding. (<bold>a</bold>) Histogram of the average firing rate of the 200 simulated neurons. Numbers indicate the average firing rate across cells and the average number of spikes in a 100 ms theta cycle. (<bold>b</bold>) Maximum firing rate as a function of place field size (area over the 10% of the maximum rate). Orange circles indicates cells with place fields shown in e. (<bold>c</bold>) Histogram of the Fisher lower bound for decoding error estimated for different positions in the arena. (<bold>d</bold>) Average firing rate as a function of spatial information. (<bold>e</bold>) Normalized ratemaps of the four cells selected (orange in panels b and d). (<bold>f-h</bold>) Similar to panel b for for the product (f), DDC (g) and the sampling (h) encoding schemes. (<bold>i-m</bold>) Same as a-e for experimental session rat 1 day 2. Note that panel j includes putative inhibitory cells (gray), whereas other panels show only putative excitatory neurons.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-74058-fig3-figsupp3-v1.tif"/></fig></fig-group><p>After generating the synthetic datasets, we investigated how positional information is represented during theta sequences in each of the four alternative coding schemes. We decoded the synthetic population activity in early, mid and late theta phases and compared the estimated position with the actual trajectory of the simulated animal. The deviation between the decoded position and the motion trajectory increased throughout the theta cycle irrespective of the coding scheme (<xref ref-type="fig" rid="fig3">Figure 3f</xref>) due to the combined effects of the divergence of possible future trajectories and the increased variability of the encoded locations. Moreover, place fields were significantly larger when estimated from late than early-phase spikes in all four encoding schemes (<xref ref-type="fig" rid="fig3">Figure 3g</xref>, <inline-formula><mml:math id="inf24"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mrow><mml:mi mathvariant="normal">P</mml:mi></mml:mrow><mml:mo>&lt;</mml:mo><mml:msup><mml:mn>10</mml:mn><mml:mrow><mml:mo>−</mml:mo><mml:mn>16</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:mstyle></mml:math></inline-formula> for each scheme). Finally, when aligned to the current position and motion direction of the simulated animal, the spread of the decoded locations increased with the advancement of their mean within theta cycles in all four coding schemes (<xref ref-type="fig" rid="fig3">Figure 3h</xref>).</p><p>Our analyses thus confirmed that the disproportionate increase in the variability of the encoded locations at late theta phase is consistent with encoding trajectories in a dynamical model of the environment irrespective of the representation of the uncertainty. These synthetic datasets provide a functional interpretation of the hippocampal population activity during theta oscillations and offer a unique testbed for contrasting different probabilistic encoding schemes. In the following sections, we will identify hallmarks for each of the encoding schemes of uncertainty and use these hallmarks to discriminate them through the analysis of neural data (<xref ref-type="fig" rid="fig4">Figure 4a</xref>).</p><fig-group><fig id="fig4" position="float"><label>Figure 4.</label><caption><title>Product scheme: population gain decreases with uncertainty.</title><p>(<bold>a</bold>) Decision-tree for identifying the encoding scheme. (<bold>b</bold>) Schematic of encoding a high-uncertainty (left) and a low-uncertainty (right) target distribution using the product scheme with 4 neurons. The variance is represented by the gain of the population. (<bold>c</bold>) Population firing rate (bottom) and forward decoding bias (top) as a function of theta phase for the four schemes in synthetic data. Only the product scheme predicts a systematic change in the firing rate. Error bars show SD across n=17990 theta cycles. (<bold>d</bold>) Correlation between firing rate and forward bias for the product scheme. Inset: Firing rate as a function of forward bias in the product scheme. Color code is the same as in f. (<bold>e</bold>) Decoded position relative to the location and motion direction of the animal (black arrow) at eight different theta phases in an example recording session. Filled circles indicate mean, ellipses indicate 50% CI of the data. (<bold>f</bold>) Forward decoding bias of the decoded position (top) and population firing rate (bottom) as a function of theta phase in an example recording session. Gray line in top and bottom show cosine fit to the forward decoding bias. Error bars show SD across n=9264 theta cycles. (<bold>g</bold>) Decoding bias (top) and firing rate (bottom) for all animals and sessions (line type). (<bold>h</bold>) Correlation between firing rate and forward bias for all recorded sessions. Gray bar: mean and SD across the eight sessions. Inset: Firing rate as a function of forward decoding bias in an example session. Bias in (e-g) was calculated using the 5% highest spike count theta cycles. Population firing rate plots show average over all cycles. In this figure, decoding was performed in 120° bins with 45° shifts.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-74058-fig4-v1.tif"/></fig><fig id="fig4s1" position="float" specific-use="child-fig"><label>Figure 4—figure supplement 1.</label><caption><title>Population gain as a hallmark of the product representation.</title><p>(<bold>a</bold>) The 110 tuning curves <inline-formula><mml:math id="inf25"><mml:mrow><mml:mi>ψ</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>x</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> from the example session R1D2 used in this analysis as basis function <inline-formula><mml:math id="inf26"><mml:mrow><mml:mrow><mml:mi>h</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>x</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mo>=</mml:mo><mml:mrow><mml:mrow><mml:mi>log</mml:mi><mml:mo>⁡</mml:mo><mml:msup><mml:mi>ψ</mml:mi><mml:mo>′</mml:mo></mml:msup></mml:mrow><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>x</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:math></inline-formula> (<xref ref-type="disp-formula" rid="equ37">Equation 36</xref>), with <inline-formula><mml:math id="inf27"><mml:mrow><mml:mrow><mml:msup><mml:mi>ψ</mml:mi><mml:mo>′</mml:mo></mml:msup><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>x</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mo>=</mml:mo><mml:mrow><mml:mrow><mml:mi>ψ</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>x</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mo>/</mml:mo><mml:mrow><mml:mo largeop="true" symmetric="true">∫</mml:mo><mml:mrow><mml:mi>ψ</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>x</mml:mi><mml:mo rspace="4.2pt" stretchy="false">)</mml:mo></mml:mrow><mml:mo>⁢</mml:mo><mml:mrow><mml:mo rspace="0pt">d</mml:mo><mml:mi>x</mml:mi></mml:mrow></mml:mrow></mml:mrow></mml:mrow></mml:mrow></mml:math></inline-formula>. (<bold>b</bold>) Representing distributions of increasing uncertainty in the product form using the basis functions shown in panel a. Top: target isotropic Gaussian distributions with increasing SD. Bottom: Approximate distributions with the total number of spikes indicated on the lower left corner. (<bold>c</bold>) The number of spikes required for optimally approximating a distribution decreases as a function of the target SD. Boxplots show median, quartiles and data range. (<bold>d</bold>) The number of spikes (mean and SD across n=50 samples) as a function of the inverse of the variance (precision) and a linear fit (red) to the data.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-74058-fig4-figsupp1-v1.tif"/></fig><fig id="fig4s2" position="float" specific-use="child-fig"><label>Figure 4—figure supplement 2.</label><caption><title>Theta sequence bias and variability in all recording sessions.</title><p>(<bold>a</bold>) Location and direction-aligned motion trajectories and 0.5 confidence interval ellipses for <inline-formula><mml:math id="inf28"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mo>−</mml:mo><mml:mn>1</mml:mn><mml:mo>≥</mml:mo><mml:mi mathvariant="normal">Δ</mml:mi><mml:mi>t</mml:mi><mml:mo>≥</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:mstyle></mml:math></inline-formula>. (<bold>b</bold>) Bias and spread of motion trajectories as a function of time in an example session. (<bold>c</bold>) Left: Decoding bias (top) and firing rate (bottom) as a function of theta phase calculated for all theta cycles. Error bars show SD across n=8483-16419 theta cycles. Right: Decoding error for early, mid and late phase spikes calculated as a function of time shift of reference position along the motion trajectory of the animal for all theta cycles (thick lines) or theta cycles with the highest 5% of spike counts (symbols, with the minimum spike count per bin indicated). (<bold>d-j</bold>) Same as panel c for other recording sessions.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-74058-fig4-figsupp2-v1.tif"/></fig><fig id="fig4s3" position="float" specific-use="child-fig"><label>Figure 4—figure supplement 3.</label><caption><title>No evidence for encoding parameters of distributions via product or DDC schemes in linear track data.</title><p>(<bold>a</bold>) Normalized firing rate of all putative excitatory neurons recorded in a single session (Achilles, up) ordered by the location of the peak activity on rightward runs from a previously published dataset (<xref ref-type="bibr" rid="bib18">Grosmark et al., 2016</xref>). (<bold>b</bold>) Median forward bias and average firing rate as a function of the theta phase calculated in <inline-formula><mml:math id="inf29"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msup><mml:mn>120</mml:mn><mml:mo>∘</mml:mo></mml:msup></mml:mrow></mml:mstyle></mml:math></inline-formula> windows with <inline-formula><mml:math id="inf30"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msup><mml:mn>45</mml:mn><mml:mo>∘</mml:mo></mml:msup></mml:mrow></mml:mstyle></mml:math></inline-formula> shift for the example session in panel a. Error bars show SEM across n=1846 theta cycles. Inset: the distribution of the decoded locations relative to the position of the animal (vertical line) as a function of theta phase (color) and firing rate versus median decoded location (top) for the different theta phases (color). (<bold>c</bold>) Median forward bias (top) and average firing rate (bottom) as a function of the theta phase for all recording sessions. Peak forward bias is shifted to <inline-formula><mml:math id="inf31"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msup><mml:mn>270</mml:mn><mml:mo>∘</mml:mo></mml:msup></mml:mrow></mml:mstyle></mml:math></inline-formula>, diamonds indicate the peak of the firing rate. Color indicate animal name and line style indicates running direction. (<bold>d</bold>) Correlation between median forward bias and firing rate is typically positive except for one outlier. We note, that the number of recorded neurons was the lowest for the outlier rat (Buddy; N=15 cells with place field on right and N=16 on left runs.) (<bold>e</bold>) Cumulative distribution of the estimated SD for different distributions encoded with a 1 dimensional DDC scheme. Gaussian distributions of different means and SDs were encoded using the tuning functions derived from the place fields shown in panel a with the same number of theta cycles (N=1846) and bin width (<inline-formula><mml:math id="inf32"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi mathvariant="normal">Δ</mml:mi><mml:mi>t</mml:mi><mml:mo>=</mml:mo><mml:mn>36</mml:mn></mml:mrow></mml:mstyle></mml:math></inline-formula> ms) as in the experimental data (g–h). (<bold>f</bold>) Mean decoded SD at different values of the true SD. At this short time window the decoder is still biased (see <xref ref-type="fig" rid="fig5">Figure 5</xref>), but the decoded SD correlates with the true SD. Error bars show SEM across n=1846 theta cycles. (<bold>g</bold>) Cumulative distribution of the decoded SD for early, mid and late theta phases for the same session as in panels a-b. We used sharpened tuning functions to reduce the decoding bias. (<bold>h</bold>) Mean decoded SD at different theta phases. Error bars show SEM across n=1846 theta cycles. (<bold>i</bold>) Mean decoded SD at different theta phases for all recorded sessions. Color code is the same as in panels c-d. Only one of the animals (Gatsby) showed an increase in the decoded SD within the theta cycle. Gray symbols show mean and SD across animals. All experimental data presented in this figure was obtained from <xref ref-type="bibr" rid="bib18">Grosmark et al., 2016</xref>.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-74058-fig4-figsupp3-v1.tif"/></fig></fig-group></sec><sec id="s2-3"><title>Testing the product scheme: gain</title><p>To discriminate the product scheme from other representations, we capitalize on the specific relationship between response intensity of neurons and uncertainty of the represented variable. In a product representation, a probability distribution over a feature, such as the position, is encoded by the product of the neuronal basis functions (Methods). When the basis functions are localized, as in the case of hippocampal place fields, the width of the encoded distribution tends to decrease with the total number of spikes in the population (<xref ref-type="bibr" rid="bib29">Ma et al., 2006</xref>, <xref ref-type="fig" rid="fig4">Figure 4b</xref>, Appendix 1, <xref ref-type="fig" rid="fig4s1">Figure 4—figure supplement 1</xref>). Therefore, we propose using the systematic decrease of the population firing rate (<italic>gain</italic>) with increasing uncertainty as a hallmark of the product scheme.</p><p>We first tested for the specificity of the co-modulation of the population gain with uncertainty to the product scheme: we compared gain modulation in the four different coding schemes in our synthetic dataset. In each of the coding schemes, we identified the theta phase with the maximal uncertainty by the maximal forward bias in encoded positions. For this, we decoded positions from spikes using eight overlapping 120° windows in theta cycles and defined the end of the theta cycles based on the maximum of the average forward bias (<xref ref-type="fig" rid="fig4">Figure 4C</xref> top). Then we calculated the average number of spikes in a given 120° window as a function of the theta phase. We found that the product scheme predicted a systematic, ∼threefold modulation of the firing rate within the theta cycle (<xref ref-type="fig" rid="fig4">Figure 4c</xref>, bottom). The peak of the firing rate coincided with the start of the encoded trajectory, where the uncertainty is minimal and the correlation between the firing rate and the forward bias was negative (<xref ref-type="fig" rid="fig4">Figure 4d</xref>). The three other coding schemes did not constrain the firing rate of the population to represent probabilistic quantities, and thus the firing rate was independent of the theta phase or the encoded uncertainty.</p><p>After demonstrating the specificity of uncertainty-related gain modulation to the product scheme, we returned to the experimental dataset and applied the same analysis to neuronal activity recorded from freely navigating rats. We first decoded the spikes during theta oscillation falling in eight overlapping 120° window and aligned the decoded locations relative to the animals’ position and motion direction. We confirmed that the encoded location varied systematically within the theta cycle from the beginning towards the end of the theta cycle both when considering all theta cycles (<xref ref-type="fig" rid="fig4s2">Figure 4—figure supplement 2</xref>) or when constraining the analysis to theta cycles with the highest 5% spike count (<xref ref-type="fig" rid="fig4">Figure 4e, f</xref>; <xref ref-type="fig" rid="fig2">Figure 2f, g</xref>). Maximal population firing rate coincided with the end of the theta sequences which correspond to future positions characterized by the highest uncertainty (<xref ref-type="fig" rid="fig4">Figure 4f</xref>). Thus, a positive correlation emerged between the represented uncertainty and the population gain (<xref ref-type="fig" rid="fig4">Figure 4h</xref>). This result was consistent across recording sessions and animals (<xref ref-type="fig" rid="fig4">Figure 4g, h</xref>) and was also confirmed in an independent dataset where rats were running on a linear track (<xref ref-type="fig" rid="fig4s3">Figure 4—figure supplement 3a–d</xref>; <xref ref-type="bibr" rid="bib18">Grosmark et al., 2016</xref>).</p><p>This observation is in sharp contract with the prediction of the product encoding scheme where the maximum of the firing rate should be near the beginning of the theta sequences (<xref ref-type="fig" rid="fig4">Figure 4c</xref>). The other encoding schemes are neutral about the theta modulation of the firing rate, and therefore they are all consistent with the observed small phase-modulation of the firing rate.</p></sec><sec id="s2-4"><title>Testing the DDC scheme: diversity</title><p>Next, we set out to discriminate the DDC scheme from the mean and the sampling schemes. In the DDC scheme, neuronal firing rate represents the overlap of the basis functions with the encoded distribution (<xref ref-type="fig" rid="fig1">Figure 1e</xref>; <xref ref-type="bibr" rid="bib65">Zemel et al., 1998</xref>; <xref ref-type="bibr" rid="bib56">Vértes and Sahani, 2018</xref>). Intuitively, in this scheme the diversity of the co-active neurons increases as the variance of the encoded distribution increases, i.e. when the encoded variance is small, only a smaller fraction of basis functions will overlap with the distribution, thus limiting the number of neurons participating in encoding. (<xref ref-type="fig" rid="fig5">Figure 5a</xref>). Conversely, a diverse set of neurons becomes co-active when encoding a distribution of high variance (<xref ref-type="fig" rid="fig5">Figure 5a</xref>). Therefore, the set of active neurons reflects the width of the encoded probability distribution. This feature of the population code carries information about uncertainty, which can thus be decoded from the population activity (<xref ref-type="fig" rid="fig5s1">Figure 5—figure supplement 1b</xref>). We used a maximum likelihood decoder to estimate the first two moments (mean and SD) of the encoded distribution (Methods, <xref ref-type="disp-formula" rid="equ20">Equation 19</xref>). Intuitively, increased uncertainty at later stages of the trajectory is expected to be reflected in a parallel increase in the decoded SD, and we propose to use this systematic increase of decoded SD as a hallmark of DDC encoding.</p><fig-group><fig id="fig5" position="float"><label>Figure 5.</label><caption><title>DDC scheme: diversity increases with uncertainty.</title><p>(<bold>a</bold>) Schematic of encoding a narrow (left) and a wide (right) distribution with spike-based DDC using four neurons. Intuitively, the standard deviation (SD) is represented by the diversity of the co-active neurons. (<bold>b</bold>) Cumulative distribution function (CDF, accross theta cycles) of the decoded SD from spikes at different theta phases for the mean (left), DDC (middle) and sampling schemes (right) in the simulated dataset. (<bold>c</bold>) Mean and SE (across n=14954 theta cycles) of decoded SD as a function of theta phase for the different schemes in the simulated dataset. Only the DDC code predicts a slight, but significant increase in the decoded SD at late theta phases. (<bold>d</bold>) Same as panel c, calculated from theta cycles with higher than median spike count (SE across n=7214 theta cycles). (<bold>e</bold>) CDF of the decoded SD from spikes in early, mid and late phase of the theta cycles (across all cycles) for the analysed sessions.(<bold>f, g</bold>) Mean of the decoded SD for each animal from early, mid and late theta spikes using all theta cycles (<bold>f</bold>) or theta cycles with higher than median spikecount (<bold>g</bold>). Grey symbols show mean and SD across sessions. See also <xref ref-type="fig" rid="fig5s2">Figure 5—figure supplement 2</xref> for similar analysis using the estimated encoding basis functions instead of the empirical tuning curves for decoding and <xref ref-type="fig" rid="fig5s3">Figure 5—figure supplement 3</xref> for the predictions of the product scheme.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-74058-fig5-v1.tif"/></fig><fig id="fig5s1" position="float" specific-use="child-fig"><label>Figure 5—figure supplement 1.</label><caption><title>Reducing the bias of the decoded SD in the DDC scheme.</title><p>(<bold>a</bold>) Illustration of the problem of decoding bias. In the DDC scheme, the firing rate of the neurons is proportional to the overlap between the target distribution and the basis functions of the neurons (black shading). It is possible to approximately reconstruct the encoded distribution from the spikes observed in the population activity and the basis functions (bottom left). However, when the tuning functions used for decoding are different than the basis functions used for encoding than the reconstruction will be biased: Wider tuning functions showing similar overlap with a narrower distribution lead to systematic underestimation of the variance of the encoded distribution (bottom right). (<bold>b</bold>) Average of the estimated mean (top) and SD (bottom) of two-dimensional Gaussian distributions decoded in a spike-based DDC scheme with different temporal windows using the true encoding basis functions <inline-formula><mml:math id="inf33"><mml:mrow><mml:mi>ϕ</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>x</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula>. Shading represents the standard error across 1000 repetitions for each combination of time bin and encoded SD. Decoding is approximately unbiased for <inline-formula><mml:math id="inf34"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi mathvariant="normal">Δ</mml:mi><mml:mi>t</mml:mi><mml:mo>≥</mml:mo><mml:mn>50</mml:mn></mml:mrow></mml:mstyle></mml:math></inline-formula> ms. (<bold>c</bold>) Same as b using the empirical rate maps for decoding instead of the true encoding basis functions. The decoded SD is biased even for <inline-formula><mml:math id="inf35"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi mathvariant="normal">Δ</mml:mi><mml:mi>t</mml:mi><mml:mo>≥</mml:mo><mml:mn>50</mml:mn></mml:mrow></mml:mstyle></mml:math></inline-formula> ms. (<bold>d</bold>) Same as b using the estimated encoding basis functions after three (left) or six (right) sharpening steps for decoding. Sharpening the tuning curves for three steps eliminates the negative decoding bias while further sharpening introduces a positive bias. (<bold>e</bold>) Ratio of the estimated and the true encoding basis function sizes for different estimation strategies: empirical tuning curves (place fields) and estimated after three to nine sharpening steps. The size of the estimated basis function is closest to the original around 6 sharpening steps. (<bold>f</bold>) Average absolute difference between the true basis function and the estimation across 200 cells is decreased after algorithmic sharpening the tuning curves. The difference is minimal after three to six sharpening steps. (<bold>g</bold>) Examples for the original two-dimensional basis functions in the synthetic data (top), empirical tuning curves (2nd row) and basis functions estimated using three (3rd row) or six (bottom) sharpening steps.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-74058-fig5-figsupp1-v1.tif"/></fig><fig id="fig5s2" position="float" specific-use="child-fig"><label>Figure 5—figure supplement 2.</label><caption><title>No evidence for DDC code when decoding spikes using the estimated basis functions instead of the empirical tuning curves.</title><p>No evidence for DDC code when decoding spikes using the estimated basis functions instead of the empirical tuning curves. (<bold>a-b</bold>) Estimated standard deviation of the DDC-decoded distribution from spikes at early, mid and late theta phases using the estimated basis functions after 3 sharpening steps using all theta cycles (a) or theta cycles with higher than median spike count (b). Only the distribution encoded via the DDC scheme provides consistent increase in the estimated SD from early to late theta phase. Symbols show mean and SE across n=14954 (a) or n=7214 (b) theta cycles. p-values of one-sided, two sample Kolmogorov-Smirnov test comparing the distribution of early versus late for panel a: mean: <inline-formula><mml:math id="inf36"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>P</mml:mi><mml:mo>=</mml:mo><mml:mn>0.99</mml:mn></mml:mrow></mml:mstyle></mml:math></inline-formula>, DDC: <inline-formula><mml:math id="inf37"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>P</mml:mi><mml:mo>=</mml:mo><mml:mn>5</mml:mn><mml:mo>×</mml:mo><mml:msup><mml:mn>10</mml:mn><mml:mrow><mml:mo>−</mml:mo><mml:mn>33</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:mstyle></mml:math></inline-formula>, sampling: <inline-formula><mml:math id="inf38"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>P</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:mstyle></mml:math></inline-formula>; for panel b: mean: <inline-formula><mml:math id="inf39"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>P</mml:mi><mml:mo>=</mml:mo><mml:mn>0.99</mml:mn></mml:mrow></mml:mstyle></mml:math></inline-formula>, DDC: <inline-formula><mml:math id="inf40"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>P</mml:mi><mml:mo>=</mml:mo><mml:mn>8.7</mml:mn><mml:mo>×</mml:mo><mml:msup><mml:mn>10</mml:mn><mml:mrow><mml:mo>−</mml:mo><mml:mn>28</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:mstyle></mml:math></inline-formula>, sampling: <inline-formula><mml:math id="inf41"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>P</mml:mi><mml:mo>=</mml:mo><mml:mn>0.94</mml:mn></mml:mrow></mml:mstyle></mml:math></inline-formula>. (<bold>c-d</bold>) Mean of the decoded SD for each animal from early, mid and late theta spikes using all theta cycles (c) or theta cycles with higher than median spike count (d) calculated using the estimated basis functions. Gray symbols show mean and SD across sessions tested individually. See also <xref ref-type="fig" rid="fig5">Figure 5</xref> for similar analysis using the empirical tuning curves and <xref ref-type="fig" rid="fig5s3">Figure 5—figure supplement 3</xref> for the predictions of the product scheme. p-values of one-sided, two sample Kolmogorov-Smirnov test comparing the distribution of early versus late for panel c: <inline-formula><mml:math id="inf42"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>P</mml:mi><mml:mo>&gt;</mml:mo><mml:mn>0.1</mml:mn></mml:mrow></mml:mstyle></mml:math></inline-formula> for all animals; panel d: <inline-formula><mml:math id="inf43"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>P</mml:mi><mml:mo>&gt;</mml:mo><mml:mn>0.4</mml:mn></mml:mrow></mml:mstyle></mml:math></inline-formula> for all animals.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-74058-fig5-figsupp2-v1.tif"/></fig><fig id="fig5s3" position="float" specific-use="child-fig"><label>Figure 5—figure supplement 3.</label><caption><title>Summary figure showing the decoded SD and EV-index for all encoding schemes.</title><p>(<bold>a</bold>) Similar to <xref ref-type="fig" rid="fig5">Figure 5c, d</xref> but also including data for the product scheme. Estimated standard deviation of the DDC-decoded distribution from spikes at early, mid and late theta phases using the empirical tuning curves including all theta cycles (left) or theta cycles with higher than median spike count (right). This large increase in the case of the product code is associated with the low firing rate at the end of the theta cycle in this scheme. Specifically, when we divide the theta cycle into periods of equal spike counts, the last bin (’late’) is responsible for a longer portion of the encoded trajectory and thus cells active in the late phase have more diverse tuning curves. p-values of one-sided, two sample Kolmogorov-Smirnov test comparing the distribution of early versus late for the product scheme, all cycles: <inline-formula><mml:math id="inf44"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>P</mml:mi><mml:mo>=</mml:mo><mml:mn>4</mml:mn><mml:mo>×</mml:mo><mml:msup><mml:mn>10</mml:mn><mml:mrow><mml:mo>−</mml:mo><mml:mn>87</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:mstyle></mml:math></inline-formula>; high spike count cycles: <inline-formula><mml:math id="inf45"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>P</mml:mi><mml:mo>=</mml:mo><mml:mn>7</mml:mn><mml:mo>×</mml:mo><mml:msup><mml:mn>10</mml:mn><mml:mrow><mml:mo>−</mml:mo><mml:mn>53</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:mstyle></mml:math></inline-formula>. Other P-values were reported in the caption of <xref ref-type="fig" rid="fig5">Figure 5</xref>. (<bold>b</bold>) Similar to <xref ref-type="fig" rid="fig5s2">Figure 5—figure supplement 2a, b</xref> but also including data for the product scheme. p-values of one-sided, two sample Kolmogorov-Smirnov test comparing the distribution of early versus late for the product scheme, all cycles: <inline-formula><mml:math id="inf46"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>P</mml:mi><mml:mo>=</mml:mo><mml:mn>7</mml:mn><mml:mo>×</mml:mo><mml:msup><mml:mn>10</mml:mn><mml:mrow><mml:mo>−</mml:mo><mml:mn>88</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:mstyle></mml:math></inline-formula>; high spike count cycles: <inline-formula><mml:math id="inf47"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>P</mml:mi><mml:mo>=</mml:mo><mml:mn>7</mml:mn><mml:mo>×</mml:mo><mml:msup><mml:mn>10</mml:mn><mml:mrow><mml:mo>−</mml:mo><mml:mn>67</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:mstyle></mml:math></inline-formula>. Other P-values were reported in the caption of <xref ref-type="fig" rid="fig5s2">Figure 5—figure supplement 2</xref>. Symbols show mean and SE across n=14954 (left) and n=7214 (right) theta cycles. (<bold>c</bold>) The EV-index for all encoding schemes calculated from the mean across theta cycles with simulating regular or irregular theta-trajectories either using all theta cycles (left) or only the theta cycles with high spike count (right). The data for the mean and the sampling schemes are replotted from <xref ref-type="fig" rid="fig6">Figure 6f, g</xref> and <xref ref-type="fig" rid="fig6s1">Figure 6—figure supplement 1e, f</xref>. Error bars show SE across n=17989, 14956, 5300 and 4529 theta cycle-pairs, respectively.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-74058-fig5-figsupp3-v1.tif"/></fig></fig-group><p>First, we turned to our synthetic dataset to demonstrate that systematic changes in decoded SD are specific to this scheme. In each of the three remaining coding schemes (mean, DDC and sampling), we divided the population activity to three distinct windows relative to the theta cycle (early, mid, and late). We decoded the mean and the SD of the encoded distribution of trajectories (<xref ref-type="fig" rid="fig5">Figure 5b</xref> inset) using the empirical tuning curves in each theta cycle and analysed the systematic changes in the decoded SD values from early to late theta phase (Methods). We found a systematic and significant increase in the decoded SD in the DDC scheme from early to late theta phases (one-sided, two sample Kolmogorov-Smirnov test, <inline-formula><mml:math id="inf48"><mml:mrow><mml:mi>P</mml:mi><mml:mo>=</mml:mo><mml:mrow><mml:mn>1.3</mml:mn><mml:mo>×</mml:mo><mml:msup><mml:mn>10</mml:mn><mml:mrow><mml:mo>-</mml:mo><mml:mn>16</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:mrow></mml:math></inline-formula>), whereas the decoded SD was independent of the theta phase for the mean and the sampling schemes (KS test, mean scheme: <inline-formula><mml:math id="inf49"><mml:mrow><mml:mi>P</mml:mi><mml:mo>=</mml:mo><mml:mn>0.98</mml:mn></mml:mrow></mml:math></inline-formula>, sampling scheme: <inline-formula><mml:math id="inf50"><mml:mrow><mml:mi>P</mml:mi><mml:mo>=</mml:mo><mml:mn>0.95</mml:mn></mml:mrow></mml:math></inline-formula>, <xref ref-type="fig" rid="fig5">Figure 5b, c</xref>). This result was robust against using the theta cycles with higher than median spike count for the analysis (<xref ref-type="fig" rid="fig5">Figure 5d</xref>, mean: <inline-formula><mml:math id="inf51"><mml:mrow><mml:mi>P</mml:mi><mml:mo>=</mml:mo><mml:mn>0.99</mml:mn></mml:mrow></mml:math></inline-formula>, DDC: <inline-formula><mml:math id="inf52"><mml:mrow><mml:mi>P</mml:mi><mml:mo>=</mml:mo><mml:mrow><mml:mn>8.2</mml:mn><mml:mo>×</mml:mo><mml:msup><mml:mn>10</mml:mn><mml:mrow><mml:mo>-</mml:mo><mml:mn>12</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:mrow></mml:math></inline-formula>, sampling: <inline-formula><mml:math id="inf53"><mml:mrow><mml:mi>P</mml:mi><mml:mo>=</mml:mo><mml:mn>0.93</mml:mn></mml:mrow></mml:math></inline-formula>) or against using the estimated basis functions instead of the empirical tuning curves for decoding (<xref ref-type="fig" rid="fig5s2">Figure 5—figure supplement 2b</xref>; Appendix 2). Thus, our analysis of synthetic data demonstrated that the decoded SD is a reliable measure to discriminate the DDC scheme from sampling or mean encoding.</p><p>After testing on synthetic data, we repeated the same analysis on the experimental dataset. We divided each theta cycle into three windows of equal spike counts (early, mid, and late) and decoded the mean and the SD of the encoded trajectories from the population activity in each window. We found that the decoded SDs had a nearly identical distribution at the three theta phases for all recording sessions (<xref ref-type="fig" rid="fig5">Figure 5e</xref>). The mean of the decoded SD did not change significantly or consistently across the recording session neither when we analysed all theta cycles (early vs. late, KS test <inline-formula><mml:math id="inf54"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>P</mml:mi><mml:mo>&gt;</mml:mo><mml:mn>0.62</mml:mn></mml:mrow></mml:mstyle></mml:math></inline-formula> for all sessions, <xref ref-type="fig" rid="fig5">Figure 5e, f</xref>) nor when we constrained the analysis to the half of the cycles with higher than median spike count (KS test, <inline-formula><mml:math id="inf55"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>P</mml:mi><mml:mo>&gt;</mml:mo><mml:mn>0.7</mml:mn></mml:mrow></mml:mstyle></mml:math></inline-formula> for all sessions, <xref ref-type="fig" rid="fig5">Figure 5g</xref>) or when we used the estimated encoding basis functions instead of the empirical tuning curves for decoding (<xref ref-type="fig" rid="fig5s2">Figure 5—figure supplement 2d</xref>). We obtained similar results in a different dataset with rats running on a linear track (<xref ref-type="fig" rid="fig4s3">Figure 4—figure supplement 3e-i</xref>; <xref ref-type="bibr" rid="bib18">Grosmark et al., 2016</xref>). We conclude that there are no signatures of DDC encoding scheme in the hippocampal population activity during theta oscillation. Taken together with the findings on the product scheme, our results indicate that hippocampal neurons encode individual trajectories rather than entire distributions during theta sequences.</p></sec><sec id="s2-5"><title>Testing the sampling scheme: excess variability</title><p>Both the mean scheme and the sampling scheme represent individual trajectories but only the sampling scheme is capable of representing uncertainty. Therefore, a critical question concerns if the two schemes can be distinguished based on the population activity during theta sequences. Sampling-based codes are characterized by large and structured trial-to-trial neuronal variability (<xref ref-type="bibr" rid="bib41">Orbán et al., 2016</xref>). Our results showed a systematic increase in the variability of the decoded location at phases of theta oscillation that correspond to later portions of the trajectory associated with higher uncertainty. This parallel increase of variability and uncertainty could be taken as evidence towards the sampling scheme. However, we demonstrated that the systematic theta phase-dependence of the neural variability and the variability of the encoded trajectories is a general feature of predictions in a dynamical model characterizing both the sampling and the mean schemes (<xref ref-type="fig" rid="fig3">Figure 3</xref>). In the sampling scheme, the cycle-to-cycle variability is further increased by the sampling variance, that is the stochasticity of the represented trajectory, such that the magnitude of excess variance is proportional to uncertainty. In order to discriminate sampling from the mean scheme we designed a measure, excess variability, that can identify the additional variance resulting from sampling. For this, we partitioned the variability of encoded trajectories such that the full magnitude of variability across theta cycles (cycle-to-cycle variability, <italic>CCV</italic>) is compared to the amount of variability expected from the animal’s own uncertainty (trajectory encoding error, <italic>TEE</italic>, <xref ref-type="fig" rid="fig6">Figure 6a</xref>, Methods).</p><fig-group><fig id="fig6" position="float"><label>Figure 6.</label><caption><title>Sampling scheme: excess variability increases with uncertainty.</title><p>(<bold>a</bold>) To discriminate sampling from mean encoding, we defined the EV-index which measures the magnitude of cycle-to-cycle variability (<italic>CCV</italic>) relative to the trajectory encoding error (<italic>TEE</italic>). (<bold>b</bold>) Cumulative distribution of <italic>CCV</italic> (dashed) and <italic>TEE</italic> (solid) across theta cycles for early, mid and late theta phase (colors) in the mean scheme using simulated data. Note the logarithmic x axis. (<bold>c</bold>) Mean <italic>CCV</italic> and <italic>TEE</italic> calculated from early, mid and late phase spikes in the mean scheme. (<bold>d-e</bold>) Same as (b-c) for the sampling scheme. (<bold>f-g</bold>) The EV-index for the mean (f) and sampling (g) schemes with simulating regular or irregular theta-trajectories (left inset) and applying various amount of jitter for segmenting the theta cycles (color code, right inset). Error bars show SE across n=5300 (regular) and n=4529 (irregular) theta cycle-pairs. (<bold>h</bold>) Cumulative distribution of <italic>CCV</italic> (dashed) and <italic>TEE</italic> (solid) across theta cycles for early, mid, and late theta phase (colors) for an example recording session. Note the logarithmic x axis. Arrows in inset highlight atypically large errors occurring mostly at early theta phase. (<bold>i-j</bold>) Mean (i) and median (j) of <italic>CCV</italic> and <italic>TEE</italic> calculated from early, mid and late phase spikes for the session shown in h. (<bold>k-l</bold>) EV-index calculated for all analysed sessions (color) and across session mean and SD (gray) using the mean (k) or the median (l) across theta cycles. Error bars show SE in k and 5% and 95% confidence interval in l across n=3098-6558 theta cycle-pairs. p-values are shown in <xref ref-type="table" rid="table3">Table 3</xref>. Here, we analysed only theta cycles with higher than median spike count. See <xref ref-type="fig" rid="fig6s1">Figure 6—figure supplement 1</xref> for similar analysis including all theta cycles and <xref ref-type="fig" rid="fig5s3">Figure 5—figure supplement 3</xref> for the EV-index calculated using the product and DDC schemes.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-74058-fig6-v1.tif"/></fig><fig id="fig6s1" position="float" specific-use="child-fig"><label>Figure 6—figure supplement 1.</label><caption><title>EV-index calculated from all theta cycles.</title><p>(<bold>a</bold>) Cumulative distribution of <italic>CCV</italic> (dashed) and <italic>TEE</italic> (solid) for early, mid, and late theta phase (colors) in the mean scheme using simulated data. Note the logarithmic x axis. (<bold>b</bold>) Mean <italic>CCV</italic> and <italic>TEE</italic> calculated from early, mid, and late phase spikes in the mean scheme. (<bold>c, d</bold>) Same as a-b for the sampling scheme. (<bold>e, f</bold>) The EV-index for the mean (e) and sampling (f) schemes calculated from the mean across theta cycles with simulating regular or irregular theta-trajectories after applying various amount of jitter for segmenting the theta cycles (color code, right inset). Error bars show SE across n=17989 (regular) and n=14956 (irregular) theta cycle-pairs. (<bold>g</bold>) Cumulative distribution of <italic>CCV</italic> (dashed) and <italic>TEE</italic> (solid) for early, mid and late theta phase (colors) for session R1D2. Note the logarithmic x axis. Arrows in the inset highlight atypically large errors occurring mostly at early theta phase. (<bold>h-i</bold>) Mean (h) and median (i) of <italic>CCV</italic> and <italic>TEE</italic> calculated from early, mid, and late phase spikes for session R1D2. (<bold>j-k</bold>) EV-index calculated for all analysed sessions (color) and across session mean and SD (gray) using the mean (j) or the median (k) across all theta cycles. See <xref ref-type="fig" rid="fig6">Figure 6</xref> for the same analysis including only theta cycles with high spike count and <xref ref-type="fig" rid="fig5s3">Figure 5—figure supplement 3c</xref> for the EV-index calculated using the product and DDC schemes. Error bars show standard error except for k where they indicate the 5% and 95% confidence interval around the median across n=8081-16047 theta cycle-pairs. p-values for panels e-f and j-k are shown in <xref ref-type="table" rid="table4">Table 4</xref>.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-74058-fig6-figsupp1-v1.tif"/></fig><fig id="fig6s2" position="float" specific-use="child-fig"><label>Figure 6—figure supplement 2.</label><caption><title>Spatial representation and EV-index is similar across task phases.</title><p>(<bold>a</bold>) Violin plots showing that the distribution of the running speeds are highly overlapping in home (goal directed navigation) and away (random foraging) trials in all recorded sessions. Symbols show mean and SD across n=4794-14624 datapoints. (<bold>b</bold>) Estimated tuning curves in an example session (R1D1) using all trials (top), only home trials (2nd row) or only away trials (3rd row). The maximal firing rate of each ratemap is indicated in the lower left corner. Colomaps are identical within each column. The number above each column is the normalized home-away difference, also shown in panel d. (<bold>c</bold>) Proportion of neurons with significantly (p&lt;0.05) different ratemaps between home and away trials. To assess the significance of the remapping, we calculated ratemaps using either home (2nd row in panel c) and away trials (3rd row in panel c) separately, and compared their difference to a shuffling control (randomly splitting the session 100 times into two halves with duration matched to the duration of home and away trials). Less then half of the cells had a home-away difference larger than shuffle control. (<bold>d</bold>) The relative magnitude of the place field change between home and away trials for neurons with significant remapping. For each cell (points), we subtracted the change expected from random splitting of the data from the observed difference between home and away trials and then divided the results with the expected difference with independent tuning curves. For most cells, the magnitude of the place field change is small. (<bold>e</bold>) The EV-index calculated separately in home and away trials for all recorded sessions. Although there is a trend indicating increased variability in away trials, the difference is small and is not consistent across the sessions. Error bars show SE across n=357-4761 theta cycle-pairs and across the n=8 sessions (rigth).</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-74058-fig6-figsupp2-v1.tif"/></fig></fig-group><p>We assessed excess variability in our synthetic dataset using either the sampling or the mean representational schemes, that is encoding either sampled trajectories or mean trajectories. Specifically, we decoded the population activity in three separate windows of the theta cycle (early, mid, and late) using a standard static Bayesian decoder and computed the difference between the decoded locations across subsequent theta cycles (cycle-to-cycle variability, <italic>CCV</italic>) and the difference between the decoded position and the true location of the animal (trajectory encoding error, <italic>TEE</italic>). As expected, both <italic>TEE</italic> and <italic>CCV</italic> increased from early to late theta phase both for mean (<xref ref-type="fig" rid="fig6">Figure 6b, c</xref>) and sampling codes (<xref ref-type="fig" rid="fig6">Figure 6d, e</xref>, Methods). Our analysis confirmed that it is the magnitude of the increase that is the most informative of the identity of the code: the increase of <italic>CCV</italic> is more intense within theta cycle than <italic>TEE</italic> in the case of sampling (<xref ref-type="fig" rid="fig6">Figure 6e</xref>) whereas the increase of the <italic>TEE</italic> is more intense during the theta cycle than that of <italic>CCV</italic> in the mean encoding scheme (<xref ref-type="fig" rid="fig6">Figure 6c</xref>, Methods). To evaluate this distinction in population responses, we quantified the difference between the rate of change of <italic>CCV</italic> and <italic>TEE</italic> using the <italic>excess variability index</italic> (EV-index). The EV-index was negative for mean (Methods, <xref ref-type="fig" rid="fig6">Figure 6f</xref>) and positive for sampling schemes (<xref ref-type="fig" rid="fig6">Figure 6g</xref>). To test the robustness of the EV-index against various factors influencing the cycle-to-cycle variability, we analyzed potential confounding factors. First, to compensate for the potentially large decoding errors during low spike count theta cycles, we calculated the EV-index both using all theta cycles (<xref ref-type="fig" rid="fig6s1">Figure 6—figure supplement 1e, f</xref>) or only theta cycles with high spike count (<xref ref-type="fig" rid="fig6">Figure 6f, g</xref>). Second, we varied randomly the speed and the length of the encoded trajectories (irregular vs. regular trajectories, <xref ref-type="fig" rid="fig6">Figure 6f</xref> inset, Methods). Third, we introduced a jitter to the boundaries of the theta cycles in order to model our uncertainty about cycle boundaries in experimental data (jitter 0–40ms, <xref ref-type="fig" rid="fig6">Figure 6g</xref> inset, Methods). We found that the EV-index was robust against these manipulations, reliably discriminating sampling-based codes from mean codes across a wide range of parameters. Thus, EV-index can distinguish sampling related excess variability from variability resulting from other sources.</p><p>We repeated the same analysis on the dataset recorded from rats exploring the 2D spatial arena. We calculated cycle-to-cycle variability and trajectory encoding error and found that typically both the error and the variability increased during theta (<xref ref-type="fig" rid="fig6">Figure 6h</xref>, inset). However, at early theta phase the distributions had high positive skewness due to a few outliers displaying extremely large errors typically at early theta phase (<xref ref-type="fig" rid="fig6">Figure 6h</xref>, arrows in the inset). The outliers could reflect an error in the identification of the start of the theta cycles, and the resulting erroneous assignment of spikes that encode a different trajectory caused increased error in the estimation of the starting position of the trajectory. To mitigate this effect, we calculated the EV-index using both the mean and the median across all theta cycles (<xref ref-type="fig" rid="fig6s1">Figure 6—figure supplement 1j, k</xref>) or including only high spike count cycles (<xref ref-type="fig" rid="fig6">Figure 6k, l</xref>). We found that the EV-index was consistently and significantly positive for all recording sessions. This analysis supports that the large cycle-to-cycle variability of the encoded trajectories during hippocampal theta sequences (<xref ref-type="bibr" rid="bib19">Gupta et al., 2012</xref>) is consistent with random sampling from the posterior distribution of possible trajectories in a dynamic generative model.</p><p>The consistently positive EV-index across all recording sessions signified that variance in the measured responses was higher at the end of theta cycle than what would be expected from a scheme not encoding uncertainty. In fact, the magnitude of the EV-index was substantially larger when evaluated on real data than in any of our synthetic datasets, including datasets where additional structured variability was introduced through randomly changing the speed or the length of the encoded trajectories (irregular trajectories, <xref ref-type="fig" rid="fig6">Figure 6g</xref>) or through additional randomness in the cycle boundaries (jitter in <xref ref-type="fig" rid="fig6">Figure 6g</xref> cf., <xref ref-type="fig" rid="fig6">Figure 6k</xref>). A potential source for higher excess variability could be task-dependent switching between multiple coexisting maps (<xref ref-type="bibr" rid="bib26">Kelemen and Fenton, 2010</xref>; <xref ref-type="bibr" rid="bib21">Jezek et al., 2011</xref>). However, we found that most neurons had identical spatial tuning in the two phases of the task (random foraging versus goal directed navigation; <xref ref-type="fig" rid="fig6s2">Figure 6—figure supplement 2a–c</xref>) and the remaining cells typically showed relatively minor change in their spatial activity across task phases (<xref ref-type="fig" rid="fig6s2">Figure 6—figure supplement 2</xref>; see also <xref ref-type="bibr" rid="bib43">Pfeiffer, 2022</xref>). Thus, multiple maps are not responsible for the large EV-index. Furthermore, we did not find consistent differences in the EV-index evaluated in the random foraging versus the goal directed search phase of the task (<xref ref-type="fig" rid="fig6s2">Figure 6—figure supplement 2</xref>), implying that specific goals during planning do not modulate the uncertainty of trajectories during theta sequences. Finally, large variability could be indicative of efficient sampling algorithms where correlations between subsequent samples are actively suppressed (<xref ref-type="bibr" rid="bib30">MacKay, 2003</xref>; <xref ref-type="bibr" rid="bib25">Kay et al., 2020</xref>; <xref ref-type="bibr" rid="bib11">Echeveste et al., 2020</xref>). In the final section, we tested this possibility using real and simulated data.</p></sec><sec id="s2-6"><title>Signature of efficient sampling: generative cycling</title><p>The efficiency of a sampling process can be characterized by the number of samples required to cover the target probability distribution. The efficiency can be increased when subsequent samples are generated from distant parts of the distribution making the samples anti-correlated. To test the hypothesis that the magnitude of the EV-index may be indicative of the magnitude of correlation between the samples, we first generated five datasets with varying the degree of correlation between the endpoint of trajectories sampled in subsequent theta cycles (<xref ref-type="fig" rid="fig7">Figure 7a</xref>; Methods) and calculated the EV-index for all these datasets. We found that the EV-index varied consistently with the sign and the magnitude of the correlation between the sampled trajectories: The EV-index was negative when positive correlations between the subsequent trajectories reduced the cycle-to-cycle variability (<xref ref-type="fig" rid="fig7">Figure 7b</xref>). In this case, persistent sampling biases could not be distinguished from erroneous inference (<xref ref-type="bibr" rid="bib1">Beck et al., 2012</xref>) and sampling became very similar to mean scheme. Conversely, the EV-index was positive for independent or anti-correlated samples with a substantial increase in the magnitude of the EV-index for strongly anti-correlated samples (<xref ref-type="fig" rid="fig7">Figure 7b</xref>). Thus, the large EV-index observed in the data is consistent with an efficient sampling algorithm that preferentially collects diverging trajectories in subsequent theta cycles.</p><fig-group><fig id="fig7" position="float"><label>Figure 7.</label><caption><title>Signature of efficient sampling: generative cycling.</title><p>(<bold>a</bold>) Examples of sampled trajectories with positive (left) and negative (right) correlation between the direction of subsequent trajectory endpoints (squares) relative to the current position (circles). (<bold>b</bold>) EV-index calculated with different amount of correlation between the subsequent trajectories. Error bars show SE across n=17989 theta cycle-pairs. (<bold>c</bold>) Schematic showing the measurement of the cycling length <inline-formula><mml:math id="inf56"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mrow><mml:mrow><mml:mo>$</mml:mo></mml:mrow><mml:mstyle displaystyle="false" scriptlevel="0"><mml:mi>ℓ</mml:mi><mml:mrow><mml:mo>$</mml:mo></mml:mrow></mml:mstyle></mml:mrow></mml:mrow></mml:mstyle></mml:math></inline-formula>. Top: theta oscillation. Middle: relative direction (L: left; R: right) of the sampled trajectories in each cycle. Bottom: cycling length (<inline-formula><mml:math id="inf57"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mrow><mml:mrow><mml:mo>$</mml:mo></mml:mrow><mml:mstyle displaystyle="false" scriptlevel="0"><mml:mi>ℓ</mml:mi><mml:mrow><mml:mo>$</mml:mo></mml:mrow></mml:mstyle></mml:mrow></mml:mrow></mml:mstyle></mml:math></inline-formula>) defined as the number of cycles with consistent alternation between left and right samples. (<bold>d</bold>) Histograms of the cycling length (<inline-formula><mml:math id="inf58"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mrow><mml:mrow><mml:mo>$</mml:mo></mml:mrow><mml:mstyle displaystyle="false" scriptlevel="0"><mml:mi>ℓ</mml:mi><mml:mrow><mml:mo>$</mml:mo></mml:mrow></mml:mstyle></mml:mrow></mml:mrow></mml:mstyle></mml:math></inline-formula>, see panel c) on simulated data (colors) with strong positive correlations (left), no correlations (middle) or with strong negative correlations (right). Gray shows the distribution after randomly shuffling the data across theta cycles, red shows the theoretical distribution assuming iid directions. Insets show the same distribution using logarithmic y-axes. (<bold>e</bold>) Schematic illustrating how difference between the true position (blue triangle) and the estimated position (brown arrowhead) can induce apparent correlations between alternating trajectories. Brown arrow represents the animal’s own position and motion direction estimate with the green circle illustrating its uncertainty. Green and blue lines depict two hypothetical trajectories alternating around the animal’s own position estimate (brown) but falling to the same side of its measured trajectory (black). (<bold>f</bold>) Cycling index (<inline-formula><mml:math id="inf59"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>N</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mi>ℓ</mml:mi></mml:mrow><mml:mo>≥</mml:mo><mml:mn>4</mml:mn><mml:mo stretchy="false">)</mml:mo><mml:mrow><mml:mo>/</mml:mo></mml:mrow><mml:mi>N</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mn>1</mml:mn><mml:mo>&lt;</mml:mo><mml:mrow><mml:mi>ℓ</mml:mi></mml:mrow><mml:mo>&lt;</mml:mo><mml:mn>3</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mstyle></mml:math></inline-formula>) in simulated data with different amount of correlation between the subsequent trajectories (colors) versus shuffled data (gray, 10,000 permutations). (<bold>g</bold>) Histograms of the cycling length (<inline-formula><mml:math id="inf60"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mrow><mml:mrow><mml:mo>$</mml:mo></mml:mrow><mml:mstyle displaystyle="false" scriptlevel="0"><mml:mi>ℓ</mml:mi><mml:mrow><mml:mo>$</mml:mo></mml:mrow></mml:mstyle></mml:mrow></mml:mrow></mml:mstyle></mml:math></inline-formula>) in an example session (green, R1D2) versus shuffle control (gray) and the theoretical distribution assuming iid directions (red). Inset shows the same histogram on a logarithmic scale. (<bold>h</bold>) Cycling index for the dataset shown in g (pink symbol) versus shuffled data (gray, 10000 permutations). (<bold>i</bold>) z-scored cycling index for all experimental sessions (colors) versus shuffle control (gray).</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-74058-fig7-v1.tif"/></fig><fig id="fig7s1" position="float" specific-use="child-fig"><label>Figure 7—figure supplement 1.</label><caption><title>Cycling index is unbiased when the encoded position is compared to the internally estimated rather than the true position.</title><p>Similar to <xref ref-type="fig" rid="fig7">Figure 7d and f</xref>, using the simulated animal’s internal position and motion direction estimate to calculate the relative direction of the encoded trajectory endpoints in each theta cycle. Note, that this information is not available for experimental data. (<bold>a</bold>) Histograms of the cycling length (<inline-formula><mml:math id="inf61"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>ℓ</mml:mi></mml:mrow></mml:mstyle></mml:math></inline-formula>, see <xref ref-type="fig" rid="fig7">Figure 7c</xref>) on simulated data (colors) with strong positive correlations (left), no correlations (middle) or with strong negative correlations (right). Gray shows the distribution after randomly shuffling the data across theta cycles, red shows the theoretical distribution assuming iid directions. Note, that repeats (<inline-formula><mml:math id="inf62"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>ℓ</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:mstyle></mml:math></inline-formula>) are overrepresented only when subsequent trajectories show positive correlations. Insets show the same histogram using a logarithmic y-axis. (<bold>b</bold>) Cycling index (<inline-formula><mml:math id="inf63"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>N</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>ℓ</mml:mi><mml:mo>≥</mml:mo><mml:mn>4</mml:mn><mml:mo stretchy="false">)</mml:mo><mml:mrow><mml:mo>/</mml:mo></mml:mrow><mml:mi>N</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mn>1</mml:mn><mml:mo>&lt;</mml:mo><mml:mi>ℓ</mml:mi><mml:mo>≤</mml:mo><mml:mn>3</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mstyle></mml:math></inline-formula>) in simulated data with different amount of correlation between the subsequent trajectories (colors) versus shuffled data (gray, 10,000 permutations). The measure is unbiased in this case, as only the independent case is consistent with the shuffling distribution. (<bold>c</bold>) Examples of motion trajectories of rat 1 day 2 with the position of the animal (empty circles) and the corresponding position decoded from late theta phase (filled circles) in subsequent theta cycles. The end of the motion trajectory is indicated with the circle filled in gray. Theta cycles are colored by the orientation (left or right) of the decoded position wrt. the motion direction of the animal.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-74058-fig7-figsupp1-v1.tif"/></fig><fig id="fig7s2" position="float" specific-use="child-fig"><label>Figure 7—figure supplement 2.</label><caption><title>Model-free replication of the main findings of the paper.</title><p>(<bold>a</bold>) Ten segments of the recorded motion trajectory of a real animal (black, target) and examples of potential motion trajectories with initial motion direction and velocity matching those of the target motion trajectory (gray). Each gray line is a short segment of real motion trajectory of the animal rotated and translated to match the target segment. The bouquet of the trajectories was used to emulate the subjective uncertainty of the animal. Note that model-free trajectories start from the present whereas model-based trajectories in <xref ref-type="fig" rid="fig3s1">Figure 3—figure supplement 1c-d</xref> and <xref ref-type="fig" rid="fig3">Figure 3a–c</xref> start from the past. (<bold>b</bold>) Decoding error from early, mid and late phase spikes (highest 5% spike count cycles) as a function of the time shift of the simulated animal’s position in the mean, product, DDC and sampling schemes (c.f. <xref ref-type="fig" rid="fig3">Figure 3f</xref>). (<bold>c</bold>) Decoding spread (top), decoding forward bias (middle) and firing rate (bottom) as a function of theta phase for the four different encoding models. All models show correlation between forward bias and decoding spread but only the product model predicts a strong negative correlation between the forward bias and the firing rate (c.f. <xref ref-type="fig" rid="fig3">Figure 3h</xref> and <xref ref-type="fig" rid="fig4">Figure 4c</xref>). (<bold>d</bold>) Cumulative distribution function (CDF, accross theta cycles) of the decoded SD from spikes at different theta phases for the mean (left), DDC (middle) and sampling schemes (right) in the model-free simulated dataset (c.f. <xref ref-type="fig" rid="fig5">Figure 5b</xref>). (<bold>e</bold>) Mean and SE (across n=39295, all theta cycles) of decoded SD as a function of theta phase for the different schemes in the model-free simulated dataset. Only the DDC code predicts a slight, but significant increase in the decoded SD at late theta phases (c.f. <xref ref-type="fig" rid="fig5">Figure 5c</xref>). (<bold>f</bold>) Mean CCV and TEE calculated from early, mid and late phase spikes in the mean scheme using the mean scheme (left; c.f. <xref ref-type="fig" rid="fig6">Figure 6c</xref>) and the sampling scheme (right; c.f. <xref ref-type="fig" rid="fig6">Figure 6e</xref>). (<bold>g</bold>) The EV-index for the mean and sampling schemes with simulating regular model-free theta-trajectories (c.f. <xref ref-type="fig" rid="fig6">Figure 6f–g</xref>). Error bars show SE across n=39294 theta cycle-pairs.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-74058-fig7-figsupp2-v1.tif"/></fig></fig-group><p>To more directly test the hypothesis that subsequently encoded trajectories are anti-correlated, we explored if future portions of decoded trajectories tend to visit distinct parts of the environments. If sampling is optimized to produce anti-correlated samples then future portions of trajectories are expected to alternate around the real trajectories more intensely than positively correlated trajectories. To formulate this, we calculated the duration of the consistent cycling periods (cycling length, <inline-formula><mml:math id="inf64"><mml:mi mathvariant="normal">ℓ</mml:mi></mml:math></inline-formula>, <xref ref-type="fig" rid="fig7">Figure 7c</xref>; <xref ref-type="bibr" rid="bib25">Kay et al., 2020</xref>). In our synthetic dataset, we found that ch:cyclingthe cycling length took the value one more frequently than in the shuffle control, indicating the absence of alternation even when the samples were strongly anti-correlated (<xref ref-type="fig" rid="fig7">Figure 7d</xref>). We identified that the source of this bias is the difference between the observed true position of the animal, and the animal’s subjective location estimate (<xref ref-type="fig" rid="fig7">Figure 7e</xref>). Specifically, even when the sampled trajectories alternate around the estimated position, the alternating trajectories often fell into the same side of the real trajectory of the animal if the true and the estimated position do not coincide (<xref ref-type="fig" rid="fig7">Figure 7e</xref>). Indeed, the bias was be eliminated when we calculated the alternation ot the encoded trajectories with respect to the animal’s internal location estimate (<xref ref-type="fig" rid="fig7s1">Figure 7—figure supplement 1</xref>). Note that this bias is not present in simpler, 1-dimensional environments when the position of the animal is constrained to a linear corridor (<xref ref-type="bibr" rid="bib25">Kay et al., 2020</xref>). To compensate for this bias, we introduced the cycling index, that ignores the repeats (<inline-formula><mml:math id="inf65"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>ℓ</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:mstyle></mml:math></inline-formula>) and measures the prevalence of long (<inline-formula><mml:math id="inf66"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>ℓ</mml:mi><mml:mo>≥</mml:mo><mml:mn>4</mml:mn></mml:mrow></mml:mstyle></mml:math></inline-formula>) cycling periods relative to the short alternations (<inline-formula><mml:math id="inf67"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mn>1</mml:mn><mml:mo>&lt;</mml:mo><mml:mi>ℓ</mml:mi><mml:mo>≤</mml:mo><mml:mn>3</mml:mn></mml:mrow></mml:mstyle></mml:math></inline-formula>; <xref ref-type="fig" rid="fig7">Figure 7f</xref>). We validated the cycling index on synthetic data by showing that it correctly distinguishes strongly correlated and anti-correlated settings.</p><p>Finally, we analysed the cycling behavior in the experimental data. We found that, similar to our synthetic datasets, repeats (<inline-formula><mml:math id="inf68"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>ℓ</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:mstyle></mml:math></inline-formula>) were relatively overrepresented in the data compared to short alternations (<inline-formula><mml:math id="inf69"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>ℓ</mml:mi><mml:mo>=</mml:mo><mml:mn>2</mml:mn></mml:mrow></mml:mstyle></mml:math></inline-formula>, <xref ref-type="fig" rid="fig7">Figure 7g</xref>). However, the distribution of cycling length had a long tail and long periods of alternations (<inline-formula><mml:math id="inf70"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>ℓ</mml:mi><mml:mo>&gt;=</mml:mo><mml:mn>4</mml:mn></mml:mrow></mml:mstyle></mml:math></inline-formula>) were frequent (<xref ref-type="fig" rid="fig7">Figure 7g</xref>, see also <xref ref-type="fig" rid="fig7s1">Figure 7—figure supplement 1c</xref>) resulting in a cycling index significantly larger than in shuffle control (<xref ref-type="fig" rid="fig7">Figure 7h</xref>). To standardize the cycling index for all sessions, we z-scored it using the corresponding shuffle distribution and found that the normalized cycling index was significantly positive for 7 of the 8 recording sessions (<xref ref-type="fig" rid="fig7">Figure 7i</xref>) and not different from random in the remaining session. This finding indicates that hypothetical trajectories encoded in subsequent theta cycles tend to alternate between different directions relative to the animal’s true motion trajectory, which is a signature of efficient sampling from the underlying probability distribution.</p></sec><sec id="s2-7"><title>Analysis of signatures using model-free trajectories</title><p>The core of our analysis was a generative model that we used to obtain distributions of potential trajectories in order to identify signatures of alternative coding schemes. To test if specific properties of the generative model affect these signatures, we designed an analysis in which the same signatures could be tested in a model-free manner. The original generative model directly provided a way to assess the distributions of past, current, and future potential positions using probabilistic inference in the model. In the model-free version, we used only the recorded motion trajectories to construct an empirical distribution of hypothetical trajectories at each point in the motion trajectory of the animal. Specifically, for a particular target point on a recorded motion trajectory, we sampled multiple real trajectory segments with similar starting speed and aligned the start of these trajectories with the start of the target trajectory by shifting and rotating the sampled segments (<xref ref-type="fig" rid="fig7s2">Figure 7—figure supplement 2a</xref>). This alignment resulted in a bouquet of trajectories for each actual point along the motion trajectory that outlined an empirical distribution of hypothetical future positions and speeds (<xref ref-type="fig" rid="fig7s2">Figure 7—figure supplement 2a</xref>).</p><p>We used the empirical, model-free distributions of motion trajectories to synthesize spiking data using the four different coding schemes. We then showed that the forward bias and the spread of the decoded locations changed systematically within the theta cycle (<xref ref-type="fig" rid="fig7s2">Figure 7—figure supplement 2b, c</xref>) indicating that theta sequences are similar in this model-free dataset to real data (<xref ref-type="fig" rid="fig1">Figure 1d, f and g</xref>). Next, we repeated identical analyses that were performed with the original, model-based synthetic trajectories. Our analyses demonstrated that the signatures we introduced to test alternative coding schemes are robust against changes in the way distributions of planned trajectories are constructed (<xref ref-type="fig" rid="fig7s2">Figure 7—figure supplement 2c–g</xref>).</p></sec></sec><sec id="s3" sec-type="discussion"><title>Discussion</title><p>In this paper, we demonstrated that the statistical structure of the sequential neural activity during theta oscillation in the hippocampus is consistent with repeatedly performing inference and predictions in a dynamical generative model. Further, we have established a framework to directly contrast competing hypotheses about the way probability distributions can be represented in neural populations. Importantly, new measures were developed to dissociate alternative coding schemes and to identify their hallmarks in the population activity. Reliability and robustness of these measures was validated on multiple synthetic data sets that were designed to match the statistics of neuronal and behavioral activity of recorded animals. Our analysis demonstrated that the neural code in the hippocampus shows hallmarks of probabilistic planning by representing information about uncertainty associated with the encoded positions. Specifically, our analysis has shown that the hippocampal population code displays the signature of efficient sampling of possible motion trajectories but could not identify the hallmarks of alternative proposed schemes for coding uncertainty.</p><sec id="s3-1"><title>Planning and dynamical models</title><p>Hippocampal activity sequences both during theta oscillation and sharp waves have been implicated in planning. During sharp waves, sequential activation of place cells can outline extended trajectories up to 10 m long (<xref ref-type="bibr" rid="bib8">Davidson et al., 2009</xref>), providing a mechanism suitable for selecting the correct path leading to goal locations (<xref ref-type="bibr" rid="bib42">Pfeiffer and Foster, 2013</xref>; <xref ref-type="bibr" rid="bib33">Mattar and Daw, 2018</xref>; <xref ref-type="bibr" rid="bib62">Widloski and Foster, 2022</xref>). During theta oscillation, sequences typically cover a few tens of centimeters (<xref ref-type="fig" rid="fig2">Figure 2</xref>; <xref ref-type="bibr" rid="bib63">Wikenheiser and Redish, 2015</xref>) and are thus more suitable for surveilling the immediate consequences of the imminent actions. Monitoring future consequences of actions at multiple time scales is a general strategy for animals, humans and autonomous artificial agents alike (<xref ref-type="bibr" rid="bib39">Neftci and Averbeck, 2019</xref>).</p><p>In our model, the dominant source of uncertainty represented by the hippocampal population activity was the stochasticity of the animal’s forthcoming choices. Indeed, it has been observed that before the decision point in a W-maze the hippocampus also represents hypothetical trajectories not actually taken by the animal (<xref ref-type="bibr" rid="bib45">Redish, 2016</xref>; <xref ref-type="bibr" rid="bib25">Kay et al., 2020</xref>; <xref ref-type="bibr" rid="bib54">Tang et al., 2021</xref>). Here, we generalized this observation to an open-field task and found that monitoring alternative paths is not restricted to decision points but the hippocampus constantly monitors consequences of alternative choices. Disentangling the potential contribution of other sources of uncertainty, including ambiguous sensory inputs (<xref ref-type="bibr" rid="bib21">Jezek et al., 2011</xref>) or unpredictable environments to hippocampal representations requires analysing population activity during more structured experimental paradigms (<xref ref-type="bibr" rid="bib26">Kelemen and Fenton, 2010</xref>; <xref ref-type="bibr" rid="bib36">Miller et al., 2017</xref>).</p><p>Although representation of alternative choices in theta sequences is well supported by data, it is not clear how much the encoded trajectories are influenced by the current policy of the animal. On one hand, prospective coding, reversed sequences during backward travel or the modulation of the sequences by goal location indicates that current context influences the content and dynamics of the sequences (<xref ref-type="bibr" rid="bib16">Frank et al., 2000</xref>; <xref ref-type="bibr" rid="bib23">Johnson and Redish, 2007</xref>; <xref ref-type="bibr" rid="bib4">Cei et al., 2014</xref>; <xref ref-type="bibr" rid="bib63">Wikenheiser and Redish, 2015</xref>). On the other hand, theta sequences represent alternatives with equal probability in binary decision tasks and the content of the sequences is not predictive about the future choice of the animal (<xref ref-type="bibr" rid="bib25">Kay et al., 2020</xref>; <xref ref-type="bibr" rid="bib54">Tang et al., 2021</xref>). Our finding that there is no consistent difference between the EVindex in home versus away trials (<xref ref-type="fig" rid="fig6s2">Figure 6—figure supplement 2</xref>) is also consistent with the idea that trajectories are sampled from a wide distribution not influenced strongly by the current goal or policy of the animal. Sampling from a relatively wide proposal distribution is a general motif utilized by several sampling algorithms (<xref ref-type="bibr" rid="bib30">MacKay, 2003</xref>). Brain areas beyond the hippocampus, such as the prefrontal cortex, might perform additional computations on the array of trajectories sampled during theta oscillations, including rejection of the samples not consistent with the current policy (<xref ref-type="bibr" rid="bib54">Tang et al., 2021</xref>). The outcome of the sampling process can have profound effect on future behavior as selective abolishment of theta sequences by pharmacological manipulations impairs behavioral performance (<xref ref-type="bibr" rid="bib47">Robbe et al., 2006</xref>).</p><p>Compared to previous models simulating hippocampal place cell activity (<xref ref-type="bibr" rid="bib35">McClain et al., 2019</xref>; <xref ref-type="bibr" rid="bib5">Chadwick et al., 2015</xref>), a major novelty in our approach was that its spatial location was not assumed to be known by the animal. Instead, the animal had to estimate its own position and motion trajectory using a probabilistic generative model of the environment. Consequently, the neuronal activity in our simulations was driven by the estimated rather than the true positions. This probabilistic perspective allowed us to identify the sources of the variability of theta sequences, to define quantities (CCV, TEE and EV-index) that can discriminate between sampling and mean schemes and to recognise the origin of biases in generative cycling. Although the fine details of the model are not crucial for our results (<xref ref-type="fig" rid="fig7s2">Figure 7—figure supplement 2</xref>) and our specific parameter choices were motivated mainly to achieve a good match with the real motion and neural data (<xref ref-type="fig" rid="fig3s2">Figure 3—figure supplements 2</xref> and <xref ref-type="fig" rid="fig3s3">3</xref>), a probabilistic generative model was necessary for these insights and for the consistent implementation of the inference process. Alternative frameworks, such as the successor representations (<xref ref-type="bibr" rid="bib9">Dayan, 1993</xref>; <xref ref-type="bibr" rid="bib52">Stachenfeld et al., 2017</xref>) provide only aggregate predictions in the form of expected future state occupancy averaged across time and intermediate states instead of temporally and spatially detailed predictions on specific future states necessary for generating hypothetical trajectories (<xref ref-type="bibr" rid="bib22">Johnson and Redish, 2005</xref>; <xref ref-type="bibr" rid="bib25">Kay et al., 2020</xref>).</p><p>We found that excess variability in the experimental data was higher than that in the simulated data sampling independent trajectories in subsequent theta cycles. This high EV-index is consistent with preferentially selecting samples from the opposite lobes of the target distribution (<xref ref-type="bibr" rid="bib30">MacKay, 2003</xref>) via generative cycling (<xref ref-type="bibr" rid="bib25">Kay et al., 2020</xref>) leading to low autocorrelation of the samples. Recurrent neural networks can be trained to generate samples with rapidly decaying auto-correlation (<xref ref-type="bibr" rid="bib11">Echeveste et al., 2020</xref>). Interestingly, these networks were shown to display strong oscillatory activity in the gamma band (<xref ref-type="bibr" rid="bib11">Echeveste et al., 2020</xref>). Concurrent gamma and theta band activities are characteristics of hippocampus (<xref ref-type="bibr" rid="bib7">Colgin, 2016</xref>), which indicates that network mechanisms underlying efficient sampling might be exploited by the hippocampal circuitry. Efficient sampling of trajectories instead of static variables could necessitate multiple interacting oscillations where individual trajectories evolve during multiple gamma cycles and alternative trajectories are sampled in subsequent theta cycles.</p></sec><sec id="s3-2"><title>Circuit mechanisms</title><p>Recent theoretical studies established that recurrent neural networks can implement complex nonlinear dynamics (<xref ref-type="bibr" rid="bib32">Mastrogiuseppe and Ostojic, 2018</xref>; <xref ref-type="bibr" rid="bib58">Vyas et al., 2020</xref>) including sampling from the posterior distribution of a static generative model (<xref ref-type="bibr" rid="bib11">Echeveste et al., 2020</xref>). External inputs to the network can efficiently influence the trajectories emerging in the network either by changing the internal state and initiating a new sequence (<xref ref-type="bibr" rid="bib24">Kao et al., 2021</xref>) or by modulating the internal dynamics influencing the transition structure between the cell assemblies or the represented spatial locations (<xref ref-type="bibr" rid="bib31">Mante et al., 2013</xref>; <xref ref-type="bibr" rid="bib53">Stroud et al., 2018</xref>). We speculate that the recurrent network of the CA3 subfield could serve as a neural implementation of the dynamical generative model with inputs from the entorhinal cortex providing strong contextual signals selecting the right map and conveying landmark information necessary for periodic resets at the beginning of the theta cycles.</p><p>Although little is known about the role of entorhinal inputs to the CA3 subfield during theta sequences, inputs to the CA1 subfield show functional segregation consistent with this idea. Specifically, inputs to the CA1 network from the entorhinal cortex and from the CA3 region are activated dominantly at distinct phases of the theta cycle and are associated with different bands of gamma oscillations reflecting the engagement of different local micro-circuits (<xref ref-type="bibr" rid="bib6">Colgin et al., 2009</xref>; <xref ref-type="bibr" rid="bib49">Schomburg et al., 2014</xref>). The entorhinal inputs are most active at early theta phases when they elicit fast gamma oscillations (<xref ref-type="bibr" rid="bib49">Schomburg et al., 2014</xref>) and these inputs might contribute to the reset of the sequences (<xref ref-type="bibr" rid="bib13">Fernández-Ruiz et al., 2017</xref>). Initial part of the theta cycle showing transient backward sequences (<xref ref-type="bibr" rid="bib61">Wang et al., 2020</xref>) could reflect the effect of external inputs resetting the local network dynamics. Conversely, CA3 inputs to CA1 are coupled to local slow gamma rhythms preferentially occurring at later theta phases, associated with prospective coding and relatively long, temporally compressed paths (<xref ref-type="bibr" rid="bib49">Schomburg et al., 2014</xref>; <xref ref-type="bibr" rid="bib2">Bieri et al., 2014</xref>) potentially following the trajectory outlined by the CA3 place cells.</p></sec><sec id="s3-3"><title>Representations of uncertainty</title><p>Uncertainty representation implies that not only a best estimate of an inferred quantity is maintained in the population but properties of a full probability distribution can also be recovered from the activity. Machine learning provides two major classes of computational methods to represent probability distributions: 1, instantaneous representations which rely on a set of parameters to encode a probability distribution; or 2, sequential representations that collect samples from the distributions (<xref ref-type="bibr" rid="bib30">MacKay, 2003</xref>). Accordingly, theories of neural probabilistic computations fall into these categories: the product scheme and DDC instantaneously, while sampling sequentially represents uncertainty (<xref ref-type="bibr" rid="bib44">Pouget et al., 2013</xref>; <xref ref-type="bibr" rid="bib48">Savin and Deneve, 2014</xref>). Our analysis did not find evidence for representing a probability distributions instantaneously during hippocampal theta sequences. Instead, our data is consistent with representing a single location at any given time where uncertainty is encoded sequentially by the variability of the represented locations across time.</p><p>Importantly, it is not possible to accurately recover the represented position of the animal from the observed spikes in any of the coding schemes: one can only estimate it with a finite precision, summarized by a posterior distribution over the possible positions. Thus, decoding noisy neural activity naturally leads to a posterior distribution. However, this does not imply that it was actually a probability distribution encoded in the population activity (<xref ref-type="bibr" rid="bib65">Zemel et al., 1998</xref>; <xref ref-type="bibr" rid="bib28">Lange et al., 2020</xref>). Specifically, when a scalar variable <inline-formula><mml:math id="inf71"><mml:mi>x</mml:mi></mml:math></inline-formula> is encoded in the spiking activity <inline-formula><mml:math id="inf72"><mml:mrow><mml:mi>s</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>x</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> of neurons using an exponential family likelihood function, then the resulting code is a linear probabilistic population code (PPC; <xref ref-type="bibr" rid="bib29">Ma et al., 2006</xref>). In fact, we used an exponential family likelihood function (Poisson) in our mean and sampling scheme, so these schemes belong, by definition, to the PPC family. However, the PPC should not be confused with our product scheme where a target distribution is encoded in the noisy population activity instead of a single variable (<xref ref-type="bibr" rid="bib28">Lange et al., 2020</xref>).</p><p>To test the product scheme, we used the population gain as a hallmark. We found that the gain varied systematically, but the variance was not consistent with the basic statistical principle, that on average uncertainty accumulates when predicting future states. An alternative test would be to estimate both the encoding basis functions and the represented distributions as proposed by <xref ref-type="bibr" rid="bib29">Ma et al., 2006</xref> but this would require the precise estimation of stimulus dependent correlations among the neurons.</p><p>We also did not find evidence for representing distributions via the DDC scheme during theta sequences. However, the lack of evidence for instantaneous representation of probability distributions in the hippocampus does not rule out that these schemes might be effectively employed by other neuronal systems (<xref ref-type="bibr" rid="bib44">Pouget et al., 2013</xref>). In particular, on the behavioral time scale when averaging over many theta cycles, the sampling and DDC schemes become equivalent: when we calculate the average firing rate of a neuron that uses the sampling scheme across several theta cycles, it becomes the expectation of its associated encoding basis function under the represented distribution. This way, sampling alternative trajectories in each theta cycle can be interpreted as DDC on the behavioral time scale with all computational advantages of this coding scheme (<xref ref-type="bibr" rid="bib57">Vértes and Sahani, 2019</xref>). Similarly, sampling potential future trajectories at the theta time scale naturally explains the emergence of successor representations on the behavioral time scale (<xref ref-type="bibr" rid="bib52">Stachenfeld et al., 2017</xref>).</p><p>In standard sampling codes, individual neurons correspond to variables and their activity (membrane potential or firing rate) represent the value of the represented variable which is very efficient for sampling from complex, high dimensional distributions (<xref ref-type="bibr" rid="bib14">Fiser et al., 2010</xref>; <xref ref-type="bibr" rid="bib41">Orbán et al., 2016</xref>). Here, we take a population coding approach when individual neurons are associated with encoding basis functions and the population activity collectively encode the value of the variable (<xref ref-type="bibr" rid="bib65">Zemel et al., 1998</xref>; <xref ref-type="bibr" rid="bib48">Savin and Deneve, 2014</xref>). This scheme allows the hippocampal activity to efficiently encode the value of a low dimensional variable at high temporal precision.</p><p>Recurrent networks can implement parallel chains of sampling from the posterior distribution of static (<xref ref-type="bibr" rid="bib48">Savin and Deneve, 2014</xref>) or dynamic (<xref ref-type="bibr" rid="bib27">Kutschireiter et al., 2017</xref>) generative models. Similar to the DDC scheme, these implementations would also encode uncertainty by the increase of the diversity of the co-active neurons. Thus, our data indicates that the hippocampus avoids sampling multiple, parallel chains for representing uncertainty in dynamical models and rather multiplexes sampling in time by collecting several samples subsequently at an accelerated temporal scale.</p><p>Our analysis leveraged the systematic increase in the uncertainty of the predicted states with time in dynamical models. The advantage of this approach is that we could analyse 1000s of theta cycles, much more than the typical number of trials in behavioral experiments where uncertainty is varied by manipulating stimulus parameters (e.g. image contrast; <xref ref-type="bibr" rid="bib41">Orbán et al., 2016</xref>; <xref ref-type="bibr" rid="bib60">Walker et al., 2020</xref>). Uncertainty could also be manipulated during navigation by changing the amount of available sensory information (<xref ref-type="bibr" rid="bib67">Zhang et al., 2014</xref>), introducing ambiguity regarding the spatial context (<xref ref-type="bibr" rid="bib21">Jezek et al., 2011</xref>) or manipulating the volatility of the environment (<xref ref-type="bibr" rid="bib36">Miller et al., 2017</xref>). Our analysis predicts that the variability across theta cycles will increase systematically after all manipulations causing an increase in the uncertainty regardless of the nature of this manipulation or the shape of the environment. These experiments would also allow a more direct test of our theory by comparing changes in the neuronal activity with a behavioral readout of subjective uncertainty.</p></sec></sec><sec id="s4" sec-type="methods"><title>Methods</title><sec id="s4-1"><title>Theory</title><p>To study the neural signatures of the probabilistic coding schemes during hippocampal theta sequences, we developed a coherent theoretical framework which assumes that the hippocampus implements a dynamical generative model of the environment. The animal uses this model to estimate its current spatial location and predict possible consequences of its future actions. Since multiple possible positions are consistent with recent sensory inputs and multiple options are available to choose from, representing these alternative possibilities, and their respective probabilities, in the neuronal activity is beneficial for efficient computations. Within this framework, we interpreted trajectories represented by the sequential population activity during theta oscillation as inferences and predictions in the dynamical generative model.</p><p>We define three hierarchical levels for this generative process (<xref ref-type="fig" rid="fig3s1">Figure 3—figure supplement 1a</xref>). (1) We modeled the generation of <italic>smooth planned trajectories</italic> in the two-dimensional box, similar to the experimental setup, with a stochastic process. These trajectories represented the intended locations for the animal at discrete time steps. (2) We formulated the generation of <italic>motion trajectories</italic> via motor commands that are calculated as the difference between the planned trajectory and the position estimated from the sensory inputs. Again, this component was assumed to be stochastic due to noisy observations and motor commands. Calculating the correct motor command required the animal to update its position estimate at each time step and we assumed that the animal also maintained a representation of its inferred past and predicted future trajectory. (3) We modeled the generative process which <italic>encodes the represented trajectories by neural activity</italic>. Activity of a population of hippocampal neurons was assumed to be generated by either of the four different encoding schemes as described below.</p><p>We implemented this generative model to synthesize both locomotion and neural data and used it to test contrasting predictions of different encoding schemes. Importantly, the specific algorithm we used to synthesize motion trajectories and perform inference is not assumed to underlie the algorithmic steps implemented in the hippocampal network, it only provides sample trajectories from the distribution with the right summary statistics. The flexibility of this hierarchical framework enabled us to match qualitatively the experimental data both at the behavioral (<xref ref-type="fig" rid="fig3s2">Figure 3—figure supplement 2</xref>) and the neural (<xref ref-type="fig" rid="fig3s3">Figure 3—figure supplement 3</xref>) level. In the following paragraphs we will describe these levels in detail.</p><sec id="s4-1-1"><title>Generation of smooth planned trajectory</title><p>The planned trajectory was established at a temporal resolution corresponding to the length of a theta cycle, <inline-formula><mml:math id="inf73"><mml:mrow><mml:mrow><mml:mi mathvariant="normal">Δ</mml:mi><mml:mo>⁢</mml:mo><mml:mi>t</mml:mi></mml:mrow><mml:mo>=</mml:mo><mml:mn>0.1</mml:mn></mml:mrow></mml:math></inline-formula> s, and spanned a length <inline-formula><mml:math id="inf74"><mml:mrow><mml:mi>T</mml:mi><mml:mo>≈</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:math></inline-formula> s providing a set of planned positions, <inline-formula><mml:math id="inf75"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mrow><mml:mover><mml:mrow><mml:mi mathvariant="bold">x</mml:mi></mml:mrow><mml:mo stretchy="false">¯</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>n</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula> for any given theta cycle <inline-formula><mml:math id="inf76"><mml:mi>n</mml:mi></mml:math></inline-formula> (see <xref ref-type="table" rid="table1">Table 1</xref> for a list of frequently used symbols). The planned trajectories were initialized from the center of a hypothetical 2 m×2 m box with a random initial velocity. Magnitude and direction of the velocity in subsequent steps were jointly sampled from their respective probability distributions. Specifically, at time step <inline-formula><mml:math id="inf77"><mml:mi>n</mml:mi></mml:math></inline-formula> we first updated the direction of motion by adding a random two-dimensional vector of length <inline-formula><mml:math id="inf78"><mml:mrow><mml:msub><mml:mi>μ</mml:mi><mml:mrow><mml:mi mathvariant="normal">Δ</mml:mi><mml:mo>⁢</mml:mo><mml:mi>v</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mn>3.5</mml:mn></mml:mrow></mml:math></inline-formula> cm/s to the velocity <inline-formula><mml:math id="inf79"><mml:msub><mml:mover accent="true"><mml:mi>v</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover><mml:mi>n</mml:mi></mml:msub></mml:math></inline-formula>. Next, we changed the speed, the magnitude of <inline-formula><mml:math id="inf80"><mml:msub><mml:mover accent="true"><mml:mi>v</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover><mml:mi>n</mml:mi></mml:msub></mml:math></inline-formula>, according to an Ornstein-Uhlenbeck process:<disp-formula id="equ1"><label>(1)</label><mml:math id="m1"><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi>ν</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover><mml:mi>n</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi>ν</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover><mml:mrow><mml:mi>n</mml:mi><mml:mo>-</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:msub><mml:mi>μ</mml:mi><mml:mi>ν</mml:mi></mml:msub><mml:mo>-</mml:mo><mml:msub><mml:mover accent="true"><mml:mi>ν</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover><mml:mrow><mml:mi>n</mml:mi><mml:mo>-</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>⁢</mml:mo><mml:mfrac><mml:mrow><mml:mi mathvariant="normal">Δ</mml:mi><mml:mo>⁢</mml:mo><mml:mi>t</mml:mi></mml:mrow><mml:msub><mml:mi>τ</mml:mi><mml:mi>ν</mml:mi></mml:msub></mml:mfrac></mml:mrow><mml:mo>+</mml:mo><mml:mrow><mml:msub><mml:mi>Q</mml:mi><mml:mi>ν</mml:mi></mml:msub><mml:mo>⁢</mml:mo><mml:mi>ϵ</mml:mi><mml:mo>⁢</mml:mo><mml:msqrt><mml:mrow><mml:mi mathvariant="normal">Δ</mml:mi><mml:mo>⁢</mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:msqrt></mml:mrow></mml:mrow></mml:mrow></mml:math></disp-formula></p><table-wrap id="table1" position="float"><label>Table 1.</label><caption><title>Summary of the symbols used in the model.</title></caption><table frame="hsides" rules="groups"><thead><tr><th align="left" valign="bottom">Symbol</th><th align="left" valign="bottom">Meaning</th></tr></thead><tbody><tr><td align="left" valign="bottom"><inline-formula><mml:math id="inf81"><mml:mi>n</mml:mi></mml:math></inline-formula></td><td align="left" valign="bottom">index of time step in the generative model measured as the number of theta cycles</td></tr><tr><td align="left" valign="bottom"><inline-formula><mml:math id="inf82"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>x</mml:mi><mml:mi>n</mml:mi></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula></td><td align="left" valign="bottom">position at theta cycle <italic>n</italic> (two-dimensional)</td></tr><tr><td align="left" valign="bottom"><inline-formula><mml:math id="inf83"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>y</mml:mi><mml:mi>n</mml:mi></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula></td><td align="left" valign="bottom">sensory input (two-dimensional)</td></tr><tr><td align="left" valign="bottom"><inline-formula><mml:math id="inf84"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>u</mml:mi><mml:mi>n</mml:mi></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula></td><td align="left" valign="bottom">motor command (two-dimensional)</td></tr><tr><td align="left" valign="bottom"><inline-formula><mml:math id="inf85"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mover><mml:mrow><mml:mi mathvariant="bold">x</mml:mi></mml:mrow><mml:mo stretchy="false">¯</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>n</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mrow></mml:mstyle></mml:math></inline-formula></td><td align="left" valign="bottom">planned position (<inline-formula><mml:math id="inf86"><mml:mrow><mml:mn>2</mml:mn><mml:mo>×</mml:mo><mml:mi>T</mml:mi></mml:mrow></mml:math></inline-formula>-dimensional)</td></tr><tr><td align="left" valign="bottom"><inline-formula><mml:math id="inf87"><mml:msub><mml:mover accent="true"><mml:mi>x</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover><mml:mi>n</mml:mi></mml:msub></mml:math></inline-formula></td><td align="left" valign="bottom">planned position (two-dimensional)</td></tr><tr><td align="left" valign="bottom"><inline-formula><mml:math id="inf88"><mml:msub><mml:mi>y</mml:mi><mml:mrow><mml:mn>1</mml:mn><mml:mo>:</mml:mo><mml:mi>n</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula></td><td align="left" valign="bottom">past sensory input until theta cycle <italic>n</italic></td></tr><tr><td align="left" valign="bottom"><inline-formula><mml:math id="inf89"><mml:msub><mml:mi>μ</mml:mi><mml:mi>n</mml:mi></mml:msub></mml:math></inline-formula></td><td align="left" valign="bottom">mean of the filtering posterior</td></tr><tr><td align="left" valign="bottom"><inline-formula><mml:math id="inf90"><mml:msub><mml:mi mathvariant="normal">Σ</mml:mi><mml:mi>n</mml:mi></mml:msub></mml:math></inline-formula></td><td align="left" valign="bottom">covariance of the filtering posterior</td></tr><tr><td align="left" valign="bottom"><inline-formula><mml:math id="inf91"><mml:mi>φ</mml:mi></mml:math></inline-formula></td><td align="left" valign="bottom">theta phase</td></tr><tr><td align="left" valign="bottom"><inline-formula><mml:math id="inf92"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="bold">x</mml:mi></mml:mrow><mml:mrow><mml:mi>n</mml:mi></mml:mrow></mml:msub><mml:mo>≡</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>n</mml:mi><mml:mo>−</mml:mo><mml:msub><mml:mi>n</mml:mi><mml:mrow><mml:mi>p</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:mo>:</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mi>n</mml:mi><mml:mo>+</mml:mo><mml:msub><mml:mi>n</mml:mi><mml:mrow><mml:mi>f</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula></td><td align="left" valign="bottom">trajectory of the animal around theta cycle <italic>n</italic></td></tr><tr><td align="left" valign="bottom"><inline-formula><mml:math id="inf93"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi mathvariant="bold-italic">μ</mml:mi><mml:mrow><mml:mi>n</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>φ</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mstyle></mml:math></inline-formula></td><td align="left" valign="bottom">posterior mean trajectory at theta cycle <italic>n</italic><break/></td></tr><tr><td align="left" valign="bottom"><inline-formula><mml:math id="inf94"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi mathvariant="bold">Σ</mml:mi><mml:mrow><mml:mi>n</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>φ</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mstyle></mml:math></inline-formula></td><td align="left" valign="bottom">posterior variance of trajectory at theta cycle <italic>n</italic></td></tr><tr><td align="left" valign="bottom"><inline-formula><mml:math id="inf95"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mrow><mml:mover><mml:mrow><mml:mi mathvariant="bold">x</mml:mi></mml:mrow><mml:mo stretchy="false">~</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>n</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula></td><td align="left" valign="bottom">trajectory sampled from <inline-formula><mml:math id="inf96"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>P</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mrow><mml:mi mathvariant="bold">x</mml:mi></mml:mrow><mml:mrow><mml:mi>n</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:msub><mml:mi>y</mml:mi><mml:mrow><mml:mn>1</mml:mn><mml:mo>:</mml:mo><mml:mi>n</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>u</mml:mi><mml:mrow><mml:mn>1</mml:mn><mml:mo>:</mml:mo><mml:mi>n</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mstyle></mml:math></inline-formula></td></tr><tr><td align="left" valign="bottom"><inline-formula><mml:math id="inf97"><mml:mrow><mml:msub><mml:mi>ϕ</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>x</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula></td><td align="left" valign="bottom">encoding basis function of cell <italic>i</italic> - firing rate as a function of the <italic>encoded</italic> position</td></tr><tr><td align="left" valign="bottom"><inline-formula><mml:math id="inf98"><mml:mrow><mml:msub><mml:mi>ψ</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>x</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula></td><td align="left" valign="bottom">empirical tuning curve of cell <italic>i</italic> - firing rate as a function of the <italic>real</italic> position</td></tr><tr><td align="left" valign="bottom"><inline-formula><mml:math id="inf99"><mml:msub><mml:mi>λ</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:math></inline-formula></td><td align="left" valign="bottom">firing rate of cell i</td></tr><tr><td align="left" valign="bottom"><inline-formula><mml:math id="inf100"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="bold">s</mml:mi></mml:mrow><mml:mrow><mml:mi>n</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>φ</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mstyle></mml:math></inline-formula></td><td align="left" valign="bottom">spikes recorded in theta cycle <italic>n</italic> encoding trajectory <italic><bold>x</bold></italic><sub><italic>n</italic></sub></td></tr><tr><td align="left" valign="bottom"><inline-formula><mml:math id="inf101"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mrow><mml:mover><mml:mrow><mml:mi mathvariant="bold">x</mml:mi></mml:mrow><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>n</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>φ</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mstyle></mml:math></inline-formula></td><td align="left" valign="bottom">trajectory decoded from the observed spikes assuming direct encoding (<xref ref-type="disp-formula" rid="equ19">Equation 18</xref>)</td></tr><tr><td align="left" valign="bottom"><inline-formula><mml:math id="inf102"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mrow><mml:mover><mml:mi mathvariant="bold-italic">μ</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>n</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>φ</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mstyle></mml:math></inline-formula></td><td align="left" valign="bottom">estimated trajectory mean assuming DDC encoding (<xref ref-type="disp-formula" rid="equ20">Equation 19</xref>)</td></tr><tr><td align="left" valign="bottom"><inline-formula><mml:math id="inf103"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mrow><mml:mover><mml:mi mathvariant="bold">Σ</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>n</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>φ</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mstyle></mml:math></inline-formula></td><td align="left" valign="bottom">estimated trajectory variance assuming DDC encoding (<xref ref-type="disp-formula" rid="equ20">Equation 19</xref>)</td></tr></tbody></table></table-wrap><p>where <inline-formula><mml:math id="inf104"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mrow><mml:mover><mml:mi>ν</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>n</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula> denotes the speed in theta cycle <inline-formula><mml:math id="inf105"><mml:mi>n</mml:mi></mml:math></inline-formula>. We used the parameters <inline-formula><mml:math id="inf106"><mml:mrow><mml:msub><mml:mi>μ</mml:mi><mml:mi>ν</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mn>16</mml:mn></mml:mrow></mml:math></inline-formula> cm/s, <inline-formula><mml:math id="inf107"><mml:mrow><mml:msub><mml:mi>τ</mml:mi><mml:mi>ν</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mn>2</mml:mn></mml:mrow></mml:math></inline-formula> s, <inline-formula><mml:math id="inf108"><mml:mrow><mml:msub><mml:mi>Q</mml:mi><mml:mi>ν</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mrow><mml:mpadded width="+1.7pt"><mml:msqrt><mml:mrow><mml:mn>2</mml:mn><mml:mo>/</mml:mo><mml:msub><mml:mi>τ</mml:mi><mml:mi>ν</mml:mi></mml:msub></mml:mrow></mml:msqrt></mml:mpadded><mml:mo>⁢</mml:mo><mml:msub><mml:mi>σ</mml:mi><mml:mi>ν</mml:mi></mml:msub></mml:mrow></mml:mrow></mml:math></inline-formula> with <inline-formula><mml:math id="inf109"><mml:mrow><mml:msub><mml:mi>σ</mml:mi><mml:mi>ν</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mn>10</mml:mn></mml:mrow></mml:math></inline-formula> cm/s and <inline-formula><mml:math id="inf110"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>ϵ</mml:mi><mml:mo>∼</mml:mo><mml:mrow><mml:mi mathvariant="script">N</mml:mi></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mstyle></mml:math></inline-formula> when <inline-formula><mml:math id="inf111"><mml:mrow><mml:mrow><mml:mpadded width="+1.7pt"><mml:mn>2</mml:mn></mml:mpadded><mml:mo>⁢</mml:mo><mml:mtext>cm/s</mml:mtext></mml:mrow><mml:mo>≤</mml:mo><mml:mi>ν</mml:mi><mml:mo>≤</mml:mo><mml:mrow><mml:mpadded width="+1.7pt"><mml:mn>80</mml:mn></mml:mpadded><mml:mo>⁢</mml:mo><mml:mtext>cm/s</mml:mtext></mml:mrow></mml:mrow></mml:math></inline-formula> and <inline-formula><mml:math id="inf112"><mml:mrow><mml:mi>ϵ</mml:mi><mml:mo>=</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:math></inline-formula> otherwise. The planned trajectory was generated by discretized integration of the velocity signal:<disp-formula id="equ2"><label>(2)</label><mml:math id="m2"><mml:mrow><mml:msub><mml:mrow><mml:mover><mml:mi>x</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>n</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:msub><mml:mrow><mml:mover><mml:mi>x</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>n</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mrow><mml:mover><mml:mi>v</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>n</mml:mi></mml:mrow></mml:msub><mml:mspace width="thinmathspace"/><mml:mi mathvariant="normal">Δ</mml:mi><mml:mi>t</mml:mi><mml:mo>.</mml:mo></mml:mrow></mml:math></disp-formula></p><p>When the planned trajectory reached the boundary of the box, the trajectory was reflected from the walls by inverting the component of the velocity vector that was perpendicular to the wall. The parameters of the planned trajectory were chosen to approximate the movement of the real rats by the movement of the simulated animal (<xref ref-type="fig" rid="fig3s2">Figure 3—figure supplement 2</xref>).</p><p>Importantly, in any theta cycle multiple hypothetical planned trajectories could be generated by resampling the motion direction and the noise term, <inline-formula><mml:math id="inf113"><mml:mi>ϵ</mml:mi></mml:math></inline-formula> in <xref ref-type="disp-formula" rid="equ1">Equation 1</xref>. Moreover, these planned trajectories can be elongated by recursively applying <xref ref-type="disp-formula" rid="equ1 equ2">Equations 1 and 2</xref>. The planned trajectory influenced the motion of the simulated animal through the external control signal (motor command) as we describe it in the next paragraph.</p></sec><sec id="s4-1-2"><title>Generation of motion trajectories</title><p>We assumed that the simulated animal aims at following the planned trajectory but does not have access to its own location. Therefore the animal was assumed to infer the location from its noisy sensory inputs. To follow the planned trajectory, the simulated animal calculated motor commands to minimize the deviation between its planned and estimated locations.</p><p>To describe the transition between physical locations, <inline-formula><mml:math id="inf114"><mml:mi>x</mml:mi></mml:math></inline-formula>, we formulated a model where transitions were a result of motor commands, <inline-formula><mml:math id="inf115"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>u</mml:mi><mml:mi>n</mml:mi></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula>. For this, we adopted the standard linear Gaussian state space model:<disp-formula id="equ3"><label>(3)</label><mml:math id="m3"><mml:mrow><mml:msub><mml:mi>x</mml:mi><mml:mrow><mml:mi>n</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mrow><mml:mi>n</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mi>u</mml:mi><mml:mrow><mml:mi>n</mml:mi></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mi>ε</mml:mi><mml:mrow><mml:mi>u</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:mspace width="1em"/><mml:msub><mml:mi>ε</mml:mi><mml:mrow><mml:mi>u</mml:mi></mml:mrow></mml:msub><mml:mo>∼</mml:mo><mml:mrow><mml:mi mathvariant="script">N</mml:mi></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:mi>Q</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></disp-formula></p><p>where <inline-formula><mml:math id="inf116"><mml:msub><mml:mi>ε</mml:mi><mml:mi>u</mml:mi></mml:msub></mml:math></inline-formula> represented motor noise. The animal only had access to the location-dependent, but noisy sensory observations, <inline-formula><mml:math id="inf117"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>y</mml:mi><mml:mi>n</mml:mi></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula>:<disp-formula id="equ4"> <label>(4)</label><mml:math id="m4"><mml:mrow><mml:msub><mml:mi>y</mml:mi><mml:mi>n</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mrow><mml:mi>n</mml:mi></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mi>ε</mml:mi><mml:mrow><mml:mi>y</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:mspace width="thinmathspace"/><mml:mspace width="thinmathspace"/><mml:msub><mml:mi>ε</mml:mi><mml:mrow><mml:mi>y</mml:mi></mml:mrow></mml:msub><mml:mo>∼</mml:mo><mml:mrow><mml:mi mathvariant="script">N</mml:mi></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:mi>R</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></disp-formula></p><p>where <inline-formula><mml:math id="inf118"><mml:msub><mml:mi>ε</mml:mi><mml:mi>y</mml:mi></mml:msub></mml:math></inline-formula> is the sensory noise and <inline-formula><mml:math id="inf119"><mml:mi>Q</mml:mi></mml:math></inline-formula> and <inline-formula><mml:math id="inf120"><mml:mi>R</mml:mi></mml:math></inline-formula> are diagonal noise covariance matrices with <inline-formula><mml:math id="inf121"><mml:mrow><mml:msub><mml:mi>Q</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo>⁢</mml:mo><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mn>2.25</mml:mn></mml:mrow></mml:math></inline-formula> cm<sup>2</sup> and <inline-formula><mml:math id="inf122"><mml:mrow><mml:msub><mml:mi>R</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo>⁢</mml:mo><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mn>225</mml:mn></mml:mrow></mml:math></inline-formula> cm<sup>2</sup>. The small motor variance was necessary for smooth movements since motor errors accumulate across time (<xref ref-type="fig" rid="fig3s2">Figure 3—figure supplement 2</xref>). Conversely, large sensory variance was efficiently reduced by combining sensory information across different time steps (see below, <xref ref-type="disp-formula" rid="equ6">Equation 6</xref>).</p><p>Since the location, <inline-formula><mml:math id="inf123"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>x</mml:mi><mml:mi>n</mml:mi></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula>, was not observed, inference was required to calculate the motor command. This inference relied on estimates of the location in earlier theta cycles, the motor command, and the current sensory observation. The estimated location was represented by the Gaussian filtering posterior:<disp-formula id="equ5"><label>(5)</label><mml:math id="m5"><mml:mrow><mml:mi>P</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mi>n</mml:mi></mml:msub><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:msub><mml:mi>y</mml:mi><mml:mrow><mml:mn>1</mml:mn><mml:mo>:</mml:mo><mml:mi>n</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>u</mml:mi><mml:mrow><mml:mn>1</mml:mn><mml:mo>:</mml:mo><mml:mi>n</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mrow><mml:mi mathvariant="script">N</mml:mi></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>μ</mml:mi><mml:mi>n</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi mathvariant="normal">Σ</mml:mi><mml:mi>n</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:mo>.</mml:mo></mml:mrow></mml:math></disp-formula></p><p>This posterior is characterized by the mean estimated location <inline-formula><mml:math id="inf124"><mml:msub><mml:mi>μ</mml:mi><mml:mi>n</mml:mi></mml:msub></mml:math></inline-formula> and a covariance, <inline-formula><mml:math id="inf125"><mml:msub><mml:mi mathvariant="normal">Σ</mml:mi><mml:mi>n</mml:mi></mml:msub></mml:math></inline-formula>, which quantifies the uncertainty of the estimate. These parameters were updated in each time step (theta cycle) using the standard Kalman filter algorithm (<xref ref-type="bibr" rid="bib37">Murphy, 2012</xref>):<disp-formula id="equ6"><label>(6)</label><mml:math id="m6"><mml:mtable columnspacing="5pt" displaystyle="true" rowspacing="0pt"><mml:mtr><mml:mtd columnalign="right"><mml:msub><mml:mi>μ</mml:mi><mml:mi>n</mml:mi></mml:msub></mml:mtd><mml:mtd columnalign="left"><mml:mrow><mml:mi/><mml:mo>=</mml:mo><mml:mrow><mml:msub><mml:mi>μ</mml:mi><mml:mrow><mml:mi>n</mml:mi><mml:mo>-</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mi>u</mml:mi><mml:mi>n</mml:mi></mml:msub><mml:mo>+</mml:mo><mml:mrow><mml:msub><mml:mi>K</mml:mi><mml:mi>n</mml:mi></mml:msub><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:msub><mml:mi>y</mml:mi><mml:mi>n</mml:mi></mml:msub><mml:mo>-</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:msub><mml:mi>μ</mml:mi><mml:mrow><mml:mi>n</mml:mi><mml:mo>-</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mi>u</mml:mi><mml:mi>n</mml:mi></mml:msub></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:mrow></mml:mtd></mml:mtr><mml:mtr><mml:mtd columnalign="right"><mml:msub><mml:mi mathvariant="normal">Σ</mml:mi><mml:mi>n</mml:mi></mml:msub></mml:mtd><mml:mtd columnalign="left"><mml:mrow><mml:mi/><mml:mo>=</mml:mo><mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mi>I</mml:mi><mml:mo>-</mml:mo><mml:msub><mml:mi>K</mml:mi><mml:mi>n</mml:mi></mml:msub></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:msub><mml:mi mathvariant="normal">Σ</mml:mi><mml:mrow><mml:mi>n</mml:mi><mml:mo>-</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:mi>Q</mml:mi></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></disp-formula></p><p>where <inline-formula><mml:math id="inf126"><mml:mrow><mml:msub><mml:mi>K</mml:mi><mml:mi>n</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:msub><mml:mi mathvariant="normal">Σ</mml:mi><mml:mrow><mml:mi>n</mml:mi><mml:mo>-</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:mi>Q</mml:mi></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>⁢</mml:mo><mml:msup><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:msub><mml:mi mathvariant="normal">Σ</mml:mi><mml:mrow><mml:mi>n</mml:mi><mml:mo>-</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:mi>Q</mml:mi><mml:mo>+</mml:mo><mml:mi>R</mml:mi></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mrow><mml:mo>-</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:mrow></mml:math></inline-formula> is the Kalman gain matrix.</p><p>The motor command, <inline-formula><mml:math id="inf127"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>u</mml:mi><mml:mi>n</mml:mi></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula>, was calculated by low-pass filtering the deviation between the planned position, <inline-formula><mml:math id="inf128"><mml:msub><mml:mover accent="true"><mml:mi>x</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover><mml:mi>n</mml:mi></mml:msub></mml:math></inline-formula>, and the estimated position of the animal (posterior mean, <inline-formula><mml:math id="inf129"><mml:msub><mml:mi>μ</mml:mi><mml:mrow><mml:mi>n</mml:mi><mml:mo>-</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:math></inline-formula>):<disp-formula id="equ7"><label>(7)</label><mml:math id="m7"><mml:mrow><mml:msub><mml:mi>u</mml:mi><mml:mi>n</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mrow><mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mn>1</mml:mn><mml:mo>-</mml:mo><mml:mi>α</mml:mi></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>⁢</mml:mo><mml:msub><mml:mi>u</mml:mi><mml:mrow><mml:mi>n</mml:mi><mml:mo>-</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mrow><mml:mo>+</mml:mo><mml:mrow><mml:mi>α</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi>x</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover><mml:mi>n</mml:mi></mml:msub><mml:mo>-</mml:mo><mml:msub><mml:mi>μ</mml:mi><mml:mrow><mml:mi>n</mml:mi><mml:mo>-</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:mrow></mml:math></disp-formula></p><p>with <inline-formula><mml:math id="inf130"><mml:mrow><mml:mi>α</mml:mi><mml:mo>=</mml:mo><mml:mn>0.25</mml:mn></mml:mrow></mml:math></inline-formula> ensuring sufficiently smooth motion trajectories (<xref ref-type="fig" rid="fig3s2">Figure 3—figure supplement 2</xref>). Relationship between the planned position <inline-formula><mml:math id="inf131"><mml:msub><mml:mover accent="true"><mml:mi>x</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover><mml:mi>n</mml:mi></mml:msub></mml:math></inline-formula>, actual position <inline-formula><mml:math id="inf132"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>x</mml:mi><mml:mi>n</mml:mi></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula>, the sensory input <inline-formula><mml:math id="inf133"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>y</mml:mi><mml:mi>n</mml:mi></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula>, and the estimated location <inline-formula><mml:math id="inf134"><mml:mrow><mml:mi>P</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:msub><mml:mi>x</mml:mi><mml:mi>n</mml:mi></mml:msub><mml:mo lspace="2.5pt" rspace="2.5pt" stretchy="false">|</mml:mo><mml:mrow><mml:msub><mml:mi>y</mml:mi><mml:mrow><mml:mn>1</mml:mn><mml:mo>:</mml:mo><mml:mi>n</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>u</mml:mi><mml:mrow><mml:mn>1</mml:mn><mml:mo>:</mml:mo><mml:mi>n</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> is depicted in <xref ref-type="fig" rid="fig3s1">Figure 3—figure supplement 1b</xref>.</p><p>To make predictions about future positions, we defined the subjective trajectory of the animal, the distribution of trajectories consistent with all past observations and motor commands: <inline-formula><mml:math id="inf135"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>P</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mrow><mml:mi mathvariant="bold">x</mml:mi></mml:mrow><mml:mrow><mml:mi>n</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:msub><mml:mi>y</mml:mi><mml:mrow><mml:mn>1</mml:mn><mml:mo>:</mml:mo><mml:mi>n</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>u</mml:mi><mml:mrow><mml:mn>1</mml:mn><mml:mo>:</mml:mo><mml:mi>n</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mstyle></mml:math></inline-formula>. This subjective trajectory is associated with a particular theta cycle: since it is estimated on a cycle-by-cycle manner we use the index <inline-formula><mml:math id="inf136"><mml:mi>n</mml:mi></mml:math></inline-formula> to distinguish trajectories at different cycles. Here <inline-formula><mml:math id="inf137"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="bold">x</mml:mi></mml:mrow><mml:mrow><mml:mi>n</mml:mi></mml:mrow></mml:msub><mml:mo>≡</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>n</mml:mi><mml:mo>−</mml:mo><mml:msub><mml:mi>n</mml:mi><mml:mrow><mml:mi>p</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:mo>:</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mi>n</mml:mi><mml:mo>+</mml:mo><mml:msub><mml:mi>n</mml:mi><mml:mrow><mml:mi>f</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula> is a trajectory starting <inline-formula><mml:math id="inf138"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>n</mml:mi><mml:mi>p</mml:mi></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula> steps in the past and ending <inline-formula><mml:math id="inf139"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>n</mml:mi><mml:mi>f</mml:mi></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula> steps ahead in the future (<xref ref-type="fig" rid="fig3s1">Figure 3—figure supplement 1c</xref>, <xref ref-type="table" rid="table1">Table 1</xref>). We call the distribution <inline-formula><mml:math id="inf140"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>P</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mrow><mml:mi mathvariant="bold">x</mml:mi></mml:mrow><mml:mrow><mml:mi>n</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:msub><mml:mi>y</mml:mi><mml:mrow><mml:mn>1</mml:mn><mml:mo>:</mml:mo><mml:mi>n</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>u</mml:mi><mml:mrow><mml:mn>1</mml:mn><mml:mo>:</mml:mo><mml:mi>n</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mstyle></mml:math></inline-formula> the <italic>trajectory posterior</italic>. We sampled trajectories from the posterior distribution by starting each trajectory from the posterior of current position (filtering posterior, <xref ref-type="disp-formula" rid="equ5">Equation 5</xref>) and proceeded first backward, sampling from the conditional smoothing posterior, and then forward, sampling from the generative model.</p><p>To sample the past component of the trajectory (<inline-formula><mml:math id="inf141"><mml:mrow><mml:mi>m</mml:mi><mml:mo>≤</mml:mo><mml:mi>n</mml:mi></mml:mrow></mml:math></inline-formula>), we capitalized on the following relationship:<disp-formula id="equ8"><label>(8)</label><mml:math id="m8"><mml:mtable columnspacing="5pt" displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:mi>P</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:msub><mml:mi>x</mml:mi><mml:mrow><mml:mi>m</mml:mi><mml:mo>-</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo lspace="2.5pt" rspace="2.5pt" stretchy="false">|</mml:mo><mml:mrow><mml:msub><mml:mi>x</mml:mi><mml:mi>m</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>y</mml:mi><mml:mrow><mml:mn>1</mml:mn><mml:mo>:</mml:mo><mml:mi>n</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>u</mml:mi><mml:mrow><mml:mn>1</mml:mn><mml:mo>:</mml:mo><mml:mi>n</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:mtd><mml:mtd columnalign="left"><mml:mrow><mml:mo>∝</mml:mo><mml:mi>P</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mrow><mml:mi>m</mml:mi><mml:mo>-</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo stretchy="false">|</mml:mo><mml:msub><mml:mi>y</mml:mi><mml:mrow><mml:mn>1</mml:mn><mml:mo>:</mml:mo><mml:mrow><mml:mi>m</mml:mi><mml:mo>-</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>u</mml:mi><mml:mrow><mml:mn>1</mml:mn><mml:mo>:</mml:mo><mml:mrow><mml:mi>m</mml:mi><mml:mo>-</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:mrow></mml:msub><mml:mo rspace="4.2pt" stretchy="false">)</mml:mo></mml:mrow><mml:mi>P</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mi>m</mml:mi></mml:msub><mml:mo stretchy="false">|</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mrow><mml:mi>m</mml:mi><mml:mo>-</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>u</mml:mi><mml:mi>m</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></disp-formula><disp-formula id="equ9"><label>(9)</label><mml:math id="m9"><mml:mrow><mml:mtable columnalign="right left" rowspacing="4pt" columnspacing="1em"><mml:mtr><mml:mtd><mml:mo>=</mml:mo><mml:mrow><mml:mi mathvariant="script">N</mml:mi></mml:mrow><mml:mrow><mml:mo maxsize="1.2em" minsize="1.2em">(</mml:mo></mml:mrow><mml:msub><mml:mi mathvariant="normal">Λ</mml:mi><mml:mrow><mml:mi>m</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:msup><mml:mi>Q</mml:mi><mml:mrow><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msup><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mrow><mml:mi>m</mml:mi></mml:mrow></mml:msub><mml:mo>−</mml:mo><mml:msub><mml:mi>u</mml:mi><mml:mrow><mml:mi>m</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:mo>+</mml:mo><mml:msubsup><mml:mi mathvariant="normal">Σ</mml:mi><mml:mrow><mml:mi>m</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msubsup><mml:msub><mml:mi>μ</mml:mi><mml:mrow><mml:mi>m</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi mathvariant="normal">Λ</mml:mi><mml:mrow><mml:mi>m</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mrow><mml:mo maxsize="1.2em" minsize="1.2em">)</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:math></disp-formula></p><p>where the first factor on the right hand side of <xref ref-type="disp-formula" rid="equ8">Equation 8</xref> is the filtering posterior (<xref ref-type="disp-formula" rid="equ5">Equation 5</xref>) and the second factor is defined by the generative process ( (<xref ref-type="disp-formula" rid="equ3">Equation 3</xref>) ) and <inline-formula><mml:math id="inf142"><mml:mrow><mml:mi mathvariant="normal">Λ</mml:mi><mml:mo>=</mml:mo><mml:msup><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:msubsup><mml:mi mathvariant="normal">Σ</mml:mi><mml:mrow><mml:mi>m</mml:mi><mml:mo>-</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mo>-</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msubsup><mml:mo>+</mml:mo><mml:msup><mml:mi>Q</mml:mi><mml:mrow><mml:mo>-</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msup></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mrow><mml:mo>-</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:math></inline-formula>. We started each trajectory by sampling its first point independently from the filtering posterior (<xref ref-type="disp-formula" rid="equ5">Equation 5</xref>) and applied (<xref ref-type="disp-formula" rid="equ8">Equation 8</xref>) recursively to elongate the trajectory backward in time.</p><p>To generate samples in the forward direction (<inline-formula><mml:math id="inf143"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>m</mml:mi><mml:mo>&gt;</mml:mo><mml:mi>n</mml:mi></mml:mrow></mml:mstyle></mml:math></inline-formula>) we implemented an ancestral sampling approach. First, a hypothetical planned trajectory was generated as in <xref ref-type="disp-formula" rid="equ1 equ2">Equations 1 and 2</xref> starting from the last planned location <inline-formula><mml:math id="inf144"><mml:msub><mml:mover accent="true"><mml:mi>x</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover><mml:mi>n</mml:mi></mml:msub></mml:math></inline-formula>. Next, we calculated the hypothetical future motor command, <inline-formula><mml:math id="inf145"><mml:msub><mml:mi>u</mml:mi><mml:mrow><mml:mi>m</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:math></inline-formula> based on the difference between the next planned location <inline-formula><mml:math id="inf146"><mml:msub><mml:mover accent="true"><mml:mi>x</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover><mml:mrow><mml:mi>m</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:math></inline-formula> and current prediction for <inline-formula><mml:math id="inf147"><mml:mi>m</mml:mi></mml:math></inline-formula>, <inline-formula><mml:math id="inf148"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>x</mml:mi><mml:mi>m</mml:mi></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula> as in <xref ref-type="disp-formula" rid="equ7">Equation 7</xref>. Finally, we sampled the next predicted position from the distribution<disp-formula id="equ10"><label>(10)</label><mml:math id="m10"><mml:mrow><mml:mi>P</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mrow><mml:mi>m</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:msub><mml:mi>x</mml:mi><mml:mrow><mml:mi>m</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>u</mml:mi><mml:mrow><mml:mi>m</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mrow><mml:mi mathvariant="script">N</mml:mi></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mrow><mml:mi>m</mml:mi></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mi>u</mml:mi><mml:mrow><mml:mi>m</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:mi>Q</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>.</mml:mo></mml:mrow></mml:math></disp-formula></p><p>To elongate the trajectory further into the future we repeated this procedure multiple times.</p><p>We introduce <inline-formula><mml:math id="inf149"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi mathvariant="bold-italic">μ</mml:mi><mml:mrow><mml:mi>n</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>φ</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mrow><mml:mi mathvariant="double-struck">E</mml:mi></mml:mrow><mml:mo stretchy="false">[</mml:mo><mml:mi>P</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mrow><mml:mi mathvariant="bold">x</mml:mi></mml:mrow><mml:mrow><mml:mi>n</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:msub><mml:mi>y</mml:mi><mml:mrow><mml:mn>1</mml:mn><mml:mo>:</mml:mo><mml:mi>n</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>u</mml:mi><mml:mrow><mml:mn>1</mml:mn><mml:mo>:</mml:mo><mml:mi>n</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:mo stretchy="false">]</mml:mo></mml:mrow></mml:mstyle></mml:math></inline-formula> to denote the average over possible trajectories. <inline-formula><mml:math id="inf150"><mml:mi>φ</mml:mi></mml:math></inline-formula> indexes different parts of the trajectory and refers to the phase of the theta cycle at which the trajectory unfolds. Similarly, we also defined the covariance of the trajectories, <inline-formula><mml:math id="inf151"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi mathvariant="bold">Σ</mml:mi><mml:mrow><mml:mi>n</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>φ</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mstyle></mml:math></inline-formula>. We used an approximate, diagonal covariance matrix and ignored the covariances between different trajectories and theta phase. In our simulations we estimated <inline-formula><mml:math id="inf152"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi mathvariant="bold-italic">μ</mml:mi><mml:mrow><mml:mi>n</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>φ</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mstyle></mml:math></inline-formula> and <inline-formula><mml:math id="inf153"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi mathvariant="bold">Σ</mml:mi><mml:mrow><mml:mi>n</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>φ</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mstyle></mml:math></inline-formula> from 100 samples both for the past and for the future part of the represented trajectories.</p><p>The motion profile of the simulated animal, including the distribution and the auto-correlation of the speed, acceleration and heading was matched to empirical data from real animals (<xref ref-type="fig" rid="fig3s2">Figure 3—figure supplement 2</xref>). <xref ref-type="fig" rid="fig3s1">Figure 3—figure supplement 1c, d</xref> illustrates the inference process in the model by showing a short segment of the true trajectory of the simulated animal centered on its location at time step <inline-formula><mml:math id="inf154"><mml:mi>n</mml:mi></mml:math></inline-formula> as well as trajectories starting in the past and extending into the future sampled from the posterior distribution. As expected, the variance of these hypothetical trajectories <inline-formula><mml:math id="inf155"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi mathvariant="bold">Σ</mml:mi><mml:mrow><mml:mi>n</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>φ</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mstyle></mml:math></inline-formula> increased consistently from the past towards the future (from the beginning to the end of the theta cycle; illustrated by the increasing diameter of the ellipses in <xref ref-type="fig" rid="fig3s1">Figure 3—figure supplement 1d</xref>), while their mean <inline-formula><mml:math id="inf156"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi mathvariant="bold-italic">μ</mml:mi><mml:mrow><mml:mi>n</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>φ</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mstyle></mml:math></inline-formula> tracked accurately the true trajectory of the animal (<xref ref-type="fig" rid="fig3s1">Figure 3—figure supplement 1c, d</xref>). Mean trajectories and trajectories sampled from the trajectory posterior at subsequent theta cycles are compared in <xref ref-type="fig" rid="fig3s1">Figure 3—figure supplement 1e, f</xref> and in <xref ref-type="fig" rid="fig3">Figure 3a, b</xref>.</p><p>To change the correlation between the subsequent trajectories in <xref ref-type="fig" rid="fig7">Figure 7</xref>, we first generated 100 candidate trajectories sampled randomly from the posterior in time step (theta cycle) <inline-formula><mml:math id="inf157"><mml:mi>n</mml:mi></mml:math></inline-formula> and calculated <inline-formula><mml:math id="inf158"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msubsup><mml:mi>ϑ</mml:mi><mml:mrow><mml:mi>n</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msubsup></mml:mrow></mml:mstyle></mml:math></inline-formula>, the direction of the endpoint of each of them relative to the current motion direction of the animal. Next, we calculated the absolute circular difference in the endpoint direction between the candidate directions and the direction of the endpoint of the trajectory in the previous theta cycle:<disp-formula id="equ11"><label>(11)</label><mml:math id="m11"><mml:mrow><mml:mrow><mml:mi mathvariant="normal">Δ</mml:mi><mml:mo>⁢</mml:mo><mml:msubsup><mml:mi>ϑ</mml:mi><mml:mi>n</mml:mi><mml:mi>i</mml:mi></mml:msubsup></mml:mrow><mml:mo>=</mml:mo><mml:msub><mml:mrow><mml:mo stretchy="false">|</mml:mo><mml:mrow><mml:msubsup><mml:mi>ϑ</mml:mi><mml:mi>n</mml:mi><mml:mi>i</mml:mi></mml:msubsup><mml:mo>-</mml:mo><mml:msub><mml:mi>ϑ</mml:mi><mml:mrow><mml:mi>n</mml:mi><mml:mo>-</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mtext>circ</mml:mtext></mml:msub></mml:mrow></mml:math></disp-formula></p><p>Finally, we chose a single trajectory randomly, where the probability of each candidate trajectory was proportional to a sigmoid function of <inline-formula><mml:math id="inf159"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi mathvariant="normal">Δ</mml:mi><mml:msubsup><mml:mi>ϑ</mml:mi><mml:mi>n</mml:mi><mml:mi>i</mml:mi></mml:msubsup></mml:mrow></mml:mstyle></mml:math></inline-formula><disp-formula id="equ12">: <label>(12)</label><mml:math id="m12"><mml:mrow><mml:msubsup><mml:mi>p</mml:mi><mml:mrow><mml:mi>n</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msubsup><mml:mo>∝</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mrow><mml:mn>1</mml:mn><mml:mo>+</mml:mo><mml:mi>exp</mml:mi><mml:mo>⁡</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mo>−</mml:mo><mml:msub><mml:mi>γ</mml:mi><mml:mrow><mml:mi>ϑ</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi mathvariant="normal">Δ</mml:mi><mml:msubsup><mml:mi>ϑ</mml:mi><mml:mrow><mml:mi>n</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msubsup><mml:mo>−</mml:mo><mml:msub><mml:mi>ϑ</mml:mi><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mfrac></mml:mrow></mml:math></disp-formula></p><p>with slope (<inline-formula><mml:math id="inf160"><mml:msub><mml:mi>γ</mml:mi><mml:mi>ϑ</mml:mi></mml:msub></mml:math></inline-formula>) and threshold (<inline-formula><mml:math id="inf161"><mml:msub><mml:mi>ϑ</mml:mi><mml:mn>0</mml:mn></mml:msub></mml:math></inline-formula>) parameters controlling the sign and magnitude of the correlation between subsequent samples (<xref ref-type="table" rid="table2">Table 2</xref>).</p><table-wrap id="table2" position="float"><label>Table 2.</label><caption><title>Parameters controlling the auto-correlation of the sampled trajectories.</title></caption><table frame="hsides" rules="groups"><thead><tr><th align="left" valign="bottom">Parameter</th><th align="left" valign="bottom">Strong +</th><th align="left" valign="bottom">Weak +</th><th align="left" valign="bottom">Independent</th><th align="left" valign="bottom">Weak -</th><th align="left" valign="bottom">Strong -</th></tr></thead><tbody><tr><td align="left" valign="bottom"><inline-formula><mml:math id="inf162"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>γ</mml:mi><mml:mrow><mml:mi>ϑ</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula>(slope)</td><td align="char" char="." valign="bottom">-8</td><td align="char" char="." valign="bottom">-5</td><td align="char" char="." valign="bottom">0</td><td align="char" char="." valign="bottom">5</td><td align="char" char="." valign="bottom">5</td></tr><tr><td align="left" valign="bottom"><inline-formula><mml:math id="inf163"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>ϑ</mml:mi><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula>(threshold)</td><td align="left" valign="bottom"><inline-formula><mml:math id="inf164"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>π</mml:mi><mml:mrow><mml:mo>/</mml:mo></mml:mrow><mml:mn>8</mml:mn></mml:mrow></mml:mstyle></mml:math></inline-formula></td><td align="left" valign="bottom"><inline-formula><mml:math id="inf165"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>π</mml:mi><mml:mrow><mml:mo>/</mml:mo></mml:mrow><mml:mn>4</mml:mn></mml:mrow></mml:mstyle></mml:math></inline-formula></td><td align="left" valign="bottom"><inline-formula><mml:math id="inf166"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>π</mml:mi><mml:mrow><mml:mo>/</mml:mo></mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:mstyle></mml:math></inline-formula></td><td align="left" valign="bottom"><inline-formula><mml:math id="inf167"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>π</mml:mi><mml:mrow><mml:mo>/</mml:mo></mml:mrow><mml:mn>4</mml:mn></mml:mrow></mml:mstyle></mml:math></inline-formula></td><td align="left" valign="bottom"><inline-formula><mml:math id="inf168"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>π</mml:mi><mml:mrow><mml:mo>/</mml:mo></mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:mstyle></mml:math></inline-formula></td></tr></tbody></table></table-wrap></sec><sec id="s4-1-3"><title>Model-free generation of motion trajectories</title><p>In <xref ref-type="fig" rid="fig7s2">Figure 7—figure supplement 2</xref> we replaced our generative model for potential motion trajectories by sampling trajectory segments from the real trajectory of an animal (R1D2). Specifically, we selected all 1.5 s long motion trajectory segments of continuous running and divided them into 10 quantiles based on the starting speed of the segments. To generate a distribution of potential motion trajectories for a given starting point, we collected 100 randomly sampled trajectory segments from the matching speed quantile as the reference trajectory such that all samples were consistent with the geometry of the environment (i.e. they did not cross the border of the arena). This set of trajectory segments were then used to evaluate the posterior mean trajectory (<inline-formula><mml:math id="inf169"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi mathvariant="bold-italic">μ</mml:mi><mml:mrow><mml:mi>n</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>φ</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mstyle></mml:math></inline-formula>), the posterior variance of the trajectories (<inline-formula><mml:math id="inf170"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi mathvariant="bold">Σ</mml:mi><mml:mrow><mml:mi>n</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>φ</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mstyle></mml:math></inline-formula>). Note, that the variance of the trajectory segments were zero at the beginning (since all segments were aligned to the same starting point). To avoid unrealistically high firing rates in the product scheme, we added a constant 16 cm<sup>2</sup> to <inline-formula><mml:math id="inf171"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi mathvariant="bold">Σ</mml:mi><mml:mrow><mml:mi>n</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>φ</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mstyle></mml:math></inline-formula>. We used these quantities to drive the neuronal activity (see below) in the same way as we used trajectories sampled from the posterior of the generative model.</p></sec><sec id="s4-1-4"><title>Encoding the represented trajectory by the firing of place cells</title><p>We assumed that in each theta cycle the sequential activity of hippocampal place cells represents the temporally compressed trajectory posterior. The encoded trajectory was assumed to start in the past at the beginning of the theta cycle and arrive to the predicted future states (locations) by the end of the theta cycle (<xref ref-type="bibr" rid="bib51">Skaggs et al., 1996</xref>; <xref ref-type="bibr" rid="bib15">Foster and Wilson, 2007</xref>). Each model place cell <inline-formula><mml:math id="inf172"><mml:mi>i</mml:mi></mml:math></inline-formula> was associated with an encoding basis function, <inline-formula><mml:math id="inf173"><mml:mrow><mml:msub><mml:mi>ϕ</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>x</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula>, mapping the <italic>encoded position</italic> to the firing rate of cell <inline-formula><mml:math id="inf174"><mml:mi>i</mml:mi></mml:math></inline-formula>. Each basis function was generated as the sum of <inline-formula><mml:math id="inf175"><mml:mi>K</mml:mi></mml:math></inline-formula> Gaussian functions (subfields):<disp-formula id="equ13"><label>(13)</label><mml:math id="m13"><mml:mrow><mml:msub><mml:mi>ϕ</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>x</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:msub><mml:mi>ρ</mml:mi><mml:mn>0</mml:mn></mml:msub><mml:mo>+</mml:mo><mml:munderover><mml:mo>∑</mml:mo><mml:mrow><mml:mi>k</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>K</mml:mi></mml:munderover><mml:msub><mml:mi>ρ</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>k</mml:mi></mml:mrow></mml:msub><mml:mi>exp</mml:mi><mml:mo>⁡</mml:mo><mml:mrow><mml:mo maxsize="2.047em" minsize="2.047em">(</mml:mo></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mo>−</mml:mo><mml:msub><mml:mrow><mml:mi>μ</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mi>k</mml:mi></mml:mrow></mml:msub><mml:msup><mml:mo stretchy="false">)</mml:mo><mml:mrow><mml:mi mathvariant="normal">T</mml:mi></mml:mrow></mml:msup><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mo>−</mml:mo><mml:msub><mml:mrow><mml:mi>μ</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mi>k</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:mrow><mml:mo>/</mml:mo></mml:mrow><mml:msubsup><mml:mi>σ</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>k</mml:mi></mml:mrow><mml:mn>2</mml:mn></mml:msubsup><mml:mrow><mml:mo maxsize="2.047em" minsize="2.047em">)</mml:mo></mml:mrow></mml:mrow></mml:math></disp-formula></p><p>with the following choice of the parameters:</p><list list-type="bullet"><list-item><p>The number of subfields <inline-formula><mml:math id="inf176"><mml:mi>K</mml:mi></mml:math></inline-formula> was sampled from a gamma distribution with parameters <inline-formula><mml:math id="inf177"><mml:mrow><mml:mi>α</mml:mi><mml:mo>=</mml:mo><mml:mn>0.57</mml:mn></mml:mrow></mml:math></inline-formula> and <inline-formula><mml:math id="inf178"><mml:mrow><mml:mi>β</mml:mi><mml:mo>=</mml:mo><mml:mrow><mml:mn>1</mml:mn><mml:mo>/</mml:mo><mml:mn>0.14</mml:mn></mml:mrow></mml:mrow></mml:math></inline-formula> (<xref ref-type="bibr" rid="bib46">Rich et al., 2014</xref>). We included only cells with at least one subfield within the arena (<inline-formula><mml:math id="inf179"><mml:mrow><mml:mi>K</mml:mi><mml:mo>≥</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:math></inline-formula>).</p></list-item><list-item><p>The location of the subfields (μ) was distributed uniformly within the environment.</p></list-item><list-item><p>The radius of each subfield, <inline-formula><mml:math id="inf180"><mml:mi>σ</mml:mi></mml:math></inline-formula>, was sampled uniformly between 10 and 30 cm.</p></list-item><list-item><p>The maximum firing rate of each subfield <inline-formula><mml:math id="inf181"><mml:msub><mml:mi>ρ</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo>⁢</mml:mo><mml:mi>k</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> was chosen uniformly on the range 5–15 Hz.</p></list-item><list-item><p>The baseline firing rate <inline-formula><mml:math id="inf182"><mml:msub><mml:mi>ρ</mml:mi><mml:mn>0</mml:mn></mml:msub></mml:math></inline-formula> was chosen uniformly on the range 0.1–0.25 Hz.</p></list-item></list><p>Examples of the encoding basis functions are shown in <xref ref-type="fig" rid="fig5s1">Figure 5—figure supplement 1f</xref> (top row). Since the <italic>encoded</italic> positions can be different than the <italic>measured</italic> positions, the encoding basis function <inline-formula><mml:math id="inf183"><mml:mrow><mml:msub><mml:mi>ϕ</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>x</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> is not identical to the measured <italic>tuning curve</italic> <inline-formula><mml:math id="inf184"><mml:mrow><mml:msub><mml:mi>ψ</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>x</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula>, which is defined as a mapping from the <italic>measured</italic> position to the firing rate. The exact relationship between tuning curves and the encoding basis functions depends on the way the estimated location is encoded in the population activity. Tuning curves estimated from the synthetic position data are compared with experimentally recorded place cell tuning curves in <xref ref-type="fig" rid="fig3s3">Figure 3—figure supplement 3</xref>.</p><p>Importantly, in our model the activity of place cells was determined by the inferred trajectories and not the motion trajectory of the animal. The way the trajectories were encoded by the activity of place cells was different in the four encoding schemes:</p><list list-type="order"><list-item><p>In the <italic>mean</italic> encoding scheme the instantaneous firing rate of the place cells was determined by the mean of the trajectory posterior<disp-formula id="equ14"><label>(14)</label><mml:math id="m14"><mml:mrow><mml:msub><mml:mi mathvariant="bold-italic">λ</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>φ</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:msub><mml:mi>ϕ</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi mathvariant="bold-italic">μ</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>φ</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></disp-formula></p><p>That is, the cell’s firing rate changed within the theta cycle according to the value of its basis function at the different points of the mean inferred trajectory.</p></list-item><list-item><p>In the <italic>product</italic> scheme (<xref ref-type="bibr" rid="bib29">Ma et al., 2006</xref>) the firing rate was controlled both by the posterior mean and variance of the trajectory:<disp-formula id="equ15"><label>(15)</label><mml:math id="m15"><mml:mrow><mml:msub><mml:mi mathvariant="bold-italic">λ</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>φ</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:msub><mml:mi>ϕ</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi mathvariant="bold-italic">μ</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>φ</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo stretchy="false">)</mml:mo><mml:mspace width="thinmathspace"/><mml:mfrac><mml:msubsup><mml:mi>ς</mml:mi><mml:mrow><mml:mn>0</mml:mn></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup><mml:mrow><mml:msup><mml:mi>ς</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup><mml:mo stretchy="false">(</mml:mo><mml:mi>φ</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mfrac></mml:mrow></mml:math></disp-formula></p><p>where <inline-formula><mml:math id="inf185"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msup><mml:mrow><mml:mi>ς</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup><mml:mo stretchy="false">(</mml:mo><mml:mi>φ</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:msqrt><mml:mo movablelimits="true" form="prefix">det</mml:mo><mml:mi mathvariant="bold">Σ</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>φ</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:msqrt></mml:mrow></mml:mstyle></mml:math></inline-formula> and <inline-formula><mml:math id="inf186"><mml:mrow><mml:msub><mml:mi>ς</mml:mi><mml:mn>0</mml:mn></mml:msub><mml:mo>=</mml:mo><mml:mn>5</mml:mn></mml:mrow></mml:math></inline-formula> cm. This is similar to the mean encoding model, except that the population firing rate is scaled by the inverse of the posterior variance.</p></list-item><list-item><p>In the <italic>DDC</italic> scheme (<xref ref-type="bibr" rid="bib65">Zemel et al., 1998</xref>; <xref ref-type="bibr" rid="bib56">Vértes and Sahani, 2018</xref>) the instantaneous firing rate of cell <inline-formula><mml:math id="inf187"><mml:mi>i</mml:mi></mml:math></inline-formula> is the expectation of the basis function <inline-formula><mml:math id="inf188"><mml:mi>i</mml:mi></mml:math></inline-formula> under the trajectory posterior at the encoded time point (that is, the overlap between the basis function and the posterior):<disp-formula id="equ16"><label>(16)</label><mml:math id="m16"><mml:mrow><mml:msub><mml:mi mathvariant="bold-italic">λ</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>φ</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mo>∫</mml:mo><mml:msub><mml:mi>ϕ</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mi mathvariant="bold">x</mml:mi></mml:mrow><mml:mo stretchy="false">)</mml:mo><mml:mspace width="thinmathspace"/><mml:mi>P</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mi mathvariant="bold">x</mml:mi></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>φ</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:msub><mml:mi>y</mml:mi><mml:mrow><mml:mn>1</mml:mn><mml:mo>:</mml:mo><mml:mi>n</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>u</mml:mi><mml:mrow><mml:mn>1</mml:mn><mml:mo>:</mml:mo><mml:mi>n</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:mspace width="thinmathspace"/><mml:mi>d</mml:mi><mml:mi>x</mml:mi></mml:mrow></mml:math></disp-formula></p></list-item><list-item><p>In the <italic>sampling</italic> scheme, the encoded trajectory was sampled from the trajectory posterior, <inline-formula><mml:math id="inf189"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mrow><mml:mover><mml:mrow><mml:mi mathvariant="bold">x</mml:mi></mml:mrow><mml:mo stretchy="false">~</mml:mo></mml:mover></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>φ</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>∼</mml:mo><mml:mi>P</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mrow><mml:mi mathvariant="bold">x</mml:mi></mml:mrow><mml:mrow><mml:mi>n</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:msub><mml:mi>y</mml:mi><mml:mrow><mml:mn>1</mml:mn><mml:mo>:</mml:mo><mml:mi>n</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>u</mml:mi><mml:mrow><mml:mn>1</mml:mn><mml:mo>:</mml:mo><mml:mi>n</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mstyle></mml:math></inline-formula> and the instantaneous firing rate was the function of the sampled trajectory:<disp-formula id="equ17"><label>(17)</label><mml:math id="m17"><mml:mrow><mml:msub><mml:mi mathvariant="bold-italic">λ</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>φ</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:msub><mml:mi>ϕ</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mover><mml:mrow><mml:mi mathvariant="bold">x</mml:mi></mml:mrow><mml:mo stretchy="false">~</mml:mo></mml:mover></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>φ</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></disp-formula></p></list-item></list><p>In each encoding model, spikes were generated from the instantaneous firing rate <inline-formula><mml:math id="inf190"><mml:mrow><mml:msub><mml:mi>λ</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>φ</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> as an inhomogeneous Poisson process:<disp-formula id="equ18"><mml:math id="m18"><mml:mrow><mml:msub><mml:mrow><mml:mrow><mml:mi mathvariant="bold">s</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>φ</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>∼</mml:mo><mml:mrow><mml:mi mathvariant="normal">P</mml:mi><mml:mi mathvariant="normal">o</mml:mi><mml:mi mathvariant="normal">i</mml:mi><mml:mi mathvariant="normal">s</mml:mi><mml:mi mathvariant="normal">s</mml:mi><mml:mi mathvariant="normal">o</mml:mi><mml:mi mathvariant="normal">n</mml:mi></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi mathvariant="bold-italic">λ</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>φ</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></disp-formula></p></sec></sec><sec id="s4-2"><title>Decoding</title><p>To discriminate encoding schemes from each other we decoded position information both from experimentally recorded and from synthesized hippocampal neuronal activity. We performed decoding based on two different assumptions: First, assuming that a single position is encoded by the population activity (consistent with the mean and sampling schemes). Second, assuming that a distribution is encoded via the DDC scheme. We used static decoders to ensure that the variance of the decoder is independent of the theta phase as opposed to dynamic decoders, where the variance can be larger around the boundaries of the decoded segments.</p><sec id="s4-2-1"><title>Single point decoding</title><p>We performed static Bayesian decoding independently in each temporal bin at different phases of the theta cycle. The estimated position at theta phase <inline-formula><mml:math id="inf191"><mml:mi>φ</mml:mi></mml:math></inline-formula> is the mean of the posterior distribution calculated using Bayes rule:<disp-formula id="equ19"><label>(18)</label><mml:math id="m19"><mml:mrow><mml:mtable columnalign="right left" rowspacing="4pt" columnspacing="1em"><mml:mtr><mml:mtd><mml:mrow><mml:mover><mml:mi>x</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>φ</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mtd><mml:mtd><mml:mo>=</mml:mo><mml:mo>∫</mml:mo><mml:mspace width="thinmathspace"/><mml:mi>x</mml:mi><mml:mspace width="thinmathspace"/><mml:mi>P</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>x</mml:mi><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mrow><mml:mi mathvariant="bold">s</mml:mi></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>φ</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo stretchy="false">)</mml:mo><mml:mspace width="thinmathspace"/><mml:mi>d</mml:mi><mml:mi>x</mml:mi></mml:mtd></mml:mtr><mml:mtr><mml:mtd/><mml:mtd><mml:mo>=</mml:mo><mml:mo>∫</mml:mo><mml:mspace width="thinmathspace"/><mml:mi>x</mml:mi><mml:mspace width="thinmathspace"/><mml:mfrac><mml:mrow><mml:munder><mml:mo>∏</mml:mo><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:munder><mml:mtext>Poisson</mml:mtext><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>s</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>φ</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>;</mml:mo><mml:msub><mml:mi>ψ</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>x</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo stretchy="false">)</mml:mo><mml:mspace width="thinmathspace"/><mml:mi>P</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>x</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mrow><mml:mi>P</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mi mathvariant="bold">s</mml:mi></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>φ</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mfrac><mml:mspace width="thinmathspace"/><mml:mi>d</mml:mi><mml:mi>x</mml:mi></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:math></disp-formula></p><p>where the prior <inline-formula><mml:math id="inf192"><mml:mrow><mml:mi>P</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>x</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> was the estimated occupancy map and we used a Poisson likelihood with spatial tuning curves <inline-formula><mml:math id="inf193"><mml:mrow><mml:msub><mml:mi>ψ</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>x</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula>, estimated from the smoothed (10 cm Gaussian kernel) and binned spike counts. We binned spikes either into windows of fixed duration (20ms, <xref ref-type="fig" rid="fig2">Figure 2a–c</xref>) fixed theta phase (120°, <xref ref-type="fig" rid="fig3">Figure 3h</xref> and <xref ref-type="fig" rid="fig4">Figure 4</xref>) or into three bins with equal number of spike counts within a theta cycle (<xref ref-type="fig" rid="fig5">Figures 5</xref> and <xref ref-type="fig" rid="fig6">6</xref> and everywhere else). When calculating the spread of the decoded locations (<xref ref-type="fig" rid="fig2">Figure 2g</xref>, <xref ref-type="fig" rid="fig3">Figure 3h</xref>), we controlled for the possible biases introduced by theta phase modulation of the firing rates by randomly downsampling the data to match the spike count histograms across theta phase.</p></sec><sec id="s4-2-2"><title>DDC decoding</title><p>The DDC decoder assumes that at each time point in the theta cycle an isotropic Gaussian distribution over the locations is encoded by the population activity via <xref ref-type="disp-formula" rid="equ16">Equation 16</xref> and we aim at recovering the mean and the variance of the encoded distribution. To ensure that the theta phase dependence of the firing rates does not introduce a bias in the decoded variance, we divided each theta cycle into three windows (early, middle and late) with equal number of spikes. As linear decoding of DDC codes (<xref ref-type="bibr" rid="bib56">Vértes and Sahani, 2018</xref>) from spikes is very inaccurate, we performed maximum likelihood decoding of the parameters of the encoded distribution. The estimated mean and the variance in bin <inline-formula><mml:math id="inf194"><mml:mi>φ</mml:mi></mml:math></inline-formula> is:<disp-formula id="equ20"><label>(19)</label><mml:math id="m20"><mml:mrow><mml:mo fence="false" stretchy="false">{</mml:mo><mml:mrow><mml:mover><mml:mi mathvariant="bold-italic">μ</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>φ</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>,</mml:mo><mml:mspace width="thinmathspace"/><mml:msup><mml:mrow><mml:mover><mml:mi>σ</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup><mml:mo stretchy="false">(</mml:mo><mml:mi>φ</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo fence="false" stretchy="false">}</mml:mo><mml:mo>=</mml:mo><mml:munder><mml:mrow><mml:mi mathvariant="normal">a</mml:mi><mml:mi mathvariant="normal">r</mml:mi><mml:mi mathvariant="normal">g</mml:mi><mml:mspace width="thinmathspace"/><mml:mi mathvariant="normal">m</mml:mi><mml:mi mathvariant="normal">a</mml:mi><mml:mi mathvariant="normal">x</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="bold-italic">μ</mml:mi><mml:mo>,</mml:mo><mml:mspace width="thinmathspace"/><mml:msup><mml:mi>σ</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:munder><mml:munder><mml:mo>∏</mml:mo><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:munder><mml:mrow><mml:mi mathvariant="normal">P</mml:mi><mml:mi mathvariant="normal">o</mml:mi><mml:mi mathvariant="normal">i</mml:mi><mml:mi mathvariant="normal">s</mml:mi><mml:mi mathvariant="normal">s</mml:mi><mml:mi mathvariant="normal">o</mml:mi><mml:mi mathvariant="normal">n</mml:mi></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mi mathvariant="bold">s</mml:mi></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>φ</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>;</mml:mo><mml:msub><mml:mi>λ</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi mathvariant="bold-italic">μ</mml:mi><mml:mo>,</mml:mo><mml:msup><mml:mi>σ</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup><mml:mo stretchy="false">)</mml:mo><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></disp-formula></p><p>where<disp-formula id="equ21"><label>(20)</label><mml:math id="m21"><mml:mrow><mml:msub><mml:mi>λ</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi mathvariant="bold-italic">μ</mml:mi><mml:mo>,</mml:mo><mml:msup><mml:mi>σ</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mo>∫</mml:mo><mml:msub><mml:mi>ϕ</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>x</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mspace width="thinmathspace"/><mml:mrow><mml:mi mathvariant="script">N</mml:mi></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>x</mml:mi><mml:mo>;</mml:mo><mml:mi mathvariant="bold-italic">μ</mml:mi><mml:mo>,</mml:mo><mml:msup><mml:mi>σ</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup><mml:mrow><mml:mi mathvariant="bold">I</mml:mi></mml:mrow><mml:mo stretchy="false">)</mml:mo><mml:mspace width="thinmathspace"/><mml:mrow><mml:mi>d</mml:mi><mml:mi>x</mml:mi></mml:mrow><mml:mo>.</mml:mo></mml:mrow></mml:math></disp-formula></p><p>Here, <inline-formula><mml:math id="inf195"><mml:mrow><mml:msub><mml:mi>ϕ</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>x</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> is the basis function of neuron <inline-formula><mml:math id="inf196"><mml:mi>i</mml:mi></mml:math></inline-formula> used in the encoding process (<xref ref-type="disp-formula" rid="equ16">Equation 16</xref>). We numerically searched for the maximum likelihood parameters with constraints <inline-formula><mml:math id="inf197"><mml:mrow><mml:mi>μ</mml:mi><mml:mo>∈</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:mn>200</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> (cm) and <inline-formula><mml:math id="inf198"><mml:mrow><mml:mi>σ</mml:mi><mml:mo>∈</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mn>3</mml:mn><mml:mo>,</mml:mo><mml:mn>200</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> (cm) using quasi-Newton optimizer and a finite-difference approximation for the gradients.</p><p>In practice we do not have access to the encoding basis functions, <inline-formula><mml:math id="inf199"><mml:mrow><mml:msub><mml:mi>ϕ</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>x</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula>, only to the empirical tuning curves, <inline-formula><mml:math id="inf200"><mml:mrow><mml:mi>ψ</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>x</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula>. Based on the synthetic data we found that the tuning curves are typically more dispersed than the basis functions since the encoded and the measured location is not identical or the encoded distributions have nonzero variance (<xref ref-type="fig" rid="fig5s1">Figure 5—figure supplement 1e, g</xref>, Appendix 2). The difference between the size of the basis functions used for encoding and decoding introduces a bias in decoding the variance of the distribution (<xref ref-type="fig" rid="fig5s1">Figure 5—figure supplement 1a, c</xref>). To reduce this bias, we devised a non-parametric deconvolution algorithm that could estimate the encoding basis functions from the empirical tuning curves (<xref ref-type="fig" rid="fig5s1">Figure 5—figure supplement 1d–f</xref>, Appendix 2). Although we demonstrated on synthetic data that the bias of the decoder can be eliminated by using these estimated basis functions (<xref ref-type="fig" rid="fig5s1">Figure 5—figure supplement 1d</xref>), we obtained qualitatively similar decoding results with either the estimated basis functions or the empirical tuning curves. Therefore in <xref ref-type="fig" rid="fig5">Figure 5</xref> we show DDC decoding results obtained using the empirical tuning curves and show decoding with the estimated basis functions in <xref ref-type="fig" rid="fig5s2">Figure 5—figure supplement 2</xref> (see also Appendix 2).</p></sec></sec><sec id="s4-3"><title>Analysis of trajectory variability</title><p>To discriminate the mean scheme from the sampling scheme we introduced the excess variability index (EV-index). The EV-index is the difference between the cycle-to-cycle variability and the trajectory encoding error and is positive for sampling and negative for the mean scheme. In this section, we provide definitions for these quantities, derive their expected value for the sampling and the mean scheme and show how the EV-index can be estimated from data.</p><sec id="s4-3-1"><title>Cycle-to-cycle variability (<italic>CCV</italic>)</title><p>We defined cycle-to-cycle variability (<inline-formula><mml:math id="inf201"><mml:mi>χ</mml:mi></mml:math></inline-formula>) as the difference between the trajectories decoded from the neural activity in two subsequent theta cycles (<xref ref-type="fig" rid="fig3s1">Figure 3—figure supplement 1f</xref>):<disp-formula id="equ22"><label>(21)</label><mml:math id="m22"><mml:mtable columnspacing="5pt" displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:mi>χ</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>φ</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:mtd><mml:mtd columnalign="left"><mml:mrow><mml:mi/><mml:mo>=</mml:mo><mml:mrow><mml:mstyle displaystyle="false"><mml:msub><mml:mo largeop="true" symmetric="true">∑</mml:mo><mml:mi>i</mml:mi></mml:msub></mml:mstyle><mml:msup><mml:mrow><mml:mo maxsize="120%" minsize="120%">(</mml:mo><mml:mrow><mml:mrow><mml:msubsup><mml:mover accent="true"><mml:mi>x</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover><mml:mi>n</mml:mi><mml:mi>i</mml:mi></mml:msubsup><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>φ</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mo>-</mml:mo><mml:mrow><mml:msubsup><mml:mover accent="true"><mml:mi>x</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover><mml:mrow><mml:mi>n</mml:mi><mml:mo>-</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>i</mml:mi></mml:msubsup><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>φ</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:mrow><mml:mo maxsize="120%" minsize="120%">)</mml:mo></mml:mrow><mml:mn>2</mml:mn></mml:msup></mml:mrow></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></disp-formula></p><p>where <inline-formula><mml:math id="inf202"><mml:mi>φ</mml:mi></mml:math></inline-formula> is the theta phase and the index <inline-formula><mml:math id="inf203"><mml:mi>i</mml:mi></mml:math></inline-formula> runs over the 2 dimensions. As we show in Appendix 3, for the mean encoding scheme the expected value of the cycle-to-cycle variability is the sum of two terms:<disp-formula id="equ23"><label>(22)</label><mml:math id="m23"><mml:mrow><mml:mrow><mml:msub><mml:mi>E</mml:mi><mml:mtext>mean</mml:mtext></mml:msub><mml:mo>⁢</mml:mo><mml:mrow><mml:mo maxsize="120%" minsize="120%">[</mml:mo><mml:mrow><mml:mi>χ</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>φ</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mo maxsize="120%" minsize="120%">]</mml:mo></mml:mrow></mml:mrow><mml:mo>=</mml:mo><mml:mrow><mml:mrow><mml:mn>2</mml:mn><mml:mo>⁢</mml:mo><mml:msup><mml:mi>ϵ</mml:mi><mml:mn>2</mml:mn></mml:msup></mml:mrow><mml:mo>+</mml:mo><mml:mrow><mml:msup><mml:mi>ζ</mml:mi><mml:mn>2</mml:mn></mml:msup><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>φ</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:mrow></mml:math></disp-formula></p><p>where <inline-formula><mml:math id="inf204"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msup><mml:mi>ζ</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup><mml:mo>=</mml:mo><mml:mrow><mml:mi mathvariant="double-struck">E</mml:mi></mml:mrow><mml:mo stretchy="false">[</mml:mo><mml:munder><mml:mo>∑</mml:mo><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:munder><mml:mo stretchy="false">(</mml:mo><mml:msubsup><mml:mi mathvariant="bold-italic">μ</mml:mi><mml:mrow><mml:mi>n</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msubsup><mml:mspace width="thinmathspace"/><mml:mo>−</mml:mo><mml:mspace width="thinmathspace"/><mml:msubsup><mml:mrow><mml:mi mathvariant="bold-italic">μ</mml:mi></mml:mrow><mml:mrow><mml:mi>n</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msubsup><mml:msup><mml:mo stretchy="false">)</mml:mo><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup><mml:mo stretchy="false">]</mml:mo></mml:mrow></mml:mstyle></mml:math></inline-formula> is the expected change of the encoded mean trajectory between subsequent theta cycles, <inline-formula><mml:math id="inf205"><mml:msup><mml:mi>ϵ</mml:mi><mml:mn>2</mml:mn></mml:msup></mml:math></inline-formula> is the error of the decoder reflecting the finite number of observed neurons in the population and their stochastic spiking and the expectation runs across theta cycles. Since each theta cycle is divided into equal spike count bins, the decoder variance is independent of the theta phase <inline-formula><mml:math id="inf206"><mml:mi>φ</mml:mi></mml:math></inline-formula>. Conversely, <inline-formula><mml:math id="inf207"><mml:msup><mml:mi>ζ</mml:mi><mml:mn>2</mml:mn></mml:msup></mml:math></inline-formula> increases with <inline-formula><mml:math id="inf208"><mml:mi>φ</mml:mi></mml:math></inline-formula> (<xref ref-type="fig" rid="fig3s1">Figure 3—figure supplement 1g</xref>) as new observations have larger effect on uncertain future predictions than on the estimated past positions.</p><p>Although our derivations use the expected value (mean across theta cycles), in practice we often found that the median is more robust to outliers and thus in <xref ref-type="fig" rid="fig6">Figure 6</xref> and <xref ref-type="fig" rid="fig6s1">Figure 6—figure supplement 1</xref> we also show results with median next to the mean.</p><p>When estimating the cycle-to-cycle variability for the sampling scheme, where the population activity encodes independent samples drawn from the trajectory posterior, an additional term appears:<disp-formula id="equ24"><label>(23)</label><mml:math id="m24"><mml:mrow><mml:mrow><mml:mrow><mml:msub><mml:mi>E</mml:mi><mml:mtext>sam</mml:mtext></mml:msub><mml:mo>⁢</mml:mo><mml:mrow><mml:mo maxsize="120%" minsize="120%">[</mml:mo><mml:mrow><mml:mi>χ</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>φ</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mo maxsize="120%" minsize="120%">]</mml:mo></mml:mrow></mml:mrow><mml:mo>=</mml:mo><mml:mrow><mml:mrow><mml:mn>2</mml:mn><mml:mo>⁢</mml:mo><mml:msup><mml:mi>ϵ</mml:mi><mml:mn>2</mml:mn></mml:msup></mml:mrow><mml:mo>+</mml:mo><mml:mrow><mml:msup><mml:mi>ζ</mml:mi><mml:mn>2</mml:mn></mml:msup><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>φ</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mo>+</mml:mo><mml:mrow><mml:mn>2</mml:mn><mml:mo>⁢</mml:mo><mml:msup><mml:mi>σ</mml:mi><mml:mn>2</mml:mn></mml:msup><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>φ</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:mrow><mml:mo>.</mml:mo></mml:mrow></mml:math></disp-formula></p><p>Here, <inline-formula><mml:math id="inf209"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msup><mml:mrow><mml:mi>σ</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup><mml:mo stretchy="false">(</mml:mo><mml:mi>φ</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mrow><mml:mi mathvariant="double-struck">E</mml:mi></mml:mrow><mml:mrow><mml:mo maxsize="1.2em" minsize="1.2em">[</mml:mo></mml:mrow><mml:munder><mml:mo>∑</mml:mo><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:munder><mml:msup><mml:mi mathvariant="bold">Σ</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msup><mml:mo stretchy="false">(</mml:mo><mml:mi>φ</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mrow><mml:mo maxsize="1.2em" minsize="1.2em">]</mml:mo></mml:mrow></mml:mrow></mml:mstyle></mml:math></inline-formula> is the total posterior variance, which reflects the variance coming from the uncertainty of the inference. In our synthetic dataset, we found that the trajectory change is proportional to the posterior variance:<disp-formula id="equ25"><label>(24)</label><mml:math id="m25"><mml:mrow><mml:mrow><mml:msup><mml:mi>ζ</mml:mi><mml:mn>2</mml:mn></mml:msup><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>φ</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mo>=</mml:mo><mml:mrow><mml:mpadded width="+1.7pt"><mml:mi>α</mml:mi></mml:mpadded><mml:mo>⁢</mml:mo><mml:msup><mml:mi>σ</mml:mi><mml:mn>2</mml:mn></mml:msup><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>φ</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:math></disp-formula></p><p>with the proportionality constant <inline-formula><mml:math id="inf210"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mn>0</mml:mn><mml:mo>&lt;</mml:mo><mml:mi>α</mml:mi><mml:mo>&lt;</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:mstyle></mml:math></inline-formula> (<xref ref-type="fig" rid="fig3s1">Figure 3—figure supplement 1g</xref>). Using this insight, we can simplify our treatment: by substituting <xref ref-type="disp-formula" rid="equ25">Equation 24</xref> into <xref ref-type="disp-formula" rid="equ23 equ24">Equations 22 and 23</xref>, we can see that in both coding schemes the cycle-to-cycle variability increases with the theta phase, and the magnitude of this increase, proportional to the total posterior variance <inline-formula><mml:math id="inf211"><mml:mrow><mml:msup><mml:mi>σ</mml:mi><mml:mn>2</mml:mn></mml:msup><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>φ</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula>, can discriminate the two coding schemes. In order to obtain an independent estimate of <inline-formula><mml:math id="inf212"><mml:mrow><mml:msup><mml:mi>σ</mml:mi><mml:mn>2</mml:mn></mml:msup><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>φ</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula>, we can exploit insights obtained from synthetic data and introduce another measure, the trajectory encoding error.</p></sec><sec id="s4-3-2"><title>Trajectory encoding error (<italic>TEE</italic>)</title><p>We defined trajectory encoding error (<inline-formula><mml:math id="inf213"><mml:mi>γ</mml:mi></mml:math></inline-formula>) as the expected difference between the true two-dimensional trajectory of the rat, <inline-formula><mml:math id="inf214"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="bold">x</mml:mi></mml:mrow><mml:mrow><mml:mi>n</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula>, and the trajectory decoded from the neural activity <inline-formula><mml:math id="inf215"><mml:msub><mml:mover accent="true"><mml:mi mathvariant="bold">x</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover><mml:mi>n</mml:mi></mml:msub></mml:math></inline-formula> (<xref ref-type="fig" rid="fig3s1">Figure 3—figure supplement 1e</xref>):<disp-formula id="equ26"><label>(25)</label><mml:math id="m26"><mml:mrow><mml:mi>γ</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>φ</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:munder><mml:mo>∑</mml:mo><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:munder><mml:mrow><mml:mo maxsize="1.2em" minsize="1.2em">(</mml:mo></mml:mrow><mml:msubsup><mml:mrow><mml:mi mathvariant="bold">x</mml:mi></mml:mrow><mml:mrow><mml:mi>n</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msubsup><mml:mo>−</mml:mo><mml:msubsup><mml:mrow><mml:mover><mml:mrow><mml:mi mathvariant="bold">x</mml:mi></mml:mrow><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>n</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msubsup><mml:mo stretchy="false">(</mml:mo><mml:mi>φ</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:msup><mml:mrow><mml:mo maxsize="1.2em" minsize="1.2em">)</mml:mo></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:math></disp-formula></p><p>When comparing decoded and physical trajectories, we assumed a fixed correspondence between theta phase <inline-formula><mml:math id="inf216"><mml:mi>φ</mml:mi></mml:math></inline-formula> and temporal shift along the true trajectory. Specifically, for each animal we first calculated the average decoding error for early, mid and late phase spikes with respect to the true position temporally shifted along the motion trajectory (<xref ref-type="fig" rid="fig4s2">Figure 4—figure supplement 2</xref>). Next, we determined the temporal shift <inline-formula><mml:math id="inf217"><mml:mrow><mml:mi mathvariant="normal">Δ</mml:mi><mml:mo>⁢</mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:math></inline-formula> that minimized the decoding error separately for early, mid, and late theta phases and used this <inline-formula><mml:math id="inf218"><mml:mrow><mml:mi mathvariant="normal">Δ</mml:mi><mml:mo>⁢</mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:math></inline-formula> to calculate <inline-formula><mml:math id="inf219"><mml:mi>γ</mml:mi></mml:math></inline-formula>.</p><p>In the case of mean encoding the trajectory encoding error is the sum of two terms:<disp-formula id="equ27"><label>(26)</label><mml:math id="m27"><mml:mrow><mml:mtable columnalign="right left" rowspacing="4pt" columnspacing="1em"><mml:mtr><mml:mtd><mml:msub><mml:mrow><mml:mrow><mml:mi mathvariant="double-struck">E</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:mtext>mean</mml:mtext></mml:mrow></mml:msub><mml:mi>γ</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>φ</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mtd><mml:mtd><mml:mo>=</mml:mo><mml:mrow><mml:mi mathvariant="double-struck">E</mml:mi></mml:mrow><mml:mrow><mml:mo>[</mml:mo><mml:mrow><mml:munder><mml:mo mathvariant="bold">∑</mml:mo><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:munder><mml:msubsup><mml:mrow><mml:mi mathvariant="bold">x</mml:mi></mml:mrow><mml:mrow><mml:mi>n</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msubsup><mml:mo>−</mml:mo><mml:msubsup><mml:mi mathvariant="bold-italic">μ</mml:mi><mml:mrow><mml:mi>n</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msubsup><mml:mo stretchy="false">(</mml:mo><mml:mi>φ</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>+</mml:mo><mml:msubsup><mml:mi mathvariant="bold-italic">μ</mml:mi><mml:mrow><mml:mi>n</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msubsup><mml:mo stretchy="false">(</mml:mo><mml:mi>φ</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>−</mml:mo><mml:msubsup><mml:mrow><mml:mover><mml:mrow><mml:mi mathvariant="bold">x</mml:mi></mml:mrow><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>n</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msubsup><mml:mo stretchy="false">(</mml:mo><mml:mi>φ</mml:mi><mml:msup><mml:mo stretchy="false">)</mml:mo><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:mrow><mml:mo>]</mml:mo></mml:mrow></mml:mtd></mml:mtr><mml:mtr><mml:mtd/><mml:mtd><mml:mo>=</mml:mo><mml:msup><mml:mi mathvariant="bold-italic">σ</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup><mml:mo stretchy="false">(</mml:mo><mml:mi>φ</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>+</mml:mo><mml:msup><mml:mi>ϵ</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:math></disp-formula></p><p>where we used the fact that the encoded trajectory is the mean <inline-formula><mml:math id="inf220"><mml:mrow><mml:msub><mml:mi>μ</mml:mi><mml:mi>n</mml:mi></mml:msub><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>φ</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula>, and if the model of the animal is consistent, then the expected difference between the posterior mean and the true location equals the variance of the posterior, <inline-formula><mml:math id="inf221"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mrow><mml:mi mathvariant="double-struck">E</mml:mi></mml:mrow><mml:mrow><mml:mo maxsize="1.2em" minsize="1.2em">[</mml:mo></mml:mrow><mml:munder><mml:mo>∑</mml:mo><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:munder><mml:mo stretchy="false">(</mml:mo><mml:msubsup><mml:mrow><mml:mi mathvariant="bold">x</mml:mi></mml:mrow><mml:mrow><mml:mi>n</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msubsup><mml:mo>−</mml:mo><mml:msubsup><mml:mi mathvariant="bold-italic">μ</mml:mi><mml:mrow><mml:mi>n</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msubsup><mml:msup><mml:mo stretchy="false">)</mml:mo><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup><mml:mrow><mml:mo maxsize="1.2em" minsize="1.2em">]</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:msup><mml:mi mathvariant="bold-italic">σ</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:mstyle></mml:math></inline-formula>.</p><p>In the case of sampling the encoded trajectory is <inline-formula><mml:math id="inf222"><mml:msub><mml:mover accent="true"><mml:mi mathvariant="bold">x</mml:mi><mml:mo stretchy="false">~</mml:mo></mml:mover><mml:mi>n</mml:mi></mml:msub></mml:math></inline-formula> and the trajectory encoding error is increased by the difference between the mean and the sampled trajectory:<disp-formula id="equ28"><label>(27)</label><mml:math id="m28"><mml:mrow><mml:mtable columnalign="right left" rowspacing="4pt" columnspacing="1em"><mml:mtr><mml:mtd><mml:msub><mml:mrow><mml:mi mathvariant="double-struck">E</mml:mi></mml:mrow><mml:mrow><mml:mtext>sam</mml:mtext></mml:mrow></mml:msub><mml:mrow><mml:mo maxsize="1.2em" minsize="1.2em">[</mml:mo></mml:mrow><mml:mi>γ</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>φ</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mrow><mml:mo maxsize="1.2em" minsize="1.2em">]</mml:mo></mml:mrow></mml:mtd><mml:mtd><mml:mo>=</mml:mo><mml:mrow><mml:mi mathvariant="double-struck">E</mml:mi></mml:mrow><mml:mrow><mml:mo maxsize="1.623em" minsize="1.623em">[</mml:mo></mml:mrow><mml:munder><mml:mo>∑</mml:mo><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:munder><mml:mrow><mml:mo maxsize="1.2em" minsize="1.2em">(</mml:mo></mml:mrow><mml:msubsup><mml:mrow><mml:mi mathvariant="bold">x</mml:mi></mml:mrow><mml:mrow><mml:mi>n</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msubsup><mml:mo>−</mml:mo><mml:msubsup><mml:mrow><mml:mi mathvariant="bold-italic">μ</mml:mi></mml:mrow><mml:mrow><mml:mi>n</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msubsup><mml:mo stretchy="false">(</mml:mo><mml:mi>φ</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>+</mml:mo><mml:msubsup><mml:mrow><mml:mi mathvariant="bold-italic">μ</mml:mi></mml:mrow><mml:mrow><mml:mi>n</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msubsup><mml:mo stretchy="false">(</mml:mo><mml:mi>φ</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>−</mml:mo><mml:msubsup><mml:mrow><mml:mover><mml:mrow><mml:mi mathvariant="bold">x</mml:mi></mml:mrow><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>n</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msubsup><mml:mo stretchy="false">(</mml:mo><mml:mi>φ</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:msup><mml:mrow><mml:mo maxsize="1.2em" minsize="1.2em">)</mml:mo></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup><mml:mrow><mml:mo maxsize="1.623em" minsize="1.623em">]</mml:mo></mml:mrow></mml:mtd></mml:mtr><mml:mtr><mml:mtd/><mml:mtd><mml:mo>=</mml:mo><mml:msup><mml:mrow><mml:mi mathvariant="bold-italic">σ</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup><mml:mo stretchy="false">(</mml:mo><mml:mi>φ</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>+</mml:mo><mml:mrow><mml:mi mathvariant="double-struck">E</mml:mi></mml:mrow><mml:mrow><mml:mo maxsize="1.623em" minsize="1.623em">[</mml:mo></mml:mrow><mml:munder><mml:mo>∑</mml:mo><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:munder><mml:mrow><mml:mo maxsize="1.2em" minsize="1.2em">(</mml:mo></mml:mrow><mml:msubsup><mml:mrow><mml:mi mathvariant="bold-italic">μ</mml:mi></mml:mrow><mml:mrow><mml:mi>n</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msubsup><mml:mo stretchy="false">(</mml:mo><mml:mi>φ</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>−</mml:mo><mml:msubsup><mml:mrow><mml:mover><mml:mrow><mml:mi mathvariant="bold">x</mml:mi></mml:mrow><mml:mo stretchy="false">~</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>n</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msubsup><mml:mo stretchy="false">(</mml:mo><mml:mi>φ</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>+</mml:mo><mml:msubsup><mml:mrow><mml:mover><mml:mrow><mml:mi mathvariant="bold">x</mml:mi></mml:mrow><mml:mo stretchy="false">~</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>n</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msubsup><mml:mo stretchy="false">(</mml:mo><mml:mi>φ</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>−</mml:mo><mml:msubsup><mml:mrow><mml:mover><mml:mrow><mml:mi mathvariant="bold">x</mml:mi></mml:mrow><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>n</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msubsup><mml:mo stretchy="false">(</mml:mo><mml:mi>φ</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:msup><mml:mrow><mml:mo maxsize="1.2em" minsize="1.2em">)</mml:mo></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup><mml:mrow><mml:mo maxsize="1.623em" minsize="1.623em">]</mml:mo></mml:mrow></mml:mtd></mml:mtr><mml:mtr><mml:mtd/><mml:mtd><mml:mo>=</mml:mo><mml:mn>2</mml:mn><mml:msup><mml:mrow><mml:mi mathvariant="bold-italic">σ</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup><mml:mo stretchy="false">(</mml:mo><mml:mi>φ</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>+</mml:mo><mml:msup><mml:mi>ϵ</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:math></disp-formula></p></sec><sec id="s4-3-3"><title>Decoding error</title><p>To directly compare cycle-to-cycle variability with trajectory encoding error we have to estimate the decoding error, <inline-formula><mml:math id="inf223"><mml:msup><mml:mi>ϵ</mml:mi><mml:mn>2</mml:mn></mml:msup></mml:math></inline-formula>. A lower bound to the decoding error is given by the Cramér-Rao bound (<xref ref-type="bibr" rid="bib10">Dayan and Abbott, 2001</xref>), but in our simulations the actual decoding error was slightly larger than this bound. Underestimating the decoding error would bias the excess variability towards more positive values (see below), which we wanted to avoid as it would provide false evidence for the sampling scheme.</p><p>To obtain a reasonable upper bound instead, we note, that both <inline-formula><mml:math id="inf224"><mml:mi>χ</mml:mi></mml:math></inline-formula> and <inline-formula><mml:math id="inf225"><mml:mi>γ</mml:mi></mml:math></inline-formula> were evaluated in three different phases of the theta cycles: early (<inline-formula><mml:math id="inf226"><mml:msub><mml:mi>φ</mml:mi><mml:mn>1</mml:mn></mml:msub></mml:math></inline-formula>), mid (<inline-formula><mml:math id="inf227"><mml:msub><mml:mi>φ</mml:mi><mml:mn>2</mml:mn></mml:msub></mml:math></inline-formula>) and late (<inline-formula><mml:math id="inf228"><mml:msub><mml:mi>φ</mml:mi><mml:mn>3</mml:mn></mml:msub></mml:math></inline-formula>). At early theta phases when encoding past positions the posterior variance <inline-formula><mml:math id="inf229"><mml:msup><mml:mi>σ</mml:mi><mml:mn>2</mml:mn></mml:msup></mml:math></inline-formula> is small and thus both <inline-formula><mml:math id="inf230"><mml:mi>χ</mml:mi></mml:math></inline-formula> and <inline-formula><mml:math id="inf231"><mml:mi>γ</mml:mi></mml:math></inline-formula> are dominated by <inline-formula><mml:math id="inf232"><mml:msup><mml:mi>ϵ</mml:mi><mml:mn>2</mml:mn></mml:msup></mml:math></inline-formula>. Thus, we estimated the decoding error from the measured cycle-to-cycle variability and trajectory encoding error at early theta phase.</p><p>Furthermore, to compare cycle-to-cycle variability with trajectory encoding error we defined the compensated cycle-to-cycle variability and trajectory encoding error by subtracting the estimated decoding error:<disp-formula id="equ29"><label>(28)</label><mml:math id="m29"><mml:mtable columnspacing="5pt" displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:mrow><mml:msup><mml:mi>χ</mml:mi><mml:mo>′</mml:mo></mml:msup><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>φ</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mo>=</mml:mo><mml:mrow><mml:mrow><mml:mi>χ</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>φ</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mo>-</mml:mo><mml:mrow><mml:mn>2</mml:mn><mml:mo>⁢</mml:mo><mml:msup><mml:mi>ϵ</mml:mi><mml:mn>2</mml:mn></mml:msup></mml:mrow></mml:mrow></mml:mrow></mml:mtd><mml:mtd columnalign="left"><mml:mrow><mml:mi/><mml:mo>≈</mml:mo><mml:mrow><mml:mrow><mml:mi>χ</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>φ</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mo>-</mml:mo><mml:mrow><mml:mi>χ</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>φ</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></disp-formula><disp-formula id="equ30"><label>(29)</label><mml:math id="m30"><mml:mtable columnspacing="5pt" displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:mrow><mml:msup><mml:mi>γ</mml:mi><mml:mo>′</mml:mo></mml:msup><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>φ</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mo>=</mml:mo><mml:mrow><mml:mrow><mml:mi>γ</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>φ</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mo>-</mml:mo><mml:msup><mml:mi>ϵ</mml:mi><mml:mn>2</mml:mn></mml:msup></mml:mrow></mml:mrow></mml:mtd><mml:mtd columnalign="left"><mml:mrow><mml:mi/><mml:mo>≈</mml:mo><mml:mrow><mml:mrow><mml:mi>γ</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>φ</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mo>-</mml:mo><mml:mrow><mml:mi>γ</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>φ</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></disp-formula></p></sec><sec id="s4-3-4"><title>Excess variability</title><p>We define the excess variability as the difference between <inline-formula><mml:math id="inf233"><mml:msup><mml:mi>χ</mml:mi><mml:mo>′</mml:mo></mml:msup></mml:math></inline-formula> and <inline-formula><mml:math id="inf234"><mml:msup><mml:mi>γ</mml:mi><mml:mo>′</mml:mo></mml:msup></mml:math></inline-formula>:<disp-formula id="equ31"><label>(30)</label><mml:math id="m31"><mml:mtable columnspacing="5pt" displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:mi>ξ</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>φ</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:mtd><mml:mtd columnalign="left"><mml:mrow><mml:mi/><mml:mo>=</mml:mo><mml:mrow><mml:mrow><mml:msup><mml:mi>χ</mml:mi><mml:mo>′</mml:mo></mml:msup><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>φ</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mo>-</mml:mo><mml:mrow><mml:msup><mml:mi>γ</mml:mi><mml:mo>′</mml:mo></mml:msup><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>φ</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></disp-formula></p><p>Substituting <xref ref-type="disp-formula" rid="equ23 equ24">Equations 22 and 23</xref>, <xref ref-type="disp-formula" rid="equ27 equ28">Equations 26 and 27</xref> and <xref ref-type="disp-formula" rid="equ29 equ30">Equations 28 and 29</xref> to <xref ref-type="disp-formula" rid="equ31">Equation 30</xref> we can obtain the expectation of the excess variability in the sampling and the mean encoding scheme:<disp-formula id="equ32"><label>(31)</label><mml:math id="m32"><mml:mrow><mml:mtable columnalign="right left" rowspacing="4pt" columnspacing="1em"><mml:mtr><mml:mtd><mml:msub><mml:mi>ξ</mml:mi><mml:mrow><mml:mtext>mean</mml:mtext></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>φ</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mi>α</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">)</mml:mo><mml:mspace width="thinmathspace"/><mml:msup><mml:mi mathvariant="bold-italic">σ</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup><mml:mo stretchy="false">(</mml:mo><mml:mi>φ</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>&lt;</mml:mo><mml:mn>0</mml:mn></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:math></disp-formula><disp-formula id="equ33"><label>(32)</label><mml:math id="m33"><mml:mrow><mml:mtable columnalign="right left" rowspacing="4pt" columnspacing="1em"><mml:mtr><mml:mtd><mml:msub><mml:mi>ξ</mml:mi><mml:mrow><mml:mtext>sam</mml:mtext></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>φ</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mi>α</mml:mi><mml:mspace width="thinmathspace"/><mml:msup><mml:mi mathvariant="bold-italic">σ</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup><mml:mo stretchy="false">(</mml:mo><mml:mi>φ</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>&gt;</mml:mo><mml:mn>0</mml:mn></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:math></disp-formula></p><p>The excess variability is positive for sampling and negative for mean encoding. As <inline-formula><mml:math id="inf235"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msup><mml:mi mathvariant="bold-italic">σ</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:mstyle></mml:math></inline-formula> is expected to increase within a theta cycle, the excess variability is most distinctive at late theta phases. Therefore, throughout the paper we defined the <italic>EV-index</italic> as the excess variability at late theta phases:<disp-formula id="equ34"><label>(33)</label><mml:math id="m34"><mml:mtable columnspacing="5pt" displaystyle="true" rowspacing="0pt"><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:mi>ξ</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>φ</mml:mi><mml:mn>3</mml:mn></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:mtd><mml:mtd columnalign="left"><mml:mrow><mml:mi/><mml:mo>=</mml:mo><mml:mrow><mml:mrow><mml:msup><mml:mi>χ</mml:mi><mml:mo>′</mml:mo></mml:msup><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>φ</mml:mi><mml:mn>3</mml:mn></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mo>-</mml:mo><mml:mrow><mml:msup><mml:mi>γ</mml:mi><mml:mo>′</mml:mo></mml:msup><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>φ</mml:mi><mml:mn>3</mml:mn></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:mrow></mml:mtd></mml:mtr><mml:mtr><mml:mtd/><mml:mtd columnalign="left"><mml:mrow><mml:mi/><mml:mo>=</mml:mo><mml:mrow><mml:mrow><mml:mrow><mml:mi>χ</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>φ</mml:mi><mml:mn>3</mml:mn></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mo>-</mml:mo><mml:mrow><mml:mi>χ</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>φ</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mo>-</mml:mo><mml:mrow><mml:mi>γ</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>φ</mml:mi><mml:mn>3</mml:mn></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:mrow><mml:mo>+</mml:mo><mml:mrow><mml:mi>γ</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>φ</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></disp-formula></p><p>Importantly, all terms in <xref ref-type="disp-formula" rid="equ34">Equation 33</xref> can be measured directly from the data.</p><p>We calculated the EV-index either using all theta cycles (<xref ref-type="fig" rid="fig6s1">Figure 6—figure supplement 1</xref>) or using theta cycles with high spike counts in order to mitigate the effect of large decoding error (<xref ref-type="fig" rid="fig6">Figure 6</xref>). To reduce the effect of outliers, we also reported the median of the EV-index in <xref ref-type="fig" rid="fig6">Figure 6l and k</xref>. Error bars on the EV-index (<xref ref-type="fig" rid="fig6">Figure 6f–g and k</xref>, <xref ref-type="fig" rid="fig6s1">Figure 6—figure supplement 1e-f, j</xref>) reflect the standard error across the theta cycles. When showing the median across the theta cycles (<xref ref-type="fig" rid="fig6">Figure 6l</xref>, <xref ref-type="fig" rid="fig6s1">Figure 6—figure supplement 1k</xref>), the error bars indicate the 5% and 95% confidence intervals estimated by bootstrapping. Specifically, we obtained 1000 pseudo-datasets by discarding randomly selected half of the theta cycles and calculating the EV-index of the remaining data. The statistical significance of the EV-index was tested using one sample t-tests (<xref ref-type="fig" rid="fig6">Figure 6f, g and k</xref>; <xref ref-type="fig" rid="fig6s1">Figure 6—figure supplement 1e, f and j</xref>) or bootstrapping (<xref ref-type="fig" rid="fig6">Figure 6l</xref> and <xref ref-type="fig" rid="fig6s1">Figure 6—figure supplement 1k</xref>). The resulting p-values are shown in <xref ref-type="table" rid="table3 table4">Tables 3 and 4</xref>.</p><table-wrap id="table3" position="float"><label>Table 3.</label><caption><title>p-values associated with <xref ref-type="fig" rid="fig6">Figure 6</xref>.</title><p>p-values for panels f,g and k were calculated using a one sample t-test. p-values for panel l were estimated by bootstrapping.</p></caption><table frame="hsides" rules="groups"><tbody><tr><td align="left" valign="bottom"><bold>Panel: f</bold></td><td align="left" valign="bottom"/><td align="left" valign="bottom"/><td align="left" valign="bottom"/><td align="left" valign="bottom"/><td align="left" valign="bottom"/><td align="left" valign="bottom"/><td align="left" valign="bottom"/></tr><tr><td align="left" valign="bottom">regular</td><td align="left" valign="bottom">jitter: 0</td><td align="char" char="." valign="bottom">5</td><td align="char" char="." valign="bottom">10</td><td align="char" char="." valign="bottom">20</td><td align="char" char="." valign="bottom">30</td><td align="char" char="." valign="bottom">40</td><td align="left" valign="bottom"/></tr><tr><td align="char" char="hyphen" valign="bottom">8.9e-10</td><td align="char" char="hyphen" valign="bottom">1e-06</td><td align="char" char="hyphen" valign="bottom">4.4e-07</td><td align="char" char="hyphen" valign="bottom">1.5e-07</td><td align="char" char="hyphen" valign="bottom">1e-05</td><td align="char" char="hyphen" valign="bottom">5.7e-07</td><td align="char" char="hyphen" valign="bottom">1.8e-07</td><td align="left" valign="bottom"/></tr><tr><td align="left" valign="bottom"><bold>panel: g</bold></td><td align="left" valign="bottom"/><td align="left" valign="bottom"/><td align="left" valign="bottom"/><td align="left" valign="bottom"/><td align="left" valign="bottom"/><td align="left" valign="bottom"/><td align="left" valign="bottom"/></tr><tr><td align="left" valign="bottom">regular</td><td align="left" valign="bottom">jitter: 0</td><td align="char" char="." valign="bottom">5</td><td align="char" char="." valign="bottom">10</td><td align="char" char="." valign="bottom">20</td><td align="char" char="." valign="bottom">30</td><td align="char" char="." valign="bottom">40</td><td align="left" valign="bottom"/></tr><tr><td align="char" char="." valign="bottom">0.0001</td><td align="char" char="hyphen" valign="bottom">4e-15</td><td align="char" char="hyphen" valign="bottom">3.9e-15</td><td align="char" char="hyphen" valign="bottom">1e-13</td><td align="char" char="hyphen" valign="bottom">3.4e-11</td><td align="char" char="hyphen" valign="bottom">1.5e-11</td><td align="char" char="hyphen" valign="bottom">2.4e-06</td><td align="left" valign="bottom"/></tr><tr><td align="left" valign="bottom"><bold>panel: k</bold></td><td align="left" valign="bottom"/><td align="left" valign="bottom"/><td align="left" valign="bottom"/><td align="left" valign="bottom"/><td align="left" valign="bottom"/><td align="left" valign="bottom"/><td align="left" valign="bottom"/></tr><tr><td align="left" valign="bottom">rat1 day1</td><td align="left" valign="bottom">rat1 day2</td><td align="left" valign="bottom">rat2 day1</td><td align="left" valign="bottom">rat2 day2</td><td align="left" valign="bottom">rat3 day1</td><td align="left" valign="bottom">rat3 day2</td><td align="left" valign="bottom">rat4 day1</td><td align="left" valign="bottom">rat4 day2</td></tr><tr><td align="char" char="hyphen" valign="bottom">5e-05</td><td align="char" char="hyphen" valign="bottom">2.5e-18</td><td align="char" char="hyphen" valign="bottom">2.5e-05</td><td align="char" char="." valign="bottom">0.0001</td><td align="char" char="hyphen" valign="bottom">2.1e-10</td><td align="char" char="hyphen" valign="bottom">2.8e-07</td><td align="char" char="hyphen" valign="bottom">1.4e-08</td><td align="char" char="hyphen" valign="bottom">2.4e-06</td></tr><tr><td align="left" valign="bottom"><bold>panel: l</bold></td><td align="left" valign="bottom"/><td align="left" valign="bottom"/><td align="left" valign="bottom"/><td align="left" valign="bottom"/><td align="left" valign="bottom"/><td align="left" valign="bottom"/><td align="left" valign="bottom"/></tr><tr><td align="left" valign="bottom">rat1 day1</td><td align="left" valign="bottom">rat1 day2</td><td align="left" valign="bottom">rat2 day1</td><td align="left" valign="bottom">rat2 day2</td><td align="left" valign="bottom">rat3 day1</td><td align="left" valign="bottom">rat3 day2</td><td align="left" valign="bottom">rat4 day1</td><td align="left" valign="bottom">rat4 day2</td></tr><tr><td align="char" char="." valign="bottom">&lt;0.001</td><td align="char" char="." valign="bottom">&lt;0.001</td><td align="char" char="." valign="bottom">&lt;0.001</td><td align="char" char="." valign="bottom">&lt;0.001</td><td align="char" char="." valign="bottom">&lt;0.001</td><td align="char" char="." valign="bottom">&lt;0.001</td><td align="char" char="." valign="bottom">&lt;0.001</td><td align="char" char="." valign="bottom">&lt;0.001</td></tr></tbody></table></table-wrap><table-wrap id="table4" position="float"><label>Table 4.</label><caption><title>p-Values associated with <xref ref-type="fig" rid="fig6s1">Figure 6—figure supplement 1</xref>.</title><p>p-Values for panels e,f and j were calculated using a one sample t-test. p-Values for panel k were estimated by bootstrapping.</p></caption><table frame="hsides" rules="groups"><tbody><tr><td align="left" valign="bottom"><bold>Panel: e</bold></td><td align="left" valign="bottom"/><td align="left" valign="bottom"/><td align="left" valign="bottom"/><td align="left" valign="bottom"/><td align="left" valign="bottom"/><td align="left" valign="bottom"/><td align="left" valign="bottom"/></tr><tr><td align="left" valign="bottom">regular</td><td align="left" valign="bottom">jitter: 0</td><td align="char" char="." valign="bottom">5</td><td align="char" char="." valign="bottom">10</td><td align="char" char="." valign="bottom">20</td><td align="char" char="." valign="bottom">30</td><td align="char" char="." valign="bottom">40</td><td align="left" valign="bottom"/></tr><tr><td align="char" char="hyphen" valign="bottom">1.8e-05</td><td align="char" char="hyphen" valign="bottom">1.4e-05</td><td align="char" char="hyphen" valign="bottom">9e-05</td><td align="char" char="hyphen" valign="bottom">4.8e-05</td><td align="char" char="." valign="bottom">0.0016</td><td align="char" char="." valign="bottom">0.0025</td><td align="char" char="." valign="bottom">0.0006</td><td align="left" valign="bottom"/></tr><tr><td align="left" valign="bottom"><bold>panel: f</bold></td><td align="left" valign="bottom"/><td align="left" valign="bottom"/><td align="left" valign="bottom"/><td align="left" valign="bottom"/><td align="left" valign="bottom"/><td align="left" valign="bottom"/><td align="left" valign="bottom"/></tr><tr><td align="left" valign="bottom">regular</td><td align="left" valign="bottom">jitter: 0</td><td align="char" char="." valign="bottom">5</td><td align="char" char="." valign="bottom">10</td><td align="char" char="." valign="bottom">20</td><td align="char" char="." valign="bottom">30</td><td align="char" char="." valign="bottom">40</td><td align="left" valign="bottom"/></tr><tr><td align="char" char="." valign="bottom">0.01</td><td align="char" char="hyphen" valign="bottom">4e-05</td><td align="char" char="hyphen" valign="bottom">7e-05</td><td align="char" char="." valign="bottom">0.0007</td><td align="char" char="." valign="bottom">0.0006</td><td align="char" char="." valign="bottom">0.014</td><td align="char" char="." valign="bottom">0.16</td><td align="left" valign="bottom"/></tr><tr><td align="left" valign="bottom"><bold>panel: j</bold></td><td align="left" valign="bottom"/><td align="left" valign="bottom"/><td align="left" valign="bottom"/><td align="left" valign="bottom"/><td align="left" valign="bottom"/><td align="left" valign="bottom"/><td align="left" valign="bottom"/></tr><tr><td align="left" valign="bottom">rat1 day1</td><td align="left" valign="bottom">rat1 day2</td><td align="left" valign="bottom">rat2 day1</td><td align="left" valign="bottom">rat2 day2</td><td align="left" valign="bottom">rat3 day1</td><td align="left" valign="bottom">rat3 day2</td><td align="left" valign="bottom">rat4 day1</td><td align="left" valign="bottom">rat4 day2</td></tr><tr><td align="char" char="." valign="bottom">0.0018</td><td align="char" char="hyphen" valign="bottom">4.5e-09</td><td align="char" char="hyphen" valign="bottom">6e-08</td><td align="char" char="hyphen" valign="bottom">4.9e-07</td><td align="char" char="hyphen" valign="bottom">3.7e-19</td><td align="char" char="hyphen" valign="bottom">4e-11</td><td align="char" char="hyphen" valign="bottom">3.3e-25</td><td align="char" char="hyphen" valign="bottom">2.4e-07</td></tr><tr><td align="left" valign="bottom"><bold>panel: k</bold></td><td align="left" valign="bottom"/><td align="left" valign="bottom"/><td align="left" valign="bottom"/><td align="left" valign="bottom"/><td align="left" valign="bottom"/><td align="left" valign="bottom"/><td align="left" valign="bottom"/></tr><tr><td align="left" valign="bottom">rat1 day1</td><td align="left" valign="bottom">rat1 day2</td><td align="left" valign="bottom">rat2 day1</td><td align="left" valign="bottom">rat2 day2</td><td align="left" valign="bottom">rat3 day1</td><td align="left" valign="bottom">rat3 day2</td><td align="left" valign="bottom">rat4 day1</td><td align="left" valign="bottom">rat4 day2</td></tr><tr><td align="char" char="." valign="bottom">&lt;0.001</td><td align="char" char="." valign="bottom">&lt;0.001</td><td align="char" char="." valign="bottom">&lt;0.001</td><td align="char" char="." valign="bottom">&lt;0.001</td><td align="char" char="." valign="bottom">&lt;0.001</td><td align="char" char="." valign="bottom">&lt;0.001</td><td align="char" char="." valign="bottom">&lt;0.001</td><td align="char" char="." valign="bottom">&lt;0.001</td></tr></tbody></table></table-wrap></sec></sec><sec id="s4-4"><title>Data analysis</title><sec id="s4-4-1"><title>Processing experimental data</title><p>To test the predictions of the theory, we analysed the dataset recorded by <xref ref-type="bibr" rid="bib42">Pfeiffer and Foster, 2013</xref>. In short, rats were required to collect food reward from one of the 36 uniformly distributed food wells alternating between random forging and spatial memory task. The rat’s position and head direction were determined via two distinctly colored, head-mounted LEDs recorded by an overhead video camera and digitized at 30 Hz. Neural activity was recorded by 40 independently adjustable tetrodes targeting the left and the right hippocampi. Local field potential (LFP) was recorded on one representative electrode, digitally filtered between 0.1 and 500 Hz and recorded at 3,255 Hz. Individual units were identified by manual clustering based on spike waveform peak amplitudes based on the signals digitalized at 32,556 Hz as in <xref ref-type="bibr" rid="bib42">Pfeiffer and Foster, 2013</xref>.</p><p>The raw position signal was filtered with a 250ms Gaussian kernel and instantaneous speed and motion direction was calculated from the smooth position signal. We restricted the analysis to run periods with <inline-formula><mml:math id="inf236"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>v</mml:mi><mml:mo>&gt;</mml:mo><mml:mn>5</mml:mn></mml:mrow></mml:mstyle></mml:math></inline-formula> cm/s for at least 1 s separated by stops with duration of <inline-formula><mml:math id="inf237"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>δ</mml:mi><mml:mi>t</mml:mi><mml:mo>&gt;</mml:mo><mml:mn>0.2</mml:mn></mml:mrow></mml:mstyle></mml:math></inline-formula> s. In this study we included only putative excitatory neurons on the basis of spike width and mean firing rate (<xref ref-type="bibr" rid="bib42">Pfeiffer and Foster, 2013</xref>) with at least 200 spikes during the analysed run epochs. Position was binned (5 cm) and spatial occupancy map was calculated as the smoothed (10 cm Gaussian kernel) histogram of the time spent in each bin. Position tuning curves (ratemaps, <inline-formula><mml:math id="inf238"><mml:mrow><mml:mi>ψ</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>x</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula>) were calculated as the smoothed (10 cm Gaussian kernel) histogram of firing activity normalized by the occupancy map and we used <inline-formula><mml:math id="inf239"><mml:mrow><mml:msub><mml:mi>ψ</mml:mi><mml:mtext>min</mml:mtext></mml:msub><mml:mo>=</mml:mo><mml:mn>0.1</mml:mn></mml:mrow></mml:math></inline-formula> Hz wherever <inline-formula><mml:math id="inf240"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>ψ</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>x</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>&lt;</mml:mo><mml:mn>0.1</mml:mn></mml:mrow></mml:mstyle></mml:math></inline-formula> Hz.</p><p>Theta phase was calculated by applying Hilbert transformation on band pass filtered (4–12 Hz) LFP signal. To find the starting phase of the theta sequences in each animal, we calculated the forward bias by decoding spikes using 120° windows advanced in 45° increments (<xref ref-type="fig" rid="fig4">Figure 4h</xref>). The forward (lateral) bias of the decoder was defined as the average of the error between the decoded and the actual position of the animal parallel (perpendicular) to the motion direction of the animal. Theta start was defined as 135° after the peak of the cosine function (<xref ref-type="fig" rid="fig4">Figure 4f</xref>) fitted to the forward bias. We used two complementary strategies to avoid biases related to systemic changes in the firing rate during decoding: (1) When analysing early, mid and late theta phases, we divided each theta cycle into three periods of equal spike count. (2) When calculating decoding spread, we subsampled the data in order to match the distribution of spike counts across theta phases. The decoding spread was defined as <inline-formula><mml:math id="inf241"><mml:mrow><mml:mo>det</mml:mo><mml:mo>⁡</mml:mo><mml:msup><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi mathvariant="normal">Σ</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mrow><mml:mn>1</mml:mn><mml:mo>/</mml:mo><mml:mn>4</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:math></inline-formula> where <inline-formula><mml:math id="inf242"><mml:mi mathvariant="normal">Σ</mml:mi></mml:math></inline-formula> is the covariance matrix of the decoded positions.</p><p>To calculate the theta phase dependence of the place field size (<xref ref-type="fig" rid="fig2">Figure 2e</xref>) we estimated the place fields in the three theta phase (early, mid and late) using the position of the rat shifted in time with <inline-formula><mml:math id="inf243"><mml:mrow><mml:mi mathvariant="normal">Δ</mml:mi><mml:mo>⁢</mml:mo><mml:mi>t</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>φ</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> that minimized the median error between the decoded and temporally shifted position in that session (<xref ref-type="fig" rid="fig2">Figure 2d</xref>). Similarly, when we calculated trajectory encoding error, we compared the decoded position in each phase bin to the real position shifted in time with the same <inline-formula><mml:math id="inf244"><mml:mrow><mml:mi mathvariant="normal">Δ</mml:mi><mml:mo>⁢</mml:mo><mml:mi>t</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>φ</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula>.</p><p>To compare place fields between home and away conditions, we first estimated separately the neuronal tuning curves for the two trial types. Home trials where the rat did not reach the goal location within 100 s were excluded from the analysis and we only included neurons with average firing rate higher than 0.1 Hz. We z-scored each tuning curve using the mean and variance of the tuning curve estimated from all trials. This step allowed us to compare changes in the tuning curves across cells (see below).</p><p>Next, we compared the normalized tuning curve changes between the home and away trials (<inline-formula><mml:math id="inf245"><mml:msub><mml:mi>δ</mml:mi><mml:mrow><mml:mi>H</mml:mi><mml:mo>-</mml:mo><mml:mi>A</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula>) to two different controls. First, we randomly split the data into trials of two types 100 times and estimated normalized tuning curves from the random splits. This provided a baseline measure of the tuning curve change <inline-formula><mml:math id="inf246"><mml:msub><mml:mi>δ</mml:mi><mml:mtext>shuffle</mml:mtext></mml:msub></mml:math></inline-formula>. Second, we obtained an upper bound on the expected tuning curve changes by comparing normalized home and away tuning curves of different neurons, <inline-formula><mml:math id="inf247"><mml:msub><mml:mi>δ</mml:mi><mml:mtext>indep</mml:mtext></mml:msub></mml:math></inline-formula>. Neurons with the average difference between the tuning curves across random splits of the data larger than the average difference across cells (<inline-formula><mml:math id="inf248"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mrow><mml:mi mathvariant="double-struck">E</mml:mi></mml:mrow><mml:mo stretchy="false">[</mml:mo><mml:msub><mml:mi>δ</mml:mi><mml:mrow><mml:mrow><mml:mi mathvariant="normal">s</mml:mi><mml:mi mathvariant="normal">h</mml:mi><mml:mi mathvariant="normal">u</mml:mi><mml:mi mathvariant="normal">f</mml:mi><mml:mi mathvariant="normal">f</mml:mi><mml:mi mathvariant="normal">l</mml:mi><mml:mi mathvariant="normal">e</mml:mi></mml:mrow></mml:mrow></mml:msub><mml:mo stretchy="false">]</mml:mo><mml:mo>&gt;</mml:mo><mml:mrow><mml:mi mathvariant="double-struck">E</mml:mi></mml:mrow><mml:mo stretchy="false">[</mml:mo><mml:msub><mml:mi>δ</mml:mi><mml:mrow><mml:mrow><mml:mi mathvariant="normal">i</mml:mi><mml:mi mathvariant="normal">n</mml:mi><mml:mi mathvariant="normal">d</mml:mi><mml:mi mathvariant="normal">e</mml:mi><mml:mi mathvariant="normal">p</mml:mi></mml:mrow></mml:mrow></mml:msub><mml:mo stretchy="false">]</mml:mo></mml:mrow></mml:mstyle></mml:math></inline-formula>) were considered unreliable and were excluded from further analysis. <xref ref-type="fig" rid="fig6s2">Figure 6—figure supplement 2</xref> shows the proportion of cells in each recording session where <inline-formula><mml:math id="inf249"><mml:msub><mml:mi>δ</mml:mi><mml:mrow><mml:mi>H</mml:mi><mml:mo>-</mml:mo><mml:mi>A</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> was larger than the 95% of distribution of <inline-formula><mml:math id="inf250"><mml:msub><mml:mi>δ</mml:mi><mml:mtext>shuffle</mml:mtext></mml:msub></mml:math></inline-formula>, the difference between random splits of the data. To quantify the magnitude of remapping between home and away trials, we calculated the remapping index:<disp-formula id="equ35"><label>(34)</label><mml:math id="m35"><mml:mrow><mml:mtext>RI</mml:mtext><mml:mo>=</mml:mo><mml:mrow><mml:mrow><mml:mrow><mml:mo maxsize="120%" minsize="120%">(</mml:mo><mml:mrow><mml:msub><mml:mi>δ</mml:mi><mml:mrow><mml:mi>H</mml:mi><mml:mo>-</mml:mo><mml:mi>A</mml:mi></mml:mrow></mml:msub><mml:mo>-</mml:mo><mml:mrow><mml:mi>E</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">[</mml:mo><mml:msub><mml:mi>δ</mml:mi><mml:mtext>shuffle</mml:mtext></mml:msub><mml:mo stretchy="false">]</mml:mo></mml:mrow></mml:mrow></mml:mrow><mml:mo maxsize="120%" minsize="120%">)</mml:mo></mml:mrow><mml:mo>/</mml:mo><mml:mi>E</mml:mi></mml:mrow><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">[</mml:mo><mml:msub><mml:mi>δ</mml:mi><mml:mtext>indep</mml:mtext></mml:msub><mml:mo stretchy="false">]</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:math></disp-formula></p><p>which is 0 when the observed difference between home and away tuning curves (<inline-formula><mml:math id="inf251"><mml:msub><mml:mi>δ</mml:mi><mml:mrow><mml:mi>H</mml:mi><mml:mo>-</mml:mo><mml:mi>A</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula>) equals the mean tuning curve change in the shuffle control (<inline-formula><mml:math id="inf252"><mml:mrow><mml:mi>E</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">[</mml:mo><mml:msub><mml:mi>δ</mml:mi><mml:mtext>shuffle</mml:mtext></mml:msub><mml:mo stretchy="false">]</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula>) and is 1 when the magnitude of tuning curve change is similar to the difference between the tuning curves of independent neurons (<inline-formula><mml:math id="inf253"><mml:mrow><mml:mi>E</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">[</mml:mo><mml:msub><mml:mi>δ</mml:mi><mml:mtext>indep</mml:mtext></mml:msub><mml:mo stretchy="false">]</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula>).</p></sec><sec id="s4-4-2"><title>Processing synthetic data</title><p>We simulated the movement of the animal using <xref ref-type="disp-formula" rid="equ1 equ2 equ3 equ4 equ5 equ6 equ7">Equations 1–7</xref> in a <inline-formula><mml:math id="inf254"><mml:mrow><mml:mn>2</mml:mn><mml:mo>×</mml:mo><mml:mn>2</mml:mn></mml:mrow></mml:math></inline-formula> m open arena, except for <xref ref-type="fig" rid="fig3">Figure 3d, e</xref>, where we used a <inline-formula><mml:math id="inf255"><mml:mrow><mml:mn>2</mml:mn><mml:mo>×</mml:mo><mml:mn>0.1</mml:mn></mml:mrow></mml:math></inline-formula> m long linear track. We used the same procedure to analyse the synthetic data as we applied to the experimental data: we filtered the raw position signal, calculated the speed and motion direction and estimated the spatial occupancy maps and position tuning curves from the generated spikes. Importantly, we used these estimated tuning curves and not the true, noiseless encoding basis functions for decoding position from spikes in the synthetic data. In our model, each theta cycle was 100ms long (but also see an alternative variant below) and the encoded trajectory spanned 2 s centered on the current position of the animal (<italic>regular</italic> theta sequences).</p><p>To test the robustness of the EV-index to variations across theta cycles (<xref ref-type="fig" rid="fig6">Figure 6f, g</xref>), we added variability to the theta cycles in two different ways: First, the duration and the content of each theta cycle was varied stochastically. Specifically, for the simulations using <italic>irregular</italic> theta sequences in <xref ref-type="fig" rid="fig6">Figure 6f, g</xref>, we varied the duration of each theta cycle (80–160 ms) together with the total length of the encoded trajectory (1–3 s) with constraining the encoded trajectory to start in the past and end in the future. Second, a uniformly distributed random jitter (0–40 ms) was added to the true time of the theta cycle boundaries before binning the spikes according to their theta phase.</p></sec></sec></sec></body><back><sec sec-type="additional-information" id="s5"><title>Additional information</title><fn-group content-type="competing-interest"><title>Competing interests</title><fn fn-type="COI-statement" id="conf1"><p>No competing interests declared</p></fn></fn-group><fn-group content-type="author-contribution"><title>Author contributions</title><fn fn-type="con" id="con1"><p>Conceptualization, Data curation, Formal analysis, Funding acquisition, Writing – original draft</p></fn><fn fn-type="con" id="con2"><p>Conceptualization, Funding acquisition, Writing – original draft</p></fn></fn-group></sec><sec sec-type="supplementary-material" id="s6"><title>Additional files</title><supplementary-material id="transrepform"><label>Transparent reporting form</label><media xlink:href="elife-74058-transrepform1-v1.pdf" mimetype="application" mime-subtype="pdf"/></supplementary-material></sec><sec sec-type="data-availability" id="s7"><title>Data availability</title><p>The current manuscript is a computational study, so no data have been generated for this manuscript. The (R) code and parameters for the simulations and analysis are available at <ext-link ext-link-type="uri" xlink:href="https://github.com/bbujfalussy/tSeq">https://github.com/bbujfalussy/tSeq</ext-link> (copy archived at <ext-link ext-link-type="uri" xlink:href="https://archive.softwareheritage.org/swh:1:dir:9477487b28fcc311b706d51943b609baf0f9d589;origin=https://github.com/bbujfalussy/tSeq;visit=swh:1:snp:2a7cf19c0df97b1bc3499579e14039b11e68c67a;anchor=swh:1:rev:6d131540ba45e56b46f07aba1d0cc211114d0a6d">swh:1:rev:6d131540ba45e56b46f07aba1d0cc211114d0a6d</ext-link>).</p><p>The following previously published dataset was used:</p><p><element-citation publication-type="data" specific-use="references" id="dataset1"><person-group person-group-type="author"><name><surname>Grosmark</surname><given-names>AD</given-names></name><name><surname>Long</surname><given-names>J</given-names></name><name><surname>Buzsáki</surname><given-names>G</given-names></name></person-group><year iso-8601-date="2016">2016</year><data-title>Recordings from hippocampal area CA1, PRE, during and POST novel spatial learning</data-title><source>Collaborative Research in Computational Neuroscience</source><pub-id pub-id-type="doi">10.6080/K0862DC5</pub-id></element-citation></p></sec><ack id="ack"><title>Acknowledgements</title><p>We thank Brad E Pfeiffer and David J Foster for kindly sharing their data and Andres D Grosmark and György Buzsáki for making their data publicly available. We thank Márton Kis and Judit K Makara for useful discussions; Mihály Bányai and Judit K Makara for comments on a previous version of the manuscript. This work was supported by an NKFIH fellowship (PD-125386, FK-125324; BBU), by the Hungarian Brain Research Program (2017–1.2.1-NKP-2017–00002, GO and KTIA-NAP-12-2-201, BBU and GO), by the Artificial Intelligence National Laboratory (European Union project RRF-2.3.1-21-2022-00004, GO).</p></ack><ref-list><title>References</title><ref id="bib1"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Beck</surname><given-names>JM</given-names></name><name><surname>Ma</surname><given-names>WJ</given-names></name><name><surname>Pitkow</surname><given-names>X</given-names></name><name><surname>Latham</surname><given-names>PE</given-names></name><name><surname>Pouget</surname><given-names>A</given-names></name></person-group><year iso-8601-date="2012">2012</year><article-title>Not noisy, just wrong: the role of suboptimal inference in behavioral variability</article-title><source>Neuron</source><volume>74</volume><fpage>30</fpage><lpage>39</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2012.03.016</pub-id><pub-id pub-id-type="pmid">22500627</pub-id></element-citation></ref><ref id="bib2"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bieri</surname><given-names>KW</given-names></name><name><surname>Bobbitt</surname><given-names>KN</given-names></name><name><surname>Colgin</surname><given-names>LL</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>Slow and fast γ rhythms coordinate different spatial coding modes in hippocampal place cells</article-title><source>Neuron</source><volume>82</volume><fpage>670</fpage><lpage>681</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2014.03.013</pub-id><pub-id pub-id-type="pmid">24746420</pub-id></element-citation></ref><ref id="bib3"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Buzsáki</surname><given-names>G</given-names></name></person-group><year iso-8601-date="2005">2005</year><article-title>Theta rhythm of navigation: link between path integration and landmark navigation, episodic and semantic memory</article-title><source>Hippocampus</source><volume>15</volume><fpage>827</fpage><lpage>840</lpage><pub-id pub-id-type="doi">10.1002/hipo.20113</pub-id><pub-id pub-id-type="pmid">16149082</pub-id></element-citation></ref><ref id="bib4"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Cei</surname><given-names>A</given-names></name><name><surname>Girardeau</surname><given-names>G</given-names></name><name><surname>Drieu</surname><given-names>C</given-names></name><name><surname>Kanbi</surname><given-names>KE</given-names></name><name><surname>Zugaro</surname><given-names>M</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>Reversed theta sequences of hippocampal cell assemblies during backward travel</article-title><source>Nature Neuroscience</source><volume>17</volume><fpage>719</fpage><lpage>724</lpage><pub-id pub-id-type="doi">10.1038/nn.3698</pub-id><pub-id pub-id-type="pmid">24667574</pub-id></element-citation></ref><ref id="bib5"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Chadwick</surname><given-names>A</given-names></name><name><surname>van Rossum</surname><given-names>MCW</given-names></name><name><surname>Nolan</surname><given-names>MF</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>Independent theta phase coding accounts for CA1 population sequences and enables flexible remapping</article-title><source>eLife</source><volume>4</volume><elocation-id>e03542</elocation-id><pub-id pub-id-type="doi">10.7554/eLife.03542</pub-id><pub-id pub-id-type="pmid">25643396</pub-id></element-citation></ref><ref id="bib6"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Colgin</surname><given-names>LL</given-names></name><name><surname>Denninger</surname><given-names>T</given-names></name><name><surname>Fyhn</surname><given-names>M</given-names></name><name><surname>Hafting</surname><given-names>T</given-names></name><name><surname>Bonnevie</surname><given-names>T</given-names></name><name><surname>Jensen</surname><given-names>O</given-names></name><name><surname>Moser</surname><given-names>MB</given-names></name><name><surname>Moser</surname><given-names>EI</given-names></name></person-group><year iso-8601-date="2009">2009</year><article-title>Frequency of gamma oscillations routes flow of information in the hippocampus</article-title><source>Nature</source><volume>462</volume><fpage>353</fpage><lpage>357</lpage><pub-id pub-id-type="doi">10.1038/nature08573</pub-id><pub-id pub-id-type="pmid">19924214</pub-id></element-citation></ref><ref id="bib7"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Colgin</surname><given-names>LL</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Rhythms of the hippocampal network</article-title><source>Nature Reviews. Neuroscience</source><volume>17</volume><fpage>239</fpage><lpage>249</lpage><pub-id pub-id-type="doi">10.1038/nrn.2016.21</pub-id><pub-id pub-id-type="pmid">26961163</pub-id></element-citation></ref><ref id="bib8"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Davidson</surname><given-names>TJ</given-names></name><name><surname>Kloosterman</surname><given-names>F</given-names></name><name><surname>Wilson</surname><given-names>MA</given-names></name></person-group><year iso-8601-date="2009">2009</year><article-title>Hippocampal replay of extended experience</article-title><source>Neuron</source><volume>63</volume><fpage>497</fpage><lpage>507</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2009.07.027</pub-id><pub-id pub-id-type="pmid">19709631</pub-id></element-citation></ref><ref id="bib9"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Dayan</surname><given-names>P</given-names></name></person-group><year iso-8601-date="1993">1993</year><article-title>Improving generalization for temporal difference learning: the successor representation</article-title><source>Neural Computation</source><volume>5</volume><fpage>613</fpage><lpage>624</lpage><pub-id pub-id-type="doi">10.1162/neco.1993.5.4.613</pub-id></element-citation></ref><ref id="bib10"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Dayan</surname><given-names>P</given-names></name><name><surname>Abbott</surname><given-names>LF</given-names></name></person-group><year iso-8601-date="2001">2001</year><source>Theoretical Neuroscience</source><publisher-name>The MIT press</publisher-name></element-citation></ref><ref id="bib11"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Echeveste</surname><given-names>R</given-names></name><name><surname>Aitchison</surname><given-names>L</given-names></name><name><surname>Hennequin</surname><given-names>G</given-names></name><name><surname>Lengyel</surname><given-names>M</given-names></name></person-group><year iso-8601-date="2020">2020</year><article-title>Cortical-like dynamics in recurrent circuits optimized for sampling-based probabilistic inference</article-title><source>Nature Neuroscience</source><volume>23</volume><fpage>1138</fpage><lpage>1149</lpage><pub-id pub-id-type="doi">10.1038/s41593-020-0671-1</pub-id><pub-id pub-id-type="pmid">32778794</pub-id></element-citation></ref><ref id="bib12"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Fenton</surname><given-names>AA</given-names></name><name><surname>Muller</surname><given-names>RU</given-names></name></person-group><year iso-8601-date="1998">1998</year><article-title>Place cell discharge is extremely variable during individual passes of the rat through the firing field</article-title><source>PNAS</source><volume>95</volume><fpage>3182</fpage><lpage>3187</lpage><pub-id pub-id-type="doi">10.1073/pnas.95.6.3182</pub-id><pub-id pub-id-type="pmid">9501237</pub-id></element-citation></ref><ref id="bib13"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Fernández-Ruiz</surname><given-names>A</given-names></name><name><surname>Oliva</surname><given-names>A</given-names></name><name><surname>Nagy</surname><given-names>GA</given-names></name><name><surname>Maurer</surname><given-names>AP</given-names></name><name><surname>Berényi</surname><given-names>A</given-names></name><name><surname>Buzsáki</surname><given-names>G</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>Entorhinal-CA3 dual-input control of spike timing in the hippocampus by theta-gamma coupling</article-title><source>Neuron</source><volume>93</volume><fpage>1213</fpage><lpage>1226</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2017.02.017</pub-id><pub-id pub-id-type="pmid">28279355</pub-id></element-citation></ref><ref id="bib14"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Fiser</surname><given-names>J</given-names></name><name><surname>Berkes</surname><given-names>P</given-names></name><name><surname>Orbán</surname><given-names>G</given-names></name><name><surname>Lengyel</surname><given-names>M</given-names></name></person-group><year iso-8601-date="2010">2010</year><article-title>Statistically optimal perception and learning: from behavior to neural representations</article-title><source>Trends in Cognitive Sciences</source><volume>14</volume><fpage>119</fpage><lpage>130</lpage><pub-id pub-id-type="doi">10.1016/j.tics.2010.01.003</pub-id><pub-id pub-id-type="pmid">20153683</pub-id></element-citation></ref><ref id="bib15"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Foster</surname><given-names>DJ</given-names></name><name><surname>Wilson</surname><given-names>MA</given-names></name></person-group><year iso-8601-date="2007">2007</year><article-title>Hippocampal theta sequences</article-title><source>Hippocampus</source><volume>17</volume><fpage>1093</fpage><lpage>1099</lpage><pub-id pub-id-type="doi">10.1002/hipo.20345</pub-id><pub-id pub-id-type="pmid">17663452</pub-id></element-citation></ref><ref id="bib16"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Frank</surname><given-names>LM</given-names></name><name><surname>Brown</surname><given-names>EN</given-names></name><name><surname>Wilson</surname><given-names>M</given-names></name></person-group><year iso-8601-date="2000">2000</year><article-title>Trajectory encoding in the hippocampus and entorhinal cortex</article-title><source>Neuron</source><volume>27</volume><fpage>169</fpage><lpage>178</lpage><pub-id pub-id-type="doi">10.1016/s0896-6273(00)00018-0</pub-id><pub-id pub-id-type="pmid">10939340</pub-id></element-citation></ref><ref id="bib17"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Glimcher</surname><given-names>PW</given-names></name></person-group><year iso-8601-date="2003">2003</year><source>Decisions, Uncertainty, and the Brain</source><publisher-name>MIT Press</publisher-name><pub-id pub-id-type="doi">10.7551/mitpress/2302.001.0001</pub-id></element-citation></ref><ref id="bib18"><element-citation publication-type="data"><person-group person-group-type="author"><name><surname>Grosmark</surname><given-names>A</given-names></name><name><surname>Long</surname><given-names>J</given-names></name><name><surname>Buzsáki</surname><given-names>G</given-names></name></person-group><year iso-8601-date="2016">2016</year><data-title>Recordings from hippocampal area CA1, PRE, during and POST novel spatial learning</data-title><source>Collaborative Research in Computational Neuroscience</source><pub-id pub-id-type="doi">10.6080/K0862DC5</pub-id></element-citation></ref><ref id="bib19"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Gupta</surname><given-names>AS</given-names></name><name><surname>van der Meer</surname><given-names>MAA</given-names></name><name><surname>Touretzky</surname><given-names>DS</given-names></name><name><surname>Redish</surname><given-names>AD</given-names></name></person-group><year iso-8601-date="2012">2012</year><article-title>Segmentation of spatial experience by hippocampal θ sequences</article-title><source>Nature Neuroscience</source><volume>15</volume><fpage>1032</fpage><lpage>1039</lpage><pub-id pub-id-type="doi">10.1038/nn.3138</pub-id><pub-id pub-id-type="pmid">22706269</pub-id></element-citation></ref><ref id="bib20"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hunt</surname><given-names>LT</given-names></name><name><surname>Daw</surname><given-names>ND</given-names></name><name><surname>Kaanders</surname><given-names>P</given-names></name><name><surname>MacIver</surname><given-names>MA</given-names></name><name><surname>Mugan</surname><given-names>U</given-names></name><name><surname>Procyk</surname><given-names>E</given-names></name><name><surname>Redish</surname><given-names>AD</given-names></name><name><surname>Russo</surname><given-names>E</given-names></name><name><surname>Scholl</surname><given-names>J</given-names></name><name><surname>Stachenfeld</surname><given-names>K</given-names></name><name><surname>Wilson</surname><given-names>CRE</given-names></name><name><surname>Kolling</surname><given-names>N</given-names></name></person-group><year iso-8601-date="2021">2021</year><article-title>Formalizing planning and information search in naturalistic decision-making</article-title><source>Nature Neuroscience</source><volume>24</volume><fpage>1051</fpage><lpage>1064</lpage><pub-id pub-id-type="doi">10.1038/s41593-021-00866-w</pub-id><pub-id pub-id-type="pmid">34155400</pub-id></element-citation></ref><ref id="bib21"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Jezek</surname><given-names>K</given-names></name><name><surname>Henriksen</surname><given-names>EJ</given-names></name><name><surname>Treves</surname><given-names>A</given-names></name><name><surname>Moser</surname><given-names>EI</given-names></name><name><surname>Moser</surname><given-names>M-B</given-names></name></person-group><year iso-8601-date="2011">2011</year><article-title>Theta-paced flickering between place-cell maps in the hippocampus</article-title><source>Nature</source><volume>478</volume><fpage>246</fpage><lpage>249</lpage><pub-id pub-id-type="doi">10.1038/nature10439</pub-id><pub-id pub-id-type="pmid">21964339</pub-id></element-citation></ref><ref id="bib22"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Johnson</surname><given-names>A</given-names></name><name><surname>Redish</surname><given-names>AD</given-names></name></person-group><year iso-8601-date="2005">2005</year><article-title>Hippocampal replay contributes to within session learning in a temporal difference reinforcement learning model</article-title><source>Neural Networks</source><volume>18</volume><fpage>1163</fpage><lpage>1171</lpage><pub-id pub-id-type="doi">10.1016/j.neunet.2005.08.009</pub-id><pub-id pub-id-type="pmid">16198539</pub-id></element-citation></ref><ref id="bib23"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Johnson</surname><given-names>A</given-names></name><name><surname>Redish</surname><given-names>AD</given-names></name></person-group><year iso-8601-date="2007">2007</year><article-title>Neural ensembles in CA3 transiently encode paths forward of the animal at a decision point</article-title><source>The Journal of Neuroscience</source><volume>27</volume><fpage>12176</fpage><lpage>12189</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.3761-07.2007</pub-id><pub-id pub-id-type="pmid">17989284</pub-id></element-citation></ref><ref id="bib24"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kao</surname><given-names>TC</given-names></name><name><surname>Sadabadi</surname><given-names>MS</given-names></name><name><surname>Hennequin</surname><given-names>G</given-names></name></person-group><year iso-8601-date="2021">2021</year><article-title>Optimal anticipatory control as a theory of motor preparation: a thalamo-cortical circuit model</article-title><source>Neuron</source><volume>109</volume><fpage>1567</fpage><lpage>1581</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2021.03.009</pub-id><pub-id pub-id-type="pmid">33789082</pub-id></element-citation></ref><ref id="bib25"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kay</surname><given-names>K</given-names></name><name><surname>Chung</surname><given-names>JE</given-names></name><name><surname>Sosa</surname><given-names>M</given-names></name><name><surname>Schor</surname><given-names>JS</given-names></name><name><surname>Karlsson</surname><given-names>MP</given-names></name><name><surname>Larkin</surname><given-names>MC</given-names></name><name><surname>Liu</surname><given-names>DF</given-names></name><name><surname>Frank</surname><given-names>LM</given-names></name></person-group><year iso-8601-date="2020">2020</year><article-title>Constant sub-second cycling between representations of possible futures in the hippocampus</article-title><source>Cell</source><volume>180</volume><fpage>552</fpage><lpage>567</lpage><pub-id pub-id-type="doi">10.1016/j.cell.2020.01.014</pub-id><pub-id pub-id-type="pmid">32004462</pub-id></element-citation></ref><ref id="bib26"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kelemen</surname><given-names>E</given-names></name><name><surname>Fenton</surname><given-names>AA</given-names></name></person-group><year iso-8601-date="2010">2010</year><article-title>Dynamic grouping of hippocampal neural activity during cognitive control of two spatial frames</article-title><source>PLOS Biology</source><volume>8</volume><elocation-id>e1000403</elocation-id><pub-id pub-id-type="doi">10.1371/journal.pbio.1000403</pub-id><pub-id pub-id-type="pmid">20585373</pub-id></element-citation></ref><ref id="bib27"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kutschireiter</surname><given-names>A</given-names></name><name><surname>Surace</surname><given-names>SC</given-names></name><name><surname>Sprekeler</surname><given-names>H</given-names></name><name><surname>Pfister</surname><given-names>JP</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>Nonlinear Bayesian filtering and learning: a neuronal dynamics for perception</article-title><source>Scientific Reports</source><volume>7</volume><elocation-id>8722</elocation-id><pub-id pub-id-type="doi">10.1038/s41598-017-06519-y</pub-id><pub-id pub-id-type="pmid">28821729</pub-id></element-citation></ref><ref id="bib28"><element-citation publication-type="preprint"><person-group person-group-type="author"><name><surname>Lange</surname><given-names>RD</given-names></name><name><surname>Shivkumar</surname><given-names>S</given-names></name><name><surname>Chattoraj</surname><given-names>A</given-names></name><name><surname>Haefner</surname><given-names>RM</given-names></name></person-group><year iso-8601-date="2020">2020</year><article-title>Bayesian Encoding and Decoding as Distinct Perspectives on Neural Coding</article-title><source>bioRxiv</source><pub-id pub-id-type="doi">10.1101/2020.10.14.339770</pub-id></element-citation></ref><ref id="bib29"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ma</surname><given-names>WJ</given-names></name><name><surname>Beck</surname><given-names>JM</given-names></name><name><surname>Latham</surname><given-names>PE</given-names></name><name><surname>Pouget</surname><given-names>A</given-names></name></person-group><year iso-8601-date="2006">2006</year><article-title>Bayesian inference with probabilistic population codes</article-title><source>Nature Neuroscience</source><volume>9</volume><fpage>1432</fpage><lpage>1438</lpage><pub-id pub-id-type="doi">10.1038/nn1790</pub-id><pub-id pub-id-type="pmid">17057707</pub-id></element-citation></ref><ref id="bib30"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>MacKay</surname><given-names>DJC</given-names></name></person-group><year iso-8601-date="2003">2003</year><source>Information Theory, Inference, and Learning Algorithms</source><publisher-name>Cambridge University Press</publisher-name></element-citation></ref><ref id="bib31"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Mante</surname><given-names>V</given-names></name><name><surname>Sussillo</surname><given-names>D</given-names></name><name><surname>Shenoy</surname><given-names>KV</given-names></name><name><surname>Newsome</surname><given-names>WT</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>Context-Dependent computation by recurrent dynamics in prefrontal cortex</article-title><source>Nature</source><volume>503</volume><fpage>78</fpage><lpage>84</lpage><pub-id pub-id-type="doi">10.1038/nature12742</pub-id><pub-id pub-id-type="pmid">24201281</pub-id></element-citation></ref><ref id="bib32"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Mastrogiuseppe</surname><given-names>F</given-names></name><name><surname>Ostojic</surname><given-names>S</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>Linking connectivity, dynamics, and computations in low-rank recurrent neural networks</article-title><source>Neuron</source><volume>99</volume><fpage>609</fpage><lpage>623</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2018.07.003</pub-id><pub-id pub-id-type="pmid">30057201</pub-id></element-citation></ref><ref id="bib33"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Mattar</surname><given-names>MG</given-names></name><name><surname>Daw</surname><given-names>ND</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>Prioritized memory access explains planning and hippocampal replay</article-title><source>Nature Neuroscience</source><volume>21</volume><fpage>1609</fpage><lpage>1617</lpage><pub-id pub-id-type="doi">10.1038/s41593-018-0232-z</pub-id><pub-id pub-id-type="pmid">30349103</pub-id></element-citation></ref><ref id="bib34"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Mattar</surname><given-names>MG</given-names></name><name><surname>Lengyel</surname><given-names>M</given-names></name></person-group><year iso-8601-date="2022">2022</year><article-title>Planning in the brain</article-title><source>Neuron</source><volume>110</volume><fpage>914</fpage><lpage>934</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2021.12.018</pub-id><pub-id pub-id-type="pmid">35041804</pub-id></element-citation></ref><ref id="bib35"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>McClain</surname><given-names>K</given-names></name><name><surname>Tingley</surname><given-names>D</given-names></name><name><surname>Heeger</surname><given-names>DJ</given-names></name><name><surname>Buzsáki</surname><given-names>G</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>Position-theta-phase model of hippocampal place cell activity applied to quantification of running speed modulation of firing rate</article-title><source>PNAS</source><volume>116</volume><elocation-id>201912792</elocation-id><pub-id pub-id-type="doi">10.1073/pnas.1912792116</pub-id><pub-id pub-id-type="pmid">31843934</pub-id></element-citation></ref><ref id="bib36"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Miller</surname><given-names>KJ</given-names></name><name><surname>Botvinick</surname><given-names>MM</given-names></name><name><surname>Brody</surname><given-names>CD</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>Dorsal hippocampus contributes to model-based planning</article-title><source>Nature Neuroscience</source><volume>20</volume><fpage>1269</fpage><lpage>1276</lpage><pub-id pub-id-type="doi">10.1038/nn.4613</pub-id><pub-id pub-id-type="pmid">28758995</pub-id></element-citation></ref><ref id="bib37"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Murphy</surname><given-names>KP</given-names></name></person-group><year iso-8601-date="2012">2012</year><source>Machine Learning: A Probabilistic Perspective</source><publisher-loc>Cambridge, MA</publisher-loc><publisher-name>MIT Press</publisher-name></element-citation></ref><ref id="bib38"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Murray</surname><given-names>I</given-names></name></person-group><year iso-8601-date="2007">2007</year><source>Advances in Markov Chain Monte Carlo Methods</source><publisher-loc>London, UK</publisher-loc><publisher-name>University College</publisher-name></element-citation></ref><ref id="bib39"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Neftci</surname><given-names>EO</given-names></name><name><surname>Averbeck</surname><given-names>BB</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>Reinforcement learning in artificial and biological systems</article-title><source>Nature Machine Intelligence</source><volume>1</volume><fpage>133</fpage><lpage>143</lpage><pub-id pub-id-type="doi">10.1038/s42256-019-0025-4</pub-id></element-citation></ref><ref id="bib40"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>O’Keefe</surname><given-names>J</given-names></name><name><surname>Nadel</surname><given-names>L</given-names></name></person-group><year iso-8601-date="1978">1978</year><source>The Hippocampus as a Cognitive Map</source><publisher-name>Oxford University Press</publisher-name></element-citation></ref><ref id="bib41"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Orbán</surname><given-names>G</given-names></name><name><surname>Berkes</surname><given-names>P</given-names></name><name><surname>Fiser</surname><given-names>J</given-names></name><name><surname>Lengyel</surname><given-names>M</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Neural variability and sampling-based probabilistic representations in the visual cortex</article-title><source>Neuron</source><volume>92</volume><fpage>530</fpage><lpage>543</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2016.09.038</pub-id><pub-id pub-id-type="pmid">27764674</pub-id></element-citation></ref><ref id="bib42"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Pfeiffer</surname><given-names>BE</given-names></name><name><surname>Foster</surname><given-names>DJ</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>Hippocampal place-cell sequences depict future paths to remembered goals</article-title><source>Nature</source><volume>497</volume><fpage>74</fpage><lpage>79</lpage><pub-id pub-id-type="doi">10.1038/nature12112</pub-id><pub-id pub-id-type="pmid">23594744</pub-id></element-citation></ref><ref id="bib43"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Pfeiffer</surname><given-names>BE</given-names></name></person-group><year iso-8601-date="2022">2022</year><article-title>Spatial learning drives rapid goal representation in hippocampal ripples without place field accumulation or goal-oriented theta sequences</article-title><source>The Journal of Neuroscience</source><volume>42</volume><fpage>3975</fpage><lpage>3988</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.2479-21.2022</pub-id><pub-id pub-id-type="pmid">35396328</pub-id></element-citation></ref><ref id="bib44"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Pouget</surname><given-names>A</given-names></name><name><surname>Beck</surname><given-names>JM</given-names></name><name><surname>Ma</surname><given-names>WJ</given-names></name><name><surname>Latham</surname><given-names>PE</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>Probabilistic brains: knowns and unknowns</article-title><source>Nature Neuroscience</source><volume>16</volume><fpage>1170</fpage><lpage>1178</lpage><pub-id pub-id-type="doi">10.1038/nn.3495</pub-id><pub-id pub-id-type="pmid">23955561</pub-id></element-citation></ref><ref id="bib45"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Redish</surname><given-names>AD</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Vicarious trial and error</article-title><source>Nature Reviews. Neuroscience</source><volume>17</volume><fpage>147</fpage><lpage>159</lpage><pub-id pub-id-type="doi">10.1038/nrn.2015.30</pub-id><pub-id pub-id-type="pmid">26891625</pub-id></element-citation></ref><ref id="bib46"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Rich</surname><given-names>PD</given-names></name><name><surname>Liaw</surname><given-names>HP</given-names></name><name><surname>Lee</surname><given-names>AK</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>Place cells. Large environments reveal the statistical structure governing hippocampal representations</article-title><source>Science</source><volume>345</volume><fpage>814</fpage><lpage>817</lpage><pub-id pub-id-type="doi">10.1126/science.1255635</pub-id><pub-id pub-id-type="pmid">25124440</pub-id></element-citation></ref><ref id="bib47"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Robbe</surname><given-names>D</given-names></name><name><surname>Montgomery</surname><given-names>SM</given-names></name><name><surname>Thome</surname><given-names>A</given-names></name><name><surname>Rueda-Orozco</surname><given-names>PE</given-names></name><name><surname>McNaughton</surname><given-names>BL</given-names></name><name><surname>Buzsaki</surname><given-names>G</given-names></name></person-group><year iso-8601-date="2006">2006</year><article-title>Cannabinoids reveal importance of spike timing coordination in hippocampal function</article-title><source>Nature Neuroscience</source><volume>9</volume><fpage>1526</fpage><lpage>1533</lpage><pub-id pub-id-type="doi">10.1038/nn1801</pub-id><pub-id pub-id-type="pmid">17115043</pub-id></element-citation></ref><ref id="bib48"><element-citation publication-type="confproc"><person-group person-group-type="author"><name><surname>Savin</surname><given-names>C</given-names></name><name><surname>Deneve</surname><given-names>S</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>Spatio-temporal representations of uncertainty in spiking neural networks</article-title><conf-name>In Proceedings of the 27th International Conference on Neural Information Processing Systems</conf-name></element-citation></ref><ref id="bib49"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Schomburg</surname><given-names>EW</given-names></name><name><surname>Fernández-Ruiz</surname><given-names>A</given-names></name><name><surname>Mizuseki</surname><given-names>K</given-names></name><name><surname>Berényi</surname><given-names>A</given-names></name><name><surname>Anastassiou</surname><given-names>CA</given-names></name><name><surname>Koch</surname><given-names>C</given-names></name><name><surname>Buzsáki</surname><given-names>G</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>Theta phase segregation of input-specific gamma patterns in entorhinal-hippocampal networks</article-title><source>Neuron</source><volume>84</volume><fpage>470</fpage><lpage>485</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2014.08.051</pub-id><pub-id pub-id-type="pmid">25263753</pub-id></element-citation></ref><ref id="bib50"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Sezener</surname><given-names>CE</given-names></name><name><surname>Dezfouli</surname><given-names>A</given-names></name><name><surname>Keramati</surname><given-names>M</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>Optimizing the depth and the direction of prospective planning using information values</article-title><source>PLOS Computational Biology</source><volume>15</volume><elocation-id>e1006827</elocation-id><pub-id pub-id-type="doi">10.1371/journal.pcbi.1006827</pub-id><pub-id pub-id-type="pmid">30861001</pub-id></element-citation></ref><ref id="bib51"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Skaggs</surname><given-names>WE</given-names></name><name><surname>McNaughton</surname><given-names>BL</given-names></name><name><surname>Wilson</surname><given-names>MA</given-names></name><name><surname>Barnes</surname><given-names>CA</given-names></name></person-group><year iso-8601-date="1996">1996</year><article-title>Theta phase precession in hippocampal neuronal populations and the compression of temporal sequences</article-title><source>Hippocampus</source><volume>6</volume><fpage>149</fpage><lpage>172</lpage><pub-id pub-id-type="doi">10.1002/(SICI)1098-1063(1996)6:2&lt;149::AID-HIPO6&gt;3.0.CO;2-K</pub-id><pub-id pub-id-type="pmid">8797016</pub-id></element-citation></ref><ref id="bib52"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Stachenfeld</surname><given-names>KL</given-names></name><name><surname>Botvinick</surname><given-names>MM</given-names></name><name><surname>Gershman</surname><given-names>SJ</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>The hippocampus as a predictive MAP</article-title><source>Nature Neuroscience</source><volume>20</volume><fpage>1643</fpage><lpage>1653</lpage><pub-id pub-id-type="doi">10.1038/nn.4650</pub-id><pub-id pub-id-type="pmid">28967910</pub-id></element-citation></ref><ref id="bib53"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Stroud</surname><given-names>JP</given-names></name><name><surname>Porter</surname><given-names>MA</given-names></name><name><surname>Hennequin</surname><given-names>G</given-names></name><name><surname>Vogels</surname><given-names>TP</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>Motor primitives in space and time via targeted gain modulation in cortical networks</article-title><source>Nature Neuroscience</source><volume>21</volume><fpage>1774</fpage><lpage>1783</lpage><pub-id pub-id-type="doi">10.1038/s41593-018-0276-0</pub-id><pub-id pub-id-type="pmid">30482949</pub-id></element-citation></ref><ref id="bib54"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Tang</surname><given-names>W</given-names></name><name><surname>Shin</surname><given-names>JD</given-names></name><name><surname>Jadhav</surname><given-names>SP</given-names></name></person-group><year iso-8601-date="2021">2021</year><article-title>Multiple time-scales of decision-making in the hippocampus and prefrontal cortex</article-title><source>eLife</source><volume>10</volume><elocation-id>e66227</elocation-id><pub-id pub-id-type="doi">10.7554/eLife.66227</pub-id><pub-id pub-id-type="pmid">33683201</pub-id></element-citation></ref><ref id="bib55"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ujfalussy</surname><given-names>BB</given-names></name><name><surname>Makara</surname><given-names>JK</given-names></name><name><surname>Branco</surname><given-names>T</given-names></name><name><surname>Lengyel</surname><given-names>M</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>Dendritic nonlinearities are tuned for efficient spike-based computations in cortical circuits</article-title><source>eLife</source><volume>4</volume><elocation-id>e10056</elocation-id><pub-id pub-id-type="doi">10.7554/eLife.10056</pub-id><pub-id pub-id-type="pmid">26705334</pub-id></element-citation></ref><ref id="bib56"><element-citation publication-type="preprint"><person-group person-group-type="author"><name><surname>Vértes</surname><given-names>E</given-names></name><name><surname>Sahani</surname><given-names>M</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>Flexible and Accurate Inference and Learning for Deep Generative Models</article-title><source>arXiv</source><pub-id pub-id-type="doi">10.48550/arXiv.1805.11051</pub-id></element-citation></ref><ref id="bib57"><element-citation publication-type="preprint"><person-group person-group-type="author"><name><surname>Vértes</surname><given-names>E</given-names></name><name><surname>Sahani</surname><given-names>M</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>A Neurally Plausible Model Learns Successor Representations in Partially Observable Environments</article-title><source>arXiv</source><ext-link ext-link-type="uri" xlink:href="https://arxiv.org/abs/1906.09480">https://arxiv.org/abs/1906.09480</ext-link></element-citation></ref><ref id="bib58"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Vyas</surname><given-names>S</given-names></name><name><surname>Golub</surname><given-names>MD</given-names></name><name><surname>Sussillo</surname><given-names>D</given-names></name><name><surname>Shenoy</surname><given-names>KV</given-names></name></person-group><year iso-8601-date="2020">2020</year><article-title>Computation through neural population dynamics</article-title><source>Annual Review of Neuroscience</source><volume>43</volume><fpage>249</fpage><lpage>275</lpage><pub-id pub-id-type="doi">10.1146/annurev-neuro-092619-094115</pub-id><pub-id pub-id-type="pmid">32640928</pub-id></element-citation></ref><ref id="bib59"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wainwright</surname><given-names>MJ</given-names></name><name><surname>Jordan</surname><given-names>MI</given-names></name></person-group><year iso-8601-date="2007">2007</year><article-title>Graphical models, exponential families, and variational inference</article-title><source>Foundations and Trends in Machine Learning</source><volume>1</volume><fpage>1</fpage><lpage>305</lpage><pub-id pub-id-type="doi">10.1561/2200000001</pub-id></element-citation></ref><ref id="bib60"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Walker</surname><given-names>EY</given-names></name><name><surname>Cotton</surname><given-names>RJ</given-names></name><name><surname>Ma</surname><given-names>WJ</given-names></name><name><surname>Tolias</surname><given-names>AS</given-names></name></person-group><year iso-8601-date="2020">2020</year><article-title>A neural basis of probabilistic computation in visual cortex</article-title><source>Nature Neuroscience</source><volume>23</volume><fpage>122</fpage><lpage>129</lpage><pub-id pub-id-type="doi">10.1038/s41593-019-0554-5</pub-id><pub-id pub-id-type="pmid">31873286</pub-id></element-citation></ref><ref id="bib61"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wang</surname><given-names>M</given-names></name><name><surname>Foster</surname><given-names>DJ</given-names></name><name><surname>Pfeiffer</surname><given-names>BE</given-names></name></person-group><year iso-8601-date="2020">2020</year><article-title>Alternating sequences of future and past behavior encoded within hippocampal theta oscillations</article-title><source>Science</source><volume>370</volume><fpage>247</fpage><lpage>250</lpage><pub-id pub-id-type="doi">10.1126/science.abb4151</pub-id><pub-id pub-id-type="pmid">33033222</pub-id></element-citation></ref><ref id="bib62"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Widloski</surname><given-names>J</given-names></name><name><surname>Foster</surname><given-names>DJ</given-names></name></person-group><year iso-8601-date="2022">2022</year><article-title>Flexible rerouting of hippocampal replay sequences around changing barriers in the absence of global place field remapping</article-title><source>Neuron</source><volume>110</volume><fpage>1547</fpage><lpage>1558</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2022.02.002</pub-id><pub-id pub-id-type="pmid">35180390</pub-id></element-citation></ref><ref id="bib63"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wikenheiser</surname><given-names>AM</given-names></name><name><surname>Redish</surname><given-names>AD</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>Hippocampal theta sequences reflect current goals</article-title><source>Nature Neuroscience</source><volume>18</volume><fpage>289</fpage><lpage>294</lpage><pub-id pub-id-type="doi">10.1038/nn.3909</pub-id><pub-id pub-id-type="pmid">25559082</pub-id></element-citation></ref><ref id="bib64"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wilson</surname><given-names>MA</given-names></name><name><surname>McNaughton</surname><given-names>BL</given-names></name></person-group><year iso-8601-date="1993">1993</year><article-title>Dynamics of the hippocampal ensemble code for space</article-title><source>Science</source><volume>261</volume><fpage>1055</fpage><lpage>1058</lpage><pub-id pub-id-type="doi">10.1126/science.8351520</pub-id><pub-id pub-id-type="pmid">8351520</pub-id></element-citation></ref><ref id="bib65"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Zemel</surname><given-names>RS</given-names></name><name><surname>Dayan</surname><given-names>P</given-names></name><name><surname>Pouget</surname><given-names>A</given-names></name></person-group><year iso-8601-date="1998">1998</year><article-title>Probabilistic interpretation of population codes</article-title><source>Neural Computation</source><volume>10</volume><fpage>403</fpage><lpage>430</lpage><pub-id pub-id-type="doi">10.1162/089976698300017818</pub-id><pub-id pub-id-type="pmid">9472488</pub-id></element-citation></ref><ref id="bib66"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Zhang</surname><given-names>K</given-names></name><name><surname>Ginzburg</surname><given-names>I</given-names></name><name><surname>McNaughton</surname><given-names>BL</given-names></name><name><surname>Sejnowski</surname><given-names>TJ</given-names></name></person-group><year iso-8601-date="1998">1998</year><article-title>Interpreting neuronal population activity by reconstruction: unified framework with application to hippocampal place cells</article-title><source>Journal of Neurophysiology</source><volume>79</volume><fpage>1017</fpage><lpage>1044</lpage><pub-id pub-id-type="doi">10.1152/jn.1998.79.2.1017</pub-id><pub-id pub-id-type="pmid">9463459</pub-id></element-citation></ref><ref id="bib67"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Zhang</surname><given-names>S</given-names></name><name><surname>Schönfeld</surname><given-names>F</given-names></name><name><surname>Wiskott</surname><given-names>L</given-names></name><name><surname>Manahan-Vaughan</surname><given-names>D</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>Spatial representations of place cells in darkness are supported by path integration and border information</article-title><source>Frontiers in Behavioral Neuroscience</source><volume>8</volume><elocation-id>222</elocation-id><pub-id pub-id-type="doi">10.3389/fnbeh.2014.00222</pub-id><pub-id pub-id-type="pmid">25009477</pub-id></element-citation></ref><ref id="bib68"><element-citation publication-type="preprint"><person-group person-group-type="author"><name><surname>Zheng</surname><given-names>C</given-names></name><name><surname>Hwaun</surname><given-names>E</given-names></name><name><surname>Colgin</surname><given-names>LL</given-names></name></person-group><year iso-8601-date="2020">2020</year><article-title>Impairments in Hippocampal Place Cell Sequences during Errors in Spatial Memory</article-title><source>bioRxiv</source><pub-id pub-id-type="doi">10.1101/2020.04.20.051755</pub-id></element-citation></ref></ref-list><app-group><app id="appendix-1"><title>Appendix 1</title><sec sec-type="appendix" id="s8"><title>Product coding scheme</title><p>In a product representation, a probability distribution over a feature, such as the position <inline-formula><mml:math id="inf256"><mml:mi>x</mml:mi></mml:math></inline-formula>, is encoded by the product of the encoding basis functions, <inline-formula><mml:math id="inf257"><mml:mrow><mml:msub><mml:mi>ϕ</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>x</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula>:<disp-formula id="equ36"><label>(35)</label><mml:math id="m36"><mml:mrow><mml:mi>P</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>x</mml:mi><mml:mo>;</mml:mo><mml:mrow><mml:mi mathvariant="bold">s</mml:mi></mml:mrow><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:msub><mml:mi>ϕ</mml:mi><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>x</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mrow><mml:mi>η</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mi mathvariant="bold">s</mml:mi></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mfrac><mml:munder><mml:mo>∏</mml:mo><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:munder><mml:msub><mml:mi>ϕ</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>x</mml:mi><mml:msup><mml:mo stretchy="false">)</mml:mo><mml:mrow><mml:msub><mml:mi>s</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:msup></mml:mrow></mml:math></disp-formula></p><p>where is the number of spikes fired by neuron <inline-formula><mml:math id="inf258"><mml:mi>i</mml:mi></mml:math></inline-formula> and <inline-formula><mml:math id="inf259"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>η</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mi mathvariant="bold">s</mml:mi></mml:mrow><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mo>∫</mml:mo><mml:msub><mml:mi>ϕ</mml:mi><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>x</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:munder><mml:mo>∏</mml:mo><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:munder><mml:msub><mml:mi>ϕ</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>x</mml:mi><mml:msup><mml:mo stretchy="false">)</mml:mo><mml:mrow><mml:msub><mml:mi>s</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:msup><mml:mspace width="thinmathspace"/><mml:mrow><mml:mi mathvariant="normal">d</mml:mi></mml:mrow><mml:mi>x</mml:mi></mml:mrow></mml:mstyle></mml:math></inline-formula> is the normalizing factor. Alternatively, by defining a set of sufficient statistics, <inline-formula><mml:math id="inf260"><mml:mrow><mml:mrow><mml:msub><mml:mi>h</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>x</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mo>=</mml:mo><mml:mrow><mml:mrow><mml:mi>log</mml:mi><mml:mo>⁡</mml:mo><mml:msub><mml:mi>ϕ</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>x</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:math></inline-formula>, the same distribution can be expressed in the standard, exponential form:<disp-formula id="equ37"><label>(36)</label><mml:math id="m37"><mml:mrow><mml:mi>P</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>x</mml:mi><mml:mo>;</mml:mo><mml:mrow><mml:mi mathvariant="bold">s</mml:mi></mml:mrow><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:msub><mml:mi>ϕ</mml:mi><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>x</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mrow><mml:mi>η</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mi mathvariant="bold">s</mml:mi></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mfrac><mml:mi>exp</mml:mi><mml:mo>⁡</mml:mo><mml:mrow><mml:mo maxsize="2.047em" minsize="2.047em">(</mml:mo></mml:mrow><mml:munder><mml:mo>∑</mml:mo><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:munder><mml:msub><mml:mi>s</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mspace width="thinmathspace"/><mml:msub><mml:mi>h</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>x</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mrow><mml:mo maxsize="2.047em" minsize="2.047em">)</mml:mo></mml:mrow></mml:mrow></mml:math></disp-formula></p><p>where the neuronal spikes serve as the canonical or exponential parameters of the distribution (<xref ref-type="bibr" rid="bib59">Wainwright and Jordan, 2007</xref>). Intuitively, increasing the number of spikes <inline-formula><mml:math id="inf261"><mml:mi mathvariant="bold">s</mml:mi></mml:math></inline-formula> in the population adds more and more terms in <xref ref-type="disp-formula" rid="equ36 equ37">Equations 35; 36</xref> leading to an increase in the sharpness of the represented distribution. In the special case where the tuning functions are Gaussians with variances <inline-formula><mml:math id="inf262"><mml:msubsup><mml:mi>σ</mml:mi><mml:mi>i</mml:mi><mml:mn>2</mml:mn></mml:msubsup></mml:math></inline-formula> and the likelihood is conditionally independent Poisson, the represented distribution is also Gaussian with a variance, <inline-formula><mml:math id="inf263"><mml:mrow><mml:msup><mml:mi>σ</mml:mi><mml:mn>2</mml:mn></mml:msup><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi mathvariant="bold">s</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> that is inversely proportional to the total spike count (<xref ref-type="bibr" rid="bib29">Ma et al., 2006</xref>):<disp-formula id="equ38"><label>(37)</label><mml:math id="m38"><mml:mrow><mml:mfrac><mml:mn>1</mml:mn><mml:mrow><mml:msup><mml:mi>σ</mml:mi><mml:mn>2</mml:mn></mml:msup><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>s</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:mfrac><mml:mo>=</mml:mo><mml:mrow><mml:munder><mml:mo largeop="true" movablelimits="false" symmetric="true">∑</mml:mo><mml:mi>i</mml:mi></mml:munder><mml:mfrac><mml:msub><mml:mi>s</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:msubsup><mml:mi>σ</mml:mi><mml:mi>i</mml:mi><mml:mn>2</mml:mn></mml:msubsup></mml:mfrac></mml:mrow></mml:mrow></mml:math></disp-formula></p><p>Here we show numerically that this relationship still holds for more general, multimodal basis functions, similar to the empirical tuning curves found in our dataset (<xref ref-type="fig" rid="fig2">Figure 2b</xref>). We used 110 tuning curves from an example session with mean firing rate <inline-formula><mml:math id="inf264"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mrow><mml:mover><mml:mi>r</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover></mml:mrow><mml:mo>&gt;</mml:mo><mml:mn>0.1</mml:mn></mml:mrow></mml:mstyle></mml:math></inline-formula> Hz and tuning curve peak <inline-formula><mml:math id="inf265"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>r</mml:mi><mml:mrow><mml:mrow><mml:mi mathvariant="normal">m</mml:mi><mml:mi mathvariant="normal">a</mml:mi><mml:mi mathvariant="normal">x</mml:mi></mml:mrow></mml:mrow></mml:msub><mml:mo>&gt;</mml:mo><mml:mn>10</mml:mn></mml:mrow></mml:mstyle></mml:math></inline-formula> Hz (<xref ref-type="fig" rid="fig4s1">Figure 4—figure supplement 1a</xref>), we normalised the tuning curves and used their logarithm as sufficient statistics to encode distributions in the form of <xref ref-type="disp-formula" rid="equ37">Equation 36</xref>:<disp-formula id="equ39"><label>(38)</label><mml:math id="m39"><mml:mrow><mml:mrow><mml:msub><mml:mi>h</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>x</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mo>=</mml:mo><mml:mrow><mml:mrow><mml:mrow><mml:mi>log</mml:mi><mml:mo>⁡</mml:mo><mml:msub><mml:mi>ψ</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>x</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mo>-</mml:mo><mml:mrow><mml:mi>log</mml:mi><mml:mo>⁡</mml:mo><mml:mrow><mml:mo maxsize="210%" minsize="210%">(</mml:mo><mml:mrow><mml:mo largeop="true" symmetric="true">∫</mml:mo><mml:mrow><mml:msub><mml:mi>ψ</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>x</mml:mi><mml:mo rspace="4.2pt" stretchy="false">)</mml:mo></mml:mrow><mml:mo>⁢</mml:mo><mml:mrow><mml:mo rspace="0pt">d</mml:mo><mml:mi>x</mml:mi></mml:mrow></mml:mrow></mml:mrow><mml:mo maxsize="210%" minsize="210%">)</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:mrow></mml:math></disp-formula></p><p>We used isotropic 2-dimensional Gaussians with a wide range of mean (20 cm <inline-formula><mml:math id="inf266"><mml:mrow><mml:mi/><mml:mo>≥</mml:mo><mml:mi>μ</mml:mi><mml:mo>≥</mml:mo><mml:mi/></mml:mrow></mml:math></inline-formula> 180 cm) and variance (<inline-formula><mml:math id="inf267"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msup><mml:mrow><mml:mn>4</mml:mn><mml:mspace width="thinmathspace"/><mml:mi mathvariant="normal">c</mml:mi><mml:mi mathvariant="normal">m</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup><mml:mspace width="thinmathspace"/><mml:mo>≥</mml:mo><mml:msup><mml:mi>σ</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup><mml:mo>≥</mml:mo><mml:mspace width="thinmathspace"/><mml:msup><mml:mrow><mml:mn>1600</mml:mn><mml:mspace width="thinmathspace"/><mml:mi mathvariant="normal">c</mml:mi><mml:mi mathvariant="normal">m</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:mstyle></mml:math></inline-formula>) as target distributions and encoded them in the spiking activity of the neurons. <xref ref-type="disp-formula" rid="equ37">Equation 36</xref> defines how a set of observed spikes (canonical parameters) can be interpreted as encoding a probability distribution. However, this mapping is not invertible and finding a set of spikes approximating an arbitrary target distribution is computationally challenging. We solved this problem by iteratively and greedily selecting spikes to minimise the Kullback-Leibler divergence between the encoded distribution, <inline-formula><mml:math id="inf268"><mml:mrow><mml:mrow><mml:mi>Q</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>x</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mo>∝</mml:mo><mml:mrow><mml:mi>exp</mml:mi><mml:mo>⁡</mml:mo><mml:mrow><mml:mo maxsize="120%" minsize="120%">(</mml:mo><mml:mrow><mml:msub><mml:mo largeop="true" symmetric="true">∑</mml:mo><mml:mi>i</mml:mi></mml:msub><mml:mrow><mml:mpadded width="+1.7pt"><mml:msub><mml:mi>s</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mpadded><mml:mo>⁢</mml:mo><mml:msub><mml:mi>h</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>x</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:mrow><mml:mo maxsize="120%" minsize="120%">)</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:math></inline-formula>, and the Gaussian target distribution, <inline-formula><mml:math id="inf269"><mml:mrow><mml:mi>P</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>x</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula>. Specifically, we first selected a single neuron whose spike minimised <inline-formula><mml:math id="inf270"><mml:mrow><mml:msub><mml:mi mathvariant="normal">D</mml:mi><mml:mi>KL</mml:mi></mml:msub><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>Q</mml:mi><mml:mo>,</mml:mo><mml:mi>P</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula>, then added more spikes one by one until the additional spikes stopped decreasing <inline-formula><mml:math id="inf271"><mml:mrow><mml:msub><mml:mi mathvariant="normal">D</mml:mi><mml:mi>KL</mml:mi></mml:msub><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>Q</mml:mi><mml:mo>,</mml:mo><mml:mi>P</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula>.</p><p>We found that the approximations were reasonably accurate, especially for distributions with smaller variance (<xref ref-type="fig" rid="fig4s1">Figure 4—figure supplement 1b</xref>). Importantly, the average number of spikes used for encoding decreased systematically with the variance of the encoded distribution (<xref ref-type="fig" rid="fig4s1">Figure 4—figure supplement 1c</xref>). Moreover, we found that even for highly variable basis functions, the total spike count in the population was well approximated as a linear function of the target precision, as expected from the theory for uniform basis functions (<xref ref-type="fig" rid="fig4s1">Figure 4—figure supplement 1d</xref>; <xref ref-type="disp-formula" rid="equ38">Equation 37</xref>). Therefore we used the systematic variation of the total spike count in the population (population gain) as a function of the represented uncertainty as a hallmark of the product scheme.</p><p>When encoding trajectories in the population activity we used a simplified encoding model and scaled the gain of the neurons by the instantaneous variance of the encoded distribution (<xref ref-type="disp-formula" rid="equ15">Equation 15</xref>).</p></sec></app><app id="appendix-2"><title>Appendix 2</title><sec sec-type="appendix" id="s9"><title>DDC coding scheme</title><p>In the DDC coding scheme the firing rate of neuron <inline-formula><mml:math id="inf272"><mml:mi>i</mml:mi></mml:math></inline-formula> corresponds to the expectation of its basis function under the encoded distribution (<xref ref-type="bibr" rid="bib65">Zemel et al., 1998</xref>; <xref ref-type="bibr" rid="bib56">Vértes and Sahani, 2018</xref>):<disp-formula id="equ40"><label>(39)</label><mml:math id="m40"><mml:mrow><mml:msub><mml:mi>λ</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mrow><mml:mo largeop="true" symmetric="true">∫</mml:mo><mml:mrow><mml:msub><mml:mi>ϕ</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>x</mml:mi><mml:mo rspace="4.2pt" stretchy="false">)</mml:mo></mml:mrow><mml:mo>⁢</mml:mo><mml:mi>P</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>x</mml:mi><mml:mo rspace="4.2pt" stretchy="false">)</mml:mo></mml:mrow><mml:mo>⁢</mml:mo><mml:mrow><mml:mo rspace="0pt">d</mml:mo><mml:mi>x</mml:mi></mml:mrow></mml:mrow></mml:mrow></mml:mrow></mml:math></disp-formula></p><p>This encoding scheme has complementary properties to the product scheme, as it represents exponential family distributions using their mean parameters instead of their canonical, natural parameters (<xref ref-type="bibr" rid="bib59">Wainwright and Jordan, 2007</xref>). <xref ref-type="disp-formula" rid="equ40">Equation 39</xref> defines a mapping from a distribution to firing rates, but the reverse mapping, from the rates to the encoded distribution is not trivial. When the firing rates are observed then the expectation of any nonlinear function <inline-formula><mml:math id="inf273"><mml:mrow><mml:mi>f</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mo>⋅</mml:mo><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> under the encoded distribution, including its moments, the mean and the covariance, can be calculated as a linear combination of the rates (<xref ref-type="bibr" rid="bib56">Vértes and Sahani, 2018</xref>):<disp-formula id="equ41"><label>(40)</label><mml:math id="m41"><mml:mrow><mml:mrow><mml:mi>E</mml:mi><mml:mo>⁢</mml:mo><mml:msub><mml:mrow><mml:mo stretchy="false">[</mml:mo><mml:mrow><mml:mi>f</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>x</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mo stretchy="false">]</mml:mo></mml:mrow><mml:mrow><mml:mi>P</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>x</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:msub></mml:mrow><mml:mo>=</mml:mo><mml:mrow><mml:munder><mml:mo largeop="true" movablelimits="false" symmetric="true">∑</mml:mo><mml:mi>i</mml:mi></mml:munder><mml:mrow><mml:mpadded width="+1.7pt"><mml:msub><mml:mi>α</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mpadded><mml:mo>⁢</mml:mo><mml:msub><mml:mi>λ</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:mrow></mml:mrow></mml:math></disp-formula></p><p>where <inline-formula><mml:math id="inf274"><mml:mrow><mml:mrow><mml:mi>f</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>x</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mo>≈</mml:mo><mml:mrow><mml:msub><mml:mo largeop="true" symmetric="true">∑</mml:mo><mml:mi>i</mml:mi></mml:msub><mml:mrow><mml:mpadded width="+1.7pt"><mml:msub><mml:mi>α</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mpadded><mml:mo>⁢</mml:mo><mml:msub><mml:mi>ϕ</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>x</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:mrow></mml:math></inline-formula>. However, in the experimental data only the discrete spike counts are observed and the underlying firing rates are hidden. In this case <xref ref-type="disp-formula" rid="equ41">Equation 40</xref> can be computed as an expectation under the posterior of the firing rates <inline-formula><mml:math id="inf275"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>P</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi mathvariant="bold-italic">λ</mml:mi><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mrow><mml:mi mathvariant="bold">s</mml:mi></mml:mrow><mml:mo mathvariant="bold" stretchy="false">)</mml:mo></mml:mrow></mml:mstyle></mml:math></inline-formula>:<disp-formula id="equ42"><label>(41)</label><mml:math id="m42"><mml:mrow><mml:mrow><mml:mi mathvariant="double-struck">E</mml:mi></mml:mrow><mml:mo stretchy="false">[</mml:mo><mml:mi>f</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>x</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:msub><mml:mo stretchy="false">]</mml:mo><mml:mrow><mml:mi>P</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>x</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mo>∫</mml:mo><mml:mi>P</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi mathvariant="bold-italic">λ</mml:mi><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mrow><mml:mi mathvariant="bold">s</mml:mi></mml:mrow><mml:mo stretchy="false">)</mml:mo><mml:munder><mml:mo>∑</mml:mo><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:munder><mml:msub><mml:mi>α</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mspace width="thinmathspace"/><mml:msub><mml:mi>λ</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mspace width="thinmathspace"/><mml:mrow><mml:mi mathvariant="normal">d</mml:mi></mml:mrow><mml:mi mathvariant="bold-italic">λ</mml:mi></mml:mrow></mml:math></disp-formula></p><p>with<disp-formula id="equ43"><label>(42)</label><mml:math id="m43"><mml:mrow><mml:mi>P</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi mathvariant="bold-italic">λ</mml:mi><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mrow><mml:mi mathvariant="bold">s</mml:mi></mml:mrow><mml:mo stretchy="false">)</mml:mo><mml:mo>∝</mml:mo><mml:mi>P</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi mathvariant="bold-italic">λ</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mspace width="thinmathspace"/><mml:munder><mml:mo>∏</mml:mo><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:munder><mml:mi>P</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>s</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:msub><mml:mi>λ</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></disp-formula></p><p>Here the prior over the firing rates <inline-formula><mml:math id="inf276"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>P</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi mathvariant="bold-italic">λ</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mstyle></mml:math></inline-formula> (the distribution of coactivity patterns among neurons with different tuning curves or place fields) is usually assumed to be factorised for computational efficiency. However, correlations between neuronal tuning curves introduce strong dependence in the prior and thus using a factorised approximation of <xref ref-type="disp-formula" rid="equ42">Equation 41</xref> leads to a substantial loss of information (<xref ref-type="bibr" rid="bib55">Ujfalussy et al., 2015</xref>). Therefore, instead of following this Bayesian approach, we aimed at directly estimating the parameters of the distribution encoded by the spikes observed in a neuronal population using a maximum likelihood decoder (<xref ref-type="disp-formula" rid="equ20">Equation 19</xref>).</p><p>We tested the performance of the maximum likelihood DDC decoder by encoding isotropic 2-dimensional Gaussian distributions with a wide range of mean (20 cm <inline-formula><mml:math id="inf277"><mml:mrow><mml:mi/><mml:mo>≥</mml:mo><mml:mi>μ</mml:mi><mml:mo>≥</mml:mo><mml:mi/></mml:mrow></mml:math></inline-formula> 180 cm) and variance (<inline-formula><mml:math id="inf278"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msup><mml:mrow><mml:mn>40</mml:mn><mml:mspace width="thinmathspace"/><mml:mi mathvariant="normal">c</mml:mi><mml:mi mathvariant="normal">m</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup><mml:mspace width="thinmathspace"/><mml:mo>≥</mml:mo><mml:msup><mml:mi>σ</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup><mml:mo>≥</mml:mo><mml:mspace width="thinmathspace"/><mml:mn>400</mml:mn><mml:mspace width="thinmathspace"/><mml:mi mathvariant="normal">c</mml:mi><mml:msup><mml:mi mathvariant="normal">m</mml:mi><mml:mn>2</mml:mn></mml:msup></mml:mrow></mml:mstyle></mml:math></inline-formula>) as target in the spiking activity of a neural population using 200 encoding basis functions similar to the empirical tuning curves recorded experimentally (<xref ref-type="fig" rid="fig6s1">Figure 6—figure supplement 1</xref>, top). We calculated the firing rate of the neurons according to <xref ref-type="disp-formula" rid="equ40">Equation 39</xref> and generated Poisson spike counts in <inline-formula><mml:math id="inf279"><mml:mrow><mml:mrow><mml:mi mathvariant="normal">Δ</mml:mi><mml:mo>⁢</mml:mo><mml:mi>t</mml:mi></mml:mrow><mml:mo>=</mml:mo><mml:mrow><mml:mn>20</mml:mn><mml:mo>-</mml:mo><mml:mn>100</mml:mn></mml:mrow></mml:mrow></mml:math></inline-formula> ms time bins. We found that on average, we could accurately estimate the encoded mean and SD of the target distributions when we used the same basis functions during encoding and decoding at least for <inline-formula><mml:math id="inf280"><mml:mrow><mml:mrow><mml:mi mathvariant="normal">Δ</mml:mi><mml:mo>⁢</mml:mo><mml:mi>t</mml:mi></mml:mrow><mml:mo>≥</mml:mo><mml:mn>50</mml:mn></mml:mrow></mml:math></inline-formula> ms. (<xref ref-type="fig" rid="fig5s1">Figure 5—figure supplement 1b</xref>). However, in practice, we do not have access to the encoding basis functions, only the empirical tuning curves, substantially wider than the basis functions (<xref ref-type="fig" rid="fig5s1">Figure 5—figure supplement 1e</xref>). When we used the wider tuning curves for decoding, the estimate of the SD became substantially biased: the decoded SD could be on average 5–7 cm below the target SD even for <inline-formula><mml:math id="inf281"><mml:mrow><mml:mrow><mml:mi mathvariant="normal">Δ</mml:mi><mml:mo>⁢</mml:mo><mml:mi>t</mml:mi></mml:mrow><mml:mo>=</mml:mo><mml:mn>100</mml:mn></mml:mrow></mml:math></inline-formula> ms (<xref ref-type="fig" rid="fig5s1">Figure 5—figure supplement 1e</xref>).</p><p>To identify DDC scheme in the data it is important to be able to reduce this decoding bias and accurately estimate the SD of the encoded distribution even in small time windows. We speculated that this bias is due to the difference between the wider empirical tuning curves used for decoding and the narrower basis functions used for encoding the target distributions. This effect is caused by encoding locations other than the actual position of the animal and by encoding distributions with non-zero variance using the DDC scheme. The decoder tries to match the overlap between the tuning functions and the estimated distribution with the observed spike counts. When the tuning functions used for DDC-decoding are wider than the encoding tuning functions, the decoder will compensate this by choosing a narrower decoded distribution to achieve a similar overlap with the decoding tuning functions (<xref ref-type="fig" rid="fig5s1">Figure 5—figure supplement 1a</xref>). Thus, the decoder will be biased towards lower variances, leading to systematic underestimation of the variance of the encoded distribution.</p><p>In order to reduce this bias we aimed at estimating the true encoding basis functions from the recorded neuronal activity. Note, that deriving an optimal estimator is hindered by the fact that in <xref ref-type="disp-formula" rid="equ40">Equation 39</xref> neither the tuning functions nor the encoded distributions or the true firing rates are observed. Therefore we developed an approximate algorithm to sharpen the empirical tuning curves and reconstruct the original tuning functions. The aim was to find a flexible algorithm that preserves the relative mass of different modes of the tuning curves but sharpens all of them to a similar degree. Our method was inspired by particle filtering and the use of annealing methods in sampling (<xref ref-type="bibr" rid="bib38">Murray, 2007</xref>): we first generated a set of samples from the empirical tuning curves, and then added random noise to propagate the samples towards the desired distribution. Specifically, we used the following procedure to sharpen the tuning curves:</p><list list-type="order"><list-item><p>We generated <inline-formula><mml:math id="inf282"><mml:mrow><mml:mi>N</mml:mi><mml:mo>=</mml:mo><mml:mrow><mml:mn>10</mml:mn><mml:mo>,</mml:mo><mml:mn>000</mml:mn></mml:mrow></mml:mrow></mml:math></inline-formula> samples from the empirical tuning curve <inline-formula><mml:math id="inf283"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>z</mml:mi><mml:mo>∼</mml:mo><mml:mi>P</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>z</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mi>η</mml:mi></mml:mfrac><mml:msub><mml:mi>ψ</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>z</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mstyle></mml:math></inline-formula>, where <inline-formula><mml:math id="inf284"><mml:mrow><mml:mi>η</mml:mi><mml:mo>=</mml:mo><mml:mrow><mml:mo largeop="true" symmetric="true">∫</mml:mo><mml:mrow><mml:msub><mml:mi>ψ</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>z</mml:mi><mml:mo rspace="4.2pt" stretchy="false">)</mml:mo></mml:mrow><mml:mo>⁢</mml:mo><mml:mrow><mml:mo rspace="0pt">d</mml:mo><mml:mi>z</mml:mi></mml:mrow></mml:mrow></mml:mrow></mml:mrow></mml:math></inline-formula> is the normalization constant to convert the tuning curve to a distribution.</p></list-item><list-item><p>We added a Gaussian random noise to the samples <inline-formula><mml:math id="inf285"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msup><mml:mi>z</mml:mi><mml:mrow><mml:mi mathvariant="normal">′</mml:mi></mml:mrow></mml:msup><mml:mo>=</mml:mo><mml:mi>z</mml:mi><mml:mo>+</mml:mo><mml:mi>ϵ</mml:mi></mml:mrow></mml:mstyle></mml:math></inline-formula> with <inline-formula><mml:math id="inf286"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>ϵ</mml:mi><mml:mo>∼</mml:mo><mml:mrow><mml:mi mathvariant="script">N</mml:mi></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:msup><mml:mi>σ</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mstyle></mml:math></inline-formula> where the proposal variance, <inline-formula><mml:math id="inf287"><mml:msup><mml:mi>σ</mml:mi><mml:mn>2</mml:mn></mml:msup></mml:math></inline-formula> controls the degree of mixing between the different modes. We used <inline-formula><mml:math id="inf288"><mml:mrow><mml:mi>σ</mml:mi><mml:mo>=</mml:mo><mml:mn>10</mml:mn></mml:mrow></mml:math></inline-formula> cm.</p></list-item><list-item><p>We accepted the new sample <inline-formula><mml:math id="inf289"><mml:msubsup><mml:mi>z</mml:mi><mml:mi>k</mml:mi><mml:mo>′</mml:mo></mml:msubsup></mml:math></inline-formula> with probability <inline-formula><mml:math id="inf290"><mml:mrow><mml:msub><mml:mi>p</mml:mi><mml:mi>k</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mrow><mml:mi>min</mml:mi><mml:mo>⁡</mml:mo><mml:mrow><mml:mo maxsize="160%" minsize="160%">(</mml:mo><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:msup><mml:mrow><mml:mo maxsize="120%" minsize="120%">(</mml:mo><mml:mrow><mml:mrow><mml:mrow><mml:mi>P</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msubsup><mml:mi>z</mml:mi><mml:mi>k</mml:mi><mml:mo>′</mml:mo></mml:msubsup><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mo>/</mml:mo><mml:mi>P</mml:mi></mml:mrow><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>z</mml:mi><mml:mi>k</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mo maxsize="120%" minsize="120%">)</mml:mo></mml:mrow><mml:mi>β</mml:mi></mml:msup><mml:mo maxsize="160%" minsize="160%">)</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:math></inline-formula> where the parameter <inline-formula><mml:math id="inf291"><mml:mi>β</mml:mi></mml:math></inline-formula> controls the sign and degree of sharpening. We used <inline-formula><mml:math id="inf292"><mml:mrow><mml:mi>β</mml:mi><mml:mo>=</mml:mo><mml:mn>3</mml:mn></mml:mrow></mml:math></inline-formula>.</p></list-item><list-item><p>We repeated steps 2. and 3. for a number of iterations, not necessarily until convergence.</p></list-item><list-item><p>Finally, we defined the estimated basis functions as the smoothed (5 cm Gaussian kernel) histogram of the number of samples in 5 cm spatial bins.</p></list-item></list><p><xref ref-type="fig" rid="fig5s1">Figure 5—figure supplement 1g</xref> shows the tuning functions of a few example cells from our synthetic dataset (top row) together with the measured tuning curves (second row) and the result of the sharpening algorithm after 3 and 6 steps (3rd and 4th rows). We evaluated the sharpening algorithm by comparing the relative size of the estimated and the original tuning functions and the average difference between them. We found that 6 iterations of the algorithm eliminates overestimation bias of the tuning curve size (<xref ref-type="fig" rid="fig5s1">Figure 5—figure supplement 1e</xref>) and 3–6 iterations minimized the estimation error (<xref ref-type="fig" rid="fig5s1">Figure 5—figure supplement 1f</xref>). Using the 3-step sharpened tuning curves also improved the performance of the DDC-decoder as it substantially reduced the bias when decoding the SD of the distribution (<xref ref-type="fig" rid="fig5s1">Figure 5—figure supplement 1d</xref>). Therefore we repeated the DDC decoding analysis shown in <xref ref-type="fig" rid="fig5">Figure 5</xref> using the 3-step sharpened tuning curves in <xref ref-type="fig" rid="fig5s2">Figure 5—figure supplement 2</xref>.</p><p>Even with this correction, trial by trial decoding of the represented distributions was not possible on short time scales. However, when averaged across 1000s of theta cycles, the decoder became sufficiently sensitive to the encoded SD to identify systematic changes in the represented uncertainty. Therefore, we used the average SD decoded from the neural activity as a hallmark of DDC encoding.</p></sec></app><app id="appendix-3"><title>Appendix 3</title><sec sec-type="appendix" id="s10"><title>Background for the calculation of EV-index</title><sec sec-type="appendix" id="s10-1"><title>Cycle-to-cycle variability</title><p>Here we derive the expectation of <xref ref-type="disp-formula" rid="equ22">Equation 21</xref> in the case of mean encoding scheme, when the population activity encodes the posterior mean trajectory <inline-formula><mml:math id="inf293"><mml:msub><mml:mi mathvariant="bold-italic">μ </mml:mi><mml:mi>n</mml:mi></mml:msub></mml:math></inline-formula>:<disp-formula id="equ44"><label>(43)</label><mml:math id="m44"><mml:mrow><mml:mtable columnalign="right left" rowspacing="4pt" columnspacing="1em"><mml:mtr><mml:mtd><mml:msub><mml:mrow><mml:mi mathvariant="double-struck">E</mml:mi></mml:mrow><mml:mrow><mml:mtext>mean</mml:mtext></mml:mrow></mml:msub><mml:mrow><mml:mo>[</mml:mo><mml:mrow><mml:munder><mml:mo>∑</mml:mo><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:munder><mml:mo stretchy="false">(</mml:mo><mml:msubsup><mml:mrow><mml:mover><mml:mrow><mml:mi mathvariant="bold">x</mml:mi></mml:mrow><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>n</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msubsup><mml:mo>−</mml:mo><mml:msubsup><mml:mrow><mml:mover><mml:mrow><mml:mi mathvariant="bold">x</mml:mi></mml:mrow><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>n</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msubsup><mml:msup><mml:mo stretchy="false">)</mml:mo><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:mrow><mml:mo>]</mml:mo></mml:mrow></mml:mtd><mml:mtd><mml:mo>=</mml:mo><mml:mrow><mml:mi mathvariant="double-struck">E</mml:mi></mml:mrow><mml:mrow><mml:mo>[</mml:mo><mml:mrow><mml:munder><mml:mo>∑</mml:mo><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:munder><mml:msup><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msubsup><mml:mrow><mml:mover><mml:mrow><mml:mi mathvariant="bold">x</mml:mi></mml:mrow><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>n</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msubsup><mml:mo>−</mml:mo><mml:msubsup><mml:mi mathvariant="bold-italic">μ</mml:mi><mml:mrow><mml:mi>n</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msubsup><mml:mo stretchy="false">)</mml:mo><mml:mo>−</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:msubsup><mml:mrow><mml:mover><mml:mrow><mml:mi mathvariant="bold">x</mml:mi></mml:mrow><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>n</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msubsup><mml:mo>−</mml:mo><mml:msubsup><mml:mi mathvariant="bold-italic">μ</mml:mi><mml:mrow><mml:mi>n</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msubsup><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:mrow><mml:mo>]</mml:mo></mml:mrow></mml:mtd></mml:mtr><mml:mtr><mml:mtd/><mml:mtd><mml:mo>≈</mml:mo><mml:mrow><mml:mi mathvariant="double-struck">E</mml:mi></mml:mrow><mml:mrow><mml:mo>[</mml:mo><mml:mrow><mml:munder><mml:mo>∑</mml:mo><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:munder><mml:mo stretchy="false">(</mml:mo><mml:msubsup><mml:mrow><mml:mover><mml:mrow><mml:mi mathvariant="bold">x</mml:mi></mml:mrow><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>n</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msubsup><mml:mo>−</mml:mo><mml:msubsup><mml:mi mathvariant="bold-italic">μ</mml:mi><mml:mrow><mml:mi>n</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msubsup><mml:msup><mml:mo stretchy="false">)</mml:mo><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup><mml:mo>+</mml:mo><mml:munder><mml:mo>∑</mml:mo><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:munder><mml:mo stretchy="false">(</mml:mo><mml:msubsup><mml:mrow><mml:mover><mml:mrow><mml:mi mathvariant="bold">x</mml:mi></mml:mrow><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>n</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msubsup><mml:mo>−</mml:mo><mml:msubsup><mml:mi mathvariant="bold-italic">μ</mml:mi><mml:mrow><mml:mi>n</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msubsup><mml:msup><mml:mo stretchy="false">)</mml:mo><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:mrow><mml:mo>]</mml:mo></mml:mrow></mml:mtd></mml:mtr><mml:mtr><mml:mtd/><mml:mtd><mml:mo>=</mml:mo><mml:msup><mml:mi>ϵ</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup><mml:mo>+</mml:mo><mml:mrow><mml:mi mathvariant="double-struck">E</mml:mi></mml:mrow><mml:mrow><mml:mo>[</mml:mo><mml:mrow><mml:munder><mml:mo>∑</mml:mo><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:munder><mml:mo stretchy="false">(</mml:mo><mml:msubsup><mml:mrow><mml:mover><mml:mrow><mml:mi mathvariant="bold">x</mml:mi></mml:mrow><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>n</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msubsup><mml:mo>−</mml:mo><mml:msubsup><mml:mi mathvariant="bold-italic">μ</mml:mi><mml:mrow><mml:mi>n</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msubsup><mml:mo>+</mml:mo><mml:msubsup><mml:mi mathvariant="bold-italic">μ</mml:mi><mml:mrow><mml:mi>n</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msubsup><mml:mo>−</mml:mo><mml:msubsup><mml:mi mathvariant="bold-italic">μ</mml:mi><mml:mrow><mml:mi>n</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msubsup><mml:msup><mml:mo stretchy="false">)</mml:mo><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:mrow><mml:mo>]</mml:mo></mml:mrow></mml:mtd></mml:mtr><mml:mtr><mml:mtd/><mml:mtd><mml:mo>≈</mml:mo><mml:mn>2</mml:mn><mml:msup><mml:mi>ϵ</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup><mml:mo>+</mml:mo><mml:msup><mml:mi>ζ</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:math></disp-formula></p><p>where <inline-formula><mml:math id="inf294"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msup><mml:mi>ζ</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup><mml:mo>=</mml:mo><mml:mrow><mml:mi mathvariant="double-struck">E</mml:mi></mml:mrow><mml:mrow><mml:mo maxsize="1.2em" minsize="1.2em">[</mml:mo></mml:mrow><mml:munder><mml:mo>∑</mml:mo><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:munder><mml:mo stretchy="false">(</mml:mo><mml:msubsup><mml:mi mathvariant="bold-italic">μ</mml:mi><mml:mrow><mml:mi>n</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msubsup><mml:mo>−</mml:mo><mml:msubsup><mml:mi mathvariant="bold-italic">μ</mml:mi><mml:mrow><mml:mi>n</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msubsup><mml:msup><mml:mo stretchy="false">)</mml:mo><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup><mml:mrow><mml:mo maxsize="1.2em" minsize="1.2em">]</mml:mo></mml:mrow></mml:mrow></mml:mstyle></mml:math></inline-formula> is the expected change of the posterior mean trajectory due to sensory inputs, and we omitted second order terms including the correlations between the decoding errors in subsequent theta cycles and the correlation between decoding error and trajectory change.</p><p>The same expectation in the case of sampling, when the encoded location <inline-formula><mml:math id="inf295"><mml:msub><mml:mover accent="true"><mml:mi mathvariant="bold">x</mml:mi><mml:mo stretchy="false">~</mml:mo></mml:mover><mml:mi>n</mml:mi></mml:msub></mml:math></inline-formula> is sampled from the posterior:<disp-formula id="equ45"><label>(44)</label><mml:math id="m45"><mml:mrow><mml:mtable columnalign="right left" rowspacing="4pt" columnspacing="1em"><mml:mtr><mml:mtd><mml:msub><mml:mrow><mml:mi mathvariant="double-struck">E</mml:mi></mml:mrow><mml:mrow><mml:mtext>sam</mml:mtext></mml:mrow></mml:msub><mml:mrow><mml:mo maxsize="2.047em" minsize="2.047em">[</mml:mo></mml:mrow><mml:munder><mml:mo>∑</mml:mo><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:munder><mml:mo stretchy="false">(</mml:mo><mml:msubsup><mml:mrow><mml:mover><mml:mrow><mml:mi mathvariant="bold">x</mml:mi></mml:mrow><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>n</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msubsup><mml:mo>−</mml:mo><mml:msubsup><mml:mrow><mml:mover><mml:mrow><mml:mi mathvariant="bold">x</mml:mi></mml:mrow><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>n</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msubsup><mml:msup><mml:mo stretchy="false">)</mml:mo><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup><mml:mo stretchy="false">]</mml:mo></mml:mtd><mml:mtd><mml:mo>=</mml:mo><mml:mrow><mml:mi mathvariant="double-struck">E</mml:mi></mml:mrow><mml:mrow><mml:mo maxsize="1.623em" minsize="1.623em">[</mml:mo></mml:mrow><mml:munder><mml:mo>∑</mml:mo><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:munder><mml:mrow><mml:mo maxsize="1.2em" minsize="1.2em">(</mml:mo></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msubsup><mml:mrow><mml:mover><mml:mrow><mml:mi mathvariant="bold">x</mml:mi></mml:mrow><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>n</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msubsup><mml:mo>−</mml:mo><mml:msubsup><mml:mrow><mml:mover><mml:mrow><mml:mi mathvariant="bold">x</mml:mi></mml:mrow><mml:mo stretchy="false">~</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>n</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msubsup><mml:mo stretchy="false">)</mml:mo><mml:mo>−</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:msubsup><mml:mrow><mml:mover><mml:mrow><mml:mi mathvariant="bold">x</mml:mi></mml:mrow><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>n</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msubsup><mml:mo>−</mml:mo><mml:msubsup><mml:mrow><mml:mover><mml:mrow><mml:mi mathvariant="bold">x</mml:mi></mml:mrow><mml:mo stretchy="false">~</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>n</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msubsup><mml:mo stretchy="false">)</mml:mo><mml:msup><mml:mrow><mml:mo maxsize="1.2em" minsize="1.2em">)</mml:mo></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup><mml:mrow><mml:mo maxsize="1.623em" minsize="1.623em">]</mml:mo></mml:mrow></mml:mtd></mml:mtr><mml:mtr><mml:mtd/><mml:mtd><mml:mo>≈</mml:mo><mml:msup><mml:mi>ϵ</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup><mml:mo>+</mml:mo><mml:mrow><mml:mi mathvariant="double-struck">E</mml:mi></mml:mrow><mml:mrow><mml:mo maxsize="2.047em" minsize="2.047em">[</mml:mo></mml:mrow><mml:munder><mml:mo>∑</mml:mo><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:munder><mml:mo stretchy="false">(</mml:mo><mml:msubsup><mml:mrow><mml:mover><mml:mrow><mml:mi mathvariant="bold">x</mml:mi></mml:mrow><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>n</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msubsup><mml:mo>−</mml:mo><mml:msubsup><mml:mrow><mml:mover><mml:mrow><mml:mi mathvariant="bold">x</mml:mi></mml:mrow><mml:mo stretchy="false">~</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>n</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msubsup><mml:mo>+</mml:mo><mml:msubsup><mml:mrow><mml:mover><mml:mrow><mml:mi mathvariant="bold">x</mml:mi></mml:mrow><mml:mo stretchy="false">~</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>n</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msubsup><mml:mo>−</mml:mo><mml:msubsup><mml:mrow><mml:mover><mml:mrow><mml:mi mathvariant="bold">x</mml:mi></mml:mrow><mml:mo stretchy="false">~</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>n</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msubsup><mml:msup><mml:mo stretchy="false">)</mml:mo><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup><mml:mrow><mml:mo maxsize="2.047em" minsize="2.047em">]</mml:mo></mml:mrow></mml:mtd></mml:mtr><mml:mtr><mml:mtd/><mml:mtd><mml:mo>≈</mml:mo><mml:mn>2</mml:mn><mml:msup><mml:mi>ϵ</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup><mml:mo>+</mml:mo><mml:mrow><mml:mi mathvariant="double-struck">E</mml:mi></mml:mrow><mml:mrow><mml:mo maxsize="2.047em" minsize="2.047em">[</mml:mo></mml:mrow><mml:munder><mml:mo>∑</mml:mo><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:munder><mml:mo stretchy="false">(</mml:mo><mml:msubsup><mml:mrow><mml:mover><mml:mrow><mml:mi mathvariant="bold">x</mml:mi></mml:mrow><mml:mo stretchy="false">~</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>n</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msubsup><mml:mo>−</mml:mo><mml:msubsup><mml:mrow><mml:mover><mml:mrow><mml:mi mathvariant="bold">x</mml:mi></mml:mrow><mml:mo stretchy="false">~</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>n</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msubsup><mml:msup><mml:mo stretchy="false">)</mml:mo><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup><mml:mrow><mml:mo maxsize="2.047em" minsize="2.047em">]</mml:mo></mml:mrow></mml:mtd></mml:mtr><mml:mtr><mml:mtd/><mml:mtd><mml:mo>=</mml:mo><mml:mn>2</mml:mn><mml:msup><mml:mi>ϵ</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup><mml:mo>+</mml:mo><mml:mrow><mml:mi mathvariant="double-struck">E</mml:mi></mml:mrow><mml:mrow><mml:mo maxsize="1.623em" minsize="1.623em">[</mml:mo></mml:mrow><mml:munder><mml:mo>∑</mml:mo><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:munder><mml:mrow><mml:mo maxsize="1.2em" minsize="1.2em">(</mml:mo></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msubsup><mml:mrow><mml:mover><mml:mrow><mml:mi mathvariant="bold">x</mml:mi></mml:mrow><mml:mo stretchy="false">~</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>n</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msubsup><mml:mo>−</mml:mo><mml:msubsup><mml:mi mathvariant="bold-italic">μ</mml:mi><mml:mrow><mml:mi>n</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msubsup><mml:mo>+</mml:mo><mml:msubsup><mml:mi mathvariant="bold-italic">μ</mml:mi><mml:mrow><mml:mi>n</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msubsup><mml:mo stretchy="false">)</mml:mo><mml:mo>−</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:msubsup><mml:mrow><mml:mover><mml:mrow><mml:mi mathvariant="bold">x</mml:mi></mml:mrow><mml:mo stretchy="false">~</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>n</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msubsup><mml:mo>−</mml:mo><mml:msubsup><mml:mi mathvariant="bold-italic">μ</mml:mi><mml:mrow><mml:mi>n</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msubsup><mml:mo>+</mml:mo><mml:msubsup><mml:mi mathvariant="bold-italic">μ</mml:mi><mml:mrow><mml:mi>n</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msubsup><mml:mo stretchy="false">)</mml:mo><mml:msup><mml:mrow><mml:mo maxsize="1.2em" minsize="1.2em">)</mml:mo></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup><mml:mrow><mml:mo maxsize="1.623em" minsize="1.623em">]</mml:mo></mml:mrow></mml:mtd></mml:mtr><mml:mtr><mml:mtd/><mml:mtd><mml:mo>≈</mml:mo><mml:mn>2</mml:mn><mml:msup><mml:mi>ϵ</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup><mml:mo>+</mml:mo><mml:mrow><mml:mi mathvariant="double-struck">E</mml:mi></mml:mrow><mml:mrow><mml:mo maxsize="2.047em" minsize="2.047em">[</mml:mo></mml:mrow><mml:munder><mml:mo>∑</mml:mo><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:munder><mml:mo stretchy="false">(</mml:mo><mml:msubsup><mml:mrow><mml:mover><mml:mrow><mml:mi mathvariant="bold">x</mml:mi></mml:mrow><mml:mo stretchy="false">~</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>n</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msubsup><mml:mo>−</mml:mo><mml:msubsup><mml:mi mathvariant="bold-italic">μ</mml:mi><mml:mrow><mml:mi>n</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msubsup><mml:msup><mml:mo stretchy="false">)</mml:mo><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup><mml:mo>+</mml:mo><mml:munder><mml:mo>∑</mml:mo><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:munder><mml:mo stretchy="false">(</mml:mo><mml:msubsup><mml:mi mathvariant="bold-italic">μ</mml:mi><mml:mrow><mml:mi>n</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msubsup><mml:mo>−</mml:mo><mml:msubsup><mml:mrow><mml:mover><mml:mrow><mml:mi mathvariant="bold">x</mml:mi></mml:mrow><mml:mo stretchy="false">~</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>n</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msubsup><mml:msup><mml:mo stretchy="false">)</mml:mo><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup><mml:mo>+</mml:mo><mml:munder><mml:mo>∑</mml:mo><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:munder><mml:mo stretchy="false">(</mml:mo><mml:msubsup><mml:mi mathvariant="bold-italic">μ</mml:mi><mml:mrow><mml:mi>n</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msubsup><mml:mo>−</mml:mo><mml:msubsup><mml:mi mathvariant="bold-italic">μ</mml:mi><mml:mrow><mml:mi>n</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msubsup><mml:msup><mml:mo stretchy="false">)</mml:mo><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup><mml:mrow><mml:mo maxsize="2.047em" minsize="2.047em">]</mml:mo></mml:mrow></mml:mtd></mml:mtr><mml:mtr><mml:mtd/><mml:mtd><mml:mo>=</mml:mo><mml:mn>2</mml:mn><mml:msup><mml:mi>ϵ</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup><mml:mo>+</mml:mo><mml:mn>2</mml:mn><mml:msup><mml:mi mathvariant="bold-italic">σ</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup><mml:mo>+</mml:mo><mml:msup><mml:mi>ζ</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:math></disp-formula></p><p>where <inline-formula><mml:math id="inf296"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msup><mml:mi mathvariant="bold-italic">σ</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup><mml:mo>=</mml:mo><mml:mrow><mml:mi mathvariant="double-struck">E</mml:mi></mml:mrow><mml:mrow><mml:mo maxsize="1.2em" minsize="1.2em">[</mml:mo></mml:mrow><mml:munder><mml:mo>∑</mml:mo><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:munder><mml:msup><mml:mi mathvariant="bold">Σ</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msup><mml:mrow><mml:mo maxsize="1.2em" minsize="1.2em">]</mml:mo></mml:mrow></mml:mrow></mml:mstyle></mml:math></inline-formula> measures the total variance of the posterior and we omitted all second order terms. In our numerical simulations we found that the contribution of second order terms are small in most cases, except for the <italic>border-effect</italic> which captures the correlation of the decoding error in two subsequent theta cycles. The relatively strong positive correlation is explained by the bias of the decoder near the borders of the arena. Importantly, the contribution of this term is independent of theta phase and thus does not influence our analysis. We also assumed that the sample auto-correlation is near zero i.e., the samples drawn in subsequent theta cycles are independent.</p></sec></sec></app></app-group></back><sub-article article-type="editor-report" id="sa0"><front-stub><article-id pub-id-type="doi">10.7554/eLife.74058.sa0</article-id><title-group><article-title>Editor's evaluation</article-title></title-group><contrib-group><contrib contrib-type="author"><name><surname>Peyrache</surname><given-names>Adrien</given-names></name><role specific-use="editor">Reviewing Editor</role><aff><institution-wrap><institution-id institution-id-type="ror">https://ror.org/01pxwe438</institution-id><institution>McGill University</institution></institution-wrap><country>Canada</country></aff></contrib></contrib-group><related-object id="sa0ro1" object-id-type="id" object-id="10.1101/2021.12.14.472575" link-type="continued-by" xlink:href="https://sciety.org/articles/activity/10.1101/2021.12.14.472575"/></front-stub><body><p>This paper will be of interest to neuroscientists interested in predictive coding and planning. It presents a novel analysis of hippocampal place cells during exploration of an open arena. It performs a comprehensive comparison of real and synthetic data to determine which encoding model best explains population activity in the hippocampus.</p></body></sub-article><sub-article article-type="decision-letter" id="sa1"><front-stub><article-id pub-id-type="doi">10.7554/eLife.74058.sa1</article-id><title-group><article-title>Decision letter</article-title></title-group><contrib-group content-type="section"><contrib contrib-type="editor"><name><surname>Peyrache</surname><given-names>Adrien</given-names></name><role>Reviewing Editor</role><aff><institution-wrap><institution-id institution-id-type="ror">https://ror.org/01pxwe438</institution-id><institution>McGill University</institution></institution-wrap><country>Canada</country></aff></contrib></contrib-group></front-stub><body><boxed-text id="sa2-box1"><p>Our editorial process produces two outputs: (i) <ext-link ext-link-type="uri" xlink:href="https://sciety.org/articles/activity/10.1101/2021.12.14.472575">public reviews</ext-link> designed to be posted alongside <ext-link ext-link-type="uri" xlink:href="https://www.biorxiv.org/content/10.1101/2021.12.14.472575v1">the preprint</ext-link> for the benefit of readers; (ii) feedback on the manuscript for the authors, including requests for revisions, shown below. We also include an acceptance summary that explains what the editors found interesting or important about the work.</p></boxed-text><p><bold>Decision letter after peer review:</bold></p><p>Thank you for submitting your article &quot;Sampling motion trajectories during hippocampal theta sequences&quot; for consideration by <italic>eLife</italic>. Your article has been reviewed by 3 peer reviewers, and the evaluation has been overseen by a Reviewing Editor and Laura Colgin as the Senior Editor. The reviewers have opted to remain anonymous.</p><p>The reviewers have discussed their reviews with one another, and the Reviewing Editor has drafted this to help you prepare a revised submission.</p><p>Essential revisions:</p><p>1) The demonstration that place cell firing samples potential future trajectories from the current location has so far only been shown in narrow armed mazes. This study, based on hippocampal recording in rats exploring 2D environments, is thus an interesting new contribution. However, there are several aspects of the analyses that should be clarified. Most importantly, it was recently shown that future sweeps of place cells alternate left/right on a T-maze (Kay et al., 2020). Grid cells may do the same in open environments (Gardner R. J., Vollan A. Z., Moser M.-B., Moser E. I. (2019) Soc. Neurosci. Abstr. 604.13/AA9). This study would thus benefit from bringing its original framing more up to date and from analyzing whether consecutive sweeps are anticorrelated.</p><p>2) Then, it is possible that the sampling of future trajectories corresponds to the representation of multiple coexisting &quot;maps&quot; (e.g. Jackson and Redish Hippocampus 2007, Kelemen and Fenton PLoS Biol 2010), especially since the animals alternated between two different behavioural strategies, namely the search of the &quot;away&quot; location and going back to the &quot;home&quot; location. This &quot;flickering&quot; between maps could potentially explain the over-dispersion of the data, resulting in variance that could be interpreted as sampling of possible future trajectories. Additional analyses could clarify this potential bias.</p><p>3) The generative model seems to be a key aspect of the study. A lot of work has clearly been done to model as accurately as possible an animal's movement. However, it also raises the question of how critical this is for the whole analysis. Are the predictions somehow different with a simpler model, for example one that would be generated as a successor representation? It is possible that generating naturally looking trajectories this way is not possible, but it would be interesting to at least discuss why all components of the generative model are strictly necessary. In other words, to discuss why the same predictions cannot be done with a simpler model.</p><p>4) It is unclear how the diversity prediction of the DDC model was tested. Specifically, how the variance in panel 5b was computed?</p><p>5) Not all &quot;signatures&quot; were shown for all models. The study would benefit from a summary figure or table showing how each model's prediction compared to the data for each of the signatures.</p><p><italic>Reviewer #1 (Recommendations for the authors):</italic></p><p>I think this paper should be presented from the point of view that theta sweeps are already thought to represent specific potential trajectories extending from the current location, from extensive work on mazes. However, in open field data (where trajectories are not constrained to specific routes), although there are similar reports concerning replay in open fields and theta sweeps in entorhinal cortex, it is still possible that place cells actually represent the distribution of possible future trajectories, and you show that this is not the case, providing some of the first evidence that theta sweeps in open fields encode specific trajectories.</p><p>I did not find it helpful that the paper is framed as evaluating different possible neural representations of uncertainty, and I don't think the rejection of the product or DDC schemes for doing this necessarily tells us much about whether or not they are used in situations where the brain might in fact represent a probability distribution.</p><p><italic>Reviewer #3 (Recommendations for the authors):</italic></p><p>Please provide more details how the increased diversity prediction of the DDC was tested. How is the diversity decoded from the population? What do the cumulative probabilities on Figure 5 subplot b show exactly and why and how can they show the increased diversity? The authors may want to provide some intuition/more explanation about what the decoded SD reflects in Figure 5 b, d and why it reflects the diversity and not the uncertainty which would increase in the late cycles for the rest of the models too.</p><p>We assume all analyses (&quot;signatures&quot;) were applied to all models but not all of the results are shown. We appreciate that the step-by-step approach eliminating one model at a time makes for a simpler story but a figure with all results would seem to be very informative: e.g. are the other signatures that contradict the product scheme?</p><p>Presentation: we did not understand the cumulative probability panels and how they are related to the text. E.g. lines 249-252 and Figure 5b, same for Figure 6. Maybe it would be more intuitive to show the pdf instead of the cdf? But even then, the x-axis and general interpretation remains unclear to us.</p><p>Line 333: How do the results suggest efficient planning in the hippocampus? It suggests probabilistic, i.e. close to statistically optimal computations, but the authors should provide more details why they think it is also efficient.</p><p>[Editors’ note: further revisions were suggested prior to acceptance, as described below.]</p><p>Thank you for resubmitting your work entitled &quot;Sampling motion trajectories during hippocampal theta sequences&quot; for further consideration by <italic>eLife</italic>. Your revised article has been evaluated by Laura Colgin (Senior Editor) and a Reviewing Editor.</p><p>The manuscript has been improved but reviewer #2 has one remaining issue that needs to be addressed, as outlined below.</p><p><italic>Reviewer #1 (Recommendations for the authors):</italic></p><p>The authors have answered my main concerns</p><p><italic>Reviewer #2 (Recommendations for the authors):</italic></p><p>In this revision, the authors have made a number of improvements to what was already a systematic, rigorous examination of an important issue. The control analysis ruling out excess variance is due to different place maps across navigation-to-goal and random foraging further enhances confidence in the results, and is additionally supported by a similar analysis in Brad Pfeiffer's paper that just came out (PMID: 35396328).</p><p>My one remaining hesitation with this paper is the one I brought up in my previous review but perhaps didn't explain clearly, so I will try again. My understanding of the core logic of the paper is that the authors first establish what the signatures are of the coding schemes they wish to distinguish, by implementing these schemes in a series of models that generate synthetic spiking data. Then, they test to what extent those signatures exist in real data, and draw inferences from comparison with the simulated results.</p><p>I think this is a powerful approach and am completely on board with it. However, it does raise an overall question of how robust the simulation results are: what components of the simulation are necessary and sufficient for the results? How sensitive are the results to specific parameter choices? I appreciate and agree with the authors' argument that the Kalman filter is an appropriate and relatively minimal way to model the animal's uncertainty about its own location. But it is not obvious to me what modeling the animal's uncertainty about its position contributes to the results in the first place. Would you get the same simulated signatures if all you had was a probability distribution of expected future trajectories given true current location, and then applied the various coding schemes (encoding MAP trajectory, sampling, etc)?</p><p>Hence, my suggestion of using the SR to obtain such trajectory distributions from the animal's behavioral data, but really any approach that estimates these distributions from the data would help address my concern. This feels important, because comparison between these different generative models would give a sense of what data sets/behavioral tasks/task conditions should show the predicted signatures. Ultimately we don't want to just understand what happens in the Pfeiffer and Foster 2013 data set the authors analyze, but have some idea of what to expect say, in the dark with high uncertainty about current location, or on armed mazes where possible futures are highly constrained.</p><p>I realize that the paper is already extensive and thorough, but unless I'm off base with this intuition or misunderstand the authors' argument, it could actually simplify their paper if the same results obtain with a simpler way of generating probability distributions over trajectories. If they don't obtain, then this is important to point out, because of the resulting prediction that theta sequences ought to have different spiking statistics in high vs low uncertainty-about-current-position conditions.</p><p><italic>Reviewer #3 (Recommendations for the authors):</italic></p><p>The authors have addressed all my concerns. They have added an interesting new analysis as the result of the reviewer suggestions. Congratulations to the authors for an impressive piece of work.</p><p>In the final version, I'd like to encourage the authors to better explain the cause of the bias towards similar directions described in line 404. I didn't understand it. Please elaborate.</p></body></sub-article><sub-article article-type="reply" id="sa2"><front-stub><article-id pub-id-type="doi">10.7554/eLife.74058.sa2</article-id><title-group><article-title>Author response</article-title></title-group></front-stub><body><disp-quote content-type="editor-comment"><p>Essential revisions:</p><p>1) The demonstration that place cell firing samples potential future trajectories from the current location has so far only been shown in narrow armed mazes. This study, based on hippocampal recording in rats exploring 2D environments, is thus an interesting new contribution. However, there are several aspects of the analyses that should be clarified. Most importantly, it was recently shown that future sweeps of place cells alternate left/right on a T-maze (Kay et al., 2020). Grid cells may do the same in open environments (Gardner R. J., Vollan A. Z., Moser M.-B., Moser E. I. (2019) Soc. Neurosci. Abstr. 604.13/AA9). This study would thus benefit from bringing its original framing more up to date and from analyzing whether consecutive sweeps are anticorrelated.</p></disp-quote><p>We thank the reviewers for encouraging us to analyse the autocorrelation structure of the theta sequences. We performed the suggested analysis and our results confirm and extend previous findings that trajectories encoded during theta sequences are indeed anti-correlated in 2-dimensional environments. Since this result also underscores one of the main messages of the paper, i.e., that the brain is able to perform probabilistic computations efficiently: correlated samples require a higher number of samples to represent a probability distribution, and therefore decorrelation can contribute to a code that requires less samples and consequently less time to perform more accurate inference. We present these results on a new main figure (Figure 7) and associated section in the main text (Signature of efficient sampling:generative cycling, line ~382-425). We also added a corresponding supplemenal figure (Figure 7 figure supplement 1).</p><disp-quote content-type="editor-comment"><p>2) Then, it is possible that the sampling of future trajectories corresponds to the representation of multiple coexisting &quot;maps&quot; (e.g. Jackson and Redish Hippocampus 2007, Kelemen and Fenton PLoS Biol 2010), especially since the animals alternated between two different behavioural strategies, namely the search of the &quot;away&quot; location and going back to the &quot;home&quot; location. This &quot;flickering&quot; between maps could potentially explain the over-dispersion of the data, resulting in variance that could be interpreted as sampling of possible future trajectories. Additional analyses could clarify this potential bias.</p></disp-quote><p>Thank you for raising this issue. We performed the analysis to assess the differences in the behaviour and the spatial tuning of the recorded neurons between the two task phases (home versus away runs). Although we found significant differences in spatial tuning of a minority of the cells, these differences were relatively small and thus we do not believe that this flickering could substantially contribute to the overdispersion of the data. We included this analysis as a supplemental figure (Figure 6 figure supplement 2)</p><disp-quote content-type="editor-comment"><p>3) The generative model seems to be a key aspect of the study. A lot of work has clearly been done to model as accurately as possible an animal's movement. However, it also raises the question of how critical this is for the whole analysis. Are the predictions somehow different with a simpler model, for example one that would be generated as a successor representation? It is possible that generating naturally looking trajectories this way is not possible, but it would be interesting to at least discuss why all components of the generative model are strictly necessary. In other words, to discuss why the same predictions cannot be done with a simpler model.</p></disp-quote><p>The generality of the signatures follows from the fact that we derived them from the fundamental properties of the encoding schemes, not the generative model. The sole criterion for the generative model was to produce synthetic trajectories that match experimental trajectories well (Figure 3, figure supplement 2) and to enable simple inference in the model (Figure 3, figure supplement 1). We tested the robustness of signatures using both idealized test data (Figure 4, figure supplement 1c-d, Figure 5, figure supplement 1) and our simulated hippocampal model (Figure 4c, Figure 5B-c, Fig6b-g). We added a paragraph discussing the choice of the generative model and clarified the relationship between our model and the successor representation framework in the discussion (lines 486-490).</p><disp-quote content-type="editor-comment"><p>4) It is unclear how the diversity prediction of the DDC model was tested. Specifically, how the variance in panel 5b was computed?</p></disp-quote><p>Thank you for raising the issue of clarity of presentation. We extended the description of DDC decoding in the main text (lines 268-273) and added a reference to the Methods section where the mathematical details are provided (Equations 17-18).</p><p>Briefly, In the DDC scheme we assumed that the hippocampal population activity at each time point encodes the probability distribution using the overlap between the neuronal basis functions and the target distribution. Just as we can use a static Bayesian decoder to decode the mean of the encoded location when a single position is encoded (as in the mean encoding scheme), we can also decode higher moments (e.g., variance) from a set of spikes when a full distribution is represented in the population activity (as in the product or the DDC schemes). In this case, we made a further assumption, that an isotropic Gaussian distribution was encoded, and used a maximum likelihood estimation to infer the three parameters of the encoded distribution (x and y position as well as the standard deviation).</p><disp-quote content-type="editor-comment"><p>5) Not all &quot;signatures&quot; were shown for all models. The study would benefit from a summary figure or table showing how each model's prediction compared to the data for each of the signatures.</p></disp-quote><p>We added a novel supplemental figure (Figure 5—figure supplement 3.) showing all signatures for all Models.</p><disp-quote content-type="editor-comment"><p>Reviewer #1 (Recommendations for the authors):</p><p>I think this paper should be presented from the point of view that theta sweeps are already thought to represent specific potential trajectories extending from the current location, from extensive work on mazes. However, in open field data (where trajectories are not constrained to specific routes), although there are similar reports concerning replay in open fields and theta sweeps in entorhinal cortex, it is still possible that place cells actually represent the distribution of possible future trajectories, and you show that this is not the case, providing some of the first evidence that theta sweeps in open fields encode specific trajectories.</p></disp-quote><p>We thank the reviewer for this suggestion. We added a new paragraph (lines 74-88) to the introduction to clarify that one of the novel contributions of the paper is the generalization of previous intuitions, largely based on work on mazes, to open field environments.</p><disp-quote content-type="editor-comment"><p>I did not find it helpful that the paper is framed as evaluating different possible neural representations of uncertainty, and I don't think the rejection of the product or DDC schemes for doing this necessarily tells us much about whether or not they are used in situations where the brain might in fact represent a probability distribution.</p></disp-quote><p>We did not aim to suggest that our results exclude the viability of the product or DDC schemes in other brain regions or at different temporal scales. We clarified this point in the discussion (line 556).</p><disp-quote content-type="editor-comment"><p>Reviewer #3 (Recommendations for the authors):</p><p>Please provide more details how the increased diversity prediction of the DDC was tested. How is the diversity decoded from the population? What do the cumulative probabilities on Figure 5 subplot b show exactly and why and how can they show the increased diversity? The authors may want to provide some intuition/more explanation about what the decoded SD reflects in Figure 5 b, d and why it reflects the diversity and not the uncertainty which would increase in the late cycles for the rest of the models too.</p></disp-quote><p>We rewrote the text (lines ~264-273) and the legend of the corresponding figures to clarify that we use the decoded SD and not the diversity across neurons to test the DDC code, and that the CDFs are calculated across theta cycles. We summarise the answer to the question below.</p><p>In the DDC scheme the firing rate of neurons is defined by the overlap between the target distribution and their tuning functions. Intuitively, this scheme leads to a code where the diversity of the coactive neurons increases with uncertainty. This increase in the diversity provides a useful intuition about how neuronal activities change with uncertainty in this scheme. We did not aim to decode diversity nor to directly evaluate how diversity changes within a theta cycle. Instead we aimed at directly decoding the summary statistics of the probability distribution that had been encoded in the population activity. To this end, we used the standard deviation (SD) of the distribution to quantify the uncertainty (large SD = large uncertainty, implying large diversity as well).</p><p>To achieve this, we built a maximum likelihood decoder that finds the most likely parameters (mean and SD) of the encoded distribution. We applied this decoder to early, mid, and late spikes in each theta cycle recorded either using simulated data (Figure 5B-d) or experimental data (Figure 5e-g). The plots in Figure 5b and e show the results of this decoding process. Specifically, the three curves in Figure 5b (some of them are overlapping) show the distribution of the standard deviation values decoded from the observed spikes in the three different theta phases (early, mid and late) in the form of cumulative distribution functions (CDF). An increased uncertainty of the encoded distribution would be reflected by a rightward shift of the distribution. Importantly, the three CDF curves completely overlap for the sampling and the mean schemes as these schemes do not represent uncertainty in the instantaneous population activity. Instead, these schemes represent a single trajectory throughout the whole theta cycle.</p><p>Shift of CDF is only present in the DDC scheme (green), thus indicating that this measure displays specificity to DDC.</p><disp-quote content-type="editor-comment"><p>We assume all analyses (&quot;signatures&quot;) were applied to all models but not all of the results are shown. We appreciate that the step-by-step approach eliminating one model at a time makes for a simpler story but a figure with all results would seem to be very informative: e.g. are the other signatures that contradict the product scheme?</p></disp-quote><p>We agree with the Reviewer that the signatures not shown could also be informative. We thus prepared a supplementary figure to show all signatures for all encoding schemes (Figure 5—figure supplement 3).</p><p>Further to the patterns observed before, our analysis also revealed that the DDC inspired decoding of SD grows within a theta cycle not only for DDC but for the product scheme as well. This can be taken as further evidence against this encoding scheme (Figure S9a-b). The EV-index is positive for the product scheme and negative for the DDC scheme (Figure S9c). We explain the positivity in the case of the product scheme by the fact that the firing rate is the lowest for the most uncertain future predictions inflating the variability at late theta cycles. In the case of DDC scheme the EVindex is negative as the distributions encoded in subsequent theta cycles are similar.</p><p>However, we would like to add a cautionary note. The EV-index and the DDC decoded SD were not designed to work consistently for all encoding schemes and thus there is no theoretically solid justification for their specificity and robustness.</p><p>For example the positivity of the EV-index in the case of the product code may not reflect true variability of the encoded locations but the large decoding noise due to the low firing rate. Indeed, the magnitude of the EV-index decreases substantially for the product code if we consider only high spike count theta cycles (Figure 5—figure supplement 3c). Consequently, the value of these measures taken on simulated datasets could be misleading and may not generalise well to the real situation. Thus we prefer to keep this figure in the supplementary material.</p><disp-quote content-type="editor-comment"><p>Presentation: we did not understand the cumulative probability panels and how they are related to the text. E.g. lines 249-252 and Figure 5b, same for Figure 6. Maybe it would be more intuitive to show the pdf instead of the cdf? But even then, the x-axis and general interpretation remains unclear to us.</p></disp-quote><p>To test the DDC code we assumed that a probability distribution is encoded in each moment by the activity of the neuron. We decoded the moments (mean and SD) of this distribution in each theta cycle for the three theta phases (early, mid and late) separately using a maximum likelihood decoder. As a result of this decoding process we obtained three distributions of the decoded SD values (three SD values for each theta cycle, corresponding to early mid and late phase) and plotted these distributions separately as three CDF curves with the SD on the xaxis. The shift of these curves along the x-axis indicate differences in the magnitude of the represented uncertainty.</p><p>The interpretation of the CDF curves in Fig6b,d,h are similar.</p><p>We decided to show the distribution using the CDF as relatively small, but significant differences between the distributions are more apparent in the CDF than in the PDF (Figure R1).</p><p>We rewrote the description of these panels in the text and in the legend to clarify that CDFs are calculated across theta cycles (line ~278).</p><disp-quote content-type="editor-comment"><p>Line 333: How do the results suggest efficient planning in the hippocampus? It suggests probabilistic, i.e. close to statistically optimal computations, but the authors should provide more details why they think it is also efficient.</p></disp-quote><p>In the revised manuscript we clarified our wording and use the word <italic>efficient</italic> solely when we refer to anti-correlated samples.</p><p>[Editors’ note: further revisions were suggested prior to acceptance, as described below.]</p><disp-quote content-type="editor-comment"><p>The manuscript has been improved but reviewer #2 has one remaining issue that needs to be addressed, as outlined below.</p></disp-quote><p>We conducted additional simulations and analysis to address the remaining comment of reviewer #2. Our results demonstrated that our analysis is robust to the way we generate synthetic data and thus the signatures we derived can be used to discriminate the alternative coding schemes. The results of this analysis in included in the new version of the paper.</p><p>We provide a detailed answer to the Reviewers’ comments below.</p><disp-quote content-type="editor-comment"><p>Reviewer #2 (Recommendations for the authors):</p><p>In this revision, the authors have made a number of improvements to what was already a systematic, rigorous examination of an important issue. The control analysis ruling out excess variance is due to different place maps across navigation-to-goal and random foraging further enhances confidence in the results, and is additionally supported by a similar analysis in Brad Pfeiffer's paper that just came out (PMID: 35396328).</p></disp-quote><p>We thank the Reviewer for drawing our attention to this recent paper which we included in our reference list.</p><disp-quote content-type="editor-comment"><p>My one remaining hesitation with this paper is the one I brought up in my previous review but perhaps didn't explain clearly, so I will try again. My understanding of the core logic of the paper is that the authors first establish what the signatures are of the coding schemes they wish to distinguish, by implementing these schemes in a series of models that generate synthetic spiking data. Then, they test to what extent those signatures exist in real data, and draw inferences from comparison with the simulated results.</p><p>I think this is a powerful approach and am completely on board with it. However, it does raise an overall question of how robust the simulation results are: what components of the simulation are necessary and sufficient for the results? How sensitive are the results to specific parameter choices? I appreciate and agree with the authors' argument that the Kalman filter is an appropriate and relatively minimal way to model the animal's uncertainty about its own location. But it is not obvious to me what modeling the animal's uncertainty about its position contributes to the results in the first place. Would you get the same simulated signatures if all you had was a probability distribution of expected future trajectories given true current location, and then applied the various coding schemes (encoding MAP trajectory, sampling, etc)?</p></disp-quote><p>The reviewer suggested that representation of uncertainty associated with the current position of the animal might not be necessary to interpret experimental data. Indeed, the key to our analysis is the change in uncertainty along the planned trajectory of the animal that is less sensitive to the level of uncertainty at any given time. Accordingly, the trajectory distribution that is using the model-free alternative, which lacks the representation of current uncertainty is expected to produce similar results than the generative model that explicitly represents uncertainty in current beliefs. To corroborate our expectations, we designed a minimalist approach to generate hypothetical future trajectories without explicitly modelling the animal’s subjective uncertainty and demonstrated that our signatures robustly discriminate the different coding schemes.</p><disp-quote content-type="editor-comment"><p>Hence, my suggestion of using the SR to obtain such trajectory distributions from the animal's behavioral data, but really any approach that estimates these distributions from the data would help address my concern. This feels important, because comparison between these different generative models would give a sense of what data sets/behavioral tasks/task conditions should show the predicted signatures. Ultimately we don't want to just understand what happens in the Pfeiffer and Foster 2013 data set the authors analyze, but have some idea of what to expect say, in the dark with high uncertainty about current location, or on armed mazes where possible futures are highly constrained.</p></disp-quote><p>We thank the reviewer for clarifying this idea. Indeed, we agree that paper benefits from the demonstration that the signatures of coding schemes are not sensitive to the specific properties of the generative model of motion trajectories.</p><p>Therefore we designed a minimal, model-free approach to obtain trajectory distributions directly from the animal’s behavioral data. Specifically, we collected trajectory distribution for a particular target point on the real motion trajectory we first sampled multiple real trajectory segments with similar starting speed. Next, we aligned the start of these trajectory segments with the start of the target trajectory by shifting and rotating the sampled segments. This alignment resulted in a bouquet of trajectories for each actual point along the motion trajectory that outlined an empirical distribution of hypothetical future positions and speeds (Figure 7—figure supplement 2a).</p><p>Next we used the empirical, model-free distributions of motion trajectories to generate spiking data using the four different coding schemes in the same way as we did it for model-based trajectories. Next, we repeated identical analyses that were performed with the original, model-based synthetic trajectories. We found that the population gain, the increase in the DDC-decoded SD and the sampling index were potent signatures to discriminate these alternative encoding schemes (Figure 7—figure supplement 2c-g). We concluded that our results are robust against changes in the way distributions of planned trajectories are constructed. We present the results of this new analysis in a novel subsection of the Results (Analysis of signatures using model-free trajectories, line 430) and in a novel Supplemental Figure (Figure 7—figure supplement).</p><disp-quote content-type="editor-comment"><p>I realize that the paper is already extensive and thorough, but unless I'm off base with this intuition or misunderstand the authors' argument, it could actually simplify their paper if the same results obtain with a simpler way of generating probability distributions over trajectories. If they don't obtain, then this is important to point out, because of the resulting prediction that theta sequences ought to have different spiking statistics in high vs low uncertainty-about-current-position conditions.</p></disp-quote><p>We had a hard time deciding how to include the new, model-free analysis into the paper. We decided to present it at the end of the Results section as a separate subsection and on a new Figure Supplement. Our choice was based on the following arguments. First, we consider the presentation of the generative model of planning an insightful ingredient of the paper, as the readers are provided with new ways of thinking about hippocampal theta sequences and therefore has the perspective to inspire the design of new experiments in the future.</p><p>1. Experimental data suggests that the hippocampus is involved in model-based planning. Our original approach, implementing a model based method to generate synthetic trajectories, is thus more similar to what might be actually implemented by the hippocampal circuitry than the new, model-free alternative.</p><p>2. We believe that representing subjective uncertainty in a self-consistent way using a probabilistic model is an important principle used in many artificial systems. This idea has been also applied recently to neuronal systems and gained support from a wide range of studies, albeit from different domains of cognition than the one studied here.</p><p>3. Our generative model was a key component of our framework providing crucial insights about the variability of hippocampal theta sequences. In particular, we realized that the subjective uncertainty of the animal is an important and often neglected factor shaping hippocampal representations. In our work, this is best reflected in the relationship between the decoding error, the subjective uncertainty, and the expected change in the posterior mean that allowed us to derive the sampling index and in the way we can explain the source of the bias in the cycling index (Figure 7e).</p><p>Second, we decided to present the keep the original logic of the paper and present the main findings first using the original, generative model and only describe the model-free approach at the end of the manuscript as a control simulation. Alternatively, we could have introduce the two approaches in parallel around Figure 3 and demonstrate all results using both alternatives, but we were afraid that this would break the narrative of the main text and confuse the readers.</p><disp-quote content-type="editor-comment"><p>Reviewer #3 (Recommendations for the authors):</p><p>The authors have addressed all my concerns. They have added an interesting new analysis as the result of the reviewer suggestions. Congratulations to the authors for an impressive piece of work.</p><p>In the final version, I'd like to encourage the authors to better explain the cause of the bias towards similar directions described in line 404. I didn't understand it. Please elaborate.</p></disp-quote><p>We thank the Reviewer for their encouraging words.</p><p>We rewrote the corresponding section of the Results (lines 402-409) and the caption of Figure 7e to clarify the source of this bias.</p><p>The bias can be best understood if we consider that the true position of the animal in room coordinates that we can directly observe can sometimes be different from the animal’s own position estimate. Although this difference may be quite small (it is typically not larger than a few centimeters in our synthetic dataset in a 2×2 m arena), the important point is that this subjective position represent the animal’s best guess about its own position and hypothetical trajectories will alternate around this subjective position during generative cycling. Even if the subsequent trajectories are alternating around the subjective position they might fall into the same side of the true position if the two are different (Figure 7e).</p></body></sub-article></article>