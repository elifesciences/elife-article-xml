<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD with MathML3 v1.2 20190208//EN"  "JATS-archivearticle1-mathml3.dtd"><article article-type="research-article" dtd-version="1.2" xmlns:ali="http://www.niso.org/schemas/ali/1.0/" xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink"><front><journal-meta><journal-id journal-id-type="nlm-ta">elife</journal-id><journal-id journal-id-type="publisher-id">eLife</journal-id><journal-title-group><journal-title>eLife</journal-title></journal-title-group><issn pub-type="epub" publication-format="electronic">2050-084X</issn><publisher><publisher-name>eLife Sciences Publications, Ltd</publisher-name></publisher></journal-meta><article-meta><article-id pub-id-type="publisher-id">63405</article-id><article-id pub-id-type="doi">10.7554/eLife.63405</article-id><article-categories><subj-group subj-group-type="display-channel"><subject>Research Article</subject></subj-group><subj-group subj-group-type="heading"><subject>Neuroscience</subject></subj-group></article-categories><title-group><article-title>Influence of sensory modality and control dynamics on human path integration</article-title></title-group><contrib-group><contrib contrib-type="author" corresp="yes" equal-contrib="yes" id="author-208490"><name><surname>Stavropoulos</surname><given-names>Akis</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">https://orcid.org/0000-0003-4613-9422</contrib-id><email>ges6@nyu.edu</email><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="fn" rid="equal-contrib1">†</xref><xref ref-type="fn" rid="con1"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" equal-contrib="yes" id="author-211035"><name><surname>Lakshminarasimhan</surname><given-names>Kaushik J</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">https://orcid.org/0000-0003-3932-2616</contrib-id><xref ref-type="aff" rid="aff2">2</xref><xref ref-type="fn" rid="equal-contrib1">†</xref><xref ref-type="other" rid="fund2"/><xref ref-type="other" rid="fund3"/><xref ref-type="fn" rid="con2"/><xref ref-type="fn" rid="conf2"/></contrib><contrib contrib-type="author" id="author-66060"><name><surname>Laurens</surname><given-names>Jean</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">https://orcid.org/0000-0002-9101-2802</contrib-id><xref ref-type="aff" rid="aff3">3</xref><xref ref-type="fn" rid="con3"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" corresp="yes" id="author-172393"><name><surname>Pitkow</surname><given-names>Xaq</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">https://orcid.org/0000-0001-6376-329X</contrib-id><email>xaq@rice.edu</email><xref ref-type="aff" rid="aff4">4</xref><xref ref-type="aff" rid="aff5">5</xref><xref ref-type="aff" rid="aff6">6</xref><xref ref-type="other" rid="fund6"/><xref ref-type="other" rid="fund7"/><xref ref-type="other" rid="fund5"/><xref ref-type="fn" rid="con4"/><xref ref-type="fn" rid="conf2"/></contrib><contrib contrib-type="author" corresp="yes" id="author-138210"><name><surname>Angelaki</surname><given-names>Dora</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">https://orcid.org/0000-0002-9650-8962</contrib-id><email>da93@nyu.edu</email><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="aff" rid="aff5">5</xref><xref ref-type="aff" rid="aff7">7</xref><xref ref-type="other" rid="fund1"/><xref ref-type="other" rid="fund4"/><xref ref-type="other" rid="fund5"/><xref ref-type="fn" rid="con5"/><xref ref-type="fn" rid="conf2"/></contrib><aff id="aff1"><label>1</label><institution-wrap><institution-id institution-id-type="ror">https://ror.org/0190ak572</institution-id><institution>Center for Neural Science, New York University</institution></institution-wrap><addr-line><named-content content-type="city">New York</named-content></addr-line><country>United States</country></aff><aff id="aff2"><label>2</label><institution-wrap><institution-id institution-id-type="ror">https://ror.org/00hj8s172</institution-id><institution>Center for Theoretical Neuroscience, Columbia University</institution></institution-wrap><addr-line><named-content content-type="city">New York</named-content></addr-line><country>United States</country></aff><aff id="aff3"><label>3</label><institution-wrap><institution-id institution-id-type="ror">https://ror.org/00ygt2y02</institution-id><institution>Ernst Strüngmann Institute for Neuroscience</institution></institution-wrap><addr-line><named-content content-type="city">Frankfurt</named-content></addr-line><country>Germany</country></aff><aff id="aff4"><label>4</label><institution-wrap><institution-id institution-id-type="ror">https://ror.org/008zs3103</institution-id><institution>Department of Electrical and Computer Engineering, Rice University</institution></institution-wrap><addr-line><named-content content-type="city">Houston</named-content></addr-line><country>United States</country></aff><aff id="aff5"><label>5</label><institution-wrap><institution-id institution-id-type="ror">https://ror.org/02pttbw34</institution-id><institution>Department of Neuroscience, Baylor College of Medicine</institution></institution-wrap><addr-line><named-content content-type="city">Houston</named-content></addr-line><country>United States</country></aff><aff id="aff6"><label>6</label><institution-wrap><institution-id institution-id-type="ror">https://ror.org/02pttbw34</institution-id><institution>Center for Neuroscience and Artificial Intelligence, Baylor College of Medicine</institution></institution-wrap><addr-line><named-content content-type="city">Houston</named-content></addr-line><country>United States</country></aff><aff id="aff7"><label>7</label><institution-wrap><institution-id institution-id-type="ror">https://ror.org/0190ak572</institution-id><institution>Tandon School of Engineering, New York University</institution></institution-wrap><addr-line><named-content content-type="city">New York</named-content></addr-line><country>United States</country></aff></contrib-group><contrib-group content-type="section"><contrib contrib-type="editor"><name><surname>Peyrache</surname><given-names>Adrien</given-names></name><role>Reviewing Editor</role><aff><institution-wrap><institution-id institution-id-type="ror">https://ror.org/01pxwe438</institution-id><institution>McGill University</institution></institution-wrap><country>Canada</country></aff></contrib><contrib contrib-type="senior_editor"><name><surname>Ivry</surname><given-names>Richard B</given-names></name><role>Senior Editor</role><aff><institution-wrap><institution-id institution-id-type="ror">https://ror.org/01an7q238</institution-id><institution>University of California, Berkeley</institution></institution-wrap><country>United States</country></aff></contrib></contrib-group><author-notes><fn fn-type="con" id="equal-contrib1"><label>†</label><p>These authors contributed equally to this work</p></fn></author-notes><pub-date date-type="publication" publication-format="electronic"><day>18</day><month>02</month><year>2022</year></pub-date><pub-date pub-type="collection"><year>2022</year></pub-date><volume>11</volume><elocation-id>e63405</elocation-id><history><date date-type="received" iso-8601-date="2020-09-23"><day>23</day><month>09</month><year>2020</year></date><date date-type="accepted" iso-8601-date="2021-12-11"><day>11</day><month>12</month><year>2021</year></date></history><pub-history><event><event-desc>This manuscript was published as a preprint at bioRxiv.</event-desc><date date-type="preprint" iso-8601-date="2020-09-23"><day>23</day><month>09</month><year>2020</year></date><self-uri content-type="preprint" xlink:href="https://doi.org/10.1101/2020.09.21.307256"/></event></pub-history><permissions><copyright-statement>© 2022, Stavropoulos et al</copyright-statement><copyright-year>2022</copyright-year><copyright-holder>Stavropoulos et al</copyright-holder><ali:free_to_read/><license xlink:href="http://creativecommons.org/licenses/by/4.0/"><ali:license_ref>http://creativecommons.org/licenses/by/4.0/</ali:license_ref><license-p>This article is distributed under the terms of the <ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/licenses/by/4.0/">Creative Commons Attribution License</ext-link>, which permits unrestricted use and redistribution provided that the original author and source are credited.</license-p></license></permissions><self-uri content-type="pdf" xlink:href="elife-63405-v1.pdf"/><self-uri content-type="figures-pdf" xlink:href="elife-63405-figures-v1.pdf"/><abstract><p>Path integration is a sensorimotor computation that can be used to infer latent dynamical states by integrating self-motion cues. We studied the influence of sensory observation (visual/vestibular) and latent control dynamics (velocity/acceleration) on human path integration using a novel motion-cueing algorithm. Sensory modality and control dynamics were both varied randomly across trials, as participants controlled a joystick to steer to a memorized target location in virtual reality. Visual and vestibular steering cues allowed comparable accuracies only when participants controlled their acceleration, suggesting that vestibular signals, on their own, fail to support accurate path integration in the absence of sustained acceleration. Nevertheless, performance in all conditions reflected a failure to fully adapt to changes in the underlying control dynamics, a result that was well explained by a bias in the dynamics estimation. This work demonstrates how an incorrect internal model of control dynamics affects navigation in volatile environments in spite of continuous sensory feedback.</p></abstract><kwd-group kwd-group-type="author-keywords"><kwd>navigation</kwd><kwd>path integration</kwd><kwd>control dynamics</kwd><kwd>motion dynamics</kwd><kwd>optic flow</kwd><kwd>vestibular</kwd></kwd-group><kwd-group kwd-group-type="research-organism"><title>Research organism</title><kwd>Human</kwd></kwd-group><funding-group><award-group id="fund1"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/100000135</institution-id><institution>NIH Blueprint for Neuroscience Research</institution></institution-wrap></funding-source><award-id>NIH DC007620</award-id><principal-award-recipient><name><surname>Angelaki</surname><given-names>Dora</given-names></name></principal-award-recipient></award-group><award-group id="fund2"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/100000001</institution-id><institution>National Science Foundation</institution></institution-wrap></funding-source><award-id>NeuroNex DBI-1707398</award-id><principal-award-recipient><name><surname>Lakshminarasimhan</surname><given-names>Kaushik J</given-names></name></principal-award-recipient></award-group><award-group id="fund3"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/501100000324</institution-id><institution>Gatsby Charitable Foundation</institution></institution-wrap></funding-source><principal-award-recipient><name><surname>Lakshminarasimhan</surname><given-names>Kaushik J</given-names></name></principal-award-recipient></award-group><award-group id="fund4"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/100000893</institution-id><institution>Simons Foundation</institution></institution-wrap></funding-source><award-id>324143</award-id><principal-award-recipient><name><surname>Pitkow</surname><given-names>Xaq</given-names></name><name><surname>Angelaki</surname><given-names>Dora</given-names></name></principal-award-recipient></award-group><award-group id="fund5"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/100000002</institution-id><institution>National Institutes of Health</institution></institution-wrap></funding-source><award-id>R01NS120407</award-id><principal-award-recipient><name><surname>Pitkow</surname><given-names>Xaq</given-names></name><name><surname>Angelaki</surname><given-names>Dora</given-names></name></principal-award-recipient></award-group><award-group id="fund6"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/100000001</institution-id><institution>National Science Foundation</institution></institution-wrap></funding-source><award-id>1707400</award-id><principal-award-recipient><name><surname>Pitkow</surname><given-names>Xaq</given-names></name></principal-award-recipient></award-group><award-group id="fund7"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/100000001</institution-id><institution>National Science Foundation</institution></institution-wrap></funding-source><award-id>1552868</award-id><principal-award-recipient><name><surname>Pitkow</surname><given-names>Xaq</given-names></name></principal-award-recipient></award-group><funding-statement>The funders had no role in study design, data collection and interpretation, or the decision to submit the work for publication.</funding-statement></funding-group><custom-meta-group><custom-meta specific-use="meta-only"><meta-name>Author impact statement</meta-name><meta-value>Human path integration accuracy is strongly influenced by the underlying control dynamics, but less so when visual, rather than vestibular, feedback is available.</meta-value></custom-meta></custom-meta-group></article-meta></front><body><sec id="s1" sec-type="intro"><title>Introduction</title><p>Imagine driving a car onto an icy road, where steering dynamics can change rapidly. To avoid crashing, one must rapidly infer the new dynamics and respond appropriately to keep the car on the desired path. Conversely, when you leave an ice patch, control dynamics change again, compelling you to re-adjust your steering. The quality of sensory cues may also vary depending on environmental factors (e.g. reduced visibility in fog or twilight, sub-threshold vestibular stimulation under near-constant travel velocity). Humans are adept at using time-varying sensory cues to adapt quickly to a wide range of latent control dynamics in volatile environments. However, the relative contributions of different sensory modalities and the precise impact of latent control dynamics on goal-directed navigation remain poorly understood. Here, we study this in the context of path integration.</p><p>Path integration, a natural computation in which the brain uses dynamic sensory cues to infer the evolution of latent world states to continuously maintain a self-position estimate, has been studied in humans, but past experimental paradigms imposed several constraints. First, in many tasks, the motion was passive and/or restricted along predetermined, often one-dimensional (1D), trajectories (<xref ref-type="bibr" rid="bib25">Klatzky, 1998</xref>; <xref ref-type="bibr" rid="bib21">Jürgens and Becker, 2006</xref>; <xref ref-type="bibr" rid="bib38">Petzschner and Glasauer, 2011</xref>; <xref ref-type="bibr" rid="bib9">Campos et al., 2012</xref>; <xref ref-type="bibr" rid="bib49">Tramper and Medendorp, 2015</xref>). Second, unlike time-varying actions that characterize navigation under natural conditions, participants’ responses were often reduced to single, binary end-of-trial decisions (<xref ref-type="bibr" rid="bib48">ter Horst et al., 2015</xref>; <xref ref-type="bibr" rid="bib11">Chrastil et al., 2016</xref>; <xref ref-type="bibr" rid="bib26">Koppen et al., 2019</xref>). Third, even studies that explored contributions of different sensory modalities in naturalistic settings failed to properly disentangle vestibular from motor cues generated during active locomotion (<xref ref-type="bibr" rid="bib23">Kearns et al., 2002</xref>; <xref ref-type="bibr" rid="bib8">Campos et al., 2010</xref>; <xref ref-type="bibr" rid="bib5">Bergmann et al., 2011</xref>; <xref ref-type="bibr" rid="bib10">Chen et al., 2017</xref>; <xref ref-type="bibr" rid="bib41">Schubert et al., 2012</xref>; <xref ref-type="bibr" rid="bib35">Péruch et al., 1999</xref>; <xref ref-type="bibr" rid="bib36">Péruch et al., 2005</xref>). Furthermore, varying constraints have presumably resulted in inconsistent findings on the contribution of vestibular cues to path integration (<xref ref-type="bibr" rid="bib21">Jürgens and Becker, 2006</xref>; <xref ref-type="bibr" rid="bib8">Campos et al., 2010</xref>; <xref ref-type="bibr" rid="bib48">ter Horst et al., 2015</xref>; <xref ref-type="bibr" rid="bib49">Tramper and Medendorp, 2015</xref>; <xref ref-type="bibr" rid="bib26">Koppen et al., 2019</xref>; <xref ref-type="bibr" rid="bib12">Chrastil et al., 2019</xref>; <xref ref-type="bibr" rid="bib16">Glasauer et al., 1994</xref>; <xref ref-type="bibr" rid="bib43">Seidman, 2008</xref>).</p><p>There is a tight link between path integration and spatial navigation on the one hand, and internal models and control dynamics on the other. To accurately estimate self-motion, we rely not only on momentary sensory evidence but also on the knowledge of motion dynamics, that is, an internal model of the world. Knowledge of the dynamics makes the sensory consequences of actions predictable, allowing for more dexterous steering. However, although there is a large body of research focused on dynamics and adaptation for motor control (<xref ref-type="bibr" rid="bib44">Shadmehr and Mussa-Ivaldi, 1994</xref>; <xref ref-type="bibr" rid="bib30">Lackner and Dizio, 1994</xref>; <xref ref-type="bibr" rid="bib29">Krakauer et al., 1999</xref>; <xref ref-type="bibr" rid="bib46">Takahashi et al., 2001</xref>; <xref ref-type="bibr" rid="bib7">Burdet et al., 2001</xref>; <xref ref-type="bibr" rid="bib28">Kording et al., 2007</xref>; <xref ref-type="bibr" rid="bib6">Berniker et al., 2010</xref>), studies of perceptual inference of latent dynamics during navigation have been limited. Some pioneering studies demonstrated participants’ ability to reproduce arbitrary 1D velocity profiles (<xref ref-type="bibr" rid="bib18">Grasso et al., 1999</xref>; <xref ref-type="bibr" rid="bib20">Israël et al., 1997</xref>), while more recent efforts showed that the history of linear (<xref ref-type="bibr" rid="bib38">Petzschner and Glasauer, 2011</xref>) and angular (<xref ref-type="bibr" rid="bib39">Prsa et al., 2015</xref>) displacements affects how participants process sensory input in the current trial. We previously observed that false expectations about the magnitude of self-motion can have a drastic effect on path integration (<xref ref-type="bibr" rid="bib31">Lakshminarasimhan et al., 2018</xref>). We wondered whether prior expectations about the <italic>temporal dynamics</italic> of self-motion, that is, how velocities are temporally correlated, can also propagate over time to influence navigation.</p><p>To explore how dynamics influence navigation across sensory modalities (visual, vestibular, or both), we have built upon a naturalistic paradigm of path integration in which participants navigate to a briefly cued target location using a joystick to control their velocity in a virtual visual environment (<xref ref-type="bibr" rid="bib31">Lakshminarasimhan et al., 2018</xref>; <xref ref-type="bibr" rid="bib1">Alefantis et al., 2021</xref>). Here, we generalize this framework by varying both the control dynamics (joystick control varied along a continuum from velocity to acceleration) and the available sensory cues (vestibular, visual, or both). To achieve this, we designed a motion-cueing (MC) algorithm to render self-motion stimuli according to a joystick control input of maintained accelerations while maintaining correspondence between visual (optic flow) and inertial cues. Using a motion platform with six degrees of freedom to approximate the accelerations that an observer would feel under the imposed control dynamics, we ensured that the MC algorithm would generate matching visual and vestibular cues to closely approximate the desired self-motion (see Materials and methods, <xref ref-type="fig" rid="fig1s1">Figure 1—figure supplements 1</xref> and <xref ref-type="fig" rid="fig1s2">2</xref>). The development of the MC algorithm represents a departure from classical paradigms of navigation research in humans (<xref ref-type="bibr" rid="bib12">Chrastil et al., 2019</xref>; <xref ref-type="bibr" rid="bib19">Israël et al., 1996</xref>; <xref ref-type="bibr" rid="bib26">Koppen et al., 2019</xref>; <xref ref-type="bibr" rid="bib42">Seemungal et al., 2007</xref>; <xref ref-type="bibr" rid="bib48">ter Horst et al., 2015</xref>), as it helps eliminate artificial constraints while still allowing for the isolation of different sensory contributions, most notably vestibular/somatosensory cues, during active, volitional, steering.</p><p>We found that participants’ steering responses were biased (undershooting), and the biases were more prominent in the vestibular condition. Furthermore, steering biases were strongly modulated by the underlying control dynamics. These findings suggest that inertial cues alone (as generated by motion cueing) lack the reliability to support accurate path integration in the absence of sustained acceleration, and that an accurate internal model of control dynamics is needed to make use of sensory observations when navigating in volatile environments.</p></sec><sec id="s2" sec-type="results"><title>Results</title><sec id="s2-1"><title>Task structure</title><p>Human participants steered toward a briefly cued target location on a virtual ground plane, with varying sensory conditions and control dynamics interleaved across trials. Participants sat on a motion platform in front of a screen displaying a virtual environment (<xref ref-type="fig" rid="fig1">Figure 1A</xref>). Stereoscopic depth cues were provided using polarizing goggles. On each trial, a circular target appeared briefly at a random location (drawn from a uniform distribution within the field of view; <xref ref-type="fig" rid="fig1">Figure 1B and C</xref>) and participants had to navigate to the remembered target location in the virtual world using a joystick to control linear and angular self-motion. The virtual ground plane was defined visually by a texture of many small triangles which independently appeared only transiently; they could therefore only provide optic-flow information and could not be used as landmarks. The self-motion process evolved according to Markov dynamics, such that the movement velocity at the next time step depended only on the current joystick input and the current velocity (Materials and methods – <xref ref-type="disp-formula" rid="equ1">Equation 1a</xref>).</p><fig-group><fig id="fig1" position="float"><label>Figure 1.</label><caption><title>Experimental design.</title><p>(<bold>A</bold>) Experimental setup. Participants sit on a six-degrees-of-freedom motion platform with a coupled rotator that allowed unlimited yaw displacements. Visual stimuli were back-projected on a screen (see Materials and methods). The joystick participants used to navigate in the virtual world is mounted in front of the participants’ midline. (<bold>B</bold>) Schematic view of the experimental virtual environment. Participants use a joystick to navigate to a cued target (<italic>yellow disc</italic>) using optic-flow cues generated by ground plane elements (<italic>brown triangles; visual and combined conditions only</italic>). The ground plane elements appeared transiently at random orientations to ensure they cannot serve as spatial or angular landmarks. (<bold>C</bold>) Left: Overhead view of the spatial distribution of target positions across trials. <italic>Red dot</italic> shows the starting position of the participant. Positions were uniformly distributed within the participant’s field of view. Right: Movement trajectories of one participant during a representative subset of trials. Starting location is denoted by the <italic>red dot</italic>. (<bold>D</bold>) Control dynamics. Inset: Linear joystick input from a subset of trials in the visual condition of an example participant. Left: Simulated maximum pulse joystick input (<italic>max joystick input = 1</italic>) (see also <xref ref-type="fig" rid="fig1s3">Figure 1—figure supplement 3</xref>). This input is lowpass filtered to mimic the existence of inertia. The time constant of the filter varies across trials (time constant <italic>τ</italic>). In our framework, maximum velocity also varies according to the time constant <italic>τ</italic> of each trial to ensure comparable travel times across trials (see Materials and methods – <italic>Control Dynamics</italic>). Right: The same joystick input (scaled by the corresponding maximum velocity for each <italic>τ</italic>) produces different velocity profiles for different time constants (<italic>τ</italic> = 0.6 s corresponds to <italic>velocity control</italic>; <italic>τ</italic> = 3 s corresponds to <italic>acceleration control; τ</italic> values varied randomly along a continuum across trials, see Materials and methods). Also depicted is the brief cueing period of the target at the beginning of the trial (gray zone, 1 s long). (<bold>E</bold>) Markov decision process governing self-motion sensation (Materials and methods – <xref ref-type="disp-formula" rid="equ1">Equation 1a</xref>). <inline-formula><mml:math id="inf1"><mml:mi>u</mml:mi></mml:math></inline-formula>, <inline-formula><mml:math id="inf2"><mml:mi>v</mml:mi></mml:math></inline-formula>, and <inline-formula><mml:math id="inf3"><mml:mi>o</mml:mi></mml:math></inline-formula> denote joystick input, movement velocity, and sensory observations, respectively, and subscripts denote time indices. Note that due to the 2D nature of the task, these variables are all vector-valued, but we depict them as scalars for the purpose of illustration. By varying the time constant, we manipulated the control dynamics (i.e., the degree to which the current velocity carried over to the future, indicated by the thickness of the horizontal lines) along a continuum such that the joystick position primarily determined either the participant’s velocity (top; <italic>thin lines</italic>) or acceleration (bottom; <italic>thick lines</italic>) (compare with (<bold>D</bold>) top and bottom, respectively). Sensory observations were available in the form of vestibular (left), optic flow (middle), or both (right).</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-63405-fig1-v1.tif"/></fig><fig id="fig1s1" position="float" specific-use="child-fig"><label>Figure 1—figure supplement 1.</label><caption><title>Motion Cueing framework.</title><p>(<bold>A</bold>) Flow diagram of motion-cueing (MC) algorithm.</p><p>The participant pilots themselves in a simulated environment using a joystick. The MC algorithm aims at controlling a platform such that the sum of inertial and gravitational acceleration experienced when sitting on the platform (<italic>desired platform gravito-inertial acceleration [GIA]</italic>, blue; the curve illustrates an example profile consisting of a single rectangular waveform) matches the linear acceleration experienced in the simulated virtual environment. ‘Desired’ refers to the fact that the motion platform may not be able to match this acceleration exactly. The desired GIA is fed through a step impulse function to compute the <italic>desired linear acceleration</italic> of the platform. The difference between the desired linear acceleration and GIA is used to compute the <italic>desired platform tilt</italic>. The desired platform motion (linear and tilt motion) are passed through a controller that restricts its motion to the actuator’s limits (in terms of linear and angular acceleration, velocity, and position). The two actuator output commands are sent to the platform and are also used to compute the <italic>actuator GIA</italic> which is actually rendered by the platform. To ensure that the inertial motion produced by the platform matches the motion in the simulated environment, the actuator GIA is compared to the desired linear acceleration to compute an <italic>actuator GIA error</italic> feedback signal<italic>,</italic> which updates the simulated motion. (<bold>B</bold>) Acceleration profile of an actual trial. The first panel shows the desired GIA of the participant for that trial. The second and third panels show the desired linear acceleration (red) and desired tilt acceleration (green), respectively. The fourth panel shows the final GIA achieved (blue) and the GIA error (magenta). (<bold>C</bold>) Correspondence between visual acceleration and platform GIA (blue), measured independently from the MC algorithm using an inertial measurement unit mounted next to the participant’s head. There is an almost perfect match between the two. The gray histogram indicates the range of acceleration experienced by the participant.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-63405-fig1-figsupp1-v1.tif"/></fig><fig id="fig1s2" position="float" specific-use="child-fig"><label>Figure 1—figure supplement 2.</label><caption><title>Verification of Motion Cueing output.</title><p>(<bold>A</bold>) Net gravito-inertial acceleration (GIA; <italic>thick lines</italic>) and net GIA error (<italic>thin lines</italic>) aligned to start and end of trial, for the vestibular and combined conditions across participants (average across trials over all time constants).</p><p>The <italic>dashed line</italic> represents a conservative choice of the vestibular motion detection threshold according to the relevant literature (8 cm/s<sup>2</sup>; <xref ref-type="bibr" rid="bib24">Kingma, 2005</xref>; <xref ref-type="bibr" rid="bib33">MacNeilage et al., 2010</xref>; <xref ref-type="bibr" rid="bib50">Zupan and Merfeld, 2008</xref>). <italic>Gray region</italic> represents the target presentation period. <italic>Shaded regions</italic> denote ±1 SEM. (<bold>B</bold>) Net tilt velocity aligned to start and end of trial, for the vestibular and combined conditions across participants. <italic>Dashed line</italic> represents the estimated tilt/translation discrimination threshold of 1 deg/s: although tilt/translation discrimination thresholds have not been explicitly studied, we can use the rotation sensation thresholds of the semicircular canals to estimate what that threshold would be. Since it is the rotation velocity that tells a participant that they are tilting and not translating, we propose that the tilt/translation discrimination threshold is at least the same as the rotation sensation threshold (if not larger; <xref ref-type="bibr" rid="bib32">Lim et al., 2017</xref>; <xref ref-type="bibr" rid="bib33">MacNeilage et al., 2010</xref>). <italic>Shaded regions</italic> represent ±1 SEM across participants. Inset shows the probability distribution of displacements during the suprathreshold tilt period after trial onset (~0.6 s). Although the tilt can be perceived by the participants during trial onset, the displacement during that period does not exceed 10 cm and could potentially not contribute significantly to steering errors, for three reasons: (a) the displacement during that period is negligible, (<bold>b</bold>) tilt velocity is kept below the perceptual threshold for the remainder of the trajectory, (<bold>c</bold>) GIA is always above the motion detection threshold of the vestibular system. However, since the initial tilt could be perceived (as it briefly exceeded the canal detection threshold), this might alter the perceived orientation of the participants. In turn, this could influence the extent to which vestibular cues would be used as input to the path integration system (see Discussion ‘Limitations and future directions’ for further discussion). Thus, perceived tilt might be used as an indicator of trial onset, but it cannot contribute to path integration for three reasons: (a) the displacement during that period is negligible, (b) tilt velocity is kept below the perceptual threshold for the remainder of the trajectory, (c) GIA is always above the motion detection threshold of the vestibular system.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-63405-fig1-figsupp2-v1.tif"/></fig><fig id="fig1s3" position="float" specific-use="child-fig"><label>Figure 1—figure supplement 3.</label><caption><title>Control dynamics framework.</title><p>(<bold>A</bold>) Example dynamics for bang-bang control.</p><p>Position, velocity, and controls are shown. Control switches at time <italic>s</italic> and ends at time <italic>T</italic>. (<bold>B</bold>) Maximal velocity (blue) needed for bang-bang control to produce a desired average velocity <inline-formula><mml:math id="inf4"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mrow><mml:mover><mml:mi>u</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover></mml:mrow><mml:mo>=</mml:mo><mml:mi>x</mml:mi><mml:mrow><mml:mo>/</mml:mo></mml:mrow><mml:mi>T</mml:mi></mml:mrow></mml:mstyle></mml:math></inline-formula> , as a function of the fraction of trial duration given by the time constant, <inline-formula><mml:math id="inf5"><mml:mrow><mml:mrow><mml:mi>τ</mml:mi></mml:mrow><mml:mo>/</mml:mo><mml:mrow><mml:mi>T</mml:mi></mml:mrow></mml:mrow></mml:math></inline-formula> . When the time constant is a small fraction of the trial (velocity control), the max velocity equals the average velocity (orange line). When the time constant is much longer than a trial (acceleration control), the maximum velocity grows as <inline-formula><mml:math id="inf6"><mml:mrow><mml:mrow><mml:mn>4</mml:mn><mml:mi>τ</mml:mi></mml:mrow><mml:mo>/</mml:mo><mml:mrow><mml:mi>T</mml:mi></mml:mrow></mml:mrow></mml:math></inline-formula> (green), although this speed is never approached since braking begins before the velocity approaches equilibrium. (<bold>C</bold>) Example dynamics for control behavior. Left: Log-normal distribution of control time constants <inline-formula><mml:math id="inf7"><mml:mi>τ</mml:mi></mml:math></inline-formula> (see also <xref ref-type="fig" rid="fig3s1">Figure 3—figure supplement 1A</xref>). Right: Example random walk in <inline-formula><mml:math id="inf8"><mml:mrow><mml:mrow><mml:mi mathvariant="normal">log</mml:mi></mml:mrow><mml:mo>⁡</mml:mo><mml:mrow><mml:mi>τ</mml:mi></mml:mrow></mml:mrow></mml:math></inline-formula> space.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-63405-fig1-figsupp3-v1.tif"/></fig></fig-group><p>A time constant for the control filter (control timescale) governed the control dynamics: in trials with a <italic>small</italic> time constant and a fast filter, joystick position essentially controlled velocity, providing participants with responsive control over their self-motion, resembling regular road-driving dynamics. However, when the time constant was <italic>large</italic> and the control filter was slow, joystick position mainly controlled acceleration, mimicking high inertia under viscous damping, as one would experience on an icy road where steering is sluggish (<xref ref-type="fig" rid="fig1">Figure 1D</xref> right and 1E – top vs. bottom). For these experiments, as the control timescale changed, the maximum velocity was adjusted so that the participant could reach the typical target in about the same amount of time on average. This design ensured that the effect of changing control dynamics would not be confused with the effect of integrating sensory signals over a longer or shorter time.</p><p>Concurrently, we manipulated the modality of sensory observations to generate three conditions: (1) a <italic>vestibular</italic> condition in which participants navigated in darkness, and sensed only the platform’s motion (note that this condition also engages somatosensory cues, see Materials and methods), (2) a <italic>visual</italic> condition in which the motion platform was stationary and velocity was signaled by optic flow, and (3) a <italic>combined</italic> condition in which both cues were available (<xref ref-type="fig" rid="fig1">Figure 1E</xref> – left to right). Across trials, sensory conditions were randomly interleaved while manipulation of the time constant followed a bounded random walk (Materials and methods – <xref ref-type="disp-formula" rid="equ11">Equation 2</xref>). Participants did not receive any performance-related feedback.</p></sec><sec id="s2-2"><title>Effect of sensory modality on performance</title><p>We first compared the participants’ stopping locations on each trial to the corresponding target locations, separately for each sensory condition. We calculated the radial distance <inline-formula><mml:math id="inf9"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mrow><mml:mover><mml:mi>r</mml:mi><mml:mo stretchy="false">~</mml:mo></mml:mover></mml:mrow></mml:mrow></mml:mstyle></mml:math></inline-formula> and angular eccentricity <inline-formula><mml:math id="inf10"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mrow><mml:mover><mml:mi>θ</mml:mi><mml:mo stretchy="false">~</mml:mo></mml:mover></mml:mrow></mml:mrow></mml:mstyle></mml:math></inline-formula> of the participants’ final position relative to the initial position (<xref ref-type="fig" rid="fig2">Figure 2A</xref>), and compared them to the initial target distance <inline-formula><mml:math id="inf11"><mml:mi>r</mml:mi></mml:math></inline-formula> and angle <inline-formula><mml:math id="inf12"><mml:mi>θ</mml:mi></mml:math></inline-formula>, as shown for all trials (all time constants together) of a typical participant in <xref ref-type="fig" rid="fig2">Figure 2B and C</xref>. This revealed biased performance with notable undershooting (participants stopped short of the true target location), in both distance and angle, which was well described by a linear model without intercept (radial distance <inline-formula><mml:math id="inf13"><mml:msup><mml:mrow><mml:mi>R</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:math></inline-formula> ± standard deviation – vestibular: 0.39 ± 0.06, visual: 0.67 ± 0.1, combined: 0.64 ± 0.11; angular eccentricity <inline-formula><mml:math id="inf14"><mml:msup><mml:mrow><mml:mi>R</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:math></inline-formula> ± standard deviation – vestibular: 0.85 ± 0.06, visual: 0.95 ± 0.05, combined: 0.96 ± 0.04. Adding a non-zero intercept term offered negligible improvement; radial distance <inline-formula><mml:math id="inf15"><mml:msup><mml:mrow><mml:mi>Δ</mml:mi><mml:mi>R</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:math></inline-formula> – vestibular: 0.02 ± 0.02, visual: 0.03 ± 0.03, combined: 0.03 ± 0.02; angular eccentricity <inline-formula><mml:math id="inf16"><mml:msup><mml:mrow><mml:mi>Δ</mml:mi><mml:mi>R</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:math></inline-formula> – vestibular: 0.02 ± 0.03, visual: 0.01 ± 0.01, combined: 0.01 ± 0.01). We refer to the slope of the linear regression as ‘response gain’: a response gain of unity indicates no bias, while gains larger (smaller) than unity indicate overshooting (undershooting). As shown with the example participant in <xref ref-type="fig" rid="fig2">Figure 2B and C</xref>, there was substantial undershooting in the vestibular condition, whereas performance was relatively unbiased under the combined and visual conditions (see also <xref ref-type="fig" rid="fig2s1">Figure 2—figure supplement 1A</xref>). These results were consistent across participants (<xref ref-type="fig" rid="fig2">Figure 2D</xref>, mean radial gain± standard deviation – vestibular: 0.76 ± 0.25, visual: 0.88 ± 0.23, combined: 0.85 ± 0.22, mean angular gain± standard deviation – vestibular: 0.79 ± 0.22, visual: 0.98 ± 0.14, combined: 0.95 ± 0.12), and no significant sex differences were observed (see <xref ref-type="fig" rid="fig2s1">Figure 2—figure supplement 1B</xref>). The difference in response gain between modalities could be traced back to the control exerted by the subjects on the joystick. Both linear and angular components of control input had shorter duration in the vestibular condition (mean ± SEM of total area of joystick input across participants (a.u.): radial – vestibular: 5.62 ± 0.27, visual: 7.31 ± 0.33, combined: 7.07 ± 0.34; angular – vestibular: 2.39 ± 0.30, visual: 3.29 ± 0.42, combined: 3.79 ± 0.46), and produced smaller displacements, as summarized by the response gains (<xref ref-type="fig" rid="fig2">Figure 2</xref>, <xref ref-type="fig" rid="fig2s2">Figure 2—figure supplement 2</xref>).</p><fig-group><fig id="fig2" position="float"><label>Figure 2.</label><caption><title>Effect of sensory modality on participants' responses.</title><p>(<bold>A</bold>) Geometric definition of analysis variables.</p><p>The <italic>gray solid line</italic> indicates an example trajectory. The target and response distance and angle relative to the starting position of the participant are given by <inline-formula><mml:math id="inf17"><mml:mi>r</mml:mi><mml:mo>,</mml:mo><mml:mi>θ</mml:mi></mml:math></inline-formula> (<italic>thin lines</italic>) and <inline-formula><mml:math id="inf18"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mrow><mml:mover><mml:mi>r</mml:mi><mml:mo stretchy="false">~</mml:mo></mml:mover></mml:mrow><mml:mo>,</mml:mo><mml:mrow><mml:mover><mml:mi>θ</mml:mi><mml:mo stretchy="false">~</mml:mo></mml:mover></mml:mrow></mml:mrow></mml:mstyle></mml:math></inline-formula> (<italic>thick lines</italic>), respectively. (<bold>B, C</bold>) Example participant: Comparison of the radial distance <inline-formula><mml:math id="inf19"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mrow><mml:mover><mml:mi>r</mml:mi><mml:mo stretchy="false">~</mml:mo></mml:mover></mml:mrow></mml:mrow></mml:mstyle></mml:math></inline-formula> of an example participant’s response (final position) against the radial distance <inline-formula><mml:math id="inf20"><mml:mi>r</mml:mi></mml:math></inline-formula> of the target (<bold>B</bold>), as well as the angular eccentricity of the participant’s response <inline-formula><mml:math id="inf21"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mrow><mml:mover><mml:mi>θ</mml:mi><mml:mo stretchy="false">~</mml:mo></mml:mover></mml:mrow></mml:mrow></mml:mstyle></mml:math></inline-formula> vs. target angle <inline-formula><mml:math id="inf22"><mml:mi>θ</mml:mi></mml:math></inline-formula> (<bold>C</bold>), across all trials for one participant, colored according to the sensory condition (<italic>green</italic>: vestibular, <italic>cyan:</italic> visual, <italic>purple:</italic> combined visual and vestibular; <xref ref-type="supplementary-material" rid="fig2sdata1">Figure 2—source data 1</xref>). Radial and angular response gains were defined as the slope of the corresponding regressions. Black dashed lines show unity slope, and the solid lines represent slopes of the regression fits (intercept set to 0). (<bold>D</bold>) All participants: Radial and angular gains in each sensory condition plotted for each individual participant (<xref ref-type="supplementary-material" rid="fig2sdata2">Figure 2—source data 2</xref>). <italic>Ellipses</italic> show 68% confidence intervals of the distribution of data points for the corresponding sensory condition. <italic>Diamonds</italic> (centers of the ellipses) represent the mean radial and angular response gains across participants. Dashed lines indicate unbiased radial or angular position responses. Solid diagonal line has unit slope. (<bold>E</bold>) Magnitudes of radial and angular components of control inputs across sensory conditions for an example participant. <italic>Shaded regions</italic> represent ±1 standard deviation across trials. The <italic>gray zone</italic> corresponds to the target presentation period.</p><p><supplementary-material id="fig2sdata1"><label>Figure 2—source data 1.</label><caption><title>Radial and angular responses.</title></caption><media mime-subtype="zip" mimetype="application" xlink:href="elife-63405-fig2-data1-v1.zip"/></supplementary-material></p><p><supplementary-material id="fig2sdata2"><label>Figure 2—source data 2.</label><caption><title>Response gains.</title></caption><media mime-subtype="zip" mimetype="application" xlink:href="elife-63405-fig2-data2-v1.zip"/></supplementary-material></p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-63405-fig2-v1.tif"/></fig><fig id="fig2s1" position="float" specific-use="child-fig"><label>Figure 2—figure supplement 1.</label><caption><title>Trajectories in all conditions and sex differences in performance.</title><p>(<bold>A</bold>) Random subset of trajectories of an example participant under each sensory condition. The corresponding radial and angular response gains are indicated for each condition (green: vestibular, cyan: visual, purple: combined). <italic>Gray region</italic> represents the target range. (<bold>B</bold>) Sex differences in participants’ performance: radial and angular gains (see <xref ref-type="fig" rid="fig2">Figure 2D</xref>) grouped based on sex (F: female, M: male; see legend; p-values of differences in response gains between male and female participants: Radial gain – vestibular: p = 0.17, visual: p = 0.09, combined: p = 0.09; angular gain – vestibular: p = 0.58, visual: p = 0.38, combined: p = 0.21; two-sample <italic>t</italic>-test). (<bold>C</bold>) Sex differences in participants’ performance: correlation coefficients between the time constant and the residual errors (radial and angular components; see <xref ref-type="fig" rid="fig3">Figure 3C</xref>) grouped based on sex. Specifically, the x and y axes represent the correlation values between the time constant and the radial and angular residual errors, respectively (p-values of differences in correlation coefficients between male and female participants: Radial – vestibular: p = 0.5, visual: p = 0.66, combined: p = 0.71; angular – vestibular: p = 0.51, visual: p = 0.97 combined: p = 0.82 two-sample <italic>t</italic>-test).</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-63405-fig2-figsupp1-v1.tif"/></fig><fig id="fig2s2" position="float" specific-use="child-fig"><label>Figure 2—figure supplement 2.</label><caption><title>Joystick inputs.</title><p>(<bold>A–G</bold>) Linear (left) and angular (right) joystick input over time, for a subset of participants in all conditions (see <italic>legend</italic>; bottom right). The joystick control had shorter duration in the vestibular condition, reflecting our findings of the smaller response gains. Shaded regions represent ±1 standard deviation across trials.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-63405-fig2-figsupp2-v1.tif"/></fig></fig-group></sec><sec id="s2-3"><title>Effect of control dynamics on performance</title><p>To examine whether control dynamics affected the response gain, we performed three complementary analyses. First, we recomputed response gains by stratifying the trials into three groups of equal size based on the time constants. We found that smaller time constants (velocity control) were associated with smaller response gains (<xref ref-type="fig" rid="fig3">Figure 3A</xref>; <xref ref-type="table" rid="app2table1">Appendix 2—table 1</xref>). This relationship was most pronounced in the vestibular condition, where larger time constants (acceleration control) resulted in better (closer to ideal) performance (<xref ref-type="fig" rid="fig3">Figure 3</xref>, green; see Discussion). Control dynamics had a smaller but considerable effect on steering responses in the visual and combined conditions, with participants exhibiting modest overshooting (undershooting) when the time constant was large (small) (<xref ref-type="fig" rid="fig3">Figure 3A</xref>, cyan/purple).</p><fig-group><fig id="fig3" position="float"><label>Figure 3.</label><caption><title>Effect of control dynamics on participants’ responses.</title><p>(<bold>A</bold>) Participant average of radial and angular response gains in each condition, with trials grouped into tertiles of increasing time constant <italic>τ</italic>. Error bars denote ±1 SEM. (<bold>B</bold>) Effect of time constant <inline-formula><mml:math id="inf23"><mml:mi>τ</mml:mi></mml:math></inline-formula> on radial (left) and angular (right) residual error, for an example participant (<xref ref-type="supplementary-material" rid="fig3sdata1">Figure 3—source data 1</xref>). <italic>Solid lines</italic> represent linear regression fits and <italic>ellipses</italic> the 68% confidence interval of the distribution for each sensory condition. <italic>Dashed lines</italic> denote zero residual error (i.e. stopping location matches mean response). (<bold>C</bold>) Correlations of radial (<inline-formula><mml:math id="inf24"><mml:msub><mml:mrow><mml:mi>ε</mml:mi></mml:mrow><mml:mrow><mml:mi>r</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula>) and angular (<inline-formula><mml:math id="inf25"><mml:msub><mml:mrow><mml:mi>ε</mml:mi></mml:mrow><mml:mrow><mml:mi>θ</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula>) residual errors with the time constant for all participants. <italic>Ellipses</italic> indicate the 68% confidence intervals of the distribution of data points for each sensory condition. Solid diagonal line has unit slope. Across participants, radial correlations, which were larger for the vestibular condition, were greater than angular correlations (see also <xref ref-type="table" rid="app2table2">Appendix 2—table 2</xref>). (<bold>D</bold>) Linear regression coefficients for the prediction of participants’ response location (final position:,<inline-formula><mml:math id="inf26"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mrow><mml:mover><mml:mi>r</mml:mi><mml:mo stretchy="false">~</mml:mo></mml:mover></mml:mrow><mml:mo>,</mml:mo></mml:mrow></mml:mstyle></mml:math></inline-formula> <inline-formula><mml:math id="inf27"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mrow><mml:mover><mml:mi>θ</mml:mi><mml:mo stretchy="false">~</mml:mo></mml:mover></mml:mrow></mml:mrow></mml:mstyle></mml:math></inline-formula>; left and right, respectively) from initial target location (<inline-formula><mml:math id="inf28"><mml:mi>r</mml:mi></mml:math></inline-formula>,<inline-formula><mml:math id="inf29"><mml:mi>θ</mml:mi></mml:math></inline-formula>) and the interaction between initial target location and the time constant (<inline-formula><mml:math id="inf30"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>r</mml:mi><mml:mo>⋅</mml:mo><mml:mi>τ</mml:mi></mml:mrow></mml:mstyle></mml:math></inline-formula>,<inline-formula><mml:math id="inf31"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>θ</mml:mi><mml:mo>⋅</mml:mo><mml:mi>τ</mml:mi></mml:mrow></mml:mstyle></mml:math></inline-formula>) (all variables were standardized before regressing, see Materials and methods<bold>;</bold> <xref ref-type="supplementary-material" rid="fig3sdata2">Figure 3—source data 2</xref>). <italic>Asterisks</italic> denote statistical significance of the difference in coefficient values of the interaction terms across sensory conditions (paired <italic>t</italic>-test; *: p&lt;0.05, **: p&lt;0.01, ***: p&lt;0.001; <italic>see</italic> main text). <italic>Error bars</italic> denote ±1 SEM. Note a qualitative agreement between the terms that included target location only and the gains calculated with the simple linear regression model (<xref ref-type="fig" rid="fig2">Figure 2B</xref>). (<bold>E</bold>) Comparison of actual and null-case (no adaptation) response gains, for radial (<italic>top</italic>) and angular (<italic>bottom</italic>) components, respectively (average across participants). <italic>Dashed lines</italic> represent unity lines, that is, actual response gain corresponds to no adaptation. Inset: Regression slopes between actual and null-case response gains. A slope of 0 or 1 corresponds to perfect or no adaptation (<italic>gray dashed lines</italic>), respectively. <italic>Error bars</italic> denote ±1 SEM.</p><p><supplementary-material id="fig3sdata1"><label>Figure 3—source data 1.</label><caption><title>Residual errors.</title></caption><media mime-subtype="zip" mimetype="application" xlink:href="elife-63405-fig3-data1-v1.zip"/></supplementary-material></p><p><supplementary-material id="fig3sdata2"><label>Figure 3—source data 2.</label><caption><title>Regression coefficients between time constant and residual errors.</title></caption><media mime-subtype="zip" mimetype="application" xlink:href="elife-63405-fig3-data2-v1.zip"/></supplementary-material></p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-63405-fig3-v1.tif"/></fig><fig id="fig3s1" position="float" specific-use="child-fig"><label>Figure 3—figure supplement 1.</label><caption><title>Effect of time constant on residual errors.</title><p>(<bold>A</bold>) Sampling distributions of the time constant for all three sensory conditions across participants.</p><p>The sampling distribution both across participants and across conditions is almost identical.</p><p><italic>Transparent</italic> lines and <italic>thick</italic> lines represent the individual sampling distributions of participants and their mean, respectively. (<bold>B–J</bold>) Effect of the time constant on radial (left) and angular (right) residual error, for a large subset of participants.<italic>Solid lines</italic> represent linear regression fits (see <xref ref-type="table" rid="app2table3">Appendix 2—table 3</xref> for individual regression coefficient values). <italic>Dashed lines</italic> denote zero residual error (i.e. stopping location matches mean response).</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-63405-fig3-figsupp1-v1.tif"/></fig><fig id="fig3s2" position="float" specific-use="child-fig"><label>Figure 3—figure supplement 2.</label><caption><title>Partial correlation analysis.</title><p>(<bold>A</bold>) Partial correlation coefficients for prediction of stopping distance <inline-formula><mml:math id="inf32"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mrow><mml:mover><mml:mi>r</mml:mi><mml:mo stretchy="false">~</mml:mo></mml:mover></mml:mrow></mml:mrow></mml:mstyle></mml:math></inline-formula> (relative to starting position) from initial target distance (<inline-formula><mml:math id="inf33"><mml:mi>r</mml:mi></mml:math></inline-formula>), <italic>τ</italic>, and the interaction of the two (<inline-formula><mml:math id="inf34"><mml:mi>r</mml:mi><mml:mi>τ</mml:mi></mml:math></inline-formula>), for all participants across sensory conditions.</p><p>Values at each bar group represent the average coefficient value across participants ±1 standard deviation. The contribution of the <italic>τ-</italic>only term was considered insignificant across all conditions. The simplified version of this model would be: <inline-formula><mml:math id="inf35"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mrow><mml:mover><mml:mi>r</mml:mi><mml:mo stretchy="false">~</mml:mo></mml:mover></mml:mrow><mml:mo>=</mml:mo><mml:mi>r</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>α</mml:mi><mml:mo>+</mml:mo><mml:mi>γ</mml:mi><mml:mi>τ</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mstyle></mml:math></inline-formula> , which implies that the radial gain is <italic>τ-</italic>dependent. (<bold>B</bold>) Partial correlation coefficients for prediction of stopping angle <inline-formula><mml:math id="inf36"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mrow><mml:mover><mml:mi>θ</mml:mi><mml:mo stretchy="false">~</mml:mo></mml:mover></mml:mrow></mml:mrow></mml:mstyle></mml:math></inline-formula> (relative to starting position) from initial target angle (<inline-formula><mml:math id="inf37"><mml:mi>θ</mml:mi></mml:math></inline-formula>), <italic>τ</italic>, and the interaction of the two (<inline-formula><mml:math id="inf38"><mml:mi>θ</mml:mi><mml:mi>τ</mml:mi></mml:math></inline-formula>), for all participants across sensory conditions. Values at each bar group represent the average coefficient value across participants ±1 standard deviation. In agreement with the findings for the response distance, the contribution of the <italic>τ-</italic>only term was considered insignificant across all conditions. The simplified version of this model would be: <inline-formula><mml:math id="inf39"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mrow><mml:mover><mml:mi>θ</mml:mi><mml:mo stretchy="false">~</mml:mo></mml:mover></mml:mrow><mml:mo>=</mml:mo><mml:mi>θ</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>α</mml:mi><mml:mo>+</mml:mo><mml:mi>γ</mml:mi><mml:mi>τ</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mstyle></mml:math></inline-formula> , which implies that the angular gain is also <italic>τ-</italic>dependent.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-63405-fig3-figsupp2-v1.tif"/></fig></fig-group><p>Second, we performed a fine-grained version of the above analysis by computing residual errors on each trial, that is, the deviation of the response from the mean response predicted from target location alone (Materials and methods – <xref ref-type="disp-formula" rid="equ12">Equation 3</xref>). Since participants try to stop at their believed target location, ideally their mean responses should depend only on target location, and not on control dynamics. In other words, if participants adapted their control appropriately to the varying control dynamics, their responses should cluster around their mean response, and as a result, their residual errors should be centered around zero without any mean dependence on dynamics. However, we found a significant correlation between residual errors and the time constant across trials (<xref ref-type="fig" rid="fig3">Figure 3B, C</xref>; <xref ref-type="fig" rid="fig3s1">Figure 3—figure supplement 1</xref><bold>,</bold> <xref ref-type="table" rid="app2table2">Appendix 2—table 2</xref>, see Materials and methods; no significant sex differences were observed, and therefore are not investigated in subsequent analyses, see also <xref ref-type="fig" rid="fig2s1">Figure 2—figure supplement 1C</xref>). This correlation and the corresponding regression slopes were substantially higher in the vestibular condition (mean Pearson’s <italic>r</italic> ± SEM: radial component – vestibular: 0.52 ± 0.02, visual: 0.36 ± 0.03, combined: 0.37 ± 0.03; angular component – vestibular: 0.23 ± 0.02, visual: 0.23 ± 0.03, combined: 0.26 ± 0.03; see also <xref ref-type="table" rid="app2table2 app2table3">Appendix 2—Tables 2 and 3</xref>). Thus, for a given target distance, participants tended to travel further when the time constant was larger (acceleration control), indicating they did not fully adapt their steering control to the underlying dynamics.</p><p>Third, to quantify the contribution of the time constant in the participants’ responses, we expanded the linear model to accommodate a dependence of response (final stopping position) on target location, time constant, and their interaction. A partial correlation analyses revealed that the time constant contributed substantially to participants’ response gain, albeit only by modulating the radial and angular distance dependence (<xref ref-type="table" rid="app2table4">Appendix 2—table 4</xref>; <xref ref-type="fig" rid="fig3s2">Figure 3—figure supplement 2</xref>; see Materials and methods – <xref ref-type="disp-formula" rid="equ14">Equation 4</xref>). Again, the contribution of the time constant-dependent term was much greater for the vestibular condition (<xref ref-type="fig" rid="fig3">Figure 3D</xref>), especially for the radial distance (p-values of difference in coefficient values across modalities obtained by a paired <italic>t</italic>-test – radial: vestibular vs. visual: p &lt; 10<sup>–4</sup> , vestibular vs. combined: p &lt; 10<sup>–4</sup>; angular: vestibular vs. visual: p = 0.016, vestibular vs. combined: p = 0.013). While perfect adaptation should lead to response gain that is independent of control dynamics, all three independent analyses revealed that control dynamics did substantially influence the steering response gain, exposing participants’ failure to adapt their steering to the underlying dynamics. Adaptation was lowest for the vestibular condition; in contrast, for the visual and combined conditions, the response gain was less affected indicating greater compensation when visual information was available.</p><p>We quantified the extent to which participants failed to adapt to the control dynamics, by simulating a null case for no adaptation. Specifically, we generated null-case trajectories by using the steering input from actual trials and re-integrating it with time constants from other trials. In this set of null-case trajectories, the steering control corresponds to different time constants; in other words, steering is not adapted to the underlying dynamics (see Materials and methods). We then grouped these trajectories based on the simulation time constant (as in <xref ref-type="fig" rid="fig3">Figure 3A</xref>) and computed the corresponding response gains. We found that the true response gains in the vestibular condition were much closer to the no-adaptation null case, compared to visual/combined conditions (<xref ref-type="fig" rid="fig3">Figure 3E</xref>). Interestingly, this finding was more prominent in the radial component of the response gain (<xref ref-type="fig" rid="fig3">Figure 3E</xref> insets), consistent with our earlier observations of a stronger influence of the dynamics on the radial component of the responses.</p><p>We have shown how various measures of the participants’ final responses (stopping positions,response gain, residual errors) are influenced by the time constant of the dynamics. This large dependence of the final responses on the time constant exposes participants’ failure to fully adapt their steering to the underlying dynamics. In other words, the influence of the dynamics on steering control was relatively weak, especially in the vestibular condition.</p><p>For best performance, however, control dynamics <italic>should</italic> influence the time course of steering behavior. We directly quantified the influence of the control dynamics on steering by comparing participants’ braking (negative control input) across time constants: when the time constant is large, we ideally expect to see more braking as a countermeasure for the sluggish control (<xref ref-type="fig" rid="fig1">Figure 1D</xref>) to minimize travel duration (see Materials and methods). Indeed, participants do tend to brake more for higher time constants, but this effect is weaker in the vestibular condition (<xref ref-type="fig" rid="fig4">Figure 4 and</xref> inset). Nevertheless, correlations between the time constant and cumulative braking (total area below zero linear control input) were significant in all sensory conditions (mean Pearson’s <italic>r</italic> ± SEM – vestibular: 0.20 ± 0.03, visual: 0.62 ± 0.04, combined: 0.57 ± 0.04; p-values of Pearson’s <italic>r</italic> difference from zero – vestibular: p = 10<sup>−5</sup>, visual: p &lt; 10<sup>−7</sup>, combined: p &lt; 10<sup>−7</sup>). Overall, it appears that behavior in the vestibular condition is minimally influenced by the dynamics (i.e. smaller modulation of control input by the time constant, as shown by the cumulative braking). When optic flow is available, however, participants are more flexible in adjusting their control.</p><fig id="fig4" position="float"><label>Figure 4.</label><caption><title>Linear and angular control inputs for each condition grouped based on the time constant (see <italic>legend</italic>; bottom right), for an example participant.</title><p><italic>Shaded regions</italic> represent ±1 standard deviation across trials. <italic>Yellow zones</italic> denote target presentation period. Inset: Cumulative braking (i.e. absolute sum of negative linear input) for each condition across time constant groups. Braking was averaged across trials. <italic>Error bars</italic> denote ±1 SEM across participants.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-63405-fig4-v1.tif"/></fig><p>We have shown previously that accumulating sensory noise over an extended time (~10 s) would lead to a large uncertainty in the participant’s beliefs about their position, causing them to undershoot (<xref ref-type="bibr" rid="bib31">Lakshminarasimhan et al., 2018</xref>). The exact amount of undershooting depends both on the reliability of self-motion cues, which determines the <italic>instantaneous</italic> uncertainty in the self-motion estimate, and on travel duration, which governs how much uncertainty is <italic>accumulated</italic> while navigating to the target. With recent findings ascribing uncertainty accumulation to noise in the velocity input (<xref ref-type="bibr" rid="bib45">Stangl et al., 2020</xref>), the observed differences in navigation performance across sensory modalities can be readily attributed to greater measurement noise (lower reliability) in vestibular signals. On the other hand, we observed performance differences across control dynamics within each sensory modality, so those differences cannot be attributed to differences in the reliability of self-motion cues (<italic>instantaneous uncertainty</italic>). However, it might seem that this effect of control dynamics must be due to either differences in travel duration or velocity profiles, which would both affect the <italic>accumulated uncertainty</italic>. We adjusted stimulus parameters to ensure that the average travel time and average velocity were similar across different control dynamics (Materials and methods – <xref ref-type="disp-formula" rid="equ2 equ3 equ4 equ5 equ6 equ7 equ8 equ9 equ10">Equation 1.2-1.10)</xref>, however, we found that travel duration and average velocity depend weakly on the time constant in some participants. Simulations suggest that both dependencies are a consequence of maladaptation to the dynamics rather than a cause of the observed effect of the dynamics on the responses. Interestingly, the dependence is stronger in the vestibular condition where there is less adaptation to the dynamics, agreeing with our simulations (<xref ref-type="fig" rid="fig5s1">Figure 5—figure supplement 1A, B</xref>). Difference in velocity profiles is also an unlikely explanation since their expected effect on the participants’ responses (undershoot) is the opposite of the observed effect of the control dynamics (overshooting tendency; <xref ref-type="fig" rid="fig5s1">Figure 5—figure supplement 1C</xref>). Consequently, unlike the effect of sensory modality on response gain, neither instantaneous nor accumulated differences in the uncertainty can fully account for the influence of control dynamics, that is, the time constant. Instead, we will now show that the data are well explained by strong prior expectations about motion dynamics that cause a bias in estimating the time constant.</p></sec><sec id="s2-4"><title>Modeling the effect of control dynamics across sensory modalities</title><p>From a normative standpoint, to optimally infer movement velocity, one must combine sensory observations with the knowledge of the time constant. Misestimating the time constant would produce errors in velocity estimates, which would then propagate to position estimates, leading control dynamics to influence response gain (<xref ref-type="fig" rid="fig5">Figure 5A</xref>, middle-right). This is akin to misestimating the slipperiness of an ice patch on the road causing an inappropriate steering response, which would culminate in a displacement that differs from the intended one (<xref ref-type="fig" rid="fig5s2">Figure 5—figure supplement 2</xref>). However, in the absence of performance-related feedback at the end of the trial, participants would be unaware of this discrepancy, wrongly believing that the actual trajectory was indeed the intended one. In other words, participants’ imperfect adaptation to changes in control dynamics could be a consequence of control dynamics misestimation.</p><fig-group><fig id="fig5" position="float"><label>Figure 5.</label><caption><title>Bayesian model framework and correlations between the time constant and model-implied residual errors.</title><p><italic>(</italic><bold>A</bold><italic>)</italic>Left: Illustration of the Bayesian estimator model. We fit two parameters: the ratio <italic>λ</italic> of standard deviations of prior and likelihood (<inline-formula><mml:math id="inf40"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>λ</mml:mi><mml:mo>=</mml:mo><mml:msub><mml:mi>σ</mml:mi><mml:mrow><mml:mrow><mml:mi mathvariant="normal">p</mml:mi><mml:mi mathvariant="normal">r</mml:mi><mml:mi mathvariant="normal">i</mml:mi><mml:mi mathvariant="normal">o</mml:mi><mml:mi mathvariant="normal">r</mml:mi></mml:mrow></mml:mrow></mml:msub><mml:mrow><mml:mo>/</mml:mo></mml:mrow><mml:msub><mml:mi>σ</mml:mi><mml:mrow><mml:mrow><mml:mi mathvariant="normal">l</mml:mi><mml:mi mathvariant="normal">i</mml:mi><mml:mi mathvariant="normal">k</mml:mi><mml:mi mathvariant="normal">e</mml:mi><mml:mi mathvariant="normal">l</mml:mi><mml:mi mathvariant="normal">i</mml:mi><mml:mi mathvariant="normal">h</mml:mi><mml:mi mathvariant="normal">o</mml:mi><mml:mi mathvariant="normal">o</mml:mi><mml:mi mathvariant="normal">d</mml:mi></mml:mrow></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula>) and the mean of the prior <inline-formula><mml:math id="inf41"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:msub><mml:mi>μ</mml:mi><mml:mrow><mml:mi mathvariant="normal">p</mml:mi><mml:mi mathvariant="normal">r</mml:mi><mml:mi mathvariant="normal">i</mml:mi><mml:mi mathvariant="normal">o</mml:mi><mml:mi mathvariant="normal">r</mml:mi></mml:mrow></mml:msub><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mstyle></mml:math></inline-formula> of the normally distributed variable <inline-formula><mml:math id="inf42"><mml:mi>φ</mml:mi><mml:mo>=</mml:mo><mml:mrow><mml:mrow><mml:mi mathvariant="normal">log</mml:mi></mml:mrow><mml:mo>⁡</mml:mo><mml:mrow><mml:mi>τ</mml:mi></mml:mrow></mml:mrow></mml:math></inline-formula> (<italic>black dotted box</italic>). Likelihood function is centered on the log-transformation of the actual <italic>τ,</italic> <inline-formula><mml:math id="inf43"><mml:msup><mml:mrow><mml:mi>φ</mml:mi></mml:mrow><mml:mrow><mml:mi>*</mml:mi></mml:mrow></mml:msup><mml:mo>=</mml:mo><mml:mrow><mml:mrow><mml:mi mathvariant="normal">log</mml:mi></mml:mrow><mml:mo>⁡</mml:mo><mml:mrow><mml:msup><mml:mrow><mml:mi>τ</mml:mi></mml:mrow><mml:mrow><mml:mi>*</mml:mi></mml:mrow></mml:msup></mml:mrow></mml:mrow></mml:math></inline-formula> (<italic>black dashed line</italic>). The time constant estimate <inline-formula><mml:math id="inf44"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mrow><mml:mover><mml:mi>τ</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow></mml:mrow></mml:mstyle></mml:math></inline-formula> corresponded to the median of the posterior distribution over <inline-formula><mml:math id="inf45"><mml:mi>τ</mml:mi></mml:math></inline-formula>, which corresponds to the median <inline-formula><mml:math id="inf46"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mrow><mml:mrow><mml:mover><mml:mi>φ</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow></mml:mrow></mml:mrow></mml:mstyle></mml:math></inline-formula> over <inline-formula><mml:math id="inf47"><mml:mi>φ</mml:mi></mml:math></inline-formula>, <inline-formula><mml:math id="inf48"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mrow><mml:mrow><mml:mover><mml:mi>τ</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow></mml:mrow><mml:mo>=</mml:mo><mml:mrow><mml:mi mathvariant="normal">e</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">x</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">p</mml:mi></mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mrow><mml:mover><mml:mi>φ</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mstyle></mml:math></inline-formula> (<italic>red dotted box;red dashed line</italic>; see Materials and methods). Middle: Control dynamics implied by the actual time constant <inline-formula><mml:math id="inf49"><mml:mi>τ</mml:mi></mml:math></inline-formula> (top; gray shade) and the estimated time constant <inline-formula><mml:math id="inf50"><mml:mover accent="true"><mml:mrow><mml:mi>τ</mml:mi></mml:mrow><mml:mo>^</mml:mo></mml:mover></mml:math></inline-formula> (bottom; red shade). <inline-formula><mml:math id="inf51"><mml:mi>u</mml:mi></mml:math></inline-formula>, <inline-formula><mml:math id="inf52"><mml:mi>v</mml:mi></mml:math></inline-formula>, and <inline-formula><mml:math id="inf53"><mml:mi>o</mml:mi></mml:math></inline-formula> denote joystick input, movement velocity, and sensory observations, respectively, and subscripts denote time indices. <inline-formula><mml:math id="inf54"><mml:mover accent="true"><mml:mrow><mml:mi>v</mml:mi></mml:mrow><mml:mo>^</mml:mo></mml:mover></mml:math></inline-formula> denotes the inferred velocity implied by the model. Misestimation of the time constant leads to erroneous velocity estimates about self-motion <inline-formula><mml:math id="inf55"><mml:mover accent="true"><mml:mrow><mml:mi>v</mml:mi></mml:mrow><mml:mo>^</mml:mo></mml:mover></mml:math></inline-formula> which result in biased position beliefs. Right: Illustration of the actual (black) and believed (red) trajectories produced by integrating (box) the actual velocity <inline-formula><mml:math id="inf56"><mml:mi>v</mml:mi></mml:math></inline-formula> and the estimated velocity <inline-formula><mml:math id="inf57"><mml:mover accent="true"><mml:mrow><mml:mi>v</mml:mi></mml:mrow><mml:mo>^</mml:mo></mml:mover></mml:math></inline-formula> , respectively. <italic>White and yellow dots</italic> denote the starting and target position, respectively. Inset: Illustration of correlated (<italic>black</italic> dots) and uncorrelated (<italic>red</italic> dots) residual errors with the time constant for actual and model-implied responses (simulated data). For simplicity, we depict residual errors as one-dimensional and assume unbiased responses (response gain of 1). Blown-up dots with yellow halo correspond to the actual and model-implied trajectories of the right panel. <italic>Solid black horizontal line</italic> corresponds to zero residual error (i.e. stop on target location). (<bold>B</bold>) Comparison of correlations between real and subjective residual errors with <italic>τ</italic> (<xref ref-type="supplementary-material" rid="fig5sdata1">Figure 5—source data 1</xref>). On the right, participant averages of these correlations are shown. Colored bars: ‘Subjective’ correlations, open bars: Actual correlations. Error bars denote ±1 SEM across participants. <italic>Asterisks</italic> denote the level of statistical significance of differences between real and subjective correlations (*: p&lt;0.05, **: p&lt;0.01, ***: p&lt;0.001).</p><p><supplementary-material id="fig5sdata1"><label>Figure 5—source data 1.</label><caption><title>correlations between time constant and model-implied residual errors.</title></caption><media mime-subtype="zip" mimetype="application" xlink:href="elife-63405-fig5-data1-v1.zip"/></supplementary-material></p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-63405-fig5-v1.tif"/></fig><fig id="fig5s1" position="float" specific-use="child-fig"><label>Figure 5—figure supplement 1.</label><caption><title>Testing model assumptions.</title><p>(<bold>A</bold>) Correlation coefficients between the time constant and travel duration (left) or average travel velocity (right) across trials for all participants.</p><p><italic>Colors of circles</italic> indicate the sensory condition (<italic>green</italic>: vestibular, <italic>cyan</italic>: visual, <italic>purple</italic>: combined). <italic>Open and filled circles</italic> denote statistical significance according to the legend. (<bold>B</bold>) Dependence of travel duration (<italic>top right</italic>) and average velocity (<italic>bottom right</italic>) on the time constant for perfect or no estimation/adaptation to the dynamics (<italic>left</italic>), for a simulated bang-bang controller. Correlation coefficients and statistical significance are indicated in the legends of the corresponding panels. Solid lines represent linear regression fits. (<bold>C</bold>) Left: Uncertainty (variance) of instantaneous self-motion velocity estimation. Illustration of a linear (<italic>blue</italic>) and a quadratic (<italic>orange</italic>) model of velocity estimation uncertainty as a function of the instantaneous velocity magnitude. We wanted to test whether the effect of the time constant on performance could be attributed to differences in the accumulated uncertainty of the different velocity profiles. Right: Correlation between time constant and accumulated uncertainty for the linear and quadratic models. We found that the accumulated uncertainty is positively correlated with the time constant for both models (adding an intercept term to the models did not qualitatively change the results). This means that higher time constants yield larger uncertainty and, therefore, participants should undershoot more. However, this is the opposite of the observed effect of the time constant on the responses. Error bars denote ±1 SEM.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-63405-fig5-figsupp1-v1.tif"/></fig><fig id="fig5s2" position="float" specific-use="child-fig"><label>Figure 5—figure supplement 2.</label><caption><title>Changes in travel distance for a given control input under different control dynamics.</title><p>Whether in the domain of velocity (<italic>top</italic>) or acceleration control (<italic>bottom</italic>), a control input that is appropriate to reach a certain target distance (<italic>horizontal black dashed line</italic>) under only a certain time constant (<italic>red vertical line</italic>) will produce erroneous displacements under any other time constant (<italic>blue line</italic>). For smaller time constants, the intended distance will be undershot, whereas larger time constants will lead to overshooting. In other words, assuming that the <italic>red vertical line</italic> denotes the believed dynamics of a controller, a larger actual time constant (underestimation) will lead to overshooting (relative to the intended displacement; <italic>horizontal black dashed line</italic>). Inversely, overestimation of the time constant would lead to undershooting. Note that, for acceleration control, we chose a bang-bang controller such that we can demonstrate that this holds true whether there is braking at the end of the trial or not.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-63405-fig5-figsupp2-v1.tif"/></fig></fig-group><p>We tested the hypothesis that participants misestimated the time constant using a two-step model that reconstructs the participants’ believed trajectories according to their <italic>point estimate</italic> of the time constant <italic>τ</italic>, as follows. First, a Bayesian observer model infers the participant’s belief about <italic>τ</italic> on individual trials, that is, the subjective posterior distribution over the time constant (<italic>τ</italic> inference step; <xref ref-type="fig" rid="fig5">Figure 5A</xref>, left). Second, we used the median of that belief to reconstruct the believed trajectory by integrating the actual joystick input according to the <italic>estimated</italic> time constant on that trial (integration step), resulting in a believed stopping location (<xref ref-type="fig" rid="fig5">Figure 5A</xref>, middle-right). In the absence of bias (response gain of one), the believed stopping locations should land on or near the target. However, various unmeasurable fluctuations in that belief across trials should lead to variability clustered around the target location. When the behavior is biased (response gain different from one, as was the case here – <xref ref-type="fig" rid="fig2">Figure 2D</xref>), this cluster should instead be centered around the participants’ <italic>mean</italic> belief for that target location (determined from their biased responses and henceforth referred to as <italic>mean stopping location</italic>). Since the participants’ goal is to stop as close to their perceived target location as possible, the deviation of believed stopping locations from the mean stopping location for a given target should be small. We call this deviation the <italic>subjective</italic> residual error. Therefore, we inferred the parameters of the Bayesian model separately for each participant by minimizing the <italic>subjective</italic> residual errors induced by the control dynamics using the principle of least squares (see Materials and methods for further details). We next describe the parameters of the Bayesian model and then describe the results of fitting the model to our data.</p><p>Because the time constant <italic>τ</italic> is always positive, we model both the prior distribution and the likelihood function over the variable <inline-formula><mml:math id="inf58"><mml:mi>φ</mml:mi><mml:mo>=</mml:mo><mml:mrow><mml:mrow><mml:mi mathvariant="normal">log</mml:mi></mml:mrow><mml:mo>⁡</mml:mo><mml:mrow><mml:mi>τ</mml:mi></mml:mrow></mml:mrow></mml:math></inline-formula> as Gaussians in log-space. We parameterized both the prior and the likelihood with a mean (<inline-formula><mml:math id="inf59"><mml:mi>μ</mml:mi></mml:math></inline-formula>) and standard deviation (<inline-formula><mml:math id="inf60"><mml:mi>σ</mml:mi></mml:math></inline-formula>). The mean of the prior (<inline-formula><mml:math id="inf61"><mml:mi>μ</mml:mi></mml:math></inline-formula>) was allowed to freely vary across sensory conditions but assumed to remain fixed across trials. On each trial, the likelihood was assumed to be centered on the actual value of the log time constant <inline-formula><mml:math id="inf62"><mml:msup><mml:mrow><mml:mi>τ</mml:mi></mml:mrow><mml:mrow><mml:mi>*</mml:mi></mml:mrow></mml:msup></mml:math></inline-formula> on that trial according to <inline-formula><mml:math id="inf63"><mml:mi>μ</mml:mi><mml:mo>=</mml:mo><mml:msup><mml:mrow><mml:mi>φ</mml:mi></mml:mrow><mml:mrow><mml:mi>*</mml:mi></mml:mrow></mml:msup><mml:mo>=</mml:mo><mml:mrow><mml:mrow><mml:mi mathvariant="normal">log</mml:mi></mml:mrow><mml:mo>⁡</mml:mo><mml:mrow><mml:msup><mml:mrow><mml:mi>τ</mml:mi></mml:mrow><mml:mrow><mml:mi>*</mml:mi></mml:mrow></mml:msup></mml:mrow></mml:mrow></mml:math></inline-formula> and was therefore not a free parameter. Finally, we set the ratio <inline-formula><mml:math id="inf64"><mml:mi>λ</mml:mi></mml:math></inline-formula> of prior over likelihood <inline-formula><mml:math id="inf65"><mml:mi>σ</mml:mi></mml:math></inline-formula>, to freely vary across sensory conditions. Thus, for each sensory condition, we fit two parameters: the <inline-formula><mml:math id="inf66"><mml:mi>μ</mml:mi></mml:math></inline-formula> of the prior, and the ratio (<inline-formula><mml:math id="inf67"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>λ</mml:mi></mml:mrow></mml:mstyle></mml:math></inline-formula>) of prior <inline-formula><mml:math id="inf68"><mml:mi>σ</mml:mi></mml:math></inline-formula> to likelihood <inline-formula><mml:math id="inf69"><mml:mi>σ</mml:mi></mml:math></inline-formula>. As mentioned above, we fit the model to minimize the difference between their believed stopping locations and their experimentally measured mean stopping location (<italic>subjective</italic> residual errors), using a least-squares approach (Materials and methods) and obtained one set of parameters for each condition. Finally, the participant’s estimated time constant <inline-formula><mml:math id="inf70"><mml:mover accent="true"><mml:mrow><mml:mi>τ</mml:mi></mml:mrow><mml:mo>^</mml:mo></mml:mover></mml:math></inline-formula> on each trial was taken to be the median of the best-fit model, which equals the median of the distribution over <inline-formula><mml:math id="inf71"><mml:mi>φ</mml:mi></mml:math></inline-formula> (<xref ref-type="fig" rid="fig5">Figure 5A</xref>, left). By integrating the subject’s joystick inputs on each trial using <inline-formula><mml:math id="inf72"><mml:mover accent="true"><mml:mrow><mml:mi>τ</mml:mi></mml:mrow><mml:mo>^</mml:mo></mml:mover></mml:math></inline-formula> rather than the actual time constant <inline-formula><mml:math id="inf73"><mml:mi>τ</mml:mi></mml:math></inline-formula>, we computed the believed stopping location and the subjective residual errors implied by the best-fit model.</p><p>We then compared the correlations between the time constant and the residual errors for <italic>real responses</italic> (from data in <xref ref-type="fig" rid="fig3">Figure 3B and C</xref>) or <italic>subjective</italic> responses (from model), separately for radial and angular components. Because participants try to stop at their believed target location, the believed stopping position should depend only on target location and not on the control dynamics. Any departure would suggest that participants <italic>knowingly</italic> failed to account for the effect of the control dynamics, which would manifest as a dependence of the <italic>subjective</italic> residual errors on the time constant <italic>τ</italic>. In other words, a good model of the participants’ beliefs would predict that the <italic>subjective</italic> residual errors should be uncorrelated with the time constant <italic>τ</italic> (<xref ref-type="fig" rid="fig5">Figure 5A</xref> inset – red) even if the <italic>real</italic> residual errors are correlated with the time constant (<xref ref-type="fig" rid="fig5">Figure 5A</xref> inset – black). In all cases, we observed that the correlation between residual error and time constant was indeed significantly smaller when these errors were computed using the <italic>subjective</italic> (believed) rather than <italic>real</italic> stopping location (<xref ref-type="fig" rid="fig5">Figure 5B</xref>). In fact, subjective residual errors were completely uncorrelated with the time constant suggesting that the Bayesian model is a good model of participants’ beliefs, and that the apparent influence of control dynamics on behavioral performance was entirely because participants misestimated the time constant of the underlying dynamics.</p><p>We next examined the model posterior estimates to assess how subjects’ internal estimate of the control dynamics departed from the true dynamics. The relationship between real and model-estimated time constants for all participants can be seen in <xref ref-type="fig" rid="fig6">Figure 6A</xref>. In the vestibular condition, all participants consistently misestimated <italic>τ</italic>, exhibiting a substantial regression toward the mean (<xref ref-type="fig" rid="fig6">Figure 6A</xref>, green). This effect was much weaker in the visual condition. Only a few participants showed relatively flat estimates, with the majority showing smaller departures from ideal estimates (<italic>dashed line</italic>). The data for the combined condition followed a similar trend, with properties between those in the visual and vestibular conditions (<xref ref-type="fig" rid="fig6">Figure 6A</xref>, purple). These results suggest that the better control adaptation in the visual and combined conditions shown in <xref ref-type="fig" rid="fig3">Figure 3</xref> is due to participants’ improved estimates of the time constant when optic flow was available.</p><fig id="fig6" position="float"><label>Figure 6.</label><caption><title>Model parameters.</title><p>(<bold>A</bold>) Relationship between the model-estimated and actual time constant across all participants in vestibular (green), visual (cyan), and combined (purple) conditions. Participant averages are superimposed (<italic>thick lines</italic>). <italic>Dashed line</italic>: unbiased estimation (<xref ref-type="supplementary-material" rid="fig6sdata1">Figure 6—source data 1</xref>). (<bold>B</bold>) Fitted model parameters: ratio <inline-formula><mml:math id="inf74"><mml:mi>λ</mml:mi></mml:math></inline-formula> of prior (<inline-formula><mml:math id="inf75"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>σ</mml:mi><mml:mrow><mml:mi>p</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula>) over likelihood (<inline-formula><mml:math id="inf76"><mml:msub><mml:mrow><mml:mi>σ</mml:mi></mml:mrow><mml:mrow><mml:mi>l</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula>) standard deviation and mean (<inline-formula><mml:math id="inf77"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>μ</mml:mi></mml:mrow></mml:mstyle></mml:math></inline-formula>) of prior. Error bars denote ±1 SEM. <italic>Dashed lines</italic> represent the corresponding values of the sampling distribution of <inline-formula><mml:math id="inf78"><mml:mi>φ</mml:mi><mml:mo>=</mml:mo><mml:mrow><mml:mrow><mml:mi mathvariant="normal">log</mml:mi></mml:mrow><mml:mo>⁡</mml:mo><mml:mrow><mml:mi>τ</mml:mi></mml:mrow></mml:mrow></mml:math></inline-formula> , which is normal (see Materials and methods; <xref ref-type="supplementary-material" rid="fig6sdata2">Figure 6—source data 2</xref>). The prior distribution’s <inline-formula><mml:math id="inf79"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>μ</mml:mi></mml:mrow></mml:mstyle></mml:math></inline-formula> was comparable in the vestibular condition to the <inline-formula><mml:math id="inf80"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>μ</mml:mi></mml:mrow></mml:mstyle></mml:math></inline-formula> of the actual sampling distribution (sampling distribution <inline-formula><mml:math id="inf81"><mml:mi>μ</mml:mi></mml:math></inline-formula>: 0.58 <inline-formula><mml:math id="inf82"><mml:mrow><mml:mrow><mml:mi mathvariant="normal">log</mml:mi></mml:mrow><mml:mo>⁡</mml:mo><mml:mrow><mml:mi>s</mml:mi></mml:mrow></mml:mrow></mml:math></inline-formula> – p-value of prior <inline-formula><mml:math id="inf83"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>μ</mml:mi></mml:mrow></mml:mstyle></mml:math></inline-formula> difference obtained by bootstrapping – vestibular: p = 0.014, visual: p =&lt; 10<sup>–7</sup>; combined: p &lt; 10<sup>–7</sup>). <italic>Asterisks</italic> denote the level of statistical significance of differences in the fitted parameters across conditions (*: p&lt;0.05, **: p&lt;0.01, ***: p&lt;0.001).</p><p><supplementary-material id="fig6sdata1"><label>Figure 6—source data 1.</label><caption><title>Real versus estimated time constants.</title></caption><media mime-subtype="zip" mimetype="application" xlink:href="elife-63405-fig6-data1-v1.zip"/></supplementary-material></p><p><supplementary-material id="fig6sdata2"><label>Figure 6—source data 2.</label><caption><title>Model parameters.</title></caption><media mime-subtype="zip" mimetype="application" xlink:href="elife-63405-fig6-data2-v1.zip"/></supplementary-material></p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-63405-fig6-v1.tif"/></fig><p>The source of inaccuracies in the estimated time constant can be understood by examining the model parameters (<xref ref-type="fig" rid="fig6">Figure 6B</xref>).The ratio <inline-formula><mml:math id="inf84"><mml:mi>λ</mml:mi></mml:math></inline-formula> of prior over likelihood standard deviations was significantly lower in the vestibular condition than other conditions, suggesting stronger relative weighting of the prior over the likelihood (<xref ref-type="fig" rid="fig6">Figure 6B</xref> left, green bar; mean ratio <inline-formula><mml:math id="inf85"><mml:mi>λ</mml:mi></mml:math></inline-formula>± standard SEM – vestibular: 0.30 ± 0.09, visual: 1.02 ± 0.17, combined: 0.80 ± 0.10; p-value of ratio <inline-formula><mml:math id="inf86"><mml:mi>λ</mml:mi></mml:math></inline-formula> paired differences obtained by bootstrapping – vestibular vs. visual: p = 0.0007, vestibular vs. combined: p = 0.0087; visual vs. combined: p = 0.016). Notably, the ratio was close to one for the visual and combined conditions, suggesting equal weighting of prior and likelihood. Thus, participants’ estimate of the control dynamics in the vestibular condition was plagued by a combination of strong prior and weak likelihood, which explains the much stronger regression toward the mean in <xref ref-type="fig" rid="fig6">Figure 6A</xref>.</p></sec><sec id="s2-5"><title>Alternative models</title><p>To test whether our assumption of a static prior distribution over time constants was reasonable, we fit an alternative Bayesian model in which the prior distribution was updated iteratively on every trial, as a weighted average of the prior on the previous trial and the current likelihood over <inline-formula><mml:math id="inf87"><mml:mi>φ</mml:mi></mml:math></inline-formula> (Dynamic prior model; see Materials and methods). For this version, the initial prior <inline-formula><mml:math id="inf88"><mml:mi>μ</mml:mi></mml:math></inline-formula> was taken to be the time constant on the first trial, and we once again modeled the likelihood and prior as normal distributions over the log-transformed variable, <inline-formula><mml:math id="inf89"><mml:mi>φ</mml:mi></mml:math></inline-formula>, where the likelihood was centered on the actual <inline-formula><mml:math id="inf90"><mml:mi>φ</mml:mi></mml:math></inline-formula> and was therefore not a free parameter. Thus, we fit one parameter: the ratio <inline-formula><mml:math id="inf91"><mml:mi>λ</mml:mi></mml:math></inline-formula> of prior <inline-formula><mml:math id="inf92"><mml:mi>σ</mml:mi></mml:math></inline-formula> over likelihood <inline-formula><mml:math id="inf93"><mml:mi>σ</mml:mi></mml:math></inline-formula>. On each trial, the relative weighting of prior and likelihood responsible for the update of the prior depended solely on <inline-formula><mml:math id="inf94"><mml:mi>λ</mml:mi></mml:math></inline-formula>; that is, the relationship between their corresponding <inline-formula><mml:math id="inf95"><mml:mi>σ</mml:mi></mml:math></inline-formula> (i.e. relative widths). The performance of the static and dynamic prior models was comparable in all conditions, for both distance and angle, suggesting that a static prior is adequate in explaining the participants’ behavior on this task (<xref ref-type="fig" rid="fig7">Figure 7</xref>; <italic>light</italic> vs. <italic>dark bars</italic>). In line with our expectations, when updating the prior in the dynamic model, the weighting of the previous-trial prior received significantly more weight in the vestibular condition (in the range of [0,1]; mean prior weights ± SEM– vestibular: 0.93 ± 0.03, visual: 0.48 ± 0.10, combined: 0.61 ± 0.09; p-value of paired weight differences obtained by bootstrapping – vestibular vs. visual: p = 10<sup>–5</sup> , vestibular vs. combined: p = 4 · 10<sup>–4</sup>; visual vs. combined: p = 0.08). The comparable goodness of models with static and dynamic priors suggest that sensory observations were not too reliable to cause rapid changes in prior expectations during the course of the experiment.</p><fig-group><fig id="fig7" position="float"><label>Figure 7.</label><caption><title>Comparison of the correlations between the actual <italic>τ</italic> and the subjective residual errors implied by three different <italic>τ</italic>-estimation models (Bayesian estimation with a static prior ([S], Bayesian estimation with a dynamic prior [D], fixed estimate [F]).</title><p>We tested the hypotheses that either the prior distribution should not be static or that the participants ignored changes in the control dynamics and navigated according to a fixed time constant across all trials (fixed <italic>τ</italic> estimate model; see Materials and methods). For this, we compared the correlations between the subjective residual error and the actual trial <italic>τ</italic> that each model produces. The dynamic prior model performs similarly to the static prior model in all conditions, indicating that a static prior is adequate in explaining our data (p-values of paired t-test between correlation coefficients of the two models: distance – vestibular: p = 0.96, visual: p = 0.19, combined: p = 0.91; angle – vestibular: p = 0.87, visual: p = 0.09, combined: p = 0.59). For visual and combined conditions, the fixed <italic>τ</italic> model not only fails to minimize the correlations but, in fact, strongly reverses it, for both distance (<italic>left</italic>) and angle (<italic>right</italic>). Since these correlations arise from the believed trajectories that the fixed <italic>τ</italic> model produces, this suggests that participants knowingly stop before their believed target location for higher time constants. Model performance was only comparable in the vestibular condition, where the average correlation of the fixed <italic>τ</italic> model (F) was contained within the 95% confidence intervals (CI) of the static prior Bayesian model (<italic>S</italic>), for both distance and angle (distance – <italic>F</italic>: mean Pearson’s correlation coefficient <italic>ρ</italic> = 0.03, <italic>S</italic>: 95% CI of Pearson’s correlation coefficient <italic>ρ</italic> = [–0.10 0.25]; angle – <italic>F</italic>: mean Pearson’s correlation coefficient <italic>ρ</italic> = –0.01, <italic>S</italic>: 95% CI of Pearson’s correlation coefficient <italic>ρ</italic> = [–0.12 0.15]). Error bars denote ±1 SEM.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-63405-fig7-v1.tif"/></fig><fig id="fig7s1" position="float" specific-use="child-fig"><label>Figure 7—figure supplement 1.</label><caption><title>Correlation coefficients in the vestibular condition between the actual time constant and the subjective radial (left) and angular (right) residual errors, if participants carried over their <italic>τ</italic> estimate from the previous trial.</title><p>With sensory conditions interleaved and a common random walk of <italic>τ</italic> (see Materials and methods, <xref ref-type="fig" rid="fig1s3">Figure 1—figure supplement 3C</xref>), we searched for a trial-type history effect in the vestibular condition, due to participants’ poor <italic>τ</italic> estimation performance. Specifically, we asked whether participants in the vestibular condition would leverage from the correlation structure between recent time constants by carrying over their estimates from the previous visual or combined trials. We first compared the correlations from the actual data (<italic>open bars</italic>; same as <xref ref-type="fig" rid="fig3">Figures 3C</xref> and <xref ref-type="fig" rid="fig5">5B</xref>) with those obtained when using the actual (<italic>middle bar couple</italic>) or estimated (<italic>right bar couple;</italic> estimates from the static prior Bayesian model) time constant from the previous visual (<italic>cyan bars</italic>) or combined (<italic>purple bars</italic>) trial to generate believed trajectories. Although correlations were significantly smaller for the carry-over models relative to the actual data (p&lt;0.01) they nevertheless remained significant (p&lt;10<sup>−5</sup>), thus, failing to explain away the effect (compare with <italic>gray bars</italic>: correlations implied by estimation in the current vestibular trial with the static prior Bayesian model). The carry-over strategy does not seem likely since it fails to explain away a large part of the correlation between the radial component of the subjective residual errors and the time constant (compare rightmost <italic>cyan/purple bars</italic> with <italic>gray bars</italic>; p-values of paired <italic>t</italic>-test between radial correlation coefficients – current vestibular vs. previous visual trial estimation: p=0.006, current vestibular vs. previous combined trial estimation: p=0.02; p-values of paired <italic>t</italic>-test between angular correlation coefficients – current vestibular vs. previous visual trial estimation: p=0.008, current vestibular vs. previous combined trial estimation: p = 0.71). <italic>Error bars</italic> denote ±1 SEM across participants.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-63405-fig7-figsupp1-v1.tif"/></fig><fig id="fig7s2" position="float" specific-use="child-fig"><label>Figure 7—figure supplement 2.</label><caption><title>Comparing bayesian and feedback control models.</title><p>(<bold>A</bold>) We tested a sensory feedback control model, in which the controller uses bang-bang control and switches from forward to backward input at a constant and predetermined distance from the target position (corrected for the bias).</p><p>We fit the mean and standard deviation of the switch distance for each participant in each condition separately, by minimizing the distance of the actual from the model-predicted stopping locations (see Materials and methods). The correlations (<italic>left</italic>) and the regression slopes (<italic>right</italic>) between the model-predicted residual errors and the time constant were significantly higher than those found in our data (p-values of difference in correlations between true data and model obtained by paired <italic>t</italic>-test – vestibular: p = 10<sup>–5</sup>, visual: p = 10<sup>–6</sup>, combined: p = 10<sup>–7</sup>; p-values of difference regression slopes between true data and model obtained by paired <italic>t</italic>-test – vestibular: p = 10<sup>–7</sup>, visual: p = 10<sup>–8</sup>, combined: p = 10<sup>–9</sup>). <italic>Error bars</italic> represent ±1SEM across participants. (<bold>B</bold>) Probability distribution of bang-bang switch distance from target position (corrected for the bias). According to the sensory feedback control model, the probability distribution of switch distance should be very narrow since participants switch at a constant perceived distance from the target. If participants implemented this type of control (<italic>black lines</italic>), we would expect to see such a narrow distribution in the actual data. In all conditions, however, the switch distance distribution of the true data (<italic>colored lines</italic>) is wider and resembles what we expect to see if participants implemented optimal (ideal) bang-bang control (<italic>gray lines</italic>). <italic>Shaded regions</italic> represent ±1 SEM across participants.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-63405-fig7-figsupp2-v1.tif"/></fig></fig-group><p>At the other extreme, to test whether participants used sensory observations at all to estimate control dynamics, we compared the static prior Bayesian model to a parsimonious model that assumed a fixed time constant across all trials (i.e. completely ignoring changes in control dynamics). This latter model can be understood as a Bayesian model instantiated with a very strong static prior. In line with our expectations (see <xref ref-type="fig" rid="fig6">Figure 6A</xref>), this latter model performed comparably in the vestibular condition, but substantially worse in the visual and combined conditions (<xref ref-type="fig" rid="fig7">Figure 7</xref>).</p><p>Due to the correlated nature of the random walk process dictating the evolution of time constants, an alternative by which participants could get away without estimating the time constant in the vestibular condition would be to carry over their estimate from the previous combined/visual trial to the current vestibular trial. To test this, we considered two models: the time constant estimate in the current vestibular trial was taken to be either the real time constant or the posterior estimate of the time constant from the previous visual/combined trial. Neither model, however, could account for the participants’ behavior, as they could not fully explain away the correlation between the residual errors and the time constant (<xref ref-type="fig" rid="fig7s1">Figure 7—figure supplement 1</xref>). Intuitively, although choosing actions with respect to the previous trial’s time constant should result in estimates that regress toward the mean, the predicted effect is weaker than that observed in the data.</p><p>Finally, we tested a variation of previously suggested sensory feedback control models (<xref ref-type="bibr" rid="bib17">Glasauer et al., 2007</xref>; <xref ref-type="bibr" rid="bib18">Grasso et al., 1999</xref>) where a controller relies solely on sensory inputs to adjust their control without explicitly estimating the latent variables governing the control dynamics. Specifically, the model assumes that participants implement a type of bang-bang control that switches at a certain distance from the target (or more accurately, the mean response). However, this model predicts a much stronger dependence of the responses on the dynamics compared to our data, and characteristics of the predicted control input differ significantly from the actual control (<xref ref-type="fig" rid="fig7s2">Figure 7—figure supplement 2</xref>). Overall, our results suggest that optic flow, but not vestibular signals, primarily contributes to inferring the latent velocity dynamics.</p></sec></sec><sec id="s3" sec-type="discussion"><title>Discussion</title><p>We showed that human participants can navigate using different sensory cues and that changes in the control dynamics affect their performance. Specifically, we showed that participants can path integrate to steer toward a remembered target location quite accurately in the presence of optic flow. In contrast, inertial (vestibular/somatosensory) cues generated by motion cueing alone lacked the reliability to support accurate path integration, leading to substantially biased responses under velocity control. Performance was also influenced by the changing control dynamics in all sensory conditions. Because control dynamics were varied on a trial-by-trial basis, sensory cues were crucial for inferring those dynamics. We used probabilistic inference models to show that the observed responses are consistent with estimates of the control dynamics that were biased toward the center of the experimental distribution. This was particularly strong under the vestibular condition such that the response gain substantially increased as the motion dynamics tended toward acceleration control. Although control dynamics were correlated across trials, our models showed that participants did not take advantage of those correlations to improve their estimates.</p><sec id="s3-1"><title>Relation to past work</title><p>In the paradigm used here, participants actively controlled linear and angular motion, allowing us to study multisensory path integration in two dimensions with few constraints. This paradigm was made possible by the development of an MC algorithm to render visual and vestibular cues either synchronously or separately. In contrast, previous studies on human path integration used restricted paradigms in which motion was either 1D or passively rendered, and participants’ decisions were typically reduced to end-of-trial binary evaluations of relative displacement (<xref ref-type="bibr" rid="bib9">Campos et al., 2012</xref>; <xref ref-type="bibr" rid="bib11">Chrastil et al., 2016</xref>; <xref ref-type="bibr" rid="bib12">Chrastil et al., 2019</xref>; <xref ref-type="bibr" rid="bib21">Jürgens and Becker, 2006</xref>; <xref ref-type="bibr" rid="bib26">Koppen et al., 2019</xref>; <xref ref-type="bibr" rid="bib48">ter Horst et al., 2015</xref>; <xref ref-type="bibr" rid="bib49">Tramper and Medendorp, 2015</xref>). As a result, findings from past studies that evaluate the contributions of different sensory modalities to self-motion perception (<xref ref-type="bibr" rid="bib12">Chrastil et al., 2019</xref>; <xref ref-type="bibr" rid="bib19">Israël et al., 1996</xref>; <xref ref-type="bibr" rid="bib26">Koppen et al., 2019</xref>; <xref ref-type="bibr" rid="bib42">Seemungal et al., 2007</xref>; <xref ref-type="bibr" rid="bib48">ter Horst et al., 2015</xref>) may be more limited in generalizing to real-world navigation.</p><p>Our results show that, at least in humans, navigation is driven primarily by visual cues under conditions of near-constant travel velocity (velocity control). This dominance of vision suggests that the reliability of the visual cues is much higher than vestibular cues (as generated by our platform), as corroborated by the data from the combined condition in which performance resembles the visual condition. This makes sense because the vestibular system is mainly sensitive to acceleration, exhibiting higher sensitivity to higher-frequency motion compared to the visual system (<xref ref-type="bibr" rid="bib22">Karmali et al., 2014</xref>). Consequently, it may only be reliable when motion is dominated by acceleration. This interpretation is further supported by the observation that participants’ vestibular performance was a lot less biased in the regime of acceleration joystick control, where accelerations are prolonged during navigation.</p><p>Experimental constraints in past navigation studies have also precluded examining the influence of control dynamics. In fact, the importance of accurately inferring control dynamics, which are critical for predicting the sensory consequences of actions, has largely been studied in the context of limb control and motor adaptation (<xref ref-type="bibr" rid="bib7">Burdet et al., 2001</xref>; <xref ref-type="bibr" rid="bib28">Kording et al., 2007</xref>; <xref ref-type="bibr" rid="bib29">Krakauer et al., 1999</xref>; <xref ref-type="bibr" rid="bib30">Lackner and Dizio, 1994</xref>; <xref ref-type="bibr" rid="bib44">Shadmehr and Mussa-Ivaldi, 1994</xref>; <xref ref-type="bibr" rid="bib46">Takahashi et al., 2001</xref>). Here, we provide evidence for the importance of accurately inferring control dynamics in the context of path integration and spatial navigation. Although participants were not instructed to expect changes in the latent dynamics and received no feedback, we showed that they nevertheless partly adapted to those dynamics while exhibiting a bias toward prior expectations about these dynamics. This biased estimation of control dynamics led to biased path integration performance. This result is analogous to findings about the effect of changing control dynamics in motor control: first, adaptation to the dynamics happens even in the absence of performance-related feedback (<xref ref-type="bibr" rid="bib4">Batcho et al., 2016</xref>; <xref ref-type="bibr" rid="bib30">Lackner and Dizio, 1994</xref>) and, second, this adaptation relies on prior experience (<xref ref-type="bibr" rid="bib3">Arce et al., 2009</xref>) and leads to systematic errors when knowledge of the dynamics is inaccurate (<xref ref-type="bibr" rid="bib27">Körding et al., 2004</xref>). Thus, participants try to exploit the additional information that the dynamics contain about their self-motion in order to achieve the desired displacement.</p><p>A Bayesian estimator with a static prior over the dynamics sufficiently explained participants’ beliefs in our data, while results were comparable with a dynamic prior that was updated at every trial. This could be attributed to the structure of the random walk of the control dynamics across trials, as a static prior is not as computationally demanding and potentially more suitable for fast changes in the time constant. These Bayesian models attempt to explain behavior in an optimal way given the task structure. Meanwhile, alternative suboptimal models (fixed estimate, carry-over estimate, sensory feedback model) failed to explain behavior successfully, especially when optic flow was available. These results strongly favor underlying computations within the context of optimality in the presence of optic flow.</p><p>Task performance was substantially worse in the vestibular condition, in a manner suggesting that vestibular inputs from motion cueing lack the reliability to precisely estimate control dynamics on individual trials. Nevertheless, the vestibular system could still facilitate inference by integrating trial history to build expectations about their statistics. Consistent with this, the mean of the prior distribution over the dynamics fit to data was very close to the mean of the true sampled distribution, suggesting that even if within-trial vestibular observations are not sufficient, participants possibly combine information about the dynamics across trials to construct their prior beliefs. This is consistent with the findings of <xref ref-type="bibr" rid="bib39">Prsa et al., 2015</xref>, where vestibular cues were used to infer an underlying pattern of magnitude of motion across trials. However, the measurement of the dynamics in that study substantially differs from ours: here, motion dynamics are inferred using self-motion cues within each trial whereas in <xref ref-type="bibr" rid="bib39">Prsa et al., 2015</xref>, the dynamics were inferred by integrating observations about the magnitude of the displacement across trials. If vestibular cues can in fact support inference of dynamics – as recent findings suggest in eye-head gaze shifts (<xref ref-type="bibr" rid="bib40">Sağlam et al., 2014</xref>) – a common processing mechanism could be shared across sensory modalities. Overall, this finding highlights the importance of incorporating estimates of the control dynamics in models of self-motion perception and path integration.</p></sec><sec id="s3-2"><title>Limitations and future directions</title><p>Note that restrictions of our motion platform limited the range of velocities that could be tested, allowing only for relatively small velocities (see Materials and methods). Consequently, trial durations were long, but the motion platform also restricted total displacement, so we could not test larger target distances. We previously studied visual path integration with larger velocities and our results in the visual and combined conditions are comparable for similar travel times (as trials exceeded durations of 10 s, undershooting became more prevalent; <xref ref-type="bibr" rid="bib31">Lakshminarasimhan et al., 2018</xref>). However, it is unclear how larger velocities (and accelerations) would affect participants’ performance (especially under the vestibular condition) and whether the present conclusions are also representative of the regime of velocities not tested.</p><p>The design of the MC algorithm allowed us to circumvent the issues associated with the physical limitations of the platform to a large degree. This was achieved in part by exploiting the tilt/translation ambiguity and substituting linear translation with tilt (see Materials and methods). However, high-frequency accelerations, as those found at movement onset, generated tilts that briefly exceeded the tilt-detection threshold of the semicircular canals (<xref ref-type="fig" rid="fig1s2">Figure 1—figure supplement 2</xref>). Although the duration of suprathreshold stimulation was very small, we cannot exclude the possibility that the perceived tilt affected the interpretation of vestibular inputs. For example, participants may not attribute tilt to linear translation, hence underestimating their displacement. This, however, would lead to overshooting to compensate for the lack of perceived displacement,which is not what we observed in our experiment. Another potential explanation for the poor vestibular performance could be that participants perceive tilt as a conflicting cue with respect to their expected motion or visual cues. In that case, participants would only use the vestibular inputs to a small extent if at all. Manipulating vestibular inputs (e.g. gain, noise manipulations) in future experiments, either alone or in conjunction with visual cues, would offer valuable insights on two fronts: first, to help clarify the efficiency of our MC algorithm and its implications on the design of driving simulators in the future, and second, to precisely quantify the contribution of vestibular cues to path integration in natural settings.</p><p>For the sake of simplicity, we modeled each trial’s control dynamics as a single measurement per trial when, in reality, participants must infer the dynamics over the course of a trial using a dynamic process of evidence accumulation. Specifically, participants must measure their self-motion velocity over time and combine a series of measurements to extract information about the underlying dynamics. Although we were able to explain the experimental findings of the influence of control dynamics on steering responses with our model, this approach could be expanded into a more normative framework using hierarchical Bayesian models (<xref ref-type="bibr" rid="bib34">Mathys et al., 2011</xref>) to infer subjective position estimates by marginalizing over possible control dynamics.</p><p>One interesting question is whether providing feedback would eliminate the inference bias of the control dynamics estimation and future studies should explicitly test this hypothesis. Furthermore, it would be interesting to jointly introduce sensory conflict and manipulate sensory reliability to study dynamic multisensory integration such that sensory contributions during navigation can be better disentangled. Although it has been shown that cue combination takes place during path integration (<xref ref-type="bibr" rid="bib47">Tcheang et al., 2011</xref>), previous studies have had contradicting results regarding the manner in which body-based and visual cues are combined (<xref ref-type="bibr" rid="bib8">Campos et al., 2010</xref>; <xref ref-type="bibr" rid="bib12">Chrastil et al., 2019</xref>; <xref ref-type="bibr" rid="bib26">Koppen et al., 2019</xref>; <xref ref-type="bibr" rid="bib37">Petrini et al., 2016</xref>; <xref ref-type="bibr" rid="bib48">ter Horst et al., 2015</xref>). Since visual and vestibular signals differ in their sensitivity to different types of motion (<xref ref-type="bibr" rid="bib22">Karmali et al., 2014</xref>), the outcomes of their integration may depend on the self-motion stimuli employed. Combined with hierarchical models of self-motion inference that considers the control dynamics, it is possible to develop an integrated, multi-level model of navigation, while constraining dramatically the hypothesized brain computations and their neurophysiological correlates.</p></sec></sec><sec id="s4" sec-type="materials|methods"><title>Materials and methods</title><sec id="s4-1"><title>Equipment and task</title><p>Fifteen participants (9 male, 6 female; all adults in the age group 18–32) participated in the experiments. Apart from two participants, all participants were unaware of the purpose of the study. Experiments were first performed in the above two participants before testing others. All experimental procedures were approved by the Institutional Review Board at Baylor College of Medicine and all participants signed an approved consent form.</p><sec id="s4-1-1"><title>Experimental setup</title><p>The participants sat comfortably on a chair mounted on an electric motor allowing unrestricted yaw rotation (Kollmorgen motor DH142M-13–1320, Kollmorgen, Radford, VA), itself mounted on a six-degree-of-freedom motion platform (comprised of MOOG 6DOF2000E, Moog Inc, East Aurora, NY). Participants used an analog joystick (M20U9T-N82, CTI electronics, Stratford, CT) with two degrees of freedom and a circular displacement boundary to control their linear and angular speed in a virtual environment based on visual and/or vestibular feedback. The visual stimulus was projected (Canon LV-8235 UST Multimedia Projector, Canon USA, Melville, NY) onto a large rectangular screen (width × height : 158 × 94 cm) positioned in front of the participant (77 cm from the rear of the head). Participants wore crosstalk free ferroelectric active-shutter 3D goggles (RealD CE4s, ColorLink Japan, Ltd, Tokyo, Japan) to view the stimulus. Participants wore headphones generating white noise to mask the auditory motion cues. The participants’ head was fixed on the chair using an adjustable CIVCO FirmFit Thermoplastic face mask (CIVCO, Coralville, IA).</p><p>Spike2 software (Power 1401 MkII data acquisition system from Cambridge Electronic Design Ltd, Cambridge, United Kingdom) was used to record joystick and all event markers for offline analysis at a sampling rate of <inline-formula><mml:math id="inf96"><mml:mn>833</mml:mn><mml:mfrac><mml:mrow><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mn>3</mml:mn></mml:mrow></mml:mfrac></mml:math></inline-formula> Hz.</p></sec><sec id="s4-1-2"><title>Visual stimulus</title><p>Visual stimuli were generated and rendered using C++ Open Graphics Library (OpenGL) by continuously repositioning the camera based on joystick inputs to update the visual scene at 60 Hz. The camera was positioned at a height of 70 cm above the ground plane, whose textural elements lifetimes were limited (∼250 ms) to avoid serving as landmarks. The ground plane was circular with a radius of 37.5 m (near and far clipping planes at 5 and 3750 cm, respectively), with the participant positioned at its center at the beginning of each trial. Each texture element was an isosceles triangle (base × height 5.95 × 12.95 cm) that was randomly repositioned and reoriented at the end of its lifetime. The floor density was held constant across trials at <inline-formula><mml:math id="inf97"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>ρ</mml:mi><mml:mo>=</mml:mo><mml:mn>2.5</mml:mn><mml:mspace width="thickmathspace"/><mml:mrow><mml:mi mathvariant="normal">e</mml:mi><mml:mi mathvariant="normal">l</mml:mi><mml:mi mathvariant="normal">e</mml:mi><mml:mi mathvariant="normal">m</mml:mi><mml:mi mathvariant="normal">e</mml:mi><mml:mi mathvariant="normal">n</mml:mi><mml:mi mathvariant="normal">t</mml:mi><mml:mi mathvariant="normal">s</mml:mi></mml:mrow><mml:mrow><mml:mo>/</mml:mo></mml:mrow><mml:msup><mml:mrow><mml:mi mathvariant="normal">m</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:mstyle></mml:math></inline-formula>. The target, a circle of radius 25 cm whose luminance was matched to the texture elements, flickered at 5 Hz and appeared at a random location between <inline-formula><mml:math id="inf98"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>θ</mml:mi><mml:mo>=</mml:mo><mml:mo>±</mml:mo><mml:mn>38</mml:mn><mml:mtext> </mml:mtext><mml:mi>d</mml:mi><mml:mi>e</mml:mi><mml:mi>g</mml:mi></mml:mrow></mml:mstyle></mml:math></inline-formula> of visual angle at a distance of <inline-formula><mml:math id="inf99"><mml:mi>r</mml:mi><mml:mo>=</mml:mo><mml:mn>2.5</mml:mn><mml:mo>-</mml:mo><mml:mn>5.5</mml:mn><mml:mi> </mml:mi><mml:mi mathvariant="normal">m</mml:mi></mml:math></inline-formula> (average distance <inline-formula><mml:math id="inf100"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mrow><mml:mover><mml:mi>r</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mtext> </mml:mtext></mml:mrow><mml:mo>=</mml:mo><mml:mrow><mml:mtext> </mml:mtext></mml:mrow><mml:mn>4</mml:mn><mml:mrow><mml:mtext> </mml:mtext></mml:mrow><mml:mrow><mml:mi mathvariant="normal">m</mml:mi></mml:mrow></mml:mrow></mml:mstyle></mml:math></inline-formula>) relative to where the participant was stationed at the beginning of the trial. The stereoscopic visual stimulus was rendered in an alternate frame sequencing format and participants wore active-shutter 3D goggles to view the stimulus.</p></sec><sec id="s4-1-3"><title>Behavioral task – visual, inertial, and multisensory motion cues</title><p>Participants were asked to navigate to a remembered target (‘firefly’) location on a horizontal virtual plane using a joystick, rendered in 3D from a forward-facing vantage point above the plane. Participants pressed a button on the joystick to initiate each trial and were tasked with steering to a randomly placed target that was cued briefly at the beginning of the trial. A short tone at every button push indicated the beginning of the trial and the appearance of the target. After 1 s, the target disappeared, which was a cue for the participant to start steering. During steering, visual and/or vestibular/somatosensory sensory feedback was provided (see below). Participants were instructed to stop at the remembered target location, and then push the button to register their final position and start the next trial. Participants did not receive any feedback about their performance. Prior to the first session, all participants performed about 10 practice trials to familiarize themselves with joystick movements and the task structure.</p><p>The three sensory conditions (visual, vestibular, combined) were randomly interleaved. In the visual condition, participants had to navigate toward the remembered target position given only visual information (optic flow). Visual feedback was stereoscopic, composed of flashing triangles to provide self-motion information but no landmark. In the vestibular condition, after the target disappeared, the entire visual stimulus was shut off too, leaving the participants to navigate in complete darkness using only vestibular/somatosensory cues generated by the motion platform. In the combined condition, participants were provided with both visual and vestibular information during their movement.</p><p>Independently of the manipulation of the sensory information, the properties of the motion controller also varied from trial to trial. Participants experienced different time constants in each trial, which affected the type and amount of control that was required to complete the task. In trials with short time constants, joystick position mainly controlled velocity, whereas in trials with long time constants, joystick position approximately controlled the acceleration (explained in detail in <italic>Control dynamics</italic> below).</p><p>Each participant performed a total of about 1450 trials (mean ± standard deviation (SD): 1450 ± 224), split equally among the three sensory conditions (mean ± SD – vestibular: 476 ± 71, visual: 487 ± 77, combined: 487 ± 77). We aimed for at least 1200 total trials per participant, and collected extended data from participants whose availability was compatible with the long runtime of our experiment.</p></sec><sec id="s4-1-4"><title>Joystick control</title><p>Participants navigated in the virtual environment using a joystick placed in front of the participant’s midline, in a holder mounted on the bottom of the screen. This ensured that the joystick was parallel to the participant’s vertical axis, and its horizontal orientation aligned to the forward movement axis. The joystick had two degrees of freedom that controlled linear and angular motion. Joystick displacements were physically bounded to lie within a disk, and digitally bounded to lie within a square. Displacement of the joystick over the anterior-posterior axis resulted in forward or backward translational motion, whereas displacement in the left-right axis resulted in rotational motion. The joystick was enabled after the disappearance of the target. To avoid skipping trials and abrupt stops, the button used to initiate trials was activated only when the participant’s velocity dropped below 1 cm/s.</p><p>The joystick controlled both the visual and vestibular stimuli through an algorithm that involved two processes. The first varied the control dynamics, producing velocities given by a lowpass filtering of the joystick input, mimicking an inertial body under viscous damping. The time constant for the control filter (control timescale) was varied from trial to trial, according to a correlated random process as explained below.</p><p>The second process was an MC algorithm applied to the output of the control dynamics process, which defined physical motion that approximated the accelerations an observer would feel under the desired control dynamics, while avoiding the hardwired constraints of the motion platform. This MC algorithm trades translation for tilt, allowing extended acceleration without hitting the displacement limits (24 cm).</p><p>These two processes are explained in detail below.</p></sec><sec id="s4-1-5"><title>Control dynamics</title><p>Inertia under viscous damping was introduced by applying a lowpass filter on the control input, following an exponential weighted moving average with a time constant that slowly varied across trials. On each trial, the system state evolved according to a first-order Markov process in discrete time, such that the movement velocity at the next time step depended only on the current joystick input and the current velocity. Specifically, the vertical and horizontal joystick positions <inline-formula><mml:math id="inf101"><mml:msubsup><mml:mrow><mml:mi>u</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow><mml:mrow><mml:mi>v</mml:mi></mml:mrow></mml:msubsup></mml:math></inline-formula> and <inline-formula><mml:math id="inf102"><mml:msubsup><mml:mrow><mml:mi>u</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow><mml:mrow><mml:mi>ω</mml:mi></mml:mrow></mml:msubsup></mml:math></inline-formula> determined the linear and angular velocities <inline-formula><mml:math id="inf103"><mml:msub><mml:mrow><mml:mi>v</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> and <inline-formula><mml:math id="inf104"><mml:msub><mml:mrow><mml:mi>ω</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> as:<disp-formula id="equ1"><label>(1a)</label><mml:math id="m1"><mml:mrow><mml:msub><mml:mi>v</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mrow><mml:mi>α</mml:mi><mml:msub><mml:mi>v</mml:mi><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mi>β</mml:mi><mml:mrow><mml:mi>v</mml:mi></mml:mrow></mml:msub><mml:msubsup><mml:mi>u</mml:mi><mml:mrow><mml:mi>t</mml:mi></mml:mrow><mml:mi>v</mml:mi></mml:msubsup></mml:mrow><mml:mspace width="thinmathspace"/><mml:mspace width="thinmathspace"/><mml:mrow><mml:mi mathvariant="normal">a</mml:mi><mml:mi mathvariant="normal">n</mml:mi><mml:mi mathvariant="normal">d</mml:mi></mml:mrow><mml:mspace width="thinmathspace"/><mml:mspace width="thinmathspace"/><mml:mrow><mml:msub><mml:mi>ω</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mi>α</mml:mi><mml:msub><mml:mi>ω</mml:mi><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mi>β</mml:mi><mml:mrow><mml:mi>ω</mml:mi></mml:mrow></mml:msub><mml:msubsup><mml:mi>u</mml:mi><mml:mrow><mml:mi>t</mml:mi></mml:mrow><mml:mrow><mml:mi>ω</mml:mi></mml:mrow></mml:msubsup></mml:mrow></mml:mrow></mml:math></disp-formula></p><p>The time constant <inline-formula><mml:math id="inf105"><mml:mi>τ</mml:mi></mml:math></inline-formula> of the lowpass filter determined the coefficient <inline-formula><mml:math id="inf106"><mml:mi>α</mml:mi></mml:math></inline-formula> (<xref ref-type="fig" rid="fig1s3">Figure 1—figure supplement 3A</xref>):<disp-formula id="equ2"><label>(1b)</label><mml:math id="m2"><mml:mrow><mml:mi>α</mml:mi><mml:mo>=</mml:mo><mml:mtext> </mml:mtext><mml:msup><mml:mi>e</mml:mi><mml:mrow><mml:mfrac><mml:mrow><mml:mo>−</mml:mo><mml:mi mathvariant="normal">Δ</mml:mi><mml:mi>t</mml:mi></mml:mrow><mml:mi>τ</mml:mi></mml:mfrac></mml:mrow></mml:msup></mml:mrow></mml:math></disp-formula></p><p>Sustained maximal controller inputs of <inline-formula><mml:math id="inf107"><mml:msubsup><mml:mrow><mml:mi>u</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow><mml:mrow><mml:mi>v</mml:mi></mml:mrow></mml:msubsup><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:math></inline-formula> or <inline-formula><mml:math id="inf108"><mml:msubsup><mml:mrow><mml:mi>u</mml:mi></mml:mrow><mml:mrow><mml:mi>ω</mml:mi></mml:mrow><mml:mrow><mml:mi>v</mml:mi></mml:mrow></mml:msubsup><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:math></inline-formula> produce velocities that saturate at:<disp-formula id="equ3"><label>(1c)</label><mml:math id="m3"><mml:mrow><mml:msub><mml:mi>ν</mml:mi><mml:mrow><mml:mi mathvariant="normal">m</mml:mi><mml:mi mathvariant="normal">a</mml:mi><mml:mi mathvariant="normal">x</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:msub><mml:mi>β</mml:mi><mml:mrow><mml:mi>ν</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo>/</mml:mo></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:mi>α</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mspace width="1em"/><mml:mrow><mml:mi mathvariant="normal">a</mml:mi><mml:mi mathvariant="normal">n</mml:mi><mml:mi mathvariant="normal">d</mml:mi></mml:mrow><mml:mspace width="1em"/><mml:msub><mml:mi>ω</mml:mi><mml:mrow><mml:mi mathvariant="normal">m</mml:mi><mml:mi mathvariant="normal">a</mml:mi><mml:mi mathvariant="normal">x</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:msub><mml:mi>β</mml:mi><mml:mrow><mml:mi>ω</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo>/</mml:mo></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:mi>α</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></disp-formula></p><p>We wanted to set <inline-formula><mml:math id="inf109"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>v</mml:mi><mml:mrow><mml:mi mathvariant="normal">m</mml:mi><mml:mi mathvariant="normal">a</mml:mi><mml:mi mathvariant="normal">x</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula> and <inline-formula><mml:math id="inf110"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>ω</mml:mi><mml:mrow><mml:mi mathvariant="normal">m</mml:mi><mml:mi mathvariant="normal">a</mml:mi><mml:mi mathvariant="normal">x</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula> in such a way that would ensure that a target at an average linear or angular displacement <inline-formula><mml:math id="inf111"><mml:mi>x</mml:mi></mml:math></inline-formula> is reachable in an average time <inline-formula><mml:math id="inf112"><mml:mi>T</mml:mi></mml:math></inline-formula>, regardless of <inline-formula><mml:math id="inf113"><mml:mi>τ</mml:mi></mml:math></inline-formula> (we set <inline-formula><mml:math id="inf114"><mml:mi>x</mml:mi><mml:mo>=</mml:mo><mml:mn>4</mml:mn></mml:math></inline-formula> m and <inline-formula><mml:math id="inf115"><mml:mi>T</mml:mi><mml:mo>=</mml:mo><mml:mn>8.5</mml:mn></mml:math></inline-formula> s). This constrains the input gains <inline-formula><mml:math id="inf116"><mml:msub><mml:mrow><mml:mi>β</mml:mi></mml:mrow><mml:mrow><mml:mi>v</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> and <inline-formula><mml:math id="inf117"><mml:msub><mml:mrow><mml:mi>β</mml:mi></mml:mrow><mml:mrow><mml:mi>ω</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula>. We derived these desired gains based on a 1D bang-bang control model (i.e. purely forward movement, or pure turning) which assumes maximal positive control until time <inline-formula><mml:math id="inf118"><mml:mi>s</mml:mi></mml:math></inline-formula>, followed by maximal negative control until time <inline-formula><mml:math id="inf119"><mml:mi>T</mml:mi></mml:math></inline-formula> (<xref ref-type="fig" rid="fig1s3">Figure 1—figure supplement 3A</xref>). Although we implemented the leaky integration in discrete time with a frame rate of 60 Hz, we derived the input gains using continuous time and translated them to discrete time.</p><p>The velocity at any time <inline-formula><mml:math id="inf120"><mml:mn>0</mml:mn><mml:mo>≤</mml:mo><mml:mi>t</mml:mi><mml:mo>≤</mml:mo><mml:mi>T</mml:mi></mml:math></inline-formula> during the control is:<disp-formula id="equ4"><label>(1d)</label><mml:math id="m4"><mml:mrow><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mfrac><mml:msub><mml:mi>v</mml:mi><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:msub><mml:mi>v</mml:mi><mml:mrow><mml:mrow><mml:mi mathvariant="normal">m</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">a</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">x</mml:mi></mml:mrow></mml:mrow></mml:msub></mml:mfrac><mml:mo>=</mml:mo><mml:mrow><mml:mo maxsize="2.470em" minsize="2.470em">{</mml:mo></mml:mrow><mml:mtable columnspacing="1em" rowspacing="4pt"><mml:mtr><mml:mtd><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:mtext> </mml:mtext><mml:msup><mml:mi>e</mml:mi><mml:mrow><mml:mfrac><mml:mrow><mml:mo>−</mml:mo><mml:mi>t</mml:mi></mml:mrow><mml:mi>τ</mml:mi></mml:mfrac></mml:mrow></mml:msup></mml:mtd><mml:mtd><mml:mn>0</mml:mn><mml:mtext> </mml:mtext><mml:mo>&lt;</mml:mo><mml:mi>t</mml:mi><mml:mo>≤</mml:mo><mml:mi>s</mml:mi></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mo>−</mml:mo><mml:mn>1</mml:mn><mml:mo>+</mml:mo><mml:mtext> </mml:mtext><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mfrac><mml:msub><mml:mi>v</mml:mi><mml:mrow><mml:mi>s</mml:mi></mml:mrow></mml:msub><mml:msub><mml:mi>v</mml:mi><mml:mrow><mml:mrow><mml:mi mathvariant="normal">m</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">a</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">x</mml:mi></mml:mrow></mml:mrow></mml:msub></mml:mfrac><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:msup><mml:mi>e</mml:mi><mml:mrow><mml:mo>−</mml:mo><mml:mfrac><mml:mrow><mml:mi>t</mml:mi><mml:mo>−</mml:mo><mml:mi>s</mml:mi></mml:mrow><mml:mi>τ</mml:mi></mml:mfrac></mml:mrow></mml:msup></mml:mtd><mml:mtd><mml:mi>s</mml:mi><mml:mtext> </mml:mtext><mml:mo>&lt;</mml:mo><mml:mi>t</mml:mi><mml:mo>&lt;</mml:mo><mml:mi>T</mml:mi></mml:mtd></mml:mtr></mml:mtable></mml:mstyle></mml:mrow></mml:math></disp-formula></p><p>where <inline-formula><mml:math id="inf121"><mml:msub><mml:mrow><mml:mi>v</mml:mi></mml:mrow><mml:mrow><mml:mi>s</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> is the velocity at the switching time <inline-formula><mml:math id="inf122"><mml:mi>s</mml:mi></mml:math></inline-formula> when control switched from positive to negative, given by:<disp-formula id="equ5"><label>(1e)</label><mml:math id="m5"><mml:msub><mml:mrow><mml:mi>v</mml:mi></mml:mrow><mml:mrow><mml:mi>s</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mi> </mml:mi><mml:msub><mml:mrow><mml:mi>v</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">m</mml:mi><mml:mi mathvariant="normal">a</mml:mi><mml:mi mathvariant="normal">x</mml:mi></mml:mrow></mml:msub><mml:mfenced separators="|"><mml:mrow><mml:mn>1</mml:mn><mml:mo>-</mml:mo><mml:mi> </mml:mi><mml:msup><mml:mrow><mml:mi>e</mml:mi></mml:mrow><mml:mrow><mml:mfrac><mml:mrow><mml:mo>-</mml:mo><mml:mi>s</mml:mi></mml:mrow><mml:mrow><mml:mi>τ</mml:mi></mml:mrow></mml:mfrac></mml:mrow></mml:msup></mml:mrow></mml:mfenced></mml:math></disp-formula></p><p>By substituting <inline-formula><mml:math id="inf123"><mml:msub><mml:mrow><mml:mi>v</mml:mi></mml:mrow><mml:mrow><mml:mi>s</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> into <xref ref-type="disp-formula" rid="equ4">Equation 1d</xref> and using the fact that at time <inline-formula><mml:math id="inf124"><mml:mi>T</mml:mi></mml:math></inline-formula>, the controlled velocity should return to 0, we obtain an expression that we can use to solve for <inline-formula><mml:math id="inf125"><mml:mi>s</mml:mi></mml:math></inline-formula>:<disp-formula id="equ6"><label>(1f)</label><mml:math id="m6"><mml:msub><mml:mrow><mml:mi>v</mml:mi></mml:mrow><mml:mrow><mml:mi>T</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mn>0</mml:mn><mml:mo>=</mml:mo><mml:mi> </mml:mi><mml:mo>-</mml:mo><mml:mn>1</mml:mn><mml:mo>+</mml:mo><mml:mi> </mml:mi><mml:mfenced separators="|"><mml:mrow><mml:mfrac><mml:mrow><mml:msub><mml:mrow><mml:mi>v</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">m</mml:mi><mml:mi mathvariant="normal">a</mml:mi><mml:mi mathvariant="normal">x</mml:mi></mml:mrow></mml:msub><mml:mfenced separators="|"><mml:mrow><mml:mn>1</mml:mn><mml:mo>-</mml:mo><mml:mi> </mml:mi><mml:msup><mml:mrow><mml:mi>e</mml:mi></mml:mrow><mml:mrow><mml:mfrac><mml:mrow><mml:mo>-</mml:mo><mml:mi>s</mml:mi></mml:mrow><mml:mrow><mml:mi>τ</mml:mi></mml:mrow></mml:mfrac></mml:mrow></mml:msup></mml:mrow></mml:mfenced></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>v</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">m</mml:mi><mml:mi mathvariant="normal">a</mml:mi><mml:mi mathvariant="normal">x</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfrac><mml:mi> </mml:mi><mml:mo>+</mml:mo><mml:mi> </mml:mi><mml:mn>1</mml:mn></mml:mrow></mml:mfenced><mml:msup><mml:mrow><mml:mi>e</mml:mi></mml:mrow><mml:mrow><mml:mo>-</mml:mo><mml:mfrac><mml:mrow><mml:mi>T</mml:mi><mml:mo>-</mml:mo><mml:mi>s</mml:mi></mml:mrow><mml:mrow><mml:mi>τ</mml:mi></mml:mrow></mml:mfrac></mml:mrow></mml:msup></mml:math></disp-formula></p><p>Observe that <inline-formula><mml:math id="inf126"><mml:msub><mml:mrow><mml:mi>v</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">m</mml:mi><mml:mi mathvariant="normal">a</mml:mi><mml:mi mathvariant="normal">x</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> cancels in this equation, so the switching time <inline-formula><mml:math id="inf127"><mml:mi>s</mml:mi></mml:math></inline-formula> is independent of <inline-formula><mml:math id="inf128"><mml:msub><mml:mrow><mml:mi>v</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">m</mml:mi><mml:mi mathvariant="normal">a</mml:mi><mml:mi mathvariant="normal">x</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> and therefore also independent of the displacement <inline-formula><mml:math id="inf129"><mml:mi>x</mml:mi></mml:math></inline-formula> (see also <xref ref-type="fig" rid="fig1s3">Figure 1—figure supplement 3A</xref>):<disp-formula id="equ7"><label>(1g)</label><mml:math id="m7"><mml:mrow><mml:mi>s</mml:mi><mml:mtext> </mml:mtext><mml:mo>=</mml:mo><mml:mtext> </mml:mtext><mml:mi>τ</mml:mi><mml:mrow><mml:mi mathvariant="normal">l</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">o</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">g</mml:mi></mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mfrac><mml:mrow><mml:mn>1</mml:mn><mml:mtext> </mml:mtext><mml:mo>+</mml:mo><mml:mtext> </mml:mtext><mml:msup><mml:mi>e</mml:mi><mml:mrow><mml:mfrac><mml:mi>T</mml:mi><mml:mi>τ</mml:mi></mml:mfrac></mml:mrow></mml:msup></mml:mrow><mml:mn>2</mml:mn></mml:mfrac><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></disp-formula></p><p>Integrating the velocity profile of <xref ref-type="disp-formula" rid="equ4">Equation 1d</xref> to obtain the distance travelled by time <inline-formula><mml:math id="inf130"><mml:mi>T</mml:mi></mml:math></inline-formula>, substituting the switch time <inline-formula><mml:math id="inf131"><mml:mi>s</mml:mi></mml:math></inline-formula> (<xref ref-type="fig" rid="fig1s3">Figure 1—figure supplement 3A</xref>), and simplifying, we obtain:<disp-formula id="equ8"><label>(1h)</label><mml:math id="m8"><mml:mrow><mml:mi>x</mml:mi><mml:mo>=</mml:mo><mml:mtext> </mml:mtext><mml:msub><mml:mi>x</mml:mi><mml:mrow><mml:mi>T</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mn>2</mml:mn><mml:mtext> </mml:mtext><mml:mi>τ</mml:mi><mml:mtext> </mml:mtext><mml:msub><mml:mi>v</mml:mi><mml:mrow><mml:mrow><mml:mi mathvariant="normal">m</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">a</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">x</mml:mi></mml:mrow></mml:mrow></mml:msub><mml:mrow><mml:mi mathvariant="normal">l</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">o</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">g</mml:mi></mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mrow><mml:mi mathvariant="normal">c</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">o</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">s</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">h</mml:mi></mml:mrow><mml:mfrac><mml:mi>T</mml:mi><mml:mrow><mml:mn>2</mml:mn><mml:mi>τ</mml:mi></mml:mrow></mml:mfrac></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></disp-formula></p><p>We can then solve for the desired maximum linear speed <inline-formula><mml:math id="inf132"><mml:msub><mml:mrow><mml:mi>v</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">m</mml:mi><mml:mi mathvariant="normal">a</mml:mi><mml:mi mathvariant="normal">x</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> for any time constant <italic>τ</italic>, average displacement <inline-formula><mml:math id="inf133"><mml:mi>x</mml:mi></mml:math></inline-formula>, and trial duration <inline-formula><mml:math id="inf134"><mml:mi>T</mml:mi></mml:math></inline-formula>:<disp-formula id="equ9"><label>(1i)</label><mml:math id="m9"><mml:mrow><mml:msub><mml:mi>v</mml:mi><mml:mrow><mml:mrow><mml:mi mathvariant="normal">m</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">a</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">x</mml:mi></mml:mrow></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mi>τ</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mtext> </mml:mtext><mml:mfrac><mml:mi>x</mml:mi><mml:mrow><mml:mn>2</mml:mn><mml:mi>τ</mml:mi></mml:mrow></mml:mfrac><mml:mfrac><mml:mn>1</mml:mn><mml:mrow><mml:mi>log</mml:mi><mml:mo>⁡</mml:mo><mml:mi>cosh</mml:mi><mml:mo>⁡</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>T</mml:mi><mml:mrow><mml:mo>/</mml:mo></mml:mrow><mml:mn>2</mml:mn><mml:mi>τ</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mfrac></mml:mrow></mml:math></disp-formula></p><p>Similarly, the maximum angular velocity was: <inline-formula><mml:math id="inf135"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>ω</mml:mi><mml:mrow><mml:mrow><mml:mi mathvariant="normal">m</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">a</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">x</mml:mi></mml:mrow></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mi>τ</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mtext> </mml:mtext><mml:mfrac><mml:mi>θ</mml:mi><mml:mrow><mml:mn>2</mml:mn><mml:mi>τ</mml:mi></mml:mrow></mml:mfrac><mml:mfrac><mml:mn>1</mml:mn><mml:mrow><mml:mi>log</mml:mi><mml:mo>⁡</mml:mo><mml:mi>cosh</mml:mi><mml:mo>⁡</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>T</mml:mi><mml:mrow><mml:mo>/</mml:mo></mml:mrow><mml:mn>2</mml:mn><mml:mi>τ</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mfrac></mml:mrow></mml:mstyle></mml:math></inline-formula> , where <inline-formula><mml:math id="inf136"><mml:mi>θ</mml:mi></mml:math></inline-formula> is the average angle we want our participant to be able to turn within the average time <italic>T</italic>.</p><p>These equations can also be re-written in terms of a dimensionless time <inline-formula><mml:math id="inf137"><mml:mi>z</mml:mi><mml:mo>=</mml:mo><mml:mi> </mml:mi><mml:mrow><mml:mrow><mml:mi>τ</mml:mi></mml:mrow><mml:mo>/</mml:mo><mml:mrow><mml:mi>T</mml:mi></mml:mrow></mml:mrow></mml:math></inline-formula> (duration of trial in units of the time constant) and average velocities <inline-formula><mml:math id="inf138"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mrow><mml:mover><mml:mi>v</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover></mml:mrow><mml:mo>=</mml:mo><mml:mi>x</mml:mi><mml:mrow><mml:mo>/</mml:mo></mml:mrow><mml:mi>T</mml:mi></mml:mrow></mml:mstyle></mml:math></inline-formula> and <inline-formula><mml:math id="inf139"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mrow><mml:mover><mml:mi>ω</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover></mml:mrow><mml:mo>=</mml:mo><mml:mi>θ</mml:mi><mml:mrow><mml:mo>/</mml:mo></mml:mrow><mml:mi>T</mml:mi></mml:mrow></mml:mstyle></mml:math></inline-formula>:<disp-formula id="equ10"><label>(1j)</label><mml:math id="m10"><mml:mrow><mml:msub><mml:mi>v</mml:mi><mml:mrow><mml:mrow><mml:mi mathvariant="normal">m</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">a</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">x</mml:mi></mml:mrow></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mrow><mml:mrow><mml:mover><mml:mi>v</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover></mml:mrow><mml:mfrac><mml:mrow><mml:mn>1</mml:mn><mml:mrow><mml:mo>/</mml:mo></mml:mrow><mml:mn>2</mml:mn><mml:mi>z</mml:mi></mml:mrow><mml:mrow><mml:mi>log</mml:mi><mml:mo>⁡</mml:mo><mml:mi>cosh</mml:mi><mml:mo>⁡</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mn>1</mml:mn><mml:mrow><mml:mo>/</mml:mo></mml:mrow><mml:mn>2</mml:mn><mml:mi>z</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mfrac></mml:mrow><mml:mspace width="1em"/><mml:mrow><mml:mi mathvariant="normal">a</mml:mi><mml:mi mathvariant="normal">n</mml:mi><mml:mi mathvariant="normal">d</mml:mi></mml:mrow><mml:mspace width="1em"/><mml:msub><mml:mi>ω</mml:mi><mml:mrow><mml:mrow><mml:mi mathvariant="normal">m</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">a</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">x</mml:mi></mml:mrow></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mrow><mml:mrow><mml:mover><mml:mi>ω</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover></mml:mrow><mml:mfrac><mml:mrow><mml:mn>1</mml:mn><mml:mrow><mml:mo>/</mml:mo></mml:mrow><mml:mn>2</mml:mn><mml:mi>z</mml:mi></mml:mrow><mml:mrow><mml:mi>log</mml:mi><mml:mo>⁡</mml:mo><mml:mi>cosh</mml:mi><mml:mo>⁡</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mn>1</mml:mn><mml:mrow><mml:mo>/</mml:mo></mml:mrow><mml:mn>2</mml:mn><mml:mi>z</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mfrac></mml:mrow></mml:mrow></mml:math></disp-formula></p><p>where <inline-formula><mml:math id="inf140"><mml:mi>θ</mml:mi></mml:math></inline-formula> is the average angle we want the participants to be able to steer within time <inline-formula><mml:math id="inf141"><mml:mi>T</mml:mi></mml:math></inline-formula>.</p><p>Setting control gains according to <xref ref-type="disp-formula" rid="equ9">Equation 1i</xref> allows us to manipulate the control timescale <inline-formula><mml:math id="inf142"><mml:mi>τ</mml:mi></mml:math></inline-formula>, while approximately maintaining the average trial duration for each target location (<xref ref-type="fig" rid="fig1s3">Figure 1—figure supplement 3B</xref>). Converting these maximal velocities into discrete-time control gains using <xref ref-type="disp-formula" rid="equ1 equ2 equ3">Equations 1.1–1.3</xref> gives us the desired inertial control dynamics.</p></sec><sec id="s4-1-6"><title>Slow changes in time constant</title><p>The time constant <italic>τ</italic> was sampled according to a temporally correlated log-normal distribution. The log of the time constant, <inline-formula><mml:math id="inf143"><mml:mi>ϕ</mml:mi><mml:mo>=</mml:mo><mml:mrow><mml:mrow><mml:mi mathvariant="normal">log</mml:mi></mml:mrow><mml:mo>⁡</mml:mo><mml:mrow><mml:mi>τ</mml:mi></mml:mrow></mml:mrow></mml:math></inline-formula> , followed a bounded random walk across trials according to (<xref ref-type="fig" rid="fig1s3">Figure 1—figure supplement 3C</xref>)<disp-formula id="equ11"><label>(2)</label><mml:math id="m11"><mml:msub><mml:mrow><mml:mi>ϕ</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mi> </mml:mi><mml:mo>=</mml:mo><mml:mi> </mml:mi><mml:mi>c</mml:mi><mml:mi> </mml:mi><mml:msub><mml:mrow><mml:mi>ϕ</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mi> </mml:mi><mml:mo>+</mml:mo><mml:mi> </mml:mi><mml:msub><mml:mrow><mml:mi>η</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub></mml:math></disp-formula></p><p>The marginal distribution of <inline-formula><mml:math id="inf144"><mml:mi>ϕ</mml:mi></mml:math></inline-formula> was normal, <inline-formula><mml:math id="inf145"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mrow><mml:mi mathvariant="script">N</mml:mi></mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>μ</mml:mi><mml:mrow><mml:mi>ϕ</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msubsup><mml:mi>σ</mml:mi><mml:mrow><mml:mi>ϕ</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mstyle></mml:math></inline-formula> , with mean <inline-formula><mml:math id="inf146"><mml:msub><mml:mrow><mml:mi>μ</mml:mi></mml:mrow><mml:mrow><mml:mi>ϕ</mml:mi></mml:mrow></mml:msub><mml:mi> </mml:mi><mml:mo>=</mml:mo><mml:mi> </mml:mi><mml:mfrac><mml:mrow><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:mfrac><mml:mfenced separators="|"><mml:mrow><mml:mrow><mml:mrow><mml:mi mathvariant="normal">ln</mml:mi></mml:mrow><mml:mo>⁡</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mi>τ</mml:mi></mml:mrow><mml:mrow><mml:mo>-</mml:mo></mml:mrow></mml:msub></mml:mrow></mml:mrow><mml:mo>+</mml:mo><mml:mrow><mml:mrow><mml:mi mathvariant="normal">ln</mml:mi></mml:mrow><mml:mo>⁡</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mi>τ</mml:mi></mml:mrow><mml:mrow><mml:mo>+</mml:mo></mml:mrow></mml:msub></mml:mrow></mml:mrow></mml:mrow></mml:mfenced></mml:math></inline-formula> and standard deviation <inline-formula><mml:math id="inf147"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>σ</mml:mi><mml:mrow><mml:mi>ϕ</mml:mi></mml:mrow></mml:msub><mml:mtext> </mml:mtext><mml:mo>=</mml:mo><mml:mtext> </mml:mtext><mml:mfrac><mml:mn>1</mml:mn><mml:mn>4</mml:mn></mml:mfrac><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>log</mml:mi><mml:mo>⁡</mml:mo><mml:msub><mml:mi>τ</mml:mi><mml:mrow><mml:mo>+</mml:mo></mml:mrow></mml:msub><mml:mtext> </mml:mtext><mml:mo>−</mml:mo><mml:mtext> </mml:mtext><mml:mi>log</mml:mi><mml:mo>⁡</mml:mo><mml:msub><mml:mi>τ</mml:mi><mml:mrow><mml:mo>−</mml:mo></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mstyle></mml:math></inline-formula> , which ensured that 95% of the velocity timescales lay between <inline-formula><mml:math id="inf148"><mml:msub><mml:mrow><mml:mi>τ</mml:mi></mml:mrow><mml:mrow><mml:mo>-</mml:mo></mml:mrow></mml:msub></mml:math></inline-formula> and <inline-formula><mml:math id="inf149"><mml:msub><mml:mrow><mml:mi>τ</mml:mi></mml:mrow><mml:mrow><mml:mo>+</mml:mo></mml:mrow></mml:msub></mml:math></inline-formula> . The velocity timescales changed across trials with their own timescale <inline-formula><mml:math id="inf150"><mml:msub><mml:mrow><mml:mi>τ</mml:mi></mml:mrow><mml:mrow><mml:mi>ϕ</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> , related to the update coefficient by <inline-formula><mml:math id="inf151"><mml:mi>c</mml:mi><mml:mi> </mml:mi><mml:mo>=</mml:mo><mml:mi> </mml:mi><mml:msup><mml:mrow><mml:mi>e</mml:mi></mml:mrow><mml:mrow><mml:mfrac bevelled="true"><mml:mrow><mml:mo>-</mml:mo><mml:mi>Δ</mml:mi><mml:mi>t</mml:mi></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>τ</mml:mi></mml:mrow><mml:mrow><mml:mi>ϕ</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfrac></mml:mrow></mml:msup></mml:math></inline-formula> , where we set <inline-formula><mml:math id="inf152"><mml:mi mathvariant="normal">Δ</mml:mi><mml:mi>t</mml:mi></mml:math></inline-formula> to be one trial and <inline-formula><mml:math id="inf153"><mml:msub><mml:mrow><mml:mi>τ</mml:mi></mml:mrow><mml:mrow><mml:mi>ϕ</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> to be two trials. To produce the desired equilibrium distribution of <inline-formula><mml:math id="inf154"><mml:mi>ϕ</mml:mi></mml:math></inline-formula> we set the scale of the random walk Gaussian noise <inline-formula><mml:math id="inf155"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>η</mml:mi><mml:mo>∼</mml:mo><mml:mrow><mml:mi mathvariant="script">N</mml:mi></mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>μ</mml:mi><mml:mrow><mml:mi>η</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msubsup><mml:mi>σ</mml:mi><mml:mrow><mml:mi>η</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mstyle></mml:math></inline-formula> with <inline-formula><mml:math id="inf156"><mml:msub><mml:mrow><mml:msub><mml:mrow><mml:mi>μ</mml:mi></mml:mrow><mml:mrow><mml:mi>η</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mi>μ</mml:mi></mml:mrow><mml:mrow><mml:mi>ϕ</mml:mi></mml:mrow></mml:msub><mml:mo>(</mml:mo><mml:mn>1</mml:mn><mml:mo>-</mml:mo><mml:mi>c</mml:mi><mml:mo>)</mml:mo></mml:math></inline-formula> and <inline-formula><mml:math id="inf157"><mml:msubsup><mml:mrow><mml:mi>σ</mml:mi></mml:mrow><mml:mrow><mml:mi>η</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup><mml:mo>=</mml:mo><mml:msubsup><mml:mrow><mml:mi>σ</mml:mi></mml:mrow><mml:mrow><mml:mi>ϕ</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup><mml:mfenced separators="|"><mml:mrow><mml:mn>1</mml:mn><mml:mo>-</mml:mo><mml:msup><mml:mrow><mml:mi>c</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:mfenced></mml:math></inline-formula> .</p></sec><sec id="s4-1-7"><title>MC algorithm</title><p>Each motion trajectory consisted of a linear displacement in the 2D virtual space combined with a rotation in the horizontal plane. While the motion platform could reproduce the rotational movement using the yaw motor (which was unconstrained in movement range and powerful enough to render any angular acceleration or speed in this study), its ability to reproduce linear movement was limited by the platform’s maximum range of 25 cm and maximum velocity of 50 cm/s (in practice, the platform was powerful enough to render any linear acceleration in this study). To circumvent this limitation, we designed an MC algorithm that takes advantage of the gravito-inertial ambiguity (<xref ref-type="bibr" rid="bib13">Einstein, 1907</xref>) inherent to the vestibular organs (<xref ref-type="bibr" rid="bib2">Angelaki and Dickman, 2000</xref>; <xref ref-type="bibr" rid="bib14">Fernandez et al., 1972</xref>; <xref ref-type="bibr" rid="bib15">Fernández and Goldberg, 1976</xref>).</p><p>Specifically, the otolith organs in the inner ear sense both linear acceleration (<italic>A</italic>) and gravity (<italic>G</italic>), that is, they sense the gravito-inertial acceleration (GIA): <inline-formula><mml:math id="inf158"><mml:mi>F</mml:mi><mml:mo>=</mml:mo><mml:mi>G</mml:mi><mml:mo>+</mml:mo><mml:mi>A</mml:mi></mml:math></inline-formula>. Consequently, a forward acceleration of the head (<inline-formula><mml:math id="inf159"><mml:msub><mml:mrow><mml:mi>a</mml:mi></mml:mrow><mml:mrow><mml:mi>x</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> , expressed in <italic>g</italic>, with 1<italic>g</italic> = 9.81 m/s<sup>2</sup>) and a backward pitch (by an angle <inline-formula><mml:math id="inf160"><mml:mi>θ</mml:mi></mml:math></inline-formula>, in radians) will generate a total GIA <inline-formula><mml:math id="inf161"><mml:mi>F</mml:mi><mml:mi>x</mml:mi><mml:mi> </mml:mi><mml:mo>=</mml:mo><mml:mi> </mml:mi><mml:mi>θ</mml:mi><mml:mo>+</mml:mo><mml:mi> </mml:mi><mml:msub><mml:mrow><mml:mi>a</mml:mi></mml:mrow><mml:mrow><mml:mi>x</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula>. The MC took advantage of this ambiguity to replace linear acceleration by tilt. Specifically, it controlled the motion platform to produce a total GIA (<xref ref-type="fig" rid="fig1s1">Figure 1—figure supplement 1</xref>, ‘desired platform GIA’) that matched the linear acceleration of the simulated motion in the virtual environment. As long as the rotation that induced this simulated acceleration was slow enough, the motion felt subjectively was a linear acceleration.</p><p>This control algorithm was based on a trade-off where the high-pass component of the simulated inertial acceleration (<xref ref-type="fig" rid="fig1s1">Figure 1—figure supplement 1</xref>, ‘desired platform linear acceleration’) was produced by translating the platform, whereas the low-pass component was produced by tilting the platform (<xref ref-type="fig" rid="fig1s1">Figure 1—figure supplement 1</xref>, ‘desired platform tilt’).</p><p>Even though this method is generally sufficient to ensure that platform motion remains within its envelope, it does not guarantee it. Thus, the platform’s position, velocity, and acceleration commands were fed through a sigmoid function <inline-formula><mml:math id="inf162"><mml:mi>f</mml:mi></mml:math></inline-formula> (<xref ref-type="fig" rid="fig1s1">Figure 1—figure supplement 1</xref>, ‘platform limits’). This function was equal to the identity function (<inline-formula><mml:math id="inf163"><mml:mi>f</mml:mi><mml:mfenced separators="|"><mml:mrow><mml:mi>x</mml:mi></mml:mrow></mml:mfenced><mml:mo>=</mml:mo><mml:mi>x</mml:mi></mml:math></inline-formula>) as long as motion commands were within 75% of the platform’s limits, so these motion commands were unaffected. When motion commands exceed this range, the function bends smoothly to saturate at a value set slightly below the limit, thus preventing the platform from reaching its mechanical range (in position, velocity, or acceleration) while ensuring a smooth trajectory. Thus, if the desired motion exceeds 75% of the platform’s performance envelope, the actual motion of the platform is diminished, such that the total GIA actually experienced by the participant (‘actual platform GIA’) may not match the desired GIA. If left uncorrected, these GIA errors would result in a mismatch between inertial motion and the visual VR stimulus. To prevent these mismatches, we designed a loop that estimates GIA error and updates the simulated motion in the visual environment. For instance, if the joystick input commands a large forward acceleration and the platform is unable to reproduce this acceleration, then the visual motion is updated to represent a slower acceleration that matches the platform’s motion. Altogether, the IC and MC algorithms are applied sequentially as follows: (1) The velocity signal produced by the IC process controls the participant’s attempted motion in the virtual environment. (2) The participant acceleration in the VR environment is calculated and inputted to the MC algorithm (‘desired platform GIA’). (3) The MC computes the platform’s motion commands and the actual platform GIA is computed. (4) The difference between the desired GIA motion actual GIA (GIA error) is computed and used to update the motion in the virtual environment. (5) The updated position is sent to the visual display.</p><p>A summary of the performance and efficiency of the MC algorithm during the experiment can be seen in <xref ref-type="fig" rid="fig1s2">Figure 1—figure supplement 2</xref>. For a detailed view of the implementation of the MC algorithm, refer to Appendix 1.</p></sec></sec><sec id="s4-2"><title>Quantification and statistical analysis</title><p>Customized MATLAB code was written to analyze data and to fit models. Depending on the quantity estimated, we report statistical dispersions either using 95% confidence interval, standard deviation, or standard error in the mean. The specific dispersion measure is identified in the portion of the text accompanying the estimates. For error bars in figures, we provide this information in the caption of the corresponding figure. We report and describe the outcome as significant if p&lt;0.05.</p><sec id="s4-2-1"><title>Estimation of response gain</title><p>In each sensory condition, we first computed the <italic>τ</italic>-independent gain for each participant; we regressed (without an intercept term) each participant’s response positions (<inline-formula><mml:math id="inf164"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mrow><mml:mover><mml:mi>r</mml:mi><mml:mo stretchy="false">~</mml:mo></mml:mover></mml:mrow><mml:mo>,</mml:mo><mml:mrow><mml:mover><mml:mi>θ</mml:mi><mml:mo stretchy="false">~</mml:mo></mml:mover></mml:mrow></mml:mrow></mml:mstyle></mml:math></inline-formula>) against target positions (<inline-formula><mml:math id="inf165"><mml:mi>r</mml:mi><mml:mo>,</mml:mo><mml:mi>θ</mml:mi></mml:math></inline-formula>) separately for the radial (<inline-formula><mml:math id="inf166"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mrow><mml:mover><mml:mi>r</mml:mi><mml:mo stretchy="false">~</mml:mo></mml:mover></mml:mrow></mml:mrow></mml:mstyle></mml:math></inline-formula> vs. <inline-formula><mml:math id="inf167"><mml:mi>r</mml:mi></mml:math></inline-formula>) and angular (<inline-formula><mml:math id="inf168"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mrow><mml:mover><mml:mi>θ</mml:mi><mml:mo stretchy="false">~</mml:mo></mml:mover></mml:mrow></mml:mrow></mml:mstyle></mml:math></inline-formula> vs. <inline-formula><mml:math id="inf169"><mml:mi>θ</mml:mi></mml:math></inline-formula>) coordinates, and the radial and angular response gains (<inline-formula><mml:math id="inf170"><mml:msub><mml:mrow><mml:mi>g</mml:mi></mml:mrow><mml:mrow><mml:mi>r</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> , <inline-formula><mml:math id="inf171"><mml:msub><mml:mrow><mml:mi>g</mml:mi></mml:mrow><mml:mrow><mml:mi>θ</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula>) were quantified as the slope of the respective regressions (<xref ref-type="fig" rid="fig2">Figure 2A</xref>). In addition, we followed the same process to calculate gain terms within three <italic>τ</italic> groups of equal size (<xref ref-type="fig" rid="fig3">Figure 3A</xref>).</p></sec><sec id="s4-2-2"><title>Correlation between residual error and time constant <italic>τ</italic></title><p>To evaluate the influence of the time constant on the steering responses, we computed the correlation coefficient between the time constants and the residual errors from the mean response (estimated using the response gain) for distance and angle. Under each sensory condition, the radial residual error (<inline-formula><mml:math id="inf172"><mml:msub><mml:mrow><mml:mi>ε</mml:mi></mml:mrow><mml:mrow><mml:mi>r</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula>) for each trial <inline-formula><mml:math id="inf173"><mml:mi>i</mml:mi></mml:math></inline-formula> was given by:<disp-formula id="equ12"><label>(3a)</label><mml:math id="m12"><mml:mrow><mml:msub><mml:mi>ε</mml:mi><mml:mrow><mml:mi>r</mml:mi><mml:mo>,</mml:mo><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:msub><mml:mrow><mml:mover><mml:mi>r</mml:mi><mml:mo stretchy="false">~</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>−</mml:mo><mml:msub><mml:mi>g</mml:mi><mml:mrow><mml:mi>r</mml:mi></mml:mrow></mml:msub><mml:msub><mml:mi>r</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:math></disp-formula></p><p>where <inline-formula><mml:math id="inf174"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mrow><mml:mover><mml:mi>r</mml:mi><mml:mo stretchy="false">~</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula> is the radial response, and the mean radial response is given by multiplying the target distance <inline-formula><mml:math id="inf175"><mml:msub><mml:mrow><mml:mi>r</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> by the radial gain <inline-formula><mml:math id="inf176"><mml:msub><mml:mrow><mml:mi>g</mml:mi></mml:mrow><mml:mrow><mml:mi>r</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> . Similarly, the angular residual error (<inline-formula><mml:math id="inf177"><mml:msub><mml:mrow><mml:mi>ε</mml:mi></mml:mrow><mml:mrow><mml:mi>θ</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula>) was calculated as:<disp-formula id="equ13"><label>(3b)</label><mml:math id="m13"><mml:mrow><mml:msub><mml:mi>ε</mml:mi><mml:mrow><mml:mi>θ</mml:mi><mml:mo>,</mml:mo><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:msub><mml:mrow><mml:mover><mml:mi>θ</mml:mi><mml:mo stretchy="false">~</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>−</mml:mo><mml:msub><mml:mi>g</mml:mi><mml:mrow><mml:mi>θ</mml:mi></mml:mrow></mml:msub><mml:msub><mml:mi>θ</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:math></disp-formula></p></sec><sec id="s4-2-3"><title>Regression model containing <italic>τ</italic></title><p>To assess the manner in which the time constant affected the steering responses, we augmented the simple linear regression models for response gain estimation mentioned above with <italic>τ</italic>-dependent terms (<xref ref-type="fig" rid="fig3s2">Figure 3—figure supplement 2</xref>; <inline-formula><mml:math id="inf178"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>τ</mml:mi></mml:mrow></mml:mstyle></mml:math></inline-formula> and <inline-formula><mml:math id="inf179"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>τ</mml:mi><mml:mo>∗</mml:mo><mml:mi>r</mml:mi></mml:mrow></mml:mstyle></mml:math></inline-formula> for radial response <inline-formula><mml:math id="inf180"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mrow><mml:mover><mml:mi>r</mml:mi><mml:mo stretchy="false">~</mml:mo></mml:mover></mml:mrow></mml:mrow></mml:mstyle></mml:math></inline-formula> , <inline-formula><mml:math id="inf181"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>τ</mml:mi></mml:mrow></mml:mstyle></mml:math></inline-formula>, and <inline-formula><mml:math id="inf182"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>τ</mml:mi><mml:mo>∗</mml:mo><mml:mi>θ</mml:mi></mml:mrow></mml:mstyle></mml:math></inline-formula> for angular response <inline-formula><mml:math id="inf183"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mrow><mml:mover><mml:mi>θ</mml:mi><mml:mo stretchy="false">~</mml:mo></mml:mover></mml:mrow></mml:mrow></mml:mstyle></mml:math></inline-formula>). Subsequently, we calculated the Pearson’s linear partial correlations between the response positions and each of the three predictors.</p></sec><sec id="s4-2-4"><title>Estimation of <italic>τ</italic>-dependent gain</title><p>To quantify the extent to which the time constant modulates the response gain, we linearly regressed each participant’s response positions (<inline-formula><mml:math id="inf184"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mrow><mml:mover><mml:mi>r</mml:mi><mml:mo stretchy="false">~</mml:mo></mml:mover></mml:mrow><mml:mo>,</mml:mo><mml:mrow><mml:mover><mml:mi>θ</mml:mi><mml:mo stretchy="false">~</mml:mo></mml:mover></mml:mrow></mml:mrow></mml:mstyle></mml:math></inline-formula>) against target positions (<inline-formula><mml:math id="inf185"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>r</mml:mi><mml:mo>,</mml:mo><mml:mi>θ</mml:mi></mml:mrow></mml:mstyle></mml:math></inline-formula>) and the interaction between target positions and the time constant <inline-formula><mml:math id="inf186"><mml:mi>τ</mml:mi></mml:math></inline-formula> according to:<disp-formula id="equ14">.<label>(4a)</label><mml:math id="m14"><mml:mrow><mml:mrow><mml:mover><mml:mi>r</mml:mi><mml:mo stretchy="false">~</mml:mo></mml:mover></mml:mrow><mml:mo>=</mml:mo><mml:msub><mml:mi>b</mml:mi><mml:mrow><mml:mi>r</mml:mi></mml:mrow></mml:msub><mml:mi>r</mml:mi><mml:mo>+</mml:mo><mml:msub><mml:mi>a</mml:mi><mml:mrow><mml:mi>r</mml:mi></mml:mrow></mml:msub><mml:mi>r</mml:mi><mml:mi>τ</mml:mi><mml:mspace width="1em"/><mml:mrow><mml:mi mathvariant="normal">a</mml:mi><mml:mi mathvariant="normal">n</mml:mi><mml:mi mathvariant="normal">d</mml:mi></mml:mrow><mml:mspace width="1em"/><mml:mrow><mml:mover><mml:mi>θ</mml:mi><mml:mo stretchy="false">~</mml:mo></mml:mover></mml:mrow><mml:mo>=</mml:mo><mml:msub><mml:mrow><mml:mi mathvariant="italic">b</mml:mi></mml:mrow><mml:mrow><mml:mi>θ</mml:mi></mml:mrow></mml:msub><mml:mi>θ</mml:mi><mml:mo>+</mml:mo><mml:msub><mml:mrow><mml:mi mathvariant="italic">a</mml:mi></mml:mrow><mml:mrow><mml:mi>θ</mml:mi></mml:mrow></mml:msub><mml:mi>θ</mml:mi><mml:mi>τ</mml:mi></mml:mrow></mml:math></disp-formula></p><p>where <inline-formula><mml:math id="inf187"><mml:msub><mml:mrow><mml:mi>b</mml:mi></mml:mrow><mml:mrow><mml:mi>r</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula>, <inline-formula><mml:math id="inf188"><mml:msub><mml:mrow><mml:mi>b</mml:mi></mml:mrow><mml:mrow><mml:mi>θ</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> and <inline-formula><mml:math id="inf189"><mml:msub><mml:mrow><mml:mi>a</mml:mi></mml:mrow><mml:mrow><mml:mi>r</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula>, <inline-formula><mml:math id="inf190"><mml:msub><mml:mrow><mml:mi>a</mml:mi></mml:mrow><mml:mrow><mml:mi>θ</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> are the coefficients of the target locations and the interaction terms, respectively. All quantities were first standardized by dividing them with their respective standard deviation, to avoid size effects of the different predictors. This form allows for modulation of the response gain by the time constant, which is clear when the target location is factored out:<disp-formula id="equ15">.<label>(4b)</label><mml:math id="m15"><mml:mrow><mml:mrow><mml:mover><mml:mi>r</mml:mi><mml:mo stretchy="false">~</mml:mo></mml:mover></mml:mrow><mml:mo>=</mml:mo><mml:mi>r</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>b</mml:mi><mml:mrow><mml:mi>r</mml:mi></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mi>a</mml:mi><mml:mrow><mml:mi>r</mml:mi></mml:mrow></mml:msub><mml:mi>τ</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mspace width="1em"/><mml:mrow><mml:mi mathvariant="normal">a</mml:mi><mml:mi mathvariant="normal">n</mml:mi><mml:mi mathvariant="normal">d</mml:mi></mml:mrow><mml:mspace width="1em"/><mml:mrow><mml:mover><mml:mi>θ</mml:mi><mml:mo stretchy="false">~</mml:mo></mml:mover></mml:mrow><mml:mo>=</mml:mo><mml:mi>θ</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="italic">b</mml:mi></mml:mrow><mml:mrow><mml:mi>θ</mml:mi></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mrow><mml:mi mathvariant="italic">a</mml:mi></mml:mrow><mml:mrow><mml:mi>θ</mml:mi></mml:mrow></mml:msub><mml:mi>τ</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></disp-formula></p></sec><sec id="s4-2-5"><title>Estimation of simulated no-adaptation response gains</title><p>We quantified the extent to which participants failed to adapt to the underlying control dynamics, by generating a simulated null case for no adaptation. First, we selected trials in which the time constant was close to the mean of the sampling distribution (±0.2 s). Then, we integrated the steering input of those trials with time constants from other trials (see <xref ref-type="disp-formula" rid="equ1 equ2">Equations 1a, 1b)</xref>. This generated a set of trajectories for which the steering corresponded to a different time constant, providing us with a null case of no adaptation to the underlying dynamics. We then stratified the simulated trajectories into equal-sized groups based on the time constants (same as in <xref ref-type="fig" rid="fig3">Figure 3A</xref>) and computed the corresponding radial and angular response gains. Note that the response gains were computed according to the target locations of the initial set of trials.</p></sec><sec id="s4-2-6"><title>Rationale behind modeling approach</title><p>We tested the hypothesis that the <italic>τ-</italic>dependent errors in steering responses arise from participants misestimating control dynamics on individual trials. Specifically, if participants’ estimate of the time constant <italic>τ</italic> differs from the actual value, then their <italic>believed</italic> trajectories (computed using the estimated <italic>τ</italic>) would differ accordingly from the <italic>actual</italic> trajectories along which they travelled. believed stopping locations should land on or near the target. However, various unmeasurable fluctuations in that belief across trials should lead to variability clustered around the target location. Because participants try to stop on their believed target location, the <italic>believed</italic> stopping locations, subject to unmeasurable fluctuations of the belief across trials, should be distributed evenly around the participant’s mean response (mean belief), after adjusting for the average response gain. This is so because, if the distribution of believed responses depended on the time constant, then that would imply that participants willingly misestimated the control dynamics. Mathematically, the <italic>subjective</italic> residual errors (deviation of the believed stopping location from the mean response for a given target; see Materials and methods: <italic>Correlation between residual error and time constant τ</italic>) should be distributed evenly around zero and be uncorrelated with the time constant <italic>τ</italic>. Therefore, a good model of the participants’ beliefs should predict that subjective residual errors are statistically independent of the time constant.</p></sec><sec id="s4-2-7"><title>Bayesian observer model for <italic>τ</italic> estimation</title><p>To account for the effect of the time constant <italic>τ</italic> on steering performance, we considered a two-step observer model that uses a measurement <inline-formula><mml:math id="inf191"><mml:mi>m</mml:mi></mml:math></inline-formula> of the real time constant <inline-formula><mml:math id="inf192"><mml:mi>τ</mml:mi></mml:math></inline-formula> and a prior distribution over hypothesized time constants in logarithmic scale to compute an estimate <inline-formula><mml:math id="inf193"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mrow><mml:mrow><mml:mover><mml:mi>τ</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow></mml:mrow></mml:mrow></mml:mstyle></mml:math></inline-formula> on each trial (first step), and then integrates the actual joystick input using that estimate to reconstruct the participant’s believed trajectory (second step). We formulated our model in the logarithmic space of <inline-formula><mml:math id="inf194"><mml:mi>φ</mml:mi><mml:mo>=</mml:mo><mml:mi> </mml:mi><mml:mrow><mml:mrow><mml:mi mathvariant="normal">log</mml:mi></mml:mrow><mml:mo>⁡</mml:mo><mml:mrow><mml:mi>τ</mml:mi></mml:mrow></mml:mrow></mml:math></inline-formula> , therefore the prior distribution over the hypothesized time constants <inline-formula><mml:math id="inf195"><mml:mi mathvariant="normal">p</mml:mi><mml:mfenced separators="|"><mml:mrow><mml:mi>φ</mml:mi></mml:mrow></mml:mfenced></mml:math></inline-formula> was assumed to be normal in log-space with mean, <inline-formula><mml:math id="inf196"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mrow><mml:mi>μ</mml:mi></mml:mrow><mml:mrow><mml:mrow><mml:mi mathvariant="normal">p</mml:mi><mml:mi mathvariant="normal">r</mml:mi><mml:mi mathvariant="normal">i</mml:mi><mml:mi mathvariant="normal">o</mml:mi><mml:mi mathvariant="normal">r</mml:mi></mml:mrow></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula> and standard deviation, <inline-formula><mml:math id="inf197"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mrow><mml:mi>σ</mml:mi></mml:mrow><mml:mrow><mml:mrow><mml:mi mathvariant="normal">p</mml:mi><mml:mi mathvariant="normal">r</mml:mi><mml:mi mathvariant="normal">i</mml:mi><mml:mi mathvariant="normal">o</mml:mi><mml:mi mathvariant="normal">r</mml:mi></mml:mrow></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula>. The measurement distribution <inline-formula><mml:math id="inf198"><mml:mi mathvariant="normal">p</mml:mi><mml:mo>(</mml:mo><mml:mi>m</mml:mi><mml:mo>|</mml:mo><mml:mi>φ</mml:mi><mml:mo>)</mml:mo></mml:math></inline-formula> was also assumed to be normal in log-space with mean <inline-formula><mml:math id="inf199"><mml:mi>φ</mml:mi></mml:math></inline-formula>, and standard deviation <inline-formula><mml:math id="inf200"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mrow><mml:mi>σ</mml:mi></mml:mrow><mml:mrow><mml:mrow><mml:mi mathvariant="normal">l</mml:mi><mml:mi mathvariant="normal">i</mml:mi><mml:mi mathvariant="normal">k</mml:mi><mml:mi mathvariant="normal">e</mml:mi><mml:mi mathvariant="normal">l</mml:mi><mml:mi mathvariant="normal">i</mml:mi><mml:mi mathvariant="normal">h</mml:mi><mml:mi mathvariant="normal">o</mml:mi><mml:mi mathvariant="normal">o</mml:mi><mml:mi mathvariant="normal">d</mml:mi></mml:mrow></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula> . Note that whereas the prior <inline-formula><mml:math id="inf201"><mml:mi mathvariant="normal">p</mml:mi><mml:mo>(</mml:mo><mml:mi>φ</mml:mi><mml:mo>)</mml:mo></mml:math></inline-formula> remains fixed across trials of a particular sensory modality, the mean of measurement distribution is governed by <inline-formula><mml:math id="inf202"><mml:mi>φ</mml:mi></mml:math></inline-formula> and thus varies across trials. For each sensory modality, we fit two parameters, <inline-formula><mml:math id="inf203"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi mathvariant="normal">Θ</mml:mi><mml:mo>∋</mml:mo><mml:mrow><mml:mo>{</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mi>μ</mml:mi></mml:mrow><mml:mrow><mml:mrow><mml:mi mathvariant="normal">p</mml:mi><mml:mi mathvariant="normal">r</mml:mi><mml:mi mathvariant="normal">i</mml:mi><mml:mi mathvariant="normal">o</mml:mi><mml:mi mathvariant="normal">r</mml:mi></mml:mrow></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:mi>λ</mml:mi></mml:mrow><mml:mo>}</mml:mo></mml:mrow></mml:mrow></mml:mstyle></mml:math></inline-formula> , where <inline-formula><mml:math id="inf204"><mml:mi>λ</mml:mi></mml:math></inline-formula> was taken to be the ratio of <inline-formula><mml:math id="inf205"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mrow><mml:mi>σ</mml:mi></mml:mrow><mml:mrow><mml:mrow><mml:mi mathvariant="normal">p</mml:mi><mml:mi mathvariant="normal">r</mml:mi><mml:mi mathvariant="normal">i</mml:mi><mml:mi mathvariant="normal">o</mml:mi><mml:mi mathvariant="normal">r</mml:mi></mml:mrow></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula> over <inline-formula><mml:math id="inf206"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mrow><mml:mi>σ</mml:mi></mml:mrow><mml:mrow><mml:mrow><mml:mi mathvariant="normal">l</mml:mi><mml:mi mathvariant="normal">i</mml:mi><mml:mi mathvariant="normal">k</mml:mi><mml:mi mathvariant="normal">e</mml:mi><mml:mi mathvariant="normal">l</mml:mi><mml:mi mathvariant="normal">i</mml:mi><mml:mi mathvariant="normal">h</mml:mi><mml:mi mathvariant="normal">o</mml:mi><mml:mi mathvariant="normal">o</mml:mi><mml:mi mathvariant="normal">d</mml:mi></mml:mrow></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula> (i.e. their relative weight).</p></sec></sec><sec id="s4-3"><title>Model fitting</title><p>When inferring the participant’s beliefs about the control dynamics, we computed the posterior distribution on trial <italic>i</italic> as <inline-formula><mml:math id="inf207"><mml:mi mathvariant="normal">p</mml:mi><mml:mfenced separators="|"><mml:mrow><mml:mi>φ</mml:mi></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>m</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfenced><mml:mo>∝</mml:mo><mml:mi mathvariant="normal">p</mml:mi><mml:mo>(</mml:mo><mml:mi>φ</mml:mi><mml:mo>)</mml:mo><mml:mi mathvariant="normal">p</mml:mi><mml:mo>(</mml:mo><mml:msub><mml:mrow><mml:mi>m</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>|</mml:mo><mml:mi>φ</mml:mi><mml:mo>)</mml:mo></mml:math></inline-formula> (<xref ref-type="fig" rid="fig5">Figure 5A</xref>, left) and then selected the median over <inline-formula><mml:math id="inf208"><mml:mi>φ</mml:mi></mml:math></inline-formula> (equal to the maximum a posteriori estimate), and back-transformed it from log-space to obtain an estimate of the time constant <inline-formula><mml:math id="inf209"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mrow><mml:mrow><mml:mover><mml:mi>τ</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula> for that trial:<disp-formula id="equ16"><label>(5)</label><mml:math id="m16"><mml:mrow><mml:msub><mml:mrow><mml:mover><mml:mi>τ</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mrow><mml:mi mathvariant="normal">e</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">x</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">p</mml:mi></mml:mrow><mml:mrow><mml:mo>{</mml:mo><mml:mrow><mml:munder><mml:mrow><mml:mrow><mml:mi mathvariant="normal">a</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">r</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">g</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">m</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">a</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">x</mml:mi></mml:mrow></mml:mrow><mml:mi>φ</mml:mi></mml:munder><mml:mrow><mml:mtext> </mml:mtext></mml:mrow><mml:mrow><mml:mtext> </mml:mtext></mml:mrow><mml:mrow><mml:mi mathvariant="normal">p</mml:mi></mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>φ</mml:mi><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:msub><mml:mi>m</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>}</mml:mo></mml:mrow></mml:mrow></mml:math></disp-formula></p><p>Subsequently, <inline-formula><mml:math id="inf210"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mrow><mml:mrow><mml:mover><mml:mi>τ</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow></mml:mrow></mml:mrow></mml:mstyle></mml:math></inline-formula> is used to integrate the actual joystick input and produce the participant’s believed trajectory, according to (<xref ref-type="disp-formula" rid="equ1 equ2 equ3 equ4 equ5 equ6 equ7 equ8 equ9 equ10">Equations 1–10)</xref> in the <italic>Control dynamics</italic> section.</p><p>The Bayesian model had two free parameters <inline-formula><mml:math id="inf211"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi mathvariant="normal">Θ</mml:mi><mml:mo>∋</mml:mo><mml:mrow><mml:mo>{</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mi>μ</mml:mi></mml:mrow><mml:mrow><mml:mrow><mml:mi mathvariant="normal">p</mml:mi><mml:mi mathvariant="normal">r</mml:mi><mml:mi mathvariant="normal">i</mml:mi><mml:mi mathvariant="normal">o</mml:mi><mml:mi mathvariant="normal">r</mml:mi></mml:mrow></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:mi>λ</mml:mi></mml:mrow><mml:mo>}</mml:mo></mml:mrow></mml:mrow></mml:mstyle></mml:math></inline-formula>. We fit the model by assuming that participants stop as close to the target as possible given their understanding of the task. Specifically, we minimized the mean squared error (MSE) between the measured mean stopping position (computed using the response gains <inline-formula><mml:math id="inf212"><mml:msub><mml:mrow><mml:mi>g</mml:mi></mml:mrow><mml:mrow><mml:mi>r</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> and <inline-formula><mml:math id="inf213"><mml:msub><mml:mrow><mml:mi>g</mml:mi></mml:mrow><mml:mrow><mml:mi>θ</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> from <xref ref-type="disp-formula" rid="equ12">Equation 3</xref>) and our model of the participant’s believed stopping location <inline-formula><mml:math id="inf214"><mml:msub><mml:mrow><mml:mover accent="true"><mml:mrow><mml:mi mathvariant="bold">x</mml:mi></mml:mrow><mml:mo>^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> given the inferred dynamics <inline-formula><mml:math id="inf215"><mml:msub><mml:mrow><mml:mover accent="true"><mml:mrow><mml:mi>τ</mml:mi></mml:mrow><mml:mo>^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> . For each sensory condition:<disp-formula id="equ17"><label>(6)</label><mml:math id="m17"><mml:mrow><mml:msup><mml:mrow><mml:mi mathvariant="normal">Θ</mml:mi></mml:mrow><mml:mrow><mml:mo>∗</mml:mo></mml:mrow></mml:msup><mml:mo>=</mml:mo><mml:munder><mml:mrow><mml:mi mathvariant="normal">a</mml:mi><mml:mi mathvariant="normal">r</mml:mi><mml:mi mathvariant="normal">g</mml:mi><mml:mi mathvariant="normal">m</mml:mi><mml:mi mathvariant="normal">i</mml:mi><mml:mi mathvariant="normal">n</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">Θ</mml:mi></mml:mrow></mml:munder><mml:mtext> </mml:mtext><mml:mfrac><mml:mn>1</mml:mn><mml:mi>n</mml:mi></mml:mfrac><mml:munderover><mml:mo>∑</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>n</mml:mi></mml:mrow></mml:munderover><mml:msup><mml:mrow><mml:mo>{</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mover><mml:mrow><mml:mi mathvariant="bold">x</mml:mi></mml:mrow><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mover><mml:mi>τ</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi mathvariant="bold">u</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>−</mml:mo><mml:mrow><mml:mi mathvariant="bold-italic">G</mml:mi></mml:mrow><mml:msubsup><mml:mrow><mml:mrow><mml:mi mathvariant="bold">x</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mrow><mml:mi mathvariant="normal">t</mml:mi><mml:mi mathvariant="normal">a</mml:mi><mml:mi mathvariant="normal">r</mml:mi></mml:mrow></mml:mrow></mml:msubsup></mml:mrow><mml:mo>}</mml:mo></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:math></disp-formula></p><p>where, for each trial <inline-formula><mml:math id="inf216"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mover><mml:mrow><mml:mi mathvariant="bold">x</mml:mi></mml:mrow><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula> is the believed participant’s position, <inline-formula><mml:math id="inf217"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mrow><mml:mrow><mml:mover><mml:mi>τ</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula> is the estimated time constant, <inline-formula><mml:math id="inf218"><mml:msub><mml:mrow><mml:mi mathvariant="bold">u</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> is the time series of the joystick control input, <inline-formula><mml:math id="inf219"><mml:msubsup><mml:mrow><mml:mi mathvariant="bold">x</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">t</mml:mi><mml:mi mathvariant="normal">a</mml:mi><mml:mi mathvariant="normal">r</mml:mi></mml:mrow></mml:msubsup></mml:math></inline-formula> is the actual target position, <inline-formula><mml:math id="inf220"><mml:mi mathvariant="bold">G</mml:mi></mml:math></inline-formula> is the response gain matrix determined from <inline-formula><mml:math id="inf221"><mml:msub><mml:mrow><mml:mi>g</mml:mi></mml:mrow><mml:mrow><mml:mi>r</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> and <inline-formula><mml:math id="inf222"><mml:msub><mml:mrow><mml:mi>g</mml:mi></mml:mrow><mml:mrow><mml:mi>θ</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> , and <inline-formula><mml:math id="inf223"><mml:mi>n</mml:mi></mml:math></inline-formula> is the total number of trials.</p><sec id="s4-3-1"><title>Model validation</title><p>To evaluate the performance of our model, we examined the correlations between the <italic>subjective</italic> residual error and <inline-formula><mml:math id="inf224"><mml:mi>τ</mml:mi></mml:math></inline-formula> that are given by the model. The subjective residual error is defined as the difference between the believed (subjective) stopping location that a model produces and the mean response of the actual trajectories, adjusted for the response gain. The subjective residual errors are calculated for the radial and angular components of the response separately, according to <xref ref-type="disp-formula" rid="equ12">Equation 3</xref> (where actual responses <inline-formula><mml:math id="inf225"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mrow><mml:mover><mml:mi>r</mml:mi><mml:mo stretchy="false">~</mml:mo></mml:mover></mml:mrow><mml:mo>,</mml:mo><mml:mrow><mml:mover><mml:mi>θ</mml:mi><mml:mo stretchy="false">~</mml:mo></mml:mover></mml:mrow></mml:mrow></mml:mstyle></mml:math></inline-formula> are substituted by believed responses <inline-formula><mml:math id="inf226"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mrow><mml:mover><mml:mrow><mml:mover><mml:mi>r</mml:mi><mml:mo stretchy="false">~</mml:mo></mml:mover></mml:mrow><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mo>,</mml:mo><mml:mrow><mml:mover><mml:mrow><mml:mover><mml:mi>θ</mml:mi><mml:mo stretchy="false">~</mml:mo></mml:mover></mml:mrow><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow></mml:mrow></mml:mstyle></mml:math></inline-formula> , respectively). Ideally, these correlations should not exist for the model predictions (explained in text; <xref ref-type="fig" rid="fig5">Figure 5B</xref>). We determined the statistical significance of the model-implied correlations by adjusting for multiple comparisons (required level of statistical significance: p = 0.0085). To assess the performance of the Bayesian model, we compared the correlations between believed and actual stopping location with the time constant (<xref ref-type="fig" rid="fig5">Figure 5B</xref>; Wilcoxon signed-rank test).</p></sec><sec id="s4-3-2"><title>Dynamic prior model</title><p>Since the time constant changes randomly across trials, we tested whether the history of time constants influenced the estimate <inline-formula><mml:math id="inf227"><mml:mover accent="true"><mml:mrow><mml:mi>τ</mml:mi></mml:mrow><mml:mo>^</mml:mo></mml:mover></mml:math></inline-formula> . If true, the Bayesian model would imply a prior distribution over <inline-formula><mml:math id="inf228"><mml:mi>φ</mml:mi><mml:mo>=</mml:mo><mml:mrow><mml:mrow><mml:mi mathvariant="normal">log</mml:mi></mml:mrow><mml:mo>⁡</mml:mo><mml:mrow><mml:mi>τ</mml:mi></mml:mrow></mml:mrow></mml:math></inline-formula> that is dynamically changing according to the recent history of time constants, rather than being fixed. To explore this possibility, we repeated the two-step model outlined above, with the difference that the mean of the prior distribution is updated at every trial <inline-formula><mml:math id="inf229"><mml:mi>i</mml:mi></mml:math></inline-formula> by a weighted average of the mean prior in the previous trial and the current measurement over <inline-formula><mml:math id="inf230"><mml:mi>φ</mml:mi></mml:math></inline-formula>:<disp-formula id="equ18"><label>(7)</label><mml:math id="m18"><mml:mrow><mml:msub><mml:mi>μ</mml:mi><mml:mrow><mml:mrow><mml:mi mathvariant="normal">p</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">r</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">i</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">o</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">r</mml:mi></mml:mrow><mml:mo>,</mml:mo><mml:mtext> </mml:mtext><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:mi>k</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:msub><mml:mi>μ</mml:mi><mml:mrow><mml:mrow><mml:mi mathvariant="normal">p</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">r</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">i</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">o</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">r</mml:mi></mml:mrow><mml:mo>,</mml:mo><mml:mrow><mml:mtext> </mml:mtext></mml:mrow><mml:mi>i</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:mi>k</mml:mi><mml:mtext> </mml:mtext><mml:msub><mml:mi>φ</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:mrow><mml:mi mathvariant="normal">w</mml:mi><mml:mi mathvariant="normal">h</mml:mi><mml:mi mathvariant="normal">e</mml:mi><mml:mi mathvariant="normal">r</mml:mi><mml:mi mathvariant="normal">e</mml:mi></mml:mrow><mml:mtext> </mml:mtext><mml:mi>k</mml:mi><mml:mo>=</mml:mo><mml:mfrac><mml:msup><mml:mi>λ</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup><mml:mrow><mml:msup><mml:mi>λ</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:mfrac></mml:mrow></mml:math></disp-formula></p><p>and where <inline-formula><mml:math id="inf231"><mml:mi>λ</mml:mi></mml:math></inline-formula> is the ratio of prior standard deviation over likelihood standard deviation. As <inline-formula><mml:math id="inf232"><mml:mi>k</mml:mi></mml:math></inline-formula> indicates, the relative weighting between prior and measurement on each trial depends solely on their relative widths. Finally, the initial prior was taken to be the time constant on the first trial. Thus, the only free parameter we fit was <italic>λ</italic>.</p></sec><sec id="s4-3-3"><title>Sensory-independent model</title><p>As another alternative to the Bayesian model with a static prior, we also constructed a model where participants ignored changes in the time constants and navigated according to a fixed estimate <inline-formula><mml:math id="inf233"><mml:mover accent="true"><mml:mrow><mml:mi>τ</mml:mi></mml:mrow><mml:mo>^</mml:mo></mml:mover></mml:math></inline-formula> across all trials in each sensory condition. This model had only one free parameter: the time constant estimate <inline-formula><mml:math id="inf234"><mml:mover accent="true"><mml:mrow><mml:mi>τ</mml:mi></mml:mrow><mml:mo>^</mml:mo></mml:mover></mml:math></inline-formula> , which was integrated with the actual joystick input of each trial to reconstruct the believed trajectory of the participant. We fit <inline-formula><mml:math id="inf235"><mml:mover accent="true"><mml:mrow><mml:mi>τ</mml:mi></mml:mrow><mml:mo>^</mml:mo></mml:mover></mml:math></inline-formula> for each sensory condition by minimizing the MSE between the believed stopping location and the mean response (according to <xref ref-type="disp-formula" rid="equ17">Equation 6</xref>).</p></sec><sec id="s4-3-4"><title>Model comparison</title><p>To compare the static prior Bayesian model against the dynamic prior Bayesian and the sensory-independent models, we compared the correlations between believed stopping locations and time constants that each model produces (<xref ref-type="fig" rid="fig7">Figure 7</xref>; paired Student’s <italic>t</italic>-test).</p></sec><sec id="s4-3-5"><title>Sensory feedback control model</title><p>We tested a sensory feedback control model, in which the controller uses bang-bang control and switches from forward to backward input at a constant and predetermined distance from the target position (corrected for the bias, i.e. mean response). Specifically, we preserved the actual angular and only fitted the linear control input for each trial. Thus, as switch distance, we refer to a Euclidean distance from the bias-corrected target position. We fit the mean and standard deviation of the switch distance for each participant in each condition separately, by minimizing the distance of the actual from the model-predicted stopping locations. To evaluate how well this model describes our data, we compared the correlations and regression slopes between the time constant and residual errors from the stopping locations predicted by the model with those from our actual data (<xref ref-type="fig" rid="fig7s2">Figure 7—figure supplement 2</xref>).</p></sec></sec></sec></body><back><sec id="s5" sec-type="additional-information"><title>Additional information</title><fn-group content-type="competing-interest"><title>Competing interests</title><fn fn-type="COI-statement" id="conf1"><p>No competing interests declared</p></fn><fn fn-type="COI-statement" id="conf2"><p>No competing interests declared</p></fn></fn-group><fn-group content-type="author-contribution"><title>Author contributions</title><fn fn-type="con" id="con1"><p>Conceptualization, Data curation, Formal analysis, Investigation, Methodology, Software, Validation, Visualization, Writing – original draft</p></fn><fn fn-type="con" id="con2"><p>Formal analysis, Investigation, Methodology, Project administration, Software, Supervision, Validation, Visualization, Writing – original draft, Writing – review and editing</p></fn><fn fn-type="con" id="con3"><p>Conceptualization, Investigation, Methodology, Software, Writing – review and editing</p></fn><fn fn-type="con" id="con4"><p>Conceptualization, Funding acquisition, Investigation, Methodology, Project administration, Resources, Supervision, Validation, Writing – review and editing</p></fn><fn fn-type="con" id="con5"><p>Conceptualization, Funding acquisition, Investigation, Project administration, Resources, Validation, Writing – review and editing</p></fn></fn-group><fn-group content-type="ethics-information"><title>Ethics</title><fn fn-type="other"><p>Human subjects: All experimental procedures were approved by the Institutional Review Board at Baylor College of Medicine and all participants signed an approved consent form (H-29411).</p></fn></fn-group></sec><sec id="s6" sec-type="supplementary-material"><title>Additional files</title><supplementary-material id="transrepform"><label>Transparent reporting form</label><media mime-subtype="pdf" mimetype="application" xlink:href="elife-63405-transrepform1-v1.pdf"/></supplementary-material></sec><sec id="s7" sec-type="data-availability"><title>Data availability</title><p>MATLAB code implementing all quantitative analyses in this study is available online (<ext-link ext-link-type="uri" xlink:href="https://github.com/AkisStavropoulos/matlab_code">https://github.com/AkisStavropoulos/matlab_code</ext-link>, copy archived at <ext-link ext-link-type="uri" xlink:href="https://archive.softwareheritage.org/swh:1:dir:f83d21b0e9b0ba70635333feea223519681765c9;origin=https://github.com/AkisStavropoulos/matlab_code;visit=swh:1:snp:d3157e05526743951fa6946e658a953704617734;anchor=swh:1:rev:03fcaf8a8170d99f80e2bd9b40c888df34513f89">swh:1:rev:03fcaf8a8170d99f80e2bd9b40c888df34513f89</ext-link>). The dataset was made available online at the following address: <ext-link ext-link-type="uri" xlink:href="https://gin.g-node.org/akis_stavropoulos/humans_control_dynamics_sensory_modality_steering">https://gin.g-node.org/akis_stavropoulos/humans_control_dynamics_sensory_modality_steering</ext-link>.</p><p>The following dataset was generated:</p><p><element-citation id="dataset1" publication-type="data" specific-use="isSupplementedBy"><person-group person-group-type="author"><name><surname>Stavropoulos</surname><given-names>L</given-names></name><name><surname>Laurens, Pitkow</surname><given-names>A</given-names></name></person-group><year iso-8601-date="2021">2021</year><data-title>Steering data from a navigation study in virtual reality under different sensory modalities and control dynamics, named &quot;Influence of sensory modality and control dynamics on human path integration&quot;</data-title><source>G-node</source><pub-id pub-id-type="accession" xlink:href="https://gin.g-node.org/akis_stavropoulos/humans_control_dynamics_sensory_modality_steering">humans_control_dynamics_sensory_modality_steering</pub-id></element-citation></p></sec><ack id="ack"><title>Acknowledgements</title><p>We thank Jing Lin and Jian Chen for their technical support, and Baptiste Caziot, Panos Alefantis, Babis Stavropoulos, Evangelia Pappou, and Emmanouela Pechynaki for their useful insights. This work was supported by the Simons Collaboration on the Global Brain, grant no. <ext-link ext-link-type="uri" xlink:href="https://www.sciencedirect.com/science/article/pii/S0896627318304677#gs1">324143</ext-link>, and NIH <ext-link ext-link-type="uri" xlink:href="https://www.sciencedirect.com/science/article/pii/S0896627318304677#gs2">DC007620</ext-link>. GCD was supported by NIH <ext-link ext-link-type="uri" xlink:href="https://www.sciencedirect.com/science/article/pii/S0896627318304677#gs3">EY016178</ext-link>.</p></ack><ref-list><title>References</title><ref id="bib1"><element-citation publication-type="preprint"><person-group person-group-type="author"><name><surname>Alefantis</surname><given-names>P</given-names></name><name><surname>Lakshminarasimhan</surname><given-names>KJ</given-names></name><name><surname>Avila</surname><given-names>E</given-names></name><name><surname>Pitkow</surname><given-names>X</given-names></name><name><surname>Angelaki</surname><given-names>DE</given-names></name></person-group><year iso-8601-date="2021">2021</year><article-title>Sensory Evidence Accumulation Using Optic Flow in a Naturalistic Navigation Task</article-title><source>bioRxiv</source><pub-id pub-id-type="doi">10.1101/2021.04.26.441532</pub-id></element-citation></ref><ref id="bib2"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Angelaki</surname><given-names>DE</given-names></name><name><surname>Dickman</surname><given-names>JD</given-names></name></person-group><year iso-8601-date="2000">2000</year><article-title>Spatiotemporal processing of linear acceleration: primary afferent and central vestibular neuron responses</article-title><source>Journal of Neurophysiology</source><volume>84</volume><fpage>2113</fpage><lpage>2132</lpage><pub-id pub-id-type="doi">10.1152/jn.2000.84.4.2113</pub-id><pub-id pub-id-type="pmid">11024100</pub-id></element-citation></ref><ref id="bib3"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Arce</surname><given-names>F</given-names></name><name><surname>Novick</surname><given-names>I</given-names></name><name><surname>Shahar</surname><given-names>M</given-names></name><name><surname>Link</surname><given-names>Y</given-names></name><name><surname>Ghez</surname><given-names>C</given-names></name><name><surname>Vaadia</surname><given-names>E</given-names></name><name><surname>Gribble</surname><given-names>PL</given-names></name></person-group><year iso-8601-date="2009">2009</year><article-title>Differences in Context and Feedback Result in Different Trajectories and Adaptation Strategies in Reaching</article-title><source>PLOS ONE</source><volume>4</volume><elocation-id>e4214</elocation-id><pub-id pub-id-type="doi">10.1371/journal.pone.0004214</pub-id></element-citation></ref><ref id="bib4"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Batcho</surname><given-names>CS</given-names></name><name><surname>Gagné</surname><given-names>M</given-names></name><name><surname>Bouyer</surname><given-names>LJ</given-names></name><name><surname>Roy</surname><given-names>JS</given-names></name><name><surname>Mercier</surname><given-names>C</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Impact of online visual feedback on motor acquisition and retention when learning to reach in a force field</article-title><source>Neuroscience</source><volume>337</volume><fpage>267</fpage><lpage>275</lpage><pub-id pub-id-type="doi">10.1016/j.neuroscience.2016.09.020</pub-id></element-citation></ref><ref id="bib5"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bergmann</surname><given-names>J</given-names></name><name><surname>Krauss</surname><given-names>E</given-names></name><name><surname>Münch</surname><given-names>A</given-names></name><name><surname>Jungmann</surname><given-names>R</given-names></name><name><surname>Oberfeld</surname><given-names>D</given-names></name><name><surname>Hecht</surname><given-names>H</given-names></name></person-group><year iso-8601-date="2011">2011</year><article-title>Locomotor and verbal distance judgments in action and vista space</article-title><source>Experimental Brain Research</source><volume>210</volume><fpage>13</fpage><lpage>23</lpage><pub-id pub-id-type="doi">10.1007/s00221-011-2597-z</pub-id><pub-id pub-id-type="pmid">21365183</pub-id></element-citation></ref><ref id="bib6"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Berniker</surname><given-names>M</given-names></name><name><surname>Voss</surname><given-names>M</given-names></name><name><surname>Kording</surname><given-names>K</given-names></name></person-group><year iso-8601-date="2010">2010</year><article-title>Learning priors for Bayesian computations in the nervous system</article-title><source>PLOS ONE</source><volume>5</volume><elocation-id>e12686</elocation-id><pub-id pub-id-type="doi">10.1371/journal.pone.0012686</pub-id><pub-id pub-id-type="pmid">20844766</pub-id></element-citation></ref><ref id="bib7"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Burdet</surname><given-names>E</given-names></name><name><surname>Osu</surname><given-names>R</given-names></name><name><surname>Franklin</surname><given-names>DW</given-names></name><name><surname>Milner</surname><given-names>TE</given-names></name><name><surname>Kawato</surname><given-names>M</given-names></name></person-group><year iso-8601-date="2001">2001</year><article-title>The central nervous system stabilizes unstable dynamics by learning optimal impedance</article-title><source>Nature</source><volume>414</volume><fpage>446</fpage><lpage>449</lpage><pub-id pub-id-type="doi">10.1038/35106566</pub-id><pub-id pub-id-type="pmid">11719805</pub-id></element-citation></ref><ref id="bib8"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Campos</surname><given-names>JL</given-names></name><name><surname>Byrne</surname><given-names>P</given-names></name><name><surname>Sun</surname><given-names>HJ</given-names></name></person-group><year iso-8601-date="2010">2010</year><article-title>The brain weights body-based cues higher than vision when estimating walked distances</article-title><source>The European Journal of Neuroscience</source><volume>31</volume><fpage>1889</fpage><lpage>1898</lpage><pub-id pub-id-type="doi">10.1111/j.1460-9568.2010.07212.x</pub-id><pub-id pub-id-type="pmid">20584194</pub-id></element-citation></ref><ref id="bib9"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Campos</surname><given-names>JL</given-names></name><name><surname>Butler</surname><given-names>JS</given-names></name><name><surname>Bülthoff</surname><given-names>HH</given-names></name></person-group><year iso-8601-date="2012">2012</year><article-title>Multisensory integration in the estimation of walked distances</article-title><source>Experimental Brain Research</source><volume>218</volume><fpage>551</fpage><lpage>565</lpage><pub-id pub-id-type="doi">10.1007/s00221-012-3048-1</pub-id><pub-id pub-id-type="pmid">22411581</pub-id></element-citation></ref><ref id="bib10"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Chen</surname><given-names>X</given-names></name><name><surname>McNamara</surname><given-names>TP</given-names></name><name><surname>Kelly</surname><given-names>JW</given-names></name><name><surname>Wolbers</surname><given-names>T</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>Cue combination in human spatial navigation</article-title><source>Cognitive Psychology</source><volume>95</volume><fpage>105</fpage><lpage>144</lpage><pub-id pub-id-type="doi">10.1016/j.cogpsych.2017.04.003</pub-id><pub-id pub-id-type="pmid">28478330</pub-id></element-citation></ref><ref id="bib11"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Chrastil</surname><given-names>ER</given-names></name><name><surname>Sherrill</surname><given-names>KR</given-names></name><name><surname>Hasselmo</surname><given-names>ME</given-names></name><name><surname>Stern</surname><given-names>CE</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Which way and how far? Tracking of translation and rotation information for human path integration</article-title><source>Human Brain Mapping</source><volume>37</volume><fpage>3636</fpage><lpage>3655</lpage><pub-id pub-id-type="doi">10.1002/hbm.23265</pub-id><pub-id pub-id-type="pmid">27238897</pub-id></element-citation></ref><ref id="bib12"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Chrastil</surname><given-names>ER</given-names></name><name><surname>Nicora</surname><given-names>GL</given-names></name><name><surname>Huang</surname><given-names>A</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>Vision and proprioception make equal contributions to path integration in a novel homing task</article-title><source>Cognition</source><volume>192</volume><elocation-id>103998</elocation-id><pub-id pub-id-type="doi">10.1016/j.cognition.2019.06.010</pub-id><pub-id pub-id-type="pmid">31228680</pub-id></element-citation></ref><ref id="bib13"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Einstein</surname><given-names>A</given-names></name></person-group><year iso-8601-date="1907">1907</year><article-title>Relativitätsprinzip und die ausdemselbengezogenenFolgerungenOn the Relativity Principle and the Conclusions Drawn from It</article-title><source>Jahrbuch Der Radioaktivität</source><volume>1</volume><fpage>411</fpage><lpage>462</lpage></element-citation></ref><ref id="bib14"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Fernandez</surname><given-names>C</given-names></name><name><surname>Goldberg</surname><given-names>JM</given-names></name><name><surname>Abend</surname><given-names>WK</given-names></name></person-group><year iso-8601-date="1972">1972</year><article-title>Response to static tilts of peripheral neurons innervating otolith organs of the squirrel monkey</article-title><source>Journal of Neurophysiology</source><volume>35</volume><fpage>978</fpage><lpage>987</lpage><pub-id pub-id-type="doi">10.1152/jn.1972.35.6.978</pub-id><pub-id pub-id-type="pmid">4631840</pub-id></element-citation></ref><ref id="bib15"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Fernández</surname><given-names>C</given-names></name><name><surname>Goldberg</surname><given-names>JM</given-names></name></person-group><year iso-8601-date="1976">1976</year><article-title>Physiology of peripheral neurons innervating otolith organs of the squirrel monkey. I. Response to static tilts and to long-duration centrifugal force</article-title><source>Journal of Neurophysiology</source><volume>39</volume><fpage>970</fpage><lpage>984</lpage><pub-id pub-id-type="doi">10.1152/jn.1976.39.5.970</pub-id><pub-id pub-id-type="pmid">824412</pub-id></element-citation></ref><ref id="bib16"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Glasauer</surname><given-names>S</given-names></name><name><surname>Amorim</surname><given-names>MA</given-names></name><name><surname>Vitte</surname><given-names>E</given-names></name><name><surname>Berthoz</surname><given-names>A</given-names></name></person-group><year iso-8601-date="1994">1994</year><article-title>Goal-directed linear locomotion in normal and labyrinthine-defective subjects</article-title><source>Experimental Brain Research</source><volume>98</volume><fpage>323</fpage><lpage>335</lpage><pub-id pub-id-type="doi">10.1007/BF00228420</pub-id><pub-id pub-id-type="pmid">8050517</pub-id></element-citation></ref><ref id="bib17"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Glasauer</surname><given-names>S</given-names></name><name><surname>Schneider</surname><given-names>E</given-names></name><name><surname>Grasso</surname><given-names>R</given-names></name><name><surname>Ivanenko</surname><given-names>YP</given-names></name></person-group><year iso-8601-date="2007">2007</year><article-title>Space-time relativity in self-motion reproduction</article-title><source>Journal of Neurophysiology</source><volume>97</volume><fpage>451</fpage><lpage>461</lpage><pub-id pub-id-type="doi">10.1152/jn.01243.2005</pub-id><pub-id pub-id-type="pmid">17050823</pub-id></element-citation></ref><ref id="bib18"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Grasso</surname><given-names>R</given-names></name><name><surname>Glasauer</surname><given-names>S</given-names></name><name><surname>Georges-François</surname><given-names>P</given-names></name><name><surname>Israël</surname><given-names>I</given-names></name></person-group><year iso-8601-date="1999">1999</year><article-title>Replication of passive whole-body linear displacements from inertial cues: Facts and mechanisms</article-title><source>Annals of the New York Academy of Sciences</source><volume>871</volume><fpage>345</fpage><lpage>366</lpage><pub-id pub-id-type="doi">10.1111/j.1749-6632.1999.tb09197.x</pub-id><pub-id pub-id-type="pmid">10372084</pub-id></element-citation></ref><ref id="bib19"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Israël</surname><given-names>I</given-names></name><name><surname>Bronstein</surname><given-names>AM</given-names></name><name><surname>Kanayama</surname><given-names>R</given-names></name><name><surname>Faldon</surname><given-names>M</given-names></name><name><surname>Gresty</surname><given-names>MA</given-names></name></person-group><year iso-8601-date="1996">1996</year><article-title>Visual and vestibular factors influencing vestibular “navigation.”</article-title><source>Experimental Brain Research</source><volume>112</volume><fpage>411</fpage><lpage>419</lpage><pub-id pub-id-type="doi">10.1007/BF00227947</pub-id><pub-id pub-id-type="pmid">9007543</pub-id></element-citation></ref><ref id="bib20"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Israël</surname><given-names>I</given-names></name><name><surname>Grasso</surname><given-names>R</given-names></name><name><surname>Georges-Francois</surname><given-names>P</given-names></name><name><surname>Tsuzuku</surname><given-names>T</given-names></name><name><surname>Berthoz</surname><given-names>A</given-names></name></person-group><year iso-8601-date="1997">1997</year><article-title>Spatial memory and path integration studied by self-driven passive linear displacement. I. Basic properties</article-title><source>Journal of Neurophysiology</source><volume>77</volume><fpage>3180</fpage><lpage>3192</lpage><pub-id pub-id-type="doi">10.1152/jn.1997.77.6.3180</pub-id><pub-id pub-id-type="pmid">9212267</pub-id></element-citation></ref><ref id="bib21"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Jürgens</surname><given-names>R</given-names></name><name><surname>Becker</surname><given-names>W</given-names></name></person-group><year iso-8601-date="2006">2006</year><article-title>Perception of angular displacement without landmarks: evidence for Bayesian fusion of vestibular, optokinetic, podokinesthetic, and cognitive information</article-title><source>Experimental Brain Research</source><volume>174</volume><fpage>528</fpage><lpage>543</lpage><pub-id pub-id-type="doi">10.1007/s00221-006-0486-7</pub-id><pub-id pub-id-type="pmid">16832684</pub-id></element-citation></ref><ref id="bib22"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Karmali</surname><given-names>F</given-names></name><name><surname>Lim</surname><given-names>K</given-names></name><name><surname>Merfeld</surname><given-names>DM</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>Visual and vestibular perceptual thresholds each demonstrate better precision at specific frequencies and also exhibit optimal integration</article-title><source>Journal of Neurophysiology</source><volume>111</volume><fpage>2393</fpage><lpage>2403</lpage><pub-id pub-id-type="doi">10.1152/jn.00332.2013</pub-id><pub-id pub-id-type="pmid">24371292</pub-id></element-citation></ref><ref id="bib23"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kearns</surname><given-names>MJ</given-names></name><name><surname>Warren</surname><given-names>WH</given-names></name><name><surname>Duchon</surname><given-names>AP</given-names></name><name><surname>Tarr</surname><given-names>MJ</given-names></name></person-group><year iso-8601-date="2002">2002</year><article-title>Path integration from optic flow and body senses in a homing task</article-title><source>Perception</source><volume>31</volume><fpage>349</fpage><lpage>374</lpage><pub-id pub-id-type="doi">10.1068/p3311</pub-id><pub-id pub-id-type="pmid">11954696</pub-id></element-citation></ref><ref id="bib24"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kingma</surname><given-names>H</given-names></name></person-group><year iso-8601-date="2005">2005</year><article-title>Thresholds for perception of direction of linear acceleration as a possible evaluation of the otolith function</article-title><source>BMC Ear, Nose, and Throat Disorders</source><volume>5</volume><elocation-id>5</elocation-id><pub-id pub-id-type="doi">10.1186/1472-6815-5-5</pub-id><pub-id pub-id-type="pmid">15972096</pub-id></element-citation></ref><ref id="bib25"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Klatzky</surname><given-names>RL</given-names></name></person-group><year iso-8601-date="1998">1998</year><article-title>Spatial updating of selfposition and orientation during real</article-title><source>Psychological Science</source><volume>9</volume><elocation-id>e58</elocation-id><pub-id pub-id-type="doi">10.1111/1467-9280.00058</pub-id></element-citation></ref><ref id="bib26"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Koppen</surname><given-names>M</given-names></name><name><surname>Ter Horst</surname><given-names>AC</given-names></name><name><surname>Medendorp</surname><given-names>WP</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>Weighted Visual and Vestibular Cues for Spatial Updating During Passive Self-Motion</article-title><source>Multisensory Research</source><volume>32</volume><fpage>165</fpage><lpage>178</lpage><pub-id pub-id-type="doi">10.1163/22134808-20191364</pub-id><pub-id pub-id-type="pmid">31059483</pub-id></element-citation></ref><ref id="bib27"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Körding</surname><given-names>KP</given-names></name><name><surname>Ku</surname><given-names>S</given-names></name><name><surname>Wolpert</surname><given-names>DM</given-names></name></person-group><year iso-8601-date="2004">2004</year><article-title>Bayesian integration in force estimation</article-title><source>Journal of Neurophysiology</source><volume>92</volume><fpage>3161</fpage><lpage>3165</lpage><pub-id pub-id-type="doi">10.1152/jn.00275.2004</pub-id><pub-id pub-id-type="pmid">15190091</pub-id></element-citation></ref><ref id="bib28"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kording</surname><given-names>KP</given-names></name><name><surname>Tenenbaum</surname><given-names>JB</given-names></name><name><surname>Shadmehr</surname><given-names>R</given-names></name></person-group><year iso-8601-date="2007">2007</year><article-title>The dynamics of memory as a consequence of optimal adaptation to a changing body</article-title><source>Nature Neuroscience</source><volume>10</volume><fpage>779</fpage><lpage>786</lpage><pub-id pub-id-type="doi">10.1038/nn1901</pub-id><pub-id pub-id-type="pmid">17496891</pub-id></element-citation></ref><ref id="bib29"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Krakauer</surname><given-names>JW</given-names></name><name><surname>Ghilardi</surname><given-names>MF</given-names></name><name><surname>Ghez</surname><given-names>C</given-names></name></person-group><year iso-8601-date="1999">1999</year><article-title>Independent learning of internal models for kinematic and dynamic control of reaching</article-title><source>Nature Neuroscience</source><volume>2</volume><fpage>1026</fpage><lpage>1031</lpage><pub-id pub-id-type="doi">10.1038/14826</pub-id><pub-id pub-id-type="pmid">10526344</pub-id></element-citation></ref><ref id="bib30"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Lackner</surname><given-names>JR</given-names></name><name><surname>Dizio</surname><given-names>P</given-names></name></person-group><year iso-8601-date="1994">1994</year><article-title>Rapid adaptation to Coriolis force perturbations of arm trajectory</article-title><source>Journal of Neurophysiology</source><volume>72</volume><fpage>299</fpage><lpage>313</lpage><pub-id pub-id-type="doi">10.1152/jn.1994.72.1.299</pub-id><pub-id pub-id-type="pmid">7965013</pub-id></element-citation></ref><ref id="bib31"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Lakshminarasimhan</surname><given-names>KJ</given-names></name><name><surname>Petsalis</surname><given-names>M</given-names></name><name><surname>Park</surname><given-names>H</given-names></name><name><surname>DeAngelis</surname><given-names>GC</given-names></name><name><surname>Pitkow</surname><given-names>X</given-names></name><name><surname>Angelaki</surname><given-names>DE</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>A Dynamic Bayesian Observer Model Reveals Origins of Bias in Visual Path Integration</article-title><source>Neuron</source><volume>99</volume><fpage>194</fpage><lpage>206</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2018.05.040</pub-id><pub-id pub-id-type="pmid">29937278</pub-id></element-citation></ref><ref id="bib32"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Lim</surname><given-names>K</given-names></name><name><surname>Karmali</surname><given-names>F</given-names></name><name><surname>Nicoucar</surname><given-names>K</given-names></name><name><surname>Merfeld</surname><given-names>DM</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>Perceptual precision of passive body tilt is consistent with statistically optimal cue integration</article-title><source>Journal of Neurophysiology</source><volume>117</volume><fpage>2037</fpage><lpage>2052</lpage><pub-id pub-id-type="doi">10.1152/jn.00073.2016</pub-id><pub-id pub-id-type="pmid">28179477</pub-id></element-citation></ref><ref id="bib33"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>MacNeilage</surname><given-names>PR</given-names></name><name><surname>Turner</surname><given-names>AH</given-names></name><name><surname>Angelaki</surname><given-names>DE</given-names></name></person-group><year iso-8601-date="2010">2010</year><article-title>Canal-otolith interactions and detection thresholds of linear and angular components during curved-path self-motion</article-title><source>Journal of Neurophysiology</source><volume>104</volume><fpage>765</fpage><lpage>773</lpage><pub-id pub-id-type="doi">10.1152/jn.01067.2009</pub-id><pub-id pub-id-type="pmid">20554843</pub-id></element-citation></ref><ref id="bib34"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Mathys</surname><given-names>C</given-names></name><name><surname>Daunizeau</surname><given-names>J</given-names></name><name><surname>Friston</surname><given-names>KJ</given-names></name><name><surname>Stephan</surname><given-names>KE</given-names></name></person-group><year iso-8601-date="2011">2011</year><article-title>A bayesian foundation for individual learning under uncertainty</article-title><source>Frontiers in Human Neuroscience</source><volume>5</volume><elocation-id>39</elocation-id><pub-id pub-id-type="doi">10.3389/fnhum.2011.00039</pub-id><pub-id pub-id-type="pmid">21629826</pub-id></element-citation></ref><ref id="bib35"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Péruch</surname><given-names>P</given-names></name><name><surname>Borel</surname><given-names>L</given-names></name><name><surname>Gaunet</surname><given-names>F</given-names></name><name><surname>Thinus-Blanc</surname><given-names>G</given-names></name><name><surname>Magnan</surname><given-names>J</given-names></name><name><surname>Lacour</surname><given-names>M</given-names></name></person-group><year iso-8601-date="1999">1999</year><article-title>Spatial performance of unilateral vestibular defective patients in nonvisual versus visual navigation</article-title><source>Journal of Vestibular Research</source><volume>9</volume><fpage>37</fpage><lpage>47</lpage><pub-id pub-id-type="doi">10.3233/VES-1999-9105</pub-id></element-citation></ref><ref id="bib36"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Péruch</surname><given-names>P</given-names></name><name><surname>Borel</surname><given-names>L</given-names></name><name><surname>Magnan</surname><given-names>J</given-names></name><name><surname>Lacour</surname><given-names>M</given-names></name></person-group><year iso-8601-date="2005">2005</year><article-title>Direction and distance deficits in path integration after unilateral vestibular loss depend on task complexity</article-title><source>Brain Research. Cognitive Brain Research</source><volume>25</volume><fpage>862</fpage><lpage>872</lpage><pub-id pub-id-type="doi">10.1016/j.cogbrainres.2005.09.012</pub-id><pub-id pub-id-type="pmid">16256321</pub-id></element-citation></ref><ref id="bib37"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Petrini</surname><given-names>K</given-names></name><name><surname>Caradonna</surname><given-names>A</given-names></name><name><surname>Foster</surname><given-names>C</given-names></name><name><surname>Burgess</surname><given-names>N</given-names></name><name><surname>Nardini</surname><given-names>M</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>How vision and self-motion combine or compete during path reproduction changes with age</article-title><source>Scientific Reports</source><volume>6</volume><elocation-id>29163</elocation-id><pub-id pub-id-type="doi">10.1038/srep29163</pub-id><pub-id pub-id-type="pmid">27381183</pub-id></element-citation></ref><ref id="bib38"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Petzschner</surname><given-names>FH</given-names></name><name><surname>Glasauer</surname><given-names>S</given-names></name></person-group><year iso-8601-date="2011">2011</year><article-title>Iterative Bayesian estimation as an explanation for range and regression effects: a study on human path integration</article-title><source>The Journal of Neuroscience</source><volume>31</volume><fpage>17220</fpage><lpage>17229</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.2028-11.2011</pub-id><pub-id pub-id-type="pmid">22114288</pub-id></element-citation></ref><ref id="bib39"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Prsa</surname><given-names>M</given-names></name><name><surname>Jimenez-Rezende</surname><given-names>D</given-names></name><name><surname>Blanke</surname><given-names>O</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>Inference of perceptual priors from path dynamics of passive self-motion</article-title><source>Journal of Neurophysiology</source><volume>113</volume><fpage>1400</fpage><lpage>1413</lpage><pub-id pub-id-type="doi">10.1152/jn.00755.2014</pub-id><pub-id pub-id-type="pmid">25505114</pub-id></element-citation></ref><ref id="bib40"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Sağlam</surname><given-names>M</given-names></name><name><surname>Glasauer</surname><given-names>S</given-names></name><name><surname>Lehnen</surname><given-names>N</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>Vestibular and cerebellar contribution to gaze optimality</article-title><source>Brain: A Journal of Neurology</source><volume>137</volume><fpage>1080</fpage><lpage>1094</lpage><pub-id pub-id-type="doi">10.1093/brain/awu006</pub-id><pub-id pub-id-type="pmid">24549962</pub-id></element-citation></ref><ref id="bib41"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Schubert</surname><given-names>MC</given-names></name><name><surname>Arthur</surname><given-names>JC</given-names></name><name><surname>Shelhamer</surname><given-names>M</given-names></name><name><surname>Kortte</surname><given-names>KB</given-names></name></person-group><year iso-8601-date="2012">2012</year><article-title>Linear Path Integration Deficits in Patients with Abnormal Vestibular Afference</article-title><source>Seeing and Perceiving</source><volume>25</volume><fpage>155</fpage><lpage>178</lpage><pub-id pub-id-type="doi">10.1163/187847612X629928</pub-id></element-citation></ref><ref id="bib42"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Seemungal</surname><given-names>BM</given-names></name><name><surname>Glasauer</surname><given-names>S</given-names></name><name><surname>Gresty</surname><given-names>MA</given-names></name><name><surname>Bronstein</surname><given-names>AM</given-names></name></person-group><year iso-8601-date="2007">2007</year><article-title>Vestibular perception and navigation in the congenitally blind</article-title><source>Journal of Neurophysiology</source><volume>97</volume><fpage>4341</fpage><lpage>4356</lpage><pub-id pub-id-type="doi">10.1152/jn.01321.2006</pub-id><pub-id pub-id-type="pmid">17392406</pub-id></element-citation></ref><ref id="bib43"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Seidman</surname><given-names>SH</given-names></name></person-group><year iso-8601-date="2008">2008</year><article-title>Translational motion perception and vestiboocular responses in the absence of non-inertial cues</article-title><source>Experimental Brain Research</source><volume>184</volume><fpage>13</fpage><lpage>29</lpage><pub-id pub-id-type="doi">10.1007/s00221-007-1072-3</pub-id><pub-id pub-id-type="pmid">17680240</pub-id></element-citation></ref><ref id="bib44"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Shadmehr</surname><given-names>R</given-names></name><name><surname>Mussa-Ivaldi</surname><given-names>FA</given-names></name></person-group><year iso-8601-date="1994">1994</year><article-title>Adaptive representation of dynamics during learning of a motor task</article-title><source>The Journal of Neuroscience</source><volume>14</volume><fpage>3208</fpage><lpage>3224</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.14-05-03208.1994</pub-id><pub-id pub-id-type="pmid">8182467</pub-id></element-citation></ref><ref id="bib45"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Stangl</surname><given-names>M</given-names></name><name><surname>Kanitscheider</surname><given-names>I</given-names></name><name><surname>Riemer</surname><given-names>M</given-names></name><name><surname>Fiete</surname><given-names>I</given-names></name><name><surname>Wolbers</surname><given-names>T</given-names></name></person-group><year iso-8601-date="2020">2020</year><article-title>Sources of path integration error in young and aging humans</article-title><source>Nature Communications</source><volume>11</volume><elocation-id>2626</elocation-id><pub-id pub-id-type="doi">10.1038/s41467-020-15805-9</pub-id><pub-id pub-id-type="pmid">32457293</pub-id></element-citation></ref><ref id="bib46"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Takahashi</surname><given-names>CD</given-names></name><name><surname>Scheidt</surname><given-names>RA</given-names></name><name><surname>Reinkensmeyer</surname><given-names>DJ</given-names></name></person-group><year iso-8601-date="2001">2001</year><article-title>Impedance control and internal model formation when reaching in a randomly varying dynamical environment</article-title><source>Journal of Neurophysiology</source><volume>86</volume><fpage>1047</fpage><lpage>1051</lpage><pub-id pub-id-type="doi">10.1152/jn.2001.86.2.1047</pub-id><pub-id pub-id-type="pmid">11495973</pub-id></element-citation></ref><ref id="bib47"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Tcheang</surname><given-names>L</given-names></name><name><surname>Bülthoff</surname><given-names>HH</given-names></name><name><surname>Burgess</surname><given-names>N</given-names></name></person-group><year iso-8601-date="2011">2011</year><article-title>Visual influence on path integration in darkness indicates a multimodal representation of large-scale space</article-title><source>PNAS</source><volume>108</volume><fpage>1152</fpage><lpage>1157</lpage><pub-id pub-id-type="doi">10.1073/pnas.1011843108</pub-id><pub-id pub-id-type="pmid">21199934</pub-id></element-citation></ref><ref id="bib48"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>ter Horst</surname><given-names>AC</given-names></name><name><surname>Koppen</surname><given-names>M</given-names></name><name><surname>Selen</surname><given-names>LPJ</given-names></name><name><surname>Medendorp</surname><given-names>WP</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>Reliability-Based Weighting of Visual and Vestibular Cues in Displacement Estimation</article-title><source>PLOS ONE</source><volume>10</volume><elocation-id>e0145015</elocation-id><pub-id pub-id-type="doi">10.1371/journal.pone.0145015</pub-id><pub-id pub-id-type="pmid">26658990</pub-id></element-citation></ref><ref id="bib49"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Tramper</surname><given-names>JJ</given-names></name><name><surname>Medendorp</surname><given-names>WP</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>Parallel updating and weighting of multiple spatial maps for visual stability during whole body motion</article-title><source>Journal of Neurophysiology</source><volume>114</volume><fpage>3211</fpage><lpage>3219</lpage><pub-id pub-id-type="doi">10.1152/jn.00576.2015</pub-id><pub-id pub-id-type="pmid">26490289</pub-id></element-citation></ref><ref id="bib50"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Zupan</surname><given-names>LH</given-names></name><name><surname>Merfeld</surname><given-names>DM</given-names></name></person-group><year iso-8601-date="2008">2008</year><article-title>Interaural self-motion linear velocity thresholds are shifted by roll vection</article-title><source>Experimental Brain Research</source><volume>191</volume><fpage>505</fpage><lpage>511</lpage><pub-id pub-id-type="doi">10.1007/s00221-008-1540-4</pub-id><pub-id pub-id-type="pmid">18843487</pub-id></element-citation></ref></ref-list><app-group><app id="appendix-1"><title>Appendix 1</title><sec id="s8" sec-type="appendix"><title>Implementation of MC algorithm</title><sec id="s8-1" sec-type="appendix"><title>Step 1</title><p>In the first step, the participant’s velocity is being transformed into the VR (screen) coordinates. This transformation is necessary to deduce centrifugal components from the participants’ trajectory, and include them in the motor commands:<disp-formula id="equ19"><mml:math id="m19"><mml:mrow><mml:msubsup><mml:mi>v</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mrow><mml:mi mathvariant="normal">V</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">R</mml:mi></mml:mrow><mml:mo>,</mml:mo><mml:mi>x</mml:mi></mml:mrow></mml:msubsup><mml:mo>=</mml:mo><mml:mtext> </mml:mtext><mml:msubsup><mml:mi>v</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mrow><mml:mi mathvariant="normal">J</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">S</mml:mi></mml:mrow></mml:mrow></mml:msubsup><mml:mo>⋅</mml:mo><mml:mrow><mml:mi mathvariant="normal">c</mml:mi><mml:mi mathvariant="normal">o</mml:mi><mml:mi mathvariant="normal">s</mml:mi></mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:msubsup><mml:mi>φ</mml:mi><mml:mrow><mml:mi>t</mml:mi></mml:mrow><mml:mrow><mml:mrow><mml:mi mathvariant="normal">V</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">R</mml:mi></mml:mrow></mml:mrow></mml:msubsup><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></disp-formula><disp-formula id="equ20"><mml:math id="m20"><mml:mrow><mml:msubsup><mml:mi>v</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mrow><mml:mi mathvariant="normal">V</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">R</mml:mi></mml:mrow><mml:mo>,</mml:mo><mml:mi>y</mml:mi></mml:mrow></mml:msubsup><mml:mo>=</mml:mo><mml:mtext> </mml:mtext><mml:msubsup><mml:mi>v</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mrow><mml:mi mathvariant="normal">J</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">S</mml:mi></mml:mrow></mml:mrow></mml:msubsup><mml:mo>⋅</mml:mo><mml:mrow><mml:mi mathvariant="normal">s</mml:mi><mml:mi mathvariant="normal">i</mml:mi><mml:mi mathvariant="normal">n</mml:mi></mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:msubsup><mml:mi>φ</mml:mi><mml:mrow><mml:mi>t</mml:mi></mml:mrow><mml:mrow><mml:mrow><mml:mi mathvariant="normal">V</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">R</mml:mi></mml:mrow></mml:mrow></mml:msubsup><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></disp-formula><disp-formula id="equ21"><mml:math id="m21"><mml:msubsup><mml:mrow><mml:mi>ω</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi mathvariant="normal">V</mml:mi><mml:mi mathvariant="normal">R</mml:mi></mml:mrow></mml:msubsup><mml:mo>=</mml:mo><mml:mi> </mml:mi><mml:msubsup><mml:mrow><mml:mi>ω</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi mathvariant="normal">J</mml:mi><mml:mi mathvariant="normal">S</mml:mi></mml:mrow></mml:msubsup></mml:math></disp-formula></p><p>where <inline-formula><mml:math id="inf236"><mml:msubsup><mml:mrow><mml:mi>v</mml:mi></mml:mrow><mml:mrow/><mml:mrow><mml:mi mathvariant="normal">V</mml:mi><mml:mi mathvariant="normal">R</mml:mi><mml:mo>,</mml:mo><mml:mi>x</mml:mi></mml:mrow></mml:msubsup></mml:math></inline-formula> and <inline-formula><mml:math id="inf237"><mml:msubsup><mml:mrow><mml:mi>v</mml:mi></mml:mrow><mml:mrow/><mml:mrow><mml:mi mathvariant="normal">V</mml:mi><mml:mi mathvariant="normal">R</mml:mi><mml:mo>,</mml:mo><mml:mi>y</mml:mi></mml:mrow></mml:msubsup></mml:math></inline-formula> are the linear velocities of the participant in VR coordinates, <inline-formula><mml:math id="inf238"><mml:msubsup><mml:mrow><mml:mi>ω</mml:mi></mml:mrow><mml:mrow/><mml:mrow><mml:mi mathvariant="normal">V</mml:mi><mml:mi mathvariant="normal">R</mml:mi></mml:mrow></mml:msubsup></mml:math></inline-formula> is the angular velocity of the VR system, and <inline-formula><mml:math id="inf239"><mml:msubsup><mml:mrow><mml:mi>φ</mml:mi></mml:mrow><mml:mrow/><mml:mrow><mml:mi mathvariant="normal">V</mml:mi><mml:mi mathvariant="normal">R</mml:mi></mml:mrow></mml:msubsup></mml:math></inline-formula> is the direction of the platform in space.</p></sec><sec id="s8-2" sec-type="appendix"><title>Step 2</title><p>As mentioned before, the arena diameter is finite, and it is necessary to keep track of the participant’s position in the arena, to avoid ‘crashing’ on the invisible walls. In this step, the participant’s velocity is slowed down when the participant approaches the boundaries of the arena, to account for a ‘smooth crash’.</p></sec><sec id="s8-3" sec-type="appendix"><title>Step 3</title><p>Here, the current acceleration is calculated in the VR coordinates <inline-formula><mml:math id="inf240"><mml:mfenced separators="|"><mml:mrow><mml:msubsup><mml:mrow><mml:mi>a</mml:mi></mml:mrow><mml:mrow/><mml:mrow><mml:mi mathvariant="normal">V</mml:mi><mml:mi mathvariant="normal">R</mml:mi><mml:mo>,</mml:mo><mml:mi>x</mml:mi></mml:mrow></mml:msubsup><mml:mo>,</mml:mo><mml:mi> </mml:mi><mml:msubsup><mml:mrow><mml:mi>a</mml:mi></mml:mrow><mml:mrow/><mml:mrow><mml:mi mathvariant="normal">V</mml:mi><mml:mi mathvariant="normal">R</mml:mi><mml:mo>,</mml:mo><mml:mi>y</mml:mi></mml:mrow></mml:msubsup></mml:mrow></mml:mfenced></mml:math></inline-formula> . This is also where the GIA error feedback loop (see Step 10) updates the VR acceleration.<disp-formula id="equ22"><mml:math id="m22"><mml:mrow><mml:msubsup><mml:mi>α</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mrow><mml:mi mathvariant="normal">V</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">R</mml:mi></mml:mrow><mml:mo>,</mml:mo><mml:mi>x</mml:mi></mml:mrow></mml:msubsup><mml:mo>=</mml:mo><mml:mtext> </mml:mtext><mml:mfrac><mml:mrow><mml:msubsup><mml:mi>v</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mrow><mml:mi mathvariant="normal">V</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">R</mml:mi></mml:mrow><mml:mo>,</mml:mo><mml:mi>x</mml:mi></mml:mrow></mml:msubsup><mml:mo>−</mml:mo><mml:mtext> </mml:mtext><mml:msubsup><mml:mi>v</mml:mi><mml:mrow><mml:mi>t</mml:mi></mml:mrow><mml:mrow><mml:mrow><mml:mi mathvariant="normal">V</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">R</mml:mi></mml:mrow><mml:mo>,</mml:mo><mml:mi>x</mml:mi></mml:mrow></mml:msubsup><mml:mo>+</mml:mo><mml:mfrac><mml:mrow><mml:mi>d</mml:mi><mml:mi>t</mml:mi></mml:mrow><mml:msub><mml:mi>τ</mml:mi><mml:mrow><mml:mrow><mml:mi mathvariant="normal">M</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">C</mml:mi></mml:mrow></mml:mrow></mml:msub></mml:mfrac><mml:mo>.</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msubsup><mml:mi>v</mml:mi><mml:mrow><mml:mi>t</mml:mi></mml:mrow><mml:mrow><mml:mrow><mml:mi mathvariant="normal">V</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">R</mml:mi></mml:mrow><mml:mo>,</mml:mo><mml:mi>x</mml:mi></mml:mrow></mml:msubsup><mml:mo>−</mml:mo><mml:mtext> </mml:mtext><mml:msubsup><mml:mrow><mml:mrow><mml:mover><mml:mi>v</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow><mml:mrow><mml:mrow><mml:mi mathvariant="normal">V</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">R</mml:mi></mml:mrow><mml:mo>,</mml:mo><mml:mi>x</mml:mi></mml:mrow></mml:msubsup></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mrow><mml:mi>d</mml:mi><mml:mi>t</mml:mi></mml:mrow></mml:mfrac></mml:mrow></mml:math></disp-formula><disp-formula id="equ23"><mml:math id="m23"><mml:mrow><mml:msubsup><mml:mi>α</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mrow><mml:mi mathvariant="normal">V</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">R</mml:mi></mml:mrow><mml:mo>,</mml:mo><mml:mi>y</mml:mi></mml:mrow></mml:msubsup><mml:mo>=</mml:mo><mml:mtext> </mml:mtext><mml:mfrac><mml:mrow><mml:msubsup><mml:mi>v</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mrow><mml:mi mathvariant="normal">V</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">R</mml:mi></mml:mrow><mml:mo>,</mml:mo><mml:mi>y</mml:mi></mml:mrow></mml:msubsup><mml:mo>−</mml:mo><mml:mtext> </mml:mtext><mml:msubsup><mml:mi>v</mml:mi><mml:mrow><mml:mi>t</mml:mi></mml:mrow><mml:mrow><mml:mrow><mml:mi mathvariant="normal">V</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">R</mml:mi></mml:mrow><mml:mo>,</mml:mo><mml:mi>y</mml:mi></mml:mrow></mml:msubsup><mml:mo>+</mml:mo><mml:mfrac><mml:mrow><mml:mi>d</mml:mi><mml:mi>t</mml:mi></mml:mrow><mml:msub><mml:mi>τ</mml:mi><mml:mrow><mml:mrow><mml:mi mathvariant="normal">M</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">C</mml:mi></mml:mrow></mml:mrow></mml:msub></mml:mfrac><mml:mo>.</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msubsup><mml:mi>v</mml:mi><mml:mrow><mml:mi>t</mml:mi></mml:mrow><mml:mrow><mml:mrow><mml:mi mathvariant="normal">V</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">R</mml:mi></mml:mrow><mml:mo>,</mml:mo><mml:mi>y</mml:mi></mml:mrow></mml:msubsup><mml:mo>−</mml:mo><mml:mtext> </mml:mtext><mml:msubsup><mml:mrow><mml:mrow><mml:mover><mml:mi>v</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow><mml:mrow><mml:mrow><mml:mi mathvariant="normal">V</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">R</mml:mi></mml:mrow><mml:mo>,</mml:mo><mml:mi>y</mml:mi></mml:mrow></mml:msubsup></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mrow><mml:mi>d</mml:mi><mml:mi>t</mml:mi></mml:mrow></mml:mfrac></mml:mrow></mml:math></disp-formula></p><p>where <inline-formula><mml:math id="inf241"><mml:msub><mml:mrow><mml:mover accent="true"><mml:mrow><mml:mi>v</mml:mi></mml:mrow><mml:mo>^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> is the updated velocity from the previous timestep (<inline-formula><mml:math id="inf242"><mml:msub><mml:mrow><mml:mi>τ</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">M</mml:mi><mml:mi mathvariant="normal">C</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> explained in Step 10). After the acceleration is obtained, it is being transformed back to the participant’s coordinates <inline-formula><mml:math id="inf243"><mml:mfenced separators="|"><mml:mrow><mml:msubsup><mml:mrow><mml:mi>a</mml:mi></mml:mrow><mml:mrow/><mml:mrow><mml:mi mathvariant="normal">s</mml:mi><mml:mi mathvariant="normal">u</mml:mi><mml:mi mathvariant="normal">b</mml:mi><mml:mo>,</mml:mo><mml:mi>x</mml:mi></mml:mrow></mml:msubsup><mml:mo>,</mml:mo><mml:mi> </mml:mi><mml:msubsup><mml:mrow><mml:mi>a</mml:mi></mml:mrow><mml:mrow/><mml:mrow><mml:mi mathvariant="normal">s</mml:mi><mml:mi mathvariant="normal">u</mml:mi><mml:mi mathvariant="normal">b</mml:mi><mml:mo>,</mml:mo><mml:mi>y</mml:mi></mml:mrow></mml:msubsup></mml:mrow></mml:mfenced></mml:math></inline-formula>:<disp-formula id="equ24"><mml:math id="m24"><mml:msubsup><mml:mrow><mml:mi>α</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi mathvariant="normal">s</mml:mi><mml:mi mathvariant="normal">u</mml:mi><mml:mi mathvariant="normal">b</mml:mi><mml:mo>,</mml:mo><mml:mi>x</mml:mi></mml:mrow></mml:msubsup><mml:mo>=</mml:mo><mml:mi> </mml:mi><mml:msubsup><mml:mrow><mml:mi>α</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi mathvariant="normal">V</mml:mi><mml:mi mathvariant="normal">R</mml:mi><mml:mo>,</mml:mo><mml:mi>x</mml:mi></mml:mrow></mml:msubsup><mml:mo>∙</mml:mo><mml:mrow><mml:mrow><mml:mi mathvariant="normal">cos</mml:mi></mml:mrow><mml:mo>⁡</mml:mo><mml:mrow><mml:mfenced separators="|"><mml:mrow><mml:msubsup><mml:mrow><mml:mi>φ</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">V</mml:mi><mml:mi mathvariant="normal">R</mml:mi></mml:mrow></mml:msubsup></mml:mrow></mml:mfenced></mml:mrow></mml:mrow><mml:mo>+</mml:mo><mml:mi> </mml:mi><mml:msubsup><mml:mrow><mml:mi>α</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi mathvariant="normal">V</mml:mi><mml:mi mathvariant="normal">R</mml:mi><mml:mo>,</mml:mo><mml:mi>y</mml:mi></mml:mrow></mml:msubsup><mml:mo>∙</mml:mo><mml:mrow><mml:mrow><mml:mi mathvariant="normal">sin</mml:mi></mml:mrow><mml:mo>⁡</mml:mo><mml:mrow><mml:mfenced separators="|"><mml:mrow><mml:msubsup><mml:mrow><mml:mi>φ</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">V</mml:mi><mml:mi mathvariant="normal">R</mml:mi></mml:mrow></mml:msubsup></mml:mrow></mml:mfenced></mml:mrow></mml:mrow></mml:math></disp-formula><disp-formula id="equ25"><mml:math id="m25"><mml:msubsup><mml:mrow><mml:mi>α</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi mathvariant="normal">s</mml:mi><mml:mi mathvariant="normal">u</mml:mi><mml:mi mathvariant="normal">b</mml:mi><mml:mo>,</mml:mo><mml:mi>y</mml:mi></mml:mrow></mml:msubsup><mml:mo>=</mml:mo><mml:mi> </mml:mi><mml:msubsup><mml:mrow><mml:mo>-</mml:mo><mml:mi>α</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi mathvariant="normal">V</mml:mi><mml:mi mathvariant="normal">R</mml:mi><mml:mo>,</mml:mo><mml:mi>x</mml:mi></mml:mrow></mml:msubsup><mml:mo>∙</mml:mo><mml:mrow><mml:mrow><mml:mi mathvariant="normal">sin</mml:mi></mml:mrow><mml:mo>⁡</mml:mo><mml:mrow><mml:mfenced separators="|"><mml:mrow><mml:msubsup><mml:mrow><mml:mi>φ</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">V</mml:mi><mml:mi mathvariant="normal">R</mml:mi></mml:mrow></mml:msubsup></mml:mrow></mml:mfenced></mml:mrow></mml:mrow><mml:mo>+</mml:mo><mml:mi> </mml:mi><mml:msubsup><mml:mrow><mml:mi>α</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi mathvariant="normal">V</mml:mi><mml:mi mathvariant="normal">R</mml:mi><mml:mo>,</mml:mo><mml:mi>y</mml:mi></mml:mrow></mml:msubsup><mml:mo>∙</mml:mo><mml:mrow><mml:mrow><mml:mi mathvariant="normal">cos</mml:mi></mml:mrow><mml:mo>⁡</mml:mo><mml:mrow><mml:mfenced separators="|"><mml:mrow><mml:msubsup><mml:mrow><mml:mi>φ</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">V</mml:mi><mml:mi mathvariant="normal">R</mml:mi></mml:mrow></mml:msubsup></mml:mrow></mml:mfenced></mml:mrow></mml:mrow></mml:math></disp-formula></p></sec><sec id="s8-4" sec-type="appendix"><title>Step 4</title><p>Now, the acceleration <inline-formula><mml:math id="inf244"><mml:msup><mml:mrow><mml:mi>a</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">s</mml:mi><mml:mi mathvariant="normal">u</mml:mi><mml:mi mathvariant="normal">b</mml:mi></mml:mrow></mml:msup></mml:math></inline-formula> in participant’s coordinates is being transformed into platform coordinates to take into account the orientation of the participant onto the motion platform (<inline-formula><mml:math id="inf245"><mml:msubsup><mml:mrow><mml:mi>φ</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">m</mml:mi><mml:mi mathvariant="normal">o</mml:mi><mml:mi mathvariant="normal">o</mml:mi><mml:mi mathvariant="normal">g</mml:mi></mml:mrow></mml:msubsup></mml:math></inline-formula>), which is controlled by the yaw motor. For instance, if the participant faces toward the left of the platform and accelerates forward in egocentric coordinates, then the platform should move to the left:<disp-formula id="equ26"><mml:math id="m26"><mml:msubsup><mml:mrow><mml:mi>α</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi mathvariant="normal">d</mml:mi><mml:mi mathvariant="normal">e</mml:mi><mml:mi mathvariant="normal">s</mml:mi><mml:mi mathvariant="normal">i</mml:mi><mml:mi mathvariant="normal">r</mml:mi><mml:mi mathvariant="normal">e</mml:mi><mml:mi mathvariant="normal">d</mml:mi><mml:mo>,</mml:mo><mml:mi>x</mml:mi></mml:mrow></mml:msubsup><mml:mo>=</mml:mo><mml:mi> </mml:mi><mml:msubsup><mml:mrow><mml:mi>α</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi mathvariant="normal">s</mml:mi><mml:mi mathvariant="normal">u</mml:mi><mml:mi mathvariant="normal">b</mml:mi><mml:mo>,</mml:mo><mml:mi>x</mml:mi></mml:mrow></mml:msubsup><mml:mo>∙</mml:mo><mml:mi mathvariant="normal">c</mml:mi><mml:mi mathvariant="normal">o</mml:mi><mml:mi mathvariant="normal">s</mml:mi><mml:mfenced separators="|"><mml:mrow><mml:msubsup><mml:mrow><mml:mi>φ</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">m</mml:mi><mml:mi mathvariant="normal">o</mml:mi><mml:mi mathvariant="normal">o</mml:mi><mml:mi mathvariant="normal">g</mml:mi></mml:mrow></mml:msubsup></mml:mrow></mml:mfenced><mml:mo>-</mml:mo><mml:mi> </mml:mi><mml:msubsup><mml:mrow><mml:mi>α</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi mathvariant="normal">s</mml:mi><mml:mi mathvariant="normal">u</mml:mi><mml:mi mathvariant="normal">b</mml:mi><mml:mo>,</mml:mo><mml:mi>y</mml:mi></mml:mrow></mml:msubsup><mml:mo>∙</mml:mo><mml:mi mathvariant="normal">s</mml:mi><mml:mi mathvariant="normal">i</mml:mi><mml:mi mathvariant="normal">n</mml:mi><mml:mfenced separators="|"><mml:mrow><mml:msubsup><mml:mrow><mml:mi>φ</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">m</mml:mi><mml:mi mathvariant="normal">o</mml:mi><mml:mi mathvariant="normal">o</mml:mi><mml:mi mathvariant="normal">g</mml:mi></mml:mrow></mml:msubsup></mml:mrow></mml:mfenced></mml:math></disp-formula><disp-formula id="equ27"><mml:math id="m27"><mml:msubsup><mml:mrow><mml:mi>α</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi mathvariant="normal">d</mml:mi><mml:mi mathvariant="normal">e</mml:mi><mml:mi mathvariant="normal">s</mml:mi><mml:mi mathvariant="normal">i</mml:mi><mml:mi mathvariant="normal">r</mml:mi><mml:mi mathvariant="normal">e</mml:mi><mml:mi mathvariant="normal">d</mml:mi><mml:mo>,</mml:mo><mml:mi>y</mml:mi></mml:mrow></mml:msubsup><mml:mo>=</mml:mo><mml:mi> </mml:mi><mml:msubsup><mml:mrow><mml:mi>α</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi mathvariant="normal">s</mml:mi><mml:mi mathvariant="normal">u</mml:mi><mml:mi mathvariant="normal">b</mml:mi><mml:mo>,</mml:mo><mml:mi>x</mml:mi></mml:mrow></mml:msubsup><mml:mo>∙</mml:mo><mml:mi mathvariant="normal">s</mml:mi><mml:mi mathvariant="normal">i</mml:mi><mml:mi mathvariant="normal">n</mml:mi><mml:mfenced separators="|"><mml:mrow><mml:msubsup><mml:mrow><mml:mi>φ</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">m</mml:mi><mml:mi mathvariant="normal">o</mml:mi><mml:mi mathvariant="normal">o</mml:mi><mml:mi mathvariant="normal">g</mml:mi></mml:mrow></mml:msubsup></mml:mrow></mml:mfenced><mml:mo>+</mml:mo><mml:mi> </mml:mi><mml:msubsup><mml:mrow><mml:mi>α</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi mathvariant="normal">s</mml:mi><mml:mi mathvariant="normal">u</mml:mi><mml:mi mathvariant="normal">b</mml:mi><mml:mo>,</mml:mo><mml:mi>y</mml:mi></mml:mrow></mml:msubsup><mml:mo>∙</mml:mo><mml:mi mathvariant="normal">c</mml:mi><mml:mi mathvariant="normal">o</mml:mi><mml:mi mathvariant="normal">s</mml:mi><mml:mfenced separators="|"><mml:mrow><mml:msubsup><mml:mrow><mml:mi>φ</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">m</mml:mi><mml:mi mathvariant="normal">o</mml:mi><mml:mi mathvariant="normal">o</mml:mi><mml:mi mathvariant="normal">g</mml:mi></mml:mrow></mml:msubsup></mml:mrow></mml:mfenced></mml:math></disp-formula></p><p>where <inline-formula><mml:math id="inf246"><mml:msubsup><mml:mrow><mml:mi>α</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi mathvariant="normal">d</mml:mi><mml:mi mathvariant="normal">e</mml:mi><mml:mi mathvariant="normal">s</mml:mi><mml:mi mathvariant="normal">i</mml:mi><mml:mi mathvariant="normal">r</mml:mi><mml:mi mathvariant="normal">e</mml:mi><mml:mi mathvariant="normal">d</mml:mi><mml:mo>,</mml:mo><mml:mi>x</mml:mi></mml:mrow></mml:msubsup></mml:math></inline-formula> is the desired platform acceleration.</p></sec><sec id="s8-5" sec-type="appendix"><title>Step 5</title><p>This is the MC step. Here, the amount of tilt and translation that will be commanded is computed, based on the tilt-translation trade-off we set. First, the platform’s desired acceleration is computed by applying a step response function <inline-formula><mml:math id="inf247"><mml:mi>f</mml:mi><mml:mfenced separators="|"><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:mfenced></mml:math></inline-formula> to the acceleration input:<disp-formula id="equ28"><mml:math id="m28"><mml:msup><mml:mrow><mml:mi>a</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">M</mml:mi><mml:mi mathvariant="normal">C</mml:mi><mml:mo>,</mml:mo><mml:mi>x</mml:mi></mml:mrow></mml:msup><mml:mfenced separators="|"><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:mfenced><mml:mo>=</mml:mo><mml:mi> </mml:mi><mml:mrow><mml:munderover><mml:mo>∫</mml:mo><mml:mrow><mml:mn>0</mml:mn></mml:mrow><mml:mrow><mml:mo>+</mml:mo><mml:mi>∞</mml:mi></mml:mrow></mml:munderover><mml:mrow><mml:msup><mml:mrow><mml:mi>a</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">d</mml:mi><mml:mi mathvariant="normal">e</mml:mi><mml:mi mathvariant="normal">s</mml:mi><mml:mi mathvariant="normal">i</mml:mi><mml:mi mathvariant="normal">r</mml:mi><mml:mi mathvariant="normal">e</mml:mi><mml:mi mathvariant="normal">d</mml:mi><mml:mo>,</mml:mo><mml:mi>x</mml:mi></mml:mrow></mml:msup><mml:mfenced separators="|"><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:mfenced><mml:mo>∙</mml:mo><mml:mi>f</mml:mi><mml:mfenced separators="|"><mml:mrow><mml:mi>t</mml:mi><mml:mo>-</mml:mo><mml:mi>s</mml:mi></mml:mrow></mml:mfenced><mml:mi> </mml:mi><mml:mi>d</mml:mi><mml:mi>s</mml:mi></mml:mrow></mml:mrow></mml:math></disp-formula></p><p>where:<disp-formula id="equ29"><mml:math id="m29"><mml:mrow><mml:mi>f</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mtext> </mml:mtext><mml:msub><mml:mi>k</mml:mi><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>⋅</mml:mo><mml:msup><mml:mi>e</mml:mi><mml:mrow><mml:mfrac><mml:mrow><mml:mo>−</mml:mo><mml:mi>t</mml:mi></mml:mrow><mml:msub><mml:mi>T</mml:mi><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mfrac></mml:mrow></mml:msup><mml:mo>+</mml:mo><mml:mtext> </mml:mtext><mml:msub><mml:mi>k</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:mo>⋅</mml:mo><mml:msup><mml:mi>e</mml:mi><mml:mrow><mml:mfrac><mml:mrow><mml:mo>−</mml:mo><mml:mi>t</mml:mi></mml:mrow><mml:msub><mml:mi>T</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub></mml:mfrac></mml:mrow></mml:msup><mml:mo>+</mml:mo><mml:mtext> </mml:mtext><mml:msub><mml:mi>k</mml:mi><mml:mrow><mml:mn>3</mml:mn></mml:mrow></mml:msub><mml:mo>⋅</mml:mo><mml:msup><mml:mi>e</mml:mi><mml:mrow><mml:mfrac><mml:mrow><mml:mo>−</mml:mo><mml:mi>t</mml:mi></mml:mrow><mml:msub><mml:mi>T</mml:mi><mml:mrow><mml:mn>3</mml:mn></mml:mrow></mml:msub></mml:mfrac></mml:mrow></mml:msup></mml:mrow></mml:math></disp-formula><disp-formula id="equ30"><mml:math id="m30"><mml:mrow><mml:mi>T</mml:mi><mml:mo>=</mml:mo><mml:mo stretchy="false">[</mml:mo><mml:mn>0.07</mml:mn><mml:mtext> </mml:mtext><mml:mtext> </mml:mtext><mml:mn>0.3</mml:mn><mml:mtext> </mml:mtext><mml:mtext> </mml:mtext><mml:mn>1</mml:mn><mml:mo stretchy="false">]</mml:mo><mml:mo>,</mml:mo><mml:mi>K</mml:mi><mml:mo>=</mml:mo><mml:mo stretchy="false">[</mml:mo><mml:mo>−</mml:mo><mml:mn>0.4254</mml:mn><mml:mtext> </mml:mtext><mml:mtext> </mml:mtext><mml:mn>1.9938</mml:mn><mml:mtext> </mml:mtext><mml:mtext> </mml:mtext><mml:mo>−</mml:mo><mml:mn>0.5684</mml:mn><mml:mo stretchy="false">]</mml:mo></mml:mrow></mml:math></disp-formula></p><p>These coefficients were adjusted with respect to the following constraints:</p><list list-type="order"><list-item><p><inline-formula><mml:math id="inf248"><mml:mi>f</mml:mi><mml:mo>(</mml:mo><mml:mn>0</mml:mn><mml:mo>)</mml:mo><mml:mi> </mml:mi><mml:mo>=</mml:mo><mml:mi> </mml:mi><mml:mn>1</mml:mn></mml:math></inline-formula>, that is, the output would correspond to the input at <inline-formula><mml:math id="inf249"><mml:mi>t</mml:mi><mml:mo>=</mml:mo><mml:mn>0</mml:mn></mml:math></inline-formula>. This was chosen to ensure that the high-frequency content of the motion would be rendered by translating the platform.</p></list-item><list-item><p><inline-formula><mml:math id="inf250"><mml:mrow><mml:msubsup><mml:mo>∫</mml:mo><mml:mrow><mml:mn>0</mml:mn></mml:mrow><mml:mrow><mml:mi>∞</mml:mi></mml:mrow></mml:msubsup><mml:mrow><mml:mi>f</mml:mi></mml:mrow></mml:mrow><mml:mo>=</mml:mo><mml:mn>0</mml:mn></mml:math></inline-formula>: This was chosen to ensure that, if the input was an infinitely long acceleration, the motion of the platform would stabilize to a point where the linear velocity was 0.</p></list-item><list-item><p><inline-formula><mml:math id="inf251"><mml:mi>d</mml:mi><mml:mi>f</mml:mi><mml:mo>/</mml:mo><mml:mi>d</mml:mi><mml:mi>t</mml:mi><mml:mi> </mml:mi><mml:mo>=</mml:mo><mml:mi> </mml:mi><mml:mn>0</mml:mn></mml:math></inline-formula> at <inline-formula><mml:math id="inf252"><mml:mi>t</mml:mi><mml:mo>=</mml:mo><mml:mn>0</mml:mn></mml:math></inline-formula>. This was chosen because tilt velocity of the platform is equal to <inline-formula><mml:math id="inf253"><mml:mo>-</mml:mo><mml:mi>d</mml:mi><mml:mi>f</mml:mi><mml:mo>/</mml:mo><mml:mi>d</mml:mi><mml:mi>t</mml:mi></mml:math></inline-formula>. Since the tilt velocity at <italic>t</italic> &lt; 0 is zero, this constraint ensures that tilt velocity is continuous and prevents excessive angular acceleration at <italic>t</italic> = 0.</p></list-item></list><p>The same process is repeated for the <italic>y</italic> component of the acceleration.</p><p>Finally, the amount of tilt (<inline-formula><mml:math id="inf254"><mml:mi>θ</mml:mi><mml:mo>,</mml:mo></mml:math></inline-formula> in degrees) is calculated based on the difference between the desired platform motion and the deliverable motion:<disp-formula id="equ31"><mml:math id="m31"><mml:msubsup><mml:mrow><mml:mi>θ</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi mathvariant="normal">M</mml:mi><mml:mi mathvariant="normal">C</mml:mi><mml:mo>,</mml:mo><mml:mi>x</mml:mi></mml:mrow></mml:msubsup><mml:mo>=</mml:mo><mml:mrow><mml:mrow><mml:msup><mml:mrow><mml:mi mathvariant="normal">sin</mml:mi></mml:mrow><mml:mrow><mml:mo>-</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msup></mml:mrow><mml:mo>⁡</mml:mo><mml:mrow><mml:mfenced separators="|"><mml:mrow><mml:mfrac><mml:mrow><mml:msubsup><mml:mrow><mml:mi>a</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi mathvariant="normal">m</mml:mi><mml:mi mathvariant="normal">o</mml:mi><mml:mi mathvariant="normal">o</mml:mi><mml:mi mathvariant="normal">g</mml:mi><mml:mo>,</mml:mo><mml:mi>x</mml:mi></mml:mrow></mml:msubsup><mml:mo>-</mml:mo><mml:mi> </mml:mi><mml:msubsup><mml:mrow><mml:mi>a</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi mathvariant="normal">M</mml:mi><mml:mi mathvariant="normal">C</mml:mi><mml:mo>,</mml:mo><mml:mi>x</mml:mi></mml:mrow></mml:msubsup></mml:mrow><mml:mrow><mml:mi>g</mml:mi></mml:mrow></mml:mfrac></mml:mrow></mml:mfenced></mml:mrow></mml:mrow></mml:math></disp-formula><disp-formula id="equ32"><mml:math id="m32"><mml:msubsup><mml:mrow><mml:mi>θ</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi mathvariant="normal">M</mml:mi><mml:mi mathvariant="normal">C</mml:mi><mml:mo>,</mml:mo><mml:mi>y</mml:mi></mml:mrow></mml:msubsup><mml:mo>=</mml:mo><mml:mrow><mml:mrow><mml:msup><mml:mrow><mml:mi mathvariant="normal">sin</mml:mi></mml:mrow><mml:mrow><mml:mo>-</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msup></mml:mrow><mml:mo>⁡</mml:mo><mml:mrow><mml:mfenced separators="|"><mml:mrow><mml:mfrac><mml:mrow><mml:msubsup><mml:mrow><mml:mi>a</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi mathvariant="normal">m</mml:mi><mml:mi mathvariant="normal">o</mml:mi><mml:mi mathvariant="normal">o</mml:mi><mml:mi mathvariant="normal">g</mml:mi><mml:mo>,</mml:mo><mml:mi>y</mml:mi></mml:mrow></mml:msubsup><mml:mo>-</mml:mo><mml:mi> </mml:mi><mml:msubsup><mml:mrow><mml:mi>a</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi mathvariant="normal">M</mml:mi><mml:mi mathvariant="normal">C</mml:mi><mml:mo>,</mml:mo><mml:mi>y</mml:mi></mml:mrow></mml:msubsup></mml:mrow><mml:mrow><mml:mi>g</mml:mi></mml:mrow></mml:mfrac></mml:mrow></mml:mfenced></mml:mrow></mml:mrow></mml:math></disp-formula></p><p>where <italic>g</italic> = 9.81 m/s<sup>2<sub>.</sub></sup></p></sec><sec id="s8-6" sec-type="appendix"><title>Step 6</title><p>Afterward, the tilt velocity and acceleration are being calculated:<disp-formula id="equ33">,<mml:math id="m33"><mml:mrow><mml:msubsup><mml:mover><mml:mi>θ</mml:mi><mml:mrow><mml:mo>˙</mml:mo></mml:mrow></mml:mover><mml:mrow><mml:mi>t</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mrow><mml:mi mathvariant="normal">M</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">C</mml:mi></mml:mrow><mml:mo>,</mml:mo><mml:mi>y</mml:mi></mml:mrow></mml:msubsup><mml:mo>=</mml:mo><mml:mtext> </mml:mtext><mml:mfrac><mml:mrow><mml:msubsup><mml:mi>θ</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mrow><mml:mi mathvariant="normal">M</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">C</mml:mi></mml:mrow><mml:mo>,</mml:mo><mml:mi>y</mml:mi></mml:mrow></mml:msubsup><mml:mo>−</mml:mo><mml:mtext> </mml:mtext><mml:msubsup><mml:mi>θ</mml:mi><mml:mrow><mml:mi>t</mml:mi></mml:mrow><mml:mrow><mml:mrow><mml:mi mathvariant="normal">M</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">C</mml:mi></mml:mrow><mml:mo>,</mml:mo><mml:mi>y</mml:mi></mml:mrow></mml:msubsup></mml:mrow><mml:mrow><mml:mi>d</mml:mi><mml:mi>t</mml:mi></mml:mrow></mml:mfrac><mml:mspace width="thinmathspace"/><mml:mspace width="thinmathspace"/><mml:mrow><mml:mo>,</mml:mo></mml:mrow><mml:mspace width="thinmathspace"/><mml:mspace width="thinmathspace"/><mml:msubsup><mml:mover><mml:mi>θ</mml:mi><mml:mrow><mml:mo>˙</mml:mo></mml:mrow></mml:mover><mml:mrow><mml:mi>t</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mrow><mml:mi mathvariant="normal">M</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">C</mml:mi></mml:mrow><mml:mo>,</mml:mo><mml:mi>x</mml:mi></mml:mrow></mml:msubsup><mml:mo>=</mml:mo><mml:mtext> </mml:mtext><mml:mfrac><mml:mrow><mml:msubsup><mml:mi>θ</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mrow><mml:mi mathvariant="normal">M</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">C</mml:mi></mml:mrow><mml:mo>,</mml:mo><mml:mi>x</mml:mi></mml:mrow></mml:msubsup><mml:mo>−</mml:mo><mml:mtext> </mml:mtext><mml:msubsup><mml:mi>θ</mml:mi><mml:mrow><mml:mi>t</mml:mi></mml:mrow><mml:mrow><mml:mrow><mml:mi mathvariant="normal">M</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">C</mml:mi></mml:mrow><mml:mo>,</mml:mo><mml:mi>x</mml:mi></mml:mrow></mml:msubsup></mml:mrow><mml:mrow><mml:mi>d</mml:mi><mml:mi>t</mml:mi></mml:mrow></mml:mfrac></mml:mrow></mml:math></disp-formula><disp-formula id="equ34">,<mml:math id="m34"><mml:mrow><mml:mrow><mml:mover><mml:mi>θ</mml:mi><mml:mo>¨</mml:mo></mml:mover></mml:mrow><mml:msubsup><mml:mtext> </mml:mtext><mml:mrow><mml:mi>t</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mrow><mml:mi mathvariant="normal">M</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">C</mml:mi></mml:mrow><mml:mo>,</mml:mo><mml:mi>y</mml:mi></mml:mrow></mml:msubsup><mml:mo>=</mml:mo><mml:mtext> </mml:mtext><mml:mfrac><mml:mrow><mml:msubsup><mml:mover><mml:mi>θ</mml:mi><mml:mrow><mml:mo>˙</mml:mo></mml:mrow></mml:mover><mml:mrow><mml:mi>t</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mrow><mml:mi mathvariant="normal">M</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">C</mml:mi></mml:mrow><mml:mo>,</mml:mo><mml:mi>y</mml:mi></mml:mrow></mml:msubsup><mml:mtext> </mml:mtext><mml:mo>−</mml:mo><mml:mtext> </mml:mtext><mml:msubsup><mml:mover><mml:mi>θ</mml:mi><mml:mrow><mml:mo>˙</mml:mo></mml:mrow></mml:mover><mml:mrow><mml:mi>t</mml:mi></mml:mrow><mml:mrow><mml:mrow><mml:mi mathvariant="normal">M</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">C</mml:mi></mml:mrow><mml:mo>,</mml:mo><mml:mi>y</mml:mi></mml:mrow></mml:msubsup></mml:mrow><mml:mrow><mml:mi>d</mml:mi><mml:mi>t</mml:mi></mml:mrow></mml:mfrac><mml:mspace width="thinmathspace"/><mml:mspace width="thinmathspace"/><mml:mrow><mml:mo>,</mml:mo></mml:mrow><mml:mspace width="thinmathspace"/><mml:mspace width="thinmathspace"/><mml:mrow><mml:mover><mml:mi>θ</mml:mi><mml:mo>¨</mml:mo></mml:mover></mml:mrow><mml:msubsup><mml:mtext> </mml:mtext><mml:mrow><mml:mi>t</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mrow><mml:mi mathvariant="normal">M</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">C</mml:mi></mml:mrow><mml:mo>,</mml:mo><mml:mi>x</mml:mi></mml:mrow></mml:msubsup><mml:mo>=</mml:mo><mml:mtext> </mml:mtext><mml:mfrac><mml:mrow><mml:msubsup><mml:mover><mml:mi>θ</mml:mi><mml:mrow><mml:mo>˙</mml:mo></mml:mrow></mml:mover><mml:mrow><mml:mi>t</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mrow><mml:mi mathvariant="normal">M</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">C</mml:mi></mml:mrow><mml:mo>,</mml:mo><mml:mi>x</mml:mi></mml:mrow></mml:msubsup><mml:mtext> </mml:mtext><mml:mo>−</mml:mo><mml:mtext> </mml:mtext><mml:msubsup><mml:mover><mml:mi>θ</mml:mi><mml:mrow><mml:mo>˙</mml:mo></mml:mrow></mml:mover><mml:mrow><mml:mi>t</mml:mi></mml:mrow><mml:mrow><mml:mrow><mml:mi mathvariant="normal">M</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">C</mml:mi></mml:mrow><mml:mo>,</mml:mo><mml:mi>x</mml:mi></mml:mrow></mml:msubsup></mml:mrow><mml:mrow><mml:mi>d</mml:mi><mml:mi>t</mml:mi></mml:mrow></mml:mfrac></mml:mrow></mml:math></disp-formula></p><p>In a next step, we compute the motion command that should be sent by the platform. Note that the platform is placed at a height <inline-formula><mml:math id="inf255"><mml:mi>h</mml:mi></mml:math></inline-formula> below the head. Therefore, tilting the platform by an angle <inline-formula><mml:math id="inf256"><mml:mi>θ</mml:mi></mml:math></inline-formula> induces a linear displacement of the head corresponding to <inline-formula><mml:math id="inf257"><mml:mo>-</mml:mo><mml:mi>h</mml:mi><mml:mo>∙</mml:mo><mml:mi>θ</mml:mi><mml:mo>∙</mml:mo><mml:mfrac bevelled="true"><mml:mrow><mml:mi>π</mml:mi></mml:mrow><mml:mrow><mml:mn>180</mml:mn></mml:mrow></mml:mfrac></mml:math></inline-formula> . Therefore, a linear displacement is added to the platform’s motion to compensate for this. Next, we limit the platform’s acceleration, velocity, and position commands to ensure that they remain within the limit of the actuators. For this purpose, we define the following function <inline-formula><mml:math id="inf258"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mtext> </mml:mtext><mml:msub><mml:mi>f</mml:mi><mml:mrow><mml:mi>λ</mml:mi><mml:mo>,</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mrow><mml:mi mathvariant="normal">m</mml:mi><mml:mi mathvariant="normal">a</mml:mi><mml:mi mathvariant="normal">x</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mi>x</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mstyle></mml:math></inline-formula>:<disp-formula id="equ35"><mml:math id="m35"><mml:mrow><mml:mrow><mml:mo>{</mml:mo><mml:mtable columnspacing="1em" rowspacing="4pt"><mml:mtr><mml:mtd><mml:mtext> </mml:mtext><mml:mi mathvariant="normal">i</mml:mi><mml:mi mathvariant="normal">f</mml:mi><mml:mtext> </mml:mtext><mml:mrow><mml:mo>|</mml:mo><mml:mi mathvariant="normal">x</mml:mi><mml:mo>|</mml:mo></mml:mrow><mml:mo>≤</mml:mo><mml:mi>λ</mml:mi><mml:mo>⋅</mml:mo><mml:msub><mml:mi mathvariant="normal">x</mml:mi><mml:mrow><mml:mi mathvariant="normal">m</mml:mi><mml:mi mathvariant="normal">a</mml:mi><mml:mi mathvariant="normal">x</mml:mi></mml:mrow></mml:msub><mml:mtext> </mml:mtext><mml:mo>,</mml:mo><mml:mtext> </mml:mtext><mml:mtext> </mml:mtext><mml:mtext> </mml:mtext><mml:mtext> </mml:mtext><mml:mtext> </mml:mtext><mml:mtext> </mml:mtext><mml:mtext> </mml:mtext><mml:mtext> </mml:mtext><mml:mtext> </mml:mtext><mml:mtext> </mml:mtext><mml:mtext> </mml:mtext><mml:mtext> </mml:mtext><mml:mtext> </mml:mtext><mml:mtext> </mml:mtext><mml:mtext> </mml:mtext><mml:mtext> </mml:mtext><mml:mtext> </mml:mtext><mml:mtext> </mml:mtext><mml:mtext> </mml:mtext><mml:mtext> </mml:mtext><mml:mtext> </mml:mtext><mml:msub><mml:mi mathvariant="normal">f</mml:mi><mml:mrow><mml:mi>λ</mml:mi><mml:mo>,</mml:mo><mml:msub><mml:mi mathvariant="normal">x</mml:mi><mml:mrow><mml:mi mathvariant="normal">m</mml:mi><mml:mi mathvariant="normal">a</mml:mi><mml:mi mathvariant="normal">x</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mi mathvariant="normal">x</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mtext> </mml:mtext><mml:mi mathvariant="normal">x</mml:mi><mml:mtext> </mml:mtext><mml:mtext> </mml:mtext><mml:mtext> </mml:mtext><mml:mtext> </mml:mtext><mml:mtext> </mml:mtext><mml:mtext> </mml:mtext><mml:mtext> </mml:mtext><mml:mtext> </mml:mtext><mml:mtext> </mml:mtext><mml:mtext> </mml:mtext><mml:mtext> </mml:mtext><mml:mtext> </mml:mtext><mml:mtext> </mml:mtext><mml:mtext> </mml:mtext><mml:mtext> </mml:mtext><mml:mtext> </mml:mtext><mml:mtext> </mml:mtext><mml:mtext> </mml:mtext><mml:mtext> </mml:mtext><mml:mtext> </mml:mtext><mml:mtext> </mml:mtext><mml:mtext> </mml:mtext><mml:mtext> </mml:mtext><mml:mtext> </mml:mtext><mml:mtext> </mml:mtext><mml:mtext> </mml:mtext><mml:mtext> </mml:mtext><mml:mtext> </mml:mtext><mml:mtext> </mml:mtext><mml:mtext> </mml:mtext><mml:mtext> </mml:mtext><mml:mtext> </mml:mtext><mml:mtext> </mml:mtext><mml:mtext> </mml:mtext><mml:mtext> </mml:mtext><mml:mtext> </mml:mtext><mml:mtext> </mml:mtext><mml:mtext> </mml:mtext><mml:mtext> </mml:mtext><mml:mtext> </mml:mtext><mml:mtext> </mml:mtext><mml:mtext> </mml:mtext><mml:mtext> </mml:mtext><mml:mtext> </mml:mtext><mml:mtext> </mml:mtext><mml:mtext> </mml:mtext><mml:mtext> </mml:mtext><mml:mtext> </mml:mtext><mml:mtext> </mml:mtext><mml:mtext> </mml:mtext><mml:mtext> </mml:mtext><mml:mtext> </mml:mtext><mml:mtext> </mml:mtext><mml:mtext> </mml:mtext><mml:mtext> </mml:mtext><mml:mtext> </mml:mtext><mml:mtext> </mml:mtext><mml:mtext> </mml:mtext><mml:mtext> </mml:mtext><mml:mtext> </mml:mtext><mml:mtext> </mml:mtext><mml:mtext> </mml:mtext><mml:mtext> </mml:mtext><mml:mtext> </mml:mtext><mml:mtext> </mml:mtext><mml:mtext> </mml:mtext><mml:mtext> </mml:mtext><mml:mtext> </mml:mtext></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mi mathvariant="normal">e</mml:mi><mml:mi mathvariant="normal">l</mml:mi><mml:mi mathvariant="normal">s</mml:mi><mml:mi mathvariant="normal">e</mml:mi><mml:mtext> </mml:mtext><mml:mtext> </mml:mtext><mml:mi mathvariant="normal">i</mml:mi><mml:mi mathvariant="normal">f</mml:mi><mml:mtext> </mml:mtext><mml:mrow><mml:mo>|</mml:mo><mml:mi mathvariant="normal">x</mml:mi><mml:mo>|</mml:mo></mml:mrow><mml:mo>≤</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mn>2</mml:mn><mml:mo>−</mml:mo><mml:mi>λ</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>⋅</mml:mo><mml:msub><mml:mi mathvariant="normal">x</mml:mi><mml:mrow><mml:mi mathvariant="normal">m</mml:mi><mml:mi mathvariant="normal">a</mml:mi><mml:mi mathvariant="normal">x</mml:mi></mml:mrow></mml:msub><mml:mtext> </mml:mtext><mml:mo>,</mml:mo><mml:mtext> </mml:mtext><mml:mtext> </mml:mtext><mml:mtext> </mml:mtext><mml:msub><mml:mi mathvariant="normal">f</mml:mi><mml:mrow><mml:mi>λ</mml:mi><mml:mo>,</mml:mo><mml:msub><mml:mi mathvariant="normal">x</mml:mi><mml:mrow><mml:mi mathvariant="normal">m</mml:mi><mml:mi mathvariant="normal">a</mml:mi><mml:mi mathvariant="normal">x</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mi mathvariant="normal">x</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:msub><mml:mi mathvariant="normal">x</mml:mi><mml:mrow><mml:mi mathvariant="normal">m</mml:mi><mml:mi mathvariant="normal">a</mml:mi><mml:mi mathvariant="normal">x</mml:mi></mml:mrow></mml:msub><mml:mo>.</mml:mo><mml:mi mathvariant="normal">s</mml:mi><mml:mi mathvariant="normal">i</mml:mi><mml:mi mathvariant="normal">g</mml:mi><mml:mi mathvariant="normal">n</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi mathvariant="normal">x</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>.</mml:mo><mml:mrow><mml:mo>[</mml:mo><mml:mrow><mml:mrow><mml:mo>|</mml:mo><mml:mrow><mml:mi mathvariant="normal">x</mml:mi><mml:mrow><mml:mo>/</mml:mo></mml:mrow><mml:msub><mml:mi mathvariant="normal">x</mml:mi><mml:mrow><mml:mi mathvariant="normal">m</mml:mi><mml:mi mathvariant="normal">a</mml:mi><mml:mi mathvariant="normal">x</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>|</mml:mo></mml:mrow><mml:mo>−</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mrow><mml:mn>4.</mml:mn><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:mi>λ</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mfrac><mml:mo>.</mml:mo><mml:msup><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mi mathvariant="normal">x</mml:mi><mml:mrow><mml:mo>/</mml:mo></mml:mrow><mml:msub><mml:mi mathvariant="normal">x</mml:mi><mml:mrow><mml:mi mathvariant="normal">m</mml:mi><mml:mi mathvariant="normal">a</mml:mi><mml:mi mathvariant="normal">x</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mo>−</mml:mo><mml:mi>λ</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:mrow><mml:mo>]</mml:mo></mml:mrow></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mtext> </mml:mtext><mml:mi mathvariant="normal">i</mml:mi><mml:mi mathvariant="normal">f</mml:mi><mml:mtext> </mml:mtext><mml:mrow><mml:mo>|</mml:mo><mml:mi mathvariant="normal">x</mml:mi><mml:mo>|</mml:mo></mml:mrow><mml:mo>&gt;</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mn>2</mml:mn><mml:mo>−</mml:mo><mml:mi>λ</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>⋅</mml:mo><mml:msub><mml:mi mathvariant="normal">x</mml:mi><mml:mrow><mml:mi mathvariant="normal">m</mml:mi><mml:mi mathvariant="normal">a</mml:mi><mml:mi mathvariant="normal">x</mml:mi></mml:mrow></mml:msub><mml:mtext> </mml:mtext><mml:mo>,</mml:mo><mml:mtext> </mml:mtext><mml:mtext> </mml:mtext><mml:mtext> </mml:mtext><mml:mtext> </mml:mtext><mml:mtext> </mml:mtext><mml:mtext> </mml:mtext><mml:mtext> </mml:mtext><mml:mtext> </mml:mtext><mml:mtext> </mml:mtext><mml:mtext> </mml:mtext><mml:msub><mml:mi mathvariant="normal">f</mml:mi><mml:mrow><mml:mi>λ</mml:mi><mml:mo>,</mml:mo><mml:msub><mml:mi mathvariant="normal">x</mml:mi><mml:mrow><mml:mi mathvariant="normal">m</mml:mi><mml:mi mathvariant="normal">a</mml:mi><mml:mi mathvariant="normal">x</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mi mathvariant="normal">x</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mtext> </mml:mtext><mml:mi mathvariant="normal">s</mml:mi><mml:mi mathvariant="normal">i</mml:mi><mml:mi mathvariant="normal">g</mml:mi><mml:mi mathvariant="normal">n</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi mathvariant="normal">x</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>.</mml:mo><mml:msub><mml:mi mathvariant="normal">x</mml:mi><mml:mrow><mml:mi mathvariant="normal">m</mml:mi><mml:mi mathvariant="normal">a</mml:mi><mml:mi mathvariant="normal">x</mml:mi></mml:mrow></mml:msub></mml:mtd></mml:mtr></mml:mtable><mml:mo>}</mml:mo></mml:mrow></mml:mrow></mml:math></disp-formula></p><p>This function is designed so that if the input <inline-formula><mml:math id="inf259"><mml:mi>x</mml:mi></mml:math></inline-formula> increases continuously, for example, <inline-formula><mml:math id="inf260"><mml:mi>x</mml:mi><mml:mfenced separators="|"><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:mfenced><mml:mo>=</mml:mo><mml:mi>t</mml:mi></mml:math></inline-formula>, then the output <inline-formula><mml:math id="inf261"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mtext> </mml:mtext><mml:msub><mml:mi>f</mml:mi><mml:mrow><mml:mi>λ</mml:mi><mml:mo>,</mml:mo><mml:mrow><mml:msub><mml:mi mathvariant="normal">x</mml:mi><mml:mrow><mml:mi mathvariant="normal">m</mml:mi><mml:mi mathvariant="normal">a</mml:mi><mml:mi mathvariant="normal">x</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>x</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mstyle></mml:math></inline-formula> will be identical to <inline-formula><mml:math id="inf262"><mml:mi>x</mml:mi></mml:math></inline-formula> until <inline-formula><mml:math id="inf263"><mml:mi>x</mml:mi></mml:math></inline-formula> reaches a threshold <inline-formula><mml:math id="inf264"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>λ</mml:mi><mml:mo>⋅</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mrow><mml:mrow><mml:mi mathvariant="normal">m</mml:mi><mml:mi mathvariant="normal">a</mml:mi><mml:mi mathvariant="normal">x</mml:mi></mml:mrow></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula> . After this, the output will decelerate continuously (<inline-formula><mml:math id="inf265"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mfrac><mml:mrow><mml:mi>d</mml:mi><mml:mtext> </mml:mtext><mml:msub><mml:mi>f</mml:mi><mml:mrow><mml:mi>λ</mml:mi><mml:mo>,</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mrow><mml:mrow><mml:mi mathvariant="normal">m</mml:mi><mml:mi mathvariant="normal">a</mml:mi><mml:mi mathvariant="normal">x</mml:mi></mml:mrow></mml:mrow></mml:msub></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>x</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mrow><mml:mi>d</mml:mi><mml:mi>t</mml:mi></mml:mrow></mml:mfrac><mml:mo>=</mml:mo><mml:mrow><mml:mi mathvariant="normal">c</mml:mi><mml:mi mathvariant="normal">o</mml:mi><mml:mi mathvariant="normal">n</mml:mi><mml:mi mathvariant="normal">s</mml:mi><mml:mi mathvariant="normal">t</mml:mi><mml:mi mathvariant="normal">a</mml:mi><mml:mi mathvariant="normal">n</mml:mi><mml:mi mathvariant="normal">t</mml:mi></mml:mrow></mml:mrow></mml:mstyle></mml:math></inline-formula>) until it stops at a value <inline-formula><mml:math id="inf266"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>x</mml:mi><mml:mrow><mml:mrow><mml:mi mathvariant="normal">m</mml:mi><mml:mi mathvariant="normal">a</mml:mi><mml:mi mathvariant="normal">x</mml:mi></mml:mrow></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula> . We fed the platform’s acceleration, velocity, and position command through this function, as follows:<disp-formula id="equ36"><mml:math id="m36"><mml:mrow><mml:msubsup><mml:mi>a</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mrow><mml:mi mathvariant="normal">m</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">o</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">o</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">g</mml:mi></mml:mrow><mml:mo>,</mml:mo><mml:mi>x</mml:mi></mml:mrow></mml:msubsup><mml:mo>=</mml:mo><mml:mtext> </mml:mtext><mml:mtext> </mml:mtext><mml:msub><mml:mi>f</mml:mi><mml:mrow><mml:mi>λ</mml:mi><mml:mo>,</mml:mo><mml:msub><mml:mi>a</mml:mi><mml:mrow><mml:mrow><mml:mi mathvariant="normal">m</mml:mi><mml:mi mathvariant="normal">a</mml:mi><mml:mi mathvariant="normal">x</mml:mi></mml:mrow></mml:mrow></mml:msub></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msubsup><mml:mi>a</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mrow><mml:mi mathvariant="normal">M</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">C</mml:mi></mml:mrow><mml:mo>,</mml:mo><mml:mi>x</mml:mi></mml:mrow></mml:msubsup><mml:mo>+</mml:mo><mml:mi>h</mml:mi><mml:mo>⋅</mml:mo><mml:msubsup><mml:mover><mml:mi>θ</mml:mi><mml:mrow><mml:mo>¨</mml:mo></mml:mrow></mml:mover><mml:mrow><mml:mi>t</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mrow><mml:mi mathvariant="normal">M</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">C</mml:mi></mml:mrow><mml:mo>,</mml:mo><mml:mi>x</mml:mi></mml:mrow></mml:msubsup><mml:mo>⋅</mml:mo><mml:mfrac><mml:mi>π</mml:mi><mml:mn>180</mml:mn></mml:mfrac><mml:mtext> </mml:mtext></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></disp-formula><disp-formula id="equ37"><mml:math id="m37"><mml:mrow><mml:msubsup><mml:mi>v</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mrow><mml:mi mathvariant="normal">m</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">o</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">o</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">g</mml:mi></mml:mrow><mml:mo>,</mml:mo><mml:mi>x</mml:mi></mml:mrow></mml:msubsup><mml:mo>=</mml:mo><mml:mtext> </mml:mtext><mml:mtext> </mml:mtext><mml:msub><mml:mi>f</mml:mi><mml:mrow><mml:mi>λ</mml:mi><mml:mo>,</mml:mo><mml:msub><mml:mi>v</mml:mi><mml:mrow><mml:mrow><mml:mi mathvariant="normal">m</mml:mi><mml:mi mathvariant="normal">a</mml:mi><mml:mi mathvariant="normal">x</mml:mi></mml:mrow></mml:mrow></mml:msub></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msubsup><mml:mi>v</mml:mi><mml:mrow><mml:mi>t</mml:mi></mml:mrow><mml:mrow><mml:mrow><mml:mi mathvariant="normal">m</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">o</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">o</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">g</mml:mi></mml:mrow><mml:mo>,</mml:mo><mml:mi>x</mml:mi></mml:mrow></mml:msubsup><mml:mo>+</mml:mo><mml:mi>d</mml:mi><mml:mi>t</mml:mi><mml:mo>.</mml:mo><mml:msubsup><mml:mi>a</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mrow><mml:mi mathvariant="normal">m</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">o</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">o</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">g</mml:mi></mml:mrow><mml:mo>,</mml:mo><mml:mi>x</mml:mi></mml:mrow></mml:msubsup></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></disp-formula><disp-formula id="equ38"><mml:math id="m38"><mml:mrow><mml:msubsup><mml:mi>x</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mrow><mml:mi mathvariant="normal">m</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">o</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">o</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">g</mml:mi></mml:mrow><mml:mo>,</mml:mo><mml:mi>x</mml:mi></mml:mrow></mml:msubsup><mml:mo>=</mml:mo><mml:mtext> </mml:mtext><mml:mtext> </mml:mtext><mml:msub><mml:mi>f</mml:mi><mml:mrow><mml:mi>λ</mml:mi><mml:mo>,</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mrow><mml:mrow><mml:mi mathvariant="normal">m</mml:mi><mml:mi mathvariant="normal">a</mml:mi><mml:mi mathvariant="normal">x</mml:mi></mml:mrow></mml:mrow></mml:msub></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msubsup><mml:mi>x</mml:mi><mml:mrow><mml:mi>t</mml:mi></mml:mrow><mml:mrow><mml:mrow><mml:mi mathvariant="normal">m</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">o</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">o</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">g</mml:mi></mml:mrow><mml:mo>,</mml:mo><mml:mi>x</mml:mi></mml:mrow></mml:msubsup><mml:mo>+</mml:mo><mml:mi>d</mml:mi><mml:mi>t</mml:mi><mml:mo>.</mml:mo><mml:msubsup><mml:mi>x</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mrow><mml:mi mathvariant="normal">m</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">o</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">o</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">g</mml:mi></mml:mrow><mml:mo>,</mml:mo><mml:mi>x</mml:mi></mml:mrow></mml:msubsup></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></disp-formula></p><p>The same operation takes place for the <italic>y</italic> component of the acceleration, as well as for the platform velocity and position. The process is repeated for the tilt command itself.</p><p>We set <inline-formula><mml:math id="inf267"><mml:mi>λ</mml:mi><mml:mo>=</mml:mo><mml:mn>0.75</mml:mn></mml:math></inline-formula> and <inline-formula><mml:math id="inf268"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>a</mml:mi><mml:mrow><mml:mrow><mml:mi mathvariant="normal">m</mml:mi><mml:mi mathvariant="normal">a</mml:mi><mml:mi mathvariant="normal">x</mml:mi></mml:mrow></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mn>4</mml:mn><mml:mtext> </mml:mtext><mml:mrow><mml:mi mathvariant="normal">m</mml:mi><mml:mrow><mml:mo>/</mml:mo></mml:mrow><mml:msup><mml:mi mathvariant="normal">s</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:mrow></mml:mstyle></mml:math></inline-formula> , <inline-formula><mml:math id="inf269"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>v</mml:mi><mml:mrow><mml:mrow><mml:mi mathvariant="normal">m</mml:mi><mml:mi mathvariant="normal">a</mml:mi><mml:mi mathvariant="normal">x</mml:mi></mml:mrow></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mn>0.4</mml:mn><mml:mtext> </mml:mtext><mml:mrow><mml:mi mathvariant="normal">m</mml:mi><mml:mrow><mml:mo>/</mml:mo></mml:mrow><mml:mi mathvariant="normal">s</mml:mi></mml:mrow></mml:mrow></mml:mstyle></mml:math></inline-formula>, <inline-formula><mml:math id="inf270"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>x</mml:mi><mml:mrow><mml:mrow><mml:mi mathvariant="normal">m</mml:mi><mml:mi mathvariant="normal">a</mml:mi><mml:mi mathvariant="normal">x</mml:mi></mml:mrow></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mn>0.23</mml:mn><mml:mtext> </mml:mtext><mml:mrow><mml:mi mathvariant="normal">m</mml:mi></mml:mrow></mml:mrow></mml:mstyle></mml:math></inline-formula>, <inline-formula><mml:math id="inf271"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mover><mml:mi>θ</mml:mi><mml:mrow><mml:mo>¨</mml:mo></mml:mrow></mml:mover><mml:mrow><mml:mrow><mml:mi mathvariant="normal">m</mml:mi><mml:mi mathvariant="normal">a</mml:mi><mml:mi mathvariant="normal">x</mml:mi></mml:mrow></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mn>300</mml:mn><mml:mtext> </mml:mtext><mml:mi mathvariant="normal">d</mml:mi><mml:mi mathvariant="normal">e</mml:mi><mml:mi mathvariant="normal">g</mml:mi><mml:mrow><mml:mo>/</mml:mo></mml:mrow><mml:mi mathvariant="normal">s</mml:mi></mml:mrow></mml:mstyle></mml:math></inline-formula>, <inline-formula><mml:math id="inf272"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mover><mml:mi>θ</mml:mi><mml:mrow><mml:mo>˙</mml:mo></mml:mrow></mml:mover><mml:mrow><mml:mrow><mml:mi mathvariant="normal">m</mml:mi><mml:mi mathvariant="normal">a</mml:mi><mml:mi mathvariant="normal">x</mml:mi></mml:mrow></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mn>30</mml:mn><mml:mtext> </mml:mtext><mml:mi mathvariant="normal">d</mml:mi><mml:mi mathvariant="normal">e</mml:mi><mml:mi mathvariant="normal">g</mml:mi><mml:mrow><mml:mo>/</mml:mo></mml:mrow><mml:mi mathvariant="normal">s</mml:mi></mml:mrow></mml:mstyle></mml:math></inline-formula> and <inline-formula><mml:math id="inf273"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>θ</mml:mi><mml:mrow><mml:mi>m</mml:mi><mml:mi>a</mml:mi><mml:mi>x</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mn>10</mml:mn><mml:mtext> </mml:mtext><mml:mrow><mml:mi mathvariant="normal">d</mml:mi><mml:mi mathvariant="normal">e</mml:mi><mml:mi mathvariant="normal">g</mml:mi></mml:mrow></mml:mrow></mml:mstyle></mml:math></inline-formula>, slightly below the platform’s and actuator physical limits. This ensured that the platform’s motion matched exactly the MC algorithm’s output, as long as it stayed within 75% of the platform’s range. Otherwise, the function <inline-formula><mml:math id="inf274"><mml:mi>f</mml:mi></mml:math></inline-formula> ensured a smooth trajectory and, as detailed in Steps 8–10, a feedback mechanism was used to update the participant position in the VR environment, so as to guarantee that visual motion always matched inertial motion.</p></sec><sec id="s8-7" sec-type="appendix"><title>Step 7</title><p>The motor commands for tilt and translation are being sent to the platform:<disp-formula id="equ39"><mml:math id="m39"><mml:mfenced close="]" open="[" separators="|"><mml:mrow><mml:msubsup><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi mathvariant="normal">m</mml:mi><mml:mi mathvariant="normal">o</mml:mi><mml:mi mathvariant="normal">o</mml:mi><mml:mi mathvariant="normal">g</mml:mi></mml:mrow></mml:msubsup><mml:mo>,</mml:mo><mml:mi> </mml:mi><mml:msubsup><mml:mrow><mml:mi>y</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi mathvariant="normal">m</mml:mi><mml:mi mathvariant="normal">o</mml:mi><mml:mi mathvariant="normal">o</mml:mi><mml:mi mathvariant="normal">g</mml:mi></mml:mrow></mml:msubsup><mml:mo>,</mml:mo><mml:mi> </mml:mi><mml:msubsup><mml:mrow><mml:mi>θ</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi mathvariant="normal">m</mml:mi><mml:mi mathvariant="normal">o</mml:mi><mml:mi mathvariant="normal">o</mml:mi><mml:mi mathvariant="normal">g</mml:mi><mml:mo>,</mml:mo><mml:mi>x</mml:mi></mml:mrow></mml:msubsup><mml:mo>,</mml:mo><mml:mi> </mml:mi><mml:msubsup><mml:mrow><mml:mi>θ</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi mathvariant="normal">m</mml:mi><mml:mi mathvariant="normal">o</mml:mi><mml:mi mathvariant="normal">o</mml:mi><mml:mi mathvariant="normal">g</mml:mi><mml:mo>,</mml:mo><mml:mi>y</mml:mi></mml:mrow></mml:msubsup></mml:mrow></mml:mfenced></mml:math></disp-formula></p></sec><sec id="s8-8" sec-type="appendix"><title>Step 8</title><p>Because of Step 6, the total GIA of the platform may differ from what is commanded by the MC algorithm. To detect and discrepancy, we computed the GIA provided by the platform:<disp-formula id="equ40"><mml:math id="m40"><mml:msubsup><mml:mrow><mml:mi>v</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi mathvariant="normal">a</mml:mi><mml:mi mathvariant="normal">c</mml:mi><mml:mi mathvariant="normal">t</mml:mi><mml:mi mathvariant="normal">u</mml:mi><mml:mi mathvariant="normal">a</mml:mi><mml:mi mathvariant="normal">l</mml:mi><mml:mo>,</mml:mo><mml:mi>x</mml:mi></mml:mrow></mml:msubsup><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mfenced separators="|"><mml:mrow><mml:msubsup><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi mathvariant="normal">m</mml:mi><mml:mi mathvariant="normal">o</mml:mi><mml:mi mathvariant="normal">o</mml:mi><mml:mi mathvariant="normal">g</mml:mi></mml:mrow></mml:msubsup><mml:mo>-</mml:mo><mml:mi> </mml:mi><mml:msubsup><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">m</mml:mi><mml:mi mathvariant="normal">o</mml:mi><mml:mi mathvariant="normal">o</mml:mi><mml:mi mathvariant="normal">g</mml:mi></mml:mrow></mml:msubsup></mml:mrow></mml:mfenced></mml:mrow><mml:mrow><mml:mi>d</mml:mi><mml:mi>t</mml:mi></mml:mrow></mml:mfrac><mml:mi> </mml:mi><mml:mo>,</mml:mo><mml:mi> </mml:mi><mml:mi> </mml:mi><mml:msubsup><mml:mrow><mml:mi>v</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi mathvariant="normal">a</mml:mi><mml:mi mathvariant="normal">c</mml:mi><mml:mi mathvariant="normal">t</mml:mi><mml:mi mathvariant="normal">u</mml:mi><mml:mi mathvariant="normal">a</mml:mi><mml:mi mathvariant="normal">l</mml:mi><mml:mo>,</mml:mo><mml:mi>y</mml:mi></mml:mrow></mml:msubsup><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mfenced separators="|"><mml:mrow><mml:msubsup><mml:mrow><mml:mi>y</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi mathvariant="normal">m</mml:mi><mml:mi mathvariant="normal">o</mml:mi><mml:mi mathvariant="normal">o</mml:mi><mml:mi mathvariant="normal">g</mml:mi></mml:mrow></mml:msubsup><mml:mo>-</mml:mo><mml:mi> </mml:mi><mml:msubsup><mml:mrow><mml:mi>y</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">m</mml:mi><mml:mi mathvariant="normal">o</mml:mi><mml:mi mathvariant="normal">o</mml:mi><mml:mi mathvariant="normal">g</mml:mi></mml:mrow></mml:msubsup></mml:mrow></mml:mfenced></mml:mrow><mml:mrow><mml:mi>d</mml:mi><mml:mi>t</mml:mi></mml:mrow></mml:mfrac></mml:math></disp-formula><disp-formula id="equ41"><mml:math id="m41"><mml:msubsup><mml:mrow><mml:mi>a</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi mathvariant="normal">a</mml:mi><mml:mi mathvariant="normal">c</mml:mi><mml:mi mathvariant="normal">t</mml:mi><mml:mi mathvariant="normal">u</mml:mi><mml:mi mathvariant="normal">a</mml:mi><mml:mi mathvariant="normal">l</mml:mi><mml:mo>,</mml:mo><mml:mi>x</mml:mi></mml:mrow></mml:msubsup><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mfenced separators="|"><mml:mrow><mml:msubsup><mml:mrow><mml:mi>v</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi mathvariant="normal">a</mml:mi><mml:mi mathvariant="normal">c</mml:mi><mml:mi mathvariant="normal">t</mml:mi><mml:mi mathvariant="normal">u</mml:mi><mml:mi mathvariant="normal">a</mml:mi><mml:mi mathvariant="normal">l</mml:mi><mml:mo>,</mml:mo><mml:mi>x</mml:mi></mml:mrow></mml:msubsup><mml:mo>-</mml:mo><mml:mi> </mml:mi><mml:msubsup><mml:mrow><mml:mi>v</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">a</mml:mi><mml:mi mathvariant="normal">c</mml:mi><mml:mi mathvariant="normal">t</mml:mi><mml:mi mathvariant="normal">u</mml:mi><mml:mi mathvariant="normal">a</mml:mi><mml:mi mathvariant="normal">l</mml:mi><mml:mo>,</mml:mo><mml:mi>x</mml:mi></mml:mrow></mml:msubsup></mml:mrow></mml:mfenced></mml:mrow><mml:mrow><mml:mi>d</mml:mi><mml:mi>t</mml:mi></mml:mrow></mml:mfrac><mml:mi> </mml:mi><mml:mo>,</mml:mo><mml:mi> </mml:mi><mml:mi> </mml:mi><mml:msubsup><mml:mrow><mml:mi>a</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi mathvariant="normal">a</mml:mi><mml:mi mathvariant="normal">c</mml:mi><mml:mi mathvariant="normal">t</mml:mi><mml:mi mathvariant="normal">u</mml:mi><mml:mi mathvariant="normal">a</mml:mi><mml:mi mathvariant="normal">l</mml:mi><mml:mo>,</mml:mo><mml:mi>y</mml:mi></mml:mrow></mml:msubsup><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mfenced separators="|"><mml:mrow><mml:msubsup><mml:mrow><mml:mi>v</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi mathvariant="normal">a</mml:mi><mml:mi mathvariant="normal">c</mml:mi><mml:mi mathvariant="normal">t</mml:mi><mml:mi mathvariant="normal">u</mml:mi><mml:mi mathvariant="normal">a</mml:mi><mml:mi mathvariant="normal">l</mml:mi><mml:mo>,</mml:mo><mml:mi>y</mml:mi></mml:mrow></mml:msubsup><mml:mo>-</mml:mo><mml:mi> </mml:mi><mml:msubsup><mml:mrow><mml:mi>y</mml:mi></mml:mrow><mml:mrow><mml:mi>v</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">a</mml:mi><mml:mi mathvariant="normal">c</mml:mi><mml:mi mathvariant="normal">t</mml:mi><mml:mi mathvariant="normal">u</mml:mi><mml:mi mathvariant="normal">a</mml:mi><mml:mi mathvariant="normal">l</mml:mi><mml:mo>,</mml:mo><mml:mi>y</mml:mi></mml:mrow></mml:msubsup></mml:mrow></mml:mfenced></mml:mrow><mml:mrow><mml:mi>d</mml:mi><mml:mi>t</mml:mi></mml:mrow></mml:mfrac></mml:math></disp-formula><disp-formula id="equ42"><mml:math id="m42"><mml:mrow><mml:mi>G</mml:mi><mml:mi>I</mml:mi><mml:msubsup><mml:mi>A</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mrow><mml:mi mathvariant="normal">a</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">c</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">t</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">u</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">a</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">l</mml:mi></mml:mrow><mml:mo>,</mml:mo><mml:mi>x</mml:mi></mml:mrow></mml:msubsup><mml:mo>=</mml:mo><mml:msubsup><mml:mi>a</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mrow><mml:mi mathvariant="normal">a</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">c</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">t</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">u</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">a</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">l</mml:mi></mml:mrow><mml:mo>,</mml:mo><mml:mi>x</mml:mi></mml:mrow></mml:msubsup><mml:mo>+</mml:mo><mml:mrow><mml:mi mathvariant="normal">g</mml:mi></mml:mrow><mml:mo>⋅</mml:mo><mml:mi>sin</mml:mi><mml:mo>⁡</mml:mo><mml:msubsup><mml:mi>θ</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mrow><mml:mi mathvariant="normal">m</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">o</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">o</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">g</mml:mi></mml:mrow><mml:mo>,</mml:mo><mml:mi>x</mml:mi></mml:mrow></mml:msubsup><mml:mo>−</mml:mo><mml:mi>h</mml:mi><mml:mo>⋅</mml:mo><mml:msubsup><mml:mrow><mml:mover><mml:mi>θ</mml:mi><mml:mo>¨</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>t</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mrow><mml:mi mathvariant="normal">m</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">o</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">o</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">g</mml:mi></mml:mrow><mml:mo>,</mml:mo><mml:mi>x</mml:mi></mml:mrow></mml:msubsup><mml:mo>⋅</mml:mo><mml:mfrac><mml:mi>π</mml:mi><mml:mn>180</mml:mn></mml:mfrac></mml:mrow></mml:math></disp-formula><disp-formula id="equ43"><mml:math id="m43"><mml:mrow><mml:mi>G</mml:mi><mml:mi>I</mml:mi><mml:msubsup><mml:mi>A</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mrow><mml:mi mathvariant="normal">a</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">c</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">t</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">u</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">a</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">l</mml:mi></mml:mrow><mml:mo>,</mml:mo><mml:mi>y</mml:mi></mml:mrow></mml:msubsup><mml:mo>=</mml:mo><mml:msubsup><mml:mi>a</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mrow><mml:mi mathvariant="normal">a</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">c</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">t</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">u</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">a</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">l</mml:mi></mml:mrow><mml:mo>,</mml:mo><mml:mi>y</mml:mi></mml:mrow></mml:msubsup><mml:mo>+</mml:mo><mml:mrow><mml:mi mathvariant="normal">g</mml:mi></mml:mrow><mml:mo>⋅</mml:mo><mml:mi>sin</mml:mi><mml:mo>⁡</mml:mo><mml:msubsup><mml:mi>θ</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mrow><mml:mi mathvariant="normal">m</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">o</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">o</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">g</mml:mi></mml:mrow><mml:mo>,</mml:mo><mml:mi>y</mml:mi></mml:mrow></mml:msubsup><mml:mo>−</mml:mo><mml:mi>h</mml:mi><mml:mo>⋅</mml:mo><mml:msubsup><mml:mrow><mml:mover><mml:mi>θ</mml:mi><mml:mo>¨</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>t</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mrow><mml:mi mathvariant="normal">m</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">o</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">o</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">g</mml:mi></mml:mrow><mml:mo>,</mml:mo><mml:mi>y</mml:mi></mml:mrow></mml:msubsup><mml:mo>⋅</mml:mo><mml:mfrac><mml:mi>π</mml:mi><mml:mn>180</mml:mn></mml:mfrac></mml:mrow></mml:math></disp-formula></p></sec><sec id="s8-9" sec-type="appendix"><title>Step 9</title><p>We transform platform’s GIA into participant’s reference frame:<disp-formula id="equ44"><mml:math id="m44"><mml:msubsup><mml:mrow><mml:mi>G</mml:mi><mml:mi>I</mml:mi><mml:mi>A</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi mathvariant="normal">s</mml:mi><mml:mi mathvariant="normal">u</mml:mi><mml:mi mathvariant="normal">b</mml:mi><mml:mo>,</mml:mo><mml:mi>x</mml:mi></mml:mrow></mml:msubsup><mml:mo>=</mml:mo><mml:msubsup><mml:mrow><mml:mi>G</mml:mi><mml:mi>I</mml:mi><mml:mi>A</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi mathvariant="normal">a</mml:mi><mml:mi mathvariant="normal">c</mml:mi><mml:mi mathvariant="normal">t</mml:mi><mml:mi mathvariant="normal">u</mml:mi><mml:mi mathvariant="normal">a</mml:mi><mml:mi mathvariant="normal">l</mml:mi><mml:mo>,</mml:mo><mml:mi>x</mml:mi></mml:mrow></mml:msubsup><mml:mo>∙</mml:mo><mml:mrow><mml:mrow><mml:mi mathvariant="normal">cos</mml:mi></mml:mrow><mml:mo>⁡</mml:mo><mml:mrow><mml:msubsup><mml:mrow><mml:mi>φ</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">m</mml:mi><mml:mi mathvariant="normal">o</mml:mi><mml:mi mathvariant="normal">o</mml:mi><mml:mi mathvariant="normal">g</mml:mi></mml:mrow></mml:msubsup><mml:mo>+</mml:mo></mml:mrow></mml:mrow><mml:msubsup><mml:mrow><mml:mi>G</mml:mi><mml:mi>I</mml:mi><mml:mi>A</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi mathvariant="normal">a</mml:mi><mml:mi mathvariant="normal">c</mml:mi><mml:mi mathvariant="normal">t</mml:mi><mml:mi mathvariant="normal">u</mml:mi><mml:mi mathvariant="normal">a</mml:mi><mml:mi mathvariant="normal">l</mml:mi><mml:mo>,</mml:mo><mml:mi>y</mml:mi></mml:mrow></mml:msubsup><mml:mo>∙</mml:mo><mml:mrow><mml:mrow><mml:mi mathvariant="normal">sin</mml:mi></mml:mrow><mml:mo>⁡</mml:mo><mml:mrow><mml:msubsup><mml:mrow><mml:mi>φ</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">m</mml:mi><mml:mi mathvariant="normal">o</mml:mi><mml:mi mathvariant="normal">o</mml:mi><mml:mi mathvariant="normal">g</mml:mi></mml:mrow></mml:msubsup></mml:mrow></mml:mrow></mml:math></disp-formula><disp-formula id="equ45"><mml:math id="m45"><mml:msubsup><mml:mrow><mml:mi>G</mml:mi><mml:mi>I</mml:mi><mml:mi>A</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi mathvariant="normal">s</mml:mi><mml:mi mathvariant="normal">u</mml:mi><mml:mi mathvariant="normal">b</mml:mi><mml:mo>,</mml:mo><mml:mi>y</mml:mi></mml:mrow></mml:msubsup><mml:mo>=</mml:mo><mml:mo>-</mml:mo><mml:msubsup><mml:mrow><mml:mi>G</mml:mi><mml:mi>I</mml:mi><mml:mi>A</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi mathvariant="normal">a</mml:mi><mml:mi mathvariant="normal">c</mml:mi><mml:mi mathvariant="normal">t</mml:mi><mml:mi mathvariant="normal">u</mml:mi><mml:mi mathvariant="normal">a</mml:mi><mml:mi mathvariant="normal">l</mml:mi><mml:mo>,</mml:mo><mml:mi>x</mml:mi></mml:mrow></mml:msubsup><mml:mo>∙</mml:mo><mml:mrow><mml:mrow><mml:mi mathvariant="normal">sin</mml:mi></mml:mrow><mml:mo>⁡</mml:mo><mml:mrow><mml:msubsup><mml:mrow><mml:mi>φ</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">m</mml:mi><mml:mi mathvariant="normal">o</mml:mi><mml:mi mathvariant="normal">o</mml:mi><mml:mi mathvariant="normal">g</mml:mi></mml:mrow></mml:msubsup><mml:mo>+</mml:mo></mml:mrow></mml:mrow><mml:msubsup><mml:mrow><mml:mi>G</mml:mi><mml:mi>I</mml:mi><mml:mi>A</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi mathvariant="normal">a</mml:mi><mml:mi mathvariant="normal">c</mml:mi><mml:mi mathvariant="normal">t</mml:mi><mml:mi mathvariant="normal">u</mml:mi><mml:mi mathvariant="normal">a</mml:mi><mml:mi mathvariant="normal">l</mml:mi><mml:mo>,</mml:mo><mml:mi>y</mml:mi></mml:mrow></mml:msubsup><mml:mo>∙</mml:mo><mml:mrow><mml:mrow><mml:mi mathvariant="normal">cos</mml:mi></mml:mrow><mml:mo>⁡</mml:mo><mml:mrow><mml:msubsup><mml:mrow><mml:mi>φ</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">m</mml:mi><mml:mi mathvariant="normal">o</mml:mi><mml:mi mathvariant="normal">o</mml:mi><mml:mi mathvariant="normal">g</mml:mi></mml:mrow></mml:msubsup></mml:mrow></mml:mrow></mml:math></disp-formula></p><p>Also, the error <inline-formula><mml:math id="inf275"><mml:msup><mml:mrow><mml:mi>e</mml:mi></mml:mrow><mml:mrow><mml:mi>s</mml:mi><mml:mi>u</mml:mi><mml:mi>b</mml:mi></mml:mrow></mml:msup></mml:math></inline-formula> between the obtained GIA and desired GIA (from Step 3) is calculated, and fed through the same sigmoid function (<inline-formula><mml:math id="inf276"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>λ</mml:mi><mml:mo>=</mml:mo><mml:mtext> </mml:mtext><mml:mn>0.75</mml:mn><mml:mo>,</mml:mo><mml:mtext> </mml:mtext><mml:mi>G</mml:mi><mml:mi>I</mml:mi><mml:msub><mml:mi>A</mml:mi><mml:mrow><mml:mi mathvariant="normal">m</mml:mi><mml:mi mathvariant="normal">a</mml:mi><mml:mi mathvariant="normal">x</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mn>1</mml:mn><mml:mtext> </mml:mtext><mml:mfrac><mml:mi mathvariant="normal">m</mml:mi><mml:msup><mml:mi mathvariant="normal">s</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:mfrac></mml:mrow></mml:mstyle></mml:math></inline-formula>) discussed previously, to avoid computational instability in the case of a big mismatch:<disp-formula id="equ46"><mml:math id="m46"><mml:mrow><mml:msubsup><mml:mi>e</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>x</mml:mi></mml:mrow></mml:msubsup><mml:mo>=</mml:mo><mml:mtext> </mml:mtext><mml:msub><mml:mi>f</mml:mi><mml:mrow><mml:mi>λ</mml:mi><mml:mo>,</mml:mo><mml:mi>G</mml:mi><mml:mi>I</mml:mi><mml:msub><mml:mi>A</mml:mi><mml:mrow><mml:mrow><mml:mi mathvariant="normal">m</mml:mi><mml:mi mathvariant="normal">a</mml:mi><mml:mi mathvariant="normal">x</mml:mi></mml:mrow></mml:mrow></mml:msub></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>G</mml:mi><mml:mi>I</mml:mi><mml:msubsup><mml:mi>A</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mrow><mml:mi mathvariant="normal">s</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">u</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">b</mml:mi></mml:mrow><mml:mo>,</mml:mo><mml:mi>x</mml:mi></mml:mrow></mml:msubsup><mml:mo>−</mml:mo><mml:mtext> </mml:mtext><mml:msubsup><mml:mi>a</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mrow><mml:mi mathvariant="normal">s</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">u</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">b</mml:mi></mml:mrow><mml:mo>,</mml:mo><mml:mi>x</mml:mi></mml:mrow></mml:msubsup></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></disp-formula><disp-formula id="equ47"><mml:math id="m47"><mml:mrow><mml:msubsup><mml:mi>e</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>y</mml:mi></mml:mrow></mml:msubsup><mml:mo>=</mml:mo><mml:mtext> </mml:mtext><mml:msub><mml:mi>f</mml:mi><mml:mrow><mml:mi>λ</mml:mi><mml:mo>,</mml:mo><mml:mi>G</mml:mi><mml:mi>I</mml:mi><mml:msub><mml:mi>A</mml:mi><mml:mrow><mml:mrow><mml:mi mathvariant="normal">m</mml:mi><mml:mi mathvariant="normal">a</mml:mi><mml:mi mathvariant="normal">x</mml:mi></mml:mrow></mml:mrow></mml:msub></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>G</mml:mi><mml:mi>I</mml:mi><mml:msubsup><mml:mi>A</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mrow><mml:mi mathvariant="normal">s</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">u</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">b</mml:mi></mml:mrow><mml:mo>,</mml:mo><mml:mi>y</mml:mi></mml:mrow></mml:msubsup><mml:mo>−</mml:mo><mml:mtext> </mml:mtext><mml:msubsup><mml:mi>a</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mrow><mml:mi mathvariant="normal">s</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">u</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">b</mml:mi></mml:mrow><mml:mo>,</mml:mo><mml:mi>y</mml:mi></mml:mrow></mml:msubsup></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></disp-formula></p></sec><sec id="s8-10" sec-type="appendix"><title>Step 10</title><p>The GIA error is now used to update the system in the case of a mismatch. First, it is transformed into VR coordinates. Then, the velocity and position in VR coordinates are recomputed based on the joystick input and on the error signal:<disp-formula id="equ48"><mml:math id="m48"><mml:msubsup><mml:mrow><mml:mi>e</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi mathvariant="normal">V</mml:mi><mml:mi mathvariant="normal">R</mml:mi><mml:mo>,</mml:mo><mml:mi>x</mml:mi></mml:mrow></mml:msubsup><mml:mo>=</mml:mo><mml:msubsup><mml:mrow><mml:mi>e</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi mathvariant="normal">s</mml:mi><mml:mi mathvariant="normal">u</mml:mi><mml:mi mathvariant="normal">b</mml:mi><mml:mo>,</mml:mo><mml:mi>x</mml:mi></mml:mrow></mml:msubsup><mml:mo>∙</mml:mo><mml:mrow><mml:mrow><mml:mi mathvariant="normal">cos</mml:mi></mml:mrow><mml:mo>⁡</mml:mo><mml:mrow><mml:msubsup><mml:mrow><mml:mi>φ</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">V</mml:mi><mml:mi mathvariant="normal">R</mml:mi></mml:mrow></mml:msubsup></mml:mrow></mml:mrow><mml:mo>-</mml:mo><mml:mi> </mml:mi><mml:msubsup><mml:mrow><mml:mi>e</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi mathvariant="normal">s</mml:mi><mml:mi mathvariant="normal">u</mml:mi><mml:mi mathvariant="normal">b</mml:mi><mml:mo>,</mml:mo><mml:mi>y</mml:mi></mml:mrow></mml:msubsup><mml:mo>∙</mml:mo><mml:mrow><mml:mrow><mml:mi mathvariant="normal">sin</mml:mi></mml:mrow><mml:mo>⁡</mml:mo><mml:mrow><mml:msubsup><mml:mrow><mml:mi>φ</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">V</mml:mi><mml:mi mathvariant="normal">R</mml:mi></mml:mrow></mml:msubsup></mml:mrow></mml:mrow></mml:math></disp-formula><disp-formula id="equ49"><mml:math id="m49"><mml:msubsup><mml:mrow><mml:mi>e</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi mathvariant="normal">V</mml:mi><mml:mi mathvariant="normal">R</mml:mi><mml:mo>,</mml:mo><mml:mi>y</mml:mi></mml:mrow></mml:msubsup><mml:mo>=</mml:mo><mml:msubsup><mml:mrow><mml:mi>e</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi mathvariant="normal">s</mml:mi><mml:mi mathvariant="normal">u</mml:mi><mml:mi mathvariant="normal">b</mml:mi><mml:mo>,</mml:mo><mml:mi>x</mml:mi></mml:mrow></mml:msubsup><mml:mo>∙</mml:mo><mml:mrow><mml:mrow><mml:mi mathvariant="normal">sin</mml:mi></mml:mrow><mml:mo>⁡</mml:mo><mml:mrow><mml:msubsup><mml:mrow><mml:mi>φ</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">V</mml:mi><mml:mi mathvariant="normal">R</mml:mi></mml:mrow></mml:msubsup></mml:mrow></mml:mrow><mml:mo>+</mml:mo><mml:mi> </mml:mi><mml:msubsup><mml:mrow><mml:mi>e</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi mathvariant="normal">s</mml:mi><mml:mi mathvariant="normal">u</mml:mi><mml:mi mathvariant="normal">b</mml:mi><mml:mo>,</mml:mo><mml:mi>y</mml:mi></mml:mrow></mml:msubsup><mml:mo>∙</mml:mo><mml:mrow><mml:mrow><mml:mi mathvariant="normal">cos</mml:mi></mml:mrow><mml:mo>⁡</mml:mo><mml:mrow><mml:msubsup><mml:mrow><mml:mi>φ</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">V</mml:mi><mml:mi mathvariant="normal">R</mml:mi></mml:mrow></mml:msubsup></mml:mrow></mml:mrow></mml:math></disp-formula><disp-formula id="equ50"><mml:math id="m50"><mml:mrow><mml:msubsup><mml:mrow><mml:mover><mml:mi>v</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>t</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mrow><mml:mi mathvariant="normal">V</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">R</mml:mi></mml:mrow><mml:mo>,</mml:mo><mml:mi>x</mml:mi></mml:mrow></mml:msubsup><mml:mo>=</mml:mo><mml:msubsup><mml:mrow><mml:mover><mml:mi>v</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow><mml:mrow><mml:mrow><mml:mi mathvariant="normal">V</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">R</mml:mi></mml:mrow><mml:mo>,</mml:mo><mml:mi>x</mml:mi></mml:mrow></mml:msubsup><mml:mo>+</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msubsup><mml:mi>a</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mrow><mml:mi mathvariant="normal">V</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">R</mml:mi></mml:mrow><mml:mo>,</mml:mo><mml:mi>x</mml:mi></mml:mrow></mml:msubsup><mml:mo>+</mml:mo><mml:msubsup><mml:mi>e</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mrow><mml:mi mathvariant="normal">V</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">R</mml:mi></mml:mrow><mml:mo>,</mml:mo><mml:mi>x</mml:mi></mml:mrow></mml:msubsup></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>⋅</mml:mo><mml:mi>d</mml:mi><mml:mi>t</mml:mi></mml:mrow></mml:math></disp-formula><disp-formula id="equ51"><mml:math id="m51"><mml:mrow><mml:msubsup><mml:mrow><mml:mover><mml:mi>v</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>t</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mrow><mml:mi mathvariant="normal">V</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">R</mml:mi></mml:mrow><mml:mo>,</mml:mo><mml:mi>y</mml:mi></mml:mrow></mml:msubsup><mml:mo>=</mml:mo><mml:msubsup><mml:mrow><mml:mover><mml:mi>v</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow><mml:mrow><mml:mrow><mml:mi mathvariant="normal">V</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">R</mml:mi></mml:mrow><mml:mo>,</mml:mo><mml:mi>y</mml:mi></mml:mrow></mml:msubsup><mml:mo>+</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msubsup><mml:mi>a</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mrow><mml:mi mathvariant="normal">V</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">R</mml:mi></mml:mrow><mml:mo>,</mml:mo><mml:mi>y</mml:mi></mml:mrow></mml:msubsup><mml:mo>+</mml:mo><mml:msubsup><mml:mi>e</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mrow><mml:mi mathvariant="normal">V</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">R</mml:mi></mml:mrow><mml:mo>,</mml:mo><mml:mi>y</mml:mi></mml:mrow></mml:msubsup></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>⋅</mml:mo><mml:mi>d</mml:mi><mml:mi>t</mml:mi></mml:mrow></mml:math></disp-formula><disp-formula id="equ52"><mml:math id="m52"><mml:mrow><mml:msubsup><mml:mi>x</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mrow><mml:mi mathvariant="normal">V</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">R</mml:mi></mml:mrow><mml:mo>,</mml:mo><mml:mi>x</mml:mi></mml:mrow></mml:msubsup><mml:mo>=</mml:mo><mml:msubsup><mml:mi>x</mml:mi><mml:mrow><mml:mi>t</mml:mi></mml:mrow><mml:mrow><mml:mrow><mml:mi mathvariant="normal">V</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">R</mml:mi></mml:mrow><mml:mo>,</mml:mo><mml:mi>x</mml:mi></mml:mrow></mml:msubsup><mml:mo>+</mml:mo><mml:msubsup><mml:mrow><mml:mover><mml:mi>v</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>t</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mrow><mml:mi mathvariant="normal">V</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">R</mml:mi></mml:mrow><mml:mo>,</mml:mo><mml:mi>x</mml:mi></mml:mrow></mml:msubsup><mml:mo>⋅</mml:mo><mml:mi>d</mml:mi><mml:mi>t</mml:mi></mml:mrow></mml:math></disp-formula><disp-formula id="equ53"><mml:math id="m53"><mml:mrow><mml:msubsup><mml:mi>x</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mrow><mml:mi mathvariant="normal">V</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">R</mml:mi></mml:mrow><mml:mo>,</mml:mo><mml:mi>y</mml:mi></mml:mrow></mml:msubsup><mml:mo>=</mml:mo><mml:msubsup><mml:mi>x</mml:mi><mml:mrow><mml:mi>t</mml:mi></mml:mrow><mml:mrow><mml:mrow><mml:mi mathvariant="normal">V</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">R</mml:mi></mml:mrow><mml:mo>,</mml:mo><mml:mi>y</mml:mi></mml:mrow></mml:msubsup><mml:mo>+</mml:mo><mml:msubsup><mml:mrow><mml:mover><mml:mi>v</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>t</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mrow><mml:mi mathvariant="normal">V</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">R</mml:mi></mml:mrow><mml:mo>,</mml:mo><mml:mi>y</mml:mi></mml:mrow></mml:msubsup><mml:mo>⋅</mml:mo><mml:mi>d</mml:mi><mml:mi>t</mml:mi></mml:mrow></mml:math></disp-formula><disp-formula id="equ54"><mml:math id="m54"><mml:msubsup><mml:mrow><mml:mi>φ</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi mathvariant="normal">V</mml:mi><mml:mi mathvariant="normal">R</mml:mi></mml:mrow></mml:msubsup><mml:mo>=</mml:mo><mml:msubsup><mml:mrow><mml:mi>φ</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">V</mml:mi><mml:mi mathvariant="normal">R</mml:mi></mml:mrow></mml:msubsup><mml:mo>+</mml:mo><mml:msubsup><mml:mrow><mml:mi>ω</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">V</mml:mi><mml:mi mathvariant="normal">R</mml:mi></mml:mrow></mml:msubsup><mml:mo>⋅</mml:mo><mml:mi>d</mml:mi><mml:mi>t</mml:mi></mml:math></disp-formula></p><p>Note that the error signal is also fed into the acceleration in VR coordinates (see Step 3). Ideally, linear acceleration should be computed based on the updated velocity value at time <inline-formula><mml:math id="inf277"><mml:mi>t</mml:mi></mml:math></inline-formula>, that is:<disp-formula id="equ55"><mml:math id="m55"><mml:mrow><mml:msubsup><mml:mi>α</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mrow><mml:mi mathvariant="normal">V</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">R</mml:mi></mml:mrow><mml:mo>,</mml:mo><mml:mi>x</mml:mi></mml:mrow></mml:msubsup><mml:mo>=</mml:mo><mml:mtext> </mml:mtext><mml:mfrac><mml:mrow><mml:msubsup><mml:mi>v</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mrow><mml:mi mathvariant="normal">V</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">R</mml:mi></mml:mrow><mml:mo>,</mml:mo><mml:mi>x</mml:mi></mml:mrow></mml:msubsup><mml:mo>−</mml:mo><mml:msubsup><mml:mrow><mml:mover><mml:mi>v</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow><mml:mrow><mml:mrow><mml:mi mathvariant="normal">V</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">R</mml:mi></mml:mrow><mml:mo>,</mml:mo><mml:mi>x</mml:mi></mml:mrow></mml:msubsup></mml:mrow><mml:mrow><mml:mi>d</mml:mi><mml:mi>t</mml:mi></mml:mrow></mml:mfrac></mml:mrow></mml:math></disp-formula></p><p>However, we found that this led to numerical instability, and instead we introduced a time constant <inline-formula><mml:math id="inf278"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>τ</mml:mi><mml:mrow><mml:mrow><mml:mi mathvariant="normal">M</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">C</mml:mi></mml:mrow></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mn>1</mml:mn><mml:mrow><mml:mi mathvariant="normal">s</mml:mi></mml:mrow></mml:mrow></mml:mstyle></mml:math></inline-formula> in the computation, as shown in Step 3.</p></sec></sec></app><app id="appendix-2"><title>Appendix 2</title><table-wrap id="app2table1" position="float"><label>Appendix 2—table 1.</label><caption><title>Average radial (top) and angular (bottom) behavioral response gains across participants, for groups of time constant <italic>τ</italic> magnitudes (mean ± SEM).</title></caption><table frame="hsides" rules="groups"><thead><tr><th align="center" colspan="4" valign="bottom">Radial bias table</th></tr><tr><th align="left" valign="bottom"/><th align="center" valign="bottom">Vestibular</th><th align="center" valign="bottom">Visual</th><th align="center" valign="bottom">Combined</th></tr></thead><tbody><tr><td align="left" valign="bottom"><italic>τ</italic>: [0.34–1.53]</td><td align="center" valign="bottom">0.649 ± 0.056</td><td align="center" valign="bottom">0.818 ± 0.057</td><td align="center" valign="bottom">0.786 ± 0.055</td></tr><tr><td align="left" valign="bottom"><italic>τ</italic>: [1.53–2.16]</td><td align="center" valign="bottom">0.733 ± 0.063</td><td align="center" valign="bottom">0.871 ± 0.059</td><td align="center" valign="bottom">0.836 ± 0.056</td></tr><tr><td align="left" valign="bottom"><italic>τ</italic>: [2.16–8.89]</td><td align="center" valign="bottom">0.902 ± 0.077</td><td align="center" valign="bottom">0.944 ± 0.061</td><td align="center" valign="bottom">0.917 ± 0.058</td></tr><tr><th align="center" colspan="4" valign="bottom">Angular bias table</th></tr><tr><th align="left" valign="bottom"/><th align="center" valign="bottom">Vestibular</th><th align="center" valign="bottom">Visual</th><th align="center" valign="bottom">Combined</th></tr><tr><td align="left" valign="bottom"><italic>τ</italic>: [0.34–1.53]</td><td align="center" valign="bottom">0.731 ± 0.053</td><td align="center" valign="bottom">0.919 ± 0.036</td><td align="center" valign="bottom">0.902 ± 0.032</td></tr><tr><td align="left" valign="bottom"><italic>τ</italic>: [1.53–2.16]</td><td align="center" valign="bottom">0.770 ± 0.060</td><td align="center" valign="bottom">0.984 ± 0.038</td><td align="center" valign="bottom">0.944 ± 0.029</td></tr><tr><td align="left" valign="bottom"><italic>τ</italic>: [2.16–8.89]</td><td align="center" valign="bottom">0.878 ± 0.061</td><td align="center" valign="bottom">1.024 ± 0.040</td><td align="center" valign="bottom">1.012 ± 0.033</td></tr></tbody></table></table-wrap><table-wrap id="app2table2" position="float"><label>Appendix 2—table 2.</label><caption><title>Pearson’s correlation coefficient (<italic>r</italic>) and corresponding p-value (p) for radial (top) and angular (bottom) correlation between residual error and the time constant <italic>τ</italic> across participants.</title><p>Mean Pearson’s <italic>r</italic> ± SEM: radial component – vestibular: 0.52±0.02, visual: 0.36±0.03, combined: 0.37±0.03; angular component – vestibular: 0.23±0.02, visual: 0.23±0.03, combined: 0.26±0.03.</p></caption><table frame="hsides" rules="groups"><thead><tr><th align="center" colspan="4" valign="bottom">Radial correlations</th></tr><tr><th align="center" valign="bottom"/><th align="center" valign="bottom">Vestibular</th><th align="center" valign="bottom">Visual</th><th align="center" valign="bottom">Combined</th></tr></thead><tbody><tr><td align="left" valign="bottom">Subject 1</td><td align="center" valign="bottom"><italic>r</italic> = 0.585, p = 4.2·10<sup>–45</sup></td><td align="center" valign="bottom"><italic>r</italic> = 0.502, p = 1.2·10<sup>–37</sup></td><td align="center" valign="bottom"><italic>r</italic> = 0.617, p = 1.0·10<sup>–59</sup></td></tr><tr><td align="left" valign="bottom">Subject 2</td><td align="center" valign="bottom"><italic>r</italic> = 0.622, p = 5.5·10<sup>–43</sup></td><td align="center" valign="bottom"><italic>r</italic> = 0.338, p = 7.4·10<sup>–12</sup></td><td align="center" valign="bottom"><italic>r</italic> = 0.377, p = 2.9·10<sup>–14</sup></td></tr><tr><td align="left" valign="bottom">Subject 3</td><td align="center" valign="bottom"><italic>r</italic> = 0.433, p = 3.5·10<sup>–25</sup></td><td align="center" valign="bottom"><italic>r</italic> = 0.280, p = 2.7·10<sup>–11</sup></td><td align="center" valign="bottom"><italic>r</italic> = 0.374, p = 8.7·10<sup>–20</sup></td></tr><tr><td align="left" valign="bottom">Subject 4</td><td align="center" valign="bottom"><italic>r</italic> = 0.492, p = 9.1·10<sup>–31</sup></td><td align="center" valign="bottom"><italic>r</italic> = 0.494, p = 3.1·10<sup>–31</sup></td><td align="center" valign="bottom"><italic>r</italic> = 0.350, p = 2.1·10<sup>–15</sup></td></tr><tr><td align="left" valign="bottom">Subject 5</td><td align="center" valign="bottom"><italic>r</italic> = 0.411, p = 4.4·10<sup>–17</sup></td><td align="center" valign="bottom"><italic>r</italic> = 0.314, p = 3.4·10<sup>–10</sup></td><td align="center" valign="bottom"><italic>r</italic> = 0.360, p = 3.7·10<sup>–13</sup></td></tr><tr><td align="left" valign="bottom">Subject 6</td><td align="center" valign="bottom"><italic>r</italic> = 0.601, p = 2.0·10<sup>–58</sup></td><td align="center" valign="bottom"><italic>r</italic> = 0.233, p = 1.2·10<sup>–08</sup></td><td align="center" valign="bottom"><italic>r</italic> = 0.233, p = 1.2·10<sup>–08</sup></td></tr><tr><td align="left" valign="bottom">Subject 7</td><td align="center" valign="bottom"><italic>r</italic> = 0.606, p = 1.6·10<sup>–44</sup></td><td align="center" valign="bottom"><italic>r</italic> = 0.522, p = 1.5·10<sup>–31</sup></td><td align="center" valign="bottom"><italic>r</italic> = 0.474, p = 1.1·10<sup>–25</sup></td></tr><tr><td align="left" valign="bottom">Subject 8</td><td align="center" valign="bottom"><italic>r</italic> = 0.477, p = 9.6·10<sup>–34</sup></td><td align="center" valign="bottom"><italic>r</italic> = 0.255, p = 5.7·10<sup>–10</sup></td><td align="center" valign="bottom"><italic>r</italic> = 0.294, p = 4.6·10<sup>–13</sup></td></tr><tr><td align="left" valign="bottom">Subject 9</td><td align="center" valign="bottom"><italic>r</italic> = 0.478, p = 1.0·10<sup>–22</sup></td><td align="center" valign="bottom"><italic>r</italic> = 0.517, p = 7.9·10<sup>–27</sup></td><td align="center" valign="bottom"><italic>r</italic> = 0.523, p = 6.3·10<sup>–28</sup></td></tr><tr><td align="left" valign="bottom">Subject 10</td><td align="center" valign="bottom"><italic>r</italic> = 0.573, p = 7.2·10<sup>–39</sup></td><td align="center" valign="bottom"><italic>r</italic> = 0.497, p = 4.7·10<sup>–28</sup></td><td align="center" valign="bottom"><italic>r</italic> = 0.576, p = 3.5·10<sup>–39</sup></td></tr><tr><td align="left" valign="bottom">Subject 11</td><td align="center" valign="bottom"><italic>r</italic> = 0.375, p = 5.9·10<sup>–16</sup></td><td align="center" valign="bottom"><italic>r</italic> = 0.224, p = 2.1·10<sup>–06</sup></td><td align="center" valign="bottom"><italic>r</italic> = 0.144, p = 0.002</td></tr><tr><td align="left" valign="bottom">Subject 12</td><td align="center" valign="bottom"><italic>r</italic> = 0.522, p = 2.1·10<sup>–39</sup></td><td align="center" valign="bottom"><italic>r</italic> = 0.341, p = 1.3·10<sup>–16</sup></td><td align="center" valign="bottom"><italic>r</italic> = 0.319, p = 1.1·10<sup>–14</sup></td></tr><tr><td align="left" valign="bottom">Subject 13</td><td align="center" valign="bottom"><italic>r</italic> = 0.512, p = 1.1·10<sup>–38</sup></td><td align="center" valign="bottom"><italic>r</italic> = 0.385, p = 1.4·10<sup>–21</sup></td><td align="center" valign="bottom"><italic>r</italic> = 0.401, p = 4.7·10<sup>–23</sup></td></tr><tr><td align="left" valign="bottom">Subject 14</td><td align="center" valign="bottom">r = 0.461, p = 8.3·10<sup>–30</sup></td><td align="center" valign="bottom"><italic>r</italic> = 0.241, p = 1.3·10<sup>–08</sup></td><td align="center" valign="bottom"><italic>r</italic> = 0.276, p = 7.0·10<sup>–11</sup></td></tr><tr><td align="left" valign="bottom">Subject 15</td><td align="center" valign="bottom">r = 0.703, p = 1.7·10<sup>–61</sup></td><td align="center" valign="bottom"><italic>r</italic> = 0.214, p = 1.1·10<sup>–05</sup></td><td align="center" valign="bottom"><italic>r</italic> = 0.213, p = 1.3·10<sup>–05</sup></td></tr><tr><th align="center" colspan="4" valign="bottom">Angular correlations</th></tr><tr><th align="left" valign="bottom"/><th align="center" valign="bottom">Vestibular</th><th align="center" valign="bottom">Visual</th><th align="center" valign="bottom">Combined</th></tr><tr><td align="left" valign="bottom">Subject 1</td><td align="center" valign="bottom"><italic>r</italic> = 0.254, p = 1.9·10<sup>–08</sup></td><td align="center" valign="bottom"><italic>r</italic> = 0.302, p = 1.8·10<sup>–13</sup></td><td align="center" valign="bottom"><italic>r</italic> = 0.437, p = 2.3·10<sup>–27</sup></td></tr><tr><td align="left" valign="bottom">Subject 2</td><td align="center" valign="bottom"><italic>r</italic> = 0.156, p = 0.002</td><td align="center" valign="bottom"><italic>r</italic> = 0.287, p = 8.6·10<sup>–09</sup></td><td align="center" valign="bottom"><italic>r</italic> = 0.270, p = 9.2·10<sup>–08</sup></td></tr><tr><td align="left" valign="bottom">Subject 3</td><td align="center" valign="bottom"><italic>r</italic> = 0.301, p = 2.2·10<sup>–12</sup></td><td align="center" valign="bottom"><italic>r</italic> = 0.274, p = 7.3·10<sup>–11</sup></td><td align="center" valign="bottom"><italic>r</italic> = 0.351, p = 1.7·10<sup>–17</sup></td></tr><tr><td align="left" valign="bottom">Subject 4</td><td align="center" valign="bottom"><italic>r</italic> = 0.315, p = 1.3·10<sup>–12</sup></td><td align="center" valign="bottom"><italic>r</italic> = 0.299, p = 1.7·10<sup>–11</sup></td><td align="center" valign="bottom"><italic>r</italic> = 0.343, p = 8.9·10<sup>–15</sup></td></tr><tr><td align="left" valign="bottom">Subject 5</td><td align="center" valign="bottom"><italic>r</italic> = 0.153, p = 0.003</td><td align="center" valign="bottom"><italic>r</italic> = 0.291, p = 6.7·10<sup>–09</sup></td><td align="center" valign="bottom"><italic>r</italic> = 0.387, p = 3.8·10<sup>–15</sup></td></tr><tr><td align="left" valign="bottom">Subject 6</td><td align="center" valign="bottom"><italic>r</italic> = 0.292, p = 5.9·10<sup>–13</sup></td><td align="center" valign="bottom"><italic>r</italic> = 0.121, p = 0.003</td><td align="center" valign="bottom"><italic>r</italic> = 0.224, p = 4.8·10<sup>–08</sup></td></tr><tr><td align="left" valign="bottom">Subject 7</td><td align="center" valign="bottom"><italic>r</italic> = 0.098, p = 0.042</td><td align="center" valign="bottom"><italic>r</italic> = 0.356, p = 2.4·10<sup>–14</sup></td><td align="center" valign="bottom"><italic>r</italic> = 0.275, p = 6.0·10<sup>–09</sup></td></tr><tr><td align="left" valign="bottom">Subject 8</td><td align="center" valign="bottom"><italic>r</italic> = 0.346, p = 2.0·10<sup>–17</sup></td><td align="center" valign="bottom"><italic>r</italic> = –0.004, p = 0.920</td><td align="center" valign="bottom"><italic>r</italic> = 0.005, p = 0.902</td></tr><tr><td align="left" valign="bottom">Subject 9</td><td align="center" valign="bottom"><italic>r</italic> = 0.093, p = 0.071</td><td align="center" valign="bottom"><italic>r</italic> = 0.349, p = 4.1·10<sup>–12</sup></td><td align="center" valign="bottom"><italic>r</italic> = 0.348, p = 3.1·10<sup>–12</sup></td></tr><tr><td align="left" valign="bottom">Subject 10</td><td align="center" valign="bottom"><italic>r</italic> = 0.294, p = 4.7·10<sup>–10</sup></td><td align="center" valign="bottom"><italic>r</italic> = 0.336, p = 9.6·10<sup>–13</sup></td><td align="center" valign="bottom"><italic>r</italic> = 0.235, p = 9.0·10<sup>–07</sup></td></tr><tr><td align="left" valign="bottom">Subject 11</td><td align="center" valign="bottom"><italic>r</italic> = 0.064, p = 0.183</td><td align="center" valign="bottom"><italic>r</italic> = –0.032, p = 0.507</td><td align="center" valign="bottom"><italic>r</italic> = 0.027, p = 0.575</td></tr><tr><td align="left" valign="bottom">Subject 12</td><td align="center" valign="bottom"><italic>r</italic> = 0.271, p = 1.2·10<sup>–10</sup></td><td align="center" valign="bottom"><italic>r</italic> = 0.278, p = 2.7·10<sup>–11</sup></td><td align="center" valign="bottom"><italic>r</italic> = 0.333, p = 5.6·10<sup>–16</sup></td></tr><tr><td align="left" valign="bottom">Subject 13</td><td align="center" valign="bottom"><italic>r</italic> = 0.238, p = 1.2·10<sup>–08</sup></td><td align="center" valign="bottom"><italic>r</italic> = 0.312, p = 2.5·10<sup>–14</sup></td><td align="center" valign="bottom"><italic>r</italic> = 0.255, p = 1.0·10<sup>–09</sup></td></tr><tr><td align="left" valign="bottom">Subject 14</td><td align="center" valign="bottom"><italic>r</italic> = 0.215, p = 4.3·10<sup>–07</sup></td><td align="center" valign="bottom"><italic>r</italic> = 0.138, p = 0.001</td><td align="center" valign="bottom"><italic>r</italic> = 0.217, p = 3.7·10<sup>–07</sup></td></tr><tr><td align="left" valign="bottom">Subject 15</td><td align="center" valign="bottom"><italic>r</italic> = 0.328, p = 1.2·10<sup>–11</sup></td><td align="center" valign="bottom"><italic>r</italic> = 0.134, p = 0.006</td><td align="center" valign="bottom"><italic>r</italic> = 0.137, p = 0.005</td></tr></tbody></table></table-wrap><table-wrap id="app2table3" position="float"><label>Appendix 2—table 3.</label><caption><title>Linear regression slope coefficients for radial (<italic>α</italic>, top) and angular (<italic>β</italic>, bottom) components of residual error against the time constant <italic>τ</italic> across participants.</title><p>Mean regression slope ± SEM: Radial (m/s) – vestibular: 0.62±0.06, visual: 0.28±0.03, combined: 0.29±0.03; angular (deg/s) – vestibular: 2.05±0.2, visual: 1.04±0.23, combined: 1.09±0.19.</p></caption><table frame="hsides" rules="groups"><thead><tr><th align="center" colspan="4" valign="bottom">Radial regression coeﬃcients (m/s)</th></tr><tr><th align="center" valign="bottom"/><th align="center" valign="bottom">Vestibular</th><th align="center" valign="bottom">Visual</th><th align="center" valign="bottom">Combined</th></tr></thead><tbody><tr><td align="left" valign="bottom">Subject 1</td><td align="center" valign="bottom"><italic>α</italic> = 0.775</td><td align="center" valign="bottom"><italic>α</italic> = 0.247</td><td align="center" valign="bottom"><italic>α</italic> = 0.337</td></tr><tr><td align="left" valign="bottom">Subject 2</td><td align="center" valign="bottom"><italic>α</italic> = 0.776</td><td align="center" valign="bottom"><italic>α</italic> = 0.464</td><td align="center" valign="bottom"><italic>α</italic> = 0.470</td></tr><tr><td align="left" valign="bottom">Subject 3</td><td align="center" valign="bottom"><italic>α</italic> = 0.255</td><td align="center" valign="bottom"><italic>α</italic> = 0.138</td><td align="center" valign="bottom"><italic>α</italic> = 0.157</td></tr><tr><td align="left" valign="bottom">Subject 4</td><td align="center" valign="bottom"><italic>α</italic> = 0.406</td><td align="center" valign="bottom"><italic>α</italic> = 0.138</td><td align="center" valign="bottom"><italic>α</italic> = 0.269</td></tr><tr><td align="left" valign="bottom">Subject 5</td><td align="center" valign="bottom"><italic>α</italic> = 1.009</td><td align="center" valign="bottom"><italic>α</italic> = 0.559</td><td align="center" valign="bottom"><italic>α</italic> = 0.487</td></tr><tr><td align="left" valign="bottom">Subject 6</td><td align="center" valign="bottom"><italic>α</italic> = 0.829</td><td align="center" valign="bottom"><italic>α</italic> = 0.151</td><td align="center" valign="bottom"><italic>α</italic> = 0.149</td></tr><tr><td align="left" valign="bottom">Subject 7</td><td align="center" valign="bottom"><italic>α</italic> = 0.512</td><td align="center" valign="bottom"><italic>α</italic> = 0.351</td><td align="center" valign="bottom"><italic>α</italic> = 0.330</td></tr><tr><td align="left" valign="bottom">Subject 8</td><td align="center" valign="bottom"><italic>α</italic> = 0.582</td><td align="center" valign="bottom"><italic>α</italic> = 0.245</td><td align="center" valign="bottom"><italic>α</italic> = 0.222</td></tr><tr><td align="left" valign="bottom">Subject 9</td><td align="center" valign="bottom"><italic>α</italic> = 0.321</td><td align="center" valign="bottom"><italic>α</italic> = 0.330</td><td align="center" valign="bottom"><italic>α</italic> = 0.311</td></tr><tr><td align="left" valign="bottom">Subject 10</td><td align="center" valign="bottom"><italic>α</italic> = 0.943</td><td align="center" valign="bottom"><italic>α</italic> = 0.365</td><td align="center" valign="bottom"><italic>α</italic> = 0.445</td></tr><tr><td align="left" valign="bottom">Subject 11</td><td align="center" valign="bottom"><italic>α</italic> = 0.522</td><td align="center" valign="bottom"><italic>α</italic> = 0.322</td><td align="center" valign="bottom"><italic>α</italic> = 0.177</td></tr><tr><td align="left" valign="bottom">Subject 12</td><td align="center" valign="bottom"><italic>α</italic> = 0.484</td><td align="center" valign="bottom"><italic>α</italic> = 0.166</td><td align="center" valign="bottom"><italic>α</italic> = 0.210</td></tr><tr><td align="left" valign="bottom">Subject 13</td><td align="center" valign="bottom"><italic>α</italic> = 0.570</td><td align="center" valign="bottom"><italic>α</italic> = 0.324</td><td align="center" valign="bottom"><italic>α</italic> = 0.327</td></tr><tr><td align="left" valign="bottom">Subject 14</td><td align="center" valign="bottom"><italic>α</italic> = 0.507</td><td align="center" valign="bottom"><italic>α</italic> = 0.253</td><td align="center" valign="bottom"><italic>α</italic> = 0.321</td></tr><tr><td align="left" valign="bottom">Subject 15</td><td align="center" valign="bottom"><italic>α</italic> = 0.799</td><td align="center" valign="bottom"><italic>α</italic> = 0.091</td><td align="center" valign="bottom"><italic>α</italic> = 0.102</td></tr><tr><th align="center" colspan="4" valign="bottom">Angular regression coeﬃcients (deg/s)</th></tr><tr><th align="left" valign="bottom"/><th align="center" valign="bottom">Vestibular</th><th align="center" valign="bottom">Visual</th><th align="center" valign="bottom">Combined</th></tr><tr><td align="left" valign="bottom">Subject 1</td><td align="center" valign="bottom"><italic>β</italic> = 1.664</td><td align="center" valign="bottom"><italic>β</italic> = 1.045</td><td align="center" valign="bottom"><italic>β</italic> = 1.553</td></tr><tr><td align="left" valign="bottom">Subject 2</td><td align="center" valign="bottom"><italic>β</italic> = 1.645</td><td align="center" valign="bottom"><italic>β</italic> = 2.022</td><td align="center" valign="bottom"><italic>β</italic> = 1.632</td></tr><tr><td align="left" valign="bottom">Subject 3</td><td align="center" valign="bottom"><italic>β</italic> = 1.317</td><td align="center" valign="bottom"><italic>β</italic> = 0.552</td><td align="center" valign="bottom"><italic>β</italic> = 1.232</td></tr><tr><td align="left" valign="bottom">Subject 4</td><td align="center" valign="bottom"><italic>β</italic> = 2.165</td><td align="center" valign="bottom"><italic>β</italic> = 0.919</td><td align="center" valign="bottom"><italic>β</italic> = 1.155</td></tr><tr><td align="left" valign="bottom">Subject 5</td><td align="center" valign="bottom"><italic>β</italic> = 2.349</td><td align="center" valign="bottom"><italic>β</italic> = 3.201</td><td align="center" valign="bottom"><italic>β</italic> = 3.045</td></tr><tr><td align="left" valign="bottom">Subject 6</td><td align="center" valign="bottom"><italic>β</italic> = 2.620</td><td align="center" valign="bottom"><italic>β</italic> = 0.563</td><td align="center" valign="bottom"><italic>β</italic> = 0.870</td></tr><tr><td align="left" valign="bottom">Subject 7</td><td align="center" valign="bottom"><italic>β</italic> = 1.434</td><td align="center" valign="bottom"><italic>β</italic> = 1.101</td><td align="center" valign="bottom"><italic>β</italic> = 0.843</td></tr><tr><td align="left" valign="bottom">Subject 8</td><td align="center" valign="bottom"><italic>β</italic> = 4.185</td><td align="center" valign="bottom"><italic>β</italic> = –0.039</td><td align="center" valign="bottom"><italic>β</italic> = 0.040</td></tr><tr><td align="left" valign="bottom">Subject 9</td><td align="center" valign="bottom"><italic>β</italic> = 1.254</td><td align="center" valign="bottom"><italic>β</italic> = 1.562</td><td align="center" valign="bottom"><italic>β</italic> = 1.394</td></tr><tr><td align="left" valign="bottom">Subject 10</td><td align="center" valign="bottom"><italic>β</italic> = 2.937</td><td align="center" valign="bottom"><italic>β</italic> = 1.971</td><td align="center" valign="bottom"><italic>β</italic> = 1.152</td></tr><tr><td align="left" valign="bottom">Subject 11</td><td align="center" valign="bottom"><italic>β</italic> = 1.849</td><td align="center" valign="bottom"><italic>β</italic> = –0.193</td><td align="center" valign="bottom"><italic>β</italic> = 0.194</td></tr><tr><td align="left" valign="bottom">Subject 12</td><td align="center" valign="bottom"><italic>β</italic> = 1.382</td><td align="center" valign="bottom"><italic>β</italic> = 0.836</td><td align="center" valign="bottom"><italic>β</italic> = 0.954</td></tr><tr><td align="left" valign="bottom">Subject 13</td><td align="center" valign="bottom"><italic>β</italic> = 1.619</td><td align="center" valign="bottom"><italic>β</italic> = 1.233</td><td align="center" valign="bottom"><italic>β</italic> = 1.165</td></tr><tr><td align="left" valign="bottom">Subject 14</td><td align="center" valign="bottom"><italic>β</italic> = 2.141</td><td align="center" valign="bottom"><italic>β</italic> = 0.585</td><td align="center" valign="bottom"><italic>β</italic> = 0.790</td></tr><tr><td align="left" valign="bottom">Subject 15</td><td align="center" valign="bottom"><italic>β</italic> = 2.214</td><td align="center" valign="bottom"><italic>β</italic> = 0.256</td><td align="center" valign="bottom"><italic>β</italic> = 0.264</td></tr></tbody></table></table-wrap><table-wrap id="app2table4" position="float"><label>Appendix 2—table 4.</label><caption><title>Partial correlation coefficients (mean ± standard deviation) for prediction of the radial (<inline-formula><mml:math id="inf279"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mrow><mml:mover><mml:mi>r</mml:mi><mml:mo stretchy="false">~</mml:mo></mml:mover></mml:mrow></mml:mrow></mml:mstyle></mml:math></inline-formula>, top) and angular (<inline-formula><mml:math id="inf280"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mrow><mml:mover><mml:mi>θ</mml:mi><mml:mo stretchy="false">~</mml:mo></mml:mover></mml:mrow></mml:mrow></mml:mstyle></mml:math></inline-formula>, bottom) components of the final stopping location (relative to starting position) from initial target distance (<italic>r</italic>) and angle (<italic>θ</italic>), the time constant <italic>τ</italic>, and the interaction of the two (<italic>r·τ</italic> or <italic>r·θ</italic>), respectively.</title></caption><table frame="hsides" rules="groups"><thead><tr><th align="center" colspan="5" valign="bottom">Radial partial correlation coeﬃcients ± standard deviation</th></tr><tr><th align="center" colspan="2" valign="bottom"/><th align="center" valign="bottom">Vestibular</th><th align="center" valign="bottom">Visual</th><th align="center" valign="bottom">Combined</th></tr></thead><tbody><tr><td align="left" rowspan="3" valign="bottom">Predictors</td><td align="left" valign="bottom">Radial distance (<italic>r</italic>)</td><td align="center" valign="bottom">0.20 ± 0.05</td><td align="center" valign="bottom">0.48 ± 0.13</td><td align="center" valign="bottom">0.45 ± 0.10</td></tr><tr><td align="left" valign="bottom">Time constant (<italic>τ</italic>)</td><td align="center" valign="bottom">–0.06 ± 0.07</td><td align="center" valign="bottom">0.01 ± 0.06</td><td align="center" valign="bottom">–0.03 ± 0.06</td></tr><tr><td align="left" valign="bottom">Interaction term (<italic>r·τ</italic>)</td><td align="center" valign="bottom">0.20 ± 0.09</td><td align="center" valign="bottom">0.07 ± 0.06</td><td align="center" valign="bottom">0.12 ± 0.09</td></tr><tr><th align="center" colspan="5" valign="bottom">Angular partial correlation coeﬃcients ± standard deviation</th></tr><tr><th align="left" colspan="2" valign="bottom"/><th align="center" valign="bottom">Vestibular</th><th align="center" valign="bottom">Visual</th><th align="center" valign="bottom">Combined</th></tr><tr><td align="left" rowspan="3" valign="bottom">Predictors</td><td align="left" valign="bottom">Angular distance (<italic>θ</italic>)</td><td align="center" valign="bottom">0.57 ± 0.13</td><td align="center" valign="bottom">0.90 ± 0.08</td><td align="center" valign="bottom">0.90 ± 0.06</td></tr><tr><td align="left" valign="bottom">Time constant (<italic>τ</italic>)</td><td align="center" valign="bottom">–0.06 ± 0.08</td><td align="center" valign="bottom">–0.01 ± 0.06</td><td align="center" valign="bottom">–0.07 ± 0.06</td></tr><tr><td align="left" valign="bottom">Interaction term (<italic>θ·τ</italic>)</td><td align="center" valign="bottom">0.27 ± 0.11</td><td align="center" valign="bottom">0.28 ± 0.15</td><td align="center" valign="bottom">0.33 ± 0.14</td></tr></tbody></table></table-wrap></app></app-group></back><sub-article article-type="editor-report" id="sa0"><front-stub><article-id pub-id-type="doi">10.7554/eLife.63405.sa0</article-id><title-group><article-title>Editor's evaluation</article-title></title-group><contrib-group><contrib contrib-type="author"><name><surname>Peyrache</surname><given-names>Adrien</given-names></name><role specific-use="editor">Reviewing Editor</role><aff><institution-wrap><institution-id institution-id-type="ror">https://ror.org/01pxwe438</institution-id><institution>McGill University</institution></institution-wrap><country>Canada</country></aff></contrib></contrib-group></front-stub><body><p>This paper investigates the importance of visual and inertial sensory cues as well as the underlying motion dynamics to the accuracy of spatial navigation. When motion control was artificially manipulated in a virtual environment, subjects could navigate accurately using vision, but not inertial signals alone. Overall, these findings shed new light on how the brain combines sensory information and internal models of control dynamics for self-motion perception and navigation.</p></body></sub-article><sub-article article-type="decision-letter" id="sa1"><front-stub><article-id pub-id-type="doi">10.7554/eLife.63405.sa1</article-id><title-group><article-title>Decision letter</article-title></title-group><contrib-group content-type="section"><contrib contrib-type="editor"><name><surname>Peyrache</surname><given-names>Adrien</given-names></name><role>Reviewing Editor</role><aff><institution-wrap><institution-id institution-id-type="ror">https://ror.org/01pxwe438</institution-id><institution>McGill University</institution></institution-wrap><country>Canada</country></aff></contrib></contrib-group><contrib-group><contrib contrib-type="reviewer"><name><surname>Clark</surname><given-names>Benjamin J</given-names></name><role>Reviewer</role><aff><institution-wrap><institution-id institution-id-type="ror">https://ror.org/05fs6jp91</institution-id><institution>University of New Mexico</institution></institution-wrap><country>United States</country></aff></contrib><contrib contrib-type="reviewer"><name><surname>Blohm</surname><given-names>Gunnar</given-names></name><role>Reviewer</role><aff><institution-wrap><institution-id institution-id-type="ror">https://ror.org/02y72wh86</institution-id><institution>Queen's University</institution></institution-wrap><country>Canada</country></aff></contrib><contrib contrib-type="reviewer"><name><surname>Glasauer</surname><given-names>Stefan</given-names></name><role>Reviewer</role><aff><institution-wrap><institution-id institution-id-type="ror">https://ror.org/05591te55</institution-id><institution>Ludwig-Maximilians-Universität München</institution></institution-wrap><country>Germany</country></aff></contrib></contrib-group></front-stub><body><boxed-text id="box1"><p>In the interests of transparency, eLife publishes the most substantive revision requests and the accompanying author responses.</p></boxed-text><p><bold>Decision letter after peer review:</bold></p><p>Thank you for submitting your article &quot;Influence of sensory modality and control dynamics on human path integration&quot; for consideration by <italic>eLife</italic>. Your article has been reviewed by 3 peer reviewers, and the evaluation has been overseen by a Reviewing Editor and Richard Ivry as the Senior Editor. The following individuals involved in review of your submission have agreed to reveal their identity: Benjamin Clark (Reviewer #1); Gunnar Blohm (Reviewer #2); Stefan Glasauer (Reviewer #3).</p><p>The reviewers have discussed the reviews with one another and the Reviewing Editor has drafted this decision to help you prepare a revised submission.</p><p>Summary:</p><p>In this manuscript, the authors investigated the importance of visual and vestibular sensory cues and the underlying motion dynamics to the accuracy of spatial navigation by human subjects. A virtual environment coupled with a 6-degrees of motion platform, as described in prior studies, allowed precise control over sensory cues and motion dynamics. To investigate whether control dynamics influence performance, the transfer function between joystick deflection and self-motion velocity was modified at each trial, resulting in subject to rely more on velocity or acceleration to find their way. To explain the main result that navigation error depends on control dynamics, the authors propose a probabilistic model in which an internal estimate of dynamics is biased by a strong prior. Overall, the three reviewers agree this manuscript might be suitable for publication in <italic>eLife</italic> and that additional data are not necessary. However, the analyses need to be clarified and the conclusion better justified. You will find below a summary of the main concerns. Please refer to the reviewers' comments appended at the end for more details.</p><p>Essential revisions:</p><p>1. Concerns were raised regarding motion cueing that was used to approximate the vestibular cues that would be present during real motion. The reviewers think that it should be better to refrain from generalizing and to restrict the conclusions to this specific artificial type of vestibular input. It could even by interesting, since motion cueing is used in driving simulators. See reviewer #2, point #3 and reviewer #3, point #3.</p><p>2. One possible interpretation of the data is that the subjects rely almost exclusively on sensory feedback, and that no estimate of control dynamics is necessary. One caveat of the current design is that the different trial types were interleaved, possibly resulting in unreliable efferent copies (leading subjects to estimate velocity from sensory inputs only) and a history effect in the estimation of tau (biasing vestibular trials). The authors should provide more evidence that their effect is not the result of feedback control only and that there is no history effect. See reviewer #2 point #2 and reviewer #3, point #1-2.</p><p>3. The relationship between tau and performance is unclear and should be clarified. Figure 3A seems to contradict Figure 5A. See reviewer #2, point #1.</p><p>4. It is unclear why the authors did not propose a more normative framework, e.g. using a hierarchical Bayesian model, as suggested in the discussion. This would be a very interesting addition to the manuscript. See reviewer #2 point #4.</p><p>5. The manuscript lack important information and details: number of trials, maximal velocity, difference between males and females, slope of the dependence between time constant and error. The actual control signal, the joystick command, should be shown and analyzed. See reviewer #1, point #1-2; reviewer #3, point #4-5.</p><p>6. It seems that tau was correlated with trial duration and velocity (Supp Figure 4), unlike what is stated in the manuscript (the effect of both factors are said to be &quot;unlikely&quot; p 161-167). The author should clarify this point. See reviewer #3, point #5.</p><p>7. Data presentation can be improved. See reviewer #1 point #3-5.</p><p><italic>Reviewer #1:</italic></p><p>1) The study tested performance by both male and female subjects. Could the authors comment as to whether sex differences were observed across performance measures? Perhaps sex can be indicated in some of the scatter plots.</p><p>2) Figure 2A. It would be helpful if the authors identified the start-point of the trajectory and also provided more explanation of the schematic in the caption.</p><p>3) Figure 2B-C. It would be helpful if the authors could expand this section to show some example trajectories and the relationship between examples and plotted data points. This could be done by presenting measures (radial distance, angular eccentricity, grain) for each example trajectory.</p><p>4) Because the range of sampled time-constants can vary across subjects, it would nice to show plots as in Figure 3B for each subject (i.e., in supplementary material).</p><p>5) Discussion. The broader implications of the findings from the models are not sufficiently discussed. In addition, some comparison could also be made to other recent efforts to model path integration error (e.g., PMC7250899).<italic>Reviewer #2:</italic></p><p>The authors asked how the brain uses different sensory signals to estimate self-motion for path integration in the presence of different movement dynamics. They used a new paradigm to show that path integration based on vision was mostly accurate, but vestibular signals alone led to systematic errors particularly for velocity-based control.</p><p>While I really like the general idea and approach, the conclusions of this study hinge on a number of assumptions for which it would be helpful if the authors could provide better justifications. I also have some clarification questions for certain parts of the manuscript.</p><p>1) lines 26-7: &quot;performance in all conditions was highly sensitive to the underlying control dynamics&quot;. This is hard to really appreciate from the residual error regressions in Figure 3 and seems to be contradicting Figure 5A (for vestibular condition). A more explicit demonstration of how tau affects performance would be helpful.</p><p>2) One of the main potential caviats I see in the study design is the fact that trial types (vest, visual, combined) were randomly interleaved. In the combined condition, this could potentially result in a form of calibration of the vestibular signal and/or a better estimate of tau that then is used for a subsequent vestibular-only trial. As such, you'd espect a history effect based on trial type more so (or in addition to) simple sequence effects. This is particularly true since you have a random walk design for across-trial changes of tau. In other words, my question is whether in the vestibular condition participants simple use their previous estimate of tau, since that would be on average close enough to the real tau?</p><p>3) I thought the experimental design was very clever, but I was missing some crucial information regarding the design choices and their consequences. First, has there been a psychophysical validation of GIA vs pure inertial acceleration? Second, were GIAs always well above the vestibular motion detection threshold? In other words could the worse performance in the vestibular condition be simply related to signal detection limitations? Third, how often did the motion platform enter the platform motion range limit regime (non-linear portion of sigmoid)?</p><p>4) lines 331-345: it's unclear to me why you did not propose a more normative framework as outlined here. Especially, a model that would &quot;contrain the hypothesized brain computationa dn their neurophysiological correlates&quot; would be highly desirable and really strengthen the future impact of this study.</p><p>5) I would highly recommend all data to be made available online in the same way as the analysis code has been made available.<italic>Reviewer #3:</italic></p><p>The manuscript describes interesting experimental and modelling results of a novel study of human navigation in virtual space, where participants had to move towards a briefly flashed target using optic flow and/or vestibular cues to infer their trajectory via path integration. To investigate whether control dynamics influence performance, the transfer function between joystick deflection and self-motion velocity was modified trial-by-trial in a clever way. To explain the main result that navigation error depends on control dynamics, the authors propose a probabilistic model in which an internal estimate of dynamics is biased by a strong prior. Even though the paper is clearly written and contains most of the necessary information, the study has several shortcomings, as outlined below, and an important alternative hypothesis has not been considered, so that some of the conclusions are not fully supported by results and modelling.</p><p>Substantive concerns</p><p>1) The main idea of the paper for explaining the influence of control dynamics is that for accurate path integration performance participants have to estimate dynamics. This idea is apparently inspired by studies on limb motor control. However, tasks in these studies are often ballistic, because durations are short compared to feedback delays. In navigation, this is not the case and participants can therefore rely on feedback control (for another reason, why reliance on sensory feedback in the present study is a good idea, see point 2 below). This means that the task can be solved, even though not perfectly, without actually knowing the control dynamics. Thus, an alternative hypothesis for explaining the results that has not been considered is that the error dependence of control dynamics is a direct consequence of feedback control. Feedback control models have previously been suggested for goal-directed path integration (e.g., Grasso et al., 1999; Glasauer et al., 2007).</p><p>To test this assumption, I modelled the experiment assuming a simple bang-bang feedback control that switches at a predefined and constant perceived distance from the target from +1 to -1 and stops when perceived velocity is smaller than an epsilon. Sensory feedback is perceived position, which is assumed to be computed via integration of optic flow. This model predicts a response gain of unity, a strong dependence of error on time constant (slope similar to Figure 3) or of response gain on time constant (Equation 4.1) with regression coefficients of 0.8 and 0.05 (cf. Figure 3D), and a modest correlation between movement duration and time constant (r approximately 0.2, similar to Figure 3A). Thus, a feedback model uninformed about actual motion dynamics and without any attempt to estimate them can explain most features of the data. Modifications (velocity uncertainty, delayed perception, noise on the stopping criterion, etc.) do not change the main features of the simulation results.</p><p>Accordingly, since simple feedback control seems to be an alternative to estimating control dynamics in this experiment, the authors’ conclusion in the abstract “that people need an accurate internal model of control dynamics when navigating in volatile environments” is not supported by the current results.</p><p>2) Modelling: the main rationale of the model (line 173 ff: “From a normative standpoint, …”) is correct, but an accurate estimate of the dynamics is only required if the uncertainty of the velocity estimate based on the efference copy is not too large. Otherwise, velocity estimation should rely predominantly on sensory input. In my opinion that’s what happens here: due to the trial-by-trial variation in dynamics, estimates based on efference copy are very unreliable (the same command generates a different sensory feedback in each trial), and participants resort to sensory input for velocity estimation. This results in feedback control, which, as mentioned above, seems to be compatible with the results.</p><p>3) Motion cueing: Motion cueing can, in the best case, approximate the vestibular cues that would be present during real motion. Furthermore, it is not clear whether the applied tilt is really perceived as linear acceleration, or whether the induced semi-circular canal stimulus is too strong so that subjects experience tilt. Participants might have used the tilt has indicator for onset or offset of translational motion, specifically because it is self-generated, but the contribution of the vestibular cues found in the present experiment might be completely different from what would happen during real movement. Therefore, conclusions about vestibular contributions are not warranted here and cannot solve the questions around “conflicting findings” mentioned in the introduction.</p><p>4) Methods: I was not able to find an important piece of information: how many trials were performed in each condition? Without this information, the statistical results are incomplete. It was also not possible to compute the maximal velocity allowed by joystick control, since for Equation 1.9 not just the displacement x and the time constant is required, but also the trial duration T, which is not reported. One can only guess from Figure 1D that vmax is about 50 cm/s for tau=0.6 s and therefore the average T is assumed to be around 8.5 s.</p><p>5) Results: information that would useful is not reported. On page 6 it is mentioned that the “effect of control dynamics must be due to either differences in travel duration or velocity profiles”, it is then stated that both is “unlikely”, but no results are given. It turns out that in the supplementary Figure 4A the correlation between time constant and duration/velocity is shown, and apparently the correlation with duration is significant (but small) in the majority of cases. Why is that not discussed in the Results section? Other results are also not reported, for example, what was the slope of the dependence between time constant and error? Why is the actual control signal, the joystick command, not shown and analyzed?</p><p>[Editors’ note: further revisions were suggested prior to acceptance, as described below.]</p><p>Thank you for resubmitting your work entitled “Influence of sensory modality and control dynamics on human path integration” for further consideration by <italic>eLife</italic>. Your revised article has been evaluated by Richard Ivry (Senior Editor) and a Reviewing Editor.</p><p>The manuscript has been improved but reviewer #3 has raised several issues that need to be addressed, as outlined below:</p><p><italic>Reviewer #3:</italic></p><p>The present version of the manuscript has clearly improved, and the authors responded adequately to the comments, and a link to the data was also provided. Some very helpful additional analysis was added, such as shown in Figure 3E. There are, however, some critical points left which are outlined below.</p><p>Introduction, line 83f: “These findings suggest that inertial cues alone lack the reliability to support accurate path integration …” Even though in general I’d agree with this statement, the findings in the current paper do not support this claim. Since the inertial cues were generated by motion cueing rather than being natural, it could be that natural inertial cues would yield much better path integration performance. Please change accordingly. See also next comments.</p><p>Figure 1 suppl. 2: I agree that the initial tilt cannot contribute to linear path integration, but if it is processed by the central estimator (see, for example, your co-author Jean Laurens’ models), it would change the perceived orientation of the participant to a tilted position. Consequently, the GIA after the tilt would be correctly perceived as being due to tilt, this means it would not be interpreted as resulting from linear displacement, and vestibular input would not at all, or only to a very little part, be used as input to the path integration system. This could be an explanation for the findings of inferior performance in the vestibular condition (see comment above). It would mean that motion cueing as applied here is not appropriate for simulating linear travel, which would be an important finding for designing driving simulators. Please discuss …</p><p>Results, page 4: it seems that the fit for the combined condition, specifically for distance (both in terms of R<sup>2</sup> and of response gain), was worse than for the visual condition. This would be surprising, since adding a second sensory input should not have that effect. However, if the vestibular stimulus, specifically for distance, is not appropriate, then this is exactly what should happen. A conflicting vestibular stimulus could decrease response gain (and the fit).</p><p>Results, page 6, line 164ff: “A partial correlation analyses revealed..” A summary statistical result should be shown here as well to support the result of time constant dependence.</p><p>Line 165: “…albeit only by modulating the distance dependence” I first misunderstood this and thought it would only modulate radial distance dependence. After looking at Figure 3 suppl 2: maybe better write “…albeit only by modulating both angular and radial distance dependence.”</p><p>Figure 5: text in figure caption is missing (probably due to clipping of the text box).</p><p>Results page 12-13, Bayesian model: I’m surprised that both SD of likelihood and prior were free parameters. For a Bayes model with Gaussian distributions and fixed prior, only the quotient of both standard deviations is a free parameter (the model is basically equivalent to a weighted sum of the mean of prior and the measurement, with the weight being determined by the quotient of the variances). So, either I misunderstand your model, or there’s a mistake. If the latter is the case, then Figure 6 and the corresponding results are also partly wrong, since likelihood σ and prior σ cannot be determined on their own, but only their quotient. See next comment, I suppose there is really a mistake.</p><p>Results page 14, dynamic prior model: here you can easily see from equation 7 (page 25) that there are in fact only 2 free parameters, not three (as you state), if you re-express the weight k: the weight k is given as k=var<sub>p</sub>/(var<sub>p</sub>+var<sub>m</sub>)=1/(1+var<sub>m</sub>/var<sub>p</sub>). So only var<sub>m</sub>/var<sub>p</sub> is free, not both, you cannot determine both from the fit. Note: in this model, it is usually sufficient to take the first measurement as mean of the first prior (corresponding to a maximum likelihood estimate on the first trial, or uninformative prior). This reduces the model to one free parameter.</p><p>Discussion, line 343-344: “In contrast, inertial (vestibular/somatosensory cues) alone lacked the reliability to support accurate path integration …” this is the case for the motion cueing inertial cues, so please make clear here and at other points that your data only refer to this type of inertial cues.</p><p>Discussion: I miss a general discussion of the limits of the study due to using motion cueing. As mentioned several times, the results concerning the vestibular and combined conditions of this study cannot be generalized to vestibular stimuli under natural conditions.</p><p>Along these lines I’m also very puzzled to read in the authors’ responses the following statement: “Therefore, there is no need to ensure that these accelerations are perceived identically: they <italic>are</italic> identical.”</p><p>(This reminds me of an astronaut who once stated that there is no need to study perception of up and down in space, because in weightlessness there is no up and down.)</p><p>Two identical linear accelerations can very well be perceived completely differently depending on the rotational history and context. That’s the reason why we perceive a tilt of the head as what it is, and not as rapid linear displacement. Please ask your coauthors Dora Angelaki and Jean Laurens, who are long enough in the field to know this. And this is extremely relevant in the present context.</p></body></sub-article><sub-article article-type="reply" id="sa2"><front-stub><article-id pub-id-type="doi">10.7554/eLife.63405.sa2</article-id><title-group><article-title>Author response</article-title></title-group></front-stub><body><disp-quote content-type="editor-comment"><p>Essential revisions:</p><p>1. Concerns were raised regarding motion cueing that was used to approximate the vestibular cues that would be present during real motion. The reviewers think that it should be better to refrain from generalizing and to restrict the conclusions to this specific artificial type of vestibular input. It could even by interesting, since motion cueing is used in driving simulators. See reviewer #2, point #3 and reviewer #3, point #3.</p></disp-quote><p>We agree with the remark and we apologize for our overgeneralization. We have responded to the reviewers’ specific questions about the motion cueing algorithm below. Although we have not claimed to have solved any questions regarding conflicting findings in the literature, we rephrased lines 47-50 such that we do not create the impression that we make such a claim. However, we are confident that our less restricted experimental design generalizes better than the strong vestibular-visual cue conflict that is present when simulating real-world navigation without motion cueing (lines 75-78 and 352-355).</p><disp-quote content-type="editor-comment"><p>2. One possible interpretation of the data is that the subjects rely almost exclusively on sensory feedback, and that no estimate of control dynamics is necessary. One caveat of the current design is that the different trial types were interleaved, possibly resulting in unreliable efferent copies (leading subjects to estimate velocity from sensory inputs only) and a history effect in the estimation of tau (biasing vestibular trials). The authors should provide more evidence that their effect is not the result of feedback control only and that there is no history effect. See reviewer #2 point #2 and reviewer #3, point #1-2.</p></disp-quote><p>History effect: we now test the history effect explicitly. We hypothesize that subjects try to compensate for whatever time constant (tau) they currently believe in, in order to stop at their believed target location. If so, their stopping location should depend only on the target location and not on tau; otherwise they knowingly failed to compensate for tau. In other words, their subjective residual errors (from their believed trajectories) should not depend on tau (correlation equal to zero). If the subjects use their previous tau estimate, then accordingly their believed responses should yield zero correlations between the subjective residual errors and that tau. If participants used the tau from the previous visual/combined trial as their estimate of tau in the current vestibular trial, there should be zero correlation between the tau and the (model-based) subjective residual errors. The data shows that for this model the correlation does not drop to zero when that estimate comes from a visual or combined trial (Figure 7 suppl. 1). In other words, the lack of adaptation cannot be fully explained away by subjects carrying over the tau estimates from the previous combined/visual trials. Intuitively, although the previous tau is, on average, in the direction of the mean of the sampling distribution, it is still far away from the overall mean due to the correlated nature of the random walk. Therefore, carrying over the previous estimate cannot fully explain away how much the participants were oblivious to dynamics changes in the vestibular condition – something that the Bayesian model readily does (Figure 6A). We reference the corresponding figure and analysis in lines 315-323.</p><p>Sensory feedback control: With respect to feedback control, we agree that, in principle, it is possible to perform this task suboptimally by directly estimating velocity using sensory feedback in the form of optic flow without estimating the control dynamics. To minimize travel time, bang-bang control is the optimal policy. But to implement it correctly, one must predict accurately when to start braking (switch from +1 to -1) based on the current dynamics. For this reason, we argue that an accurate internal model of the dynamics is required. On the other hand, a bang-bang control policy that is oblivious to the dynamics, such as a purely sensory feedback control model, is guaranteed to result in errors unless the participant performs further corrections. In other words, a bang-bang control policy that is based purely on momentary sensory feedback only allows for inaccurate but never perfect performance.</p><p>We appreciate the reviewer’s care in substantiating their idea about feedback control in a simulation of their own! To test whether the reviewer’s model explains our observations, we fit a sensory feedback control model with fixed-distance bang-bang policy to our data with two parameters: mean and standard deviation of switching distance from target (Methods – lines 707-715). The problem with the fixed policy proposed by the reviewer is without adaptation to the control dynamics, the errors have a stronger dependence on those dynamics than we measure experimentally. This fixed model predicts much higher correlations and regressions slopes between the time constant and the residual error than the ones found in the actual data (lines 324-331, Figure 7 suppl. 2A). In fact, the empirical distributions of the switching distances were broad and much closer to that predicted by an ideal bang-bang control policy (that anticipates when to brake using knowledge of the dynamics) than the best-fit fixed-distance bang-bang control policy (Figure 7 suppl. 2C).</p><p>We conclude that participants do not fully adapt to the control dynamics, but nor do they ignore them. The previous version of this paper emphasized the imperfection of adaptation, while underemphasizing that there was indeed some significant adaptation. Now we compute the responses expected from both a perfectly adapting policy and a fixed, unadapting one, and show (Figure 3E) that data lies between these extremes, revealing partial adaptation for all conditions. Visual information allows more adaptation, but even in the vestibular condition we still see more adaptation than a fixed controller that does not adapt its policy based on the current dynamics.</p><disp-quote content-type="editor-comment"><p>3. The relationship between tau and performance is unclear and should be clarified. Figure 3A seems to contradict Figure 5A. See reviewer #2, point #1.</p></disp-quote><p>(Please note that Figure 5 has changed to Figure 6 due to our edits). We apologize for the lack of clarity in our description. Under ideal steering control adaptation, stopping positions should depend only on target location, and nothing else (see lines 145-149, 165-168). However, we observed a relationship between the responses and the time constant (Figure 3A), indicating a deviation from ideal adaptation. Our model attributes this deviation to misestimated dynamics (lines 226-228): better/worse control adaptation corresponds to better/worse estimation of the time constant. As pointed out in lines 278-280, better dynamics estimation (Figure 6A; visual/combined) results in smaller modulation of the actual responses by the dynamics (Figure 3A; visual/combined). Conversely, greater misestimation (i.e. vestibular in Figure 6A) leads to stronger modulation (i.e. vestibular in Figure 3A). We rephrased lines 25-27 to better convey the effect of the dynamics on performance. For an explicit demonstration of how the participants’ steering was influenced by the changes in the dynamics, we added lines 185-195 and Figure 4.</p><disp-quote content-type="editor-comment"><p>4. It is unclear why the authors did not propose a more normative framework, e.g. using a hierarchical Bayesian model, as suggested in the discussion. This would be a very interesting addition to the manuscript. See reviewer #2 point #4.</p></disp-quote><p>In this study, we explored the contribution of different sensory modalities, control dynamics, and their interaction in human path integration. The extensiveness of the analyses needed to describe the model performance and beliefs in this novel approach does not leave room for a highly technical and thorough multi-level model of goal-oriented path integration. Such a model should include a detailed description of how participants estimate the dynamics. Our goal was to use this study as a foundation and develop such a model in follow-up studies.</p><disp-quote content-type="editor-comment"><p>5. The manuscript lack important information and details: number of trials, maximal velocity, difference between males and females, slope of the dependence between time constant and error. The actual control signal, the joystick command, should be shown and analyzed. See reviewer #1, point #1-2; reviewer #3, point #4-5.</p></disp-quote><p>We apologize for our omissions. We provided all missing information and additional figures as indicated by the reviewers. We would like to point out that an explicit demonstration of how the participants’ control was influenced by the changes in the dynamics was added in lines 130-134, 185-195 and Figures 2E, 4.</p><disp-quote content-type="editor-comment"><p>6. It seems that tau was correlated with trial duration and velocity (Supp Figure 4), unlike what is stated in the manuscript (the effect of both factors are said to be “unlikely” p 161-167). The author should clarify this point. See reviewer #3, point #5.</p></disp-quote><p>We thank the reviewers for giving us a chance to explain. Prior to the start of data collection, we adjusted stimulus parameters to ensure travel time and mean velocity are similar across different dynamics for a controller with perfect knowledge of the dynamics. However, participants’ knowledge of the dynamics was not perfect, as revealed by the dynamics-dependent responses that we attributed to erroneous adaptation/estimation. Additionally, we found a small dependence of travel duration and average travel velocity on the dynamics for some participants. Importantly, travel duration is a feature of the control policy. Since perfect adaptation would yield identical travel times across dynamics, the resulting dependence on the dynamics again shows that participants failed to adapt perfectly. Simulations confirmed this, as maladaptation results in a dependence of travel duration on the dynamics. We edited lines 207-214 to reflect this explanation and updated Figure 5 suppl. 1 to include our simulations.</p><disp-quote content-type="editor-comment"><p>7. Data presentation can be improved. See reviewer #1 point #3-5.</p></disp-quote><p>Reviewer #1’s comments about data presentation were greatly appreciated. All suggestions were accommodated to the fullest extent we could, and we adjusted other figures in the same spirit (e.g. Figure 1D, 4A).</p><disp-quote content-type="editor-comment"><p>Reviewer #1:</p><p>1) The study tested performance by both male and female subjects. Could the authors comment as to whether sex differences were observed across performance measures? Perhaps sex can be indicated in some of the scatter plots.</p></disp-quote><p>Since no significant sex differences were observed (see lines mentioned below for stats), we do not indicate the sexes of the participants in the main figures (lines 125-129, 149-152), however, we added Figure 2 suppl. 1B, C to illustrate the difference in performance across sexes.</p><disp-quote content-type="editor-comment"><p>2) Figure 2A. It would be helpful if the authors identified the start-point of the trajectory and also provided more explanation of the schematic in the caption.</p></disp-quote><p>Figure 2A has been updated accordingly and the corresponding caption was expanded.</p><disp-quote content-type="editor-comment"><p>3) Figure 2B-C. It would be helpful if the authors could expand this section to show some example trajectories and the relationship between examples and plotted data points. This could be done by presenting measures (radial distance, angular eccentricity, grain) for each example trajectory.</p></disp-quote><p>We think that the update in Figure 2A addresses the point of the reviewer by identifying the variables in 2B, C as they relate to the trajectory. Because the response gain is not a trial-by-trial measure, it can only be shown as is in Figure 2B, C. Nevertheless, we added Figure 2 suppl. 1A (referenced in line 126) where we display trajectories of an example subject under each sensory condition with the corresponding response gain values displayed on top.</p><disp-quote content-type="editor-comment"><p>4) Because the range of sampled time-constants can vary across subjects, it would be nice to show plots as in Figure 3B for each subject (i.e., in supplementary material).</p></disp-quote><p>The sampling distributions of the time constant across subjects and conditions were added in new Figure 3 suppl. 1, along with plots as in Figure 3B for more subjects.</p><disp-quote content-type="editor-comment"><p>5) Discussion. The broader implications of the findings from the models are not sufficiently discussed. In addition, some comparison could also be made to other recent efforts to model path integration error (e.g., PMC7250899).</p></disp-quote><p>We added a discussion paragraph about the model comparisons and the implications of our findings in lines 378385, while we discuss the proposed study in lines 200-201.</p><disp-quote content-type="editor-comment"><p>Reviewer #2:</p><p>The authors asked how the brain uses different sensory signals to estimate self-motion for path integration in the presence of different movement dynamics. They used a new paradigm to show that path integration based on vision was mostly accurate, but vestibular signals alone led to systematic errors particularly for velocity-based control.</p><p>While I really like the general idea and approach, the conclusions of this study hinge on a number of assumptions for which it would be helpful if the authors could provide better justifications. I also have some clarification questions for certain parts of the manuscript.</p><p>1) lines 26-7: “performance in all conditions was highly sensitive to the underlying control dynamics”. This is hard to really appreciate from the residual error regressions in Figure 3 and seems to be contradicting Figure 5A (for vestibular condition). A more explicit demonstration of how tau affects performance would be helpful.</p></disp-quote><p>We rephrased lines 25-27 to better convey the effect of the control dynamics on performance (i.e. failure to adapt steering to the underlying dynamics). The observed relationship between the responses and the time constant (Figure 3A) denotes a deviation from ideal steering control adaptation (ideal adaptation would manifest as an absence of modulation because stopping positions should depend only on target location and nothing else, see lines 145-149, 165-168). With our model, we attributed this modulation, and thereby, the corresponding erroneous adaptation, to dynamics misestimation (lines 226-228). Therefore, better/worse control adaptation corresponds to better/worse estimation of the time constant. As pointed out in lines 278-280, better dynamics estimation (Figure 6A; visual/combined) results in smaller modulation of the actual responses by the dynamics (Figure 3A; visual/combined). Conversely, greater misestimation (i.e. vestibular in Figure 6A) leads to stronger response modulation (i.e. vestibular in Figure 3A).</p><p>Last but not least, for an explicit demonstration of how the participants’ steering was influenced by the changes in dynamics, we added lines 185-195 and Figure 4 describing how participants’ control adapts to changes of the time constant.</p><disp-quote content-type="editor-comment"><p>2) One of the main potential caviats I see in the study design is the fact that trial types (vest, visual, combined) were randomly interleaved. In the combined condition, this could potentially result in a form of calibration of the vestibular signal and/or a better estimate of tau that then is used for a subsequent vestibular-only trial. As such, you’d expect a history effect based on trial type more so (or in addition to) simple sequence effects. This is particularly true since you have a random walk design for across-trial changes of tau. In other words, my question is whether in the vestibular condition participants simple use their previous estimate of tau, since that would be on average close enough to the real tau?</p></disp-quote><p>The motivation for our stimulus design was expressly to provide an opportunity for participants to rely on history. Despite our efforts, we did not find a significant history effect.</p><p>As clarified in the response to the question above and in the revised text, the model tries to explain why participants failed to adapt to the changes in tau. In the data, this failure manifests itself as a correlation between response errors and tau (lines 149-155; Figure 3A-D). The proposed model successfully attributes this failure to participants misestimating tau, because response errors obtained by integrating the participants’ control input according to the MAP estimate of tau (instead of the real tau), no longer exhibits such a correlation (Figure 5B; lines 278-280). If alternatively, participants simply used the real tau from the previous visual/combined trial as their estimate of tau in the current vestibular trial, then integrating the participants’ control input using this new way of estimating tau should also result in a correlation of zero.</p><p>We tested this and found that, using the previous estimate, model predicted correlations do not drop to zero when that estimate comes from a visual or combined trial (Figure 7 suppl. 1). In other words, the lack of adaptation cannot be fully explained away by subjects carrying over the tau estimates from the previous combined/visual trials. Intuitively, although the previous tau is, on average, in the direction of the mean of the sampling distribution, it is still far away from the mean due to the correlated nature of the random walk. Therefore, carrying over the previous estimate cannot fully explain away the regression towards the mean (the degree to which the participants were oblivious to dynamics changes) – something that the Bayesian model readily does (Figure 6A). We reference the corresponding figure and analysis in lines 315-323.</p><disp-quote content-type="editor-comment"><p>3) I thought the experimental design was very clever, but I was missing some crucial information regarding the design choices and their consequences. First, has there been a psychophysical validation of GIA vs pure inertial acceleration? Second, were GIAs always well above the vestibular motion detection threshold? In other words could the worse performance in the vestibular condition be simply related to signal detection limitations? Third, how often did the motion platform enter the platform motion range limit regime (non-linear portion of sigmoid)?</p></disp-quote><p>1. To determine the parameters of the Motion Cuing Algorithm, we performed several pilot experiments in ourselves to verify the effectiveness of the perception. More detailed answers to the reviewer’s question follow</p><p>2. Has there been a psychophysical validation of GIA vs pure inertial acceleration? From the point of view of physics, GIA and pure inertial acceleration are indistinguishable (Einstein, 1907). Therefore, there is no need to ensure that these accelerations are perceived identically: they <italic>are</italic> identical. However, it is possible to sense the rotation movements generated when the MC algorithm tilts the subjects. We analyzed the rotation velocity (Figure 1 suppl. 2B) and found that they could exceed rotation velocity thresholds found in the literature (Lim et al., 2017, MacNeilage et al., 2010) for brief periods (~0.6s), but we argue that these periods are too short to influence our experiment’s outcome (see Figure 1 suppl. 2B).</p><p>3. Were GIAs always well above the vestibular motion detection threshold? Yes, we verified (in Figure 1 suppl. 2A) that the GIAs profiles were higher than a conservative motion detection threshold (8 cm/s2, based on Kingma 2005, MacNeilage et al., 2010, Zupan and Merfeld: the thresholds range between 5 and 8.5 cm/s2 in these studies).</p><p>4. How often did the motion platform enter the platform motion range limit regime (non-linear portion of sigmoid)? To evaluate this, we show the GIA error in Figure 1 suppl. 2A. Indeed, these GIA error occur if (and only if) the platform is this range limit regime. We show in Figure 1 suppl. 2A that these errors remain well below the GIA threshold: therefore, we don’t think that the limitations of the platform could have influenced the subject’s perception.</p><disp-quote content-type="editor-comment"><p>4) lines 331-345: it’s unclear to me why you did not propose a more normative framework as outlined here. Especially, a model that would “contrain the hypothesized brain computationa dn their neurophysiological correlates” would be highly desirable and really strengthen the future impact of this study.</p></disp-quote><p>In short, this paper is already too dense. We plan to develop such a model, along with behavior and neural recordings in monkeys, which are currently underway. See also response to Reviewing Editor’s comment #4.</p><disp-quote content-type="editor-comment"><p>5) I would highly recommend all data to be made available online in the same way as the analysis code has been made available.</p></disp-quote><p>The dataset was made available online at the following address, and the link was provided in line 719: https://gin.g-node.org/akis_stavropoulos/humans_control_dynamics_sensory_modality_steering</p><disp-quote content-type="editor-comment"><p>Reviewer #3:</p><p>The manuscript describes interesting experimental and modelling results of a novel study of human navigation in virtual space, where participants had to move towards a briefly flashed target using optic flow and/or vestibular cues to infer their trajectory via path integration. To investigate whether control dynamics influence performance, the transfer function between joystick deflection and self-motion velocity was modified trial-by-trial in a clever way. To explain the main result that navigation error depends on control dynamics, the authors propose a probabilistic model in which an internal estimate of dynamics is biased by a strong prior. Even though the paper is clearly written and contains most of the necessary information, the study has several shortcomings, as outlined below, and an important alternative hypothesis has not been considered, so that some of the conclusions are not fully supported by results and modelling.</p><p>Substantive concerns</p><p>1) The main idea of the paper for explaining the influence of control dynamics is that for accurate path integration performance participants have to estimate dynamics. This idea is apparently inspired by studies on limb motor control. However, tasks in these studies are often ballistic, because durations are short compared to feedback delays. In navigation, this is not the case and participants can therefore rely on feedback control (for another reason, why reliance on sensory feedback in the present study is a good idea, see point 2 below). This means that the task can be solved, even though not perfectly, without actually knowing the control dynamics. Thus, an alternative hypothesis for explaining the results that has not been considered is that the error dependence of control dynamics is a direct consequence of feedback control. Feedback control models have previously been suggested for goal-directed path integration (e.g., Grasso et al., 1999; Glasauer et al., 2007).</p><p>To test this assumption, I modelled the experiment assuming a simple bang-bang feedback control that switches at a predefined and constant perceived distance from the target from +1 to -1 and stops when perceived velocity is smaller than an epsilon. Sensory feedback is perceived position, which is assumed to be computed via integration of optic flow. This model predicts a response gain of unity, a strong dependence of error on time constant (slope similar to Figure 3) or of response gain on time constant (Equation 4.1) with regression coefficients of 0.8 and 0.05 (cf. Figure 3D), and a modest correlation between movement duration and time constant (r approximately 0.2, similar to Figure 3A). Thus, a feedback model uninformed about actual motion dynamics and without any attempt to estimate them can explain most features of the data. Modifications (velocity uncertainty, delayed perception, noise on the stopping criterion, etc.) do not change the main features of the simulation results.</p><p>Accordingly, since simple feedback control seems to be an alternative to estimating control dynamics in this experiment, the authors' conclusion in the abstract &quot;that people need an accurate internal model of control dynamics when navigating in volatile environments&quot; is not supported by the current results.</p></disp-quote><p>Indeed, in principle, it is possible to perform this task suboptimally by directly estimating velocity using sensory feedback in the form of optic flow, without estimating the control dynamics.</p><p>We appreciate the reviewer’s care in substantiating their idea about feedback control in a simulation of their own! To test whether the reviewer’s model explains our observations, we fit a sensory feedback control model with fixed-distance bang-bang policy to our data with two parameters: mean and standard deviation of switching distance from target (Methods – lines 707-715). The problem with the fixed policy proposed by the reviewer is without adaptation to the control dynamics, the errors have a stronger dependence on those dynamics than we measure experimentally. This fixed model predicts much higher correlations and regressions slopes between the time constant and the residual error than the ones found in the actual data (lines 324-331, Figure 7 suppl. 2A). In fact, the empirical distributions of the switching distances were broad and much closer to that predicted by an ideal bang-bang control policy (that anticipates when to brake using knowledge of the dynamics) than the best-fit fixed-distance bang-bang control policy (Figure 7 suppl. 2C).</p><p>We conclude that participants do not fully adapt to the control dynamics, but nor do they ignore them. The previous version of this paper emphasized the imperfection of adaptation, while underemphasizing that there was indeed some significant adaptation. Now we compute the responses expected from both a perfectly adapting policy and a fixed, unadapting one, and show (Figure 3E) that data lies between these extremes, revealing partial adaptation for all conditions. Visual information allows more adaptation, but even in the vestibular condition we still see more adaptation than a fixed controller that does not adapt its policy based on the current dynamics.</p><disp-quote content-type="editor-comment"><p>2) Modelling: the main rationale of the model (line 173 ff: &quot;From a normative standpoint, …&quot;) is correct, but an accurate estimate of the dynamics is only required if the uncertainty of the velocity estimate based on the efference copy is not too large. Otherwise, velocity estimation should rely predominantly on sensory input. In my opinion that's what happens here: due to the trial-by-trial variation in dynamics, estimates based on efference copy are very unreliable (the same command generates a different sensory feedback in each trial), and participants resort to sensory input for velocity estimation. This results in feedback control, which, as mentioned above, seems to be compatible with the results.</p></disp-quote><p>We manipulated the dynamics in this way precisely because we did not want the efference copy to be fully informative about self-motion velocity. As explained above, we agree that velocity estimation relies predominantly on sensory input. However, as mentioned in the response to the previous question, reliance on sensory input need not necessarily result in pure feedback control, since sensory observations can contribute significantly to the estimation of the control dynamics, which seems to be what the participants are attempting based on our findings (lines 411-412). Pure feedback control would certainly become valuable, and thus much more likely, if we alter the control dynamics within the duration of each trial. This is something that we would like to investigate in future studies.</p><disp-quote content-type="editor-comment"><p>3) Motion cueing: Motion cueing can, in the best case, approximate the vestibular cues that would be present during real motion. Furthermore, it is not clear whether the applied tilt is really perceived as linear acceleration, or whether the induced semicircular canal stimulus is too strong so that subjects experience tilt. Participants might have used the tilt has indicator for onset or offset of translational motion, specifically because it is self-generated, but the contribution of the vestibular cues found in the present experiment might be completely different from what would happen during real movement. Therefore, conclusions about vestibular contributions are not warranted here and cannot solve the questions around &quot;conflicting findings&quot; mentioned in the introduction.</p></disp-quote><p>This comment has also been answered in response to comments of Rev. 2 (see also response to Rev. Editor’s comment #1). Specifically, we have added Figure 1 suppl. 2B (referenced in lines 74-75 and 592-593), where we show the tilt velocity profile over time with a tilt/translation discrimination threshold we chose according to the canal thresholds literature (Lim et al., 2017, MacNeilage et al., 2010). Tilt velocity exceeds the proposed threshold briefly right after trial onset, however, the displacement of the subjects during that period is negligible and should not influence navigation. Thus, perceived tilt can be used as an indicator of trial onset, but it cannot contribute to path integration for 3 reasons: (a) the displacement during that period is negligible, (b) tilt velocity is kept below the perceptual threshold for the remainder of the trajectory, (c) GIA is always above the motion detection threshold of the vestibular system (Figure 1 suppl. 2A).</p><p>We have also rephrased lines 47-50 such that we do not create the impression that we make the claim to solve the questions around &quot;conflicting findings&quot;. However, we are confident that our relatively less restricted experimental design can be more generalizable when it comes to vestibular contributions in real-world navigation (lines 75-78 and 352-355).</p><disp-quote content-type="editor-comment"><p>4) Methods: I was not able to find an important piece of information: how many trials were performed in each condition? Without this information, the statistical results are incomplete. It was also not possible to compute the maximal velocity allowed by joystick control, since for Equation 1.9 not just the displacement x and the time constant is required, but also the trial duration T, which is not reported. One can only guess from Figure 1D that vmax is about 50 cm/s for tau=0.6 s and therefore the average T is assumed to be around 8.5 s.</p></disp-quote><p>We apologize for our omission. The values for <italic>x</italic> and <italic>T</italic> that we used are added in line 518. Also, we added the number of trials each participant performed in each condition in lines 484-487.</p><disp-quote content-type="editor-comment"><p>5) Results: information that would useful is not reported. On page 6 it is mentioned that the &quot;effect of control dynamics must be due to either differences in travel duration or velocity profiles&quot;, it is then stated that both is &quot;unlikely&quot;, but no results are given. It turns out that in the supplementary Figure 4A the correlation between time constant and duration/velocity is shown, and apparently the correlation with duration is significant (but small) in the majority of cases. Why is that not discussed in the Results section? Other results are also not reported, for example, what was the slope of the dependence between time constant and error? Why is the actual control signal, the joystick command, not shown and analyzed?</p></disp-quote><p>We thank the reviewer for allowing us to fix these problems. Prior to the start of data collection, we adjusted stimulus parameters to ensure travel time and mean velocity are similar across different dynamics for a controller with perfect knowledge of the dynamics. Nevertheless, participants’ knowledge of the dynamics was incorrect, as revealed by the dynamics-dependent responses that we attributed to erroneous adaptation/estimation. Additionally, we found a small dependence of travel duration and average travel velocity on the dynamics for some participants. Importantly, travel duration is a feature of the control policy. Since, according to our design, perfect adaptation would exhibit similar travel times across dynamics, the resulting dependence on the dynamics merely shows that participants failed to adapt perfectly. Simulations confirmed this, as maladaptation results in a dependence of travel duration on the dynamics.</p><p>We edited lines 207-214 to reflect this explanation and updated Figure 5 suppl. 1 to include our simulations. We added the slopes of the regression between the time constant and the residual errors in Figure 3 suppl. 1 and Table 3 (referenced in line 155).</p><p>We also added a discussion of analyses (lines 185-195) and figures 1D inset, 2D inset, 4, and Figure 2 suppl. 2 that refer to the joystick input.</p><p>[Editors' note: further revisions were suggested prior to acceptance, as described below.]</p><disp-quote content-type="editor-comment"><p>Reviewer #3:</p><p>The present version of the manuscript has clearly improved, and the authors responded adequately to the comments, and a link to the data was also provided. Some very helpful additional analysis was added, such as shown in Figure 3E. There are, however, some critical points left which are outlined below.</p><p>Introduction, line 83f: &quot;These findings suggest that inertial cues alone lack the reliability to support accurate path integration …&quot; Even though in general I'd agree with this statement, the findings in the current paper do not support this claim. Since the inertial cues were generated by motion cueing rather than being natural, it could be that natural inertial cues would yield much better path integration performance. Please change accordingly. See also next comments.</p></disp-quote><p>We agree with this comment. We edited this sentence to include this consideration (lines 87-88), and also adjusted the wording in other parts of the text where we refer to inertial cues (lines 358, 381, 412).</p><disp-quote content-type="editor-comment"><p>Figure 1 suppl. 2: I agree that the initial tilt cannot contribute to linear path integration, but if it is processed by the central estimator (see, for example, your co-author Jean Laurens' models), it would change the perceived orientation of the participant to a tilted position. Consequently, the GIA after the tilt would be correctly perceived as being due to tilt, this means it would not be interpreted as resulting from linear displacement, and vestibular input would not at all, or only to a very little part, be used as input to the path integration system. This could be an explanation for the findings of inferior performance in the vestibular condition (see comment above). It would mean that motion cueing as applied here is not appropriate for simulating linear travel, which would be an important finding for designing driving simulators. Please discuss …</p></disp-quote><p>We edited the legend in Figure 1 Suppl. 2 to reflect this view and point to the main text for a more detailed discussion (lines 435-450). We want to point out that, in a previous study, we measured the participants’ performance in complete absence of sensory cues (Lakshminarasimhan, 2018 Figure S1B). Compared to the response measured in the present study using vestibular feedback, we find that the performance is much worse in the absence of sensory feedback, suggesting that participants used the generated vestibular cues to some extent (no sensory cues condition correlation ± SD between target position and response, radial component: 0.39±0.12, angular component: 0.58±0.2; vestibular condition correlation ± SD between target position and response, radial component: 0.64±0.05, angular component: 0.93±0.03; radial component t-test p=9 ∙ 10<sup>−7</sup>, angular component t-test p = 10<sup>−8</sup>). However, we agree that the possibility that the perceived tilt would influence the processing of vestibular inputs cannot be ruled out. We hope that our revised text clearly highlights this limitation.</p><disp-quote content-type="editor-comment"><p>Results, page 4: it seems that the fit for the combined condition, specifically for distance (both in terms of R<sup>2</sup> and of response gain), was worse than for the visual condition. This would be surprising, since adding a second sensory input should not have that effect. However, if the vestibular stimulus, specifically for distance, is not appropriate, then this is exactly what should happen. A conflicting vestibular stimulus could decrease response gain (and the fit).</p></disp-quote><p>This is a good observation. Although R<sup>2</sup> and the response gain for the combined condition are slightly lower than the visual condition (only for the radial component), their difference is not significant as R<sup>2</sup> and response gain for combined falls within the 95% CI of the mean R<sup>2</sup> and response gain of the visual condition, respectively (Radial component: combined condition mean R<sup>2</sup> = 0.64, visual condition 95% CI of mean R<sup>2</sup> = [0.62 0.72], paired t-test p=0.074; Angular component: combined condition mean R<sup>2</sup> = 0.96, visual condition 95% CI of mean R<sup>2</sup> = [0.93 0.98], paired t-test p=0.37). Other than the concerns raised in the previous comment about the effect of perceived tilt on path integration and performance, our experimental design should not allow for a sensory conflict. We propose further manipulations for future experiments that would investigate the relationship between vestibular and visual cues in our edited Discussion section (lines 446-450).</p><disp-quote content-type="editor-comment"><p>Results, page 6, line 164ff: &quot;A partial correlation analyses revealed..&quot; A summary statistical result should be shown here as well to support the result of time constant dependence.</p></disp-quote><p>We apologize for this omission. We added Table 4 that shows these values, since the total number of values to be shown (3 conditions x 3 predictors) would take up too much space and would be hard to read. We refer to the Table on line 174.</p><disp-quote content-type="editor-comment"><p>Line 165: &quot;…albeit only by modulating the distance dependence&quot; I first misunderstood this and thought it would only modulate radial distance dependence. After looking at Figure 3 suppl 2: maybe better write &quot;…albeit only by modulating both angular and radial distance dependence.&quot;</p></disp-quote><p>We apologize for the confusion, we changed the wording as suggested.</p><disp-quote content-type="editor-comment"><p>Figure 5: text in figure caption is missing (probably due to clipping of the text box).</p></disp-quote><p>Apologies, corrected.</p><disp-quote content-type="editor-comment"><p>Results page 12-13, Bayesian model: I'm surprised that both SD of likelihood and prior were free parameters. For a Bayes model with Gaussian distributions and fixed prior, only the quotient of both standard deviations is a free parameter (the model is basically equivalent to a weighted sum of the mean of prior and the measurement, with the weight being determined by the quotient of the variances). So, either I misunderstand your model, or there's a mistake. If the latter is the case, then Figure 6 and the corresponding results are also partly wrong, since likelihood σ and prior σ cannot be determined on their own, but only their quotient. See next comment, I suppose there is really a mistake.</p></disp-quote><p>Thank you for pointing this out. Indeed, there was a subtle error on our behalf. We corrected and re-fitted our models (static and dynamic prior) with just the ratio <italic>λ</italic> of prior σ over likelihood σ instead of both prior and likelihood σ, and therefore decreased the fitted parameters to 2 and 1 for the static and dynamic prior models, respectively. We updated the text and the relevant statistics and figures.</p><disp-quote content-type="editor-comment"><p>Results page 14, dynamic prior model: here you can easily see from equation 7 (page 25) that there are in fact only 2 free parameters, not three (as you state), if you re-express the weight k: the weight k is given as k=var<sub>p</sub>/(var<sub>p</sub>+var<sub>m</sub>)=1/(1+var<sub>m</sub>/var<sub>p</sub>). So only var<sub>m</sub>/var<sub>p</sub> is free, not both, you cannot determine both from the fit. Note: in this model, it is usually sufficient to take the first measurement as mean of the first prior (corresponding to a maximum likelihood estimate on the first trial, or uninformative prior). This reduces the model to one free parameter.</p></disp-quote><p>We want to clarify that we use <italic>k</italic> only to update the mean of the prior distribution across trials. After our corrections according to the previous comment, we fit just the ratio <italic>λ</italic> of prior σ over likelihood σ, and set the initial prior to be the time constant on the first trial. This reduced the fitted parameters of the dynamic prior model to 1.</p><disp-quote content-type="editor-comment"><p>Discussion, line 343-344: &quot;In contrast, inertial (vestibular/somatosensory cues) alone lacked the reliability to support accurate path integration …&quot; this is the case for the motion cueing inertial cues, so please make clear here and at other points that your data only refer to this type of inertial cues.</p></disp-quote><p>We already adjusted the wording to this sentence in response to the first comment.</p><disp-quote content-type="editor-comment"><p>Discussion: I miss a general discussion of the limits of the study due to using motion cueing. As mentioned several times, the results concerning the vestibular and combined conditions of this study cannot be generalized to vestibular stimuli under natural conditions.</p></disp-quote><p>We have considered the comments and concerns raised carefully and made the necessary adjustments to the text. As mentioned in the responses above, we clarified wherever applicable that any conclusions made based on our findings apply only to this specific paradigm (lines 87-88, 358, 381, 412). We also added a paragraph in Discussion describing the limitation of the Motion Cueing algorithm and opportunities for future work (435-450).</p><disp-quote content-type="editor-comment"><p>Along these lines I'm also very puzzled to read in the authors' responses the following statement: &quot;Therefore, there is no need to ensure that these accelerations are perceived identically: they are identical.&quot;</p><p>(This reminds me of an astronaut who once stated that there is no need to study perception of up and down in space, because in weightlessness there is no up and down.)</p><p>Two identical linear accelerations can very well be perceived completely differently depending on the rotational history and context. That's the reason why we perceive a tilt of the head as what it is, and not as rapid linear displacement. Please ask your coauthors Dora Angelaki and Jean Laurens, who are long enough in the field to know this. And this is extremely relevant in the present context.</p></disp-quote><p>All our apologies: this is a misunderstanding. Yes, the combination of rotation and acceleration experienced during tilt can be perceived differently from the acceleration experienced during translation. The misunderstanding originated from the way we think about it: in our mind, it is the rotation history (sensed by the canals) that makes the difference, whereas the accelerations are the same (that is to say, in the absence of rotation sensors, the acceleration induced by tilt and translation are indistinguishable); hence our response.</p></body></sub-article></article>