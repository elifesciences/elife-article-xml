<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD with MathML3 v1.2 20190208//EN"  "JATS-archivearticle1-mathml3.dtd"><article xmlns:ali="http://www.niso.org/schemas/ali/1.0/" xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" article-type="research-article" dtd-version="1.2"><front><journal-meta><journal-id journal-id-type="nlm-ta">elife</journal-id><journal-id journal-id-type="publisher-id">eLife</journal-id><journal-title-group><journal-title>eLife</journal-title></journal-title-group><issn publication-format="electronic" pub-type="epub">2050-084X</issn><publisher><publisher-name>eLife Sciences Publications, Ltd</publisher-name></publisher></journal-meta><article-meta><article-id pub-id-type="publisher-id">69430</article-id><article-id pub-id-type="doi">10.7554/eLife.69430</article-id><article-categories><subj-group subj-group-type="display-channel"><subject>Research Article</subject></subj-group><subj-group subj-group-type="heading"><subject>Neuroscience</subject></subj-group></article-categories><title-group><article-title>Developmental changes in story-evoked responses in the neocortex and hippocampus</article-title></title-group><contrib-group><contrib contrib-type="author" corresp="yes" id="author-52477"><name><surname>Cohen</surname><given-names>Samantha S</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">https://orcid.org/0000-0003-3007-5372</contrib-id><email>samantha.s.cohen@gmail.com</email><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="other" rid="fund1"/><xref ref-type="fn" rid="con1"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" id="author-116115"><name><surname>Tottenham</surname><given-names>Nim</given-names></name><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="fn" rid="conf1"/><xref ref-type="fn" rid="con2"/></contrib><contrib contrib-type="author" id="author-241909"><name><surname>Baldassano</surname><given-names>Christopher</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">https://orcid.org/0000-0003-3540-5019</contrib-id><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="fn" rid="conf1"/><xref ref-type="fn" rid="con3"/></contrib><aff id="aff1"><label>1</label><institution-wrap><institution-id institution-id-type="ror">https://ror.org/00hj8s172</institution-id><institution>Department of Psychology, Columbia University</institution></institution-wrap><addr-line><named-content content-type="city">New York</named-content></addr-line><country>United States</country></aff></contrib-group><contrib-group content-type="section"><contrib contrib-type="editor"><name><surname>Kok</surname><given-names>Peter</given-names></name><role>Reviewing Editor</role><aff><institution-wrap><institution-id institution-id-type="ror">https://ror.org/02jx3x895</institution-id><institution>University College London</institution></institution-wrap><country>United Kingdom</country></aff></contrib><contrib contrib-type="senior_editor"><name><surname>de Lange</surname><given-names>Floris P</given-names></name><role>Senior Editor</role><aff><institution-wrap><institution-id institution-id-type="ror">https://ror.org/016xsfp80</institution-id><institution>Radboud University</institution></institution-wrap><country>Netherlands</country></aff></contrib></contrib-group><pub-date publication-format="electronic" date-type="publication"><day>05</day><month>07</month><year>2022</year></pub-date><pub-date pub-type="collection"><year>2022</year></pub-date><volume>11</volume><elocation-id>e69430</elocation-id><history><date date-type="received" iso-8601-date="2021-04-15"><day>15</day><month>04</month><year>2021</year></date><date date-type="accepted" iso-8601-date="2022-06-17"><day>17</day><month>06</month><year>2022</year></date></history><pub-history><event><event-desc>This manuscript was published as a preprint at .</event-desc><date date-type="preprint" iso-8601-date="2021-04-12"><day>12</day><month>04</month><year>2021</year></date><self-uri content-type="preprint" xlink:href="https://doi.org/10.1101/2021.04.12.439526"/></event></pub-history><permissions><copyright-statement>© 2022, Cohen et al</copyright-statement><copyright-year>2022</copyright-year><copyright-holder>Cohen et al</copyright-holder><ali:free_to_read/><license xlink:href="http://creativecommons.org/licenses/by/4.0/"><ali:license_ref>http://creativecommons.org/licenses/by/4.0/</ali:license_ref><license-p>This article is distributed under the terms of the <ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/licenses/by/4.0/">Creative Commons Attribution License</ext-link>, which permits unrestricted use and redistribution provided that the original author and source are credited.</license-p></license></permissions><self-uri content-type="pdf" xlink:href="elife-69430-v2.pdf"/><self-uri content-type="figures-pdf" xlink:href="elife-69430-figures-v2.pdf"/><abstract><p>How does the representation of naturalistic life events change with age? Here, we analyzed fMRI data from 414 children and adolescents (5–19 years) as they watched a narrative movie. In addition to changes in the degree of inter-subject correlation (ISC) with age in sensory and medial parietal regions, we used a novel measure (between-group ISC) to reveal age-related shifts in the responses across the majority of the neocortex. Over the course of development, brain responses became more discretized into stable and coherent events and shifted earlier in time to anticipate upcoming perceived event transitions, measured behaviorally in an age-matched sample. However, hippocampal responses to event boundaries actually decreased with age, suggesting a shifting division of labor between episodic encoding processes and schematic event representations between the ages of 5 and 19.</p></abstract><kwd-group kwd-group-type="author-keywords"><kwd>child development</kwd><kwd>inter-subject correlation</kwd><kwd>event segmentation</kwd><kwd>hippocampus</kwd><kwd>hidden Markov model</kwd><kwd>narrative</kwd></kwd-group><kwd-group kwd-group-type="research-organism"><title>Research organism</title><kwd>Human</kwd></kwd-group><funding-group><award-group id="fund1"><funding-source><institution-wrap><institution>Andrew Africk</institution></institution-wrap></funding-source><principal-award-recipient><name><surname>Cohen</surname><given-names>Samantha S</given-names></name></principal-award-recipient></award-group><funding-statement>The funders had no role in study design, data collection and interpretation, or the decision to submit the work for publication.</funding-statement></funding-group><custom-meta-group><custom-meta specific-use="meta-only"><meta-name>Author impact statement</meta-name><meta-value>Brain responses to a narrative movie change over the course of childhood and adolescence, shifting from event-boundary responses in the hippocampus to stable and anticipatory event representations in the neocortex.</meta-value></custom-meta></custom-meta-group></article-meta></front><body><sec id="s1" sec-type="intro"><title>Introduction</title><p>The ability to perceive and remember the world changes radically throughout the first twenty years of life (<xref ref-type="bibr" rid="bib4">Aslin and Smith, 1988</xref>; <xref ref-type="bibr" rid="bib73">Schneider and Pressley, 2013</xref>). Older children and adolescents are better able to understand and interpret the world around them, and anticipate upcoming situations (<xref ref-type="bibr" rid="bib13">Carpendale and Lewis, 2006</xref>; <xref ref-type="bibr" rid="bib14">Casillas and Frank, 2017</xref>; <xref ref-type="bibr" rid="bib69">Richardson and Saxe, 2020</xref>). Much of this increase in ability can be attributed to greater familiarity with the events that they are likely to encounter (<xref ref-type="bibr" rid="bib73">Schneider and Pressley, 2013</xref>). For instance, children have better memory for situations that they have expertise in (e.g. Chess; <xref ref-type="bibr" rid="bib16">Chi, 1978</xref>). Here, we characterize changes that occur in the brain’s response to complex naturalistic stimuli during this period of the acquisition of structured knowledge about the world.</p><p>Previous research has examined developmental changes in neural activity when learning principled relationships between items in a laboratory setting (<xref ref-type="bibr" rid="bib11">Brod et al., 2017</xref>). Children, however, normally acquire and organize novel information about their world over the course of weeks, if not years (<xref ref-type="bibr" rid="bib59">Nelson, 1986</xref>). Naturalistic narrative stimuli provide a tool for probing this complex, real-world knowledge that children have acquired across repeated experiences and can deploy automatically (<xref ref-type="bibr" rid="bib12">Cantlon and Li, 2013</xref>; <xref ref-type="bibr" rid="bib51">Lerner et al., 2019</xref>; <xref ref-type="bibr" rid="bib61">Petroni et al., 2018</xref>; <xref ref-type="bibr" rid="bib55">Moraczewski et al., 2018</xref>; <xref ref-type="bibr" rid="bib56">Moraczewski et al., 2020</xref>; <xref ref-type="bibr" rid="bib68">Richardson et al., 2019</xref>; <xref ref-type="bibr" rid="bib69">Richardson and Saxe, 2020</xref>; <xref ref-type="bibr" rid="bib81">Vanderwal et al., 2020</xref>).</p><p>We utilized functional magnetic resonance imaging (fMRI) data acquired while children and adolescents between the ages of 5 and 19 watched a short narrative cartoon that contained both social and emotional content (<xref ref-type="bibr" rid="bib2">Alexander et al., 2017</xref>; <xref ref-type="bibr" rid="bib61">Petroni et al., 2018</xref>). Although cartoons do not physically replicate the characteristics of everyday perception, there is evidence to suggest that children respond similarly to the social cues in cartoons and live action videos (<xref ref-type="bibr" rid="bib39">Han et al., 2007</xref>). Analyzing brain responses to complex stories or movies is challenging, since we do not yet have models that can predict brain-wide responses to these types of stimuli, especially given the fact that the representation of meaning likely changes with age (<xref ref-type="bibr" rid="bib17">Clark, 1973</xref>). A model-free approach to assess brain responses to this kind of stimuli is inter-subject correlation (ISC), which measures the similarity of brain responses in a brain region across movie viewers (<xref ref-type="bibr" rid="bib12">Cantlon and Li, 2013</xref>; <xref ref-type="bibr" rid="bib51">Lerner et al., 2019</xref>; <xref ref-type="bibr" rid="bib61">Petroni et al., 2018</xref>; <xref ref-type="bibr" rid="bib55">Moraczewski et al., 2018</xref>; <xref ref-type="bibr" rid="bib56">Moraczewski et al., 2020</xref>). ISC within an age group has generally been found to increase with age, possibly due to more mature engagement with the content, greater shared knowledge about the world, or more exposure to widely used cinematic conventions (<xref ref-type="bibr" rid="bib12">Cantlon and Li, 2013</xref>; <xref ref-type="bibr" rid="bib51">Lerner et al., 2019</xref>; <xref ref-type="bibr" rid="bib55">Moraczewski et al., 2018</xref>; <xref ref-type="bibr" rid="bib56">Moraczewski et al., 2020</xref>). We therefore measured ISC in parcels throughout the cortex (<xref ref-type="bibr" rid="bib72">Schaefer et al., 2018</xref>) to assess if processing becomes more similar with age. In line with previous studies, we hypothesized that the magnitude of ISC would increase with age, although decreases have been found in studies in other modalities (<xref ref-type="bibr" rid="bib61">Petroni et al., 2018</xref>).</p><p>ISC has also been measured between age groups to assess the similarity between the responses of children and adults (<xref ref-type="bibr" rid="bib12">Cantlon and Li, 2013</xref>; <xref ref-type="bibr" rid="bib51">Lerner et al., 2019</xref>; <xref ref-type="bibr" rid="bib55">Moraczewski et al., 2018</xref>). If a child is more similar to adults, they are considered more mature, and therefore likely to have better academic or social abilities (<xref ref-type="bibr" rid="bib12">Cantlon and Li, 2013</xref>; <xref ref-type="bibr" rid="bib55">Moraczewski et al., 2018</xref>). This previous work is consistent with the idea that children are simply noisy versions of adults, and the noise level decreases with age. We test an alternative hypothesis: that children and adolescents have <italic>different</italic> average response timecourses, corresponding to different age-related interpretations of the movie. We therefore employed a new across-group ISC measure that allows for comparisons across age groups while controlling for the degree of similarity within each age group. This allowed us to determine whether there was a consistent shift in the group-level temporal patterns of activity, independent of changes in within-group consistency. We hypothesized that in default mode network regions responsible for story interpretation and self-referential thought, even where within-age ISC magnitude does not change, the pattern of activity representing the movie will change across development, just as the semantic interpretation of movies changes with age (<xref ref-type="bibr" rid="bib59">Nelson, 1986</xref>; <xref ref-type="bibr" rid="bib65">Raichle et al., 2001</xref>).</p><p>How can we characterize the changes that are occurring in response timecourses? Although some knowledge of the hierarchical structure of the events that compose a narrative develops in infancy, the ability to reliably notice these events does not mature until at least the teenage years (<xref ref-type="bibr" rid="bib83">Yates et al., 2021</xref>; <xref ref-type="bibr" rid="bib84">Zacks and Tversky, 2001</xref>; <xref ref-type="bibr" rid="bib87">Zheng et al., 2020</xref>). It is likely that the characterization of events changes with age. We therefore asked both children and adults to subjectively report where they believed meaningful scene changes occurred in the narrative. We hypothesized that although there would be no change in the behaviorally reported location of these coarse-grained narrative segments, the neural representation of events along the cortical hierarchy would change with age.</p><p>Recent work in adults has shown that the neural activity evoked by narratives are characterized by stable patterns of responses, and that the moments of transition between stable patterns in association areas correspond to these meaningful boundaries between ‘events’' in a continuous perceptual stream (<xref ref-type="bibr" rid="bib6">Baldassano et al., 2020</xref>; <xref ref-type="bibr" rid="bib5">Baldassano et al., 2018</xref>; <xref ref-type="bibr" rid="bib15">Chen et al., 2017</xref>). These event patterns are driven in part by learned schematic scripts about common experiences in the world, such as the sequence of events that characterize a visit to a restaurant (<xref ref-type="bibr" rid="bib5">Baldassano et al., 2018</xref>).</p><p>We hypothesized that with age, the strength of schematic event representations, that are able to generalize across different instances of similar events, will increase due to more experience with different exemplars. These kinds of representations should be stored in default mode regions such as the medial prefrontal cortex and posterior medial cortex (PMC). Following previous research in adults, we assessed the ability of children of different ages to segment their world into discrete chunks with a Hidden Markov model (HMM; <xref ref-type="bibr" rid="bib6">Baldassano et al., 2020</xref>; <xref ref-type="bibr" rid="bib5">Baldassano et al., 2018</xref>; <xref ref-type="bibr" rid="bib50">Lee et al., 2021</xref>). We predicted that activity patterns will be more consistent among older subjects and become more stable across timepoints within events, providing a better fit to the HMM event segmentation model. If we do not find a general improvement in event model fits with age, this will refute the hypothesis that the schematic event representations that support event models are strengthened with age.</p><p>It is also likely that the timing of event transitions changes as a function of age. Activity in regions responsible for representing the viewpoints of others occurs earlier during the second presentation of a movie in children between six and seven years then in children between three and four years (<xref ref-type="bibr" rid="bib69">Richardson and Saxe, 2020</xref>). Here we test whether, on an <italic>initial</italic> viewing of a naturalistic video, the timing of event transitions varies with age. Unlike previous work that considered anticipation at only a fixed offset of two seconds (<xref ref-type="bibr" rid="bib69">Richardson and Saxe, 2020</xref>), the HMM-derived transition timings provide a flexible approach for detecting timing shifts between age groups that can vary across brain regions with different processing timescales (<xref ref-type="bibr" rid="bib6">Baldassano et al., 2020</xref>; <xref ref-type="bibr" rid="bib41">Hasson et al., 2015</xref>) and can vary across timepoints throughout the movie. In line with the idea that schematic event representations improve with age, older adolescents should be able to anticipate events further into the future due to their increased experience with the world.</p><p>Another characteristic of adult responses to narrative movies is the robust hippocampal activity evoked by boundaries between events (<xref ref-type="bibr" rid="bib6">Baldassano et al., 2020</xref>; <xref ref-type="bibr" rid="bib7">Ben-Yakov and Henson, 2018</xref>). Age-related changes in this signal have been previously observed in older adults, with response decreases between ages 18 and 88 in the posterior hippocampus (<xref ref-type="bibr" rid="bib67">Reagh et al., 2020</xref>). It is therefore possible that development of event-structured responses in the cortex is mirrored by changes in the hippocampus’s ability to respond to event transitions. We predicted that the magnitude of the hippocampal response to event boundaries would increase with age, in line with a model of maturation wherein the ability to encode the unique episodes of daily experience increase into middle age and then decreases with senescence (<xref ref-type="bibr" rid="bib37">Grady, 2012</xref>; <xref ref-type="bibr" rid="bib67">Reagh et al., 2020</xref>). However, should we find a decrease in the hippocampal response to event boundaries with age, this would provide support for the idea that younger children may focus on the episodic encoding processes responsible for encoding the specific details of events as they work towards creating more stable schematic event representations (<xref ref-type="bibr" rid="bib45">Keresztes et al., 2018</xref>; <xref ref-type="bibr" rid="bib52">Maril et al., 2010</xref>).</p></sec><sec id="s2" sec-type="results"><title>Results</title><p>We sought to uncover whether and how the neural representation of naturalistic stimuli change with age between 5 and 19 years. To accomplish this, we used a large, publicly available dataset (<xref ref-type="bibr" rid="bib2">Alexander et al., 2017</xref>) of functional magnetic resonance imaging (fMRI) data recorded while children watch a short video animation with both social and emotional themes. As the data were not equally distributed with age, the results are derived from equally sized subsamples from each age group (each with an age span of approximately 3 years). To maximize the power and reproducibility of the results, our analyses were averaged across five random subsamples from each age group (See Methods; <xref ref-type="bibr" rid="bib62">Poldrack et al., 2017</xref>).</p><p>We first measured inter-subject correlation (ISC) across all subjects, as well as within the youngest (5–8 years) and oldest (16–19 years) age groups, as a general measure of story comprehension and engagement (<xref ref-type="fig" rid="fig1s1">Figure 1—figure supplement 1</xref> and <xref ref-type="fig" rid="fig1s2">Figure 1—figure supplement 2</xref>; <xref ref-type="bibr" rid="bib58">Nastase et al., 2019</xref>). To statistically examine changes in this measure due to age, we compared ISCs for the youngest and oldest age groups, calculated within parcels (<xref ref-type="bibr" rid="bib72">Schaefer et al., 2018</xref>). We found (<xref ref-type="fig" rid="fig1">Figure 1</xref>) that ISC increases with age in low level sensory regions such as the auditory cortex, and decreases with age in some higher level association regions such as the retrosplenial cortex (RSC) portion of the PMC. To ensure that the increases in ISC with age are not due to differences in the level of noise between the groups, we measured the relationship between the framewise displacement of each child in the Youngest group and their ISC with the other subjects. There was no relationship between framewise displacement and ISC in any of the parcels where ISC increased with age, indicating that motion did not drive the result in these parcels (all q’s&gt;0.05).</p><fig-group><fig id="fig1" position="float"><label>Figure 1.</label><caption><title>Inter-subject correlation (ISC) increases with age in sensory regions and decreases with age in the PMC.</title><p>(<bold>a</bold>) Within-group ISC was computed for five distinct age groups, and a statistical comparison was performed between the Oldest and Youngest age groups. (<bold>b</bold>) The difference in ISC between the Youngest (5–8years) group and the Oldest (16–19years) group is displayed in significant parcels (q&lt;0.05) on the cortical surface. ISCs for all age groups are plotted for four significant parcels, selected post hoc for illustration, along with the ISC difference between the Youngest and Oldest groups compared to the null distribution.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-69430-fig1-v2.tif"/></fig><fig id="fig1s1" position="float" specific-use="child-fig"><label>Figure 1—figure supplement 1.</label><caption><title>Inter-subject correlation (ISC) across a random mixture of the Youngest and Oldest subjects.</title><p>(<bold>a</bold>) Schematic illustration of the correlation for each parcel between subjects in the Youngest (5–8 years) and Oldest (16–19 years) groups. (<bold>b</bold>) ISC in parcels on the cortical surface.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-69430-fig1-figsupp1-v2.tif"/></fig><fig id="fig1s2" position="float" specific-use="child-fig"><label>Figure 1—figure supplement 2.</label><caption><title>Inter-subject correlation (ISC) within the Youngest and Oldest subjects.</title><p>ISC is displayed separately in parcels across the cortical surface for subjects in the Youngest (5–8 years) and Oldest (16–19 years) groups. Both age groups show a similar pattern of ISC increasing from sensory to anterior regions.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-69430-fig1-figsupp2-v2.tif"/></fig><fig id="fig1s3" position="float" specific-use="child-fig"><label>Figure 1—figure supplement 3.</label><caption><title>The demographic breakdown of the subject groups studied.</title><p>The “Oldest” age group (16–19 years) had only 40 subjects. All other age groups contained a sub-sample of 40 subjects whose gender distribution matched that of the Oldest group. The counts of male and female subjects are overlapping.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-69430-fig1-figsupp3-v2.tif"/></fig></fig-group><p>In most of the cortex, there is no difference in ISC magnitude as a function of age, which could indicate that children of all ages engage similarly with the movie (<xref ref-type="bibr" rid="bib61">Petroni et al., 2018</xref>). It is also possible, however, that responses are highly consistent within each age group but differ systematically across age groups. For instance, it is possible that the most salient features of the video change with age, eliciting responses that are predictable within an age group but different across groups. To get a pure measure of across-group similarity that is insensitive to within-group variation, we use a novel measure called between-group ISC (ISC<sub>b</sub>; see Appendix 1) (<xref ref-type="fig" rid="fig2">Figure 2a</xref>). To calculate the correlation between groups, ISC<sub>b</sub> is computed by dividing the between-group (Youngest to Oldest) correlation by the geometric mean of the within-group correlation (<xref ref-type="fig" rid="fig2">Figure 2b</xref>).</p><fig id="fig2" position="float"><label>Figure 2.</label><caption><title>Stimulus processing differs in semantic and default mode regions between the Youngest and Oldest ages.</title><p>(<bold>a</bold>) Response timecourses were correlated within the Oldest and Youngest groups separately, and also correlated between groups. (<bold>b</bold>) For each parcel, between-group ISC (ISC<sub>b</sub>) is calculated by dividing the across-group correlation by the geometric mean of the within-group correlation. This allows us to identify regions in which the correlations between groups are smaller than we would expect based on the within-group similarities, reflecting differing mean responses across groups. (<bold>c</bold>) The Youngest and Oldest groups are most dissimilar (indicated by darker colors) in regions in the default mode network, such as the temporoparietal junction, and in regions responsible for semantic processing, such as the inferior temporal cortices, temporoparietal junction, and dorsolateral prefrontal cortex (parcels shown have ISC<sub>b</sub> values less than age-shuffled null permutations, thresholded at q&lt;0.05).</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-69430-fig2-v2.tif"/></fig><p>Eighty-one of the 100 (<xref ref-type="bibr" rid="bib72">Schaefer et al., 2018</xref>) parcels tested show significant age-specific response timecourses including default mode regions, such as the temporoparietal junction (TPJ) and PMC (<xref ref-type="bibr" rid="bib65">Raichle et al., 2001</xref>), and language and concept sensitive regions, such as the dorsolateral prefrontal cortex (dlPFC) and inferior temporal cortices, and orbitofrontal cortex (<xref ref-type="bibr" rid="bib10">Binder and Desai, 2011</xref>; <xref ref-type="bibr" rid="bib66">Ralph et al., 2017</xref>; <xref ref-type="fig" rid="fig2">Figure 2c</xref>).</p><p>This result demonstrates that responses are changing substantially with age in many brain regions, but does not indicate <italic>how</italic> these responses are changing. One possibility is that the interpretation of the events and scenes in the narrative changes with age. We therefore assessed when adults and children, age-matched to the fMRI sample, report that an event in the narrative has finished, and a new event has begun. There are small but significant differences in the timing of the event boundaries marked by adults and children (ISC<sub>b</sub> = 0.97, p=0.009). This discrepancy was true for both the younger and older children, separated by a median split based on age (adult-older children ISC<sub>b</sub> = 0.95, adult-younger children ISC<sub>b</sub> = 0.91, both p’s&lt;1 × 10<sup>–5</sup>). The timing of event boundaries was also slightly, but significantly different between the younger half and older half of the children (ISC<sub>b</sub> = 0.96, p=0.01, <xref ref-type="fig" rid="fig3">Figure 3</xref>). Given this overall similarity in behavior, we next ask whether there are differences in how these events are represented and tracked in the brain.</p><fig id="fig3" position="float"><label>Figure 3.</label><caption><title>Event boundary alignment between children and adults.</title><p>The proportion of Adult, Older Children, and Younger Children raters who marked a boundary during the stimulus. Colored lines indicate the event durations and boundaries agreed upon by at least half of a group of independent adult raters (see Methods). Brief descriptions of each scene are written in italics.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-69430-fig3-v2.tif"/></fig><p>In adults, movie responses are often characterized by rapid transitions between stable periods of brain activity, corresponding to meaningful events in the narrative (<xref ref-type="bibr" rid="bib6">Baldassano et al., 2020</xref>; <xref ref-type="bibr" rid="bib15">Chen et al., 2017</xref>). To identify the extent of this temporal clustering in our data, and the timescale of this clustering, we use a Hidden Markov Model (HMM) (<xref ref-type="bibr" rid="bib6">Baldassano et al., 2020</xref>). Fitting the HMM separately to the Youngest and Oldest groups, we found that the HMM was able to identify event structure in at least one of the groups (Youngest and/or Oldest) for 70 out of our 100 parcels (<xref ref-type="fig" rid="fig5s1">Figure 5—figure supplement 1</xref>). In these 71 parcels, we found that the optimal timescale (optimal number of events) was highly correlated between the Youngest and Oldest ages (<italic>r</italic>=0.78, RMS difference between groups = 12.3 s), showing increasing timescales from sensory regions to higher level association regions (<xref ref-type="fig" rid="fig5s2">Figure 5—figure supplement 2</xref>). This replicates previous research showing increasing event timescales across the cortical hierarchy (<xref ref-type="bibr" rid="bib6">Baldassano et al., 2020</xref>; <xref ref-type="bibr" rid="bib34">Geerligs et al., 2021</xref>; <xref ref-type="bibr" rid="bib41">Hasson et al., 2015</xref>), and shows that this timescale hierarchy is present even in our Youngest (5–8 years) age group.</p><p>As all 71 parcels had similar timescales in both groups, we jointly fit an HMM (with the parcel’s optimal number of events) simultaneously to the Youngest and Oldest groups. As expected based on previous research in adults, the event boundaries from this model correspond to the boundaries subjectively placed by human raters in association regions, such as PMC, TPJ, and precuneus (<xref ref-type="fig" rid="fig5s3">Figure 5—figure supplement 3</xref>; <xref ref-type="bibr" rid="bib6">Baldassano et al., 2020</xref>). The jointly fit HMM produced an ordered set of event patterns which were shared across both groups (<xref ref-type="fig" rid="fig4">Figure 4a</xref>). We then tested this event model in held-out subjects, allowing us to measure in each group: (1) the model fit (log likelihood on held-out data), indicating the extent to which brain responses could be explained as an ordered sequence of these stable event patterns (<xref ref-type="fig" rid="fig4">Figure 4b–c</xref>), and (2) the timing of event transitions. We hypothesized that the Oldest subjects would have a better model fit than the Youngest subjects, indicating increased stability and reliability of event representations. We also hypothesized that the Oldest group would exhibit earlier event transitions than the Youngest group, due to predictive, anticipatory, or preparatory processes (<xref ref-type="bibr" rid="bib13">Carpendale and Lewis, 2006</xref>; <xref ref-type="bibr" rid="bib50">Lee et al., 2021</xref>; <xref ref-type="bibr" rid="bib69">Richardson and Saxe, 2020</xref>).</p><fig id="fig4" position="float"><label>Figure 4.</label><caption><title>Measuring fits to the HMM event model.</title><p>(<bold>a</bold>) The Hidden Markov Model (HMM) assumes that brain activity in response to a movie should proceed through a specific sequence of stable event patterns, each with a specific pattern of high and low activities across voxels (represented here as the saturation of each color). (<bold>b</bold>) The model is a good fit to brain responses that exhibit patterns consistent with the model assumptions, sequentially transitioning between the HMM event patterns with little variability during events. (<bold>c</bold>) A poor model fit indicates that this event model does not capture a brain region’s dynamics, because the order of the relative activity levels does not match the model’s sequence of event patterns (Voxel 1), the event transitions do not align between voxels (Voxel 2), or there is high within-event variability (across time or across subjects) (Voxel 3).</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-69430-fig4-v2.tif"/></fig><p>As hypothesized, the neural activity of the Oldest group can be better represented by an event model in most of the parcels that significantly differ with age. These regions include sensory areas, such as the auditory and visual cortex, as well as the left parietal operculum and dlPFC (<xref ref-type="fig" rid="fig5">Figure 5</xref>). In sensory regions, the largest change in event model-fit occurs between children 5–8 years and those 8–11 years (<xref ref-type="fig" rid="fig5">Figure 5</xref>, side panels). The left parietal operculum increases in model-fit through approximately age 13. These developmental trajectories hold not just for these regions' optimal event timescale, but also across a wide range of event timescales (<xref ref-type="fig" rid="fig5">Figure 5</xref>, side panels). Surprisingly, the HMM exhibits better model fits in the PMC, including both the posterior cingulate cortex (PCC) and RSC, for the Youngest group than the Oldest group. These results partially reflect changes in across-subject consistency as identified by the model-free ISC analysis (<xref ref-type="fig" rid="fig1">Figure 1</xref>), but also show effects in additional regions including the dlPFC.</p><fig-group><fig id="fig5" position="float"><label>Figure 5.</label><caption><title>The Oldest group has better event models in regions including visual cortex and auditory cortex, whereas the Youngest group has a better model-fit in PMC.</title><p>Regions with a significant model-fit difference between the youngest and oldest age group (at the optimal timescale for that region) are plotted on the cortical surface. Redder shades indicate that the event model fits improve with age, and bluer shades indicate that they weaken with age. The model fits for event models with different event durations are shown across all age groups and event durations in four example regions, selected post hoc for illustration. Error bars represent the standard deviation of model fit in the held out subjects, averaged across five cross-validated folds.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-69430-fig5-v2.tif"/></fig><fig id="fig5s1" position="float" specific-use="child-fig"><label>Figure 5—figure supplement 1.</label><caption><title>Comparing the model-fit difference for all parcels between the Youngest and Oldest ages.</title><p>The model-fit difference is the difference in log-likelihood between the HMM for two events (expected to fit poorly), and the HMM with maximal model-fit (the best fitting number of events). (<bold>a</bold>) Parcels within the box in the lower left-hand corner of the scatter plot did not capture event structure in either age group (model fit differences smaller than 0.002), and were therefore excluded from the HMM-based analyses. (<bold>b</bold>) The model-fit difference is displayed in cortical parcels for both the Youngest and Oldest ages.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-69430-fig5-figsupp1-v2.tif"/></fig><fig id="fig5s2" position="float" specific-use="child-fig"><label>Figure 5—figure supplement 2.</label><caption><title>The best-fitting average duration of events for the optimal HMMs trained and tested on either the Youngest or the Oldest ages.</title><p>The average event duration increases from sensory to association parcels for both age groups and the average event durations are highly correlated between the groups (<italic>r</italic>=0.78, RMS difference between groups = 12.3 seconds). Only parcels that had good model-fits in at least one age group (see <xref ref-type="fig" rid="fig1s2">Figure 1—figure supplement 2</xref>) are shown.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-69430-fig5-figsupp2-v2.tif"/></fig><fig id="fig5s3" position="float" specific-use="child-fig"><label>Figure 5—figure supplement 3.</label><caption><title>The HMM-derived event boundaries correlate with behaviorally estimated event boundaries from children.</title><p>The event boundaries determined by the HMM jointly-fit to both the Youngest and Oldest groups correspond to behaviorally estimated event boundaries in association regions such as PMC, TPJ, and precuneus. All parcels for which a jointly fit HMM was modeled are displayed.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-69430-fig5-figsupp3-v2.tif"/></fig></fig-group><p>We also expected that event boundaries would occur earlier in time with age, because adolescents are more experienced with real-world schemas and can thus predictively represent upcoming situations. This hypothesis was borne out in sensory regions including auditory and visual cortex, as well as left lateralized associative regions including the left precuneus and left dlPFC (<xref ref-type="fig" rid="fig6">Figure 6a</xref>). Sensory regions are predictive at shorter time scales, consistent with their quicker processing speed (<xref ref-type="bibr" rid="bib6">Baldassano et al., 2020</xref>; <xref ref-type="bibr" rid="bib41">Hasson et al., 2015</xref>; <xref ref-type="bibr" rid="bib50">Lee et al., 2021</xref>), while the higher level association regions anticipate upcoming events on average up to tens of seconds into the future. This anticipation increases rapidly across ages 5–11 in the left dlPFC and left precuneus, with a more variable trajectory in left postcentral sulcus (side panels). However, as was seen for model-fit, this trend reverses in the right ventral temporal cortex where the Youngest children anticipate upcoming events slightly sooner, and anticipation decreases almost linearly with age.</p><fig id="fig6" position="float"><label>Figure 6.</label><caption><title>The timing of event boundaries shifts with age.</title><p>(<bold>a</bold>) The Oldest group represents upcoming events before the Youngest group in auditory and visual cortex, as well as left lateralized associative regions including the left precuneus and left dorsolateral prefrontal cortex (reddish hues). The Youngest group anticipates events sooner in the right ventral temporal cortex (bluish hues). Highlighted parcels showing age anticipation trajectories were selected post hoc for illustration. (<bold>b</bold>) The event boundaries in the brains of the Oldest group generally lead behaviorally-derived event boundaries, whereas the transitions in the brains of the Youngest group generally lag behind behavior. In both (<bold>a</bold>) and (<bold>b</bold>), the parcels shown have differences greater than age shuffled permutations (q&lt;0.05).</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-69430-fig6-v2.tif"/></fig><p>To determine whether developmental changes in the timing of event transitions reflect an increased level of anticipation in the Oldest group, or, alternatively, a delayed response in the Youngest group, we compared the HMM-derived event boundaries to event transitions behaviorally identified by an age-matched group of children. Across the cortex we find that the Oldest ages generally anticipate event shifts, while the Youngest ages lag behind them to some degree (<xref ref-type="fig" rid="fig6">Figure 6b</xref>).</p><p>Finally, we asked whether hippocampal responses differ as a function of age at the event boundaries reported by our age-matched sample of children. We found a robust response to event boundaries in all ages (all p’s&lt;0.0001 for each age group’s response at time 0, see <xref ref-type="fig" rid="fig7">Figure 7a</xref>, right side). This response decreases with age between 5 and 19 years old (<italic>r</italic>=0.–16, p=1 × 10<sup>–3</sup>, N=414; <xref ref-type="fig" rid="fig7">Figure 7a</xref>). As previous research has indicated that the anterior and posterior HPC may potentially respond differently to event boundaries (<xref ref-type="bibr" rid="bib67">Reagh et al., 2020</xref>), we examined whether the anterior or posterior HPC were driving this change in boundary-driven response with age. We found that there is a significant decrease in the anterior hippocampal (aHPC) response to event boundaries with age (<italic>r</italic>=−0.18, p=2 × 10<sup>–4</sup>, <xref ref-type="fig" rid="fig7">Figure 7b</xref>). We did not find a significant decrease in the posterior HPC (pHPC; <italic>r</italic>=−0.09, p=0.06, <xref ref-type="fig" rid="fig7">Figure 7c</xref>), nor a significant interaction between HPC subregions (p=0.7). In none of these regions was the change in boundary-related response explained by anatomical volume changes (see Methods).</p><fig id="fig7" position="float"><label>Figure 7.</label><caption><title>The hippocampus in children as young as 5 responds to event boundaries, an effect that decreases with age.</title><p>(<bold>a</bold>) The event-boundary driven response decreases as a function of age in the hippocampus (HPC). This can be shown across individuals at the time point where hippocampus-to-event correlation is maximal (left), and throughout the time-course of the HPC’s correlation with event boundaries. (<bold>b</bold>) The correlation between the HPC and event boundaries significantly decreases with age in the anterior HPC (aHPC), but in (<bold>c</bold>) posterior HPC (pHPC) there is no significant relationship between the boundary-driven signal and age. The shaded region surrounding each line represents the 95% confidence interval across all 415 subjects.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-69430-fig7-v2.tif"/></fig></sec><sec id="s3" sec-type="discussion"><title>Discussion</title><p>Using a novel measure of response similarity, we found that the processes used to perceive a dynamic narrative change from ages 5–19 throughout the majority of the neocortex and in the hippocampus. These developmental changes are characterized by increasingly event-structured dynamics in the neocortex, with periods of stability punctuated by rapid transitions, and anticipatory shifts in event timing. In parallel, hippocampal responses at event boundaries <italic>decrease</italic> in magnitude with age. These changes suggest that the brain’s strategy for narrative processing shifts from encoding each event as a novel episode in the hippocampus to activating and maintaining generalized event knowledge in the cortex, storing only episode-specific information into long-term memory.</p><p>Older ages exhibit more across-subject synchrony in auditory cortex (<xref ref-type="fig" rid="fig1">Figure 1</xref>), consistent with prior work showing developmental increases in ISC evoked by other similarly highly produced animated movies (<xref ref-type="bibr" rid="bib55">Moraczewski et al., 2018</xref>). These results are likely related to more strongly correlated semantic processing in adolescents, resulting in top-down increases in auditory understanding (<xref ref-type="bibr" rid="bib32">Franchak et al., 2016</xref>; <xref ref-type="bibr" rid="bib46">Kirkorian et al., 2012</xref>). Unfortunately, as eye movements were not recorded, we cannot establish the relationship between eye movements and synchrony in sensory cortex (<xref ref-type="bibr" rid="bib2">Alexander et al., 2017</xref>). The growth of coordinated responses with age may also drive the stronger event models in these regions (<xref ref-type="fig" rid="fig5">Figure 5</xref>). The ISC<sub>b</sub> analysis (<xref ref-type="fig" rid="fig2">Figure 2</xref>) found relatively small but significant shifts in the group-level responses in sensory regions, and auditory responses shifted slightly earlier in time with age (<xref ref-type="fig" rid="fig6">Figure 6</xref>). This indicates that the age-related changes in sensory regions are not only largely characterized by increasing synchrony across subjects, but also (to some extent) a shift from a more child-like to more adult-like timecourse of responses.</p><p>Theory of mind regions responsible for representing the mental states of others (<xref ref-type="bibr" rid="bib33">Gallagher et al., 2000</xref>; <xref ref-type="bibr" rid="bib71">Saxe and Kanwisher, 2003</xref>), including TPJ (<xref ref-type="bibr" rid="bib70">Samson et al., 2004</xref>), develop immensely in the age range studied (<xref ref-type="bibr" rid="bib74">Sebastian et al., 2012</xref>). We found very large age-related changes in the functional responses of TPJ (<xref ref-type="fig" rid="fig2">Figure 2</xref>). Older children, due to stronger schematic event representations, are likely able to construct better internal models of social and emotional structure (<xref ref-type="bibr" rid="bib28">Dumontheil et al., 2010</xref>; <xref ref-type="bibr" rid="bib60">Pavias et al., 2016</xref>), allowing them to form more cohesive models of the world. Previous work found that responses in a network of regions, including TPJ, shift approximately 2 s earlier when 6–7 year-olds watch a movie for a second time (<xref ref-type="bibr" rid="bib68">Richardson et al., 2019</xref>). In the right posterior-superior temporal sulcus (part of TPJ as defined by <xref ref-type="bibr" rid="bib27">Dufour et al., 2013</xref>) and in the TPJ-adjacent left postcentral sulcus, we found that neural representations in 16–19 year-olds can be as far as 20 s ahead of those for 5–8 year-olds on the <italic>first</italic> viewing of a movie clip. This reveals a protracted development in this region, likely due to continued growth in the ability to proactively represent the minds of others (<xref ref-type="bibr" rid="bib28">Dumontheil et al., 2010</xref>; <xref ref-type="bibr" rid="bib60">Pavias et al., 2016</xref>), or possibly due to a growth in attentional abilities in this region more generally (<xref ref-type="bibr" rid="bib20">Corbetta and Shulman, 2002</xref>; <xref ref-type="bibr" rid="bib25">Downar et al., 2001</xref>).</p><p>We also found age-related shifts in dlPFC (<xref ref-type="fig" rid="fig2">Figure 2</xref>) and increasing anticipation from ages 5–11 (<xref ref-type="fig" rid="fig6">Figure 6</xref>). This region, along with other regions showing age-related shifts such as the inferior temporal cortex and orbitofrontal cortex, are a part of a network responsible for processing conceptual knowledge about the world (<xref ref-type="bibr" rid="bib9">Binder et al., 2009</xref>). The age-driven differences in story responses may therefore be partially due to changes in the understanding of the people, actions, and culture presented in the movie (<xref ref-type="bibr" rid="bib9">Binder et al., 2009</xref>). The dlPFC is also critical for working memory, or the ability to keep recently learned information readily accessible (<xref ref-type="bibr" rid="bib22">Curtis and D’Esposito, 2003</xref>). The dlPFC exhibits an improvement in event structure with age (<xref ref-type="fig" rid="fig5">Figure 5</xref>), which may be due to the ongoing development of working memory (<xref ref-type="bibr" rid="bib48">Kwon et al., 2002</xref>), a cognitive function necessary to chunk incoming information into discrete events (<xref ref-type="bibr" rid="bib18">Clewett et al., 2019</xref>). The changes in dlPFC may also be related to development of theory of mind as discussed above, as it overlaps with the theory of mind network identified by <xref ref-type="bibr" rid="bib68">Richardson et al., 2019</xref>.</p><p>In the PMC event model fits worsened with age (<xref ref-type="fig" rid="fig5">Figure 5</xref>), and in the more posterior RSC portion, reliability also decreased with age (<xref ref-type="fig" rid="fig1">Figure 1</xref>). This finding contrasts with our hypothesis that schematic event representations should increase with age in regions such as the PMC. One possible reason for this discrepancy is that PMC performs additional processing due to its lack of strong schemas about observed events; <xref ref-type="bibr" rid="bib44">Keidel et al., 2018</xref> found that the PMC (RSC) had significantly more activity in response to movies when the narrative topic was new than when it was a continuation of themes from the previous clip. Younger children may therefore more consistently rely on this region to understand a relatively more novel environment. RSC is also known to be responsible for processing visual scenes and is fully developed by age 7 (<xref ref-type="bibr" rid="bib29">Epstein and Baker, 2019</xref>; <xref ref-type="bibr" rid="bib54">Meissner et al., 2019</xref>). It is therefore possible that young children are more consistently reliant on spatial scene representations as they process an ongoing narrative. PMC has an intrinsically long timescale for information processing, one that emerges in infancy, which may thus support strong event models in children as young as five (<xref ref-type="bibr" rid="bib41">Hasson et al., 2015</xref>; <xref ref-type="bibr" rid="bib76">Stephens et al., 2013</xref>; <xref ref-type="bibr" rid="bib83">Yates et al., 2021</xref>). However, we did find both age-related shifts in the pattern by which the narrative was represented bilaterally (<xref ref-type="fig" rid="fig2">Figure 2</xref>) and increased anticipation in the left PMC (<xref ref-type="fig" rid="fig6">Figure 6</xref>). These findings in the more dorsal portion of PMC are notable because there were no significant age-related differences in this region, suggesting that these shifts are not due to overall changes in attention or executive function. This result is in line with our hypothesis that increasing age is associated with more anticipation of higher level themes, and different ages likely process these themes with a different overall pattern of activity.</p><p>We found small, but significant changes in the timecourse of narrative processing in the medial prefrontal cortex (<xref ref-type="fig" rid="fig2">Figure 2</xref>). This region has been previously implicated in tracking schematic knowledge during movie-watching (<xref ref-type="bibr" rid="bib5">Baldassano et al., 2018</xref>; <xref ref-type="bibr" rid="bib80">van Kesteren et al., 2010</xref>), suggesting that schematic responses evolve across this age range. However, we surprisingly did not find a change in the strength of event representations with age. This may be due to an overall low level of ISC in this region, either due to idiosyncratic cognition, inconsistent neuroanatomy across subjects, or noisy signals in this region (<xref ref-type="fig" rid="fig1s1">Figure 1—figure supplement 1</xref>), making it challenging to study this region using the group-level approaches in this study. This result is not entirely unexpected given that previous studies have found low levels of ISC in this region (<xref ref-type="bibr" rid="bib6">Baldassano et al., 2020</xref>), especially in developmental populations (<xref ref-type="bibr" rid="bib51">Lerner et al., 2019</xref>; <xref ref-type="bibr" rid="bib55">Moraczewski et al., 2018</xref>). Furthermore, as has been found previously, it may be that only a subregion of the medial prefrontal cortex represents events (<xref ref-type="bibr" rid="bib6">Baldassano et al., 2020</xref>; <xref ref-type="bibr" rid="bib11">Brod et al., 2017</xref>; <xref ref-type="bibr" rid="bib53">Masís-Obando et al., 2022</xref>; <xref ref-type="bibr" rid="bib80">van Kesteren et al., 2010</xref>).</p><p>The HPC was found to reliably respond to the boundaries between events (<xref ref-type="fig" rid="fig7">Figure 7</xref>). This result extends evidence that the HPC tracks event changes in adults to children as young as five (<xref ref-type="bibr" rid="bib7">Ben-Yakov and Henson, 2018</xref>; <xref ref-type="bibr" rid="bib6">Baldassano et al., 2020</xref>; <xref ref-type="bibr" rid="bib67">Reagh et al., 2020</xref>). This boundary-triggered response decreased with age across our sample, which is surprising given that adolescents have stronger event models and event anticipation in most of the cortical regions with significant effects. The decrease in HPC responsiveness with age may be a signature of age-related increases in the reliance on schematic representations of the environment which are stored in the cortex, thus decreasing the reliance on the HPC to encode newly encountered events (<xref ref-type="bibr" rid="bib75">Sekeres et al., 2018</xref>). The HPC may thus have a more robust signal in young children who need to focus on encoding the specific details of events as they use them to extract commonalities across experiences (<xref ref-type="bibr" rid="bib45">Keresztes et al., 2018</xref>; <xref ref-type="bibr" rid="bib52">Maril et al., 2010</xref>). Likewise, the HPC has been shown to have increased activity during memory consolidation, and in response to novel events (<xref ref-type="bibr" rid="bib57">Nadel and Moscovitch, 1997</xref>; <xref ref-type="bibr" rid="bib77">Stern et al., 1996</xref>). It is possible that younger children found the events in the movie generally more novel, or needed to spend more effort consolidating them due to their impoverished schematic representations. However, if this was truly a novelty-related response we would have expected to see a greater age-related change in the pHPC which has been shown to be more responsive to novelty (<xref ref-type="bibr" rid="bib77">Stern et al., 1996</xref>).</p><p>Interestingly, previous research in older adults also found a decrease in the HPC response to event boundaries (<xref ref-type="bibr" rid="bib67">Reagh et al., 2020</xref>). However, in this previous research the decrease with age was seen in the pHPC (<xref ref-type="bibr" rid="bib67">Reagh et al., 2020</xref>). Here, we find that only the response in the aHPC significantly decreases with age. This shift in age-related decline may be due to the developmental changes in the mnemonic roles along the long axis of the HPC (<xref ref-type="bibr" rid="bib24">Demaster and Ghetti, 2013</xref>; <xref ref-type="bibr" rid="bib49">Langnes et al., 2019</xref>). The decline in the response of the aHPC may also be related to the process of semanticization (<xref ref-type="bibr" rid="bib75">Sekeres et al., 2018</xref>), whereas older ages may be experiencing age-related mnemonic, and thus perceptual declines (<xref ref-type="bibr" rid="bib67">Reagh et al., 2020</xref>).</p><p>Jointly fitting an HMM across children of different ages was sensible because we found that the optimal event timescales in all regions with high model fits were similar between the Youngest and Oldest groups. This was not a foregone conclusion, because infants under one year of age segment ongoing narratives into far fewer events than adults (<xref ref-type="bibr" rid="bib83">Yates et al., 2021</xref>) and behaviorally, we found small, but significant differences in segmentation behavior between adults and children, and children of different ages. However, at least neurally, children therefore develop enough narrative comprehension to segment the story in an adult-like manner by age five.</p><p>Although we largely attribute the better segmentation ability and prediction to adolescents’ greater experience with the world in general, it is possible that our Oldest cohort also had more previous experience watching the specific stimulus used (a clip from &quot;Despicable Me&quot;), as it was first released when they were young children themselves. Alternatively, younger children may have had more recent exposure to the film because it was more age appropriate for them, and this may have elicited a retrieval induced increase in HPC activity. Future research should collect data on prior stimulus exposure or aim to use stimulus-naive subjects for better control. Furthermore, we cannot distinguish whether the improvements that we see with age are due to the overall maturation of the brain or the increased life experience that underlies schematic knowledge. Additionally, although we chose to use this dataset because it is one of the few large databases of movie-watching in a developmental population, the subjects recruited for this study had a high prevalence of psychopathology and limited socioeconomic diversity. Future work should generalize our findings to more diverse and representative subject samples. Finally, our analyses require stimuli that exhibit multiple transitions between events that are at least 30 s. We were therefore unable to make use of the other movie available in this dataset or data from the short video clips used in other developmental datasets (<xref ref-type="bibr" rid="bib2">Alexander et al., 2017</xref>; <xref ref-type="bibr" rid="bib68">Richardson et al., 2019</xref>). Future studies should seek to generalize these results to stimuli with greater content diversity, and duration.</p><p>Our results reveal that brain responses to a narrative movie do not simply become more synchronized across children as they age, but in fact change their dynamics and timing to become more adult-like. Brain activity patterns in many regions become more cleanly structured into discrete, consistent events, and the timing of these events shifts to anticipate upcoming content in the movie. We also found that hippocampal responses to event boundaries are present in children as young as 5 years old, and that these event-boundary responses are in fact larger in children than in adolescents. This study provides the groundwork for assessing how children acquire schematic knowledge about the world and ultimately deploy that knowledge at the appropriate time.</p></sec><sec id="s4" sec-type="materials|methods"><title>Materials and methods</title><sec id="s4-1"><title>Participants</title><p>The data in these analyses was downloaded from the Child Mind Institute’s Health Brain Network (HBN) project (<xref ref-type="bibr" rid="bib2">Alexander et al., 2017</xref>) when 1758 MRI datasets were available (data release 6). All participants provided written consent or assent, and consent was obtained from the parents or legal guardians for participants younger than 18 years. The goal of the HBN project was to collect data from subjects with heterogeneous developmental psychopathologies. As such, although the demographics and prevalence of psychopathology may not be representative of the general population, this is one of the largest developmental datasets collected while children viewed natural stimuli, and it therefore allows us to do the novel analyses outlined below. The HBN project was approved by the Chesapeake Institutional Review Board. No task functional magnetic resonance imaging (fMRI) data was available for 343 subjects. Of the remaining subjects, 803 subjects were rejected because they did not contain recordings for one of the two possible movie stimuli, they lacked one of the two possible fieldmap scans, or one of the two movies had a different number of time samples than was expected if the subject watched the entire movie. Of the remaining subjects, 183 were rejected due to unacceptably poor T1 scans, as assessed by four independent raters. Two additional subjects were eliminated as the field of view of the acquisition did not cover the whole brain, one subject was eliminated due to a damaged T1 file, and one subject was eliminated due to median framewise displacement greater than three standard deviations above the mean. Four hundred and twenty six subjects remained after these eliminations. To allow for a sufficient number of subjects (N=40) in each age group spanning 2.76 years, with an equivalent ratio of males to females in each age group, subjects older than 19 were not used in further analyses (N=11). Most analyses were computed on gender-matched (22 males) samples of the Youngest (5.04–7.8 years, rounded in displays to 5–8 years) and Oldest (16.10–18.87 years, rounded in displays to 16–19 years) subjects, although illustrative analyses were also computed on the intermediate age groups. The subjects were not evenly distributed across the age groups (<xref ref-type="fig" rid="fig1s3">Figure 1—figure supplement 3</xref>). Many different groups of 40 subjects could therefore be drawn from the Youngest group (N=87, 47 males). Since the results change slightly depending on which group of 40 was selected, we conducted our analyses on the average of five random subsamples of each age group.</p></sec><sec id="s4-2"><title>MRI data collection</title><p>Magnetic Resonance Imaging (MRI) data used in this study were collected at both the HBN Rutgers University Brain Imaging Center site on a Siemens Trio Tim 3T scanner and the HBN CitiGroup Cornell Brain Imaging Center site on a Siemens Prisma 3T scanner. The scan parameters at both sites were identical: TR = 800ms, TE = 30ms, # slices = 60, flip angle = 31°, # volumes = 750, voxel size = 2.4 mm. Complete information regarding the scan parameters used for the Healthy Brain Network project can be found at: <ext-link ext-link-type="uri" xlink:href="http://fcon_1000.projects.nitrc.org/indi/cmi_healthy_brain_network/MRI%20Protocol.html">http://fcon_1000.projects.nitrc.org/indi/cmi_healthy_brain_network/MRI%20Protocol.html</ext-link>.</p></sec><sec id="s4-3"><title>Stimulus and event rating</title><p>fMRI data were collected while participants viewed a 10 min clip from the movie <italic>Despicable Me</italic> (01:02:09–01:12:09; presentation details available at <ext-link ext-link-type="uri" xlink:href="http://fcon_1000.projects.nitrc.org/indi/cmi_healthy_brain_network/MRI%20Protocol.html">http://fcon_1000.projects.nitrc.org/indi/cmi_healthy_brain_network/MRI%20Protocol.html</ext-link>). To obtain the timing of event boundaries, a separate group of 21 adult raters (6 males) watched the clip and were given the following instructions: “The movie clip can be divided into meaningful segments. Record the times (in seconds) denoting when you feel like a meaningful segment has ended. Pause the clip at the end of the segment, write down the time in the attached spreadsheet, and provide a short, descriptive title. Try to do this when you watch the clip for the first time.” No one reported watching the clip more than once. Event boundaries were determined as time points where over half of the group agreed an event had occurred and are displayed for reference at the top of <xref ref-type="fig" rid="fig3">Figure 3</xref>. On average, raters found 14.4+/-6.5 events in the movie (minimum = 4, maximum = 30).</p><p>The perceived timing of event boundaries according to participants within the age range that fMRI was recorded (5–19 years) was assessed online via the Gorilla platform (https://gorilla.sc; <xref ref-type="bibr" rid="bib3">Anwyl-Irvine et al., 2020</xref>). The online experiment involved a brief training to ensure comprehension of the task. Participants first watched a different clip from Despicable Me (03:25 to 04:47 in the full movie). Participants were notified after the first event boundary (04:10 in the full movie) and asked to identify the next event boundary (04:37 in the full movie). Participants were given three attempts to correctly identify the second boundary. If a participant successfully identified the second boundary, they watched the same clip that was used during fMRI scanning and identified boundaries in that clip at their discretion. The children’s data were first analyzed in aggregate, and then analyzed after splitting based on the median age (12.25 years).</p><p>The online task was also administered to 25 adults (9 male, 19–56 years) recruited via Prolific (https://www.prolific.co). The data from two adults were not analyzed as their ages overlapped with the age range of the fMRI participants (they were under 19 years). Data from 66 participants (39 male, 7–18 years) within the age range of the fMRI participants were recruited via word of mouth and Facebook. The data from eight subjects were eliminated as their median event duration was less than one second. All online experimental procedures were approved by the Columbia University IRB (protocol number AAAS0252, for adults, and AAAT8550, for children), and the data is available online: <ext-link ext-link-type="uri" xlink:href="https://github.com/samsydco/HBN">https://github.com/samsydco/HBN</ext-link>.</p></sec><sec id="s4-4"><title>Anatomical data preprocessing</title><p>The results included in this manuscript come from preprocessing performed using fMRIPprep 1.1.4 (<xref ref-type="bibr" rid="bib30">Esteban et al., 2018</xref>; RRID:<ext-link ext-link-type="uri" xlink:href="https://identifiers.org/RRID/RRID:SCR_016216">SCR_016216</ext-link>), based on Nipype 1.1.1 (<xref ref-type="bibr" rid="bib36">Gorgolewski et al., 2011</xref>; RRID:<ext-link ext-link-type="uri" xlink:href="https://identifiers.org/RRID/RRID:SCR_002502">SCR_002502</ext-link>). The T1-weighted (T1w) image was corrected for intensity non-uniformity (INU) using `N4BiasFieldCorrection` (<xref ref-type="bibr" rid="bib79">Tustison et al., 2010</xref>; ANTs 2.2.0; RRID:<ext-link ext-link-type="uri" xlink:href="https://identifiers.org/RRID/RRID:SCR_004757">SCR_004757</ext-link>), and is referred to as ‘T1w-reference’ throughout the workflow description. The T1w-reference was then skull-stripped using `antsBrainExtraction.sh` (ANTs 2.2.0), using OASIS as a target template. Brain surfaces were reconstructed using `recon-all` (<xref ref-type="bibr" rid="bib23">Dale et al., 1999</xref>; FreeSurfer 6.0.1,RRID:<ext-link ext-link-type="uri" xlink:href="https://identifiers.org/RRID/RRID:SCR_001847">SCR_001847</ext-link>), and the brain mask estimated was refined with a custom variation of the method used to reconcile the ANTs-derived and the FreeSurfer-derived segmentations of the cortical gray-matter in Mindboggle (<xref ref-type="bibr" rid="bib47">Klein et al., 2017</xref>; RRID:<ext-link ext-link-type="uri" xlink:href="https://identifiers.org/RRID/RRID:SCR_002438">SCR_002438</ext-link>). Spatial normalization to the ICBM 152 Nonlinear Asymmetrical template version 2009c (<xref ref-type="bibr" rid="bib31">Fonov et al., 2009</xref>; MNI152NLin2009cAsym; RRID:<ext-link ext-link-type="uri" xlink:href="https://identifiers.org/RRID/RRID:SCR_008796">SCR_008796</ext-link>) was performed through nonlinear registration with `antsRegistration` (ANTs 2.2.0, RRID:<ext-link ext-link-type="uri" xlink:href="https://identifiers.org/RRID/RRID:SCR_004757">SCR_004757</ext-link>), using brain-extracted versions of both the T1w volume and the template. Brain tissue segmentation of cerebrospinal fluid (CSF), white-matter (WM) and gray-matter (GM) was performed on the brain-extracted T1w using `fast` (<xref ref-type="bibr" rid="bib86">Zhang et al., 2001</xref>; FSL 5.0.9, RRID:<ext-link ext-link-type="uri" xlink:href="https://identifiers.org/RRID/RRID:SCR_002823">SCR_002823</ext-link>).</p></sec><sec id="s4-5"><title>Functional data preprocessing</title><p>A reference volume and its skull-stripped version were generated using custom fMRIprep methodology. For the cortical results, a B0-nonuniformity map (or fieldmap) was estimated based on two echo-planar imaging (EPI) references with opposing phase-encoding directions, with `3dQwarp` (<xref ref-type="bibr" rid="bib21">Cox, 1996</xref>; AFNI 20160207). Based on the estimated susceptibility distortion, a corrected EPI reference was calculated for a more accurate co-registration with the anatomical reference. For the hippocampal results, &quot;Fieldmap-less&quot; distortion correction was performed by co-registering the functional image to the same-subject T1w image with intensity inverted, (<xref ref-type="bibr" rid="bib42">Huntenburg, 2014</xref>; <xref ref-type="bibr" rid="bib82">Wang et al., 2017</xref>) constrained with an average fieldmap template (<xref ref-type="bibr" rid="bib78">Treiber et al., 2016</xref>), implemented with antsRegistration (ANTs).</p><p>Head-motion parameters with respect to the BOLD reference (transformation matrices, and six corresponding rotation and translation parameters) were estimated before any spatiotemporal filtering using `mcflirt` (<xref ref-type="bibr" rid="bib43">Jenkinson et al., 2002</xref>; FSL 5.0.9). The BOLD time-series was resampled into its original, native space by applying a single, composite transform to correct for head-motion and susceptibility distortions. This resampled BOLD time-series will be referred to as ‘preprocessed BOLD’. The BOLD reference was then co-registered to the T1w reference using `bbregister` (FreeSurfer) which implements boundary-based registration (<xref ref-type="bibr" rid="bib38">Greve and Fischl, 2009</xref>). To account for distortions remaining in the BOLD reference, co-registration was configured with nine degrees of freedom. The BOLD time-series was resampled to the ‘fsaverage6’ space for the cortical analyses, and to the 'MNI152NLin2009cAsym' space for the hippocampal analyses. Confound time-series were calculated based on the preprocessed BOLD. Framewise displacement (FD) was calculated using the Nipype implementation (<xref ref-type="bibr" rid="bib64">Power et al., 2013</xref>). Global signals were extracted within the CSF and the WM masks. Eight discrete cosine filters were extracted with 128 s cut-off. These nuisance regressors, as well as the head-motion estimates, were placed in a confounds file and subsequently regressed out of the BOLD time series separately for the cortex and the hippocampus using custom python scripts. All resamplings can be performed with a single interpolation step by composing all the pertinent transformations (i.e. head-motion transform matrices, susceptibility distortion correction, and co-registration to anatomical and template spaces). Gridded (volumetric) resamplings were performed using `antsApplyTransforms` (ANTs), configured with Lanczos interpolation to minimize the smoothing effects of other kernels. Non-gridded (surface) resamplings were performed using `mri_vol2surf` (FreeSurfer).</p><p>Many of the internal operations of fMRIPrep use Nilearn (version 0.4.2, <xref ref-type="bibr" rid="bib1">Abraham et al., 2014</xref>, RRID:<ext-link ext-link-type="uri" xlink:href="https://identifiers.org/RRID/RRID:SCR_001362">SCR_001362</ext-link>), mostly within the functional processing workflow. (For more details of the pipeline, see <ext-link ext-link-type="uri" xlink:href="https://fmriprep.readthedocs.io/en/latest/workflows.html">https://fmriprep.readthedocs.io/en/latest/workflows.html</ext-link> &quot;FMRIPrep’s documentation&quot;.) After these preprocessing steps were taken, the cortical surface was parcellated into the 100 parcel, seven network parcellation from <xref ref-type="bibr" rid="bib72">Schaefer et al., 2018</xref>.</p></sec><sec id="s4-6"><title>Defining temporoparietal junction</title><p>To better understand how our findings relate to the previous literature we defined the portion of the temporoparietal junction (TPJ) responsible for theory of mind processes based on its definition in <xref ref-type="bibr" rid="bib27">Dufour et al., 2013</xref>. We projected the definition of the TPJ from this paper, originally in voxel space, onto the cortical surface, and parcels in which over two-thirds of their vertices were within the boundary of the TPJ were labeled as members of this region.</p></sec><sec id="s4-7"><title>Inter-subject correlation (ISC) calculations</title><p>After preprocessing, split-half inter-subject correlation (shISC) was calculated by splitting the group within which ISC will be calculated, into two equal halves, averaging each halves’ timecourse, and then correlating the two average timecourses. We chose to use shISC since we found that it could produce ISC estimates for a large group much more quickly than using pairwise ISC (pwISC) and leave-one-out ISC (looISC). Using a model similar to <xref ref-type="bibr" rid="bib58">Nastase et al., 2019</xref>, it can be shown that, in expectation, pwISC and looISC can be calculated from shISC if the sample size is known (see Appendix 2). shISC was calculated for each vertex on the cortical surface, and then averaged within each parcel.</p><p>The overall level of ISC among the participants, irrespective of age, was calculated in a randomized mixture of the Youngest and Oldest subjects (<xref ref-type="fig" rid="fig1s1">Figure 1—figure supplement 1</xref>). This calculation can be viewed as a quality assurance step because if there is no baseline level of ISC, it is possible that the movie was not engaging to subjects, or that the sample is dominated by movement artifacts (<xref ref-type="bibr" rid="bib19">Cohen et al., 2017</xref>; <xref ref-type="bibr" rid="bib81">Vanderwal et al., 2020</xref>). After establishing the level of the overall group ISC, ISC was calculated within the Youngest and Oldest groups and compared between the groups, following the methods used in previous research (<xref ref-type="bibr" rid="bib12">Cantlon and Li, 2013</xref>; <xref ref-type="bibr" rid="bib55">Moraczewski et al., 2018</xref>). To ensure that any regions in which ISC increased with age were not driven by an increase in the level of noise in the Youngest group, we calculated the correlation between each individual’s median framewise displacement and their looISC with the other subjects for the Youngest group in parcels where ISC was found to increase with age.</p><p>In addition to measuring within-group ISC, we sought to compare the similarity between age groups (while controlling for within-group consistency). In order to assess a potential difference in stimulus response timecourses between the groups, while accounting for the relative level of within group correlation, we introduce a measure named between-group ISC (ISC<sub>b</sub>). Previous researchers have measured the timecourse correlations between subjects in two different groups (<xref ref-type="bibr" rid="bib12">Cantlon and Li, 2013</xref>; <xref ref-type="bibr" rid="bib40">Hasson et al., 2009</xref>; <xref ref-type="bibr" rid="bib55">Moraczewski et al., 2018</xref>; <xref ref-type="bibr" rid="bib58">Nastase et al., 2019</xref>), but this measure mixes information about across-group differences and within-group consistency. For example, if two groups are identical, we would expect the between-group correlation to be the same as the within-group correlation. ISC<sub>b</sub> disentangles these effects, producing an estimate of the correlation between the average timecourses of two groups in the limit of infinite data (in which the group-average timecourses are measured without noise). Mathematically, ISC<sub>b</sub> is computed as the correlation between two different groups divided by the geometric mean of the correlation within each group. The denominator means that ISC<sub>b</sub> accounts for differences in ISC magnitude between the groups (see Appendix 1 for mathematical derivation). ISC<sub>b</sub> was calculated between the Youngest and Oldest groups, using the shISC formulation (Appendix 1).</p></sec><sec id="s4-8"><title>Analysis of event segmentation behavior</title><p>Event segmentation behavioral data from each individual was first convolved with a canonical hemodynamic response function (HRF, one parameter gamma model from AFNI’s 3dDeconvolve) at each timepoint (<xref ref-type="bibr" rid="bib50">Lee et al., 2021</xref>). This data was compared between children, adults, and the younger and older children as determined by a median split based on age. Data was compared within and between groups by splitting each group in half, and averaging the data across raters within a split, thus computing shISCs where appropriate. This procedure was done on five random splits of the data. The ISC<sub>b</sub> measure was used to compare response timecourses between the groups. These values were computed across five random splits of the data and results were averaged across the splits. All significance values were computed on 10,000 random permutations of the data.</p></sec><sec id="s4-9"><title>Calculating the number of events in each age group</title><p>To determine whether the Oldest and Youngest groups perceived the same number of events in the movie, following <xref ref-type="bibr" rid="bib6">Baldassano et al., 2020</xref>, we define an event as a stable spatial pattern of neural activity within a parcel. In each age group, and each parcel, event patterns and the number of events are chosen using a hidden markov model (HMM). To find the best fitting model, HMMs that used between 2 and 50 events (approximately logarithmically spaced) were trained and tested using five-fold cross-validation by first averaging the brain activity of four-fifths of the subjects in an age group, and then testing on the average brain activity of the held-out subjects. The number of events in an age group were defined as the average of the number of events that maximized the log likelihood of the HMM (model fit) in the held out subjects in each of the five cross-validated folds.</p><p>Although most cortical regions are expected to exhibit event structure in response to a movie stimulus, some regions will not have activity that can be well modeled by a model of events. The difference in model fit between a baseline HMM in which two events were fit and the HMM with the number of events yielding the best fit was used as a measure of the extent to which event structure was successfully detected in this region (<xref ref-type="fig" rid="fig5s1">Figure 5—figure supplement 1</xref>). Regions that do not show substantial improvement in model fit over the two-event model either have preferred event lengths on the scale of 300 s or longer (since the stimulus was 600 s long) or do not have event-structured responses. In 30 parcels both the Youngest and Oldest groups had a model fit difference less than 0.002 and were therefore not considered in future analyses (<xref ref-type="fig" rid="fig5s1">Figure 5—figure supplement 1</xref>). In 40 parcels, the Youngest group had a model fit difference less than 0.002 and in 33 parcels the Oldest group had a model fit difference less than 0.002. In the remaining 71 parcels with a good model fit in at least one group, there was no significant difference in the number of events between the groups (<xref ref-type="fig" rid="fig5s2">Figure 5—figure supplement 2</xref>; see Statistical Significance section for permutation test details).</p></sec><sec id="s4-10"><title>Comparison of event boundaries in brain regions to annotations</title><p>Following the methods of <xref ref-type="bibr" rid="bib50">Lee et al., 2021</xref>, we jointly fit an HMM in each parcel to the Youngest and Oldest groups simultaneously. This joint-fitting procedure assumes that both groups share the same number of events and brain pattern in each event. Both the degree of model fit and the timing of these events can vary between the groups. The number of events and event patterns were determined by finding the maximum log likelihood of the model-fit on the average of five held-out folds of the data from all five age groups (including ages in between the Youngest and Oldest). This fitting procedure is similar to the case where HMMs are fit separately in each age group, except in this case, the log likelihood of the model-fit is averaged over all age groups in addition to all training folds.</p><p>We next evaluated the correspondence between the HMM-derived event boundaries and boundaries from age-matched children. To determine where event transitions occur in the model, we computed the derivative of the expected event label over time for each age group and parcel. The behavioral boundaries were derived from the number of boundary annotations at each timepoint convolved with a canonical HRF, as was done in the Analysis of event segmentation behavior (<xref ref-type="bibr" rid="bib50">Lee et al., 2021</xref>). We related the two timecourses using Pearson correlation (<xref ref-type="fig" rid="fig5s2">Figure 5—figure supplement 2</xref>).</p></sec><sec id="s4-11"><title>Determining the model fit in each age group</title><p>The log likelihood, or model-fit, of the best-fitting jointly-fit HMM was compared between the Oldest and Youngest groups. For illustration of the change in log likelihood with age, the average log likelihood was also computed on similarly sized folds of the age groups in between the Youngest and Oldest groups.</p></sec><sec id="s4-12"><title>Measuring changes in event timing across age</title><p>Following the procedure from <xref ref-type="bibr" rid="bib50">Lee et al., 2021</xref>, using the jointly-fit HMMs described in the previous section, the probability that each fold of the held-out data was in any of the events was determined for each age group in each parcel. Averaging these probabilities across all five-folds yielded a time-point by number of events matrix. We then computed (separately for each group) the expected value of the event present at each timepoint. Summing over these expectation values produced a value describing the amount of time that this region spent in earlier versus later events, with larger numbers indicating that more time was spent in later events. If the sum of these expectation values is greater in one age group than in the other, this indicates that this age group represents upcoming events before the other age group.</p><p>In all parcels that had a significant change in event timing between age groups, we compared the timing of the event boundaries identified by the HMM to the event boundary timecourse obtained behaviorally from raters. Following methods used previously, the number of boundary annotations from the child raters at each timepoint during the movie were convolved with a canonical HRF (<xref ref-type="bibr" rid="bib50">Lee et al., 2021</xref>). To obtain a measure of when the brain is switching between events, we took the derivative of the expected value of the event that the HMM assigned to each timepoint (following methods from <xref ref-type="bibr" rid="bib50">Lee et al., 2021</xref>). To determine the timing of the alignment between these two signals, we cross-correlated the HMM-derived boundary timecourse with the behavioral event boundary timecourse from children, in aggregate. To precisely estimate the optimal lag, we fit a quadratic function to the maximum correlation lag and its two neighboring lags, and found the location of the peak of this quadratic fit. We computed the maximum-correlation lag separately in the Oldest and Youngest groups to determine whether there is a significant difference in the relationship between the brain’s event boundaries and the behavioral event boundaries.</p></sec><sec id="s4-13"><title>Statistical significance</title><p>To test for a significant difference between the Youngest and Oldest groups in all of the above analyses, Age permuted values were computed for each parcel for the difference in ISC magnitude (absolute value of ISC difference), ISC<sub>b</sub>, number of events in age group specific HMMs, difference in model fit (maximum log likelihood) for jointly-fit HMMs, difference in event timing for jointly-fit HMMs, and difference the timing of the jointly-fit HMMs events with behavior. All age permuted groups had the same gender distribution as the true sample. For each parcel, the calculation of the real (non-permuted) value, as well as all permuted values were calculated in five random subsamples of each age group (Youngest and Oldest) since random subsampling generates slightly different results. Both the real and permuted values were then averaged across all five subsamples to calculate both the values reported here and their significance. The permuted group assignment in each permutation was therefore maintained across the five subsamples.</p><p>If in any parcel, for any test, the number of the permuted values greater than (or less than, in the case of ISC<sub>b</sub>) the true value was less than 5% in any of the five random subsamples after 100 permutations, 1000 additional permutations were run. A total of 1000 additional permutations were computed until every parcel had at least one permuted value greater than (or less than) the value in the original data, or 6000 permutations had been computed (whichever came first). If after 6000 permutations, there were still no permuted values greater than (or less than) the value in the original data, the original data was included as a permuted value for significance tests.</p><p>All HMMs were initially trained on the original (non age-permuted) training data (four-fifths of the full dataset). To compute permuted differences of the number of events, age-specific HMMs were tested on age-permuted testing data for all numbers of events. The jointly-fit HMMs were tested on permuted data for only the best fitting number of events, determined from the original data. In all statistical tests, the false discovery rate (FDR) of parcel differences was controlled for by setting the expected proportion of false positives to.05 (<xref ref-type="bibr" rid="bib8">Benjamini and Hochberg, 1995</xref>). The code for all the included analyses is available at: <ext-link ext-link-type="uri" xlink:href="https://github.com/samsydco/HBN">https://github.com/samsydco/HBN.</ext-link></p></sec><sec id="s4-14"><title>Hippocampal segmentation and event rating correlation</title><p>The hippocampus was defined using the Freesurfer segmentation generated using fMRIPrep 1.5.6 (<xref ref-type="bibr" rid="bib30">Esteban et al., 2018</xref>). Consistent with previous studies, the anterior hippocampus (aHPC) was defined as voxels anterior to y = –21 mm in MNI space, and the posterior hippocampus (pHPC) was defined as voxels including and posterior to y = –21 mm in MNI space (<xref ref-type="bibr" rid="bib63">Poppenk et al., 2013</xref>; <xref ref-type="bibr" rid="bib85">Zeidman et al., 2015</xref>). For each subject, voxel-wise activity was averaged within the entire hippocampus, the aHPC, and the pHPC. Each subject’s hippocampal timecourses was then correlated with an event boundary timecourse obtained behaviorally from age-matched children. Similarly to the behavioral timecourse related to the HMM, here, the event boundary timecourse was computed by convolving the number of boundary annotations at each timepoint during the movie with a canonical HRF (<xref ref-type="bibr" rid="bib50">Lee et al., 2021</xref>). The hippocampal timecourses and the event boundary timecourse were correlated at differences in delay of up to 10 s. These lagged correlations were computed because previous research has shown that the hippocampal response to event boundaries can follow event boundaries by several seconds (<xref ref-type="bibr" rid="bib6">Baldassano et al., 2020</xref>; <xref ref-type="bibr" rid="bib7">Ben-Yakov and Henson, 2018</xref>; <xref ref-type="bibr" rid="bib26">DuBrow and Davachi, 2016</xref>; <xref ref-type="bibr" rid="bib67">Reagh et al., 2020</xref>). The correlation values for each hippocampal region, temporal lag, and subject were then grouped according to the age of the subject. The Pearson’s correlation at lag 0 between age and the hippocampus-to-event boundary correlation was assessed across all subjects in the entire hippocampus as well as in all hippocampal subregions.</p><p>Previous research has shown that the volume of the hippocampus may decrease with age (<xref ref-type="bibr" rid="bib35">Gogtay et al., 2006</xref>). The volume of the hippocampus and its subregions was therefore measured as the number of voxels that the Freesurfer parcellation allotted to the hippocampus. The aHPC volume was the number of voxels anterior to y = –21 mm in MNI space, and the pHPC volume was the number of voxels including and posterior to y = –21 mm in MNI space. The volume of the entire hippocampus and aHPC correlated with subject age (entire HPC: <italic>r</italic>=–0.1, p=0.03, aHPC: <italic>r</italic>=–0.1, p=0.03) while the volume of the pHPC did not (<italic>r</italic>=–0.05, p=0.3). However, in none of the regions was the age-matched event boundary response significantly correlated with the change in volume (entire HPC, <italic>r</italic>=0.01, p=0.9, aHPC, <italic>r</italic>=–0.01, p=0.9, pHPC, <italic>r</italic>=–0.03, p=0.6).</p></sec></sec></body><back><sec sec-type="additional-information" id="s5"><title>Additional information</title><fn-group content-type="competing-interest"><title>Competing interests</title><fn fn-type="COI-statement" id="conf1"><p>No competing interests declared</p></fn></fn-group><fn-group content-type="author-contribution"><title>Author contributions</title><fn fn-type="con" id="con1"><p>Conceptualization, Data curation, Formal analysis, Methodology, Software, Visualization, Writing - original draft, Writing - review and editing</p></fn><fn fn-type="con" id="con2"><p>Conceptualization, Investigation, Methodology, Project administration, Resources, Supervision, Writing - review and editing</p></fn><fn fn-type="con" id="con3"><p>Conceptualization, Funding acquisition, Methodology, Resources, Supervision, Writing - review and editing</p></fn></fn-group><fn-group content-type="ethics-information"><title>Ethics</title><fn fn-type="other"><p>Human subjects: Informed consent, and consent to publish, was obtained from all subjects 18 years and older. Consent was obtained from the parents or legal guardians for participants younger than 18 years. The neuroimaging portion of the study was approved by the Chesapeake Institutional Review Board (https://www.chesapeakeirb.com/). The behavioral experimental procedures were approved by the Columbia University IRB (protocol number AAAS0252, for adult data, and AAAT8550, for child data).</p></fn></fn-group></sec><sec sec-type="supplementary-material" id="s6"><title>Additional files</title><supplementary-material id="transrepform"><label>Transparent reporting form</label><media xlink:href="elife-69430-transrepform1-v2.pdf" mimetype="application" mime-subtype="pdf"/></supplementary-material></sec><sec sec-type="data-availability" id="s7"><title>Data availability</title><p>All neuroimaging data is available at: <ext-link ext-link-type="uri" xlink:href="http://fcon_1000.projects.nitrc.org/indi/cmi_healthy_brain_network/sharing_neuro.html">http://fcon_1000.projects.nitrc.org/indi/cmi_healthy_brain_network/sharing_neuro.html</ext-link>, and all behavioral data is available at: <ext-link ext-link-type="uri" xlink:href="https://github.com/samsydco/HBN">https://github.com/samsydco/HBN</ext-link>, (copy archived at <ext-link ext-link-type="uri" xlink:href="https://archive.softwareheritage.org/swh:1:dir:0854d9801892dec45a2e0449ef200a22718a7a75;origin=https://github.com/samsydco/HBN;visit=swh:1:snp:d07d3ab48523fdb095b2e4d49288a3b1226591e4;anchor=swh:1:rev:278127d07b721c73679c11d0d1836631df778323">swh:1:rev:278127d07b721c73679c11d0d1836631df778323</ext-link>).</p><p>The following dataset was generated:</p><p><element-citation publication-type="data" specific-use="isSupplementedBy" id="dataset1"><person-group person-group-type="author"><name><surname>Cohen</surname><given-names>S</given-names></name></person-group><year iso-8601-date="2022">2022</year><data-title>HBN</data-title><source>GitHub</source><pub-id pub-id-type="accession" xlink:href="https://github.com/samsydco/HBN">278127d</pub-id></element-citation></p></sec><ack id="ack"><title>Acknowledgements</title><p>We thank Andrew Africk for providing funding support for S.C., Michael Chow for helping to formulate the math for ISCb, and Nora Newcombe, Paul A Bloom, Rolando Masis-Obando, and Vishnu “Deepu” Murty for their edits and suggestions.</p></ack><ref-list><title>References</title><ref id="bib1"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Abraham</surname><given-names>A</given-names></name><name><surname>Pedregosa</surname><given-names>F</given-names></name><name><surname>Eickenberg</surname><given-names>M</given-names></name><name><surname>Gervais</surname><given-names>P</given-names></name><name><surname>Mueller</surname><given-names>A</given-names></name><name><surname>Kossaifi</surname><given-names>J</given-names></name><name><surname>Gramfort</surname><given-names>A</given-names></name><name><surname>Thirion</surname><given-names>B</given-names></name><name><surname>Varoquaux</surname><given-names>G</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>Machine learning for neuroimaging with scikit-learn</article-title><source>Frontiers in Neuroinformatics</source><volume>8</volume><elocation-id>14</elocation-id><pub-id pub-id-type="doi">10.3389/fninf.2014.00014</pub-id><pub-id pub-id-type="pmid">24600388</pub-id></element-citation></ref><ref id="bib2"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Alexander</surname><given-names>LM</given-names></name><name><surname>Escalera</surname><given-names>J</given-names></name><name><surname>Ai</surname><given-names>L</given-names></name><name><surname>Andreotti</surname><given-names>C</given-names></name><name><surname>Febre</surname><given-names>K</given-names></name><name><surname>Mangone</surname><given-names>A</given-names></name><name><surname>Vega-Potler</surname><given-names>N</given-names></name><name><surname>Langer</surname><given-names>N</given-names></name><name><surname>Alexander</surname><given-names>A</given-names></name><name><surname>Kovacs</surname><given-names>M</given-names></name><name><surname>Litke</surname><given-names>S</given-names></name><name><surname>O’Hagan</surname><given-names>B</given-names></name><name><surname>Andersen</surname><given-names>J</given-names></name><name><surname>Bronstein</surname><given-names>B</given-names></name><name><surname>Bui</surname><given-names>A</given-names></name><name><surname>Bushey</surname><given-names>M</given-names></name><name><surname>Butler</surname><given-names>H</given-names></name><name><surname>Castagna</surname><given-names>V</given-names></name><name><surname>Camacho</surname><given-names>N</given-names></name><name><surname>Chan</surname><given-names>E</given-names></name><name><surname>Citera</surname><given-names>D</given-names></name><name><surname>Clucas</surname><given-names>J</given-names></name><name><surname>Cohen</surname><given-names>S</given-names></name><name><surname>Dufek</surname><given-names>S</given-names></name><name><surname>Eaves</surname><given-names>M</given-names></name><name><surname>Fradera</surname><given-names>B</given-names></name><name><surname>Gardner</surname><given-names>J</given-names></name><name><surname>Grant-Villegas</surname><given-names>N</given-names></name><name><surname>Green</surname><given-names>G</given-names></name><name><surname>Gregory</surname><given-names>C</given-names></name><name><surname>Hart</surname><given-names>E</given-names></name><name><surname>Harris</surname><given-names>S</given-names></name><name><surname>Horton</surname><given-names>M</given-names></name><name><surname>Kahn</surname><given-names>D</given-names></name><name><surname>Kabotyanski</surname><given-names>K</given-names></name><name><surname>Karmel</surname><given-names>B</given-names></name><name><surname>Kelly</surname><given-names>SP</given-names></name><name><surname>Kleinman</surname><given-names>K</given-names></name><name><surname>Koo</surname><given-names>B</given-names></name><name><surname>Kramer</surname><given-names>E</given-names></name><name><surname>Lennon</surname><given-names>E</given-names></name><name><surname>Lord</surname><given-names>C</given-names></name><name><surname>Mantello</surname><given-names>G</given-names></name><name><surname>Margolis</surname><given-names>A</given-names></name><name><surname>Merikangas</surname><given-names>KR</given-names></name><name><surname>Milham</surname><given-names>J</given-names></name><name><surname>Minniti</surname><given-names>G</given-names></name><name><surname>Neuhaus</surname><given-names>R</given-names></name><name><surname>Levine</surname><given-names>A</given-names></name><name><surname>Osman</surname><given-names>Y</given-names></name><name><surname>Parra</surname><given-names>LC</given-names></name><name><surname>Pugh</surname><given-names>KR</given-names></name><name><surname>Racanello</surname><given-names>A</given-names></name><name><surname>Restrepo</surname><given-names>A</given-names></name><name><surname>Saltzman</surname><given-names>T</given-names></name><name><surname>Septimus</surname><given-names>B</given-names></name><name><surname>Tobe</surname><given-names>R</given-names></name><name><surname>Waltz</surname><given-names>R</given-names></name><name><surname>Williams</surname><given-names>A</given-names></name><name><surname>Yeo</surname><given-names>A</given-names></name><name><surname>Castellanos</surname><given-names>FX</given-names></name><name><surname>Klein</surname><given-names>A</given-names></name><name><surname>Paus</surname><given-names>T</given-names></name><name><surname>Leventhal</surname><given-names>BL</given-names></name><name><surname>Craddock</surname><given-names>RC</given-names></name><name><surname>Koplewicz</surname><given-names>HS</given-names></name><name><surname>Milham</surname><given-names>MP</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>An open resource for transdiagnostic research in pediatric mental health and learning disorders</article-title><source>Scientific Data</source><volume>4</volume><elocation-id>170181</elocation-id><pub-id pub-id-type="doi">10.1038/sdata.2017.181</pub-id><pub-id pub-id-type="pmid">29257126</pub-id></element-citation></ref><ref id="bib3"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Anwyl-Irvine</surname><given-names>AL</given-names></name><name><surname>Massonnié</surname><given-names>J</given-names></name><name><surname>Flitton</surname><given-names>A</given-names></name><name><surname>Kirkham</surname><given-names>N</given-names></name><name><surname>Evershed</surname><given-names>JK</given-names></name></person-group><year iso-8601-date="2020">2020</year><article-title>Gorilla in our midst: an online behavioral experiment builder</article-title><source>Behavior Research Methods</source><volume>52</volume><fpage>388</fpage><lpage>407</lpage><pub-id pub-id-type="doi">10.3758/s13428-019-01237-x</pub-id><pub-id pub-id-type="pmid">31016684</pub-id></element-citation></ref><ref id="bib4"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Aslin</surname><given-names>RN</given-names></name><name><surname>Smith</surname><given-names>LB</given-names></name></person-group><year iso-8601-date="1988">1988</year><article-title>Perceptual development</article-title><source>Annual Review of Psychology</source><volume>39</volume><fpage>435</fpage><lpage>473</lpage><pub-id pub-id-type="doi">10.1146/annurev.ps.39.020188.002251</pub-id><pub-id pub-id-type="pmid">3278680</pub-id></element-citation></ref><ref id="bib5"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Baldassano</surname><given-names>C</given-names></name><name><surname>Hasson</surname><given-names>U</given-names></name><name><surname>Norman</surname><given-names>KA</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>Representation of real-world event schemas during narrative perception</article-title><source>The Journal of Neuroscience</source><volume>38</volume><fpage>9689</fpage><lpage>9699</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.0251-18.2018</pub-id><pub-id pub-id-type="pmid">30249790</pub-id></element-citation></ref><ref id="bib6"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Baldassano</surname><given-names>C</given-names></name><name><surname>Chen</surname><given-names>J</given-names></name><name><surname>Zadbood</surname><given-names>A</given-names></name><name><surname>Pillow</surname><given-names>JW</given-names></name><name><surname>Hasson</surname><given-names>U</given-names></name><name><surname>Norman</surname><given-names>KA</given-names></name></person-group><year iso-8601-date="2020">2020</year><article-title>Discovering event structure in continuous narrative perception and memory</article-title><source>Neuron</source><volume>95</volume><fpage>709</fpage><lpage>721</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2017.06.041</pub-id><pub-id pub-id-type="pmid">28772125</pub-id></element-citation></ref><ref id="bib7"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ben-Yakov</surname><given-names>A</given-names></name><name><surname>Henson</surname><given-names>RN</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>The hippocampal film editor: sensitivity and specificity to event boundaries in continuous experience</article-title><source>The Journal of Neuroscience</source><volume>38</volume><fpage>10057</fpage><lpage>10068</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.0524-18.2018</pub-id><pub-id pub-id-type="pmid">30301758</pub-id></element-citation></ref><ref id="bib8"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Benjamini</surname><given-names>Y</given-names></name><name><surname>Hochberg</surname><given-names>Y</given-names></name></person-group><year iso-8601-date="1995">1995</year><article-title>Controlling the false discovery rate: a practical and powerful approach to multiple testing</article-title><source>Journal of the Royal Statistical Society</source><volume>57</volume><fpage>289</fpage><lpage>300</lpage><pub-id pub-id-type="doi">10.1111/j.2517-6161.1995.tb02031.x</pub-id></element-citation></ref><ref id="bib9"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Binder</surname><given-names>JR</given-names></name><name><surname>Desai</surname><given-names>RH</given-names></name><name><surname>Graves</surname><given-names>WW</given-names></name><name><surname>Conant</surname><given-names>LL</given-names></name></person-group><year iso-8601-date="2009">2009</year><article-title>Where is the semantic system? A critical review and meta-analysis of 120 functional neuroimaging studies</article-title><source>Cerebral Cortex</source><volume>19</volume><fpage>2767</fpage><lpage>2796</lpage><pub-id pub-id-type="doi">10.1093/cercor/bhp055</pub-id><pub-id pub-id-type="pmid">19329570</pub-id></element-citation></ref><ref id="bib10"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Binder</surname><given-names>JR</given-names></name><name><surname>Desai</surname><given-names>RH</given-names></name></person-group><year iso-8601-date="2011">2011</year><article-title>The neurobiology of semantic memory</article-title><source>Trends in Cognitive Sciences</source><volume>15</volume><fpage>527</fpage><lpage>536</lpage><pub-id pub-id-type="doi">10.1016/j.tics.2011.10.001</pub-id><pub-id pub-id-type="pmid">22001867</pub-id></element-citation></ref><ref id="bib11"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Brod</surname><given-names>G</given-names></name><name><surname>Lindenberger</surname><given-names>U</given-names></name><name><surname>Shing</surname><given-names>YL</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>Neural activation patterns during retrieval of schema-related memories: differences and commonalities between children and adults</article-title><source>Developmental Science</source><volume>20</volume><elocation-id>12475</elocation-id><pub-id pub-id-type="doi">10.1111/desc.12475</pub-id><pub-id pub-id-type="pmid">29076268</pub-id></element-citation></ref><ref id="bib12"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Cantlon</surname><given-names>JF</given-names></name><name><surname>Li</surname><given-names>R</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>Neural activity during natural viewing of sesame street statistically predicts test scores in early childhood</article-title><source>PLOS Biology</source><volume>11</volume><elocation-id>e1001462</elocation-id><pub-id pub-id-type="doi">10.1371/journal.pbio.1001462</pub-id><pub-id pub-id-type="pmid">23300385</pub-id></element-citation></ref><ref id="bib13"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Carpendale</surname><given-names>J</given-names></name><name><surname>Lewis</surname><given-names>C</given-names></name></person-group><year iso-8601-date="2006">2006</year><source>How Children Develop Social Understanding</source><publisher-name>Blackwell Publishing</publisher-name></element-citation></ref><ref id="bib14"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Casillas</surname><given-names>M</given-names></name><name><surname>Frank</surname><given-names>MC</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>The development of children’s ability to track and predict turn structure in conversation</article-title><source>Journal of Memory and Language</source><volume>92</volume><fpage>234</fpage><lpage>253</lpage><pub-id pub-id-type="doi">10.1016/j.jml.2016.06.013</pub-id></element-citation></ref><ref id="bib15"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Chen</surname><given-names>J</given-names></name><name><surname>Leong</surname><given-names>YC</given-names></name><name><surname>Honey</surname><given-names>CJ</given-names></name><name><surname>Yong</surname><given-names>CH</given-names></name><name><surname>Norman</surname><given-names>KA</given-names></name><name><surname>Hasson</surname><given-names>U</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>Shared memories reveal shared structure in neural activity across individuals</article-title><source>Nature Neuroscience</source><volume>20</volume><fpage>115</fpage><lpage>125</lpage><pub-id pub-id-type="doi">10.1038/nn.4450</pub-id><pub-id pub-id-type="pmid">27918531</pub-id></element-citation></ref><ref id="bib16"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Chi</surname><given-names>MTH</given-names></name></person-group><year iso-8601-date="1978">1978</year><chapter-title>Knowledge structures and memory development</chapter-title><person-group person-group-type="editor"><name><surname>Siegler</surname><given-names>R</given-names></name></person-group><source>Children’s Thinking: What Develops</source><publisher-loc>Hillsdale, NJ</publisher-loc><publisher-name>Erlbaum</publisher-name><fpage>73</fpage><lpage>96</lpage></element-citation></ref><ref id="bib17"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Clark</surname><given-names>EV</given-names></name></person-group><year iso-8601-date="1973">1973</year><chapter-title>What’s in a word? On the child’s acquisition of semantics in his first language</chapter-title><person-group person-group-type="editor"><name><surname>Moore</surname><given-names>TE</given-names></name></person-group><source>Cognitive Development and the Acquisition of Language</source><publisher-loc>New York, NY</publisher-loc><publisher-name>Academic Press</publisher-name><fpage>65</fpage><lpage>110</lpage></element-citation></ref><ref id="bib18"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Clewett</surname><given-names>D</given-names></name><name><surname>DuBrow</surname><given-names>S</given-names></name><name><surname>Davachi</surname><given-names>L</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>Transcending time in the brain: how event memories are constructed from experience</article-title><source>Hippocampus</source><volume>29</volume><fpage>162</fpage><lpage>183</lpage><pub-id pub-id-type="doi">10.1002/hipo.23074</pub-id><pub-id pub-id-type="pmid">30734391</pub-id></element-citation></ref><ref id="bib19"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Cohen</surname><given-names>SS</given-names></name><name><surname>Henin</surname><given-names>S</given-names></name><name><surname>Parra</surname><given-names>LC</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>Engaging narratives evoke similar neural activity and lead to similar time perception</article-title><source>Scientific Reports</source><volume>7</volume><fpage>1</fpage><lpage>10</lpage></element-citation></ref><ref id="bib20"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Corbetta</surname><given-names>M</given-names></name><name><surname>Shulman</surname><given-names>GL</given-names></name></person-group><year iso-8601-date="2002">2002</year><article-title>Control of goal-directed and stimulus-driven attention in the brain</article-title><source>Nature Reviews. Neuroscience</source><volume>3</volume><fpage>201</fpage><lpage>215</lpage><pub-id pub-id-type="doi">10.1038/nrn755</pub-id><pub-id pub-id-type="pmid">11994752</pub-id></element-citation></ref><ref id="bib21"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Cox</surname><given-names>RW</given-names></name></person-group><year iso-8601-date="1996">1996</year><article-title>AFNI: software for analysis and visualization of functional magnetic resonance neuroimages</article-title><source>Computers and Biomedical Research, an International Journal</source><volume>29</volume><fpage>162</fpage><lpage>173</lpage><pub-id pub-id-type="doi">10.1006/cbmr.1996.0014</pub-id><pub-id pub-id-type="pmid">8812068</pub-id></element-citation></ref><ref id="bib22"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Curtis</surname><given-names>CE</given-names></name><name><surname>D’Esposito</surname><given-names>M</given-names></name></person-group><year iso-8601-date="2003">2003</year><article-title>Persistent activity in the prefrontal cortex during working memory</article-title><source>Trends in Cognitive Sciences</source><volume>7</volume><fpage>415</fpage><lpage>423</lpage><pub-id pub-id-type="doi">10.1016/s1364-6613(03)00197-9</pub-id><pub-id pub-id-type="pmid">12963473</pub-id></element-citation></ref><ref id="bib23"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Dale</surname><given-names>AM</given-names></name><name><surname>Fischl</surname><given-names>B</given-names></name><name><surname>Sereno</surname><given-names>MI</given-names></name></person-group><year iso-8601-date="1999">1999</year><article-title>Cortical surface-based analysis</article-title><source>NeuroImage</source><volume>9</volume><fpage>179</fpage><lpage>194</lpage><pub-id pub-id-type="doi">10.1006/nimg.1998.0395</pub-id><pub-id pub-id-type="pmid">9931268</pub-id></element-citation></ref><ref id="bib24"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Demaster</surname><given-names>DM</given-names></name><name><surname>Ghetti</surname><given-names>S</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>Developmental differences in hippocampal and cortical contributions to episodic retrieval</article-title><source>Cortex; a Journal Devoted to the Study of the Nervous System and Behavior</source><volume>49</volume><fpage>1482</fpage><lpage>1493</lpage><pub-id pub-id-type="doi">10.1016/j.cortex.2012.08.004</pub-id><pub-id pub-id-type="pmid">22981810</pub-id></element-citation></ref><ref id="bib25"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Downar</surname><given-names>J</given-names></name><name><surname>Crawley</surname><given-names>AP</given-names></name><name><surname>Mikulis</surname><given-names>DJ</given-names></name><name><surname>Davis</surname><given-names>KD</given-names></name></person-group><year iso-8601-date="2001">2001</year><article-title>The effect of task relevance on the cortical response to changes in visual and auditory stimuli: an event-related fMRI study</article-title><source>NeuroImage</source><volume>14</volume><fpage>1256</fpage><lpage>1267</lpage><pub-id pub-id-type="doi">10.1006/nimg.2001.0946</pub-id><pub-id pub-id-type="pmid">11707082</pub-id></element-citation></ref><ref id="bib26"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>DuBrow</surname><given-names>S</given-names></name><name><surname>Davachi</surname><given-names>L</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Temporal binding within and across events</article-title><source>Neurobiology of Learning and Memory</source><volume>134 Pt A</volume><fpage>107</fpage><lpage>114</lpage><pub-id pub-id-type="doi">10.1016/j.nlm.2016.07.011</pub-id><pub-id pub-id-type="pmid">27422018</pub-id></element-citation></ref><ref id="bib27"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Dufour</surname><given-names>N</given-names></name><name><surname>Redcay</surname><given-names>E</given-names></name><name><surname>Young</surname><given-names>L</given-names></name><name><surname>Mavros</surname><given-names>PL</given-names></name><name><surname>Moran</surname><given-names>JM</given-names></name><name><surname>Triantafyllou</surname><given-names>C</given-names></name><name><surname>Gabrieli</surname><given-names>JDE</given-names></name><name><surname>Saxe</surname><given-names>R</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>Similar brain activation during false belief tasks in a large sample of adults with and without autism</article-title><source>PLOS ONE</source><volume>8</volume><elocation-id>e75468</elocation-id><pub-id pub-id-type="doi">10.1371/journal.pone.0075468</pub-id><pub-id pub-id-type="pmid">24073267</pub-id></element-citation></ref><ref id="bib28"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Dumontheil</surname><given-names>I</given-names></name><name><surname>Apperly</surname><given-names>IA</given-names></name><name><surname>Blakemore</surname><given-names>SJ</given-names></name></person-group><year iso-8601-date="2010">2010</year><article-title>Online usage of theory of mind continues to develop in late adolescence</article-title><source>Developmental Science</source><volume>13</volume><fpage>331</fpage><lpage>338</lpage><pub-id pub-id-type="doi">10.1111/j.1467-7687.2009.00888.x</pub-id><pub-id pub-id-type="pmid">20136929</pub-id></element-citation></ref><ref id="bib29"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Epstein</surname><given-names>RA</given-names></name><name><surname>Baker</surname><given-names>CI</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>Scene perception in the human brain</article-title><source>Annual Review of Vision Science</source><volume>5</volume><fpage>373</fpage><lpage>397</lpage><pub-id pub-id-type="doi">10.1146/annurev-vision-091718-014809</pub-id><pub-id pub-id-type="pmid">31226012</pub-id></element-citation></ref><ref id="bib30"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Esteban</surname><given-names>O</given-names></name><name><surname>Markiewicz</surname><given-names>CJ</given-names></name><name><surname>Blair</surname><given-names>RW</given-names></name><name><surname>Moodie</surname><given-names>CA</given-names></name><name><surname>Isik</surname><given-names>AI</given-names></name><name><surname>Erramuzpe</surname><given-names>A</given-names></name><name><surname>Kent</surname><given-names>JD</given-names></name><name><surname>Goncalves</surname><given-names>M</given-names></name><name><surname>DuPre</surname><given-names>E</given-names></name><name><surname>Snyder</surname><given-names>M</given-names></name><name><surname>Oya</surname><given-names>H</given-names></name><name><surname>Ghosh</surname><given-names>SS</given-names></name><name><surname>Wright</surname><given-names>J</given-names></name><name><surname>Durnez</surname><given-names>J</given-names></name><name><surname>Poldrack</surname><given-names>RA</given-names></name><name><surname>Gorgolewski</surname><given-names>KJ</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>fMRIPrep: a robust preprocessing pipeline for functional MRI</article-title><source>Nature Methods</source><volume>16</volume><fpage>111</fpage><lpage>116</lpage><pub-id pub-id-type="doi">10.1038/s41592-018-0235-4</pub-id><pub-id pub-id-type="pmid">30532080</pub-id></element-citation></ref><ref id="bib31"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Fonov</surname><given-names>VS</given-names></name><name><surname>Evans</surname><given-names>AC</given-names></name><name><surname>McKinstry</surname><given-names>RC</given-names></name><name><surname>Almli</surname><given-names>CR</given-names></name><name><surname>Collins</surname><given-names>DL</given-names></name></person-group><year iso-8601-date="2009">2009</year><article-title>Unbiased nonlinear average age-appropriate brain templates from birth to adulthood</article-title><source>NeuroImage</source><volume>47</volume><fpage>S39</fpage><lpage>S41</lpage><pub-id pub-id-type="doi">10.1016/S1053-8119(09)70884-5</pub-id></element-citation></ref><ref id="bib32"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Franchak</surname><given-names>JM</given-names></name><name><surname>Heeger</surname><given-names>DJ</given-names></name><name><surname>Hasson</surname><given-names>U</given-names></name><name><surname>Adolph</surname><given-names>KE</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Free viewing gaze behavior in infants and adults</article-title><source>Infancy</source><volume>21</volume><fpage>262</fpage><lpage>287</lpage><pub-id pub-id-type="doi">10.1111/infa.12119</pub-id><pub-id pub-id-type="pmid">27134573</pub-id></element-citation></ref><ref id="bib33"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Gallagher</surname><given-names>HL</given-names></name><name><surname>Happé</surname><given-names>F</given-names></name><name><surname>Brunswick</surname><given-names>N</given-names></name><name><surname>Fletcher</surname><given-names>PC</given-names></name><name><surname>Frith</surname><given-names>U</given-names></name><name><surname>Frith</surname><given-names>CD</given-names></name></person-group><year iso-8601-date="2000">2000</year><article-title>Reading the mind in cartoons and stories: an fMRI study of “theory of mind” in verbal and nonverbal tasks</article-title><source>Neuropsychologia</source><volume>38</volume><fpage>11</fpage><lpage>21</lpage><pub-id pub-id-type="doi">10.1016/s0028-3932(99)00053-6</pub-id><pub-id pub-id-type="pmid">10617288</pub-id></element-citation></ref><ref id="bib34"><element-citation publication-type="preprint"><person-group person-group-type="author"><name><surname>Geerligs</surname><given-names>L</given-names></name><name><surname>Gözükara</surname><given-names>D</given-names></name><name><surname>Oetringer</surname><given-names>D</given-names></name><name><surname>Campbell</surname><given-names>K</given-names></name><name><surname>van Gerven</surname><given-names>M</given-names></name><name><surname>Güçlü</surname><given-names>U</given-names></name></person-group><year iso-8601-date="2021">2021</year><article-title>A Partially Nested Cortical Hierarchy of Neural States Underlies Event Segmentation in the Human Brain</article-title><source>bioRxiv</source><pub-id pub-id-type="doi">10.1101/2021.02.05.429165</pub-id></element-citation></ref><ref id="bib35"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Gogtay</surname><given-names>N</given-names></name><name><surname>Nugent</surname><given-names>TF</given-names></name><name><surname>Herman</surname><given-names>DH</given-names></name><name><surname>Ordonez</surname><given-names>A</given-names></name><name><surname>Greenstein</surname><given-names>D</given-names></name><name><surname>Hayashi</surname><given-names>KM</given-names></name><name><surname>Clasen</surname><given-names>L</given-names></name><name><surname>Toga</surname><given-names>AW</given-names></name><name><surname>Giedd</surname><given-names>JN</given-names></name><name><surname>Rapoport</surname><given-names>JL</given-names></name><name><surname>Thompson</surname><given-names>PM</given-names></name></person-group><year iso-8601-date="2006">2006</year><article-title>Dynamic mapping of normal human hippocampal development</article-title><source>Hippocampus</source><volume>16</volume><fpage>664</fpage><lpage>672</lpage><pub-id pub-id-type="doi">10.1002/hipo.20193</pub-id><pub-id pub-id-type="pmid">16826559</pub-id></element-citation></ref><ref id="bib36"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Gorgolewski</surname><given-names>K</given-names></name><name><surname>Burns</surname><given-names>CD</given-names></name><name><surname>Madison</surname><given-names>C</given-names></name><name><surname>Clark</surname><given-names>D</given-names></name><name><surname>Halchenko</surname><given-names>YO</given-names></name><name><surname>Waskom</surname><given-names>ML</given-names></name><name><surname>Ghosh</surname><given-names>SS</given-names></name></person-group><year iso-8601-date="2011">2011</year><article-title>Nipype: a flexible, lightweight and extensible neuroimaging data processing framework in python</article-title><source>Frontiers in Neuroinformatics</source><volume>5</volume><elocation-id>13</elocation-id><pub-id pub-id-type="doi">10.3389/fninf.2011.00013</pub-id><pub-id pub-id-type="pmid">21897815</pub-id></element-citation></ref><ref id="bib37"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Grady</surname><given-names>C</given-names></name></person-group><year iso-8601-date="2012">2012</year><article-title>The cognitive neuroscience of ageing</article-title><source>Nature Reviews. Neuroscience</source><volume>13</volume><fpage>491</fpage><lpage>505</lpage><pub-id pub-id-type="doi">10.1038/nrn3256</pub-id><pub-id pub-id-type="pmid">22714020</pub-id></element-citation></ref><ref id="bib38"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Greve</surname><given-names>DN</given-names></name><name><surname>Fischl</surname><given-names>B</given-names></name></person-group><year iso-8601-date="2009">2009</year><article-title>Accurate and robust brain image alignment using boundary-based registration</article-title><source>NeuroImage</source><volume>48</volume><fpage>63</fpage><lpage>72</lpage><pub-id pub-id-type="doi">10.1016/j.neuroimage.2009.06.060</pub-id><pub-id pub-id-type="pmid">19573611</pub-id></element-citation></ref><ref id="bib39"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Han</surname><given-names>S</given-names></name><name><surname>Jiang</surname><given-names>Y</given-names></name><name><surname>Humphreys</surname><given-names>GW</given-names></name></person-group><year iso-8601-date="2007">2007</year><article-title>Watching cartoons activates the medial prefrontal cortex in children</article-title><source>Chinese Science Bulletin</source><volume>52</volume><fpage>3371</fpage><lpage>3375</lpage><pub-id pub-id-type="doi">10.1007/s11434-007-0505-5</pub-id></element-citation></ref><ref id="bib40"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hasson</surname><given-names>U</given-names></name><name><surname>Avidan</surname><given-names>G</given-names></name><name><surname>Gelbard</surname><given-names>H</given-names></name><name><surname>Vallines</surname><given-names>I</given-names></name><name><surname>Harel</surname><given-names>M</given-names></name><name><surname>Minshew</surname><given-names>N</given-names></name><name><surname>Behrmann</surname><given-names>M</given-names></name></person-group><year iso-8601-date="2009">2009</year><article-title>Shared and idiosyncratic cortical activation patterns in autism revealed under continuous real-life viewing conditions</article-title><source>Autism Research</source><volume>2</volume><fpage>220</fpage><lpage>231</lpage><pub-id pub-id-type="doi">10.1002/aur.89</pub-id><pub-id pub-id-type="pmid">19708061</pub-id></element-citation></ref><ref id="bib41"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hasson</surname><given-names>U</given-names></name><name><surname>Chen</surname><given-names>J</given-names></name><name><surname>Honey</surname><given-names>CJ</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>Hierarchical process memory: memory as an integral component of information processing</article-title><source>Trends in Cognitive Sciences</source><volume>19</volume><fpage>304</fpage><lpage>313</lpage><pub-id pub-id-type="doi">10.1016/j.tics.2015.04.006</pub-id><pub-id pub-id-type="pmid">25980649</pub-id></element-citation></ref><ref id="bib42"><element-citation publication-type="confproc"><person-group person-group-type="author"><name><surname>Huntenburg</surname><given-names>JM</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>Evaluating nonlinear coregistration of BOLD EPI and T1w images</article-title><conf-name>Freie Universität Berlin</conf-name></element-citation></ref><ref id="bib43"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Jenkinson</surname><given-names>M</given-names></name><name><surname>Bannister</surname><given-names>P</given-names></name><name><surname>Brady</surname><given-names>M</given-names></name><name><surname>Smith</surname><given-names>S</given-names></name></person-group><year iso-8601-date="2002">2002</year><article-title>Improved optimization for the robust and accurate linear registration and motion correction of brain images</article-title><source>NeuroImage</source><volume>17</volume><fpage>825</fpage><lpage>841</lpage><pub-id pub-id-type="doi">10.1016/s1053-8119(02)91132-8</pub-id><pub-id pub-id-type="pmid">12377157</pub-id></element-citation></ref><ref id="bib44"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Keidel</surname><given-names>JL</given-names></name><name><surname>Oedekoven</surname><given-names>CSH</given-names></name><name><surname>Tut</surname><given-names>AC</given-names></name><name><surname>Bird</surname><given-names>CM</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>Multiscale integration of contextual information during a naturalistic task</article-title><source>Cerebral Cortex</source><volume>28</volume><fpage>3531</fpage><lpage>3539</lpage><pub-id pub-id-type="doi">10.1093/cercor/bhx218</pub-id><pub-id pub-id-type="pmid">28968727</pub-id></element-citation></ref><ref id="bib45"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Keresztes</surname><given-names>A</given-names></name><name><surname>Ngo</surname><given-names>CT</given-names></name><name><surname>Lindenberger</surname><given-names>U</given-names></name><name><surname>Werkle-Bergner</surname><given-names>M</given-names></name><name><surname>Newcombe</surname><given-names>NS</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>Hippocampal maturation drives memory from generalization to specificity</article-title><source>Trends in Cognitive Sciences</source><volume>22</volume><fpage>676</fpage><lpage>686</lpage><pub-id pub-id-type="doi">10.1016/j.tics.2018.05.004</pub-id><pub-id pub-id-type="pmid">29934029</pub-id></element-citation></ref><ref id="bib46"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kirkorian</surname><given-names>HL</given-names></name><name><surname>Anderson</surname><given-names>DR</given-names></name><name><surname>Keen</surname><given-names>R</given-names></name></person-group><year iso-8601-date="2012">2012</year><article-title>Age differences in online processing of video: an eye movement study</article-title><source>Child Development</source><volume>83</volume><fpage>497</fpage><lpage>507</lpage><pub-id pub-id-type="doi">10.1111/j.1467-8624.2011.01719.x</pub-id><pub-id pub-id-type="pmid">22288510</pub-id></element-citation></ref><ref id="bib47"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Klein</surname><given-names>A</given-names></name><name><surname>Ghosh</surname><given-names>SS</given-names></name><name><surname>Bao</surname><given-names>FS</given-names></name><name><surname>Giard</surname><given-names>J</given-names></name><name><surname>Häme</surname><given-names>Y</given-names></name><name><surname>Stavsky</surname><given-names>E</given-names></name><name><surname>Lee</surname><given-names>N</given-names></name><name><surname>Rossa</surname><given-names>B</given-names></name><name><surname>Reuter</surname><given-names>M</given-names></name><name><surname>Chaibub Neto</surname><given-names>E</given-names></name><name><surname>Keshavan</surname><given-names>A</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>Mindboggling morphometry of human brains</article-title><source>PLOS Computational Biology</source><volume>13</volume><elocation-id>1005350</elocation-id><pub-id pub-id-type="doi">10.1371/journal.pcbi.1005350</pub-id><pub-id pub-id-type="pmid">28231282</pub-id></element-citation></ref><ref id="bib48"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kwon</surname><given-names>H</given-names></name><name><surname>Reiss</surname><given-names>AL</given-names></name><name><surname>Menon</surname><given-names>V</given-names></name></person-group><year iso-8601-date="2002">2002</year><article-title>Neural basis of protracted developmental changes in visuo-spatial working memory</article-title><source>PNAS</source><volume>99</volume><fpage>13336</fpage><lpage>13341</lpage><pub-id pub-id-type="doi">10.1073/pnas.162486399</pub-id><pub-id pub-id-type="pmid">12244209</pub-id></element-citation></ref><ref id="bib49"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Langnes</surname><given-names>E</given-names></name><name><surname>Vidal-Piñeiro</surname><given-names>D</given-names></name><name><surname>Sneve</surname><given-names>MH</given-names></name><name><surname>Amlien</surname><given-names>IK</given-names></name><name><surname>Walhovd</surname><given-names>KB</given-names></name><name><surname>Fjell</surname><given-names>AM</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>Development and decline of the hippocampal long-axis specialization and differentiation during encoding and retrieval of episodic memories</article-title><source>Cerebral Cortex</source><volume>29</volume><fpage>3398</fpage><lpage>3414</lpage><pub-id pub-id-type="doi">10.1093/cercor/bhy209</pub-id><pub-id pub-id-type="pmid">30272128</pub-id></element-citation></ref><ref id="bib50"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Lee</surname><given-names>CS</given-names></name><name><surname>Aly</surname><given-names>M</given-names></name><name><surname>Baldassano</surname><given-names>C</given-names></name></person-group><year iso-8601-date="2021">2021</year><article-title>Anticipation of temporally structured events in the brain</article-title><source>eLife</source><volume>10</volume><elocation-id>e64972</elocation-id><pub-id pub-id-type="doi">10.7554/eLife.64972</pub-id><pub-id pub-id-type="pmid">33884953</pub-id></element-citation></ref><ref id="bib51"><element-citation publication-type="preprint"><person-group person-group-type="author"><name><surname>Lerner</surname><given-names>Y</given-names></name><name><surname>Scherf</surname><given-names>KS</given-names></name><name><surname>Katkov</surname><given-names>M</given-names></name><name><surname>Hasson</surname><given-names>U</given-names></name><name><surname>Behrmann</surname><given-names>M</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>Age-Related Changes in Neural Networks Supporting Complex Visual and Social Processing in Adolescence</article-title><source>bioRxiv</source><pub-id pub-id-type="doi">10.1101/650887</pub-id></element-citation></ref><ref id="bib52"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Maril</surname><given-names>A</given-names></name><name><surname>Davis</surname><given-names>PE</given-names></name><name><surname>Koo</surname><given-names>JJ</given-names></name><name><surname>Reggev</surname><given-names>N</given-names></name><name><surname>Zuckerman</surname><given-names>M</given-names></name><name><surname>Ehrenfeld</surname><given-names>L</given-names></name><name><surname>Mulkern</surname><given-names>RV</given-names></name><name><surname>Waber</surname><given-names>DP</given-names></name><name><surname>Rivkin</surname><given-names>MJ</given-names></name></person-group><year iso-8601-date="2010">2010</year><article-title>Developmental fMRI study of episodic verbal memory encoding in children</article-title><source>Neurology</source><volume>75</volume><fpage>2110</fpage><lpage>2116</lpage><pub-id pub-id-type="doi">10.1212/WNL.0b013e318201526e</pub-id><pub-id pub-id-type="pmid">21135385</pub-id></element-citation></ref><ref id="bib53"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Masís-Obando</surname><given-names>R</given-names></name><name><surname>Norman</surname><given-names>KA</given-names></name><name><surname>Baldassano</surname><given-names>C</given-names></name></person-group><year iso-8601-date="2022">2022</year><article-title>Schema representations in distinct brain networks support narrative memory during encoding and retrieval</article-title><source>eLife</source><volume>11</volume><elocation-id>e70445</elocation-id><pub-id pub-id-type="doi">10.7554/eLife.70445</pub-id><pub-id pub-id-type="pmid">35393941</pub-id></element-citation></ref><ref id="bib54"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Meissner</surname><given-names>TW</given-names></name><name><surname>Nordt</surname><given-names>M</given-names></name><name><surname>Weigelt</surname><given-names>S</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>Prolonged functional development of the parahippocampal place area and occipital place area</article-title><source>NeuroImage</source><volume>191</volume><fpage>104</fpage><lpage>115</lpage><pub-id pub-id-type="doi">10.1016/j.neuroimage.2019.02.025</pub-id><pub-id pub-id-type="pmid">30763610</pub-id></element-citation></ref><ref id="bib55"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Moraczewski</surname><given-names>D</given-names></name><name><surname>Chen</surname><given-names>G</given-names></name><name><surname>Redcay</surname><given-names>E</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>Inter-subject synchrony as an index of functional specialization in early childhood</article-title><source>Scientific Reports</source><volume>8</volume><fpage>1</fpage><lpage>12</lpage><pub-id pub-id-type="doi">10.1038/s41598-018-20600-0</pub-id><pub-id pub-id-type="pmid">29396415</pub-id></element-citation></ref><ref id="bib56"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Moraczewski</surname><given-names>D</given-names></name><name><surname>Nketia</surname><given-names>J</given-names></name><name><surname>Redcay</surname><given-names>E</given-names></name></person-group><year iso-8601-date="2020">2020</year><article-title>Cortical temporal hierarchy is immature in middle childhood</article-title><source>NeuroImage</source><volume>216</volume><elocation-id>116616</elocation-id><pub-id pub-id-type="doi">10.1016/j.neuroimage.2020.116616</pub-id><pub-id pub-id-type="pmid">32058003</pub-id></element-citation></ref><ref id="bib57"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Nadel</surname><given-names>L</given-names></name><name><surname>Moscovitch</surname><given-names>M</given-names></name></person-group><year iso-8601-date="1997">1997</year><article-title>Memory consolidation, retrograde amnesia and the hippocampal complex</article-title><source>Current Opinion in Neurobiology</source><volume>7</volume><fpage>217</fpage><lpage>227</lpage><pub-id pub-id-type="doi">10.1016/s0959-4388(97)80010-4</pub-id><pub-id pub-id-type="pmid">9142752</pub-id></element-citation></ref><ref id="bib58"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Nastase</surname><given-names>SA</given-names></name><name><surname>Gazzola</surname><given-names>V</given-names></name><name><surname>Hasson</surname><given-names>U</given-names></name><name><surname>Keysers</surname><given-names>C</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>Measuring shared responses across subjects using intersubject correlation</article-title><source>Social Cognitive and Affective Neuroscience</source><volume>14</volume><fpage>667</fpage><lpage>685</lpage><pub-id pub-id-type="doi">10.1093/scan/nsz037</pub-id><pub-id pub-id-type="pmid">31099394</pub-id></element-citation></ref><ref id="bib59"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Nelson</surname><given-names>K</given-names></name></person-group><year iso-8601-date="1986">1986</year><source>Event Knowledge Structure and Function in Development</source><publisher-name>Erlbaum</publisher-name></element-citation></ref><ref id="bib60"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Pavias</surname><given-names>M</given-names></name><name><surname>van den Broek</surname><given-names>P</given-names></name><name><surname>Hickendorff</surname><given-names>M</given-names></name><name><surname>Beker</surname><given-names>K</given-names></name><name><surname>Van Leijenhorst</surname><given-names>L</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Effects of social-cognitive processing demands and structural importance on narrative recall: differences between children, adolescents, and adults</article-title><source>Discourse Processes</source><volume>53</volume><fpage>488</fpage><lpage>512</lpage><pub-id pub-id-type="doi">10.1080/0163853X.2016.1171070</pub-id></element-citation></ref><ref id="bib61"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Petroni</surname><given-names>A</given-names></name><name><surname>Cohen</surname><given-names>SS</given-names></name><name><surname>Ai</surname><given-names>L</given-names></name><name><surname>Langer</surname><given-names>N</given-names></name><name><surname>Henin</surname><given-names>S</given-names></name><name><surname>Vanderwal</surname><given-names>T</given-names></name><name><surname>Milham</surname><given-names>MP</given-names></name><name><surname>Parra</surname><given-names>LC</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>The Variability of Neural Responses to Naturalistic Videos Change with Age and Sex</article-title><source>ENeuro</source><volume>5</volume><elocation-id>ENEURO.0244-17.2017</elocation-id><pub-id pub-id-type="doi">10.1523/ENEURO.0244-17.2017</pub-id><pub-id pub-id-type="pmid">29379880</pub-id></element-citation></ref><ref id="bib62"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Poldrack</surname><given-names>RA</given-names></name><name><surname>Baker</surname><given-names>CI</given-names></name><name><surname>Durnez</surname><given-names>J</given-names></name><name><surname>Gorgolewski</surname><given-names>KJ</given-names></name><name><surname>Matthews</surname><given-names>PM</given-names></name><name><surname>Munafò</surname><given-names>MR</given-names></name><name><surname>Nichols</surname><given-names>TE</given-names></name><name><surname>Poline</surname><given-names>JB</given-names></name><name><surname>Vul</surname><given-names>E</given-names></name><name><surname>Yarkoni</surname><given-names>T</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>Scanning the horizon: towards transparent and reproducible neuroimaging research</article-title><source>Nature Reviews Neuroscience</source><volume>18</volume><fpage>115</fpage><lpage>126</lpage><pub-id pub-id-type="doi">10.1038/nrn.2016.167</pub-id></element-citation></ref><ref id="bib63"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Poppenk</surname><given-names>J</given-names></name><name><surname>Evensmoen</surname><given-names>HR</given-names></name><name><surname>Moscovitch</surname><given-names>M</given-names></name><name><surname>Nadel</surname><given-names>L</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>Long-axis specialization of the human hippocampus</article-title><source>Trends in Cognitive Sciences</source><volume>17</volume><fpage>230</fpage><lpage>240</lpage><pub-id pub-id-type="doi">10.1016/j.tics.2013.03.005</pub-id><pub-id pub-id-type="pmid">23597720</pub-id></element-citation></ref><ref id="bib64"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Power</surname><given-names>JD</given-names></name><name><surname>Mitra</surname><given-names>A</given-names></name><name><surname>Laumann</surname><given-names>TO</given-names></name><name><surname>Snyder</surname><given-names>AZ</given-names></name><name><surname>Schlaggar</surname><given-names>BL</given-names></name><name><surname>Petersen</surname><given-names>SE</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>Methods to detect, characterize, and remove motion artifact in resting state fMRI</article-title><source>NeuroImage</source><volume>84</volume><fpage>320</fpage><lpage>341</lpage><pub-id pub-id-type="doi">10.1016/j.neuroimage.2013.08.048</pub-id><pub-id pub-id-type="pmid">23994314</pub-id></element-citation></ref><ref id="bib65"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Raichle</surname><given-names>ME</given-names></name><name><surname>MacLeod</surname><given-names>AM</given-names></name><name><surname>Snyder</surname><given-names>AZ</given-names></name><name><surname>Powers</surname><given-names>WJ</given-names></name><name><surname>Gusnard</surname><given-names>DA</given-names></name><name><surname>Shulman</surname><given-names>GL</given-names></name></person-group><year iso-8601-date="2001">2001</year><article-title>A default mode of brain function</article-title><source>PNAS</source><volume>98</volume><fpage>676</fpage><lpage>682</lpage><pub-id pub-id-type="doi">10.1073/pnas.98.2.676</pub-id></element-citation></ref><ref id="bib66"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ralph</surname><given-names>MAL</given-names></name><name><surname>Jefferies</surname><given-names>E</given-names></name><name><surname>Patterson</surname><given-names>K</given-names></name><name><surname>Rogers</surname><given-names>TT</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>The neural and computational bases of semantic cognition</article-title><source>Nature Reviews. Neuroscience</source><volume>18</volume><fpage>42</fpage><lpage>55</lpage><pub-id pub-id-type="doi">10.1038/nrn.2016.150</pub-id><pub-id pub-id-type="pmid">27881854</pub-id></element-citation></ref><ref id="bib67"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Reagh</surname><given-names>ZM</given-names></name><name><surname>Delarazan</surname><given-names>AI</given-names></name><name><surname>Garber</surname><given-names>A</given-names></name><name><surname>Ranganath</surname><given-names>C</given-names></name></person-group><year iso-8601-date="2020">2020</year><article-title>Aging alters neural activity at event boundaries in the hippocampus and posterior medial network</article-title><source>Nature Communications</source><volume>11</volume><fpage>1</fpage><lpage>12</lpage><pub-id pub-id-type="doi">10.1038/s41467-020-17713-4</pub-id><pub-id pub-id-type="pmid">32769969</pub-id></element-citation></ref><ref id="bib68"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Richardson</surname><given-names>H</given-names></name><name><surname>Lisandrelli</surname><given-names>G</given-names></name><name><surname>Riobueno-Naylor</surname><given-names>A</given-names></name><name><surname>Saxe</surname><given-names>R</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>Development of the social brain from age three to twelve years</article-title><source>Nature Communications</source><volume>9</volume><fpage>1</fpage><lpage>12</lpage><pub-id pub-id-type="doi">10.1038/s41467-018-03399-2</pub-id><pub-id pub-id-type="pmid">29531321</pub-id></element-citation></ref><ref id="bib69"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Richardson</surname><given-names>H</given-names></name><name><surname>Saxe</surname><given-names>R</given-names></name></person-group><year iso-8601-date="2020">2020</year><article-title>Development of predictive responses in theory of mind brain regions</article-title><source>Developmental Science</source><volume>23</volume><elocation-id>e12863</elocation-id><pub-id pub-id-type="doi">10.1111/desc.12863</pub-id><pub-id pub-id-type="pmid">31125472</pub-id></element-citation></ref><ref id="bib70"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Samson</surname><given-names>D</given-names></name><name><surname>Apperly</surname><given-names>IA</given-names></name><name><surname>Chiavarino</surname><given-names>C</given-names></name><name><surname>Humphreys</surname><given-names>GW</given-names></name></person-group><year iso-8601-date="2004">2004</year><article-title>Left temporoparietal junction is necessary for representing someone else’s belief</article-title><source>Nature Neuroscience</source><volume>7</volume><fpage>499</fpage><lpage>500</lpage><pub-id pub-id-type="doi">10.1038/nn1223</pub-id><pub-id pub-id-type="pmid">15077111</pub-id></element-citation></ref><ref id="bib71"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Saxe</surname><given-names>R</given-names></name><name><surname>Kanwisher</surname><given-names>N</given-names></name></person-group><year iso-8601-date="2003">2003</year><article-title>People thinking about thinking people: the role of the temporo-parietal junction in “theory of mind.”</article-title><source>NeuroImage</source><volume>19</volume><fpage>1835</fpage><lpage>1842</lpage><pub-id pub-id-type="doi">10.1016/s1053-8119(03)00230-1</pub-id><pub-id pub-id-type="pmid">12948738</pub-id></element-citation></ref><ref id="bib72"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Schaefer</surname><given-names>A</given-names></name><name><surname>Kong</surname><given-names>R</given-names></name><name><surname>Gordon</surname><given-names>EM</given-names></name><name><surname>Laumann</surname><given-names>TO</given-names></name><name><surname>Zuo</surname><given-names>XN</given-names></name><name><surname>Holmes</surname><given-names>AJ</given-names></name><name><surname>Eickhoff</surname><given-names>SB</given-names></name><name><surname>Yeo</surname><given-names>BTT</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>Local-global parcellation of the human cerebral cortex from intrinsic functional connectivity MRI</article-title><source>Cerebral Cortex</source><volume>28</volume><fpage>3095</fpage><lpage>3114</lpage><pub-id pub-id-type="doi">10.1093/cercor/bhx179</pub-id><pub-id pub-id-type="pmid">28981612</pub-id></element-citation></ref><ref id="bib73"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Schneider</surname><given-names>W</given-names></name><name><surname>Pressley</surname><given-names>M</given-names></name></person-group><year iso-8601-date="2013">2013</year><source>Memory Development between Two and Twenty</source><publisher-name>Psychology Press</publisher-name><pub-id pub-id-type="doi">10.4324/9780203774496</pub-id></element-citation></ref><ref id="bib74"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Sebastian</surname><given-names>CL</given-names></name><name><surname>Fontaine</surname><given-names>NMG</given-names></name><name><surname>Bird</surname><given-names>G</given-names></name><name><surname>Blakemore</surname><given-names>S-J</given-names></name><name><surname>Brito</surname><given-names>SAD</given-names></name><name><surname>McCrory</surname><given-names>EJP</given-names></name><name><surname>Viding</surname><given-names>E</given-names></name></person-group><year iso-8601-date="2012">2012</year><article-title>Neural processing associated with cognitive and affective Theory of Mind in adolescents and adults</article-title><source>Social Cognitive and Affective Neuroscience</source><volume>7</volume><fpage>53</fpage><lpage>63</lpage><pub-id pub-id-type="doi">10.1093/scan/nsr023</pub-id><pub-id pub-id-type="pmid">21467048</pub-id></element-citation></ref><ref id="bib75"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Sekeres</surname><given-names>MJ</given-names></name><name><surname>Winocur</surname><given-names>G</given-names></name><name><surname>Moscovitch</surname><given-names>M</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>The hippocampus and related neocortical structures in memory transformation</article-title><source>Neuroscience Letters</source><volume>680</volume><fpage>39</fpage><lpage>53</lpage><pub-id pub-id-type="doi">10.1016/j.neulet.2018.05.006</pub-id><pub-id pub-id-type="pmid">29733974</pub-id></element-citation></ref><ref id="bib76"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Stephens</surname><given-names>GJ</given-names></name><name><surname>Honey</surname><given-names>CJ</given-names></name><name><surname>Hasson</surname><given-names>U</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>A place for time: the spatiotemporal structure of neural dynamics during natural audition</article-title><source>Journal of Neurophysiology</source><volume>110</volume><fpage>2019</fpage><lpage>2026</lpage><pub-id pub-id-type="doi">10.1152/jn.00268.2013</pub-id><pub-id pub-id-type="pmid">23926041</pub-id></element-citation></ref><ref id="bib77"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Stern</surname><given-names>CE</given-names></name><name><surname>Corkin</surname><given-names>S</given-names></name><name><surname>González</surname><given-names>RG</given-names></name><name><surname>Guimaraes</surname><given-names>AR</given-names></name><name><surname>Baker</surname><given-names>JR</given-names></name><name><surname>Jennings</surname><given-names>PJ</given-names></name><name><surname>Carr</surname><given-names>CA</given-names></name><name><surname>Sugiura</surname><given-names>RM</given-names></name><name><surname>Vedantham</surname><given-names>V</given-names></name><name><surname>Rosen</surname><given-names>BR</given-names></name></person-group><year iso-8601-date="1996">1996</year><article-title>The hippocampal formation participates in novel picture encoding: evidence from functional magnetic resonance imaging</article-title><source>PNAS</source><volume>93</volume><fpage>8660</fpage><lpage>8665</lpage><pub-id pub-id-type="doi">10.1073/pnas.93.16.8660</pub-id><pub-id pub-id-type="pmid">8710927</pub-id></element-citation></ref><ref id="bib78"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Treiber</surname><given-names>JM</given-names></name><name><surname>White</surname><given-names>NS</given-names></name><name><surname>Steed</surname><given-names>TC</given-names></name><name><surname>Bartsch</surname><given-names>H</given-names></name><name><surname>Holland</surname><given-names>D</given-names></name><name><surname>Farid</surname><given-names>N</given-names></name><name><surname>McDonald</surname><given-names>CR</given-names></name><name><surname>Carter</surname><given-names>BS</given-names></name><name><surname>Dale</surname><given-names>AM</given-names></name><name><surname>Chen</surname><given-names>CC</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Characterization and Correction of Geometric Distortions in 814 Diffusion Weighted Images</article-title><source>PLOS ONE</source><volume>11</volume><elocation-id>e0152472</elocation-id><pub-id pub-id-type="doi">10.1371/journal.pone.0152472</pub-id><pub-id pub-id-type="pmid">27027775</pub-id></element-citation></ref><ref id="bib79"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Tustison</surname><given-names>NJ</given-names></name><name><surname>Avants</surname><given-names>BB</given-names></name><name><surname>Cook</surname><given-names>PA</given-names></name><name><surname>Zheng</surname><given-names>Y</given-names></name><name><surname>Egan</surname><given-names>A</given-names></name><name><surname>Yushkevich</surname><given-names>PA</given-names></name><name><surname>Gee</surname><given-names>JC</given-names></name></person-group><year iso-8601-date="2010">2010</year><article-title>N4ITK: improved N3 bias correction</article-title><source>IEEE Transactions on Medical Imaging</source><volume>29</volume><fpage>1310</fpage><lpage>1320</lpage><pub-id pub-id-type="doi">10.1109/TMI.2010.2046908</pub-id><pub-id pub-id-type="pmid">20378467</pub-id></element-citation></ref><ref id="bib80"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>van Kesteren</surname><given-names>MTR</given-names></name><name><surname>Fernández</surname><given-names>G</given-names></name><name><surname>Norris</surname><given-names>DG</given-names></name><name><surname>Hermans</surname><given-names>EJ</given-names></name></person-group><year iso-8601-date="2010">2010</year><article-title>Persistent schema-dependent hippocampal-neocortical connectivity during memory encoding and postencoding rest in humans</article-title><source>PNAS</source><volume>107</volume><fpage>7550</fpage><lpage>7555</lpage><pub-id pub-id-type="doi">10.1073/pnas.0914892107</pub-id><pub-id pub-id-type="pmid">20363957</pub-id></element-citation></ref><ref id="bib81"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Vanderwal</surname><given-names>T</given-names></name><name><surname>Eilbott</surname><given-names>J</given-names></name><name><surname>Castellanos</surname><given-names>FX</given-names></name></person-group><year iso-8601-date="2020">2020</year><article-title>Movies in the magnet: naturalistic paradigms in developmental functional neuroimaging</article-title><source>Developmental Cognitive Neuroscience</source><volume>36</volume><elocation-id>100600</elocation-id><pub-id pub-id-type="doi">10.1016/j.dcn.2018.10.004</pub-id><pub-id pub-id-type="pmid">30551970</pub-id></element-citation></ref><ref id="bib82"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wang</surname><given-names>S</given-names></name><name><surname>Peterson</surname><given-names>DJ</given-names></name><name><surname>Gatenby</surname><given-names>JC</given-names></name><name><surname>Li</surname><given-names>W</given-names></name><name><surname>Grabowski</surname><given-names>TJ</given-names></name><name><surname>Madhyastha</surname><given-names>TM</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>Evaluation of field map and nonlinear registration methods for correction of susceptibility artifacts in diffusion MRI</article-title><source>Frontiers in Neuroinformatics</source><volume>11</volume><elocation-id>17</elocation-id><pub-id pub-id-type="doi">10.3389/fninf.2017.00017</pub-id><pub-id pub-id-type="pmid">28270762</pub-id></element-citation></ref><ref id="bib83"><element-citation publication-type="preprint"><person-group person-group-type="author"><name><surname>Yates</surname><given-names>TS</given-names></name><name><surname>Skalaban</surname><given-names>LJ</given-names></name><name><surname>Ellis</surname><given-names>CT</given-names></name><name><surname>Bracher</surname><given-names>AJ</given-names></name><name><surname>Baldassano</surname><given-names>C</given-names></name><name><surname>Turk-Browne</surname><given-names>NB</given-names></name></person-group><year iso-8601-date="2021">2021</year><article-title>Neural Event Segmentation of Continuous Experience in Human Infants</article-title><source>bioRxiv</source><pub-id pub-id-type="doi">10.1101/2021.06.16.448755</pub-id></element-citation></ref><ref id="bib84"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Zacks</surname><given-names>JM</given-names></name><name><surname>Tversky</surname><given-names>B</given-names></name></person-group><year iso-8601-date="2001">2001</year><article-title>Event structure in perception and conception</article-title><source>Psychological Bulletin</source><volume>127</volume><fpage>3</fpage><lpage>21</lpage><pub-id pub-id-type="doi">10.1037/0033-2909.127.1.3</pub-id><pub-id pub-id-type="pmid">11271755</pub-id></element-citation></ref><ref id="bib85"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Zeidman</surname><given-names>P</given-names></name><name><surname>Mullally</surname><given-names>SL</given-names></name><name><surname>Maguire</surname><given-names>EA</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>Constructing, perceiving, and maintaining scenes: hippocampal activity and connectivity</article-title><source>Cerebral Cortex</source><volume>25</volume><fpage>3836</fpage><lpage>3855</lpage><pub-id pub-id-type="doi">10.1093/cercor/bhu266</pub-id><pub-id pub-id-type="pmid">25405941</pub-id></element-citation></ref><ref id="bib86"><element-citation publication-type="confproc"><person-group person-group-type="author"><name><surname>Zhang</surname><given-names>Y</given-names></name><name><surname>Brady</surname><given-names>M</given-names></name><name><surname>Smith</surname><given-names>S</given-names></name></person-group><year iso-8601-date="2001">2001</year><article-title>Segmentation of brain MR images through a hidden Markov random field model and the expectation-maximization algorithm</article-title><conf-name>IEEE Transactions on Medical Imaging</conf-name><fpage>45</fpage><lpage>57</lpage><pub-id pub-id-type="doi">10.1109/42.906424</pub-id></element-citation></ref><ref id="bib87"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Zheng</surname><given-names>Y</given-names></name><name><surname>Zacks</surname><given-names>JM</given-names></name><name><surname>Markson</surname><given-names>L</given-names></name></person-group><year iso-8601-date="2020">2020</year><article-title>The development of event perception and memory</article-title><source>Cognitive Development</source><volume>54</volume><elocation-id>100848</elocation-id><pub-id pub-id-type="doi">10.1016/j.cogdev.2020.100848</pub-id></element-citation></ref></ref-list><app-group><app id="appendix-1"><title>Appendix 1</title><p>For across-group analyses, we want to calculate the ISC between two groups of subjects, with two different sets of shared responses, <italic>g</italic><sub>1</sub> and <italic>g</italic><sub>2</sub>, and different levels of variance, <inline-formula><mml:math id="inf1"><mml:msub><mml:mi>ϵ</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:math></inline-formula> and <inline-formula><mml:math id="inf2"><mml:msub><mml:mi>ϵ</mml:mi><mml:mi>j</mml:mi></mml:msub></mml:math></inline-formula>. To simplify the notation, we define <inline-formula><mml:math id="inf3"><mml:mrow><mml:mrow><mml:msubsup><mml:mi>g</mml:mi><mml:mn>1</mml:mn><mml:mi>T</mml:mi></mml:msubsup><mml:mo>⁢</mml:mo><mml:msub><mml:mi>g</mml:mi><mml:mn>1</mml:mn></mml:msub></mml:mrow><mml:mo>=</mml:mo><mml:msub><mml:mi>a</mml:mi><mml:mn>1</mml:mn></mml:msub></mml:mrow></mml:math></inline-formula>, <inline-formula><mml:math id="inf4"><mml:mrow><mml:mrow><mml:msubsup><mml:mi>g</mml:mi><mml:mn>2</mml:mn><mml:mi>T</mml:mi></mml:msubsup><mml:mo>⁢</mml:mo><mml:msub><mml:mi>g</mml:mi><mml:mn>2</mml:mn></mml:msub></mml:mrow><mml:mo>=</mml:mo><mml:msub><mml:mi>a</mml:mi><mml:mn>2</mml:mn></mml:msub></mml:mrow></mml:math></inline-formula>, <inline-formula><mml:math id="inf5"><mml:mrow><mml:mrow><mml:msubsup><mml:mi>g</mml:mi><mml:mn>1</mml:mn><mml:mi>T</mml:mi></mml:msubsup><mml:mo>⁢</mml:mo><mml:msub><mml:mi>g</mml:mi><mml:mn>2</mml:mn></mml:msub></mml:mrow><mml:mo>=</mml:mo><mml:msub><mml:mi>a</mml:mi><mml:mi>B</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula>, <inline-formula><mml:math id="inf6"><mml:mrow><mml:mrow><mml:mi>E</mml:mi><mml:mo>⁡</mml:mo><mml:mrow><mml:mo stretchy="false">[</mml:mo><mml:mrow><mml:msubsup><mml:mi>ϵ</mml:mi><mml:mi>i</mml:mi><mml:mi>T</mml:mi></mml:msubsup><mml:mo>⁢</mml:mo><mml:msub><mml:mi>ϵ</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow><mml:mo stretchy="false">]</mml:mo></mml:mrow></mml:mrow><mml:mo>=</mml:mo><mml:msub><mml:mi>b</mml:mi><mml:mn>1</mml:mn></mml:msub></mml:mrow></mml:math></inline-formula> and <inline-formula><mml:math id="inf7"><mml:mrow><mml:mrow><mml:mi>E</mml:mi><mml:mo>⁡</mml:mo><mml:mrow><mml:mo stretchy="false">[</mml:mo><mml:mrow><mml:msubsup><mml:mi>ϵ</mml:mi><mml:mi>j</mml:mi><mml:mi>T</mml:mi></mml:msubsup><mml:mo>⁢</mml:mo><mml:msub><mml:mi>ϵ</mml:mi><mml:mi>j</mml:mi></mml:msub></mml:mrow><mml:mo stretchy="false">]</mml:mo></mml:mrow></mml:mrow><mml:mo>=</mml:mo><mml:msub><mml:mi>b</mml:mi><mml:mn>2</mml:mn></mml:msub></mml:mrow></mml:math></inline-formula>. We would like to estimate the correlation between <italic>g</italic><sub>1</sub> and <italic>g</italic><sub>2</sub>, regardless of the difference in signal-to-noise levels between the two groups. That is, our goal is to compute:<disp-formula id="equ1"><mml:math id="m1"><mml:mtable columnspacing="5pt" displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:mi>I</mml:mi><mml:mo>⁢</mml:mo><mml:mi>S</mml:mi><mml:mo>⁢</mml:mo><mml:msub><mml:mi>C</mml:mi><mml:mi>b</mml:mi></mml:msub></mml:mrow></mml:mtd><mml:mtd columnalign="left"><mml:mrow><mml:mi/><mml:mo>=</mml:mo><mml:mstyle displaystyle="false"><mml:mfrac><mml:msub><mml:mi>a</mml:mi><mml:mi>B</mml:mi></mml:msub><mml:mrow><mml:msqrt><mml:msub><mml:mi>a</mml:mi><mml:mn>1</mml:mn></mml:msub></mml:msqrt><mml:mo>⁢</mml:mo><mml:msqrt><mml:msub><mml:mi>a</mml:mi><mml:mn>2</mml:mn></mml:msub></mml:msqrt></mml:mrow></mml:mfrac></mml:mstyle></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></disp-formula></p><p>If we know the ISCs for each group, from <xref ref-type="disp-formula" rid="equ8">equation 1</xref>:<disp-formula id="equ2"><mml:math id="m2"><mml:mtable columnspacing="5pt" displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:mi>s</mml:mi><mml:mo>⁢</mml:mo><mml:mi>h</mml:mi><mml:mo>⁢</mml:mo><mml:mi>I</mml:mi><mml:mo>⁢</mml:mo><mml:mi>S</mml:mi><mml:mo>⁢</mml:mo><mml:msub><mml:mi>C</mml:mi><mml:mn>1</mml:mn></mml:msub></mml:mrow></mml:mtd><mml:mtd columnalign="left"><mml:mrow><mml:mi/><mml:mo>=</mml:mo><mml:mstyle displaystyle="false"><mml:mfrac><mml:mrow><mml:msup><mml:mi>N</mml:mi><mml:mn>2</mml:mn></mml:msup><mml:mo>⁢</mml:mo><mml:msub><mml:mi>a</mml:mi><mml:mn>1</mml:mn></mml:msub></mml:mrow><mml:mrow><mml:mrow><mml:msup><mml:mi>N</mml:mi><mml:mn>2</mml:mn></mml:msup><mml:mo>⁢</mml:mo><mml:msub><mml:mi>a</mml:mi><mml:mn>1</mml:mn></mml:msub></mml:mrow><mml:mo>+</mml:mo><mml:mrow><mml:mn>4</mml:mn><mml:mo>⁢</mml:mo><mml:mi>N</mml:mi><mml:mo>⁢</mml:mo><mml:msub><mml:mi>b</mml:mi><mml:mn>1</mml:mn></mml:msub></mml:mrow></mml:mrow></mml:mfrac></mml:mstyle></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></disp-formula></p><p>and<disp-formula id="equ3"><mml:math id="m3"><mml:mtable columnspacing="5pt" displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:mi>s</mml:mi><mml:mo>⁢</mml:mo><mml:mi>h</mml:mi><mml:mo>⁢</mml:mo><mml:mi>I</mml:mi><mml:mo>⁢</mml:mo><mml:mi>S</mml:mi><mml:mo>⁢</mml:mo><mml:msub><mml:mi>C</mml:mi><mml:mn>2</mml:mn></mml:msub></mml:mrow></mml:mtd><mml:mtd columnalign="left"><mml:mrow><mml:mrow><mml:mi/><mml:mo>=</mml:mo><mml:mstyle displaystyle="false"><mml:mfrac><mml:mrow><mml:msup><mml:mi>N</mml:mi><mml:mn>2</mml:mn></mml:msup><mml:mo>⁢</mml:mo><mml:msub><mml:mi>a</mml:mi><mml:mn>2</mml:mn></mml:msub></mml:mrow><mml:mrow><mml:mrow><mml:msup><mml:mi>N</mml:mi><mml:mn>2</mml:mn></mml:msup><mml:mo>⁢</mml:mo><mml:msub><mml:mi>a</mml:mi><mml:mn>2</mml:mn></mml:msub></mml:mrow><mml:mo>+</mml:mo><mml:mrow><mml:mn>4</mml:mn><mml:mo>⁢</mml:mo><mml:mi>N</mml:mi><mml:mo>⁢</mml:mo><mml:msub><mml:mi>b</mml:mi><mml:mn>2</mml:mn></mml:msub></mml:mrow></mml:mrow></mml:mfrac></mml:mstyle></mml:mrow><mml:mo>,</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></disp-formula></p><p>where <inline-formula><mml:math id="inf8"><mml:mi>N</mml:mi></mml:math></inline-formula> is the number of subjects in each group, and the ISC between the two groups is:</p><p><inline-formula><mml:math id="inf9"><mml:mtable columnspacing="5pt" displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:mi>s</mml:mi><mml:mo>⁢</mml:mo><mml:mi>h</mml:mi><mml:mo>⁢</mml:mo><mml:mi>I</mml:mi><mml:mo>⁢</mml:mo><mml:mi>S</mml:mi><mml:mo>⁢</mml:mo><mml:msub><mml:mi>C</mml:mi><mml:mi>B</mml:mi></mml:msub></mml:mrow></mml:mtd><mml:mtd columnalign="left"><mml:mrow><mml:mrow><mml:mi/><mml:mo>=</mml:mo><mml:mstyle displaystyle="false"><mml:mfrac><mml:mrow><mml:msup><mml:mi>N</mml:mi><mml:mn>2</mml:mn></mml:msup><mml:mo>⁢</mml:mo><mml:msub><mml:mi>a</mml:mi><mml:mi>B</mml:mi></mml:msub></mml:mrow><mml:mrow><mml:msqrt><mml:mrow><mml:mrow><mml:msup><mml:mi>N</mml:mi><mml:mn>2</mml:mn></mml:msup><mml:mo>⁢</mml:mo><mml:msub><mml:mi>a</mml:mi><mml:mn>1</mml:mn></mml:msub></mml:mrow><mml:mo>+</mml:mo><mml:mrow><mml:mn>4</mml:mn><mml:mo>⁢</mml:mo><mml:mi>N</mml:mi><mml:mo>⁢</mml:mo><mml:msub><mml:mi>b</mml:mi><mml:mn>1</mml:mn></mml:msub></mml:mrow></mml:mrow></mml:msqrt><mml:mo>⁢</mml:mo><mml:msqrt><mml:mrow><mml:mrow><mml:msup><mml:mi>N</mml:mi><mml:mn>2</mml:mn></mml:msup><mml:mo>⁢</mml:mo><mml:msub><mml:mi>a</mml:mi><mml:mn>2</mml:mn></mml:msub></mml:mrow><mml:mo>+</mml:mo><mml:mrow><mml:mn>4</mml:mn><mml:mo>⁢</mml:mo><mml:mi>N</mml:mi><mml:mo>⁢</mml:mo><mml:msub><mml:mi>b</mml:mi><mml:mn>2</mml:mn></mml:msub></mml:mrow></mml:mrow></mml:msqrt></mml:mrow></mml:mfrac></mml:mstyle></mml:mrow><mml:mo>.</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></inline-formula></p><p>Dividing <inline-formula><mml:math id="inf10"><mml:mrow><mml:mi>s</mml:mi><mml:mo>⁢</mml:mo><mml:mi>h</mml:mi><mml:mo>⁢</mml:mo><mml:mi>I</mml:mi><mml:mo>⁢</mml:mo><mml:mi>S</mml:mi><mml:mo>⁢</mml:mo><mml:msub><mml:mi>C</mml:mi><mml:mi>B</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula> by the geometric mean of <inline-formula><mml:math id="inf11"><mml:mrow><mml:mi>s</mml:mi><mml:mo>⁢</mml:mo><mml:mi>h</mml:mi><mml:mo>⁢</mml:mo><mml:mi>I</mml:mi><mml:mo>⁢</mml:mo><mml:mi>S</mml:mi><mml:mo>⁢</mml:mo><mml:msub><mml:mi>C</mml:mi><mml:mn>1</mml:mn></mml:msub></mml:mrow></mml:math></inline-formula> and <inline-formula><mml:math id="inf12"><mml:mrow><mml:mi>s</mml:mi><mml:mo>⁢</mml:mo><mml:mi>h</mml:mi><mml:mo>⁢</mml:mo><mml:mi>I</mml:mi><mml:mo>⁢</mml:mo><mml:mi>S</mml:mi><mml:mo>⁢</mml:mo><mml:msub><mml:mi>C</mml:mi><mml:mn>2</mml:mn></mml:msub></mml:mrow></mml:math></inline-formula> allows us to calculate the between-group ISC without the <inline-formula><mml:math id="inf13"><mml:mi>b</mml:mi></mml:math></inline-formula>’s:<disp-formula id="equ4"><mml:math id="m4"><mml:mtable columnspacing="5pt" displaystyle="true" rowspacing="0pt"><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:mi>I</mml:mi><mml:mo>⁢</mml:mo><mml:mi>S</mml:mi><mml:mo>⁢</mml:mo><mml:msub><mml:mi>C</mml:mi><mml:mi>b</mml:mi></mml:msub></mml:mrow></mml:mtd><mml:mtd columnalign="left"><mml:mrow><mml:mi/><mml:mo>=</mml:mo><mml:mstyle displaystyle="false"><mml:mfrac><mml:mrow><mml:mi>s</mml:mi><mml:mo>⁢</mml:mo><mml:mi>h</mml:mi><mml:mo>⁢</mml:mo><mml:mi>I</mml:mi><mml:mo>⁢</mml:mo><mml:mi>S</mml:mi><mml:mo>⁢</mml:mo><mml:msub><mml:mi>C</mml:mi><mml:mi>B</mml:mi></mml:msub></mml:mrow><mml:mrow><mml:msqrt><mml:mrow><mml:mi>s</mml:mi><mml:mo>⁢</mml:mo><mml:mi>h</mml:mi><mml:mo>⁢</mml:mo><mml:mi>I</mml:mi><mml:mo>⁢</mml:mo><mml:mi>S</mml:mi><mml:mo>⁢</mml:mo><mml:msub><mml:mi>C</mml:mi><mml:mn>1</mml:mn></mml:msub></mml:mrow></mml:msqrt><mml:mo>⁢</mml:mo><mml:msqrt><mml:mrow><mml:mi>s</mml:mi><mml:mo>⁢</mml:mo><mml:mi>h</mml:mi><mml:mo>⁢</mml:mo><mml:mi>I</mml:mi><mml:mo>⁢</mml:mo><mml:mi>S</mml:mi><mml:mo>⁢</mml:mo><mml:msub><mml:mi>C</mml:mi><mml:mn>2</mml:mn></mml:msub></mml:mrow></mml:msqrt></mml:mrow></mml:mfrac></mml:mstyle></mml:mrow></mml:mtd></mml:mtr><mml:mtr><mml:mtd/><mml:mtd columnalign="left"><mml:mrow><mml:mrow><mml:mi/><mml:mo>=</mml:mo><mml:mstyle displaystyle="false"><mml:mfrac><mml:msub><mml:mi>a</mml:mi><mml:mi>B</mml:mi></mml:msub><mml:mrow><mml:msqrt><mml:msub><mml:mi>a</mml:mi><mml:mn>1</mml:mn></mml:msub></mml:msqrt><mml:mo>⁢</mml:mo><mml:msqrt><mml:msub><mml:mi>a</mml:mi><mml:mn>2</mml:mn></mml:msub></mml:msqrt></mml:mrow></mml:mfrac></mml:mstyle></mml:mrow><mml:mo>.</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></disp-formula></p></app><app id="appendix-2"><title>Appendix 2</title><p>We start by assuming that the response timecourse for every subject consists of a response that is shared across subjects, <inline-formula><mml:math id="inf14"><mml:mi>g</mml:mi></mml:math></inline-formula>, and a subject-specific response, <inline-formula><mml:math id="inf15"><mml:mi>ϵ</mml:mi></mml:math></inline-formula>. The response timecourse for subject <inline-formula><mml:math id="inf16"><mml:mi>i</mml:mi></mml:math></inline-formula> can therefore be represented as <inline-formula><mml:math id="inf17"><mml:mrow><mml:msub><mml:mi>s</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mrow><mml:mi>g</mml:mi><mml:mo>+</mml:mo><mml:msub><mml:mi>ϵ</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:mrow></mml:math></inline-formula>. For simplicity, all subject timecourses, <inline-formula><mml:math id="inf18"><mml:mi>s</mml:mi></mml:math></inline-formula>, have zero mean, we define <inline-formula><mml:math id="inf19"><mml:mi>a</mml:mi></mml:math></inline-formula> as the norm of <inline-formula><mml:math id="inf20"><mml:mi>g</mml:mi></mml:math></inline-formula> (<inline-formula><mml:math id="inf21"><mml:mrow><mml:mrow><mml:msup><mml:mi>g</mml:mi><mml:mi>T</mml:mi></mml:msup><mml:mo>⁢</mml:mo><mml:mi>g</mml:mi></mml:mrow><mml:mo>=</mml:mo><mml:mi>a</mml:mi></mml:mrow></mml:math></inline-formula>), and we define <inline-formula><mml:math id="inf22"><mml:mrow><mml:mrow><mml:mi>E</mml:mi><mml:mo>⁡</mml:mo><mml:mrow><mml:mo stretchy="false">[</mml:mo><mml:mrow><mml:msubsup><mml:mi>ϵ</mml:mi><mml:mi>i</mml:mi><mml:mi>T</mml:mi></mml:msubsup><mml:mo>⁢</mml:mo><mml:msub><mml:mi>ϵ</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow><mml:mo stretchy="false">]</mml:mo></mml:mrow></mml:mrow><mml:mo>=</mml:mo><mml:mi>b</mml:mi></mml:mrow></mml:math></inline-formula>. If we have N subjects in total, the split half ISC (<inline-formula><mml:math id="inf23"><mml:mrow><mml:mi>s</mml:mi><mml:mo>⁢</mml:mo><mml:mi>h</mml:mi><mml:mo>⁢</mml:mo><mml:mi>I</mml:mi><mml:mo>⁢</mml:mo><mml:mi>S</mml:mi><mml:mo>⁢</mml:mo><mml:mi>C</mml:mi></mml:mrow></mml:math></inline-formula>) is:<disp-formula id="equ5"><label>(1)</label><mml:math id="m5"><mml:mrow><mml:mtable columnalign="right left" rowspacing="4pt" columnspacing="1em"><mml:mtr><mml:mtd><mml:mi>s</mml:mi><mml:mi>h</mml:mi><mml:mi>I</mml:mi><mml:mi>S</mml:mi><mml:mi>C</mml:mi></mml:mtd><mml:mtd><mml:mo>=</mml:mo><mml:mrow><mml:mrow><mml:mi mathvariant="double-struck">E</mml:mi></mml:mrow></mml:mrow><mml:mo>⁡</mml:mo><mml:mrow><mml:mo>[</mml:mo><mml:mrow><mml:mi>ρ</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:munderover><mml:mo>∑</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>N</mml:mi><mml:mrow><mml:mo>/</mml:mo></mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:munderover><mml:msub><mml:mi>s</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:munderover><mml:mo>∑</mml:mo><mml:mrow><mml:mi>j</mml:mi><mml:mo>=</mml:mo><mml:mi>N</mml:mi><mml:mrow><mml:mo>/</mml:mo></mml:mrow><mml:mn>2</mml:mn><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>N</mml:mi></mml:mrow></mml:munderover><mml:msub><mml:mi>s</mml:mi><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>]</mml:mo></mml:mrow></mml:mtd></mml:mtr><mml:mtr><mml:mtd/><mml:mtd><mml:mo>=</mml:mo><mml:mrow><mml:mrow><mml:mi mathvariant="double-struck">E</mml:mi></mml:mrow></mml:mrow><mml:mo>⁡</mml:mo><mml:mrow><mml:mo>[</mml:mo><mml:mrow><mml:mi>ρ</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mfrac><mml:mi>N</mml:mi><mml:mn>2</mml:mn></mml:mfrac><mml:mi>g</mml:mi><mml:mo>+</mml:mo><mml:munderover><mml:mo>∑</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>N</mml:mi><mml:mrow><mml:mo>/</mml:mo></mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:munderover><mml:msub><mml:mi>ϵ</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:mfrac><mml:mi>N</mml:mi><mml:mn>2</mml:mn></mml:mfrac><mml:mi>g</mml:mi><mml:mo>+</mml:mo><mml:munderover><mml:mo>∑</mml:mo><mml:mrow><mml:mi>j</mml:mi><mml:mo>=</mml:mo><mml:mi>N</mml:mi><mml:mrow><mml:mo>/</mml:mo></mml:mrow><mml:mn>2</mml:mn><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>N</mml:mi></mml:mrow></mml:munderover><mml:msub><mml:mi>ϵ</mml:mi><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>]</mml:mo></mml:mrow></mml:mtd></mml:mtr><mml:mtr><mml:mtd/><mml:mtd><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mfrac><mml:msup><mml:mi>N</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup><mml:mn>4</mml:mn></mml:mfrac><mml:msup><mml:mi>g</mml:mi><mml:mrow><mml:mi>T</mml:mi></mml:mrow></mml:msup><mml:mi>g</mml:mi></mml:mrow><mml:mrow><mml:msqrt><mml:mfrac><mml:msup><mml:mi>N</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup><mml:mn>4</mml:mn></mml:mfrac><mml:msup><mml:mi>g</mml:mi><mml:mrow><mml:mi>T</mml:mi></mml:mrow></mml:msup><mml:mi>g</mml:mi><mml:mo>+</mml:mo><mml:mrow><mml:mrow><mml:mi mathvariant="double-struck">E</mml:mi></mml:mrow></mml:mrow><mml:mo>⁡</mml:mo><mml:mo stretchy="false">[</mml:mo><mml:munderover><mml:mo>∑</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>N</mml:mi><mml:mrow><mml:mo>/</mml:mo></mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:munderover><mml:msubsup><mml:mi>ϵ</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mi>T</mml:mi></mml:mrow></mml:msubsup><mml:msub><mml:mi>ϵ</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">]</mml:mo></mml:msqrt><mml:msqrt><mml:mfrac><mml:msup><mml:mi>N</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup><mml:mn>4</mml:mn></mml:mfrac><mml:msup><mml:mi>g</mml:mi><mml:mrow><mml:mi>T</mml:mi></mml:mrow></mml:msup><mml:mi>g</mml:mi><mml:mo>+</mml:mo><mml:mrow><mml:mrow><mml:mi mathvariant="double-struck">E</mml:mi></mml:mrow></mml:mrow><mml:mo>⁡</mml:mo><mml:mo stretchy="false">[</mml:mo><mml:munderover><mml:mo>∑</mml:mo><mml:mrow><mml:mi>j</mml:mi><mml:mo>=</mml:mo><mml:mi>N</mml:mi><mml:mrow><mml:mo>/</mml:mo></mml:mrow><mml:mn>2</mml:mn><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>N</mml:mi></mml:mrow></mml:munderover><mml:msubsup><mml:mi>ϵ</mml:mi><mml:mrow><mml:mi>j</mml:mi></mml:mrow><mml:mrow><mml:mi>T</mml:mi></mml:mrow></mml:msubsup><mml:msub><mml:mi>ϵ</mml:mi><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">]</mml:mo></mml:msqrt></mml:mrow></mml:mfrac></mml:mtd></mml:mtr><mml:mtr><mml:mtd/><mml:mtd><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:msup><mml:mi>N</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup><mml:mi>a</mml:mi></mml:mrow><mml:mrow><mml:msup><mml:mi>N</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup><mml:mi>a</mml:mi><mml:mo>+</mml:mo><mml:mn>2</mml:mn><mml:mi>N</mml:mi><mml:mi>b</mml:mi></mml:mrow></mml:mfrac></mml:mtd></mml:mtr><mml:mtr><mml:mtd/><mml:mtd><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mi>N</mml:mi><mml:mi>f</mml:mi></mml:mrow><mml:mrow><mml:mi>N</mml:mi><mml:mi>f</mml:mi><mml:mo>+</mml:mo><mml:mn>2</mml:mn></mml:mrow></mml:mfrac></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:math></disp-formula></p><p>where <inline-formula><mml:math id="inf24"><mml:mrow><mml:mi>f</mml:mi><mml:mo>=</mml:mo><mml:mrow><mml:mi>a</mml:mi><mml:mo>/</mml:mo><mml:mi>b</mml:mi></mml:mrow></mml:mrow></mml:math></inline-formula>, or the signal to noise ratio (the ratio of norms between <inline-formula><mml:math id="inf25"><mml:mi>g</mml:mi></mml:math></inline-formula> and <inline-formula><mml:math id="inf26"><mml:msub><mml:mi>ϵ</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:math></inline-formula>).</p><p>If we rearrange the variables in <xref ref-type="disp-formula" rid="equ8">Equation 1</xref>, we find that:<disp-formula id="equ6"><label>(2)</label><mml:math id="m6"><mml:mtable columnspacing="5pt" displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mi>f</mml:mi></mml:mtd><mml:mtd columnalign="left"><mml:mrow><mml:mrow><mml:mi/><mml:mo>=</mml:mo><mml:mstyle displaystyle="false"><mml:mfrac><mml:mrow><mml:mrow><mml:mn>2</mml:mn><mml:mo>*</mml:mo><mml:mi>s</mml:mi></mml:mrow><mml:mo>⁢</mml:mo><mml:mi>h</mml:mi><mml:mo>⁢</mml:mo><mml:mi>I</mml:mi><mml:mo>⁢</mml:mo><mml:mi>S</mml:mi><mml:mo>⁢</mml:mo><mml:mi>C</mml:mi></mml:mrow><mml:mrow><mml:mrow><mml:mo>-</mml:mo><mml:mrow><mml:mrow><mml:mi>N</mml:mi><mml:mo>*</mml:mo><mml:mi>s</mml:mi></mml:mrow><mml:mo>⁢</mml:mo><mml:mi>h</mml:mi><mml:mo>⁢</mml:mo><mml:mi>I</mml:mi><mml:mo>⁢</mml:mo><mml:mi>S</mml:mi><mml:mo>⁢</mml:mo><mml:mi>C</mml:mi></mml:mrow></mml:mrow><mml:mo>-</mml:mo><mml:mi>N</mml:mi></mml:mrow></mml:mfrac></mml:mstyle></mml:mrow><mml:mo>.</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></disp-formula></p><p>We can thus calculate <inline-formula><mml:math id="inf27"><mml:mrow><mml:mi>p</mml:mi><mml:mo>⁢</mml:mo><mml:mi>w</mml:mi><mml:mo>⁢</mml:mo><mml:mi>I</mml:mi><mml:mo>⁢</mml:mo><mml:mi>S</mml:mi><mml:mo>⁢</mml:mo><mml:mi>C</mml:mi></mml:mrow></mml:math></inline-formula> and <inline-formula><mml:math id="inf28"><mml:mrow><mml:mi>l</mml:mi><mml:mo>⁢</mml:mo><mml:mi>o</mml:mi><mml:mo>⁢</mml:mo><mml:mi>o</mml:mi><mml:mo>⁢</mml:mo><mml:mi>I</mml:mi><mml:mo>⁢</mml:mo><mml:mi>S</mml:mi><mml:mo>⁢</mml:mo><mml:mi>C</mml:mi></mml:mrow></mml:math></inline-formula> from <inline-formula><mml:math id="inf29"><mml:mrow><mml:mi>s</mml:mi><mml:mo>⁢</mml:mo><mml:mi>h</mml:mi><mml:mo>⁢</mml:mo><mml:mi>I</mml:mi><mml:mo>⁢</mml:mo><mml:mi>S</mml:mi><mml:mo>⁢</mml:mo><mml:mi>C</mml:mi></mml:mrow></mml:math></inline-formula> as they relate to <inline-formula><mml:math id="inf30"><mml:mi>f</mml:mi></mml:math></inline-formula> as follows. For <inline-formula><mml:math id="inf31"><mml:mrow><mml:mi>p</mml:mi><mml:mo>⁢</mml:mo><mml:mi>w</mml:mi><mml:mo>⁢</mml:mo><mml:mi>I</mml:mi><mml:mo>⁢</mml:mo><mml:mi>S</mml:mi><mml:mo>⁢</mml:mo><mml:mi>C</mml:mi></mml:mrow></mml:math></inline-formula> between subjects <inline-formula><mml:math id="inf32"><mml:mi>i</mml:mi></mml:math></inline-formula> and <inline-formula><mml:math id="inf33"><mml:mi>j</mml:mi></mml:math></inline-formula>:<disp-formula id="equ7"><mml:math id="m7"><mml:mrow><mml:mtable columnalign="right left" rowspacing="4pt" columnspacing="1em"><mml:mtr><mml:mtd><mml:mi>p</mml:mi><mml:mi>w</mml:mi><mml:mi>I</mml:mi><mml:mi>S</mml:mi><mml:mi>C</mml:mi></mml:mtd><mml:mtd><mml:mo>=</mml:mo><mml:mrow><mml:mrow><mml:mi mathvariant="double-struck">E</mml:mi></mml:mrow></mml:mrow><mml:mo>⁡</mml:mo><mml:mo stretchy="false">[</mml:mo><mml:mi>ρ</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>s</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>s</mml:mi><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:mo stretchy="false">]</mml:mo></mml:mtd></mml:mtr><mml:mtr><mml:mtd/><mml:mtd><mml:mo>=</mml:mo><mml:mrow><mml:mrow><mml:mi mathvariant="double-struck">E</mml:mi></mml:mrow></mml:mrow><mml:mo>⁡</mml:mo><mml:mo stretchy="false">[</mml:mo><mml:mi>ρ</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>g</mml:mi><mml:mo>+</mml:mo><mml:msub><mml:mi>ϵ</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:mi>g</mml:mi><mml:mo>+</mml:mo><mml:msub><mml:mi>ϵ</mml:mi><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:mo stretchy="false">]</mml:mo></mml:mtd></mml:mtr><mml:mtr><mml:mtd/><mml:mtd><mml:mo>=</mml:mo><mml:mrow><mml:mrow><mml:mi mathvariant="double-struck">E</mml:mi></mml:mrow></mml:mrow><mml:mo>⁡</mml:mo><mml:mrow><mml:mo>[</mml:mo><mml:mfrac><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>g</mml:mi><mml:mo>+</mml:mo><mml:msub><mml:mi>ϵ</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:msup><mml:mo stretchy="false">)</mml:mo><mml:mrow><mml:mi>T</mml:mi></mml:mrow></mml:msup><mml:mo stretchy="false">(</mml:mo><mml:mi>g</mml:mi><mml:mo>+</mml:mo><mml:msub><mml:mi>ϵ</mml:mi><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mrow><mml:msqrt><mml:mo stretchy="false">(</mml:mo><mml:mi>g</mml:mi><mml:mo>+</mml:mo><mml:msub><mml:mi>ϵ</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:msup><mml:mo stretchy="false">)</mml:mo><mml:mrow><mml:mi>T</mml:mi></mml:mrow></mml:msup><mml:mo stretchy="false">(</mml:mo><mml:mi>g</mml:mi><mml:mo>+</mml:mo><mml:msub><mml:mi>ϵ</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:msqrt><mml:msqrt><mml:mo stretchy="false">(</mml:mo><mml:mi>g</mml:mi><mml:mo>+</mml:mo><mml:msub><mml:mi>ϵ</mml:mi><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:msup><mml:mo stretchy="false">)</mml:mo><mml:mrow><mml:mi>T</mml:mi></mml:mrow></mml:msup><mml:mo stretchy="false">(</mml:mo><mml:mi>g</mml:mi><mml:mo>+</mml:mo><mml:msub><mml:mi>ϵ</mml:mi><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:msqrt></mml:mrow></mml:mfrac><mml:mo>]</mml:mo></mml:mrow></mml:mtd></mml:mtr><mml:mtr><mml:mtd/><mml:mtd><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:msup><mml:mi>g</mml:mi><mml:mrow><mml:mi>T</mml:mi></mml:mrow></mml:msup><mml:mi>g</mml:mi></mml:mrow><mml:mrow><mml:msqrt><mml:msup><mml:mi>g</mml:mi><mml:mrow><mml:mi>T</mml:mi></mml:mrow></mml:msup><mml:mi>g</mml:mi><mml:mo>+</mml:mo><mml:mrow><mml:mrow><mml:mi mathvariant="double-struck">E</mml:mi></mml:mrow></mml:mrow><mml:mo>⁡</mml:mo><mml:mo stretchy="false">[</mml:mo><mml:msubsup><mml:mi>ϵ</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mi>T</mml:mi></mml:mrow></mml:msubsup><mml:msub><mml:mi>ϵ</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">]</mml:mo></mml:msqrt><mml:msqrt><mml:msup><mml:mi>g</mml:mi><mml:mrow><mml:mi>T</mml:mi></mml:mrow></mml:msup><mml:mi>g</mml:mi><mml:mo>+</mml:mo><mml:mrow><mml:mrow><mml:mi mathvariant="double-struck">E</mml:mi></mml:mrow></mml:mrow><mml:mo>⁡</mml:mo><mml:mo stretchy="false">[</mml:mo><mml:msubsup><mml:mi>ϵ</mml:mi><mml:mrow><mml:mi>j</mml:mi></mml:mrow><mml:mrow><mml:mi>T</mml:mi></mml:mrow></mml:msubsup><mml:msub><mml:mi>ϵ</mml:mi><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">]</mml:mo></mml:msqrt></mml:mrow></mml:mfrac></mml:mtd></mml:mtr><mml:mtr><mml:mtd/><mml:mtd><mml:mo>=</mml:mo><mml:mfrac><mml:mi>a</mml:mi><mml:mrow><mml:mi>a</mml:mi><mml:mo>+</mml:mo><mml:mi>b</mml:mi></mml:mrow></mml:mfrac></mml:mtd></mml:mtr><mml:mtr><mml:mtd/><mml:mtd><mml:mo>=</mml:mo><mml:mfrac><mml:mi>f</mml:mi><mml:mrow><mml:mi>f</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:mfrac><mml:mo>,</mml:mo></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:math></disp-formula></p><p>and for <inline-formula><mml:math id="inf34"><mml:mrow><mml:mi>l</mml:mi><mml:mo>⁢</mml:mo><mml:mi>o</mml:mi><mml:mo>⁢</mml:mo><mml:mi>o</mml:mi><mml:mo>⁢</mml:mo><mml:mi>I</mml:mi><mml:mo>⁢</mml:mo><mml:mi>S</mml:mi><mml:mo>⁢</mml:mo><mml:mi>C</mml:mi></mml:mrow></mml:math></inline-formula>, between one left-out subject, and all others:<disp-formula id="equ8"><mml:math id="m8"><mml:mrow><mml:mtable columnalign="right left" rowspacing="4pt" columnspacing="1em"><mml:mtr><mml:mtd><mml:mi>l</mml:mi><mml:mi>o</mml:mi><mml:mi>o</mml:mi><mml:mi>I</mml:mi><mml:mi>S</mml:mi><mml:mi>C</mml:mi></mml:mtd><mml:mtd><mml:mo>=</mml:mo><mml:mrow><mml:mrow><mml:mi mathvariant="double-struck">E</mml:mi></mml:mrow></mml:mrow><mml:mo>⁡</mml:mo><mml:mrow><mml:mo>[</mml:mo><mml:mrow><mml:mi>ρ</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>s</mml:mi><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:munderover><mml:mo>∑</mml:mo><mml:mrow><mml:mi>j</mml:mi><mml:mo>=</mml:mo><mml:mn>2</mml:mn></mml:mrow><mml:mrow><mml:mi>N</mml:mi></mml:mrow></mml:munderover><mml:msub><mml:mi>s</mml:mi><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>]</mml:mo></mml:mrow></mml:mtd></mml:mtr><mml:mtr><mml:mtd/><mml:mtd><mml:mo>=</mml:mo><mml:mrow><mml:mrow><mml:mi mathvariant="double-struck">E</mml:mi></mml:mrow></mml:mrow><mml:mo>⁡</mml:mo><mml:mrow><mml:mo>[</mml:mo><mml:mrow><mml:mi>ρ</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>g</mml:mi><mml:mo>+</mml:mo><mml:msub><mml:mi>ϵ</mml:mi><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mi>N</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">)</mml:mo><mml:mi>g</mml:mi><mml:mo>+</mml:mo><mml:munderover><mml:mo>∑</mml:mo><mml:mrow><mml:mi>j</mml:mi><mml:mo>=</mml:mo><mml:mn>2</mml:mn></mml:mrow><mml:mrow><mml:mi>N</mml:mi></mml:mrow></mml:munderover><mml:msub><mml:mi>ϵ</mml:mi><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>]</mml:mo></mml:mrow></mml:mtd></mml:mtr><mml:mtr><mml:mtd/><mml:mtd><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>N</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">)</mml:mo><mml:mi>a</mml:mi></mml:mrow><mml:mrow><mml:msqrt><mml:mi>a</mml:mi><mml:mo>+</mml:mo><mml:mi>b</mml:mi></mml:msqrt><mml:msqrt><mml:mo stretchy="false">(</mml:mo><mml:mi>N</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn><mml:msup><mml:mo stretchy="false">)</mml:mo><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup><mml:mi>a</mml:mi><mml:mo>+</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mi>N</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">)</mml:mo><mml:mi>b</mml:mi></mml:msqrt></mml:mrow></mml:mfrac></mml:mtd></mml:mtr><mml:mtr><mml:mtd/><mml:mtd><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>N</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">)</mml:mo><mml:mi>f</mml:mi></mml:mrow><mml:mrow><mml:msqrt><mml:mi>f</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:msqrt><mml:msqrt><mml:mo stretchy="false">(</mml:mo><mml:mi>N</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn><mml:msup><mml:mo stretchy="false">)</mml:mo><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup><mml:mi>f</mml:mi><mml:mo>+</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mi>N</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:msqrt></mml:mrow></mml:mfrac></mml:mtd></mml:mtr><mml:mtr><mml:mtd/><mml:mtd><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:msqrt><mml:mi>N</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:msqrt><mml:mi>f</mml:mi></mml:mrow><mml:mrow><mml:msqrt><mml:mi>f</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:msqrt><mml:msqrt><mml:mo stretchy="false">(</mml:mo><mml:mi>N</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">)</mml:mo><mml:mi>f</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:msqrt></mml:mrow></mml:mfrac><mml:mo>.</mml:mo></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:math></disp-formula></p><p>Thus, for example, if there are 40 subjects, and <inline-formula><mml:math id="inf35"><mml:mrow><mml:mi>s</mml:mi><mml:mo>⁢</mml:mo><mml:mi>h</mml:mi><mml:mo>⁢</mml:mo><mml:mi>I</mml:mi><mml:mo>⁢</mml:mo><mml:mi>S</mml:mi><mml:mo>⁢</mml:mo><mml:mi>C</mml:mi></mml:mrow></mml:math></inline-formula> is 0.5, the estimated <inline-formula><mml:math id="inf36"><mml:mrow><mml:mrow><mml:mi>p</mml:mi><mml:mo>⁢</mml:mo><mml:mi>w</mml:mi><mml:mo>⁢</mml:mo><mml:mi>I</mml:mi><mml:mo>⁢</mml:mo><mml:mi>S</mml:mi><mml:mo>⁢</mml:mo><mml:mi>C</mml:mi></mml:mrow><mml:mo>=</mml:mo><mml:mn>0.05</mml:mn></mml:mrow></mml:math></inline-formula> and the estimated <inline-formula><mml:math id="inf37"><mml:mrow><mml:mrow><mml:mi>l</mml:mi><mml:mo>⁢</mml:mo><mml:mi>o</mml:mi><mml:mo>⁢</mml:mo><mml:mi>o</mml:mi><mml:mo>⁢</mml:mo><mml:mi>I</mml:mi><mml:mo>⁢</mml:mo><mml:mi>S</mml:mi><mml:mo>⁢</mml:mo><mml:mi>C</mml:mi></mml:mrow><mml:mo>=</mml:mo><mml:mn>0.18</mml:mn></mml:mrow></mml:math></inline-formula>.</p></app></app-group></back><sub-article article-type="editor-report" id="sa0"><front-stub><article-id pub-id-type="doi">10.7554/eLife.69430.sa0</article-id><title-group><article-title>Editor's evaluation</article-title></title-group><contrib-group><contrib contrib-type="author"><name><surname>Kok</surname><given-names>Peter</given-names></name><role specific-use="editor">Reviewing Editor</role><aff><institution-wrap><institution-id institution-id-type="ror">https://ror.org/02jx3x895</institution-id><institution>University College London</institution></institution-wrap><country>United Kingdom</country></aff></contrib></contrib-group><related-object id="sa0ro1" object-id-type="id" object-id="10.1101/2021.04.12.439526" link-type="continued-by" xlink:href="https://sciety.org/articles/activity/10.1101/2021.04.12.439526"/></front-stub><body><p>Cohen et al., present analyses of a large publicly available set of neuroimaging data from children and adolescents watching an animated video, and is likely to be of interest to neuroscientists interested in methods for analyzing naturalistic neuroimaging data, or those interested in the development of narrative processing in the brain. The methodological approach developed here is a valuable addition to the repertoire of developmental neuroscience.</p></body></sub-article><sub-article article-type="decision-letter" id="sa1"><front-stub><article-id pub-id-type="doi">10.7554/eLife.69430.sa1</article-id><title-group><article-title>Decision letter</article-title></title-group><contrib-group content-type="section"><contrib contrib-type="editor"><name><surname>Kok</surname><given-names>Peter</given-names></name><role>Reviewing Editor</role><aff><institution-wrap><institution-id institution-id-type="ror">https://ror.org/02jx3x895</institution-id><institution>University College London</institution></institution-wrap><country>United Kingdom</country></aff></contrib></contrib-group><contrib-group><contrib contrib-type="reviewer"><name><surname>Kok</surname><given-names>Peter</given-names></name><role>Reviewer</role><aff><institution-wrap><institution-id institution-id-type="ror">https://ror.org/02jx3x895</institution-id><institution>University College London</institution></institution-wrap><country>United Kingdom</country></aff></contrib><contrib contrib-type="reviewer"><name><surname>Saxe</surname><given-names>Rebecca</given-names></name><role>Reviewer</role><aff><institution-wrap><institution-id institution-id-type="ror">https://ror.org/042nb2s44</institution-id><institution>MIT</institution></institution-wrap><country>United States</country></aff></contrib><contrib contrib-type="reviewer"><name><surname>Reagh</surname><given-names>Zachariah M</given-names></name><role>Reviewer</role><aff><institution-wrap><institution-id institution-id-type="ror">https://ror.org/05rrcem69</institution-id><institution>University of California, Davis</institution></institution-wrap><country>United States</country></aff></contrib></contrib-group></front-stub><body><boxed-text id="sa2-box1"><p>Our editorial process produces two outputs: (i) <ext-link ext-link-type="uri" xlink:href="https://sciety.org/articles/activity/10.1101/2021.04.12.439526">public reviews</ext-link> designed to be posted alongside <ext-link ext-link-type="uri" xlink:href="https://www.biorxiv.org/content/10.1101/2021.04.12.439526v1">the preprint</ext-link> for the benefit of readers; (ii) feedback on the manuscript for the authors, including requests for revisions, shown below. We also include an acceptance summary that explains what the editors found interesting or important about the work.</p></boxed-text><p><bold>Decision letter after peer review:</bold></p><p>Thank you for submitting your article &quot;Developmental changes in story-evoked responses in the neocortex and hippocampus&quot; for consideration by <italic>eLife</italic>. Your article has been reviewed by 3 peer reviewers, including Peter Kok as Reviewing Editor and Reviewer #1, and the evaluation has been overseen by Floris de Lange as the Senior Editor. The following individuals involved in review of your submission have agreed to reveal their identity: Rebecca Saxe (with help from Frederik Kamps) (Reviewer #2); Zachariah M Reagh (Reviewer #3).</p><p>The reviewers have discussed their reviews with one another, and the Reviewing Editor has drafted this to help you prepare a revised submission.</p><p>Essential revisions:</p><p>1. It needs to be carefully ruled out that (some of) the results can be explained by lower SNR in the younger age groups. See the reviewers' recommendations for authors for detailed suggestions.</p><p>2. It is not clear which hypotheses were tested, supported and refuted in the current study. We suggest you either improve the theoretical framework of the study, and clearly describe the hypotheses tested, or reframe the paper as an exploratory or methods paper. The reviewers provide some suggestions for how you might go about this.</p><p>3. It would greatly strengthen confidence in the current findings, which seem quite exploratory rather than hypothesis-driven, if they could be replicated in an independent data set. There are multiple public datasets of children watching videos, could any of these be leveraged to replicate the current findings?</p><p>4. The boundary ratings are obtained from adults, and may therefore not accurately reflect those of younger participants. It would strengthen the paper if boundary ratings could be obtained across the age range studied here.</p><p>5. How can we be sure developmental changes in the timing of event transitions reflect increasing &quot;anticipation&quot; in the older group, rather than lagging processes in the younger group? And are anticipatory shifts as long as 20s cognitively plausible?</p><p>6. Given the relatively uncontrolled nature of the stimuli, it is challenging to know exactly what video content drove responses for any given region. In addition to neural variance, differential eye and head movements induced by move content may also explain variance in the data. This should be acknowledged and discussed.</p><p>7. There is a relatively loose use of anatomy in places, e.g. regarding the TPJ. This should be either improved or acknowledged.</p><p>We encourage you to refer to the individual reviews for detailed recommendations on how to address these points.</p><p><italic>Reviewer #1 (Recommendations for the authors):</italic></p><p>– Could increased similarity in participants' eye movements (i.e. the way they overtly sample the videos) with age explain some of the effects reported here?</p><p>– Could there be a difference in head motion between age groups? Importantly, head motion might affect some regions (e.g. lateral ones) more than others (medial ones).</p><p>– Do the authors think that any of their effects are due to general development of the cortex rather than narrative comprehension? That is, might some of their effects also be found when participants watch scrambled videos without structure or meaning?</p><p>– Figure 6, right panels: can you make the different age groups more easily distinguishable?</p><p>– Seimen's -&gt; Siemens</p><p><italic>Reviewer #2 (Recommendations for the authors):</italic></p><p>Major 1. The authors should significantly reframe the paper. There are many ways this could be done. One possibility is to hone attention toward a specific network most closely associated with &quot;narrative&quot; processing based on similar adult work, or which shows the strongest correlations to behaviorally-determined event boundaries. In this case, the authors should take care to provide clear definitions of the various terms in the manuscript, and clear hypotheses and alternative hypotheses. A second possibility is that the paper could be reframed in terms of the methodological approach (i.e., using HMM to explore event structure in naturalistic video data, which may have particular promise in pediatric datasets).</p><p>Major 2. Specific suggestions for addressing the concern that key effects are driving by lower data quality in younger children:</p><p>The authors should show within-group ISC across the cortex for young and old groups separately, not just the direct comparison of the two groups. Beyond confirming that the data in young children look reasonable, this analysis would reveal which regions actually show reliable within-group ISC (especially in the young group alone), and which do not. For example, it is possible that only occipital parcels show strong within-group ISC (as suggested by Supplemental Figure 1); if so, then it is not surprising to find no difference in within-group ISC between older and younger groups in regions beyond the occipital cortex, since reliable video responses could not really be detected there.</p><p>For the new between-group ISC measure (Figure 2), despite normalizing by within group ISC, this result could still be driven by lower data quality in younger kids than older kids. The strongest test of a qualitative developmental change in video responses would be to ask whether &quot;young-young group&quot; ISC is greater than &quot;young-old group&quot; ISC. If young children predict other young children better than older adolescents, then there is a reliable signal in the young group that cannot be explained by lower data quality in the younger sample than the older one. The alternative is that any comparison between a good dataset and a bad dataset will yield lower between group ISC than expected based on within-group ISC (i.e., driven by the older group only, by virtue of the higher data quality in that group).</p><p>The authors should also show HMM fits across the cortex, particularly in the young group alone. The comparison of model-fit-difference between young and old subjects in Supplemental Figure 2 is encouraging, although it appears that the young and old data are presented on slightly different scales (x versus y axis), and that more parcels did not show significant model fits in young children than older adolescents (based on the number of data points below the box &quot;cutoff&quot; line on each axis; the authors should report this number for each group directly, rather than the combined measure across groups). Further, in Figure 4 (side panels), it seems that the optimal timescale for the youngest group in many regions (TPJ, V1, A1) barely beats out the longest timescale, again calling into question the quality of the young child data. Finally, it would be helpful to know which parcels are showing the best model fit, and which show only weak model fits, again in both young and old groups separately.</p><p><italic>Reviewer #3 (Recommendations for the authors):</italic></p><p>I do not have what I would consider to be serious issues with the manuscript. In general, I think this is very good science and will make a solid contribution. I do, however, have some concerns that would make for a stronger publication if addressed:</p><p>(1) The authors obtained independent behavioral boundary ratings from adults, and compared these ratings to the neural responses from the participants. It does not appear that any of the independent raters were in the actual age range of interest (5-19 years). I suggest obtaining independent behavioral boundary ratings from the same age group to determine whether neural responses track with the behavior of the same age group. I will note that this discrepancy is not, in my view, a huge issue for the paper either way. Rather, I think there are interesting and important questions pertaining to this issue, namely whether behavioral measures pertaining to event boundaries differ fundamentally across this age range, and whether this has any bearing on the neural measures obtained in this study. It would be an equally novel and important contribution to demonstrate that this either does or does not have major influences on the patterns of results one might observe. While I am hesitant to request further data collection and/or analyses, in this case, I think it is warranted and would strengthen the kinds of conclusions that can be drawn from these data.</p><p>(2) On page 11, the authors suggest that the decreased response reliability, anticipation, and model fit performance is possibly due to the PMC performing &quot;additional processing in the absence of strong schemas… [and] younger children may therefore more consistently rely on this region to understand a relatively more novel environment.&quot; It is unclear to me why people would anticipate an unfamiliar scene transition. Furthermore, based on the authors' prior work, it is unclear why the PMC, if it is relatively sensitive to higher-order event schemas (Baldassano, Hasson, and Norman, 2018), should show <italic>more</italic> anticipation by younger children. I am afraid I do not understand the logic here, or how to reconcile it with other findings. Can the authors clarify this?</p><p>(3) A general concern when comparing neural signals across different age ranges is the issue of signal quality, which can differ markedly across groups. The authors have seemingly accounted for potential differences in SNR in several formulae in the appendices, but do not mention in the main text whether age-related differences in SNR were examined or accounted for. This may perhaps be deducible from the formulae the authors provide, but regardless, I think a more direct mention of this issue would be helpful.</p></body></sub-article><sub-article article-type="reply" id="sa2"><front-stub><article-id pub-id-type="doi">10.7554/eLife.69430.sa2</article-id><title-group><article-title>Author response</article-title></title-group></front-stub><body><disp-quote content-type="editor-comment"><p>Essential revisions:</p><p>1. It needs to be carefully ruled out that (some of) the results can be explained by lower SNR in the younger age groups. See the reviewers' recommendations for authors for detailed suggestions.</p></disp-quote><p>Upon re-examining the difference in framewise displacement (a measure of noise in fMRI data), we have realized that there was one outlier subject with a median framewise displacement of over three standard deviations above the mean. To ensure that the excessive motion in this subject did not affect any of our results, we have re-run all of the analyses in the paper without this subject.</p><p>As a result of eliminating this subject (from the youngest group), we have found slight changes in our results. Figure 1 reflects that there is no longer a significant increase in ISC with age in the visual cortex, and there is no longer a significant decrease in ISC with age in the anterior portion of PMC (PCC portion):</p><p>We have therefore modified the discussion to reflect this where we write:</p><p>“In the PMC event model fits worsened with age (Figure 5), and in the more posterior RSC portion, reliability also decreased with age (Figure 1).”</p><p>Additionally, we now find small but significant changes in ISCb in the medial prefrontal cortex in Figure 2.</p><p>We now address this in the discussion, where we write:</p><p>“We found small, but significant changes in the timecourse of narrative processing in the medial prefrontal cortex (Figure 2). This region has been previously implicated in tracking schematic knowledge during video-watching (Baldassano et al., 2018; Van Kesteren et al., 2010), suggesting that schematic responses evolve across this age range.”</p><p>Figure 6a reflects that there is no longer a decrease in anticipation with age in the PMC. We now find a decrease in anticipation in the right ventral temporal cortex.</p><p>We interpret the new increase in anticipation with age in the PMC in the discussion where we write:</p><p>“However, we did find both age-related shifts in the pattern by which the narrative was represented bilaterally (Figure 2) and increased anticipation in the left PMC (Figure 6). These findings in the more dorsal portion of PMC are notable because there were no significant age-related differences in this region, suggesting that these shifts are not due to overall changes in attention or executive function. This result is in line with our hypothesis that increasing age is associated with more anticipation of higher level themes, and different ages likely process these themes with a different overall pattern of activity.”</p><p>Even after removing the subject with high motion, a t-test reveals that there is significantly more motion in the Youngest age group than in the Oldest age group (t(125) = 5.12, p = 1x10-6). We performed standard preprocessing measures to try to minimize the impact of motion. We thus regressed out framewise displacement, the global signals from the cerebrospinal fluid and white matter, eight discrete cosine filters with 128s cut-off, and six rotation and translation parameters, as well as their derivatives as nuisance regressors out of the fMRI time courses. We additionally performed a new analysis to determine whether the result that some parcels have lower ISC in the Youngest group could be explained as an artifact of increased motion. We compared the framewise displacement for each individual in the Youngest group and the correlation of their brain response with the rest of the group (in all parcels where ISC increased with age). We found no relationship between framewise displacement and ISC and now report this in the Results:</p><p>“To ensure that the increases in ISC with age are not due to differences in the level of noise between the groups, we measured the relationship between the framewise displacement of each child in the Youngest group and their ISC with the other subjects. There was no relationship between framewise displacement and ISC in any of the parcels where ISC increased with age, indicating that motion did not drive the result in these parcels (all q’s&gt;0.05).”</p><p>We therefore conclude that head motion alone cannot explain the difference we observed between age groups.</p><p>To further compare the ISC values in the Youngest and Oldest groups, we now include an additional supplementary figure (Supplementary Figure 2) which displays ISC across the cortical surface for both age groups. Both show a similar pattern of ISC that increases from sensory to anterior regions.</p><p>To ensure that the between-group ISC measure (Figure 2) is not driven by lower data quality in the younger participants than in the older participants, following the suggestion from Reviewer 2, we have calculated Young-Young ISC minus Young-Old ISC (see <xref ref-type="fig" rid="sa2fig1">Author response image 1</xref>). (a) displays this without thresholding for a significant difference between the two quantities and (b) displays this with thresholding for multiple comparisons (q &lt; 0.05).</p><fig id="sa2fig1" position="float"><label>Author response image 1.</label><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-69430-sa2-fig1-v2.tif"/></fig><p>All significant parcels are positive values, indicating that Young-Young ISC is always greater than Young-Old ISC where it is significant. There is therefore a reliable signal in the young group.We have opted to not include this in the manuscript because ISCb inherently controls for differences in data quality or reliability between the groups by dividing the between-group ISC by the geometric mean of the within-group ISCs. Additionally, the significant regions in panel (b) largely overlap with those found to have significant between group differences in Figure 2.</p><p>To better assess any potential differences in data quality that may be driving our HMM fits, we have revised Figure 5—figure supplement 1 (formerly Supplementary Figure 2) to include modelfit differences displayed across the cortex for both the Youngest and Oldest groups.</p><p>This illustrates a very similar pattern of HMM fits across cortex for both age groups. Additionally, we have revised the scatterplot portion of the figure such that the x-axis scale equals the y-axis scale, and there is now an x=y line for illustrative purposes. In the methods section, we now report the number of datapoints below the threshold for model-fit difference (0.002) in each group:</p><p>“In 40 parcels the Youngest group had a model fit difference less than 0.002 and in 33 parcels the Oldest group had a model fit difference less than 0.002.”</p><disp-quote content-type="editor-comment"><p>2. It is not clear which hypotheses were tested, supported and refuted in the current study. We suggest you either improve the theoretical framework of the study, and clearly describe the hypotheses tested, or reframe the paper as an exploratory or methods paper. The reviewers provide some suggestions for how you might go about this.</p></disp-quote><p>We have now significantly reframed the introduction and discussion portions of the paper in line with improving the theoretical framework of the paper, and in order to better describe the hypotheses tested.</p><p>We have now better defined our hypotheses and defined the terms in the manuscript more clearly. In the introduction, we define “schematic event representations” as those that:</p><p>“are able to generalize across different instances of similar events”</p><p>and we define “episodic encoding processes” as those:</p><p>“responsible for encoding the specific details of events.”</p><p>We also better outline the regions or networks of regions that we hypothesize to be responsible for these processes. We now write:</p><p>“We hypothesized that in default mode network regions responsible for story interpretation and self-referential thought, even where within-age ISC magnitude does not change, the pattern of activity representing the video will change across development, just as the semantic interpretation of videos changes with age (Nelson, 1986; Raichle et al., 2001).”</p><p>and</p><p>“We hypothesized that with age, the strength of schematic event representations, that are able to generalize across different instances of similar events, will increase due to more experience with different exemplars. These kinds of representations should be stored in default mode regions such as the medial prefrontal cortex and posterior medial cortex (PMC).”</p><p>We now also better define the grounds for refuting this hypothesis:</p><p>“If we do not find a general improvement in event model fits with age, this will refute the hypothesis that the schematic event representations that support event models are strengthened with age.”</p><p>To better describe our hypothesis, we now write:</p><p>“In line with the idea that schematic event representations improve with age, older adolescents should be able to anticipate events further into the future due to their increased experience with the world.”</p><p>And finally, we clarify what it would mean to refute the hypothesis that the magnitude of the hippocampal response to event boundaries would increase with age, in line with a model of maturation wherein the ability to encode the unique episodes of daily experience increase into middle age and then decreases with senescence,” when we write:</p><p>“However, should we find a decrease in the hippocampal response to event boundaries with age, this would provide support for the idea that younger children may focus on the episodic encoding processes responsible for encoding the specific details of events as they work towards creating more stable schematic event representations (Keresztes, et al., 2018; Maril et al., 2010).”</p><p>In the discussion, we have clarified where we did not find support for our specific brain-related hypotheses. We now write:</p><p>“This finding contrasts with our hypothesis that schematic event representations should increase with age in regions such as the PMC.”</p><p>We also have an entire paragraph dedicated to our mixed findings in the medial prefrontal cortex:</p><p>“We found small, but significant changes in the timecourse of narrative processing in the medial prefrontal cortex (Figure 2). This region has been previously implicated in tracking schematic knowledge during video-watching (Baldassano et al., 2018; Van Kesteren et al., 2010), suggesting that schematic responses evolve across this age range. However, we surprisingly did not find a change in the strength of event representations with age. This may be due to an overall low level of ISC in this region, either due to idiosyncratic cognition, inconsistent neuroanatomy across subjects, or noisy signals in this region (Supplementary Figure 1), making it challenging to study this region using the group-level approaches in this study. This result is not entirely unexpected given that previous studies have found low levels of ISC in this region (Baldassano et al., 2017), especially in developmental populations (Lerner et al., 2019; Moraczewski et al., 2018). Furthermore, as has been found previously, it may be that only a subregion of the medial prefrontal cortex represents events (Baldassano et al., 2017; Brod et al., 2017; Masís-Obando, Norman, and Baldassano, 2022; Van Kesteren et al., 2010).”</p><p>Finally, we clarify what hypothesis the hippocampal (HPC) results support:</p><p>“The HPC may thus have a more robust signal in young children who need to focus on encoding the specific details of events as they use them to extract commonalities across experiences (Keresztes, et al., 2018; Maril et al., 2010). Likewise, the HPC has been shown to have increased activity during memory consolidation, and in response to novel events (Nadel, and Moscovitch, 1997; Stern et al., 1996). It is possible that younger children found the events in the video generally more novel, or needed to spend more effort consolidating them due to their impoverished schematic representations. However, if this was truly a novelty-related response we would have expected to see a greater age-related change in the pHPC which has been shown to be more responsive to novelty (Stern et al., 1996).”</p><disp-quote content-type="editor-comment"><p>3. It would greatly strengthen confidence in the current findings, which seem quite exploratory rather than hypothesis-driven, if they could be replicated in an independent data set. There are multiple public datasets of children watching videos, could any of these be leveraged to replicate the current findings?</p></disp-quote><p>We agree that a replication would increase the confidence in the current findings. However, we do not know of a publicly available dataset that meets the criteria necessary for running the analyses in the paper. This dataset is unique in several ways, having both (a) a large number of subjects of each age, and (b) a narrative video stimulus that is long enough to study regions with event timescales that can extend multiple minutes. Fitting a Hidden Markov Model with the minimum number of events (2), requires a video of at least ~six minutes (and preferably ten minutes or more) to access timescales extending up to ~three minutes. We address these limitations in the discussion where we write:</p><p>“…our analyses require stimuli that exhibit multiple transitions between events that are at least 30 seconds. We were therefore unable to make use of the other video available in this dataset or data from the short video clips used in other developmental datasets (Alexander et al., 2017; Richardson et al., 2018).”</p><disp-quote content-type="editor-comment"><p>4. The boundary ratings are obtained from adults, and may therefore not accurately reflect those of younger participants. It would strengthen the paper if boundary ratings could be obtained across the age range studied here.</p></disp-quote><p>Obtaining boundary ratings from a developmental population is challenging, since there is currently no standardized protocol for how to conduct this type of experiment. In this revision, we devised an online study to collect boundary ratings from other children whose ages are between 5 and 18 years.</p><p>We briefly describe the findings in the Abstract:</p><p>“Over the course of development, brain responses became more discretized into stable and coherent events and shifted earlier in time to anticipate upcoming perceived event transitions, measured behaviorally in an age-matched sample.”</p><p>And introduce our approach in the Introduction:</p><p>“How can we characterize the changes that are occurring in response timecourses? Although some knowledge of the hierarchical structure of the events that compose a narrative develops in infancy, the ability to reliably notice these events does not mature until at least the teenage years (Zacks and Tversky, 2001; Zheng, Zacks, and Markson, L., 2020). It is likely that the characterization of events changes with age. We therefore asked both children and adults to subjectively report where they believed meaningful scene changes occurred in the narrative. We hypothesized that although there would be no change in the behaviorally reported location of these coarse-grained narrative segments, the neural representation of events along the cortical hierarchy would change with age.”</p><p>We describe the procedure in the Methods section in the Stimulus and event rating section:</p><p>“The perceived timing of event boundaries according to participants within the age range that fMRI was recorded (5-19 years) was assessed online via the Gorilla platform (www.gorilla.sc; Anwyl-Irvine et al., 2020). The online experiment involved a brief training to ensure comprehension of the task. Participants first watched a different clip from Despicable Me (03:25 to 04:47 in the full video). Participants were notified after the first event boundary (04:10 in the full video) and asked to identify the next event boundary (04:37 in the full video). Participants were given three attempts to correctly identify the second boundary. If a participant successfully identified the second boundary, they watched the same clip that was used during fMRI scanning and identified boundaries in that clip at their discretion. The children's data were first analyzed in aggregate, and then analyzed after splitting based on the median age (12.25 years).</p><p>The online task was also administered to 25 adults (9 male, 19-56 years) recruited via Prolific (www.prolific.co). The data from two adults were not analyzed as their ages overlapped with the age range of the fMRI participants (they were under 19 years). Data from 66 participants (39 male, 7-18 years) within the age range of the fMRI participants were recruited via word of mouth and Facebook. The data from eight subjects were eliminated as their median event duration was less than one second. All online experimental procedures were approved by the Columbia University IRB (protocol number AAAS0252, for adults, and AAAT8550, for children), and the data is available online: https://github.com/samsydco/HBN.”</p><p>And in a new Methods section regarding the analysis of this new behavioral data:</p><p>“Analysis of event segmentation behavior</p><p>Event segmentation behavioral data from each individual was first convolved with a canonical hemodynamic response function (HRF, one parameter γ model from AFNI's 3dDeconvolve) at each timepoint (Lee et al., 2021). This data was compared between children, adults, and the younger and older children as determined by a median split based on age. Data was compared within and between groups by splitting each group in half, and averaging the data across raters within a split, thus computing shISCs where appropriate. This procedure was done on five random splits of the data. The ISCb measure was used to compare response timecourses between the groups. These values were computed across five random splits of the data and results were averaged across the splits. All significance values were computed on 10,000 random permutations of the data.”</p><p>We have added the new data to the Results section, with an accompanying new figure (Figure 3):</p><p>“This result demonstrates that responses are changing substantially with age in many brain regions, but does not indicate how these responses are changing. One possibility is that the interpretation of the events and scenes in the narrative changes with age. We therefore assessed when adults and children, age-matched to the fMRI sample, report that an event in the narrative has finished, and a new event has begun. There are small but significant differences in the timing of the event boundaries marked by adults and children (ISCb = 0.97, p = 0.009). This discrepancy was true for both the younger and older children, separated by a median split based on age (adult-older children ISCb = 0.95, adult-younger children ISCb = 0.91, both p’s &lt; 1x10-5). The timing of event boundaries was also slightly, but significantly different between the younger half and older half of the children (ISCb = 0.96, p = 0.01, Figure 3). Given this overall similarity in</p><p>behavior, we next ask whether there are differences in how these events are represented and tracked in the brain.”</p><p>And we briefly discuss the results in the discussion:</p><p>“… behaviorally, we found small, but significant differences in segmentation behavior between adults and children, and children of different ages.”</p><p>All analyses that compare brain data with behavior have been updated to compare the brain data with the age-matched behavioral data. We have thus updated Figure 6 and Figure 5—figure supplement 3, and our results and conclusions do not change. We have additionally updated relevant portions of the Methods to reflect that the behavioral data is from an “age-matched” sample.</p><disp-quote content-type="editor-comment"><p>5. How can we be sure developmental changes in the timing of event transitions reflect increasing &quot;anticipation&quot; in the older group, rather than lagging processes in the younger group? And are anticipatory shifts as long as 20s cognitively plausible?</p></disp-quote><p>To better assess whether we are measuring anticipation in the older group or lagging processes in the younger group we have added an additional analysis to the paper. In this analysis we compare the timing of the event transitions in each age group to the behaviorally-derived event boundaries to determine the parcels in which the brain’s activity leads the recognition of behavioral events, and the parcels in which the brain’s activity lags behind the behavioral events. We conducted this analysis separately in the Oldest and Youngest groups and now report on only the parcels with significant event timing differences. We have added these analyses to the Results and Methods sections, as well as displaying them in Figure 6b.</p><p>In the Results section, we write:</p><p>“To determine whether developmental changes in the timing of event transitions reflect an increased level of anticipation in the Oldest group, or, alternatively, a delayed response in the Youngest group, we compared the HMM-derived event boundaries to event transitions behaviorally identified by an age-matched group of children. Across the cortex we find that the Oldest ages generally anticipate event shifts, while the Youngest ages lag behind them to some degree (Figure 6b).”</p><p>And in the Methods section, we write:</p><p>“In all parcels that had a significant change in event timing between age groups, we compared the timing of the event boundaries identified by the HMM to the event boundary timecourse obtained behaviorally from raters. Following methods used previously, the number of boundary annotations from the child raters at each timepoint during the video were convolved with a canonical HRF (Lee et al., 2021). To obtain a measure of when the brain is switching between events, we took the derivative of the expected value of the event that the HMM assigned to each timepoint (following methods from Lee et al., 2021). To determine the timing of the alignment between these two signals, we cross-correlated the HMM-derived boundary timecourse with the behavioral event boundary timecourse from children, in aggregate. To precisely estimate the optimal lag, we fit a quadratic function to the maximum correlation lag and its two neighboring lags, and found the location of the peak of this quadratic fit. We computed the maximum-correlation lag separately in the Oldest and Youngest groups to determine whether there is a significant difference in the relationship between the brain’s event boundaries and the behavioral event boundaries.”</p><p>This additional analysis thus confirms our interpretation that the Oldest group is in fact anticipating the event transitions in the video ahead of those in the Youngest group. We believe that anticipatory effects as large as 20 seconds are plausible in a 10 minute story in which individual events can last as long as 130 seconds (see Figure 5—figure supplement 2). Previous work has found anticipation up to 15 seconds in a much shorter (90 second) stimulus (Baldassano et al., 2021).</p><disp-quote content-type="editor-comment"><p>6. Given the relatively uncontrolled nature of the stimuli, it is challenging to know exactly what video content drove responses for any given region. In addition to neural variance, differential eye and head movements induced by move content may also explain variance in the data. This should be acknowledged and discussed.</p></disp-quote><p>We agree that there are many factors that may drive the responses to an uncontrolled stimulus such as the one used here. As discussed in our response to Essential Revisions comment #1, we did not find that head motion in the Youngest group had a major impact on ISC values. Eye movements were unfortunately not recorded as part of this dataset, making it unclear the extent to which changes in viewing patterns are driving the observed results in the visual cortex. We have now added this clarification in the Discussion:</p><p>“Unfortunately, as eye movements were not recorded, we cannot establish the relationship between eye movements and synchrony in sensory cortex (Alexander et al., 2017).”</p><disp-quote content-type="editor-comment"><p>7. There is a relatively loose use of anatomy in places, e.g. regarding the TPJ. This should be either improved or acknowledged.</p></disp-quote><p>We now define the TPJ more specifically, based on the functional theory of mind ROI from Dufour et al., (2013). We label parcels belonging to TPJ as only those parcels for which two thirds of their area falls within this functional ROI, as described in the Methods section of the paper.</p><p>“Defining temporoparietal junction</p><p>To better understand how our findings relate to the previous literature we defined the portion of the temporoparietal junction (TPJ) responsible for theory of mind processes based on its definition in Dufour et al., (2013). We projected the definition of the TPJ from this paper, originally in voxel space, onto the cortical surface, and parcels in which over two-thirds of their vertices were within the boundary of the TPJ were labeled as members of this region.”</p><p>We have therefore reduced our definition of regions within the TPJ to only three parcels (one in the left hemisphere, and two, relatively smaller parcels in the right hemisphere), illustrated in Figure 2. We have changed the label for the region in Figure 4 to “left parietal operculum”, and we have changed the label for the region in Figure 6 to “left postcentral sulcus.” When we refer to these regions in the discussion, we make it clear which regions overlap with the TPJ, and which do not:</p><p>“In the right posterior-superior temporal sulcus (part of TPJ as defined by Dufour and colleagues, 2013) and in the TPJ-adjacent left postcentral sulcus, we found that neural representations in 16-19 year-olds can be as far as 20 seconds ahead of those for 5-8 year-olds on the first viewing of a video clip.”</p><disp-quote content-type="editor-comment"><p>We encourage you to refer to the individual reviews for detailed recommendations on how to address these points.</p><p>Reviewer #1 (Recommendations for the authors):</p><p>– Could increased similarity in participants' eye movements (i.e. the way they overtly sample the videos) with age explain some of the effects reported here?</p></disp-quote><p>Yes, an age-related change in the similarity of participants’ eye movements could definitely explain some of the effects that we observe. We highlight this possibility in the discussion where we write:</p><p>“Older ages exhibit more across-subject synchrony in visual and auditory cortices… These results are likely related to more strongly correlated semantic processing in adolescents, resulting in top-down increases in synchronous eye movements and auditory understanding.”</p><p>Unfortunately, the dataset that we analyzed for this project did not track eye movements during video viewing. We have now added this limitation in the Discussion:</p><p>“Unfortunately, as eye movements were not recorded, we cannot establish the relationship between eye movements and synchrony in sensory cortex (Alexander et al., 2017).”</p><p>It would have been interesting to see if age-related changes in eye movement synchrony help to explain any of our cortical results.</p><disp-quote content-type="editor-comment"><p>– Could there be a difference in head motion between age groups? Importantly, head motion might affect some regions (e.g. lateral ones) more than others (medial ones).</p></disp-quote><p>Yes! Thank you for bringing this important caveat to our attention. We have now analyzed the difference in framewise displacement between the Youngest and Oldest ages. We report this difference, as well as how we address potential differences in the effect of head motion on lateral regions in which ISC increases with age in our response to Essential Revisions comment #1.</p><disp-quote content-type="editor-comment"><p>– Do the authors think that any of their effects are due to general development of the cortex rather than narrative comprehension? That is, might some of their effects also be found when participants watch scrambled videos without structure or meaning?</p></disp-quote><p>This dataset does not provide a way to separate the effects of the maturation of the brain from the increased experience with the world that underlies schematic knowledge. We now highlight this in the discussion, where we write:</p><p>“Furthermore, we cannot distinguish whether the improvements that we see with age are due to the overall maturation of the brain or the increased life experience that underlies schematic knowledge.”</p><p>It is unclear how we would interpret data from a scrambled-video paradigm in children, since there would likely be large attentional differences across ages and it would be unlikely to see ISC in any region outside of sensory cortex (see: Hasson, et al., 2008, A hierarchy of temporal receptive windows in human cortex for evidence in adults). Videos without structure and meaning, such as Inscapes (Vanderwal et al., 2015), have been previously used to measure differences in functional connectivity, but are unlikely to evoke the kinds of stable event patterns necessary for applying our Hidden Markov Model analyses.</p><disp-quote content-type="editor-comment"><p>– Figure 6, right panels: can you make the different age groups more easily distinguishable?</p></disp-quote><p>We have increased the thickness of the lines in Figure 6 (now Figure 7 in paper), right panels, and hope that this solves the problem.</p><disp-quote content-type="editor-comment"><p>– Seimen's -&gt; Siemens</p></disp-quote><p>Thank you for alerting us to this typo. We have corrected this in the manuscript.</p><disp-quote content-type="editor-comment"><p>Reviewer #2 (Recommendations for the authors):</p><p>Major 1. The authors should significantly reframe the paper. There are many ways this could be done. One possibility is to hone attention toward a specific network most closely associated with &quot;narrative&quot; processing based on similar adult work, or which shows the strongest correlations to behaviorally-determined event boundaries. In this case, the authors should take care to provide clear definitions of the various terms in the manuscript, and clear hypotheses and alternative hypotheses. A second possibility is that the paper could be reframed in terms of the methodological approach (i.e., using HMM to explore event structure in naturalistic video data, which may have particular promise in pediatric datasets).</p></disp-quote><p>We have taken the reviewer’s first suggestion to better define our hypotheses and define the terms in the manuscript more clearly. We outline these specific changes in our response to Essential Revisions comment #2.</p><disp-quote content-type="editor-comment"><p>Major 2. Specific suggestions for addressing the concern that key effects are driving by lower data quality in younger children:</p><p>The authors should show within-group ISC across the cortex for young and old groups separately, not just the direct comparison of the two groups. Beyond confirming that the data in young children look reasonable, this analysis would reveal which regions actually show reliable within-group ISC (especially in the young group alone), and which do not. For example, it is possible that only occipital parcels show strong within-group ISC (as suggested by Supplemental Figure 1); if so, then it is not surprising to find no difference in within-group ISC between older and younger groups in regions beyond the occipital cortex, since reliable video responses could not really be detected there.</p><p>For the new between-group ISC measure (Figure 2), despite normalizing by within group ISC, this result could still be driven by lower data quality in younger kids than older kids. The strongest test of a qualitative developmental change in video responses would be to ask whether &quot;young-young group&quot; ISC is greater than &quot;young-old group&quot; ISC. If young children predict other young children better than older adolescents, then there is a reliable signal in the young group that cannot be explained by lower data quality in the younger sample than the older one. The alternative is that any comparison between a good dataset and a bad dataset will yield lower between group ISC than expected based on within-group ISC (i.e., driven by the older group only, by virtue of the higher data quality in that group).</p><p>The authors should also show HMM fits across the cortex, particularly in the young group alone. The comparison of model-fit-difference between young and old subjects in Supplemental Figure 2 is encouraging, although it appears that the young and old data are presented on slightly different scales (x versus y axis), and that more parcels did not show significant model fits in young children than older adolescents (based on the number of data points below the box &quot;cutoff&quot; line on each axis; the authors should report this number for each group directly, rather than the combined measure across groups). Further, in Figure 4 (side panels), it seems that the optimal timescale for the youngest group in many regions (TPJ, V1, A1) barely beats out the longest timescale, again calling into question the quality of the young child data. Finally, it would be helpful to know which parcels are showing the best model fit, and which show only weak model fits, again in both young and old groups separately.</p></disp-quote><p>We address these points with several additional figures and analyses in our response to Essential Revisions comment #1.</p><disp-quote content-type="editor-comment"><p>Reviewer #3 (Recommendations for the authors):</p><p>Per my public review, I do not have what I would consider to be serious issues with the manuscript. In general, I think this is very good science and will make a solid contribution. I do, however, have some concerns that would make for a stronger publication if addressed:</p><p>(1) The authors obtained independent behavioral boundary ratings from adults, and compared these ratings to the neural responses from the participants. It does not appear that any of the independent raters were in the actual age range of interest (5-19 years). I suggest obtaining independent behavioral boundary ratings from the same age group to determine whether neural responses track with the behavior of the same age group. I will note that this discrepancy is not, in my view, a huge issue for the paper either way. Rather, I think there are interesting and important questions pertaining to this issue, namely whether behavioral measures pertaining to event boundaries differ fundamentally across this age range, and whether this has any bearing on the neural measures obtained in this study. It would be an equally novel and important contribution to demonstrate that this either does or does not have major influences on the patterns of results one might observe. While I am hesitant to request further data collection and/or analyses, in this case, I think it is warranted and would strengthen the kinds of conclusions that can be drawn from these data.</p></disp-quote><p>We have now collected additional boundary ratings from children and we discuss these new results in our response to Essential Revisions comment #4.</p><disp-quote content-type="editor-comment"><p>(2) On page 11, the authors suggest that the decreased response reliability, anticipation, and model fit performance is possibly due to the PMC performing &quot;additional processing in the absence of strong schemas… [and] younger children may therefore more consistently rely on this region to understand a relatively more novel environment.&quot; It is unclear to me why people would anticipate an unfamiliar scene transition. Furthermore, based on the authors' prior work, it is unclear why the PMC, if it is relatively sensitive to higher-order event schemas (Baldassano, Hasson, and Norman, 2018), should show more anticipation by younger children. I am afraid I do not understand the logic here, or how to reconcile it with other findings. Can the authors clarify this?</p></disp-quote><p>After eliminating one subject whose motion was three standard deviations above the rest of the subjects, the PMC no longer significantly decreases in anticipation. The RSC still decreases in reliability with age (Figure 1), and the PMC does decrease in model fit with age (Figure 5). An updated version of Figure 5 is now Figure 6. It seems that now, if anything, the left PMC actually increases in anticipation with age, as we would expect.</p><p>We interpret this result in the discussion, where we write:</p><p>“However, we did find both age-related shifts in the pattern by which the narrative was represented bilaterally (Figure 2) and increased anticipation in the left PMC (Figure 6). These findings in the more dorsal portion of PMC are notable because there were no significant age-related differences in this region, suggesting that these shifts are not due to overall changes in attention or executive function. This result is in line with our hypothesis that increasing age is associated with more anticipation of higher level themes, and different ages likely process these themes with a different overall pattern of activity.”</p><p>We have also added additional interpretation to the finding that event model-fits in PMC decrease with age in the discussion:</p><p>PMC has an intrinsically long timescale for information processing, one that emerges in infancy, which may thus support strong event models in children as young as five (Hasson et al., 2015; Stephens, Honey, and Hasson, 2013; Yates et al., 2021).</p><disp-quote content-type="editor-comment"><p>(3) A general concern when comparing neural signals across different age ranges is the issue of signal quality, which can differ markedly across groups. The authors have seemingly accounted for potential differences in SNR in several formulae in the appendices, but do not mention in the main text whether age-related differences in SNR were examined or accounted for. This may perhaps be deducible from the formulae the authors provide, but regardless, I think a more direct mention of this issue would be helpful.</p></disp-quote><p>We address potential differences in SNR between the groups in our response to Essential Revisions comment #1.</p></body></sub-article></article>