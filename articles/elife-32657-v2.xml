<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD v1.1 20151215//EN"  "JATS-archivearticle1.dtd"><article article-type="research-article" dtd-version="1.1" xmlns:ali="http://www.niso.org/schemas/ali/1.0/" xmlns:xlink="http://www.w3.org/1999/xlink"><front><journal-meta><journal-id journal-id-type="nlm-ta">elife</journal-id><journal-id journal-id-type="publisher-id">eLife</journal-id><journal-title-group><journal-title>eLife</journal-title></journal-title-group><issn pub-type="epub" publication-format="electronic">2050-084X</issn><publisher><publisher-name>eLife Sciences Publications, Ltd</publisher-name></publisher></journal-meta><article-meta><article-id pub-id-type="publisher-id">32657</article-id><article-id pub-id-type="doi">10.7554/eLife.32657</article-id><article-categories><subj-group subj-group-type="display-channel"><subject>Research Advance</subject></subj-group><subj-group subj-group-type="heading"><subject>Neuroscience</subject></subj-group></article-categories><title-group><article-title>Interactions between stimulus and response types are more strongly represented in the entorhinal cortex than in its upstream regions in rats</article-title></title-group><contrib-group><contrib contrib-type="author" equal-contrib="yes" id="author-98984"><name><surname>Park</surname><given-names>Eun-Hye</given-names></name><email>p40192367@gmail.com</email><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="fn" rid="equal-contrib1">†</xref><xref ref-type="fn" rid="con1"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" equal-contrib="yes" id="author-98985"><name><surname>Ahn</surname><given-names>Jae-Rong</given-names></name><email>grungespirit1@gmail.com</email><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="fn" rid="equal-contrib1">†</xref><xref ref-type="fn" rid="con2"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" corresp="yes" id="author-68569"><name><surname>Lee</surname><given-names>Inah</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">http://orcid.org/0000-0003-3760-4257</contrib-id><email>inahlee@snu.ac.kr</email><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="other" rid="fund1"/><xref ref-type="other" rid="fund2"/><xref ref-type="other" rid="fund3"/><xref ref-type="other" rid="fund4"/><xref ref-type="fn" rid="con3"/><xref ref-type="fn" rid="conf1"/></contrib><aff id="aff1"><label>1</label><institution content-type="dept">Department of Brain and Cognitive Sciences</institution><institution>Seoul National University</institution><addr-line><named-content content-type="city">Shillim-dong</named-content></addr-line><country>Korea</country></aff></contrib-group><contrib-group content-type="section"><contrib contrib-type="editor" id="author-11737"><name><surname>Schoenbaum</surname><given-names>Geoffrey</given-names></name><role>Reviewing Editor</role><aff><institution>NIDA</institution><country>United States</country></aff></contrib></contrib-group><author-notes><fn fn-type="con" id="equal-contrib1"><label>†</label><p>These authors contributed equally to this work</p></fn></author-notes><pub-date date-type="publication" publication-format="electronic"><day>27</day><month>12</month><year>2017</year></pub-date><pub-date pub-type="collection"><year>2017</year></pub-date><volume>6</volume><elocation-id>e32657</elocation-id><history><date date-type="received" iso-8601-date="2017-10-10"><day>10</day><month>10</month><year>2017</year></date><date date-type="accepted" iso-8601-date="2017-12-22"><day>22</day><month>12</month><year>2017</year></date></history><permissions><copyright-statement>© 2017, Park et al</copyright-statement><copyright-year>2017</copyright-year><copyright-holder>Park et al</copyright-holder><ali:free_to_read/><license xlink:href="http://creativecommons.org/licenses/by/4.0/"><ali:license_ref>http://creativecommons.org/licenses/by/4.0/</ali:license_ref><license-p>This article is distributed under the terms of the <ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/licenses/by/4.0/">Creative Commons Attribution License</ext-link>, which permits unrestricted use and redistribution provided that the original author and source are credited.</license-p></license></permissions><self-uri content-type="pdf" xlink:href="elife-32657-v2.pdf"/><related-article ext-link-type="doi" id="ra1" related-article-type="article-reference" xlink:href="10.7554/eLife.21543"/><abstract><object-id pub-id-type="doi">10.7554/eLife.32657.001</object-id><p>Previously we reported results which suggested that response types are critical in dissociating the lateral entorhinal cortex (LEC) from the medial entorhinal cortex (MEC) in a scene memory task (<xref ref-type="bibr" rid="bib26">Yoo and Lee, 2017</xref>). Here, we investigated whether the perirhinal cortex (PER) and postrhinal cortex (POR), the upstream regions of the LEC and MEC, respectively, could be dissociated similarly. We conducted four tasks by combining different stimulus and response types. Our results suggest that the PER is important whenever object recognition is required and, together with prior findings, imply that PER-LEC networks are essential in goal-directed interactions with objects. The POR appears critical for recognizing visual scenes and may play key roles in scene-based navigation together with the MEC. The relative lack of functional dissociation between stimulus and response types at the PER-POR level suggests that actions conditioned on the recognition of external stimuli may be uniquely represented from the EC.</p></abstract><kwd-group kwd-group-type="author-keywords"><kwd>episodic memory</kwd><kwd>recognition memory</kwd><kwd>object memory</kwd><kwd>scene memory</kwd><kwd>context</kwd></kwd-group><kwd-group kwd-group-type="research-organism"><title>Research organism</title><kwd>Rat</kwd></kwd-group><funding-group><award-group id="fund1"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/501100003725</institution-id><institution>National Research Foundation of Korea</institution></institution-wrap></funding-source><award-id>2015M3C7A1031969</award-id><principal-award-recipient><name><surname>Lee</surname><given-names>Inah</given-names></name></principal-award-recipient></award-group><award-group id="fund2"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/501100003725</institution-id><institution>National Research Foundation of Korea</institution></institution-wrap></funding-source><award-id>2016R1A2B4008692</award-id><principal-award-recipient><name><surname>Lee</surname><given-names>Inah</given-names></name></principal-award-recipient></award-group><award-group id="fund3"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/501100003725</institution-id><institution>National Research Foundation of Korea</institution></institution-wrap></funding-source><award-id>2017M3C7A1029661</award-id><principal-award-recipient><name><surname>Lee</surname><given-names>Inah</given-names></name></principal-award-recipient></award-group><award-group id="fund4"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/501100003725</institution-id><institution>National Research Foundation of Korea</institution></institution-wrap></funding-source><award-id>5286-2014100 (BK21+ program)</award-id><principal-award-recipient><name><surname>Lee</surname><given-names>Inah</given-names></name></principal-award-recipient></award-group><funding-statement>The funders had no role in study design, data collection and interpretation, or the decision to submit the work for publication.</funding-statement></funding-group><custom-meta-group><custom-meta specific-use="meta-only"><meta-name>Author impact statement</meta-name><meta-value>Goal-directed interaction with objects and spatial navigation are subserved by the perirhinal-lateral entorhinal networks and the postrhinal-medial entorhinal networks, respectively, with action-based functional differentiation more strongly represented in the entorhinal cortex than its upstream.</meta-value></custom-meta></custom-meta-group></article-meta></front><body><sec id="s1" sec-type="intro"><title>Introduction</title><p>A prevailing theory posits that spatial information travels from the postrhinal cortex (POR) to the medial entorhinal cortex (MEC), and nonspatial information is transmitted from the perirhinal cortex (PER) to the lateral entorhinal cortex (LEC), before both types of information merge in the hippocampus (<xref ref-type="bibr" rid="bib16">Knierim et al., 2014</xref>). An important caveat of this theory is that it does not explain explicitly how visual scene information is processed in these circuits, although it becomes increasingly clear that visual scenes may provide critical contextual information to the hippocampus (<xref ref-type="bibr" rid="bib7">Dombeck et al., 2010</xref>; <xref ref-type="bibr" rid="bib12">Hassabis and Maguire, 2009</xref>; <xref ref-type="bibr" rid="bib15">Kim et al., 2012</xref>; <xref ref-type="bibr" rid="bib17">Maguire and Mullally, 2013</xref>; <xref ref-type="bibr" rid="bib21">Prusky et al., 2004</xref>; <xref ref-type="bibr" rid="bib25">Wirth et al., 2003</xref>; <xref ref-type="bibr" rid="bib27">Zeidman et al., 2015</xref>).</p><p>Recently, we reported that the LEC and MEC can be functionally dissociated in scene-memory tasks (<xref ref-type="bibr" rid="bib26">Yoo and Lee, 2017</xref>). Interestingly, we found that sensory cues interact with task-specific response types. Specifically, we found that the LEC, but not the MEC, is critical when rats were required to manipulate a common object in different ways (by pushing it or digging sand) using visual scenes in the background, whereas the MEC, but not the LEC, was important when rats made spatial choices in the T-maze using the same visual scenes.</p><p>Building on our prior findings, we here sought to address a critical question, namely, whether such dissociation uniquely occurs at the level of the EC or is inherited from its upstream structures. We tested this by pharmacologically manipulating the PER and POR, the direct upstream regions of the LEC and MEC, respectively, and testing rats in the same scene-based testing paradigms applied in the Yoo and Lee study. Furthermore, as a comparison to the null results reported in the LEC and MEC in object-based behavioral tasks in our previous study, we investigated whether the PER and POR play a role in such tasks (<xref ref-type="bibr" rid="bib26">Yoo and Lee, 2017</xref>).</p></sec><sec id="s2" sec-type="results"><title>Results</title><p>The following four different behavioral tasks, named based on stimulus and response types, were used in the current study: (i) scene-cued nonspatial response (SCN-NSR) task, (ii) scene-cued spatial response (SCN-SR) task, (iii) object-cued nonspatial response (OBJ-NSR) task, and (iv) object-cued spatial response (OBJ-SR) task. Rats (n = 23) trained to associate different types of stimuli (visual scenes and objects) with responses (spatial and nonspatial responses) were implanted bilaterally with cannulae in both the PER and POR (<xref ref-type="fig" rid="fig1">Figure 1A</xref>). Individual tip locations of cannulae were histologically verified (<xref ref-type="fig" rid="fig1">Figure 1B</xref>), and data from rats whose cannula-tip locations were misplaced from either area were discarded (n = 2).</p><fig id="fig1" position="float"><object-id pub-id-type="doi">10.7554/eLife.32657.002</object-id><label>Figure 1.</label><caption><title>Cannula implantation in the PER and POR.</title><p>(<bold>A</bold>) Cannula tracks in thionin-stained sections in the PER and POR. (<bold>B</bold>) Cannula-tip positions are indicated by dots (color-coded for rats) for the nonspatial response tasks (top), SCN-SR task (middle), and OBJ-SR task (bottom).</p></caption><graphic mime-subtype="postscript" mimetype="application" xlink:href="elife-32657-fig1-v2"/></fig><sec id="s2-1"><title>Similar contributions of the PER and POR to visual scene-based nonspatial responses</title><p>Rats (n = 7) were trained in the SCN-NSR task as described previously (<xref ref-type="bibr" rid="bib26">Yoo and Lee, 2017</xref>) (<xref ref-type="fig" rid="fig2">Figure 2A</xref>). Injection of muscimol (MUS) into either the PER or POR (0.5 μL per site) resulted in significant performance deficits compared with injection of the same volume of artificial cerebrospinal fluid (ACSF) (<xref ref-type="fig" rid="fig2">Figure 2B</xref>; <xref ref-type="supplementary-material" rid="fig2sdata1">Figure 2—source data 1</xref>). A one-way repeated-measures ANOVA showed a significant effect of drug (F<sub>(2,12)</sub> = 11.363, p=0.001). A Bonferroni-Dunn post hoc test (corrected α = 0.017) revealed significant differences in performance between ACSF and PER-MUS groups (p&lt;0.01) and between ACSF and POR-MUS groups (p&lt;0.001), but not between PER-MUS and POR-MUS groups (p&gt;0.1) (<xref ref-type="fig" rid="fig2">Figure 2B</xref>). These results suggest that, unlike in the LEC and MEC (<xref ref-type="bibr" rid="bib26">Yoo and Lee, 2017</xref>), both the PER and POR may play some role in nonspatial behavioral choices made using visual background scenes.</p><fig id="fig2" position="float"><object-id pub-id-type="doi">10.7554/eLife.32657.003</object-id><label>Figure 2.</label><caption><title>Scene-memory tasks.</title><p>(<bold>A</bold>) Scene-cued nonspatial response task. Rats made a nonspatial response (push or dig) depending on the visual scene displayed on monitors. (<bold>B</bold>) Behavioral performance in the SCN-NSR task (Mean ± SEM). Both the PER- and POR-MUS conditions produced significant differences in performance compared to controls. (<bold>C</bold>) Scene-cued spatial response task. Rats made a spatial choice (left or right turn) depending on visual scenes. (<bold>D</bold>) Behavioral performance in the SCN-SR task (Mean ± SEM). Both the PER-MUS and POR-MUS conditions resulted in significantly impaired performance compared to control conditions. **p&lt;0.01.</p><p><supplementary-material id="fig2sdata1"><object-id pub-id-type="doi">10.7554/eLife.32657.004</object-id><label>Figure 2—source data 1.</label><caption><title>Performance in the SCN-NSR task.</title><p>Percent correct performance for individual rats under different drug conditions in the SCN-NSR task.</p></caption><media mime-subtype="xlsx" mimetype="application" xlink:href="elife-32657-fig2-data1-v2.xlsx"/></supplementary-material></p><p><supplementary-material id="fig2sdata2"><object-id pub-id-type="doi">10.7554/eLife.32657.005</object-id><label>Figure 2—source data 2.</label><caption><title>Performance in the SCN-SR task.</title><p>Percent correct performance for individual rats under different drug conditions in the SCN-SR task.</p></caption><media mime-subtype="xlsx" mimetype="application" xlink:href="elife-32657-fig2-data2-v2.xlsx"/></supplementary-material></p></caption><graphic mime-subtype="postscript" mimetype="application" xlink:href="elife-32657-fig2-v2"/></fig></sec><sec id="s2-2"><title>Both the PER and POR are involved in making visual scene-based spatial responses</title><p>To examine whether the type of response interacts with the scene stimulus, as has been observed between the LEC and MEC (<xref ref-type="bibr" rid="bib26">Yoo and Lee, 2017</xref>), we tested a separate group of rats (n = 8) in the SCN-SR task (<xref ref-type="fig" rid="fig2">Figure 2C</xref>). We found that inactivating either the PER or POR yielded similar performance deficits compared with controls (<xref ref-type="fig" rid="fig2">Figure 2D</xref>; <xref ref-type="supplementary-material" rid="fig2sdata2">Figure 2—source data 2</xref>). A one-way repeated-measures ANOVA showed a significant effect of drug (F<sub>(2,14)</sub> = 12.745, p&lt;0.001). Performance decreased significantly in both the PER-MUS (p&lt;0.01) and POR-MUS (p&lt;0.001) group, compared with the ACSF group. Performance was similar between PER-MUS and POR-MUS groups (p=0.133; Bonferroni-Dunn) (<xref ref-type="fig" rid="fig2">Figure 2D</xref>). These results indicate that both regions contribute to scene-based spatial choice behavior. Importantly, unlike the case for the LEC and MEC (<xref ref-type="bibr" rid="bib26">Yoo and Lee, 2017</xref>), a functional interaction between scene and response type was not observed in the PER or POR.</p></sec><sec id="s2-3"><title>Greater contribution of the PER than the POR to object-based memory tasks</title><p>In our previous study (<xref ref-type="bibr" rid="bib26">Yoo and Lee, 2017</xref>), we reported that the LEC and MEC were not involved in the OBJ-NSR task. To test the involvement of the PER and POR in the same task, we trained the same rats (n = 7) used in the SCN-NSR task in the OBJ-NSR task (<xref ref-type="fig" rid="fig3">Figure 3A</xref>). Inactivation of the PER caused a noticeable drop in performance compared with controls (<xref ref-type="fig" rid="fig3">Figure 3B</xref>), whereas similar deficits were not found in the POR-MUS group. A one-way repeated-measures ANOVA showed a significant effect of drug (F<sub>(2,12)</sub> = 15.548, p&lt;0.001); a significant difference in performance was also found between ACSF and PER-MUS groups (p&lt;0.001) and between PER-MUS and POR-MUS groups (p&lt;0.001; Bonferroni-Dunn) (<xref ref-type="fig" rid="fig3">Figure 3B</xref>; <xref ref-type="supplementary-material" rid="fig3sdata1">Figure 3—source data 1</xref>). Interestingly, allowing rats to sample the object only visually in the same task recruited the PER similarly and, to some extent, the POR as well (see <xref ref-type="fig" rid="fig3s1">Figure 3—figure supplement 1</xref>, <xref ref-type="supplementary-material" rid="fig3s1sdata1">Figure 3—figure supplement 1—source data 1</xref> for additional details).</p><fig-group><fig id="fig3" position="float"><object-id pub-id-type="doi">10.7554/eLife.32657.006</object-id><label>Figure 3.</label><caption><title>Object-memory tasks.</title><p>(<bold>A</bold>) Rats made a nonspatial choice (push or dig) toward the sand-filled jar depending on the object cue attached to the jar. (<bold>B</bold>) Behavioral performance in the OBJ-NSR task (Mean ±SEM). The PER-MUS condition resulted in significant deficits in performance compared to the ACSF and POR-MUS conditions. (<bold>C</bold>) Object-cued spatial response task. Rats made a spatial choice depending on the toy object attached to the intersection wall. (<bold>D</bold>) Behavioral performance in the OBJ-SR task (Mean ± SEM). A significant difference in performance was found between the ACSF and PER-MUS conditions. **p&lt;0.01.</p><p><supplementary-material id="fig3sdata1"><object-id pub-id-type="doi">10.7554/eLife.32657.009</object-id><label>Figure 3—source data 1.</label><caption><title>Performance in the OBJ-NSR task.</title><p>Percent correct performance for individual rats under different drug conditions in the OBJ-NSR task.</p></caption><media mime-subtype="xlsx" mimetype="application" xlink:href="elife-32657-fig3-data1-v2.xlsx"/></supplementary-material></p><p><supplementary-material id="fig3sdata2"><object-id pub-id-type="doi">10.7554/eLife.32657.010</object-id><label>Figure 3—source data 2.</label><caption><title>Performance in the OBJ-SR task.</title><p>Percent correct performance for individual rats under different drug conditions in the OBJ-SR task.</p></caption><media mime-subtype="xlsx" mimetype="application" xlink:href="elife-32657-fig3-data2-v2.xlsx"/></supplementary-material></p></caption><graphic mime-subtype="postscript" mimetype="application" xlink:href="elife-32657-fig3-v2"/></fig><fig id="fig3s1" position="float" specific-use="child-fig"><object-id pub-id-type="doi">10.7554/eLife.32657.007</object-id><label>Figure 3—figure supplement 1.</label><caption><title>Multimodal versus visual OBJ-NSR tasks.</title><p>(<bold>A</bold>) Cumulative performance of the PER-MUS group across trials in the multimodal OBJ-NSR (mOBJ-NSR) task and visual OBJ-NSR (vOBJ-NSR) task. We noticed that the performance of rats in the PER-MUS group in the mOBJ-NSR task improved in later trials, possibly suggesting a switch in the animal’s dependence on specific sensory modality (e.g., from visual to tactile) during object recognition. Such trend was not observed when objects were only sampled using visual modality in the vOBJ-NSR task. In the mOBJ-NSR task, the rats were allowed to sample the object stimulus using multiple sensory modalities such as vision and tactile information. The use of olfactory information, however, was controlled by cleaning the objects every 10 trials with diluted ethanol (70%), and replacing the object with its replica. Behavioral testing in the mOBJ-NSR task was followed by the vOBJ-NSR task. In the task, the object stimuli were encased in a transparent acrylic box (6 × 6 × 4 cm) with a sliding door to restrict the perceptual access to the object to the visual modality only. The general task procedures and object-response contingencies were the same between the two versions of the task. There was a significant difference between the slopes of the performance curves for the two tasks. (<bold>B</bold>) Behavioral performance in the vOBJ-NSR task (Mean ± SEM). Significant differences in performance were found among all groups (F<sub>(2,12)</sub> = 40.477, p&lt;0.0001; one-way repeated ANOVA). There was a significant performance difference between ACSF and PER-MUS groups (p&lt;0.0001), between ACSF and POR-MUS groups (p=0.001), and between PER-MUS and POR-MUS groups (p&lt;0.001; Bonferroni-Dunn). **p&lt;0.01, ***p&lt;0.0001.</p><p><supplementary-material id="fig3s1sdata1"><object-id pub-id-type="doi">10.7554/eLife.32657.008</object-id><label>Figure 3—figure supplement 1—source data 1.</label><caption><title>Performance in the visual OBJ-NSR task.</title></caption><media mime-subtype="xlsx" mimetype="application" xlink:href="elife-32657-fig3-figsupp1-data1-v2.xlsx"/></supplementary-material></p></caption><graphic mime-subtype="postscript" mimetype="application" xlink:href="elife-32657-fig3-figsupp1-v2"/></fig></fig-group><p>We further tested whether the PER was important when spatial choices were required upon recognizing an object, because the PER may be engaged in a task as long as an object is used as a cue, regardless of the response type. For this purpose, we trained another group of rats (n = 6) in the OBJ-SR task, in which rats learned to make spatial choices using a toy object as a cue (<xref ref-type="fig" rid="fig3">Figure 3C</xref>). Rats exhibited severe performance deficits in the PER-MUS group, as was the case in the OBJ-NSR task (<xref ref-type="fig" rid="fig3">Figure 3D</xref>; <xref ref-type="supplementary-material" rid="fig3sdata2">Figure 3—source data 2</xref>). Compared with the OBJ-NSR task, the POR-MUS group showed a trend toward mild deficits that failed to reach statistical significance. Specifically, a one-way repeated-measures ANOVA showed a significant effect of the drug (F<sub>(2,10)</sub> = 7.611, p&lt;0.01) and a significant difference only between ACSF and PER-MUS groups (p&lt;0.005), but not between ACSF and POR-MUS groups (p=0.034, a value that did not reach the corrected α = 0.017 in Bonferroni-Dunn tests) (<xref ref-type="fig" rid="fig3">Figure 3D</xref>).</p></sec><sec id="s2-4"><title>Functional dissociations are less clear in the upstream cortical regions of the EC</title><p>To compare the current findings with functional dissociations previously observed in the MEC and LEC (<xref ref-type="bibr" rid="bib26">Yoo and Lee, 2017</xref>), we plotted the relative performance deficits under MUS conditions (compared to ASCF conditions) in all tasks by subtracting the performance level under MUS from that in control conditions (<xref ref-type="fig" rid="fig4">Figure 4A</xref>).</p><fig-group><fig id="fig4" position="float"><object-id pub-id-type="doi">10.7554/eLife.32657.011</object-id><label>Figure 4.</label><caption><title>Lack of stimulus-response interaction in the PER and POR and a theoretical model.</title><p>(<bold>A</bold>) Performance deficits (calculated by subtracting the ACSF-based performance from the MUS-based performance) in the nonspatial response tasks (Mean ± SEM). The POR-MUS condition resulted in significant deficits in performance when scenes were used as cues, but not when objects were used. The PER-MUS condition produced deficits in using scenes and objects for making nonspatial choices with bigger deficits with object cues. (<bold>B</bold>) Performance deficits in the spatial response tasks (Mean ± SEM). Both PER-MUS and POR-MUS conditioned produced similar levels of impairment observed in the nonspatial tasks (<bold>A</bold>), suggesting the lack of scene-response interaction at the PER and POR level. Furthermore, the more prominent roles of the PER, but not the POR, in the object-cued task was also observed in the spatial response tasks. *p&lt;0.025. (<bold>C</bold>) A working model for information processing in the medial temporal lobe. Multimodal sensory inputs (VIS: visual, OLF: olfactory, AUD: auditory, SOM: somatosensory) are provided to the PER, and only visual inputs are fed to the POR. The PER and POR process these inputs to recognize objects and scenes, respectively. The LEC is involved in remembering choice responses associated with objects, whereas the MEC represents navigation-related variables using visual scene information from the POR. The LEC is reciprocally connected to the PER, hippocampus, insular cortex, and frontal areas (<xref ref-type="bibr" rid="bib4">Burwell and Amaral, 1998a</xref>). Also, the LEC projects to the basal ganglia, medial prefrontal cortex, somatosensory cortex, and motor areas (<xref ref-type="bibr" rid="bib24">Swanson and Köhler, 1986</xref>). The MEC has reciprocal connections with the POR, hippocampus, cingulate, and parietal cortex (<xref ref-type="bibr" rid="bib5">Burwell and Amaral, 1998b</xref>). The MEC receives projections from the parasubiculum and postsubiculum (<xref ref-type="bibr" rid="bib6">Canto et al., 2008</xref>). In this model, the PER-LEC networks are to interact with objects and the POR-MEC networks process information to navigate in space. In the hippocampus, the neural representations from these two channels are temporally structured with relative values in a goal-directed manner to generate rich episodic memories.</p></caption><graphic mime-subtype="postscript" mimetype="application" xlink:href="elife-32657-fig4-v2"/></fig><fig id="fig4s1" position="float" specific-use="child-fig"><object-id pub-id-type="doi">10.7554/eLife.32657.012</object-id><label>Figure 4—figure supplement 1.</label><caption><title>Comparisons of the PER-POR networks with the LEC-MEC networks.</title><p>(<bold>A</bold>) Performance deficits in the nonspatial response tasks (Mean ± SEM). The POR-MUS showed significant deficits when scenes and vOBJ were used as cues. The PER-MUS produced deficits in using scenes and objects for making nonspatial choices with bigger deficits with object cues. Between vOBJ- and SCN-NSR tasks, significant effects of task (F<sub>(1,6)</sub> = 8.794, p&lt;0.05) and task-region interaction (F<sub>(1,6)</sub> = 7.556, p&lt;0.05) were found. A <italic>post hoc</italic> t-test showed a significantly larger deficit in the PER in the vOBJ-NSR task than in the SCN-NSR task (p&lt;0.025), a difference that was not observed in the POR (F<sub>(1,6)</sub> = 3.36, p&gt;0.1). (<bold>B</bold>) Double dissociation reported in the <xref ref-type="bibr" rid="bib26">Yoo and Lee, 2017</xref> between the LEC and MEC in the SCN-SR and SCN-NSR tasks. (<bold>C</bold>) Performance deficits of the PER-MUS and POR-MUS groups in the SCN-SR and SCN-NSR tasks. *p&lt;0.05, **p&lt;0.001.</p></caption><graphic mime-subtype="postscript" mimetype="application" xlink:href="elife-32657-fig4-figsupp1-v2"/></fig></fig-group><p>In the NSR tasks (SCN-NSR and OBJ-NSR), the PER-MUS group showed large performance deficits in the OBJ-NSR task. The performance deficits in the SCN-NSR task were relatively smaller than those in the OBJ-NSR task. The POR-MUS group did not show any performance deficits in the OBJ-NSR task, but showed significant deficits in the SCN-NSR task (<xref ref-type="fig" rid="fig4">Figure 4A</xref>). A comparison of performance between OBJ-NSR and SCN-NSR tasks (two-way repeated measures ANOVA with task and region as within-subject factors) revealed a significant effect of region (F<sub>(1,6)</sub> = 30.295, p&lt;0.01), but not task (F<sub>(1,6)</sub> = 0.08, p&gt;0.5). The interaction between the two factors was significant (F<sub>(1,6)</sub> = 6.561, p&lt;0.05). A post hoc t-test (α = 0.025) showed a significantly larger deficit in the SCN-NSR than in the OBJ-NSR task in the POR (p&lt;0.025), but not in the PER (p&gt;0.1) (<xref ref-type="fig" rid="fig4">Figure 4A</xref>). Similar results were also obtained when only visual sampling was allowed in the OBJ-NSR task (<xref ref-type="fig" rid="fig4s1">Figure 4—figure supplement 1A</xref>).</p><p>In SR tasks (SCN-SR and OBJ-SR), the PER-MUS group showed larger deficits in the OBJ-SR task than in the SCN-SR task, whereas in the POR-MUS group, the results were similar between the two tasks (<xref ref-type="fig" rid="fig4">Figure 4B</xref>). There were no significant effects of region (F<sub>(1,12)</sub> = 0.470, p=0.506) or task (F<sub>(1,12)</sub> = 0.872, p=0.368), but the interaction between the two factors approached significance (F<sub>(1,12)</sub> = 4.338, p=0.059).</p><p>Taken together, these findings strongly indicate that whether an object functions as a cue in a task may determine whether the PER plays an important role in the task, whereas the associated type of response may not be so critical. In contrast, the type of response (e.g., spatial navigational response) may play a greater role in recruiting the POR than the type of the cueing stimulus. An important finding in our study is that there is a condition in which the POR may not be necessary, namely the OBJ-NSR task (<xref ref-type="fig" rid="fig4">Figure 4A</xref>). One exception might be when a purely visual object is used as a cueing object (see below for further discussion). Most importantly, it is clear that the interaction between the stimulus attribute and response type between the PER and POR is not as strong as between the LEC and MEC (<xref ref-type="fig" rid="fig4">Figure 4C</xref>; <xref ref-type="fig" rid="fig4s1">Figure 4—figure supplement 1B and C</xref>).</p></sec></sec><sec id="s3" sec-type="discussion"><title>Discussion</title><p>In the current study, we sought to investigate functional differences between the PER and POR, the upstream regions of the LEC and MEC, respectively. Unlike in the LEC and MEC (<xref ref-type="bibr" rid="bib26">Yoo and Lee, 2017</xref>), functional dissociations based on the response type (i.e., spatial vs. nonspatial) were less clear in the upstream areas in the scene-based tasks. Instead, the type of stimulus (i.e., object and scene) appears to critically determine the involvement of these areas in a task (<xref ref-type="fig" rid="fig4">Figure 4</xref>). Specifically, the PER was important in cases where an object stimulus should be recognized, but less so for scenes, regardless of the response type, whereas the POR was involved when either visual scene recognition or spatial navigation was necessary. Our findings suggest that the PER and POR may provide object and scene information to the LEC and MEC, respectively. In the EC, this information may be associated with task-demand–specific actions involving interaction with an object (LEC) or navigating in space (MEC). That is, the PER-LEC and POR-MEC networks may process ‘what should I do in relation to this object?’ and ‘where should I go from here?', respectively (<xref ref-type="fig" rid="fig4">Figure 4C</xref>).</p><p>Anatomically, the PER receives multimodal sensory inputs (e.g., auditory, visual, olfactory, and somatosensory) from various sensory-perceptual cortices, whereas the POR receives major inputs largely from visual areas, including the retrosplenial cortex (<xref ref-type="bibr" rid="bib1">Agster and Burwell, 2009</xref>; <xref ref-type="bibr" rid="bib4">Burwell and Amaral, 1998a</xref>). In the current study, inactivating the PER indeed produced large deficits compared with controls whenever rats were required to recognize an object before making a spatial or nonspatial response. In contrast, inactivation of the POR resulted in reliable deficits in performance whenever scene was used as a conditional cue before making a spatial or nonspatial choice. Together with prior findings (<xref ref-type="bibr" rid="bib8">Epstein and Kanwisher, 1998</xref>; <xref ref-type="bibr" rid="bib19">Murray and Richmond, 2001</xref>), our results suggest that the PER and POR may be specialized in recognizing (and perhaps perceiving) objects (<xref ref-type="bibr" rid="bib2">Ahn and Lee, 2017</xref>; <xref ref-type="bibr" rid="bib18">McTighe et al., 2010</xref>) and scenes, respectively.</p><p>We previously reported a strong double dissociation in the LEC and MEC between scene-based tasks that required nonspatial responses (i.e., object manipulation) and spatial responses (i.e., navigational turns) (<xref ref-type="fig" rid="fig4s1">Figure 4—figure supplement 1B</xref>) (<xref ref-type="bibr" rid="bib26">Yoo and Lee, 2017</xref>). Testing rats in the same tasks with the PER or POR inactivated did not result in such strong dissociations in the current study (<xref ref-type="fig" rid="fig4s1">Figure 4—figure supplement 1C</xref>), suggesting that scene-response interactions may uniquely occur in the EC. However, when the stimulus category was extended to include objects, some interactions between stimulus and response types became apparent in the POR, but not necessarily in the PER. Specifically, a comparison of performance deficits between scene- and object-based tasks with the PER inactivated showed similarly larger deficits in object-based tasks (OBJ-NSR and OBJ-SR tasks) than in scene-based tasks (SCN-NSR and SCN-SR tasks), regardless of the response type. However, the navigational task demand in both OBJ-SR and SCN-SR tasks required the POR, irrespective of the type of stimulus, whereas the same region was only necessary when a visual scene (SCN-NSR task), but not an object (OBJ-NSR task), was used as a cue in nonspatial tasks. These results suggest that both scene recognition and spatial navigation constitute important computational components of the POR network (<xref ref-type="fig" rid="fig4">Figure 4C</xref>).</p><p>It is unclear why the navigational demand affected the POR regardless of the stimulus type, but had a lesser effect in the PER (<xref ref-type="fig" rid="fig4">Figure 4B</xref>). One possibility is that the POR indeed processes navigation-related signals in association with objects and scenes, based on the reciprocal connections with the MEC (<xref ref-type="fig" rid="fig4">Figure 4C</xref>). Because strong neural correlates for spatial navigation (e.g., grid cells and border cells) have been reported in the MEC (<xref ref-type="bibr" rid="bib11">Hafting et al., 2005</xref>; <xref ref-type="bibr" rid="bib22">Sargolini et al., 2006</xref>; <xref ref-type="bibr" rid="bib23">Solstad et al., 2008</xref>), the MEC may bias the POR network toward processing incoming sensory inputs (e.g., visual object or scene information) in relation to the spatial navigation components of the task. Such a strong bias may not be exerted by the LEC to the PER, because object recognition may lead to many different types of responses in natural settings, as opposed to the case of scene recognition, which is normally associated with spatial navigation. Another possibility is that top-down influences from other navigation-related regions (e.g., retrosplenial cortex) might be stronger in the POR-MEC networks than in the PER-LEC networks. Considering the anatomical finding that the POR-to-PER connection is stronger than the PER-to-POR connection (<xref ref-type="bibr" rid="bib5">Burwell and Amaral, 1998b</xref>; <xref ref-type="bibr" rid="bib10">Furtak et al., 2007</xref>; <xref ref-type="bibr" rid="bib14">Kealy and Commins, 2011</xref>), it is also possible that rats with inactivation in the POR might send disturbing signals to the PER, preventing normal object recognition in the OBJ-SR task (<xref ref-type="fig" rid="fig3">Figure 3D</xref>). Nonetheless, our study clearly demonstrates that the POR is not necessary if neither spatial navigation nor visual scene information processing is required.</p><p>Visual scenes used in our tasks may be considered as a context, and the PER-POR networks may play significant roles in contextual object recognition (<xref ref-type="bibr" rid="bib20">Norman and Eacott, 2005</xref>; <xref ref-type="bibr" rid="bib13">Heimer-McGinn et al., 2017</xref>). In natural situations, an animal never experiences an object completely detached from its background, and a visual context also always involves objects in it (<xref ref-type="bibr" rid="bib3">Aminoff et al., 2013</xref>). Therefore, PER and POR networks may function in harmony in natural settings, rather than in isolation from each other. For example, an object is recognized efficiently when it appears against a contextually plausible background (<xref ref-type="bibr" rid="bib3">Aminoff et al., 2013</xref>). Disrupting the POR network may affect such contextual object recognition (<xref ref-type="bibr" rid="bib9">Furtak et al., 2012</xref>) in our SCN-NSR task because the ‘meaning’ (e.g., push or dig) of the object (i.e., jar) should be disambiguated using visual scenes in the background in that task. Likewise, inactivating the PER as in our study may make it harder for the animal to focus on the target object against its background context. These functional relationships between the PER and POR may underlie the similar deficits between PER-MUS and POR-MUS groups in the SCN-NSR task. Inactivation of the PER may also have some disruptive effects on the POR’s functions in scene information processing through PER-to-POR connections, leading to mild performance deficits (but still &gt;80% correct) in the SCN-SR task in our study. Another possibility is that scene recognition in the POR may require some contribution of the PER, because a scene is normally composed of individual objects (e.g., individual pebble stones in the pebbles scene in our task). On a similar note, inactivation of the POR may make it difficult for an animal to focus on the cueing object in the OBJ-SR task, because contextual disruption, but not facilitation, of object recognition might occur.</p><p>In the view of traditional theory, spatial and nonspatial information is processed via separate streams in the medial temporal lobe (<xref ref-type="bibr" rid="bib16">Knierim et al., 2014</xref>). According to this model, the physical attribute (i.e., spatial or nonspatial) of a stimulus determines the processing stream (i.e., PER-LEC or POR-MEC) to which the information is channeled. However, the current results, together with our previous findings, strongly suggest that such a view may be too simplistic. Our current working model is that the PER-LEC and POR-MEC networks are mainly concerned with object manipulation (or exploration) and spatial navigation (or contextual memory), respectively (<xref ref-type="fig" rid="fig4">Figure 4C</xref>). Our model posits that recognition of perceptual stimuli mainly occurs at the level of the PER (for objects) and POR (for scenes), and their task-related actions are associatively represented in the EC networks. The hippocampus, which receives these inputs together, may encode and retrieve various event memories in sequences as an animal navigates through a space to achieve goals.</p></sec><sec id="s4" sec-type="materials|methods"><title>Materials and methods</title><sec id="s4-1"><title>Subjects</title><p>Twenty-three male Long-Evans rats (8 weeks old) were obtained and housed individually in Plexiglas cages in a temperature- and humidity-controlled animal colony. Rats were maintained on a 12 hr light/dark cycle (lights on at 8:00 am), and experiments were carried out in the light phase of the cycle. Rats were food-restricted to maintain 80% of their free-feeding weight, but allowed access to water freely. All protocols for animal care and surgery adhered to the guidelines of the Institutional animal care and Use Committee of the Seoul National University (SNU-120925-1-7).</p></sec><sec id="s4-2"><title>Behavioral paradigm</title><p>Detailed procedures for the SCN-NSR, SCN-SR, and OBJ-NSR tasks can be found in the previous study (<xref ref-type="bibr" rid="bib26">Yoo and Lee, 2017</xref>). The OBJ-SR task was performed in the same T-shaped linear track used in the SCN-SR task. One of the four 3-dimensional toy objects (dolphin, turtle, crab and duck) were affixed upright via a magnet at the intersection of the track, and the rat had to visit the arm associated with the object. The object stimuli used in the OBJ-SR task were somewhat bigger (6–7 cm in width and 7–8 cm in height) than those in the OBJ-NSR (3 cm in width and 3–7 cm in height) task to ensure that the rats properly sampled the objects before making a choice in the intersection.</p></sec><sec id="s4-3"><title>Bilateral cannulae implantation in the PER and POR</title><p>Four small burr holes were drilled and cannulae were implanted in the PER and POR bilaterally. The following coordinates were used for the first three animals: (1) PER: AP - 4.8 mm, ML ± 6.8 mm, DV - 4.6 mm from dura; (2) POR: AP – 8 mm, ML ± 6.5 mm, DV - 1.5 mm from dura in 3 animals. In order to minimize the damage in the temporal muscles, the coordinates were later revised for the rest of the animals: (1) PER: AP - 4.8 mm, ML ±5 mm, DV – 6 mm from dura with the tip angled at 15° laterally, and (2) POR: AP – 8 to 8.2 mm, ML ± 5 to 5.3 mm, DV - 3.4 to 4 mm from dura with the tip angled at 15° laterally.</p></sec></sec></body><back><ack id="ack"><title>Acknowledgements</title><p>This work was supported by the National Research Foundation of Korea (2015M3C7A1031969, 2016R1A2B4008692, 2017M3C7A1029661) and the BK21 + program (5286–2014100). We thank Heung-Yeol Lim for his assistance in behavioral testing.</p></ack><sec id="s5" sec-type="additional-information"><title>Additional information</title><fn-group content-type="competing-interest"><title>Competing interests</title><fn fn-type="COI-statement" id="conf1"><p>No competing interests declared</p></fn></fn-group><fn-group content-type="author-contribution"><title>Author contributions</title><fn fn-type="con" id="con1"><p>Conceptualization, Data curation, Software, Formal analysis, Visualization, Methodology, Writing—original draft</p></fn><fn fn-type="con" id="con2"><p>Data curation, Software, Formal analysis, Visualization, Methodology, Writing—original draft, Writing—review and editing</p></fn><fn fn-type="con" id="con3"><p>Conceptualization, Resources, Supervision, Funding acquisition, Validation, Investigation, Visualization, Methodology, Writing—original draft, Project administration, Writing—review and editing</p></fn></fn-group><fn-group content-type="ethics-information"><title>Ethics</title><fn fn-type="other"><p>Animal experimentation: All of the animals were handled according to approved institutional animal care and use committee (IACUC) protocols of the Seoul National University (SNU-120925-1-7). All surgery was performed under isoflurane anesthesia, and every effort was made to minimize suffering.</p></fn></fn-group></sec><sec id="s6" sec-type="supplementary-material"><title>Additional files</title><supplementary-material id="transrepform"><object-id pub-id-type="doi">10.7554/eLife.32657.013</object-id><label>Transparent reporting form</label><media mime-subtype="docx" mimetype="application" xlink:href="elife-32657-transrepform-v2.docx"/></supplementary-material></sec><ref-list><title>References</title><ref id="bib1"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Agster</surname> <given-names>KL</given-names></name><name><surname>Burwell</surname> <given-names>RD</given-names></name></person-group><year iso-8601-date="2009">2009</year><article-title>Cortical efferents of the perirhinal, postrhinal, and entorhinal cortices of the rat</article-title><source>Hippocampus</source><volume>19</volume><fpage>1159</fpage><lpage>1186</lpage><pub-id pub-id-type="doi">10.1002/hipo.20578</pub-id><pub-id pub-id-type="pmid">19360714</pub-id></element-citation></ref><ref id="bib2"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ahn</surname> <given-names>JR</given-names></name><name><surname>Lee</surname> <given-names>I</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>Neural Correlates of Both Perception and Memory for Objects in the Rodent Perirhinal Cortex</article-title><source>Cerebral Cortex</source><volume>27</volume><fpage>3856</fpage><lpage>3868</lpage><pub-id pub-id-type="doi">10.1093/cercor/bhx093</pub-id><pub-id pub-id-type="pmid">28444371</pub-id></element-citation></ref><ref id="bib3"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Aminoff</surname> <given-names>EM</given-names></name><name><surname>Kveraga</surname> <given-names>K</given-names></name><name><surname>Bar</surname> <given-names>M</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>The role of the parahippocampal cortex in cognition</article-title><source>Trends in Cognitive Sciences</source><volume>17</volume><fpage>379</fpage><lpage>390</lpage><pub-id pub-id-type="doi">10.1016/j.tics.2013.06.009</pub-id><pub-id pub-id-type="pmid">23850264</pub-id></element-citation></ref><ref id="bib4"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Burwell</surname> <given-names>RD</given-names></name><name><surname>Amaral</surname> <given-names>DG</given-names></name></person-group><year iso-8601-date="1998">1998a</year><article-title>Cortical afferents of the perirhinal, postrhinal, and entorhinal cortices of the rat</article-title><source>The Journal of Comparative Neurology</source><volume>398</volume><fpage>179</fpage><lpage>205</lpage><pub-id pub-id-type="doi">10.1002/(SICI)1096-9861(19980824)398:2&lt;179::AID-CNE3&gt;3.0.CO;2-Y</pub-id><pub-id pub-id-type="pmid">9700566</pub-id></element-citation></ref><ref id="bib5"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Burwell</surname> <given-names>RD</given-names></name><name><surname>Amaral</surname> <given-names>DG</given-names></name></person-group><year iso-8601-date="1998">1998b</year><article-title>Perirhinal and postrhinal cortices of the rat: interconnectivity and connections with the entorhinal cortex</article-title><source>The Journal of Comparative Neurology</source><volume>391</volume><fpage>293</fpage><lpage>321</lpage><pub-id pub-id-type="doi">10.1002/(SICI)1096-9861(19980216)391:3&lt;293::AID-CNE2&gt;3.0.CO;2-X</pub-id><pub-id pub-id-type="pmid">9492202</pub-id></element-citation></ref><ref id="bib6"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Canto</surname> <given-names>CB</given-names></name><name><surname>Wouterlood</surname> <given-names>FG</given-names></name><name><surname>Witter</surname> <given-names>MP</given-names></name></person-group><year iso-8601-date="2008">2008</year><article-title>What Does the Anatomical Organization of the Entorhinal Cortex Tell Us?</article-title><source>Neural Plasticity</source><volume>2008</volume><fpage>1</fpage><lpage>18</lpage><pub-id pub-id-type="doi">10.1155/2008/381243</pub-id></element-citation></ref><ref id="bib7"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Dombeck</surname> <given-names>DA</given-names></name><name><surname>Harvey</surname> <given-names>CD</given-names></name><name><surname>Tian</surname> <given-names>L</given-names></name><name><surname>Looger</surname> <given-names>LL</given-names></name><name><surname>Tank</surname> <given-names>DW</given-names></name></person-group><year iso-8601-date="2010">2010</year><article-title>Functional imaging of hippocampal place cells at cellular resolution during virtual navigation</article-title><source>Nature Neuroscience</source><volume>13</volume><fpage>1433</fpage><lpage>1440</lpage><pub-id pub-id-type="doi">10.1038/nn.2648</pub-id><pub-id pub-id-type="pmid">20890294</pub-id></element-citation></ref><ref id="bib8"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Epstein</surname> <given-names>R</given-names></name><name><surname>Kanwisher</surname> <given-names>N</given-names></name></person-group><year iso-8601-date="1998">1998</year><article-title>A cortical representation of the local visual environment</article-title><source>Nature</source><volume>392</volume><fpage>598</fpage><lpage>601</lpage><pub-id pub-id-type="doi">10.1038/33402</pub-id><pub-id pub-id-type="pmid">9560155</pub-id></element-citation></ref><ref id="bib9"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Furtak</surname> <given-names>SC</given-names></name><name><surname>Ahmed</surname> <given-names>OJ</given-names></name><name><surname>Burwell</surname> <given-names>RD</given-names></name></person-group><year iso-8601-date="2012">2012</year><article-title>Single neuron activity and theta modulation in postrhinal cortex during visual object discrimination</article-title><source>Neuron</source><volume>76</volume><fpage>976</fpage><lpage>988</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2012.10.039</pub-id><pub-id pub-id-type="pmid">23217745</pub-id></element-citation></ref><ref id="bib10"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Furtak</surname> <given-names>SC</given-names></name><name><surname>Wei</surname> <given-names>SM</given-names></name><name><surname>Agster</surname> <given-names>KL</given-names></name><name><surname>Burwell</surname> <given-names>RD</given-names></name></person-group><year iso-8601-date="2007">2007</year><article-title>Functional neuroanatomy of the parahippocampal region in the rat: the perirhinal and postrhinal cortices</article-title><source>Hippocampus</source><volume>17</volume><fpage>709</fpage><lpage>722</lpage><pub-id pub-id-type="doi">10.1002/hipo.20314</pub-id><pub-id pub-id-type="pmid">17604355</pub-id></element-citation></ref><ref id="bib11"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hafting</surname> <given-names>T</given-names></name><name><surname>Fyhn</surname> <given-names>M</given-names></name><name><surname>Molden</surname> <given-names>S</given-names></name><name><surname>Moser</surname> <given-names>MB</given-names></name><name><surname>Moser</surname> <given-names>EI</given-names></name></person-group><year iso-8601-date="2005">2005</year><article-title>Microstructure of a spatial map in the entorhinal cortex</article-title><source>Nature</source><volume>436</volume><fpage>801</fpage><lpage>806</lpage><pub-id pub-id-type="doi">10.1038/nature03721</pub-id><pub-id pub-id-type="pmid">15965463</pub-id></element-citation></ref><ref id="bib12"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hassabis</surname> <given-names>D</given-names></name><name><surname>Maguire</surname> <given-names>EA</given-names></name></person-group><year iso-8601-date="2009">2009</year><article-title>The construction system of the brain</article-title><source>Philosophical Transactions of the Royal Society B: Biological Sciences</source><volume>364</volume><fpage>1263</fpage><lpage>1271</lpage><pub-id pub-id-type="doi">10.1098/rstb.2008.0296</pub-id><pub-id pub-id-type="pmid">19528007</pub-id></element-citation></ref><ref id="bib13"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Heimer-McGinn</surname> <given-names>VR</given-names></name><name><surname>Poeta</surname> <given-names>DL</given-names></name><name><surname>Aghi</surname> <given-names>K</given-names></name><name><surname>Udawatta</surname> <given-names>M</given-names></name><name><surname>Burwell</surname> <given-names>RD</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>Disconnection of the perirhinal and postrhinal cortices impairs recognition of objects in context but not contextual fear conditioning</article-title><source>The Journal of Neuroscience</source><volume>37</volume><fpage>4819</fpage><lpage>4829</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.0254-17.2017</pub-id><pub-id pub-id-type="pmid">28411272</pub-id></element-citation></ref><ref id="bib14"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kealy</surname> <given-names>J</given-names></name><name><surname>Commins</surname> <given-names>S</given-names></name></person-group><year iso-8601-date="2011">2011</year><article-title>The rat perirhinal cortex: A review of anatomy, physiology, plasticity, and function</article-title><source>Progress in Neurobiology</source><volume>93</volume><fpage>522</fpage><lpage>548</lpage><pub-id pub-id-type="doi">10.1016/j.pneurobio.2011.03.002</pub-id><pub-id pub-id-type="pmid">21420466</pub-id></element-citation></ref><ref id="bib15"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kim</surname> <given-names>S</given-names></name><name><surname>Lee</surname> <given-names>J</given-names></name><name><surname>Lee</surname> <given-names>I</given-names></name></person-group><year iso-8601-date="2012">2012</year><article-title>The hippocampus is required for visually cued contextual response selection, but not for visual discrimination of contexts</article-title><source>Frontiers in Behavioral Neuroscience</source><volume>6</volume><elocation-id>66</elocation-id><pub-id pub-id-type="doi">10.3389/fnbeh.2012.00066</pub-id><pub-id pub-id-type="pmid">23060765</pub-id></element-citation></ref><ref id="bib16"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Knierim</surname> <given-names>JJ</given-names></name><name><surname>Neunuebel</surname> <given-names>JP</given-names></name><name><surname>Deshmukh</surname> <given-names>SS</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>Functional correlates of the lateral and medial entorhinal cortex: objects, path integration and local-global reference frames</article-title><source>Philosophical Transactions of the Royal Society B: Biological Sciences</source><volume>369</volume><fpage>20130369</fpage><pub-id pub-id-type="doi">10.1098/rstb.2013.0369</pub-id><pub-id pub-id-type="pmid">24366146</pub-id></element-citation></ref><ref id="bib17"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Maguire</surname> <given-names>EA</given-names></name><name><surname>Mullally</surname> <given-names>SL</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>The hippocampus: a manifesto for change</article-title><source>Journal of Experimental Psychology: General</source><volume>142</volume><fpage>1180</fpage><lpage>1189</lpage><pub-id pub-id-type="doi">10.1037/a0033650</pub-id><pub-id pub-id-type="pmid">23855494</pub-id></element-citation></ref><ref id="bib18"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>McTighe</surname> <given-names>SM</given-names></name><name><surname>Cowell</surname> <given-names>RA</given-names></name><name><surname>Winters</surname> <given-names>BD</given-names></name><name><surname>Bussey</surname> <given-names>TJ</given-names></name><name><surname>Saksida</surname> <given-names>LM</given-names></name></person-group><year iso-8601-date="2010">2010</year><article-title>Paradoxical false memory for objects after brain damage</article-title><source>Science</source><volume>330</volume><fpage>1408</fpage><lpage>1410</lpage><pub-id pub-id-type="doi">10.1126/science.1194780</pub-id><pub-id pub-id-type="pmid">21127256</pub-id></element-citation></ref><ref id="bib19"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Murray</surname> <given-names>EA</given-names></name><name><surname>Richmond</surname> <given-names>BJ</given-names></name></person-group><year iso-8601-date="2001">2001</year><article-title>Role of perirhinal cortex in object perception, memory, and associations</article-title><source>Current Opinion in Neurobiology</source><volume>11</volume><fpage>188</fpage><lpage>193</lpage><pub-id pub-id-type="doi">10.1016/S0959-4388(00)00195-1</pub-id><pub-id pub-id-type="pmid">11301238</pub-id></element-citation></ref><ref id="bib20"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Norman</surname> <given-names>G</given-names></name><name><surname>Eacott</surname> <given-names>MJ</given-names></name></person-group><year iso-8601-date="2005">2005</year><article-title>Dissociable effects of lesions to the perirhinal cortex and the postrhinal cortex on memory for context and objects in rats</article-title><source>Behavioral Neuroscience</source><volume>119</volume><fpage>557</fpage><lpage>566</lpage><pub-id pub-id-type="doi">10.1037/0735-7044.119.2.557</pub-id><pub-id pub-id-type="pmid">15839802</pub-id></element-citation></ref><ref id="bib21"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Prusky</surname> <given-names>GT</given-names></name><name><surname>Douglas</surname> <given-names>RM</given-names></name><name><surname>Nelson</surname> <given-names>L</given-names></name><name><surname>Shabanpoor</surname> <given-names>A</given-names></name><name><surname>Sutherland</surname> <given-names>RJ</given-names></name></person-group><year iso-8601-date="2004">2004</year><article-title>Visual memory task for rats reveals an essential role for hippocampus and perirhinal cortex</article-title><source>PNAS</source><volume>101</volume><fpage>5064</fpage><lpage>5068</lpage><pub-id pub-id-type="doi">10.1073/pnas.0308528101</pub-id><pub-id pub-id-type="pmid">15051876</pub-id></element-citation></ref><ref id="bib22"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Sargolini</surname> <given-names>F</given-names></name><name><surname>Fyhn</surname> <given-names>M</given-names></name><name><surname>Hafting</surname> <given-names>T</given-names></name><name><surname>McNaughton</surname> <given-names>BL</given-names></name><name><surname>Witter</surname> <given-names>MP</given-names></name><name><surname>Moser</surname> <given-names>MB</given-names></name><name><surname>Moser</surname> <given-names>EI</given-names></name></person-group><year iso-8601-date="2006">2006</year><article-title>Conjunctive representation of position, direction, and velocity in entorhinal cortex</article-title><source>Science</source><volume>312</volume><fpage>758</fpage><lpage>762</lpage><pub-id pub-id-type="doi">10.1126/science.1125572</pub-id><pub-id pub-id-type="pmid">16675704</pub-id></element-citation></ref><ref id="bib23"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Solstad</surname> <given-names>T</given-names></name><name><surname>Boccara</surname> <given-names>CN</given-names></name><name><surname>Kropff</surname> <given-names>E</given-names></name><name><surname>Moser</surname> <given-names>MB</given-names></name><name><surname>Moser</surname> <given-names>EI</given-names></name></person-group><year iso-8601-date="2008">2008</year><article-title>Representation of geometric borders in the entorhinal cortex</article-title><source>Science</source><volume>322</volume><fpage>1865</fpage><lpage>1868</lpage><pub-id pub-id-type="doi">10.1126/science.1166466</pub-id><pub-id pub-id-type="pmid">19095945</pub-id></element-citation></ref><ref id="bib24"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Swanson</surname> <given-names>LW</given-names></name><name><surname>Köhler</surname> <given-names>C</given-names></name></person-group><year iso-8601-date="1986">1986</year><article-title>Anatomical evidence for direct projections from the entorhinal area to the entire cortical mantle in the rat.</article-title><source>The Journal of Neuroscience : The Official Journal of the Society for Neuroscience</source><volume>6</volume><fpage>3010</fpage><lpage>3033</lpage><pub-id pub-id-type="pmid">3020190</pub-id></element-citation></ref><ref id="bib25"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wirth</surname> <given-names>S</given-names></name><name><surname>Yanike</surname> <given-names>M</given-names></name><name><surname>Frank</surname> <given-names>LM</given-names></name><name><surname>Smith</surname> <given-names>AC</given-names></name><name><surname>Brown</surname> <given-names>EN</given-names></name><name><surname>Suzuki</surname> <given-names>WA</given-names></name></person-group><year iso-8601-date="2003">2003</year><article-title>Single neurons in the monkey hippocampus and learning of new associations</article-title><source>Science</source><volume>300</volume><fpage>1578</fpage><lpage>1581</lpage><pub-id pub-id-type="doi">10.1126/science.1084324</pub-id><pub-id pub-id-type="pmid">12791995</pub-id></element-citation></ref><ref id="bib26"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Yoo</surname> <given-names>SW</given-names></name><name><surname>Lee</surname> <given-names>I</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>Correction: Functional double dissociation within the entorhinal cortex for visual scene-dependent choice behavior</article-title><source>eLife</source><volume>6</volume><elocation-id>e28407</elocation-id><pub-id pub-id-type="doi">10.7554/eLife.28407</pub-id><pub-id pub-id-type="pmid">28492367</pub-id></element-citation></ref><ref id="bib27"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Zeidman</surname> <given-names>P</given-names></name><name><surname>Mullally</surname> <given-names>SL</given-names></name><name><surname>Maguire</surname> <given-names>EA</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>Constructing, perceiving, and maintaining scenes: hippocampal activity and connectivity</article-title><source>Cerebral Cortex</source><volume>25</volume><fpage>3836</fpage><lpage>3855</lpage><pub-id pub-id-type="doi">10.1093/cercor/bhu266</pub-id><pub-id pub-id-type="pmid">25405941</pub-id></element-citation></ref></ref-list></back><sub-article article-type="decision-letter" id="SA1"><front-stub><article-id pub-id-type="doi">10.7554/eLife.32657.016</article-id><title-group><article-title>Decision letter</article-title></title-group><contrib-group><contrib contrib-type="editor"><name><surname>Schoenbaum</surname><given-names>Geoffrey</given-names></name><role>Reviewing Editor</role><aff><institution>NIDA</institution><country>United States</country></aff></contrib></contrib-group></front-stub><body><boxed-text><p>In the interests of transparency, eLife includes the editorial decision letter and accompanying author responses. A lightly edited version of the letter sent to the authors after peer review is shown, indicating the most substantive concerns; minor comments are not usually included.</p></boxed-text><p>Thank you for submitting your article &quot;Interactions between stimulus and response types are uniquely represented in the entorhinal cortex, but not in its upstream cortical regions&quot; for consideration by <italic>eLife</italic>. Your article has been reviewed by two peer reviewers, and the evaluation has been overseen by a Reviewing Editor and Sabine Kastner as the Senior Editor. The following individual involved in review of your submission has agreed to reveal his identity: Alex Easton (Reviewer #1).</p><p>The reviewers have discussed the reviews with one another and the Reviewing Editor has drafted this decision to help you prepare a revised submission.</p><p>Summary:</p><p>The current study is a follow-up to work done recently, published in <italic>eLife</italic>, in which these authors showed a dissociation in the lateral EC (LEC) from the medial EC (MEC) in a scene memory task based on response type. Here the authors test whether a similar dichotomy in processing information exists at the two regions directly upstream from these areas, the perirhinal and postrhinal regions. Each region was inactivated across several tasks using either object or response type. The authors found that the clean dissociation present at EC was not fully reproduced, and that instead there was substantial overlap in the involvement of the two areas across task requirements.</p><p>Essential revisions:</p><p>Both reviewers were overall positive and felt that the study was a logical and appropriate follow-up to the prior work, and that the experiments were well designed and executed. That the data did not cleanly match predictions nor detract from enthusiasm for the experiment and desire to see it published. However in discussions, it was felt that the authors could be clearer in describing some of the results (see reviews). In addition, and probably more critically, it was felt that the authors need to go beyond their current conclusions and provide a model or proposal of some sort to explain the unexpected results. As one reviewer put it, they should &quot;explain how their results cannot be explained by existing models and therefore which part(s) of the existing models need changing….. what they think might be going on (is it feedback from ERC that means these regions are harder to dissociate further upstream? Is it some anatomical crossover at the PER/POR level that differentiates the effects from the clearer dissociations in ERC? Is it that only in ERC does processing require these components to be separated and before that there is just less going on? Is it a difficulty effect between scenes and objects?)&quot;. Basically propose some testable ideas for why the segregation of information is present at one level but not another. These were the essential revisions I think.</p><p>Reviewer #1:</p><p>This is a concise, but important, follow up study to the authors' 2017 paper. Using spatial and non-spatial tasks in which the instruction cues are either objects (visual or multisensory) or scenes they investigate the role of Perirhinal and Postrhinal cortices through pharmacological inactivation of these regions.</p><p>The authors find that inactivation of the perirhinal cortex impairs performance on object cued tasks more than scene cued tasks (for both spatial and non spatial tasks). Postrhinal lesions appear to have a similar effect on both object and scene cued tasks, except where the object is multisensory in nature, in which case for non spatial tasks there is little sign of impairment.</p><p>Whilst the paper is clear and the findings of great interest, there is much the authors leave unsaid which is important. They broadly discuss that existing theory needs to be updated – but it seems to me that the authors are in a position with their data now to make suggestions as to what that updated theory might look like. It is important that the authors interpret this data in terms of potential mechanistic explanations. In particular, at the moment they talk in general about POR being critical for recognising visual stimuli and the PER for objects in particular. However, it seems to me this might not reflect the full dissociation the authors suggest. It is possible that both PER and POR could have the same function, but with POR having a more significant effect, meaning that scenes and objects are impaired following POR lesions, but the lesser effects of PER lesions would impair objects but not scenes, where additional information might be able to be used to solve the task. There is no clear double dissociation here to be confident about the independence of these two regions.</p><p>In that theme, <xref ref-type="fig" rid="fig4">Figure 4</xref> is extremely helpful, but highlights that scene guided learning is never more impacted by a lesion than object guided learning. This might provide support for the idea that scene guided learning is just easier, and that the apparent dissociation between POR and PER merely reflects this.</p><p>Reviewer #2:</p><p>The submitted manuscript fits the format of Research Advance papers published in <italic>eLife</italic> in the sense that it builds upon a Research Article recently published by the same authors in 2017, by using an experimental design directly inspired by the original data. The published paper was about the contribution of lateral and medial entorhinal cortex (LEC and MEC respectively) to spatial and non-spatial response in the context of a scene discrimination. In the present manuscript, the authors ask whether the cortical structures directly upstream LEC and MEC, i.e. perirhinal and postrhinal cortex (PER and POR, respectively) show the same dissociation as that observed in LEC and MEC for the processing of scene-based type of response.</p><p>To do so, they use a within-subject design in which rats received local intra-cerebral injections of muscimol in either PER of POR during specific trials of several tasks differing in either the type of stimuli (spatial scene or object) or the type of response required (spatial, i.e. turn left or right, or non-spatial, i.e. push or dig). The results do not reveal a dissociation between PER and POR inactivations with regard to the type of response in the spatial scene discriminations. Both inactivations induce a deficit no matter the response required, contrary to MEC and LEC inactivations. This is the main result shown in <xref ref-type="fig" rid="fig2">Figure 2</xref> and <xref ref-type="fig" rid="fig4s1">Figure 4—figure supplement 1</xref>. In addition, the authors show a complex pattern of results (with stronger effects of PER than of POR inactivations) with regard to object-based discrimination but here again no clear effect of the type of response.</p><p>The experiments are very well done. The results are interesting but the way they are summarized in <xref ref-type="fig" rid="fig4">Figure 4</xref> and analyzed in complex two-way and three-way ANOVAs (last section of results) is very complicated and therefore distract the reader from the main message (perfectly understandable from <xref ref-type="fig" rid="fig2">Figure 2</xref> and very nicely summarized in <xref ref-type="fig" rid="fig4s1">Figure 4—figure supplement 1</xref>). That PER and POR inactivations may have different effects on object discrimination in combination with type of response (<xref ref-type="fig" rid="fig3">Figure 3A</xref> vs. 3E) is also interesting and may be worth being reported. However, the introduction of the condition &quot;vOBJ-NSR&quot; here makes interpretation of the whole pattern of result even more complicated. If the authors want to carry a clear take-home message with significant impact, I suggest they simplify their presentation as much as possible.</p><p>In addition, some of their interpretations of the results are weird. One such example is the section on the results of object-based spatial choice where they say that &quot;A significant difference was found only between ACSF and PER-MUS groups (p &lt; 0.005), and not between ACSF and POR&quot;. Not only the statistics they report in this paragraph seem to show that POR are indeed impaired (and do not show a difference with PER), but just looking at the performance points in <xref ref-type="fig" rid="fig3">Figure 3E</xref> together with the height of the SEM seems to indicate the existence of an impairment as great in POR than in PER. In contrast it is clear that there is no impairment in PER rats for the same object discrimination if a non-spatial response if required (<xref ref-type="fig" rid="fig3">Figure 3A</xref>) while POR rats are clearly impaired. We thus have a dissociation here, though it is not the one that was expected.</p><p>Thus overall the paper brings interesting data that complement nicely those of the original paper, but my impression is that the important points are buried in such a way the main message is obscured. What we need here is a model, even sketchy, of how all this circuitry works and a possible interpretation of what makes that the type of response required from the rat is so important in triggering such complex effects in conjunction with the type of stimuli.</p></body></sub-article><sub-article article-type="reply" id="SA2"><front-stub><article-id pub-id-type="doi">10.7554/eLife.32657.017</article-id><title-group><article-title>Author response</article-title></title-group></front-stub><body><disp-quote content-type="editor-comment"><p>Reviewer #1:</p><p>[…]</p><p>Whilst the paper is clear and the findings of great interest, there is much the authors leave unsaid which is important. They broadly discuss that existing theory needs to be updated – but it seems to me that the authors are in a position with their data now to make suggestions as to what that updated theory might look like. It is important that the authors interpret this data in terms of potential mechanistic explanations. In particular, at the moment they talk in general about POR being critical for recognising visual stimuli and the PER for objects in particular. However, it seems to me this might not reflect the full dissociation the authors suggest. It is possible that both PER and POR could have the same function, but with POR having a more significant effect, meaning that scenes and objects are impaired following POR lesions, but the lesser effects of PER lesions would impair objects but not scenes, where additional information might be able to be used to solve the task. There is no clear double dissociation here to be confident about the independence of these two regions.</p></disp-quote><p>We thank the reviewer for this suggestion. In our revised manuscript, we have included our working model to explain the results of the current study and the Yoo and Lee study. Specifically, we have added a model diagram in <xref ref-type="fig" rid="fig4">Figure 4C</xref> and, using this model, provided a more detailed discussion of our results. The Discussion section has been rewritten to the model-based accounts of the data and literature. Examples of paragraphs are as follows:</p><p>“In the current study, we sought to investigate functional differences between the PER and POR, the upstream regions of the LEC and MEC, respectively. […] That is, the PER-LEC and POR-MEC networks may process “what should I do in relation to this object?” and “where should I go from here?”, respectively (<xref ref-type="fig" rid="fig4">Figure 4C</xref>).”</p><p>“In the view of traditional theory, spatial and nonspatial information is processed via separate streams in the medial temporal lobe (Knierim et al., 2014). […] The hippocampus, which receives these inputs together, may encode and retrieve various event memories in sequences as an animal navigates through a space to achieve goals.”</p><disp-quote content-type="editor-comment"><p>In that theme, <xref ref-type="fig" rid="fig4">Figure 4</xref> is extremely helpful, but highlights that scene guided learning is never more impacted by a lesion than object guided learning. This might provide support for the idea that scene guided learning is just easier, and that the apparent dissociation between POR and PER merely reflects this.</p></disp-quote><p>We agree with the reviewer that there might be some differences in task difficulty among the behavioral tasks in our current and prior studies. One thing we haven’t observed, however, is a systematic relationship between a certain stimulus type (e.g., scene) and performance level. For example, based on the control’s performance level (ACSF), the easiest task seems to be the SCN-SR task (ACSF: ~95% correct, <xref ref-type="fig" rid="fig2">Figure 2D</xref>). However, in the SCN-NSR task, the control’s performance was approximately 10% lower than that in the SCN-SR task even though the same scene stimuli were used (<xref ref-type="fig" rid="fig2">Figure 2B</xref>). When objects were used as cues in the OBJ-NSR and OBJ-SR tasks, the control’s performance stayed at ~90% correct level, which was a bit higher than in the SCN-SR task, but lower than in the SCN-SR task. Moreover, performance in the SCN-NSR task of the POR-MUS group was significantly impaired, whereas the same group’s performance was not affected in the OBJ-NSR task. This pattern of results was reversed in the PER-MUS group (<xref ref-type="fig" rid="fig4">Figure 4A</xref>). Based on these results, we believe that task difficulty alone may not be able to explain our results.</p><disp-quote content-type="editor-comment"><p>Reviewer #2:</p><p>[…]</p><p>The experiments are very well done. The results are interesting but the way they are summarized in <xref ref-type="fig" rid="fig4">Figure 4</xref> and analyzed in complex two-way and three-way ANOVAs (last section of results) is very complicated and therefore distract the reader from the main message (perfectly understandable from <xref ref-type="fig" rid="fig2">Figure 2</xref> and very nicely summarized in <xref ref-type="fig" rid="fig4s1">Figure 4—figure supplement 1</xref>). That PER and POR inactivations may have different effects on object discrimination in combination with type of response (<xref ref-type="fig" rid="fig3">Figure 3A</xref> vs. 3E) is also interesting and may be worth being reported. However, the introduction of the condition &quot;vOBJ-NSR&quot; here makes interpretation of the whole pattern of result even more complicated. If the authors want to carry a clear take-home message with significant impact, I suggest they simplify their presentation as much as possible.</p></disp-quote><p>We thank the reviewer for the constructive comments. This was one of our concerns as well as we put together our original manuscript. Following the reviewer’s comments, we decided to remove the vOBJ-NSR data from the main text in the revised manuscript (moved to our revised <xref ref-type="fig" rid="fig3s1">Figure 3—figure supplement 1</xref> and <xref ref-type="fig" rid="fig4s1">Figure 4—figure supplement 1</xref>). We think this makes sense also because rats might rarely experience an object using visual modality alone in natural settings, and the data from the vOBJ-NSR task may be better suited for supplementary information.</p><disp-quote content-type="editor-comment"><p>In addition, some of their interpretations of the results are weird. One such example is the section on the results of object-based spatial choice where they say that &quot;A significant difference was found only between ACSF and PER-MUS groups (p &lt; 0.005), and not between ACSF and POR&quot;. Not only the statistics they report in this paragraph seem to show that POR are indeed impaired (and do not show a difference with PER), but just looking at the performance points in <xref ref-type="fig" rid="fig3">Figure 3E</xref> together with the height of the SEM seems to indicate the existence of an impairment as great in POR than in PER. In contrast it is clear that there is no impairment in PER rats for the same object discrimination if a non-spatial response if required (<xref ref-type="fig" rid="fig3">Figure 3A</xref>) while POR rats are clearly impaired. We thus have a dissociation here, though it is not the one that was expected.</p></disp-quote><p>This is a good point. The performance of the POR-MUS group in the OBJ-SR indeed look lower than that of controls. In this study, we used the Bonferroni/Dunn post-hoc test for all post-hoc comparisons. The significance criterion (α) for the Dunn’s post-hoc test was 0.0167, and only the difference between the ACSF and PER-MUS (p = 0.0037), but not between the ACSF and POR-MUS (p = 0.034) met this criterion. Other conservative tests such as the Scheffe and Tukey/Kramer test also resulted in nonsignificant differences between the ACSF and PER-MUS groups. However, if we use more liberal post-hoc tests such as Fisher’s PLSD and Student Newman-Keuls, the difference became significant. In our prior study (Yoo and Lee, 2017), we used the Bonferroni-Dunn test to interpret the results more conservatively and to minimize the risk of making Type I error. Since the current study examined the same phenomena observed in the EC in the PER and POR, we would like to keep the same post-hoc tests in the current study. In the revised manuscript, we added more information in the graph (<xref ref-type="fig" rid="fig3">Figure 3D</xref>) to explicitly show the p-value.</p><p>Nonetheless, although the Dunn’s test called the results insignificant, we agree with the reviewer that this is the case where one can see at least the trend of impairment. In the revised manuscript, we reflected this as we develop a working model to explain the results from the current and previous studies. Specifically, our revised manuscript states that the POR could be involved when scene recognition or spatial navigation (separately or together) is required in a task to include the possibility that POR inactivation actually could lead to significant performance deficits in the OBJ-SR task if sampling size increases. We now incorporate this in our newly presented model (see <xref ref-type="fig" rid="fig4">Figure 4C</xref> and its associated texts in Discussion) and explicitly states this point in the summary part of the discussion as follows:</p><p>“… Unlike in the LEC and MEC (Yoo and Lee, 2017), functional dissociations based on the response type (i.e., spatial vs. nonspatial) were less clear in the upstream areas in the scene-based tasks. Instead, the type of stimulus (i.e., object and scene) appears to critically determine the involvement of these areas in a task (<xref ref-type="fig" rid="fig4">Figure 4</xref>). Specifically, the PER was important in cases where an object stimulus should be recognized, but less so for scenes, regardless of the response type, whereas the POR was involved when either visual scene recognition or spatial navigation was necessary…”</p><p>The almost complete lack of impairment in the POR-MUS condition in the OBJ-NSR task indeed served as one of the clear results that helped us to build a hypothetical working model in our revised manuscript. That is, as stated above if neither visual scene nor spatial navigation is required, the POR doesn’t seem to be interested in the task (e.g., object-based digging or pushing an object). This point has also been added to our Discussion as we introduce our model and explain it in the revised manuscript.</p><disp-quote content-type="editor-comment"><p>Thus overall the paper brings interesting data that complement nicely those of the original paper, but my impression is that the important points are buried in such a way the main message is obscured. What we need here is a model, even sketchy, of how all this circuitry works and a possible interpretation of what makes that the type of response required from the rat is so important in triggering such complex effects in conjunction with the type of stimuli.</p></disp-quote><p>We thank the reviewer for the suggestion. Please see our responses to reviewer #1.</p></body></sub-article></article>