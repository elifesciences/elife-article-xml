<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD with MathML3 v1.3 20210610//EN"  "JATS-archivearticle1-3-mathml3.dtd"><article xmlns:ali="http://www.niso.org/schemas/ali/1.0/" xmlns:xlink="http://www.w3.org/1999/xlink" article-type="research-article" dtd-version="1.3"><front><journal-meta><journal-id journal-id-type="nlm-ta">elife</journal-id><journal-id journal-id-type="publisher-id">eLife</journal-id><journal-title-group><journal-title>eLife</journal-title></journal-title-group><issn publication-format="electronic" pub-type="epub">2050-084X</issn><publisher><publisher-name>eLife Sciences Publications, Ltd</publisher-name></publisher></journal-meta><article-meta><article-id pub-id-type="publisher-id">91129</article-id><article-id pub-id-type="doi">10.7554/eLife.91129</article-id><article-categories><subj-group subj-group-type="display-channel"><subject>Research Advance</subject></subj-group><subj-group subj-group-type="heading"><subject>Neuroscience</subject></subj-group></article-categories><title-group><article-title>Multiple objects evoke fluctuating responses in several regions of the visual pathway</article-title></title-group><contrib-group><contrib contrib-type="author" corresp="yes" id="author-320442"><name><surname>Schmehl</surname><given-names>Meredith N</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">https://orcid.org/0000-0002-0848-309X</contrib-id><email>meredith.schmehl@duke.edu</email><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="aff" rid="aff2">2</xref><xref ref-type="aff" rid="aff3">3</xref><xref ref-type="other" rid="fund1"/><xref ref-type="fn" rid="con1"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" id="author-87938"><name><surname>Caruso</surname><given-names>Valeria C</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">https://orcid.org/0000-0002-3895-1296</contrib-id><xref ref-type="aff" rid="aff4">4</xref><xref ref-type="fn" rid="con2"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" id="author-327892"><name><surname>Chen</surname><given-names>Yunran</given-names></name><xref ref-type="aff" rid="aff5">5</xref><xref ref-type="fn" rid="con3"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" id="author-176526"><name><surname>Jun</surname><given-names>Na Young</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">https://orcid.org/0000-0002-8841-3947</contrib-id><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="aff" rid="aff3">3</xref><xref ref-type="fn" rid="con4"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" id="author-327893"><name><surname>Willett</surname><given-names>Shawn M</given-names></name><xref ref-type="aff" rid="aff6">6</xref><xref ref-type="fn" rid="con5"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" id="author-327894"><name><surname>Mohl</surname><given-names>Jeff T</given-names></name><xref ref-type="aff" rid="aff7">7</xref><xref ref-type="fn" rid="con6"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" id="author-327895"><name><surname>Ruff</surname><given-names>Douglas A</given-names></name><xref ref-type="aff" rid="aff8">8</xref><xref ref-type="fn" rid="con7"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" id="author-327896"><name><surname>Cohen</surname><given-names>Marlene</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">https://orcid.org/0000-0001-8583-4300</contrib-id><xref ref-type="aff" rid="aff8">8</xref><xref ref-type="other" rid="fund2"/><xref ref-type="other" rid="fund3"/><xref ref-type="other" rid="fund4"/><xref ref-type="fn" rid="con8"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" id="author-327897"><name><surname>Ebihara</surname><given-names>Akinori F</given-names></name><xref ref-type="aff" rid="aff9">9</xref><xref ref-type="fn" rid="con9"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" id="author-118400"><name><surname>Freiwald</surname><given-names>Winrich A</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">https://orcid.org/0000-0001-8456-5030</contrib-id><xref ref-type="aff" rid="aff9">9</xref><xref ref-type="fn" rid="con10"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" id="author-327899"><name><surname>Tokdar</surname><given-names>Surya T</given-names></name><xref ref-type="aff" rid="aff3">3</xref><xref ref-type="aff" rid="aff5">5</xref><xref ref-type="other" rid="fund5"/><xref ref-type="other" rid="fund6"/><xref ref-type="fn" rid="con11"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" id="author-61015"><name><surname>Groh</surname><given-names>Jennifer M</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">https://orcid.org/0000-0002-6435-3935</contrib-id><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="aff" rid="aff2">2</xref><xref ref-type="aff" rid="aff3">3</xref><xref ref-type="aff" rid="aff10">10</xref><xref ref-type="aff" rid="aff11">11</xref><xref ref-type="aff" rid="aff12">12</xref><xref ref-type="other" rid="fund5"/><xref ref-type="other" rid="fund6"/><xref ref-type="fn" rid="con12"/><xref ref-type="fn" rid="conf2"/></contrib><aff id="aff1"><label>1</label><institution-wrap><institution-id institution-id-type="ror">https://ror.org/00py81415</institution-id><institution>Department of Neurobiology, Duke University</institution></institution-wrap><addr-line><named-content content-type="city">Durham</named-content></addr-line><country>United States</country></aff><aff id="aff2"><label>2</label><institution-wrap><institution-id institution-id-type="ror">https://ror.org/00py81415</institution-id><institution>Center for Cognitive Neuroscience, Duke University</institution></institution-wrap><addr-line><named-content content-type="city">Durham</named-content></addr-line><country>United States</country></aff><aff id="aff3"><label>3</label><institution-wrap><institution-id institution-id-type="ror">https://ror.org/00py81415</institution-id><institution>Duke Institute for Brain Sciences, Duke University</institution></institution-wrap><addr-line><named-content content-type="city">Durham</named-content></addr-line><country>United States</country></aff><aff id="aff4"><label>4</label><institution-wrap><institution-id institution-id-type="ror">https://ror.org/00jmfr291</institution-id><institution>Department of Psychiatry, University of Michigan</institution></institution-wrap><addr-line><named-content content-type="city">Ann Arbor</named-content></addr-line><country>United States</country></aff><aff id="aff5"><label>5</label><institution-wrap><institution-id institution-id-type="ror">https://ror.org/00py81415</institution-id><institution>Department of Statistical Science, Duke University</institution></institution-wrap><addr-line><named-content content-type="city">Durham</named-content></addr-line><country>United States</country></aff><aff id="aff6"><label>6</label><institution-wrap><institution-id institution-id-type="ror">https://ror.org/01an3r305</institution-id><institution>Department of Ophthalmology, University of Pittsburgh</institution></institution-wrap><addr-line><named-content content-type="city">Pittsburgh</named-content></addr-line><country>United States</country></aff><aff id="aff7"><label>7</label><institution-wrap><institution-id institution-id-type="ror">https://ror.org/011znd796</institution-id><institution>American Medical Group Association</institution></institution-wrap><addr-line><named-content content-type="city">Alexandria</named-content></addr-line><country>United States</country></aff><aff id="aff8"><label>8</label><institution-wrap><institution-id institution-id-type="ror">https://ror.org/024mw5h28</institution-id><institution>Department of Neurobiology, University of Chicago</institution></institution-wrap><addr-line><named-content content-type="city">Chicago</named-content></addr-line><country>United States</country></aff><aff id="aff9"><label>9</label><institution-wrap><institution-id institution-id-type="ror">https://ror.org/0420db125</institution-id><institution>The Rockefeller University</institution></institution-wrap><addr-line><named-content content-type="city">New York</named-content></addr-line><country>United States</country></aff><aff id="aff10"><label>10</label><institution-wrap><institution-id institution-id-type="ror">https://ror.org/00py81415</institution-id><institution>Department of Psychology &amp; Neuroscience, Duke University</institution></institution-wrap><addr-line><named-content content-type="city">Durham</named-content></addr-line><country>United States</country></aff><aff id="aff11"><label>11</label><institution-wrap><institution-id institution-id-type="ror">https://ror.org/00py81415</institution-id><institution>Department of Computer Science, Duke University</institution></institution-wrap><addr-line><named-content content-type="city">Durham</named-content></addr-line><country>United States</country></aff><aff id="aff12"><label>12</label><institution-wrap><institution-id institution-id-type="ror">https://ror.org/00py81415</institution-id><institution>Department of Biomedical Engineering, Duke University</institution></institution-wrap><addr-line><named-content content-type="city">Durham</named-content></addr-line><country>United States</country></aff></contrib-group><contrib-group content-type="section"><contrib contrib-type="editor"><name><surname>Sharpee</surname><given-names>Tatyana O</given-names></name><role>Reviewing Editor</role><aff><institution-wrap><institution-id institution-id-type="ror">https://ror.org/03xez1567</institution-id><institution>Salk Institute for Biological Studies</institution></institution-wrap><country>United States</country></aff></contrib><contrib contrib-type="senior_editor"><name><surname>Gold</surname><given-names>Joshua I</given-names></name><role>Senior Editor</role><aff><institution-wrap><institution-id institution-id-type="ror">https://ror.org/00b30xv10</institution-id><institution>University of Pennsylvania</institution></institution-wrap><country>United States</country></aff></contrib></contrib-group><pub-date publication-format="electronic" date-type="publication"><day>15</day><month>03</month><year>2024</year></pub-date><volume>13</volume><elocation-id>e91129</elocation-id><history><date date-type="received" iso-8601-date="2023-08-01"><day>01</day><month>08</month><year>2023</year></date><date date-type="accepted" iso-8601-date="2024-02-15"><day>15</day><month>02</month><year>2024</year></date></history><pub-history><event><event-desc>This manuscript was published as a preprint at bioRxiv.</event-desc><date date-type="preprint" iso-8601-date="2023-07-19"><day>19</day><month>07</month><year>2023</year></date><self-uri content-type="preprint" xlink:href="https://doi.org/10.1101/2023.07.19.549668"/></event></pub-history><permissions><copyright-statement>© 2024, Schmehl et al</copyright-statement><copyright-year>2024</copyright-year><copyright-holder>Schmehl et al</copyright-holder><ali:free_to_read/><license xlink:href="http://creativecommons.org/licenses/by/4.0/"><ali:license_ref>http://creativecommons.org/licenses/by/4.0/</ali:license_ref><license-p>This article is distributed under the terms of the <ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/licenses/by/4.0/">Creative Commons Attribution License</ext-link>, which permits unrestricted use and redistribution provided that the original author and source are credited.</license-p></license></permissions><self-uri content-type="pdf" xlink:href="elife-91129-v1.pdf"/><self-uri content-type="figures-pdf" xlink:href="elife-91129-figures-v1.pdf"/><related-article related-article-type="article-reference" ext-link-type="doi" xlink:href="10.7554/eLife.76452" id="ra1"/><abstract><p>How neural representations preserve information about multiple stimuli is mysterious. Because tuning of individual neurons is coarse (e.g., visual receptive field diameters can exceed perceptual resolution), the populations of neurons potentially responsive to each individual stimulus can overlap, raising the question of how information about each item might be segregated and preserved in the population. We recently reported evidence for a potential solution to this problem: when two stimuli were present, some neurons in the macaque visual cortical areas V1 and V4 exhibited fluctuating firing patterns, as if they responded to only one individual stimulus at a time (Jun et al., 2022). However, whether such an information encoding strategy is ubiquitous in the visual pathway and thus could constitute a general phenomenon remains unknown. Here, we provide new evidence that such fluctuating activity is also evoked by multiple stimuli in visual areas responsible for processing visual motion (middle temporal visual area, MT), and faces (middle fundus and anterolateral face patches in inferotemporal cortex – areas MF and AL), thus extending the scope of circumstances in which fluctuating activity is observed. Furthermore, consistent with our previous results in the early visual area V1, MT exhibits fluctuations between the representations of two stimuli when these form distinguishable objects but not when they fuse into one perceived object, suggesting that fluctuating activity patterns may underlie visual object formation. Taken together, these findings point toward an updated model of how the brain preserves sensory information about multiple stimuli for subsequent processing and behavioral action.</p></abstract><kwd-group kwd-group-type="author-keywords"><kwd>neural representation</kwd><kwd>neural code</kwd><kwd>multiplexing</kwd><kwd>object vision</kwd><kwd>figure ground segregation</kwd><kwd>visual system</kwd></kwd-group><kwd-group kwd-group-type="research-organism"><title>Research organism</title><kwd>Rhesus macaque</kwd></kwd-group><funding-group><award-group id="fund1"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/100000055</institution-id><institution>National Institute on Deafness and Other Communication Disorders</institution></institution-wrap></funding-source><award-id>F31DC020361</award-id><principal-award-recipient><name><surname>Schmehl</surname><given-names>Meredith N</given-names></name></principal-award-recipient></award-group><award-group id="fund2"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/100000053</institution-id><institution>National Eye Institute</institution></institution-wrap></funding-source><award-id>R00EY020844</award-id><principal-award-recipient><name><surname>Cohen</surname><given-names>Marlene</given-names></name></principal-award-recipient></award-group><award-group id="fund3"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/100000053</institution-id><institution>National Eye Institute</institution></institution-wrap></funding-source><award-id>R01EY022930</award-id><principal-award-recipient><name><surname>Cohen</surname><given-names>Marlene</given-names></name></principal-award-recipient></award-group><award-group id="fund4"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/100000053</institution-id><institution>National Eye Institute</institution></institution-wrap></funding-source><award-id>P30EY008098</award-id><principal-award-recipient><name><surname>Cohen</surname><given-names>Marlene</given-names></name></principal-award-recipient></award-group><award-group id="fund5"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/100000055</institution-id><institution>National Institute on Deafness and Other Communication Disorders</institution></institution-wrap></funding-source><award-id>R01DC013906</award-id><principal-award-recipient><name><surname>Tokdar</surname><given-names>Surya T</given-names></name><name><surname>Groh</surname><given-names>Jennifer M</given-names></name></principal-award-recipient></award-group><award-group id="fund6"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/100000055</institution-id><institution>National Institute on Deafness and Other Communication Disorders</institution></institution-wrap></funding-source><award-id>R01DC016363</award-id><principal-award-recipient><name><surname>Tokdar</surname><given-names>Surya T</given-names></name><name><surname>Groh</surname><given-names>Jennifer M</given-names></name></principal-award-recipient></award-group><funding-statement>The funders had no role in study design, data collection, and interpretation, or the decision to submit the work for publication.</funding-statement></funding-group><custom-meta-group><custom-meta specific-use="meta-only"><meta-name>Author impact statement</meta-name><meta-value>Neural fluctuations in multiple areas along the visual cortical hierarchy could allow the brain to represent distinct co-occurring visual stimuli.</meta-value></custom-meta></custom-meta-group></article-meta></front><body><sec id="s1" sec-type="intro"><title>Introduction</title><p>Neurons are broadly tuned. For example, even in primary visual cortex, neurons typically have receptive fields that are several times larger than spatial acuity at the perceptual level (<xref ref-type="bibr" rid="bib5">Dow et al., 1981</xref>; <xref ref-type="bibr" rid="bib30">Smith et al., 2001</xref>; <xref ref-type="bibr" rid="bib27">Motter, 2009</xref>; <xref ref-type="bibr" rid="bib12">Freeman and Simoncelli, 2011</xref>; <xref ref-type="bibr" rid="bib15">Grill-Spector et al., 2017</xref>; <xref ref-type="bibr" rid="bib20">Keliris et al., 2019</xref>). Due to this broad tuning, a given neuron may be capable of responding to more than one sensory object in a scene. When multiple stimuli are present, how does the brain preserve information about each item?</p><p>We recently reported a potential solution to this problem: When two stimuli co-occur, individual neurons may fluctuate between responding to only one or the other stimulus at a time, allowing dynamic populations of neurons to encode different stimuli at the same time. In our earlier work, we developed statistical approaches to evaluate whether the fluctuating activity patterns predicted from such a scheme exist (<xref ref-type="bibr" rid="bib4">Caruso et al., 2018</xref>; <xref ref-type="bibr" rid="bib26">Mohl et al., 2020</xref>; <xref ref-type="bibr" rid="bib14">Glynn et al., 2021</xref>), and we reported evidence for this phenomenon in both auditory (<xref ref-type="bibr" rid="bib4">Caruso et al., 2018</xref>) and visual (<xref ref-type="bibr" rid="bib4">Caruso et al., 2018</xref>; <xref ref-type="bibr" rid="bib19">Jun et al., 2022</xref>) areas. In particular, we found evidence for fluctuating activity in the inferior colliculus (<xref ref-type="bibr" rid="bib4">Caruso et al., 2018</xref>), primary visual cortex (V1), area V4 (<xref ref-type="bibr" rid="bib19">Jun et al., 2022</xref>), and the middle fundus (MF) face patch of inferotemporal (IT) cortex (<xref ref-type="bibr" rid="bib4">Caruso et al., 2018</xref>) when two distinguishable stimuli were presented. Relatedly, oscillatory patterns of activity triggered by the appearance of multiple stimuli have also been observed in V4 using other paradigms and analysis methods (<xref ref-type="bibr" rid="bib21">Kienitz et al., 2018</xref>; <xref ref-type="bibr" rid="bib22">Kienitz et al., 2022</xref>).</p><p>In short, activity fluctuation has now been identified in a wide array of brain areas, from early auditory regions to early, middle, and late visual cortical regions. This breadth of brain areas suggests that fluctuating activity may reflect a general mechanism of neural representation supporting the encoding of multiple stimuli. However, the relevant factors that govern the occurrence of such fluctuating activity remain poorly understood. Here, we explore how fluctuating activity may depend on the nature of the stimuli involved. In particular, we investigate the roles of (1) neural selectivity for stimulus type and (2) the discriminability of stimuli into one vs. more than one object. In so doing, we expand the scope of the visual brain regions studied to include the middle temporal area (MT) and multiple areas of the IT face patch system (the MF, and anterolateral, AL, face patches).</p><p>We report that neuronal activity in all three areas fluctuated across trials between responses that appeared to be drawn from the response distributions corresponding to the respective individual stimuli. In MF and AL, fluctuating neuronal activity was present when two faces were presented (i.e., stimuli for which the patches are specialized) as well as when a face and a non-face object were presented, but in MF the fluctuations were more common when two faces were presented (i.e., two stimuli of the category for which the neurons appear specialized) than when a face and a non-face object (different stimulus categories) were presented. This suggests that multiple faces compete more severely for representation in this face-specific system than do non-face objects. In MT, such fluctuating activity was present only when the two visual stimuli were distinct (adjacent gratings or dot patches), and not when they were superimposed and fused to form single objects (plaids), thus implicating fluctuating activity as playing a role in perceptual segregation of distinct visual elements into distinct objects, supporting previous findings in V1 (<xref ref-type="bibr" rid="bib19">Jun et al., 2022</xref>).</p><p>Together, these findings suggest that fluctuating activity patterns are a widespread phenomenon connected to the computations underlying object formation and identification. Object separation appears generally necessary for fluctuating activity to occur, and specialization for certain types of stimuli can also affect the prevalence of fluctuations across the neural population.</p></sec><sec id="s2" sec-type="materials|methods"><title>Materials and methods</title><sec id="s2-1"><title>Introduction to datasets</title><p>We analyzed multiple datasets from two visual cortical regions (MT and IT cortex). All datasets were collected in awake, behaving macaques (MT: <italic>Macaca mulatta;</italic> IT: <italic>Macaca mulatta</italic> and <italic>Macaca fascicularis</italic>). The data were originally collected at the University of Pittsburgh (<xref ref-type="bibr" rid="bib29">Ruff and Cohen, 2016b</xref>; <xref ref-type="bibr" rid="bib28">Ruff et al., 2016a</xref>), Rockefeller University (<xref ref-type="bibr" rid="bib6">Ebihara, 2015</xref>), and the German Primate Center in Goettingen (<xref ref-type="bibr" rid="bib23">Li et al., 2016</xref>). All procedures were conducted in accordance with applicable US, German, and European guidelines or regulations and were approved by the relevant compliance committees at the relevant institutions (US guidelines: National Institutes of Health (NIH) Pub. No. 86-23, Revised 1985; Pittsburgh MT grating datasets: Institutional Animal Care and Use Committees of the University of Pittsburgh and Carnegie Mellon University (Protocol #: 20067560, PHS Assurance Number: D16-00118); IT datasets: The Rockefeller University Institutional Animal Care and Use Committee (Protocol #: 21,104 H USDA, PHS Assurance Number: A3081-01); Goettingen MT dot patch dataset: [Niedersächsisches Landesamtfür Verbraucherschutzund Lebensmittelsicherheit (LAVES)] permit numbers 33.42502/08-07.02 and 33.14.42502-04-064/07). All surgical procedures were conducted aseptically and with suitable anesthetics and analgesics.</p><p>Our goal was to assess fluctuating neural activity in multiple visual areas and in response to multiple stimuli (<xref ref-type="table" rid="table1">Table 1</xref>). In all datasets, fixation was controlled while the stimuli were presented (0.5–1.2 degree fixation window radius, depending on the dataset). In some datasets, monkeys performed a behavioral task in which attention was directed away from the stimuli, such as to the fixation position itself or to an additional stimulus in the ipsilateral hemifield. In the fixation-only tasks, it should be noted that the absence of experimental control over attention could have led to the monkeys covertly attending the receptive field stimuli from time to time.</p><table-wrap id="table1" position="float"><label>Table 1.</label><caption><title>Comparison of datasets.</title></caption><table frame="hsides" rules="groups"><thead><tr><th align="left" valign="bottom">Dataset name</th><th align="left" valign="bottom">Citation</th><th align="left" valign="bottom">Brain area</th><th align="left" valign="bottom">Stimuli</th><th align="left" valign="bottom">Stimulus locations</th><th align="left" valign="bottom">Task</th><th align="left" valign="bottom">Recording method</th></tr></thead><tbody><tr><td align="left" valign="bottom">MT adjacent gratings</td><td align="left" valign="bottom"><xref ref-type="bibr" rid="bib29">Ruff and Cohen, 2016b</xref></td><td align="left" valign="bottom">MT</td><td align="left" valign="bottom">Drifting images of two gratings</td><td align="left" valign="bottom">Adjacent (3 degrees eccentric)</td><td align="left" valign="bottom">Detect orientation change of a different, ipsilateral stimulus</td><td align="left" valign="bottom">Array, single and multi-unit</td></tr><tr><td align="left" valign="bottom">MT dot patches</td><td align="left" valign="bottom"><xref ref-type="bibr" rid="bib23">Li et al., 2016</xref></td><td align="left" valign="bottom">MT</td><td align="left" valign="bottom">Moving dots</td><td align="left" valign="bottom">Adjacent</td><td align="left" valign="bottom">Detect change in fixation stimulus</td><td align="left" valign="bottom">Single electrode, single unit</td></tr><tr><td align="left" valign="bottom">MT plaid</td><td align="left" valign="bottom"><xref ref-type="bibr" rid="bib28">Ruff et al., 2016a</xref></td><td align="left" valign="bottom">MT</td><td align="left" valign="bottom">Drifting images of gratings and plaids</td><td align="left" valign="bottom">Same location</td><td align="left" valign="bottom">Passive fixation</td><td align="left" valign="bottom">Array, single and multi-unit</td></tr><tr><td align="left" valign="bottom">IT face patch MF</td><td align="left" valign="bottom"><xref ref-type="bibr" rid="bib6">Ebihara, 2015</xref>; <xref ref-type="bibr" rid="bib4">Caruso et al., 2018</xref></td><td align="left" valign="bottom">MF</td><td align="left" valign="bottom">Images of faces and objects</td><td align="left" valign="bottom">Adjacent</td><td align="left" valign="bottom">Passive fixation</td><td align="left" valign="bottom">Single electrode, single unit</td></tr><tr><td align="left" valign="bottom">IT face patch AL</td><td align="left" valign="bottom"><xref ref-type="bibr" rid="bib6">Ebihara, 2015</xref></td><td align="left" valign="bottom">AL</td><td align="left" valign="bottom">Images of faces and objects</td><td align="left" valign="bottom">Adjacent</td><td align="left" valign="bottom">Passive fixation</td><td align="left" valign="bottom">Single electrode, single unit</td></tr></tbody></table></table-wrap><p>For area MT, we used three datasets. The first dataset included single- and multi-unit responses to drifting grating stimuli positioned adjacent to one another (<xref ref-type="fig" rid="fig1">Figure 1a.1 and 2</xref>; <xref ref-type="bibr" rid="bib29">Ruff and Cohen, 2016b</xref>). The experiment involved simultaneous recordings from V1, V4, and MT. As we have previously identified fluctuating response patterns in V1 and V4 (<xref ref-type="bibr" rid="bib19">Jun et al., 2022</xref>), this MT dataset provides an opportunity to compare the presence of fluctuating activity across visual areas under the same experimental conditions (and some of the same recording sessions) as in our previous work. However, this dataset was comparatively small (as detailed further below), making additional data desirable.</p><fig-group><fig id="fig1" position="float"><label>Figure 1.</label><caption><title>Description of datasets.</title><p>(<bold>a</bold>) Middle temporal area (MT) gratings datasets from <xref ref-type="bibr" rid="bib29">Ruff and Cohen, 2016b</xref> and <xref ref-type="bibr" rid="bib28">Ruff et al., 2016a</xref>. (<bold>a.1</bold>). For the adjacent gratings, the two stimuli were placed side by side and roughly within the MT neuron’s receptive field. The superimposed gratings were larger and each was placed at the same position, also within the MT neuron’s receptive field. (<bold>a.2</bold>) Monkeys performed an attention task during the presentation of the adjacent gratings; only trials in which attention was successfully directed to the stimulus in the ipsilateral hemifield were included in this study. (<bold>a.3</bold>) Monkeys performed a fixation task during presentation of the superimposed gratings. (<bold>b</bold>) MT random dot patch dataset from <xref ref-type="bibr" rid="bib23">Li et al., 2016</xref>. Patches of moving dots were presented within apertures placed within the receptive field of an MT neuron. Attention was directed to the fixation target for the trials included in the present study. (<bold>c</bold>) Face patch stimulus conditions (<xref ref-type="bibr" rid="bib6">Ebihara, 2015</xref>). (<bold>c.1</bold>) Monkeys performed a fixation task and stimuli were presented either at the center of the receptive field or from one of eight locations surrounding it. (<bold>c.2</bold>) ‘Preferred’ faces were faces that evoked a strong response, and were presented in the center of the receptive field. Non-preferred faces or non-face objects were presented at one of the other locations. Combinations of stimuli involved the preferred face in the center and one of the non-preferred stimuli at one of the adjacent locations. (<bold>c.3</bold>) Additional examples of stimuli used in the face patch datasets.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-91129-fig1-v1.tif"/></fig><fig id="fig1s1" position="float" specific-use="child-fig"><label>Figure 1—figure supplement 1.</label><caption><title>Properties of the datasets and application of exclusion criteria.</title><p>(<bold>a</bold>) Average A, B, and AB trial counts for each included triplet (after Poisson, trial count, and response separation screening). (<bold>b</bold>) The distribution of variance-to-mean ratios, or Fano factors, on A- and B-alone trials across the different datasets.Results shown involve the average A and B Fano factors for a given triplet (computed after the screening for minimum trial count and A and B response separation). (<bold>c</bold>) A and B response separations, computed as an index of the difference between A and B responses as a fraction of their sum, for included triplets (after Poisson, trial count, and response separation screening). Note that the middle temporal area (MT) plaid dataset differs from the other 4 datasets in that many of the included triplets have much smaller A and B response separations than those that are included for other datasets. This is likely due to the larger numbers of trials providing greater confidence that the A and B responses did indeed differ at smaller difference levels. (<bold>d</bold>) Average ‘winning probability’ for the ‘mixture’ model (see Materials and methods: Data analysis) as a function of the response separation. Average ‘mixture’ winning probability was higher for all four datasets involving distinguishable stimuli (MT adjacent gratings and dot patches, the face patch datasets) than for the MT plaid dataset, across all levels of A vs. B response separation.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-91129-fig1-figsupp1-v1.tif"/></fig></fig-group><p>Accordingly, we included a second dataset from a previously published study involving single- and multi-unit responses to adjacent random dot stimuli (<xref ref-type="fig" rid="fig1">Figure 1b</xref>; <xref ref-type="bibr" rid="bib23">Li et al., 2016</xref>). Both of these datasets were recorded while monkeys performed a behavioral task in which attention was directed away from the stimuli in the MT receptive field: toward the opposite hemifield (<xref ref-type="bibr" rid="bib29">Ruff and Cohen, 2016b</xref>) or to the fixation point (<xref ref-type="bibr" rid="bib23">Li et al., 2016</xref>). Fixation was maintained during stimulus presentation to within 0.5 degrees of the fixation point for the Ruff and Cohen dataset and 1.2 degrees for the Li et al. dataset.</p><p>In both of these MT datasets, the stimuli can be considered as distinct and distinguishable objects from each other, regardless of whether they are gratings or patches of moving dots, because they are presented at separate locations. Our third MT dataset provides a comparison to these first two. In this dataset, individual gratings were presented at the same location in space, such that when they were presented together, they fused to form a plaid stimulus (<xref ref-type="fig" rid="fig1">Figure 1a.1 and 3</xref>). This dataset was originally published in <xref ref-type="bibr" rid="bib28">Ruff et al., 2016a</xref> and involved simultaneous V1 and V4 recordings previously analyzed for fluctuating activity in <xref ref-type="bibr" rid="bib19">Jun et al., 2022</xref>. In this dataset, monkeys performed a simple fixation task.</p><p>The specific stimulus details for these MT datasets are as follows. In the adjacent gratings dataset, the grating sizes were selected to lie within the MT receptive field under study and did not exceed 1 degree in diameter. The gratings used in the superimposed dataset were larger, ranging between 7 and 13 degrees in diameter, and covered the MT receptive field. The sizes of the random dot patches are not available, but they were depicted at adjacent positions within the MT receptive field (<xref ref-type="bibr" rid="bib23">Li et al., 2016</xref>).</p><p>For the IT cortex, we included datasets involving single-unit recordings in two areas of the face patch system, areas MF and AL, during a fixation task (<xref ref-type="fig" rid="fig1">Figure 1c</xref>; fixation maintained within 1 degree) (<xref ref-type="bibr" rid="bib6">Ebihara, 2015</xref>). We have previously reported fluctuating activity in face patch MF (<xref ref-type="bibr" rid="bib4">Caruso et al., 2018</xref>), but here we have re-analyzed the MF dataset (see ‘Analysis: response periods and inclusion criteria’) to provide detailed results for different types of stimuli (face–face vs. face–object pairs), allowing a comparison of results in the two face patches (MF and AL) in the same experimental conditions.</p><p>For both MF and AL, we assessed neural responses to image pairs drawn from three visual stimuli selected from a pool of faces and objects: a ‘preferred face’ (strong neural response), a ‘non-preferred face’ (little to no neural response), and a ‘non-preferred object’ (little to no neural response). These stimuli were randomly presented either alone or in pairs, with each pair including the preferred face, positioned at the center of the neuron’s receptive field, and one of the non-preferred stimuli, presented adjacent to the preferred face at one of eight equidistant locations. Stimuli were 4 × 4 degrees in size.</p><p>As in <xref ref-type="bibr" rid="bib4">Caruso et al., 2018</xref>, we did not incorporate the exact location of the non-preferred face/object into the present analysis, but any excessive heterogeneity in the responses of the non-preferred stimuli due to location would likely result in exclusion of the condition from further analysis (see ‘Analysis: response periods and inclusion criteria’).</p></sec><sec id="s2-2"><title>Analysis: response periods and inclusion criteria</title><sec id="s2-2-1"><title>Response periods</title><p>For each dataset, we compared neural responses (see ‘Data analysis’) using a spike counting window of 200 ms, the minimum stimulus presentation window across all datasets. This window was shifted by the approximate response latency of the brain region, specifically 30 ms for MT and 50 ms for IT, that is, spikes were counted in a window from 30 to 230 ms after stimulus onset for MT or 50–250 ms for IT. For the IT datasets, the stimuli were presented for 400 ms, and results were similar when we analyzed the data in a 50–450 ms time window.</p></sec><sec id="s2-2-2"><title>Trial inclusion criteria</title><p>Only correctly performed trials were analyzed. For fixation tasks, this meant that the monkey maintained fixation for the required interval (MT plaid dataset, IT datasets). For attention tasks, this meant that the monkey correctly identified the change in the attended stimulus, which was outside the receptive field of the neurons under study (MT gratings dataset: the motion change in a grating presented in the ipsilateral field; MT dot patch dataset: the change in color in the fixation target). In addition, trials were excluded from the MT gratings dataset if any microsaccades were identified during the stimulus presentation period. Microsaccades were defined as periods of time in which eye speed exceeded the mean eye speed in the fixation epoch by more than 6 standard deviations, following standards established by <xref ref-type="bibr" rid="bib7">Engbert and Kliegl, 2003</xref> and deployed in our previous studies involving these same experiments (<xref ref-type="bibr" rid="bib28">Ruff et al., 2016a</xref>; <xref ref-type="bibr" rid="bib29">Ruff and Cohen, 2016b</xref>; <xref ref-type="bibr" rid="bib19">Jun et al., 2022</xref>).</p></sec></sec><sec id="s2-3"><title>‘Triplet’ definition and inclusion criteria</title><p>Our analysis of fluctuating activity patterns relies on comparing the activity evoked on trials in which two stimuli, A and B, are presented simultaneously (AB) to trials in which only the A or only the B stimulus was presented. We refer to the corresponding A-alone, B-alone, and combined AB conditions as ‘triplets’.</p><p>To be included for analysis, triplets were required to meet several criteria. First, the minimum number of included trials for each of the A, B, and AB components was set at five trials for each, in keeping with our prior work and assessments of the sensitivity of the analysis to the number of trials involved (<xref ref-type="bibr" rid="bib4">Caruso et al., 2018</xref>; <xref ref-type="bibr" rid="bib26">Mohl et al., 2020</xref>; <xref ref-type="bibr" rid="bib19">Jun et al., 2022</xref>). The average numbers of trials of the included triplets across datasets are illustrated in <xref ref-type="fig" rid="fig1s1">Figure 1—figure supplement 1</xref>. The two MT datasets involving adjacent stimuli had the lowest average trial counts (average of the A, B, and AB trial counts was ~18 trials for the gratings and ~6 trials for the dot patches), whereas the MT ‘plaid’ dataset had the most (average ~37 trials; all values computed after imposition of the full set of exclusion criteria, including those described below).</p><p>Second, spike count distributions for the A- and B-alone trials in a triplet were required to be sufficiently well described by a Poisson distribution (with a variance roughly equal to the mean). The spike count distributions for A and B trials for triplets in all five datasets exhibited variance-to-mean ratios (Fano factors) with a mode of about 1, but there was some spread around that value (<xref ref-type="fig" rid="fig1s1">Figure 1—figure supplement 1B</xref>). Accordingly, we discarded triplets for which the average variance-to-mean ratio in the A and B conditions was greater than 3. This value was chosen to exclude the worst outliers while preserving adequate data across all datasets to allow for appropriate comparisons. Screening with a more stringent criterion (variance-to-mean ratio &lt;2) reduced the overall quantity of data but did not change the key results we report here (<xref ref-type="fig" rid="fig4s1">Figure 4—figure supplement 1</xref>). Notably, screening with the variance-to-mean ratio is a deviation from our previous approach involving an approximate chi-square goodness of fit test with Monte Carlo p-value calculation (<xref ref-type="bibr" rid="bib4">Caruso et al., 2018</xref>; <xref ref-type="bibr" rid="bib19">Jun et al., 2022</xref>). The former approach had the undesired effect of being more likely to exclude conditions with larger amounts of data, whereas the present method is neutral to dataset size.</p><p>Finally, spike count distributions for the individual A and B stimuli in a triplet were required to be sufficiently separable from one another. This is necessary so that it is possible to ascertain with some confidence how the AB spike count distributions compare to each of the corresponding single-stimulus A and B distributions. We set the inclusion criterion as a 95% likelihood that the A and B spike counts were drawn from different Poisson distributions (specifically, the logarithm of the intrinsic Bayes factor was required to be greater than 3, given an a priori 50–50 chance that the two distribution means are the same vs. different). The greater numbers of trials in some datasets than in others allowed for inclusion of triplets at smaller differences in the A vs. B response distributions (<xref ref-type="fig" rid="fig1s1">Figure 1—figure supplement 1</xref>), but this did not appear to impact the overall conclusions (see <xref ref-type="fig" rid="fig1s1">Figure 1—figure supplement 1</xref> and associated legend).</p></sec><sec id="s2-4"><title>Data analysis</title><p>A full description of our statistical method has been published previously (<xref ref-type="bibr" rid="bib4">Caruso et al., 2018</xref>; <xref ref-type="bibr" rid="bib26">Mohl et al., 2020</xref>; <xref ref-type="bibr" rid="bib19">Jun et al., 2022</xref>). Our method centers on modeling spike counts based on Poisson distributions, a common technique for handling non-negative count data in neuroscience and other fields.</p><p>Briefly, we compare the distribution of spike counts in response to a stimulus pair (AB) to the distributions of spike counts in response to the component stimuli presented individually (A and B). We consider four possibilities for the relationship between the AB response and the individual A and B responses (<xref ref-type="fig" rid="fig2">Figure 2</xref>). The first three attempt to fit the AB responses with a single Poisson distribution, as follows:</p><sec id="s2-4-1"><title>Outside</title><p>The mean of the distribution of AB responses might be higher than the maximum or lower than the minimum of A or B. This possibility includes either summation of the mean A and B responses or strong suppression of responses to one stimulus by the presence of the other.</p></sec><sec id="s2-4-2"><title>Single</title><p>The mean of the distribution of AB responses might match the mean response to either A or B. This is akin to winner-take-all, with the same winner on every trial.</p></sec><sec id="s2-4-3"><title>Intermediate</title><p>The AB responses might be well fit by a single Poisson distribution with a mean between A and B, as if the neuron performed an averaging operation on its inputs.</p><fig id="fig2" position="float"><label>Figure 2.</label><caption><title>Statistical comparisons to be made across datasets.</title><p>We assign each trial into a ‘triplet’ consisting of trials in which stimulus A (red), stimulus B (blue), or both stimulus A and B (AB, black) were presented. (<bold>a</bold>) Within each triplet, spike count distributions are compared to determine how the AB distribution relates to the A and B distributions. (<bold>b</bold>) The AB spike count distribution may be: a mixture of the A and B distributions, suggesting fluctuations between the responses to the two stimuli; an intermediate rate between the A and B distributions, suggesting averaging (or fluctuations on a faster time scale than the analysis period); a rate that matches either the single A or B distribution, suggesting a winner-take-all strategy; or a rate outside the range bounded by the A and B distributions, suggesting addition or subtraction of the responses. Spike counts are assumed to be drawn from Poisson distributions, with a weighting parameter alpha defining the relative contribution of the individual A and B distributions in ‘mixtures’ and ‘intermediates’.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-91129-fig2-v1.tif"/></fig><p>These possibilities are in contrast to the final possibility of interest:</p></sec><sec id="s2-4-4"><title>Mixture</title><p>The AB responses match A on some trials and match B on other trials, creating a mixture of the two A and B distributions across trials (fluctuations or ‘multiplexing’ from trial to trial). We model this possibility as a bimodal mixture of the A and B Poisson distributions as assessed on those single-stimulus trials.</p><p>We evaluated these four hypotheses by computing their posterior probabilities based on intrinsic Bayes factors (<xref ref-type="bibr" rid="bib1">Berger and Pericchi, 1996</xref>; <xref ref-type="bibr" rid="bib4">Caruso et al., 2018</xref>). We used equal priors (25%) for each of the four possibilities. For the purposes of this work, we defined ‘fluctuating responses’ as responses that were classified as ‘mixture’ with a posterior probability greater than 0.67 (i.e., mixture is at least twice as likely as the other three categories combined).</p><p>As noted previously (<xref ref-type="bibr" rid="bib4">Caruso et al., 2018</xref>; <xref ref-type="bibr" rid="bib19">Jun et al., 2022</xref>), these category boundaries may not always perfectly capture the presence of fluctuating activity. For example, if a neuron sometimes switches between responding to A and B stimuli in the middle of a stimulus presentation, it will tend to be classified in the ‘intermediate’ bucket. Similarly, if a neuron responds to A on 90% of the trials, it is likely to be classified as ‘single’ even if it responds to B on the remaining 10%.</p></sec></sec></sec><sec id="s3" sec-type="results"><title>Results</title><sec id="s3-1"><title>Spiking activity fluctuates in MT when two stimuli are distinct, but not when they fuse into one object</title><p>We first evaluated the responses in visual area MT to stimuli that appeared as distinct objects. The first dataset involved adjacent drifting gratings, both of which were positioned within the receptive field of the MT neuron under study. These data were recorded simultaneously with recordings in V1, in which we have previously reported the presence of fluctuating activity in response to these stimuli (<xref ref-type="bibr" rid="bib19">Jun et al., 2022</xref>). On the trials included for analysis, monkeys performed a task in which attention was directed elsewhere.</p><p>As in V1, we found that some units exhibited bimodal AB spike count distributions whose modes approximately match the individual A and B means, suggesting that the AB responses fluctuate between the A and B response rates across trials. An example of such a unit is shown in <xref ref-type="fig" rid="fig3">Figure 3a</xref>: the red and blue dashed lines indicate the means of the A- and B-alone response distributions, and the black curve provides a smoothed depiction of the distribution of spike counts across the combined AB trials. This distribution appears to reflect an admixture of the A- and B-alone response distributions, indicating that the unit fluctuates between each single response rate from trial to trial.</p><fig id="fig3" position="float"><label>Figure 3.</label><caption><title>Example individual unit responses and population results for middle temporal area (MT).</title><p>(<bold>a</bold>) An example unit’s response to two simultaneous adjacent gratings (AB, black solid lines) in comparison to the mean response to each grating individually (A and B, red and blue dotted lines). (<bold>b</bold>) A different example unit’s response to simultaneous dot patches. In both (<bold>a</bold>) and (<bold>b</bold>), gray bars indicate the raw distributions. The black lines indicate a smoothed fit for display purposes; this fit was generated by convolution with a 3-point sliding window of which the middle point is weighted twice as much as either of the two outer points followed by cubic spline interpolation. Spike counts were computed for a window 200 ms in duration (see Materials and Methods); multiply <italic>x</italic>-axis by 5 to convert to spike rates in Hz. (<bold>c</bold>) Number of triplets classified into each category (as shown in <xref ref-type="fig" rid="fig2">Figure 2</xref>) when responses to two simultaneous gratings (dark blue) or dot patches (light blue) are recorded in MT. Only triplets for which the winning model garnered a posterior probability of 0.67 or greater are shown. (<bold>d</bold>) Same as (<bold>c</bold>) but for fused objects, created by overlaying two gratings to form a plaid. (<bold>e</bold>) Comparison of (<bold>c</bold>) and (<bold>d</bold>) showing that fluctuating (mixture) responses are only present when two objects are distinct, and not when two objects are fused into one. Results in this figure only include triplet conditions for which the average variance-to-mean ratio (Fano factor) of activity on the A- and B-only trials was less than 3. See <xref ref-type="fig" rid="fig4s1">Figure 4—figure supplement 1</xref> for corresponding findings using stricter inclusion criteria.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-91129-fig3-v1.tif"/></fig><p>We next considered a second independent dataset from MT (<xref ref-type="bibr" rid="bib23">Li et al., 2016</xref>) that shares similar properties to the adjacent gratings dataset. In this study, two separate patches of dots, each moving in different directions, were presented within the receptive field of the neurons under study. For the included trials, the monkey was performing a task in which attention was directed to a fixation point away from the dot patches. The combined stimulus AB trials in this dataset were previously reported to show fluctuating activity patterns using a different analysis method (<xref ref-type="bibr" rid="bib23">Li et al., 2016</xref>), and the dataset was made publicly available at <xref ref-type="bibr" rid="bib23">Li et al., 2016</xref>. As in the adjacent gratings MT dataset, we observed bimodal spike count distributions on combined AB trials with modes that appeared to match the mean responses observed on A- and B-alone trials (<xref ref-type="fig" rid="fig3">Figure 3b</xref>).</p><p>To evaluate the prevalence of such fluctuating activity patterns at the population level, we deployed the statistical comparison described in Materials and methods, in which spike count distributions on combined AB trials were evaluated in comparison to four possible options: ‘mixture’, ‘intermediate’, ‘single’, and ‘outside’ (<xref ref-type="fig" rid="fig2">Figure 2</xref>). <xref ref-type="fig" rid="fig3">Figure 3c</xref> shows the results of this analysis for the adjacent gratings and dot patches datasets. In these two datasets, we only identified ‘mixtures’ and ‘intermediates’, but no ‘singles’ or ‘outsides’. There was little difference between these two datasets (light blue vs. dark blue stacked bars in <xref ref-type="fig" rid="fig3">Figure 3c</xref>). Overall in these two datasets, ‘mixtures’ constituted about 45% of the categorized conditions (<xref ref-type="fig" rid="fig3">Figure 3e</xref>, bar labeled ‘distinct objects’).</p><p>In contrast, evidence of fluctuating activity was much lower in our third MT dataset, which involved gratings that were either presented individually (A- and B-alone) or superimposed to produce a fused percept of a ‘plaid’ or checkerboard-like pattern. As in the first dataset, the stimuli were presented in the receptive field of the MT neuron under study, but this time they were presented at the same exact location, rather than adjacent to one another. The monkeys were performing a fixation task; no explicit attentional report was required. In this dataset, ‘mixture’ responses were very rare, constituting only about 1.4% of the conditions that were well categorized (<xref ref-type="fig" rid="fig3">Figure 3d, e</xref>). The majority of conditions were categorized as ‘outside’ (~78%), with ‘single’ and ‘intermediate’ accounting for a further ~14% and ~6%, respectively.</p><p>The difference in the proportions of ‘mixture’ response patterns in the first two MT datasets involving distinct objects (~45%) vs. this last dataset in which the two stimuli fuse to form a new third object (~1.4%) was statistically significant (<xref ref-type="fig" rid="fig3">Figure 3e</xref>, blue vs. green bars, chi-squared test p &lt; 10<sup>−9</sup>). This finding is consistent with the interpretation that the prevalence of fluctuating activity is related to whether two stimuli are perceptually distinguishable vs. fuse to form a single object.</p></sec><sec id="s3-2"><title>Spiking activity fluctuates in face patches MF and AL when two stimuli are distinct</title><p>To further explore the generality of these fluctuating activity patterns, we next turned to a higher order area of the visual pathway – the face patch system of IT cortex. Face patches are exquisitely sensitive to the identity of individual faces, and respond preferentially to faces as compared to other objects. This affords the opportunity to test whether fluctuating activity is evoked solely when the two stimuli are both faces, as might be expected because the non-face objects are largely thought to be encoded by neural populations in other regions of IT, or if both face–face and face–object pairs evoke fluctuating activity. We previously identified fluctuating activity patterns in the MF face patch (<xref ref-type="bibr" rid="bib4">Caruso et al., 2018</xref>), but we did not separate face–face and face–object stimulus conditions. Here, we revisited that dataset to conduct that comparison. We also sought to compare the results in MF to those in face patch AL. Recent work has suggested that MF is ‘earlier’ in the face patch hierarchy than AL, and that AL shows properties such as view-invariance that are less evident in MF (<xref ref-type="bibr" rid="bib25">Moeller et al., 2008</xref>; <xref ref-type="bibr" rid="bib13">Freiwald and Tsao, 2010</xref>; <xref ref-type="bibr" rid="bib6">Ebihara, 2015</xref>). Thus, any differences between the results in MF and AL could shed light on how fluctuating activity varies within the processing hierarchy at this late stage of visual processing.</p><p>Accordingly, we assessed MF and AL face patch responses with both face–face and face–object stimulus combinations. In face–face combinations, one face evoked the strongest response from among a stimulus set (preferred face), and the other face evoked the weakest response from the same set. The preferred face was presented at the center of the neuron’s receptive field, while the non-preferred face was presented at a different location (<xref ref-type="fig" rid="fig1">Figure 1c</xref>). Similarly, the object stimuli were also chosen to evoke weak responses and were presented at a different location than the preferred face. The stimulus conditions were randomly interleaved, and the data were collected while monkeys performed simple fixation tasks.</p><p>Both face patch regions and both types of stimulus combinations elicited fluctuating activity. <xref ref-type="fig" rid="fig4">Figure 4a–d</xref> shows the responses of four example neurons, each of which exhibited spike counts that fluctuated across trials between appearing to respond to the preferred vs. non-preferred face (<xref ref-type="fig" rid="fig4">Figure 4a, c</xref>) or to the face vs. the object (<xref ref-type="fig" rid="fig4">Figure 4b, d</xref>).</p><fig-group><fig id="fig4" position="float"><label>Figure 4.</label><caption><title>Example individual unit responses and population results for IT face patches middle fundus (MF) and AL.</title><p>(<bold>a</bold>) An example single MF unit’s response to two simultaneous faces (AB, black solid lines) in comparison to the mean response to each face individually (A and B, red and blue dotted lines). (<bold>b</bold>) Same as (<bold>a</bold>) but in response to one face and one object. (<bold>c</bold>) Same as (<bold>a</bold>) but recorded in AL. (<bold>d</bold>) Same as (<bold>b</bold>) but recorded in AL. In (<bold>a</bold>) through (<bold>d</bold>), distributions were smoothed for display purposes via convolution with a 3-point sliding window of which the middle point is weighted twice as much as either of the two outer points, followed by cubic spline interpolation. Gray bars show the raw spike counts for the 200 ms spike counting windows (multiply <italic>x</italic>-axis scale by 5 to convert to spike rates in Hz). (<bold>e</bold>) Number of triplets classified into each category (as shown in <xref ref-type="fig" rid="fig2">Figure 2</xref>) when responses to a face–face pair (dark brown) or a face–object pair (mustard color) are recorded in face patch MF. Only triplets for which the winning model garnered a posterior probability of 0.67 or greater are shown. (<bold>f</bold>) Same as (<bold>e</bold>) but recorded in face patch AL. (<bold>g</bold>) Comparison of (<bold>e</bold>) and (<bold>f</bold>) showing that more conditions display a fluctuating (mixture) pattern in AL than in MF. In MF, there were more ‘mixtures’ among face–face pairs than among face–object pairs. Results in this figure only include triplet conditions for which the average variance-to-mean ratio (Fano factor) of activity on the A- and B-only trials was less than 3. See <xref ref-type="fig" rid="fig4s1">Figure 4—figure supplement 1</xref> for corresponding findings using stricter inclusion criteria.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-91129-fig4-v1.tif"/></fig><fig id="fig4s1" position="float" specific-use="child-fig"><label>Figure 4—figure supplement 1.</label><caption><title>Same as population results in <xref ref-type="fig" rid="fig3">Figures 3</xref> and <xref ref-type="fig" rid="fig4">4</xref>, but using a Fano factor criterion of 2 instead of 3.</title><p>All trends in the data are maintained compared to the comparisons with a criterion of 3, other than the loss of significance between face–face and face–object comparisons in middle fundus (MF).</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-91129-fig4-figsupp1-v1.tif"/></fig></fig-group><p>To evaluate these results at the population level, we used the same statistical comparison described above for the MT analysis. As shown in <xref ref-type="fig" rid="fig4">Figure 4e</xref>, we identified ‘mixtures’ in face patch MF for both face–face (dark brown bar) and face–object (mustard-colored bar) stimulus combinations. We also observed ‘intermediates’ and ‘singles’, but no ‘outsides’. Overall, ‘mixtures’ constituted about 32.5% of well-categorized conditions (<xref ref-type="fig" rid="fig4">Figure 4g</xref>, light brown bar). The proportion of ‘mixtures’ was higher for face–face stimulus combinations (43.6%, <xref ref-type="fig" rid="fig4">Figure 4g</xref>, dark brown bar) than for face–object stimulus combinations (22.7%, <xref ref-type="fig" rid="fig4">Figure 4g</xref>, mustard-colored bar). The difference in these proportions was just barely significant by chi-squared test (p = 0.043), but we note that when using stricter Fano factor inclusion criteria for the dataset (variance-to-mean ratio of single-stimulus responses less than 2 rather than 3, see Materials and methods: ‘Triplet’ definition and inclusion criteria), the reduction in the amount of included data increases this p value to p = 0.054 (see <xref ref-type="fig" rid="fig4s1">Figure 4—figure supplement 1</xref>). Accordingly, this aspect of the results should be viewed as of borderline significance.</p><p>‘Mixtures’ were even more prevalent in face patch AL (<xref ref-type="fig" rid="fig4">Figure 4f</xref>), constituting about 66% of the conditions for both face–face and face–object pairs (<xref ref-type="fig" rid="fig4">Figure 4g</xref>). The approximate doubling in the prevalence of ‘mixtures’ in AL vs. MF (65.9 vs. 32.5%) was statistically significant by chi-squared test (p = 0.00002). Like face patch MF, AL responses had no ‘outsides’, but ‘singles’ and ‘intermediates’ were still present. In MF, we previously showed that such ‘intermediates’ could show fluctuating activity within the timescale of individual trials (<xref ref-type="bibr" rid="bib4">Caruso et al., 2018</xref>).</p></sec></sec><sec id="s4" sec-type="discussion"><title>Discussion</title><p>A key problem in neuroscience is how the brain retains information about multiple co-occurring stimuli. We present a potential solution to this problem: When multiple stimuli are present, neurons across levels of visual processing may fluctuate, on the whole trial time scale, between responding to individual stimuli in distinct time windows. This fluctuating pattern may be a way for the brain to preserve information about multiple stimuli in complex sensory environments.</p><p>We report here that fluctuating activity was evoked by pairs of distinguishable stimuli in MT and areas MF and AL in the face patch system of IT cortex. This work extends our previous findings in several key ways. First, it expands the range of brain regions and stimulus conditions in which this phenomenon has been observed. In MT, fluctuating activity was observed in two independent datasets involving different stimulus conditions and collected by different labs. In the face patch system, fluctuating activity was observed in both face patches included in this study. This suggests that fluctuating activity evoked by combinations of stimuli is a robust phenomenon within the visual pathway and occurs across multiple stages of the visual hierarchy.</p><p>Second, another of our goals was to evaluate whether fluctuating activity is more prevalent when the two stimuli involved are competing for representation in the same neural population. The use of face–face and face–object stimulus combinations to probe signals in the face patch system provides an opportunity to address this question in a unique way. If the face patch system serves as a series of structures whose specific role is to represent faces and not non-face objects, one might expect that fluctuating activity would be more evident when the two stimuli were both faces than when only one of the stimuli is a face. Specifically, one might expect winner-take-all for the face stimulus, which would be classified as ‘single’ in our analysis. Instead, we observed fluctuating activity for both face–face and face–object pairs, although there was a modestly higher incidence of fluctuating activity for face–face stimuli than face–object stimuli in MF. In AL, fluctuating activity was very common for both types of stimulus combinations. This suggests that fluctuating activity can occur even when somewhat distinct populations of neurons are available to respond to the two stimuli in question; neurons outside the face patch system are in principle available to encode the presence and properties of the non-face object, yet fluctuating activity nevertheless occurred.</p><p>The presence of fluctuations evoked by face–object stimuli is reminiscent of a related aspect of our previous findings in V1 (<xref ref-type="bibr" rid="bib19">Jun et al., 2022</xref>). Specifically, we observed fluctuating activity in V1 even though the two stimuli involved were usually not located within the same receptive field and in principle could have evoked activity in largely distinct neural subpopulations. One possible explanation for this is that the activity of the whole population is necessary to specify the presence or identity of a stimulus, even if some members of the population are silent. A second possibility is that fluctuations occur ‘on spec’ regardless of the particular stimuli involved due to the possibility that they may require activity in overlapping populations of neurons to be encoded. Supporting these possibilities, we found fluctuating activity not only in the two MT datasets, which involved adjacent stimuli in the same neural receptive field, but also in the IT and earlier V1 datasets, which largely did not.</p><p>Finally, the evidence for fluctuating activity in MT when the two stimuli were perceptually distinct but not when they fused to form a common object lends support to the idea that there is an interplay between segregation of the scene into separate objects and the occurrence of fluctuating activity patterns. We previously found a similar pattern in V1 although not in V4 (<xref ref-type="bibr" rid="bib19">Jun et al., 2022</xref>). It is not yet clear what might account for the discrepancy with V4, and this matter bears further investigation.</p><p>There are both strengths and limitations to the use of multiple datasets across different laboratories, brain areas, and experimental conditions. The key strength is that the presence of fluctuating activity under a wide variety of circumstances indicates that this property of neural representations is a robust one that does not require specialized circumstances to uncover. Across this and our two previous studies (<xref ref-type="bibr" rid="bib4">Caruso et al., 2018</xref>; <xref ref-type="bibr" rid="bib19">Jun et al., 2022</xref>), we have now shown fluctuating activity occurring in the context of behavioral tasks requiring a report of both stimuli (IC, <xref ref-type="bibr" rid="bib4">Caruso et al., 2018</xref>), strictly fixation (MF, AL, V4; this study, <xref ref-type="bibr" rid="bib4">Caruso et al., 2018</xref>; <xref ref-type="bibr" rid="bib19">Jun et al., 2022</xref>), and attend-elsewhere tasks (MT, V1; this study, <xref ref-type="bibr" rid="bib19">Jun et al., 2022</xref>). As mentioned above, fluctuating activity can be observed when two stimuli are within the same receptive field (MT) as well as when they are not (V1). A key limitation is that comparisons between datasets are likely to be affected by parameters such as the amount of data acquired. Future work in which conditions are held constant as much as possible across datasets will be needed before strong claims can be made about matters such as whether fluctuating activity is more vs. less prevalent across different behavioral tasks, brain areas, and even sensory systems. For example, the variation in behavioral tasks but consistency of results across datasets suggests that attentional task performance (or, conversely, lack of attentional control) is not a strong driver of the observed effects, but more work will be needed to fully establish this.</p><p>Our findings are part of an emerging body of literature suggesting that neural circuits fluctuate between different response states. For example, ‘on/off’ or ‘up/down’ states, characterized by different levels of spontaneous neural activity and/or responsiveness to stimuli, have been identified in multiple animal models, cortical areas, and behavioral contexts (<xref ref-type="bibr" rid="bib17">Hasenstaub et al., 2007</xref>; <xref ref-type="bibr" rid="bib16">Harris and Thiele, 2011</xref>; <xref ref-type="bibr" rid="bib8">Engel et al., 2016</xref>). What causes these fluctuating activity patterns is not fully known, but they have been found to be influenced by attention and state of arousal (<xref ref-type="bibr" rid="bib16">Harris and Thiele, 2011</xref>; <xref ref-type="bibr" rid="bib8">Engel et al., 2016</xref>). The relationship between such up/down states and the fluctuations we have observed here remains unexplored. A key question is how the fluctuating activity evoked by multiple stimuli is coordinated across neurons. Up/down states can be either synchronized or desynchronized across neurons, depending on the behavioral context (<xref ref-type="bibr" rid="bib16">Harris and Thiele, 2011</xref>; <xref ref-type="bibr" rid="bib8">Engel et al., 2016</xref>). In our previous work, we showed that the fluctuating activity in V1 showed both positive and negative correlations across neurons in a fashion that suggests that at least some portion of the neural population responds to each stimulus on any given presentation (<xref ref-type="bibr" rid="bib19">Jun et al., 2022</xref>). The neurons in the adjacent gratings MT dataset in our current study were recorded at the same time as the V1 dataset in that earlier study, so we can infer that the MT neurons would also likely have shown both positive and negative correlations with those simultaneously recorded V1 neurons.</p><p>Also relevant are studies of rhythmicity and/or serial sampling in attention (e.g., <xref ref-type="bibr" rid="bib31">Treisman and Gelade, 1980</xref>; <xref ref-type="bibr" rid="bib33">Van Rullen, 2016</xref>; <xref ref-type="bibr" rid="bib11">Fiebelkorn and Kastner, 2019</xref>). Reaction times to detect a target among distractors can scale with the number of distractor stimuli (depending on how the target differs from the distractors) (<xref ref-type="bibr" rid="bib31">Treisman and Gelade, 1980</xref>). Near threshold stimuli or stimulus changes occurring at certain phases of electroencephalography (EEG) or local field potential (LFP) oscillatory cycles are more likely to be detected than those occurring at other phases (<xref ref-type="bibr" rid="bib2">Busch et al., 2009</xref>; <xref ref-type="bibr" rid="bib3">Busch and VanRullen, 2010</xref>; <xref ref-type="bibr" rid="bib32">Vanrullen et al., 2011</xref>; <xref ref-type="bibr" rid="bib9">Fiebelkorn et al., 2013</xref>; <xref ref-type="bibr" rid="bib24">McLelland and VanRullen, 2016</xref>; <xref ref-type="bibr" rid="bib10">Fiebelkorn et al., 2018</xref>; <xref ref-type="bibr" rid="bib18">Helfrich et al., 2018</xref>). And conversely, rhythmic fluctuations can be triggered by presentation of multiple stimuli in V4 (<xref ref-type="bibr" rid="bib21">Kienitz et al., 2018</xref>; <xref ref-type="bibr" rid="bib22">Kienitz et al., 2022</xref>).</p><p>Collectively, these findings support the view that aspects of the nervous system sequentially samples the sensory environment across time, a notion with a clear conceptual link to the findings presented here. Future work will be needed to fully explore this possible connection, for several reasons. First, our current analysis method does not actually require fluctuating activity to occur rhythmically so long as it fluctuates. Thus, our method may be uncovering patterns of fluctuating activity that have not been seen before, due to irregularity in the timing of fluctuations or their coordination across the neural population. Second, our method requires that the fluctuating activity be reasonably well modeled as fluctuating between two specific benchmarks, namely the activity evoked by stimulus A vs. B. A combined analysis method that evaluates the periodicity of such benchmarked fluctuating activity will be useful for bridging the gap between the present study and these related findings. In addition, deployment of attentional tasks will be needed to fully explore this connection.</p><p>Another area for future exploration is the extent to which fluctuating responses could allow for preservation of more than two stimuli. The current study exclusively used datasets in which two stimuli were presented, either alone or in pairs. It will be sensible to extend these analysis methods to more complex but realistic stimulus conditions involving three or more stimuli.</p><p>In sum, neural switching appears to be a general phenomenon throughout a range of areas in the visual system and could support the ability to preserve information about multiple sensory components. Fluctuating activity may relate to object formation, a key perceptual ability whose underlying mechanism(s) remain poorly understood. Future experimentation is needed to understand how neural fluctuations may support such cognitive phenomena.</p></sec></body><back><sec sec-type="additional-information" id="s5"><title>Additional information</title><fn-group content-type="competing-interest"><title>Competing interests</title><fn fn-type="COI-statement" id="conf1"><p>No competing interests declared</p></fn><fn fn-type="COI-statement" id="conf2"><p>Reviewing editor, <italic>eLife</italic></p></fn></fn-group><fn-group content-type="author-contribution"><title>Author contributions</title><fn fn-type="con" id="con1"><p>Conceptualization, Data curation, Formal analysis, Funding acquisition, Validation, Investigation, Visualization, Methodology, Writing – original draft, Project administration, Writing – review and editing</p></fn><fn fn-type="con" id="con2"><p>Conceptualization, Data curation, Formal analysis, Validation, Investigation, Visualization, Methodology, Writing – original draft, Project administration, Writing – review and editing</p></fn><fn fn-type="con" id="con3"><p>Conceptualization, Data curation, Software, Investigation, Methodology, Writing – review and editing</p></fn><fn fn-type="con" id="con4"><p>Data curation, Formal analysis, Investigation, Methodology, Writing – review and editing</p></fn><fn fn-type="con" id="con5"><p>Conceptualization, Data curation, Investigation, Methodology, Writing – review and editing</p></fn><fn fn-type="con" id="con6"><p>Conceptualization, Data curation, Investigation, Methodology, Writing – review and editing</p></fn><fn fn-type="con" id="con7"><p>Conceptualization, Data curation, Investigation, Methodology, Writing – review and editing</p></fn><fn fn-type="con" id="con8"><p>Conceptualization, Data curation, Supervision, Funding acquisition, Investigation, Methodology, Writing – review and editing</p></fn><fn fn-type="con" id="con9"><p>Conceptualization, Data curation, Investigation, Methodology, Writing – review and editing</p></fn><fn fn-type="con" id="con10"><p>Conceptualization, Data curation, Supervision, Funding acquisition, Investigation, Methodology, Writing – review and editing</p></fn><fn fn-type="con" id="con11"><p>Conceptualization, Data curation, Software, Formal analysis, Supervision, Funding acquisition, Validation, Investigation, Methodology, Writing – review and editing</p></fn><fn fn-type="con" id="con12"><p>Conceptualization, Data curation, Formal analysis, Supervision, Funding acquisition, Validation, Investigation, Visualization, Methodology, Writing – original draft, Project administration, Writing – review and editing</p></fn></fn-group><fn-group content-type="ethics-information"><title>Ethics</title><fn fn-type="other"><p>All datasets were collected in awake, behaving macaques (MT: <italic>Macaca mulatta</italic>; IT: <italic>Macaca mulatta</italic> and Macaca fascicularis). The data were originally collected at the University of Pittsburgh (Ruff and Cohen, 2016; Ruff et al., 2016), Rockefeller University (Ebihara, 2015), and the German Primate Center in Goettingen (Li et al., 2016). All procedures were conducted in accordance with applicable US, German, and European guidelines or regulations and were approved by the relevant compliance committees at the relevant institutions (US guidelines: National Institutes of Health (NIH) Pub. No. 86-23, Revised 1985; Pittsburgh MT grating datasets: Institutional Animal Care and Use Committees of the University of Pittsburgh and Carnegie Mellon University (Protocol #: 20067560, PHS Assurance Number: D16-00118); IT datasets: The Rockefeller University Institutional Animal Care and Use Committee (Protocol #: 21104-H USDA, PHS Assurance Number: A3081-01); Goettingen MT dot patch dataset: [Niedersx00E4;chsisches Landesamtfx00FC;r Verbraucherschutzund Lebensmittelsicherheit (LAVES)] permit numbers 33.42502/08-07.02 and 33.14.42502-04-064/07). All surgical procedures were conducted aseptically and with suitable anesthetics and analgesics.</p></fn></fn-group></sec><sec sec-type="supplementary-material" id="s6"><title>Additional files</title><supplementary-material id="mdar"><label>MDAR checklist</label><media xlink:href="elife-91129-mdarchecklist1-v1.pdf" mimetype="application" mime-subtype="pdf"/></supplementary-material><supplementary-material id="sdata1"><label>Source data 1.</label><caption><title>Source data for the figures and analyses in this article.</title><p>Spreadsheets are included for the analysis output from each dataset. Individual file names indicate which datasets they relate to.</p></caption><media xlink:href="elife-91129-data1-v1.zip" mimetype="application" mime-subtype="zip"/></supplementary-material></sec><sec sec-type="data-availability" id="s7"><title>Data availability</title><p>Some of the data used in this study has been published previously (<ext-link ext-link-type="uri" xlink:href="https://doi.org/10.5061/DRYAD.88PV1">https://doi.org/10.5061/DRYAD.88PV1</ext-link>). Data underlying the figures can be found in Source data 1.</p><p>The following previously published dataset was used:</p><p><element-citation publication-type="data" specific-use="references" id="dataset1"><person-group person-group-type="author"><name><surname>Li</surname><given-names>K</given-names></name><name><surname>Kozyrev</surname><given-names>V</given-names></name><name><surname>Kyllingsbæk</surname><given-names>S</given-names></name><name><surname>Treue</surname><given-names>S</given-names></name><name><surname>Ditlevsen</surname><given-names>S</given-names></name><name><surname>Bundesen</surname><given-names>C</given-names></name></person-group><year iso-8601-date="2020">2020</year><data-title>Data from: Neurons in primate visual cortex alternate between responses to multiple stimuli in their receptive field</data-title><source>Dryad Digital Repository</source><pub-id pub-id-type="doi">10.5061/dryad.88pv1</pub-id></element-citation></p></sec><ack id="ack"><title>Acknowledgements</title><p>We thank Justine Shih, Tingan Zhu, Gelana Tostaeva, Justine Griego, and Sara Gannon for helpful discussions about these topics. This work was supported by F31 fellowship to MNS; National Institutes of Health grant nos. R00EY020844 (MRC), R01EY022930 (MRC); Core Grant P30 EY008098s (MRC); R01DC013906 (JMG, STT); and R01DC016363 (JMG, STT); and by support to MRC from the McKnight, Whitehall, Sloan, and Simons Foundations.</p></ack><ref-list><title>References</title><ref id="bib1"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Berger</surname><given-names>JO</given-names></name><name><surname>Pericchi</surname><given-names>LR</given-names></name></person-group><year iso-8601-date="1996">1996</year><article-title>The intrinsic bayes factor for model selection and prediction</article-title><source>Journal of the American Statistical Association</source><volume>91</volume><fpage>109</fpage><lpage>122</lpage><pub-id pub-id-type="doi">10.1080/01621459.1996.10476668</pub-id></element-citation></ref><ref id="bib2"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Busch</surname><given-names>NA</given-names></name><name><surname>Dubois</surname><given-names>J</given-names></name><name><surname>VanRullen</surname><given-names>R</given-names></name></person-group><year iso-8601-date="2009">2009</year><article-title>The phase of ongoing EEG oscillations predicts visual perception</article-title><source>The Journal of Neuroscience</source><volume>29</volume><fpage>7869</fpage><lpage>7876</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.0113-09.2009</pub-id><pub-id pub-id-type="pmid">19535598</pub-id></element-citation></ref><ref id="bib3"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Busch</surname><given-names>NA</given-names></name><name><surname>VanRullen</surname><given-names>R</given-names></name></person-group><year iso-8601-date="2010">2010</year><article-title>Spontaneous EEG oscillations reveal periodic sampling of visual attention</article-title><source>PNAS</source><volume>107</volume><fpage>16048</fpage><lpage>16053</lpage><pub-id pub-id-type="doi">10.1073/pnas.1004801107</pub-id><pub-id pub-id-type="pmid">20805482</pub-id></element-citation></ref><ref id="bib4"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Caruso</surname><given-names>VC</given-names></name><name><surname>Mohl</surname><given-names>JT</given-names></name><name><surname>Glynn</surname><given-names>C</given-names></name><name><surname>Lee</surname><given-names>J</given-names></name><name><surname>Willett</surname><given-names>SM</given-names></name><name><surname>Zaman</surname><given-names>A</given-names></name><name><surname>Ebihara</surname><given-names>AF</given-names></name><name><surname>Estrada</surname><given-names>R</given-names></name><name><surname>Freiwald</surname><given-names>WA</given-names></name><name><surname>Tokdar</surname><given-names>ST</given-names></name><name><surname>Groh</surname><given-names>JM</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>Single neurons may encode simultaneous stimuli by switching between activity patterns</article-title><source>Nature Communications</source><volume>9</volume><elocation-id>2715</elocation-id><pub-id pub-id-type="doi">10.1038/s41467-018-05121-8</pub-id><pub-id pub-id-type="pmid">30006598</pub-id></element-citation></ref><ref id="bib5"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Dow</surname><given-names>BM</given-names></name><name><surname>Snyder</surname><given-names>AZ</given-names></name><name><surname>Vautin</surname><given-names>RG</given-names></name><name><surname>Bauer</surname><given-names>R</given-names></name></person-group><year iso-8601-date="1981">1981</year><article-title>Magnification factor and receptive field size in foveal striate cortex of the monkey</article-title><source>Experimental Brain Research</source><volume>44</volume><fpage>213</fpage><lpage>228</lpage><pub-id pub-id-type="doi">10.1007/BF00237343</pub-id><pub-id pub-id-type="pmid">7286109</pub-id></element-citation></ref><ref id="bib6"><element-citation publication-type="thesis"><person-group person-group-type="author"><name><surname>Ebihara</surname><given-names>AF</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>Normalization among heterogeneous population confers stimulus discriminability on the macaque face patch neurons</article-title><publisher-name>The Rockefeller University: Student Theses and Dissertations</publisher-name><ext-link ext-link-type="uri" xlink:href="https://digitalcommons.rockefeller.edu/student_theses_and_dissertations/278/">https://digitalcommons.rockefeller.edu/student_theses_and_dissertations/278/</ext-link></element-citation></ref><ref id="bib7"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Engbert</surname><given-names>R</given-names></name><name><surname>Kliegl</surname><given-names>R</given-names></name></person-group><year iso-8601-date="2003">2003</year><article-title>Microsaccades uncover the orientation of covert attention</article-title><source>Vision Research</source><volume>43</volume><fpage>1035</fpage><lpage>1045</lpage><pub-id pub-id-type="doi">10.1016/s0042-6989(03)00084-1</pub-id><pub-id pub-id-type="pmid">12676246</pub-id></element-citation></ref><ref id="bib8"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Engel</surname><given-names>TA</given-names></name><name><surname>Steinmetz</surname><given-names>NA</given-names></name><name><surname>Gieselmann</surname><given-names>MA</given-names></name><name><surname>Thiele</surname><given-names>A</given-names></name><name><surname>Moore</surname><given-names>T</given-names></name><name><surname>Boahen</surname><given-names>K</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Selective modulation of cortical state during spatial attention</article-title><source>Science</source><volume>354</volume><fpage>1140</fpage><lpage>1144</lpage><pub-id pub-id-type="doi">10.1126/science.aag1420</pub-id><pub-id pub-id-type="pmid">27934763</pub-id></element-citation></ref><ref id="bib9"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Fiebelkorn</surname><given-names>IC</given-names></name><name><surname>Saalmann</surname><given-names>YB</given-names></name><name><surname>Kastner</surname><given-names>S</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>Rhythmic sampling within and between objects despite sustained attention at a cued location</article-title><source>Current Biology</source><volume>23</volume><fpage>2553</fpage><lpage>2558</lpage><pub-id pub-id-type="doi">10.1016/j.cub.2013.10.063</pub-id><pub-id pub-id-type="pmid">24316204</pub-id></element-citation></ref><ref id="bib10"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Fiebelkorn</surname><given-names>IC</given-names></name><name><surname>Pinsk</surname><given-names>MA</given-names></name><name><surname>Kastner</surname><given-names>S</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>A Dynamic interplay within the frontoparietal network underlies rhythmic spatial attention</article-title><source>Neuron</source><volume>99</volume><fpage>842</fpage><lpage>853</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2018.07.038</pub-id><pub-id pub-id-type="pmid">30138590</pub-id></element-citation></ref><ref id="bib11"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Fiebelkorn</surname><given-names>IC</given-names></name><name><surname>Kastner</surname><given-names>S</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>A rhythmic theory of attention</article-title><source>Trends in Cognitive Sciences</source><volume>23</volume><fpage>87</fpage><lpage>101</lpage><pub-id pub-id-type="doi">10.1016/j.tics.2018.11.009</pub-id><pub-id pub-id-type="pmid">30591373</pub-id></element-citation></ref><ref id="bib12"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Freeman</surname><given-names>J</given-names></name><name><surname>Simoncelli</surname><given-names>EP</given-names></name></person-group><year iso-8601-date="2011">2011</year><article-title>Metamers of the ventral stream</article-title><source>Nature Neuroscience</source><volume>14</volume><fpage>1195</fpage><lpage>1201</lpage><pub-id pub-id-type="doi">10.1038/nn.2889</pub-id><pub-id pub-id-type="pmid">21841776</pub-id></element-citation></ref><ref id="bib13"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Freiwald</surname><given-names>WA</given-names></name><name><surname>Tsao</surname><given-names>DY</given-names></name></person-group><year iso-8601-date="2010">2010</year><article-title>Functional compartmentalization and viewpoint generalization within the macaque face-processing system</article-title><source>Science</source><volume>330</volume><fpage>845</fpage><lpage>851</lpage><pub-id pub-id-type="doi">10.1126/science.1194908</pub-id><pub-id pub-id-type="pmid">21051642</pub-id></element-citation></ref><ref id="bib14"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Glynn</surname><given-names>C</given-names></name><name><surname>Tokdar</surname><given-names>ST</given-names></name><name><surname>Zaman</surname><given-names>A</given-names></name><name><surname>Caruso</surname><given-names>VC</given-names></name><name><surname>Mohl</surname><given-names>JT</given-names></name><name><surname>Willett</surname><given-names>SM</given-names></name><name><surname>Groh</surname><given-names>JM</given-names></name></person-group><year iso-8601-date="2021">2021</year><article-title>Analyzing second order stochasticity of neural spiking under stimuli-bundle exposure</article-title><source>The Annals of Applied Statistics</source><volume>15</volume><fpage>41</fpage><lpage>63</lpage><pub-id pub-id-type="doi">10.1214/20-AOAS1383</pub-id><pub-id pub-id-type="pmid">34413921</pub-id></element-citation></ref><ref id="bib15"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Grill-Spector</surname><given-names>K</given-names></name><name><surname>Weiner</surname><given-names>KS</given-names></name><name><surname>Kay</surname><given-names>K</given-names></name><name><surname>Gomez</surname><given-names>J</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>The functional neuroanatomy of human face perception</article-title><source>Annual Review of Vision Science</source><volume>3</volume><fpage>167</fpage><lpage>196</lpage><pub-id pub-id-type="doi">10.1146/annurev-vision-102016-061214</pub-id><pub-id pub-id-type="pmid">28715955</pub-id></element-citation></ref><ref id="bib16"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Harris</surname><given-names>KD</given-names></name><name><surname>Thiele</surname><given-names>A</given-names></name></person-group><year iso-8601-date="2011">2011</year><article-title>Cortical state and attention</article-title><source>Nature Reviews. Neuroscience</source><volume>12</volume><fpage>509</fpage><lpage>523</lpage><pub-id pub-id-type="doi">10.1038/nrn3084</pub-id><pub-id pub-id-type="pmid">21829219</pub-id></element-citation></ref><ref id="bib17"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hasenstaub</surname><given-names>A</given-names></name><name><surname>Sachdev</surname><given-names>RNS</given-names></name><name><surname>McCormick</surname><given-names>DA</given-names></name></person-group><year iso-8601-date="2007">2007</year><article-title>State changes rapidly modulate cortical neuronal responsiveness</article-title><source>The Journal of Neuroscience</source><volume>27</volume><fpage>9607</fpage><lpage>9622</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.2184-07.2007</pub-id><pub-id pub-id-type="pmid">17804621</pub-id></element-citation></ref><ref id="bib18"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Helfrich</surname><given-names>RF</given-names></name><name><surname>Fiebelkorn</surname><given-names>IC</given-names></name><name><surname>Szczepanski</surname><given-names>SM</given-names></name><name><surname>Lin</surname><given-names>JJ</given-names></name><name><surname>Parvizi</surname><given-names>J</given-names></name><name><surname>Knight</surname><given-names>RT</given-names></name><name><surname>Kastner</surname><given-names>S</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>Neural mechanisms of sustained attention are rhythmic</article-title><source>Neuron</source><volume>99</volume><fpage>854</fpage><lpage>865</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2018.07.032</pub-id><pub-id pub-id-type="pmid">30138591</pub-id></element-citation></ref><ref id="bib19"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Jun</surname><given-names>NY</given-names></name><name><surname>Ruff</surname><given-names>DA</given-names></name><name><surname>Kramer</surname><given-names>LE</given-names></name><name><surname>Bowes</surname><given-names>B</given-names></name><name><surname>Tokdar</surname><given-names>ST</given-names></name><name><surname>Cohen</surname><given-names>MR</given-names></name><name><surname>Groh</surname><given-names>JM</given-names></name></person-group><year iso-8601-date="2022">2022</year><article-title>Coordinated multiplexing of information about separate objects in visual cortex</article-title><source>eLife</source><volume>11</volume><elocation-id>e76452</elocation-id><pub-id pub-id-type="doi">10.7554/eLife.76452</pub-id><pub-id pub-id-type="pmid">36444983</pub-id></element-citation></ref><ref id="bib20"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Keliris</surname><given-names>GA</given-names></name><name><surname>Li</surname><given-names>Q</given-names></name><name><surname>Papanikolaou</surname><given-names>A</given-names></name><name><surname>Logothetis</surname><given-names>NK</given-names></name><name><surname>Smirnakis</surname><given-names>SM</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>Estimating average single-neuron visual receptive field sizes by fMRI</article-title><source>PNAS</source><volume>116</volume><fpage>6425</fpage><lpage>6434</lpage><pub-id pub-id-type="doi">10.1073/pnas.1809612116</pub-id><pub-id pub-id-type="pmid">30867291</pub-id></element-citation></ref><ref id="bib21"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kienitz</surname><given-names>R</given-names></name><name><surname>Schmiedt</surname><given-names>JT</given-names></name><name><surname>Shapcott</surname><given-names>KA</given-names></name><name><surname>Kouroupaki</surname><given-names>K</given-names></name><name><surname>Saunders</surname><given-names>RC</given-names></name><name><surname>Schmid</surname><given-names>MC</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>Theta rhythmic neuronal activity and reaction times arising from cortical receptive field interactions during distributed attention</article-title><source>Current Biology</source><volume>28</volume><fpage>2377</fpage><lpage>2387</lpage><pub-id pub-id-type="doi">10.1016/j.cub.2018.05.086</pub-id><pub-id pub-id-type="pmid">30017481</pub-id></element-citation></ref><ref id="bib22"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kienitz</surname><given-names>R</given-names></name><name><surname>Schmid</surname><given-names>MC</given-names></name><name><surname>Dugué</surname><given-names>L</given-names></name></person-group><year iso-8601-date="2022">2022</year><article-title>Rhythmic sampling revisited: experimental paradigms and neural mechanisms</article-title><source>The European Journal of Neuroscience</source><volume>55</volume><fpage>3010</fpage><lpage>3024</lpage><pub-id pub-id-type="doi">10.1111/ejn.15489</pub-id><pub-id pub-id-type="pmid">34643973</pub-id></element-citation></ref><ref id="bib23"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Li</surname><given-names>K</given-names></name><name><surname>Kozyrev</surname><given-names>V</given-names></name><name><surname>Kyllingsbæk</surname><given-names>S</given-names></name><name><surname>Treue</surname><given-names>S</given-names></name><name><surname>Ditlevsen</surname><given-names>S</given-names></name><name><surname>Bundesen</surname><given-names>C</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Neurons in primate visual cortex alternate between responses to multiple stimuli in their receptive field</article-title><source>Frontiers in Computational Neuroscience</source><volume>10</volume><elocation-id>141</elocation-id><pub-id pub-id-type="doi">10.3389/fncom.2016.00141</pub-id><pub-id pub-id-type="pmid">28082892</pub-id></element-citation></ref><ref id="bib24"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>McLelland</surname><given-names>D</given-names></name><name><surname>VanRullen</surname><given-names>R</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Theta-gamma coding meets communication-through-coherence: neuronal oscillatory multiplexing theories reconciled</article-title><source>PLOS Computational Biology</source><volume>12</volume><elocation-id>e1005162</elocation-id><pub-id pub-id-type="doi">10.1371/journal.pcbi.1005162</pub-id><pub-id pub-id-type="pmid">27741229</pub-id></element-citation></ref><ref id="bib25"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Moeller</surname><given-names>S</given-names></name><name><surname>Freiwald</surname><given-names>WA</given-names></name><name><surname>Tsao</surname><given-names>DY</given-names></name></person-group><year iso-8601-date="2008">2008</year><article-title>Patches with links: a unified system for processing faces in the macaque temporal lobe</article-title><source>Science</source><volume>320</volume><fpage>1355</fpage><lpage>1359</lpage><pub-id pub-id-type="doi">10.1126/science.1157436</pub-id><pub-id pub-id-type="pmid">18535247</pub-id></element-citation></ref><ref id="bib26"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Mohl</surname><given-names>JT</given-names></name><name><surname>Caruso</surname><given-names>VC</given-names></name><name><surname>Tokdar</surname><given-names>ST</given-names></name><name><surname>Groh</surname><given-names>JM</given-names></name></person-group><year iso-8601-date="2020">2020</year><article-title>Sensitivity and specificity of a Bayesian single trial analysis for time varying neural signals</article-title><source>Neurons, Behavior, Data Analysis, and Theory</source><volume>3</volume><elocation-id>01</elocation-id><pub-id pub-id-type="pmid">34505116</pub-id></element-citation></ref><ref id="bib27"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Motter</surname><given-names>BC</given-names></name></person-group><year iso-8601-date="2009">2009</year><article-title>Central V4 receptive fields are scaled by the V1 cortical magnification and correspond to a constant-sized sampling of the V1 surface</article-title><source>The Journal of Neuroscience</source><volume>29</volume><fpage>5749</fpage><lpage>5757</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.4496-08.2009</pub-id><pub-id pub-id-type="pmid">19420243</pub-id></element-citation></ref><ref id="bib28"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ruff</surname><given-names>DA</given-names></name><name><surname>Alberts</surname><given-names>JJ</given-names></name><name><surname>Cohen</surname><given-names>MR</given-names></name></person-group><year iso-8601-date="2016">2016a</year><article-title>Relating normalization to neuronal populations across cortical areas</article-title><source>Journal of Neurophysiology</source><volume>116</volume><fpage>1375</fpage><lpage>1386</lpage><pub-id pub-id-type="doi">10.1152/jn.00017.2016</pub-id><pub-id pub-id-type="pmid">27358313</pub-id></element-citation></ref><ref id="bib29"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ruff</surname><given-names>DA</given-names></name><name><surname>Cohen</surname><given-names>MR</given-names></name></person-group><year iso-8601-date="2016">2016b</year><article-title>Attention increases spike count correlations between visual cortical Areas</article-title><source>The Journal of Neuroscience</source><volume>36</volume><fpage>7523</fpage><lpage>7534</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.0610-16.2016</pub-id><pub-id pub-id-type="pmid">27413161</pub-id></element-citation></ref><ref id="bib30"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Smith</surname><given-names>AT</given-names></name><name><surname>Singh</surname><given-names>KD</given-names></name><name><surname>Williams</surname><given-names>AL</given-names></name><name><surname>Greenlee</surname><given-names>MW</given-names></name></person-group><year iso-8601-date="2001">2001</year><article-title>Estimating receptive field size from fMRI data in human striate and extrastriate visual cortex</article-title><source>Cerebral Cortex</source><volume>11</volume><fpage>1182</fpage><lpage>1190</lpage><pub-id pub-id-type="doi">10.1093/cercor/11.12.1182</pub-id><pub-id pub-id-type="pmid">11709489</pub-id></element-citation></ref><ref id="bib31"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Treisman</surname><given-names>AM</given-names></name><name><surname>Gelade</surname><given-names>G</given-names></name></person-group><year iso-8601-date="1980">1980</year><article-title>A feature-integration theory of attention</article-title><source>Cognitive Psychology</source><volume>12</volume><fpage>97</fpage><lpage>136</lpage><pub-id pub-id-type="doi">10.1016/0010-0285(80)90005-5</pub-id><pub-id pub-id-type="pmid">7351125</pub-id></element-citation></ref><ref id="bib32"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Vanrullen</surname><given-names>R</given-names></name><name><surname>Busch</surname><given-names>NA</given-names></name><name><surname>Drewes</surname><given-names>J</given-names></name><name><surname>Dubois</surname><given-names>J</given-names></name></person-group><year iso-8601-date="2011">2011</year><article-title>Ongoing EEG phase as a trial-by-trial predictor of perceptual and attentional variability</article-title><source>Frontiers in Psychology</source><volume>2</volume><elocation-id>60</elocation-id><pub-id pub-id-type="doi">10.3389/fpsyg.2011.00060</pub-id><pub-id pub-id-type="pmid">21716580</pub-id></element-citation></ref><ref id="bib33"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Van Rullen</surname><given-names>R</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Perceptual cycles</article-title><source>Trends in Cognitive Sciences</source><volume>20</volume><fpage>723</fpage><lpage>735</lpage><pub-id pub-id-type="doi">10.1016/j.tics.2016.07.006</pub-id><pub-id pub-id-type="pmid">27567317</pub-id></element-citation></ref></ref-list></back><sub-article article-type="editor-report" id="sa0"><front-stub><article-id pub-id-type="doi">10.7554/eLife.91129.sa0</article-id><title-group><article-title>Editor's evaluation</article-title></title-group><contrib-group><contrib contrib-type="author"><name><surname>Sharpee</surname><given-names>Tatyana O</given-names></name><role specific-use="editor">Reviewing Editor</role><aff><institution-wrap><institution-id institution-id-type="ror">https://ror.org/03xez1567</institution-id><institution>Salk Institute for Biological Studies</institution></institution-wrap><country>United States</country></aff></contrib></contrib-group><related-object id="sa0ro1" object-id-type="id" object-id="10.1101/2023.07.19.549668" link-type="continued-by" xlink:href="https://sciety.org/articles/activity/10.1101/2023.07.19.549668"/></front-stub><body><p>This important study adds to the growing body of evidence that neural responses fluctuate in time to alternatively represent one among multiple concurrent stimuli and that these fluctuations seize when objects fuse into one perceived object. The present study provides solid evidence from multiple brain areas and stimuli types to support this hypothesis. Overall, the study illustrates how the brain can use time dimension and synchrony to either parse or integrate stimuli into a coherent representation.</p></body></sub-article><sub-article article-type="decision-letter" id="sa1"><front-stub><article-id pub-id-type="doi">10.7554/eLife.91129.sa1</article-id><title-group><article-title>Decision letter</article-title></title-group><contrib-group content-type="section"><contrib contrib-type="editor"><name><surname>Sharpee</surname><given-names>Tatyana O</given-names></name><role>Reviewing Editor</role><aff><institution-wrap><institution-id institution-id-type="ror">https://ror.org/03xez1567</institution-id><institution>Salk Institute for Biological Studies</institution></institution-wrap><country>United States</country></aff></contrib></contrib-group></front-stub><body><boxed-text id="sa2-box1"><p>Our editorial process produces two outputs: (i) <ext-link ext-link-type="uri" xlink:href="https://sciety.org/articles/activity/10.1101/2023.07.19.549668">public reviews</ext-link> designed to be posted alongside <ext-link ext-link-type="uri" xlink:href="https://www.biorxiv.org/content/10.1101/2023.07.19.549668v1">the preprint</ext-link> for the benefit of readers; (ii) feedback on the manuscript for the authors, including requests for revisions, shown below. We also include an acceptance summary that explains what the editors found interesting or important about the work.</p></boxed-text><p><bold>Decision letter after peer review:</bold></p><p>Thank you for submitting your article &quot;Multiple objects evoke fluctuating responses in several regions of the visual pathway&quot; for consideration by <italic>eLife</italic>. Your article has been reviewed by 2 peer reviewers, and the evaluation has been overseen by a Reviewing Editor and Joshua Gold as the Senior Editor.</p><p>The reviewers have discussed their reviews with one another, and the Reviewing Editor has drafted this to help you prepare a revised submission.</p><p>Essential revisions:</p><p>Please revise to more appropriately place the work in the context of prior studies and address possible confounds from differences in attention and statistical analyses related to selection criteria for microsaccades and spike train smoothing.</p><p><italic>Reviewer #1 (Recommendations for the authors):</italic></p><p>Attention state: On p. 5. It is stated that the &quot;stimuli in question … were unattended&quot;. Could you elaborate how this was controlled? When maintain central fixation under passive viewing conditions, stimuli presented in the periphery are typically not ignored, but at least partially attended (unless one engages the participant in a highly demanding task at fixation). How did attention state factor into the results given the work of Engel and Moore on fluctuating firing patterns due to attentional state?</p><p>Microsaccades: Given that microsaccades (MSs) might play an important role in the modulation of firing patterns it is important to control for them. MSs were defined as &quot;time periods during which eye speed exceeded 6 standard deviations&quot;. Can you present a control analysis to show what this practically means? MSs have standard definitions and occur along a continuum. It will be important to understand which part of the continuum is excluded by your definition.</p><p><italic>Reviewer #2 (Recommendations for the authors):</italic></p><p>The size of receptive fields in MT and IT may vary quite a bit. The optimal stimulus size may therefore be important information for the reader. To give a better sense of the stimuli used in these experiments, please add scale bars to panels in Figure 1.</p><p>Please clarify the time window on the x-axis when showing spike counts, such as in Figure 4. Can this be interpreted as spikes/second, or converted into spikes/second when analyzing a shorter time window? This is especially relevant when looking at the overall spike counts in relation to other studies. Whereas some previous work has shown vigorous spiking for faces in IT face patches, the spike counts for preferred faces of ~5 spikes seems very low. However, if this is not yet converted into spikes/second, it may be difficult to compare. Note: there may be good reasons to stick to total spike count instead of spike rate. If so, please just clarify this in the figure caption to give the reader an idea of what the spike rate may be.</p><p>Unless this goes against the journal guidelines, please improve the readability of statistical results by rounding the p-values such that they are not a long list of zeros (Figure 3e) or overly precise (e.g. Figure 4g).</p></body></sub-article><sub-article article-type="reply" id="sa2"><front-stub><article-id pub-id-type="doi">10.7554/eLife.91129.sa2</article-id><title-group><article-title>Author response</article-title></title-group></front-stub><body><disp-quote content-type="editor-comment"><p>Essential revisions:</p><p>Please revise to more appropriately place the work in the context of prior studies and address possible confounds from differences in attention and statistical analyses related to selection criteria for microsaccades and spike train smoothing.</p></disp-quote><p>We are grateful for all the reviewer comments and the “license” to expand the scope of the literature to which we think this work relates. We have expanded the introduction and discussion to incorporate additional coverage of exciting relevant literature in the domains of attention and fluctuating states in the nervous system as revealed by other studies. We have also clarified procedures related to spike train smoothing and incorporated raw data into the relevant figures. With regard to microsaccades, we have addressed omissions in the methods section regarding fixation control more generally, and we present below a more detailed summary of relevant parameters and previous analyses.</p><disp-quote content-type="editor-comment"><p>Reviewer #1 (Recommendations for the authors):</p><p>Attention state: On p. 5. It is stated that the &quot;stimuli in question … were unattended&quot;. Could you elaborate how this was controlled? When maintain central fixation under passive viewing conditions, stimuli presented in the periphery are typically not ignored, but at least partially attended (unless one engages the participant in a highly demanding task at fixation). How did attention state factor into the results given the work of Engel and Moore on fluctuating firing patterns due to attentional state?</p></disp-quote><p>We appreciate this comment – we have revised the text to indicate that the monkeys were directed to fixate away from the stimuli in question, but we recognize that eye position may not be informative about where attention was directed during each trial. We have rewritten this section to clarify:</p><p>“Our goal was to assess fluctuating neural activity in multiple visual areas and in response to multiple stimuli (Table 1). In all datasets, fixation was controlled while the stimuli were presented (0.5-1.2 degree fixation window radius, depending on the dataset). In some datasets, monkeys performed a behavioral task in which attention was directed away from the stimuli, such as to the fixation position itself or to an additional stimulus in the ipsilateral hemifield. In the fixation-only tasks, it should be noted that the absence of experimental control over attention could have led to the monkeys covertly attending the receptive field stimuli from time to time.” (Methods, Introduction to Datasets, para 2).</p><p>Nevertheless, we do not think that a varying locus of attention during fixation can fully account for fluctuating activity. If this were the case, we would have expected to see fluctuating activity in all the datasets that involved passive fixation, including the MT “superimposed gratings” dataset, but we do not. Accordingly, we now include this argument in the discussion, while acknowledging that the ideal scenario would be to deliberately test the findings in an attention task:</p><p>“For example, the variation in behavioral tasks but consistency of results across datasets suggests that attentional task performance (or, conversely, lack of attentional control) is not a strong driver of the observed effects, but more work will be needed to fully establish this.” (Discussion, paragraph 6)</p><disp-quote content-type="editor-comment"><p>Microsaccades: Given that microsaccades (MSs) might play an important role in the modulation of firing patterns it is important to control for them. MSs were defined as &quot;time periods during which eye speed exceeded 6 standard deviations&quot;. Can you present a control analysis to show what this practically means? MSs have standard definitions and occur along a continuum. It will be important to understand which part of the continuum is excluded by your definition.</p></disp-quote><p>We address this comment at both the specific and conceptual levels:</p><p>First, at the conceptual level, given that our analysis focused on trial-by-trial spike counts, the main concern would be fluctuations in fixation across trials; any affects of microsaccades within trials would likely muddy this analysis but not serve as a confound (especially given the short duration of the spike counting windows – a mere 200 ms does not allow much time for a stimulus-triggered microsaccade to cause the stimulus to land on a different portion of the retina and be reflected in the spike count on that trial).</p><p>That said, this comment made us aware that we had failed to include information about the size of the fixation windows for the datasets included in this manuscript. We have now included these details in the methods section, first as an overall range:</p><p>“In all datasets, fixation was controlled while the stimuli were presented (0.5-1.2 degree radius, depending on the dataset)”, (Methods, Introduction to datasets para 2),</p><p>and then again where the specific datasets and tasks are described (see tracked changes). Any saccade that caused the eyes to depart from these windows during stimulus presentation would have caused the trials to be excluded.</p><p>Indeed, the actual variation in fixation was probably considerably smaller than these fixation windows. While we do not have the eye tracking data for all datasets, in Jun et al. <italic>eLife</italic> 2018 we did analyze the fixation scatter for the V1 recordings that occurred simultaneously with the MT adjacent gratings dataset in the present study.</p><p>In short, the average deviation of the eyes from the fixation target was less than 0.15 degrees – a tiny amount given the size of MT receptive fields.</p><p>With regard to screening microsaccades specifically, we agree that we should have included more information about how this was done and the precedent for it. The precedent for this screening comes from Engbert and Kliegl (2003), in which microsaccades were defined by eye speeds that exceed 6 standard deviations from the mean speed. We also deployed this method previously in our prior publication involving other recordings from these same sets of experiments (Jun et al. <italic>eLife</italic> 2022). We have expanded the description in “Methods/ Analysis: response periods and inclusion criteria/ Trial inclusion criteria” to explain this more fully:</p><p>“Microsaccades were defined as periods of time in which eye speed exceeded the mean eye speed in the fixation epoch by more than 6 standard deviations following standards established by (Engbert and Kliegl, 2003) and deployed in our previous studies involving these same experiments (Jun et al. 2022, Ruff et al. 2016, Ruff and Cohen 2016)”.</p><disp-quote content-type="editor-comment"><p>Reviewer #2 (Recommendations for the authors):</p><p>The size of receptive fields in MT and IT may vary quite a bit. The optimal stimulus size may therefore be important information for the reader. To give a better sense of the stimuli used in these experiments, please add scale bars to panels in Figure 1.</p></disp-quote><p>We thank the reviewer for this suggestion to increase clarity, and we have added scale bars to this figure, with the exception of the MT dot patch dataset, for which the stimulus sizes were not provided in the original Li et al. study.</p><disp-quote content-type="editor-comment"><p>Please clarify the time window on the x-axis when showing spike counts, such as in Figure 4. Can this be interpreted as spikes/second, or converted into spikes/second when analyzing a shorter time window? This is especially relevant when looking at the overall spike counts in relation to other studies. Whereas some previous work has shown vigorous spiking for faces in IT face patches, the spike counts for preferred faces of ~5 spikes seems very low. However, if this is not yet converted into spikes/second, it may be difficult to compare. Note: there may be good reasons to stick to total spike count instead of spike rate. If so, please just clarify this in the figure caption to give the reader an idea of what the spike rate may be.</p></disp-quote><p>For all analyses, we counted spikes in a window of 200 ms, shifted by the approximate response latency of each brain region (30 to 230 ms after stimulus onset for MT, and 50 to 250 ms after stimulus onset for AL and MF). Therefore, the spike counts shown in these figures should be multiplied by a factor of 5 to give their equivalent values in spikes/second. We have clarified this in the captions of Figures 3 and 4, e.g.:</p><p>“Spike counts were computed for a window 200 ms in duration (see Methods); multiply x-axis by 5 to convert to spike rates in Hz.”</p><disp-quote content-type="editor-comment"><p>Unless this goes against the journal guidelines, please improve the readability of statistical results by rounding the p-values such that they are not a long list of zeros (Figure 3e) or overly precise (e.g. Figure 4g).</p></disp-quote><p>Thank you for catching this. We have rounded the p-values in Figure 4G and Figure 4—figure supplement 1F to two significant digits, which now matches the text. We have also made adjustments to the graphics of these figures so that it is more clear which comparisons these p values relate to. For now, we are leaving the “long list of zeros” p values, which involved the MT adjacent vs. superimposed gratings chi-square test. Technically, the p value returned by the chi-square function in Matlab was zero, with a floating point precision suggesting a value of less than 2.22507e-308. However, we are skeptical that the chi-square test can provide that level of significance for a dataset of this size; we will seek guidance from the journal with regard to how to convey this p value according to their standards.</p></body></sub-article></article>