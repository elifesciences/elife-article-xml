<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD with MathML3 v1.3 20210610//EN"  "JATS-archivearticle1-3-mathml3.dtd"><article xmlns:ali="http://www.niso.org/schemas/ali/1.0/" xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" article-type="research-article" dtd-version="1.3"><front><journal-meta><journal-id journal-id-type="nlm-ta">elife</journal-id><journal-id journal-id-type="publisher-id">eLife</journal-id><journal-title-group><journal-title>eLife</journal-title></journal-title-group><issn publication-format="electronic" pub-type="epub">2050-084X</issn><publisher><publisher-name>eLife Sciences Publications, Ltd</publisher-name></publisher></journal-meta><article-meta><article-id pub-id-type="publisher-id">99545</article-id><article-id pub-id-type="doi">10.7554/eLife.99545</article-id><article-id pub-id-type="doi" specific-use="version">10.7554/eLife.99545.4</article-id><article-version article-version-type="publication-state">version of record</article-version><article-categories><subj-group subj-group-type="display-channel"><subject>Research Article</subject></subj-group><subj-group subj-group-type="heading"><subject>Computational and Systems Biology</subject></subj-group></article-categories><title-group><article-title>Efficient coding in biophysically realistic excitatory-inhibitory spiking networks</article-title></title-group><contrib-group><contrib contrib-type="author" corresp="yes"><name><surname>Koren</surname><given-names>Veronika</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">https://orcid.org/0000-0003-2920-2717</contrib-id><email>v.koren@uke.de</email><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="aff" rid="aff2">2</xref><xref ref-type="aff" rid="aff3">3</xref><xref ref-type="fn" rid="con1"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author"><name><surname>Blanco Malerba</surname><given-names>Simone</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">https://orcid.org/0000-0002-4467-5988</contrib-id><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="other" rid="fund5"/><xref ref-type="fn" rid="con2"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author"><name><surname>Schwalger</surname><given-names>Tilo</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">https://orcid.org/0000-0002-5422-3723</contrib-id><xref ref-type="aff" rid="aff2">2</xref><xref ref-type="aff" rid="aff3">3</xref><xref ref-type="fn" rid="con3"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" corresp="yes"><name><surname>Panzeri</surname><given-names>Stefano</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">https://orcid.org/0000-0003-1700-8909</contrib-id><email>s.panzeri@uke.de</email><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="fn" rid="con4"/><xref ref-type="fn" rid="conf1"/></contrib><aff id="aff1"><label>1</label><institution-wrap><institution-id institution-id-type="ror">https://ror.org/01zgy1s35</institution-id><institution>Institute of Neural Information Processing, Center for Molecular Neurobiology (ZMNH), University Medical Center Hamburg-Eppendorf</institution></institution-wrap><addr-line><named-content content-type="city">Hamburg</named-content></addr-line><country>Germany</country></aff><aff id="aff2"><label>2</label><institution-wrap><institution-id institution-id-type="ror">https://ror.org/03v4gjf40</institution-id><institution>Institute of Mathematics, Technische Universität Berlin</institution></institution-wrap><addr-line><named-content content-type="city">Berlin</named-content></addr-line><country>Germany</country></aff><aff id="aff3"><label>3</label><institution-wrap><institution-id institution-id-type="ror">https://ror.org/05ewdps05</institution-id><institution>Bernstein Center for Computational Neuroscience Berlin</institution></institution-wrap><addr-line><named-content content-type="city">Berlin</named-content></addr-line><country>Germany</country></aff></contrib-group><contrib-group content-type="section"><contrib contrib-type="editor"><name><surname>Naud</surname><given-names>Richard</given-names></name><role>Reviewing Editor</role><aff><institution-wrap><institution-id institution-id-type="ror">https://ror.org/03c4mmv16</institution-id><institution>University of Ottawa</institution></institution-wrap><country>Canada</country></aff></contrib><contrib contrib-type="senior_editor"><name><surname>Poirazi</surname><given-names>Panayiota</given-names></name><role>Senior Editor</role><aff><institution-wrap><institution-id institution-id-type="ror">https://ror.org/01gzszr18</institution-id><institution>FORTH Institute of Molecular Biology and Biotechnology</institution></institution-wrap><country>Greece</country></aff></contrib></contrib-group><pub-date publication-format="electronic" date-type="publication"><day>07</day><month>03</month><year>2025</year></pub-date><volume>13</volume><elocation-id>RP99545</elocation-id><history><date date-type="sent-for-review" iso-8601-date="2024-05-28"><day>28</day><month>05</month><year>2024</year></date></history><pub-history><event><event-desc>This manuscript was published as a preprint.</event-desc><date date-type="preprint" iso-8601-date="2024-04-27"><day>27</day><month>04</month><year>2024</year></date><self-uri content-type="preprint" xlink:href="https://doi.org/10.1101/2024.04.24.590955"/></event><event><event-desc>This manuscript was published as a reviewed preprint.</event-desc><date date-type="reviewed-preprint" iso-8601-date="2024-07-26"><day>26</day><month>07</month><year>2024</year></date><self-uri content-type="reviewed-preprint" xlink:href="https://doi.org/10.7554/eLife.99545.1"/></event><event><event-desc>The reviewed preprint was revised.</event-desc><date date-type="reviewed-preprint" iso-8601-date="2025-01-22"><day>22</day><month>01</month><year>2025</year></date><self-uri content-type="reviewed-preprint" xlink:href="https://doi.org/10.7554/eLife.99545.2"/></event><event><event-desc>The reviewed preprint was revised.</event-desc><date date-type="reviewed-preprint" iso-8601-date="2025-01-30"><day>30</day><month>01</month><year>2025</year></date><self-uri content-type="reviewed-preprint" xlink:href="https://doi.org/10.7554/eLife.99545.3"/></event></pub-history><permissions><copyright-statement>© 2024, Koren et al</copyright-statement><copyright-year>2024</copyright-year><copyright-holder>Koren et al</copyright-holder><ali:free_to_read/><license xlink:href="http://creativecommons.org/licenses/by/4.0/"><ali:license_ref>http://creativecommons.org/licenses/by/4.0/</ali:license_ref><license-p>This article is distributed under the terms of the <ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/licenses/by/4.0/">Creative Commons Attribution License</ext-link>, which permits unrestricted use and redistribution provided that the original author and source are credited.</license-p></license></permissions><self-uri content-type="pdf" xlink:href="elife-99545-v1.pdf"/><self-uri content-type="figures-pdf" xlink:href="elife-99545-figures-v1.pdf"/><abstract><p>The principle of efficient coding posits that sensory cortical networks are designed to encode maximal sensory information with minimal metabolic cost. Despite the major influence of efficient coding in neuroscience, it has remained unclear whether fundamental empirical properties of neural network activity can be explained solely based on this normative principle. Here, we derive the structural, coding, and biophysical properties of excitatory-inhibitory recurrent networks of spiking neurons that emerge directly from imposing that the network minimizes an instantaneous loss function and a time-averaged performance measure enacting efficient coding. We assumed that the network encodes a number of independent stimulus features varying with a time scale equal to the membrane time constant of excitatory and inhibitory neurons. The optimal network has biologically plausible biophysical features, including realistic integrate-and-fire spiking dynamics, spike-triggered adaptation, and a non-specific excitatory external input. The excitatory-inhibitory recurrent connectivity between neurons with similar stimulus tuning implements feature-specific competition, similar to that recently found in visual cortex. Networks with unstructured connectivity cannot reach comparable levels of coding efficiency. The optimal ratio of excitatory vs inhibitory neurons and the ratio of mean inhibitory-to-inhibitory vs excitatory-to-inhibitory connectivity are comparable to those of cortical sensory networks. The efficient network solution exhibits an instantaneous balance between excitation and inhibition. The network can perform efficient coding even when external stimuli vary over multiple time scales. Together, these results suggest that key properties of biological neural networks may be accounted for by efficient coding.</p></abstract><abstract abstract-type="plain-language-summary"><title>eLife digest</title><p>The networks of nerve cells that make up the brain are complex and versatile. They enable the information processing necessary for both simple and complex thought processes. But, the organization of nerve networks in the brain is a topic of great debate among scientists.</p><p>One idea is that nerve cell networks in the brain are organized to be as efficient as possible at transmitting information. Scientists supporting this idea say it allows the brain to send accurate information using as little energy as possible.</p><p>Scientists have developed mathematical models to explain how this efficient coding model of brain activity works. But how accurately these mathematical models capture complex brain tasks is up for debate. Some question how well these models explain how the brain makes sense of sensory information like sights or smells. Are they able to explain nerve cell organization or how nerve cells react to new information or experiences? Scientists also question how well the mathematical models capture biological and physical constraints on nerve cell activity.</p><p>To answer these questions, Koren et al. used mathematical models to systematically test whether the efficient coding model was consistent with what happens in realistic circumstances. The experiments show that mathematical models of efficient coding are consistent with actual brain cell behavior, organization and interconnections. The models also reflected the cells’ biological and physical constraints.</p><p>The experiments support the idea that brain networks are designed for efficiency. But the models used in the study are too simple to assess the full range and complexity of information processing in the brain. More studies are needed to test more complex mathematical models that better recreate more advanced brain activities. Further study of the biological and physical constraints on nerve cells in the brain may shed more light on how they behave in brain networks.</p></abstract><kwd-group kwd-group-type="author-keywords"><kwd>efficient coding</kwd><kwd>spiking neural network</kwd><kwd>excitatory-inhibitory balance</kwd><kwd>optimal connectivity</kwd><kwd>optimality</kwd><kwd>neural coding</kwd></kwd-group><kwd-group kwd-group-type="research-organism"><title>Research organism</title><kwd>None</kwd></kwd-group><funding-group><award-group id="fund1"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/501100006764</institution-id><institution>Technische Universität Berlin</institution></institution-wrap></funding-source><award-id>Equal Opportunity Program</award-id><principal-award-recipient><name><surname>Koren</surname><given-names>Veronika</given-names></name></principal-award-recipient></award-group><award-group id="fund2"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/501100006764</institution-id><institution>Technische Universität Berlin</institution></institution-wrap></funding-source><award-id>Internal Research Funding</award-id><principal-award-recipient><name><surname>Schwalger</surname><given-names>Tilo</given-names></name></principal-award-recipient></award-group><award-group id="fund3"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/100000002</institution-id><institution>NIH BRAIN Initiative</institution></institution-wrap></funding-source><award-id>U19 NS107464</award-id><principal-award-recipient><name><surname>Panzeri</surname><given-names>Stefano</given-names></name></principal-award-recipient></award-group><award-group id="fund4"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/100014370</institution-id><institution>Simons Foundation Autism Research Initiative</institution></institution-wrap></funding-source><award-id>982347</award-id><principal-award-recipient><name><surname>Panzeri</surname><given-names>Stefano</given-names></name></principal-award-recipient></award-group><award-group id="fund5"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/100018694</institution-id><institution>Marie Sklodowska-Curie Actions</institution></institution-wrap></funding-source><award-id award-id-type="doi">10.3030/101152984</award-id><principal-award-recipient><name><surname>Blanco Malerba</surname><given-names>Simone</given-names></name></principal-award-recipient></award-group><award-group id="fund6"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/100000002</institution-id><institution>NIH BRAIN Initiative</institution></institution-wrap></funding-source><award-id>R01 NS109961</award-id><principal-award-recipient><name><surname>Panzeri</surname><given-names>Stefano</given-names></name></principal-award-recipient></award-group><award-group id="fund7"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/100000002</institution-id><institution>NIH BRAIN Initiative</institution></institution-wrap></funding-source><award-id>R01 NS108410</award-id><principal-award-recipient><name><surname>Panzeri</surname><given-names>Stefano</given-names></name></principal-award-recipient></award-group><funding-statement>The funders had no role in study design, data collection and interpretation, or the decision to submit the work for publication.</funding-statement></funding-group><custom-meta-group><custom-meta specific-use="meta-only"><meta-name>Author impact statement</meta-name><meta-value>Recurrent spiking networks that process input stimuli with optimal efficiency have key emerging properties that are similar to those of biological neural networks.</meta-value></custom-meta><custom-meta specific-use="meta-only"><meta-name>publishing-route</meta-name><meta-value>prc</meta-value></custom-meta></custom-meta-group></article-meta></front><body><sec id="s1" sec-type="intro"><title>Introduction</title><p>Information about the sensory world is represented in the brain through the dynamics of neural population activity (<xref ref-type="bibr" rid="bib2">Abbott et al., 2016</xref>; <xref ref-type="bibr" rid="bib99">Thalmeier et al., 2016</xref>). One prominent theory about the principles that may guide the design of neural computations for sensory function is efficient coding (<xref ref-type="bibr" rid="bib6">Barlow, 1961</xref>; <xref ref-type="bibr" rid="bib73">Olshausen and Field, 1996</xref>; <xref ref-type="bibr" rid="bib27">Deneve and Chalk, 2016a</xref>). This theory posits that neural computations are optimized to maximize the information that neural systems encode about sensory stimuli while at the same time limiting the metabolic cost of neural activity. Efficient coding has been highly influential as a normative theory of how networks are organized and designed to optimally process natural sensory stimuli in visual (<xref ref-type="bibr" rid="bib5">Atick, 1992</xref>; <xref ref-type="bibr" rid="bib74">Olshausen and Field, 1997</xref>; <xref ref-type="bibr" rid="bib93">Simoncelli and Olshausen, 2001</xref>; <xref ref-type="bibr" rid="bib104">Vinje and Gallant, 2000</xref>; <xref ref-type="bibr" rid="bib75">Olshausen and Field, 2004</xref>; <xref ref-type="bibr" rid="bib57">Li, 2014</xref>), auditory (<xref ref-type="bibr" rid="bib56">Lewicki, 2002</xref>), and olfactory sensory pathways (<xref ref-type="bibr" rid="bib52">Koulakov and Rinberg, 2011</xref>).</p><p>The first normative neural network models (<xref ref-type="bibr" rid="bib73">Olshausen and Field, 1996</xref>; <xref ref-type="bibr" rid="bib75">Olshausen and Field, 2004</xref>) designed with efficient coding principles had at least two major levels of abstractions. First, neural dynamics was greatly simplified, ignoring the spiking nature of neural activity. Instead, biological networks often encode information through millisecond-precise spike timing (<xref ref-type="bibr" rid="bib8">Bialek et al., 1991</xref>; <xref ref-type="bibr" rid="bib9">Bialek and Rieke, 1992</xref>; <xref ref-type="bibr" rid="bib77">Panzeri et al., 2001</xref>; <xref ref-type="bibr" rid="bib69">Nemenman et al., 2008</xref>; <xref ref-type="bibr" rid="bib47">Kayser et al., 2010</xref>; <xref ref-type="bibr" rid="bib43">Ince et al., 2013</xref>; <xref ref-type="bibr" rid="bib78">Panzeri et al., 2010</xref>). Second, these earlier contributions mostly considered encoding of static sensory stimuli, whereas the sensory environment changes continuously at multiple timescales and the dynamics of neural networks encodes these temporal variations of the environment (<xref ref-type="bibr" rid="bib34">Fairhall et al., 2001</xref>; <xref ref-type="bibr" rid="bib106">Wark et al., 2009</xref>; <xref ref-type="bibr" rid="bib63">Mazzoni et al., 2008</xref>; <xref ref-type="bibr" rid="bib65">Młynarski and Hermundstad, 2021</xref>).</p><p>Recent years have witnessed a considerable effort and success in laying down the mathematical tools and methodology to understand how to formulate efficient coding theories of neural networks with more biological realism (<xref ref-type="bibr" rid="bib50">Koren et al., 2023</xref>). This effort has established the incorporation of recurrent connectivity (<xref ref-type="bibr" rid="bib58">Lochmann et al., 2012</xref>; <xref ref-type="bibr" rid="bib111">Zhu and Rozell, 2013</xref>), of spiking neurons, and of time-varying stimulus inputs (<xref ref-type="bibr" rid="bib11">Boerlin et al., 2013</xref>; <xref ref-type="bibr" rid="bib12">Bourdoukan et al., 2012</xref>; <xref ref-type="bibr" rid="bib66">Moreno-Bote and Drugowitsch, 2015</xref>; <xref ref-type="bibr" rid="bib20">Chalk et al., 2016</xref>; <xref ref-type="bibr" rid="bib28">Deneve and Machens, 2016b</xref>; <xref ref-type="bibr" rid="bib39">Gutierrez and Denève, 2019</xref>; <xref ref-type="bibr" rid="bib45">Kadmon et al., 2020</xref>; <xref ref-type="bibr" rid="bib84">Rullán Buxó and Pillow, 2020</xref>). In these models, the efficient coding principle has been implemented by designing networks whose activity maximizes the encoding accuracy, by minimizing the error between a desired representation and a linear readout of network’s activity, subject to a constraint on the metabolic cost of processing. This double objective is captured by a loss function that trades off encoding accuracy and metabolic cost. The minimization of the loss function is performed through a greedy approach, by assuming that a neuron will emit a spike only if this will decrease the loss. This, in turn, yields a set of leaky integrate-and-fire (LIF) neural equations (<xref ref-type="bibr" rid="bib11">Boerlin et al., 2013</xref>; <xref ref-type="bibr" rid="bib12">Bourdoukan et al., 2012</xref>), which can also include biologically plausible non-instantaneous synaptic delays (<xref ref-type="bibr" rid="bib48">Koren and Denève, 2017</xref>; <xref ref-type="bibr" rid="bib84">Rullán Buxó and Pillow, 2020</xref>; <xref ref-type="bibr" rid="bib45">Kadmon et al., 2020</xref>). Although most initial implementations did not respect Dale’s law, further studies analytically derived efficient networks of excitatory (E) and inhibitory (I) spiking neurons that respect Dale’s law (<xref ref-type="bibr" rid="bib11">Boerlin et al., 2013</xref>; <xref ref-type="bibr" rid="bib7">Barrett et al., 2016</xref>; <xref ref-type="bibr" rid="bib20">Chalk et al., 2016</xref>; <xref ref-type="bibr" rid="bib49">Koren and Panzeri, 2022</xref>) and included spike-triggered adaptation (<xref ref-type="bibr" rid="bib49">Koren and Panzeri, 2022</xref>). These networks take the form of generalized leaky integrate-and-fire (gLIF) models neurons, which are realistic models of neuronal activity (<xref ref-type="bibr" rid="bib14">Brette and Gerstner, 2005</xref>; <xref ref-type="bibr" rid="bib64">Mensi et al., 2012</xref>; <xref ref-type="bibr" rid="bib37">Gerstner et al., 2014</xref>) and capable of accurately predicting real neural spike times in vivo (<xref ref-type="bibr" rid="bib44">Jolivet et al., 2008</xref>). Efficient spiking models thus have the potential to provide a normative theory of neural coding through spiking dynamics of E-I circuits (<xref ref-type="bibr" rid="bib13">Brendel et al., 2020</xref>; <xref ref-type="bibr" rid="bib49">Koren and Panzeri, 2022</xref>; <xref ref-type="bibr" rid="bib80">Podlaski and Machens, 2024</xref>) with high biological plausibility.</p><p>However, despite the major progress described above, we still lack a thorough characterization of which structural, coding, biophysical and dynamical properties of excitatory- inhibitory recurrent spiking neural networks directly relate to efficient coding. Previous studies only rarely made predictions that could be quantitatively compared against experimentally measurable biological properties. As a consequence, we still do not know which, if any, fundamental properties of cortical networks emerge directly from efficient coding.</p><p>To address the above questions, we systematically analyze our biologically plausible efficient coding model of E and I neurons that respects Dale’s law (<xref ref-type="bibr" rid="bib49">Koren and Panzeri, 2022</xref>). We make concrete predictions about experimentally measurable structural, coding and dynamical features of neurons that arise from efficient coding. We systematically investigate how experimentally measurable emergent dynamical properties, including firing rates, trial-to-trial spiking variability of single neurons and E-I balance (<xref ref-type="bibr" rid="bib105">Vogels et al., 2011</xref>), relate to network optimality. We further analyze how the organization of the connectivity arising by imposing efficient coding relates to the anatomical and effective connectivity recently reported in visual cortex, which suggests competition between excitatory neurons with similar stimulus tuning. We find that several key and robustly found empirical properties of cortical circuits match those of our efficient coding network. This lends support to the notion that efficient coding may be a design principle that has shaped the evolution of cortical circuits and that may be used to conceptually understand and interpret them.</p></sec><sec id="s2" sec-type="results"><title>Results</title><sec id="s2-1"><title>Assumptions and emergent structural properties of the efficient E-I network derived from first principles</title><p>We study the properties of a spiking neural network in which the dynamics and structure of the network are analytically derived starting from first principles of efficient coding of sensory stimuli. The model relies on a number of assumptions, described next.</p><p>The network responds to <inline-formula><mml:math id="inf1"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>M</mml:mi></mml:mstyle></mml:math></inline-formula> time-varying features of a sensory stimulus, <inline-formula><mml:math id="inf2"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mrow><mml:mover><mml:mi>s</mml:mi><mml:mo stretchy="false">→</mml:mo></mml:mover></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mo stretchy="false">[</mml:mo><mml:msub><mml:mi>s</mml:mi><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>,</mml:mo><mml:mo>…</mml:mo><mml:mo>,</mml:mo><mml:msub><mml:mi>s</mml:mi><mml:mrow><mml:mi>M</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:msup><mml:mo stretchy="false">]</mml:mo><mml:mi mathvariant="normal">⊤</mml:mi></mml:msup></mml:mrow></mml:mstyle></mml:math></inline-formula> (e.g. for a visual stimulus, contrast, orientation, etc.) received as inputs from an earlier sensory area. We model each feature <inline-formula><mml:math id="inf3"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>s</mml:mi><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mstyle></mml:math></inline-formula> as an independent Ornstein–Uhlenbeck (OU) processes (see Materials and methods). The network’s objective is to compute a leaky integration of sensory features; the target representations of the network, <inline-formula><mml:math id="inf4"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mover><mml:mi>x</mml:mi><mml:mo stretchy="false">→</mml:mo></mml:mover></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mstyle></mml:mrow></mml:mstyle></mml:math></inline-formula>, is defined as<disp-formula id="equ1"><label>(1)</label><mml:math id="m1"><mml:mrow><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mover><mml:mrow><mml:mover><mml:mi>x</mml:mi><mml:mo>˙</mml:mo></mml:mover></mml:mrow><mml:mo stretchy="false">→</mml:mo></mml:mover></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mo>−</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mi>τ</mml:mi></mml:mfrac><mml:mrow><mml:mover><mml:mi>x</mml:mi><mml:mo stretchy="false">→</mml:mo></mml:mover></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>+</mml:mo><mml:mrow><mml:mover><mml:mi>s</mml:mi><mml:mo stretchy="false">→</mml:mo></mml:mover></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>,</mml:mo></mml:mstyle></mml:mrow></mml:math></disp-formula></p><p>with <inline-formula><mml:math id="inf5"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>τ</mml:mi></mml:mstyle></mml:math></inline-formula> a characteristic integration time-scale (<xref ref-type="fig" rid="fig1">Figure 1A(i)</xref>). We assumed leaky integration of sensory features for consistency with previous theoretical models (<xref ref-type="bibr" rid="bib7">Barrett et al., 2016</xref>; <xref ref-type="bibr" rid="bib20">Chalk et al., 2016</xref>; <xref ref-type="bibr" rid="bib39">Gutierrez and Denève, 2019</xref>). This assumption stems from the finding that, in many cases, integration of sensory evidence by neurons is well described by an exponential kernel (<xref ref-type="bibr" rid="bib91">Scott et al., 2017</xref>; <xref ref-type="bibr" rid="bib26">Danskin et al., 2023</xref>). Additionally, a leaky integration of neural activity with an exponential kernel implemented in models of neural activity readout often explains well the perceptual discrimination results (<xref ref-type="bibr" rid="bib38">Gold and Shadlen, 2001</xref>; <xref ref-type="bibr" rid="bib102">Usher and McClelland, 2001</xref>; <xref ref-type="bibr" rid="bib23">Chong et al., 2020</xref>). This suggests that the assumption of leaky integration of sensory evidence, although possibly simplistic, captures relevant aspects of neural computations.</p><fig-group><fig id="fig1" position="float"><label>Figure 1.</label><caption><title>Structural and dynamical properties of the efficient E-I spiking network.</title><p>(<bold>A, i</bold>) Encoding of a target signal representing the evolution of a stimulus feature (top) with one E (middle) and one I spiking neuron (bottom). The target signal <inline-formula><mml:math id="inf6"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>x</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mstyle></mml:mrow></mml:mstyle></mml:math></inline-formula> integrates the input signal <inline-formula><mml:math id="inf7"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>s</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mstyle></mml:math></inline-formula>. The readout of the E neuron tracks the target signal and the readout of the I neuron tracks the readout of the E neuron. Neurons spike to bring the readout of their activity closer to their respective target. Each spike causes a jump of the readout, with the sign and the amplitude of the jump being determined by neuron’s tuning parameters. (ii) Schematic of the matrix of tuning parameters. Every neuron is selective to all stimulus features (columns of the matrix), and all neurons participate in encoding of every feature (rows). (<bold>B, i</bold>) Schematic of the network with E (red) and I (blue) cell type. E neurons are driven by the stimulus features while I neurons are driven by the activity of E neurons. E and I neurons are connected through recurrent connectivity matrices. (ii) Schematic of E (red) and I (blue) synaptic interactions. Arrows represent the direction of the tuning vector of each neuron. Only neurons with similar tuning are connected and the connection strength is proportional to the tuning similarity. (<bold>C, i</bold>) Schematic of similarity of tuning vectors (tuning similarity) in a 2-dimensional space of stimulus features. (ii) Synaptic strength as a function of tuning similarity. (<bold>D</bold>) Coding and dynamics in a simulation trial. Top three rows show the signal (black), the E estimate (red) and the I estimate (blue) for each of the three stimulus features. Below are the spike trains. In the bottom row, we show the average instantaneous firing rate (in Hz). (<bold>E</bold>) Top: Example of the target signal (black) and the E estimate in three simulation trials (colors) for one stimulus feature. Bottom: Distribution (across time) of the time-dependent bias of estimates in E and I cell type. (<bold>F</bold>) Left: Distribution of time-averaged firing rates in E (top) and I neurons (bottom). Black traces are fits with log-normal distribution. Right: Distribution of coefficients of variation of interspike intervals for E and I neurons. (<bold>G</bold>) Distribution (across neurons) of time-averaged synaptic inputs to E (left) and I neurons (right). In E neurons, the mean of distributions of inhibitory and of net synaptic inputs are very close. (<bold>H</bold>) Sum of synaptic inputs over time in a single E (top) and I neuron (bottom) in a simulation trial. (<bold>I</bold>) Distribution (across neurons) of Pearson’s correlation coefficients measuring the correlation of synaptic inputs <inline-formula><mml:math id="inf8"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msup><mml:mi>A</mml:mi><mml:mrow><mml:mi>E</mml:mi><mml:mi>y</mml:mi></mml:mrow></mml:msup></mml:mrow></mml:mstyle></mml:math></inline-formula> and <inline-formula><mml:math id="inf9"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msup><mml:mi>A</mml:mi><mml:mrow><mml:mi>I</mml:mi><mml:mi>y</mml:mi></mml:mrow></mml:msup></mml:mrow></mml:mstyle></mml:math></inline-formula> (as defined in Materials and methods, <xref ref-type="disp-formula" rid="equ59">Equation 43</xref>) in single E (red) and I (blue) neurons. All statistical results (<bold>E–F, H–I</bold>) were computed on 10 simulation trials of 10 s duration. For model parameters, see <xref ref-type="table" rid="table1">Table 1</xref>.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-99545-fig1-v1.tif"/></fig><fig id="fig1s1" position="float" specific-use="child-fig"><label>Figure 1—figure supplement 1.</label><caption><title>Efficient spiking model with one cell type and the encoding bias of the E-I network.</title><p>(<bold>A</bold>) Schematic of efficient coding with a single spiking neuron. In this toy example, the neuron has a positive decoding weight and responds to a single stimulus feature <inline-formula><mml:math id="inf10"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>s</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mstyle></mml:math></inline-formula> (top). The target signal <inline-formula><mml:math id="inf11"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>x</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mstyle></mml:math></inline-formula> (bottom, black) integrates the stimulus feature from top. The neuron spikes to keep the readout of its activity <inline-formula><mml:math id="inf12"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mrow><mml:mover><mml:mi>x</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mstyle></mml:math></inline-formula> (magenta) close to the target. (<bold>B</bold>) Schematic of an efficient 1CT model. The target signal is computed from the stimulus feature. The spiking network estimates the targets by generating population readouts of its spiking activity. (<bold>C</bold>) Schematic of excitatory (red) and inhibitory (blue) synaptic interactions in the 1CT model. Neurons with similar selectivity inhibit each other (blue), while neurons with different selectivity excite each other (red). The same neuron is sending excitatory and inhibitory synaptic outputs, which is not consistent with Dale’s law. (<bold>D</bold>) Strength of recurrent synapses as a function of pair-wise tuning similarity. (<bold>E</bold>) Simulation of the model with 1CT. Top three rows show the target (black), and the estimate (magenta) in each of the 3 input dimensions. (<bold>F</bold>) Top left: The target (black) and the estimate (red) of the E population in the first signal dimension (in response to the first stimulus feature <inline-formula><mml:math id="inf13"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>s</mml:mi><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mstyle></mml:math></inline-formula>). The estimate is averaged across 100 trials, with trials varying about the initial conditions and the noise in the membrane potential. Bottom left: Same as on top left, for the I population. Right: Time-dependent bias of estimates in E (top) and I (bottom) population in each of the three stimulus dimensions. (<bold>G</bold>) Left: Root mean squared error (RMSE) as a function of the metabolic constant <inline-formula><mml:math id="inf14"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msup><mml:mi>β</mml:mi><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:mstyle></mml:math></inline-formula>. Right: Normalized metabolic cost (green) and normalized average loss (black) as a function of the metabolic constant <inline-formula><mml:math id="inf15"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msup><mml:mi>β</mml:mi><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:mstyle></mml:math></inline-formula>. The black arrow denotes the minimum of the loss and thus the optimal parameter <inline-formula><mml:math id="inf16"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msup><mml:mi>β</mml:mi><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:mstyle></mml:math></inline-formula>. (<bold>H</bold>) Same as in <bold>G</bold>, measured as a function of the noise strength <inline-formula><mml:math id="inf17"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msup><mml:mi>σ</mml:mi><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:mstyle></mml:math></inline-formula>. Results in F, G and H were computed in 100 simulation trials of duration of 1 second. For other parameters, see <xref ref-type="table" rid="table1">Table 1</xref> (E-I model) and Appendix 3 (1CT model).</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-99545-fig1-figsupp1-v1.tif"/></fig></fig-group><p>The network is composed of two neural populations of excitatory (E) and inhibitory (I) neurons, defined by their postsynaptic action which respects Dale’s law. For each population, <inline-formula><mml:math id="inf18"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>y</mml:mi><mml:mo>∈</mml:mo><mml:mo fence="false" stretchy="false">{</mml:mo><mml:mi>E</mml:mi><mml:mo>,</mml:mo><mml:mi>I</mml:mi><mml:mo fence="false" stretchy="false">}</mml:mo></mml:mstyle></mml:math></inline-formula>, we define a population readout of each feature, <inline-formula><mml:math id="inf19"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msup><mml:mrow><mml:mover><mml:mrow><mml:mrow><mml:mover><mml:mi>x</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow></mml:mrow><mml:mo stretchy="false">→</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>y</mml:mi></mml:mrow></mml:msup><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mstyle></mml:math></inline-formula>, as a filtered weighted sum of spiking activity of neurons in the population,<disp-formula id="equ2"><label>(2)</label><mml:math id="m2"><mml:mrow><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msup><mml:mrow><mml:mover><mml:mrow><mml:mover><mml:mrow><mml:mover><mml:mi>x</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mo>˙</mml:mo></mml:mover></mml:mrow><mml:mo stretchy="false">→</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mspace width="thinmathspace"/><mml:mi>y</mml:mi></mml:mrow></mml:msup><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mo>−</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mi>τ</mml:mi></mml:mfrac><mml:msup><mml:mrow><mml:mover><mml:mrow><mml:mover><mml:mi>x</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mo stretchy="false">→</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mspace width="thinmathspace"/><mml:mi>y</mml:mi></mml:mrow></mml:msup><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>+</mml:mo><mml:munderover><mml:mo>∑</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:msup><mml:mi>N</mml:mi><mml:mrow><mml:mspace width="thinmathspace"/><mml:mi>y</mml:mi></mml:mrow></mml:msup></mml:mrow></mml:munderover><mml:msubsup><mml:mrow><mml:mover><mml:mi>w</mml:mi><mml:mo stretchy="false">→</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mspace width="thinmathspace"/><mml:mi>y</mml:mi></mml:mrow></mml:msubsup><mml:msubsup><mml:mi>f</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mspace width="thinmathspace"/><mml:mi>y</mml:mi></mml:mrow></mml:msubsup><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>,</mml:mo></mml:mstyle></mml:mrow></mml:math></disp-formula></p><p>where <inline-formula><mml:math id="inf20"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msubsup><mml:mi>f</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mspace width="thinmathspace"/><mml:mi>y</mml:mi></mml:mrow></mml:msubsup><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mstyle></mml:math></inline-formula> is the spike train of neuron <inline-formula><mml:math id="inf21"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>i</mml:mi></mml:mstyle></mml:math></inline-formula> of type <inline-formula><mml:math id="inf22"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>y</mml:mi></mml:mstyle></mml:math></inline-formula> and <inline-formula><mml:math id="inf23"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msubsup><mml:mrow><mml:mover><mml:mi>w</mml:mi><mml:mo stretchy="false">→</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mspace width="thinmathspace"/><mml:mi>y</mml:mi></mml:mrow></mml:msubsup><mml:mo>=</mml:mo><mml:mo stretchy="false">[</mml:mo><mml:msubsup><mml:mi>w</mml:mi><mml:mrow><mml:mn>1</mml:mn><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mspace width="thinmathspace"/><mml:mi>y</mml:mi></mml:mrow></mml:msubsup><mml:mo>,</mml:mo><mml:mo>…</mml:mo><mml:mo>,</mml:mo><mml:msubsup><mml:mi>w</mml:mi><mml:mrow><mml:mi>M</mml:mi><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mspace width="thinmathspace"/><mml:mi>y</mml:mi></mml:mrow></mml:msubsup><mml:msup><mml:mo stretchy="false">]</mml:mo><mml:mrow><mml:mi mathvariant="normal">⊤</mml:mi></mml:mrow></mml:msup></mml:mrow></mml:mstyle></mml:math></inline-formula> is the vector of decoding weights of the neuron for features <inline-formula><mml:math id="inf24"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>k</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mo>.</mml:mo><mml:mo>.</mml:mo><mml:mo>.</mml:mo><mml:mo>,</mml:mo><mml:mi>M</mml:mi></mml:mstyle></mml:math></inline-formula> (<xref ref-type="fig" rid="fig1">Figure 1A(ii)</xref>). We assume that every neuron encodes multiple (<inline-formula><mml:math id="inf25"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>M</mml:mi><mml:mo>&gt;</mml:mo><mml:mn>1</mml:mn></mml:mstyle></mml:math></inline-formula>) stimulus features and that the encoding of every stimulus is distributed among neurons. As a result of the optimization, the decoding weights of the neurons are equivalent to the neuron’s stimulus tuning parameters (see Materials and methods and <xref ref-type="bibr" rid="bib13">Brendel et al., 2020</xref>). We sampled tuning parameters uniformly from a <inline-formula><mml:math id="inf26"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>M</mml:mi></mml:mstyle></mml:math></inline-formula>-dimensional hypersphere with unit radius, giving tuning vectors with unit length to all neurons (see Materials and methods). To control the amount of inhibition in the network, we then multiplied the tuning vectors of I neurons with a factor <inline-formula><mml:math id="inf27"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>d</mml:mi><mml:mo>&gt;</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:mstyle></mml:math></inline-formula>, homogeneously across all I neurons. Normalization of decoding vectors preserves the heterogeneity of decoding weights across neurons, which may benefit coding efficiency (<xref ref-type="bibr" rid="bib110">Zeldenrust et al., 2021</xref>).</p><p>Following previous work (<xref ref-type="bibr" rid="bib11">Boerlin et al., 2013</xref>; <xref ref-type="bibr" rid="bib7">Barrett et al., 2016</xref>; <xref ref-type="bibr" rid="bib20">Chalk et al., 2016</xref>), we impose that E and I neurons have distinct normative objectives and we define specific loss functions relative to each neuron type. To implement at the same time, as requested by efficient coding, the constraints of faithful stimulus representation with limited computational resources (<xref ref-type="bibr" rid="bib98">Tavoni et al., 2019</xref>), we define the loss functions of the population <inline-formula><mml:math id="inf28"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>y</mml:mi><mml:mo>∈</mml:mo><mml:mo fence="false" stretchy="false">{</mml:mo><mml:mi>E</mml:mi><mml:mo>,</mml:mo><mml:mi>I</mml:mi><mml:mo fence="false" stretchy="false">}</mml:mo></mml:mstyle></mml:math></inline-formula> as a weighted sum of a time-dependent encoding error and time-dependent metabolic cost:<disp-formula id="equ3"><label>(3)</label><mml:math id="m3"><mml:mrow><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msup><mml:mrow><mml:mi mathvariant="normal">L</mml:mi></mml:mrow><mml:mi>y</mml:mi></mml:msup><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:msup><mml:mi>ϵ</mml:mi><mml:mrow><mml:mspace width="thinmathspace"/><mml:mi>y</mml:mi></mml:mrow></mml:msup><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>+</mml:mo><mml:mi>β</mml:mi><mml:msup><mml:mi>κ</mml:mi><mml:mi>y</mml:mi></mml:msup><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>,</mml:mo><mml:mspace width="2em"/><mml:mi>y</mml:mi><mml:mo>∈</mml:mo><mml:mo fence="false" stretchy="false">{</mml:mo><mml:mi>E</mml:mi><mml:mo>,</mml:mo><mml:mi>I</mml:mi><mml:mo fence="false" stretchy="false">}</mml:mo><mml:mo>.</mml:mo></mml:mstyle></mml:mrow></mml:math></disp-formula></p><p>We refer to <inline-formula><mml:math id="inf29"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>β</mml:mi></mml:mstyle></mml:math></inline-formula>, the parameter controlling the relative importance of the metabolic cost over the encoding error, as the metabolic constant of the network. We hypothesize that population readouts of E neurons, <inline-formula><mml:math id="inf30"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msup><mml:mrow><mml:mover><mml:mrow><mml:mrow><mml:mover><mml:mi>x</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow></mml:mrow><mml:mo stretchy="false">→</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mspace width="thinmathspace"/><mml:mi>E</mml:mi></mml:mrow></mml:msup><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mstyle></mml:math></inline-formula>, track the target representations, <inline-formula><mml:math id="inf31"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mrow><mml:mover><mml:mi>x</mml:mi><mml:mo stretchy="false">→</mml:mo></mml:mover></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mstyle></mml:math></inline-formula>, and the population readouts of I neurons, <inline-formula><mml:math id="inf32"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msup><mml:mrow><mml:mover><mml:mrow><mml:mrow><mml:mover><mml:mi>x</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow></mml:mrow><mml:mo stretchy="false">→</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mspace width="thinmathspace"/><mml:mi>I</mml:mi></mml:mrow></mml:msup><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mstyle></mml:math></inline-formula>, track the population readouts of E neurons, <inline-formula><mml:math id="inf33"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msup><mml:mrow><mml:mover><mml:mrow><mml:mrow><mml:mover><mml:mi>x</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow></mml:mrow><mml:mo stretchy="false">→</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mspace width="thinmathspace"/><mml:mi>E</mml:mi></mml:mrow></mml:msup><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mstyle></mml:math></inline-formula>, by minimizing the squared error between these quantities (<xref ref-type="bibr" rid="bib49">Koren and Panzeri, 2022</xref>) (see also (<xref ref-type="bibr" rid="bib11">Boerlin et al., 2013</xref>; <xref ref-type="bibr" rid="bib29">Denève et al., 2017</xref>) for related approaches). Furthermore, we hypothesize the metabolic cost to be proportional to the instantaneous estimate of network’s firing frequency. We thus define the variables of loss functions in <xref ref-type="disp-formula" rid="equ3">Equation 3</xref> as<disp-formula id="equ4"><label>(4)</label><mml:math id="m4"><mml:mrow><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mtable columnalign="right left right left right left right left right left right left" rowspacing="3pt" columnspacing="0em 2em 0em 2em 0em 2em 0em 2em 0em 2em 0em" displaystyle="true"><mml:mtr><mml:mtd><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msup><mml:mi>ε</mml:mi><mml:mrow><mml:mspace width="thinmathspace"/><mml:mi>E</mml:mi></mml:mrow></mml:msup><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mstyle></mml:mtd><mml:mtd><mml:mi/><mml:mo>=</mml:mo><mml:msup><mml:mrow><mml:mo symmetric="true">‖</mml:mo><mml:mrow><mml:mrow><mml:mover><mml:mi>x</mml:mi><mml:mo stretchy="false">→</mml:mo></mml:mover></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>−</mml:mo><mml:msup><mml:mrow><mml:mover><mml:mi>x</mml:mi><mml:mo stretchy="false">→</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mspace width="thinmathspace"/><mml:mi>E</mml:mi></mml:mrow></mml:msup><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo symmetric="true">‖</mml:mo></mml:mrow><mml:mn>2</mml:mn></mml:msup><mml:mo>,</mml:mo><mml:mspace width="2em"/><mml:msup><mml:mi>κ</mml:mi><mml:mrow><mml:mspace width="thinmathspace"/><mml:mi>E</mml:mi></mml:mrow></mml:msup><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:munderover><mml:mo>∑</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:msup><mml:mi>N</mml:mi><mml:mrow><mml:mi>E</mml:mi></mml:mrow></mml:msup></mml:mrow></mml:munderover><mml:msup><mml:mrow><mml:mo>[</mml:mo><mml:mrow><mml:msubsup><mml:mi>r</mml:mi><mml:mi>i</mml:mi><mml:mrow><mml:mspace width="thinmathspace"/><mml:mi>E</mml:mi></mml:mrow></mml:msubsup><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>]</mml:mo></mml:mrow><mml:mn>2</mml:mn></mml:msup><mml:mo>,</mml:mo></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msup><mml:mi>ε</mml:mi><mml:mrow><mml:mspace width="thinmathspace"/><mml:mi>I</mml:mi></mml:mrow></mml:msup><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mstyle></mml:mtd><mml:mtd><mml:mi/><mml:mo>=</mml:mo><mml:msup><mml:mrow><mml:mo symmetric="true">‖</mml:mo><mml:mrow><mml:msup><mml:mrow><mml:mover><mml:mi>x</mml:mi><mml:mo stretchy="false">→</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mspace width="thinmathspace"/><mml:mi>E</mml:mi></mml:mrow></mml:msup><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>−</mml:mo><mml:msup><mml:mrow><mml:mover><mml:mi>x</mml:mi><mml:mo stretchy="false">→</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mspace width="thinmathspace"/><mml:mi>I</mml:mi></mml:mrow></mml:msup><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo symmetric="true">‖</mml:mo></mml:mrow><mml:mn>2</mml:mn></mml:msup><mml:mo>,</mml:mo><mml:mspace width="2em"/><mml:msup><mml:mi>κ</mml:mi><mml:mrow><mml:mspace width="thinmathspace"/><mml:mi>I</mml:mi></mml:mrow></mml:msup><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:munderover><mml:mo>∑</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:msup><mml:mi>N</mml:mi><mml:mrow><mml:mi>I</mml:mi></mml:mrow></mml:msup></mml:mrow></mml:munderover><mml:msup><mml:mrow><mml:mo>[</mml:mo><mml:mrow><mml:msubsup><mml:mi>r</mml:mi><mml:mi>i</mml:mi><mml:mrow><mml:mspace width="thinmathspace"/><mml:mi>I</mml:mi></mml:mrow></mml:msubsup><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>]</mml:mo></mml:mrow><mml:mn>2</mml:mn></mml:msup><mml:mo>,</mml:mo></mml:mtd></mml:mtr></mml:mtable></mml:mstyle></mml:mrow></mml:math></disp-formula></p><p>where <inline-formula><mml:math id="inf34"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msubsup><mml:mi>r</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mspace width="thinmathspace"/><mml:mi>y</mml:mi></mml:mrow></mml:msubsup><mml:mo>,</mml:mo><mml:mi>y</mml:mi><mml:mo>∈</mml:mo><mml:mo fence="false" stretchy="false">{</mml:mo><mml:mi>E</mml:mi><mml:mo>,</mml:mo><mml:mi>I</mml:mi><mml:mo fence="false" stretchy="false">}</mml:mo></mml:mrow></mml:mstyle></mml:math></inline-formula>, is the low-pass filtered spike train of neuron <inline-formula><mml:math id="inf35"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>i</mml:mi></mml:mstyle></mml:math></inline-formula> (single neuron readout) with time constant <inline-formula><mml:math id="inf36"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msubsup><mml:mi>τ</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>r</mml:mi></mml:mrow><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>y</mml:mi></mml:mrow></mml:msubsup></mml:mstyle></mml:math></inline-formula>, proportional to the instantaneous firing rate of the neuron: <inline-formula><mml:math id="inf37"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mrow><mml:msubsup><mml:mi>z</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mspace width="thinmathspace"/><mml:mi>y</mml:mi></mml:mrow></mml:msubsup><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:msubsup><mml:mi>τ</mml:mi><mml:mrow><mml:mi>r</mml:mi></mml:mrow><mml:mrow><mml:mspace width="thinmathspace"/><mml:mi>y</mml:mi></mml:mrow></mml:msubsup><mml:msup><mml:mo stretchy="false">)</mml:mo><mml:mrow><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msup><mml:msubsup><mml:mi>r</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mspace width="thinmathspace"/><mml:mi>y</mml:mi></mml:mrow></mml:msubsup><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:mstyle></mml:math></inline-formula>. We then impose the following condition for spiking: a neuron emits a spike at time <inline-formula><mml:math id="inf38"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>t</mml:mi></mml:mstyle></mml:math></inline-formula> only if this decreases the loss function of its population (<xref ref-type="disp-formula" rid="equ3">Equation 3</xref>) in the immediate future. The condition for spiking also includes a noise term (Materials and methods) accounting for sources of stochasticity in spike generation (<xref ref-type="bibr" rid="bib35">Faisal et al., 2008</xref>) which include the effect of non-specific inputs from the rest of the brain.</p><p>We derived the dynamics and network structure of a spiking network that instantiates efficient coding (<xref ref-type="fig" rid="fig1">Figure 1B</xref>, see Materials and methods). The derived dynamics of the subthreshold membrane potential <inline-formula><mml:math id="inf39"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msubsup><mml:mi>V</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mspace width="thinmathspace"/><mml:mi>E</mml:mi></mml:mrow></mml:msubsup><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mstyle></mml:mrow></mml:mstyle></mml:math></inline-formula> and <inline-formula><mml:math id="inf40"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msubsup><mml:mi>V</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mspace width="thinmathspace"/><mml:mi>I</mml:mi></mml:mrow></mml:msubsup><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mstyle></mml:mrow></mml:mstyle></mml:math></inline-formula> obey the equations of the generalized leaky integrate and fire (gLIF) neuron<disp-formula id="equ5"><label>(5)</label><mml:math id="m5"><mml:mrow><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>τ</mml:mi><mml:msubsup><mml:mrow><mml:mover><mml:mi>V</mml:mi><mml:mo>˙</mml:mo></mml:mover></mml:mrow><mml:mi>i</mml:mi><mml:mrow><mml:mtext> </mml:mtext><mml:mi>y</mml:mi></mml:mrow></mml:msubsup><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mo>−</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msubsup><mml:mi>V</mml:mi><mml:mi>i</mml:mi><mml:mrow><mml:mtext> </mml:mtext><mml:mi>y</mml:mi></mml:mrow></mml:msubsup><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>−</mml:mo><mml:msubsup><mml:mi>V</mml:mi><mml:mrow><mml:mtext>rest</mml:mtext></mml:mrow><mml:mrow><mml:mtext> </mml:mtext><mml:mi>y</mml:mi></mml:mrow></mml:msubsup></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>+</mml:mo><mml:msub><mml:mi>R</mml:mi><mml:mi>m</mml:mi></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msubsup><mml:mi>I</mml:mi><mml:mi>i</mml:mi><mml:mrow><mml:mspace width="thinmathspace"/><mml:mtext>syn</mml:mtext><mml:mo>,</mml:mo><mml:mi>y</mml:mi></mml:mrow></mml:msubsup><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>−</mml:mo><mml:msubsup><mml:mi>I</mml:mi><mml:mi>i</mml:mi><mml:mrow><mml:mspace width="thinmathspace"/><mml:mtext>ad</mml:mtext><mml:mo>,</mml:mo><mml:mi>y</mml:mi></mml:mrow></mml:msubsup><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>+</mml:mo><mml:msubsup><mml:mi>I</mml:mi><mml:mi>i</mml:mi><mml:mrow><mml:mspace width="thinmathspace"/><mml:mtext>ext</mml:mtext><mml:mo>,</mml:mo><mml:mi>y</mml:mi></mml:mrow></mml:msubsup><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>,</mml:mo><mml:mspace width="2em"/><mml:mi>y</mml:mi><mml:mo>∈</mml:mo><mml:mo fence="false" stretchy="false">{</mml:mo><mml:mi>E</mml:mi><mml:mo>,</mml:mo><mml:mi>I</mml:mi><mml:mo fence="false" stretchy="false">}</mml:mo><mml:mo>,</mml:mo></mml:mstyle></mml:mrow></mml:math></disp-formula></p><p>where <inline-formula><mml:math id="inf41"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msubsup><mml:mi>I</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mspace width="thinmathspace"/><mml:mtext>syn</mml:mtext><mml:mo>,</mml:mo><mml:mi>y</mml:mi></mml:mrow></mml:msubsup></mml:mrow></mml:mstyle></mml:math></inline-formula>, <inline-formula><mml:math id="inf42"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msubsup><mml:mi>I</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mspace width="thinmathspace"/><mml:mtext>ad</mml:mtext><mml:mo>,</mml:mo><mml:mi>y</mml:mi></mml:mrow></mml:msubsup></mml:mrow></mml:mstyle></mml:math></inline-formula>, and <inline-formula><mml:math id="inf43"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msubsup><mml:mi>I</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mspace width="thinmathspace"/><mml:mtext>ext</mml:mtext><mml:mo>,</mml:mo><mml:mi>y</mml:mi></mml:mrow></mml:msubsup></mml:mrow></mml:mstyle></mml:math></inline-formula> are synaptic current, spike-triggered adaptation current and non-specific external current, respectively, <inline-formula><mml:math id="inf44"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msub><mml:mi>R</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>m</mml:mi></mml:mrow></mml:msub></mml:mstyle></mml:math></inline-formula> is the membrane resistance and <inline-formula><mml:math id="inf45"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msubsup><mml:mi>V</mml:mi><mml:mrow><mml:mtext>rest</mml:mtext></mml:mrow><mml:mrow><mml:mspace width="thinmathspace"/><mml:mi>y</mml:mi></mml:mrow></mml:msubsup></mml:mrow></mml:mstyle></mml:math></inline-formula> is the resting potential. This dynamics is complemented with a fire-and-reset rule: when the membrane potential reaches the firing threshold <inline-formula><mml:math id="inf46"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msup><mml:mi>ϑ</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>y</mml:mi></mml:mrow></mml:msup></mml:mstyle></mml:math></inline-formula>, a spike is fired and <inline-formula><mml:math id="inf47"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msubsup><mml:mi>V</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mspace width="thinmathspace"/><mml:mi>y</mml:mi></mml:mrow></mml:msubsup><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mstyle></mml:math></inline-formula> is set to the reset potential <inline-formula><mml:math id="inf48"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msubsup><mml:mi>V</mml:mi><mml:mi>i</mml:mi><mml:mrow><mml:mspace width="thinmathspace"/><mml:mtext>reset</mml:mtext><mml:mo>,</mml:mo><mml:mi>y</mml:mi></mml:mrow></mml:msubsup></mml:mrow></mml:mstyle></mml:math></inline-formula>. The analytical solution in <xref ref-type="disp-formula" rid="equ5">Equation 5</xref> holds for any number of neurons (with at least 1 neuron in each population) and predicts an optimal spike pattern to encode the presented external stimulus. Following previous work (<xref ref-type="bibr" rid="bib11">Boerlin et al., 2013</xref>) in which physical units were assigned to derived mathematical expressions to interpret them as biophysical variables, we express computational variables (target stimuli in <xref ref-type="disp-formula" rid="equ1">Equation 1</xref>, population readouts in <xref ref-type="disp-formula" rid="equ2">Equation 2</xref> and the metabolic constant in <xref ref-type="disp-formula" rid="equ3">Equation 3</xref>) with physical units in such a way that all terms of the biophysical model (<xref ref-type="disp-formula" rid="equ5">Equation 5</xref>) have realistic physical units.</p><p>The synaptic currents in E neurons, <inline-formula><mml:math id="inf49"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msubsup><mml:mi>I</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mspace width="thinmathspace"/><mml:mtext>syn</mml:mtext><mml:mo>,</mml:mo><mml:mi>E</mml:mi></mml:mrow></mml:msubsup></mml:mrow></mml:mstyle></mml:math></inline-formula>, consist of feedforward currents, obtained as stimulus features <inline-formula><mml:math id="inf50"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow class="MJX-TeXAtom-ORD"><mml:mover><mml:mi>s</mml:mi><mml:mo stretchy="false">→</mml:mo></mml:mover></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mstyle></mml:math></inline-formula> weighted by the tuning weights of the neuron, and of recurrent inhibitory currents (<xref ref-type="fig" rid="fig1">Figure 1B</xref>). Synaptic currents in I neurons, <inline-formula><mml:math id="inf51"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msubsup><mml:mi>I</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mspace width="thinmathspace"/><mml:mtext>syn</mml:mtext><mml:mo>,</mml:mo><mml:mi>I</mml:mi></mml:mrow></mml:msubsup></mml:mrow></mml:mstyle></mml:math></inline-formula>, consist of recurrent excitatory and inhibitory currents. Note that there are no recurrent connections between E neurons, a consequence of our assumption of no across-feature interaction in the leaky integration of stimulus features (<xref ref-type="disp-formula" rid="equ1">Equation 1</xref>). This assumption is likely to be simplistic even for early sensory cortices (<xref ref-type="bibr" rid="bib32">Emanuel et al., 2021</xref>). However, in other studies, we found that many properties of efficient networks implementing leaky integration hold also when input features are linearly mixed during integration (<xref ref-type="bibr" rid="bib49">Koren and Panzeri, 2022</xref>; <xref ref-type="bibr" rid="bib50">Koren et al., 2023</xref>).</p><p>The optimization of the loss function yielded structured recurrent connectivity (<xref ref-type="fig" rid="fig1">Figure 1B(ii)–C</xref>). Synaptic strength between two neurons is proportional to their tuning similarity, forming like-to-like connectivity, if the tuning similarity is positive; otherwise the synaptic weight is set to zero (<xref ref-type="fig" rid="fig1">Figure 1C(ii)</xref>) to ensure that Dale’s law is respected. A connectivity structure in which the synaptic weight is proportional to pairwise tuning similarity is consistent with some empirical observations in visual cortex (<xref ref-type="bibr" rid="bib112">Znamenskiy et al., 2024</xref>) and has been suggested by previous models (<xref ref-type="bibr" rid="bib11">Boerlin et al., 2013</xref>; <xref ref-type="bibr" rid="bib86">Sadeh and Clopath, 2020</xref>). Such connectivity organization is also suggested by across-neuron influence measured with optogenetic perturbations of visual cortex (<xref ref-type="bibr" rid="bib22">Chettih and Harvey, 2019</xref>; <xref ref-type="bibr" rid="bib72">Oldenburg et al., 2024</xref>). While such connectivity structure is the result of optimization, the rectification of the connectivity that enforces Dale’s law does not emerge from imposing efficient coding, but from constraining the space of solutions to biologically plausible networks. Rectification also sets the overall connection probability to 0.5, which is consistent with empirically observed connection probability from pyramidal (E) neurons to parvalbumin-positive (I) neurons (<xref ref-type="bibr" rid="bib76">Pala and Petersen, 2015</xref>; <xref ref-type="bibr" rid="bib19">Campagnola et al., 2022</xref>), but likely overestimates the connection probability from parvalbumin-positive neurons to pyramidal neurons, which tends to be lower (<xref ref-type="bibr" rid="bib19">Campagnola et al., 2022</xref>). (For a study of how efficient coding would be implemented if the above Dale’s law constraint were removed and each neuron were free to have either an inhibitory or excitatory effect depending on the postsynaptic target, see Appendix 1 and <xref ref-type="fig" rid="fig1s1">Figure 1—figure supplement 1A–E</xref>).</p><p>The spike-triggered adaptation current of neuron <inline-formula><mml:math id="inf52"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>i</mml:mi></mml:mstyle></mml:math></inline-formula> in population <inline-formula><mml:math id="inf53"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>y</mml:mi></mml:mstyle></mml:math></inline-formula>, <inline-formula><mml:math id="inf54"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msubsup><mml:mi>I</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mspace width="thinmathspace"/><mml:mtext>ad</mml:mtext><mml:mo>,</mml:mo><mml:mi>y</mml:mi></mml:mrow></mml:msubsup></mml:mrow></mml:mstyle></mml:math></inline-formula>, is proportional to its low-pass filtered spike train. This current realizes spike-frequency adaptation or facilitation depending on the difference between the time constants of population and single neuron readout (see Results subsection ‘Weak or no spike-triggered adaptation optimizes network efficiency’).</p><p>Finally, non-specific external currents <inline-formula><mml:math id="inf55"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msubsup><mml:mi>I</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mspace width="thinmathspace"/><mml:mtext>ext</mml:mtext><mml:mo>,</mml:mo><mml:mi>y</mml:mi></mml:mrow></mml:msubsup><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mstyle></mml:math></inline-formula> have a constant mean that depends on the parameter <inline-formula><mml:math id="inf56"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>β</mml:mi></mml:mstyle></mml:math></inline-formula>, and fluctuations that arise from the noise with strength <inline-formula><mml:math id="inf57"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>σ</mml:mi></mml:mstyle></mml:math></inline-formula> in the condition for spiking. The relative weight of the metabolic cost over the encoding error, <inline-formula><mml:math id="inf58"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>β</mml:mi></mml:mstyle></mml:math></inline-formula>, controls how the network responds to feedforward stimuli, by modulating the mean of the non-specific synaptic currents incoming to all neurons. Together with the noise strength <inline-formula><mml:math id="inf59"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>σ</mml:mi></mml:mstyle></mml:math></inline-formula>, these two parameters set the non-specific synaptic currents to single neurons that are homogeneous across the network and akin to the background synaptic input discussed in <xref ref-type="bibr" rid="bib31">Destexhe et al., 2003</xref>. By allowing a large part of the distance between the resting potential and the threshold to be taken by the non-specific current, we found a biologically plausible set of optimally efficient model parameters (<xref ref-type="table" rid="table1">Table 1</xref>) including the firing threshold at about 20 mV from the resting potential, which is within the experimental ballpark (<xref ref-type="bibr" rid="bib24">Constantinople and Bruno, 2013</xref>), and average synaptic strengths of 0.75 mV (E-I and I-E synapses) and 2.25 mV (I-I synapses), which are consistent with measurements in sensory cortex (<xref ref-type="bibr" rid="bib19">Campagnola et al., 2022</xref>). An optimal network without non-specific currents can be derived (see Materials and methods, <xref ref-type="disp-formula" rid="equ27">Equation 25</xref>), but its parameters are not consistent with biology (see Appendix 2). The non-specific currents can be interpreted as synaptic currents that are modulated by larger-scale variables, such as brain states (see subsection ‘Non-specific currents regulate network coding properties’).</p><table-wrap id="table1" position="float"><label>Table 1.</label><caption><title>Table of default model parameters for the efficient E-I network.</title><p>Parameters above the double horizontal line are the minimal set of parameters needed to simulate model equations (<xref ref-type="disp-formula" rid="equ33">Equation 29a</xref>-<xref ref-type="disp-formula" rid="equ40">29h</xref> in Materials and methods). Parameters below the double horizontal line are biophysical parameters, derived from the same model equations and from model parameters listed above the horizontal line. Parameters <inline-formula><mml:math id="inf60"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msup><mml:mi>N</mml:mi><mml:mrow><mml:mspace width="thinmathspace"/><mml:mi>E</mml:mi></mml:mrow></mml:msup></mml:mrow></mml:mstyle></mml:math></inline-formula>, <inline-formula><mml:math id="inf61"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>M</mml:mi></mml:mstyle></mml:math></inline-formula>, <inline-formula><mml:math id="inf62"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>τ</mml:mi></mml:mstyle></mml:math></inline-formula> and <inline-formula><mml:math id="inf63"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msubsup><mml:mi>σ</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>w</mml:mi></mml:mrow><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>E</mml:mi></mml:mrow></mml:msubsup></mml:mstyle></mml:math></inline-formula> were chosen for their biological plausibility and computational simplicity. Parameters <inline-formula><mml:math id="inf64"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msup><mml:mi>N</mml:mi><mml:mrow><mml:mspace width="thinmathspace"/><mml:mi>I</mml:mi></mml:mrow></mml:msup></mml:mrow></mml:mstyle></mml:math></inline-formula>, <inline-formula><mml:math id="inf65"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msubsup><mml:mi>τ</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>r</mml:mi></mml:mrow><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>E</mml:mi></mml:mrow></mml:msubsup></mml:mstyle></mml:math></inline-formula>, <inline-formula><mml:math id="inf66"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msubsup><mml:mi>τ</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>r</mml:mi></mml:mrow><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>I</mml:mi></mml:mrow></mml:msubsup></mml:mstyle></mml:math></inline-formula>, <inline-formula><mml:math id="inf67"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>σ</mml:mi></mml:mstyle></mml:math></inline-formula>, ratio of mean E-I to I-I synaptic connectivity and <inline-formula><mml:math id="inf68"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>β</mml:mi></mml:mstyle></mml:math></inline-formula> are parameters that maximize network efficiency (see the section ‘Criterion for determining model parameters’ in Materials and methods). The metabolic constant <inline-formula><mml:math id="inf69"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>β</mml:mi></mml:mstyle></mml:math></inline-formula> and the noise strength <inline-formula><mml:math id="inf70"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>σ</mml:mi></mml:mstyle></mml:math></inline-formula> are interpreted as global network parameters and are for this reason assumed to be the same across the E and I population, e.g., <inline-formula><mml:math id="inf71"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msup><mml:mi>β</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>E</mml:mi></mml:mrow></mml:msup><mml:mo>=</mml:mo><mml:msup><mml:mi>β</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>I</mml:mi></mml:mrow></mml:msup><mml:mo>=</mml:mo><mml:mi>β</mml:mi></mml:mstyle></mml:math></inline-formula> and <inline-formula><mml:math id="inf72"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msup><mml:mi>σ</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>E</mml:mi></mml:mrow></mml:msup><mml:mo>=</mml:mo><mml:msup><mml:mi>σ</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>I</mml:mi></mml:mrow></mml:msup><mml:mo>=</mml:mo><mml:mi>σ</mml:mi></mml:mstyle></mml:math></inline-formula> (see <xref ref-type="disp-formula" rid="equ3">Equation 3</xref>). The connection probability of <inline-formula><mml:math id="inf73"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msup><mml:mi>p</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>x</mml:mi><mml:mi>y</mml:mi></mml:mrow></mml:msup><mml:mo>=</mml:mo><mml:mn>0.5</mml:mn></mml:mstyle></mml:math></inline-formula> is the consequence of rectification of the connectivity (see <xref ref-type="disp-formula" rid="equ26">Equation 24</xref> in Materials and methods).</p></caption><table frame="hsides" rules="groups"><thead><tr><th align="left" valign="bottom">Parameter</th><th align="left" valign="bottom">Notation</th><th align="left" valign="bottom">Value</th></tr></thead><tbody><tr><td align="left" valign="bottom">Number of E neurons</td><td align="left" valign="bottom"><inline-formula><mml:math id="inf74"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msup><mml:mi>N</mml:mi><mml:mrow><mml:mspace width="thinmathspace"/><mml:mi>E</mml:mi></mml:mrow></mml:msup></mml:mstyle></mml:mrow></mml:mstyle></mml:math></inline-formula></td><td align="left" valign="bottom">400</td></tr><tr><td align="left" valign="bottom">Ratio of E to I neuron numbers</td><td align="left" valign="bottom"><inline-formula><mml:math id="inf75"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msup><mml:mi>N</mml:mi><mml:mrow><mml:mspace width="thinmathspace"/><mml:mi>E</mml:mi></mml:mrow></mml:msup><mml:mo>:</mml:mo><mml:msup><mml:mi>N</mml:mi><mml:mrow><mml:mspace width="thinmathspace"/><mml:mi>I</mml:mi></mml:mrow></mml:msup></mml:mstyle></mml:mrow></mml:mstyle></mml:math></inline-formula></td><td align="left" valign="bottom">4:1</td></tr><tr><td align="left" valign="bottom">Number of the input features</td><td align="left" valign="bottom"><inline-formula><mml:math id="inf76"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>M</mml:mi></mml:mstyle></mml:math></inline-formula></td><td align="left" valign="bottom">3</td></tr><tr><td align="left" valign="bottom">Time constant of the population readout (E and I)</td><td align="left" valign="bottom"><inline-formula><mml:math id="inf77"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>τ</mml:mi></mml:mstyle></mml:math></inline-formula></td><td align="left" valign="bottom">10ms</td></tr><tr><td align="left" valign="bottom">Time constant of the single neuron readout</td><td align="left" valign="bottom"><inline-formula><mml:math id="inf78"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msubsup><mml:mi>τ</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>r</mml:mi></mml:mrow><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>E</mml:mi></mml:mrow></mml:msubsup><mml:mo>=</mml:mo><mml:msubsup><mml:mi>τ</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>r</mml:mi></mml:mrow><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>I</mml:mi></mml:mrow></mml:msubsup></mml:mstyle></mml:math></inline-formula></td><td align="left" valign="bottom">10ms</td></tr><tr><td align="left" valign="bottom">Noise strength (non-specific current)</td><td align="left" valign="bottom"><inline-formula><mml:math id="inf79"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>σ</mml:mi></mml:mstyle></mml:math></inline-formula></td><td align="left" valign="bottom">5.0 mV</td></tr><tr><td align="left" valign="bottom">Heterogeneity factor of tuning parameters in E</td><td align="left" valign="bottom"><inline-formula><mml:math id="inf80"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msubsup><mml:mi>σ</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>w</mml:mi></mml:mrow><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>E</mml:mi></mml:mrow></mml:msubsup></mml:mstyle></mml:math></inline-formula></td><td align="left" valign="bottom">1.0 (mV)<sup>1/2</sup></td></tr><tr><td align="left" valign="bottom">Ratio of mean I-I to E-I synaptic connectivity</td><td align="left" valign="bottom">mean I-I: mean E-I</td><td align="left" valign="bottom">3:1</td></tr><tr><td align="left" valign="bottom">Metabolic constant</td><td align="left" valign="bottom"><inline-formula><mml:math id="inf81"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>β</mml:mi></mml:mstyle></mml:math></inline-formula></td><td align="left" valign="bottom">14 mV</td></tr><tr><td align="left" valign="bottom">Threshold constant</td><td align="left" valign="bottom"><inline-formula><mml:math id="inf82"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>c</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mo>/</mml:mo></mml:mrow><mml:mn>2</mml:mn></mml:mstyle></mml:math></inline-formula></td><td align="left" valign="bottom">18 mV</td></tr><tr><td align="left" valign="bottom">Distance threshold to reset potential (E neurons)</td><td align="left" valign="bottom"><inline-formula><mml:math id="inf83"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow class="MJX-TeXAtom-ORD"><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:msup><mml:mi>ϑ</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>E</mml:mi></mml:mrow></mml:msup><mml:mo>−</mml:mo><mml:msubsup><mml:mi>V</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mtext>rest</mml:mtext></mml:mrow><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>E</mml:mi></mml:mrow></mml:msubsup><mml:mrow class="MJX-TeXAtom-ORD"><mml:mo stretchy="false">|</mml:mo></mml:mrow></mml:mstyle></mml:math></inline-formula></td><td align="left" valign="bottom">19 mV</td></tr><tr><td align="left" valign="bottom">Distance threshold to reset potential (I neurons)</td><td align="left" valign="bottom"><inline-formula><mml:math id="inf84"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:msup><mml:mi>ϑ</mml:mi><mml:mrow><mml:mi>I</mml:mi></mml:mrow></mml:msup><mml:mo>−</mml:mo><mml:msubsup><mml:mi>V</mml:mi><mml:mrow><mml:mtext>rest</mml:mtext></mml:mrow><mml:mrow><mml:mspace width="thinmathspace"/><mml:mi>I</mml:mi></mml:mrow></mml:msubsup><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow></mml:mstyle></mml:mrow></mml:mstyle></mml:math></inline-formula></td><td align="left" valign="bottom">21 mV</td></tr><tr><td align="left" valign="bottom">Connection probability (recurrent synapses)</td><td align="left" valign="bottom"><inline-formula><mml:math id="inf85"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msup><mml:mi>p</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>I</mml:mi><mml:mi>E</mml:mi></mml:mrow></mml:msup><mml:mo>=</mml:mo><mml:msup><mml:mi>p</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>I</mml:mi><mml:mi>I</mml:mi></mml:mrow></mml:msup><mml:mo>=</mml:mo><mml:msup><mml:mi>p</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>E</mml:mi><mml:mi>I</mml:mi></mml:mrow></mml:msup></mml:mstyle></mml:math></inline-formula></td><td align="left" valign="bottom">0.5</td></tr><tr><td align="left" valign="bottom">Mean E-I synaptic weight (EPSP to I at max)</td><td align="left" valign="bottom"><inline-formula><mml:math id="inf86"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mo fence="false" stretchy="false">⟨</mml:mo><mml:msubsup><mml:mi>J</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow><mml:mrow><mml:mspace width="thinmathspace"/><mml:mi>I</mml:mi><mml:mi>E</mml:mi></mml:mrow></mml:msubsup><mml:mo fence="false" stretchy="false">⟩</mml:mo></mml:mstyle></mml:mrow></mml:mstyle></mml:math></inline-formula></td><td align="left" valign="bottom">0.75 mV</td></tr><tr><td align="left" valign="bottom">Mean I-E synaptic weight (IPSP to E at max)</td><td align="left" valign="bottom"><inline-formula><mml:math id="inf87"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mo fence="false" stretchy="false">⟨</mml:mo><mml:msubsup><mml:mi>J</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow><mml:mrow><mml:mspace width="thinmathspace"/><mml:mi>E</mml:mi><mml:mi>I</mml:mi></mml:mrow></mml:msubsup><mml:mo fence="false" stretchy="false">⟩</mml:mo></mml:mstyle></mml:mrow></mml:mstyle></mml:math></inline-formula></td><td align="left" valign="bottom">0.75 mV</td></tr><tr><td align="left" valign="bottom">Mean I-I synaptic weight (IPSP at max)</td><td align="left" valign="bottom"><inline-formula><mml:math id="inf88"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mo fence="false" stretchy="false">⟨</mml:mo><mml:msubsup><mml:mi>J</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow><mml:mrow><mml:mspace width="thinmathspace"/><mml:mi>I</mml:mi><mml:mi>I</mml:mi></mml:mrow></mml:msubsup><mml:mo fence="false" stretchy="false">⟩</mml:mo></mml:mstyle></mml:mrow></mml:mstyle></mml:math></inline-formula></td><td align="left" valign="bottom">2.25 mV</td></tr></tbody></table></table-wrap><p>To summarize, the analytical derivation of an optimally efficient network includes gLIF neurons (<xref ref-type="bibr" rid="bib16">Burkitt, 2006</xref>; <xref ref-type="bibr" rid="bib44">Jolivet et al., 2008</xref>; <xref ref-type="bibr" rid="bib37">Gerstner et al., 2014</xref>; <xref ref-type="bibr" rid="bib90">Schwalger et al., 2017</xref>; <xref ref-type="bibr" rid="bib40">Harkin et al., 2021</xref>), a distributed code with linear mixed selectivity to the input stimuli (<xref ref-type="bibr" rid="bib21">Chang and Tsao, 2017</xref>; <xref ref-type="bibr" rid="bib46">Kaufman et al., 2014</xref>), spike-triggered adaptation, structured synaptic connectivity, and a non-specific external current akin to background synaptic input.</p></sec><sec id="s2-2"><title>Encoding performance and neural dynamics in an optimally efficient E-I network</title><p>The equations for the E-I network of gLIF neurons in <xref ref-type="disp-formula" rid="equ5">Equation 5</xref> optimize the loss functions at any given time and for any set of parameters. In particular, the network equations have the same analytical form for any positive value of the metabolic constant <inline-formula><mml:math id="inf89"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>β</mml:mi></mml:mstyle></mml:math></inline-formula>. To find a set of parameters that optimizes the overall performance, we minimized the loss function averaged over time and trials. We then optimized the parameters by setting the metabolic constant <inline-formula><mml:math id="inf90"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>β</mml:mi></mml:mstyle></mml:math></inline-formula> such that the encoding error weights 70% and the metabolic error weights 30% of the average loss, and by choosing all other parameters such as to minimize numerically the average loss (see Materials and methods). The numerical optimization was performed by simulating a model of 400 E and 100 I units, a network size relevant for computations within one layer of a cortical microcolumn (<xref ref-type="bibr" rid="bib54">Lefort et al., 2009</xref>). The set of model parameters that optimized network efficiency is detailed in <xref ref-type="table" rid="table1">Table 1</xref>. Unless otherwise stated, we will use the optimal parameters of <xref ref-type="table" rid="table1">Table 1</xref> in all simulations and only vary parameters detailed in the figure axes.</p><p>With optimally efficient parameters, population readouts closely tracked the target signals (<xref ref-type="fig" rid="fig1">Figure 1D</xref>, M=3, <inline-formula><mml:math id="inf91"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msup><mml:mi>R</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mn>2</mml:mn></mml:mrow></mml:msup><mml:mo>=</mml:mo><mml:mo stretchy="false">[</mml:mo><mml:mn>0.95</mml:mn><mml:mo>,</mml:mo><mml:mn>0.97</mml:mn><mml:mo stretchy="false">]</mml:mo></mml:mstyle></mml:math></inline-formula> for E and I neurons, respectively). When stimulated by our three-dimensional time-varying feedforward input, the optimal E-I network provided a precise estimator of target signals (<xref ref-type="fig" rid="fig1">Figure 1E</xref>, top). The average estimation bias (<inline-formula><mml:math id="inf92"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msup><mml:mi>B</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>E</mml:mi></mml:mrow></mml:msup></mml:mstyle></mml:math></inline-formula> and <inline-formula><mml:math id="inf93"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msup><mml:mi>B</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>I</mml:mi></mml:mrow></mml:msup></mml:mstyle></mml:math></inline-formula>, see Materials and methods) of the network minimizing the encoding error was close to zero (<inline-formula><mml:math id="inf94"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msup><mml:mi>B</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>E</mml:mi></mml:mrow></mml:msup></mml:mstyle></mml:math></inline-formula> = 0.02 and <inline-formula><mml:math id="inf95"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msup><mml:mi>B</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>I</mml:mi></mml:mrow></mml:msup></mml:mstyle></mml:math></inline-formula> = 0.03) while the bias of the network minimizing the average loss (and optimizing efficiency) was slightly larger and negative (<inline-formula><mml:math id="inf96"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msup><mml:mi>B</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>E</mml:mi></mml:mrow></mml:msup></mml:mstyle></mml:math></inline-formula>= –0.15 and <inline-formula><mml:math id="inf97"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msup><mml:mi>B</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>I</mml:mi></mml:mrow></mml:msup></mml:mstyle></mml:math></inline-formula>= −0.34), but still small compared to the stimulus amplitude (<xref ref-type="fig" rid="fig1">Figure 1E</xref>, bottom, <xref ref-type="fig" rid="fig1s1">Figure 1—figure supplement 1F</xref>). Time- and trial-averaged encoding error (RMSE) and metabolic cost (MC, see Materials and methods) were comparable in magnitude (<inline-formula><mml:math id="inf98"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>R</mml:mi><mml:mi>M</mml:mi><mml:mi>S</mml:mi><mml:mi>E</mml:mi><mml:mo>=</mml:mo><mml:mo stretchy="false">[</mml:mo><mml:mn>3.5</mml:mn><mml:mo>,</mml:mo><mml:mn>2.4</mml:mn><mml:mo stretchy="false">]</mml:mo></mml:mstyle></mml:math></inline-formula>, <inline-formula><mml:math id="inf99"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>M</mml:mi><mml:mi>C</mml:mi><mml:mo>=</mml:mo><mml:mo stretchy="false">[</mml:mo><mml:mn>4.4</mml:mn><mml:mo>,</mml:mo><mml:mn>2.8</mml:mn><mml:mo stretchy="false">]</mml:mo></mml:mstyle></mml:math></inline-formula> for E and I), but with smaller error and lower cost in I, leading to a better performance in I (average loss of 2.5) compared to E neurons (average loss of 3.7). We report both the encoding error and the metabolic cost throughout the paper, so that readers can evaluate how these performance measures may generalize when weighting differently the error and the metabolic cost.</p><p>Next, we examined the emergent dynamical properties of an optimally efficient E-I network. I neurons had higher average firing rates compared to E neurons, consistently with observations in cortex (<xref ref-type="bibr" rid="bib70">Neske et al., 2015</xref>). The distribution of firing rates was well described by a log-normal distribution (<xref ref-type="fig" rid="fig1">Figure 1F</xref>, left), consistent with distributions of cortical firing observed empirically (<xref ref-type="bibr" rid="bib17">Buzsáki and Mizuseki, 2014</xref>). Neurons fired irregularly, with mean coefficient of variation (CV) slightly smaller than 1 (<xref ref-type="fig" rid="fig1">Figure 1F</xref>, right; CV = [0.97, 0.95] for E and I neurons, respectively), compatible with cortical firing (<xref ref-type="bibr" rid="bib94">Softky and Koch, 1993</xref>). We assessed E-I balance in single neurons through two complementary measures. First, we calculated the <italic>average</italic> (global) balance of E-I currents by taking the time-average of the net sum of synaptic inputs (shortened to net synaptic input, see <xref ref-type="bibr" rid="bib3">Ahmadian and Miller, 2021</xref>). Second, we computed the <italic>instantaneous</italic> (<xref ref-type="bibr" rid="bib71">Okun and Lampl, 2008</xref>; also termed detailed in <xref ref-type="bibr" rid="bib105">Vogels et al., 2011</xref>) E-I balance as the Pearson correlation (<inline-formula><mml:math id="inf100"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>ρ</mml:mi></mml:mstyle></mml:math></inline-formula>) over time of E and I currents received by each neuron (see Materials and methods).</p><p>We observed an excess inhibition in both E and I neurons, with a negative net synaptic input in both E and I cells (<xref ref-type="fig" rid="fig1">Figure 1H</xref>), indicating an inhibition-dominated network according to the criterion of average balance (<xref ref-type="bibr" rid="bib3">Ahmadian and Miller, 2021</xref>). In E neurons, net synaptic current is the sum of the feedforward current and recurrent inhibition and the mean of the net current is close to the mean of the inhibitory current, because feedforward inputs have vanishing mean. Furthermore, we found a moderate instantaneous balance (<xref ref-type="bibr" rid="bib109">Xue et al., 2014</xref>), stronger in I compared to E cell type (<xref ref-type="fig" rid="fig1">Figure 1G, I</xref>, <inline-formula><mml:math id="inf101"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>ρ</mml:mi><mml:mo>=</mml:mo><mml:mo stretchy="false">[</mml:mo><mml:mn>0.44</mml:mn><mml:mo>,</mml:mo><mml:mn>0.25</mml:mn><mml:mo stretchy="false">]</mml:mo></mml:mstyle></mml:math></inline-formula>, for I and E neurons, respectively), similar to levels measured empirically in rat visual cortex (<xref ref-type="bibr" rid="bib97">Tan et al., 2013</xref>).</p><p>We determined optimal model parameters by optimizing one parameter at a time. To independently validate the so obtained optimal parameter set (reported in <xref ref-type="table" rid="table1">Table 1</xref>), we varied all six model parameters explored in the paper with Monte-Carlo random joint sampling (10,000 random samples), uniformly within a biologically plausible parameter range for each parameter (<xref ref-type="table" rid="table2">Table 2</xref>). We did not find any parameter configuration with lower average loss than the setting in <xref ref-type="table" rid="table1">Table 1</xref> (<xref ref-type="fig" rid="fig2">Figure 2A–B</xref>) when using the weighting of the encoding error with metabolic cost between <inline-formula><mml:math id="inf102"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mn>0.4</mml:mn><mml:mo>&lt;</mml:mo><mml:msub><mml:mi>g</mml:mi><mml:mrow><mml:mi>L</mml:mi></mml:mrow></mml:msub><mml:mo>&lt;</mml:mo><mml:mn>0.81</mml:mn></mml:mrow></mml:mstyle></mml:math></inline-formula> (<xref ref-type="fig" rid="fig2">Figure 2C</xref>). The three parameter settings that came the closest to our configuration on <xref ref-type="table" rid="table1">Table 1</xref> had stronger noise but also stronger metabolic constant than our configuration (<xref ref-type="table" rid="table3">Table 3</xref>). The second, third and fourth configurations had longer time constants of both E and I single neurons. Ratios of E-I neuron numbers and of I-I to E-I connectivity in the second, third, and fourth best configuration were either jointly increased or decreased with respect to our optimal configuration. This suggests that joint covariations in parameters may influence the network’s optimality. While our finite Monte-Carlo random sampling does not fully prove the global optimality of the configuration in <xref ref-type="table" rid="table1">Table 1</xref>, it shows that it is highly efficient.</p><table-wrap id="table2" position="float"><label>Table 2.</label><caption><title>Table of parameter ranges for Monte-Carlo sampling.</title><p>Minimum and maximum of the uniform distributions from which we randomly drew parameters during Monte-Carlo random sampling.</p></caption><table frame="hsides" rules="groups"><thead><tr><th align="left" valign="bottom">Parameter</th><th align="left" valign="bottom"><inline-formula><mml:math id="inf103"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msubsup><mml:mi>τ</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>r</mml:mi></mml:mrow><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>E</mml:mi></mml:mrow></mml:msubsup></mml:mstyle></mml:math></inline-formula></th><th align="left" valign="bottom"><inline-formula><mml:math id="inf104"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msubsup><mml:mi>τ</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>r</mml:mi></mml:mrow><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>I</mml:mi></mml:mrow></mml:msubsup></mml:mstyle></mml:math></inline-formula></th><th align="left" valign="bottom"><inline-formula><mml:math id="inf105"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>β</mml:mi></mml:mstyle></mml:math></inline-formula></th><th align="left" valign="bottom"><inline-formula><mml:math id="inf106"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>σ</mml:mi></mml:mstyle></mml:math></inline-formula></th><th align="left" valign="bottom"><inline-formula><mml:math id="inf107"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msup><mml:mi>N</mml:mi><mml:mrow><mml:mspace width="thinmathspace"/><mml:mi>E</mml:mi></mml:mrow></mml:msup><mml:mo>:</mml:mo><mml:msup><mml:mi>N</mml:mi><mml:mrow><mml:mspace width="thinmathspace"/><mml:mi>I</mml:mi></mml:mrow></mml:msup></mml:mstyle></mml:mrow></mml:mstyle></mml:math></inline-formula></th><th align="left" valign="bottom">mean I-I: mean E-I</th></tr></thead><tbody><tr><td align="left" valign="bottom">minimum</td><td align="char" char="." valign="bottom">5 ms</td><td align="char" char="." valign="bottom">5 ms</td><td align="char" char="." valign="bottom">2 mV</td><td align="char" char="." valign="bottom">1 mV</td><td align="char" char="." valign="bottom">1</td><td align="char" char="." valign="bottom">1</td></tr><tr><td align="left" valign="bottom">maximum</td><td align="char" char="." valign="bottom">50 ms</td><td align="char" char="." valign="bottom">50 ms</td><td align="char" char="." valign="bottom">29 mV</td><td align="char" char="." valign="bottom">10 mV</td><td align="char" char="." valign="bottom">8</td><td align="char" char="." valign="bottom">8</td></tr></tbody></table></table-wrap><fig id="fig2" position="float"><label>Figure 2.</label><caption><title>Monte-Carlo joint random sampling on six model parameters.</title><p>(<bold>A</bold>) Distribution of the trial-averaged loss, with weighting  <inline-formula><mml:math id="inf108"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msub><mml:mi>g</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>L</mml:mi></mml:mrow></mml:msub></mml:mstyle></mml:math></inline-formula> = 0.7, from 10,000 random simulations and using 20 simulation trials of duration of 1 s for each parameter configuration. The red cross marks the average loss of the parameter setting in <xref ref-type="table" rid="table1">Table 1</xref>. Inset: The average loss of the parameter setting in <xref ref-type="table" rid="table1">Table 1</xref> (red cross) and of the first- and second-best parameter settings from the random search. (<bold>B</bold>) Distribution of the average loss across 20 simulation trials for the parameter setting in <xref ref-type="table" rid="table1">Table 1</xref> (red) and for the first four ranked points according to the trial-averaged loss in A. Stars indicate a significant two-tailed t-test against the distribution in red (*** indicate <inline-formula><mml:math id="inf109"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>p</mml:mi><mml:mo>&lt;</mml:mo><mml:mn>0.001</mml:mn></mml:mstyle></mml:math></inline-formula>). (<bold>C</bold>) Same as in A, for different values of weighting of the error with the cost <inline-formula><mml:math id="inf110"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msub><mml:mi>g</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>L</mml:mi></mml:mrow></mml:msub></mml:mstyle></mml:math></inline-formula>. Parameters for all plots are in <xref ref-type="table" rid="table1">Table 1</xref>.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-99545-fig2-v1.tif"/></fig><table-wrap id="table3" position="float"><label>Table 3.</label><caption><title>Table of best four parameter settings from Monte-Carlo sampling.</title><p>The performance was evaluated using trial- and time-averaged loss. Each parameter setting was evaluated on 20 trials, with each trial using an independent realization of tuning parameters, noise in the non-specific current and initial conditions for the integration of the membrane potentials. We tested 10,000 parameter settings.</p></caption><table frame="hsides" rules="groups"><thead><tr><th align="left" valign="bottom">Parameter</th><th align="left" valign="bottom"><inline-formula><mml:math id="inf111"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msubsup><mml:mi>τ</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>r</mml:mi></mml:mrow><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>E</mml:mi></mml:mrow></mml:msubsup></mml:mstyle></mml:math></inline-formula></th><th align="left" valign="bottom"><inline-formula><mml:math id="inf112"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msubsup><mml:mi>τ</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>r</mml:mi></mml:mrow><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>I</mml:mi></mml:mrow></mml:msubsup></mml:mstyle></mml:math></inline-formula></th><th align="left" valign="bottom"><inline-formula><mml:math id="inf113"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>β</mml:mi></mml:mstyle></mml:math></inline-formula></th><th align="left" valign="bottom"><inline-formula><mml:math id="inf114"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>σ</mml:mi></mml:mstyle></mml:math></inline-formula></th><th align="left" valign="bottom"><inline-formula><mml:math id="inf115"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msup><mml:mi>N</mml:mi><mml:mrow><mml:mspace width="thinmathspace"/><mml:mi>E</mml:mi></mml:mrow></mml:msup><mml:mo>:</mml:mo><mml:msup><mml:mi>N</mml:mi><mml:mrow><mml:mspace width="thinmathspace"/><mml:mi>I</mml:mi></mml:mrow></mml:msup></mml:mstyle></mml:mrow></mml:mstyle></mml:math></inline-formula></th><th align="left" valign="bottom">mean I-I: mean E-I</th></tr></thead><tbody><tr><td align="left" valign="bottom">First</td><td align="char" char="." valign="bottom">12.6</td><td align="char" char="." valign="bottom">11.1</td><td align="char" char="." valign="bottom">2.1</td><td align="char" char="." valign="bottom">4.7</td><td align="char" char="." valign="bottom">5.4</td><td align="char" char="." valign="bottom">3.0</td></tr><tr><td align="left" valign="bottom">Second</td><td align="char" char="." valign="bottom">11.4</td><td align="char" char="." valign="bottom">10.0</td><td align="char" char="." valign="bottom">2.9</td><td align="char" char="." valign="bottom">6.2</td><td align="char" char="." valign="bottom">6.1</td><td align="char" char="." valign="bottom">3.3</td></tr><tr><td align="left" valign="bottom">Third</td><td align="char" char="." valign="bottom">10.0</td><td align="char" char="." valign="bottom">10.7</td><td align="char" char="." valign="bottom">10.1</td><td align="char" char="." valign="bottom">3.0</td><td align="char" char="." valign="bottom">3.2</td><td align="char" char="." valign="bottom">2.5</td></tr><tr><td align="left" valign="bottom">Fourth</td><td align="char" char="." valign="bottom">12.5</td><td align="char" char="." valign="bottom">13.5</td><td align="char" char="." valign="bottom">2.9</td><td align="char" char="." valign="bottom">5.4</td><td align="char" char="." valign="bottom">4.9</td><td align="char" char="." valign="bottom">3.5</td></tr></tbody></table></table-wrap></sec><sec id="s2-3"><title>Competition across neurons with similar stimulus tuning emerging in efficient spiking networks</title><p>We next explored coding properties emerging from recurrent synaptic interactions between E and I populations in the optimally efficient networks.</p><p>An approach that has recently provided empirical insight into local recurrent interactions is measuring effective connectivity with cellular resolution. Recent effective connectivity experiments photostimulated single E neurons in primary visual cortex and measured its effect on neighbouring neurons, finding that the photostimulation of an E neuron led to a decrease in firing rate of similarly tuned close-by neurons (<xref ref-type="bibr" rid="bib22">Chettih and Harvey, 2019</xref>). This effective lateral inhibition (<xref ref-type="bibr" rid="bib58">Lochmann et al., 2012</xref>) between E neurons with similar tuning to the stimulus implements competition between neurons for the representation of stimulus features (<xref ref-type="bibr" rid="bib22">Chettih and Harvey, 2019</xref>). Since our model instantiates efficient coding by design and because we removed connections between neurons with different selectivity, we expected that our network implements lateral inhibition and would thus give comparable effective connectivity results in simulated photostimulation experiments.</p><p>To test this prediction, we simulated photostimulation experiments in our optimally efficient network. We first performed experiments in the absence of the feedforward input to ensure all effects are only due to the recurrent processing. We stimulated a randomly selected single target E neuron and measured the change in the instantaneous firing rate from the baseline firing rate, <inline-formula><mml:math id="inf116"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi mathvariant="normal">Δ</mml:mi><mml:msub><mml:mi>z</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mstyle></mml:math></inline-formula>, in all the other I and E neurons (<xref ref-type="fig" rid="fig3">Figure 3A</xref>, left). The photostimulation was modeled as an application of a constant depolarising current with a strength parameter, <inline-formula><mml:math id="inf117"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msub><mml:mi>a</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>p</mml:mi></mml:mrow></mml:msub></mml:mstyle></mml:math></inline-formula>, proportional to the distance between the resting potential and the firing threshold (<inline-formula><mml:math id="inf118"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msub><mml:mi>a</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>p</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mn>0</mml:mn></mml:mstyle></mml:math></inline-formula> means no stimulation, while <inline-formula><mml:math id="inf119"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msub><mml:mi>a</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>p</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mstyle></mml:math></inline-formula> indicates photostimulation at the firing threshold). We quantified the effect of the simulated photostimulation of a target E neuron on other E and I neurons, distinguishing neurons with either similar or different tuning with respect to the target neuron (<xref ref-type="fig" rid="fig3">Figure 3A</xref>, right; <xref ref-type="fig" rid="fig3s1">Figure 3—figure supplement 1A–D</xref>).</p><fig-group><fig id="fig3" position="float"><label>Figure 3.</label><caption><title>Mechanism of lateral excitation/inhibition in the efficient spiking network.</title><p>(<bold>A</bold>) Left: Schematic of the E-I network and of the stimulation and measurement in a perturbation experiment. Right: Schematic of the propagation of the neural activity between E and I neurons with similar tuning. (<bold>B</bold>) Trial and neuron-averaged deviation of the firing rate from the baseline, for the population of I (top) and E (bottom) neurons with similar (magenta) and different tuning (gray) to the target neuron. Traces show the mean ± standard error of the mean, with the standard error of the mean on the variability across neurons and across trials. The stimulation strength corresponded to an increase in the firing rate of the stimulated neuron by 28.0 Hz. (<bold>C</bold>) Scatter plot of the tuning similarity vs. effective connectivity to the target neuron. Red line marks zero effective connectivity and magenta line is the least-squares line. Stimulation strength was <inline-formula><mml:math id="inf120"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msub><mml:mi>a</mml:mi><mml:mrow><mml:mi>p</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mstyle></mml:mrow></mml:mstyle></mml:math></inline-formula>. (<bold>D</bold>) Correlation of membrane potentials vs. the tuning similarity in E (top) and I cell type (bottom), for the efficient E-I network (left), for the network where each E neuron receives independent instead of shared stimulus features (middle), and for the network with unstructured connectivity (right). In the model with unstructured connectivity, elements of each connectivity matrix were randomly shuffled. We quantified voltage correlation using the (zero-lag) Pearson’s correlation coefficient, denoted as <inline-formula><mml:math id="inf121"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>ρ</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msubsup><mml:mi>V</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mspace width="thinmathspace"/><mml:mi>y</mml:mi></mml:mrow></mml:msubsup><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>,</mml:mo><mml:msubsup><mml:mi>V</mml:mi><mml:mrow><mml:mi>j</mml:mi></mml:mrow><mml:mrow><mml:mspace width="thinmathspace"/><mml:mi>y</mml:mi></mml:mrow></mml:msubsup><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo stretchy="false">)</mml:mo></mml:mstyle></mml:mrow></mml:mstyle></mml:math></inline-formula>, for each pair of neurons. (<bold>E</bold>) Average cross-correlogram (CCG) of spike timing with strongly similar (orange), weakly similar (green) and different tuning (black). Statistical results (<bold>B–E</bold>) were computed on 100 simulation trials. The duration of the trial in D-E was 1 s. Parameters for all plots are in <xref ref-type="table" rid="table1">Table 1</xref>.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-99545-fig3-v1.tif"/></fig><fig id="fig3s1" position="float" specific-use="child-fig"><label>Figure 3—figure supplement 1.</label><caption><title>Tuning similarity and its relation to lateral excitation/inhibition.</title><p>(<bold>A</bold>) Pair-wise tuning similarity for all pairs of E neurons. Tuning similarity is measured as cosine similarity of decoding vectors between the target neuron and every other E neuron. (<bold>B</bold>) Histogram of tuning similarity across all E-E pairs shown in <bold>A</bold>. (<bold>C</bold>) Tuning similarity to a single, randomly selected target neuron. Tuning similarity to a target neuron corresponds to a vector from the tuning similarity matrix in <bold>A</bold>. We sorted the tuning similarity to target from the smallest to the biggest value. Neurons with negative similarity are grouped as neurons with different tuning, while neurons with positive tuning similarity are grouped as neurons with similar tuning. (<bold>D</bold>) Histogram of tuning similarity of E neurons to the target neuron shown in <bold>C</bold>. With distribution of tuning parameters that is symmetric around zero as used in our study, any choice of the target neuron gives approximately the same number of neurons with similar and different selectivity. (<bold>E</bold>) Top: Trial and neuron-averaged deviation of the instantaneous firing rate from the baseline in presence of weak feedforward stimulus. We show the mean ± standard error of the mean (SEM) of neurons with similar (orange) and different tuning (gray) to the target neuron. The standard error of the mean shows the variability across enurons and across trials. The photostimulation intensity is at threshold (<inline-formula><mml:math id="inf122"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msub><mml:mi>a</mml:mi><mml:mrow><mml:mi>p</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mstyle></mml:mrow></mml:mstyle></mml:math></inline-formula>). The feedforward stimulus was received by all E neurons and it induced, together with the external current, the mean firing rates of 7.3 Hz and 13.5 Hz in E and I neurons, respectively. Bottom: Scatter plot of the tuning similarity versus effective connectivity. Magenta line marks the least-squares line. (<bold>F</bold>) Same as in <bold>E</bold>, for the network with partial (fine-grained) removal of connectivity structure. Partial removal of connectivity structure is achieved by shuffling the synaptic weights among pairs of neurons with similar tuning (for which <inline-formula><mml:math id="inf123"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msubsup><mml:mi>ϕ</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow><mml:mrow><mml:mi>X</mml:mi><mml:mi>Y</mml:mi></mml:mrow></mml:msubsup><mml:mo>&gt;</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:mstyle></mml:math></inline-formula>). For model parameters, see <xref ref-type="table" rid="table1">Table 1</xref>.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-99545-fig3-figsupp1-v1.tif"/></fig></fig-group><p>The photostimulation of the target E neuron increased the instantaneous firing rate of similarly-tuned I neurons and reduced that of other similarly-tuned E neurons (<xref ref-type="fig" rid="fig3">Figure 3B</xref>). We quantified the effective connectivity as the difference between the time-averaged firing rate of the recorded cell in presence or absence of the photostimulation of the targeted cell, measured during perturbation and up to 50 ms after. We found positive effective connectivity on I and negative effective connectivity on E neurons with similar tuning to the target neuron, with a positive correlation between tuning similarity and effective connectivity on I neurons and a negative correlation on E neurons (<xref ref-type="fig" rid="fig3">Figure 3C</xref>). We confirmed these effects of photostimulation in presence of a weak feedforward input (<xref ref-type="fig" rid="fig3s1">Figure 3—figure supplement 1E</xref>), similar to the experiments of <xref ref-type="bibr" rid="bib22">Chettih and Harvey, 2019</xref> in which photostimulation was applied during the presentation of visual stimuli with weak contrast. Thus, the optimal network replicates the preponderance of negative effective connectivity between E neurons and the dependence of its strength on tuning similarity found in <xref ref-type="bibr" rid="bib22">Chettih and Harvey, 2019</xref>.</p><p>In summary, lateral excitation of I neurons and lateral inhibition of E neurons with similar tuning is an emerging coding property of the efficient E-I network, which recapitulates competition between neurons with similar stimulus tuning found in visual cortex (<xref ref-type="bibr" rid="bib22">Chettih and Harvey, 2019</xref>; <xref ref-type="bibr" rid="bib72">Oldenburg et al., 2024</xref>). An intuition of why this competition implements efficient coding is that the E neuron that fires first activates I neurons with similar tuning. In turn, these I neurons inhibit all similarly tuned E neurons (<xref ref-type="fig" rid="fig3">Figure 3A</xref>, right), preventing them to generate redundant spikes to encode the sensory information that has already been encoded by the first spike. Suppression of redundant spiking reduces metabolic cost without reducing encoded information (<xref ref-type="bibr" rid="bib11">Boerlin et al., 2013</xref>; <xref ref-type="bibr" rid="bib48">Koren and Denève, 2017</xref>).</p><p>While perturbing the activity of E neurons in our model qualitatively reproduces empirically observed lateral inhibition among E neurons (<xref ref-type="bibr" rid="bib22">Chettih and Harvey, 2019</xref>; <xref ref-type="bibr" rid="bib72">Oldenburg et al., 2024</xref>), these experiments have also reported positive effective connectivity between E neurons with very similar stimulus tuning. Our intuition is that our simple model cannot reproduce this finding because it lacks E-E connectivity.</p><p>To explore further the consequences of E-I interactions for stimulus encoding, we next investigated the dynamics of lateral inhibition in the optimal network driven by the feedforward sensory input but without perturbing the neural activity. Previous work has established that efficient spiking neurons may present strong correlations in the membrane potentials, but only weak correlations in the spiking output, because redundant spikes are prevented by lateral inhibition (<xref ref-type="bibr" rid="bib11">Boerlin et al., 2013</xref>; <xref ref-type="bibr" rid="bib28">Deneve and Machens, 2016b</xref>). We investigated voltage correlations in pairs of neurons within our network as a function of their tuning similarity. Because the feedforward inputs are shared across E neurons and weighted by their tuning parameters, they cause strong positive voltage correlations between E-E neuronal pairs with very similar tuning and strong negative correlations between pairs with very different (opposite) tuning (<xref ref-type="fig" rid="fig3">Figure 3D</xref>, top-left). Voltage correlations between E-E pairs vanished regardless of tuning similarity when we made the feedforward inputs independent across neurons (<xref ref-type="fig" rid="fig3">Figure 3D</xref>, top-middle), showing that the dependence of voltage correlations on tuning similarity occurs because of shared feedforward inputs. In contrast to E neurons, I neurons do not receive feedforward inputs and are driven only by similarly tuned E neurons (<xref ref-type="fig" rid="fig3">Figure 3A</xref>, right). This causes positive voltage correlations in I-I neuronal pairs with similar tuning and vanishing correlations in neurons with different tuning (<xref ref-type="fig" rid="fig3">Figure 3D</xref>, bottom-left). Such dependence of voltage correlations on tuning similarity disappears when removing the structure from the E-I synaptic connectivity (<xref ref-type="fig" rid="fig3">Figure 3D</xref>, bottom-right).</p><p>In contrast to voltage correlations, and as expected by previous studies (<xref ref-type="bibr" rid="bib11">Boerlin et al., 2013</xref>; <xref ref-type="bibr" rid="bib28">Deneve and Machens, 2016b</xref>), the coordination of spike timing of pairs of E neurons (measured with cross-correlograms or CCGs) was very weak (<xref ref-type="fig" rid="fig3">Figure 3E</xref>). For I-I and E-I neuronal pairs, the peaks of CCGs were stronger than those observed in E-E pairs, but they were present only at very short lags (lags &lt; 1 ms). This confirms that recurrent interactions of the efficient E-I network wipe away the effect of membrane potential correlations at the spiking output level, and shows information processing with millisecond precision in these networks (<xref ref-type="bibr" rid="bib11">Boerlin et al., 2013</xref>; <xref ref-type="bibr" rid="bib28">Deneve and Machens, 2016b</xref>; <xref ref-type="bibr" rid="bib48">Koren and Denève, 2017</xref>).</p></sec><sec id="s2-4"><title>The effect of structured connectivity on coding efficiency and neural dynamics</title><p>The analytical solution of the optimally efficient E-I network predicts that recurrent synaptic weights are proportional to the tuning similarity between neurons. We next investigated the role of such connectivity structure by comparing the behavior of an efficient network with an unstructured E-I network, similar to the type studied in previous works (<xref ref-type="bibr" rid="bib15">Brunel, 2000</xref>; <xref ref-type="bibr" rid="bib82">Renart et al., 2010</xref>; <xref ref-type="bibr" rid="bib63">Mazzoni et al., 2008</xref>). We removed the connectivity structure by randomly permuting synaptic weights across neuronal pairs (see Materials and methods). Such shuffling destroys the relationship between tuning similarity and synaptic strength (as shown in <xref ref-type="fig" rid="fig1">Figure 1C(ii)</xref>) while it preserves Dale’s law and the overall distribution of connectivity weights.</p><p>We found that shuffling the connectivity structure significantly altered the efficiency of the network (<xref ref-type="fig" rid="fig4">Figure 4A, B</xref>), neural dynamics (<xref ref-type="fig" rid="fig4">Figure 4C, D, F–H</xref>) and lateral inhibition (<xref ref-type="fig" rid="fig4">Figure 4I</xref>). In particular, structured networks differ from unstructured ones by showing better encoding performance (<xref ref-type="fig" rid="fig4">Figure 4A</xref>), lower metabolic cost (<xref ref-type="fig" rid="fig4">Figure 4B</xref>), weaker variance of the membrane potential over time (<xref ref-type="fig" rid="fig4">Figure 4C</xref>), lower firing rates (<xref ref-type="fig" rid="fig4">Figure 4D</xref>) and weaker average (<xref ref-type="fig" rid="fig4">Figure 4F</xref>) and instantaneous balance (<xref ref-type="fig" rid="fig4">Figure 4G</xref>) of synaptic inputs. However, we found only a small difference in the variability of spiking between structured and unstructured networks (<xref ref-type="fig" rid="fig4">Figure 4E</xref>). While these results are difficult to test experimentally due to the difficulty of manipulating synaptic connectivity structures in vivo, they highlight the importance of the connectivity structure for cortical computations.</p><fig-group><fig id="fig4" position="float"><label>Figure 4.</label><caption><title>Effects of connectivity structure on coding efficiency, neural dynamics and lateral inhibition.</title><p>(<bold>A</bold>) Left: Root mean squared error (RMSE) in networks with structured and randomly shuffled recurrent connectivity. Random shuffling consisted of a random permutation of the elements within each of the three (<bold>E–I, I–I, I–E</bold>) connectivity matrices. Right: Distribution of decoding weights after training the decoder on neural activity from the structured network (green), and a sample from uniform distribution as typically used in the optimal network. (<bold>B</bold>) Metabolic cost in structured and shuffled networks with matched average balance. The average balance of the shuffled network was matched with the one of the structured network by changing the following parameters: <inline-formula><mml:math id="inf124"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow class="MJX-TeXAtom-ORD"><mml:mover><mml:mi>β</mml:mi><mml:mo stretchy="false">~</mml:mo></mml:mover></mml:mrow><mml:mo>=</mml:mo><mml:mn>16.3</mml:mn></mml:mstyle></mml:math></inline-formula>, <inline-formula><mml:math id="inf125"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow class="MJX-TeXAtom-ORD"><mml:mover><mml:mi>σ</mml:mi><mml:mo stretchy="false">~</mml:mo></mml:mover></mml:mrow><mml:mo>=</mml:mo><mml:mn>3</mml:mn></mml:mstyle></mml:math></inline-formula> and by decreasing the amplitude of the OU stimulus by factor of 0.88. (<bold>C</bold>) Standard deviation of the membrane potential (in mV) for networks with structured and unstructured connectivity. Distributions are across neurons. (<bold>D</bold>) Average firing rate of E (top) and I neurons (bottom) in networks with structured and unstructured connectivity. (<bold>E</bold>) Same as in D, showing the coefficient of variation of spiking activity in a network responding to a constant stimulus. (<bold>F</bold>) Same as in D, showing the average net synaptic input, a measure of average imbalance. (<bold>G</bold>) Same as in D, showing the time-dependent correlation of synaptic inputs, a measure of instantaneous balance. (<bold>H</bold>) Voltage correlation in E-E (top) and I-I neuronal pairs (bottom) for the four cases of unstructured connectivity (colored dots) and the equivalent result in the structured network (grey dots). We show the results for pairs with similar tuning. (<bold>I</bold>) Scatter plot of effective connectivity versus tuning similarity to the photostimulated E neuron in shuffled networks. The title of each plot indicates the connectivity matrix that has been shuffled. The magenta line is the least-squares regression line and the photostimulation is at threshold (<inline-formula><mml:math id="inf126"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msub><mml:mi>a</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>p</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mn>1.0</mml:mn></mml:mstyle></mml:math></inline-formula>). Results were computed using 200 (<bold>A–G</bold>) and 100 (<bold>H–I</bold>) simulation trials of 1 s duration. Parameters for all plots are in <xref ref-type="table" rid="table1">Table 1</xref>.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-99545-fig4-v1.tif"/></fig><fig id="fig4s1" position="float" specific-use="child-fig"><label>Figure 4—figure supplement 1.</label><caption><title>Effect of removal of connectivity structure and of jittering of synaptic weights.</title><p>(<bold>A</bold>) Distribution of decoding weights after training a linear decoder on neural activity generated by the network without connectivity structure. (<bold>B</bold>) RMSE in E (top) and I neurons (bottom) in networks with partial removal of connectivity structure. Partial removal of connectivity structure is achieved by limiting the permutation of synaptic connectivity to neuronal pairs with similar tuning, e.g. to neuronal pairs for which the following is true: <inline-formula><mml:math id="inf127"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msubsup><mml:mi mathvariant="normal">Φ</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow><mml:mrow><mml:mi>X</mml:mi><mml:mi>Y</mml:mi></mml:mrow></mml:msubsup><mml:mo>&gt;</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:mstyle></mml:math></inline-formula>. (<bold>C</bold>) Same as in B, showing the average metabolic cost on spiking. (<bold>D</bold>) Same as in B, showing the average net synaptic input, a measure of the average E-I balance. (<bold>E</bold>) Same as in B, showing the correlation of synaptic inputs, a measure of instantaneous balance. (<bold>F</bold>) Average deviation of the instantaneous firing rate from the baseline for the population of I (top) and E (bottom) neurons in networks with fully removed structure in E-I (left), I-E (middle) and in all connectivity matrices (right). We show the mean ± SEM for neurons with similar (ochre) and different (green) tuning to the target neuron. The mean traces of the network with structured connectivity are shown for comparison, with magenta and gray for similar and different tuning, respectively. (<bold>G</bold>) Top: The RMSE (top) in E and I cell type, as a function of the strength of perturbation of the synaptic connectivity by random jittering. Bottom: Same as on top, showing the normalized metabolic cost (green) and average loss (black). (<bold>H</bold>) Target signals, E estimates and I estimates in three input dimensions (three top rows), spike trains (fourth row) and the instantaneous estimate of the firing rate of E and I populations (bottom) in a simulation trial, with significant jitter of recurrent connectivity (jittering strength of 0.5, see Methods). In spite of a relatively strong jittering, the network shows excellent encoding of the target signal. All statistical results were computed in 100 simulation trials of duration of 1 second. Other parameters are in <xref ref-type="table" rid="table1">Table 1</xref>.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-99545-fig4-figsupp1-v1.tif"/></fig></fig-group><p>We also compared structured and unstructured networks about their relation between pairwise voltage correlations and tuning similarity, by randomizing connections within a single connectivity type (E-I, I-I or I-E) or within all these three connectivity types at once (‘all’). We found the structure of E-I connectivity to be crucial for the linear relation between voltage correlations and tuning similarity in pairs of I neurons (<xref ref-type="fig" rid="fig4">Figure 4H</xref>, magenta).</p><p>Finally, we analyzed how the structure in recurrent connectivity influences lateral inhibition that we observed in efficient networks. We found that the dependence of lateral inhibition on tuning similarity vanishes when the connectivity structure is fully removed (<xref ref-type="fig" rid="fig4">Figure 4I</xref>, ‘all’ on the right plot), thus showing that connectivity structure is necessary for lateral inhibition. While networks with unstructured E-I and I-E connectivity still show inhibition in E neurons upon single neuron photostimulation (because of the net inhibitory effect of recurrent connectivity; <xref ref-type="fig" rid="fig4s1">Figure 4—figure supplement 1F</xref>), this inhibition was largely unspecific to tuning similarity (<xref ref-type="fig" rid="fig4">Figure 4I</xref>, ‘E-I’ and ‘I-E’). Unstructured connectivity decreased the correlation between tuning similarity and effective connectivity from <inline-formula><mml:math id="inf128"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>r</mml:mi><mml:mo>=</mml:mo><mml:mo stretchy="false">[</mml:mo><mml:mn>0.31</mml:mn><mml:mo>,</mml:mo><mml:mo>−</mml:mo><mml:mn>0.54</mml:mn><mml:mo stretchy="false">]</mml:mo></mml:mrow></mml:mstyle></mml:math></inline-formula> in I and E neurons in a structured network to <inline-formula><mml:math id="inf129"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>r</mml:mi><mml:mo>=</mml:mo><mml:mo stretchy="false">[</mml:mo><mml:mn>0.02</mml:mn><mml:mo>,</mml:mo><mml:mo>−</mml:mo><mml:mn>0.13</mml:mn><mml:mo stretchy="false">]</mml:mo></mml:mrow></mml:mstyle></mml:math></inline-formula> and <inline-formula><mml:math id="inf130"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>r</mml:mi><mml:mo>=</mml:mo><mml:mo stretchy="false">[</mml:mo><mml:mn>0.57</mml:mn><mml:mo>,</mml:mo><mml:mn>0.11</mml:mn><mml:mo stretchy="false">]</mml:mo></mml:mrow></mml:mstyle></mml:math></inline-formula> in networks with unstructured E-I and I-E connectivity, respectively. Removing the structure in I-I connectivity, in contrast, increased the correlation between effective connectivity and tuning similarity in E neurons (<inline-formula><mml:math id="inf131"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>r</mml:mi><mml:mo>=</mml:mo><mml:mo stretchy="false">[</mml:mo><mml:mn>0.30</mml:mn><mml:mo>,</mml:mo><mml:mo>−</mml:mo><mml:mn>0.65</mml:mn><mml:mo stretchy="false">]</mml:mo></mml:mstyle></mml:math></inline-formula>, <xref ref-type="fig" rid="fig4">Figure 4I</xref>, second from the left), showing that lateral inhibition takes place irrespectively of the I-I connectivity structure.</p><p>Previous empirical (<xref ref-type="bibr" rid="bib112">Znamenskiy et al., 2024</xref>) and theoretical work has established the necessity of strong E-I-E synaptic connectivity for lateral inhibition (<xref ref-type="bibr" rid="bib86">Sadeh and Clopath, 2020</xref>; <xref ref-type="bibr" rid="bib60">Mackwood et al., 2021</xref>). To refine this understanding, we asked what is the minimal connectivity structure necessary to qualitatively replicate empirically observed lateral inhibition. We did so by considering a simpler connectivity rule than the one obtained from first principles. We assumed neurons to be connected (with random synaptic efficacy) if their tuning vectors are similar (<inline-formula><mml:math id="inf132"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msubsup><mml:mi>J</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow><mml:mrow><mml:mspace width="thinmathspace"/><mml:mi>x</mml:mi><mml:mi>y</mml:mi></mml:mrow></mml:msubsup><mml:mo>&gt;</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:mstyle></mml:math></inline-formula> if <inline-formula><mml:math id="inf133"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msubsup><mml:mi>ϕ</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>x</mml:mi><mml:mi>y</mml:mi></mml:mrow></mml:msubsup><mml:mo>&gt;</mml:mo><mml:mn>0</mml:mn></mml:mstyle></mml:math></inline-formula>) and unconnected otherwise (<inline-formula><mml:math id="inf134"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msubsup><mml:mi>J</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow><mml:mrow><mml:mspace width="thinmathspace"/><mml:mi>x</mml:mi><mml:mi>y</mml:mi></mml:mrow></mml:msubsup><mml:mo>=</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:mstyle></mml:math></inline-formula> if <inline-formula><mml:math id="inf135"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msubsup><mml:mi>ϕ</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>x</mml:mi><mml:mi>y</mml:mi></mml:mrow></mml:msubsup><mml:mo>≤</mml:mo><mml:mn>0</mml:mn></mml:mstyle></mml:math></inline-formula>), relaxing the precise proportionality relationship between tuning similarity and synaptic weights (as on <xref ref-type="fig" rid="fig1">Figure 1C(ii)</xref>). We found that networks with such simpler connectivity respond to activity perturbation in a qualitatively similar way as the optimal network (<xref ref-type="fig" rid="fig3s1">Figure 3—figure supplement 1F</xref>) and still replicate experimentally observed activity profiles in <xref ref-type="bibr" rid="bib22">Chettih and Harvey, 2019</xref>.</p><p>While optimally structured connectivity predicted by efficient coding is biologically plausible, it may be difficult to realise it exactly on a synapse-by-synapse basis in biological networks. Following <xref ref-type="bibr" rid="bib18">Calaim et al., 2022</xref>, we verified the robustness of the model to small deviations from the optimal synaptic weights by adding a random jitter, proportional to the synaptic strength, to all synaptic connections (see Materials and methods). The encoding performance and neural activity were barely affected by weak and moderate levels of such perturbation (<xref ref-type="fig" rid="fig4s1">Figure 4—figure supplement 1G, H</xref>), demonstrating that the network is robust against random jittering of the optimal synaptic weights.</p><p>In summary, we found that some aspects of recurrent connectivity structure, such as the like-to-like organization, are crucial to achieve efficient coding. Instead, for other aspects there is considerable flexibility; the proportionality between tuning similarity and synaptic weights is not crucial for efficiency and small random jitter of optimal weights has only minor effects. Structured E-I and I-E, but not I-I connectivity, is necessary for implementing experimentally observed pattern of lateral inhibition whose strength is modulated by tuning similarity.</p></sec><sec id="s2-5"><title>Weak or no spike-triggered adaptation optimizes network efficiency</title><p>We next investigated the role of within-neuron feedback triggered by each spike, <inline-formula><mml:math id="inf136"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msubsup><mml:mi>I</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mspace width="thinmathspace"/><mml:mtext>ad</mml:mtext><mml:mo>,</mml:mo><mml:mi>y</mml:mi></mml:mrow></mml:msubsup></mml:mrow></mml:mstyle></mml:math></inline-formula>, that emerges from the optimally efficient solution (<xref ref-type="disp-formula" rid="equ5">Equation 5</xref>). A previous study (<xref ref-type="bibr" rid="bib39">Gutierrez and Denève, 2019</xref>) showed that spike-triggered adaptation, together with structured connectivity, redistributes the activity from highly excitable neurons to less excitable neurons, leaving the population readout invariant. Here, we address model efficiency in presence of adapting or facilitating feedback as well as differential effects of adaptation in E and I neurons.</p><p>The spike-triggered within-neuron feedback <inline-formula><mml:math id="inf137"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msubsup><mml:mi>I</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mspace width="thinmathspace"/><mml:mtext>ad</mml:mtext><mml:mo>,</mml:mo><mml:mi>y</mml:mi></mml:mrow></mml:msubsup></mml:mrow></mml:mstyle></mml:math></inline-formula> has a time constant equal to that of the single neuron readout <inline-formula><mml:math id="inf138"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msubsup><mml:mi>τ</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>r</mml:mi></mml:mrow><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>E</mml:mi></mml:mrow></mml:msubsup></mml:mstyle></mml:math></inline-formula> (E neurons) and <inline-formula><mml:math id="inf139"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msubsup><mml:mi>τ</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>r</mml:mi></mml:mrow><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>I</mml:mi></mml:mrow></mml:msubsup></mml:mstyle></mml:math></inline-formula> (I neurons). The strength of the current is proportional to the difference in inverse time constants of single neuron and population readouts, <inline-formula><mml:math id="inf140"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mn>1</mml:mn><mml:mrow><mml:mo>/</mml:mo></mml:mrow><mml:mi>τ</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn><mml:mrow><mml:mo>/</mml:mo></mml:mrow><mml:msubsup><mml:mi>τ</mml:mi><mml:mrow><mml:mi>r</mml:mi></mml:mrow><mml:mrow><mml:mspace width="thinmathspace"/><mml:mi>y</mml:mi></mml:mrow></mml:msubsup></mml:mrow></mml:mstyle></mml:math></inline-formula>. This spike-triggered current is negative, giving spike-triggered adaptation (<xref ref-type="bibr" rid="bib64">Mensi et al., 2012</xref>), if the single-neuron readout has longer time constant than the population readout (<inline-formula><mml:math id="inf141"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msubsup><mml:mi>τ</mml:mi><mml:mrow><mml:mi>r</mml:mi></mml:mrow><mml:mrow><mml:mspace width="thinmathspace"/><mml:mi>y</mml:mi></mml:mrow></mml:msubsup><mml:mo>&gt;</mml:mo><mml:mi>τ</mml:mi></mml:mrow></mml:mstyle></mml:math></inline-formula>), or positive, giving spike-triggered facilitation, if the opposite is true (<inline-formula><mml:math id="inf142"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msubsup><mml:mi>τ</mml:mi><mml:mrow><mml:mi>r</mml:mi></mml:mrow><mml:mrow><mml:mspace width="thinmathspace"/><mml:mi>y</mml:mi></mml:mrow></mml:msubsup><mml:mo>&lt;</mml:mo><mml:mi>τ</mml:mi></mml:mrow></mml:mstyle></mml:math></inline-formula>; <xref ref-type="table" rid="table4">Table 4</xref>). We expected that network efficiency would benefit from spike-triggered adaptation, because accurate encoding requires fast temporal dynamics of the population readouts, to capture fast fluctuations in the target signal, while we expect a slower dynamics in the readout of single neuron’s firing frequency, <inline-formula><mml:math id="inf143"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msubsup><mml:mi>r</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mspace width="thinmathspace"/><mml:mi>y</mml:mi></mml:mrow></mml:msubsup><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mstyle></mml:mrow></mml:mstyle></mml:math></inline-formula>, a process that could be related to homeostatic regulation of single neuron’s firing rate (<xref ref-type="bibr" rid="bib1">Abbott and Nelson, 2000</xref>; <xref ref-type="bibr" rid="bib101">Turrigiano and Nelson, 2004</xref>). In our optimal E-I network we indeed found that optimal coding efficiency is achieved in absence of within-neuron feedback or with weak adaptation in both cell types (<xref ref-type="fig" rid="fig5">Figure 5A</xref>). The optimal set of time constants <inline-formula><mml:math id="inf144"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mo stretchy="false">[</mml:mo><mml:msubsup><mml:mi>τ</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>r</mml:mi></mml:mrow><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>E</mml:mi></mml:mrow></mml:msubsup><mml:mo>,</mml:mo><mml:msubsup><mml:mi>τ</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>r</mml:mi></mml:mrow><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>I</mml:mi></mml:mrow></mml:msubsup><mml:mo stretchy="false">]</mml:mo></mml:mstyle></mml:math></inline-formula> only weakly depended on the weighting of the encoding error with the metabolic cost <inline-formula><mml:math id="inf145"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msub><mml:mi>g</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>L</mml:mi></mml:mrow></mml:msub></mml:mstyle></mml:math></inline-formula> (<xref ref-type="fig" rid="fig7s1">Figure 7—figure supplement 1A</xref>). We note that adaptation in E neurons promotes efficient coding because it enforces every spike to be error-correcting, while a spike-triggered facilitation in E neurons would lead to additional spikes that might be redundant and reduce network efficiency. Contrary to previously proposed models of adaptation in LIF neurons (<xref ref-type="bibr" rid="bib14">Brette and Gerstner, 2005</xref>; <xref ref-type="bibr" rid="bib89">Schwalger and Lindner, 2013</xref>), the strength and the time constant of adaptation in our model are not independent, but they both depend on <inline-formula><mml:math id="inf146"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msubsup><mml:mi>τ</mml:mi><mml:mrow><mml:mi>r</mml:mi></mml:mrow><mml:mrow><mml:mspace width="thinmathspace"/><mml:mi>y</mml:mi></mml:mrow></mml:msubsup></mml:mstyle></mml:mrow></mml:mstyle></mml:math></inline-formula>, with larger <inline-formula><mml:math id="inf147"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msubsup><mml:mi>τ</mml:mi><mml:mrow><mml:mi>r</mml:mi></mml:mrow><mml:mrow><mml:mspace width="thinmathspace"/><mml:mi>y</mml:mi></mml:mrow></mml:msubsup></mml:mstyle></mml:mrow></mml:mstyle></mml:math></inline-formula> yielding both longer and stronger adaptation.</p><table-wrap id="table4" position="float"><label>Table 4.</label><caption><title>Relation of time constants of single-neuron and population readout set an adaptation or a facilitation current.</title><p>The population readout that evolves on a faster (slower) time scale than the single neuron readout determines a spike-triggered adaptation (facilitation) in its own cell type.</p></caption><table frame="hsides" rules="groups"><thead><tr><th align="left" valign="bottom">Relative speed</th><th align="left" valign="bottom">Relation of time constants</th><th align="left" valign="bottom">Current</th></tr></thead><tbody><tr><td align="left" valign="bottom"><inline-formula><mml:math id="inf148"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msup><mml:mrow class="MJX-TeXAtom-ORD"><mml:mover><mml:mi>x</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>E</mml:mi></mml:mrow></mml:msup></mml:mstyle></mml:math></inline-formula> faster than <inline-formula><mml:math id="inf149"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msup><mml:mi>r</mml:mi><mml:mrow><mml:mspace width="thinmathspace"/><mml:mi>E</mml:mi></mml:mrow></mml:msup></mml:mrow></mml:mstyle></mml:math></inline-formula></td><td align="left" valign="bottom"><inline-formula><mml:math id="inf150"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>τ</mml:mi><mml:mo>&lt;</mml:mo><mml:msubsup><mml:mi>τ</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>r</mml:mi></mml:mrow><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>E</mml:mi></mml:mrow></mml:msubsup></mml:mstyle></mml:math></inline-formula></td><td align="left" valign="bottom">adaptation in E</td></tr><tr><td align="left" valign="bottom"><inline-formula><mml:math id="inf151"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msup><mml:mrow class="MJX-TeXAtom-ORD"><mml:mover><mml:mi>x</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>E</mml:mi></mml:mrow></mml:msup></mml:mstyle></mml:math></inline-formula> slower than <inline-formula><mml:math id="inf152"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msup><mml:mi>r</mml:mi><mml:mrow><mml:mspace width="thinmathspace"/><mml:mi>E</mml:mi></mml:mrow></mml:msup></mml:mrow></mml:mstyle></mml:math></inline-formula></td><td align="left" valign="bottom"><inline-formula><mml:math id="inf153"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>τ</mml:mi><mml:mo>&gt;</mml:mo><mml:msubsup><mml:mi>τ</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>r</mml:mi></mml:mrow><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>E</mml:mi></mml:mrow></mml:msubsup></mml:mstyle></mml:math></inline-formula></td><td align="left" valign="bottom">facilitation in E</td></tr><tr><td align="left" valign="bottom"><inline-formula><mml:math id="inf154"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msup><mml:mrow class="MJX-TeXAtom-ORD"><mml:mover><mml:mi>x</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>I</mml:mi></mml:mrow></mml:msup></mml:mstyle></mml:math></inline-formula> faster than <inline-formula><mml:math id="inf155"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msup><mml:mi>r</mml:mi><mml:mrow><mml:mspace width="thinmathspace"/><mml:mi>I</mml:mi></mml:mrow></mml:msup></mml:mrow></mml:mstyle></mml:math></inline-formula></td><td align="left" valign="bottom"><inline-formula><mml:math id="inf156"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>τ</mml:mi><mml:mo>&lt;</mml:mo><mml:msubsup><mml:mi>τ</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>r</mml:mi></mml:mrow><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>I</mml:mi></mml:mrow></mml:msubsup></mml:mstyle></mml:math></inline-formula></td><td align="left" valign="bottom">adaptation in I</td></tr><tr><td align="left" valign="bottom"><inline-formula><mml:math id="inf157"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msup><mml:mrow class="MJX-TeXAtom-ORD"><mml:mover><mml:mi>x</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>I</mml:mi></mml:mrow></mml:msup></mml:mstyle></mml:math></inline-formula> slower than <inline-formula><mml:math id="inf158"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msup><mml:mi>r</mml:mi><mml:mrow><mml:mspace width="thinmathspace"/><mml:mi>I</mml:mi></mml:mrow></mml:msup></mml:mrow></mml:mstyle></mml:math></inline-formula></td><td align="left" valign="bottom"><inline-formula><mml:math id="inf159"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>τ</mml:mi><mml:mo>&gt;</mml:mo><mml:msubsup><mml:mi>τ</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>r</mml:mi></mml:mrow><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>I</mml:mi></mml:mrow></mml:msubsup></mml:mstyle></mml:math></inline-formula></td><td align="left" valign="bottom">facilitation in I</td></tr></tbody></table></table-wrap><fig id="fig5" position="float"><label>Figure 5.</label><caption><title>Adaptation, network coding efficiency and excitation-inhibition balance.</title><p>(<bold>A</bold>) The encoding error (left), metabolic cost (middle) and average loss (right) as a function of single neuron time constants <inline-formula><mml:math id="inf160"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msubsup><mml:mi>τ</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>r</mml:mi></mml:mrow><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>E</mml:mi></mml:mrow></mml:msubsup></mml:mstyle></mml:math></inline-formula> (E neurons) and <inline-formula><mml:math id="inf161"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msubsup><mml:mi>τ</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>r</mml:mi></mml:mrow><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>I</mml:mi></mml:mrow></mml:msubsup></mml:mstyle></mml:math></inline-formula> (I neurons), in units of ms. These parameters set the sign, the strength, as well as the time constant of the feedback current in E and I neurons. Best performance (lowest average loss) is obtained in the top right quadrant, where the feedback current is spike-triggered adaptation in both E and I neurons. The performance measures are computed as a weighted sum of the respective measures across the E and I populations with equal weighting for E and I. All measures are plotted on the scale of the natural logarithm for better visibility. (<bold>B</bold>) Top: Log-log plot of the RMSE of the E (red) and the I (blue) estimates as a function of the time constant of the single neuron readout of E neurons, <inline-formula><mml:math id="inf162"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msubsup><mml:mi>τ</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>r</mml:mi></mml:mrow><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>E</mml:mi></mml:mrow></mml:msubsup></mml:mstyle></mml:math></inline-formula>, in the regime with spike-triggered adaptation. Feedback current in I neurons is set to 0. Bottom: Same as on top, as a function of <inline-formula><mml:math id="inf163"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msubsup><mml:mi>τ</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>r</mml:mi></mml:mrow><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>I</mml:mi></mml:mrow></mml:msubsup></mml:mstyle></mml:math></inline-formula> while the feedback current in E neurons is set to 0. (<bold>C</bold>) Same as in B, showing the average loss. (<bold>D</bold>) Same as in B, showing the firing rate. (<bold>E</bold>) Firing rate in E (left) and I neurons (right), as a function of time constants <inline-formula><mml:math id="inf164"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msubsup><mml:mi>τ</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>r</mml:mi></mml:mrow><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>E</mml:mi></mml:mrow></mml:msubsup></mml:mstyle></mml:math></inline-formula> and <inline-formula><mml:math id="inf165"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msubsup><mml:mi>τ</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>r</mml:mi></mml:mrow><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>I</mml:mi></mml:mrow></mml:msubsup></mml:mstyle></mml:math></inline-formula>. (<bold>F</bold>) Same as in E, showing the coefficient of variation. (<bold>G</bold>) Same as E, showing the average net synaptic input, a measure of average imbalance. (<bold>H</bold>) Same as E, showing the average net synaptic input, a measure of instantaneous balance. All statistical results were computed on 100 simulation trials of 1 s duration. For other parameters, see <xref ref-type="table" rid="table1">Table 1</xref>.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-99545-fig5-v1.tif"/></fig><p>To gain insights on the differential effect of adaptation in E vs I neurons, we set the adaptation in one cell type to 0 and varied the strength of adaptation in the other cell type by varying the time constant of the single neuron readout. With adaptation in E neurons (and no adaptation in I), we observed a slow increase of the encoding error in E neurons, while the encoding error increased faster with adaptation in I neurons (<xref ref-type="fig" rid="fig5">Figure 5B</xref>). Similarly, network efficiency increased slowly with adaptation in E and faster with adaptation in I neurons (<xref ref-type="fig" rid="fig5">Figure 5C</xref>), thus showing that adaptation in E neurons decreases less the performance compared to the adaptation in I neurons. With increasing adaptation in E neurons, the firing rate in E neurons decreased (<xref ref-type="fig" rid="fig5">Figure 5D</xref>), leading to E estimates with smaller amplitude. Because E estimates are target signals for I neurons and because weaker E signals imply weaker drive to I neurons, average loss of the I population decreased by increasing adaptation in E neurons (<xref ref-type="fig" rid="fig5">Figure 5C</xref> top, blue trace).</p><p>Firing rates and variability of spiking were sensitive to the strength of adaptation. As expected, adaptation in E neurons caused a decrease in the firing levels in both cell types (<xref ref-type="fig" rid="fig5">Figure 5D, E</xref>). In contrast, adaptation in I neurons decreased the firing rate in I neurons, but increased the firing rate in E neurons, due to a decrease in the level of inhibition. Furthermore, adaptation decreased the variability of spiking, in particular in the cell type with strong adaptation (<xref ref-type="fig" rid="fig5">Figure 5F</xref>), a well-known effect of spike-triggered adaptation in single neurons (<xref ref-type="bibr" rid="bib89">Schwalger and Lindner, 2013</xref>).</p><p>In regimes with adaptation, time constants of single neuron readout <inline-formula><mml:math id="inf166"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msubsup><mml:mi>τ</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>r</mml:mi></mml:mrow><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>y</mml:mi></mml:mrow></mml:msubsup></mml:mstyle></mml:math></inline-formula> influenced the average balance (<xref ref-type="fig" rid="fig5">Figure 5G</xref>) as well as the instantaneous balance (<xref ref-type="fig" rid="fig5">Figure 5H</xref>) in E and I cell type. To gain a better understanding of the relationship between adaptation, E-I interactions and network optimality, we measured the instantaneous and time-averaged E-I balance while varying the adaptation parameters and studied their relation with the loss. By increasing adaptation in E neurons, the average imbalance got weaker in E neurons (<xref ref-type="fig" rid="fig5">Figure 5G</xref>, left), but stronger in I neurons (<xref ref-type="fig" rid="fig5">Figure 5G</xref>, right). Regimes with precise average balance in both cell types were suboptimal (compare <xref ref-type="fig" rid="fig5">Figure 5A</xref>, right and G), while regimes with precise instantaneous balance were highly efficient (compare <xref ref-type="fig" rid="fig5">Figure 5A</xref>, right and H).</p><p>To test how well the average balance and the instantaneous balance of synaptic inputs predict network efficiency, we concatenated the column-vectors of the measured average loss and of the average imbalance in each cell type and computed the Pearson correlation between these quantities. The correlation between the average imbalance and the average loss was weak in the E cell type (<inline-formula><mml:math id="inf167"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>r</mml:mi><mml:mo>=</mml:mo><mml:mn>0.16</mml:mn></mml:mstyle></mml:math></inline-formula>) and close to zero in the I cell type (<inline-formula><mml:math id="inf168"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>r</mml:mi><mml:mo>=</mml:mo><mml:mn>0.02</mml:mn></mml:mstyle></mml:math></inline-formula>), suggesting almost no relation between efficiency and average imbalance. In contrast, the average loss was negatively correlated with the instantaneous balance in both E (<inline-formula><mml:math id="inf169"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>r</mml:mi><mml:mo>=</mml:mo><mml:mo>−</mml:mo><mml:mn>0.35</mml:mn></mml:mstyle></mml:math></inline-formula>) and in I cell type (<inline-formula><mml:math id="inf170"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>r</mml:mi><mml:mo>=</mml:mo><mml:mo>−</mml:mo><mml:mn>0.45</mml:mn></mml:mstyle></mml:math></inline-formula>), showing that instantaneous balance of synaptic inputs is positively correlated with network efficiency. When measured for varying levels of spike-triggered adaptation, unlike the average balance of synaptic inputs, the instantaneous balance is thus mildly predictive of network efficiency.</p><p>In sum, our results show that the optimally efficient solution does not include within-neuron feedback, while a model with weak and short-lasting spike-triggered adaptation is slightly suboptimal, although still highly efficient. Our results predict that information coding would be more efficient with adaptation than with facilitation. Assuming that our I neurons describe parvalbumin-positive interneurons, our results suggest that the weaker adaptation in I compared to E neurons, reported empirically (<xref ref-type="bibr" rid="bib76">Pala and Petersen, 2015</xref>), may be beneficial for the network’s encoding efficiency.</p><p>Spike-triggered adaptation in our model captures adaptive processes in single neurons that occur on time scales lasting from a couple of milliseconds to tens of milliseconds after each spike. However, spiking in biological neurons triggers adaptation on multiple time scales, including much slower time scales on the order of seconds or tens of seconds (<xref ref-type="bibr" rid="bib81">Pozzorini et al., 2013</xref>). Our model does not capture adaptive processes on these longer time scales (but see <xref ref-type="bibr" rid="bib39">Gutierrez and Denève, 2019</xref>).</p></sec><sec id="s2-6"><title>Non-specific currents regulate network coding properties</title><p>In our derivation of the optimal network, we obtained a non-specific external current (in the following, non-specific current) <inline-formula><mml:math id="inf171"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msubsup><mml:mi>I</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mspace width="thinmathspace"/><mml:mtext>ext</mml:mtext><mml:mo>,</mml:mo><mml:mi>y</mml:mi></mml:mrow></mml:msubsup><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mstyle></mml:mrow></mml:mstyle></mml:math></inline-formula>. Non-specific current captures all synaptic currents that are unrelated and unspecific to the stimulus features. This non-specific term collates effects of synaptic currents from neurons untuned to the stimulus (<xref ref-type="bibr" rid="bib55">Levy et al., 2020</xref>; <xref ref-type="bibr" rid="bib113">Zylberberg, 2018</xref>), as well as synaptic currents from other brain areas. It can be conceptualized as the background synaptic activity that provides a large fraction of all synaptic inputs to both E and I neurons in cortical networks (<xref ref-type="bibr" rid="bib30">Destexhe and Paré, 1999</xref>), and which may modulate feedforward-driven responses by controlling the distance between the membrane potential and the firing threshold (<xref ref-type="bibr" rid="bib31">Destexhe et al., 2003</xref>). Likewise, in our model, the non-specific current does not directly convey information about the feedforward input features, but influences the network dynamics.</p><p>Non-specific current comprises mean and fluctuations (see Materials and methods). The mean is proportional to the metabolic constant <inline-formula><mml:math id="inf172"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>β</mml:mi></mml:mstyle></mml:math></inline-formula> and its fluctuations reflect the noise that we included in the condition for spiking. Since <inline-formula><mml:math id="inf173"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>β</mml:mi></mml:mstyle></mml:math></inline-formula> governs the trade-off between encoding error and metabolic cost (<xref ref-type="disp-formula" rid="equ3">Equation 3</xref>), higher values of <inline-formula><mml:math id="inf174"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>β</mml:mi></mml:mstyle></mml:math></inline-formula> imply that more importance is assigned to the metabolic efficiency than to coding accuracy, yielding a reduction in firing rates. In the expression for the non-specific current, we found that the mean of the current is negatively proportional to the metabolic constant <inline-formula><mml:math id="inf175"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>β</mml:mi></mml:mstyle></mml:math></inline-formula> (see Materials and methods). Because the non-specific current is typically depolarizing, this means that increasing <inline-formula><mml:math id="inf176"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>β</mml:mi></mml:mstyle></mml:math></inline-formula> yields a weaker non-specific current and increases the distance between the mean membrane potential and the firing threshold. Thus, an increase of the metabolic constant is expected to make the network less responsive to the feedforward signal.</p><p>We found the metabolic constant <inline-formula><mml:math id="inf177"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>β</mml:mi></mml:mstyle></mml:math></inline-formula> to significantly influence the spiking dynamics (<xref ref-type="fig" rid="fig6">Figure 6A</xref>). The optimal efficiency was achieved for non-zero levels of the metabolic constant (<xref ref-type="fig" rid="fig6">Figure 6B</xref>), with the mean of the non-specific current spanning more than half of the distance between the resting potential and the threshold (<xref ref-type="table" rid="table1">Table 1</xref>). Stronger weighting of the loss of I compared to E neurons and stronger weighting of the error compared to the cost yielded weaker optimal metabolic constant (<xref ref-type="fig" rid="fig7s1">Figure 7—figure supplement 1B</xref>). Metabolic constant modulated the firing rate as expected, with the firing rate in E and I neurons decreasing with the increasing of the metabolic constant (<xref ref-type="fig" rid="fig6">Figure 6C</xref>, top). It also modulated the variability of spiking, as increasing the metabolic constant decreased the variability of spiking in both cell types (<xref ref-type="fig" rid="fig6">Figure 6C</xref>, bottom). Furthermore, it modulated the average balance and the instantaneous balance in opposite ways: larger values of <inline-formula><mml:math id="inf178"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>β</mml:mi></mml:mstyle></mml:math></inline-formula> led to regimes that had stronger average balance, but weaker instantaneous balance (<xref ref-type="fig" rid="fig6">Figure 6D</xref>). We note that, even with suboptimal values of the metabolic constant, the neural dynamics remained within biologically relevant ranges.</p><fig id="fig6" position="float"><label>Figure 6.</label><caption><title>State-dependent coding and dynamics are controlled by non-specific currents.</title><p>(<bold>A</bold>) Spike trains of the efficient E-I network in one simulation trial, with different values of the metabolic constant <inline-formula><mml:math id="inf179"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>β</mml:mi></mml:mstyle></mml:math></inline-formula>. The network received identical stimulus across trials. (<bold>B</bold>) Top: RMSE of E (red) and I (blue) estimates as a function of the metabolic constant. Bottom: Normalized average metabolic cost and average loss as a function of the metabolic constant. Black arrow indicates the minimum loss and therefore the optimal metabolic constant. (<bold>C</bold>) Average firing rate (top) and the coefficient of variation of the spiking activity (bottom), as a function of the metabolic constant. Black arrow marks the metabolic constant leading to optimal network efficiency in B. (<bold>D</bold>) Average imbalance (top) and instantaneous balance (bottom) balance as a function of the metabolic constant. (<bold>E</bold>) Same as in A, for different values of the noise strength <inline-formula><mml:math id="inf180"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>σ</mml:mi></mml:mstyle></mml:math></inline-formula>. (<bold>F</bold>) Same as in B, as a function of the noise strength. The noise is a Gaussian random process, independent over time and across neurons. (<bold>G</bold>) Same as C, as a function of the noise strength. (<bold>H</bold>) Top: Same as in D, as a function of the noise strength. (<bold>I</bold>) The encoding error measured as RMSE (left), the metabolic cost (middle) and the average loss (right) as a function of the metabolic constant <inline-formula><mml:math id="inf181"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>β</mml:mi></mml:mstyle></mml:math></inline-formula> and the noise strength <inline-formula><mml:math id="inf182"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>σ</mml:mi></mml:mstyle></mml:math></inline-formula>. Metabolic constant and noise strength that are optimal for the single parameter search (in B and F) are marked with a red cross in the figure on the right. For plots in B-D and F-I, we computed and averaged results over 100 simulation trials with 1 second duration. For other parameters, see <xref ref-type="table" rid="table1">Table 1</xref>.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-99545-fig6-v1.tif"/></fig><p>The fluctuation part of the non-specific current, modulated by the noise strength <inline-formula><mml:math id="inf183"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>σ</mml:mi></mml:mstyle></mml:math></inline-formula> that we added in the definition of spiking rule for biological plausibility (see Materials and methods), strongly affected the neural dynamics as well (<xref ref-type="fig" rid="fig6">Figure 6E</xref>). The optimal performance was achieved with non-vanishing noise levels (<xref ref-type="fig" rid="fig6">Figure 6F</xref>), similarly to previous work showing that the noise prevents excessive network synchronization that would harm performance (<xref ref-type="bibr" rid="bib20">Chalk et al., 2016</xref>; <xref ref-type="bibr" rid="bib48">Koren and Denève, 2017</xref>; <xref ref-type="bibr" rid="bib100">Timcheck et al., 2022</xref>). The optimal noise strength depended on the weighting of the error with the cost, with strong weighting of the error predicting stronger noise (<xref ref-type="fig" rid="fig7s1">Figure 7—figure supplement 1C</xref>).</p><p>The average firing rate of both cell types, as well as the variability of spiking in E neurons, increased with noise strength (<xref ref-type="fig" rid="fig6">Figure 6G</xref>), and some level of noise in the non-specific inputs was necessary to establish the optimal level of spiking variability. Nevertheless, we measured significant levels of spiking variability already in the absence of noise, with a coefficient of variation of about 0.8 in E and 0.9 in I neurons (<xref ref-type="fig" rid="fig6">Figure 6G</xref>, bottom). This indicates that the recurrent network dynamics generates substantial variability even in absence of an external source of noise. The average and instantaneous balance of synaptic currents exhibited a non-linear behavior as a function of noise strength (<xref ref-type="fig" rid="fig6">Figure 6H</xref>). Due to decorrelation of membrane potentials by the noise, instantaneous balance in I neurons decreased with increasing noise strength (<xref ref-type="fig" rid="fig6">Figure 6H</xref>, bottom).</p><p>Next, we investigated the joint impact of the metabolic constant and the noise strength on network optimality. We expect these two parameters to be related, because larger noise strength requires stronger metabolic constant to prevent the activity of the network to be dominated by noise. We thus performed a two-dimensional parameter search (<xref ref-type="fig" rid="fig6">Figure 6I</xref>). As expected, the optima of the metabolic constant and the noise strength were positively correlated. A weaker noise required lower metabolic constant, and-vice-versa. While achieving maximal efficiency at non-zero levels of the metabolic cost and noise (see <xref ref-type="fig" rid="fig6">Figure 6I</xref>) might seem counterintuitive, we speculate that such setting is optimal because some noise in the non-specific current prevents over-synchronization and over-regularity of firing that would harm efficiency, similarly to what was shown in previous works (<xref ref-type="bibr" rid="bib20">Chalk et al., 2016</xref>; <xref ref-type="bibr" rid="bib48">Koren and Denève, 2017</xref>; <xref ref-type="bibr" rid="bib100">Timcheck et al., 2022</xref>). In the presence of noise, a non-zero metabolic constant is needed to suppress inefficient spikes purely induced by noise that do not contribute to coding and increase the error. This gives rise to a form of stochastic resonance, where an optimal level of noise is helpful to detect the signal coming from the feedforward currents.</p><p>In summary, non-specific external currents derived in our optimal solution have a major effect on coding efficiency and on neural dynamics. In qualitative agreement with empirical measurements (<xref ref-type="bibr" rid="bib30">Destexhe and Paré, 1999</xref>; <xref ref-type="bibr" rid="bib31">Destexhe et al., 2003</xref>), our model predicts that more than half of the average distance between the resting potential and firing threshold is accounted for by non-specific synaptic currents. Similarly to previous theoretical work (<xref ref-type="bibr" rid="bib20">Chalk et al., 2016</xref>; <xref ref-type="bibr" rid="bib48">Koren and Denève, 2017</xref>), we find that some level of external noise, in the form of a random fluctuation of the non-specific synaptic current, is beneficial for network efficiency. This remains a prediction for experiments.</p></sec><sec id="s2-7"><title>Optimal ratio of E-I neuron numbers and of the mean I-I to E-I synaptic efficacy coincide with biophysical measurements</title><p>Next, we investigated how coding efficiency and neural dynamics depend on the ratio of the number of E and I neurons (<inline-formula><mml:math id="inf184"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msup><mml:mi>N</mml:mi><mml:mrow><mml:mspace width="thinmathspace"/><mml:mi>E</mml:mi></mml:mrow></mml:msup><mml:mo>:</mml:mo><mml:msup><mml:mi>N</mml:mi><mml:mrow><mml:mspace width="thinmathspace"/><mml:mi>I</mml:mi></mml:mrow></mml:msup></mml:mstyle></mml:mrow></mml:mstyle></mml:math></inline-formula> or E-I ratio) and on the relative synaptic strengths between E-I and I-I connections.</p><p>Efficiency objectives (<xref ref-type="disp-formula" rid="equ3">Equation 3</xref>) are based on population, rather than single-neuron activity. Our efficient E-I network thus realizes a computation of the target representation that is distributed across multiple neurons (<xref ref-type="fig" rid="fig7">Figure 7A</xref>). Following previous reports (<xref ref-type="bibr" rid="bib7">Barrett et al., 2016</xref>), we predict that, if the number of neurons within the population decreases, neurons have to fire more spikes to achieve an optimal population readout because the task of tracking the target signal is distributed among fewer neurons. To test this prediction, we varied the number of I neurons while keeping the number of E neurons constant. As predicted, a decrease of the number of I neurons (and thus an increase in the ratio of the number of E to I neurons) caused a linear increase in the firing rate of I neurons, while the firing rate of E neurons stayed constant (<xref ref-type="fig" rid="fig7">Figure 7B</xref>, top). However, the variability of spiking and the average synaptic inputs remained relatively constant in both cell types as we varied the E-I ratio (<xref ref-type="fig" rid="fig7">Figure 7B</xref>, bottom, C), indicating a compensation for the change in the ratio of E-I neuron numbers through adjustment in the firing rates. These results are consistent with the observation in neuronal cultures of a linear change in the rate of postsynaptic events but unchanged postsynaptic current in either E and I neurons for variations in the E-I neuron number ratio (<xref ref-type="bibr" rid="bib96">Sukenik et al., 2021</xref>).</p><fig-group><fig id="fig7" position="float"><label>Figure 7.</label><caption><title>Optimal ratios of E-I neuron numbers and of mean I-I to E-I efficacy.</title><p>(<bold>A</bold>) Schematic of the effect of changing the number of I neurons on firing rates of I neurons. As encoding of the stimulus is distributed among more I neurons, the number of spikes per I neuron decreases. (<bold>B</bold>) Average firing rate as a function of the ratio of the number of E to I neurons. Black arrow marks the optimal ratio. (<bold>C</bold>) Average net synaptic input in E neurons (top) and in I neurons (bottom). (<bold>D</bold>) Top: Encoding error (RMSE) of the E (red) and I (blue) estimates, as a function of the ratio of E-I neuron numbers. Bottom: Same as on top, showing the cost and the average loss. Black arrow shows the minimum of the loss, indicating the optimal parameter. (<bold>E</bold>) Top: Optimal ratio of the number of E to I neurons as a function of the weighting of the average loss of E and I cell type (using the weighting of the error and cost of 0.7 and 0.3, respectively). Bottom: Same as on top, measured as a function of the weighting of the error and the cost when computing the loss. (The weighting of the losses of E and I neurons is 0.5.) Black triangles mark weightings that we typically used. (<bold>F</bold>) Schematic of the readout of the spiking activity of E (red) and I population (blue) with equal amplitude of decoding weights (left) and with stronger decoding weight in I neuron (right). Stronger decoding weight in I neurons results in a stronger effect of spikes on the readout, leading to less spikes by the I population. (<bold>G–H</bold>) Same as in D and B, as a function of the ratio of mean I-I to E-I efficacy. (<bold>I</bold>) Average imbalance (top) and instantaneous balance (bottom) balance, as a function of the ratio of mean I-I to E-I efficacy. (<bold>J</bold>) The encoding error (RMSE; left) the metabolic cost (middle) and the average loss (right) as a function of the ratio of E-I neuron numbers and the ratio of mean I-I to E-I connectivity. The optimal ratios obtained with single parameter search (in D and G) are marked with a red cross. All statistical results were computed on 100 simulation trials of 1 second duration. For other parameters, see <xref ref-type="table" rid="table1">Table 1</xref>.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-99545-fig7-v1.tif"/></fig><fig id="fig7s1" position="float" specific-use="child-fig"><label>Figure 7—figure supplement 1.</label><caption><title>Dependence of optimal parameters on weighting of the encoding error and the metabolic cost and analysis of mean ratio of I-I to E-I connectivity by varying the number of E neurons.</title><p>(<bold>A</bold>) Optimal set of time constants of E and I neurons [<inline-formula><mml:math id="inf185"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msubsup><mml:mi>τ</mml:mi><mml:mrow><mml:mi>r</mml:mi></mml:mrow><mml:mrow><mml:mi>E</mml:mi></mml:mrow></mml:msubsup><mml:mo>,</mml:mo><mml:msubsup><mml:mi>τ</mml:mi><mml:mrow><mml:mi>r</mml:mi></mml:mrow><mml:mrow><mml:mi>I</mml:mi></mml:mrow></mml:msubsup></mml:mrow></mml:mstyle></mml:math></inline-formula>] for different weightings between the error and the cost when computing the loss. Optimal time constants show little dependency on this weighting. (<bold>B</bold>) Top: Optimal metabolic constant as a function of the weighting of the average loss of E and I cell type. Bottom: Same as on top, as a function of the weighting between the error and the cost. Black triangles mark weightings that are typically used to estimate optimal model efficiency. (<bold>C</bold>) Same as in B, as a function of noise strength. (<bold>D</bold>) Same as in B, as a function of the optimal ratio of I-I to E-I connectivity. This analysis was performed by varying the number of I neurons while the number of E neurons stays fixed. (<bold>E</bold>) Top: Encoding error (RMSE) of the E (red) and I (blue) estimates as a function of mean I-I to E-I connectivity. The ratio was varied by changing the number of E neurons and keeping the number of I neurons fixed at a value specified in <xref ref-type="table" rid="table1">Table 1</xref>. Bottom: Same as on top, showing the normalized cost and average loss. (<bold>F</bold>) Same as in E, showing, the average firing rate (top), and average coefficient of variation (bottom) in E and I cell type. (<bold>G</bold>) Same as in E, showing the average imbalance and instantaneous balance of synaptic currents in E and I neurons. (<bold>H</bold>) Same as in D, for the optimal ratio measured by varying the number of E neurons. All results were computed in 100 trials of duration of 1 second for each trial. For other parameters, see <xref ref-type="table" rid="table1">Table 1</xref>.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-99545-fig7-figsupp1-v1.tif"/></fig></fig-group><p>The ratio of the number of E to I neurons had a significant influence on coding efficiency. We found a unique minimum of the encoding error of each cell type, while the metabolic cost increased linearly with the ratio of the number of E and I neurons (<xref ref-type="fig" rid="fig7">Figure 7D</xref>). Using the usual weighting <inline-formula><mml:math id="inf186"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msub><mml:mi>g</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>L</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mn>0.7</mml:mn></mml:mstyle></mml:math></inline-formula>, we found the optimal ratio of E to I neuron numbers to be in range observed experimentally in cortical circuits (<xref ref-type="fig" rid="fig7">Figure 7D</xref>, bottom, black arrow, <inline-formula><mml:math id="inf187"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msup><mml:mi>N</mml:mi><mml:mrow><mml:mspace width="thinmathspace"/><mml:mi>E</mml:mi></mml:mrow></mml:msup><mml:mo>:</mml:mo><mml:msup><mml:mi>N</mml:mi><mml:mrow><mml:mspace width="thinmathspace"/><mml:mi>I</mml:mi></mml:mrow></mml:msup><mml:mo>=</mml:mo><mml:mn>3.75</mml:mn><mml:mo>:</mml:mo><mml:mn>1</mml:mn></mml:mstyle></mml:mrow></mml:mstyle></mml:math></inline-formula>; <xref ref-type="bibr" rid="bib62">Markram et al., 2004</xref>). The optimal ratio depended on the weighting of the error with the cost, decreasing when increasing the cost of firing (<xref ref-type="fig" rid="fig7">Figure 7E</xref>, bottom). Also the encoding error (RMSE) alone, without considering the metabolic cost, predicted optimal ratio of the number of E to I neurons within a plausible physiological range, <inline-formula><mml:math id="inf188"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msup><mml:mi>N</mml:mi><mml:mrow><mml:mspace width="thinmathspace"/><mml:mi>E</mml:mi></mml:mrow></mml:msup><mml:mo>:</mml:mo><mml:msup><mml:mi>N</mml:mi><mml:mrow><mml:mspace width="thinmathspace"/><mml:mi>I</mml:mi></mml:mrow></mml:msup><mml:mo>=</mml:mo><mml:mo stretchy="false">[</mml:mo><mml:mn>3.75</mml:mn><mml:mo>:</mml:mo><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mn>5.25</mml:mn><mml:mo>:</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">]</mml:mo></mml:mstyle></mml:mrow></mml:mstyle></mml:math></inline-formula>, with stronger weightings of the encoding error by I neurons predicting higher ratios (<xref ref-type="fig" rid="fig7">Figure 7E</xref>, top).</p><p>Next, we investigated the impact of the strength of E and I synaptic efficacy (EPSPs and IPSPs). As evident from the expression for the population readouts (<xref ref-type="disp-formula" rid="equ2">Equation 2</xref>), the magnitude of tuning parameters (which are also decoding weights) determines the amplitude of jumps of the population readout caused by spikes (<xref ref-type="fig" rid="fig7">Figure 7F</xref>). The larger these weights are, the larger is the impact of spikes on the population signals.</p><p>E and I synaptic efficacies depend on the tuning parameters. We parametrized the distribution of tuning parameters as uniform distributions centered at zero, but allowed the spread of distributions in E and I neurons (<inline-formula><mml:math id="inf189"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msubsup><mml:mi>σ</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>w</mml:mi></mml:mrow><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>E</mml:mi></mml:mrow></mml:msubsup></mml:mstyle></mml:math></inline-formula> and <inline-formula><mml:math id="inf190"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msubsup><mml:mi>σ</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>w</mml:mi></mml:mrow><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>I</mml:mi></mml:mrow></mml:msubsup></mml:mstyle></mml:math></inline-formula>) to vary across E and I cell type (Materials and methods). In the optimally efficient network, as found analytically (Materials and methods section ‘Dynamic equations for the membrane potentials’), the E-I connectivity is the transpose of the of the I-E connectivity, which implies that these connectivities are exactly balanced and have the same mean. We also showed analytically that by parametrizing tuning parameters with uniform distributions, the scaling of synaptic connectivity of E-I (equal to I-E) and I-I connectivity is controlled by the variance of tuning parameters of the pre and postsynaptic population as follows: <inline-formula><mml:math id="inf191"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mo fence="false" stretchy="false">⟨</mml:mo><mml:msup><mml:mi>J</mml:mi><mml:mrow><mml:mspace width="thinmathspace"/><mml:mi>x</mml:mi><mml:mi>y</mml:mi></mml:mrow></mml:msup><mml:mo fence="false" stretchy="false">⟩</mml:mo><mml:mo>∝</mml:mo><mml:msubsup><mml:mi>σ</mml:mi><mml:mrow><mml:mi>w</mml:mi></mml:mrow><mml:mrow><mml:mi>x</mml:mi></mml:mrow></mml:msubsup><mml:msubsup><mml:mi>σ</mml:mi><mml:mrow><mml:mi>w</mml:mi></mml:mrow><mml:mrow><mml:mi>y</mml:mi></mml:mrow></mml:msubsup></mml:mstyle></mml:mrow></mml:mstyle></mml:math></inline-formula>. Using these insights, we were able to analytically evaluate the mean E-I and I-I synaptic efficacy (see Materials and methods section ‘Parametrization of synaptic connectivity’).</p><p>We next searched for the optimal ratio of the mean I-I to E-I efficacy as the parameter that maximizes network efficiency. Network efficiency was maximized when such ratio was about 3–1 (<xref ref-type="fig" rid="fig7">Figure 7G</xref>). Our results suggest the optimal E-I and I-E synaptic efficacy, averaged across neuronal pairs, of 0.75 mV, and the optimal I-I efficacy of 2.25 mV, values that are consistent with empirical measurements in the primary sensory cortex (<xref ref-type="bibr" rid="bib25">Cossell et al., 2015</xref>; <xref ref-type="bibr" rid="bib76">Pala and Petersen, 2015</xref>; <xref ref-type="bibr" rid="bib19">Campagnola et al., 2022</xref>). The optimal ratio of mean I-I to E-I connectivity decreased when the error was weighted more with respect to the metabolic cost (<xref ref-type="fig" rid="fig7s1">Figure 7—figure supplement 1D</xref>).</p><p>Similarly to the ratio of E-I neuron numbers, a change in the ratio of mean E-I to I-E synaptic efficacy was compensated for by a change in firing rates, with stronger I-I synapses leading to a decrease in the firing rate of I neurons (<xref ref-type="fig" rid="fig7">Figure 7H</xref>, top). Conversely, weakening the E-I (and I-E) synapses resulted in an increase in the firing rate in E neurons (<xref ref-type="fig" rid="fig7s1">Figure 7—figure supplement 1E, F</xref>). This is easily understood by considering that weakening the E-I and I-E synapses activates less strongly the lateral inhibition in E neurons (<xref ref-type="fig" rid="fig3">Figure 3</xref>) and thus leads to an increase in the firing rate of E neurons. We also found that single neuron variability remained almost unchanged when varying the ratio of mean I-I to E-I efficacy (<xref ref-type="fig" rid="fig7">Figure 7H</xref>, bottom) and the optimal ratio yielded optimal levels of average and instantaneous balance of synaptic inputs, as found previously (<xref ref-type="fig" rid="fig7">Figure 7I</xref>). The instantaneous balance monotonically decreased with increasing ratio of I-I to E-I efficacy (<xref ref-type="fig" rid="fig7">Figure 7I</xref>, bottom, <xref ref-type="fig" rid="fig7s1">Figure 7—figure supplement 1G</xref>).</p><p>Further, we tested the co-dependency of network optimality on the above two ratios with a 2-dimensional parameter search. We expected a positive correlation of network performance as a function of these two parameters, because both of them regulate the level of instantaneous E-I balance in the network. We found that the lower ratio of E-I neuron numbers indeed predicts a lower ratio of the mean I-I to E-I connectivity (<xref ref-type="fig" rid="fig7">Figure 7J</xref>). This is because fewer E neurons bring less excitation in the network, thus requiring less inhibition to achieve optimal levels of instantaneous balance. The co-dependency of the two parameters in affecting network optimality might be informative as to why E-I neuron number ratios may vary across species (for example, it is reported to be 2:1 in human cortex [<xref ref-type="bibr" rid="bib36">Fang et al., 2022</xref>] and 4:1 in mouse cortex). Our model predicts that lower E-I neuron number ratios require weaker mean I-I to E-I connectivity.</p><p>In summary, our analysis suggests that optimal coding efficiency is achieved with more E neurons than I neurons and with mean I-I synaptic efficacy stronger than the E-I and I-E efficacy, and that these two parameters are positively correlated. Optimal ratios of E to I neurons and of connection strengths are broadly consistent with empirical measurements of these parameters in biological networks. The optimal network has less I than E neurons, but the impact of spikes of I neurons on the population readout is stronger, also suggesting that spikes of I neurons convey more information.</p></sec><sec id="s2-8"><title>Dependence of efficient coding and neural dynamics on the stimulus statistics</title><p>We further investigated how the network’s behavior depends on the timescales of the input stimulus features. We manipulated the stimulus timescales by changing the time constants of <inline-formula><mml:math id="inf192"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>M</mml:mi><mml:mo>=</mml:mo><mml:mn>3</mml:mn></mml:mstyle></mml:math></inline-formula> OU processes. The network efficiently encoded stimulus features when their time constants varied between 1 and 200 ms, with stable encoding error, metabolic cost (<xref ref-type="fig" rid="fig8">Figure 8A</xref>) and neural dynamics (<xref ref-type="fig" rid="fig8s1">Figure 8—figure supplement 1A, B</xref>). To examine if the network can efficiently encode also stimuli that evolve on different timescales, we tested its performance in response to <inline-formula><mml:math id="inf193"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>M</mml:mi><mml:mo>=</mml:mo><mml:mn>3</mml:mn></mml:mstyle></mml:math></inline-formula> input variables, each with a different timescale. We kept the timescale of the first variable constant at <inline-formula><mml:math id="inf194"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msubsup><mml:mi>τ</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mn>1</mml:mn></mml:mrow><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>s</mml:mi></mml:mrow></mml:msubsup><mml:mo>=</mml:mo><mml:mn>10</mml:mn></mml:mstyle></mml:math></inline-formula> ms, while we varied the time constants of the other two keeping the time constant of the third twice as long as that of the second. We found excellent performance of the network in response to such stimuli that was stable across timescales (<xref ref-type="fig" rid="fig8">Figure 8B</xref>). The prediction that the network can encode information effectively over a wide range of time scales can be tested experimentally, by measuring the sensory information encoded by the activity of a set of neurons while varying the sensory stimulus timescales over a wide range.</p><fig-group><fig id="fig8" position="float"><label>Figure 8.</label><caption><title>Dependence of efficient coding and neural dynamics on stimulus parameters and comparison of E-I versus one cell type model architecture.</title><p>(<bold>A</bold>) Top: Root mean squared error (RMSE) of E estimates (red) and I estimates (blue), as a function of the time constant (in ms) of stimulus features. The time constant <inline-formula><mml:math id="inf195"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msub><mml:mi>τ</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>s</mml:mi></mml:mrow></mml:msub></mml:mstyle></mml:math></inline-formula> is the same for all stimulus features. Bottom: Same as on top, showing the metabolic cost (MC) of E and I cell type. (<bold>B</bold>) Left: Mean squared error between the targets and their estimates for every stimulus feature (marked as dimensions), as a function of time constants of OU stimuli in E population (top) and in I population (bottom). In the first dimension, the stimulus feature has a time constant fixed at 10 ms, while the second and third feature increase their time constants from left to right. The time constant of the third stimulus feature (x-axis on the bottom) is the double of the time constant of the second stimulus feature (x-axis on top). Right: Same as on the left, showing the RMSE that was averaged across stimulus features (top), and the metabolic cost (bottom) in E (red) and I (blue) populations. (<bold>C</bold>) Top: Same as in A top, measured as a function of the number of stimulus features <inline-formula><mml:math id="inf196"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>M</mml:mi></mml:mstyle></mml:math></inline-formula>. Bottom: Normalized cost and the average loss as a function of the number of stimulus features. Black arrow marks the minimum loss and the optimal parameter <inline-formula><mml:math id="inf197"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>M</mml:mi></mml:mstyle></mml:math></inline-formula>. (<bold>D</bold>) Top: Optimal number of encoded variables (stimulus features) as a function of weighting of the losses of E and I population. The weighting of the error with the cost is 0.7. Bottom: Same as on top, as a function of the weighting of the error with the cost and with equal weighting of losses of E and I populations. (<bold>E</bold>) Tuning curves of 10 example E (left) and I neurons (right). We computed tuning curves using = M3 stimulus features that were constant over time. We varied the amplitude of the first stimulus feature <inline-formula><mml:math id="inf198"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msub><mml:mi>s</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mstyle></mml:math></inline-formula>, while two other stimulus features were kept fixed. (<bold>F</bold>) Distribution of the selectivity index across E (red) and I neurons (blue). (<bold>G</bold>) Root mean squared error (left) and metabolic cost (right) in E and I populations in the E-I model and in the 1CT model. The distribution is across 100 simulation trials. (<bold>H</bold>) Left: Average loss in the E population of the E-I model and of the 1CT model. The distribution is across 100 simulation trials. Right: Average loss in the E population of the E-I models and in the 1CT model as a function of the weighting <inline-formula><mml:math id="inf199"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msub><mml:mi>g</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>L</mml:mi></mml:mrow></mml:msub></mml:mstyle></mml:math></inline-formula>, averaged across trials. (<bold>I</bold>) Firing rate in the 1CT model as a function of the metabolic constant. All statistical results were computed on 100 simulation trials of 1 second duration. For other parameters of the E-I model see <xref ref-type="table" rid="table1">Table 1</xref>, and for the 1CT model see Appendix 2.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-99545-fig8-v1.tif"/></fig><fig id="fig8s1" position="float" specific-use="child-fig"><label>Figure 8—figure supplement 1.</label><caption><title>Effect of stimulus properties on efficient neural coding and dynamics.</title><p>(<bold>A</bold>) Average firing rate (top), and average coefficient of variation (bottom) in E and I cell type, as a function of the time constant of the stimulus features <inline-formula><mml:math id="inf200"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>τ</mml:mi><mml:mrow><mml:mi>s</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula>. All stimulus features have the same time constant. (<bold>B</bold>) Average imbalance (top) and instantaneous balance (bottom) as a function of the time constant of stimuli <inline-formula><mml:math id="inf201"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>τ</mml:mi><mml:mrow><mml:mi>s</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula>. (<bold>C</bold>) Top: RMSE of E (red) and I (blue) estimates as a function of the time constant of the targets <inline-formula><mml:math id="inf202"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>τ</mml:mi><mml:mrow><mml:mi>x</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula>. All targets have the same time constant. Middle: Metabolic cost in the E and I population. Bottom: Average loss in the E and I population. Black arrow indicates the minimum loss and therefore the optimal time constant. (<bold>D-E</bold>) Same as in A-B, as a function of the time constant of the targets <inline-formula><mml:math id="inf203"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>τ</mml:mi><mml:mrow><mml:mi>x</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula>. (<bold>F-G</bold>) Same as in A-B, as a function of the number of encoded variables <italic>M</italic>. All results were computed in 100 trials of duration of 1 second. For parameters, see <xref ref-type="table" rid="table1">Table 1</xref>.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-99545-fig8-figsupp1-v1.tif"/></fig></fig-group><p>We next examined network performance while varying the timescale of targets <inline-formula><mml:math id="inf204"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msub><mml:mi>τ</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>x</mml:mi></mml:mrow></mml:msub></mml:mstyle></mml:math></inline-formula> (see <xref ref-type="disp-formula" rid="equ1">Equation 1</xref>). Because we assumed that the target time constants equal the membrane time constant of E and I neurons (<inline-formula><mml:math id="inf205"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msub><mml:mi>τ</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>x</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:msup><mml:mi>τ</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>E</mml:mi></mml:mrow></mml:msup><mml:mo>=</mml:mo><mml:msup><mml:mi>τ</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>I</mml:mi></mml:mrow></mml:msup><mml:mo>=</mml:mo><mml:mi>τ</mml:mi></mml:mstyle></mml:math></inline-formula>), it is not surprising that the best performance was achieved when these time constants were similar (<xref ref-type="fig" rid="fig8s1">Figure 8—figure supplement 1C</xref>). Firing rates, firing variability and the average and instantaneous balance did not change appreciably with this time constant (<xref ref-type="fig" rid="fig8s1">Figure 8—figure supplement 1D–E</xref>).</p><p>Next, we tested how the network’s behavior changed when we varied the number of stimulus features <inline-formula><mml:math id="inf206"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>M</mml:mi></mml:mstyle></mml:math></inline-formula>. Because all other parameters were optimized using <inline-formula><mml:math id="inf207"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>M</mml:mi><mml:mo>=</mml:mo><mml:mn>3</mml:mn></mml:mstyle></mml:math></inline-formula>, the encoding error of E (RMSE<italic><sup>E</sup></italic>) and I neurons (RMSE<italic><sup>I</sup></italic>) achieved a minimum around this value (<xref ref-type="fig" rid="fig8">Figure 8C</xref>, top). The metabolic cost increased monotonically with <inline-formula><mml:math id="inf208"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>M</mml:mi></mml:mstyle></mml:math></inline-formula> (<xref ref-type="fig" rid="fig8">Figure 8C</xref>, bottom). The number of features that optimized network efficiency (and minimized the average loss) depended on <inline-formula><mml:math id="inf209"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msub><mml:mi>g</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>L</mml:mi></mml:mrow></mml:msub></mml:mstyle></mml:math></inline-formula>, with stronger penalty of firing yielding a smaller optimal number of features. Increasing <inline-formula><mml:math id="inf210"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>M</mml:mi></mml:mstyle></mml:math></inline-formula> beyond the optimal number resulted in a gentle monotonic increase in firing rates for both E and I neurons, and it increased the average E-I balance and weakened the instantaneous balance (<xref ref-type="fig" rid="fig8s1">Figure 8—figure supplement 1F, G</xref>).</p><p>We next characterized the tuning and the stimulus selectivity of E and I neurons. E neurons receive a feedforward current, which is expected to make them stimulus-selective, while I neurons receive synaptic inputs from E neurons through dense E-I connectivity. We measured stimulus tuning by computing tuning curves for each neuron in response to M=3 constant stimulus features (see Materials and methods). Similarly to previous work (<xref ref-type="bibr" rid="bib7">Barrett et al., 2016</xref>), tuning curves of both E and I neurons were strongly heterogeneous (<xref ref-type="fig" rid="fig8">Figure 8E</xref>). We tested if the selectivity differs across E and I cell types. We computed a selectivity index for each neuron as the stimulus-response gain (average change in the firing rate in response to a small change in the stimulus divided by the stimulus change size, see Materials and methods), and found that E and I neurons had similar mean stimulus selectivity (<inline-formula><mml:math id="inf211"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>p</mml:mi><mml:mo>=</mml:mo><mml:mn>0.418</mml:mn></mml:mstyle></mml:math></inline-formula>, two-tailed t-test; <xref ref-type="fig" rid="fig8">Figure 8F</xref>). Thus, I neurons, despite not receiving direct feedforward inputs and acquiring stimulus selectivity only through structured E-I connections, are tuned to the input stimuli as strongly as the E neurons.</p></sec><sec id="s2-9"><title>Comparison of E-I and one cell type model architecture for coding efficiency and robustness</title><p>Neurons in the brain are either excitatory or inhibitory. To understand how differentiating E and I neurons benefits efficient coding, we compared the properties of our efficient E-I network with an efficient network with a single cell type (1CT). The 1CT model can be seen as a simplification of the E-I model (see Appendix 1) and has been derived and analyzed in previous studies (<xref ref-type="bibr" rid="bib12">Bourdoukan et al., 2012</xref>; <xref ref-type="bibr" rid="bib11">Boerlin et al., 2013</xref>; <xref ref-type="bibr" rid="bib48">Koren and Denève, 2017</xref>; <xref ref-type="bibr" rid="bib39">Gutierrez and Denève, 2019</xref>; <xref ref-type="bibr" rid="bib4">Alemi et al., 2018</xref>; <xref ref-type="bibr" rid="bib13">Brendel et al., 2020</xref>). We compared the average encoding error (RMSE), the average metabolic cost (MC), and the average loss (see Appendix 3) of the E-I model against the one cell type (1CT) model. Compared to the 1CT model, the E-I model exhibited a higher encoding error and metabolic cost in the E population, but a lower encoding error and metabolic cost in the I population (<xref ref-type="fig" rid="fig8">Figure 8G</xref>). The 1CT model can perform similar computations as the E-I network. Instead of an E neuron directly providing lateral inhibition to its neighbor (<xref ref-type="fig" rid="fig1s1">Figure 1—figure supplement 1A–C</xref>), it goes through an interneuron in the E-I model (<xref ref-type="fig" rid="fig1">Figure 1A(i) and B</xref>). Because the E population of the E-I model and the 1CT model perform a similar computation, we compared the efficiency of the E population of the E-I model with the 1CT model. We found that the 1CT model is slightly more efficient than the E population of the E-I model, consistently for different weightings of the error with the cost (<xref ref-type="fig" rid="fig8">Figure 8H</xref>).</p><p>We further compared the robustness of firing rates to changes in the metabolic constant of the two models. Consistently with previous studies (<xref ref-type="bibr" rid="bib48">Koren and Denève, 2017</xref>; <xref ref-type="bibr" rid="bib84">Rullán Buxó and Pillow, 2020</xref>), firing rates in the 1CT model were highly sensitive to variations in the metabolic constant (<xref ref-type="fig" rid="fig8">Figure 8I</xref>, note the logarithmic scale on the y-axis), with a superexponential growth of the firing rate with the inverse of the metabolic constant in regimes with metabolic cost lower than optimal. This is in contrast to the E-I model, whose firing rates exhibited lower sensitivity to the metabolic constant, and never exceeded physiological limits (<xref ref-type="fig" rid="fig7">Figure 7C</xref>, top). Because our E-I model does not incorporate a saturating input-output function that constrains the range of firing as in <xref ref-type="bibr" rid="bib45">Kadmon et al., 2020</xref>, the ability of the E-I model to maintain firing rates within biologically plausible limits emerges as a highly desirable dynamic property. One reason for higher stability of our E-I model compared to the 1CT model is that the delay of the lateral inhibition in the E-I model is twice that of the 1CT model (because in the E-I model, the lateral inhibition travels through an additional synapse). A second reason is that the recurrent connectivity of the 1CT model has exactly the same amount of average excitation and inhibition, while the E-I model is inhibition-dominated, which makes the E-I model more stable.</p><p>In summary, although the optimal E-I model is slightly less efficient than the optimal 1CT model, it does not enter into states of physiologically unrealistic firing rates when the metabolic constant is lower than the optimal one.</p></sec></sec><sec id="s3" sec-type="discussion"><title>Discussion</title><p>We analyzed the structural, dynamical and coding properties that emerge in networks of spiking neurons that implement efficient coding. We demonstrated that efficient recurrent E-I networks form highly accurate representations of stimulus features with biologically plausible parameters, biologically plausible neural dynamics, instantaneous E-I balance and like-to-like connectivity structure leading to lateral inhibition. The network can implement efficient coding with stimulus features varying over a wide range of timescales and when encoding even multiple such features. Here we discuss the implications of these findings.</p><p>By a systematic study of the model, we determined the model parameters that optimize network efficiency. The optimal parameters (including the ratio between the number of E and I neurons, the ratio of I-I to E-I synaptic efficacy and parameters of non-specific currents) were consistent with parameters measured empirically in cortical circuits, and generated plausible spiking dynamics. This result lends credibility to the hypothesis that cortical networks might be designed for efficient coding and may operate close to optimal efficiency, as well as provides a solid intuition about what specific parameter ranges (e.g. higher numbers of E than I neurons) may be good for. With moderate deviations from the optimal parameters, efficient networks still exhibited realistic dynamics and close-to-efficient coding, suggesting that the optimal operational point of such networks is relatively robust. We also found that optimally efficient analytical solution derives generalized LIF (gLIF) equations for neuron models (<xref ref-type="bibr" rid="bib49">Koren and Panzeri, 2022</xref>). While gLIF (<xref ref-type="bibr" rid="bib89">Schwalger and Lindner, 2013</xref>; <xref ref-type="bibr" rid="bib37">Gerstner et al., 2014</xref>) and LIF (<xref ref-type="bibr" rid="bib15">Brunel, 2000</xref>; <xref ref-type="bibr" rid="bib82">Renart et al., 2010</xref>) models are reasonably biologically plausible and are widely used to model and study spiking neural network dynamics, it was unclear how their parameters affect network-level information coding. Our study provides a principled way to determine uniquely the parameter values of gLIF networks that are optimal for efficient information encoding. Studying the dynamics of gLIF networks with such optimal parameters thus provides a direct link between optimal coding and neural dynamics. Moreover, our formalism provides a framework for the optimization of neural parameters that can in principle be used not only for neural network models that study brain function but also for the design of artificial neuromorphic circuits that perform information coding computations (<xref ref-type="bibr" rid="bib83">Roy et al., 2019</xref>; <xref ref-type="bibr" rid="bib88">Schuman et al., 2022</xref>).</p><p>Our model generates a number of insights about the role of structured connectivity in efficient information processing. A first insight is that I neurons develop stimulus feature selectivity because of the structured recurrent connectivity. While in visual cortex of naive animals, I neurons are typically reported to be less tuned than E neurons (<xref ref-type="bibr" rid="bib41">Hofer et al., 2011</xref>; <xref ref-type="bibr" rid="bib42">Hu et al., 2014</xref>) (but see <xref ref-type="bibr" rid="bib85">Runyan et al., 2010</xref>), recent studies in association areas of well task trained animals consistently find I neurons as strongly tuned as E neurons (<xref ref-type="bibr" rid="bib68">Najafi et al., 2020</xref>; <xref ref-type="bibr" rid="bib53">Kuan et al., 2024</xref>). A second insight is that a network with structured connectivity shows stronger average and instantaneous E-I balance, as well as significantly lower variance of membrane potentials compared to an equivalent network with randomly organized connections. This implies that the connectivity structure is not only crucial for coding efficiency, but also influences the dynamical regime of the network. A third insight is that the structured network exhibits both lower encoding error and lower firing rates compared to unstructured networks, thus achieving higher efficiency. Our analysis of the effective connectivity created by the efficient connectivity structure shows that this structure sharpens stimulus representations, reduces redundancy and increases metabolic efficiency by implementing feature-specific competition, that is a negative effective connectivity between E neurons with similar stimulus tuning, as proposed by recent theories (<xref ref-type="bibr" rid="bib66">Moreno-Bote and Drugowitsch, 2015</xref>) and experiments (<xref ref-type="bibr" rid="bib22">Chettih and Harvey, 2019</xref>; <xref ref-type="bibr" rid="bib72">Oldenburg et al., 2024</xref>) of computations in visual cortex.</p><p>Our model gives insights on what would be minimal requirements for a biological network to implement efficient coding. The network has to have structured E-I and I-E connectivity and weak and short-lasting or no spike-triggered adaptation. Further, at least half of the distance between the resting potential and the threshold should be provided by a stochastic external current that is unrelated to the feedforward stimuli. Finally, the network should have a ratio of E to I neuron numbers in the range of about 2:1 to 4:1 and the ratio of average I-I to E-I connectivity in the range of about 2:1 to 3:1, with smaller E-I neuron number ratios implying smaller average I-I to E-I connectivity ratios.</p><p>Our study gives insights into how structured connectivity between E and I neurons affects the dynamics of E-I balancing and how this relates to information coding. Previous work (<xref ref-type="bibr" rid="bib28">Deneve and Machens, 2016b</xref>) proposed that the E-I balance in efficient spiking networks operates on a finer time scale than in classical balanced E-I networks with random connectivity (<xref ref-type="bibr" rid="bib82">Renart et al., 2010</xref>). However, theoretical attempts to determine the levels of instantaneous E-I balance that are optimal for coding are rare (<xref ref-type="bibr" rid="bib33">Engelken and Goedeke, 2022</xref>). Consistent with the general idea put forth in <xref ref-type="bibr" rid="bib28">Deneve and Machens, 2016b</xref>; <xref ref-type="bibr" rid="bib20">Chalk et al., 2016</xref>; <xref ref-type="bibr" rid="bib29">Denève et al., 2017</xref>, we here showed that moderate levels of E-I balance are optimal for coding, and that too strong levels of instantaneous E-I balance are detrimental to coding efficiency. Our results predict that structured E-I-E connectivity is necessary for optimal levels of instantaneous E-I balance. Finally, the E-I-E structured connectivity that we derived supports optimal levels of instantaneous E-I balance and causes desynchronization of the spiking output. Such intrinsically generated desynchronization is a desirable network property that in previously proposed models could only be achieved by the less plausible addition of strong noise to each neuron (<xref ref-type="bibr" rid="bib20">Chalk et al., 2016</xref>; <xref ref-type="bibr" rid="bib84">Rullán Buxó and Pillow, 2020</xref>).</p><p>Our result that network efficiency depends gently on the number of neurons is consistent with previous findings that demonstrated robustness of efficient networks to neuronal loss (<xref ref-type="bibr" rid="bib7">Barrett et al., 2016</xref>) and robustness of efficient spiking to the number of neurons (<xref ref-type="bibr" rid="bib18">Calaim et al., 2022</xref>). Building on these studies, we additionally documented how the optimal ratio of the number of E to I neurons relates to the optimal ratio of average I-I to E-I connectivity. In particular, our analysis predicts that the optima of these two ratios are positively correlated. This might give insights into the diversity of ratios of E-I neuron number ratios observed across species (<xref ref-type="bibr" rid="bib36">Fang et al., 2022</xref>).</p><p>We found that our efficient network, optimizing the representation of a leaky integration of stimulus features, does not require recurrent E-E connections. This is compatible with the relatively sparse levels of recurrent E-E connections in primary visual cortex (<xref ref-type="bibr" rid="bib92">Seeman et al., 2018</xref>), with the majority of E-E synapses suggested to be long-range (<xref ref-type="bibr" rid="bib95">Stepanyants et al., 2009</xref>). Nevertheless, a limitation of our study is that it did not investigate the computations that could be made by E-E connections. Future studies could address the role of recurrent excitatory synapses that implement efficient coding computations beyond leaky integration, such as linear (<xref ref-type="bibr" rid="bib49">Koren and Panzeri, 2022</xref>) or non-linear mixing of stimulus features (<xref ref-type="bibr" rid="bib4">Alemi et al., 2018</xref>). Investigating such networks would also allow addressing whether biologically plausible efficient networks exhibit criticality, as suggested by <xref ref-type="bibr" rid="bib87">Safavi et al., 2024</xref>.</p><p>A more realistic mapping of efficient coding onto biological networks would also entail including multiple types of inhibitory neurons (<xref ref-type="bibr" rid="bib108">Wilson et al., 2012</xref>), which could provide additional insights into how interneuron diversity serves information coding. Further limitations of our study to be addressed in future work include a more realistic implementation of the feedforward current. In our implementation, the feedforward current is simply a sum of uncorrelated stimulus features. However, in biological circuits, the feedforward input is a series of complex synaptic inputs from upstream circuits. A more detailed implementation of feedforward inputs, coupled with recurrent E-E synapses, might influence the levels of the instantaneous balance, in particular in E neurons, and have an impact on network efficiency. Moreover, we here did not explore cases where the same stimulus feature has multiple time scales. Finally, we note that efficient encoding might be the primary normative objective in sensory areas, while areas supporting high-level cognitive tasks might include other computational objectives, such as efficient transmission of information downstream to generate reliable behavioral outputs (<xref ref-type="bibr" rid="bib103">Valente et al., 2021</xref>; <xref ref-type="bibr" rid="bib79">Panzeri et al., 2022</xref>; <xref ref-type="bibr" rid="bib61">Manning et al., 2024</xref>; <xref ref-type="bibr" rid="bib50">Koren et al., 2023</xref>; <xref ref-type="bibr" rid="bib10">Blanco Malerba et al., 2024</xref>). It would thus be important to understand how networks could simultaneously optimize or trade off different objectives.</p></sec><sec id="s4" sec-type="materials|methods"><title>Materials and methods</title><sec id="s4-1"><title>Overview of the current approach and of differences with previous approaches</title><p>In the following, we present a detailed derivation of the E-I spiking network implementing the efficient coding principle. The analytical derivation is based on previous works on efficient coding with spikes (<xref ref-type="bibr" rid="bib11">Boerlin et al., 2013</xref>; <xref ref-type="bibr" rid="bib48">Koren and Denève, 2017</xref>), and in particular on our recent work (<xref ref-type="bibr" rid="bib49">Koren and Panzeri, 2022</xref>). While these previous works analytically derived feedforward and recurrent transmembrane currents in leaky integrate-and fire neuron models, they did not contain any synaptic currents unrelated to feedforward and recurrent processing. Non-specific synaptic currents were suggested to be important for an accurate description of coding and dynamics in cortical networks (<xref ref-type="bibr" rid="bib31">Destexhe et al., 2003</xref>). In the model derivation that follows, we also derived non-specific external current from efficiency objectives.</p><p>Moreover, we here revisited the derivation of physical units in efficient spiking networks. We built on a previous work <xref ref-type="bibr" rid="bib11">Boerlin et al., 2013</xref> that assigned physical units to mathematical expressions that correspond to membrane potentials, firing thresholds, etc. Here, we instead assigned physical units to the computational variables such as the target signals and the population readouts, and then derived units of the membrane potentials and firing thresholds.</p><p>With this model, we aim to describe neural dynamics and computation in early sensory cortices such as the primary visual cortex in rodents, even though many principles of the model developed here could be relevant throughout the brain.</p></sec><sec id="s4-2"><title>Introducing variables of the model</title><p>We consider two types of neurons, excitatory neurons <inline-formula><mml:math id="inf212"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>E</mml:mi></mml:mstyle></mml:math></inline-formula> and inhibitory neurons <inline-formula><mml:math id="inf213"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>I</mml:mi></mml:mstyle></mml:math></inline-formula>. We denote as <inline-formula><mml:math id="inf214"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msup><mml:mi>N</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>E</mml:mi></mml:mrow></mml:msup></mml:mstyle></mml:math></inline-formula> and <inline-formula><mml:math id="inf215"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msup><mml:mi>N</mml:mi><mml:mrow><mml:mspace width="thinmathspace"/><mml:mi>I</mml:mi></mml:mrow></mml:msup></mml:mstyle></mml:mrow></mml:mstyle></mml:math></inline-formula> the number of <inline-formula><mml:math id="inf216"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>E</mml:mi></mml:mstyle></mml:math></inline-formula>-cells and <inline-formula><mml:math id="inf217"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>I</mml:mi></mml:mstyle></mml:math></inline-formula>-cells, respectively. The spike train of neuron <inline-formula><mml:math id="inf218"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>i</mml:mi></mml:mstyle></mml:math></inline-formula> of type <inline-formula><mml:math id="inf219"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>y</mml:mi><mml:mo>∈</mml:mo><mml:mo fence="false" stretchy="false">{</mml:mo><mml:mi>E</mml:mi><mml:mo>,</mml:mo><mml:mi>I</mml:mi><mml:mo fence="false" stretchy="false">}</mml:mo></mml:mstyle></mml:math></inline-formula>, <inline-formula><mml:math id="inf220"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mn>2</mml:mn><mml:mo>,</mml:mo><mml:mo>.</mml:mo><mml:mo>.</mml:mo><mml:mo>.</mml:mo><mml:mo>,</mml:mo><mml:msup><mml:mi>N</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>y</mml:mi></mml:mrow></mml:msup></mml:mstyle></mml:math></inline-formula>, is defined as a sum of Dirac delta functions,<disp-formula id="equ6"><label>(6)</label><mml:math id="m6"><mml:mrow><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msubsup><mml:mi>f</mml:mi><mml:mi>i</mml:mi><mml:mrow><mml:mspace width="thinmathspace"/><mml:mi>y</mml:mi></mml:mrow></mml:msubsup><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:munder><mml:mo>∑</mml:mo><mml:mrow><mml:mi>α</mml:mi></mml:mrow></mml:munder><mml:mi>δ</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo>−</mml:mo><mml:msubsup><mml:mi>t</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mspace width="thinmathspace"/><mml:mi>y</mml:mi><mml:mo>,</mml:mo><mml:mspace width="thinmathspace"/><mml:mi>α</mml:mi></mml:mrow></mml:msubsup><mml:mo stretchy="false">)</mml:mo><mml:mo>,</mml:mo></mml:mstyle></mml:mrow></mml:math></disp-formula></p><p>where <inline-formula><mml:math id="inf221"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msubsup><mml:mi>t</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>i</mml:mi></mml:mrow><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>y</mml:mi><mml:mo>,</mml:mo><mml:mi>α</mml:mi></mml:mrow></mml:msubsup></mml:mstyle></mml:math></inline-formula> is the time of the <inline-formula><mml:math id="inf222"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>α</mml:mi></mml:mstyle></mml:math></inline-formula>-th spike of that neuron, defined as a time point at which the membrane potential of neuron <inline-formula><mml:math id="inf223"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>i</mml:mi></mml:mstyle></mml:math></inline-formula> crosses the firing threshold.</p><p>We define the readout of the spiking activity of neuron <inline-formula><mml:math id="inf224"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>i</mml:mi></mml:mstyle></mml:math></inline-formula> of type <inline-formula><mml:math id="inf225"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>y</mml:mi></mml:mstyle></mml:math></inline-formula> (in the following, ‘ingle neuron readout’) as a leaky integration of its spike train,<disp-formula id="equ7"><label>(7)</label><mml:math id="m7"><mml:mrow><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msubsup><mml:mrow><mml:mover><mml:mi>r</mml:mi><mml:mo>˙</mml:mo></mml:mover></mml:mrow><mml:mi>i</mml:mi><mml:mrow><mml:mspace width="thinmathspace"/><mml:mi>y</mml:mi></mml:mrow></mml:msubsup><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mo>−</mml:mo><mml:msubsup><mml:mi>λ</mml:mi><mml:mi>r</mml:mi><mml:mrow><mml:mspace width="thinmathspace"/><mml:mi>y</mml:mi></mml:mrow></mml:msubsup><mml:msubsup><mml:mi>r</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mspace width="thinmathspace"/><mml:mi>y</mml:mi></mml:mrow></mml:msubsup><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>+</mml:mo><mml:msubsup><mml:mi>f</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mspace width="thinmathspace"/><mml:mi>y</mml:mi></mml:mrow></mml:msubsup><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>,</mml:mo><mml:mspace width="2em"/><mml:mi>y</mml:mi><mml:mo>∈</mml:mo><mml:mo fence="false" stretchy="false">{</mml:mo><mml:mi>E</mml:mi><mml:mo>,</mml:mo><mml:mi>I</mml:mi><mml:mo fence="false" stretchy="false">}</mml:mo><mml:mo>,</mml:mo></mml:mstyle></mml:mrow></mml:math></disp-formula></p><p>with <inline-formula><mml:math id="inf226"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msubsup><mml:mi>λ</mml:mi><mml:mrow><mml:mi>r</mml:mi></mml:mrow><mml:mi>y</mml:mi></mml:msubsup></mml:mrow></mml:mstyle></mml:math></inline-formula> denoting the inverse time constant. This way, the quantity <inline-formula><mml:math id="inf227"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msubsup><mml:mi>z</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>i</mml:mi></mml:mrow><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>y</mml:mi></mml:mrow></mml:msubsup><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:msubsup><mml:mi>λ</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>r</mml:mi></mml:mrow><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>y</mml:mi></mml:mrow></mml:msubsup><mml:msubsup><mml:mi>r</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>i</mml:mi></mml:mrow><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>y</mml:mi></mml:mrow></mml:msubsup><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mstyle></mml:math></inline-formula> represents an estimate of the instantaneous firing rate of neuron <inline-formula><mml:math id="inf228"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>i</mml:mi></mml:mstyle></mml:math></inline-formula>.</p><p>We denote as <inline-formula><mml:math id="inf229"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow class="MJX-TeXAtom-ORD"><mml:mover><mml:mi>s</mml:mi><mml:mo stretchy="false">→</mml:mo></mml:mover></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>:=</mml:mo><mml:mo stretchy="false">[</mml:mo><mml:msub><mml:mi>s</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>,</mml:mo><mml:mo>…</mml:mo><mml:mo>,</mml:mo><mml:msub><mml:mi>s</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>M</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:msup><mml:mo stretchy="false">]</mml:mo><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi mathvariant="normal">⊤</mml:mi></mml:mrow></mml:msup></mml:mstyle></mml:math></inline-formula> the set of <inline-formula><mml:math id="inf230"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>M</mml:mi></mml:mstyle></mml:math></inline-formula> dynamical features of the external stimulus (in the following, stimulus features) which are transmitted to the network through a feedforward sensory pathway. The stimulus features have the unit of the square root of millivolt, (mV)<sup>1/2</sup>. The target signal is then obtained through a leaky integration of the feedforward variable, <inline-formula><mml:math id="inf231"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow class="MJX-TeXAtom-ORD"><mml:mover><mml:mi>s</mml:mi><mml:mo stretchy="false">→</mml:mo></mml:mover></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mstyle></mml:math></inline-formula> (<xref ref-type="bibr" rid="bib12">Bourdoukan et al., 2012</xref>), with inverse time constant <inline-formula><mml:math id="inf232"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>λ</mml:mi></mml:mstyle></mml:math></inline-formula>, as<disp-formula id="equ8"><label>(8)</label><mml:math id="m8"><mml:mrow><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mover><mml:mrow><mml:mover><mml:mi>x</mml:mi><mml:mo>˙</mml:mo></mml:mover></mml:mrow><mml:mo stretchy="false">→</mml:mo></mml:mover></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mo>−</mml:mo><mml:mi>λ</mml:mi><mml:mrow><mml:mover><mml:mi>x</mml:mi><mml:mo stretchy="false">→</mml:mo></mml:mover></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>+</mml:mo><mml:mrow><mml:mover><mml:mi>s</mml:mi><mml:mo stretchy="false">→</mml:mo></mml:mover></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>,</mml:mo></mml:mstyle></mml:mrow></mml:math></disp-formula></p><p>with <inline-formula><mml:math id="inf233"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow class="MJX-TeXAtom-ORD"><mml:mover><mml:mi>x</mml:mi><mml:mo stretchy="false">→</mml:mo></mml:mover></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>:=</mml:mo><mml:mo stretchy="false">[</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>,</mml:mo><mml:mo>…</mml:mo><mml:mo>,</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>M</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:msup><mml:mo stretchy="false">]</mml:mo><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi mathvariant="normal">⊤</mml:mi></mml:mrow></mml:msup></mml:mstyle></mml:math></inline-formula> the vector of <inline-formula><mml:math id="inf234"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>M</mml:mi></mml:mstyle></mml:math></inline-formula> target signals. Furthermore, we define a linear population readout of the spiking activity of E and I neurons<disp-formula id="equ9"><label>(9)</label><mml:math id="m9"><mml:mrow><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msup><mml:mrow><mml:mover><mml:mrow><mml:mover><mml:mrow><mml:mover><mml:mi>x</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mo>˙</mml:mo></mml:mover></mml:mrow><mml:mo stretchy="false">→</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mspace width="thinmathspace"/><mml:mi>y</mml:mi></mml:mrow></mml:msup><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mo>−</mml:mo><mml:mi>λ</mml:mi><mml:msup><mml:mrow><mml:mover><mml:mrow><mml:mover><mml:mi>x</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mo stretchy="false">→</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mspace width="thinmathspace"/><mml:mi>y</mml:mi></mml:mrow></mml:msup><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>+</mml:mo><mml:munderover><mml:mo>∑</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:msup><mml:mi>N</mml:mi><mml:mrow><mml:mspace width="thinmathspace"/><mml:mi>y</mml:mi></mml:mrow></mml:msup></mml:mrow></mml:munderover><mml:msubsup><mml:mrow><mml:mover><mml:mi>w</mml:mi><mml:mo stretchy="false">→</mml:mo></mml:mover></mml:mrow><mml:mi>i</mml:mi><mml:mrow><mml:mspace width="thinmathspace"/><mml:mi>y</mml:mi></mml:mrow></mml:msubsup><mml:msubsup><mml:mi>f</mml:mi><mml:mi>i</mml:mi><mml:mrow><mml:mspace width="thinmathspace"/><mml:mi>y</mml:mi></mml:mrow></mml:msubsup><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>,</mml:mo><mml:mspace width="2em"/><mml:mi>y</mml:mi><mml:mo>∈</mml:mo><mml:mo fence="false" stretchy="false">{</mml:mo><mml:mi>E</mml:mi><mml:mo>,</mml:mo><mml:mi>I</mml:mi><mml:mo fence="false" stretchy="false">}</mml:mo><mml:mo>,</mml:mo></mml:mstyle></mml:mrow></mml:math></disp-formula></p><p>with <inline-formula><mml:math id="inf235"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msup><mml:mrow><mml:mover><mml:mrow><mml:mrow><mml:mover><mml:mi>x</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow></mml:mrow><mml:mo stretchy="false">→</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>y</mml:mi></mml:mrow></mml:msup><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>:=</mml:mo><mml:mo stretchy="false">[</mml:mo><mml:msubsup><mml:mrow><mml:mover><mml:mi>x</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>y</mml:mi></mml:mrow></mml:msubsup><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>,</mml:mo><mml:mo>…</mml:mo><mml:mo>,</mml:mo><mml:msubsup><mml:mrow><mml:mover><mml:mi>x</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>M</mml:mi></mml:mrow><mml:mrow><mml:mi>y</mml:mi></mml:mrow></mml:msubsup><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:msup><mml:mo stretchy="false">]</mml:mo><mml:mrow><mml:mi mathvariant="normal">⊤</mml:mi></mml:mrow></mml:msup></mml:mrow></mml:mstyle></mml:math></inline-formula> the vector of estimates of cell type <inline-formula><mml:math id="inf236"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>y</mml:mi></mml:mstyle></mml:math></inline-formula> and <inline-formula><mml:math id="inf237"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msubsup><mml:mrow><mml:mover><mml:mi>w</mml:mi><mml:mo stretchy="false">→</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mtext> </mml:mtext><mml:mi>y</mml:mi></mml:mrow></mml:msubsup></mml:mrow></mml:mstyle></mml:math></inline-formula> in units of (mV)<sup>1/2</sup>. Here, each neuron <inline-formula><mml:math id="inf238"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>i</mml:mi></mml:mstyle></mml:math></inline-formula> of type <inline-formula><mml:math id="inf239"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>y</mml:mi></mml:mstyle></mml:math></inline-formula> is associated with a vector <inline-formula><mml:math id="inf240"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msubsup><mml:mrow><mml:mover><mml:mi>w</mml:mi><mml:mo stretchy="false">→</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mtext> </mml:mtext><mml:mi>y</mml:mi></mml:mrow></mml:msubsup><mml:mo>:=</mml:mo><mml:mo stretchy="false">[</mml:mo><mml:msubsup><mml:mi>w</mml:mi><mml:mrow><mml:mn>1</mml:mn><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mtext> </mml:mtext><mml:mi>y</mml:mi></mml:mrow></mml:msubsup><mml:mo>,</mml:mo><mml:mo>…</mml:mo><mml:mo>,</mml:mo><mml:msubsup><mml:mi>w</mml:mi><mml:mrow><mml:mi>M</mml:mi><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mtext> </mml:mtext><mml:mi>y</mml:mi></mml:mrow></mml:msubsup><mml:msup><mml:mo stretchy="false">]</mml:mo><mml:mrow><mml:mi mathvariant="normal">⊤</mml:mi></mml:mrow></mml:msup></mml:mrow></mml:mstyle></mml:math></inline-formula> of <inline-formula><mml:math id="inf241"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>M</mml:mi></mml:mstyle></mml:math></inline-formula> tuning parameters representing the decoding weight of neuron <inline-formula><mml:math id="inf242"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>i</mml:mi></mml:mstyle></mml:math></inline-formula> with respect to the <inline-formula><mml:math id="inf243"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>M</mml:mi></mml:mstyle></mml:math></inline-formula> population readouts in <xref ref-type="disp-formula" rid="equ9">Equation 9</xref>. These decoding vectors can be combined in the <inline-formula><mml:math id="inf244"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>M</mml:mi><mml:mo>×</mml:mo><mml:msup><mml:mi>N</mml:mi><mml:mrow><mml:mtext> </mml:mtext><mml:mi>y</mml:mi></mml:mrow></mml:msup></mml:mrow></mml:mstyle></mml:math></inline-formula> matrix <inline-formula><mml:math id="inf245"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msup><mml:mi>W</mml:mi><mml:mrow><mml:mspace width="thinmathspace"/><mml:mi>y</mml:mi></mml:mrow></mml:msup><mml:mo>=</mml:mo><mml:mrow><mml:mo maxsize="1.2em" minsize="1.2em">[</mml:mo></mml:mrow><mml:msubsup><mml:mi>w</mml:mi><mml:mrow><mml:mi>k</mml:mi><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mtext> </mml:mtext><mml:mi>y</mml:mi></mml:mrow></mml:msubsup><mml:mrow><mml:mo maxsize="1.2em" minsize="1.2em">]</mml:mo></mml:mrow></mml:mrow></mml:mstyle></mml:math></inline-formula>. The rows of this matrix define the patterns of decoding weights <inline-formula><mml:math id="inf246"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msubsup><mml:mrow><mml:mover><mml:mrow><mml:mover><mml:mi>w</mml:mi><mml:mo stretchy="false">~</mml:mo></mml:mover></mml:mrow><mml:mo stretchy="false">→</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>k</mml:mi></mml:mrow><mml:mrow><mml:mi>y</mml:mi></mml:mrow></mml:msubsup><mml:mo>:=</mml:mo><mml:mrow><mml:mo maxsize="1.2em" minsize="1.2em">[</mml:mo></mml:mrow><mml:msubsup><mml:mi>w</mml:mi><mml:mrow><mml:mi>k</mml:mi><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mtext> </mml:mtext><mml:mi>y</mml:mi></mml:mrow></mml:msubsup><mml:mo>,</mml:mo><mml:mo>…</mml:mo><mml:mo>,</mml:mo><mml:msubsup><mml:mi>w</mml:mi><mml:mrow><mml:mi>k</mml:mi><mml:mtext> </mml:mtext><mml:msup><mml:mi>N</mml:mi><mml:mrow><mml:mi>y</mml:mi></mml:mrow></mml:msup></mml:mrow><mml:mrow><mml:mtext> </mml:mtext><mml:mi>y</mml:mi></mml:mrow></mml:msubsup><mml:msup><mml:mrow><mml:mo maxsize="1.2em" minsize="1.2em">]</mml:mo></mml:mrow><mml:mrow><mml:mi mathvariant="normal">⊤</mml:mi></mml:mrow></mml:msup></mml:mrow></mml:mstyle></mml:math></inline-formula> for each signal dimension <inline-formula><mml:math id="inf247"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>k</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mo>…</mml:mo><mml:mo>,</mml:mo><mml:mi>M</mml:mi></mml:mstyle></mml:math></inline-formula>.</p></sec><sec id="s4-3"><title>Loss functions</title><p>We assume that the activity of a population <inline-formula><mml:math id="inf248"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>y</mml:mi><mml:mo>∈</mml:mo><mml:mo fence="false" stretchy="false">{</mml:mo><mml:mi>E</mml:mi><mml:mo>,</mml:mo><mml:mi>I</mml:mi><mml:mo fence="false" stretchy="false">}</mml:mo></mml:mrow></mml:mstyle></mml:math></inline-formula> is set so as to minimize a time-dependent encoding error and a time-dependent metabolic cost:<disp-formula id="equ10"><label>(10)</label><mml:math id="m10"><mml:mrow><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msup><mml:mrow><mml:mi mathvariant="normal">L</mml:mi></mml:mrow><mml:mi>y</mml:mi></mml:msup><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:msup><mml:mi>ϵ</mml:mi><mml:mrow><mml:mspace width="thinmathspace"/><mml:mi>y</mml:mi></mml:mrow></mml:msup><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>+</mml:mo><mml:msup><mml:mi>β</mml:mi><mml:mi>y</mml:mi></mml:msup><mml:msup><mml:mi>κ</mml:mi><mml:mi>y</mml:mi></mml:msup><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>,</mml:mo></mml:mstyle></mml:mrow></mml:math></disp-formula></p><p>with <inline-formula><mml:math id="inf249"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msup><mml:mi>β</mml:mi><mml:mrow><mml:mspace width="thinmathspace"/><mml:mi>y</mml:mi></mml:mrow></mml:msup><mml:mo>&gt;</mml:mo><mml:mn>0</mml:mn></mml:mstyle></mml:mrow></mml:mstyle></mml:math></inline-formula> in units of mV the Lagrange multiplier which controls the weight of the metabolic cost relative to the encoding error. The time-dependent encoding error is defined as the squared distance between the targets and their estimates, and the role of estimates is assigned to the population readouts <inline-formula><mml:math id="inf250"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msup><mml:mrow><mml:mover><mml:mrow><mml:mrow><mml:mover><mml:mi>x</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow></mml:mrow><mml:mo stretchy="false">→</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mspace width="thinmathspace"/><mml:mi>y</mml:mi></mml:mrow></mml:msup><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mstyle></mml:mrow></mml:mstyle></mml:math></inline-formula>. In E neurons, the targets are defined as the target signals <inline-formula><mml:math id="inf251"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow class="MJX-TeXAtom-ORD"><mml:mover><mml:mi>x</mml:mi><mml:mo stretchy="false">→</mml:mo></mml:mover></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mstyle></mml:math></inline-formula>, and their estimators are the population readouts of the spiking activity of E neurons, <inline-formula><mml:math id="inf252"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msup><mml:mrow><mml:mover><mml:mrow><mml:mrow><mml:mover><mml:mi>x</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow></mml:mrow><mml:mo stretchy="false">→</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mspace width="thinmathspace"/><mml:mi>E</mml:mi></mml:mrow></mml:msup><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mstyle></mml:mrow></mml:mstyle></mml:math></inline-formula>. In I neurons, the targets are defined as the population readouts of E neurons <inline-formula><mml:math id="inf253"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msup><mml:mrow><mml:mover><mml:mrow><mml:mrow><mml:mover><mml:mi>x</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow></mml:mrow><mml:mo stretchy="false">→</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mspace width="thinmathspace"/><mml:mi>E</mml:mi></mml:mrow></mml:msup><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mstyle></mml:mrow></mml:mstyle></mml:math></inline-formula> and their estimators are the population readouts of I neurons <inline-formula><mml:math id="inf254"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msup><mml:mrow><mml:mover><mml:mrow><mml:mrow><mml:mover><mml:mi>x</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow></mml:mrow><mml:mo stretchy="false">→</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mspace width="thinmathspace"/><mml:mi>I</mml:mi></mml:mrow></mml:msup><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mstyle></mml:mrow></mml:mstyle></mml:math></inline-formula>. Furthermore, the time-dependent metabolic cost is proportional to the squared estimate of the instantaneous firing rate, summed across neurons from the same population. Following these assumptions, we define the variables of loss functions in <xref ref-type="disp-formula" rid="equ10">Equation 10</xref> as<disp-formula id="equ11"><label>(11)</label><mml:math id="m11"><mml:mrow><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mtable columnalign="right left right left right left right left right left right left" rowspacing="0.7em 0.3em" columnspacing="0em 2em 0em 2em 0em 2em 0em 2em 0em 2em 0em" displaystyle="true"><mml:mtr><mml:mtd><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msup><mml:mi>ε</mml:mi><mml:mrow><mml:mspace width="thinmathspace"/><mml:mi>E</mml:mi></mml:mrow></mml:msup><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mstyle></mml:mtd><mml:mtd><mml:mi/><mml:mo>=</mml:mo><mml:msup><mml:mrow><mml:mo symmetric="true">‖</mml:mo><mml:mrow><mml:mrow><mml:mover><mml:mi>x</mml:mi><mml:mo stretchy="false">→</mml:mo></mml:mover></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>−</mml:mo><mml:msup><mml:mrow><mml:mover><mml:mrow><mml:mover><mml:mi>x</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mo stretchy="false">→</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mspace width="thinmathspace"/><mml:mi>E</mml:mi></mml:mrow></mml:msup><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo symmetric="true">‖</mml:mo></mml:mrow><mml:mn>2</mml:mn></mml:msup><mml:mo>,</mml:mo><mml:mspace width="2em"/><mml:msup><mml:mi>κ</mml:mi><mml:mrow><mml:mspace width="thinmathspace"/><mml:mi>E</mml:mi></mml:mrow></mml:msup><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:munderover><mml:mo>∑</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:msup><mml:mi>N</mml:mi><mml:mrow><mml:mspace width="thinmathspace"/><mml:mi>E</mml:mi></mml:mrow></mml:msup></mml:mrow></mml:munderover><mml:msup><mml:mrow><mml:mo>[</mml:mo><mml:mrow><mml:msubsup><mml:mi>r</mml:mi><mml:mi>i</mml:mi><mml:mrow><mml:mspace width="thinmathspace"/><mml:mi>E</mml:mi></mml:mrow></mml:msubsup><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>]</mml:mo></mml:mrow><mml:mn>2</mml:mn></mml:msup><mml:mo>,</mml:mo></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msup><mml:mi>ε</mml:mi><mml:mrow><mml:mspace width="thinmathspace"/><mml:mi>I</mml:mi></mml:mrow></mml:msup><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mstyle></mml:mtd><mml:mtd><mml:mi/><mml:mo>=</mml:mo><mml:msup><mml:mrow><mml:mo symmetric="true">‖</mml:mo><mml:mrow><mml:msup><mml:mrow><mml:mover><mml:mrow><mml:mover><mml:mi>x</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mo stretchy="false">→</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mspace width="thinmathspace"/><mml:mi>E</mml:mi></mml:mrow></mml:msup><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>−</mml:mo><mml:msup><mml:mrow><mml:mover><mml:mrow><mml:mover><mml:mi>x</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mo stretchy="false">→</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mspace width="thinmathspace"/><mml:mi>I</mml:mi></mml:mrow></mml:msup><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo symmetric="true">‖</mml:mo></mml:mrow><mml:mn>2</mml:mn></mml:msup><mml:mo>,</mml:mo><mml:mspace width="2em"/><mml:msup><mml:mi>κ</mml:mi><mml:mrow><mml:mspace width="thinmathspace"/><mml:mi>I</mml:mi></mml:mrow></mml:msup><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:munderover><mml:mo>∑</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:msup><mml:mi>N</mml:mi><mml:mrow><mml:mspace width="thinmathspace"/><mml:mi>I</mml:mi></mml:mrow></mml:msup></mml:mrow></mml:munderover><mml:msup><mml:mrow><mml:mo>[</mml:mo><mml:mrow><mml:msubsup><mml:mi>r</mml:mi><mml:mi>i</mml:mi><mml:mrow><mml:mspace width="thinmathspace"/><mml:mi>I</mml:mi></mml:mrow></mml:msubsup><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>]</mml:mo></mml:mrow><mml:mn>2</mml:mn></mml:msup><mml:mo>.</mml:mo></mml:mtd></mml:mtr></mml:mtable></mml:mstyle></mml:mrow></mml:math></disp-formula></p><p>We use a quadratic metabolic cost because it promotes the distribution of spiking across neurons (<xref ref-type="bibr" rid="bib11">Boerlin et al., 2013</xref>). In particular, the loss function of I neurons, <inline-formula><mml:math id="inf255"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msup><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi mathvariant="normal">L</mml:mi></mml:mrow><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>I</mml:mi></mml:mrow></mml:msup><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mstyle></mml:math></inline-formula> implies the relevance of the approximation: <inline-formula><mml:math id="inf256"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msup><mml:mrow><mml:mover><mml:mrow><mml:mrow><mml:mover><mml:mi>x</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow></mml:mrow><mml:mo stretchy="false">→</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mspace width="thinmathspace"/><mml:mi>E</mml:mi></mml:mrow></mml:msup><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>≈</mml:mo><mml:msup><mml:mrow><mml:mover><mml:mrow><mml:mrow><mml:mover><mml:mi>x</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow></mml:mrow><mml:mo stretchy="false">→</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mspace width="thinmathspace"/><mml:mi>I</mml:mi></mml:mrow></mml:msup><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mstyle></mml:mrow></mml:mstyle></mml:math></inline-formula> (see <inline-formula><mml:math id="inf257"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msup><mml:mi>ϵ</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>I</mml:mi></mml:mrow></mml:msup></mml:mstyle></mml:math></inline-formula> in the <xref ref-type="disp-formula" rid="equ11">Equation 11</xref>), which will be used in what follows.</p></sec><sec id="s4-4"><title>When shall a neuron spike?</title><p>We minimize the loss function by positing that neuron <inline-formula><mml:math id="inf258"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>i</mml:mi></mml:mstyle></mml:math></inline-formula> of type <inline-formula><mml:math id="inf259"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>y</mml:mi><mml:mo>∈</mml:mo><mml:mo fence="false" stretchy="false">{</mml:mo><mml:mi>E</mml:mi><mml:mo>,</mml:mo><mml:mi>I</mml:mi><mml:mo fence="false" stretchy="false">}</mml:mo></mml:mstyle></mml:math></inline-formula> emits a spike as soon as its spike decreases the loss function of its population <inline-formula><mml:math id="inf260"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>y</mml:mi></mml:mstyle></mml:math></inline-formula> in the immediate future (<xref ref-type="bibr" rid="bib49">Koren and Panzeri, 2022</xref>). We also define <inline-formula><mml:math id="inf261"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msup><mml:mi>t</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mo>−</mml:mo></mml:mrow></mml:msup></mml:mstyle></mml:math></inline-formula> and <inline-formula><mml:math id="inf262"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msup><mml:mi>t</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mo>+</mml:mo></mml:mrow></mml:msup></mml:mstyle></mml:math></inline-formula> as the left- and right-sided limits of a spike time <inline-formula><mml:math id="inf263"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>t</mml:mi><mml:mo>=</mml:mo><mml:msubsup><mml:mi>t</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>i</mml:mi></mml:mrow><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>y</mml:mi><mml:mo>,</mml:mo><mml:mi>α</mml:mi></mml:mrow></mml:msubsup></mml:mstyle></mml:math></inline-formula>, respectively. Thus, at the spike time, the following jump condition must hold:<disp-formula id="equ12"><label>(12)</label><mml:math id="m12"><mml:mrow><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msup><mml:mrow><mml:mi mathvariant="normal">L</mml:mi></mml:mrow><mml:mi>y</mml:mi></mml:msup><mml:mo stretchy="false">(</mml:mo><mml:msup><mml:mi>t</mml:mi><mml:mo>+</mml:mo></mml:msup><mml:mo stretchy="false">)</mml:mo><mml:mo>≤</mml:mo><mml:msup><mml:mrow><mml:mi mathvariant="normal">L</mml:mi></mml:mrow><mml:mi>y</mml:mi></mml:msup><mml:mo stretchy="false">(</mml:mo><mml:msup><mml:mi>t</mml:mi><mml:mo>−</mml:mo></mml:msup><mml:mo stretchy="false">)</mml:mo><mml:mo>+</mml:mo><mml:msubsup><mml:mi>ξ</mml:mi><mml:mi>i</mml:mi><mml:mrow><mml:mspace width="thinmathspace"/><mml:mi>y</mml:mi></mml:mrow></mml:msubsup><mml:mo stretchy="false">(</mml:mo><mml:msup><mml:mi>t</mml:mi><mml:mrow><mml:mo>−</mml:mo></mml:mrow></mml:msup><mml:mo stretchy="false">)</mml:mo><mml:mo>,</mml:mo><mml:mspace width="2em"/><mml:mi>y</mml:mi><mml:mo>∈</mml:mo><mml:mo fence="false" stretchy="false">{</mml:mo><mml:mi>E</mml:mi><mml:mo>,</mml:mo><mml:mi>I</mml:mi><mml:mo fence="false" stretchy="false">}</mml:mo><mml:mo>,</mml:mo></mml:mstyle></mml:mrow></mml:math></disp-formula></p><p>with <inline-formula><mml:math id="inf264"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msubsup><mml:mi>ξ</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mspace width="thinmathspace"/><mml:mi>y</mml:mi></mml:mrow></mml:msubsup></mml:mstyle></mml:mrow></mml:mstyle></mml:math></inline-formula> in units of mV. Here, the arguments <inline-formula><mml:math id="inf265"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msup><mml:mi>t</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mo>−</mml:mo></mml:mrow></mml:msup></mml:mstyle></mml:math></inline-formula> and <inline-formula><mml:math id="inf266"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msup><mml:mi>t</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mo>+</mml:mo></mml:mrow></mml:msup></mml:mstyle></mml:math></inline-formula> denote the left- and right-sided limits of the respected functions at time <inline-formula><mml:math id="inf267"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>t</mml:mi></mml:mstyle></mml:math></inline-formula>. Furthermore, we added a noise term on the right-hand side of the <xref ref-type="disp-formula" rid="equ12">Equation 12</xref> in order to consider the stochastic nature of spike generation in biological networks (<xref ref-type="bibr" rid="bib35">Faisal et al., 2008</xref>). A convenient choice for the noise <inline-formula><mml:math id="inf268"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msubsup><mml:mi>ξ</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mspace width="thinmathspace"/><mml:mi>y</mml:mi></mml:mrow></mml:msubsup><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mstyle></mml:mrow></mml:mstyle></mml:math></inline-formula> is the Ornstein-Uhlenbeck process obeying<disp-formula id="equ13"><label>(13)</label><mml:math id="m13"><mml:mrow><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msubsup><mml:mrow><mml:mover><mml:mi>ξ</mml:mi><mml:mo>˙</mml:mo></mml:mover></mml:mrow><mml:mi>i</mml:mi><mml:mrow><mml:mspace width="thinmathspace"/><mml:mi>y</mml:mi></mml:mrow></mml:msubsup><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mo>−</mml:mo><mml:mi>λ</mml:mi><mml:msubsup><mml:mi>ξ</mml:mi><mml:mi>i</mml:mi><mml:mrow><mml:mspace width="thinmathspace"/><mml:mi>y</mml:mi></mml:mrow></mml:msubsup><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>+</mml:mo><mml:msqrt><mml:mn>2</mml:mn><mml:mi>λ</mml:mi></mml:msqrt><mml:msubsup><mml:mi>σ</mml:mi><mml:mrow><mml:mi>ξ</mml:mi></mml:mrow><mml:mrow><mml:mspace width="thinmathspace"/><mml:mi>y</mml:mi></mml:mrow></mml:msubsup><mml:msubsup><mml:mi>η</mml:mi><mml:mi>i</mml:mi><mml:mrow><mml:mspace width="thinmathspace"/><mml:mi>y</mml:mi></mml:mrow></mml:msubsup><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>,</mml:mo></mml:mstyle></mml:mrow></mml:math></disp-formula></p><p>where <inline-formula><mml:math id="inf269"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msubsup><mml:mi>η</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mspace width="thinmathspace"/><mml:mi>y</mml:mi></mml:mrow></mml:msubsup></mml:mrow></mml:mstyle></mml:math></inline-formula> is a Gaussian white noise with auto-covariance function <inline-formula><mml:math id="inf270"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mo fence="false" stretchy="false">⟨</mml:mo><mml:msub><mml:mi>η</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:msub><mml:mi>η</mml:mi><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:msup><mml:mi>t</mml:mi><mml:mrow><mml:mi mathvariant="normal">′</mml:mi></mml:mrow></mml:msup><mml:mo stretchy="false">)</mml:mo><mml:mo fence="false" stretchy="false">⟩</mml:mo><mml:mo>=</mml:mo><mml:msub><mml:mi>δ</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mi>δ</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo>−</mml:mo><mml:msup><mml:mi>t</mml:mi><mml:mrow><mml:mi mathvariant="normal">′</mml:mi></mml:mrow></mml:msup><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mstyle></mml:math></inline-formula>. The process <inline-formula><mml:math id="inf271"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msubsup><mml:mi>ξ</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mspace width="thinmathspace"/><mml:mi>y</mml:mi></mml:mrow></mml:msubsup><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mstyle></mml:math></inline-formula> has zero mean and auto-covariance function <inline-formula><mml:math id="inf272"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mo fence="false" stretchy="false">⟨</mml:mo><mml:msub><mml:mi>ξ</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:msub><mml:mi>ξ</mml:mi><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:msup><mml:mi>t</mml:mi><mml:mrow><mml:mi mathvariant="normal">′</mml:mi></mml:mrow></mml:msup><mml:mo stretchy="false">)</mml:mo><mml:mo fence="false" stretchy="false">⟩</mml:mo><mml:mo>=</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:msubsup><mml:mi>σ</mml:mi><mml:mrow><mml:mi>ξ</mml:mi></mml:mrow><mml:mrow><mml:mspace width="thinmathspace"/><mml:mi>y</mml:mi></mml:mrow></mml:msubsup><mml:msup><mml:mo stretchy="false">)</mml:mo><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup><mml:msub><mml:mi>δ</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:msup><mml:mi>e</mml:mi><mml:mrow><mml:mo>−</mml:mo><mml:mi>λ</mml:mi><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mi>t</mml:mi><mml:mo>−</mml:mo><mml:msup><mml:mi>t</mml:mi><mml:mrow><mml:mi mathvariant="normal">′</mml:mi></mml:mrow></mml:msup><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow></mml:mrow></mml:msup></mml:mrow></mml:mstyle></mml:math></inline-formula>, with <inline-formula><mml:math id="inf273"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msubsup><mml:mi>σ</mml:mi><mml:mrow><mml:mi>ξ</mml:mi></mml:mrow><mml:mrow><mml:mspace width="thinmathspace"/><mml:mi>y</mml:mi></mml:mrow></mml:msubsup><mml:msup><mml:mo stretchy="false">)</mml:mo><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:mstyle></mml:math></inline-formula> the variance of the noise.</p><p>By applying the condition for spiking in <xref ref-type="disp-formula" rid="equ12">Equation 12</xref> using <inline-formula><mml:math id="inf274"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>y</mml:mi><mml:mo>=</mml:mo><mml:mi>E</mml:mi></mml:mstyle></mml:math></inline-formula> and <inline-formula><mml:math id="inf275"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>y</mml:mi><mml:mo>=</mml:mo><mml:mi>I</mml:mi></mml:mstyle></mml:math></inline-formula>, respectively, we get<disp-formula id="equ14"><label>(14)</label><mml:math id="m14"><mml:mrow><mml:mtable columnalign="right left right left right left right left right left right left" rowspacing="3pt" columnspacing="0em 2em 0em 2em 0em 2em 0em 2em 0em 2em 0em" displaystyle="true"><mml:mtr><mml:mtd><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mo>[</mml:mo><mml:mrow><mml:msup><mml:mrow><mml:mo symmetric="true">‖</mml:mo><mml:mrow><mml:mrow><mml:mover><mml:mi>x</mml:mi><mml:mo stretchy="false">→</mml:mo></mml:mover></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msup><mml:mi>t</mml:mi><mml:mo>+</mml:mo></mml:msup><mml:mo stretchy="false">)</mml:mo><mml:mo>−</mml:mo><mml:msup><mml:mrow><mml:mover><mml:mrow><mml:mover><mml:mi>x</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mo stretchy="false">→</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mspace width="thinmathspace"/><mml:mi>E</mml:mi></mml:mrow></mml:msup><mml:mo stretchy="false">(</mml:mo><mml:msup><mml:mi>t</mml:mi><mml:mo>+</mml:mo></mml:msup><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo symmetric="true">‖</mml:mo></mml:mrow><mml:mn>2</mml:mn></mml:msup><mml:mo>+</mml:mo><mml:msup><mml:mi>β</mml:mi><mml:mrow><mml:mspace width="thinmathspace"/><mml:mi>E</mml:mi></mml:mrow></mml:msup><mml:munderover><mml:mo>∑</mml:mo><mml:mrow><mml:mi>j</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:msup><mml:mi>N</mml:mi><mml:mrow><mml:mspace width="thinmathspace"/><mml:mi>E</mml:mi></mml:mrow></mml:msup></mml:mrow></mml:munderover><mml:msup><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msubsup><mml:mi>r</mml:mi><mml:mrow><mml:mi>j</mml:mi></mml:mrow><mml:mrow><mml:mspace width="thinmathspace"/><mml:mi>E</mml:mi></mml:mrow></mml:msubsup><mml:mo stretchy="false">(</mml:mo><mml:msup><mml:mi>t</mml:mi><mml:mo>+</mml:mo></mml:msup><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mn>2</mml:mn></mml:msup></mml:mrow><mml:mo>]</mml:mo></mml:mrow><mml:mo>−</mml:mo><mml:mrow><mml:mo>[</mml:mo><mml:mrow><mml:msup><mml:mrow><mml:mo symmetric="true">‖</mml:mo><mml:mrow><mml:mrow><mml:mover><mml:mi>x</mml:mi><mml:mo stretchy="false">→</mml:mo></mml:mover></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msup><mml:mi>t</mml:mi><mml:mo>−</mml:mo></mml:msup><mml:mo stretchy="false">)</mml:mo><mml:mo>−</mml:mo><mml:msup><mml:mrow><mml:mover><mml:mrow><mml:mover><mml:mi>x</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mo stretchy="false">→</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mspace width="thinmathspace"/><mml:mi>E</mml:mi></mml:mrow></mml:msup><mml:mo stretchy="false">(</mml:mo><mml:msup><mml:mi>t</mml:mi><mml:mo>−</mml:mo></mml:msup><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo symmetric="true">‖</mml:mo></mml:mrow><mml:mn>2</mml:mn></mml:msup><mml:mo>+</mml:mo><mml:msup><mml:mi>β</mml:mi><mml:mrow><mml:mspace width="thinmathspace"/><mml:mi>E</mml:mi></mml:mrow></mml:msup><mml:munderover><mml:mo>∑</mml:mo><mml:mrow><mml:mi>j</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:msup><mml:mi>N</mml:mi><mml:mrow><mml:mspace width="thinmathspace"/><mml:mi>E</mml:mi></mml:mrow></mml:msup></mml:mrow></mml:munderover><mml:msup><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msubsup><mml:mi>r</mml:mi><mml:mrow><mml:mi>j</mml:mi></mml:mrow><mml:mrow><mml:mspace width="thinmathspace"/><mml:mi>E</mml:mi></mml:mrow></mml:msubsup><mml:mo stretchy="false">(</mml:mo><mml:msup><mml:mi>t</mml:mi><mml:mo>−</mml:mo></mml:msup><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mn>2</mml:mn></mml:msup></mml:mrow><mml:mo>]</mml:mo></mml:mrow><mml:mo>≤</mml:mo><mml:msubsup><mml:mi>ξ</mml:mi><mml:mi>i</mml:mi><mml:mrow><mml:mspace width="thinmathspace"/><mml:mi>E</mml:mi></mml:mrow></mml:msubsup><mml:mo stretchy="false">(</mml:mo><mml:msup><mml:mi>t</mml:mi><mml:mo>−</mml:mo></mml:msup><mml:mo stretchy="false">)</mml:mo><mml:mo>,</mml:mo></mml:mstyle></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mo>[</mml:mo><mml:mrow><mml:msup><mml:mrow><mml:mo symmetric="true">‖</mml:mo><mml:mrow><mml:msup><mml:mrow><mml:mover><mml:mrow><mml:mover><mml:mi>x</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mo stretchy="false">→</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mspace width="thinmathspace"/><mml:mi>E</mml:mi></mml:mrow></mml:msup><mml:mo stretchy="false">(</mml:mo><mml:msup><mml:mi>t</mml:mi><mml:mo>+</mml:mo></mml:msup><mml:mo stretchy="false">)</mml:mo><mml:mo>−</mml:mo><mml:msup><mml:mrow><mml:mover><mml:mrow><mml:mover><mml:mi>x</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mo stretchy="false">→</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mspace width="thinmathspace"/><mml:mi>I</mml:mi></mml:mrow></mml:msup><mml:mo stretchy="false">(</mml:mo><mml:msup><mml:mi>t</mml:mi><mml:mo>+</mml:mo></mml:msup><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo symmetric="true">‖</mml:mo></mml:mrow><mml:mn>2</mml:mn></mml:msup><mml:mo>+</mml:mo><mml:msup><mml:mi>β</mml:mi><mml:mrow><mml:mspace width="thinmathspace"/><mml:mi>I</mml:mi></mml:mrow></mml:msup><mml:munderover><mml:mo>∑</mml:mo><mml:mrow><mml:mi>j</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:msup><mml:mi>N</mml:mi><mml:mrow><mml:mspace width="thinmathspace"/><mml:mi>I</mml:mi></mml:mrow></mml:msup></mml:mrow></mml:munderover><mml:msup><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msubsup><mml:mi>r</mml:mi><mml:mrow><mml:mi>j</mml:mi></mml:mrow><mml:mrow><mml:mspace width="thinmathspace"/><mml:mi>I</mml:mi></mml:mrow></mml:msubsup><mml:mo stretchy="false">(</mml:mo><mml:msup><mml:mi>t</mml:mi><mml:mo>+</mml:mo></mml:msup><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mn>2</mml:mn></mml:msup></mml:mrow><mml:mo>]</mml:mo></mml:mrow><mml:mo>−</mml:mo><mml:mrow><mml:mo>[</mml:mo><mml:mrow><mml:msup><mml:mrow><mml:mo symmetric="true">‖</mml:mo><mml:mrow><mml:msup><mml:mrow><mml:mover><mml:mrow><mml:mover><mml:mi>x</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mo stretchy="false">→</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mspace width="thinmathspace"/><mml:mi>E</mml:mi></mml:mrow></mml:msup><mml:mo stretchy="false">(</mml:mo><mml:msup><mml:mi>t</mml:mi><mml:mo>−</mml:mo></mml:msup><mml:mo stretchy="false">)</mml:mo><mml:mo>−</mml:mo><mml:msup><mml:mrow><mml:mover><mml:mrow><mml:mover><mml:mi>x</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mo stretchy="false">→</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mspace width="thinmathspace"/><mml:mi>I</mml:mi></mml:mrow></mml:msup><mml:mo stretchy="false">(</mml:mo><mml:msup><mml:mi>t</mml:mi><mml:mo>−</mml:mo></mml:msup><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo symmetric="true">‖</mml:mo></mml:mrow><mml:mn>2</mml:mn></mml:msup><mml:mo>+</mml:mo><mml:msup><mml:mi>β</mml:mi><mml:mrow><mml:mspace width="thinmathspace"/><mml:mi>I</mml:mi></mml:mrow></mml:msup><mml:munderover><mml:mo>∑</mml:mo><mml:mrow><mml:mi>j</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:msup><mml:mi>N</mml:mi><mml:mrow><mml:mspace width="thinmathspace"/><mml:mi>I</mml:mi></mml:mrow></mml:msup></mml:mrow></mml:munderover><mml:msup><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msubsup><mml:mi>r</mml:mi><mml:mrow><mml:mi>j</mml:mi></mml:mrow><mml:mrow><mml:mspace width="thinmathspace"/><mml:mi>I</mml:mi></mml:mrow></mml:msubsup><mml:mo stretchy="false">(</mml:mo><mml:msup><mml:mi>t</mml:mi><mml:mo>−</mml:mo></mml:msup><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mn>2</mml:mn></mml:msup></mml:mrow><mml:mo>]</mml:mo></mml:mrow><mml:mo>≤</mml:mo><mml:msubsup><mml:mi>ξ</mml:mi><mml:mi>i</mml:mi><mml:mrow><mml:mspace width="thinmathspace"/><mml:mi>I</mml:mi></mml:mrow></mml:msubsup><mml:mo stretchy="false">(</mml:mo><mml:msup><mml:mi>t</mml:mi><mml:mo>−</mml:mo></mml:msup><mml:mo stretchy="false">)</mml:mo><mml:mo>.</mml:mo></mml:mstyle></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:math></disp-formula></p><p>According to the definitions in <xref ref-type="disp-formula" rid="equ7">Equation 7</xref> and <xref ref-type="disp-formula" rid="equ9">Equation 9</xref>, if neuron <italic>i</italic> fires a spike at time <inline-formula><mml:math id="inf276"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>t</mml:mi><mml:mo>=</mml:mo><mml:msubsup><mml:mi>t</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mspace width="thinmathspace"/><mml:mi>y</mml:mi><mml:mo>,</mml:mo><mml:mi>α</mml:mi></mml:mrow></mml:msubsup></mml:mstyle></mml:mrow></mml:mstyle></mml:math></inline-formula>, it causes a jump of its own filtered spike train (but not of other neurons <inline-formula><mml:math id="inf277"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>j</mml:mi><mml:mo>≠</mml:mo><mml:mi>i</mml:mi></mml:mstyle></mml:math></inline-formula>), as well as of the population readout of the population it belongs to. Therefore, when neuron <inline-formula><mml:math id="inf278"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>i</mml:mi></mml:mstyle></mml:math></inline-formula> fires a spike, we have for a given neuron <inline-formula><mml:math id="inf279"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>j</mml:mi></mml:mstyle></mml:math></inline-formula> and a given population readout <inline-formula><mml:math id="inf280"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>k</mml:mi></mml:mstyle></mml:math></inline-formula>:<disp-formula id="equ15"><label>(15a)</label><mml:math id="m15"><mml:mrow><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msubsup><mml:mi>r</mml:mi><mml:mrow><mml:mi>j</mml:mi></mml:mrow><mml:mrow><mml:mspace width="thinmathspace"/><mml:mi>y</mml:mi></mml:mrow></mml:msubsup><mml:mo stretchy="false">(</mml:mo><mml:msup><mml:mi>t</mml:mi><mml:mo>+</mml:mo></mml:msup><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:msubsup><mml:mi>r</mml:mi><mml:mrow><mml:mi>j</mml:mi></mml:mrow><mml:mrow><mml:mspace width="thinmathspace"/><mml:mi>y</mml:mi></mml:mrow></mml:msubsup><mml:mo stretchy="false">(</mml:mo><mml:msup><mml:mi>t</mml:mi><mml:mo>−</mml:mo></mml:msup><mml:mo stretchy="false">)</mml:mo><mml:mo>+</mml:mo><mml:msub><mml:mi>δ</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo></mml:mstyle></mml:mrow></mml:math></disp-formula><disp-formula id="equ16"><label>(15b)</label><mml:math id="m16"><mml:mrow><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msubsup><mml:mrow><mml:mover><mml:mi>x</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>k</mml:mi></mml:mrow><mml:mrow><mml:mspace width="thinmathspace"/><mml:mi>y</mml:mi></mml:mrow></mml:msubsup><mml:mo stretchy="false">(</mml:mo><mml:msup><mml:mi>t</mml:mi><mml:mo>+</mml:mo></mml:msup><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:msubsup><mml:mrow><mml:mover><mml:mi>x</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>k</mml:mi></mml:mrow><mml:mrow><mml:mspace width="thinmathspace"/><mml:mi>y</mml:mi></mml:mrow></mml:msubsup><mml:mo stretchy="false">(</mml:mo><mml:msup><mml:mi>t</mml:mi><mml:mo>−</mml:mo></mml:msup><mml:mo stretchy="false">)</mml:mo><mml:mo>+</mml:mo><mml:msubsup><mml:mi>w</mml:mi><mml:mrow><mml:mi>k</mml:mi><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mspace width="thinmathspace"/><mml:mi>y</mml:mi></mml:mrow></mml:msubsup><mml:mo>.</mml:mo></mml:mstyle></mml:mrow></mml:math></disp-formula></p><p>By inserting <xref ref-type="disp-formula" rid="equ15">Equation 15a</xref>, <xref ref-type="disp-formula" rid="equ16">Equation 15b</xref> in <xref ref-type="disp-formula" rid="equ12">Equation 12</xref>, we find that neuron <inline-formula><mml:math id="inf281"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>i</mml:mi></mml:mstyle></mml:math></inline-formula> of type <inline-formula><mml:math id="inf282"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>y</mml:mi></mml:mstyle></mml:math></inline-formula> should fire a spike if the following condition holds:<disp-formula id="equ17"><label>(16a)</label><mml:math id="m17"><mml:mrow><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mtable columnalign="right left right left right left right left right left right left" rowspacing="3pt" columnspacing="0em 2em 0em 2em 0em 2em 0em 2em 0em 2em 0em" displaystyle="true"><mml:mtr><mml:mtd/><mml:mtd><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mo stretchy="false">(</mml:mo><mml:msubsup><mml:mrow><mml:mover><mml:mi>w</mml:mi><mml:mo stretchy="false">→</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mspace width="thinmathspace"/><mml:mi>E</mml:mi></mml:mrow></mml:msubsup><mml:msup><mml:mo stretchy="false">)</mml:mo><mml:mrow><mml:mi mathvariant="normal">⊤</mml:mi></mml:mrow></mml:msup><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mrow><mml:mover><mml:mi>x</mml:mi><mml:mo stretchy="false">→</mml:mo></mml:mover></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>−</mml:mo><mml:msup><mml:mrow><mml:mover><mml:mrow><mml:mover><mml:mi>x</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mo stretchy="false">→</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mspace width="thinmathspace"/><mml:mi>E</mml:mi></mml:mrow></mml:msup><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>−</mml:mo><mml:msup><mml:mi>β</mml:mi><mml:mrow><mml:mspace width="thinmathspace"/><mml:mi>E</mml:mi></mml:mrow></mml:msup><mml:msubsup><mml:mi>r</mml:mi><mml:mi>i</mml:mi><mml:mrow><mml:mspace width="thinmathspace"/><mml:mi>E</mml:mi></mml:mrow></mml:msubsup><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>≥</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mn>2</mml:mn></mml:mfrac><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msup><mml:mrow><mml:mo symmetric="true">‖</mml:mo><mml:msubsup><mml:mrow><mml:mover><mml:mi>w</mml:mi><mml:mo stretchy="false">→</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mspace width="thinmathspace"/><mml:mi>E</mml:mi></mml:mrow></mml:msubsup><mml:mo symmetric="true">‖</mml:mo></mml:mrow><mml:mn>2</mml:mn></mml:msup><mml:mo>+</mml:mo><mml:msup><mml:mi>β</mml:mi><mml:mrow><mml:mspace width="thinmathspace"/><mml:mi>E</mml:mi></mml:mrow></mml:msup><mml:mo>−</mml:mo><mml:msubsup><mml:mi>ξ</mml:mi><mml:mi>i</mml:mi><mml:mrow><mml:mspace width="thinmathspace"/><mml:mi>E</mml:mi></mml:mrow></mml:msubsup><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>,</mml:mo></mml:mstyle></mml:mtd></mml:mtr><mml:mtr><mml:mtd/><mml:mtd><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mo stretchy="false">(</mml:mo><mml:msubsup><mml:mrow><mml:mover><mml:mi>w</mml:mi><mml:mo stretchy="false">→</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mspace width="thinmathspace"/><mml:mi>I</mml:mi></mml:mrow></mml:msubsup><mml:msup><mml:mo stretchy="false">)</mml:mo><mml:mrow><mml:mi mathvariant="normal">⊤</mml:mi></mml:mrow></mml:msup><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msup><mml:mrow><mml:mover><mml:mrow><mml:mover><mml:mi>x</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mo stretchy="false">→</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mspace width="thinmathspace"/><mml:mi>E</mml:mi></mml:mrow></mml:msup><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>−</mml:mo><mml:msup><mml:mrow><mml:mover><mml:mrow><mml:mover><mml:mi>x</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mo stretchy="false">→</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mspace width="thinmathspace"/><mml:mi>I</mml:mi></mml:mrow></mml:msup><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>−</mml:mo><mml:msup><mml:mi>β</mml:mi><mml:mrow><mml:mspace width="thinmathspace"/><mml:mi>I</mml:mi></mml:mrow></mml:msup><mml:msubsup><mml:mi>r</mml:mi><mml:mi>i</mml:mi><mml:mrow><mml:mspace width="thinmathspace"/><mml:mi>I</mml:mi></mml:mrow></mml:msubsup><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>≥</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mn>2</mml:mn></mml:mfrac><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msup><mml:mrow><mml:mo symmetric="true">‖</mml:mo><mml:msubsup><mml:mrow><mml:mover><mml:mi>w</mml:mi><mml:mo stretchy="false">→</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mspace width="thinmathspace"/><mml:mi>I</mml:mi></mml:mrow></mml:msubsup><mml:mo symmetric="true">‖</mml:mo></mml:mrow><mml:mn>2</mml:mn></mml:msup><mml:mo>+</mml:mo><mml:msup><mml:mi>β</mml:mi><mml:mrow><mml:mspace width="thinmathspace"/><mml:mi>I</mml:mi></mml:mrow></mml:msup><mml:mo>−</mml:mo><mml:msubsup><mml:mi>ξ</mml:mi><mml:mi>i</mml:mi><mml:mrow><mml:mspace width="thinmathspace"/><mml:mi>I</mml:mi></mml:mrow></mml:msubsup><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mstyle></mml:mtd></mml:mtr></mml:mtable></mml:mstyle></mml:mrow></mml:math></disp-formula></p><p>with <inline-formula><mml:math id="inf283"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mo fence="false" stretchy="false">‖</mml:mo><mml:msubsup><mml:mrow><mml:mover><mml:mi>w</mml:mi><mml:mo stretchy="false">→</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mspace width="thinmathspace"/><mml:mi>y</mml:mi></mml:mrow></mml:msubsup><mml:msup><mml:mo fence="false" stretchy="false">‖</mml:mo><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup><mml:mo>:=</mml:mo><mml:munderover><mml:mo>∑</mml:mo><mml:mrow><mml:mi>k</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>M</mml:mi></mml:mrow></mml:munderover><mml:mo stretchy="false">(</mml:mo><mml:msubsup><mml:mi>w</mml:mi><mml:mrow><mml:mi>k</mml:mi><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mspace width="thinmathspace"/><mml:mi>y</mml:mi></mml:mrow></mml:msubsup><mml:msup><mml:mo stretchy="false">)</mml:mo><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:mstyle></mml:math></inline-formula> the squared length of the tuning vector of neuron <inline-formula><mml:math id="inf284"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>i</mml:mi></mml:mstyle></mml:math></inline-formula> of type <inline-formula><mml:math id="inf285"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>y</mml:mi></mml:mstyle></mml:math></inline-formula>. These equations tell us when the neuron <inline-formula><mml:math id="inf286"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>i</mml:mi></mml:mstyle></mml:math></inline-formula> of type <inline-formula><mml:math id="inf287"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>E</mml:mi></mml:mstyle></mml:math></inline-formula> and <inline-formula><mml:math id="inf288"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>I</mml:mi></mml:mstyle></mml:math></inline-formula>, respectively, emits a spike, and are similar to the ones derived in previous works (<xref ref-type="bibr" rid="bib49">Koren and Panzeri, 2022</xref>; <xref ref-type="bibr" rid="bib11">Boerlin et al., 2013</xref>). In addition to what has been found in these previous works, we here also find that each term on the left- and right-hand side in the <xref ref-type="disp-formula" rid="equ17">Equation 16a</xref> has the physical units of millivolts.</p><p>We note that the expression derived from the minimization of the loss function of E neurons in the top row of <xref ref-type="disp-formula" rid="equ17">Equation 16a</xref> is independent of the activity of I neurons, and would thus lead to the E population being unconnected with the I population. In order to derive a recurrently connected E-I network, the activity of E neurons must depend on the activity of I neurons. We impose this property by using the approximation of estimates that holds under the assumption of efficient coding in I neurons (see <inline-formula><mml:math id="inf289"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msup><mml:mi>ϵ</mml:mi><mml:mrow><mml:mspace width="thinmathspace"/><mml:mi>I</mml:mi></mml:mrow></mml:msup></mml:mstyle></mml:mrow></mml:mstyle></mml:math></inline-formula> in the <xref ref-type="disp-formula" rid="equ11">Equation 11</xref>), <inline-formula><mml:math id="inf290"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msup><mml:mrow><mml:mover><mml:mrow><mml:mrow><mml:mover><mml:mi>x</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow></mml:mrow><mml:mo stretchy="false">→</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mspace width="thinmathspace"/><mml:mi>I</mml:mi></mml:mrow></mml:msup><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>≈</mml:mo><mml:msup><mml:mrow><mml:mover><mml:mrow><mml:mrow><mml:mover><mml:mi>x</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow></mml:mrow><mml:mo stretchy="false">→</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mspace width="thinmathspace"/><mml:mi>E</mml:mi></mml:mrow></mml:msup><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mstyle></mml:mrow></mml:mstyle></mml:math></inline-formula>. This yields the following conditions:<disp-formula id="equ18"><label>(16b)</label><mml:math id="m18"><mml:mrow><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mtable columnalign="right left right left right left right left right left right left" rowspacing="3pt" columnspacing="0em 2em 0em 2em 0em 2em 0em 2em 0em 2em 0em" displaystyle="true"><mml:mtr><mml:mtd/><mml:mtd><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mo stretchy="false">(</mml:mo><mml:msubsup><mml:mrow><mml:mover><mml:mi>w</mml:mi><mml:mo stretchy="false">→</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mspace width="thinmathspace"/><mml:mi>E</mml:mi></mml:mrow></mml:msubsup><mml:msup><mml:mo stretchy="false">)</mml:mo><mml:mrow><mml:mi mathvariant="normal">⊤</mml:mi></mml:mrow></mml:msup><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mrow><mml:mover><mml:mi>x</mml:mi><mml:mo stretchy="false">→</mml:mo></mml:mover></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>−</mml:mo><mml:msup><mml:mrow><mml:mover><mml:mrow><mml:mover><mml:mi>x</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mo stretchy="false">→</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mspace width="thinmathspace"/><mml:mi>E</mml:mi></mml:mrow></mml:msup><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>−</mml:mo><mml:msup><mml:mi>β</mml:mi><mml:mrow><mml:mspace width="thinmathspace"/><mml:mi>E</mml:mi></mml:mrow></mml:msup><mml:msubsup><mml:mi>r</mml:mi><mml:mi>i</mml:mi><mml:mrow><mml:mspace width="thinmathspace"/><mml:mi>E</mml:mi></mml:mrow></mml:msubsup><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>≥</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mn>2</mml:mn></mml:mfrac><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msup><mml:mrow><mml:mo symmetric="true">‖</mml:mo><mml:msubsup><mml:mrow><mml:mover><mml:mi>w</mml:mi><mml:mo stretchy="false">→</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mspace width="thinmathspace"/><mml:mi>E</mml:mi></mml:mrow></mml:msubsup><mml:mo symmetric="true">‖</mml:mo></mml:mrow><mml:mn>2</mml:mn></mml:msup><mml:mo>+</mml:mo><mml:msup><mml:mi>β</mml:mi><mml:mrow><mml:mspace width="thinmathspace"/><mml:mi>E</mml:mi></mml:mrow></mml:msup><mml:mo>−</mml:mo><mml:msubsup><mml:mi>ξ</mml:mi><mml:mi>i</mml:mi><mml:mrow><mml:mspace width="thinmathspace"/><mml:mi>E</mml:mi></mml:mrow></mml:msubsup><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>,</mml:mo></mml:mstyle></mml:mtd></mml:mtr><mml:mtr><mml:mtd/><mml:mtd><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mo stretchy="false">(</mml:mo><mml:msubsup><mml:mrow><mml:mover><mml:mi>w</mml:mi><mml:mo stretchy="false">→</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mspace width="thinmathspace"/><mml:mi>I</mml:mi></mml:mrow></mml:msubsup><mml:msup><mml:mo stretchy="false">)</mml:mo><mml:mrow><mml:mi mathvariant="normal">⊤</mml:mi></mml:mrow></mml:msup><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msup><mml:mrow><mml:mover><mml:mrow><mml:mover><mml:mi>x</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mo stretchy="false">→</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mspace width="thinmathspace"/><mml:mi>E</mml:mi></mml:mrow></mml:msup><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>−</mml:mo><mml:msup><mml:mrow><mml:mover><mml:mrow><mml:mover><mml:mi>x</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mo stretchy="false">→</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mspace width="thinmathspace"/><mml:mi>I</mml:mi></mml:mrow></mml:msup><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>−</mml:mo><mml:msup><mml:mi>β</mml:mi><mml:mrow><mml:mspace width="thinmathspace"/><mml:mi>I</mml:mi></mml:mrow></mml:msup><mml:msubsup><mml:mi>r</mml:mi><mml:mi>i</mml:mi><mml:mrow><mml:mspace width="thinmathspace"/><mml:mi>I</mml:mi></mml:mrow></mml:msubsup><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>≥</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mn>2</mml:mn></mml:mfrac><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msup><mml:mrow><mml:mo symmetric="true">‖</mml:mo><mml:msubsup><mml:mrow><mml:mover><mml:mi>w</mml:mi><mml:mo stretchy="false">→</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mspace width="thinmathspace"/><mml:mi>I</mml:mi></mml:mrow></mml:msubsup><mml:mo symmetric="true">‖</mml:mo></mml:mrow><mml:mn>2</mml:mn></mml:msup><mml:mo>+</mml:mo><mml:msup><mml:mi>β</mml:mi><mml:mrow><mml:mspace width="thinmathspace"/><mml:mi>I</mml:mi></mml:mrow></mml:msup><mml:mo>−</mml:mo><mml:msubsup><mml:mi>ξ</mml:mi><mml:mi>i</mml:mi><mml:mrow><mml:mspace width="thinmathspace"/><mml:mi>I</mml:mi></mml:mrow></mml:msubsup><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>.</mml:mo></mml:mstyle></mml:mtd></mml:mtr></mml:mtable></mml:mstyle></mml:mrow></mml:math></disp-formula></p><p>We now define new variables <inline-formula><mml:math id="inf291"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msubsup><mml:mi>u</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>i</mml:mi></mml:mrow><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>y</mml:mi></mml:mrow></mml:msubsup><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mstyle></mml:math></inline-formula> and <inline-formula><mml:math id="inf292"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msubsup><mml:mi>θ</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mspace width="thinmathspace"/><mml:mi>y</mml:mi></mml:mrow></mml:msubsup></mml:mstyle></mml:mrow></mml:mstyle></mml:math></inline-formula> as proportional to the left- and the right-hand side of these expressions,<disp-formula id="equ19"><label>(17)</label><mml:math id="m19"><mml:mrow><mml:mtable columnalign="right left right left right left right left right left right left" rowspacing="3pt" columnspacing="0em 2em 0em 2em 0em 2em 0em 2em 0em 2em 0em" displaystyle="true"><mml:mtr><mml:mtd/><mml:mtd><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msubsup><mml:mi>u</mml:mi><mml:mi>i</mml:mi><mml:mrow><mml:mspace width="thinmathspace"/><mml:mi>E</mml:mi></mml:mrow></mml:msubsup><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>:=</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:msubsup><mml:mrow><mml:mover><mml:mi>w</mml:mi><mml:mo stretchy="false">→</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mi>E</mml:mi></mml:mrow></mml:msubsup><mml:msup><mml:mo stretchy="false">)</mml:mo><mml:mrow><mml:mi mathvariant="normal">⊤</mml:mi></mml:mrow></mml:msup><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mrow><mml:mover><mml:mi>x</mml:mi><mml:mo stretchy="false">→</mml:mo></mml:mover></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>−</mml:mo><mml:msup><mml:mrow><mml:mover><mml:mrow><mml:mover><mml:mi>x</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mo stretchy="false">→</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mspace width="thinmathspace"/><mml:mi>I</mml:mi></mml:mrow></mml:msup><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>−</mml:mo><mml:msup><mml:mi>β</mml:mi><mml:mrow><mml:mspace width="thinmathspace"/><mml:mi>E</mml:mi></mml:mrow></mml:msup><mml:msubsup><mml:mi>r</mml:mi><mml:mi>i</mml:mi><mml:mrow><mml:mspace width="thinmathspace"/><mml:mi>E</mml:mi></mml:mrow></mml:msubsup><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>,</mml:mo></mml:mstyle></mml:mtd></mml:mtr><mml:mtr><mml:mtd/><mml:mtd><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msubsup><mml:mi>u</mml:mi><mml:mi>i</mml:mi><mml:mrow><mml:mspace width="thinmathspace"/><mml:mi>I</mml:mi></mml:mrow></mml:msubsup><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>:=</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:msubsup><mml:mrow><mml:mover><mml:mi>w</mml:mi><mml:mo stretchy="false">→</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mi>E</mml:mi></mml:mrow></mml:msubsup><mml:msup><mml:mo stretchy="false">)</mml:mo><mml:mrow><mml:mi mathvariant="normal">⊤</mml:mi></mml:mrow></mml:msup><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msup><mml:mrow><mml:mover><mml:mrow><mml:mover><mml:mi>x</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mo stretchy="false">→</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mspace width="thinmathspace"/><mml:mi>E</mml:mi></mml:mrow></mml:msup><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>−</mml:mo><mml:msup><mml:mrow><mml:mover><mml:mrow><mml:mover><mml:mi>x</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mo stretchy="false">→</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mspace width="thinmathspace"/><mml:mi>I</mml:mi></mml:mrow></mml:msup><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>−</mml:mo><mml:msup><mml:mi>β</mml:mi><mml:mrow><mml:mspace width="thinmathspace"/><mml:mi>I</mml:mi></mml:mrow></mml:msup><mml:msubsup><mml:mi>r</mml:mi><mml:mi>i</mml:mi><mml:mrow><mml:mspace width="thinmathspace"/><mml:mi>I</mml:mi></mml:mrow></mml:msubsup><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>,</mml:mo></mml:mstyle></mml:mtd></mml:mtr><mml:mtr><mml:mtd/><mml:mtd><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msubsup><mml:mi>θ</mml:mi><mml:mi>i</mml:mi><mml:mrow><mml:mspace width="thinmathspace"/><mml:mi>y</mml:mi></mml:mrow></mml:msubsup><mml:mo>:=</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mn>2</mml:mn></mml:mfrac><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msup><mml:mrow><mml:mo symmetric="true">‖</mml:mo><mml:mrow><mml:mover><mml:msubsup><mml:mi>w</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mspace width="thinmathspace"/><mml:mi>y</mml:mi></mml:mrow></mml:msubsup><mml:mo stretchy="false">→</mml:mo></mml:mover></mml:mrow><mml:mo symmetric="true">‖</mml:mo></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup><mml:mo>+</mml:mo><mml:msup><mml:mi>β</mml:mi><mml:mrow><mml:mspace width="thinmathspace"/><mml:mi>y</mml:mi></mml:mrow></mml:msup></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>−</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mn>2</mml:mn></mml:mfrac><mml:msubsup><mml:mi>ξ</mml:mi><mml:mi>i</mml:mi><mml:mrow><mml:mspace width="thinmathspace"/><mml:mi>y</mml:mi></mml:mrow></mml:msubsup><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>,</mml:mo><mml:mspace width="1em"/><mml:mi>y</mml:mi><mml:mo>∈</mml:mo><mml:mo fence="false" stretchy="false">{</mml:mo><mml:mi>E</mml:mi><mml:mo>,</mml:mo><mml:mi>I</mml:mi><mml:mo fence="false" stretchy="false">}</mml:mo><mml:mo>.</mml:mo></mml:mstyle></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:math></disp-formula></p><p>The variables <inline-formula><mml:math id="inf293"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msubsup><mml:mi>u</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>i</mml:mi></mml:mrow><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>y</mml:mi></mml:mrow></mml:msubsup><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mstyle></mml:math></inline-formula> and <inline-formula><mml:math id="inf294"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msubsup><mml:mi>θ</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>i</mml:mi></mml:mrow><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>y</mml:mi></mml:mrow></mml:msubsup></mml:mstyle></mml:math></inline-formula> are interpreted as the membrane potential and the firing threshold of neuron <inline-formula><mml:math id="inf295"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>i</mml:mi></mml:mstyle></mml:math></inline-formula> of cell type <inline-formula><mml:math id="inf296"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>y</mml:mi><mml:mo>∈</mml:mo><mml:mo fence="false" stretchy="false">{</mml:mo><mml:mi>E</mml:mi><mml:mo>,</mml:mo><mml:mi>I</mml:mi><mml:mo fence="false" stretchy="false">}</mml:mo></mml:mstyle></mml:math></inline-formula>.</p></sec><sec id="s4-5"><title>Dynamic equations for the membrane potentials</title><p>In this section, we develop the exact dynamic equations of the membrane potentials <inline-formula><mml:math id="inf297"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msubsup><mml:mrow class="MJX-TeXAtom-ORD"><mml:mover><mml:mi>u</mml:mi><mml:mo>˙</mml:mo></mml:mover></mml:mrow><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>i</mml:mi></mml:mrow><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>y</mml:mi></mml:mrow></mml:msubsup><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mstyle></mml:math></inline-formula> for <inline-formula><mml:math id="inf298"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>y</mml:mi><mml:mo>∈</mml:mo><mml:mo fence="false" stretchy="false">{</mml:mo><mml:mi>E</mml:mi><mml:mo>,</mml:mo><mml:mi>I</mml:mi><mml:mo fence="false" stretchy="false">}</mml:mo></mml:mstyle></mml:math></inline-formula> according to the efficient coding assumption. We rewrite <xref ref-type="disp-formula" rid="equ9">Equation 9</xref> in vector notation as<disp-formula id="equ20"><label>(18)</label><mml:math id="m20"><mml:mrow><mml:mtable columnalign="right left right left right left right left right left right left" rowspacing="3pt" columnspacing="0em 2em 0em 2em 0em 2em 0em 2em 0em 2em 0em" displaystyle="true"><mml:mtr><mml:mtd><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msup><mml:mrow><mml:mover><mml:mrow><mml:mover><mml:mrow><mml:mover><mml:mi>x</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mo>˙</mml:mo></mml:mover></mml:mrow><mml:mo stretchy="false">→</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mspace width="thinmathspace"/><mml:mi>E</mml:mi></mml:mrow></mml:msup><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mstyle></mml:mtd><mml:mtd><mml:mi/><mml:mo>=</mml:mo><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mo>−</mml:mo><mml:mi>λ</mml:mi><mml:msup><mml:mrow><mml:mover><mml:mrow><mml:mover><mml:mi>x</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mo stretchy="false">→</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mspace width="thinmathspace"/><mml:mi>E</mml:mi></mml:mrow></mml:msup><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>+</mml:mo><mml:msup><mml:mi>W</mml:mi><mml:mrow><mml:mspace width="thinmathspace"/><mml:mi>E</mml:mi></mml:mrow></mml:msup><mml:mspace width="thinmathspace"/><mml:msup><mml:mrow><mml:mover><mml:mi>f</mml:mi><mml:mo stretchy="false">→</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mspace width="thinmathspace"/><mml:mi>E</mml:mi></mml:mrow></mml:msup><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>,</mml:mo></mml:mstyle></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:msup><mml:mrow><mml:mover><mml:mrow><mml:mover><mml:mrow><mml:mover><mml:mi>x</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mo>˙</mml:mo></mml:mover></mml:mrow><mml:mo stretchy="false">→</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mspace width="thinmathspace"/><mml:mi>I</mml:mi></mml:mrow></mml:msup><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mtd><mml:mtd><mml:mi/><mml:mo>=</mml:mo><mml:mo>−</mml:mo><mml:mi>λ</mml:mi><mml:msup><mml:mrow><mml:mover><mml:mrow><mml:mover><mml:mi>x</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mo stretchy="false">→</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mspace width="thinmathspace"/><mml:mi>I</mml:mi></mml:mrow></mml:msup><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>+</mml:mo><mml:msup><mml:mi>W</mml:mi><mml:mrow><mml:mspace width="thinmathspace"/><mml:mi>I</mml:mi></mml:mrow></mml:msup><mml:mspace width="thinmathspace"/><mml:msup><mml:mrow><mml:mover><mml:mi>f</mml:mi><mml:mo stretchy="false">→</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mspace width="thinmathspace"/><mml:mi>I</mml:mi></mml:mrow></mml:msup><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>,</mml:mo></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:math></disp-formula></p><p>with <inline-formula><mml:math id="inf299"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msup><mml:mrow><mml:mover><mml:mi>f</mml:mi><mml:mo stretchy="false">→</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mspace width="thinmathspace"/><mml:mi>y</mml:mi></mml:mrow></mml:msup><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>:=</mml:mo><mml:mo stretchy="false">[</mml:mo><mml:msubsup><mml:mi>f</mml:mi><mml:mrow><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mspace width="thinmathspace"/><mml:mi>y</mml:mi></mml:mrow></mml:msubsup><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>,</mml:mo><mml:mo>…</mml:mo><mml:mo>,</mml:mo><mml:msubsup><mml:mi>f</mml:mi><mml:mrow><mml:msup><mml:mi>N</mml:mi><mml:mrow><mml:mspace width="thinmathspace"/><mml:mi>y</mml:mi></mml:mrow></mml:msup></mml:mrow><mml:mrow><mml:mspace width="thinmathspace"/><mml:mi>y</mml:mi></mml:mrow></mml:msubsup><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:msup><mml:mo stretchy="false">]</mml:mo><mml:mrow><mml:mi mathvariant="normal">⊤</mml:mi></mml:mrow></mml:msup></mml:mrow></mml:mstyle></mml:math></inline-formula> the vector of spike trains for <inline-formula><mml:math id="inf300"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msup><mml:mi>N</mml:mi><mml:mrow><mml:mspace width="thinmathspace"/><mml:mi>y</mml:mi></mml:mrow></mml:msup></mml:mstyle></mml:mrow></mml:mstyle></mml:math></inline-formula> neurons of cell type <inline-formula><mml:math id="inf301"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>y</mml:mi><mml:mo>∈</mml:mo><mml:mo fence="false" stretchy="false">{</mml:mo><mml:mi>E</mml:mi><mml:mo>,</mml:mo><mml:mi>I</mml:mi><mml:mo fence="false" stretchy="false">}</mml:mo></mml:mstyle></mml:math></inline-formula>.</p><p>In the case of E neurons, the time-derivative of the membrane potential <inline-formula><mml:math id="inf302"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msubsup><mml:mrow><mml:mover><mml:mi>u</mml:mi><mml:mo>˙</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mspace width="thinmathspace"/><mml:mi>E</mml:mi></mml:mrow></mml:msubsup><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mstyle></mml:mrow></mml:mstyle></mml:math></inline-formula> in <xref ref-type="disp-formula" rid="equ19">Equation 17</xref>, is obtained as<disp-formula id="equ21"><label>(19)</label><mml:math id="m21"><mml:mrow><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msubsup><mml:mrow><mml:mover><mml:mi>u</mml:mi><mml:mo>˙</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mspace width="thinmathspace"/><mml:mi>E</mml:mi></mml:mrow></mml:msubsup><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:msubsup><mml:mrow><mml:mover><mml:mi>w</mml:mi><mml:mo stretchy="false">→</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mspace width="thinmathspace"/><mml:mi>E</mml:mi></mml:mrow></mml:msubsup><mml:msup><mml:mo stretchy="false">)</mml:mo><mml:mrow><mml:mi mathvariant="normal">⊤</mml:mi></mml:mrow></mml:msup><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mrow><mml:mover><mml:mrow><mml:mover><mml:mi>x</mml:mi><mml:mo>˙</mml:mo></mml:mover></mml:mrow><mml:mo stretchy="false">→</mml:mo></mml:mover></mml:mrow><mml:mo>−</mml:mo><mml:msup><mml:mrow><mml:mover><mml:mrow><mml:mover><mml:mrow><mml:mover><mml:mi>x</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mo>˙</mml:mo></mml:mover></mml:mrow><mml:mo stretchy="false">→</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mspace width="thinmathspace"/><mml:mi>I</mml:mi></mml:mrow></mml:msup><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>−</mml:mo><mml:msup><mml:mi>β</mml:mi><mml:mrow><mml:mspace width="thinmathspace"/><mml:mi>E</mml:mi></mml:mrow></mml:msup><mml:msubsup><mml:mrow><mml:mover><mml:mi>r</mml:mi><mml:mo>˙</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mspace width="thinmathspace"/><mml:mi>E</mml:mi></mml:mrow></mml:msubsup><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>.</mml:mo></mml:mstyle></mml:mrow></mml:math></disp-formula></p><p>By inserting the dynamic equations of the target signal <inline-formula><mml:math id="inf303"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow class="MJX-TeXAtom-ORD"><mml:mover><mml:mrow class="MJX-TeXAtom-ORD"><mml:mover><mml:mi>x</mml:mi><mml:mo>˙</mml:mo></mml:mover></mml:mrow><mml:mo stretchy="false">→</mml:mo></mml:mover></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mstyle></mml:math></inline-formula>, its estimate <inline-formula><mml:math id="inf304"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msup><mml:mrow><mml:mover><mml:mrow><mml:mover><mml:mrow><mml:mover><mml:mi>x</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mo>˙</mml:mo></mml:mover></mml:mrow><mml:mo stretchy="false">→</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mspace width="thinmathspace"/><mml:mi>I</mml:mi></mml:mrow></mml:msup><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mstyle></mml:math></inline-formula> (<xref ref-type="disp-formula" rid="equ20">Equation 18</xref>) and of the single neuron readout <inline-formula><mml:math id="inf305"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msubsup><mml:mrow class="MJX-TeXAtom-ORD"><mml:mover><mml:mi>r</mml:mi><mml:mo>˙</mml:mo></mml:mover></mml:mrow><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>i</mml:mi></mml:mrow><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>E</mml:mi></mml:mrow></mml:msubsup><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mstyle></mml:math></inline-formula> (<xref ref-type="disp-formula" rid="equ7">Equation 7</xref> in the case <inline-formula><mml:math id="inf306"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>y</mml:mi><mml:mo>=</mml:mo><mml:mi>E</mml:mi></mml:mstyle></mml:math></inline-formula>), we get<disp-formula id="equ22"><label>(20)</label><mml:math id="m22"><mml:mrow><mml:mtable columnalign="right left right left right left right left right left right left" rowspacing="3pt" columnspacing="0em 2em 0em 2em 0em 2em 0em 2em 0em 2em 0em" displaystyle="true"><mml:mtr><mml:mtd><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msubsup><mml:mrow><mml:mover><mml:mi>u</mml:mi><mml:mo>˙</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mi>E</mml:mi></mml:mrow></mml:msubsup><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo></mml:mstyle></mml:mtd><mml:mtd><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mo stretchy="false">(</mml:mo><mml:msubsup><mml:mrow><mml:mover><mml:mi>w</mml:mi><mml:mo stretchy="false">→</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mi>E</mml:mi></mml:mrow></mml:msubsup><mml:msup><mml:mo stretchy="false">)</mml:mo><mml:mrow><mml:mi mathvariant="normal">⊤</mml:mi></mml:mrow></mml:msup><mml:mrow><mml:mo>[</mml:mo><mml:mrow><mml:mo>−</mml:mo><mml:mi>λ</mml:mi><mml:mrow><mml:mover><mml:mi>x</mml:mi><mml:mo stretchy="false">→</mml:mo></mml:mover></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>+</mml:mo><mml:mrow><mml:mover><mml:mi>s</mml:mi><mml:mo stretchy="false">→</mml:mo></mml:mover></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>+</mml:mo><mml:mi>λ</mml:mi><mml:msup><mml:mrow><mml:mover><mml:mrow><mml:mover><mml:mi>x</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mo stretchy="false">→</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>I</mml:mi></mml:mrow></mml:msup><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>−</mml:mo><mml:msup><mml:mi>W</mml:mi><mml:mrow><mml:mspace width="thinmathspace"/><mml:mi>I</mml:mi></mml:mrow></mml:msup><mml:msup><mml:mrow><mml:mover><mml:mi>f</mml:mi><mml:mo stretchy="false">→</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mspace width="thinmathspace"/><mml:mi>I</mml:mi></mml:mrow></mml:msup></mml:mrow><mml:mo>]</mml:mo></mml:mrow><mml:mo>−</mml:mo><mml:msup><mml:mi>β</mml:mi><mml:mi>E</mml:mi></mml:msup><mml:mrow><mml:mo>[</mml:mo><mml:mrow><mml:mo>−</mml:mo><mml:msubsup><mml:mi>λ</mml:mi><mml:mi>r</mml:mi><mml:mrow><mml:mspace width="thinmathspace"/><mml:mi>E</mml:mi></mml:mrow></mml:msubsup><mml:msubsup><mml:mi>r</mml:mi><mml:mi>i</mml:mi><mml:mrow><mml:mspace width="thinmathspace"/><mml:mi>E</mml:mi></mml:mrow></mml:msubsup><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>+</mml:mo><mml:msubsup><mml:mi>f</mml:mi><mml:mi>i</mml:mi><mml:mrow><mml:mspace width="thinmathspace"/><mml:mi>E</mml:mi></mml:mrow></mml:msubsup><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>]</mml:mo></mml:mrow><mml:mo>,</mml:mo></mml:mstyle></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mo>=</mml:mo></mml:mtd><mml:mtd><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mo>−</mml:mo><mml:mi>λ</mml:mi><mml:mrow><mml:mo>[</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msubsup><mml:mrow><mml:mover><mml:mi>w</mml:mi><mml:mo stretchy="false">→</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mi>E</mml:mi></mml:mrow></mml:msubsup><mml:msup><mml:mo stretchy="false">)</mml:mo><mml:mrow><mml:mi mathvariant="normal">⊤</mml:mi></mml:mrow></mml:msup><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mrow><mml:mover><mml:mi>x</mml:mi><mml:mo stretchy="false">→</mml:mo></mml:mover></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>−</mml:mo><mml:msup><mml:mrow><mml:mover><mml:mrow><mml:mover><mml:mi>x</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mo stretchy="false">→</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>I</mml:mi></mml:mrow></mml:msup><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>−</mml:mo><mml:msup><mml:mi>β</mml:mi><mml:mrow><mml:mspace width="thinmathspace"/><mml:mi>E</mml:mi></mml:mrow></mml:msup><mml:msubsup><mml:mi>r</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mspace width="thinmathspace"/><mml:mi>E</mml:mi></mml:mrow></mml:msubsup><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>]</mml:mo></mml:mrow><mml:mo>+</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:msubsup><mml:mrow><mml:mover><mml:mi>w</mml:mi><mml:mo stretchy="false">→</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mi>E</mml:mi></mml:mrow></mml:msubsup><mml:msup><mml:mo stretchy="false">)</mml:mo><mml:mrow><mml:mi mathvariant="normal">⊤</mml:mi></mml:mrow></mml:msup><mml:mrow><mml:mover><mml:mi>s</mml:mi><mml:mo stretchy="false">→</mml:mo></mml:mover></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>−</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:msubsup><mml:mrow><mml:mover><mml:mi>w</mml:mi><mml:mo stretchy="false">→</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mi>E</mml:mi></mml:mrow></mml:msubsup><mml:msup><mml:mo stretchy="false">)</mml:mo><mml:mrow><mml:mi mathvariant="normal">⊤</mml:mi></mml:mrow></mml:msup><mml:msup><mml:mi>W</mml:mi><mml:mi>I</mml:mi></mml:msup><mml:mspace width="thinmathspace"/><mml:msup><mml:mrow><mml:mover><mml:mi>f</mml:mi><mml:mo stretchy="false">→</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mspace width="thinmathspace"/><mml:mi>I</mml:mi></mml:mrow></mml:msup></mml:mstyle></mml:mtd></mml:mtr><mml:mtr><mml:mtd/><mml:mtd><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mo>−</mml:mo><mml:msup><mml:mi>β</mml:mi><mml:mi>E</mml:mi></mml:msup><mml:mo stretchy="false">(</mml:mo><mml:mi>λ</mml:mi><mml:mo>−</mml:mo><mml:msubsup><mml:mi>λ</mml:mi><mml:mi>r</mml:mi><mml:mrow><mml:mspace width="thinmathspace"/><mml:mi>E</mml:mi></mml:mrow></mml:msubsup><mml:mo stretchy="false">)</mml:mo><mml:msubsup><mml:mi>r</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mspace width="thinmathspace"/><mml:mi>E</mml:mi></mml:mrow></mml:msubsup><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>−</mml:mo><mml:msup><mml:mi>β</mml:mi><mml:mrow><mml:mspace width="thinmathspace"/><mml:mi>E</mml:mi></mml:mrow></mml:msup><mml:msubsup><mml:mi>f</mml:mi><mml:mi>i</mml:mi><mml:mrow><mml:mspace width="thinmathspace"/><mml:mi>E</mml:mi></mml:mrow></mml:msubsup><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>,</mml:mo></mml:mstyle></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mo>=</mml:mo></mml:mtd><mml:mtd><mml:mi/><mml:mo>−</mml:mo><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>λ</mml:mi><mml:msubsup><mml:mi>u</mml:mi><mml:mi>i</mml:mi><mml:mi>E</mml:mi></mml:msubsup><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>+</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:msubsup><mml:mrow><mml:mover><mml:mi>w</mml:mi><mml:mo stretchy="false">→</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mi>E</mml:mi></mml:mrow></mml:msubsup><mml:msup><mml:mo stretchy="false">)</mml:mo><mml:mrow><mml:mi mathvariant="normal">⊤</mml:mi></mml:mrow></mml:msup><mml:mrow><mml:mover><mml:mi>s</mml:mi><mml:mo stretchy="false">→</mml:mo></mml:mover></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>−</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:msubsup><mml:mrow><mml:mover><mml:mi>w</mml:mi><mml:mo stretchy="false">→</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mspace width="thinmathspace"/><mml:mi>E</mml:mi></mml:mrow></mml:msubsup><mml:msup><mml:mo stretchy="false">)</mml:mo><mml:mrow><mml:mi mathvariant="normal">⊤</mml:mi></mml:mrow></mml:msup><mml:msup><mml:mi>W</mml:mi><mml:mrow><mml:mspace width="thinmathspace"/><mml:mi>I</mml:mi></mml:mrow></mml:msup><mml:msup><mml:mrow><mml:mover><mml:mi>f</mml:mi><mml:mo stretchy="false">→</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mspace width="thinmathspace"/><mml:mi>I</mml:mi></mml:mrow></mml:msup><mml:mo>−</mml:mo><mml:msup><mml:mi>β</mml:mi><mml:mi>E</mml:mi></mml:msup><mml:mo stretchy="false">(</mml:mo><mml:mi>λ</mml:mi><mml:mo>−</mml:mo><mml:msubsup><mml:mi>λ</mml:mi><mml:mi>r</mml:mi><mml:mi>E</mml:mi></mml:msubsup><mml:mo stretchy="false">)</mml:mo><mml:msubsup><mml:mi>r</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mi>E</mml:mi></mml:msubsup><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>−</mml:mo><mml:msup><mml:mi>β</mml:mi><mml:mi>E</mml:mi></mml:msup><mml:msubsup><mml:mi>f</mml:mi><mml:mi>i</mml:mi><mml:mrow><mml:mspace width="thinmathspace"/><mml:mi>E</mml:mi></mml:mrow></mml:msubsup><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>,</mml:mo></mml:mstyle></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:math></disp-formula></p><p>where in the last line we used the definition of <inline-formula><mml:math id="inf307"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msubsup><mml:mi>u</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>i</mml:mi></mml:mrow><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>E</mml:mi></mml:mrow></mml:msubsup><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mstyle></mml:math></inline-formula> from the <xref ref-type="disp-formula" rid="equ19">Equation 17</xref>.</p><p>In the case of I neurons, the time derivative of the membrane potential <inline-formula><mml:math id="inf308"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msubsup><mml:mrow class="MJX-TeXAtom-ORD"><mml:mover><mml:mi>u</mml:mi><mml:mo>˙</mml:mo></mml:mover></mml:mrow><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>i</mml:mi></mml:mrow><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>I</mml:mi></mml:mrow></mml:msubsup><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mstyle></mml:math></inline-formula> in <xref ref-type="disp-formula" rid="equ19">Equation 17</xref> is<disp-formula id="equ23"><label>(21)</label><mml:math id="m23"><mml:mrow><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msubsup><mml:mrow><mml:mover><mml:mi>u</mml:mi><mml:mo>˙</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mi>E</mml:mi></mml:mrow></mml:msubsup><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:msubsup><mml:mrow><mml:mover><mml:mi>w</mml:mi><mml:mo stretchy="false">→</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mspace width="thinmathspace"/><mml:mi>E</mml:mi></mml:mrow></mml:msubsup><mml:msup><mml:mo stretchy="false">)</mml:mo><mml:mrow><mml:mi mathvariant="normal">⊤</mml:mi></mml:mrow></mml:msup><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msup><mml:mrow><mml:mover><mml:mrow><mml:mover><mml:mrow><mml:mover><mml:mi>x</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mo>˙</mml:mo></mml:mover></mml:mrow><mml:mo stretchy="false">→</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>E</mml:mi></mml:mrow></mml:msup><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>−</mml:mo><mml:msup><mml:mrow><mml:mover><mml:mrow><mml:mover><mml:mrow><mml:mover><mml:mi>x</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mo>˙</mml:mo></mml:mover></mml:mrow><mml:mo stretchy="false">→</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>I</mml:mi></mml:mrow></mml:msup><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>−</mml:mo><mml:msup><mml:mi>β</mml:mi><mml:mrow><mml:mspace width="thinmathspace"/><mml:mi>I</mml:mi></mml:mrow></mml:msup><mml:msubsup><mml:mrow><mml:mover><mml:mi>r</mml:mi><mml:mo>˙</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mspace width="thinmathspace"/><mml:mi>I</mml:mi></mml:mrow></mml:msubsup><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>.</mml:mo></mml:mstyle></mml:mrow></mml:math></disp-formula></p><p>By inserting the dynamic equations of the population readouts of E neurons <inline-formula><mml:math id="inf309"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msup><mml:mrow class="MJX-TeXAtom-ORD"><mml:mover><mml:mrow class="MJX-TeXAtom-ORD"><mml:mover><mml:mrow class="MJX-TeXAtom-ORD"><mml:mover><mml:mi>x</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mo>˙</mml:mo></mml:mover></mml:mrow><mml:mo stretchy="false">→</mml:mo></mml:mover></mml:mrow><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>E</mml:mi></mml:mrow></mml:msup><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mstyle></mml:math></inline-formula> and of the I neurons <inline-formula><mml:math id="inf310"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msup><mml:mrow class="MJX-TeXAtom-ORD"><mml:mover><mml:mrow class="MJX-TeXAtom-ORD"><mml:mover><mml:mrow class="MJX-TeXAtom-ORD"><mml:mover><mml:mi>x</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mo>˙</mml:mo></mml:mover></mml:mrow><mml:mo stretchy="false">→</mml:mo></mml:mover></mml:mrow><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>I</mml:mi></mml:mrow></mml:msup><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mstyle></mml:math></inline-formula> (<xref ref-type="disp-formula" rid="equ20">Equation 18</xref>) and of the single neuron readout <inline-formula><mml:math id="inf311"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msubsup><mml:mrow class="MJX-TeXAtom-ORD"><mml:mover><mml:mi>r</mml:mi><mml:mo>˙</mml:mo></mml:mover></mml:mrow><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>i</mml:mi></mml:mrow><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>I</mml:mi></mml:mrow></mml:msubsup><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mstyle></mml:math></inline-formula> (<xref ref-type="disp-formula" rid="equ7">Equation 7</xref> in the case <inline-formula><mml:math id="inf312"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>y</mml:mi><mml:mo>=</mml:mo><mml:mi>I</mml:mi></mml:mstyle></mml:math></inline-formula>), we get<disp-formula id="equ24"><label>(22)</label><mml:math id="m24"><mml:mrow><mml:mtable columnalign="right left right left right left right left right left right left" rowspacing="3pt" columnspacing="0em 2em 0em 2em 0em 2em 0em 2em 0em 2em 0em" displaystyle="true"><mml:mtr><mml:mtd><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msubsup><mml:mrow><mml:mover><mml:mi>u</mml:mi><mml:mo>˙</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mspace width="thinmathspace"/><mml:mi>I</mml:mi></mml:mrow></mml:msubsup><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo></mml:mstyle></mml:mtd><mml:mtd><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mo stretchy="false">(</mml:mo><mml:msubsup><mml:mrow><mml:mover><mml:mi>w</mml:mi><mml:mo stretchy="false">→</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mspace width="thinmathspace"/><mml:mi>I</mml:mi></mml:mrow></mml:msubsup><mml:msup><mml:mo stretchy="false">)</mml:mo><mml:mrow><mml:mi mathvariant="normal">⊤</mml:mi></mml:mrow></mml:msup><mml:mrow><mml:mo>[</mml:mo><mml:mrow><mml:mo>−</mml:mo><mml:mi>λ</mml:mi><mml:msup><mml:mrow><mml:mover><mml:mrow><mml:mover><mml:mi>x</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mo stretchy="false">→</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mspace width="thinmathspace"/><mml:mi>E</mml:mi></mml:mrow></mml:msup><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>+</mml:mo><mml:msup><mml:mi>W</mml:mi><mml:mrow><mml:mspace width="thinmathspace"/><mml:mi>E</mml:mi></mml:mrow></mml:msup><mml:msup><mml:mrow><mml:mover><mml:mi>f</mml:mi><mml:mo stretchy="false">→</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mspace width="thinmathspace"/><mml:mi>E</mml:mi></mml:mrow></mml:msup><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>+</mml:mo><mml:mi>λ</mml:mi><mml:msup><mml:mrow><mml:mover><mml:mrow><mml:mover><mml:mi>x</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mo stretchy="false">→</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>I</mml:mi></mml:mrow></mml:msup><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>−</mml:mo><mml:msup><mml:mi>W</mml:mi><mml:mrow><mml:mi>I</mml:mi></mml:mrow></mml:msup><mml:msup><mml:mrow><mml:mover><mml:mi>f</mml:mi><mml:mo stretchy="false">→</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mspace width="thinmathspace"/><mml:mi>I</mml:mi></mml:mrow></mml:msup><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>]</mml:mo></mml:mrow><mml:mo>−</mml:mo><mml:msup><mml:mi>β</mml:mi><mml:mi>I</mml:mi></mml:msup><mml:mrow><mml:mo>[</mml:mo><mml:mrow><mml:mo>−</mml:mo><mml:msubsup><mml:mi>λ</mml:mi><mml:mi>r</mml:mi><mml:mrow><mml:mspace width="thinmathspace"/><mml:mi>I</mml:mi></mml:mrow></mml:msubsup><mml:msubsup><mml:mi>r</mml:mi><mml:mi>i</mml:mi><mml:mrow><mml:mspace width="thinmathspace"/><mml:mi>I</mml:mi></mml:mrow></mml:msubsup><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>+</mml:mo><mml:msubsup><mml:mi>f</mml:mi><mml:mi>i</mml:mi><mml:mrow><mml:mspace width="thinmathspace"/><mml:mi>I</mml:mi></mml:mrow></mml:msubsup><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>]</mml:mo></mml:mrow><mml:mo>,</mml:mo></mml:mstyle></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mo>=</mml:mo></mml:mtd><mml:mtd><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mo>−</mml:mo><mml:mi>λ</mml:mi><mml:mrow><mml:mo>[</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msubsup><mml:mrow><mml:mover><mml:mi>w</mml:mi><mml:mo stretchy="false">→</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mspace width="thinmathspace"/><mml:mi>I</mml:mi></mml:mrow></mml:msubsup><mml:msup><mml:mo stretchy="false">)</mml:mo><mml:mrow><mml:mi mathvariant="normal">⊤</mml:mi></mml:mrow></mml:msup><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msup><mml:mrow><mml:mover><mml:mrow><mml:mover><mml:mi>x</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mo stretchy="false">→</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mspace width="thinmathspace"/><mml:mi>E</mml:mi></mml:mrow></mml:msup><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>−</mml:mo><mml:msup><mml:mrow><mml:mover><mml:mrow><mml:mover><mml:mi>x</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mo stretchy="false">→</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mspace width="thinmathspace"/><mml:mi>I</mml:mi></mml:mrow></mml:msup><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>−</mml:mo><mml:msup><mml:mi>β</mml:mi><mml:mrow><mml:mspace width="thinmathspace"/><mml:mi>I</mml:mi></mml:mrow></mml:msup><mml:msubsup><mml:mi>r</mml:mi><mml:mi>i</mml:mi><mml:mrow><mml:mspace width="thinmathspace"/><mml:mi>I</mml:mi></mml:mrow></mml:msubsup><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>]</mml:mo></mml:mrow><mml:mo>+</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:msubsup><mml:mrow><mml:mover><mml:mrow><mml:mi mathvariant="script">w</mml:mi></mml:mrow><mml:mo stretchy="false">→</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mspace width="thinmathspace"/><mml:mi>I</mml:mi></mml:mrow></mml:msubsup><mml:msup><mml:mo stretchy="false">)</mml:mo><mml:mrow><mml:mi mathvariant="normal">⊤</mml:mi></mml:mrow></mml:msup><mml:msup><mml:mi>W</mml:mi><mml:mrow><mml:mspace width="thinmathspace"/><mml:mi>E</mml:mi></mml:mrow></mml:msup><mml:msup><mml:mrow><mml:mover><mml:mi>f</mml:mi><mml:mo stretchy="false">→</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mspace width="thinmathspace"/><mml:mi>E</mml:mi></mml:mrow></mml:msup><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>−</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:msubsup><mml:mrow><mml:mover><mml:mrow><mml:mi mathvariant="script">w</mml:mi></mml:mrow><mml:mo stretchy="false">→</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mspace width="thinmathspace"/><mml:mi>I</mml:mi></mml:mrow></mml:msubsup><mml:msup><mml:mo stretchy="false">)</mml:mo><mml:mrow><mml:mi mathvariant="normal">⊤</mml:mi></mml:mrow></mml:msup><mml:msup><mml:mi>W</mml:mi><mml:mrow><mml:mspace width="thinmathspace"/><mml:mi>I</mml:mi></mml:mrow></mml:msup><mml:msup><mml:mrow><mml:mover><mml:mi>f</mml:mi><mml:mo stretchy="false">→</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mspace width="thinmathspace"/><mml:mi>I</mml:mi></mml:mrow></mml:msup><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mstyle></mml:mtd></mml:mtr><mml:mtr><mml:mtd/><mml:mtd><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mo>−</mml:mo><mml:msup><mml:mi>β</mml:mi><mml:mrow><mml:mspace width="thinmathspace"/><mml:mi>I</mml:mi></mml:mrow></mml:msup><mml:mo stretchy="false">(</mml:mo><mml:mi>λ</mml:mi><mml:mo>−</mml:mo><mml:msubsup><mml:mi>λ</mml:mi><mml:mi>r</mml:mi><mml:mrow><mml:mspace width="thinmathspace"/><mml:mi>I</mml:mi></mml:mrow></mml:msubsup><mml:mo stretchy="false">)</mml:mo><mml:msup><mml:mi>r</mml:mi><mml:mi>I</mml:mi></mml:msup><mml:msub><mml:mrow><mml:mspace width="thinmathspace"/><mml:mi>I</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>−</mml:mo><mml:msup><mml:mi>β</mml:mi><mml:mrow><mml:mspace width="thinmathspace"/><mml:mi>I</mml:mi></mml:mrow></mml:msup><mml:msubsup><mml:mi>f</mml:mi><mml:mi>i</mml:mi><mml:mrow><mml:mspace width="thinmathspace"/><mml:mi>E</mml:mi><mml:mi>I</mml:mi></mml:mrow></mml:msubsup><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>,</mml:mo></mml:mstyle></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mo>=</mml:mo></mml:mtd><mml:mtd><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mo>−</mml:mo><mml:mi>λ</mml:mi><mml:msubsup><mml:mi>u</mml:mi><mml:mi>i</mml:mi><mml:mrow><mml:mspace width="thinmathspace"/><mml:mi>I</mml:mi></mml:mrow></mml:msubsup><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>+</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:msubsup><mml:mrow><mml:mover><mml:mi>w</mml:mi><mml:mo stretchy="false">→</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mspace width="thinmathspace"/><mml:mi>I</mml:mi></mml:mrow></mml:msubsup><mml:msup><mml:mo stretchy="false">)</mml:mo><mml:mrow><mml:mi mathvariant="normal">⊤</mml:mi></mml:mrow></mml:msup><mml:msup><mml:mi>W</mml:mi><mml:mrow><mml:mspace width="thinmathspace"/><mml:mi>E</mml:mi></mml:mrow></mml:msup><mml:msup><mml:mrow><mml:mover><mml:mi>f</mml:mi><mml:mo stretchy="false">→</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mspace width="thinmathspace"/><mml:mi>E</mml:mi></mml:mrow></mml:msup><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>−</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:msubsup><mml:mrow><mml:mover><mml:mi>w</mml:mi><mml:mo stretchy="false">→</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mspace width="thinmathspace"/><mml:mi>I</mml:mi></mml:mrow></mml:msubsup><mml:msup><mml:mo stretchy="false">)</mml:mo><mml:mrow><mml:mi mathvariant="normal">⊤</mml:mi></mml:mrow></mml:msup><mml:msup><mml:mi>W</mml:mi><mml:mrow><mml:mspace width="thinmathspace"/><mml:mi>I</mml:mi></mml:mrow></mml:msup><mml:msup><mml:mrow><mml:mover><mml:mi>f</mml:mi><mml:mo stretchy="false">→</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mspace width="thinmathspace"/><mml:mi>I</mml:mi></mml:mrow></mml:msup><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>−</mml:mo><mml:msup><mml:mi>β</mml:mi><mml:mi>I</mml:mi></mml:msup><mml:mo stretchy="false">(</mml:mo><mml:mi>λ</mml:mi><mml:mo>−</mml:mo><mml:msubsup><mml:mi>λ</mml:mi><mml:mi>r</mml:mi><mml:mrow><mml:mspace width="thinmathspace"/><mml:mi>I</mml:mi></mml:mrow></mml:msubsup><mml:mo stretchy="false">)</mml:mo><mml:msubsup><mml:mi>r</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mspace width="thinmathspace"/><mml:mi>I</mml:mi></mml:mrow></mml:msubsup><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>−</mml:mo><mml:msup><mml:mi>β</mml:mi><mml:mrow><mml:mspace width="thinmathspace"/><mml:mi>I</mml:mi></mml:mrow></mml:msup><mml:msubsup><mml:mi>f</mml:mi><mml:mi>i</mml:mi><mml:mrow><mml:mspace width="thinmathspace"/><mml:mi>I</mml:mi></mml:mrow></mml:msubsup><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>.</mml:mo></mml:mstyle></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:math></disp-formula></p><p>where in the last line we used the definition of <inline-formula><mml:math id="inf313"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msubsup><mml:mi>u</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>i</mml:mi></mml:mrow><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>I</mml:mi></mml:mrow></mml:msubsup><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mstyle></mml:math></inline-formula> from <xref ref-type="disp-formula" rid="equ19">Equation 17</xref>.</p><sec id="s4-5-1"><title>Leaky integrate-and-fire neurons</title><p>The terms on the right-hand-side in <xref ref-type="disp-formula" rid="equ22">Equation 20</xref> and <xref ref-type="disp-formula" rid="equ24">Equation 22</xref> can be interpreted as transmembrane currents. The last term in these equations, <inline-formula><mml:math id="inf314"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mo>−</mml:mo><mml:msup><mml:mi>β</mml:mi><mml:mrow><mml:mspace width="thinmathspace"/><mml:mi>y</mml:mi></mml:mrow></mml:msup><mml:msubsup><mml:mi>f</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mspace width="thinmathspace"/><mml:mi>y</mml:mi></mml:mrow></mml:msubsup><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>,</mml:mo><mml:mi>y</mml:mi><mml:mo>∈</mml:mo><mml:mo fence="false" stretchy="false">{</mml:mo><mml:mi>E</mml:mi><mml:mo>,</mml:mo><mml:mi>I</mml:mi><mml:mo fence="false" stretchy="false">}</mml:mo></mml:mrow></mml:mstyle></mml:math></inline-formula>, can be interpreted as a current instantaneously resetting the membrane potential upon reaching the firing threshold (<xref ref-type="bibr" rid="bib11">Boerlin et al., 2013</xref>). Indeed, when the membrane potential reaches the threshold, it triggers a spike and causes a jump of the membrane potential by an amount <inline-formula><mml:math id="inf315"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mo>−</mml:mo><mml:msup><mml:mi>β</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>y</mml:mi></mml:mrow></mml:msup></mml:mstyle></mml:math></inline-formula>; this realizes resetting of the membrane potential which is equivalent to the resetting rule of integrate-and-fire neurons (<xref ref-type="bibr" rid="bib16">Burkitt, 2006</xref>; <xref ref-type="bibr" rid="bib40">Harkin et al., 2021</xref>). Thus, by taking into account the resetting mechanism and defining the time constants of population and single neuron readout <inline-formula><mml:math id="inf316"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>τ</mml:mi><mml:mo>:=</mml:mo><mml:msup><mml:mi>λ</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msup></mml:mstyle></mml:math></inline-formula> and <inline-formula><mml:math id="inf317"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow class="MJX-TeXAtom-ORD"><mml:msubsup><mml:mi>τ</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>r</mml:mi></mml:mrow><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>y</mml:mi></mml:mrow></mml:msubsup><mml:mo>:=</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:msubsup><mml:mi>λ</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>r</mml:mi></mml:mrow><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>y</mml:mi></mml:mrow></mml:msubsup><mml:msup><mml:mo stretchy="false">)</mml:mo><mml:mrow class="MJX-TeXAtom-ORD"><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:mstyle></mml:math></inline-formula>, we can rewrite <xref ref-type="disp-formula" rid="equ22">Equation 20</xref> and <xref ref-type="disp-formula" rid="equ24">Equation 22</xref> as a leaky integrate-and-fire neuron model,<disp-formula id="equ25"><label>(23)</label><mml:math id="m25"><mml:mrow><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mtable columnalign="right left right left right left right left right left right left" rowspacing="3pt" columnspacing="0em 2em 0em 2em 0em 2em 0em 2em 0em 2em 0em" displaystyle="true"><mml:mtr><mml:mtd><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msubsup><mml:mrow><mml:mover><mml:mi>u</mml:mi><mml:mo>˙</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mspace width="thinmathspace"/><mml:mi>E</mml:mi></mml:mrow></mml:msubsup><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mstyle></mml:mtd><mml:mtd><mml:mi/><mml:mo>=</mml:mo><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mo>−</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mi>τ</mml:mi></mml:mfrac><mml:msubsup><mml:mi>u</mml:mi><mml:mi>i</mml:mi><mml:mrow><mml:mspace width="thinmathspace"/><mml:mi>E</mml:mi></mml:mrow></mml:msubsup><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>+</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:msubsup><mml:mrow><mml:mrow><mml:mover><mml:mi>w</mml:mi><mml:mo stretchy="false">→</mml:mo></mml:mover></mml:mrow></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mspace width="thinmathspace"/><mml:mi>E</mml:mi></mml:mrow></mml:msubsup><mml:msup><mml:mo stretchy="false">)</mml:mo><mml:mrow><mml:mi mathvariant="normal">⊤</mml:mi></mml:mrow></mml:msup><mml:mrow><mml:mover><mml:mi>s</mml:mi><mml:mo stretchy="false">→</mml:mo></mml:mover></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>−</mml:mo><mml:munderover><mml:mo>∑</mml:mo><mml:mrow><mml:mi>j</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:msup><mml:mi>N</mml:mi><mml:mi>I</mml:mi></mml:msup></mml:mrow></mml:munderover><mml:mo stretchy="false">(</mml:mo><mml:msubsup><mml:mrow><mml:mrow><mml:mover><mml:mi>w</mml:mi><mml:mo stretchy="false">→</mml:mo></mml:mover></mml:mrow></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mspace width="thinmathspace"/><mml:mi>E</mml:mi></mml:mrow></mml:msubsup><mml:msup><mml:mo stretchy="false">)</mml:mo><mml:mrow><mml:mi mathvariant="normal">⊤</mml:mi></mml:mrow></mml:msup><mml:msubsup><mml:mrow><mml:mover><mml:mi>w</mml:mi><mml:mo stretchy="false">→</mml:mo></mml:mover></mml:mrow><mml:mi>j</mml:mi><mml:mrow><mml:mspace width="thinmathspace"/><mml:mi>I</mml:mi></mml:mrow></mml:msubsup><mml:msubsup><mml:mi>f</mml:mi><mml:mrow><mml:mi>j</mml:mi></mml:mrow><mml:mrow><mml:mspace width="thinmathspace"/><mml:mi>I</mml:mi></mml:mrow></mml:msubsup><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>−</mml:mo><mml:msup><mml:mi>β</mml:mi><mml:mrow><mml:mspace width="thinmathspace"/><mml:mi>E</mml:mi></mml:mrow></mml:msup><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mfrac><mml:mn>1</mml:mn><mml:mi>τ</mml:mi></mml:mfrac><mml:mo>−</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:msubsup><mml:mi>τ</mml:mi><mml:mi>r</mml:mi><mml:mrow><mml:mspace width="thinmathspace"/><mml:mi>E</mml:mi></mml:mrow></mml:msubsup></mml:mfrac></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:msubsup><mml:mi>r</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mspace width="thinmathspace"/><mml:mi>E</mml:mi></mml:mrow></mml:msubsup><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>,</mml:mo></mml:mstyle></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:msubsup><mml:mrow><mml:mover><mml:mi>u</mml:mi><mml:mo>˙</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mspace width="thinmathspace"/><mml:mi>E</mml:mi></mml:mrow></mml:msubsup><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mtd><mml:mtd><mml:mi/><mml:mo>=</mml:mo><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mo>−</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mi>τ</mml:mi></mml:mfrac><mml:msubsup><mml:mi>u</mml:mi><mml:mi>i</mml:mi><mml:mrow><mml:mspace width="thinmathspace"/><mml:mi>I</mml:mi></mml:mrow></mml:msubsup><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>+</mml:mo><mml:munderover><mml:mo>∑</mml:mo><mml:mrow><mml:mi>j</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:msup><mml:mi>N</mml:mi><mml:mrow><mml:mspace width="thinmathspace"/><mml:mi>E</mml:mi></mml:mrow></mml:msup></mml:mrow></mml:munderover><mml:mo stretchy="false">(</mml:mo><mml:msubsup><mml:mrow><mml:mrow><mml:mover><mml:mi>w</mml:mi><mml:mo stretchy="false">→</mml:mo></mml:mover></mml:mrow></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mspace width="thinmathspace"/><mml:mi>I</mml:mi></mml:mrow></mml:msubsup><mml:msup><mml:mo stretchy="false">)</mml:mo><mml:mrow><mml:mi mathvariant="normal">⊤</mml:mi></mml:mrow></mml:msup><mml:msubsup><mml:mrow><mml:mover><mml:mi>w</mml:mi><mml:mo stretchy="false">→</mml:mo></mml:mover></mml:mrow><mml:mi>j</mml:mi><mml:mrow><mml:mspace width="thinmathspace"/><mml:mi>E</mml:mi></mml:mrow></mml:msubsup><mml:msubsup><mml:mi>f</mml:mi><mml:mi>j</mml:mi><mml:mrow><mml:mspace width="thinmathspace"/><mml:mi>E</mml:mi></mml:mrow></mml:msubsup><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>−</mml:mo><mml:munderover><mml:mo>∑</mml:mo><mml:mrow><mml:mstyle scriptlevel="1"><mml:mtable rowspacing="0.1em" columnspacing="0em" displaystyle="false"><mml:mtr><mml:mtd><mml:mi>j</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mi>i</mml:mi><mml:mo>≠</mml:mo><mml:mi>j</mml:mi></mml:mtd></mml:mtr></mml:mtable></mml:mstyle></mml:mrow><mml:mrow><mml:msup><mml:mi>N</mml:mi><mml:mrow><mml:mspace width="thinmathspace"/><mml:mi>I</mml:mi></mml:mrow></mml:msup></mml:mrow></mml:munderover><mml:mo stretchy="false">(</mml:mo><mml:msubsup><mml:mrow><mml:mrow><mml:mover><mml:mi>w</mml:mi><mml:mo stretchy="false">→</mml:mo></mml:mover></mml:mrow></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mspace width="thinmathspace"/><mml:mi>I</mml:mi></mml:mrow></mml:msubsup><mml:msup><mml:mo stretchy="false">)</mml:mo><mml:mrow><mml:mi mathvariant="normal">⊤</mml:mi></mml:mrow></mml:msup><mml:msubsup><mml:mrow><mml:mover><mml:mi>w</mml:mi><mml:mo stretchy="false">→</mml:mo></mml:mover></mml:mrow><mml:mi>j</mml:mi><mml:mrow><mml:mspace width="thinmathspace"/><mml:mi>I</mml:mi></mml:mrow></mml:msubsup><mml:msubsup><mml:mi>f</mml:mi><mml:mrow><mml:mi>j</mml:mi></mml:mrow><mml:mrow><mml:mspace width="thinmathspace"/><mml:mi>I</mml:mi></mml:mrow></mml:msubsup><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>−</mml:mo><mml:msup><mml:mi>β</mml:mi><mml:mrow><mml:mspace width="thinmathspace"/><mml:mi>I</mml:mi></mml:mrow></mml:msup><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mfrac><mml:mn>1</mml:mn><mml:mi>τ</mml:mi></mml:mfrac><mml:mo>−</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:msubsup><mml:mi>τ</mml:mi><mml:mi>r</mml:mi><mml:mi>I</mml:mi></mml:msubsup></mml:mfrac></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:msubsup><mml:mi>r</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mspace width="thinmathspace"/><mml:mi>I</mml:mi></mml:mrow></mml:msubsup><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>,</mml:mo></mml:mstyle></mml:mtd></mml:mtr><mml:mtr><mml:mtd/><mml:mtd><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mtext>if </mml:mtext><mml:msubsup><mml:mi>u</mml:mi><mml:mi>i</mml:mi><mml:mi>y</mml:mi></mml:msubsup><mml:mo stretchy="false">(</mml:mo><mml:msup><mml:mi>t</mml:mi><mml:mo>−</mml:mo></mml:msup><mml:mo stretchy="false">)</mml:mo><mml:mo>≥</mml:mo><mml:msubsup><mml:mi>θ</mml:mi><mml:mi>i</mml:mi><mml:mi>y</mml:mi></mml:msubsup><mml:mo stretchy="false">→</mml:mo><mml:msubsup><mml:mi>u</mml:mi><mml:mi>i</mml:mi><mml:mrow><mml:mspace width="thinmathspace"/><mml:mi>y</mml:mi></mml:mrow></mml:msubsup><mml:mo stretchy="false">(</mml:mo><mml:msup><mml:mi>t</mml:mi><mml:mo>+</mml:mo></mml:msup><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:msubsup><mml:mi>u</mml:mi><mml:mi>i</mml:mi><mml:mrow><mml:mrow><mml:mspace width="thinmathspace"/><mml:mi>y</mml:mi></mml:mrow><mml:mo>,</mml:mo><mml:mtext>reset</mml:mtext></mml:mrow></mml:msubsup><mml:mo>,</mml:mo></mml:mstyle></mml:mtd></mml:mtr><mml:mtr><mml:mtd/><mml:mtd><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msubsup><mml:mi>θ</mml:mi><mml:mi>i</mml:mi><mml:mrow><mml:mspace width="thinmathspace"/><mml:mi>y</mml:mi></mml:mrow></mml:msubsup><mml:mo>=</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mn>2</mml:mn></mml:mfrac><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msup><mml:mrow><mml:mo symmetric="true">‖</mml:mo><mml:msubsup><mml:mrow><mml:mover><mml:mi>w</mml:mi><mml:mo stretchy="false">→</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mspace width="thinmathspace"/><mml:mi>y</mml:mi></mml:mrow></mml:msubsup><mml:mo symmetric="true">‖</mml:mo></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup><mml:mo>+</mml:mo><mml:msup><mml:mi>β</mml:mi><mml:mrow><mml:mspace width="thinmathspace"/><mml:mi>y</mml:mi></mml:mrow></mml:msup><mml:mo>−</mml:mo><mml:msubsup><mml:mi>ξ</mml:mi><mml:mi>i</mml:mi><mml:mrow><mml:mspace width="thinmathspace"/><mml:mi>y</mml:mi></mml:mrow></mml:msubsup><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>,</mml:mo></mml:mstyle></mml:mtd></mml:mtr><mml:mtr><mml:mtd/><mml:mtd><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msubsup><mml:mi>u</mml:mi><mml:mi>i</mml:mi><mml:mrow><mml:mspace width="thinmathspace"/><mml:mi>E</mml:mi><mml:mo>,</mml:mo><mml:mtext>reset</mml:mtext></mml:mrow></mml:msubsup><mml:mo>=</mml:mo><mml:msubsup><mml:mi>θ</mml:mi><mml:mi>i</mml:mi><mml:mrow><mml:mspace width="thinmathspace"/><mml:mi>E</mml:mi></mml:mrow></mml:msubsup><mml:mo>−</mml:mo><mml:msup><mml:mi>β</mml:mi><mml:mrow><mml:mspace width="thinmathspace"/><mml:mi>E</mml:mi></mml:mrow></mml:msup><mml:mo>,</mml:mo></mml:mstyle></mml:mtd></mml:mtr><mml:mtr><mml:mtd/><mml:mtd><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msubsup><mml:mi>u</mml:mi><mml:mi>i</mml:mi><mml:mrow><mml:mspace width="thinmathspace"/><mml:mi>I</mml:mi><mml:mo>,</mml:mo><mml:mtext>reset</mml:mtext></mml:mrow></mml:msubsup><mml:mo>=</mml:mo><mml:msubsup><mml:mi>θ</mml:mi><mml:mi>i</mml:mi><mml:mrow><mml:mspace width="thinmathspace"/><mml:mi>I</mml:mi></mml:mrow></mml:msubsup><mml:mo>−</mml:mo><mml:msup><mml:mi>β</mml:mi><mml:mrow><mml:mspace width="thinmathspace"/><mml:mi>I</mml:mi></mml:mrow></mml:msup><mml:mo>−</mml:mo><mml:msup><mml:mrow><mml:mo symmetric="true">‖</mml:mo><mml:msubsup><mml:mrow><mml:mover><mml:mi>w</mml:mi><mml:mo stretchy="false">→</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mspace width="thinmathspace"/><mml:mi>I</mml:mi></mml:mrow></mml:msubsup><mml:mo symmetric="true">‖</mml:mo></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup><mml:mo>.</mml:mo></mml:mstyle></mml:mtd></mml:mtr></mml:mtable></mml:mstyle></mml:mrow></mml:math></disp-formula></p><p>In the <xref ref-type="disp-formula" rid="equ25">Equation 23</xref>, we wrote explicitly the terms <inline-formula><mml:math id="inf318"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msubsup><mml:mrow><mml:mover><mml:mi>w</mml:mi><mml:mo stretchy="false">→</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mspace width="thinmathspace"/><mml:mi>y</mml:mi></mml:mrow></mml:msubsup><mml:msup><mml:mo stretchy="false">)</mml:mo><mml:mrow><mml:mi mathvariant="normal">⊤</mml:mi></mml:mrow></mml:msup><mml:msup><mml:mi>W</mml:mi><mml:mrow><mml:mspace width="thinmathspace"/><mml:mi>x</mml:mi></mml:mrow></mml:msup><mml:msup><mml:mrow><mml:mover><mml:mi>f</mml:mi><mml:mo stretchy="false">→</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mspace width="thinmathspace"/><mml:mi>x</mml:mi></mml:mrow></mml:msup><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:munderover><mml:mo>∑</mml:mo><mml:mrow><mml:mi>j</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:msup><mml:mi>N</mml:mi><mml:mrow><mml:mi>x</mml:mi></mml:mrow></mml:msup></mml:mrow></mml:munderover><mml:mo stretchy="false">(</mml:mo><mml:msubsup><mml:mrow><mml:mover><mml:mi>w</mml:mi><mml:mo stretchy="false">→</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mspace width="thinmathspace"/><mml:mi>y</mml:mi></mml:mrow></mml:msubsup><mml:msup><mml:mo stretchy="false">)</mml:mo><mml:mrow><mml:mi mathvariant="normal">⊤</mml:mi></mml:mrow></mml:msup><mml:msubsup><mml:mrow><mml:mover><mml:mi>w</mml:mi><mml:mo stretchy="false">→</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow><mml:mrow><mml:mspace width="thinmathspace"/><mml:mi>x</mml:mi></mml:mrow></mml:msubsup><mml:msubsup><mml:mi>f</mml:mi><mml:mrow><mml:mi>j</mml:mi></mml:mrow><mml:mrow><mml:mspace width="thinmathspace"/><mml:mi>x</mml:mi></mml:mrow></mml:msubsup><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mstyle></mml:math></inline-formula>, which correspond to the synaptic projections of <inline-formula><mml:math id="inf319"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msup><mml:mi>N</mml:mi><mml:mrow><mml:mspace width="thinmathspace"/><mml:mi>x</mml:mi></mml:mrow></mml:msup></mml:mstyle></mml:mrow></mml:mstyle></mml:math></inline-formula> presynaptic neurons of type <inline-formula><mml:math id="inf320"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>x</mml:mi></mml:mstyle></mml:math></inline-formula> to the postsynaptic neuron <inline-formula><mml:math id="inf321"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>i</mml:mi></mml:mstyle></mml:math></inline-formula> of type <inline-formula><mml:math id="inf322"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>y</mml:mi></mml:mstyle></mml:math></inline-formula>, with the quantity <inline-formula><mml:math id="inf323"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mo stretchy="false">(</mml:mo><mml:msubsup><mml:mrow><mml:mover><mml:mi>w</mml:mi><mml:mo stretchy="false">→</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mspace width="thinmathspace"/><mml:mi>y</mml:mi></mml:mrow></mml:msubsup><mml:msup><mml:mo stretchy="false">)</mml:mo><mml:mrow><mml:mi mathvariant="normal">⊤</mml:mi></mml:mrow></mml:msup><mml:msubsup><mml:mrow><mml:mover><mml:mi>w</mml:mi><mml:mo stretchy="false">→</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow><mml:mrow><mml:mspace width="thinmathspace"/><mml:mi>x</mml:mi></mml:mrow></mml:msubsup></mml:mstyle></mml:mrow></mml:mstyle></mml:math></inline-formula> denoting the synaptic weight. We note that, in the case of I neurons, the element with <inline-formula><mml:math id="inf324"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>j</mml:mi><mml:mo>=</mml:mo><mml:mi>i</mml:mi></mml:mstyle></mml:math></inline-formula> describes an autapse, that is a projection of a neuron with itself; this term is equal to <inline-formula><mml:math id="inf325"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mo>−</mml:mo><mml:msup><mml:mrow><mml:mo>(</mml:mo><mml:msubsup><mml:mrow><mml:mover><mml:mi>w</mml:mi><mml:mo stretchy="false">→</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mspace width="thinmathspace"/><mml:mi>I</mml:mi></mml:mrow></mml:msubsup><mml:mo>)</mml:mo></mml:mrow><mml:mrow><mml:mi mathvariant="normal">⊤</mml:mi></mml:mrow></mml:msup><mml:msubsup><mml:mrow><mml:mover><mml:mi>w</mml:mi><mml:mo stretchy="false">→</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mspace width="thinmathspace"/><mml:mi>I</mml:mi></mml:mrow></mml:msubsup><mml:msubsup><mml:mi>f</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mspace width="thinmathspace"/><mml:mi>I</mml:mi></mml:mrow></mml:msubsup><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mo>−</mml:mo><mml:mo fence="false" stretchy="false">‖</mml:mo><mml:msubsup><mml:mrow><mml:mover><mml:mi>w</mml:mi><mml:mo stretchy="false">→</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mspace width="thinmathspace"/><mml:mi>I</mml:mi></mml:mrow></mml:msubsup><mml:msup><mml:mo fence="false" stretchy="false">‖</mml:mo><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup><mml:msubsup><mml:mi>f</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mspace width="thinmathspace"/><mml:mi>I</mml:mi></mml:mrow></mml:msubsup><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mstyle></mml:math></inline-formula>, and thus contributes to the resetting of the neuron <inline-formula><mml:math id="inf326"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>i</mml:mi></mml:mstyle></mml:math></inline-formula>.</p></sec><sec id="s4-5-2"><title>Imposing Dale’s principle on synaptic connectivity</title><p>We now examine the synaptic terms in <xref ref-type="disp-formula" rid="equ25">Equation 23</xref>. As a first remark, we see that synaptic weights depend on tuning parameters <inline-formula><mml:math id="inf327"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msubsup><mml:mi>w</mml:mi><mml:mrow><mml:mi>k</mml:mi><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mspace width="thinmathspace"/><mml:mi>y</mml:mi></mml:mrow></mml:msubsup></mml:mrow></mml:mstyle></mml:math></inline-formula>. For the sake of generality we drew tuning parameters <inline-formula><mml:math id="inf328"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msubsup><mml:mi>w</mml:mi><mml:mrow><mml:mi>k</mml:mi><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mspace width="thinmathspace"/><mml:mi>y</mml:mi></mml:mrow></mml:msubsup></mml:mrow></mml:mstyle></mml:math></inline-formula> from a normal distribution with vanishing mean, which yielded both positive and negative values of <inline-formula><mml:math id="inf329"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msubsup><mml:mi>w</mml:mi><mml:mrow><mml:mi>k</mml:mi><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mspace width="thinmathspace"/><mml:mi>y</mml:mi></mml:mrow></mml:msubsup></mml:mrow></mml:mstyle></mml:math></inline-formula>. This has the desirable consequence that a spike of a neuron with a positive tuning parameter in signal dimension <inline-formula><mml:math id="inf330"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>k</mml:mi></mml:mstyle></mml:math></inline-formula>, <inline-formula><mml:math id="inf331"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msubsup><mml:mi>w</mml:mi><mml:mrow><mml:mi>k</mml:mi><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mspace width="thinmathspace"/><mml:mi>y</mml:mi></mml:mrow></mml:msubsup><mml:mo>&gt;</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:mstyle></mml:math></inline-formula> pulls the estimate, <inline-formula><mml:math id="inf332"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msubsup><mml:mrow class="MJX-TeXAtom-ORD"><mml:mover><mml:mi>x</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>k</mml:mi></mml:mrow><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>y</mml:mi></mml:mrow></mml:msubsup><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mstyle></mml:math></inline-formula>, up, while a spike of a neuron with <inline-formula><mml:math id="inf333"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msubsup><mml:mi>w</mml:mi><mml:mrow><mml:mi>k</mml:mi><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mspace width="thinmathspace"/><mml:mi>y</mml:mi></mml:mrow></mml:msubsup><mml:mo>&lt;</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:mstyle></mml:math></inline-formula> pulls the estimate down, allowing population readouts to track both positive and negative fluctuations of the target signal on a fast time scale.</p><p>Another consequence of synaptic connectivity in the <xref ref-type="disp-formula" rid="equ25">Equation 23</xref> is that the synaptic weight between a presynaptic neuron <inline-formula><mml:math id="inf334"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>j</mml:mi></mml:mstyle></mml:math></inline-formula> of type <inline-formula><mml:math id="inf335"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>x</mml:mi></mml:mstyle></mml:math></inline-formula> and a postsynaptic neuron <inline-formula><mml:math id="inf336"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>i</mml:mi></mml:mstyle></mml:math></inline-formula> of type <inline-formula><mml:math id="inf337"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>y</mml:mi></mml:mstyle></mml:math></inline-formula> is symmetric and depends on the similarity of tuning vectors of the presynaptic and the postsynaptic neuron: <inline-formula><mml:math id="inf338"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msubsup><mml:mrow><mml:mover><mml:mi>w</mml:mi><mml:mo stretchy="false">→</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mi>y</mml:mi></mml:mrow></mml:msubsup><mml:msup><mml:mo stretchy="false">)</mml:mo><mml:mrow><mml:mi mathvariant="normal">⊤</mml:mi></mml:mrow></mml:msup><mml:msubsup><mml:mrow><mml:mover><mml:mi>w</mml:mi><mml:mo stretchy="false">→</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow><mml:mrow><mml:mi>x</mml:mi></mml:mrow></mml:msubsup><mml:mo>=</mml:mo><mml:munderover><mml:mo>∑</mml:mo><mml:mrow><mml:mi>k</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>M</mml:mi></mml:mrow></mml:munderover><mml:msubsup><mml:mi>w</mml:mi><mml:mrow><mml:mi>k</mml:mi><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mspace width="thinmathspace"/><mml:mi>y</mml:mi></mml:mrow></mml:msubsup><mml:msubsup><mml:mi>w</mml:mi><mml:mrow><mml:mi>k</mml:mi><mml:mi>j</mml:mi></mml:mrow><mml:mrow><mml:mspace width="thinmathspace"/><mml:mi>x</mml:mi></mml:mrow></mml:msubsup></mml:mrow></mml:mstyle></mml:math></inline-formula>. The sign of this scalar product is positive between neurons with similar tuning and negative between neurons with different tuning (and zero when the two tuning vectors are orthogonal). Thus, for a presynaptic neuron <inline-formula><mml:math id="inf339"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>j</mml:mi></mml:mstyle></mml:math></inline-formula> of type <inline-formula><mml:math id="inf340"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>x</mml:mi></mml:mstyle></mml:math></inline-formula>, the synaptic weights of its outgoing connections can be both positive and negative, because some of its postsynaptic neurons have similar tuning to the neuron <inline-formula><mml:math id="inf341"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>j</mml:mi></mml:mstyle></mml:math></inline-formula> while others have different tuning. This is inconsistent with Dale’s principle (<xref ref-type="bibr" rid="bib107">Whittaker, 1983</xref>), which postulates that a particular neuron can only have one type of effect on postsynaptic neurons (excitatory or inhibitory), but never both. To impose this constraint in our model, we set synaptic weights between neurons with different tuning (i.e. <inline-formula><mml:math id="inf342"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msubsup><mml:mrow><mml:mover><mml:mi>w</mml:mi><mml:mo stretchy="false">→</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mspace width="thinmathspace"/><mml:mi>y</mml:mi></mml:mrow></mml:msubsup><mml:msup><mml:mo stretchy="false">)</mml:mo><mml:mrow><mml:mi mathvariant="normal">⊤</mml:mi></mml:mrow></mml:msup><mml:msubsup><mml:mrow><mml:mover><mml:mi>w</mml:mi><mml:mo stretchy="false">→</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow><mml:mrow><mml:mspace width="thinmathspace"/><mml:mi>x</mml:mi></mml:mrow></mml:msubsup><mml:mo>&lt;</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:mstyle></mml:math></inline-formula>) to zero. To this end, we define the rectified connectivity matrices,<disp-formula id="equ26"><label>(24)</label><mml:math id="m26"><mml:mrow><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msubsup><mml:mi>J</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow><mml:mrow><mml:mspace width="thinmathspace"/><mml:mi>y</mml:mi><mml:mi>x</mml:mi></mml:mrow></mml:msubsup><mml:mo>=</mml:mo><mml:msub><mml:mrow><mml:mo>[</mml:mo><mml:mrow><mml:msup><mml:mrow><mml:mo>(</mml:mo><mml:msubsup><mml:mrow><mml:mover><mml:mi>w</mml:mi><mml:mo stretchy="false">→</mml:mo></mml:mover></mml:mrow><mml:mi>i</mml:mi><mml:mrow><mml:mspace width="thinmathspace"/><mml:mi>y</mml:mi></mml:mrow></mml:msubsup><mml:mo>)</mml:mo></mml:mrow><mml:mi mathvariant="normal">⊤</mml:mi></mml:msup><mml:msubsup><mml:mrow><mml:mover><mml:mi>w</mml:mi><mml:mo stretchy="false">→</mml:mo></mml:mover></mml:mrow><mml:mi>j</mml:mi><mml:mrow><mml:mspace width="thinmathspace"/><mml:mi>x</mml:mi></mml:mrow></mml:msubsup></mml:mrow><mml:mo>]</mml:mo></mml:mrow><mml:mo>+</mml:mo></mml:msub><mml:mo>,</mml:mo></mml:mstyle></mml:mrow></mml:math></disp-formula></p><p>with <inline-formula><mml:math id="inf343"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mo stretchy="false">(</mml:mo><mml:mi>x</mml:mi><mml:mo>,</mml:mo><mml:mi>y</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>∈</mml:mo><mml:mo fence="false" stretchy="false">{</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mi>E</mml:mi><mml:mo>,</mml:mo><mml:mi>I</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>,</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mi>I</mml:mi><mml:mo>,</mml:mo><mml:mi>I</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>,</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mi>I</mml:mi><mml:mo>,</mml:mo><mml:mi>E</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo fence="false" stretchy="false">}</mml:mo></mml:mstyle></mml:math></inline-formula> and <inline-formula><mml:math id="inf344"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mo stretchy="false">[</mml:mo><mml:mi>a</mml:mi><mml:msub><mml:mo stretchy="false">]</mml:mo><mml:mrow class="MJX-TeXAtom-ORD"><mml:mo>+</mml:mo></mml:mrow></mml:msub><mml:mo>≡</mml:mo><mml:mo movablelimits="true" form="prefix">max</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:mi>a</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mstyle></mml:math></inline-formula> a rectified linear function. Note that there are no direct synaptic connections between E neurons. Since the elements of the matrix <inline-formula><mml:math id="inf345"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msup><mml:mi>J</mml:mi><mml:mrow><mml:mspace width="thinmathspace"/><mml:mi>y</mml:mi><mml:mi>x</mml:mi></mml:mrow></mml:msup></mml:mstyle></mml:mrow></mml:mstyle></mml:math></inline-formula> are all non-negative, it is the sign in front of the synaptic term in the <xref ref-type="disp-formula" rid="equ25">Equation 23</xref> that determines the sign of the synaptic current between neurons <inline-formula><mml:math id="inf346"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>i</mml:mi></mml:mstyle></mml:math></inline-formula> and <inline-formula><mml:math id="inf347"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>j</mml:mi></mml:mstyle></mml:math></inline-formula>. The synaptic current is excitatory if the sign is positive, and inhibitory if the sign is negative.</p><p>It is also interesting to note that rectification affects the rank of connectivity matrices. Without rectification, the product in <xref ref-type="disp-formula" rid="equ26">Equation 24</xref> yields a connectivity matrix with rank smaller or equal to the number of input features to the network, <inline-formula><mml:math id="inf348"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>M</mml:mi></mml:mstyle></mml:math></inline-formula>, similarly as in previous works (<xref ref-type="bibr" rid="bib12">Bourdoukan et al., 2012</xref>; <xref ref-type="bibr" rid="bib7">Barrett et al., 2016</xref>; <xref ref-type="bibr" rid="bib4">Alemi et al., 2018</xref>). Since typically the number of input features is much smaller than the number of neurons, that is <inline-formula><mml:math id="inf349"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>M</mml:mi><mml:mo>&lt;&lt;</mml:mo><mml:msup><mml:mi>N</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>y</mml:mi></mml:mrow></mml:msup></mml:mstyle></mml:math></inline-formula>, this would give a low-rank connectivity matrix. However, rectification in <xref ref-type="disp-formula" rid="equ26">Equation 24</xref>, necessary to ensure Dale’s principle in presence of positive and negative tuning parameters, typically results in a substantial increase of the rank of the connectivity matrix.</p><p>Using the synaptic connectivity defined in <xref ref-type="disp-formula" rid="equ26">Equation 24</xref>, we rewrite the network dynamics from <xref ref-type="disp-formula" rid="equ25">Equation 23</xref> as:<disp-formula id="equ27"><label>(25)</label><mml:math id="m27"><mml:mrow><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mtable columnalign="right left right left right left right left right left right left" rowspacing="3pt" columnspacing="0em 2em 0em 2em 0em 2em 0em 2em 0em 2em 0em" displaystyle="true"><mml:mtr><mml:mtd><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msubsup><mml:mrow><mml:mover><mml:mi>u</mml:mi><mml:mo>˙</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mi>E</mml:mi></mml:mrow></mml:msubsup><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mo>−</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mi>τ</mml:mi></mml:mfrac><mml:msubsup><mml:mi>u</mml:mi><mml:mi>i</mml:mi><mml:mi>E</mml:mi></mml:msubsup><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mstyle></mml:mstyle></mml:mtd><mml:mtd><mml:mi/><mml:mo>+</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:msubsup><mml:mrow><mml:mover><mml:mi>w</mml:mi><mml:mo stretchy="false">→</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mi>E</mml:mi></mml:mrow></mml:msubsup><mml:msup><mml:mo stretchy="false">)</mml:mo><mml:mrow><mml:mi mathvariant="normal">⊤</mml:mi></mml:mrow></mml:msup><mml:mrow><mml:mover><mml:mi>s</mml:mi><mml:mo stretchy="false">→</mml:mo></mml:mover></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>−</mml:mo><mml:munderover><mml:mo>∑</mml:mo><mml:mrow><mml:mi>j</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:msup><mml:mi>N</mml:mi><mml:mi>I</mml:mi></mml:msup></mml:mrow></mml:munderover><mml:msubsup><mml:mi>J</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow><mml:mrow><mml:mspace width="thinmathspace"/><mml:mi>E</mml:mi><mml:mi>I</mml:mi></mml:mrow></mml:msubsup><mml:msubsup><mml:mi>f</mml:mi><mml:mrow><mml:mi>j</mml:mi></mml:mrow><mml:mrow><mml:mspace width="thinmathspace"/><mml:mi>I</mml:mi></mml:mrow></mml:msubsup><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>−</mml:mo><mml:msup><mml:mi>β</mml:mi><mml:mi>E</mml:mi></mml:msup><mml:mo stretchy="false">(</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mi>τ</mml:mi></mml:mfrac><mml:mo>−</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:msubsup><mml:mi>τ</mml:mi><mml:mi>r</mml:mi><mml:mi>E</mml:mi></mml:msubsup></mml:mfrac><mml:mo stretchy="false">)</mml:mo><mml:msubsup><mml:mi>r</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mi>E</mml:mi></mml:msubsup><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>,</mml:mo></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msubsup><mml:mrow><mml:mover><mml:mi>u</mml:mi><mml:mo>˙</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mi>E</mml:mi></mml:mrow></mml:msubsup><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mo>−</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mi>τ</mml:mi></mml:mfrac><mml:msubsup><mml:mi>u</mml:mi><mml:mi>i</mml:mi><mml:mi>I</mml:mi></mml:msubsup><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mstyle></mml:mtd><mml:mtd><mml:mi/><mml:mo>+</mml:mo><mml:munderover><mml:mo>∑</mml:mo><mml:mrow><mml:mi>j</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:msup><mml:mi>N</mml:mi><mml:mi>E</mml:mi></mml:msup></mml:mrow></mml:munderover><mml:msubsup><mml:mi>J</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow><mml:mrow><mml:mspace width="thinmathspace"/><mml:mi>I</mml:mi><mml:mi>E</mml:mi></mml:mrow></mml:msubsup><mml:msubsup><mml:mi>f</mml:mi><mml:mi>j</mml:mi><mml:mrow><mml:mspace width="thinmathspace"/><mml:mi>E</mml:mi></mml:mrow></mml:msubsup><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>−</mml:mo><mml:munderover><mml:mo>∑</mml:mo><mml:mrow><mml:mstyle scriptlevel="1"><mml:mtable rowspacing="0.1em" columnspacing="0em" displaystyle="false"><mml:mtr><mml:mtd><mml:mi>j</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mi>i</mml:mi><mml:mo>≠</mml:mo><mml:mi>j</mml:mi></mml:mtd></mml:mtr></mml:mtable></mml:mstyle></mml:mrow><mml:mrow><mml:msup><mml:mi>N</mml:mi><mml:mi>I</mml:mi></mml:msup></mml:mrow></mml:munderover><mml:msubsup><mml:mi>J</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow><mml:mrow><mml:mspace width="thinmathspace"/><mml:mi>I</mml:mi><mml:mi>I</mml:mi></mml:mrow></mml:msubsup><mml:msubsup><mml:mi>f</mml:mi><mml:mrow><mml:mi>j</mml:mi></mml:mrow><mml:mrow><mml:mspace width="thinmathspace"/><mml:mi>I</mml:mi></mml:mrow></mml:msubsup><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>−</mml:mo><mml:msup><mml:mi>β</mml:mi><mml:mi>I</mml:mi></mml:msup><mml:mo stretchy="false">(</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mi>τ</mml:mi></mml:mfrac><mml:mo>−</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:msubsup><mml:mi>τ</mml:mi><mml:mi>r</mml:mi><mml:mi>I</mml:mi></mml:msubsup></mml:mfrac><mml:mo stretchy="false">)</mml:mo><mml:msubsup><mml:mi>r</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mi>I</mml:mi></mml:msubsup><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>,</mml:mo></mml:mtd></mml:mtr><mml:mtr><mml:mtd/><mml:mtd><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mtext>if </mml:mtext><mml:msubsup><mml:mi>u</mml:mi><mml:mi>i</mml:mi><mml:mi>y</mml:mi></mml:msubsup><mml:mo stretchy="false">(</mml:mo><mml:msup><mml:mi>t</mml:mi><mml:mo>−</mml:mo></mml:msup><mml:mo stretchy="false">)</mml:mo><mml:mo>≥</mml:mo><mml:msubsup><mml:mi>θ</mml:mi><mml:mi>i</mml:mi><mml:mrow><mml:mspace width="thinmathspace"/><mml:mi>y</mml:mi></mml:mrow></mml:msubsup><mml:mo stretchy="false">→</mml:mo><mml:msubsup><mml:mi>u</mml:mi><mml:mi>i</mml:mi><mml:mi>y</mml:mi></mml:msubsup><mml:mo stretchy="false">(</mml:mo><mml:msup><mml:mi>t</mml:mi><mml:mo>+</mml:mo></mml:msup><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:msubsup><mml:mi>u</mml:mi><mml:mi>i</mml:mi><mml:mrow><mml:mi>y</mml:mi><mml:mo>,</mml:mo><mml:mtext>reset</mml:mtext></mml:mrow></mml:msubsup><mml:mo>,</mml:mo></mml:mstyle></mml:mtd></mml:mtr><mml:mtr><mml:mtd/><mml:mtd><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msubsup><mml:mi>θ</mml:mi><mml:mi>i</mml:mi><mml:mrow><mml:mspace width="thinmathspace"/><mml:mi>y</mml:mi></mml:mrow></mml:msubsup><mml:mo>=</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mn>2</mml:mn></mml:mfrac><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msup><mml:mrow><mml:mo symmetric="true">‖</mml:mo><mml:msubsup><mml:mrow><mml:mover><mml:mi>w</mml:mi><mml:mo stretchy="false">→</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mspace width="thinmathspace"/><mml:mi>y</mml:mi></mml:mrow></mml:msubsup><mml:mo symmetric="true">‖</mml:mo></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup><mml:mo>+</mml:mo><mml:msup><mml:mi>β</mml:mi><mml:mi>y</mml:mi></mml:msup><mml:mo>−</mml:mo><mml:msubsup><mml:mi>ξ</mml:mi><mml:mi>i</mml:mi><mml:mi>y</mml:mi></mml:msubsup><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>,</mml:mo></mml:mstyle></mml:mtd></mml:mtr><mml:mtr><mml:mtd/><mml:mtd><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msubsup><mml:mi>u</mml:mi><mml:mi>i</mml:mi><mml:mrow><mml:mi>E</mml:mi><mml:mo>,</mml:mo><mml:mtext>reset</mml:mtext></mml:mrow></mml:msubsup><mml:mo>=</mml:mo><mml:msubsup><mml:mi>θ</mml:mi><mml:mi>i</mml:mi><mml:mi>E</mml:mi></mml:msubsup><mml:mo>−</mml:mo><mml:msup><mml:mi>β</mml:mi><mml:mi>E</mml:mi></mml:msup><mml:mo>,</mml:mo></mml:mstyle></mml:mtd></mml:mtr><mml:mtr><mml:mtd/><mml:mtd><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msubsup><mml:mi>u</mml:mi><mml:mi>i</mml:mi><mml:mrow><mml:mi>I</mml:mi><mml:mo>,</mml:mo><mml:mtext>reset</mml:mtext></mml:mrow></mml:msubsup><mml:mo>=</mml:mo><mml:msubsup><mml:mi>θ</mml:mi><mml:mi>i</mml:mi><mml:mi>I</mml:mi></mml:msubsup><mml:mo>−</mml:mo><mml:msup><mml:mi>β</mml:mi><mml:mi>I</mml:mi></mml:msup><mml:mo>−</mml:mo><mml:msup><mml:mrow><mml:mo symmetric="true">‖</mml:mo><mml:msubsup><mml:mrow><mml:mover><mml:mi>w</mml:mi><mml:mo stretchy="false">→</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mspace width="thinmathspace"/><mml:mi>I</mml:mi></mml:mrow></mml:msubsup><mml:mo symmetric="true">‖</mml:mo></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup><mml:mo>.</mml:mo></mml:mstyle></mml:mtd></mml:mtr></mml:mtable></mml:mstyle></mml:mrow></mml:math></disp-formula></p><p>These equations express the neural dynamics which minimizes the loss functions (<xref ref-type="disp-formula" rid="equ10">Equation 10</xref>) in terms of a generalized leaky integrate-and-fire model with E and I cell types, and are consistent with Dale’s principle.</p><p>In principle, it is possible to use the same strategy as for the E-I network to enforce Dale’s principle in model with one cell type (introduced by <xref ref-type="bibr" rid="bib11">Boerlin et al., 2013</xref>). To do so, we constrained the recurrent connectivity of the model with a single cell type from <xref ref-type="bibr" rid="bib48">Koren and Denève, 2017</xref> by keeping only connections between neurons with similar tuning vectors and setting other connections to 0 (see Appendix 1). This led to a network of only inhibitory neurons, a type of network model which is less relevant for the description of biological networks.</p></sec><sec id="s4-5-3"><title>Model with resting potential and an external current</title><p>In the model given by the <xref ref-type="disp-formula" rid="equ27">Equation 25</xref> the resting potential is equal to zero. In order to account for biophysical values of the resting potential and to introduce an implementation of the metabolic constant that is consistent with neurobiology, we add a constant value to the dynamical equations of the membrane potentials <inline-formula><mml:math id="inf350"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msubsup><mml:mrow class="MJX-TeXAtom-ORD"><mml:mover><mml:mi>u</mml:mi><mml:mo>˙</mml:mo></mml:mover></mml:mrow><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>i</mml:mi></mml:mrow><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>y</mml:mi></mml:mrow></mml:msubsup></mml:mstyle></mml:math></inline-formula>, the firing thresholds <inline-formula><mml:math id="inf351"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msubsup><mml:mi>θ</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>i</mml:mi></mml:mrow><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>y</mml:mi></mml:mrow></mml:msubsup></mml:mstyle></mml:math></inline-formula> and the reset potentials <inline-formula><mml:math id="inf352"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msubsup><mml:mi>u</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>i</mml:mi></mml:mrow><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>y</mml:mi><mml:mo>,</mml:mo><mml:mtext>reset</mml:mtext></mml:mrow></mml:msubsup></mml:mstyle></mml:math></inline-formula>. This does not change the spiking dynamics of the model, as what matters to correctly infer the efficient spiking times of neurons is the distance between the membrane potential and the threshold.</p><p>Furthermore, in the same equations, the role of the metabolic constant <inline-formula><mml:math id="inf353"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msup><mml:mi>β</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>y</mml:mi></mml:mrow></mml:msup></mml:mstyle></mml:math></inline-formula> as a biophysical quantity is questionable. The metabolic constant <inline-formula><mml:math id="inf354"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msup><mml:mi>β</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>y</mml:mi></mml:mrow></mml:msup></mml:mstyle></mml:math></inline-formula> is an important parameter that weights the metabolic cost over the encoding error in the objective functions (<xref ref-type="disp-formula" rid="equ10">Equation 10</xref>). On the level of computational objectives, the metabolic constant naturally controls firing rates, as it allows the network to fire more or less spikes to correct for a certain encoding error. A flexible control of the firing rates is a desirable property, as gives the possibility to potentially capture different dynamical regimes of efficient spiking networks (<xref ref-type="bibr" rid="bib48">Koren and Denève, 2017</xref>). In the spiking model we developed thus far (<xref ref-type="disp-formula" rid="equ27">Equation 25</xref>), similarly to previous efficient spiking models (<xref ref-type="bibr" rid="bib48">Koren and Denève, 2017</xref>; <xref ref-type="bibr" rid="bib39">Gutierrez and Denève, 2019</xref>), the metabolic constant <inline-formula><mml:math id="inf355"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msup><mml:mi>β</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>y</mml:mi></mml:mrow></mml:msup></mml:mstyle></mml:math></inline-formula> controls the firing threshold. In neurobiology, however, strong changes to the firing threshold that would reflect metabolic constraints of the network are not plausible. We thus searched for an implementation of the metabolic constant <inline-formula><mml:math id="inf356"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msup><mml:mi>β</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>y</mml:mi></mml:mrow></mml:msup></mml:mstyle></mml:math></inline-formula> that is consistent with neurobiology.</p><p>The condition for threshold crossing of the neuron <inline-formula><mml:math id="inf357"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>i</mml:mi></mml:mstyle></mml:math></inline-formula> can be written by <xref ref-type="disp-formula" rid="equ27">Equation 25</xref> as<disp-formula id="equ28"><label>(26)</label><mml:math id="m28"><mml:mrow><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msubsup><mml:mi>u</mml:mi><mml:mi>i</mml:mi><mml:mi>y</mml:mi></mml:msubsup><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>+</mml:mo><mml:msubsup><mml:mi>V</mml:mi><mml:mrow><mml:mtext>rest</mml:mtext></mml:mrow><mml:mrow><mml:mspace width="thinmathspace"/><mml:mi>y</mml:mi></mml:mrow></mml:msubsup><mml:mo>+</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mn>2</mml:mn></mml:mfrac><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>c</mml:mi><mml:mo>−</mml:mo><mml:msup><mml:mi>β</mml:mi><mml:mrow><mml:mspace width="thinmathspace"/><mml:mi>y</mml:mi></mml:mrow></mml:msup><mml:mo>+</mml:mo><mml:msubsup><mml:mi>ξ</mml:mi><mml:mi>i</mml:mi><mml:mi>y</mml:mi></mml:msubsup><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>≥</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mn>2</mml:mn></mml:mfrac><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msup><mml:mrow><mml:mo symmetric="true">‖</mml:mo><mml:msubsup><mml:mrow><mml:mover><mml:mi>w</mml:mi><mml:mo stretchy="false">→</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mspace width="thinmathspace"/><mml:mi>y</mml:mi></mml:mrow></mml:msubsup><mml:mo symmetric="true">‖</mml:mo></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup><mml:mo>+</mml:mo><mml:mi>c</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>+</mml:mo><mml:msubsup><mml:mi>V</mml:mi><mml:mrow><mml:mtext>rest</mml:mtext></mml:mrow><mml:mrow><mml:mspace width="thinmathspace"/><mml:mi>y</mml:mi></mml:mrow></mml:msubsup><mml:mo>,</mml:mo></mml:mstyle></mml:mrow></mml:math></disp-formula></p><p>with <inline-formula><mml:math id="inf358"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>c</mml:mi></mml:mstyle></mml:math></inline-formula> an arbitrary constant in units of millivolts. In <xref ref-type="disp-formula" rid="equ28">Equation 26</xref> we added a constant <inline-formula><mml:math id="inf359"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>c</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mo>/</mml:mo></mml:mrow><mml:mn>2</mml:mn></mml:mstyle></mml:math></inline-formula> and a resting potential <inline-formula><mml:math id="inf360"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msubsup><mml:mi>V</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mtext>rest</mml:mtext></mml:mrow><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>y</mml:mi></mml:mrow></mml:msubsup></mml:mstyle></mml:math></inline-formula> on the left- and right-hand side of the firing rule. Moreover, we shifted the noise and the dependency on the parameter <inline-formula><mml:math id="inf361"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>β</mml:mi></mml:mstyle></mml:math></inline-formula> from the firing threshold to the membrane potential. Thus, we assumed that the firing threshold is independent of the metabolic constant and the noise, and we instead assumed the dependence on the metabolic constant and noise in the membrane potentials.</p><p>We now define new variables for <inline-formula><mml:math id="inf362"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>y</mml:mi><mml:mo>∈</mml:mo><mml:mo fence="false" stretchy="false">{</mml:mo><mml:mi>E</mml:mi><mml:mo>,</mml:mo><mml:mi>I</mml:mi><mml:mo fence="false" stretchy="false">}</mml:mo></mml:mstyle></mml:math></inline-formula>:<disp-formula id="equ29"><label>(27)</label><mml:math id="m29"><mml:mrow><mml:mtable columnalign="right left right left right left right left right left right left" rowspacing="3pt" columnspacing="0em 2em 0em 2em 0em 2em 0em 2em 0em 2em 0em" displaystyle="true"><mml:mtr><mml:mtd><mml:msubsup><mml:mi>V</mml:mi><mml:mi>i</mml:mi><mml:mrow><mml:mspace width="thinmathspace"/><mml:mi>y</mml:mi></mml:mrow></mml:msubsup><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mtd><mml:mtd><mml:mi/><mml:mo>:≡</mml:mo><mml:msubsup><mml:mi>u</mml:mi><mml:mi>i</mml:mi><mml:mi>y</mml:mi></mml:msubsup><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>+</mml:mo><mml:msubsup><mml:mi>V</mml:mi><mml:mrow><mml:mtext>rest</mml:mtext></mml:mrow><mml:mrow><mml:mspace width="thinmathspace"/><mml:mi>y</mml:mi></mml:mrow></mml:msubsup><mml:mo>+</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mn>2</mml:mn></mml:mfrac><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>c</mml:mi><mml:mo>−</mml:mo><mml:msup><mml:mi>β</mml:mi><mml:mi>y</mml:mi></mml:msup><mml:mo>+</mml:mo><mml:msubsup><mml:mi>ξ</mml:mi><mml:mi>i</mml:mi><mml:mi>y</mml:mi></mml:msubsup><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>,</mml:mo><mml:mspace width="2em"/><mml:msubsup><mml:mi>V</mml:mi><mml:mrow><mml:mtext>rest</mml:mtext></mml:mrow><mml:mrow><mml:mspace width="thinmathspace"/><mml:mi>y</mml:mi></mml:mrow></mml:msubsup><mml:mo>&lt;</mml:mo><mml:mn>0</mml:mn><mml:mo>,</mml:mo></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:msubsup><mml:mi>ϑ</mml:mi><mml:mi>i</mml:mi><mml:mi>y</mml:mi></mml:msubsup></mml:mtd><mml:mtd><mml:mi/><mml:mo>:≡</mml:mo><mml:msubsup><mml:mi>V</mml:mi><mml:mrow><mml:mtext>rest</mml:mtext></mml:mrow><mml:mrow><mml:mspace width="thinmathspace"/><mml:mi>y</mml:mi></mml:mrow></mml:msubsup><mml:mo>+</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mn>2</mml:mn></mml:mfrac><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msup><mml:mrow><mml:mo symmetric="true">‖</mml:mo><mml:msubsup><mml:mrow><mml:mover><mml:mi>w</mml:mi><mml:mo stretchy="false">→</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mspace width="thinmathspace"/><mml:mi>y</mml:mi></mml:mrow></mml:msubsup><mml:mo symmetric="true">‖</mml:mo></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup><mml:mo>+</mml:mo><mml:mi>c</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>,</mml:mo></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:math></disp-formula></p><p>and rewrite the model in <xref ref-type="disp-formula" rid="equ27">Equation 25</xref> in these new variables<disp-formula id="equ30"><mml:math id="m30"><mml:mrow><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mtable columnalign="right left right left right left right left right left right left" rowspacing="3pt" columnspacing="0em 2em 0em 2em 0em 2em 0em 2em 0em 2em 0em" displaystyle="true"><mml:mtr><mml:mtd><mml:mi>τ</mml:mi><mml:msubsup><mml:mrow><mml:mover><mml:mi>V</mml:mi><mml:mo>˙</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mspace width="thinmathspace"/><mml:mi>E</mml:mi></mml:mrow></mml:msubsup><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mspace width="thinmathspace"/></mml:mtd><mml:mtd><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mo>−</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msubsup><mml:mi>V</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mspace width="thinmathspace"/><mml:mi>E</mml:mi></mml:mrow></mml:msubsup><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>−</mml:mo><mml:msubsup><mml:mi>V</mml:mi><mml:mrow><mml:mtext>rest</mml:mtext></mml:mrow><mml:mrow><mml:mi>E</mml:mi></mml:mrow></mml:msubsup></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>+</mml:mo><mml:mi>τ</mml:mi><mml:msup><mml:mrow><mml:mo>(</mml:mo><mml:msubsup><mml:mrow><mml:mover><mml:mi>w</mml:mi><mml:mo stretchy="false">→</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mspace width="thinmathspace"/><mml:mi>E</mml:mi></mml:mrow></mml:msubsup><mml:mo>)</mml:mo></mml:mrow><mml:mrow><mml:mi mathvariant="normal">⊤</mml:mi></mml:mrow></mml:msup><mml:mrow><mml:mover><mml:mi>s</mml:mi><mml:mo stretchy="false">→</mml:mo></mml:mover></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>−</mml:mo><mml:mi>τ</mml:mi><mml:munderover><mml:mo>∑</mml:mo><mml:mrow><mml:mi>j</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:msup><mml:mi>N</mml:mi><mml:mrow><mml:mi>I</mml:mi></mml:mrow></mml:msup></mml:mrow></mml:munderover><mml:msubsup><mml:mi>J</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow><mml:mrow><mml:mspace width="thinmathspace"/><mml:mi>E</mml:mi><mml:mi>I</mml:mi></mml:mrow></mml:msubsup><mml:msubsup><mml:mi>f</mml:mi><mml:mrow><mml:mi>j</mml:mi></mml:mrow><mml:mrow><mml:mspace width="thinmathspace"/><mml:mi>I</mml:mi></mml:mrow></mml:msubsup><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>−</mml:mo><mml:msup><mml:mi>β</mml:mi><mml:mrow><mml:mi>E</mml:mi></mml:mrow></mml:msup><mml:mo stretchy="false">(</mml:mo><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:mfrac><mml:mi>τ</mml:mi><mml:msubsup><mml:mi>τ</mml:mi><mml:mrow><mml:mi>r</mml:mi></mml:mrow><mml:mrow><mml:mi>E</mml:mi></mml:mrow></mml:msubsup></mml:mfrac><mml:mo stretchy="false">)</mml:mo><mml:msubsup><mml:mi>r</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mi>E</mml:mi></mml:mrow></mml:msubsup><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mstyle></mml:mtd></mml:mtr><mml:mtr><mml:mtd/><mml:mtd><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mo>+</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mn>2</mml:mn></mml:mfrac><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>c</mml:mi><mml:mo>−</mml:mo><mml:msup><mml:mi>β</mml:mi><mml:mrow><mml:mi>E</mml:mi></mml:mrow></mml:msup></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>+</mml:mo><mml:msqrt><mml:mfrac><mml:mi>τ</mml:mi><mml:mn>2</mml:mn></mml:mfrac></mml:msqrt><mml:msubsup><mml:mi>σ</mml:mi><mml:mrow><mml:mi>ξ</mml:mi></mml:mrow><mml:mrow><mml:mi>E</mml:mi></mml:mrow></mml:msubsup><mml:msubsup><mml:mi>η</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mi>E</mml:mi></mml:mrow></mml:msubsup><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>,</mml:mo></mml:mstyle></mml:mtd></mml:mtr></mml:mtable></mml:mstyle></mml:mrow></mml:math></disp-formula><disp-formula id="equ31"><mml:math id="m31"><mml:mrow><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mtable columnalign="right left right left right left right left right left right left" rowspacing="3pt" columnspacing="0em 2em 0em 2em 0em 2em 0em 2em 0em 2em 0em" displaystyle="true"><mml:mtr><mml:mtd><mml:mi>τ</mml:mi><mml:msubsup><mml:mrow><mml:mover><mml:mi>V</mml:mi><mml:mo>˙</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mspace width="thinmathspace"/><mml:mi>I</mml:mi></mml:mrow></mml:msubsup><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mspace width="thinmathspace"/></mml:mtd><mml:mtd><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mo>−</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msubsup><mml:mi>V</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mspace width="thinmathspace"/><mml:mi>I</mml:mi></mml:mrow></mml:msubsup><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>−</mml:mo><mml:msubsup><mml:mi>V</mml:mi><mml:mrow><mml:mtext>rest</mml:mtext></mml:mrow><mml:mrow><mml:mspace width="thinmathspace"/><mml:mi>I</mml:mi></mml:mrow></mml:msubsup></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>+</mml:mo><mml:mi>τ</mml:mi><mml:munderover><mml:mo>∑</mml:mo><mml:mrow><mml:mi>j</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:msup><mml:mi>N</mml:mi><mml:mrow><mml:mi>E</mml:mi></mml:mrow></mml:msup></mml:mrow></mml:munderover><mml:msubsup><mml:mi>J</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow><mml:mrow><mml:mspace width="thinmathspace"/><mml:mi>I</mml:mi><mml:mi>E</mml:mi></mml:mrow></mml:msubsup><mml:msubsup><mml:mi>f</mml:mi><mml:mrow><mml:mi>j</mml:mi></mml:mrow><mml:mrow><mml:mspace width="thinmathspace"/><mml:mi>E</mml:mi></mml:mrow></mml:msubsup><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>−</mml:mo><mml:mi>τ</mml:mi><mml:munderover><mml:mo>∑</mml:mo><mml:mrow><mml:mstyle scriptlevel="1"><mml:mtable rowspacing="0.1em" columnspacing="0em" displaystyle="false"><mml:mtr><mml:mtd><mml:mi>j</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mi>i</mml:mi><mml:mo>≠</mml:mo><mml:mi>j</mml:mi></mml:mtd></mml:mtr></mml:mtable></mml:mstyle></mml:mrow><mml:mrow><mml:msup><mml:mi>N</mml:mi><mml:mrow><mml:mi>I</mml:mi></mml:mrow></mml:msup></mml:mrow></mml:munderover><mml:msubsup><mml:mi>J</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow><mml:mrow><mml:mspace width="thinmathspace"/><mml:mi>I</mml:mi><mml:mi>I</mml:mi></mml:mrow></mml:msubsup><mml:msubsup><mml:mi>f</mml:mi><mml:mi>j</mml:mi><mml:mrow><mml:mspace width="thinmathspace"/><mml:mi>I</mml:mi></mml:mrow></mml:msubsup><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>−</mml:mo><mml:msup><mml:mi>β</mml:mi><mml:mrow><mml:mi>I</mml:mi></mml:mrow></mml:msup><mml:mo stretchy="false">(</mml:mo><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:mfrac><mml:mi>τ</mml:mi><mml:msubsup><mml:mi>τ</mml:mi><mml:mrow><mml:mi>r</mml:mi></mml:mrow><mml:mrow><mml:mi>I</mml:mi></mml:mrow></mml:msubsup></mml:mfrac><mml:mo stretchy="false">)</mml:mo><mml:msubsup><mml:mi>r</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mi>I</mml:mi></mml:mrow></mml:msubsup><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mstyle></mml:mtd></mml:mtr><mml:mtr><mml:mtd/><mml:mtd><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mo>+</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mn>2</mml:mn></mml:mfrac><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>c</mml:mi><mml:mo>−</mml:mo><mml:msup><mml:mi>β</mml:mi><mml:mrow><mml:mi>I</mml:mi></mml:mrow></mml:msup></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>+</mml:mo><mml:msqrt><mml:mfrac><mml:mi>τ</mml:mi><mml:mn>2</mml:mn></mml:mfrac></mml:msqrt><mml:msubsup><mml:mi>σ</mml:mi><mml:mrow><mml:mi>ξ</mml:mi></mml:mrow><mml:mrow><mml:mi>I</mml:mi></mml:mrow></mml:msubsup><mml:msubsup><mml:mi>η</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mi>I</mml:mi></mml:mrow></mml:msubsup><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>,</mml:mo></mml:mstyle></mml:mtd></mml:mtr></mml:mtable></mml:mstyle></mml:mrow></mml:math></disp-formula><disp-formula id="equ32"><label>(28)</label><mml:math id="m32"><mml:mrow><mml:mtable columnalign="right left right left right left right left right left right left" rowspacing="3pt" columnspacing="0em 2em 0em 2em 0em 2em 0em 2em 0em 2em 0em" displaystyle="true"><mml:mtr><mml:mtd/><mml:mtd><mml:mtext>if</mml:mtext><mml:mspace width="thinmathspace"/><mml:mspace width="thinmathspace"/><mml:msubsup><mml:mi>V</mml:mi><mml:mi>i</mml:mi><mml:mrow><mml:mspace width="thinmathspace"/><mml:mi>y</mml:mi></mml:mrow></mml:msubsup><mml:mo stretchy="false">(</mml:mo><mml:msup><mml:mi>t</mml:mi><mml:mo>−</mml:mo></mml:msup><mml:mo stretchy="false">)</mml:mo><mml:mo>≥</mml:mo><mml:msubsup><mml:mi>ϑ</mml:mi><mml:mi>i</mml:mi><mml:mi>y</mml:mi></mml:msubsup><mml:mo stretchy="false">→</mml:mo><mml:msubsup><mml:mi>V</mml:mi><mml:mi>i</mml:mi><mml:mrow><mml:mspace width="thinmathspace"/><mml:mi>y</mml:mi></mml:mrow></mml:msubsup><mml:mo stretchy="false">(</mml:mo><mml:msup><mml:mi>t</mml:mi><mml:mo>+</mml:mo></mml:msup><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:msubsup><mml:mi>V</mml:mi><mml:mi>i</mml:mi><mml:mrow><mml:mspace width="thinmathspace"/><mml:mi>y</mml:mi><mml:mo>,</mml:mo><mml:mtext>reset</mml:mtext></mml:mrow></mml:msubsup><mml:mo>,</mml:mo></mml:mtd></mml:mtr><mml:mtr><mml:mtd/><mml:mtd><mml:msubsup><mml:mi>ϑ</mml:mi><mml:mi>i</mml:mi><mml:mi>y</mml:mi></mml:msubsup><mml:mo>=</mml:mo><mml:msubsup><mml:mi>V</mml:mi><mml:mrow><mml:mtext>rest</mml:mtext></mml:mrow><mml:mrow><mml:mspace width="thinmathspace"/><mml:mi>y</mml:mi></mml:mrow></mml:msubsup><mml:mo>+</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mn>2</mml:mn></mml:mfrac><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msup><mml:mrow><mml:mo symmetric="true">‖</mml:mo><mml:msubsup><mml:mrow><mml:mover><mml:mi>w</mml:mi><mml:mo stretchy="false">→</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mspace width="thinmathspace"/><mml:mi>y</mml:mi></mml:mrow></mml:msubsup><mml:mo symmetric="true">‖</mml:mo></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup><mml:mo>+</mml:mo><mml:mi>c</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>,</mml:mo></mml:mtd></mml:mtr><mml:mtr><mml:mtd/><mml:mtd><mml:msubsup><mml:mi>V</mml:mi><mml:mi>i</mml:mi><mml:mrow><mml:mspace width="thinmathspace"/><mml:mi>E</mml:mi><mml:mo>,</mml:mo><mml:mtext>reset</mml:mtext></mml:mrow></mml:msubsup><mml:mo>=</mml:mo><mml:msubsup><mml:mi>V</mml:mi><mml:mrow><mml:mtext>rest</mml:mtext></mml:mrow><mml:mi>E</mml:mi></mml:msubsup><mml:mo>−</mml:mo><mml:msup><mml:mi>β</mml:mi><mml:mi>E</mml:mi></mml:msup><mml:mo>+</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mn>2</mml:mn></mml:mfrac><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>c</mml:mi><mml:mo>+</mml:mo><mml:msup><mml:mrow><mml:mo symmetric="true">‖</mml:mo><mml:msubsup><mml:mrow><mml:mover><mml:mi>w</mml:mi><mml:mo stretchy="false">→</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mspace width="thinmathspace"/><mml:mi>E</mml:mi></mml:mrow></mml:msubsup><mml:mo symmetric="true">‖</mml:mo></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>,</mml:mo></mml:mtd></mml:mtr><mml:mtr><mml:mtd/><mml:mtd><mml:msubsup><mml:mi>V</mml:mi><mml:mi>i</mml:mi><mml:mrow><mml:mspace width="thinmathspace"/><mml:mi>I</mml:mi><mml:mo>,</mml:mo><mml:mtext>reset</mml:mtext></mml:mrow></mml:msubsup><mml:mo>=</mml:mo><mml:msubsup><mml:mi>V</mml:mi><mml:mrow><mml:mtext>rest</mml:mtext></mml:mrow><mml:mi>I</mml:mi></mml:msubsup><mml:mo>−</mml:mo><mml:msup><mml:mi>β</mml:mi><mml:mi>I</mml:mi></mml:msup><mml:mo>+</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mn>2</mml:mn></mml:mfrac><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>c</mml:mi><mml:mo>−</mml:mo><mml:msup><mml:mrow><mml:mo symmetric="true">‖</mml:mo><mml:msubsup><mml:mrow><mml:mover><mml:mi>w</mml:mi><mml:mo stretchy="false">→</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mspace width="thinmathspace"/><mml:mi>I</mml:mi></mml:mrow></mml:msubsup><mml:mo symmetric="true">‖</mml:mo></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>,</mml:mo></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:math></disp-formula></p><p>where <inline-formula><mml:math id="inf363"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msubsup><mml:mi>η</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>i</mml:mi></mml:mrow><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>E</mml:mi></mml:mrow></mml:msubsup><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mstyle></mml:math></inline-formula> and <inline-formula><mml:math id="inf364"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msubsup><mml:mi>η</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>i</mml:mi></mml:mrow><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>I</mml:mi></mml:mrow></mml:msubsup><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mstyle></mml:math></inline-formula> are the independent Gaussian white noise processes defined in <xref ref-type="disp-formula" rid="equ13">Equation 13</xref> above. We note that all terms on the right-hand side of <xref ref-type="disp-formula" rid="equ32">Equation 28</xref> have the desired units of mV. The model in <xref ref-type="disp-formula" rid="equ32">Equation 28</xref> is an efficient E-I spiking network with improved compatibility with neurobiology. We have expressed two new terms in the membrane potentials of E and I neurons, one dependent on the metabolic constant <inline-formula><mml:math id="inf365"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msup><mml:mi>β</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>y</mml:mi></mml:mrow></mml:msup></mml:mstyle></mml:math></inline-formula> and one on the noise that we assumed in the condition for spiking (see <xref ref-type="disp-formula" rid="equ12">Equation 12</xref>). We will group these two terms to define an external current, a current that is well known in spiking models of neural dynamics (<xref ref-type="bibr" rid="bib37">Gerstner et al., 2014</xref>).</p></sec></sec><sec id="s4-6"><title>Efficient generalized leaky integrate-and-fire neuron model</title><p>Finally, we rewrite the model from <xref ref-type="disp-formula" rid="equ32">Equation 28</xref> in a compact form in terms of transmembrane currents, and discuss their biological interpretation. The efficient coding with spikes is realized by the following model for the neuron <inline-formula><mml:math id="inf366"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>i</mml:mi></mml:mstyle></mml:math></inline-formula> of type <inline-formula><mml:math id="inf367"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>y</mml:mi><mml:mo>∈</mml:mo><mml:mo fence="false" stretchy="false">{</mml:mo><mml:mi>E</mml:mi><mml:mo>,</mml:mo><mml:mi>I</mml:mi><mml:mo fence="false" stretchy="false">}</mml:mo></mml:mstyle></mml:math></inline-formula>:<disp-formula id="equ33"><label>(29a)</label><mml:math id="m33"><mml:mrow><mml:mtable columnalign="right left right left right left right left right left right left" rowspacing="3pt" columnspacing="0em 2em 0em 2em 0em 2em 0em 2em 0em 2em 0em" displaystyle="true"><mml:mtr><mml:mtd><mml:mi>τ</mml:mi><mml:msubsup><mml:mrow><mml:mover><mml:mi>V</mml:mi><mml:mo>˙</mml:mo></mml:mover></mml:mrow><mml:mi>i</mml:mi><mml:mrow><mml:mspace width="thinmathspace"/><mml:mi>E</mml:mi></mml:mrow></mml:msubsup><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mtd><mml:mtd><mml:mi/><mml:mo>=</mml:mo><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mo>−</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msubsup><mml:mi>V</mml:mi><mml:mi>i</mml:mi><mml:mrow><mml:mspace width="thinmathspace"/><mml:mi>E</mml:mi></mml:mrow></mml:msubsup><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>−</mml:mo><mml:msubsup><mml:mi>V</mml:mi><mml:mrow><mml:mtext>rest</mml:mtext></mml:mrow><mml:mrow><mml:mspace width="thinmathspace"/><mml:mi>E</mml:mi></mml:mrow></mml:msubsup></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>+</mml:mo><mml:msub><mml:mi>R</mml:mi><mml:mi>m</mml:mi></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msubsup><mml:mi>I</mml:mi><mml:mi>i</mml:mi><mml:mrow><mml:mspace width="thinmathspace"/><mml:mtext>syn</mml:mtext><mml:mo>,</mml:mo><mml:mi>E</mml:mi></mml:mrow></mml:msubsup><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>−</mml:mo><mml:msubsup><mml:mi>I</mml:mi><mml:mi>i</mml:mi><mml:mrow><mml:mspace width="thinmathspace"/><mml:mtext>ad</mml:mtext><mml:mo>,</mml:mo><mml:mi>E</mml:mi></mml:mrow></mml:msubsup><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>+</mml:mo><mml:msubsup><mml:mi>I</mml:mi><mml:mi>i</mml:mi><mml:mrow><mml:mspace width="thinmathspace"/><mml:mtext>ext</mml:mtext><mml:mo>,</mml:mo><mml:mi>E</mml:mi></mml:mrow></mml:msubsup><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>,</mml:mo></mml:mstyle></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mi>τ</mml:mi><mml:msubsup><mml:mrow><mml:mover><mml:mi>V</mml:mi><mml:mo>˙</mml:mo></mml:mover></mml:mrow><mml:mi>i</mml:mi><mml:mrow><mml:mspace width="thinmathspace"/><mml:mi>I</mml:mi></mml:mrow></mml:msubsup><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mtd><mml:mtd><mml:mi/><mml:mo>=</mml:mo><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mo>−</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msubsup><mml:mi>V</mml:mi><mml:mi>i</mml:mi><mml:mrow><mml:mspace width="thinmathspace"/><mml:mi>I</mml:mi></mml:mrow></mml:msubsup><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>−</mml:mo><mml:msubsup><mml:mi>V</mml:mi><mml:mrow><mml:mtext>rest</mml:mtext></mml:mrow><mml:mrow><mml:mspace width="thinmathspace"/><mml:mi>I</mml:mi></mml:mrow></mml:msubsup></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>+</mml:mo><mml:msub><mml:mi>R</mml:mi><mml:mi>m</mml:mi></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msubsup><mml:mi>I</mml:mi><mml:mi>i</mml:mi><mml:mrow><mml:mspace width="thinmathspace"/><mml:mtext>syn</mml:mtext><mml:mo>,</mml:mo><mml:mi>I</mml:mi></mml:mrow></mml:msubsup><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>−</mml:mo><mml:msubsup><mml:mi>I</mml:mi><mml:mi>i</mml:mi><mml:mrow><mml:mspace width="thinmathspace"/><mml:mtext>ad</mml:mtext><mml:mo>,</mml:mo><mml:mi>I</mml:mi></mml:mrow></mml:msubsup><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>+</mml:mo><mml:msubsup><mml:mi>I</mml:mi><mml:mi>i</mml:mi><mml:mrow><mml:mspace width="thinmathspace"/><mml:mtext>ext</mml:mtext><mml:mo>,</mml:mo><mml:mi>I</mml:mi></mml:mrow></mml:msubsup><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>,</mml:mo></mml:mstyle></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mtext>if</mml:mtext><mml:mspace width="thinmathspace"/><mml:mspace width="thinmathspace"/><mml:msubsup><mml:mi>V</mml:mi><mml:mi>i</mml:mi><mml:mrow><mml:mspace width="thinmathspace"/><mml:mi>y</mml:mi></mml:mrow></mml:msubsup><mml:mo stretchy="false">(</mml:mo><mml:msup><mml:mi>t</mml:mi><mml:mo>−</mml:mo></mml:msup><mml:mo stretchy="false">)</mml:mo></mml:mtd><mml:mtd><mml:mi/><mml:mo>≥</mml:mo><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msubsup><mml:mi>ϑ</mml:mi><mml:mi>i</mml:mi><mml:mi>y</mml:mi></mml:msubsup><mml:mo stretchy="false">→</mml:mo><mml:msubsup><mml:mi>V</mml:mi><mml:mi>i</mml:mi><mml:mrow><mml:mspace width="thinmathspace"/><mml:mi>y</mml:mi></mml:mrow></mml:msubsup><mml:mo stretchy="false">(</mml:mo><mml:msup><mml:mi>t</mml:mi><mml:mo>+</mml:mo></mml:msup><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:msubsup><mml:mi>V</mml:mi><mml:mi>i</mml:mi><mml:mrow><mml:mspace width="thinmathspace"/><mml:mi>y</mml:mi><mml:mo>,</mml:mo><mml:mtext>reset</mml:mtext></mml:mrow></mml:msubsup><mml:mo>,</mml:mo></mml:mstyle></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:msubsup><mml:mi>ϑ</mml:mi><mml:mi>i</mml:mi><mml:mrow><mml:mspace width="thinmathspace"/><mml:mi>y</mml:mi></mml:mrow></mml:msubsup></mml:mtd><mml:mtd><mml:mi/><mml:mo>=</mml:mo><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msubsup><mml:mi>V</mml:mi><mml:mrow><mml:mtext>rest</mml:mtext></mml:mrow><mml:mi>y</mml:mi></mml:msubsup><mml:mo>+</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mn>2</mml:mn></mml:mfrac><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msup><mml:mrow><mml:mo symmetric="true">‖</mml:mo><mml:msubsup><mml:mrow><mml:mover><mml:mi>w</mml:mi><mml:mo stretchy="false">→</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mspace width="thinmathspace"/><mml:mi>y</mml:mi></mml:mrow></mml:msubsup><mml:mo symmetric="true">‖</mml:mo></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup><mml:mo>+</mml:mo><mml:mi>c</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>,</mml:mo></mml:mstyle></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:msubsup><mml:mi>V</mml:mi><mml:mi>i</mml:mi><mml:mrow><mml:mspace width="thinmathspace"/><mml:mi>E</mml:mi><mml:mo>,</mml:mo><mml:mtext>reset</mml:mtext></mml:mrow></mml:msubsup></mml:mtd><mml:mtd><mml:mi/><mml:mo>=</mml:mo><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msubsup><mml:mi>V</mml:mi><mml:mrow><mml:mtext>rest</mml:mtext></mml:mrow><mml:mrow><mml:mspace width="thinmathspace"/><mml:mi>E</mml:mi></mml:mrow></mml:msubsup><mml:mo>−</mml:mo><mml:msup><mml:mi>β</mml:mi><mml:mi>E</mml:mi></mml:msup><mml:mo>+</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mn>2</mml:mn></mml:mfrac><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>c</mml:mi><mml:mo>+</mml:mo><mml:msup><mml:mrow><mml:mo symmetric="true">‖</mml:mo><mml:msubsup><mml:mrow><mml:mover><mml:mi>w</mml:mi><mml:mo stretchy="false">→</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mspace width="thinmathspace"/><mml:mi>E</mml:mi></mml:mrow></mml:msubsup><mml:mo symmetric="true">‖</mml:mo></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>,</mml:mo></mml:mstyle></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:msubsup><mml:mi>V</mml:mi><mml:mi>i</mml:mi><mml:mrow><mml:mspace width="thinmathspace"/><mml:mi>I</mml:mi><mml:mo>,</mml:mo><mml:mtext>reset</mml:mtext></mml:mrow></mml:msubsup></mml:mtd><mml:mtd><mml:mi/><mml:mo>=</mml:mo><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msubsup><mml:mi>V</mml:mi><mml:mrow><mml:mtext>rest</mml:mtext></mml:mrow><mml:mrow><mml:mspace width="thinmathspace"/><mml:mi>I</mml:mi></mml:mrow></mml:msubsup><mml:mo>−</mml:mo><mml:msup><mml:mi>β</mml:mi><mml:mi>I</mml:mi></mml:msup><mml:mo>+</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mn>2</mml:mn></mml:mfrac><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>c</mml:mi><mml:mo>−</mml:mo><mml:msup><mml:mrow><mml:mo symmetric="true">‖</mml:mo><mml:msubsup><mml:mrow><mml:mover><mml:mi>w</mml:mi><mml:mo stretchy="false">→</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mspace width="thinmathspace"/><mml:mi>I</mml:mi></mml:mrow></mml:msubsup><mml:mo symmetric="true">‖</mml:mo></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>,</mml:mo></mml:mstyle></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:math></disp-formula></p><p>with <inline-formula><mml:math id="inf368"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msub><mml:mi>R</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>m</mml:mi></mml:mrow></mml:msub></mml:mstyle></mml:math></inline-formula> the current resistance. The leak current,<disp-formula id="equ34"><label>(29b)</label><mml:math id="m34"><mml:mrow><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msubsup><mml:mi>I</mml:mi><mml:mi>i</mml:mi><mml:mrow><mml:mspace width="thinmathspace"/><mml:mtext>leak</mml:mtext><mml:mo>,</mml:mo><mml:mi>y</mml:mi></mml:mrow></mml:msubsup><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mo>−</mml:mo><mml:mfrac><mml:msub><mml:mi>C</mml:mi><mml:mi>m</mml:mi></mml:msub><mml:mi>τ</mml:mi></mml:mfrac><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msubsup><mml:mi>V</mml:mi><mml:mi>i</mml:mi><mml:mrow><mml:mspace width="thinmathspace"/><mml:mi>y</mml:mi></mml:mrow></mml:msubsup><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>−</mml:mo><mml:msubsup><mml:mi>V</mml:mi><mml:mrow><mml:mtext>rest</mml:mtext></mml:mrow><mml:mrow><mml:mspace width="thinmathspace"/><mml:mi>y</mml:mi></mml:mrow></mml:msubsup></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>,</mml:mo><mml:mspace width="2em"/><mml:mi>y</mml:mi><mml:mo>∈</mml:mo><mml:mo fence="false" stretchy="false">{</mml:mo><mml:mi>E</mml:mi><mml:mo>,</mml:mo><mml:mi>I</mml:mi><mml:mo fence="false" stretchy="false">}</mml:mo><mml:mo>,</mml:mo></mml:mstyle></mml:mrow></mml:math></disp-formula></p><p>with <inline-formula><mml:math id="inf369"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>τ</mml:mi><mml:mo>=</mml:mo><mml:msub><mml:mi>R</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>m</mml:mi></mml:mrow></mml:msub><mml:msub><mml:mi>C</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>m</mml:mi></mml:mrow></mml:msub></mml:mstyle></mml:math></inline-formula> and <inline-formula><mml:math id="inf370"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msub><mml:mi>C</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>m</mml:mi></mml:mrow></mml:msub></mml:mstyle></mml:math></inline-formula> the capacitance of the neural membrane (<xref ref-type="bibr" rid="bib16">Burkitt, 2006</xref>), arose by assuming the same time constant for the target signals <inline-formula><mml:math id="inf371"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow class="MJX-TeXAtom-ORD"><mml:mover><mml:mi>x</mml:mi><mml:mo stretchy="false">→</mml:mo></mml:mover></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mstyle></mml:math></inline-formula> and estimates <inline-formula><mml:math id="inf372"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msup><mml:mrow class="MJX-TeXAtom-ORD"><mml:mover><mml:mrow class="MJX-TeXAtom-ORD"><mml:mrow class="MJX-TeXAtom-ORD"><mml:mover><mml:mi>x</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow></mml:mrow><mml:mo stretchy="false">→</mml:mo></mml:mover></mml:mrow><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>E</mml:mi></mml:mrow></mml:msup><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mstyle></mml:math></inline-formula> and <inline-formula><mml:math id="inf373"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msup><mml:mrow class="MJX-TeXAtom-ORD"><mml:mover><mml:mrow class="MJX-TeXAtom-ORD"><mml:mrow class="MJX-TeXAtom-ORD"><mml:mover><mml:mi>x</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow></mml:mrow><mml:mo stretchy="false">→</mml:mo></mml:mover></mml:mrow><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>I</mml:mi></mml:mrow></mml:msup><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mstyle></mml:math></inline-formula> (see <xref ref-type="disp-formula" rid="equ8 equ20">Equations 8 and 18</xref>). We see that the passive membrane time constant <inline-formula><mml:math id="inf374"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>τ</mml:mi><mml:mo>=</mml:mo><mml:msup><mml:mi>λ</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msup></mml:mstyle></mml:math></inline-formula> can be traced back to the time constant of the population read-out in <xref ref-type="disp-formula" rid="equ9">Equation 9</xref>. The synaptic currents are defined as<disp-formula id="equ35"><label>(29c)</label><mml:math id="m35"><mml:mrow><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mtable columnalign="right left right left right left right left right left right left" rowspacing="3pt" columnspacing="0em 2em 0em 2em 0em 2em 0em 2em 0em 2em 0em" displaystyle="true"><mml:mtr><mml:mtd><mml:msubsup><mml:mi>I</mml:mi><mml:mi>i</mml:mi><mml:mrow><mml:mspace width="thinmathspace"/><mml:mtext>syn</mml:mtext><mml:mo>,</mml:mo><mml:mi>E</mml:mi></mml:mrow></mml:msubsup><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mtd><mml:mtd><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mo>=</mml:mo><mml:msub><mml:mi>C</mml:mi><mml:mi>m</mml:mi></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msubsup><mml:mrow><mml:mover><mml:mi>w</mml:mi><mml:mo stretchy="false">→</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mspace width="thinmathspace"/><mml:mi>E</mml:mi></mml:mrow></mml:msubsup><mml:msup><mml:mo stretchy="false">)</mml:mo><mml:mrow><mml:mi mathvariant="normal">⊤</mml:mi></mml:mrow></mml:msup><mml:mrow><mml:mover><mml:mi>s</mml:mi><mml:mo stretchy="false">→</mml:mo></mml:mover></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>−</mml:mo><mml:munderover><mml:mo>∑</mml:mo><mml:mrow><mml:mi>j</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mspace width="thinmathspace"/><mml:msup><mml:mi>N</mml:mi><mml:mrow><mml:mspace width="thinmathspace"/><mml:mi>I</mml:mi></mml:mrow></mml:msup></mml:mrow></mml:munderover><mml:msubsup><mml:mi>J</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow><mml:mrow><mml:mspace width="thinmathspace"/><mml:mi>E</mml:mi><mml:mi>I</mml:mi></mml:mrow></mml:msubsup><mml:msubsup><mml:mi>f</mml:mi><mml:mrow><mml:mi>j</mml:mi></mml:mrow><mml:mrow><mml:mspace width="thinmathspace"/><mml:mi>I</mml:mi></mml:mrow></mml:msubsup><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>,</mml:mo></mml:mstyle></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:msubsup><mml:mi>I</mml:mi><mml:mi>i</mml:mi><mml:mrow><mml:mspace width="thinmathspace"/><mml:mtext>syn</mml:mtext><mml:mo>,</mml:mo><mml:mi>I</mml:mi></mml:mrow></mml:msubsup><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mtd><mml:mtd><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mo>=</mml:mo><mml:msub><mml:mi>C</mml:mi><mml:mi>m</mml:mi></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:munderover><mml:mo>∑</mml:mo><mml:mrow><mml:mi>j</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:msup><mml:mi>N</mml:mi><mml:mrow><mml:mspace width="thinmathspace"/><mml:mi>E</mml:mi></mml:mrow></mml:msup></mml:mrow></mml:munderover><mml:msubsup><mml:mi>J</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow><mml:mrow><mml:mspace width="thinmathspace"/><mml:mi>I</mml:mi><mml:mi>E</mml:mi></mml:mrow></mml:msubsup><mml:msubsup><mml:mi>f</mml:mi><mml:mi>j</mml:mi><mml:mrow><mml:mspace width="thinmathspace"/><mml:mi>E</mml:mi></mml:mrow></mml:msubsup><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>−</mml:mo><mml:munderover><mml:mo>∑</mml:mo><mml:mrow><mml:mstyle scriptlevel="1"><mml:mtable rowspacing="0.1em" columnspacing="0em" displaystyle="false"><mml:mtr><mml:mtd><mml:mi>j</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mi>i</mml:mi><mml:mo>≠</mml:mo><mml:mi>j</mml:mi></mml:mtd></mml:mtr></mml:mtable></mml:mstyle></mml:mrow><mml:mrow><mml:msup><mml:mi>N</mml:mi><mml:mrow><mml:mspace width="thinmathspace"/><mml:mi>I</mml:mi></mml:mrow></mml:msup></mml:mrow></mml:munderover><mml:msubsup><mml:mi>J</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow><mml:mrow><mml:mspace width="thinmathspace"/><mml:mi>I</mml:mi><mml:mi>I</mml:mi></mml:mrow></mml:msubsup><mml:msubsup><mml:mi>f</mml:mi><mml:mrow><mml:mi>j</mml:mi></mml:mrow><mml:mrow><mml:mspace width="thinmathspace"/><mml:mi>I</mml:mi></mml:mrow></mml:msubsup><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>,</mml:mo></mml:mstyle></mml:mtd></mml:mtr></mml:mtable></mml:mstyle></mml:mrow></mml:math></disp-formula></p><p>where we note the presence of a feedforward current to E neurons,<disp-formula id="equ36"><label>(29d)</label><mml:math id="m36"><mml:mrow><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mtable columnalign="right left right left right left right left right left right left" rowspacing="3pt" columnspacing="0em 2em 0em 2em 0em 2em 0em 2em 0em 2em 0em" displaystyle="true"><mml:mtr><mml:mtd><mml:msubsup><mml:mi>I</mml:mi><mml:mi>i</mml:mi><mml:mrow><mml:mtext>ff</mml:mtext></mml:mrow></mml:msubsup><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mtd><mml:mtd><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mo>=</mml:mo><mml:msub><mml:mi>C</mml:mi><mml:mi>m</mml:mi></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:msubsup><mml:mrow><mml:mover><mml:mi>w</mml:mi><mml:mo stretchy="false">→</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mspace width="thinmathspace"/><mml:mi>E</mml:mi></mml:mrow></mml:msubsup><mml:msup><mml:mo stretchy="false">)</mml:mo><mml:mrow><mml:mi mathvariant="normal">⊤</mml:mi></mml:mrow></mml:msup><mml:mrow><mml:mover><mml:mi>s</mml:mi><mml:mo stretchy="false">→</mml:mo></mml:mover></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>,</mml:mo></mml:mstyle></mml:mtd></mml:mtr><mml:mtr><mml:mtd/><mml:mtd><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mo>=</mml:mo><mml:msub><mml:mi>C</mml:mi><mml:mi>m</mml:mi></mml:msub><mml:munderover><mml:mo>∑</mml:mo><mml:mrow><mml:mi>k</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>M</mml:mi></mml:munderover><mml:msubsup><mml:mi>w</mml:mi><mml:mrow><mml:mi>k</mml:mi><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mspace width="thinmathspace"/><mml:mi>E</mml:mi></mml:mrow></mml:msubsup><mml:msub><mml:mi>s</mml:mi><mml:mi>k</mml:mi></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>,</mml:mo></mml:mstyle></mml:mtd></mml:mtr></mml:mtable></mml:mstyle></mml:mrow></mml:math></disp-formula></p><p>which consist in a linear combination of the stimulus features <inline-formula><mml:math id="inf375"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow class="MJX-TeXAtom-ORD"><mml:mover><mml:mi>s</mml:mi><mml:mo stretchy="false">→</mml:mo></mml:mover></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mstyle></mml:math></inline-formula> weighted by the decoding weights <inline-formula><mml:math id="inf376"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msubsup><mml:mrow class="MJX-TeXAtom-ORD"><mml:mover><mml:mi>w</mml:mi><mml:mo stretchy="false">→</mml:mo></mml:mover></mml:mrow><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>i</mml:mi></mml:mrow><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>E</mml:mi></mml:mrow></mml:msubsup></mml:mstyle></mml:math></inline-formula>. The stimulus features can be traced back to the definition of the target signals in <xref ref-type="disp-formula" rid="equ8">Equation 8</xref>. This current emerges in E neurons, as a consequence of having the target signal <inline-formula><mml:math id="inf377"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow class="MJX-TeXAtom-ORD"><mml:mover><mml:mi>x</mml:mi><mml:mo stretchy="false">→</mml:mo></mml:mover></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mstyle></mml:math></inline-formula> in the loss function of the E population (see <xref ref-type="disp-formula" rid="equ10 equ11">Equations 10 and 11</xref>). I neurons do not receive the feedforward current because their loss function does not contain the target signal.</p><p>The current providing within-neuron feedback triggered by each spike,<disp-formula id="equ37"><label>(29e)</label><mml:math id="m37"><mml:mrow><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msubsup><mml:mi>I</mml:mi><mml:mi>i</mml:mi><mml:mrow><mml:mspace width="thinmathspace"/><mml:mtext>ad</mml:mtext><mml:mo>,</mml:mo><mml:mi>y</mml:mi></mml:mrow></mml:msubsup><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:msub><mml:mi>C</mml:mi><mml:mi>m</mml:mi></mml:msub><mml:msup><mml:mi>β</mml:mi><mml:mi>y</mml:mi></mml:msup><mml:mo stretchy="false">(</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mi>τ</mml:mi></mml:mfrac><mml:mo>−</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:msubsup><mml:mi>τ</mml:mi><mml:mi>r</mml:mi><mml:mi>y</mml:mi></mml:msubsup></mml:mfrac><mml:mo stretchy="false">)</mml:mo><mml:msubsup><mml:mi>r</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mspace width="thinmathspace"/><mml:mi>y</mml:mi></mml:mrow></mml:msubsup><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>,</mml:mo></mml:mstyle></mml:mrow></mml:math></disp-formula></p><p>was recently recovered (<xref ref-type="bibr" rid="bib49">Koren and Panzeri, 2022</xref>). This current has the kinetics of the single neuron readout <inline-formula><mml:math id="inf378"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msubsup><mml:mi>r</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mspace width="thinmathspace"/><mml:mi>y</mml:mi></mml:mrow></mml:msubsup><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mstyle></mml:mrow></mml:mstyle></mml:math></inline-formula> (i.e. low-pass filtered spike train). Its sign depends on the relation between the time constant of the population readout <inline-formula><mml:math id="inf379"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>τ</mml:mi><mml:mo>=</mml:mo><mml:msup><mml:mi>λ</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:mstyle></mml:math></inline-formula> and single neuron readout <inline-formula><mml:math id="inf380"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mrow><mml:msubsup><mml:mi>τ</mml:mi><mml:mi>r</mml:mi><mml:mrow><mml:mspace width="thinmathspace"/><mml:mi>y</mml:mi></mml:mrow></mml:msubsup><mml:mo>=</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:msubsup><mml:mi>λ</mml:mi><mml:mrow><mml:mi>r</mml:mi></mml:mrow><mml:mrow><mml:mi>y</mml:mi></mml:mrow></mml:msubsup><mml:msup><mml:mo stretchy="false">)</mml:mo><mml:mrow><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:mrow></mml:mstyle></mml:math></inline-formula>, because the metabolic constant <inline-formula><mml:math id="inf381"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msup><mml:mi>β</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>y</mml:mi></mml:mrow></mml:msup></mml:mstyle></mml:math></inline-formula> is non-negative by definition (<xref ref-type="disp-formula" rid="equ10">Equation 10</xref>). If the single neuron readout is slower than the population readout, <inline-formula><mml:math id="inf382"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msubsup><mml:mi>τ</mml:mi><mml:mi>r</mml:mi><mml:mrow><mml:mspace width="thinmathspace"/><mml:mi>y</mml:mi></mml:mrow></mml:msubsup><mml:mo>&gt;</mml:mo><mml:mi>τ</mml:mi></mml:mrow></mml:mstyle></mml:math></inline-formula>, within-neuron feedback is negative, and can thus be interpreted as spike-triggered <italic>adaptation</italic>. On the contrary, if the single neuron readout is faster than the population readout, <inline-formula><mml:math id="inf383"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msubsup><mml:mi>τ</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>r</mml:mi></mml:mrow><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>E</mml:mi></mml:mrow></mml:msubsup><mml:mo>&lt;</mml:mo><mml:mi>τ</mml:mi></mml:mstyle></mml:math></inline-formula>, the within-neuron feedback is positive and can thus be interpreted as spike-triggered <italic>facilitation</italic>. In a special case where the time constant of the single neuron and population readout are assumed to be equal, within-neuron feedback vanishes.</p><p>Finally, we here derived the non-specific external current:<disp-formula id="equ38"><label>(29f)</label><mml:math id="m38"><mml:mrow><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msubsup><mml:mi>I</mml:mi><mml:mi>i</mml:mi><mml:mrow><mml:mspace width="thinmathspace"/><mml:mtext>ext</mml:mtext><mml:mo>,</mml:mo><mml:mi>y</mml:mi></mml:mrow></mml:msubsup><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:msub><mml:mi>C</mml:mi><mml:mi>m</mml:mi></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mfrac><mml:mrow><mml:mi>c</mml:mi><mml:mo>−</mml:mo><mml:msup><mml:mi>β</mml:mi><mml:mrow><mml:mspace width="thinmathspace"/><mml:mi>y</mml:mi></mml:mrow></mml:msup></mml:mrow><mml:mn>2</mml:mn></mml:mfrac><mml:mo>+</mml:mo><mml:msup><mml:mi>σ</mml:mi><mml:mrow><mml:mspace width="thinmathspace"/><mml:mi>y</mml:mi></mml:mrow></mml:msup><mml:msubsup><mml:mi>η</mml:mi><mml:mi>i</mml:mi><mml:mrow><mml:mspace width="thinmathspace"/><mml:mi>y</mml:mi></mml:mrow></mml:msubsup><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>,</mml:mo><mml:mspace width="2em"/><mml:msup><mml:mi>σ</mml:mi><mml:mrow><mml:mspace width="thinmathspace"/><mml:mi>y</mml:mi></mml:mrow></mml:msup><mml:mo>=</mml:mo><mml:mfrac><mml:msubsup><mml:mi>σ</mml:mi><mml:mrow><mml:mi>ξ</mml:mi></mml:mrow><mml:mrow><mml:mspace width="thinmathspace"/><mml:mi>y</mml:mi></mml:mrow></mml:msubsup><mml:msqrt><mml:mn>2</mml:mn><mml:mi>τ</mml:mi></mml:msqrt></mml:mfrac></mml:mstyle></mml:mrow></mml:math></disp-formula></p><p>that captures the ensemble of non-specific synaptic currents received by each single neuron. The non-specific current has a homogeneous mean across all neurons of the same cell type, and a neuron-specific fluctuation. The mean of the non-specific current can be traced back to the weighting of the metabolic cost over the encoding error in model objectives (<xref ref-type="disp-formula" rid="equ10">Equation 10</xref>), while the fluctuation can be traced back to the noise strength that we assumed in the condition for spiking (<xref ref-type="disp-formula" rid="equ12">Equation 12</xref>). The non-specific external current might arise because of synaptic inputs from other brain areas than the brain area that delivers feedforward projections to the E-I network we consider here, or it might result from synaptic activity of neurons that are part of the local network, but are not tuned to the feedforward input (<xref ref-type="bibr" rid="bib113">Zylberberg, 2018</xref>).</p><p>We also recall the fast and slower time scales of single neuron activity:<disp-formula id="equ39"><label>(29g)</label><mml:math id="m39"><mml:mrow><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mtable columnalign="right left right left right left right left right left right left" rowspacing="3pt" columnspacing="0em 2em 0em 2em 0em 2em 0em 2em 0em 2em 0em" displaystyle="true"><mml:mtr><mml:mtd><mml:msubsup><mml:mi>f</mml:mi><mml:mi>i</mml:mi><mml:mrow><mml:mspace width="thinmathspace"/><mml:mi>y</mml:mi></mml:mrow></mml:msubsup><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mtd><mml:mtd><mml:mi/><mml:mo>=</mml:mo><mml:mstyle displaystyle="true" scriptlevel="0"><mml:munder><mml:mo>∑</mml:mo><mml:mrow><mml:mi>α</mml:mi></mml:mrow></mml:munder><mml:mi>δ</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo>−</mml:mo><mml:msubsup><mml:mi>t</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mspace width="thinmathspace"/><mml:mi>y</mml:mi><mml:mo>,</mml:mo><mml:mi>α</mml:mi></mml:mrow></mml:msubsup><mml:mo stretchy="false">)</mml:mo><mml:mo>,</mml:mo></mml:mstyle></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mrow><mml:mover><mml:mrow><mml:msubsup><mml:mi>r</mml:mi><mml:mi>i</mml:mi><mml:mrow><mml:mspace width="thinmathspace"/><mml:mi>y</mml:mi></mml:mrow></mml:msubsup><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>˙</mml:mo></mml:mover></mml:mrow></mml:mtd><mml:mtd><mml:mi/><mml:mo>=</mml:mo><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mo>−</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:msubsup><mml:mi>τ</mml:mi><mml:mi>r</mml:mi><mml:mi>y</mml:mi></mml:msubsup><mml:msup><mml:mo stretchy="false">)</mml:mo><mml:mrow><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msup><mml:msubsup><mml:mi>r</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mspace width="thinmathspace"/><mml:mi>y</mml:mi></mml:mrow></mml:msubsup><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>+</mml:mo><mml:msubsup><mml:mi>f</mml:mi><mml:mi>i</mml:mi><mml:mrow><mml:mspace width="thinmathspace"/><mml:mi>y</mml:mi></mml:mrow></mml:msubsup><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>,</mml:mo></mml:mstyle></mml:mtd></mml:mtr></mml:mtable></mml:mstyle></mml:mrow></mml:math></disp-formula></p><p>and the connectivity matrices<disp-formula id="equ40"><label>(29h)</label><mml:math id="m40"><mml:mrow><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msubsup><mml:mi>J</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow><mml:mrow><mml:mspace width="thinmathspace"/><mml:mi>I</mml:mi><mml:mi>E</mml:mi></mml:mrow></mml:msubsup><mml:mo>=</mml:mo><mml:msub><mml:mrow><mml:mo>[</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msubsup><mml:mrow><mml:mover><mml:mi>w</mml:mi><mml:mo stretchy="false">→</mml:mo></mml:mover></mml:mrow><mml:mi>i</mml:mi><mml:mrow><mml:mi>I</mml:mi></mml:mrow></mml:msubsup><mml:msup><mml:mo stretchy="false">)</mml:mo><mml:mi mathvariant="normal">⊤</mml:mi></mml:msup><mml:msubsup><mml:mrow><mml:mover><mml:mi>w</mml:mi><mml:mo stretchy="false">→</mml:mo></mml:mover></mml:mrow><mml:mi>j</mml:mi><mml:mrow><mml:mi>E</mml:mi></mml:mrow></mml:msubsup></mml:mrow><mml:mo>]</mml:mo></mml:mrow><mml:mo>+</mml:mo></mml:msub><mml:mo>,</mml:mo><mml:mspace width="2em"/><mml:msubsup><mml:mi>J</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow><mml:mrow><mml:mspace width="thinmathspace"/><mml:mi>I</mml:mi><mml:mi>I</mml:mi></mml:mrow></mml:msubsup><mml:mo>=</mml:mo><mml:msub><mml:mrow><mml:mo>[</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msubsup><mml:mrow><mml:mover><mml:mi>w</mml:mi><mml:mo stretchy="false">→</mml:mo></mml:mover></mml:mrow><mml:mi>i</mml:mi><mml:mrow><mml:mi>I</mml:mi></mml:mrow></mml:msubsup><mml:msup><mml:mo stretchy="false">)</mml:mo><mml:mi mathvariant="normal">⊤</mml:mi></mml:msup><mml:msubsup><mml:mrow><mml:mover><mml:mi>w</mml:mi><mml:mo stretchy="false">→</mml:mo></mml:mover></mml:mrow><mml:mi>j</mml:mi><mml:mrow><mml:mi>I</mml:mi></mml:mrow></mml:msubsup></mml:mrow><mml:mo>]</mml:mo></mml:mrow><mml:mo>+</mml:mo></mml:msub><mml:mo>,</mml:mo><mml:mi>i</mml:mi><mml:mo>≠</mml:mo><mml:mi>j</mml:mi><mml:mo>,</mml:mo><mml:mspace width="2em"/><mml:msubsup><mml:mi>J</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow><mml:mrow><mml:mspace width="thinmathspace"/><mml:mi>E</mml:mi><mml:mi>I</mml:mi></mml:mrow></mml:msubsup><mml:mo>=</mml:mo><mml:msub><mml:mrow><mml:mo>[</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msubsup><mml:mrow><mml:mover><mml:mi>w</mml:mi><mml:mo stretchy="false">→</mml:mo></mml:mover></mml:mrow><mml:mi>i</mml:mi><mml:mrow><mml:mi>E</mml:mi></mml:mrow></mml:msubsup><mml:msup><mml:mo stretchy="false">)</mml:mo><mml:mi mathvariant="normal">⊤</mml:mi></mml:msup><mml:msubsup><mml:mrow><mml:mover><mml:mi>w</mml:mi><mml:mo stretchy="false">→</mml:mo></mml:mover></mml:mrow><mml:mi>j</mml:mi><mml:mrow><mml:mi>I</mml:mi></mml:mrow></mml:msubsup></mml:mrow><mml:mo>]</mml:mo></mml:mrow><mml:mo>+</mml:mo></mml:msub><mml:mo>.</mml:mo></mml:mstyle></mml:mrow></mml:math></disp-formula></p><p>The structure of synaptic connectivity is fully determined by the similarity of tuning vectors of the presynaptic and the postsynaptic neurons (<inline-formula><mml:math id="inf384"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msubsup><mml:mrow><mml:mover><mml:mi>w</mml:mi><mml:mo stretchy="false">→</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow><mml:mrow><mml:mspace width="thinmathspace"/><mml:mi>x</mml:mi></mml:mrow></mml:msubsup></mml:mstyle></mml:mrow></mml:mstyle></mml:math></inline-formula> and <inline-formula><mml:math id="inf385"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msubsup><mml:mrow><mml:mover><mml:mi>w</mml:mi><mml:mo stretchy="false">→</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mspace width="thinmathspace"/><mml:mi>y</mml:mi></mml:mrow></mml:msubsup></mml:mstyle></mml:mrow></mml:mstyle></mml:math></inline-formula>, respectively), while the distribution of synaptic connectivity weights is fully determined by the distribution of tuning parameters <inline-formula><mml:math id="inf386"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msubsup><mml:mi>w</mml:mi><mml:mrow><mml:mi>k</mml:mi><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mspace width="thinmathspace"/><mml:mi>y</mml:mi></mml:mrow></mml:msubsup></mml:mrow></mml:mstyle></mml:math></inline-formula>.</p></sec><sec id="s4-7"><title>Stimulus features</title><p>We define stimulus features <inline-formula><mml:math id="inf387"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow class="MJX-TeXAtom-ORD"><mml:mover><mml:mi>s</mml:mi><mml:mo stretchy="false">→</mml:mo></mml:mover></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mstyle></mml:math></inline-formula> as a set of <inline-formula><mml:math id="inf388"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>k</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mo>…</mml:mo><mml:mo>,</mml:mo><mml:mi>M</mml:mi></mml:mstyle></mml:math></inline-formula> independent Ornstein-Uhlenbeck processes with vanishing mean, standard deviation <inline-formula><mml:math id="inf389"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msup><mml:mi>σ</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>s</mml:mi></mml:mrow></mml:msup></mml:mstyle></mml:math></inline-formula> and the correlation time <inline-formula><mml:math id="inf390"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msubsup><mml:mi>τ</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>k</mml:mi></mml:mrow><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>s</mml:mi></mml:mrow></mml:msubsup></mml:mstyle></mml:math></inline-formula>,<disp-formula id="equ41"><label>(30)</label><mml:math id="m41"><mml:mrow><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msubsup><mml:mi>τ</mml:mi><mml:mi>k</mml:mi><mml:mi>s</mml:mi></mml:msubsup><mml:msub><mml:mrow><mml:mover><mml:mi>s</mml:mi><mml:mo>˙</mml:mo></mml:mover></mml:mrow><mml:mi>k</mml:mi></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mo>−</mml:mo><mml:msub><mml:mi>s</mml:mi><mml:mi>k</mml:mi></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>+</mml:mo><mml:msqrt><mml:mn>2</mml:mn><mml:msubsup><mml:mi>τ</mml:mi><mml:mi>k</mml:mi><mml:mi>s</mml:mi></mml:msubsup></mml:msqrt><mml:msup><mml:mi>σ</mml:mi><mml:mi>s</mml:mi></mml:msup><mml:msub><mml:mi>η</mml:mi><mml:mi>k</mml:mi></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>.</mml:mo></mml:mstyle></mml:mrow></mml:math></disp-formula></p><p>If not mentioned otherwise, we use the following parameters, identical across stimulus features: <inline-formula><mml:math id="inf391"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msup><mml:mi>σ</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>s</mml:mi></mml:mrow></mml:msup><mml:mo>=</mml:mo><mml:mn>2</mml:mn></mml:mstyle></mml:math></inline-formula> (mV)<sup>1/2</sup> and <inline-formula><mml:math id="inf392"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msubsup><mml:mi>τ</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>k</mml:mi></mml:mrow><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>s</mml:mi></mml:mrow></mml:msubsup><mml:mo>=</mml:mo><mml:msub><mml:mi>τ</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>s</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mn>10</mml:mn></mml:mstyle></mml:math></inline-formula> ms. Variables <inline-formula><mml:math id="inf393"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msub><mml:mi>η</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>k</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mstyle></mml:math></inline-formula> are independent Gaussian white noise processes with zero mean and covariance function <inline-formula><mml:math id="inf394"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mo fence="false" stretchy="false">⟨</mml:mo><mml:msub><mml:mi>η</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>k</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:msub><mml:mi>η</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>l</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:msup><mml:mi>t</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi class="MJX-variant" mathvariant="normal">′</mml:mi></mml:mrow></mml:msup><mml:mo stretchy="false">)</mml:mo><mml:mo fence="false" stretchy="false">⟩</mml:mo><mml:mo>=</mml:mo><mml:msub><mml:mi>δ</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>k</mml:mi><mml:mi>l</mml:mi></mml:mrow></mml:msub><mml:mi>δ</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo>−</mml:mo><mml:msup><mml:mi>t</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi class="MJX-variant" mathvariant="normal">′</mml:mi></mml:mrow></mml:msup><mml:mo stretchy="false">)</mml:mo></mml:mstyle></mml:math></inline-formula>. These variables should not be confused with the Gaussian white noises <inline-formula><mml:math id="inf395"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msubsup><mml:mi>η</mml:mi><mml:mrow><mml:mi>k</mml:mi></mml:mrow><mml:mrow><mml:mspace width="thinmathspace"/><mml:mi>y</mml:mi></mml:mrow></mml:msubsup><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mstyle></mml:mrow></mml:mstyle></mml:math></inline-formula> in <xref ref-type="disp-formula" rid="equ32">Equation 28</xref>.</p></sec><sec id="s4-8"><title>Parametrization of synaptic connectivity</title><p>In the efficient E-I model, synaptic weights <inline-formula><mml:math id="inf396"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msubsup><mml:mi>J</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow><mml:mrow><mml:mspace width="thinmathspace"/><mml:mi>y</mml:mi><mml:mi>x</mml:mi></mml:mrow></mml:msubsup></mml:mstyle></mml:mrow></mml:mstyle></mml:math></inline-formula> are parametrized by tuning parameters <inline-formula><mml:math id="inf397"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msubsup><mml:mi>w</mml:mi><mml:mrow><mml:mi>k</mml:mi><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mspace width="thinmathspace"/><mml:mi>y</mml:mi></mml:mrow></mml:msubsup></mml:mstyle></mml:mrow></mml:mstyle></mml:math></inline-formula> through <xref ref-type="disp-formula" rid="equ26">Equation 24</xref>. The total number of synapses in the E-I, I-I, and I-E connectivity matrices (including silent synapses with zero synaptic weight) is <inline-formula><mml:math id="inf398"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mrow><mml:msub><mml:mi>n</mml:mi><mml:mrow><mml:mtext>syn</mml:mtext></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mn>2</mml:mn><mml:msup><mml:mi>N</mml:mi><mml:mrow><mml:mi>E</mml:mi></mml:mrow></mml:msup><mml:msup><mml:mi>N</mml:mi><mml:mrow><mml:mspace width="thinmathspace"/><mml:mi>I</mml:mi></mml:mrow></mml:msup><mml:mo>+</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:msup><mml:mi>N</mml:mi><mml:mrow><mml:mspace width="thinmathspace"/><mml:mi>I</mml:mi></mml:mrow></mml:msup><mml:msup><mml:mo stretchy="false">)</mml:mo><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:mrow></mml:mstyle></mml:math></inline-formula>, while the number of tuning parameters is <inline-formula><mml:math id="inf399"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow class="MJX-TeXAtom-ORD"><mml:msub><mml:mi>n</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>w</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mi>M</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msup><mml:mi>N</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>E</mml:mi></mml:mrow></mml:msup><mml:mo>+</mml:mo><mml:msup><mml:mi>N</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>I</mml:mi></mml:mrow></mml:msup><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mstyle></mml:math></inline-formula>. Because the number of stimulus features <inline-formula><mml:math id="inf400"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>M</mml:mi></mml:mstyle></mml:math></inline-formula> is expected to be much smaller than the number of E or I neurons, the number of tuning parameters <inline-formula><mml:math id="inf401"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msub><mml:mi>n</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>w</mml:mi></mml:mrow></mml:msub></mml:mstyle></mml:math></inline-formula> is much smaller than the number of synapses <inline-formula><mml:math id="inf402"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msub><mml:mi>n</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mtext>syn</mml:mtext></mml:mrow></mml:msub></mml:mstyle></mml:math></inline-formula>.</p><p>We can achieve a further substantial decrease in the number of free parameters by using a parametric distribution of tuning parameters <inline-formula><mml:math id="inf403"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msubsup><mml:mi>w</mml:mi><mml:mrow><mml:mi>k</mml:mi><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mspace width="thinmathspace"/><mml:mi>y</mml:mi></mml:mrow></mml:msubsup></mml:mrow></mml:mstyle></mml:math></inline-formula>. We set the tuning parameters following a normal distribution and found that excellent performance can be achieved with random draws of tuning parameters from the normal distribution, thus without searching for a specific set of tuning parameters. This drastically decreased the number of free parameters relative to synaptic weights to only a handful of parameters that determine the distributions of tuning parameters.</p><p>Given <inline-formula><mml:math id="inf404"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>M</mml:mi></mml:mstyle></mml:math></inline-formula> features, we sampled tuning parameters, <inline-formula><mml:math id="inf405"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msubsup><mml:mrow><mml:mover><mml:mi>w</mml:mi><mml:mo stretchy="false">→</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mspace width="thinmathspace"/><mml:mi>y</mml:mi></mml:mrow></mml:msubsup><mml:mo>=</mml:mo><mml:mo stretchy="false">[</mml:mo><mml:msub><mml:mi>w</mml:mi><mml:mrow><mml:mn>1</mml:mn><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:mo>…</mml:mo><mml:mo>,</mml:mo><mml:msub><mml:mi>w</mml:mi><mml:mrow><mml:mi>M</mml:mi><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:msup><mml:mo stretchy="false">]</mml:mo><mml:mrow><mml:mi mathvariant="normal">⊤</mml:mi></mml:mrow></mml:msup></mml:mrow></mml:mstyle></mml:math></inline-formula>, with <inline-formula><mml:math id="inf406"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mo>…</mml:mo><mml:mo>,</mml:mo><mml:msup><mml:mi>N</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>y</mml:mi></mml:mrow></mml:msup></mml:mstyle></mml:math></inline-formula>, <inline-formula><mml:math id="inf407"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>y</mml:mi><mml:mo>∈</mml:mo><mml:mo fence="false" stretchy="false">{</mml:mo><mml:mi>E</mml:mi><mml:mo>,</mml:mo><mml:mi>I</mml:mi><mml:mo fence="false" stretchy="false">}</mml:mo></mml:mstyle></mml:math></inline-formula>, as random points uniformly distributed on a <inline-formula><mml:math id="inf408"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>M</mml:mi></mml:mstyle></mml:math></inline-formula>-dimensional sphere of radius <inline-formula><mml:math id="inf409"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msubsup><mml:mi>σ</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>w</mml:mi></mml:mrow><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>y</mml:mi></mml:mrow></mml:msubsup></mml:mstyle></mml:math></inline-formula>. We obtained this by sampling, for each neuron, a vector of <inline-formula><mml:math id="inf410"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>M</mml:mi></mml:mstyle></mml:math></inline-formula> i.i.d. standard Gaussian random variables, <inline-formula><mml:math id="inf411"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msubsup><mml:mrow><mml:mover><mml:mi>ξ</mml:mi><mml:mo stretchy="false">→</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mspace width="thinmathspace"/><mml:mi>y</mml:mi></mml:mrow></mml:msubsup><mml:mo>=</mml:mo><mml:mo stretchy="false">[</mml:mo><mml:msubsup><mml:mi>ξ</mml:mi><mml:mrow><mml:mn>1</mml:mn><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mspace width="thinmathspace"/><mml:mi>y</mml:mi></mml:mrow></mml:msubsup><mml:mo>,</mml:mo><mml:mo>…</mml:mo><mml:mo>,</mml:mo><mml:msubsup><mml:mi>ξ</mml:mi><mml:mrow><mml:mi>M</mml:mi><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mspace width="thinmathspace"/><mml:mi>y</mml:mi></mml:mrow></mml:msubsup><mml:msup><mml:mo stretchy="false">]</mml:mo><mml:mrow><mml:mi mathvariant="normal">⊤</mml:mi></mml:mrow></mml:msup></mml:mrow></mml:mstyle></mml:mrow></mml:mstyle></mml:math></inline-formula>, with <inline-formula><mml:math id="inf412"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msubsup><mml:mi>ξ</mml:mi><mml:mrow><mml:mi>k</mml:mi><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mspace width="thinmathspace"/><mml:mi>y</mml:mi></mml:mrow></mml:msubsup><mml:mo>∼</mml:mo><mml:mrow><mml:mi class="mathcal" mathvariant="script">N</mml:mi></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mstyle></mml:mrow></mml:mstyle></mml:math></inline-formula>, and normalizing the vector such as to have length equal to <inline-formula><mml:math id="inf413"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msubsup><mml:mi>σ</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>w</mml:mi></mml:mrow><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>y</mml:mi></mml:mrow></mml:msubsup></mml:mstyle></mml:math></inline-formula> (<xref ref-type="bibr" rid="bib67">Muller, 1959</xref>),<disp-formula id="equ42"><label>(31)</label><mml:math id="m42"><mml:mrow><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msubsup><mml:mrow><mml:mrow><mml:mover><mml:mi>w</mml:mi><mml:mo stretchy="false">→</mml:mo></mml:mover></mml:mrow></mml:mrow><mml:mi>i</mml:mi><mml:mrow><mml:mspace width="thinmathspace"/><mml:mi>y</mml:mi></mml:mrow></mml:msubsup><mml:mo>=</mml:mo><mml:msubsup><mml:mi>σ</mml:mi><mml:mi>w</mml:mi><mml:mrow><mml:mspace width="thinmathspace"/><mml:mi>y</mml:mi></mml:mrow></mml:msubsup><mml:mfrac><mml:msubsup><mml:mrow><mml:mover><mml:mi>ξ</mml:mi><mml:mo stretchy="false">→</mml:mo></mml:mover></mml:mrow><mml:mi>i</mml:mi><mml:mrow><mml:mspace width="thinmathspace"/><mml:mi>y</mml:mi></mml:mrow></mml:msubsup><mml:mrow><mml:mo fence="false" stretchy="false">‖</mml:mo><mml:msubsup><mml:mrow><mml:mover><mml:mi>ξ</mml:mi><mml:mo stretchy="false">→</mml:mo></mml:mover></mml:mrow><mml:mi>i</mml:mi><mml:mrow><mml:mspace width="thinmathspace"/><mml:mi>y</mml:mi></mml:mrow></mml:msubsup><mml:msub><mml:mo fence="false" stretchy="false">‖</mml:mo><mml:mn>2</mml:mn></mml:msub></mml:mrow></mml:mfrac><mml:mo>,</mml:mo><mml:mspace width="2em"/><mml:mi>y</mml:mi><mml:mo>∈</mml:mo><mml:mo fence="false" stretchy="false">{</mml:mo><mml:mi>E</mml:mi><mml:mo>,</mml:mo><mml:mi>I</mml:mi><mml:mo fence="false" stretchy="false">}</mml:mo><mml:mo>.</mml:mo></mml:mstyle></mml:mrow></mml:math></disp-formula></p><p>This ensures that the length of tuning vectors <inline-formula><mml:math id="inf414"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mspace width="thinmathspace"/><mml:msubsup><mml:mrow><mml:mover><mml:mi>w</mml:mi><mml:mo stretchy="false">→</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mspace width="thinmathspace"/><mml:mi>y</mml:mi></mml:mrow></mml:msubsup></mml:mrow></mml:mstyle></mml:math></inline-formula> in <xref ref-type="disp-formula" rid="equ42">Equation 31</xref> is homogeneous across neurons of the same cell type, that is <inline-formula><mml:math id="inf415"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mrow><mml:mo fence="false" stretchy="false">‖</mml:mo><mml:msubsup><mml:mrow><mml:mover><mml:mi>w</mml:mi><mml:mo stretchy="false">→</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mspace width="thinmathspace"/><mml:mi>y</mml:mi></mml:mrow></mml:msubsup><mml:msub><mml:mo fence="false" stretchy="false">‖</mml:mo><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub></mml:mrow><mml:mo>=</mml:mo><mml:msubsup><mml:mi>σ</mml:mi><mml:mrow><mml:mi>w</mml:mi></mml:mrow><mml:mrow><mml:mspace width="thinmathspace"/><mml:mi>y</mml:mi></mml:mrow></mml:msubsup></mml:mrow></mml:mstyle></mml:math></inline-formula>. Parameters <inline-formula><mml:math id="inf416"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msubsup><mml:mi>σ</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>w</mml:mi></mml:mrow><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>E</mml:mi></mml:mrow></mml:msubsup></mml:mstyle></mml:math></inline-formula> and <inline-formula><mml:math id="inf417"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msubsup><mml:mi>σ</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>w</mml:mi></mml:mrow><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>I</mml:mi></mml:mrow></mml:msubsup></mml:mstyle></mml:math></inline-formula> determine the heterogeneity (spread) of tuning parameters.</p><p>By combining <xref ref-type="disp-formula" rid="equ26">Equation 24</xref> and <xref ref-type="disp-formula" rid="equ42">Equation 31</xref>, we obtain the synaptic weights, <inline-formula><mml:math id="inf418"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msubsup><mml:mi>J</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow><mml:mrow><mml:mspace width="thinmathspace"/><mml:mi>y</mml:mi><mml:mi>x</mml:mi></mml:mrow></mml:msubsup></mml:mstyle></mml:mrow></mml:mstyle></mml:math></inline-formula>, as a function of the angle, <inline-formula><mml:math id="inf419"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msubsup><mml:mi>α</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>x</mml:mi><mml:mi>y</mml:mi></mml:mrow></mml:msubsup></mml:mstyle></mml:math></inline-formula>, between the tuning vectors of presynaptic neurons, <inline-formula><mml:math id="inf420"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msubsup><mml:mrow><mml:mover><mml:mi>w</mml:mi><mml:mo stretchy="false">→</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mspace width="thinmathspace"/><mml:mi>x</mml:mi></mml:mrow></mml:msubsup></mml:mstyle></mml:mrow></mml:mstyle></mml:math></inline-formula>, and postsynaptic neurons, <inline-formula><mml:math id="inf421"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msubsup><mml:mrow><mml:mover><mml:mi>w</mml:mi><mml:mo stretchy="false">→</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow><mml:mrow><mml:mspace width="thinmathspace"/><mml:mi>y</mml:mi></mml:mrow></mml:msubsup></mml:mstyle></mml:mrow></mml:mstyle></mml:math></inline-formula>,<disp-formula id="equ43"><label>(32)</label><mml:math id="m43"><mml:mrow><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msubsup><mml:mi>J</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow><mml:mrow><mml:mi>y</mml:mi><mml:mi>x</mml:mi></mml:mrow></mml:msubsup><mml:mo>=</mml:mo><mml:msubsup><mml:mi>σ</mml:mi><mml:mi>w</mml:mi><mml:mrow><mml:mspace width="thinmathspace"/><mml:mi>y</mml:mi></mml:mrow></mml:msubsup><mml:msubsup><mml:mi>σ</mml:mi><mml:mi>w</mml:mi><mml:mi>x</mml:mi></mml:msubsup><mml:msub><mml:mrow><mml:mo>[</mml:mo><mml:mrow><mml:mi>cos</mml:mi><mml:mo>⁡</mml:mo><mml:msubsup><mml:mi>α</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow><mml:mrow><mml:mspace width="thinmathspace"/><mml:mi>y</mml:mi><mml:mi>x</mml:mi></mml:mrow></mml:msubsup></mml:mrow><mml:mo>]</mml:mo></mml:mrow><mml:mo>+</mml:mo></mml:msub><mml:mo>.</mml:mo></mml:mstyle></mml:mrow></mml:math></disp-formula></p><p>In the <inline-formula><mml:math id="inf422"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>M</mml:mi><mml:mo>=</mml:mo><mml:mn>3</mml:mn></mml:mstyle></mml:math></inline-formula> dimensional case, we have that the distribution of the angle between two vectors is <inline-formula><mml:math id="inf423"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>p</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msubsup><mml:mi>α</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow><mml:mrow><mml:mspace width="thinmathspace"/><mml:mi>y</mml:mi><mml:mi>x</mml:mi></mml:mrow></mml:msubsup><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mn>2</mml:mn></mml:mfrac><mml:mi>sin</mml:mi><mml:mo>⁡</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:msubsup><mml:mi>α</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow><mml:mrow><mml:mspace width="thinmathspace"/><mml:mi>y</mml:mi><mml:mi>x</mml:mi></mml:mrow></mml:msubsup><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mstyle></mml:math></inline-formula>, with <inline-formula><mml:math id="inf424"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msubsup><mml:mi>α</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>y</mml:mi><mml:mi>x</mml:mi></mml:mrow></mml:msubsup><mml:mo>∈</mml:mo><mml:mo stretchy="false">[</mml:mo><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:mi>π</mml:mi><mml:mo stretchy="false">]</mml:mo></mml:mstyle></mml:math></inline-formula>. Thus, the average strength of synaptic weights between the pre- and the postsynaptic population can be calculated as<disp-formula id="equ44"><label>(33)</label><mml:math id="m44"><mml:mrow><mml:mtable columnalign="right left right left right left right left right left right left" rowspacing="3pt" columnspacing="0em 2em 0em 2em 0em 2em 0em 2em 0em 2em 0em" displaystyle="true"><mml:mtr><mml:mtd><mml:mo fence="false" stretchy="false">⟨</mml:mo><mml:msubsup><mml:mi>J</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow><mml:mrow><mml:mspace width="thinmathspace"/><mml:mi>y</mml:mi><mml:mi>x</mml:mi></mml:mrow></mml:msubsup><mml:mo fence="false" stretchy="false">⟩</mml:mo></mml:mtd><mml:mtd><mml:mi/><mml:mo>=</mml:mo><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mfrac><mml:mn>1</mml:mn><mml:mn>2</mml:mn></mml:mfrac><mml:msubsup><mml:mi>σ</mml:mi><mml:mi>w</mml:mi><mml:mrow><mml:mspace width="thinmathspace"/><mml:mi>y</mml:mi></mml:mrow></mml:msubsup><mml:msubsup><mml:mi>σ</mml:mi><mml:mi>w</mml:mi><mml:mrow><mml:mspace width="thinmathspace"/><mml:mi>x</mml:mi></mml:mrow></mml:msubsup><mml:msubsup><mml:mo>∫</mml:mo><mml:mn>0</mml:mn><mml:mi>π</mml:mi></mml:msubsup><mml:mi>d</mml:mi><mml:msubsup><mml:mi>α</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow><mml:mrow><mml:mspace width="thinmathspace"/><mml:mi>y</mml:mi><mml:mi>x</mml:mi></mml:mrow></mml:msubsup><mml:mi>sin</mml:mi><mml:mo>⁡</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:msubsup><mml:mi>α</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow><mml:mrow><mml:mspace width="thinmathspace"/><mml:mi>y</mml:mi><mml:mi>x</mml:mi></mml:mrow></mml:msubsup><mml:mo stretchy="false">)</mml:mo><mml:msub><mml:mrow><mml:mo>[</mml:mo><mml:mrow><mml:mi>cos</mml:mi><mml:mo>⁡</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:msubsup><mml:mi>α</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow><mml:mrow><mml:mspace width="thinmathspace"/><mml:mi>y</mml:mi><mml:mi>x</mml:mi></mml:mrow></mml:msubsup><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>]</mml:mo></mml:mrow><mml:mo>+</mml:mo></mml:msub></mml:mstyle></mml:mtd></mml:mtr><mml:mtr><mml:mtd/><mml:mtd><mml:mi/><mml:mo>=</mml:mo><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mfrac><mml:mn>1</mml:mn><mml:mn>4</mml:mn></mml:mfrac><mml:msubsup><mml:mi>σ</mml:mi><mml:mi>w</mml:mi><mml:mrow><mml:mspace width="thinmathspace"/><mml:mi>y</mml:mi></mml:mrow></mml:msubsup><mml:msubsup><mml:mi>σ</mml:mi><mml:mi>w</mml:mi><mml:mrow><mml:mspace width="thinmathspace"/><mml:mi>x</mml:mi></mml:mrow></mml:msubsup><mml:mo>.</mml:mo></mml:mstyle></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:math></disp-formula></p><p>Thus, the upper bound for the synaptic weight between cell types <inline-formula><mml:math id="inf425"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>x</mml:mi></mml:mstyle></mml:math></inline-formula> and <inline-formula><mml:math id="inf426"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>y</mml:mi></mml:mstyle></mml:math></inline-formula> is simply<disp-formula id="equ45"><label>(34)</label><mml:math id="m45"><mml:mrow><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mo movablelimits="true" form="prefix">max</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:msubsup><mml:mi>J</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow><mml:mrow><mml:mspace width="thinmathspace"/><mml:mi>y</mml:mi><mml:mi>x</mml:mi></mml:mrow></mml:msubsup><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:msubsup><mml:mi>σ</mml:mi><mml:mi>w</mml:mi><mml:mi>y</mml:mi></mml:msubsup><mml:msubsup><mml:mi>σ</mml:mi><mml:mi>w</mml:mi><mml:mi>x</mml:mi></mml:msubsup><mml:mo>.</mml:mo></mml:mstyle></mml:mrow></mml:math></disp-formula></p><p>From the <xref ref-type="disp-formula" rid="equ44">Equation 33</xref>, we have that the mean E-I connectivity is equal to the mean I-E connectivity, <inline-formula><mml:math id="inf427"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mo fence="false" stretchy="false">⟨</mml:mo><mml:msubsup><mml:mi>J</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow><mml:mrow><mml:mspace width="thinmathspace"/><mml:mi>E</mml:mi><mml:mi>I</mml:mi></mml:mrow></mml:msubsup><mml:mo fence="false" stretchy="false">⟩</mml:mo><mml:mo>=</mml:mo><mml:mo fence="false" stretchy="false">⟨</mml:mo><mml:msubsup><mml:mi>J</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow><mml:mrow><mml:mspace width="thinmathspace"/><mml:mi>I</mml:mi><mml:mi>E</mml:mi></mml:mrow></mml:msubsup><mml:mo fence="false" stretchy="false">⟩</mml:mo></mml:mrow></mml:mstyle></mml:math></inline-formula>. As we consider the ratio of the mean connectivity between I-I and E-I connections, we find that it is given by the following:<disp-formula id="equ46"><label>(35)</label><mml:math id="m46"><mml:mrow><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mfrac><mml:mrow><mml:mo fence="false" stretchy="false">⟨</mml:mo><mml:msubsup><mml:mi>J</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow><mml:mrow><mml:mi>I</mml:mi><mml:mi>I</mml:mi></mml:mrow></mml:msubsup><mml:mo fence="false" stretchy="false">⟩</mml:mo></mml:mrow><mml:mrow><mml:mo fence="false" stretchy="false">⟨</mml:mo><mml:msubsup><mml:mi>J</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow><mml:mrow><mml:mi>E</mml:mi><mml:mi>I</mml:mi></mml:mrow></mml:msubsup><mml:mo fence="false" stretchy="false">⟩</mml:mo></mml:mrow></mml:mfrac><mml:mo>=</mml:mo><mml:mfrac><mml:msup><mml:mrow><mml:mo>(</mml:mo><mml:msubsup><mml:mi>σ</mml:mi><mml:mi>w</mml:mi><mml:mrow><mml:mi>I</mml:mi></mml:mrow></mml:msubsup><mml:mo>)</mml:mo></mml:mrow><mml:mn>2</mml:mn></mml:msup><mml:mrow><mml:msubsup><mml:mi>σ</mml:mi><mml:mi>w</mml:mi><mml:mrow><mml:mi>I</mml:mi></mml:mrow></mml:msubsup><mml:msubsup><mml:mi>σ</mml:mi><mml:mi>w</mml:mi><mml:mi>E</mml:mi></mml:msubsup></mml:mrow></mml:mfrac><mml:mo>=</mml:mo><mml:mfrac><mml:msubsup><mml:mi>σ</mml:mi><mml:mi>w</mml:mi><mml:mrow><mml:mi>I</mml:mi></mml:mrow></mml:msubsup><mml:msubsup><mml:mi>σ</mml:mi><mml:mi>w</mml:mi><mml:mrow><mml:mi>E</mml:mi></mml:mrow></mml:msubsup></mml:mfrac><mml:mo>.</mml:mo></mml:mstyle></mml:mrow></mml:math></disp-formula></p></sec><sec id="s4-9"><title>Performance measures</title><sec id="s4-9-1"><title>Average encoding error and average metabolic cost</title><p>The definition of the time-dependent loss functions (<xref ref-type="disp-formula" rid="equ10">Equation 10</xref>) induces a natural choice for the performance measure: the mean squared error (MSE) between the targets and their estimators for each cell type. In the case of the E population, the time-dependent encoding error is captured by the variable <inline-formula><mml:math id="inf428"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msup><mml:mi>ϵ</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>E</mml:mi></mml:mrow></mml:msup><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mstyle></mml:math></inline-formula> in the <xref ref-type="disp-formula" rid="equ11">Equation 11</xref> and in case of I population it is captured by <inline-formula><mml:math id="inf429"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msup><mml:mi>ϵ</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>I</mml:mi></mml:mrow></mml:msup><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mstyle></mml:math></inline-formula> defined in the same equation. We used the root MSE (RMSE), a standard measure for the performance of an estimator (<xref ref-type="bibr" rid="bib37">Gerstner et al., 2014</xref>). For the cell type <inline-formula><mml:math id="inf430"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>y</mml:mi><mml:mo>∈</mml:mo><mml:mo fence="false" stretchy="false">{</mml:mo><mml:mi>E</mml:mi><mml:mo>,</mml:mo><mml:mi>I</mml:mi><mml:mo fence="false" stretchy="false">}</mml:mo></mml:mstyle></mml:math></inline-formula> in trial <inline-formula><mml:math id="inf431"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>q</mml:mi></mml:mstyle></mml:math></inline-formula>, the RMSE is measured as<disp-formula id="equ47"><label>(36)</label><mml:math id="m47"><mml:mrow><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msup><mml:mrow><mml:mi mathvariant="normal">R</mml:mi><mml:mi mathvariant="normal">M</mml:mi><mml:mi mathvariant="normal">S</mml:mi><mml:mi mathvariant="normal">E</mml:mi></mml:mrow><mml:mi>y</mml:mi></mml:msup><mml:mo>=</mml:mo><mml:msqrt><mml:mo fence="false" stretchy="false">⟨</mml:mo><mml:msubsup><mml:mi>ϵ</mml:mi><mml:mi>q</mml:mi><mml:mrow><mml:mspace width="thinmathspace"/><mml:mi>y</mml:mi></mml:mrow></mml:msubsup><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:msub><mml:mo fence="false" stretchy="false">⟩</mml:mo><mml:mrow><mml:mi>t</mml:mi><mml:mo>,</mml:mo><mml:mi>q</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo></mml:msqrt></mml:mstyle></mml:mrow></mml:math></disp-formula></p><p>with <inline-formula><mml:math id="inf432"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mo fence="false" stretchy="false">⟨</mml:mo><mml:msub><mml:mi>z</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>q</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:msub><mml:mo fence="false" stretchy="false">⟩</mml:mo><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>t</mml:mi><mml:mo>,</mml:mo><mml:mi>q</mml:mi></mml:mrow></mml:msub></mml:mstyle></mml:math></inline-formula> denoting the time- and trial-average.</p><p>Following the definition of the time-dependent metabolic cost in the loss functions (<xref ref-type="disp-formula" rid="equ10">Equation 10</xref>), we measured the average metabolic cost in a trial <inline-formula><mml:math id="inf433"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>q</mml:mi></mml:mstyle></mml:math></inline-formula> for the cell type <inline-formula><mml:math id="inf434"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>y</mml:mi><mml:mo>∈</mml:mo><mml:mo fence="false" stretchy="false">{</mml:mo><mml:mi>E</mml:mi><mml:mo>,</mml:mo><mml:mi>I</mml:mi><mml:mo fence="false" stretchy="false">}</mml:mo></mml:mstyle></mml:math></inline-formula> as<disp-formula id="equ48"><label>(37)</label><mml:math id="m48"><mml:mrow><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msup><mml:mrow><mml:mi mathvariant="normal">M</mml:mi><mml:mi mathvariant="normal">C</mml:mi></mml:mrow><mml:mrow><mml:mi>y</mml:mi></mml:mrow></mml:msup><mml:mo>=</mml:mo><mml:msqrt><mml:mo fence="false" stretchy="false">⟨</mml:mo><mml:msubsup><mml:mi>κ</mml:mi><mml:mi>q</mml:mi><mml:mrow><mml:mspace width="thinmathspace"/><mml:mi>y</mml:mi></mml:mrow></mml:msubsup><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:msub><mml:mo fence="false" stretchy="false">⟩</mml:mo><mml:mrow><mml:mi>t</mml:mi><mml:mo>,</mml:mo><mml:mi>q</mml:mi></mml:mrow></mml:msub></mml:msqrt><mml:mo>,</mml:mo></mml:mstyle></mml:mrow></mml:math></disp-formula></p><p>with time-dependent metabolic cost <inline-formula><mml:math id="inf435"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msup><mml:mi>κ</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>y</mml:mi></mml:mrow></mml:msup><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mstyle></mml:math></inline-formula> as in model’s objectives (<xref ref-type="disp-formula" rid="equ11">Equation 11</xref>) and <inline-formula><mml:math id="inf436"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mo fence="false" stretchy="false">⟨</mml:mo><mml:msub><mml:mi>z</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>q</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:msub><mml:mo fence="false" stretchy="false">⟩</mml:mo><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>t</mml:mi><mml:mo>,</mml:mo><mml:mi>q</mml:mi></mml:mrow></mml:msub></mml:mstyle></mml:math></inline-formula> the time- and trial-average. The square root was taken to have the same scale as for the RMSE (see <xref ref-type="disp-formula" rid="equ47">Equation 36</xref>).</p></sec><sec id="s4-9-2"><title>The bias of the estimator</title><p>The MSE can be decomposed into the bias and the variance of the estimator. The time-dependent bias of estimates <inline-formula><mml:math id="inf437"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msubsup><mml:mrow><mml:mover><mml:mi>x</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>k</mml:mi></mml:mrow><mml:mrow><mml:mspace width="thinmathspace"/><mml:mi>y</mml:mi></mml:mrow></mml:msubsup><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>,</mml:mo><mml:mtext> </mml:mtext><mml:mi>y</mml:mi><mml:mo>∈</mml:mo><mml:mo fence="false" stretchy="false">{</mml:mo><mml:mi>E</mml:mi><mml:mo>,</mml:mo><mml:mi>I</mml:mi><mml:mo fence="false" stretchy="false">}</mml:mo></mml:mrow></mml:mstyle></mml:math></inline-formula>, were evaluated for each time point over <inline-formula><mml:math id="inf438"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>q</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mo>…</mml:mo><mml:mo>,</mml:mo><mml:mi>Q</mml:mi></mml:mstyle></mml:math></inline-formula> trials. The time-dependent bias in input dimension <inline-formula><mml:math id="inf439"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>k</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mo>…</mml:mo><mml:mo>,</mml:mo><mml:mi>M</mml:mi></mml:mstyle></mml:math></inline-formula> is defined as<disp-formula id="equ49"><label>(38a)</label><mml:math id="m49"><mml:mrow><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mtable columnalign="right left right left right left right left right left right left" rowspacing="3pt" columnspacing="0em 2em 0em 2em 0em 2em 0em 2em 0em 2em 0em" displaystyle="true"><mml:mtr><mml:mtd><mml:msubsup><mml:mi>B</mml:mi><mml:mi>k</mml:mi><mml:mrow><mml:mspace width="thinmathspace"/><mml:mi>E</mml:mi></mml:mrow></mml:msubsup><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mtd><mml:mtd><mml:mi/><mml:mo>=</mml:mo><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mfrac><mml:mn>1</mml:mn><mml:mi>Q</mml:mi></mml:mfrac><mml:munderover><mml:mo>∑</mml:mo><mml:mrow><mml:mi>q</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>Q</mml:mi></mml:munderover><mml:mo stretchy="false">[</mml:mo><mml:msubsup><mml:mrow><mml:mover><mml:mi>x</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>k</mml:mi><mml:mo>,</mml:mo><mml:mi>q</mml:mi></mml:mrow><mml:mrow><mml:mspace width="thinmathspace"/><mml:mi>E</mml:mi></mml:mrow></mml:msubsup><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>−</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mi>k</mml:mi></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo stretchy="false">]</mml:mo><mml:mo>,</mml:mo></mml:mstyle></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:msubsup><mml:mi>B</mml:mi><mml:mi>k</mml:mi><mml:mrow><mml:mspace width="thinmathspace"/><mml:mi>I</mml:mi></mml:mrow></mml:msubsup><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mtd><mml:mtd><mml:mi/><mml:mo>=</mml:mo><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mfrac><mml:mn>1</mml:mn><mml:mi>Q</mml:mi></mml:mfrac><mml:munderover><mml:mo>∑</mml:mo><mml:mrow><mml:mi>q</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>Q</mml:mi></mml:munderover><mml:mo stretchy="false">[</mml:mo><mml:msubsup><mml:mrow><mml:mover><mml:mi>x</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>k</mml:mi><mml:mo>,</mml:mo><mml:mi>q</mml:mi></mml:mrow><mml:mrow><mml:mspace width="thinmathspace"/><mml:mi>I</mml:mi></mml:mrow></mml:msubsup><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>−</mml:mo><mml:mo fence="false" stretchy="false">⟨</mml:mo><mml:msubsup><mml:mrow><mml:mover><mml:mi>x</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>k</mml:mi><mml:mo>,</mml:mo><mml:mi>q</mml:mi></mml:mrow><mml:mrow><mml:mspace width="thinmathspace"/><mml:mi>E</mml:mi></mml:mrow></mml:msubsup><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:msub><mml:mo fence="false" stretchy="false">⟩</mml:mo><mml:mi>q</mml:mi></mml:msub><mml:mo stretchy="false">]</mml:mo><mml:mo>,</mml:mo></mml:mstyle></mml:mtd></mml:mtr></mml:mtable></mml:mstyle></mml:mrow></mml:math></disp-formula></p><p>with <inline-formula><mml:math id="inf440"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mo fence="false" stretchy="false">⟨</mml:mo><mml:msub><mml:mi>z</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>q</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:msub><mml:mo fence="false" stretchy="false">⟩</mml:mo><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>q</mml:mi></mml:mrow></mml:msub></mml:mstyle></mml:math></inline-formula> the trial-averaged realization at time <inline-formula><mml:math id="inf441"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>t</mml:mi></mml:mstyle></mml:math></inline-formula>. To have an average measure of the encoding bias, we averaged the bias of estimators over time and over input dimensions:<disp-formula id="equ50"><label>(38b)</label><mml:math id="m50"><mml:mrow><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msup><mml:mi>B</mml:mi><mml:mrow><mml:mspace width="thinmathspace"/><mml:mi>y</mml:mi></mml:mrow></mml:msup><mml:mo>=</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mrow><mml:mi>T</mml:mi><mml:mi>M</mml:mi></mml:mrow></mml:mfrac><mml:munderover><mml:mo>∑</mml:mo><mml:mrow><mml:mi>k</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>M</mml:mi></mml:munderover><mml:msubsup><mml:mo>∫</mml:mo><mml:mn>0</mml:mn><mml:mi>T</mml:mi></mml:msubsup><mml:msubsup><mml:mi>B</mml:mi><mml:mi>k</mml:mi><mml:mrow><mml:mspace width="thinmathspace"/><mml:mi>y</mml:mi></mml:mrow></mml:msubsup><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mi>d</mml:mi><mml:mi>t</mml:mi><mml:mo>.</mml:mo></mml:mstyle></mml:mrow></mml:math></disp-formula></p><p>The averaging over time and input dimensions is justified because <inline-formula><mml:math id="inf442"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msub><mml:mi>s</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>k</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mstyle></mml:math></inline-formula> are independent realizations of the Ornstein-Uhlenbeck process (see <xref ref-type="disp-formula" rid="equ41">Equation 30</xref>) with vanishing mean and with the same time constant, and variance across input dimensions.</p></sec><sec id="s4-9-3"><title>Criterion for determining optimal model parameters</title><p>The equations of the E-I spiking network in <xref ref-type="disp-formula" rid="equ33">Equation 29a</xref>, <xref ref-type="disp-formula" rid="equ34">Equation 29b</xref>, <xref ref-type="disp-formula" rid="equ35">Equation 29c</xref>, <xref ref-type="disp-formula" rid="equ36">Equation 29d</xref>, <xref ref-type="disp-formula" rid="equ37">Equation 29e</xref>, <xref ref-type="disp-formula" rid="equ38">Equation 29f</xref>, <xref ref-type="disp-formula" rid="equ39">Equation 29g</xref>, <xref ref-type="disp-formula" rid="equ40">Equation 29h</xref> (Materials and methods), derived from the instantaneous loss functions, give efficient coding solutions valid for any set of parameter values. However, to choose parameters values in simulated data in a principled way, we performed a numerical optimization of the performance function detailed below. Numerical optimization gave the set of optimal parameters listed in <xref ref-type="table" rid="table1">Table 1</xref>. When testing the efficient E-I model with simulations, we used the optimal parameters in <xref ref-type="table" rid="table1">Table 1</xref> and changed only the parameters plotted in the figure axes on a figure-by-figure basis.</p><p>To estimate the optimal set of parameters <inline-formula><mml:math id="inf443"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>θ</mml:mi><mml:mo>=</mml:mo><mml:msup><mml:mi>θ</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mo>∗</mml:mo></mml:mrow></mml:msup></mml:mstyle></mml:math></inline-formula>, we performed a grid search on each parameter <inline-formula><mml:math id="inf444"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msub><mml:mi>θ</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:mstyle></mml:math></inline-formula> while keeping all other parameters fixed as specified in <xref ref-type="table" rid="table1">Table 1</xref>. While varying the parameters, we measured a weighted sum of the time- and trial-averaged encoding error and metabolic cost. For each cell type <inline-formula><mml:math id="inf445"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>y</mml:mi><mml:mo>∈</mml:mo><mml:mo fence="false" stretchy="false">{</mml:mo><mml:mi>E</mml:mi><mml:mo>,</mml:mo><mml:mi>I</mml:mi><mml:mo fence="false" stretchy="false">}</mml:mo></mml:mstyle></mml:math></inline-formula>, we computed<disp-formula id="equ51"><label>(39a)</label><mml:math id="m51"><mml:mrow><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msubsup><mml:mrow><mml:mi class="mathcal" mathvariant="script">L</mml:mi></mml:mrow><mml:mi>θ</mml:mi><mml:mi>y</mml:mi></mml:msubsup><mml:mo>=</mml:mo><mml:msub><mml:mi>g</mml:mi><mml:mi>L</mml:mi></mml:msub><mml:msqrt><mml:mo fence="false" stretchy="false">⟨</mml:mo><mml:msubsup><mml:mi>ϵ</mml:mi><mml:mi>q</mml:mi><mml:mrow><mml:mspace width="thinmathspace"/><mml:mi>y</mml:mi></mml:mrow></mml:msubsup><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo>∣</mml:mo><mml:mi>θ</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:msub><mml:mo fence="false" stretchy="false">⟩</mml:mo><mml:mrow><mml:mi>t</mml:mi><mml:mo>,</mml:mo><mml:mi>q</mml:mi></mml:mrow></mml:msub></mml:msqrt><mml:mo>+</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:msub><mml:mi>g</mml:mi><mml:mi>L</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:msqrt><mml:mo fence="false" stretchy="false">⟨</mml:mo><mml:msubsup><mml:mi>κ</mml:mi><mml:mi>q</mml:mi><mml:mrow><mml:mspace width="thinmathspace"/><mml:mi>y</mml:mi></mml:mrow></mml:msubsup><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo>∣</mml:mo><mml:mi>θ</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:msub><mml:mo fence="false" stretchy="false">⟩</mml:mo><mml:mrow><mml:mi>t</mml:mi><mml:mo>,</mml:mo><mml:mi>q</mml:mi></mml:mrow></mml:msub></mml:msqrt><mml:mo>,</mml:mo></mml:mstyle></mml:mrow></mml:math></disp-formula></p><p>with <inline-formula><mml:math id="inf446"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mo fence="false" stretchy="false">⟨</mml:mo><mml:msub><mml:mi>z</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>q</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:msub><mml:mo fence="false" stretchy="false">⟩</mml:mo><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>t</mml:mi><mml:mo>,</mml:mo><mml:mi>q</mml:mi></mml:mrow></mml:msub></mml:mstyle></mml:math></inline-formula> the average over time and over trials and with <inline-formula><mml:math id="inf447"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msup><mml:mi>ϵ</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>y</mml:mi></mml:mrow></mml:msup><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mstyle></mml:math></inline-formula> and <inline-formula><mml:math id="inf448"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msup><mml:mi>κ</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>y</mml:mi></mml:mrow></mml:msup><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mstyle></mml:math></inline-formula> as in model’s objectives (<xref ref-type="disp-formula" rid="equ11">Equation 11</xref>), where <inline-formula><mml:math id="inf449"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>g</mml:mi><mml:mi>L</mml:mi></mml:msub><mml:mo>∈</mml:mo><mml:mo stretchy="false">[</mml:mo><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">]</mml:mo></mml:mrow></mml:mstyle></mml:math></inline-formula> is a weighting factor.</p><p>To optimize the performance measure, we used a value of <inline-formula><mml:math id="inf450"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msub><mml:mi>g</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>L</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mn>0.7</mml:mn></mml:mstyle></mml:math></inline-formula>. The parameter <inline-formula><mml:math id="inf451"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msub><mml:mi>g</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>L</mml:mi></mml:mrow></mml:msub></mml:mstyle></mml:math></inline-formula> in the <xref ref-type="disp-formula" rid="equ51">Equation 39a</xref> regulates the relative importance of the average encoding error over the average metabolic cost. Since the performance measure in <xref ref-type="disp-formula" rid="equ51">Equation 39a</xref> is closely related to the average over time and trials of the instantaneous loss function (<xref ref-type="disp-formula" rid="equ10">Equation 10</xref>) where the parameter <inline-formula><mml:math id="inf452"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>β</mml:mi></mml:mstyle></mml:math></inline-formula> regulates the relative weight of instantaneous encoding error over the metabolic cost, setting <inline-formula><mml:math id="inf453"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msub><mml:mi>g</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>L</mml:mi></mml:mrow></mml:msub></mml:mstyle></mml:math></inline-formula> is effectively achieved by setting <inline-formula><mml:math id="inf454"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>β</mml:mi></mml:mstyle></mml:math></inline-formula>.</p><p>The optimal parameter set <inline-formula><mml:math id="inf455"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>θ</mml:mi><mml:mo>=</mml:mo><mml:msup><mml:mi>θ</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mo>∗</mml:mo></mml:mrow></mml:msup></mml:mstyle></mml:math></inline-formula> reported in <xref ref-type="table" rid="table1">Table 1</xref> is the parameter set that minimizes the sum of losses across E and I cell type<disp-formula id="equ52"><label>(39b)</label><mml:math id="m52"><mml:mrow><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msup><mml:mi>θ</mml:mi><mml:mo>∗</mml:mo></mml:msup><mml:mo>=</mml:mo><mml:msub><mml:mrow><mml:mi mathvariant="normal">a</mml:mi><mml:mi mathvariant="normal">r</mml:mi><mml:mi mathvariant="normal">g</mml:mi><mml:mspace width="thinmathspace"/><mml:mi mathvariant="normal">m</mml:mi><mml:mi mathvariant="normal">i</mml:mi><mml:mi mathvariant="normal">n</mml:mi></mml:mrow><mml:mrow><mml:mi>θ</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msubsup><mml:mrow><mml:mi class="mathcal" mathvariant="script">L</mml:mi></mml:mrow><mml:mi>θ</mml:mi><mml:mi>E</mml:mi></mml:msubsup><mml:mo>+</mml:mo><mml:msubsup><mml:mrow><mml:mi class="mathcal" mathvariant="script">L</mml:mi></mml:mrow><mml:mi>θ</mml:mi><mml:mi>I</mml:mi></mml:msubsup></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>.</mml:mo></mml:mstyle></mml:mrow></mml:math></disp-formula></p><p>For visualization of the behavior of the average metabolic cost (<xref ref-type="disp-formula" rid="equ48">Equation 37</xref>) and average loss (<xref ref-type="disp-formula" rid="equ51">Equation 39a</xref>) across a range of a specific parameter <inline-formula><mml:math id="inf456"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msub><mml:mi>θ</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:mstyle></mml:math></inline-formula>, we summed these measures across the E and I cell type and normalized them across the range of tested parameters.</p><p>The exact neural dynamics and performance of our model depends on the realizations of random variables which describe the the tuning parameters <inline-formula><mml:math id="inf457"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msubsup><mml:mi>w</mml:mi><mml:mrow><mml:mi>k</mml:mi><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mi>y</mml:mi></mml:mrow></mml:msubsup></mml:mrow></mml:mstyle></mml:math></inline-formula>, the Gaussian noise in the non-specific currents <inline-formula><mml:math id="inf458"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msubsup><mml:mi>η</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mspace width="thinmathspace"/><mml:mi>y</mml:mi></mml:mrow></mml:msubsup><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mstyle></mml:math></inline-formula>, and the initial conditions of the membrane potential <inline-formula><mml:math id="inf459"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msubsup><mml:mi>V</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mspace width="thinmathspace"/><mml:mi>y</mml:mi></mml:mrow></mml:msubsup><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo>=</mml:mo><mml:mn>0</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mstyle></mml:math></inline-formula>, that were randomly drawn from a normal distribution in each simulation trial. To capture the performance of a ‘typical’ network, we iterated the performance measures across trials with different realizations of these random variables, and averaged the performance measures across trials. We typically used 100 simulation trials for each parameter value.</p></sec></sec><sec id="s4-10"><title>Functional activity measures</title><sec id="s4-10-1"><title>Tuning similarity</title><p>The pairwise tuning similarity was measured as the cosine similarity (<xref ref-type="bibr" rid="bib59">Luo et al., 2018</xref>), defined as:<disp-formula id="equ53"><label>(40)</label><mml:math id="m53"><mml:mrow><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msubsup><mml:mi mathvariant="normal">Φ</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow><mml:mrow><mml:mi>y</mml:mi><mml:mi>x</mml:mi></mml:mrow></mml:msubsup><mml:mo>=</mml:mo><mml:mi>cos</mml:mi><mml:mo>⁡</mml:mo><mml:mi>α</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msubsup><mml:mrow><mml:mover><mml:mi>w</mml:mi><mml:mo stretchy="false">→</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mspace width="thinmathspace"/><mml:mi>y</mml:mi></mml:mrow></mml:msubsup><mml:mo>,</mml:mo><mml:msubsup><mml:mrow><mml:mover><mml:mi>w</mml:mi><mml:mo stretchy="false">→</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow><mml:mrow><mml:mi>x</mml:mi><mml:mspace width="thinmathspace"/></mml:mrow></mml:msubsup><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msubsup><mml:mrow><mml:mover><mml:mi>w</mml:mi><mml:mo stretchy="false">→</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mspace width="thinmathspace"/><mml:mi>y</mml:mi></mml:mrow></mml:msubsup><mml:msup><mml:mo stretchy="false">)</mml:mo><mml:mi mathvariant="normal">⊤</mml:mi></mml:msup><mml:msubsup><mml:mrow><mml:mover><mml:mi>w</mml:mi><mml:mo stretchy="false">→</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow><mml:mrow><mml:mspace width="thinmathspace"/><mml:mi>x</mml:mi></mml:mrow></mml:msubsup></mml:mrow><mml:mrow><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:msubsup><mml:mrow><mml:mover><mml:mi>w</mml:mi><mml:mo stretchy="false">→</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mspace width="thinmathspace"/><mml:mi>y</mml:mi></mml:mrow></mml:msubsup><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:msub><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mn>2</mml:mn></mml:msub><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:msubsup><mml:mrow><mml:mover><mml:mi>w</mml:mi><mml:mo stretchy="false">→</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow><mml:mrow><mml:mspace width="thinmathspace"/><mml:mi>x</mml:mi></mml:mrow></mml:msubsup><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:msub><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mn>2</mml:mn></mml:msub></mml:mrow></mml:mfrac><mml:mo>,</mml:mo><mml:mspace width="2em"/><mml:mi>y</mml:mi><mml:mo>,</mml:mo><mml:mi>x</mml:mi><mml:mo>∈</mml:mo><mml:mo fence="false" stretchy="false">{</mml:mo><mml:mi>E</mml:mi><mml:mo>,</mml:mo><mml:mi>I</mml:mi><mml:mo fence="false" stretchy="false">}</mml:mo><mml:mo>,</mml:mo></mml:mstyle></mml:mrow></mml:math></disp-formula></p><p>with <inline-formula><mml:math id="inf460"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:msubsup><mml:mrow><mml:mover><mml:mi>w</mml:mi><mml:mo stretchy="false">→</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mspace width="thinmathspace"/><mml:mi>y</mml:mi></mml:mrow></mml:msubsup><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:msub><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:msqrt><mml:munderover><mml:mo>∑</mml:mo><mml:mrow><mml:mi>k</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>M</mml:mi></mml:mrow></mml:munderover><mml:mo stretchy="false">(</mml:mo><mml:msubsup><mml:mi>w</mml:mi><mml:mrow><mml:mi>k</mml:mi><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mspace width="thinmathspace"/><mml:mi>y</mml:mi></mml:mrow></mml:msubsup><mml:msup><mml:mo stretchy="false">)</mml:mo><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:msqrt></mml:mrow></mml:mstyle></mml:math></inline-formula> the length of the tuning vector in Euclidean space and <inline-formula><mml:math id="inf461"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>α</mml:mi></mml:mstyle></mml:math></inline-formula> the angle between the tuning vectors <inline-formula><mml:math id="inf462"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msubsup><mml:mrow><mml:mover><mml:mi>w</mml:mi><mml:mo stretchy="false">→</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow><mml:mrow><mml:mspace width="thinmathspace"/><mml:mi>x</mml:mi></mml:mrow></mml:msubsup></mml:mrow></mml:mstyle></mml:math></inline-formula> and <inline-formula><mml:math id="inf463"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msubsup><mml:mrow><mml:mover><mml:mi>w</mml:mi><mml:mo stretchy="false">→</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mspace width="thinmathspace"/><mml:mi>y</mml:mi></mml:mrow></mml:msubsup></mml:mrow></mml:mstyle></mml:math></inline-formula>.</p></sec><sec id="s4-10-2"><title>Cross-correlograms of spike timing</title><p>The time-dependent coordination of spike timing was measured with the cross-correlogram (CCG) of spike trains, corrected for stimulus-driven coincident spiking. The raw cross-correlogram (CCG) for neuron <inline-formula><mml:math id="inf464"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>i</mml:mi></mml:mstyle></mml:math></inline-formula> of cell type <inline-formula><mml:math id="inf465"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>y</mml:mi></mml:mstyle></mml:math></inline-formula> and neuron <inline-formula><mml:math id="inf466"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>j</mml:mi></mml:mstyle></mml:math></inline-formula> of cell type <inline-formula><mml:math id="inf467"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>x</mml:mi></mml:mstyle></mml:math></inline-formula> was measured as follows:<disp-formula id="equ54"><label>(41a)</label><mml:math id="m54"><mml:mrow><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msubsup><mml:mi>C</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow><mml:mrow><mml:mspace width="thinmathspace"/><mml:mi>y</mml:mi><mml:mi>x</mml:mi></mml:mrow></mml:msubsup><mml:mo stretchy="false">(</mml:mo><mml:mi>τ</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mi>Q</mml:mi></mml:mfrac><mml:munderover><mml:mo movablelimits="false">∑</mml:mo><mml:mrow><mml:mi>q</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>Q</mml:mi></mml:mrow></mml:munderover><mml:msubsup><mml:mo>∫</mml:mo><mml:mrow><mml:mn>0</mml:mn></mml:mrow><mml:mrow><mml:mi>T</mml:mi></mml:mrow></mml:msubsup><mml:mspace width="thinmathspace"/><mml:msubsup><mml:mi>f</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>q</mml:mi></mml:mrow><mml:mrow><mml:mspace width="thinmathspace"/><mml:mi>y</mml:mi></mml:mrow></mml:msubsup><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:msubsup><mml:mi>f</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>q</mml:mi></mml:mrow><mml:mrow><mml:mspace width="thinmathspace"/><mml:mi>y</mml:mi></mml:mrow></mml:msubsup><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo>+</mml:mo><mml:mi>τ</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mspace width="thinmathspace"/><mml:mi>d</mml:mi><mml:mi>t</mml:mi><mml:mo>,</mml:mo></mml:mstyle></mml:mrow></mml:math></disp-formula></p><p>with <inline-formula><mml:math id="inf468"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>q</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mo>…</mml:mo><mml:mo>,</mml:mo><mml:mi>Q</mml:mi></mml:mstyle></mml:math></inline-formula> simulation trials with identical stimulus and <inline-formula><mml:math id="inf469"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>T</mml:mi></mml:mstyle></mml:math></inline-formula> the duration of the trial. We subtracted from the raw CCG the CCG of trial-invariant activity. To evaluate the trial-invariant cross-correlogram, we first computed the peri-stimulus time histogram (PSTH) for each neuron as follows:<disp-formula id="equ55"><label>(41b)</label><mml:math id="m55"><mml:mrow><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msubsup><mml:mi>P</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mspace width="thinmathspace"/><mml:mi>y</mml:mi></mml:mrow></mml:msubsup><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mi>Q</mml:mi></mml:mfrac><mml:munderover><mml:mo movablelimits="false">∑</mml:mo><mml:mrow><mml:mi>q</mml:mi><mml:mo>=</mml:mo><mml:mn>0</mml:mn></mml:mrow><mml:mrow><mml:mi>Q</mml:mi></mml:mrow></mml:munderover><mml:msubsup><mml:mi>f</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>q</mml:mi></mml:mrow><mml:mrow><mml:mspace width="thinmathspace"/><mml:mi>y</mml:mi></mml:mrow></mml:msubsup><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>.</mml:mo></mml:mstyle></mml:mrow></mml:math></disp-formula></p><p>The trial-invariant CCG was then evaluated as the cross-correlation function of PSTHs between neurons <inline-formula><mml:math id="inf470"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>i</mml:mi></mml:mstyle></mml:math></inline-formula> and <inline-formula><mml:math id="inf471"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>j</mml:mi></mml:mstyle></mml:math></inline-formula>,<disp-formula id="equ56"><label>(41c)</label><mml:math id="m56"><mml:mrow><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msubsup><mml:mi>S</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow><mml:mrow><mml:mspace width="thinmathspace"/><mml:mi>y</mml:mi><mml:mi>x</mml:mi></mml:mrow></mml:msubsup><mml:mo stretchy="false">(</mml:mo><mml:mi>τ</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:msubsup><mml:mo>∫</mml:mo><mml:mn>0</mml:mn><mml:mi>T</mml:mi></mml:msubsup><mml:msubsup><mml:mi>P</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mspace width="thinmathspace"/><mml:mi>y</mml:mi></mml:mrow></mml:msubsup><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:msubsup><mml:mi>P</mml:mi><mml:mrow><mml:mi>j</mml:mi></mml:mrow><mml:mrow><mml:mspace width="thinmathspace"/><mml:mi>x</mml:mi></mml:mrow></mml:msubsup><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo>+</mml:mo><mml:mi>τ</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mi>d</mml:mi><mml:mi>t</mml:mi><mml:mo>.</mml:mo></mml:mstyle></mml:mrow></mml:math></disp-formula></p><p>Finally, the temporal coordination of spike timing was computed by subtracting the correction term from the raw CCG:<disp-formula id="equ57"><label>(41d)</label><mml:math id="m57"><mml:mrow><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msubsup><mml:mi>c</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow><mml:mrow><mml:mspace width="thinmathspace"/><mml:mi>y</mml:mi><mml:mi>x</mml:mi></mml:mrow></mml:msubsup><mml:mo stretchy="false">(</mml:mo><mml:mi>τ</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:msubsup><mml:mi>C</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow><mml:mrow><mml:mspace width="thinmathspace"/><mml:mi>y</mml:mi><mml:mi>x</mml:mi></mml:mrow></mml:msubsup><mml:mo stretchy="false">(</mml:mo><mml:mi>τ</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>−</mml:mo><mml:msubsup><mml:mi>S</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow><mml:mrow><mml:mspace width="thinmathspace"/><mml:mi>y</mml:mi><mml:mi>x</mml:mi></mml:mrow></mml:msubsup><mml:mo stretchy="false">(</mml:mo><mml:mi>τ</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>.</mml:mo></mml:mstyle></mml:mrow></mml:math></disp-formula></p></sec><sec id="s4-10-3"><title>Average imbalance of synaptic inputs</title><p>We considered time and trial-averaged synaptic inputs to each E and I neuron <inline-formula><mml:math id="inf472"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>i</mml:mi></mml:mstyle></mml:math></inline-formula> in trial <inline-formula><mml:math id="inf473"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>q</mml:mi></mml:mstyle></mml:math></inline-formula>, evaluated as:<disp-formula id="equ58"><label>(42)</label><mml:math id="m58"><mml:mrow><mml:mtable columnalign="right left right left right left right left right left right left" rowspacing="3pt" columnspacing="0em 2em 0em 2em 0em 2em 0em 2em 0em 2em 0em" displaystyle="true"><mml:mtr><mml:mtd><mml:msubsup><mml:mrow><mml:mover><mml:mi>A</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>q</mml:mi></mml:mrow><mml:mrow><mml:mtext>net</mml:mtext><mml:mo>,</mml:mo><mml:mi>E</mml:mi></mml:mrow></mml:msubsup></mml:mtd><mml:mtd><mml:mi/><mml:mo>=</mml:mo><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mfrac><mml:mn>1</mml:mn><mml:mrow><mml:mi>T</mml:mi><mml:msub><mml:mi>C</mml:mi><mml:mi>m</mml:mi></mml:msub></mml:mrow></mml:mfrac><mml:msubsup><mml:mo>∫</mml:mo><mml:mrow><mml:mn>0</mml:mn></mml:mrow><mml:mi>T</mml:mi></mml:msubsup><mml:msubsup><mml:mi>I</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>q</mml:mi></mml:mrow><mml:mrow><mml:mspace width="thinmathspace"/><mml:mtext>syn,</mml:mtext><mml:mi>E</mml:mi></mml:mrow></mml:msubsup><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mi>d</mml:mi><mml:mi>t</mml:mi><mml:mo>,</mml:mo></mml:mstyle></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:msubsup><mml:mrow><mml:mover><mml:mi>A</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>q</mml:mi></mml:mrow><mml:mrow><mml:mtext>net</mml:mtext><mml:mo>,</mml:mo><mml:mi>I</mml:mi></mml:mrow></mml:msubsup></mml:mtd><mml:mtd><mml:mi/><mml:mo>=</mml:mo><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mfrac><mml:mn>1</mml:mn><mml:mrow><mml:mi>T</mml:mi><mml:msub><mml:mi>C</mml:mi><mml:mi>m</mml:mi></mml:msub></mml:mrow></mml:mfrac><mml:msubsup><mml:mo>∫</mml:mo><mml:mrow><mml:mn>0</mml:mn></mml:mrow><mml:mi>T</mml:mi></mml:msubsup><mml:msubsup><mml:mi>I</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>q</mml:mi></mml:mrow><mml:mrow><mml:mspace width="thinmathspace"/><mml:mtext>syn,</mml:mtext><mml:mi>I</mml:mi></mml:mrow></mml:msubsup><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mi>d</mml:mi><mml:mi>t</mml:mi><mml:mo>,</mml:mo></mml:mstyle></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:math></disp-formula></p><p>with synaptic currents to E neurons <inline-formula><mml:math id="inf474"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msubsup><mml:mi>I</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>q</mml:mi></mml:mrow><mml:mrow><mml:mspace width="thinmathspace"/><mml:mtext>syn,</mml:mtext><mml:mi>E</mml:mi></mml:mrow></mml:msubsup><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mstyle></mml:math></inline-formula> and to I neurons <inline-formula><mml:math id="inf475"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msubsup><mml:mi>I</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>q</mml:mi></mml:mrow><mml:mrow><mml:mspace width="thinmathspace"/><mml:mtext>syn,</mml:mtext><mml:mi>I</mml:mi></mml:mrow></mml:msubsup><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mstyle></mml:math></inline-formula> as in <xref ref-type="disp-formula" rid="equ35">Equation 29c</xref>. Synaptic inputs were measured in units of mV. We reported trial-averages of the net synaptic inputs from the <xref ref-type="disp-formula" rid="equ58">Equation 42</xref>.</p></sec><sec id="s4-10-4"><title>Instantaneous balance of synaptic inputs</title><p>We measured the instantaneous balance of synaptic inputs as the Pearson correlation of time-dependent synaptic inputs incoming to the neuron <inline-formula><mml:math id="inf476"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>i</mml:mi></mml:mstyle></mml:math></inline-formula>. For those synaptic inputs that are defined as weighted delta-spikes (for which the Pearson correlation is not well defined; see <xref ref-type="disp-formula" rid="equ35">Equation 29c</xref>), we convolved spikes with a synaptic filter <inline-formula><mml:math id="inf477"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>F</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mi>exp</mml:mi><mml:mo>⁡</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mo>−</mml:mo><mml:mfrac><mml:mi>t</mml:mi><mml:msub><mml:mi>τ</mml:mi><mml:mrow><mml:mi>s</mml:mi><mml:mi>y</mml:mi><mml:mi>n</mml:mi></mml:mrow></mml:msub></mml:mfrac><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mstyle></mml:math></inline-formula>,<disp-formula id="equ59"><label>(43)</label><mml:math id="m59"><mml:mrow><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mtable columnalign="right left right left right left right left right left right left" rowspacing="3pt" columnspacing="0em 2em 0em 2em 0em 2em 0em 2em 0em 2em 0em" displaystyle="true"><mml:mtr><mml:mtd><mml:msubsup><mml:mi>A</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>q</mml:mi></mml:mrow><mml:mrow><mml:mi>I</mml:mi><mml:mi>E</mml:mi></mml:mrow></mml:msubsup><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mtd><mml:mtd><mml:mi/><mml:mo>=</mml:mo><mml:mstyle displaystyle="true" scriptlevel="0"><mml:munderover><mml:mo>∑</mml:mo><mml:mrow><mml:mi>j</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:msup><mml:mi>N</mml:mi><mml:mi>E</mml:mi></mml:msup></mml:mrow></mml:munderover><mml:msubsup><mml:mi>J</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi><mml:mo>,</mml:mo><mml:mi>q</mml:mi></mml:mrow><mml:mrow><mml:mi>I</mml:mi><mml:mi>E</mml:mi></mml:mrow></mml:msubsup><mml:msubsup><mml:mo>∫</mml:mo><mml:mn>0</mml:mn><mml:mi>t</mml:mi></mml:msubsup><mml:msubsup><mml:mi>f</mml:mi><mml:mrow><mml:mi>j</mml:mi><mml:mo>,</mml:mo><mml:mi>q</mml:mi></mml:mrow><mml:mi>E</mml:mi></mml:msubsup><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo>−</mml:mo><mml:mi>s</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mi>F</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>s</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mi>d</mml:mi><mml:mi>s</mml:mi><mml:mo>,</mml:mo></mml:mstyle></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:msubsup><mml:mi>A</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>q</mml:mi></mml:mrow><mml:mrow><mml:mi>I</mml:mi><mml:mi>I</mml:mi></mml:mrow></mml:msubsup><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mtd><mml:mtd><mml:mi/><mml:mo>=</mml:mo><mml:mstyle displaystyle="true" scriptlevel="0"><mml:munderover><mml:mo>∑</mml:mo><mml:mrow><mml:mstyle scriptlevel="1"><mml:mtable rowspacing="0.1em" columnspacing="0em" displaystyle="false"><mml:mtr><mml:mtd><mml:mi>j</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mi>i</mml:mi><mml:mo>≠</mml:mo><mml:mi>j</mml:mi></mml:mtd></mml:mtr></mml:mtable></mml:mstyle></mml:mrow><mml:mrow><mml:msup><mml:mi>N</mml:mi><mml:mi>I</mml:mi></mml:msup></mml:mrow></mml:munderover><mml:msubsup><mml:mi>J</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi><mml:mo>,</mml:mo><mml:mi>q</mml:mi></mml:mrow><mml:mrow><mml:mi>I</mml:mi><mml:mi>I</mml:mi></mml:mrow></mml:msubsup><mml:msubsup><mml:mo>∫</mml:mo><mml:mn>0</mml:mn><mml:mi>t</mml:mi></mml:msubsup><mml:msubsup><mml:mi>f</mml:mi><mml:mrow><mml:mi>j</mml:mi><mml:mo>,</mml:mo><mml:mi>q</mml:mi></mml:mrow><mml:mi>I</mml:mi></mml:msubsup><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo>−</mml:mo><mml:mi>s</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mi>F</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>s</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mi>d</mml:mi><mml:mi>s</mml:mi><mml:mo>,</mml:mo></mml:mstyle></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:msubsup><mml:mi>A</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>q</mml:mi></mml:mrow><mml:mrow><mml:mi>E</mml:mi><mml:mi>I</mml:mi></mml:mrow></mml:msubsup><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mtd><mml:mtd><mml:mi/><mml:mo>=</mml:mo><mml:mstyle displaystyle="true" scriptlevel="0"><mml:munderover><mml:mo>∑</mml:mo><mml:mrow><mml:mi>j</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:msup><mml:mi>N</mml:mi><mml:mi>I</mml:mi></mml:msup></mml:mrow></mml:munderover><mml:msubsup><mml:mi>J</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi><mml:mo>,</mml:mo><mml:mi>q</mml:mi></mml:mrow><mml:mrow><mml:mi>E</mml:mi><mml:mi>I</mml:mi></mml:mrow></mml:msubsup><mml:msubsup><mml:mo>∫</mml:mo><mml:mn>0</mml:mn><mml:mi>t</mml:mi></mml:msubsup><mml:msubsup><mml:mi>f</mml:mi><mml:mrow><mml:mi>j</mml:mi><mml:mo>,</mml:mo><mml:mi>q</mml:mi></mml:mrow><mml:mi>I</mml:mi></mml:msubsup><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo>−</mml:mo><mml:mi>s</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mi>F</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>s</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mi>d</mml:mi><mml:mi>s</mml:mi><mml:mo>,</mml:mo></mml:mstyle></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:msubsup><mml:mi>A</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>q</mml:mi></mml:mrow><mml:mrow><mml:mtext>ff</mml:mtext></mml:mrow></mml:msubsup><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mtd><mml:mtd><mml:mi/><mml:mo>=</mml:mo><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msubsup><mml:mi>C</mml:mi><mml:mi>m</mml:mi><mml:mrow><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msubsup><mml:msubsup><mml:mi>I</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>q</mml:mi></mml:mrow><mml:mrow><mml:mtext>ff</mml:mtext></mml:mrow></mml:msubsup><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>,</mml:mo></mml:mstyle></mml:mtd></mml:mtr></mml:mtable></mml:mstyle></mml:mrow></mml:math></disp-formula></p><p>where we used the expression for the feedforward synaptic current from the <xref ref-type="disp-formula" rid="equ36">Equation 29d</xref>. Note that the feedforward synaptic current is already already low-pass filtered (see <xref ref-type="disp-formula" rid="equ41">Equation 30</xref>). Using synaptic inputs from the <xref ref-type="disp-formula" rid="equ59">Equation 43</xref>, we computed the Pearson correlation of synaptic inputs incoming to single E neurons, <inline-formula><mml:math id="inf478"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msubsup><mml:mi>ρ</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>q</mml:mi></mml:mrow><mml:mrow><mml:mi>E</mml:mi></mml:mrow></mml:msubsup><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msubsup><mml:mi>A</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>q</mml:mi></mml:mrow><mml:mrow><mml:mi>I</mml:mi><mml:mi>E</mml:mi></mml:mrow></mml:msubsup><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>,</mml:mo><mml:msubsup><mml:mi>A</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>q</mml:mi></mml:mrow><mml:mrow><mml:mi>I</mml:mi><mml:mi>I</mml:mi></mml:mrow></mml:msubsup><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mstyle></mml:math></inline-formula> for <inline-formula><mml:math id="inf479"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mo>…</mml:mo><mml:mo>,</mml:mo><mml:msup><mml:mi>N</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>E</mml:mi></mml:mrow></mml:msup></mml:mstyle></mml:math></inline-formula>, and to single I neurons, <inline-formula><mml:math id="inf480"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msubsup><mml:mi>ρ</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>q</mml:mi></mml:mrow><mml:mrow><mml:mi>I</mml:mi></mml:mrow></mml:msubsup><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msubsup><mml:mi>A</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>q</mml:mi></mml:mrow><mml:mrow><mml:mi>E</mml:mi><mml:mi>I</mml:mi></mml:mrow></mml:msubsup><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>,</mml:mo><mml:msubsup><mml:mi>A</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>q</mml:mi></mml:mrow><mml:mrow><mml:mtext>ff</mml:mtext></mml:mrow></mml:msubsup><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mstyle></mml:math></inline-formula> for <inline-formula><mml:math id="inf481"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mo>…</mml:mo><mml:mo>,</mml:mo><mml:msup><mml:mi>N</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>I</mml:mi></mml:mrow></mml:msup></mml:mstyle></mml:math></inline-formula>. The coefficients were then averaged across trials.</p></sec><sec id="s4-10-5"><title>Tuning curves and selectivity index</title><p>The selectivity index of a neuron captures the change in neuron’s firing rate in response to a change in the stimulus. We first evaluated the tuning curve of each neuron by measuring the firing rate of the neuron <inline-formula><mml:math id="inf482"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msubsup><mml:mi>z</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mspace width="thinmathspace"/><mml:mi>y</mml:mi></mml:mrow></mml:msubsup><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>s</mml:mi><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:mo>,</mml:mo><mml:mi>y</mml:mi><mml:mo>∈</mml:mo><mml:mo fence="false" stretchy="false">{</mml:mo><mml:mi>E</mml:mi><mml:mo>,</mml:mo><mml:mi>I</mml:mi><mml:mo fence="false" stretchy="false">}</mml:mo></mml:mrow></mml:mstyle></mml:math></inline-formula>, as a function of the amplitude of the stimulus feature <inline-formula><mml:math id="inf483"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msub><mml:mi>s</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mstyle></mml:math></inline-formula>. The firing rate was evaluated from the network response to <inline-formula><mml:math id="inf484"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>M</mml:mi><mml:mo>=</mml:mo><mml:mn>3</mml:mn></mml:mstyle></mml:math></inline-formula> stimulus features that were constant over time. We varied the first stimulus feature <inline-formula><mml:math id="inf485"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msub><mml:mi>s</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mstyle></mml:math></inline-formula> from strongly negative (<inline-formula><mml:math id="inf486"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msub><mml:mi>s</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mo>−</mml:mo><mml:mn>5</mml:mn></mml:mstyle></mml:math></inline-formula>) to strongly positive values (<inline-formula><mml:math id="inf487"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msub><mml:mi>s</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:msub><mml:mi>s</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mtext>max</mml:mtext></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mn>5</mml:mn></mml:mstyle></mml:math></inline-formula>), while the two other features were kept at an intermediate positive value (<inline-formula><mml:math id="inf488"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msub><mml:mi>s</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:msub><mml:mi>s</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mn>3</mml:mn></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mn>1.6</mml:mn></mml:mstyle></mml:math></inline-formula>). Note that with all three features at such intermediate value (<inline-formula><mml:math id="inf489"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msub><mml:mi>s</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:msub><mml:mi>s</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:msub><mml:mi>s</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mn>3</mml:mn></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mn>1.6</mml:mn></mml:mstyle></mml:math></inline-formula>), the average firing rate was about 8 Hz in E and 12 Hz in I neurons. To evaluate the tuning curve of a neuron, we measured its firing rate in 100 simulation trials of 1 s duration, for each value of the stimulus feature <inline-formula><mml:math id="inf490"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msub><mml:mi>s</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mstyle></mml:math></inline-formula>.</p><p>To evaluate the sensitivity index, we normalized the tuning curve of the neuron with its maximal value,<disp-formula id="equ60"><label>(44a)</label><mml:math id="m60"><mml:mrow><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msubsup><mml:mrow><mml:mover><mml:mi>z</mml:mi><mml:mo stretchy="false">~</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mspace width="thinmathspace"/><mml:mi>y</mml:mi></mml:mrow></mml:msubsup><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>s</mml:mi><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:msubsup><mml:mi>z</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mspace width="thinmathspace"/><mml:mi>y</mml:mi></mml:mrow></mml:msubsup><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>s</mml:mi><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mrow><mml:mo movablelimits="true" form="prefix">max</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:msubsup><mml:mi>z</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mspace width="thinmathspace"/><mml:mi>y</mml:mi></mml:mrow></mml:msubsup><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>s</mml:mi><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mfrac></mml:mstyle></mml:mrow></mml:math></disp-formula></p><p>We then computed the sensitivity index as the average absolute change of the normalized firing rate with the change in the stimulus:<disp-formula id="equ61"><label>(44b)</label><mml:math id="m61"><mml:mrow><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msubsup><mml:mi>α</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mspace width="thinmathspace"/><mml:mi>y</mml:mi></mml:mrow></mml:msubsup><mml:mo>=</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mrow><mml:mn>2</mml:mn><mml:msub><mml:mi>s</mml:mi><mml:mrow><mml:mi mathvariant="normal">m</mml:mi><mml:mi mathvariant="normal">a</mml:mi><mml:mi mathvariant="normal">x</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfrac><mml:msubsup><mml:mo>∫</mml:mo><mml:mrow><mml:mo>−</mml:mo><mml:msub><mml:mi>s</mml:mi><mml:mrow><mml:mi mathvariant="normal">m</mml:mi><mml:mi mathvariant="normal">a</mml:mi><mml:mi mathvariant="normal">x</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:msub><mml:mi>s</mml:mi><mml:mrow><mml:mi mathvariant="normal">m</mml:mi><mml:mi mathvariant="normal">a</mml:mi><mml:mi mathvariant="normal">x</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:msubsup><mml:mrow><mml:mo>|</mml:mo><mml:mfrac><mml:mrow><mml:mi>d</mml:mi><mml:mspace width="thinmathspace"/><mml:msubsup><mml:mrow><mml:mover><mml:mi>z</mml:mi><mml:mo stretchy="false">~</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mspace width="thinmathspace"/><mml:mi>y</mml:mi></mml:mrow></mml:msubsup></mml:mrow><mml:mrow><mml:mi>d</mml:mi><mml:msub><mml:mi>s</mml:mi><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:mfrac><mml:mo>|</mml:mo></mml:mrow><mml:mi>d</mml:mi><mml:msub><mml:mi>s</mml:mi><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>.</mml:mo></mml:mstyle></mml:mrow></mml:math></disp-formula></p></sec></sec><sec id="s4-11"><title>Perturbation experiments</title><sec id="s4-11-1"><title>Perturbation of neural activity</title><p>Empirical studies (<xref ref-type="bibr" rid="bib22">Chettih and Harvey, 2019</xref>; <xref ref-type="bibr" rid="bib72">Oldenburg et al., 2024</xref>) suggested experiments with perturbation of neural activity that estimate functional connectivity in recurrently connected neural networks. Here, we detail the procedure on how we performed similar experiments on simulated neural networks. To evaluate the functional connectivity between pairs of neurons, we measured the effect of activation of a single E neuron (‘target’ neuron) on the activity of other neurons. We stimulated a randomly chosen E neuron with a depolarizing input, capturing the effect of photostimulation in empirical studies (<xref ref-type="bibr" rid="bib22">Chettih and Harvey, 2019</xref>; <xref ref-type="bibr" rid="bib72">Oldenburg et al., 2024</xref>), and measured the deviation of the firing rate from the baseline in all other neurons.</p><p>The time-dependent deviation of the firing rate from the baseline for neuron <inline-formula><mml:math id="inf491"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>i</mml:mi></mml:mstyle></mml:math></inline-formula> of type <inline-formula><mml:math id="inf492"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>y</mml:mi><mml:mo>∈</mml:mo><mml:mo fence="false" stretchy="false">{</mml:mo><mml:mi>E</mml:mi><mml:mo>,</mml:mo><mml:mi>I</mml:mi><mml:mo fence="false" stretchy="false">}</mml:mo></mml:mstyle></mml:math></inline-formula> was computed as <inline-formula><mml:math id="inf493"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi mathvariant="normal">Δ</mml:mi><mml:msubsup><mml:mi>z</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mspace width="thinmathspace"/><mml:mi>y</mml:mi></mml:mrow></mml:msubsup><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:msubsup><mml:mi>z</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mspace width="thinmathspace"/><mml:mi>y</mml:mi></mml:mrow></mml:msubsup><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>−</mml:mo><mml:msubsup><mml:mrow><mml:mover><mml:mi>z</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mspace width="thinmathspace"/><mml:mi>y</mml:mi></mml:mrow></mml:msubsup></mml:mrow></mml:mstyle></mml:math></inline-formula>, with <inline-formula><mml:math id="inf494"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msubsup><mml:mi>z</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mspace width="thinmathspace"/><mml:mi>y</mml:mi></mml:mrow></mml:msubsup><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:msubsup><mml:mi>τ</mml:mi><mml:mrow><mml:mi>r</mml:mi></mml:mrow><mml:mrow><mml:mspace width="thinmathspace"/><mml:mi>y</mml:mi></mml:mrow></mml:msubsup><mml:msup><mml:mo stretchy="false">)</mml:mo><mml:mrow><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msup><mml:msubsup><mml:mi>r</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mspace width="thinmathspace"/><mml:mi>y</mml:mi></mml:mrow></mml:msubsup><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mstyle></mml:math></inline-formula> the estimate of the instantaneous firing rate and <inline-formula><mml:math id="inf495"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msubsup><mml:mrow><mml:mover><mml:mi>z</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mspace width="thinmathspace"/><mml:mi>y</mml:mi></mml:mrow></mml:msubsup></mml:mstyle></mml:mrow></mml:mstyle></mml:math></inline-formula> the average spontaneous firing rate of the neuron <inline-formula><mml:math id="inf496"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>i</mml:mi></mml:mstyle></mml:math></inline-formula>. The target neuron received a constant depolarizing current during 50 ms and the effect of its activity on other neurons was measured during a time window of [0, 100] ms with respect to the onset of the stimulation. The functional connectivity between the target neuron and every other neuron in the network was then computed as the time average of the variable <inline-formula><mml:math id="inf497"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi mathvariant="normal">Δ</mml:mi><mml:msubsup><mml:mi>z</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mspace width="thinmathspace"/><mml:mi>y</mml:mi></mml:mrow></mml:msubsup><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mstyle></mml:math></inline-formula>. To isolate the functional effect of recurrent connections on firing rate changes, we performed these experiments in a network without external stimuli, setting <inline-formula><mml:math id="inf498"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msub><mml:mi>s</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>k</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mn>0</mml:mn><mml:mtext/><mml:mi mathvariant="normal">∀</mml:mi><mml:mi>t</mml:mi><mml:mo>,</mml:mo><mml:mi>k</mml:mi></mml:mstyle></mml:math></inline-formula>.</p></sec><sec id="s4-11-2"><title>Removal of connectivity structure</title><p>To better understand the effect of optimally structured recurrent connectivity (as given by the <xref ref-type="disp-formula" rid="equ26">Equation 24</xref>) on network’s activity and efficiency, we compared networks with and without the connectivity structure. To fully remove the connectivity structure, we randomly permuted, without repetition, recurrent connectivity weights between all neuronal pairs of all the three recurrent connectivity matrices. This was achieved by shuffling entries within each recurrent connectivity matrix. This procedure preserves all properties of the distribution of connectivity weights and only removes the connectivity structure. Shuffling of connections was iterated across 200 simulation trials, with each trial implementing a different random permutation of the connectivity. Dale’s law is preserved by such manipulation.</p><p>To compare the performance of models with structured and unstructured connectivity (as reported on <xref ref-type="fig" rid="fig4">Figure 4A</xref>), we collected the low-pass filtered spiking activity in networks with and without connectivity structure. We used this neural activity to train a linear decoder with least squares method that minimizes the Euclidean distance between target signals and a linear readout of low-pass filtered spikes. The output of the training was a set of linear coefficients akin to decoding weights <inline-formula><mml:math id="inf499"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msubsup><mml:mi>w</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>k</mml:mi><mml:mi>i</mml:mi></mml:mrow><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>y</mml:mi></mml:mrow></mml:msubsup></mml:mstyle></mml:math></inline-formula>. We used these decoding weights estimated by the decoder to weight spikes in a held-out validation set. The performance was measured with root mean squared error (RMSE) between target signals and their estimates in the validation set. The training set comprised 70% of trials (140 trials), and the validation test comprised the remaining 30% of trials (60 trials).</p><p>To compare networks with and without connectivity structure about their metabolic cost, firing rate, variability of spiking and the E-I balance (<xref ref-type="fig" rid="fig4">Figure 4B–G</xref>), we performed these measures in networks with and without connectivity structure and plotted their distributions across 200 simulation trials. For the comparison of the metabolic cost (<xref ref-type="fig" rid="fig4">Figure 4B</xref>), we additionally matched the network with and without the connectivity structure about their mean net synaptic input to E and I neurons, to see if the difference in the metabolic cost between structured and unstructured networks persists after such matching. For the comparison of the coefficient of variation in structured and unstructured networks (<xref ref-type="fig" rid="fig4">Figure 4E</xref>), we used a constant stimulus instead of the OU stimulus, to exclude possible effects of time-dependent variations of the stimulus on the variability of spiking. Constant stimulus was homogeneous across all stimulus dimensions, <inline-formula><mml:math id="inf500"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow class="MJX-TeXAtom-ORD"><mml:msub><mml:mi>s</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>k</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mn>1.6</mml:mn><mml:mo>,</mml:mo><mml:mtext/><mml:mi mathvariant="normal">∀</mml:mi><mml:mi>k</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mo>…</mml:mo><mml:mo>,</mml:mo><mml:mi>M</mml:mi></mml:mrow></mml:mstyle></mml:math></inline-formula>. The amplitude of the constant stimulus was set such that the average firing rate in response to the constant stimulus matched the firing rate in response to the OU stimulus.</p><p>For the comparison of the voltage correlations and the effective connectivity between structured and unstructured networks (<xref ref-type="fig" rid="fig4">Figure 4H–I</xref>), we additionally permuted individual connectivity (sub)matrices. This gave four cases, namely, permuted E-I, I-I, I-E, and “all”, with “all” meaning that all three recurrent connectivity matrices have been randomly permuted.</p><p>We also tested networks where the connectivity structure was not fully but only partially removed. There, we limited random permutation of synaptic weights to pairs of neurons that already had a connection in the structured network. By the <xref ref-type="disp-formula" rid="equ26">Equation 24</xref>, connected neurons are those with positive tuning similarity, that is, neuronal pairs for which the following holds: <inline-formula><mml:math id="inf501"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow class="MJX-TeXAtom-ORD"><mml:msubsup><mml:mi mathvariant="normal">Φ</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>y</mml:mi><mml:mi>x</mml:mi></mml:mrow></mml:msubsup><mml:mo>≥</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:mstyle></mml:math></inline-formula>, with tuning similarity as in <xref ref-type="disp-formula" rid="equ53">Equation 40</xref>. We compared partially unstructured networks with structured networks by plotting measures of neural activity in structured and partially unstructured networks across 200 simulation trials (<xref ref-type="fig" rid="fig4s1">Figure 4—figure supplement 1B–E</xref>).</p></sec><sec id="s4-11-3"><title>Perturbation of connectivity</title><p>To test the robustness of the model to random perturbations of synaptic weights (<xref ref-type="fig" rid="fig4s1">Figure 4—figure supplement 1G–H</xref>), we applied a random jitter to optimally efficient recurrent synaptic connectivity weights. The random jitter was proportional to the optimal synaptic weight, <inline-formula><mml:math id="inf502"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msubsup><mml:mrow><mml:mover><mml:mi>J</mml:mi><mml:mo stretchy="false">~</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow><mml:mrow><mml:mspace width="thinmathspace"/><mml:mi>y</mml:mi><mml:mi>x</mml:mi></mml:mrow></mml:msubsup><mml:mo>=</mml:mo><mml:msubsup><mml:mi>J</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow><mml:mrow><mml:mspace width="thinmathspace"/><mml:mi>y</mml:mi><mml:mi>x</mml:mi></mml:mrow></mml:msubsup><mml:mo stretchy="false">(</mml:mo><mml:mn>1</mml:mn><mml:mo>+</mml:mo><mml:msub><mml:mi>σ</mml:mi><mml:mrow><mml:mi>J</mml:mi></mml:mrow></mml:msub><mml:msubsup><mml:mi>Z</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow><mml:mrow><mml:mspace width="thinmathspace"/><mml:mi>y</mml:mi><mml:mi>x</mml:mi></mml:mrow></mml:msubsup><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mstyle></mml:math></inline-formula>, where <inline-formula><mml:math id="inf503"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msub><mml:mi>σ</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>J</mml:mi></mml:mrow></mml:msub></mml:mstyle></mml:math></inline-formula> is the strength of the perturbation and <inline-formula><mml:math id="inf504"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msubsup><mml:mi>Z</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow><mml:mrow><mml:mspace width="thinmathspace"/><mml:mi>y</mml:mi><mml:mi>x</mml:mi></mml:mrow></mml:msubsup></mml:mrow></mml:mstyle></mml:math></inline-formula> are independent standard normal random variables. All three recurrent connectivity matrices (E-I, I-I, and I-E) were randomly perturbed at once.</p></sec></sec><sec id="s4-12"><title>Computer simulations</title><p>We ran computer simulations with Matlab R2023b (Mathworks). The membrane equation for each neuron was integrated with Euler integration scheme with the time step of <inline-formula><mml:math id="inf505"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>d</mml:mi><mml:mi>t</mml:mi><mml:mo>=</mml:mo><mml:mn>0.02</mml:mn></mml:mstyle></mml:math></inline-formula> ms. The simulation of the E-I network with 400 E units and 100 I units for an equivalent of 1 s of neural activity lasted approximately 1.65 s on a laptop.</p></sec><sec id="s4-13"><title>Code availability</title><p>The complete computer code to reproduce the results can be downloaded anonymously from a public GitHub repository <ext-link ext-link-type="uri" xlink:href="https://github.com/VeronikaKoren/efficient_EI">https://github.com/VeronikaKoren/efficient_EI</ext-link> and has the associated DOI: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.5281/zenodo.14628524">https://doi.org/10.5281/zenodo.14628524</ext-link>.</p></sec></sec></body><back><sec sec-type="additional-information" id="s5"><title>Additional information</title><fn-group content-type="competing-interest"><title>Competing interests</title><fn fn-type="COI-statement" id="conf1"><p>No competing interests declared</p></fn></fn-group><fn-group content-type="author-contribution"><title>Author contributions</title><fn fn-type="con" id="con1"><p>Conceptualization, Data curation, Software, Formal analysis, Funding acquisition, Validation, Investigation, Visualization, Methodology, Writing – original draft, Writing – review and editing</p></fn><fn fn-type="con" id="con2"><p>Formal analysis, Funding acquisition, Validation, Writing – review and editing</p></fn><fn fn-type="con" id="con3"><p>Resources, Supervision, Funding acquisition, Validation, Writing – review and editing</p></fn><fn fn-type="con" id="con4"><p>Conceptualization, Resources, Supervision, Funding acquisition, Writing – original draft, Project administration, Writing – review and editing</p></fn></fn-group></sec><sec sec-type="supplementary-material" id="s6"><title>Additional files</title><supplementary-material id="mdar"><label>MDAR checklist</label><media xlink:href="elife-99545-mdarchecklist1-v1.pdf" mimetype="application" mime-subtype="pdf"/></supplementary-material></sec><sec sec-type="data-availability" id="s7"><title>Data availability</title><p>The current manuscript is a computational study, and no data have been generated for this manuscript. The complete computer code for reproducing the results can be downloaded anonymously froma public GitHub repository: <ext-link ext-link-type="uri" xlink:href="https://github.com/VeronikaKoren/efficient_EI">https://github.com/VeronikaKoren/efficient_EI</ext-link>, with a copy archived at <xref ref-type="bibr" rid="bib51">Koren, 2025</xref> and with the associated DOI: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.5281/zenodo.14628524">https://doi.org/10.5281/zenodo.14628524</ext-link>.</p><p>The following dataset was generated:</p><p><element-citation publication-type="data" specific-use="isSupplementedBy" id="dataset1"><person-group person-group-type="author"><name><surname>Koren</surname><given-names>V</given-names></name></person-group><year iso-8601-date="2025">2025</year><data-title>VeronikaKoren/efficient_EI: third release</data-title><source>Zenodo</source><pub-id pub-id-type="doi">10.5281/zenodo.14628524</pub-id></element-citation></p></sec><ack id="ack"><title>Acknowledgements</title><p>VK and TS thank Tatiana Engel for her contribution to the discussion of results and for her comments on an earlier version of the manuscript.</p></ack><ref-list><title>References</title><ref id="bib1"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Abbott</surname><given-names>LF</given-names></name><name><surname>Nelson</surname><given-names>SB</given-names></name></person-group><year iso-8601-date="2000">2000</year><article-title>Synaptic plasticity: taming the beast</article-title><source>Nature Neuroscience</source><volume>3 Suppl</volume><fpage>1178</fpage><lpage>1183</lpage><pub-id pub-id-type="doi">10.1038/81453</pub-id><pub-id pub-id-type="pmid">11127835</pub-id></element-citation></ref><ref id="bib2"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Abbott</surname><given-names>LF</given-names></name><name><surname>DePasquale</surname><given-names>B</given-names></name><name><surname>Memmesheimer</surname><given-names>R-M</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Building functional networks of spiking model neurons</article-title><source>Nature Neuroscience</source><volume>19</volume><fpage>350</fpage><lpage>355</lpage><pub-id pub-id-type="doi">10.1038/nn.4241</pub-id><pub-id pub-id-type="pmid">26906501</pub-id></element-citation></ref><ref id="bib3"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ahmadian</surname><given-names>Y</given-names></name><name><surname>Miller</surname><given-names>KD</given-names></name></person-group><year iso-8601-date="2021">2021</year><article-title>What is the dynamical regime of cerebral cortex?</article-title><source>Neuron</source><volume>109</volume><fpage>3373</fpage><lpage>3391</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2021.07.031</pub-id><pub-id pub-id-type="pmid">34464597</pub-id></element-citation></ref><ref id="bib4"><element-citation publication-type="confproc"><person-group person-group-type="author"><name><surname>Alemi</surname><given-names>A</given-names></name><name><surname>Machens</surname><given-names>C</given-names></name><name><surname>Deneve</surname><given-names>S</given-names></name><name><surname>Slotine</surname><given-names>JJ</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>Learning Nonlinear Dynamics in Efficient, Balanced Spiking Networks Using Local Plasticity Rules</article-title><conf-name>Proceedings of the AAAI Conference on Artificial Intelligence</conf-name><pub-id pub-id-type="doi">10.1609/aaai.v32i1.11320</pub-id></element-citation></ref><ref id="bib5"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Atick</surname><given-names>JJ</given-names></name></person-group><year iso-8601-date="1992">1992</year><article-title>Could information theory provide an ecological theory of sensory processing?</article-title><source>Network</source><volume>3</volume><fpage>213</fpage><lpage>251</lpage><pub-id pub-id-type="doi">10.1088/0954-898X/3/2/009</pub-id></element-citation></ref><ref id="bib6"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Barlow</surname><given-names>HB</given-names></name></person-group><year iso-8601-date="1961">1961</year><chapter-title>Possible principles underlying the transformation of sensory messages</chapter-title><person-group person-group-type="editor"><name><surname>Rosenblith</surname><given-names>WA</given-names></name></person-group><source>Sensory Communication</source><publisher-name>MIT Press</publisher-name><fpage>217</fpage><lpage>233</lpage><pub-id pub-id-type="doi">10.7551/mitpress/9780262518420.003.0013</pub-id></element-citation></ref><ref id="bib7"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Barrett</surname><given-names>DG</given-names></name><name><surname>Denève</surname><given-names>S</given-names></name><name><surname>Machens</surname><given-names>CK</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Optimal compensation for neuron loss</article-title><source>eLife</source><volume>5</volume><elocation-id>e12454</elocation-id><pub-id pub-id-type="doi">10.7554/eLife.12454</pub-id><pub-id pub-id-type="pmid">27935480</pub-id></element-citation></ref><ref id="bib8"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bialek</surname><given-names>W</given-names></name><name><surname>Rieke</surname><given-names>F</given-names></name><name><surname>de Ruyter van Steveninck</surname><given-names>RR</given-names></name><name><surname>Warland</surname><given-names>D</given-names></name></person-group><year iso-8601-date="1991">1991</year><article-title>Reading a neural code</article-title><source>Science</source><volume>252</volume><fpage>1854</fpage><lpage>1857</lpage><pub-id pub-id-type="doi">10.1126/science.2063199</pub-id><pub-id pub-id-type="pmid">2063199</pub-id></element-citation></ref><ref id="bib9"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bialek</surname><given-names>W</given-names></name><name><surname>Rieke</surname><given-names>F</given-names></name></person-group><year iso-8601-date="1992">1992</year><article-title>Reliability and information transmission in spiking neurons</article-title><source>Trends in Neurosciences</source><volume>15</volume><fpage>428</fpage><lpage>434</lpage><pub-id pub-id-type="doi">10.1016/0166-2236(92)90005-s</pub-id><pub-id pub-id-type="pmid">1281349</pub-id></element-citation></ref><ref id="bib10"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Blanco Malerba</surname><given-names>S</given-names></name><name><surname>Micheli</surname><given-names>A</given-names></name><name><surname>Woodford</surname><given-names>M</given-names></name><name><surname>Azeredo da Silveira</surname><given-names>R</given-names></name></person-group><year iso-8601-date="2024">2024</year><article-title>Jointly efficient encoding and decoding in neural populations</article-title><source>PLOS Computational Biology</source><volume>20</volume><elocation-id>e1012240</elocation-id><pub-id pub-id-type="doi">10.1371/journal.pcbi.1012240</pub-id><pub-id pub-id-type="pmid">38985828</pub-id></element-citation></ref><ref id="bib11"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Boerlin</surname><given-names>M</given-names></name><name><surname>Machens</surname><given-names>CK</given-names></name><name><surname>Denève</surname><given-names>S</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>Predictive coding of dynamical variables in balanced spiking networks</article-title><source>PLOS Computational Biology</source><volume>9</volume><elocation-id>e1003258</elocation-id><pub-id pub-id-type="doi">10.1371/journal.pcbi.1003258</pub-id><pub-id pub-id-type="pmid">24244113</pub-id></element-citation></ref><ref id="bib12"><element-citation publication-type="confproc"><person-group person-group-type="author"><name><surname>Bourdoukan</surname><given-names>R</given-names></name><name><surname>Barrett</surname><given-names>D</given-names></name><name><surname>Deneve</surname><given-names>S</given-names></name><name><surname>Machens</surname><given-names>CK</given-names></name></person-group><year iso-8601-date="2012">2012</year><article-title>Learning optimal spike-based representations</article-title><conf-name>Advances in Neural Information Processing Systems</conf-name><fpage>2285</fpage><lpage>2293</lpage></element-citation></ref><ref id="bib13"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Brendel</surname><given-names>W</given-names></name><name><surname>Bourdoukan</surname><given-names>R</given-names></name><name><surname>Vertechi</surname><given-names>P</given-names></name><name><surname>Machens</surname><given-names>CK</given-names></name><name><surname>Denève</surname><given-names>S</given-names></name></person-group><year iso-8601-date="2020">2020</year><article-title>Learning to represent signals spike by spike</article-title><source>PLOS Computational Biology</source><volume>16</volume><elocation-id>e1007692</elocation-id><pub-id pub-id-type="doi">10.1371/journal.pcbi.1007692</pub-id><pub-id pub-id-type="pmid">32176682</pub-id></element-citation></ref><ref id="bib14"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Brette</surname><given-names>R</given-names></name><name><surname>Gerstner</surname><given-names>W</given-names></name></person-group><year iso-8601-date="2005">2005</year><article-title>Adaptive exponential integrate-and-fire model as an effective description of neuronal activity</article-title><source>Journal of Neurophysiology</source><volume>94</volume><fpage>3637</fpage><lpage>3642</lpage><pub-id pub-id-type="doi">10.1152/jn.00686.2005</pub-id><pub-id pub-id-type="pmid">16014787</pub-id></element-citation></ref><ref id="bib15"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Brunel</surname><given-names>N</given-names></name></person-group><year iso-8601-date="2000">2000</year><article-title>Dynamics of sparsely connected networks of excitatory and inhibitory spiking neurons</article-title><source>Journal of Computational Neuroscience</source><volume>8</volume><fpage>183</fpage><lpage>208</lpage><pub-id pub-id-type="doi">10.1023/a:1008925309027</pub-id><pub-id pub-id-type="pmid">10809012</pub-id></element-citation></ref><ref id="bib16"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Burkitt</surname><given-names>AN</given-names></name></person-group><year iso-8601-date="2006">2006</year><article-title>A review of the integrate-and-fire neuron model: I. Homogeneous synaptic input</article-title><source>Biological Cybernetics</source><volume>95</volume><fpage>1</fpage><lpage>19</lpage><pub-id pub-id-type="doi">10.1007/s00422-006-0068-6</pub-id><pub-id pub-id-type="pmid">16622699</pub-id></element-citation></ref><ref id="bib17"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Buzsáki</surname><given-names>G</given-names></name><name><surname>Mizuseki</surname><given-names>K</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>The log-dynamic brain: how skewed distributions affect network operations</article-title><source>Nature Reviews. Neuroscience</source><volume>15</volume><fpage>264</fpage><lpage>278</lpage><pub-id pub-id-type="doi">10.1038/nrn3687</pub-id><pub-id pub-id-type="pmid">24569488</pub-id></element-citation></ref><ref id="bib18"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Calaim</surname><given-names>N</given-names></name><name><surname>Dehmelt</surname><given-names>FA</given-names></name><name><surname>Gonçalves</surname><given-names>PJ</given-names></name><name><surname>Machens</surname><given-names>CK</given-names></name></person-group><year iso-8601-date="2022">2022</year><article-title>The geometry of robustness in spiking neural networks</article-title><source>eLife</source><volume>11</volume><elocation-id>e73276</elocation-id><pub-id pub-id-type="doi">10.7554/eLife.73276</pub-id><pub-id pub-id-type="pmid">35635432</pub-id></element-citation></ref><ref id="bib19"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Campagnola</surname><given-names>L</given-names></name><name><surname>Seeman</surname><given-names>SC</given-names></name><name><surname>Chartrand</surname><given-names>T</given-names></name><name><surname>Kim</surname><given-names>L</given-names></name><name><surname>Hoggarth</surname><given-names>A</given-names></name><name><surname>Gamlin</surname><given-names>C</given-names></name><name><surname>Ito</surname><given-names>S</given-names></name><name><surname>Trinh</surname><given-names>J</given-names></name><name><surname>Davoudian</surname><given-names>P</given-names></name><name><surname>Radaelli</surname><given-names>C</given-names></name><name><surname>Kim</surname><given-names>M-H</given-names></name><name><surname>Hage</surname><given-names>T</given-names></name><name><surname>Braun</surname><given-names>T</given-names></name><name><surname>Alfiler</surname><given-names>L</given-names></name><name><surname>Andrade</surname><given-names>J</given-names></name><name><surname>Bohn</surname><given-names>P</given-names></name><name><surname>Dalley</surname><given-names>R</given-names></name><name><surname>Henry</surname><given-names>A</given-names></name><name><surname>Kebede</surname><given-names>S</given-names></name><name><surname>Alice</surname><given-names>M</given-names></name><name><surname>Sandman</surname><given-names>D</given-names></name><name><surname>Williams</surname><given-names>G</given-names></name><name><surname>Larsen</surname><given-names>R</given-names></name><name><surname>Teeter</surname><given-names>C</given-names></name><name><surname>Daigle</surname><given-names>TL</given-names></name><name><surname>Berry</surname><given-names>K</given-names></name><name><surname>Dotson</surname><given-names>N</given-names></name><name><surname>Enstrom</surname><given-names>R</given-names></name><name><surname>Gorham</surname><given-names>M</given-names></name><name><surname>Hupp</surname><given-names>M</given-names></name><name><surname>Dingman Lee</surname><given-names>S</given-names></name><name><surname>Ngo</surname><given-names>K</given-names></name><name><surname>Nicovich</surname><given-names>PR</given-names></name><name><surname>Potekhina</surname><given-names>L</given-names></name><name><surname>Ransford</surname><given-names>S</given-names></name><name><surname>Gary</surname><given-names>A</given-names></name><name><surname>Goldy</surname><given-names>J</given-names></name><name><surname>McMillen</surname><given-names>D</given-names></name><name><surname>Pham</surname><given-names>T</given-names></name><name><surname>Tieu</surname><given-names>M</given-names></name><name><surname>Siverts</surname><given-names>L</given-names></name><name><surname>Walker</surname><given-names>M</given-names></name><name><surname>Farrell</surname><given-names>C</given-names></name><name><surname>Schroedter</surname><given-names>M</given-names></name><name><surname>Slaughterbeck</surname><given-names>C</given-names></name><name><surname>Cobb</surname><given-names>C</given-names></name><name><surname>Ellenbogen</surname><given-names>R</given-names></name><name><surname>Gwinn</surname><given-names>RP</given-names></name><name><surname>Keene</surname><given-names>CD</given-names></name><name><surname>Ko</surname><given-names>AL</given-names></name><name><surname>Ojemann</surname><given-names>JG</given-names></name><name><surname>Silbergeld</surname><given-names>DL</given-names></name><name><surname>Carey</surname><given-names>D</given-names></name><name><surname>Casper</surname><given-names>T</given-names></name><name><surname>Crichton</surname><given-names>K</given-names></name><name><surname>Clark</surname><given-names>M</given-names></name><name><surname>Dee</surname><given-names>N</given-names></name><name><surname>Ellingwood</surname><given-names>L</given-names></name><name><surname>Gloe</surname><given-names>J</given-names></name><name><surname>Kroll</surname><given-names>M</given-names></name><name><surname>Sulc</surname><given-names>J</given-names></name><name><surname>Tung</surname><given-names>H</given-names></name><name><surname>Wadhwani</surname><given-names>K</given-names></name><name><surname>Brouner</surname><given-names>K</given-names></name><name><surname>Egdorf</surname><given-names>T</given-names></name><name><surname>Maxwell</surname><given-names>M</given-names></name><name><surname>McGraw</surname><given-names>M</given-names></name><name><surname>Pom</surname><given-names>CA</given-names></name><name><surname>Ruiz</surname><given-names>A</given-names></name><name><surname>Bomben</surname><given-names>J</given-names></name><name><surname>Feng</surname><given-names>D</given-names></name><name><surname>Hejazinia</surname><given-names>N</given-names></name><name><surname>Shi</surname><given-names>S</given-names></name><name><surname>Szafer</surname><given-names>A</given-names></name><name><surname>Wakeman</surname><given-names>W</given-names></name><name><surname>Phillips</surname><given-names>J</given-names></name><name><surname>Bernard</surname><given-names>A</given-names></name><name><surname>Esposito</surname><given-names>L</given-names></name><name><surname>D’Orazi</surname><given-names>FD</given-names></name><name><surname>Sunkin</surname><given-names>S</given-names></name><name><surname>Smith</surname><given-names>K</given-names></name><name><surname>Tasic</surname><given-names>B</given-names></name><name><surname>Arkhipov</surname><given-names>A</given-names></name><name><surname>Sorensen</surname><given-names>S</given-names></name><name><surname>Lein</surname><given-names>E</given-names></name><name><surname>Koch</surname><given-names>C</given-names></name><name><surname>Murphy</surname><given-names>G</given-names></name><name><surname>Zeng</surname><given-names>H</given-names></name><name><surname>Jarsky</surname><given-names>T</given-names></name></person-group><year iso-8601-date="2022">2022</year><article-title>Local connectivity and synaptic dynamics in mouse and human neocortex</article-title><source>Science</source><volume>375</volume><elocation-id>eabj5861</elocation-id><pub-id pub-id-type="doi">10.1126/science.abj5861</pub-id><pub-id pub-id-type="pmid">35271334</pub-id></element-citation></ref><ref id="bib20"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Chalk</surname><given-names>M</given-names></name><name><surname>Gutkin</surname><given-names>B</given-names></name><name><surname>Denève</surname><given-names>S</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Neural oscillations as a signature of efficient coding in the presence of synaptic delays</article-title><source>eLife</source><volume>5</volume><elocation-id>e13824</elocation-id><pub-id pub-id-type="doi">10.7554/eLife.13824</pub-id><pub-id pub-id-type="pmid">27383272</pub-id></element-citation></ref><ref id="bib21"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Chang</surname><given-names>L</given-names></name><name><surname>Tsao</surname><given-names>DY</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>The code for facial identity in the primate brain</article-title><source>Cell</source><volume>169</volume><fpage>1013</fpage><lpage>1028</lpage><pub-id pub-id-type="doi">10.1016/j.cell.2017.05.011</pub-id><pub-id pub-id-type="pmid">28575666</pub-id></element-citation></ref><ref id="bib22"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Chettih</surname><given-names>SN</given-names></name><name><surname>Harvey</surname><given-names>CD</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>Single-neuron perturbations reveal feature-specific competition in V1</article-title><source>Nature</source><volume>567</volume><fpage>334</fpage><lpage>340</lpage><pub-id pub-id-type="doi">10.1038/s41586-019-0997-6</pub-id><pub-id pub-id-type="pmid">30842660</pub-id></element-citation></ref><ref id="bib23"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Chong</surname><given-names>E</given-names></name><name><surname>Moroni</surname><given-names>M</given-names></name><name><surname>Wilson</surname><given-names>C</given-names></name><name><surname>Shoham</surname><given-names>S</given-names></name><name><surname>Panzeri</surname><given-names>S</given-names></name><name><surname>Rinberg</surname><given-names>D</given-names></name></person-group><year iso-8601-date="2020">2020</year><article-title>Manipulating synthetic optogenetic odors reveals the coding logic of olfactory perception</article-title><source>Science</source><volume>368</volume><elocation-id>eaba2357</elocation-id><pub-id pub-id-type="doi">10.1126/science.aba2357</pub-id><pub-id pub-id-type="pmid">32554567</pub-id></element-citation></ref><ref id="bib24"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Constantinople</surname><given-names>CM</given-names></name><name><surname>Bruno</surname><given-names>RM</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>Deep cortical layers are activated directly by thalamus</article-title><source>Science</source><volume>340</volume><fpage>1591</fpage><lpage>1594</lpage><pub-id pub-id-type="doi">10.1126/science.1236425</pub-id><pub-id pub-id-type="pmid">23812718</pub-id></element-citation></ref><ref id="bib25"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Cossell</surname><given-names>L</given-names></name><name><surname>Iacaruso</surname><given-names>MF</given-names></name><name><surname>Muir</surname><given-names>DR</given-names></name><name><surname>Houlton</surname><given-names>R</given-names></name><name><surname>Sader</surname><given-names>EN</given-names></name><name><surname>Ko</surname><given-names>H</given-names></name><name><surname>Hofer</surname><given-names>SB</given-names></name><name><surname>Mrsic-Flogel</surname><given-names>TD</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>Functional organization of excitatory synaptic strength in primary visual cortex</article-title><source>Nature</source><volume>518</volume><fpage>399</fpage><lpage>403</lpage><pub-id pub-id-type="doi">10.1038/nature14182</pub-id><pub-id pub-id-type="pmid">25652823</pub-id></element-citation></ref><ref id="bib26"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Danskin</surname><given-names>BP</given-names></name><name><surname>Hattori</surname><given-names>R</given-names></name><name><surname>Zhang</surname><given-names>YE</given-names></name><name><surname>Babic</surname><given-names>Z</given-names></name><name><surname>Aoi</surname><given-names>M</given-names></name><name><surname>Komiyama</surname><given-names>T</given-names></name></person-group><year iso-8601-date="2023">2023</year><article-title>Exponential history integration with diverse temporal scales in retrosplenial cortex supports hyperbolic behavior</article-title><source>Science Advances</source><volume>9</volume><elocation-id>eadj4897</elocation-id><pub-id pub-id-type="doi">10.1126/sciadv.adj4897</pub-id><pub-id pub-id-type="pmid">38019904</pub-id></element-citation></ref><ref id="bib27"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Deneve</surname><given-names>S</given-names></name><name><surname>Chalk</surname><given-names>M</given-names></name></person-group><year iso-8601-date="2016">2016a</year><article-title>Efficiency turns the table on neural encoding, decoding and noise</article-title><source>Current Opinion in Neurobiology</source><volume>37</volume><fpage>141</fpage><lpage>148</lpage><pub-id pub-id-type="doi">10.1016/j.conb.2016.03.002</pub-id><pub-id pub-id-type="pmid">27065340</pub-id></element-citation></ref><ref id="bib28"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Deneve</surname><given-names>S</given-names></name><name><surname>Machens</surname><given-names>CK</given-names></name></person-group><year iso-8601-date="2016">2016b</year><article-title>Efficient codes and balanced networks</article-title><source>Nature Neuroscience</source><volume>19</volume><fpage>375</fpage><lpage>382</lpage><pub-id pub-id-type="doi">10.1038/nn.4243</pub-id><pub-id pub-id-type="pmid">26906504</pub-id></element-citation></ref><ref id="bib29"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Denève</surname><given-names>S</given-names></name><name><surname>Alemi</surname><given-names>A</given-names></name><name><surname>Bourdoukan</surname><given-names>R</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>The brain as an efficient and robust adaptive learner</article-title><source>Neuron</source><volume>94</volume><fpage>969</fpage><lpage>977</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2017.05.016</pub-id><pub-id pub-id-type="pmid">28595053</pub-id></element-citation></ref><ref id="bib30"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Destexhe</surname><given-names>A</given-names></name><name><surname>Paré</surname><given-names>D</given-names></name></person-group><year iso-8601-date="1999">1999</year><article-title>Impact of network activity on the integrative properties of neocortical pyramidal neurons in vivo</article-title><source>Journal of Neurophysiology</source><volume>81</volume><fpage>1531</fpage><lpage>1547</lpage><pub-id pub-id-type="doi">10.1152/jn.1999.81.4.1531</pub-id><pub-id pub-id-type="pmid">10200189</pub-id></element-citation></ref><ref id="bib31"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Destexhe</surname><given-names>A</given-names></name><name><surname>Rudolph</surname><given-names>M</given-names></name><name><surname>Paré</surname><given-names>D</given-names></name></person-group><year iso-8601-date="2003">2003</year><article-title>The high-conductance state of neocortical neurons in vivo</article-title><source>Nature Reviews. Neuroscience</source><volume>4</volume><fpage>739</fpage><lpage>751</lpage><pub-id pub-id-type="doi">10.1038/nrn1198</pub-id><pub-id pub-id-type="pmid">12951566</pub-id></element-citation></ref><ref id="bib32"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Emanuel</surname><given-names>AJ</given-names></name><name><surname>Lehnert</surname><given-names>BP</given-names></name><name><surname>Panzeri</surname><given-names>S</given-names></name><name><surname>Harvey</surname><given-names>CD</given-names></name><name><surname>Ginty</surname><given-names>DD</given-names></name></person-group><year iso-8601-date="2021">2021</year><article-title>Cortical responses to touch reflect subcortical integration of LTMR signals</article-title><source>Nature</source><volume>600</volume><fpage>680</fpage><lpage>685</lpage><pub-id pub-id-type="doi">10.1038/s41586-021-04094-x</pub-id><pub-id pub-id-type="pmid">34789880</pub-id></element-citation></ref><ref id="bib33"><element-citation publication-type="confproc"><person-group person-group-type="author"><name><surname>Engelken</surname><given-names>R</given-names></name><name><surname>Goedeke</surname><given-names>S</given-names></name></person-group><year iso-8601-date="2022">2022</year><article-title>A time-resolved theory of information encoding in recurrent neural networks</article-title><conf-name>Advances in Neural Information Processing Systems</conf-name><fpage>35490</fpage><lpage>35503</lpage></element-citation></ref><ref id="bib34"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Fairhall</surname><given-names>AL</given-names></name><name><surname>Lewen</surname><given-names>GD</given-names></name><name><surname>Bialek</surname><given-names>W</given-names></name><name><surname>de Ruyter Van Steveninck</surname><given-names>RR</given-names></name></person-group><year iso-8601-date="2001">2001</year><article-title>Efficiency and ambiguity in an adaptive neural code</article-title><source>Nature</source><volume>412</volume><fpage>787</fpage><lpage>792</lpage><pub-id pub-id-type="doi">10.1038/35090500</pub-id><pub-id pub-id-type="pmid">11518957</pub-id></element-citation></ref><ref id="bib35"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Faisal</surname><given-names>AA</given-names></name><name><surname>Selen</surname><given-names>LPJ</given-names></name><name><surname>Wolpert</surname><given-names>DM</given-names></name></person-group><year iso-8601-date="2008">2008</year><article-title>Noise in the nervous system</article-title><source>Nature Reviews. Neuroscience</source><volume>9</volume><fpage>292</fpage><lpage>303</lpage><pub-id pub-id-type="doi">10.1038/nrn2258</pub-id><pub-id pub-id-type="pmid">18319728</pub-id></element-citation></ref><ref id="bib36"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Fang</surname><given-names>R</given-names></name><name><surname>Xia</surname><given-names>C</given-names></name><name><surname>Close</surname><given-names>JL</given-names></name><name><surname>Zhang</surname><given-names>M</given-names></name><name><surname>He</surname><given-names>J</given-names></name><name><surname>Huang</surname><given-names>Z</given-names></name><name><surname>Halpern</surname><given-names>AR</given-names></name><name><surname>Long</surname><given-names>B</given-names></name><name><surname>Miller</surname><given-names>JA</given-names></name><name><surname>Lein</surname><given-names>ES</given-names></name><name><surname>Zhuang</surname><given-names>X</given-names></name></person-group><year iso-8601-date="2022">2022</year><article-title>Conservation and divergence of cortical cell organization in human and mouse revealed by MERFISH</article-title><source>Science</source><volume>377</volume><fpage>56</fpage><lpage>62</lpage><pub-id pub-id-type="doi">10.1126/science.abm1741</pub-id><pub-id pub-id-type="pmid">35771910</pub-id></element-citation></ref><ref id="bib37"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Gerstner</surname><given-names>W</given-names></name><name><surname>Kistler</surname><given-names>WM</given-names></name><name><surname>Naud</surname><given-names>R</given-names></name><name><surname>Paninski</surname><given-names>L</given-names></name></person-group><year iso-8601-date="2014">2014</year><source>Neuronal Dynamics: From Single Neurons to Networks and Models of Cognition</source><publisher-name>Cambridge University Press</publisher-name><pub-id pub-id-type="doi">10.1017/CBO9781107447615</pub-id></element-citation></ref><ref id="bib38"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Gold</surname><given-names>JI</given-names></name><name><surname>Shadlen</surname><given-names>MN</given-names></name></person-group><year iso-8601-date="2001">2001</year><article-title>Neural computations that underlie decisions about sensory stimuli</article-title><source>Trends in Cognitive Sciences</source><volume>5</volume><fpage>10</fpage><lpage>16</lpage><pub-id pub-id-type="doi">10.1016/S1364-6613(00)01567-9</pub-id></element-citation></ref><ref id="bib39"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Gutierrez</surname><given-names>GJ</given-names></name><name><surname>Denève</surname><given-names>S</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>Population adaptation in efficient balanced networks</article-title><source>eLife</source><volume>8</volume><elocation-id>e46926</elocation-id><pub-id pub-id-type="doi">10.7554/eLife.46926</pub-id><pub-id pub-id-type="pmid">31550233</pub-id></element-citation></ref><ref id="bib40"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Harkin</surname><given-names>EF</given-names></name><name><surname>Béïque</surname><given-names>JC</given-names></name><name><surname>Naud</surname><given-names>R</given-names></name></person-group><year iso-8601-date="2021">2021</year><chapter-title>A user’s guide to generalized integrate-and-fire models</chapter-title><person-group person-group-type="editor"><name><surname>Giugliano</surname><given-names>M</given-names></name><name><surname>Negrello</surname><given-names>M</given-names></name><name><surname>Linaro</surname><given-names>D</given-names></name></person-group><source>Computational Modelling of the Brain: Modelling Approaches to Cells, Circuits and Networks</source><publisher-name>Springer</publisher-name><fpage>69</fpage><lpage>86</lpage><pub-id pub-id-type="doi">10.1007/978-3-030-89439-9_3</pub-id></element-citation></ref><ref id="bib41"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hofer</surname><given-names>SB</given-names></name><name><surname>Ko</surname><given-names>H</given-names></name><name><surname>Pichler</surname><given-names>B</given-names></name><name><surname>Vogelstein</surname><given-names>J</given-names></name><name><surname>Ros</surname><given-names>H</given-names></name><name><surname>Zeng</surname><given-names>H</given-names></name><name><surname>Lein</surname><given-names>E</given-names></name><name><surname>Lesica</surname><given-names>NA</given-names></name><name><surname>Mrsic-Flogel</surname><given-names>TD</given-names></name></person-group><year iso-8601-date="2011">2011</year><article-title>Differential connectivity and response dynamics of excitatory and inhibitory neurons in visual cortex</article-title><source>Nature Neuroscience</source><volume>14</volume><fpage>1045</fpage><lpage>1052</lpage><pub-id pub-id-type="doi">10.1038/nn.2876</pub-id><pub-id pub-id-type="pmid">21765421</pub-id></element-citation></ref><ref id="bib42"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hu</surname><given-names>H</given-names></name><name><surname>Gan</surname><given-names>J</given-names></name><name><surname>Jonas</surname><given-names>P</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>GABAergic interneurons: from cellular design to microcircuit function</article-title><source>Science</source><volume>345</volume><elocation-id>1255263</elocation-id><pub-id pub-id-type="doi">10.1126/science.1255263</pub-id><pub-id pub-id-type="pmid">25082707</pub-id></element-citation></ref><ref id="bib43"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ince</surname><given-names>RAA</given-names></name><name><surname>Panzeri</surname><given-names>S</given-names></name><name><surname>Kayser</surname><given-names>C</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>Neural codes formed by small and temporally precise populations in auditory cortex</article-title><source>The Journal of Neuroscience</source><volume>33</volume><fpage>18277</fpage><lpage>18287</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.2631-13.2013</pub-id><pub-id pub-id-type="pmid">24227737</pub-id></element-citation></ref><ref id="bib44"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Jolivet</surname><given-names>R</given-names></name><name><surname>Schürmann</surname><given-names>F</given-names></name><name><surname>Berger</surname><given-names>TK</given-names></name><name><surname>Naud</surname><given-names>R</given-names></name><name><surname>Gerstner</surname><given-names>W</given-names></name><name><surname>Roth</surname><given-names>A</given-names></name></person-group><year iso-8601-date="2008">2008</year><article-title>The quantitative single-neuron modeling competition</article-title><source>Biological Cybernetics</source><volume>99</volume><fpage>417</fpage><lpage>426</lpage><pub-id pub-id-type="doi">10.1007/s00422-008-0261-x</pub-id><pub-id pub-id-type="pmid">19011928</pub-id></element-citation></ref><ref id="bib45"><element-citation publication-type="confproc"><person-group person-group-type="author"><name><surname>Kadmon</surname><given-names>J</given-names></name><name><surname>Timcheck</surname><given-names>J</given-names></name><name><surname>Ganguli</surname><given-names>S</given-names></name></person-group><year iso-8601-date="2020">2020</year><article-title>Predictive coding in balanced neural networks with noise, chaos and delays</article-title><conf-name>Advances in Neural Information Processing Systems</conf-name><fpage>16677</fpage><lpage>16688</lpage></element-citation></ref><ref id="bib46"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kaufman</surname><given-names>MT</given-names></name><name><surname>Churchland</surname><given-names>MM</given-names></name><name><surname>Ryu</surname><given-names>SI</given-names></name><name><surname>Shenoy</surname><given-names>KV</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>Cortical activity in the null space: permitting preparation without movement</article-title><source>Nature Neuroscience</source><volume>17</volume><fpage>440</fpage><lpage>448</lpage><pub-id pub-id-type="doi">10.1038/nn.3643</pub-id><pub-id pub-id-type="pmid">24487233</pub-id></element-citation></ref><ref id="bib47"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kayser</surname><given-names>C</given-names></name><name><surname>Logothetis</surname><given-names>NK</given-names></name><name><surname>Panzeri</surname><given-names>S</given-names></name></person-group><year iso-8601-date="2010">2010</year><article-title>Millisecond encoding precision of auditory cortex neurons</article-title><source>PNAS</source><volume>107</volume><fpage>16976</fpage><lpage>16981</lpage><pub-id pub-id-type="doi">10.1073/pnas.1012656107</pub-id><pub-id pub-id-type="pmid">20837521</pub-id></element-citation></ref><ref id="bib48"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Koren</surname><given-names>V</given-names></name><name><surname>Denève</surname><given-names>S</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>Computational account of spontaneous activity as a signature of predictive coding</article-title><source>PLOS Computational Biology</source><volume>13</volume><elocation-id>e1005355</elocation-id><pub-id pub-id-type="doi">10.1371/journal.pcbi.1005355</pub-id><pub-id pub-id-type="pmid">28114353</pub-id></element-citation></ref><ref id="bib49"><element-citation publication-type="confproc"><person-group person-group-type="author"><name><surname>Koren</surname><given-names>V</given-names></name><name><surname>Panzeri</surname><given-names>S</given-names></name></person-group><year iso-8601-date="2022">2022</year><article-title>Biologically plausible solutions for spiking networks with efficient coding</article-title><conf-name>Advances in Neural Information Processing Systems</conf-name><fpage>20607</fpage><lpage>20620</lpage></element-citation></ref><ref id="bib50"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Koren</surname><given-names>V</given-names></name><name><surname>Bondanelli</surname><given-names>G</given-names></name><name><surname>Panzeri</surname><given-names>S</given-names></name></person-group><year iso-8601-date="2023">2023</year><article-title>Computational methods to study information processing in neural circuits</article-title><source>Computational and Structural Biotechnology Journal</source><volume>21</volume><fpage>910</fpage><lpage>922</lpage><pub-id pub-id-type="doi">10.1016/j.csbj.2023.01.009</pub-id><pub-id pub-id-type="pmid">36698970</pub-id></element-citation></ref><ref id="bib51"><element-citation publication-type="software"><person-group person-group-type="author"><name><surname>Koren</surname><given-names>V</given-names></name></person-group><year iso-8601-date="2025">2025</year><data-title>Efficient_EI</data-title><version designator="swh:1:rev:f8140d49fe2bc539ebff433991af788745379710">swh:1:rev:f8140d49fe2bc539ebff433991af788745379710</version><source>Software Heritage</source><ext-link ext-link-type="uri" xlink:href="https://archive.softwareheritage.org/swh:1:dir:0d9ecc8155d9d134fd0fbbc2e7272c4f38bb13ea;origin=https://github.com/VeronikaKoren/efficient_EI;visit=swh:1:snp:e89530842de2ae5ce9af7dac13f6c32ac4f29afe;anchor=swh:1:rev:f8140d49fe2bc539ebff433991af788745379710">https://archive.softwareheritage.org/swh:1:dir:0d9ecc8155d9d134fd0fbbc2e7272c4f38bb13ea;origin=https://github.com/VeronikaKoren/efficient_EI;visit=swh:1:snp:e89530842de2ae5ce9af7dac13f6c32ac4f29afe;anchor=swh:1:rev:f8140d49fe2bc539ebff433991af788745379710</ext-link></element-citation></ref><ref id="bib52"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Koulakov</surname><given-names>AA</given-names></name><name><surname>Rinberg</surname><given-names>D</given-names></name></person-group><year iso-8601-date="2011">2011</year><article-title>Sparse incomplete representations: A potential role of olfactory granule cells</article-title><source>Neuron</source><volume>72</volume><fpage>124</fpage><lpage>136</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2011.07.031</pub-id><pub-id pub-id-type="pmid">21982374</pub-id></element-citation></ref><ref id="bib53"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kuan</surname><given-names>AT</given-names></name><name><surname>Bondanelli</surname><given-names>G</given-names></name><name><surname>Driscoll</surname><given-names>LN</given-names></name><name><surname>Han</surname><given-names>J</given-names></name><name><surname>Kim</surname><given-names>M</given-names></name><name><surname>Hildebrand</surname><given-names>DGC</given-names></name><name><surname>Graham</surname><given-names>BJ</given-names></name><name><surname>Wilson</surname><given-names>DE</given-names></name><name><surname>Thomas</surname><given-names>LA</given-names></name><name><surname>Panzeri</surname><given-names>S</given-names></name><name><surname>Harvey</surname><given-names>CD</given-names></name><name><surname>Lee</surname><given-names>W-CA</given-names></name></person-group><year iso-8601-date="2024">2024</year><article-title>Synaptic wiring motifs in posterior parietal cortex support decision-making</article-title><source>Nature</source><volume>627</volume><fpage>367</fpage><lpage>373</lpage><pub-id pub-id-type="doi">10.1038/s41586-024-07088-7</pub-id><pub-id pub-id-type="pmid">38383788</pub-id></element-citation></ref><ref id="bib54"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Lefort</surname><given-names>S</given-names></name><name><surname>Tomm</surname><given-names>C</given-names></name><name><surname>Floyd Sarria</surname><given-names>JC</given-names></name><name><surname>Petersen</surname><given-names>CCH</given-names></name></person-group><year iso-8601-date="2009">2009</year><article-title>The excitatory neuronal network of the C2 barrel column in mouse primary somatosensory cortex</article-title><source>Neuron</source><volume>61</volume><fpage>301</fpage><lpage>316</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2008.12.020</pub-id><pub-id pub-id-type="pmid">19186171</pub-id></element-citation></ref><ref id="bib55"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Levy</surname><given-names>M</given-names></name><name><surname>Sporns</surname><given-names>O</given-names></name><name><surname>MacLean</surname><given-names>JN</given-names></name></person-group><year iso-8601-date="2020">2020</year><article-title>Network analysis of murine cortical dynamics implicates untuned neurons in visual stimulus coding</article-title><source>Cell Reports</source><volume>31</volume><elocation-id>107483</elocation-id><pub-id pub-id-type="doi">10.1016/j.celrep.2020.03.047</pub-id><pub-id pub-id-type="pmid">32294431</pub-id></element-citation></ref><ref id="bib56"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Lewicki</surname><given-names>MS</given-names></name></person-group><year iso-8601-date="2002">2002</year><article-title>Efficient coding of natural sounds</article-title><source>Nature Neuroscience</source><volume>5</volume><fpage>356</fpage><lpage>363</lpage><pub-id pub-id-type="doi">10.1038/nn831</pub-id><pub-id pub-id-type="pmid">11896400</pub-id></element-citation></ref><ref id="bib57"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Li</surname><given-names>Z</given-names></name></person-group><year iso-8601-date="2014">2014</year><source>Understanding Vision: Theory, Models, and Data</source><publisher-name>Oxford University Press</publisher-name></element-citation></ref><ref id="bib58"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Lochmann</surname><given-names>T</given-names></name><name><surname>Ernst</surname><given-names>UA</given-names></name><name><surname>Denève</surname><given-names>S</given-names></name></person-group><year iso-8601-date="2012">2012</year><article-title>Perceptual inference predicts contextual modulations of sensory responses</article-title><source>The Journal of Neuroscience</source><volume>32</volume><fpage>4179</fpage><lpage>4195</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.0817-11.2012</pub-id><pub-id pub-id-type="pmid">22442081</pub-id></element-citation></ref><ref id="bib59"><element-citation publication-type="confproc"><person-group person-group-type="author"><name><surname>Luo</surname><given-names>C</given-names></name><name><surname>Zhan</surname><given-names>J</given-names></name><name><surname>Xue</surname><given-names>X</given-names></name><name><surname>Wang</surname><given-names>L</given-names></name><name><surname>Ren</surname><given-names>R</given-names></name><name><surname>Yang</surname><given-names>Q</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>Cosine normalization: Using cosine similarity instead of dot product in neural networks</article-title><conf-name>Artificial Neural Networks and Machine Learning–ICANN 2018: 27th International Conference on Artificial Neural Networks</conf-name><fpage>382</fpage><lpage>391</lpage><pub-id pub-id-type="doi">10.1007/978-3-030-01418-6_38</pub-id></element-citation></ref><ref id="bib60"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Mackwood</surname><given-names>O</given-names></name><name><surname>Naumann</surname><given-names>LB</given-names></name><name><surname>Sprekeler</surname><given-names>H</given-names></name></person-group><year iso-8601-date="2021">2021</year><article-title>Learning excitatory-inhibitory neuronal assemblies in recurrent networks</article-title><source>eLife</source><volume>10</volume><elocation-id>e59715</elocation-id><pub-id pub-id-type="doi">10.7554/eLife.59715</pub-id><pub-id pub-id-type="pmid">33900199</pub-id></element-citation></ref><ref id="bib61"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Manning</surname><given-names>TS</given-names></name><name><surname>Alexander</surname><given-names>E</given-names></name><name><surname>Cumming</surname><given-names>BG</given-names></name><name><surname>DeAngelis</surname><given-names>GC</given-names></name><name><surname>Huang</surname><given-names>X</given-names></name><name><surname>Cooper</surname><given-names>EA</given-names></name></person-group><year iso-8601-date="2024">2024</year><article-title>Transformations of sensory information in the brain suggest changing criteria for optimality</article-title><source>PLOS Computational Biology</source><volume>20</volume><elocation-id>e1011783</elocation-id><pub-id pub-id-type="doi">10.1371/journal.pcbi.1011783</pub-id><pub-id pub-id-type="pmid">38206969</pub-id></element-citation></ref><ref id="bib62"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Markram</surname><given-names>H</given-names></name><name><surname>Toledo-Rodriguez</surname><given-names>M</given-names></name><name><surname>Wang</surname><given-names>Y</given-names></name><name><surname>Gupta</surname><given-names>A</given-names></name><name><surname>Silberberg</surname><given-names>G</given-names></name><name><surname>Wu</surname><given-names>C</given-names></name></person-group><year iso-8601-date="2004">2004</year><article-title>Interneurons of the neocortical inhibitory system</article-title><source>Nature Reviews. Neuroscience</source><volume>5</volume><fpage>793</fpage><lpage>807</lpage><pub-id pub-id-type="doi">10.1038/nrn1519</pub-id><pub-id pub-id-type="pmid">15378039</pub-id></element-citation></ref><ref id="bib63"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Mazzoni</surname><given-names>A</given-names></name><name><surname>Panzeri</surname><given-names>S</given-names></name><name><surname>Logothetis</surname><given-names>NK</given-names></name><name><surname>Brunel</surname><given-names>N</given-names></name></person-group><year iso-8601-date="2008">2008</year><article-title>Encoding of naturalistic stimuli by local field potential spectra in networks of excitatory and inhibitory neurons</article-title><source>PLOS Computational Biology</source><volume>4</volume><elocation-id>e1000239</elocation-id><pub-id pub-id-type="doi">10.1371/journal.pcbi.1000239</pub-id><pub-id pub-id-type="pmid">19079571</pub-id></element-citation></ref><ref id="bib64"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Mensi</surname><given-names>S</given-names></name><name><surname>Naud</surname><given-names>R</given-names></name><name><surname>Pozzorini</surname><given-names>C</given-names></name><name><surname>Avermann</surname><given-names>M</given-names></name><name><surname>Petersen</surname><given-names>CCH</given-names></name><name><surname>Gerstner</surname><given-names>W</given-names></name></person-group><year iso-8601-date="2012">2012</year><article-title>Parameter extraction and classification of three cortical neuron types reveals two distinct adaptation mechanisms</article-title><source>Journal of Neurophysiology</source><volume>107</volume><fpage>1756</fpage><lpage>1775</lpage><pub-id pub-id-type="doi">10.1152/jn.00408.2011</pub-id><pub-id pub-id-type="pmid">22157113</pub-id></element-citation></ref><ref id="bib65"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Młynarski</surname><given-names>WF</given-names></name><name><surname>Hermundstad</surname><given-names>AM</given-names></name></person-group><year iso-8601-date="2021">2021</year><article-title>Efficient and adaptive sensory codes</article-title><source>Nature Neuroscience</source><volume>24</volume><fpage>998</fpage><lpage>1009</lpage><pub-id pub-id-type="doi">10.1038/s41593-021-00846-0</pub-id></element-citation></ref><ref id="bib66"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Moreno-Bote</surname><given-names>R</given-names></name><name><surname>Drugowitsch</surname><given-names>J</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>Causal inference and explaining away in a spiking network</article-title><source>Scientific Reports</source><volume>5</volume><elocation-id>17531</elocation-id><pub-id pub-id-type="doi">10.1038/srep17531</pub-id><pub-id pub-id-type="pmid">26621426</pub-id></element-citation></ref><ref id="bib67"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Muller</surname><given-names>ME</given-names></name></person-group><year iso-8601-date="1959">1959</year><article-title>A note on A method for generating points uniformly on <italic>n</italic> -dimensional spheres</article-title><source>Communications of the ACM</source><volume>2</volume><fpage>19</fpage><lpage>20</lpage><pub-id pub-id-type="doi">10.1145/377939.377946</pub-id></element-citation></ref><ref id="bib68"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Najafi</surname><given-names>F</given-names></name><name><surname>Elsayed</surname><given-names>GF</given-names></name><name><surname>Cao</surname><given-names>R</given-names></name><name><surname>Pnevmatikakis</surname><given-names>E</given-names></name><name><surname>Latham</surname><given-names>PE</given-names></name><name><surname>Cunningham</surname><given-names>JP</given-names></name><name><surname>Churchland</surname><given-names>AK</given-names></name></person-group><year iso-8601-date="2020">2020</year><article-title>Excitatory and inhibitory subnetworks are equally selective during decision-making and emerge simultaneously during learning</article-title><source>Neuron</source><volume>105</volume><fpage>165</fpage><lpage>179</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2019.09.045</pub-id><pub-id pub-id-type="pmid">31753580</pub-id></element-citation></ref><ref id="bib69"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Nemenman</surname><given-names>I</given-names></name><name><surname>Lewen</surname><given-names>GD</given-names></name><name><surname>Bialek</surname><given-names>W</given-names></name><name><surname>de Ruyter van Steveninck</surname><given-names>RR</given-names></name></person-group><year iso-8601-date="2008">2008</year><article-title>Neural coding of natural stimuli: information at sub-millisecond resolution</article-title><source>PLOS Computational Biology</source><volume>4</volume><elocation-id>e1000025</elocation-id><pub-id pub-id-type="doi">10.1371/journal.pcbi.1000025</pub-id><pub-id pub-id-type="pmid">18369423</pub-id></element-citation></ref><ref id="bib70"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Neske</surname><given-names>GT</given-names></name><name><surname>Patrick</surname><given-names>SL</given-names></name><name><surname>Connors</surname><given-names>BW</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>Contributions of diverse excitatory and inhibitory neurons to recurrent network activity in cerebral cortex</article-title><source>The Journal of Neuroscience</source><volume>35</volume><fpage>1089</fpage><lpage>1105</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.2279-14.2015</pub-id><pub-id pub-id-type="pmid">25609625</pub-id></element-citation></ref><ref id="bib71"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Okun</surname><given-names>M</given-names></name><name><surname>Lampl</surname><given-names>I</given-names></name></person-group><year iso-8601-date="2008">2008</year><article-title>Instantaneous correlation of excitation and inhibition during ongoing and sensory-evoked activities</article-title><source>Nature Neuroscience</source><volume>11</volume><fpage>535</fpage><lpage>537</lpage><pub-id pub-id-type="doi">10.1038/nn.2105</pub-id></element-citation></ref><ref id="bib72"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Oldenburg</surname><given-names>IA</given-names></name><name><surname>Hendricks</surname><given-names>WD</given-names></name><name><surname>Handy</surname><given-names>G</given-names></name><name><surname>Shamardani</surname><given-names>K</given-names></name><name><surname>Bounds</surname><given-names>HA</given-names></name><name><surname>Doiron</surname><given-names>B</given-names></name><name><surname>Adesnik</surname><given-names>H</given-names></name></person-group><year iso-8601-date="2024">2024</year><article-title>The logic of recurrent circuits in the primary visual cortex</article-title><source>Nature Neuroscience</source><volume>27</volume><fpage>137</fpage><lpage>147</lpage><pub-id pub-id-type="doi">10.1038/s41593-023-01510-5</pub-id><pub-id pub-id-type="pmid">38172437</pub-id></element-citation></ref><ref id="bib73"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Olshausen</surname><given-names>BA</given-names></name><name><surname>Field</surname><given-names>DJ</given-names></name></person-group><year iso-8601-date="1996">1996</year><article-title>Emergence of simple-cell receptive field properties by learning a sparse code for natural images</article-title><source>Nature</source><volume>381</volume><fpage>607</fpage><lpage>609</lpage><pub-id pub-id-type="doi">10.1038/381607a0</pub-id><pub-id pub-id-type="pmid">8637596</pub-id></element-citation></ref><ref id="bib74"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Olshausen</surname><given-names>BA</given-names></name><name><surname>Field</surname><given-names>DJ</given-names></name></person-group><year iso-8601-date="1997">1997</year><article-title>Sparse coding with an overcomplete basis set: A strategy employed by V1?</article-title><source>Vision Research</source><volume>37</volume><fpage>3311</fpage><lpage>3325</lpage><pub-id pub-id-type="doi">10.1016/s0042-6989(97)00169-7</pub-id><pub-id pub-id-type="pmid">9425546</pub-id></element-citation></ref><ref id="bib75"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Olshausen</surname><given-names>B</given-names></name><name><surname>Field</surname><given-names>D</given-names></name></person-group><year iso-8601-date="2004">2004</year><article-title>Sparse coding of sensory inputs</article-title><source>Current Opinion in Neurobiology</source><volume>14</volume><fpage>481</fpage><lpage>487</lpage><pub-id pub-id-type="doi">10.1016/j.conb.2004.07.007</pub-id></element-citation></ref><ref id="bib76"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Pala</surname><given-names>A</given-names></name><name><surname>Petersen</surname><given-names>CCH</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>In vivo measurement of cell-type-specific synaptic connectivity and synaptic transmission in layer 2/3 mouse barrel cortex</article-title><source>Neuron</source><volume>85</volume><fpage>68</fpage><lpage>75</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2014.11.025</pub-id><pub-id pub-id-type="pmid">25543458</pub-id></element-citation></ref><ref id="bib77"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Panzeri</surname><given-names>S</given-names></name><name><surname>Petersen</surname><given-names>RS</given-names></name><name><surname>Schultz</surname><given-names>SR</given-names></name><name><surname>Lebedev</surname><given-names>M</given-names></name><name><surname>Diamond</surname><given-names>ME</given-names></name></person-group><year iso-8601-date="2001">2001</year><article-title>The role of spike timing in the coding of stimulus location in rat somatosensory cortex</article-title><source>Neuron</source><volume>29</volume><fpage>769</fpage><lpage>777</lpage><pub-id pub-id-type="doi">10.1016/S0896-6273(01)00251-3</pub-id></element-citation></ref><ref id="bib78"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Panzeri</surname><given-names>S</given-names></name><name><surname>Brunel</surname><given-names>N</given-names></name><name><surname>Logothetis</surname><given-names>NK</given-names></name><name><surname>Kayser</surname><given-names>C</given-names></name></person-group><year iso-8601-date="2010">2010</year><article-title>Sensory neural codes using multiplexed temporal scales</article-title><source>Trends in Neurosciences</source><volume>33</volume><fpage>111</fpage><lpage>120</lpage><pub-id pub-id-type="doi">10.1016/j.tins.2009.12.001</pub-id></element-citation></ref><ref id="bib79"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Panzeri</surname><given-names>S</given-names></name><name><surname>Moroni</surname><given-names>M</given-names></name><name><surname>Safaai</surname><given-names>H</given-names></name><name><surname>Harvey</surname><given-names>CD</given-names></name></person-group><year iso-8601-date="2022">2022</year><article-title>The structures and functions of correlations in neural population codes</article-title><source>Nature Reviews Neuroscience</source><volume>23</volume><fpage>551</fpage><lpage>567</lpage><pub-id pub-id-type="doi">10.1038/s41583-022-00606-4</pub-id></element-citation></ref><ref id="bib80"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Podlaski</surname><given-names>WF</given-names></name><name><surname>Machens</surname><given-names>CK</given-names></name></person-group><year iso-8601-date="2024">2024</year><article-title>Approximating nonlinear functions with latent boundaries in low-rank excitatory-inhibitory spiking networks</article-title><source>Neural Computation</source><volume>36</volume><fpage>803</fpage><lpage>857</lpage><pub-id pub-id-type="doi">10.1162/neco_a_01658</pub-id></element-citation></ref><ref id="bib81"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Pozzorini</surname><given-names>C</given-names></name><name><surname>Naud</surname><given-names>R</given-names></name><name><surname>Mensi</surname><given-names>S</given-names></name><name><surname>Gerstner</surname><given-names>W</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>Temporal whitening by power-law adaptation in neocortical neurons</article-title><source>Nature Neuroscience</source><volume>16</volume><fpage>942</fpage><lpage>948</lpage><pub-id pub-id-type="doi">10.1038/nn.3431</pub-id></element-citation></ref><ref id="bib82"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Renart</surname><given-names>A</given-names></name><name><surname>de la Rocha</surname><given-names>J</given-names></name><name><surname>Bartho</surname><given-names>P</given-names></name><name><surname>Hollender</surname><given-names>L</given-names></name><name><surname>Parga</surname><given-names>N</given-names></name><name><surname>Reyes</surname><given-names>A</given-names></name><name><surname>Harris</surname><given-names>KD</given-names></name></person-group><year iso-8601-date="2010">2010</year><article-title>The asynchronous state in cortical circuits</article-title><source>Science</source><volume>327</volume><fpage>587</fpage><lpage>590</lpage><pub-id pub-id-type="doi">10.1126/science.1179850</pub-id><pub-id pub-id-type="pmid">20110507</pub-id></element-citation></ref><ref id="bib83"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Roy</surname><given-names>K</given-names></name><name><surname>Jaiswal</surname><given-names>A</given-names></name><name><surname>Panda</surname><given-names>P</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>Towards spike-based machine intelligence with neuromorphic computing</article-title><source>Nature</source><volume>575</volume><fpage>607</fpage><lpage>617</lpage><pub-id pub-id-type="doi">10.1038/s41586-019-1677-2</pub-id></element-citation></ref><ref id="bib84"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Rullán Buxó</surname><given-names>CE</given-names></name><name><surname>Pillow</surname><given-names>JW</given-names></name></person-group><year iso-8601-date="2020">2020</year><article-title>Poisson balanced spiking networks</article-title><source>PLOS Computational Biology</source><volume>16</volume><elocation-id>e1008261</elocation-id><pub-id pub-id-type="doi">10.1371/journal.pcbi.1008261</pub-id><pub-id pub-id-type="pmid">33216741</pub-id></element-citation></ref><ref id="bib85"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Runyan</surname><given-names>CA</given-names></name><name><surname>Schummers</surname><given-names>J</given-names></name><name><surname>Van Wart</surname><given-names>A</given-names></name><name><surname>Kuhlman</surname><given-names>SJ</given-names></name><name><surname>Wilson</surname><given-names>NR</given-names></name><name><surname>Huang</surname><given-names>ZJ</given-names></name><name><surname>Sur</surname><given-names>M</given-names></name></person-group><year iso-8601-date="2010">2010</year><article-title>Response features of parvalbumin-expressing interneurons suggest precise roles for subtypes of inhibition in visual cortex</article-title><source>Neuron</source><volume>67</volume><fpage>847</fpage><lpage>857</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2010.08.006</pub-id><pub-id pub-id-type="pmid">20826315</pub-id></element-citation></ref><ref id="bib86"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Sadeh</surname><given-names>S</given-names></name><name><surname>Clopath</surname><given-names>C</given-names></name></person-group><year iso-8601-date="2020">2020</year><article-title>Theory of neuronal perturbome in cortical networks</article-title><source>PNAS</source><volume>117</volume><fpage>26966</fpage><lpage>26976</lpage><pub-id pub-id-type="doi">10.1073/pnas.2004568117</pub-id><pub-id pub-id-type="pmid">33055215</pub-id></element-citation></ref><ref id="bib87"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Safavi</surname><given-names>S</given-names></name><name><surname>Chalk</surname><given-names>M</given-names></name><name><surname>Logothetis</surname><given-names>NK</given-names></name><name><surname>Levina</surname><given-names>A</given-names></name></person-group><year iso-8601-date="2024">2024</year><article-title>Signatures of criticality in efficient coding networks</article-title><source>PNAS</source><volume>121</volume><elocation-id>e2302730121</elocation-id><pub-id pub-id-type="doi">10.1073/pnas.2302730121</pub-id><pub-id pub-id-type="pmid">39352933</pub-id></element-citation></ref><ref id="bib88"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Schuman</surname><given-names>CD</given-names></name><name><surname>Kulkarni</surname><given-names>SR</given-names></name><name><surname>Parsa</surname><given-names>M</given-names></name><name><surname>Mitchell</surname><given-names>JP</given-names></name><name><surname>Date</surname><given-names>P</given-names></name><name><surname>Kay</surname><given-names>B</given-names></name></person-group><year iso-8601-date="2022">2022</year><article-title>Opportunities for neuromorphic computing algorithms and applications</article-title><source>Nature Computational Science</source><volume>2</volume><fpage>10</fpage><lpage>19</lpage><pub-id pub-id-type="doi">10.1038/s43588-021-00184-y</pub-id></element-citation></ref><ref id="bib89"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Schwalger</surname><given-names>T</given-names></name><name><surname>Lindner</surname><given-names>B</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>Patterns of interval correlations in neural oscillators with adaptation</article-title><source>Frontiers in Computational Neuroscience</source><volume>7</volume><elocation-id>164</elocation-id><pub-id pub-id-type="doi">10.3389/fncom.2013.00164</pub-id><pub-id pub-id-type="pmid">24348372</pub-id></element-citation></ref><ref id="bib90"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Schwalger</surname><given-names>T</given-names></name><name><surname>Deger</surname><given-names>M</given-names></name><name><surname>Gerstner</surname><given-names>W</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>Towards a theory of cortical columns: From spiking neurons to interacting neural populations of finite size</article-title><source>PLOS Computational Biology</source><volume>13</volume><elocation-id>e1005507</elocation-id><pub-id pub-id-type="doi">10.1371/journal.pcbi.1005507</pub-id><pub-id pub-id-type="pmid">28422957</pub-id></element-citation></ref><ref id="bib91"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Scott</surname><given-names>BB</given-names></name><name><surname>Constantinople</surname><given-names>CM</given-names></name><name><surname>Akrami</surname><given-names>A</given-names></name><name><surname>Hanks</surname><given-names>TD</given-names></name><name><surname>Brody</surname><given-names>CD</given-names></name><name><surname>Tank</surname><given-names>DW</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>Fronto-parietal cortical circuits encode accumulated evidence with a diversity of timescales</article-title><source>Neuron</source><volume>95</volume><fpage>385</fpage><lpage>398</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2017.06.013</pub-id><pub-id pub-id-type="pmid">28669543</pub-id></element-citation></ref><ref id="bib92"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Seeman</surname><given-names>SC</given-names></name><name><surname>Campagnola</surname><given-names>L</given-names></name><name><surname>Davoudian</surname><given-names>PA</given-names></name><name><surname>Hoggarth</surname><given-names>A</given-names></name><name><surname>Hage</surname><given-names>TA</given-names></name><name><surname>Bosma-Moody</surname><given-names>A</given-names></name><name><surname>Baker</surname><given-names>CA</given-names></name><name><surname>Lee</surname><given-names>JH</given-names></name><name><surname>Mihalas</surname><given-names>S</given-names></name><name><surname>Teeter</surname><given-names>C</given-names></name><name><surname>Ko</surname><given-names>AL</given-names></name><name><surname>Ojemann</surname><given-names>JG</given-names></name><name><surname>Gwinn</surname><given-names>RP</given-names></name><name><surname>Silbergeld</surname><given-names>DL</given-names></name><name><surname>Cobbs</surname><given-names>C</given-names></name><name><surname>Phillips</surname><given-names>J</given-names></name><name><surname>Lein</surname><given-names>E</given-names></name><name><surname>Murphy</surname><given-names>G</given-names></name><name><surname>Koch</surname><given-names>C</given-names></name><name><surname>Zeng</surname><given-names>H</given-names></name><name><surname>Jarsky</surname><given-names>T</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>Sparse recurrent excitatory connectivity in the microcircuit of the adult mouse and human cortex</article-title><source>eLife</source><volume>7</volume><elocation-id>e37349</elocation-id><pub-id pub-id-type="doi">10.7554/eLife.37349</pub-id><pub-id pub-id-type="pmid">30256194</pub-id></element-citation></ref><ref id="bib93"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Simoncelli</surname><given-names>EP</given-names></name><name><surname>Olshausen</surname><given-names>BA</given-names></name></person-group><year iso-8601-date="2001">2001</year><article-title>Natural image statistics and neural representation</article-title><source>Annual Review of Neuroscience</source><volume>24</volume><fpage>1193</fpage><lpage>1216</lpage><pub-id pub-id-type="doi">10.1146/annurev.neuro.24.1.1193</pub-id><pub-id pub-id-type="pmid">11520932</pub-id></element-citation></ref><ref id="bib94"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Softky</surname><given-names>WR</given-names></name><name><surname>Koch</surname><given-names>C</given-names></name></person-group><year iso-8601-date="1993">1993</year><article-title>The highly irregular firing of cortical cells is inconsistent with temporal integration of random EPSPs</article-title><source>The Journal of Neuroscience</source><volume>13</volume><fpage>334</fpage><lpage>350</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.13-01-00334.1993</pub-id><pub-id pub-id-type="pmid">8423479</pub-id></element-citation></ref><ref id="bib95"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Stepanyants</surname><given-names>A</given-names></name><name><surname>Martinez</surname><given-names>LM</given-names></name><name><surname>Ferecskó</surname><given-names>AS</given-names></name><name><surname>Kisvárday</surname><given-names>ZF</given-names></name></person-group><year iso-8601-date="2009">2009</year><article-title>The fractions of short- and long-range connections in the visual cortex</article-title><source>PNAS</source><volume>106</volume><fpage>3555</fpage><lpage>3560</lpage><pub-id pub-id-type="doi">10.1073/pnas.0810390106</pub-id><pub-id pub-id-type="pmid">19221032</pub-id></element-citation></ref><ref id="bib96"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Sukenik</surname><given-names>N</given-names></name><name><surname>Vinogradov</surname><given-names>O</given-names></name><name><surname>Weinreb</surname><given-names>E</given-names></name><name><surname>Segal</surname><given-names>M</given-names></name><name><surname>Levina</surname><given-names>A</given-names></name><name><surname>Moses</surname><given-names>E</given-names></name></person-group><year iso-8601-date="2021">2021</year><article-title>Neuronal circuits overcome imbalance in excitation and inhibition by adjusting connection numbers</article-title><source>PNAS</source><volume>118</volume><elocation-id>e2018459118</elocation-id><pub-id pub-id-type="doi">10.1073/pnas.2018459118</pub-id><pub-id pub-id-type="pmid">33723048</pub-id></element-citation></ref><ref id="bib97"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Tan</surname><given-names>AYY</given-names></name><name><surname>Andoni</surname><given-names>S</given-names></name><name><surname>Priebe</surname><given-names>NJ</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>A spontaneous state of weakly correlated synaptic excitation and inhibition in visual cortex</article-title><source>Neuroscience</source><volume>247</volume><fpage>364</fpage><lpage>375</lpage><pub-id pub-id-type="doi">10.1016/j.neuroscience.2013.05.037</pub-id><pub-id pub-id-type="pmid">23727451</pub-id></element-citation></ref><ref id="bib98"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Tavoni</surname><given-names>G</given-names></name><name><surname>Balasubramanian</surname><given-names>V</given-names></name><name><surname>Gold</surname><given-names>JI</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>What is optimal in optimal inference?</article-title><source>Current Opinion in Behavioral Sciences</source><volume>29</volume><fpage>117</fpage><lpage>126</lpage><pub-id pub-id-type="doi">10.1016/j.cobeha.2019.07.008</pub-id><pub-id pub-id-type="pmid">32832585</pub-id></element-citation></ref><ref id="bib99"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Thalmeier</surname><given-names>D</given-names></name><name><surname>Uhlmann</surname><given-names>M</given-names></name><name><surname>Kappen</surname><given-names>HJ</given-names></name><name><surname>Memmesheimer</surname><given-names>R-M</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Learning universal computations with spikes</article-title><source>PLOS Computational Biology</source><volume>12</volume><elocation-id>e1004895</elocation-id><pub-id pub-id-type="doi">10.1371/journal.pcbi.1004895</pub-id><pub-id pub-id-type="pmid">27309381</pub-id></element-citation></ref><ref id="bib100"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Timcheck</surname><given-names>J</given-names></name><name><surname>Kadmon</surname><given-names>J</given-names></name><name><surname>Boahen</surname><given-names>K</given-names></name><name><surname>Ganguli</surname><given-names>S</given-names></name></person-group><year iso-8601-date="2022">2022</year><article-title>Optimal noise level for coding with tightly balanced networks of spiking neurons in the presence of transmission delays</article-title><source>PLOS Computational Biology</source><volume>18</volume><elocation-id>e1010593</elocation-id><pub-id pub-id-type="doi">10.1371/journal.pcbi.1010593</pub-id><pub-id pub-id-type="pmid">36251693</pub-id></element-citation></ref><ref id="bib101"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Turrigiano</surname><given-names>GG</given-names></name><name><surname>Nelson</surname><given-names>SB</given-names></name></person-group><year iso-8601-date="2004">2004</year><article-title>Homeostatic plasticity in the developing nervous system</article-title><source>Nature Reviews Neuroscience</source><volume>5</volume><fpage>97</fpage><lpage>107</lpage><pub-id pub-id-type="doi">10.1038/nrn1327</pub-id></element-citation></ref><ref id="bib102"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Usher</surname><given-names>M</given-names></name><name><surname>McClelland</surname><given-names>JL</given-names></name></person-group><year iso-8601-date="2001">2001</year><article-title>The time course of perceptual choice: The leaky, competing accumulator model</article-title><source>Psychological Review</source><volume>108</volume><fpage>550</fpage><lpage>592</lpage><pub-id pub-id-type="doi">10.1037//0033-295X.108.3.550</pub-id></element-citation></ref><ref id="bib103"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Valente</surname><given-names>M</given-names></name><name><surname>Pica</surname><given-names>G</given-names></name><name><surname>Bondanelli</surname><given-names>G</given-names></name><name><surname>Moroni</surname><given-names>M</given-names></name><name><surname>Runyan</surname><given-names>CA</given-names></name><name><surname>Morcos</surname><given-names>AS</given-names></name><name><surname>Harvey</surname><given-names>CD</given-names></name><name><surname>Panzeri</surname><given-names>S</given-names></name></person-group><year iso-8601-date="2021">2021</year><article-title>Correlations enhance the behavioral readout of neural population activity in association cortex</article-title><source>Nature Neuroscience</source><volume>24</volume><fpage>975</fpage><lpage>986</lpage><pub-id pub-id-type="doi">10.1038/s41593-021-00845-1</pub-id><pub-id pub-id-type="pmid">33986549</pub-id></element-citation></ref><ref id="bib104"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Vinje</surname><given-names>WE</given-names></name><name><surname>Gallant</surname><given-names>JL</given-names></name></person-group><year iso-8601-date="2000">2000</year><article-title>Sparse coding and decorrelation in primary visual cortex during natural vision</article-title><source>Science</source><volume>287</volume><fpage>1273</fpage><lpage>1276</lpage><pub-id pub-id-type="doi">10.1126/science.287.5456.1273</pub-id></element-citation></ref><ref id="bib105"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Vogels</surname><given-names>TP</given-names></name><name><surname>Sprekeler</surname><given-names>H</given-names></name><name><surname>Zenke</surname><given-names>F</given-names></name><name><surname>Clopath</surname><given-names>C</given-names></name><name><surname>Gerstner</surname><given-names>W</given-names></name></person-group><year iso-8601-date="2011">2011</year><article-title>Inhibitory plasticity balances excitation and inhibition in sensory pathways and memory networks</article-title><source>Science</source><volume>334</volume><fpage>1569</fpage><lpage>1573</lpage><pub-id pub-id-type="doi">10.1126/science.1211095</pub-id><pub-id pub-id-type="pmid">22075724</pub-id></element-citation></ref><ref id="bib106"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wark</surname><given-names>B</given-names></name><name><surname>Fairhall</surname><given-names>A</given-names></name><name><surname>Rieke</surname><given-names>F</given-names></name></person-group><year iso-8601-date="2009">2009</year><article-title>Timescales of inference in visual adaptation</article-title><source>Neuron</source><volume>61</volume><fpage>750</fpage><lpage>761</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2009.01.019</pub-id><pub-id pub-id-type="pmid">19285471</pub-id></element-citation></ref><ref id="bib107"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Whittaker</surname><given-names>VP</given-names></name></person-group><year iso-8601-date="1983">1983</year><chapter-title>What is dale’s principle</chapter-title><person-group person-group-type="editor"><name><surname>Osborne</surname><given-names>NN</given-names></name></person-group><source>Dale’s Principle and Communication Between Neurones Pergamon</source><publisher-name>Elsevier</publisher-name><fpage>1</fpage><lpage>5</lpage><pub-id pub-id-type="doi">10.1016/B978-0-08-029789-7.50006-5</pub-id></element-citation></ref><ref id="bib108"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wilson</surname><given-names>NR</given-names></name><name><surname>Runyan</surname><given-names>CA</given-names></name><name><surname>Wang</surname><given-names>FL</given-names></name><name><surname>Sur</surname><given-names>M</given-names></name></person-group><year iso-8601-date="2012">2012</year><article-title>Division and subtraction by distinct cortical inhibitory networks in vivo</article-title><source>Nature</source><volume>488</volume><fpage>343</fpage><lpage>348</lpage><pub-id pub-id-type="doi">10.1038/nature11347</pub-id><pub-id pub-id-type="pmid">22878717</pub-id></element-citation></ref><ref id="bib109"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Xue</surname><given-names>M</given-names></name><name><surname>Atallah</surname><given-names>BV</given-names></name><name><surname>Scanziani</surname><given-names>M</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>Equalizing excitation-inhibition ratios across visual cortical neurons</article-title><source>Nature</source><volume>511</volume><fpage>596</fpage><lpage>600</lpage><pub-id pub-id-type="doi">10.1038/nature13321</pub-id><pub-id pub-id-type="pmid">25043046</pub-id></element-citation></ref><ref id="bib110"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Zeldenrust</surname><given-names>F</given-names></name><name><surname>Gutkin</surname><given-names>B</given-names></name><name><surname>Denéve</surname><given-names>S</given-names></name></person-group><year iso-8601-date="2021">2021</year><article-title>Efficient and robust coding in heterogeneous recurrent networks</article-title><source>PLOS Computational Biology</source><volume>17</volume><elocation-id>e1008673</elocation-id><pub-id pub-id-type="doi">10.1371/journal.pcbi.1008673</pub-id><pub-id pub-id-type="pmid">33930016</pub-id></element-citation></ref><ref id="bib111"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Zhu</surname><given-names>M</given-names></name><name><surname>Rozell</surname><given-names>CJ</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>Visual nonclassical receptive field effects emerge from sparse coding in a dynamical system</article-title><source>PLOS Computational Biology</source><volume>9</volume><elocation-id>e1003191</elocation-id><pub-id pub-id-type="doi">10.1371/journal.pcbi.1003191</pub-id><pub-id pub-id-type="pmid">24009491</pub-id></element-citation></ref><ref id="bib112"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Znamenskiy</surname><given-names>P</given-names></name><name><surname>Kim</surname><given-names>MH</given-names></name><name><surname>Muir</surname><given-names>DR</given-names></name><name><surname>Iacaruso</surname><given-names>MF</given-names></name><name><surname>Hofer</surname><given-names>SB</given-names></name><name><surname>Mrsic-Flogel</surname><given-names>TD</given-names></name></person-group><year iso-8601-date="2024">2024</year><article-title>Functional specificity of recurrent inhibition in visual cortex</article-title><source>Neuron</source><volume>112</volume><fpage>991</fpage><lpage>1000</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2023.12.013</pub-id><pub-id pub-id-type="pmid">38244539</pub-id></element-citation></ref><ref id="bib113"><element-citation publication-type="preprint"><person-group person-group-type="author"><name><surname>Zylberberg</surname><given-names>J</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>The role of untuned neurons in sensory information coding</article-title><source>bioRxiv</source><pub-id pub-id-type="doi">10.1101/134379</pub-id></element-citation></ref></ref-list><app-group><app id="appendix-1"><title>Appendix 1</title><sec sec-type="appendix" id="s8"><title>Derivation of the one cell type model</title><p>An efficient spiking model network with one cell type (1CT) has been developed previously (<xref ref-type="bibr" rid="bib11">Boerlin et al., 2013</xref>), and properties of the 1CT model where the computation is assumed to be the leaky integration of inputs has been addressed in a number of previous studies (<xref ref-type="bibr" rid="bib12">Bourdoukan et al., 2012</xref>; <xref ref-type="bibr" rid="bib7">Barrett et al., 2016</xref>; <xref ref-type="bibr" rid="bib48">Koren and Denève, 2017</xref>; <xref ref-type="bibr" rid="bib39">Gutierrez and Denève, 2019</xref>; <xref ref-type="bibr" rid="bib13">Brendel et al., 2020</xref>). Compared to the efficient E-I model, the 1CT model can be seen as a simplification, and can be treated similarly to the E-I model, which is what we demonstrate in this section.</p><p>As the name of the model suggests, all neurons in the 1CT model are of the same cell type, and we have <inline-formula><mml:math id="inf506"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mo>…</mml:mo><mml:mo>,</mml:mo><mml:mi>N</mml:mi></mml:mstyle></mml:math></inline-formula> such neurons. We can then use the definitions in <xref ref-type="disp-formula" rid="equ6 equ7 equ8 equ9">Equations 6–9</xref> (now without the index <inline-formula><mml:math id="inf507"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>y</mml:mi></mml:mstyle></mml:math></inline-formula>) and a loss function similar to the one in <xref ref-type="bibr" rid="bib48">Koren and Denève, 2017</xref>, but with only one (quadratic) regularizer<disp-formula id="equ62"><label>(45)</label><mml:math id="m62"><mml:mrow><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msup><mml:mrow><mml:mi mathvariant="normal">L</mml:mi></mml:mrow><mml:mrow><mml:mtext>1CT</mml:mtext></mml:mrow></mml:msup><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mrow><mml:mo symmetric="true">‖</mml:mo><mml:mrow><mml:mrow><mml:mover><mml:mi>x</mml:mi><mml:mo stretchy="false">→</mml:mo></mml:mover></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>−</mml:mo><mml:mrow><mml:mover><mml:mrow><mml:mover><mml:mi>x</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mo stretchy="false">→</mml:mo></mml:mover></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo symmetric="true">‖</mml:mo></mml:mrow><mml:mo>+</mml:mo><mml:msup><mml:mi>β</mml:mi><mml:mn>1</mml:mn></mml:msup><mml:munderover><mml:mo>∑</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>N</mml:mi></mml:mrow></mml:munderover><mml:msubsup><mml:mi>r</mml:mi><mml:mi>i</mml:mi><mml:mrow><mml:mspace width="thinmathspace"/><mml:mn>2</mml:mn></mml:mrow></mml:msubsup><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>,</mml:mo></mml:mstyle></mml:mrow></mml:math></disp-formula></p><p>with <inline-formula><mml:math id="inf508"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msup><mml:mi>β</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mn>1</mml:mn></mml:mrow></mml:msup><mml:mo>&gt;</mml:mo><mml:mn>0</mml:mn></mml:mstyle></mml:math></inline-formula>. The encoding error of the 1CT model minimizes the squared distance between the target signal <inline-formula><mml:math id="inf509"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow class="MJX-TeXAtom-ORD"><mml:mover><mml:mi>x</mml:mi><mml:mo stretchy="false">→</mml:mo></mml:mover></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mstyle></mml:math></inline-formula> and the estimate <inline-formula><mml:math id="inf510"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow class="MJX-TeXAtom-ORD"><mml:mover><mml:mrow class="MJX-TeXAtom-ORD"><mml:mover><mml:mi>x</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mo stretchy="false">→</mml:mo></mml:mover></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mstyle></mml:math></inline-formula>. As we apply the condition for spiking as for the E-I network (<xref ref-type="disp-formula" rid="equ12">Equation 12</xref> without the index <inline-formula><mml:math id="inf511"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>y</mml:mi></mml:mstyle></mml:math></inline-formula>) and follow the same steps as for the E-I network, we get<disp-formula id="equ63"><label>(46)</label><mml:math id="m63"><mml:mrow><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msubsup><mml:mrow><mml:mover><mml:mi>w</mml:mi><mml:mo stretchy="false">→</mml:mo></mml:mover></mml:mrow><mml:mi>i</mml:mi><mml:mi mathvariant="normal">⊤</mml:mi></mml:msubsup><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mrow><mml:mover><mml:mi>x</mml:mi><mml:mo stretchy="false">→</mml:mo></mml:mover></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>−</mml:mo><mml:mrow><mml:mover><mml:mrow><mml:mover><mml:mi>x</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mo stretchy="false">→</mml:mo></mml:mover></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>−</mml:mo><mml:msup><mml:mi>β</mml:mi><mml:mn>1</mml:mn></mml:msup><mml:msub><mml:mi>r</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>&gt;</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mn>2</mml:mn></mml:mfrac><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msup><mml:mrow><mml:mo symmetric="true">‖</mml:mo><mml:msub><mml:mrow><mml:mover><mml:mi>w</mml:mi><mml:mo stretchy="false">→</mml:mo></mml:mover></mml:mrow><mml:mi>i</mml:mi></mml:msub><mml:mo symmetric="true">‖</mml:mo></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup><mml:mo>+</mml:mo><mml:msup><mml:mi>β</mml:mi><mml:mn>1</mml:mn></mml:msup><mml:mo>−</mml:mo><mml:msub><mml:mi>ξ</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>,</mml:mo></mml:mstyle></mml:mrow></mml:math></disp-formula></p><p>with <inline-formula><mml:math id="inf512"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msub><mml:mi>ξ</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mstyle></mml:math></inline-formula> the noise at the condition for spiking. Same as in the E-I model, we define the noise as an Ornstein-Uhlenbeck process with zero mean, obeying<disp-formula id="equ64"><label>(47)</label><mml:math id="m64"><mml:mrow><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msub><mml:mrow><mml:mover><mml:mi>ξ</mml:mi><mml:mo>˙</mml:mo></mml:mover></mml:mrow><mml:mi>i</mml:mi></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mo>−</mml:mo><mml:mi>λ</mml:mi><mml:msub><mml:mi>ξ</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>+</mml:mo><mml:msqrt><mml:mn>2</mml:mn><mml:mi>λ</mml:mi></mml:msqrt><mml:msub><mml:mi>σ</mml:mi><mml:mrow><mml:mi>ξ</mml:mi></mml:mrow></mml:msub><mml:msub><mml:mi>η</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>,</mml:mo></mml:mstyle></mml:mrow></mml:math></disp-formula></p><p>where <inline-formula><mml:math id="inf513"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>η</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula> is a Gaussian white noise and <inline-formula><mml:math id="inf514"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>λ</mml:mi><mml:mo>=</mml:mo><mml:msup><mml:mi>τ</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msup></mml:mstyle></mml:math></inline-formula> is the inverse time constant of the process.</p><p>We now define proxies of the membrane potential and the firing threshold as<disp-formula id="equ65"><label>(48)</label><mml:math id="m65"><mml:mrow><mml:mtable columnalign="right left right left right left right left right left right left" rowspacing="3pt" columnspacing="0em 2em 0em 2em 0em 2em 0em 2em 0em 2em 0em" displaystyle="true"><mml:mtr><mml:mtd><mml:msub><mml:mi>u</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mtd><mml:mtd><mml:mi/><mml:mo>:=</mml:mo><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msubsup><mml:mrow><mml:mover><mml:mi>w</mml:mi><mml:mo stretchy="false">→</mml:mo></mml:mover></mml:mrow><mml:mi>i</mml:mi><mml:mi mathvariant="normal">⊤</mml:mi></mml:msubsup><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mrow><mml:mover><mml:mi>x</mml:mi><mml:mo stretchy="false">→</mml:mo></mml:mover></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>−</mml:mo><mml:mrow><mml:mover><mml:mrow><mml:mover><mml:mi>x</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mo stretchy="false">→</mml:mo></mml:mover></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>−</mml:mo><mml:msup><mml:mi>β</mml:mi><mml:mn>1</mml:mn></mml:msup><mml:msub><mml:mi>r</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>,</mml:mo></mml:mstyle></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:msub><mml:mi>θ</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mtd><mml:mtd><mml:mi/><mml:mo>:=</mml:mo><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mfrac><mml:mn>1</mml:mn><mml:mn>2</mml:mn></mml:mfrac><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msup><mml:mrow><mml:mo symmetric="true">‖</mml:mo><mml:msub><mml:mrow><mml:mover><mml:mi>w</mml:mi><mml:mo stretchy="false">→</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo symmetric="true">‖</mml:mo></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup><mml:mo>+</mml:mo><mml:msup><mml:mi>β</mml:mi><mml:mn>1</mml:mn></mml:msup><mml:mo>−</mml:mo><mml:msub><mml:mi>ξ</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>.</mml:mo></mml:mstyle></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:math></disp-formula></p><p>Differentiating the proxy of the membrane potential <inline-formula><mml:math id="inf515"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msub><mml:mi>u</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mstyle></mml:math></inline-formula> and rewriting the model as an integrate-and-fire neuron, we get<disp-formula id="equ66"><label>(49)</label><mml:math id="m66"><mml:mrow><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mtable columnalign="right left right left right left right left right left right left" rowspacing="3pt" columnspacing="0em 2em 0em 2em 0em 2em 0em 2em 0em 2em 0em" displaystyle="true"><mml:mtr><mml:mtd><mml:msub><mml:mrow><mml:mover><mml:mi>u</mml:mi><mml:mo>˙</mml:mo></mml:mover></mml:mrow><mml:mi>i</mml:mi></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mtd><mml:mtd><mml:mi/><mml:mo>=</mml:mo><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mo>−</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mi>τ</mml:mi></mml:mfrac><mml:msub><mml:mi>u</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>+</mml:mo><mml:msubsup><mml:mrow><mml:mover><mml:mi>w</mml:mi><mml:mo stretchy="false">→</mml:mo></mml:mover></mml:mrow><mml:mi>i</mml:mi><mml:mi mathvariant="normal">⊤</mml:mi></mml:msubsup><mml:mrow><mml:mover><mml:mi>s</mml:mi><mml:mo stretchy="false">→</mml:mo></mml:mover></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>−</mml:mo><mml:munderover><mml:mo>∑</mml:mo><mml:mrow><mml:mstyle scriptlevel="1"><mml:mtable rowspacing="0.1em" columnspacing="0em" displaystyle="false"><mml:mtr><mml:mtd><mml:mi>j</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mi>j</mml:mi><mml:mo>≠</mml:mo><mml:mi>i</mml:mi></mml:mtd></mml:mtr></mml:mtable></mml:mstyle></mml:mrow><mml:mi>N</mml:mi></mml:munderover><mml:msubsup><mml:mrow><mml:mover><mml:mi>w</mml:mi><mml:mo stretchy="false">→</mml:mo></mml:mover></mml:mrow><mml:mi>i</mml:mi><mml:mi mathvariant="normal">⊤</mml:mi></mml:msubsup><mml:msub><mml:mrow><mml:mover><mml:mi>w</mml:mi><mml:mo stretchy="false">→</mml:mo></mml:mover></mml:mrow><mml:mi>j</mml:mi></mml:msub><mml:mtext> </mml:mtext><mml:msub><mml:mi>f</mml:mi><mml:mi>j</mml:mi></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>,</mml:mo></mml:mstyle></mml:mtd></mml:mtr><mml:mtr><mml:mtd/><mml:mtd><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mtext>if</mml:mtext><mml:mspace width="thinmathspace"/><mml:mspace width="thinmathspace"/><mml:msub><mml:mi>u</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:msup><mml:mi>t</mml:mi><mml:mo>−</mml:mo></mml:msup><mml:mo stretchy="false">)</mml:mo><mml:mo>≥</mml:mo><mml:msub><mml:mi>θ</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo stretchy="false">→</mml:mo><mml:msub><mml:mi>u</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:msup><mml:mi>t</mml:mi><mml:mo>+</mml:mo></mml:msup><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:msubsup><mml:mi>u</mml:mi><mml:mi>i</mml:mi><mml:mrow><mml:mtext>reset</mml:mtext></mml:mrow></mml:msubsup><mml:mo>,</mml:mo></mml:mstyle></mml:mtd></mml:mtr><mml:mtr><mml:mtd/><mml:mtd><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msub><mml:mi>θ</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mn>2</mml:mn></mml:mfrac><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mo fence="false" stretchy="false">‖</mml:mo><mml:msub><mml:mrow><mml:mover><mml:mi>w</mml:mi><mml:mo stretchy="false">→</mml:mo></mml:mover></mml:mrow><mml:mi>i</mml:mi></mml:msub><mml:msubsup><mml:mo fence="false" stretchy="false">‖</mml:mo><mml:mn>2</mml:mn><mml:mn>2</mml:mn></mml:msubsup><mml:mo>+</mml:mo><mml:msup><mml:mi>β</mml:mi><mml:mn>1</mml:mn></mml:msup><mml:mo>−</mml:mo><mml:msub><mml:mi>ξ</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>,</mml:mo></mml:mstyle></mml:mtd></mml:mtr><mml:mtr><mml:mtd/><mml:mtd><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msubsup><mml:mi>u</mml:mi><mml:mi>i</mml:mi><mml:mrow><mml:mtext>reset</mml:mtext></mml:mrow></mml:msubsup><mml:mo>=</mml:mo><mml:msub><mml:mi>θ</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>−</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msup><mml:mrow><mml:mo symmetric="true">‖</mml:mo><mml:msub><mml:mrow><mml:mover><mml:mi>w</mml:mi><mml:mo stretchy="false">→</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo symmetric="true">‖</mml:mo></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup><mml:mo>+</mml:mo><mml:msup><mml:mi>β</mml:mi><mml:mn>1</mml:mn></mml:msup></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>.</mml:mo></mml:mstyle></mml:mtd></mml:mtr></mml:mtable></mml:mstyle></mml:mrow></mml:math></disp-formula></p><p>We now proceed in the same way as with the E-I model and define new variables<disp-formula id="equ67"><label>(50)</label><mml:math id="m67"><mml:mrow><mml:mtable columnalign="right left right left right left right left right left right left" rowspacing="3pt" columnspacing="0em 2em 0em 2em 0em 2em 0em 2em 0em 2em 0em" displaystyle="true"><mml:mtr><mml:mtd><mml:msub><mml:mi>V</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mtd><mml:mtd><mml:mi/><mml:mo>:=</mml:mo><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msub><mml:mi>u</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>+</mml:mo><mml:msub><mml:mi>V</mml:mi><mml:mrow><mml:mtext>rest</mml:mtext></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mn>2</mml:mn></mml:mfrac><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>c</mml:mi><mml:mo>−</mml:mo><mml:msup><mml:mi>β</mml:mi><mml:mn>1</mml:mn></mml:msup><mml:mo>+</mml:mo><mml:msub><mml:mi>ξ</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>,</mml:mo><mml:mspace width="2em"/><mml:msub><mml:mi>V</mml:mi><mml:mrow><mml:mtext>rest</mml:mtext></mml:mrow></mml:msub><mml:mo>&lt;</mml:mo><mml:mn>0</mml:mn><mml:mo>,</mml:mo></mml:mstyle></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:msub><mml:mi>ϑ</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mtd><mml:mtd><mml:mi/><mml:mo>:=</mml:mo><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msub><mml:mi>V</mml:mi><mml:mrow><mml:mtext>rest</mml:mtext></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mn>2</mml:mn></mml:mfrac><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msup><mml:mrow><mml:mo symmetric="true">‖</mml:mo><mml:msub><mml:mrow><mml:mover><mml:mi>w</mml:mi><mml:mo stretchy="false">→</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo symmetric="true">‖</mml:mo></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup><mml:mo>+</mml:mo><mml:mi>c</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>.</mml:mo></mml:mstyle></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:math></disp-formula></p><p>In these new variables, we can rewrite the membrane equation of the 1CT model as follows:<disp-formula id="equ68"><label>(51)</label><mml:math id="m68"><mml:mrow><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>τ</mml:mi><mml:msub><mml:mrow><mml:mover><mml:mi>V</mml:mi><mml:mo>˙</mml:mo></mml:mover></mml:mrow><mml:mi>i</mml:mi></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mo>−</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>V</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>−</mml:mo><mml:msub><mml:mi>V</mml:mi><mml:mrow><mml:mtext>rest</mml:mtext></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:mo>+</mml:mo><mml:mi>τ</mml:mi><mml:msubsup><mml:mrow><mml:mover><mml:mi>w</mml:mi><mml:mo stretchy="false">→</mml:mo></mml:mover></mml:mrow><mml:mi>i</mml:mi><mml:mi mathvariant="normal">⊤</mml:mi></mml:msubsup><mml:mrow><mml:mover><mml:mi>s</mml:mi><mml:mo stretchy="false">→</mml:mo></mml:mover></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>−</mml:mo><mml:mi>τ</mml:mi><mml:munderover><mml:mo>∑</mml:mo><mml:mrow><mml:mrow><mml:munder><mml:mrow><mml:mi>j</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>j</mml:mi><mml:mo>≠</mml:mo><mml:mi>i</mml:mi></mml:mrow></mml:munder></mml:mrow></mml:mrow><mml:mi>N</mml:mi></mml:munderover><mml:msubsup><mml:mrow><mml:mover><mml:mi>w</mml:mi><mml:mo stretchy="false">→</mml:mo></mml:mover></mml:mrow><mml:mi>i</mml:mi><mml:mi mathvariant="normal">⊤</mml:mi></mml:msubsup><mml:msub><mml:mrow><mml:mover><mml:mi>w</mml:mi><mml:mo stretchy="false">→</mml:mo></mml:mover></mml:mrow><mml:mi>j</mml:mi></mml:msub><mml:mtext> </mml:mtext><mml:msub><mml:mi>f</mml:mi><mml:mi>j</mml:mi></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>+</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mn>2</mml:mn></mml:mfrac><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>c</mml:mi><mml:mo>−</mml:mo><mml:msup><mml:mi>β</mml:mi><mml:mn>1</mml:mn></mml:msup></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>+</mml:mo><mml:msqrt><mml:mfrac><mml:mi>τ</mml:mi><mml:mn>2</mml:mn></mml:mfrac></mml:msqrt><mml:msub><mml:mi>σ</mml:mi><mml:mrow><mml:mi>ξ</mml:mi></mml:mrow></mml:msub><mml:msub><mml:mi>η</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>.</mml:mo></mml:mstyle></mml:mrow></mml:math></disp-formula></p><p>Finally, we rewrite the model with a more compact notation of a leaky integrate-and-fire neuron model with transmembrane currents,<disp-formula id="equ69"><label>(52a)</label><mml:math id="m69"><mml:mrow><mml:mtable columnalign="right left right left right left right left right left right left" rowspacing="3pt" columnspacing="0em 2em 0em 2em 0em 2em 0em 2em 0em 2em 0em" displaystyle="true"><mml:mtr><mml:mtd><mml:mi>τ</mml:mi><mml:msub><mml:mrow><mml:mover><mml:mi>V</mml:mi><mml:mo>˙</mml:mo></mml:mover></mml:mrow><mml:mi>i</mml:mi></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mtd><mml:mtd><mml:mi/><mml:mo>=</mml:mo><mml:mo>−</mml:mo><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>V</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>−</mml:mo><mml:msub><mml:mi>V</mml:mi><mml:mrow><mml:mtext>rest</mml:mtext></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>+</mml:mo><mml:msub><mml:mi>R</mml:mi><mml:mi>m</mml:mi></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msubsup><mml:mi>I</mml:mi><mml:mi>i</mml:mi><mml:mrow><mml:mspace width="thinmathspace"/><mml:mtext>ff</mml:mtext></mml:mrow></mml:msubsup><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>+</mml:mo><mml:msubsup><mml:mi>I</mml:mi><mml:mi>i</mml:mi><mml:mrow><mml:mspace width="thinmathspace"/><mml:mtext>syn</mml:mtext></mml:mrow></mml:msubsup><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>+</mml:mo><mml:msubsup><mml:mi>I</mml:mi><mml:mi>i</mml:mi><mml:mrow><mml:mspace width="thinmathspace"/><mml:mtext>ext</mml:mtext></mml:mrow></mml:msubsup><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>,</mml:mo></mml:mstyle></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mtext>if </mml:mtext><mml:msub><mml:mi>V</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:msup><mml:mi>t</mml:mi><mml:mo>−</mml:mo></mml:msup><mml:mo stretchy="false">)</mml:mo></mml:mtd><mml:mtd><mml:mi/><mml:mo>≥</mml:mo><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msub><mml:mi>ϑ</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo stretchy="false">→</mml:mo><mml:msub><mml:mi>V</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:msup><mml:mi>t</mml:mi><mml:mo>+</mml:mo></mml:msup><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:msubsup><mml:mi>V</mml:mi><mml:mi>i</mml:mi><mml:mrow><mml:mspace width="thinmathspace"/><mml:mtext>reset</mml:mtext></mml:mrow></mml:msubsup><mml:mo>,</mml:mo></mml:mstyle></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:msub><mml:mi>ϑ</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mtd><mml:mtd><mml:mi/><mml:mo>=</mml:mo><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msub><mml:mi>V</mml:mi><mml:mrow><mml:mtext>rest</mml:mtext></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mn>2</mml:mn></mml:mfrac><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mo fence="false" stretchy="false">‖</mml:mo><mml:msub><mml:mrow><mml:mover><mml:mi>w</mml:mi><mml:mo stretchy="false">→</mml:mo></mml:mover></mml:mrow><mml:mi>i</mml:mi></mml:msub><mml:msubsup><mml:mo fence="false" stretchy="false">‖</mml:mo><mml:mn>2</mml:mn><mml:mn>2</mml:mn></mml:msubsup><mml:mo>+</mml:mo><mml:mi>c</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>,</mml:mo></mml:mstyle></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:msubsup><mml:mi>V</mml:mi><mml:mi>i</mml:mi><mml:mrow><mml:mspace width="thinmathspace"/><mml:mtext>reset</mml:mtext></mml:mrow></mml:msubsup></mml:mtd><mml:mtd><mml:mi/><mml:mo>=</mml:mo><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msub><mml:mi>V</mml:mi><mml:mrow><mml:mtext>rest</mml:mtext></mml:mrow></mml:msub><mml:mo>−</mml:mo><mml:msup><mml:mi>β</mml:mi><mml:mn>1</mml:mn></mml:msup><mml:mo>+</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mn>2</mml:mn></mml:mfrac><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>c</mml:mi><mml:mo>−</mml:mo><mml:mo fence="false" stretchy="false">‖</mml:mo><mml:msub><mml:mrow><mml:mover><mml:mi>w</mml:mi><mml:mo stretchy="false">→</mml:mo></mml:mover></mml:mrow><mml:mi>i</mml:mi></mml:msub><mml:msubsup><mml:mo fence="false" stretchy="false">‖</mml:mo><mml:mn>2</mml:mn><mml:mn>2</mml:mn></mml:msubsup></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>,</mml:mo></mml:mstyle></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:math></disp-formula></p><p>with currents<disp-formula id="equ70"><label>(52b)</label><mml:math id="m70"><mml:mrow><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mtable columnalign="right left right left right left right left right left right left" rowspacing="3pt" columnspacing="0em 2em 0em 2em 0em 2em 0em 2em 0em 2em 0em" displaystyle="true"><mml:mtr><mml:mtd><mml:msubsup><mml:mi>I</mml:mi><mml:mi>i</mml:mi><mml:mrow><mml:mspace width="thinmathspace"/><mml:mtext>ff</mml:mtext></mml:mrow></mml:msubsup><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mtd><mml:mtd><mml:mi/><mml:mo>=</mml:mo><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msub><mml:mi>C</mml:mi><mml:mi>m</mml:mi></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msubsup><mml:mrow><mml:mover><mml:mi>w</mml:mi><mml:mo stretchy="false">→</mml:mo></mml:mover></mml:mrow><mml:mi>i</mml:mi><mml:mi mathvariant="normal">⊤</mml:mi></mml:msubsup><mml:mrow><mml:mover><mml:mi>s</mml:mi><mml:mo stretchy="false">→</mml:mo></mml:mover></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>,</mml:mo></mml:mstyle></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:msubsup><mml:mi>I</mml:mi><mml:mi>i</mml:mi><mml:mrow><mml:mspace width="thinmathspace"/><mml:mtext>syn</mml:mtext></mml:mrow></mml:msubsup><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mtd><mml:mtd><mml:mi/><mml:mo>=</mml:mo><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msub><mml:mi>C</mml:mi><mml:mi>m</mml:mi></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:munderover><mml:mo>∑</mml:mo><mml:mrow><mml:mstyle scriptlevel="1"><mml:mtable rowspacing="0.1em" columnspacing="0em" displaystyle="false"><mml:mtr><mml:mtd><mml:mi>j</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mi>j</mml:mi><mml:mo>≠</mml:mo><mml:mi>i</mml:mi></mml:mtd></mml:mtr></mml:mtable></mml:mstyle></mml:mrow><mml:mi>N</mml:mi></mml:munderover><mml:msub><mml:mi>J</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mtext> </mml:mtext><mml:msub><mml:mi>f</mml:mi><mml:mi>j</mml:mi></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>,</mml:mo><mml:mspace width="2em"/><mml:msub><mml:mi>J</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mo>−</mml:mo><mml:msubsup><mml:mrow><mml:mover><mml:mi>w</mml:mi><mml:mo stretchy="false">→</mml:mo></mml:mover></mml:mrow><mml:mi>i</mml:mi><mml:mi mathvariant="normal">⊤</mml:mi></mml:msubsup><mml:msub><mml:mrow><mml:mover><mml:mi>w</mml:mi><mml:mo stretchy="false">→</mml:mo></mml:mover></mml:mrow><mml:mi>j</mml:mi></mml:msub><mml:mo>,</mml:mo></mml:mstyle></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:msubsup><mml:mi>I</mml:mi><mml:mi>i</mml:mi><mml:mrow><mml:mspace width="thinmathspace"/><mml:mtext>ext</mml:mtext></mml:mrow></mml:msubsup><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mtd><mml:mtd><mml:mi/><mml:mo>=</mml:mo><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msub><mml:mi>C</mml:mi><mml:mi>m</mml:mi></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mfrac><mml:mrow><mml:mi>c</mml:mi><mml:mo>−</mml:mo><mml:msup><mml:mi>β</mml:mi><mml:mn>1</mml:mn></mml:msup></mml:mrow><mml:mn>2</mml:mn></mml:mfrac><mml:mo>+</mml:mo><mml:msup><mml:mi>σ</mml:mi><mml:mn>1</mml:mn></mml:msup><mml:msub><mml:mi>η</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>,</mml:mo><mml:mspace width="2em"/><mml:msup><mml:mi>σ</mml:mi><mml:mn>1</mml:mn></mml:msup><mml:mo>=</mml:mo><mml:mfrac><mml:msub><mml:mi>σ</mml:mi><mml:mrow><mml:mi>ξ</mml:mi></mml:mrow></mml:msub><mml:msqrt><mml:mn>2</mml:mn><mml:mi>τ</mml:mi></mml:msqrt></mml:mfrac><mml:mo>.</mml:mo></mml:mstyle></mml:mtd></mml:mtr></mml:mtable></mml:mstyle></mml:mrow></mml:math></disp-formula></p><p>Note that the model with one cell type does not obey Dale’s law, since the same neuron sends to its postsynaptic targets excitatory and inhibitory currents, depending on the tuning similarity of the presynaptic and the postsynaptic neuron <inline-formula><mml:math id="inf516"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msub><mml:mrow class="MJX-TeXAtom-ORD"><mml:mover><mml:mi>w</mml:mi><mml:mo stretchy="false">→</mml:mo></mml:mover></mml:mrow><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:mstyle></mml:math></inline-formula> and <inline-formula><mml:math id="inf517"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msub><mml:mrow class="MJX-TeXAtom-ORD"><mml:mover><mml:mi>w</mml:mi><mml:mo stretchy="false">→</mml:mo></mml:mover></mml:mrow><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:mstyle></mml:math></inline-formula> (<xref ref-type="disp-formula" rid="equ70">Equation 52b</xref>). In particular, if the pre- and postsynaptic neurons have similar selectivity (<inline-formula><mml:math id="inf518"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msubsup><mml:mrow><mml:mover><mml:mi>w</mml:mi><mml:mo stretchy="false">→</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">⊤</mml:mi></mml:mrow></mml:msubsup><mml:msub><mml:mrow><mml:mover><mml:mi>w</mml:mi><mml:mo stretchy="false">→</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>&gt;</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:mstyle></mml:math></inline-formula>), the recurrent interaction is inhibitory, and if the neurons have different selectivity (<inline-formula><mml:math id="inf519"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msubsup><mml:mrow><mml:mover><mml:mi>w</mml:mi><mml:mo stretchy="false">→</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">⊤</mml:mi></mml:mrow></mml:msubsup><mml:msub><mml:mrow><mml:mover><mml:mi>w</mml:mi><mml:mo stretchy="false">→</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>&lt;</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:mstyle></mml:math></inline-formula>), the interaction is excitatory. Simply put, neurons with similar selectivity inhibit each other while neurons with different selectivity excite each other (<xref ref-type="bibr" rid="bib48">Koren and Denève, 2017</xref>).</p><p>Dale’s law can be imposed to the 1CT model the same way as in the E-I model, by removing synaptic interactions between neurons with different selectivity with rectification of the connectivity matrix,<disp-formula id="equ71"><label>(53)</label><mml:math id="m71"><mml:mrow><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msub><mml:mrow><mml:mover><mml:mi>J</mml:mi><mml:mo stretchy="false">~</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mo>−</mml:mo><mml:mo stretchy="false">[</mml:mo><mml:msubsup><mml:mrow><mml:mover><mml:mi>w</mml:mi><mml:mo stretchy="false">→</mml:mo></mml:mover></mml:mrow><mml:mi>i</mml:mi><mml:mi mathvariant="normal">⊤</mml:mi></mml:msubsup><mml:msub><mml:mrow><mml:mover><mml:mi>w</mml:mi><mml:mo stretchy="false">→</mml:mo></mml:mover></mml:mrow><mml:mi>j</mml:mi></mml:msub><mml:msub><mml:mo stretchy="false">]</mml:mo><mml:mo>+</mml:mo></mml:msub><mml:mo>.</mml:mo></mml:mstyle></mml:mrow></mml:math></disp-formula></p><p>However, this manipulation results in a network with only inhibitory recurrent synaptic interactions, and thus a network of only inhibitory neurons. Network with only inhibitory interactions is less relevant for the description of recurrently connected biological networks.</p></sec></app><app id="appendix-2"><title>Appendix 2</title><sec sec-type="appendix" id="s9"><title>Parameters of the E-I model without non-specific currents</title><p>Our analytical derivation in <xref ref-type="disp-formula" rid="equ27">Equation 25</xref> suggested an efficient E-I model that is simpler with respect to the E-I model studied in this contribution, as it does not have non-specific synaptic currents. Optimal (computational) model parameters of such simpler model, listed above the double line are by definition identical to the full E-I model listed in <xref ref-type="table" rid="table1">Table 1</xref>. However, the model without non-specific synaptic currents differs from the full E-I model about the distance between the resting potential and the threshold. In the simpler model, this distance is lower compared to the full E-I model, and is not consistent with empirically measured distance, which is about 20 mV (<xref ref-type="bibr" rid="bib24">Constantinople and Bruno, 2013</xref>).</p><table-wrap id="app2table1" position="float"><label>Appendix 2—table 1.</label><caption><title>Table of optimal model parameters for the efficient E-I network without non-specific synaptic currents.</title><p>As in <xref ref-type="table" rid="table1">Table 1</xref>, for the E-I model without non-specific currents. The model is defined in <xref ref-type="disp-formula" rid="equ27">Equation 25</xref>.</p></caption><table frame="hsides" rules="groups"><thead><tr><th align="left" valign="bottom">Parameter</th><th align="left" valign="bottom">Notation</th><th align="left" valign="bottom">Value</th></tr></thead><tbody><tr><td align="left" valign="bottom">Number of E neurons</td><td align="left" valign="bottom"><inline-formula><mml:math id="inf520"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msup><mml:mi>N</mml:mi><mml:mrow><mml:mspace width="thinmathspace"/><mml:mi>E</mml:mi></mml:mrow></mml:msup></mml:mstyle></mml:mrow></mml:mstyle></mml:math></inline-formula></td><td align="left" valign="bottom">400</td></tr><tr><td align="left" valign="bottom">Ratio of E to I neuron numbers</td><td align="left" valign="bottom"><inline-formula><mml:math id="inf521"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msup><mml:mi>N</mml:mi><mml:mrow><mml:mspace width="thinmathspace"/><mml:mi>E</mml:mi></mml:mrow></mml:msup><mml:mo>:</mml:mo><mml:msup><mml:mi>N</mml:mi><mml:mrow><mml:mspace width="thinmathspace"/><mml:mi>I</mml:mi></mml:mrow></mml:msup></mml:mstyle></mml:mrow></mml:mstyle></mml:math></inline-formula></td><td align="left" valign="bottom">4:1</td></tr><tr><td align="left" valign="bottom">Number of the input features</td><td align="left" valign="bottom"><inline-formula><mml:math id="inf522"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>M</mml:mi></mml:mstyle></mml:math></inline-formula></td><td align="left" valign="bottom">3</td></tr><tr><td align="left" valign="bottom">Time constant of the population readout (E and I)</td><td align="left" valign="bottom"><inline-formula><mml:math id="inf523"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>τ</mml:mi></mml:mstyle></mml:math></inline-formula></td><td align="left" valign="bottom">10ms</td></tr><tr><td align="left" valign="bottom">Time constant of the single neuron readout</td><td align="left" valign="bottom"><inline-formula><mml:math id="inf524"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msubsup><mml:mi>τ</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>r</mml:mi></mml:mrow><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>E</mml:mi></mml:mrow></mml:msubsup><mml:mo>=</mml:mo><mml:msubsup><mml:mi>τ</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>r</mml:mi></mml:mrow><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>I</mml:mi></mml:mrow></mml:msubsup></mml:mstyle></mml:math></inline-formula></td><td align="left" valign="bottom">10ms</td></tr><tr><td align="left" valign="bottom">Noise strength (non-specific current)</td><td align="left" valign="bottom"><inline-formula><mml:math id="inf525"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>σ</mml:mi></mml:mstyle></mml:math></inline-formula></td><td align="left" valign="bottom">5.0 mV</td></tr><tr><td align="left" valign="bottom">Heterogeneity factor of tuning parameters in E</td><td align="left" valign="bottom"><inline-formula><mml:math id="inf526"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msubsup><mml:mi>σ</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>w</mml:mi></mml:mrow><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>E</mml:mi></mml:mrow></mml:msubsup></mml:mstyle></mml:math></inline-formula></td><td align="left" valign="bottom">1.0 (mV)<sup>1/2</sup></td></tr><tr><td align="left" valign="bottom">Ratio of mean E-I to I-I synaptic connectivity</td><td align="left" valign="bottom">mean E-I: mean I-I</td><td align="left" valign="bottom">3:1</td></tr><tr><td align="left" valign="bottom">Metabolic constant</td><td align="left" valign="bottom"><inline-formula><mml:math id="inf527"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>β</mml:mi></mml:mstyle></mml:math></inline-formula></td><td align="left" valign="bottom">14 mV</td></tr><tr><td align="left" valign="bottom">(Threshold constant)</td><td align="char" char="." valign="bottom">(<inline-formula><mml:math id="inf528"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>c</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mo>/</mml:mo></mml:mrow><mml:mn>2</mml:mn></mml:mstyle></mml:math></inline-formula>)</td><td align="left" valign="bottom">(0 mV)</td></tr><tr><td align="left" valign="bottom">Distance threshold to reset potential (E neurons)</td><td align="left" valign="bottom"><inline-formula><mml:math id="inf529"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:msup><mml:mi>ϑ</mml:mi><mml:mrow><mml:mi>E</mml:mi></mml:mrow></mml:msup><mml:mo>−</mml:mo><mml:msubsup><mml:mi>V</mml:mi><mml:mrow><mml:mtext>rest</mml:mtext></mml:mrow><mml:mrow><mml:mspace width="thinmathspace"/><mml:mi>E</mml:mi></mml:mrow></mml:msubsup><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow></mml:mstyle></mml:mrow></mml:mstyle></mml:math></inline-formula></td><td align="left" valign="bottom">7.5 mV</td></tr><tr><td align="left" valign="bottom">Distance threshold to reset potential (I neurons)</td><td align="left" valign="bottom"><inline-formula><mml:math id="inf530"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:msup><mml:mi>ϑ</mml:mi><mml:mrow><mml:mi>I</mml:mi></mml:mrow></mml:msup><mml:mo>−</mml:mo><mml:msubsup><mml:mi>V</mml:mi><mml:mrow><mml:mtext>rest</mml:mtext></mml:mrow><mml:mrow><mml:mspace width="thinmathspace"/><mml:mi>I</mml:mi></mml:mrow></mml:msubsup><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow></mml:mstyle></mml:mrow></mml:mstyle></mml:math></inline-formula></td><td align="left" valign="bottom">11.5 mV</td></tr><tr><td align="left" valign="bottom">Connection probability (recurrent synapses)</td><td align="left" valign="bottom"><inline-formula><mml:math id="inf531"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msup><mml:mi>p</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>I</mml:mi><mml:mi>E</mml:mi></mml:mrow></mml:msup><mml:mo>=</mml:mo><mml:msup><mml:mi>p</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>I</mml:mi><mml:mi>I</mml:mi></mml:mrow></mml:msup><mml:mo>=</mml:mo><mml:msup><mml:mi>p</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>E</mml:mi><mml:mi>I</mml:mi></mml:mrow></mml:msup></mml:mstyle></mml:math></inline-formula></td><td align="left" valign="bottom">0.5</td></tr><tr><td align="left" valign="bottom">Mean E-I synaptic weight (EPSP to I at max)</td><td align="left" valign="bottom"><inline-formula><mml:math id="inf532"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mo fence="false" stretchy="false">⟨</mml:mo><mml:msubsup><mml:mi>J</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow><mml:mrow><mml:mspace width="thinmathspace"/><mml:mi>I</mml:mi><mml:mi>E</mml:mi></mml:mrow></mml:msubsup><mml:mo fence="false" stretchy="false">⟩</mml:mo></mml:mstyle></mml:mrow></mml:mstyle></mml:math></inline-formula></td><td align="left" valign="bottom">0.75 mV</td></tr><tr><td align="left" valign="bottom">Mean I-E synaptic weight (IPSP to E at max)</td><td align="left" valign="bottom"><inline-formula><mml:math id="inf533"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mo fence="false" stretchy="false">⟨</mml:mo><mml:msubsup><mml:mi>J</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow><mml:mrow><mml:mspace width="thinmathspace"/><mml:mi>E</mml:mi><mml:mi>I</mml:mi></mml:mrow></mml:msubsup><mml:mo fence="false" stretchy="false">⟩</mml:mo></mml:mstyle></mml:mrow></mml:mstyle></mml:math></inline-formula></td><td align="left" valign="bottom">0.75 mV</td></tr><tr><td align="left" valign="bottom">Mean I-I synaptic weight (IPSP at max)</td><td align="left" valign="bottom"><inline-formula><mml:math id="inf534"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mo fence="false" stretchy="false">⟨</mml:mo><mml:msubsup><mml:mi>J</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow><mml:mrow><mml:mspace width="thinmathspace"/><mml:mi>I</mml:mi><mml:mi>I</mml:mi></mml:mrow></mml:msubsup><mml:mo fence="false" stretchy="false">⟩</mml:mo></mml:mstyle></mml:mrow></mml:mstyle></mml:math></inline-formula></td><td align="left" valign="bottom">2.25 mV</td></tr></tbody></table></table-wrap><p>A simple way to increase the distance between the resting potential and the firing threshold is to introduce a constant that multiplies all mathematical terms in the <xref ref-type="disp-formula" rid="equ27">Equation 25</xref>. While this allows to achieve biologically plausible values for the distance between the resting potential and the threshold, it leads to values of mean recurrent synaptic connectivity <inline-formula><mml:math id="inf535"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mo fence="false" stretchy="false">⟨</mml:mo><mml:msubsup><mml:mi>J</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow><mml:mrow><mml:mspace width="thinmathspace"/><mml:mi>I</mml:mi><mml:mi>E</mml:mi></mml:mrow></mml:msubsup><mml:mo fence="false" stretchy="false">⟩</mml:mo></mml:mstyle></mml:mrow></mml:mstyle></mml:math></inline-formula>, <inline-formula><mml:math id="inf536"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mo fence="false" stretchy="false">⟨</mml:mo><mml:msubsup><mml:mi>J</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow><mml:mrow><mml:mspace width="thinmathspace"/><mml:mi>I</mml:mi><mml:mi>I</mml:mi></mml:mrow></mml:msubsup><mml:mo fence="false" stretchy="false">⟩</mml:mo></mml:mrow></mml:mstyle></mml:math></inline-formula> and <inline-formula><mml:math id="inf537"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mo fence="false" stretchy="false">⟨</mml:mo><mml:msubsup><mml:mi>J</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>E</mml:mi><mml:mi>I</mml:mi></mml:mrow></mml:msubsup><mml:mo fence="false" stretchy="false">⟩</mml:mo></mml:mstyle></mml:math></inline-formula> that are stronger than typically reported in the empirical literature (<xref ref-type="bibr" rid="bib19">Campagnola et al., 2022</xref>).</p></sec></app><app id="appendix-3"><title>Appendix 3</title><sec sec-type="appendix" id="s10"><title>Analysis of the one cell type model and comparison with the E-I model</title><p>We re-derived the 1CT model as a simplification of the E-I network (Appendix 1, <xref ref-type="fig" rid="fig1s1">Figure 1—figure supplement 1A–B</xref>), with objective function of the same form as <inline-formula><mml:math id="inf538"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msup><mml:mi>L</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>E</mml:mi></mml:mrow></mml:msup></mml:mstyle></mml:math></inline-formula> and by allowing a single type of neurons sending both excitatory and inhibitory synaptic currents to their post-synaptic targets (<xref ref-type="fig" rid="fig1s1">Figure 1—figure supplement 1C</xref>). Similarly to the E-I model, also the 1CT model exhibits structured connectivity, with synaptic strength depending on the tuning similarity between the presynaptic and the postsynaptic neuron. Pairs of neurons with stronger tuning similarity (dissimilarity) have stronger mutual inhibition (excitation); see <xref ref-type="fig" rid="fig1s1">Figure 1—figure supplement 1D</xref>.</p><p>We compared the coding performance of the E-I model with that of a fully connected 1CT model. Both models received the same set of stimulus features and performed the same computation. In the 1CT model, tuning parameters were drawn from the same distribution as used for the E neurons in the E-I model. We used the same membrane time constant <inline-formula><mml:math id="inf539"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>τ</mml:mi></mml:mstyle></mml:math></inline-formula> in both models, while the metabolic constants (<inline-formula><mml:math id="inf540"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>β</mml:mi></mml:mstyle></mml:math></inline-formula> of the E-I model and <inline-formula><mml:math id="inf541"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msup><mml:mi>β</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mn>1</mml:mn></mml:mrow></mml:msup></mml:mstyle></mml:math></inline-formula> of the 1CT model) and the noise strength (<inline-formula><mml:math id="inf542"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>σ</mml:mi></mml:mstyle></mml:math></inline-formula> of the E-I model and <inline-formula><mml:math id="inf543"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msup><mml:mi>σ</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mn>1</mml:mn></mml:mrow></mml:msup></mml:mstyle></mml:math></inline-formula> of the 1CT model) were chosen such as to optimize the average loss for each model (<xref ref-type="fig" rid="fig6">Figure 6B</xref> for E-I model, <xref ref-type="fig" rid="fig1s1">Figure 1—figure supplement 1F–G</xref> for 1CT model). Parameters of the 1CT model are listed in the Table below. A qualitative comparison of the E-I and the 1CT model showed that with optimal parameters, both models accurately tracked multiple target signals (<xref ref-type="fig" rid="fig1">Figure 1G</xref>, <xref ref-type="fig" rid="fig1s1">Figure 1—figure supplement 1E</xref>).</p><p>To compare the performance of the E-I and the 1CT models also quantitatively, we measured the average encoding error (RMSE), metabolic cost (MC) and loss of each model. The RMSE and the MC in the 1CT model were measured as in <xref ref-type="disp-formula" rid="equ47">Equation 36</xref> and <xref ref-type="disp-formula" rid="equ48">Equation 37</xref>, while the average loss of each model was evaluated as follows:<disp-formula id="equ72"><label>(54)</label><mml:math id="m72"><mml:mrow><mml:mtable columnalign="right left right left right left right left right left right left" rowspacing="3pt" columnspacing="0em 2em 0em 2em 0em 2em 0em 2em 0em 2em 0em" displaystyle="true"><mml:mtr><mml:mtd><mml:msup><mml:mrow><mml:mi class="mathcal" mathvariant="script">L</mml:mi></mml:mrow><mml:mrow><mml:mtext>1CT</mml:mtext></mml:mrow></mml:msup></mml:mtd><mml:mtd><mml:mi/><mml:mo>=</mml:mo><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msub><mml:mi>g</mml:mi><mml:mi>L</mml:mi></mml:msub><mml:msqrt><mml:mo fence="false" stretchy="false">⟨</mml:mo><mml:msubsup><mml:mi>ϵ</mml:mi><mml:mi>q</mml:mi><mml:mrow><mml:mtext>1CT</mml:mtext></mml:mrow></mml:msubsup><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:msub><mml:mo fence="false" stretchy="false">⟩</mml:mo><mml:mrow><mml:mi>t</mml:mi><mml:mo>,</mml:mo><mml:mi>q</mml:mi></mml:mrow></mml:msub></mml:msqrt><mml:mo>+</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:msub><mml:mi>g</mml:mi><mml:mi>L</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:msqrt><mml:mo fence="false" stretchy="false">⟨</mml:mo><mml:msubsup><mml:mi>κ</mml:mi><mml:mi>q</mml:mi><mml:mrow><mml:mtext>1CT</mml:mtext></mml:mrow></mml:msubsup><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:msub><mml:mo fence="false" stretchy="false">⟩</mml:mo><mml:mrow><mml:mi>t</mml:mi><mml:mo>,</mml:mo><mml:mi>q</mml:mi></mml:mrow></mml:msub></mml:msqrt><mml:mo>,</mml:mo></mml:mstyle></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:msup><mml:mrow><mml:mi class="mathcal" mathvariant="script">L</mml:mi></mml:mrow><mml:mrow><mml:mtext>E-I</mml:mtext></mml:mrow></mml:msup></mml:mtd><mml:mtd><mml:mi/><mml:mo>=</mml:mo><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msub><mml:mi>g</mml:mi><mml:mi>L</mml:mi></mml:msub><mml:msqrt><mml:mo fence="false" stretchy="false">⟨</mml:mo><mml:msubsup><mml:mi>ϵ</mml:mi><mml:mi>q</mml:mi><mml:mrow><mml:mspace width="thinmathspace"/><mml:mi>E</mml:mi></mml:mrow></mml:msubsup><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:msub><mml:mo fence="false" stretchy="false">⟩</mml:mo><mml:mrow><mml:mi>t</mml:mi><mml:mo>,</mml:mo><mml:mi>q</mml:mi></mml:mrow></mml:msub></mml:msqrt><mml:mo>+</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:msub><mml:mi>g</mml:mi><mml:mi>L</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:msqrt><mml:mo fence="false" stretchy="false">⟨</mml:mo><mml:msubsup><mml:mi>κ</mml:mi><mml:mi>q</mml:mi><mml:mrow><mml:mspace width="thinmathspace"/><mml:mi>E</mml:mi></mml:mrow></mml:msubsup><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:msub><mml:mo fence="false" stretchy="false">⟩</mml:mo><mml:mrow><mml:mi>t</mml:mi><mml:mo>,</mml:mo><mml:mi>q</mml:mi></mml:mrow></mml:msub></mml:msqrt><mml:mo>.</mml:mo></mml:mstyle></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:math></disp-formula></p><p>Unless mentioned otherwise, we weighted stronger the encoding error compared to the metabolic cost and used <inline-formula><mml:math id="inf544"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msub><mml:mi>g</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>L</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mn>0.7</mml:mn></mml:mstyle></mml:math></inline-formula>.</p><table-wrap id="app3table1" position="float"><label>Appendix 3—table 1.</label><caption><title>Table of default model parameters for the efficient network with one cell type.</title><p>The parameters <inline-formula><mml:math id="inf545"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>N</mml:mi></mml:mstyle></mml:math></inline-formula>, <inline-formula><mml:math id="inf546"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>M</mml:mi></mml:mstyle></mml:math></inline-formula>, <inline-formula><mml:math id="inf547"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>τ</mml:mi></mml:mstyle></mml:math></inline-formula> and <inline-formula><mml:math id="inf548"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msubsup><mml:mi>σ</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>w</mml:mi></mml:mrow><mml:mrow class="MJX-TeXAtom-ORD"><mml:mn>1</mml:mn></mml:mrow></mml:msubsup></mml:mstyle></mml:math></inline-formula> were chosen identical to the E-I network (see <xref ref-type="table" rid="table1">Table 1</xref> in the main text). Parameters <inline-formula><mml:math id="inf549"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msup><mml:mi>σ</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mn>1</mml:mn></mml:mrow></mml:msup></mml:mstyle></mml:math></inline-formula> and <inline-formula><mml:math id="inf550"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msup><mml:mi>β</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mn>1</mml:mn></mml:mrow></mml:msup></mml:mstyle></mml:math></inline-formula> were determined as values that maximize network efficiency (see section &quot;Performance measures&quot; in Methods).</p></caption><table frame="hsides" rules="groups"><thead><tr><th align="left" valign="bottom">Parameter</th><th align="left" valign="bottom">Notation</th><th align="left" valign="bottom">Value</th></tr></thead><tbody><tr><td align="left" valign="bottom">Number of E neurons</td><td align="left" valign="bottom"><inline-formula><mml:math id="inf551"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>N</mml:mi></mml:mstyle></mml:math></inline-formula></td><td align="left" valign="bottom">400</td></tr><tr><td align="left" valign="bottom">Number of the input features</td><td align="left" valign="bottom"><inline-formula><mml:math id="inf552"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>M</mml:mi></mml:mstyle></mml:math></inline-formula></td><td align="left" valign="bottom">3</td></tr><tr><td align="left" valign="bottom">Time constant of the single neuron and population readout</td><td align="left" valign="bottom"><inline-formula><mml:math id="inf553"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>τ</mml:mi></mml:mstyle></mml:math></inline-formula></td><td align="left" valign="bottom">10ms</td></tr><tr><td align="left" valign="bottom">Noise strength</td><td align="left" valign="bottom"><inline-formula><mml:math id="inf554"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msup><mml:mi>σ</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mn>1</mml:mn></mml:mrow></mml:msup></mml:mstyle></mml:math></inline-formula></td><td align="left" valign="bottom">1.8 mV</td></tr><tr><td align="left" valign="bottom">SD of tuning parameters</td><td align="left" valign="bottom"><inline-formula><mml:math id="inf555"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msubsup><mml:mi>σ</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>w</mml:mi></mml:mrow><mml:mrow class="MJX-TeXAtom-ORD"><mml:mn>1</mml:mn></mml:mrow></mml:msubsup></mml:mstyle></mml:math></inline-formula></td><td align="left" valign="bottom">1 (mV)<sup>1/2</sup></td></tr><tr><td align="left" valign="bottom">Metabolic constant</td><td align="left" valign="bottom"><inline-formula><mml:math id="inf556"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msup><mml:mi>β</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mn>1</mml:mn></mml:mrow></mml:msup></mml:mstyle></mml:math></inline-formula></td><td align="left" valign="bottom">11.4 mV</td></tr></tbody></table></table-wrap></sec></app></app-group></back><sub-article article-type="editor-report" id="sa0"><front-stub><article-id pub-id-type="doi">10.7554/eLife.99545.4.sa0</article-id><title-group><article-title>eLife Assessment</article-title></title-group><contrib-group><contrib contrib-type="author"><name><surname>Naud</surname><given-names>Richard</given-names></name><role specific-use="editor">Reviewing Editor</role><aff><institution>University of Ottawa</institution><country>Canada</country></aff></contrib></contrib-group><kwd-group kwd-group-type="evidence-strength"><kwd>Convincing</kwd></kwd-group><kwd-group kwd-group-type="claim-importance"><kwd>Valuable</kwd></kwd-group></front-stub><body><p>This study offers a <bold>valuable</bold> treatment of how the population of excitatory and inhibitory neurons integrates principles of energy efficiency in their coding strategies. The <bold>convincing</bold> analysis provides a comprehensive characterisation of the model, highlighting the structured connectivity between excitatory and inhibitory neurons. The role of the many free parameters are discussed and studied in depth.</p></body></sub-article><sub-article article-type="referee-report" id="sa1"><front-stub><article-id pub-id-type="doi">10.7554/eLife.99545.4.sa1</article-id><title-group><article-title>Reviewer #1 (Public review):</article-title></title-group><contrib-group><contrib contrib-type="author"><anonymous/><role specific-use="referee">Reviewer</role></contrib></contrib-group></front-stub><body><p>Koren et al. derive and analyse a spiking network model optimised to represent external signals using the minimum number of spikes. Unlike most prior work using a similar setup, the network includes separate populations of excitatory and inhibitory neurons. The authors show that the optimised connectivity has a like-to-like structure, which leads to the experimentally observed phenomenon of feature competition. The authors also examine how various (hyper)parameters-such as adaptation timescale, the excitatory-to-inhibitory cell ratio, regularization strength, and background current-affect the model. These findings add biological realism to a specific implementation of efficient coding. They show that efficient coding explains, or at least is consistent with, multiple experimentally observed properties of excitatory and inhibitory neurons.</p><p>As discussed in the first round of reviews, the model's ability to replicate biological observations such as the 4:1 ratio of excitatory vs. inhibitory neurons hinges on somewhat arbitrary hyperparameter choices. Although this may limit the model's explanatory power, the authors have made significant efforts to explore how these parameters influence their model. It is an empirical question whether the uncovered relationships between, e.g., metabolic cost and the fraction of excitatory neurons are biologically relevant.</p><p>The revised manuscript is also more transparent about the model's limitations, such as the lack of excitatory-excitatory connectivity.</p></body></sub-article><sub-article article-type="referee-report" id="sa2"><front-stub><article-id pub-id-type="doi">10.7554/eLife.99545.4.sa2</article-id><title-group><article-title>Reviewer #2 (Public review):</article-title></title-group><contrib-group><contrib contrib-type="author"><anonymous/><role specific-use="referee">Reviewer</role></contrib></contrib-group></front-stub><body><p>Summary:</p><p>In this work, the authors present a biologically plausible, efficient E-I spiking network model and study various aspects of the model and its relation to experimental observations. This includes a derivation of the network into two (E-I) populations, the study of single-neuron perturbations and lateral-inhibition, the study of the effects of adaptation and metabolic cost, and considerations of optimal parameters. From this, they conclude that their work puts forth a plausible implementation of efficient coding that matches several experimental findings, including feature-specific inhibition, tight instantaneous balance, a 4 to 1 ratio of excitatory to inhibitory neurons, and a 3 to 1 ratio of I-I to E-I connectivity strength.</p><p>Strengths:</p><p>While many network implementations of efficient coding have been developed, such normative models are often abstract and lacking sufficient detail to compare directly to experiments. The intention of this work to produce a more plausible and efficient spiking model and compare it with experimental data is important and necessary in order to test these models. In rigorously deriving the model with real physical units, this work maps efficient spiking networks onto other more classical biophysical spiking neuron models. It also attempts to compare the model to recent single-neuron perturbation experiments, as well as some long-standing puzzles about neural circuits, such as the presence of separate excitatory and inhibitory neurons, the ratio of excitatory to inhibitory neurons, and E/I balance. One of the primary goals of this paper, to determine if these are merely biological constraints or come from some normative efficient coding objective, is also important. Lastly, though several of the observations have been reported and studied before, this work arguably studies them in more depth, which could be useful for comparing more directly to experiments.</p><p>Weaknesses:</p><p>This work is the latest among a line of research papers studying the properties of efficient spiking networks. Many of the characteristics and findings here have been discussed before, thereby limiting the new insights that this work can provide. Thus, the conclusions of this work should be considered and understood in the context of those previous works, as the authors state. Furthermore, the number of assumptions and free parameters in the model, though necessary to bring the model closer to biophysical reality, make it more difficult to understand and to draw clear conclusions from. As the authors state, many of the optimality claims depend on these free parameters, such as the dimensionality of the input signal (M=3), the relative weighting of encoding error and metabolic cost, and several others. This raises the possibility that it is not the case that the set of biophysical properties measured in the brain are accounted for by efficient coding, but rather that theories of efficient coding are flexible enough to be consistent with this regime. With this in mind, some of the conclusions made in the text may be overstated and should be considered in this light.</p><p>Conclusions, Impact, and additional context:</p><p>Notions of optimality are important for normative theories, but they are often studied in simple models with as few free parameters as possible. Biophysically detailed and mechanistic models, on the other hand, will often have many free parameters by their very nature, thereby muddying the connection to optimality. This tradeoff is an important concern in neuroscientific models. Previous efficient spiking models have often been criticized for their lack of biophysically-plausible characteristics, such as large synaptic weights, dense connectivity, and instantaneous communication. This work is an important contribution in showing that such networks can be modified to be much closer to biophysical reality without losing their essential properties. Though the model presented does suffer from complexity issues which raise questions about its connections to &quot;optimal&quot; efficient coding, the extensive study of various parameter dependencies offers a good characterization of the model and puts its conclusions in context.</p></body></sub-article><sub-article article-type="referee-report" id="sa3"><front-stub><article-id pub-id-type="doi">10.7554/eLife.99545.4.sa3</article-id><title-group><article-title>Reviewer #3 (Public review):</article-title></title-group><contrib-group><contrib contrib-type="author"><anonymous/><role specific-use="referee">Reviewer</role></contrib></contrib-group></front-stub><body><p>Summary:</p><p>In their paper the authors tackle three things at once in a theoretical model: how can spiking neural networks perform efficient coding, how can such networks limit the energy use at the same time, and how can this be done in a more biologically realistic way than previous work.</p><p>They start by working from a long-running theory on how networks operating in a precisely balanced state can perform efficient coding. First, they assume split networks of excitatory (E) and inhibitory (I) neurons. The E neurons have the task to represent some lower dimensional input signal, and the I neurons have the task to represent the signal represented by the E neurons. Additionally, the E and I populations should minimize an energy cost represented by the sum of all spikes. All this results in two loss functions for the E and I populations, and the networks are then derived by assuming E and I neurons should only spike if this improves their respective loss. This results in networks of spiking neurons that live in a balanced state, and can accurately represent the network inputs.</p><p>They then investigate in depth different aspects of the resulting networks, such as responses to perturbations, the effect of following Dale's law, spiking statistics, the excitation (E)/inhibition (I) balance, optimal E/I cell ratios, and others. Overall, they expand on previous work by taking a more biological angle on the theory and show the networks can operate in a biologically realistic regime.</p><p>Strengths:</p><p>* The authors take a much more biological angle on the efficient spiking networks theory than previous work, which is an essential contribution to the field</p><p>* They make a very extensive investigation of many aspects of the network in this context, and do so thoroughly</p><p>* They put sensible constraints on their networks, while still maintaining the good properties these networks should have</p><p>Weaknesses:</p><p>* One of the core goals of the paper is to make a more biophysically realistic network than previous work using similar optimization principles. One of the important things they consider is a split into E and I neurons. While this works fine, and they consider the coding consequences of this, it is not clear from an optimization perspective why the split into E and I neurons and following Dale's law would be beneficial. This would be out of scope for the current paper however.</p><p>* The theoretical advances in the paper are not all novel by themselves, as most of them (in particular the split into E and I neurons and the use of biophysical constants) had been achieved in previous models. However, the authors discuss these links thoroughly and do more in-depth follow-up experiments with the resulting model.</p><p>Assessment and context:</p><p>Overall, although much of the underlying theory is not necessarily new, the work provides an important addition to the field. The authors succeeded well in their goal of making the networks more biologically realistic, and incorporate aspects of energy efficiency. For computational neuroscientists this paper is a good example of how to build models that link well to experimental knowledge and constraints, while still being computationally and mathematically tractable. For experimental readers the model provides a clearer link of efficient coding spiking networks to known experimental constraints and provides a few predictions.</p></body></sub-article><sub-article article-type="author-comment" id="sa4"><front-stub><article-id pub-id-type="doi">10.7554/eLife.99545.4.sa4</article-id><title-group><article-title>Author response</article-title></title-group><contrib-group><contrib contrib-type="author"><name><surname>Koren</surname><given-names>Veronika</given-names></name><role specific-use="author">Author</role><aff><institution>University Medical Center Hamburg-Eppendorf</institution><addr-line><named-content content-type="city">Hamburg</named-content></addr-line><country>Germany</country></aff></contrib><contrib contrib-type="author"><name><surname>Blanco Malerba</surname><given-names>Simone</given-names></name><role specific-use="author">Author</role><aff><institution>University Medical Center Hamburg-Eppendorf</institution><addr-line><named-content content-type="city">Hamburg</named-content></addr-line><country>Germany</country></aff></contrib><contrib contrib-type="author"><name><surname>Schwalger</surname><given-names>Tilo</given-names></name><role specific-use="author">Author</role><aff><institution>Technische Universität Berlin</institution><addr-line><named-content content-type="city">Berlin</named-content></addr-line><country>Germany</country></aff></contrib><contrib contrib-type="author"><name><surname>Panzeri</surname><given-names>Stefano</given-names></name><role specific-use="author">Author</role><aff><institution>University Medical Center Hamburg-Eppendorf</institution><addr-line><named-content content-type="city">Hamburg</named-content></addr-line><country>Germany</country></aff></contrib></contrib-group></front-stub><body><p>The following is the authors’ response to the previous reviews.</p><disp-quote content-type="editor-comment"><p><bold>Public Reviews:</bold></p><p><bold>Reviewer #1 (Public review):</bold></p><p>Koren et al. derive and analyse a spiking network model optimised to represent external signals using the minimum number of spikes. Unlike most prior work using a similar setup, the network includes separate populations of excitatory and inhibitory neurons. The authors show that the optimised connectivity has a like-to-like structure, which leads to the experimentally observed phenomenon of feature competition. The authors also examine how various (hyper)parameters-such as adaptation timescale, the excitatory-to-inhibitory cell ratio, regularization strength, and background current-affect the model. These findings add biological realism to a specific implementation of efficient coding. They show that efficient coding explains, or at least is consistent with, multiple experimentally observed properties of excitatory and inhibitory neurons.</p><p>As discussed in the first round of reviews, the model's ability to replicate biological observations such as the 4:1 ratio of excitatory vs. inhibitory neurons hinges on somewhat arbitrary hyperparameter choices. Although this may limit the model's explanatory power, the authors have made significant efforts to explore how these parameters influence their model. It is an empirical question whether the uncovered relationships between, e.g., metabolic cost and the fraction of excitatory neurons are biologically relevant.</p><p>The revised manuscript is also more transparent about the model's limitations, such as the lack of excitatory-excitatory connectivity. Further improvements could come from explicitly acknowledging additional discrepancies with biological data, such as the widely reported weak stimulus tuning of inhibitory neurons in the primary sensory cortex of untrained animals.</p></disp-quote><p>We thank the Reviewer for their insightful characterization of our paper and for further suggestions on how to improve it. We have now further improved the transparency about model’s limitations and we explicitly acknowledged the discrepancy with biological data about connection probability and about the selectivity of inhibitory neurons (pages 4 and 15).</p><disp-quote content-type="editor-comment"><p><bold>Reviewer #2 (Public review):</bold></p><p>Summary:</p><p>In this work, the authors present a biologically plausible, efficient E-I spiking network model and study various aspects of the model and its relation to experimental observations. This includes a derivation of the network into two (E-I) populations, the study of single-neuron perturbations and lateral-inhibition, the study of the effects of adaptation and metabolic cost, and considerations of optimal parameters. From this, they conclude that their work puts forth a plausible implementation of efficient coding that matches several experimental findings, including feature-specific inhibition, tight instantaneous balance, a 4 to 1 ratio of excitatory to inhibitory neurons, and a 3 to 1 ratio of I-I to E-I connectivity strength.</p><p>Strengths:</p><p>While many network implementations of efficient coding have been developed, such normative models are often abstract and lacking sufficient detail to compare directly to experiments. The intention of this work to produce a more plausible and efficient spiking model and compare it with experimental data is important and necessary in order to test these models. In rigorously deriving the model with real physical units, this work maps efficient spiking networks onto other more classical biophysical spiking neuron models. It also attempts to compare the model to recent single-neuron perturbation experiments, as well as some long-standing puzzles about neural circuits, such as the presence of separate excitatory and inhibitory neurons, the ratio of excitatory to inhibitory neurons, and E/I balance. One of the primary goals of this paper, to determine if these are merely biological constraints or come from some normative efficient coding objective, is also important. Lastly, though several of the observations have been reported and studied before, this work arguably studies them in more depth, which could be useful for comparing more directly to experiments.</p><p>Weaknesses:</p><p>This work is the latest among a line of research papers studying the properties of efficient spiking networks. Many of the characteristics and findings here have been discussed before, thereby limiting the new insights that this work can provide. Thus, the conclusions of this work should be considered and understood in the context of those previous works, as the authors state. Furthermore, the number of assumptions and free parameters in the model, though necessary to bring the model closer to biophysical reality, make it more difficult to understand and to draw clear conclusions from. As the authors state, many of the optimality claims depend on these free parameters, such as the dimensionality of the input signal (M=3), the relative weighting of encoding error and metabolic cost, and several others. This raises the possibility that it is not the case that the set of biophysical properties measured in the brain are accounted for by efficient coding, but rather that theories of efficient coding are flexible enough to be consistent with this regime. With this in mind, some of the conclusions made in the text may be overstated and should be considered in this light.</p><p>Conclusions, Impact, and additional context:</p><p>Notions of optimality are important for normative theories, but they are often studied in simple models with as few free parameters as possible. Biophysically detailed and mechanistic models, on the other hand, will often have many free parameters by their very nature, thereby muddying the connection to optimality. This tradeoff is an important concern in neuroscientific models. Previous efficient spiking models have often been criticized for their lack of biophysically-plausible characteristics, such as large synaptic weights, dense connectivity, and instantaneous communication. This work is an important contribution in showing that such networks can be modified to be much closer to biophysical reality without losing their essential properties. Though the model presented does suffer from complexity issues which raise questions about its connections to &quot;optimal&quot; efficient coding, the extensive study of various parameter dependencies offers a good characterization of the model and puts its conclusions in context.</p></disp-quote><p>We thank the Reviewer for their thorough and accurate assessment of our paper.</p><disp-quote content-type="editor-comment"><p><bold>Reviewer #3 (Public review):</bold></p><p>Summary:</p><p>In their paper the authors tackle three things at once in a theoretical model: how can spiking neural networks perform efficient coding, how can such networks limit the energy use at the same time, and how can this be done in a more biologically realistic way than previous work.</p><p>They start by working from a long-running theory on how networks operating in a precisely balanced state can perform efficient coding. First, they assume split networks of excitatory (E) and inhibitory (I) neurons. The E neurons have the task to represent some lower dimensional input signal, and the I neurons have the task to represent the signal represented by the E neurons. Additionally, the E and I populations should minimize an energy cost represented by the sum of all spikes. All this results in two loss functions for the E and I populations, and the networks are then derived by assuming E and I neurons should only spike if this improves their respective loss. This results in networks of spiking neurons that live in a balanced state, and can accurately represent the network inputs.</p><p>They then investigate in depth different aspects of the resulting networks, such as responses to perturbations, the effect of following Dale's law, spiking statistics, the excitation (E)/inhibition (I) balance, optimal E/I cell ratios, and others. Overall, they expand on previous work by taking a more biological angle on the theory and show the networks can operate in a biologically realistic regime.</p><p>Strengths:</p><p>* The authors take a much more biological angle on the efficient spiking networks theory than previous work, which is an essential contribution to the field</p><p>* They make a very extensive investigation of many aspects of the network in this context, and do so thoroughly</p><p>* They put sensible constraints on their networks, while still maintaining the good properties these networks should have</p><p>Weaknesses:</p><p>* One of the core goals of the paper is to make a more biophysically realistic network than previous work using similar optimization principles. One of the important things they consider is a split into E and I neurons. While this works fine, and they consider the coding consequences of this, it is not clear from an optimization perspective why the split into E and I neurons and following Dale's law would be beneficial. This would be out of scope for the current paper however.</p><p>* The theoretical advances in the paper are not all novel by themselves, as most of them (in particular the split into E and I neurons and the use of biophysical constants) had been achieved in previous models. However, the authors discuss these links thoroughly and do more in-depth follow-up experiments with the resulting model.</p><p>Assessment and context:</p><p>Overall, although much of the underlying theory is not necessarily new, the work provides an important addition to the field. The authors succeeded well in their goal of making the networks more biologically realistic, and incorporate aspects of energy efficiency. For computational neuroscientists this paper is a good example of how to build models that link well to experimental knowledge and constraints, while still being computationally and mathematically tractable. For experimental readers the model provides a clearer link of efficient coding spiking networks to known experimental constraints and provides a few predictions.</p></disp-quote><p>We thank the Reviewer for a positive assessment and for pointing out the merits of our work.</p><disp-quote content-type="editor-comment"><p><bold>Recommendations for the authors:</bold></p><p><bold>Reviewer #1 (Recommendations for the authors):</bold></p><p>The authors have addressed my previous concerns, and I agree that the manuscript has improved. However, I believe they could still do more to acknowledge two notable mismatches between the model and experimental data.</p><p>(1) Stimulus selectivity of excitatory and inhibitory neurons</p><p>In the model, excitatory and inhibitory neurons exhibit similar stimulus selectivity, which appears inconsistent with most experimental findings. The authors argue that whether inhibitory neurons are less selective remains an open question, citing three studies in support. However, only one of these studies (Ranyan) was conducted in primary sensory cortex and it is, to my knowledge, one of the few papers showing this (indeed, it's often cited as an exception). The other two studies (Kuan and Najafi) recorded from the parietal cortex of mice trained on decision making tasks, and therefore seem less relevant to the model.</p><p>In contrast to the cited studies, the overwhelming majority of the work has found that inhibitory neurons in sensory cortex, in particular those expressing Parvalbumin, are less stimulus selective than excitatory cells. And this is indeed the prevailing view, as summarized by the review from Hu et al. (Science, 2014): &quot;PV+ interneurons exhibit broader orientation tuning and weaker contrast specificity than pyramidal neurons.&quot; This view emerged from numerous classical studies, including Sohya et al. (J. Neurosci., 2007), Cardin (J. Neurosci., 2007), Nowak (Cereb. Cortex, 2008), Niell et al. (J. Neurosci., 2008), Liu (J. Neurosci., 2009), Kerlin (Neuron, 2010), Ma et al. (J. Neurosci., 2010), Hofer et al. (Nature Neurosci. 2011), and Atallah et al. (Neuron 2012). Weak inhibitory tuning has been confirmed by recent studies, such as Sanghavi &amp; Kar (biorxiv 2023), Znamenskiy et al. (Neuron 2024), and Hong et al. (Nature, 2024).</p><p>The authors should acknowledge this consensus and cite the conflicting evidence. Failing to do so is cherry picking from the literature. Since training can increase the stimulus selectivity of PV+ neurons to that of Pyr levels, also in primary visual cortex (Khan et al. Neuron 2018), a favourable interpretation of the model is that it represents a highly optimized, if not overtrained, state.</p></disp-quote><p>We have carefully considered the literature cited by the Reviewer. We agree with the interpretation that stimulus selectivity of inhibitory neurons in our model is higher than the stimulus selectivity of Parvalbumin-positive inhibitory neurons in the primary sensory cortex of naïve animals. We have edited the text in Discussion (page 14).</p><disp-quote content-type="editor-comment"><p>(2) Connection probability</p><p>The manuscript claims that &quot;rectification sets the overall connection probability to 0.5, consistent with experimental results (Pala &amp; Petersen; Campagnola et al.).&quot; However, the cited studies, and others, report significantly lower probabilities, except for Pyr-PV (E-I connections in the model). For example, Campagnola et al. measured PV-Pyr connectivity at 34% in L2/3 and 20% in L5.</p><p>It's perfectly acceptable that the model cannot replicate every detail of biological circuits. But it's important to be cautious when claiming consistency with experimental data.</p></disp-quote><p>Here as well, we agree with the Reviewer that the connection probability of 0.5 is consistent with reported connectivity of Pyr-PV neurons, but less so with reported connectivity of PV-Pyr neurons. We have now qualified our claim about compatibility of the connection probability in our model with empirical observations more precise (page 4).</p><disp-quote content-type="editor-comment"><p><bold>Reviewer #2 (Recommendations for the authors):</bold></p><p>I commend the authors for an extremely thorough and detailed rebuttal, and for all of the additional work put in to address the reviewer concerns. For the most part, I am satisfied with the current state of the manuscript.</p></disp-quote><p>We thank the Reviewer for recognizing our effort to address the first round of Reviews to our best ability.</p><disp-quote content-type="editor-comment"><p>Here are some small points still remaining that I think the authors should address:</p><p>(1) Pg. 8, &quot;We verified the robustness of the model to small deviations from the optimal synaptic weights&quot; - while the authors now cite Calaim et al. 2022 in the discussion, its relevance to several of the results justify its inclusion in other places. Here is one place where the authors test something that was also studied in this previous paper.</p></disp-quote><p>The Reviewer is correct that Calaim et al. (eLife 2022) addressed the robustness of synaptic weights, and we now cited this study when describing our results on jiVering of synaptic connections (page 8).</p><disp-quote content-type="editor-comment"><p>(2) Pg. 9, &quot;In our optimal E-I network we indeed found that optimal coding efficiency is achieved in absence of within-neuron feedback or with weak adaptation in both cell types&quot; Pg. 10, &quot;the absence of within-neuron feedback or the presence of weak and short-lasting spike-triggered adaptation in both E and I neurons are optimally efficient solutions&quot; The authors seem to state that both weak adaptation and no adaptation at all are optimal. In contrast to the rest of the results presented, this is very vague and does not give a particular level of adaptation as being optimal. The authors should make this more clear.</p></disp-quote><p>We agree that the text about optimal level of adaptation was unclear. The optimal solution is no adaptation, while weak and short-lasting adaptation define a slightly suboptimal, yet still efficient, network state, as now stated on page 10.</p><disp-quote content-type="editor-comment"><p>(3) Pg. 13, &quot;In summary our analysis suggests that optimal coding efficiency is achieved with four times more E neurons than I neurons and with mean I-I synaptic efficacy about 3 times stronger...&quot; --- claims such as these are still too strong, in my opinion. It is rather the case that the particular ratio of E to I neurons and connections strengths can be made consistent with an optimally efficient regime.</p></disp-quote><p>We agree here as well. We have revised the text (page 13) to beVer explain our results.</p><disp-quote content-type="editor-comment"><p>(4) Pg. 14, &quot;firing rates in the 1CT model were highly sensitive to variations in the metabolic constant&quot; (Fig. 8I, as compared to Fig. 6C). This difference between the 1CT and E-I networks is striking, and I would suspect it is due to some idiosyncrasies in the difference between the two models (e.g., the relative amount of delay that it takes for lateral inhibition to take effect, or the fact that E-E connections have not been removed in this model). The authors should ideally back up this result with some justified explanation.</p></disp-quote><p>We agree with Reviewer that the delay for lateral inhibition in the E-I model is twice that of the 1CT model and that the E-I model gains stability from the lack of E-E connectivity. Furthermore, the tuning is stronger in I compared to E neurons in the E-I model, which contributes to making the E-I network inhibition-dominated (Fig. 1H). In contrast, the average excitation and inhibition in the 1CT model are of exactly the same magnitude. The property of being inhibition-dominated makes the E-I model more stable. We report these observations in the revised text (pages 14-15).</p><disp-quote content-type="editor-comment"><p><bold>Reviewer #3 (Recommendations for the authors):</bold></p><p>Overall my points were very well responded to and I removed most of my weaknesses.</p><p>I appreciate the authors implementing my suggested analysis change for Figure 8, and I find the result very clear. I would further suggest they add a bit of text for the reader as to why this is done. For a new reader without much knowledge of these networks at first it seems the inhibitory population is very good at representation in fig 8G: so why is it not further considered in fig 8H?</p></disp-quote><p>We thank the reviewer for providing further suggestions. We now clarified in the text why only the excitatory population of the E-I model is considered in E-I vs 1 cell type model comparison (page 14).</p><disp-quote content-type="editor-comment"><p>Thanks for sharing the code. From a quick browse through it looks very manageable to implement for follow up work, although some more guidance for how to navigate the quite complicated codebase and how to reproduce specific paper results would be helpful.</p></disp-quote><p>We have also updated the code repository, where we have included more complete instructions on how to reproduce results of each figure. We renamed the folders with the computer code so that they point to a specific figure in the paper. The repository has been completed with the output of the numerical simulations we run, which allows immediate replot of all figures. We have deposited the repository at Zenodo to have the final version of the code associated with the DOI https://doi.org/10.5281/zenodo.14628524. This is mentioned in the section Code availability (page 17).</p></body></sub-article></article>