<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD with MathML3 v1.3 20210610//EN"  "JATS-archivearticle1-3-mathml3.dtd"><article xmlns:ali="http://www.niso.org/schemas/ali/1.0/" xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" article-type="research-article" dtd-version="1.3"><front><journal-meta><journal-id journal-id-type="nlm-ta">elife</journal-id><journal-id journal-id-type="publisher-id">eLife</journal-id><journal-title-group><journal-title>eLife</journal-title></journal-title-group><issn publication-format="electronic" pub-type="epub">2050-084X</issn><publisher><publisher-name>eLife Sciences Publications, Ltd</publisher-name></publisher></journal-meta><article-meta><article-id pub-id-type="publisher-id">95127</article-id><article-id pub-id-type="doi">10.7554/eLife.95127</article-id><article-id pub-id-type="doi" specific-use="version">10.7554/eLife.95127.4</article-id><article-version article-version-type="publication-state">version of record</article-version><article-categories><subj-group subj-group-type="display-channel"><subject>Research Article</subject></subj-group><subj-group subj-group-type="heading"><subject>Neuroscience</subject></subj-group></article-categories><title-group><article-title>Uncertainty-modulated prediction errors in cortical microcircuits</article-title></title-group><contrib-group><contrib contrib-type="author" corresp="yes"><name><surname>Wilmes</surname><given-names>Katharina Anna</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">https://orcid.org/0000-0003-4948-1864</contrib-id><email>katharina.wilmes@unibe.ch</email><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="fn" rid="con1"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author"><name><surname>Petrovici</surname><given-names>Mihai A</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">https://orcid.org/0000-0003-2632-0427</contrib-id><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="other" rid="fund1"/><xref ref-type="other" rid="fund2"/><xref ref-type="other" rid="fund3"/><xref ref-type="other" rid="fund5"/><xref ref-type="other" rid="fund6"/><xref ref-type="fn" rid="con2"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author"><name><surname>Sachidhanandam</surname><given-names>Shankar</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">https://orcid.org/0000-0002-9359-6653</contrib-id><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="fn" rid="con3"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author"><name><surname>Senn</surname><given-names>Walter</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">https://orcid.org/0000-0003-3622-0497</contrib-id><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="other" rid="fund1"/><xref ref-type="other" rid="fund2"/><xref ref-type="other" rid="fund3"/><xref ref-type="other" rid="fund4"/><xref ref-type="other" rid="fund5"/><xref ref-type="fn" rid="con4"/><xref ref-type="fn" rid="conf1"/></contrib><aff id="aff1"><label>1</label><institution-wrap><institution-id institution-id-type="ror">https://ror.org/02k7v4d05</institution-id><institution>Department of Physiology, University of Bern</institution></institution-wrap><addr-line><named-content content-type="city">Bern</named-content></addr-line><country>Switzerland</country></aff></contrib-group><contrib-group content-type="section"><contrib contrib-type="editor"><name><surname>Keller</surname><given-names>Georg B</given-names></name><role>Reviewing Editor</role><aff><institution-wrap><institution-id institution-id-type="ror">https://ror.org/01bmjkv45</institution-id><institution>Friedrich Miescher Institute</institution></institution-wrap><country>Switzerland</country></aff></contrib><contrib contrib-type="senior_editor"><name><surname>Poirazi</surname><given-names>Panayiota</given-names></name><role>Senior Editor</role><aff><institution-wrap><institution-id institution-id-type="ror">https://ror.org/01gzszr18</institution-id><institution>FORTH Institute of Molecular Biology and Biotechnology</institution></institution-wrap><country>Greece</country></aff></contrib></contrib-group><pub-date publication-format="electronic" date-type="publication"><day>05</day><month>06</month><year>2025</year></pub-date><volume>13</volume><elocation-id>RP95127</elocation-id><history><date date-type="sent-for-review" iso-8601-date="2023-12-20"><day>20</day><month>12</month><year>2023</year></date></history><pub-history><event><event-desc>This manuscript was published as a preprint.</event-desc><date date-type="preprint" iso-8601-date="2023-12-06"><day>06</day><month>12</month><year>2023</year></date><self-uri content-type="preprint" xlink:href="https://doi.org/10.1101/2023.05.11.540393"/></event><event><event-desc>This manuscript was published as a reviewed preprint.</event-desc><date date-type="reviewed-preprint" iso-8601-date="2024-02-27"><day>27</day><month>02</month><year>2024</year></date><self-uri content-type="reviewed-preprint" xlink:href="https://doi.org/10.7554/eLife.95127.1"/></event><event><event-desc>The reviewed preprint was revised.</event-desc><date date-type="reviewed-preprint" iso-8601-date="2024-09-27"><day>27</day><month>09</month><year>2024</year></date><self-uri content-type="reviewed-preprint" xlink:href="https://doi.org/10.7554/eLife.95127.2"/></event><event><event-desc>The reviewed preprint was revised.</event-desc><date date-type="reviewed-preprint" iso-8601-date="2025-01-22"><day>22</day><month>01</month><year>2025</year></date><self-uri content-type="reviewed-preprint" xlink:href="https://doi.org/10.7554/eLife.95127.3"/></event></pub-history><permissions><copyright-statement>© 2024, Wilmes et al</copyright-statement><copyright-year>2024</copyright-year><copyright-holder>Wilmes et al</copyright-holder><ali:free_to_read/><license xlink:href="http://creativecommons.org/licenses/by/4.0/"><ali:license_ref>http://creativecommons.org/licenses/by/4.0/</ali:license_ref><license-p>This article is distributed under the terms of the <ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/licenses/by/4.0/">Creative Commons Attribution License</ext-link>, which permits unrestricted use and redistribution provided that the original author and source are credited.</license-p></license></permissions><self-uri content-type="pdf" xlink:href="elife-95127-v1.pdf"/><self-uri content-type="figures-pdf" xlink:href="elife-95127-figures-v1.pdf"/><abstract><p>Understanding the variability of the environment is essential to function in everyday life. The brain must hence take uncertainty into account when updating its internal model of the world. The basis for updating the model are prediction errors that arise from a difference between the current model and new sensory experiences. Although prediction error neurons have been identified in layer 2/3 of diverse brain areas, how uncertainty modulates these errors and hence learning is, however, unclear. Here, we use a normative approach to derive how uncertainty should modulate prediction errors and postulate that layer 2/3 neurons represent uncertainty-modulated prediction errors (UPE). We further hypothesise that the layer 2/3 circuit calculates the UPE through the subtractive and divisive inhibition by different inhibitory cell types. By implementing the calculation of UPEs in a microcircuit model, we show that different cell types can compute the means and variances of the stimulus distribution. With local activity-dependent plasticity rules, these computations can be learned context-dependently, and allow the prediction of upcoming stimuli and their distribution. Finally, the mechanism enables an organism to optimise its learning strategy via adaptive learning rates.</p></abstract><kwd-group kwd-group-type="author-keywords"><kwd>cortex</kwd><kwd>circuits</kwd><kwd>cells</kwd></kwd-group><kwd-group kwd-group-type="research-organism"><title>Research organism</title><kwd>None</kwd></kwd-group><funding-group><award-group id="fund1"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/100010661</institution-id><institution>Horizon 2020 Framework Programme</institution></institution-wrap></funding-source><award-id award-id-type="doi">10.3030/720270</award-id><principal-award-recipient><name><surname>Senn</surname><given-names>Walter</given-names></name><name><surname>Petrovici</surname><given-names>Mihai A</given-names></name></principal-award-recipient></award-group><award-group id="fund2"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/100010661</institution-id><institution>Horizon 2020 Framework Programme</institution></institution-wrap></funding-source><award-id award-id-type="doi">10.3030/785907</award-id><principal-award-recipient><name><surname>Senn</surname><given-names>Walter</given-names></name><name><surname>Petrovici</surname><given-names>Mihai A</given-names></name></principal-award-recipient></award-group><award-group id="fund3"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/100010661</institution-id><institution>Horizon 2020 Framework Programme</institution></institution-wrap></funding-source><award-id award-id-type="doi">10.3030/945539</award-id><principal-award-recipient><name><surname>Senn</surname><given-names>Walter</given-names></name><name><surname>Petrovici</surname><given-names>Mihai A</given-names></name></principal-award-recipient></award-group><award-group id="fund4"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/100011102</institution-id><institution>European Union 7th Framework Programme</institution></institution-wrap></funding-source><award-id>604102</award-id><principal-award-recipient><name><surname>Senn</surname><given-names>Walter</given-names></name></principal-award-recipient></award-group><award-group id="fund5"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/100018693</institution-id><institution>Horizon Europe Programme</institution></institution-wrap></funding-source><award-id award-id-type="doi">10.3030/101147319</award-id><principal-award-recipient><name><surname>Senn</surname><given-names>Walter</given-names></name><name><surname>Petrovici</surname><given-names>Mihai A</given-names></name></principal-award-recipient></award-group><award-group id="fund6"><funding-source><institution-wrap><institution>Manfred Stärk Stiftung</institution></institution-wrap></funding-source><principal-award-recipient><name><surname>Petrovici</surname><given-names>Mihai A</given-names></name></principal-award-recipient></award-group><funding-statement>The funders had no role in study design, data collection and interpretation, or the decision to submit the work for publication.</funding-statement></funding-group><custom-meta-group><custom-meta specific-use="meta-only"><meta-name>Author impact statement</meta-name><meta-value>A new model of how the brain's circuits compute uncertainty and use it during learning by modulating prediction error responses.</meta-value></custom-meta><custom-meta specific-use="meta-only"><meta-name>publishing-route</meta-name><meta-value>prc</meta-value></custom-meta></custom-meta-group></article-meta></front><body><sec id="s1" sec-type="intro"><title>Introduction</title><p>Decades of cognitive research indicate that our brain maintains a model of the world, based on which it can make predictions about upcoming stimuli (<xref ref-type="bibr" rid="bib49">Kveraga et al., 2007</xref>; <xref ref-type="bibr" rid="bib11">Cohen et al., 2011</xref>). Predicting the sensory experience is useful for both perception and learning: Perception becomes more tolerant to uncertainty and noise when sensory information and predictions are integrated (<xref ref-type="bibr" rid="bib59">Payzan-LeNestour and Bossaerts, 2011</xref>). Learning can happen when predictions are compared to sensory information, as the resulting prediction error indicates how to improve the internal model. In both cases, the uncertainties (associated with both the sensory information and the internal model) should determine how much weight we give to the sensory information relative to the predictions, according to theoretical accounts. Behavioural and electrophysiological studies indicate that humans indeed estimate uncertainty and adjust their behaviour accordingly (<xref ref-type="bibr" rid="bib59">Payzan-LeNestour and Bossaerts, 2011</xref>; <xref ref-type="bibr" rid="bib77">Walker et al., 2019</xref>; <xref ref-type="bibr" rid="bib27">Goris et al., 2018</xref>; <xref ref-type="bibr" rid="bib10">Cannon et al., 2021</xref>; <xref ref-type="bibr" rid="bib47">Körding and Wolpert, 2004</xref>). The neural mechanisms underlying uncertainty and prediction error computation are, however, less well understood. Recently, the activity of individual neurons of layer 2/3 cortical circuits in diverse cortical areas of mouse brains has been linked to prediction errors (visual, <xref ref-type="bibr" rid="bib43">Keller et al., 2012</xref>; <xref ref-type="bibr" rid="bib84">Zmarz and Keller, 2016</xref>; <xref ref-type="bibr" rid="bib22">Fiser et al., 2016</xref>; <xref ref-type="bibr" rid="bib4">Attinger et al., 2017</xref>; <xref ref-type="bibr" rid="bib26">Gillon et al., 2021</xref>), auditory (<xref ref-type="bibr" rid="bib17">Eliades and Wang, 2008</xref>; <xref ref-type="bibr" rid="bib42">Keller and Hahnloser, 2009</xref>), somatosensory (<xref ref-type="bibr" rid="bib5">Ayaz et al., 2019</xref>), and posterior parietal (<xref ref-type="bibr" rid="bib66">Raltschev et al., 2023</xref>). Importantly, prediction errors could be associated with learning (<xref ref-type="bibr" rid="bib40">Jordan and Keller, 2023</xref>). Prediction error neurons are embedded in neural circuits that consist of heterogeneous cell types, most of which are inhibitory. It has been suggested that prediction error activity results from an imbalance of excitatory and inhibitory inputs (<xref ref-type="bibr" rid="bib32">Hertäg and Sprekeler, 2020</xref>; <xref ref-type="bibr" rid="bib33">Hertäg and Clopath, 2022</xref>), and that the prediction is subtracted from the sensory input [see e.g. <xref ref-type="bibr" rid="bib67">Rao and Ballard, 1999</xref>; <xref ref-type="bibr" rid="bib4">Attinger et al., 2017</xref>], possibly mediated by so-called somatostatin-positive interneurons (SSTs) (<xref ref-type="bibr" rid="bib4">Attinger et al., 2017</xref>). How uncertainty is influencing these computations has not yet been investigated. Prediction error neurons receive inputs from a diversity of inhibitory cell types, the role of which is not completely understood. Here, we hypothesise that one role of inhibition is to modulate the prediction error neuron activity by uncertainty.</p><p>In this study, we use both analytical calculations and numerical simulations of rate-based circuit models with different inhibitory cell types to study circuit mechanisms leading to uncertainty-modulated prediction errors. First, we derive that uncertainty should divisively modulate prediction error activity and introduce uncertainty-modulated prediction errors (UPEs). We hypothesise that, first, layer 2/3 prediction error neurons reflect such UPEs. Second, we hypothesise that different inhibitory cell types are involved in calculating the difference between predictions and stimuli, and in the uncertainty modulation, respectively. Based on experimental findings, we suggest that SSTs and PVs play the respective roles. We then derive biologically plausible plasticity rules that enable those cell types to learn the means and variances from their inputs. Notably, because the information about the stimulus distribution is stored in the connectivity, single inhibitory cells encode the means and variances of their inputs in a context-dependent manner. Layer 2/3 pyramidal cells in this model hence encode uncertainty-modulated prediction errors context-dependently. We show that error neurons can additionally implement out-of-distribution detection by amplifying large errors and reducing small errors with a nonlinear fI-curve (activation function). Finally, we demonstrate that UPEs effectively mediate an adjustable learning rate, which allows fast learning in high-certainty contexts and reduces the learning rate, thus suppressing fluctuations in uncertain contexts.</p></sec><sec id="s2" sec-type="results"><title>Results</title><sec id="s2-1"><title>Normative theories suggest uncertainty-modulated prediction errors (UPEs)</title><p>In a complex, uncertain, and hence partly unpredictable world, it is impossible to avoid prediction errors. Some prediction errors will be the result of this variability or noise, other prediction errors will be the result of a change in the environment or new information. Ideally, only the latter should be used for learning, that is updating the current model of the world. The challenge our brain faces is to learn from prediction errors that result from new information, and less from prediction errors that result from noise. Hence, intuitively, if we learned that a kind of stimulus or context is very variable (high uncertainty), then a prediction error should have only little influence on our model. Consider a situation in which a person waits for a bus to arrive. If they learned that the bus is not reliable, another late arrival of the bus does not surprise them and does not change their model of the bus (<xref ref-type="fig" rid="fig1">Figure 1A</xref>). If, on the contrary, they learned that the kind of stimulus or context is not very variable (low uncertainty), a prediction error should have a larger impact on their model. For example, if they learned that buses are reliable, they will notice that the bus is late and may use this information to update their model of the bus (<xref ref-type="fig" rid="fig1">Figure 1A</xref>). This intuition of modulating prediction errors by the uncertainty associated with the stimulus or context is supported by both behavioural studies and normative theories of learning. Here we take the view that uncertainty is computed and represented on each level of the cortical hierarchy, from early sensory areas to higher level brain areas, as opposed to a task-specific uncertainty estimate at the level of decision-making in higher level brain areas (<xref ref-type="fig" rid="fig1">Figure 1B</xref>) [see this review for a comparison of these two accounts: <xref ref-type="bibr" rid="bib46">Koblinger et al., 2021</xref>].</p><fig id="fig1" position="float"><label>Figure 1.</label><caption><title>Distributed uncertainty-modulated prediction error computation in cortical circuits.</title><p>(<bold>A</bold>) A person who learned that buses are unreliable has a prior expectation, which can be described by a wide Gaussian distribution of expected bus arrival times. When the bus does not arrive at the scheduled time, this person is not surprised and remains calm, as everything happens according to their model of the world. On the other hand, a person who learned that buses are punctual, which can be described by a narrow distribution of arrival times, may notice that the bus is late and get nervous, as they expected the bus to be punctual. This person can learn from this experience. If they always took this particular bus, and their uncertainty estimate is accurate, the prediction error could indicate that the bus schedule changed. (<bold>B</bold>) Models of uncertainty representation in cortex. Some models suggest that uncertainty is only represented in higher level areas concerned with decision-making (left). In contrast, we propose that uncertainty is represented at each level of the cortical hierarchy (right, shown is the visual hierarchy as an example). (<bold>C</bold>) A mouse learns the association between a sound (<inline-formula><mml:math id="inf1"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>a</mml:mi></mml:mrow></mml:mstyle></mml:math></inline-formula>) and a whisker deflection (<inline-formula><mml:math id="inf2"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>s</mml:mi></mml:mrow></mml:mstyle></mml:math></inline-formula>). The posterior parietal cortex (PPC) receives inputs from both somatosensory and auditory cortex. (<bold>D</bold>) The whisker stimulus intensities are drawn from a Gaussian distribution with mean μ and standard deviation <inline-formula><mml:math id="inf3"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>σ</mml:mi></mml:mrow></mml:mstyle></mml:math></inline-formula>. (<bold>E</bold>) Negative (left) and positive (right) prediction error circuit consisting of three cell types: layer 2/3 pyramidal cells (triangle), somatostatin-positive interneurons (SST, circle) and parvalbumin-positive interneurons (PV). SSTs represent the mean prediction in the postive circuit and the stimulus in the negative circuit, and PVs represent the variance.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-95127-fig1-v1.tif"/></fig><p>Before we suggest how cortical circuits compute such uncertainty-modulated prediction errors, we consider the normative solution to a simple association that a mouse can learn. The setting we consider is to predict a somatosensory stimulus based on an auditory stimulus. The auditory stimulus <italic>a</italic> is fixed, and the subsequent somatosensory stimulus <inline-formula><mml:math id="inf4"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>s</mml:mi></mml:mrow></mml:mstyle></mml:math></inline-formula> is variable and sampled from a Gaussian distribution (<inline-formula><mml:math id="inf5"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>s</mml:mi><mml:mo>∼</mml:mo><mml:mrow><mml:mi class="mathcal" mathvariant="script">N</mml:mi></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>μ</mml:mi><mml:mo>,</mml:mo><mml:mi>σ</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mstyle></mml:math></inline-formula>, <xref ref-type="fig" rid="fig1">Figure 1C and D</xref>). The optimal (maximum-likelihood) prediction is given by the mean of the stimulus distribution. Framed as an optimisation problem, the goal is to adapt the internal model of the mean <inline-formula><mml:math id="inf6"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mrow><mml:mover><mml:mi>μ</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow></mml:mrow></mml:mstyle></mml:math></inline-formula> such that the probability of observing samples <inline-formula><mml:math id="inf7"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>s</mml:mi></mml:mrow></mml:mstyle></mml:math></inline-formula> from the true distribution of whisker deflections is maximised given this model.</p><p>Hence, stochastic gradient ascent learning on the log-likelihood suggests that with each observation <inline-formula><mml:math id="inf8"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>s</mml:mi></mml:mrow></mml:mstyle></mml:math></inline-formula>, the prediction (corresponding to the internal model of the mean) should be updated as follows to approach the maximum likelihood solution:<disp-formula id="equ1"><label>(1)</label><mml:math id="m1"><mml:mrow><mml:mtable columnalign="right left right left right left right left right left right left" rowspacing="3pt" columnspacing="0em 2em 0em 2em 0em 2em 0em 2em 0em 2em 0em" displaystyle="true"><mml:mtr><mml:mtd><mml:mi mathvariant="normal">Δ</mml:mi><mml:mrow><mml:mover><mml:mi>μ</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mo>∝</mml:mo><mml:mfrac><mml:mi mathvariant="normal">∂</mml:mi><mml:mrow><mml:mi mathvariant="normal">∂</mml:mi><mml:mrow><mml:mover><mml:mi>μ</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow></mml:mrow></mml:mfrac><mml:mo stretchy="false">(</mml:mo><mml:mi>log</mml:mi><mml:mo>⁡</mml:mo><mml:mrow><mml:mi class="mathcal" mathvariant="script">L</mml:mi></mml:mrow><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:msup><mml:mi>σ</mml:mi><mml:mn>2</mml:mn></mml:msup></mml:mfrac><mml:mo stretchy="false">(</mml:mo><mml:mi>s</mml:mi><mml:mo>−</mml:mo><mml:mrow><mml:mover><mml:mi>μ</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mo stretchy="false">)</mml:mo><mml:mo>,</mml:mo></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:math></disp-formula></p><p>where L is the likelihood. According to this formulation, the update for the internal model should be the prediction error scaled inversely by the variance <inline-formula><mml:math id="inf9"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msup><mml:mi>σ</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:mstyle></mml:math></inline-formula>. Therefore, we propose that prediction errors should be modulated by uncertainty.</p></sec><sec id="s2-2"><title>Computation of UPEs in cortical microcircuits</title><p>How can cortical microcircuits achieve uncertainty modulation? Prediction errors can be positive or negative, but neuronal firing rates are always positive. Because baseline firing rates are low in layer 2/3 pyramidal cells [e.g., (<xref ref-type="bibr" rid="bib58">Niell and Stryker, 2008</xref>)], positive and negative prediction errors were suggested to be represented by distinct neuronal populations (<xref ref-type="bibr" rid="bib44">Keller and Mrsic-Flogel, 2018</xref>; <xref ref-type="bibr" rid="bib67">Rao and Ballard, 1999</xref>), which is in line with experimental data (<xref ref-type="bibr" rid="bib38">Jordan and Keller, 2020</xref>). We, therefore, decompose the UPE into a positive UPE<sup>+</sup> and a negative UPE<sup>−</sup> component (<xref ref-type="fig" rid="fig1">Figure 1C and D</xref>):<disp-formula id="equ2"><label>(2)</label><mml:math id="m2"><mml:mrow><mml:mrow><mml:mi mathvariant="normal">U</mml:mi><mml:mi mathvariant="normal">P</mml:mi><mml:mi mathvariant="normal">E</mml:mi><mml:mo>=</mml:mo><mml:mi mathvariant="normal">U</mml:mi><mml:mi mathvariant="normal">P</mml:mi><mml:msup><mml:mi mathvariant="normal">E</mml:mi><mml:mrow><mml:mo>+</mml:mo></mml:mrow></mml:msup><mml:mo>−</mml:mo><mml:mi mathvariant="normal">U</mml:mi><mml:mi mathvariant="normal">P</mml:mi><mml:msup><mml:mi mathvariant="normal">E</mml:mi><mml:mrow><mml:mo>−</mml:mo></mml:mrow></mml:msup></mml:mrow><mml:mo>=</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:msup><mml:mi>σ</mml:mi><mml:mn>2</mml:mn></mml:msup></mml:mfrac><mml:mo fence="false" stretchy="false">⌊</mml:mo><mml:mi>s</mml:mi><mml:mo>−</mml:mo><mml:mi>μ</mml:mi><mml:msup><mml:mo fence="false" stretchy="false">⌋</mml:mo><mml:mrow><mml:mo>+</mml:mo></mml:mrow></mml:msup><mml:mo>−</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:msup><mml:mi>σ</mml:mi><mml:mn>2</mml:mn></mml:msup></mml:mfrac><mml:mo fence="false" stretchy="false">⌊</mml:mo><mml:mi>μ</mml:mi><mml:mo>−</mml:mo><mml:mi>s</mml:mi><mml:msup><mml:mo fence="false" stretchy="false">⌋</mml:mo><mml:mrow><mml:mo>+</mml:mo></mml:mrow></mml:msup><mml:mo>,</mml:mo></mml:mrow></mml:math></disp-formula></p><p>where <inline-formula><mml:math id="inf10"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mo fence="false" stretchy="false">⌊</mml:mo><mml:mo>.</mml:mo><mml:mo>.</mml:mo><mml:mo>.</mml:mo><mml:msup><mml:mo fence="false" stretchy="false">⌋</mml:mo><mml:mrow><mml:mo>+</mml:mo></mml:mrow></mml:msup></mml:mrow></mml:mstyle></mml:math></inline-formula> denotes rectification at 0.</p><p>It has been suggested that error neurons compute prediction errors by subtracting the prediction from the stimulus input (or vice versa) (<xref ref-type="bibr" rid="bib4">Attinger et al., 2017</xref>). The stimulus input can come from local stimulus-encoding layer 2/3 cells (<xref ref-type="bibr" rid="bib66">Raltschev et al., 2023</xref>). Inhibitory interneurons provide the subtraction, resulting in an excitation-inhibition balance when they match (<xref ref-type="bibr" rid="bib32">Hertäg and Sprekeler, 2020</xref>). To represent a UPE, error neurons need additionally be divisively modulated by the uncertainty. Depending on synaptic properties, such as reversal potentials, inhibitory neurons can have subtractive or divisive influences on their postsynaptic targets. Therefore, we propose that an inhibitory cell type that divisively modulates prediction error activity represents the uncertainty. We hypothesise, first, that in positive prediction error circuits, inhibitory interneurons with subtractive inhibitory effects represent the mean μ of the prediction. They probably either inherit the mean prediction or calculate it locally. Second, we hypothesise that inhibitory interneurons with divisive inhibitory effects represent the uncertainty <inline-formula><mml:math id="inf11"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msup><mml:mi>σ</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:mstyle></mml:math></inline-formula> of the prediction (<xref ref-type="fig" rid="fig1">Figure 1C and D</xref>), which they calculate locally. A layer 2/3 pyramidal cell that receives these sources of inhibition then reflects the uncertainty-modulated prediction error (<xref ref-type="fig" rid="fig1">Figure 1E</xref>).</p><p>More specifically, we propose, first, that the SSTs are involved in the computation of the difference between predictions and stimuli, as suggested before (<xref ref-type="bibr" rid="bib4">Attinger et al., 2017</xref>). This subtraction could happen on the apical dendrite. Second, we propose that the PVs provide the uncertainty modulation. In line with this, prediction error neurons in layer 2/3 receive subtractive inhibition from somatostatin (SST) and divisive inhibition from parvalbumin (PV) interneurons (<xref ref-type="bibr" rid="bib83">Wilson et al., 2012</xref>). However, SSTs can also have divisive effects, and PVs can have subtractive effects, dependent on circuit and postsynaptic properties (<xref ref-type="bibr" rid="bib72">Seybold et al., 2015</xref>; <xref ref-type="bibr" rid="bib52">Lee et al., 2012</xref>; <xref ref-type="bibr" rid="bib16">Dorsett et al., 2021</xref>).</p><p>In the following, we investigate circuits of prediction error neurons and different inhibitory cell types. We start by investigating in local positive and negative prediction error circuits whether the inhibitory cell types can locally learn to predict means and variances, before combining both subcircuits into a recurrent circuit consisting of both positive and negative prediction error neurons.</p></sec><sec id="s2-3"><title>Local inhibitory cells learn to represent the mean and the variance given an associative cue</title><p>As discussed above, how much an individual sensory input contributes to updating the internal model should depend on the uncertainty associated with the sensory stimulus in its current context. Uncertainty estimation requires multiple stimulus samples. Therefore, our brain needs to have a context-dependent mechanism to estimate uncertainty from multiple past instances of the sensory input. Let us consider the simple example from above, in which a sound stimulus represents a context with a particular amount of uncertainty. In terms of neural activity, the context could be encoded in a higher level representation of the sound. Here, we investigate whether the context representation can elicit activity in the PVs that reflects the expected uncertainty of the situation. To investigate whether the context provided by the sound can cause activity in SSTs and PVs that reflects the mean and the variance of the whisker stimulus distribution, respectively, we simulated a rate-based circuit model consisting of pyramidal cells and the relevant inhibitory cell types. This circuit receives both the sound and the whisker stimuli as inputs.</p></sec><sec id="s2-4"><title>SSTs learn to estimate the mean</title><p>With our circuit model, we first investigate whether SSTs can learn to represent the mean of the stimulus distribution. In this model, SSTs receive whisker stimulus inputs <inline-formula><mml:math id="inf12"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>s</mml:mi></mml:mrow></mml:mstyle></mml:math></inline-formula>, drawn from Gaussian distributions (<xref ref-type="fig" rid="fig2">Figure 2B</xref>), and an input from a higher level representation of the sound <italic>a</italic> (which is either on or off, see <xref ref-type="disp-formula" rid="equ16">Equation 9</xref> in Methods). The connection weight from the sound representation to the SSTs is plastic according to a local activity-dependent plasticity rule (see <xref ref-type="disp-formula" rid="equ17">Equation 10</xref>). The aim of this rule is to minimise the difference between the activation of the SSTs caused by the sound input (which has to be learned) and the activation of the SSTs by the whisker stimulus (which nudges the SST activity in the right direction). The learning rule ensures that the auditory input itself causes SSTs to fire at the desired rate. After learning, the weight and the average SST firing rate reflect the mean of the presented whisker stimulus intensities (<xref ref-type="fig" rid="fig2">Figure 2C–F</xref>).</p><fig id="fig2" position="float"><label>Figure 2.</label><caption><title>SSTs learn to represent the mean context-dependently.</title><p>Illustration of the changes in the positive prediction error circuit. Thicker lines denote stronger weights. (<bold>B</bold>) Two different tones (red, orange) are associated with two somatosensory stimulus distributions with different means (red: high, orange: low). (<bold>C</bold>) SST firing rates (mean and std) during stimulus input. (<bold>D</bold>) SST firing rates over time for low (orange) and high (red) stimulus means. (<bold>E</bold>) Weights (mean and std) from sound <italic>a</italic> to SST for different values of μ. (<bold>F</bold>) SST firing rates (mean and std) for different values of μ. Mean and std were computed over 1000 data points from timestep 9000–10,000.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-95127-fig2-v1.tif"/></fig></sec><sec id="s2-5"><title>PVs learn to estimate the variance context-dependently</title><p>We next addressed whether PVs can estimate and learn the variance locally. To estimate the variance of the whisker deflections <inline-formula><mml:math id="inf13"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>s</mml:mi></mml:mrow></mml:mstyle></mml:math></inline-formula>, the PVs have to estimate <inline-formula><mml:math id="inf14"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msup><mml:mi>σ</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup><mml:mo stretchy="false">[</mml:mo><mml:mi>s</mml:mi><mml:mo stretchy="false">]</mml:mo><mml:mo>=</mml:mo><mml:msub><mml:mrow><mml:mi mathvariant="double-struck">E</mml:mi></mml:mrow><mml:mrow><mml:mi>s</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">[</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mi>s</mml:mi><mml:mo>−</mml:mo><mml:mrow><mml:mi mathvariant="double-struck">E</mml:mi></mml:mrow><mml:mo stretchy="false">[</mml:mo><mml:mi>s</mml:mi><mml:mo stretchy="false">]</mml:mo><mml:msup><mml:mo stretchy="false">)</mml:mo><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup><mml:mo stretchy="false">]</mml:mo><mml:mo>=</mml:mo><mml:msub><mml:mrow><mml:mi mathvariant="double-struck">E</mml:mi></mml:mrow><mml:mrow><mml:mi>s</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">[</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mi>s</mml:mi><mml:mo>−</mml:mo><mml:mi>μ</mml:mi><mml:msup><mml:mo stretchy="false">)</mml:mo><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup><mml:mo stretchy="false">]</mml:mo></mml:mrow></mml:mstyle></mml:math></inline-formula>. To do so, they need to have access to both the whisker stimulus <inline-formula><mml:math id="inf15"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>s</mml:mi></mml:mrow></mml:mstyle></mml:math></inline-formula> and the mean μ. PVs in PPC respond to sensory inputs in diverse cortical areas [S1:<xref ref-type="bibr" rid="bib70">Sachidhanandam et al., 2016</xref>] and are inhibited by SSTs in layer 2/3, which we assumed to represent the mean. Finally, for calculating the variance, these inputs need to be squared. PVs were shown to integrate their inputs supralinearly (<xref ref-type="bibr" rid="bib12">Cornford et al., 2019</xref>), which could help PVs to approximately estimate the variance.</p><p>In our circuit model, we next tested whether the PVs can learn to represent the variance of an upcoming whisker stimulus based on a context provided by an auditory input (<xref ref-type="fig" rid="fig3">Figure 3A</xref>). Two different auditory inputs (<xref ref-type="fig" rid="fig3">Figure 3B</xref> purple, green) are paired with two whisker stimulus distributions that differ in their variances (green: low, purple: high). PVs receive both the stimulus input as well as the inhibition from the SSTs, which subtracts the prediction of the mean (<xref ref-type="disp-formula" rid="equ1">Equation 11</xref>). The synaptic connection from the auditory input to the PVs is plastic according to the same local activity-dependent plasticity rule as the connection to the SSTs (<xref ref-type="disp-formula" rid="equ20">Equation 13</xref>). With this learning rule, the weight onto the PV becomes proportional to <inline-formula><mml:math id="inf16"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>σ</mml:mi></mml:mrow></mml:mstyle></mml:math></inline-formula> (<xref ref-type="fig" rid="fig3">Figure 3C</xref>), such that the PV firing rate becomes proportional to <inline-formula><mml:math id="inf17"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msup><mml:mi>σ</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:mstyle></mml:math></inline-formula> on average (<xref ref-type="fig" rid="fig3">Figure 3D</xref>). The average PV firing rate is exactly proportional to <inline-formula><mml:math id="inf18"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msup><mml:mi>σ</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:mstyle></mml:math></inline-formula> assuming a quadratic activation function <inline-formula><mml:math id="inf19"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>ϕ</mml:mi><mml:mrow><mml:mi>P</mml:mi><mml:mi>V</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>x</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mstyle></mml:math></inline-formula> (<xref ref-type="fig" rid="fig3">Figure 3D–F and H</xref>) and monotonically increasing with <inline-formula><mml:math id="inf20"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msup><mml:mi>σ</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:mstyle></mml:math></inline-formula> with other choices of activation functions (<xref ref-type="fig" rid="fig3s1">Figure 3—figure supplement 1</xref>), both when the sound input is presented alone (<xref ref-type="fig" rid="fig3">Figure 3D, E and H</xref>) or when paired with whisker stimulation (<xref ref-type="fig" rid="fig3">Figure 3F</xref>). Notably, a single PV neuron is sufficient for encoding variances of different contexts because the context-dependent <inline-formula><mml:math id="inf21"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>σ</mml:mi></mml:mrow></mml:mstyle></mml:math></inline-formula> is stored in the connection weights.</p><fig-group><fig id="fig3" position="float"><label>Figure 3.</label><caption><title>PVs learn to estimate the variance context-dependently.</title><p>(<bold>A</bold>) Illustration of the changes in the positive prediction error circuit. Thicker lines denote stronger weights. (<bold>B</bold>) Two different tones (purple, green) are associated with two somatosensory stimulus distributions with different variances (purple: high, green: low). (<bold>C</bold>) Weights from sound <italic>a</italic> to PV over time for two different values of stimulus variance (high: <inline-formula><mml:math id="inf22"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>σ</mml:mi><mml:mo>=</mml:mo><mml:mn>0.8</mml:mn></mml:mrow></mml:mstyle></mml:math></inline-formula> [purple], low: <inline-formula><mml:math id="inf23"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>σ</mml:mi><mml:mo>=</mml:mo><mml:mn>0.4</mml:mn></mml:mrow></mml:mstyle></mml:math></inline-formula> [green]). (<bold>D</bold>) PV firing rates over time given sound input (without whisker stimulus input) for low (green) and high (purple) stimulus variance. (<bold>E</bold>) PV firing rates (mean and std) given sound input and whisker stimuli for low and high stimulus variance. (<bold>F</bold>) PV firing rates (mean and std) during sound and stimulus input. (<bold>G</bold>) Weights (mean and std) from sound <inline-formula><mml:math id="inf24"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>a</mml:mi></mml:mrow></mml:mstyle></mml:math></inline-formula> to PV for different values of <inline-formula><mml:math id="inf25"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>σ</mml:mi></mml:mrow></mml:mstyle></mml:math></inline-formula>. (<bold>H</bold>) PV firing rates (mean and std) given sound input for different values of <inline-formula><mml:math id="inf26"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msup><mml:mi>σ</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:mstyle></mml:math></inline-formula>. Mean and std were computed from 150,000 data points from timestep 450,000–600,000.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-95127-fig3-v1.tif"/></fig><fig id="fig3s1" position="float" specific-use="child-fig"><label>Figure 3—figure supplement 1.</label><caption><title>Different choice of supralinear activation function for PV.</title><p>Learning the variance in the positive prediction error circuit with PVs with a power activation function (exponent = 3.0). (<bold>A, B</bold>) are analogous to <xref ref-type="fig" rid="fig3">Figure 3G and H</xref>, and the circuit is the same except that the activation function of the PVs (<inline-formula><mml:math id="inf27"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>ϕ</mml:mi><mml:mrow><mml:mi>P</mml:mi><mml:mi>V</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>x</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mstyle></mml:math></inline-formula>) has an exponent of 3.0 instead of 2.0. (<bold>C, D</bold>) are zoomed-out versions of (<bold>A, B</bold>).</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-95127-fig3-figsupp1-v1.tif"/></fig><fig id="fig3s2" position="float" specific-use="child-fig"><label>Figure 3—figure supplement 2.</label><caption><title>Plastic weights from SST to PV learn to match weights from <inline-formula><mml:math id="inf28"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>s</mml:mi></mml:mrow></mml:mstyle></mml:math></inline-formula> to PV.</title><p>With inhibitory plasticity, weights from SST to PV can be learned. This figure shows that the weight from SST to PV (<inline-formula><mml:math id="inf29"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>w</mml:mi><mml:mrow><mml:mrow><mml:mi mathvariant="normal">P</mml:mi><mml:mi mathvariant="normal">V</mml:mi></mml:mrow><mml:mo>,</mml:mo><mml:mrow><mml:mi mathvariant="normal">S</mml:mi><mml:mi mathvariant="normal">S</mml:mi><mml:mi mathvariant="normal">T</mml:mi></mml:mrow></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula>) is equal to the weight from <inline-formula><mml:math id="inf30"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>s</mml:mi></mml:mrow></mml:mstyle></mml:math></inline-formula> to PV (<inline-formula><mml:math id="inf31"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>w</mml:mi><mml:mrow><mml:mtext>PV</mml:mtext><mml:mo>,</mml:mo><mml:mi>s</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula>). The inhibitory plasticity rule is described in the Appendix.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-95127-fig3-figsupp2-v1.tif"/></fig><fig id="fig3s3" position="float" specific-use="child-fig"><label>Figure 3—figure supplement 3.</label><caption><title>PVs learn to represent the variance given an associative cue in the negative prediction error circuit.</title><p>(<bold>A</bold>) Illustration of the changes in the negative prediction error circuit. Thicker lines denote stronger weights. (<bold>B</bold>) Two different tones (purple, green) are associated with two somatosensory stimulus distributions with different variances (purple: high, green: low). (<bold>C</bold>) Weights from sound <inline-formula><mml:math id="inf32"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>a</mml:mi></mml:mrow></mml:mstyle></mml:math></inline-formula> to PV over time for two different values of stimulus variance (high: <inline-formula><mml:math id="inf33"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>σ</mml:mi><mml:mo>=</mml:mo><mml:mn>0.8</mml:mn></mml:mrow></mml:mstyle></mml:math></inline-formula> [purple], low: <inline-formula><mml:math id="inf34"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>σ</mml:mi><mml:mo>=</mml:mo><mml:mn>0.4</mml:mn></mml:mrow></mml:mstyle></mml:math></inline-formula> [green]). (<bold>D</bold>) PV firing rates over time given sound input (without stimulus input) for low (green) and high (purple) stimulus variance. (<bold>E</bold>) PV firing rates (mean and std) given sound input for low and high stimulus variance. (<bold>F</bold>) PV firing rates (mean and std) during sound and stimulus input. (<bold>G</bold>) Weights from sound <inline-formula><mml:math id="inf35"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>a</mml:mi></mml:mrow></mml:mstyle></mml:math></inline-formula> to PV for different values of <inline-formula><mml:math id="inf36"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>σ</mml:mi></mml:mrow></mml:mstyle></mml:math></inline-formula> (mean and std). (<bold>H</bold>) PV firing rates given sound input for different values of <inline-formula><mml:math id="inf37"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msup><mml:mi>σ</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:mstyle></mml:math></inline-formula> (mean and std).</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-95127-fig3-figsupp3-v1.tif"/></fig></fig-group><p>To estimate the variance, the mean needs to be subtracted from the stimulus samples. A faithful mean subtraction is only ensured if the weights from the SSTs to the PVs (<inline-formula><mml:math id="inf38"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>w</mml:mi><mml:mrow><mml:mrow><mml:mi mathvariant="normal">P</mml:mi><mml:mi mathvariant="normal">V</mml:mi></mml:mrow><mml:mo>,</mml:mo><mml:mrow><mml:mi mathvariant="normal">S</mml:mi><mml:mi mathvariant="normal">S</mml:mi><mml:mi mathvariant="normal">T</mml:mi></mml:mrow></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula>) match the weights from the stimuli <inline-formula><mml:math id="inf39"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>s</mml:mi></mml:mrow></mml:mstyle></mml:math></inline-formula> to the PVs (<inline-formula><mml:math id="inf40"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>w</mml:mi><mml:mrow><mml:mrow><mml:mi mathvariant="normal">P</mml:mi><mml:mi mathvariant="normal">V</mml:mi></mml:mrow><mml:mo>,</mml:mo><mml:mi>s</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula>). The weight <inline-formula><mml:math id="inf41"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>w</mml:mi><mml:mrow><mml:mrow><mml:mi mathvariant="normal">P</mml:mi><mml:mi mathvariant="normal">V</mml:mi></mml:mrow><mml:mo>,</mml:mo><mml:mrow><mml:mi mathvariant="normal">S</mml:mi><mml:mi mathvariant="normal">S</mml:mi><mml:mi mathvariant="normal">T</mml:mi></mml:mrow></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula> can be learned to match the weight <inline-formula><mml:math id="inf42"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>w</mml:mi><mml:mrow><mml:mrow><mml:mi mathvariant="normal">P</mml:mi><mml:mi mathvariant="normal">V</mml:mi></mml:mrow><mml:mo>,</mml:mo><mml:mi>s</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula> with a local activity-dependent plasticity rule (see <xref ref-type="fig" rid="fig3s2">Figure 3—figure supplement 2</xref> and Appendix).</p><p>The PVs can similarly estimate the uncertainty in negative prediction error circuits (<xref ref-type="fig" rid="fig3s3">Figure 3—figure supplement 3</xref>). In these circuits, SSTs represent the current sensory stimulus, and the mean prediction is an excitatory input to both negative prediction error neurons and PVs.</p></sec><sec id="s2-6"><title>Calculation of the UPE in layer 2/3 error neurons</title><p>Embedded in a circuit with subtractive and divisive interneuron types, layer 2/3 pyramidal cells could first compute the difference between the prediction and the stimulus in their dendrites, before their firing rate is divisively modulated by inhibition close to their soma. Layer 2/3 pyramidal cell dendrites can generate NMDA and calcium spikes, which cause a nonlinear integration of inputs. Hence, we took this into account and modelled the integration of dendritic activity as <inline-formula><mml:math id="inf43"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>I</mml:mi><mml:mrow><mml:mtext>dend</mml:mtext></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mo fence="false" stretchy="false">⌊</mml:mo><mml:msub><mml:mi>w</mml:mi><mml:mrow><mml:mrow><mml:mi mathvariant="normal">U</mml:mi><mml:mi mathvariant="normal">P</mml:mi><mml:mi mathvariant="normal">E</mml:mi></mml:mrow><mml:mo>,</mml:mo><mml:mi>s</mml:mi></mml:mrow></mml:msub><mml:mspace width="thickmathspace"/><mml:mi>s</mml:mi><mml:mo>−</mml:mo><mml:msub><mml:mi>w</mml:mi><mml:mrow><mml:mrow><mml:mi mathvariant="normal">U</mml:mi><mml:mi mathvariant="normal">P</mml:mi><mml:mi mathvariant="normal">E</mml:mi></mml:mrow><mml:mo>,</mml:mo><mml:mrow><mml:mi mathvariant="normal">S</mml:mi><mml:mi mathvariant="normal">S</mml:mi><mml:mi mathvariant="normal">T</mml:mi></mml:mrow></mml:mrow></mml:msub><mml:mspace width="thickmathspace"/><mml:msub><mml:mi>r</mml:mi><mml:mrow><mml:mrow><mml:mi mathvariant="normal">S</mml:mi><mml:mi mathvariant="normal">S</mml:mi><mml:mi mathvariant="normal">T</mml:mi></mml:mrow></mml:mrow></mml:msub><mml:msup><mml:mo fence="false" stretchy="false">⌋</mml:mo><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:msup></mml:mrow></mml:mstyle></mml:math></inline-formula> with <inline-formula><mml:math id="inf44"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:mstyle></mml:math></inline-formula> determining the non-linearity. The total activity of prediction error neurons was modelled by<disp-formula id="equ3"><label>(3)</label><mml:math id="m3"><mml:mtable rowspacing="3pt" columnspacing="0em 2em 0em 2em 0em 2em 0em 2em 0em 2em 0em" displaystyle="true"><mml:mtr><mml:mtd><mml:msub><mml:mi>τ</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi mathvariant="normal">E</mml:mi></mml:mrow></mml:mrow></mml:msub><mml:mfrac><mml:mrow><mml:mi>d</mml:mi><mml:msub><mml:mi>r</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi mathvariant="normal">U</mml:mi><mml:mi mathvariant="normal">P</mml:mi><mml:mi mathvariant="normal">E</mml:mi></mml:mrow></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:mi>d</mml:mi><mml:mi>t</mml:mi></mml:mrow></mml:mfrac></mml:mtd><mml:mtd><mml:mi/><mml:mo>=</mml:mo><mml:mo>−</mml:mo><mml:msub><mml:mi>r</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi mathvariant="normal">U</mml:mi><mml:mi mathvariant="normal">P</mml:mi><mml:mi mathvariant="normal">E</mml:mi></mml:mrow></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:mi>ϕ</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mfrac><mml:msub><mml:mi>I</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mtext>dend</mml:mtext></mml:mrow></mml:msub><mml:mrow><mml:msub><mml:mi>I</mml:mi><mml:mn>0</mml:mn></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mi>w</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi mathvariant="normal">U</mml:mi><mml:mi mathvariant="normal">P</mml:mi><mml:mi mathvariant="normal">E</mml:mi></mml:mrow><mml:mo>,</mml:mo><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi mathvariant="normal">P</mml:mi><mml:mi mathvariant="normal">V</mml:mi></mml:mrow></mml:mrow></mml:msub><mml:mspace width="thickmathspace"/><mml:msub><mml:mi>r</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi mathvariant="normal">P</mml:mi><mml:mi mathvariant="normal">V</mml:mi></mml:mrow></mml:mrow></mml:msub></mml:mrow></mml:mfrac><mml:mo>)</mml:mo></mml:mrow><mml:mo>.</mml:mo></mml:mtd></mml:mtr></mml:mtable></mml:math></disp-formula></p><p>The nonlinear integration of inputs is beneficial when the mean input changes and the current prediction differs strongly from the new mean of the stimulus distribution.</p><p>For example, if the mean input increases strongly, the PV firing rate will increase for larger errors and inhibit error neurons more strongly than indicated by the learned variance estimate. The pyramidal nonlinearity compensates for this increased inhibition by PVs, such that in the end, layer 2/3 cell activity reflects an uncertainty-modulated prediction error (<xref ref-type="fig" rid="fig4">Figure 4D–F</xref>) in both negative (<xref ref-type="fig" rid="fig4">Figure 4A</xref>) and positive (<xref ref-type="fig" rid="fig4">Figure 4C</xref>) prediction error circuits. A stronger nonlinearity (<xref ref-type="fig" rid="fig4">Figure 4G–I</xref>) has the effect that error neurons elicit larger responses to larger prediction errors.</p><fig-group><fig id="fig4" position="float"><label>Figure 4.</label><caption><title>Calculation of the UPE in layer 2/3 error neurons.</title><p>(<bold>A</bold>) Illustration of the negative prediction error circuit. (<bold>B</bold>) Distributions with different standard deviations <inline-formula><mml:math id="inf45"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>σ</mml:mi></mml:mrow></mml:mstyle></mml:math></inline-formula>. (<bold>C</bold>) Illustration of the positive prediction error circuit. (<bold>D</bold>) Firing rate of the error neuron in the negative prediction error circuit (UPE) as a function of <inline-formula><mml:math id="inf46"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>σ</mml:mi></mml:mrow></mml:mstyle></mml:math></inline-formula> for two values of <inline-formula><mml:math id="inf47"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mi>s</mml:mi><mml:mo>−</mml:mo><mml:mi>μ</mml:mi><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow></mml:mrow></mml:mstyle></mml:math></inline-formula> after learning μ and <inline-formula><mml:math id="inf48"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>σ</mml:mi></mml:mrow></mml:mstyle></mml:math></inline-formula>. (<bold>E</bold>) Rates of both UPE<sup>+</sup> and UPE<sup>−</sup>-representing error neurons with a nonlinear activation function, where <inline-formula><mml:math id="inf49"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>k</mml:mi><mml:mo>=</mml:mo><mml:mn>2.0</mml:mn></mml:mrow></mml:mstyle></mml:math></inline-formula>, as a function of the difference between the stimulus and the mean (<inline-formula><mml:math id="inf50"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>s</mml:mi><mml:mo>−</mml:mo><mml:mi>μ</mml:mi></mml:mrow></mml:mstyle></mml:math></inline-formula>). (<bold>F</bold>) Firing rate of the error neuron in the positive prediction error circuit (UPE<sup>+</sup>) as a function of <inline-formula><mml:math id="inf51"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>σ</mml:mi></mml:mrow></mml:mstyle></mml:math></inline-formula> for two values of <inline-formula><mml:math id="inf52"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mi>s</mml:mi><mml:mo>−</mml:mo><mml:mi>μ</mml:mi><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow></mml:mrow></mml:mstyle></mml:math></inline-formula> after learning μ and <inline-formula><mml:math id="inf53"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>σ</mml:mi></mml:mrow></mml:mstyle></mml:math></inline-formula>. (<bold>G-I</bold>) same as (<bold>D-F</bold>) for error neurons with <inline-formula><mml:math id="inf54"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>k</mml:mi><mml:mo>=</mml:mo><mml:mn>2.5</mml:mn></mml:mrow></mml:mstyle></mml:math></inline-formula> with the same legend as in (<bold>D-F</bold>).</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-95127-fig4-v1.tif"/></fig><fig id="fig4s1" position="float" specific-use="child-fig"><label>Figure 4—figure supplement 1.</label><caption><title>Learning the weights from the SSTs to the UPE neurons.</title><p>This figure shows that the weights from the SSTs to the UPEs in both the positive (left) and the negative (right) prediction error circuit can be learned with inhibitory plasticity to match the weights from the stimulus representation <inline-formula><mml:math id="inf55"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>s</mml:mi></mml:mrow></mml:mstyle></mml:math></inline-formula> to the UPEs. The inhibitory plasticity rule is described in the Appendix.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-95127-fig4-figsupp1-v1.tif"/></fig></fig-group><p>To ensure a comparison between the stimulus and the prediction, the inhibition from the SSTs needs to match the excitation, which it is compared to, in the UPE neurons: In the positive PE circuit, the weights from the SSTs representing the prediction to the UPE neurons need to match the weights from the stimulus <inline-formula><mml:math id="inf56"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>s</mml:mi></mml:mrow></mml:mstyle></mml:math></inline-formula> to the UPE neurons. In the negative PE circuit, the weights from SSTs representing the stimulus to the negative UPE neurons need to match the weights from the mean representation to the UPE neurons, respectively. In line with previous proposals, error neuron activity signals the breaking of EI balance (<xref ref-type="bibr" rid="bib32">Hertäg and Sprekeler, 2020</xref>; <xref ref-type="bibr" rid="bib7">Barry and Gerstner, 2024</xref>). With inhibitory plasticity (target-based, see Appendix), the weights from the SSTs can learn to match the incoming excitatory weights (<xref ref-type="fig" rid="fig4s1">Figure 4—figure supplement 1</xref>).</p></sec><sec id="s2-7"><title>Interactions between representation neurons and error neurons</title><p>The theoretical framework of predictive processing includes both prediction error neurons and representation neurons, the activity of which reflects the internal representation and should hence be compared to the sensory information. To make predictions for the activity of representation neurons, we expand our circuit model with this additional cell type. We first show that a representation neuron R can learn a representation of the stimulus mean given inputs from L2/3 error neurons. The representation neuron receives inputs from positive and negative prediction error neurons and from a higher level representation of the sound <inline-formula><mml:math id="inf57"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>a</mml:mi></mml:mrow></mml:mstyle></mml:math></inline-formula> (<xref ref-type="fig" rid="fig5">Figure 5A</xref>). It sends its current mean estimate to the error circuits by either targeting the SSTs (in the positive circuit) or the pyramidal cells directly (in the negative circuit). Hence in this recurrent circuit, the SSTs inherit the mean representation instead of learning it. After learning, the weights <inline-formula><mml:math id="inf58"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>w</mml:mi><mml:mrow><mml:mi>R</mml:mi><mml:mo>,</mml:mo><mml:mi>a</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula> from the sound representation to the representation neuron and the average firing rate of this representation neuron reflects the mean of the stimulus distribution (<xref ref-type="fig" rid="fig5">Figure 5B and C</xref>).</p><fig-group><fig id="fig5" position="float"><label>Figure 5.</label><caption><title>Learning the mean representation with UPEs.</title><p>(<bold>A</bold>) Illustration of the circuit. A representation neuron (turquoise) receives input from both positive and negative prediction error circuits (UPE<sup>+</sup> and UPE<sup>−</sup>) and projects back to them. The UPE<sup>−</sup> has a negative impact on the firing rate of the representation neuron (<inline-formula><mml:math id="inf59"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>r</mml:mi><mml:mrow><mml:mi>R</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula>). A weight <inline-formula><mml:math id="inf60"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>w</mml:mi><mml:mrow><mml:mi>R</mml:mi><mml:mo>,</mml:mo><mml:mi>a</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula> from the higher level representation of the context given by sound <inline-formula><mml:math id="inf61"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>a</mml:mi></mml:mrow></mml:mstyle></mml:math></inline-formula> is learned. (<bold>B</bold>) Weights <inline-formula><mml:math id="inf62"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>w</mml:mi><mml:mrow><mml:mi>R</mml:mi><mml:mo>,</mml:mo><mml:mi>a</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula> over time for different values of μ (<inline-formula><mml:math id="inf63"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>μ</mml:mi><mml:mo>∈</mml:mo><mml:mo stretchy="false">[</mml:mo><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mn>3</mml:mn><mml:mo>,</mml:mo><mml:mn>5</mml:mn><mml:mo stretchy="false">]</mml:mo></mml:mrow></mml:mstyle></mml:math></inline-formula>). (<bold>C</bold>) R firing rates given sound input for different values of μ (mean and std over 50,000 data points from timestep 50,000–100,000,, the end of the simulation). (<bold>D</bold>) Activity of the different cell types (PV: light green, R: turquiose, UPE: black) and whisker stimulus samples (grey dots) over time. Learning the mean representation with PVs (light green) reflecting the MSE at the beginning, which is compensated by nonlinear activation of L2/3 neurons (black). The evolution of the mean rate of neuron <inline-formula><mml:math id="inf64"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>R</mml:mi></mml:mrow></mml:mstyle></mml:math></inline-formula> (turquoise) is similar to the perfect case in (<bold>E</bold>). (<bold>E</bold>) Same colour code as in (<bold>D</bold>). Inset shows comparison to (<bold>D</bold>) Learning the mean representation assuming PVs (light green) perfectly represent the variance.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-95127-fig5-v1.tif"/></fig><fig id="fig5s1" position="float" specific-use="child-fig"><label>Figure 5—figure supplement 1.</label><caption><title>PV firing rates are proportional to the variance in the recurrent circuit model.</title><p>Weights from <inline-formula><mml:math id="inf65"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>a</mml:mi></mml:mrow></mml:mstyle></mml:math></inline-formula> to PV as a function of <inline-formula><mml:math id="inf66"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>σ</mml:mi></mml:mrow></mml:mstyle></mml:math></inline-formula> in the positive (<bold>A</bold>) and negative (<bold>C</bold>) prediction error subcircuit. PV firing rates as a function of <inline-formula><mml:math id="inf67"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msup><mml:mi>σ</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:mstyle></mml:math></inline-formula> in the positive (<bold>B</bold>) and negative (<bold>D</bold>) prediction error circuit.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-95127-fig5-figsupp1-v1.tif"/></fig></fig-group><p>As discussed earlier, pyramidal cells tend to integrate their dendritic inputs nonlinearly due to NMDA spikes. We here show that a circuit with prediction error neurons with a dendritic nonlinearity (as in <xref ref-type="fig" rid="fig4">Figure 4</xref>) approximates an idealised circuit, in which the PV rate perfectly represents the variance (<xref ref-type="fig" rid="fig5">Figure 5D and E</xref>, see inset for comparison of the two models). The dendritic nonlinearity can hence compensate for PV neuron dynamics. Also in this recurrent circuit, PVs learn to reflect the variance, as the weight from the sound representation <inline-formula><mml:math id="inf68"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>a</mml:mi></mml:mrow></mml:mstyle></mml:math></inline-formula> is learned to be proportional to <inline-formula><mml:math id="inf69"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>σ</mml:mi></mml:mrow></mml:mstyle></mml:math></inline-formula> (<xref ref-type="fig" rid="fig5s1">Figure 5—figure supplement 1</xref>).</p></sec><sec id="s2-8"><title>Predictions for different cell types</title><p>Our model makes predictions for the activity of different cell types for positive and negative prediction errors (e.g. when a mouse receives whisker stimuli that are larger (<xref ref-type="fig" rid="fig6">Figure 6A</xref>, black) or smaller (<xref ref-type="fig" rid="fig6">Figure 6G</xref>, grey) than expected) in contexts associated with different amounts of uncertainty (e.g. the high-uncertainty (purple) versus the low-uncertainty (green) context are associated with different sounds). Our model suggests that there are two types of interneurons that provide subtractive inhibition to the prediction error neurons (presumably SST subtypes): in the positive prediction error circuit (<inline-formula><mml:math id="inf70"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msup><mml:mrow><mml:mi mathvariant="normal">S</mml:mi><mml:mi mathvariant="normal">S</mml:mi><mml:mi mathvariant="normal">T</mml:mi></mml:mrow><mml:mrow><mml:mo>+</mml:mo></mml:mrow></mml:msup></mml:mrow></mml:mstyle></mml:math></inline-formula>), they signal the expected value of the whisker stimulus intensity (<xref ref-type="fig" rid="fig6">Figure 6B and H</xref>). In the negative prediction error circuit (<inline-formula><mml:math id="inf71"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msup><mml:mrow><mml:mi mathvariant="normal">S</mml:mi><mml:mi mathvariant="normal">S</mml:mi><mml:mi mathvariant="normal">T</mml:mi></mml:mrow><mml:mrow><mml:mo>−</mml:mo></mml:mrow></mml:msup></mml:mrow></mml:mstyle></mml:math></inline-formula>) they signal the whisker stimulus intensity (<xref ref-type="fig" rid="fig6">Figure 6C, I</xref>). We further predict that interneurons that divisively modulate prediction error neuron activity represent the uncertainty (presumably PVs). Those do not differ in their activity between positive and negative circuits and may even be shared across the two circuits: in both positive and negative prediction error circuits, these cells signal the variance (<xref ref-type="fig" rid="fig6">Figure 6D and J</xref>). L2/3 pyramidal cells that encode prediction errors signal uncertainty-modulated positive prediction errors (<xref ref-type="fig" rid="fig6">Figure 6E</xref>) and uncertainty-modulated negative prediction errors (<xref ref-type="fig" rid="fig6">Figure 6L</xref>), respectively. Finally, the existence of so-called internal representation neurons has been proposed (<xref ref-type="bibr" rid="bib44">Keller and Mrsic-Flogel, 2018</xref>). In our case, those neurons represent the predicted mean of the associated whisker deflections. Our model predicts that upon presentation of an unexpected whisker stimulus, those internal representation neurons adjust their activity to represent the new whisker deflection depending on the variability of the associated whisker deflections: they adjust their activity more (given equal deviations from the mean) if the associated whisker deflections are less variable (see the next section and <xref ref-type="fig" rid="fig7">Figure 7</xref>).</p><fig id="fig6" position="float"><label>Figure 6.</label><caption><title>Cell-type-specific experimentally testable predictions.</title><p>(<bold>A</bold>) Illustration of the two experienced stimulus distributions with different variances that are associated with two different sounds (green, purple). The presented mismatch (MM) stimulus (black) is larger than expected (positive prediction error). (<bold>B-F</bold>) Simulated firing rates of different cell types to positive prediction errors when a sound associated with high (purple) or low (green) uncertainty is presented. (<bold>G</bold>) As in (<bold>A</bold>) the presented mismatch stimulus (grey) is smaller than expected (negative prediction error). (<bold>H-L</bold>) Firing rates of different cell types to the negative mismatch when a sound associated with high (purple) or low (green) uncertainty is presented. Because the firing rate predictions are equal for PV<sup>+</sup> and PV<sup>−</sup>, we only show the results for PV<sup>+</sup> in the figure.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-95127-fig6-v1.tif"/></fig><fig id="fig7" position="float"><label>Figure 7.</label><caption><title>Effective learning rate is automatically adjusted with UPEs.</title><p>(<bold>A, B</bold>) Firing rate over time of the representation neuron in a circuit with uncertainty-modulated prediction errors (gold) and in a circuit with unmodulated errors (black) in a low uncertainty setting (<bold>A</bold>) and a high uncertainty setting (<bold>B</bold>). (<bold>C</bold>) Standard deviation of the firing rate of the representation neuron in the low uncertainty setting (inset has a different scale, outer axis scale matches the one in <bold>D</bold>). (<bold>D</bold>) Standard deviation of the firing rate of the representation neuron in the high uncertainty setting. (<bold>E</bold>) Standard deviation of the firing rate <inline-formula><mml:math id="inf72"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>r</mml:mi><mml:mrow><mml:mi>R</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula> as a function of the standard deviation of the presented stimulus distribution <inline-formula><mml:math id="inf73"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>σ</mml:mi><mml:mrow><mml:mi>s</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula>. Standard deviations were computed over 100,000 data points from timestep 100,000–200,000.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-95127-fig7-v1.tif"/></fig><p>The following experimental results are compatible with our predictions: First, putative inhibitory neurons (narrow spiking units) in the macaque anterior cingulate cortex increased their firing rates in periods of high uncertainty (<xref ref-type="bibr" rid="bib6">Banaie Boroujeni et al., 2021</xref>). These inhibitory neurons could correspond to the PVs in our model. Second, prediction error activity seems to decrease in less predictable, and hence more uncertain, contexts: in mice reared in a predictable environment [where locomotion and visual flow match (<xref ref-type="bibr" rid="bib43">Keller et al., 2012</xref>)], error neuron responses to mismatches in locomotion and visual flow decreased with each day of experiencing these unpredictable mismatches. Third, the responses of SSTs and PVs to mismatches between locomotion and visual flow (<xref ref-type="bibr" rid="bib4">Attinger et al., 2017</xref>) are in line with our model (note that in this experiment the mismatches are negative prediction errors as visual flow was halted despite ongoing locomotion): In this study, SST responses decreased during mismatch, that is when the visual flow was halted, and there was no difference between mice reared in a predictable or unpredictable environment. In line with these observations, the authors concluded that SST responses reflected the actual visual input. In our model negative PE circuit, SSTs also reflect the actual stimulus input, which in our case was a whisker stimulus (SST rates in <xref ref-type="fig" rid="fig6">Figure 6C, I</xref> reflect the stimuli (black and grey bar) in A and G, respectively) and SST rates are the same for high and low uncertainty (corresponding to mice reared in a predictable or unpredictable environment). In the same study, PV responses were absent towards mismatches in animals reared in an unpredictable environment (<xref ref-type="bibr" rid="bib4">Attinger et al., 2017</xref>). The authors argued that mice reared in an unpredictable environment did not learn to form a prediction. In our model, the missing prediction corresponds to missing predictive input from the auditory domain (e.g. due to undeveloped synapses from the predictive auditory input). If we removed the predictive input in our model, PVs in the negative PE circuit would also be silent as they would not receive any of the excitatory predictive inputs.</p></sec><sec id="s2-9"><title>The effective learning rate is automatically adjusted with UPEs</title><p>To test whether UPEs can automatically adjust the effective learning rate of a downstream neural population, we looked at two contexts that differed in uncertainty and compared how the mean representation evolves with and without UPEs. Indeed, in a low-uncertainty setting, a new mean representation can be learned faster with UPEs (in comparison to unmodulated, <xref ref-type="fig" rid="fig7">Figure 7A and C</xref>). In a high-uncertainty setting, the effective learning rate is smaller, and the mean representation is less variable than in the unmodulated case (<xref ref-type="fig" rid="fig7">Figure 7B and D</xref>). The standard deviation of the firing rate increases only sublinearly with the standard deviation of the inputs (<xref ref-type="fig" rid="fig7">Figure 7E</xref>). In summary, uncertainty-modulation of prediction errors enables an adaptive learning rate modulation.</p></sec><sec id="s2-10"><title>UPEs ensure uncertainty-based weighting of prior and sensory information</title><p>Behavioural studies suggest that during perception humans integrate priors or predictions (<inline-formula><mml:math id="inf74"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>p</mml:mi></mml:mrow></mml:mstyle></mml:math></inline-formula>) and sensory information (<inline-formula><mml:math id="inf75"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>s</mml:mi></mml:mrow></mml:mstyle></mml:math></inline-formula>) in a Bayes-optimal manner (<xref ref-type="bibr" rid="bib3">Ashourian and Loewenstein, 2011</xref>; <xref ref-type="bibr" rid="bib61">Petzschner and Glasauer, 2011</xref>). This entails that an internal neural representation (<inline-formula><mml:math id="inf76"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>r</mml:mi></mml:mrow></mml:mstyle></mml:math></inline-formula>, which determines perception, is achieved by weighting the two according to their uncertainties:<disp-formula id="equ4"><label>(4)</label><mml:math id="m4"><mml:mrow><mml:mi>r</mml:mi><mml:mo>=</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mi>c</mml:mi></mml:mfrac><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mfrac><mml:mn>1</mml:mn><mml:msubsup><mml:mi>σ</mml:mi><mml:mrow><mml:mi>s</mml:mi></mml:mrow><mml:mn>2</mml:mn></mml:msubsup></mml:mfrac><mml:mi>s</mml:mi><mml:mo>+</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:msubsup><mml:mi>σ</mml:mi><mml:mi>p</mml:mi><mml:mn>2</mml:mn></mml:msubsup></mml:mfrac><mml:mi>p</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>,</mml:mo></mml:mrow></mml:math></disp-formula></p><p>where <inline-formula><mml:math id="inf77"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>c</mml:mi><mml:mo>=</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:msubsup><mml:mi>σ</mml:mi><mml:mrow><mml:mtext>s</mml:mtext></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup></mml:mfrac><mml:mo>+</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:msubsup><mml:mi>σ</mml:mi><mml:mrow><mml:mtext>p</mml:mtext></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup></mml:mfrac></mml:mrow></mml:mstyle></mml:math></inline-formula>, <inline-formula><mml:math id="inf78"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msubsup><mml:mi>σ</mml:mi><mml:mrow><mml:mtext>s</mml:mtext></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup></mml:mrow></mml:mstyle></mml:math></inline-formula> is the uncertainty of the sensory information, and <inline-formula><mml:math id="inf79"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msubsup><mml:mi>σ</mml:mi><mml:mrow><mml:mtext>p</mml:mtext></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup></mml:mrow></mml:mstyle></mml:math></inline-formula> is the uncertainty of the prior.</p><p>To obtain this weighting in the steady state, prediction errors from the lower area, the sensory prediction error (<inline-formula><mml:math id="inf80"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>s</mml:mi><mml:mo>−</mml:mo><mml:mi>r</mml:mi></mml:mrow></mml:mstyle></mml:math></inline-formula>), and from the local area, the representation prediction error (<inline-formula><mml:math id="inf81"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>r</mml:mi><mml:mo>−</mml:mo><mml:mi>p</mml:mi></mml:mrow></mml:mstyle></mml:math></inline-formula>), can be used to update the current representation [as in <xref ref-type="bibr" rid="bib67">Rao and Ballard, 1999</xref>]. Maximising the log-likelihood (<xref ref-type="disp-formula" rid="equ29">Equation 22</xref> in Methods and <xref ref-type="disp-formula" rid="equ53">Equation 35</xref> in SI) yields an update of the representation by the difference between the bottom-up and top-down prediction errors.<disp-formula id="equ5"><label>(5)</label><mml:math id="m5"><mml:mrow><mml:mrow><mml:mover><mml:mi>r</mml:mi><mml:mo>˙</mml:mo></mml:mover></mml:mrow><mml:mo>=</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:msubsup><mml:mi>σ</mml:mi><mml:mrow><mml:mi>s</mml:mi></mml:mrow><mml:mn>2</mml:mn></mml:msubsup></mml:mfrac><mml:mo stretchy="false">(</mml:mo><mml:mi>s</mml:mi><mml:mo>−</mml:mo><mml:mi>r</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>−</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:msubsup><mml:mi>σ</mml:mi><mml:mi>p</mml:mi><mml:mn>2</mml:mn></mml:msubsup></mml:mfrac><mml:mo stretchy="false">(</mml:mo><mml:mi>r</mml:mi><mml:mo>−</mml:mo><mml:mi>p</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></disp-formula></p><p>From this we obtain <xref ref-type="disp-formula" rid="equ4">Equation 4</xref> by setting <inline-formula><mml:math id="inf82"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mrow><mml:mover><mml:mi>r</mml:mi><mml:mo>˙</mml:mo></mml:mover></mml:mrow><mml:mo>=</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:mstyle></mml:math></inline-formula>. Translating the update in <xref ref-type="disp-formula" rid="equ5">Equation 5</xref> into our framework of UPE circuits reads as<disp-formula id="equ6"><label>(6)</label><mml:math id="m6"><mml:mrow><mml:mrow><mml:mover><mml:mi>r</mml:mi><mml:mo>˙</mml:mo></mml:mover></mml:mrow><mml:mo>=</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:msubsup><mml:mtext>UPE</mml:mtext><mml:mrow><mml:mi>s</mml:mi></mml:mrow><mml:mo>+</mml:mo></mml:msubsup><mml:mo>−</mml:mo><mml:msubsup><mml:mtext>UPE</mml:mtext><mml:mrow><mml:mi>s</mml:mi></mml:mrow><mml:mo>−</mml:mo></mml:msubsup><mml:mo stretchy="false">)</mml:mo><mml:mo>−</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:msubsup><mml:mtext>UPE</mml:mtext><mml:mrow><mml:mi>p</mml:mi></mml:mrow><mml:mo>+</mml:mo></mml:msubsup><mml:mo>−</mml:mo><mml:msubsup><mml:mtext>UPE</mml:mtext><mml:mrow><mml:mi>p</mml:mi></mml:mrow><mml:mo>−</mml:mo></mml:msubsup><mml:mo stretchy="false">)</mml:mo><mml:mo>,</mml:mo></mml:mrow></mml:math></disp-formula></p><p>illustrated in <xref ref-type="fig" rid="fig8">Figure 8A</xref>.</p><fig id="fig8" position="float"><label>Figure 8.</label><caption><title>UPEs ensure uncertainty-based weighting of prior and sensory information.</title><p>(<bold>A</bold>) Illustration of the hierarchical two-area model. A representation neuron (<inline-formula><mml:math id="inf83"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>r</mml:mi></mml:mrow></mml:mstyle></mml:math></inline-formula>) in area <inline-formula><mml:math id="inf84"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>ℓ</mml:mi></mml:mrow></mml:mstyle></mml:math></inline-formula> receives positive and negative UPEs from the area <inline-formula><mml:math id="inf85"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>ℓ</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:mstyle></mml:math></inline-formula> below (sensory prediction error, as in <xref ref-type="fig" rid="fig5">Figure 5</xref>), and positive and negative UPEs from the same area (representation prediction error) with different signs, see <xref ref-type="disp-formula" rid="equ5">Equation 5</xref>. In this example, the uncertainty in area <inline-formula><mml:math id="inf86"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>ℓ</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:mstyle></mml:math></inline-formula> corresponds to the sensory uncertainty <inline-formula><mml:math id="inf87"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msubsup><mml:mi>σ</mml:mi><mml:mrow><mml:mi>s</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup></mml:mrow></mml:mstyle></mml:math></inline-formula>, and the uncertainty in the area <inline-formula><mml:math id="inf88"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>ℓ</mml:mi></mml:mrow></mml:mstyle></mml:math></inline-formula> above, corresponds to the prior uncertainty <inline-formula><mml:math id="inf89"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msubsup><mml:mi>σ</mml:mi><mml:mrow><mml:mi>p</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup></mml:mrow></mml:mstyle></mml:math></inline-formula>. Both uncertainties are represented by PV activity in the respective area. (<bold>B, C</bold>) The simulation results from the hierarchical circuit model yield an uncertainty-based weighting of prior and sensory information as in <xref ref-type="disp-formula" rid="equ4">Equation 4</xref>. (<bold>B</bold>) The activity <inline-formula><mml:math id="inf90"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>r</mml:mi></mml:mrow></mml:mstyle></mml:math></inline-formula> of the representation neuron as a function of the stimulus <inline-formula><mml:math id="inf91"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>s</mml:mi></mml:mrow></mml:mstyle></mml:math></inline-formula> for different amounts of prior uncertainty <inline-formula><mml:math id="inf92"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msubsup><mml:mi>σ</mml:mi><mml:mrow><mml:mi>p</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup></mml:mrow></mml:mstyle></mml:math></inline-formula>, when the sensory uncertainty is fixed <inline-formula><mml:math id="inf93"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msubsup><mml:mi>σ</mml:mi><mml:mrow><mml:mi>s</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup><mml:mo>=</mml:mo><mml:mn>0.5</mml:mn></mml:mrow></mml:mstyle></mml:math></inline-formula>. The histograms show the distribution of the sensory stimulus samples (grey) and the distribution of the activity of the representation neuron (green). (<bold>C</bold>) The activity of the representation neuron as a function of the stimulus for different amounts of sensory uncertainty <inline-formula><mml:math id="inf94"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msubsup><mml:mi>σ</mml:mi><mml:mrow><mml:mi>s</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup></mml:mrow></mml:mstyle></mml:math></inline-formula>, when the prior uncertainty is fixed <inline-formula><mml:math id="inf95"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msubsup><mml:mi>σ</mml:mi><mml:mrow><mml:mi>p</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup><mml:mo>=</mml:mo><mml:mn>0.5</mml:mn></mml:mrow></mml:mstyle></mml:math></inline-formula>.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-95127-fig8-v1.tif"/></fig><p>In our circuit, the representation neuron (green) receives the bottom-up errors, which are modulated by sensory uncertainty <inline-formula><mml:math id="inf96"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msubsup><mml:mi>σ</mml:mi><mml:mrow><mml:mi>s</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup></mml:mrow></mml:mstyle></mml:math></inline-formula>, as in the recurrent circuit model from the previous section. In addition, it receives errors between its current activity and a prior (a higher level expectation of the representation). The prior is set to the learned mean of the stimulus distribution and the errors are modulated by the learned prior uncertainty <inline-formula><mml:math id="inf97"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msubsup><mml:mi>σ</mml:mi><mml:mrow><mml:mi>p</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup></mml:mrow></mml:mstyle></mml:math></inline-formula>. We simulated this circuit, to which we presented stimuli drawn from Gaussian distributions as before. We varied the PV activity reflecting the sensory and prior uncertainty, and measured the activity of the representation neuron <inline-formula><mml:math id="inf98"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>r</mml:mi></mml:mrow></mml:mstyle></mml:math></inline-formula> to each stimulus. The higher the uncertainty of the prior information <inline-formula><mml:math id="inf99"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>σ</mml:mi><mml:mrow><mml:mi>s</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula>, the more the representation reflects the current stimulus (<xref ref-type="fig" rid="fig8">Figure 8B</xref>, see also <xref ref-type="disp-formula" rid="equ4">Equation 4</xref>). The higher the uncertainty of the sensory information <inline-formula><mml:math id="inf100"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>σ</mml:mi><mml:mrow><mml:mi>s</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula>, the more the representation reflects the prior mean (<xref ref-type="fig" rid="fig8">Figure 8C</xref>). This is a common behavioural effect, which is often referred to as central tendency effect or contraction bias (<xref ref-type="bibr" rid="bib35">Hollingworth, 1910</xref>; <xref ref-type="bibr" rid="bib37">Jazayeri and Shadlen, 2010</xref>; <xref ref-type="bibr" rid="bib2">Akrami et al., 2018</xref>; <xref ref-type="bibr" rid="bib57">Meirhaeghe et al., 2021</xref>).</p><p>To give a simple example how the prior uncertainty could come about in a dynamical environment, imagine noisy Gaussian sensory inputs with a fixed variance <inline-formula><mml:math id="inf101"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msubsup><mml:mi>σ</mml:mi><mml:mrow><mml:mi>s</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup></mml:mrow></mml:mstyle></mml:math></inline-formula>, and step changes in the mean, as in <xref ref-type="fig" rid="fig7">Figure 7</xref>. On the lowest level 0, after faithful learning, the learned variance <inline-formula><mml:math id="inf102"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msubsup><mml:mi>σ</mml:mi><mml:mrow><mml:mn>0</mml:mn></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup></mml:mrow></mml:mstyle></mml:math></inline-formula> will represent the variance of the sensory input <inline-formula><mml:math id="inf103"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msubsup><mml:mi>σ</mml:mi><mml:mrow><mml:mi>s</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup></mml:mrow></mml:mstyle></mml:math></inline-formula> for a given mean. If in addition, the mean of the sensory input varies (as in <xref ref-type="fig" rid="fig7">Figure 7</xref>), then on the level above <inline-formula><mml:math id="inf104"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msubsup><mml:mi>σ</mml:mi><mml:mrow><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup></mml:mrow></mml:mstyle></mml:math></inline-formula> will reflect how much the mean varies. The former corresponds to the sensory uncertainty, the latter to the environmental volatility, which increases the uncertainty about the prediction for the mean (<inline-formula><mml:math id="inf105"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msubsup><mml:mi>σ</mml:mi><mml:mrow><mml:mi>p</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup></mml:mrow></mml:mstyle></mml:math></inline-formula>).</p></sec></sec><sec id="s3" sec-type="discussion"><title>Discussion</title><p>Based on normative theories, we propose that the brain uses uncertainty-modulated prediction errors. In particular, we hypothesise that layer 2/3 prediction error neurons represent prediction errors that are inversely modulated by uncertainty. Here, we showed that different inhibitory cell types in layer 2/3 cortical circuits can compute means and variances and thereby enable pyramidal cells to represent uncertainty-modulated prediction errors. We further showed that the cells in the circuit are able to learn to predict the means and variances of their inputs with local activity-dependent plasticity rules. Our study makes experimentally testable predictions for the activity of different cell types, PV and SST interneurons, in particular, prediction error neurons and representation neurons. Finally, we showed that circuits with uncertainty-modulated prediction errors enable adaptive learning rates, resulting in fast learning when uncertainty is low and slow learning to avoid detrimental fluctuations when uncertainty is high.</p><p>Our theory has the following notable implications: The first implication concerns the hierarchical organisation of the brain. At each level of the hierarchy, we find similar canonical circuit motifs that receive both feedforward (from a lower level) and feedback (from a higher level, predictive) inputs that need to be integrated. We propose that uncertainty is computed on each level of the hierarchy. This enables uncertainty estimates specific to the processing level of a particular area. Experimental evidence is so far insufficient to favour distributed uncertainty representation over the idea that uncertainty is only computed on the level of decisions in higher level brain areas such as the parietal cortex (<xref ref-type="bibr" rid="bib45">Kiani and Shadlen, 2009</xref>), orbitofrontal cortex (<xref ref-type="bibr" rid="bib56">Masset et al., 2020</xref>), or prefrontal cortex (<xref ref-type="bibr" rid="bib69">Rushworth and Behrens, 2008</xref>). Our study provides a concrete suggestion for a canonical circuit implementation and, therefore, experimentally testable predictions. The distributed account has clear computational advantages for task-flexibility, information integration, active sensing, and learning (see <xref ref-type="bibr" rid="bib46">Koblinger et al., 2021</xref> for a recent review of the two accounts). Additionally, adding uncertainty-modulated prediction errors from different hierarchical levels according to the predictive coding model (<xref ref-type="bibr" rid="bib67">Rao and Ballard, 1999</xref>; <xref ref-type="bibr" rid="bib78">Whittington and Bogacz, 2017</xref>) yields an uncertainty-based weighting of feedback and feedforward information, similar to a Bayes-optimal weighting, which can be reconciled with human behaviour (<xref ref-type="bibr" rid="bib59">Payzan-LeNestour and Bossaerts, 2011</xref>). Two further important implications result from storing uncertainty in the afferent connections to the PVs. First, this implies that the same PV cell can store different uncertainties depending on the context, which is encoded in the pre-synaptic activation. Second, fewer PVs than pyramidal cells are required for the mechanism, which is compatible with the 80/20 ratio of excitatory to inhibitory cells in the brain. The lower selectivity of interneurons in comparison to pyramidal cells could be a feature in prediction error circuits. Error neurons selective to similar stimuli are more likely to receive similar stimulus information, and hence similar predictions. Therefore, a circuit structure may have developed such that prediction error neurons with similar selectivity may receive inputs from the same inhibitory interneurons.</p><p>We claim that the uncertainty represented by PVs in our theoretical framework corresponds to <italic>expected uncertainty</italic> that results from noise or irreducible uncertainty in the stimuli and should therefore decrease the learning rate. Another common source of uncertainty are changes in the environment, also referred to as the <italic>unexpected uncertainty</italic>. In volatile environments with high unexpected uncertainty, the learning rate should increase. We suggest that vasointestinal-peptide-positive interneurons (VIPs) could be responsible for signalling the unexpected uncertainty, as they respond to reward, punishment and surprise (<xref ref-type="bibr" rid="bib64">Pi et al., 2013</xref>), which can be indicators of high unexpected uncertainty. They provide potent disinhibition of pyramidal cells (<xref ref-type="bibr" rid="bib63">Pfeffer, 2014</xref>), and also inhibit PVs in layer 2/3 (<xref ref-type="bibr" rid="bib62">Pfeffer et al., 2013</xref>). Hence, they could increase error activity resulting in a larger learning signal. In general, interneurons are innervated by different kinds of neuromodulators (<xref ref-type="bibr" rid="bib53">Lee et al., 2013</xref>; <xref ref-type="bibr" rid="bib65">Prönneke et al., 2015</xref>) and control pyramidal cell’s activity and plasticity (<xref ref-type="bibr" rid="bib36">Isaacson and Scanziani, 2011</xref>; <xref ref-type="bibr" rid="bib25">Gidon and Segev, 2012</xref>; <xref ref-type="bibr" rid="bib79">Wilmes et al., 2016</xref>; <xref ref-type="bibr" rid="bib80">Wilmes et al., 2017</xref>; <xref ref-type="bibr" rid="bib81">Wilmes and Clopath, 2019</xref>). Therefore, neuromodulators could have powerful control over error neuron activity and hence perception and learning.</p><p>A diversity of proposals about the neural representation of uncertainty exist. For example, it has been suggested that uncertainty is represented in single neurons by the width (<xref ref-type="bibr" rid="bib21">Fischer and Peña, 2011</xref>), or amplitude of their responses (<xref ref-type="bibr" rid="bib55">Ma et al., 2006</xref>), or implicitly via sampling [neural sampling hypothesis; (<xref ref-type="bibr" rid="bib60">Petrovici et al., 2013</xref>; <xref ref-type="bibr" rid="bib9">Buesing et al., 2011</xref>; <xref ref-type="bibr" rid="bib8">Berkes et al., 2011</xref>)], or rather than being represented by a single feature, can be decoded from the activity of an entire population (<xref ref-type="bibr" rid="bib15">Dehaene et al., 2021</xref>). While we suggest that PVs represent uncertainty to modulate prediction error responses, we do not claim that this is the sole representation of uncertainty in neuronal circuits.</p><p>Uncertainty estimation is relevant for Bayes-optimal integration of different sources of information, for example different modalities [multi-sensory integration; <xref ref-type="bibr" rid="bib18">Ernst and Banks, 2002</xref>; <xref ref-type="bibr" rid="bib19">Fetsch et al., 2012</xref>] or priors and sensory information. Here, we present a circuit implementation for weighting sensory information versus priors according to their uncertainties by integrating uncertainty-modulated prediction errors. An alternative solution is to estimate uncertainty from the activity of prediction error neurons and use it to weight priors and sensory information (<xref ref-type="bibr" rid="bib34">Hertäg et al., 2023</xref>), leading to contraction bias (<xref ref-type="bibr" rid="bib33">Hertäg and Clopath, 2022</xref>). <xref ref-type="bibr" rid="bib33">Hertäg and Clopath, 2022</xref> previously showed that the integration of prediction errors with sensory information in representation neurons can also lead to contraction bias, but without being dependent on uncertainty. Instead of modulating the error on each level by the uncertainty on that level as in our suggestion, one can also obtain a Bayes-optimal weighting by combining an unweighted top-down error with a bottom-error that is multiplicatively modulated by the prior uncertainty, and divisively modulated by the bottom-up uncertainty (<xref ref-type="bibr" rid="bib29">Granier et al., 2024</xref>). It has also been suggested that Bayes-optimal multi-sensory integration could be achieved in single neurons (<xref ref-type="bibr" rid="bib19">Fetsch et al., 2012</xref>; <xref ref-type="bibr" rid="bib39">Jordan et al., 2022</xref>). Our proposal is complementary to these solutions in that uncertainty-modulated errors can be forwarded to other cortical and subcortical circuits at different levels of the hierarchy, where they can be used for inference and learning. It further allows for a context-dependent integration of sensory inputs.</p><p>Multiple neurological disorders, such as autism spectrum disorder or schizophrenia, are associated with maladaptive contextual uncertainty-weighting of sensory and prior information (<xref ref-type="bibr" rid="bib28">Goris et al., 2021</xref>; <xref ref-type="bibr" rid="bib50">Lawson et al., 2014</xref>; <xref ref-type="bibr" rid="bib76">Van de Cruys et al., 2014</xref>; <xref ref-type="bibr" rid="bib51">Lawson et al., 2017</xref>; <xref ref-type="bibr" rid="bib73">Shi et al., 2022</xref>). These disorders are also associated with aberrant inhibition, for example ASD is associated with an excitation-inhibition imbalance (<xref ref-type="bibr" rid="bib68">Rubenstein and Merzenich, 2003</xref>) and reduced inhibition (<xref ref-type="bibr" rid="bib31">Harada et al., 2011</xref>; <xref ref-type="bibr" rid="bib24">Gaetz et al., 2014</xref>). Interestingly, PV cells, in particular chandelier PV cells, were shown to be reduced in number and synaptic strength in ASD (<xref ref-type="bibr" rid="bib41">Juarez and Martínez Cerdeño, 2022</xref>). Our theory provides one possible explanation of how deficits in uncertainty-weighting on the behavioural level could be linked to altered PVs on the circuit level.</p><p>Finally, uncertainty-modulated errors could advance deep hierarchical neural networks. In addition to propagating gradients, propagating uncertainty may have advantages for learning. The additional information on uncertainty could enable calculating distances between distributions, which can provide an informative and parameter-independent metric for learning [e.g. natural gradient learning (<xref ref-type="bibr" rid="bib48">Kreutzer et al., 2022</xref>)].</p><p>To provide experimental predictions that are immediately testable, we suggested specific roles for SSTs and PVs, as they can subtractively and divisively modulate pyramidal cell activity, respectively. In principle, our theory more generally posits that any subtractive or divisive inhibition could implement the suggested computations. With the emerging data on inhibitory cell types, subtypes of SSTs and PVs or other cell types may turn out to play the proposed role.</p><p>The model predicts that the divisive interneuron type, which we here suggest to be the PVs, receives a representation of the stimulus as an input. PVs could be pooling the inputs from stimulus-responsive layer 2/3 neurons to estimate uncertainty. The more the stimulus varies, the larger the variability of the pyramidal neuron responses and, hence, the variability of the PV activity. The broader sensory tuning of PVs (<xref ref-type="bibr" rid="bib13">Cottam et al., 2013</xref>) is in line with the model insofar as uncertainty modulation could be more general than the specific feature, which is more likely for low-level features processed in primary sensory cortices. PVs were shown to connect more to pyramidal cells with similar feature tuning (<xref ref-type="bibr" rid="bib85">Znamenskiy et al., 2024</xref>) this would be in line with the model, as uncertainty modulation should be feature-related. In our model, some SSTs deliver the prediction to the positive prediction error neurons. SSTs are already known to be involved in spatial prediction, as they underlie the effect of surround suppression (<xref ref-type="bibr" rid="bib1">Adesnik et al., 2012</xref>), in which SSTs suppress the local activity dependent on a predictive surround.</p><p>In the model we propose, SSTs should be subtractive and PVs divisive. However, SSTs can also be divisive, and PVs subtractive dependent on circuit and postsynaptic properties (<xref ref-type="bibr" rid="bib72">Seybold et al., 2015</xref>; <xref ref-type="bibr" rid="bib52">Lee et al., 2012</xref>; <xref ref-type="bibr" rid="bib16">Dorsett et al., 2021</xref>). This does not necessarily contradict our model, as circuits in which SSTs are divisive and PVs subtractive could implement a different function, as not all pyramidal cells are error neurons. Hence, our model suggests that error neurons which can calculate UPEs should have similar physiological properties to the layer 2/3 cells observed in the study by <xref ref-type="bibr" rid="bib83">Wilson et al., 2012</xref>.</p><p>Our model further posits the existence of two distinct subtypes of SSTs in positive and negative error circuits. Indeed, there are many different subtypes of SSTs (<xref ref-type="bibr" rid="bib71">Schneider-Mizell et al., 2024</xref>). SST is expressed by a large population of interneurons, which can be further subdivided. There is, for example, a type called SST44, which was shown to specifically respond when the animal corrects a movement (<xref ref-type="bibr" rid="bib30">Green et al., 2023</xref>). Our proposal is hence aligned with the observation of functionally specialised subtypes of SSTs. Importantly, the comparison between stimulus and prediction needs to happen before the divisive modulation. Although our model does not make assumptions about the precise dendritic location of this comparison, we suggest this to happen on the apical dendrite, as top-down inputs and SST synapses arrive there. SSTs receive top-down inputs (<xref ref-type="bibr" rid="bib54">Liu et al., 2020</xref>), which could provide the prediction to be subtracted in negative prediction error circuits.</p><p>To compare predictions and stimuli in a subtractive manner, the encoded prediction/stimulus needs to be translated into a direct variable code. In this framework, we assume that this can be achieved by the weight matrix defining the synaptic connections from the neural populations representing predictions and stimuli (possibly in a population code).</p><p>To enable the comparison between predictions and sensory information via subtractive inhibition, we pointed out that the weights of those inputs on the postsynaptic neuron need to match. This essentially means that there needs to be a balance of excitatory and inhibitory inputs. Such an EI balance has been observed experimentally (<xref ref-type="bibr" rid="bib74">Tan and Wehr, 2009</xref>). And it has previously been suggested that error responses are the result of breaking this EI balance (<xref ref-type="bibr" rid="bib32">Hertäg and Sprekeler, 2020</xref>; <xref ref-type="bibr" rid="bib7">Barry and Gerstner, 2024</xref>). Heterosynaptic plasticity is a possible mechanism to achieve EI balance (<xref ref-type="bibr" rid="bib20">Field et al., 2020</xref>). For example, spike pairing in pre- and postsynaptic neurons induces long-term potentiation at co-activated excitatory and inhibitory synapses with the degree of inhibitory potentiation depending on the evoked excitation (<xref ref-type="bibr" rid="bib14">D’amour and Froemke, 2015</xref>), which can normalise EI balance (<xref ref-type="bibr" rid="bib20">Field et al., 2020</xref>).</p><sec id="s3-1"><title>Conclusion</title><p>To conclude, we proposed that prediction error activity in layer 2/3 circuits is modulated by uncertainty and that the diversity of cell types in these circuits achieves the appropriate scaling of the prediction error activity. The proposed model is compatible with Bayes-optimal behaviour and makes predictions for future experiments.</p></sec></sec><sec id="s4" sec-type="methods"><title>Methods</title><sec id="s4-1"><title>Derivation of the UPE</title><p>The goal is to learn <inline-formula><mml:math id="inf106"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mrow><mml:mover><mml:mi>μ</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow></mml:mrow></mml:mstyle></mml:math></inline-formula> to maximise the log-likelihood:<disp-formula id="equ7"><mml:math id="m7"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>log</mml:mi><mml:mo>⁡</mml:mo><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi class="MJX-tex-caligraphic" mathvariant="script">L</mml:mi></mml:mrow></mml:mstyle><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mo>=</mml:mo><mml:mi>log</mml:mi><mml:mo>⁡</mml:mo><mml:mi>p</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi mathvariant="double-struck">s</mml:mi></mml:mrow><mml:mrow class="MJX-TeXAtom-ORD"><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mrow class="MJX-TeXAtom-ORD"><mml:mover><mml:mi>μ</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mo>,</mml:mo><mml:mi>σ</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mstyle></mml:math></disp-formula><disp-formula id="equ8"><mml:math id="m8"><mml:mrow><mml:mo>=</mml:mo><mml:mi>log</mml:mi><mml:mo>⁡</mml:mo><mml:munderover><mml:mo>∏</mml:mo><mml:mrow><mml:mi>n</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>N</mml:mi></mml:munderover><mml:mrow><mml:mi class="mathcal" mathvariant="script">N</mml:mi></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>s</mml:mi><mml:mi>n</mml:mi></mml:msub><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mrow><mml:mover><mml:mi>μ</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mo>,</mml:mo><mml:mi>σ</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></disp-formula><disp-formula id="equ9"><mml:math id="m9"><mml:mrow><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mo>=</mml:mo><mml:mo>−</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mrow><mml:mn>2</mml:mn><mml:msup><mml:mi>σ</mml:mi><mml:mn>2</mml:mn></mml:msup></mml:mrow></mml:mfrac><mml:munderover><mml:mo>∑</mml:mo><mml:mrow><mml:mi>n</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>N</mml:mi></mml:munderover><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>s</mml:mi><mml:mi>n</mml:mi></mml:msub><mml:mo>−</mml:mo><mml:mrow><mml:mover><mml:mi>μ</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:msup><mml:mo stretchy="false">)</mml:mo><mml:mn>2</mml:mn></mml:msup><mml:mo>−</mml:mo><mml:mfrac><mml:mi>N</mml:mi><mml:mn>2</mml:mn></mml:mfrac><mml:mi>log</mml:mi><mml:mo>⁡</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mn>2</mml:mn><mml:mi>π</mml:mi><mml:msup><mml:mi>σ</mml:mi><mml:mn>2</mml:mn></mml:msup><mml:mo stretchy="false">)</mml:mo></mml:mstyle></mml:mrow></mml:math></disp-formula></p><p>We consider the log-likelihood for one sample <inline-formula><mml:math id="inf107"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>s</mml:mi></mml:mrow></mml:mstyle></mml:math></inline-formula> of the stimulus distribution:<disp-formula id="equ10"><mml:math id="m10"><mml:mrow><mml:mi>log</mml:mi><mml:mo>⁡</mml:mo><mml:mi>p</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>s</mml:mi><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mrow><mml:mover><mml:mi>μ</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mo>,</mml:mo><mml:mi>σ</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mo>−</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mrow><mml:mn>2</mml:mn><mml:msup><mml:mi>σ</mml:mi><mml:mn>2</mml:mn></mml:msup></mml:mrow></mml:mfrac><mml:mo stretchy="false">(</mml:mo><mml:mi>s</mml:mi><mml:mo>−</mml:mo><mml:mrow><mml:mover><mml:mi>μ</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:msup><mml:mo stretchy="false">)</mml:mo><mml:mn>2</mml:mn></mml:msup><mml:mo>−</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mn>2</mml:mn></mml:mfrac><mml:mi>log</mml:mi><mml:mo>⁡</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mn>2</mml:mn><mml:mi>π</mml:mi><mml:msup><mml:mi>σ</mml:mi><mml:mn>2</mml:mn></mml:msup><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></disp-formula></p><p>Stochastic gradient ascent on the log-likelihood gives the update for <inline-formula><mml:math id="inf108"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mrow><mml:mover><mml:mi>μ</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow></mml:mrow></mml:mstyle></mml:math></inline-formula>:<disp-formula id="equ11"><mml:math id="m11"><mml:mrow><mml:mi mathvariant="normal">Δ</mml:mi><mml:mrow><mml:mover><mml:mi>μ</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mo>∝</mml:mo><mml:mfrac><mml:mi mathvariant="normal">∂</mml:mi><mml:mrow><mml:mi mathvariant="normal">∂</mml:mi><mml:mrow><mml:mover><mml:mi>μ</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow></mml:mrow></mml:mfrac><mml:mo stretchy="false">(</mml:mo><mml:mi>log</mml:mi><mml:mo>⁡</mml:mo><mml:mi>p</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>s</mml:mi><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mrow><mml:mover><mml:mi>μ</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mo>,</mml:mo><mml:mi>σ</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></disp-formula><disp-formula id="equ12"><mml:math id="m12"><mml:mrow><mml:mo>=</mml:mo><mml:mfrac><mml:mi mathvariant="normal">∂</mml:mi><mml:mrow><mml:mi mathvariant="normal">∂</mml:mi><mml:mrow><mml:mover><mml:mi>μ</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow></mml:mrow></mml:mfrac><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mo>−</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mrow><mml:mn>2</mml:mn><mml:msup><mml:mi>σ</mml:mi><mml:mn>2</mml:mn></mml:msup></mml:mrow></mml:mfrac><mml:mo stretchy="false">(</mml:mo><mml:mi>s</mml:mi><mml:mo>−</mml:mo><mml:mrow><mml:mover><mml:mi>μ</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:msup><mml:mo stretchy="false">)</mml:mo><mml:mn>2</mml:mn></mml:msup><mml:mo>−</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mn>2</mml:mn></mml:mfrac><mml:mi>log</mml:mi><mml:mo>⁡</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mn>2</mml:mn><mml:mi>π</mml:mi><mml:msup><mml:mi>σ</mml:mi><mml:mn>2</mml:mn></mml:msup><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></disp-formula><disp-formula id="equ13"><mml:math id="m13"><mml:mrow><mml:mo>=</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:msup><mml:mi>σ</mml:mi><mml:mn>2</mml:mn></mml:msup></mml:mfrac><mml:mo stretchy="false">(</mml:mo><mml:mi>s</mml:mi><mml:mo>−</mml:mo><mml:mrow><mml:mover><mml:mi>μ</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mo stretchy="false">)</mml:mo><mml:mo>.</mml:mo></mml:mrow></mml:math></disp-formula></p></sec><sec id="s4-2"><title>Circuit model</title><sec id="s4-2-1"><title>Prediction error circuit</title><p>We modelled a circuit consisting of excitatory prediction error neurons in layer 2/3, and two inhibitory populations, corresponding to PV and SST interneurons.</p><p>Layer 2/3 pyramidal cells receive divisive inhibition from PVs (<xref ref-type="bibr" rid="bib83">Wilson et al., 2012</xref>). We, hence, modelled the activity of prediction error neurons as<disp-formula id="equ14"><label>(7)</label><mml:math id="m14"><mml:mrow><mml:msub><mml:mi>τ</mml:mi><mml:mrow><mml:mrow><mml:mi mathvariant="normal">E</mml:mi></mml:mrow></mml:mrow></mml:msub><mml:mfrac><mml:mrow><mml:mi>d</mml:mi><mml:msub><mml:mi>r</mml:mi><mml:mrow><mml:mrow><mml:mi mathvariant="normal">U</mml:mi><mml:mi mathvariant="normal">P</mml:mi><mml:mi mathvariant="normal">E</mml:mi></mml:mrow></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:mi>d</mml:mi><mml:mi>t</mml:mi></mml:mrow></mml:mfrac><mml:mo>=</mml:mo><mml:mo>−</mml:mo><mml:msub><mml:mi>r</mml:mi><mml:mrow><mml:mrow><mml:mi mathvariant="normal">U</mml:mi><mml:mi mathvariant="normal">P</mml:mi><mml:mi mathvariant="normal">E</mml:mi></mml:mrow></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:mi>ϕ</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mfrac><mml:msub><mml:mi>I</mml:mi><mml:mrow><mml:mtext>dend</mml:mtext></mml:mrow></mml:msub><mml:mrow><mml:msub><mml:mi>I</mml:mi><mml:mn>0</mml:mn></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mi>w</mml:mi><mml:mrow><mml:mrow><mml:mi mathvariant="normal">U</mml:mi><mml:mi mathvariant="normal">P</mml:mi><mml:mi mathvariant="normal">E</mml:mi></mml:mrow><mml:mo>,</mml:mo><mml:mrow><mml:mi mathvariant="normal">P</mml:mi><mml:mi mathvariant="normal">V</mml:mi></mml:mrow></mml:mrow></mml:msub><mml:mspace width="thickmathspace"/><mml:msub><mml:mi>r</mml:mi><mml:mrow><mml:mrow><mml:mi mathvariant="normal">P</mml:mi><mml:mi mathvariant="normal">V</mml:mi></mml:mrow></mml:mrow></mml:msub></mml:mrow></mml:mfrac><mml:mo>)</mml:mo></mml:mrow><mml:mo>,</mml:mo></mml:mrow></mml:math></disp-formula></p><p>where <inline-formula><mml:math id="inf109"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>ϕ</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>x</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mstyle></mml:math></inline-formula> is the activation function defined as:<disp-formula id="equ15"><label>(8)</label><mml:math id="m15"><mml:mrow><mml:mi>ϕ</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>x</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mrow><mml:mo>{</mml:mo><mml:mtable columnalign="left left" rowspacing=".2em" columnspacing="1em" displaystyle="false"><mml:mtr><mml:mtd><mml:mn>0</mml:mn></mml:mtd><mml:mtd><mml:mrow><mml:mtext>if </mml:mtext><mml:mrow><mml:mi>x</mml:mi><mml:mo>≤</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:mrow></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mi>x</mml:mi></mml:mtd><mml:mtd><mml:mrow><mml:mtext>if </mml:mtext><mml:mrow><mml:mn>0</mml:mn><mml:mo>&lt;</mml:mo><mml:mi>x</mml:mi><mml:mo>&lt;</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mrow><mml:mo movablelimits="true" form="prefix">max</mml:mo></mml:mrow></mml:msub></mml:mrow></mml:mrow></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:msub><mml:mi>r</mml:mi><mml:mrow><mml:mo movablelimits="true" form="prefix">max</mml:mo></mml:mrow></mml:msub></mml:mtd><mml:mtd><mml:mrow><mml:mtext>if </mml:mtext><mml:mrow><mml:mi>x</mml:mi><mml:mo>≥</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mrow><mml:mo movablelimits="true" form="prefix">max</mml:mo></mml:mrow></mml:msub></mml:mrow></mml:mrow><mml:mo>,</mml:mo></mml:mtd></mml:mtr></mml:mtable><mml:mo fence="true" stretchy="true" symmetric="true"/></mml:mrow></mml:mrow></mml:math></disp-formula></p><p><inline-formula><mml:math id="inf110"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>I</mml:mi><mml:mrow><mml:mtext>dend</mml:mtext></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mo fence="false" stretchy="false">⌊</mml:mo><mml:msub><mml:mi>w</mml:mi><mml:mrow><mml:mrow><mml:mi mathvariant="normal">U</mml:mi><mml:mi mathvariant="normal">P</mml:mi><mml:mi mathvariant="normal">E</mml:mi></mml:mrow><mml:mo>,</mml:mo><mml:mrow><mml:mi mathvariant="normal">s</mml:mi></mml:mrow></mml:mrow></mml:msub><mml:mspace width="thickmathspace"/><mml:mrow><mml:mi mathvariant="normal">s</mml:mi></mml:mrow><mml:mo>−</mml:mo><mml:msub><mml:mi>w</mml:mi><mml:mrow><mml:mrow><mml:mi mathvariant="normal">U</mml:mi><mml:mi mathvariant="normal">P</mml:mi><mml:mi mathvariant="normal">E</mml:mi></mml:mrow><mml:mo>,</mml:mo><mml:mrow><mml:mi mathvariant="normal">S</mml:mi><mml:mi mathvariant="normal">S</mml:mi><mml:mi mathvariant="normal">T</mml:mi></mml:mrow></mml:mrow></mml:msub><mml:mspace width="thickmathspace"/><mml:msub><mml:mi>r</mml:mi><mml:mrow><mml:mrow><mml:mi mathvariant="normal">S</mml:mi><mml:mi mathvariant="normal">S</mml:mi><mml:mi mathvariant="normal">T</mml:mi></mml:mrow></mml:mrow></mml:msub><mml:msup><mml:mo fence="false" stretchy="false">⌋</mml:mo><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:msup></mml:mrow></mml:mstyle></mml:math></inline-formula> is the dendritic input current to the positive prediction error neuron (see section Neuronal dynamics below for <inline-formula><mml:math id="inf111"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>r</mml:mi><mml:mrow><mml:mi>x</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula> and for the negative prediction error neuron, and <xref ref-type="table" rid="table1">Table 1</xref> for <inline-formula><mml:math id="inf112"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>w</mml:mi><mml:mrow><mml:mi>x</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula>). The nonlinearity in the dendrite is determined by the exponent <inline-formula><mml:math id="inf113"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:mstyle></mml:math></inline-formula>, which is by default <inline-formula><mml:math id="inf114"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>k</mml:mi><mml:mo>=</mml:mo><mml:mn>2</mml:mn></mml:mrow></mml:mstyle></mml:math></inline-formula>, unless otherwise specified as in <xref ref-type="fig" rid="fig4">Figure 4G–J</xref>. <inline-formula><mml:math id="inf115"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>I</mml:mi><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msub><mml:mo>&gt;</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:mstyle></mml:math></inline-formula> is a constant ensuring that the divisive inhibition does not become excitatory, when <inline-formula><mml:math id="inf116"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>σ</mml:mi><mml:mo>&lt;</mml:mo><mml:mn>1.0</mml:mn></mml:mrow></mml:mstyle></mml:math></inline-formula>. All firing rates are rectified to ensure that they remain positive.</p><table-wrap id="table1" position="float"><label>Table 1.</label><caption><title>Parameters of the network.</title></caption><table frame="hsides" rules="groups"><thead><tr><th align="left" valign="bottom">Parameter</th><th align="left" valign="bottom">Value</th><th align="left" valign="bottom">Description</th></tr></thead><tbody><tr><td align="left" valign="bottom"><inline-formula><mml:math id="inf117"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>w</mml:mi><mml:mrow><mml:msup><mml:mrow><mml:mi mathvariant="normal">P</mml:mi><mml:mi mathvariant="normal">V</mml:mi></mml:mrow><mml:mrow><mml:mo>+</mml:mo></mml:mrow></mml:msup><mml:mo>,</mml:mo><mml:msup><mml:mrow><mml:mi mathvariant="normal">S</mml:mi><mml:mi mathvariant="normal">S</mml:mi><mml:mi mathvariant="normal">T</mml:mi></mml:mrow><mml:mrow><mml:mo>+</mml:mo></mml:mrow></mml:msup></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula></td><td align="left" valign="bottom"><inline-formula><mml:math id="inf118"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msqrt><mml:mfrac><mml:mrow><mml:mn>2</mml:mn><mml:mo>−</mml:mo><mml:mi>β</mml:mi></mml:mrow><mml:mi>β</mml:mi></mml:mfrac></mml:msqrt></mml:mrow></mml:mstyle></mml:math></inline-formula><break/><break/></td><td align="left" valign="bottom">Weight from <inline-formula><mml:math id="inf119"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msup><mml:mrow><mml:mrow><mml:mi mathvariant="normal">S</mml:mi><mml:mi mathvariant="normal">S</mml:mi><mml:mi mathvariant="normal">T</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:mo>+</mml:mo></mml:mrow></mml:msup></mml:mrow></mml:mstyle></mml:math></inline-formula> to <inline-formula><mml:math id="inf120"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msup><mml:mrow><mml:mi mathvariant="normal">P</mml:mi><mml:mi mathvariant="normal">V</mml:mi></mml:mrow><mml:mrow><mml:mo>+</mml:mo></mml:mrow></mml:msup></mml:mrow></mml:mstyle></mml:math></inline-formula></td></tr><tr><td align="left" valign="bottom"><inline-formula><mml:math id="inf121"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>w</mml:mi><mml:mrow><mml:msup><mml:mrow><mml:mi mathvariant="normal">P</mml:mi><mml:mi mathvariant="normal">V</mml:mi></mml:mrow><mml:mrow><mml:mo>+</mml:mo></mml:mrow></mml:msup><mml:mo>,</mml:mo><mml:mrow><mml:mi mathvariant="normal">s</mml:mi></mml:mrow></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula></td><td align="left" valign="bottom"><inline-formula><mml:math id="inf122"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msqrt><mml:mfrac><mml:mrow><mml:mn>2</mml:mn><mml:mo>−</mml:mo><mml:mi>β</mml:mi></mml:mrow><mml:mi>β</mml:mi></mml:mfrac></mml:msqrt></mml:mrow></mml:mstyle></mml:math></inline-formula><break/><break/></td><td align="left" valign="bottom">Weight from <inline-formula><mml:math id="inf123"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mrow><mml:mi mathvariant="normal">s</mml:mi></mml:mrow></mml:mrow></mml:mstyle></mml:math></inline-formula> to <inline-formula><mml:math id="inf124"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msup><mml:mrow><mml:mi mathvariant="normal">P</mml:mi><mml:mi mathvariant="normal">V</mml:mi></mml:mrow><mml:mrow><mml:mo>+</mml:mo></mml:mrow></mml:msup></mml:mrow></mml:mstyle></mml:math></inline-formula></td></tr><tr><td align="left" valign="bottom"><inline-formula><mml:math id="inf125"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>w</mml:mi><mml:mrow><mml:msup><mml:mrow><mml:mi mathvariant="normal">P</mml:mi><mml:mi mathvariant="normal">V</mml:mi></mml:mrow><mml:mrow><mml:mo>−</mml:mo></mml:mrow></mml:msup><mml:mo>,</mml:mo><mml:msup><mml:mrow><mml:mi mathvariant="normal">S</mml:mi><mml:mi mathvariant="normal">S</mml:mi><mml:mi mathvariant="normal">T</mml:mi></mml:mrow><mml:mrow><mml:mo>−</mml:mo></mml:mrow></mml:msup></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula></td><td align="left" valign="bottom"><inline-formula><mml:math id="inf126"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msqrt><mml:mfrac><mml:mrow><mml:mn>2</mml:mn><mml:mo>−</mml:mo><mml:mi>β</mml:mi></mml:mrow><mml:mi>β</mml:mi></mml:mfrac></mml:msqrt></mml:mrow></mml:mstyle></mml:math></inline-formula><break/><break/></td><td align="left" valign="bottom">Weight from <inline-formula><mml:math id="inf127"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msup><mml:mrow><mml:mi mathvariant="normal">S</mml:mi><mml:mi mathvariant="normal">S</mml:mi><mml:mi mathvariant="normal">T</mml:mi></mml:mrow><mml:mrow><mml:mo>−</mml:mo></mml:mrow></mml:msup></mml:mrow></mml:mstyle></mml:math></inline-formula> to <inline-formula><mml:math id="inf128"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msup><mml:mrow><mml:mi mathvariant="normal">P</mml:mi><mml:mi mathvariant="normal">V</mml:mi></mml:mrow><mml:mrow><mml:mo>−</mml:mo></mml:mrow></mml:msup></mml:mrow></mml:mstyle></mml:math></inline-formula></td></tr><tr><td align="left" valign="bottom"><inline-formula><mml:math id="inf129"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>w</mml:mi><mml:mrow><mml:msup><mml:mrow><mml:mi mathvariant="normal">P</mml:mi><mml:mi mathvariant="normal">V</mml:mi></mml:mrow><mml:mrow><mml:mo>−</mml:mo></mml:mrow></mml:msup><mml:mo>,</mml:mo><mml:mrow><mml:mi mathvariant="normal">R</mml:mi></mml:mrow></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula></td><td align="left" valign="bottom"><inline-formula><mml:math id="inf130"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msqrt><mml:mfrac><mml:mrow><mml:mn>2</mml:mn><mml:mo>−</mml:mo><mml:mi>β</mml:mi></mml:mrow><mml:mi>β</mml:mi></mml:mfrac></mml:msqrt></mml:mrow></mml:mstyle></mml:math></inline-formula><break/><break/></td><td align="left" valign="bottom">Weight from <inline-formula><mml:math id="inf131"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mrow><mml:mi mathvariant="normal">R</mml:mi></mml:mrow></mml:mrow></mml:mstyle></mml:math></inline-formula> to <inline-formula><mml:math id="inf132"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msup><mml:mrow><mml:mi mathvariant="normal">P</mml:mi><mml:mi mathvariant="normal">V</mml:mi></mml:mrow><mml:mrow><mml:mo>−</mml:mo></mml:mrow></mml:msup></mml:mrow></mml:mstyle></mml:math></inline-formula></td></tr><tr><td align="left" valign="bottom"><inline-formula><mml:math id="inf133"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>w</mml:mi><mml:mrow><mml:msup><mml:mrow><mml:mi mathvariant="normal">S</mml:mi><mml:mi mathvariant="normal">S</mml:mi><mml:mi mathvariant="normal">T</mml:mi></mml:mrow><mml:mrow><mml:mo>+</mml:mo></mml:mrow></mml:msup><mml:mo>,</mml:mo><mml:mrow><mml:mi mathvariant="normal">R</mml:mi></mml:mrow></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula></td><td align="left" valign="bottom">1.0</td><td align="left" valign="bottom">Weight from <inline-formula><mml:math id="inf134"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mrow><mml:mi mathvariant="normal">R</mml:mi></mml:mrow></mml:mrow></mml:mstyle></mml:math></inline-formula> to <inline-formula><mml:math id="inf135"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msup><mml:mrow><mml:mi mathvariant="normal">S</mml:mi><mml:mi mathvariant="normal">S</mml:mi><mml:mi mathvariant="normal">T</mml:mi></mml:mrow><mml:mrow><mml:mo>+</mml:mo></mml:mrow></mml:msup></mml:mrow></mml:mstyle></mml:math></inline-formula></td></tr><tr><td align="left" valign="bottom"><inline-formula><mml:math id="inf136"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>w</mml:mi><mml:mrow><mml:msup><mml:mrow><mml:mi mathvariant="normal">S</mml:mi><mml:mi mathvariant="normal">S</mml:mi><mml:mi mathvariant="normal">T</mml:mi></mml:mrow><mml:mrow><mml:mo>−</mml:mo></mml:mrow></mml:msup><mml:mo>,</mml:mo><mml:mrow><mml:mi mathvariant="normal">s</mml:mi></mml:mrow></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula></td><td align="left" valign="bottom">1.0</td><td align="left" valign="bottom">Weight from <inline-formula><mml:math id="inf137"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mrow><mml:mi mathvariant="normal">s</mml:mi></mml:mrow></mml:mrow></mml:mstyle></mml:math></inline-formula> to <inline-formula><mml:math id="inf138"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msup><mml:mtext>SST</mml:mtext><mml:mrow><mml:mo>−</mml:mo></mml:mrow></mml:msup></mml:mrow></mml:mstyle></mml:math></inline-formula></td></tr><tr><td align="left" valign="bottom"><inline-formula><mml:math id="inf139"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>w</mml:mi><mml:mrow><mml:msup><mml:mrow><mml:mi mathvariant="normal">U</mml:mi><mml:mi mathvariant="normal">P</mml:mi><mml:mi mathvariant="normal">E</mml:mi></mml:mrow><mml:mrow><mml:mo>+</mml:mo></mml:mrow></mml:msup><mml:mo>,</mml:mo><mml:msup><mml:mrow><mml:mi mathvariant="normal">S</mml:mi><mml:mi mathvariant="normal">S</mml:mi><mml:mi mathvariant="normal">T</mml:mi></mml:mrow><mml:mrow><mml:mo>+</mml:mo></mml:mrow></mml:msup></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula></td><td align="left" valign="bottom">1.0</td><td align="left" valign="bottom">Weight from <inline-formula><mml:math id="inf140"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msup><mml:mtext>SST</mml:mtext><mml:mrow><mml:mo>+</mml:mo></mml:mrow></mml:msup></mml:mrow></mml:mstyle></mml:math></inline-formula> to <inline-formula><mml:math id="inf141"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msup><mml:mtext>UPE</mml:mtext><mml:mrow><mml:mo>+</mml:mo></mml:mrow></mml:msup></mml:mrow></mml:mstyle></mml:math></inline-formula></td></tr><tr><td align="left" valign="bottom"><inline-formula><mml:math id="inf142"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>w</mml:mi><mml:mrow><mml:msup><mml:mrow><mml:mi mathvariant="normal">U</mml:mi><mml:mi mathvariant="normal">P</mml:mi><mml:mi mathvariant="normal">E</mml:mi></mml:mrow><mml:mrow><mml:mo>+</mml:mo></mml:mrow></mml:msup><mml:mo>,</mml:mo><mml:mrow><mml:mi mathvariant="normal">s</mml:mi></mml:mrow></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula></td><td align="left" valign="bottom">1.0</td><td align="left" valign="bottom">Weight from <inline-formula><mml:math id="inf143"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mrow><mml:mi mathvariant="normal">s</mml:mi></mml:mrow></mml:mrow></mml:mstyle></mml:math></inline-formula> to <inline-formula><mml:math id="inf144"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msup><mml:mtext>UPE</mml:mtext><mml:mrow><mml:mo>+</mml:mo></mml:mrow></mml:msup></mml:mrow></mml:mstyle></mml:math></inline-formula></td></tr><tr><td align="left" valign="bottom"><inline-formula><mml:math id="inf145"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>w</mml:mi><mml:mrow><mml:msup><mml:mrow><mml:mi mathvariant="normal">U</mml:mi><mml:mi mathvariant="normal">P</mml:mi><mml:mi mathvariant="normal">E</mml:mi></mml:mrow><mml:mrow><mml:mo>−</mml:mo></mml:mrow></mml:msup><mml:mo>,</mml:mo><mml:mrow><mml:mi mathvariant="normal">R</mml:mi></mml:mrow></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula></td><td align="left" valign="bottom">1.0</td><td align="left" valign="bottom">Weight from <inline-formula><mml:math id="inf146"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mrow><mml:mi mathvariant="normal">R</mml:mi></mml:mrow></mml:mrow></mml:mstyle></mml:math></inline-formula> to <inline-formula><mml:math id="inf147"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msup><mml:mrow><mml:mi mathvariant="normal">U</mml:mi><mml:mi mathvariant="normal">P</mml:mi><mml:mi mathvariant="normal">E</mml:mi></mml:mrow><mml:mrow><mml:mo>−</mml:mo></mml:mrow></mml:msup></mml:mrow></mml:mstyle></mml:math></inline-formula></td></tr><tr><td align="left" valign="bottom"><inline-formula><mml:math id="inf148"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>w</mml:mi><mml:mrow><mml:msup><mml:mrow><mml:mi mathvariant="normal">U</mml:mi><mml:mi mathvariant="normal">P</mml:mi><mml:mi mathvariant="normal">E</mml:mi></mml:mrow><mml:mrow><mml:mo>−</mml:mo></mml:mrow></mml:msup><mml:mo>,</mml:mo><mml:msup><mml:mrow><mml:mi mathvariant="normal">S</mml:mi><mml:mi mathvariant="normal">S</mml:mi><mml:mi mathvariant="normal">T</mml:mi></mml:mrow><mml:mrow><mml:mo>−</mml:mo></mml:mrow></mml:msup></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula></td><td align="left" valign="bottom">1.0</td><td align="left" valign="bottom">Weight from <inline-formula><mml:math id="inf149"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msup><mml:mtext>SST</mml:mtext><mml:mrow><mml:mo>−</mml:mo></mml:mrow></mml:msup></mml:mrow></mml:mstyle></mml:math></inline-formula> to <inline-formula><mml:math id="inf150"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msup><mml:mrow><mml:mi mathvariant="normal">U</mml:mi><mml:mi mathvariant="normal">P</mml:mi><mml:mi mathvariant="normal">E</mml:mi></mml:mrow><mml:mrow><mml:mo>−</mml:mo></mml:mrow></mml:msup></mml:mrow></mml:mstyle></mml:math></inline-formula></td></tr><tr><td align="left" valign="bottom"><inline-formula><mml:math id="inf151"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>w</mml:mi><mml:mrow><mml:mrow><mml:mi mathvariant="normal">R</mml:mi></mml:mrow><mml:mo>,</mml:mo><mml:msup><mml:mrow><mml:mi mathvariant="normal">U</mml:mi><mml:mi mathvariant="normal">P</mml:mi><mml:mi mathvariant="normal">E</mml:mi></mml:mrow><mml:mrow><mml:mo>+</mml:mo></mml:mrow></mml:msup></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula></td><td align="left" valign="bottom">0.1(1.0)</td><td align="left" valign="bottom">Weight from <inline-formula><mml:math id="inf152"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msup><mml:mrow><mml:mi mathvariant="normal">U</mml:mi><mml:mi mathvariant="normal">P</mml:mi><mml:mi mathvariant="normal">E</mml:mi></mml:mrow><mml:mrow><mml:mo>+</mml:mo></mml:mrow></mml:msup></mml:mrow></mml:mstyle></mml:math></inline-formula> to <inline-formula><mml:math id="inf153"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mrow><mml:mi mathvariant="normal">R</mml:mi></mml:mrow></mml:mrow></mml:mstyle></mml:math></inline-formula> (<xref ref-type="fig" rid="fig6">Figure 6</xref>)</td></tr><tr><td align="left" valign="bottom"><inline-formula><mml:math id="inf154"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>w</mml:mi><mml:mrow><mml:mrow><mml:mi mathvariant="normal">R</mml:mi></mml:mrow><mml:mo>,</mml:mo><mml:msup><mml:mrow><mml:mi mathvariant="normal">U</mml:mi><mml:mi mathvariant="normal">P</mml:mi><mml:mi mathvariant="normal">E</mml:mi></mml:mrow><mml:mrow><mml:mo>−</mml:mo></mml:mrow></mml:msup></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula></td><td align="left" valign="bottom">0.1(1.0)</td><td align="left" valign="bottom">Weight from <inline-formula><mml:math id="inf155"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msup><mml:mtext>UPE</mml:mtext><mml:mrow><mml:mo>−</mml:mo></mml:mrow></mml:msup></mml:mrow></mml:mstyle></mml:math></inline-formula> to <inline-formula><mml:math id="inf156"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mrow><mml:mi mathvariant="normal">R</mml:mi></mml:mrow></mml:mrow></mml:mstyle></mml:math></inline-formula> (<xref ref-type="fig" rid="fig6">Figure 6</xref>)</td></tr><tr><td align="left" valign="bottom"><inline-formula><mml:math id="inf157"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>x</mml:mi><mml:mrow><mml:mrow><mml:mi mathvariant="normal">m</mml:mi><mml:mi mathvariant="normal">a</mml:mi><mml:mi mathvariant="normal">x</mml:mi></mml:mrow></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula></td><td align="left" valign="bottom">20</td><td align="left" valign="bottom">Limits neuronal activity</td></tr><tr><td align="left" valign="bottom"><inline-formula><mml:math id="inf158"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>β</mml:mi></mml:mrow></mml:mstyle></mml:math></inline-formula></td><td align="left" valign="bottom">0.1</td><td align="left" valign="bottom">Nudging parameter</td></tr></tbody></table></table-wrap><p>In the positive prediction error circuit, in which the SSTs learn to represent the mean, the SST activity is determined by<disp-formula id="equ16"><label>(9)</label><mml:math id="m16"><mml:mrow><mml:msub><mml:mi>τ</mml:mi><mml:mrow><mml:mrow><mml:mi mathvariant="normal">I</mml:mi></mml:mrow></mml:mrow></mml:msub><mml:mfrac><mml:mrow><mml:mi>d</mml:mi><mml:msub><mml:mi>r</mml:mi><mml:mrow><mml:mrow><mml:mi mathvariant="normal">S</mml:mi><mml:mi mathvariant="normal">S</mml:mi><mml:msup><mml:mi mathvariant="normal">T</mml:mi><mml:mo>+</mml:mo></mml:msup></mml:mrow></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:mi>d</mml:mi><mml:mi>t</mml:mi></mml:mrow></mml:mfrac><mml:mo>=</mml:mo><mml:mo>−</mml:mo><mml:msub><mml:mi>r</mml:mi><mml:mrow><mml:mrow><mml:mi mathvariant="normal">S</mml:mi><mml:mi mathvariant="normal">S</mml:mi><mml:msup><mml:mi mathvariant="normal">T</mml:mi><mml:mo>+</mml:mo></mml:msup></mml:mrow></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:mi>ϕ</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:mi>β</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:msub><mml:mi>w</mml:mi><mml:mrow><mml:mrow><mml:mi mathvariant="normal">S</mml:mi><mml:mi mathvariant="normal">S</mml:mi><mml:msup><mml:mi mathvariant="normal">T</mml:mi><mml:mo>+</mml:mo></mml:msup></mml:mrow><mml:mo>,</mml:mo><mml:mtext>a</mml:mtext></mml:mrow></mml:msub><mml:mspace width="thickmathspace"/><mml:msub><mml:mi>r</mml:mi><mml:mtext>a</mml:mtext></mml:msub><mml:mo>+</mml:mo><mml:mi>β</mml:mi><mml:mi>s</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>.</mml:mo></mml:mrow></mml:math></disp-formula></p><p>The SST activity is influenced (nudged with a factor <inline-formula><mml:math id="inf159"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>β</mml:mi></mml:mrow></mml:mstyle></mml:math></inline-formula>) by the somatosensory stimuli <inline-formula><mml:math id="inf160"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>s</mml:mi></mml:mrow></mml:mstyle></mml:math></inline-formula>, which provide targets for the desired SST activity. The connection weight from the sound representation to the SSTs <inline-formula><mml:math id="inf161"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>w</mml:mi><mml:mrow><mml:mrow><mml:mi mathvariant="normal">S</mml:mi><mml:mi mathvariant="normal">S</mml:mi><mml:mi mathvariant="normal">T</mml:mi></mml:mrow><mml:mo>,</mml:mo><mml:mtext>a</mml:mtext></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula> is plastic according to the following local activity-dependent plasticity rule (<xref ref-type="bibr" rid="bib75">Urbanczik and Senn, 2014</xref>):<disp-formula id="equ17"><label>(10)</label><mml:math id="m17"><mml:mrow><mml:mi mathvariant="normal">Δ</mml:mi><mml:msub><mml:mi>w</mml:mi><mml:mrow><mml:mrow><mml:mi mathvariant="normal">S</mml:mi><mml:mi mathvariant="normal">S</mml:mi><mml:mi mathvariant="normal">T</mml:mi></mml:mrow><mml:mo>,</mml:mo><mml:mtext>a</mml:mtext></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mi>η</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>r</mml:mi><mml:mrow><mml:mrow><mml:mi mathvariant="normal">S</mml:mi><mml:mi mathvariant="normal">S</mml:mi><mml:mi mathvariant="normal">T</mml:mi></mml:mrow></mml:mrow></mml:msub><mml:mo>−</mml:mo><mml:mi>ϕ</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>w</mml:mi><mml:mrow><mml:mrow><mml:mi mathvariant="normal">S</mml:mi><mml:mi mathvariant="normal">S</mml:mi><mml:mi mathvariant="normal">T</mml:mi></mml:mrow><mml:mo>,</mml:mo><mml:mtext>a</mml:mtext></mml:mrow></mml:msub><mml:mspace width="thickmathspace"/><mml:msub><mml:mi>r</mml:mi><mml:mtext>a</mml:mtext></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:mo stretchy="false">)</mml:mo><mml:mspace width="thickmathspace"/><mml:msub><mml:mi>r</mml:mi><mml:mtext>a</mml:mtext></mml:msub><mml:mo>,</mml:mo></mml:mrow></mml:math></disp-formula></p><p>where <inline-formula><mml:math id="inf162"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>η</mml:mi></mml:mrow></mml:mstyle></mml:math></inline-formula> is the learning rate, <inline-formula><mml:math id="inf163"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>r</mml:mi><mml:mrow><mml:mtext>a</mml:mtext></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula> is the pre-synaptic firing rate, <inline-formula><mml:math id="inf164"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>r</mml:mi><mml:mrow><mml:mrow><mml:mi mathvariant="normal">S</mml:mi><mml:mi mathvariant="normal">S</mml:mi><mml:mi mathvariant="normal">T</mml:mi></mml:mrow></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula> is the post-synaptic firing rate of the SSTs, <inline-formula><mml:math id="inf165"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>ϕ</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>x</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mstyle></mml:math></inline-formula> is a rectified linear activation function of the SSTs.</p><p>The learning rule ensures that the auditory input alone causes SSTs to fire at their target activity. As in the original proposal (<xref ref-type="bibr" rid="bib75">Urbanczik and Senn, 2014</xref>), the terms in the learning rule can be mapped to local neuronal variables, which could be represented by dendritic (<inline-formula><mml:math id="inf166"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>w</mml:mi><mml:mrow><mml:mrow><mml:mi mathvariant="normal">S</mml:mi><mml:mi mathvariant="normal">S</mml:mi><mml:mi mathvariant="normal">T</mml:mi></mml:mrow><mml:mo>,</mml:mo><mml:mtext>a</mml:mtext></mml:mrow></mml:msub><mml:mspace width="thickmathspace"/><mml:msub><mml:mi>r</mml:mi><mml:mrow><mml:mtext>a</mml:mtext></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula>) and somatic (<inline-formula><mml:math id="inf167"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>r</mml:mi><mml:mrow><mml:mrow><mml:mi mathvariant="normal">S</mml:mi><mml:mi mathvariant="normal">S</mml:mi><mml:mi mathvariant="normal">T</mml:mi></mml:mrow></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula>) activity.</p><p>The PV firing rate is determined by the input from the sound representation (<inline-formula><mml:math id="inf168"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>w</mml:mi><mml:mrow><mml:msup><mml:mrow><mml:mi mathvariant="normal">P</mml:mi><mml:mi mathvariant="normal">V</mml:mi></mml:mrow><mml:mrow><mml:mo>+</mml:mo></mml:mrow></mml:msup><mml:mo>,</mml:mo><mml:mtext>a</mml:mtext></mml:mrow></mml:msub><mml:mspace width="thickmathspace"/><mml:msub><mml:mi>r</mml:mi><mml:mrow><mml:mtext>a</mml:mtext></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula>) and the whisker stimuli, from which their mean is subtracted (<inline-formula><mml:math id="inf169"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>w</mml:mi><mml:mrow><mml:msup><mml:mrow><mml:mi mathvariant="normal">P</mml:mi><mml:mi mathvariant="normal">V</mml:mi></mml:mrow><mml:mrow><mml:mo>+</mml:mo></mml:mrow></mml:msup><mml:mo>,</mml:mo><mml:mrow><mml:mi mathvariant="normal">s</mml:mi></mml:mrow></mml:mrow></mml:msub><mml:mspace width="thickmathspace"/><mml:mrow><mml:mi mathvariant="normal">s</mml:mi></mml:mrow><mml:mo>−</mml:mo><mml:msub><mml:mi>w</mml:mi><mml:mrow><mml:msup><mml:mrow><mml:mi mathvariant="normal">P</mml:mi><mml:mi mathvariant="normal">V</mml:mi></mml:mrow><mml:mrow><mml:mo>+</mml:mo></mml:mrow></mml:msup><mml:mo>,</mml:mo><mml:msup><mml:mrow><mml:mi mathvariant="normal">S</mml:mi><mml:mi mathvariant="normal">S</mml:mi><mml:mi mathvariant="normal">T</mml:mi></mml:mrow><mml:mrow><mml:mo>+</mml:mo></mml:mrow></mml:msup></mml:mrow></mml:msub><mml:mspace width="thickmathspace"/><mml:msub><mml:mi>r</mml:mi><mml:mrow><mml:msup><mml:mrow><mml:mi mathvariant="normal">S</mml:mi><mml:mi mathvariant="normal">S</mml:mi><mml:mi mathvariant="normal">T</mml:mi></mml:mrow><mml:mrow><mml:mo>+</mml:mo></mml:mrow></mml:msup></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula>, where the mean is given by <inline-formula><mml:math id="inf170"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>r</mml:mi><mml:mrow><mml:msup><mml:mrow><mml:mi mathvariant="normal">S</mml:mi><mml:mi mathvariant="normal">S</mml:mi><mml:mi mathvariant="normal">T</mml:mi></mml:mrow><mml:mrow><mml:mo>+</mml:mo></mml:mrow></mml:msup></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula>). The mean-subtracted whisker stimuli serve as a target for learning the weight from the sound representation to the PV <inline-formula><mml:math id="inf171"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>η</mml:mi></mml:mrow></mml:mstyle></mml:math></inline-formula>. The PV firing rate evoles over time according to:<disp-formula id="equ18"><label>(11)</label><mml:math id="m18"><mml:mrow><mml:msub><mml:mi>τ</mml:mi><mml:mrow><mml:mrow><mml:mi mathvariant="normal">I</mml:mi></mml:mrow></mml:mrow></mml:msub><mml:mfrac><mml:mrow><mml:mi>d</mml:mi><mml:msub><mml:mi>r</mml:mi><mml:mrow><mml:mrow><mml:mi mathvariant="normal">P</mml:mi><mml:msup><mml:mi mathvariant="normal">V</mml:mi><mml:mo>+</mml:mo></mml:msup></mml:mrow></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:mi>d</mml:mi><mml:mi>t</mml:mi></mml:mrow></mml:mfrac><mml:mo>=</mml:mo><mml:mo>−</mml:mo><mml:msub><mml:mi>r</mml:mi><mml:mrow><mml:mrow><mml:mi mathvariant="normal">P</mml:mi><mml:msup><mml:mi mathvariant="normal">V</mml:mi><mml:mo>+</mml:mo></mml:msup></mml:mrow></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mi>ϕ</mml:mi><mml:mrow><mml:mrow><mml:mi mathvariant="normal">P</mml:mi><mml:mi mathvariant="normal">V</mml:mi></mml:mrow></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:mi>β</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:msub><mml:mi>w</mml:mi><mml:mrow><mml:mrow><mml:mi mathvariant="normal">P</mml:mi><mml:msup><mml:mi mathvariant="normal">V</mml:mi><mml:mo>+</mml:mo></mml:msup></mml:mrow><mml:mo>,</mml:mo><mml:mtext>a</mml:mtext></mml:mrow></mml:msub><mml:mspace width="thickmathspace"/><mml:msub><mml:mi>r</mml:mi><mml:mtext>a</mml:mtext></mml:msub><mml:mo>+</mml:mo><mml:mi>β</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>w</mml:mi><mml:mrow><mml:mrow><mml:mi mathvariant="normal">P</mml:mi><mml:msup><mml:mi mathvariant="normal">V</mml:mi><mml:mo>+</mml:mo></mml:msup></mml:mrow><mml:mo>,</mml:mo><mml:mrow><mml:mi mathvariant="normal">s</mml:mi></mml:mrow></mml:mrow></mml:msub><mml:mspace width="thickmathspace"/><mml:mrow><mml:mi mathvariant="normal">s</mml:mi></mml:mrow><mml:mo>−</mml:mo><mml:msub><mml:mi>w</mml:mi><mml:mrow><mml:mrow><mml:mi mathvariant="normal">P</mml:mi><mml:msup><mml:mi mathvariant="normal">V</mml:mi><mml:mo>+</mml:mo></mml:msup></mml:mrow><mml:mo>,</mml:mo><mml:mrow><mml:mi mathvariant="normal">S</mml:mi><mml:mi mathvariant="normal">S</mml:mi><mml:msup><mml:mi mathvariant="normal">T</mml:mi><mml:mo>+</mml:mo></mml:msup></mml:mrow></mml:mrow></mml:msub><mml:mspace width="thickmathspace"/><mml:msub><mml:mi>r</mml:mi><mml:mrow><mml:mrow><mml:mi mathvariant="normal">S</mml:mi><mml:mi mathvariant="normal">S</mml:mi><mml:msup><mml:mi mathvariant="normal">T</mml:mi><mml:mo>+</mml:mo></mml:msup></mml:mrow></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:mo stretchy="false">)</mml:mo><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></disp-formula></p><p>where <inline-formula><mml:math id="inf172"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>ϕ</mml:mi><mml:mrow><mml:mrow><mml:mi mathvariant="normal">P</mml:mi><mml:mi mathvariant="normal">V</mml:mi></mml:mrow></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>x</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mstyle></mml:math></inline-formula> is a rectified quadratic activation function, defined as follows:<disp-formula id="equ19"><label>(12)</label><mml:math id="m19"><mml:mrow><mml:msub><mml:mi>ϕ</mml:mi><mml:mrow><mml:mrow><mml:mi mathvariant="normal">P</mml:mi><mml:mi mathvariant="normal">V</mml:mi></mml:mrow></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>x</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mrow><mml:mo>{</mml:mo><mml:mtable columnalign="left left" rowspacing=".2em" columnspacing="1em" displaystyle="false"><mml:mtr><mml:mtd><mml:mn>0</mml:mn></mml:mtd><mml:mtd><mml:mrow><mml:mtext>if </mml:mtext><mml:mrow><mml:mi>x</mml:mi><mml:mo>≤</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:mrow></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:msup><mml:mi>x</mml:mi><mml:mn>2</mml:mn></mml:msup></mml:mtd><mml:mtd><mml:mrow><mml:mtext>if </mml:mtext><mml:mrow><mml:mn>0</mml:mn><mml:mo>&lt;</mml:mo><mml:mi>x</mml:mi><mml:mo>&lt;</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mrow><mml:mo movablelimits="true" form="prefix">max</mml:mo></mml:mrow></mml:msub></mml:mrow></mml:mrow></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:msub><mml:mi>r</mml:mi><mml:mrow><mml:mo movablelimits="true" form="prefix">max</mml:mo></mml:mrow></mml:msub></mml:mtd><mml:mtd><mml:mrow><mml:mtext>if </mml:mtext><mml:mrow><mml:mi>x</mml:mi><mml:mo>≥</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mrow><mml:mo movablelimits="true" form="prefix">max</mml:mo></mml:mrow></mml:msub></mml:mrow></mml:mrow><mml:mo>.</mml:mo></mml:mtd></mml:mtr></mml:mtable><mml:mo fence="true" stretchy="true" symmetric="true"/></mml:mrow></mml:mrow></mml:math></disp-formula></p><p>The connection weight from the sound representation to the PVs <inline-formula><mml:math id="inf173"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>w</mml:mi><mml:mrow><mml:mrow><mml:mi mathvariant="normal">P</mml:mi><mml:mi mathvariant="normal">V</mml:mi></mml:mrow><mml:mo>,</mml:mo><mml:mtext>a</mml:mtext></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula> is plastic according to the same local activity-dependent plasticity rule as the SSTs (<xref ref-type="bibr" rid="bib75">Urbanczik and Senn, 2014</xref>):<disp-formula id="equ20"><label>(13)</label><mml:math id="m20"><mml:mrow><mml:msub><mml:mi>w</mml:mi><mml:mrow><mml:mi mathvariant="normal">P</mml:mi><mml:mi mathvariant="normal">V</mml:mi><mml:mo>,</mml:mo><mml:mrow><mml:mi mathvariant="normal">a</mml:mi></mml:mrow></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mi>η</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>r</mml:mi><mml:mrow><mml:mi mathvariant="normal">P</mml:mi><mml:mi mathvariant="normal">V</mml:mi></mml:mrow></mml:msub><mml:mo>−</mml:mo><mml:msub><mml:mi>ϕ</mml:mi><mml:mrow><mml:mrow><mml:mi mathvariant="normal">P</mml:mi><mml:mi mathvariant="normal">V</mml:mi></mml:mrow></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>w</mml:mi><mml:mrow><mml:mrow><mml:mi mathvariant="normal">P</mml:mi><mml:mi mathvariant="normal">V</mml:mi></mml:mrow><mml:mo>,</mml:mo><mml:mrow><mml:mi>a</mml:mi></mml:mrow></mml:mrow></mml:msub><mml:mspace width="thickmathspace"/><mml:msub><mml:mi>r</mml:mi><mml:mrow><mml:mi>a</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:mo stretchy="false">)</mml:mo><mml:mspace width="thickmathspace"/><mml:msub><mml:mi>r</mml:mi><mml:mrow><mml:mi>a</mml:mi></mml:mrow></mml:msub><mml:mo>.</mml:mo></mml:mrow></mml:math></disp-formula></p><p>The weight from the sound representation to the PV <inline-formula><mml:math id="inf174"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>w</mml:mi><mml:mrow><mml:msup><mml:mrow><mml:mi mathvariant="normal">P</mml:mi><mml:mi mathvariant="normal">V</mml:mi></mml:mrow><mml:mrow><mml:mo>+</mml:mo></mml:mrow></mml:msup><mml:mo>,</mml:mo><mml:mtext>a</mml:mtext></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula> approaches <inline-formula><mml:math id="inf175"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>σ</mml:mi></mml:mrow></mml:mstyle></mml:math></inline-formula> (instead of μ as the weight to the SSTs), because the PV activity is a function of the mean-subtracted whisker stimuli (instead of the whisker stimuli as the SST activity), and for a Gaussian-distributed stimulus <inline-formula><mml:math id="inf176"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>s</mml:mi><mml:mo>∼</mml:mo><mml:mrow><mml:mi class="mathcal" mathvariant="script">N</mml:mi></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>s</mml:mi><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mi>μ</mml:mi><mml:mo>,</mml:mo><mml:mi>σ</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mstyle></mml:math></inline-formula>, it holds that <inline-formula><mml:math id="inf177"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mrow><mml:mi mathvariant="double-struck">E</mml:mi></mml:mrow><mml:mrow><mml:mo>[</mml:mo><mml:mrow><mml:mo fence="false" stretchy="false">⌊</mml:mo><mml:mi>s</mml:mi><mml:mo>−</mml:mo><mml:mi>μ</mml:mi><mml:msup><mml:mo fence="false" stretchy="false">⌋</mml:mo><mml:mrow><mml:mo>+</mml:mo></mml:mrow></mml:msup></mml:mrow><mml:mo>]</mml:mo></mml:mrow><mml:mo>∝</mml:mo><mml:mi>σ</mml:mi></mml:mrow></mml:mstyle></mml:math></inline-formula>.</p></sec></sec><sec id="s4-3"><title>Recurrent circuit model</title><p>In the recurrent circuit, shown in <xref ref-type="fig" rid="fig5">Figure 5</xref>, we added an internal representation neuron to the circuit with firing rate <inline-formula><mml:math id="inf178"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>r</mml:mi><mml:mrow><mml:mrow><mml:mi mathvariant="normal">R</mml:mi></mml:mrow></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula>. In this circuit, the SSTs in the positive PE circuit inherit the mean representation from the representation neuron instead of learning it themselves, that is why they receive an input <inline-formula><mml:math id="inf179"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>w</mml:mi><mml:mrow><mml:msup><mml:mrow><mml:mi mathvariant="normal">P</mml:mi><mml:mi mathvariant="normal">V</mml:mi></mml:mrow><mml:mrow><mml:mo>+</mml:mo></mml:mrow></mml:msup><mml:mo>,</mml:mo><mml:mtext>a</mml:mtext></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula>. The SSTs in the negative circuit inherit the stimulus representation and hence receive an input <inline-formula><mml:math id="inf180"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>w</mml:mi><mml:mrow><mml:msup><mml:mrow><mml:mi mathvariant="normal">S</mml:mi><mml:mi mathvariant="normal">S</mml:mi><mml:mi mathvariant="normal">T</mml:mi></mml:mrow><mml:mrow><mml:mo>−</mml:mo></mml:mrow></mml:msup><mml:mo>,</mml:mo><mml:mrow><mml:mi mathvariant="normal">s</mml:mi></mml:mrow></mml:mrow></mml:msub><mml:mspace width="thickmathspace"/><mml:mrow><mml:mi mathvariant="normal">s</mml:mi></mml:mrow></mml:mrow></mml:mstyle></mml:math></inline-formula> In this recurrent circuit, the firing rate of each population <inline-formula><mml:math id="inf181"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>r</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula> where <inline-formula><mml:math id="inf182"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>i</mml:mi><mml:mo>∈</mml:mo><mml:mo stretchy="false">[</mml:mo><mml:msup><mml:mrow><mml:mi mathvariant="normal">S</mml:mi><mml:mi mathvariant="normal">S</mml:mi><mml:mi mathvariant="normal">T</mml:mi></mml:mrow><mml:mrow><mml:mo>+</mml:mo></mml:mrow></mml:msup><mml:mo>,</mml:mo><mml:msup><mml:mrow><mml:mi mathvariant="normal">S</mml:mi><mml:mi mathvariant="normal">S</mml:mi><mml:mi mathvariant="normal">T</mml:mi></mml:mrow><mml:mrow><mml:mo>−</mml:mo></mml:mrow></mml:msup><mml:mo>,</mml:mo><mml:msup><mml:mrow><mml:mi mathvariant="normal">P</mml:mi><mml:mi mathvariant="normal">V</mml:mi></mml:mrow><mml:mrow><mml:mo>+</mml:mo></mml:mrow></mml:msup><mml:mo>,</mml:mo><mml:msup><mml:mrow><mml:mi mathvariant="normal">P</mml:mi><mml:mi mathvariant="normal">V</mml:mi></mml:mrow><mml:mrow><mml:mo>−</mml:mo></mml:mrow></mml:msup><mml:mo>,</mml:mo><mml:msup><mml:mrow><mml:mi mathvariant="normal">U</mml:mi><mml:mi mathvariant="normal">P</mml:mi><mml:mi mathvariant="normal">E</mml:mi></mml:mrow><mml:mrow><mml:mo>+</mml:mo></mml:mrow></mml:msup><mml:mo>,</mml:mo><mml:msup><mml:mrow><mml:mi mathvariant="normal">U</mml:mi><mml:mi mathvariant="normal">P</mml:mi><mml:mi mathvariant="normal">E</mml:mi></mml:mrow><mml:mrow><mml:mo>−</mml:mo></mml:mrow></mml:msup><mml:mo>,</mml:mo><mml:mrow><mml:mi mathvariant="normal">R</mml:mi></mml:mrow><mml:mo stretchy="false">]</mml:mo></mml:mrow></mml:mstyle></mml:math></inline-formula> evolves over time according to the following neuronal dynamics. <inline-formula><mml:math id="inf183"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>ϕ</mml:mi></mml:mrow></mml:mstyle></mml:math></inline-formula> denotes a rectified linear activation function with saturation, <inline-formula><mml:math id="inf184"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>ϕ</mml:mi><mml:mrow><mml:mi>P</mml:mi><mml:mi>V</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula> denotes a rectified quadratic activation function with saturation, defined in the section below. All firing rates are rectified to ensure that they remain positive.<disp-formula id="equ21"><label>(14)</label><mml:math id="m21"><mml:mtable rowspacing="3pt" columnspacing="0em 2em 0em 2em 0em 2em 0em 2em 0em 2em 0em" displaystyle="true"><mml:mtr><mml:mtd><mml:msub><mml:mi>τ</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi mathvariant="normal">I</mml:mi></mml:mrow></mml:mrow></mml:msub><mml:mfrac><mml:mrow><mml:mi>d</mml:mi><mml:msub><mml:mi>r</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:msup><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi mathvariant="normal">S</mml:mi><mml:mi mathvariant="normal">S</mml:mi><mml:mi mathvariant="normal">T</mml:mi></mml:mrow><mml:mo>+</mml:mo></mml:msup></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:mi>d</mml:mi><mml:mi>t</mml:mi></mml:mrow></mml:mfrac></mml:mtd><mml:mtd><mml:mi/><mml:mo>=</mml:mo><mml:mo>−</mml:mo><mml:msub><mml:mi>r</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:msup><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi mathvariant="normal">S</mml:mi><mml:mi mathvariant="normal">S</mml:mi><mml:mi mathvariant="normal">T</mml:mi></mml:mrow><mml:mo>+</mml:mo></mml:msup></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:mi>ϕ</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>w</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:msup><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi mathvariant="normal">S</mml:mi><mml:mi mathvariant="normal">S</mml:mi><mml:mi mathvariant="normal">T</mml:mi></mml:mrow><mml:mo>+</mml:mo></mml:msup><mml:mo>,</mml:mo><mml:mtext>R</mml:mtext></mml:mrow></mml:msub><mml:mspace width="thickmathspace"/><mml:msub><mml:mi>r</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi mathvariant="normal">R</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:mo>,</mml:mo></mml:mtd></mml:mtr></mml:mtable></mml:math></disp-formula><disp-formula id="equ22"><label>(15)</label><mml:math id="m22"><mml:mtable rowspacing="3pt" columnspacing="0em 2em 0em 2em 0em 2em 0em 2em 0em 2em 0em" displaystyle="true"><mml:mtr><mml:mtd><mml:msub><mml:mi>τ</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi mathvariant="normal">I</mml:mi></mml:mrow></mml:mrow></mml:msub><mml:mfrac><mml:mrow><mml:mi>d</mml:mi><mml:msub><mml:mi>r</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:msup><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi mathvariant="normal">P</mml:mi><mml:mi mathvariant="normal">V</mml:mi></mml:mrow><mml:mo>+</mml:mo></mml:msup></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:mi>d</mml:mi><mml:mi>t</mml:mi></mml:mrow></mml:mfrac></mml:mtd><mml:mtd><mml:mi/><mml:mo>=</mml:mo><mml:mo>−</mml:mo><mml:msub><mml:mi>r</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:msup><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi mathvariant="normal">P</mml:mi><mml:mi mathvariant="normal">V</mml:mi></mml:mrow><mml:mo>+</mml:mo></mml:msup></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mi>ϕ</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi mathvariant="normal">P</mml:mi><mml:mi mathvariant="normal">V</mml:mi></mml:mrow></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:mi>β</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:msub><mml:mi>w</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:msup><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi mathvariant="normal">P</mml:mi><mml:mi mathvariant="normal">V</mml:mi></mml:mrow><mml:mo>+</mml:mo></mml:msup><mml:mo>,</mml:mo><mml:mtext>a</mml:mtext></mml:mrow></mml:msub><mml:mspace width="mediummathspace"/><mml:msub><mml:mi>r</mml:mi><mml:mtext>a</mml:mtext></mml:msub><mml:mo>+</mml:mo><mml:mi>β</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>w</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:msup><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi mathvariant="normal">P</mml:mi><mml:mi mathvariant="normal">V</mml:mi></mml:mrow><mml:mo>+</mml:mo></mml:msup><mml:mo>,</mml:mo><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi mathvariant="normal">s</mml:mi></mml:mrow></mml:mrow></mml:msub><mml:mspace width="thickmathspace"/><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi mathvariant="normal">s</mml:mi></mml:mrow><mml:mo>−</mml:mo><mml:msub><mml:mi>w</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:msup><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi mathvariant="normal">P</mml:mi><mml:mi mathvariant="normal">V</mml:mi></mml:mrow><mml:mo>+</mml:mo></mml:msup><mml:mo>,</mml:mo><mml:msup><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi mathvariant="normal">S</mml:mi><mml:mi mathvariant="normal">S</mml:mi><mml:mi mathvariant="normal">T</mml:mi></mml:mrow><mml:mo>+</mml:mo></mml:msup></mml:mrow></mml:msub><mml:mspace width="thickmathspace"/><mml:msub><mml:mi>r</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:msup><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi mathvariant="normal">S</mml:mi><mml:mi mathvariant="normal">S</mml:mi><mml:mi mathvariant="normal">T</mml:mi></mml:mrow><mml:mo>+</mml:mo></mml:msup></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:mo stretchy="false">)</mml:mo><mml:mo stretchy="false">)</mml:mo><mml:mo>,</mml:mo></mml:mtd></mml:mtr></mml:mtable></mml:math></disp-formula><disp-formula id="equ23"><label>(16)</label><mml:math id="m23"><mml:mtable rowspacing="3pt" columnspacing="0em 2em 0em 2em 0em 2em 0em 2em 0em 2em 0em" displaystyle="true"><mml:mtr><mml:mtd><mml:msub><mml:mi>τ</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi mathvariant="normal">E</mml:mi></mml:mrow></mml:mrow></mml:msub><mml:mfrac><mml:mrow><mml:mi>d</mml:mi><mml:msub><mml:mi>r</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:msup><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi mathvariant="normal">U</mml:mi><mml:mi mathvariant="normal">P</mml:mi><mml:mi mathvariant="normal">E</mml:mi></mml:mrow><mml:mo>+</mml:mo></mml:msup></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:mi>d</mml:mi><mml:mi>t</mml:mi></mml:mrow></mml:mfrac></mml:mtd><mml:mtd><mml:mi/><mml:mo>=</mml:mo><mml:mo>−</mml:mo><mml:msub><mml:mi>r</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:msup><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi mathvariant="normal">U</mml:mi><mml:mi mathvariant="normal">P</mml:mi><mml:mi mathvariant="normal">E</mml:mi></mml:mrow><mml:mo>+</mml:mo></mml:msup></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:mi>ϕ</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mfrac><mml:mrow><mml:mo fence="false" stretchy="false">⌊</mml:mo><mml:msub><mml:mi>w</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi mathvariant="normal">U</mml:mi><mml:mi mathvariant="normal">P</mml:mi><mml:mi mathvariant="normal">E</mml:mi></mml:mrow><mml:mo>,</mml:mo><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi mathvariant="normal">s</mml:mi></mml:mrow></mml:mrow></mml:msub><mml:mspace width="thickmathspace"/><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi mathvariant="normal">s</mml:mi></mml:mrow><mml:mo>−</mml:mo><mml:msub><mml:mi>w</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi mathvariant="normal">U</mml:mi><mml:mi mathvariant="normal">P</mml:mi><mml:mi mathvariant="normal">E</mml:mi></mml:mrow><mml:mo>,</mml:mo><mml:msup><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi mathvariant="normal">S</mml:mi><mml:mi mathvariant="normal">S</mml:mi><mml:mi mathvariant="normal">T</mml:mi></mml:mrow><mml:mo>+</mml:mo></mml:msup></mml:mrow></mml:msub><mml:mspace width="thickmathspace"/><mml:msub><mml:mi>r</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:msup><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi mathvariant="normal">S</mml:mi><mml:mi mathvariant="normal">S</mml:mi><mml:mi mathvariant="normal">T</mml:mi></mml:mrow><mml:mo>+</mml:mo></mml:msup></mml:mrow></mml:msub><mml:msup><mml:mo fence="false" stretchy="false">⌋</mml:mo><mml:mi>k</mml:mi></mml:msup></mml:mrow><mml:mrow><mml:msub><mml:mi>I</mml:mi><mml:mn>0</mml:mn></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mi>w</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi mathvariant="normal">U</mml:mi><mml:mi mathvariant="normal">P</mml:mi><mml:mi mathvariant="normal">E</mml:mi></mml:mrow><mml:mo>,</mml:mo><mml:msup><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi mathvariant="normal">P</mml:mi><mml:mi mathvariant="normal">V</mml:mi></mml:mrow><mml:mo>+</mml:mo></mml:msup></mml:mrow></mml:msub><mml:mspace width="thickmathspace"/><mml:msub><mml:mi>r</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:msup><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi mathvariant="normal">P</mml:mi><mml:mi mathvariant="normal">V</mml:mi></mml:mrow><mml:mo>+</mml:mo></mml:msup></mml:mrow></mml:msub></mml:mrow></mml:mfrac><mml:mo>)</mml:mo></mml:mrow><mml:mo>,</mml:mo></mml:mtd></mml:mtr></mml:mtable></mml:math></disp-formula><disp-formula id="equ24"><label>(17)</label><mml:math id="m24"><mml:mtable rowspacing="3pt" columnspacing="0em 2em 0em 2em 0em 2em 0em 2em 0em 2em 0em" displaystyle="true"><mml:mtr><mml:mtd><mml:msub><mml:mi>τ</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi mathvariant="normal">I</mml:mi></mml:mrow></mml:mrow></mml:msub><mml:mfrac><mml:mrow><mml:mi>d</mml:mi><mml:msub><mml:mi>r</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:msup><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi mathvariant="normal">S</mml:mi><mml:mi mathvariant="normal">S</mml:mi><mml:mi mathvariant="normal">T</mml:mi></mml:mrow><mml:mo>−</mml:mo></mml:msup></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:mi>d</mml:mi><mml:mi>t</mml:mi></mml:mrow></mml:mfrac></mml:mtd><mml:mtd><mml:mi/><mml:mo>=</mml:mo><mml:mo>−</mml:mo><mml:msub><mml:mi>r</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:msup><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi mathvariant="normal">S</mml:mi><mml:mi mathvariant="normal">S</mml:mi><mml:mi mathvariant="normal">T</mml:mi></mml:mrow><mml:mo>−</mml:mo></mml:msup></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:mi>ϕ</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>w</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:msup><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi mathvariant="normal">S</mml:mi><mml:mi mathvariant="normal">S</mml:mi><mml:mi mathvariant="normal">T</mml:mi></mml:mrow><mml:mo>−</mml:mo></mml:msup><mml:mo>,</mml:mo><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi mathvariant="normal">s</mml:mi></mml:mrow></mml:mrow></mml:msub><mml:mspace width="thickmathspace"/><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi mathvariant="normal">s</mml:mi></mml:mrow><mml:mo stretchy="false">)</mml:mo><mml:mo>,</mml:mo></mml:mtd></mml:mtr></mml:mtable></mml:math></disp-formula><disp-formula id="equ25"><label>(18)</label><mml:math id="m25"><mml:mtable rowspacing="3pt" columnspacing="0em 2em 0em 2em 0em 2em 0em 2em 0em 2em 0em" displaystyle="true"><mml:mtr><mml:mtd><mml:msub><mml:mi>τ</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi mathvariant="normal">I</mml:mi></mml:mrow></mml:mrow></mml:msub><mml:mfrac><mml:mrow><mml:mi>d</mml:mi><mml:msub><mml:mi>r</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:msup><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi mathvariant="normal">P</mml:mi><mml:mi mathvariant="normal">V</mml:mi></mml:mrow><mml:mo>−</mml:mo></mml:msup></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:mi>d</mml:mi><mml:mi>t</mml:mi></mml:mrow></mml:mfrac></mml:mtd><mml:mtd><mml:mi/><mml:mo>=</mml:mo><mml:mo>−</mml:mo><mml:msub><mml:mi>r</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:msup><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi mathvariant="normal">P</mml:mi><mml:mi mathvariant="normal">V</mml:mi></mml:mrow><mml:mo>−</mml:mo></mml:msup></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mi>ϕ</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi mathvariant="normal">P</mml:mi><mml:mi mathvariant="normal">V</mml:mi></mml:mrow></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:mi>β</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:msub><mml:mi>w</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:msup><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi mathvariant="normal">P</mml:mi><mml:mi mathvariant="normal">V</mml:mi></mml:mrow><mml:mo>−</mml:mo></mml:msup><mml:mo>,</mml:mo><mml:mtext>a</mml:mtext></mml:mrow></mml:msub><mml:mspace width="thickmathspace"/><mml:msub><mml:mi>r</mml:mi><mml:mtext>a</mml:mtext></mml:msub><mml:mo>+</mml:mo><mml:mi>β</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>w</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:msup><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi mathvariant="normal">P</mml:mi><mml:mi mathvariant="normal">V</mml:mi></mml:mrow><mml:mo>−</mml:mo></mml:msup><mml:mo>,</mml:mo><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi mathvariant="normal">R</mml:mi></mml:mrow></mml:mrow></mml:msub><mml:mspace width="thickmathspace"/><mml:msub><mml:mi>r</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi mathvariant="normal">R</mml:mi></mml:mrow></mml:msub><mml:mo>−</mml:mo><mml:msub><mml:mi>w</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:msup><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi mathvariant="normal">P</mml:mi><mml:mi mathvariant="normal">V</mml:mi></mml:mrow><mml:mo>−</mml:mo></mml:msup><mml:mo>,</mml:mo><mml:msup><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi mathvariant="normal">S</mml:mi><mml:mi mathvariant="normal">S</mml:mi><mml:mi mathvariant="normal">T</mml:mi></mml:mrow><mml:mo>−</mml:mo></mml:msup></mml:mrow></mml:msub><mml:mspace width="thickmathspace"/><mml:msub><mml:mi>r</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:msup><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi mathvariant="normal">S</mml:mi><mml:mi mathvariant="normal">S</mml:mi><mml:mi mathvariant="normal">T</mml:mi></mml:mrow><mml:mo>−</mml:mo></mml:msup></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:mo stretchy="false">)</mml:mo><mml:mo stretchy="false">)</mml:mo><mml:mo>,</mml:mo></mml:mtd></mml:mtr></mml:mtable></mml:math></disp-formula><disp-formula id="equ26"><label>(19)</label><mml:math id="m26"><mml:mtable rowspacing="3pt" columnspacing="0em 2em 0em 2em 0em 2em 0em 2em 0em 2em 0em" displaystyle="true"><mml:mtr><mml:mtd><mml:msub><mml:mi>τ</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi mathvariant="normal">E</mml:mi></mml:mrow></mml:msub><mml:mfrac><mml:mrow><mml:mi>d</mml:mi><mml:msub><mml:mi>r</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:msup><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi mathvariant="normal">U</mml:mi><mml:mi mathvariant="normal">P</mml:mi><mml:mi mathvariant="normal">E</mml:mi></mml:mrow><mml:mo>−</mml:mo></mml:msup></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:mi>d</mml:mi><mml:mi>t</mml:mi></mml:mrow></mml:mfrac></mml:mtd><mml:mtd><mml:mi/><mml:mo>=</mml:mo><mml:mo>−</mml:mo><mml:msub><mml:mi>r</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:msup><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi mathvariant="normal">U</mml:mi><mml:mi mathvariant="normal">P</mml:mi><mml:mi mathvariant="normal">E</mml:mi></mml:mrow><mml:mo>−</mml:mo></mml:msup></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:mi>ϕ</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mfrac><mml:mrow><mml:mo fence="false" stretchy="false">⌊</mml:mo><mml:msub><mml:mi>w</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi mathvariant="normal">U</mml:mi><mml:mi mathvariant="normal">P</mml:mi><mml:mi mathvariant="normal">E</mml:mi></mml:mrow><mml:mo>,</mml:mo><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi mathvariant="normal">R</mml:mi></mml:mrow></mml:mrow></mml:msub><mml:mspace width="thickmathspace"/><mml:msub><mml:mi>r</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi mathvariant="normal">R</mml:mi></mml:mrow></mml:msub><mml:mo>−</mml:mo><mml:msub><mml:mi>w</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi mathvariant="normal">U</mml:mi><mml:mi mathvariant="normal">P</mml:mi><mml:mi mathvariant="normal">E</mml:mi></mml:mrow><mml:mo>,</mml:mo><mml:msup><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi mathvariant="normal">S</mml:mi><mml:mi mathvariant="normal">S</mml:mi><mml:mi mathvariant="normal">T</mml:mi></mml:mrow><mml:mo>−</mml:mo></mml:msup></mml:mrow></mml:msub><mml:mspace width="thickmathspace"/><mml:msub><mml:mi>r</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:msup><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi mathvariant="normal">S</mml:mi><mml:mi mathvariant="normal">S</mml:mi><mml:mi mathvariant="normal">T</mml:mi></mml:mrow><mml:mo>−</mml:mo></mml:msup></mml:mrow></mml:msub><mml:msup><mml:mo fence="false" stretchy="false">⌋</mml:mo><mml:mi>k</mml:mi></mml:msup></mml:mrow><mml:mrow><mml:msub><mml:mi>I</mml:mi><mml:mn>0</mml:mn></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mi>w</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi mathvariant="normal">U</mml:mi><mml:mi mathvariant="normal">P</mml:mi><mml:mi mathvariant="normal">E</mml:mi></mml:mrow><mml:mo>,</mml:mo><mml:msup><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi mathvariant="normal">P</mml:mi><mml:mi mathvariant="normal">V</mml:mi></mml:mrow><mml:mo>−</mml:mo></mml:msup></mml:mrow></mml:msub><mml:mspace width="thickmathspace"/><mml:msub><mml:mi>r</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:msup><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi mathvariant="normal">P</mml:mi><mml:mi mathvariant="normal">V</mml:mi></mml:mrow><mml:mo>−</mml:mo></mml:msup></mml:mrow></mml:msub></mml:mrow></mml:mfrac><mml:mo>)</mml:mo></mml:mrow><mml:mo>,</mml:mo></mml:mtd></mml:mtr></mml:mtable></mml:math></disp-formula><disp-formula id="equ27"><label>(20)</label><mml:math id="m27"><mml:mtable rowspacing="3pt" columnspacing="0em 2em 0em 2em 0em 2em 0em 2em 0em 2em 0em" displaystyle="true"><mml:mtr><mml:mtd><mml:msub><mml:mi>τ</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi mathvariant="normal">E</mml:mi></mml:mrow></mml:msub><mml:mfrac><mml:mrow><mml:mi>d</mml:mi><mml:msub><mml:mi>r</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi mathvariant="normal">R</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:mi>d</mml:mi><mml:mi>t</mml:mi></mml:mrow></mml:mfrac></mml:mtd><mml:mtd><mml:mi/><mml:mo>=</mml:mo><mml:mo>−</mml:mo><mml:msub><mml:mi>r</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi mathvariant="normal">R</mml:mi></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:mi>ϕ</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>w</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi mathvariant="normal">R</mml:mi></mml:mrow><mml:mo>,</mml:mo><mml:mtext>a</mml:mtext></mml:mrow></mml:msub><mml:mspace width="thickmathspace"/><mml:msub><mml:mi>r</mml:mi><mml:mtext>a</mml:mtext></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mi>w</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi mathvariant="normal">R</mml:mi></mml:mrow><mml:mo>,</mml:mo><mml:msup><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi mathvariant="normal">U</mml:mi><mml:mi mathvariant="normal">P</mml:mi><mml:mi mathvariant="normal">E</mml:mi></mml:mrow><mml:mo>+</mml:mo></mml:msup></mml:mrow></mml:msub><mml:mspace width="thickmathspace"/><mml:msub><mml:mi>r</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:msup><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi mathvariant="normal">U</mml:mi><mml:mi mathvariant="normal">P</mml:mi><mml:mi mathvariant="normal">E</mml:mi></mml:mrow><mml:mo>+</mml:mo></mml:msup></mml:mrow></mml:msub><mml:mo>−</mml:mo><mml:msub><mml:mi>w</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi mathvariant="normal">R</mml:mi></mml:mrow><mml:mo>,</mml:mo><mml:msup><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi mathvariant="normal">U</mml:mi><mml:mi mathvariant="normal">P</mml:mi><mml:mi mathvariant="normal">E</mml:mi></mml:mrow><mml:mo>−</mml:mo></mml:msup></mml:mrow></mml:msub><mml:mspace width="thickmathspace"/><mml:msub><mml:mi>r</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:msup><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi mathvariant="normal">U</mml:mi><mml:mi mathvariant="normal">P</mml:mi><mml:mi mathvariant="normal">E</mml:mi></mml:mrow><mml:mo>−</mml:mo></mml:msup></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:mo stretchy="false">)</mml:mo><mml:mo>.</mml:mo></mml:mtd></mml:mtr></mml:mtable></mml:math></disp-formula></p></sec><sec id="s4-4"><title>Hierarchical predictive coding</title><p>The idea behind hierarchical predictive coding is that the brain infers or represents the causes of its sensory inputs using a hierarchical generative model (<xref ref-type="bibr" rid="bib23">Friston, 2005</xref>). Each level of the cortical hierarchy provides a prior for the mean of the lower level representation, with the top level representation <inline-formula><mml:math id="inf185"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>r</mml:mi><mml:mrow><mml:mi>L</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula> being determined by the context.</p><p>Noise enters in the sensory area by sampling a stimulus <inline-formula><mml:math id="inf186"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>s</mml:mi><mml:mo>=</mml:mo><mml:msub><mml:mi>r</mml:mi><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula>. In the sensory area, the variance <inline-formula><mml:math id="inf187"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msubsup><mml:mi>σ</mml:mi><mml:mrow><mml:mn>0</mml:mn></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup></mml:mrow></mml:mstyle></mml:math></inline-formula> is learned to match the variability of the external stimulus <inline-formula><mml:math id="inf188"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msubsup><mml:mi>σ</mml:mi><mml:mrow><mml:mi>s</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup></mml:mrow></mml:mstyle></mml:math></inline-formula>.</p><p>The goal is to infer the set of latent representations <inline-formula><mml:math id="inf189"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mrow><mml:mtext mathvariant="bold">r</mml:mtext></mml:mrow><mml:mo>=</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>r</mml:mi><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:mo>.</mml:mo><mml:mo>.</mml:mo><mml:mo>,</mml:mo><mml:msub><mml:mi>r</mml:mi><mml:mrow><mml:mi>L</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mstyle></mml:math></inline-formula>, given the synaptic weights <inline-formula><mml:math id="inf190"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>w</mml:mi><mml:mrow><mml:mi>ℓ</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula> of the internal model and the top activity <inline-formula><mml:math id="inf191"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>r</mml:mi><mml:mrow><mml:mi>L</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula>, that best reproduces the sensory inputs <inline-formula><mml:math id="inf192"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>s</mml:mi></mml:mrow></mml:mstyle></mml:math></inline-formula>. To this end, we minimise the following energy:<disp-formula id="equ28"> <label>(21)</label><mml:math id="m28"><mml:mrow><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>E</mml:mi><mml:mo>=</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mn>2</mml:mn></mml:mfrac><mml:munderover><mml:mo>∑</mml:mo><mml:mrow><mml:mi>ℓ</mml:mi><mml:mo>=</mml:mo><mml:mn>0</mml:mn></mml:mrow><mml:mrow><mml:mi>L</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:munderover><mml:mfrac><mml:mn>1</mml:mn><mml:msubsup><mml:mi>σ</mml:mi><mml:mrow><mml:mi>ℓ</mml:mi></mml:mrow><mml:mn>2</mml:mn></mml:msubsup></mml:mfrac><mml:mo fence="false" stretchy="false">‖</mml:mo><mml:msub><mml:mi>r</mml:mi><mml:mrow><mml:mi>ℓ</mml:mi></mml:mrow></mml:msub><mml:mo>−</mml:mo><mml:mi>ρ</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>w</mml:mi><mml:mrow><mml:mi>ℓ</mml:mi></mml:mrow></mml:msub><mml:msub><mml:mi>r</mml:mi><mml:mrow><mml:mi>ℓ</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:msubsup><mml:mo fence="false" stretchy="false">‖</mml:mo><mml:mn>2</mml:mn><mml:mn>2</mml:mn></mml:msubsup><mml:mspace width="thinmathspace"/></mml:mstyle></mml:mrow></mml:math></disp-formula></p><p>where <inline-formula><mml:math id="inf193"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>ρ</mml:mi></mml:mrow></mml:mstyle></mml:math></inline-formula> is a transfer function.</p><p>We obtain the update for <inline-formula><mml:math id="inf194"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>r</mml:mi><mml:mrow><mml:mi>ℓ</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula> with gradient descent on the energy with respect to <inline-formula><mml:math id="inf195"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>r</mml:mi><mml:mrow><mml:mi>ℓ</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula>:<disp-formula id="equ29"><label>(22)</label><mml:math id="m29"><mml:mrow><mml:mtable columnalign="left left" rowspacing="4pt" columnspacing="1em"><mml:mtr><mml:mtd><mml:mrow><mml:mover><mml:msub><mml:mi>r</mml:mi><mml:mi>ℓ</mml:mi></mml:msub><mml:mo>˙</mml:mo></mml:mover></mml:mrow></mml:mtd><mml:mtd><mml:mo>=</mml:mo><mml:mo>−</mml:mo><mml:mfrac><mml:mrow><mml:mi mathvariant="normal">∂</mml:mi><mml:mi>E</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">∂</mml:mi><mml:msub><mml:mi>r</mml:mi><mml:mi>ℓ</mml:mi></mml:msub></mml:mrow></mml:mfrac><mml:mo>=</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:msubsup><mml:mi>σ</mml:mi><mml:mrow><mml:mi>ℓ</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mn>2</mml:mn></mml:msubsup></mml:mfrac><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>r</mml:mi><mml:mrow><mml:mi>ℓ</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>−</mml:mo><mml:mi>ρ</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>w</mml:mi><mml:mrow><mml:mi>ℓ</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:msub><mml:mi>r</mml:mi><mml:mi>ℓ</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:mo stretchy="false">)</mml:mo><mml:msub><mml:mi>w</mml:mi><mml:mrow><mml:mi>ℓ</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:msup><mml:mi>ρ</mml:mi><mml:mi mathvariant="normal">′</mml:mi></mml:msup><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>r</mml:mi><mml:mi>ℓ</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:mo>−</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:msubsup><mml:mi>σ</mml:mi><mml:mi>ℓ</mml:mi><mml:mn>2</mml:mn></mml:msubsup></mml:mfrac><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>r</mml:mi><mml:mi>ℓ</mml:mi></mml:msub><mml:mo>−</mml:mo><mml:mi>ρ</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>w</mml:mi><mml:mi>ℓ</mml:mi></mml:msub><mml:msub><mml:mi>r</mml:mi><mml:mrow><mml:mi>ℓ</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:mo stretchy="false">)</mml:mo></mml:mtd></mml:mtr><mml:mtr><mml:mtd/><mml:mtd><mml:mo>=</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:msubsup><mml:mi>σ</mml:mi><mml:mrow><mml:mi>ℓ</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mn>2</mml:mn></mml:msubsup></mml:mfrac><mml:msup><mml:mi>ρ</mml:mi><mml:mi mathvariant="normal">′</mml:mi></mml:msup><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>w</mml:mi><mml:mrow><mml:mi>ℓ</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:msub><mml:mi>r</mml:mi><mml:mi>ℓ</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:msub><mml:mi>e</mml:mi><mml:mrow><mml:mi>ℓ</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>−</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:msubsup><mml:mi>σ</mml:mi><mml:mi>ℓ</mml:mi><mml:mn>2</mml:mn></mml:msubsup></mml:mfrac><mml:msub><mml:mi>e</mml:mi><mml:mrow><mml:mi>ℓ</mml:mi></mml:mrow></mml:msub></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:math></disp-formula></p><p>In our model, <inline-formula><mml:math id="inf196"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>w</mml:mi><mml:mrow><mml:mi>ℓ</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula> are scalars as they denote single weights.</p><p>We obtain the steady-state representation <inline-formula><mml:math id="inf197"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>r</mml:mi><mml:mrow><mml:mi>ℓ</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula> by setting its derivative in <xref ref-type="disp-formula" rid="equ28">Equation 21</xref> to 0:<disp-formula id="equ30"><label>(23)</label><mml:math id="m30"><mml:mrow><mml:mn>0</mml:mn><mml:mover><mml:mo>=</mml:mo><mml:mo>!</mml:mo></mml:mover><mml:mfrac><mml:mrow><mml:msub><mml:mi>w</mml:mi><mml:mrow><mml:mi>ℓ</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:msup><mml:mi>ρ</mml:mi><mml:mi mathvariant="normal">′</mml:mi></mml:msup><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>w</mml:mi><mml:mrow><mml:mi>ℓ</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:msub><mml:mi>r</mml:mi><mml:mi>ℓ</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:msubsup><mml:mi>σ</mml:mi><mml:mrow><mml:mi>ℓ</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mn>2</mml:mn></mml:msubsup></mml:mfrac><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>r</mml:mi><mml:mrow><mml:mi>ℓ</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>−</mml:mo><mml:mi>ρ</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>w</mml:mi><mml:mrow><mml:mi>ℓ</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:msub><mml:mi>r</mml:mi><mml:mi>ℓ</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:mo stretchy="false">)</mml:mo><mml:mo>−</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:msubsup><mml:mi>σ</mml:mi><mml:mi>ℓ</mml:mi><mml:mn>2</mml:mn></mml:msubsup></mml:mfrac><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>r</mml:mi><mml:mi>ℓ</mml:mi></mml:msub><mml:mo>−</mml:mo><mml:mi>ρ</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>w</mml:mi><mml:mi>ℓ</mml:mi></mml:msub><mml:msub><mml:mi>r</mml:mi><mml:mrow><mml:mi>ℓ</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></disp-formula></p><p>We next consider, for simplicity, a threshold-linear transfer function <inline-formula><mml:math id="inf198"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>ρ</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>w</mml:mi><mml:mrow><mml:mi>ℓ</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:msub><mml:mi>r</mml:mi><mml:mrow><mml:mi>ℓ</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mstyle></mml:math></inline-formula> such that if <inline-formula><mml:math id="inf199"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>w</mml:mi><mml:mrow><mml:mi>ℓ</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:msub><mml:mi>r</mml:mi><mml:mrow><mml:mi>ℓ</mml:mi></mml:mrow></mml:msub><mml:mo>&lt;</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:mstyle></mml:math></inline-formula>, then <inline-formula><mml:math id="inf200"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>ρ</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>w</mml:mi><mml:mrow><mml:mi>ℓ</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:msub><mml:mi>r</mml:mi><mml:mrow><mml:mi>ℓ</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:mstyle></mml:math></inline-formula> and its derivative <inline-formula><mml:math id="inf201"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msup><mml:mi>ρ</mml:mi><mml:mrow><mml:mi mathvariant="normal">′</mml:mi></mml:mrow></mml:msup><mml:mo>=</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:mstyle></mml:math></inline-formula> or if <inline-formula><mml:math id="inf202"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>w</mml:mi><mml:mrow><mml:mi>ℓ</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:msub><mml:mi>r</mml:mi><mml:mrow><mml:mi>ℓ</mml:mi></mml:mrow></mml:msub><mml:mo>≥</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:mstyle></mml:math></inline-formula> then <inline-formula><mml:math id="inf203"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>ρ</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>w</mml:mi><mml:mrow><mml:mi>ℓ</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:msub><mml:mi>r</mml:mi><mml:mrow><mml:mi>ℓ</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:msub><mml:mi>w</mml:mi><mml:mrow><mml:mi>ℓ</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:msub><mml:mi>r</mml:mi><mml:mrow><mml:mi>ℓ</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula> and <inline-formula><mml:math id="inf204"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msup><mml:mi>ρ</mml:mi><mml:mrow><mml:mi mathvariant="normal">′</mml:mi></mml:mrow></mml:msup><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:mstyle></mml:math></inline-formula>.</p><p>Solving <xref ref-type="disp-formula" rid="equ31">Equation 24</xref> for <inline-formula><mml:math id="inf205"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>r</mml:mi><mml:mrow><mml:mi>ℓ</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula> and assuming <inline-formula><mml:math id="inf206"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>r</mml:mi><mml:mrow><mml:mi>ℓ</mml:mi></mml:mrow></mml:msub><mml:mo>≥</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:mstyle></mml:math></inline-formula>, we get:<disp-formula id="equ31"><label>(24)</label><mml:math id="m31"><mml:mrow><mml:msub><mml:mi>r</mml:mi><mml:mrow><mml:mi>ℓ</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mfrac><mml:mfrac><mml:msubsup><mml:mi>w</mml:mi><mml:mrow><mml:mi>ℓ</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mn>2</mml:mn></mml:msubsup><mml:msubsup><mml:mi>σ</mml:mi><mml:mrow><mml:mi>ℓ</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mn>2</mml:mn></mml:msubsup></mml:mfrac><mml:mrow><mml:mfrac><mml:msubsup><mml:mi>w</mml:mi><mml:mrow><mml:mi>ℓ</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mn>2</mml:mn></mml:msubsup><mml:msubsup><mml:mi>σ</mml:mi><mml:mrow><mml:mi>ℓ</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mn>2</mml:mn></mml:msubsup></mml:mfrac><mml:mo>+</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:msubsup><mml:mi>σ</mml:mi><mml:mi>ℓ</mml:mi><mml:mn>2</mml:mn></mml:msubsup></mml:mfrac></mml:mrow></mml:mfrac><mml:mfrac><mml:msub><mml:mi>r</mml:mi><mml:mrow><mml:mi>ℓ</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:msub><mml:mi>w</mml:mi><mml:mrow><mml:mi>ℓ</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mfrac><mml:mo>+</mml:mo><mml:mfrac><mml:mfrac><mml:mn>1</mml:mn><mml:msubsup><mml:mi>σ</mml:mi><mml:mi>ℓ</mml:mi><mml:mn>2</mml:mn></mml:msubsup></mml:mfrac><mml:mrow><mml:mfrac><mml:msubsup><mml:mi>w</mml:mi><mml:mrow><mml:mi>ℓ</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mn>2</mml:mn></mml:msubsup><mml:msubsup><mml:mi>σ</mml:mi><mml:mrow><mml:mi>ℓ</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mn>2</mml:mn></mml:msubsup></mml:mfrac><mml:mo>+</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:msubsup><mml:mi>σ</mml:mi><mml:mi>ℓ</mml:mi><mml:mn>2</mml:mn></mml:msubsup></mml:mfrac></mml:mrow></mml:mfrac><mml:msub><mml:mi>w</mml:mi><mml:mi>ℓ</mml:mi></mml:msub><mml:msub><mml:mi>r</mml:mi><mml:mrow><mml:mi>ℓ</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>.</mml:mo></mml:mrow></mml:math></disp-formula></p><p>See appendix for the general case with any transfer function and weight matrix.</p></sec><sec id="s4-5"><title>Hierarchical circuit model</title><p>In the hierarchical circuit model, the representation neuron does not only receive UPEs from the area below, but also from the current area.<disp-formula id="equ32"><label>(25)</label><mml:math id="m32"><mml:mtable rowspacing="3pt" columnspacing="0em 2em 0em 2em 0em 2em 0em 2em 0em 2em 0em" displaystyle="true"><mml:mtr><mml:mtd><mml:msub><mml:mi>τ</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi mathvariant="normal">E</mml:mi></mml:mrow></mml:msub><mml:mfrac><mml:mrow><mml:mi>d</mml:mi><mml:msub><mml:mi>r</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi mathvariant="normal">R</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:mi>d</mml:mi><mml:mi>t</mml:mi></mml:mrow></mml:mfrac><mml:mo>=</mml:mo><mml:mo>−</mml:mo><mml:msub><mml:mi>r</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi mathvariant="normal">R</mml:mi></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:mi>ϕ</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>w</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi mathvariant="normal">R</mml:mi></mml:mrow><mml:mo>,</mml:mo><mml:mtext>a</mml:mtext></mml:mrow></mml:msub><mml:mspace width="thickmathspace"/><mml:msub><mml:mi>r</mml:mi><mml:mtext>a</mml:mtext></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mi>w</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi mathvariant="normal">R</mml:mi></mml:mrow><mml:mo>,</mml:mo><mml:msubsup><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi mathvariant="normal">U</mml:mi><mml:mi mathvariant="normal">P</mml:mi><mml:mi mathvariant="normal">E</mml:mi></mml:mrow><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>ℓ</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mo>+</mml:mo></mml:msubsup></mml:mrow></mml:msub><mml:mspace width="thickmathspace"/><mml:msub><mml:mi>r</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:msubsup><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi mathvariant="normal">U</mml:mi><mml:mi mathvariant="normal">P</mml:mi><mml:mi mathvariant="normal">E</mml:mi></mml:mrow><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>ℓ</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mo>+</mml:mo></mml:msubsup></mml:mrow></mml:msub><mml:mo>−</mml:mo><mml:msub><mml:mi>w</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi mathvariant="normal">R</mml:mi></mml:mrow><mml:mo>,</mml:mo><mml:msubsup><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi mathvariant="normal">U</mml:mi><mml:mi mathvariant="normal">P</mml:mi><mml:mi mathvariant="normal">E</mml:mi></mml:mrow><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>ℓ</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mo>−</mml:mo></mml:msubsup></mml:mrow></mml:msub><mml:mspace width="thickmathspace"/><mml:msub><mml:mi>r</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:msubsup><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi mathvariant="normal">U</mml:mi><mml:mi mathvariant="normal">P</mml:mi><mml:mi mathvariant="normal">E</mml:mi></mml:mrow><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>ℓ</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mo>−</mml:mo></mml:msubsup></mml:mrow></mml:msub><mml:mo>−</mml:mo><mml:msub><mml:mi>w</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi mathvariant="normal">R</mml:mi></mml:mrow><mml:mo>,</mml:mo><mml:msubsup><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi mathvariant="normal">U</mml:mi><mml:mi mathvariant="normal">P</mml:mi><mml:mi mathvariant="normal">E</mml:mi></mml:mrow><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>ℓ</mml:mi></mml:mrow><mml:mo>+</mml:mo></mml:msubsup></mml:mrow></mml:msub><mml:mspace width="thickmathspace"/><mml:msub><mml:mi>r</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:msubsup><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi mathvariant="normal">U</mml:mi><mml:mi mathvariant="normal">P</mml:mi><mml:mi mathvariant="normal">E</mml:mi></mml:mrow><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>ℓ</mml:mi></mml:mrow><mml:mo>+</mml:mo></mml:msubsup></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mi>w</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi mathvariant="normal">R</mml:mi></mml:mrow><mml:mo>,</mml:mo><mml:msubsup><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi mathvariant="normal">U</mml:mi><mml:mi mathvariant="normal">P</mml:mi><mml:mi mathvariant="normal">E</mml:mi></mml:mrow><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>ℓ</mml:mi></mml:mrow><mml:mo>−</mml:mo></mml:msubsup></mml:mrow></mml:msub><mml:mspace width="thickmathspace"/><mml:msub><mml:mi>r</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:msubsup><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi mathvariant="normal">U</mml:mi><mml:mi mathvariant="normal">P</mml:mi><mml:mi mathvariant="normal">E</mml:mi></mml:mrow><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>ℓ</mml:mi></mml:mrow><mml:mo>−</mml:mo></mml:msubsup></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:mo>.</mml:mo></mml:mtd></mml:mtr></mml:mtable></mml:math></disp-formula></p><p>The UPEs from the area below are as defined in the recurrent circuit model, and the UPEs from the current area are defined accordingly as:<disp-formula id="equ33"><label>(26)</label><mml:math id="m33"><mml:mrow><mml:msub><mml:mi>τ</mml:mi><mml:mrow><mml:mrow><mml:mi mathvariant="normal">E</mml:mi></mml:mrow></mml:mrow></mml:msub><mml:mfrac><mml:mrow><mml:mi>d</mml:mi><mml:msub><mml:mi>r</mml:mi><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="normal">U</mml:mi><mml:mi mathvariant="normal">P</mml:mi><mml:msup><mml:mi mathvariant="normal">E</mml:mi><mml:mrow><mml:mo>+</mml:mo></mml:mrow></mml:msup></mml:mrow><mml:mi>ℓ</mml:mi></mml:msub></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:mi>d</mml:mi><mml:mi>t</mml:mi></mml:mrow></mml:mfrac><mml:mo>=</mml:mo><mml:mo>−</mml:mo><mml:msub><mml:mi>r</mml:mi><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="normal">U</mml:mi><mml:mi mathvariant="normal">P</mml:mi><mml:msup><mml:mi mathvariant="normal">E</mml:mi><mml:mrow><mml:mo>+</mml:mo></mml:mrow></mml:msup></mml:mrow><mml:mi>ℓ</mml:mi></mml:msub></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:mi>ϕ</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mfrac><mml:mrow><mml:mo fence="false" stretchy="false">⌊</mml:mo><mml:msub><mml:mi>w</mml:mi><mml:mrow><mml:mrow><mml:mi mathvariant="normal">U</mml:mi><mml:mi mathvariant="normal">P</mml:mi><mml:mi mathvariant="normal">E</mml:mi></mml:mrow><mml:mo>,</mml:mo><mml:msub><mml:mi>r</mml:mi><mml:mrow><mml:mi mathvariant="normal">R</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:msub><mml:mspace width="thickmathspace"/><mml:mrow><mml:mi mathvariant="normal">R</mml:mi></mml:mrow><mml:mo>−</mml:mo><mml:msub><mml:mi>w</mml:mi><mml:mrow><mml:mrow><mml:mi mathvariant="normal">U</mml:mi><mml:mi mathvariant="normal">P</mml:mi><mml:mi mathvariant="normal">E</mml:mi></mml:mrow><mml:mo>,</mml:mo><mml:mrow><mml:mi mathvariant="normal">S</mml:mi><mml:mi mathvariant="normal">S</mml:mi><mml:msup><mml:mi mathvariant="normal">T</mml:mi><mml:mrow><mml:mo>+</mml:mo></mml:mrow></mml:msup></mml:mrow></mml:mrow></mml:msub><mml:mspace width="thickmathspace"/><mml:msub><mml:mi>r</mml:mi><mml:mrow><mml:mrow><mml:mi mathvariant="normal">S</mml:mi><mml:mi mathvariant="normal">S</mml:mi><mml:msup><mml:mi mathvariant="normal">T</mml:mi><mml:mrow><mml:mo>+</mml:mo></mml:mrow></mml:msup></mml:mrow></mml:mrow></mml:msub><mml:msup><mml:mo fence="false" stretchy="false">⌋</mml:mo><mml:mi>k</mml:mi></mml:msup></mml:mrow><mml:mrow><mml:msub><mml:mi>I</mml:mi><mml:mn>0</mml:mn></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mi>w</mml:mi><mml:mrow><mml:mrow><mml:mi mathvariant="normal">U</mml:mi><mml:mi mathvariant="normal">P</mml:mi><mml:mi mathvariant="normal">E</mml:mi></mml:mrow><mml:mo>,</mml:mo><mml:mrow><mml:mi mathvariant="normal">P</mml:mi><mml:msup><mml:mi mathvariant="normal">V</mml:mi><mml:mrow><mml:mo>+</mml:mo></mml:mrow></mml:msup></mml:mrow></mml:mrow></mml:msub><mml:mspace width="thickmathspace"/><mml:msub><mml:mi>r</mml:mi><mml:mrow><mml:mrow><mml:mi mathvariant="normal">P</mml:mi><mml:msup><mml:mi mathvariant="normal">V</mml:mi><mml:mrow><mml:mo>+</mml:mo></mml:mrow></mml:msup></mml:mrow></mml:mrow></mml:msub></mml:mrow></mml:mfrac><mml:mo>)</mml:mo></mml:mrow><mml:mo>,</mml:mo></mml:mrow></mml:math></disp-formula><disp-formula id="equ34"><label>(27)</label><mml:math id="m34"><mml:mtable rowspacing="3pt" columnspacing="0em 2em 0em 2em 0em 2em 0em 2em 0em 2em 0em" displaystyle="true"><mml:mtr><mml:mtd><mml:msub><mml:mi>τ</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi mathvariant="normal">E</mml:mi></mml:mrow></mml:msub><mml:mfrac><mml:mrow><mml:mi>d</mml:mi><mml:msub><mml:mi>r</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:msubsup><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi mathvariant="normal">U</mml:mi><mml:mi mathvariant="normal">P</mml:mi><mml:mi mathvariant="normal">E</mml:mi></mml:mrow><mml:mi>ℓ</mml:mi><mml:mo>−</mml:mo></mml:msubsup></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:mi>d</mml:mi><mml:mi>t</mml:mi></mml:mrow></mml:mfrac></mml:mtd><mml:mtd><mml:mi/><mml:mo>=</mml:mo><mml:mo>−</mml:mo><mml:msub><mml:mi>r</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:msubsup><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi mathvariant="normal">U</mml:mi><mml:mi mathvariant="normal">P</mml:mi><mml:mi mathvariant="normal">E</mml:mi></mml:mrow><mml:mi>ℓ</mml:mi><mml:mo>−</mml:mo></mml:msubsup></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:mi>ϕ</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mfrac><mml:mrow><mml:mo fence="false" stretchy="false">⌊</mml:mo><mml:msub><mml:mi>w</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi mathvariant="normal">U</mml:mi><mml:mi mathvariant="normal">P</mml:mi><mml:mi mathvariant="normal">E</mml:mi></mml:mrow><mml:mo>,</mml:mo><mml:mtext>prior</mml:mtext></mml:mrow></mml:msub><mml:mspace width="thickmathspace"/><mml:msub><mml:mi>μ</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mtext>prior</mml:mtext></mml:mrow></mml:msub><mml:mo>−</mml:mo><mml:msub><mml:mi>w</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi mathvariant="normal">U</mml:mi><mml:mi mathvariant="normal">P</mml:mi><mml:mi mathvariant="normal">E</mml:mi></mml:mrow><mml:mo>,</mml:mo><mml:msup><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi mathvariant="normal">S</mml:mi><mml:mi mathvariant="normal">S</mml:mi><mml:mi mathvariant="normal">T</mml:mi></mml:mrow><mml:mo>−</mml:mo></mml:msup></mml:mrow></mml:msub><mml:mspace width="thickmathspace"/><mml:msub><mml:mi>r</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:msup><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi mathvariant="normal">S</mml:mi><mml:mi mathvariant="normal">S</mml:mi><mml:mi mathvariant="normal">T</mml:mi></mml:mrow><mml:mo>−</mml:mo></mml:msup></mml:mrow></mml:msub><mml:msup><mml:mo fence="false" stretchy="false">⌋</mml:mo><mml:mi>k</mml:mi></mml:msup></mml:mrow><mml:mrow><mml:msub><mml:mi>I</mml:mi><mml:mn>0</mml:mn></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mi>w</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi mathvariant="normal">U</mml:mi><mml:mi mathvariant="normal">P</mml:mi><mml:mi mathvariant="normal">E</mml:mi></mml:mrow><mml:mo>,</mml:mo><mml:msup><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi mathvariant="normal">P</mml:mi><mml:mi mathvariant="normal">V</mml:mi></mml:mrow><mml:mo>−</mml:mo></mml:msup></mml:mrow></mml:msub><mml:mspace width="thickmathspace"/><mml:msub><mml:mi>r</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:msup><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi mathvariant="normal">P</mml:mi><mml:mi mathvariant="normal">V</mml:mi></mml:mrow><mml:mo>−</mml:mo></mml:msup></mml:mrow></mml:msub></mml:mrow></mml:mfrac><mml:mo>)</mml:mo></mml:mrow><mml:mo>,</mml:mo></mml:mtd></mml:mtr></mml:mtable></mml:math></disp-formula></p><p>The computations and parameters in each area are the same as for the recurrent circuit model above and in <xref ref-type="fig" rid="fig5">Figure 5</xref>.</p><p>Synapses from the higher level representation of the sound <inline-formula><mml:math id="inf207"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>a</mml:mi></mml:mrow></mml:mstyle></mml:math></inline-formula> to R were plastic according to the following activity-dependent plasticity rules (<xref ref-type="bibr" rid="bib75">Urbanczik and Senn, 2014</xref>).<disp-formula id="equ35"><label>(28)</label><mml:math id="m35"><mml:mrow><mml:mi mathvariant="normal">Δ</mml:mi><mml:msub><mml:mi>w</mml:mi><mml:mrow><mml:mrow><mml:mi mathvariant="normal">R</mml:mi></mml:mrow><mml:mo>,</mml:mo><mml:mtext>a</mml:mtext></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:msub><mml:mi>η</mml:mi><mml:mrow><mml:mi mathvariant="normal">R</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>r</mml:mi><mml:mrow><mml:mi mathvariant="normal">R</mml:mi></mml:mrow></mml:msub><mml:mo>−</mml:mo><mml:mi>ϕ</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>w</mml:mi><mml:mrow><mml:mrow><mml:mi mathvariant="normal">R</mml:mi></mml:mrow><mml:mo>,</mml:mo><mml:mtext>a</mml:mtext></mml:mrow></mml:msub><mml:msub><mml:mi>r</mml:mi><mml:mtext>a</mml:mtext></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:mo stretchy="false">)</mml:mo><mml:msub><mml:mi>r</mml:mi><mml:mtext>a</mml:mtext></mml:msub><mml:mo>,</mml:mo></mml:mrow></mml:math></disp-formula></p><p>where <inline-formula><mml:math id="inf208"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>η</mml:mi><mml:mrow><mml:mrow><mml:mi mathvariant="normal">P</mml:mi><mml:mi mathvariant="normal">V</mml:mi></mml:mrow></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mn>0.01</mml:mn><mml:msub><mml:mi>η</mml:mi><mml:mrow><mml:mi>R</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula>.</p></sec><sec id="s4-6"><title>Estimating the variance correctly</title><p>The PVs estimate the variance of the sensory input from the variance of the teaching input <inline-formula><mml:math id="inf209"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>s</mml:mi><mml:mo>−</mml:mo><mml:mi>μ</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mstyle></mml:math></inline-formula>, which nudges the membrane potential of the PVs with a nudging factor <inline-formula><mml:math id="inf210"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>β</mml:mi></mml:mrow></mml:mstyle></mml:math></inline-formula>. The nudging factor reduces the effective variance of the teaching input, such that in order to correctly estimate the variance, this reduction needs to be compensated by larger weights from the SSTs to the PVs (<inline-formula><mml:math id="inf211"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>w</mml:mi><mml:mrow><mml:mrow><mml:mi mathvariant="normal">P</mml:mi><mml:mi mathvariant="normal">V</mml:mi></mml:mrow><mml:mo>,</mml:mo><mml:mrow><mml:mi mathvariant="normal">S</mml:mi><mml:mi mathvariant="normal">S</mml:mi><mml:mi mathvariant="normal">T</mml:mi></mml:mrow></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula>) and from the sensory input to the PVs (<inline-formula><mml:math id="inf212"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>w</mml:mi><mml:mrow><mml:mrow><mml:mi mathvariant="normal">P</mml:mi><mml:mi mathvariant="normal">V</mml:mi></mml:mrow><mml:mo>,</mml:mo><mml:mi>s</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula>). To determine how strong the weights <inline-formula><mml:math id="inf213"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>w</mml:mi><mml:mrow><mml:mi>s</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:msub><mml:mi>w</mml:mi><mml:mrow><mml:mrow><mml:mi mathvariant="normal">P</mml:mi><mml:mi mathvariant="normal">V</mml:mi></mml:mrow><mml:mo>,</mml:mo><mml:mrow><mml:mi mathvariant="normal">S</mml:mi><mml:mi mathvariant="normal">S</mml:mi><mml:mi mathvariant="normal">T</mml:mi></mml:mrow></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:msub><mml:mi>w</mml:mi><mml:mrow><mml:mrow><mml:mi mathvariant="normal">P</mml:mi><mml:mi mathvariant="normal">V</mml:mi></mml:mrow><mml:mo>,</mml:mo><mml:mi>s</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula> need to be to compensate for the downscaling of the input variance by <inline-formula><mml:math id="inf214"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>β</mml:mi></mml:mrow></mml:mstyle></mml:math></inline-formula>, we require that <inline-formula><mml:math id="inf215"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mrow><mml:mi mathvariant="double-struck">E</mml:mi></mml:mrow><mml:mo stretchy="false">[</mml:mo><mml:mi>w</mml:mi><mml:mi>a</mml:mi><mml:msup><mml:mo stretchy="false">]</mml:mo><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup><mml:mo>=</mml:mo><mml:msup><mml:mi>σ</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:mstyle></mml:math></inline-formula> when the average weight change <inline-formula><mml:math id="inf216"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mrow><mml:mi mathvariant="double-struck">E</mml:mi></mml:mrow><mml:mo stretchy="false">[</mml:mo><mml:mi mathvariant="normal">Δ</mml:mi><mml:mi>w</mml:mi><mml:mo stretchy="false">]</mml:mo><mml:mo>=</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:mstyle></mml:math></inline-formula>. The learning rule for <inline-formula><mml:math id="inf217"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>w</mml:mi></mml:mrow></mml:mstyle></mml:math></inline-formula> is as follows:<disp-formula id="equ36"><mml:math id="m36"><mml:mtable rowspacing="3pt" columnspacing="0em 2em 0em 2em 0em 2em 0em 2em 0em 2em 0em" displaystyle="true"><mml:mtr><mml:mtd><mml:mi mathvariant="normal">Δ</mml:mi><mml:mi>w</mml:mi></mml:mtd><mml:mtd><mml:mi/><mml:mo>=</mml:mo><mml:mi>η</mml:mi><mml:mo stretchy="false">[</mml:mo><mml:msub><mml:mi>r</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi mathvariant="normal">P</mml:mi><mml:mi mathvariant="normal">V</mml:mi></mml:mrow></mml:mrow></mml:msub><mml:mo>−</mml:mo><mml:mi>ϕ</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>w</mml:mi><mml:mi>a</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo stretchy="false">]</mml:mo><mml:mi>a</mml:mi></mml:mtd></mml:mtr></mml:mtable></mml:math></disp-formula><disp-formula id="equ37"><mml:math id="m37"><mml:mtable rowspacing="3pt" columnspacing="0em 2em 0em 2em 0em 2em 0em 2em 0em 2em 0em" displaystyle="true"><mml:mtr><mml:mtd/><mml:mtd><mml:mi/><mml:mo>=</mml:mo><mml:mi>η</mml:mi><mml:mo stretchy="false">[</mml:mo><mml:mi>ϕ</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:mi>β</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mi>w</mml:mi><mml:mi>a</mml:mi><mml:mo>+</mml:mo><mml:mi>β</mml:mi><mml:msub><mml:mi>w</mml:mi><mml:mi>s</mml:mi></mml:msub><mml:mrow class="MJX-TeXAtom-ORD"><mml:mover><mml:mi>s</mml:mi><mml:mo stretchy="false">~</mml:mo></mml:mover></mml:mrow><mml:mo stretchy="false">)</mml:mo><mml:mo>−</mml:mo><mml:mi>ϕ</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>w</mml:mi><mml:mi>a</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo stretchy="false">]</mml:mo><mml:mi>a</mml:mi></mml:mtd></mml:mtr></mml:mtable></mml:math></disp-formula></p><p>where <inline-formula><mml:math id="inf218"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mrow><mml:mover><mml:mi>s</mml:mi><mml:mo stretchy="false">~</mml:mo></mml:mover></mml:mrow><mml:mo>=</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mi>s</mml:mi><mml:mo>−</mml:mo><mml:mi>μ</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>∼</mml:mo><mml:mrow><mml:mi class="mathcal" mathvariant="script">N</mml:mi></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:mi>σ</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mstyle></mml:math></inline-formula> and <inline-formula><mml:math id="inf219"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mrow><mml:mover><mml:mi>s</mml:mi><mml:mo stretchy="false">~</mml:mo></mml:mover></mml:mrow><mml:mo>=</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mi>s</mml:mi><mml:mo>−</mml:mo><mml:mi>μ</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>∼</mml:mo><mml:mrow><mml:mi class="mathcal" mathvariant="script">N</mml:mi></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:mi>σ</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mstyle></mml:math></inline-formula>.</p><p>Using that <inline-formula><mml:math id="inf220"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>ϕ</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>u</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:msup><mml:mi>u</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:mstyle></mml:math></inline-formula>, the average weight change becomes:<disp-formula id="equ38"><mml:math id="m38"><mml:mtable rowspacing="3pt" columnspacing="0em 2em 0em 2em 0em 2em 0em 2em 0em 2em 0em" displaystyle="true"><mml:mtr><mml:mtd><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi mathvariant="double-struck">E</mml:mi></mml:mrow><mml:mo stretchy="false">[</mml:mo><mml:mi mathvariant="normal">Δ</mml:mi><mml:mi>w</mml:mi><mml:mo stretchy="false">]</mml:mo></mml:mtd><mml:mtd><mml:mi/><mml:mo>=</mml:mo><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi mathvariant="double-struck">E</mml:mi></mml:mrow><mml:mo stretchy="false">[</mml:mo><mml:mi>η</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:mi>β</mml:mi><mml:msup><mml:mo stretchy="false">)</mml:mo><mml:mn>2</mml:mn></mml:msup><mml:msup><mml:mi>w</mml:mi><mml:mn>2</mml:mn></mml:msup><mml:msup><mml:mi>a</mml:mi><mml:mn>2</mml:mn></mml:msup><mml:mo>+</mml:mo><mml:msup><mml:mi>β</mml:mi><mml:mn>2</mml:mn></mml:msup><mml:msubsup><mml:mi>w</mml:mi><mml:mi>s</mml:mi><mml:mn>2</mml:mn></mml:msubsup><mml:msup><mml:mrow class="MJX-TeXAtom-ORD"><mml:mover><mml:mi>s</mml:mi><mml:mo stretchy="false">~</mml:mo></mml:mover></mml:mrow><mml:mn>2</mml:mn></mml:msup><mml:mo>+</mml:mo><mml:mn>2</mml:mn><mml:mo stretchy="false">(</mml:mo><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:mi>β</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mi>w</mml:mi><mml:mi>a</mml:mi><mml:mi>β</mml:mi><mml:msub><mml:mi>w</mml:mi><mml:mi>s</mml:mi></mml:msub><mml:mrow class="MJX-TeXAtom-ORD"><mml:mover><mml:mi>s</mml:mi><mml:mo stretchy="false">~</mml:mo></mml:mover></mml:mrow><mml:mo>−</mml:mo><mml:msup><mml:mi>w</mml:mi><mml:mn>2</mml:mn></mml:msup><mml:msup><mml:mi>a</mml:mi><mml:mn>2</mml:mn></mml:msup><mml:mo stretchy="false">)</mml:mo><mml:mi>a</mml:mi><mml:mo stretchy="false">]</mml:mo></mml:mtd></mml:mtr></mml:mtable></mml:math></disp-formula><disp-formula id="equ39"><mml:math id="m39"><mml:mtable rowspacing="3pt" columnspacing="0em 2em 0em 2em 0em 2em 0em 2em 0em 2em 0em" displaystyle="true"><mml:mtr><mml:mtd/><mml:mtd><mml:mi/><mml:mo>=</mml:mo><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi mathvariant="double-struck">E</mml:mi></mml:mrow><mml:mo stretchy="false">[</mml:mo><mml:mi>η</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mn>1</mml:mn><mml:mo>+</mml:mo><mml:msup><mml:mi>β</mml:mi><mml:mn>2</mml:mn></mml:msup><mml:mo>−</mml:mo><mml:mn>2</mml:mn><mml:mi>β</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:msup><mml:mi>w</mml:mi><mml:mn>2</mml:mn></mml:msup><mml:msup><mml:mi>a</mml:mi><mml:mn>2</mml:mn></mml:msup><mml:mo>+</mml:mo><mml:msup><mml:mi>β</mml:mi><mml:mn>2</mml:mn></mml:msup><mml:msubsup><mml:mi>w</mml:mi><mml:mi>s</mml:mi><mml:mn>2</mml:mn></mml:msubsup><mml:msup><mml:mrow class="MJX-TeXAtom-ORD"><mml:mover><mml:mi>s</mml:mi><mml:mo stretchy="false">~</mml:mo></mml:mover></mml:mrow><mml:mn>2</mml:mn></mml:msup><mml:mo>+</mml:mo><mml:mn>2</mml:mn><mml:mo stretchy="false">(</mml:mo><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:mi>β</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mi>w</mml:mi><mml:mi>a</mml:mi><mml:mi>β</mml:mi><mml:msub><mml:mi>w</mml:mi><mml:mi>s</mml:mi></mml:msub><mml:mrow class="MJX-TeXAtom-ORD"><mml:mover><mml:mi>s</mml:mi><mml:mo stretchy="false">~</mml:mo></mml:mover></mml:mrow><mml:mo>−</mml:mo><mml:msup><mml:mi>w</mml:mi><mml:mn>2</mml:mn></mml:msup><mml:msup><mml:mi>a</mml:mi><mml:mn>2</mml:mn></mml:msup><mml:mo stretchy="false">)</mml:mo><mml:mi>a</mml:mi><mml:mo stretchy="false">]</mml:mo><mml:mspace width="1em"/><mml:mrow class="MJX-TeXAtom-ORD"><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mspace width="1em"/><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi mathvariant="double-struck">E</mml:mi></mml:mrow><mml:mo stretchy="false">[</mml:mo><mml:mrow class="MJX-TeXAtom-ORD"><mml:mover><mml:mi>s</mml:mi><mml:mo stretchy="false">~</mml:mo></mml:mover></mml:mrow><mml:mo stretchy="false">]</mml:mo><mml:mo>=</mml:mo><mml:mn>0</mml:mn></mml:mtd></mml:mtr></mml:mtable></mml:math></disp-formula><disp-formula id="equ40"><mml:math id="m40"><mml:mtable rowspacing="3pt" columnspacing="0em 2em 0em 2em 0em 2em 0em 2em 0em 2em 0em" displaystyle="true"><mml:mtr><mml:mtd/><mml:mtd><mml:mi/><mml:mo>=</mml:mo><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi mathvariant="double-struck">E</mml:mi></mml:mrow><mml:mo stretchy="false">[</mml:mo><mml:mi>η</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msup><mml:mi>β</mml:mi><mml:mn>2</mml:mn></mml:msup><mml:msup><mml:mi>w</mml:mi><mml:mn>2</mml:mn></mml:msup><mml:msup><mml:mi>a</mml:mi><mml:mn>2</mml:mn></mml:msup><mml:mo>−</mml:mo><mml:mn>2</mml:mn><mml:mi>β</mml:mi><mml:msup><mml:mi>w</mml:mi><mml:mn>2</mml:mn></mml:msup><mml:msup><mml:mi>a</mml:mi><mml:mn>2</mml:mn></mml:msup><mml:mo>+</mml:mo><mml:msup><mml:mi>β</mml:mi><mml:mn>2</mml:mn></mml:msup><mml:msubsup><mml:mi>w</mml:mi><mml:mi>s</mml:mi><mml:mn>2</mml:mn></mml:msubsup><mml:msup><mml:mrow class="MJX-TeXAtom-ORD"><mml:mover><mml:mi>s</mml:mi><mml:mo stretchy="false">~</mml:mo></mml:mover></mml:mrow><mml:mn>2</mml:mn></mml:msup><mml:mo stretchy="false">)</mml:mo><mml:mi>a</mml:mi><mml:mo stretchy="false">]</mml:mo></mml:mtd></mml:mtr></mml:mtable></mml:math></disp-formula><disp-formula id="equ41"><mml:math id="m41"><mml:mtable rowspacing="3pt" columnspacing="0em 2em 0em 2em 0em 2em 0em 2em 0em 2em 0em" displaystyle="true"><mml:mtr><mml:mtd/><mml:mtd><mml:mi/><mml:mo>=</mml:mo><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi mathvariant="double-struck">E</mml:mi></mml:mrow><mml:mo stretchy="false">[</mml:mo><mml:mi>η</mml:mi><mml:mi>β</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>β</mml:mi><mml:msup><mml:mi>w</mml:mi><mml:mn>2</mml:mn></mml:msup><mml:msup><mml:mi>a</mml:mi><mml:mn>2</mml:mn></mml:msup><mml:mo>−</mml:mo><mml:mn>2</mml:mn><mml:msup><mml:mi>w</mml:mi><mml:mn>2</mml:mn></mml:msup><mml:msup><mml:mi>a</mml:mi><mml:mn>2</mml:mn></mml:msup><mml:mo>+</mml:mo><mml:mi>β</mml:mi><mml:msubsup><mml:mi>w</mml:mi><mml:mi>s</mml:mi><mml:mn>2</mml:mn></mml:msubsup><mml:msup><mml:mrow class="MJX-TeXAtom-ORD"><mml:mover><mml:mi>s</mml:mi><mml:mo stretchy="false">~</mml:mo></mml:mover></mml:mrow><mml:mn>2</mml:mn></mml:msup><mml:mo stretchy="false">)</mml:mo><mml:mi>a</mml:mi><mml:mo stretchy="false">]</mml:mo></mml:mtd></mml:mtr></mml:mtable></mml:math></disp-formula><disp-formula id="equ42"><mml:math id="m42"><mml:mtable rowspacing="3pt" columnspacing="0em 2em 0em 2em 0em 2em 0em 2em 0em 2em 0em" displaystyle="true"><mml:mtr><mml:mtd/><mml:mtd><mml:mi/><mml:mo>=</mml:mo><mml:mi>η</mml:mi><mml:mi>β</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mi>β</mml:mi><mml:mo>−</mml:mo><mml:mn>2</mml:mn><mml:mo stretchy="false">)</mml:mo><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi mathvariant="double-struck">E</mml:mi></mml:mrow><mml:mo stretchy="false">[</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mi>w</mml:mi><mml:mi>a</mml:mi><mml:msup><mml:mo stretchy="false">)</mml:mo><mml:mn>2</mml:mn></mml:msup><mml:mo stretchy="false">]</mml:mo><mml:mo>+</mml:mo><mml:mi>β</mml:mi><mml:msubsup><mml:mi>w</mml:mi><mml:mi>s</mml:mi><mml:mn>2</mml:mn></mml:msubsup><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi mathvariant="double-struck">E</mml:mi></mml:mrow><mml:mo stretchy="false">[</mml:mo><mml:msup><mml:mrow class="MJX-TeXAtom-ORD"><mml:mover><mml:mi>s</mml:mi><mml:mo stretchy="false">~</mml:mo></mml:mover></mml:mrow><mml:mn>2</mml:mn></mml:msup><mml:mo stretchy="false">]</mml:mo><mml:mo stretchy="false">)</mml:mo><mml:mi>a</mml:mi><mml:mspace width="1em"/><mml:mrow class="MJX-TeXAtom-ORD"><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mspace width="1em"/><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi mathvariant="double-struck">E</mml:mi></mml:mrow><mml:mo stretchy="false">[</mml:mo><mml:msup><mml:mrow class="MJX-TeXAtom-ORD"><mml:mover><mml:mi>s</mml:mi><mml:mo stretchy="false">~</mml:mo></mml:mover></mml:mrow><mml:mn>2</mml:mn></mml:msup><mml:mo stretchy="false">]</mml:mo><mml:mo>=</mml:mo><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi mathvariant="double-struck">E</mml:mi></mml:mrow><mml:mo stretchy="false">[</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mi>s</mml:mi><mml:mo>−</mml:mo><mml:mi>μ</mml:mi><mml:msup><mml:mo stretchy="false">)</mml:mo><mml:mn>2</mml:mn></mml:msup><mml:mo stretchy="false">]</mml:mo><mml:mo>=</mml:mo><mml:msup><mml:mi>σ</mml:mi><mml:mn>2</mml:mn></mml:msup></mml:mtd></mml:mtr></mml:mtable></mml:math></disp-formula><disp-formula id="equ43"><mml:math id="m43"><mml:mtable rowspacing="3pt" columnspacing="0em 2em 0em 2em 0em 2em 0em 2em 0em 2em 0em" displaystyle="true"><mml:mtr><mml:mtd/><mml:mtd><mml:mi/><mml:mo>=</mml:mo><mml:mi>η</mml:mi><mml:mi>β</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mi>β</mml:mi><mml:mo>−</mml:mo><mml:mn>2</mml:mn><mml:mo stretchy="false">)</mml:mo><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi mathvariant="double-struck">E</mml:mi></mml:mrow><mml:mo stretchy="false">[</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mi>w</mml:mi><mml:mi>a</mml:mi><mml:msup><mml:mo stretchy="false">)</mml:mo><mml:mn>2</mml:mn></mml:msup><mml:mo stretchy="false">]</mml:mo><mml:mo>+</mml:mo><mml:mi>β</mml:mi><mml:msubsup><mml:mi>w</mml:mi><mml:mi>s</mml:mi><mml:mn>2</mml:mn></mml:msubsup><mml:msup><mml:mi>σ</mml:mi><mml:mn>2</mml:mn></mml:msup><mml:mo stretchy="false">)</mml:mo><mml:mi>a</mml:mi></mml:mtd></mml:mtr></mml:mtable></mml:math></disp-formula></p><p>Given our objective <inline-formula><mml:math id="inf221"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mrow><mml:mi mathvariant="double-struck">E</mml:mi></mml:mrow><mml:mo stretchy="false">[</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mi>w</mml:mi><mml:mi>a</mml:mi><mml:msup><mml:mo stretchy="false">)</mml:mo><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup><mml:mo stretchy="false">]</mml:mo><mml:mo>=</mml:mo><mml:msup><mml:mi>σ</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:mstyle></mml:math></inline-formula>, we can write:<disp-formula id="equ44"><mml:math id="m44"><mml:mtable rowspacing="3pt" columnspacing="0em 2em 0em 2em 0em 2em 0em 2em 0em 2em 0em" displaystyle="true"><mml:mtr><mml:mtd><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi mathvariant="double-struck">E</mml:mi></mml:mrow><mml:mo stretchy="false">[</mml:mo><mml:mi mathvariant="normal">Δ</mml:mi><mml:mi>w</mml:mi><mml:mo stretchy="false">]</mml:mo><mml:mo>=</mml:mo><mml:mi>η</mml:mi><mml:mi>β</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mi>β</mml:mi><mml:mo>−</mml:mo><mml:mn>2</mml:mn><mml:mo stretchy="false">)</mml:mo><mml:msup><mml:mi>σ</mml:mi><mml:mn>2</mml:mn></mml:msup><mml:mo>+</mml:mo><mml:mi>β</mml:mi><mml:msubsup><mml:mi>w</mml:mi><mml:mi>s</mml:mi><mml:mn>2</mml:mn></mml:msubsup><mml:msup><mml:mi>σ</mml:mi><mml:mn>2</mml:mn></mml:msup><mml:mo stretchy="false">)</mml:mo><mml:mi>a</mml:mi></mml:mtd></mml:mtr></mml:mtable></mml:math></disp-formula></p><p>Then for <inline-formula><mml:math id="inf222"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mrow><mml:mi mathvariant="double-struck">E</mml:mi></mml:mrow><mml:mo stretchy="false">[</mml:mo><mml:mi mathvariant="normal">Δ</mml:mi><mml:mi>w</mml:mi><mml:mo stretchy="false">]</mml:mo><mml:mo>=</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:mstyle></mml:math></inline-formula>:<disp-formula id="equ45"><mml:math id="m45"><mml:mtable rowspacing="3pt" columnspacing="0em 2em 0em 2em 0em 2em 0em 2em 0em 2em 0em" displaystyle="true"><mml:mtr><mml:mtd><mml:mn>0</mml:mn></mml:mtd><mml:mtd><mml:mi/><mml:mo>=</mml:mo><mml:mi>β</mml:mi><mml:mo>−</mml:mo><mml:mn>2</mml:mn><mml:mo>+</mml:mo><mml:mi>β</mml:mi><mml:msubsup><mml:mi>w</mml:mi><mml:mi>s</mml:mi><mml:mn>2</mml:mn></mml:msubsup></mml:mtd></mml:mtr></mml:mtable></mml:math></disp-formula><disp-formula id="equ46"><mml:math id="m46"><mml:mtable rowspacing="3pt" columnspacing="0em 2em 0em 2em 0em 2em 0em 2em 0em 2em 0em" displaystyle="true"><mml:mtr><mml:mtd><mml:mo stretchy="false">⇒</mml:mo><mml:msub><mml:mi>w</mml:mi><mml:mi>s</mml:mi></mml:msub></mml:mtd><mml:mtd><mml:mi/><mml:mo>=</mml:mo><mml:msqrt><mml:mfrac><mml:mrow><mml:mn>2</mml:mn><mml:mo>−</mml:mo><mml:mi>β</mml:mi></mml:mrow><mml:mi>β</mml:mi></mml:mfrac></mml:msqrt></mml:mtd></mml:mtr></mml:mtable></mml:math></disp-formula></p><p>Here, we assumed that <inline-formula><mml:math id="inf223"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>ϕ</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>u</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:msup><mml:mi>u</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:mstyle></mml:math></inline-formula> instead of <inline-formula><mml:math id="inf224"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>ϕ</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>u</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mo fence="false" stretchy="false">⌊</mml:mo><mml:mi>u</mml:mi><mml:msup><mml:mo fence="false" stretchy="false">⌋</mml:mo><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:mstyle></mml:math></inline-formula>. To test how well this approximation holds, we simulated the circuit for different values of <inline-formula><mml:math id="inf225"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>β</mml:mi></mml:mrow></mml:mstyle></mml:math></inline-formula> and hence <inline-formula><mml:math id="inf226"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>w</mml:mi><mml:mrow><mml:mi>s</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula>, and plotted the PV firing rate <inline-formula><mml:math id="inf227"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>r</mml:mi><mml:mrow><mml:mrow><mml:mi mathvariant="normal">P</mml:mi><mml:mi mathvariant="normal">V</mml:mi></mml:mrow></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>a</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mstyle></mml:math></inline-formula> given the sound input <inline-formula><mml:math id="inf228"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>a</mml:mi></mml:mrow></mml:mstyle></mml:math></inline-formula> and the weight from <inline-formula><mml:math id="inf229"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>a</mml:mi></mml:mrow></mml:mstyle></mml:math></inline-formula> to PV, <inline-formula><mml:math id="inf230"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>w</mml:mi><mml:mrow><mml:mrow><mml:mi mathvariant="normal">P</mml:mi><mml:mi mathvariant="normal">V</mml:mi></mml:mrow><mml:mo>,</mml:mo><mml:mi>a</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula>, for different values of <inline-formula><mml:math id="inf231"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>β</mml:mi></mml:mrow></mml:mstyle></mml:math></inline-formula> (<xref ref-type="fig" rid="fig9">Figure 9</xref>). This analysis shows that the approximation holds for small <inline-formula><mml:math id="inf232"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>β</mml:mi></mml:mrow></mml:mstyle></mml:math></inline-formula> up to a value of <inline-formula><mml:math id="inf233"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>β</mml:mi><mml:mo>=</mml:mo><mml:mn>0.2</mml:mn></mml:mrow></mml:mstyle></mml:math></inline-formula>.</p><fig id="fig9" position="float"><label>Figure 9.</label><caption><title>For small <inline-formula><mml:math id="inf234"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>β</mml:mi></mml:mrow></mml:mstyle></mml:math></inline-formula>, and <inline-formula><mml:math id="inf235"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>w</mml:mi><mml:mrow><mml:mi>s</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:msqrt><mml:mfrac><mml:mrow><mml:mn>2</mml:mn><mml:mo>−</mml:mo><mml:mi>β</mml:mi></mml:mrow><mml:mi>β</mml:mi></mml:mfrac></mml:msqrt></mml:mrow></mml:mstyle></mml:math></inline-formula>, the weight from <inline-formula><mml:math id="inf236"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>a</mml:mi></mml:mrow></mml:mstyle></mml:math></inline-formula> to PV approaches <inline-formula><mml:math id="inf237"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>σ</mml:mi></mml:mrow></mml:mstyle></mml:math></inline-formula> and the PV firing rate approaches <inline-formula><mml:math id="inf238"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msup><mml:mi>σ</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:mstyle></mml:math></inline-formula>.</title></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-95127-fig9-v1.tif"/></fig><p>We initialised the circuits with the initial weight configuration in <xref ref-type="table" rid="table1">Table 1</xref> and <xref ref-type="table" rid="table2">Table 2</xref>, and neural firing rates were initialised to be 0 (<inline-formula><mml:math id="inf239"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>r</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mn>0</mml:mn><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:mstyle></mml:math></inline-formula> with <inline-formula><mml:math id="inf240"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>i</mml:mi><mml:mo>∈</mml:mo><mml:mo stretchy="false">[</mml:mo><mml:msup><mml:mrow><mml:mi mathvariant="normal">S</mml:mi><mml:mi mathvariant="normal">S</mml:mi><mml:mi mathvariant="normal">T</mml:mi></mml:mrow><mml:mrow><mml:mo>+</mml:mo></mml:mrow></mml:msup><mml:mo>,</mml:mo><mml:msup><mml:mrow><mml:mi mathvariant="normal">S</mml:mi><mml:mi mathvariant="normal">S</mml:mi><mml:mi mathvariant="normal">T</mml:mi></mml:mrow><mml:mrow><mml:mo>−</mml:mo></mml:mrow></mml:msup><mml:mo>,</mml:mo><mml:msup><mml:mrow><mml:mi mathvariant="normal">P</mml:mi><mml:mi mathvariant="normal">V</mml:mi></mml:mrow><mml:mrow><mml:mo>+</mml:mo></mml:mrow></mml:msup><mml:mo>,</mml:mo><mml:msup><mml:mrow><mml:mi mathvariant="normal">P</mml:mi><mml:mi mathvariant="normal">V</mml:mi></mml:mrow><mml:mrow><mml:mo>−</mml:mo></mml:mrow></mml:msup><mml:mo>,</mml:mo><mml:msup><mml:mrow><mml:mi mathvariant="normal">U</mml:mi><mml:mi mathvariant="normal">P</mml:mi><mml:mi mathvariant="normal">E</mml:mi></mml:mrow><mml:mrow><mml:mo>+</mml:mo></mml:mrow></mml:msup><mml:mo>,</mml:mo><mml:msup><mml:mrow><mml:mi mathvariant="normal">U</mml:mi><mml:mi mathvariant="normal">P</mml:mi><mml:mi mathvariant="normal">E</mml:mi></mml:mrow><mml:mrow><mml:mo>−</mml:mo></mml:mrow></mml:msup><mml:mo>,</mml:mo><mml:mrow><mml:mi mathvariant="normal">R</mml:mi></mml:mrow><mml:mo stretchy="false">]</mml:mo></mml:mrow></mml:mstyle></mml:math></inline-formula>). We then paired a constant tone input with N samples from the whisker stimulus distribution, the parameters of which we varied and are indicated in each Figure. Each whisker stimulus intensity was presented for <inline-formula><mml:math id="inf241"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>D</mml:mi></mml:mrow></mml:mstyle></mml:math></inline-formula> timesteps (see <xref ref-type="table" rid="table3">Table 3</xref>). Parameters of the plasticity rules can be found in <xref ref-type="table" rid="table4">Table 4</xref>. All simulations were written in Python. Differential equations were numerically integrated with a time step of <inline-formula><mml:math id="inf242"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>d</mml:mi><mml:mi>t</mml:mi><mml:mo>=</mml:mo><mml:mn>0.1</mml:mn></mml:mrow></mml:mstyle></mml:math></inline-formula>. Parameters of the simulations can be found in <xref ref-type="table" rid="table5 table6">Tables 5 and 6</xref>.</p><table-wrap id="table2" position="float"><label>Table 2.</label><caption><title>Additional parameters of the hierarchical network.</title></caption><table frame="hsides" rules="groups"><thead><tr><th align="left" valign="bottom">Parameter</th><th align="left" valign="bottom">Value</th><th align="left" valign="bottom">Description</th></tr></thead><tbody><tr><td align="left" valign="bottom"><inline-formula><mml:math id="inf243"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>w</mml:mi><mml:mrow><mml:mrow><mml:mi mathvariant="normal">R</mml:mi></mml:mrow><mml:mo>,</mml:mo><mml:msubsup><mml:mrow><mml:mi mathvariant="normal">U</mml:mi><mml:mi mathvariant="normal">P</mml:mi><mml:mi mathvariant="normal">E</mml:mi></mml:mrow><mml:mrow><mml:mi>ℓ</mml:mi></mml:mrow><mml:mrow><mml:mo>+</mml:mo></mml:mrow></mml:msubsup></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula></td><td align="left" valign="bottom">1.0</td><td align="left" valign="bottom">Weight from <inline-formula><mml:math id="inf244"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msubsup><mml:mtext>UPE</mml:mtext><mml:mrow><mml:mi>ℓ</mml:mi></mml:mrow><mml:mrow><mml:mo>+</mml:mo></mml:mrow></mml:msubsup></mml:mrow></mml:mstyle></mml:math></inline-formula> to <inline-formula><mml:math id="inf245"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mrow><mml:mi mathvariant="normal">R</mml:mi></mml:mrow></mml:mrow></mml:mstyle></mml:math></inline-formula></td></tr><tr><td align="left" valign="bottom"><inline-formula><mml:math id="inf246"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>w</mml:mi><mml:mrow><mml:mrow><mml:mi mathvariant="normal">R</mml:mi></mml:mrow><mml:mo>,</mml:mo><mml:msubsup><mml:mrow><mml:mi mathvariant="normal">U</mml:mi><mml:mi mathvariant="normal">P</mml:mi><mml:mi mathvariant="normal">E</mml:mi></mml:mrow><mml:mrow><mml:mi>ℓ</mml:mi></mml:mrow><mml:mrow><mml:mo>−</mml:mo></mml:mrow></mml:msubsup></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula></td><td align="left" valign="bottom">1.0</td><td align="left" valign="bottom">Weight from <inline-formula><mml:math id="inf247"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msubsup><mml:mtext>UPE</mml:mtext><mml:mrow><mml:mi>ℓ</mml:mi></mml:mrow><mml:mrow><mml:mo>−</mml:mo></mml:mrow></mml:msubsup></mml:mrow></mml:mstyle></mml:math></inline-formula> to <inline-formula><mml:math id="inf248"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mrow><mml:mi mathvariant="normal">R</mml:mi></mml:mrow></mml:mrow></mml:mstyle></mml:math></inline-formula></td></tr><tr><td align="left" valign="bottom"><inline-formula><mml:math id="inf249"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>w</mml:mi><mml:mrow><mml:msubsup><mml:mrow><mml:mi mathvariant="normal">U</mml:mi><mml:mi mathvariant="normal">P</mml:mi><mml:mi mathvariant="normal">E</mml:mi></mml:mrow><mml:mrow><mml:mi>ℓ</mml:mi></mml:mrow><mml:mrow><mml:mo>−</mml:mo></mml:mrow></mml:msubsup><mml:mo>,</mml:mo><mml:mrow><mml:mi mathvariant="normal">R</mml:mi></mml:mrow></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula></td><td align="left" valign="bottom">1.0</td><td align="left" valign="bottom">Weight from <inline-formula><mml:math id="inf250"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mrow><mml:mi mathvariant="normal">R</mml:mi></mml:mrow></mml:mrow></mml:mstyle></mml:math></inline-formula> to <inline-formula><mml:math id="inf251"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msubsup><mml:mtext>UPE</mml:mtext><mml:mrow><mml:mi>ℓ</mml:mi></mml:mrow><mml:mrow><mml:mo>−</mml:mo></mml:mrow></mml:msubsup></mml:mrow></mml:mstyle></mml:math></inline-formula></td></tr><tr><td align="left" valign="bottom"><inline-formula><mml:math id="inf252"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>w</mml:mi><mml:mrow><mml:msup><mml:mrow><mml:mi mathvariant="normal">U</mml:mi><mml:mi mathvariant="normal">P</mml:mi><mml:mi mathvariant="normal">E</mml:mi></mml:mrow><mml:mrow><mml:mo>−</mml:mo></mml:mrow></mml:msup><mml:mo>,</mml:mo><mml:mrow><mml:mi mathvariant="normal">p</mml:mi><mml:mi mathvariant="normal">r</mml:mi><mml:mi mathvariant="normal">i</mml:mi><mml:mi mathvariant="normal">o</mml:mi><mml:mi mathvariant="normal">r</mml:mi></mml:mrow></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula></td><td align="left" valign="bottom">1.0</td><td align="left" valign="bottom">Weight from <inline-formula><mml:math id="inf253"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mrow><mml:mi mathvariant="normal">R</mml:mi></mml:mrow></mml:mrow></mml:mstyle></mml:math></inline-formula> to <inline-formula><mml:math id="inf254"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msup><mml:mtext>UPE</mml:mtext><mml:mrow><mml:mo>−</mml:mo></mml:mrow></mml:msup></mml:mrow></mml:mstyle></mml:math></inline-formula></td></tr></tbody></table></table-wrap><table-wrap id="table3" position="float"><label>Table 3.</label><caption><title>Inputs.</title></caption><table frame="hsides" rules="groups"><thead><tr><th align="left" valign="bottom">Parameter</th><th align="left" valign="bottom">Value</th><th align="left" valign="bottom">Description</th></tr></thead><tbody><tr><td align="left" valign="bottom">a</td><td align="left" valign="bottom">{0.0, 1.0}</td><td align="left" valign="bottom">Auditory stimulus (on/off)</td></tr><tr><td align="left" valign="bottom"><inline-formula><mml:math id="inf255"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>s</mml:mi></mml:mrow></mml:mstyle></mml:math></inline-formula></td><td align="left" valign="bottom"><inline-formula><mml:math id="inf256"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mo>∼</mml:mo><mml:mrow><mml:mi class="mathcal" mathvariant="script">N</mml:mi></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>μ</mml:mi><mml:mo>,</mml:mo><mml:mi>σ</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mstyle></mml:math></inline-formula></td><td align="left" valign="bottom">Somatosensory (whisker) stimulus</td></tr><tr><td align="left" valign="bottom"><inline-formula><mml:math id="inf257"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>N</mml:mi></mml:mrow></mml:mstyle></mml:math></inline-formula></td><td align="left" valign="bottom">1000–20,000</td><td align="left" valign="bottom">Number of whisker stimulus samples</td></tr><tr><td align="left" valign="bottom"><inline-formula><mml:math id="inf258"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>D</mml:mi></mml:mrow></mml:mstyle></mml:math></inline-formula></td><td align="left" valign="bottom">{10, 100}</td><td align="left" valign="bottom">Stimulus duration (<xref ref-type="fig" rid="fig1">Figures 1</xref>—<xref ref-type="fig" rid="fig5">5</xref> and <xref ref-type="fig" rid="fig7">7</xref>)</td></tr></tbody></table></table-wrap><table-wrap id="table4" position="float"><label>Table 4.</label><caption><title>Parameters of the plasticity rules.</title></caption><table frame="hsides" rules="groups"><thead><tr><th align="left" valign="bottom">Parameter</th><th align="left" valign="bottom">Value</th><th align="left" valign="bottom">Description</th></tr></thead><tbody><tr><td align="left" valign="bottom"><inline-formula><mml:math id="inf259"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>η</mml:mi><mml:mrow><mml:mrow><mml:mi mathvariant="normal">S</mml:mi><mml:mi mathvariant="normal">S</mml:mi><mml:mi mathvariant="normal">T</mml:mi></mml:mrow></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula></td><td align="left" valign="bottom">0.1</td><td align="left" valign="bottom">Learning rate for <inline-formula><mml:math id="inf260"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>w</mml:mi><mml:mrow><mml:msup><mml:mrow><mml:mi mathvariant="normal">S</mml:mi><mml:mi mathvariant="normal">S</mml:mi><mml:mi mathvariant="normal">T</mml:mi></mml:mrow><mml:mrow><mml:mo>+</mml:mo><mml:mrow><mml:mo>/</mml:mo></mml:mrow><mml:mo>−</mml:mo></mml:mrow></mml:msup><mml:mo>,</mml:mo><mml:mrow><mml:mi mathvariant="normal">a</mml:mi></mml:mrow></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula></td></tr><tr><td align="left" valign="bottom"><inline-formula><mml:math id="inf261"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>η</mml:mi><mml:mrow><mml:mrow><mml:mi mathvariant="normal">P</mml:mi><mml:mi mathvariant="normal">V</mml:mi></mml:mrow></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula></td><td align="left" valign="bottom"><inline-formula><mml:math id="inf262"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mn>0.01</mml:mn><mml:mo>∗</mml:mo><mml:msub><mml:mi>η</mml:mi><mml:mrow><mml:mrow><mml:mi mathvariant="normal">R</mml:mi></mml:mrow></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mn>0.001</mml:mn></mml:mrow></mml:mstyle></mml:math></inline-formula></td><td align="left" valign="bottom">Learning rate for <inline-formula><mml:math id="inf263"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>w</mml:mi><mml:mrow><mml:msup><mml:mrow><mml:mi mathvariant="normal">P</mml:mi><mml:mi mathvariant="normal">V</mml:mi></mml:mrow><mml:mrow><mml:mo>+</mml:mo><mml:mrow><mml:mo>/</mml:mo></mml:mrow><mml:mo>−</mml:mo></mml:mrow></mml:msup><mml:mo>,</mml:mo><mml:mrow><mml:mi mathvariant="normal">a</mml:mi></mml:mrow></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula></td></tr><tr><td align="left" valign="bottom"><inline-formula><mml:math id="inf264"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>η</mml:mi><mml:mrow><mml:mrow><mml:mi mathvariant="normal">R</mml:mi></mml:mrow></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula></td><td align="left" valign="bottom">0.1</td><td align="left" valign="bottom">Learning rate for <inline-formula><mml:math id="inf265"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>w</mml:mi><mml:mrow><mml:mrow><mml:mi mathvariant="normal">R</mml:mi></mml:mrow><mml:mo>,</mml:mo><mml:mtext>a</mml:mtext></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula></td></tr><tr><td align="left" valign="bottom"><inline-formula><mml:math id="inf266"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msubsup><mml:mi>w</mml:mi><mml:mrow><mml:mrow><mml:mi mathvariant="normal">S</mml:mi><mml:mi mathvariant="normal">S</mml:mi><mml:mi mathvariant="normal">T</mml:mi></mml:mrow><mml:mo>,</mml:mo><mml:mrow><mml:mi mathvariant="normal">a</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:mrow><mml:mi mathvariant="normal">i</mml:mi><mml:mi mathvariant="normal">n</mml:mi><mml:mi mathvariant="normal">i</mml:mi><mml:mi mathvariant="normal">t</mml:mi><mml:mi mathvariant="normal">i</mml:mi><mml:mi mathvariant="normal">a</mml:mi><mml:mi mathvariant="normal">l</mml:mi></mml:mrow></mml:mrow></mml:msubsup></mml:mrow></mml:mstyle></mml:math></inline-formula></td><td align="left" valign="bottom">0.01</td><td align="left" valign="bottom">Initial value for <inline-formula><mml:math id="inf267"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>w</mml:mi><mml:mrow><mml:msup><mml:mrow><mml:mi mathvariant="normal">S</mml:mi><mml:mi mathvariant="normal">S</mml:mi><mml:mi mathvariant="normal">T</mml:mi></mml:mrow><mml:mrow><mml:mo>+</mml:mo><mml:mrow><mml:mo>/</mml:mo></mml:mrow><mml:mo>−</mml:mo></mml:mrow></mml:msup><mml:mo>,</mml:mo><mml:mtext>a</mml:mtext></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula></td></tr><tr><td align="left" valign="bottom"><inline-formula><mml:math id="inf268"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msubsup><mml:mi>w</mml:mi><mml:mrow><mml:mrow><mml:mi mathvariant="normal">P</mml:mi><mml:mi mathvariant="normal">V</mml:mi></mml:mrow><mml:mo>,</mml:mo><mml:mrow><mml:mi mathvariant="normal">a</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:mrow><mml:mi mathvariant="normal">i</mml:mi><mml:mi mathvariant="normal">n</mml:mi><mml:mi mathvariant="normal">i</mml:mi><mml:mi mathvariant="normal">t</mml:mi><mml:mi mathvariant="normal">i</mml:mi><mml:mi mathvariant="normal">a</mml:mi><mml:mi mathvariant="normal">l</mml:mi></mml:mrow></mml:mrow></mml:msubsup></mml:mrow></mml:mstyle></mml:math></inline-formula></td><td align="left" valign="bottom">0.01</td><td align="left" valign="bottom">Initial value for <inline-formula><mml:math id="inf269"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>d</mml:mi><mml:mi>t</mml:mi><mml:mo>=</mml:mo><mml:mn>0.1</mml:mn></mml:mrow></mml:mstyle></mml:math></inline-formula></td></tr><tr><td align="left" valign="bottom"><inline-formula><mml:math id="inf270"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msubsup><mml:mi>w</mml:mi><mml:mrow><mml:mrow><mml:mi mathvariant="normal">R</mml:mi></mml:mrow><mml:mo>,</mml:mo><mml:mrow><mml:mi mathvariant="normal">a</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:mrow><mml:mi mathvariant="normal">i</mml:mi><mml:mi mathvariant="normal">n</mml:mi><mml:mi mathvariant="normal">i</mml:mi><mml:mi mathvariant="normal">t</mml:mi><mml:mi mathvariant="normal">i</mml:mi><mml:mi mathvariant="normal">a</mml:mi><mml:mi mathvariant="normal">l</mml:mi></mml:mrow></mml:mrow></mml:msubsup></mml:mrow></mml:mstyle></mml:math></inline-formula></td><td align="left" valign="bottom">0.01</td><td align="left" valign="bottom">Initial value for <inline-formula><mml:math id="inf271"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>w</mml:mi><mml:mrow><mml:mrow><mml:mi mathvariant="normal">R</mml:mi></mml:mrow><mml:mo>,</mml:mo><mml:mtext>a</mml:mtext></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula></td></tr></tbody></table></table-wrap><table-wrap id="table5" position="float"><label>Table 5.</label><caption><title>Parameters of simulations in <xref ref-type="fig" rid="fig2">Figures 2</xref>—<xref ref-type="fig" rid="fig5">5</xref>.</title></caption><table frame="hsides" rules="groups"><thead><tr><th align="left" valign="bottom">Parameter</th><th align="left" valign="bottom">Value</th><th align="left" valign="bottom">Description</th></tr></thead><tbody><tr><td align="left" valign="bottom"><inline-formula><mml:math id="inf272"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>T</mml:mi></mml:mrow></mml:mstyle></mml:math></inline-formula></td><td align="left" valign="bottom"><inline-formula><mml:math id="inf273"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>N</mml:mi><mml:mo>∗</mml:mo><mml:mi>D</mml:mi></mml:mrow></mml:mstyle></mml:math></inline-formula></td><td align="left" valign="bottom">Simulation time</td></tr><tr><td align="left" valign="bottom"><inline-formula><mml:math id="inf274"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>d</mml:mi><mml:mi>t</mml:mi></mml:mrow></mml:mstyle></mml:math></inline-formula></td><td align="left" valign="bottom">0.1</td><td align="left" valign="bottom">Simulation time step</td></tr><tr><td align="left" valign="bottom"><inline-formula><mml:math id="inf275"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>τ</mml:mi><mml:mrow><mml:mi>E</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula></td><td align="left" valign="bottom">1.0</td><td align="left" valign="bottom">Excitatory membrane time constant</td></tr><tr><td align="left" valign="bottom"><inline-formula><mml:math id="inf276"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>τ</mml:mi><mml:mrow><mml:mi>I</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula></td><td align="left" valign="bottom">1.0</td><td align="left" valign="bottom">Inhibitory membrane time constant</td></tr></tbody></table></table-wrap><table-wrap id="table6" position="float"><label>Table 6.</label><caption><title>Parameters of the simulation in <xref ref-type="fig" rid="fig6">Figure 6</xref>.</title></caption><table frame="hsides" rules="groups"><thead><tr><th align="left" valign="bottom">Parameter</th><th align="left" valign="bottom">Value</th><th align="left" valign="bottom">Description</th></tr></thead><tbody><tr><td align="left" valign="bottom"><inline-formula><mml:math id="inf277"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>T</mml:mi></mml:mrow></mml:mstyle></mml:math></inline-formula></td><td align="left" valign="bottom"><inline-formula><mml:math id="inf278"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>N</mml:mi><mml:mo>∗</mml:mo><mml:mi>D</mml:mi></mml:mrow></mml:mstyle></mml:math></inline-formula></td><td align="left" valign="bottom">Simulation time</td></tr><tr><td align="left" valign="bottom"><inline-formula><mml:math id="inf279"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>d</mml:mi><mml:mi>t</mml:mi></mml:mrow></mml:mstyle></mml:math></inline-formula></td><td align="left" valign="bottom">0.1</td><td align="left" valign="bottom">Simulation time step</td></tr><tr><td align="left" valign="bottom"><inline-formula><mml:math id="inf280"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>τ</mml:mi><mml:mrow><mml:mi>E</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula></td><td align="left" valign="bottom">10.0</td><td align="left" valign="bottom">Excitatory membrane time constant</td></tr><tr><td align="left" valign="bottom"><inline-formula><mml:math id="inf281"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>τ</mml:mi><mml:mrow><mml:mi>I</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula></td><td align="left" valign="bottom">2.0</td><td align="left" valign="bottom">Inhibitory membrane time constant</td></tr><tr><td align="left" valign="bottom"><inline-formula><mml:math id="inf282"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>η</mml:mi><mml:mrow><mml:mi>R</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula></td><td align="left" valign="bottom">0.01</td><td align="left" valign="bottom">Learning rate of <inline-formula><mml:math id="inf283"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>w</mml:mi><mml:mrow><mml:mi>R</mml:mi><mml:mo>,</mml:mo><mml:mi>A</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula></td></tr></tbody></table></table-wrap><p>Eliciting responses to mismatches (<xref ref-type="fig" rid="fig4">Figure 4</xref> and <xref ref-type="fig" rid="fig6">Figure 6</xref>).</p><p>We first trained the circuit with 10,000 stimulus samples to learn the variances in the a-to-PV weights. Then we presented different mismatch stimuli to calculate the error magnitude for each mismatch of magnitude <inline-formula><mml:math id="inf284"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>s</mml:mi><mml:mo>−</mml:mo><mml:mi>μ</mml:mi></mml:mrow></mml:mstyle></mml:math></inline-formula>.</p><p>Comparing the UPE circuit with an unmodulated circuit (<xref ref-type="fig" rid="fig7">Figure 7</xref>).</p><p>To ensure a fair comparison, the unmodulated control has an effective learning rate that is the mean of the two effective learning rates in the uncertainty-modulated case.</p></sec></sec></body><back><sec sec-type="additional-information" id="s5"><title>Additional information</title><fn-group content-type="competing-interest"><title>Competing interests</title><fn fn-type="COI-statement" id="conf1"><p>No competing interests declared</p></fn></fn-group><fn-group content-type="author-contribution"><title>Author contributions</title><fn fn-type="con" id="con1"><p>Conceptualization, Resources, Data curation, Software, Formal analysis, Validation, Investigation, Visualization, Methodology, Writing - original draft, Project administration, Writing - review and editing</p></fn><fn fn-type="con" id="con2"><p>Formal analysis, Methodology, Writing - review and editing</p></fn><fn fn-type="con" id="con3"><p>Resources, Data curation, Funding acquisition</p></fn><fn fn-type="con" id="con4"><p>Formal analysis, Supervision, Funding acquisition, Writing - review and editing</p></fn></fn-group></sec><sec sec-type="supplementary-material" id="s6"><title>Additional files</title><supplementary-material id="mdar"><label>MDAR checklist</label><media xlink:href="elife-95127-mdarchecklist1-v1.pdf" mimetype="application" mime-subtype="pdf"/></supplementary-material></sec><sec sec-type="data-availability" id="s7"><title>Data availability</title><p>The current manuscript is a computational study, so no data have been generated for this manuscript. All simulation code used for this paper is available on <ext-link ext-link-type="uri" xlink:href="https://github.com/k47h4/UPE">GitHub</ext-link>, copy archived at <xref ref-type="bibr" rid="bib82">Wilmes, 2025</xref>.</p></sec><ack id="ack"><title>Acknowledgements</title><p>We thank Loreen Hertäg and Jakob Jordan for helpful discussions and Loreen Hertäg and Sadra Sadeh for feedback on the manuscript. This work has received funding from the European Union 7th Framework Programme under grant agreement 604102 (HBP), the Horizon 2020 Framework Programme under grant agreements 720270, 785907 and 945539 (HBP) and the Manfred Stärk Foundation.</p></ack><ref-list><title>References</title><ref id="bib1"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Adesnik</surname><given-names>H</given-names></name><name><surname>Bruns</surname><given-names>W</given-names></name><name><surname>Taniguchi</surname><given-names>H</given-names></name><name><surname>Huang</surname><given-names>ZJ</given-names></name><name><surname>Scanziani</surname><given-names>M</given-names></name></person-group><year iso-8601-date="2012">2012</year><article-title>A neural circuit for spatial summation in visual cortex</article-title><source>Nature</source><volume>490</volume><fpage>226</fpage><lpage>231</lpage><pub-id pub-id-type="doi">10.1038/nature11526</pub-id><pub-id pub-id-type="pmid">23060193</pub-id></element-citation></ref><ref id="bib2"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Akrami</surname><given-names>A</given-names></name><name><surname>Kopec</surname><given-names>CD</given-names></name><name><surname>Diamond</surname><given-names>ME</given-names></name><name><surname>Brody</surname><given-names>CD</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>Posterior parietal cortex represents sensory history and mediates its effects on behaviour</article-title><source>Nature</source><volume>554</volume><fpage>368</fpage><lpage>372</lpage><pub-id pub-id-type="doi">10.1038/nature25510</pub-id><pub-id pub-id-type="pmid">29414944</pub-id></element-citation></ref><ref id="bib3"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ashourian</surname><given-names>P</given-names></name><name><surname>Loewenstein</surname><given-names>Y</given-names></name></person-group><year iso-8601-date="2011">2011</year><article-title>Bayesian inference underlies the contraction bias in delayed comparison tasks</article-title><source>PLOS ONE</source><volume>6</volume><elocation-id>e19551</elocation-id><pub-id pub-id-type="doi">10.1371/journal.pone.0019551</pub-id><pub-id pub-id-type="pmid">21589867</pub-id></element-citation></ref><ref id="bib4"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Attinger</surname><given-names>A</given-names></name><name><surname>Wang</surname><given-names>B</given-names></name><name><surname>Keller</surname><given-names>GB</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>Visuomotor coupling shapes the functional development of mouse visual cortex</article-title><source>Cell</source><volume>169</volume><fpage>1291</fpage><lpage>1302</lpage><pub-id pub-id-type="doi">10.1016/j.cell.2017.05.023</pub-id><pub-id pub-id-type="pmid">28602353</pub-id></element-citation></ref><ref id="bib5"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ayaz</surname><given-names>A</given-names></name><name><surname>Stäuble</surname><given-names>A</given-names></name><name><surname>Hamada</surname><given-names>M</given-names></name><name><surname>Wulf</surname><given-names>M-A</given-names></name><name><surname>Saleem</surname><given-names>AB</given-names></name><name><surname>Helmchen</surname><given-names>F</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>Layer-specific integration of locomotion and sensory information in mouse barrel cortex</article-title><source>Nature Communications</source><volume>10</volume><elocation-id>2585</elocation-id><pub-id pub-id-type="doi">10.1038/s41467-019-10564-8</pub-id><pub-id pub-id-type="pmid">31197148</pub-id></element-citation></ref><ref id="bib6"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Banaie Boroujeni</surname><given-names>K</given-names></name><name><surname>Tiesinga</surname><given-names>P</given-names></name><name><surname>Womelsdorf</surname><given-names>T</given-names></name></person-group><year iso-8601-date="2021">2021</year><article-title>Interneuron-specific gamma synchronization indexes cue uncertainty and prediction errors in lateral prefrontal and anterior cingulate cortex</article-title><source>eLife</source><volume>10</volume><elocation-id>e69111</elocation-id><pub-id pub-id-type="doi">10.7554/eLife.69111</pub-id><pub-id pub-id-type="pmid">34142661</pub-id></element-citation></ref><ref id="bib7"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Barry</surname><given-names>MLLR</given-names></name><name><surname>Gerstner</surname><given-names>W</given-names></name></person-group><year iso-8601-date="2024">2024</year><article-title>Fast adaptation to rule switching using neuronal surprise</article-title><source>PLOS Computational Biology</source><volume>20</volume><elocation-id>e1011839</elocation-id><pub-id pub-id-type="doi">10.1371/journal.pcbi.1011839</pub-id><pub-id pub-id-type="pmid">38377112</pub-id></element-citation></ref><ref id="bib8"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Berkes</surname><given-names>P</given-names></name><name><surname>Orbán</surname><given-names>G</given-names></name><name><surname>Lengyel</surname><given-names>M</given-names></name><name><surname>Fiser</surname><given-names>J</given-names></name></person-group><year iso-8601-date="2011">2011</year><article-title>Spontaneous cortical activity reveals hallmarks of an optimal internal model of the environment</article-title><source>Science</source><volume>331</volume><fpage>83</fpage><lpage>87</lpage><pub-id pub-id-type="doi">10.1126/science.1195870</pub-id><pub-id pub-id-type="pmid">21212356</pub-id></element-citation></ref><ref id="bib9"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Buesing</surname><given-names>L</given-names></name><name><surname>Bill</surname><given-names>J</given-names></name><name><surname>Nessler</surname><given-names>B</given-names></name><name><surname>Maass</surname><given-names>W</given-names></name></person-group><year iso-8601-date="2011">2011</year><article-title>Neural dynamics as sampling: a model for stochastic computation in recurrent networks of spiking neurons</article-title><source>PLOS Computational Biology</source><volume>7</volume><elocation-id>e1002211</elocation-id><pub-id pub-id-type="doi">10.1371/journal.pcbi.1002211</pub-id><pub-id pub-id-type="pmid">22096452</pub-id></element-citation></ref><ref id="bib10"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Cannon</surname><given-names>J</given-names></name><name><surname>O’Brien</surname><given-names>AM</given-names></name><name><surname>Bungert</surname><given-names>L</given-names></name><name><surname>Sinha</surname><given-names>P</given-names></name></person-group><year iso-8601-date="2021">2021</year><article-title>Prediction in autism spectrum disorder: a systematic review of empirical evidence</article-title><source>Autism Research</source><volume>14</volume><fpage>604</fpage><lpage>630</lpage><pub-id pub-id-type="doi">10.1002/aur.2482</pub-id><pub-id pub-id-type="pmid">33570249</pub-id></element-citation></ref><ref id="bib11"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Cohen</surname><given-names>MX</given-names></name><name><surname>Wilmes</surname><given-names>K</given-names></name><name><surname>van de Vijver</surname><given-names>I</given-names></name></person-group><year iso-8601-date="2011">2011</year><article-title>Cortical electrophysiological network dynamics of feedback learning</article-title><source>Trends in Cognitive Sciences</source><volume>15</volume><fpage>558</fpage><lpage>566</lpage><pub-id pub-id-type="doi">10.1016/j.tics.2011.10.004</pub-id><pub-id pub-id-type="pmid">22078930</pub-id></element-citation></ref><ref id="bib12"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Cornford</surname><given-names>JH</given-names></name><name><surname>Mercier</surname><given-names>MS</given-names></name><name><surname>Leite</surname><given-names>M</given-names></name><name><surname>Magloire</surname><given-names>V</given-names></name><name><surname>Häusser</surname><given-names>M</given-names></name><name><surname>Kullmann</surname><given-names>DM</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>Dendritic NMDA receptors in parvalbumin neurons enable strong and stable neuronal assemblies</article-title><source>eLife</source><volume>8</volume><elocation-id>e49872</elocation-id><pub-id pub-id-type="doi">10.7554/eLife.49872</pub-id><pub-id pub-id-type="pmid">31657720</pub-id></element-citation></ref><ref id="bib13"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Cottam</surname><given-names>JCH</given-names></name><name><surname>Smith</surname><given-names>SL</given-names></name><name><surname>Häusser</surname><given-names>M</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>Target-specific effects of somatostatin-expressing interneurons on neocortical visual processing</article-title><source>The Journal of Neuroscience</source><volume>33</volume><fpage>19567</fpage><lpage>19578</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.2624-13.2013</pub-id><pub-id pub-id-type="pmid">24336721</pub-id></element-citation></ref><ref id="bib14"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>D’amour</surname><given-names>JA</given-names></name><name><surname>Froemke</surname><given-names>RC</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>Inhibitory and excitatory spike-timing-dependent plasticity in the auditory cortex</article-title><source>Neuron</source><volume>86</volume><fpage>514</fpage><lpage>528</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2015.03.014</pub-id><pub-id pub-id-type="pmid">25843405</pub-id></element-citation></ref><ref id="bib15"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Dehaene</surname><given-names>GP</given-names></name><name><surname>Coen-Cagli</surname><given-names>R</given-names></name><name><surname>Pouget</surname><given-names>A</given-names></name></person-group><year iso-8601-date="2021">2021</year><article-title>Investigating the representation of uncertainty in neuronal circuits</article-title><source>PLOS Computational Biology</source><volume>17</volume><elocation-id>e1008138</elocation-id><pub-id pub-id-type="doi">10.1371/journal.pcbi.1008138</pub-id><pub-id pub-id-type="pmid">33577553</pub-id></element-citation></ref><ref id="bib16"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Dorsett</surname><given-names>C</given-names></name><name><surname>Philpot</surname><given-names>BD</given-names></name><name><surname>Smith</surname><given-names>SL</given-names></name><name><surname>Smith</surname><given-names>IT</given-names></name></person-group><year iso-8601-date="2021">2021</year><article-title>The Impact of SST and PV interneurons on nonlinear synaptic integration in the neocortex</article-title><source>eNeuro</source><volume>8</volume><fpage>Sep</fpage><lpage>Oct</lpage><pub-id pub-id-type="doi">10.1523/ENEURO.0235-21.2021</pub-id><pub-id pub-id-type="pmid">34400470</pub-id></element-citation></ref><ref id="bib17"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Eliades</surname><given-names>SJ</given-names></name><name><surname>Wang</surname><given-names>X</given-names></name></person-group><year iso-8601-date="2008">2008</year><article-title>Neural substrates of vocalization feedback monitoring in primate auditory cortex</article-title><source>Nature</source><volume>453</volume><fpage>1102</fpage><lpage>1106</lpage><pub-id pub-id-type="doi">10.1038/nature06910</pub-id><pub-id pub-id-type="pmid">18454135</pub-id></element-citation></ref><ref id="bib18"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ernst</surname><given-names>MO</given-names></name><name><surname>Banks</surname><given-names>MS</given-names></name></person-group><year iso-8601-date="2002">2002</year><article-title>Humans integrate visual and haptic information in a statistically optimal fashion</article-title><source>Nature</source><volume>415</volume><fpage>429</fpage><lpage>433</lpage><pub-id pub-id-type="doi">10.1038/415429a</pub-id><pub-id pub-id-type="pmid">11807554</pub-id></element-citation></ref><ref id="bib19"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Fetsch</surname><given-names>CR</given-names></name><name><surname>Pouget</surname><given-names>A</given-names></name><name><surname>DeAngelis</surname><given-names>GC</given-names></name><name><surname>Angelaki</surname><given-names>DE</given-names></name></person-group><year iso-8601-date="2012">2012</year><article-title>Neural correlates of reliability-based cue weighting during multisensory integration</article-title><source>Nature Neuroscience</source><volume>15</volume><fpage>146</fpage><lpage>154</lpage><pub-id pub-id-type="doi">10.1038/nn.2983</pub-id></element-citation></ref><ref id="bib20"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Field</surname><given-names>RE</given-names></name><name><surname>D’amour</surname><given-names>JA</given-names></name><name><surname>Tremblay</surname><given-names>R</given-names></name><name><surname>Miehl</surname><given-names>C</given-names></name><name><surname>Rudy</surname><given-names>B</given-names></name><name><surname>Gjorgjieva</surname><given-names>J</given-names></name><name><surname>Froemke</surname><given-names>RC</given-names></name></person-group><year iso-8601-date="2020">2020</year><article-title>Heterosynaptic plasticity determines the set point for cortical excitatory-inhibitory balance</article-title><source>Neuron</source><volume>106</volume><fpage>842</fpage><lpage>854</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2020.03.002</pub-id><pub-id pub-id-type="pmid">32213321</pub-id></element-citation></ref><ref id="bib21"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Fischer</surname><given-names>BJ</given-names></name><name><surname>Peña</surname><given-names>J</given-names></name></person-group><year iso-8601-date="2011">2011</year><article-title>Owl’s behavior and neural representation predicted by Bayesian inference</article-title><source>Nature Neuroscience</source><volume>14</volume><fpage>1061</fpage><lpage>1066</lpage><pub-id pub-id-type="doi">10.1038/nn.2872</pub-id><pub-id pub-id-type="pmid">21725311</pub-id></element-citation></ref><ref id="bib22"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Fiser</surname><given-names>A</given-names></name><name><surname>Mahringer</surname><given-names>D</given-names></name><name><surname>Oyibo</surname><given-names>HK</given-names></name><name><surname>Petersen</surname><given-names>AV</given-names></name><name><surname>Leinweber</surname><given-names>M</given-names></name><name><surname>Keller</surname><given-names>GB</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Experience-dependent spatial expectations in mouse visual cortex</article-title><source>Nature Neuroscience</source><volume>19</volume><fpage>1658</fpage><lpage>1664</lpage><pub-id pub-id-type="doi">10.1038/nn.4385</pub-id><pub-id pub-id-type="pmid">27618309</pub-id></element-citation></ref><ref id="bib23"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Friston</surname><given-names>K</given-names></name></person-group><year iso-8601-date="2005">2005</year><article-title>A theory of cortical responses</article-title><source>Philosophical Transactions of the Royal Society of London. Series B, Biological Sciences</source><volume>360</volume><fpage>815</fpage><lpage>836</lpage><pub-id pub-id-type="doi">10.1098/rstb.2005.1622</pub-id><pub-id pub-id-type="pmid">15937014</pub-id></element-citation></ref><ref id="bib24"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Gaetz</surname><given-names>W</given-names></name><name><surname>Bloy</surname><given-names>L</given-names></name><name><surname>Wang</surname><given-names>DJ</given-names></name><name><surname>Port</surname><given-names>RG</given-names></name><name><surname>Blaskey</surname><given-names>L</given-names></name><name><surname>Levy</surname><given-names>SE</given-names></name><name><surname>Roberts</surname><given-names>TPL</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>GABA estimation in the brains of children on the autism spectrum: measurement precision and regional cortical variation</article-title><source>NeuroImage</source><volume>86</volume><fpage>1</fpage><lpage>9</lpage><pub-id pub-id-type="doi">10.1016/j.neuroimage.2013.05.068</pub-id><pub-id pub-id-type="pmid">23707581</pub-id></element-citation></ref><ref id="bib25"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Gidon</surname><given-names>A</given-names></name><name><surname>Segev</surname><given-names>I</given-names></name></person-group><year iso-8601-date="2012">2012</year><article-title>Principles governing the operation of synaptic inhibition in dendrites</article-title><source>Neuron</source><volume>75</volume><fpage>330</fpage><lpage>341</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2012.05.015</pub-id><pub-id pub-id-type="pmid">22841317</pub-id></element-citation></ref><ref id="bib26"><element-citation publication-type="preprint"><person-group person-group-type="author"><name><surname>Gillon</surname><given-names>CJ</given-names></name><name><surname>Pina</surname><given-names>JE</given-names></name><name><surname>Lecoq</surname><given-names>JA</given-names></name><name><surname>Ahmed</surname><given-names>R</given-names></name><name><surname>Billeh</surname><given-names>Y</given-names></name><name><surname>Caldejon</surname><given-names>S</given-names></name><name><surname>Groblewski</surname><given-names>P</given-names></name><name><surname>Henley</surname><given-names>TM</given-names></name><name><surname>Kato</surname><given-names>I</given-names></name><name><surname>Lee</surname><given-names>E</given-names></name><name><surname>Luviano</surname><given-names>J</given-names></name><name><surname>Mace</surname><given-names>K</given-names></name><name><surname>Nayan</surname><given-names>C</given-names></name><name><surname>Nguyen</surname><given-names>T</given-names></name><name><surname>North</surname><given-names>K</given-names></name><name><surname>Perkins</surname><given-names>J</given-names></name><name><surname>Seid</surname><given-names>S</given-names></name><name><surname>Valley</surname><given-names>M</given-names></name><name><surname>Williford</surname><given-names>A</given-names></name><name><surname>Bengio</surname><given-names>Y</given-names></name><name><surname>Lillicrap</surname><given-names>TP</given-names></name><name><surname>Richards</surname><given-names>BA</given-names></name></person-group><year iso-8601-date="2021">2021</year><article-title>Learning from Unexpected Events in the Neocortical Microcircuit</article-title><source>bioRxiv</source><pub-id pub-id-type="doi">10.1101/2021.01.15.426915</pub-id></element-citation></ref><ref id="bib27"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Goris</surname><given-names>J</given-names></name><name><surname>Braem</surname><given-names>S</given-names></name><name><surname>Nijhof</surname><given-names>AD</given-names></name><name><surname>Rigoni</surname><given-names>D</given-names></name><name><surname>Deschrijver</surname><given-names>E</given-names></name><name><surname>Van de Cruys</surname><given-names>S</given-names></name><name><surname>Wiersema</surname><given-names>JR</given-names></name><name><surname>Brass</surname><given-names>M</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>Sensory prediction errors are less modulated by global context in autism spectrum disorder</article-title><source>Biological Psychiatry. Cognitive Neuroscience and Neuroimaging</source><volume>3</volume><fpage>667</fpage><lpage>674</lpage><pub-id pub-id-type="doi">10.1016/j.bpsc.2018.02.003</pub-id><pub-id pub-id-type="pmid">29628433</pub-id></element-citation></ref><ref id="bib28"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Goris</surname><given-names>J</given-names></name><name><surname>Silvetti</surname><given-names>M</given-names></name><name><surname>Verguts</surname><given-names>T</given-names></name><name><surname>Wiersema</surname><given-names>JR</given-names></name><name><surname>Brass</surname><given-names>M</given-names></name><name><surname>Braem</surname><given-names>S</given-names></name></person-group><year iso-8601-date="2021">2021</year><article-title>Autistic traits are related to worse performance in a volatile reward learning task despite adaptive learning rates</article-title><source>Autism</source><volume>25</volume><fpage>440</fpage><lpage>451</lpage><pub-id pub-id-type="doi">10.1177/1362361320962237</pub-id><pub-id pub-id-type="pmid">33030041</pub-id></element-citation></ref><ref id="bib29"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Granier</surname><given-names>A</given-names></name><name><surname>Petrovici</surname><given-names>MA</given-names></name><name><surname>Senn</surname><given-names>W</given-names></name><name><surname>Wilmes</surname><given-names>KA</given-names></name></person-group><year iso-8601-date="2024">2024</year><article-title>Confidence and second-order errors in cortical circuits</article-title><source>PNAS Nexus</source><volume>3</volume><elocation-id>404</elocation-id><pub-id pub-id-type="doi">10.1093/pnasnexus/pgae404</pub-id><pub-id pub-id-type="pmid">39346625</pub-id></element-citation></ref><ref id="bib30"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Green</surname><given-names>J</given-names></name><name><surname>Bruno</surname><given-names>CA</given-names></name><name><surname>Traunmüller</surname><given-names>L</given-names></name><name><surname>Ding</surname><given-names>J</given-names></name><name><surname>Hrvatin</surname><given-names>S</given-names></name><name><surname>Wilson</surname><given-names>DE</given-names></name><name><surname>Khodadad</surname><given-names>T</given-names></name><name><surname>Samuels</surname><given-names>J</given-names></name><name><surname>Greenberg</surname><given-names>ME</given-names></name><name><surname>Harvey</surname><given-names>CD</given-names></name></person-group><year iso-8601-date="2023">2023</year><article-title>A cell-type-specific error-correction signal in the posterior parietal cortex</article-title><source>Nature</source><volume>620</volume><fpage>366</fpage><lpage>373</lpage><pub-id pub-id-type="doi">10.1038/s41586-023-06357-1</pub-id><pub-id pub-id-type="pmid">37468637</pub-id></element-citation></ref><ref id="bib31"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Harada</surname><given-names>M</given-names></name><name><surname>Taki</surname><given-names>MM</given-names></name><name><surname>Nose</surname><given-names>A</given-names></name><name><surname>Kubo</surname><given-names>H</given-names></name><name><surname>Mori</surname><given-names>K</given-names></name><name><surname>Nishitani</surname><given-names>H</given-names></name><name><surname>Matsuda</surname><given-names>T</given-names></name></person-group><year iso-8601-date="2011">2011</year><article-title>Non-invasive evaluation of the GABAergic/glutamatergic system in autistic patients observed by MEGA-editing proton MR spectroscopy using a clinical 3 tesla instrument</article-title><source>Journal of Autism and Developmental Disorders</source><volume>41</volume><fpage>447</fpage><lpage>454</lpage><pub-id pub-id-type="doi">10.1007/s10803-010-1065-0</pub-id><pub-id pub-id-type="pmid">20652388</pub-id></element-citation></ref><ref id="bib32"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hertäg</surname><given-names>L</given-names></name><name><surname>Sprekeler</surname><given-names>H</given-names></name></person-group><year iso-8601-date="2020">2020</year><article-title>Learning prediction error neurons in a canonical interneuron circuit</article-title><source>eLife</source><volume>9</volume><elocation-id>e57541</elocation-id><pub-id pub-id-type="doi">10.7554/eLife.57541</pub-id><pub-id pub-id-type="pmid">32820723</pub-id></element-citation></ref><ref id="bib33"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hertäg</surname><given-names>L</given-names></name><name><surname>Clopath</surname><given-names>C</given-names></name></person-group><year iso-8601-date="2022">2022</year><article-title>Prediction-error neurons in circuits with multiple neuron types: Formation, refinement, and functional implications</article-title><source>PNAS</source><volume>119</volume><elocation-id>e2115699119</elocation-id><pub-id pub-id-type="doi">10.1073/pnas.2115699119</pub-id><pub-id pub-id-type="pmid">35320037</pub-id></element-citation></ref><ref id="bib34"><element-citation publication-type="preprint"><person-group person-group-type="author"><name><surname>Hertäg</surname><given-names>L</given-names></name><name><surname>Wilmes</surname><given-names>KA</given-names></name><name><surname>Clopath</surname><given-names>C</given-names></name></person-group><year iso-8601-date="2023">2023</year><article-title>Knowing what you don’t know: estimating the uncertainty of feedforward and feedback inputs with prediction-error circuits</article-title><source>bioRxiv</source><pub-id pub-id-type="doi">10.1101/2023.12.13.571410</pub-id></element-citation></ref><ref id="bib35"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hollingworth</surname><given-names>HL</given-names></name></person-group><year iso-8601-date="1910">1910</year><article-title>The central tendency of judgment</article-title><source>The Journal of Philosophy, Psychology and Scientific Methods</source><volume>7</volume><elocation-id>461</elocation-id><pub-id pub-id-type="doi">10.2307/2012819</pub-id></element-citation></ref><ref id="bib36"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Isaacson</surname><given-names>JS</given-names></name><name><surname>Scanziani</surname><given-names>M</given-names></name></person-group><year iso-8601-date="2011">2011</year><article-title>How inhibition shapes cortical activity</article-title><source>Neuron</source><volume>72</volume><fpage>231</fpage><lpage>243</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2011.09.027</pub-id><pub-id pub-id-type="pmid">22017986</pub-id></element-citation></ref><ref id="bib37"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Jazayeri</surname><given-names>M</given-names></name><name><surname>Shadlen</surname><given-names>MN</given-names></name></person-group><year iso-8601-date="2010">2010</year><article-title>Temporal context calibrates interval timing</article-title><source>Nature Neuroscience</source><volume>13</volume><fpage>1020</fpage><lpage>1026</lpage><pub-id pub-id-type="doi">10.1038/nn.2590</pub-id><pub-id pub-id-type="pmid">20581842</pub-id></element-citation></ref><ref id="bib38"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Jordan</surname><given-names>R</given-names></name><name><surname>Keller</surname><given-names>GB</given-names></name></person-group><year iso-8601-date="2020">2020</year><article-title>opposing influence of top-down and bottom-up input on excitatory layer 2/3 neurons in mouse primary visual cortex</article-title><source>Neuron</source><volume>108</volume><fpage>1194</fpage><lpage>1206</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2020.09.024</pub-id><pub-id pub-id-type="pmid">33091338</pub-id></element-citation></ref><ref id="bib39"><element-citation publication-type="preprint"><person-group person-group-type="author"><name><surname>Jordan</surname><given-names>J</given-names></name><name><surname>Sacramento</surname><given-names>J</given-names></name><name><surname>Wybo</surname><given-names>WAM</given-names></name><name><surname>Petrovici</surname><given-names>MA</given-names></name><name><surname>Senn</surname><given-names>W</given-names></name></person-group><year iso-8601-date="2022">2022</year><article-title>Learning bayes-optimal dendritic opinion pooling</article-title><source>arXiv</source><ext-link ext-link-type="uri" xlink:href="https://arxiv.org/abs/2104.13238">https://arxiv.org/abs/2104.13238</ext-link></element-citation></ref><ref id="bib40"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Jordan</surname><given-names>R</given-names></name><name><surname>Keller</surname><given-names>GB</given-names></name></person-group><year iso-8601-date="2023">2023</year><article-title>The locus coeruleus broadcasts prediction errors across the cortex to promote sensorimotor plasticity</article-title><source>eLife</source><volume>12</volume><elocation-id>RP85111</elocation-id><pub-id pub-id-type="doi">10.7554/eLife.85111.2</pub-id></element-citation></ref><ref id="bib41"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Juarez</surname><given-names>P</given-names></name><name><surname>Martínez Cerdeño</surname><given-names>V</given-names></name></person-group><year iso-8601-date="2022">2022</year><article-title>Parvalbumin and parvalbumin chandelier interneurons in autism and other psychiatric disorders</article-title><source>Frontiers in Psychiatry</source><volume>13</volume><elocation-id>913550</elocation-id><pub-id pub-id-type="doi">10.3389/fpsyt.2022.913550</pub-id><pub-id pub-id-type="pmid">36311505</pub-id></element-citation></ref><ref id="bib42"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Keller</surname><given-names>GB</given-names></name><name><surname>Hahnloser</surname><given-names>RHR</given-names></name></person-group><year iso-8601-date="2009">2009</year><article-title>Neural processing of auditory feedback during vocal practice in a songbird</article-title><source>Nature</source><volume>457</volume><fpage>187</fpage><lpage>190</lpage><pub-id pub-id-type="doi">10.1038/nature07467</pub-id><pub-id pub-id-type="pmid">19005471</pub-id></element-citation></ref><ref id="bib43"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Keller</surname><given-names>GB</given-names></name><name><surname>Bonhoeffer</surname><given-names>T</given-names></name><name><surname>Hübener</surname><given-names>M</given-names></name></person-group><year iso-8601-date="2012">2012</year><article-title>Sensorimotor mismatch signals in primary visual cortex of the behaving mouse</article-title><source>Neuron</source><volume>74</volume><fpage>809</fpage><lpage>815</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2012.03.040</pub-id><pub-id pub-id-type="pmid">22681686</pub-id></element-citation></ref><ref id="bib44"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Keller</surname><given-names>GB</given-names></name><name><surname>Mrsic-Flogel</surname><given-names>TD</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>Predictive processing: a canonical cortical computation</article-title><source>Neuron</source><volume>100</volume><fpage>424</fpage><lpage>435</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2018.10.003</pub-id><pub-id pub-id-type="pmid">30359606</pub-id></element-citation></ref><ref id="bib45"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kiani</surname><given-names>R</given-names></name><name><surname>Shadlen</surname><given-names>MN</given-names></name></person-group><year iso-8601-date="2009">2009</year><article-title>Representation of confidence associated with a decision by neurons in the parietal cortex</article-title><source>Science</source><volume>324</volume><fpage>759</fpage><lpage>764</lpage><pub-id pub-id-type="doi">10.1126/science.1169405</pub-id><pub-id pub-id-type="pmid">19423820</pub-id></element-citation></ref><ref id="bib46"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Koblinger</surname><given-names>Á</given-names></name><name><surname>Fiser</surname><given-names>J</given-names></name><name><surname>Lengyel</surname><given-names>M</given-names></name></person-group><year iso-8601-date="2021">2021</year><article-title>Representations of uncertainty: where art thou?</article-title><source>Current Opinion in Behavioral Sciences</source><volume>38</volume><fpage>150</fpage><lpage>162</lpage><pub-id pub-id-type="doi">10.1016/j.cobeha.2021.03.009</pub-id><pub-id pub-id-type="pmid">34026948</pub-id></element-citation></ref><ref id="bib47"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Körding</surname><given-names>KP</given-names></name><name><surname>Wolpert</surname><given-names>DM</given-names></name></person-group><year iso-8601-date="2004">2004</year><article-title>Bayesian integration in sensorimotor learning</article-title><source>Nature</source><volume>427</volume><fpage>244</fpage><lpage>247</lpage><pub-id pub-id-type="doi">10.1038/nature02169</pub-id><pub-id pub-id-type="pmid">14724638</pub-id></element-citation></ref><ref id="bib48"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kreutzer</surname><given-names>E</given-names></name><name><surname>Senn</surname><given-names>W</given-names></name><name><surname>Petrovici</surname><given-names>MA</given-names></name></person-group><year iso-8601-date="2022">2022</year><article-title>Natural-gradient learning for spiking neurons</article-title><source>eLife</source><volume>11</volume><elocation-id>e66526</elocation-id><pub-id pub-id-type="doi">10.7554/eLife.66526</pub-id><pub-id pub-id-type="pmid">35467527</pub-id></element-citation></ref><ref id="bib49"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kveraga</surname><given-names>K</given-names></name><name><surname>Ghuman</surname><given-names>AS</given-names></name><name><surname>Bar</surname><given-names>M</given-names></name></person-group><year iso-8601-date="2007">2007</year><article-title>Top-down predictions in the cognitive brain</article-title><source>Brain and Cognition</source><volume>65</volume><fpage>145</fpage><lpage>168</lpage><pub-id pub-id-type="doi">10.1016/j.bandc.2007.06.007</pub-id><pub-id pub-id-type="pmid">17923222</pub-id></element-citation></ref><ref id="bib50"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Lawson</surname><given-names>RP</given-names></name><name><surname>Rees</surname><given-names>G</given-names></name><name><surname>Friston</surname><given-names>KJ</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>An aberrant precision account of autism</article-title><source>Frontiers in Human Neuroscience</source><volume>8</volume><elocation-id>302</elocation-id><pub-id pub-id-type="doi">10.3389/fnhum.2014.00302</pub-id><pub-id pub-id-type="pmid">24860482</pub-id></element-citation></ref><ref id="bib51"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Lawson</surname><given-names>RP</given-names></name><name><surname>Mathys</surname><given-names>C</given-names></name><name><surname>Rees</surname><given-names>G</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>Adults with autism overestimate the volatility of the sensory environment</article-title><source>Nature Neuroscience</source><volume>20</volume><fpage>1293</fpage><lpage>1299</lpage><pub-id pub-id-type="doi">10.1038/nn.4615</pub-id><pub-id pub-id-type="pmid">28758996</pub-id></element-citation></ref><ref id="bib52"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Lee</surname><given-names>S-H</given-names></name><name><surname>Kwan</surname><given-names>AC</given-names></name><name><surname>Zhang</surname><given-names>S</given-names></name><name><surname>Phoumthipphavong</surname><given-names>V</given-names></name><name><surname>Flannery</surname><given-names>JG</given-names></name><name><surname>Masmanidis</surname><given-names>SC</given-names></name><name><surname>Taniguchi</surname><given-names>H</given-names></name><name><surname>Huang</surname><given-names>ZJ</given-names></name><name><surname>Zhang</surname><given-names>F</given-names></name><name><surname>Boyden</surname><given-names>ES</given-names></name><name><surname>Deisseroth</surname><given-names>K</given-names></name><name><surname>Dan</surname><given-names>Y</given-names></name></person-group><year iso-8601-date="2012">2012</year><article-title>Activation of specific interneurons improves V1 feature selectivity and visual perception</article-title><source>Nature</source><volume>488</volume><fpage>379</fpage><lpage>383</lpage><pub-id pub-id-type="doi">10.1038/nature11312</pub-id><pub-id pub-id-type="pmid">22878719</pub-id></element-citation></ref><ref id="bib53"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Lee</surname><given-names>S</given-names></name><name><surname>Kruglikov</surname><given-names>I</given-names></name><name><surname>Huang</surname><given-names>ZJ</given-names></name><name><surname>Fishell</surname><given-names>G</given-names></name><name><surname>Rudy</surname><given-names>B</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>A disinhibitory circuit mediates motor integration in the somatosensory cortex</article-title><source>Nature Neuroscience</source><volume>16</volume><fpage>1662</fpage><lpage>1670</lpage><pub-id pub-id-type="doi">10.1038/nn.3544</pub-id><pub-id pub-id-type="pmid">24097044</pub-id></element-citation></ref><ref id="bib54"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Liu</surname><given-names>D</given-names></name><name><surname>Deng</surname><given-names>J</given-names></name><name><surname>Zhang</surname><given-names>Z</given-names></name><name><surname>Zhang</surname><given-names>Z-Y</given-names></name><name><surname>Sun</surname><given-names>Y-G</given-names></name><name><surname>Yang</surname><given-names>T</given-names></name><name><surname>Yao</surname><given-names>H</given-names></name></person-group><year iso-8601-date="2020">2020</year><article-title>Orbitofrontal control of visual cortex gain promotes visual associative learning</article-title><source>Nature Communications</source><volume>11</volume><elocation-id>2784</elocation-id><pub-id pub-id-type="doi">10.1038/s41467-020-16609-7</pub-id><pub-id pub-id-type="pmid">32493971</pub-id></element-citation></ref><ref id="bib55"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ma</surname><given-names>WJ</given-names></name><name><surname>Beck</surname><given-names>JM</given-names></name><name><surname>Latham</surname><given-names>PE</given-names></name><name><surname>Pouget</surname><given-names>A</given-names></name></person-group><year iso-8601-date="2006">2006</year><article-title>Bayesian inference with probabilistic population codes</article-title><source>Nature Neuroscience</source><volume>9</volume><fpage>1432</fpage><lpage>1438</lpage><pub-id pub-id-type="doi">10.1038/nn1790</pub-id><pub-id pub-id-type="pmid">17057707</pub-id></element-citation></ref><ref id="bib56"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Masset</surname><given-names>P</given-names></name><name><surname>Ott</surname><given-names>T</given-names></name><name><surname>Lak</surname><given-names>A</given-names></name><name><surname>Hirokawa</surname><given-names>J</given-names></name><name><surname>Kepecs</surname><given-names>A</given-names></name></person-group><year iso-8601-date="2020">2020</year><article-title>Behavior- and modality-general representation of confidence in orbitofrontal cortex</article-title><source>Cell</source><volume>182</volume><fpage>112</fpage><lpage>126</lpage><pub-id pub-id-type="doi">10.1016/j.cell.2020.05.022</pub-id><pub-id pub-id-type="pmid">32504542</pub-id></element-citation></ref><ref id="bib57"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Meirhaeghe</surname><given-names>N</given-names></name><name><surname>Sohn</surname><given-names>H</given-names></name><name><surname>Jazayeri</surname><given-names>M</given-names></name></person-group><year iso-8601-date="2021">2021</year><article-title>A precise and adaptive neural mechanism for predictive temporal processing in the frontal cortex</article-title><source>Neuron</source><volume>109</volume><fpage>2995</fpage><lpage>3011</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2021.08.025</pub-id><pub-id pub-id-type="pmid">34534456</pub-id></element-citation></ref><ref id="bib58"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Niell</surname><given-names>CM</given-names></name><name><surname>Stryker</surname><given-names>MP</given-names></name></person-group><year iso-8601-date="2008">2008</year><article-title>Highly selective receptive fields in mouse visual cortex</article-title><source>The Journal of Neuroscience</source><volume>28</volume><fpage>7520</fpage><lpage>7536</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.0623-08.2008</pub-id><pub-id pub-id-type="pmid">18650330</pub-id></element-citation></ref><ref id="bib59"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Payzan-LeNestour</surname><given-names>E</given-names></name><name><surname>Bossaerts</surname><given-names>P</given-names></name></person-group><year iso-8601-date="2011">2011</year><article-title>Risk, unexpected uncertainty, and estimation uncertainty: Bayesian learning in unstable settings</article-title><source>PLOS Computational Biology</source><volume>7</volume><elocation-id>e1001048</elocation-id><pub-id pub-id-type="doi">10.1371/journal.pcbi.1001048</pub-id><pub-id pub-id-type="pmid">21283774</pub-id></element-citation></ref><ref id="bib60"><element-citation publication-type="preprint"><person-group person-group-type="author"><name><surname>Petrovici</surname><given-names>MA</given-names></name><name><surname>Bill</surname><given-names>J</given-names></name><name><surname>Bytschok</surname><given-names>I</given-names></name><name><surname>Schemmel</surname><given-names>J</given-names></name><name><surname>Meier</surname><given-names>K</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>Stochastic inference with deterministic spiking neurons</article-title><source>arXiv</source><ext-link ext-link-type="uri" xlink:href="https://arxiv.org/abs/1311.3211">https://arxiv.org/abs/1311.3211</ext-link></element-citation></ref><ref id="bib61"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Petzschner</surname><given-names>FH</given-names></name><name><surname>Glasauer</surname><given-names>S</given-names></name></person-group><year iso-8601-date="2011">2011</year><article-title>Iterative Bayesian estimation as an explanation for range and regression effects: a study on human path integration</article-title><source>The Journal of Neuroscience</source><volume>31</volume><fpage>17220</fpage><lpage>17229</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.2028-11.2011</pub-id><pub-id pub-id-type="pmid">22114288</pub-id></element-citation></ref><ref id="bib62"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Pfeffer</surname><given-names>CK</given-names></name><name><surname>Xue</surname><given-names>M</given-names></name><name><surname>He</surname><given-names>M</given-names></name><name><surname>Huang</surname><given-names>ZJ</given-names></name><name><surname>Scanziani</surname><given-names>M</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>Inhibition of inhibition in visual cortex: the logic of connections between molecularly distinct interneurons</article-title><source>Nature Neuroscience</source><volume>16</volume><fpage>1068</fpage><lpage>1076</lpage><pub-id pub-id-type="doi">10.1038/nn.3446</pub-id><pub-id pub-id-type="pmid">23817549</pub-id></element-citation></ref><ref id="bib63"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Pfeffer</surname><given-names>CK</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>Inhibitory neurons: Vip cells hit the brake on inhibition</article-title><source>Current Biology</source><volume>24</volume><fpage>R18</fpage><lpage>R20</lpage><pub-id pub-id-type="doi">10.1016/j.cub.2013.11.001</pub-id></element-citation></ref><ref id="bib64"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Pi</surname><given-names>H-J</given-names></name><name><surname>Hangya</surname><given-names>B</given-names></name><name><surname>Kvitsiani</surname><given-names>D</given-names></name><name><surname>Sanders</surname><given-names>JI</given-names></name><name><surname>Huang</surname><given-names>ZJ</given-names></name><name><surname>Kepecs</surname><given-names>A</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>Cortical interneurons that specialize in disinhibitory control</article-title><source>Nature</source><volume>503</volume><fpage>521</fpage><lpage>524</lpage><pub-id pub-id-type="doi">10.1038/nature12676</pub-id><pub-id pub-id-type="pmid">24097352</pub-id></element-citation></ref><ref id="bib65"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Prönneke</surname><given-names>A</given-names></name><name><surname>Scheuer</surname><given-names>B</given-names></name><name><surname>Wagener</surname><given-names>RJ</given-names></name><name><surname>Möck</surname><given-names>M</given-names></name><name><surname>Witte</surname><given-names>M</given-names></name><name><surname>Staiger</surname><given-names>JF</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>Characterizing VIP neurons in the barrel cortex of VIPcre/tdTomato mice reveals layer-specific differences</article-title><source>Cerebral Cortex</source><volume>25</volume><fpage>4854</fpage><lpage>4868</lpage><pub-id pub-id-type="doi">10.1093/cercor/bhv202</pub-id><pub-id pub-id-type="pmid">26420784</pub-id></element-citation></ref><ref id="bib66"><element-citation publication-type="preprint"><person-group person-group-type="author"><name><surname>Raltschev</surname><given-names>C</given-names></name><name><surname>Kasavica</surname><given-names>S</given-names></name><name><surname>Leonardon</surname><given-names>B</given-names></name><name><surname>Nevian</surname><given-names>T</given-names></name><name><surname>Sachidhanandam</surname><given-names>S</given-names></name></person-group><year iso-8601-date="2023">2023</year><article-title>Top-down modulation of sensory processing and mismatch in the mouse posterior parietal cortex</article-title><source>bioRxiv</source><pub-id pub-id-type="doi">10.1101/2023.05.11.540431</pub-id></element-citation></ref><ref id="bib67"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Rao</surname><given-names>RPN</given-names></name><name><surname>Ballard</surname><given-names>DH</given-names></name></person-group><year iso-8601-date="1999">1999</year><article-title>Predictive coding in the visual cortex: a functional interpretation of some extra-classical receptive-field effects</article-title><source>Nature Neuroscience</source><volume>2</volume><fpage>79</fpage><lpage>87</lpage><pub-id pub-id-type="doi">10.1038/4580</pub-id></element-citation></ref><ref id="bib68"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Rubenstein</surname><given-names>JLR</given-names></name><name><surname>Merzenich</surname><given-names>MM</given-names></name></person-group><year iso-8601-date="2003">2003</year><article-title>Model of autism: increased ratio of excitation/inhibition in key neural systems</article-title><source>Genes, Brain, and Behavior</source><volume>2</volume><fpage>255</fpage><lpage>267</lpage><pub-id pub-id-type="doi">10.1034/j.1601-183x.2003.00037.x</pub-id><pub-id pub-id-type="pmid">14606691</pub-id></element-citation></ref><ref id="bib69"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Rushworth</surname><given-names>MFS</given-names></name><name><surname>Behrens</surname><given-names>TEJ</given-names></name></person-group><year iso-8601-date="2008">2008</year><article-title>Choice, uncertainty and value in prefrontal and cingulate cortex</article-title><source>Nature Neuroscience</source><volume>11</volume><fpage>389</fpage><lpage>397</lpage><pub-id pub-id-type="doi">10.1038/nn2066</pub-id><pub-id pub-id-type="pmid">18368045</pub-id></element-citation></ref><ref id="bib70"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Sachidhanandam</surname><given-names>S</given-names></name><name><surname>Sermet</surname><given-names>BS</given-names></name><name><surname>Petersen</surname><given-names>CCH</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Parvalbumin-expressing GABAergic neurons in mouse barrel cortex contribute to gating a goal-directed sensorimotor transformation</article-title><source>Cell Reports</source><volume>15</volume><fpage>700</fpage><lpage>706</lpage><pub-id pub-id-type="doi">10.1016/j.celrep.2016.03.063</pub-id><pub-id pub-id-type="pmid">27149853</pub-id></element-citation></ref><ref id="bib71"><element-citation publication-type="preprint"><person-group person-group-type="author"><name><surname>Schneider-Mizell</surname><given-names>CM</given-names></name><name><surname>Bodor</surname><given-names>AL</given-names></name><name><surname>Brittain</surname><given-names>D</given-names></name><name><surname>Buchanan</surname><given-names>J</given-names></name><name><surname>Bumbarger</surname><given-names>DJ</given-names></name><name><surname>Elabbady</surname><given-names>L</given-names></name><name><surname>Gamlin</surname><given-names>C</given-names></name><name><surname>Kapner</surname><given-names>D</given-names></name><name><surname>Kinn</surname><given-names>S</given-names></name><name><surname>Mahalingam</surname><given-names>G</given-names></name><name><surname>Seshamani</surname><given-names>S</given-names></name><name><surname>Suckow</surname><given-names>S</given-names></name><name><surname>Takeno</surname><given-names>M</given-names></name><name><surname>Torres</surname><given-names>R</given-names></name><name><surname>Yin</surname><given-names>W</given-names></name><name><surname>Sven Dorkenwald</surname><given-names>JAB</given-names></name><name><surname>Castro</surname><given-names>MA</given-names></name><name><surname>Halageri</surname><given-names>A</given-names></name><name><surname>Jia</surname><given-names>Z</given-names></name><name><surname>Jordan</surname><given-names>C</given-names></name><name><surname>Kemnitz</surname><given-names>N</given-names></name><name><surname>Lee</surname><given-names>K</given-names></name><name><surname>Li</surname><given-names>K</given-names></name><name><surname>Lu</surname><given-names>R</given-names></name><name><surname>Macrina</surname><given-names>T</given-names></name><name><surname>Mitchell</surname><given-names>E</given-names></name><name><surname>Mondal</surname><given-names>SS</given-names></name><name><surname>Mu</surname><given-names>S</given-names></name><name><surname>Nehoran</surname><given-names>B</given-names></name><name><surname>Popovych</surname><given-names>S</given-names></name><name><surname>Silversmith</surname><given-names>W</given-names></name><name><surname>Turner</surname><given-names>NL</given-names></name></person-group><year iso-8601-date="2024">2024</year><article-title>Cell-type-specific inhibitory circuitry from a connectomic census of mouse visual cortex</article-title><source>bioRxiv</source><pub-id pub-id-type="doi">10.1101/2023.01.23.525290</pub-id></element-citation></ref><ref id="bib72"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Seybold</surname><given-names>BA</given-names></name><name><surname>Phillips</surname><given-names>EAK</given-names></name><name><surname>Schreiner</surname><given-names>CE</given-names></name><name><surname>Hasenstaub</surname><given-names>AR</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>Inhibitory actions unified by network integration</article-title><source>Neuron</source><volume>87</volume><fpage>1181</fpage><lpage>1192</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2015.09.013</pub-id><pub-id pub-id-type="pmid">26402602</pub-id></element-citation></ref><ref id="bib73"><element-citation publication-type="preprint"><person-group person-group-type="author"><name><surname>Shi</surname><given-names>Z</given-names></name><name><surname>Theisinger</surname><given-names>LA</given-names></name><name><surname>Allenmark</surname><given-names>F</given-names></name><name><surname>Pistorius</surname><given-names>RL</given-names></name><name><surname>Müller</surname><given-names>HJ</given-names></name><name><surname>Falter-Wagner</surname><given-names>CM</given-names></name></person-group><year iso-8601-date="2022">2022</year><article-title>Predictive Coding in Asd: Inflexible Weighting of Prediction Errors When Switching from Stable to Volatile Environments</article-title><source>bioRxiv</source><pub-id pub-id-type="doi">10.1101/2022.01.21.477218</pub-id></element-citation></ref><ref id="bib74"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Tan</surname><given-names>AYY</given-names></name><name><surname>Wehr</surname><given-names>M</given-names></name></person-group><year iso-8601-date="2009">2009</year><article-title>Balanced tone-evoked synaptic excitation and inhibition in mouse auditory cortex</article-title><source>Neuroscience</source><volume>163</volume><fpage>1302</fpage><lpage>1315</lpage><pub-id pub-id-type="doi">10.1016/j.neuroscience.2009.07.032</pub-id><pub-id pub-id-type="pmid">19628023</pub-id></element-citation></ref><ref id="bib75"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Urbanczik</surname><given-names>R</given-names></name><name><surname>Senn</surname><given-names>W</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>Learning by the dendritic prediction of somatic spiking</article-title><source>Neuron</source><volume>81</volume><fpage>521</fpage><lpage>528</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2013.11.030</pub-id><pub-id pub-id-type="pmid">24507189</pub-id></element-citation></ref><ref id="bib76"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Van de Cruys</surname><given-names>S</given-names></name><name><surname>Evers</surname><given-names>K</given-names></name><name><surname>Van der Hallen</surname><given-names>R</given-names></name><name><surname>Van Eylen</surname><given-names>L</given-names></name><name><surname>Boets</surname><given-names>B</given-names></name><name><surname>de-Wit</surname><given-names>L</given-names></name><name><surname>Wagemans</surname><given-names>J</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>Precise minds in uncertain worlds: predictive coding in autism</article-title><source>Psychological Review</source><volume>121</volume><fpage>649</fpage><lpage>675</lpage><pub-id pub-id-type="doi">10.1037/a0037665</pub-id><pub-id pub-id-type="pmid">25347312</pub-id></element-citation></ref><ref id="bib77"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Walker</surname><given-names>AR</given-names></name><name><surname>Luque</surname><given-names>D</given-names></name><name><surname>Le Pelley</surname><given-names>ME</given-names></name><name><surname>Beesley</surname><given-names>T</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>The role of uncertainty in attentional and choice exploration</article-title><source>Psychonomic Bulletin &amp; Review</source><volume>26</volume><fpage>1911</fpage><lpage>1916</lpage><pub-id pub-id-type="doi">10.3758/s13423-019-01653-2</pub-id></element-citation></ref><ref id="bib78"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Whittington</surname><given-names>JCR</given-names></name><name><surname>Bogacz</surname><given-names>R</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>An approximation of the error backpropagation algorithm in a predictive coding network with local hebbian synaptic plasticity</article-title><source>Neural Computation</source><volume>29</volume><fpage>1229</fpage><lpage>1262</lpage><pub-id pub-id-type="doi">10.1162/NECO_a_00949</pub-id><pub-id pub-id-type="pmid">28333583</pub-id></element-citation></ref><ref id="bib79"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wilmes</surname><given-names>KA</given-names></name><name><surname>Sprekeler</surname><given-names>H</given-names></name><name><surname>Schreiber</surname><given-names>S</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Inhibition as a binary switch for excitatory plasticity in pyramidal neurons</article-title><source>PLOS Computational Biology</source><volume>12</volume><elocation-id>e1004768</elocation-id><pub-id pub-id-type="doi">10.1371/journal.pcbi.1004768</pub-id><pub-id pub-id-type="pmid">27003565</pub-id></element-citation></ref><ref id="bib80"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wilmes</surname><given-names>KA</given-names></name><name><surname>Schleimer</surname><given-names>J-H</given-names></name><name><surname>Schreiber</surname><given-names>S</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>Spike-timing dependent inhibitory plasticity to learn a selective gating of backpropagating action potentials</article-title><source>The European Journal of Neuroscience</source><volume>45</volume><fpage>1032</fpage><lpage>1043</lpage><pub-id pub-id-type="doi">10.1111/ejn.13326</pub-id><pub-id pub-id-type="pmid">27374316</pub-id></element-citation></ref><ref id="bib81"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wilmes</surname><given-names>KA</given-names></name><name><surname>Clopath</surname><given-names>C</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>Inhibitory microcircuits for top-down plasticity of sensory representations</article-title><source>Nature Communications</source><volume>10</volume><elocation-id>5055</elocation-id><pub-id pub-id-type="doi">10.1038/s41467-019-12972-2</pub-id><pub-id pub-id-type="pmid">31699994</pub-id></element-citation></ref><ref id="bib82"><element-citation publication-type="software"><person-group person-group-type="author"><name><surname>Wilmes</surname><given-names>K</given-names></name></person-group><year iso-8601-date="2025">2025</year><data-title>UPE</data-title><version designator="swh:1:rev:047dbbe560688af0d59c8e8ee4964a497fcea890">swh:1:rev:047dbbe560688af0d59c8e8ee4964a497fcea890</version><source>Software Heritage</source><ext-link ext-link-type="uri" xlink:href="https://archive.softwareheritage.org/swh:1:dir:d9b917d5bf84387d27ba8252fa6b763b390107d5;origin=https://github.com/k47h4/UPE;visit=swh:1:snp:afbd0b1439e095339333eae4bbd93109c5dedf4c;anchor=swh:1:rev:047dbbe560688af0d59c8e8ee4964a497fcea890">https://archive.softwareheritage.org/swh:1:dir:d9b917d5bf84387d27ba8252fa6b763b390107d5;origin=https://github.com/k47h4/UPE;visit=swh:1:snp:afbd0b1439e095339333eae4bbd93109c5dedf4c;anchor=swh:1:rev:047dbbe560688af0d59c8e8ee4964a497fcea890</ext-link></element-citation></ref><ref id="bib83"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wilson</surname><given-names>NR</given-names></name><name><surname>Runyan</surname><given-names>CA</given-names></name><name><surname>Wang</surname><given-names>FL</given-names></name><name><surname>Sur</surname><given-names>M</given-names></name></person-group><year iso-8601-date="2012">2012</year><article-title>Division and subtraction by distinct cortical inhibitory networks in vivo</article-title><source>Nature</source><volume>488</volume><fpage>343</fpage><lpage>348</lpage><pub-id pub-id-type="doi">10.1038/nature11347</pub-id><pub-id pub-id-type="pmid">22878717</pub-id></element-citation></ref><ref id="bib84"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Zmarz</surname><given-names>P</given-names></name><name><surname>Keller</surname><given-names>GB</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Mismatch receptive fields in mouse visual cortex</article-title><source>Neuron</source><volume>92</volume><fpage>766</fpage><lpage>772</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2016.09.057</pub-id><pub-id pub-id-type="pmid">27974161</pub-id></element-citation></ref><ref id="bib85"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Znamenskiy</surname><given-names>P</given-names></name><name><surname>Kim</surname><given-names>M-H</given-names></name><name><surname>Muir</surname><given-names>DR</given-names></name><name><surname>Iacaruso</surname><given-names>MF</given-names></name><name><surname>Hofer</surname><given-names>SB</given-names></name><name><surname>Mrsic-Flogel</surname><given-names>TD</given-names></name></person-group><year iso-8601-date="2024">2024</year><article-title>Functional specificity of recurrent inhibition in visual cortex</article-title><source>Neuron</source><volume>112</volume><fpage>991</fpage><lpage>1000</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2023.12.013</pub-id><pub-id pub-id-type="pmid">38244539</pub-id></element-citation></ref></ref-list><app-group><app id="appendix-1"><title>Appendix 1</title><sec sec-type="appendix" id="s8"><title>Synaptic dynamics/plasticity rules</title><p><disp-formula id="equ47"><label>(29)</label><mml:math id="m47"><mml:mrow><mml:mi mathvariant="normal">Δ</mml:mi><mml:msub><mml:mi>w</mml:mi><mml:mrow><mml:msup><mml:mrow><mml:mi mathvariant="normal">P</mml:mi><mml:mi mathvariant="normal">V</mml:mi></mml:mrow><mml:mrow><mml:mo>+</mml:mo></mml:mrow></mml:msup><mml:mo>,</mml:mo><mml:msup><mml:mrow><mml:mi mathvariant="normal">S</mml:mi><mml:mi mathvariant="normal">S</mml:mi><mml:mi mathvariant="normal">T</mml:mi></mml:mrow><mml:mrow><mml:mo>+</mml:mo></mml:mrow></mml:msup></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:msub><mml:mi>η</mml:mi><mml:mrow><mml:mrow><mml:mi mathvariant="normal">P</mml:mi><mml:mi mathvariant="normal">V</mml:mi></mml:mrow></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>w</mml:mi><mml:mrow><mml:msup><mml:mrow><mml:mi mathvariant="normal">P</mml:mi><mml:mi mathvariant="normal">V</mml:mi></mml:mrow><mml:mrow><mml:mo>+</mml:mo></mml:mrow></mml:msup><mml:mo>,</mml:mo><mml:mi>s</mml:mi></mml:mrow></mml:msub><mml:msub><mml:mrow><mml:mi mathvariant="normal">s</mml:mi><mml:mo>−</mml:mo><mml:mi mathvariant="normal">w</mml:mi></mml:mrow><mml:mrow><mml:msup><mml:mrow><mml:mi mathvariant="normal">P</mml:mi><mml:mi mathvariant="normal">V</mml:mi></mml:mrow><mml:mrow><mml:mo>+</mml:mo></mml:mrow></mml:msup><mml:mo>,</mml:mo><mml:msup><mml:mrow><mml:mi mathvariant="normal">S</mml:mi><mml:mi mathvariant="normal">S</mml:mi><mml:mi mathvariant="normal">T</mml:mi></mml:mrow><mml:mrow><mml:mo>+</mml:mo></mml:mrow></mml:msup></mml:mrow></mml:msub><mml:msub><mml:mi>r</mml:mi><mml:mrow><mml:msup><mml:mrow><mml:mi mathvariant="normal">S</mml:mi><mml:mi mathvariant="normal">S</mml:mi><mml:mi mathvariant="normal">T</mml:mi></mml:mrow><mml:mrow><mml:mo>+</mml:mo></mml:mrow></mml:msup></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:msub><mml:mi>r</mml:mi><mml:mrow><mml:msup><mml:mrow><mml:mi mathvariant="normal">S</mml:mi><mml:mi mathvariant="normal">S</mml:mi><mml:mi mathvariant="normal">T</mml:mi></mml:mrow><mml:mrow><mml:mo>+</mml:mo></mml:mrow></mml:msup></mml:mrow></mml:msub><mml:mo>,</mml:mo></mml:mrow></mml:math></disp-formula><disp-formula id="equ48"><label>(30)</label><mml:math id="m48"><mml:mrow><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mtable columnalign="right left right left right left right left right left right left" rowspacing="3pt" columnspacing="0em 2em 0em 2em 0em 2em 0em 2em 0em 2em 0em" displaystyle="true"><mml:mtr><mml:mtd><mml:mi mathvariant="normal">Δ</mml:mi><mml:msub><mml:mi>w</mml:mi><mml:mrow><mml:msup><mml:mrow><mml:mi mathvariant="normal">P</mml:mi><mml:mi mathvariant="normal">V</mml:mi></mml:mrow><mml:mo>−</mml:mo></mml:msup><mml:mo>,</mml:mo><mml:msup><mml:mrow><mml:mi mathvariant="normal">S</mml:mi><mml:mi mathvariant="normal">S</mml:mi><mml:mi mathvariant="normal">T</mml:mi></mml:mrow><mml:mo>−</mml:mo></mml:msup></mml:mrow></mml:msub></mml:mtd><mml:mtd><mml:mi/><mml:mo>=</mml:mo><mml:msub><mml:mi>η</mml:mi><mml:mrow><mml:mrow><mml:mi mathvariant="normal">P</mml:mi><mml:mi mathvariant="normal">V</mml:mi></mml:mrow></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>w</mml:mi><mml:mrow><mml:msup><mml:mrow><mml:mi mathvariant="normal">P</mml:mi><mml:mi mathvariant="normal">V</mml:mi></mml:mrow><mml:mo>−</mml:mo></mml:msup><mml:mo>,</mml:mo><mml:mi>R</mml:mi></mml:mrow></mml:msub><mml:msub><mml:mi>r</mml:mi><mml:mrow><mml:mi mathvariant="normal">R</mml:mi></mml:mrow></mml:msub><mml:mo>−</mml:mo><mml:msub><mml:mi>w</mml:mi><mml:mrow><mml:msup><mml:mrow><mml:mi mathvariant="normal">P</mml:mi><mml:mi mathvariant="normal">V</mml:mi></mml:mrow><mml:mo>−</mml:mo></mml:msup><mml:mo>,</mml:mo><mml:msup><mml:mrow><mml:mi mathvariant="normal">S</mml:mi><mml:mi mathvariant="normal">S</mml:mi><mml:mi mathvariant="normal">T</mml:mi></mml:mrow><mml:mo>−</mml:mo></mml:msup></mml:mrow></mml:msub><mml:msub><mml:mi>r</mml:mi><mml:mrow><mml:msup><mml:mrow><mml:mi mathvariant="normal">S</mml:mi><mml:mi mathvariant="normal">S</mml:mi><mml:mi mathvariant="normal">T</mml:mi></mml:mrow><mml:mo>−</mml:mo></mml:msup></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:msub><mml:mi>r</mml:mi><mml:mrow><mml:msup><mml:mrow><mml:mi mathvariant="normal">S</mml:mi><mml:mi mathvariant="normal">S</mml:mi><mml:mi mathvariant="normal">T</mml:mi></mml:mrow><mml:mo>−</mml:mo></mml:msup></mml:mrow></mml:msub><mml:mo>,</mml:mo></mml:mtd></mml:mtr></mml:mtable></mml:mstyle></mml:mrow></mml:math></disp-formula><disp-formula id="equ49"><label>(31)</label><mml:math id="m49"><mml:mtable rowspacing="3pt" columnspacing="0em 2em 0em 2em 0em 2em 0em 2em 0em 2em 0em" displaystyle="true"><mml:mtr><mml:mtd><mml:mi mathvariant="normal">Δ</mml:mi><mml:msub><mml:mi>w</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:msup><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi mathvariant="normal">U</mml:mi><mml:mi mathvariant="normal">P</mml:mi><mml:mi mathvariant="normal">E</mml:mi></mml:mrow><mml:mo>+</mml:mo></mml:msup><mml:mo>,</mml:mo><mml:msup><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi mathvariant="normal">S</mml:mi><mml:mi mathvariant="normal">S</mml:mi><mml:mi mathvariant="normal">T</mml:mi></mml:mrow><mml:mo>+</mml:mo></mml:msup></mml:mrow></mml:msub></mml:mtd><mml:mtd><mml:mi/><mml:mo>=</mml:mo><mml:msub><mml:mi>η</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi mathvariant="normal">U</mml:mi><mml:mi mathvariant="normal">P</mml:mi><mml:mi mathvariant="normal">E</mml:mi></mml:mrow></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>w</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:msup><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi mathvariant="normal">U</mml:mi><mml:mi mathvariant="normal">P</mml:mi><mml:mi mathvariant="normal">E</mml:mi></mml:mrow><mml:mo>+</mml:mo></mml:msup><mml:mo>,</mml:mo><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi mathvariant="normal">s</mml:mi></mml:mrow></mml:mrow></mml:msub><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi mathvariant="normal">s</mml:mi></mml:mrow><mml:mo>−</mml:mo><mml:msub><mml:mi>w</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:msup><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi mathvariant="normal">U</mml:mi><mml:mi mathvariant="normal">P</mml:mi><mml:mi mathvariant="normal">E</mml:mi></mml:mrow><mml:mo>+</mml:mo></mml:msup><mml:mo>,</mml:mo><mml:msup><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi mathvariant="normal">S</mml:mi><mml:mi mathvariant="normal">S</mml:mi><mml:mi mathvariant="normal">T</mml:mi></mml:mrow><mml:mo>+</mml:mo></mml:msup></mml:mrow></mml:msub><mml:msub><mml:mi>r</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:msup><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi mathvariant="normal">S</mml:mi><mml:mi mathvariant="normal">S</mml:mi><mml:mi mathvariant="normal">T</mml:mi></mml:mrow><mml:mo>+</mml:mo></mml:msup></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:msub><mml:mi>r</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:msup><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi mathvariant="normal">S</mml:mi><mml:mi mathvariant="normal">S</mml:mi><mml:mi mathvariant="normal">T</mml:mi></mml:mrow><mml:mo>+</mml:mo></mml:msup></mml:mrow></mml:msub><mml:mo>,</mml:mo></mml:mtd></mml:mtr></mml:mtable></mml:math></disp-formula><disp-formula id="equ50"><label>(32)</label><mml:math id="m50"><mml:mrow><mml:mi mathvariant="normal">Δ</mml:mi><mml:msub><mml:mi>w</mml:mi><mml:mrow><mml:mi mathvariant="normal">U</mml:mi><mml:mi mathvariant="normal">P</mml:mi><mml:msup><mml:mi mathvariant="normal">E</mml:mi><mml:mo>+</mml:mo></mml:msup><mml:mi mathvariant="normal">S</mml:mi><mml:mi mathvariant="normal">S</mml:mi><mml:msup><mml:mi mathvariant="normal">T</mml:mi><mml:mo>−</mml:mo></mml:msup></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:msub><mml:mi>η</mml:mi><mml:mrow><mml:mi mathvariant="normal">U</mml:mi><mml:mi mathvariant="normal">P</mml:mi><mml:mi mathvariant="normal">E</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>w</mml:mi><mml:mrow><mml:mi mathvariant="normal">U</mml:mi><mml:mi mathvariant="normal">P</mml:mi><mml:msup><mml:mi mathvariant="normal">E</mml:mi><mml:mrow><mml:mo>−</mml:mo></mml:mrow></mml:msup></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:mi>R</mml:mi><mml:msub><mml:mi>r</mml:mi><mml:mrow><mml:mi>R</mml:mi></mml:mrow></mml:msub><mml:mo>−</mml:mo><mml:msub><mml:mi>w</mml:mi><mml:mrow><mml:mi mathvariant="normal">U</mml:mi><mml:mi mathvariant="normal">P</mml:mi><mml:msup><mml:mi mathvariant="normal">E</mml:mi><mml:mrow><mml:mo>−</mml:mo></mml:mrow></mml:msup><mml:mo>,</mml:mo><mml:mi mathvariant="normal">S</mml:mi><mml:mi mathvariant="normal">S</mml:mi><mml:mi mathvariant="normal">T</mml:mi></mml:mrow></mml:msub><mml:mo>−</mml:mo><mml:msub><mml:mi>r</mml:mi><mml:mrow><mml:mi mathvariant="normal">S</mml:mi><mml:mi mathvariant="normal">S</mml:mi><mml:msup><mml:mi mathvariant="normal">T</mml:mi><mml:mrow><mml:mo>−</mml:mo></mml:mrow></mml:msup></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:mo>,</mml:mo></mml:mrow></mml:math></disp-formula></p></sec><sec sec-type="appendix" id="s9"><title>Hierarchical predictive coding with uncertainties</title><p>The total energy across the <inline-formula><mml:math id="inf285"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>w</mml:mi><mml:mrow><mml:msup><mml:mrow><mml:mi mathvariant="normal">P</mml:mi><mml:mi mathvariant="normal">V</mml:mi></mml:mrow><mml:mrow><mml:mo>+</mml:mo><mml:mrow><mml:mo>/</mml:mo></mml:mrow><mml:mo>−</mml:mo></mml:mrow></mml:msup><mml:mo>,</mml:mo><mml:mtext>a</mml:mtext></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula> layers is<disp-formula id="equ51"><label>(33)</label><mml:math id="m51"><mml:mi>E</mml:mi><mml:mo>=</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mn>2</mml:mn></mml:mfrac><mml:munderover><mml:mo>∑</mml:mo><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>ℓ</mml:mi><mml:mo>=</mml:mo><mml:mn>0</mml:mn></mml:mrow><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>L</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:munderover><mml:mstyle scriptlevel="0"><mml:mrow class="MJX-TeXAtom-ORD"><mml:mo symmetric="true" maxsize="1.2em" minsize="1.2em">‖</mml:mo></mml:mrow></mml:mstyle><mml:mfrac><mml:msub><mml:mi>e</mml:mi><mml:mi>ℓ</mml:mi></mml:msub><mml:msub><mml:mi>σ</mml:mi><mml:mi>ℓ</mml:mi></mml:msub></mml:mfrac><mml:msup><mml:mstyle scriptlevel="0"><mml:mrow class="MJX-TeXAtom-ORD"><mml:mo symmetric="true" maxsize="1.2em" minsize="1.2em">‖</mml:mo></mml:mrow></mml:mstyle><mml:mn>2</mml:mn></mml:msup><mml:mspace width="thickmathspace"/><mml:mo>,</mml:mo></mml:math></disp-formula></p><p>where <inline-formula><mml:math id="inf286"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>σ</mml:mi><mml:mrow><mml:mi>ℓ</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula> and <inline-formula><mml:math id="inf287"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>e</mml:mi><mml:mrow><mml:mi>ℓ</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula> are vectors, and the division is taken component-wise. The error at layer <inline-formula><mml:math id="inf288"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>ℓ</mml:mi></mml:mrow></mml:mstyle></mml:math></inline-formula> is<disp-formula id="equ52"><label>(34)</label><mml:math id="m52"><mml:msub><mml:mi>e</mml:mi><mml:mi>ℓ</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:msub><mml:mi>r</mml:mi><mml:mi>ℓ</mml:mi></mml:msub><mml:mo>−</mml:mo><mml:mi>ρ</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>W</mml:mi><mml:mi>ℓ</mml:mi></mml:msub><mml:msub><mml:mi>r</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>ℓ</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:mspace width="thickmathspace"/><mml:mo>,</mml:mo></mml:math></disp-formula></p><p>where, <inline-formula><mml:math id="inf289"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>r</mml:mi><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mi>s</mml:mi></mml:mrow></mml:mstyle></mml:math></inline-formula> is the stochastic sensory input vector, and <inline-formula><mml:math id="inf290"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>r</mml:mi><mml:mrow><mml:mi>L</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula> represents a given context vector at the very top layer <inline-formula><mml:math id="inf291"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>L</mml:mi></mml:mrow></mml:mstyle></mml:math></inline-formula>. The only source of stochasticity is the stimulus <inline-formula><mml:math id="inf292"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>s</mml:mi></mml:mrow></mml:mstyle></mml:math></inline-formula>, for which the top-down input, <inline-formula><mml:math id="inf293"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>ρ</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>W</mml:mi><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msub><mml:msub><mml:mi>r</mml:mi><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mstyle></mml:math></inline-formula>, is an estimate of its mean.</p><sec sec-type="appendix" id="s9-1"><title>Dynamics for uncertainty-weighted prediction errors</title><p>We first consider the gradient dynamics <inline-formula><mml:math id="inf294"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mrow><mml:mover><mml:mi>r</mml:mi><mml:mo>˙</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>ℓ</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mo>−</mml:mo><mml:mfrac><mml:mrow><mml:mi mathvariant="normal">∂</mml:mi><mml:mi>E</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">∂</mml:mi><mml:msub><mml:mi>r</mml:mi><mml:mrow><mml:mi>ℓ</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfrac></mml:mrow></mml:mstyle></mml:math></inline-formula> for a fixed stimulus <inline-formula><mml:math id="inf295"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>s</mml:mi></mml:mrow></mml:mstyle></mml:math></inline-formula>, and assume that this converges to a critical point of <inline-formula><mml:math id="inf296"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>E</mml:mi></mml:mrow></mml:mstyle></mml:math></inline-formula> given by <inline-formula><mml:math id="inf297"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mfrac><mml:mrow><mml:mi mathvariant="normal">∂</mml:mi><mml:mi>E</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">∂</mml:mi><mml:msub><mml:mi>r</mml:mi><mml:mrow><mml:mi>ℓ</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfrac><mml:mo>=</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:mstyle></mml:math></inline-formula>. In our simulations, <inline-formula><mml:math id="inf298"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>s</mml:mi></mml:mrow></mml:mstyle></mml:math></inline-formula> is sampled from a Gaussian with constant mean, or a mean that changes in steps across time. We calculate (assuming that the variances <inline-formula><mml:math id="inf299"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msubsup><mml:mi>σ</mml:mi><mml:mrow><mml:mi>ℓ</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup></mml:mrow></mml:mstyle></mml:math></inline-formula> are constant),<disp-formula id="equ53"><label>(35)</label><mml:math id="m53"><mml:msub><mml:mrow class="MJX-TeXAtom-ORD"><mml:mover><mml:mi>r</mml:mi><mml:mo>˙</mml:mo></mml:mover></mml:mrow><mml:mi>ℓ</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mo>−</mml:mo><mml:mfrac><mml:mrow><mml:mi mathvariant="normal">∂</mml:mi><mml:mi>E</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">∂</mml:mi><mml:msub><mml:mi>r</mml:mi><mml:mi>ℓ</mml:mi></mml:msub></mml:mrow></mml:mfrac><mml:mo>=</mml:mo><mml:msubsup><mml:mi>W</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>ℓ</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>T</mml:mi></mml:msubsup><mml:mrow><mml:mo>(</mml:mo><mml:msup><mml:mi>ρ</mml:mi><mml:mo>′</mml:mo></mml:msup><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>W</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>ℓ</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:msub><mml:mi>r</mml:mi><mml:mi>ℓ</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:mo>⋅</mml:mo><mml:mfrac><mml:msub><mml:mi>e</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>ℓ</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:msubsup><mml:mi>σ</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>ℓ</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mn>2</mml:mn></mml:msubsup></mml:mfrac><mml:mo>)</mml:mo></mml:mrow><mml:mo>−</mml:mo><mml:mfrac><mml:msub><mml:mi>e</mml:mi><mml:mi>l</mml:mi></mml:msub><mml:msubsup><mml:mi>σ</mml:mi><mml:mi>l</mml:mi><mml:mn>2</mml:mn></mml:msubsup></mml:mfrac><mml:mspace width="thickmathspace"/><mml:mo>,</mml:mo></mml:math></disp-formula></p><p>where · denotes the component-wise product. To reveal the relation to our uncertainty-weighted prediction errors UPEs, we rewrite this equation as<disp-formula id="equ54"><label>(36)</label><mml:math id="m54"><mml:msub><mml:mrow class="MJX-TeXAtom-ORD"><mml:mover><mml:mi>r</mml:mi><mml:mo>˙</mml:mo></mml:mover></mml:mrow><mml:mi>ℓ</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:msub><mml:mi>M</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>ℓ</mml:mi></mml:mrow></mml:msub><mml:mspace width="thinmathspace"/><mml:mfrac><mml:msub><mml:mi>e</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>ℓ</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:msubsup><mml:mi>σ</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>ℓ</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mn>2</mml:mn></mml:msubsup></mml:mfrac><mml:mo>−</mml:mo><mml:mfrac><mml:msub><mml:mi>e</mml:mi><mml:mi>l</mml:mi></mml:msub><mml:msubsup><mml:mi>σ</mml:mi><mml:mi>l</mml:mi><mml:mn>2</mml:mn></mml:msubsup></mml:mfrac><mml:mspace width="thinmathspace"/><mml:mo>=</mml:mo><mml:msub><mml:mi>M</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>ℓ</mml:mi></mml:mrow></mml:msub><mml:mspace width="thinmathspace"/><mml:msub><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi mathvariant="normal">U</mml:mi><mml:mi mathvariant="normal">P</mml:mi><mml:mi mathvariant="normal">E</mml:mi></mml:mrow><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>ℓ</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>−</mml:mo><mml:msub><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi mathvariant="normal">U</mml:mi><mml:mi mathvariant="normal">P</mml:mi><mml:mi mathvariant="normal">E</mml:mi></mml:mrow><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>ℓ</mml:mi></mml:mrow></mml:msub><mml:mspace width="thickmathspace"/><mml:mo>,</mml:mo></mml:math></disp-formula></p><p>with matrix <inline-formula><mml:math id="inf300"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>M</mml:mi><mml:mrow><mml:mi>ℓ</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula> mapping from the lower layer <inline-formula><mml:math id="inf301"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>ℓ</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:mstyle></mml:math></inline-formula> to layer <inline-formula><mml:math id="inf302"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>ℓ</mml:mi></mml:mrow></mml:mstyle></mml:math></inline-formula>,<disp-formula id="equ55"><label>(37)</label><mml:math id="m55"><mml:msub><mml:mi>M</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>ℓ</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:msubsup><mml:mi>W</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>ℓ</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>T</mml:mi></mml:msubsup><mml:mspace width="thinmathspace"/><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi mathvariant="normal">d</mml:mi><mml:mi mathvariant="normal">i</mml:mi><mml:mi mathvariant="normal">a</mml:mi><mml:mi mathvariant="normal">g</mml:mi></mml:mrow><mml:mstyle scriptlevel="0"><mml:mrow class="MJX-TeXAtom-ORD"><mml:mo maxsize="1.2em" minsize="1.2em">(</mml:mo></mml:mrow></mml:mstyle><mml:msup><mml:mi>ρ</mml:mi><mml:mo>′</mml:mo></mml:msup><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>W</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>ℓ</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:msub><mml:mi>r</mml:mi><mml:mi>ℓ</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:mstyle scriptlevel="0"><mml:mrow class="MJX-TeXAtom-ORD"><mml:mo maxsize="1.2em" minsize="1.2em">)</mml:mo></mml:mrow></mml:mstyle><mml:mspace width="thinmathspace"/><mml:mo>.</mml:mo></mml:math></disp-formula></p><p><xref ref-type="disp-formula" rid="equ54">Equation 36</xref> is the general rate dynamics in a hierarchical predictive network. It represents a reformulation of the classical predictive coding model by <xref ref-type="bibr" rid="bib67">Rao and Ballard, 1999</xref>, but with a noise model that is restricted to Gaussian noise only in the stimulus <inline-formula><mml:math id="inf303"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>s</mml:mi></mml:mrow></mml:mstyle></mml:math></inline-formula>. Upper layer representations <inline-formula><mml:math id="inf304"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>r</mml:mi><mml:mrow><mml:mi>ℓ</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula> will inherit the noise from the sensory input by a propagation of the stochastic error <inline-formula><mml:math id="inf305"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>e</mml:mi><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mi>s</mml:mi><mml:mo>−</mml:mo><mml:mi>ρ</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>W</mml:mi><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msub><mml:msub><mml:mi>r</mml:mi><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mstyle></mml:math></inline-formula> to higher layers <inline-formula><mml:math id="inf306"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>ℓ</mml:mi></mml:mrow></mml:mstyle></mml:math></inline-formula>. We also consider a fixed prior on the context rate <inline-formula><mml:math id="inf307"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>r</mml:mi><mml:mrow><mml:mi>L</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula> at the top layer <inline-formula><mml:math id="inf308"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>L</mml:mi></mml:mrow></mml:mstyle></mml:math></inline-formula> that is not included in the energy.</p><p>Going beyond (<xref ref-type="bibr" rid="bib67">Rao and Ballard, 1999</xref>), we show how a microcircuit can explicitly learn the uncertainties <inline-formula><mml:math id="inf309"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msubsup><mml:mi>σ</mml:mi><mml:mrow><mml:mi>ℓ</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup></mml:mrow></mml:mstyle></mml:math></inline-formula>, and how they can scale the error representations. Notice that the dynamics of <xref ref-type="disp-formula" rid="equ54">Equation 36</xref> only contains divisions by <inline-formula><mml:math id="inf310"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msup><mml:mi>σ</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:mstyle></mml:math></inline-formula> in the UPEs, and hence will lead to a simple neuronal implementation as shown in <xref ref-type="fig" rid="fig8">Figure 8</xref> for two layers.</p><p>From <xref ref-type="disp-formula" rid="equ54">Equation 36</xref> we obtain the special case of <xref ref-type="disp-formula" rid="equ6">Equation 6</xref> in the main text, that is <inline-formula><mml:math id="inf311"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mrow><mml:mover><mml:mi>r</mml:mi><mml:mo>˙</mml:mo></mml:mover></mml:mrow><mml:mo>=</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:msubsup><mml:mtext>UPE</mml:mtext><mml:mrow><mml:mi>s</mml:mi></mml:mrow><mml:mrow><mml:mo>+</mml:mo></mml:mrow></mml:msubsup><mml:mo>−</mml:mo><mml:msubsup><mml:mtext>UPE</mml:mtext><mml:mrow><mml:mi>s</mml:mi></mml:mrow><mml:mrow><mml:mo>−</mml:mo></mml:mrow></mml:msubsup><mml:mo stretchy="false">)</mml:mo><mml:mo>−</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:msubsup><mml:mtext>UPE</mml:mtext><mml:mrow><mml:mi>p</mml:mi></mml:mrow><mml:mrow><mml:mo>+</mml:mo></mml:mrow></mml:msubsup><mml:mo>−</mml:mo><mml:msubsup><mml:mtext>UPE</mml:mtext><mml:mrow><mml:mi>p</mml:mi></mml:mrow><mml:mrow><mml:mo>−</mml:mo></mml:mrow></mml:msubsup><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mstyle></mml:math></inline-formula>, by choosing <inline-formula><mml:math id="inf312"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>ℓ</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:mstyle></mml:math></inline-formula>, <inline-formula><mml:math id="inf313"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>M</mml:mi><mml:mrow><mml:mi>ℓ</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula> the identity, and decomposing the uncertainty-modulated prediction error into the positive and negative part, <inline-formula><mml:math id="inf314"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="normal">U</mml:mi><mml:mi mathvariant="normal">P</mml:mi><mml:mi mathvariant="normal">E</mml:mi></mml:mrow><mml:mrow><mml:mi>ℓ</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:msubsup><mml:mrow><mml:mi mathvariant="normal">U</mml:mi><mml:mi mathvariant="normal">P</mml:mi><mml:mi mathvariant="normal">E</mml:mi></mml:mrow><mml:mrow><mml:mi>ℓ</mml:mi></mml:mrow><mml:mrow><mml:mo>+</mml:mo></mml:mrow></mml:msubsup><mml:mo>−</mml:mo><mml:msubsup><mml:mrow><mml:mi mathvariant="normal">U</mml:mi><mml:mi mathvariant="normal">P</mml:mi><mml:mi mathvariant="normal">E</mml:mi></mml:mrow><mml:mrow><mml:mi>ℓ</mml:mi></mml:mrow><mml:mrow><mml:mo>−</mml:mo></mml:mrow></mml:msubsup></mml:mrow></mml:mstyle></mml:math></inline-formula>.</p><p>Opposite of <inline-formula><mml:math id="inf315"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>r</mml:mi><mml:mrow><mml:mi>ℓ</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula> scaling by upper and lower uncertainties.</p><p>We next give two expressions for the steady state rate reached at <inline-formula><mml:math id="inf316"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mrow><mml:mover><mml:mi>r</mml:mi><mml:mo>˙</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>ℓ</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:mstyle></mml:math></inline-formula> with a given stimulus <inline-formula><mml:math id="inf317"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>s</mml:mi></mml:mrow></mml:mstyle></mml:math></inline-formula>. The steady state condition <inline-formula><mml:math id="inf318"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mrow><mml:mover><mml:mi>r</mml:mi><mml:mo>˙</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>ℓ</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mo>−</mml:mo><mml:mfrac><mml:mrow><mml:mi mathvariant="normal">∂</mml:mi><mml:mi>E</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">∂</mml:mi><mml:msub><mml:mi>r</mml:mi><mml:mrow><mml:mi>ℓ</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfrac><mml:mo>=</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:mstyle></mml:math></inline-formula> writes according to <xref ref-type="disp-formula" rid="equ54">Equation 36</xref> as<disp-formula id="equ56"><label>(38)</label><mml:math id="m56"><mml:msub><mml:mi>M</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>ℓ</mml:mi></mml:mrow></mml:msub><mml:mspace width="thinmathspace"/><mml:mfrac><mml:msub><mml:mi>e</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>ℓ</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:msubsup><mml:mi>σ</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>ℓ</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mn>2</mml:mn></mml:msubsup></mml:mfrac><mml:mo>−</mml:mo><mml:mfrac><mml:msub><mml:mi>e</mml:mi><mml:mi>l</mml:mi></mml:msub><mml:msubsup><mml:mi>σ</mml:mi><mml:mi>l</mml:mi><mml:mn>2</mml:mn></mml:msubsup></mml:mfrac><mml:mo>=</mml:mo><mml:mn>0</mml:mn><mml:mspace width="thickmathspace"/><mml:mo>,</mml:mo></mml:math></disp-formula></p><p>where <inline-formula><mml:math id="inf319"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>M</mml:mi><mml:mrow><mml:mi>ℓ</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula> is defined in <xref ref-type="disp-formula" rid="equ55">Equation 37</xref>. To lighten the notation, we abbreviate<disp-formula id="equ57"><label>(39)</label><mml:math id="m57"><mml:mrow><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msub><mml:mrow><mml:mover><mml:mi>r</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mi>ℓ</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mi>ρ</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>W</mml:mi><mml:mi>ℓ</mml:mi></mml:msub><mml:msub><mml:mi>r</mml:mi><mml:mrow><mml:mi>ℓ</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:mspace width="thickmathspace"/><mml:mo>.</mml:mo></mml:mstyle></mml:mrow></mml:math></disp-formula></p><p><inline-formula><mml:math id="inf320"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mrow><mml:mover><mml:mi>r</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>ℓ</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula> is the top-down estimate of the representation <inline-formula><mml:math id="inf321"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>r</mml:mi><mml:mrow><mml:mi>ℓ</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula>, based on the prior <inline-formula><mml:math id="inf322"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>r</mml:mi><mml:mrow><mml:mi>ℓ</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula> in the upper layer. The error defined in <xref ref-type="disp-formula" rid="equ52">Equation 34</xref> then writes as <inline-formula><mml:math id="inf323"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>e</mml:mi><mml:mrow><mml:mi>l</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:msub><mml:mi>r</mml:mi><mml:mrow><mml:mi>ℓ</mml:mi></mml:mrow></mml:msub><mml:mo>−</mml:mo><mml:msub><mml:mrow><mml:mover><mml:mi>r</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>ℓ</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula>. Plugging this into <xref ref-type="disp-formula" rid="equ56">Equation 38</xref>, yields a self-consistency equation for <inline-formula><mml:math id="inf324"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>r</mml:mi><mml:mrow><mml:mi>ℓ</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula><disp-formula id="equ58"><label>(40)</label><mml:math id="m58"><mml:msub><mml:mi>r</mml:mi><mml:mi>ℓ</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:msub><mml:mrow class="MJX-TeXAtom-ORD"><mml:mover><mml:mi>r</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mi>ℓ</mml:mi></mml:msub><mml:mo>+</mml:mo><mml:msubsup><mml:mi>σ</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>ℓ</mml:mi></mml:mrow><mml:mn>2</mml:mn></mml:msubsup><mml:mo>⋅</mml:mo><mml:mstyle scriptlevel="0"><mml:mrow class="MJX-TeXAtom-ORD"><mml:mo maxsize="1.623em" minsize="1.623em">(</mml:mo></mml:mrow></mml:mstyle><mml:msub><mml:mi>M</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>ℓ</mml:mi></mml:mrow></mml:msub><mml:mspace width="thinmathspace"/><mml:mfrac><mml:msub><mml:mi>e</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>ℓ</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:msubsup><mml:mi>σ</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>ℓ</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mn>2</mml:mn></mml:msubsup></mml:mfrac><mml:mstyle scriptlevel="0"><mml:mrow class="MJX-TeXAtom-ORD"><mml:mo maxsize="1.623em" minsize="1.623em">)</mml:mo></mml:mrow></mml:mstyle><mml:mspace width="thickmathspace"/><mml:mo>.</mml:mo></mml:math></disp-formula></p><p>Here, the divisive modulation of the error by the lower-layer uncertainty <inline-formula><mml:math id="inf325"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msubsup><mml:mi>σ</mml:mi><mml:mrow><mml:mi>ℓ</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup></mml:mrow></mml:mstyle></mml:math></inline-formula>, and the multiplicative modulation by the upper-layer uncertainty <inline-formula><mml:math id="inf326"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msubsup><mml:mi>σ</mml:mi><mml:mrow><mml:mi>ℓ</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup></mml:mrow></mml:mstyle></mml:math></inline-formula> becomes visible. This feature is shared by the full model of uncertainty-coding that considers independent Gaussian noise at each layer, and that takes the rate-dependency of <inline-formula><mml:math id="inf327"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msubsup><mml:mi>σ</mml:mi><mml:mrow><mml:mi>ℓ</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup></mml:mrow></mml:mstyle></mml:math></inline-formula> into account (resulting in second-order error driving the dynamics of <inline-formula><mml:math id="inf328"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>r</mml:mi><mml:mrow><mml:mi>ℓ</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula>, see <xref ref-type="bibr" rid="bib29">Granier et al., 2024</xref>). Crucially, again, the neuronal implementation of the dynamics in <xref ref-type="disp-formula" rid="equ54">Equation 36</xref> only requires the division by <inline-formula><mml:math id="inf329"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msubsup><mml:mi>σ</mml:mi><mml:mrow><mml:mi>ℓ</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup></mml:mrow></mml:mstyle></mml:math></inline-formula> and <inline-formula><mml:math id="inf330"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msubsup><mml:mi>σ</mml:mi><mml:mrow><mml:mi>ℓ</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup></mml:mrow></mml:mstyle></mml:math></inline-formula>, see also <xref ref-type="fig" rid="fig8">Figure 8</xref>.</p></sec><sec sec-type="appendix" id="s9-2"><title>Uncertainty representation as a convex combinations of rates</title><p>According to the dynamics in <xref ref-type="disp-formula" rid="equ54">Equation 36</xref>, the dynamics of the representation is given by a combination of bottom-up and top-down errors. The steady state is characterised by balanced errors, <inline-formula><mml:math id="inf331"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>M</mml:mi><mml:mrow><mml:mi>ℓ</mml:mi></mml:mrow></mml:msub><mml:mspace width="thinmathspace"/><mml:msub><mml:mrow><mml:mi mathvariant="normal">U</mml:mi><mml:mi mathvariant="normal">P</mml:mi><mml:mi mathvariant="normal">E</mml:mi></mml:mrow><mml:mrow><mml:mi>ℓ</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:msub><mml:mrow><mml:mi mathvariant="normal">U</mml:mi><mml:mi mathvariant="normal">P</mml:mi><mml:mi mathvariant="normal">E</mml:mi></mml:mrow><mml:mrow><mml:mi>ℓ</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula>. We next show that also on the level of the rates, the steady state can be written as a combination of bottom-up and top-down rates.</p><p>For this, we introduce the bottom-up error-corrected representation <inline-formula><mml:math id="inf332"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mrow><mml:mover><mml:mi>r</mml:mi><mml:mo stretchy="false">ˇ</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>ℓ</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula>, which is the representation <inline-formula><mml:math id="inf333"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>r</mml:mi><mml:mrow><mml:mi>ℓ</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula> updated by the uncertainty-weighted error from the lower layer,<disp-formula id="equ59"><label>(41)</label><mml:math id="m59"><mml:msub><mml:mrow class="MJX-TeXAtom-ORD"><mml:mover><mml:mi>r</mml:mi><mml:mo stretchy="false">ˇ</mml:mo></mml:mover></mml:mrow><mml:mi>ℓ</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:msub><mml:mi>r</mml:mi><mml:mi>ℓ</mml:mi></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mi>M</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>ℓ</mml:mi></mml:mrow></mml:msub><mml:mspace width="thinmathspace"/><mml:mfrac><mml:msub><mml:mi>e</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>ℓ</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:msubsup><mml:mi>σ</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>ℓ</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mn>2</mml:mn></mml:msubsup></mml:mfrac><mml:mspace width="thinmathspace"/><mml:mspace width="thickmathspace"/><mml:mo>.</mml:mo></mml:math></disp-formula></p><p>From this we obtain <inline-formula><mml:math id="inf334"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msubsup><mml:mi>σ</mml:mi><mml:mrow><mml:mi>ℓ</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup></mml:mrow></mml:mstyle></mml:math></inline-formula>, while <inline-formula><mml:math id="inf335"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>r</mml:mi><mml:mrow><mml:mi>ℓ</mml:mi></mml:mrow></mml:msub><mml:mo>−</mml:mo><mml:msub><mml:mrow><mml:mover><mml:mi>r</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>ℓ</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:msub><mml:mi>e</mml:mi><mml:mrow><mml:mi>l</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula> is the error from <xref ref-type="disp-formula" rid="equ52">Equation 34</xref>. Plugging these two expressions into the dynamics underlying <xref ref-type="disp-formula" rid="equ56">Equation 38</xref> yields<disp-formula id="equ60"><label>(42)</label><mml:math id="m60"><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mrow class="MJX-TeXAtom-ORD"><mml:mover><mml:mi>r</mml:mi><mml:mo stretchy="false">ˇ</mml:mo></mml:mover></mml:mrow><mml:mi>ℓ</mml:mi></mml:msub><mml:mo>−</mml:mo><mml:msub><mml:mi>r</mml:mi><mml:mi>ℓ</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:mo>+</mml:mo><mml:mfrac><mml:mrow><mml:msub><mml:mrow class="MJX-TeXAtom-ORD"><mml:mover><mml:mi>r</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mi>ℓ</mml:mi></mml:msub><mml:mo>−</mml:mo><mml:msub><mml:mi>r</mml:mi><mml:mi>ℓ</mml:mi></mml:msub></mml:mrow><mml:msubsup><mml:mi>σ</mml:mi><mml:mi>l</mml:mi><mml:mn>2</mml:mn></mml:msubsup></mml:mfrac><mml:mo>=</mml:mo><mml:mn>0</mml:mn><mml:mspace width="thickmathspace"/><mml:mo>.</mml:mo></mml:math></disp-formula></p><p>This <xref ref-type="disp-formula" rid="equ60">Equation 42</xref> now yields a self-consistency equation for <inline-formula><mml:math id="inf336"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>r</mml:mi><mml:mrow><mml:mi>ℓ</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula>, where the representation <inline-formula><mml:math id="inf337"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>r</mml:mi><mml:mrow><mml:mi>ℓ</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula> is a convex combination of the top-down prior <inline-formula><mml:math id="inf338"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mrow><mml:mover><mml:mi>r</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>ℓ</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula> and the bottom-up update <inline-formula><mml:math id="inf339"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mrow><mml:mover><mml:mi>r</mml:mi><mml:mo stretchy="false">ˇ</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>ℓ</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula>,<disp-formula id="equ61"><label>(43)</label><mml:math id="m61"><mml:msub><mml:mi>r</mml:mi><mml:mi>ℓ</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mi>c</mml:mi></mml:mfrac><mml:mstyle scriptlevel="0"><mml:mrow class="MJX-TeXAtom-ORD"><mml:mo maxsize="1.623em" minsize="1.623em">(</mml:mo></mml:mrow></mml:mstyle><mml:mfrac><mml:msub><mml:mrow class="MJX-TeXAtom-ORD"><mml:mover><mml:mi>r</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mi>ℓ</mml:mi></mml:msub><mml:msubsup><mml:mi>σ</mml:mi><mml:mi>l</mml:mi><mml:mn>2</mml:mn></mml:msubsup></mml:mfrac><mml:mo>+</mml:mo><mml:msub><mml:mrow class="MJX-TeXAtom-ORD"><mml:mover><mml:mi>r</mml:mi><mml:mo stretchy="false">ˇ</mml:mo></mml:mover></mml:mrow><mml:mi>ℓ</mml:mi></mml:msub><mml:mstyle scriptlevel="0"><mml:mrow class="MJX-TeXAtom-ORD"><mml:mo maxsize="1.623em" minsize="1.623em">)</mml:mo></mml:mrow></mml:mstyle><mml:mspace width="thinmathspace"/><mml:mo>.</mml:mo></mml:math></disp-formula></p><p>Here, <inline-formula><mml:math id="inf340"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>c</mml:mi><mml:mo>=</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:msubsup><mml:mi>σ</mml:mi><mml:mrow><mml:mi>ℓ</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup></mml:mfrac><mml:mo>+</mml:mo><mml:mrow><mml:mn mathvariant="bold">1</mml:mn></mml:mrow></mml:mrow></mml:mstyle></mml:math></inline-formula> is the sum of the certainty vector <inline-formula><mml:math id="inf341"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mn>1</mml:mn><mml:mrow><mml:mo>/</mml:mo></mml:mrow><mml:msubsup><mml:mi>σ</mml:mi><mml:mrow><mml:mi>ℓ</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup></mml:mrow></mml:mstyle></mml:math></inline-formula> at layer <inline-formula><mml:math id="inf342"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>ℓ</mml:mi></mml:mrow></mml:mstyle></mml:math></inline-formula> and the vector 1 of dim <inline-formula><mml:math id="inf343"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>r</mml:mi><mml:mrow><mml:mi>ℓ</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mstyle></mml:math></inline-formula> filled by 1’s. Hence, the integration of the UPEs according to <xref ref-type="disp-formula" rid="equ54">Equation 36</xref> converges to the convex combination of <inline-formula><mml:math id="inf344"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>r</mml:mi><mml:mrow><mml:mi>ℓ</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula> and <inline-formula><mml:math id="inf345"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mrow><mml:mover><mml:mi>r</mml:mi><mml:mo stretchy="false">ˇ</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>ℓ</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula> given by <xref ref-type="disp-formula" rid="equ61">Equation 43</xref>. This is the generalization of <xref ref-type="disp-formula" rid="equ4">Equation 4</xref> in the main text.</p></sec><sec sec-type="appendix" id="s9-3"><title>Interpretation of the convex combination</title><p><xref ref-type="disp-formula" rid="equ61">Equation 43</xref> can be interpreted in different ways: It gives</p><list list-type="bullet" id="list1"><list-item><p>the posterior rate <inline-formula><mml:math id="inf346"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>r</mml:mi><mml:mrow><mml:mi>ℓ</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula> as convex combination of the top-down prior <inline-formula><mml:math id="inf347"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mrow><mml:mover><mml:mi>r</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>ℓ</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula> (<xref ref-type="disp-formula" rid="equ61">Equation 43</xref>) and the bottom-up error-corrected representation <inline-formula><mml:math id="inf348"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mrow><mml:mover><mml:mi>r</mml:mi><mml:mo stretchy="false">ˇ</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>ℓ</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula> (<xref ref-type="disp-formula" rid="equ57">Equation 39</xref>). Notice that ‘prior’ and ‘posterior’ here do not imply the classical Bayesian inversion since the noise at the various layers <inline-formula><mml:math id="inf349"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>ℓ</mml:mi></mml:mrow></mml:mstyle></mml:math></inline-formula>, inherited from the stochastic stimulus <inline-formula><mml:math id="inf350"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>r</mml:mi><mml:mrow><mml:mi>ℓ</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula>, is not independent.</p></list-item><list-item><p>a self-consistency equation for the stationary rate <inline-formula><mml:math id="inf351"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>r</mml:mi><mml:mrow><mml:mi>ℓ</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula> satisfying <inline-formula><mml:math id="inf352"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mfrac><mml:mrow><mml:mi mathvariant="normal">∂</mml:mi><mml:mi>E</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">∂</mml:mi><mml:msub><mml:mi>r</mml:mi><mml:mrow><mml:mi>ℓ</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfrac><mml:mo>=</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:mstyle></mml:math></inline-formula>, with <inline-formula><mml:math id="inf353"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>r</mml:mi><mml:mrow><mml:mi>ℓ</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula> appearing also on the right-hand side of <xref ref-type="disp-formula" rid="equ61">Equation 43</xref> via <xref ref-type="disp-formula" rid="equ55 equ59">Equations 37 and 41</xref>.</p></list-item><list-item><p>an iterative scheme to calculate the steady-state representation <inline-formula><mml:math id="inf354"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>r</mml:mi><mml:mrow><mml:mi>ℓ</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula>, starting from the old value of <inline-formula><mml:math id="inf355"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>r</mml:mi><mml:mrow><mml:mi>ℓ</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula> on the right-hand side, and obtaining the new value on the left-hand side, if the iteration converges. The iteration typically converges due to the gradient descent construction.</p></list-item></list></sec></sec></app></app-group></back><sub-article article-type="editor-report" id="sa0"><front-stub><article-id pub-id-type="doi">10.7554/eLife.95127.4.sa0</article-id><title-group><article-title>eLife Assessment</article-title></title-group><contrib-group><contrib contrib-type="author"><name><surname>Keller</surname><given-names>Georg B</given-names></name><role specific-use="editor">Reviewing Editor</role><aff><institution>Friedrich Miescher Institute</institution><country>Switzerland</country></aff></contrib></contrib-group><kwd-group kwd-group-type="evidence-strength"><kwd>Compelling</kwd></kwd-group><kwd-group kwd-group-type="claim-importance"><kwd>Important</kwd></kwd-group></front-stub><body><p>This <bold>important</bold> study introduces a new cortical circuit model for predictive processing. Simulations effectively illustrate that, with appropriate synaptic plasticity, a canonical layer 2/3 cortical circuit - comprising two classes of interneurons providing subtractive and divisive inhibition - can generate uncertainty-modulated prediction errors by pyramidal neurons. The model is <bold>compelling</bold>; although it relies on many assumptions and has not yet been compared directly to data, the model does align with empirical observations and yields a range of testable predictions. The study is expected to be of great interest to those involved in cortical and predictive processing research.</p></body></sub-article><sub-article article-type="referee-report" id="sa1"><front-stub><article-id pub-id-type="doi">10.7554/eLife.95127.4.sa1</article-id><title-group><article-title>Reviewer #2 (Public review):</article-title></title-group><contrib-group><contrib contrib-type="author"><anonymous/><role specific-use="referee">Reviewer</role></contrib></contrib-group></front-stub><body><p>Summary:</p><p>This computational modeling study addresses the observation that variable observations are interpreted differently depending on how much uncertainty an agent expects from its environment. That is, the same mismatch between a stimulus and an expected stimulus would be less significant, and specifically would represent a smaller prediction error, in an environment with a high degree of variability than in one where observations have historically been similar to each other. The authors show that if two different classes of inhibitory interneurons, the PV and SST cells, (1) encode different aspects of a stimulus distribution and (2) act in different (divisive vs. subtractive) ways, and if (3) synaptic weights evolve in a way that causes the impact of certain inputs to balance the firing rates of the targets of those inputs, then pyramidal neurons in layer 2/3 of canonical cortical circuits can indeed encode uncertainty-modulated prediction errors. To achieve this result, SST neurons learn to represent the mean of a stimulus distribution and PV neurons its variance.</p><p>The impact of uncertainty on prediction errors in an understudied topic, and this study provides an intriguing and elegant new framework for how this impact could be achieved and what effects it could produce. The ideas here differ from past proposals about how neuronal firing represents uncertainty. The developed theory is accompanied by several predictions for future experimental testing, including the existence of different forms of coding by different subclasses of PV interneurons, which target different sets of SST interneurons (as well as pyramidal cells). The authors are able to point to some experimental observations that are at least consistent with their computational results. The simulations shown demonstrate that if we accept its assumptions, then the authors' theory works very well: SSTs learn to represent the mean of a stimulus distribution, PVs learn to estimate its variance, firing rates of other model neurons scale as they should, and the level of uncertainty automatically tunes the learning rate, so that variable observations are less impactful in a high uncertainty setting.</p><p>Strengths:</p><p>The ideas in this work are novel and elegant, and they are instantiated in a progression of simulations that demonstrate the behavior of the circuit. The framework used by the authors is biologically plausible and matches some known biological data. The results attained, as well as the assumptions that go into the theory, provide several predictions for future experimental testing. The authors have taken into account earlier review comments to revise their paper in ways that enhance its clarity.</p><p>Weaknesses:</p><p>One weakness could be that the proposed theory does rely on a fairly large number of assumptions. However, there is at least some biological support for these. Importantly, the authors do lay out and discuss their key assumptions in the Discussion section, so readers can assess their validity and implications for themselves.</p><p>Comments on revisions:</p><p>I have no further suggestions for the authors.</p></body></sub-article><sub-article article-type="referee-report" id="sa2"><front-stub><article-id pub-id-type="doi">10.7554/eLife.95127.4.sa2</article-id><title-group><article-title>Reviewer #4 (Public review):</article-title></title-group><contrib-group><contrib contrib-type="author"><anonymous/><role specific-use="referee">Reviewer</role></contrib></contrib-group></front-stub><body><p>Summary:</p><p>Wilmes and colleagues develop a model for the computation of uncertainty modulated prediction errors based on an experimentally inspired cortical circuit model for predictive processing. Predictive processing is a promising theory of cortical function. An essential aspect of the model is the idea of precision weighting of prediction errors. There is ample experimental evidence for prediction error responses in cortex. However, a central prediction of the theory is that these prediction error responses are regulated by the uncertainty of the input. Testing this idea experimentally has been difficult due to a lack of concrete models. This work provides one such model and makes experimentally testable predictions.</p><p>Strengths:</p><p>The model proposed is novel and well-implemented. It has sufficient biological accuracy to make useful and testable predictions.</p><p>Weaknesses:</p><p>One key idea the model hinges on is that stimulus uncertainty is encoded in the firing rate of parvalbumin positive interneurons. While this assumption is rather speculative, the model also here makes experimentally testable predictions.</p><p>Comments on revisions:</p><p>Congratulations on a very nice paper.</p></body></sub-article><sub-article article-type="author-comment" id="sa3"><front-stub><article-id pub-id-type="doi">10.7554/eLife.95127.4.sa3</article-id><title-group><article-title>Author response</article-title></title-group><contrib-group><contrib contrib-type="author"><name><surname>Wilmes</surname><given-names>Katharina Anna</given-names></name><role specific-use="author">Author</role><aff><institution>University of Bern</institution><addr-line><named-content content-type="city">Bern</named-content></addr-line><country>Switzerland</country></aff></contrib><contrib contrib-type="author"><name><surname>Petrovici</surname><given-names>Mihai A</given-names></name><role specific-use="author">Author</role><aff><institution>University of Bern</institution><addr-line><named-content content-type="city">Bern</named-content></addr-line><country>Switzerland</country></aff></contrib><contrib contrib-type="author"><name><surname>Sachidhanandam</surname><given-names>Shankar</given-names></name><role specific-use="author">Author</role><aff><institution>University of Bern</institution><addr-line><named-content content-type="city">Bern</named-content></addr-line><country>Switzerland</country></aff></contrib><contrib contrib-type="author"><name><surname>Senn</surname><given-names>Walter</given-names></name><role specific-use="author">Author</role><aff><institution>University of Bern</institution><addr-line><named-content content-type="city">Bern</named-content></addr-line><country>Switzerland</country></aff></contrib></contrib-group></front-stub><body><p>The following is the authors’ response to the previous reviews.</p><disp-quote content-type="editor-comment"><p><bold>Public Reviews:</bold></p><p><bold>Reviewer #2 (Public Review):</bold></p><p>Summary:</p><p>This computational modeling study addresses the observation that variable observations are interpreted differently depending on how much uncertainty an agent expects from its environment. That is, the same mismatch between a stimulus and an expected stimulus would be less significant, and specifically would represent a smaller prediction error, in an environment with a high degree of variability than in one where observations have historically been similar to each other. The authors show that if two different classes of inhibitory interneurons, the PV and SST cells, (1) encode different aspects of a stimulus distribution and (2) act in different (divisive vs. subtractive) ways, and if (3) synaptic weights evolve in a way that causes the impact of certain inputs to balance the firing rates of the targets of those inputs, then pyramidal neurons in layer 2/3 of canonical cortical circuits can indeed encode uncertainty-modulated prediction errors. To achieve this result, SST neurons learn to represent the mean of a stimulus distribution and PV neurons its variance.</p><p>The impact of uncertainty on prediction errors in an understudied topic, and this study provides an intriguing and elegant new framework for how this impact could be achieved and what effects it could produce. The ideas here differ from past proposals about how neuronal firing represents uncertainty. The developed theory is accompanied by several predictions for future experimental testing, including the existence of different forms of coding by different subclasses of PV interneurons, which target different sets of SST interneurons (as well as pyramidal cells). The authors are able to point to some experimental observations that are at least consistent with their computational results. The simulations shown demonstrate that if we accept its assumptions, then the authors’ theory works very well: SSTs learn to represent the mean of a stimulus distribution, PVs learn to estimate its variance, firing rates of other model neurons scale as they should, and the level of uncertainty automatically tunes the learning rate, so that variable observations are less impactful in a high uncertainty setting.</p><p>Strengths:</p><p>The ideas in this work are novel and elegant, and they are instantiated in a progression of simulations that demonstrate the behavior of the circuit. The framework used by the authors is biologically plausible and matches some known biological data. The results attained, as well as the assumptions that go into the theory, provide several predictions for future experimental testing. The authors have taken into account earlier review comments to revise their paper in ways that enhance its clarity.</p><p>Weaknesses:</p><p>One weakness could be that the proposed theory does rely on a fairly large number of assumptions. However, there is at least some biological support for these. Importantly, the authors do lay out and discuss their key assumptions in the Discussion section, so readers can assess their validity and implications for themselves.</p></disp-quote><p>Thank you very much, we are very satisfied with this public review.</p><disp-quote content-type="editor-comment"><p><bold>Reviewer #4 (Public Review):</bold></p><p>Summary:</p><p>Wilmes and colleagues develop a model for the computation of uncertainty modulated prediction errors based on an experimentally inspired cortical circuit model for predictive processing. Predictive processing is a promising theory of cortical function. An essential aspect of the model is the idea of precision weighting of prediction errors. There is ample experimental evidence for prediction error responses in cortex. However, a central prediction of the theory is that these prediction error responses are regulated by the uncertainty of the input. Testing this idea experimentally has been difficult due to a lack of concrete models. This work provides one such model and makes experimentally testable predictions.</p><p>Strengths:</p><p>The model proposed is novel and well-implemented. It has sufficient biological accuracy to make useful and testable predictions.</p><p>Weaknesses:</p><p>One key idea the model hinges on is that stimulus uncertainty is encoded in the firing rate of parvalbumin positive interneurons. This assumption, however, is rather speculative and there is no direct evidence for this.</p></disp-quote><p>Thank you very much for this nice description. With regard to the weakness: it is true that the key idea hinges on uncertainty being encoded in the firing of inhibitory neurons. If it turns out that these inhibitory neurons are not PV neurons, however, the theory does not break down. The suggestion of PV neurons is fueled by the observation that PV neurons implement shunting and hence divisive inhibition and by the connectivity of PVs in the circuit. We discuss this in the discussion section: &quot;To provide experimental predictions that are immediately testable, we suggested specific roles for SSTs and PVs, as they can subtractively and divisively modulate pyramidal cell activity, respectively. In principle, our theory more generally posits that any subtractive or divisive inhibition could implement the suggested computations. With the emerging data on inhibitory cell types, subtypes of SSTs and PVs or other cell types may turn out to play the proposed role.&quot;</p><disp-quote content-type="editor-comment"><p><bold>Recommendations for the authors:</bold></p><p><bold>Reviewer #4 (Recommendations For The Authors):</bold></p><p>(1) Line numbers would simplify reviewing.</p></disp-quote><p>We will add line numbers to our next submission.</p><disp-quote content-type="editor-comment"><p>(2) The existence of positive and negative PE was already suggested by Rao &amp; Ballard.</p></disp-quote><p>We added the citation to the sentence &quot;Because baseline firing rates are low in layer 2/3 pyramidal cells () positive and negative prediction errors were suggested to be represented by distinct neuronal populations [44,66],[...]&quot; in the section &quot;Computation of UPEs in cortical microcircuits&quot;.</p><disp-quote content-type="editor-comment"><p>(3) wekk should probably read well.</p></disp-quote><p>Indeed, thank you. We fixed it.</p><disp-quote content-type="editor-comment"><p>(4) Figure 4. legends A-C are mixed up. What are the two values of ¦s-u¦ in F and I - the same as in D and F.</p></disp-quote><p>Thank you, we fixed this.</p><disp-quote content-type="editor-comment"><p>(5) &quot;representation neurons, the activity of which reflects the internal model&quot;. For consistency with the original definitions this should read &quot;the activity of which reflects the internal representation&quot;. The internal &quot;model&quot; is the synaptic weights (or transformation between areas) - the activity of representation neurons (as the name implies) is the internal &quot;representation&quot;.</p></disp-quote><p>Thank you, we changed it.</p><disp-quote content-type="editor-comment"><p>(6) &quot;Mice trained in a predictable environment [...] [4].&quot; This should read &quot;reared&quot; in an unpredictable environment, etc. Relatedly, the problem with this argument is that, the referenced paper argues that the mice never learned to predict and the reduced PE responses are a consequence of a reduction in prediction strength (these mice never - in life - had experience of visuomotor coupling). Better evidence might be the acute changes observed in normal mice (see e.g. Figure 3B in <ext-link ext-link-type="uri" xlink:href="https://pubmed.ncbi.nlm.nih.gov/22681686/">https://pubmed.ncbi.nlm.nih.gov/22681686/</ext-link>). However, another finding from the paper referenced is that in mice reared without visuomotor coupling, MM responses of SST interneurons are unchanged, while those in PV interneurons are completely absent. Would the authors model come to similar results if trained in an environment with (very) high uncertainty and then tested in a low uncertainty environment?</p></disp-quote><p>Thank you for pointing us to Figure 3B of Keller et al. 2012. We are now citing this result as it is indeed better evidence.</p><p>Thank you very much for your illuminating question and for pointing out that a mouse that never experienced a predictable visual flow may not have formed a model of the visual flow, and hence may not have any prediction about its visual experience. We haven’t considered this scenario in our paper before. So far, we only considered scenarios, in which it is possible to learn a prediction, i.e. to infer the mean from the sensory input. We now consider this other scenario in which the mouse that was reared in an unpredictable environment did not form a prediction and compare SST (1) and PV (2) activity in this mouse to one that learned to form a prediction, and added it to the section &quot;Predictions for different cell types&quot;:</p><p>&quot;Second, prediction error activity seems to decrease in less predictable, and hence more uncertain, contexts: in mice reared in a predictable environment [where locomotion and visual flow match, 42], error neuron responses to mismatches in locomotion and visual flow decreased with each day of experiencing these unpredictable mismatches. Third, the responses of SSTs and PVs to mismatches between locomotion and visual flow [4] are in line with our model (note that in this experiment the mismatches are negative prediction errors as visual flow was halted despite ongoing locomotion): In this study, SST responses decreased during mismatch, i.e. when the visual flow was halted, and there was no difference between mice reared in a predictable or unpredictable environment. In line with these observations, the authors concluded that SST responses reflected the actual visual input. In our model negative PE circuit, SSTs also reflect the actual stimulus input, which in our case was a whisker stimulus (SST rates in Fig. 6C and I reflect the stimuli (black and grey bar) in A and G, respectively) and SST rates are the same for high and low uncertainty (corresponding to mice reared in a predictable or unpredictable environment). In the same study, PV responses were absent towards mismatches in animals reared in an unpredictable environment [4]. The authors argued that mice reared in an unpredictable environment did not learn to form a prediction. In our model, the missing prediction corresponds to missing predictive input from the auditory domain (e.g. due to undeveloped synapses from the predictive auditory input). If we removed the predictive input in our model, PVs in the negative PE circuit would also be silent as they would not receive any of the excitatory predictive inputs.&quot;</p><disp-quote content-type="editor-comment"><p>(7) &quot;Our model further posits the existence of two distinct subtypes of SSTs in positive and negative error circuits.&quot; There is some evidence for this: Figure 5a in <ext-link ext-link-type="uri" xlink:href="https://pubmed.ncbi.nlm.nih.gov/36747710/">https://pubmed.ncbi.nlm.nih.gov/36747710/</ext-link></p></disp-quote><p>Thank you, we added this citation to the corresponding section.</p></body></sub-article></article>