<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD with MathML3 v1.3 20210610//EN"  "JATS-archivearticle1-3-mathml3.dtd"><article xmlns:ali="http://www.niso.org/schemas/ali/1.0/" xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" article-type="research-article" dtd-version="1.3"><front><journal-meta><journal-id journal-id-type="nlm-ta">elife</journal-id><journal-id journal-id-type="publisher-id">eLife</journal-id><journal-title-group><journal-title>eLife</journal-title></journal-title-group><issn publication-format="electronic" pub-type="epub">2050-084X</issn><publisher><publisher-name>eLife Sciences Publications, Ltd</publisher-name></publisher></journal-meta><article-meta><article-id pub-id-type="publisher-id">102840</article-id><article-id pub-id-type="doi">10.7554/eLife.102840</article-id><article-id pub-id-type="doi" specific-use="version">10.7554/eLife.102840.3</article-id><article-version article-version-type="publication-state">version of record</article-version><article-categories><subj-group subj-group-type="display-channel"><subject>Tools and Resources</subject></subj-group><subj-group subj-group-type="heading"><subject>Neuroscience</subject></subj-group></article-categories><title-group><article-title>Automatic and accurate reconstruction of long-range axonal projections of single-neuron in mouse brain</article-title></title-group><contrib-group><contrib contrib-type="author"><name><surname>Cai</surname><given-names>Lin</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">https://orcid.org/0000-0002-4413-3599</contrib-id><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="aff" rid="aff2">2</xref><xref ref-type="fn" rid="con1"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author"><name><surname>Fan</surname><given-names>Taiyu</given-names></name><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="aff" rid="aff2">2</xref><xref ref-type="fn" rid="con2"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author"><name><surname>Qu</surname><given-names>Xuzhong</given-names></name><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="aff" rid="aff2">2</xref><xref ref-type="fn" rid="con3"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author"><name><surname>Zhang</surname><given-names>Ying</given-names></name><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="aff" rid="aff2">2</xref><xref ref-type="fn" rid="con4"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author"><name><surname>Gou</surname><given-names>Xianyu</given-names></name><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="aff" rid="aff2">2</xref><xref ref-type="fn" rid="con5"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author"><name><surname>Ding</surname><given-names>Quanwei</given-names></name><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="aff" rid="aff2">2</xref><xref ref-type="aff" rid="aff3">3</xref><xref ref-type="fn" rid="con6"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author"><name><surname>Feng</surname><given-names>Weihua</given-names></name><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="aff" rid="aff2">2</xref><xref ref-type="fn" rid="con7"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author"><name><surname>Cao</surname><given-names>Tingting</given-names></name><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="aff" rid="aff2">2</xref><xref ref-type="fn" rid="con8"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author"><name><surname>Lv</surname><given-names>Xiaohua</given-names></name><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="aff" rid="aff2">2</xref><xref ref-type="fn" rid="con9"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author"><name><surname>Liu</surname><given-names>Xiuli</given-names></name><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="aff" rid="aff2">2</xref><xref ref-type="fn" rid="con10"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author"><name><surname>Huang</surname><given-names>Qing</given-names></name><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="aff" rid="aff2">2</xref><xref ref-type="aff" rid="aff3">3</xref><xref ref-type="fn" rid="con11"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" corresp="yes"><name><surname>Quan</surname><given-names>Tingwei</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">https://orcid.org/0000-0002-8393-4292</contrib-id><email>quantingwei@hust.edu.cn</email><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="aff" rid="aff2">2</xref><xref ref-type="other" rid="fund1"/><xref ref-type="fn" rid="con12"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author"><name><surname>Zeng</surname><given-names>Shaoqun</given-names></name><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="aff" rid="aff2">2</xref><xref ref-type="fn" rid="con13"/><xref ref-type="fn" rid="conf1"/></contrib><aff id="aff1"><label>1</label><institution-wrap><institution-id institution-id-type="ror">https://ror.org/00p991c53</institution-id><institution>Britton Chance Center for Biomedical Photonics, Wuhan National Laboratory for Optoelectronics, Huazhong University of Science and Technology</institution></institution-wrap><addr-line><named-content content-type="city">Wuhan</named-content></addr-line><country>China</country></aff><aff id="aff2"><label>2</label><institution-wrap><institution-id institution-id-type="ror">https://ror.org/00p991c53</institution-id><institution>MOE Key Laboratory for Biomedical Photonics, Wuhan National Laboratory for Optoelectronics, Huazhong University of Science and Technology</institution></institution-wrap><addr-line><named-content content-type="city">Wuhan</named-content></addr-line><country>China</country></aff><aff id="aff3"><label>3</label><institution-wrap><institution-id institution-id-type="ror">https://ror.org/04jcykh16</institution-id><institution>School of Computer Science and Engineering, Hubei Key Laboratory of Intelligent Robot, Wuhan Institute of Technology</institution></institution-wrap><addr-line><named-content content-type="city">Wuhan</named-content></addr-line><country>China</country></aff></contrib-group><contrib-group content-type="section"><contrib contrib-type="editor"><name><surname>Naud</surname><given-names>Richard</given-names></name><role>Reviewing Editor</role><aff><institution-wrap><institution-id institution-id-type="ror">https://ror.org/03c4mmv16</institution-id><institution>University of Ottawa</institution></institution-wrap><country>Canada</country></aff></contrib><contrib contrib-type="senior_editor"><name><surname>Poirazi</surname><given-names>Panayiota</given-names></name><role>Senior Editor</role><aff><institution-wrap><institution-id institution-id-type="ror">https://ror.org/01gzszr18</institution-id><institution>FORTH Institute of Molecular Biology and Biotechnology</institution></institution-wrap><country>Greece</country></aff></contrib></contrib-group><pub-date publication-format="electronic" date-type="publication"><day>01</day><month>09</month><year>2025</year></pub-date><volume>13</volume><elocation-id>RP102840</elocation-id><history><date date-type="sent-for-review" iso-8601-date="2024-09-20"><day>20</day><month>09</month><year>2024</year></date></history><pub-history><event><event-desc>This manuscript was published as a preprint.</event-desc><date date-type="preprint" iso-8601-date="2024-09-23"><day>23</day><month>09</month><year>2024</year></date><self-uri content-type="preprint" xlink:href="https://doi.org/10.1101/2024.09.23.614432"/></event><event><event-desc>This manuscript was published as a reviewed preprint.</event-desc><date date-type="reviewed-preprint" iso-8601-date="2024-11-11"><day>11</day><month>11</month><year>2024</year></date><self-uri content-type="reviewed-preprint" xlink:href="https://doi.org/10.7554/eLife.102840.1"/></event><event><event-desc>The reviewed preprint was revised.</event-desc><date date-type="reviewed-preprint" iso-8601-date="2025-07-22"><day>22</day><month>07</month><year>2025</year></date><self-uri content-type="reviewed-preprint" xlink:href="https://doi.org/10.7554/eLife.102840.2"/></event></pub-history><permissions><copyright-statement>© 2024, Cai et al</copyright-statement><copyright-year>2024</copyright-year><copyright-holder>Cai et al</copyright-holder><ali:free_to_read/><license xlink:href="http://creativecommons.org/licenses/by/4.0/"><ali:license_ref>http://creativecommons.org/licenses/by/4.0/</ali:license_ref><license-p>This article is distributed under the terms of the <ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/licenses/by/4.0/">Creative Commons Attribution License</ext-link>, which permits unrestricted use and redistribution provided that the original author and source are credited.</license-p></license></permissions><self-uri content-type="pdf" xlink:href="elife-102840-v1.pdf"/><self-uri content-type="figures-pdf" xlink:href="elife-102840-figures-v1.pdf"/><abstract><p>Single-neuron axonal projections reveal the route map of neuron output and provide a key cue for understanding how information flows across the brain. Reconstruction of single-neuron axonal projections requires intensive manual operations in tens of terabytes of brain imaging data and is highly time-consuming and labor-intensive. The main issue lies in the need for precise reconstruction algorithms to avoid reconstruction errors, yet current methods struggle with densely distributed axons, focusing mainly on skeleton extraction. To overcome this, we introduce a point assignment-based method that uses cylindrical point sets to accurately represent axons and a minimal information flow tree model to suppress the snowball effect of reconstruction errors. Our method successfully reconstructs single-neuron axonal projections across hundreds of GBs (Gigabytes) images within a mouse brain with an average of 80% f1-score, while current methods only provide less than 40% f1-score reconstructions from a few hundred MBs (Megabytes) images. This huge improvement is helpful for high-throughput mapping of neuron projections.</p></abstract><kwd-group kwd-group-type="author-keywords"><kwd>neuronal axon reconstruction</kwd><kwd>long-range projection</kwd><kwd>dense axon identification</kwd></kwd-group><kwd-group kwd-group-type="research-organism"><title>Research organism</title><kwd>Mouse</kwd></kwd-group><funding-group><award-group id="fund1"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/501100001809</institution-id><institution>National Natural Science Foundation of China</institution></institution-wrap></funding-source><award-id>32471146</award-id><principal-award-recipient><name><surname>Quan</surname><given-names>Tingwei</given-names></name></principal-award-recipient></award-group><award-group id="fund2"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/501100009580</institution-id><institution>PLA General Hospital</institution></institution-wrap></funding-source><award-id>N20240194</award-id><principal-award-recipient><name><surname>Quan</surname><given-names>Tingwei</given-names></name></principal-award-recipient></award-group><funding-statement>The funders had no role in study design, data collection and interpretation, or the decision to submit the work for publication.</funding-statement></funding-group><custom-meta-group><custom-meta specific-use="meta-only"><meta-name>Author impact statement</meta-name><meta-value>A novel point assignment method achieves 80% f1-score in single-neuron reconstruction across broad brain regions, enabling high-throughput brain-wide projection mapping.</meta-value></custom-meta><custom-meta specific-use="meta-only"><meta-name>publishing-route</meta-name><meta-value>prc</meta-value></custom-meta></custom-meta-group></article-meta></front><body><sec id="s1" sec-type="intro"><title>Introduction</title><p>Neuronal axons in general project to different brain regions, and their projection distribution is an essential cue for neuron type identification, neuronal circuit construction, and deeper insight into how information flows in the brain (<xref ref-type="bibr" rid="bib14">Huang and Luo, 2015</xref>; <xref ref-type="bibr" rid="bib26">Meijering, 2010</xref>; <xref ref-type="bibr" rid="bib29">Parekh and Ascoli, 2013</xref>; <xref ref-type="bibr" rid="bib56">Zingg et al., 2014</xref>). Advances in optical imaging and molecular labeling techniques (<xref ref-type="bibr" rid="bib1">Cai et al., 2019</xref>; <xref ref-type="bibr" rid="bib5">Chung and Deisseroth, 2013</xref>; <xref ref-type="bibr" rid="bib6">Çiçek et al., 2016</xref>; <xref ref-type="bibr" rid="bib17">Kim and Schnitzer, 2022</xref>; <xref ref-type="bibr" rid="bib18">Li et al., 2010</xref>; <xref ref-type="bibr" rid="bib28">Osten and Margrie, 2013</xref>) have allowed us to observe the entire mouse brain at single-axon resolution and provided the database for the study of neuronal projection patterns (<xref ref-type="bibr" rid="bib8">Foster et al., 2021</xref>; <xref ref-type="bibr" rid="bib10">Gao et al., 2022</xref>; <xref ref-type="bibr" rid="bib27">Muñoz-Castañeda et al., 2021</xref>; <xref ref-type="bibr" rid="bib32">Peng et al., 2021</xref>; <xref ref-type="bibr" rid="bib33">Qiu et al., 2024</xref>; <xref ref-type="bibr" rid="bib39">Sun et al., 2019</xref>; <xref ref-type="bibr" rid="bib48">Xu et al., 2021</xref>; <xref ref-type="bibr" rid="bib51">Zeng, 2022</xref>). However, the reconstruction of these long-range projected axons still requires extensive manual annotation in tens of TBs volumetric images (<xref ref-type="bibr" rid="bib6">Çiçek et al., 2016</xref>; <xref ref-type="bibr" rid="bib9">Friedmann et al., 2020</xref>; <xref ref-type="bibr" rid="bib42">Wang et al., 2019</xref>; <xref ref-type="bibr" rid="bib45">Winnubst et al., 2019</xref>; <xref ref-type="bibr" rid="bib55">Zhou et al., 2021</xref>), this labor-intensive process creates a major bottleneck for high-throughput mapping of neuronal projections (<xref ref-type="bibr" rid="bib50">Zeng and Sanes, 2017</xref>).</p><p>The difficulties in reconstructing the long-range projections of neurons are as follows. On the one hand, while molecular labeling techniques can shed light on a very small fraction of neurons, a significant fraction of neuronal axons is still densely distributed due to the morphological complexity of neurons. The identification of densely distributed axons is considered an open problem in the field (<xref ref-type="bibr" rid="bib19">Li et al., 2019</xref>; <xref ref-type="bibr" rid="bib22">Lichtman and Denk, 2011</xref>; <xref ref-type="bibr" rid="bib50">Zeng and Sanes, 2017</xref>), which still has no good solution. On the other hand, during neuron reconstruction, reconstruction errors accumulate, and a single reconstruction error can result in an entire branch being connected erroneously to other neurons or missing (<xref ref-type="bibr" rid="bib13">Helmstaedter, 2013</xref>). Therefore, effective large-scale reconstruction of neurons requires extremely high identification accuracy of dense axons. The contradictions between these two aspects seem hard to reconcile.</p><p>The current neuron reconstruction frameworks focus on how to accurately extract skeletons of neurites and establish the connections between skeletons (<xref ref-type="bibr" rid="bib26">Meijering, 2010</xref>; <xref ref-type="bibr" rid="bib31">Peng et al., 2015</xref>). The BigNeuron project (<xref ref-type="bibr" rid="bib24">Manubens-Gil et al., 2023</xref>) conducts a systematic evaluation of 35 automatic neuron reconstruction algorithms, all of which are based on tracing neurite skeletons and can be divided into two categories: local and global approaches. In the local approach (<xref ref-type="bibr" rid="bib4">Choromanska et al., 2012</xref>; <xref ref-type="bibr" rid="bib20">Li et al., 2020</xref>; <xref ref-type="bibr" rid="bib30">Peng et al., 2011</xref>; <xref ref-type="bibr" rid="bib49">Yang et al., 2013</xref>), the localization of the next skeleton point requires computation of the signal anisotropy of the image region near the current skeleton point. Localization errors typically occur when this image region contains other neurite signals. The global approach (<xref ref-type="bibr" rid="bib19">Li et al., 2019</xref>; <xref ref-type="bibr" rid="bib40">Türetken et al., 2011</xref>; <xref ref-type="bibr" rid="bib47">Xiao and Peng, 2013</xref>) first generates multiple seed points that are commonly located at the neurite centerline and then establishes connections between these seed points for generating the neurite skeleton. This connection relies mainly on spatial location information, resulting in densely distributed neurites being connected to each other erroneously. While deep learning is widely used in neuron reconstruction (<xref ref-type="bibr" rid="bib15">Huang et al., 2020</xref>; <xref ref-type="bibr" rid="bib21">Li and Shen, 2020</xref>; <xref ref-type="bibr" rid="bib23">Liu et al., 2022</xref>; <xref ref-type="bibr" rid="bib54">Zhou et al., 2018</xref>), - mainly for neuronal image segmentation and signal intensity enhancement to reduce reconstruction errors - even ideal segmentation with all neurite centers identified and their signal enhanced still exhibits significant reconstruction errors with skeleton-based methods (<xref ref-type="fig" rid="fig1s1">Figure 1—figure supplement 1</xref>).</p><p>To address the problem of error accumulation during neuron reconstruction, it is common practice to utilize statistical information of neuron morphology, such as the angle between two neurites, to identify and remove spurious connections between the reconstructed neurites. This strategy (<xref ref-type="bibr" rid="bib19">Li et al., 2019</xref>; <xref ref-type="bibr" rid="bib34">Quan et al., 2016</xref>) achieves 80% reconstruction accuracy from GB-scale images under two critical constraints: (1) precise identification of neurite terminals and branch points is required for accurate angle computation and morphological analysis, and (2) somatic locations are required as critical information to remove some links between the reconstructed neurites to ensure that each cell body can be mapped to the root node of a single tree structure. However, for long-range axonal reconstruction across hundreds of GB-scale images, the strategy is not effective to eliminate the accumulation of errors due to factors such as the position of the axon at a distance from the soma and slight morphological differences between axon junction and termination. Consequently, current long-range projection reconstruction methods are semi-automatic and require substantial human intervention (<xref ref-type="bibr" rid="bib11">Gao et al., 2023</xref>; <xref ref-type="bibr" rid="bib42">Wang et al., 2019</xref>; <xref ref-type="bibr" rid="bib45">Winnubst et al., 2019</xref>; <xref ref-type="bibr" rid="bib55">Zhou et al., 2021</xref>).</p><p>Here, we propose a new neuron reconstruction method called PointTree, which aims at how to assign foreground points in neuronal images to their own neurons. In the workflow, we design a constrained Gaussian clustering method to partition the foreground region of a neuronal image into a series of columnar regions whose centerline belongs to only a single neurite. This operation essentially eliminates the interference of different neurites in the dense reconstruction. In addition, each columnar region is characterized by a minimal envelope ellipsoid for constructing connections between columnar regions, which forms the neurite shapes. Based on the reconstructed shapes, we design a minimal information flow tree model to suppress the cumulative reconstruction error. Using the proposed method, we successfully achieve accurate reconstruction of long-range projections of neurons across hundreds of gigabytes of volumetric image.</p></sec><sec id="s2" sec-type="results"><title>Results</title><sec id="s2-1"><title>The architecture and principles of PointTree</title><p>In the design of PointTree, we have developed a series of optimization problems to assign foreground points in data blocks to their respective neurites. Firstly, the segment network is utilized for each data block to obtain foreground points. Subsequently, we apply a constrained Gaussian clustering method (<xref ref-type="bibr" rid="bib36">Reynolds, 2009</xref>) to partition the foreground points into columnar regions and determine their geometrical parameters by solving the minimum-volume covering ellipsoids problem (<xref ref-type="bibr" rid="bib38">Sun and Freund, 2004</xref>). Using these geometrical parameters, we construct a 0–1 assignment problem (<xref ref-type="bibr" rid="bib41">Volgenant, 1996</xref>) to establish links between these columnar regions. Finally, skeletons are extracted from these linked columnar regions to reduce data redundancy by using region growing (<xref ref-type="bibr" rid="bib12">Harris, 2011</xref>). The key procedures for neuron reconstruction are presented in <xref ref-type="fig" rid="fig1">Figure 1A</xref>.</p><fig-group><fig id="fig1" position="float"><label>Figure 1.</label><caption><title>Summary and principle of PointTree.</title><p>(<bold>A</bold>) The reconstruction procedure of PointTree involves the generation, clustering, and connection of foreground points (the first row). Within this procedure, three optimization problems are designed to allocate the foreground points into their respective neurites (the second row). (<bold>B</bold>) Schematic diagram of information flow score calculation. In a neurite branch with a fixed root node (green circle), the information flow score is calculated based on the assumption that a neurite has few directional changes. The assumption determines the neurite directly connecting to the root node (red), resulting in two branch angles used to calculate the information flow score. (<bold>C</bold>) Statistical analysis of the consistency between the minimum information flow and the real situation. For 208 neurite branches, the information flow scores are calculated as ground truth according to their manually determined skeletons and root nodes. These scores are then displayed in ascending order. The root nodes of neurite branches are changed to generate both maximum and minimum information flow scores. (<bold>D</bold>) One neurite branch is decomposed into two by minimizing the total information flow scores. (<bold>E</bold>) Performance of different methods on separating closely paralleled neurites. In PointTree, a single neurite is represented by a series of ellipsoids whose centerlines are not simultaneously located within different neurites. They are connected using an ellipsoid shape, which results in perfect reconstruction (Left). However, skeleton-based methods fail to separate two closely paralleled neurites due to interference from other signals (Red circle in middle) or connections being interfered with by another neighboring skeleton point (Red circle in right).</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-102840-fig1-v1.tif"/></fig><fig id="fig1s1" position="float" specific-use="child-fig"><label>Figure 1—figure supplement 1.</label><caption><title>Comparison of PointTree and several skeleton-based methods for reconstructing the segmented image block derived from ground-truth skeletons.</title><p>The ground-truth skeletons are generated using GTree (a semi-automatic software) with manual modification. A series of Gaussian kernels with mean values equal to the coordinates of skeleton points are summed to obtain the corresponding probability image block. The segmented image block is finally generated using a threshold method.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-102840-fig1-figsupp1-v1.tif"/></fig><fig id="fig1s2" position="float" specific-use="child-fig"><label>Figure 1—figure supplement 2.</label><caption><title>The generation of minimal information flow tree.</title><p>In (<bold>A</bold>), the calculation of the information flow score for a branch of neurites with root node 1 is illustrated. The reconstructed skeletons are transformed into a binary structure based on the root node, and the angles with respect to branching nodes labeled with brown circles determine the information flow. These angles will change when the root node changes. The angle of a branching node is formed by its father and child nodes, as exemplified by the N2 node. In (<bold>B</bold>), the optimization of tree structure to minimize the total information flow score is demonstrated. It shows that decreasing the information flow leads to a more proper tree structure. The second row of (<bold>B</bold>) provides an example of decomposing tree structure into two individual parts.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-102840-fig1-figsupp2-v1.tif"/></fig><fig id="fig1s3" position="float" specific-use="child-fig"><label>Figure 1—figure supplement 3.</label><caption><title>Post-processing for structures violating the MIFT rule.</title><p>(<bold>A</bold>) MIFT criterion will incorrectly split neurites with sharp directional changes into two branches, but the splitting location is explicitly recorded during this process. (<bold>B</bold>) Our algorithm searches for connectable neurites around the head nodes identified by MIFT. If no connectable neurites are found for both head nodes, the algorithm will reconnect them based on the recorded splitting points to prevent isolated neurite fragments. (<bold>C</bold>) presents two real examples violating the MIFT criterion. Through post-processing, PointTree successfully reconnects the split branches back to the correct neurites.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-102840-fig1-figsupp3-v1.tif"/></fig><fig id="fig1s4" position="float" specific-use="child-fig"><label>Figure 1—figure supplement 4.</label><caption><title>Tree structure derived from SWC file that records the axonal reconstruction.</title><p>(<bold>A</bold>) shows an input swc file and its corresponding skeleton structure. (<bold>B</bold>) shows how the reconstructed skeletons are converted to a binary tree structure.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-102840-fig1-figsupp4-v1.tif"/></fig></fig-group><p>In addition, PointTree employed the statistical prior information to reduce the reconstruction errors. At the branching point (node) of the neurites, it can be divided into three segments of neurite skeletons. The segment entering the node forms two angles with the other two segments exiting the node respectively. The node angle is defined as the smaller angle between the entering segment and each exiting segment (<xref ref-type="fig" rid="fig1">Figure 1B</xref>). With node angle, we can identify the single complete neurite and its corresponding node angles. The skeleton of the neurite is generally smooth, with very few sudden directional changes and even fewer at the nodes. So, the node angles should be as small as possible. For neuronal branches, the node angles are uniquely determined when the root node is given, and the sum of the negative cosine of these node angles expressed by information flow value is small when the root node is correctly identified. This rule is defined as a minimal information flow tree (MIFT).</p><p>In image blocks of densely distributed neurites, we used semi-automatic software (<xref ref-type="bibr" rid="bib55">Zhou et al., 2021</xref>) extracting 208 neuronal branches and identifying their root nodes. For each branch, we calculated their information flow values as the ground-truth information flow values (<xref ref-type="fig" rid="fig1">Figure 1C</xref>). To validate MIFT, we looped through all possible structures of these branches by changing the root node in order to compute the maximum and minimum information flow values (<xref ref-type="fig" rid="fig1">Figure 1C</xref>). It is evident that, for most neuronal branches (195/208), the ground-truth values of the information flow achieve the minimum value, suggesting that MIFT rule is reasonable. We utilized MIFT to modify skeleton structure and remove spurious connections between reconstructed neurites (<xref ref-type="fig" rid="fig1">Figure 1D</xref> and <xref ref-type="fig" rid="fig1s2">Figure 1—figure supplement 2</xref>), both for reconstructions within individual blocks and for the fused reconstruction in adjacent blocks.</p><p>PointTree has the capability to separate densely distributed neurites. When dealing with two parallel neurites in close proximity to each other, their shapes can be represented by a series of columnar regions (the left panels of <xref ref-type="fig" rid="fig1">Figure 1E</xref>). We have modified the Gaussian clustering algorithm by constraining the estimated mean and covariance parameters so that the cluster shape approaches a columnar shape. Additionally, foreground points within the same cluster are connected to each other. These two features ensure that the central line in the columnar region belongs to only a single neurite, which is crucial for separating densely packed neurites. Furthermore, we utilize the minimum volume covering ellipsoid to extract shape information of the columnar regions for constructing their connections. These designs enable PointTree to successfully reconstruct packed neurites. In contrast, skeleton-based local methods rely on determining the position of the next skeleton point based on the shape anisotropy of the region. This often leads to localization errors when there are two neurite image signals within a region (the middle panels of <xref ref-type="fig" rid="fig1">Figure 1E</xref>). When it comes to skeleton-based global methods, although seed points can be located at individual neurite centers, accurately constructing connections between these seed points proves challenging due to the reliance on distance between points and susceptibility to interference from densely distributed neurites (the right panels of <xref ref-type="fig" rid="fig1">Figure 1E</xref>).</p></sec><sec id="s2-2"><title>The merits of PointTree in dense reconstruction</title><p>In dense reconstruction, one of the main concerns is how well to separate densely distributed neurites that behave as crossover and closely paralleled neurites. These neurites can be manually identified by visualization with different view angles (<xref ref-type="fig" rid="fig2s1">Figure 2—figure supplement 1</xref>). We compared PointTree with several skeleton-based methods such as neuTube (<xref ref-type="bibr" rid="bib7">Feng et al., 2015</xref>), PHDF (<xref ref-type="bibr" rid="bib35">Radojevic and Meijering, 2017</xref>), NGPST (<xref ref-type="bibr" rid="bib34">Quan et al., 2016</xref>), and MOST (<xref ref-type="bibr" rid="bib46">Wu et al., 2014</xref>) in performing this task. We manually labeled the locations where neurites are crossover or closely parallel from five 256×256 × 256 image blocks. For a fair comparison, all methods are performed on segmented images derived from the segmentation network. <xref ref-type="fig" rid="fig2">Figure 2A</xref> illustrates the process of PointTree’s separation of crossover and closely paralleled neurites. PointTree can successfully separate the densely distributed neurites in a range of 71.4% and 91.7%, while these skeleton-based methods only separate 25.0% densely distributed neurites (<xref ref-type="fig" rid="fig2">Figure 2B</xref>) at most. We also present the comparison of PointTree and other methods on some reconstruction examples in which multi-crossover neurites (<xref ref-type="fig" rid="fig2">Figure 2C</xref>) and closely paralleled neurites are involved. PointTree provides the perfect reconstruction while other methods fail to reconstruct these neurites.</p><fig-group><fig id="fig2" position="float"><label>Figure 2.</label><caption><title>Performance of PointTree on crossover and closely paralleled neurites.</title><p>(<bold>A</bold>) The reconstruction process of crossover and closely paralleled neurites. (<bold>B</bold>) Quantitative evaluation of PointTree and several skeleton-based methods on identifying closely distributed neurites. The box plots present the statistical information (n=5) in which the horizontal line in the box, the lower and upper borders of the box represent the median value, the first quartile (<bold>Q1</bold>), and the third quartile (<bold>Q3</bold>), respectively. The vertical black lines indicate 1.5 × IQR. (<bold>C</bold>) Three reconstruction examples derived from PointTree and several skeleton-based methods.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-102840-fig2-v1.tif"/></fig><fig id="fig2s1" position="float" specific-use="child-fig"><label>Figure 2—figure supplement 1.</label><caption><title>Visualization of two parallel neurites with different viewing angles.</title><p>When the two parallel neurites are in close proximity, they can be distinguished by visualizing them from different angles.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-102840-fig2-figsupp1-v1.tif"/></fig></fig-group><p>Furthermore, we present the quantitative results derived from PointTree and five widely used skeleton-based reconstruction methods, including APP2, neuTube, NGPST, PHDF, and MOST. Eight 256×256 × 256 image blocks that include many densely distributed neurites are of the testing dataset. All reconstruction algorithms are performed on the segmentation images of these testing datasets. We give the intuitive reconstruction comparisons (<xref ref-type="fig" rid="fig3">Figure 3A</xref>). PointTree provides the reconstruction close to the ground truth. The skeleton-based methods generate lots of reconstruction errors and incorrectly combine multi-neurites into a single branch. The quantitative reconstructions suggest that PointTree is far superior to skeleton-based methods (<xref ref-type="fig" rid="fig3">Figure 3B</xref>). For PointTree, the average precision is above 90%, both recall and f1-score are above 85%. The skeleton-based methods cannot provide a good solution to separate the densely packed neurites. The f1-score of these reconstructions ranges from 30% to 40%, which indicates the ineffective reconstructions.</p><fig id="fig3" position="float"><label>Figure 3.</label><caption><title>Comparison of reconstruction methods on image blocks containing densely distributed neurites.</title><p>(<bold>A</bold>) Comparison of reconstruction performance among six methods, including PointTree, NGPST, neuTube, APP2, PHDF, and MOST. Individual neurite branches are delineated in different colors. (<bold>B</bold>) Quantitative evaluation of reconstruction performance using precision, recall, and f1-score. The box plots display these three evaluation indexes (n=8). In the box, the horizontal line represents the median value. The box shows the interquartile range (IQR) from the first quartile (<bold>Q1</bold>) to the third quartile (<bold>Q3</bold>). The vertical lines indicate 1.5×IQR.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-102840-fig3-v1.tif"/></fig></sec><sec id="s2-3"><title>Reconstruction of data with different signal-to-noise ratios</title><p>In the field of neuronal reconstruction, data acquired by different imaging systems often exhibit varying signal-to-noise ratio (SNR) characteristics. For some low-SNR datasets, severe noise interference makes it difficult even for human observers to accurately identify neurite structures. To systematically evaluate PointTree’s reconstruction performance across datasets with different SNRs, we selected and analyzed data from three imaging systems: light sheet microscopy (<xref ref-type="bibr" rid="bib37">Stelzer et al., 2021</xref>) (LSM), fluorescent micro-optical sectioning tomography (<xref ref-type="bibr" rid="bib43">Wang et al., 2021</xref>) (fMOST), and high-definition fluorescent micro-optical sectioning tomography (<xref ref-type="bibr" rid="bib53">Zhong et al., 2021</xref>) (HD-fMOST), with SNR ranges of 2–7, 6–12, and 9–14, respectively (<xref ref-type="fig" rid="fig4">Figure 4A</xref>).</p><fig id="fig4" position="float"><label>Figure 4.</label><caption><title>Reconstruction performance of PointTree across data with different signal-to-noise ratios.</title><p>(<bold>A</bold>) Data blocks from light sheet microscopy (LSM), fluorescent micro-optical sectioning tomography (fMOST), and high-definition fluorescent micro-optical sectioning tomography (HD-fMOST) are selected. SNR and corresponding reconstruction scores with PointTree are drawn with line charts. Each dataset is of sample size n=25 and each data block size of 128×128 × 128. (<bold>B</bold>) shows reconstruction performance of PointTree on different datasets. (<bold>C</bold>) The zoomed-in view displays the region marked by white box in the first column of (<bold>B</bold>), with 25 foreground points and 25 background points sampled respectively. The signal intensities of both the foreground points and background points are plotted in the adjacent line charts.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-102840-fig4-v1.tif"/></fig><p>Experimental results demonstrate that, thanks to the powerful feature extraction capability of the deep learning network, the trained neural network achieves satisfactory segmentation performance (third row in <xref ref-type="fig" rid="fig4">Figure 4B</xref>) even on low-SNR data (first two columns in <xref ref-type="fig" rid="fig4">Figure 4B</xref>, top row), laying a solid foundation for subsequent accurate reconstruction (bottom row in <xref ref-type="fig" rid="fig4">Figure 4B</xref>). Quantitative analysis reveals that PointTree delivers stable reconstruction performance across all SNR levels. Specifically: for LSM data (sample size n=25, mean SNR = 5.01), average precision = 96.0%, recall = 88.7%, and f1-score=91.0%; for fMOST data (sample size n=25, mean SNR = 8.68), average precision = 95.8%, recall = 87.3%, and f1-score=90.0%; for HD-fMOST data (sample size n=25, mean SNR = 11.4), average precision = 98.1%, recall = 91.0%, and f1-score=93.3% (<xref ref-type="fig" rid="fig4">Figure 4A</xref>).</p><p>Notably, in low-SNR LSM data, background regions contain more artifactual signals (first panel in <xref ref-type="fig" rid="fig4">Figure 4C</xref>) due to similar intensity distributions between background and foreground points. In contrast, high-SNR datasets (fMOST and HD-fMOST) exhibit cleaner background features with distinct intensity separation between background noise and neurite signals (second and third panel in <xref ref-type="fig" rid="fig4">Figure 4C</xref>). This observation highlights the critical impact of SNR on reconstruction quality while simultaneously validating the robustness of PointTree, which is aided by the segmentation network, across diverse SNR conditions.</p></sec><sec id="s2-4"><title>Restrain error accumulation in the reconstruction</title><p>In order to achieve accurate axon reconstruction, it is essential to effectively suppress the snowballing accumulation of reconstruction errors. The performance of the minimal information flow tree (MIFT) in retraining the reconstruction errors is evaluated in this study. <xref ref-type="fig" rid="fig5">Figure 5A</xref> presents six 512×512 × 512 image blocks and their reconstructions using PointTree in the first column. The reconstruction fusing procedure is then performed on these axonal reconstructions (<xref ref-type="fig" rid="fig5">Figure 5A</xref>). By employing MIFT to revise the reconstructions and remove false connections between axons, reasonable reconstructions are achieved. In contrast, when the same fusion procedure is conducted without MIFT to revise the reconstruction, almost all axons are incorrectly connected together (bottom-right panel in <xref ref-type="fig" rid="fig5">Figure 5A</xref>).</p><fig id="fig5" position="float"><label>Figure 5.</label><caption><title>Minimal information flow tree effectively restrains the accumulation of reconstruction errors.</title><p>(<bold>A</bold>) Reconstruction comparisons in the fusion process with MIFT and without MIFT are shown. Both image blocks and neurite reconstructions are displayed using maximum projection along the z-direction. Two fusion procedures are performed, and the final fusion reconstructions are presented in the third column. (<bold>B</bold>) The variation in reconstruction accuracy during the fusion process with MIFT and without MIFT is illustrated. Blue points represent the initial reconstruction accuracy from six image blocks, while green points and red points denote the merged reconstruction accuracy with MIFT and without MIFT, respectively. The squares represent the mean values of the evaluation indexes. (<bold>C</bold>) The skeletons of three neurite branches from the final merged reconstructions with MIFT are shown. Additionally, corresponding ground-truth reconstructions and reconstruction evaluations are also presented.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-102840-fig5-v1.tif"/></fig><p>We furthermore measure the enhancement in the reconstruction accuracy achieved by MIFT (<xref ref-type="fig" rid="fig5">Figure 5B</xref>). For the initial reconstructions from six image blocks, the average of f1-score is about 0.86. By using MIFT, the average of f1-score is above 0.8 for the reconstructions from two image blocks which are generated with the first fusion. In the second fusion (top-right panel in <xref ref-type="fig" rid="fig5">Figure 5A</xref>), the f1-score still keeps 0.79. In contrast, without MIFT, the first fusion leads to a drop of about f1-score of 0.3. After the second fusion, the f1-score is less than 0.2. We also present some reconstruction examples after two fusions in <xref ref-type="fig" rid="fig5">Figure 5C</xref>, which are close to the ground truth. These results suggest that the MIFT model takes consideration of the proper structure of axons and thus can restrain the error communications in the reconstruction fusion process.</p></sec><sec id="s2-5"><title>Long-range axonal projections reconstruction</title><p>We applied PointTree for long-range axon reconstruction. The testing image block has the size of 11226×8791 × 1486 voxels and includes axons from eight neurons (<xref ref-type="fig" rid="fig6">Figure 6A</xref>). We also used GTree to manually reconstruct these neurons as the ground-truth reconstruction (<xref ref-type="fig" rid="fig6">Figure 6B</xref>). Except for the labeling of training data for segmentation network and of the axon starting points of a single neuron, the whole reconstruction process is totally automatic. The results show PointTree successfully recovered the axonal morphology of these eight neurons without manual interference (<xref ref-type="fig" rid="fig6">Figure 6C</xref> and <xref ref-type="video" rid="video1">Videos 1</xref> and <xref ref-type="video" rid="video2">2</xref>), and we compared these reconstructions with ground truth (<xref ref-type="fig" rid="fig6s1">Figure 6—figure supplement 1</xref>). The average precision is above 85% and the average recall and f1-score are above 80% (<xref ref-type="fig" rid="fig6">Figure 6E</xref>). In addition, we presented the axon reconstructions from two image blocks (<xref ref-type="fig" rid="fig6">Figure 6C1 and C2</xref>) which include a large number of densely distributed axons. This reconstruction performance suggests that the point assignment and the minimal information flow tree mode, as the two key strategies in PointTree, perform well in long-range axonal reconstruction.</p><fig-group><fig id="fig6" position="float"><label>Figure 6.</label><caption><title>Long-range axonal reconstruction using PointTree.</title><p>(<bold>A</bold>) The image block contains eight neurons in the ventral posteromedial thalamic region. The projection of these neurons includes a large number of densely distributed axons, which are enlarged in A<sub>1</sub> and A<sub>2</sub>. (<bold>B</bold>) The reconstruction of the eight neurons is achieved by annotators with semi-automatic software GTree, serving as ground-truth reconstruction to evaluate automatic algorithms. The reconstructions B<sub>1</sub> and B<sub>2</sub> correspond to the image blocks A<sub>1</sub> and A<sub>2</sub>. (<bold>C</bold>) Automatic reconstruction with PointTree results in reconstructions of the densely distributed axons, which are enlarged in C<sub>1</sub> and C<sub>2</sub>. (<bold>D</bold>) A comparison between automatic reconstruction and ground-truth reconstruction of axonal projection for one neuron is shown. Green indicates consistent reconstruction, blue indicates missed branches, and red denotes branches from other neurons. (<bold>E</bold>) Quantitative analysis of long-range projections for these neurons is presented. Statistical information is displayed in boxes (n=8), the horizontal line in the box, the lower and upper borders of the box represent the median value, the first quartile (Q1) and the third quartile (Q3) respectively, the vertical black lines indicate 1.5 × IQR, while black points represent the accuracy of the reconstructions for these neurons.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-102840-fig6-v1.tif"/></fig><fig id="fig6s1" position="float" specific-use="child-fig"><label>Figure 6—figure supplement 1.</label><caption><title>Reconstruction of long-range axonal projections.</title><p>The reconstructions were performed using semi-automatic methods with manual modification (GTree, left column) and automatic methods (PointTree, right column). The semi-automatic reconstruction is considered the ground-truth reconstruction for quantifying the accuracy of the automatic reconstruction. In the right column, each panel includes a set of quantitative evaluation indexes in the bottom-right corner, which consist of precision, recall, and f1-score.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-102840-fig6-figsupp1-v1.tif"/></fig><fig id="fig6s2" position="float" specific-use="child-fig"><label>Figure 6—figure supplement 2.</label><caption><title>Reconstruction from different datasets.</title><p>Axonal reconstructions were generated from the image blocks (10739×11226 × 3921) collected using the Limo system. The upper portion represents the ground-truth reconstruction, which includes data from 13 neurons. The automatic reconstruction (shown at the bottom) closely matches the ground-truth reconstruction. A quantitative evaluation of the automatic reconstruction is presented in <xref ref-type="table" rid="table1">Table 1</xref>.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-102840-fig6-figsupp2-v1.tif"/></fig></fig-group><media mimetype="video" mime-subtype="mp4" xlink:href="elife-102840-video1.mp4" id="video1"><label>Video 1.</label><caption><title>Reconstructed long-range axonal projections and raw image data shown in <xref ref-type="fig" rid="fig6">Figure 6</xref>, individual axonal projections are delineated in different colors.</title></caption></media><media mimetype="video" mime-subtype="mp4" xlink:href="elife-102840-video2.mp4" id="video2"><label>Video 2.</label><caption><title>Trace one of the reconstructed projections shown in <xref ref-type="fig" rid="fig6">Figure 6</xref>.</title></caption></media><p>We also applied PointTree to process another 10739×11226 × 3921 image blocks collected with HD-fMOST system (<xref ref-type="bibr" rid="bib53">Zhong et al., 2021</xref>). The high signal-to-noise ratio in this optical system results in a significantly extended dynamic range of the signal. PointTree can effectively deal with this case, and all 14 long-range projections are successfully reconstructed (<xref ref-type="fig" rid="fig6s2">Figure 6—figure supplement 2</xref>). The quantitative results suggest that the average f1-score is above 90% (<xref ref-type="table" rid="table1">Table 1</xref>).</p><table-wrap id="table1" position="float"><label>Table 1.</label><caption><title>Quantitative metrics comparing ground truth and reconstructed neurons are presented in <xref ref-type="fig" rid="fig6s2">Figure 6—figure supplement 2</xref>.</title></caption><table frame="hsides" rules="groups"><thead><tr><th align="left" valign="bottom">ID</th><th align="left" valign="bottom">Precision</th><th align="left" valign="bottom">Recall</th><th align="left" valign="bottom">F1-Score</th></tr></thead><tbody><tr><td align="left" valign="bottom">1</td><td align="left" valign="bottom">1.00</td><td align="left" valign="bottom">0.92</td><td align="left" valign="bottom">0.95</td></tr><tr><td align="left" valign="bottom">2</td><td align="left" valign="bottom">1.00</td><td align="left" valign="bottom">1.00</td><td align="left" valign="bottom">1.00</td></tr><tr><td align="left" valign="bottom">3</td><td align="left" valign="bottom">0.98</td><td align="left" valign="bottom">0.76</td><td align="left" valign="bottom">0.86</td></tr><tr><td align="left" valign="bottom">4</td><td align="left" valign="bottom">1.00</td><td align="left" valign="bottom">0.82</td><td align="left" valign="bottom">0.90</td></tr><tr><td align="left" valign="bottom">5</td><td align="left" valign="bottom">1.00</td><td align="left" valign="bottom">0.77</td><td align="left" valign="bottom">0.87</td></tr><tr><td align="left" valign="bottom">6</td><td align="left" valign="bottom">1.00</td><td align="left" valign="bottom">0.92</td><td align="left" valign="bottom">0.96</td></tr><tr><td align="left" valign="bottom">7</td><td align="left" valign="bottom">0.96</td><td align="left" valign="bottom">0.75</td><td align="left" valign="bottom">0.84</td></tr><tr><td align="left" valign="bottom">8</td><td align="left" valign="bottom">1.00</td><td align="left" valign="bottom">0.87</td><td align="left" valign="bottom">0.93</td></tr><tr><td align="left" valign="bottom">9</td><td align="left" valign="bottom">1.00</td><td align="left" valign="bottom">0.82</td><td align="left" valign="bottom">0.90</td></tr><tr><td align="left" valign="bottom">10</td><td align="left" valign="bottom">1.00</td><td align="left" valign="bottom">0.96</td><td align="left" valign="bottom">0.98</td></tr><tr><td align="left" valign="bottom">11</td><td align="left" valign="bottom">1.00</td><td align="left" valign="bottom">0.99</td><td align="left" valign="bottom">0.99</td></tr><tr><td align="left" valign="bottom">12</td><td align="left" valign="bottom">1.00</td><td align="left" valign="bottom">0.77</td><td align="left" valign="bottom">0.87</td></tr><tr><td align="left" valign="bottom">13</td><td align="left" valign="bottom">1.00</td><td align="left" valign="bottom">0.90</td><td align="left" valign="bottom">0.95</td></tr><tr><td align="left" valign="bottom">14</td><td align="left" valign="bottom">0.99</td><td align="left" valign="bottom">0.87</td><td align="left" valign="bottom">0.93</td></tr></tbody></table></table-wrap><p>Despite the need to solve multiple large-scale optimization problems, the reconstruction speed using PointTree is generally faster than the imaging speed. For instance, in a typical scenario involving 254 image blocks with 512×512 × 512 voxels, the total time required for reconstruction is approximately 44 min. Even for a larger dataset comprising 821 image blocks with 512×512 × 512 voxels and including a significant number of sparsely distributed neurites, the total time cost amounts to about 60 min (<xref ref-type="table" rid="table2">Table 2</xref>). It should be noted that the time cost does not increase linearly as data volume increases due to the influence of neurite density on overall reconstruction time. In summary, PointTree demonstrates remarkable speed in reconstructing long-range axons (<xref ref-type="video" rid="video3">Video 3</xref>).</p><table-wrap id="table2" position="float"><label>Table 2.</label><caption><title>Time cost of three modules in the entire reconstruction for two testing datasets shown in <xref ref-type="fig" rid="fig6">Figure 6</xref>, <xref ref-type="fig" rid="fig6s2">Figure 6—figure supplement 2</xref>.</title></caption><table frame="hsides" rules="groups"><thead><tr><th align="left" valign="bottom">block number(size: 512×512 × 512)</th><th align="left" valign="bottom">Points clustering(mins)</th><th align="left" valign="bottom">Clusters connection(mins)</th><th align="left" valign="bottom">Reconstruction merging (mins)</th></tr></thead><tbody><tr><td align="left" valign="bottom">254</td><td align="left" valign="bottom">23</td><td align="left" valign="bottom">18</td><td align="left" valign="bottom">3</td></tr><tr><td align="left" valign="bottom">821</td><td align="left" valign="bottom">22</td><td align="left" valign="bottom">35</td><td align="left" valign="bottom">3</td></tr></tbody></table></table-wrap><media mimetype="video" mime-subtype="mp4" xlink:href="elife-102840-video3.mp4" id="video3"><label>Video 3.</label><caption><title>Example run of PointTree on Windows.</title></caption></media></sec></sec><sec id="s3" sec-type="discussion"><title>Discussion</title><p>We have presented an automated method for reconstructing the long-range projections of neurons. In this study, we address the problem of mutual interference among densely distributed neurites and the cumulative error during reconstruction by designing a reconstruction method based on point set assignment and the minimal information flow tree, respectively. As a result, our approach enables accurate reconstruction of long-range neuron projections from hundreds of gigabytes of data. This advance significantly enhances the efficiency of whole-brain-scale neuron reconstruction, bridging the substantial gap between factory-level generation of whole-brain-scale neuronal imaging data and tens of hours required to reconstruct one neuron.</p><p>Our approach is performed on image foregrounds where the segmented neurites have a fixed radius approximately equal to the total size of the three voxels. In this case, we can estimate the total number of foreground points (voxels) and set a suitable number of columnar regions for ensuring the anisotropy of each columnar region, which is based on the fact that the union of columnar regions equals the foreground region. The anisotropy of the columnar regions will reduce the difficulty in establishing their connection. The requirement that all segmented neurites have a relatively fixed radius can be fulfilled. For all neurites, the value of their voxels decreases as these voxels deviate from the nearest centerline. The deep learning network is able to grasp this feature and segment only the neurite centerline and its neighborhood. Typically, in reconstructions of neurons whose projections are distributed over hundreds to thousands of GBs of data, less than GB-sized images with labels are needed as training data. The labeling process takes a few hours, which is negligible for semi-automatic reconstruction of all neurons in the whole volume images.</p><p>We propose a new reconstruction mode centered on point set assignment instead of the current reconstruction mode focused on skeleton extraction. In the current reconstruction paradigm, most deep networks are used to enhance the signal-to-noise ratio of neuronal images and do not address the issue of signal interference during skeleton extraction. In contrast, our reconstruction approach is based on directly processing the foreground points generated by the deep learning network. With continued advances in deep learning techniques, the generality and accuracy of image segmentation will be continuously enhanced, thereby significantly boosting the application scope of our method in various scenarios. Essentially, our method can be applied to any skeleton tracking-based application scenario and effectively eliminate dense signal interference.</p><p>Our method still generates a few reconstruction errors. This is due to the following three aspects. First, our method directly handles image foregrounds, which leads to reconstruction errors when some neurites with weak image intensities are not identified. Second, relying solely on foreground point information and rule-based judgment methods may generate some connection errors when establishing connections between neurites. Finally, the minimal information flow tree’s fundamental assumption, that axons should be as smooth as possible, does not always hold true. In fact, real axons can take quite sharp turns (<xref ref-type="fig" rid="fig1s3">Figure 1—figure supplement 3</xref>) leading the algorithm to erroneously separate a single continuous axon into disjoint fibers (<xref ref-type="fig" rid="fig1s3">Figure 1—figure supplement 3</xref>). Therefore, for the automatic reconstruction of neurons on a brain-wide scale, further work is needed to enhance the imaging intensity and incorporate soma shapes and raw image signals for neurites connection recognition.</p></sec><sec id="s4" sec-type="materials|methods"><title>Materials and methods</title><sec id="s4-1"><title>Data collections</title><p>All animal experiments followed procedures approved by the Institutional Animal Ethics Committee of the Huazhong University of Science and Technology. The test datasets are collected through the preparation of two kinds of samples. For one C57BL/6 male mouse, 100 nl AAV-Cre virus and 100 nl of AAV-EF1α-DIO-EYFP virus were injected into the VPM nucleus at the same time. 21 days later, the chemical sectioning fluorescence tomography (CSFT) system (<xref ref-type="bibr" rid="bib43">Wang et al., 2021</xref>) was used to acquire imaging data (<xref ref-type="fig" rid="fig1">Figures 1</xref>—<xref ref-type="fig" rid="fig6">6</xref>), more details can be seen in the reference (<xref ref-type="bibr" rid="bib52">Zhang et al., 2021</xref>). For one C57BL/6 J male mouse, 100 nl of AAV-YFP was injected into the motor area. 21 days later, high-definition fluorescent micro-optical sectioning tomography (HD-fMOST) was used to acquire imaging data (<xref ref-type="bibr" rid="bib53">Zhong et al., 2021</xref>; <xref ref-type="fig" rid="fig6s2">Figure 6—figure supplement 2</xref>).</p></sec><sec id="s4-2"><title>Generation of foreground points</title><p>Our reconstruction method performs on the image foregrounds. Here, we used UNet3D (<xref ref-type="bibr" rid="bib6">Çiçek et al., 2016</xref>) for image stacks segmentation without network structure modification. The detailed information about UNet3D can be found in the reference (<xref ref-type="bibr" rid="bib6">Çiçek et al., 2016</xref>). Considering the requirement that the network output, the segmented neurites, have the relatively fixed radius, we calculate the distance field of the neurite’s skeleton as the ground truth for supervising the network. Initially, the semi-automatic software GTree was utilized to extract the neurite skeleton and subsequently interpolate the skeleton points. The interpolation operation ensured that the distance between any skeleton point and its nearest point was less than 1 μm. Subsequently, the interpolated skeleton points were used as centers to mark spherical regions with a radius of 5 voxels. These spherical regions served as candidate areas for foreground. Within these candidate areas, the distance from each point to its nearest interpolated skeleton point was calculated. Finally, the distances are mapped into Gaussian kernel distances, which form the Gaussian density map. This map normalized by maximum value leads to the distance field map to supervise UNet3D output.</p><p>In the training stage, Adam optimizer is used with an initial learning rate at 3e-4. The input image size is 128×128 × 128. Batch size is set to 1, the L1-norm is used as loss function to train the network. We presented the reconstructions from two kinds of fMOST datasets. One is from the reference (<xref ref-type="bibr" rid="bib52">Zhang et al., 2021</xref>) and the other is from the reference (<xref ref-type="bibr" rid="bib53">Zhong et al., 2021</xref>). Therefore, we created two sets of training data, each consisting of 20 512×512 × 512 image blocks (each divided into 64 image blocks of size 128×128 × 128). In each set, 10 image blocks contain densely distributed neurites, while the other 10 blocks contain sparsely distributed neurites. In the predicting stage, we applied the threshold operation to the distance field image. The voxels whose values are more than 0.5 are regarded as the foreground points.</p></sec><sec id="s4-3"><title>Neuron Reconstruction based on Points assignment</title><p>For the image stack, we allocated the foreground points to their respective neurites and established connections between neurites by constructing three optimization models: (1) the constrained Gaussian mixture model divides the foreground points into a set of points, each of which has a column shape; (2) the minimum-volume covering ellipsoids model extracts the features of the column-shaped point set; (3) the 0–1 assignment optimization model establishes connections between the column-shaped point sets, resulting in the shapes of individual neurites, and then builds connections between the reconstructed neurites.</p></sec><sec id="s4-4"><title>Constrained Gaussian mixture model</title><p>The three-dimensional Gaussian function exhibits an ellipsoidal shape in space, which we have utilized to approximate the columnar shape of local neurites. In this study, Gaussian distribution mixture functions with <inline-formula><alternatives><mml:math id="inf1"><mml:mi>K</mml:mi></mml:math><tex-math id="inft1">\begin{document}$K$\end{document}</tex-math></alternatives></inline-formula> components are employed to approximate the shape of all neurites in an image block. The component number <inline-formula><alternatives><mml:math id="inf2"><mml:mi>K</mml:mi></mml:math><tex-math id="inft2">\begin{document}$K$\end{document}</tex-math></alternatives></inline-formula> is obtained by point density and will be discussed later. Given the foreground points <inline-formula><alternatives><mml:math id="inf3"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>x</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mn>2</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:mo>⋯</mml:mo><mml:mo>,</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mi>n</mml:mi></mml:msub></mml:mrow></mml:mstyle></mml:math><tex-math id="inft3">\begin{document}$x_1,x_2,\cdots ,x_n$\end{document}</tex-math></alternatives></inline-formula>, for each foreground points <inline-formula><alternatives><mml:math id="inf4"><mml:mrow><mml:msub><mml:mi>x</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:math><tex-math id="inft4">\begin{document}$x_{i}$\end{document}</tex-math></alternatives></inline-formula>, the probability density function <inline-formula><alternatives><mml:math id="inf5"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>P</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mstyle></mml:math><tex-math id="inft5">\begin{document}$P\left (x_{i}\right)$\end{document}</tex-math></alternatives></inline-formula> is calculated as follows:<disp-formula id="equ1"><label>(1)</label><alternatives><mml:math id="m1"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>P</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:munderover><mml:mo>∑</mml:mo><mml:mrow><mml:mi>j</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>K</mml:mi></mml:mrow></mml:munderover><mml:msub><mml:mi>π</mml:mi><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mi>N</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>x</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:msub><mml:mi>μ</mml:mi><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi mathvariant="normal">Σ</mml:mi><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mstyle></mml:mrow></mml:mstyle></mml:math><tex-math id="t1">\begin{document}$$\displaystyle  P\left (x_{i}\right)=\sum _{j=1}^{K}\pi _{j}N\left (x_{i}|\mu _{j},\Sigma _{j}\right)$$\end{document}</tex-math></alternatives></disp-formula></p><p>Here, <inline-formula><alternatives><mml:math id="inf6"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>N</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>x</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:msub><mml:mi>μ</mml:mi><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi mathvariant="normal">Σ</mml:mi><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mstyle></mml:math><tex-math id="inft6">\begin{document}$N\left (x_{i}|\mu _{j},\Sigma _{j}\right)$\end{document}</tex-math></alternatives></inline-formula> is the Gaussian density function with mean value <inline-formula><alternatives><mml:math id="inf7"><mml:mrow><mml:msub><mml:mi>μ</mml:mi><mml:mi>j</mml:mi></mml:msub></mml:mrow></mml:math><tex-math id="inft7">\begin{document}$\mu _{j}$\end{document}</tex-math></alternatives></inline-formula> and covariance matrix <inline-formula><alternatives><mml:math id="inf8"><mml:mrow><mml:msub><mml:mi>Σ</mml:mi><mml:mi>j</mml:mi></mml:msub></mml:mrow></mml:math><tex-math id="inft8">\begin{document}$\Sigma _{j}$\end{document}</tex-math></alternatives></inline-formula>. Weight <inline-formula><alternatives><mml:math id="inf9"><mml:mrow><mml:msub><mml:mi>π</mml:mi><mml:mi>j</mml:mi></mml:msub></mml:mrow></mml:math><tex-math id="inft9">\begin{document}$\pi _{j}$\end{document}</tex-math></alternatives></inline-formula> is the regularization parameter. <inline-formula><alternatives><mml:math id="inf10"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>N</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>x</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:msub><mml:mi>μ</mml:mi><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi mathvariant="normal">Σ</mml:mi><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mstyle></mml:math><tex-math id="inft10">\begin{document}$N\left (x_{i}|\mu _{j},\Sigma _{j}\right)$\end{document}</tex-math></alternatives></inline-formula> is given by the formula:<disp-formula id="equ2"><label>(2)</label><alternatives><mml:math id="m2"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>N</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>x</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:msub><mml:mi>μ</mml:mi><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi mathvariant="normal">Σ</mml:mi><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mrow><mml:mn>2</mml:mn><mml:msup><mml:mi>π</mml:mi><mml:mrow><mml:mn>3</mml:mn><mml:mrow><mml:mo>/</mml:mo></mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:msub><mml:mi mathvariant="normal">Σ</mml:mi><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:msup><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mrow><mml:mn>1</mml:mn><mml:mrow><mml:mo>/</mml:mo></mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:mfrac><mml:msup><mml:mi>e</mml:mi><mml:mrow><mml:mo>−</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mn>2</mml:mn></mml:mfrac><mml:msup><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>x</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>−</mml:mo><mml:msub><mml:mi>μ</mml:mi><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mrow><mml:mi>T</mml:mi></mml:mrow></mml:msup><mml:msubsup><mml:mi mathvariant="normal">Σ</mml:mi><mml:mrow><mml:mi>j</mml:mi></mml:mrow><mml:mrow><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msubsup><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>x</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>−</mml:mo><mml:msub><mml:mi>μ</mml:mi><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:msup></mml:mstyle></mml:mrow></mml:mstyle></mml:math><tex-math id="t2">\begin{document}$$\displaystyle  N\left (x_{i}|\mu _{j},\Sigma _{j}\right)=\frac{1}{2\pi ^{3/2}|\Sigma _{j}|^{1/2}}e^{- \frac{1}{2}\left (x_{i}- \mu _{j}\right)^{T}\Sigma _{j}^{- 1}\left (x_{i}- \mu _{j}\right)}$$\end{document}</tex-math></alternatives></disp-formula></p><p>Based on probability density function, the conditional probability can be computed as:<disp-formula id="equ3"><label>(3)</label><alternatives><mml:math id="m3"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msub><mml:mi>p</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mi>P</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>x</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mi>c</mml:mi><mml:mi>l</mml:mi><mml:mi>u</mml:mi><mml:mi>s</mml:mi><mml:mi>t</mml:mi><mml:mi>e</mml:mi><mml:msub><mml:mi>r</mml:mi><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:msub><mml:mi>π</mml:mi><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mi>N</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>x</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:msub><mml:mi>μ</mml:mi><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi mathvariant="normal">Σ</mml:mi><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mrow><mml:munderover><mml:mo>∑</mml:mo><mml:mrow><mml:mi>j</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>K</mml:mi></mml:mrow></mml:munderover><mml:msub><mml:mi>π</mml:mi><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mi>N</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>x</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:msub><mml:mi>μ</mml:mi><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi mathvariant="normal">Σ</mml:mi><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mfrac><mml:mspace width="2em"/><mml:mi>j</mml:mi><mml:mo>=</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mn>2</mml:mn><mml:mo>,</mml:mo><mml:mo>.</mml:mo><mml:mo>.</mml:mo><mml:mo>.</mml:mo><mml:mo>,</mml:mo><mml:mi>K</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mstyle></mml:mrow></mml:mstyle></mml:math><tex-math id="t3">\begin{document}$$\displaystyle  p_{i,j}=P\left (x_{i}|cluster_{j}\right)=\frac{\pi _{j}N\left (x_{i}|\mu _{j},\Sigma _{j}\right)}{\sum _{j=1}^{K}\pi _{j}N\left (x_{i}|\mu _{j},\Sigma _{j}\right)} \qquad j=\left (1,2,...,K\right)$$\end{document}</tex-math></alternatives></disp-formula></p><p>Here, <inline-formula><alternatives><mml:math id="inf11"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>p</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math><tex-math id="inft11">\begin{document}$p_{i,j}$\end{document}</tex-math></alternatives></inline-formula> is the conditional probability for <inline-formula><alternatives><mml:math id="inf12"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>x</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math><tex-math id="inft12">\begin{document}$x_{i}$\end{document}</tex-math></alternatives></inline-formula> to assign to the <italic>j</italic>-th cluster. If <inline-formula><alternatives><mml:math id="inf13"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>p</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>k</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math><tex-math id="inft13">\begin{document}$p_{i,k}$\end{document}</tex-math></alternatives></inline-formula> is the maximum value among <inline-formula><alternatives><mml:math id="inf14"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mrow><mml:mo>{</mml:mo><mml:mrow><mml:msub><mml:mi>p</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:mo>.</mml:mo><mml:mo>.</mml:mo><mml:mo>.</mml:mo><mml:msub><mml:mi>p</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>K</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>}</mml:mo></mml:mrow></mml:mrow></mml:mstyle></mml:math><tex-math id="inft14">\begin{document}$\left \{p_{i,1},...p_{i,K}\right \}$\end{document}</tex-math></alternatives></inline-formula>, the foreground point <inline-formula><alternatives><mml:math id="inf15"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>x</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math><tex-math id="inft15">\begin{document}$x_{i}$\end{document}</tex-math></alternatives></inline-formula> will be assigned to the <italic>k</italic>-th cluster. All the points assigned to the <italic>k</italic>-th cluster form a columnar region. Considering that both the number of foreground points and component number are large, we have added some constrained conditions for Gaussian mixture model as follows:<disp-formula id="equ4"><label>(4)</label><alternatives><mml:math id="m4"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mstyle displaystyle="true" scriptlevel="0"><mml:munderover><mml:mo>∑</mml:mo><mml:mrow><mml:mi>j</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>K</mml:mi></mml:mrow></mml:munderover><mml:msub><mml:mi>π</mml:mi><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mstyle></mml:mrow></mml:mstyle></mml:math><tex-math id="t4">\begin{document}$$\displaystyle  \sum _{j=1}^{K}\pi _{j}=1$$\end{document}</tex-math></alternatives></disp-formula><disp-formula id="equ5"><label>(5)</label><alternatives><mml:math id="m5"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>I</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:msub><mml:mi>μ</mml:mi><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>)</mml:mo></mml:mrow><mml:mo>≥</mml:mo><mml:msub><mml:mi>ε</mml:mi><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:msub><mml:mi mathvariant="normal">Σ</mml:mi><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mo>≤</mml:mo><mml:msub><mml:mi>ε</mml:mi><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mstyle></mml:mrow></mml:mstyle></mml:math><tex-math id="t5">\begin{document}$$\displaystyle  I\left (\mu _{j}\right)\geq \varepsilon _{0},|\Sigma _{j}|\leq \varepsilon _{1}$$\end{document}</tex-math></alternatives></disp-formula></p><p><inline-formula><alternatives><mml:math id="inf16"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:munderover><mml:mo>∑</mml:mo><mml:mrow><mml:mi>j</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>K</mml:mi></mml:mrow></mml:munderover><mml:msub><mml:mi>π</mml:mi><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:mstyle></mml:math><tex-math id="inft16">\begin{document}$\sum _{j=1}^{K}\pi _{j}=1$\end{document}</tex-math></alternatives></inline-formula> refers to the fact that the total probability distribution normalizes to 1. <inline-formula><alternatives><mml:math id="inf17"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>I</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mo>⋅</mml:mo><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mstyle></mml:math><tex-math id="inft17">\begin{document}$I\left (\cdot \right)$\end{document}</tex-math></alternatives></inline-formula> represents the signal intensity from segment image, <inline-formula><alternatives><mml:math id="inf18"><mml:mrow><mml:msub><mml:mi>ε</mml:mi><mml:mn>0</mml:mn></mml:msub></mml:mrow></mml:math><tex-math id="inft18">\begin{document}$\varepsilon _{0}$\end{document}</tex-math></alternatives></inline-formula> is the minimum signal intensity of foreground points and is set to 128 in the algorithm. <inline-formula><alternatives><mml:math id="inf19"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>I</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:msub><mml:mi>μ</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>)</mml:mo></mml:mrow><mml:mo>≥</mml:mo><mml:msub><mml:mi>ε</mml:mi><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math><tex-math id="inft19">\begin{document}$I\left (\mu _{i}\right)\geq \varepsilon _{0}$\end{document}</tex-math></alternatives></inline-formula> restrain the center of the Gaussian distribution to be a foreground point. <inline-formula><alternatives><mml:math id="inf20"><mml:mrow><mml:mo>|</mml:mo><mml:msub><mml:mi>Σ</mml:mi><mml:mi>j</mml:mi></mml:msub><mml:mo>|</mml:mo><mml:mo>≤</mml:mo><mml:msub><mml:mi>ε</mml:mi><mml:mn>1</mml:mn></mml:msub></mml:mrow></mml:math><tex-math id="inft20">\begin{document}$|\Sigma _{j}|\leq \varepsilon _{1}$\end{document}</tex-math></alternatives></inline-formula> restrain the determinant of the covariance matrix which controls the suitable number of foreground points for each columnar region. <inline-formula><alternatives><mml:math id="inf21"><mml:mrow><mml:msub><mml:mi>ε</mml:mi><mml:mn>1</mml:mn></mml:msub></mml:mrow></mml:math><tex-math id="inft21">\begin{document}$\varepsilon _{1}$\end{document}</tex-math></alternatives></inline-formula> is set to the cube of three times the average diameter of neurite.</p><p>Maximum likelihood is employed to estimate the parameters of Gaussian mixture model and the final optimization problem is formed as follows:<disp-formula id="equ6"><label>(6)</label><alternatives><mml:math id="m6"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msubsup><mml:mi>π</mml:mi><mml:mrow><mml:mi>j</mml:mi></mml:mrow><mml:mrow><mml:mo>∗</mml:mo></mml:mrow></mml:msubsup><mml:mo>,</mml:mo><mml:msubsup><mml:mi>μ</mml:mi><mml:mrow><mml:mi>j</mml:mi></mml:mrow><mml:mrow><mml:mo>∗</mml:mo></mml:mrow></mml:msubsup><mml:mo>,</mml:mo><mml:msubsup><mml:mi mathvariant="normal">Σ</mml:mi><mml:mrow><mml:mi>j</mml:mi></mml:mrow><mml:mrow><mml:mo>∗</mml:mo></mml:mrow></mml:msubsup></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mrow><mml:mi>j</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mn>2</mml:mn><mml:mo>,</mml:mo><mml:mo>⋯</mml:mo><mml:mo>,</mml:mo><mml:mi>K</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mi>arg</mml:mi><mml:mo>⁡</mml:mo><mml:mo movablelimits="true" form="prefix">max</mml:mo><mml:munderover><mml:mo movablelimits="false">∏</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>n</mml:mi></mml:mrow></mml:munderover><mml:mi>P</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mi>arg</mml:mi><mml:mo>⁡</mml:mo><mml:mo movablelimits="true" form="prefix">max</mml:mo><mml:munderover><mml:mo movablelimits="false">∏</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>n</mml:mi></mml:mrow></mml:munderover><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:munderover><mml:mo>∑</mml:mo><mml:mrow><mml:mi>j</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>K</mml:mi></mml:mrow></mml:munderover><mml:msub><mml:mi>π</mml:mi><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mi>N</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>x</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:msub><mml:mi>μ</mml:mi><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi mathvariant="normal">Σ</mml:mi><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mstyle></mml:mrow></mml:mstyle></mml:math><tex-math id="t6">\begin{document}$$\displaystyle  \left (\pi _{j}^{*},\mu _{j}^{*},\Sigma _{j}^{*}\right)_{j=1,2,\cdots ,K}=\arg \max\prod \limits_{i=1}^{n}P\left (x_i\right)=\arg \max \prod \limits_{i=1}^{n}\left (\sum _{j=1}^{K}\pi _{j}N\left (x_i | \mu _{j},\Sigma _{j}\right)\right)$$\end{document}</tex-math></alternatives></disp-formula><disp-formula id="equ7"><label>(7)</label><alternatives><mml:math id="m7"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>s</mml:mi><mml:mo>.</mml:mo><mml:mi>t</mml:mi><mml:mo>.</mml:mo><mml:munderover><mml:mo>∑</mml:mo><mml:mrow><mml:mi>j</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>K</mml:mi></mml:mrow></mml:munderover><mml:msub><mml:mi>π</mml:mi><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mi>I</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:msub><mml:mi>μ</mml:mi><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>)</mml:mo></mml:mrow><mml:mo>≥</mml:mo><mml:msub><mml:mi>ε</mml:mi><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:msub><mml:mi mathvariant="normal">Σ</mml:mi><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mo>≤</mml:mo><mml:msub><mml:mi>ε</mml:mi><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mstyle></mml:mrow></mml:mstyle></mml:math><tex-math id="t7">\begin{document}$$\displaystyle  s.t.\sum _{j=1}^{K}\pi _{j}=1,I\left (\mu _{j}\right)\geq \varepsilon _{0},|\Sigma _{j}|\leq \varepsilon _{1}$$\end{document}</tex-math></alternatives></disp-formula></p><p>In solving this optimization problem, we employ peak density algorithm (<xref ref-type="bibr" rid="bib44">Wei et al., 2023</xref>) to compute density for each foreground points and sort them in descending order. We first select a point as a seed point, and the foreground points within a radius of 5 centered on it will be excluded. Then we continue selecting seed points until all foreground points are either selected or excluded. The selected <inline-formula><alternatives><mml:math id="inf22"><mml:mi>K</mml:mi></mml:math><tex-math id="inft22">\begin{document}$K$\end{document}</tex-math></alternatives></inline-formula> seed points represent the initial <inline-formula><alternatives><mml:math id="inf23"><mml:mi>K</mml:mi></mml:math><tex-math id="inft23">\begin{document}$K$\end{document}</tex-math></alternatives></inline-formula> components. We select signal points from the median (based on density) to both sides as seed points, which can decrease the situations that seed points lie in the center of a crossover or the edge of neurites. This strategy can make the generated columnar regions be more reasonable. The positions of the <inline-formula><alternatives><mml:math id="inf24"><mml:mi>K</mml:mi></mml:math><tex-math id="inft24">\begin{document}$K$\end{document}</tex-math></alternatives></inline-formula> seed points are set to the initial <inline-formula><alternatives><mml:math id="inf25"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>μ</mml:mi><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>μ</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:mo>⋯</mml:mo><mml:mo>,</mml:mo><mml:msub><mml:mi>μ</mml:mi><mml:mi>K</mml:mi></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mstyle></mml:math><tex-math id="inft25">\begin{document}$\left (\mu _{1},\mu _{2},\cdots ,\mu _K\right)$\end{document}</tex-math></alternatives></inline-formula>. The initial setting of the covariance matrix is the identity matrix. The constrained Gaussian mixture model was solved by the EM algorithm (<xref ref-type="bibr" rid="bib25">McLachlan and Krishnan, 2007</xref>), the EM algorithm is divided into two steps:</p><p>E-step: For each point <inline-formula><alternatives><mml:math id="inf26"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>x</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:mstyle></mml:math><tex-math id="inft26">\begin{document}$x_i$\end{document}</tex-math></alternatives></inline-formula>, compute its probability within each Gaussian distribution using the probability density function:<disp-formula id="equ8"><label>(8)</label><alternatives><mml:math id="m8"><mml:mrow><mml:msub><mml:mi>p</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:msub><mml:mi>π</mml:mi><mml:mi>j</mml:mi></mml:msub><mml:mi>N</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>|</mml:mo><mml:msub><mml:mi>μ</mml:mi><mml:mi>j</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>Σ</mml:mi><mml:mi>j</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mrow><mml:mstyle displaystyle="true"><mml:msubsup><mml:mo>∑</mml:mo><mml:mrow><mml:mi>j</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>K</mml:mi></mml:msubsup><mml:mrow><mml:msub><mml:mi>π</mml:mi><mml:mi>j</mml:mi></mml:msub><mml:mi>N</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>|</mml:mo><mml:msub><mml:mi>μ</mml:mi><mml:mi>j</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>Σ</mml:mi><mml:mi>j</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mstyle></mml:mrow></mml:mfrac></mml:mrow></mml:math><tex-math id="t8">\begin{document}$$\displaystyle  p_{i,j}=\frac{\pi _{j}N\left (x_{i}|\mu _{j},\Sigma _{j}\right)}{\sum _{j=1}^{K}\pi _{j}N\left (x_{i}|\mu _{j},\Sigma _{j}\right)}$$\end{document}</tex-math></alternatives></disp-formula></p><p>M-step: Update the mean value, covariance matrices, and weight vectors.<disp-formula id="equ9"><label>(9)</label><alternatives><mml:math id="m9"><mml:mrow><mml:msub><mml:mi>π</mml:mi><mml:mi>j</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mstyle displaystyle="true"><mml:msubsup><mml:mo>∑</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>n</mml:mi></mml:msubsup><mml:mrow><mml:msub><mml:mi>p</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:mrow><mml:mi>n</mml:mi></mml:mfrac></mml:mrow></mml:math><tex-math id="t9">\begin{document}$$\displaystyle  \pi _{j}=\frac{\sum _{i=1}^{n}p_{i,j}}{n}$$\end{document}</tex-math></alternatives></disp-formula><disp-formula id="equ10"><label>(10)</label><alternatives><mml:math id="m10"><mml:mrow><mml:msub><mml:mi>μ</mml:mi><mml:mi>j</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mstyle displaystyle="true"><mml:msubsup><mml:mo>∑</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>n</mml:mi></mml:msubsup><mml:mrow><mml:msub><mml:mi>p</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:msub><mml:mi>x</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:mstyle></mml:mrow><mml:mrow><mml:mstyle displaystyle="true"><mml:msubsup><mml:mo>∑</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>n</mml:mi></mml:msubsup><mml:mrow><mml:msub><mml:mi>p</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:mrow></mml:mfrac></mml:mrow></mml:math><tex-math id="t10">\begin{document}$$\displaystyle  \mu _{j}=\frac{\sum _{i=1}^{n}p_{i,j}x_{i}}{\sum _{i=1}^{n}p_{i,j}}$$\end{document}</tex-math></alternatives></disp-formula><disp-formula id="equ11"><label>(11)</label><alternatives><mml:math id="m11"><mml:mrow><mml:msub><mml:mi>Σ</mml:mi><mml:mi>j</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:msup><mml:mrow><mml:mstyle displaystyle="true"><mml:msubsup><mml:mo>∑</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>n</mml:mi></mml:msubsup><mml:mrow><mml:msub><mml:mi>p</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>−</mml:mo><mml:msub><mml:mi>μ</mml:mi><mml:mi>j</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>−</mml:mo><mml:msub><mml:mi>μ</mml:mi><mml:mi>j</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mstyle></mml:mrow><mml:mi>T</mml:mi></mml:msup></mml:mrow><mml:mrow><mml:mstyle displaystyle="true"><mml:msubsup><mml:mo>∑</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>n</mml:mi></mml:msubsup><mml:mrow><mml:msub><mml:mi>p</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:mrow></mml:mfrac></mml:mrow></mml:math><tex-math id="t11">\begin{document}$$\displaystyle  \Sigma _{j}=\frac{\sum _{i=1}^{n}p_{i,j}\left (x_{i}- \mu _{j}\right)\left (x_{i}- \mu _{j}\right)^{T}}{\sum _{i=1}^{n}p_{i,j}}$$\end{document}</tex-math></alternatives></disp-formula></p><p>Besides, the constrained Gaussian mixture model possesses additional constraints: <inline-formula><alternatives><mml:math id="inf27"><mml:mrow><mml:mi>I</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>μ</mml:mi><mml:mi>j</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:mo>≥</mml:mo><mml:msub><mml:mi>ε</mml:mi><mml:mn>0</mml:mn></mml:msub></mml:mrow></mml:math><tex-math id="inft27">\begin{document}$I\left (\mu _{j}\right)\geq \varepsilon _{0}$\end{document}</tex-math></alternatives></inline-formula> and <inline-formula><alternatives><mml:math id="inf28"><mml:mrow><mml:mo>|</mml:mo><mml:msub><mml:mi>Σ</mml:mi><mml:mi>j</mml:mi></mml:msub><mml:mo>|</mml:mo><mml:mo>≤</mml:mo><mml:msub><mml:mi>ε</mml:mi><mml:mn>1</mml:mn></mml:msub></mml:mrow></mml:math><tex-math id="inft28">\begin{document}$|\Sigma _{j}|\leq \varepsilon _{1}$\end{document}</tex-math></alternatives></inline-formula>. After finishing the M-step, <inline-formula><alternatives><mml:math id="inf29"><mml:mrow><mml:msub><mml:mi>μ</mml:mi><mml:mi>j</mml:mi></mml:msub></mml:mrow></mml:math><tex-math id="inft29">\begin{document}$\mu _{j}$\end{document}</tex-math></alternatives></inline-formula> with <inline-formula><alternatives><mml:math id="inf30"><mml:mrow><mml:mi>I</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>μ</mml:mi><mml:mi>j</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:mo>&lt;</mml:mo><mml:msub><mml:mi>ε</mml:mi><mml:mn>0</mml:mn></mml:msub></mml:mrow></mml:math><tex-math id="inft30">\begin{document}$I\left (\mu _{j}\right) \lt \varepsilon _{0}$\end{document}</tex-math></alternatives></inline-formula> are selected. Eigenvalue decomposition is applied on <inline-formula><alternatives><mml:math id="inf31"><mml:mrow><mml:msub><mml:mi>Σ</mml:mi><mml:mi>j</mml:mi></mml:msub></mml:mrow></mml:math><tex-math id="inft31">\begin{document}$\Sigma _{j}$\end{document}</tex-math></alternatives></inline-formula> and obtains eigenvalues <inline-formula><alternatives><mml:math id="inf32"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>γ</mml:mi><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>γ</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>γ</mml:mi><mml:mrow><mml:mn>3</mml:mn></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mstyle></mml:math><tex-math id="inft32">\begin{document}$\left (\gamma _{1},\gamma _{2},\gamma _{3}\right)$\end{document}</tex-math></alternatives></inline-formula> in descending order and eigenvectors <inline-formula><alternatives><mml:math id="inf33"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>v</mml:mi><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>v</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>v</mml:mi><mml:mrow><mml:mn>3</mml:mn></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mstyle></mml:math><tex-math id="inft33">\begin{document}$\left (v_{1},v_{2},v_{3}\right)$\end{document}</tex-math></alternatives></inline-formula>. <inline-formula><alternatives><mml:math id="inf34"><mml:mrow><mml:msub><mml:mi>μ</mml:mi><mml:mi>j</mml:mi></mml:msub></mml:mrow></mml:math><tex-math id="inft34">\begin{document}$\mu _{j}$\end{document}</tex-math></alternatives></inline-formula> is updated along <inline-formula><alternatives><mml:math id="inf35"><mml:mrow><mml:msub><mml:mi>v</mml:mi><mml:mn>1</mml:mn></mml:msub></mml:mrow></mml:math><tex-math id="inft35">\begin{document}$v_{1}$\end{document}</tex-math></alternatives></inline-formula> and <inline-formula><alternatives><mml:math id="inf36"><mml:mrow><mml:mo>−</mml:mo><mml:msub><mml:mi>v</mml:mi><mml:mn>1</mml:mn></mml:msub></mml:mrow></mml:math><tex-math id="inft36">\begin{document}$- v_{1}$\end{document}</tex-math></alternatives></inline-formula> to generate two new clusters with mean value and covariance matrices <inline-formula><alternatives><mml:math id="inf37"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>u</mml:mi><mml:mrow><mml:mi>j</mml:mi><mml:mo>,</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi mathvariant="normal">Σ</mml:mi><mml:mrow><mml:mi>j</mml:mi><mml:mo>,</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mstyle></mml:math><tex-math id="inft37">\begin{document}$\left (u_{j,1},\Sigma _{j,1}\right)$\end{document}</tex-math></alternatives></inline-formula> and <inline-formula><alternatives><mml:math id="inf38"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>u</mml:mi><mml:mrow><mml:mi>j</mml:mi><mml:mo>,</mml:mo><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi mathvariant="normal">Σ</mml:mi><mml:mrow><mml:mi>j</mml:mi><mml:mo>,</mml:mo><mml:mn>2</mml:mn></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mstyle></mml:math><tex-math id="inft38">\begin{document}$\left (u_{j,2},\Sigma _{j,2}\right)$\end{document}</tex-math></alternatives></inline-formula> as follows:<disp-formula id="equ12"><label>(12)</label><alternatives><mml:math id="m12"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msub><mml:mi>u</mml:mi><mml:mrow><mml:mi>j</mml:mi><mml:mo>,</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:msub><mml:mi>u</mml:mi><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mi>v</mml:mi><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>⋅</mml:mo><mml:mfrac><mml:mi>γ</mml:mi><mml:mn>2</mml:mn></mml:mfrac></mml:mstyle></mml:mrow></mml:mstyle></mml:math><tex-math id="t12">\begin{document}$$\displaystyle  u_{j,1}=u_{j}+v_{1}\cdot \frac{\gamma }{2}$$\end{document}</tex-math></alternatives></disp-formula><disp-formula id="equ13"><label>(13)</label><alternatives><mml:math id="m13"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msub><mml:mi>u</mml:mi><mml:mrow><mml:mi>j</mml:mi><mml:mo>,</mml:mo><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:msub><mml:mi>u</mml:mi><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>−</mml:mo><mml:msub><mml:mi>v</mml:mi><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>⋅</mml:mo><mml:mfrac><mml:mi>γ</mml:mi><mml:mn>2</mml:mn></mml:mfrac></mml:mstyle></mml:mrow></mml:mstyle></mml:math><tex-math id="t13">\begin{document}$$\displaystyle  u_{j,2}=u_{j}- v_{1}\cdot \frac{\gamma }{2}$$\end{document}</tex-math></alternatives></disp-formula><disp-formula id="equ14"><label>(14)</label><alternatives><mml:math id="m14"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msub><mml:mi mathvariant="normal">Σ</mml:mi><mml:mrow><mml:mi>j</mml:mi><mml:mo>,</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:munderover><mml:mo>∑</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>n</mml:mi></mml:mrow></mml:munderover><mml:msub><mml:mi>p</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>x</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>−</mml:mo><mml:msub><mml:mi>μ</mml:mi><mml:mrow><mml:mi>j</mml:mi><mml:mo>,</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:msup><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>x</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>−</mml:mo><mml:msub><mml:mi>μ</mml:mi><mml:mrow><mml:mi>j</mml:mi><mml:mo>,</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mrow><mml:mi>T</mml:mi></mml:mrow></mml:msup></mml:mrow><mml:mrow><mml:munderover><mml:mo>∑</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>n</mml:mi></mml:mrow></mml:munderover><mml:msub><mml:mi>p</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfrac></mml:mstyle></mml:mrow></mml:mstyle></mml:math><tex-math id="t14">\begin{document}$$\displaystyle  \Sigma _{j,1}=\frac{\sum _{i=1}^{n}p_{i,j}\left (x_{i}- \mu _{j,1}\right)\left (x_{i}- \mu _{j,1}\right)^{T}}{\sum _{i=1}^{n}p_{i,j}}$$\end{document}</tex-math></alternatives></disp-formula><disp-formula id="equ15"><label>(15)</label><alternatives><mml:math id="m15"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msub><mml:mi mathvariant="normal">Σ</mml:mi><mml:mrow><mml:mi>j</mml:mi><mml:mo>,</mml:mo><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:munderover><mml:mo>∑</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>n</mml:mi></mml:mrow></mml:munderover><mml:msub><mml:mi>p</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>x</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>−</mml:mo><mml:msub><mml:mi>μ</mml:mi><mml:mrow><mml:mi>j</mml:mi><mml:mo>,</mml:mo><mml:mn>2</mml:mn></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:msup><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>x</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>−</mml:mo><mml:msub><mml:mi>μ</mml:mi><mml:mrow><mml:mi>j</mml:mi><mml:mo>,</mml:mo><mml:mn>2</mml:mn></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mrow><mml:mi>T</mml:mi></mml:mrow></mml:msup></mml:mrow><mml:mrow><mml:munderover><mml:mo>∑</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>n</mml:mi></mml:mrow></mml:munderover><mml:msub><mml:mi>p</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfrac></mml:mstyle></mml:mrow></mml:mstyle></mml:math><tex-math id="t15">\begin{document}$$\displaystyle  \Sigma _{j,2}=\frac{\sum _{i=1}^{n}p_{i,j}\left (x_{i}- \mu _{j,2}\right)\left (x_{i}- \mu _{j,2}\right)^{T}}{\sum _{i=1}^{n}p_{i,j}}$$\end{document}</tex-math></alternatives></disp-formula></p><p>For <inline-formula><alternatives><mml:math id="inf39"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi mathvariant="normal">Σ</mml:mi><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>&gt;</mml:mo><mml:msub><mml:mi>ε</mml:mi><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math><tex-math id="inft39">\begin{document}$\Sigma _{j} \gt \varepsilon _{1}$\end{document}</tex-math></alternatives></inline-formula>, it will be updated as follows:<disp-formula id="equ16"><label>(16)</label><alternatives><mml:math id="m16"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msubsup><mml:mi mathvariant="normal">Σ</mml:mi><mml:mrow><mml:mi>j</mml:mi></mml:mrow><mml:mrow><mml:mo>′</mml:mo></mml:mrow></mml:msubsup><mml:mo>=</mml:mo><mml:mfrac><mml:msub><mml:mi>ε</mml:mi><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:msub><mml:mi mathvariant="normal">Σ</mml:mi><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:mfrac><mml:msub><mml:mi mathvariant="normal">Σ</mml:mi><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:mstyle></mml:mrow></mml:mstyle></mml:math><tex-math id="t16">\begin{document}$$\displaystyle  \Sigma _{j}^{'}=\frac{\varepsilon _{1}}{\Sigma _{j}}\Sigma _{j}$$\end{document}</tex-math></alternatives></disp-formula></p><p>Iteration of E-step and M-step will continue until the <italic>k</italic>-th result <inline-formula><alternatives><mml:math id="inf40"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mrow><mml:mo>{</mml:mo><mml:mrow><mml:msup><mml:mi>μ</mml:mi><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:msup><mml:mo>,</mml:mo><mml:msup><mml:mi mathvariant="normal">Σ</mml:mi><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:msup></mml:mrow><mml:mo>}</mml:mo></mml:mrow></mml:mrow></mml:mstyle></mml:math><tex-math id="inft40">\begin{document}$\left \{\mu^{k},\Sigma^{k}\right\}$\end{document}</tex-math></alternatives></inline-formula> and (<italic>k-</italic>1)-th result satisfy the stopping criteria:<disp-formula id="equ17"><label>(17)</label><alternatives><mml:math id="m17"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mo fence="false" stretchy="false">‖</mml:mo><mml:mfrac><mml:mrow><mml:msup><mml:mi>u</mml:mi><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:msup><mml:mo>−</mml:mo><mml:msup><mml:mi>u</mml:mi><mml:mrow><mml:mi>k</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msup></mml:mrow><mml:msup><mml:mi>u</mml:mi><mml:mrow><mml:mi>k</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msup></mml:mfrac><mml:mo fence="false" stretchy="false">‖</mml:mo><mml:mo>&lt;</mml:mo><mml:mi>ε</mml:mi><mml:mspace width="thinmathspace"/><mml:mspace width="thinmathspace"/><mml:mrow><mml:mi mathvariant="normal">a</mml:mi><mml:mi mathvariant="normal">n</mml:mi><mml:mi mathvariant="normal">d</mml:mi></mml:mrow><mml:mspace width="thinmathspace"/><mml:mspace width="thinmathspace"/><mml:mo fence="false" stretchy="false">‖</mml:mo><mml:mfrac><mml:mrow><mml:msup><mml:mi mathvariant="normal">Σ</mml:mi><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:msup><mml:mo>−</mml:mo><mml:msup><mml:mi mathvariant="normal">Σ</mml:mi><mml:mrow><mml:mi>k</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msup></mml:mrow><mml:msup><mml:mi mathvariant="normal">Σ</mml:mi><mml:mrow><mml:mi>k</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msup></mml:mfrac><mml:mo fence="false" stretchy="false">‖</mml:mo><mml:mo>&lt;</mml:mo><mml:mi>ε</mml:mi></mml:mstyle></mml:mrow></mml:mstyle></mml:math><tex-math id="t17">\begin{document}$$\displaystyle  \| \frac{u^{k}- u^{k- 1}}{u^{k- 1}}\| \lt \varepsilon\, \, \mathrm{and}\,\, \| \frac{\Sigma ^{k}- \Sigma ^{k- 1}}{\Sigma^{k- 1}}\| \lt \varepsilon $$\end{document}</tex-math></alternatives></disp-formula></p><p>Here the division represents element-wise division and <inline-formula><alternatives><mml:math id="inf41"><mml:mrow><mml:mrow><mml:mo>‖</mml:mo> <mml:mo>·</mml:mo> <mml:mo>‖</mml:mo></mml:mrow></mml:mrow></mml:math><tex-math id="inft41">\begin{document}$\| \cdot \| $\end{document}</tex-math></alternatives></inline-formula> denotes <inline-formula><alternatives><mml:math id="inf42"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>L</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math><tex-math id="inft42">\begin{document}$L_{2}$\end{document}</tex-math></alternatives></inline-formula>-norm and <inline-formula><alternatives><mml:math id="inf43"><mml:mi>ε</mml:mi></mml:math><tex-math id="inft43">\begin{document}$\varepsilon $\end{document}</tex-math></alternatives></inline-formula> is set to 0.01.</p></sec><sec id="s4-5"><title>Shape characterization of columnar regions</title><p>After deriving the columnar regions through solving the constrained Gaussian mixture model, it is imperative to characterize their geometric shape (terminals and centerlines). For this purpose, we calculate the minimum-volume ellipsoids that can fully encompass each individual columnar region. For <inline-formula><alternatives><mml:math id="inf44"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>c</mml:mi><mml:mo>∈</mml:mo><mml:msup><mml:mi>R</mml:mi><mml:mrow><mml:mn>3</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:mstyle></mml:math><tex-math id="inft44">\begin{document}$c\in R^{3}$\end{document}</tex-math></alternatives></inline-formula>, <inline-formula><alternatives><mml:math id="inf45"><mml:mrow><mml:mi>Q</mml:mi><mml:mo>∈</mml:mo><mml:msubsup><mml:mi>S</mml:mi><mml:mrow><mml:mo>+</mml:mo><mml:mo>+</mml:mo></mml:mrow><mml:mn>3</mml:mn></mml:msubsup></mml:mrow></mml:math><tex-math id="inft45">\begin{document}$Q\in S_{++}^{3}$\end{document}</tex-math></alternatives></inline-formula>, a three-dimensional ellipsoid can be defined as follows <xref ref-type="bibr" rid="bib38">Sun and Freund, 2004</xref>:<disp-formula id="equ18"><label>(18)</label><alternatives><mml:math id="m18"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msub><mml:mi>E</mml:mi><mml:mrow><mml:mi>c</mml:mi><mml:mo>,</mml:mo><mml:mi>Q</mml:mi></mml:mrow></mml:msub><mml:mo>:</mml:mo><mml:mo>=</mml:mo><mml:mrow><mml:mo>{</mml:mo><mml:mrow><mml:mi>x</mml:mi><mml:mo>∈</mml:mo><mml:msup><mml:mi>R</mml:mi><mml:mrow><mml:mn>3</mml:mn></mml:mrow></mml:msup><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:msup><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>x</mml:mi><mml:mo>−</mml:mo><mml:mi>c</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mrow><mml:mi>T</mml:mi></mml:mrow></mml:msup><mml:mi>Q</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>x</mml:mi><mml:mo>−</mml:mo><mml:mi>c</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>≤</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mo>}</mml:mo></mml:mrow></mml:mstyle></mml:mrow></mml:mstyle></mml:math><tex-math id="t18">\begin{document}$$\displaystyle  E_{c,Q}\colon =\left \{x\in R^{3}|\left (x- c\right)^{T}Q\left (x- c\right)\leq 1\right \}$$\end{document}</tex-math></alternatives></disp-formula></p><p>Here, <inline-formula><alternatives><mml:math id="inf46"><mml:mi>c</mml:mi></mml:math><tex-math id="inft46">\begin{document}$c$\end{document}</tex-math></alternatives></inline-formula> is the center of ellipsoid, <inline-formula><alternatives><mml:math id="inf47"><mml:mi>Q</mml:mi></mml:math><tex-math id="inft47">\begin{document}$Q$\end{document}</tex-math></alternatives></inline-formula> represents the geometric shape, <inline-formula><alternatives><mml:math id="inf48"><mml:mrow><mml:msubsup><mml:mi>S</mml:mi><mml:mrow><mml:mo>+</mml:mo><mml:mo>+</mml:mo></mml:mrow><mml:mn>3</mml:mn></mml:msubsup></mml:mrow></mml:math><tex-math id="inft48">\begin{document}$S_{++}^{3}$\end{document}</tex-math></alternatives></inline-formula> denotes the convex cone of 3×3 symmetric positive definite matrices. The volume of <inline-formula><alternatives><mml:math id="inf49"><mml:mrow><mml:msub><mml:mi>E</mml:mi><mml:mrow><mml:mi>c</mml:mi><mml:mo>,</mml:mo><mml:mi>Q</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:math><tex-math id="inft49">\begin{document}$E_{c,Q}$\end{document}</tex-math></alternatives></inline-formula> is given by the formula:<disp-formula id="equ19"><label>(19)</label><alternatives><mml:math id="m19"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>V</mml:mi><mml:mi>o</mml:mi><mml:mi>l</mml:mi><mml:mi>u</mml:mi><mml:mi>m</mml:mi><mml:mi>e</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:msub><mml:mi>E</mml:mi><mml:mrow><mml:mi>c</mml:mi><mml:mo>,</mml:mo><mml:mi>Q</mml:mi></mml:mrow></mml:msub><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mfrac><mml:msup><mml:mi>π</mml:mi><mml:mrow><mml:mn>3</mml:mn><mml:mrow><mml:mo>/</mml:mo></mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup><mml:mrow><mml:mi mathvariant="normal">Γ</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mn>3</mml:mn><mml:mrow><mml:mo>/</mml:mo></mml:mrow><mml:mn>2</mml:mn><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mfrac><mml:mfrac><mml:mn>1</mml:mn><mml:msqrt><mml:mi>d</mml:mi><mml:mi>e</mml:mi><mml:mi>t</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>Q</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:msqrt></mml:mfrac></mml:mstyle></mml:mrow></mml:mstyle></mml:math><tex-math id="t19">\begin{document}$$\displaystyle  Volume\left (E_{c,Q}\right)=\frac{\pi ^{3/2}}{\Gamma \left (3/2+1\right)}\frac{1}{\sqrt{det\left (Q\right)}}$$\end{document}</tex-math></alternatives></disp-formula></p><p>Here, <inline-formula><alternatives><mml:math id="inf50"><mml:mrow><mml:mi>Γ</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mo>⋅</mml:mo><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math><tex-math id="inft50">\begin{document}$\Gamma \left (\cdot \right)$\end{document}</tex-math></alternatives></inline-formula> is the standard gamma function of calculus, <inline-formula><alternatives><mml:math id="inf51"><mml:mrow><mml:mi>d</mml:mi><mml:mi>e</mml:mi><mml:mi>t</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>Q</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math><tex-math id="inft51">\begin{document}$det\left (Q\right)$\end{document}</tex-math></alternatives></inline-formula> means the determinant of matrix <italic>Q</italic>. Minimizing the volume of <inline-formula><alternatives><mml:math id="inf52"><mml:mrow><mml:msub><mml:mi>E</mml:mi><mml:mrow><mml:mi>c</mml:mi><mml:mo>,</mml:mo><mml:mi>Q</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:math><tex-math id="inft52">\begin{document}$E_{c,Q}$\end{document}</tex-math></alternatives></inline-formula> is equivalent to minimizing <inline-formula><alternatives><mml:math id="inf53"><mml:mrow><mml:mi>det</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msup><mml:mi>Q</mml:mi><mml:mrow><mml:mo>−</mml:mo><mml:mn>1</mml:mn><mml:mo>/</mml:mo><mml:mn>2</mml:mn></mml:mrow></mml:msup><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math><tex-math id="inft53">\begin{document}$det\left (Q^{- 1/2}\right)$\end{document}</tex-math></alternatives></inline-formula>. Therefore, for a columnar region with foreground points <inline-formula><alternatives><mml:math id="inf54"><mml:mrow><mml:mi>P</mml:mi><mml:mo>{</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mn>2</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:mo>…</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mi>m</mml:mi></mml:msub><mml:mo>}</mml:mo></mml:mrow></mml:math><tex-math id="inft54">\begin{document}$P\left \{x_{1},x_{2},\ldots x_{m}\right \}$\end{document}</tex-math></alternatives></inline-formula>, we define the target function as follows:<disp-formula id="equ20"><label>(20)</label><alternatives><mml:math id="m20"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>P</mml:mi><mml:mn>1</mml:mn><mml:mo>:</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msup><mml:mi>c</mml:mi><mml:mrow><mml:mo>∗</mml:mo></mml:mrow></mml:msup><mml:mo>,</mml:mo><mml:msup><mml:mi>Q</mml:mi><mml:mrow><mml:mo>∗</mml:mo></mml:mrow></mml:msup></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:msub><mml:mrow><mml:mi>arg</mml:mi><mml:mo>⁡</mml:mo><mml:mo movablelimits="true" form="prefix">min</mml:mo></mml:mrow><mml:mrow><mml:mi>c</mml:mi><mml:mo>,</mml:mo><mml:mi>Q</mml:mi></mml:mrow></mml:msub><mml:mi>d</mml:mi><mml:mi>e</mml:mi><mml:mi>t</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:msup><mml:mi>Q</mml:mi><mml:mrow><mml:mo>−</mml:mo><mml:mn>1</mml:mn><mml:mrow><mml:mo>/</mml:mo></mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup><mml:mo>)</mml:mo></mml:mrow></mml:mstyle></mml:mrow></mml:mstyle></mml:math><tex-math id="t20">\begin{document}$$\displaystyle  P1\colon \left (c^{*},Q^{*}\right)={\arg \min}_{c,Q}det\left (Q^{- 1/2}\right)$$\end{document}</tex-math></alternatives></disp-formula><disp-formula id="equ21"><label>(21)</label><alternatives><mml:math id="m21"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>s</mml:mi><mml:mo>.</mml:mo><mml:mi>t</mml:mi><mml:mo>.</mml:mo><mml:msup><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>x</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>−</mml:mo><mml:mi>c</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mrow><mml:mi>T</mml:mi></mml:mrow></mml:msup><mml:mi>Q</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>x</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>−</mml:mo><mml:mi>c</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>≤</mml:mo><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mn>2</mml:mn><mml:mspace width="thinmathspace"/><mml:mo>.</mml:mo><mml:mo>.</mml:mo><mml:mo>.</mml:mo><mml:mspace width="thinmathspace"/><mml:mi>m</mml:mi></mml:mrow></mml:mstyle></mml:math><tex-math id="t21">\begin{document}$$\displaystyle s.t.\left (x_{i}- c\right)^{T}Q\left (x_{i}- c\right)\leq 1, i=1,2\,...\,m$$\end{document}</tex-math></alternatives></disp-formula><disp-formula id="equ22"><label>(22)</label><alternatives><mml:math id="m22"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>c</mml:mi><mml:mo>∈</mml:mo><mml:mi>C</mml:mi><mml:mi>H</mml:mi><mml:mi>u</mml:mi><mml:mi>l</mml:mi><mml:mi>l</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>P</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>,</mml:mo><mml:mspace width="thinmathspace"/><mml:mi>Q</mml:mi><mml:mo>∈</mml:mo><mml:msubsup><mml:mi>S</mml:mi><mml:mrow><mml:mo>+</mml:mo><mml:mo>+</mml:mo></mml:mrow><mml:mrow><mml:mn>3</mml:mn></mml:mrow></mml:msubsup></mml:mrow></mml:mstyle></mml:math><tex-math id="t22">\begin{document}$$\displaystyle c\in CHull\left (P\right),\, Q\in S_{++}^{3}$$\end{document}</tex-math></alternatives></disp-formula></p><p>Here <inline-formula><alternatives><mml:math id="inf55"><mml:mrow><mml:mi>c</mml:mi><mml:mo>∈</mml:mo><mml:mi>C</mml:mi><mml:mi>H</mml:mi><mml:mi>u</mml:mi><mml:mi>l</mml:mi><mml:mi>l</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>P</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math><tex-math id="inft55">\begin{document}$c\in CHull\left (P_{i}\right)$\end{document}</tex-math></alternatives></inline-formula> restrain the solved center of ellipsoid to locate within the smallest convex hull formed by the clustering points. To solve this problem, a variable substitution <inline-formula><alternatives><mml:math id="inf56"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>A</mml:mi><mml:mo>=</mml:mo><mml:msup><mml:mi>Q</mml:mi><mml:mrow><mml:mn>1</mml:mn><mml:mrow><mml:mo>/</mml:mo></mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:mstyle></mml:math><tex-math id="inft56">\begin{document}$A=Q^{1/2}$\end{document}</tex-math></alternatives></inline-formula> and <inline-formula><alternatives><mml:math id="inf57"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>y</mml:mi><mml:mo>=</mml:mo><mml:msup><mml:mi>Q</mml:mi><mml:mrow><mml:mn>1</mml:mn><mml:mrow><mml:mo>/</mml:mo></mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup><mml:mi>c</mml:mi></mml:mrow></mml:mstyle></mml:math><tex-math id="inft57">\begin{document}$y=Q^{1/2}c$\end{document}</tex-math></alternatives></inline-formula> were applied to <xref ref-type="disp-formula" rid="equ20">Equation 20</xref> and <xref ref-type="disp-formula" rid="equ21">Equation 21</xref>, the original problem <italic>P</italic>1 can be transformed into a convex optimization problem as follows:<disp-formula id="equ23"><label>(23)</label><alternatives><mml:math id="m23"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>P</mml:mi><mml:mn>2</mml:mn><mml:mo>:</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msup><mml:mi>A</mml:mi><mml:mrow><mml:mo>∗</mml:mo></mml:mrow></mml:msup><mml:mo>,</mml:mo><mml:msup><mml:mi>y</mml:mi><mml:mrow><mml:mo>∗</mml:mo></mml:mrow></mml:msup></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:munder><mml:mrow><mml:mi>arg</mml:mi><mml:mo>⁡</mml:mo><mml:mo movablelimits="true" form="prefix">min</mml:mo></mml:mrow><mml:mrow><mml:mi>A</mml:mi><mml:mo>,</mml:mo><mml:mi>y</mml:mi></mml:mrow></mml:munder><mml:mspace width="thinmathspace"/><mml:mtext>-</mml:mtext><mml:mspace width="thinmathspace"/><mml:mi>l</mml:mi><mml:mi>n</mml:mi><mml:mspace width="thinmathspace"/><mml:mi>d</mml:mi><mml:mi>e</mml:mi><mml:mi>t</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>A</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mstyle></mml:mrow></mml:mstyle></mml:math><tex-math id="t23">\begin{document}$$\displaystyle  P2\colon \left (A^{*},y^{*}\right)=\underset{A,y}{\arg \min} \, \text{-} \, ln \, det \left (A\right)$$\end{document}</tex-math></alternatives></disp-formula><disp-formula id="equ24"><label>(24)</label><alternatives><mml:math id="m24"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>s</mml:mi><mml:mo>.</mml:mo><mml:mi>t</mml:mi><mml:mo>.</mml:mo><mml:mspace width="thinmathspace"/><mml:msup><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>A</mml:mi><mml:msub><mml:mi>x</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>−</mml:mo><mml:mi>y</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mrow><mml:mi>T</mml:mi></mml:mrow></mml:msup><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>A</mml:mi><mml:msub><mml:mi>x</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>−</mml:mo><mml:mi>y</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>≤</mml:mo><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mspace width="1em"/><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mn>2</mml:mn><mml:mo>,</mml:mo><mml:mo>.</mml:mo><mml:mo>.</mml:mo><mml:mo>.</mml:mo><mml:mo>,</mml:mo><mml:mi>m</mml:mi></mml:mrow></mml:mstyle></mml:math><tex-math id="t24">\begin{document}$$\displaystyle s.t.\, \left (Ax_{i}- y\right)^{T}\left (Ax_{i}- y\right)\leq 1, \quad i=1,2,...,m$$\end{document}</tex-math></alternatives></disp-formula><disp-formula id="equ25"><label>(25)</label><alternatives><mml:math id="m25"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>A</mml:mi><mml:mo>∈</mml:mo><mml:msubsup><mml:mi>S</mml:mi><mml:mrow><mml:mo>+</mml:mo><mml:mo>+</mml:mo></mml:mrow><mml:mrow><mml:mn>3</mml:mn></mml:mrow></mml:msubsup></mml:mrow></mml:mstyle></mml:math><tex-math id="t25">\begin{document}$$\displaystyle A\in S_{++}^{3}$$\end{document}</tex-math></alternatives></disp-formula></p><p>Through adding the logarithmic barrier function, we can obtain the following formula:<disp-formula id="equ26"><label>(26)</label><alternatives><mml:math id="m26"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>P</mml:mi><mml:mn>3</mml:mn><mml:mo>:</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msup><mml:mi>A</mml:mi><mml:mrow><mml:mo>∗</mml:mo></mml:mrow></mml:msup><mml:mo>,</mml:mo><mml:msup><mml:mi>y</mml:mi><mml:mrow><mml:mo>∗</mml:mo></mml:mrow></mml:msup><mml:mo>,</mml:mo><mml:msup><mml:mi>θ</mml:mi><mml:mrow><mml:mo>∗</mml:mo></mml:mrow></mml:msup></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:munder><mml:mrow><mml:mi>arg</mml:mi><mml:mo>⁡</mml:mo><mml:mo movablelimits="true" form="prefix">min</mml:mo></mml:mrow><mml:mrow><mml:mi>A</mml:mi><mml:mo>,</mml:mo><mml:mi>y</mml:mi><mml:mo>,</mml:mo><mml:mi>θ</mml:mi></mml:mrow></mml:munder><mml:mspace width="thinmathspace"/><mml:mtext>-</mml:mtext><mml:mspace width="thinmathspace"/><mml:mi>l</mml:mi><mml:mi>n</mml:mi><mml:mspace width="thinmathspace"/><mml:mi>d</mml:mi><mml:mi>e</mml:mi><mml:mi>t</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>A</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>−</mml:mo><mml:mi>θ</mml:mi><mml:munderover><mml:mo movablelimits="false">∑</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>m</mml:mi></mml:mrow></mml:munderover><mml:mi>ln</mml:mi><mml:mo>⁡</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:msub><mml:mi>z</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>)</mml:mo></mml:mrow></mml:mstyle></mml:mstyle></mml:mrow></mml:mstyle></mml:math><tex-math id="t26">\begin{document}$$\displaystyle   P3\colon\left (A^{*},y^{*},\theta ^{*}\right)=\underset{A,y,\theta }{\arg \min} \, \text{-} \, ln \, det \left (A\right)- \theta \sum \limits_{i=1}^{m}\ln \left (z_{i}\right)$$\end{document}</tex-math></alternatives></disp-formula><disp-formula id="equ27"><label>(27)</label><alternatives><mml:math id="m27"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>s</mml:mi><mml:mo>.</mml:mo><mml:mi>t</mml:mi><mml:mo>.</mml:mo><mml:msup><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>A</mml:mi><mml:msub><mml:mi>x</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>−</mml:mo><mml:mi>y</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mrow><mml:mi>T</mml:mi></mml:mrow></mml:msup><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>A</mml:mi><mml:msub><mml:mi>x</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>−</mml:mo><mml:mi>y</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>+</mml:mo><mml:msub><mml:mi>z</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mspace width="1em"/><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mn>2</mml:mn><mml:mo>,</mml:mo><mml:mo>.</mml:mo><mml:mo>.</mml:mo><mml:mo>.</mml:mo><mml:mo>,</mml:mo><mml:mi>m</mml:mi></mml:mrow></mml:mstyle></mml:math><tex-math id="t27">\begin{document}$$\displaystyle s.t.\left (Ax_{i}- y\right)^{T}\left (Ax_{i}- y\right) + z_{i}=1, \quad i=1,2,...,m$$\end{document}</tex-math></alternatives></disp-formula><disp-formula id="equ28"><label>(28)</label><alternatives><mml:math id="m28"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>A</mml:mi><mml:mo>∈</mml:mo><mml:msubsup><mml:mi>S</mml:mi><mml:mrow><mml:mo>+</mml:mo><mml:mo>+</mml:mo></mml:mrow><mml:mrow><mml:mn>3</mml:mn></mml:mrow></mml:msubsup><mml:mo>,</mml:mo><mml:msub><mml:mi>z</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>&gt;</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:mstyle></mml:math><tex-math id="t28">\begin{document}$$\displaystyle A\in S_{++}^{3},z_{i} \gt 0$$\end{document}</tex-math></alternatives></disp-formula></p><p>As <inline-formula><alternatives><mml:math id="inf58"><mml:mi>θ</mml:mi></mml:math><tex-math id="inft58">\begin{document}$\theta $\end{document}</tex-math></alternatives></inline-formula> varies in the interval <inline-formula><alternatives><mml:math id="inf59"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:mi mathvariant="normal">∞</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mstyle></mml:math><tex-math id="inft59">\begin{document}$\left (0,\infty \right)$\end{document}</tex-math></alternatives></inline-formula>, the solution of <inline-formula><alternatives><mml:math id="inf60"><mml:mrow><mml:mi>P</mml:mi><mml:mn>3</mml:mn></mml:mrow></mml:math><tex-math id="inft60">\begin{document}$P3$\end{document}</tex-math></alternatives></inline-formula> changes. When <inline-formula><alternatives><mml:math id="inf61"><mml:mi>θ</mml:mi></mml:math><tex-math id="inft61">\begin{document}$\theta $\end{document}</tex-math></alternatives></inline-formula> approaches 0, the optimal solution of <inline-formula><alternatives><mml:math id="inf62"><mml:mrow><mml:mi>P</mml:mi><mml:mn>3</mml:mn></mml:mrow></mml:math><tex-math id="inft62">\begin{document}$P3$\end{document}</tex-math></alternatives></inline-formula> tends to the optimal solution of <inline-formula><alternatives><mml:math id="inf63"><mml:mrow><mml:mi>P</mml:mi><mml:mn>2</mml:mn></mml:mrow></mml:math><tex-math id="inft63">\begin{document}$P2$\end{document}</tex-math></alternatives></inline-formula>. By adding the dual multipliers <inline-formula><alternatives><mml:math id="inf64"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>d</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math><tex-math id="inft64">\begin{document}$d_{i}$\end{document}</tex-math></alternatives></inline-formula> which satisfies <inline-formula><alternatives><mml:math id="inf65"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>d</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>⋅</mml:mo><mml:msub><mml:mi>z</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mi>θ</mml:mi></mml:mrow></mml:mstyle></mml:math><tex-math id="inft65">\begin{document}$d_{i}\cdot z_{i}=\theta $\end{document}</tex-math></alternatives></inline-formula>, the optimality conditions can be written as:<disp-formula id="equ29"><label>(29)</label><alternatives><mml:math id="m29"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mstyle displaystyle="true" scriptlevel="0"><mml:munderover><mml:mo movablelimits="false">∑</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>m</mml:mi></mml:mrow></mml:munderover><mml:msub><mml:mi>d</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo>[</mml:mo><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>A</mml:mi><mml:msub><mml:mi>x</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>−</mml:mo><mml:mi>y</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:msubsup><mml:mi>x</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mi>T</mml:mi></mml:mrow></mml:msubsup><mml:mo>+</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:msup><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>A</mml:mi><mml:msub><mml:mi>x</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>−</mml:mo><mml:mi>y</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mrow><mml:mi>T</mml:mi></mml:mrow></mml:msup></mml:mrow><mml:mo>]</mml:mo></mml:mrow><mml:mo>−</mml:mo><mml:msup><mml:mi>A</mml:mi><mml:mrow><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msup><mml:mo>=</mml:mo><mml:mn>0</mml:mn></mml:mstyle></mml:mrow></mml:mstyle></mml:math><tex-math id="t29">\begin{document}$$\displaystyle  \sum \limits_{i=1}^{m} d_{i}\left [\left (Ax_{i}- y\right)x_{i}^{T}+x_{i}\left (Ax_{i}- y\right)^{T}\right ]- A^{- 1}=0$$\end{document}</tex-math></alternatives></disp-formula><disp-formula id="equ30"><label>(30)</label><alternatives><mml:math id="m30"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mstyle displaystyle="true" scriptlevel="0"><mml:munderover><mml:mo movablelimits="false">∑</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>m</mml:mi></mml:mrow></mml:munderover><mml:msub><mml:mi>d</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>y</mml:mi><mml:mo>−</mml:mo><mml:mi>A</mml:mi><mml:msub><mml:mi>x</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mn>0</mml:mn></mml:mstyle></mml:mrow></mml:mstyle></mml:math><tex-math id="t30">\begin{document}$$\displaystyle  \sum \limits_{i=1}^{m} d_{i}\left (y- Ax_{i}\right)=0$$\end{document}</tex-math></alternatives></disp-formula><disp-formula id="equ31"><label>(31)</label><alternatives><mml:math id="m31"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msup><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>A</mml:mi><mml:msub><mml:mi>x</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>−</mml:mo><mml:mi>y</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mrow><mml:mi>T</mml:mi></mml:mrow></mml:msup><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>A</mml:mi><mml:msub><mml:mi>x</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>−</mml:mo><mml:mi>y</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>+</mml:mo><mml:msub><mml:mi>z</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mn>1</mml:mn><mml:mspace width="thinmathspace"/><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mn>2</mml:mn><mml:mo>,</mml:mo><mml:mo>.</mml:mo><mml:mo>.</mml:mo><mml:mo>.</mml:mo><mml:mo>,</mml:mo><mml:mi>m</mml:mi></mml:mstyle></mml:mrow></mml:mstyle></mml:math><tex-math id="t31">\begin{document}$$\displaystyle  \left (Ax_{i}- y\right)^{T}\left (Ax_{i}- y\right)+z_{i}=1 \, i=1,2,...,m$$\end{document}</tex-math></alternatives></disp-formula><disp-formula id="equ32"><label>(32)</label><alternatives><mml:math id="m32"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mstyle displaystyle="true" scriptlevel="0"><mml:munderover><mml:mo movablelimits="false">∑</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>m</mml:mi></mml:mrow></mml:munderover><mml:msub><mml:mi>d</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>⋅</mml:mo><mml:msub><mml:mi>z</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mi>θ</mml:mi><mml:mo>,</mml:mo><mml:mspace width="1em"/><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mn>2</mml:mn><mml:mo>,</mml:mo><mml:mo>.</mml:mo><mml:mo>.</mml:mo><mml:mo>.</mml:mo><mml:mo>,</mml:mo><mml:mi>m</mml:mi></mml:mstyle></mml:mrow></mml:mstyle></mml:math><tex-math id="t32">\begin{document}$$\displaystyle  \sum \limits_{i=1}^{m} d_{i}\cdot z_{i}=\theta , \quad i=1,2,...,m$$\end{document}</tex-math></alternatives></disp-formula><disp-formula id="equ33"><label>(33)</label><alternatives><mml:math id="m33"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>d</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:mspace width="thinmathspace"/><mml:msub><mml:mi>z</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>≥</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:mstyle></mml:math><tex-math id="t33">\begin{document}$$\displaystyle d_{i}, \, z_{i}\geq 0$$\end{document}</tex-math></alternatives></disp-formula></p><p>At this point, the error between the solution of the system of equations and the optimal solution of <inline-formula><alternatives><mml:math id="inf66"><mml:mrow><mml:mi>P</mml:mi><mml:mn>3</mml:mn></mml:mrow></mml:math><tex-math id="inft66">\begin{document}$P3$\end{document}</tex-math></alternatives></inline-formula> is less than <inline-formula><alternatives><mml:math id="inf67"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msup><mml:mi>d</mml:mi><mml:mrow><mml:mi>T</mml:mi></mml:mrow></mml:msup><mml:mi>z</mml:mi></mml:mrow></mml:mstyle></mml:math><tex-math id="inft67">\begin{document}$d^{T}z$\end{document}</tex-math></alternatives></inline-formula>. Through <xref ref-type="disp-formula" rid="equ30">Equation 30</xref>, the explicit expression for solving <inline-formula><alternatives><mml:math id="inf68"><mml:mi>y</mml:mi></mml:math><tex-math id="inft68">\begin{document}$y$\end{document}</tex-math></alternatives></inline-formula> can be obtained as follows:<disp-formula id="equ34"><label>(34)</label><alternatives><mml:math id="m34"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>y</mml:mi><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mi>A</mml:mi><mml:mi>X</mml:mi><mml:mi>d</mml:mi></mml:mrow><mml:mrow><mml:msup><mml:mi>e</mml:mi><mml:mrow><mml:mi>T</mml:mi></mml:mrow></mml:msup><mml:mi>d</mml:mi></mml:mrow></mml:mfrac></mml:mstyle></mml:mrow></mml:mstyle></mml:math><tex-math id="t34">\begin{document}$$\displaystyle  y=\frac{AXd}{e^{T}d}$$\end{document}</tex-math></alternatives></disp-formula></p><p>Here, <inline-formula><alternatives><mml:math id="inf69"><mml:mi>X</mml:mi></mml:math><tex-math id="inft69">\begin{document}$X$\end{document}</tex-math></alternatives></inline-formula> stands for a <inline-formula><alternatives><mml:math id="inf70"><mml:mrow><mml:mn>3</mml:mn><mml:mo>×</mml:mo><mml:mi>m</mml:mi></mml:mrow></mml:math><tex-math id="inft70">\begin{document}$3\times m$\end{document}</tex-math></alternatives></inline-formula> matrix <inline-formula><alternatives><mml:math id="inf71"><mml:mrow><mml:mo stretchy="false">[</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>|</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mn>2</mml:mn></mml:msub><mml:mo>|</mml:mo><mml:mn>...</mml:mn><mml:mo>|</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mi>m</mml:mi></mml:msub><mml:mo stretchy="false">]</mml:mo></mml:mrow></mml:math><tex-math id="inft71">\begin{document}$\left [x_{1}|x_{2}|...|x_{m}\right ]$\end{document}</tex-math></alternatives></inline-formula>, <inline-formula><alternatives><mml:math id="inf72"><mml:mi>e</mml:mi></mml:math><tex-math id="inft72">\begin{document}$e$\end{document}</tex-math></alternatives></inline-formula> stands for vector of ones <inline-formula><alternatives><mml:math id="inf73"><mml:mrow><mml:msubsup><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mn>...</mml:mn><mml:mo>,</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mrow><mml:mn>1</mml:mn><mml:mo>×</mml:mo><mml:mi>m</mml:mi></mml:mrow><mml:mi>T</mml:mi></mml:msubsup></mml:mrow></mml:math><tex-math id="inft73">\begin{document}$\left (1,1,...,1\right)_{1\times m}^{T}$\end{document}</tex-math></alternatives></inline-formula> and <inline-formula><alternatives><mml:math id="inf74"><mml:mi>d</mml:mi></mml:math><tex-math id="inft74">\begin{document}$d$\end{document}</tex-math></alternatives></inline-formula> stands for <inline-formula><alternatives><mml:math id="inf75"><mml:mrow><mml:msubsup><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>d</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>d</mml:mi><mml:mn>2</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:mn>...</mml:mn><mml:mo>,</mml:mo><mml:msub><mml:mi>d</mml:mi><mml:mi>m</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mrow><mml:mn>1</mml:mn><mml:mo>×</mml:mo><mml:mi>m</mml:mi></mml:mrow><mml:mi>T</mml:mi></mml:msubsup></mml:mrow></mml:math><tex-math id="inft75">\begin{document}$\left (d_{1},d_{2},...,d_{m}\right)_{1\times m}^{T}$\end{document}</tex-math></alternatives></inline-formula>. Substitute <xref ref-type="disp-formula" rid="equ34">Equation 34</xref> into <xref ref-type="disp-formula" rid="equ29">Equation 29</xref>, the equation for matrix <inline-formula><alternatives><mml:math id="inf76"><mml:mi>A</mml:mi></mml:math><tex-math id="inft76">\begin{document}$A$\end{document}</tex-math></alternatives></inline-formula> can be obtained by:<disp-formula id="equ35"><label>(35)</label><alternatives><mml:math id="m35"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>X</mml:mi><mml:mi>D</mml:mi><mml:msup><mml:mi>X</mml:mi><mml:mrow><mml:mi>T</mml:mi></mml:mrow></mml:msup><mml:mo>−</mml:mo><mml:mfrac><mml:mrow><mml:mi>X</mml:mi><mml:mi>d</mml:mi><mml:msup><mml:mi>d</mml:mi><mml:mrow><mml:mi>T</mml:mi></mml:mrow></mml:msup><mml:msup><mml:mi>X</mml:mi><mml:mrow><mml:mi>T</mml:mi></mml:mrow></mml:msup></mml:mrow><mml:mrow><mml:msup><mml:mi>e</mml:mi><mml:mrow><mml:mi>T</mml:mi></mml:mrow></mml:msup><mml:mi>d</mml:mi></mml:mrow></mml:mfrac></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mi>A</mml:mi><mml:mo>+</mml:mo><mml:mi>A</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>X</mml:mi><mml:mi>D</mml:mi><mml:msup><mml:mi>X</mml:mi><mml:mrow><mml:mi>T</mml:mi></mml:mrow></mml:msup><mml:mo>−</mml:mo><mml:mfrac><mml:mrow><mml:mi>X</mml:mi><mml:mi>d</mml:mi><mml:msup><mml:mi>d</mml:mi><mml:mrow><mml:mi>T</mml:mi></mml:mrow></mml:msup><mml:msup><mml:mi>X</mml:mi><mml:mrow><mml:mi>T</mml:mi></mml:mrow></mml:msup></mml:mrow><mml:mrow><mml:msup><mml:mi>e</mml:mi><mml:mrow><mml:mi>T</mml:mi></mml:mrow></mml:msup><mml:mi>d</mml:mi></mml:mrow></mml:mfrac></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:msup><mml:mi>A</mml:mi><mml:mrow><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msup></mml:mstyle></mml:mrow></mml:mstyle></mml:math><tex-math id="t35">\begin{document}$$\displaystyle  \left (XDX^{T}- \frac{Xdd^{T}X^{T}}{e^{T}d}\right)A+A\left (XDX^{T}- \frac{Xdd^{T}X^{T}}{e^{T}d}\right)=A^{- 1}$$\end{document}</tex-math></alternatives></disp-formula></p><p>Here, <inline-formula><alternatives><mml:math id="inf77"><mml:mi>D</mml:mi></mml:math><tex-math id="inft77">\begin{document}$D$\end{document}</tex-math></alternatives></inline-formula> stands for a <inline-formula><alternatives><mml:math id="inf78"><mml:mrow><mml:mi>m</mml:mi><mml:mo>×</mml:mo><mml:mi>m</mml:mi></mml:mrow></mml:math><tex-math id="inft78">\begin{document}$m\times m$\end{document}</tex-math></alternatives></inline-formula> diagonal matrix <inline-formula><alternatives><mml:math id="inf79"><mml:mrow><mml:mi>D</mml:mi><mml:mi>i</mml:mi><mml:mi>a</mml:mi><mml:mi>g</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>d</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>d</mml:mi><mml:mn>2</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:mn>...</mml:mn><mml:mo>,</mml:mo><mml:msub><mml:mi>d</mml:mi><mml:mi>m</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math><tex-math id="inft79">\begin{document}$Diag\left (d_{1},d_{2},...,d_{m}\right)$\end{document}</tex-math></alternatives></inline-formula>. And the explicit expression for <inline-formula><alternatives><mml:math id="inf80"><mml:mi>A</mml:mi></mml:math><tex-math id="inft80">\begin{document}$A$\end{document}</tex-math></alternatives></inline-formula> is formed as<disp-formula id="equ36"><label>(36)</label><alternatives><mml:math id="m36"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>A</mml:mi><mml:mo>=</mml:mo><mml:mi>A</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>d</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:msup><mml:mrow><mml:mo>[</mml:mo><mml:mrow><mml:mn>2</mml:mn><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>X</mml:mi><mml:mi>D</mml:mi><mml:msup><mml:mi>X</mml:mi><mml:mrow><mml:mi>T</mml:mi></mml:mrow></mml:msup><mml:mo>−</mml:mo><mml:mfrac><mml:mrow><mml:mi>X</mml:mi><mml:mi>d</mml:mi><mml:msup><mml:mi>d</mml:mi><mml:mrow><mml:mi>T</mml:mi></mml:mrow></mml:msup><mml:msup><mml:mi>X</mml:mi><mml:mrow><mml:mi>T</mml:mi></mml:mrow></mml:msup></mml:mrow><mml:mrow><mml:msup><mml:mi>e</mml:mi><mml:mrow><mml:mi>T</mml:mi></mml:mrow></mml:msup><mml:mi>d</mml:mi></mml:mrow></mml:mfrac></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>]</mml:mo></mml:mrow><mml:mrow><mml:mo>−</mml:mo><mml:mn>1</mml:mn><mml:mrow><mml:mo>/</mml:mo></mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:mstyle></mml:mrow></mml:mstyle></mml:math><tex-math id="t36">\begin{document}$$\displaystyle  A=A\left (d\right)=\left [2\left (XDX^{T}- \frac{Xdd^{T}X^{T}}{e^{T}d}\right)\right ]^{- 1/2}$$\end{document}</tex-math></alternatives></disp-formula></p><p>And explicit expression for <inline-formula><alternatives><mml:math id="inf81"><mml:mi>y</mml:mi></mml:math><tex-math id="inft81">\begin{document}$y$\end{document}</tex-math></alternatives></inline-formula>:<disp-formula id="equ37"><label>(37)</label><alternatives><mml:math id="m37"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>y</mml:mi><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:msup><mml:mrow><mml:mo>[</mml:mo><mml:mrow><mml:mn>2</mml:mn><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>X</mml:mi><mml:mi>D</mml:mi><mml:msup><mml:mi>X</mml:mi><mml:mrow><mml:mi>T</mml:mi></mml:mrow></mml:msup><mml:mo>−</mml:mo><mml:mfrac><mml:mrow><mml:mi>X</mml:mi><mml:mi>d</mml:mi><mml:msup><mml:mi>d</mml:mi><mml:mrow><mml:mi>T</mml:mi></mml:mrow></mml:msup><mml:msup><mml:mi>X</mml:mi><mml:mrow><mml:mi>T</mml:mi></mml:mrow></mml:msup></mml:mrow><mml:mrow><mml:msup><mml:mi>e</mml:mi><mml:mrow><mml:mi>T</mml:mi></mml:mrow></mml:msup><mml:mi>d</mml:mi></mml:mrow></mml:mfrac></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>]</mml:mo></mml:mrow><mml:mrow><mml:mo>−</mml:mo><mml:mn>1</mml:mn><mml:mrow><mml:mo>/</mml:mo></mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup><mml:mi>X</mml:mi><mml:mi>d</mml:mi></mml:mrow><mml:mrow><mml:msup><mml:mi>e</mml:mi><mml:mrow><mml:mi>T</mml:mi></mml:mrow></mml:msup><mml:mi>d</mml:mi></mml:mrow></mml:mfrac></mml:mstyle></mml:mrow></mml:mstyle></mml:math><tex-math id="t37">\begin{document}$$\displaystyle  y=\frac{\left [2\left (XDX^{T}- \frac{Xdd^{T}X^{T}}{e^{T}d}\right)\right ]^{- 1/2}Xd}{e^{T}d}$$\end{document}</tex-math></alternatives></disp-formula></p><p>Through substituting the above two equations to the system of <xref ref-type="disp-formula" rid="equ29 equ30 equ31 equ32 equ33">Equations 29-33</xref>, variables <italic>A</italic> and y are eliminated. The following system of equations with only variables <italic>d</italic> and <italic>z</italic> can be obtained:<disp-formula id="equ38"><label>(38)</label><alternatives><mml:math id="m38"><mml:mrow><mml:mi>f</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>d</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>+</mml:mo><mml:mi>z</mml:mi><mml:mo>−</mml:mo><mml:mi>e</mml:mi><mml:mo>=</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:math><tex-math id="t38">\begin{document}$$\displaystyle f\left (d\right)+z- e=0$$\end{document}</tex-math></alternatives></disp-formula><disp-formula id="equ39"><label>(39)</label><alternatives><mml:math id="m39"><mml:mrow><mml:mi>D</mml:mi><mml:mi>z</mml:mi><mml:mo>−</mml:mo><mml:mi>θ</mml:mi><mml:mi>e</mml:mi><mml:mo>=</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:math><tex-math id="t39">\begin{document}$$\displaystyle Dz- \theta e=0$$\end{document}</tex-math></alternatives></disp-formula><disp-formula id="equ40"><label>(40)</label><alternatives><mml:math id="m40"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>d</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:mspace width="thinmathspace"/><mml:msub><mml:mi>z</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>≥</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:mstyle></mml:math><tex-math id="t40">\begin{document}$$\displaystyle d_{i}, \, z_{i}\geq 0$$\end{document}</tex-math></alternatives></disp-formula></p><p>Here, <inline-formula><alternatives><mml:math id="inf82"><mml:mrow><mml:mi>f</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>d</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math><tex-math id="inft82">\begin{document}$f\left (d\right)$\end{document}</tex-math></alternatives></inline-formula> is nonlinear function of variable <inline-formula><alternatives><mml:math id="inf83"><mml:mi>d</mml:mi></mml:math><tex-math id="inft83">\begin{document}$d$\end{document}</tex-math></alternatives></inline-formula>:<disp-formula id="equ41"><label>(41)</label><alternatives><mml:math id="m41"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msub><mml:mi>f</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mi>d</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>x</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>−</mml:mo><mml:mfrac><mml:mrow><mml:mi>X</mml:mi><mml:mi>d</mml:mi></mml:mrow><mml:mrow><mml:msup><mml:mi>e</mml:mi><mml:mrow><mml:mi>T</mml:mi></mml:mrow></mml:msup><mml:mi>d</mml:mi></mml:mrow></mml:mfrac></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:msup><mml:mrow><mml:mo>[</mml:mo><mml:mrow><mml:mn>2</mml:mn><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>X</mml:mi><mml:mi>D</mml:mi><mml:msup><mml:mi>X</mml:mi><mml:mrow><mml:mi>T</mml:mi></mml:mrow></mml:msup><mml:mo>−</mml:mo><mml:mfrac><mml:mrow><mml:mi>X</mml:mi><mml:mi>d</mml:mi><mml:msup><mml:mi>d</mml:mi><mml:mrow><mml:mi>T</mml:mi></mml:mrow></mml:msup><mml:msup><mml:mi>X</mml:mi><mml:mrow><mml:mi>T</mml:mi></mml:mrow></mml:msup></mml:mrow><mml:mrow><mml:msup><mml:mi>e</mml:mi><mml:mrow><mml:mi>T</mml:mi></mml:mrow></mml:msup><mml:mi>d</mml:mi></mml:mrow></mml:mfrac></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>]</mml:mo></mml:mrow><mml:mrow><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msup><mml:mo>⋅</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>x</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>−</mml:mo><mml:mfrac><mml:mrow><mml:mi>X</mml:mi><mml:mi>d</mml:mi></mml:mrow><mml:mrow><mml:msup><mml:mi>e</mml:mi><mml:mrow><mml:mi>T</mml:mi></mml:mrow></mml:msup><mml:mi>d</mml:mi></mml:mrow></mml:mfrac></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mn>2</mml:mn><mml:mo>,</mml:mo><mml:mo>.</mml:mo><mml:mo>.</mml:mo><mml:mo>.</mml:mo><mml:mo>,</mml:mo><mml:mi>m</mml:mi></mml:mstyle></mml:mrow></mml:mstyle></mml:math><tex-math id="t41">\begin{document}$$\displaystyle  f_{i}\left (d\right)=\left (x_{i}- \frac{Xd}{e^{T}d}\right)\left [2\left (XDX^{T}- \frac{Xdd^{T}X^{T}}{e^{T}d}\right)\right]^{- 1}\cdot \left (x_{i}- \frac{Xd}{e^{T}d}\right)i=1,2,...,m$$\end{document}</tex-math></alternatives></disp-formula></p><p>For a fixed barrier parameter <inline-formula><alternatives><mml:math id="inf84"><mml:mi>θ</mml:mi></mml:math><tex-math id="inft84">\begin{document}$\theta $\end{document}</tex-math></alternatives></inline-formula>, we employ Newton’s method to solve the system of equations. We use <inline-formula><alternatives><mml:math id="inf85"><mml:mrow><mml:msub><mml:mo>∇</mml:mo><mml:mi>d</mml:mi></mml:msub><mml:mi>f</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>d</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math><tex-math id="inft85">\begin{document}$\nabla _{d}f\left (d\right)$\end{document}</tex-math></alternatives></inline-formula> to represent the Jacobian matrix of <inline-formula><alternatives><mml:math id="inf86"><mml:mrow><mml:mi>f</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>d</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math><tex-math id="inft86">\begin{document}$f\left (d\right)$\end{document}</tex-math></alternatives></inline-formula>. Thus, the Jacobian matrix of the system of equations can be computed as follows:<disp-formula id="equ42"><label>(42)</label><alternatives><mml:math id="m42"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mrow><mml:mo>[</mml:mo><mml:mtable columnalign="center center" rowspacing="4pt" columnspacing="1em"><mml:mtr><mml:mtd><mml:msub><mml:mi mathvariant="normal">∇</mml:mi><mml:mrow><mml:mi>d</mml:mi></mml:mrow></mml:msub><mml:mi>f</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>d</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mtd><mml:mtd><mml:mi>I</mml:mi></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mi>Z</mml:mi></mml:mtd><mml:mtd><mml:mi>D</mml:mi></mml:mtd></mml:mtr></mml:mtable><mml:mo>]</mml:mo></mml:mrow></mml:mrow></mml:mstyle></mml:math><tex-math id="t42">\begin{document}$$\displaystyle \left [\begin{array}{cc}\nabla _{d}f\left (d\right) &amp; I\\ Z &amp; D\end{array}\right]$$\end{document}</tex-math></alternatives></disp-formula></p><p>And the Newton’s direction is written as:<disp-formula id="equ43"><label>(43)</label><alternatives><mml:math id="m43"><mml:mrow><mml:mi>Δ</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>d</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:msup><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mo>∇</mml:mo><mml:mi>d</mml:mi></mml:msub><mml:mi>f</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>d</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>−</mml:mo><mml:msup><mml:mi>D</mml:mi><mml:mrow><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msup><mml:mi>Z</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mrow><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msup><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>h</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>−</mml:mo><mml:msup><mml:mi>D</mml:mi><mml:mrow><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msup><mml:msub><mml:mi>h</mml:mi><mml:mn>2</mml:mn></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math><tex-math id="t43">\begin{document}$$\displaystyle \Delta \left (d\right)=\left (\nabla _{d}f\left (d\right)- D^{- 1}Z\right)^{- 1}\left (h_{1}- D^{- 1}h_{2}\right)$$\end{document}</tex-math></alternatives></disp-formula><disp-formula id="equ44"><label>(44)</label><alternatives><mml:math id="m44"><mml:mrow><mml:mi>Δ</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>z</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:msup><mml:mi>D</mml:mi><mml:mrow><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msup><mml:msub><mml:mi>h</mml:mi><mml:mn>2</mml:mn></mml:msub><mml:mo>−</mml:mo><mml:msup><mml:mi>D</mml:mi><mml:mrow><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msup><mml:mi>Z</mml:mi><mml:msup><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mo>∇</mml:mo><mml:mi>d</mml:mi></mml:msub><mml:mi>f</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>d</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>−</mml:mo><mml:msup><mml:mi>D</mml:mi><mml:mrow><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msup><mml:mi>Z</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mrow><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msup><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>h</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>−</mml:mo><mml:msup><mml:mi>D</mml:mi><mml:mrow><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msup><mml:msub><mml:mi>h</mml:mi><mml:mn>2</mml:mn></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math><tex-math id="t44">\begin{document}$$\displaystyle \Delta \left (z\right)=D^{- 1}h_{2}- D^{- 1}Z\left (\nabla _{d}f\left (d\right)- D^{- 1}Z\right)^{- 1}\left (h_{1}- D^{- 1}h_{2}\right)$$\end{document}</tex-math></alternatives></disp-formula><disp-formula id="equ45"><label>(45)</label><alternatives><mml:math id="m45"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msub><mml:mi>h</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>=</mml:mo><mml:mi>e</mml:mi><mml:mo>−</mml:mo><mml:mi>z</mml:mi><mml:mo>−</mml:mo><mml:mi>f</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>d</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>,</mml:mo><mml:mspace width="1em"/><mml:msub><mml:mi>h</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mi>θ</mml:mi><mml:mi>e</mml:mi><mml:mo>−</mml:mo><mml:mi>D</mml:mi><mml:mi>z</mml:mi></mml:mstyle></mml:mrow></mml:mstyle></mml:math><tex-math id="t45">\begin{document}$$\displaystyle  h_1 = e - z - f(d), \quad h_{2}=\theta e- D z$$\end{document}</tex-math></alternatives></disp-formula></p><p>With initial <inline-formula><alternatives><mml:math id="inf87"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>d</mml:mi><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>z</mml:mi><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mstyle></mml:math><tex-math id="inft87">\begin{document}$\left (d_{0}, z_{0}\right)$\end{document}</tex-math></alternatives></inline-formula>, iterate with <inline-formula><alternatives><mml:math id="inf88"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>d</mml:mi><mml:mrow><mml:mi>n</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>z</mml:mi><mml:mrow><mml:mi>n</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>d</mml:mi><mml:mrow><mml:mi>n</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>z</mml:mi><mml:mrow><mml:mi>n</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>+</mml:mo><mml:mrow><mml:mover><mml:mi>β</mml:mi><mml:mo stretchy="false">~</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi mathvariant="normal">Δ</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:msub><mml:mi>d</mml:mi><mml:mrow><mml:mi>n</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>)</mml:mo></mml:mrow><mml:mo>,</mml:mo><mml:mi mathvariant="normal">Δ</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:msub><mml:mi>z</mml:mi><mml:mrow><mml:mi>n</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mstyle></mml:math><tex-math id="inft88">\begin{document}$\left (d_{n},z_{n}\right)=\left (d_{n- 1},z_{n- 1}\right)+\tilde{\beta }\left (\Delta \left (d_{n- 1}\right),\Delta \left (z_{n- 1}\right)\right)$\end{document}</tex-math></alternatives></inline-formula> to obtain the final optimal solution, <inline-formula><alternatives><mml:math id="inf89"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mrow><mml:mover><mml:mi>β</mml:mi><mml:mo stretchy="false">~</mml:mo></mml:mover></mml:mrow></mml:mrow></mml:mstyle></mml:math><tex-math id="inft89">\begin{document}$\tilde{\beta }$\end{document}</tex-math></alternatives></inline-formula> represents the Newton’s step. Detailed process can see the pseudo code as follows:</p><table-wrap id="inlinetable1" position="anchor"><table frame="hsides" rules="groups" id="AL1"><thead><tr><th align="left" valign="bottom">Algorithm 1. Compute Newton’s direction.</th></tr></thead><tbody><tr><td align="char" char="." valign="bottom"><bold>Input:</bold> <inline-formula><alternatives><mml:math id="inf90"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>d</mml:mi><mml:mo>,</mml:mo><mml:mi>z</mml:mi><mml:mo>,</mml:mo><mml:mi>θ</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mstyle></mml:math><tex-math id="inft90">\begin{document}$\left (d,z,\theta \right)$\end{document}</tex-math></alternatives></inline-formula> satisfying <inline-formula><alternatives><mml:math id="inf91"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>d</mml:mi><mml:mo>,</mml:mo><mml:mi>z</mml:mi><mml:mo>&gt;</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:mstyle></mml:math><tex-math id="inft91">\begin{document}$d,z \gt 0$\end{document}</tex-math></alternatives></inline-formula>, <inline-formula><alternatives><mml:math id="inf92"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>θ</mml:mi><mml:mo>≥</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:mstyle></mml:math><tex-math id="inft92">\begin{document}$\theta\geq 0$\end{document}</tex-math></alternatives></inline-formula><break/><break/><break/>1. <inline-formula><alternatives><mml:math id="inf93"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msup><mml:mi>A</mml:mi><mml:mrow><mml:mo>−</mml:mo><mml:mn>2</mml:mn></mml:mrow></mml:msup><mml:mrow><mml:mo>(</mml:mo><mml:mi>d</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mrow><mml:mo>[</mml:mo><mml:mrow><mml:mn>2</mml:mn><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>X</mml:mi><mml:mi>D</mml:mi><mml:msup><mml:mi>X</mml:mi><mml:mrow><mml:mi>T</mml:mi></mml:mrow></mml:msup><mml:mo>−</mml:mo><mml:mfrac><mml:mrow><mml:mi>X</mml:mi><mml:mi>d</mml:mi><mml:msup><mml:mi>d</mml:mi><mml:mrow><mml:mi>T</mml:mi></mml:mrow></mml:msup><mml:msup><mml:mi>X</mml:mi><mml:mrow><mml:mi>T</mml:mi></mml:mrow></mml:msup></mml:mrow><mml:mrow><mml:msup><mml:mi>e</mml:mi><mml:mrow><mml:mi>T</mml:mi></mml:mrow></mml:msup><mml:mi>d</mml:mi></mml:mrow></mml:mfrac></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>]</mml:mo></mml:mrow></mml:mrow></mml:mstyle></mml:math><tex-math id="inft93">\begin{document}$A^{- 2}\left (d\right)=\left [2\left (XDX^{T}- \frac{Xdd^{T}X^{T}}{e^{T}d}\right)\right ]$\end{document}</tex-math></alternatives></inline-formula><break/><break/><break/>2. <inline-formula><alternatives><mml:math id="inf94"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi mathvariant="normal">Σ</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>d</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>X</mml:mi><mml:mo>−</mml:mo><mml:mfrac><mml:mrow><mml:mi>X</mml:mi><mml:mi>d</mml:mi><mml:msup><mml:mi>e</mml:mi><mml:mrow><mml:mi>T</mml:mi></mml:mrow></mml:msup></mml:mrow><mml:mrow><mml:msup><mml:mi>e</mml:mi><mml:mrow><mml:mi>T</mml:mi></mml:mrow></mml:msup><mml:mi>d</mml:mi></mml:mrow></mml:mfrac></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:msup><mml:mi>A</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup><mml:mrow><mml:mo>(</mml:mo><mml:mi>d</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>X</mml:mi><mml:mo>−</mml:mo><mml:mfrac><mml:mrow><mml:mi>X</mml:mi><mml:mi>d</mml:mi><mml:msup><mml:mi>e</mml:mi><mml:mrow><mml:mi>T</mml:mi></mml:mrow></mml:msup></mml:mrow><mml:mrow><mml:msup><mml:mi>e</mml:mi><mml:mrow><mml:mi>T</mml:mi></mml:mrow></mml:msup><mml:mi>d</mml:mi></mml:mrow></mml:mfrac></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mstyle></mml:math><tex-math id="inft94">\begin{document}$\Sigma \left (d\right)=\left (X- \frac{Xde^{T}}{e^{T}d}\right)A^{2}\left (d\right)\left (X- \frac{Xde^{T}}{e^{T}d}\right)$\end{document}</tex-math></alternatives></inline-formula><break/><break/><break/>3 <inline-formula><alternatives><mml:math id="inf95"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi mathvariant="normal">∇</mml:mi><mml:mrow><mml:mi>d</mml:mi></mml:mrow></mml:msub><mml:mi>f</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>d</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mo>−</mml:mo><mml:mn>2</mml:mn><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mfrac><mml:mrow><mml:mi mathvariant="normal">Σ</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>d</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mrow><mml:msup><mml:mi>e</mml:mi><mml:mrow><mml:mi>T</mml:mi></mml:mrow></mml:msup><mml:mi>d</mml:mi></mml:mrow></mml:mfrac><mml:mo>+</mml:mo><mml:mi mathvariant="normal">Σ</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>d</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>∘</mml:mo><mml:mi mathvariant="normal">Σ</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>d</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mstyle></mml:math><tex-math id="inft95">\begin{document}$\nabla _{d}f\left (d\right)=- 2\left (\frac{\Sigma \left (d\right)}{e^{T}d}+\Sigma \left (d\right)\circ \Sigma \left (d\right)\right)$\end{document}</tex-math></alternatives></inline-formula><break/><break/><break/>4. <inline-formula><alternatives><mml:math id="inf96"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi mathvariant="normal">Δ</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>d</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>,</mml:mo><mml:mi mathvariant="normal">Δ</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>z</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msup><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi mathvariant="normal">∇</mml:mi><mml:mrow><mml:mi>d</mml:mi></mml:mrow></mml:msub><mml:mi>f</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>d</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>−</mml:mo><mml:msup><mml:mi>D</mml:mi><mml:mrow><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msup><mml:mi>Z</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mrow><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msup><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>h</mml:mi><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>−</mml:mo><mml:msup><mml:mi>D</mml:mi><mml:mrow><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msup><mml:msub><mml:mi>h</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>,</mml:mo><mml:msup><mml:mi>D</mml:mi><mml:mrow><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msup><mml:msub><mml:mi>h</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:mo>−</mml:mo><mml:msup><mml:mi>D</mml:mi><mml:mrow><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msup><mml:mi>Z</mml:mi><mml:mi mathvariant="normal">Δ</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>d</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mstyle></mml:math><tex-math id="inft96">\begin{document}$\left (\Delta \left (d\right),\Delta \left (z\right)\right)=\left (\left (\nabla _{d}f\left (d\right)- D^{- 1}Z\right)^{- 1}\left (h_{1}- D^{- 1}h_{2}\right), D^{- 1}h_{2}- D^{- 1}Z\Delta \left (d\right)\right)$\end{document}</tex-math></alternatives></inline-formula><break/><break/><break/><bold>Output:</bold> <inline-formula><alternatives><mml:math id="inf97"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi mathvariant="normal">Δ</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>d</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>,</mml:mo><mml:mi mathvariant="normal">Δ</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>z</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mstyle></mml:math><tex-math id="inft97">\begin{document}$(\Delta (d),\Delta (z))$\end{document}</tex-math></alternatives></inline-formula></td></tr></tbody></table></table-wrap><table-wrap id="inlinetable2" position="anchor"><table frame="hsides" rules="groups" id="AL2"><thead><tr><th align="left" valign="bottom">Algorithm 2. Process of solving P2.</th></tr></thead><tbody><tr><td align="left" valign="bottom"><bold>Input: </bold><inline-formula><alternatives><mml:math id="inf98"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mrow><mml:mo>{</mml:mo><mml:mrow><mml:msub><mml:mi>x</mml:mi><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:mo>.</mml:mo><mml:mo>.</mml:mo><mml:mo>.</mml:mo><mml:mo>,</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mrow><mml:mi>m</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>}</mml:mo></mml:mrow></mml:mrow></mml:mstyle></mml:math><tex-math id="inft98">\begin{document}$\left \{x_{1}, x_{2},...,x_{m}\right \}$\end{document}</tex-math></alternatives></inline-formula><break/><break/><break/>1. <inline-formula><alternatives><mml:math id="inf99"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>r</mml:mi><mml:mo>=</mml:mo><mml:mn>0.99</mml:mn></mml:mrow></mml:mstyle></mml:math><tex-math id="inft99">\begin{document}$r=0.99$\end{document}</tex-math></alternatives></inline-formula>, <inline-formula><alternatives><mml:math id="inf100"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>d</mml:mi><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>z</mml:mi><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mfrac><mml:mn>3</mml:mn><mml:mrow><mml:mn>2</mml:mn><mml:mi>m</mml:mi></mml:mrow></mml:mfrac><mml:mi>e</mml:mi><mml:mo>,</mml:mo><mml:mi>e</mml:mi><mml:mo>−</mml:mo><mml:mi>f</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:msub><mml:mi>d</mml:mi><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msub><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mstyle></mml:math><tex-math id="inft100">\begin{document}$\left (d_{0},z_{0}\right)=\left (\frac{3}{2m}e,e- f\left (d_{0}\right)\right)$\end{document}</tex-math></alternatives></inline-formula><break/><break/><break/>2.<inline-formula><alternatives><mml:math id="inf101"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>E</mml:mi><mml:mo>=</mml:mo><mml:mo>−</mml:mo><mml:mo movablelimits="true" form="prefix">det</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>A</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>d</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mstyle></mml:math><tex-math id="inft101">\begin{document}$E=- \det \left (A\left (d\right)\right)$\end{document}</tex-math></alternatives></inline-formula><break/><break/><break/>3. while (<inline-formula><alternatives><mml:math id="inf102"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mrow><mml:mo>|</mml:mo><mml:mrow><mml:mi>e</mml:mi><mml:mo>−</mml:mo><mml:mi>f</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>d</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>−</mml:mo><mml:mi>z</mml:mi></mml:mrow><mml:mo>|</mml:mo></mml:mrow><mml:mo>&gt;</mml:mo><mml:msub><mml:mi>ε</mml:mi><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math><tex-math id="inft102">\begin{document}$\left|e- f\left (d\right)- z \right| \gt \varepsilon _{1}$\end{document}</tex-math></alternatives></inline-formula> or <inline-formula><alternatives><mml:math id="inf103"><mml:mrow><mml:mfrac><mml:mrow><mml:msup><mml:mi>d</mml:mi><mml:mi>T</mml:mi></mml:msup><mml:mi>z</mml:mi></mml:mrow><mml:mi>E</mml:mi></mml:mfrac><mml:mo>&gt;</mml:mo><mml:msub><mml:mi>ε</mml:mi><mml:mn>2</mml:mn></mml:msub></mml:mrow></mml:math><tex-math id="inft103">\begin{document}$\frac{d^{T}z}{E} \gt \varepsilon _{2}$\end{document}</tex-math></alternatives></inline-formula>)<break/><break/><break/>4.   <inline-formula><alternatives><mml:math id="inf104"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>θ</mml:mi><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:msup><mml:mi>d</mml:mi><mml:mrow><mml:mi>T</mml:mi></mml:mrow></mml:msup><mml:mi>z</mml:mi></mml:mrow><mml:mrow><mml:mn>10</mml:mn><mml:mi>m</mml:mi></mml:mrow></mml:mfrac></mml:mrow></mml:mstyle></mml:math><tex-math id="inft104">\begin{document}$\theta =\frac{d^{T}z}{10m}$\end{document}</tex-math></alternatives></inline-formula><break/><break/><break/>5.  <inline-formula><alternatives><mml:math id="inf105"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi mathvariant="normal">Δ</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>d</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>,</mml:mo><mml:mi mathvariant="normal">Δ</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>z</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mstyle></mml:math><tex-math id="inft105">\begin{document}$\left (\Delta \left (d\right),\Delta \left (z\right)\right)$\end{document}</tex-math></alternatives></inline-formula> <italic>= Compute_Newton_direction</italic> <inline-formula><alternatives><mml:math id="inf106"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>d</mml:mi><mml:mo>,</mml:mo><mml:mi>z</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mstyle></mml:math><tex-math id="inft106">\begin{document}$\left (d,z\right)$\end{document}</tex-math></alternatives></inline-formula><break/><break/><break/>6.  <inline-formula><alternatives><mml:math id="inf107"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mrow><mml:mover><mml:mi>β</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover></mml:mrow><mml:mo>=</mml:mo><mml:mo movablelimits="true" form="prefix">max</mml:mo><mml:mrow><mml:mo>{</mml:mo><mml:mrow><mml:mi>β</mml:mi><mml:mrow><mml:mo>|</mml:mo><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>d</mml:mi><mml:mo>,</mml:mo><mml:mi>z</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>+</mml:mo><mml:mi>β</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi mathvariant="normal">Δ</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>d</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>,</mml:mo><mml:mi mathvariant="normal">Δ</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>z</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>≥</mml:mo><mml:mn>0</mml:mn></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>}</mml:mo></mml:mrow></mml:mrow><mml:mo fence="true" stretchy="true" symmetric="true"/></mml:mrow></mml:mrow></mml:mstyle></mml:math><tex-math id="inft107">\begin{document}$\bar{\beta }=\max \left \{\beta \left|\left (d,z\right)+\beta \left (\Delta \left (d\right),\Delta \left (z\right)\geq 0\right)\right\}\right.$\end{document}</tex-math></alternatives></inline-formula><break/><break/><break/>7.  <inline-formula><alternatives><mml:math id="inf108"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mrow><mml:mover><mml:mi>β</mml:mi><mml:mo stretchy="false">~</mml:mo></mml:mover></mml:mrow><mml:mo>=</mml:mo><mml:mo movablelimits="true" form="prefix">min</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mrow><mml:mover><mml:mrow><mml:mi>r</mml:mi><mml:mi>β</mml:mi></mml:mrow><mml:mo stretchy="false">¯</mml:mo></mml:mover></mml:mrow><mml:mo>,</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mstyle></mml:math><tex-math id="inft108">\begin{document}$\tilde{\beta }=\min \left (\bar{r\beta },1\right)$\end{document}</tex-math></alternatives></inline-formula><break/><break/><break/>8.  <inline-formula><alternatives><mml:math id="inf109"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>d</mml:mi><mml:mo>,</mml:mo><mml:mi>z</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>d</mml:mi><mml:mo>,</mml:mo><mml:mi>z</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>+</mml:mo><mml:mrow><mml:mover><mml:mi>β</mml:mi><mml:mo stretchy="false">~</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi mathvariant="normal">Δ</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>d</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>,</mml:mo><mml:mi mathvariant="normal">Δ</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>z</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mstyle></mml:math><tex-math id="inft109">\begin{document}$\left (d,z\right)=\left (d,z\right)+\tilde{\beta }\left (\Delta \left (d\right),\Delta \left (z\right)\right)$\end{document}</tex-math></alternatives></inline-formula><break/><break/><break/>9.  <inline-formula><alternatives><mml:math id="inf110"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>E</mml:mi><mml:mo>=</mml:mo><mml:mo>−</mml:mo><mml:mo movablelimits="true" form="prefix">det</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>A</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>d</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mstyle></mml:math><tex-math id="inft110">\begin{document}$E=- \det \left (A\left (d\right)\right)$\end{document}</tex-math></alternatives></inline-formula><break/><break/><break/><bold>Output:</bold> <inline-formula><alternatives><mml:math id="inf111"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>Q</mml:mi><mml:mo>=</mml:mo><mml:mi>A</mml:mi><mml:msup><mml:mrow><mml:mo>(</mml:mo><mml:mi>d</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup><mml:mo>,</mml:mo><mml:mrow><mml:mi>c</mml:mi><mml:mo>=</mml:mo><mml:mi>A</mml:mi></mml:mrow><mml:msup><mml:mrow><mml:mo>(</mml:mo><mml:mi>d</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mrow><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msup><mml:mi>y</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>d</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mstyle></mml:math><tex-math id="inft111">\begin{document}$Q=A\left (d\right)^{2},{c=A}\left (d\right)^{- 1}y\left (d\right)$\end{document}</tex-math></alternatives></inline-formula></td></tr></tbody></table></table-wrap><p>With the solved optimal solution of <inline-formula><alternatives><mml:math id="inf112"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>Q</mml:mi><mml:mo>,</mml:mo><mml:mi>c</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mstyle></mml:math><tex-math id="inft112">\begin{document}$\left (Q, c \right)$\end{document}</tex-math></alternatives></inline-formula>, we then check whether <inline-formula><alternatives><mml:math id="inf113"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>c</mml:mi></mml:mrow></mml:mstyle></mml:math><tex-math id="inft113">\begin{document}$c$\end{document}</tex-math></alternatives></inline-formula> is located within the convex hull of the input point set <inline-formula><alternatives><mml:math id="inf114"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mrow><mml:mo>{</mml:mo><mml:mrow><mml:msub><mml:mi>x</mml:mi><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:mo>.</mml:mo><mml:mo>.</mml:mo><mml:mo>.</mml:mo><mml:mo>,</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mrow><mml:mi>m</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>}</mml:mo></mml:mrow></mml:mrow></mml:mstyle></mml:math><tex-math id="inft114">\begin{document}$\left \{x_{1},x_{2},...,x_{m}\right \}$\end{document}</tex-math></alternatives></inline-formula>. If it is not, a constrained Gaussian mixture model will be applied to partition it into two subsets and solve the minimum-volume covering ellipsoids problem again in the two subsets. Through solving the above minimum-volume covering ellipsoids problem, we can characterize the columnar regions more accurately.</p><p>Note that from constrained GMM, each cluster has the corresponding mean and covariance matrix of points in the cluster. These two values essentially describe the shape of the cluster. However, if these two values directly replace <inline-formula><alternatives><mml:math id="inf115"><mml:mrow><mml:msup><mml:mi>c</mml:mi><mml:mo>*</mml:mo></mml:msup></mml:mrow></mml:math><tex-math id="inft115">\begin{document}$c^{*}$\end{document}</tex-math></alternatives></inline-formula> and <inline-formula><alternatives><mml:math id="inf116"><mml:mrow><mml:msup><mml:mi>Q</mml:mi><mml:mo>*</mml:mo></mml:msup></mml:mrow></mml:math><tex-math id="inft116">\begin{document}$Q^{*}$\end{document}</tex-math></alternatives></inline-formula><italic>,</italic> the exported ellipsoid may only encompass a part of points in the cluster. For covering all points in the cluster, all elements in the covariance matrix are needed to be proportionally enlarged, but the volume of the corresponding ellipsoid is not minimum. These two cases will reduce the accuracy of the connections between clusters, that is columnar regions. So, we introduce the minimum-volume covering ellipsoid model to extract the shape of columnar region.</p></sec><sec id="s4-6"><title>Skeleton generation using 0-1 assignment model</title><p>The 0–1 assignment model (<xref ref-type="bibr" rid="bib41">Volgenant, 1996</xref>) can robustly and accurately establish connections between particles in live-cell imaging (<xref ref-type="bibr" rid="bib16">Jaqaman et al., 2008</xref>). It is particularly effective in handling cases where particles are densely distributed, merged, or split. We analogize column regions to particles and apply the 0–1 assignment model to build the connections between column regions. For the <italic>i-</italic>th columnar region, the center and the two endpoints of the longest axis of its minimum-volume covering ellipsoid are denoted by <inline-formula><alternatives><mml:math id="inf117"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>c</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math><tex-math id="inft117">\begin{document}$c_{i}, t_{i,0}, t_{i,1}$\end{document}</tex-math></alternatives></inline-formula>. The direction refers to the pointing of the center point towards <inline-formula><alternatives><mml:math id="inf118"><mml:mrow><mml:msub><mml:mi>t</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>k</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:math><tex-math id="inft118">\begin{document}$t_{i,k}$\end{document}</tex-math></alternatives></inline-formula>, <italic>k</italic> equal to 0 or 1. According to the direction and the endpoints, we design the cost matrix for building the 0–1 assignment model.<disp-formula id="equ46"><label>(46)</label><alternatives><mml:math id="m46"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>C</mml:mi><mml:mo>=</mml:mo><mml:msub><mml:mrow><mml:mo>[</mml:mo><mml:mtable columnalign="center center center center center center" rowspacing="4pt" columnspacing="1em"><mml:mtr><mml:mtd><mml:mi>c</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>t</mml:mi><mml:mrow><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mrow><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mtd><mml:mtd><mml:mi>c</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>t</mml:mi><mml:mrow><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mrow><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mtd><mml:mtd><mml:mo>⋯</mml:mo></mml:mtd><mml:mtd><mml:mi>c</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>t</mml:mi><mml:mrow><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mrow><mml:mi>n</mml:mi><mml:mo>,</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mtd><mml:mtd/><mml:mtd/></mml:mtr><mml:mtr><mml:mtd><mml:mi>c</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>t</mml:mi><mml:mrow><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mrow><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mtd><mml:mtd><mml:mi>c</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>t</mml:mi><mml:mrow><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mrow><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mtd><mml:mtd><mml:mo>⋯</mml:mo></mml:mtd><mml:mtd><mml:mi>c</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>t</mml:mi><mml:mrow><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mrow><mml:mi>n</mml:mi><mml:mo>,</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mtd><mml:mtd/><mml:mtd><mml:mi>D</mml:mi></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mo>⋮</mml:mo></mml:mtd><mml:mtd><mml:mo>⋮</mml:mo></mml:mtd><mml:mtd><mml:mo>⋮</mml:mo></mml:mtd><mml:mtd><mml:mo>⋮</mml:mo></mml:mtd><mml:mtd/><mml:mtd/></mml:mtr><mml:mtr><mml:mtd><mml:mi>c</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>t</mml:mi><mml:mrow><mml:mi>n</mml:mi><mml:mo>,</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mrow><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mtd><mml:mtd><mml:mi>c</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>t</mml:mi><mml:mrow><mml:mi>n</mml:mi><mml:mo>,</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mrow><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mtd><mml:mtd><mml:mo>⋯</mml:mo></mml:mtd><mml:mtd><mml:mi>c</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>t</mml:mi><mml:mrow><mml:mi>n</mml:mi><mml:mo>,</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mrow><mml:mi>n</mml:mi><mml:mo>,</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mtd><mml:mtd/><mml:mtd/></mml:mtr><mml:mtr><mml:mtd/><mml:mtd/><mml:mtd/><mml:mtd/><mml:mtd/><mml:mtd/></mml:mtr><mml:mtr><mml:mtd/><mml:mtd><mml:mi>D</mml:mi></mml:mtd><mml:mtd/><mml:mtd/><mml:mtd/><mml:mtd><mml:mi>D</mml:mi></mml:mtd></mml:mtr></mml:mtable><mml:mo>]</mml:mo></mml:mrow><mml:mrow><mml:mn>4</mml:mn><mml:mi>n</mml:mi><mml:mo>×</mml:mo><mml:mn>4</mml:mn><mml:mi>n</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math><tex-math id="t46">\begin{document}$$\displaystyle C=\left [\begin{array}{cccccc}c\left (t_{1,0},t_{1,0}\right) &amp; c\left (t_{1,0},t_{1,1}\right) &amp; \cdots &amp; c\left (t_{1,0},t_{n,1}\right) &amp; &amp; \\c\left (t_{1,1},t_{1,0}\right) &amp; c\left (t_{1,1},t_{1,1}\right) &amp; \cdots &amp; c\left (t_{1,1},t_{n,1}\right) &amp; &amp; D\\\vdots &amp; \vdots &amp; \vdots &amp; \vdots &amp; &amp; \\c\left (t_{n,1},t_{1,0}\right) &amp; c\left (t_{n,1},t_{1,1}\right) &amp; \cdots &amp; c\left (t_{n,1},t_{n,1}\right) &amp; &amp; \\ &amp; &amp; &amp; &amp; &amp; \\ &amp; D &amp; &amp; &amp; &amp; D\end{array}\right]_{4n\times 4n}$$\end{document}</tex-math></alternatives></disp-formula><disp-formula id="equ47"><label>(47)</label><alternatives><mml:math id="m47"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>c</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>t</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>i</mml:mi><mml:mn>0</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mrow><mml:mi>j</mml:mi><mml:mo>,</mml:mo><mml:mi>j</mml:mi><mml:mn>0</mml:mn></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mrow><mml:mo>{</mml:mo><mml:mtable columnalign="left left" rowspacing=".2em" columnspacing="1em" displaystyle="false"><mml:mtr><mml:mtd><mml:mn>100</mml:mn></mml:mtd><mml:mtd><mml:mi>i</mml:mi><mml:mi>f</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mi>j</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mfrac><mml:mrow><mml:mi>n</mml:mi><mml:mi>o</mml:mi><mml:mi>r</mml:mi><mml:mi>m</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>t</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>i</mml:mi><mml:mn>0</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mrow><mml:mi>j</mml:mi><mml:mo>,</mml:mo><mml:mi>j</mml:mi><mml:mn>0</mml:mn></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:msup><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mn>0.5</mml:mn><mml:mo>×</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mfrac><mml:mrow><mml:mi>θ</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>t</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>i</mml:mi><mml:mn>0</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mrow><mml:mi>j</mml:mi><mml:mo>,</mml:mo><mml:mi>j</mml:mi><mml:mn>0</mml:mn></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mn>3</mml:mn></mml:mfrac><mml:mo>+</mml:mo><mml:mn>1.001</mml:mn></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mrow><mml:mn>4</mml:mn></mml:mrow></mml:msup></mml:mfrac></mml:mstyle></mml:mtd><mml:mtd><mml:mi>i</mml:mi><mml:mi>f</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>≠</mml:mo><mml:mi>j</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable><mml:mo fence="true" stretchy="true" symmetric="true"/></mml:mrow></mml:mrow></mml:mstyle></mml:math><tex-math id="t47">\begin{document}$$\displaystyle c\left (t_{i,i0},t_{j,j0}\right)= \begin{cases}100 &amp; if\left (i=j\right)\\  \frac{norm\left (t_{i,i0},t_{j,j0}\right)}{\left (0.5\times \left (\frac{\theta \left (t_{i,i0},t_{j,j0}\right)}{3}+1.001\right)\right)^{4}} &amp; if\left (i\neq j\right)\end{cases}$$\end{document}</tex-math></alternatives></disp-formula><disp-formula id="equ48"><label>(48)</label><alternatives><mml:math id="m48"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mtable columnalign="right left right left right left right left right left right left" rowspacing="3pt" columnspacing="0em 2em 0em 2em 0em 2em 0em 2em 0em 2em 0em" displaystyle="true"><mml:mtr><mml:mtd><mml:mi>θ</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>t</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>i</mml:mi><mml:mn>0</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mrow><mml:mi>j</mml:mi><mml:mo>,</mml:mo><mml:mi>j</mml:mi><mml:mn>0</mml:mn></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo></mml:mtd><mml:mtd><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mo>⟨</mml:mo><mml:mrow><mml:mi>d</mml:mi><mml:mi>i</mml:mi><mml:mi>r</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>c</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>i</mml:mi><mml:mn>0</mml:mn></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>,</mml:mo><mml:mi>d</mml:mi><mml:mi>i</mml:mi><mml:mi>r</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>c</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mrow><mml:mi>j</mml:mi><mml:mo>,</mml:mo><mml:mi>j</mml:mi><mml:mn>0</mml:mn></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>⟩</mml:mo></mml:mrow><mml:mo>+</mml:mo><mml:mrow><mml:mo>⟨</mml:mo><mml:mrow><mml:mi>d</mml:mi><mml:mi>i</mml:mi><mml:mi>r</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>c</mml:mi><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mrow><mml:mi>j</mml:mi><mml:mo>,</mml:mo><mml:mi>j</mml:mi><mml:mn>0</mml:mn></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>,</mml:mo><mml:mi>d</mml:mi><mml:mi>i</mml:mi><mml:mi>r</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>c</mml:mi><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>i</mml:mi><mml:mn>0</mml:mn></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>⟩</mml:mo></mml:mrow></mml:mstyle></mml:mtd></mml:mtr><mml:mtr><mml:mtd/><mml:mtd><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mo>−</mml:mo><mml:mrow><mml:mo>⟨</mml:mo><mml:mrow><mml:mi>d</mml:mi><mml:mi>i</mml:mi><mml:mi>r</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>c</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>i</mml:mi><mml:mn>0</mml:mn></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>,</mml:mo><mml:mi>d</mml:mi><mml:mi>i</mml:mi><mml:mi>r</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>c</mml:mi><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mrow><mml:mi>j</mml:mi><mml:mo>,</mml:mo><mml:mi>j</mml:mi><mml:mn>0</mml:mn></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>⟩</mml:mo></mml:mrow></mml:mstyle></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:mstyle></mml:math><tex-math id="t48">\begin{document}$$\displaystyle \theta \left (t_{i,i0},t_{j,j0}\right)= &amp;  \left \langle dir\left (c_{i},t_{i,i0}\right),dir\left (c_{i},t_{j,j0}\right)\right \rangle +\left \langle dir\left (c_{j},t_{j,j0}\right),dir\left (c_{j},t_{i,i0}\right)\right \rangle \\ &amp;  - \left \langle dir\left (c_{i},t_{i,i0}\right),dir\left (c_{j},t_{j,j0}\right)\right \rangle $$\end{document}</tex-math></alternatives></disp-formula></p><p>Here, <italic>D</italic> is 2<italic>n</italic>×2<italic>n</italic> auxiliary matrix all elements of which are all set 100. Both <inline-formula><alternatives><mml:math id="inf119"><mml:mrow><mml:mi>i</mml:mi><mml:mn>0</mml:mn></mml:mrow></mml:math><tex-math id="inft119">\begin{document}$i0$\end{document}</tex-math></alternatives></inline-formula> and <inline-formula><alternatives><mml:math id="inf120"><mml:mrow><mml:mi>j</mml:mi><mml:mn>0</mml:mn></mml:mrow></mml:math><tex-math id="inft120">\begin{document}$j0$\end{document}</tex-math></alternatives></inline-formula> in <xref ref-type="disp-formula" rid="equ47">Equation 47</xref> are equal to 0 or 1, labeling the two endpoints of the longest axis of the ellipsoid. <inline-formula><alternatives><mml:math id="inf121"><mml:mrow><mml:mi>n</mml:mi><mml:mi>o</mml:mi><mml:mi>r</mml:mi><mml:mi>m</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>i</mml:mi><mml:mn>0</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mrow><mml:mi>j</mml:mi><mml:mo>,</mml:mo><mml:mi>j</mml:mi><mml:mn>0</mml:mn></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math><tex-math id="inft121">\begin{document}$norm\left (t_{i,i0},t_{j,j0}\right)$\end{document}</tex-math></alternatives></inline-formula> represents the Euclidean distance between <inline-formula><alternatives><mml:math id="inf122"><mml:mrow><mml:msub><mml:mi>t</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>i</mml:mi><mml:mn>0</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:math><tex-math id="inft122">\begin{document}$t_{i,i0}$\end{document}</tex-math></alternatives></inline-formula> and <inline-formula><alternatives><mml:math id="inf123"><mml:mrow><mml:msub><mml:mi>t</mml:mi><mml:mrow><mml:mi>j</mml:mi><mml:mo>,</mml:mo><mml:mi>j</mml:mi><mml:mn>0</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:math><tex-math id="inft123">\begin{document}$t_{j,j0}$\end{document}</tex-math></alternatives></inline-formula>. <inline-formula><alternatives><mml:math id="inf124"><mml:mrow><mml:mi>θ</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>i</mml:mi><mml:mn>0</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mrow><mml:mi>j</mml:mi><mml:mo>,</mml:mo><mml:mi>j</mml:mi><mml:mn>0</mml:mn></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math><tex-math id="inft124">\begin{document}$\theta \left (t_{i,i0},t_{j,j0}\right)$\end{document}</tex-math></alternatives></inline-formula> describes the angle between two ellipsoids, that is two columnar regions. <inline-formula><alternatives><mml:math id="inf125"><mml:mrow><mml:mi>d</mml:mi><mml:mi>i</mml:mi><mml:mi>r</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>c</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>i</mml:mi><mml:mn>0</mml:mn></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math><tex-math id="inft125">\begin{document}$dir\left (c_{i},t_{i,i0}\right)$\end{document}</tex-math></alternatives></inline-formula> represents the line from point <inline-formula><alternatives><mml:math id="inf126"><mml:mrow><mml:msub><mml:mi>c</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:math><tex-math id="inft126">\begin{document}$c_{i}$\end{document}</tex-math></alternatives></inline-formula> to <inline-formula><alternatives><mml:math id="inf127"><mml:mrow><mml:msub><mml:mi>t</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>i</mml:mi><mml:mn>0</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:math><tex-math id="inft127">\begin{document}$t_{i,i0}$\end{document}</tex-math></alternatives></inline-formula>. <inline-formula><alternatives><mml:math id="inf128"><mml:mrow><mml:mrow><mml:mo>〈</mml:mo> <mml:mrow><mml:mi>d</mml:mi><mml:mi>i</mml:mi><mml:mi>r</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>c</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>i</mml:mi><mml:mn>0</mml:mn></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:mo>,</mml:mo><mml:mi>d</mml:mi><mml:mi>i</mml:mi><mml:mi>r</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>c</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mrow><mml:mi>j</mml:mi><mml:mo>,</mml:mo><mml:mi>j</mml:mi><mml:mn>0</mml:mn></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow> <mml:mo>〉</mml:mo></mml:mrow></mml:mrow></mml:math><tex-math id="inft128">\begin{document}$\left \langle dir\left (c_{i},t_{i,i0}\right),dir\left (c_{i},t_{j,j0}\right)\right \rangle $\end{document}</tex-math></alternatives></inline-formula> represents cosine angle between the two lines. The threshold of 100 in D in <xref ref-type="disp-formula" rid="equ46">Equation 46</xref> and <xref ref-type="disp-formula" rid="equ47">Equation 47</xref> is an experimental value designed to ensure that the terminal points of neurites do not connect to more than one other terminal point.</p><p>After setting the cost matrix, the 0–1 assignment problem is defined as follows:<disp-formula id="equ49"><label>(49)</label><alternatives><mml:math id="m49"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>A</mml:mi><mml:mo>=</mml:mo><mml:msub><mml:mrow><mml:mi mathvariant="normal">a</mml:mi><mml:mi mathvariant="normal">r</mml:mi><mml:mi mathvariant="normal">g</mml:mi><mml:mspace width="thinmathspace"/><mml:mi mathvariant="normal">m</mml:mi><mml:mi mathvariant="normal">i</mml:mi><mml:mi mathvariant="normal">n</mml:mi></mml:mrow><mml:mrow><mml:mi>A</mml:mi></mml:mrow></mml:msub><mml:munderover><mml:mo>∑</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mn>4</mml:mn><mml:mi>n</mml:mi></mml:mrow></mml:munderover><mml:munderover><mml:mo>∑</mml:mo><mml:mrow><mml:mi>j</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mn>4</mml:mn><mml:mi>n</mml:mi></mml:mrow></mml:munderover><mml:msub><mml:mi>A</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:msub><mml:mi>C</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:mstyle></mml:mrow></mml:mstyle></mml:math><tex-math id="t49">\begin{document}$$\displaystyle  A=\mathrm{arg \, min}_{A}\sum _{i=1}^{4n}\sum _{j=1}^{4n}A_{ij}C_{ij}$$\end{document}</tex-math></alternatives></disp-formula><disp-formula id="equ50"><label>(50)</label><alternatives><mml:math id="m50"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>s</mml:mi><mml:mo>.</mml:mo><mml:mi>t</mml:mi><mml:mo>.</mml:mo><mml:munderover><mml:mo>∑</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mn>4</mml:mn><mml:mi>n</mml:mi></mml:mrow></mml:munderover><mml:msub><mml:mi>A</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mn>1</mml:mn><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>j</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mn>2</mml:mn><mml:mo>,</mml:mo><mml:mo>⋯</mml:mo><mml:mo>,</mml:mo><mml:mn>4</mml:mn><mml:mi>n</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mstyle></mml:mrow></mml:mstyle></mml:math><tex-math id="t50">\begin{document}$$\displaystyle  s.t.\sum _{i=1}^{4n}A_{i,j}=1\left (j=1,2,\cdots ,4n\right)$$\end{document}</tex-math></alternatives></disp-formula><disp-formula id="equ51"><label>(51)</label><alternatives><mml:math id="m51"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mstyle displaystyle="true" scriptlevel="0"><mml:munderover><mml:mo>∑</mml:mo><mml:mrow><mml:mi>j</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mn>4</mml:mn><mml:mi>n</mml:mi></mml:mrow></mml:munderover><mml:msub><mml:mi>A</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mn>1</mml:mn><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mn>2</mml:mn><mml:mo>,</mml:mo><mml:mo>⋯</mml:mo><mml:mo>,</mml:mo><mml:mn>4</mml:mn><mml:mi>n</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mstyle></mml:mrow></mml:mstyle></mml:math><tex-math id="t51">\begin{document}$$\displaystyle  \sum _{j=1}^{4n}A_{i,j}=1\left (i=1,2,\cdots ,4n\right)$$\end{document}</tex-math></alternatives></disp-formula></p><p>Here, <inline-formula><alternatives><mml:math id="inf129"><mml:mi>A</mml:mi></mml:math><tex-math id="inft129">\begin{document}$A$\end{document}</tex-math></alternatives></inline-formula> represents the connectivity matrix between different terminals of columnar regions: if <inline-formula><alternatives><mml:math id="inf130"><mml:mrow><mml:msub><mml:mi>A</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:math><tex-math id="inft130">\begin{document}$A_{i,j}=1$\end{document}</tex-math></alternatives></inline-formula>, then establish connection between terminal <inline-formula><alternatives><mml:math id="inf131"><mml:mi>i</mml:mi></mml:math><tex-math id="inft131">\begin{document}$i$\end{document}</tex-math></alternatives></inline-formula> and terminal <inline-formula><alternatives><mml:math id="inf132"><mml:mi>j</mml:mi></mml:math><tex-math id="inft132">\begin{document}$j$\end{document}</tex-math></alternatives></inline-formula>, if <inline-formula><alternatives><mml:math id="inf133"><mml:mrow><mml:msub><mml:mi>A</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:math><tex-math id="inft133">\begin{document}$A_{i,j}=0$\end{document}</tex-math></alternatives></inline-formula>, then establish no connection between terminal <inline-formula><alternatives><mml:math id="inf134"><mml:mi>i</mml:mi></mml:math><tex-math id="inft134">\begin{document}$i$\end{document}</tex-math></alternatives></inline-formula> and terminal <inline-formula><alternatives><mml:math id="inf135"><mml:mi>j</mml:mi></mml:math><tex-math id="inft135">\begin{document}$j$\end{document}</tex-math></alternatives></inline-formula>.<inline-formula><alternatives><mml:math id="inf136"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:munderover><mml:mo>∑</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mn>4</mml:mn><mml:mi>n</mml:mi></mml:mrow></mml:munderover><mml:msub><mml:mi>A</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mn>1</mml:mn><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>j</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mn>2</mml:mn><mml:mo>,</mml:mo><mml:mo>⋯</mml:mo><mml:mo>,</mml:mo><mml:mn>4</mml:mn><mml:mi>n</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mstyle></mml:math><tex-math id="inft136">\begin{document}$\sum _{i=1}^{4n}A_{i,j}=1\left (j=1,2,\cdots ,4n\right)$\end{document}</tex-math></alternatives></inline-formula> and <inline-formula><alternatives><mml:math id="inf137"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:munderover><mml:mo>∑</mml:mo><mml:mrow><mml:mi>j</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mn>4</mml:mn><mml:mi>n</mml:mi></mml:mrow></mml:munderover><mml:msub><mml:mi>A</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mn>1</mml:mn><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mn>2</mml:mn><mml:mo>,</mml:mo><mml:mo>⋯</mml:mo><mml:mo>,</mml:mo><mml:mn>4</mml:mn><mml:mi>n</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mstyle></mml:math><tex-math id="inft137">\begin{document}$\sum _{j=1}^{4n}A_{i,j}=1\left (i=1,2,\cdots ,4n\right)$\end{document}</tex-math></alternatives></inline-formula> restrain each terminal from establishing connection with at most one other terminal. The Lapjv algorithm (<xref ref-type="bibr" rid="bib41">Volgenant, 1996</xref>) is utilized to solve this optimization problem and the shapes of individual neurites in block images are formed. Furthermore, we employ the region growing method to generate skeletons from the reconstructed shape, achieving the neurites reconstruction from individual image blocks.</p></sec><sec id="s4-7"><title>Minimal information flow tree for revising the reconstruction</title><p>The minimal information flow tree model is designed to modify the topology of skeletons, eliminate incorrect connections, and decompose them into multiple branches. When given an input skeleton file such as the swc file (<xref ref-type="bibr" rid="bib3">Cannon et al., 1998</xref>), we convert it into a binary tree structure with the following steps.</p><sec id="s4-7-1"><title>Step 1</title><p>select the neurite skeleton <inline-formula><alternatives><mml:math id="inf138"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>S</mml:mi><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math><tex-math id="inft138">\begin{document}$S_{1}$\end{document}</tex-math></alternatives></inline-formula>. <inline-formula><alternatives><mml:math id="inf139"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>S</mml:mi><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math><tex-math id="inft139">\begin{document}$S_{1}$\end{document}</tex-math></alternatives></inline-formula> has the largest length in the neurite skeletons that connect with each other. One of its terminal nodes is recorded as the head node <inline-formula><alternatives><mml:math id="inf140"><mml:mrow><mml:msub><mml:mi>n</mml:mi><mml:mn>1</mml:mn></mml:msub></mml:mrow></mml:math><tex-math id="inft140">\begin{document}$n_{1}$\end{document}</tex-math></alternatives></inline-formula>.</p></sec><sec id="s4-7-2"><title>Step 2</title><p>generate the initial tree structure. Starting at head node <inline-formula><alternatives><mml:math id="inf141"><mml:mrow><mml:msub><mml:mi>n</mml:mi><mml:mn>1</mml:mn></mml:msub></mml:mrow></mml:math><tex-math id="inft141">\begin{document}$n_{1}$\end{document}</tex-math></alternatives></inline-formula>, search the linking nodes along the skeleton <inline-formula><alternatives><mml:math id="inf142"><mml:mrow><mml:msub><mml:mi>S</mml:mi><mml:mn>1</mml:mn></mml:msub></mml:mrow></mml:math><tex-math id="inft142">\begin{document}$S_{1}$\end{document}</tex-math></alternatives></inline-formula>, denoted by <inline-formula><alternatives><mml:math id="inf143"><mml:mrow><mml:msubsup><mml:mi>n</mml:mi><mml:mn>1</mml:mn><mml:mrow><mml:msub><mml:mi>s</mml:mi><mml:mn>1</mml:mn></mml:msub></mml:mrow></mml:msubsup><mml:mo>,</mml:mo><mml:msubsup><mml:mi>n</mml:mi><mml:mn>2</mml:mn><mml:mrow><mml:msub><mml:mi>s</mml:mi><mml:mn>1</mml:mn></mml:msub></mml:mrow></mml:msubsup><mml:mo>,</mml:mo><mml:mo>⋯</mml:mo><mml:mo>,</mml:mo><mml:msubsup><mml:mi>n</mml:mi><mml:mrow><mml:msub><mml:mi>k</mml:mi><mml:mn>1</mml:mn></mml:msub></mml:mrow><mml:mrow><mml:msub><mml:mi>s</mml:mi><mml:mn>1</mml:mn></mml:msub></mml:mrow></mml:msubsup></mml:mrow></mml:math><tex-math id="inft143">\begin{document}$n_{1}^{s_{1}},n_{2}^{s_{1}},\cdots ,n_{k_{1}}^{s_{1}}$\end{document}</tex-math></alternatives></inline-formula>. The topology structure is <inline-formula><alternatives><mml:math id="inf144"><mml:mrow><mml:msub><mml:mi>n</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>→</mml:mo><mml:mi>l</mml:mi><mml:mi>e</mml:mi><mml:mi>f</mml:mi><mml:mi>t</mml:mi><mml:mi>n</mml:mi><mml:mi>o</mml:mi><mml:mi>d</mml:mi><mml:mi>e</mml:mi><mml:mo>=</mml:mo><mml:msubsup><mml:mi>n</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:msub><mml:mi>s</mml:mi><mml:mn>1</mml:mn></mml:msub></mml:mrow></mml:msubsup></mml:mrow></mml:math><tex-math id="inft144">\begin{document}$n_{i}\rightarrow leftnode=n_{i+1}^{s_{1}}$\end{document}</tex-math></alternatives></inline-formula>.</p></sec><sec id="s4-7-3"><title>Step 3</title><p>generate new structure induced by the linking node <inline-formula><alternatives><mml:math id="inf145"><mml:msubsup><mml:mrow><mml:mi>n</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>s</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:msubsup></mml:math><tex-math id="inft145">\begin{document}$n_{1}^{s_{1}}$\end{document}</tex-math></alternatives></inline-formula>. <inline-formula><alternatives><mml:math id="inf146"><mml:msubsup><mml:mrow><mml:mi>n</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>s</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:msubsup></mml:math><tex-math id="inft146">\begin{document}$n_{1}^{s_{1}}$\end{document}</tex-math></alternatives></inline-formula> is regarded as the head node and its corresponding neurite skeleton is denoted by <inline-formula><alternatives><mml:math id="inf147"><mml:mrow><mml:msub><mml:mi>S</mml:mi><mml:mn>2</mml:mn></mml:msub></mml:mrow></mml:math><tex-math id="inft147">\begin{document}$S_{2}$\end{document}</tex-math></alternatives></inline-formula>. Let <inline-formula><alternatives><mml:math id="inf148"><mml:msubsup><mml:mrow><mml:mi>n</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>s</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:msubsup><mml:mo>,</mml:mo><mml:msubsup><mml:mrow><mml:mi>n</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>s</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:msubsup><mml:mo>,</mml:mo><mml:mo>⋯</mml:mo><mml:mo>,</mml:mo><mml:msubsup><mml:mrow><mml:mi>n</mml:mi></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>k</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>s</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:msubsup></mml:math><tex-math id="inft148">\begin{document}$n_{1}^{s_{2}},n_{2}^{s_{2}},\cdots ,n_{k_{2}}^{s_{2}}$\end{document}</tex-math></alternatives></inline-formula> represent the linking nodes in skeleton <inline-formula><alternatives><mml:math id="inf149"><mml:mrow><mml:msub><mml:mi>S</mml:mi><mml:mn>2</mml:mn></mml:msub></mml:mrow></mml:math><tex-math id="inft149">\begin{document}$S_{2}$\end{document}</tex-math></alternatives></inline-formula>. The corresponding topology structure is <inline-formula><alternatives><mml:math id="inf150"><mml:mrow><mml:msubsup><mml:mi>n</mml:mi><mml:mn>1</mml:mn><mml:mrow><mml:msub><mml:mi>s</mml:mi><mml:mn>1</mml:mn></mml:msub></mml:mrow></mml:msubsup><mml:mo>→</mml:mo><mml:mi>r</mml:mi><mml:mi>i</mml:mi><mml:mi>g</mml:mi><mml:mi>h</mml:mi><mml:mi>t</mml:mi><mml:mi>n</mml:mi><mml:mi>o</mml:mi><mml:mi>d</mml:mi><mml:mi>e</mml:mi><mml:mo>=</mml:mo><mml:msubsup><mml:mi>n</mml:mi><mml:mn>1</mml:mn><mml:mrow><mml:msub><mml:mi>s</mml:mi><mml:mn>2</mml:mn></mml:msub></mml:mrow></mml:msubsup></mml:mrow></mml:math><tex-math id="inft150">\begin{document}$n_{1}^{s_{1}}\rightarrow rightnode=n_{1}^{s_{2}}$\end{document}</tex-math></alternatives></inline-formula>, <inline-formula><alternatives><mml:math id="inf151"><mml:mrow><mml:msubsup><mml:mi>n</mml:mi><mml:mi>i</mml:mi><mml:mrow><mml:msub><mml:mi>s</mml:mi><mml:mn>2</mml:mn></mml:msub></mml:mrow></mml:msubsup><mml:mo>→</mml:mo><mml:mi>l</mml:mi><mml:mi>e</mml:mi><mml:mi>f</mml:mi><mml:mi>t</mml:mi><mml:mi>n</mml:mi><mml:mi>o</mml:mi><mml:mi>d</mml:mi><mml:mi>e</mml:mi><mml:mo>=</mml:mo><mml:msubsup><mml:mi>n</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:msub><mml:mi>s</mml:mi><mml:mn>2</mml:mn></mml:msub></mml:mrow></mml:msubsup></mml:mrow></mml:math><tex-math id="inft151">\begin{document}$n_{i}^{s_{2}}\rightarrow leftnode=n_{i+1}^{s_{2}}$\end{document}</tex-math></alternatives></inline-formula>.</p></sec><sec id="s4-7-4"><title>Step 4</title><p>repeat the operation in <bold>Step 3</bold> for dealing with the linking nodes <inline-formula><alternatives><mml:math id="inf152"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msubsup><mml:mi>n</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow><mml:mrow><mml:msub><mml:mi>s</mml:mi><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:msubsup><mml:mo>,</mml:mo><mml:mo>⋯</mml:mo><mml:mo>,</mml:mo><mml:msubsup><mml:mi>n</mml:mi><mml:mrow><mml:msub><mml:mi>k</mml:mi><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:msub><mml:mi>s</mml:mi><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:msubsup></mml:mrow></mml:mstyle></mml:math><tex-math id="inft152">\begin{document}$n_{2}^{s_{1}},\cdots,n_{k_{1}}^{s_{1}}$\end{document}</tex-math></alternatives></inline-formula>. The corresponding topology structures are added into the total tree structure. After obtaining the tree structures induced by linking nodes in <inline-formula><alternatives><mml:math id="inf153"><mml:mrow><mml:msub><mml:mi>S</mml:mi><mml:mn>1</mml:mn></mml:msub></mml:mrow></mml:math><tex-math id="inft153">\begin{document}$S_{1}$\end{document}</tex-math></alternatives></inline-formula>, use the operation in <bold>Step 3</bold> to generate the tree structures induced by linking nodes in <inline-formula><alternatives><mml:math id="inf154"><mml:mrow><mml:msub><mml:mi>S</mml:mi><mml:mn>2</mml:mn></mml:msub></mml:mrow></mml:math><tex-math id="inft154">\begin{document}$S_{2}$\end{document}</tex-math></alternatives></inline-formula>. Continue in this manner until all linking nodes have been processed.</p><p>To gain a better understanding of the above process, we have provided a demonstration of how to generate the corresponding binary tree from the skeletons of neurites (<xref ref-type="fig" rid="fig1s4">Figure 1—figure supplement 4</xref>).</p><p>For the skeletons of neurites in an image block, the corresponding number of binary tree structures will be generated. We use the MIFT model to merge or split these binary structures. Suppose that an image stack contains <inline-formula><alternatives><mml:math id="inf155"><mml:mi>m</mml:mi></mml:math><tex-math id="inft155">\begin{document}$m$\end{document}</tex-math></alternatives></inline-formula> skeletons all of which have <italic>K</italic> nodes, denoted by <inline-formula><alternatives><mml:math id="inf156"><mml:msub><mml:mrow><mml:mi>n</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:mo>⋯</mml:mo><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>n</mml:mi></mml:mrow><mml:mrow><mml:mi>K</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>n</mml:mi></mml:mrow><mml:mrow><mml:mi>K</mml:mi></mml:mrow></mml:msub></mml:math><tex-math id="inft156">\begin{document}$n_{1},\cdots ,n_{K- 1},n_{K}$\end{document}</tex-math></alternatives></inline-formula>. The connections among these nodes are stored in a matrix <inline-formula><alternatives><mml:math id="inf157"><mml:mi>W</mml:mi></mml:math><tex-math id="inft157">\begin{document}$W$\end{document}</tex-math></alternatives></inline-formula> with <inline-formula><alternatives><mml:math id="inf158"><mml:mi>K</mml:mi><mml:mo>×</mml:mo><mml:mi>K</mml:mi></mml:math><tex-math id="inft158">\begin{document}$K\times K$\end{document}</tex-math></alternatives></inline-formula> elements. <inline-formula><alternatives><mml:math id="inf159"><mml:mrow><mml:msub><mml:mi>W</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:math><tex-math id="inft159">\begin{document}$W_{i,j}=0$\end{document}</tex-math></alternatives></inline-formula> indicates that there is no connection between node <inline-formula><alternatives><mml:math id="inf160"><mml:mi>i</mml:mi></mml:math><tex-math id="inft160">\begin{document}$i$\end{document}</tex-math></alternatives></inline-formula> and node <inline-formula><alternatives><mml:math id="inf161"><mml:mi>j</mml:mi></mml:math><tex-math id="inft161">\begin{document}$j$\end{document}</tex-math></alternatives></inline-formula>. <inline-formula><alternatives><mml:math id="inf162"><mml:mrow><mml:msub><mml:mi>W</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:math><tex-math id="inft162">\begin{document}$W_{i,j}=- 1$\end{document}</tex-math></alternatives></inline-formula> indicates that <inline-formula><alternatives><mml:math id="inf163"><mml:mrow><mml:mi>j</mml:mi><mml:mo>→</mml:mo><mml:mi>h</mml:mi><mml:mi>e</mml:mi><mml:mi>a</mml:mi><mml:mi>d</mml:mi><mml:mi>n</mml:mi><mml:mi>o</mml:mi><mml:mi>d</mml:mi><mml:mi>e</mml:mi><mml:mo>=</mml:mo><mml:mi>i</mml:mi></mml:mrow></mml:math><tex-math id="inft163">\begin{document}$j\rightarrow headnode=i$\end{document}</tex-math></alternatives></inline-formula>, <inline-formula><alternatives><mml:math id="inf164"><mml:mrow><mml:msub><mml:mi>W</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mo>−</mml:mo><mml:mn>2</mml:mn></mml:mrow></mml:math><tex-math id="inft164">\begin{document}$W_{i,j}=- 2$\end{document}</tex-math></alternatives></inline-formula> indicates that <inline-formula><alternatives><mml:math id="inf165"><mml:mrow><mml:mi>j</mml:mi><mml:mo>→</mml:mo><mml:mi>l</mml:mi><mml:mi>e</mml:mi><mml:mi>f</mml:mi><mml:mi>t</mml:mi><mml:mi>n</mml:mi><mml:mi>o</mml:mi><mml:mi>d</mml:mi><mml:mi>e</mml:mi><mml:mo>=</mml:mo><mml:mi>i</mml:mi></mml:mrow></mml:math><tex-math id="inft165">\begin{document}$j\rightarrow leftnode=i$\end{document}</tex-math></alternatives></inline-formula>, <inline-formula><alternatives><mml:math id="inf166"><mml:mrow><mml:msub><mml:mi>W</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mo>−</mml:mo><mml:mn>3</mml:mn></mml:mrow></mml:math><tex-math id="inft166">\begin{document}$W_{i,j}=- 3$\end{document}</tex-math></alternatives></inline-formula> indicates that <inline-formula><alternatives><mml:math id="inf167"><mml:mrow><mml:mi>j</mml:mi><mml:mo>→</mml:mo><mml:mi>r</mml:mi><mml:mi>i</mml:mi><mml:mi>g</mml:mi><mml:mi>h</mml:mi><mml:mi>t</mml:mi><mml:mi>n</mml:mi><mml:mi>o</mml:mi><mml:mi>d</mml:mi><mml:mi>e</mml:mi><mml:mo>=</mml:mo><mml:mi>i</mml:mi></mml:mrow></mml:math><tex-math id="inft167">\begin{document}$j\rightarrow rightnode=i$\end{document}</tex-math></alternatives></inline-formula>.</p><p>The information flow can be computed as follows:<disp-formula id="equ52"><label>(52)</label><alternatives><mml:math id="m52"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msup><mml:mi>W</mml:mi><mml:mrow><mml:mo>∗</mml:mo></mml:mrow></mml:msup><mml:mo>=</mml:mo><mml:msub><mml:mrow><mml:mi mathvariant="normal">a</mml:mi><mml:mi mathvariant="normal">r</mml:mi><mml:mi mathvariant="normal">g</mml:mi><mml:mspace width="thinmathspace"/><mml:mi mathvariant="normal">m</mml:mi><mml:mi mathvariant="normal">i</mml:mi><mml:mi mathvariant="normal">n</mml:mi></mml:mrow><mml:mrow><mml:mi>W</mml:mi></mml:mrow></mml:msub><mml:munderover><mml:mo movablelimits="false">∑</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>K</mml:mi></mml:mrow></mml:munderover><mml:mi>f</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>W</mml:mi><mml:mo>,</mml:mo><mml:msub><mml:mi>n</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mstyle></mml:mrow></mml:mstyle></mml:math><tex-math id="t52">\begin{document}$$\displaystyle  W^{*}=\mathrm{arg \,min}_{W}\sum \limits_{i=1}^{K}f\left (W,n_{i}\right)$$\end{document}</tex-math></alternatives></disp-formula><disp-formula id="equ53"><label>(53)</label><alternatives><mml:math id="m53"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>f</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>W</mml:mi><mml:mo>,</mml:mo><mml:msub><mml:mi>n</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mi>c</mml:mi><mml:mi>o</mml:mi><mml:mi>s</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>θ</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>n</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">→</mml:mo><mml:mi>h</mml:mi><mml:mi>e</mml:mi><mml:mi>a</mml:mi><mml:mi>d</mml:mi><mml:mi>n</mml:mi><mml:mi>o</mml:mi><mml:mi>d</mml:mi><mml:mi>e</mml:mi><mml:mo>,</mml:mo><mml:msub><mml:mi>n</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>n</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">→</mml:mo><mml:mi>l</mml:mi><mml:mi>e</mml:mi><mml:mi>f</mml:mi><mml:mi>t</mml:mi><mml:mi>n</mml:mi><mml:mi>o</mml:mi><mml:mi>d</mml:mi><mml:mi>e</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mstyle></mml:mrow></mml:mstyle></mml:math><tex-math id="t53">\begin{document}$$\displaystyle  f\left (W,n_{i}\right)=cos\left (\theta \left (n_{i}\rightarrow headnode,n_{i},n_{i}\rightarrow leftnode\right)\right)$$\end{document}</tex-math></alternatives></disp-formula></p><p>Here, the optimization objective function in <xref ref-type="disp-formula" rid="equ53">Equation 53</xref> is called information flow. <inline-formula><alternatives><mml:math id="inf168"><mml:mrow><mml:mi>θ</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mo>⋅</mml:mo><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math><tex-math id="inft168">\begin{document}$\theta \left (\cdot \right)$\end{document}</tex-math></alternatives></inline-formula> is the angle between flow from <inline-formula><alternatives><mml:math id="inf169"><mml:mrow><mml:msub><mml:mi>n</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>→</mml:mo><mml:mi>h</mml:mi><mml:mi>e</mml:mi><mml:mi>a</mml:mi><mml:mi>d</mml:mi><mml:mi>n</mml:mi><mml:mi>o</mml:mi><mml:mi>d</mml:mi><mml:mi>e</mml:mi></mml:mrow></mml:math><tex-math id="inft169">\begin{document}$n_{i}\rightarrow headnode$\end{document}</tex-math></alternatives></inline-formula> to <inline-formula><alternatives><mml:math id="inf170"><mml:mrow><mml:msub><mml:mi>n</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:math><tex-math id="inft170">\begin{document}$n_{i}$\end{document}</tex-math></alternatives></inline-formula> and flow from <inline-formula><alternatives><mml:math id="inf171"><mml:mrow><mml:msub><mml:mi>n</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:math><tex-math id="inft171">\begin{document}$n_{i}$\end{document}</tex-math></alternatives></inline-formula> to <inline-formula><alternatives><mml:math id="inf172"><mml:mrow><mml:msub><mml:mi>n</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>→</mml:mo><mml:mi>l</mml:mi><mml:mi>e</mml:mi><mml:mi>f</mml:mi><mml:mi>t</mml:mi><mml:mi>n</mml:mi><mml:mi>o</mml:mi><mml:mi>d</mml:mi><mml:mi>e</mml:mi></mml:mrow></mml:math><tex-math id="inft172">\begin{document}$n_{i}\rightarrow leftnode$\end{document}</tex-math></alternatives></inline-formula>. To minimize the optimization problem while ensuring that the topology matrix <inline-formula><alternatives><mml:math id="inf173"><mml:mi>W</mml:mi></mml:math><tex-math id="inft173">\begin{document}$W$\end{document}</tex-math></alternatives></inline-formula> does not exhibit abnormal values, we adopt the strategy of dynamic programming to update the topology matrix <inline-formula><alternatives><mml:math id="inf174"><mml:mi>W</mml:mi></mml:math><tex-math id="inft174">\begin{document}$W$\end{document}</tex-math></alternatives></inline-formula>. Briefly, we calculate the other two possible angles <inline-formula><alternatives><mml:math id="inf175"><mml:mrow><mml:mi>θ</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>n</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>→</mml:mo><mml:mi>h</mml:mi><mml:mi>e</mml:mi><mml:mi>a</mml:mi><mml:mi>d</mml:mi><mml:mi>n</mml:mi><mml:mi>o</mml:mi><mml:mi>d</mml:mi><mml:mi>e</mml:mi><mml:mo>,</mml:mo><mml:msub><mml:mi>n</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>n</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>→</mml:mo><mml:mi>r</mml:mi><mml:mi>i</mml:mi><mml:mi>g</mml:mi><mml:mi>h</mml:mi><mml:mi>t</mml:mi><mml:mi>n</mml:mi><mml:mi>o</mml:mi><mml:mi>d</mml:mi><mml:mi>e</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math><tex-math id="inft175">\begin{document}$\theta \left (n_{i}\rightarrow headnode,n_{i},n_{i}\rightarrow rightnode\right)$\end{document}</tex-math></alternatives></inline-formula> and <inline-formula><alternatives><mml:math id="inf176"><mml:mrow><mml:mi>θ</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>n</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>→</mml:mo><mml:mi>l</mml:mi><mml:mi>e</mml:mi><mml:mi>f</mml:mi><mml:mi>t</mml:mi><mml:mi>n</mml:mi><mml:mi>o</mml:mi><mml:mi>d</mml:mi><mml:mi>e</mml:mi><mml:mo>,</mml:mo><mml:msub><mml:mi>n</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>n</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>→</mml:mo><mml:mi>r</mml:mi><mml:mi>i</mml:mi><mml:mi>g</mml:mi><mml:mi>h</mml:mi><mml:mi>t</mml:mi><mml:mi>n</mml:mi><mml:mi>o</mml:mi><mml:mi>d</mml:mi><mml:mi>e</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math><tex-math id="inft176">\begin{document}$\theta \left (n_{i}\rightarrow leftnode,n_{i},n_{i}\rightarrow rightnode\right)$\end{document}</tex-math></alternatives></inline-formula> at the first linking node <inline-formula><alternatives><mml:math id="inf177"><mml:mrow><mml:msub><mml:mi>n</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:math><tex-math id="inft177">\begin{document}$n_{i}$\end{document}</tex-math></alternatives></inline-formula>. The minimum information flow is selected, and <inline-formula><alternatives><mml:math id="inf178"><mml:mi>W</mml:mi></mml:math><tex-math id="inft178">\begin{document}$W$\end{document}</tex-math></alternatives></inline-formula> is updated. Following the updated <inline-formula><alternatives><mml:math id="inf179"><mml:mi>W</mml:mi></mml:math><tex-math id="inft179">\begin{document}$W$\end{document}</tex-math></alternatives></inline-formula>, the next branching node is found and information flow and <inline-formula><alternatives><mml:math id="inf180"><mml:mi>W</mml:mi></mml:math><tex-math id="inft180">\begin{document}$W$\end{document}</tex-math></alternatives></inline-formula> is updated. The updating process iterates until all nodes are updated. The final root nodes <inline-formula><alternatives><mml:math id="inf181"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mrow><mml:mo>{</mml:mo><mml:mrow><mml:msub><mml:mi>r</mml:mi><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>r</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:mo>.</mml:mo><mml:mo>.</mml:mo><mml:mo>.</mml:mo><mml:mo>,</mml:mo><mml:msub><mml:mi>r</mml:mi><mml:mrow><mml:mi>m</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>}</mml:mo></mml:mrow></mml:mrow></mml:mstyle></mml:math><tex-math id="inft181">\begin{document}$\left \{r_{1},r_{2},...,r_{m}\right \}$\end{document}</tex-math></alternatives></inline-formula> are obtained (node satisfies <inline-formula><alternatives><mml:math id="inf182"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>W</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>r</mml:mi><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:mi>i</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mn>0</mml:mn><mml:mspace width="thinmathspace"/><mml:mspace width="thinmathspace"/><mml:mrow><mml:mi mathvariant="normal">o</mml:mi><mml:mi mathvariant="normal">r</mml:mi></mml:mrow><mml:mspace width="thinmathspace"/><mml:mspace width="thinmathspace"/><mml:mo>−</mml:mo><mml:mn>1</mml:mn><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mo>.</mml:mo><mml:mo>.</mml:mo><mml:mo>.</mml:mo><mml:mi>n</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mstyle></mml:math><tex-math id="inft182">\begin{document}$W\left (r_{t}, i\right)=0\,\, \mathrm{or}\,\, - 1\left (i=1,...n\right)$\end{document}</tex-math></alternatives></inline-formula> is set root node). The pseudo-code for solving the optimization problem is provided below:</p><table-wrap id="inlinetable3" position="anchor"><table frame="hsides" rules="groups" id="AL3"><thead><tr><th align="left" valign="bottom">Algorithm 3. Generation of Minimal Information Flow Tree.</th></tr></thead><tbody><tr><td align="left" valign="bottom"># Graph defines tree topology of the nodes, t_node-&gt;left represents the left child node of t_node, t_node-&gt;right represents the right child node of t_node, t_node-&gt;head represents the head node of t_node.<break/><bold>Input</bold>: <italic>N</italic>: <inline-formula><alternatives><mml:math id="inf183"><mml:mrow><mml:mo>{</mml:mo><mml:msub><mml:mi>N</mml:mi><mml:mn>0</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>N</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:mn>...</mml:mn><mml:mo>,</mml:mo><mml:msub><mml:mi>N</mml:mi><mml:mi>k</mml:mi></mml:msub><mml:mo>}</mml:mo></mml:mrow></mml:math><tex-math id="inft183">\begin{document}$\left \{N_{0},N_{1},...,N_{k}\right \}$\end{document}</tex-math></alternatives></inline-formula>, Graph head: <inline-formula><alternatives><mml:math id="inf184"><mml:mrow><mml:mo>{</mml:mo><mml:msub><mml:mi>N</mml:mi><mml:mn>0</mml:mn></mml:msub><mml:mo>}</mml:mo></mml:mrow></mml:math><tex-math id="inft184">\begin{document}$\left \{N_{0}\right \}$\end{document}</tex-math></alternatives></inline-formula><break/>    <inline-formula><alternatives><mml:math id="inf185"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>S</mml:mi><mml:mi>e</mml:mi><mml:mi>t</mml:mi><mml:mo>=</mml:mo><mml:mrow><mml:mo>{</mml:mo><mml:msub><mml:mi>N</mml:mi><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msub><mml:mo>}</mml:mo></mml:mrow></mml:mrow></mml:mstyle></mml:math><tex-math id="inft185">\begin{document}$Set=\left \{N_{0}\right \}$\end{document}</tex-math></alternatives></inline-formula><break/>    While <inline-formula><alternatives><mml:math id="inf186"><mml:mrow><mml:mo>|</mml:mo><mml:mi>S</mml:mi><mml:mi>e</mml:mi><mml:mi>t</mml:mi><mml:mo>|</mml:mo><mml:mo>&gt;</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:math><tex-math id="inft186">\begin{document}$|Set| \gt 0$\end{document}</tex-math></alternatives></inline-formula>:<break/>      <inline-formula><alternatives><mml:math id="inf187"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>t</mml:mi><mml:mi mathvariant="normal">_</mml:mi><mml:mi>n</mml:mi><mml:mi>o</mml:mi><mml:mi>d</mml:mi><mml:mi>e</mml:mi><mml:mo>=</mml:mo><mml:mi>S</mml:mi><mml:mi>e</mml:mi><mml:mi>t</mml:mi><mml:mrow><mml:mo>[</mml:mo><mml:mn>0</mml:mn><mml:mo>]</mml:mo></mml:mrow></mml:mrow></mml:mstyle></mml:math><tex-math id="inft187">\begin{document}$t\_ node=Set\left [0\right ]$\end{document}</tex-math></alternatives></inline-formula><break/>      # calculate three possible information flow<break/>      <inline-formula><alternatives><mml:math id="inf188"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>r</mml:mi><mml:mi>e</mml:mi><mml:mi>s</mml:mi><mml:mo>=</mml:mo><mml:mi>c</mml:mi><mml:mi>a</mml:mi><mml:mi>l</mml:mi><mml:mi>c</mml:mi><mml:mi mathvariant="normal">_</mml:mi><mml:mi>t</mml:mi><mml:mi>h</mml:mi><mml:mi>r</mml:mi><mml:mi>e</mml:mi><mml:mi>e</mml:mi><mml:mi mathvariant="normal">_</mml:mi><mml:mi>d</mml:mi><mml:mi>i</mml:mi><mml:mi>r</mml:mi><mml:mi>e</mml:mi><mml:mi>c</mml:mi><mml:mi>t</mml:mi><mml:mi>i</mml:mi><mml:mi>o</mml:mi><mml:mi>n</mml:mi><mml:mi>s</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>t</mml:mi><mml:mi mathvariant="normal">_</mml:mi><mml:mi>n</mml:mi><mml:mi>o</mml:mi><mml:mi>d</mml:mi><mml:mi>e</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mstyle></mml:math><tex-math id="inft188">\begin{document}$res=calc\_ three\_ directions\left (t\_ node\right)$\end{document}</tex-math></alternatives></inline-formula><break/>      if <inline-formula><alternatives><mml:math id="inf189"><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>r</mml:mi><mml:mi>e</mml:mi><mml:mi>s</mml:mi><mml:mo>=</mml:mo><mml:mo>=</mml:mo><mml:mn>0</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math><tex-math id="inft189">\begin{document}$\left (res==0\right)$\end{document}</tex-math></alternatives></inline-formula>:<break/>      # maintain original structure.<break/>        <inline-formula><alternatives><mml:math id="inf190"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>S</mml:mi><mml:mi>e</mml:mi><mml:mi>t</mml:mi><mml:mrow><mml:mo>[</mml:mo><mml:mn>0</mml:mn><mml:mo>]</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mi>t</mml:mi><mml:mi mathvariant="normal">_</mml:mi><mml:mi>n</mml:mi><mml:mi>o</mml:mi><mml:mi>d</mml:mi><mml:mi>e</mml:mi><mml:mo>−</mml:mo><mml:mo>&gt;</mml:mo><mml:mi>l</mml:mi><mml:mi>e</mml:mi><mml:mi>f</mml:mi><mml:mi>t</mml:mi></mml:mrow></mml:mstyle></mml:math><tex-math id="inft190">\begin{document}$Set\left [0\right ]=t\_ node- \gt left$\end{document}</tex-math></alternatives></inline-formula><break/>       <inline-formula><alternatives><mml:math id="inf191"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>S</mml:mi><mml:mi>e</mml:mi><mml:mi>t</mml:mi><mml:mo>.</mml:mo><mml:mi>p</mml:mi><mml:mi>u</mml:mi><mml:mi>s</mml:mi><mml:mi>h</mml:mi><mml:mi mathvariant="normal">_</mml:mi><mml:mi>b</mml:mi><mml:mi>a</mml:mi><mml:mi>c</mml:mi><mml:mi>k</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>t</mml:mi><mml:mi mathvariant="normal">_</mml:mi><mml:mi>n</mml:mi><mml:mi>o</mml:mi><mml:mi>d</mml:mi><mml:mi>e</mml:mi><mml:mo>−</mml:mo><mml:mo>&gt;</mml:mo><mml:mi>r</mml:mi><mml:mi>i</mml:mi><mml:mi>g</mml:mi><mml:mi>h</mml:mi><mml:mi>t</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mstyle></mml:math><tex-math id="inft191">\begin{document}$Set.push\_ back\left (t\_ node- \gt right\right)$\end{document}</tex-math></alternatives></inline-formula><break/>      if <inline-formula><alternatives><mml:math id="inf192"><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>r</mml:mi><mml:mi>e</mml:mi><mml:mi>s</mml:mi><mml:mo>=</mml:mo><mml:mo>=</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math><tex-math id="inft192">\begin{document}$\left (res==1\right)$\end{document}</tex-math></alternatives></inline-formula>:<break/>      # change the position of t_node’s two child nodes.<break/>       <inline-formula><alternatives><mml:math id="inf193"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>E</mml:mi><mml:mi>x</mml:mi><mml:mi>c</mml:mi><mml:mi>h</mml:mi><mml:mi>a</mml:mi><mml:mi>n</mml:mi><mml:mi>g</mml:mi><mml:mi>e</mml:mi><mml:mi mathvariant="normal">_</mml:mi><mml:mi>c</mml:mi><mml:mi>h</mml:mi><mml:mi>i</mml:mi><mml:mi>l</mml:mi><mml:mi>d</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>t</mml:mi><mml:mi mathvariant="normal">_</mml:mi><mml:mi>n</mml:mi><mml:mi>o</mml:mi><mml:mi>d</mml:mi><mml:mi>e</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mstyle></mml:math><tex-math id="inft193">\begin{document}$Exchange\_ child\left (t\_ node\right)$\end{document}</tex-math></alternatives></inline-formula><break/>       <inline-formula><alternatives><mml:math id="inf194"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>S</mml:mi><mml:mi>e</mml:mi><mml:mi>t</mml:mi><mml:mrow><mml:mo>[</mml:mo><mml:mn>0</mml:mn><mml:mo>]</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mi>t</mml:mi><mml:mi mathvariant="normal">_</mml:mi><mml:mi>n</mml:mi><mml:mi>o</mml:mi><mml:mi>d</mml:mi><mml:mi>e</mml:mi><mml:mo>−</mml:mo><mml:mo>&gt;</mml:mo><mml:mi>l</mml:mi><mml:mi>e</mml:mi><mml:mi>f</mml:mi><mml:mi>t</mml:mi></mml:mrow></mml:mstyle></mml:math><tex-math id="inft194">\begin{document}$Set\left [0\right ]=t\_ node- \gt left$\end{document}</tex-math></alternatives></inline-formula><break/>       <inline-formula><alternatives><mml:math id="inf195"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>S</mml:mi><mml:mi>e</mml:mi><mml:mi>t</mml:mi><mml:mo>.</mml:mo><mml:mi>p</mml:mi><mml:mi>u</mml:mi><mml:mi>s</mml:mi><mml:mi>h</mml:mi><mml:mi mathvariant="normal">_</mml:mi><mml:mi>b</mml:mi><mml:mi>a</mml:mi><mml:mi>c</mml:mi><mml:mi>k</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>t</mml:mi><mml:mi mathvariant="normal">_</mml:mi><mml:mi>n</mml:mi><mml:mi>o</mml:mi><mml:mi>d</mml:mi><mml:mi>e</mml:mi><mml:mo>−</mml:mo><mml:mo>&gt;</mml:mo><mml:mi>r</mml:mi><mml:mi>i</mml:mi><mml:mi>g</mml:mi><mml:mi>h</mml:mi><mml:mi>t</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mstyle></mml:math><tex-math id="inft195">\begin{document}$Set.push\_ back\left (t\_ node- \gt right\right)$\end{document}</tex-math></alternatives></inline-formula><break/>      if <inline-formula><alternatives><mml:math id="inf196"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>r</mml:mi><mml:mi>e</mml:mi><mml:mi>s</mml:mi><mml:mo>==</mml:mo><mml:mn>2</mml:mn></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mstyle></mml:math><tex-math id="inft196">\begin{document}$\left (res==2\right)$\end{document}</tex-math></alternatives></inline-formula>:<break/>      # Information flows from t_node-&gt;left to t_node-&gt;right, update the structure along t_node-&gt;left and t_node-&gt;head, generate new head if possible.<break/>        <inline-formula><alternatives><mml:math id="inf197"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>N</mml:mi><mml:mi>e</mml:mi><mml:mi>w</mml:mi><mml:mi mathvariant="normal">_</mml:mi><mml:mi>n</mml:mi><mml:mi>o</mml:mi><mml:mi>d</mml:mi><mml:mi>e</mml:mi><mml:mo>=</mml:mo><mml:mi>R</mml:mi><mml:mi>e</mml:mi><mml:mi>v</mml:mi><mml:mi>e</mml:mi><mml:mi>r</mml:mi><mml:mi>s</mml:mi><mml:mi>e</mml:mi><mml:mi mathvariant="normal">_</mml:mi><mml:mi>h</mml:mi><mml:mi>e</mml:mi><mml:mi>a</mml:mi><mml:mi>d</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>t</mml:mi><mml:mi mathvariant="normal">_</mml:mi><mml:mi>n</mml:mi><mml:mi>o</mml:mi><mml:mi>d</mml:mi><mml:mi>e</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mstyle></mml:math><tex-math id="inft197">\begin{document}$New\_ node=Reverse\_ head\left (t\_ node\right)$\end{document}</tex-math></alternatives></inline-formula><break/>        <inline-formula><alternatives><mml:math id="inf198"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>S</mml:mi><mml:mi>e</mml:mi><mml:mi>t</mml:mi><mml:mrow><mml:mo>[</mml:mo><mml:mn>0</mml:mn><mml:mo>]</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mi>N</mml:mi><mml:mi>e</mml:mi><mml:mi>w</mml:mi><mml:mi mathvariant="normal">_</mml:mi><mml:mi>n</mml:mi><mml:mi>o</mml:mi><mml:mi>d</mml:mi><mml:mi>e</mml:mi></mml:mrow></mml:mstyle></mml:math><tex-math id="inft198">\begin{document}$Set\left [0\right ]=New\_ node$\end{document}</tex-math></alternatives></inline-formula><break/><bold>Output:</bold> <italic>N</italic>: <inline-formula><alternatives><mml:math id="inf199"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mrow><mml:mo>{</mml:mo><mml:mrow><mml:msub><mml:mi>N</mml:mi><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>N</mml:mi><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:mo>.</mml:mo><mml:mo>.</mml:mo><mml:mo>.</mml:mo><mml:mo>,</mml:mo><mml:msub><mml:mi>N</mml:mi><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>}</mml:mo></mml:mrow></mml:mrow></mml:mstyle></mml:math><tex-math id="inft199">\begin{document}$\left \{N_{0},N_{1},...,N_{k}\right \}$\end{document}</tex-math></alternatives></inline-formula>, Graph head: <inline-formula><alternatives><mml:math id="inf200"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mrow><mml:mo>{</mml:mo><mml:mrow><mml:msubsup><mml:mi>N</mml:mi><mml:mrow><mml:mn>0</mml:mn></mml:mrow><mml:mrow><mml:mo>′</mml:mo></mml:mrow></mml:msubsup><mml:mo>,</mml:mo><mml:msubsup><mml:mi>N</mml:mi><mml:mrow><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mo>′</mml:mo></mml:mrow></mml:msubsup><mml:mo>,</mml:mo><mml:mo>.</mml:mo><mml:mo>.</mml:mo><mml:mo>.</mml:mo><mml:mo>,</mml:mo><mml:msubsup><mml:mi>N</mml:mi><mml:mrow><mml:mi>m</mml:mi></mml:mrow><mml:mrow><mml:mo>′</mml:mo></mml:mrow></mml:msubsup></mml:mrow><mml:mo>}</mml:mo></mml:mrow></mml:mrow></mml:mstyle></mml:math><tex-math id="inft200">\begin{document}$\left \{N_{0}^{'},N_{1}^{'},...,N_{m}^{'}\right \}$\end{document}</tex-math></alternatives></inline-formula>.</td></tr></tbody></table></table-wrap><p>Please note that the model has the capability to merge binary trees. When two branches of neurites have identifiable root nodes, and one root node is in close proximity to the skeleton points on the other branch of neurites, the root node does not contribute to the calculation of information flow without fusion. However, after fusion, the root node becomes a linking node in the other branch of neurites, resulting in an additional negative information flow value. In this merging process, a threshold is required to be set. When the minimum distance between the root node of a branch of neurites and the skeleton point of the other branch of neurites is less than 8 for individual image blocks or less than 8,12,16 for fused image blocks respectively, these two branches are merged. When splitting a branch of neurites, the minimal information flow tree model is also applied to both individual and fused image blocks.</p></sec></sec><sec id="s4-8"><title>The fusion of neurites reconstruction</title><p>By using the MIFT model to revise the neurites reconstruction in individual image blocks, the root nodes and leaf nodes of a branch of neurites can be extracted directly. Here, we use a 0–1 assignment model to merge the reconstructions between two adjacent image blocks. For two adjacent image blocks <inline-formula><alternatives><mml:math id="inf201"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>P</mml:mi></mml:mrow></mml:mstyle></mml:math><tex-math id="inft201">\begin{document}$P$\end{document}</tex-math></alternatives></inline-formula> and <inline-formula><alternatives><mml:math id="inf202"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>Q</mml:mi></mml:mrow></mml:mstyle></mml:math><tex-math id="inft202">\begin{document}$Q$\end{document}</tex-math></alternatives></inline-formula>, the neurite skeleton nodes which locate near the common boundary are extracted as <inline-formula><alternatives><mml:math id="inf203"><mml:mrow><mml:mo>{</mml:mo><mml:msub><mml:mi>p</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>p</mml:mi><mml:mn>2</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:mn>...</mml:mn><mml:msub><mml:mi>p</mml:mi><mml:mi>m</mml:mi></mml:msub><mml:mo>}</mml:mo></mml:mrow></mml:math><tex-math id="inft203">\begin{document}$\left \{p_{1},p_{2},...p_{m}\right \}$\end{document}</tex-math></alternatives></inline-formula>, <inline-formula><alternatives><mml:math id="inf204"><mml:mrow><mml:mo>{</mml:mo><mml:msub><mml:mi>q</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>q</mml:mi><mml:mn>2</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:mn>...</mml:mn><mml:msub><mml:mi>q</mml:mi><mml:mi>n</mml:mi></mml:msub><mml:mo>}</mml:mo></mml:mrow></mml:math><tex-math id="inft204">\begin{document}$\left \{q_{1},q_{2},...q_{n}\right \}$\end{document}</tex-math></alternatives></inline-formula> and the cost matrix is constructed as follows:<disp-formula id="equ54"><label>(54)</label><alternatives><mml:math id="m54"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>C</mml:mi><mml:mo>=</mml:mo><mml:msub><mml:mrow><mml:mo>[</mml:mo><mml:mtable columnalign="center center" rowspacing="4pt" columnspacing="1em"><mml:mtr><mml:mtd><mml:mtable columnalign="center center center" rowspacing="4pt" columnspacing="1em"><mml:mtr><mml:mtd><mml:mi>c</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>p</mml:mi><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>q</mml:mi><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mtd><mml:mtd><mml:mo>⋯</mml:mo></mml:mtd><mml:mtd><mml:mi>c</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>p</mml:mi><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>q</mml:mi><mml:mrow><mml:mi>n</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mo>⋮</mml:mo></mml:mtd><mml:mtd><mml:mo>⋱</mml:mo></mml:mtd><mml:mtd><mml:mo>⋮</mml:mo></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mi>c</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>p</mml:mi><mml:mrow><mml:mi>m</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>q</mml:mi><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mtd><mml:mtd><mml:mo>⋯</mml:mo></mml:mtd><mml:mtd><mml:mi>c</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>p</mml:mi><mml:mrow><mml:mi>m</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>q</mml:mi><mml:mrow><mml:mi>n</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:mtd><mml:mtd><mml:msub><mml:mi>D</mml:mi><mml:mrow><mml:mi>m</mml:mi><mml:mo>×</mml:mo><mml:mi>m</mml:mi></mml:mrow></mml:msub></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:msub><mml:mi>D</mml:mi><mml:mrow><mml:mi>n</mml:mi><mml:mo>×</mml:mo><mml:mi>n</mml:mi></mml:mrow></mml:msub></mml:mtd><mml:mtd><mml:msub><mml:mi>D</mml:mi><mml:mrow><mml:mi>n</mml:mi><mml:mo>×</mml:mo><mml:mi>m</mml:mi></mml:mrow></mml:msub></mml:mtd></mml:mtr></mml:mtable><mml:mo>]</mml:mo></mml:mrow><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>m</mml:mi><mml:mo>+</mml:mo><mml:mi>n</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>×</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>m</mml:mi><mml:mo>+</mml:mo><mml:mi>n</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math><tex-math id="t54">\begin{document}$$\displaystyle C=\left [\begin{array}{cc}\begin{array}{ccc}c\left (p_{1},q_{1}\right) &amp; \cdots &amp; c\left (p_{1},q_{n}\right)\\\vdots &amp; \ddots &amp; \vdots \\ c\left (p_{m},q_{1}\right) &amp; \cdots &amp; c\left (p_{m},q_{n}\right)\end{array} &amp; D_{m\times m}\\ D_{n\times n} &amp; D_{n\times m}\end{array}\right ]_{\left (m+n\right)\times \left (m+n\right)}$$\end{document}</tex-math></alternatives></disp-formula><disp-formula id="equ55"><label>(55)</label><alternatives><mml:math id="m55"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>c</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>p</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>q</mml:mi><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mi>d</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>p</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>q</mml:mi><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>×</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mn>2</mml:mn><mml:mo>−</mml:mo><mml:mi>θ</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>L</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:msub><mml:mi>p</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>)</mml:mo></mml:mrow><mml:mo>,</mml:mo><mml:mi>L</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:msub><mml:mi>q</mml:mi><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mstyle></mml:mrow></mml:mstyle></mml:math><tex-math id="t55">\begin{document}$$\displaystyle  c\left (p_{i},q_{j}\right)=d\left (p_{i},q_{j}\right)\times \left (2- \theta \left (L\left (p_{i}\right),L\left (q_{j}\right)\right)\right)$$\end{document}</tex-math></alternatives></disp-formula></p><p>Here, <inline-formula><alternatives><mml:math id="inf205"><mml:mrow><mml:msub><mml:mi>D</mml:mi><mml:mrow><mml:mi>m</mml:mi><mml:mo>×</mml:mo><mml:mi>m</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:math><tex-math id="inft205">\begin{document}$D_{m\times m}$\end{document}</tex-math></alternatives></inline-formula>, <inline-formula><alternatives><mml:math id="inf206"><mml:mrow><mml:msub><mml:mi>D</mml:mi><mml:mrow><mml:mi>n</mml:mi><mml:mo>×</mml:mo><mml:mi>n</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:math><tex-math id="inft206">\begin{document}$D_{n\times n}$\end{document}</tex-math></alternatives></inline-formula>, <inline-formula><alternatives><mml:math id="inf207"><mml:mrow><mml:msub><mml:mi>D</mml:mi><mml:mrow><mml:mi>n</mml:mi><mml:mo>×</mml:mo><mml:mi>m</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:math><tex-math id="inft207">\begin{document}$D_{n\times m}$\end{document}</tex-math></alternatives></inline-formula> are auxiliary matrix which the values are all set 20. <inline-formula><alternatives><mml:math id="inf208"><mml:mrow><mml:mi>d</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>p</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>q</mml:mi><mml:mi>j</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math><tex-math id="inft208">\begin{document}$d\left (p_{i},q_{j}\right)$\end{document}</tex-math></alternatives></inline-formula> represents the Euclidean distance between terminal <inline-formula><alternatives><mml:math id="inf209"><mml:mrow><mml:msub><mml:mi>p</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:math><tex-math id="inft209">\begin{document}$p_{i}$\end{document}</tex-math></alternatives></inline-formula> and <inline-formula><alternatives><mml:math id="inf210"><mml:mrow><mml:msub><mml:mi>q</mml:mi><mml:mi>j</mml:mi></mml:msub></mml:mrow></mml:math><tex-math id="inft210">\begin{document}$q_{j}$\end{document}</tex-math></alternatives></inline-formula>. <inline-formula><alternatives><mml:math id="inf211"><mml:mrow><mml:mi>L</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>p</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math><tex-math id="inft211">\begin{document}$L\left (p_{i}\right)$\end{document}</tex-math></alternatives></inline-formula> and <inline-formula><alternatives><mml:math id="inf212"><mml:mrow><mml:mi>L</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>q</mml:mi><mml:mi>j</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math><tex-math id="inft212">\begin{document}$L\left (q_{j}\right)$\end{document}</tex-math></alternatives></inline-formula> are fitted lines from the skeleton points near <inline-formula><alternatives><mml:math id="inf213"><mml:mrow><mml:msub><mml:mi>p</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:math><tex-math id="inft213">\begin{document}$p_{i}$\end{document}</tex-math></alternatives></inline-formula> and <inline-formula><alternatives><mml:math id="inf214"><mml:mrow><mml:msub><mml:mi>q</mml:mi><mml:mi>j</mml:mi></mml:msub></mml:mrow></mml:math><tex-math id="inft214">\begin{document}$q_{j}$\end{document}</tex-math></alternatives></inline-formula>. <inline-formula><alternatives><mml:math id="inf215"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>θ</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>L</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:msub><mml:mi>p</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>)</mml:mo></mml:mrow><mml:mo>,</mml:mo><mml:mi>L</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:msub><mml:mi>q</mml:mi><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mstyle></mml:math><tex-math id="inft215">\begin{document}$\theta \left (L\left (p_{i}\right),L\left (q_{j}\right)\right)$\end{document}</tex-math></alternatives></inline-formula> represents the cosine value of their angle. Thus, the 0–1 assignment problem is formed as follows:<disp-formula id="equ56"><label>(56)</label><alternatives><mml:math id="m56"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>A</mml:mi><mml:mo>=</mml:mo><mml:msub><mml:mrow><mml:mi mathvariant="normal">a</mml:mi><mml:mi mathvariant="normal">r</mml:mi><mml:mi mathvariant="normal">g</mml:mi><mml:mspace width="thinmathspace"/><mml:mi mathvariant="normal">m</mml:mi><mml:mi mathvariant="normal">i</mml:mi><mml:mi mathvariant="normal">n</mml:mi></mml:mrow><mml:mrow><mml:mi>A</mml:mi></mml:mrow></mml:msub><mml:munderover><mml:mo movablelimits="false">∑</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>m</mml:mi><mml:mo>+</mml:mo><mml:mi>n</mml:mi></mml:mrow></mml:munderover><mml:munderover><mml:mo movablelimits="false">∑</mml:mo><mml:mrow><mml:mi>j</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>m</mml:mi><mml:mo>+</mml:mo><mml:mi>n</mml:mi></mml:mrow></mml:munderover><mml:msub><mml:mi>A</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>⋅</mml:mo><mml:msub><mml:mi>C</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:mstyle></mml:mrow></mml:mstyle></mml:math><tex-math id="t56">\begin{document}$$\displaystyle  A=\mathrm{arg \,min}_{A}\sum \limits_{i=1}^{m+n}\sum \limits_{j=1}^{m+n}A_{i,j}\cdot C_{i,j}$$\end{document}</tex-math></alternatives></disp-formula><disp-formula id="equ57"><label>(57)</label><alternatives><mml:math id="m57"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>s</mml:mi><mml:mo>.</mml:mo><mml:mi>t</mml:mi><mml:mo>.</mml:mo><mml:munderover><mml:mo movablelimits="false">∑</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>m</mml:mi><mml:mo>+</mml:mo><mml:mi>n</mml:mi></mml:mrow></mml:munderover><mml:msub><mml:mi>A</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mn>1</mml:mn><mml:mspace width="thinmathspace"/><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>j</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mn>2</mml:mn><mml:mo>,</mml:mo><mml:mo>…</mml:mo><mml:mi>m</mml:mi><mml:mo>+</mml:mo><mml:mi>n</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mstyle></mml:mrow></mml:mstyle></mml:math><tex-math id="t57">\begin{document}$$\displaystyle  s.t.\sum \limits_{i=1}^{m+n}A_{i,j}=1\,\left (j=1,2,\ldots m+n\right)$$\end{document}</tex-math></alternatives></disp-formula><disp-formula id="equ58"><label>(58)</label><alternatives><mml:math id="m58"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mstyle displaystyle="true" scriptlevel="0"><mml:munderover><mml:mo movablelimits="false">∑</mml:mo><mml:mrow><mml:mi>j</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>m</mml:mi><mml:mo>+</mml:mo><mml:mi>n</mml:mi></mml:mrow></mml:munderover><mml:msub><mml:mi>A</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mn>1</mml:mn><mml:mspace width="thinmathspace"/><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mn>2</mml:mn><mml:mo>,</mml:mo><mml:mo>…</mml:mo><mml:mi>m</mml:mi><mml:mo>+</mml:mo><mml:mi>n</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mstyle></mml:mrow></mml:mstyle></mml:math><tex-math id="t58">\begin{document}$$\displaystyle  \sum \limits_{j=1}^{m+n}A_{i,j}=1\,\left (i=1,2,\ldots m+n\right)$$\end{document}</tex-math></alternatives></disp-formula></p><p>Here, <inline-formula><alternatives><mml:math id="inf216"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>A</mml:mi></mml:mrow></mml:mstyle></mml:math><tex-math id="inft216">\begin{document}$A$\end{document}</tex-math></alternatives></inline-formula> represents the connectivity relationship between nodes, if <inline-formula><alternatives><mml:math id="inf217"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>A</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:mstyle></mml:math><tex-math id="inft217">\begin{document}$A_{i,j}=1$\end{document}</tex-math></alternatives></inline-formula>, there is connection between block <inline-formula><alternatives><mml:math id="inf218"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>P</mml:mi></mml:mrow></mml:mstyle></mml:math><tex-math id="inft218">\begin{document}$P$\end{document}</tex-math></alternatives></inline-formula>’s node <inline-formula><alternatives><mml:math id="inf219"><mml:mi>i</mml:mi></mml:math><tex-math id="inft219">\begin{document}$i$\end{document}</tex-math></alternatives></inline-formula> and block <inline-formula><alternatives><mml:math id="inf220"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>Q</mml:mi></mml:mrow></mml:mstyle></mml:math><tex-math id="inft220">\begin{document}$Q$\end{document}</tex-math></alternatives></inline-formula>’s node <inline-formula><alternatives><mml:math id="inf221"><mml:mi>j</mml:mi></mml:math><tex-math id="inft221">\begin{document}$j$\end{document}</tex-math></alternatives></inline-formula>, if <inline-formula><alternatives><mml:math id="inf222"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>A</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:mstyle></mml:math><tex-math id="inft222">\begin{document}$A_{i,j}=0$\end{document}</tex-math></alternatives></inline-formula>, there is no connection between block <inline-formula><alternatives><mml:math id="inf223"><mml:mi>P</mml:mi></mml:math><tex-math id="inft223">\begin{document}$P$\end{document}</tex-math></alternatives></inline-formula>’s node <inline-formula><alternatives><mml:math id="inf224"><mml:mi>i</mml:mi></mml:math><tex-math id="inft224">\begin{document}$i$\end{document}</tex-math></alternatives></inline-formula> and block <inline-formula><alternatives><mml:math id="inf225"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>Q</mml:mi></mml:mrow></mml:mstyle></mml:math><tex-math id="inft225">\begin{document}$Q$\end{document}</tex-math></alternatives></inline-formula>’s node <inline-formula><alternatives><mml:math id="inf226"><mml:mi>j</mml:mi></mml:math><tex-math id="inft226">\begin{document}$j$\end{document}</tex-math></alternatives></inline-formula>. <inline-formula><alternatives><mml:math id="inf227"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:munderover><mml:mo movablelimits="false">∑</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>m</mml:mi><mml:mo>+</mml:mo><mml:mi>n</mml:mi></mml:mrow></mml:munderover><mml:msub><mml:mi>A</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mn>1</mml:mn><mml:mspace width="thinmathspace"/><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>j</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mn>2</mml:mn><mml:mo>,</mml:mo><mml:mo>…</mml:mo><mml:mi>m</mml:mi><mml:mo>+</mml:mo><mml:mi>n</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mstyle></mml:math><tex-math id="inft227">\begin{document}$\sum \limits_{i=1}^{m+n}A_{i,j}=1\,\left (j=1,2,\ldots m+n\right)$\end{document}</tex-math></alternatives></inline-formula> and <inline-formula><alternatives><mml:math id="inf228"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:munderover><mml:mo movablelimits="false">∑</mml:mo><mml:mrow><mml:mi>j</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>m</mml:mi><mml:mo>+</mml:mo><mml:mi>n</mml:mi></mml:mrow></mml:munderover><mml:msub><mml:mi>A</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mn>1</mml:mn><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mn>2</mml:mn><mml:mo>,</mml:mo><mml:mo>…</mml:mo><mml:mi>m</mml:mi><mml:mo>+</mml:mo><mml:mi>n</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mstyle></mml:math><tex-math id="inft228">\begin{document}$\sum \limits_{j=1}^{m+n}A_{i,j}=1\left (i=1,2,\ldots m+n\right)$\end{document}</tex-math></alternatives></inline-formula> restrict each node to connect to one other node at most. With the solved matrix <inline-formula><alternatives><mml:math id="inf229"><mml:mi>A</mml:mi></mml:math><tex-math id="inft229">\begin{document}$A$\end{document}</tex-math></alternatives></inline-formula>, the neurite skeletons of adjacent blocks can be merged and fused skeleton structures can be obtained.</p></sec><sec id="s4-9"><title>Statistical analysis</title><p>In this study, three commonly used metrics defined in <xref ref-type="bibr" rid="bib34">Quan et al., 2016</xref> were used, including precision, recall, and f1-score, which are computed to measure the fidelity between the reconstruction results and the ground truth. They are defined as follows:<disp-formula id="equ59"><label>(59)</label><alternatives><mml:math id="m59"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>p</mml:mi><mml:mi>r</mml:mi><mml:mi>e</mml:mi><mml:mi>c</mml:mi><mml:mi>i</mml:mi><mml:mi>s</mml:mi><mml:mi>i</mml:mi><mml:mi>o</mml:mi><mml:mi>n</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>R</mml:mi><mml:mo>,</mml:mo><mml:mi>G</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mi>R</mml:mi><mml:mo>∩</mml:mo><mml:mi>G</mml:mi><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow></mml:mrow><mml:mrow><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mi>R</mml:mi><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow></mml:mrow></mml:mfrac><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mi>T</mml:mi><mml:mi>P</mml:mi><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow></mml:mrow><mml:mrow><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mi>R</mml:mi><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow></mml:mrow></mml:mfrac></mml:mstyle></mml:mrow></mml:mstyle></mml:math><tex-math id="t59">\begin{document}$$\displaystyle  precision\left (R,G\right)=\frac{|R\cap G|}{|R|}=\frac{|TP|}{|R|}$$\end{document}</tex-math></alternatives></disp-formula><disp-formula id="equ60"><label>(60)</label><alternatives><mml:math id="m60"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>r</mml:mi><mml:mi>e</mml:mi><mml:mi>c</mml:mi><mml:mi>a</mml:mi><mml:mi>l</mml:mi><mml:mi>l</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>R</mml:mi><mml:mo>,</mml:mo><mml:mi>G</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mi>R</mml:mi><mml:mo>∩</mml:mo><mml:mi>G</mml:mi><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow></mml:mrow><mml:mrow><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mi>G</mml:mi><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow></mml:mrow></mml:mfrac><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mi>T</mml:mi><mml:mi>P</mml:mi><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow></mml:mrow><mml:mrow><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mi>G</mml:mi><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow></mml:mrow></mml:mfrac></mml:mstyle></mml:mrow></mml:mstyle></mml:math><tex-math id="t60">\begin{document}$$\displaystyle  recall\left (R,G\right)=\frac{|R\cap G|}{|G|}=\frac{|TP|}{|G|}$$\end{document}</tex-math></alternatives></disp-formula><disp-formula id="equ61"><label>(61)</label><alternatives><mml:math id="m61"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>f</mml:mi><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:mi>s</mml:mi><mml:mi>c</mml:mi><mml:mi>o</mml:mi><mml:mi>r</mml:mi><mml:mi>e</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>R</mml:mi><mml:mo>,</mml:mo><mml:mi>G</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mn>2</mml:mn><mml:mo>⋅</mml:mo><mml:mfrac><mml:mrow><mml:mi>p</mml:mi><mml:mi>r</mml:mi><mml:mi>e</mml:mi><mml:mi>c</mml:mi><mml:mi>i</mml:mi><mml:mi>s</mml:mi><mml:mi>i</mml:mi><mml:mi>o</mml:mi><mml:mi>n</mml:mi><mml:mo>×</mml:mo><mml:mi>r</mml:mi><mml:mi>e</mml:mi><mml:mi>c</mml:mi><mml:mi>a</mml:mi><mml:mi>l</mml:mi><mml:mi>l</mml:mi></mml:mrow><mml:mrow><mml:mi>p</mml:mi><mml:mi>r</mml:mi><mml:mi>e</mml:mi><mml:mi>c</mml:mi><mml:mi>i</mml:mi><mml:mi>s</mml:mi><mml:mi>i</mml:mi><mml:mi>o</mml:mi><mml:mi>n</mml:mi><mml:mo>+</mml:mo><mml:mi>r</mml:mi><mml:mi>e</mml:mi><mml:mi>c</mml:mi><mml:mi>a</mml:mi><mml:mi>l</mml:mi><mml:mi>l</mml:mi></mml:mrow></mml:mfrac></mml:mstyle></mml:mrow></mml:mstyle></mml:math><tex-math id="t61">\begin{document}$$\displaystyle  f1- score\left (R,G\right)=2\cdot \frac{precision\times recall}{precision+recall}$$\end{document}</tex-math></alternatives></disp-formula></p><p><inline-formula><alternatives><mml:math id="inf230"><mml:mi>R</mml:mi></mml:math><tex-math id="inft230">\begin{document}$R$\end{document}</tex-math></alternatives></inline-formula> represents the point set of reconstructed neurons, <inline-formula><alternatives><mml:math id="inf231"><mml:mi>G</mml:mi></mml:math><tex-math id="inft231">\begin{document}$G$\end{document}</tex-math></alternatives></inline-formula> represents the point set of the ground truth, <inline-formula><alternatives><mml:math id="inf232"><mml:mrow><mml:mo>|</mml:mo><mml:mo>⋅</mml:mo><mml:mo>|</mml:mo></mml:mrow></mml:math><tex-math id="inft232">\begin{document}$|\cdot |$\end{document}</tex-math></alternatives></inline-formula> represents the number of points of a set. The three metrics are first computed on each individual neuron and then averaged by weighting each neuron with its point number of its ground truth neuritis.</p><p>We also calculated the signal-to-ratio (SNR) of the data using the following method: For a given data block <inline-formula><alternatives><mml:math id="inf233"><mml:mi>B</mml:mi></mml:math><tex-math id="inft233">\begin{document}$B$\end{document}</tex-math></alternatives></inline-formula> and its corresponding ground-truth skeleton <inline-formula><alternatives><mml:math id="inf234"><mml:mi>S</mml:mi></mml:math><tex-math id="inft234">\begin{document}$S$\end{document}</tex-math></alternatives></inline-formula>, we first densify the skeleton <inline-formula><alternatives><mml:math id="inf235"><mml:mi>S</mml:mi></mml:math><tex-math id="inft235">\begin{document}$S$\end{document}</tex-math></alternatives></inline-formula> by using linear interpolation to ensure that the Euclidean distance between adjacent skeleton points is less than 1 voxel. Next, we expand each skeleton point in the densified skeleton <inline-formula><alternatives><mml:math id="inf236"><mml:mrow><mml:msup><mml:mi>S</mml:mi><mml:mo>`</mml:mo></mml:msup></mml:mrow></mml:math><tex-math id="inft236">\begin{document}$S^{'}$\end{document}</tex-math></alternatives></inline-formula> into a spherical mask with a radius of 3 voxels. The resulting region serves as the foreground <inline-formula><alternatives><mml:math id="inf237"><mml:mrow><mml:mi>m</mml:mi><mml:mi>a</mml:mi><mml:mi>s</mml:mi><mml:mi>k</mml:mi></mml:mrow></mml:math><tex-math id="inft237">\begin{document}$mask$\end{document}</tex-math></alternatives></inline-formula>. Finally, SNR is computed with mean intensity of foreground points and standard deviation of background points as follows:<disp-formula id="equ62"><label>(62)</label><alternatives><mml:math id="m62"><mml:mrow><mml:mi>M</mml:mi><mml:mi>e</mml:mi><mml:mi>a</mml:mi><mml:msub><mml:mi>n</mml:mi><mml:mrow><mml:mi>f</mml:mi><mml:mi>o</mml:mi><mml:mi>r</mml:mi><mml:mi>e</mml:mi><mml:mi>g</mml:mi><mml:mi>r</mml:mi><mml:mi>o</mml:mi><mml:mi>u</mml:mi><mml:mi>n</mml:mi><mml:mi>d</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mstyle displaystyle="true"><mml:munder><mml:mo>∑</mml:mo><mml:mrow><mml:mi>x</mml:mi><mml:mo>∈</mml:mo><mml:mi>B</mml:mi></mml:mrow></mml:munder><mml:mrow><mml:mi>I</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>x</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>×</mml:mo><mml:msub><mml:mi>σ</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>x</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>/</mml:mo><mml:mstyle displaystyle="true"><mml:munder><mml:mo>∑</mml:mo><mml:mrow><mml:mi>x</mml:mi><mml:mo>∈</mml:mo><mml:mi>B</mml:mi></mml:mrow></mml:munder><mml:mrow><mml:msub><mml:mi>σ</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>x</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mstyle></mml:mrow></mml:mstyle></mml:mrow></mml:math><tex-math id="t62">\begin{document}$$\displaystyle  Mean_{foreground}=\underset{x\in B}{\sum }I\left (x\right)\times \sigma _{1}\left (x\right)/\underset{x\in B}{\sum }\sigma _{1}\left (x\right)$$\end{document}</tex-math></alternatives></disp-formula><disp-formula id="equ63"><label>(63)</label><alternatives><mml:math id="m63"><mml:mrow><mml:mi>M</mml:mi><mml:mi>e</mml:mi><mml:mi>a</mml:mi><mml:msub><mml:mi>n</mml:mi><mml:mrow><mml:mi>b</mml:mi><mml:mi>a</mml:mi><mml:mi>c</mml:mi><mml:mi>k</mml:mi><mml:mi>g</mml:mi><mml:mi>r</mml:mi><mml:mi>o</mml:mi><mml:mi>u</mml:mi><mml:mi>n</mml:mi><mml:mi>d</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mstyle displaystyle="true"><mml:munder><mml:mo>∑</mml:mo><mml:mrow><mml:mi>x</mml:mi><mml:mo>∈</mml:mo><mml:mi>B</mml:mi></mml:mrow></mml:munder><mml:mrow><mml:mi>I</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>x</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>×</mml:mo><mml:msub><mml:mi>σ</mml:mi><mml:mn>2</mml:mn></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>x</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>/</mml:mo><mml:mstyle displaystyle="true"><mml:munder><mml:mo>∑</mml:mo><mml:mrow><mml:mi>x</mml:mi><mml:mo>∈</mml:mo><mml:mi>B</mml:mi></mml:mrow></mml:munder><mml:mrow><mml:msub><mml:mi>σ</mml:mi><mml:mn>2</mml:mn></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>x</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mstyle></mml:mrow></mml:mstyle></mml:mrow></mml:math><tex-math id="t63">\begin{document}$$\displaystyle  Mean_{background}=\underset{x\in B}{\sum }I\left (x\right)\times \sigma _{2}\left (x\right)/\underset{x\in B}{\sum }\sigma _{2}\left (x\right)$$\end{document}</tex-math></alternatives></disp-formula><disp-formula id="equ64"><label>(64)</label><alternatives><mml:math id="m64"><mml:mrow><mml:mi>S</mml:mi><mml:mi>t</mml:mi><mml:msub><mml:mi>d</mml:mi><mml:mrow><mml:mi>b</mml:mi><mml:mi>a</mml:mi><mml:mi>c</mml:mi><mml:mi>k</mml:mi><mml:mi>g</mml:mi><mml:mi>r</mml:mi><mml:mi>o</mml:mi><mml:mi>u</mml:mi><mml:mi>n</mml:mi><mml:mi>d</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:msqrt><mml:mrow><mml:mstyle displaystyle="true"><mml:munder><mml:mo>∑</mml:mo><mml:mrow><mml:mi>x</mml:mi><mml:mo>∈</mml:mo><mml:mi>B</mml:mi></mml:mrow></mml:munder><mml:mrow><mml:msup><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>I</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>x</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>−</mml:mo><mml:mi>M</mml:mi><mml:mi>e</mml:mi><mml:mi>a</mml:mi><mml:msub><mml:mi>n</mml:mi><mml:mrow><mml:mi>b</mml:mi><mml:mi>a</mml:mi><mml:mi>c</mml:mi><mml:mi>k</mml:mi><mml:mi>g</mml:mi><mml:mi>r</mml:mi><mml:mi>o</mml:mi><mml:mi>u</mml:mi><mml:mi>n</mml:mi><mml:mi>d</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mn>2</mml:mn></mml:msup><mml:mo>×</mml:mo><mml:msub><mml:mi>σ</mml:mi><mml:mn>2</mml:mn></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>x</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mstyle><mml:mo>/</mml:mo><mml:mstyle displaystyle="true"><mml:munder><mml:mo>∑</mml:mo><mml:mrow><mml:mi>x</mml:mi><mml:mo>∈</mml:mo><mml:mi>B</mml:mi></mml:mrow></mml:munder><mml:mrow><mml:msub><mml:mi>σ</mml:mi><mml:mn>2</mml:mn></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>x</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mstyle></mml:mrow></mml:msqrt></mml:mrow></mml:math><tex-math id="t64">\begin{document}$$\displaystyle  Std_{background}=\sqrt{\underset{x\in B}{\sum }\left (I\left (x\right)- Mean_{background}\right)^{2}\times \sigma _{2}\left (x\right)/\underset{x\in B}{\sum }\sigma _{2}\left (x\right)}$$\end{document}</tex-math></alternatives></disp-formula><disp-formula id="equ65"><label>(65)</label><alternatives><mml:math id="m65"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>σ</mml:mi><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mi>x</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mrow><mml:mo>{</mml:mo><mml:mtable columnalign="center center" rowspacing="4pt" columnspacing="1em"><mml:mtr><mml:mtd><mml:mn>1</mml:mn></mml:mtd><mml:mtd><mml:mi>i</mml:mi><mml:mi>f</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>x</mml:mi><mml:mo>∈</mml:mo><mml:msup><mml:mi>S</mml:mi><mml:mrow><mml:mo>′</mml:mo></mml:mrow></mml:msup></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mn>0</mml:mn></mml:mtd><mml:mtd><mml:mi>i</mml:mi><mml:mi>f</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>x</mml:mi><mml:mo>∉</mml:mo><mml:msup><mml:mi>S</mml:mi><mml:mrow><mml:mo>′</mml:mo></mml:mrow></mml:msup></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable><mml:mo fence="true" stretchy="true" symmetric="true"/></mml:mrow></mml:mrow></mml:mstyle></mml:math><tex-math id="t65">\begin{document}$$\displaystyle \sigma _{1}\left (x\right)=\left \{\begin{array}{cc}1 &amp; if\left (x\in S^{'}\right)\\0 &amp; if\left (x\notin S^{'}\right)\end{array}\right.$$\end{document}</tex-math></alternatives></disp-formula><disp-formula id="equ66"><label>(66)</label><alternatives><mml:math id="m66"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>σ</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mi>x</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mrow><mml:mo>{</mml:mo><mml:mtable columnalign="center center" rowspacing="4pt" columnspacing="1em"><mml:mtr><mml:mtd><mml:mn>1</mml:mn></mml:mtd><mml:mtd><mml:mi>i</mml:mi><mml:mi>f</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>x</mml:mi><mml:mo>∉</mml:mo><mml:mi>m</mml:mi><mml:mi>a</mml:mi><mml:mi>s</mml:mi><mml:mi>k</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mn>0</mml:mn></mml:mtd><mml:mtd><mml:mi>i</mml:mi><mml:mi>f</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>x</mml:mi><mml:mo>∈</mml:mo><mml:mi>m</mml:mi><mml:mi>a</mml:mi><mml:mi>s</mml:mi><mml:mi>k</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable><mml:mo fence="true" stretchy="true" symmetric="true"/></mml:mrow></mml:mrow></mml:mstyle></mml:math><tex-math id="t66">\begin{document}$$\displaystyle \sigma _{2}\left (x\right)=\left \{\begin{array}{cc}1 &amp; if\left (x\notin mask\right)\\0 &amp; if\left (x\in mask\right)\end{array}\right.$$\end{document}</tex-math></alternatives></disp-formula></p><p>Here, <inline-formula><alternatives><mml:math id="inf238"><mml:mrow><mml:mi>I</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>x</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math><tex-math id="inft238">\begin{document}$I\left (x\right)$\end{document}</tex-math></alternatives></inline-formula> represents the signal intensity of the voxel at position <inline-formula><alternatives><mml:math id="inf239"><mml:mi>x</mml:mi></mml:math><tex-math id="inft239">\begin{document}$x$\end{document}</tex-math></alternatives></inline-formula>, the SNR is calculated by <inline-formula><alternatives><mml:math id="inf240"><mml:mrow><mml:mi>M</mml:mi><mml:mi>e</mml:mi><mml:mi>a</mml:mi><mml:msub><mml:mi>n</mml:mi><mml:mrow><mml:mi>f</mml:mi><mml:mi>o</mml:mi><mml:mi>r</mml:mi><mml:mi>e</mml:mi><mml:mi>g</mml:mi><mml:mi>r</mml:mi><mml:mi>o</mml:mi><mml:mi>u</mml:mi><mml:mi>n</mml:mi><mml:mi>d</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:math><tex-math id="inft240">\begin{document}$Mean_{foreground}$\end{document}</tex-math></alternatives></inline-formula> and <inline-formula><alternatives><mml:math id="inf241"><mml:mrow><mml:mi>S</mml:mi><mml:mi>t</mml:mi><mml:msub><mml:mi>d</mml:mi><mml:mrow><mml:mi>b</mml:mi><mml:mi>a</mml:mi><mml:mi>c</mml:mi><mml:mi>k</mml:mi><mml:mi>g</mml:mi><mml:mi>r</mml:mi><mml:mi>o</mml:mi><mml:mi>u</mml:mi><mml:mi>n</mml:mi><mml:mi>d</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:math><tex-math id="inft241">\begin{document}$Std_{background}$\end{document}</tex-math></alternatives></inline-formula> by the following formula:<disp-formula id="equ67"><label>(67)</label><alternatives><mml:math id="m67"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>S</mml:mi><mml:mi>N</mml:mi><mml:mi>R</mml:mi><mml:mo>=</mml:mo><mml:mn>10</mml:mn><mml:mi>l</mml:mi><mml:mi>o</mml:mi><mml:msub><mml:mi>g</mml:mi><mml:mrow><mml:mn>10</mml:mn></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>M</mml:mi><mml:mi>e</mml:mi><mml:mi>a</mml:mi><mml:msub><mml:mi>n</mml:mi><mml:mrow><mml:mi>f</mml:mi><mml:mi>o</mml:mi><mml:mi>r</mml:mi><mml:mi>e</mml:mi><mml:mi>g</mml:mi><mml:mi>r</mml:mi><mml:mi>o</mml:mi><mml:mi>u</mml:mi><mml:mi>n</mml:mi><mml:mi>d</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo>/</mml:mo></mml:mrow><mml:mi>S</mml:mi><mml:mi>t</mml:mi><mml:msub><mml:mi>d</mml:mi><mml:mrow><mml:mi>b</mml:mi><mml:mi>a</mml:mi><mml:mi>c</mml:mi><mml:mi>k</mml:mi><mml:mi>g</mml:mi><mml:mi>r</mml:mi><mml:mi>o</mml:mi><mml:mi>u</mml:mi><mml:mi>n</mml:mi><mml:mi>d</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mstyle></mml:math><tex-math id="t67">\begin{document}$$\displaystyle SNR=10log_{10}\left (Mean_{foreground}/Std_{background}\right)$$\end{document}</tex-math></alternatives></disp-formula></p></sec></sec></body><back><sec sec-type="additional-information" id="s5"><title>Additional information</title><fn-group content-type="competing-interest"><title>Competing interests</title><fn fn-type="COI-statement" id="conf1"><p>No competing interests declared</p></fn></fn-group><fn-group content-type="author-contribution"><title>Author contributions</title><fn fn-type="con" id="con1"><p>Validation, Investigation, Methodology, Writing – original draft, Writing – review and editing</p></fn><fn fn-type="con" id="con2"><p>Validation, Investigation, Writing – original draft</p></fn><fn fn-type="con" id="con3"><p>Software, Investigation</p></fn><fn fn-type="con" id="con4"><p>Validation</p></fn><fn fn-type="con" id="con5"><p>Investigation</p></fn><fn fn-type="con" id="con6"><p>Validation</p></fn><fn fn-type="con" id="con7"><p>Investigation</p></fn><fn fn-type="con" id="con8"><p>Validation</p></fn><fn fn-type="con" id="con9"><p>Supervision</p></fn><fn fn-type="con" id="con10"><p>Supervision</p></fn><fn fn-type="con" id="con11"><p>Supervision</p></fn><fn fn-type="con" id="con12"><p>Supervision, Funding acquisition, Investigation, Methodology, Writing – original draft, Writing – review and editing</p></fn><fn fn-type="con" id="con13"><p>Supervision</p></fn></fn-group><fn-group content-type="ethics-information"><title>Ethics</title><fn fn-type="other"><p>All animal experiments followed procedures approved by the Institutional Animal Ethics Committee of the Huazhong University of Science and Technology.</p></fn></fn-group></sec><sec sec-type="supplementary-material" id="s6"><title>Additional files</title><supplementary-material id="mdar"><label>MDAR checklist</label><media xlink:href="elife-102840-mdarchecklist1-v1.docx" mimetype="application" mime-subtype="docx"/></supplementary-material></sec><sec sec-type="data-availability" id="s7"><title>Data availability</title><p>The data for Figure 1C, Figure 2, Figure 3, Figure 4, Figure 5, Figure 6 and Figure 6—figure supplement 2 is available in <ext-link ext-link-type="uri" xlink:href="https://zenodo.org/records/15589145">https://zenodo.org/records/15589145</ext-link>. The training code of the segmentation network is available on Github: <ext-link ext-link-type="uri" xlink:href="https://github.com/FateUBW0227/Seg_Net">https://github.com/FateUBW0227/Seg_Net</ext-link> (copy archived at <xref ref-type="bibr" rid="bib2">Cai, 2025</xref>). The software of PointTree and its user guideline are available at <ext-link ext-link-type="uri" xlink:href="https://zenodo.org/records/15589145">https://zenodo.org/records/15589145</ext-link>.</p><p>The following dataset was generated:</p><p><element-citation publication-type="data" specific-use="isSupplementedBy" id="dataset1"><person-group person-group-type="author"><name><surname>Lin</surname><given-names>C</given-names></name></person-group><year iso-8601-date="2025">2025</year><data-title>Dataset for PointTree: Automatic and accurate reconstruction of long-range axonal projections of single-neuron</data-title><source>Zenodo</source><pub-id pub-id-type="doi">10.5281/zenodo.15589145</pub-id></element-citation></p></sec><ack id="ack"><title>Acknowledgements</title><p>We thank the members of the Britton Chance Center for Biomedical Photonics for advice and help in experiments. This work was supported by the National Natural Science Foundation of China (32471146) and the project N20240194.</p></ack><ref-list><title>References</title><ref id="bib1"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Cai</surname><given-names>R</given-names></name><name><surname>Pan</surname><given-names>C</given-names></name><name><surname>Ghasemigharagoz</surname><given-names>A</given-names></name><name><surname>Todorov</surname><given-names>MI</given-names></name><name><surname>Förstera</surname><given-names>B</given-names></name><name><surname>Zhao</surname><given-names>S</given-names></name><name><surname>Bhatia</surname><given-names>HS</given-names></name><name><surname>Parra-Damas</surname><given-names>A</given-names></name><name><surname>Mrowka</surname><given-names>L</given-names></name><name><surname>Theodorou</surname><given-names>D</given-names></name><name><surname>Rempfler</surname><given-names>M</given-names></name><name><surname>Xavier</surname><given-names>ALR</given-names></name><name><surname>Kress</surname><given-names>BT</given-names></name><name><surname>Benakis</surname><given-names>C</given-names></name><name><surname>Steinke</surname><given-names>H</given-names></name><name><surname>Liebscher</surname><given-names>S</given-names></name><name><surname>Bechmann</surname><given-names>I</given-names></name><name><surname>Liesz</surname><given-names>A</given-names></name><name><surname>Menze</surname><given-names>B</given-names></name><name><surname>Kerschensteiner</surname><given-names>M</given-names></name><name><surname>Nedergaard</surname><given-names>M</given-names></name><name><surname>Ertürk</surname><given-names>A</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>Panoptic imaging of transparent mice reveals whole-body neuronal projections and skull-meninges connections</article-title><source>Nature Neuroscience</source><volume>22</volume><fpage>317</fpage><lpage>327</lpage><pub-id pub-id-type="doi">10.1038/s41593-018-0301-3</pub-id><pub-id pub-id-type="pmid">30598527</pub-id></element-citation></ref><ref id="bib2"><element-citation publication-type="software"><person-group person-group-type="author"><name><surname>Cai</surname><given-names>L</given-names></name></person-group><year iso-8601-date="2025">2025</year><data-title>Seg_Net</data-title><version designator="swh:1:rev:5d29c54b2b41f44cc87252c265c82998ccc494c1">swh:1:rev:5d29c54b2b41f44cc87252c265c82998ccc494c1</version><source>Software Heritage</source><ext-link ext-link-type="uri" xlink:href="https://archive.softwareheritage.org/swh:1:dir:4a6b444598ac0f8f80b664fa96504d5c9a57b4fa;origin=https://github.com/FateUBW0227/Seg_Net;visit=swh:1:snp:320efc5d379135155542b22fe0f36233033c94e6;anchor=swh:1:rev:5d29c54b2b41f44cc87252c265c82998ccc494c1">https://archive.softwareheritage.org/swh:1:dir:4a6b444598ac0f8f80b664fa96504d5c9a57b4fa;origin=https://github.com/FateUBW0227/Seg_Net;visit=swh:1:snp:320efc5d379135155542b22fe0f36233033c94e6;anchor=swh:1:rev:5d29c54b2b41f44cc87252c265c82998ccc494c1</ext-link></element-citation></ref><ref id="bib3"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Cannon</surname><given-names>RC</given-names></name><name><surname>Turner</surname><given-names>DA</given-names></name><name><surname>Pyapali</surname><given-names>GK</given-names></name><name><surname>Wheal</surname><given-names>HV</given-names></name></person-group><year iso-8601-date="1998">1998</year><article-title>An on-line archive of reconstructed hippocampal neurons</article-title><source>Journal of Neuroscience Methods</source><volume>84</volume><fpage>49</fpage><lpage>54</lpage><pub-id pub-id-type="doi">10.1016/s0165-0270(98)00091-0</pub-id><pub-id pub-id-type="pmid">9821633</pub-id></element-citation></ref><ref id="bib4"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Choromanska</surname><given-names>A</given-names></name><name><surname>Chang</surname><given-names>SF</given-names></name><name><surname>Yuste</surname><given-names>R</given-names></name></person-group><year iso-8601-date="2012">2012</year><article-title>Automatic reconstruction of neural morphologies with multi-scale tracking</article-title><source>Frontiers in Neural Circuits</source><volume>6</volume><elocation-id>25</elocation-id><pub-id pub-id-type="doi">10.3389/fncir.2012.00025</pub-id><pub-id pub-id-type="pmid">22754498</pub-id></element-citation></ref><ref id="bib5"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Chung</surname><given-names>K</given-names></name><name><surname>Deisseroth</surname><given-names>K</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>CLARITY for mapping the nervous system</article-title><source>Nature Methods</source><volume>10</volume><fpage>508</fpage><lpage>513</lpage><pub-id pub-id-type="doi">10.1038/nmeth.2481</pub-id><pub-id pub-id-type="pmid">23722210</pub-id></element-citation></ref><ref id="bib6"><element-citation publication-type="confproc"><person-group person-group-type="author"><name><surname>Çiçek</surname><given-names>Ö</given-names></name><name><surname>Abdulkadir</surname><given-names>A</given-names></name><name><surname>Lienkamp</surname><given-names>SS</given-names></name><name><surname>Brox</surname><given-names>T</given-names></name><name><surname>Ronneberger</surname><given-names>O</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>3D U-Net: learning dense volumetric segmentation from sparse annotation</article-title><conf-name>Medical Image Computing and Computer-Assisted Intervention–MICCAI 2016: 19th International Conference</conf-name></element-citation></ref><ref id="bib7"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Feng</surname><given-names>L</given-names></name><name><surname>Zhao</surname><given-names>T</given-names></name><name><surname>Kim</surname><given-names>J</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>neuTube 1.0: a new design for efficient neuron reconstruction software based on the SWC Format</article-title><source>eNeuro</source><volume>2</volume><elocation-id>ENEURO.0049-14.2014</elocation-id><pub-id pub-id-type="doi">10.1523/ENEURO.0049-14.2014</pub-id><pub-id pub-id-type="pmid">26464967</pub-id></element-citation></ref><ref id="bib8"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Foster</surname><given-names>NN</given-names></name><name><surname>Barry</surname><given-names>J</given-names></name><name><surname>Korobkova</surname><given-names>L</given-names></name><name><surname>Garcia</surname><given-names>L</given-names></name><name><surname>Gao</surname><given-names>L</given-names></name><name><surname>Becerra</surname><given-names>M</given-names></name><name><surname>Sherafat</surname><given-names>Y</given-names></name><name><surname>Peng</surname><given-names>B</given-names></name><name><surname>Li</surname><given-names>X</given-names></name><name><surname>Choi</surname><given-names>J-H</given-names></name><name><surname>Gou</surname><given-names>L</given-names></name><name><surname>Zingg</surname><given-names>B</given-names></name><name><surname>Azam</surname><given-names>S</given-names></name><name><surname>Lo</surname><given-names>D</given-names></name><name><surname>Khanjani</surname><given-names>N</given-names></name><name><surname>Zhang</surname><given-names>B</given-names></name><name><surname>Stanis</surname><given-names>J</given-names></name><name><surname>Bowman</surname><given-names>I</given-names></name><name><surname>Cotter</surname><given-names>K</given-names></name><name><surname>Cao</surname><given-names>C</given-names></name><name><surname>Yamashita</surname><given-names>S</given-names></name><name><surname>Tugangui</surname><given-names>A</given-names></name><name><surname>Li</surname><given-names>A</given-names></name><name><surname>Jiang</surname><given-names>T</given-names></name><name><surname>Jia</surname><given-names>X</given-names></name><name><surname>Feng</surname><given-names>Z</given-names></name><name><surname>Aquino</surname><given-names>S</given-names></name><name><surname>Mun</surname><given-names>H-S</given-names></name><name><surname>Zhu</surname><given-names>M</given-names></name><name><surname>Santarelli</surname><given-names>A</given-names></name><name><surname>Benavidez</surname><given-names>NL</given-names></name><name><surname>Song</surname><given-names>M</given-names></name><name><surname>Dan</surname><given-names>G</given-names></name><name><surname>Fayzullina</surname><given-names>M</given-names></name><name><surname>Ustrell</surname><given-names>S</given-names></name><name><surname>Boesen</surname><given-names>T</given-names></name><name><surname>Johnson</surname><given-names>DL</given-names></name><name><surname>Xu</surname><given-names>H</given-names></name><name><surname>Bienkowski</surname><given-names>MS</given-names></name><name><surname>Yang</surname><given-names>XW</given-names></name><name><surname>Gong</surname><given-names>H</given-names></name><name><surname>Levine</surname><given-names>MS</given-names></name><name><surname>Wickersham</surname><given-names>I</given-names></name><name><surname>Luo</surname><given-names>Q</given-names></name><name><surname>Hahn</surname><given-names>JD</given-names></name><name><surname>Lim</surname><given-names>BK</given-names></name><name><surname>Zhang</surname><given-names>LI</given-names></name><name><surname>Cepeda</surname><given-names>C</given-names></name><name><surname>Hintiryan</surname><given-names>H</given-names></name><name><surname>Dong</surname><given-names>H-W</given-names></name></person-group><year iso-8601-date="2021">2021</year><article-title>The mouse cortico-basal ganglia-thalamic network</article-title><source>Nature</source><volume>598</volume><fpage>188</fpage><lpage>194</lpage><pub-id pub-id-type="doi">10.1038/s41586-021-03993-3</pub-id><pub-id pub-id-type="pmid">34616074</pub-id></element-citation></ref><ref id="bib9"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Friedmann</surname><given-names>D</given-names></name><name><surname>Pun</surname><given-names>A</given-names></name><name><surname>Adams</surname><given-names>EL</given-names></name><name><surname>Lui</surname><given-names>JH</given-names></name><name><surname>Kebschull</surname><given-names>JM</given-names></name><name><surname>Grutzner</surname><given-names>SM</given-names></name><name><surname>Castagnola</surname><given-names>C</given-names></name><name><surname>Tessier-Lavigne</surname><given-names>M</given-names></name><name><surname>Luo</surname><given-names>L</given-names></name></person-group><year iso-8601-date="2020">2020</year><article-title>Mapping mesoscale axonal projections in the mouse brain using a 3D convolutional network</article-title><source>PNAS</source><volume>117</volume><fpage>11068</fpage><lpage>11075</lpage><pub-id pub-id-type="doi">10.1073/pnas.1918465117</pub-id></element-citation></ref><ref id="bib10"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Gao</surname><given-names>Le</given-names></name><name><surname>Liu</surname><given-names>S</given-names></name><name><surname>Gou</surname><given-names>L</given-names></name><name><surname>Hu</surname><given-names>Y</given-names></name><name><surname>Liu</surname><given-names>Y</given-names></name><name><surname>Deng</surname><given-names>L</given-names></name><name><surname>Ma</surname><given-names>D</given-names></name><name><surname>Wang</surname><given-names>H</given-names></name><name><surname>Yang</surname><given-names>Q</given-names></name><name><surname>Chen</surname><given-names>Z</given-names></name><name><surname>Liu</surname><given-names>D</given-names></name><name><surname>Qiu</surname><given-names>S</given-names></name><name><surname>Wang</surname><given-names>X</given-names></name><name><surname>Wang</surname><given-names>D</given-names></name><name><surname>Wang</surname><given-names>X</given-names></name><name><surname>Ren</surname><given-names>B</given-names></name><name><surname>Liu</surname><given-names>Q</given-names></name><name><surname>Chen</surname><given-names>T</given-names></name><name><surname>Shi</surname><given-names>X</given-names></name><name><surname>Yao</surname><given-names>H</given-names></name><name><surname>Xu</surname><given-names>C</given-names></name><name><surname>Li</surname><given-names>CT</given-names></name><name><surname>Sun</surname><given-names>Y</given-names></name><name><surname>Li</surname><given-names>A</given-names></name><name><surname>Luo</surname><given-names>Q</given-names></name><name><surname>Gong</surname><given-names>H</given-names></name><name><surname>Xu</surname><given-names>N</given-names></name><name><surname>Yan</surname><given-names>J</given-names></name></person-group><year iso-8601-date="2022">2022</year><article-title>Single-neuron projectome of mouse prefrontal cortex</article-title><source>Nature Neuroscience</source><volume>25</volume><fpage>515</fpage><lpage>529</lpage><pub-id pub-id-type="doi">10.1038/s41593-022-01041-5</pub-id><pub-id pub-id-type="pmid">35361973</pub-id></element-citation></ref><ref id="bib11"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Gao</surname><given-names>L</given-names></name><name><surname>Liu</surname><given-names>S</given-names></name><name><surname>Wang</surname><given-names>Y</given-names></name><name><surname>Wu</surname><given-names>Q</given-names></name><name><surname>Gou</surname><given-names>L</given-names></name><name><surname>Yan</surname><given-names>J</given-names></name></person-group><year iso-8601-date="2023">2023</year><article-title>Single-neuron analysis of dendrites and axons reveals the network organization in mouse prefrontal cortex</article-title><source>Nature Neuroscience</source><volume>26</volume><fpage>1111</fpage><lpage>1126</lpage><pub-id pub-id-type="doi">10.1038/s41593-023-01339-y</pub-id><pub-id pub-id-type="pmid">37217724</pub-id></element-citation></ref><ref id="bib12"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Harris</surname><given-names>R</given-names></name></person-group><year iso-8601-date="2011">2011</year><article-title>Models of regional growth: past, present and future</article-title><source>Journal of Economic Surveys</source><volume>25</volume><fpage>913</fpage><lpage>951</lpage><pub-id pub-id-type="doi">10.1111/j.1467-6419.2010.00630.x</pub-id></element-citation></ref><ref id="bib13"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Helmstaedter</surname><given-names>M</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>Cellular-resolution connectomics: challenges of dense neural circuit reconstruction</article-title><source>Nature Methods</source><volume>10</volume><fpage>501</fpage><lpage>507</lpage><pub-id pub-id-type="doi">10.1038/nmeth.2476</pub-id><pub-id pub-id-type="pmid">23722209</pub-id></element-citation></ref><ref id="bib14"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Huang</surname><given-names>ZJ</given-names></name><name><surname>Luo</surname><given-names>L</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>Neuroscience: It takes the world to understand the brain</article-title><source>Science</source><volume>350</volume><fpage>42</fpage><lpage>44</lpage><pub-id pub-id-type="doi">10.1126/science.aad4120</pub-id><pub-id pub-id-type="pmid">26430110</pub-id></element-citation></ref><ref id="bib15"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Huang</surname><given-names>Q</given-names></name><name><surname>Chen</surname><given-names>Y</given-names></name><name><surname>Liu</surname><given-names>S</given-names></name><name><surname>Xu</surname><given-names>C</given-names></name><name><surname>Cao</surname><given-names>T</given-names></name><name><surname>Xu</surname><given-names>Y</given-names></name><name><surname>Wang</surname><given-names>X</given-names></name><name><surname>Rao</surname><given-names>G</given-names></name><name><surname>Li</surname><given-names>A</given-names></name><name><surname>Zeng</surname><given-names>S</given-names></name><name><surname>Quan</surname><given-names>T</given-names></name></person-group><year iso-8601-date="2020">2020</year><article-title>Weakly supervised learning of 3D deep network for neuron reconstruction</article-title><source>Frontiers in Neuroanatomy</source><volume>14</volume><elocation-id>38</elocation-id><pub-id pub-id-type="doi">10.3389/fnana.2020.00038</pub-id><pub-id pub-id-type="pmid">32848636</pub-id></element-citation></ref><ref id="bib16"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Jaqaman</surname><given-names>K</given-names></name><name><surname>Loerke</surname><given-names>D</given-names></name><name><surname>Mettlen</surname><given-names>M</given-names></name><name><surname>Kuwata</surname><given-names>H</given-names></name><name><surname>Grinstein</surname><given-names>S</given-names></name><name><surname>Schmid</surname><given-names>SL</given-names></name><name><surname>Danuser</surname><given-names>G</given-names></name></person-group><year iso-8601-date="2008">2008</year><article-title>Robust single-particle tracking in live-cell time-lapse sequences</article-title><source>Nature Methods</source><volume>5</volume><fpage>695</fpage><lpage>702</lpage><pub-id pub-id-type="doi">10.1038/nmeth.1237</pub-id><pub-id pub-id-type="pmid">18641657</pub-id></element-citation></ref><ref id="bib17"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kim</surname><given-names>TH</given-names></name><name><surname>Schnitzer</surname><given-names>MJ</given-names></name></person-group><year iso-8601-date="2022">2022</year><article-title>Fluorescence imaging of large-scale neural ensemble dynamics</article-title><source>Cell</source><volume>185</volume><fpage>9</fpage><lpage>41</lpage><pub-id pub-id-type="doi">10.1016/j.cell.2021.12.007</pub-id><pub-id pub-id-type="pmid">34995519</pub-id></element-citation></ref><ref id="bib18"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Li</surname><given-names>A</given-names></name><name><surname>Gong</surname><given-names>H</given-names></name><name><surname>Zhang</surname><given-names>B</given-names></name><name><surname>Wang</surname><given-names>Q</given-names></name><name><surname>Yan</surname><given-names>C</given-names></name><name><surname>Wu</surname><given-names>J</given-names></name><name><surname>Liu</surname><given-names>Q</given-names></name><name><surname>Zeng</surname><given-names>S</given-names></name><name><surname>Luo</surname><given-names>Q</given-names></name></person-group><year iso-8601-date="2010">2010</year><article-title>Micro-optical sectioning tomography to obtain a high-resolution atlas of the mouse brain</article-title><source>Science</source><volume>330</volume><fpage>1404</fpage><lpage>1408</lpage><pub-id pub-id-type="doi">10.1126/science.1191776</pub-id><pub-id pub-id-type="pmid">21051596</pub-id></element-citation></ref><ref id="bib19"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Li</surname><given-names>R</given-names></name><name><surname>Zhu</surname><given-names>M</given-names></name><name><surname>Li</surname><given-names>J</given-names></name><name><surname>Bienkowski</surname><given-names>MS</given-names></name><name><surname>Foster</surname><given-names>NN</given-names></name><name><surname>Xu</surname><given-names>H</given-names></name><name><surname>Ard</surname><given-names>T</given-names></name><name><surname>Bowman</surname><given-names>I</given-names></name><name><surname>Zhou</surname><given-names>C</given-names></name><name><surname>Veldman</surname><given-names>MB</given-names></name><name><surname>Yang</surname><given-names>XW</given-names></name><name><surname>Hintiryan</surname><given-names>H</given-names></name><name><surname>Zhang</surname><given-names>J</given-names></name><name><surname>Dong</surname><given-names>H-W</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>Precise segmentation of densely interweaving neuron clusters using G-Cut</article-title><source>Nature Communications</source><volume>10</volume><elocation-id>1549</elocation-id><pub-id pub-id-type="doi">10.1038/s41467-019-09515-0</pub-id></element-citation></ref><ref id="bib20"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Li</surname><given-names>S</given-names></name><name><surname>Quan</surname><given-names>T</given-names></name><name><surname>Zhou</surname><given-names>H</given-names></name><name><surname>Huang</surname><given-names>Q</given-names></name><name><surname>Guan</surname><given-names>T</given-names></name><name><surname>Chen</surname><given-names>Y</given-names></name><name><surname>Xu</surname><given-names>C</given-names></name><name><surname>Kang</surname><given-names>H</given-names></name><name><surname>Li</surname><given-names>A</given-names></name><name><surname>Fu</surname><given-names>L</given-names></name><name><surname>Luo</surname><given-names>Q</given-names></name><name><surname>Gong</surname><given-names>H</given-names></name><name><surname>Zeng</surname><given-names>S</given-names></name></person-group><year iso-8601-date="2020">2020</year><article-title>Brain-wide shape reconstruction of a traced neuron using the convex image segmentation method</article-title><source>Neuroinformatics</source><volume>18</volume><fpage>199</fpage><lpage>218</lpage><pub-id pub-id-type="doi">10.1007/s12021-019-09434-x</pub-id><pub-id pub-id-type="pmid">31396858</pub-id></element-citation></ref><ref id="bib21"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Li</surname><given-names>Q</given-names></name><name><surname>Shen</surname><given-names>L</given-names></name></person-group><year iso-8601-date="2020">2020</year><article-title>3D neuron reconstruction in tangled neuronal image with deep networks</article-title><source>IEEE Transactions on Medical Imaging</source><volume>39</volume><fpage>425</fpage><lpage>435</lpage><pub-id pub-id-type="doi">10.1109/TMI.2019.2926568</pub-id><pub-id pub-id-type="pmid">31295108</pub-id></element-citation></ref><ref id="bib22"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Lichtman</surname><given-names>JW</given-names></name><name><surname>Denk</surname><given-names>W</given-names></name></person-group><year iso-8601-date="2011">2011</year><article-title>The big and the small: challenges of imaging the brain’s circuits</article-title><source>Science</source><volume>334</volume><fpage>618</fpage><lpage>623</lpage><pub-id pub-id-type="doi">10.1126/science.1209168</pub-id><pub-id pub-id-type="pmid">22053041</pub-id></element-citation></ref><ref id="bib23"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Liu</surname><given-names>Y</given-names></name><name><surname>Wang</surname><given-names>G</given-names></name><name><surname>Ascoli</surname><given-names>GA</given-names></name><name><surname>Zhou</surname><given-names>J</given-names></name><name><surname>Liu</surname><given-names>L</given-names></name></person-group><year iso-8601-date="2022">2022</year><article-title>Neuron tracing from light microscopy images: automation, deep learning and bench testing</article-title><source>Bioinformatics</source><volume>38</volume><fpage>5329</fpage><lpage>5339</lpage><pub-id pub-id-type="doi">10.1093/bioinformatics/btac712</pub-id></element-citation></ref><ref id="bib24"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Manubens-Gil</surname><given-names>L</given-names></name><name><surname>Zhou</surname><given-names>Z</given-names></name><name><surname>Chen</surname><given-names>H</given-names></name><name><surname>Ramanathan</surname><given-names>A</given-names></name><name><surname>Liu</surname><given-names>X</given-names></name><name><surname>Liu</surname><given-names>Y</given-names></name><name><surname>Bria</surname><given-names>A</given-names></name><name><surname>Gillette</surname><given-names>T</given-names></name><name><surname>Ruan</surname><given-names>Z</given-names></name><name><surname>Yang</surname><given-names>J</given-names></name><name><surname>Radojević</surname><given-names>M</given-names></name><name><surname>Zhao</surname><given-names>T</given-names></name><name><surname>Cheng</surname><given-names>L</given-names></name><name><surname>Qu</surname><given-names>L</given-names></name><name><surname>Liu</surname><given-names>S</given-names></name><name><surname>Bouchard</surname><given-names>KE</given-names></name><name><surname>Gu</surname><given-names>L</given-names></name><name><surname>Cai</surname><given-names>W</given-names></name><name><surname>Ji</surname><given-names>S</given-names></name><name><surname>Roysam</surname><given-names>B</given-names></name><name><surname>Wang</surname><given-names>C-W</given-names></name><name><surname>Yu</surname><given-names>H</given-names></name><name><surname>Sironi</surname><given-names>A</given-names></name><name><surname>Iascone</surname><given-names>DM</given-names></name><name><surname>Zhou</surname><given-names>J</given-names></name><name><surname>Bas</surname><given-names>E</given-names></name><name><surname>Conde-Sousa</surname><given-names>E</given-names></name><name><surname>Aguiar</surname><given-names>P</given-names></name><name><surname>Li</surname><given-names>X</given-names></name><name><surname>Li</surname><given-names>Y</given-names></name><name><surname>Nanda</surname><given-names>S</given-names></name><name><surname>Wang</surname><given-names>Y</given-names></name><name><surname>Muresan</surname><given-names>L</given-names></name><name><surname>Fua</surname><given-names>P</given-names></name><name><surname>Ye</surname><given-names>B</given-names></name><name><surname>He</surname><given-names>H-Y</given-names></name><name><surname>Staiger</surname><given-names>JF</given-names></name><name><surname>Peter</surname><given-names>M</given-names></name><name><surname>Cox</surname><given-names>DN</given-names></name><name><surname>Simonneau</surname><given-names>M</given-names></name><name><surname>Oberlaender</surname><given-names>M</given-names></name><name><surname>Jefferis</surname><given-names>G</given-names></name><name><surname>Ito</surname><given-names>K</given-names></name><name><surname>Gonzalez-Bellido</surname><given-names>P</given-names></name><name><surname>Kim</surname><given-names>J</given-names></name><name><surname>Rubel</surname><given-names>E</given-names></name><name><surname>Cline</surname><given-names>HT</given-names></name><name><surname>Zeng</surname><given-names>H</given-names></name><name><surname>Nern</surname><given-names>A</given-names></name><name><surname>Chiang</surname><given-names>A-S</given-names></name><name><surname>Yao</surname><given-names>J</given-names></name><name><surname>Roskams</surname><given-names>J</given-names></name><name><surname>Livesey</surname><given-names>R</given-names></name><name><surname>Stevens</surname><given-names>J</given-names></name><name><surname>Liu</surname><given-names>T</given-names></name><name><surname>Dang</surname><given-names>C</given-names></name><name><surname>Guo</surname><given-names>Y</given-names></name><name><surname>Zhong</surname><given-names>N</given-names></name><name><surname>Tourassi</surname><given-names>G</given-names></name><name><surname>Hill</surname><given-names>S</given-names></name><name><surname>Hawrylycz</surname><given-names>M</given-names></name><name><surname>Koch</surname><given-names>C</given-names></name><name><surname>Meijering</surname><given-names>E</given-names></name><name><surname>Ascoli</surname><given-names>GA</given-names></name><name><surname>Peng</surname><given-names>H</given-names></name></person-group><year iso-8601-date="2023">2023</year><article-title>BigNeuron: a resource to benchmark and predict performance of algorithms for automated tracing of neurons in light microscopy datasets</article-title><source>Nature Methods</source><volume>20</volume><fpage>824</fpage><lpage>835</lpage><pub-id pub-id-type="doi">10.1038/s41592-023-01848-5</pub-id><pub-id pub-id-type="pmid">37069271</pub-id></element-citation></ref><ref id="bib25"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>McLachlan</surname><given-names>GJ</given-names></name><name><surname>Krishnan</surname><given-names>T</given-names></name></person-group><year iso-8601-date="2007">2007</year><source>The EM Algorithm and Extensions</source><publisher-name>John Wiley &amp; Sons</publisher-name><pub-id pub-id-type="doi">10.1002/9780470191613</pub-id></element-citation></ref><ref id="bib26"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Meijering</surname><given-names>E</given-names></name></person-group><year iso-8601-date="2010">2010</year><article-title>Neuron tracing in perspective</article-title><source>Cytometry. Part A</source><volume>77</volume><fpage>693</fpage><lpage>704</lpage><pub-id pub-id-type="doi">10.1002/cyto.a.20895</pub-id><pub-id pub-id-type="pmid">20583273</pub-id></element-citation></ref><ref id="bib27"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Muñoz-Castañeda</surname><given-names>R</given-names></name><name><surname>Zingg</surname><given-names>B</given-names></name><name><surname>Matho</surname><given-names>KS</given-names></name><name><surname>Chen</surname><given-names>X</given-names></name><name><surname>Wang</surname><given-names>Q</given-names></name><name><surname>Foster</surname><given-names>NN</given-names></name><name><surname>Li</surname><given-names>A</given-names></name><name><surname>Narasimhan</surname><given-names>A</given-names></name><name><surname>Hirokawa</surname><given-names>KE</given-names></name><name><surname>Huo</surname><given-names>B</given-names></name><name><surname>Bannerjee</surname><given-names>S</given-names></name><name><surname>Korobkova</surname><given-names>L</given-names></name><name><surname>Park</surname><given-names>CS</given-names></name><name><surname>Park</surname><given-names>Y-G</given-names></name><name><surname>Bienkowski</surname><given-names>MS</given-names></name><name><surname>Chon</surname><given-names>U</given-names></name><name><surname>Wheeler</surname><given-names>DW</given-names></name><name><surname>Li</surname><given-names>X</given-names></name><name><surname>Wang</surname><given-names>Y</given-names></name><name><surname>Naeemi</surname><given-names>M</given-names></name><name><surname>Xie</surname><given-names>P</given-names></name><name><surname>Liu</surname><given-names>L</given-names></name><name><surname>Kelly</surname><given-names>K</given-names></name><name><surname>An</surname><given-names>X</given-names></name><name><surname>Attili</surname><given-names>SM</given-names></name><name><surname>Bowman</surname><given-names>I</given-names></name><name><surname>Bludova</surname><given-names>A</given-names></name><name><surname>Cetin</surname><given-names>A</given-names></name><name><surname>Ding</surname><given-names>L</given-names></name><name><surname>Drewes</surname><given-names>R</given-names></name><name><surname>D’Orazi</surname><given-names>F</given-names></name><name><surname>Elowsky</surname><given-names>C</given-names></name><name><surname>Fischer</surname><given-names>S</given-names></name><name><surname>Galbavy</surname><given-names>W</given-names></name><name><surname>Gao</surname><given-names>L</given-names></name><name><surname>Gillis</surname><given-names>J</given-names></name><name><surname>Groblewski</surname><given-names>PA</given-names></name><name><surname>Gou</surname><given-names>L</given-names></name><name><surname>Hahn</surname><given-names>JD</given-names></name><name><surname>Hatfield</surname><given-names>JT</given-names></name><name><surname>Hintiryan</surname><given-names>H</given-names></name><name><surname>Huang</surname><given-names>JJ</given-names></name><name><surname>Kondo</surname><given-names>H</given-names></name><name><surname>Kuang</surname><given-names>X</given-names></name><name><surname>Lesnar</surname><given-names>P</given-names></name><name><surname>Li</surname><given-names>X</given-names></name><name><surname>Li</surname><given-names>Y</given-names></name><name><surname>Lin</surname><given-names>M</given-names></name><name><surname>Lo</surname><given-names>D</given-names></name><name><surname>Mizrachi</surname><given-names>J</given-names></name><name><surname>Mok</surname><given-names>S</given-names></name><name><surname>Nicovich</surname><given-names>PR</given-names></name><name><surname>Palaniswamy</surname><given-names>R</given-names></name><name><surname>Palmer</surname><given-names>J</given-names></name><name><surname>Qi</surname><given-names>X</given-names></name><name><surname>Shen</surname><given-names>E</given-names></name><name><surname>Sun</surname><given-names>Y-C</given-names></name><name><surname>Tao</surname><given-names>HW</given-names></name><name><surname>Wakemen</surname><given-names>W</given-names></name><name><surname>Wang</surname><given-names>Y</given-names></name><name><surname>Yao</surname><given-names>S</given-names></name><name><surname>Yuan</surname><given-names>J</given-names></name><name><surname>Zhan</surname><given-names>H</given-names></name><name><surname>Zhu</surname><given-names>M</given-names></name><name><surname>Ng</surname><given-names>L</given-names></name><name><surname>Zhang</surname><given-names>LI</given-names></name><name><surname>Lim</surname><given-names>BK</given-names></name><name><surname>Hawrylycz</surname><given-names>M</given-names></name><name><surname>Gong</surname><given-names>H</given-names></name><name><surname>Gee</surname><given-names>JC</given-names></name><name><surname>Kim</surname><given-names>Y</given-names></name><name><surname>Chung</surname><given-names>K</given-names></name><name><surname>Yang</surname><given-names>XW</given-names></name><name><surname>Peng</surname><given-names>H</given-names></name><name><surname>Luo</surname><given-names>Q</given-names></name><name><surname>Mitra</surname><given-names>PP</given-names></name><name><surname>Zador</surname><given-names>AM</given-names></name><name><surname>Zeng</surname><given-names>H</given-names></name><name><surname>Ascoli</surname><given-names>GA</given-names></name><name><surname>Josh Huang</surname><given-names>Z</given-names></name><name><surname>Osten</surname><given-names>P</given-names></name><name><surname>Harris</surname><given-names>JA</given-names></name><name><surname>Dong</surname><given-names>H-W</given-names></name></person-group><year iso-8601-date="2021">2021</year><article-title>Cellular anatomy of the mouse primary motor cortex</article-title><source>Nature</source><volume>598</volume><fpage>159</fpage><lpage>166</lpage><pub-id pub-id-type="doi">10.1038/s41586-021-03970-w</pub-id><pub-id pub-id-type="pmid">34616071</pub-id></element-citation></ref><ref id="bib28"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Osten</surname><given-names>P</given-names></name><name><surname>Margrie</surname><given-names>TW</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>Mapping brain circuitry with a light microscope</article-title><source>Nature Methods</source><volume>10</volume><fpage>515</fpage><lpage>523</lpage><pub-id pub-id-type="doi">10.1038/nmeth.2477</pub-id><pub-id pub-id-type="pmid">23722211</pub-id></element-citation></ref><ref id="bib29"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Parekh</surname><given-names>R</given-names></name><name><surname>Ascoli</surname><given-names>GA</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>Neuronal morphology goes digital: a research hub for cellular and system neuroscience</article-title><source>Neuron</source><volume>77</volume><fpage>1017</fpage><lpage>1038</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2013.03.008</pub-id><pub-id pub-id-type="pmid">23522039</pub-id></element-citation></ref><ref id="bib30"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Peng</surname><given-names>H</given-names></name><name><surname>Long</surname><given-names>F</given-names></name><name><surname>Myers</surname><given-names>G</given-names></name></person-group><year iso-8601-date="2011">2011</year><article-title>Automatic 3D neuron tracing using all-path pruning</article-title><source>Bioinformatics</source><volume>27</volume><fpage>i239</fpage><lpage>i247</lpage><pub-id pub-id-type="doi">10.1093/bioinformatics/btr237</pub-id><pub-id pub-id-type="pmid">21685076</pub-id></element-citation></ref><ref id="bib31"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Peng</surname><given-names>H</given-names></name><name><surname>Hawrylycz</surname><given-names>M</given-names></name><name><surname>Roskams</surname><given-names>J</given-names></name><name><surname>Hill</surname><given-names>S</given-names></name><name><surname>Spruston</surname><given-names>N</given-names></name><name><surname>Meijering</surname><given-names>E</given-names></name><name><surname>Ascoli</surname><given-names>GA</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>BigNeuron: large-scale 3D neuron reconstruction from optical microscopy images</article-title><source>Neuron</source><volume>87</volume><fpage>252</fpage><lpage>256</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2015.06.036</pub-id><pub-id pub-id-type="pmid">26182412</pub-id></element-citation></ref><ref id="bib32"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Peng</surname><given-names>H</given-names></name><name><surname>Xie</surname><given-names>P</given-names></name><name><surname>Liu</surname><given-names>L</given-names></name><name><surname>Kuang</surname><given-names>X</given-names></name><name><surname>Wang</surname><given-names>Y</given-names></name><name><surname>Qu</surname><given-names>L</given-names></name><name><surname>Gong</surname><given-names>H</given-names></name><name><surname>Jiang</surname><given-names>S</given-names></name><name><surname>Li</surname><given-names>A</given-names></name><name><surname>Ruan</surname><given-names>Z</given-names></name><name><surname>Ding</surname><given-names>L</given-names></name><name><surname>Yao</surname><given-names>Z</given-names></name><name><surname>Chen</surname><given-names>C</given-names></name><name><surname>Chen</surname><given-names>M</given-names></name><name><surname>Daigle</surname><given-names>TL</given-names></name><name><surname>Dalley</surname><given-names>R</given-names></name><name><surname>Ding</surname><given-names>Z</given-names></name><name><surname>Duan</surname><given-names>Y</given-names></name><name><surname>Feiner</surname><given-names>A</given-names></name><name><surname>He</surname><given-names>P</given-names></name><name><surname>Hill</surname><given-names>C</given-names></name><name><surname>Hirokawa</surname><given-names>KE</given-names></name><name><surname>Hong</surname><given-names>G</given-names></name><name><surname>Huang</surname><given-names>L</given-names></name><name><surname>Kebede</surname><given-names>S</given-names></name><name><surname>Kuo</surname><given-names>H-C</given-names></name><name><surname>Larsen</surname><given-names>R</given-names></name><name><surname>Lesnar</surname><given-names>P</given-names></name><name><surname>Li</surname><given-names>L</given-names></name><name><surname>Li</surname><given-names>Q</given-names></name><name><surname>Li</surname><given-names>X</given-names></name><name><surname>Li</surname><given-names>Y</given-names></name><name><surname>Li</surname><given-names>Y</given-names></name><name><surname>Liu</surname><given-names>A</given-names></name><name><surname>Lu</surname><given-names>D</given-names></name><name><surname>Mok</surname><given-names>S</given-names></name><name><surname>Ng</surname><given-names>L</given-names></name><name><surname>Nguyen</surname><given-names>TN</given-names></name><name><surname>Ouyang</surname><given-names>Q</given-names></name><name><surname>Pan</surname><given-names>J</given-names></name><name><surname>Shen</surname><given-names>E</given-names></name><name><surname>Song</surname><given-names>Y</given-names></name><name><surname>Sunkin</surname><given-names>SM</given-names></name><name><surname>Tasic</surname><given-names>B</given-names></name><name><surname>Veldman</surname><given-names>MB</given-names></name><name><surname>Wakeman</surname><given-names>W</given-names></name><name><surname>Wan</surname><given-names>W</given-names></name><name><surname>Wang</surname><given-names>P</given-names></name><name><surname>Wang</surname><given-names>Q</given-names></name><name><surname>Wang</surname><given-names>T</given-names></name><name><surname>Wang</surname><given-names>Y</given-names></name><name><surname>Xiong</surname><given-names>F</given-names></name><name><surname>Xiong</surname><given-names>W</given-names></name><name><surname>Xu</surname><given-names>W</given-names></name><name><surname>Ye</surname><given-names>M</given-names></name><name><surname>Yin</surname><given-names>L</given-names></name><name><surname>Yu</surname><given-names>Y</given-names></name><name><surname>Yuan</surname><given-names>J</given-names></name><name><surname>Yuan</surname><given-names>J</given-names></name><name><surname>Yun</surname><given-names>Z</given-names></name><name><surname>Zeng</surname><given-names>S</given-names></name><name><surname>Zhang</surname><given-names>S</given-names></name><name><surname>Zhao</surname><given-names>S</given-names></name><name><surname>Zhao</surname><given-names>Z</given-names></name><name><surname>Zhou</surname><given-names>Z</given-names></name><name><surname>Huang</surname><given-names>ZJ</given-names></name><name><surname>Esposito</surname><given-names>L</given-names></name><name><surname>Hawrylycz</surname><given-names>MJ</given-names></name><name><surname>Sorensen</surname><given-names>SA</given-names></name><name><surname>Yang</surname><given-names>XW</given-names></name><name><surname>Zheng</surname><given-names>Y</given-names></name><name><surname>Gu</surname><given-names>Z</given-names></name><name><surname>Xie</surname><given-names>W</given-names></name><name><surname>Koch</surname><given-names>C</given-names></name><name><surname>Luo</surname><given-names>Q</given-names></name><name><surname>Harris</surname><given-names>JA</given-names></name><name><surname>Wang</surname><given-names>Y</given-names></name><name><surname>Zeng</surname><given-names>H</given-names></name></person-group><year iso-8601-date="2021">2021</year><article-title>Morphological diversity of single neurons in molecularly defined cell types</article-title><source>Nature</source><volume>598</volume><fpage>174</fpage><lpage>181</lpage><pub-id pub-id-type="doi">10.1038/s41586-021-03941-1</pub-id><pub-id pub-id-type="pmid">34616072</pub-id></element-citation></ref><ref id="bib33"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Qiu</surname><given-names>S</given-names></name><name><surname>Hu</surname><given-names>Y</given-names></name><name><surname>Huang</surname><given-names>Y</given-names></name><name><surname>Gao</surname><given-names>T</given-names></name><name><surname>Wang</surname><given-names>X</given-names></name><name><surname>Wang</surname><given-names>D</given-names></name><name><surname>Ren</surname><given-names>B</given-names></name><name><surname>Shi</surname><given-names>X</given-names></name><name><surname>Chen</surname><given-names>Y</given-names></name><name><surname>Wang</surname><given-names>X</given-names></name><name><surname>Wang</surname><given-names>D</given-names></name><name><surname>Han</surname><given-names>L</given-names></name><name><surname>Liang</surname><given-names>Y</given-names></name><name><surname>Liu</surname><given-names>D</given-names></name><name><surname>Liu</surname><given-names>Q</given-names></name><name><surname>Deng</surname><given-names>L</given-names></name><name><surname>Chen</surname><given-names>Z</given-names></name><name><surname>Zhan</surname><given-names>L</given-names></name><name><surname>Chen</surname><given-names>T</given-names></name><name><surname>Huang</surname><given-names>Y</given-names></name><name><surname>Wu</surname><given-names>Q</given-names></name><name><surname>Xie</surname><given-names>T</given-names></name><name><surname>Qian</surname><given-names>L</given-names></name><name><surname>Jin</surname><given-names>C</given-names></name><name><surname>Huang</surname><given-names>J</given-names></name><name><surname>Deng</surname><given-names>W</given-names></name><name><surname>Jiang</surname><given-names>T</given-names></name><name><surname>Li</surname><given-names>X</given-names></name><name><surname>Jia</surname><given-names>X</given-names></name><name><surname>Yuan</surname><given-names>J</given-names></name><name><surname>Li</surname><given-names>A</given-names></name><name><surname>Yan</surname><given-names>J</given-names></name><name><surname>Xu</surname><given-names>N</given-names></name><name><surname>Xu</surname><given-names>L</given-names></name><name><surname>Luo</surname><given-names>Q</given-names></name><name><surname>Poo</surname><given-names>M-M</given-names></name><name><surname>Sun</surname><given-names>Y</given-names></name><name><surname>Li</surname><given-names>CT</given-names></name><name><surname>Yao</surname><given-names>H</given-names></name><name><surname>Gong</surname><given-names>H</given-names></name><name><surname>Sun</surname><given-names>Y-G</given-names></name><name><surname>Xu</surname><given-names>C</given-names></name></person-group><year iso-8601-date="2024">2024</year><article-title>Whole-brain spatial organization of hippocampal single-neuron projectomes</article-title><source>Science</source><volume>383</volume><elocation-id>eadj9198</elocation-id><pub-id pub-id-type="doi">10.1126/science.adj9198</pub-id><pub-id pub-id-type="pmid">38300992</pub-id></element-citation></ref><ref id="bib34"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Quan</surname><given-names>T</given-names></name><name><surname>Zhou</surname><given-names>H</given-names></name><name><surname>Li</surname><given-names>J</given-names></name><name><surname>Li</surname><given-names>S</given-names></name><name><surname>Li</surname><given-names>A</given-names></name><name><surname>Li</surname><given-names>Y</given-names></name><name><surname>Lv</surname><given-names>X</given-names></name><name><surname>Luo</surname><given-names>Q</given-names></name><name><surname>Gong</surname><given-names>H</given-names></name><name><surname>Zeng</surname><given-names>S</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>NeuroGPS-Tree: automatic reconstruction of large-scale neuronal populations with dense neurites</article-title><source>Nature Methods</source><volume>13</volume><fpage>51</fpage><lpage>54</lpage><pub-id pub-id-type="doi">10.1038/nmeth.3662</pub-id><pub-id pub-id-type="pmid">26595210</pub-id></element-citation></ref><ref id="bib35"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Radojevic</surname><given-names>M</given-names></name><name><surname>Meijering</surname><given-names>E</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>Automated neuron tracing using probability hypothesis density filtering</article-title><source>Bioinformatics</source><volume>33</volume><fpage>1073</fpage><lpage>1080</lpage><pub-id pub-id-type="doi">10.1093/bioinformatics/btw751</pub-id><pub-id pub-id-type="pmid">28065895</pub-id></element-citation></ref><ref id="bib36"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Reynolds</surname><given-names>DA</given-names></name></person-group><year iso-8601-date="2009">2009</year><chapter-title>Gaussian mixture models</chapter-title><person-group person-group-type="editor"><name><surname>Li</surname><given-names>SZ</given-names></name><name><surname>Jain</surname><given-names>A</given-names></name></person-group><source>Encyclopedia of Biometrics</source><publisher-name>Springer</publisher-name><fpage>659</fpage><lpage>663</lpage><pub-id pub-id-type="doi">10.1007/978-0-387-73003-5_196</pub-id></element-citation></ref><ref id="bib37"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Stelzer</surname><given-names>EHK</given-names></name><name><surname>Strobl</surname><given-names>F</given-names></name><name><surname>Chang</surname><given-names>B-J</given-names></name><name><surname>Preusser</surname><given-names>F</given-names></name><name><surname>Preibisch</surname><given-names>S</given-names></name><name><surname>McDole</surname><given-names>K</given-names></name><name><surname>Fiolka</surname><given-names>R</given-names></name></person-group><year iso-8601-date="2021">2021</year><article-title>Light sheet fluorescence microscopy</article-title><source>Nature Reviews Methods Primers</source><volume>1</volume><elocation-id>73</elocation-id><pub-id pub-id-type="doi">10.1038/s43586-021-00069-4</pub-id></element-citation></ref><ref id="bib38"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Sun</surname><given-names>P</given-names></name><name><surname>Freund</surname><given-names>RM</given-names></name></person-group><year iso-8601-date="2004">2004</year><article-title>Computation of minimum-volume covering ellipsoids</article-title><source>Operations Research</source><volume>52</volume><fpage>690</fpage><lpage>706</lpage><pub-id pub-id-type="doi">10.1287/opre.1040.0115</pub-id></element-citation></ref><ref id="bib39"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Sun</surname><given-names>Q</given-names></name><name><surname>Li</surname><given-names>X</given-names></name><name><surname>Ren</surname><given-names>M</given-names></name><name><surname>Zhao</surname><given-names>M</given-names></name><name><surname>Zhong</surname><given-names>Q</given-names></name><name><surname>Ren</surname><given-names>Y</given-names></name><name><surname>Luo</surname><given-names>P</given-names></name><name><surname>Ni</surname><given-names>H</given-names></name><name><surname>Zhang</surname><given-names>X</given-names></name><name><surname>Zhang</surname><given-names>C</given-names></name><name><surname>Yuan</surname><given-names>J</given-names></name><name><surname>Li</surname><given-names>A</given-names></name><name><surname>Luo</surname><given-names>M</given-names></name><name><surname>Gong</surname><given-names>H</given-names></name><name><surname>Luo</surname><given-names>Q</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>A whole-brain map of long-range inputs to GABAergic interneurons in the mouse medial prefrontal cortex</article-title><source>Nature Neuroscience</source><volume>22</volume><fpage>1357</fpage><lpage>1370</lpage><pub-id pub-id-type="doi">10.1038/s41593-019-0429-9</pub-id><pub-id pub-id-type="pmid">31285615</pub-id></element-citation></ref><ref id="bib40"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Türetken</surname><given-names>E</given-names></name><name><surname>González</surname><given-names>G</given-names></name><name><surname>Blum</surname><given-names>C</given-names></name><name><surname>Fua</surname><given-names>P</given-names></name></person-group><year iso-8601-date="2011">2011</year><article-title>Automated reconstruction of dendritic and axonal trees by global optimization with geometric priors</article-title><source>Neuroinformatics</source><volume>9</volume><fpage>279</fpage><lpage>302</lpage><pub-id pub-id-type="doi">10.1007/s12021-011-9122-1</pub-id><pub-id pub-id-type="pmid">21573886</pub-id></element-citation></ref><ref id="bib41"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Volgenant</surname><given-names>A</given-names></name></person-group><year iso-8601-date="1996">1996</year><article-title>Linear and semi-assignment problems: a core oriented approach</article-title><source>Computers &amp; Operations Research</source><volume>23</volume><fpage>917</fpage><lpage>932</lpage><pub-id pub-id-type="doi">10.1016/0305-0548(96)00010-X</pub-id></element-citation></ref><ref id="bib42"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wang</surname><given-names>Y</given-names></name><name><surname>Li</surname><given-names>Q</given-names></name><name><surname>Liu</surname><given-names>L</given-names></name><name><surname>Zhou</surname><given-names>Z</given-names></name><name><surname>Ruan</surname><given-names>Z</given-names></name><name><surname>Kong</surname><given-names>L</given-names></name><name><surname>Li</surname><given-names>Y</given-names></name><name><surname>Wang</surname><given-names>Y</given-names></name><name><surname>Zhong</surname><given-names>N</given-names></name><name><surname>Chai</surname><given-names>R</given-names></name><name><surname>Luo</surname><given-names>X</given-names></name><name><surname>Guo</surname><given-names>Y</given-names></name><name><surname>Hawrylycz</surname><given-names>M</given-names></name><name><surname>Luo</surname><given-names>Q</given-names></name><name><surname>Gu</surname><given-names>Z</given-names></name><name><surname>Xie</surname><given-names>W</given-names></name><name><surname>Zeng</surname><given-names>H</given-names></name><name><surname>Peng</surname><given-names>H</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>TeraVR empowers precise reconstruction of complete 3-D neuronal morphology in the whole brain</article-title><source>Nature Communications</source><volume>10</volume><elocation-id>3474</elocation-id><pub-id pub-id-type="doi">10.1038/s41467-019-11443-y</pub-id></element-citation></ref><ref id="bib43"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wang</surname><given-names>X</given-names></name><name><surname>Xiong</surname><given-names>H</given-names></name><name><surname>Liu</surname><given-names>Y</given-names></name><name><surname>Yang</surname><given-names>T</given-names></name><name><surname>Li</surname><given-names>A</given-names></name><name><surname>Huang</surname><given-names>F</given-names></name><name><surname>Yin</surname><given-names>F</given-names></name><name><surname>Su</surname><given-names>L</given-names></name><name><surname>Liu</surname><given-names>L</given-names></name><name><surname>Li</surname><given-names>N</given-names></name><name><surname>Li</surname><given-names>L</given-names></name><name><surname>Cheng</surname><given-names>S</given-names></name><name><surname>Liu</surname><given-names>X</given-names></name><name><surname>Lv</surname><given-names>X</given-names></name><name><surname>Liu</surname><given-names>X</given-names></name><name><surname>Chu</surname><given-names>J</given-names></name><name><surname>Xu</surname><given-names>T</given-names></name><name><surname>Xu</surname><given-names>F</given-names></name><name><surname>Gong</surname><given-names>H</given-names></name><name><surname>Luo</surname><given-names>Q</given-names></name><name><surname>Yuan</surname><given-names>J</given-names></name><name><surname>Zeng</surname><given-names>S</given-names></name></person-group><year iso-8601-date="2021">2021</year><article-title>Chemical sectioning fluorescence tomography: high-throughput, high-contrast, multicolor, whole-brain imaging at subcellular resolution</article-title><source>Cell Reports</source><volume>34</volume><elocation-id>108709</elocation-id><pub-id pub-id-type="doi">10.1016/j.celrep.2021.108709</pub-id></element-citation></ref><ref id="bib44"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wei</surname><given-names>X</given-names></name><name><surname>Peng</surname><given-names>M</given-names></name><name><surname>Huang</surname><given-names>H</given-names></name><name><surname>Zhou</surname><given-names>Y</given-names></name></person-group><year iso-8601-date="2023">2023</year><article-title>An overview on density peaks clustering</article-title><source>Neurocomputing</source><volume>554</volume><elocation-id>126633</elocation-id><pub-id pub-id-type="doi">10.1016/j.neucom.2023.126633</pub-id></element-citation></ref><ref id="bib45"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Winnubst</surname><given-names>J</given-names></name><name><surname>Bas</surname><given-names>E</given-names></name><name><surname>Ferreira</surname><given-names>TA</given-names></name><name><surname>Wu</surname><given-names>Z</given-names></name><name><surname>Economo</surname><given-names>MN</given-names></name><name><surname>Edson</surname><given-names>P</given-names></name><name><surname>Arthur</surname><given-names>BJ</given-names></name><name><surname>Bruns</surname><given-names>C</given-names></name><name><surname>Rokicki</surname><given-names>K</given-names></name><name><surname>Schauder</surname><given-names>D</given-names></name><name><surname>Olbris</surname><given-names>DJ</given-names></name><name><surname>Murphy</surname><given-names>SD</given-names></name><name><surname>Ackerman</surname><given-names>DG</given-names></name><name><surname>Arshadi</surname><given-names>C</given-names></name><name><surname>Baldwin</surname><given-names>P</given-names></name><name><surname>Blake</surname><given-names>R</given-names></name><name><surname>Elsayed</surname><given-names>A</given-names></name><name><surname>Hasan</surname><given-names>M</given-names></name><name><surname>Ramirez</surname><given-names>D</given-names></name><name><surname>Dos Santos</surname><given-names>B</given-names></name><name><surname>Weldon</surname><given-names>M</given-names></name><name><surname>Zafar</surname><given-names>A</given-names></name><name><surname>Dudman</surname><given-names>JT</given-names></name><name><surname>Gerfen</surname><given-names>CR</given-names></name><name><surname>Hantman</surname><given-names>AW</given-names></name><name><surname>Korff</surname><given-names>W</given-names></name><name><surname>Sternson</surname><given-names>SM</given-names></name><name><surname>Spruston</surname><given-names>N</given-names></name><name><surname>Svoboda</surname><given-names>K</given-names></name><name><surname>Chandrashekar</surname><given-names>J</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>Reconstruction of 1,000 projection neurons reveals new cell types and organization of long-range connectivity in the mouse brain</article-title><source>Cell</source><volume>179</volume><fpage>268</fpage><lpage>281</lpage><pub-id pub-id-type="doi">10.1016/j.cell.2019.07.042</pub-id><pub-id pub-id-type="pmid">31495573</pub-id></element-citation></ref><ref id="bib46"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wu</surname><given-names>J</given-names></name><name><surname>He</surname><given-names>Y</given-names></name><name><surname>Yang</surname><given-names>Z</given-names></name><name><surname>Guo</surname><given-names>C</given-names></name><name><surname>Luo</surname><given-names>Q</given-names></name><name><surname>Zhou</surname><given-names>W</given-names></name><name><surname>Chen</surname><given-names>S</given-names></name><name><surname>Li</surname><given-names>A</given-names></name><name><surname>Xiong</surname><given-names>B</given-names></name><name><surname>Jiang</surname><given-names>T</given-names></name><name><surname>Gong</surname><given-names>H</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>3D BrainCV: simultaneous visualization and analysis of cells and capillaries in a whole mouse brain with one-micron voxel resolution</article-title><source>NeuroImage</source><volume>87</volume><fpage>199</fpage><lpage>208</lpage><pub-id pub-id-type="doi">10.1016/j.neuroimage.2013.10.036</pub-id><pub-id pub-id-type="pmid">24185025</pub-id></element-citation></ref><ref id="bib47"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Xiao</surname><given-names>H</given-names></name><name><surname>Peng</surname><given-names>H</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>APP2: automatic tracing of 3D neuron morphology based on hierarchical pruning of a gray-weighted image distance-tree</article-title><source>Bioinformatics</source><volume>29</volume><fpage>1448</fpage><lpage>1454</lpage><pub-id pub-id-type="doi">10.1093/bioinformatics/btt170</pub-id><pub-id pub-id-type="pmid">23603332</pub-id></element-citation></ref><ref id="bib48"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Xu</surname><given-names>F</given-names></name><name><surname>Shen</surname><given-names>Y</given-names></name><name><surname>Ding</surname><given-names>L</given-names></name><name><surname>Yang</surname><given-names>C-Y</given-names></name><name><surname>Tan</surname><given-names>H</given-names></name><name><surname>Wang</surname><given-names>H</given-names></name><name><surname>Zhu</surname><given-names>Q</given-names></name><name><surname>Xu</surname><given-names>R</given-names></name><name><surname>Wu</surname><given-names>F</given-names></name><name><surname>Xiao</surname><given-names>Y</given-names></name><name><surname>Xu</surname><given-names>C</given-names></name><name><surname>Li</surname><given-names>Q</given-names></name><name><surname>Su</surname><given-names>P</given-names></name><name><surname>Zhang</surname><given-names>LI</given-names></name><name><surname>Dong</surname><given-names>H-W</given-names></name><name><surname>Desimone</surname><given-names>R</given-names></name><name><surname>Xu</surname><given-names>F</given-names></name><name><surname>Hu</surname><given-names>X</given-names></name><name><surname>Lau</surname><given-names>P-M</given-names></name><name><surname>Bi</surname><given-names>G-Q</given-names></name></person-group><year iso-8601-date="2021">2021</year><article-title>High-throughput mapping of a whole rhesus monkey brain at micrometer resolution</article-title><source>Nature Biotechnology</source><volume>39</volume><fpage>1521</fpage><lpage>1528</lpage><pub-id pub-id-type="doi">10.1038/s41587-021-00986-5</pub-id><pub-id pub-id-type="pmid">34312500</pub-id></element-citation></ref><ref id="bib49"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Yang</surname><given-names>J</given-names></name><name><surname>Gonzalez-Bellido</surname><given-names>PT</given-names></name><name><surname>Peng</surname><given-names>H</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>A distance-field based automatic neuron tracing method</article-title><source>BMC Bioinformatics</source><volume>14</volume><fpage>1</fpage><lpage>11</lpage><pub-id pub-id-type="doi">10.1186/1471-2105-14-93</pub-id><pub-id pub-id-type="pmid">23497429</pub-id></element-citation></ref><ref id="bib50"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Zeng</surname><given-names>H</given-names></name><name><surname>Sanes</surname><given-names>JR</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>Neuronal cell-type classification: challenges, opportunities and the path forward</article-title><source>Nature Reviews. Neuroscience</source><volume>18</volume><fpage>530</fpage><lpage>546</lpage><pub-id pub-id-type="doi">10.1038/nrn.2017.85</pub-id><pub-id pub-id-type="pmid">28775344</pub-id></element-citation></ref><ref id="bib51"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Zeng</surname><given-names>H</given-names></name></person-group><year iso-8601-date="2022">2022</year><article-title>What is a cell type and how to define it?</article-title><source>Cell</source><volume>185</volume><fpage>2739</fpage><lpage>2755</lpage><pub-id pub-id-type="doi">10.1016/j.cell.2022.06.031</pub-id><pub-id pub-id-type="pmid">35868277</pub-id></element-citation></ref><ref id="bib52"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Zhang</surname><given-names>H</given-names></name><name><surname>Wang</surname><given-names>X</given-names></name><name><surname>Guo</surname><given-names>W</given-names></name><name><surname>Li</surname><given-names>A</given-names></name><name><surname>Chen</surname><given-names>R</given-names></name><name><surname>Huang</surname><given-names>F</given-names></name><name><surname>Liu</surname><given-names>X</given-names></name><name><surname>Chen</surname><given-names>Y</given-names></name><name><surname>Li</surname><given-names>N</given-names></name><name><surname>Liu</surname><given-names>X</given-names></name><name><surname>Xu</surname><given-names>T</given-names></name><name><surname>Xue</surname><given-names>Z</given-names></name><name><surname>Zeng</surname><given-names>S</given-names></name></person-group><year iso-8601-date="2021">2021</year><article-title>Cross-streams through the ventral posteromedial thalamic nucleus to convey vibrissal information</article-title><source>Frontiers in Neuroanatomy</source><volume>15</volume><elocation-id>724861</elocation-id><pub-id pub-id-type="doi">10.3389/fnana.2021.724861</pub-id><pub-id pub-id-type="pmid">34776879</pub-id></element-citation></ref><ref id="bib53"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Zhong</surname><given-names>Q</given-names></name><name><surname>Li</surname><given-names>A</given-names></name><name><surname>Jin</surname><given-names>R</given-names></name><name><surname>Zhang</surname><given-names>D</given-names></name><name><surname>Li</surname><given-names>X</given-names></name><name><surname>Jia</surname><given-names>X</given-names></name><name><surname>Ding</surname><given-names>Z</given-names></name><name><surname>Luo</surname><given-names>P</given-names></name><name><surname>Zhou</surname><given-names>C</given-names></name><name><surname>Jiang</surname><given-names>C</given-names></name><name><surname>Feng</surname><given-names>Z</given-names></name><name><surname>Zhang</surname><given-names>Z</given-names></name><name><surname>Gong</surname><given-names>H</given-names></name><name><surname>Yuan</surname><given-names>J</given-names></name><name><surname>Luo</surname><given-names>Q</given-names></name></person-group><year iso-8601-date="2021">2021</year><article-title>High-definition imaging using line-illumination modulation microscopy</article-title><source>Nature Methods</source><volume>18</volume><fpage>309</fpage><lpage>315</lpage><pub-id pub-id-type="doi">10.1038/s41592-021-01074-x</pub-id><pub-id pub-id-type="pmid">33649587</pub-id></element-citation></ref><ref id="bib54"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Zhou</surname><given-names>Z</given-names></name><name><surname>Kuo</surname><given-names>HC</given-names></name><name><surname>Peng</surname><given-names>H</given-names></name><name><surname>Long</surname><given-names>F</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>DeepNeuron: an open deep learning toolbox for neuron tracing</article-title><source>Brain Informatics</source><volume>5</volume><elocation-id>3</elocation-id><pub-id pub-id-type="doi">10.1186/s40708-018-0081-2</pub-id><pub-id pub-id-type="pmid">29876679</pub-id></element-citation></ref><ref id="bib55"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Zhou</surname><given-names>H</given-names></name><name><surname>Li</surname><given-names>S</given-names></name><name><surname>Li</surname><given-names>A</given-names></name><name><surname>Huang</surname><given-names>Q</given-names></name><name><surname>Xiong</surname><given-names>F</given-names></name><name><surname>Li</surname><given-names>N</given-names></name><name><surname>Han</surname><given-names>J</given-names></name><name><surname>Kang</surname><given-names>H</given-names></name><name><surname>Chen</surname><given-names>Y</given-names></name><name><surname>Li</surname><given-names>Y</given-names></name><name><surname>Lin</surname><given-names>H</given-names></name><name><surname>Zhang</surname><given-names>Y-H</given-names></name><name><surname>Lv</surname><given-names>X</given-names></name><name><surname>Liu</surname><given-names>X</given-names></name><name><surname>Gong</surname><given-names>H</given-names></name><name><surname>Luo</surname><given-names>Q</given-names></name><name><surname>Zeng</surname><given-names>S</given-names></name><name><surname>Quan</surname><given-names>T</given-names></name></person-group><year iso-8601-date="2021">2021</year><article-title>GTree: an open-source tool for dense reconstruction of brain-wide neuronal population</article-title><source>Neuroinformatics</source><volume>19</volume><fpage>305</fpage><lpage>317</lpage><pub-id pub-id-type="doi">10.1007/s12021-020-09484-6</pub-id><pub-id pub-id-type="pmid">32844332</pub-id></element-citation></ref><ref id="bib56"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Zingg</surname><given-names>B</given-names></name><name><surname>Hintiryan</surname><given-names>H</given-names></name><name><surname>Gou</surname><given-names>L</given-names></name><name><surname>Song</surname><given-names>MY</given-names></name><name><surname>Bay</surname><given-names>M</given-names></name><name><surname>Bienkowski</surname><given-names>MS</given-names></name><name><surname>Foster</surname><given-names>NN</given-names></name><name><surname>Yamashita</surname><given-names>S</given-names></name><name><surname>Bowman</surname><given-names>I</given-names></name><name><surname>Toga</surname><given-names>AW</given-names></name><name><surname>Dong</surname><given-names>H-W</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>Neural networks of the mouse neocortex</article-title><source>Cell</source><volume>156</volume><fpage>1096</fpage><lpage>1111</lpage><pub-id pub-id-type="doi">10.1016/j.cell.2014.02.023</pub-id><pub-id pub-id-type="pmid">24581503</pub-id></element-citation></ref></ref-list></back><sub-article article-type="editor-report" id="sa0"><front-stub><article-id pub-id-type="doi">10.7554/eLife.102840.3.sa0</article-id><title-group><article-title>eLife Assessment</article-title></title-group><contrib-group><contrib contrib-type="author"><name><surname>Naud</surname><given-names>Richard</given-names></name><role specific-use="editor">Reviewing Editor</role><aff><institution>University of Ottawa</institution><country>Canada</country></aff></contrib></contrib-group><kwd-group kwd-group-type="evidence-strength"><kwd>Compelling</kwd></kwd-group><kwd-group kwd-group-type="claim-importance"><kwd>Important</kwd></kwd-group></front-stub><body><p>This <bold>important</bold> paper takes a novel approach to the problem of automatically reconstructing long-range axonal projections from stacks of images. The key innovation is to separate the identification of sections of an axon from the statistical rules used to constrain global structure. The authors provide <bold>compelling</bold> evidence that their method is a significant improvement over existing measures in circumstances where the labelling of axons and dendrites is relatively dense.</p></body></sub-article><sub-article article-type="referee-report" id="sa1"><front-stub><article-id pub-id-type="doi">10.7554/eLife.102840.3.sa1</article-id><title-group><article-title>Reviewer #1 (Public review):</article-title></title-group><contrib-group><contrib contrib-type="author"><anonymous/><role specific-use="referee">Reviewer</role></contrib></contrib-group></front-stub><body><p>Summary:</p><p>The authors introduce a novel algorithm for the automatic identification of long-range axonal projections. This is an important problem as modern high-throughput imaging techniques can produce large amounts of raw data, but identifying neuronal morphologies and connectivities requires large amounts of manual work. The algorithm works by first identifying points in three-dimensional space corresponding to parts of labelled neural projections, these are then used to identify short sections of axon using an optimisation algorithm and the prior knowledge that axonal diameters are relatively constant. Finally, a statistical model that assumes axons tend to be smooth is used to connect the sections together into complete and distinct neural trees. The authors demonstrate that their algorithm is far superior to existing techniques, especially when a dense labelling of the tissue means that neighbouring neurites interfere with the reconstruction. Despite this improvement, however, the accuracy of reconstruction remains below 90%, so manual proof-reading is still necessary to produce accurate reconstructions of axons.</p><p>Strengths:</p><p>The new algorithm combines local and global information to make a significant improvement on the state-of -the-art for automatic axonal reconstruction. The method could be applied more broadly and might have applications to reconstructions of electron microscopy data, where similar issues of high-throughput imaging and relatively slow or inaccurate reconstruction remain.</p><p>Weaknesses:</p><p>There are three weaknesses with the algorithm and manuscript.</p><p>(1) The best reconstruction accuracy is below 90%, which does not fully solve the problem of needing manual proof-reading.</p><p>(2) The 'minimum information flow tree' model the authors use to construct connected axonal trees has the potential to bias data collection. In particular, the assumption that axons should always be as smooth as possible is not always correct. This is a good rule-of-thumb for reconstructions, but real axons in many systems can take quite sharp turns and this is also seen in the data presented in the paper (Fig 1C). I would like to see explicit acknowledgement of this bias in the current manuscript and ideally a relaxation of this rule in any later versions of the algorithm.</p><p>(3) The writing of the manuscript is not always as clear as it could be. The manuscript would benefit from careful copy editing for language, and the Methods section in particular should be expanded to more clearly explain what each algorithm is doing. The pseudo code of the Supplemental Information could be brought into the Methods if possible as these algorithms are so fundamental to the manuscript.</p><p>Comments on revisions: I have no further comments or recommendations.</p></body></sub-article><sub-article article-type="referee-report" id="sa2"><front-stub><article-id pub-id-type="doi">10.7554/eLife.102840.3.sa2</article-id><title-group><article-title>Reviewer #2 (Public review):</article-title></title-group><contrib-group><contrib contrib-type="author"><anonymous/><role specific-use="referee">Reviewer</role></contrib></contrib-group></front-stub><body><p>The authors have addressed my comments in this revised version of their manuscript. PointTree is an improved method for the reconstruction of neuronal anatomy that will be useful for neuroscientists.</p><p>In this manuscript, Cai et al. introduce PointTree, a new automated method for the reconstruction of complex neuronal projections. This method has the potential to drastically speed up the process of reconstructing complex neurites. The authors use semi-automated manual reconstruction of neurons and neurites to provide a 'ground-truth' for comparison between PointTree and other automated reconstruction methods. The reconstruction performance is evaluated for precision, recall and F1-score and positions. The performance of PointTree compared to other automated reconstruction methods is impressive based on these 3 criteria.</p><p>As an experimentalist, I will not comment on the computational aspects of the manuscript. Rather, I am interested in how PointTree's performance decrease in noisy samples. This is because many imaging datasets contain some level of background noise for which the human eye appears essential for accurate reconstruction of neurites. Although the samples presented in Figure 5 represent an inherent challenge for any reconstruction method, the signal to noise ratio is extremely high (also the case in all raw data images in the paper). It would be interesting to see how PointTree's performance change in increasingly noisy samples, and for the author to provide general guidance to the scientific community as to what samples might not be accurately reconstructed with PointTree.</p></body></sub-article><sub-article article-type="author-comment" id="sa3"><front-stub><article-id pub-id-type="doi">10.7554/eLife.102840.3.sa3</article-id><title-group><article-title>Author response</article-title></title-group><contrib-group><contrib contrib-type="author"><name><surname>Cai</surname><given-names>Lin</given-names></name><role specific-use="author">Author</role><aff><institution>Britton Chance Center for Biomedical Photonics, Wuhan National Laboratory for Optoelectronics-Huazhong University of Science and Technology</institution><addr-line><named-content content-type="city">Wuhan</named-content></addr-line><country>China</country></aff><aff><institution>School of Computer Science and Engineering, Hubei Key Laboratory of Intelligent Robot, Wuhan Institute of Technology</institution><addr-line><named-content content-type="city">Wuhan</named-content></addr-line><country>China</country></aff></contrib><contrib contrib-type="author"><name><surname>Fan</surname><given-names>Taiyu</given-names></name><role specific-use="author">Author</role><aff><institution>School of Computer Science and Engineering, Hubei Key Laboratory of Intelligent Robot, Wuhan Institute of Technology</institution><addr-line><named-content content-type="city">Wuhan</named-content></addr-line><country>China</country></aff></contrib><contrib contrib-type="author"><name><surname>Qu</surname><given-names>Xuzhong</given-names></name><role specific-use="author">Author</role><aff><institution>School of Computer Science and Engineering, Hubei Key Laboratory of Intelligent Robot, Wuhan Institute of Technology</institution><addr-line><named-content content-type="city">Wuhan</named-content></addr-line><country>China</country></aff></contrib><contrib contrib-type="author"><name><surname>Zhang</surname><given-names>Ying</given-names></name><role specific-use="author">Author</role><aff><institution>School of Computer Science and Engineering, Hubei Key Laboratory of Intelligent Robot, Wuhan Institute of Technology</institution><addr-line><named-content content-type="city">Wuhan</named-content></addr-line><country>China</country></aff></contrib><contrib contrib-type="author"><name><surname>Gou</surname><given-names>Xianyu</given-names></name><role specific-use="author">Author</role><aff><institution>School of Computer Science and Engineering, Hubei Key Laboratory of Intelligent Robot, Wuhan Institute of Technology</institution><addr-line><named-content content-type="city">Wuhan</named-content></addr-line><country>China</country></aff></contrib><contrib contrib-type="author"><name><surname>Ding</surname><given-names>Quanwei</given-names></name><role specific-use="author">Author</role><aff><institution>School of Computer Science and Engineering, Hubei Key Laboratory of Intelligent Robot, Wuhan Institute of Technology</institution><addr-line><named-content content-type="city">Wuhan</named-content></addr-line><country>China</country></aff></contrib><contrib contrib-type="author"><name><surname>Feng</surname><given-names>Weihua</given-names></name><role specific-use="author">Author</role><aff><institution>School of Computer Science and Engineering, Hubei Key Laboratory of Intelligent Robot, Wuhan Institute of Technology</institution><addr-line><named-content content-type="city">Wuhan</named-content></addr-line><country>China</country></aff></contrib><contrib contrib-type="author"><name><surname>Cao</surname><given-names>Tingting</given-names></name><role specific-use="author">Author</role><aff><institution>School of Computer Science and Engineering, Hubei Key Laboratory of Intelligent Robot, Wuhan Institute of Technology</institution><addr-line><named-content content-type="city">Wuhan</named-content></addr-line><country>China</country></aff></contrib><contrib contrib-type="author"><name><surname>Lv</surname><given-names>Xiaohua</given-names></name><role specific-use="author">Author</role><aff><institution>School of Computer Science and Engineering, Hubei Key Laboratory of Intelligent Robot, Wuhan Institute of Technology</institution><addr-line><named-content content-type="city">Wuhan</named-content></addr-line><country>China</country></aff></contrib><contrib contrib-type="author"><name><surname>Liu</surname><given-names>Xiuli</given-names></name><role specific-use="author">Author</role><aff><institution>School of Computer Science and Engineering, Hubei Key Laboratory of Intelligent Robot, Wuhan Institute of Technology</institution><addr-line><named-content content-type="city">Wuhan</named-content></addr-line><country>China</country></aff></contrib><contrib contrib-type="author"><name><surname>Huang</surname><given-names>Qing</given-names></name><role specific-use="author">Author</role><aff><institution>MOE Key Laboratory for Biomedical Photonics, Wuhan National Laboratory for Optoelectronics, Huazhong University of Science and Technology</institution><addr-line><named-content content-type="city">Wuhan</named-content></addr-line><country>China</country></aff></contrib><contrib contrib-type="author"><name><surname>Quan</surname><given-names>Tingwei</given-names></name><role specific-use="author">Author</role><aff><institution>School of Computer Science and Engineering, Hubei Key Laboratory of Intelligent Robot, Wuhan Institute of Technology</institution><addr-line><named-content content-type="city">Wuhan</named-content></addr-line><country>China</country></aff></contrib><contrib contrib-type="author"><name><surname>Zeng</surname><given-names>Shaoqun</given-names></name><role specific-use="author">Author</role><aff><institution>School of Computer Science and Engineering, Hubei Key Laboratory of Intelligent Robot, Wuhan Institute of Technology</institution><addr-line><named-content content-type="city">Wuhan</named-content></addr-line><country>China</country></aff></contrib></contrib-group></front-stub><body><p>The following is the authors’ response to the original reviews</p><disp-quote content-type="editor-comment"><p><bold>Public Reviews:</bold></p><p><bold>Reviewer #1 (Public review):</bold></p><p>Summary:</p><p>The authors introduce a novel algorithm for the automatic identification of longrange axonal projections. This is an important problem as modern high-throughput imaging techniques can produce large amounts of raw data, but identifying neuronal morphologies and connectivities requires large amounts of manual work. The algorithm works by first identifying points in three-dimensional space corresponding to parts of labelled neural projections, these are then used to identify short sections of axons using an optimisation algorithm and the prior knowledge that axonal diameters are relatively constant. Finally, a statistical model that assumes axons tend to be smooth is used to connect the sections together into complete and distinct neural trees. The authors demonstrate that their algorithm is far superior to existing techniques, especially when dense labelling of the tissue means that neighbouring neurites interfere with the reconstruction. Despite this improvement, however, the accuracy of reconstruction remains below 90%, so manual proofreading is still necessary to produce accurate reconstructions of axons.</p><p>Strengths:</p><p>The new algorithm combines local and global information to make a significant improvement on the state-of-the-art for automatic axonal reconstruction. The method could be applied more broadly and might have applications to reconstructions of electron microscopy data, where similar issues of highthroughput imaging and relatively slow or inaccurate reconstruction remain.</p></disp-quote><p>We thank the reviewer for their positive comments and for taking the time to review our manuscript. We are truly grateful that the reviewer recognized the value of our method in automatically reconstructing long-range axonal projections. While we report that our method achieves reconstruction accuracy of approximately 85%, we fully acknowledge that manual proofreading is still necessary to ensure accuracy greater than 95%. We also appreciate the reviewer’s insightful suggestion regarding the potential adaptation of our algorithm for reconstructing electron microscopy (EM) data, where similar challenges in high-throughput imaging and relatively slow or inaccurate reconstruction persist. We look forward to exploring ways to integrate our method with EM data in future work.</p><disp-quote content-type="editor-comment"><p>Weaknesses:</p><p>There are three weaknesses in the algorithm and manuscript.</p><p>(1) The best reconstruction accuracy is below 90%, which does not fully solve the problem of needing manual proofreading.</p></disp-quote><p>We sincerely appreciate the reviewer's valuable insights regarding reconstruction accuracy. Indeed, as illustrated in Figure S4, our current best automated reconstruction accuracy on fMOST data is still below 90%. This indicates that manual proofreading remains essential to ensure reliability.</p><p>For the reconstruction of long-range axonal projections, ensuring the accuracy of the reconstruction process necessitates manual revision of the automatically generated results. Existing literature has demonstrated that a higher accuracy in automatic reconstruction correlates with a reduced need for manual revisions, thereby facilitating an accelerated reconstruction process (Winnubst et al., Cell 2019; Liu et al., Nature Methods 2025).</p><p>As the reviewer rightly points out, achieving an accuracy exceeding 95% currently necessitates manual proofreading. Although our method does not completely eliminate this requirement, it significantly alleviates the proofreading workload by: (1) Minimizing common errors in regions with dense neuron distributions; (2) Providing more reliable initial reconstructions; and (3) Reducing the number of corrections needed during the proofreading process.</p><p>In the future, we will continue to enhance our reconstruction framework. As imaging systems achieve higher signal-to-noise ratios and deep learning techniques facilitate more accurate foreground detection, we anticipate that our method will attain even greater reconstruction accuracy. Furthermore, we plan to develop a software system capable of predicting potential error locations in our automated reconstruction results, thereby streamlining manual revisions. This approach distinguishes itself from existing models by obviating the need for individual traversal of the brain regions associated with each neuron reconstruction.</p><disp-quote content-type="editor-comment"><p>(2) The 'minimum information flow tree' model the authors use to construct connected axonal trees has the potential to bias data collection. In particular, the assumption that axons should always be as smooth as possible is not always correct. This is a good rule-of-thumb for reconstructions, but real axons in many systems can take quite sharp turns and this is also seen in the data presented in the paper (Figure 1C). I would like to see explicit acknowledgement of this bias in the current manuscript and ideally a relaxation of this rule in any later versions of the algorithm.</p></disp-quote><p>We appreciate the reviewer's insightful opinion regarding the potential bias introduced by our minimum information flow tree model. The reviewer is absolutely correct in noting that while axon smoothness serves as a useful reconstruction heuristic, it should not be treated as an absolute constraint given that real axons can exhibit sharp turns (as shown in Figure 1C). In response to this valuable feedback, we add explicit discussion of this limitation in Discussion section as follow: “Finally, the minimal information flow tree’s fundamental assumption, that axons should be as smooth as possible does not always hold true.</p><p>In fact, real axons can take quite sharp turns leading the algorithm to erroneously separate a single continuous axon into disjoint neurites.”</p><p>In our reconstruction process, the post-processing approach partially mitigates erroneous reconstructions derived from this rule. Specifically: The minimum information flow tree will decompose such structures into two separate branches (Fig. S7A), but the decomposition node is explicitly recorded. The newly decomposed branches attempt to reconnect by searching for plausible neurites starting from their head nodes (determined by the minimum information flow tree). If no connectable neurites are found, the branch is automatically reconnected to its originally recorded decomposition node (Fig. S7B). In Fig.S7C, two reconstruction examples demonstrate the effectiveness of the post-processing approach.</p><p>As pointed out by the reviewers, the proposed rule for revising neuron reconstruction does not encompass all scenarios. Relaxing the constraints of this rule may lead to numerous new erroneous connections. Currently, the proposed rule is solely based on the positions of neurite centerlines and does not integrate information regarding the intensity of the original images or segmentation data. Incorporating these elements into the rule could potentially reduce reconstruction errors.</p><disp-quote content-type="editor-comment"><p>(3) The writing of the manuscript is not always as clear as it could be. The manuscript would benefit from careful copy editing for language, and the Methods section in particular should be expanded to more clearly explain what each algorithm is doing. The pseudo-code of the Supplemental Information could be brought into the Methods if possible as these algorithms are so fundamental to the manuscript.</p></disp-quote><p>We sincerely thank the reviewer for these valuable suggestions to improve our manuscript’s clarity and methodological presentation. We have implemented the following revisions:</p><p>(1) Language Enhancement: we have conducted rigorous internal linguistic reviews to address grammatical inaccuracies and improve textual clarity.</p><p>(2) Methods Expansion and Pseudo-code Integration: we have incorporated all relevant derivations from the Supplementary Materials into the Methods section, with additional explanatory text to clarify the purpose and implementation of each algorithm. All mathematical formulations have been systematically rederived with modifications to variable nomenclature, subscript/superscript notations and identified errors in the original submission. All pseudocode from Supplementary Materials has been integrated into their corresponding methods subsection.</p><disp-quote content-type="editor-comment"><p><bold>Reviewer #2 (Public review):</bold></p><p>In this manuscript, Cai et al. introduce PointTree, a new automated method for the reconstruction of complex neuronal projections. This method has the potential to drastically speed up the process of reconstructing complex neurites. The authors use semi-automated manual reconstruction of neurons and neurites to provide a 'ground-truth' for comparison between PointTree and other automated reconstruction methods. The reconstruction performance is evaluated for precision, recall, and F1-score and positions. The performance of PointTree compared to other automated reconstruction methods is impressive based on these 3 criteria.</p><p>As an experimentalist, I will not comment on the computational aspects of the manuscript. Rather, I am interested in how PointTree's performance decreases in noisy samples. This is because many imaging datasets contain some level of background noise for which the human eye appears essential for the accurate reconstruction of neurites. Although the samples presented in Figure 5 represent an inherent challenge for any reconstruction method, the signal-to-noise ratio is extremely high (also the case in all raw data images in the paper). It would be interesting to see how PointTree's performance changes in increasingly noisy samples, and for the author to provide general guidance to the scientific community as to what samples might not be accurately reconstructed with PointTree.</p></disp-quote><p>We thank the reviewer for her/his time reviewing our manuscript and the interest on how PointTree perform on noisy samples. It is important to clarify that PointTree is solely responsible for the reconstruction of neurons from the foreground regions of neural images. The foreground regions of these neuronal images are obtained through a deep learning segmentation network. In cases where the image has a low signal-to-noise ratio, if the segmentation network can accurately identify the foreground areas, then PointTree will be able to accurately reconstruct neurons. In fact, existing deep learning networks have demonstrated their capability to effectively extract foreground regions from low signal-to-noise ratio images; therefore, PointTree is well-suited for processing neuronal images characterized by low signal-to-noise ratios.</p><p>In the revised manuscript, we conducted experiments on datasets with varying signal-to-noise ratios (SNR). The results demonstrate that Unet3D is capable of identifying the foreground regions in low-SNR images, thereby supporting the assertion that PointTree has broad applicability across diverse neuronal imaging datasets.</p><disp-quote content-type="editor-comment"><p><bold>Recommendations for the authors:</bold></p><p><bold>Reviewer #2 (Recommendations for the authors):</bold></p><p>It would be interesting to see how PointTree's performance changes in increasingly noisy samples, and for the author to provide general guidance to the scientific community as to what samples might not be accurately reconstructed with PointTree.</p></disp-quote><p>We extend our heartfelt gratitude to the reviewer for their insightful suggestion concerning experiments involving different noisy samples. Here are the details of the datasets used:</p><p>LSM dataset: Mean SNR = 5.01, with 25 samples, and a volume size of 192×192×192.</p><p>fMOST dataset: Mean SNR = 8.68, with 25 samples, and a volume size of 192×192×192.</p><p>HD-fMOST dataset: Mean SNR = 11.4, with 25 samples, and a volume size of 192×192×192.</p><p>The experimental results reveal that, thanks to the deep learning network's robust feature extraction capabilities, even when working with low-SNR data (as depicted in Figure 4B, first two columns of the top row), satisfactory segmentation results (Figure 4B, first two columns of the third row) were achieved. These results laid a solid foundation for subsequent accurate reconstruction.</p><p>PointTree demonstrated consistent mean F1-scores of 91.0%, 90.0%, and 93.3% across the three datasets, respectively. This underscores its reconstruction robustness under varying SNR conditions when supported by the segmentation network. For more in-depth information, please refer to the manuscript section titled &quot;Reconstruction of data with different signal-to-noise ratios&quot; and Figure 4.</p></body></sub-article></article>