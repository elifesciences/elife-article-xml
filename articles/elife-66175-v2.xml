<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD v1.2 20190208//EN"  "JATS-archivearticle1.dtd"><article article-type="research-article" dtd-version="1.2" xmlns:ali="http://www.niso.org/schemas/ali/1.0/" xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink"><front><journal-meta><journal-id journal-id-type="nlm-ta">elife</journal-id><journal-id journal-id-type="publisher-id">eLife</journal-id><journal-title-group><journal-title>eLife</journal-title></journal-title-group><issn pub-type="epub" publication-format="electronic">2050-084X</issn><publisher><publisher-name>eLife Sciences Publications, Ltd</publisher-name></publisher></journal-meta><article-meta><article-id pub-id-type="publisher-id">66175</article-id><article-id pub-id-type="doi">10.7554/eLife.66175</article-id><article-categories><subj-group subj-group-type="display-channel"><subject>Research Article</subject></subj-group><subj-group subj-group-type="heading"><subject>Computational and Systems Biology</subject></subj-group><subj-group subj-group-type="heading"><subject>Neuroscience</subject></subj-group></article-categories><title-group><article-title>Mice in a labyrinth show rapid learning, sudden insight, and efficient exploration</article-title></title-group><contrib-group><contrib contrib-type="author" equal-contrib="yes" id="author-221759"><name><surname>Rosenberg</surname><given-names>Matthew</given-names></name><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="fn" rid="equal-contrib1">†</xref><xref ref-type="fn" rid="con1"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" equal-contrib="yes" id="author-221765"><name><surname>Zhang</surname><given-names>Tony</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">https://orcid.org/0000-0002-5198-499X</contrib-id><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="fn" rid="equal-contrib1">†</xref><xref ref-type="fn" rid="con2"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" corresp="yes" id="author-4235"><name><surname>Perona</surname><given-names>Pietro</given-names></name><email>perona@caltech.edu</email><xref ref-type="aff" rid="aff2">2</xref><xref ref-type="other" rid="fund2"/><xref ref-type="other" rid="fund3"/><xref ref-type="other" rid="fund4"/><xref ref-type="fn" rid="con3"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" corresp="yes" id="author-3549"><name><surname>Meister</surname><given-names>Markus</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">https://orcid.org/0000-0003-2136-6506</contrib-id><email>meister@caltech.edu</email><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="other" rid="fund1"/><xref ref-type="fn" rid="con4"/><xref ref-type="fn" rid="conf2"/></contrib><aff id="aff1"><label>1</label><institution>Division of Biology and Biological Engineering, California Institute of Technology</institution><addr-line><named-content content-type="city">Pasadena</named-content></addr-line><country>United States</country></aff><aff id="aff2"><label>2</label><institution>Division of Engineering and Applied Science, California Institute of Technology</institution><addr-line><named-content content-type="city">Pasadena</named-content></addr-line><country>United States</country></aff></contrib-group><contrib-group content-type="section"><contrib contrib-type="editor"><name><surname>Mathis</surname><given-names>Mackenzie W</given-names></name><role>Reviewing Editor</role><aff><institution>EPFL</institution><country>Switzerland</country></aff></contrib><contrib contrib-type="senior_editor"><name><surname>Dulac</surname><given-names>Catherine</given-names></name><role>Senior Editor</role><aff><institution>Harvard University</institution><country>United States</country></aff></contrib></contrib-group><author-notes><fn fn-type="con" id="equal-contrib1"><label>†</label><p>These authors contributed equally to this work</p></fn></author-notes><pub-date date-type="publication" publication-format="electronic"><day>01</day><month>07</month><year>2021</year></pub-date><pub-date pub-type="collection"><year>2021</year></pub-date><volume>10</volume><elocation-id>e66175</elocation-id><history><date date-type="received" iso-8601-date="2020-12-31"><day>31</day><month>12</month><year>2020</year></date><date date-type="accepted" iso-8601-date="2021-06-30"><day>30</day><month>06</month><year>2021</year></date></history><permissions><copyright-statement>© 2021, Rosenberg et al</copyright-statement><copyright-year>2021</copyright-year><copyright-holder>Rosenberg et al</copyright-holder><ali:free_to_read/><license xlink:href="http://creativecommons.org/licenses/by/4.0/"><ali:license_ref>http://creativecommons.org/licenses/by/4.0/</ali:license_ref><license-p>This article is distributed under the terms of the <ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/licenses/by/4.0/">Creative Commons Attribution License</ext-link>, which permits unrestricted use and redistribution provided that the original author and source are credited.</license-p></license></permissions><self-uri content-type="pdf" xlink:href="elife-66175-v2.pdf"/><abstract><p>Animals learn certain complex tasks remarkably fast, sometimes after a single experience. What behavioral algorithms support this efficiency? Many contemporary studies based on two-alternative-forced-choice (2AFC) tasks observe only slow or incomplete learning. As an alternative, we study the unconstrained behavior of mice in a complex labyrinth and measure the dynamics of learning and the behaviors that enable it. A mouse in the labyrinth makes ~2000 navigation decisions per hour. The animal explores the maze, quickly discovers the location of a reward, and executes correct 10-bit choices after only 10 reward experiences — a learning rate 1000-fold higher than in 2AFC experiments. Many mice improve discontinuously from one minute to the next, suggesting moments of sudden insight about the structure of the labyrinth. The underlying search algorithm does not require a global memory of places visited and is largely explained by purely local turning rules.</p></abstract><kwd-group kwd-group-type="author-keywords"><kwd>behavior</kwd><kwd>few-shot learning</kwd><kwd>navigation</kwd><kwd>decision-making</kwd><kwd>predictive models</kwd><kwd>cognitive map</kwd></kwd-group><kwd-group kwd-group-type="research-organism"><title>Research organism</title><kwd>Mouse</kwd></kwd-group><funding-group><award-group id="fund1"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/100000893</institution-id><institution>Simons Foundation</institution></institution-wrap></funding-source><award-id>543015</award-id><principal-award-recipient><name><surname>Meister</surname><given-names>Markus</given-names></name></principal-award-recipient></award-group><award-group id="fund2"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/100000893</institution-id><institution>Simons Foundation</institution></institution-wrap></funding-source><award-id>543025</award-id><principal-award-recipient><name><surname>Perona</surname><given-names>Pietro</given-names></name></principal-award-recipient></award-group><award-group id="fund3"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/100000001</institution-id><institution>National Science Foundation</institution></institution-wrap></funding-source><award-id>1564330</award-id><principal-award-recipient><name><surname>Perona</surname><given-names>Pietro</given-names></name></principal-award-recipient></award-group><award-group id="fund4"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/100006785</institution-id><institution>Google</institution></institution-wrap></funding-source><principal-award-recipient><name><surname>Perona</surname><given-names>Pietro</given-names></name></principal-award-recipient></award-group><funding-statement>The funders had no role in study design, data collection and interpretation, or the decision to submit the work for publication.</funding-statement></funding-group><custom-meta-group><custom-meta specific-use="meta-only"><meta-name>Author impact statement</meta-name><meta-value>Mice exploring a labyrinth freely for the first time learn a complex action sequence after a handful of rewards, exhibiting a learning rate 1000-fold higher than in commonly-used paradigms.</meta-value></custom-meta></custom-meta-group></article-meta></front><body><sec id="s1" sec-type="intro"><title>Introduction</title><p>How can animals or machines acquire the ability for complex behaviors from one or a few experiences? Canonical examples include language learning in children, where new words are learned after just a few instances of their use, or learning to balance a bicycle, where humans progress from complete incompetence to near perfection after crashing once or a few times. Clearly, such rapid acquisition of new associations or of new motor skills can confer enormous survival advantages.</p><p>In laboratory studies, one prominent instance of one-shot learning is the Bruce effect (<xref ref-type="bibr" rid="bib8">Bruce, 1959</xref>). Here, the female mouse forms an olfactory memory of her mating partner that allows her to terminate the pregnancy if she encounters another male that threatens infanticide. Another form of rapid learning accessible to laboratory experiments is fear conditioning, where a formerly innocuous stimulus gets associated with a painful experience, leading to subsequent avoidance of the stimulus (<xref ref-type="bibr" rid="bib14">Fanselow and Bolles, 1979</xref>; <xref ref-type="bibr" rid="bib6">Bourtchuladze et al., 1994</xref>). These learning systems appear designed for special purposes, they perform very specific associations, and govern binary behavioral decisions. They are likely implemented by specialized brain circuits, and indeed great progress has been made in localizing these operations to the accessory olfactory bulb (<xref ref-type="bibr" rid="bib7">Brennan and Keverne, 1997</xref>) and the cortical amygdala (<xref ref-type="bibr" rid="bib21">LeDoux, 2000</xref>).</p><p>In the attempt to identify more generalizable mechanisms of learning and decision making, one route has been to train laboratory animals on abstract tasks with tightly specified sensory inputs that are linked to motor outputs via arbitrary contingency rules. Canonical examples are a monkey reporting motion in a visual stimulus by saccading its eyes (<xref ref-type="bibr" rid="bib27">Newsome and Paré, 1988</xref>), and a mouse in a box classifying stimuli by moving its forelimbs or the tongue (<xref ref-type="bibr" rid="bib10">Burgess et al., 2017</xref>; <xref ref-type="bibr" rid="bib18">Guo et al., 2014</xref>). The tasks are of low complexity, typically a one bit decision based on 1 or 2 bits of input. Remarkably, they are learned exceedingly slowly: a mouse typically requires many weeks of shaping and thousands of trials to reach asymptotic performance; a monkey may require many months (<xref ref-type="bibr" rid="bib11">Carandini and Churchland, 2013</xref>).</p><p>What is needed therefore is a rodent behavior that involves complex decision making, with many input variables and many possible choices. Ideally, the animals would learn to perform this task without excessive intervention by human shaping, so we may be confident that they employ innate brain mechanisms rather than circuits created by the training. Obviously, the behavior should be easy to measure in the laboratory. Finally, it would be satisfying if this behavior showed a glimpse of rapid learning.</p><p>Navigation through space is a complex behavior displayed by many animals. It typically involves integrating multiple cues to decide among many possible actions. It relies intimately on rapid learning. For example, a pigeon or desert ant leaving its shelter acquires the information needed for the homing path in a single episode. Major questions remain about how the brain stores this information and converts it to a policy for decisions during the homing path. One way to formalize the act of decision-making in the laboratory is to introduce structure in the environment in the form of a maze that defines straight paths and decision points. A maze of tunnels is in fact a natural environment for a burrowing rodent. Early studies of rodent behavior did place the animals into true labyrinths (<xref ref-type="bibr" rid="bib35">Small, 1901</xref>), but their use gradually declined in favor of linear tracks or boxes with a single choice point.</p><p>We report here on the behavior of laboratory mice in a complex labyrinth of tunnels. A single mouse is placed in a home cage from which it has free access to the maze for one night. No handling, shaping, or training by the investigators is involved. By continuous video-recording and automated tracking, we observe the animal’s entire life experience within the labyrinth. Some of the mice are water-deprived and a single location deep inside the maze offers water. We find that these animals learn to navigate to the water port after just a few reward experiences. In many cases, one can identify unique moments of 'insight' when the animal’s behavior changes discontinuously. This all happens within ~1 h. Underlying the rapid learning is an efficient mode of exploration driven by simple navigation rules. Mice that do not lack water show the same patterns of exploration. This laboratory-based navigation behavior may form a suitable substrate for studying the neural mechanisms that implement few-shot learning.</p></sec><sec id="s2" sec-type="results"><title>Results</title><sec id="s2-1"><title>Adaptation to the maze</title><p>At the start of the experiment, a single mouse was placed in a conventional mouse cage with bedding and food. A short tunnel offered free access to a maze consisting of a warren of corridors (<xref ref-type="fig" rid="fig1">Figure 1A–B</xref>). The bottom and walls of the maze were constructed of black plastic that is transparent in the infrared. A video camera placed below the maze captured the animal’s actions continuously using infrared illumination (<xref ref-type="fig" rid="fig1">Figure 1B</xref>). The recordings were analyzed offline to track the movements of the mouse, with keypoints on the nose, mid-body, tail base, and the four feet (<xref ref-type="fig" rid="fig1">Figure 1D</xref>). All observations were made in darkness during the animal’s subjective night.</p><fig-group><fig id="fig1" position="float"><label>Figure 1.</label><caption><title>The maze environment.</title><p>Top (<bold>A</bold>) and side (<bold>B</bold>) views of a home cage, connected via an entry tunnel to an enclosed labyrinth. The animal’s actions in the maze are recorded via video from below using infrared illumination. (<bold>C</bold>) The maze is structured as a binary tree with 63 branch points (in levels numbered 0,…,5) and 64 end nodes. One end node has a water port that dispenses a drop when it gets poked. Blue line in A and C: path from maze entry to water port. (<bold>D</bold>) A mouse considering the options at the maze’s central intersection. Colored keypoints are tracked by DeepLabCut: nose, mid body, tail base, four feet.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-66175-fig1-v2.tif"/></fig><fig id="fig1s1" position="float" specific-use="child-fig"><label>Figure 1—figure supplement 1.</label><caption><title>Occupancy of the maze.</title><p>Fraction of time spent in the maze. Mice could move freely between the home cage and the maze. For each animal (vertical), the fraction of time in the maze (color scale) is plotted as a function of time since start of the experiment. Time bins are 500 s. Note that mouse D6 hardly entered the maze; it never progressed beyond the first junction. This animal was excluded from all subsequent analysis steps.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-66175-fig1-figsupp1-v2.tif"/></fig><fig id="fig1s2" position="float" specific-use="child-fig"><label>Figure 1—figure supplement 2.</label><caption><title>Fraction of time in maze by group.</title><p>Average fraction of time spent in the maze by group. This shows the average fraction of time in the maze as Mean ± SD over the population of 10 rewarded and nine unrewarded animals. Right: expanded axis for early times. The tunnel to the maze opens at time 0. Rewarded and unrewarded animals used the maze in remarkably similar ways. Exploration of the maze began around 250 s after tunnel opening. Within the next 250 s, the maze occupancy rose quickly to ~70%, then declined gradually over 7 h to ~30%.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-66175-fig1-figsupp2-v2.tif"/></fig><fig id="fig1s3" position="float" specific-use="child-fig"><label>Figure 1—figure supplement 3.</label><caption><title>Transitions between cage and maze.</title><p>Rates of transition between cage and maze. (<bold>A</bold>) The instantaneous probability per unit time <inline-formula><mml:math id="inf1"><mml:mrow><mml:msub><mml:mi>r</mml:mi><mml:mi mathvariant="normal">m</mml:mi></mml:msub><mml:mo>⁢</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> of entering the maze after having spent time <inline-formula><mml:math id="inf2"><mml:mi>t</mml:mi></mml:math></inline-formula> in the cage. Note this rate is highest immediately upon entering the cage, then declines by a large factor. (<bold>B</bold>) The instantaneous probability per unit time <inline-formula><mml:math id="inf3"><mml:mrow><mml:msub><mml:mi>r</mml:mi><mml:mi mathvariant="normal">c</mml:mi></mml:msub><mml:mo>⁢</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> of exiting the maze after having spent time <inline-formula><mml:math id="inf4"><mml:mi>t</mml:mi></mml:math></inline-formula> in the maze.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-66175-fig1-figsupp3-v2.tif"/></fig></fig-group><p>The logical structure of the maze is a binary tree, with 6 levels of branches, leading from the single entrance to 64 endpoints (<xref ref-type="fig" rid="fig1">Figure 1C</xref>). A total of 63 T-junctions are connected by straight corridors in a design with maximal symmetry (<xref ref-type="fig" rid="fig1">Figure 1A</xref>, <xref ref-type="fig" rid="fig3s1">Figure 3—figure supplement 1</xref>), such that all the nodes at a given level of the tree have the same local geometry. One of the 64 endpoints of the maze is outfitted with a water port. After activation by a brief nose poke, the port delivers a small drop of water, followed by a 90 s time-out period.</p><p>After an initial period of exploratory experiments, we settled on a frozen protocol that was applied to 20 animals. Ten of these mice had been mildly water-deprived for up to 24 h; they received food in the home cage and water only from the port hidden in the maze. Another ten mice had free access to food and water in the cage, and received no water from the port in the maze. Each animal’s behavior in the maze was recorded continuously for 7 h during the first night of its experience with the maze, starting the moment the connection tunnel was opened (sample videos <ext-link ext-link-type="uri" xlink:href="https://www.youtube.com/playlist?list=PLm5UsX091_2X0ph_ldO3_lC9KFxqYpqo5">here</ext-link>). The investigator played no role during this period, and the animal was free to act as it wished including travel between the cage and the maze.</p><p>All the mice except one passed between the cage and the maze readily and frequently (<xref ref-type="fig" rid="fig1s1">Figure 1—figure supplement 1</xref>). The single outlier animal barely entered the maze and never progressed past the first junction; we excluded this mouse’s data from subsequent analysis. On average over the entire period of study the animals spent 46% of the time in the maze (<xref ref-type="fig" rid="fig1s2">Figure 1—figure supplement 2</xref>). This fraction was similar whether or not the animal was motivated by water rewards (47% for rewarded vs 44% for unrewarded animals). Over time the animals appeared increasingly comfortable in the maze, taking breaks for grooming and the occasional nap. When the investigator lifted the cage lid at the end of the night some animals were seen to escape into the safety of the maze.</p><p>We examined the rate of transitions from the cage to the maze and how it depends on time spent in the cage (<xref ref-type="fig" rid="fig1s3">Figure 1—figure supplement 3A</xref>). Surprisingly the rate of entry into the maze is highest immediately after the animal returns to the cage. Then it declines gradually by a factor of 4 over the first minute in the cage and remains steady thereafter. This is a large effect, observed for every individual animal in both the rewarded and unrewarded groups. By contrast the opposite transition, namely exit from the maze, occurs at an essentially constant rate throughout the visit (<xref ref-type="fig" rid="fig1s3">Figure 1—figure supplement 3B</xref>).</p><p>The nature of the animal’s forays into the maze changed over time. We call each foray from entrance to exit a ‘bout’. After a few hesitant entries into the main corridor, the mouse engaged in one or more long bouts that dove deep into the binary tree to most or all of the leaf nodes (<xref ref-type="fig" rid="fig2">Figure 2A</xref>). For a water-deprived animal, this typically led to discovery of the reward port. After ~10 bouts, the trajectories became more focused, involving travel to the reward port and some additional exploration (<xref ref-type="fig" rid="fig2">Figure 2B</xref>). At a later stage still, the animal often executed perfect exploitation bouts that led straight to the reward port and back with no wrong turns (<xref ref-type="fig" rid="fig2">Figure 2C</xref>). Even at this late stage, however, the animal continued to explore other parts of the maze (<xref ref-type="fig" rid="fig2">Figure 2D</xref>). Similarly the unrewarded animals explored the maze throughout the night (<xref ref-type="fig" rid="fig1s2">Figure 1—figure supplement 2</xref>). While the length and structure of the animal’s trajectories changed over time, the speed remained remarkably constant after ~50 s of adaptation (<xref ref-type="fig" rid="fig2s1">Figure 2—figure supplement 1</xref>).</p><fig-group><fig id="fig2" position="float"><label>Figure 2.</label><caption><title>Sample trajectories during adaptation to the maze.</title><p>Four sample bouts from one mouse (B3) into the maze at various times during the experiment (time markings at bottom). The trajectory of the animal’s nose is shown; time is encoded by the color of the trace. The entrance from the home cage and the water port are indicated in panel A.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-66175-fig2-v2.tif"/></fig><fig id="fig2s1" position="float" specific-use="child-fig"><label>Figure 2—figure supplement 1.</label><caption><title>Speed of locomotion.</title><p>The speed of locomotion in the maze is approximately constant. Left: Speed plotted as Mean ± SD over the population of rewarded and unrewarded animals. Right: expanded axis for early times. To assess the speed of locomotion, we divided the maze into square cells as wide as the corridors and tracked how the nose of the animal moved through those cells. Then the speed was measured in number of cells traversed per unit time. Note that the speed is very similar across animals, ~1.56 cells/s = 5.94 cm/s on average. It rises quickly over the first 50 s in the maze, then varies only little over the 7 h of the experiment.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-66175-fig2-figsupp1-v2.tif"/></fig></fig-group><p>While <xref ref-type="fig" rid="fig2">Figure 2</xref> illustrates the trajectory of a mouse’s nose in full spatio-temporal detail, a convenient reduced representation is the ‘node sequence’. This simply marks the events when the animal enters each of the 127 nodes of the binary tree that describes the maze (see Materials and methods and <xref ref-type="fig" rid="fig3s1">Figure 3—figure supplement 1</xref>). Among these nodes, 63 are T-junctions where the animal has three choices for the next node, and 64 are end nodes where the animal’s only choice is to reverse course. We call the transition from one node to the next a ‘step’. The analysis in the rest of the paper was carried out on the animal’s node sequence.</p></sec><sec id="s2-2"><title>Few-shot learning of a reward location</title><p>We now examine early changes in the animal’s behavior when it rapidly acquires and remembers information needed for navigation. First, we focus on navigation to the water port.</p><p>The 10 water-deprived animals had no indication that water would be found in the maze. Yet, all 10 discovered the water port in less than 2000 s and fewer than 17 bouts (<xref ref-type="fig" rid="fig3">Figure 3A</xref>). The port dispensed only a drop of water followed by a 90 s timeout before rearming. During the timeout, the animals generally left the port location to explore other parts of the maze or return home, even though they were not obliged to do so. For each of the water-deprived animals, the frequency at which it consumed rewards in the maze increased rapidly as it learned how to find the water port, then settled after a few reward experiences (<xref ref-type="fig" rid="fig3">Figure 3A</xref>).</p><fig-group><fig id="fig3" position="float"><label>Figure 3.</label><caption><title>Few-shot learning of path to water.</title><p>(<bold>A</bold>) Time line of all water rewards collected by 10 water-deprived mice (red dots, every fifth reward has a blue tick mark). (<bold>B</bold>) The length of runs from the entrance to the water port, measured in steps between nodes, and plotted against the number of rewards experienced. Main panel: All individual runs (cyan dots) and median over 10 mice (blue circles). Exponential fit decays by <inline-formula><mml:math id="inf5"><mml:mrow><mml:mn>1</mml:mn><mml:mo>/</mml:mo><mml:mi>e</mml:mi></mml:mrow></mml:math></inline-formula> over 10.1 rewards. Right panel: Histogram of the run length, note log axis. Red: perfect runs with the minimum length 6; green: longer runs. Top panel: The fraction of perfect runs (length 6) plotted against the number of rewards experienced, along with the median duration of those perfect runs.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-66175-fig3-v2.tif"/></fig><fig id="fig3s1" position="float" specific-use="child-fig"><label>Figure 3—figure supplement 1.</label><caption><title>Definition of node trajectories.</title><p>Definition of node trajectories. A numbering scheme for all 127 nodes of the maze. Green: a direct path from the entrance to the water port (‘water run’) with the node sequence <inline-formula><mml:math id="inf6"><mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>s</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:mn>2</mml:mn><mml:mo>,</mml:mo><mml:mn>6</mml:mn><mml:mo>,</mml:mo><mml:mn>13</mml:mn><mml:mo>,</mml:mo><mml:mn>28</mml:mn><mml:mo>,</mml:mo><mml:mn>57</mml:mn><mml:mo>,</mml:mo><mml:mn>116</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula>, involving six decisions. Magenta: a direct path from end node 83 to the exit (‘home run’). Orange: a path from end node 67 to the exit that includes a reversal. Here the home run starts only from node 8, namely <inline-formula><mml:math id="inf7"><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mn>8</mml:mn><mml:mo>,</mml:mo><mml:mn>3</mml:mn><mml:mo>,</mml:mo><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mn>0</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></inline-formula>.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-66175-fig3-figsupp1-v2.tif"/></fig></fig-group><p>How many reward experiences are sufficient to teach the animal reliable navigation to the water port? To establish a learning curve one wants to compare performance on the identical task over successive trials. Recall that this experiment has no imposed trial structure. Yet the animals naturally segmented their behavior through discrete visits to the maze. Thus, we focused on all the instances when the animal started at the maze entrance and walked to the water port (<xref ref-type="fig" rid="fig3">Figure 3B</xref>).</p><p>On the first few occasions these paths to water can involve hundreds of steps between nodes and their length scatters over a wide range. However, after a few rewards, the animals began taking the perfect path without detours (six steps, <xref ref-type="fig" rid="fig3s1">Figure 3—figure supplement 1</xref>), and soon that became the norm. Note the path length plotted here is directly related to the number of ‘turning errors’: every time the mouse turns away from the shortest path to the water port that adds two steps to the path length (<xref ref-type="disp-formula" rid="equ7">Equation 7</xref>). The rate of these errors declined over time, by a factor of <inline-formula><mml:math id="inf8"><mml:mi>e</mml:mi></mml:math></inline-formula> after ~10 rewards consumed (<xref ref-type="fig" rid="fig3">Figure 3B</xref>). Late in the night ~75% of the paths to water were perfect. The animals executed them with increasing speed; eventually, these fast ‘water runs’ took as little as 2 s (<xref ref-type="fig" rid="fig3">Figure 3B</xref>). Many of these visits went unrewarded owing to the 90 s timeout period on the water port.</p><p>In summary, after ~10 reward experiences on average the mice learn to navigate efficiently to the water port, which requires making six correct decisions, each among three options. Note that even at late times, long after they have perfected the ‘water run’, the animals continue to take some extremely long paths: a subject for a later section (Figure 7).</p></sec><sec id="s2-3"><title>The role of cues attached to the maze</title><p>These observations of rapid learning raise the question 'How do the animals navigate?’ In particular, does the mouse build an internal representation that guides its action at every junction? Or does it place marks in the external environment that signal the route to the water port? In an extreme version of externalized cognition, the mouse leaves behind a trail of urine marks or other secretions as it walks away from the water port, and on a subsequent bout simply sniffs its way up the odor gradient (<xref ref-type="fig" rid="fig4">Figure 4A</xref>). This would require no internal representation.</p><fig-group><fig id="fig4" position="float"><label>Figure 4.</label><caption><title>Navigation is robust to rotation of the maze.</title><p>(<bold>A</bold>) Logic of the experiment: The animal may have deposited an odorant in the maze (shading) that is centered on the water port. After 180 degree rotation of the maze, that gradient would lead to the image of the water port (blue dot). We also measure how often the mouse goes to two control nodes (magenta dots) that are related by symmetry. (<bold>B</bold>) Trajectory of mouse ‘A1’ in the bouts immediately before and after maze rotation. Time coded by color from dark to light as in <xref ref-type="fig" rid="fig2">Figure 2</xref>. (<bold>C</bold>) Left: Cumulative number of rewards as well as visits to the water port, the image of the water port, and the control nodes. All events are plotted vs time before and after the maze rotation. Average over four animals. Middle and right: Same data with the counts centered on zero and zoomed in for better resolution.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-66175-fig4-v2.tif"/></fig><fig id="fig4s1" position="float" specific-use="child-fig"><label>Figure 4—figure supplement 1.</label><caption><title>Navigation before and after maze rotation for each animal.</title><p>Navigation before and after maze rotation. Cumulative number of rewards, visits to the water port, the image of the water port, and the control nodes, plotted vs time before and after the maze rotation. Display as in <xref ref-type="fig" rid="fig4">Figure 4C</xref>, but split for each of four animals.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-66175-fig4-figsupp1-v2.tif"/></fig><fig id="fig4s2" position="float" specific-use="child-fig"><label>Figure 4—figure supplement 2.</label><caption><title>Speed before and after maze rotation.</title><p>Speed of the mouse vs time in the maze. Average over four animals. Time is plotted relative to the maze rotation.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-66175-fig4-figsupp2-v2.tif"/></fig></fig-group><p>The following experiment offers some partial insights. Owing to the design of the labyrinth one can rotate the entire apparatus by 180 degrees, open one wall and close another, and obtain a maze with the same structure (<xref ref-type="fig" rid="fig4">Figure 4A</xref>). Alternatively one can also rotate only the floor. After such a modification, all the physical cues attached to the rotated parts now point in the wrong direction, namely to the end node 180 degrees opposite the water port (the 'image location’). If the animal navigated to the goal following cues previously deposited in the maze, it should end up at that image location.</p><p>We performed a maze rotation on four animals after several hours of exposure, when they had acquired the perfect route to water. Immediately after rotation, three of the four animals went to the correct water port on their first entry into the maze, and before ever visiting the image location (e.g. <xref ref-type="fig" rid="fig4">Figure 4B</xref>). The fourth mouse visited the image location once and then the correct water port (<xref ref-type="fig" rid="fig4s1">Figure 4—figure supplement 1</xref>). The mice continued to collect water rewards efficiently even immediately after the rotation.</p><p>Nonetheless, the maze rotation did introduce subtle changes in behavior that lasted for an hour or more (<xref ref-type="fig" rid="fig4">Figure 4C</xref>). Visits to the image location were at chance levels prior to rotation, then increased by a factor of 1.8. Visits to the water port declined in frequency, although they still exceeded visits to the image location by a factor of 5. The reward rate declined by a factor of 0.7. These effects could be verified for each animal (<xref ref-type="fig" rid="fig4s1">Figure 4—figure supplement 1</xref>). The speed of the mice was not disturbed (<xref ref-type="fig" rid="fig4s2">Figure 4—figure supplement 2</xref>).</p><p>In summary, for navigation to the water port the experienced animals do not strictly depend on physical cues that are attached to the maze. This includes any material they might have deposited, but also pre-existing construction details by which they may have learned to identify locations in the maze. The mice clearly notice a change in these cues, but continue to navigate effectively to the goal. This conclusion applies to the time point of the rotation, a few hours into the experiment. Conceivably, the animal’s navigation policy and its use of sensory cues changes in the course of learning. This and many other questions regarding the mechanisms of cognition will be taken up in a separate study.</p></sec><sec id="s2-4"><title>Discontinuous learning</title><p>While an average across animals shows evidence of rapid learning (<xref ref-type="fig" rid="fig3">Figure 3</xref>) one wonders whether the knowledge is acquired gradually or discontinuously, through moments of ‘sudden insight’. To explore this we scrutinized more closely the time line of individual water-deprived animals in their experience with the maze. The discovery of the water port and the subsequent collection of water drops at a regular rate is one clear change in behavior that relies on new knowledge. Indeed, the rate of water rewards can increase rather suddenly (<xref ref-type="fig" rid="fig3">Figure 3A</xref>), suggesting an instantaneous step in knowledge.</p><p>Over time, the animals learned the path to water not only from the entrance of the maze but from many locations scattered throughout the maze. The largest distance between the water port and an end node in the opposite half of the maze involves 12 steps through 11 intersections (<xref ref-type="fig" rid="fig5">Figure 5A</xref>). Thus, we included as another behavioral variable the occurrence of long direct paths to the water port which reflects how directedly the animals navigate within the maze.</p><fig-group><fig id="fig5" position="float"><label>Figure 5.</label><caption><title>Sudden changes in behavior.</title><p>(<bold>A</bold>) An example of a long uninterrupted path through 11 junctions to the water port (drop icon). Blue circles mark control nodes related by symmetry to the water port to assess the frequency of long paths occurring by chance. (<bold>B</bold>) For one animal (named C1) the cumulative number of rewards (green); of long paths (&gt;6 junctions) to the water port (red); and of similar paths to the three control nodes (blue, divided by 3). All are plotted against the time spent in the maze. Arrowheads indicate the time of sudden changes, obtained from fitting a step function to the rates. (<bold>C</bold>) Same as B for animal B1. (<bold>D</bold>) Same as B for animal C9, an example of more continuous learning.</p><p><supplementary-material id="fig5sdata1"><label>Figure 5—source data 1.</label><caption><title>Statistics of sudden changes in behavior.</title><p>Statistics of sudden changes in behavior. Summary of the steps in the rate of long paths to water detected in 5 of the 10 rewarded animals. Mean and standard deviation of the step time are derived from maximum likelihood fits of a step model to the data.</p></caption><media mime-subtype="pdf" mimetype="application" xlink:href="elife-66175-fig5-data1-v2.pdf"/></supplementary-material></p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-66175-fig5-v2.tif"/></fig><fig id="fig5s1" position="float" specific-use="child-fig"><label>Figure 5—figure supplement 1.</label><caption><title>Long direct paths for all animals.</title><p>Sudden changes in behavior for all rewarded animals. For each of the 10 water-deprived animals this shows the cumulative rate of rewards, of long direct paths (&gt;6 steps) to the water port, and of similar paths to three control nodes. Display as in <xref ref-type="fig" rid="fig5">Figure 5</xref>; panels B-D of that figure are included again here. Dots are data, lines are fits using a four-parameter sigmoid function for the rate of occurrence of the events.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-66175-fig5-figsupp1-v2.tif"/></fig></fig-group><p><xref ref-type="fig" rid="fig5">Figure 5B</xref> shows for one animal the cumulative occurrence of water rewards and that of long direct paths to water. The animal discovers the water port early on at 75 s, but at 1380 s the rate of water rewards jumps suddenly by a factor of 5. The long paths to water follow a rather different time line. At first they occur randomly, at the same rate as the paths to the unrewarded control nodes. At 2070 s the long paths suddenly increase in frequency by a factor of 5. Given the sudden change in rates of both kinds of events there is little ambiguity about when the two steps happen and they are well separated in time (<xref ref-type="fig" rid="fig5">Figure 5B</xref>).</p><p>The animal behaves as though it gains a new insight at the time of the second step that allows it to travel to the water port directly from elsewhere in the maze. Note that the two behavioral variables are independent: The long paths don’t change when the reward rate steps up, and the reward rate doesn’t change when the rate of long paths steps up. Another animal (<xref ref-type="fig" rid="fig5">Figure 5C</xref>) similarly showed an early step in the reward rate (at 860 s) and a dramatic step in the rate of long paths (at 2580 s). In this case, the emergence of long paths coincided with a modest increase (factor of 2) in the reward rate.</p><p>Similar discontinuities in behavior were seen in at least 5 of the 10 water-deprived animals (<xref ref-type="fig" rid="fig5">Figure 5B</xref>, <xref ref-type="fig" rid="fig5s1">Figure 5—figure supplement 1</xref>, <xref ref-type="supplementary-material" rid="fig5sdata1">Figure 5—source data 1</xref>), and their timing could be identified to a precision of ~200 s. More gradual performance change was observed for the remaining animals (<xref ref-type="fig" rid="fig5">Figure 5D</xref>). We varied the criterion of performance by asking for even longer error-free paths, and the results were largely unchanged and no additional discontinuity appeared. These observations suggest that mice can acquire a complex decision-making skill rather suddenly. A mouse may have multiple moments of sudden insight that affect different aspects of its behavior. The exact time of the insight cannot be predicted but is easily identified post-hoc. Future neurophysiological studies of the phenomenon will face the interesting challenge of capturing these singular events.</p></sec><sec id="s2-5"><title>One-shot learning of the home path</title><p>For an animal entering an unfamiliar environment, the most important path to keep in memory may be the escape route. In the present case that is the route to the maze entrance, from which the tunnel leads home to the cage. We expected that the mice would begin by penetrating into the maze gradually and return home repeatedly so as to confirm the escape route, a pattern previously observed for rodents in an open arena (<xref ref-type="bibr" rid="bib36">Tchernichovski et al., 1998</xref>; <xref ref-type="bibr" rid="bib15">Fonio et al., 2009</xref>). This might help build a memory of the home path gradually level-by-level into the binary tree. Nothing could be further from the truth.</p><p>At the end of any given bout into the maze, there is a ‘home run’, namely the direct path without reversals that takes the animal to the exit (see <xref ref-type="fig" rid="fig3s1">Figure 3—figure supplement 1</xref>). <xref ref-type="fig" rid="fig6">Figure 6A</xref> shows the nodes where each animal started its first home run, following the first penetration into the maze. With few exceptions, that first home run began from an end node, as deep into the maze as possible. Recall that this involves making the correct choice at six successive three-way intersections, an outcome that is unlikely to happen by chance.</p><fig id="fig6" position="float"><label>Figure 6.</label><caption><title>Homing succeeds on first attempt.</title><p>(<bold>A</bold>) Locations in the maze where the 19 animals started their first return to the exit (home run). Some locations were used by two or three animals (darker color). (<bold>B</bold>) Left: The cumulative number of home runs from different levels in the maze, summed over all animals, and plotted against the bout number. Level 1 = first T-junction, level 7 = end nodes. Right: Zoom of (Left) into early bouts. (<bold>C</bold>) Overlap between the outbound and the home path. Histogram of the overlap for all bouts of all animals. (<bold>D</bold>) Same analysis for just the first bout of each animal. The length of the home run is color-coded as in panel B.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-66175-fig6-v2.tif"/></fig><p>The above hypothesis regarding gradual practice of home runs would predict that short home runs should appear before long ones in the course of the experiment. The opposite is the case (<xref ref-type="fig" rid="fig6">Figure 6B</xref>). In fact, the end nodes (level 7 of the maze) are by far the favorite place from which to return to the exit, and those maximal-length home runs systematically appear before shorter ones. This conclusion was confirmed for each individual animal, whether rewarded or unrewarded.</p><p>Clearly, the animals do not practice the home path or build it up gradually. Instead they seem to possess an Ariadne’s thread (<xref ref-type="bibr" rid="bib2">Apollodorus, 1921</xref>) starting with their first excursion into the maze, long before they might have acquired any general knowledge of the maze layout. On the other hand, the mouse does not follow the strategy of Theseus, namely to precisely retrace the path that led it into the labyrinth. In that case the animal’s home path should be the reverse of the path into the maze that started the bout. Instead the entry path and the home path tend to have little overlap (<xref ref-type="fig" rid="fig6">Figure 6C</xref>). Note the minimum overlap is 1, because all paths into and out of the maze have to pass through the central junction (node 0 in <xref ref-type="fig" rid="fig3s1">Figure 3—figure supplement 1</xref>). This is also the most frequent overlap. The peak at overlaps 6–8 for rewarded animals results from the frequent paths to the water port and back, a sequence of at least seven nodes in each direction. The separation of outbound and return path is seen even on the very first home run (<xref ref-type="fig" rid="fig6">Figure 6D</xref>). Many home runs from the deepest level (seven nodes) have only the central junction in common with the outbound path (overlap = 1).</p><p>In summary, it appears that the animal acquires a homing strategy over the course of a single bout, and in a manner that allows a direct return home even from locations not previously encountered.</p></sec><sec id="s2-6"><title>Structure of behavior in the maze</title><p>Here, we focus on rules and patterns that govern the animal’s activity in the maze on both large and small scales.</p><sec id="s2-6-1"><title>Behavioral states</title><p>Once the animal has learned to perform long uninterrupted paths to the water port, one can categorize its behavior within the maze by three states: (1) walking to the water port; (2) walking to the exit; and (3) exploring the maze. Operationally we define exploration as all periods in which the animal is in the maze but not on a direct path to water or to the exit. For the 10 sated animals this includes all times in the maze except for the walks to the exit.</p><p><xref ref-type="fig" rid="fig7">Figure 7</xref> illustrates the occupancies and transition probabilities between these states. The animals spent most of their time by far in the exploration state: 84% for rewarded and 95% for unrewarded mice. Across animals there was very little variation in the balance of the three modes (<xref ref-type="supplementary-material" rid="fig7sdata1">Figure 7—source data 1</xref>). The rewarded mice began about half their bouts into the maze with a trip to the water port and the other half by exploring (<xref ref-type="fig" rid="fig7">Figure 7A</xref>). After a drink, the animals routinely continued exploring, about 90% of the time.</p><fig id="fig7" position="float"><label>Figure 7.</label><caption><title>Exploration is a dominant and persistent mode of behavior.</title><p>(<bold>A</bold>) Ethogram for rewarded animals. Area of the circle reflects the fraction of time spent in each behavioral mode averaged over animals and duration of the experiment. Width of the arrow reflects the probability of transitioning to another mode. ‘Drink’ involves travel to the water port and time spent there. Transitions from ‘Leave’ represent what the animal does at the start of the next bout into the maze. (<bold>B</bold>) The fraction of time spent in each mode as a function of absolute time throughout the night. Mean ± SD across the 10 rewarded animals.</p><p><supplementary-material id="fig7sdata1"><label>Figure 7—source data 1.</label><caption><title>Three modes of behavior.</title><p>(<bold>A</bold>) The fraction of time mice spent in each of the three modes while in the maze. Mean ± SD for 10 rewarded and nine unrewarded animals. (<bold>B</bold>) Probability of transitioning from the mode on the left to the mode at the top. Transitions from ‘leave’ represent what the animal does at the start of the next bout into the maze.</p></caption><media mime-subtype="pdf" mimetype="application" xlink:href="elife-66175-fig7-data1-v2.pdf"/></supplementary-material></p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-66175-fig7-v2.tif"/></fig><p>For water-deprived animals, the dominance of exploration persisted even at a late stage of the night when they routinely executed perfect exploitation bouts to and from the water port: Over the duration of the night the ‘explore’ fraction dropped slightly from 0.92 to 0.75, with the balance accrued to the ‘drink’ and ‘leave’ modes as the animals executed many direct runs to the water port and back. The unrewarded group of animals also explored the maze throughout the night even though it offered no overt rewards (<xref ref-type="supplementary-material" rid="fig7sdata1">Figure 7—source data 1</xref>). One suspects that the animals derive some intrinsic reward from the act of patrolling the environment itself.</p></sec><sec id="s2-6-2"><title>Efficiency of exploration</title><p>During the direct paths to water and to the exit the animal behaves deterministically, whereas the exploration behavior appears stochastic. Here, we delve into the rules that govern the exploration component of behavior.</p><p>One can presume that a goal of the exploratory mode is to rapidly survey all parts of the environment for the appearance of new resources or threats. We will measure the efficiency of exploration by how rapidly the animal visits all end nodes of the binary maze, starting at any time during the experiment. The optimal agent with perfect memory and complete knowledge of the maze – including the absence of any loops – could visit the end nodes systematically one after another without repeats, thus encountering all of them after just 64 visits. A less perfect agent, on the other hand, will visit the same node repeatedly before having encountered all of them. <xref ref-type="fig" rid="fig8">Figure 8A</xref> plots for one exploring mouse the number of distinct end nodes it encountered as a function of the number of end nodes visited. The number of new nodes rises monotonically; 32 of the end nodes have been discovered after the mouse checked 76 times; then the curve gradually asymptotes to 64. We will characterize the efficiency of the search by the number of visits <italic>N</italic><sub>32</sub> required to survey half the end nodes, and define<disp-formula id="equ1"><label>(1)</label><mml:math id="m1"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>E</mml:mi><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mn>32</mml:mn></mml:mrow><mml:mrow><mml:mrow><mml:msub><mml:mi>N</mml:mi><mml:mrow><mml:mn>32</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:mrow></mml:mfrac></mml:mrow></mml:mstyle></mml:math></disp-formula></p><p>This mouse explores with efficiency <italic>E</italic> = 32/76 = 0.42. For comparison, <xref ref-type="fig" rid="fig8">Figure 8A</xref> plots the performance of the optimal agent (<italic>E</italic> = 1.0) and that of a random walker that makes random decisions at every three-way junction (<italic>E</italic> = 0.23). Note the mouse is about half as efficient as the optimal agent, but twice as efficient as a random walker.</p><fig-group><fig id="fig8" position="float"><label>Figure 8.</label><caption><title>Exploration covers the maze efficiently.</title><p>(<bold>A</bold>) The number of distinct end nodes encountered as a function of the number of end nodes visited for: mouse C1 (red); the optimal explorer agent (black); an unbiased random walk (blue). Arrowhead: the value <inline-formula><mml:math id="inf9"><mml:mrow><mml:msub><mml:mi>N</mml:mi><mml:mn>32</mml:mn></mml:msub><mml:mo>=</mml:mo><mml:mn>76</mml:mn></mml:mrow></mml:math></inline-formula> by which mouse C1 discovered half of the end nodes. (<bold>B</bold>) An expanded section of the graph in A including curves from 10 rewarded (red) and nine unrewarded (green) animals. The efficiency of exploration, defined as <inline-formula><mml:math id="inf10"><mml:mrow><mml:mi>E</mml:mi><mml:mo>=</mml:mo><mml:mrow><mml:mn>32</mml:mn><mml:mo>/</mml:mo><mml:msub><mml:mi>N</mml:mi><mml:mn>32</mml:mn></mml:msub></mml:mrow></mml:mrow></mml:math></inline-formula>, is <inline-formula><mml:math id="inf11"><mml:mrow><mml:mn>0.385</mml:mn><mml:mo>±</mml:mo><mml:mn>0.050</mml:mn></mml:mrow></mml:math></inline-formula> (SD) for rewarded and <inline-formula><mml:math id="inf12"><mml:mrow><mml:mn>0.384</mml:mn><mml:mo>±</mml:mo><mml:mn>0.039</mml:mn></mml:mrow></mml:math></inline-formula> (SD) for unrewarded mice. (<bold>C</bold>) The efficiency of exploration for the same animals, comparing the values in the first and second halves of the time in the maze. The decline is a factor of <inline-formula><mml:math id="inf13"><mml:mrow><mml:mn>0.74</mml:mn><mml:mo>±</mml:mo><mml:mn>0.12</mml:mn></mml:mrow></mml:math></inline-formula> (SD) for rewarded and <inline-formula><mml:math id="inf14"><mml:mrow><mml:mn>0.81</mml:mn><mml:mo>±</mml:mo><mml:mn>0.13</mml:mn></mml:mrow></mml:math></inline-formula> (SD) for unrewarded mice.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-66175-fig8-v2.tif"/></fig><fig id="fig8s1" position="float" specific-use="child-fig"><label>Figure 8—figure supplement 1.</label><caption><title>Efficiency of exploration.</title><p>Functional fits to measure exploration efficiency (<bold>A</bold>) Fitting <xref ref-type="disp-formula" rid="equ13">Equation 12</xref> to the data from the mouse’s exploration. Animals with best fit (top) and worst fit (bottom). The relative uncertainty in the two fit parameters <inline-formula><mml:math id="inf15"><mml:mi>a</mml:mi></mml:math></inline-formula> and <inline-formula><mml:math id="inf16"><mml:mi>b</mml:mi></mml:math></inline-formula> was only <inline-formula><mml:math id="inf17"><mml:mrow><mml:mn>0.0038</mml:mn><mml:mo>±</mml:mo><mml:mn>0.0020</mml:mn></mml:mrow></mml:math></inline-formula> (mean ± SD across animals). (<bold>B</bold>) The fit parameter <inline-formula><mml:math id="inf18"><mml:mi>b</mml:mi></mml:math></inline-formula> for all animals, comparing the first to the second half of the night. (<bold>C</bold>) The efficiency <inline-formula><mml:math id="inf19"><mml:mi>E</mml:mi></mml:math></inline-formula> (<xref ref-type="disp-formula" rid="equ1">Equation 1</xref>) predicted from two models of the mouse’s trajectory: The 4-bias random walk (<xref ref-type="fig" rid="fig11">Figure 11D</xref>) and the optimal Markov chain (<xref ref-type="fig" rid="fig11">Figure 11C</xref>).</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-66175-fig8-figsupp1-v2.tif"/></fig></fig-group><p>The different mice were remarkably alike in this component of their exploratory behavior (<xref ref-type="fig" rid="fig8">Figure 8B</xref>): across animals the efficiency varied by only 11% of the mean (0.387 ± 0.044 SD). Furthermore, there was no detectable difference in efficiency between the rewarded animals and the sated unrewarded animals. Over the course of the night, the efficiency declined significantly for almost every animal – whether rewarded or not – by an average of 23% (<xref ref-type="fig" rid="fig8">Figure 8C</xref>).</p></sec><sec id="s2-6-3"><title>Rules of exploration</title><p>What allows the mice to search much more efficiently than a random walking agent? We inspected more closely the decisions that the animals make at each three-way junction. It emerged that these decisions are governed by strong biases (<xref ref-type="fig" rid="fig9">Figure 9</xref>). The probability of choosing each arm of a T-junction depends crucially on how the animal entered the junction. The animal can enter a T-junction from three places and exit it in three directions (<xref ref-type="fig" rid="fig9">Figure 9A</xref>). By tallying the frequency of all these occurrences across all T-junctions in the maze one finds clear deviations from an unbiased random walk (<xref ref-type="fig" rid="fig9">Figure 9B</xref>, <xref ref-type="supplementary-material" rid="fig9sdata1">Figure 9—source data 1</xref>).</p><fig id="fig9" position="float"><label>Figure 9.</label><caption><title>Turning biases favor exploration.</title><p>(<bold>A</bold>) Definition of four turning biases at a T-junction based on the ratios of actions taken. Top: An animal arriving from the stem of the T (shaded) may either reverse or turn left or right. <inline-formula><mml:math id="inf20"><mml:msub><mml:mi>P</mml:mi><mml:mi>SF</mml:mi></mml:msub></mml:math></inline-formula> is the probability that it will move forward rather than reversing. Given that it moves forward, <inline-formula><mml:math id="inf21"><mml:msub><mml:mi>P</mml:mi><mml:mi>SA</mml:mi></mml:msub></mml:math></inline-formula> is the probability that it will take an alternating turn from the preceding one (gray), that is left-right or right-left. Bottom: An animal arriving from the bar of the T may either reverse or go straight, or turn into the stem of the T. <inline-formula><mml:math id="inf22"><mml:msub><mml:mi>P</mml:mi><mml:mi>BF</mml:mi></mml:msub></mml:math></inline-formula> is the probability that it will move forward through the junction rather than reversing. Given that it moves forward, <inline-formula><mml:math id="inf23"><mml:msub><mml:mi>P</mml:mi><mml:mi>BS</mml:mi></mml:msub></mml:math></inline-formula> is the probability that it turns into the stem. (<bold>B</bold>) Scatter graph of the biases <inline-formula><mml:math id="inf24"><mml:msub><mml:mi>P</mml:mi><mml:mi>SF</mml:mi></mml:msub></mml:math></inline-formula> and <inline-formula><mml:math id="inf25"><mml:msub><mml:mi>P</mml:mi><mml:mi>BF</mml:mi></mml:msub></mml:math></inline-formula> (left) and <inline-formula><mml:math id="inf26"><mml:msub><mml:mi>P</mml:mi><mml:mi>SA</mml:mi></mml:msub></mml:math></inline-formula> and <inline-formula><mml:math id="inf27"><mml:msub><mml:mi>P</mml:mi><mml:mi>BS</mml:mi></mml:msub></mml:math></inline-formula> (right). Every dot represents a mouse. Cross: values for an unbiased random walk. (<bold>C</bold>) Exploration curve of new end nodes discovered vs end nodes visited, displayed as in <xref ref-type="fig" rid="fig8">Figure 8A</xref>, including results from a biased random walk with the four turning biases derived from the same mouse, as well as a more elaborate Markov-chain model (see <xref ref-type="fig" rid="fig11">Figure 11C</xref>). (<bold>D</bold>) Efficiency of exploration (<xref ref-type="disp-formula" rid="equ1">Equation 1</xref>) in 19 mice compared to the efficiency of the corresponding biased random walk.</p><p><supplementary-material id="fig9sdata1"><label>Figure 9—source data 1.</label><caption><title>Bias statistics.</title><p>Statistics of the four turning biases. Mean and standard deviation of the 4 biases of <xref ref-type="fig" rid="fig9">Figure 9A–B</xref> across animals in the rewarded and unrewarded groups.</p></caption><media mime-subtype="pdf" mimetype="application" xlink:href="elife-66175-fig9-data1-v2.pdf"/></supplementary-material></p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-66175-fig9-v2.tif"/></fig><p>First, the animals have a strong preference for proceeding through a junction rather than returning to the preceding node (<inline-formula><mml:math id="inf28"><mml:msub><mml:mi>P</mml:mi><mml:mi>SF</mml:mi></mml:msub></mml:math></inline-formula> and <inline-formula><mml:math id="inf29"><mml:msub><mml:mi>P</mml:mi><mml:mi>BF</mml:mi></mml:msub></mml:math></inline-formula> in <xref ref-type="fig" rid="fig9">Figure 9B</xref>). Second, there is a bias in favor of alternating turns left and right rather than repeating the same direction turn (<inline-formula><mml:math id="inf30"><mml:msub><mml:mi>P</mml:mi><mml:mi>SA</mml:mi></mml:msub></mml:math></inline-formula>). Finally, the mice have a mild preference for taking a branch off the straight corridor rather than proceeding straight (<inline-formula><mml:math id="inf31"><mml:msub><mml:mi>P</mml:mi><mml:mi>BS</mml:mi></mml:msub></mml:math></inline-formula>). A comparison across animals again revealed a remarkable degree of consistency even in these local rules of behavior: The turning biases varied by only 3% across the population and even between the rewarded and unrewarded groups (<xref ref-type="fig" rid="fig9">Figure 9B</xref>, <xref ref-type="supplementary-material" rid="fig9sdata1">Figure 9—source data 1</xref>).</p><p>Qualitatively, one can see that these turning biases will improve the animal’s search strategy. The forward biases <inline-formula><mml:math id="inf32"><mml:msub><mml:mi>P</mml:mi><mml:mi>SF</mml:mi></mml:msub></mml:math></inline-formula> and <inline-formula><mml:math id="inf33"><mml:msub><mml:mi>P</mml:mi><mml:mi>BF</mml:mi></mml:msub></mml:math></inline-formula> keep the animal from re-entering territory it has covered already. The bias <inline-formula><mml:math id="inf34"><mml:msub><mml:mi>P</mml:mi><mml:mi>BS</mml:mi></mml:msub></mml:math></inline-formula> favors taking a branch that leads out of the maze. This allows the animal to rapidly cross multiple levels during an outward path and then enter a different territory. By comparison, the unbiased random walk tends to get stuck in the tips of the tree and revisits the same end nodes many times before escaping. To test this intuition, we simulated a biased random agent whose turning probabilities at a T-junction followed the same biases as measured from the animal (<xref ref-type="fig" rid="fig9">Figure 9C</xref>). These biased agents did in fact search with much higher efficiency than the unbiased random walk. They did not fully explain the behavior of the mice (<xref ref-type="fig" rid="fig9">Figure 9D</xref>), accounting for ~87% of the animal’s efficiency (compared to 60% for the random walk). A more sophisticated model of the animal’s behavior - involving many more parameters (Figure 11C) - failed to get any closer to the observed efficiency (<xref ref-type="fig" rid="fig9">Figure 9C</xref>, <xref ref-type="fig" rid="fig8s1">Figure 8—figure supplement 1C</xref>). Clearly some components of efficient search in these mice remain to be understood.</p></sec><sec id="s2-6-4"><title>Systematic node preferences</title><p>A surprising aspect of the animals’ explorations is that they visit certain end nodes of the binary tree much more frequently than others (<xref ref-type="fig" rid="fig10">Figure 10</xref>). This effect is large: more than a factor of 10 difference between the occupancy of the most popular and least popular end nodes (<xref ref-type="fig" rid="fig10">Figure 10A–B</xref>). This was surprising given our efforts to design the maze symmetrically, such that in principle all end nodes should be equivalent. Furthermore, the node preferences were very consistent across animals and even across the rewarded and unrewarded groups. Note that the standard error across animals of each node’s occupancy is much smaller than the differences between the nodes (<xref ref-type="fig" rid="fig10">Figure 10B</xref>).</p><fig id="fig10" position="float"><label>Figure 10.</label><caption><title>Preference for certain end nodes during exploration.</title><p>(<bold>A</bold>) The number of visits to different end nodes encoded by a gray scale. Top: rewarded, bottom: unrewarded animals. Gray scale spans a factor of 12 (top) or 13 (bottom). (<bold>B</bold>) The fraction of visits to each end node, comparing the rewarded vs unrewarded group of animals. Each data point is for one end node, the error bar is the SEM across animals in the group. The outlier on the bottom right is the neighbor of the water port, a frequently visited end node among rewarded animals. The water port is off scale and not shown. (<bold>C</bold>) As in panel B but comparing the unrewarded animals to their simulated 4-bias random walks. These biases explain 51% of the variance in the observed preference for end nodes.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-66175-fig10-v2.tif"/></fig><p>The nodes on the periphery of the maze are systematically preferred. Comparing the outermost ring of 26 end nodes (excluding the water port and its neighbor) to the innermost 16 end nodes, the outer ones are favored by a large factor of 2.2. This may relate to earlier reports of a ‘centrifugal tendency’ among rats patrolling a maze (<xref ref-type="bibr" rid="bib41">Uster et al., 1976</xref>).</p><p>Interestingly, the biased random walk using four bias numbers (<xref ref-type="fig" rid="fig9">Figure 9</xref>, <xref ref-type="fig" rid="fig11">Figure 11D</xref>) replicates a good amount of the pattern of preferences. For unrewarded animals, where the maze symmetry is not disturbed by the water port, the biased random walk predicts 51% of the observed variance across nodes (<xref ref-type="fig" rid="fig10">Figure 10C</xref>), and an outer/inner node preference of 1.97, almost matching the observed ratio of 2.20. The more complex Markov-chain model of behavior (<xref ref-type="fig" rid="fig11">Figure 11C</xref>) performed slightly better, explaining 66% of the variance in port visits and matching the outer/inner node preference of 2.20.</p><fig-group><fig id="fig11" position="float"><label>Figure 11.</label><caption><title>Recent history constrains the mouse’s decisions.</title><p>(<bold>A</bold>) The mouse’s trajectory through the maze produces a sequence of states <inline-formula><mml:math id="inf35"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>s</mml:mi><mml:mi>t</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mrow><mml:mspace width="thinmathspace"/><mml:mi mathvariant="normal">n</mml:mi><mml:mi mathvariant="normal">o</mml:mi><mml:mi mathvariant="normal">d</mml:mi><mml:mi mathvariant="normal">e</mml:mi><mml:mspace width="thinmathspace"/><mml:mi mathvariant="normal">o</mml:mi><mml:mi mathvariant="normal">c</mml:mi><mml:mi mathvariant="normal">c</mml:mi><mml:mi mathvariant="normal">u</mml:mi><mml:mi mathvariant="normal">p</mml:mi><mml:mi mathvariant="normal">i</mml:mi><mml:mi mathvariant="normal">e</mml:mi><mml:mi mathvariant="normal">d</mml:mi><mml:mspace width="thinmathspace"/><mml:mi mathvariant="normal">a</mml:mi><mml:mi mathvariant="normal">f</mml:mi><mml:mi mathvariant="normal">t</mml:mi><mml:mi mathvariant="normal">e</mml:mi><mml:mi mathvariant="normal">r</mml:mi><mml:mspace width="thinmathspace"/><mml:mi mathvariant="normal">s</mml:mi><mml:mi mathvariant="normal">t</mml:mi><mml:mi mathvariant="normal">e</mml:mi><mml:mi mathvariant="normal">p</mml:mi><mml:mspace width="thinmathspace"/></mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:mstyle></mml:math></inline-formula><inline-formula><mml:math id="inf36"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>s</mml:mi><mml:mi>t</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mrow><mml:mi mathvariant="normal">n</mml:mi><mml:mi mathvariant="normal">o</mml:mi><mml:mi mathvariant="normal">d</mml:mi><mml:mi mathvariant="normal">e</mml:mi><mml:mspace width="thinmathspace"/><mml:mi mathvariant="normal">o</mml:mi><mml:mi mathvariant="normal">c</mml:mi><mml:mi mathvariant="normal">c</mml:mi><mml:mi mathvariant="normal">u</mml:mi><mml:mi mathvariant="normal">p</mml:mi><mml:mi mathvariant="normal">i</mml:mi><mml:mi mathvariant="normal">e</mml:mi><mml:mi mathvariant="normal">d</mml:mi><mml:mspace width="thinmathspace"/><mml:mi mathvariant="normal">a</mml:mi><mml:mi mathvariant="normal">f</mml:mi><mml:mi mathvariant="normal">t</mml:mi><mml:mi mathvariant="normal">e</mml:mi><mml:mi mathvariant="normal">r</mml:mi><mml:mspace width="thinmathspace"/><mml:mi mathvariant="normal">s</mml:mi><mml:mi mathvariant="normal">t</mml:mi><mml:mi mathvariant="normal">e</mml:mi><mml:mi mathvariant="normal">p</mml:mi><mml:mspace width="thinmathspace"/></mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:mstyle></mml:math></inline-formula><inline-formula><mml:math id="inf37"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>s</mml:mi><mml:mi>t</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mrow><mml:mi mathvariant="normal">n</mml:mi><mml:mi mathvariant="normal">o</mml:mi><mml:mi mathvariant="normal">d</mml:mi><mml:mi mathvariant="normal">e</mml:mi><mml:mspace width="thinmathspace"/><mml:mi mathvariant="normal">o</mml:mi><mml:mi mathvariant="normal">c</mml:mi><mml:mi mathvariant="normal">c</mml:mi><mml:mi mathvariant="normal">u</mml:mi><mml:mi mathvariant="normal">p</mml:mi><mml:mi mathvariant="normal">i</mml:mi><mml:mi mathvariant="normal">e</mml:mi><mml:mi mathvariant="normal">d</mml:mi><mml:mspace width="thinmathspace"/><mml:mi mathvariant="normal">a</mml:mi><mml:mi mathvariant="normal">f</mml:mi><mml:mi mathvariant="normal">t</mml:mi><mml:mi mathvariant="normal">e</mml:mi><mml:mi mathvariant="normal">r</mml:mi><mml:mspace width="thinmathspace"/><mml:mi mathvariant="normal">s</mml:mi><mml:mi mathvariant="normal">t</mml:mi><mml:mi mathvariant="normal">e</mml:mi><mml:mi mathvariant="normal">p</mml:mi><mml:mspace width="thinmathspace"/></mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:mstyle></mml:math></inline-formula>. From each state, up to three possible actions lead to the next state (end nodes allow only one action). We want to predict the animal’s next action, <inline-formula><mml:math id="inf38"><mml:msub><mml:mi>a</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:math></inline-formula>, based on the prior history of states or actions. (<bold>B–D</bold>) Three possible models to make such a prediction. (<bold>B</bold>) A fixed-depth Markov chain where the probability of the next action depends only on the current state <inline-formula><mml:math id="inf39"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>s</mml:mi><mml:mi>t</mml:mi></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula> and the preceding state <inline-formula><mml:math id="inf40"><mml:msub><mml:mi>s</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mo>-</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:math></inline-formula>. The branches of the tree represent all <inline-formula><mml:math id="inf41"><mml:mrow><mml:mn>3</mml:mn><mml:mo>×</mml:mo><mml:mn>127</mml:mn></mml:mrow></mml:math></inline-formula> possible histories <inline-formula><mml:math id="inf42"><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>s</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mo>-</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>s</mml:mi><mml:mi>t</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></inline-formula>. (<bold>C</bold>) A variable-depth Markov chain where only certain branches of the tree of histories contribute to the action probability. Here one history contains only the current state, some others reach back three steps. (<bold>D</bold>) A biased random walk model, as defined in <xref ref-type="fig" rid="fig9">Figure 9</xref>, in which the probability of the next action depends only on the preceding action, not on the state. (<bold>E</bold>) Performance of the models in (<bold>B,C,D</bold>) when predicting the decisions of the animal at T-junctions. In each case we show the cross-entropy between the predicted action probability and the real actions of the animal (lower values indicate better prediction, perfect prediction would produce zero). Dotted line represents an unbiased random walk with 1/3 probability of each action.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-66175-fig11-v2.tif"/></fig><fig id="fig11s1" position="float" specific-use="child-fig"><label>Figure 11—figure supplement 1.</label><caption><title>Markov model fits.</title><p>Fitting Markov models of behavior. (<bold>A</bold>) Results of fitting the node sequence of a single animal (<bold>C3</bold>) with Markov models having a fixed depth (‘fix’) or variable depth (‘var’). The cross-entropy of the model’s prediction is plotted as a function of the average depth of history. In both cases we compare the results obtained on the training data (‘train’) vs those on separate testing data (‘test’). Note that at larger depth the ‘test’ and ‘train’ estimates diverge, a sign of over-fitting the limited data available. (<bold>B</bold>) As in (<bold>A</bold>) but to combat the data limitation we pooled the counts obtained at all nodes that were equivalent under the symmetry of the maze (see Materials and methods). Note considerably less divergence between ‘train’ and ‘test’ results, and a slightly lower cross-entropy during ‘test’ than in (<bold>A</bold>). (<bold>C</bold>) The minimal cross-entropy (circles in (<bold>B</bold>)) produced by variable vs fixed history models for each of the 19 animals. Note the variable history model always produces a better fit to the behavior.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-66175-fig11-figsupp1-v2.tif"/></fig></fig-group></sec></sec><sec id="s2-7"><title>Models of maze behavior</title><p>Moving beyond the efficiency of exploration one may ask more broadly: How well do we really understand what the mouse does in the maze? Can we predict its action at the next junction? Once the predictable component is removed, how much intrinsic randomness remains in the mouse’s behavior? Here, we address these questions using more sophisticated models that predict the probability of the mouse’s future actions based on the history of its trajectory.</p><p>At a formal level, the mouse’s trajectory through the maze is a string of numbers standing for the nodes the animal visited (<xref ref-type="fig" rid="fig11">Figure 11A</xref> and <xref ref-type="fig" rid="fig3s1">Figure 3—figure supplement 1</xref>). We want to predict the next action of the mouse, namely the step that takes it to the next node. The quality of the model will be assessed by the cross-entropy between the model’s predictions and the mouse’s observed actions, measured in bits per action. This is the uncertainty that remains about the mouse’s next action given the prediction from the model. The ultimate lower limit is the true source entropy of the mouse, namely that component of its decisions that cannot be explained by the history of its actions.</p><p>One family of models we considered are fixed-depth Markov chains (<xref ref-type="fig" rid="fig11">Figure 11B</xref>). Here, the probability of the next action <inline-formula><mml:math id="inf43"><mml:msub><mml:mi>a</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:math></inline-formula> is specified as a function of the history stretching over the <inline-formula><mml:math id="inf44"><mml:mi>k</mml:mi></mml:math></inline-formula> preceding nodes <inline-formula><mml:math id="inf45"><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>s</mml:mi><mml:mrow><mml:mrow><mml:mi>t</mml:mi><mml:mo>-</mml:mo><mml:mi>k</mml:mi></mml:mrow><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:mi mathvariant="normal">…</mml:mi><mml:mo>,</mml:mo><mml:msub><mml:mi>s</mml:mi><mml:mi>t</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></inline-formula>. In fitting the model to the mouse’s actual node sequence one tallies how often each history leads to each action, and uses those counts to estimate the conditional probabilities <inline-formula><mml:math id="inf46"><mml:mrow><mml:mi>p</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:msub><mml:mi>a</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo lspace="2.5pt" rspace="2.5pt" stretchy="false">|</mml:mo><mml:mrow><mml:msub><mml:mi>s</mml:mi><mml:mrow><mml:mrow><mml:mi>t</mml:mi><mml:mo>-</mml:mo><mml:mi>k</mml:mi></mml:mrow><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:mi mathvariant="normal">…</mml:mi><mml:mo>,</mml:mo><mml:msub><mml:mi>s</mml:mi><mml:mi>t</mml:mi></mml:msub></mml:mrow></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula>. Given a new node sequence, the model will then use the history strings <inline-formula><mml:math id="inf47"><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>s</mml:mi><mml:mrow><mml:mrow><mml:mi>t</mml:mi><mml:mo>-</mml:mo><mml:mi>k</mml:mi></mml:mrow><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:mi mathvariant="normal">…</mml:mi><mml:mo>,</mml:mo><mml:msub><mml:mi>s</mml:mi><mml:mi>t</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></inline-formula> to predict the outcome of the next action. In practice, we trained the model on 80% of the animal’s trajectory and tested it by evaluating the cross-entropy on the remaining 20%.</p><p>Ideally, the depth <inline-formula><mml:math id="inf48"><mml:mi>k</mml:mi></mml:math></inline-formula> of these action trees would be very large, so as to take as much of the prior history into account as possible. However, one soon runs into a problem of over-fitting: Because each T-junction in the maze has three neighboring junctions, the number of possible histories grows as <inline-formula><mml:math id="inf49"><mml:msup><mml:mn>3</mml:mn><mml:mi>k</mml:mi></mml:msup></mml:math></inline-formula>. As <inline-formula><mml:math id="inf50"><mml:mi>k</mml:mi></mml:math></inline-formula> increases, this quickly exceeds the length of the measured node sequence, so that every history appears only zero or one times in the data. At this point, one can no longer estimate any probabilities, and cross-validation on a different segment of data fails catastrophically. In practice, we found that this limitation sets in already beyond <inline-formula><mml:math id="inf51"><mml:mrow><mml:mi>k</mml:mi><mml:mo>=</mml:mo><mml:mn>2</mml:mn></mml:mrow></mml:math></inline-formula> (<xref ref-type="fig" rid="fig11s1">Figure 11—figure supplement 1A</xref>). To address this issue of data-limitation, we developed a variable-depth Markov chain (<xref ref-type="fig" rid="fig11">Figure 11C</xref>). This model retains longer histories, but only if they occur frequently enough to allow a reliable probability estimate (see Materials and methods, <xref ref-type="fig" rid="fig11s1">Figure 11—figure supplement 1B–C</xref>). In addition, we explored different schemes of pooling the counts across certain T-junctions that are related by the symmetry of the maze (see Materials and methods).</p><p>With these methods, we focused on the portions of trajectory when the mouse was in ‘explore’ mode, because the segments in ‘drink’ and ‘leave’ mode are fully predictable. Furthermore, we evaluated the models only at nodes corresponding to T-junctions, because the decision from an end node is again fully predictable. <xref ref-type="fig" rid="fig11">Figure 11E</xref> compares the performance of various models of mouse behavior. The variable-depth Markov chains routinely produced the best fits, although the improvement over fixed-depth models was modest. Across all 19 animals in this study the remaining uncertainty about the animal’s action at a T-junction is 1.237 ± 0.035 (SD) bits/action, compared to the prior uncertainty of <italic>log</italic><sub>2</sub> 3 = 1.585 bits. The rewarded animals have slightly lower entropy than the unrewarded ones (1.216 vs 1.261 bits/action). The Markov chain models that produced the best fits to the behavior used history strings with an average length of ~4.</p><p>We also evaluated the predictions obtained from the simple biased random walk model (<xref ref-type="fig" rid="fig11">Figure 11D</xref>). Recall that this attempts to capture the history-dependence with just four bias parameters (<xref ref-type="fig" rid="fig9">Figure 9A</xref>). As expected, this produced considerably higher cross-entropies than the more sophisticated Markov chains (by about 18%, <xref ref-type="fig" rid="fig11">Figure 11E</xref>). Finally, we used several professional file compression routines to try and compress the mouse’s node sequence. In principle, this sets an upper bound on the true source entropy of the mouse, even if the compression algorithm has no understanding of animal behavior. The best such algorithm (bzip2 compression <xref ref-type="bibr" rid="bib33">Seward, 2019</xref>) far under-performed all the other models of mouse behavior, giving 43% higher cross-entropy on average, and thus offered no additional useful bounds.</p><p>We conclude that during exploration of the maze the mouse’s choice behavior is strongly influenced by its current location and ~3 locations preceding it. There are minor contributions from states further back. By knowing the animal’s history one can narrow down its action plan at a junction from the a priori 1.59 bits (one of three possible actions) to just ~1.24 bits. This finally is a quantitative answer to the question, ‘How well can one predict the animal’s behavior?’ Whether the remainder represents an irreducible uncertainty – akin to ‘free will’ of the mouse – remains to be seen. Readers are encouraged to improve on this number by applying their own models of behavior to our published data set.</p></sec></sec><sec id="s3" sec-type="discussion"><title>Discussion</title><sec id="s3-1"><title>Summary of contributions</title><p>We present a new approach to the study of learning and decision-making in mice. We give the animal access to a complex labyrinth and leave it undisturbed for a night while monitoring its movements. The result is a rich data set that reveals new aspects of learning and the structure of exploratory behavior. With these methods, we find that mice learn a complex task that requires six correct three-way decisions after only ~10 experiences of success (<xref ref-type="fig" rid="fig2">Figure 2</xref>, <xref ref-type="fig" rid="fig3">Figure 3</xref>). Along the way the animal gains task knowledge in discontinuous steps that can be localized to within a few minutes of resolution (<xref ref-type="fig" rid="fig5">Figure 5</xref>). Underlying the learning process is an exploratory behavior that occupies 90% of the animal’s time in the maze and persists long after the task has been mastered, even in complete absence of an extrinsic reward (<xref ref-type="fig" rid="fig7">Figure 7</xref>). The decisions the animal makes at choice points in the labyrinth are constrained in part by the history of its actions (<xref ref-type="fig" rid="fig9">Figure 9</xref>, <xref ref-type="fig" rid="fig11">Figure 11</xref>), in a way that favors efficient searching of the maze (<xref ref-type="fig" rid="fig8">Figure 8</xref>). This microstructure of behavior is surprisingly consistent across mice, with variation in parameters of only a few percent (<xref ref-type="fig" rid="fig9">Figure 9</xref>). Our most expressive models to predict the animal’s choices still leave a remaining uncertainty of ~1.24 bits per decision (<xref ref-type="fig" rid="fig11">Figure 11</xref>), a quantitative benchmark by which competing models can be tested. Finally, some of the observations constrain what algorithms the animals might use for learning and navigation (<xref ref-type="fig" rid="fig4">Figure 4</xref>).</p></sec><sec id="s3-2"><title>Historical context</title><p>Mazes have been a staple of animal psychology for well over 100 years. The early versions were true labyrinths. For example, <xref ref-type="bibr" rid="bib35">Small, 1901</xref> built a model of the maze in Hampton Court gardens scaled to rat size. Subsequent researchers felt less constrained by Victorian landscapes and began to simplify the maze concept. Most commonly the maze offered one standard path from a starting location to a food reward box. A few blind alleys would branch from the standard path, and researchers would tally how many errors the animal committed by briefly turning into a blind (<xref ref-type="bibr" rid="bib39">Tolman and Honzik, 1930</xref>). Later on, the design was further reduced to a single T-junction. After all, the elementary act of maze navigation is whether to turn left or right at a junction (<xref ref-type="bibr" rid="bib37">Tolman, 1938</xref>), so why not study that process in isolation? And reducing the concept even further, one can ask the animal to refrain from walking altogether, and instead poke its nose into a hole on the left or the right side of a box (<xref ref-type="bibr" rid="bib40">Uchida and Mainen, 2003</xref>). This led to the popular behavior boxes now found in rodent neuroscience laboratories everywhere. Each of these reductions of the ‘maze’ concept enabled a new type of experiment to study learning and decision-making, for example limiting the number of choice points allows one to better sample neural activity at each one. However, the essence of a ‘confusing network of paths’ has been lost along the way, and with it the behavioral richness of the animals navigating those decisions.</p><p>Owing in part to the dissemination of user-friendly tools for animal tracking, one sees a renaissance of experiments that embrace complex environments, including mazes with many choice points (<xref ref-type="bibr" rid="bib1">Alonso et al., 2020</xref>; <xref ref-type="bibr" rid="bib44">Wood et al., 2018</xref>; <xref ref-type="bibr" rid="bib32">Sato et al., 2018</xref>; <xref ref-type="bibr" rid="bib25">Nagy et al., 2020</xref>; <xref ref-type="bibr" rid="bib30">Rondi-Reig et al., 2006</xref>; <xref ref-type="bibr" rid="bib46">Yoder et al., 2011</xref>; <xref ref-type="bibr" rid="bib22">McNamara et al., 2014</xref>), 3-dimensional environments (<xref ref-type="bibr" rid="bib17">Grobéty and Schenk, 1992</xref>), and infinite mazes (<xref ref-type="bibr" rid="bib34">Shokaku et al., 2020</xref>). The labyrinth in the present study is considerably more complex than Hampton Court or most of the mazes employed by Tolman and others (<xref ref-type="bibr" rid="bib39">Tolman and Honzik, 1930</xref>; <xref ref-type="bibr" rid="bib9">Buel, 1934</xref>; <xref ref-type="bibr" rid="bib23">Munn, 1950a</xref>). In those mazes, the blind alleys are all short and unbranched; when an animal strays from the target path it receives feedback quickly and can correct. By contrast, our binary tree maze has 64 equally deep branches, only one of which contains the reward port. If the animal makes a mistake at any level of the tree, it can find out only after traveling all the way to the last node.</p><p>Another crucial aspect of our experimental design is the absence of any human interference. Most studies of animal navigation and learning involve some kind of trial structure. For example, the experimenter puts the rat in the start box, watches it make its way through the maze, coaxes it back on the path if necessary, and picks it up once it reaches the target box. Then another trial starts. In modern experiments with two-alternative-forced-choice (2AFC) behavior boxes the animal doesn’t have to be picked up, but a trial starts with appearance of a cue, and then proceeds through some strict protocol through delivery of the reward. The argument in favor of imposing a trial structure is that it creates reproducible conditions, so that one can gather comparable data and average them suitably over many trials.</p><p>Our experiments had no imposed structure whatsoever; in fact, it may be inappropriate to call them experiments. The investigator opened the entry to the maze in the evening and did not return until the morning. A potential advantage of leaving the animals to themselves is that they are more likely to engage in mouse-like behavior, rather than constantly responding to the stress of human interference or the alienation from being a cog in a behavior machine. The result was a rich data set, with the typical animal delivering ~15,000 decisions in a single night, even if one only counts the nodes of the binary tree as decision points. Since the mice made all the choices, the scientific effort lay primarily in adapting methods of data analysis to the nature of mouse trajectories. Somewhat surprisingly, the absence of experimental structure was no obstacle to making precise and reproducible measurements of the animal’s behavior.</p></sec><sec id="s3-3"><title>How fast do animals learn?</title><p>Among the wide range of phenomena of animal learning, one can distinguish easy and hard tasks by some measure of task complexity. In a simple picture of a behavioral task, the animal needs to recognize several different contexts and based on that express one of several different actions. One can draw up a contingency table between contexts and actions, and measure the complexity of the task by the mutual information in that table. This ignores any task difficulties associated with sensing the context at all or with producing the desired actions. However, in all the examples discussed here, the stimuli are discriminated easily and the actions come naturally, thus the learning difficulty lies only in forming the associations, not in sharpening the perceptual mechanisms or practicing complex motor output.</p><p>Many well-studied behaviors have a complexity of 1 bit or less, and often animals can learn these associations after a single experience. For example, in the Bruce effect (<xref ref-type="bibr" rid="bib8">Bruce, 1959</xref>), the female maps two different contexts (smell of mate vs non-mate) onto two kinds of pregnancy outcomes (carry to term vs abort). The mutual information in that contingency table is at most one bit, and may be considerably lower, for example if non-mate males are very rare or very frequent. Mice form the correct association after a single instance of mating, although proper memory formation requires several hours of exposure to the mate odor (<xref ref-type="bibr" rid="bib31">Rosser and Keverne, 1985</xref>).</p><p>Similarly fear learning under the common electroshock paradigm establishes a mapping between two contexts (paired with shock vs innocuous) and two actions (freeze vs proceed), again with an upper bound of 1 bit of complexity. Rats and mice will form the association after a single experience lasting only seconds, and alter their behavior over several hours (<xref ref-type="bibr" rid="bib14">Fanselow and Bolles, 1979</xref>; <xref ref-type="bibr" rid="bib6">Bourtchuladze et al., 1994</xref>). This is an adaptive warning system to deal with life-threatening events, and rapid learning here has a clear survival value.</p><p>Animals are particularly adept at learning a new association between an odor and food. For example, bees will extend their proboscis in response to a new odor after just one pairing trial where the odor appeared together with sugar (<xref ref-type="bibr" rid="bib5">Bitterman et al., 1983</xref>). Similarly, rodents will start digging for food in a scented bowl after just a few pairings with that odor (<xref ref-type="bibr" rid="bib12">Cleland et al., 2009</xref>). Again, these are 1-bit tasks learned rapidly after one or a few experiences.</p><p>By comparison, the tasks that a mouse performs in the labyrinth are more complex. For example, the path from the maze entrance to the water port involves six junctions, each with three options. At a minimum six different contexts must be mapped correctly into one of three actions each, which involves 6·log<sub>2</sub>3 = 9.5 bits of complexity. The animals begin to execute perfect paths from the entrance to the water port well within the first hour (<xref ref-type="fig" rid="fig2">Figure 2C</xref>, <xref ref-type="fig" rid="fig3">Figure 3B</xref>). At a later stage during the night, the animal learns to walk direct paths to water from many different locations in the maze (<xref ref-type="fig" rid="fig5">Figure 5</xref>); by this time, it has consumed 10–20 rewards. In the limit, if the animal could turn correctly towards water from each of 63 junctions in the maze, it would have learned 63·log<sub>2</sub>3 = 100 bits. Conservatively, we estimate that the animals have mastered 10–20 bits of complexity based on 10–20 reward experiences within an hour of time spent in the maze. Note this considers only information about the water port and ignores whatever else the animals are learning about the maze during their incessant exploratory forays. These numbers align well with classic experiments on rats in diverse mazes and problem boxes <xref ref-type="bibr" rid="bib23">Munn, 1950a</xref>. Although those tasks come in many varieties, a common theme is that ~10 successful trials are sufficient to learn ~10 decisions (<xref ref-type="bibr" rid="bib45">Woodrow, 1942</xref>).</p><p>In a different corner of the speed-complexity space are the many 2-alternative-forced-choice (2AFC) tasks in popular use today. These tend to be 1-bit tasks, for example the monkey should flick its eyes to the left when visual motion is to the left (<xref ref-type="bibr" rid="bib27">Newsome and Paré, 1988</xref>), or the mouse should turn a steering wheel to the right when a light appears on the left (<xref ref-type="bibr" rid="bib10">Burgess et al., 2017</xref>). Yet, the animals take a long time to learn these simple tasks. For example, the mouse with the steering wheel requires about 10,000 experiences before performance saturates. It never gets particularly good, with a typical hit rate only 2/3 of the way from random to perfect. All this training takes 3–6 weeks; in the case of monkeys several months. The rate of learning, measured in task complexity per unit time, is surprisingly low: less than 1 bit/month compared to ~10 bits/h observed in the labyrinth. The difference is a factor of 6000. Similarly when measured in complexity learned per reward experience: The 2AFC mouse may need 5000 rewards to learn a contingency table with one bit complexity, whereas the mouse in the maze needs ~10 rewards to learn 10 bits. Given these enormous differences in learning rate, one wonders whether the ultra-slow mode of learning has any relevance for an animal’s natural condition. In the month that the 2AFC mouse requires to finally report the location of a light, its relative in the wild has developed from a baby to having its own babies. Along the way, that wild mouse had to make many decisions, often involving high stakes, without the benefit of 10,000 trials of practice.</p></sec><sec id="s3-4"><title>Sudden insight</title><p>The dynamics of the learning process are often conceived as a continuously growing association between stimuli and actions, with each reinforcing experience making an infinitesimal contribution. The reality can be quite different. When a child first learns to balance on a bicycle, performance goes from abysmal to astounding within a few seconds. The timing of such a discontinuous step in performance seems impossible to predict but easy to recognize after the fact.</p><p>From the early days of animal learning experiments, there have been warnings against the tendency to average learning curves across subjects (<xref ref-type="bibr" rid="bib20">Krechevsky, 1932</xref>; <xref ref-type="bibr" rid="bib13">Estes, 1956</xref>). The average of many discontinuous curves will certainly look continuous and incremental, but that reassuring shape may miss the essence of the learning process. A recent reanalysis of many Pavlovian conditioning experiments suggested that discontinuous steps in performance are the rule rather than the exception (<xref ref-type="bibr" rid="bib16">Gallistel et al., 2004</xref>). Here, we found that the same applies to navigation in a complex labyrinth. While the average learning curve presents like a continuous function (<xref ref-type="fig" rid="fig3">Figure 3B</xref>), the individual records of water rewards show that each animal improves rather quickly but at different times (<xref ref-type="fig" rid="fig3">Figure 3A</xref>).</p><p>Owing to the unstructured nature of the experiment, the mouse may adopt different policies for getting to the water port. In at least half the animals, we observed a discontinuous change in that policy, namely when the animal started using efficient direct paths within the maze (<xref ref-type="fig" rid="fig5">Figure 5</xref>, <xref ref-type="supplementary-material" rid="fig5sdata1">Figure 5—source data 1</xref>). This second switch happened considerably after the animal started collecting rewards, and did not greatly affect the reward rate. Furthermore, the animals never reverted to the less efficient policy, just as a child rarely unlearns to balance a bicycle.</p><p>Presumably, this switch in performance reflects some discontinuous change in the animal’s internal model of the maze, what Tolman called the ‘cognitive map’ (<xref ref-type="bibr" rid="bib38">Tolman, 1948</xref>; <xref ref-type="bibr" rid="bib3">Behrens et al., 2018</xref>). In the unrewarded animals, we could not detect any discontinuous change in the use of long paths. However, as Tolman argued, those animals may well acquire a sophisticated cognitive map that reveals itself only when presented with a concrete task, like finding water. Future experiments will need to address this. The discontinuous changes in performance pose a challenge to conventional models of reinforcement learning, in which reward events are the primary driver of learning and each event contributes an infinitesimal update to the action policy. It will also be important to model the acquisition of distinct kinds of knowledge that contribute to the same behavior, like the location of the target and efficient routes to approach it.</p></sec><sec id="s3-5"><title>Exploratory behavior</title><p>By all accounts, the animals spent a large fraction of the night exploring the maze (<xref ref-type="fig" rid="fig1s2">Figure 1—figure supplement 2</xref>). The water-deprived animals continued their forays into the depths of the maze long after they had found the water port and learned to exploit it regularly. After consuming a water reward, they wandered off into the maze 90% of the time (<xref ref-type="fig" rid="fig7">Figure 7B</xref>) instead of lazily waiting in front of the port during the timeout period. The sated animals experienced no overt reward from the maze, yet they likewise spent nearly half their time exploring that environment. As has been noted many times, animals – like humans – derive some form of intrinsic reward from exploration (<xref ref-type="bibr" rid="bib4">Berlyne, 1960</xref>). Some have suggested that there exists a homeostatic drive akin to hunger and thirst that elicits the information-seeking activity, and that the drive is in turn sated by the act of exploration (<xref ref-type="bibr" rid="bib19">Hughes, 1997</xref>). If this were the case then the drive to explore should be weakest just after an episode of exploration, much as the drive for food-seeking is weaker after a big meal.</p><p>Our observations are in conflict with this notion. The animal is most likely to enter the maze within the first minute of its return to the cage (<xref ref-type="fig" rid="fig1s3">Figure 1—figure supplement 3</xref>), a strong trend that runs opposite to the prediction from satiation of curiosity. Several possible explanations come to mind: (1) On these very brief visits to the cage the animal may just want to certify that the exit route to the safe environment still exists, before continuing with exploration of the maze. (2) The temporal contrast between the boredom of the cage and the mystery of the maze is highest right at the moment of exit from the maze, and that may exert pressure to re-enter the maze. Understanding this in more detail will require dedicated experiments. For example, one could deliberately deprive the animals of access to the maze for some hours, and test whether that results in an increased drive to explore, as observed for other homeostatic drives around eating, drinking, and sleeping.</p><p>When left to their own devices, mice choose to spend much of their time engaged in exploration. One wonders how that affects their actions when they are strapped into a rigid behavior machine, like a 2AFC choice box. Presumably the drive to explore persists, perhaps more so because the forced environment is so unpleasant. And within the confines of the two alternatives, the only act of exploration the mouse has left is to give the wrong answer. This would manifest as an unexpectedly high error rate on unambiguous stimuli, sometimes called the 'lapse rate' (<xref ref-type="bibr" rid="bib11">Carandini and Churchland, 2013</xref>; <xref ref-type="bibr" rid="bib29">Pisupati et al., 2021</xref>). The fact that the lapse rate decreases only gradually over weeks to months of training (<xref ref-type="bibr" rid="bib10">Burgess et al., 2017</xref>) suggests that it is difficult to crush the animal’s drive to explore.</p><p>The animals in our experiments had never been presented with a maze environment, yet they quickly settled into a steady mode of exploration. Once a mouse progressed beyond the first intersection it typically entered deep into the maze to one or more end nodes (<xref ref-type="fig" rid="fig6">Figure 6</xref>). Within 50 s of the first entry, the animals adopted a steady speed of locomotion that they would retain throughout the night (<xref ref-type="fig" rid="fig2s1">Figure 2—figure supplement 1</xref>). Within 250 s of first contact with the maze, the average animal already spent 50% of its time there (<xref ref-type="fig" rid="fig1s2">Figure 1—figure supplement 2</xref>). Contrast this with a recent study of ‘free exploration’ in an exposed arena: Those animals required several hours before they even completed one walk around the perimeter (<xref ref-type="bibr" rid="bib15">Fonio et al., 2009</xref>). Here the drive to explore is clearly pitted against fear of the open space, which may not be conducive to observing exploration per se.</p><p>The persistence of exploration throughout the entire duration of the experiment suggests that the animals are continuously surveying the environment, perhaps expecting new features to arise. These surveys are quite efficient: The animals cover all parts of the maze much faster than expected from a random walk (<xref ref-type="fig" rid="fig8">Figure 8</xref>). Effectively they avoid re-entering territory they surveyed just recently. It is often assumed that this requires some global memory of places visited in the environment (<xref ref-type="bibr" rid="bib25">Nagy et al., 2020</xref>; <xref ref-type="bibr" rid="bib28">Olton, 1979</xref>). Such memory would have to persist for a long time: Surveying half of the available end nodes typically required 450 turning decisions. However, we found that a global long-term memory is not needed to explain the efficient search. The animals seem to be governed by a set of local turning biases that require memory only of the most recent decision and no knowledge of location (<xref ref-type="fig" rid="fig9">Figure 9</xref>). These local biases alone can explain most of the character of exploration without any global understanding or long-term memory. Incidentally, they also explain other seemingly global aspects of the behavior, for example the systematic preference that the mice have for the outer rather than the inner regions of the maze (<xref ref-type="fig" rid="fig10">Figure 10</xref>). Of course, this argument does not exclude the presence of a long-term memory, which may reveal itself in some other feature of the behavior.</p><p>Perhaps, the most remarkable aspect of these biases is how similar they are across all 19 mice studied here, regardless of whether the animal experienced water rewards or not (<xref ref-type="fig" rid="fig9">Figure 9B</xref>, <xref ref-type="supplementary-material" rid="fig9sdata1">Figure 9—source data 1</xref>), and independent of the sex of the mouse. The four decision probabilities were identical across individuals to within a standard deviation of less than 0.03. We cannot think of a trivial reason why this should be so. For example the two biases for forward motion (<xref ref-type="fig" rid="fig9">Figure 9B</xref> left) are poised halfway between the value for a random walk (<inline-formula><mml:math id="inf52"><mml:mrow><mml:mi>p</mml:mi><mml:mo>=</mml:mo><mml:mrow><mml:mn>2</mml:mn><mml:mo>/</mml:mo><mml:mn>3</mml:mn></mml:mrow></mml:mrow></mml:math></inline-formula>) and certainty (<inline-formula><mml:math id="inf53"><mml:mrow><mml:mi>p</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:math></inline-formula>). At either of those extremes, simple saturation might lead to a reproducible value, but not in the middle of the range. Why do different animals follow the exact same decision rules at an intersection between tunnels? Given that tunnel systems are part of the mouse’s natural ecology, it is possible that those rules are innate and determined genetically. Indeed the rules by which mice build tunnels have a strong genetic component (<xref ref-type="bibr" rid="bib42">Weber et al., 2013</xref>), so the rules for using tunnels may be written in the genes as well. The high precision with which one can measure those behaviors even in a single night of activity opens the way to efficient comparisons across genotypes, and also across animals with different developmental experience.</p><p>Finally, after mice discover the water port and learn to access it from many different points in the maze (<xref ref-type="fig" rid="fig5">Figure 5</xref>), they are presumably eager to discover other things. In ongoing work, we installed three water ports (visible in the videos accompanying this article) and implemented a rule that activates the three ports in a cyclic sequence. Mice discovered all three ports rapidly and learned to visit them in the correct order. Future experiments will have to raise the bar on what the mice are expected to learn in a night.</p></sec><sec id="s3-6"><title>Mechanisms of navigation</title><p>How do the animals navigate when they perform direct paths to the water port or to the exit? The present study cannot resolve that, but one can gain some clues based on observations so far. Early workers already concluded that rodents in a maze will use whatever sensory cues and tricks are available to accomplish their tasks (<xref ref-type="bibr" rid="bib24">Munn, 1950b</xref>). Our maze was designed to restrict those options somewhat.</p><p>To limit the opportunity for visual navigation, the floor and walls of the maze are visually opaque. The ceiling is transparent, but the room is kept dark except for infrared illuminators. Even if the animal finds enough light, the goals (water port or exit) are invisible within the maze except from the immediately adjacent corridor. There are no visible beacons that would identify the goal.</p><p>With regard to the sense of touch and kinesthetics, the maze was constructed for maximal symmetry. At each level of the binary tree, all the junctions have locally identical geometry, with intersecting corridors of the same length. In practice, the animals may well detect some inadvertent cues, like an unusual drop of glue, that could identify one node from another. The maze rotation experiment suggests that such cues are not essential for the animal’s sense of location in the maze, at least in the expert phase.</p><p>The role of odors deserves particular attention because the mouse may use them both passively and actively. Does the animal first find the water port by following the smell of water? Probably not. For one, the port only emits a single drop of water when triggered by a nose poke. Second, we observed many instances where the animal is in the final corridor adjacent to the water port yet fails to discover it. The initial discovery seems to occur via touch. The reader can verify this in the videos accompanying this article. Regarding active use of odor markings in the maze, the maze rotation experiment suggests that such cues are not required for navigation, at least once the animals have adopted the shortest path to the water port (<xref ref-type="fig" rid="fig4">Figure 4</xref>).</p><p>Another algorithm that is often invoked for animals moving in an open arena is vector-based navigation (<xref ref-type="bibr" rid="bib43">Wehner et al., 1996</xref>). Once the animal discovers a target, it keeps track of that target’s heading and distance using a path integrator. When it needs to return to the target it follows the heading vector and updates heading and distance until it arrives. Such a strategy has limited appeal inside a labyrinth because the vectors are constantly blocked by walls. Consider, for example, the ‘home runs’ back to the exit at the end of a bout. Here the target, namely the exit, is known from the start of the bout, because the animal enters through the same hole. At the end of the bout, when the mouse decides to exit from the maze, can it follow the heading vector to the exit? <xref ref-type="fig" rid="fig6">Figure 6A</xref> shows the 13 locations from which mice returned in a direct path to the exit on their very first foray. None of these locations is compatible with heading-based navigation: In each case an animal following the heading to the exit would get stuck in a different end node first and would have to reverse from there, quite unlike what really happened.</p><p>Finally, a partial clue comes from errors the animals make. We found that the rotation image of the water port, an end node diametrically across the entire maze, is one of the most popular destinations for rewarded animals (<xref ref-type="fig" rid="fig10">Figure 10A</xref>). These errors would be highly unexpected if the animals navigated from the entrance to the water by odor markings, or if they used an absolute representation of heading and distance. On the other hand, if the animal navigates via a remembered sequence of turns, then it will end up at that image node if it makes a single mistake at just the first T-junction.</p><p>Future directed experiments will serve to narrow down how mice learn to navigate this environment, and how their policy might change over time. Since the animals get to perfection within an hour or so, one can test a new hypothesis quite efficiently. Understanding what mechanisms they use will then inform thinking about the algorithm for learning, and about the neuronal mechanisms that implement it.</p></sec></sec><sec id="s4" sec-type="materials|methods"><title>Materials and methods</title><sec id="s4-1"><title>Experimental design</title><p>The goal of the study was to observe mice as they explored a complex environment for the first time, with little or no human interference and no specific instructions. In preliminary experiments, we tested several labyrinth designs and water reward schedules. Eventually, we settled on the protocol described here, and tested 20 mice in rapid succession. Each mouse was observed only over a 7-h period during the first night it encountered the labyrinth.</p></sec><sec id="s4-2"><title>Maze construction</title><p>The maze measured ~24 x 24 x 2 inches; for manufacture we used materials specified in inches, so dimensions are quoted in those non-SI units where appropriate. The ceiling was made of 0.5 inch clear acrylic. Slots of 1/8 inch width were cut into this plate on a 1.5 inch grid. Pegged walls made of 1/8 inch infrared-transmitting acrylic (opaque in the visible spectrum, ePlastics) were inserted into these slots and secured with a small amount of hot glue. The floor was a sheet of infrared-transmitting acrylic, supported by a thicker sheet of clear acrylic. The resulting corridors (1-1/8 inches wide) formed a 6-level binary tree with T-junctions and progressive shortening of each branch, ranging from ~12 inch to 1.5 inch (<xref ref-type="fig" rid="fig1">Figure 1</xref> and <xref ref-type="fig" rid="fig2">Figure 2</xref>). A single end node contained a 1.5 cm circular opening with a water delivery port (described below). The maze included provision for two additional water ports not used in the present report. Once per week the maze was submerged in cage cleaning solution. Between different animals the floor and walls were cleaned with ethanol.</p></sec><sec id="s4-3"><title>Reward delivery system</title><p>The water reward port was controlled by a Matlab script on the main computer through an interface (Sanworks Bpod State Machine r1). Rewards were triggered when the animal’s nose broke the IR beam in the water port (Sanworks Port interface + valve). The interface briefly opened the water valve to deliver ~30 µL of water and flashed an infrared LED mounted outside the maze for 1 s. This served to mark reward events on the video recording. Following each reward, the system entered a time-out period for 90 s, during which the port did not provide further reward. In experiments with sated mice the water port was turned off.</p></sec><sec id="s4-4"><title>Cage and connecting passage</title><p>The entrance to the maze was connected to an otherwise normal mouse cage by red plastic tubing (3 cm dia, 1 m long). The cage contained food, bedding, nesting material, and in the case of unrewarded experiments also a normal water bottle.</p></sec><sec id="s4-5"><title>Animals and treatments</title><p>All mice were C57BL/6J animals (Jackson Labs) between the ages of 45 and 98 days (mean 62 days). Both sexes were used: four males and six females in the rewarded experiments, five males and four females in the unrewarded experiments. For water deprivation, the animal was transferred from its home cage (generally group-housed) to the maze cage ~22 h before the start of the experiment. Non-deprived animals were transferred minutes before the start. All procedures were performed in accordance with institutional guidelines and approved by the Caltech IACUC.</p></sec><sec id="s4-6"><title>Video recording</title><p>All data reported here were collected over the course of 7 h during the dark portion of the animal’s light cycle. Video recording was initiated a few seconds prior to connecting the tunnel to the maze. Videos were recorded by an OpenCV python script controlling a single webcam (Logitech C920) located ~1 m below the floor of the maze. The maze and access tube were illuminated by multiple infrared LED arrays (center wavelength 850 nm). Three of these lights illuminated the maze from below at a 45 degree angle, producing contrast to resolve the animal’s foot pads. The remaining lights pointed at the ceiling of the room to produce backlight for a sharp outline of the animal.</p></sec><sec id="s4-7"><title>Animal tracking</title><p>A version of DeepLabCut (<xref ref-type="bibr" rid="bib26">Nath et al., 2019</xref>) modified to support gray-scale processing was used to track the animal’s trajectory, using key points at the nose, feet, tail base and mid-body. All subsequent analyses were based on the trajectory of the animal’s nose, consisting of positions <inline-formula><mml:math id="inf54"><mml:mrow><mml:mi>x</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> and <inline-formula><mml:math id="inf55"><mml:mrow><mml:mi>y</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> in every video frame.</p></sec><sec id="s4-8"><title>Rates of transition between cage and maze</title><p>This section relates to <xref ref-type="fig" rid="fig1s3">Figure 1—figure supplement 3</xref>. We entertained the hypothesis that the animals become ‘thirsty for exploration’ as they spend more time in the cage. In that case one would predict that the probability of entering the maze in the next second will increase with time spent in the cage. One can compute this probability from the distribution of residency times in the cage, as follows:</p><p>Say <inline-formula><mml:math id="inf56"><mml:mrow><mml:mi>t</mml:mi><mml:mo>=</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:math></inline-formula> when the animal enters the cage. The probability density that the animal will next leave the cage at time <inline-formula><mml:math id="inf57"><mml:mi>t</mml:mi></mml:math></inline-formula> is<disp-formula id="equ2"><label>(2)</label><mml:math id="m2"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>p</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mrow><mml:msup><mml:mi>e</mml:mi><mml:mrow><mml:mo>−</mml:mo><mml:munderover><mml:mo>∫</mml:mo><mml:mn>0</mml:mn><mml:mi>t</mml:mi></mml:munderover><mml:mrow><mml:mi>r</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msup><mml:mi>t</mml:mi><mml:mo>′</mml:mo></mml:msup></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mi>d</mml:mi><mml:msup><mml:mi>t</mml:mi><mml:mo>′</mml:mo></mml:msup></mml:mrow></mml:mrow></mml:msup></mml:mrow><mml:mi>r</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mstyle></mml:math></disp-formula>where <inline-formula><mml:math id="inf58"><mml:mrow><mml:mi>r</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> is the instantaneous rate for entering the maze. So<disp-formula id="equ3"><label>(3)</label><mml:math id="m3"><mml:mrow><mml:mstyle displaystyle="true"><mml:munderover><mml:mo largeop="true" movablelimits="false" symmetric="true">∫</mml:mo><mml:mn>0</mml:mn><mml:mi>t</mml:mi></mml:munderover></mml:mstyle><mml:mrow><mml:mi>p</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:msup><mml:mi>t</mml:mi><mml:mo>′</mml:mo></mml:msup><mml:mo>)</mml:mo></mml:mrow><mml:mo>⁢</mml:mo><mml:mrow><mml:mo>𝑑</mml:mo><mml:msup><mml:mi>t</mml:mi><mml:mo>′</mml:mo></mml:msup></mml:mrow></mml:mrow></mml:mrow><mml:mrow><mml:mi/><mml:mo>=</mml:mo><mml:mrow><mml:mn>1</mml:mn><mml:mo>-</mml:mo><mml:msup><mml:mi>e</mml:mi><mml:mrow><mml:mo>-</mml:mo><mml:mrow><mml:mstyle displaystyle="false"><mml:munderover><mml:mo largeop="true" movablelimits="false" symmetric="true">∫</mml:mo><mml:mn>0</mml:mn><mml:mi>t</mml:mi></mml:munderover></mml:mstyle><mml:mrow><mml:mi>r</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:msup><mml:mi>t</mml:mi><mml:mo>′</mml:mo></mml:msup><mml:mo>)</mml:mo></mml:mrow><mml:mo>⁢</mml:mo><mml:mrow><mml:mo>𝑑</mml:mo><mml:msup><mml:mi>t</mml:mi><mml:mo>′</mml:mo></mml:msup></mml:mrow></mml:mrow></mml:mrow></mml:mrow></mml:msup></mml:mrow></mml:mrow></mml:math></disp-formula><disp-formula id="equ4"><label>(4)</label><mml:math id="m4"><mml:mrow><mml:mstyle displaystyle="true"><mml:munderover><mml:mo largeop="true" movablelimits="false" symmetric="true">∫</mml:mo><mml:mn>0</mml:mn><mml:mi>t</mml:mi></mml:munderover></mml:mstyle><mml:mrow><mml:mi>r</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:msup><mml:mi>t</mml:mi><mml:mo>′</mml:mo></mml:msup><mml:mo>)</mml:mo></mml:mrow><mml:mo>⁢</mml:mo><mml:mrow><mml:mo>𝑑</mml:mo><mml:msup><mml:mi>t</mml:mi><mml:mo>′</mml:mo></mml:msup></mml:mrow></mml:mrow></mml:mrow><mml:mrow><mml:mi/><mml:mo>=</mml:mo><mml:mrow><mml:mo>-</mml:mo><mml:mrow><mml:mi>ln</mml:mi><mml:mo>⁡</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mn>1</mml:mn><mml:mo>-</mml:mo><mml:mrow><mml:mstyle displaystyle="true"><mml:munderover><mml:mo largeop="true" movablelimits="false" symmetric="true">∫</mml:mo><mml:mn>0</mml:mn><mml:mi>t</mml:mi></mml:munderover></mml:mstyle><mml:mrow><mml:mi>p</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:msup><mml:mi>t</mml:mi><mml:mo>′</mml:mo></mml:msup><mml:mo>)</mml:mo></mml:mrow><mml:mo>⁢</mml:mo><mml:mrow><mml:mo>𝑑</mml:mo><mml:msup><mml:mi>t</mml:mi><mml:mo>′</mml:mo></mml:msup></mml:mrow></mml:mrow></mml:mrow></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:mrow></mml:math></disp-formula></p><p>This relates the cumulative of the instantaneous rate function to the cumulative of the observed transition times. In this way we computed the rates <disp-formula id="equ5"><label>(5)</label><mml:math id="m5"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msub><mml:mi>r</mml:mi><mml:mrow><mml:mrow><mml:mi mathvariant="normal">m</mml:mi></mml:mrow></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>t</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mrow><mml:mi mathvariant="normal">r</mml:mi><mml:mi mathvariant="normal">a</mml:mi><mml:mi mathvariant="normal">t</mml:mi><mml:mi mathvariant="normal">e</mml:mi><mml:mtext> </mml:mtext><mml:mi mathvariant="normal">o</mml:mi><mml:mi mathvariant="normal">f</mml:mi><mml:mtext> </mml:mtext><mml:mi mathvariant="normal">e</mml:mi><mml:mi mathvariant="normal">n</mml:mi><mml:mi mathvariant="normal">t</mml:mi><mml:mi mathvariant="normal">r</mml:mi><mml:mi mathvariant="normal">y</mml:mi><mml:mtext> </mml:mtext><mml:mi mathvariant="normal">i</mml:mi><mml:mi mathvariant="normal">n</mml:mi><mml:mi mathvariant="normal">t</mml:mi><mml:mi mathvariant="normal">o</mml:mi><mml:mtext> </mml:mtext><mml:mi mathvariant="normal">t</mml:mi><mml:mi mathvariant="normal">h</mml:mi><mml:mi mathvariant="normal">e</mml:mi><mml:mtext> </mml:mtext><mml:mi mathvariant="normal">m</mml:mi><mml:mi mathvariant="normal">a</mml:mi><mml:mi mathvariant="normal">z</mml:mi><mml:mi mathvariant="normal">e</mml:mi><mml:mtext> </mml:mtext><mml:mi mathvariant="normal">a</mml:mi><mml:mi mathvariant="normal">s</mml:mi><mml:mtext> </mml:mtext><mml:mi mathvariant="normal">a</mml:mi><mml:mtext> </mml:mtext><mml:mi mathvariant="normal">f</mml:mi><mml:mi mathvariant="normal">u</mml:mi><mml:mi mathvariant="normal">n</mml:mi><mml:mi mathvariant="normal">c</mml:mi><mml:mi mathvariant="normal">t</mml:mi><mml:mi mathvariant="normal">i</mml:mi><mml:mi mathvariant="normal">o</mml:mi><mml:mi mathvariant="normal">n</mml:mi><mml:mtext> </mml:mtext><mml:mi mathvariant="normal">o</mml:mi><mml:mi mathvariant="normal">f</mml:mi><mml:mtext> </mml:mtext><mml:mi mathvariant="normal">t</mml:mi><mml:mi mathvariant="normal">i</mml:mi><mml:mi mathvariant="normal">m</mml:mi><mml:mi mathvariant="normal">e</mml:mi><mml:mtext> </mml:mtext><mml:mi mathvariant="normal">s</mml:mi><mml:mi mathvariant="normal">p</mml:mi><mml:mi mathvariant="normal">e</mml:mi><mml:mi mathvariant="normal">n</mml:mi><mml:mi mathvariant="normal">t</mml:mi><mml:mtext> </mml:mtext><mml:mi mathvariant="normal">i</mml:mi><mml:mi mathvariant="normal">n</mml:mi><mml:mtext> </mml:mtext><mml:mi mathvariant="normal">t</mml:mi><mml:mi mathvariant="normal">h</mml:mi><mml:mi mathvariant="normal">e</mml:mi><mml:mtext> </mml:mtext><mml:mi mathvariant="normal">c</mml:mi><mml:mi mathvariant="normal">a</mml:mi><mml:mi mathvariant="normal">g</mml:mi><mml:mi mathvariant="normal">e</mml:mi></mml:mrow></mml:mstyle></mml:mrow></mml:mstyle></mml:math></disp-formula><disp-formula id="equ6"><label>(6)</label><mml:math id="m6"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msub><mml:mi>r</mml:mi><mml:mrow><mml:mrow><mml:mi mathvariant="normal">c</mml:mi></mml:mrow></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>t</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mrow><mml:mi mathvariant="normal">r</mml:mi><mml:mi mathvariant="normal">a</mml:mi><mml:mi mathvariant="normal">t</mml:mi><mml:mi mathvariant="normal">e</mml:mi><mml:mtext> </mml:mtext><mml:mi mathvariant="normal">o</mml:mi><mml:mi mathvariant="normal">f</mml:mi><mml:mtext> </mml:mtext><mml:mi mathvariant="normal">e</mml:mi><mml:mi mathvariant="normal">n</mml:mi><mml:mi mathvariant="normal">t</mml:mi><mml:mi mathvariant="normal">r</mml:mi><mml:mi mathvariant="normal">y</mml:mi><mml:mtext> </mml:mtext><mml:mi mathvariant="normal">i</mml:mi><mml:mi mathvariant="normal">n</mml:mi><mml:mi mathvariant="normal">t</mml:mi><mml:mi mathvariant="normal">o</mml:mi><mml:mtext> </mml:mtext><mml:mi mathvariant="normal">t</mml:mi><mml:mi mathvariant="normal">h</mml:mi><mml:mi mathvariant="normal">e</mml:mi><mml:mtext> </mml:mtext><mml:mi mathvariant="normal">c</mml:mi><mml:mi mathvariant="normal">a</mml:mi><mml:mi mathvariant="normal">g</mml:mi><mml:mi mathvariant="normal">e</mml:mi><mml:mtext> </mml:mtext><mml:mi mathvariant="normal">a</mml:mi><mml:mi mathvariant="normal">s</mml:mi><mml:mtext> </mml:mtext><mml:mi mathvariant="normal">a</mml:mi><mml:mtext> </mml:mtext><mml:mi mathvariant="normal">f</mml:mi><mml:mi mathvariant="normal">u</mml:mi><mml:mi mathvariant="normal">n</mml:mi><mml:mi mathvariant="normal">c</mml:mi><mml:mi mathvariant="normal">t</mml:mi><mml:mi mathvariant="normal">i</mml:mi><mml:mi mathvariant="normal">o</mml:mi><mml:mi mathvariant="normal">n</mml:mi><mml:mtext> </mml:mtext><mml:mi mathvariant="normal">o</mml:mi><mml:mi mathvariant="normal">f</mml:mi><mml:mtext> </mml:mtext><mml:mi mathvariant="normal">t</mml:mi><mml:mi mathvariant="normal">i</mml:mi><mml:mi mathvariant="normal">m</mml:mi><mml:mi mathvariant="normal">e</mml:mi><mml:mtext> </mml:mtext><mml:mi mathvariant="normal">s</mml:mi><mml:mi mathvariant="normal">p</mml:mi><mml:mi mathvariant="normal">e</mml:mi><mml:mi mathvariant="normal">n</mml:mi><mml:mi mathvariant="normal">t</mml:mi><mml:mtext> </mml:mtext><mml:mi mathvariant="normal">i</mml:mi><mml:mi mathvariant="normal">n</mml:mi><mml:mtext> </mml:mtext><mml:mi mathvariant="normal">t</mml:mi><mml:mi mathvariant="normal">h</mml:mi><mml:mi mathvariant="normal">e</mml:mi><mml:mtext> </mml:mtext><mml:mi mathvariant="normal">m</mml:mi><mml:mi mathvariant="normal">a</mml:mi><mml:mi mathvariant="normal">z</mml:mi><mml:mi mathvariant="normal">e</mml:mi></mml:mrow></mml:mstyle></mml:mrow></mml:mstyle></mml:math></disp-formula></p><p>The rate of entering the maze is highest at short times in the cage (<xref ref-type="fig" rid="fig1s3">Figure 1—figure supplement 3A</xref>). It peaks after ~15 s in the cage and then declines gradually by a factor of 4 over the first minute. So the mouse is most likely to enter the maze just after it returns from there. This runs opposite to the expectation from a homeostatic drive for exploration, which should be sated right after the animal returns. We found no evidence for an increase in the rate at late times. These effects were very similar in rewarded and unrewarded groups and in fact the tendency to return early was seen in every animal.</p><p>By contrast, the rate of exiting the maze is almost perfectly constant over time (<xref ref-type="fig" rid="fig1s3">Figure 1—figure supplement 3B</xref>). In other words, the exit from the maze appears like a constant rate Poisson process. There is a slight elevation of the rate at short times among rewarded animals (<xref ref-type="fig" rid="fig1s3">Figure 1—figure supplement 3B</xref> top). This may come from the occasional brief water runs they perform. Another strange deviation is an unusual number of very short bouts (duration 2–12 s) among unrewarded animals (<xref ref-type="fig" rid="fig1s3">Figure 1—figure supplement 3B</xref> bottom). These are brief excursions in which the animal runs to the central junction, turns around, and runs to the exit. Several animals exhibited these, often several bouts in a row, and at all times of the night.</p></sec><sec id="s4-9"><title>Reduced trajectories</title><p>From the raw nose trajectory we computed two reduced versions. First, we divided the maze into discrete ‘cells’, namely the squares the width of a corridor that make up the grid of the maze. At any given time, the nose is in one of these cells and that time series defines the cell trajectory.</p><p>At a coarser level still one can ask when the animal passes through the nodes of the binary tree, which are the decision points in the maze. The special cells that correspond to the nodes of the tree are those at the center of a T-junction and those at the leaves of the tree. We marked all the times when the trajectory <inline-formula><mml:math id="inf59"><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mi>x</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mo>,</mml:mo><mml:mrow><mml:mi>y</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></inline-formula> entered a new node cell. If the animal leaves a node cell and returns to it before entering a different node cell, that is not considered a new node. This procedure defines a discrete node sequence <italic>s</italic><sub><italic>i</italic></sub> and corresponding arrival times at those nodes <italic>t</italic><sub><italic>i</italic></sub>. We call the transition between two nodes a ‘step’. Much of the analysis in this paper is derived from the animal’s node sequence. The median mouse performed 16,192 steps in the 7 h period of observation (mean = 15,257; SD = 3340).</p><p>In <xref ref-type="fig" rid="fig5">Figure 5</xref> and <xref ref-type="fig" rid="fig6">Figure 6</xref>, we count the occurrence of direct paths leading to the water port (a ‘water run’) or to the exit (a ‘home run’). A direct path is a node sequence without any reversals. <xref ref-type="fig" rid="fig3s1">Figure 3—figure supplement 1</xref> illustrates some examples.</p><p>If the animal makes one wrong step from the direct path, that step needs to be backtracked, adding a total of two steps to the length of the path. If further errors occur during backtracking, they need to be corrected as well. The binary maze contains no loops, so the number of errors is directly related to the length of the path:<disp-formula id="equ7"><label>(7)</label><mml:math id="m7"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mrow><mml:mi mathvariant="normal">E</mml:mi><mml:mi mathvariant="normal">r</mml:mi><mml:mi mathvariant="normal">r</mml:mi><mml:mi mathvariant="normal">o</mml:mi><mml:mi mathvariant="normal">r</mml:mi><mml:mi mathvariant="normal">s</mml:mi></mml:mrow><mml:mo>=</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mi mathvariant="normal">L</mml:mi><mml:mi mathvariant="normal">e</mml:mi><mml:mi mathvariant="normal">n</mml:mi><mml:mi mathvariant="normal">g</mml:mi><mml:mi mathvariant="normal">t</mml:mi><mml:mi mathvariant="normal">h</mml:mi><mml:mtext> </mml:mtext><mml:mi mathvariant="normal">o</mml:mi><mml:mi mathvariant="normal">f</mml:mi><mml:mtext> </mml:mtext><mml:mi mathvariant="normal">p</mml:mi><mml:mi mathvariant="normal">a</mml:mi><mml:mi mathvariant="normal">t</mml:mi><mml:mi mathvariant="normal">h</mml:mi></mml:mrow><mml:mo>−</mml:mo><mml:mrow><mml:mi mathvariant="normal">L</mml:mi><mml:mi mathvariant="normal">e</mml:mi><mml:mi mathvariant="normal">n</mml:mi><mml:mi mathvariant="normal">g</mml:mi><mml:mi mathvariant="normal">t</mml:mi><mml:mi mathvariant="normal">h</mml:mi><mml:mtext> </mml:mtext><mml:mi mathvariant="normal">o</mml:mi><mml:mi mathvariant="normal">f</mml:mi><mml:mtext> </mml:mtext><mml:mi mathvariant="normal">d</mml:mi><mml:mi mathvariant="normal">i</mml:mi><mml:mi mathvariant="normal">r</mml:mi><mml:mi mathvariant="normal">e</mml:mi><mml:mi mathvariant="normal">c</mml:mi><mml:mi mathvariant="normal">t</mml:mi><mml:mtext> </mml:mtext><mml:mi mathvariant="normal">p</mml:mi><mml:mi mathvariant="normal">a</mml:mi><mml:mi mathvariant="normal">t</mml:mi><mml:mi mathvariant="normal">h</mml:mi></mml:mrow><mml:mo stretchy="false">)</mml:mo><mml:mrow><mml:mo>/</mml:mo></mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:mstyle></mml:math></disp-formula></p></sec><sec id="s4-10"><title>Maze rotation</title><p>The maze rotation experiment (<xref ref-type="fig" rid="fig4">Figure 4</xref>) was performed on four mice, all water-deprived. Two of the animals (’D7’ and ’D9’) had experienced the maze before, and are part of the ’rewarded’ group in other sections of the report. Two additional animals (’F2’ and ’A1’) had had no prior contact with the maze.</p><p>The maze rotation occurred after at least 6 h of exposure, by which time the animals had all perfected the direct path to the water port.</p><p>For animals ’D7’ and ’D9’ we rotated only the floor of the maze, leaving the walls and ceiling in the original configuration. For ’F2’ and ’A1’ we rotated the entire maze, moving one wall segment at the central junction and the water port to attain the same shape. Navigation remained intact for all animals. Note that ’A1’ performed a perfect path to the water port and back immediately before and after a full maze rotation (<xref ref-type="fig" rid="fig4">Figure 4B</xref>).</p><p>The visits to the four locations in the maze (<xref ref-type="fig" rid="fig4">Figure 4C</xref>, <xref ref-type="fig" rid="fig4s1">Figure 4—figure supplement 1</xref>) were limited to direct paths of length at least two steps. This avoids counting rapid flickers between two adjacent nodes. In other words, the animal has to move at least two steps away from the target node before another visit qualifies.</p></sec><sec id="s4-11"><title>Statistics of sudden insight</title><p>In <xref ref-type="fig" rid="fig5">Figure 5</xref> one can distinguish two events: First, the animal finds the water port and begins to collect rewards at a steady rate: this is when the green curve rises up. At a later time, the long direct paths to the water port become much more frequent than to the comparable control nodes: this is when the red and blue curves diverge. For almost all animals these two events are well separated in time (<xref ref-type="fig" rid="fig5s1">Figure 5—figure supplement 1</xref>). In many cases, the rate of long paths seems to change discontinuously: a sudden change in slope of the curve.</p><p>Here, we analyze the degree of 'sudden change', namely how rapidly the rate changes in a time series of events. We modeled the rate as a sigmoid function of time during the experiment:<disp-formula id="equ8"><label>(8)</label><mml:math id="m8"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>r</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mrow><mml:msub><mml:mi>r</mml:mi><mml:mrow><mml:mtext>i</mml:mtext></mml:mrow></mml:msub></mml:mrow><mml:mo>+</mml:mo><mml:mfrac><mml:mrow><mml:mrow><mml:msub><mml:mi>r</mml:mi><mml:mrow><mml:mtext>f</mml:mtext></mml:mrow></mml:msub></mml:mrow><mml:mo>−</mml:mo><mml:mrow><mml:msub><mml:mi>r</mml:mi><mml:mrow><mml:mtext>i</mml:mtext></mml:mrow></mml:msub></mml:mrow></mml:mrow><mml:mn>2</mml:mn></mml:mfrac><mml:mspace width="thinmathspace"/><mml:mrow><mml:mi mathvariant="normal">e</mml:mi><mml:mi mathvariant="normal">r</mml:mi><mml:mi mathvariant="normal">f</mml:mi></mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mfrac><mml:mrow><mml:mi>t</mml:mi><mml:mo>−</mml:mo><mml:mrow><mml:msub><mml:mi>t</mml:mi><mml:mrow><mml:mtext>s</mml:mtext></mml:mrow></mml:msub></mml:mrow></mml:mrow><mml:mi>w</mml:mi></mml:mfrac></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mstyle></mml:math></disp-formula>where<disp-formula id="equ9"><mml:math id="m9"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mrow><mml:mi mathvariant="normal">e</mml:mi><mml:mi mathvariant="normal">r</mml:mi><mml:mi mathvariant="normal">f</mml:mi></mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mi>x</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mfrac><mml:mn>2</mml:mn><mml:mrow><mml:msqrt><mml:mi>π</mml:mi></mml:msqrt></mml:mrow></mml:mfrac><mml:munderover><mml:mo>∫</mml:mo><mml:mrow><mml:mn>0</mml:mn></mml:mrow><mml:mrow><mml:mi>x</mml:mi></mml:mrow></mml:munderover><mml:mrow><mml:mrow><mml:msup><mml:mi>e</mml:mi><mml:mrow><mml:mo>−</mml:mo><mml:mrow><mml:msup><mml:mi>x</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:mrow></mml:msup></mml:mrow><mml:mrow><mml:mtext>d</mml:mtext></mml:mrow><mml:mi>x</mml:mi></mml:mrow></mml:mrow></mml:mstyle></mml:math></disp-formula></p><p>The rate begins at a low initial level <inline-formula><mml:math id="inf60"><mml:msub><mml:mi>r</mml:mi><mml:mtext>i</mml:mtext></mml:msub></mml:math></inline-formula>, reflecting chance occurrence of the event, and saturates at a high final level <inline-formula><mml:math id="inf61"><mml:msub><mml:mi>r</mml:mi><mml:mtext>f</mml:mtext></mml:msub></mml:math></inline-formula>, limited for example by the animal’s walking speed. The other two parameters are the time <inline-formula><mml:math id="inf62"><mml:msub><mml:mi>t</mml:mi><mml:mtext>s</mml:mtext></mml:msub></mml:math></inline-formula> of half-maximal rate change, and the width <inline-formula><mml:math id="inf63"><mml:mi>w</mml:mi></mml:math></inline-formula> over which that rate change takes place. A sudden change in the event rate would correspond to <inline-formula><mml:math id="inf64"><mml:mrow><mml:mi>w</mml:mi><mml:mo>=</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:math></inline-formula>.</p><p>The data are a set of <inline-formula><mml:math id="inf65"><mml:mi>n</mml:mi></mml:math></inline-formula> event times <inline-formula><mml:math id="inf66"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>t</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula> in the observation interval <inline-formula><mml:math id="inf67"><mml:mrow><mml:mo stretchy="false">[</mml:mo><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:mi>T</mml:mi><mml:mo stretchy="false">]</mml:mo></mml:mrow></mml:math></inline-formula>. We model the event train as an inhomogeneous Poisson point process with instantaneous rate <inline-formula><mml:math id="inf68"><mml:mrow><mml:mi>r</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula>. The likelihood of the data given the rate function <inline-formula><mml:math id="inf69"><mml:mrow><mml:mi>r</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> is<disp-formula id="equ10"><label>(9)</label><mml:math id="m10"><mml:mrow><mml:mrow><mml:mi>L</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo>[</mml:mo><mml:mrow><mml:mi>r</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>]</mml:mo></mml:mrow></mml:mrow><mml:mo>=</mml:mo><mml:mrow><mml:msup><mml:mi>e</mml:mi><mml:mrow><mml:mo>-</mml:mo><mml:mrow><mml:mstyle displaystyle="false"><mml:munderover><mml:mo largeop="true" movablelimits="false" symmetric="true">∫</mml:mo><mml:mn>0</mml:mn><mml:mi>T</mml:mi></mml:munderover></mml:mstyle><mml:mrow><mml:mi>r</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>⁢</mml:mo><mml:mrow><mml:mo>𝑑</mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:mrow></mml:mrow></mml:mrow></mml:msup><mml:mo>⁢</mml:mo><mml:mrow><mml:munder><mml:mo largeop="true" movablelimits="false" symmetric="true">∏</mml:mo><mml:mi>i</mml:mi></mml:munder><mml:mrow><mml:mi>r</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:mrow></mml:mrow></mml:math></disp-formula>and the log likelihood is<disp-formula id="equ11"><label>(10)</label><mml:math id="m11"><mml:mrow><mml:mrow><mml:mi>ln</mml:mi><mml:mo>⁡</mml:mo><mml:mi>L</mml:mi></mml:mrow><mml:mo>=</mml:mo><mml:mrow><mml:mrow><mml:munder><mml:mo largeop="true" movablelimits="false" symmetric="true">∑</mml:mo><mml:mi>i</mml:mi></mml:munder><mml:mrow><mml:mrow><mml:mi>ln</mml:mi><mml:mo>⁡</mml:mo><mml:mi>r</mml:mi></mml:mrow><mml:mo>⁢</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mrow><mml:mo>-</mml:mo><mml:mrow><mml:munderover><mml:mo largeop="true" movablelimits="false" symmetric="true">∫</mml:mo><mml:mn>0</mml:mn><mml:mi>T</mml:mi></mml:munderover><mml:mrow><mml:mi>r</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>⁢</mml:mo><mml:mrow><mml:mo>𝑑</mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:mrow></mml:mrow></mml:mrow></mml:mrow></mml:math></disp-formula></p><p>For each of the 10 rewarded mice, we maximized <inline-formula><mml:math id="inf70"><mml:mrow><mml:mi>ln</mml:mi><mml:mo>⁡</mml:mo><mml:mi>L</mml:mi></mml:mrow></mml:math></inline-formula> over the 4 parameters of the rate model, both for the reward events and the long paths to water. The resulting fits are plotted in <xref ref-type="fig" rid="fig5s1">Figure 5—figure supplement 1</xref>.</p><p>Focusing on the learning of long paths to water, for 6 of the 10 animals the optimal width parameter <inline-formula><mml:math id="inf71"><mml:mi>w</mml:mi></mml:math></inline-formula> was less than 300 s: B1, B2, C1, C3, C6, C7. These are the same animals one would credit with a sudden kink in the cumulative event count based on visual inspection (<xref ref-type="fig" rid="fig5s1">Figure 5—figure supplement 1</xref>).</p><p>To measure the uncertainty in the timing of this step, we refit the data for this subgroup of mice with a model involving a sudden step in the rate,<disp-formula id="equ12"><label>(11)</label><mml:math id="m12"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>r</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mrow><mml:mo>{</mml:mo><mml:mtable columnspacing="1em" rowspacing="4pt"><mml:mtr><mml:mtd><mml:msub><mml:mi>r</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>,</mml:mo></mml:mtd><mml:mtd><mml:mi>t</mml:mi><mml:mo>&lt;</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mi>s</mml:mi></mml:msub></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:msub><mml:mi>r</mml:mi><mml:mi>f</mml:mi></mml:msub><mml:mo>,</mml:mo></mml:mtd><mml:mtd><mml:mi>t</mml:mi><mml:mo>&gt;</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mi>s</mml:mi></mml:msub></mml:mtd></mml:mtr></mml:mtable><mml:mo fence="true" stretchy="true" symmetric="true"/></mml:mrow></mml:mrow></mml:mstyle></mml:math></disp-formula>and computed the likelihood of the data as a function of the step time <inline-formula><mml:math id="inf72"><mml:msub><mml:mi>t</mml:mi><mml:mtext>s</mml:mtext></mml:msub></mml:math></inline-formula>. We report the mean and standard deviation of the step time over its likelihood in <xref ref-type="supplementary-material" rid="fig5sdata1">Figure 5—source data 1</xref>. Animal C6 was dropped from this 'sudden step' group, because the uncertainty in the step time was too large (∼900 s).</p></sec><sec id="s4-12"><title>Efficiency of exploration</title><p>The goal of this analysis is to measure how effectively the animal surveys all the end nodes of the maze. The specific question is: In a string of <inline-formula><mml:math id="inf73"><mml:mi>n</mml:mi></mml:math></inline-formula> end nodes that the animal samples, how many of these are distinct? On average how does the number of distinct nodes <inline-formula><mml:math id="inf74"><mml:mi>d</mml:mi></mml:math></inline-formula> increase with <inline-formula><mml:math id="inf75"><mml:mi>n</mml:mi></mml:math></inline-formula>? This was calculated as follows:</p><p>We restricted the animal’s node trajectory <inline-formula><mml:math id="inf76"><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>s</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></inline-formula> to clips of exploration mode, excluding the direct paths to the water port or the exit. All subsequent steps were applied to these clips, then averaged over clips. Within each clip we marked the sequence of end nodes <inline-formula><mml:math id="inf77"><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>e</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></inline-formula>. We slid a window of size <inline-formula><mml:math id="inf78"><mml:mi>n</mml:mi></mml:math></inline-formula> across this sequence and counted the number of distinct nodes <inline-formula><mml:math id="inf79"><mml:mi>d</mml:mi></mml:math></inline-formula> in each window. Then we averaged <inline-formula><mml:math id="inf80"><mml:mi>d</mml:mi></mml:math></inline-formula> over all windows in all clips. Then we repeated that for a wide range of <inline-formula><mml:math id="inf81"><mml:mi>n</mml:mi></mml:math></inline-formula>. The resulting <inline-formula><mml:math id="inf82"><mml:mrow><mml:mi>d</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>n</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> is plotted in the figures reporting new nodes vs nodes visited (<xref ref-type="fig" rid="fig8">Figure 8A,B</xref> and <xref ref-type="fig" rid="fig9">Figure 9C</xref>).</p><p>For a summary analysis, we fitted the curves of <inline-formula><mml:math id="inf83"><mml:mrow><mml:mi>d</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>n</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> with a two-parameter function:<disp-formula id="equ13"><label>(12)</label><mml:math id="m13"><mml:mrow><mml:mrow><mml:mi>d</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>n</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mo>≈</mml:mo><mml:mrow><mml:mn>64</mml:mn><mml:mo>⁢</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mn>1</mml:mn><mml:mo>-</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mrow><mml:mn>1</mml:mn><mml:mo>+</mml:mo><mml:mfrac><mml:mrow><mml:mi>z</mml:mi><mml:mo>+</mml:mo><mml:mrow><mml:mi>b</mml:mi><mml:mo>⁢</mml:mo><mml:msup><mml:mi>z</mml:mi><mml:mn>3</mml:mn></mml:msup></mml:mrow></mml:mrow><mml:mrow><mml:mn>1</mml:mn><mml:mo>+</mml:mo><mml:mi>b</mml:mi></mml:mrow></mml:mfrac></mml:mrow></mml:mfrac></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:math></disp-formula>where <disp-formula id="equ14"><label>(13)</label><mml:math id="m14"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>z</mml:mi><mml:mo>=</mml:mo><mml:mi>n</mml:mi><mml:mrow><mml:mo>/</mml:mo></mml:mrow><mml:mi>a</mml:mi></mml:mrow></mml:mstyle></mml:math></disp-formula></p><p>The parameter <inline-formula><mml:math id="inf84"><mml:mi>a</mml:mi></mml:math></inline-formula> is the number of visits <inline-formula><mml:math id="inf85"><mml:mi>n</mml:mi></mml:math></inline-formula> required to survey half of the end nodes, whereas <inline-formula><mml:math id="inf86"><mml:mi>b</mml:mi></mml:math></inline-formula> reflects a relative acceleration in discovering the last few end nodes. This function was found by trial and error and produces absurdly good fits to the data (<xref ref-type="fig" rid="fig8s1">Figure 8—figure supplement 1</xref>). The values quoted in the text for efficiency of exploration are <inline-formula><mml:math id="inf87"><mml:mrow><mml:mi>E</mml:mi><mml:mo>=</mml:mo><mml:mrow><mml:mn>32</mml:mn><mml:mo>/</mml:mo><mml:mi>a</mml:mi></mml:mrow></mml:mrow></mml:math></inline-formula> (<xref ref-type="disp-formula" rid="equ1">Equation 1</xref>).</p><p>The value of <inline-formula><mml:math id="inf88"><mml:mi>b</mml:mi></mml:math></inline-formula> was generally small (~0.1) with no difference between rewarded and unrewarded animals. It declined slightly over the night (<xref ref-type="fig" rid="fig8s1">Figure 8—figure supplement 1B</xref>), along with the decline in <inline-formula><mml:math id="inf89"><mml:mi>a</mml:mi></mml:math></inline-formula> (<xref ref-type="fig" rid="fig8">Figure 8C</xref>).</p></sec><sec id="s4-13"><title>Biased random walk</title><p>For the analysis of <xref ref-type="fig" rid="fig9">Figure 9</xref>, we considered only the parts of the trajectory during ‘exploration’ mode. Then we parsed every step between two nodes in terms of the type of action it represents. Note that every link between nodes in the maze is either a ‘left branch’ or a ‘right branch’, depending on its relationship to the parent T-junction. Therefore, there are four kinds of action:</p><list list-type="bullet"><list-item><p><inline-formula><mml:math id="inf90"><mml:mrow><mml:mi>a</mml:mi><mml:mo>=</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:math></inline-formula>: ‘in left’, take a left branch into the maze</p></list-item><list-item><p><inline-formula><mml:math id="inf91"><mml:mrow><mml:mi>a</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:math></inline-formula>: ‘in right’, take a right branch into the maze</p></list-item><list-item><p><inline-formula><mml:math id="inf92"><mml:mrow><mml:mi>a</mml:mi><mml:mo>=</mml:mo><mml:mn>2</mml:mn></mml:mrow></mml:math></inline-formula>: ‘out left’, take a left branch out of the maze</p></list-item><list-item><p><inline-formula><mml:math id="inf93"><mml:mrow><mml:mi>a</mml:mi><mml:mo>=</mml:mo><mml:mn>3</mml:mn></mml:mrow></mml:math></inline-formula>: ‘out right’, take a right branch out of the maze</p></list-item></list><p>At any given node, some actions are not available, for example from an end node one can only take one of the ‘out’ actions.</p><p>To compute the turning biases, we considered every T-junction along the trajectory and correlated the action <inline-formula><mml:math id="inf94"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>a</mml:mi><mml:mn>0</mml:mn></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula> that led into that node with the subsequent action <inline-formula><mml:math id="inf95"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>a</mml:mi><mml:mn>1</mml:mn></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula>. By tallying the action pairs <inline-formula><mml:math id="inf96"><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>a</mml:mi><mml:mn>0</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>a</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></inline-formula>, we computed the conditional probabilities <inline-formula><mml:math id="inf97"><mml:mrow><mml:mi>p</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:msub><mml:mi>a</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo lspace="2.5pt" rspace="2.5pt" stretchy="false">|</mml:mo><mml:msub><mml:mi>a</mml:mi><mml:mn>0</mml:mn></mml:msub></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula>. Then the four biases are defined as<disp-formula id="equ15"><label>(14)</label><mml:math id="m15"><mml:msub><mml:mi>P</mml:mi><mml:mtext>SF</mml:mtext></mml:msub><mml:mrow><mml:mi/><mml:mo>=</mml:mo><mml:mstyle displaystyle="true"><mml:mfrac><mml:mrow><mml:mrow><mml:mi>p</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mn>0</mml:mn><mml:mo lspace="2.5pt" rspace="2.5pt">|</mml:mo><mml:mn>0</mml:mn></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>+</mml:mo><mml:mrow><mml:mi>p</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mn>0</mml:mn><mml:mo lspace="2.5pt" rspace="2.5pt">|</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>+</mml:mo><mml:mrow><mml:mi>p</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mn>1</mml:mn><mml:mo lspace="2.5pt" rspace="2.5pt">|</mml:mo><mml:mn>0</mml:mn></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>+</mml:mo><mml:mrow><mml:mi>p</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mn>1</mml:mn><mml:mo lspace="2.5pt" rspace="2.5pt">|</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mrow><mml:mrow><mml:mrow><mml:mi>p</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mn>0</mml:mn><mml:mo lspace="2.5pt" rspace="2.5pt">|</mml:mo><mml:mn>0</mml:mn></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>+</mml:mo><mml:mrow><mml:mi>p</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mn>0</mml:mn><mml:mo lspace="2.5pt" rspace="2.5pt">|</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>+</mml:mo><mml:mrow><mml:mi>p</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mn>1</mml:mn><mml:mo lspace="2.5pt" rspace="2.5pt">|</mml:mo><mml:mn>0</mml:mn></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>+</mml:mo><mml:mrow><mml:mi>p</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mn>1</mml:mn><mml:mo lspace="2.5pt" rspace="2.5pt">|</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>+</mml:mo><mml:mrow><mml:mi>p</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mn>2</mml:mn><mml:mo lspace="2.5pt" rspace="2.5pt">|</mml:mo><mml:mn>0</mml:mn></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>+</mml:mo><mml:mrow><mml:mi>p</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mn>3</mml:mn><mml:mo lspace="2.5pt" rspace="2.5pt">|</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:mfrac></mml:mstyle></mml:mrow></mml:math></disp-formula><disp-formula id="equ16"><label>(15)</label><mml:math id="m16"><mml:msub><mml:mi>P</mml:mi><mml:mtext>SA</mml:mtext></mml:msub><mml:mrow><mml:mi/><mml:mo>=</mml:mo><mml:mstyle displaystyle="true"><mml:mfrac><mml:mrow><mml:mrow><mml:mi>p</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mn>0</mml:mn><mml:mo lspace="2.5pt" rspace="2.5pt">|</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>+</mml:mo><mml:mrow><mml:mi>p</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mn>1</mml:mn><mml:mo lspace="2.5pt" rspace="2.5pt">|</mml:mo><mml:mn>0</mml:mn></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mrow><mml:mrow><mml:mrow><mml:mi>p</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mn>0</mml:mn><mml:mo lspace="2.5pt" rspace="2.5pt">|</mml:mo><mml:mn>0</mml:mn></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>+</mml:mo><mml:mrow><mml:mi>p</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mn>0</mml:mn><mml:mo lspace="2.5pt" rspace="2.5pt">|</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>+</mml:mo><mml:mrow><mml:mi>p</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mn>1</mml:mn><mml:mo lspace="2.5pt" rspace="2.5pt">|</mml:mo><mml:mn>0</mml:mn></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>+</mml:mo><mml:mrow><mml:mi>p</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mn>1</mml:mn><mml:mo lspace="2.5pt" rspace="2.5pt">|</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:mfrac></mml:mstyle></mml:mrow></mml:math></disp-formula><disp-formula id="equ17"><label>(16)</label><mml:math id="m17"><mml:msub><mml:mi>P</mml:mi><mml:mtext>BF</mml:mtext></mml:msub><mml:mrow><mml:mi/><mml:mo>=</mml:mo><mml:mstyle displaystyle="true"><mml:mfrac><mml:mrow><mml:mrow><mml:mi>p</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mn>0</mml:mn><mml:mo lspace="2.5pt" rspace="2.5pt">|</mml:mo><mml:mn>3</mml:mn></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>+</mml:mo><mml:mrow><mml:mi>p</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mn>1</mml:mn><mml:mo lspace="2.5pt" rspace="2.5pt">|</mml:mo><mml:mn>2</mml:mn></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>+</mml:mo><mml:mrow><mml:mi>p</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mn>2</mml:mn><mml:mo lspace="2.5pt" rspace="2.5pt">|</mml:mo><mml:mn>2</mml:mn></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>+</mml:mo><mml:mrow><mml:mi>p</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mn>2</mml:mn><mml:mo lspace="2.5pt" rspace="2.5pt">|</mml:mo><mml:mn>3</mml:mn></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>+</mml:mo><mml:mrow><mml:mi>p</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mn>3</mml:mn><mml:mo lspace="2.5pt" rspace="2.5pt">|</mml:mo><mml:mn>2</mml:mn></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>+</mml:mo><mml:mrow><mml:mi>p</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mn>3</mml:mn><mml:mo lspace="2.5pt" rspace="2.5pt">|</mml:mo><mml:mn>3</mml:mn></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mrow><mml:mrow><mml:mrow><mml:mi>p</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mn>0</mml:mn><mml:mo lspace="2.5pt" rspace="2.5pt">|</mml:mo><mml:mn>3</mml:mn></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>+</mml:mo><mml:mrow><mml:mi>p</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mn>1</mml:mn><mml:mo lspace="2.5pt" rspace="2.5pt">|</mml:mo><mml:mn>2</mml:mn></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>+</mml:mo><mml:mrow><mml:mi>p</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mn>2</mml:mn><mml:mo lspace="2.5pt" rspace="2.5pt">|</mml:mo><mml:mn>2</mml:mn></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>+</mml:mo><mml:mrow><mml:mi>p</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mn>2</mml:mn><mml:mo lspace="2.5pt" rspace="2.5pt">|</mml:mo><mml:mn>3</mml:mn></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>+</mml:mo><mml:mrow><mml:mi>p</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mn>3</mml:mn><mml:mo lspace="2.5pt" rspace="2.5pt">|</mml:mo><mml:mn>2</mml:mn></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>+</mml:mo><mml:mrow><mml:mi>p</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mn>3</mml:mn><mml:mo lspace="2.5pt" rspace="2.5pt">|</mml:mo><mml:mn>3</mml:mn></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>+</mml:mo><mml:mrow><mml:mi>p</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mn>0</mml:mn><mml:mo lspace="2.5pt" rspace="2.5pt">|</mml:mo><mml:mn>2</mml:mn></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>+</mml:mo><mml:mrow><mml:mi>p</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mn>1</mml:mn><mml:mo lspace="2.5pt" rspace="2.5pt">|</mml:mo><mml:mn>3</mml:mn></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:mfrac></mml:mstyle></mml:mrow></mml:math></disp-formula><disp-formula id="equ18"><label>(17)</label><mml:math id="m18"><mml:msub><mml:mi>P</mml:mi><mml:mtext>BS</mml:mtext></mml:msub><mml:mrow><mml:mi/><mml:mo>=</mml:mo><mml:mstyle displaystyle="true"><mml:mfrac><mml:mrow><mml:mrow><mml:mi>p</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mn>2</mml:mn><mml:mo lspace="2.5pt" rspace="2.5pt">|</mml:mo><mml:mn>2</mml:mn></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>+</mml:mo><mml:mrow><mml:mi>p</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mn>2</mml:mn><mml:mo lspace="2.5pt" rspace="2.5pt">|</mml:mo><mml:mn>3</mml:mn></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>+</mml:mo><mml:mrow><mml:mi>p</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mn>3</mml:mn><mml:mo lspace="2.5pt" rspace="2.5pt">|</mml:mo><mml:mn>2</mml:mn></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>+</mml:mo><mml:mrow><mml:mi>p</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mn>3</mml:mn><mml:mo lspace="2.5pt" rspace="2.5pt">|</mml:mo><mml:mn>3</mml:mn></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mrow><mml:mrow><mml:mrow><mml:mi>p</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mn>0</mml:mn><mml:mo lspace="2.5pt" rspace="2.5pt">|</mml:mo><mml:mn>3</mml:mn></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>+</mml:mo><mml:mrow><mml:mi>p</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mn>1</mml:mn><mml:mo lspace="2.5pt" rspace="2.5pt">|</mml:mo><mml:mn>2</mml:mn></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>+</mml:mo><mml:mrow><mml:mi>p</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mn>2</mml:mn><mml:mo lspace="2.5pt" rspace="2.5pt">|</mml:mo><mml:mn>2</mml:mn></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>+</mml:mo><mml:mrow><mml:mi>p</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mn>2</mml:mn><mml:mo lspace="2.5pt" rspace="2.5pt">|</mml:mo><mml:mn>3</mml:mn></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>+</mml:mo><mml:mrow><mml:mi>p</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mn>3</mml:mn><mml:mo lspace="2.5pt" rspace="2.5pt">|</mml:mo><mml:mn>2</mml:mn></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>+</mml:mo><mml:mrow><mml:mi>p</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mn>3</mml:mn><mml:mo lspace="2.5pt" rspace="2.5pt">|</mml:mo><mml:mn>3</mml:mn></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:mfrac></mml:mstyle></mml:mrow></mml:math></disp-formula></p><p>For the simulations of random agents (<xref ref-type="fig" rid="fig8">Figure 8</xref>, <xref ref-type="fig" rid="fig9">Figure 9</xref>), we used trajectories long enough so the uncertainty in the resulting curves was smaller than the line width.</p></sec><sec id="s4-14"><title>Models of decisions during exploration</title><p>The general approach is to develop a model that assigns probabilities to the animal’s next action, namely which node it will move to next, based on its recent history of actions. All the analyses were restricted to the animal’s ‘exploration’ mode and to the 63 nodes in the maze that are T-junctions. During the ‘drink’ and ‘leave’ modes the animal’s next action is predictable. Similarly, when it finds itself at one of the 64 end nodes it only has one action available.</p><p>For every mouse trajectory, we split the data into five segments, trained the model on 80% of the data, and tested it on 20%, averaging the resulting cross-entropy over the five possible splits. Each segment was in turn composed of parts of the trajectory sampled evenly throughout the 7 h experiment, so as to average over the small changes in the course of the night. The model was evaluated by the cross-entropy between the predictions and the animal’s true actions. If one had an optimal model of behavior, the result would reveal the animal’s true source entropy.</p><sec id="s4-14-1"><title>Fixed depth Markov chain</title><p>To fit a model with fixed history depth <inline-formula><mml:math id="inf98"><mml:mi>k</mml:mi></mml:math></inline-formula> to a measured node sequence <inline-formula><mml:math id="inf99"><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>s</mml:mi><mml:mi>t</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></inline-formula>, we evaluated all the substrings in that sequence of length <inline-formula><mml:math id="inf100"><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mi>k</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></inline-formula>. At any given time <inline-formula><mml:math id="inf101"><mml:mi>t</mml:mi></mml:math></inline-formula>, the <inline-formula><mml:math id="inf102"><mml:mi>k</mml:mi></mml:math></inline-formula>-string <inline-formula><mml:math id="inf103"><mml:mrow><mml:msub><mml:mi mathvariant="bold">𝐡</mml:mi><mml:mi>t</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>s</mml:mi><mml:mrow><mml:mrow><mml:mi>t</mml:mi><mml:mo>-</mml:mo><mml:mi>k</mml:mi></mml:mrow><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:mi mathvariant="normal">…</mml:mi><mml:mo>,</mml:mo><mml:msub><mml:mi>s</mml:mi><mml:mi>t</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> identifies the history of the animal’s <inline-formula><mml:math id="inf104"><mml:mi>k</mml:mi></mml:math></inline-formula> most recent locations. The current state <inline-formula><mml:math id="inf105"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>s</mml:mi><mml:mi>t</mml:mi></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula> is one of 63 T-junctions. Each state is preceded by one of 3 possible states. So the number of history strings is <inline-formula><mml:math id="inf106"><mml:mrow><mml:mn>63</mml:mn><mml:mo>⋅</mml:mo><mml:msup><mml:mn>3</mml:mn><mml:mrow><mml:mi>k</mml:mi><mml:mo>-</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:math></inline-formula>. The 2-string <inline-formula><mml:math id="inf107"><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>s</mml:mi><mml:mi>t</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>s</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></inline-formula> identifies the next action <inline-formula><mml:math id="inf108"><mml:msub><mml:mi>a</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:math></inline-formula>, which can be ‘in left’, ‘in right’, or ‘out’, corresponding to the 3 branches of the T junction. Tallying the history strings with the resulting actions leads to a contingency table of size <inline-formula><mml:math id="inf109"><mml:mrow><mml:mrow><mml:mn>63</mml:mn><mml:mo>⋅</mml:mo><mml:msup><mml:mn>3</mml:mn><mml:mrow><mml:mi>k</mml:mi><mml:mo>-</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msup></mml:mrow><mml:mo>×</mml:mo><mml:mn>3</mml:mn></mml:mrow></mml:math></inline-formula>, containing<disp-formula id="equ19"><label>(18)</label><mml:math id="m19"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>n</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mi mathvariant="bold">h</mml:mi></mml:mrow><mml:mo>,</mml:mo><mml:mi>a</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mrow><mml:mi mathvariant="normal">n</mml:mi><mml:mi mathvariant="normal">u</mml:mi><mml:mi mathvariant="normal">m</mml:mi><mml:mi mathvariant="normal">b</mml:mi><mml:mi mathvariant="normal">e</mml:mi><mml:mi mathvariant="normal">r</mml:mi><mml:mtext> </mml:mtext><mml:mi mathvariant="normal">o</mml:mi><mml:mi mathvariant="normal">f</mml:mi><mml:mtext> </mml:mtext><mml:mi mathvariant="normal">t</mml:mi><mml:mi mathvariant="normal">i</mml:mi><mml:mi mathvariant="normal">m</mml:mi><mml:mi mathvariant="normal">e</mml:mi><mml:mi mathvariant="normal">s</mml:mi><mml:mtext> </mml:mtext><mml:mi mathvariant="normal">h</mml:mi><mml:mi mathvariant="normal">i</mml:mi><mml:mi mathvariant="normal">s</mml:mi><mml:mi mathvariant="normal">t</mml:mi><mml:mi mathvariant="normal">o</mml:mi><mml:mi mathvariant="normal">r</mml:mi><mml:mi mathvariant="normal">y</mml:mi><mml:mtext> </mml:mtext></mml:mrow><mml:mrow><mml:mrow><mml:mi mathvariant="bold">h</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:mtext> </mml:mtext><mml:mi mathvariant="normal">l</mml:mi><mml:mi mathvariant="normal">e</mml:mi><mml:mi mathvariant="normal">a</mml:mi><mml:mi mathvariant="normal">d</mml:mi><mml:mi mathvariant="normal">s</mml:mi><mml:mtext> </mml:mtext><mml:mi mathvariant="normal">t</mml:mi><mml:mi mathvariant="normal">o</mml:mi><mml:mtext> </mml:mtext><mml:mi mathvariant="normal">a</mml:mi><mml:mi mathvariant="normal">c</mml:mi><mml:mi mathvariant="normal">t</mml:mi><mml:mi mathvariant="normal">i</mml:mi><mml:mi mathvariant="normal">o</mml:mi><mml:mi mathvariant="normal">n</mml:mi></mml:mrow><mml:mtext> </mml:mtext><mml:mi mathvariant="normal">a</mml:mi></mml:mrow></mml:mstyle></mml:math></disp-formula></p><p>Based on these sample counts, we estimated the probability of each action <inline-formula><mml:math id="inf110"><mml:mi>a</mml:mi></mml:math></inline-formula> conditional on the history <inline-formula><mml:math id="inf111"><mml:mi mathvariant="bold">𝐡</mml:mi></mml:math></inline-formula> as<disp-formula id="equ20"><label>(19)</label><mml:math id="m20"><mml:mrow><mml:mrow><mml:mi>p</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>a</mml:mi><mml:mo lspace="2.5pt" rspace="2.5pt">|</mml:mo><mml:mi>𝐡</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mrow><mml:mi>n</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mi>𝐡</mml:mi><mml:mo>,</mml:mo><mml:mi>a</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mrow><mml:munder><mml:mo largeop="true" movablelimits="false" symmetric="true">∑</mml:mo><mml:msup><mml:mi>a</mml:mi><mml:mo>′</mml:mo></mml:msup></mml:munder><mml:mrow><mml:mi>n</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mi>𝐡</mml:mi><mml:mo>,</mml:mo><mml:msup><mml:mi>a</mml:mi><mml:mo>′</mml:mo></mml:msup><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mrow><mml:mo>+</mml:mo><mml:mn>3</mml:mn></mml:mrow></mml:mfrac></mml:mrow></mml:math></disp-formula></p><p>This amounts to additive smoothing with a pseudocount of 1, also known as ‘Laplace smoothing’. These conditional probabilities were then used in the testing phase to predict the action at time <inline-formula><mml:math id="inf112"><mml:mi>t</mml:mi></mml:math></inline-formula> based on the preceding history <inline-formula><mml:math id="inf113"><mml:msub><mml:mi mathvariant="bold">𝐡</mml:mi><mml:mi>t</mml:mi></mml:msub></mml:math></inline-formula>. The match to the actually observed actions <italic>a</italic><sub><italic>t</italic></sub> was measured by the cross-entropy<disp-formula id="equ21"><label>(20)</label><mml:math id="m21"><mml:mrow><mml:mi>H</mml:mi><mml:mo>=</mml:mo><mml:msub><mml:mrow><mml:mo>⟨</mml:mo><mml:mrow><mml:mo>-</mml:mo><mml:mrow><mml:mrow><mml:msub><mml:mi>log</mml:mi><mml:mn>2</mml:mn></mml:msub><mml:mo>⁡</mml:mo><mml:mi>p</mml:mi></mml:mrow><mml:mo>⁢</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>a</mml:mi><mml:mi>t</mml:mi></mml:msub><mml:mo lspace="2.5pt" rspace="2.5pt">|</mml:mo><mml:msub><mml:mi>𝐡</mml:mi><mml:mi>t</mml:mi></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mrow><mml:mo>⟩</mml:mo></mml:mrow><mml:mi>t</mml:mi></mml:msub></mml:mrow></mml:math></disp-formula></p></sec><sec id="s4-14-2"><title>Variable depth Markov chain</title><p>As one pushes to longer histories, that is larger <inline-formula><mml:math id="inf114"><mml:mi>k</mml:mi></mml:math></inline-formula>, the analysis quickly becomes data-limited, because the number of possible histories grows exponentially with <inline-formula><mml:math id="inf115"><mml:mi>k</mml:mi></mml:math></inline-formula>. Soon one finds that the counts for each history-action combination drop to where one can no longer estimate probabilities correctly. In an attempt to offset this problem, we pruned the history tree such that each surviving branch had more than some minimal number of counts in the training data. As expected, this model is less prone to over-fitting and degrades more gently as one extends to longer histories (<xref ref-type="fig" rid="fig11s1">Figure 11—figure supplement 1A</xref>). The lowest cross-entropy was obtained with an average history length of ~4.0 but including some paths of up to length 6. Of all the algorithms we tested, this produced the lowest cross-entropies, although the gains relative to the fixed-depth model were modest (<xref ref-type="fig" rid="fig11s1">Figure 11—figure supplement 1C</xref>).</p></sec><sec id="s4-14-3"><title>Pooling across symmetric nodes in the maze</title><p>Another attempt to increase the counts for each history involved pooling counts over multiple T-junctions in the maze that are closely related by symmetry. For example, all the T-junctions at the same level of the binary tree look locally similar, in that they all have corridors of identical length leading from the junction. If one supposes that the animal acts the same way at each of those junctions, one would be justified in pooling across these nodes, leading to a better estimate of the action probabilities, and perhaps less over-fitting. This particular procedure was unsuccessful, in that it produced higher cross-entropy than without pooling.</p><p>However, one may want to distinguish two types of junctions within a given level: L-nodes are reached by a left branch from their parent junction one level lower in the tree, R-nodes by a right branch. For example, in <xref ref-type="fig" rid="fig3s1">Figure 3—figure supplement 1</xref>, node 1 is L-type and node 2 is R-type. When we pooled histories over all the L-nodes at a given level and separately over all the R-nodes the cross-entropy indeed dropped, by about 5% on average. This pooling greatly reduced the amount of over-fitting (<xref ref-type="fig" rid="fig11s1">Figure 11—figure supplement 1B</xref>), which allowed the use of longer histories, which in turn improved the predictions on test data. The benefit of distinguishing L- and R-nodes probably relates to the animal’s tendency to alternate left and right turns.</p><p>All the Markov model results we report are obtained using pooling over L-nodes and R-nodes at each maze level.</p></sec></sec></sec></body><back><ack id="ack"><title>Acknowledgements</title><p>Funding: This work was supported by the Simons Collaboration on the Global Brain (grant 543015 to MM and 543025 to PP), by NSF award 1564330 to PP, and by a gift from Google to PP.</p></ack><sec id="s5" sec-type="additional-information"><title>Additional information</title><fn-group content-type="competing-interest"><title>Competing interests</title><fn fn-type="COI-statement" id="conf2"><p>Reviewing editor, <italic>eLife</italic></p></fn><fn fn-type="COI-statement" id="conf1"><p>No competing interests declared</p></fn></fn-group><fn-group content-type="author-contribution"><title>Author contributions</title><fn fn-type="con" id="con1"><p>Conceptualization, Data curation, Software, Formal analysis, Validation, Investigation, Visualization, Methodology, Writing - review and editing</p></fn><fn fn-type="con" id="con2"><p>Conceptualization, Data curation, Software, Formal analysis, Validation, Investigation, Visualization, Methodology, Writing - review and editing</p></fn><fn fn-type="con" id="con3"><p>Conceptualization, Software, Formal analysis, Supervision, Funding acquisition, Validation, Visualization, Methodology, Project administration, Writing - review and editing</p></fn><fn fn-type="con" id="con4"><p>Conceptualization, Software, Formal analysis, Supervision, Funding acquisition, Validation, Visualization, Methodology, Writing - original draft, Project administration, Writing - review and editing</p></fn></fn-group><fn-group content-type="ethics-information"><title>Ethics</title><fn fn-type="other"><p>Animal experimentation: This study was performed in strict accordance with the recommendations in the Guide for the Care and Use of Laboratory Animals of the National Institutes of Health. All of the animals were handled according to animal protocol 1656 approved by the institutional animal care and use committee (IACUC) at Caltech.</p></fn></fn-group></sec><sec id="s6" sec-type="supplementary-material"><title>Additional files</title><supplementary-material id="transrepform"><label>Transparent reporting form</label><media mime-subtype="pdf" mimetype="application" xlink:href="elife-66175-transrepform-v2.pdf"/></supplementary-material></sec><sec id="s7" sec-type="data-availability"><title>Data availability</title><p>The behavioral data and code that produced the figures are available in a public Github repository cited in the article <ext-link ext-link-type="uri" xlink:href="https://github.com/markusmeister/Rosenberg-2021-Repository">https://github.com/markusmeister/Rosenberg-2021-Repository</ext-link> (copy archived at <ext-link ext-link-type="uri" xlink:href="https://archive.softwareheritage.org/swh:1:rev:224141473e53d6e8963a77fbe625f570b0903ef1">https://archive.softwareheritage.org/swh:1:rev:224141473e53d6e8963a77fbe625f570b0903ef1</ext-link>). We also prepared a permanent institutional repository at <ext-link ext-link-type="uri" xlink:href="https://data.caltech.edu/badge/latestdoi/329740227">https://data.caltech.edu/badge/latestdoi/329740227</ext-link>.</p><p>The following dataset was generated:</p><p><element-citation id="dataset1" publication-type="data" specific-use="isSupplementedBy"><person-group person-group-type="author"><name><surname>Rosenberg</surname><given-names>M</given-names></name><name><surname>Zhang</surname><given-names>T</given-names></name><name><surname>Perona</surname><given-names>P</given-names></name><name><surname>Meister</surname><given-names>M</given-names></name></person-group><year iso-8601-date="2021">2021</year><data-title>Rosenberg-2021-Repository</data-title><source>Github</source><pub-id assigning-authority="other" pub-id-type="accession" xlink:href="https://github.com/markusmeister/Rosenberg-2021-Repository">markusmeister/Rosenberg-2021-Repository</pub-id></element-citation></p></sec><ref-list><title>References</title><ref id="bib1"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Alonso</surname> <given-names>A</given-names></name><name><surname>van der Meij</surname> <given-names>J</given-names></name><name><surname>Tse</surname> <given-names>D</given-names></name><name><surname>Genzel</surname> <given-names>L</given-names></name></person-group><year iso-8601-date="2020">2020</year><article-title>Naïve to expert: considering the role of previous knowledge in memory</article-title><source>Brain and Neuroscience Advances</source><volume>4</volume><fpage>4</fpage><lpage>17</lpage><pub-id pub-id-type="doi">10.1177/2398212820948686</pub-id></element-citation></ref><ref id="bib2"><element-citation publication-type="book"><person-group person-group-type="author"><collab>Apollodorus</collab></person-group><year iso-8601-date="1921">1921</year><source>The Library, Vol II, with an English Translation by Sir James George Frazer</source><publisher-loc>London</publisher-loc><publisher-name>William Heinemann Ltd</publisher-name></element-citation></ref><ref id="bib3"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Behrens</surname> <given-names>TEJ</given-names></name><name><surname>Muller</surname> <given-names>TH</given-names></name><name><surname>Whittington</surname> <given-names>JCR</given-names></name><name><surname>Mark</surname> <given-names>S</given-names></name><name><surname>Baram</surname> <given-names>AB</given-names></name><name><surname>Stachenfeld</surname> <given-names>KL</given-names></name><name><surname>Kurth-Nelson</surname> <given-names>Z</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>What is a cognitive map? Organizing knowledge for flexible behavior</article-title><source>Neuron</source><volume>100</volume><fpage>490</fpage><lpage>509</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2018.10.002</pub-id><pub-id pub-id-type="pmid">30359611</pub-id></element-citation></ref><ref id="bib4"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Berlyne</surname> <given-names>DE</given-names></name></person-group><year iso-8601-date="1960">1960</year><source>Conflict, Arousal, and Curiosity</source><publisher-name>McGraw-Hill Book Company</publisher-name></element-citation></ref><ref id="bib5"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bitterman</surname> <given-names>ME</given-names></name><name><surname>Menzel</surname> <given-names>R</given-names></name><name><surname>Fietz</surname> <given-names>A</given-names></name><name><surname>Schäfer</surname> <given-names>S</given-names></name></person-group><year iso-8601-date="1983">1983</year><article-title>Classical conditioning of proboscis extension in honeybees (Apis mellifera)</article-title><source>Journal of Comparative Psychology</source><volume>97</volume><fpage>107</fpage><lpage>119</lpage><pub-id pub-id-type="doi">10.1037/0735-7036.97.2.107</pub-id><pub-id pub-id-type="pmid">6872507</pub-id></element-citation></ref><ref id="bib6"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bourtchuladze</surname> <given-names>R</given-names></name><name><surname>Frenguelli</surname> <given-names>B</given-names></name><name><surname>Blendy</surname> <given-names>J</given-names></name><name><surname>Cioffi</surname> <given-names>D</given-names></name><name><surname>Schutz</surname> <given-names>G</given-names></name><name><surname>Silva</surname> <given-names>AJ</given-names></name></person-group><year iso-8601-date="1994">1994</year><article-title>Deficient long-term memory in mice with a targeted mutation of the cAMP-responsive element-binding protein</article-title><source>Cell</source><volume>79</volume><fpage>59</fpage><lpage>68</lpage><pub-id pub-id-type="doi">10.1016/0092-8674(94)90400-6</pub-id><pub-id pub-id-type="pmid">7923378</pub-id></element-citation></ref><ref id="bib7"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Brennan</surname> <given-names>PA</given-names></name><name><surname>Keverne</surname> <given-names>EB</given-names></name></person-group><year iso-8601-date="1997">1997</year><article-title>Neural mechanisms of mammalian olfactory learning</article-title><source>Progress in Neurobiology</source><volume>51</volume><fpage>457</fpage><lpage>481</lpage><pub-id pub-id-type="doi">10.1016/S0301-0082(96)00069-X</pub-id><pub-id pub-id-type="pmid">9106902</pub-id></element-citation></ref><ref id="bib8"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bruce</surname> <given-names>HM</given-names></name></person-group><year iso-8601-date="1959">1959</year><article-title>An exteroceptive block to pregnancy in the mouse</article-title><source>Nature</source><volume>184</volume><elocation-id>105</elocation-id><pub-id pub-id-type="doi">10.1038/184105a0</pub-id><pub-id pub-id-type="pmid">13805128</pub-id></element-citation></ref><ref id="bib9"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Buel</surname> <given-names>J</given-names></name></person-group><year iso-8601-date="1934">1934</year><article-title>The linear maze. I. &quot;Choice-point expectancy,&quot; &quot;correctness,&quot; and the goal gradient</article-title><source>Journal of Comparative Psychology</source><volume>17</volume><fpage>185</fpage><lpage>199</lpage><pub-id pub-id-type="doi">10.1037/h0072346</pub-id></element-citation></ref><ref id="bib10"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Burgess</surname> <given-names>CP</given-names></name><name><surname>Lak</surname> <given-names>A</given-names></name><name><surname>Steinmetz</surname> <given-names>NA</given-names></name><name><surname>Zatka-Haas</surname> <given-names>P</given-names></name><name><surname>Bai Reddy</surname> <given-names>C</given-names></name><name><surname>Jacobs</surname> <given-names>EAK</given-names></name><name><surname>Linden</surname> <given-names>JF</given-names></name><name><surname>Paton</surname> <given-names>JJ</given-names></name><name><surname>Ranson</surname> <given-names>A</given-names></name><name><surname>Schröder</surname> <given-names>S</given-names></name><name><surname>Soares</surname> <given-names>S</given-names></name><name><surname>Wells</surname> <given-names>MJ</given-names></name><name><surname>Wool</surname> <given-names>LE</given-names></name><name><surname>Harris</surname> <given-names>KD</given-names></name><name><surname>Carandini</surname> <given-names>M</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>High-yield methods for accurate two-alternative visual psychophysics in head-fixed mice</article-title><source>Cell Reports</source><volume>20</volume><fpage>2513</fpage><lpage>2524</lpage><pub-id pub-id-type="doi">10.1016/j.celrep.2017.08.047</pub-id><pub-id pub-id-type="pmid">28877482</pub-id></element-citation></ref><ref id="bib11"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Carandini</surname> <given-names>M</given-names></name><name><surname>Churchland</surname> <given-names>AK</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>Probing perceptual decisions in rodents</article-title><source>Nature Neuroscience</source><volume>16</volume><fpage>824</fpage><lpage>831</lpage><pub-id pub-id-type="doi">10.1038/nn.3410</pub-id><pub-id pub-id-type="pmid">23799475</pub-id></element-citation></ref><ref id="bib12"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Cleland</surname> <given-names>TA</given-names></name><name><surname>Narla</surname> <given-names>VA</given-names></name><name><surname>Boudadi</surname> <given-names>K</given-names></name></person-group><year iso-8601-date="2009">2009</year><article-title>Multiple learning parameters differentially regulate olfactory generalization</article-title><source>Behavioral Neuroscience</source><volume>123</volume><fpage>26</fpage><lpage>35</lpage><pub-id pub-id-type="doi">10.1037/a0013991</pub-id><pub-id pub-id-type="pmid">19170427</pub-id></element-citation></ref><ref id="bib13"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Estes</surname> <given-names>WK</given-names></name></person-group><year iso-8601-date="1956">1956</year><article-title>The problem of inference from curves based on group data</article-title><source>Psychological Bulletin</source><volume>53</volume><fpage>134</fpage><lpage>140</lpage><pub-id pub-id-type="doi">10.1037/h0045156</pub-id><pub-id pub-id-type="pmid">13297917</pub-id></element-citation></ref><ref id="bib14"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Fanselow</surname> <given-names>MS</given-names></name><name><surname>Bolles</surname> <given-names>RC</given-names></name></person-group><year iso-8601-date="1979">1979</year><article-title>Naloxone and shock-elicited freezing in the rat</article-title><source>Journal of Comparative and Physiological Psychology</source><volume>93</volume><fpage>736</fpage><lpage>744</lpage><pub-id pub-id-type="doi">10.1037/h0077609</pub-id><pub-id pub-id-type="pmid">479405</pub-id></element-citation></ref><ref id="bib15"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Fonio</surname> <given-names>E</given-names></name><name><surname>Benjamini</surname> <given-names>Y</given-names></name><name><surname>Golani</surname> <given-names>I</given-names></name></person-group><year iso-8601-date="2009">2009</year><article-title>Freedom of movement and the stability of its unfolding in free exploration of mice</article-title><source>PNAS</source><volume>106</volume><fpage>21335</fpage><lpage>21340</lpage><pub-id pub-id-type="doi">10.1073/pnas.0812513106</pub-id><pub-id pub-id-type="pmid">19934049</pub-id></element-citation></ref><ref id="bib16"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Gallistel</surname> <given-names>CR</given-names></name><name><surname>Fairhurst</surname> <given-names>S</given-names></name><name><surname>Balsam</surname> <given-names>P</given-names></name></person-group><year iso-8601-date="2004">2004</year><article-title>The learning curve: implications of a quantitative analysis</article-title><source>PNAS</source><volume>101</volume><fpage>13124</fpage><lpage>13131</lpage><pub-id pub-id-type="doi">10.1073/pnas.0404965101</pub-id><pub-id pub-id-type="pmid">15331782</pub-id></element-citation></ref><ref id="bib17"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Grobéty</surname> <given-names>M-C</given-names></name><name><surname>Schenk</surname> <given-names>F</given-names></name></person-group><year iso-8601-date="1992">1992</year><article-title>Spatial learning in a three-dimensional maze</article-title><source>Animal Behaviour</source><volume>43</volume><fpage>1011</fpage><lpage>1020</lpage><pub-id pub-id-type="doi">10.1016/S0003-3472(06)80014-X</pub-id></element-citation></ref><ref id="bib18"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Guo</surname> <given-names>ZV</given-names></name><name><surname>Li</surname> <given-names>N</given-names></name><name><surname>Huber</surname> <given-names>D</given-names></name><name><surname>Ophir</surname> <given-names>E</given-names></name><name><surname>Gutnisky</surname> <given-names>D</given-names></name><name><surname>Ting</surname> <given-names>JT</given-names></name><name><surname>Feng</surname> <given-names>G</given-names></name><name><surname>Svoboda</surname> <given-names>K</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>Flow of cortical activity underlying a tactile decision in mice</article-title><source>Neuron</source><volume>81</volume><fpage>179</fpage><lpage>194</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2013.10.020</pub-id><pub-id pub-id-type="pmid">24361077</pub-id></element-citation></ref><ref id="bib19"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hughes</surname> <given-names>RN</given-names></name></person-group><year iso-8601-date="1997">1997</year><article-title>Intrinsic exploration in animals: motives and measurement</article-title><source>Behavioural Processes</source><volume>41</volume><fpage>213</fpage><lpage>226</lpage><pub-id pub-id-type="doi">10.1016/S0376-6357(97)00055-7</pub-id><pub-id pub-id-type="pmid">24896854</pub-id></element-citation></ref><ref id="bib20"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Krechevsky</surname> <given-names>I</given-names></name></person-group><year iso-8601-date="1932">1932</year><article-title>”Hypotheses” in rats</article-title><source>Psychological Review</source><volume>39</volume><fpage>516</fpage><lpage>532</lpage></element-citation></ref><ref id="bib21"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>LeDoux</surname> <given-names>JE</given-names></name></person-group><year iso-8601-date="2000">2000</year><article-title>Emotion circuits in the brain</article-title><source>Annual Review of Neuroscience</source><volume>23</volume><fpage>155</fpage><lpage>184</lpage><pub-id pub-id-type="doi">10.1146/annurev.neuro.23.1.155</pub-id><pub-id pub-id-type="pmid">10845062</pub-id></element-citation></ref><ref id="bib22"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>McNamara</surname> <given-names>CG</given-names></name><name><surname>Tejero-Cantero</surname> <given-names>Á</given-names></name><name><surname>Trouche</surname> <given-names>S</given-names></name><name><surname>Campo-Urriza</surname> <given-names>N</given-names></name><name><surname>Dupret</surname> <given-names>D</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>Dopaminergic neurons promote hippocampal reactivation and spatial memory persistence</article-title><source>Nature Neuroscience</source><volume>17</volume><fpage>1658</fpage><lpage>1660</lpage><pub-id pub-id-type="doi">10.1038/nn.3843</pub-id><pub-id pub-id-type="pmid">25326690</pub-id></element-citation></ref><ref id="bib23"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Munn</surname> <given-names>NL</given-names></name></person-group><year iso-8601-date="1950">1950a</year><chapter-title>The learning process</chapter-title><person-group person-group-type="editor"><name><surname>Munn</surname> <given-names>N. L</given-names></name></person-group><source>Handbook of Psychological Research on the Rat; an Introduction to Animal Psychology</source><publisher-name>Houghton Mifflin</publisher-name><fpage>226</fpage><lpage>288</lpage></element-citation></ref><ref id="bib24"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Munn</surname> <given-names>NL</given-names></name></person-group><year iso-8601-date="1950">1950b</year><chapter-title>The role of sensory processes in maze behavior</chapter-title><person-group person-group-type="editor"><name><surname>Munn</surname> <given-names>N. L</given-names></name></person-group><source>Handbook of Psychological Research on the Rat; an Introduction to Animal Psychology</source><publisher-name>Houghton Mifflin</publisher-name><fpage>181</fpage><lpage>225</lpage></element-citation></ref><ref id="bib25"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Nagy</surname> <given-names>M</given-names></name><name><surname>Horicsányi</surname> <given-names>A</given-names></name><name><surname>Kubinyi</surname> <given-names>E</given-names></name><name><surname>Couzin</surname> <given-names>ID</given-names></name><name><surname>Vásárhelyi</surname> <given-names>G</given-names></name><name><surname>Flack</surname> <given-names>A</given-names></name><name><surname>Vicsek</surname> <given-names>T</given-names></name></person-group><year iso-8601-date="2020">2020</year><article-title>Synergistic benefits of group search in rats</article-title><source>Current Biology</source><volume>30</volume><fpage>4733</fpage><lpage>4738</lpage><pub-id pub-id-type="doi">10.1016/j.cub.2020.08.079</pub-id><pub-id pub-id-type="pmid">32976805</pub-id></element-citation></ref><ref id="bib26"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Nath</surname> <given-names>T</given-names></name><name><surname>Mathis</surname> <given-names>A</given-names></name><name><surname>Chen</surname> <given-names>AC</given-names></name><name><surname>Patel</surname> <given-names>A</given-names></name><name><surname>Bethge</surname> <given-names>M</given-names></name><name><surname>Mathis</surname> <given-names>MW</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>Using DeepLabCut for 3D markerless pose estimation across species and behaviors</article-title><source>Nature Protocols</source><volume>14</volume><fpage>2152</fpage><lpage>2176</lpage><pub-id pub-id-type="doi">10.1038/s41596-019-0176-0</pub-id><pub-id pub-id-type="pmid">31227823</pub-id></element-citation></ref><ref id="bib27"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Newsome</surname> <given-names>WT</given-names></name><name><surname>Paré</surname> <given-names>EB</given-names></name></person-group><year iso-8601-date="1988">1988</year><article-title>A selective impairment of motion perception following lesions of the middle temporal visual area (MT)</article-title><source>The Journal of Neuroscience</source><volume>8</volume><fpage>2201</fpage><lpage>2211</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.08-06-02201.1988</pub-id><pub-id pub-id-type="pmid">3385495</pub-id></element-citation></ref><ref id="bib28"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Olton</surname> <given-names>DS</given-names></name></person-group><year iso-8601-date="1979">1979</year><article-title>Mazes, maps, and memory</article-title><source>American Psychologist</source><volume>34</volume><fpage>583</fpage><lpage>596</lpage><pub-id pub-id-type="doi">10.1037/0003-066X.34.7.583</pub-id></element-citation></ref><ref id="bib29"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Pisupati</surname> <given-names>S</given-names></name><name><surname>Chartarifsky-Lynn</surname> <given-names>L</given-names></name><name><surname>Khanal</surname> <given-names>A</given-names></name><name><surname>Churchland</surname> <given-names>AK</given-names></name></person-group><year iso-8601-date="2021">2021</year><article-title>Lapses in perceptual decisions reflect exploration</article-title><source>eLife</source><volume>10</volume><elocation-id>e55490</elocation-id><pub-id pub-id-type="doi">10.7554/eLife.55490</pub-id><pub-id pub-id-type="pmid">33427198</pub-id></element-citation></ref><ref id="bib30"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Rondi-Reig</surname> <given-names>L</given-names></name><name><surname>Petit</surname> <given-names>GH</given-names></name><name><surname>Tobin</surname> <given-names>C</given-names></name><name><surname>Tonegawa</surname> <given-names>S</given-names></name><name><surname>Mariani</surname> <given-names>J</given-names></name><name><surname>Berthoz</surname> <given-names>A</given-names></name></person-group><year iso-8601-date="2006">2006</year><article-title>Impaired sequential egocentric and allocentric memories in forebrain-specific-NMDA receptor knock-out mice during a new task dissociating strategies of navigation</article-title><source>Journal of Neuroscience</source><volume>26</volume><fpage>4071</fpage><lpage>4081</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.3408-05.2006</pub-id><pub-id pub-id-type="pmid">16611824</pub-id></element-citation></ref><ref id="bib31"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Rosser</surname> <given-names>AE</given-names></name><name><surname>Keverne</surname> <given-names>EB</given-names></name></person-group><year iso-8601-date="1985">1985</year><article-title>The importance of central noradrenergic neurones in the formation of an olfactory memory in the prevention of pregnancy block</article-title><source>Neuroscience</source><volume>15</volume><fpage>1141</fpage><lpage>1147</lpage><pub-id pub-id-type="doi">10.1016/0306-4522(85)90258-1</pub-id><pub-id pub-id-type="pmid">4047399</pub-id></element-citation></ref><ref id="bib32"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Sato</surname> <given-names>N</given-names></name><name><surname>Fujishita</surname> <given-names>C</given-names></name><name><surname>Yamagishi</surname> <given-names>A</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>To take or not to take the shortcut: flexible spatial behaviour of rats based on cognitive map in a lattice maze</article-title><source>Behavioural Processes</source><volume>151</volume><fpage>39</fpage><lpage>43</lpage><pub-id pub-id-type="doi">10.1016/j.beproc.2018.03.010</pub-id><pub-id pub-id-type="pmid">29526812</pub-id></element-citation></ref><ref id="bib33"><element-citation publication-type="software"><person-group person-group-type="author"><name><surname>Seward</surname> <given-names>J</given-names></name></person-group><year iso-8601-date="2019">2019</year><source>Bzip2</source><ext-link ext-link-type="uri" xlink:href="https://www.sourceware.org/bzip2/">https://www.sourceware.org/bzip2/</ext-link></element-citation></ref><ref id="bib34"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Shokaku</surname> <given-names>T</given-names></name><name><surname>Moriyama</surname> <given-names>T</given-names></name><name><surname>Murakami</surname> <given-names>H</given-names></name><name><surname>Shinohara</surname> <given-names>S</given-names></name><name><surname>Manome</surname> <given-names>N</given-names></name><name><surname>Morioka</surname> <given-names>K</given-names></name></person-group><year iso-8601-date="2020">2020</year><article-title>Development of an automatic turntable-type multiple T-maze device and observation of pill bug behavior</article-title><source>Review of Scientific Instruments</source><volume>91</volume><elocation-id>104104</elocation-id><pub-id pub-id-type="doi">10.1063/5.0009531</pub-id></element-citation></ref><ref id="bib35"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Small</surname> <given-names>WS</given-names></name></person-group><year iso-8601-date="1901">1901</year><article-title>Experimental study of the mental processes of the rat II</article-title><source>The American Journal of Psychology</source><volume>12</volume><fpage>206</fpage><lpage>239</lpage><pub-id pub-id-type="doi">10.2307/1412534</pub-id></element-citation></ref><ref id="bib36"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Tchernichovski</surname> <given-names>O</given-names></name><name><surname>Benjamini</surname> <given-names>Y</given-names></name><name><surname>Golani</surname> <given-names>I</given-names></name></person-group><year iso-8601-date="1998">1998</year><article-title>The dynamics of long-term exploration in the rat</article-title><source>Biological Cybernetics</source><volume>78</volume><fpage>423</fpage><lpage>432</lpage><pub-id pub-id-type="doi">10.1007/s004220050446</pub-id></element-citation></ref><ref id="bib37"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Tolman</surname> <given-names>EC</given-names></name></person-group><year iso-8601-date="1938">1938</year><article-title>The determiners of behavior at a choice point</article-title><source>Psychological Review</source><volume>45</volume><fpage>1</fpage><lpage>41</lpage><pub-id pub-id-type="doi">10.1037/h0062733</pub-id></element-citation></ref><ref id="bib38"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Tolman</surname> <given-names>EC</given-names></name></person-group><year iso-8601-date="1948">1948</year><article-title>Cognitive maps in rats and men</article-title><source>Psychological Review</source><volume>55</volume><fpage>189</fpage><lpage>208</lpage><pub-id pub-id-type="doi">10.1037/h0061626</pub-id><pub-id pub-id-type="pmid">18870876</pub-id></element-citation></ref><ref id="bib39"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Tolman</surname> <given-names>E</given-names></name><name><surname>Honzik</surname> <given-names>C</given-names></name></person-group><year iso-8601-date="1930">1930</year><article-title>Degrees of hunger, reward and Non-Reward, and maze learning in rats</article-title><source>University of California Publications in Psychology</source><volume>4</volume><fpage>241</fpage><lpage>256</lpage></element-citation></ref><ref id="bib40"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Uchida</surname> <given-names>N</given-names></name><name><surname>Mainen</surname> <given-names>ZF</given-names></name></person-group><year iso-8601-date="2003">2003</year><article-title>Speed and accuracy of olfactory discrimination in the rat</article-title><source>Nature Neuroscience</source><volume>6</volume><fpage>1224</fpage><lpage>1229</lpage><pub-id pub-id-type="doi">10.1038/nn1142</pub-id><pub-id pub-id-type="pmid">14566341</pub-id></element-citation></ref><ref id="bib41"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Uster</surname> <given-names>HJ</given-names></name><name><surname>Bättig</surname> <given-names>K</given-names></name><name><surname>Nägeli</surname> <given-names>HH</given-names></name></person-group><year iso-8601-date="1976">1976</year><article-title>Effects of maze geometry and experience on exploratory behavior in the rat</article-title><source>Animal Learning &amp; Behavior</source><volume>4</volume><fpage>84</fpage><lpage>88</lpage><pub-id pub-id-type="doi">10.3758/BF03211992</pub-id></element-citation></ref><ref id="bib42"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Weber</surname> <given-names>JN</given-names></name><name><surname>Peterson</surname> <given-names>BK</given-names></name><name><surname>Hoekstra</surname> <given-names>HE</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>Discrete genetic modules are responsible for complex burrow evolution in Peromyscus mice</article-title><source>Nature</source><volume>493</volume><fpage>402</fpage><lpage>405</lpage><pub-id pub-id-type="doi">10.1038/nature11816</pub-id><pub-id pub-id-type="pmid">23325221</pub-id></element-citation></ref><ref id="bib43"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wehner</surname> <given-names>R</given-names></name><name><surname>Michel</surname> <given-names>B</given-names></name><name><surname>Antonsen</surname> <given-names>P</given-names></name></person-group><year iso-8601-date="1996">1996</year><article-title>Visual navigation in insects: coupling of egocentric and geocentric information</article-title><source>Journal of Experimental Biology</source><volume>199</volume><fpage>129</fpage><lpage>140</lpage><pub-id pub-id-type="doi">10.1242/jeb.199.1.129</pub-id></element-citation></ref><ref id="bib44"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wood</surname> <given-names>RA</given-names></name><name><surname>Bauza</surname> <given-names>M</given-names></name><name><surname>Krupic</surname> <given-names>J</given-names></name><name><surname>Burton</surname> <given-names>S</given-names></name><name><surname>Delekate</surname> <given-names>A</given-names></name><name><surname>Chan</surname> <given-names>D</given-names></name><name><surname>O'Keefe</surname> <given-names>J</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>The honeycomb maze provides a novel test to study hippocampal-dependent spatial navigation</article-title><source>Nature</source><volume>554</volume><fpage>102</fpage><lpage>105</lpage><pub-id pub-id-type="doi">10.1038/nature25433</pub-id><pub-id pub-id-type="pmid">29364869</pub-id></element-citation></ref><ref id="bib45"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Woodrow</surname> <given-names>H</given-names></name></person-group><year iso-8601-date="1942">1942</year><article-title>The problem of general quantitative laws in psychology</article-title><source>Psychological Bulletin</source><volume>39</volume><fpage>1</fpage><lpage>27</lpage><pub-id pub-id-type="doi">10.1037/h0058275</pub-id></element-citation></ref><ref id="bib46"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Yoder</surname> <given-names>RM</given-names></name><name><surname>Clark</surname> <given-names>BJ</given-names></name><name><surname>Brown</surname> <given-names>JE</given-names></name><name><surname>Lamia</surname> <given-names>MV</given-names></name><name><surname>Valerio</surname> <given-names>S</given-names></name><name><surname>Shinder</surname> <given-names>ME</given-names></name><name><surname>Taube</surname> <given-names>JS</given-names></name></person-group><year iso-8601-date="2011">2011</year><article-title>Both visual and idiothetic cues contribute to head direction cell stability during navigation along complex routes</article-title><source>Journal of Neurophysiology</source><volume>105</volume><fpage>2989</fpage><lpage>3001</lpage><pub-id pub-id-type="doi">10.1152/jn.01041.2010</pub-id></element-citation></ref></ref-list></back><sub-article article-type="decision-letter" id="sa1"><front-stub><article-id pub-id-type="doi">10.7554/eLife.66175.sa1</article-id><title-group><article-title>Decision letter</article-title></title-group><contrib-group><contrib contrib-type="editor"><name><surname>Mathis</surname><given-names>Mackenzie W</given-names></name><role>Reviewing Editor</role><aff><institution>EPFL</institution><country>Switzerland</country></aff></contrib></contrib-group><contrib-group><contrib contrib-type="reviewer"><name><surname>Berman</surname><given-names>Gordon J</given-names></name><role>Reviewer</role><aff><institution>Emory University</institution><country>United States</country></aff></contrib></contrib-group></front-stub><body><boxed-text><p>Our editorial process produces two outputs: (i) <ext-link ext-link-type="uri" xlink:href="https://sciety.org/articles/activity/10.1101/2021.01.14.426746">public reviews</ext-link> designed to be posted alongside <ext-link ext-link-type="uri" xlink:href="https://www.biorxiv.org/content/10.1101/2021.01.14.426746v1">the preprint</ext-link> for the benefit of readers; (ii) feedback on the manuscript for the authors, including requests for revisions, shown below. We also include an acceptance summary that explains what the editors found interesting or important about the work.</p></boxed-text><p>Thank you for submitting your article &quot;Mice in a labyrinth: Rapid learning, sudden insight, and efficient exploration&quot; for consideration by <italic>eLife</italic>. Your article has been reviewed by 3 peer reviewers, and the evaluation has been overseen by Mackenzie Mathis as the Reviewing Editor and Catherine Dulac as the Senior Editor. The following individual involved in review of your submission has agreed to reveal their identity: Gordon J Berman (Reviewer #1).</p><p>The reviewers have discussed their reviews with one another, and the Reviewing Editor has drafted this to help you prepare a revised submission.</p><p>Essential revisions:</p><p>– The role of odors in task performance. We would like to ask the authors to clarify their thinking and data with respect to the role of odors in the behavior. The manuscript as currently written gives the impression that odors play a negligible role, and that mouse behavior is comprised of a series of decisions internal to the brain (e.g., the use of the phrasing &quot;sudden insight&quot;; the abstract's statement that a mouse &quot;executes correct 10-bit choices after only 10 reward experiences – a learning rate 1000-fold higher than in 2AFC experiments&quot;; etc.) But it was not clear that odors play a negligible role.</p><p>First, the mention of odors at the end of the discussion was a little confusing: although the text as written seems to suggest that the effect of odors was negligible, the data described seems to indicate the very opposite conclusion. The authors mention an experiment in which they rotate the maze, to ask whether animals are following a previously laid down odor trail, and they write that &quot;Following that rotation the animal did in fact make a few visits to the rotated port location.&quot; Don't those first few visits to the rotated location suggest that indeed, the animal <italic>was</italic> following an odor trail? Why was behavior in those first few visits apparently discarded as inconsequential? It would be helpful if the authors clarified their thinking here. The authors proceeded to write that the mice &quot;then quickly exploited the real water port again, without any apparent re-learning.&quot; But couldn't that same odor trail be used as a scaffold for rapid behavior change in runs subsequent to the first few ones?</p><p>Second, the data for the odor experiments mentioned in those final discussion paragraphs should be shown and included as part of the manuscript (both the maze rotation data and the open water bowl data). Odors are a very significant potential confound to how these data are being interpreted. Allowing readers to see the data and evaluate it for themselves is important.</p><p>Third, we would like to invite the authors to consider and comment on the following and other odor-guided-behavior possibilities. This one seems, at first sight, to be consistent with much of their data. Consider a mouse that, as it runs it brushes against the walls, leaving behind a faint odor trail (it doesn't need to be urine or feces), and that tends to not reverse unless it reaches a dead end, but has a little bit of a tendency (doesn't need to be absolute) to avoid, based on odor, its own recent previous path. Wouldn't that mouse do a level 6 home run in its very first bout, with little overlap between entry and exit paths? Wouldn't it produce a trail very much like the trail shown in Figure 2A? Yet this mouse wouldn't have learnt <italic>anything</italic> internally, in its brain, about what constitutes a home path – the &quot;learning&quot; for this mouse would all have been in the physical odor trail it left behind. That is only one possibility for how odor could affect behavior. There could be myriad others. After an hour, the maze is going to have feces and urine in multiple spots. As written, the claims about sudden insights, without considering whether such insight moments correlate with sudden odorant depositions (which would seem likely to act as highly prominent landmarks for the animal), could give readers the impression that the data demonstrate that it's all about internal mental processes. We are not yet convinced that odors can be so thoroughly ruled out.</p><p>Fortunately, this can all be addressed in the writing. Whether or not mice use odors in the maze, the data is fascinating and the paper extremely interesting. We would invite the authors to consider addressing the issue from the beginning, in the introduction, so that readers can keep the issue in mind as they absorb the paper. (We phrase this as an invitation in the sense that this is a suggestion for the authors, not a mandatory requirement.) For example, a simple sentence in the introduction saying something like &quot;preliminary control experiments suggested to us that odors did not play a major role in how mice learned and solved these navigation problems, but we did not fully control for odors and their potential role remains to be fully elucidated,&quot; would not detract from the work in any way, and would go a very long way towards making sure that, even as they are making their way through the paper, readers don't get the impression that the issue is settled and odors can be forgotten.</p><p>– We would ask the authors to consider the implications of having an imposed 90-second delay between rewards. The authors write that animals tend to explore the maze, as opposed to simply focusing on the water reward location (line 118; Figure 6 and accompanying main text). That the imposed 90-second delay could play a role in this is, surprisingly, not mentioned or considered. The 90-second delay also has an important implication for the &quot;learning insight&quot; analysis, as described in the next weakness below.</p><p>– Another issue is in regard to a central claim in the manuscript, which is that animals have sudden insight moments in which they learn the path to the water reward. A plot based on data from one animal is presented in the main text (Figure 4B), appearing to the eye to support the claim (green and red lines have a kink in them). But for unexplained reasons data from other animals is relegated to the supplementary information (Figure 4 supplement 1), and many of these other animals do not, to the eye, support the claim (lines are smoothly curved, not kinked). The quantitative analysis that is used to adjudicate between sudden insights (a sudden step in the reward rate) versus gradual learning (slow continuous rise in reward rate) is flawed and, in our view, cannot be relied on: the approach compares a step model versus a smooth 2nd-order (quadratic) curve for how reward rate changes over time. However, because there is an imposed 90-second delay between successive rewards, the reward rate is capped at a maximum of 40 per hour, and cannot grow beyond that. A quadratic curve with a positive second-order term would rise indefinitely and will therefore be a poor fit to the data, not because the animals don't learn in a smooth way, but because of the 90-second delay, thus artifactually biasing the results of the analysis towards the step model.</p><p>– We suggest that the authors show, in simulated data, how the 90 s delay would affect the quadratic ramp model to see how much of a straw man it is. While the authors are clear that they see discontinuities in only 5 out of the 10 water-deprived animals, perhaps it would be ideal for them to show a couple of the less-discrete learners in the main text for additional clarity.</p><p>– &quot;One shot learning.&quot; We don't think the authors have convincingly shown true one-shot homing behavior. It is an interesting and important claim in the manuscript (&quot;one-shot learning of the home path&quot; is the title of a section), but it is not yet completely clear that the data support that interpretation. The authors' point is that &quot;home runs&quot; start out longer than what random gradual exploration would predict, and that point is indeed supported by the data. But for the authors' claims about one-shot learning of home runs &quot;from locations not previously encountered&quot; to be supported, it is critical that the first and second bouts have little overlap between entry and exit paths. This should be shown in a main text figure, but it isn't, and moreover, Figure 5-supplement does not show initial individual runs, but rather averages over all bouts. Thus, the critical information about the first trajectories is nowhere in the current manuscript. We ask the authors to clearly show these initial-runs data for the individual mice. We do think Figure 2A suggests that their claim about path overlap in initial bouts may actually be true, but this should be demonstrated. Otherwise, we suggest the claim of one-shot learning be toned down.</p></body></sub-article><sub-article article-type="reply" id="sa2"><front-stub><article-id pub-id-type="doi">10.7554/eLife.66175.sa2</article-id><title-group><article-title>Author response</article-title></title-group></front-stub><body><disp-quote content-type="editor-comment"><p>Essential revisions:</p><p>– The role of odors in task performance. We would like to ask the authors to clarify their thinking and data with respect to the role of odors in the behavior. The manuscript as currently written gives the impression that odors play a negligible role, and that mouse behavior is comprised of a series of decisions internal to the brain (e.g., the use of the phrasing &quot;sudden insight&quot;; the abstract's statement that a mouse &quot;executes correct 10-bit choices after only 10 reward experiences – a learning rate 1000-fold higher than in 2AFC experiments&quot;; etc.) But it was not clear that odors play a negligible role.</p><p>First, the mention of odors at the end of the discussion was a little confusing: although the text as written seems to suggest that the effect of odors was negligible, the data described seems to indicate the very opposite conclusion. The authors mention an experiment in which they rotate the maze, to ask whether animals are following a previously laid down odor trail, and they write that &quot;Following that rotation the animal did in fact make a few visits to the rotated port location.&quot; Don't those first few visits to the rotated location suggest that indeed, the animal was following an odor trail? Why was behavior in those first few visits apparently discarded as inconsequential? It would be helpful if the authors clarified their thinking here. The authors proceeded to write that the mice &quot;then quickly exploited the real water port again, without any apparent re-learning.&quot; But couldn't that same odor trail be used as a scaffold for rapid behavior change in runs subsequent to the first few ones?</p><p>Second, the data for the odor experiments mentioned in those final discussion paragraphs should be shown and included as part of the manuscript (both the maze rotation data and the open water bowl data). Odors are a very significant potential confound to how these data are being interpreted. Allowing readers to see the data and evaluate it for themselves is important.</p></disp-quote><p>Regarding the water bowl experiments: These were done somewhat informally in an exploratory phase of the work on a different labyrinth. The revised text in Discussion omits their mention. There are stronger reasons to conclude that the water port does not attract the animals from a distance. For example the mice often turn away from the port even in close proximity, and discover it only after touching it. The reader can verify this directly in the raw videos.</p><p>Regarding the maze rotation experiments: We now have additional data and analysis from four animals and present these results in a new figure. The conclusion for all 4 animals: To navigate to the water port the animals do not depend on any cues that are attached to the maze. This includes any material they might have deposited, but also any construction details by which different locations in the maze might have been identified. Please see the new Figure 4 and accompanying text and methods.</p><p>Strictly speaking this conclusion applies only to the time point of the rotation, a few hours into the experiment, when the mice are experts at finding the water port. It is conceivable that the animal’s navigation policy changes in the course of learning, and the revised text includes this caveat. This and many other questions regarding the mechanisms of cognition will be taken up in separate experiments.</p><disp-quote content-type="editor-comment"><p>Third, we would like to invite the authors to consider and comment on the following and other odor-guided-behavior possibilities. This one seems, at first sight, to be consistent with much of their data. Consider a mouse that, as it runs it brushes against the walls, leaving behind a faint odor trail (it doesn't need to be urine or feces), and that tends to not reverse unless it reaches a dead end, but has a little bit of a tendency (doesn't need to be absolute) to avoid, based on odor, its own recent previous path. Wouldn't that mouse do a level 6 home run in its very first bout, with little overlap between entry and exit paths? Wouldn't it produce a trail very much like the trail shown in Figure 2A? Yet this mouse wouldn't have learnt anything internally, in its brain, about what constitutes a home path – the &quot;learning&quot; for this mouse would all have been in the physical odor trail it left behind.</p></disp-quote><p>Yes, that is an interesting proposal. A policy of &quot;move to the location visited least recently and reverse at a cul-de-sac&quot; would lead the mouse to perform a single complete scan of the labyrinth and then return from an end node. In practice this is not what happens during the animal’s first bout. We added a figure in the data repository with trajectories of the first bout for each of the 19 animals. In most cases the animal goes over some parts of the territory multiple times while leaving other regions untouched. On almost all the first home runs the mouse violates the rule to avoid its previous path, in that it enters a recently visited location rather than one that is still untouched. Of course, that doesn’t mean that odors play no role in the process.</p><disp-quote content-type="editor-comment"><p>That is only one possibility for how odor could affect behavior. There could be myriad others. After an hour, the maze is going to have feces and urine in multiple spots. As written, the claims about sudden insights, without considering whether such insight moments correlate with sudden odorant depositions (which would seem likely to act as highly prominent landmarks for the animal), could give readers the impression that the data demonstrate that it's all about internal mental processes. We are not yet convinced that odors can be so thoroughly ruled out.</p><p>Fortunately, this can all be addressed in the writing. Whether or not mice use odors in the maze, the data is fascinating and the paper extremely interesting. We would invite the authors to consider addressing the issue from the beginning, in the introduction, so that readers can keep the issue in mind as they absorb the paper. (We phrase this as an invitation in the sense that this is a suggestion for the authors, not a mandatory requirement.) For example, a simple sentence in the introduction saying something like &quot;preliminary control experiments suggested to us that odors did not play a major role in how mice learned and solved these navigation problems, but we did not fully control for odors and their potential role remains to be fully elucidated,&quot; would not detract from the work in any way, and would go a very long way towards making sure that, even as they are making their way through the paper, readers don't get the impression that the issue is settled and odors can be forgotten.</p></disp-quote><p>Yes, we now bring up the topic immediately after the section on rapid learning, which is when these questions will start forming in the reader’s mind. The maze rotation results are presented here. We also extended the topic in the discussion. The text acknowledges that the respective roles of olfaction and other senses remain to be worked out.</p><disp-quote content-type="editor-comment"><p>– We would ask the authors to consider the implications of having an imposed 90-second delay between rewards. The authors write that animals tend to explore the maze, as opposed to simply focusing on the water reward location (line 118; Figure 6 and accompanying main text). That the imposed 90-second delay could play a role in this is, surprisingly, not mentioned or considered.</p></disp-quote><p>Nothing in the experimental design forces the animal to leave the port during the timeout period; it could sit there and nap or groom and periodically test the port without penalty. We revised the text in Results and Discussion to state this explicitly. Fortunately the animals don’t adopt that lazy policy, otherwise it would be difficult to study the learning process. On the other hand, if we did not impose a timeout then the animal could drink to satiety on the first visit. Following that, it would likely explore the maze, just like all the animals that are fully sated to begin with. But we would again be deprived of the ability to watch the animal learn.</p><disp-quote content-type="editor-comment"><p>The 90-second delay also has an important implication for the &quot;learning insight&quot; analysis, as described in the next weakness below.</p><p>– Another issue is in regard to a central claim in the manuscript, which is that animals have sudden insight moments in which they learn the path to the water reward. A plot based on data from one animal is presented in the main text (Figure 4B), appearing to the eye to support the claim (green and red lines have a kink in them). But for unexplained reasons data from other animals is relegated to the supplementary information (Figure 4 supplement 1), and many of these other animals do not, to the eye, support the claim (lines are smoothly curved, not kinked). The quantitative analysis that is used to adjudicate between sudden insights (a sudden step in the reward rate) versus gradual learning (slow continuous rise in reward rate) is flawed and, in our view, cannot be relied on: the approach compares a step model versus a smooth 2nd-order (quadratic) curve for how reward rate changes over time. However, because there is an imposed 90-second delay between successive rewards, the reward rate is capped at a maximum of 40 per hour, and cannot grow beyond that. A quadratic curve with a positive second-order term would rise indefinitely and will therefore be a poor fit to the data, not because the animals don't learn in a smooth way, but because of the 90-second delay, thus artifactually biasing the results of the analysis towards the step model.</p><p>– We suggest that the authors show, in simulated data, how the 90 s delay would affect the quadratic ramp model to see how much of a straw man it is. While the authors are clear that they see discontinuities in only 5 out of the 10 water-deprived animals, perhaps it would be ideal for them to show a couple of the less-discrete learners in the main text for additional clarity.</p></disp-quote><p>Yes, the capped reward rate limits the range of reasonable parameters for the &quot;ramp model&quot;. In response to this concern, we adopted a different analysis. We fit the rate of events with a sigmoid function having 4 parameters. It starts from a low rate and eventually saturates at some higher rate. In between it rises with an S-shape and the midpoint and width of the rise are again free parameters. The function fits all instances rather well, as shown in the revised supplementary figure.</p><p>The conclusions are almost identical to the previous approach: 6 of the 10 animals have a very short width parameter. We pursued these further to derive the uncertainty about the time of the step, as described in the revised methods. As recommended, we also moved one of the more gradual learners into the main text figure. Please see the revised Figure 5 with accompanying text and methods.</p><disp-quote content-type="editor-comment"><p>– &quot;One shot learning.&quot; We don't think the authors have convincingly shown true one-shot homing behavior. It is an interesting and important claim in the manuscript (&quot;one-shot learning of the home path&quot; is the title of a section), but it is not yet completely clear that the data support that interpretation. The authors' point is that &quot;home runs&quot; start out longer than what random gradual exploration would predict, and that point is indeed supported by the data. But for the authors' claims about one-shot learning of home runs &quot;from locations not previously encountered&quot; to be supported, it is critical that the first and second bouts have little overlap between entry and exit paths. This should be shown in a main text figure, but it isn't, and moreover, Figure 5-supplement does not show initial individual runs, but rather averages over all bouts. Thus, the critical information about the first trajectories is nowhere in the current manuscript. We ask the authors to clearly show these initial-runs data for the individual mice. We do think Figure 2A suggests that their claim about path overlap in initial bouts may actually be true, but this should be demonstrated. Otherwise, we suggest the claim of one-shot learning be toned down.</p></disp-quote><p>We have added the requested analysis for each animal’s very first home run, and moved those figure panels to the main text as suggested. The conclusion remains the same. Please see the revised Figure 6 with accompanying text and methods.</p></body></sub-article></article>