<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD v1.1d3 20150301//EN"  "JATS-archivearticle1.dtd"><article article-type="research-article" dtd-version="1.1d3" xmlns:xlink="http://www.w3.org/1999/xlink"><front><journal-meta><journal-id journal-id-type="nlm-ta">elife</journal-id><journal-id journal-id-type="publisher-id">eLife</journal-id><journal-title-group><journal-title>eLife</journal-title></journal-title-group><issn publication-format="electronic">2050-084X</issn><publisher><publisher-name>eLife Sciences Publications, Ltd</publisher-name></publisher></journal-meta><article-meta><article-id pub-id-type="publisher-id">74653</article-id><article-id pub-id-type="doi">10.7554/eLife.74653</article-id><article-categories><subj-group subj-group-type="display-channel"><subject>Research Article</subject></subj-group><subj-group subj-group-type="heading"><subject>Neuroscience</subject></subj-group></article-categories><title-group><article-title>Constructing the hierarchy of predictive auditory sequences in the marmoset brain</article-title></title-group><contrib-group><contrib contrib-type="author" id="author-256782"><name><surname>Jiang</surname><given-names>Yuwei</given-names></name><contrib-id contrib-id-type="orcid">http://orcid.org/0000-0002-9533-0760</contrib-id><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="other" rid="par-2"/><xref ref-type="other" rid="par-12"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" id="author-258204"><name><surname>Komatsu</surname><given-names>Misako</given-names></name><contrib-id contrib-id-type="orcid">http://orcid.org/0000-0003-4464-4484</contrib-id><xref ref-type="aff" rid="aff2">2</xref><xref ref-type="other" rid="par-3"/><xref ref-type="other" rid="par-4"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" id="author-258205"><name><surname>Chen</surname><given-names>Yuyan</given-names></name><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" id="author-258206"><name><surname>Xie</surname><given-names>Ruoying</given-names></name><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" id="author-258207"><name><surname>Zhang</surname><given-names>Kaiwei</given-names></name><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" id="author-258208"><name><surname>Xia</surname><given-names>Ying</given-names></name><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" id="author-258209"><name><surname>Gui</surname><given-names>Peng</given-names></name><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" corresp="yes" id="author-183545"><name><surname>Liang</surname><given-names>Zhifeng</given-names></name><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="corresp" rid="cor1">*</xref><xref ref-type="other" rid="par-7"/><xref ref-type="other" rid="par-8"/><xref ref-type="other" rid="par-10"/><xref ref-type="other" rid="par-11"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" corresp="yes" id="author-52172"><name><surname>Wang</surname><given-names>Liping</given-names></name><contrib-id contrib-id-type="orcid">http://orcid.org/0000-0003-2038-0234</contrib-id><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="corresp" rid="cor2">*</xref><xref ref-type="other" rid="par-1"/><xref ref-type="other" rid="par-5"/><xref ref-type="other" rid="par-6"/><xref ref-type="other" rid="par-8"/><xref ref-type="other" rid="par-9"/><xref ref-type="fn" rid="conf1"/></contrib><aff id="aff1"><institution content-type="dept">Institute of Neuroscience</institution>, <institution>Chinese Academy of Sciences</institution>, <addr-line><named-content content-type="city">Shanghai</named-content></addr-line>, <country>China</country></aff><aff id="aff2"><institution content-type="dept">Laboratory for Molecular Analysis of Higher Brain Function</institution>, <institution>Center for Brain Science, RIKEN</institution>, <addr-line><named-content content-type="city">Saitama</named-content></addr-line>, <country>Japan</country></aff></contrib-group><contrib-group content-type="section"><contrib contrib-type="editor" id="author-43678"><name><surname>Griffiths</surname><given-names>Timothy D</given-names></name><role>Reviewing editor</role><aff><institution>University of Newcastle</institution>, <country>United Kingdom</country></aff></contrib></contrib-group><author-notes><corresp id="cor1"><label>*</label>For correspondence: <email>zliang@ion.ac.cn</email> (ZL);</corresp><corresp id="cor2"><label>*</label>For correspondence: <email>lipingwng@gmail.com</email> (LW);</corresp></author-notes><pub-date date-type="pub" publication-format="electronic"><day>17</day><month>02</month><year>2022</year></pub-date><volume>11</volume><elocation-id>e74653</elocation-id><history><date date-type="received"><day>12</day><month>10</month><year>2021</year></date><date date-type="accepted"><day>16</day><month>02</month><year>2022</year></date></history><permissions><copyright-statement>Â© 2022, Jiang et al</copyright-statement><copyright-year>2022</copyright-year><copyright-holder>Jiang et al</copyright-holder><license xlink:href="http://creativecommons.org/licenses/by/4.0/"><license-p>This article is distributed under the terms of the <ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/licenses/by/4.0/">Creative Commons Attribution License</ext-link> permitting unrestricted use and redistribution provided that the original author and source are credited.</license-p></license></permissions><self-uri content-type="pdf" xlink:href="elife-74653-v1.pdf"/><abstract><p>Our brains constantly generate predictions of sensory input that are compared with actual inputs, propagate the prediction-errors through a hierarchy of brain regions, and subsequently update the internal predictions of the world. However, the essential feature of predictive coding, the notion of hierarchical depth and its neural mechanisms, remains largely unexplored. Here, we investigated the hierarchical depth of predictive auditory processing by combining functional magnetic resonance imaging (fMRI) and high-density whole-brain electrocorticography (ECoG) in marmoset monkeys during an auditory local-global paradigm in which the temporal regularities of the stimuli were designed at two hierarchical levels. The prediction-errors and prediction updates were examined as neural responses to auditory mismatches and omissions. Using fMRI, we identified a hierarchical gradient along the auditory pathway: midbrain and sensory regions represented local, shorter-time-scale predictive processing followed by associative auditory regions, whereas anterior temporal and prefrontal areas represented global, longer-time-scale sequence processing. The complementary ECoG recordings confirmed the activations at cortical surface areas and further differentiated the signals of prediction-error and update, which were transmitted via putative bottom-up g and top-down b oscillations, respectively. Furthermore, omission responses caused by absence of input, reflecting solely the two levels of prediction signals that are unique to the hierarchical predictive coding framework, demonstrated the hierarchical top-down process of predictions in the auditory, temporal, and prefrontal areas. Thus, our findings support the hierarchical predictive coding framework, and outline how neural networks and spatiotemporal dynamics are used to represent and arrange a hierarchical structure of auditory sequences in the marmoset brain.</p></abstract><kwd-group kwd-group-type="research-organism"><title>Research organism</title><kwd>Other</kwd></kwd-group><funding-group><award-group id="par-1"><funding-source><institution-wrap><institution>National Science and Technology Innovation 2030 Major Program</institution></institution-wrap></funding-source><award-id>2021ZD0204102</award-id><principal-award-recipient><name><surname>Wang</surname><given-names>Liping</given-names></name></principal-award-recipient></award-group><award-group id="par-2"><funding-source><institution-wrap><institution>Youth Innovation Promotion Association Chinese Academy of Sciences</institution></institution-wrap></funding-source><principal-award-recipient><name><surname>Jiang</surname><given-names>Yuwei</given-names></name></principal-award-recipient></award-group><award-group id="par-3"><funding-source><institution-wrap><institution>Brain/MINDS from the Japan Agency for Medical Research and Development</institution></institution-wrap></funding-source><award-id>JP20dm0207069</award-id><principal-award-recipient><name><surname>Komatsu</surname><given-names>Misako</given-names></name></principal-award-recipient></award-group><award-group id="par-4"><funding-source><institution-wrap><institution>JSPS KAKENHI</institution></institution-wrap></funding-source><award-id>JP19H04993</award-id><principal-award-recipient><name><surname>Komatsu</surname><given-names>Misako</given-names></name></principal-award-recipient></award-group><award-group id="par-5"><funding-source><institution-wrap><institution>Strategic Priority Research Program</institution></institution-wrap></funding-source><award-id>XDB32070201</award-id><principal-award-recipient><name><surname>Wang</surname><given-names>Liping</given-names></name></principal-award-recipient></award-group><award-group id="par-6"><funding-source><institution-wrap><institution>Strategic Priority Research Program</institution></institution-wrap></funding-source><award-id>XDB32030100</award-id><principal-award-recipient><name><surname>Wang</surname><given-names>Liping</given-names></name></principal-award-recipient></award-group><award-group id="par-7"><funding-source><institution-wrap><institution>Strategic Priority Research Program</institution></institution-wrap></funding-source><award-id>XDBS01030100</award-id><principal-award-recipient><name><surname>Liang</surname><given-names>Zhifeng</given-names></name></principal-award-recipient></award-group><award-group id="par-8"><funding-source><institution-wrap><institution>Pioneer Hundreds of Talents Program from the Chinese Academy of Sciences</institution></institution-wrap></funding-source><principal-award-recipient><name><surname>Liang</surname><given-names>Zhifeng</given-names></name><name><surname>Wang</surname><given-names>Liping</given-names></name></principal-award-recipient></award-group><award-group id="par-9"><funding-source><institution-wrap><institution>Shanghai Municipal Science and Technology Major Project</institution></institution-wrap></funding-source><award-id>2018SHZDZX05</award-id><principal-award-recipient><name><surname>Wang</surname><given-names>Liping</given-names></name></principal-award-recipient></award-group><award-group id="par-10"><funding-source><institution-wrap><institution>Shanghai Municipal Science and Technology Major Project</institution></institution-wrap></funding-source><award-id>2018SHZDZX05</award-id><principal-award-recipient><name><surname>Liang</surname><given-names>Zhifeng</given-names></name></principal-award-recipient></award-group><award-group id="par-11"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/501100001809</institution-id><institution>National Natural Science Foundation of China</institution></institution-wrap></funding-source><award-id>81801354</award-id><principal-award-recipient><name><surname>Liang</surname><given-names>Zhifeng</given-names></name></principal-award-recipient></award-group><award-group id="par-12"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/501100001809</institution-id><institution>National Natural Science Foundation of China</institution></institution-wrap></funding-source><award-id>31900797</award-id><principal-award-recipient><name><surname>Jiang</surname><given-names>Yuwei</given-names></name></principal-award-recipient></award-group><funding-statement>The funders had no role in study design, data collection and interpretation, or the decision to submit the work for publication.</funding-statement></funding-group></article-meta></front><back><sec id="s1" sec-type="additional-information"><title>Additional information</title><fn-group content-type="competing-interest"><title>Competing interest</title><fn fn-type="conflict" id="conf1"><p>The authors declare that no competing interests exist.</p></fn></fn-group><fn-group content-type="ethics-information"><title>Ethics</title><fn fn-type="other"><p>Animal experimentation: The protocol of the fMRI study was approved by the Ethical Committee of the Institute of Neuroscience, Chinese Academy of Sciences (no. ION-20180522). All procedures of the ECoG study were conducted in accordance with a protocol approved by the RIKEN Ethical Committee [no. W2020-2-008(2)].</p></fn></fn-group></sec><sec id="s2" sec-type="supplementary-material"><title>Additional Files</title><sec id="s3" sec-type="data-availability"><title>Data availability</title><p>The fMRI and ECoG data that support the findings of this study are publicly available in Dryad: Jiang, Yuwei (2021), Constructing the hierarchy of predictive auditory sequences in the marmoset brain, Dryad, Dataset, https://doi.org/10.5061/dryad.j3tx95xfp.</p><p>The following datasets were generated:</p><p><element-citation id="dataset1" publication-type="data" specific-use="isSupplementedBy"><person-group person-group-type="author"><collab>Jiang</collab><collab>Yuwei</collab></person-group><year iso-8601-date="2021">2021</year><source>Data from: Constructing the hierarchy of predictive auditory sequences in the marmoset brain</source><ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.5061/dryad.j3tx95xfp">http://dx.doi.org/10.5061/dryad.j3tx95xfp</ext-link><comment>Dryad Digital Repository, doi:10.5061/dryad.j3tx95xfp</comment></element-citation></p></sec><supplementary-material><ext-link xlink:href="elife-74653-supp-v1.zip">Download zip</ext-link><p>Any figures and tables for this article are included in the PDF. The zip folder contains additional supplemental files.</p></supplementary-material></sec></back></article>