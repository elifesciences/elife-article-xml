<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD v1.1 20151215//EN"  "JATS-archivearticle1.dtd"><article article-type="research-article" dtd-version="1.1" xmlns:ali="http://www.niso.org/schemas/ali/1.0/" xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink"><front><journal-meta><journal-id journal-id-type="nlm-ta">elife</journal-id><journal-id journal-id-type="publisher-id">eLife</journal-id><journal-title-group><journal-title>eLife</journal-title></journal-title-group><issn pub-type="epub" publication-format="electronic">2050-084X</issn><publisher><publisher-name>eLife Sciences Publications, Ltd</publisher-name></publisher></journal-meta><article-meta><article-id pub-id-type="publisher-id">60705</article-id><article-id pub-id-type="doi">10.7554/eLife.60705</article-id><article-categories><subj-group subj-group-type="display-channel"><subject>Research Article</subject></subj-group><subj-group subj-group-type="heading"><subject>Neuroscience</subject></subj-group></article-categories><title-group><article-title>Visual attention modulates the integration of goal-relevant evidence and not value</article-title></title-group><contrib-group><contrib contrib-type="author" corresp="yes" id="author-196029"><name><surname>Sepulveda</surname><given-names>Pradyumna</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">https://orcid.org/0000-0003-0159-6777</contrib-id><email>p.sepulveda@ucl.ac.uk</email><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="other" rid="fund1"/><xref ref-type="fn" rid="con1"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" id="author-206571"><name><surname>Usher</surname><given-names>Marius</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">http://orcid.org/0000-0001-8041-9060</contrib-id><xref ref-type="aff" rid="aff2">2</xref><xref ref-type="fn" rid="con2"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" id="author-198754"><name><surname>Davies</surname><given-names>Ned</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">https://orcid.org/0000-0002-3357-8576</contrib-id><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="fn" rid="con3"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" id="author-198755"><name><surname>Benson</surname><given-names>Amy A</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">http://orcid.org/0000-0002-8239-5266</contrib-id><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="fn" rid="con4"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" id="author-198756"><name><surname>Ortoleva</surname><given-names>Pietro</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">https://orcid.org/0000-0002-5943-6621</contrib-id><xref ref-type="aff" rid="aff3">3</xref><xref ref-type="fn" rid="con5"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" corresp="yes" id="author-199361"><name><surname>De Martino</surname><given-names>Benedetto</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">https://orcid.org/0000-0002-3555-2732</contrib-id><email>benedettodemartino@gmail.com</email><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="aff" rid="aff4">4</xref><xref ref-type="other" rid="fund2"/><xref ref-type="fn" rid="con6"/><xref ref-type="fn" rid="conf1"/></contrib><aff id="aff1"><label>1</label><institution>Institute of Cognitive Neuroscience, University College London</institution><addr-line><named-content content-type="city">London</named-content></addr-line><country>United Kingdom</country></aff><aff id="aff2"><label>2</label><institution>School of Psychological Sciences and Sagol School of Neuroscience, Tel Aviv University</institution><addr-line><named-content content-type="city">Tel Aviv</named-content></addr-line><country>Israel</country></aff><aff id="aff3"><label>3</label><institution>Department of Economics and Woodrow Wilson School, Princeton University</institution><addr-line><named-content content-type="city">Princeton</named-content></addr-line><country>United States</country></aff><aff id="aff4"><label>4</label><institution>Wellcome Centre for Human Neuroimaging, University College London</institution><addr-line><named-content content-type="city">London</named-content></addr-line><country>United Kingdom</country></aff></contrib-group><contrib-group content-type="section"><contrib contrib-type="senior_editor"><name><surname>Büchel</surname><given-names>Christian</given-names></name><role>Senior Editor</role><aff><institution>University Medical Center Hamburg-Eppendorf</institution><country>Germany</country></aff></contrib><contrib contrib-type="editor"><name><surname>Wyart</surname><given-names>Valentin</given-names></name><role>Reviewing Editor</role><aff><institution>École normale supérieure, PSL University, INSERM</institution><country>France</country></aff></contrib></contrib-group><pub-date date-type="publication" publication-format="electronic"><day>17</day><month>11</month><year>2020</year></pub-date><pub-date pub-type="collection"><year>2020</year></pub-date><volume>9</volume><elocation-id>e60705</elocation-id><history><date date-type="received" iso-8601-date="2020-07-03"><day>03</day><month>07</month><year>2020</year></date><date date-type="accepted" iso-8601-date="2020-11-16"><day>16</day><month>11</month><year>2020</year></date></history><permissions><copyright-statement>© 2020, Sepulveda et al</copyright-statement><copyright-year>2020</copyright-year><copyright-holder>Sepulveda et al</copyright-holder><ali:free_to_read/><license xlink:href="http://creativecommons.org/licenses/by/4.0/"><ali:license_ref>http://creativecommons.org/licenses/by/4.0/</ali:license_ref><license-p>This article is distributed under the terms of the <ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/licenses/by/4.0/">Creative Commons Attribution License</ext-link>, which permits unrestricted use and redistribution provided that the original author and source are credited.</license-p></license></permissions><self-uri content-type="pdf" xlink:href="elife-60705-v2.pdf"/><abstract><p>When choosing between options, such as food items presented in plain view, people tend to choose the option they spend longer looking at. The prevailing interpretation is that visual attention increases value. However, in previous studies, ‘value’ was coupled to a behavioural goal, since subjects had to choose the item they preferred. This makes it impossible to discern if visual attention has an effect on value, or, instead, if attention modulates the information most relevant for the goal of the decision-maker. Here, we present the results of two independent studies—a perceptual and a value-based task—that allow us to decouple value from goal-relevant information using specific task-framing. Combining psychophysics with computational modelling, we show that, contrary to the current interpretation, attention does not boost value, but instead it modulates goal-relevant information. This work provides a novel and more general mechanism by which attention interacts with choice.</p></abstract><kwd-group kwd-group-type="author-keywords"><kwd>decision-making</kwd><kwd>visual attention</kwd><kwd>computational modelling</kwd><kwd>eye movements</kwd><kwd>metacognition</kwd><kwd>goal-directed choice</kwd></kwd-group><kwd-group kwd-group-type="research-organism"><title>Research organism</title><kwd>Human</kwd></kwd-group><funding-group><award-group id="fund1"><funding-source><institution-wrap><institution>Chilean National Agency for Research and Development</institution></institution-wrap></funding-source><award-id>Graduate student scholarship - DOCTORADO BECAS CHILE/2017 - 72180193</award-id><principal-award-recipient><name><surname>Sepulveda</surname><given-names>Pradyumna</given-names></name></principal-award-recipient></award-group><award-group id="fund2"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/100004440</institution-id><institution>Wellcome Trust</institution></institution-wrap></funding-source><award-id>Sir Henry Dale Fellowship (102612 /A/13/Z)</award-id><principal-award-recipient><name><surname>De Martino</surname><given-names>Benedetto</given-names></name></principal-award-recipient></award-group><funding-statement>The funders had no role in study design, data collection and interpretation, or the decision to submit the work for publication.</funding-statement></funding-group><custom-meta-group><custom-meta specific-use="meta-only"><meta-name>Author impact statement</meta-name><meta-value>Visual attention modulates the integration of the evidence that is most useful for achieving a goal in both perceptual and value-based decisions.</meta-value></custom-meta></custom-meta-group></article-meta></front><body><sec id="s1" sec-type="intro"><title>Introduction</title><p>How is value constructed and what is the role played by visual attention in choice? Despite their centrality to the understanding of human decision-making, these remain unanswered questions. Attention is thought to play a central role, prioritising and enhancing which information is accessed during the decision-making process. How attention interacts with value-based choice has been investigated in psychology and neuroscience (<xref ref-type="bibr" rid="bib30">Krajbich et al., 2010</xref>; <xref ref-type="bibr" rid="bib32">Krajbich and Rangel, 2011</xref>; <xref ref-type="bibr" rid="bib8">Cavanagh et al., 2014</xref>; <xref ref-type="bibr" rid="bib36">Polanía et al., 2014</xref>; <xref ref-type="bibr" rid="bib17">Gluth et al., 2015</xref>; <xref ref-type="bibr" rid="bib19">Gluth et al., 2020</xref>; <xref ref-type="bibr" rid="bib13">Folke et al., 2017</xref>; <xref ref-type="bibr" rid="bib44">Tavares et al., 2017</xref>; <xref ref-type="bibr" rid="bib15">Glickman et al., 2018</xref>; <xref ref-type="bibr" rid="bib18">Gluth et al., 2018</xref>; <xref ref-type="bibr" rid="bib45">Thomas et al., 2019</xref>) and this question is at the core of the theory of rational inattention in economics (<xref ref-type="bibr" rid="bib39">Sims, 2003</xref>; <xref ref-type="bibr" rid="bib40">Sims, 2010</xref>; <xref ref-type="bibr" rid="bib7">Caplin and Dean, 2015</xref>; <xref ref-type="bibr" rid="bib24">Hébert and Woodford, 2017</xref>).</p><p>In this context, robust empirical evidence has shown that people tend to look for longer at the options with higher values (<xref ref-type="bibr" rid="bib1">Anderson et al., 2011</xref>; <xref ref-type="bibr" rid="bib18">Gluth et al., 2018</xref>; <xref ref-type="bibr" rid="bib19">Gluth et al., 2020</xref>) and that they tend to choose the option they pay more visual attention to (<xref ref-type="bibr" rid="bib30">Krajbich et al., 2010</xref>; <xref ref-type="bibr" rid="bib32">Krajbich and Rangel, 2011</xref>; <xref ref-type="bibr" rid="bib13">Folke et al., 2017</xref>; <xref ref-type="bibr" rid="bib8">Cavanagh et al., 2014</xref>; <xref ref-type="bibr" rid="bib45">Thomas et al., 2019</xref>). The most common interpretation is that attention is allocated to items based on their value and that looking or attending to an option boosts its value, either by amplifying it (<xref ref-type="bibr" rid="bib30">Krajbich et al., 2010</xref>; <xref ref-type="bibr" rid="bib32">Krajbich and Rangel, 2011</xref>; <xref ref-type="bibr" rid="bib41">Smith and Krajbich, 2019</xref>) or by shifting it upwards by a constant amount (<xref ref-type="bibr" rid="bib8">Cavanagh et al., 2014</xref>). This intuition has been elegantly formalised using models of sequential sampling, in particular the attentional drift diffusion model (aDDM), which considers that visual attention boosts the drift rate of the stochastic accumulation processes (<xref ref-type="bibr" rid="bib30">Krajbich et al., 2010</xref>). More recently, this same model has been also used to study the role of attention in the accumulation of perceptual information (<xref ref-type="bibr" rid="bib44">Tavares et al., 2017</xref>). These lines of investigation have been extremely fruitful, as they have provided an elegant algorithmic description of the interplay between attention and choice.</p><p>As consequence of this development, the predominant assumption in the field of neuroeconomics has become that attention operates over the value of the alternatives (<xref ref-type="bibr" rid="bib41">Smith and Krajbich, 2019</xref>). However, this view overlooks the fact that in the majority of these studies, value is coupled to the agents’ behavioural goal, that is, participants had to choose the item they found more rewarding. However, some recent studies have called into question this assumption and have hinted towards a flexible role of attention on sampling goal-relevant options (<xref ref-type="bibr" rid="bib29">Kovach et al., 2014</xref>; <xref ref-type="bibr" rid="bib15">Glickman et al., 2018</xref>). Even further, recent developments have shown that the ‘value networks’ in the brain could be tracking not purely reward value, but actually goal-congruent information (<xref ref-type="bibr" rid="bib14">Frömer et al., 2019</xref>; <xref ref-type="bibr" rid="bib43">Suri et al., 2020</xref>). Considering all this, our study aims to understand in more detail the role of goals on visual attention during both value-based and perceptual decisions: we aim to test the hypothesis that attention acts in a flexible way upon the accumulation of <italic>goal-relevant information</italic> and to examine the effects on the mechanism of preference formation and confidence.</p><p>Our experimental design decouples reward value from choice by means of a simple task-framing manipulation. In the main eye-tracking part of our value-based experiment, participants were asked to choose between different pairs of snacks. We used two frame manipulations: <italic>like</italic> and <italic>dislike</italic>. In the <italic>like</italic> frame, they had to indicate which snack they would like to consume at the end of the experiment; this is consistent with the standard tasks used in value-based decision studies. But in the <italic>dislike</italic> frame, subjects had to indicate the snack that they would prefer <italic>not</italic> to eat, equivalent to choosing the other option. Crucially, in the latter frame value is distinct from the behavioural goal of which item to select. In fact, in the <italic>dislike</italic> frame participants need to consider the ‘anti-value’ of the item to choose the one to reject.</p><p>To anticipate our results, in the <italic>like</italic> frame condition we replicated the typical gaze-boosting effect: participants looked for longer at the item they were about to choose – the item they deemed most valuable. In the <italic>dislike</italic> frame, however, participants looked for longer at the item that they then chose to eliminate, that is, the <italic>least</italic> valuable item. This means that agents paid more attention to the option they selected in the task, <italic>not</italic> to the option to which they deemed more valuable or wanted to consume. This suggests that attention does <italic>not</italic> boost value but rather is used to gather task-relevant information.</p><p>In order to understand the mechanism via which attention interacts with value in both framings, we use a dynamic accumulation model, which allows us to account for the preference formation process and its dependency on task variables (values of the options). We also show how goal-relevance shapes confidence and how confidence interacts with attention.</p><p>To test the generality of our findings, we also conducted a new perceptual decision-making experiment and tested a new set of participants. In this perceptual task, participants were asked to choose between two circles filled with dots. In some blocks, they had to indicate the circle with more dots – <italic>most frame</italic>; in others, the circle with fewer dots – <italic>fewest frame</italic>. In this second study, we replicated all the effects of the first, value-based one, corroborating the hypothesis of a domain-general role for attention in modulating goal-relevant information that drives choice.</p><p>This work questions the dominant view in neuroeconomics about the relationship between attention and value, showing that attention does not boost value per se but instead modulates goal-relevant information. We conclude our work by presenting an economic model of optimal evidence accumulation. Using this model, we suggest that the behavioural strategy we observe in our experiment may be the result of deploying, in the context of binary choice, a behavioural strategy that is optimal when agents face more natural larger sets of options.</p></sec><sec id="s2" sec-type="results"><title>Results</title><p>In our first experiment, hungry participants (n = 31) made binary choices between snacks in one of two task-frames, <italic>like</italic> and <italic>dislike</italic>. In the <italic>like</italic> frame, participants had to report the item they would prefer to eat; in the <italic>dislike</italic> frame, they chose the item they wanted to avoid eating (<xref ref-type="fig" rid="fig1">Figure 1A</xref>). After each choice, participants reported their confidence in having made a good choice (<xref ref-type="bibr" rid="bib11">De Martino et al., 2013</xref>; <xref ref-type="bibr" rid="bib13">Folke et al., 2017</xref>). At the beginning of the experiment, participants reported the subjective value of individual items using a standard incentive-compatible Becker-DeGroot-Marschak mechanism (BDM; see Materials and methods).</p><fig id="fig1" position="float"><label>Figure 1.</label><caption><title>Task and behavioural results.</title><p>Value-based decision task (<bold>A</bold>). Participants choose between two food items presented in an eye-contingent way. Before the choice stage, participants reported the amount of money they were willing to bid to eat that snack. In the <italic>like</italic> frame (top) participants select the item they want to consume at the end of the experiment. In the <italic>dislike frame</italic> (bottom) participants choose the opposite, the item they would prefer to avoid. After each choice participants reported their level of confidence. (<bold>B</bold>) After a median split for choice confidence, a logistic regression was calculated for the probability of choosing the right-hand item depending on the difference in value (Value<sub>Right</sub>– Value<sub>Left</sub>) for <italic>like</italic> (top) and <italic>dislike</italic> (bottom) framing conditions. The logistic curve calculated from the high confidence trials is steeper, indicating an increase in accuracy. (<bold>C</bold>) Slope of logistic regressions predicting choice for each participant, depending on the frame. The shift in sign of the slope indicates that participants are correctly modifying their choices depending on the frame. Perceptual decision task (<bold>D</bold>) Participants have to choose between two circles containing dots, also presented eye-contingently. In the <italic>most</italic> frame (top), participants select the circle with more white dots. In the <italic>fewest</italic> frame (bottom), they choose the circle with the lower number of white dots. Distractor dots (orange) are included in both frames to increase the difficulty of the task. Confidence is reported at the end of each choice. We obtained a similar pattern of results to the one observed in the Value Experiments in terms of probability of choice (<bold>E</bold>) and the flip in the slope of the choice logistic model between <italic>most</italic> and <italic>fewest</italic> frames (<bold>F</bold>).</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-60705-fig1-v2.tif"/></fig><p>Our second experiment was done to test whether the results observed in value-based decisions could be generalised to perceptual decisions. A different group of participants (n = 32) made binary choices between two circles containing a variable number of dots (<xref ref-type="fig" rid="fig1">Figure 1D</xref>). In the <italic>most</italic> frame, participants reported the circle containing the higher number of dots; in the <italic>fewest</italic> frame, the one with the lower. As in the Value Experiment, at the end of each trial participants reported their confidence in their choice.</p><sec id="s2-1"><title>The effect of attention on choice</title><sec id="s2-1-1"><title>Value experiment</title><p>Our results confirmed that participants understood the task and chose higher value items in the <italic>like</italic> frame and lower value items in the <italic>dislike</italic> frame (<xref ref-type="fig" rid="fig1">Figure 1B,C</xref>). This effect was modulated by confidence (<xref ref-type="fig" rid="fig1">Figure 1B</xref>) similarly to previous studies (<xref ref-type="bibr" rid="bib11">De Martino et al., 2013</xref>; <xref ref-type="bibr" rid="bib13">Folke et al., 2017</xref>; <xref ref-type="bibr" rid="bib4">Boldt et al., 2019</xref>). For a direct comparison of the differences between the goal manipulations in the two tasks (Value and Perceptual) see Appendix 1 (<xref ref-type="fig" rid="app1fig1">Appendix 1—figure 1</xref>).</p><p>We then tested how attention interacts with choice by examining the eye-tracking variables. Our frame manipulation, which orthogonalised choice and valuation, allowed us to distinguish between two competing hypotheses. The first hypothesis, currently dominant in the field, is that visual attention is always attracted to high values items and that it facilitates their choice. The alternative hypothesis is that the attention is attracted to items whose value matches the goal of the task. These two hypotheses make starkly different experimental predictions in our task. According to the first, gaze will mostly be allocated to the more valuable item independently of the frame. The second hypothesis instead predicts that in the <italic>like</italic> frame participants will look more at the more valuable item, while this pattern would reverse in the <italic>dislike</italic> frame, with attention mostly allocated to the least valuable item. In other words, according to this second hypothesis, visual attention should predict choice (and the match between value and goal) and not value, independently of the frame manipulation.</p><p>Our data strongly supported the second hypothesis because we found participants preferentially gaze (<xref ref-type="fig" rid="fig2">Figure 2A</xref>) the higher value option during <italic>like</italic> (t(30) = 7.56, p&lt;0.001) and the lower value option during <italic>dislike</italic> frame (t(30) = -4.99, p&lt;0.001). From a hierarchical logistic regression analysis predicting choice (<xref ref-type="fig" rid="fig2">Figure 2B</xref>), the difference between the time participants spent observing the right over left item (ΔDT) was a positive predictor of choice both in <italic>like</italic> (<italic>z</italic> = 6.448, p&lt;0.001) and <italic>dislike</italic> (<italic>z</italic> = 6.750, p&lt;0.001) frames. This means that participants looked for longer at the item that better fits the frame and not at the item with the highest value. Notably, the magnitude of this effect was slightly lower in the <italic>dislike</italic> case (t(30) = 2.31, p&lt;0.05). In <xref ref-type="fig" rid="fig2">Figure 2B</xref> are also plotted the predictors of the other variables on choice from the best fitting model.</p><fig id="fig2" position="float"><label>Figure 2.</label><caption><title>Attention and choice in Value and Perceptual Experiments.</title><p>(<bold>A</bold>) Gaze allocation time depends on the frame: while visual fixations in the <italic>like</italic> frame go preferentially to the item with higher value (top), during the <italic>dislike</italic> frame participants look for longer at the item with lower value (bottom). Dots in the bar plot indicate participants’ average gaze time across trials for high and low value items. Time is expressed as the percentage of trial time spent looking at the item. Similar results were found for gaze distribution in the Perceptual Experiment (<bold>C</bold>) participants gaze the circle with higher number of dots in <italic>most</italic> frame and the circle with lower number of dots in <italic>fewest</italic> frame. Hierarchical logistic modelling of choice (probability of choosing right item) in Value (<bold>B</bold>) and Perceptual (<bold>D</bold>) Experiments, shows that participants looked for longer (ΔDT) at the item they chose in both frames. All predictors are z-scored at the participant level. In both regression plots, bars depict the fixed-effects and dots the mixed-effects of the regression. Error bars show the 95% confidence interval for the fixed effect. In Value Experiment: ΔValue: difference in value between the two items (<italic>Value<sub>Right</sub>– Value<sub>Left</sub></italic>); RT: reaction time; ΣValue: summed value of both items; ΔDT: difference in dwell time (DT<italic><sub>Right</sub>– DT<sub>Left</sub></italic>); Conf: confidence. In Perceptual Experiment: ΔDots: difference in dots between the two circles (<italic>Dots<sub>Right</sub>– Dots<sub>Left</sub></italic>); ΣDots: summed number of dots between both circles. ***p&lt;0.001, **p&lt;0.01, *p&lt;0.05.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-60705-fig2-v2.tif"/></fig></sec><sec id="s2-1-2"><title>Perceptual experiment</title><p>We then analysed the effect of attention on choice in the perceptual case to test the generality of our findings. As in the Value Experiment, our data confirmed that participants did not have issues in choosing the circle with more dots in the <italic>most</italic> frame and the one with least amount dots in the <italic>fewest</italic> frame (<xref ref-type="fig" rid="fig1">Figure 1D,F</xref>). Furthermore, as in the Value Experiment and many other previous findings (<xref ref-type="bibr" rid="bib11">De Martino et al., 2013</xref>; <xref ref-type="bibr" rid="bib13">Folke et al., 2017</xref>), confidence modulated the accuracy of their decisions (<xref ref-type="fig" rid="fig1">Figure 1E</xref>). Critically for our main hypothesis, we found that participants’ gaze was preferentially allocated to the relevant option in each frame (<xref ref-type="fig" rid="fig2">Figure 2C</xref>): they spent more time observing the circle with more dots during <italic>most</italic> frame (t(31)=13.85, p&lt;0.001) and the one with less dots during <italic>fewest</italic> frame (t(31)=-10.88, p&lt;0.001). ΔDT was a positive predictor of choice (<xref ref-type="fig" rid="fig2">Figure 2D</xref>) in <italic>most</italic> (z = 10.249, p&lt;0.001), and <italic>fewest</italic> (<italic>z</italic> = 10.449, p&lt;0.001) frames. Contrary to the results in the Value Experiment in which the effect of ΔDT on choice was slightly more marked in the <italic>like</italic> condition (<xref ref-type="fig" rid="fig2">Figure 2B</xref>), in the Perceptual Study the effect of ΔDT was the opposite: ΔDT had a higher effect in the <italic>fewest</italic> frame (ΔDT<sub>Most-Few</sub>: t(31)=-2.17, p&lt;0.05)(<xref ref-type="fig" rid="fig2">Figure 2D</xref>). However, and most importantly, in both studies ΔDT was a robust positive predictor of choice in both frame manipulations. To summarise, these results show that in the context of a simple perceptual task, visual attention also has a specific effect in modulating information processing in a goal-directed manner: subjects spend more time fixating the option they will select, not necessarily the option with the highest number of dots.</p><p>In both Value and Perceptual Experiments, the most parsimonious models were reported in the manuscript and in <xref ref-type="fig" rid="fig2">Figure 2B and D</xref>. For a full model comparison see <xref ref-type="fig" rid="app2fig1">Appendix 2—figure 1</xref> and <xref ref-type="table" rid="app2table1">Appendix 2—table 1</xref>. More details on the choice models are reported in the Appendix 2.</p></sec></sec><sec id="s2-2"><title>Fixations effects in choice</title><p>An important prediction of attentional accumulation models is that the chosen item is generally fixated last (unless that item is much worse than the other alternative), with the magnitude of this effect related to the difference in value between the alternatives. This feature of the decision has been consistently replicated in various previous studies (<xref ref-type="bibr" rid="bib30">Krajbich et al., 2010</xref>; <xref ref-type="bibr" rid="bib32">Krajbich and Rangel, 2011</xref>; <xref ref-type="bibr" rid="bib31">Krajbich et al., 2012</xref>). We therefore tested how the last fixation was modulated by the frame manipulation.</p><sec id="s2-2-1"><title>Value experiment</title><p>In the Value Experiment in both frames, we replicated the last fixation effect and its modulation by value difference between the last fixated option and the other one (<xref ref-type="fig" rid="fig3">Figure 3A</xref>). In the <italic>like</italic> frame, the probability of choosing the last item fixated upon increases when the value of the last item is higher, as is shown by the positive sign of the slope of the logistic curve (mean β<sub>Like</sub> = 0.922). Crucially, during the <italic>dislike</italic> frame the opposite effect was found: the probability of choosing the last seen option increases when the value of the non-chosen item is higher, seen from the negative slope of the curve (mean β<sub>Dislike</sub> = −0.951; Δβ<sub>Like-Dislike</sub>: t(30)=7.963, p&lt;0.001).</p><fig id="fig3" position="float"><label>Figure 3.</label><caption><title>Fixation effects on the chosen item.</title><p>Last fixation effects: (<bold>A</bold>) in the Value Experiment, a logistic regression was calculated for the probability the last fixation is on the chosen items (P(LastFix = Chosen)) depending on the difference in value of the item last fixated upon and the alternative item. As reported in previous studies, in <italic>like</italic> frame, we find it is more probable that the item last fixated upon will be chosen when the value of that item is relatively higher. In line with the hypothesis that goal-relevant evidence, and not value, is being integrated to make the decision, during the <italic>dislike</italic> frame the effect shows the opposite pattern: P(LastFix = Chosen) is higher when the value of the item last fixated on is lower, that is, the item fixated on is more relevant given the frame. (<bold>B</bold>) A similar analysis in the Perceptual Experiment mirrors the results in the Value Experiment with a flip in the effect between <italic>most</italic> and <italic>fewest</italic> frames. Lines represent the model predictions and dots are the data binned across all participants. ΔValue and ΔDots measures are z-scored at the participant level. Gaze preference in time: (<bold>C</bold>) Pearson correlation between gaze position and difference in value (ΔValue) was calculated for each time point during the first 2 s of the trials. In the Value Experiment, after an initial phase of random exploration, fixations are positively correlated with the high value item in <italic>like</italic> frame, while this effect is the opposite for <italic>dislike</italic> frame, that is, fixations are directed to the low value item. (<bold>D</bold>) In the Perceptual Experiment, a similar pattern of goal-relevant fixations emerges. Lines in both figures correspond to the time point correlation considering all trials and participants. Shaded area corresponds to the standard error. Black line indicates time points with statistically significant difference between frames, resulting from a permutation test (p-value&lt;0.01 for at least 6 time bins, 60 ms). Correction for multiple comparison was performed using FDR, α ≤ 0.01.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-60705-fig3-v2.tif"/></fig></sec><sec id="s2-2-2"><title>Perceptual experiment</title><p>We observed the same pattern of results that in the Value Experiment (<xref ref-type="fig" rid="fig3">Figure 3B</xref>). In the <italic>most</italic> frame, it was more probable that the last fixation was on the chosen item when the fixated circle had a higher number of dots (mean β<sub>Most</sub> = 1.581). In the <italic>fewest</italic> frame, the effect flipped: it was more likely that the last circle seen was chosen when it had fewer dots (mean β<sub>Few</sub> = −0.944; Δβ<sub>Most-Few</sub>: t(31)=3.727, p&lt;0.001).</p><p>The previous set of analysis shows that the last fixation is modulated by the difference in evidence according to the goal that the participant is set to achieve. However, since the last fixation is in general followed by the participant response, one could suspect that the goal-dependent modulation of attention (i.e. ΔDT) we identified in our choice regression analysis (<xref ref-type="fig" rid="fig2">Figure 2</xref>) is entirely driven by the final fixation. This would be problematic since one would have similar results to the one presented in <xref ref-type="fig" rid="fig2">Figure 2</xref> even if participants’ pattern of attention is not modulated by the goal (i.e. attention is directed in both frames to the most valuable item) or even if the pattern of fixation, before the last fixation, is random. To control for this possibility, we performed a series of further analyses:</p><p>First of all, we repeated the analysis presented in the previous section (hierarchical choice regression – <xref ref-type="fig" rid="fig2">Figure 2</xref>), removing the last two fixations when calculating the ΔDT. Note that we removed the last two fixations and not just the last one to avoid statistical artefacts (i.e. since the final fixation is mostly directed towards the chosen item there would be an increased probability that second to last fixation is on the unchosen item). In <xref ref-type="fig" rid="app2fig3">Appendix 2—figure 3</xref>, we show that once removed the last two fixations the pattern of results is unchanged.</p><p>Second, we specifically investigated the middle fixations. Previous studies (<xref ref-type="bibr" rid="bib30">Krajbich et al., 2010</xref>; <xref ref-type="bibr" rid="bib32">Krajbich and Rangel, 2011</xref>; <xref ref-type="bibr" rid="bib44">Tavares et al., 2017</xref>) have reported that middle fixations duration increases when the difference in value ratings (or perceptual evidence) of the fixated minus unfixated item increases. We replicated this result for our <italic>like</italic> and <italic>most</italic> frames but critically the effect was reversed in <italic>dislike</italic> and <italic>fewest</italic> frames (i.e. middle fixations durations decreased when the relative value of the fixated item was higher). The results suggesting that the goal-relevant modulation of attention affects also the middle fixations are presented in the <xref ref-type="fig" rid="app3fig4">Appendix 3—figure 4</xref>.</p><p>Finally, we investigated in more detail how the relation between attentional allocation and difference in value or perceptual evidence changed over time in the context of the goal manipulation. We calculated the Pearson correlation between fixation position (0: left, 1:right) and the difference in evidence (i.e. ΔValue or ΔDots, in both cases right – left item) at different time points (<xref ref-type="fig" rid="fig3">Figure 3C</xref>). We observed that after an initial phase in which there was no clear gaze preference for any of the items (note that given the gaze-contingent design participants must explore both alternatives), fixations were correlated with the frame-relevant item: during <italic>like</italic> frame, fixations positions were positively correlated with ΔValue, that is the fixations were directed towards the item with higher value; during <italic>dislike</italic> frame the behaviour was the opposite: fixations were negatively correlated with ΔValue, indicating a preference for the option with lower value. Note that these results are in line with the ones reported by <xref ref-type="bibr" rid="bib29">Kovach et al., 2014</xref>. We see a very similar pattern of results in the Perceptual Experiment too (<xref ref-type="fig" rid="fig3">Figure 3D</xref>).</p></sec></sec><sec id="s2-3"><title>Which factors determine confidence?</title><sec id="s2-3-1"><title>Value experiment</title><p>To explore the effect that behavioural factors had over confidence, we fitted a hierarchical linear model (<xref ref-type="fig" rid="fig4">Figure 4A</xref>). As it was the case for the results presented above for the choice regression, the results for the confidence regression in the <italic>like</italic> frame replicated all the effects reported in a previous study from our lab (<xref ref-type="bibr" rid="bib13">Folke et al., 2017</xref>). Again, we presented here the most parsimonious model (<xref ref-type="fig" rid="app4fig1">Appendix 4—figure 1</xref> and <xref ref-type="table" rid="app4table1">Appendix 4—table 1</xref> for model comparison). We found that the magnitude of ΔValue (|ΔValue|) had a positive influence on confidence in <italic>like (z</italic> = 5.465, p&lt;0.001) and <italic>dislike</italic> (<italic>z</italic> = 6.300, p&lt;0.001) frames, indicating that participants reported higher confidence when the items have a larger difference in value; this effect was larger in the <italic>dislike</italic> frame (t(30) = -4.72, p&lt;0.01). Reaction time (RT) had a negative effect on confidence in <italic>like</italic> (<italic>z</italic> = −6.373, p&lt;0.001) and <italic>dislike</italic> (<italic>z</italic> = −7.739, p&lt;0.001) frames, that is, confidence was lower when the RTs were longer. Additionally, we found that, in both conditions, higher number of gaze switches (i.e. gaze shift frequency, GSF) predicted lower values of confidence in <italic>like</italic> (<italic>z</italic> = −2.365, p&lt;0.05) and <italic>dislike</italic> (<italic>z</italic> = −2.589, p&lt;0.05) frames, as reported in <xref ref-type="bibr" rid="bib13">Folke et al., 2017</xref>.</p><fig id="fig4" position="float"><label>Figure 4.</label><caption><title>Hierarchical linear regression model to predict confidence.</title><p>(<bold>A</bold>) In Value Experiment, a flip in the effect of ΣValue over confidence in the <italic>dislike</italic> frame was found. (<bold>B</bold>) In Perceptual Experiment, a similar pattern was found in the effect of ΣDots over confidence in the <italic>fewest</italic> frame. The effect of the other predictors on confidence in both experiments and frames coincides with previous reports (<xref ref-type="bibr" rid="bib13">Folke et al., 2017</xref>). All predictors are z-scored at the participant level. In both regression plots, bars depict the fixed-effects and dots the mixed-effects of the regression. Error bars show the 95% confidence interval for the fixed effect. In Value Experiment: ΔValue: difference in value between the two items (<italic>Value<sub>right</sub>– Value<sub>left</sub></italic>); RT: reaction time; ΣValue: summed value of both items; ΔDT: difference in dwell time (DT<sub>right</sub><italic>– DT<sub>left</sub></italic>); GSF: gaze shift frequency; ΔDT: difference in dwell time. In Perceptual Experiment: ΔDots: difference in dots between the two circles (<italic>Dots<sub>right</sub>– Dots<sub>left</sub></italic>); ΣDots: summed number of dots between both circles. ***p&lt;0.001, **p&lt;0.01, *p&lt;0.05.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-60705-fig4-v2.tif"/></fig><p>We then looked at the effect of the summed value of both options, ΣValue, on confidence. As in <xref ref-type="bibr" rid="bib13">Folke et al., 2017</xref>, we found a positive effect of ΣValue on confidence in the <italic>like</italic> frame (<italic>z</italic> = 3.206, p&lt;0.01); that is, participants reported a higher confidence level when both options were high in value. Interestingly, this effect was inverted in the <italic>dislike</italic> frame (<italic>z</italic> = −4.492, p&lt;0.001), with a significant difference between the two frames (t(30)=9.91, p&lt;0.001) This means that, contrary to what happened in the <italic>like</italic> frame in which confidence was boosted when both items had high value, in the <italic>dislike</italic> frame confidence increased when both items had <italic>low</italic> value. This novel finding reveals that the change in context also generates a reassessment of the evidence used to generate the confidence reports; that is, confidence also tracks goal-relevant information.</p></sec><sec id="s2-3-2"><title>Perceptual experiment</title><p>We repeated the same regression analysis in the perceptual decision experiment, replacing value evidence input with perceptual evidence (i.e. absolute difference in the number of dots, |ΔDots|). We directly replicated all the results of the Value Experiment, generalising the effects we isolated to the perceptual realm (<xref ref-type="fig" rid="fig4">Figure 4B</xref>). Specifically, we found that |ΔDots| had a positive influence on confidence in <italic>most</italic> (<italic>z</italic> = 3.546, p&lt;0.001) and <italic>fewest</italic> frames (<italic>z</italic> = 7.571, p&lt;0.001), indicating that participants reported higher confidence when the evidence was stronger. The effect of absolute evidence |ΔDots| on confidence was bigger in the <italic>fewest</italic> frame (t(31)=-4.716, p&lt;0.001). RT had a negative effect over confidence in <italic>most</italic> (<italic>z</italic> = −7.599, p&lt;0.001) and <italic>fewest</italic> frames (<italic>z</italic> = −5.51, p&lt;0.001), that is, faster trials were associated with higher confidence. We also found that GSF predicted lower values of confidence in <italic>most</italic> (<italic>z</italic> = −4.354, p&lt;0.001) and <italic>fewest</italic> (<italic>z</italic> = −5.204, p&lt;0.001) frames. Critically (like in the Value Experiment), the effect of the sum of evidence (ΣDots) on confidence also changes sign depending on the frame. While ΣDots had a positive effect over confidence in the <italic>most</italic> frame (z = 2.061, p&lt;0.05), this effect is the opposite in the <italic>fewest</italic> frame (<italic>z</italic> = −7.135, p&lt;0.001), with a significant difference between the parameters in both frames (t(31)=14.621, p&lt;0.001). The magnitude of ΣDots effect was stronger in the <italic>fewest</italic> frame (t(31)=-10.438, p&lt;0.001). For further details on the confidence models see the Appendix 4 (Appendix 4—table 2 and Appendix 4 —table 3).</p></sec></sec><sec id="s2-4"><title>Attentional model: GLAM</title><p>To gain further insights into the dynamic of the information accumulation process, we modelled the data from both experiments adapting a Gaze-weighted Linear Accumulator Model (GLAM) recently developed by <xref ref-type="bibr" rid="bib45">Thomas et al., 2019</xref>. The GLAM belongs to the family of race models and approximates the aDDM model (<xref ref-type="bibr" rid="bib30">Krajbich et al., 2010</xref>; <xref ref-type="bibr" rid="bib32">Krajbich and Rangel, 2011</xref>) in which the dynamic aspect is discarded, favouring a more efficient estimation of the parameters. This model was chosen since, unlike the aDDM, it allowed us to test the prediction of the confidence measures as balance of evidence (<xref ref-type="bibr" rid="bib48">Vickers, 1979</xref>; <xref ref-type="bibr" rid="bib28">Kepecs et al., 2008</xref>; <xref ref-type="bibr" rid="bib11">De Martino et al., 2013</xref>). Crucially, in both experiments, we used goal-relevant evidence (not the value or the number of dots) to fit the models in the <italic>dislike</italic> and <italic>fewest</italic> frames (for further details see the Materials and methods <italic>Attentional Model: Glam</italic> section).</p><sec id="s2-4-1"><title>Parameter fit and simulation</title><sec id="s2-4-1-1"><title>Value experiment</title><p>The simulations estimated with the parameters fitted for <italic>like</italic> and <italic>dislike</italic> frames data (even-trials) reproduced the behaviour observed in the data not used to fit the model (odd-trials). In both <italic>like</italic> and <italic>dislike</italic> frames, the model replicated the observed decrease of RT when |ΔValue| is high, that is, the increase in speed of response in easier trials (bigger value difference). The RT simulated by the models significantly correlated with the RT values observed in participants odd-numbered trials (<italic>Like</italic>: r(29)=0.90, p&lt;0.001; <italic>Dislike</italic>: r(29)=0.89, p&lt;0.001) (<xref ref-type="fig" rid="fig5">Figure 5A</xref>). In the <italic>like</italic> frame, the model also correctly predicted a higher probability of choosing the right item when ΔValue is higher. In the <italic>dislike</italic> frame, the model captured the change in the task goal and predicted that the selection of the right item will occur when -ΔValue is higher, that is when the value of the left item is higher. Overall, in both frames the observed and predicted probabilities of choosing the most valuable item were significantly correlated (<italic>Like</italic>: r(29)=0.80, p&lt;0.001; <italic>Dislike</italic>: r(29)=0.79, p&lt;0.001) (<xref ref-type="fig" rid="fig5">Figure 5B</xref>). See <xref ref-type="fig" rid="app5fig4">Appendix 5—figure 4A</xref> and <xref ref-type="fig" rid="app5fig5">Appendix 5—figure 5A</xref> for further details.</p><fig id="fig5" position="float"><label>Figure 5.</label><caption><title>Individual out-of-sample GLAM predictions for behavioural measures in Value (<bold>A-C</bold>) and Perceptual Experiments (<bold>D–F</bold>).</title><p>In value-based decision, (<bold>A</bold>) the model predicts individuals mean RT; (<bold>B</bold>) the probability of choosing the item with higher value in <italic>like</italic> frame, and the item with lower value in <italic>dislike</italic> frame; and (<bold>C</bold>) the influence of gaze in choice probability. In the Perceptual Experiment, (<bold>D</bold>) the model also predicts RT and (<bold>F</bold>) gaze influence. (<bold>E</bold>) The model significantly predicts the probability of choosing the best alternative in the <italic>fewest</italic> frame only (in the <italic>most</italic> frame a trend was found). The results corresponding to the models fitted with <italic>like/most</italic> frame data are presented in blue, and with <italic>dislike/fewest</italic> frame data in red. Dots depict the average of observed and predicted measures for each participant. Lines depict the slope of the correlation between observations and the predictions. Mean 95% confidence intervals are represented by the shadowed region in blue or red, with full colour representing Value Experiment and striped colour Perceptual Experiment. All model predictions are simulated using parameters estimated from individual fits for even-numbered trials.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-60705-fig5-v2.tif"/></fig><p>In both frames, the models also predicted choice depending on the difference in gaze (ΔGaze = g<sub>right</sub> – g<sub>left</sub>), that is, that the probability of choosing the right item increases when the time spent observing that item is higher. However, in this case, we cannot say if gaze allocation itself is predicting choice if we do not account for the effect of |ΔValue|. To account for the relationship between choice and gaze, we used a measure devised by <xref ref-type="bibr" rid="bib45">Thomas et al., 2019</xref>, ‘gaze influence’. Gaze influence is calculated taking the actual choice (1 or 0 for right or left choice, respectively) and subtracting the probability of choosing the right item given by a logistic regression for ΔValue calculated from actual behaviour. The averaged ‘residual’ choice probability indicates the existence of a positive or negative gaze advantage. Then, we compared the gaze influence predicted by GLAM with the empirical one observed for each participant. As in <xref ref-type="bibr" rid="bib45">Thomas et al., 2019</xref>, most of the participants had a positive gaze influence and it was properly predicted by the model in both frames (Like: r(29)=0.68, p&lt;0.001; <italic>Dislike</italic>: r(29)=0.63, p&lt;0.001) (<xref ref-type="fig" rid="fig5">Figure 5C</xref>).</p></sec><sec id="s2-4-1-2"><title>Perceptual experiment</title><p>As in the Value Experiment, we fitted the GLAM to the data and we conducted model simulations. Again, these simulations showed that we could recover most of the behavioural patterns observed in participants. We replicated the relationship between RT and |ΔDots| (<italic>Most</italic>: r(26)=0.97, p&lt;0.001; <italic>Fewest</italic>: r(26)=0.98, p&lt;0.001) (<xref ref-type="fig" rid="fig5">Figure 5D</xref>). As in the value-based experiment, the model also predicted a higher probability of choosing the right-hand item when ΔDots is higher in the <italic>most</italic> frame and when -ΔDots is higher in the <italic>fewest</italic> frame. However, in the Perceptual Experiment, the simulated choices only in the <italic>fewest</italic> frame were significantly correlated with the observed data, although we observed a non-significant trend in the <italic>most</italic> frame (<italic>Most</italic>: r(26)=0.69, p&lt;0.001; <italic>Fewest</italic>: r(26)=0.37, p=0.051) (<xref ref-type="fig" rid="fig5">Figure 5E</xref>). In both frames, we observed that the model predicted that choice was linked to ΔGaze and, as in the Value Experiment, we show that the gaze influence predicted by the model is indeed observed in the data (<italic>Most</italic>: r(26)=0.65, p&lt;0.001; <italic>Fewest</italic>: r(26)=0.47, p&lt;0.05) (<xref ref-type="fig" rid="fig5">Figure 5F</xref>). See <xref ref-type="fig" rid="app5fig4">Appendix 5—figure 4B</xref> and <xref ref-type="fig" rid="app5fig5">Appendix 5—figure 5B</xref> for further details.</p><p>Results of the models fitted without accounting for the change in goal-relevant evidence provided a poor fit of the data, these results are presented in <xref ref-type="fig" rid="app5fig1">Appendix 5—figures 1</xref>–<xref ref-type="fig" rid="app5fig3">3</xref> and <xref ref-type="fig" rid="app5fig6">6</xref>. For a direct comparison of the different GLAM parameters see Appendix 6. Additionally, we were able to mirror the results obtained with GLAM using aDDM (<xref ref-type="bibr" rid="bib30">Krajbich et al., 2010</xref>; <xref ref-type="bibr" rid="bib44">Tavares et al., 2017</xref>). For <italic>dislike</italic> and <italic>fewest</italic> frames, the best model was the one fitted using goal-relevant evidence (see Appendix 7 for details).</p></sec></sec><sec id="s2-4-2"><title>Balance of evidence and confidence</title><p>The GLAM belongs to the family of race models in which evidence is independently accumulated for each option. Therefore, using the GLAM we were able to adapt the model to estimate a measure of confidence in the decision that is defined by the balance of evidence (<xref ref-type="bibr" rid="bib48">Vickers, 1979</xref>; <xref ref-type="bibr" rid="bib47">Vickers, 1970</xref>; <xref ref-type="bibr" rid="bib28">Kepecs et al., 2008</xref>; <xref ref-type="bibr" rid="bib11">De Martino et al., 2013</xref>) allowing us to characterise the pattern of the confidence measures. Balance of evidence is defined as the absolute difference between the accumulators for each option at the moment of choice, which is when one of them reaches the decision threshold (i.e., Δe = |E<sub>right</sub>(t<sub>final</sub>) - E<sub>left</sub>(t<sub>final</sub>)|) (<xref ref-type="fig" rid="fig6">Figure 6A</xref>). To estimate Δe, we performed a large number of computer simulations using the fitted parameters for each participant in both experiments.</p><fig id="fig6" position="float"><label>Figure 6.</label><caption><title>Balance of evidence (Δe) simulated with GLAM reproduces ΣValue and ΣDots effects over confidence.</title><p>(<bold>A</bold>) GLAM is a linear stochastic race model in which two alternatives accumulate evidence until a threshold is reached by one of them. Δe has been proposed as a proxy for confidence and it captures the difference in evidence available in both accumulators once the choice for that trial has been made. (<bold>B</bold>) Using Δe simulations, we captured the flip of the effect of ΣValue over confidence between <italic>like</italic> and <italic>dislike</italic> frames. Δe simulations were calculated using the model with parameters fitted for each individual participant. A pooled linear regression model was estimated to predict Δe. The effects of ΣValue predicting Δe are presented labelled as ’Model Sim’. A second set of simulations was generated using a model in which no asymmetries in gaze allocation were considered (i.e. no attentional biases). This second model was not capable of recovering ΣValue effect on Δe and is labelled as ’Model Sim No Bias’. ΣValue coefficients for a similar model using participants’ data predicting confidence are also presented labelled as ‘Human’ for comparison. (<bold>C</bold>) A similar pattern of results is found in the Perceptual Experiment, with the model including gaze bias being capable of recovering ΣDots effect on Δe. This novel effect may suggests that goal-relevant information is also influencing the generation of second-order processes, as confidence. This effect may be originated by the attentional modulation of the accumulation dynamics. Coloured bars show the parameter values for ΣValue and ΣDots and the error bars depict the standard error. Solid colour indicates the Value Experiment and striped colours indicate the Perceptual Experiment. All predictors are z-scored at participants level.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-60705-fig6-v2.tif"/></fig><sec id="s2-4-2-1"><title>Value experiment</title><p>To confirm that the relationship between confidence and other experimental variables was captured by the balance of evidence simulations, we constructed a linear regression model predicting Δe as function of the values and the RTs obtained in the simulations (Δe ∼ |ΔValue| + simulated RT + ΣValue). We found that this model replicated the pattern of results we obtained experimentally (<xref ref-type="fig" rid="fig4">Figure 4</xref>). We then explored whether the model was able to recover the effect of ΣValue on confidence (<xref ref-type="fig" rid="fig6">Figure 6B</xref>). As we have shown when analysing confidence, ΣValue boosted Δe in the <italic>like</italic> frame (β<sub>ΣValue</sub> = 0.071, t(37196) = 14.21, p&lt;0.001) and reduced Δe in the <italic>dislike</italic> frame (β<sub>ΣValue</sub> = −0.061, t(37196) = −12.07, p&lt;0.001). The effect of ΣValue over confidence was replicated in the simulations with an increase of Δe when high value options are available to choose (<xref ref-type="fig" rid="app8fig1">Appendix 8—figure 1</xref> and <xref ref-type="fig" rid="app8fig3">Appendix 8—figure 3A,D</xref> for more details). In the <italic>dislike</italic> frame, the fitted model also replicated this pattern of behaviour, including the adaptation to context which predicts higher Δe when both alternatives have low value. Interestingly, the replication of the effect for ΣValue over Δe with GLAM did not hold when the gaze bias was taken out of the model in <italic>like</italic> (β<sub>ΣValue</sub> = −0.007, t(37196) = −1.495, p=0.13, ns) and <italic>dislike</italic> (β<sub>ΣValue</sub> = −0.002, t(37196) = −0.413, p=0.679, ns) frames (<xref ref-type="fig" rid="fig6">Figure 6B</xref>). We also found that the effect of |ΔValue| on confidence was replicated by the simulated balance of evidence, increasing Δe when the difference between item values is higher (i.e. participants and the model simulations are more ‘confident’ when |ΔValue| is higher) (<xref ref-type="fig" rid="app8fig1">Appendix 8—figure 1</xref>).</p></sec><sec id="s2-4-2-2"><title>Perceptual experiment</title><p>We conducted a set of similar analyses and model simulations in the Value Experiment (<xref ref-type="fig" rid="fig6">Figure 6C</xref>). We found that ΣDots boosted Δe in the <italic>most</italic> frame (<italic>Most</italic> : β<sub>ΣDots</sub> = 0.029, t(33596) = 4.71, p&lt;0.001) and reduced Δe in the <italic>fewest</italic> frame (<italic>Fewest</italic> : β<sub>ΣDots</sub> = −0.088, t(33596) = −14.41, p&lt;0.001) . As in the Value Experiment, this effect disappeared when the gaze bias was taken out of the model (<italic>Most</italic>: β<sub>ΣDots</sub> = −0.0002, t(33596) = −0.04, p=0.96, ns; <italic>Fewest</italic>: β<sub>ΣDots</sub> = −0.006, t(33596) = −1.03, p=0.29, ns) (see <xref ref-type="fig" rid="app8fig2">Appendix 8—figure 2</xref> and <xref ref-type="fig" rid="app8fig3">Appendix 8—figure 3B,E</xref> for more details).</p><p>Overall, these results show how the model is capable of capturing the novel empirical effect on confidence we identified experimentally, giving computational support to the hypothesis that goal-relevant evidence is fed to second order processes like confidence. It also hints at a potential origin to the effects of the sum of evidence (i.e. ΣValue, ΣDots) on confidence: asymmetries in the accumulation process, in particular the multiplicative effect of attention over accumulation of evidence, may enhance the differences between items that are more relevant for the frame. This consequentially boosts the level of confidence that participants have in their decisions.</p></sec></sec></sec><sec id="s2-5"><title>A model of optimal information acquisition</title><p>We then sought to understand why participants systematically accumulated evidence depending on the task at hand, instead of first integrating evidence using a task-independent strategy and then emitting a response appropriate with the task. We reasoned that this may reflect a response in line with models of rational information acquisition popular in economics. These include models of so-called rational inattention, according to which agents are rationally choosing which information to acquire considering the task, the incentives, and the cost of acquiring and processing information (<xref ref-type="bibr" rid="bib39">Sims, 2003</xref>; <xref ref-type="bibr" rid="bib40">Sims, 2010</xref>; <xref ref-type="bibr" rid="bib7">Caplin and Dean, 2015</xref>; <xref ref-type="bibr" rid="bib24">Hébert and Woodford, 2017</xref>). As opposed to DDM or GLAM, these models attempt to investigate not only what the consequences of information acquisition are, but also <italic>which</italic> information is acquired.</p><p>In this model, we consider an agent facing <italic>n</italic> available options. Each item <italic>i</italic> has value <italic>v</italic><sub><italic>i</italic></sub> to the agent, which is unknown, and agents have a prior such that values follow an independent, identical distribution; for simplicity, we assume it to be a Normal <inline-formula><mml:math id="inf1"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>v</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>∼</mml:mo><mml:mi>N</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>μ</mml:mi><mml:mo>,</mml:mo><mml:msubsup><mml:mi>σ</mml:mi><mml:mrow><mml:mi>μ</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mstyle></mml:math></inline-formula>. Agents can acquire information in the form of signals <inline-formula><mml:math id="inf2"><mml:mrow><mml:msub><mml:mi>x</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mrow><mml:msub><mml:mi>v</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mi>ϵ</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:mrow></mml:math></inline-formula>, with <inline-formula><mml:math id="inf3"><mml:mpadded width="+5pt"><mml:msub><mml:mi>ϵ</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mpadded></mml:math></inline-formula> independently and identically distributed with <inline-formula><mml:math id="inf4"><mml:mrow><mml:msub><mml:mi>ϵ</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>∼</mml:mo><mml:mrow><mml:mi>N</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mn>0</mml:mn><mml:mo rspace="7.5pt">,</mml:mo><mml:msubsup><mml:mi>σ</mml:mi><mml:mi>ϵ</mml:mi><mml:mn>2</mml:mn></mml:msubsup><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:math></inline-formula>. They follow Bayes’ rule in updating their beliefs after information. Once they finish acquiring information, they then choose the item with the highest expected value.</p><p>Consider first the case in which an agent needs to pick the best item out of <italic>n</italic> possible ones. Suppose that she already received one signal for each item. Denote <italic>i</italic><sub>1</sub> the item for which the agent received the highest signal, which is also the item with the highest expected value; <italic>i</italic><sub>2</sub> the second highest, etc. (Because each of these is almost surely unique, let us for simplicity assume they are indeed unique). The agent can acquire one additional signal about any of the available items or select any probability distribution over signals. The following proposition shows that it is (weakly) optimal for the agent to acquire a second signal about the item that is currently best, that is, <italic>i</italic><sub>1</sub>.</p><p>Denote Δ the set of all probability distributions over signals and <inline-formula><mml:math id="inf5"><mml:mrow><mml:mi>V</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mi>i</mml:mi><mml:mo rspace="7.5pt">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> the utility after acquiring a new signal <inline-formula><mml:math id="inf6"><mml:msub><mml:mi>x</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mn>2</mml:mn></mml:mrow></mml:msub></mml:math></inline-formula> about item <italic>i</italic>, that is,<disp-formula id="equ1"><label>(1)</label><mml:math id="m1"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>V</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>i</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>:=</mml:mo><mml:munder><mml:mo form="prefix" movablelimits="true">max</mml:mo><mml:mrow><mml:mi>j</mml:mi><mml:mo>∈</mml:mo><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mo>…</mml:mo><mml:mo>,</mml:mo><mml:mi>n</mml:mi></mml:mrow></mml:munder><mml:mrow><mml:mi mathvariant="double-struck">E</mml:mi></mml:mrow><mml:mo stretchy="false">[</mml:mo><mml:msub><mml:mi>v</mml:mi><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:msub><mml:mi>x</mml:mi><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:mo>.</mml:mo><mml:mo>.</mml:mo><mml:mo>.</mml:mo><mml:mo>,</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mrow><mml:mi>N</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mtext> </mml:mtext><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:mo stretchy="false">]</mml:mo></mml:mrow></mml:mstyle></mml:math></disp-formula></p><p><bold>Proposition 1.</bold> <italic>The optimal strategy when choosing the best option is to acquire one more signal about item i</italic><sub>1</sub> <italic>or i</italic><sub>2</sub><italic>, that is, either the item with the currently highest expected value or the one with second highest value. That is:</italic><disp-formula id="equ2"><label>(2)</label><mml:math id="m2"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mtable columnalign="left left" columnspacing="1em" rowspacing="4pt"><mml:mtr><mml:mtd><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi mathvariant="double-struck">E</mml:mi></mml:mrow><mml:mo stretchy="false">[</mml:mo><mml:mi>V</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>i</mml:mi><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:mo stretchy="false">]</mml:mo><mml:mo>=</mml:mo><mml:mrow><mml:mi mathvariant="double-struck">E</mml:mi></mml:mrow><mml:mo stretchy="false">[</mml:mo><mml:mi>V</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>i</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:mo stretchy="false">]</mml:mo><mml:mo>≥</mml:mo><mml:munder><mml:mo form="prefix" movablelimits="true">max</mml:mo><mml:mrow><mml:mi>p</mml:mi><mml:mo>∈</mml:mo><mml:mi mathvariant="normal">Δ</mml:mi></mml:mrow></mml:munder><mml:mstyle displaystyle="true" scriptlevel="0"><mml:munderover><mml:mo>∑</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>n</mml:mi></mml:mrow></mml:munderover><mml:mi>p</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>i</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mi>V</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>i</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mstyle></mml:mstyle></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi mathvariant="normal">a</mml:mi><mml:mi mathvariant="normal">n</mml:mi><mml:mi mathvariant="normal">d</mml:mi></mml:mrow><mml:mtext> </mml:mtext><mml:mrow><mml:mi mathvariant="double-struck">E</mml:mi></mml:mrow><mml:mo stretchy="false">[</mml:mo><mml:mi>V</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>i</mml:mi><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:mo stretchy="false">]</mml:mo><mml:mo>&gt;</mml:mo><mml:mrow><mml:mi mathvariant="double-struck">E</mml:mi></mml:mrow><mml:mo stretchy="false">[</mml:mo><mml:mi>V</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>i</mml:mi><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:mo stretchy="false">]</mml:mo><mml:mstyle displaystyle="false" scriptlevel="0"/><mml:mspace width="1em"/><mml:mi mathvariant="normal">∀</mml:mi><mml:mi>j</mml:mi><mml:mo>≠</mml:mo><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mn>2</mml:mn></mml:mstyle></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:mstyle></mml:math></disp-formula></p><p>This proposition shows that agents have <italic>asymmetric</italic> optimal sampling strategies: they are not indifferent between which item to sample, but rather want to acquire extra signals about items that current look best or second-best. (They are indifferent between the latter two). When <inline-formula><mml:math id="inf7"><mml:mrow><mml:mrow><mml:mi>n</mml:mi><mml:mo>&gt;</mml:mo><mml:mn>2</mml:mn></mml:mrow><mml:mo>,</mml:mo></mml:mrow></mml:math></inline-formula> these strategies are strictly better than acquiring signals about any other item.</p><p>How would this change if agents need instead to pick which item to eliminate, assuming that she gets the average utility of the items she keeps? In this case, the expected utility after acquiring a new signal <inline-formula><mml:math id="inf8"><mml:msub><mml:mi>x</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mn>2</mml:mn></mml:mrow></mml:msub></mml:math></inline-formula> about item <italic>i</italic> is:<disp-formula id="equ3"><label>(3)</label><mml:math id="m3"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mrow><mml:mover><mml:mi>V</mml:mi><mml:mo>^</mml:mo></mml:mover></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>i</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>:=</mml:mo><mml:munder><mml:mo form="prefix" movablelimits="true">max</mml:mo><mml:mrow><mml:mi>j</mml:mi><mml:mo>∈</mml:mo><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mo>…</mml:mo><mml:mo>,</mml:mo><mml:mi>n</mml:mi></mml:mrow></mml:munder><mml:mrow><mml:mi mathvariant="double-struck">E</mml:mi></mml:mrow><mml:mrow><mml:mo>[</mml:mo><mml:mrow><mml:mfrac><mml:mrow><mml:munder><mml:mo>∑</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>≠</mml:mo><mml:mi>j</mml:mi></mml:mrow></mml:munder><mml:msub><mml:mi>v</mml:mi><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:mi>n</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:mfrac><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:msub><mml:mi>x</mml:mi><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:mo>.</mml:mo><mml:mo>.</mml:mo><mml:mo>.</mml:mo><mml:mo>,</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mrow><mml:mi>N</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mn>2</mml:mn></mml:mrow></mml:msub></mml:mrow><mml:mo>]</mml:mo></mml:mrow><mml:mo>.</mml:mo></mml:mrow></mml:mstyle></mml:math></disp-formula></p><p>Then, it is optimal to receive an additional signal about the <italic>least</italic> valuable item <italic>i</italic><sub><italic>n</italic></sub> or the next one, <inline-formula><mml:math id="inf9"><mml:mrow><mml:msub><mml:mi>i</mml:mi><mml:mrow><mml:mi>n</mml:mi><mml:mo>-</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>.</mml:mo></mml:mrow></mml:math></inline-formula></p><p><bold>Proposition 2.</bold> <italic>The optimal strategy when choosing which item to discard is to acquire one more signal about item i</italic><sub><italic>n</italic></sub> <italic>or </italic><inline-formula><mml:math id="inf10"><mml:msub><mml:mi>i</mml:mi><mml:mrow><mml:mi>n</mml:mi><mml:mo>-</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:math></inline-formula><italic>, that is, either the one with the lowest or the one with the second lowest value. That is:</italic><disp-formula id="equ4"><label>(4)</label><mml:math id="m4"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mtable columnalign="left left" columnspacing="1em" rowspacing="4pt"><mml:mtr><mml:mtd><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi mathvariant="double-struck">E</mml:mi></mml:mrow><mml:mrow><mml:mo>[</mml:mo><mml:mrow><mml:mrow><mml:mover><mml:mi>V</mml:mi><mml:mo>^</mml:mo></mml:mover></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>i</mml:mi><mml:mrow><mml:mi>n</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>]</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mrow><mml:mi mathvariant="double-struck">E</mml:mi></mml:mrow><mml:mrow><mml:mo>[</mml:mo><mml:mrow><mml:mrow><mml:mover><mml:mi>V</mml:mi><mml:mo>^</mml:mo></mml:mover></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>i</mml:mi><mml:mrow><mml:mi>n</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>]</mml:mo></mml:mrow><mml:mo>≥</mml:mo><mml:munder><mml:mo form="prefix" movablelimits="true">max</mml:mo><mml:mrow><mml:mi>p</mml:mi><mml:mo>∈</mml:mo><mml:mi mathvariant="normal">Δ</mml:mi></mml:mrow></mml:munder><mml:mstyle displaystyle="true" scriptlevel="0"><mml:munderover><mml:mo>∑</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>n</mml:mi></mml:mrow></mml:munderover><mml:mi>p</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>i</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mrow><mml:mover><mml:mi>V</mml:mi><mml:mo>^</mml:mo></mml:mover></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>i</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mstyle></mml:mstyle></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi mathvariant="normal">a</mml:mi><mml:mi mathvariant="normal">n</mml:mi><mml:mi mathvariant="normal">d</mml:mi></mml:mrow><mml:mtext> </mml:mtext><mml:mrow><mml:mi mathvariant="double-struck">E</mml:mi></mml:mrow><mml:mrow><mml:mo>[</mml:mo><mml:mrow><mml:mrow><mml:mover><mml:mi>V</mml:mi><mml:mo>^</mml:mo></mml:mover></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>i</mml:mi><mml:mrow><mml:mi>n</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>]</mml:mo></mml:mrow><mml:mo>&gt;</mml:mo><mml:mrow><mml:mi mathvariant="double-struck">E</mml:mi></mml:mrow><mml:mrow><mml:mo>[</mml:mo><mml:mrow><mml:mrow><mml:mover><mml:mi>V</mml:mi><mml:mo>^</mml:mo></mml:mover></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>i</mml:mi><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>]</mml:mo></mml:mrow><mml:mstyle displaystyle="false" scriptlevel="0"/><mml:mspace width="1em"/><mml:mi mathvariant="normal">∀</mml:mi><mml:mi>j</mml:mi><mml:mo>≠</mml:mo><mml:mi>n</mml:mi><mml:mo>,</mml:mo><mml:mi>n</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mstyle></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:mstyle></mml:math></disp-formula></p><p>For a proof of both propositions, see Appendix 9.</p><p>Again, agents have <italic>asymmetric</italic> optimal sampling strategies: but now, they want to sample the items that currently look <italic>worse</italic> again. The intuition behind both results is that when one has to choose the best item, it is more useful to acquire information that is likely to change the ranking at the top (i.e. between best or second best item) than information that changes the ranking at the bottom, since these items won’t be selected (e.g. 4th and 5th item). Crucially, the reverse is true when one is tasked to select which item to eliminate.</p><p>This shows how in these simple tasks it is strictly more advantageous to acquire information in line with the current goal rather than adopting a goal-independent information-acquisition strategy.</p><p>Our model suggests that in many ecological settings, in which there are more than two options, the optimal strategy involves acquiring <italic>asymmetric</italic> information depending on the goal. It is only when there are only two options that individuals are indifferent about which information to acquire. We propose that the asymmetric strategies we observe even in this latter case might be a consequence of the fact that individuals have developed a strategy that is optimal for the more frequent, real-life cases in which <inline-formula><mml:math id="inf11"><mml:mrow><mml:mrow><mml:mi>n</mml:mi><mml:mo>&gt;</mml:mo><mml:mn>2</mml:mn></mml:mrow><mml:mo>,</mml:mo></mml:mrow></mml:math></inline-formula> and continue to implement this same asymmetric strategy to binary choices, where it remains optimal.</p></sec></sec><sec id="s3" sec-type="discussion"><title>Discussion</title><p>In this study, we investigated how framing affects the way in which information is acquired and integrated during value-based and perceptual choices. Here, using psychophysics together with computational and economic models we have been able to adjudicate between two contrasting hypotheses. The first one, currently the dominant one in the field of neuroeconomics, proposes that attention modulates (either by biasing or boosting) a value integration that starts at the beginning of the deliberation process. Subsequently, at the time of the decision, the participant would give the appropriate response (in our task accepting the option with the highest value or rejecting the one with lowest one) using the value estimate constructed during this deliberation phase. The second hypothesis suggests that, from the very start of the deliberation process, the task-frame (goal) influences the type of information that is integrated. In this second scenario, attention is not automatically attracted to high value items to facilitate their accumulation but has a more general role in prioritising the type of information that is useful for achieving the current behavioural goal. Importantly, these two hypotheses make very distinct predictions about the pattern of attention and suggest very different cognitive architecture underpinning the decision process.</p><p>Our results favour the second hypothesis: specifically, we show that, in both perceptual and value-based tasks, attention is allocated depending on the behavioural goal of the task. Although our study does not directly contradict previous findings (<xref ref-type="bibr" rid="bib30">Krajbich et al., 2010</xref>; <xref ref-type="bibr" rid="bib32">Krajbich and Rangel, 2011</xref>; <xref ref-type="bibr" rid="bib8">Cavanagh et al., 2014</xref>; <xref ref-type="bibr" rid="bib41">Smith and Krajbich, 2019</xref>), it adds nuance to the view that this is a process specifically tied to value integration (defined as a hedonic or reward attribute). Our findings speak in favour of a more general role played by attention in prioritising the information needed to fulfil a behavioural goal in both value and perceptual choices (<xref ref-type="bibr" rid="bib20">Gottlieb, 2012</xref>; <xref ref-type="bibr" rid="bib29">Kovach et al., 2014</xref>; <xref ref-type="bibr" rid="bib15">Glickman et al., 2018</xref>). Importantly, the seeking of goal-relevant information is observed along the trial, opposing the assumption that attentional sampling is random except for the last fixation (<xref ref-type="bibr" rid="bib30">Krajbich et al., 2010</xref>; <xref ref-type="bibr" rid="bib32">Krajbich and Rangel, 2011</xref>; see <xref ref-type="bibr" rid="bib18">Gluth et al., 2018</xref>; <xref ref-type="bibr" rid="bib19">Gluth et al., 2020</xref> for additional support for this idea). Pavlovian influences have been proposed to play a key role in the context of accept/reject framing manipulation (<xref ref-type="bibr" rid="bib10">De Martino et al., 2006</xref>; <xref ref-type="bibr" rid="bib22">Guitart-Masip et al., 2012</xref>; <xref ref-type="bibr" rid="bib23">Guitart-Masip et al., 2014</xref>; <xref ref-type="bibr" rid="bib9">Dayan, 2012</xref>). However, the fact that we found almost identical results in a follow-up perceptual study in which the choice was not framed in terms of ‘accept’ or ‘reject’ but using a different kind of instruction (i.e. ‘choose the option with fewer or more dots’) suggests that attention acts on a more fundamental mechanism of information processing that goes beyond simple Pavlovian influences.</p><p>We also measured the trial-by-trial fluctuations in confidence to gain a deeper insight in the dynamics of this process. We found that the role of confidence goes beyond that of simply tracking the probability of an action being correct, as proposed in standard signal detection theory. Instead, it is also influenced by the perceived sense of uncertainty in the evaluation process (<xref ref-type="bibr" rid="bib34">Navajas et al., 2017</xref>; <xref ref-type="bibr" rid="bib46">Vaghi et al., 2017</xref>), and contextual cues (<xref ref-type="bibr" rid="bib33">Lebreton et al., 2019</xref>). In turn, confidence influences future responses and information seeking (<xref ref-type="bibr" rid="bib13">Folke et al., 2017</xref>; <xref ref-type="bibr" rid="bib21">Guggenmos et al., 2016</xref>; <xref ref-type="bibr" rid="bib12">Fleming et al., 2018</xref>; <xref ref-type="bibr" rid="bib37">Rollwage et al., 2018</xref>). In previous work (<xref ref-type="bibr" rid="bib13">Folke et al., 2017</xref>), we reported how, in value-based choice, confidence was related not only to the difference in value between the two items, but also to the summed value (ΔValue and ΣValue using the current notation), and we found that confidence was higher if both items have a high value (<xref ref-type="bibr" rid="bib13">Folke et al., 2017</xref>). Here, we replicate this effect in both experiments in the <italic>like</italic> and <italic>most</italic> conditions. However, this effect flips in the <italic>dislike</italic> or <italic>fewest</italic> frame: in these cases, confidence increases when the summed value or number of dots is <italic>smaller</italic>. This result is particularly striking since the frame manipulation should be irrelevant for the purpose of the decision and has little effect on the objective performance. This suggests that similarly to attention, the sense of confidence is also shaped by the behavioural goal that participants are set to achieve.</p><p>In both experiments, the incorporation of goal-relevant evidence to fit the GLAM resulted in a better model fit compared with the model in which the value or perceptual evidence was integrated independently of the frame. We then modified the GLAM to include a measure of confidence defined as balance of evidence (<italic>Δ</italic>e) (<xref ref-type="bibr" rid="bib48">Vickers, 1979</xref>; <xref ref-type="bibr" rid="bib28">Kepecs et al., 2008</xref>; <xref ref-type="bibr" rid="bib11">De Martino et al., 2013</xref>). In doing so we confirm that our model can replicate all the main relations between confidence, choice and RT. We then tested if the model simulation was also recovering the flip in the relationship between confidence and summed evidence (ΣValue or ΣDots) triggered by the frame manipulation. We found the model captures this effect only if the attentional bias is included in the simulations. The boost in Δe when goal-relevant evidence in both alternatives is high can attributed to the architecture of the model: gaze has a multiplicative effect over evidence accumulation. For example, consider a case with two items of value A<sub>1</sub> = 2 and A<sub>2</sub> = 1, and a discount factor for the unattended item u = 0.3. Assuming the item with higher value is gazed more we could express, in a very simplified way, the Δe for this choice as Δe<sub><italic>A</italic></sub> = A<sub>1</sub>-A<sub>2</sub>*u = 2–1*0.3 = 1.7. Consider now two new items with identical ΔValue but higher magnitude of the ΣValue, B<sub>1</sub> = 10 and B<sub>2</sub> = 9. Notice that since ΔValue is the same, this choice in absence of attentional effect should be considered of identical difficulty than in case A (A<sub>1</sub>-A<sub>2</sub> = B<sub>1</sub>-B<sub>2</sub> = 1), and therefore the agent should be neither more, nor less confident. But, keeping the same attentional factors than for the first set, we have that the Δe between the items increases, Δe<sub><italic>B</italic></sub> = B<sub>1</sub>-B<sub>2</sub>*u = 10–9*0.3 = 7.3 (Δe<sub><italic>A</italic></sub>&lt;Δe<sub><italic>B</italic></sub>). This effect would not be observed if attention affected evidence accumulation in an additive way (A<sub>1</sub>-(A<sub>2</sub>-u) = B<sub>1</sub>-(B<sub>2</sub>-u)). Our empirical confidence data therefore provide further support to a multiplicative (<xref ref-type="bibr" rid="bib41">Smith and Krajbich, 2019</xref>) instead of additive effect of attention into goal-relevant information. Overall, these data speak in favour of a coding scheme in which the goal sets, from the beginning of the task, the allocation of attention and, by doing so, influences first-order processes such as choice, but also second order process such as confidence. Further empirical data will be required to test this idea more stringently.</p><p>The idea that the goal of the task plays a central role in shaping value-based decisions should not be surprising. Indeed, value-based decision is often called goal-directed choice. Nevertheless, there has been a surprisingly little amount of experimental work in which the behavioural goal has been directly manipulated as the key experimental variable for studying the relation between attention and value. Notable exceptions are two recent studies from <xref ref-type="bibr" rid="bib14">Frömer et al., 2019</xref> and <xref ref-type="bibr" rid="bib29">Kovach et al., 2014</xref>. In the first study (<xref ref-type="bibr" rid="bib14">Frömer et al., 2019</xref>), participants were shown a set of four items and asked, in half of the trials, to determine the best item and, in the second half, the worst item. In line with our findings, they found that behaviour and neural activity in the ‘value network’, including vmPFC and striatum, was determined by goal-congruency and did not simply reflected the expected reward. In the second study, <xref ref-type="bibr" rid="bib29">Kovach et al., 2014</xref> implemented a design similar to our value-based experiment in which participants were required to indicate the item to keep and the one to discard. They found, similarly to our findings in the value-based experiment, that the overall pattern of attention was mostly allocated according to the task goal. However, in the first few hundred milliseconds, these authors found that attention was directed more prominently to the most valuable item in both conditions. We did not replicate this last finding in our experiment (see <xref ref-type="fig" rid="fig3">Figure 3C and D</xref> and <xref ref-type="fig" rid="app2fig2">Appendix 2—figure 2</xref>, showing that fixations were randomly allocated during the early moments of the trial). One possible reason for this discrepancy is that the experiment by Kovach and colleagues presented both items on the screen at the beginning of the task – unlike in our task, in which the item was presented in a gaze-contingent way (to avoid processing in the visual periphery). This setting might have triggered an initial and transitory bottom-up attention grab from the most valuable (and often most salient) item before the accumulation process started.</p><p>To gain a deeper insight into our findings, we developed a normative model of optimal information acquisition rooted in economic decision theory. Our model shows that in many real-life scenarios in which the decision set is larger than two, the optimal strategy to gather and integrate information depends on the behavioural goal. Intuitively, this happens because new information is all the more useful the more likely it is to change the behavioural output, that is, the choice. When the agent needs to select the best item in a set, it is best to search for evidence that it is more likely to affect the top of the ranking (e.g. is the best item still the best one?); information that changes the middle or the bottom of the ranking is instead less valuable (e.g. is the item ranked as seven is now ranked as six?) because it would not affect the behavioural output. When choosing which item to discard, instead, the optimal strategy involves acquiring information most informative of the <italic>bottom</italic> of the ranking and not the top. We propose that even in the context of binary choice studied here, humans might still deploy this normative strategy (for multi-alternative choice), and that while it does not provide a normative advantage, it is not suboptimal. Further work in which the size of the set is increased would be required to test this idea more stringently. Notably, two recent pre-prints have also introduced models to explain how the attentional patterns in choice are generated assuming optimal information sampling (<xref ref-type="bibr" rid="bib25">Jang et al., 2020</xref>; <xref ref-type="bibr" rid="bib5">Callaway et al., 2020</xref>). Both models are based on Bayesian updates of value beliefs, with visual attention playing a role in selecting the information to sample. However, both studies were developed considering only a standard appetitive like frame (<xref ref-type="bibr" rid="bib30">Krajbich et al., 2010</xref> study was used as benchmark in both cases).</p><p>The most far reaching conclusion of our work is that context and behavioural demand have a powerful effect on how information is accumulated and processed. Notably, our data show that this is a general effect that spans both more complex value-based choice and simpler perceptual choice. Our conclusion is that, given the limited computational resources of the brain, humans have developed a mechanism that prioritises the processing or recollection of the information that is most relevant for the behavioural response that is required. This has profound implications when we think about the widespread effect of contextual information on decision making that has been at the core of the research in psychology, behavioural economics and more recently neuroeconomics (<xref ref-type="bibr" rid="bib26">Kahneman and Tversky, 1984</xref>; <xref ref-type="bibr" rid="bib27">Kahneman and Tversky, 2000</xref>; <xref ref-type="bibr" rid="bib6">Camerer et al., 2004</xref>; <xref ref-type="bibr" rid="bib10">De Martino et al., 2006</xref>; <xref ref-type="bibr" rid="bib16">Glimcher and Fehr, 2014</xref>). Most of these contextual or framing effects have been labelled as ‘biases’ because, once one strips away the context, the actual available options should remain identical. However, this perspective may not be putting enough emphasis on the fact that the decision maker has to construct low dimensional (and therefore imperfect) representations of the decision problem. As we have shown here, from the very beginning of the deliberation process, the context — even when it is simple (<italic>like</italic>/<italic>dislike</italic>, <italic>most</italic>/<italic>fewest</italic>) or irrelevant from the experimenter perspective — affects which information is processed, recalled, or attended to, with effects that spread into post-decision processing such as confidence estimation. This, as a consequence, will produce profoundly dissimilar representations according to the behavioural goal set by the context. With this shift of perspective, it may well be the case that many of the so-called ‘biases’ will be shown in a new light, given that participants are dealing with very different choices once the behavioural goal changes. This viewpoint might provide a more encouraging picture of the human mind, by suggesting that evolution has equipped us well to deal with ever-changing environments in the face of limited computational resources.</p></sec><sec id="s4" sec-type="materials|methods"><title>Materials and methods</title><sec id="s4-1"><title>Procedure</title><sec id="s4-1-1"><title>Value experiment</title><p>At the beginning of this experiment, participants were asked to report on a scale from £0 to £3 the maximum they would be willing to pay for each of 60 snack food items. They were informed that this bid will give them the opportunity to purchase a snack at the end of the experiment, using the BDM (<xref ref-type="bibr" rid="bib3">Becker et al., 1964</xref>), which gives them incentives to report their true valuation. Participants were asked to fast for 4 hr previous to the experiment, expecting they would be hungry and willing to spend money to buy a snack.</p><p>After the bid process, participants completed the choice task: in each trial, they were asked to choose between two snack items, displayed on-screen in equidistant boxes to the left and right of the centre of the screen (<xref ref-type="fig" rid="fig1">Figure 1A</xref>). After each binary choice, participants also rated their subjective level of confidence in their choice. Pairs were selected using the value ratings given in the bidding task: using a median split, each item was categorised as high- or low-value for the agent; these were then combined to produce 15 high-value, 15 low-value, and 30 mixed pairs, for a total of 60 pairs tailored to the participant’s preferences. Each pair was presented twice, inverting the position to have a counterbalanced item presentation.</p><p>The key aspect of our experimental setting is that all participants executed the choice process under two framing conditions: (1) a <italic>like</italic> frame, in which participants were asked to select the item that they liked the most, that is, the snack that they would prefer to eat at the end of the experiment and (2) a <italic>dislike</italic> frame in which participants were asked to select the item that they liked the least, knowing that this is tantamount to choosing the other item for consumption at the end of the experiment. See <xref ref-type="fig" rid="fig1">Figure 1A</xref> for a diagram of the task.</p><p>After four practice trials, participants performed a total of 6 blocks of 40 trials (240 trials in total). <italic>Like</italic> and <italic>dislike</italic> frames were presented in alternate blocks and the order was counterbalanced across participants (120 trials per frame). An icon in the top-left corner of the screen (‘thumbs up’ for <italic>like</italic> and ‘stop sign’ for <italic>dislike</italic>) reminded participants of the choice they were required to make; this was also announced by the investigator at the beginning of every block. The last pair in a block would not be first in the subsequent block.</p><p>Participants’ eye movements were recorded throughout the choice task and the presentation of food items was gaze-contingent: participants could only see one item at a time depending on which box they looked at; following <xref ref-type="bibr" rid="bib13">Folke et al., 2017</xref>, this was done to reduce the risk that participant, while gazing one item, would still look at the other item in their visual periphery.</p><p>Once all tasks were completed, one trial was randomly selected from the choice task. The BDM bid value of the preferred item (the chosen one in the <italic>like</italic> frame and the unchosen one in the <italic>dislike</italic> frame) was compared with a randomly generated number between £0 and £3. If the bid was higher than the BDM generated value, an amount equivalent to the BDM value was subtracted from their £20 payment and the participant received the food item. If the bid was lower than the generated value, participants were paid £20 for their time and did not receive any snack. In either case, participants were required to stay in the testing room for an extra hour and were unable to eat any food during this time other than food bought in the auction. Participants were made aware of the whole procedure before the experiment began.</p></sec><sec id="s4-1-2"><title>Perceptual experiment</title><p>Perceptual Experiment had a design similar to the one implemented in Value Experiment, except that alternatives were visual stimuli instead of food items. In this task, participants had to choose between two circles filled with dots (for a schematic diagram see <xref ref-type="fig" rid="fig1">Figure 1</xref>), again in two frames. In the <italic>most</italic> frame, they had to pick the one with more dots; and the one with fewer dots in the <italic>fewest</italic> frame. The total number of dots presented in the circles could have three numerosity levels (=50, 80 and 110 dots). For each pair in those three levels, the dot difference between the circles varied in 10 percentage levels (ranging from 2% to 20% with 2% steps). To increase the difficulty of the task, in addition to the target dots (blue-green coloured), distractor dots (orange coloured) were also shown. The number of distractor dots was 80% of that of target dots (40, 64, 88 for the three numerosity levels, respectively). Pairs were presented twice and counterbalanced for item presentation. After 40 practice trials (20 initial trials with feedback, last 20 without), participants completed 3 blocks of 40 trials in the <italic>most</italic> frame and the same number in the <italic>fewest</italic> frame; they faced blocks with alternating frames, with a presentation order counterbalanced across participants. On the top left side of the screen a message indicating <italic>Most</italic> or <italic>Fewest</italic> reminded participants of the current frame. Participants reported their confidence level in making the correct choice at the end of each trial. As in the previous experiment, the presentation of each circle was gaze contingent. Eye tracking information was recorded for each trial. Participants received £7.5 for 1 hr in this study.</p><p>Both tasks were programmed using Experiment Builder version 2.1.140 (SR Research).</p></sec></sec><sec id="s4-2"><title>Exclusion criteria</title><sec id="s4-2-1"><title>Value experiment</title><p>We excluded individuals that met any of the following criteria:</p><list list-type="order"><list-item><p>Participants used less than 25% of the BDM value scale.</p></list-item><list-item><p>Participants gave exactly the same BDM value for more than 50% of the items.</p></list-item><list-item><p>Participants used less than 25% of the choice confidence scales.</p></list-item><list-item><p>Participants gave exactly the same confidence rating for more than 50% of their choices.</p></list-item><list-item><p>Participants did not comply with the requirements of the experiment (i.e., participants that consistently choose the <italic>preferred</italic> item in <italic>dislike</italic> frame or their average blink time is over 15% of the duration of the trials).</p></list-item></list></sec><sec id="s4-2-2"><title>Perceptual experiment</title><p>Since for Perceptual Experiment the assessment of the value scale is irrelevant, we excluded participants according to criteria 3, 4, and 5.</p></sec></sec><sec id="s4-3"><title>Participants</title><sec id="s4-3-1"><title>Value experiment</title><p>Forty volunteers gave their informed consent to take part in this research. Of these, 31 passed the exclusion criteria and were included in the analysis (16 females, 17 males, aged 20–54, mean age of 28.8). One participant was excluded for using less than 25% of the bidding scale (criteria 1). A second participant was excluded according to criteria 2 as they frequently gave the same bid value. A further four participants were excluded under criteria 4. Three participants were excluded due to criteria 5. In the latter case, one participant’s eye-tracking data showed the highest number of blink events and made choices without fixating any of the items; the other two did not comply with the frame manipulation. To ensure familiarity with the snack items, all the participants in the study had lived in the UK for 1 year or more (average 17 years).</p></sec><sec id="s4-3-2"><title>Perceptual experiment</title><p>Forty volunteers were recruited for the second experiment. Thirty-two participants (22 females, 10 males, aged 19–50, mean age of 26.03) were included in the behavioural and regression analyses. Three participants were excluded for repetition of the confidence rating (criteria 4). Five participants were removed for criteria 5: four of them had performance close to chance level or did not followed the frame modification, and one participant presented difficulties for eye-tracking. Due to instability in parameter estimation (problem of MCMC convergence), four additional participants were removed from the GLAM modelling analysis.</p><p>All participants signed a consent form, and both studies were done following the approval given by the University College London, Division of Psychology and Language Sciences ethics committee.</p></sec></sec><sec id="s4-4"><title>Eye-tracking</title><sec id="s4-4-1"><title>Value and perceptual experiments</title><p>An Eyelink 1000 eye-tracker (SR Research) was used to collect the visual data. Left eye movements were sampled at 500 Hz. Participants rested their heads over a head support in front of the screen. Display resolution was of 1024 × 768 pixels. To standardise the environmental setting and the level of detectability, the lighting was monitored in the room using a dimmer lamp and light intensity was maintained at 4 ± 0.5 lx at the position of the head-mount when the screen was black.</p><p>Eye-tracking data were analysed initially using Data Viewer (SR Research), from which reports were extracted containing details of eye movements. We defined two interest-areas (IA) for left and right alternatives: two squares of 350 × 350 pixels in Value Experiment and two circles of 170 pixels of radius for Perceptual Experiment. The data extracted from the eye-tracker were taken between the appearance of the elements on the screen (snack items or circle with dots in experiments 1 and 2, respectively) and the choice button press (confidence report period was not considered for eye data analysis).</p><p>The time participants spent fixating on each IA was defined the dwelling time (DT). From it, we derived a difference in dwelling time (ΔDT) for each trial by subtracting DT of the right IA minus the DT of the left IA. Starting and ending IA of each saccade were recorded. This information was used to determine the number of times participants alternated their gaze between IAs, that is, ‘gaze shifts’. The total number of gaze shifts between IAs was extracted for each trial, producing the gaze shift frequency (GSF) variable.</p></sec></sec><sec id="s4-5"><title>Data analysis: behavioural data</title><p>Behavioural measures during <italic>like/dislike</italic> and <italic>most/fewest</italic> frames were compared using statistical tests available in SciPy. Sklern toolbox in Python was used to perform logistic regressions on choice data. Fixation time series analysis was performed following <xref ref-type="bibr" rid="bib29">Kovach et al., 2014</xref> methodology. We segmented the time series of all the trials in samples of 10 ms. We fixed all the trials time series to the beginning of the trial, when participant could start exploring the gaze-contingent alternatives. We considered an analysis window of 2000 ms after the presentation of stimuli for all the trials. Please notice that not all the trials have the same duration and no temporal normalisation was performed in this analysis. For each time sample, we obtained the gaze position and the difference in evidence (i.e. ΔValue or ΔDots) for all trials across participants and then Pearson correlation was calculated. Permutations testing was used to assess the difference between the time series in <italic>like/dislike</italic> and <italic>most/fewest</italic> frames. Instantaneous fixations (across trials and frames) were shuffled 200 times to create a null distribution of the difference of correlation coefficients between frames. False discovery rate (FDR) was used to correct for multiple tests the p-values obtained from the permutation test (α ≤ 0.01). All the hierarchical analyses were performed using lme4 package (<xref ref-type="bibr" rid="bib2">Bates et al., 2015</xref>) for R integrated in a Jupyter notebook using the rpy2 package (<ext-link ext-link-type="uri" xlink:href="https://rpy2.readthedocs.io/en/latest/">https://rpy2.readthedocs.io/en/latest/</ext-link>). For choice models, we predicted the log odds ratio of selecting the item appearing at the right. Fixed-effects confidence interval were calculated by multiplying standard errors by 1.96. Additionally, we predicted confidence using a linear mixed-effects model. Predictors were all z-scored at participant level. Matplotlib/Seaborn packages were used for visualisation.</p></sec><sec id="s4-6"><title>Data analysis: attentional model - GLAM</title><p>To get further insight on potential variations in the evidence accumulation process due to the change in frames we used the Gaze-weighted Linear Accumulator Model (GLAM) developed by <xref ref-type="bibr" rid="bib45">Thomas et al., 2019</xref>. GLAM is part of the family of linear stochastic race models in which different alternatives (i, i.e. left or right) accumulate evidence (E<sub>i</sub>) until a decision threshold is reached by one of them, determining the chosen alternative. The accumulator for an individual option is described by the following expression:<disp-formula id="equ5"><label>(5)</label><mml:math id="m5"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mtable columnalign="left left" columnspacing="1em" rowspacing="4pt"><mml:mtr><mml:mtd/><mml:mtd><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msub><mml:mi>E</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:msub><mml:mi>E</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">)</mml:mo><mml:mo>+</mml:mo><mml:mi>ν</mml:mi><mml:msub><mml:mi>R</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mi>ϵ</mml:mi><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub></mml:mstyle></mml:mtd></mml:mtr><mml:mtr><mml:mtd/><mml:mtd><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi mathvariant="normal">w</mml:mi><mml:mi mathvariant="normal">i</mml:mi><mml:mi mathvariant="normal">t</mml:mi><mml:mi mathvariant="normal">h</mml:mi></mml:mrow><mml:mtext> </mml:mtext><mml:msub><mml:mi>ϵ</mml:mi><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>∼</mml:mo><mml:mi>N</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:mi>σ</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mspace width="mediummathspace"/><mml:mspace width="thinmathspace"/><mml:mspace width="thinmathspace"/><mml:mtext> and </mml:mtext><mml:mspace width="thinmathspace"/><mml:mspace width="thinmathspace"/><mml:mspace width="mediummathspace"/><mml:msub><mml:mi>E</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo>=</mml:mo><mml:mn>0</mml:mn><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mn>0</mml:mn></mml:mstyle></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:mstyle></mml:math></disp-formula></p><p>With a drift term (<italic>ν</italic>) controlling the speed of relative evidence (R<sub>i</sub>) integration and i.i.d. noise terms with normal distribution (zero-centered and standard deviation σ). R<sub>i</sub> is a term that expresses the amount of evidence that is accumulated for item i at each time point t. This is calculated as follows. We denote by g<sub>i</sub>, the relative gaze term, calculated as the proportion of time that participants observed item i: <disp-formula id="equ6"><label>(6)</label><mml:math id="m6"><mml:mrow><mml:msub><mml:mi>g</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mi>D</mml:mi><mml:mo>⁢</mml:mo><mml:msub><mml:mi>T</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow><mml:mrow><mml:mrow><mml:mi>D</mml:mi><mml:mo>⁢</mml:mo><mml:msub><mml:mi>T</mml:mi><mml:mn>1</mml:mn></mml:msub></mml:mrow><mml:mo>+</mml:mo><mml:mrow><mml:mi>D</mml:mi><mml:mo>⁢</mml:mo><mml:msub><mml:mi>T</mml:mi><mml:mn>2</mml:mn></mml:msub></mml:mrow></mml:mrow></mml:mfrac></mml:mrow></mml:math></disp-formula>with DT as the dwelling time for item i during an individual trial. Let r<sub>i</sub> denote the value for item i reported during the initial stage of the experiment. We can then define the average absolute evidence for each item (A<sub>i</sub>) during a trial:<disp-formula id="equ7"><label>(7)</label><mml:math id="m7"><mml:mrow><mml:msub><mml:mi>A</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mrow><mml:mrow><mml:msub><mml:mi>g</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>⁢</mml:mo><mml:msub><mml:mi>r</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow><mml:mo>+</mml:mo><mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mn>1</mml:mn><mml:mo>-</mml:mo><mml:msub><mml:mi>g</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>⁢</mml:mo><mml:mi>γ</mml:mi><mml:mo>⁢</mml:mo><mml:msub><mml:mi>r</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:mrow></mml:mrow></mml:math></disp-formula></p><p>This formulation considers a multiplicative effect of the attentional component over the item value, capturing different rates of integration when the participant is observing item i or not (unbiased and biased states, respectively). The parameter γ is the gaze bias parameter: it controls the weight that the attentional component has in determining absolute evidence. <xref ref-type="bibr" rid="bib45">Thomas et al., 2019</xref> interpret γ as follows: when γ = 1, bias and unbiased states have no difference (i.e. the same r is added to the average absolute evidence regardless the item is attended or not); when γ &lt;1, the absolute evidence is discounted for the biased condition; when γ &lt;0, there is a leak of evidence when the item is not fixated. Following <xref ref-type="bibr" rid="bib45">Thomas et al., 2019</xref>, in our analysis, we allowed γ to take negative values, but our results do not change if γ is restricted to [0, 1] (<xref ref-type="fig" rid="app6fig2">Appendix 6—figure 2</xref>). Finally, the relative evidence of item i, R<sub>i</sub><sup>*</sup>, is given by:<disp-formula id="equ8"><label>(8)</label><mml:math id="m8"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msubsup><mml:mi>R</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mo>∗</mml:mo></mml:mrow></mml:msubsup><mml:mo>=</mml:mo><mml:msub><mml:mi>A</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>−</mml:mo><mml:mi>m</mml:mi><mml:mi>a</mml:mi><mml:msub><mml:mi>x</mml:mi><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>A</mml:mi><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:msub><mml:mi>A</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>−</mml:mo><mml:msub><mml:mi>A</mml:mi><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mtext> </mml:mtext><mml:mo stretchy="false">→</mml:mo><mml:msubsup><mml:mi>R</mml:mi><mml:mrow><mml:mtext>right</mml:mtext></mml:mrow><mml:mrow><mml:mo>∗</mml:mo></mml:mrow></mml:msubsup><mml:mo>=</mml:mo><mml:mo>−</mml:mo><mml:msubsup><mml:mi>R</mml:mi><mml:mrow><mml:mtext>left</mml:mtext></mml:mrow><mml:mrow><mml:mo>∗</mml:mo></mml:mrow></mml:msubsup></mml:mrow></mml:mstyle></mml:math></disp-formula></p><p>Since our experiment considers a binary choice the original formulation of the model (<xref ref-type="bibr" rid="bib45">Thomas et al., 2019</xref>), proposed for more than two alternatives, R<sub>i</sub><sup>*</sup> is reduced to subtract the average absolute evidence of the other item. Therefore, for the binary case, the R<sub>i</sub><sup>*</sup> for one item will be additive inverse of the other, for example if the left item has the lower value, we would have R<sub>left</sub><sup>*</sup>&lt;0 and R<sub>right</sub><sup>*</sup>&gt;0. Additionally, in their proposal for GLAM, <xref ref-type="bibr" rid="bib45">Thomas et al., 2019</xref> noted that R<sub>i</sub><sup>*</sup> range will depend on the values that the participant reported, for example evidence accumulation may appear smaller if participant valued all the items similarly, since R<sub>i</sub><sup>*</sup> may be lower in magnitude. This may not represent the actual evidence accumulation process since participants may be sensitive to marginal differences in relative evidence. To account for both of these issues, a logistic transformation is applied over R<sub>i</sub><sup>*</sup> using a scaling parameter τ:<disp-formula id="equ9"><label>(9)</label><mml:math id="m9"><mml:mrow><mml:msub><mml:mi>R</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mrow><mml:mn>1</mml:mn><mml:mo>+</mml:mo><mml:msup><mml:mi>e</mml:mi><mml:mrow><mml:mo>-</mml:mo><mml:mrow><mml:mi>τ</mml:mi><mml:mo>⁢</mml:mo><mml:msubsup><mml:mi>R</mml:mi><mml:mi>i</mml:mi><mml:mo>*</mml:mo></mml:msubsup></mml:mrow></mml:mrow></mml:msup></mml:mrow></mml:mfrac></mml:mrow></mml:math></disp-formula></p><p>In this case, R<sub>i</sub> will be always positive and the magnitude of the difference between R<sub>left</sub> and R<sub>right</sub> will be controlled by τ, for example higher τ will imply a bigger difference in relative evidence (and hence accumulation rate) between left and right item. In the case that τ = 0 the participant will not present any sensitivity to differences in relative evidence.</p><p>Given that R<sub>i</sub> represents an average of the relative evidence across the entire trial, the drift rate in E<sub>i</sub> can be assumed to be constant, which enables the use of an analytical solution for the passage of time density. Unlike aDDM (<xref ref-type="bibr" rid="bib30">Krajbich et al., 2010</xref>), GLAM does not deal with the dynamics of attentional allocation process in choice. Details of these expressions are available at <xref ref-type="bibr" rid="bib45">Thomas et al., 2019</xref>. In summary, we have four free parameters in the GLAM: ν (drift term), γ (gaze bias), τ (evidence scaling), and σ (normally distributed noise standard deviation).</p><p>The model fit with GLAM was implemented at a participant level in a Bayesian framework using PyMC3 (<xref ref-type="bibr" rid="bib38">Salvatier et al., 2016</xref>). Uniform priors were used for all the parameters:<disp-formula id="equ10"><mml:math id="m10"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>v</mml:mi><mml:mo>∼</mml:mo><mml:mrow><mml:mi mathvariant="normal">U</mml:mi><mml:mi mathvariant="normal">n</mml:mi><mml:mi mathvariant="normal">i</mml:mi><mml:mi mathvariant="normal">f</mml:mi><mml:mi mathvariant="normal">o</mml:mi><mml:mi mathvariant="normal">r</mml:mi><mml:mi mathvariant="normal">m</mml:mi></mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msup><mml:mn>1</mml:mn><mml:mrow><mml:mo>−</mml:mo><mml:mn>10</mml:mn></mml:mrow></mml:msup><mml:mo>,</mml:mo><mml:mn>0.01</mml:mn></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mstyle></mml:math></disp-formula><disp-formula id="equ11"><mml:math id="m11"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>γ</mml:mi><mml:mo>∼</mml:mo><mml:mrow><mml:mi mathvariant="normal">U</mml:mi><mml:mi mathvariant="normal">n</mml:mi><mml:mi mathvariant="normal">i</mml:mi><mml:mi mathvariant="normal">f</mml:mi><mml:mi mathvariant="normal">o</mml:mi><mml:mi mathvariant="normal">r</mml:mi><mml:mi mathvariant="normal">m</mml:mi></mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mo>−</mml:mo><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mstyle></mml:math></disp-formula><disp-formula id="equ12"><mml:math id="m12"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>σ</mml:mi><mml:mo>∼</mml:mo><mml:mrow><mml:mi mathvariant="normal">U</mml:mi><mml:mi mathvariant="normal">n</mml:mi><mml:mi mathvariant="normal">i</mml:mi><mml:mi mathvariant="normal">f</mml:mi><mml:mi mathvariant="normal">o</mml:mi><mml:mi mathvariant="normal">r</mml:mi><mml:mi mathvariant="normal">m</mml:mi></mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msup><mml:mn>1</mml:mn><mml:mrow><mml:mo>−</mml:mo><mml:mn>10</mml:mn></mml:mrow></mml:msup><mml:mo>,</mml:mo><mml:mn>5</mml:mn></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mstyle></mml:math></disp-formula><disp-formula id="equ13"><mml:math id="m13"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>τ</mml:mi><mml:mo>∼</mml:mo><mml:mrow><mml:mi mathvariant="normal">U</mml:mi><mml:mi mathvariant="normal">n</mml:mi><mml:mi mathvariant="normal">i</mml:mi><mml:mi mathvariant="normal">f</mml:mi><mml:mi mathvariant="normal">o</mml:mi><mml:mi mathvariant="normal">r</mml:mi><mml:mi mathvariant="normal">m</mml:mi></mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:mn>5</mml:mn></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mstyle></mml:math></disp-formula></p><sec id="s4-6-1"><title>Value experiment</title><p>We fitted the model for each individual participant and for <italic>like</italic> and <italic>dislike</italic> frames, separately. To model participant’s behaviour in the <italic>like</italic> frame, we used as input for GLAM the RTs and choices, plus BDM bid values and relative gaze for left and right alternatives for each trial. The original GLAM formulation (as presented above) assumes that evidence is accumulated in line with the preference value of a particular item (i.e. ‘how much I like this item’). When information about visual attention is included in the model, the multiplicative model in GLAM assumes that attention will boost the evidence accumulation already defined by value. Our proposal is that evidence accumulation is a flexible process in which attention is attracted to items based on the match between their value and task-goal (accept or reject) and not based on value alone, as most of the previous studies have assumed. Since in the <italic>dislike</italic> frame the item with the lower value becomes relevant to fulfil the task, we considered the opposite value of the items (r<sub>i,dislike</sub> = 3 - r<sub>i,like</sub>, e.g. item with value 3, the maximum value, becomes value 0) as an input for GLAM fit. For both conditions, model fit was performed only on even-numbered trials using Markov-Chain-Monte-Carlo sampling, using implementation for No-U-Turn-Sampler (NUTS), four chains were sampled, 1000 tuning samples were used, 2000 posterior samples to estimate the model parameters. The convergence was diagnosed using the Gelman-Rubin statistic (|<inline-formula><mml:math id="inf12"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mrow><mml:mover><mml:mi>R</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow></mml:mrow></mml:mstyle></mml:math></inline-formula> – 1|&lt;0.05) and also corroborating that the effective sample size (ESS) was high (ESS &gt;100) for the four parameters (ν, γ, σ, and τ). Considering all the individual models, we found divergences in less than 3% of the estimated parameters. Model comparison was performed using Watanabe-Akaike Information Criterion (WAIC) scores available in PyMC3, calculated for each individual participant fit.</p><p>Pointing to check if the model replicates the behavioural effects observed in the data (<xref ref-type="bibr" rid="bib35">Palminteri et al., 2017</xref>), simulations for choice and response time (RT) were performed using participant’s odd trials, each one repeated 50 times. For each trial, value and relative gaze for left and right items were used together with the individual estimated parameters. Random choice and RT (within a range of the minimum and maximum RT observed for each particular participant) were set for 5% of the simulations, replicating the contaminating process included in the model as described by <xref ref-type="bibr" rid="bib45">Thomas et al., 2019</xref>.</p><p>Additionally, we simulated the accumulation process in each trial to obtain a measure of balance of evidence (<xref ref-type="bibr" rid="bib47">Vickers, 1970</xref>; <xref ref-type="bibr" rid="bib48">Vickers, 1979</xref>) for each trial. The purpose of this analysis was to replicate the effect of ΣValue over confidence (check <italic>Results</italic> for details) and check if it arises from the accumulation process and its interaction with attention. Balance of evidence in accumulator models has been used previously as an approximation to the generation of confidence in perceptual and value-based decision experiments (<xref ref-type="bibr" rid="bib48">Vickers, 1979</xref>; <xref ref-type="bibr" rid="bib42">Smith and Vickers, 1988</xref>; <xref ref-type="bibr" rid="bib11">De Martino et al., 2013</xref>). Consequently, using the value of the items and gaze ratio from odd-numbered trials, we simulated two accumulators (<xref ref-type="disp-formula" rid="equ5">Equation 5</xref>), one for each alternative. Our simulations used the GLAM parameters obtained from participant’s fit. Once the boundary was reached by one of the stochastic accumulators (fixed boundary = 1), we extracted the simulated RT and choice. The absolute difference between the accumulators when the boundary was reached (Δe = |E<sub>right</sub>(t<sub>final</sub>) - E<sub>left</sub>(t<sub>final</sub>)|) delivered the balance of evidence for that trial. In total 37,200 trials were simulated (10 repetitions for each one of the trials done by the participants). A linear regression model to predict simulated Δe using |ΔValue|, simulated RT and ΣValue as predictors was calculated with the pooled participants’ data. This model was chosen since it was the most parsimonious model obtained to predict participant’s confidence in the Value Experiment (<xref ref-type="fig" rid="app4fig1">Appendix 4—figure 1</xref>). The best model includes GSF as predictor in the regression, but since GLAM does not consider the gaze dynamics we removed it from the model. Δe simulations using a GLAM without gaze influence (i.e. equal gaze time for each alternative) were also generated, to check if gaze difference was required to reproduce ΣValue effect over confidence. The parameters fitted for individual participants were also used in the no-gaze difference simulation. The same linear regression model (Δe ∼ |ΔValue| + simulated RT + ΣValue) was used with the data simulated with no-gaze difference.</p></sec><sec id="s4-6-2"><title>Perceptual experiment</title><p>In the Perceptual Experiment, we repeated the same GLAM analysis done in Value Experiment. Due to instabilities in the parameters’ fit for some participants, we excluded four extra participants. Twenty-eight participants were included in this analysis. Additionally, the GLAM fit in this case was done removing outlier trials, that is, trials with RT higher than 3 standard deviations (within participant) or higher than 20 s. Overall less than 2% of the trials were removed. For <italic>most</italic> frame, relative gaze and perceptual evidence (number of dots) for each alternative were used to fit choice and RT. In a similar way to the consideration taken in the <italic>dislike</italic> case, we reassigned the perceptual evidence in the <italic>fewest</italic> frame (r<sub>i,fewest</sub> = 133 - r<sub>i,most</sub>+ 40 , considering that 133 is the higher number of dots presented and 40 dots the minimum) in a way that the options with higher perceptual evidence in the <italic>most</italic> frame have the lower evidence in the <italic>fewest</italic> frame. The same MCMC parameters used to fit the model for each participant in the Value Experiment were used in this case (again, only even-numbered trials were used to fit the model). As in the Value Experiment, model convergence was assessed using <inline-formula><mml:math id="inf13"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mrow><mml:mover><mml:mi>R</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow></mml:mrow></mml:mstyle></mml:math></inline-formula> and ESS. Overall, we observed divergences in less than 2% of parameter estimations across participants. Behavioural out-of-sample simulations (using the odd-numbered trials) and balance of evidence simulations (33,600 trials simulated in the Perceptual Experiment) were considered in this analysis. We tested the effect of ΣDots over confidence with a similar linear regression model than the one used in the Value Experiment. Pooled participants’ data for |ΔDots|, simulated RT and ΣDots was used to predict Δe. Δe simulations using a GLAM without gaze asymmetry were also calculated in this case. All the figures and analysis were done in Python using GLAM toolbox and custom scripts.</p></sec></sec></sec></body><back><ack id="ack"><title>Acknowledgements</title><p>This study was funded by a Sir Henry Dale Fellowship (102612/A/13/Z) awarded to Benedetto De Martino by the Wellcome Trust. Pradyumna Sepulveda was funded by the Chilean National Agency for Research and Development (ANID)/Scholarship Program/DOCTORADO BECAS CHILE/2017–72180193. We thank Antonio Rangel for his valuable comments on an earlier version of the manuscript and Mariana Zurita for the help in the proofreading of the manuscript.</p></ack><sec id="s5" sec-type="additional-information"><title>Additional information</title><fn-group content-type="competing-interest"><title>Competing interests</title><fn fn-type="COI-statement" id="conf1"><p>No competing interests declared</p></fn></fn-group><fn-group content-type="author-contribution"><title>Author contributions</title><fn fn-type="con" id="con1"><p>Conceptualization, Resources, Data curation, Software, Formal analysis, Funding acquisition, Validation, Investigation, Visualization, Methodology, Writing - original draft, Project administration, Writing - review and editing</p></fn><fn fn-type="con" id="con2"><p>Supervision, Methodology, Writing - review and editing</p></fn><fn fn-type="con" id="con3"><p>Data curation, Formal analysis, Investigation, Writing - review and editing</p></fn><fn fn-type="con" id="con4"><p>Data curation, Formal analysis, Investigation, Writing - review and editing</p></fn><fn fn-type="con" id="con5"><p>Conceptualization, Supervision, Methodology, Writing - original draft, Writing - review and editing, Developed model for optimal information acquisition</p></fn><fn fn-type="con" id="con6"><p>Conceptualization, Supervision, Funding acquisition, Methodology, Writing - original draft, Project administration, Writing - review and editing</p></fn></fn-group><fn-group content-type="ethics-information"><title>Ethics</title><fn fn-type="other"><p>Human subjects: All participants signed a consent form and both studies were done following the approval given by the University College London, Division of Psychology and Language Sciences ethics committee (project ID number 1825/003).</p></fn></fn-group></sec><sec id="s6" sec-type="supplementary-material"><title>Additional files</title><supplementary-material id="transrepform"><label>Transparent reporting form</label><media mime-subtype="docx" mimetype="application" xlink:href="elife-60705-transrepform-v2.docx"/></supplementary-material></sec><sec id="s7" sec-type="data-availability"><title>Data availability</title><p>Data and codes used in this study are available at the Brain Decision Modelling Lab GitHub <ext-link ext-link-type="uri" xlink:href="https://github.com/BDMLab/Sepulveda_et_al_2020">https://github.com/BDMLab/Sepulveda_et_al_2020</ext-link> (copy archived at <ext-link ext-link-type="uri" xlink:href="https://archive.softwareheritage.org/swh:1:rev:a04585ff20b1389c713709b543a1af420bd300c1/">https://archive.softwareheritage.org/swh:1:rev:a04585ff20b1389c713709b543a1af420bd300c1/</ext-link>).</p><p>The following dataset was generated:</p><p><element-citation id="dataset1" publication-type="data" specific-use="isSupplementedBy"><person-group person-group-type="author"><name><surname>Sepulveda</surname><given-names>P</given-names></name><name><surname>Usher</surname><given-names>M</given-names></name><name><surname>Davies</surname><given-names>N</given-names></name><name><surname>Benson</surname><given-names>AA</given-names></name><name><surname>Ortoleva</surname><given-names>P</given-names></name><name><surname>De</surname><given-names>Martino B</given-names></name></person-group><year iso-8601-date="2020">2020</year><data-title>Sepulveda_et_al_2020</data-title><source>GitHub repository</source><pub-id assigning-authority="other" pub-id-type="accession" xlink:href="https://github.com/BDMLab/Sepulveda_et_al_2020">Sepulveda et al 2020</pub-id></element-citation></p></sec><ref-list><title>References</title><ref id="bib1"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Anderson</surname> <given-names>BA</given-names></name><name><surname>Laurent</surname> <given-names>PA</given-names></name><name><surname>Yantis</surname> <given-names>S</given-names></name></person-group><year iso-8601-date="2011">2011</year><article-title>Value-driven attentional capture</article-title><source>PNAS</source><volume>108</volume><fpage>10367</fpage><lpage>10371</lpage><pub-id pub-id-type="doi">10.1073/pnas.1104047108</pub-id><pub-id pub-id-type="pmid">21646524</pub-id></element-citation></ref><ref id="bib2"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bates</surname> <given-names>D</given-names></name><name><surname>Mächler</surname> <given-names>M</given-names></name><name><surname>Bolker</surname> <given-names>B</given-names></name><name><surname>Walker</surname> <given-names>S</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>Fitting linear Mixed-Effects models using lme4</article-title><source>Journal of Statistical Software</source><volume>67</volume><elocation-id>i01</elocation-id><pub-id pub-id-type="doi">10.18637/jss.v067.i01</pub-id></element-citation></ref><ref id="bib3"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Becker</surname> <given-names>GM</given-names></name><name><surname>DeGroot</surname> <given-names>MH</given-names></name><name><surname>Marschak</surname> <given-names>J</given-names></name></person-group><year iso-8601-date="1964">1964</year><article-title>Measuring utility by a single-response sequential method</article-title><source>Behavioral Science</source><volume>9</volume><fpage>226</fpage><lpage>232</lpage><pub-id pub-id-type="doi">10.1002/bs.3830090304</pub-id><pub-id pub-id-type="pmid">5888778</pub-id></element-citation></ref><ref id="bib4"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Boldt</surname> <given-names>A</given-names></name><name><surname>Blundell</surname> <given-names>C</given-names></name><name><surname>De Martino</surname> <given-names>B</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>Confidence modulates exploration and exploitation in value-based learning</article-title><source>Neuroscience of Consciousness</source><volume>2019</volume><elocation-id>niz004</elocation-id><pub-id pub-id-type="doi">10.1093/nc/niz004</pub-id><pub-id pub-id-type="pmid">31086679</pub-id></element-citation></ref><ref id="bib5"><element-citation publication-type="preprint"><person-group person-group-type="author"><name><surname>Callaway</surname> <given-names>F</given-names></name><name><surname>Rangel</surname> <given-names>A</given-names></name><name><surname>Griffiths</surname> <given-names>TL</given-names></name></person-group><year iso-8601-date="2020">2020</year><article-title>Fixation patterns in simple choice are consistent with optimal use of cognitive resources</article-title><source>PsyArXiv</source><pub-id pub-id-type="doi">10.31234/osf.io/57v6k</pub-id></element-citation></ref><ref id="bib6"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Camerer</surname> <given-names>C</given-names></name><name><surname>Loewenstein</surname> <given-names>G</given-names></name><name><surname>Rabin</surname> <given-names>M</given-names></name></person-group><year iso-8601-date="2004">2004</year><source>Advances in behavioral economics. The roundtable series in behavioral economics</source><publisher-loc>Russell Sage Foundation ; Princeton University Press, New York</publisher-loc><publisher-name>Princeton, N.J</publisher-name></element-citation></ref><ref id="bib7"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Caplin</surname> <given-names>A</given-names></name><name><surname>Dean</surname> <given-names>M</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>Revealed preference, rational inattention, and costly information acquisition</article-title><source>American Economic Review</source><volume>105</volume><fpage>2183</fpage><lpage>2203</lpage><pub-id pub-id-type="doi">10.1257/aer.20140117</pub-id></element-citation></ref><ref id="bib8"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Cavanagh</surname> <given-names>JF</given-names></name><name><surname>Wiecki</surname> <given-names>TV</given-names></name><name><surname>Kochar</surname> <given-names>A</given-names></name><name><surname>Frank</surname> <given-names>MJ</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>Eye tracking and pupillometry are indicators of dissociable latent decision processes</article-title><source>Journal of Experimental Psychology: General</source><volume>143</volume><fpage>1476</fpage><lpage>1488</lpage><pub-id pub-id-type="doi">10.1037/a0035813</pub-id><pub-id pub-id-type="pmid">24548281</pub-id></element-citation></ref><ref id="bib9"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Dayan</surname> <given-names>P</given-names></name></person-group><year iso-8601-date="2012">2012</year><article-title>Instrumental vigour in punishment and reward: vigour in punishment and reward</article-title><source>European Journal of Neuroscience</source><volume>35</volume><fpage>1152</fpage><lpage>1168</lpage><pub-id pub-id-type="doi">10.1111/j.1460-9568.2012.08026.x</pub-id><pub-id pub-id-type="pmid">22487044</pub-id></element-citation></ref><ref id="bib10"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>De Martino</surname> <given-names>B</given-names></name><name><surname>Kumaran</surname> <given-names>D</given-names></name><name><surname>Seymour</surname> <given-names>B</given-names></name><name><surname>Dolan</surname> <given-names>RJ</given-names></name></person-group><year iso-8601-date="2006">2006</year><article-title>Frames, biases, and rational decision-making in the human brain</article-title><source>Science</source><volume>313</volume><fpage>684</fpage><lpage>687</lpage><pub-id pub-id-type="doi">10.1126/science.1128356</pub-id><pub-id pub-id-type="pmid">16888142</pub-id></element-citation></ref><ref id="bib11"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>De Martino</surname> <given-names>B</given-names></name><name><surname>Fleming</surname> <given-names>SM</given-names></name><name><surname>Garrett</surname> <given-names>N</given-names></name><name><surname>Dolan</surname> <given-names>RJ</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>Confidence in value-based choice</article-title><source>Nature Neuroscience</source><volume>16</volume><fpage>105</fpage><lpage>110</lpage><pub-id pub-id-type="doi">10.1038/nn.3279</pub-id><pub-id pub-id-type="pmid">23222911</pub-id></element-citation></ref><ref id="bib12"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Fleming</surname> <given-names>SM</given-names></name><name><surname>van der Putten</surname> <given-names>EJ</given-names></name><name><surname>Daw</surname> <given-names>ND</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>Neural mediators of changes of mind about perceptual decisions</article-title><source>Nature Neuroscience</source><volume>21</volume><fpage>617</fpage><lpage>624</lpage><pub-id pub-id-type="doi">10.1038/s41593-018-0104-6</pub-id><pub-id pub-id-type="pmid">29531361</pub-id></element-citation></ref><ref id="bib13"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Folke</surname> <given-names>T</given-names></name><name><surname>Jacobsen</surname> <given-names>C</given-names></name><name><surname>Fleming</surname> <given-names>SM</given-names></name><name><surname>De Martino</surname> <given-names>B</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>Explicit representation of confidence informs future value-based decisions</article-title><source>Nature Human Behaviour</source><volume>1</volume><elocation-id>0002</elocation-id><pub-id pub-id-type="doi">10.1038/s41562-016-0002</pub-id></element-citation></ref><ref id="bib14"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Frömer</surname> <given-names>R</given-names></name><name><surname>Dean Wolf</surname> <given-names>CK</given-names></name><name><surname>Shenhav</surname> <given-names>A</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>Goal congruency dominates reward value in accounting for behavioral and neural correlates of value-based decision-making</article-title><source>Nature Communications</source><volume>10</volume><elocation-id>4926</elocation-id><pub-id pub-id-type="doi">10.1038/s41467-019-12931-x</pub-id><pub-id pub-id-type="pmid">31664035</pub-id></element-citation></ref><ref id="bib15"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Glickman</surname> <given-names>M</given-names></name><name><surname>Tsetsos</surname> <given-names>K</given-names></name><name><surname>Usher</surname> <given-names>M</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>Attentional selection mediates framing and Risk-Bias effects</article-title><source>Psychological Science</source><volume>29</volume><fpage>2010</fpage><lpage>2019</lpage><pub-id pub-id-type="doi">10.1177/0956797618803643</pub-id><pub-id pub-id-type="pmid">30403368</pub-id></element-citation></ref><ref id="bib16"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Glimcher</surname> <given-names>PW</given-names></name><name><surname>Fehr</surname> <given-names>E</given-names></name></person-group><year iso-8601-date="2014">2014</year><source>Neuroeconomics: Decision Making and the Brain</source><publisher-name>Academic Press is an imprint of Elsevier</publisher-name></element-citation></ref><ref id="bib17"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Gluth</surname> <given-names>S</given-names></name><name><surname>Sommer</surname> <given-names>T</given-names></name><name><surname>Rieskamp</surname> <given-names>J</given-names></name><name><surname>Büchel</surname> <given-names>C</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>Effective connectivity between Hippocampus and ventromedial prefrontal cortex controls preferential choices from memory</article-title><source>Neuron</source><volume>86</volume><fpage>1078</fpage><lpage>1090</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2015.04.023</pub-id><pub-id pub-id-type="pmid">25996135</pub-id></element-citation></ref><ref id="bib18"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Gluth</surname> <given-names>S</given-names></name><name><surname>Spektor</surname> <given-names>MS</given-names></name><name><surname>Rieskamp</surname> <given-names>J</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>Value-based attentional capture affects multi-alternative decision making</article-title><source>eLife</source><volume>7</volume><elocation-id>e39659</elocation-id><pub-id pub-id-type="doi">10.7554/eLife.39659</pub-id><pub-id pub-id-type="pmid">30394874</pub-id></element-citation></ref><ref id="bib19"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Gluth</surname> <given-names>S</given-names></name><name><surname>Kern</surname> <given-names>N</given-names></name><name><surname>Kortmann</surname> <given-names>M</given-names></name><name><surname>Vitali</surname> <given-names>CL</given-names></name></person-group><year iso-8601-date="2020">2020</year><article-title>Value-based attention but not divisive normalization influences decisions with multiple alternatives</article-title><source>Nature Human Behaviour</source><volume>4</volume><fpage>634</fpage><lpage>645</lpage><pub-id pub-id-type="doi">10.1038/s41562-020-0822-0</pub-id><pub-id pub-id-type="pmid">32015490</pub-id></element-citation></ref><ref id="bib20"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Gottlieb</surname> <given-names>J</given-names></name></person-group><year iso-8601-date="2012">2012</year><article-title>Attention, learning, and the value of information</article-title><source>Neuron</source><volume>76</volume><fpage>281</fpage><lpage>295</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2012.09.034</pub-id><pub-id pub-id-type="pmid">23083732</pub-id></element-citation></ref><ref id="bib21"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Guggenmos</surname> <given-names>M</given-names></name><name><surname>Wilbertz</surname> <given-names>G</given-names></name><name><surname>Hebart</surname> <given-names>MN</given-names></name><name><surname>Sterzer</surname> <given-names>P</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Mesolimbic confidence signals guide perceptual learning in the absence of external feedback</article-title><source>eLife</source><volume>5</volume><elocation-id>e13388</elocation-id><pub-id pub-id-type="doi">10.7554/eLife.13388</pub-id><pub-id pub-id-type="pmid">27021283</pub-id></element-citation></ref><ref id="bib22"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Guitart-Masip</surname> <given-names>M</given-names></name><name><surname>Huys</surname> <given-names>QJ</given-names></name><name><surname>Fuentemilla</surname> <given-names>L</given-names></name><name><surname>Dayan</surname> <given-names>P</given-names></name><name><surname>Duzel</surname> <given-names>E</given-names></name><name><surname>Dolan</surname> <given-names>RJ</given-names></name></person-group><year iso-8601-date="2012">2012</year><article-title>Go and no-go learning in reward and punishment: interactions between affect and effect</article-title><source>NeuroImage</source><volume>62</volume><fpage>154</fpage><lpage>166</lpage><pub-id pub-id-type="doi">10.1016/j.neuroimage.2012.04.024</pub-id><pub-id pub-id-type="pmid">22548809</pub-id></element-citation></ref><ref id="bib23"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Guitart-Masip</surname> <given-names>M</given-names></name><name><surname>Duzel</surname> <given-names>E</given-names></name><name><surname>Dolan</surname> <given-names>R</given-names></name><name><surname>Dayan</surname> <given-names>P</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>Action versus Valence in decision making</article-title><source>Trends in Cognitive Sciences</source><volume>18</volume><fpage>194</fpage><lpage>202</lpage><pub-id pub-id-type="doi">10.1016/j.tics.2014.01.003</pub-id><pub-id pub-id-type="pmid">24581556</pub-id></element-citation></ref><ref id="bib24"><element-citation publication-type="report"><person-group person-group-type="author"><name><surname>Hébert</surname> <given-names>B</given-names></name><name><surname>Woodford</surname> <given-names>M</given-names></name></person-group><year iso-8601-date="2017">2017</year><source>Rational Inattention and Sequential Information Sampling, Technical Report W23787</source><publisher-name>National Bureau of Economic Research</publisher-name></element-citation></ref><ref id="bib25"><element-citation publication-type="preprint"><person-group person-group-type="author"><name><surname>Jang</surname> <given-names>AI</given-names></name><name><surname>Sharma</surname> <given-names>R</given-names></name><name><surname>Drugowitsch</surname> <given-names>J</given-names></name></person-group><year iso-8601-date="2020">2020</year><article-title>Optimal policy for attention-modulated decisions explains human fixation behavior</article-title><source>bioRxiv</source><pub-id pub-id-type="doi">10.1101/2020.08.04.237057</pub-id></element-citation></ref><ref id="bib26"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kahneman</surname> <given-names>D</given-names></name><name><surname>Tversky</surname> <given-names>A</given-names></name></person-group><year iso-8601-date="1984">1984</year><article-title>Choices, values, and frames</article-title><source>American Psychologist</source><volume>39</volume><fpage>341</fpage><lpage>350</lpage><pub-id pub-id-type="doi">10.1037/0003-066X.39.4.341</pub-id></element-citation></ref><ref id="bib27"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Kahneman</surname> <given-names>D</given-names></name><name><surname>Tversky</surname> <given-names>A</given-names></name></person-group><year iso-8601-date="2000">2000</year><source>Choices, Values, and Frames</source><publisher-name>Cambridge University Press, Russell sage Foundation</publisher-name></element-citation></ref><ref id="bib28"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kepecs</surname> <given-names>A</given-names></name><name><surname>Uchida</surname> <given-names>N</given-names></name><name><surname>Zariwala</surname> <given-names>HA</given-names></name><name><surname>Mainen</surname> <given-names>ZF</given-names></name></person-group><year iso-8601-date="2008">2008</year><article-title>Neural correlates, computation and behavioural impact of decision confidence</article-title><source>Nature</source><volume>455</volume><fpage>227</fpage><lpage>231</lpage><pub-id pub-id-type="doi">10.1038/nature07200</pub-id><pub-id pub-id-type="pmid">18690210</pub-id></element-citation></ref><ref id="bib29"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kovach</surname> <given-names>CK</given-names></name><name><surname>Sutterer</surname> <given-names>MJ</given-names></name><name><surname>Rushia</surname> <given-names>SN</given-names></name><name><surname>Teriakidis</surname> <given-names>A</given-names></name><name><surname>Jenison</surname> <given-names>RL</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>Two systems drive attention to rewards</article-title><source>Frontiers in Psychology</source><volume>5</volume><elocation-id>46</elocation-id><pub-id pub-id-type="doi">10.3389/fpsyg.2014.00046</pub-id><pub-id pub-id-type="pmid">24550868</pub-id></element-citation></ref><ref id="bib30"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Krajbich</surname> <given-names>I</given-names></name><name><surname>Armel</surname> <given-names>C</given-names></name><name><surname>Rangel</surname> <given-names>A</given-names></name></person-group><year iso-8601-date="2010">2010</year><article-title>Visual fixations and the computation and comparison of value in simple choice</article-title><source>Nature Neuroscience</source><volume>13</volume><fpage>1292</fpage><lpage>1298</lpage><pub-id pub-id-type="doi">10.1038/nn.2635</pub-id><pub-id pub-id-type="pmid">20835253</pub-id></element-citation></ref><ref id="bib31"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Krajbich</surname> <given-names>I</given-names></name><name><surname>Lu</surname> <given-names>D</given-names></name><name><surname>Camerer</surname> <given-names>C</given-names></name><name><surname>Rangel</surname> <given-names>A</given-names></name></person-group><year iso-8601-date="2012">2012</year><article-title>The attentional drift-diffusion model extends to simple purchasing decisions</article-title><source>Frontiers in Psychology</source><volume>3</volume><elocation-id>193</elocation-id><pub-id pub-id-type="doi">10.3389/fpsyg.2012.00193</pub-id><pub-id pub-id-type="pmid">22707945</pub-id></element-citation></ref><ref id="bib32"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Krajbich</surname> <given-names>I</given-names></name><name><surname>Rangel</surname> <given-names>A</given-names></name></person-group><year iso-8601-date="2011">2011</year><article-title>Multialternative drift-diffusion model predicts the relationship between visual fixations and choice in value-based decisions</article-title><source>PNAS</source><volume>108</volume><fpage>13852</fpage><lpage>13857</lpage><pub-id pub-id-type="doi">10.1073/pnas.1101328108</pub-id><pub-id pub-id-type="pmid">21808009</pub-id></element-citation></ref><ref id="bib33"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Lebreton</surname> <given-names>M</given-names></name><name><surname>Bacily</surname> <given-names>K</given-names></name><name><surname>Palminteri</surname> <given-names>S</given-names></name><name><surname>Engelmann</surname> <given-names>JB</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>Contextual influence on confidence judgments in human reinforcement learning</article-title><source>PLOS Computational Biology</source><volume>15</volume><elocation-id>e1006973</elocation-id><pub-id pub-id-type="doi">10.1371/journal.pcbi.1006973</pub-id><pub-id pub-id-type="pmid">30958826</pub-id></element-citation></ref><ref id="bib34"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Navajas</surname> <given-names>J</given-names></name><name><surname>Hindocha</surname> <given-names>C</given-names></name><name><surname>Foda</surname> <given-names>H</given-names></name><name><surname>Keramati</surname> <given-names>M</given-names></name><name><surname>Latham</surname> <given-names>PE</given-names></name><name><surname>Bahrami</surname> <given-names>B</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>The idiosyncratic nature of confidence</article-title><source>Nature Human Behaviour</source><volume>1</volume><fpage>810</fpage><lpage>818</lpage><pub-id pub-id-type="doi">10.1038/s41562-017-0215-1</pub-id><pub-id pub-id-type="pmid">29152591</pub-id></element-citation></ref><ref id="bib35"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Palminteri</surname> <given-names>S</given-names></name><name><surname>Wyart</surname> <given-names>V</given-names></name><name><surname>Koechlin</surname> <given-names>E</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>The importance of falsification in computational cognitive modeling</article-title><source>Trends in Cognitive Sciences</source><volume>21</volume><fpage>425</fpage><lpage>433</lpage><pub-id pub-id-type="doi">10.1016/j.tics.2017.03.011</pub-id><pub-id pub-id-type="pmid">28476348</pub-id></element-citation></ref><ref id="bib36"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Polanía</surname> <given-names>R</given-names></name><name><surname>Krajbich</surname> <given-names>I</given-names></name><name><surname>Grueschow</surname> <given-names>M</given-names></name><name><surname>Ruff</surname> <given-names>CC</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>Neural oscillations and synchronization differentially support evidence accumulation in perceptual and value-based decision making</article-title><source>Neuron</source><volume>82</volume><fpage>709</fpage><lpage>720</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2014.03.014</pub-id><pub-id pub-id-type="pmid">24811387</pub-id></element-citation></ref><ref id="bib37"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Rollwage</surname> <given-names>M</given-names></name><name><surname>Dolan</surname> <given-names>RJ</given-names></name><name><surname>Fleming</surname> <given-names>SM</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>Metacognitive failure as a feature of those holding radical beliefs</article-title><source>Current Biology</source><volume>28</volume><fpage>4014</fpage><lpage>4021</lpage><pub-id pub-id-type="doi">10.1016/j.cub.2018.10.053</pub-id><pub-id pub-id-type="pmid">30562522</pub-id></element-citation></ref><ref id="bib38"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Salvatier</surname> <given-names>J</given-names></name><name><surname>Wiecki</surname> <given-names>TV</given-names></name><name><surname>Fonnesbeck</surname> <given-names>C</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Probabilistic programming in Python using PyMC3</article-title><source>PeerJ Computer Science</source><volume>2</volume><elocation-id>e55</elocation-id><pub-id pub-id-type="doi">10.7717/peerj-cs.55</pub-id></element-citation></ref><ref id="bib39"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Sims</surname> <given-names>CA</given-names></name></person-group><year iso-8601-date="2003">2003</year><article-title>Implications of rational inattention</article-title><source>Journal of Monetary Economics</source><volume>50</volume><fpage>665</fpage><lpage>690</lpage><pub-id pub-id-type="doi">10.1016/S0304-3932(03)00029-1</pub-id></element-citation></ref><ref id="bib40"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Sims</surname> <given-names>C</given-names></name></person-group><year iso-8601-date="2010">2010</year><chapter-title>Rational Inattention and Monetary Economics</chapter-title><person-group person-group-type="editor"><name><surname>Friedman</surname> <given-names>B</given-names></name><name><surname>Woodford</surname> <given-names>M</given-names></name></person-group><source>Handbook of Monetary Economics</source><publisher-name>Elsevier</publisher-name><fpage>155</fpage><lpage>181</lpage><pub-id pub-id-type="doi">10.1016/B978-0-444-53238-1.00004-1</pub-id></element-citation></ref><ref id="bib41"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Smith</surname> <given-names>SM</given-names></name><name><surname>Krajbich</surname> <given-names>I</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>Gaze amplifies value in decision making</article-title><source>Psychological Science</source><volume>30</volume><fpage>116</fpage><lpage>128</lpage><pub-id pub-id-type="doi">10.1177/0956797618810521</pub-id><pub-id pub-id-type="pmid">30526339</pub-id></element-citation></ref><ref id="bib42"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Smith</surname> <given-names>PL</given-names></name><name><surname>Vickers</surname> <given-names>D</given-names></name></person-group><year iso-8601-date="1988">1988</year><article-title>The accumulator model of two-choice discrimination</article-title><source>Journal of Mathematical Psychology</source><volume>32</volume><fpage>135</fpage><lpage>168</lpage><pub-id pub-id-type="doi">10.1016/0022-2496(88)90043-0</pub-id></element-citation></ref><ref id="bib43"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Suri</surname> <given-names>G</given-names></name><name><surname>Gross</surname> <given-names>JJ</given-names></name><name><surname>McClelland</surname> <given-names>JL</given-names></name></person-group><year iso-8601-date="2020">2020</year><article-title>Value-based decision making: an interactive activation perspective</article-title><source>Psychological Review</source><volume>127</volume><fpage>153</fpage><lpage>185</lpage><pub-id pub-id-type="doi">10.1037/rev0000164</pub-id><pub-id pub-id-type="pmid">31524426</pub-id></element-citation></ref><ref id="bib44"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Tavares</surname> <given-names>G</given-names></name><name><surname>Perona</surname> <given-names>P</given-names></name><name><surname>Rangel</surname> <given-names>A</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>The attentional drift diffusion model of simple perceptual Decision-Making</article-title><source>Frontiers in Neuroscience</source><volume>11</volume><elocation-id>468</elocation-id><pub-id pub-id-type="doi">10.3389/fnins.2017.00468</pub-id><pub-id pub-id-type="pmid">28894413</pub-id></element-citation></ref><ref id="bib45"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Thomas</surname> <given-names>AW</given-names></name><name><surname>Molter</surname> <given-names>F</given-names></name><name><surname>Krajbich</surname> <given-names>I</given-names></name><name><surname>Heekeren</surname> <given-names>HR</given-names></name><name><surname>Mohr</surname> <given-names>PNC</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>Gaze Bias differences capture individual choice behaviour</article-title><source>Nature Human Behaviour</source><volume>3</volume><fpage>625</fpage><lpage>635</lpage><pub-id pub-id-type="doi">10.1038/s41562-019-0584-8</pub-id><pub-id pub-id-type="pmid">30988476</pub-id></element-citation></ref><ref id="bib46"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Vaghi</surname> <given-names>MM</given-names></name><name><surname>Luyckx</surname> <given-names>F</given-names></name><name><surname>Sule</surname> <given-names>A</given-names></name><name><surname>Fineberg</surname> <given-names>NA</given-names></name><name><surname>Robbins</surname> <given-names>TW</given-names></name><name><surname>De Martino</surname> <given-names>B</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>Compulsivity reveals a novel dissociation between action and confidence</article-title><source>Neuron</source><volume>96</volume><fpage>348</fpage><lpage>354</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2017.09.006</pub-id><pub-id pub-id-type="pmid">28965997</pub-id></element-citation></ref><ref id="bib47"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Vickers</surname> <given-names>D</given-names></name></person-group><year iso-8601-date="1970">1970</year><article-title>Evidence for an accumulator model of psychophysical discrimination</article-title><source>Ergonomics</source><volume>13</volume><fpage>37</fpage><lpage>58</lpage><pub-id pub-id-type="doi">10.1080/00140137008931117</pub-id><pub-id pub-id-type="pmid">5416868</pub-id></element-citation></ref><ref id="bib48"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Vickers</surname> <given-names>D</given-names></name></person-group><year iso-8601-date="1979">1979</year><source>Decision Processes in Visual Perception</source><publisher-name>Academic Press</publisher-name></element-citation></ref></ref-list><app-group><app id="appendix-1"><title>Appendix 1</title><boxed-text><sec id="s8" sec-type="appendix"><title>Task framing differences</title><sec id="s8-1"><title>Value experiment</title><p>We examined how the frame manipulation impacted overall performance (<xref ref-type="fig" rid="app1fig1">Appendix 1—figure 1A</xref>). We defined ‘accuracy’ as the proportion of trials in which participant’s reported values (BDM bid) correctly predicted their binary decision, that is, they select the item with highest value in the <italic>like</italic> frame and the one with lowest value in the <italic>dislike</italic> frame. Overall accuracy was not significantly different in both frames (Mean<sub>Like</sub> = 0.77; Mean<sub>Dislike</sub> = 0.75, t(30) = 1.71; p=0.1). We also found that participants had slightly slower reaction times (RTs) in the <italic>dislike</italic> frame (Mean<sub>Like</sub> = 2858.2 ms, Mean<sub>Dislike</sub> = 3152.7 ms; t(30) = −2.52; p&lt;0.05). Participants reported lower confidence in the <italic>dislike</italic> frame (Mean<sub>∆Confidence</sub> = 0.19; t(30) = 4.49; p&lt;0.001) and shifted their gaze (gaze shift frequency, GSF) between items more during <italic>dislike</italic> trials (Mean<sub>∆|GSF|</sub> = −0.110; t(30) = −2.99; p&lt;0.01). These results overall suggest that the subjects may have found the <italic>dislike</italic> condition slightly less intuitive. Although this did not affect their performance, it slightly reduced their confidence and increased RT and GSF.</p><p>As observed in previous studies (<xref ref-type="bibr" rid="bib13">Folke et al., 2017</xref>; <xref ref-type="bibr" rid="bib11">De Martino et al., 2013</xref>), we found that choice accuracy was modulated by confidence: decisions in which participants reported high-confidence were more accurately predicted by the value estimate collected before the experiment – the slope of the logistic curve is steeper in the case of high confidence (<xref ref-type="fig" rid="fig1">Figure 1B</xref>, <italic>Results</italic> section). In this study, this effect is replicated in both <italic>like</italic> (low confidence: β = 0.769; high confidence: β = 1.633) and <italic>dislike</italic> (low confidence: β = −0.642; high confidence: β = −1.363) frames. Note that the inversion of the sign of the slopes in <italic>like</italic> vs <italic>dislike</italic> frames indicate that participants were performing the task correctly (∆β<sub>Like-Dislike</sub>: t(30) = 8.14, p&lt;0.001), selecting the item with lower value during the <italic>dislike</italic> frame (<xref ref-type="fig" rid="fig1">Figure 1C</xref>, <italic>Results</italic> section). Choice accuracy (steepness of the slopes) was not significantly different between <italic>like</italic> and <italic>dislike</italic> frames (∆|β<sub>Like-Dislike</sub>|: t(30) = 1.58, p=0.124).</p></sec><sec id="s8-2"><title>Perceptual experiment</title><p>We repeated the same analysis for the behavioural performance in <italic>most</italic> and <italic>fewest</italic> frames (<xref ref-type="fig" rid="app1fig1">Appendix 1—figure 1B</xref>). In contrast to the Value Experiment, we observed a slight reduction in accuracy in participant responses for the <italic>fewest</italic> frame (Mean<sub>Most</sub> = 0.77, Mean<sub>Few</sub> = 0.74, t(31) = 2.46; p&lt;0.05); unlike the Value Experiment, however, we did not find differences in RTs (Mean<sub>Most</sub> = 4029.57 ms, Mean<sub>Few</sub> = 3975.59 ms; t(31) = 0.32; p=0.75). During the <italic>fewest</italic> frame participants reported lower confidence (Mean<sub>∆Confidence</sub>=0.24; t(31) = 5.62; p&lt;0.001) and shifted their gaze more between alternatives (Mean<sub>∆|GSF|</sub> = -0.17; t(31) = -4.15; p&lt;0.001), as observed in the Value Experiment.</p><p>Participants also reported higher confidence in trials that better discriminated the number of dots (<xref ref-type="fig" rid="fig1">Figure 1E</xref>, <italic>Results</italic> section). This effect was replicated in both <italic>most</italic> (low confidence: β = 1.142; high confidence: β = 2.164) and <italic>fewest</italic> (low confidence: β = −1.118; high confidence: β = −2.010) frames. The inversion of the sign of the slopes in <italic>most</italic> vs <italic>fewest</italic> frames also shows that participants were performing correctly (∆β<sub>Most-Few</sub>: t(31) = 22.22, p&lt;0.001); the magnitude of the slopes was not significantly different between the two frames (∆|β<sub>Most-Few</sub>|: t(31) = 0.79, p=0.434; <xref ref-type="fig" rid="fig1">Figure 1F</xref>, <italic>Results</italic> section). This pattern of results mirrors the pattern seen in the Value Experiment.</p><fig id="app1fig1" position="float"><label>Appendix 1—figure 1.</label><caption><title>Behavioural results for Value (<bold>A</bold>) and Perceptual (<bold>B</bold>) Experiments.</title><p>Confidence, DDT, and GSF values have been z-scored per participant. In the violin plot, red and blue areas indicate the distribution of the parameters across participants. Black bars present the 25, 50, and 75 percentiles of the data. Solid colour indicates the Value Experiment and striped colours indicate the Perceptual Experiment. RT: reaction time; ∆DT: Difference in Dwell Time; GSF: Gaze Shift Frequency.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-60705-app1-fig1-v2.tif"/></fig><fig id="app1fig2" position="float"><label>Appendix 1—figure 2.</label><caption><title>Logistic regression predicting choice from the difference in value between the two items (∆Value).</title><p>All participants in the Value Experiment, <italic>like</italic> frame, are presented. Light blue lines depict the logistic fit calculated using only low confidence trials. Dark blue lines show the logistic fit only for high confidence trials. Segmented black line considers the logistic regression calculated using all the trials.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-60705-app1-fig2-v2.tif"/></fig><fig id="app1fig3" position="float"><label>Appendix 1—figure 3.</label><caption><title>Logistic regression predicting choice from the difference in value between the two items (∆Value).</title><p>All participants in the Value Experiment, <italic>dislike</italic> frame, are presented. Light red lines depict the logistic fit calculated using low confidence trials. Dark red lines show the logistic fit using high confidence trials. Segmented black line considers the logistic regression calculated with all the trials.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-60705-app1-fig3-v2.tif"/></fig><fig id="app1fig4" position="float"><label>Appendix 1—figure 4.</label><caption><title>Logistic regression predicting choice from the difference in number of dots between the two circles (∆Dots).</title><p>All participants in the Perceptual Experiment, <italic>most</italic> frame, are presented. Light blue lines depict the logistic fit calculated using only low confidence trials. Dark blue lines show the logistic fit only for high confidence trials. Segmented black line considers the logistic regression calculated with all the trials.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-60705-app1-fig4-v2.tif"/></fig><fig id="app1fig5" position="float"><label>Appendix 1—figure 5.</label><caption><title>Logistic regression predicting choice from the difference in number of dots between the two circles (∆Dots).</title><p>All participants in the Perceptual Experiment, <italic>fewest</italic> frame, are presented. Light red lines depict the logistic fit calculated using only low confidence trials. Dark red lines show the logistic fit only for high confidence trials. Segmented black line considers the logistic regression calculated with all the trials.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-60705-app1-fig5-v2.tif"/></fig></sec></sec></boxed-text></app><app id="appendix-2"><title>Appendix 2</title><boxed-text><sec id="s9" sec-type="appendix"><title>Choice regression models</title><table-wrap id="app2table1" position="float"><label>Appendix 2—table 1.</label><caption><title>Hierarchical logistic models for choice.</title></caption><table frame="hsides" rules="groups"><thead><tr><th>Models</th><th valign="top">Formulas</th></tr></thead><tbody><tr><td>Model 1</td><td>Choice ~ ∆Value</td></tr><tr><td>Model 2</td><td>Choice ~ ∆Value + Confidence</td></tr><tr><td>Model 3</td><td>Choice ~ ∆Value + Confidence + ΣValue</td></tr><tr><td>Model 4</td><td>Choice ~ ∆Value + Confidence + ΣValue + ∆DT</td></tr><tr><td>Model 5</td><td>Choice ~ ∆Value + Confidence + ΣValue + ∆DT + ∆Value * Confidence</td></tr><tr><td>Model 6</td><td>Choice ~ ∆Value + Confidence + ΣValue + ∆DT + ∆Value * Confidence + ∆Value * ΣValue</td></tr><tr><td>Model 7</td><td>Choice ~ ∆Value + Confidence + ΣValue + ∆DT + ∆Value * Confidence + ∆Value * ΣValue + Confidence * ∆DT</td></tr><tr><td>Model 8</td><td>Choice ~ ∆Value + Confidence + ΣValue + ∆DT + GSF + ∆Value * Confidence + ∆Value * ΣValue + Confidence * ∆DT + ∆Value * GSF</td></tr></tbody></table></table-wrap><p>In Value Experiment: ∆Value: difference in value; ΣValue: summed value; ∆DT: difference in dwell time; GSF: gaze shift frequency. In Perceptual Experiment similar models were compared but replacing ∆Value for ∆Dots and ΣValue for ΣDots.</p><fig id="app2fig1" position="float"><label>Appendix 2—figure 1.</label><caption><title>Model comparison of hierarchical logistic regressions for choice.</title><p>(<bold>A</bold>) Value and (<bold>B</bold>) Perceptual Experiments. Solid colour indicates the Value Experiment and striped colours indicate the Perceptual experiment.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-60705-app2-fig1-v2.tif"/></fig><sec id="s9-1"><title>Value experiment</title><p>Using a logistic hierarchical regression model, we investigated which factors modulated choice-proportion, defined here as the probability of choosing the item on the right side of the screen. We report here the results of the most parsimonious model (i.e. the model with a lowest BIC; <xref ref-type="fig" rid="app2fig1">Appendix 2—figure 1</xref>) fitted to the <italic>like</italic> and <italic>dislike</italic> frames independently (<xref ref-type="fig" rid="fig2">Figure 2B</xref>, <italic>Results</italic> section). In <xref ref-type="table" rid="app2table1">Appendix 2—table 1</xref>, we present the parameters for each factor included in the model. In the <italic>like</italic> frame, the difference in the value of the right item minus left item (∆Value) had a positive influence on choice-proportion, that is, participants selected the items that had higher value. This is reversed in the <italic>dislike</italic> frame: ∆Value is now a <italic>negative</italic> predictor of choice, that is, participants selected the items that had lower value. In both conditions, confidence enhanced the effect of ∆Value, as shown by the interaction between ∆Value and confidence in the <italic>like</italic> and <italic>dislike</italic> frame. These results confirm the findings presented in <xref ref-type="fig" rid="fig1">Figure 1B</xref> (Results section) while controlling for other relevant variables. Unsurprisingly, confidence and summed value (ΣValue, the added value of both alternatives) were found to show no main effect on the choice-proportion. As discussed in the Results section, gaze allocation (difference in dwell time, ∆DT) is directed to the chosen item in both frames, that is, the parameters are positive for ∆DT in <italic>like</italic> and <italic>dislike</italic> frame (<xref ref-type="table" rid="app2table2">Appendix 2—table 2</xref>). </p><table-wrap id="app2table2" position="float"><label>Appendix 2—table 2.</label><caption><title>Statistical results for the hierarchical linear models for choice in Value Experiment.</title><p>Z-values for the regression coefficients and their statistical significance are presented for both frames. To check significant differences of the regression coefficients between like and dislike frames repeated samples t-tests between the participants’ regression coefficients were calculated.</p></caption><table frame="hsides" rules="groups"><thead><tr><th rowspan="3" valign="bottom"/><th colspan="6" valign="bottom">Choice value experiment (n = 31)</th></tr><tr><th colspan="2" valign="bottom">Like</th><th colspan="2" valign="bottom">Dislike</th><th colspan="2" valign="bottom">Like - Dislike</th></tr><tr><th valign="bottom">Z</th><th valign="bottom">P</th><th valign="bottom">Z</th><th valign="bottom">P</th><th valign="bottom">T</th><th valign="bottom">P</th></tr></thead><tbody><tr><td valign="bottom">∆Value</td><td valign="bottom">7.917</td><td valign="bottom">&lt;0.001</td><td valign="bottom">−8.652</td><td valign="bottom">&lt;0.001</td><td valign="bottom">10.74</td><td valign="bottom">&lt;0.001</td></tr><tr><td valign="bottom">∆DT</td><td valign="bottom">6.448</td><td valign="bottom">&lt;0.001</td><td valign="bottom">6.75</td><td valign="bottom">&lt;0.001</td><td valign="bottom">2.31</td><td valign="bottom">&lt;0.05</td></tr><tr><td valign="bottom">∆Value <break/>x Conf</td><td valign="bottom">5.446</td><td valign="bottom">&lt;0.001</td><td valign="bottom">−4.681</td><td valign="bottom">&lt;0.001</td><td valign="bottom">9.55</td><td valign="bottom">&lt;0.001</td></tr></tbody></table><table-wrap-foot><fn><p>*Confidence and ΣValue did not have a significant effect over choice in the regression.</p></fn></table-wrap-foot></table-wrap></sec><sec id="s9-2"><title>Perceptual experiment</title><p>As in the Value Experiment, we used a logistic hierarchical regression to determine the relevant factors modulating perceptual choice (choosing the circle with dots on the right side of the screen) (<xref ref-type="fig" rid="fig2">Figure 2D</xref>, Results section). We found that the most parsimonious model for choice was the same used in the Value Experiment, where <italic>like</italic> and <italic>dislike</italic> were replaced by <italic>most</italic> and <italic>fewest</italic> frames (<xref ref-type="fig" rid="app2fig1">Appendix 2—figure 1B</xref>). In the <italic>most</italic> frame, the difference in the number of dots of the right alternative minus the left one (∆Dots) had a positive influence over choice; that is, participants tended to select the circle with more dots. As expected, this pattern was reversed in the <italic>fewest</italic> frame: ∆Dots was a negative predictor of choice. As in the Value Experiment, confidence modulated the effect of ∆Dots in <italic>most</italic> and <italic>fewest</italic> frames. The sum of dots presented in both circles during a trial (ΣDots) was found not to have a significant effect on either frame, as expected. However, as discussed in the <italic>Results</italic> section, confidence was found to be a negative predictor of choice in <italic>most</italic> and <italic>fewest</italic> frames. This means participants had a bias to report higher confidence when they chose the left circle. In a similar way to the Value Experiment, participants spend more time fixating the chosen alternative in both frames, with ∆DT effect being positive in <italic>most</italic> and <italic>fewest</italic> frames (<xref ref-type="table" rid="app2table3">Appendix 2—table 3</xref>).</p><table-wrap id="app2table3" position="float"><label>Appendix 2—table 3.</label><caption><title>Statistical results for the hierarchical logistic models for choice in Perceptual Experiment.</title><p>Z-values for the regression coefficients and their statistical significance are presented for both frames. Repeated samples t-tests between the participants’ regression coefficients in most and fewest frames were calculated.</p></caption><table frame="hsides" rules="groups"><thead><tr><th rowspan="3" valign="bottom"/><th colspan="6" valign="bottom">Choice perceptual experiment (n = 32)</th></tr><tr><th colspan="2" valign="bottom">Most</th><th colspan="2" valign="bottom">Fewest</th><th colspan="2" valign="bottom">Most - Fewest</th></tr><tr><th valign="bottom">Z</th><th valign="bottom">P</th><th valign="bottom">Z</th><th valign="bottom">P</th><th valign="bottom">T</th><th valign="bottom">P</th></tr></thead><tbody><tr><td valign="bottom">∆Dots</td><td valign="bottom">14.905</td><td valign="bottom">&lt;0.001</td><td valign="bottom">−14.394</td><td valign="bottom">&lt;0.001</td><td valign="bottom">30.32</td><td valign="bottom">&lt;0.001</td></tr><tr><td valign="bottom">Confidence</td><td valign="bottom">−2.823</td><td valign="bottom">&lt;0.01</td><td valign="bottom">−6.705</td><td valign="bottom">&lt;0.001</td><td valign="bottom">6.67</td><td valign="bottom">&lt;0.001</td></tr><tr><td valign="bottom">∆DT</td><td valign="bottom">10.249</td><td valign="bottom">&lt;0.001</td><td valign="bottom">10.449</td><td valign="bottom">&lt;0.001</td><td valign="bottom">−2.17</td><td valign="bottom">&lt;0.05</td></tr><tr><td valign="bottom">∆Dots <break/>x Conf</td><td valign="bottom">8.677</td><td valign="bottom">&lt;0.001</td><td valign="bottom">−6.23</td><td valign="bottom">&lt;0.001</td><td valign="bottom">23.69</td><td valign="bottom">&lt;0.001</td></tr></tbody></table><table-wrap-foot><fn><p>*ΣDots did not have a significant effect over choice in the regression.</p></fn></table-wrap-foot></table-wrap><p>In a study by <xref ref-type="bibr" rid="bib29">Kovach et al., 2014</xref> a design similar to our value-based experiment was implemented. Participants were required to indicate the item to keep and the one to discard. They found, similarly to our findings in the Value Experiment, that the overall pattern of attention was mostly allocated according the task goal. However, in the first few hundred milliseconds, these authors found that attention was directed more prominently to the most valuable item in both conditions. We did not replicate this last finding in our experiment, but one possible reason for this discrepancy is that the experiment by Kovach and colleagues presented both items on the screen at the beginning of the task -- unlike in our task, in which the item was presented in a gaze-contingent way (to avoid processing in the visual periphery). This setting might have triggered an initial and transitory bottom-up attention grab from the most valuable (and often most salient) item before the accumulation process started.</p><fig id="app2fig2" position="float"><label>Appendix 2—figure 2.</label><caption><title><xref ref-type="bibr" rid="bib29">Kovach et al., 2014</xref> conducted a study in which participants have to choose food items in ‘keep’ and ‘discard’ frames, in a similar way to our Value Experiment.</title><p>Gaze allocation was found to gravitate towards the chosen item overall, although during the initial moments of the trial (≈ 500 ms), they reported that gaze was directed towards the preferred item. To check if this effect appears in our Value Experiment we ran a regression model to predict choice (i.e. probability of choosing the item presented on the right side of the screen). We restricted the time to estimate ∆DT to the first 500 ms of the trial and used that variable as a predictor of choice in our model (<bold>A</bold>). We did not find a significant effect of gaze over choice in that period. This difference may be caused by the way the alternatives were presented during the decision time: while in <xref ref-type="bibr" rid="bib29">Kovach et al., 2014</xref> both alternatives were always displayed on screen during deliberation time, in our experiment the presentation was gaze contingent (i.e. participants needed to explore both items at the beginning of the trial to identify the available items). (<bold>B</bold>) We recalculated the model considering the initial 1000 ms of the trial and we observe how ∆DT starts to increase its effect over choice. The positive effect of ∆DT over choice is only significant (z = 1.97, p&lt;0.05) in the <italic>like</italic> frame; in <italic>dislike</italic> frame the small effect is only a trend (z = 1.081, p=0.07). However, at 1000 ms ∆DT is already starting to be allocated to the option coherent with the behavioural responses required by the frame, not to preference.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-60705-app2-fig2-v2.tif"/></fig><fig id="app2fig3" position="float"><label>Appendix 2—figure 3.</label><caption><title>Choice behaviour excluding last fixations.</title><p>To assess the influence that last fixations have on the goal-relevant gaze asymmetries we repeated the hierarchical logistic modelling of choice (probability of choosing right item) in Value (<bold>B</bold>) and Perceptual (<bold>D</bold>) Experiments, excluding the last two fixations from the analysis. Note the two last fixations rather than only the last fixation, because this avoids statistical artifacts. All the results from the main analysis were confirmed: participants preferentially gazed at the item they chose in both frames (positive ∆DT effect in both experiments). All predictors were z-scored at the participant level. In both regression plots, bars depict the fixed-effects and dots the mixed-effects of the regression. Error bars show the 95% confidence interval for the fixed effect. In Value Experiment: ∆Value: difference in value between the two items (Value<sub>right</sub>– Value<sub>left</sub>); RT: reaction time; ΣValue: summed value of both items; ∆DT: difference in dwell time (DT<sub>right</sub>– DT<sub>left</sub>), excluding the last two fixations; Conf: confidence. In Perceptual Experiment: ∆Dots: difference in dots between the two circles (Dots<sub>right</sub>– Dots<sub>left</sub>); ΣDots: summed number of dots between both circles. ***p&lt;0.001, **p&lt;0.01, *p&lt;0.05.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-60705-app2-fig3-v2.tif"/></fig></sec></sec></boxed-text></app><app id="appendix-3"><title>Appendix 3</title><boxed-text><sec id="s10" sec-type="appendix"><title>Fixation analysis</title><p>In the main text, we reported the analysis of last fixation and how its allocation to the (chosen) goal-relevant alternative is modulated by value/number of dots. This result confirmed the findings in <xref ref-type="bibr" rid="bib30">Krajbich et al., 2010</xref> and expanded them to <italic>dislike</italic> frame and the perceptual realm. To give a more complete view of the fixations properties, we additionally performed a similar analysis to <xref ref-type="bibr" rid="bib30">Krajbich et al., 2010</xref> for first and middle fixations.</p><p>It is important to notice that in our Value and Perceptual Experiments, at the beginning of each trial participants do not visualise the options since the presentation is gaze contingent. Therefore, an initial exploration is required to identify the alternatives involved in the decision. In <xref ref-type="bibr" rid="bib30">Krajbich et al., 2010</xref> both options are visible from the beginning of the trial, however, participants’ initial fixation is still randomly allocated.</p><p>For the analysis of middle fixations, if blank fixations were recorded between fixations to the same item, then those fixations were assigned to that item (e.g. ‘Right’, ‘Blank’, ‘Right’ was considered as ‘Right’, ‘Right’, ‘Right’). Trials without middle fixations (i.e. only a first and a last fixation) were removed from the analysis. Trials with no item fixations for more than 40 ms at the beginning of the trial were also removed. In the following figures, results from <xref ref-type="bibr" rid="bib30">Krajbich et al., 2010</xref> are presented together with our findings, as a reference.</p><fig id="app3fig1" position="float"><label>Appendix 3—figure 1.</label><caption><title>Fixation duration by type.</title><p>Middle fixations indicate any fixations that were not the first or last fixations of the trial. (<bold>A</bold>) In <xref ref-type="bibr" rid="bib30">Krajbich et al., 2010</xref> middle fixations were found to be longer than first and last fixations on average. For our Value Experiment, in <italic>like</italic> (<bold>B</bold>) and <italic>dislike</italic> (<bold>C</bold>) frames, and Perceptual Experiment, in <italic>most</italic> (<bold>D</bold>) and <italic>fewest</italic> (<bold>F</bold>) frames, the same pattern emerges with middle usually longer that first and last fixations. Violin plots depict the distribution of participant’s average fixation time. Panel A reproduced from <xref ref-type="bibr" rid="bib30">Krajbich et al., 2010</xref>. ***p&lt;0.001, **p&lt;0.01, *p&lt;0.05.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-60705-app3-fig1-v2.tif"/></fig><fig id="app3fig2" position="float"><label>Appendix 3—figure 2.</label><caption><title>Fixation properties: probability that the first fixation is to the best item.</title><p>(<bold>A</bold>) <xref ref-type="bibr" rid="bib30">Krajbich et al., 2010</xref> reported that the probability is not significantly different from 50%, unaffected by the difference in ratings or difficulty (in our experiments difficulty is equivalent to the absolute difference item value, |ΔValue|, and absolute difference in number of dots, |ΔDots|). A similar pattern emerges in our Value Experiment, for <italic>like</italic> (<bold>B</bold>) and <italic>dislike</italic> (<bold>C</bold>) frames, and Perceptual Experiment, for <italic>most</italic> (<bold>D</bold>) and <italic>fewest</italic> (<bold>F</bold>) frames. Participant responses did not diverge from chance. Importantly, while in <xref ref-type="bibr" rid="bib30">Krajbich et al., 2010</xref> participants can see both alternatives from the beginning of the trial, our presentation was gaze contingent. Segmented blue line indicates chance level. Light grey dots correspond to individual participants’ probability of first fixation to high value/number of dots alternatives for each bin. Red or blue circles indicate the average for that bin considering all the participants. Panel A reproduced from <xref ref-type="bibr" rid="bib30">Krajbich et al., 2010</xref>.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-60705-app3-fig2-v2.tif"/></fig><fig id="app3fig3" position="float"><label>Appendix 3—figure 3.</label><caption><title>Fixation properties: middle fixation duration as a function of the rating (value or number of dots) of the fixated item.</title><p>(<bold>A</bold>) <xref ref-type="bibr" rid="bib30">Krajbich et al., 2010</xref> reported that middle fixations durations were independent of the value of the fixated items. In Value Experiment, we found that middle fixation duration was independent of the value of the fixated item in <italic>like</italic> frame (<bold>B</bold>); however, a slight yet significant effect in <italic>dislike</italic> (<bold>C</bold>) frame was found (hierarchical linear regression estimate: β<sub>Dislike</sub> = 0.025, t(27.35) = 3.441, p&lt;0.001). In the Perceptual Experiment, for the <italic>most</italic> (<bold>D</bold>) frame we found a significant effect of fixated value (β<sub>Most</sub> = 0.017, t(29.51) = 3.013, p&lt;0.01), but not for <italic>fewest</italic> (<bold>F</bold>) frame. Light grey dots correspond to individual participants’ middle fixation durations for each bin. Red or blue circles indicate the average for that bin considering all the participants. For the hierarchical linear regression, z-scored data at participant levels was used. Panel A reproduced from <xref ref-type="bibr" rid="bib30">Krajbich et al., 2010</xref>.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-60705-app3-fig3-v2.tif"/></fig><fig id="app3fig4" position="float"><label>Appendix 3—figure 4.</label><caption><title>Fixation properties: middle fixation duration as a function of the difference in ratings (value or number of dots) between the fixated and unfixated items.</title><p>(<bold>A</bold>) <xref ref-type="bibr" rid="bib30">Krajbich et al., 2010</xref> reported a slight but significant dependency of middle fixations durations on the difference in value between items. In our Value Experiment, we found that in <italic>like</italic> (<bold>B</bold>) and <italic>dislike</italic> (<bold>C</bold>) this relationship was significant (hierarchical linear regression estimate: β<sub>Like</sub> = 0.015, t(28.22) = 2.192, p&lt;0.05; β<sub>Dislike</sub> = -0.027, t(28.22) = -4.415, p&lt;0.001). Similarly, in the Perceptual Experiment, <italic>most</italic> (<bold>D</bold>) and <italic>fewest</italic> (<bold>F</bold>) frames, the dependence was found also significant (β<sub>Most</sub> = 0.01, t(29.51) = 2.663, p&lt;0.01; β<sub>Few</sub> = -0.027, t(29.51) = -6.330, p&lt;0.001). Interestingly, a positive sign of the effect in <italic>like</italic> and <italic>most</italic> frames indicates that middle fixations tend to be longer for the option with the higher value or number of dots. On the other hand, the negative sign of the effect indicates that middle fixations would be longer for the option with lower value or number of dots in <italic>dislike</italic> and <italic>fewest</italic> frames. Light grey dots correspond to individual participants’ middle fixation durations for each bin. Full red or blue circles indicate participant’s average. Data are binned across participants for visualisation. All the factors and the predicted variable in the hierchical regression were z-scored at participant level. Panel A reproduced from <xref ref-type="bibr" rid="bib30">Krajbich et al., 2010</xref>.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-60705-app3-fig4-v2.tif"/></fig><fig id="app3fig5" position="float"><label>Appendix 3—figure 5.</label><caption><title>Fixation properties: middle fixation duration as a function of the difference in ratings between the best- and worst-rated items (difficulty of the trial).</title><p>In our experiments, |ΔValue| and |ΔDots| represent the difficulty of the trials. (<bold>A</bold>) <xref ref-type="bibr" rid="bib30">Krajbich et al., 2010</xref> reported a dependency of middle fixations durations on difficulty, with longer fixations in more difficult decisions. In our Value Experiment, in <italic>like</italic> (<bold>B</bold>) and <italic>dislike</italic> (<bold>C</bold>) frames a similar pattern was found: longer middle fixations for more difficult (lower |ΔValue|) trials (hierarchical linear regression estimate: β<sub>Like</sub> = -0.029, t(28.22) = -2.262, p&lt;0.05; β<sub>Dislike</sub> = -0.047, t(28.22) = -4.415, p&lt;0.001). The same relationship was found only in the <italic>most</italic> frame (<bold>D</bold>) but no in the <italic>fewest</italic> frame (<bold>F</bold>) in the Perceptual Experiment (β<sub>Most</sub> = -0.037, t(29.51) = -3.985, p&lt;0.001; β<sub>Few</sub> = -0.024, t(29.51) = -1.623, p=0.10). Light grey dots correspond to individual participants’ middle fixation durations for each bin. Full red or blue circles indicate participant’s average. Data are binned across participants for visualisation. All the factors and the predicted variable in the hierchical regression were z-scored at participant level. Panel A reproduced from <xref ref-type="bibr" rid="bib30">Krajbich et al., 2010</xref>. Tests presented here are based on a paired two-sided t-test between the first and last bin.***p&lt;0.001, **p&lt;0.01, *p&lt;0.05.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-60705-app3-fig5-v2.tif"/></fig></sec></boxed-text></app><app id="appendix-4"><title>Appendix 4</title><boxed-text><sec id="s11" sec-type="appendix"><title>Confidence regression models</title><table-wrap id="app4table1" position="float"><label>Appendix 4—table 1.</label><caption><title>Hierarchical linear models for confidence.</title></caption><table frame="hsides" rules="groups"><thead><tr><th>Models</th><th valign="top">Formulas</th></tr></thead><tbody><tr><td>Model 1</td><td>Confidence ~ |∆Value|</td></tr><tr><td>Model 2</td><td>Confidence ~ |∆Value| + RT</td></tr><tr><td>Model 3</td><td>Confidence ~ |∆Value| + RT + GSF</td></tr><tr><td>Model 4</td><td>Confidence ~ |∆Value| + RT + GSF + ΣValue</td></tr><tr><td>Model 5</td><td>Confidence ~ |∆Value| + RT + GSF + ΣValue + ∆DT</td></tr></tbody></table></table-wrap><p>In Value Experiment: |∆Value|: absolute difference in value; RT: reaction time; ΣValue: summed value; ∆DT: difference in dwell time; GSF: gaze shift frequency. In Perceptual Experiment similar models were compared, but replacing ∆Value for ∆Dots and ΣValue for ΣDots.</p><fig id="app4fig1" position="float"><label>Appendix 4—figure 1.</label><caption><title>Model comparison of hierarchical linear regressions for confidence.</title><p>(<bold>A</bold>) Value and (<bold>B</bold>) Perceptual Experiments. Solid colour indicates the value-based experiment and striped colours indicate the perceptual experiment.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-60705-app4-fig1-v2.tif"/></fig><table-wrap id="app4table2" position="float"><label>Appendix 4—table 2.</label><caption><title>Statistical results for the hierarchical linear models for confidence in Value Experiment.</title><p>Z-values for the regression coefficients and their statistical significance are presented for the two frames. Repeated samples t-tests between the participants’ regression coefficients in like and dislike frames were calculated.</p></caption><table frame="hsides" rules="groups"><thead><tr><th rowspan="3" valign="bottom"/><th colspan="6" valign="bottom">Confidence value experiment</th></tr><tr><th colspan="2" valign="bottom">Like</th><th colspan="2" valign="bottom">Dislike</th><th colspan="2" valign="bottom">Like - Dislike</th></tr><tr><th valign="bottom">Z</th><th valign="bottom">P</th><th valign="bottom">Z</th><th valign="bottom">P</th><th valign="bottom">T</th><th valign="bottom">P</th></tr></thead><tbody><tr><td valign="bottom">|∆Value|</td><td valign="bottom">5.465</td><td valign="bottom">&lt;0.001</td><td valign="bottom">6.3</td><td valign="bottom">&lt;0.001</td><td valign="bottom">−4.72</td><td valign="bottom">&lt;0.01</td></tr><tr><td valign="bottom">RT</td><td valign="bottom">−6.373</td><td valign="bottom">&lt;0.001</td><td valign="bottom">−7.739</td><td valign="bottom">&lt;0.001</td><td valign="bottom">ns</td><td valign="bottom"/></tr><tr><td valign="bottom">GSF</td><td valign="bottom">−2.365</td><td valign="bottom">&lt;0.05</td><td valign="bottom">−2.589</td><td valign="bottom">&lt;0.05</td><td valign="bottom">ns</td><td valign="bottom"/></tr><tr><td valign="bottom">ΣValue</td><td valign="bottom">3.206</td><td valign="bottom">&lt;0.001</td><td valign="bottom">−4.492</td><td valign="bottom">&lt;0.001</td><td valign="bottom">9.91</td><td valign="bottom">&lt;0.001</td></tr></tbody></table></table-wrap><table-wrap id="app4table3" position="float"><label>Appendix 4—table 3.</label><caption><title>Statistical results for the hierarchical linear models for confidence in Perceptual Experiment.</title><p>Z-values for the regression coefficients and their statistical significance are presented for the two frames. Repeated samples t-tests between the participants’ regression coefficients in most and fewest frames were calculated.</p></caption><table frame="hsides" rules="groups"><thead><tr><th rowspan="3" valign="bottom"/><th colspan="6" valign="bottom">Confidence perceptual experiment</th></tr><tr><th colspan="2" valign="bottom">Most</th><th colspan="2" valign="bottom">Fewest</th><th colspan="2" valign="bottom">Most - Fewest</th></tr><tr><th valign="bottom">Z</th><th valign="bottom">P</th><th valign="bottom">Z</th><th valign="bottom">P</th><th valign="bottom">T</th><th valign="bottom">P</th></tr></thead><tbody><tr><td valign="bottom">|∆Value|</td><td valign="bottom">3.546</td><td valign="bottom">&lt;0.001</td><td valign="bottom">7.571</td><td valign="bottom">&lt;0.001</td><td valign="bottom">−4.554</td><td valign="bottom">&lt;0.001</td></tr><tr><td valign="bottom">RT</td><td valign="bottom">−7.599</td><td valign="bottom">&lt;0.001</td><td valign="bottom">−5.51</td><td valign="bottom">&lt;0.001</td><td valign="bottom">ns</td><td valign="bottom"/></tr><tr><td valign="bottom">GSF</td><td valign="bottom">−4.354</td><td valign="bottom">&lt;0.001</td><td valign="bottom">−5.204</td><td valign="bottom">&lt;0.001</td><td valign="bottom">ns</td><td valign="bottom"/></tr><tr><td valign="bottom">ΣDots</td><td valign="bottom"><italic>2.061</italic></td><td valign="bottom">&lt;0.05</td><td valign="bottom">−7.135</td><td valign="bottom">&lt;0.001</td><td valign="bottom">14.621</td><td valign="bottom">&lt;0.001</td></tr></tbody></table></table-wrap></sec></boxed-text></app><app id="appendix-5"><title>Appendix 5</title><boxed-text><sec id="s12" sec-type="appendix"><title>GLAM – model comparison and out-of-sample simulations</title><fig id="app5fig1" position="float"><label>Appendix 5—figure 1.</label><caption><title>GLAM model comparison.</title><p>(<bold>A</bold>) Average WAIC scores for <italic>like</italic> and <italic>dislike</italic> GLAM models fitted at individual level. In the <italic>dislike</italic> frame, two possible models are compared: preference-value, value reported in the BDM bid was used directly to fit the data; and frame-value, value was adjusted to comply with the frame modification (see Methods for more details). The model accounting for goal-relevant evidence in the <italic>dislike</italic> frame had a better fit. (<bold>B</bold>) Individual WAIC differences between <italic>dislike</italic> models fitted with frame-value and preference-value. Negative differences indicate best fits for the frame-value in all the participants. (<bold>C</bold>) Average WAIC scores for <italic>most</italic> and <italic>fewest</italic> GLAM models fitted at individual level. In the <italic>fewest</italic> frame, two possible models are compared: default-evidence, the number of dots was used directly to fit the data, and frame-evidence, evidence was adjusted to comply with the frame modification (i.e. the opposite of the number of dots was used as evidence). (<bold>D</bold>) Individual WAIC differences between <italic>fewest</italic> models fitted with frame-evidence and default-evidence. Negative differences indicate best fits for the frame-evidence in all the participants. Solid colour indicates the value-based experiment and striped colours indicate the perceptual experiment.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-60705-app5-fig1-v2.tif"/></fig><fig id="app5fig2" position="float"><label>Appendix 5—figure 2.</label><caption><title>Hierarchical GLAM model comparison.</title><p>(<bold>A</bold>) Value Experiment. WAIC scores for <italic>like</italic> and <italic>dislike</italic> GLAM models fitted hierarchically. In the <italic>dislike</italic> frame, two possible models are compared: preference-value, input values corresponding to the preferences reported at the beginning of the experiment (BDM bid); and frame-value, in which value was adjusted to comply with the frame modification (see Methods for more details). In <italic>dislike</italic> frame, the model accounting for goal-relevant resulted the most parsimonious of the two. (<bold>B</bold>) Perceptual Experiment. WAIC scores for <italic>most</italic> and <italic>fewest</italic> GLAM models fitted hierarchically. In the <italic>fewest</italic> frame, two possible models are compared: default-evidence, the number of dots was used directly to fit the data, and frame-evidence, evidence was adjusted to comply with the frame modification (i.e. the opposite of the number of dots was used as evidence).</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-60705-app5-fig2-v2.tif"/></fig><fig id="app5fig3" position="float"><label>Appendix 5—figure 3.</label><caption><title>Individual out-of-sample prediction from the GLAM model for behavioural measures in Value (<italic>dislike</italic>) (<bold>A–C</bold>) and Perceptual (<italic>fewest</italic>) Experiments (<bold>D–F</bold>).</title><p>In the <italic>dislike</italic> frame, two models are used to generate simulations: preference-value, value reported in the BDM bid was used directly to fit GLAM model; and frame-value, the values were adjusted to comply with the frame modification. The model predicts participants mean reaction time (RT) (<bold>A</bold>), probability of choosing the best item (i.e. item with lower value) (<bold>B</bold>) and the influence of gaze in choice probability (C, check Results section for more details on gaze influence measure). The frame-value model correlates better with the observed data. In the Perceptual Experiment, <italic>fewest</italic> frame, also two possible models are used to generate simulations: default-evidence, the number of dots was used directly to fit the data, and frame-evidence, the evidence was adjusted to comply with the context modification (i.e. opposite of the number of dots). We show the correlation between the data and simulations for RT (<bold>D</bold>), the probability of choosing the best alternative (i.e. alternative with fewer dots) (<bold>E</bold>) and gaze influence (<bold>F</bold>). In this case, frame-evidence model also predicts the behaviour in the <italic>fewest</italic> frame better. The results corresponding to the models using frame-evidence are presented in red and the models using default-evidence in pink. Dots depict the average of predicted and observed measures for each participant. Lines depict the slope of the correlation between observations and the predictions. The shadowed region presents the 95% confidence intervals, with full colour representing Value Experiment and striped colour the Perceptual Experiment. Model predictions are simulated using parameters estimated from individual fits for even-numbered trials.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-60705-app5-fig3-v2.tif"/></fig><fig id="app5fig4" position="float"><label>Appendix 5—figure 4.</label><caption><title>Replication of behavioural effect of interest by simulations using the GLAM fitted for <italic>like</italic> (<bold>A</bold>) and <italic>most</italic> frames (<bold>B</bold>).</title><p>The four panels present four relevant behavioural relationships found in the data: (top left) faster responses (shorter RT) when the choice is easier (i.e. easier choices are found with higher |ΔValue| in value-based and higher |ΔDots| in perceptual); (top right) probability of choosing the right alternative increases when the difference in evidence (value or number of dots) is higher in the alternative at the right side of the screen (ΔValue and ΔDots are calculated considering right minus left options); (bottom left) the probability of choosing an alternative depends on the gaze difference; and (bottom right) the gaze influence on choice depending on the difference in gaze time between both alternatives. Solid blue dots depict the mean of the data across participants in <italic>like</italic> and <italic>most</italic> frames. Light blue dots present the mean value for each participant. In the Value Experiment, the solid grey lines show the average for model simulations. In the Perceptual Experiment, segmented grey lines show the model simulations. Data are binned for visualisation.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-60705-app5-fig4-v2.tif"/></fig><fig id="app5fig5" position="float"><label>Appendix 5—figure 5.</label><caption><title>Replication of behavioural effect of interest by simulations using the GLAM fitted for <italic>dislike</italic> (<bold>A</bold>) and <italic>fewest</italic> frames (<bold>B</bold>).</title><p>Frame-relevant evidence was used to fit the model. The four panels present four relevant behavioural relationships found in the data. Top left: faster responses (shorter RT) when the choice is easier (i.e. easier choices are found with higher |ΔValue| in value-based and higher |ΔDots| in perceptual). Top right: probability of choosing the right alternative increases when the difference in evidence (value or number of dots) is lower in the alternative at the right side of the screen (notice that -ΔValue and -ΔDots are calculated considering left minus right options). Bottom left: the probability of choosing the right alternative depends on the gaze difference favouring the right option. Bottom right: the gaze influence on choice depending on the difference in gaze time between both alternatives. Solid red dots depict the mean of the data across participants in <italic>dislike</italic> and <italic>fewest</italic> frames. Light red dots present the mean value for each participant. In the Value Experiment, the solid grey lines show the average for model simulations. In the Perceptual Experiment, segmented grey lines show the model simulations. Data are binned for visualisation.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-60705-app5-fig5-v2.tif"/></fig><fig id="app5fig6" position="float"><label>Appendix 5—figure 6.</label><caption><title>Replication of behavioural effect of interest by simulations using the GLAM fitted for <italic>dislike</italic> (<bold>A</bold>) and <italic>fewest</italic> frames (<bold>B</bold>).</title><p>In this case, the models were fitted without adapting the values and dot numbers to the evidence that was relevant for the particular frame, that is the preference value and the default number of dots were used to fit the model in the <italic>dislike</italic> and <italic>fewest</italic> frame, respectively. The four panels present four relevant behavioural relationships found in the data. Top left: faster responses (shorter RT) when the choice is easier (i.e. easier choices are found with higher |ΔValue| in value-based and higher |ΔDots| in perceptual). Top right: probability of choosing the right alternative increases when the difference in evidence (value or number of dots) is lower in the alternative at the right side of the screen (ΔValue and ΔDots are calculated consider right minus left options). Bottom left: the probability of choosing the right alternative depends on the gaze difference favouring the right option. Bottom right: the gaze influence on choice depending on the difference in gaze time between both alternatives. No replication of the behavioural effect was found in this case for the relationship between RT -|ΔValue| and RT -|ΔDots| in <italic>dislike</italic> and <italic>fewest</italic> frames, respectively. Also P(right item)-ΔValue and P(right item)-ΔDots relationship was not replicated in <italic>dislike</italic> and <italic>fewest</italic> frames, respectively. Gaze effect seem to still keep its relationship, since gaze allocation time was not modified to account for the frame shift. Solid red dots depict the mean of the data across participants in <italic>dislike</italic> and <italic>fewest</italic> frames. Light red dots present the mean value for each participant. In the Value Experiment, the solid grey lines show the average for model simulations. In the Perceptual Experiment, segmented grey lines show the model simulations. Data are binned for visualisation.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-60705-app5-fig6-v2.tif"/></fig></sec></boxed-text></app><app id="appendix-6"><title>Appendix 6</title><boxed-text><sec id="s13" sec-type="appendix"><title>GLAM – parameter comparison</title><p>The results from the regression models presented in the <italic>Results</italic> section show that the nature of evidence integrated during the accumulation process depends on the frame in which participants make their choices. The Gaze-weighted Linear Accumulator Model (GLAM) predicts well participants’ behaviour once frame-relevant evidence is employed to fit the model. Here we show the parameters obtained from this process. Four free parameters are fitted in GLAM: ν (drift term), γ (gaze bias), τ (evidence scaling), and σ (normally distributed noise standard deviation) (<xref ref-type="bibr" rid="bib45">Thomas et al., 2019</xref>). For Value and Perceptual Experiments, we fitted the model in both frames and in each participant separately. The parameters were fitted using the even-numbered trials and in both studies the model fit was estimated using the WAIC score (used with Bayesian Models) (<xref ref-type="fig" rid="app5fig1">Appendix 5—figure 1</xref>).</p><sec id="s13-1"><title>Value experiment</title><p>To explore variations in the process of accumulation of evidence characterised by GLAM, we compared the parameters obtained from the individual fit in <italic>like</italic> and <italic>dislike</italic> frames (<xref ref-type="fig" rid="app6fig1">Appendix 6—figure 1A</xref>). No significant variation between frames was found for the gaze bias (Mean γ <sub>Like</sub> = -0.14, Mean γ <sub>Dislike</sub> = 0.03, ∆γ <sub>Like-Dislike</sub> = -0.17, t(30) = -1.66; p=0.11, ns), the scaling parameter (τ <sub>Like</sub> = 2.81, τ<sub>Dislike</sub> = 2.69, ∆τ<sub>Like-Dislike</sub> = 0.115, t(30) = 0.313; p=0.75, ns), and the noise term (Mean σ<sub>Like</sub> = 0.0075, Mean σ <sub>Dislike</sub> = 0.0074, ∆σ<sub>Like-Dislike</sub> = 0.00012, t(30) = 0.342; p=0.734, ns). We observed a significantly higher value of the drift term, ν, during the <italic>like</italic> frame (ν<sub>Like</sub> = 5.60x10<sup>−5</sup>, ν<sub>Dislike</sub> = 4.53x10<sup>−5</sup>, ∆ν<sub>Like-Dislike</sub> = 1.06 x 10<sup>−5</sup>, t(30) = 3.44; p&lt;0.01). This means that evidence is accumulated faster during the <italic>like</italic> frame, which gives us an insight into the differences in the evidence accumulation product of the change frame modification.</p></sec><sec id="s13-2"><title>Perceptual experiment</title><p>We also compared the parameters obtained from GLAM individual fit in the perceptual experiment (<xref ref-type="fig" rid="app6fig1">Appendix 6—figure 1B</xref>). No significant variation between frames was found for the scaling parameter (τ<sub>Most</sub> = 0.34, τ<sub>Few</sub> = 0.13, ∆τ <sub>Most-Few</sub> = 0.212, t(27) = 1.43; p=0.16, ns) or the drift term (Mean ν<sub>Most</sub> = 3.8x10<sup>−5</sup>, Mean ν <sub>Few</sub> = 3.99x10<sup>−5</sup>, ∆ν<sub>Most-Few</sub> = -1.92x10<sup>−6</sup>, t(27) = -0.465; p=0.645, ns). The gaze bias is larger during the <italic>fewest</italic> frame (γ<sub>Most</sub> = 0.48, γ<sub>Few</sub> = 0.26, ∆γ<sub>Most-Few</sub> = 0.22, t(27) = 2.61; p&lt;0.05). The σ parameter is also significantly different depending on the frame, with higher noise in the <italic>most</italic> frame (σ<sub>Most</sub> = 0.0073, σ<sub>Few</sub> = 0.0066, ∆σ <sub>Most-Few</sub> = 0.0007, t(27) = 2.26; p&lt;0.05). In summary, the accumulation process seems to be noisier and less affected by visual attention in the <italic>most</italic> frame. In both frames, the finding that γ &lt; 1 indicates that gaze modulates the accumulation of evidence.</p><fig id="app6fig1" position="float"><label>Appendix 6—figure 1.</label><caption><title>Parameters fitted at subject level using GLAM in Value (<bold>A</bold>) and Perceptual (<bold>B</bold>) Experiments.</title><p>The free parameters are γ (gaze bias), τ (evidence scaling), ν (drift term), and σ (standard deviation of the normally distributed noise). In the Value Experiment, we found a significant decrease in the drift term during the <italic>dislike</italic> frame, maybe indicating a more uncertain decision process. The parameters in Perceptual Experiment were significantly different for gaze bias and noise term, with higher γ and σ values in the <italic>most</italic> frame. This may indicate a reduced effect of gaze on choice during the <italic>most</italic> frame and slightly less noisier accumulation process in the <italic>fewest</italic> frame. In each experiment, the GLAM parameters were fitted independently for each frame. In the violin plot, red and blue areas indicate the distribution of the parameters across participants. Black bars present the 25, 50, and 75 percentiles of the data. Solid colour indicates the Value Experiment and striped colours indicate the Perceptual Experiment.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-60705-app6-fig1-v2.tif"/></fig><fig id="app6fig2" position="float"><label>Appendix 6—figure 2.</label><caption><title>GLAM model parameters when the model fit is performed constraining γ to [0,1] range.</title><p><xref ref-type="bibr" rid="bib45">Thomas et al., 2019</xref> describes a ‘leakage’ of evidence when γ &lt; 0, which can be a conflicting assumption in this type of models. We corroborated that the differences between the parameters in <italic>like</italic>/<italic>dislike</italic> and <italic>most</italic>/<italic>fewest</italic> remain the same in comparison to the fit reported constraining γ to [−1,1].</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-60705-app6-fig2-v2.tif"/></fig></sec></sec></boxed-text></app><app id="appendix-7"><title>Appendix 7</title><boxed-text><sec id="s14" sec-type="appendix"><title>Attentional drift diffusion model</title><p>The attentional Drift Diffusion Model (aDDM) has been extensively used in literature to characterise the effect of attention over choice (<xref ref-type="bibr" rid="bib30">Krajbich et al., 2010</xref>). Unlike GLAM, aDDM considers the dynamics of fixations during trials to fit the model. To further support our idea that goal-relevant evidence is accumulated, we fitted both Value and Perceptual datasets with the aDDM model, as implemented by <xref ref-type="bibr" rid="bib44">Tavares et al., 2017</xref> (aDDM toolbox, <ext-link ext-link-type="uri" xlink:href="https://github.com/goptavares/aDDM-Toolbox">https://github.com/goptavares/aDDM-Toolbox</ext-link>).</p><p>The aDDM model assumes that evidence is accumulated dynamically in a variable called the relative decision value (RDV) signal. RDV starts at 0 and it evolves over time, accumulating evidence until a barrier is reached (+1 or −1) which will define the alternative to be selected (right or left). Every time step, RDV changes according to μΔ<italic>t</italic> + ε<italic>t</italic>, with μ the deterministic change (slope term) and ε the Gaussian noise term. The fixation to the two alternatives will define the value of μ: when the left option is fixated μ = <italic>d</italic>(<italic>r</italic><sub>left</sub> − <italic>θr</italic><sub>right</sub>) and μ = <italic>d</italic>(<italic>r</italic><sub>right</sub> − <italic>θr</italic><sub>left</sub>) for the right option. Therefore, the aDDM model considers three free parameters: d, σ, and <italic>θ</italic>. The parameter d is a positive constant characterising the speed of integration; σ is the standard deviation for a zero-mean Gaussian distribution for noise, and θ is the attentional parameter that controls the size of the attentional bias (range between 0 and 1). If θ = 1, the model is reduced to a standard drift-diffusion model (DDM) without attentional bias.</p><sec id="s14-1"><title>Group model fitting</title><p>The models were fitted to choice and RT data independently for <italic>like</italic> and <italic>dislike</italic> frames in our Value Experiment and for <italic>most</italic> and <italic>fewest</italic> frames in the Perceptual Experiment. The odd trials of the pooled data from 31 participants in value-based data and 32 participants for perceptual case was used to fit the models. The model considers the available evidence (item value and number of dots) and the sequence of fixations for each trial. As in GLAM, we fitted the parameters in <italic>dislike</italic> and <italic>fewest</italic> frames considering a version of the input values/evidence that accounted for the change in the objective of the task (i.e. reporting item not preferred or the alternatives with fewer dots, respectively). To compare, we also fitted another model using the evidence ‘by default’ (i.e. BDM bid values or number of dots in the circles). To account for the different ranges of item valuation used by the participants we normalised the value reports by binning at a participant level. In the Value Experiment, the data were separated in six bins using quantiles-based discretisation. In the Perceptual Experiment, given the distribution of the evidence (i.e three numerosity levels and smaller dots differences between two alternatives), we separated the dots data in eight bins. The maximum likelihood estimation (MLE) procedure was carried in iterative steps searching over a grid with the three model parameters. Initial grid was set to [0.001, 0.005, 0.01] for d, [0.01, 0.05, 0.1] for σ and [0.01, 0.5, 1] for θ. The likelihood for choice and RT in odd-trials, conditional to the pattern of fixations, was calculated for each combination of parameters in the grid (check <xref ref-type="bibr" rid="bib44">Tavares et al., 2017</xref> for the details of the algorithm to simulate aDDM trials). The time step used for the estimation of aDDM was 10 ms. The set of parameters with lower negative log-likelihood (NLL) was used as centre of the grid for the next iteration. Therefore, the grid to search in the next iteration (t+1) was defined as [d<sub>t </sub>− Δd<sub>t</sub>/2, d<sub>t</sub>, d<sub>t </sub>+ Δd<sub>t</sub>/2], [θ<sub>t </sub>− Δθ<sub>t</sub>/2, θ<sub>t</sub>, θ<sub>t</sub> + Δθ<sub>t</sub>/2], and [σ<sub>t </sub>− Δσ<sub>t</sub>/2, σ<sub>t</sub>, σ<sub>t</sub>+Δσ<sub>t</sub>/2], considering the respective constrains of each parameter value. The iterative process finished once the improvement in the MLE of the proposed parameter solution was smaller than 0.05% (|minNNL<sub>t+1</sub> – minNNL<sub>t</sub>| &lt; 0.0005*minNNL<sub>t</sub>). The convergence was reached after two iterations in our models. In our results <xref ref-type="table" rid="app7table1">Appendix 7—table 1</xref>), we found that for both, <italic>dislike</italic> and <italic>fewest</italic> conditions, the model fitted using goal-relevant evidence had better performance than the model using default value or number of dots, as indicated by a lower NLL value.</p><table-wrap id="app7table1" position="float"><label>Appendix 7—table 1.</label><caption><title>aDDM model parameters.</title><p>Estimated parameters for Value and Perceptual Experiments. Parameter description - d: speed of integration; σ: standard deviation for the noise distribution, θ: attentional bias. NNL: negative log-likelihood of the models indicating goodness-of-fit.</p></caption><table frame="hsides" rules="groups"><thead><tr><th/><th colspan="3">Value-based</th><th colspan="3">Perceptual</th></tr><tr><th/><th>Like</th><th>Dislike Preference-values</th><th>Dislike Frame-values</th><th>Most</th><th>Fewest <break/>Default-evidence</th><th>Fewest Frame-evidence</th></tr></thead><tbody><tr><td>d</td><td>0.001</td><td>0</td><td>0.001</td><td>0.001</td><td>0.001</td><td>0.001</td></tr><tr><td>σ</td><td>0.05</td><td>0.05</td><td>0.05</td><td>0.05</td><td>0.05</td><td>0.05</td></tr><tr><td><italic>θ</italic></td><td>0</td><td>0</td><td>0</td><td>0.255</td><td>0</td><td>0.01</td></tr><tr><td>NLL</td><td>12441.012*</td><td>13342.297</td><td>12640.837*</td><td>13948.411*</td><td>14169.154</td><td>13826.983*</td></tr></tbody></table><table-wrap-foot><fn><p>*Indicates the model with lower NLL for that frame</p></fn></table-wrap-foot></table-wrap></sec><sec id="s14-2"><title>Out-of-sample group simulations</title><p>To test the capacity of the model to predict out-of- sample, the aDDM with the best fitted parameters using odd-numbered trials was used to predict the behaviour observed on the even-numbered trials. We generated 40,000 simulations for the Value Experiment and 48,000 trials for the Perceptual Experiment. Fixations, latencies and inter-fixations transitions were sampled from empirical distributions, obtained from the pooled even-numbered trials across participants following the procedure used by <xref ref-type="bibr" rid="bib44">Tavares et al., 2017</xref>.</p><fig id="app7fig1" position="float"><label>Appendix 7—figure 1.</label><caption><title>Replication of behavioural effects by aDDM simulations for <italic>like</italic> (<bold>A</bold>) and <italic>most</italic> frames (<bold>B</bold>).</title><p>The four panels present four relevant behavioural relationships found in the data. Top left: faster responses (shorter reaction time, RT) when the choice is easier (i.e. easier choices are found with higher |ΔValue| and |ΔDots| in Value an Perceptual Experiments, respectively). Top right: probability of choosing the right alternative increases when the evidence towards the right item is higher (ΔValue and ΔDots are calculated considering right minus left options). Bottom left: the probability of choosing the item on the right side of the screen depends on the gaze time difference (ΔGaze, calculated as the time observing the right minus the left item). Bottom right: gaze influence on choice depending on the difference in ΔGaze (check Results section for more details on gaze influence). Solid blue dots depict the mean of the data across participants in <italic>like</italic> and <italic>most</italic> frames. Light blue dots show the mean value for each participant. In Value Experiment, the solid grey lines show the average for model simulations. In the Perceptual Experiment, segmented grey lines show the average for model simulations. Data and simulations were binned for visualisation.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-60705-app7-fig1-v2.tif"/></fig><fig id="app7fig2" position="float"><label>Appendix 7—figure 2.</label><caption><title>Replication of behavioural effects by aDDM simulations for <italic>dislike</italic> (<bold>A</bold>) and <italic>fewest</italic> (<bold>B</bold>) frames.</title><p>Importantly, these models were fitted using goal-relevant evidence. The four panels present four relevant behavioural relationships found in the data. Top left: faster responses (shorter reaction time, RT) when the choice is easier (i.e. easier choices are found with higher |ΔValue| and |ΔDots| in Value and Perceptual Experiments, respectively). Top right: probability of choosing the right alternative increases when the evidence towards the left item is higher (-ΔValue and –ΔDots, that is, increment when left item is more valuable or has more dots than the right item). Bottom left: the probability of choosing the item on the right side of the screen depends on the gaze time difference (ΔGaze, calculated as the time observing the right minus the left item). Bottom right: gaze influence on choice depending on the difference in ΔGaze (check Results section for more details on gaze influence). Solid red dots depict the mean of the data across participants in <italic>dislike</italic> and <italic>fewest</italic> frames. Light red dots show the mean value for each participant. In Value Experiment, the solid grey lines show the average for model simulations. In the Perceptual Experiment, segmented grey lines show the average for model simulations. Data and simulations were binned for visualisation.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-60705-app7-fig2-v2.tif"/></fig><fig id="app7fig3" position="float"><label>Appendix 7—figure 3.</label><caption><title>Replication of behavioural effects by aDDM simulations for <italic>dislike</italic> (<bold>A</bold>) and <italic>fewest</italic> frames (<bold>B</bold>).</title><p>Importantly, these models were fitted using the default evidence in Value and Perceptual Experiments, that is, preference value and number of dots, respectively. Unlike the models fitted with goal-relevant evidence, these models do not capture reaction time (RT) and choice behaviour in dislike and fewest frames. The four panels present four relevant behavioural relationships found in the data. Top left: faster responses (shorter RT) when the choice is easier (i.e. easier choices are found with higher |ΔValue| and |ΔDots| in Value an Perceptual Experiments, respectively). Top right: probability of choosing the right alternative increases when the evidence towards the left item is higher (ΔValue and ΔDots are calculated considering right minus left options). Bottom left: the probability of choosing the item on the right side of the screen depends on the gaze time difference (ΔGaze, calculated as the time observing the right minus the left item). Bottom right: gaze influence on choice depending on the difference in ΔGaze (check Results section for more details on gaze influence). Solid red dots depict the mean of the data across participants in <italic>dislike</italic> and <italic>fewest</italic> frames. Light blue dots show the mean value for each participant. In Value Experiment, the solid grey lines show the average for model simulations. In the Perceptual Experiment, segmented grey lines show the average for model simulations. Data and simulations were binned for visualisation.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-60705-app7-fig3-v2.tif"/></fig></sec></sec></boxed-text></app><app id="appendix-8"><title>Appendix 8</title><boxed-text><sec id="s15" sec-type="appendix"><title>GLAM – balance of evidence simulations</title><fig id="app8fig1" position="float"><label>Appendix 8—figure 1.</label><caption><title>Balance of evidence simulations in the Value Experiment.</title><p>The difference between accumulators (Δe) obtained from GLAM simulations matches participants’ confidence. Top left: a higher value difference between the two items (|ΔValue|) increases confidence and simulated Δe. Top right: in the <italic>like</italic> frame, an increase in the summed value of the two alternatives (|ΣValue|) boosts confidence and simulated Δe. Bottom left: as in <italic>like</italic> frame, |ΔValue| boosted confidence and Δe in <italic>dislike</italic> frame. Bottom right: in the <italic>dislike</italic> frame, the effect of |ΣValue| over confidence flips: confidence and Δe decrease with higher values of the alternatives, accounting for the change in goal. Blue and red dots depict the (z-scored) confidence taken from participants in <italic>like</italic> and <italic>dislike</italic> frames (respectively). Grey line presents the model simulations for both separate frames. Data were segmented in 11 bins for ΔValue or ΣValue.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-60705-app8-fig1-v2.tif"/></fig><fig id="app8fig2" position="float"><label>Appendix 8—figure 2.</label><caption><title>Balance of evidence simulations in the Perceptual Experiment.</title><p>As in Value Experiment, the difference between accumulators (Δe) obtained from GLAM simulations matches participants’ confidence. Top left: a higher difference in number of dots between the two circles (|ΔDots|) increases confidence and simulated Δe. Top right: in the <italic>most</italic> frame, an increase in the summed number of dots (|ΣDots|) boosts confidence and simulated Δe. Bottom left: as in <italic>most</italic> frame, |ΔDots| boosted confidence and Δe in <italic>fewest</italic> frame. Bottom right: in the <italic>fewest</italic> frame, the effect of |ΣDots| over confidence flips: confidence and Δe decrease with higher number of dots in both circles, accounting for the change in goal. Blue and red dots depict the (z-scored) confidence taken from participants in <italic>most</italic> and <italic>fewest</italic> frames (respectively). Grey line presents the model simulations for both separate frames. Data were segmented in 11 bins for ΔDots or ΣDots.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-60705-app8-fig2-v2.tif"/></fig><fig id="app8fig3" position="float"><label>Appendix 8—figure 3.</label><caption><title>Pooled linear regressions to predict balance of evidence (Δe) simulations.</title><p>Here the full model results for <xref ref-type="fig" rid="fig6">Figure 6</xref> (see Results section) are displayed. In Value Experiment, the full simulations of Δe replicated the pattern of results obtained in human data (confidence results), that is there is a flip in the sign of ΣValue effect over confidence between <italic>like</italic> (<bold>A</bold>) and <italic>dislike</italic> (<bold>D</bold>) frames. However, if the gaze asymmetry is removed, we found the effect of ΣValue over Δe disappears. The results in Perceptual Experiment, <italic>most</italic> (<bold>B</bold>) and <italic>fewest</italic> (<bold>E</bold>) frames, mirror the findings in the Value Experiment.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-60705-app8-fig3-v2.tif"/></fig></sec></boxed-text></app><app id="appendix-9"><title>Appendix 9</title><boxed-text><sec id="s16" sec-type="appendix"><title>Normative model – proof of propositions 1 and 2</title><p>All the uses of µ in this proof: <inline-formula><mml:math id="inf14"><mml:msub><mml:mrow><mml:mi>μ</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> is the mean of the belief on the value of item i after the agent has acquired one signal about item i; <inline-formula><mml:math id="inf15"><mml:msub><mml:mrow><mml:mi>μ</mml:mi><mml:mi>'</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> is the mean of the belief on the value of item i after the agent has acquired two signals about item i.</p><p>We begin by proving Proposition 1. Recall that qualities <inline-formula><mml:math id="inf16"><mml:msub><mml:mrow><mml:mi>v</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> are distributed independently according to a Normal distribution and that the agent knows it, thus holds a correct prior belief. Recall also that the agent has taken a sample, <inline-formula><mml:math id="inf17"><mml:msub><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:msub><mml:mrow><mml:mi>v</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mrow><mml:mi>ϵ</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula>, with <inline-formula><mml:math id="inf18"><mml:msub><mml:mrow><mml:mi>ϵ</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> independently and identically distributed with <inline-formula><mml:math id="inf19"><mml:msub><mml:mrow><mml:mi>ϵ</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>∼</mml:mo><mml:mi>N</mml:mi><mml:mfenced separators="|"><mml:mrow><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:msubsup><mml:mrow><mml:mi>σ</mml:mi></mml:mrow><mml:mrow><mml:mi>ϵ</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup></mml:mrow></mml:mfenced></mml:math></inline-formula>. Because the prior belief is Normal, and because also the signal <inline-formula><mml:math id="inf20"><mml:msub><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> is Normally distributed around the true value, standard arguments give us that the posterior belief about <inline-formula><mml:math id="inf21"><mml:msub><mml:mrow><mml:mi>v</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub> <mml:mi/></mml:math></inline-formula> is also Normal. Denote by <inline-formula><mml:math id="inf22"><mml:msub><mml:mrow><mml:mi>μ</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> and <inline-formula><mml:math id="inf23"><mml:msubsup><mml:mrow><mml:mi>σ</mml:mi></mml:mrow><mml:mrow><mml:mi>v</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup></mml:math></inline-formula> the mean and the variance, respectively, of this posterior belief about <inline-formula><mml:math id="inf24"><mml:msub><mml:mrow><mml:mi>v</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula>, for each <inline-formula><mml:math id="inf25"><mml:mi>i</mml:mi></mml:math></inline-formula>. Note that <inline-formula><mml:math id="inf26"><mml:msubsup><mml:mrow><mml:mi>σ</mml:mi></mml:mrow><mml:mrow><mml:mi>v</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup></mml:math></inline-formula> is the same for all <inline-formula><mml:math id="inf27"><mml:mi>i</mml:mi></mml:math></inline-formula> (since, with Normal distributions, the variance of the posterior only depends on the variance of the prior and of the signal).</p><p>The agent can now acquire a second signal about only one of the items and needs to decide which item. Note that, after a second signal about item <inline-formula><mml:math id="inf28"><mml:mi>i</mml:mi></mml:math></inline-formula> is acquired, this will further change the belief about <inline-formula><mml:math id="inf29"><mml:msub><mml:mrow><mml:mi>v</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula>. Denote by <inline-formula><mml:math id="inf30"><mml:msub><mml:mrow><mml:mi>μ</mml:mi><mml:mi>'</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> the mean of this belief: that is, <inline-formula><mml:math id="inf31"><mml:msub><mml:mrow><mml:mi>μ</mml:mi><mml:mi>'</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> is the mean of the belief about <inline-formula><mml:math id="inf32"><mml:msub><mml:mrow><mml:mi>v</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> after the agent has acquired <italic>two</italic> signals about it.</p><p>Recall that <inline-formula><mml:math id="inf33"><mml:mi>V</mml:mi><mml:mfenced separators="|"><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:mfenced></mml:math></inline-formula> indicates the utility that the agent expects to have after acquiring the second signal about item <inline-formula><mml:math id="inf34"><mml:mi>i</mml:mi></mml:math></inline-formula>. Recall also that we denote by <inline-formula><mml:math id="inf35"><mml:msub><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:math></inline-formula> the item for which the agent has received the highest first signal, <inline-formula><mml:math id="inf36"><mml:msub><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub></mml:math></inline-formula> the second-highest, etc. Suppose first that the second signal acquired is not about the best item. Then, there are two possibilities. First, we may have that <inline-formula><mml:math id="inf37"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>μ</mml:mi><mml:mrow><mml:msub><mml:mi>i</mml:mi><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:msub><mml:mo>&gt;</mml:mo><mml:msubsup><mml:mi>μ</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mo>′</mml:mo></mml:msubsup></mml:mrow></mml:mstyle></mml:math></inline-formula>, that is, after the second signal, the posterior mean about the quality of <inline-formula><mml:math id="inf38"><mml:mi>i</mml:mi><mml:mo>,</mml:mo></mml:math></inline-formula> <inline-formula><mml:math id="inf39"><mml:msub><mml:mrow><mml:mi>μ</mml:mi><mml:mi>'</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula>, is below that of <inline-formula><mml:math id="inf40"><mml:msub><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo></mml:math></inline-formula> <inline-formula><mml:math id="inf41"><mml:msub><mml:mrow><mml:mi>μ</mml:mi></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:msub></mml:math></inline-formula>. In that case the agent will choose <inline-formula><mml:math id="inf42"><mml:msub><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:math></inline-formula>, and receive an expected quality of <inline-formula><mml:math id="inf43"><mml:msub><mml:mrow><mml:mi>μ</mml:mi></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:msub></mml:math></inline-formula>. If instead <inline-formula><mml:math id="inf44"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>μ</mml:mi><mml:mrow><mml:msub><mml:mi>i</mml:mi><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:msub><mml:mo>&lt;</mml:mo><mml:msubsup><mml:mi>μ</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mo>′</mml:mo></mml:msubsup></mml:mrow></mml:mstyle></mml:math></inline-formula>, then the agent chooses <italic>i</italic> and has an expected quality <inline-formula><mml:math id="inf45"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msubsup><mml:mi>μ</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mo>′</mml:mo></mml:msubsup></mml:mrow></mml:mstyle></mml:math></inline-formula>. It follows that, for <inline-formula><mml:math id="inf46"><mml:msub><mml:mrow><mml:mi>i</mml:mi><mml:mo>≠</mml:mo><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:math></inline-formula>, we have<disp-formula id="equ14"><mml:math id="m14"><mml:mi>V</mml:mi><mml:mfenced separators="|"><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:mfenced><mml:mo>=</mml:mo><mml:mi>m</mml:mi><mml:mi>a</mml:mi><mml:mi>x</mml:mi><mml:mfenced close="}" open="{" separators="|"><mml:mrow><mml:msub><mml:mrow><mml:mi>μ</mml:mi></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>μ</mml:mi><mml:mi>'</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfenced><mml:mo>.</mml:mo></mml:math></disp-formula></p><p>For similar reasons, <inline-formula><mml:math id="inf47"><mml:mi>V</mml:mi><mml:mfenced separators="|"><mml:mrow><mml:msub><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:mfenced><mml:mo>=</mml:mo><mml:mi>m</mml:mi><mml:mi>a</mml:mi><mml:mi>x</mml:mi><mml:mfenced close="}" open="{" separators="|"><mml:mrow><mml:msub><mml:mrow><mml:mi>μ</mml:mi></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>μ</mml:mi><mml:mi>'</mml:mi></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:msub></mml:mrow></mml:mfenced><mml:mo>.</mml:mo></mml:math></inline-formula></p><p>When the agent needs to decide which item to acquire a second signal about, however, the second signal has not been observed yet: we thus need to compute the expectation of <inline-formula><mml:math id="inf48"><mml:mi>V</mml:mi><mml:mfenced separators="|"><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:mfenced></mml:math></inline-formula>. In order to compute this, the agent needs to form a belief about what will be the value of <inline-formula><mml:math id="inf49"><mml:msub><mml:mrow><mml:mi>μ</mml:mi><mml:mi>'</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> <italic>before</italic> acquiring the second signal about <inline-formula><mml:math id="inf50"><mml:msub><mml:mrow><mml:mi>v</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> (but after acquiring the first signal). Such belief must again be normally distributed, and have mean <inline-formula><mml:math id="inf51"><mml:msub><mml:mrow><mml:mi>μ</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula>. (This is because, of course, the expectation that the agent holds about the posterior mean before receiving the signal must be centered at the prior mean, which in this case is <inline-formula><mml:math id="inf52"><mml:msub><mml:mrow><mml:mi>μ</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula>.) Denote by <inline-formula><mml:math id="inf53"><mml:mi>θ</mml:mi></mml:math></inline-formula> the variance of this belief; again, this is the same for all <italic>i</italic>s. Thus, <inline-formula><mml:math id="inf54"><mml:msub><mml:mrow><mml:mi>μ</mml:mi><mml:mi>'</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>∼</mml:mo><mml:mi>N</mml:mi><mml:mfenced separators="|"><mml:mrow><mml:msub><mml:mrow><mml:mi>μ</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:mi>θ</mml:mi></mml:mrow></mml:mfenced><mml:mo>.</mml:mo></mml:math></inline-formula></p><p>We are now ready to prove the following claims.</p><sec id="s16-1"><title><bold>Claim 1.</bold> <inline-formula><mml:math id="inf55"><mml:mi>E</mml:mi><mml:mfenced close="]" open="[" separators="|"><mml:mrow><mml:mi>V</mml:mi><mml:mfenced separators="|"><mml:mrow><mml:msub><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:mfenced></mml:mrow></mml:mfenced><mml:mo>=</mml:mo><mml:mi>E</mml:mi><mml:mfenced close="]" open="[" separators="|"><mml:mrow><mml:mi>V</mml:mi><mml:mfenced separators="|"><mml:mrow><mml:msub><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:mfenced></mml:mrow></mml:mfenced><mml:mo>.</mml:mo></mml:math></inline-formula></title><p><bold>Proof.</bold> Recall that, for <inline-formula><mml:math id="inf56"><mml:msub><mml:mrow><mml:mi>i</mml:mi><mml:mo>≠</mml:mo><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo></mml:math></inline-formula> we have <inline-formula><mml:math id="inf57"><mml:mi>V</mml:mi><mml:mfenced separators="|"><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:mfenced><mml:mo>=</mml:mo><mml:mi>m</mml:mi><mml:mi>a</mml:mi><mml:mi>x</mml:mi><mml:mfenced close="}" open="{" separators="|"><mml:mrow><mml:msub><mml:mrow><mml:mi>μ</mml:mi></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>μ</mml:mi><mml:mi>'</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfenced></mml:math></inline-formula> and <inline-formula><mml:math id="inf58"><mml:msub><mml:mrow><mml:mi>μ</mml:mi><mml:mi>'</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>∼</mml:mo><mml:mi>N</mml:mi><mml:mfenced separators="|"><mml:mrow><mml:msub><mml:mrow><mml:mi>μ</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:mi>θ</mml:mi></mml:mrow></mml:mfenced></mml:math></inline-formula>. This means that the belief about <inline-formula><mml:math id="inf59"><mml:mi>V</mml:mi><mml:mfenced separators="|"><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:mfenced></mml:math></inline-formula>, for <inline-formula><mml:math id="inf60"><mml:msub><mml:mrow><mml:mi>i</mml:mi><mml:mo>≠</mml:mo><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:math></inline-formula>, coincides with <inline-formula><mml:math id="inf61"><mml:mi>N</mml:mi><mml:mfenced separators="|"><mml:mrow><mml:msub><mml:mrow><mml:mi>μ</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:mi>θ</mml:mi></mml:mrow></mml:mfenced></mml:math></inline-formula> for values above <inline-formula><mml:math id="inf62"><mml:msub><mml:mrow><mml:mi>μ</mml:mi></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:msub></mml:math></inline-formula>, but has a mass point at <inline-formula><mml:math id="inf63"><mml:msub><mml:mrow><mml:mi>μ</mml:mi></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:msub></mml:math></inline-formula> equal to the probability that <inline-formula><mml:math id="inf64"><mml:mi>N</mml:mi><mml:mfenced separators="|"><mml:mrow><mml:msub><mml:mrow><mml:mi>μ</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:mi>θ</mml:mi></mml:mrow></mml:mfenced></mml:math></inline-formula> is below <inline-formula><mml:math id="inf65"><mml:msub><mml:mrow><mml:mi>μ</mml:mi></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:msub></mml:math></inline-formula>. If we denote by <inline-formula><mml:math id="inf66"><mml:msub><mml:mrow><mml:mi>f</mml:mi></mml:mrow><mml:mrow><mml:mi>μ</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> the Probability Density Function of <inline-formula><mml:math id="inf67"><mml:mi>N</mml:mi><mml:mfenced separators="|"><mml:mrow><mml:mi mathvariant="normal">μ</mml:mi><mml:mo>,</mml:mo><mml:mi>θ</mml:mi></mml:mrow></mml:mfenced></mml:math></inline-formula>, it follows that we have<disp-formula id="equ15"><mml:math id="m15"><mml:mi>E</mml:mi><mml:mfenced close="]" open="[" separators="|"><mml:mrow><mml:mi>V</mml:mi><mml:mfenced separators="|"><mml:mrow><mml:msub><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:mfenced></mml:mrow></mml:mfenced><mml:mo>=</mml:mo><mml:msub><mml:mrow><mml:mi>μ</mml:mi></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:msub><mml:mrow><mml:msubsup><mml:mo>∫</mml:mo><mml:mrow><mml:mo>-</mml:mo><mml:mi>∞</mml:mi></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>μ</mml:mi></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:msub></mml:mrow></mml:msubsup><mml:mrow><mml:msub><mml:mrow><mml:mi>f</mml:mi></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>μ</mml:mi></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:msub></mml:mrow></mml:msub><mml:mfenced separators="|"><mml:mrow><mml:mi>x</mml:mi></mml:mrow></mml:mfenced></mml:mrow></mml:mrow><mml:mi>d</mml:mi><mml:mi>x</mml:mi><mml:mo>+</mml:mo><mml:mrow><mml:msubsup><mml:mo>∫</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mi>μ</mml:mi></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:mo>+</mml:mo><mml:mi>∞</mml:mi></mml:mrow></mml:msubsup><mml:mrow><mml:mi>x</mml:mi></mml:mrow></mml:mrow><mml:msub><mml:mrow><mml:mi>f</mml:mi></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>μ</mml:mi></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:msub></mml:mrow></mml:msub><mml:mfenced separators="|"><mml:mrow><mml:mi>x</mml:mi></mml:mrow></mml:mfenced><mml:mi>d</mml:mi><mml:mi>x</mml:mi><mml:mo>.</mml:mo></mml:math></disp-formula></p><p>Recall also that <inline-formula><mml:math id="inf68"><mml:mi>V</mml:mi><mml:mfenced separators="|"><mml:mrow><mml:msub><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:mfenced><mml:mo>=</mml:mo><mml:mi>m</mml:mi><mml:mi>a</mml:mi><mml:mi>x</mml:mi><mml:mfenced close="}" open="{" separators="|"><mml:mrow><mml:msub><mml:mrow><mml:mi>μ</mml:mi></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>μ</mml:mi><mml:mi>'</mml:mi></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:msub></mml:mrow></mml:mfenced></mml:math></inline-formula>. The belief about <inline-formula><mml:math id="inf69"><mml:mi>V</mml:mi><mml:mfenced separators="|"><mml:mrow><mml:msub><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:mfenced></mml:math></inline-formula> coincides with <inline-formula><mml:math id="inf70"><mml:mi>N</mml:mi><mml:mfenced separators="|"><mml:mrow><mml:msub><mml:mrow><mml:mi>μ</mml:mi></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:mi>θ</mml:mi></mml:mrow></mml:mfenced></mml:math></inline-formula> above <inline-formula><mml:math id="inf71"><mml:msub><mml:mrow><mml:mi>μ</mml:mi></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:msub></mml:math></inline-formula>, but has a mass point at <inline-formula><mml:math id="inf72"><mml:msub><mml:mrow><mml:mi>μ</mml:mi></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:msub></mml:math></inline-formula> equal to the probability that <inline-formula><mml:math id="inf73"><mml:mi>N</mml:mi><mml:mfenced separators="|"><mml:mrow><mml:msub><mml:mrow><mml:mi>μ</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:mi>θ</mml:mi></mml:mrow></mml:mfenced></mml:math></inline-formula> is below <inline-formula><mml:math id="inf74"><mml:msub><mml:mrow><mml:mi>μ</mml:mi></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:msub><mml:mo>.</mml:mo></mml:math></inline-formula> Then,<disp-formula id="equ16"><mml:math id="m16"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>E</mml:mi><mml:mrow><mml:mo>[</mml:mo><mml:mrow><mml:mi>V</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:msub><mml:mi>i</mml:mi><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>]</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:msubsup><mml:mo>∫</mml:mo><mml:mrow><mml:mo>−</mml:mo><mml:mi mathvariant="normal">∞</mml:mi></mml:mrow><mml:mrow><mml:msub><mml:mi>μ</mml:mi><mml:mrow><mml:msub><mml:mi>i</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:msub></mml:mrow></mml:msubsup><mml:msub><mml:mi>μ</mml:mi><mml:mrow><mml:msub><mml:mi>i</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:msub><mml:msub><mml:mi>f</mml:mi><mml:mrow><mml:msub><mml:mi>μ</mml:mi><mml:mrow><mml:msub><mml:mi>i</mml:mi><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:msub></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mi>x</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mi>d</mml:mi><mml:mi>x</mml:mi><mml:mo>+</mml:mo><mml:msubsup><mml:mo>∫</mml:mo><mml:mrow><mml:msub><mml:mi>μ</mml:mi><mml:mrow><mml:msub><mml:mi>i</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:mo>+</mml:mo><mml:mi mathvariant="normal">∞</mml:mi></mml:mrow></mml:msubsup><mml:mi>x</mml:mi><mml:msub><mml:mi>f</mml:mi><mml:mrow><mml:msub><mml:mi>μ</mml:mi><mml:mrow><mml:msub><mml:mi>i</mml:mi><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:msub></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mi>x</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mi>d</mml:mi><mml:mi>x</mml:mi><mml:mo>.</mml:mo></mml:mrow></mml:mstyle></mml:math></disp-formula></p><p>Note that, by construction, we have<disp-formula id="equ17"><mml:math id="m17"><mml:msub><mml:mrow><mml:mi>μ</mml:mi></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mrow><mml:msubsup><mml:mo>∫</mml:mo><mml:mrow><mml:mo>-</mml:mo><mml:mi>∞</mml:mi></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>μ</mml:mi></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:msub></mml:mrow></mml:msubsup><mml:mrow><mml:mi>x</mml:mi></mml:mrow></mml:mrow><mml:msub><mml:mrow><mml:mi>f</mml:mi></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>μ</mml:mi></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:msub></mml:mrow></mml:msub><mml:mfenced separators="|"><mml:mrow><mml:mi>x</mml:mi></mml:mrow></mml:mfenced><mml:mi>d</mml:mi><mml:mi>x</mml:mi><mml:mo>+</mml:mo><mml:mrow><mml:msubsup><mml:mo>∫</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mi>μ</mml:mi></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:mo>+</mml:mo><mml:mi>∞</mml:mi></mml:mrow></mml:msubsup><mml:mrow><mml:mi>x</mml:mi></mml:mrow></mml:mrow><mml:msub><mml:mrow><mml:mi>f</mml:mi></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>μ</mml:mi></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:msub></mml:mrow></mml:msub><mml:mfenced separators="|"><mml:mrow><mml:mi>x</mml:mi></mml:mrow></mml:mfenced><mml:mi>d</mml:mi><mml:mi>x</mml:mi><mml:mo>.</mml:mo></mml:math></disp-formula></p><p>It follows that<disp-formula id="equ18"><label>(A1)</label><mml:math id="m18"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>E</mml:mi><mml:mrow><mml:mo>[</mml:mo><mml:mrow><mml:mi>V</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:msub><mml:mi>i</mml:mi><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>]</mml:mo></mml:mrow><mml:mo>−</mml:mo><mml:msub><mml:mi>μ</mml:mi><mml:mrow><mml:msub><mml:mi>i</mml:mi><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:msubsup><mml:mo>∫</mml:mo><mml:mrow><mml:mo>−</mml:mo><mml:mi mathvariant="normal">∞</mml:mi></mml:mrow><mml:mrow><mml:msub><mml:mi>μ</mml:mi><mml:mrow><mml:msub><mml:mi>i</mml:mi><mml:mn>2</mml:mn></mml:msub></mml:mrow></mml:msub></mml:mrow></mml:msubsup><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>μ</mml:mi><mml:mrow><mml:msub><mml:mi>i</mml:mi><mml:mn>2</mml:mn></mml:msub></mml:mrow></mml:msub><mml:mo>−</mml:mo><mml:mi>x</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:msub><mml:mi>f</mml:mi><mml:mrow><mml:msub><mml:mi>μ</mml:mi><mml:mrow><mml:msub><mml:mi>i</mml:mi><mml:mn>1</mml:mn></mml:msub></mml:mrow></mml:msub></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>x</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mi>d</mml:mi><mml:mi>x</mml:mi></mml:mrow></mml:mstyle></mml:math></disp-formula>and<disp-formula id="equ19"><label>(A2)</label><mml:math id="m19"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>E</mml:mi><mml:mrow><mml:mo>[</mml:mo><mml:mrow><mml:mi>V</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:msub><mml:mi>i</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>]</mml:mo></mml:mrow><mml:mo>−</mml:mo><mml:msub><mml:mi>μ</mml:mi><mml:mrow><mml:msub><mml:mi>i</mml:mi><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:msubsup><mml:mo>∫</mml:mo><mml:mrow><mml:msub><mml:mi>μ</mml:mi><mml:mrow><mml:msub><mml:mi>i</mml:mi><mml:mn>1</mml:mn></mml:msub></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:mo>+</mml:mo><mml:mi mathvariant="normal">∞</mml:mi></mml:mrow></mml:msubsup><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>x</mml:mi><mml:mo>−</mml:mo><mml:msub><mml:mi>μ</mml:mi><mml:mrow><mml:msub><mml:mi>i</mml:mi><mml:mn>1</mml:mn></mml:msub></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:msub><mml:mi>f</mml:mi><mml:mrow><mml:msub><mml:mi>μ</mml:mi><mml:mrow><mml:msub><mml:mi>i</mml:mi><mml:mn>2</mml:mn></mml:msub></mml:mrow></mml:msub></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>x</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mi>d</mml:mi><mml:mi>x</mml:mi><mml:mo>.</mml:mo></mml:mrow></mml:mstyle></mml:math></disp-formula></p><p>But we also know that<disp-formula id="equ20"><mml:math id="m20"><mml:mrow><mml:msubsup><mml:mo>∫</mml:mo><mml:mrow><mml:mo>-</mml:mo><mml:mi>∞</mml:mi></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>μ</mml:mi></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:msub></mml:mrow></mml:msubsup><mml:mrow><mml:mfenced separators="|"><mml:mrow><mml:msub><mml:mrow><mml:mi>μ</mml:mi></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:msub><mml:mo>-</mml:mo><mml:mi>x</mml:mi></mml:mrow></mml:mfenced></mml:mrow></mml:mrow><mml:msub><mml:mrow><mml:mi>f</mml:mi></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>μ</mml:mi></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:msub></mml:mrow></mml:msub><mml:mfenced separators="|"><mml:mrow><mml:mi>x</mml:mi></mml:mrow></mml:mfenced><mml:mi>d</mml:mi><mml:mi>x</mml:mi><mml:mo>=</mml:mo><mml:mrow><mml:msubsup><mml:mo>∫</mml:mo><mml:mrow><mml:mn>2</mml:mn><mml:msub><mml:mrow><mml:mi>μ</mml:mi></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:msub><mml:mo>-</mml:mo><mml:msub><mml:mrow><mml:mi>μ</mml:mi></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:mo>+</mml:mo><mml:mi>∞</mml:mi></mml:mrow></mml:msubsup><mml:mrow><mml:mfenced separators="|"><mml:mrow><mml:mi>x</mml:mi><mml:mo>-</mml:mo><mml:mn>2</mml:mn><mml:msub><mml:mrow><mml:mi>μ</mml:mi></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mrow><mml:mi>μ</mml:mi></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:msub></mml:mrow></mml:mfenced></mml:mrow></mml:mrow><mml:msub><mml:mrow><mml:mi>f</mml:mi></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>μ</mml:mi></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:msub></mml:mrow></mml:msub><mml:mfenced separators="|"><mml:mrow><mml:mi>x</mml:mi></mml:mrow></mml:mfenced><mml:mi>d</mml:mi><mml:mi>x</mml:mi><mml:mo>=</mml:mo><mml:mrow><mml:msubsup><mml:mo>∫</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mi>μ</mml:mi></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:mo>+</mml:mo><mml:mi>∞</mml:mi></mml:mrow></mml:msubsup><mml:mrow><mml:mfenced separators="|"><mml:mrow><mml:mi>x</mml:mi><mml:mo>-</mml:mo><mml:msub><mml:mrow><mml:mi>μ</mml:mi></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:msub></mml:mrow></mml:mfenced></mml:mrow></mml:mrow><mml:msub><mml:mrow><mml:mi>f</mml:mi></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>μ</mml:mi></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:msub></mml:mrow></mml:msub><mml:mfenced separators="|"><mml:mrow><mml:mi>x</mml:mi></mml:mrow></mml:mfenced><mml:mi>d</mml:mi><mml:mi>x</mml:mi><mml:mo>.</mml:mo></mml:math></disp-formula></p><p>Together with <xref ref-type="disp-formula" rid="equ18 equ19">Equation A1 and A2</xref>, this proves the claim.■</p></sec><sec id="s16-2"><title><bold>Claim 2.</bold> If N&gt;2, <inline-formula><mml:math id="inf75"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>E</mml:mi><mml:mrow><mml:mo>[</mml:mo><mml:mrow><mml:mi>V</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:msub><mml:mi>i</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>]</mml:mo></mml:mrow><mml:mo>&gt;</mml:mo><mml:mi>E</mml:mi><mml:mrow><mml:mo>[</mml:mo><mml:mrow><mml:mi>V</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:msub><mml:mi>i</mml:mi><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>]</mml:mo></mml:mrow></mml:mrow></mml:mstyle></mml:math></inline-formula> for all <inline-formula><mml:math id="inf76"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>j</mml:mi><mml:mo>&gt;</mml:mo><mml:mn>2</mml:mn></mml:mrow></mml:mstyle></mml:math></inline-formula>.</title><p><bold>Proof.</bold> Recall that, for <inline-formula><mml:math id="inf77"><mml:msub><mml:mrow><mml:mi>i</mml:mi><mml:mo>≠</mml:mo><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:math></inline-formula>, we have <inline-formula><mml:math id="inf78"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>V</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>i</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mi>m</mml:mi><mml:mi>a</mml:mi><mml:mi>x</mml:mi><mml:mrow><mml:mo>{</mml:mo><mml:mrow><mml:msub><mml:mi>μ</mml:mi><mml:mrow><mml:msub><mml:mi>i</mml:mi><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msubsup><mml:mi>μ</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mo>′</mml:mo></mml:msubsup></mml:mrow><mml:mo>}</mml:mo></mml:mrow></mml:mrow></mml:mstyle></mml:math></inline-formula>, where <inline-formula><mml:math id="inf79"><mml:msubsup><mml:mrow><mml:mi mathvariant="normal">μ</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">i</mml:mi></mml:mrow><mml:mrow><mml:mi>'</mml:mi></mml:mrow></mml:msubsup><mml:mo>∼</mml:mo><mml:mi>N</mml:mi><mml:mfenced separators="|"><mml:mrow><mml:msub><mml:mrow><mml:mi>μ</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">i</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:mi>θ</mml:mi></mml:mrow></mml:mfenced></mml:math></inline-formula>. It follows that the beliefs about both <inline-formula><mml:math id="inf80"><mml:mi>V</mml:mi><mml:mfenced separators="|"><mml:mrow><mml:msub><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:mfenced></mml:math></inline-formula> and <inline-formula><mml:math id="inf81"><mml:mi>V</mml:mi><mml:mfenced separators="|"><mml:mrow><mml:msub><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfenced></mml:math></inline-formula> (held before the second signal is acquired) has support <inline-formula><mml:math id="inf82"><mml:msub><mml:mrow><mml:mo>[</mml:mo><mml:mi>μ</mml:mi></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:msub><mml:mo>,</mml:mo> <mml:mi/><mml:mi>∞</mml:mi><mml:mo>)</mml:mo></mml:math></inline-formula>. Denote by <inline-formula><mml:math id="inf83"><mml:msub><mml:mrow><mml:mi>F</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> the Cumulative Density Function (CDF) of this belief. To prove the claim, we show that <inline-formula><mml:math id="inf84"><mml:msub><mml:mrow><mml:mi>F</mml:mi></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:msub></mml:math></inline-formula> First Order Stochastically Dominates <inline-formula><mml:math id="inf85"><mml:msub><mml:mrow><mml:mi>F</mml:mi></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:msub></mml:math></inline-formula> for all <inline-formula><mml:math id="inf86"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>j</mml:mi><mml:mo>&gt;</mml:mo><mml:mn>2</mml:mn></mml:mrow></mml:mstyle></mml:math></inline-formula>, while the converse is not true: that is, we aim to show that for all <inline-formula><mml:math id="inf87"><mml:mi>x</mml:mi></mml:math></inline-formula> in the support, <inline-formula><mml:math id="inf88"><mml:msub><mml:mrow><mml:mi>F</mml:mi></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:msub><mml:mfenced separators="|"><mml:mrow><mml:mi>x</mml:mi></mml:mrow></mml:mfenced><mml:mo>≤</mml:mo><mml:msub><mml:mrow><mml:mi>F</mml:mi></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:msub><mml:mfenced separators="|"><mml:mrow><mml:mi>x</mml:mi></mml:mrow></mml:mfenced></mml:math></inline-formula>, strictly for some x. (Recall that a distribution F first order stochastically dominates another distribution G if for all x, the probability that F returns at least x is not below the probability that G returns x or more.) This implies <inline-formula><mml:math id="inf89"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>E</mml:mi><mml:mrow><mml:mo>[</mml:mo><mml:mrow><mml:mi>V</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:msub><mml:mi>i</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>]</mml:mo></mml:mrow><mml:mo>&gt;</mml:mo><mml:mi>E</mml:mi><mml:mrow><mml:mo>[</mml:mo><mml:mrow><mml:mi>V</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:msub><mml:mi>i</mml:mi><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>]</mml:mo></mml:mrow><mml:mo>.</mml:mo></mml:mrow></mml:mstyle></mml:math></inline-formula></p><p>Let <inline-formula><mml:math id="inf90"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>δ</mml:mi><mml:mo>:</mml:mo><mml:mo>=</mml:mo><mml:msub><mml:mi>μ</mml:mi><mml:mrow><mml:msub><mml:mi>i</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:msub><mml:mo>−</mml:mo><mml:msub><mml:mi>μ</mml:mi><mml:mrow><mml:msub><mml:mi>i</mml:mi><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula> and note that we have <inline-formula><mml:math id="inf91"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>δ</mml:mi><mml:mo>&gt;</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:mstyle></mml:math></inline-formula> and that <inline-formula><mml:math id="inf92"><mml:mi>N</mml:mi><mml:mfenced separators="|"><mml:mrow><mml:msub><mml:mrow><mml:mi>μ</mml:mi></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:mi>θ</mml:mi></mml:mrow></mml:mfenced><mml:mfenced separators="|"><mml:mrow><mml:mi>x</mml:mi><mml:mo>+</mml:mo><mml:mi>δ</mml:mi></mml:mrow></mml:mfenced><mml:mo>=</mml:mo><mml:mi>N</mml:mi><mml:mfenced separators="|"><mml:mrow><mml:msub><mml:mrow><mml:mi>μ</mml:mi></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:mi>θ</mml:mi></mml:mrow></mml:mfenced><mml:mfenced separators="|"><mml:mrow><mml:mi>x</mml:mi></mml:mrow></mml:mfenced></mml:math></inline-formula> for all <inline-formula><mml:math id="inf93"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>x</mml:mi><mml:mo>∈</mml:mo><mml:mrow><mml:mi mathvariant="double-struck">R</mml:mi></mml:mrow></mml:mrow></mml:mstyle></mml:math></inline-formula>. Since <inline-formula><mml:math id="inf94"><mml:mi>V</mml:mi><mml:mfenced separators="|"><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:mfenced></mml:math></inline-formula> coincides with <inline-formula><mml:math id="inf95"><mml:msub><mml:mrow><mml:mi>μ</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mi>'</mml:mi></mml:math></inline-formula> whenever that lies above <inline-formula><mml:math id="inf96"><mml:msub><mml:mrow><mml:mi>μ</mml:mi></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:msub></mml:math></inline-formula> and since <inline-formula><mml:math id="inf97"><mml:msub><mml:mrow><mml:mi>μ</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mi>'</mml:mi> <mml:mi mathvariant="normal"/><mml:mo>∼</mml:mo><mml:mi>N</mml:mi><mml:mfenced separators="|"><mml:mrow><mml:msub><mml:mrow><mml:mi>μ</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">i</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:mi>θ</mml:mi></mml:mrow></mml:mfenced></mml:math></inline-formula>, it follows that, for all <inline-formula><mml:math id="inf98"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>x</mml:mi><mml:mo>&gt;</mml:mo><mml:msub><mml:mi>μ</mml:mi><mml:mrow><mml:msub><mml:mi>i</mml:mi><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula>, we have <inline-formula><mml:math id="inf99"><mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mn>1</mml:mn><mml:mo>-</mml:mo><mml:mi>F</mml:mi></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:msub><mml:mfenced separators="|"><mml:mrow><mml:mi>x</mml:mi></mml:mrow></mml:mfenced><mml:mo>)</mml:mo><mml:mo>=</mml:mo><mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mn>1</mml:mn><mml:mo>-</mml:mo><mml:mi>F</mml:mi></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:msub><mml:mfenced separators="|"><mml:mrow><mml:mi>x</mml:mi><mml:mo>+</mml:mo><mml:mi>δ</mml:mi></mml:mrow></mml:mfenced><mml:mo>)</mml:mo><mml:mo>:</mml:mo></mml:math></inline-formula> the probability that <inline-formula><mml:math id="inf100"><mml:msub><mml:mrow><mml:mi>F</mml:mi></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:msub></mml:math></inline-formula> assigns to <inline-formula><mml:math id="inf101"><mml:mi>V</mml:mi><mml:mfenced separators="|"><mml:mrow><mml:msub><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfenced></mml:math></inline-formula> being <inline-formula><mml:math id="inf102"><mml:mi>x</mml:mi></mml:math></inline-formula> or higher is the same that <inline-formula><mml:math id="inf103"><mml:msub><mml:mrow><mml:mi>F</mml:mi></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:msub></mml:math></inline-formula> assigns to <inline-formula><mml:math id="inf104"><mml:mi>V</mml:mi><mml:mfenced separators="|"><mml:mrow><mml:msub><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:mfenced></mml:math></inline-formula> being <inline-formula><mml:math id="inf105"><mml:mi>x</mml:mi><mml:mo>+</mml:mo><mml:mi>δ</mml:mi></mml:math></inline-formula> or higher. Then, <inline-formula><mml:math id="inf106"><mml:msub><mml:mrow><mml:mi>F</mml:mi></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:msub><mml:mfenced separators="|"><mml:mrow><mml:mi>x</mml:mi></mml:mrow></mml:mfenced><mml:mo>=</mml:mo><mml:msub><mml:mrow><mml:mi>F</mml:mi></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:msub><mml:mfenced separators="|"><mml:mrow><mml:mi>x</mml:mi><mml:mo>+</mml:mo><mml:mi>δ</mml:mi></mml:mrow></mml:mfenced><mml:mo>.</mml:mo></mml:math></inline-formula> Because CDFs are increasing and <inline-formula><mml:math id="inf107"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>δ</mml:mi><mml:mo>&gt;</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:mstyle></mml:math></inline-formula>, then <inline-formula><mml:math id="inf108"><mml:msub><mml:mrow><mml:mi>F</mml:mi></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:msub><mml:mfenced separators="|"><mml:mrow><mml:mi>x</mml:mi></mml:mrow></mml:mfenced><mml:mo>≤</mml:mo><mml:msub><mml:mrow><mml:mi>F</mml:mi></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:msub><mml:mfenced separators="|"><mml:mrow><mml:mi>x</mml:mi><mml:mo>+</mml:mo><mml:mi>δ</mml:mi></mml:mrow></mml:mfenced></mml:math></inline-formula>, thus <inline-formula><mml:math id="inf109"><mml:msub><mml:mrow><mml:mi>F</mml:mi></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:msub><mml:mfenced separators="|"><mml:mrow><mml:mi>x</mml:mi></mml:mrow></mml:mfenced><mml:mo>≤</mml:mo><mml:msub><mml:mrow><mml:mi>F</mml:mi></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:msub><mml:mfenced separators="|"><mml:mrow><mml:mi>x</mml:mi></mml:mrow></mml:mfenced></mml:math></inline-formula> for all <inline-formula><mml:math id="inf110"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>x</mml:mi><mml:mo>&gt;</mml:mo><mml:msub><mml:mi>μ</mml:mi><mml:mrow><mml:msub><mml:mi>i</mml:mi><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula>. Moreover, notice that we must have<disp-formula id="equ21"><mml:math id="m21"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>F</mml:mi><mml:mrow><mml:msub><mml:mi>i</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:msub><mml:mi>μ</mml:mi><mml:mrow><mml:msub><mml:mi>i</mml:mi><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:msub><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mi>N</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>μ</mml:mi><mml:mrow><mml:msub><mml:mi>i</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:mi>θ</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mo>[</mml:mo><mml:mrow><mml:mo>−</mml:mo><mml:mi mathvariant="normal">∞</mml:mi><mml:mo>,</mml:mo><mml:msub><mml:mi>μ</mml:mi><mml:mrow><mml:msub><mml:mi>i</mml:mi><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:msub></mml:mrow><mml:mo>]</mml:mo></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>&lt;</mml:mo><mml:mi>N</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>μ</mml:mi><mml:mrow><mml:msub><mml:mi>i</mml:mi><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:mi>θ</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mo>[</mml:mo><mml:mrow><mml:mo>−</mml:mo><mml:mi mathvariant="normal">∞</mml:mi><mml:mo>,</mml:mo><mml:msub><mml:mi>μ</mml:mi><mml:mrow><mml:msub><mml:mi>i</mml:mi><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:msub></mml:mrow><mml:mo>]</mml:mo></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:msub><mml:mi>F</mml:mi><mml:mrow><mml:msub><mml:mi>i</mml:mi><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:msub><mml:mi>μ</mml:mi><mml:mrow><mml:msub><mml:mi>i</mml:mi><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:msub><mml:mo>)</mml:mo></mml:mrow><mml:mo>.</mml:mo></mml:mrow></mml:mstyle></mml:math></disp-formula></p><p>That is, <inline-formula><mml:math id="inf111"><mml:msub><mml:mrow><mml:mi>F</mml:mi></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:msub></mml:math></inline-formula> assigns to values below <inline-formula><mml:math id="inf112"><mml:msub><mml:mrow><mml:mi>μ</mml:mi></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:msub></mml:math></inline-formula> a lower probability than <inline-formula><mml:math id="inf113"><mml:msub><mml:mrow><mml:mi>F</mml:mi></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:msub></mml:math></inline-formula> does. It follows that for all <inline-formula><mml:math id="inf114"><mml:mi>x</mml:mi></mml:math></inline-formula> in the support <inline-formula><mml:math id="inf115"><mml:msub><mml:mrow><mml:mo>[</mml:mo><mml:mi>μ</mml:mi></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:msub><mml:mo>,</mml:mo> <mml:mi/><mml:mi>∞</mml:mi><mml:mo>)</mml:mo></mml:math></inline-formula>,we have <inline-formula><mml:math id="inf116"><mml:msub><mml:mrow><mml:mi>F</mml:mi></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:msub><mml:mfenced separators="|"><mml:mrow><mml:mi>x</mml:mi></mml:mrow></mml:mfenced><mml:mo>≤</mml:mo><mml:msub><mml:mrow><mml:mi>F</mml:mi></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:msub><mml:mfenced separators="|"><mml:mrow><mml:mi>x</mml:mi></mml:mrow></mml:mfenced></mml:math></inline-formula>, strictly for some. Thus, <inline-formula><mml:math id="inf117"><mml:msub><mml:mrow><mml:mi>F</mml:mi></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:msub></mml:math></inline-formula> First Order Stochastically Dominates <inline-formula><mml:math id="inf118"><mml:msub><mml:mrow><mml:mi>F</mml:mi></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:msub></mml:math></inline-formula> for all <inline-formula><mml:math id="inf119"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>j</mml:mi><mml:mo>&gt;</mml:mo><mml:mn>2</mml:mn></mml:mrow></mml:mstyle></mml:math></inline-formula>, while the converse is not true. The claim follows.</p><p>The two claims together prove Proposition 1.</p></sec><sec id="s16-3"><title>Proposition 2</title><p>The proof of Proposition 2 is identical once we replace <inline-formula><mml:math id="inf120"><mml:msub><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> by <inline-formula><mml:math id="inf121"><mml:msub><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mi>N</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn><mml:mo>-</mml:mo><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> for <inline-formula><mml:math id="inf122"><mml:mi>j</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mo>…</mml:mo><mml:mo>,</mml:mo><mml:mi>N</mml:mi></mml:math></inline-formula>. Intuitively, the problem of maximising the expected utility of the remaining items is strategically equivalent to the problem of choosing the lowest item, which, in turn, is symmetric to the problem of choosing the best item. <inline-formula><mml:math id="inf123"><mml:mi>Q</mml:mi><mml:mi>E</mml:mi><mml:mi>D</mml:mi><mml:mo>.</mml:mo></mml:math></inline-formula></p></sec></sec></boxed-text></app></app-group></back><sub-article article-type="decision-letter" id="sa1"><front-stub><article-id pub-id-type="doi">10.7554/eLife.60705.sa1</article-id><title-group><article-title>Decision letter</article-title></title-group><contrib-group><contrib contrib-type="editor"><name><surname>Wyart</surname><given-names>Valentin</given-names></name><role>Reviewing Editor</role><aff><institution>École normale supérieure, PSL University, INSERM</institution><country>France</country></aff></contrib></contrib-group><contrib-group><contrib contrib-type="reviewer"><name><surname>Filipowicz</surname><given-names>Alexandre LS</given-names></name><role>Reviewer</role><aff><institution>University of Pennsylvania</institution><country>United States</country></aff></contrib><contrib contrib-type="reviewer"><name><surname>Gluth</surname><given-names>Sebastian</given-names> </name><role>Reviewer</role><aff><institution>University of Basel</institution><country>Switzerland</country></aff></contrib></contrib-group></front-stub><body><boxed-text><p>In the interests of transparency, eLife publishes the most substantive revision requests and the accompanying author responses.</p></boxed-text><p><bold>Acceptance summary:</bold></p><p>Your detailed investigation of the interplay between visual attention and value-based choice from the broader perspective of goal-directed behavior has provided clear findings that challenge popular decision-making models in neuroeconomics – according to which visual attention towards a choice option increases its estimated subjective value. Your finding that visual attention modulates the integration of goal-relevant evidence rather than value, obtained using state-of-the-art cognitive modeling, is relevant to a broad research community spanning across cognitive psychology and neuroeconomics. Congratulations for an insightful article.</p><p><bold>Decision letter after peer review:</bold></p><p>Thank you for submitting your article &quot;Visual attention modulates the integration of goal-relevant evidence and not value&quot; for consideration by <italic>eLife</italic>. Your article has been reviewed by two peer reviewers, and the evaluation has been overseen by a Reviewing Editor and Christian Büchel as the Senior Editor. The following individuals involved in review of your submission have agreed to reveal their identity: Alexandre L S Filipowicz (Reviewer #2); Sebastian Gluth (Reviewer #3).</p><p>The reviewers have discussed the reviews with one another and the Reviewing Editor has drafted this decision to help you prepare a revised submission.</p><p>This manuscript describes a behavioral modeling study which aims at challenging popular decision-making models in neuroeconomics – including the “attentional drift diffusion model (aDDM)” – according to which attention towards a choice option increases its estimated subjective value (and thus its probability of being chosen). By asking participants to either choose their most preferred option (“like” frame) but also their least preferred option (“dislike” frame), the authors report that human subjects are more likely to unselect the option that they fixate more in the “dislike” frame – a finding not predicted by the aDDM. The authors report a similar framing effect in a perceptual decision-making task, and provide a theoretical validation of this framing effect. The research question of the interplay between attention and value-based choice, and the obtained findings, are relevant to a broad research community spanning across cognitive psychology and neuroeconomics. The methodology applied by the authors is sound and the manuscript is well-written.</p><p>Despite these merits, one important concern raised by the reviews is that the current manuscript does not provide an accurate description of the literature on this issue. While neuroeconomics does focus on “value” as the quantity being accumulated, existing research does not predict nor claim that “value” is the only quantity to which gaze-contingent effects should apply. Indeed, as raised by reviewer #2, gaze-dependent attention has already been shown to influence evidence accumulation in non-value-based decisions (Tavares et al., 2017), suggesting that this phenomenon is not restricted to value. Furthermore, as raised by reviewer #3, the current study overlaps with (Kovach et al., 2014) which has shown that the influence of attention on choice reverses in a “dislike” frame – something that the authors currently acknowledge only in the Appendix.</p><p>Nevertheless, reviewers agree that the aDDM has become dominant in neuroeconomics when it comes to modeling the interplay of attention, valuation and decision making. And so the current study conveys the important and timely message to the neuroeconomics community that attention is not primarily driven by values but by goals. To convey this message accurately, we think that a more balanced description of the existing literature is warranted in the Introduction and Discussion sections (including the work that provides clues toward the findings obtained by the authors). This will not significantly reduce the novelty of the study (which is not the main factor driving our evaluation in any case), but will provide a more accurate picture of the field and thus the key contributions of the study. The main strengths of the current study are the experimental design and the robust cognitive modeling methods which together provide an unambiguous answer to the research question addressed by the authors.</p><p>Beyond this first concern regarding the literature/theoretical framing of the study, there are other concerns shared by the reviewers, listed below, that the authors should address in a detailed point-by-point response before considering the manuscript as suitable for publication at <italic>eLife</italic>.</p><p>Main concerns (beyond the first concern raised above):</p><p>1) Effect of last fixation on framing effects. After reading the manuscript, it appears possible that the framing effects are entirely driven by the last fixation. That is, the increase in choice probability of the more disliked item might be entirely driven by the fact that the last fixation is usually made on the chosen option. Therefore, it would be important to repeat the analysis and exclude the last fixation to see whether the effects still exist when considering only middle and first fixations. It would also be very interesting to see how the effects develop over time within a trial – i.e., at which fixation number (or time point) the influence of attention on choice is strongest – or at which fixation number (or time point) the probability to fixate on the goal-relevant option is highest.</p><p>2) Optimal information acquisition model. The reviewers have found the proof of the optimal information acquisition model in the Appendix extremely hard to follow. Reviewer #3 rightly states that all of this may be fairly standard in econometrics, but <italic>eLife</italic> is a journal read by many life scientists, including neuroscientists and psychologists. <italic>eLife</italic> readers will have a very hard time following the proof. It is nice that the main text provides a general intuition of the proof, but the proof in the Appendix should also be amended with some more explanations and intuitions. Notations like <italic>μ<sub>i1</sub> </italic>and <italic>μ<sub>i2</sub> </italic>and then <italic>μ<sub>i1, 2</sub> </italic>(i.e., three different things that have almost exactly the same notation) are not very helpful. Regarding the optimal information acquisition model, there are two recent preprints that make a very similar argument, which is that it is optimal to allocate attention on the most promising choice candidates in the case of multi-alternative decision making: Callaway et al., PsyArXiv; and Jang et al., bioRxiv. These preprints should be cited, since they do not reduce in any way the novelty and appeal of the current study.</p><p>3) Effect of accumulation asymmetries on confidence. The authors nicely show that GLAM is only capable of reproducing the influence of sum(Value) / sum(Dots) by assuming the presence of an attention bias. The authors conclude that this indicates that the confidence effect may be &quot;caused by the asymmetries in the accumulation process generated by visual attention&quot;. The authors should be more explicit to unpack their reasoning. The reason GLAM (with bias) can account for the confidence effect is the multiplicative interaction of attention and valuation: If there are two high-value items (let's say +10 and +10), then an attention bias of 0.3 leads to accumulation rates of 10 vs. 10*0.3 = 3, so a difference of 7. But if there are two low-value items (e.g., +1 and +1), then the difference is only 0.7. Thus, as soon as there is an imbalance in allocated attention between two options, the difference in accumulation rates between those two options is higher if the options have higher values. This will eventually lead to a larger effect on δ(e).</p><p>4) Effect of hunger on value-based decisions. Hunger likely plays an important factor to turn this from a cognitive task to a value-based task. However, other than stating that participants were instructed to fast for four hours, I found no mention of measures used to validate hunger. Is a four hour fasting window enough to make people feel hungry? If so, how was participant hunger measured and/or controlled?</p><p>5) Participant drop-out rate. The participant drop-out rate seems extremely high (~20-25%), and seems mainly due to difficulties with how the BDM scale was interpreted. With such a high overall drop-out rate, how can the authors be sure that participant responses on this measure are reliable (even the participants who were included in the analyses)? The authors should discuss explicitly this high drop-out rate.</p></body></sub-article><sub-article article-type="reply" id="sa2"><front-stub><article-id pub-id-type="doi">10.7554/eLife.60705.sa2</article-id><title-group><article-title>Author response</article-title></title-group></front-stub><body><disp-quote content-type="editor-comment"><p>Despite these merits, one important concern raised by the reviews is that the current manuscript does not provide an accurate description of the literature on this issue. While neuroeconomics does focus on “value” as the quantity being accumulated, existing research does not predict nor claim that “value” is the only quantity to which gaze-contingent effects should apply. Indeed, as raised by reviewer #2, gaze-dependent attention has already been shown to influence evidence accumulation in non-value-based decisions (Tavares et al., 2017), suggesting that this phenomenon is not restricted to value. Furthermore, as raised by reviewer #3, the current study overlaps with (Kovach et al., 2014) which has shown that the influence of attention on choice reverses in a “dislike” frame – something that the authors currently acknowledge only in the Appendix.</p><p>Nevertheless, reviewers agree that the aDDM has become dominant in neuroeconomics when it comes to modeling the interplay of attention, valuation and decision making. And so the current study conveys the important and timely message to the neuroeconomics community that attention is not primarily driven by values but by goals. To convey this message accurately, we think that a more balanced description of the existing literature is warranted in the Introduction and Discussion sections (including the work that provides clues toward the findings obtained by the authors). This will not significantly reduce the novelty of the study (which is not the main factor driving our evaluation in any case), but will provide a more accurate picture of the field and thus the key contributions of the study. The main strengths of the current study are the experimental design and the robust cognitive modeling methods which together provide an unambiguous answer to the research question addressed by the authors.</p></disp-quote><p>Following your advice we have amended the Introduction and the Discussion of our paper to give a more balanced representation of the background work</p><p>Introduction:</p><p>“The most common interpretation is that attention is allocated to items based on their value and that looking or attending to an option boosts its value, either by amplifying it or by shifting it upwards by a constant amount. […] In the <italic>like</italic> frame, they had to indicate which snack they would like to consume at the end of the experiment; this is consistent with the standard tasks used in value-based decision studies.”</p><p>We have also made changes in our Discussion to include a more detailed revision of the Kovach et al., 2014 and Frömer et al., 2019 studies. Please see below for further details on other changes:</p><p>Discussion:</p><p>“Our findings speak in favour of a more general role played by attention in prioritising the information needed to fulfil a behavioural goal in both value and perceptual choices (Gottlieb et al., 2012; Kovach et al., 2014; Glickman et al., 2018). Importantly, the seeking of goal-relevant information is observed along the trial, opposing the assumption that attentional sampling is random except for the last fixation (Krajbich et al., 2010, Krajbich and Rangel, 2011; see Gluth et al., 2018; 2020, for additional support for this idea). Pavlovian influences have been proposed to play a key role in the context of accept /reject framing manipulation.”</p><p>“Notable exceptions are two recent studies from Frömer and colleagues and Kovach and colleagues. […] However, both studies were developed considering only a standard appetitive <italic>like</italic> frame (Krajbich et al., 2010 study was used as benchmark in both cases).”</p><disp-quote content-type="editor-comment"><p>Main concerns:</p><p>1) Effect of last fixation on framing effects. After reading the manuscript, it appears possible that the framing effects are entirely driven by the last fixation. That is, the increase in choice probability of the more disliked item might be entirely driven by the fact that the last fixation is usually made on the chosen option. Therefore, it would be important to repeat the analysis and exclude the last fixation to see whether the effects still exist when considering only middle and first fixations. It would also be very interesting to see how the effects develop over time within a trial – i.e., at which fixation number (or time point) the influence of attention on choice is strongest – or at which fixation number (or time point) the probability to fixate on the goal-relevant option is highest.</p></disp-quote><p>We thank the reviewers for their acute observation. We conducted further analyses that have shown that the effect we report is not only driven by the last fixation. We present below the results of the 3 new analyses we have conducted (and which are now reported in our manuscript and Appendix):</p><p>1) First of all, as per their suggestion we have excluded the final two fixations from each trial. Note that we excluded two last fixations rather than only the last fixation, because this avoids statistical artifacts. If the last fixation is mostly on the chosen item (as it is) than the fixation before last one is on the non-chosen one and eliminating both is more balanced with regards to the differential amount of time (∆DT) the subjects looked on the two items. We then repeated the hierarchical regression analysis for choice, removing the last <italic>two</italic> fixations (note that trials with 3 or less fixations were discarded from this analysis). This analysis mirrors our original findings showing that gaze is preferentially allocated towards the chosen item (∆DT effect in <italic>like: z</italic>=10.54, <italic>p</italic>&lt;0.001; <italic>dislike</italic>: <italic>z</italic>=8.87, <italic>p</italic>&lt;0.001; ∆DT effect in <italic>most: z</italic>=8.39 <italic>p</italic>&lt;0.001; <italic>fewest</italic>: <italic>z</italic>=9.15, <italic>p</italic>&lt;0.001). We have included it in the Appendix 2—figure 3 and we mentioned the analysis in the main text.</p><p>2) Following the thoughtful suggestion of the reviewer we have now conducted a new analysis that explore the temporal evolution of the effect we reported. Using an approach similar to Kovach et al., 2014, we segmented the time series of all the trials in samples of 10ms. We then computed the Pearson correlation between gaze (left = 0 and right = 1) and the difference in evidence (∆Value or ∆Dots) for each time sample. The time series were locked to the beginning of the trial. These data clearly show that, from early on in the trial (~ 1000 ms) gaze distribution was correlated with the goal-relevant item for that trial (e.g. most <italic>liked</italic> item in like frame and less liked item in dislike frame). An almost identical pattern emerged in the Perceptual Experiment. We modified figure 3 (new panels C and D) to include this new compelling result and amended the main section of the manuscript.</p><p>3) Finally, we have analysed in more detail the middle fixations. Previous studies (Krajbich et al., 2010; Krajbich and Rangel, 2011, Tavares et al., 2017) have reported that the duration of middle fixations increases when the fixated item has higher value that the unfixated options. We show that in our experiments, in <italic>like</italic> and <italic>most</italic> frames, we replicate this same pattern of results. Critically (and according to our hypothesis), in <italic>dislike</italic> and <italic>fewest</italic> frames, this effect is flipped: the duration of middle fixations decreased as the value (or number of dots) of the fixated item increases. We have now included these new results in the appendix (Appendix 3—figure 4) and we mention them in the main text. We are very grateful to the reviewers for encouraging us to perform these further checks that we believe have substantially improved our manuscript.</p><p>The name of section 2.2 has been changed from “Last fixation in choice” to “Fixation effects in choice” and the text has been amended as follow:</p><p>“2.2 Fixations effects in choice</p><p>An important prediction of attentional accumulation models is that the chosen item is generally fixated last (unless that item is much worse than the other alternative), with the magnitude of this effect related to the difference in value between the alternatives. […] Note that these results are in line with the ones reported by Kovach et al., 2014. We see a very similar pattern of results in the Perceptual Experiment too (Figure 3D).”</p><p>In Materials and methods section we have included the details for the time course analysis:</p><p>“4.5 Data Analysis: Behavioural Data</p><p>Behavioural measures during <italic>like/dislike</italic> and <italic>most/fewest</italic> frames were compared using statistical tests available in SciPy. […] False discovery rate (FDR) was used to correct for multiple tests the P-values obtained from the permutation test (α ≤0.01).”</p><disp-quote content-type="editor-comment"><p>2) Optimal information acquisition model. The reviewers have found the proof of the optimal information acquisition model in the Appendix extremely hard to follow. Reviewer #3 rightly states that all of this may be fairly standard in econometrics, but eLife is a journal read by many life scientists, including neuroscientists and psychologists. eLife readers will have a very hard time following the proof. It is nice that the main text provides a general intuition of the proof, but the proof in the Appendix should also be amended with some more explanations and intuitions. Notations like μi1 and μ<sub>i2</sub> and then μ<sub>i1</sub>,<sub>2</sub> (i.e., three different things that have almost exactly the same notation) are not very helpful. Regarding the optimal information acquisition model, there are two recent preprints that make a very similar argument, which is that it is optimal to allocate attention on the most promising choice candidates in the case of multi-alternative decision making: Callaway et al., PsyArXiv; and Jang et al., bioRxiv. These preprints should be cited, since they do not reduce in any way the novelty and appeal of the current study.</p></disp-quote><p>Thank you for highlighting this issue. We have substantially rewritten and expanded the proof of Propositions 1 and 2. We have strived to make it more accessible for a wider audience, while at the same time maintaining a sufficient rigour expected for a proof in the field of economic decision theory. Also, to reduce the confusion with notation, we have added a paragraph at the beginning introducing our notation.</p><p>For this same reason, we have not included the proof in the main text but reported the Appendix 9 for the interested reader.</p><p>“Appendix 9: Normative Model -Proof of Propositions 1 and 2</p><p>All the uses of µ in this proof: µ<sub>i</sub> is the mean of the belief on the value of item i after the agent has acquired one signal about item i; µ'<sub>i</sub> is the mean of the belief on the value of item i after the agent has acquired two signals about item i. […] The proof of Proposition 2 is identical once we replace <inline-formula><mml:math id="inf124"><mml:msub><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:msub></mml:math></inline-formula> by <inline-formula><mml:math id="inf125"><mml:msub><mml:mi>i</mml:mi><mml:mrow><mml:mi>N</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> for <inline-formula><mml:math id="inf126"><mml:mrow><mml:mi>j</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mi>…</mml:mi><mml:mo>,</mml:mo><mml:mi>N</mml:mi></mml:mrow></mml:math></inline-formula>. Intuitively, the problem of maximizing the expected utility of the remaining items is strategically equivalent to the problem of choosing the lowest item, which, in turn, is symmetric to the problem of choosing the best item. <inline-formula><mml:math id="inf127"><mml:mtext mathvariant="normal">QED.</mml:mtext></mml:math></inline-formula><bold>”</bold></p><p>Additionally, we thank the reviewer for pointing out to these relevant preprints that had escaped our notice, we have included them in our Discussion:</p><p>“To gain a deeper insight into our findings we developed a normative model of optimal information acquisition rooted in economic decision theory. […] However, both studies were developed considering only a standard appetitive <italic>like</italic> frame (Krajbich et al., 2010 study was used as benchmark in both cases).”</p><disp-quote content-type="editor-comment"><p>3) Effect of accumulation asymmetries on confidence. The authors nicely show that GLAM is only capable of reproducing the influence of sum(Value) / sum(Dots) by assuming the presence of an attention bias. The authors conclude that this indicates that the confidence effect may be &quot;caused by the asymmetries in the accumulation process generated by visual attention&quot;. The authors should be more explicit to unpack their reasoning. The reason GLAM (with bias) can account for the confidence effect is the multiplicative interaction of attention and valuation: If there are two high-value items (let's say +10 and +10), then an attention bias of 0.3 leads to accumulation rates of 10 vs. 10*0.3 = 3, so a difference of 7. But if there are two low-value items (e.g., +1 and +1), then the difference is only 0.7. Thus, as soon as there is an imbalance in allocated attention between two options, the difference in accumulation rates between those two options is higher if the options have higher values. This will eventually lead to a larger effect on δ(e).</p></disp-quote><p>We thank the reviewers for suggesting us to unpack the effect of the attention bias in generating the asymmetric effect in the GLAM model. We have modified the paragraph in the Results, section 2.4.2 (Balance of Evidence and Confidence) to be more explicit in the presentation of the role of the multiplicative effect on the results.</p><p>“Overall, these results show how the model is capable of capturing the novel empirical effect on confidence we identified experimentally, giving computational support to the hypothesis that goal-relevant evidence is fed to second order processes like confidence. It also hints at a potential origin to the effects of the sum of evidence (i.e.,ΣValue,ΣDots) on confidence: asymmetries in the accumulation process, in particular the multiplicative effect of attention over accumulation of evidence, may enhance the differences between items that are more relevant for the frame. This consequentially boosts the level of confidence that participants have in their decisions.”</p><p>And we also included the following in the Discussion:</p><p>“In both experiments, the incorporation of goal-relevant evidence to fit the GLAM resulted in a better model fit compared with the model in which the value or perceptual evidence was integrated independently of the frame. […] Further empirical data will be required to test this idea more stringently.”</p><disp-quote content-type="editor-comment"><p>4) Effect of hunger on value-based decisions. Hunger likely plays an important factor to turn this from a cognitive task to a value-based task. However, other than stating that participants were instructed to fast for four hours, I found no mention of measures used to validate hunger. Is a four hour fasting window enough to make people feel hungry? If so, how was participant hunger measured and/or controlled?</p></disp-quote><p>We thank the reviewer for highlighting this point. In our study we did not acquire extra measures to account for the hunger level participants experienced during the experiment. The methodology presented here (i.e. asking participants to fast for a couple of hours before the task) is currently the state of the art in the studies using food snack as value items (just to mention a few: Krajbich et al., 2010; Krajbich and Rangel., 2011; Lim et al., 2011; De Martino et al., 2013; Polania et al., 2014; Folke et al., 2016; Tarantola et al., 2017; Bakkour et al., 2019; Polania et al., 2019). Virtually all these studies do not report additional measures to control for participants hunger. One exception is one of the studies conducted in our lab by Folke et al., 2016, which also used a 4 hour fast, as in our experiment. In that case, we collected blood samples in all participants to measure glucose levels previous to the experiment. It was reported that fasting participants presented levels of glucose comparable to the ones expected for fasting adults. However, when we compared these results with other results from our lab (and other labs) in which the blood test was not performed we discovered that there was virtually no difference in the pattern of behaviour between the two situations since participants showed a good level of compliance even in absence of test. For this reason, we decided in further studies (including this one) to not measure blood glucose level. This is an invasive procedure that was not justified from an ethical point of view given the lack of difference we observed. In any case, it is important to highlight that the main purpose behind making participants hungry was to get them engaged in the task, and willing to report their genuine preferences. Note that most participants were happy to pay out of their reimbursement a price that was significantly higher than the price that they would have paid for same product in a retail shop. This in order to eat the item in the hour that they were forced to stay (after fasting a total 5.5 hours: 4 hours before + 1.5 hour of the experiment). This provide a further indirect suggestion that they were not engaged simply in a cognitive task of price estimation. Finally, the fact that our perceptual study shows virtually an identical pattern of result provide further evidence that the effect we observe is likely to affect in general how evidence is collected and not value specific effect. In a way this is the main take home message of our study.</p><disp-quote content-type="editor-comment"><p>5) Participant drop-out rate. The participant drop-out rate seems extremely high (~20-25%), and seems mainly due to difficulties with how the BDM scale was interpreted. With such a high overall drop-out rate, how can the authors be sure that participant responses on this measure are reliable (even the participants who were included in the analyses)? The authors should discuss explicitly this high drop-out rate.</p></disp-quote><p>We thank the reviewers for this raising this issue. Here we have followed the criteria employed in previous studies in the field with a comparable number of % of subject exclusions. We apologize if our description of exclusion criteria gave the wrong impression that most of the exclusions were due to difficulty in using the BDM scale. This is not the case since the number of participants excluded because of misuses of the BDM scale was actually only 2. In our experiments, one of the main reasons for exclusion was criteria 4, i.e. participants reported exactly the same confidence rating for a high proportion of their choices. Specifically, 4 participants in Value and 3 in Perceptual Experiment were excluded by this reason. This is not unusual for studies measuring confidence (e.g. Folke et al., 2016; Fleming et al., 2018; Rollwage et al., 2018; Mazor et al., 2020) since it has been often described that some participants tend to report extremely low variability in using confidence scale (e.g. report all choices as high confidence.) That makes impossible to use that confidence as a useful dependent variable.</p><p>Another main reason to remove participants was the difficulties in the eye-tracking procedure (e.g. the participant was restless and the tracking was lost in some trials or there were many blinking events). Overall, 3 participants were excluded by eye-tracking problems. We checked that participants were giving reliable responses assessing their performance (i.e. they were reporting the item rated with higher/lower BDM value or number of dots, depending on the frame). We excluded 2 participants with accuracy issues in the Value Experiment and 4 participants in the Perceptual Experiment. In both experiments the excluded participants had performance close to chance level (50%) or they did not follow correctly the instructions being unaware of the change in frame. Please notice that the participants included in the study had, overall, performance around 75%.</p><p>Following the reviewer suggestion, we have now been clearer on the reasons for exclusion and we have included a detailed account of the criteria that caused the exclusion of the participants in the Materials and methods subsection 4.2 Exclusion criteria.</p></body></sub-article></article>