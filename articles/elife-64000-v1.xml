<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD v1.1d3 20150301//EN"  "JATS-archivearticle1.dtd"><article article-type="research-article" dtd-version="1.1d3" xmlns:xlink="http://www.w3.org/1999/xlink"><front><journal-meta><journal-id journal-id-type="nlm-ta">elife</journal-id><journal-id journal-id-type="publisher-id">eLife</journal-id><journal-title-group><journal-title>eLife</journal-title></journal-title-group><issn publication-format="electronic">2050-084X</issn><publisher><publisher-name>eLife Sciences Publications, Ltd</publisher-name></publisher></journal-meta><article-meta><article-id pub-id-type="publisher-id">64000</article-id><article-id pub-id-type="doi">10.7554/eLife.64000</article-id><article-categories><subj-group subj-group-type="display-channel"><subject>Tools and Resources</subject></subj-group><subj-group subj-group-type="heading"><subject>Computational and Systems Biology</subject></subj-group><subj-group subj-group-type="heading"><subject>Ecology</subject></subj-group></article-categories><title-group><article-title>TRex, a fast multi-animal tracking system with markerless identification, and 2D estimation of posture and visual fields</article-title></title-group><contrib-group><contrib contrib-type="author" corresp="yes" id="author-210470"><name><surname>Walter</surname><given-names>Tristan</given-names></name><contrib-id contrib-id-type="orcid">http://orcid.org/0000-0001-8604-7229</contrib-id><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="corresp" rid="cor1">*</xref><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" corresp="yes" id="author-154185"><name><surname>Couzin</surname><given-names>Iain D</given-names></name><contrib-id contrib-id-type="orcid">http://orcid.org/0000-0001-8556-4558</contrib-id><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="corresp" rid="cor2">*</xref><xref ref-type="other" rid="par-1"/><xref ref-type="other" rid="par-2"/><xref ref-type="other" rid="par-3"/><xref ref-type="other" rid="par-4"/><xref ref-type="other" rid="par-5"/><xref ref-type="fn" rid="conf1"/></contrib><aff id="aff1"><institution content-type="dept">Department of Collective Behaviour</institution>, <institution>Max Planck Institute of Animal Behavior</institution>, <addr-line><named-content content-type="city">Konstanz</named-content></addr-line>, <country>Germany</country></aff></contrib-group><contrib-group content-type="section"><contrib contrib-type="editor" id="author-41622"><name><surname>Lentink</surname><given-names>David</given-names></name><role>Reviewing editor</role><aff><institution>Stanford University</institution>, <country>United States</country></aff></contrib></contrib-group><author-notes><corresp id="cor1"><label>*</label>For correspondence: <email>a@trex.run</email> (TW);</corresp><corresp id="cor2"><label>*</label>For correspondence: <email>icouzin@ab.mpg.de</email> (IC);</corresp></author-notes><pub-date date-type="pub" publication-format="electronic"><day>26</day><month>02</month><year>2021</year></pub-date><volume>10</volume><elocation-id>e64000</elocation-id><history><date date-type="received"><day>13</day><month>10</month><year>2020</year></date><date date-type="accepted"><day>25</day><month>02</month><year>2021</year></date></history><permissions><copyright-statement>© 2021, Walter &amp; Couzin</copyright-statement><copyright-year>2021</copyright-year><copyright-holder>Walter &amp; Couzin</copyright-holder><license xlink:href="http://creativecommons.org/licenses/by/4.0/"><license-p>This article is distributed under the terms of the <ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/licenses/by/4.0/">Creative Commons Attribution License</ext-link> permitting unrestricted use and redistribution provided that the original author and source are credited.</license-p></license></permissions><self-uri content-type="pdf" xlink:href="elife-64000-v1.pdf"/><abstract><p>Automated visual tracking of animals is rapidly becoming an indispensable tool for the study of behavior. It offers a quantitative methodology by which organisms' sensing and decision-making can be studied in a wide range of ecological contexts. Despite this, existing solutions tend to be challenging to deploy in practice, especially when considering long and/or high-resolution video-streams. Here, we present TRex, a fast and easy-to-use solution for tracking a large number of individuals simultaneously using background-subtraction with real-time (60Hz) tracking performance for up to approximately 256 individuals and estimates 2D visual-fields, outlines, and head/rear of bilateral animals, both in open and closed-loop contexts. Additionally, TRex offers highly-accurate, deep-learning-based visual identification of up to approximately 100 unmarked individuals, where it is between 2.5-46.7 times faster, and requires 2-10 times less memory, than comparable software (with relative performance increasing for more organisms/longer videos) and provides interactive data-exploration within an intuitive, platform-independent graphical user-interface.</p></abstract><kwd-group kwd-group-type="research-organism"><title>Research organism</title><kwd><italic>D. melanogaster</italic></kwd><kwd>Zebrafish</kwd><kwd>Other</kwd></kwd-group><funding-group><award-group id="par-1"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/100000154</institution-id><institution>Division of Integrative Organismal Systems</institution></institution-wrap></funding-source><award-id>IOS-1355061</award-id><principal-award-recipient><name><surname>Couzin</surname><given-names>Iain D</given-names></name></principal-award-recipient></award-group><award-group id="par-2"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/100000006</institution-id><institution>Office of Naval Research</institution></institution-wrap></funding-source><award-id>N00014-19-1-2556</award-id><principal-award-recipient><name><surname>Couzin</surname><given-names>Iain D</given-names></name></principal-award-recipient></award-group><award-group id="par-3"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/501100001659</institution-id><institution>Deutsche Forschungsgemeinschaft</institution></institution-wrap></funding-source><award-id>EXC 2117-422037984</award-id><principal-award-recipient><name><surname>Couzin</surname><given-names>Iain D</given-names></name></principal-award-recipient></award-group><award-group id="par-4"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/501100004189</institution-id><institution>Max-Planck-Gesellschaft</institution></institution-wrap></funding-source><principal-award-recipient><name><surname>Couzin</surname><given-names>Iain D</given-names></name></principal-award-recipient></award-group><award-group id="par-5"><funding-source><institution-wrap><institution>Struktur- und Innovationsfunds fuer die Forschung of the State of Baden-Wuerttemberg</institution></institution-wrap></funding-source><principal-award-recipient><name><surname>Couzin</surname><given-names>Iain D</given-names></name></principal-award-recipient></award-group><funding-statement>The funders had no role in study design, data collection and interpretation, or the decision to submit the work for publication.</funding-statement></funding-group></article-meta></front><back><sec id="s1" sec-type="additional-information"><title>Additional information</title><fn-group content-type="competing-interest"><title>Competing interest</title><fn fn-type="conflict" id="conf1"><p>The authors declare that no competing interests exist.</p></fn></fn-group><fn-group content-type="ethics-information"><title>Ethics</title><fn fn-type="other"><p>Animal experimentation: We herewith confirm that the care and use of animals described in this work is covered by the protocols 35-9185.81/G-17/162, 35-9185.81/G-17/88  and 35-9185.81/G-16/116 granted by the Regional Council of the State of Baden-Württemberg, Freiburg, Germany, to the Max Planck Institute of Animal Behavior in accordance with the German Animal Welfare Act (TierSchG) and the Regulation for the Protection of Animals Used for Experimental or Other Scientific Purposes (Animal Welfare Regulation Governing Experimental Animals - TierSchVersV).</p></fn></fn-group></sec><sec id="s2" sec-type="supplementary-material"><title>Additional Files</title><sec id="s3" sec-type="data-availability"><title>Data availability</title><p>Video data that has been used in the evaluation of TRex has been deposited in MPG Open Access Data Repository (Edmond), under the Creative Commons BY 4.0 license, at https://dx.doi.org/10.17617/3.4yMost raw videos have been trimmed, since original files are each up to 200GB in size. Pre-processed versions (in PV format) are included, so that all steps after conversion can be reproduced directly (conversion speeds do not change with video length, so proportional results are reproducible as well). Full raw videos are made available upon reasonable request.All analysis scripts, scripts used to process the original videos, and the source code/pre-compiled binaries (linux-64) that have been used, are archived in this repository. Most intermediate data (PV videos, log files, tracking data, etc.) are included, and the binaries along with the scripts can be used to automatically generate all intermediate steps. The application source code is available for free under https://github.com/mooch443/trex.Videos 11, 12 and 13 are part of idtracker.ai's example videos: URL https://drive.google.com/file/d/1pAR6oJjrEn7jf_OU2yMdyT2UJZMTNoKC/view?usp=sharing  (10_zebrafish.tar.gz) [Francisco Romero, 2018, Examples for idtracker.ai, Online, Accessed 23-Oct-2020];Video 7  (video_example_100fish_1min.avi): URL https://drive.google.com/file/d/1Tl64CHrQoc05PDElHvYGzjqtybQc4g37/view?usp=sharing [Francisco Romero, 2018, Examples for idtracker.ai, Online, Accessed 23-Oct-2020];V1 from Appendix 12: https://drive.google.com/drive/folders/1Nir2fzgxofz-fcojEiG_JCNXsGQXj_9k [Francisco Romero, 2018, Examples for idtracker.ai, Online, Accessed 09-Feb-2021];</p><p>The following datasets were generated:</p><p><element-citation id="dataset1" publication-type="data" specific-use="isSupplementedBy"><person-group person-group-type="author"><collab>Walter T</collab><collab>Albi A</collab><collab>Bath D</collab><collab>Hugo H</collab><collab>Oberhauser F</collab><collab>Mink D</collab><collab>Groettrup M</collab></person-group><year iso-8601-date="2020">2020</year><source>Reproduction Data for: TRex, a fast multi-animal tracking system with markerless identification, and 2D estimation of posture and visual fields</source><ext-link ext-link-type="uri" xlink:href="https://edmond.mpdl.mpg.de/imeji/collection/eVbVH0_57TwQsAe8">https://edmond.mpdl.mpg.de/imeji/collection/eVbVH0_57TwQsAe8</ext-link><comment>MPDL Edmond, eVbVH0_57TwQsAe8</comment></element-citation></p></sec><supplementary-material><ext-link xlink:href="elife-64000-supp-v1.zip">Download zip</ext-link><p>Any figures and tables for this article are included in the PDF. The zip folder contains additional supplemental files.</p></supplementary-material></sec></back></article>