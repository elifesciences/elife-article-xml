<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD v1.1d3 20150301//EN"  "JATS-archivearticle1.dtd"><article xmlns:xlink="http://www.w3.org/1999/xlink" article-type="research-article" dtd-version="1.1d3"><front><journal-meta><journal-id journal-id-type="nlm-ta">elife</journal-id><journal-id journal-id-type="publisher-id">eLife</journal-id><journal-title-group><journal-title>eLife</journal-title></journal-title-group><issn publication-format="electronic">2050-084X</issn><publisher><publisher-name>eLife Sciences Publications, Ltd</publisher-name></publisher></journal-meta><article-meta><article-id pub-id-type="publisher-id">77772</article-id><article-id pub-id-type="doi">10.7554/eLife.77772</article-id><article-categories><subj-group subj-group-type="display-channel"><subject>Tools and Resources</subject></subj-group><subj-group subj-group-type="heading"><subject>Neuroscience</subject></subj-group></article-categories><title-group><article-title>Deep learning based feature extraction for prediction and interpretation of sharp-wave ripples in the rodent hippocampus</article-title></title-group><contrib-group><contrib contrib-type="author" id="author-272659"><name><surname>Navas-Olive</surname><given-names>Andrea</given-names></name><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="other" rid="par-2"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" id="author-272660"><name><surname>Amaducci</surname><given-names>Rodrigo</given-names></name><xref ref-type="aff" rid="aff2">2</xref><xref ref-type="other" rid="par-3"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" id="author-152531"><name><surname>Jurado-Parras</surname><given-names>Maria-Teresa</given-names></name><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" id="author-272661"><name><surname>Sebastian</surname><given-names>Enrique R</given-names></name><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" corresp="yes" id="author-116305"><name><surname>de la Prida</surname><given-names>Liset M</given-names></name><contrib-id contrib-id-type="orcid">http://orcid.org/0000-0002-0160-6472</contrib-id><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="corresp" rid="cor1">*</xref><xref ref-type="other" rid="par-1"/><xref ref-type="fn" rid="conf2"/></contrib><aff id="aff1"><institution content-type="dept">Functional and Systems Neuroscience</institution>, <institution>Instituto Cajal</institution>, <addr-line><named-content content-type="city">Madrid</named-content></addr-line>, <country>Spain</country></aff><aff id="aff2"><institution content-type="dept">Grupo de Neurocomputación Biológica</institution>, <institution>Universidad Autónoma de Madrid</institution>, <addr-line><named-content content-type="city">Madrid</named-content></addr-line>, <country>Spain</country></aff></contrib-group><contrib-group content-type="section"><contrib contrib-type="editor" id="author-68914"><name><surname>Peyrache</surname><given-names>Adrien</given-names></name><role>Reviewing editor</role><aff><institution>McGill University</institution>, <country>Canada</country></aff></contrib></contrib-group><author-notes><corresp id="cor1"><label>*</label>For correspondence: <email>lmprida@cajal.csic.es</email> (Ld);</corresp></author-notes><pub-date date-type="pub" publication-format="electronic"><day>05</day><month>09</month><year>2022</year></pub-date><volume>11</volume><elocation-id>e77772</elocation-id><history><date date-type="received"><day>10</day><month>02</month><year>2022</year></date><date date-type="accepted"><day>02</day><month>09</month><year>2022</year></date></history><permissions><copyright-statement>© 2022, Navas-Olive et al</copyright-statement><copyright-year>2022</copyright-year><copyright-holder>Navas-Olive et al</copyright-holder><license xlink:href="http://creativecommons.org/licenses/by/4.0/"><license-p>This article is distributed under the terms of the <ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/licenses/by/4.0/">Creative Commons Attribution License</ext-link> permitting unrestricted use and redistribution provided that the original author and source are credited.</license-p></license></permissions><self-uri content-type="pdf" xlink:href="elife-77772-v1.pdf"/><abstract><p>Local field potential (LFP) deflections and oscillations define hippocampal sharp-wave ripples (SWR), one of the most synchronous events of the brain. SWR reflect firing and synaptic current sequences emerging from cognitively relevant neuronal ensembles. While spectral analysis have permitted advances, the surge of ultra-dense recordings now call for new automatic detection strategies. Here, we show how one-dimensional convolutional networks operating over high-density LFP hippocampal recordings allowed for automatic identification of SWR from the rodent hippocampus. When applied without retraining to new datasets and ultra-dense hippocampus-wide recordings, we discovered physiologically relevant processes associated to the emergence of SWR, prompting for novel classification criteria. To gain interpretability, we developed a method to interrogate the operation of the artificial network. We found it relied in feature-based specialization, which permit identification of spatially segregated oscillations and deflections, as well as synchronous population firing typical of replay. Thus, using deep learning based approaches may change the current heuristic for a better mechanistic interpretation of these relevant neurophysiological events.</p></abstract><kwd-group kwd-group-type="research-organism"><title>Research organism</title><kwd>Mouse</kwd><kwd>Rat</kwd></kwd-group><funding-group><award-group id="par-1"><funding-source><institution-wrap><institution>Fundacion La Caixa</institution></institution-wrap></funding-source><award-id>LCF/PR/HR21/52410030</award-id><principal-award-recipient><name><surname>de la Prida</surname><given-names>Liset M</given-names></name></principal-award-recipient></award-group><award-group id="par-2"><funding-source><institution-wrap><institution>Ministerio de Educacion</institution></institution-wrap></funding-source><award-id>FPU17/03268</award-id><principal-award-recipient><name><surname>Navas-Olive</surname><given-names>Andrea</given-names></name></principal-award-recipient></award-group><award-group id="par-3"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/501100004593</institution-id><institution>Universidad Autónoma de Madrid</institution></institution-wrap></funding-source><award-id>FPI-UAM-2017</award-id><principal-award-recipient><name><surname>Amaducci</surname><given-names>Rodrigo</given-names></name></principal-award-recipient></award-group><funding-statement>The funders had no role in study design, data collection and interpretation, or the decision to submit the work for publication.</funding-statement></funding-group></article-meta></front><back><sec id="s1" sec-type="additional-information"><title>Additional information</title><fn-group content-type="competing-interest"><title>Competing interest</title><fn fn-type="conflict" id="conf2"><p>Liset M de la Prida, Reviewing editor, <italic>eLife</italic>.</p></fn><fn fn-type="conflict" id="conf1"><p>The other authors declare that no competing interests exist.</p></fn></fn-group><fn-group content-type="ethics-information"><title>Ethics</title><fn fn-type="other"><p>Animal experimentation: All protocols and procedures were performed according to the Spanish legislation (R.D. 1201/2005 and L.32/2007) and the European Communities Council Directive 2003 (2003/65/CE). Experiments and procedures were approved by the Ethics Committee of the Instituto Cajal and the Spanish Research Council (PROEX131-16 and PROEX161-19). All surgical procedures were performed under isoflurane anesthesia and every effort was made to minimize suffering.</p></fn></fn-group></sec><sec id="s2" sec-type="supplementary-material"><title>Additional Files</title><sec id="s3" sec-type="data-availability"><title>Data availability</title><p>Data is deposited in the Figshare repository https://figshare.com/projects/cnn-ripple-data/117897. The trained model is accessible at the Github repository for both Python: https://github.com/PridaLab/cnn-ripple, and Matlab: https://github.com/PridaLab/cnn-matlab Code visualization and detection is shown in an interactive notebook https://colab.research.google.com/github/PridaLab/cnn-ripple/blob/main/src/notebooks/cnn-example.ipynb . The online detection Open Ephys plugin is accessible at the Github repository: https://github.com/PridaLab/CNNRippleDetectorOEPlugin</p></sec><supplementary-material><ext-link xlink:href="elife-77772-supp-v1.zip">Download zip</ext-link><p>Any figures and tables for this article are included in the PDF. The zip folder contains additional supplemental files.</p></supplementary-material></sec></back></article>