<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD with MathML3 v1.2 20190208//EN"  "JATS-archivearticle1-mathml3.dtd"><article xmlns:ali="http://www.niso.org/schemas/ali/1.0/" xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" article-type="research-article" dtd-version="1.2"><front><journal-meta><journal-id journal-id-type="nlm-ta">elife</journal-id><journal-id journal-id-type="publisher-id">eLife</journal-id><journal-title-group><journal-title>eLife</journal-title></journal-title-group><issn publication-format="electronic" pub-type="epub">2050-084X</issn><publisher><publisher-name>eLife Sciences Publications, Ltd</publisher-name></publisher></journal-meta><article-meta><article-id pub-id-type="publisher-id">81527</article-id><article-id pub-id-type="doi">10.7554/eLife.81527</article-id><article-categories><subj-group subj-group-type="display-channel"><subject>Research Article</subject></subj-group><subj-group subj-group-type="heading"><subject>Neuroscience</subject></subj-group></article-categories><title-group><article-title>Descending neuron population dynamics during odor-evoked and spontaneous limb-dependent behaviors</article-title></title-group><contrib-group><contrib contrib-type="author" id="author-284871"><name><surname>Aymanns</surname><given-names>Florian</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">https://orcid.org/0000-0003-4290-7244</contrib-id><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="other" rid="fund1"/><xref ref-type="fn" rid="con1"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" id="author-193303"><name><surname>Chen</surname><given-names>Chin-Lin</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">https://orcid.org/0000-0002-4968-4920</contrib-id><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="fn" rid="con2"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" corresp="yes" id="author-142297"><name><surname>Ramdya</surname><given-names>Pavan</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">https://orcid.org/0000-0001-5425-4610</contrib-id><email>pavan.ramdya@epfl.ch</email><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="other" rid="fund2"/><xref ref-type="other" rid="fund3"/><xref ref-type="fn" rid="con3"/><xref ref-type="fn" rid="conf1"/></contrib><aff id="aff1"><label>1</label><institution-wrap><institution-id institution-id-type="ror">https://ror.org/02s376052</institution-id><institution>Neuroengineering Laboratory, Brain Mind Institute &amp; Interfaculty Institute of Bioengineering, EPFL</institution></institution-wrap><addr-line><named-content content-type="city">Lausanne</named-content></addr-line><country>Switzerland</country></aff></contrib-group><contrib-group content-type="section"><contrib contrib-type="editor"><name><surname>VijayRaghavan</surname><given-names>K</given-names></name><role>Reviewing Editor</role><aff><institution-wrap><institution-id institution-id-type="ror">https://ror.org/03ht1xw27</institution-id><institution>National Centre for Biological Sciences, Tata Institute of Fundamental Research</institution></institution-wrap><country>India</country></aff></contrib><contrib contrib-type="senior_editor"><name><surname>VijayRaghavan</surname><given-names>K</given-names></name><role>Senior Editor</role><aff><institution-wrap><institution-id institution-id-type="ror">https://ror.org/03ht1xw27</institution-id><institution>National Centre for Biological Sciences, Tata Institute of Fundamental Research</institution></institution-wrap><country>India</country></aff></contrib></contrib-group><pub-date publication-format="electronic" date-type="publication"><day>26</day><month>10</month><year>2022</year></pub-date><pub-date pub-type="collection"><year>2022</year></pub-date><volume>11</volume><elocation-id>e81527</elocation-id><history><date date-type="received" iso-8601-date="2022-06-30"><day>30</day><month>06</month><year>2022</year></date><date date-type="accepted" iso-8601-date="2022-10-13"><day>13</day><month>10</month><year>2022</year></date></history><pub-history><event><event-desc>This manuscript was published as a preprint at bioRxiv.</event-desc><date date-type="preprint" iso-8601-date="2022-07-03"><day>03</day><month>07</month><year>2022</year></date><self-uri content-type="preprint" xlink:href="https://doi.org/10.1101/2022.06.30.497612"/></event></pub-history><permissions><copyright-statement>© 2022, Aymanns et al</copyright-statement><copyright-year>2022</copyright-year><copyright-holder>Aymanns et al</copyright-holder><ali:free_to_read/><license xlink:href="http://creativecommons.org/licenses/by/4.0/"><ali:license_ref>http://creativecommons.org/licenses/by/4.0/</ali:license_ref><license-p>This article is distributed under the terms of the <ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/licenses/by/4.0/">Creative Commons Attribution License</ext-link>, which permits unrestricted use and redistribution provided that the original author and source are credited.</license-p></license></permissions><self-uri content-type="pdf" xlink:href="elife-81527-v1.pdf"/><self-uri content-type="figures-pdf" xlink:href="elife-81527-figures-v1.pdf"/><abstract><p>Deciphering how the brain regulates motor circuits to control complex behaviors is an important, long-standing challenge in neuroscience. In the fly, <italic>Drosophila melanogaster</italic>, this is coordinated by a population of ~ 1100 descending neurons (DNs). Activating only a few DNs is known to be sufficient to drive complex behaviors like walking and grooming. However, what additional role the larger population of DNs plays during natural behaviors remains largely unknown. For example, they may modulate core behavioral commands or comprise parallel pathways that are engaged depending on sensory context. We evaluated these possibilities by recording populations of nearly 100 DNs in individual tethered flies while they generated limb-dependent behaviors, including walking and grooming. We found that the largest fraction of recorded DNs encode walking while fewer are active during head grooming and resting. A large fraction of walk-encoding DNs encode turning and far fewer weakly encode speed. Although odor context does not determine which behavior-encoding DNs are recruited, a few DNs encode odors rather than behaviors. Lastly, we illustrate how one can identify individual neurons from DN population recordings by using their spatial, functional, and morphological properties. These results set the stage for a comprehensive, population-level understanding of how the brain’s descending signals regulate complex motor actions.</p></abstract><kwd-group kwd-group-type="author-keywords"><kwd>population imaging</kwd><kwd>two-photon microscopy</kwd><kwd>descending neuron</kwd><kwd>walking</kwd><kwd>grooming</kwd><kwd>limb</kwd></kwd-group><kwd-group kwd-group-type="research-organism"><title>Research organism</title><kwd><italic>D. melanogaster</italic></kwd></kwd-group><funding-group><award-group id="fund1"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/501100001645</institution-id><institution>Boehringer Ingelheim Fonds</institution></institution-wrap></funding-source><principal-award-recipient><name><surname>Aymanns</surname><given-names>Florian</given-names></name></principal-award-recipient></award-group><award-group id="fund2"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/501100001711</institution-id><institution>Schweizerischer Nationalfonds zur Förderung der Wissenschaftlichen Forschung</institution></institution-wrap></funding-source><award-id>175667</award-id><principal-award-recipient><name><surname>Ramdya</surname><given-names>Pavan</given-names></name></principal-award-recipient></award-group><award-group id="fund3"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/501100001711</institution-id><institution>Schweizerischer Nationalfonds zur Förderung der Wissenschaftlichen Forschung</institution></institution-wrap></funding-source><award-id>181239</award-id><principal-award-recipient><name><surname>Ramdya</surname><given-names>Pavan</given-names></name></principal-award-recipient></award-group><funding-statement>The funders had no role in study design, data collection and interpretation, or the decision to submit the work for publication.</funding-statement></funding-group><custom-meta-group><custom-meta specific-use="meta-only"><meta-name>Author impact statement</meta-name><meta-value>In the fly, <italic>Drosophila melanogaster</italic>, the population activity of descending neurons (DNs) projecting from the brain to the motor system is predominantly correlated with locomotion with only a few DNs encoding grooming or olfactory signals in the absence of behavior.</meta-value></custom-meta></custom-meta-group></article-meta></front><body><sec id="s1" sec-type="intro"><title>Introduction</title><p>The richness of animal behaviors depends on the coordinated actions of many individual neurons within a population. For example, neurons or small networks may compete in a winner-take-all manner to select the next most appropriate motor action (<xref ref-type="bibr" rid="bib22">Cisek and Kalaska, 2010</xref>). To then drive behaviors, the brain conveys these decisions to motor circuits via a population of descending neurons (DNs) projecting to the spinal cord of vertebrates or ventral nerve cord (VNC) of invertebrates. There, DN axons impinge upon local circuits including central pattern generators (CPGs) that transform DN directives into specific limb or body part movements (<xref ref-type="bibr" rid="bib12">Bouvier et al., 2015</xref>; <xref ref-type="bibr" rid="bib17">Capelli et al., 2017</xref>; <xref ref-type="bibr" rid="bib15">Caggiano et al., 2018</xref>; <xref ref-type="bibr" rid="bib59">Orger et al., 2008</xref>). Because DNs make up only about 1% of brain neurons, DN population activity represents a critical information bottleneck: high-dimensional brain dynamics must be compressed into low-dimensional commands that efficiently interface with and are read out by motor circuits. The information carried by individual DNs has long been a topic of interest (<xref ref-type="bibr" rid="bib31">Heinrich, 2002</xref>; <xref ref-type="bibr" rid="bib40">Kien, 1990</xref>; <xref ref-type="bibr" rid="bib11">Böhm and Schildberger, 1992</xref>). Through electrophysiological recordings in large insects, the activities of individual DNs have been linked to behaviors like walking and stridulation (<xref ref-type="bibr" rid="bib31">Heinrich, 2002</xref>). For some DNs, links between firing rate and behavioral features like walking speed have also been established (<xref ref-type="bibr" rid="bib11">Böhm and Schildberger, 1992</xref>). However, how the larger population of DNs coordinate their activities remains unknown.</p><p>The fruit fly, <italic>Drosophila melanogaster</italic>, is an excellent model for investigating how DNs regulate behavior. Flies are genetically-tractable, have a rich behavioral repertoire, and have a numerically small and compact nervous system (<xref ref-type="bibr" rid="bib58">Olsen and Wilson, 2008</xref>). <italic>Drosophila</italic> are thought to have between ~350 (<xref ref-type="bibr" rid="bib53">Namiki et al., 2018</xref>) and ~500 (<xref ref-type="bibr" rid="bib33">Hsu and Bhandawat, 2016</xref>) pairs of DNs. Sparse sets of these DNs can be experimentally targeted using transgenic driver lines (<xref ref-type="bibr" rid="bib53">Namiki et al., 2018</xref>) for functional recordings (<xref ref-type="bibr" rid="bib82">von Reyn et al., 2014</xref>; <xref ref-type="bibr" rid="bib70">Schnell et al., 2017</xref>; <xref ref-type="bibr" rid="bib20">Chen et al., 2018</xref>; <xref ref-type="bibr" rid="bib2">Ache et al., 2019b</xref>; <xref ref-type="bibr" rid="bib54">Namiki et al., 2022</xref>) or physiological perturbations (<xref ref-type="bibr" rid="bib16">Cande, 2018</xref>; <xref ref-type="bibr" rid="bib85">Zacarias et al., 2018</xref>; <xref ref-type="bibr" rid="bib1">Ache et al., 2019a</xref>; <xref ref-type="bibr" rid="bib54">Namiki et al., 2022</xref>; <xref ref-type="bibr" rid="bib28">Guo et al., 2022</xref>). The functional properties of DNs can be understood within a circuit context using emerging connectomics datasets (<xref ref-type="bibr" rid="bib87">Zheng et al., 2018</xref>; <xref ref-type="bibr" rid="bib62">Phelps et al., 2021</xref>). Thus, by building upon foundational work in other insects (<xref ref-type="bibr" rid="bib31">Heinrich, 2002</xref>; <xref ref-type="bibr" rid="bib40">Kien, 1990</xref>; <xref ref-type="bibr" rid="bib11">Böhm and Schildberger, 1992</xref>), studies in <italic>Drosophila</italic> can ultimately reveal how identified DNs work collectively to regulate complex behaviors.</p><p>Until now, investigations of <italic>Drosophila</italic> have focused on individual or small sets of DNs. These studies have demonstrated that artificial activation of DN pairs is sufficient to drive complex behaviors including escape (<xref ref-type="bibr" rid="bib45">Lima and Miesenböck, 2005</xref>) (giant fiber neurons, 'GF'), antennal grooming (<xref ref-type="bibr" rid="bib29">Hampel et al., 2015</xref>)(antennal descending neurons, 'aDN'), backward walking (<xref ref-type="bibr" rid="bib8">Bidaye et al., 2014</xref>) (moonwalker descending neurons, 'MDN'), forward walking (<xref ref-type="bibr" rid="bib9">Bidaye et al., 2020</xref>) (DNp09), and landing (<xref ref-type="bibr" rid="bib1">Ache et al., 2019a</xref>) (DNp10 and DNp07). These results also suggest a command-like role for some DNs in that they are both necessary and sufficient to drive particular actions (<xref ref-type="bibr" rid="bib43">Kupfermann and Weiss, 1978</xref>).</p><p>Although a command-like role for individual DNs is intuitively easy to grasp it may not translate well toward understanding how natural behavior is coordinated by large DN populations. Notably, a behavioral screen revealed that optogenetic activation of most DNs drives only small changes in locomotor and grooming behaviors (<xref ref-type="bibr" rid="bib16">Cande, 2018</xref>) rather than a large variety of distinct actions as might be expected if each DN was a command-like neuron. Therefore, DN populations likely employ additional control approaches. For example, some groups of DNs might modulate or fine-tune actions primarily driven by other command-like DNs. The balance between command-like and modulatory roles of DNs may differ for stereotyped versus flexible behaviors. In line with having a role in behavioral modulation, studies in crickets and locusts have demonstrated that changes in the firing rates of some DNs (<xref ref-type="bibr" rid="bib11">Böhm and Schildberger, 1992</xref>; <xref ref-type="bibr" rid="bib88">Zorović and Hedwig, 2011</xref>) correlate with walking speed and turning (<xref ref-type="bibr" rid="bib31">Heinrich, 2002</xref>). Alternatively, DN subpopulations may represent parallel pathways that are recruited depending on sensory context (<xref ref-type="bibr" rid="bib34">Israel et al., 2022</xref>). For example, different groups of DNs may be differentially engaged during odor-evoked versus spontaneously-generated walking (<xref ref-type="bibr" rid="bib31">Heinrich, 2002</xref>; <xref ref-type="bibr" rid="bib40">Kien, 1990</xref>). Finally, some DNs may convey raw sensory information—instead of be active during behaviors—to enable feedback control of downstream motor circuits. For example, in addition to discovering DNs that are active during steering, one recent study also observed DNa02 activity in response to fictive odors in immobile flies (<xref ref-type="bibr" rid="bib65">Rayshubskiy, 2020</xref>). DNp07 activity has also been observed in response to visual stimulation in nonflying flies (<xref ref-type="bibr" rid="bib1">Ache et al., 2019a</xref>).</p><p>To resolve how DNs engage and modulate ongoing behaviors, one would ideally measure the causal relationship between DN activation and behavioral output. Although this has already been done for sparse sets of DNs (<xref ref-type="bibr" rid="bib16">Cande, 2018</xref>), emerging evidence suggests that in many instances DNs act as a population to control behaviors (<xref ref-type="bibr" rid="bib54">Namiki et al., 2022</xref>). Thus, activating specific pairs or groups of DNs would be extremely valuable. However, achieving the precise co-activation of groups of DNs is technically challenging and combinatorially daunting. One important step is to first identify which DNs are co-active during population recordings in behaving animals. Similarly, to determine the degree to which DNs are recruited depending on sensory context and/or convey raw sensory information from the environment, rather than recording one DN at a time a faster complementary approach would be to record the activity of multiple DNs during the sequential presentation of well-controlled sensory cues. Until now DN population recordings have not been performed due to several technical challenges. First, there has been an absence of tools for selectively genetically targeting DN populations. Additionally, because DN cell bodies and neurites are distributed across the brain (<xref ref-type="bibr" rid="bib53">Namiki et al., 2018</xref>), relatively invasive (<xref ref-type="bibr" rid="bib48">Mann et al., 2017</xref>) volumetric imaging approaches would be required to simultaneously record the activity of many DNs at once. As an alternative, we previously developed a thoracic dissection approach that enables the optical recording of descending and ascending axons within the cervical connective in tethered, behaving animals (<xref ref-type="bibr" rid="bib20">Chen et al., 2018</xref>; <xref ref-type="bibr" rid="bib32">Hermans et al., 2021</xref>; <xref ref-type="fig" rid="fig1">Figure 1a</xref>). Here, we combined this imaging approach with genetic tools (<xref ref-type="bibr" rid="bib5">Asahina et al., 2014</xref>) that restrict the expression of neural activity reporters to the brain. This allowed us to record populations of nearly 100 DNs in individual tethered, behaving flies. During these recordings we presented olfactory stimuli and acquired behavioral data for 3D pose estimation (<xref ref-type="bibr" rid="bib27">Günel et al., 2019</xref>), as well as fictive locomotor trajectories (<xref ref-type="bibr" rid="bib51">Moore et al., 2014</xref>).</p><fig-group><fig id="fig1" position="float"><label>Figure 1.</label><caption><title>Recording descending neuron (DN) population activity and animal behavior.</title><p>(<bold>a</bold>) Schematic of the <italic>Drosophila</italic> nervous system showing DNs projecting from the brain to motor circuits in the ventral nerve cord (VNC). For clarity, only two pairs of DNs (red and blue) are shown. Indicated (dashed gray line) is the coronal imaging region-of-interest (ROI) in the thoracic cervical connective. (<bold>b</bold>) In a ‘modulation’ framework for DN population control, new DNs (red) may be recruited to modulate ongoing behaviors primarily driven by core DNs (blue). Each ellipse is an individual DN axon (white, blue, and red). (<bold>c</bold>) In a ‘context dependence’ framework for DN population control, different DNs may be recruited to drive identical behaviors depending on sensory context. (<bold>d</bold>) Alternatively, in a ‘sensory encoding’ framework, many DNs may not drive or be active during behaviors but rather transmit raw sensory signals to the VNC. (<bold>e</bold>) An approach for deriving DN cell identity from population recordings. One may first identify sparse transgenic strains labeling specific neurons from DN populations (circled in black) using their functional attributes/encoding, positions within the cervical connective, and the shapes of their axons. Ultimately, one can use sparse morphological data to find corresponding neurons in the brain and VNC connectomes. (<bold>f, g</bold>) Template-registered confocal volume z-projections illustrating a ‘brain only’ driver line (otd-nls:FLPo; R57C10-GAL4,tub&gt;GAL80&gt;) expressing (<bold>f</bold>) a nuclear (histone-sfGFP) or (<bold>g</bold>) a cytosolic (smGFP) fluorescent reporter. Scale bar is 50 μm. Location of two-photon imaging plane in the thoracic cervical connective is indicated (white dashed lines). Tissues are stained for GFP (green) and neuropil (‘nc82’, magenta). (<bold>h</bold>) Schematic of the VNC illustrating the coronal (x–z) imaging plane. Dorsal-ventral (‘Dor’) and anterior–posterior (‘Ant’) axes are indicated. (<bold>i</bold>) Denoised two-photon image of DN axons passing through the thoracic cervical connective. Scale bar is 10 μm. (<bold>j</bold>) Two-photon imaging data from panel (<bold>i</bold>) following motion correction and <inline-formula><mml:math id="inf1"><mml:mrow><mml:mo>%</mml:mo><mml:mi mathvariant="normal">Δ</mml:mi><mml:mi>F</mml:mi><mml:mo>/</mml:mo><mml:mi>F</mml:mi></mml:mrow></mml:math></inline-formula> color-coding. An ROI (putative DN axon or closely intermingled axons) is indicated (white dashed circle). (<bold>k</bold>) Sample normalized <inline-formula><mml:math id="inf2"><mml:mrow><mml:mo>%</mml:mo><mml:mi mathvariant="normal">Δ</mml:mi><mml:mi>F</mml:mi><mml:mo>/</mml:mo><mml:mi>F</mml:mi></mml:mrow></mml:math></inline-formula> time-series traces for 28 (out of 95 total) ROIs recorded from one animal. Behavioral classification at each time point is indicated below and is color-coded as in panel (<bold>p</bold>). (<bold>l</bold>) Schematic of system for recording behavior and delivering odors during two-photon imaging (not to scale) while a tethered fly walks on a spherical treadmill. (<bold>m</bold>) Spherical treadmill ball rotations (fictive walking trajectories) are captured using the front camera and processed using FicTrac software. Overlaid (cyan) is a sample walking trajectory. (<bold>n</bold>) Video recording of a fly from six camera angles. (<bold>o</bold>) Multiview camera images are processed using DeepFly3D to calculate 2D poses and then triangulated 3D poses. These 3D poses are further processed to obtain joint angles. (<bold>p</bold>) Joint angles are input to a dilated temporal convolutional network (DTCN) to classify behaviors including walking, resting, head (eye and antennal) grooming, front leg rubbing, or posterior (abdominal and hindleg) movements.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-81527-fig1-v1.tif"/></fig><fig id="fig1s1" position="float" specific-use="child-fig"><label>Figure 1—figure supplement 1.</label><caption><title>Supporting details regarding neural denoising, driver line expression, odor stimulation, and behavior quantification.</title><p>(<bold>a</bold>) Example <inline-formula><mml:math id="inf3"><mml:mrow><mml:mrow><mml:mi mathvariant="normal">Δ</mml:mi><mml:mo>⁢</mml:mo><mml:mi>F</mml:mi></mml:mrow><mml:mo>/</mml:mo><mml:mi>F</mml:mi></mml:mrow></mml:math></inline-formula> traces extracted from optic-flow registered ‘Raw’ (gray) and corresponding ‘Denoised’ (black) images. (<bold>b</bold>, top) Time lag between denoised and raw <inline-formula><mml:math id="inf4"><mml:mrow><mml:mrow><mml:mi mathvariant="normal">Δ</mml:mi><mml:mo>⁢</mml:mo><mml:mi>F</mml:mi></mml:mrow><mml:mo>/</mml:mo><mml:mi>F</mml:mi></mml:mrow></mml:math></inline-formula> traces with maximal cross-correlation. Overlaid are individual data points from each fly (color-coded). (<bold>b</bold>, bottom) Average cross-correlation for all regions-of-interest (ROIs) and flies (solid line) and corresponding 95% confidence interval (shaded region). (<bold>c</bold>) Z-projected confocal image of the genetic complement of the ‘brain only’ driver line (otd-nls:FLPo,tub&gt;stop&gt;GAL80; R57C10-GAL4) expressing nuclear GFP. Shown are staining for neuropil (‘nc82’, magenta) and GFP (green). Scale bar is 50 μm. (<bold>d–f</bold>) Photoionization detector (PID) measurements during odor delivery switching between (<bold>d</bold>) humid and dry air, (<bold>e</bold>) humid and humid air (to measure valve-related transients) or (<bold>f</bold>) humid air, methyl salicylate (MSC), and apple cider vinegar (ACV) odors. (<bold>g</bold>) Results of leave-one-fly-out cross-validation hyperparameter search for the behavior classifier. The values <inline-formula><mml:math id="inf5"><mml:mrow><mml:msub><mml:mi>λ</mml:mi><mml:mrow><mml:mi>w</mml:mi><mml:mo>⁢</mml:mo><mml:mi>e</mml:mi><mml:mo>⁢</mml:mo><mml:mi>a</mml:mi><mml:mo>⁢</mml:mo><mml:mi>k</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:math></inline-formula> and <inline-formula><mml:math id="inf6"><mml:mrow><mml:msub><mml:mi>λ</mml:mi><mml:mrow><mml:mi>p</mml:mi><mml:mo>⁢</mml:mo><mml:mi>r</mml:mi><mml:mo>⁢</mml:mo><mml:mi>e</mml:mi><mml:mo>⁢</mml:mo><mml:mi>d</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:math></inline-formula> yield the highest classification accuracy. (<bold>h</bold>) Relative frequency of classified behaviors in our dataset (n = 5 animals). (<bold>i</bold>) The frequency of transitions between sequential behaviors.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-81527-fig1-figsupp1-v1.tif"/></fig><fig id="fig1s2" position="float" specific-use="child-fig"><label>Figure 1—figure supplement 2.</label><caption><title>The range of joint angles explored during fly behaviors.</title><p>Each subplot shows the normalized kernel density estimate of the distribution of a specific angle for the front, middle, or hind legs. Joint angles from all time points and flies were pooled to generate kernel density estimates. The angles are defined as described in <xref ref-type="bibr" rid="bib46">Lobato-Rios et al., 2022</xref>.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-81527-fig1-figsupp2-v1.tif"/></fig></fig-group><p>Using these tools, we could test the extent to which DN population activity patterns are consistent with roles in behavior modulation (<xref ref-type="fig" rid="fig1">Figure 1b</xref>), context-dependent recruitment (<xref ref-type="fig" rid="fig1">Figure 1c</xref>), and/or raw sensory signaling (<xref ref-type="fig" rid="fig1">Figure 1d</xref>). We observed that the largest fraction of DNs are active during walking. Principal component analysis (PCA) revealed diverse neural dynamics across epochs of walking. This variability reflected the activities of partially overlapping subsets of DNs that were correlated with turning and, to a far weaker extent, speed. These data support a role for DN populations in behavioral modulation. DNs are active during walking or grooming irrespective of whether the behavior was generated spontaneously or during olfactory stimulation. These data suggest a lack of strong context dependence in DN population recruitment. In the future, this finding can be further tested for its generality by examining DN population activity in the presence of other visual, mechanosensory, and olfactory cues. Notably, we did find that some DNs are specifically responsive to odors without carrying information about ongoing actions. Thus, motor circuits have access to surprisingly unfiltered sensory information. Finally, we illustrate how one can identify DNs from population recordings (<xref ref-type="fig" rid="fig1">Figure 1e</xref>). We studied a prominent pair of DNs that are asymmetrically active during antennal grooming. By using their topological and encoding properties, we could identify a sparse driver line that targets these neurons used morphological analysis (MultiColor FlpOut [MCFO] and connectomics) and propose that they are DNx01 neurons originating from the antennae (<xref ref-type="bibr" rid="bib53">Namiki et al., 2018</xref>). These data provide a more expansive view of DN population activity during natural behaviors and open the door to a comprehensive mechanistic understanding of how the brain’s descending signals regulate motor control.</p></sec><sec id="s2" sec-type="results"><title>Results</title><sec id="s2-1"><title>Recording descending neuron population activity in tethered, behaving <italic>Drosophila</italic></title><p>To selectively record the activity of populations of DNs, we devised an intersectional genetic and optical approach. First, we restricted the expression of GCaMP6s (a fluorescent indicator of neural activity; <xref ref-type="bibr" rid="bib19">Chen et al., 2013</xref>) and tdTomato (an anatomical fiduciary) to the supraesophageal zone of the brain (<xref ref-type="bibr" rid="bib5">Asahina et al., 2014</xref>) (<italic>;otd-nls:FLPo; R57C10-GAL4, tub&gt;GAL80&gt;</italic>). We confirmed that transgene expression was restricted to cell bodies in the brain (<xref ref-type="fig" rid="fig1">Figure 1f</xref>). The axons of DNs could be seen passing through the cervical connective, targeting motor circuits within the VNC (<xref ref-type="fig" rid="fig1">Figure 1g</xref>). Thus, although our driver line lacks expression in the subesophageal zone (SEZ) (<xref ref-type="fig" rid="fig1s1">Figure 1—figure supplement 1c</xref>)—a brain region known to house at least 41 DNs (<xref ref-type="bibr" rid="bib75">Sterne et al., 2021</xref>; <xref ref-type="bibr" rid="bib53">Namiki et al., 2018</xref>) some of which can drive grooming (<xref ref-type="bibr" rid="bib28">Guo et al., 2022</xref>) (DNg11, DNg12)—we could still capture the activities of a large population of DNs. Second, by performing coronal (x–z) two-photon imaging of the thoracic cervical connective (<xref ref-type="bibr" rid="bib20">Chen et al., 2018</xref>), we could exclusively record DN axons (<xref ref-type="fig" rid="fig1">Figure 1h</xref>) in tethered animals while they behaved on a spherical treadmill. This imaging approach could also compensate for image translations during animal behavior, keeping regions-of-interest (ROIs) within the field of view (FOV). We then applied image registration (<xref ref-type="bibr" rid="bib20">Chen et al., 2018</xref>)—to correct for translations and deformations—as well as image denoising (<xref ref-type="bibr" rid="bib44">Lecoq et al., 2021</xref>)—to obtain higher signal-to-noise images. We confirmed that denoising does not systematically delay or prolong the temporal dynamics of neural activity (<xref ref-type="fig" rid="fig1s1">Figure 1—figure supplement 1a and b</xref>). Resulting images included a number of elliptical ROIs that likely represent individual large axons or possibly tightly packed groups of smaller axons (<xref ref-type="fig" rid="fig1">Figure 1i</xref>). From here on, we will interchangeably refer to ROIs as DNs or neurons. From these data, we calculated <inline-formula><mml:math id="inf7"><mml:mrow><mml:mrow><mml:mi mathvariant="normal">Δ</mml:mi><mml:mo>⁢</mml:mo><mml:mi>F</mml:mi></mml:mrow><mml:mo>/</mml:mo><mml:mi>F</mml:mi></mml:mrow></mml:math></inline-formula> images (<xref ref-type="fig" rid="fig1">Figure 1j</xref>) from which manually labeled 75–95 of the most distinct and clearly visible ROIs for each animal. This resulted in high-dimensional neural activity time series (<xref ref-type="fig" rid="fig1">Figure 1k</xref>).</p><p>To test the context-dependence and sensory feedback encoding of DNs, we built an olfactometer that could sequentially present humidified air and one of two odors: ACV (an attractive odorant; <xref ref-type="bibr" rid="bib72">Semmelhack and Wang, 2009</xref>) or MSC (a putatively aversive odorant; <xref ref-type="bibr" rid="bib50">Mohamed et al., 2019</xref>). During experiments we alternated presentation of ACV and MSC with humid air. We performed photoionization detector (PID) measurements to confirm that our olfactometer could deliver a steady flow of air/odor with minimal mechanical perturbations during switching (<xref ref-type="fig" rid="fig1s1">Figure 1—figure supplement 1d–f</xref>).</p><p>Along with neural recordings and odor delivery, we quantified limb and joint positions by video recording tethered animals from six camera angles synchronously at 100 frames per second (fps) (<xref ref-type="fig" rid="fig1">Figure 1l</xref>). A seventh, front-facing camera recorded spherical treadmill rotations that were then converted into fictive locomotor trajectories using FicTrac (<xref ref-type="bibr" rid="bib51">Moore et al., 2014</xref>; <xref ref-type="fig" rid="fig1">Figure 1m</xref>). Multiview camera images (<xref ref-type="fig" rid="fig1">Figure 1n</xref>) were postprocessed using DeepFly3D (<xref ref-type="bibr" rid="bib27">Günel et al., 2019</xref>) to estimate 3D joint positions (<xref ref-type="bibr" rid="bib46">Lobato-Rios et al., 2022</xref>; <xref ref-type="fig" rid="fig1">Figure 1o</xref>). These data were used to train a dilated temporal convolutional neural network (DTCN) (<xref ref-type="bibr" rid="bib84">Whiteway et al., 2021</xref>) that could accurately classify epochs of walking, resting, head (eye and antennal) grooming, front leg rubbing, and posterior movements (a grouping of rarely generated and difficult to distinguish hindleg and abdominal grooming movements) (<xref ref-type="fig" rid="fig1">Figure 1p</xref>, <xref ref-type="fig" rid="fig1s1">Figure 1—figure supplement 1g</xref>). Animals predominantly alternated between resting, walking, and head grooming with little time spent front leg rubbing or moving their posterior limbs and abdomen (<xref ref-type="fig" rid="fig1s1">Figure 1—figure supplement 1h</xref>). Notably, we also observed structure in our behavioral data: flies were more likely to walk after resting or generating posterior movements (<xref ref-type="fig" rid="fig1s1">Figure 1—figure supplement 1i</xref>). Flies also frequently performed front leg rubbing after head grooming (<xref ref-type="bibr" rid="bib71">Seeds et al., 2014</xref>; <xref ref-type="fig" rid="fig1s1">Figure 1—figure supplement 1i</xref>). Taken together, this experimental and computational pipeline yielded a rich dataset of DN population activity and associated odor-evoked and spontaneous behaviors (<xref ref-type="video" rid="video1">Video 1</xref>).</p><media mimetype="video" mime-subtype="mp4" xlink:href="elife-81527-video1.mp4" id="video1"><label>Video 1.</label><caption><title>Representative recording and processing of descending neuron population activity and animal behavior.</title><p>(Top left) Fly behavior as seen by camera 5. Odor stimulus presentation is indicated. (Middle left) Fictive walking trajectory of the fly calculated using FicTrac. White trajectory turns gray after <inline-formula><mml:math id="inf8"><mml:mrow><mml:mn>2</mml:mn><mml:mtext/><mml:mi class="ltx_unit" mathvariant="normal">s</mml:mi></mml:mrow></mml:math></inline-formula>. (Bottom left) 3D pose of the fly calculated using DeepFly3D. Text indicates the current behavior class. (Top right) Raw two-photon microscope image after center-of-mass alignment. (Middle right) <inline-formula><mml:math id="inf9"><mml:mrow><mml:mrow><mml:mi mathvariant="normal">Δ</mml:mi><mml:mo>⁢</mml:mo><mml:mi>F</mml:mi></mml:mrow><mml:mo>/</mml:mo><mml:mi>F</mml:mi></mml:mrow></mml:math></inline-formula> image after motion correction and denoising of the green channel. (Bottom right) Linear discriminant analysis-based low-dimensional representation of the neural data. Each dimension is a linear combination of neurons. The dimensions are chosen such that frames associated with different behaviors are maximally separated.</p></caption></media></sec><sec id="s2-2"><title>Encoding of behavior in descending neuron populations</title><p>With these data, we first asked to what extent DN populations encode—and potentially drive or regulate—each of our classified behaviors: resting, walking, head grooming, posterior movements, and front leg rubbing. The word ‘encoding’ has commonly been used to convey that a neuron’s activity correlates with some continuously varying property of the sensory environment or an animal’s motor behavior. The word ‘encoding’ has also previously been used in reference to DN functional properties (<xref ref-type="bibr" rid="bib26">Gray et al., 2010</xref>; <xref ref-type="bibr" rid="bib76">Suver et al., 2016</xref>; <xref ref-type="bibr" rid="bib57">Nicholas et al., 2018</xref>; <xref ref-type="bibr" rid="bib35">Jaske et al., 2021</xref>). Although fluorescence imaging has lower temporal resolution than electrophysiological recordings–making it less able to fully resolve the specificity of feature/behavioral encoding–we use the term 'encoding' for the sake of brevity.</p><p>We identified DN behavioral encoding in two ways. First, we asked how well each behavior could be predicted based on the activity of each neuron by using a linear model to quantify the extent to which a given DN’s activity could explain the variance of (i.e., encode) each behavior (<xref ref-type="fig" rid="fig2">Figure 2a and b</xref>). The largest fraction (~60%) of DNs encode walking. The second largest group of DNs encode head grooming (~15%). Only a very small fraction of DNs encode resting and no neurons encode front leg rubbing or posterior movements (<xref ref-type="fig" rid="fig2">Figure 2c</xref>). However, some of these behaviors were very infrequent (posterior movements) or of short duration (front leg rubbing) (<xref ref-type="fig" rid="fig1s1">Figure 1—figure supplement 1h</xref>), weakening the power of our analysis in these cases. As well, although none of the DNs <italic>best</italic> explained posterior movements and front leg rubbing out of all behaviors we observed that DNs encoding walking also encoded posterior movements. Similarly, DNs encoding head grooming also encoded front leg rubbing (<xref ref-type="fig" rid="fig2">Figure 2b</xref>). This may be due to the strong sequential occurrence of these pairs of behaviors (<xref ref-type="fig" rid="fig1s1">Figure 1—figure supplement 1i</xref>) and the long decay time constant of GCaMP6s (~1 s; <xref ref-type="bibr" rid="bib19">Chen et al., 2013</xref>), resulting in elevated calcium signals for the subsequent behavior in the pair. To resolve the extent to which these DNs truly encode one behavior versus the other we performed a more narrow linear regression analysis. We used equal amounts of data from this pair of sequential behaviors and calculated the neural variance (rather than the behavioral variance) uniquely explained by these two behaviors alone. These analyses confirmed that DNs predominantly encode walking rather than posterior movements (<xref ref-type="fig" rid="fig2s1">Figure 2—figure supplement 1a</xref>) and head grooming rather than front leg rubbing (<xref ref-type="fig" rid="fig2s1">Figure 2—figure supplement 1b</xref>).</p><fig-group><fig id="fig2" position="float"><label>Figure 2.</label><caption><title>Encoding of behavior in descending neuron (DN) populations.</title><p>(<bold>a</bold>) Shown for walking (top) and head grooming (bottom) are the activity (normalized and cross-validation predicted <inline-formula><mml:math id="inf10"><mml:mrow><mml:mrow><mml:mi mathvariant="normal">Δ</mml:mi><mml:mo>⁢</mml:mo><mml:mi>F</mml:mi></mml:mrow><mml:mo>/</mml:mo><mml:mi>F</mml:mi></mml:mrow></mml:math></inline-formula>) of individual walk- and head groom-encoding DNs (red and purple lines), as well as predicted <inline-formula><mml:math id="inf11"><mml:mrow><mml:mrow><mml:mi mathvariant="normal">Δ</mml:mi><mml:mo>⁢</mml:mo><mml:mi>F</mml:mi></mml:mrow><mml:mo>/</mml:mo><mml:mi>F</mml:mi></mml:mrow></mml:math></inline-formula> traces derived by convolving binary behavior regressors with a calcium response function (crf) (black lines). The output of the behavior classifier is shown (color bar). (<bold>b</bold>) The cross-validation mean of behavioral variance explained by each of 95 DNs from one animal. Colored asterisks are above the two DNs illustrated in panel (<bold>a</bold>). (<bold>c</bold>) The percentage of DNs encoding each classified behavior across five animals. Box plots indicate the median, lower, and upper quartiles. Whiskers signify furthest data points. (<bold>d</bold>) Mean time projection of GCaMP6s fluorescence over one 9 min recording. Image is inverted for clarity (high mean fluorescence is black). Manually identified DN regions of interest (ROIs) are shown (red rectangles). Scale bar is 10 μm. Panels (<bold>d–i</bold>) share the same scale. (<bold>e</bold>) DNs color-coded (as in panel <bold>c</bold>) by the behavior their activities best explain. Radius scales with the amount of variance explained. Prominent head groom-encoding neurons that are easily identified across animals are indicated (white arrowheads). (<bold>f</bold>) Behavior-triggered average <inline-formula><mml:math id="inf12"><mml:mrow><mml:mrow><mml:mi mathvariant="normal">Δ</mml:mi><mml:mo>⁢</mml:mo><mml:mi>F</mml:mi></mml:mrow><mml:mo>/</mml:mo><mml:mi>F</mml:mi></mml:mrow></mml:math></inline-formula> image for head grooming. Prominent head grooming DNs identified through linear regression in panel (<bold>e</bold>) are indicated (white arrowheads). (<bold>g</bold>) Locations of DNs color-coded by the behavior they encode best. Data are from five animals. (<bold>h, i</bold>) Kernel density estimate based on the locations of (<bold>h</bold>) walking or (<bold>i</bold>) head grooming DNs in panel (<bold>g</bold>). (<bold>j</bold>) Amount of variance explained by the principal components (PCs) of neural activity derivatives during walking. (<bold>k, l</bold>) Neural activity data during (<bold>k</bold>) walking and (<bold>l</bold>) resting evolve on two lobes. The PC embedding was trained on data taken during walking only. Colored lines indicate individual epochs of (<bold>k</bold>) walking and (<bold>l</bold>) resting. Time is color-coded and the temporal progressions of each epoch is indicated (arrowheads). Note that color scales are inverted to match the color at transitions between walking and resting. Black arrows indicate ROIs with high PC loadings. ROI number corresponds to the matrix position in panel (<bold>b</bold>). For their locations within this fly’s cervical connective, see <xref ref-type="fig" rid="fig2s4">Figure 2—figure supplement 4d</xref>.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-81527-fig2-v1.tif"/></fig><fig id="fig2s1" position="float" specific-use="child-fig"><label>Figure 2—figure supplement 1.</label><caption><title>Disentangling the relative encoding of frequently sequential behavior pairs.</title><p>(<bold>a, b</bold>) Cross-validation mean of neural variance uniquely explained by (<bold>a</bold>) walking versus posterior movements or (<bold>b</bold>) head grooming versus front leg rubbing. In both cases, only data acquired during the two compared behaviors were analyzed. Additionally, data were balanced to have an equal amount across both behaviors.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-81527-fig2-figsupp1-v1.tif"/></fig><fig id="fig2s2" position="float" specific-use="child-fig"><label>Figure 2—figure supplement 2.</label><caption><title>Encoding of behavior in descending neuron (DN) populations across individual animals.</title><p>(<bold>a</bold>) Mean time projections of GCaMP6s fluorescence over a 9 min recording for five animals. Images are inverted for clarity, illustrating high mean fluorescence (black). Manually identified DN regions of interest (ROIs) are shown (red rectangles). Scale bar is 10 μm. All subpanels and panels (<bold>c, d</bold>) share the same scale. (<bold>b</bold>) The cross-validation mean of behavioral variance explained by DNs for each animal (Fly 1: <italic>n</italic> = 95 ROIs; Fly 2: <italic>n</italic> = 86 ROIs; Fly 3: <italic>n</italic> = 75 ROIs; Fly 4: <italic>n</italic> = 81 ROIs; Fly 5: n = 79 ROIs). (<bold>c</bold>) DNs color-coded by the behavior their activities best explain. Radius scales with the amount of variance explained. (<bold>d</bold>) Behavior-triggered average <inline-formula><mml:math id="inf13"><mml:mrow><mml:mrow><mml:mi mathvariant="normal">Δ</mml:mi><mml:mo>⁢</mml:mo><mml:mi>F</mml:mi></mml:mrow><mml:mo>/</mml:mo><mml:mi>F</mml:mi></mml:mrow></mml:math></inline-formula> images for the most common behaviors—resting, walking, and head grooming. (<bold>e</bold>) Locations of DNs for the classified behavior they encode best. Data are pooled across five animals.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-81527-fig2-figsupp2-v1.tif"/></fig><fig id="fig2s3" position="float" specific-use="child-fig"><label>Figure 2—figure supplement 3.</label><caption><title>Neural variance explained by distinct kinematic features.</title><p>(<bold>a–d</bold>) Amount of neural variance that can be uniquely explained by (<bold>a</bold>) classified behaviors (taken from the previous figure), (<bold>b</bold>) all joint movements, (<bold>c</bold>) leg pair movements, or (<bold>d</bold>) individual leg movements.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-81527-fig2-figsupp3-v1.tif"/></fig><fig id="fig2s4" position="float" specific-use="child-fig"><label>Figure 2—figure supplement 4.</label><caption><title>Principal component (PC) analysis of neural activity during walking and resting across individual animals.</title><p>(<bold>a</bold>) Amount of variance explained by six PCs of neural activity derivatives during walking for five individual flies. (<bold>b, c</bold>) The derivative of neural activity during (<bold>b</bold>) walking and (<bold>c</bold>) resting. PC embeddings were trained on data taken during walking only. Colored trajectories are individual epochs of (<bold>b</bold>) walking and (<bold>c</bold>) resting. Time is color-coded and the temporal progression of each epoch is indicated (arrowheads). Note that color scales are inverted to match the color at transitions between walking and resting. Black arrows indicate PC loadings for descending neurons (DNs) with vectors longer than <inline-formula><mml:math id="inf14"><mml:msqrt><mml:mn>0.1</mml:mn></mml:msqrt></mml:math></inline-formula>. Region of interest (ROI) numbers correspond to the connective image in panel (<bold>d</bold>). (<bold>d</bold>) Locations of ROIs for each individual animal (yellow circles). Numbers are based on the order in <xref ref-type="fig" rid="fig2s2">Figure 2—figure supplement 2b</xref>. Circle radii indicate the norm of the loadings for PCs 1 and 2 (i.e., the lengths of the vectors in panels <bold>b </bold>and <bold>c</bold>). ROIs with the largest loadings are indicated (cyan arrowheads).</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-81527-fig2-figsupp4-v1.tif"/></fig></fig-group><p>We next asked to what extent DNs encode—and presumably drive—the kinematics of joints, limbs, or limb pairs rather than behaviors. To test this possibility, we quantified how much better neural activity could be predicted from joint angles rather than from behavior. Specifically, we computed the amount of variance in DN activity that could be uniquely explained by subgroups of joint angles but not behavior categories or any of the remaining joint angles. Separating joint angles into groups (all, pairs, or individual legs) allowed us to probe the possibility that some neurons might control pairs of legs or individual legs and helped to mitigate the effect of correlations between joint angles within individual legs. Because of the rapid movements of each leg (<inline-formula><mml:math id="inf15"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mn>5</mml:mn><mml:mrow><mml:mo>−</mml:mo></mml:mrow><mml:mn>20</mml:mn><mml:mspace width="thinmathspace"/><mml:mrow><mml:mi mathvariant="normal">H</mml:mi><mml:mi mathvariant="normal">z</mml:mi></mml:mrow></mml:mrow></mml:mstyle></mml:math></inline-formula>; <xref ref-type="bibr" rid="bib64">Ravbar et al., 2021</xref>; <xref ref-type="bibr" rid="bib49">Mendes et al., 2013</xref>) and the long decay time of our calcium indicator, we also convolved joint angle and behavior regressors with a calcium response function (crf) kernel. We found that joint angles can only very marginally improve the prediction of neural activity beyond simply using behavior regressors (<xref ref-type="fig" rid="fig2s3">Figure 2—figure supplement 3</xref>). Thus, DN populations largely encode high-level behaviors suggesting that they delegate low-level kinematic control to downstream circuits in the VNC.</p></sec><sec id="s2-3"><title>The spatial organization of descending neuron encoding</title><p>Previous morphological analyses demonstrated a clear organization of <italic>Drosophila</italic> DN projections within the VNC (<xref ref-type="bibr" rid="bib53">Namiki et al., 2018</xref>). This is likely linked to the distinct functional partners of DNs that regulate limb-dependent (e.g., walking and grooming) versus wing-dependent (e.g., flight and courtship display) behaviors. To further explore the relationship between function and topology, we next asked to what extent we might observe a relationship between a DN’s encoding of behavior and its axon’s position within the cervical connective (<xref ref-type="fig" rid="fig2">Figure 2d</xref>). We found that DNs encoding walking are spread throughout the dorsal connective (<xref ref-type="fig" rid="fig2">Figure 2e, g and h</xref>). On the other hand, head groom-encoding DNs are predominantly in the ventral connective (<xref ref-type="fig" rid="fig2">Figure 2g and i</xref>) including two prominent pairs—lateral and medial-ventral (<xref ref-type="fig" rid="fig2">Figure 2e</xref>, white arrowheads)—whose activities explain the largest amount of variance in head grooming across animals (<xref ref-type="fig" rid="fig2s2">Figure 2—figure supplement 2c</xref>). Surprisingly, we also observed DNs that encode resting. These were located medially, close to the giant fibers, as well as in the lateral extremities of the connective (<xref ref-type="fig" rid="fig2">Figure 2e</xref>, olive circles). We speculate that rest-encoding DNs may suppress other behaviors or could actively drive the tonic muscle tone required to maintain a natural posture.</p><p>We next performed a complementary analysis to further examine the functional–topological organization of DNs in the connective. Specifically, we generated behavior-triggered averages of <inline-formula><mml:math id="inf16"><mml:mrow><mml:mrow><mml:mi mathvariant="normal">Δ</mml:mi><mml:mo>⁢</mml:mo><mml:mi>F</mml:mi></mml:mrow><mml:mo>/</mml:mo><mml:mi>F</mml:mi></mml:mrow></mml:math></inline-formula> images. The results of this approach were only interpretable for frequently occurring behaviors so here we focused on walking, resting, and head grooming (<xref ref-type="fig" rid="fig1s1">Figure 1—figure supplement 1h</xref>; <xref ref-type="video" rid="video2">Videos 2</xref>–<xref ref-type="video" rid="video4">4</xref>). Across animals, we consistently observed DNs in the dorsal connective encoding walking, and two pairs of ventral DNs encoding head grooming (<xref ref-type="fig" rid="fig2">Figure 2f</xref>, <xref ref-type="fig" rid="fig2s2">Figure 2—figure supplement 2d</xref>). By contrast, rest-encoding DNs were located in less consistent locations within the connective. These findings confirm that DN populations for walking and head grooming are largely spatially segregated, a feature that may facilitate the identification of specific cells from DN population recordings across animals.</p><media mimetype="video" mime-subtype="mp4" xlink:href="elife-81527-video2.mp4" id="video2"><label>Video 2.</label><caption><title>Behavior-triggered average <inline-formula><mml:math id="inf17"><mml:mrow><mml:mrow><mml:mi mathvariant="normal">Δ</mml:mi><mml:mo mathvariant="bold">⁢</mml:mo><mml:mi>F</mml:mi></mml:mrow><mml:mo mathvariant="normal">/</mml:mo><mml:mi>F</mml:mi></mml:mrow></mml:math></inline-formula> during walking.</title><p>Averaged <inline-formula><mml:math id="inf18"><mml:mrow><mml:mrow><mml:mi mathvariant="normal">Δ</mml:mi><mml:mo>⁢</mml:mo><mml:mi>F</mml:mi></mml:mrow><mml:mo>/</mml:mo><mml:mi>F</mml:mi></mml:mrow></mml:math></inline-formula> images aligned with respect to behavior onset for all walking epochs. Red circles (top left in each imaging panel) indicate the onset of behavior. When the red circle becomes cyan less than seven behavior epochs remain and the final image with more than eight epochs is shown. Shown as well is an example behavior epoch (top left) indicating the time with respect to the onset of behavior and synchronized with <inline-formula><mml:math id="inf19"><mml:mrow><mml:mrow><mml:mi mathvariant="normal">Δ</mml:mi><mml:mo>⁢</mml:mo><mml:mi>F</mml:mi></mml:mrow><mml:mo>/</mml:mo><mml:mi>F</mml:mi></mml:mrow></mml:math></inline-formula> panels.</p></caption></media><media mimetype="video" mime-subtype="mp4" xlink:href="elife-81527-video3.mp4" id="video3"><label>Video 3.</label><caption><title>Behavior-triggered average <inline-formula><mml:math id="inf20"><mml:mrow><mml:mrow><mml:mi mathvariant="normal">Δ</mml:mi><mml:mo mathvariant="bold">⁢</mml:mo><mml:mi>F</mml:mi></mml:mrow><mml:mo mathvariant="normal">/</mml:mo><mml:mi>F</mml:mi></mml:mrow></mml:math></inline-formula> during resting.</title><p>Averaged <inline-formula><mml:math id="inf21"><mml:mrow><mml:mrow><mml:mi mathvariant="normal">Δ</mml:mi><mml:mo>⁢</mml:mo><mml:mi>F</mml:mi></mml:mrow><mml:mo>/</mml:mo><mml:mi>F</mml:mi></mml:mrow></mml:math></inline-formula> images aligned with respect to behavior onset for all resting epochs. Red circles (top left in each imaging panel) indicate the onset of behavior. When the red circle becomes cyan less than seven behavior epochs remain and the final image with more than eight epochs is shown. Shown as well is an example behavior epoch (top left) indicating the time with respect to the onset of behavior and synchronized with <inline-formula><mml:math id="inf22"><mml:mrow><mml:mrow><mml:mi mathvariant="normal">Δ</mml:mi><mml:mo>⁢</mml:mo><mml:mi>F</mml:mi></mml:mrow><mml:mo>/</mml:mo><mml:mi>F</mml:mi></mml:mrow></mml:math></inline-formula> panels.</p></caption></media><media mimetype="video" mime-subtype="mp4" xlink:href="elife-81527-video4.mp4" id="video4"><label>Video 4.</label><caption><title>Behavior-triggered average <inline-formula><mml:math id="inf23"><mml:mrow><mml:mrow><mml:mi mathvariant="normal">Δ</mml:mi><mml:mo mathvariant="bold">⁢</mml:mo><mml:mi>F</mml:mi></mml:mrow><mml:mo mathvariant="normal">/</mml:mo><mml:mi>F</mml:mi></mml:mrow></mml:math></inline-formula> during head grooming.</title><p>Averaged <inline-formula><mml:math id="inf24"><mml:mrow><mml:mrow><mml:mi mathvariant="normal">Δ</mml:mi><mml:mo>⁢</mml:mo><mml:mi>F</mml:mi></mml:mrow><mml:mo>/</mml:mo><mml:mi>F</mml:mi></mml:mrow></mml:math></inline-formula> images aligned with respect to behavior onset for all head grooming epochs. Red circles (top left in each imaging panel) indicate the onset of behavior. When the red circle becomes cyan less than seven behavior epochs remain and the final image with more than eight epochs is shown. Shown as well is an example behavior epoch (top left) indicating the time with respect to the onset of behavior and synchronized with <inline-formula><mml:math id="inf25"><mml:mrow><mml:mrow><mml:mi mathvariant="normal">Δ</mml:mi><mml:mo>⁢</mml:mo><mml:mi>F</mml:mi></mml:mrow><mml:mo>/</mml:mo><mml:mi>F</mml:mi></mml:mrow></mml:math></inline-formula> panels.</p></caption></media></sec><sec id="s2-4"><title>Descending neuron population dynamics suggest more nuanced feature encoding</title><p>Thus far we have observed that DN subpopulations encode distinct behaviors and that, by far, the largest fraction encode walking. However, locomotion is not monolithic. It continuously varies in speed and direction within a single walking trajectory. Thus, the large number of DNs active during walking may represent an aggregate of subpopulations that are differentially engaged during distinct locomotor modes. To address this hypothesis, we first closely examined the temporal structure of DN population activity dynamics only during walking epochs. We asked to what extent there is variability and structure in population activity that could potentially support the modulatory encoding of walking speed, forward/backward, or turning.</p><p>As in a similar analysis of <italic>Caenorhabditis elegans</italic> population dynamics (<xref ref-type="bibr" rid="bib39">Kato et al., 2015</xref>), we calculated the temporal derivative of each DN’s activity and then performed principal component analysis (PCA) on these time series. We found that the first two PCs can explain upwards of 60% of the variance in DN population activity during walking (<xref ref-type="fig" rid="fig2">Figure 2j</xref>, <xref ref-type="fig" rid="fig2s4">Figure 2—figure supplement 4a</xref>). Visualizing 2D trajectories (PC 1 and PC 2 subspace) of DN activity during individual walking bouts revealed that they move primarily along two directions (<xref ref-type="fig" rid="fig2">Figure 2k</xref>, <xref ref-type="fig" rid="fig2s4">Figure 2—figure supplement 4b</xref>). These directions are even more clear for resting data (embedded within the same PC space) just before the fly began to walk (<xref ref-type="fig" rid="fig2">Figure 2l</xref>, <xref ref-type="fig" rid="fig2s4">Figure 2—figure supplement 4c</xref>).</p><p>To identify individual DNs that most heavily influence this dynamical divergence we next found those with the largest PC loadings. These neurons’ activities most strongly influence the position of population activity in PC space (<xref ref-type="fig" rid="fig2">Figure 2k and l</xref>, <xref ref-type="fig" rid="fig2s4">Figure 2—figure supplement 4b and c</xref>). Consistently, also in flies with a less clear divergence in neural trajectories, we found subsets of DNs whose activities correspond to one of these two directions. By examining the positions of their axons we observed that they are spatially segregated on opposite sides of the connective (<xref ref-type="fig" rid="fig2s4">Figure 2—figure supplement 4d</xref>, cyan arrowheads).</p></sec><sec id="s2-5"><title>Descending neurons that encode walking include spatially segregated turn-encoding clusters</title><p>The divergence of population dynamics and spatial segregation of associated neurons led us to hypothesize that subsets of walk-encoding DNs might preferentially become active during left and right turning. Alternatively, they might encode fast versus slow walking speeds (<xref ref-type="bibr" rid="bib9">Bidaye et al., 2020</xref>). Studies in other insects and vertebrates have shown that DNs can play a modulatory role by regulating turning and speed during locomotion (<xref ref-type="bibr" rid="bib17">Capelli et al., 2017</xref>; <xref ref-type="bibr" rid="bib31">Heinrich, 2002</xref>). As well, in <italic>Drosophila</italic>, the activation of DNp09 neurons can drive forward walking (<xref ref-type="bibr" rid="bib9">Bidaye et al., 2020</xref>). Recordings from sparse sets of DNa01 (<xref ref-type="bibr" rid="bib20">Chen et al., 2018</xref>; <xref ref-type="bibr" rid="bib65">Rayshubskiy, 2020</xref>) and DNa02 (<xref ref-type="bibr" rid="bib65">Rayshubskiy, 2020</xref>) neurons also show turn encoding (i.e., steering).</p><p>Therefore, we next tested whether variability in the activity of DNs might reflect fine-grained encoding of turning and speed during forward walking. We did not analyze backward walking due to its scarcity (<xref ref-type="fig" rid="fig3s1">Figure 3—figure supplement 1a</xref>), brevity (<xref ref-type="fig" rid="fig3s1">Figure 3—figure supplement 1b</xref>), and minimal dynamic range (<xref ref-type="fig" rid="fig3s1">Figure 3—figure supplement 1c</xref>) in our experimental data. Specifically, we quantified the degree to which DN population activity could uniquely explain yaw (turning) or pitch (speed) angular velocity of the spherical treadmill. Both of these time-series data were convolved with a crf to account for slow calcium indicator decay dynamics. To capture information about turning and walking speed that could not simply be explained by whether the fly was walking or not we compared the explained variance of our neuron-based ridge regression to a model predicting these features from just a binary walking regressor and shuffled neural data (<xref ref-type="fig" rid="fig3">Figure 3a</xref>). Neural activity could explain a great deal of variance in turning and, to a lesser extent, speed. Here, the absence of speed encoding may be because the binary walking regressor alone can partially predict speed variance from transitions between resting and walking (<inline-formula><mml:math id="inf26"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msup><mml:mi>R</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup><mml:mo>=</mml:mo><mml:mn>25</mml:mn><mml:mi mathvariant="normal">%</mml:mi></mml:mrow></mml:mstyle></mml:math></inline-formula>). Therefore, we refined our analysis by only using data from walking epochs and calculating the amount of turning and speed variance that could be explained using neural activity. In this manner, we confirmed that neural activity can uniquely explain turning to a greater extent (~60%) than it can explain walking speed (~30%) (<xref ref-type="fig" rid="fig3">Figure 3b</xref>).</p><fig-group><fig id="fig3" position="float"><label>Figure 3.</label><caption><title>Turning and speed encoding in descending neuron (DN) populations.</title><p>(<bold>a</bold>) Predictions of (top) turning and (bottom) walking speed modeled using convolved behavior regressors and all neurons in one animal. Shown are predictions (green) with all regressors intact or (blue) with neural data shuffled across time. Indicated are <inline-formula><mml:math id="inf27"><mml:msup><mml:mi>R</mml:mi><mml:mn>2</mml:mn></mml:msup></mml:math></inline-formula> values obtained by comparing predicted and real (black) turning and walking speed. These are subtracted to obtain neural unique explained variance (UEV). The fly’s behavior throughout the recording is indicated (color bar). (<bold>b</bold>) UEV obtained only using data taken during walking, thus accounting for trivial explanations of speed and turning variance resulting from transitions between resting and walking. Shown are data from five trials each for five flies (color-coded). (<bold>c</bold>) UEV of each DN from one animal for walking speed or left and right turning ordered by clustering of Pearson’s correlation coefficients in panel (<bold>d</bold>). Walking <inline-formula><mml:math id="inf28"><mml:msup><mml:mi>R</mml:mi><mml:mn>2</mml:mn></mml:msup></mml:math></inline-formula> values are the same as in <xref ref-type="fig" rid="fig2">Figure 2b</xref> but reordered according to clustering. The models for turning and walking speed were obtained using behavior regressors as well as neural activity. To compute the UEV, activity for a given neuron was shuffled temporally. The behavior whose variance is best explained by a given neuron is indicated (color bar). (<bold>d</bold>) Pearson’s correlation coefficient matrix comparing neural activity across DNs ordered by clustering. Shown as well are the correlation of each DN’s activity with right, left, and forward walking (right). (<bold>e, f</bold>) UEV for (<bold>e</bold>) turning or (<bold>f</bold>) speed for DNs that best encode walking. Neurons are sorted by UEV. Shown are the distributions for individuals (translucent lines), and the mean across all animals (opaque line). (<bold>g</bold>) Locations of turn-encoding DNs (UEV &gt; 5%), color-coded by preferred direction (left, blue; right, red). Circle radii scale with UEV. Dashed white line indicates the approximate midline of the cervical connective. Scale bar is 10 μm for panels (<bold>g</bold>) and (<bold>i</bold>). (<bold>h</bold>) Kernel density estimate of the distribution of turn encoding DNs. Shown are the distributions for individuals (translucent lines), and the mean distribution across all animals (opaque lines). Probability densities are normalized by the number of DNs along the connective’s medial–lateral axis. (<bold>i</bold>) Locations of speed encoding DNs (UEV &gt; 2%). Circle radii scale with UEV. Dashed white line indicates the approximate midline of the cervical connective. (<bold>j</bold>) Kernel density estimate of the distribution of speed encoding DNs. Shown are the distributions for individuals (translucent lines) and the mean distributions across all animals (opaque lines). Probability densities are normalized by the number of DNs along the connective’s medial–lateral axis.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-81527-fig3-v1.tif"/></fig><fig id="fig3s1" position="float" specific-use="child-fig"><label>Figure 3—figure supplement 1.</label><caption><title>Backward walking is infrequent and brief.</title><p>Compared to forward walking epochs, in our data we measured (<bold>a</bold>) fewer and (<bold>b</bold>) shorter backward walking epochs. (<bold>c</bold>) There was also a limited dynamic range in backward walking speed. In all panels colors indicates fly identities. In panels (<bold>b</bold>) and (<bold>c</bold>) circles indicate the values of 700 randomly selected epochs (subsampled for clarity). Box plots indicate the median, lower, and upper quartiles. Whiskers signify 1.5× the interquartile range.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-81527-fig3-figsupp1-v1.tif"/></fig><fig id="fig3s2" position="float" specific-use="child-fig"><label>Figure 3—figure supplement 2.</label><caption><title>Turning and speed encoding in descending neuron (DN) populations across individual animals.</title><p>(<bold>a</bold>) Unique explained variance (UEV) of each DN from individual animals for left and right turning or walking speed. Walking <inline-formula><mml:math id="inf29"><mml:msup><mml:mi>R</mml:mi><mml:mn>2</mml:mn></mml:msup></mml:math></inline-formula> values are taken from <xref ref-type="fig" rid="fig2s2">Figure 2—figure supplement 2b</xref>. The model for turning and speed was obtained using behavior regressors as well as neural activity. To compute the UEV, activity for a given neuron was temporally shuffled. The behavior whose variance is best explained by a given neuron is indicated (top). Neurons are ordered as in panel (<bold>b</bold>). (<bold>b</bold>) Pearson’s correlation coefficient matrix comparing neural activity across DNs is ordered by hierarchical clustering. Shown as well are the correlations of each DN’s activity with right, left, and forward walking (right). Neurons are ordered as in panel (<bold>a</bold>). (<bold>c</bold>) Locations of turn encoding DNs (UEV &gt; 5%), color-coded by preferred direction (left, blue; right, red). Circle radii scale with UEV. Dashed white line indicates the approximate midline of the cervical connective. Scale bars are 10 μm for all subpanels and panel (<bold>e</bold>). (<bold>d</bold>) Kernel density estimates of the distributions of turn encoding DNs across individuals (opaque lines). Probability densities are normalized by the number of DNs along the connective’s medial–lateral axis. (<bold>e</bold>) Locations of speed encoding DNs (UEV &gt; 2%). Circle radii scale with UEV. Dashed white line indicates the approximate midline of the cervical connective. (<bold>f</bold>) Kernel density estimates of the distributions of speed encoding DNs across individuals (opaque lines). Probability densities are normalized by the number of DNs along the connective medial–lateral axis.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-81527-fig3-figsupp2-v1.tif"/></fig></fig-group><p>We next investigated which individual or groups of neurons contribute to the prediction of turning and walking speed. To do this we only used the activity of one neuron at a time in our model (by contrast, above we used all neurons). Among DNs that encode walking, we found specific DNs that strongly explain right or left turning. By contrast, a more distributed set of DNs weakly encode walking speed (<xref ref-type="fig" rid="fig3">Figure 3c</xref>, <xref ref-type="fig" rid="fig3s2">Figure 3—figure supplement 2a</xref>). Having identified clusters of DNs encoding right (red) and left (blue) turning, we next investigated whether there might be groups encoding other walking features. Among neurons that best explain walking we again observed clusters for turning but no prominent clusters for speed (<xref ref-type="fig" rid="fig3">Figure 3d</xref>, <xref ref-type="fig" rid="fig3s2">Figure 3—figure supplement 2b</xref>). This was also reflected in the amount of variance explained: across animals some walk-encoding DNs also strongly encoded turning (<xref ref-type="fig" rid="fig3">Figure 3e</xref>) whereas these DNs only encoded a tiny fraction of the variance in walking speed (<xref ref-type="fig" rid="fig3">Figure 3f</xref>).</p><p>Simple models for locomotor control (<xref ref-type="bibr" rid="bib13">Braitenberg, 1986</xref>) suggest that turning can be controlled by the relative activities of DNs on one side of the brain versus the other. This is supported by studies showing that flies generate turning during asymmetric activation or asymmetric activity of DNa01 neurons (<xref ref-type="bibr" rid="bib20">Chen et al., 2018</xref>; <xref ref-type="bibr" rid="bib65">Rayshubskiy, 2020</xref>) and MDNs (<xref ref-type="bibr" rid="bib73">Sen et al., 2017</xref>). To examine the degree to which this spatial asymmetry extends beyond pairs of neurons to much larger DN populations we quantified the spatial location of turn-encoding DNs in the cervical connective. We found both ipsi- and contralateral turn-encoding DNs on both sides of the connective (<xref ref-type="fig" rid="fig3">Figure 3g</xref>, <xref ref-type="fig" rid="fig3s2">Figure 3—figure supplement 2c</xref>) but a clear ipsilateral enrichment (<xref ref-type="fig" rid="fig3">Figure 3h</xref>, <xref ref-type="fig" rid="fig3s2">Figure 3—figure supplement 2d</xref>). Many of the DNs encoding turning had high PC loading (<xref ref-type="fig" rid="fig2s4">Figure 2—figure supplement 4d</xref>) revealing that turning contributes heavily to the variance in DN population dynamics during walking. By contrast, DNs encoding walking speed were more homogeneously distributed across the connective with no clear spatial enrichment (<xref ref-type="fig" rid="fig3">Figure 3i and j</xref>, <xref ref-type="fig" rid="fig3s2">Figure 3—figure supplement 2e and f</xref>). Overall, these data support the notion that, during walking, DN population activity largely varies due to turn-related modulation rather than shifts in walking speed.</p></sec><sec id="s2-6"><title>Descending neurons are active during behaviors irrespective of olfactory context</title><p>Beyond a modulatory role, the large number of DNs active during walking could reflect context dependence: specific subpopulations may only be engaged as a function of sensory context. The possibility of recruiting separate pools of DNs for walking is supported by the observation that an attractive odor, ACV, decreases resting and increases walking (<xref ref-type="fig" rid="fig4s1">Figure 4—figure supplement 1a</xref>), increases forward walking speed (<xref ref-type="fig" rid="fig4s1">Figure 4—figure supplement 1b</xref>), and reduces turning (<xref ref-type="fig" rid="fig4s1">Figure 4—figure supplement 1c and d</xref>).</p><p>To address the extent to which subgroups of DNs are recruited depending on olfactory context, we studied the amount of walking or head grooming variance explained by each DN using only data acquired during exposure to either humidified air, ACV, or MSC—rather than analyzing all walking epochs as in our previous analysis. Humidified air data were subsampled to match the smaller amount of data available for ACV and MSC presentation. We found that largely the same DNs were highly predictive of walking (<xref ref-type="fig" rid="fig4s2">Figure 4—figure supplement 2a</xref>) and head grooming (<xref ref-type="fig" rid="fig4s2">Figure 4—figure supplement 2b</xref>) irrespective of olfactory context. Only a very small fraction of DNs were differentially recruited during odor presentation (<xref ref-type="fig" rid="fig4s2">Figure 4—figure supplement 2a and b</xref>, black asterisks, two-sided Mann–Whitney <italic>U</italic>-test on cross-validation folds). Of these four DNs with different recruitment, three achieve significance because they have only a few values distinct from zero in a single trial. The overall explained variance is also very small (<xref ref-type="fig" rid="fig4s2">Figure 4—figure supplement 2c</xref>). These data suggest that changing odor context alters action selection and locomotor kinematics but does not shift the identity of active DN subpopulations driving behavior.</p></sec><sec id="s2-7"><title>Descending neurons exhibit raw odor encoding</title><p>Although walk- and head groom-encoding DN populations are recruited irrespective of odor context, it has been shown that a fictive odor (i.e., optogenetic activation of <italic>Orco&gt;CsChrimson</italic>) can activate DNa02 neurons in immobile animals (<xref ref-type="bibr" rid="bib65">Rayshubskiy, 2020</xref>). This implies that DNs may encode the presence and identity of real odors. To examine the extent of this raw sensory encoding we trained and cross-validated linear discriminant odor classifiers using neural residuals (i.e., the neural activity remaining after subtracting activity that could be predicted using a model based on crf convolved behavior regressors). These residuals allowed us to control for the fact that odor presentation also modulates behavioral statistics (<xref ref-type="fig" rid="fig4s1">Figure 4—figure supplement 1a–c</xref>).</p><p>Classification using neural residuals performed significantly better than classification using behavioral information alone (<inline-formula><mml:math id="inf30"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mrow><mml:mrow><mml:mi mathvariant="normal">p</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:mo>&lt;</mml:mo></mml:mrow><mml:msup><mml:mn>10</mml:mn><mml:mrow><mml:mo>−</mml:mo><mml:mn>5</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:mstyle></mml:math></inline-formula> for a two-sided Mann–Whitney <italic>U</italic>-test; <xref ref-type="fig" rid="fig4">Figure 4a</xref>). This reveals raw odor encoding within DN populations. However, this might result from many neurons with weak, complementary odor encoding or a few neurons with strong odor encoding. To distinguish between these possibilities, we next identified which DNs encode olfactory signals. We predicted each neuron’s activity using regressors for behavior and the presence of each odor. The more intuitive approach of modeling neural activity by just using odor regressors does not account for the confound that behaviors are also modulated by specific odors. Therefore, we computed the amount of neural variance that could uniquely be explained by the presence of an odor and none of the behavior variables. We found that the activity of a few DNs could be uniquely explained by each of the odors (<xref ref-type="fig" rid="fig4">Figure 4b</xref>, asterisks). In these neurons, clear activity peaks coincided with the presence of MSC (<xref ref-type="fig" rid="fig4">Figure 4c</xref>) or ACV (<xref ref-type="fig" rid="fig4">Figure 4d</xref>). Notably, there appears to be no overlap between the DNs encoding MSC or ACV within individual animals (<xref ref-type="fig" rid="fig4s1">Figure 4—figure supplement 1e</xref>). MSC encoding neurons were found dorsally on the lateral sides of the giant fibers in the connective while ACV encoding neurons were more broadly dispersed (<xref ref-type="fig" rid="fig4">Figure 4e and f</xref>).</p><fig-group><fig id="fig4" position="float"><label>Figure 4.</label><caption><title>Odor encoding in descending neuron (DN) populations.</title><p>(<bold>a</bold>) Neural residuals—obtained by subtracting convolved behavior regressors from raw neural data—can predict the presence of an odor significantly better than behavior regressors convolved with a calcium response function (‘Behavior’). Two-sided Mann–Whitney <italic>U</italic>-test. The classification score was obtained using a linear discriminant classifier with cross-validation. Shown are five trials for five animals (color-coded). (<bold>b</bold>) Matrix showing the cross-validated ridge regression unique explained variance (UEV) of a model that contains behavior and odor regressors for one animal. The first row (‘Behavior’) shows the composite <inline-formula><mml:math id="inf31"><mml:msup><mml:mi>R</mml:mi><mml:mn>2</mml:mn></mml:msup></mml:math></inline-formula> for all behavior regressors with odor regressors shuffled. The second and third rows show the UEVs for regressors of the odors methyl salicylate (MSC) or apple cider vinegar (ACV), respectively. Colored asterisks indicate neurons illustrated in panel (<bold>a</bold>). (<bold>c, d</bold>) Example DNs best encoding (<bold>c</bold>) MSC or (<bold>d</bold>) ACV, respectively. Overlaid are traces of neural activity (gray), row one in the matrix (blue), and row one with odor data shuffled (red). (<bold>e, f</bold>) Locations of odor encoding neurons in (<bold>e</bold>) one individual and (<bold>f</bold>) across all five animals. Scale bar is 10 μm.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-81527-fig4-v1.tif"/></fig><fig id="fig4s1" position="float" specific-use="child-fig"><label>Figure 4—figure supplement 1.</label><caption><title>Odor-modulated behaviors and encoding in descending neuron (DN) populations across individuals.</title><p>(<bold>a</bold>) The probabilities that classified behaviors occur during periods of stimulation with humidified air, apple cider vinegar (ACV), or methyl salicylate (MSC) odors. P-values indicate the significance level for a two-sided Mann–Whitney <italic>U</italic>-test. (<bold>b–d</bold>) Swarm plots showing a subset of 250 randomly sampled points indicating (<bold>b</bold>) walking speed, (<bold>c</bold>) turning angular velocity, and (<bold>d</bold>) absolute value of turning angular velocity during periods of stimulation with humidified air, ACV, or MSC odors. (<bold>e</bold>) Matrices showing the cross-validated ridge regression unique explained variance (UEV) of models that contain behavior and odor regressors for five individual animals. The first row (‘Behavior’) shows the composite <inline-formula><mml:math id="inf32"><mml:msup><mml:mi>R</mml:mi><mml:mn>2</mml:mn></mml:msup></mml:math></inline-formula> for all behavior regressors and shuffled odor regressors. The second and third rows show UEVs for the odor regressors MSC and ACV, respectively. (<bold>f</bold>) Locations of odor encoding neurons (UEV &gt; 5%) across five individual animals. Scale bar is 10 μm and applies to all images. Color indicates odor. Radii scale with the amount of variance explained.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-81527-fig4-figsupp1-v1.tif"/></fig><fig id="fig4s2" position="float" specific-use="child-fig"><label>Figure 4—figure supplement 2.</label><caption><title>Largely identical descending neuron (DN) populations are recruited during walking and head grooming irrespective of odor context.</title><p>(<bold>a, b</bold>) Amount of (<bold>a</bold>) walking or (<bold>b</bold>) head grooming variance explained by each DN using only frames during presentation of humidified air, apple cider vinegar (ACV), or methyl salicylate (MSC). Data during humidified air presentation were split into groups to match the amount of data available during ACV and MSC presentation. Indicated are cases where a two-sided Mann–Whitney <italic>U</italic>-test comparing the cross-validation folds between humidified air and each of the odors yielded significant differences after Bonferroni correction for multiple comparisons (*<inline-formula><mml:math id="inf33"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mrow><mml:mrow><mml:mi mathvariant="normal">p</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:mo>&lt;</mml:mo></mml:mrow><mml:mn>0.05</mml:mn></mml:mrow></mml:mstyle></mml:math></inline-formula>; ***<inline-formula><mml:math id="inf34"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mrow><mml:mrow><mml:mi mathvariant="normal">p</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:mo>&lt;</mml:mo></mml:mrow><mml:mn>0.001</mml:mn></mml:mrow></mml:mstyle></mml:math></inline-formula>). (<bold>c</bold>) Individual region of interest (ROI) data points resulting in significant differences across conditions by a two-sided Mann–Whitney <italic>U</italic>-test (shown from left to right: fly 1, ROI 82; fly 1, ROI 87; fly 2, ROI 74; fly 4, ROI 28). Each point is the result of a single cross-validation fold from a single trial. p-Values shown are after Bonferroni correction for multiple comparisons.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-81527-fig4-figsupp2-v1.tif"/></fig></fig-group></sec><sec id="s2-8"><title>Identifying individual descending neurons from population recordings</title><p>Until now we have demonstrated that DN populations exhibit heterogeneous encoding: large, distributed groups encode walking and, by contrast, a few prominent pairs encode head grooming. Determining how these subpopulations control adaptive behavior is an important future challenge that will require a comprehensive approach examining phenomena ranging from global DN population dynamics down to the synaptic connectivity of individual DNs. The recent generation of hundreds of sparse transgenic driver lines (<xref ref-type="bibr" rid="bib37">Jenett et al., 2012</xref>; <xref ref-type="bibr" rid="bib53">Namiki et al., 2018</xref>) and several connectomics datasets (<xref ref-type="bibr" rid="bib62">Phelps et al., 2021</xref>) suggests that this bridging of mechanistic scales may soon be within reach in <italic>Drosophila</italic>.</p><p>To illustrate how this might be accomplished, we aimed to identify specific DNs within our population imaging dataset. Specifically, while analyzing head grooming DNs we noticed a large pair of ventral neurons (<xref ref-type="fig" rid="fig5">Figure 5a</xref>) that sometimes exhibited asymmetric activity (<xref ref-type="fig" rid="fig5">Figure 5b</xref>, gray arrowheads) when flies appeared to touch one rather than both antennae (<xref ref-type="video" rid="video5">Video 5</xref>). To quantify this observation, we replayed limb 3D kinematics in NeuroMechFly, a biomechanical simulation of <italic>Drosophila</italic> (<xref ref-type="bibr" rid="bib46">Lobato-Rios et al., 2022</xref>; <xref ref-type="fig" rid="fig5">Figure 5c</xref>). By detecting leg-antennal collisions as a proxy for antenna deflection, we found that occasional asymmetries (<xref ref-type="fig" rid="fig5">Figure 5d</xref>) did coincide with asymmetric activity in corresponding neural data (<xref ref-type="fig" rid="fig5">Figure 5b</xref>, purple traces). These results suggested that this pair of DNs encodes mechanosensory signals associated with antennal deflections.</p><fig id="fig5" position="float"><label>Figure 5.</label><caption><title>Identifying a pair of antennal deflection-encoding descending neurons (DNs) from population recordings.</title><p>(<bold>a</bold>) A pair of head groom-encoding DNs (purple circles and white arrowheads) can be identified from DN population recordings based on their shapes, locations, and activity patterns. (<bold>b</bold>) Example <inline-formula><mml:math id="inf35"><mml:mrow><mml:mrow><mml:mi mathvariant="normal">Δ</mml:mi><mml:mo>⁢</mml:mo><mml:mi>F</mml:mi></mml:mrow><mml:mo>/</mml:mo><mml:mi>F</mml:mi></mml:mrow></mml:math></inline-formula> traces (black) of DNs highlighted in panel (<bold>a</bold>). Sample time points with bilaterally asymmetric neural activity are indicated (gray arrowheads). Overlaid is a prediction of neural activity derived by convolving left and right antennal collisions measured through kinematic replay in the NeuroMechFly physics simulation (purple). (<bold>c</bold>) Kinematic replay of recorded joint angles in NeuroMechFly allow one to infer antennal collisions from real, recorded head grooming. (<bold>d</bold>) Left and right antennal collisions during simulated replay of head grooming shown in panel (<bold>b</bold>). Sample time points with bilaterally asymmetric collisions are indicated (gray arrowheads). (<bold>e</bold>) Two-photon image of the cervical connective in a R65D11&gt;OpGCaMP6f, tdTomato animal. Overlaid are regions of interest (ROIs) identified using AxoID. The pair of axonal ROIs are in a similar ventral location and have a similarly large relative size like those seen in DN population recordings. Scale bar is 5 μm. (<bold>f</bold>) Sample neural activity traces from ROIs 0 and 1. Bilaterally asymmetric neural activity events (gray arrowheads), behaviors (color bar), and CO<sub>2</sub> puffs directed at the antennae (gray bars) are indicated. (<bold>g, h</bold>) CO<sub>2</sub> puff-triggered average of neural activity for ROIs (<bold>g</bold>) 0 and (<bold>h</bold>) 1. Only events in which animals did not respond with head grooming or front leg rubbing were used. Stimuli were presented at <inline-formula><mml:math id="inf36"><mml:mrow><mml:mi>t</mml:mi><mml:mo>=</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:math></inline-formula>. Shown are individual responses (gray lines) and their means (black lines). (<bold>i</bold>) Confocal volume z-projection of MultiColor FlpOut (MCFO) expression in an R65D11-GAL4 animal. Cyan neuron morphology closely resembles DNx01 (<xref ref-type="bibr" rid="bib53">Namiki et al., 2018</xref>). Scale bar is 50 μm. (<bold>j, k</bold>) Higher-magnification MCFO image, isolating the putative DNx01 from panel (<bold>i</bold>), of the (<bold>j</bold>) brain and (<bold>k</bold>) ventral nerve cord (VNC). Scale bars are 20 μm. (<bold>l</bold>) The locations of axons in the cervical connective (purple) from neurons identified as DNx01. Scale bar is 10 μm. (<bold>m</bold>) Manual reconstruction of a DNx01 from panel (<bold>l</bold>). Scale bar is 50 μm.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-81527-fig5-v1.tif"/></fig><media mimetype="video" mime-subtype="mp4" xlink:href="elife-81527-video5.mp4" id="video5"><label>Video 5.</label><caption><title>Asymmetric activity in a pair of DNx01s is associated with asymmetric leg-antennal collisions during antennal grooming.</title><p>Three head grooming epochs in the same animal having leg contact with (top) primarily the left antenna, (middle) both antennae, or (bottom) primarily the right antenna. Shown are corresponding (right) neural activity <inline-formula><mml:math id="inf37"><mml:mrow><mml:mrow><mml:mi mathvariant="normal">Δ</mml:mi><mml:mo>⁢</mml:mo><mml:mi>F</mml:mi></mml:mrow><mml:mo>/</mml:mo><mml:mi>F</mml:mi></mml:mrow></mml:math></inline-formula> images (note putative DNx01s in dashed white circles), (middle) behavior videos (camera 2), and (left) leg-antennal collisions (green) during kinematic replay of 3D poses in the NeuroMechFly physics simulation. Video playback is 0.25× real time.</p></caption></media><p>To further reveal the identity of these DNs, we examined data from our functional screen of sparse Gal4 and split Gal4 driver lines (<xref ref-type="bibr" rid="bib21">Chen, 2022</xref>). In this dataset, we observed similar asymmetric activity during antennal grooming in R65D11-GAL4. Coronal (x–z) two-photon imaging in R65D11 animals expressing OpGCaMP6f and tdTomato shows axons that are similarly large and ventromedially located within the cervical connective (<xref ref-type="fig" rid="fig5">Figure 5e</xref>). These also produce asymmetric activity during antennal grooming (<xref ref-type="fig" rid="fig5">Figure 5f</xref>). This suggests that these neurons may report something unique to head grooming (e.g., coincident front limb movements) or simply antennal deflection. To distinguish between these possibilities we analyzed neural responses to CO<sub>2</sub> puff stimulation of the antennae while discarding data with resulting head grooming or front leg rubbing to ensure that the antennae were not touched by the legs. We measured an increase in the activity of both DNs upon puff stimulation (<xref ref-type="fig" rid="fig5">Figure 5g and h</xref>) suggesting that, like the neurons recorded in DN populations, R65D11 neurons also encode sensory signals—antennal deflection—rather than behavior.</p><p>To confirm that these sparse neurons are DNs, we next performed MCFO (<xref ref-type="bibr" rid="bib56">Nern et al., 2015</xref>) and confocal imaging of their morphologies. R65D11 drives expression in several neurons. However, we found similarly large axonal projections from only one set of neurons that descend from the brain to the VNC (<xref ref-type="fig" rid="fig5">Figure 5i</xref>, cyan). Close examination of these neurites in the brain (<xref ref-type="fig" rid="fig5">Figure 5j</xref>) and VNC (<xref ref-type="fig" rid="fig5">Figure 5k</xref>) revealed a striking resemblance to the reported structure of DNx01 neurons (<xref ref-type="bibr" rid="bib53">Namiki et al., 2018</xref>) with cell bodies outside of the brain—putatively in the antennae and enabling antennal mechanosensing.</p><p>These results enable the analysis of synaptic connectivity in identified DNs. To illustrate this, based on their unique location and size, we identified DNx01s in a VNC electron microscopy dataset (<xref ref-type="bibr" rid="bib62">Phelps et al., 2021</xref>; <xref ref-type="fig" rid="fig5">Figure 5l</xref>) via manual reconstruction and observed a striking morphological similarity to R65D11 DNs (<xref ref-type="fig" rid="fig5">Figure 5m</xref>). From this reconstruction, once the full VNC connectome becomes available, one may identify synaptic partners of DNx01s to further understand how they contribute to controlling antennal grooming and other behaviors. Taken together, these data suggest a possible road map for using functional, topological, and morphological data to decipher the cellular identity of individual DNs from population recordings.</p></sec></sec><sec id="s3" sec-type="discussion"><title>Discussion</title><p>Here, by combining genetic and optical imaging approaches, we recorded the behavioral and sensory encoding of DN populations in behaving <italic>Drosophila</italic>. Although electrophysiology provides higher temporal resolution (e.g., being capable of reporting spike timing; <xref ref-type="bibr" rid="bib82">von Reyn et al., 2014</xref>), neural population imaging serves an important complementary role in capturing the proportion and spatial locations of co-active neurons. Electrophysiological recordings and calcium imaging of sparse DN driver lines can more easily enable links to be made between neural encoding and cellular identity. However, these approaches suffer from two major disadvantages. First, there exist split-Gal4 driver lines for only a small fraction of DNs (<xref ref-type="bibr" rid="bib53">Namiki et al., 2018</xref>). Second, determining the encoding of an equivalent number of neurons requires many more sparse neural recordings than population imaging experiments. Therefore, by focusing on population imaging our study allowed us to more rapidly survey the encoding of a large number of DNs. Using this approach we found that most recorded DNs encode walking. A smaller number are active during head grooming and resting. We did not find DNs encoding posterior movements possibly due to the infrequency of this behavior. We also did not identify neurons that are active during multiple behaviors. This suggests that each ROI consists of individual neurons or that, if an ROI contains many neurons, they all show similar encoding. Subsets of walk-encoding DNs were also strongly active during turning: they were at higher density on the ipsilateral half of the cervical connective with respect to turn direction. By contrast, DNs distributed throughout the connective very weakly encoded walking speed. However, we caution that the small range of walking speeds in our data—flies accelerate rapidly from resting to walking and vice versa— may mask stronger speed encoding. The partial overlap between turn- and speed-encoding DNs leaves open the possibility that neurons simultaneously encode these two properties in a differential steering fashion. Notably, we did not observe any DNs that are only active during transitions between multiple behaviors. However, the fly makes fast transitions suggesting that the signal-to-noise and temporal resolution of our approach may not be sufficient to identify such neurons—higher temporal resolution electrophysiological recordings would be required to confirm the absence of DN encoding for behavioral transitions or for precise limb kinematics. Our dataset consists of natural walking and grooming behaviors. Therefore, some joint angles are more frequent than others (<xref ref-type="fig" rid="fig1s2">Figure 1—figure supplement 2</xref>). In future work, along with performing higher temporal resolution recordings, a larger range of possible joint angles could be explored by eliciting rarer and more complex behaviors including reaching or tethered locomotion over rugged terrain.</p><p>The encoding—and presumptive control—of walking by large numbers of DNs supports the notion that the brain tightly regulates locomotion. In contrast to walking, head grooming is encoded by far fewer neurons in our dataset. This may be because grooming limb movements are more stereotyped and thus may rely more heavily on controllers within the VNC (a notion that is supported by the ability of headless flies to perform spontaneous grooming; <xref ref-type="bibr" rid="bib30">Harris et al., 2015</xref>). Other studies have also shown brain-wide activity during walking but not during other behaviors (<xref ref-type="bibr" rid="bib3">Aimon et al., 2019</xref>; <xref ref-type="bibr" rid="bib68">Schaffer et al., 2021</xref>; <xref ref-type="bibr" rid="bib14">Brezovec et al., 2022</xref>). This difference may arise because adaptive locomotion—to avoid obstacles (<xref ref-type="bibr" rid="bib77">Tanaka and Clark, 2022</xref>), cross gaps (<xref ref-type="bibr" rid="bib79">Triphan et al., 2010</xref>), and court potential mates (<xref ref-type="bibr" rid="bib23">Coen et al., 2014</xref>)—depends heavily on the brain’s descending signals. Thus, we hypothesize that, although a core set of command neurons can drive both walking and grooming, more DNs are additionally engaged during walking to allow for more flexible navigation in continuously changing and complex environments. Interestingly, many ascending neurons (ANs) have also been shown to encode walking (<xref ref-type="bibr" rid="bib21">Chen, 2022</xref>; <xref ref-type="bibr" rid="bib25">Fujiwara et al., 2022</xref>) with a large fraction projecting to the gnathal ganglia (GNG), a brain region that is also heavily innervated by DNs (<xref ref-type="bibr" rid="bib53">Namiki et al., 2018</xref>). Thus, we speculate that ANs and DNs may be directly connected—possibly to mediate action selection (<xref ref-type="bibr" rid="bib47">Mann et al., 2013</xref>; <xref ref-type="bibr" rid="bib8">Bidaye et al., 2014</xref>)—and that this may lead to similar functional encoding.</p><p>Because of the large number of DNs involved in walking we hypothesized that subsets might represent parallel channels that are recruited depending on sensory context. For example, there may be DN subpopulations that drive walking in the presence of attractive odors and others engaged in the presence of aversive odors. This notion is supported by studies showing that optogenetic activation of a large variety of DNs elicits only a small set of stereotyped behaviors (<xref ref-type="bibr" rid="bib16">Cande, 2018</xref>). However, our population imaging data do not support this notion: largely the same DNs encode walking and head grooming irrespective of olfactory context.</p><p>A nonbehavioral role for DNs has also been suggested by previous studies showing that the perception of a fictive odor modulates the activity of specific DNs involved in steering in immobile flies (<xref ref-type="bibr" rid="bib65">Rayshubskiy, 2020</xref>). In line with this, we also identified DNs encoding odors and not behavior. Notably, the two odors we presented—ACV and MSC—were encoded by distinct DNs. Extrapolating beyond ACV and MSC, it seems unlikely that DNs encode many individual odors with high specificity: the number of DNs is far smaller than what would be required to cover an enormous olfactory space. Instead, we speculate that DN odor-encoding may represent classes like attractive versus aversive odors or the valence of sensory inputs in general. Where odor information is conveyed to within downstream motor circuits and for what purpose is a fascinating subject for future study.</p><p>Many fewer neurons encode head grooming as opposed to walking. Because our transgenic strain does not drive expression in SEZ neurons we could not record several DNs whose activation has been shown to be sufficient to drive antennal grooming (aDN), front leg rubbing (DNg11), or both head grooming and front leg rubbing (DNg12) (<xref ref-type="bibr" rid="bib28">Guo et al., 2022</xref>). Thus, we expect that with the addition of these SEZ DNs the apparent dichotomy that many neurons encode walking and fewer encode grooming may become less pronounced. Nevertheless, groom-encoding DNs were notable in that they could be more reliably identified across individual animals. Among our head groom-encoding DNs a pair passing through the ventral cervical connective appear to encode limb contact during antennal grooming as well as puff-dependent antennal deflections. We speculate that mechanosensory signals from the antennae may be used for feedback control in the VNC: being aware of whether the antennae are touched while grooming may allow for a continuous modulation of grooming kinematics and force application by the front legs. This may be a conserved control mechanism as similar DNs have been identified in the blow fly (<xref ref-type="bibr" rid="bib55">Nässel et al., 1984</xref>).</p><p>Our morphological and physiological evidence suggests that these antennal mechanosensory signals are provided by DNx01s, a subset of bilateral campaniform sensillum (bCS) neurons that are also found on the legs and form major presynaptic connections to fast motor neurons (<xref ref-type="bibr" rid="bib62">Phelps et al., 2021</xref>). Thus, DNx01s may have a role beyond feedback control during grooming. This is also implied by the large size of DNx01 axons and their high sensitivity to puff-mediated antennal deflection. Because other DNs with large axons (e.g., giant fiber neurons) are often implicated in fast reflexive movements (<xref ref-type="bibr" rid="bib41">King and Wyman, 1980</xref>; <xref ref-type="bibr" rid="bib7">Azevedo et al., 2020</xref>), DNx01s may be used to respond to, for example, strong gusts of wind that initiate a stance stabilization reflex. Testing this hypothesis will require the creation of split-Gal4 driver lines that precisely and uniquely target DNx01 neurons.</p><p>Our analysis of DNx01 illustrates a potential road map for combining functional, topological, and morphological data to uncover the cellular identity of individual DNs from population recordings. Notably, our efforts were facilitated by DNx01’s unusual bilaterally asymmetric functional properties and large caliber axons. Taking this route to identify another, arbitrary DN would likely be more challenging and may require additional tools. For example, after functional imaging of DN populations one might focally photoactivate and image GFP within individual DN axons of interest (<xref ref-type="bibr" rid="bib24">Datta et al., 2008</xref>; <xref ref-type="bibr" rid="bib66">Ruta et al., 2010</xref>). Resulting morphological images could then be compared with DNs reconstructed in connectomics datasets (<xref ref-type="bibr" rid="bib87">Zheng et al., 2018</xref>; <xref ref-type="bibr" rid="bib62">Phelps et al., 2021</xref>).</p><p>Our work sets the stage for a more comprehensive, multiscale investigation of how the brain regulates complex limb-dependent motor behaviors. Nevertheless, overcoming several technical limitations in our study should also be a focus of future work. First, although we could achieve precise limb kinematic measurements at <inline-formula><mml:math id="inf38"><mml:mrow><mml:mn>100</mml:mn><mml:mtext/><mml:mi class="ltx_unit">Hz</mml:mi></mml:mrow></mml:math></inline-formula>, it will be critical to record neural data at equally high temporal resolution. The fly can walk with stride frequencies of up to <inline-formula><mml:math id="inf39"><mml:mrow><mml:mn>20</mml:mn><mml:mtext/><mml:mi class="ltx_unit">Hz</mml:mi></mml:mrow></mml:math></inline-formula> (<xref ref-type="bibr" rid="bib49">Mendes et al., 2013</xref>) and leg movements during grooming occur at up to <inline-formula><mml:math id="inf40"><mml:mrow><mml:mn>7</mml:mn><mml:mtext/><mml:mi class="ltx_unit">Hz</mml:mi></mml:mrow></mml:math></inline-formula>(<xref ref-type="bibr" rid="bib64">Ravbar et al., 2021</xref>). This currently makes it difficult to relate neural activity—read out by the relatively slow fluorescence fluctuations of a genetically encoded calcium indicator—to individual joint angles and limb positions. To address this challenge, one might use faster indicators of neural activity (e.g., newer variants of GCaMP [<xref ref-type="bibr" rid="bib86">Zhang, 2020</xref>] or voltage indicators [<xref ref-type="bibr" rid="bib63">Piatkevich et al., 2018</xref>]). Additionally, coronal section two-photon imaging in the thoracic cervical connective with a piezo-driven objective lens limited our neural data acquisition to ~16 Hz. One might perform data acquisition at a higher rate using more advanced imaging methods including single-objective light-sheet microscopy (<xref ref-type="bibr" rid="bib81">Voleti et al., 2019</xref>). Alternatively, the fly could be forced to generate slower limb movements using a motorized treadmill (<xref ref-type="bibr" rid="bib4">Aimon et al., 2022</xref>). Another challenge is that DNs from the SEZ are absent in our driver line. The SEZ is considered a center for action section (<xref ref-type="bibr" rid="bib47">Mann et al., 2013</xref>; <xref ref-type="bibr" rid="bib78">Tastekin et al., 2015</xref>) and is known to house numerous DNs (<xref ref-type="bibr" rid="bib53">Namiki et al., 2018</xref>; <xref ref-type="bibr" rid="bib33">Hsu and Bhandawat, 2016</xref>). Thus, complementing our driver line with an SEZ-expressing transgene (<xref ref-type="bibr" rid="bib74">Simpson, 2016</xref>) would enable a fully comprehensive recording of DN population dynamics. Nevertheless, we expect our observation to remain intact: locomotion is regulated by large DN populations in a distributed manner, while more stereotyped grooming behaviors engage fewer DNs. This would suggest a dichotomy in DN population control for flexible versus stereotyped motor behaviors. Future studies may test whether this holds true as well for wing-dependent behaviors like continuous steering during flight (<xref ref-type="bibr" rid="bib70">Schnell et al., 2017</xref>; <xref ref-type="bibr" rid="bib54">Namiki et al., 2022</xref>) versus stereotyped wing displays during courtship (<xref ref-type="bibr" rid="bib60">Pavlou and Goodwin, 2013</xref>).</p></sec><sec id="s4" sec-type="materials|methods"><title>Materials and methods</title><table-wrap id="keyresource" position="anchor"><label>Key resources table</label><table frame="hsides" rules="groups"><thead><tr><th align="left" valign="top">Reagent type (species) or resource</th><th align="left" valign="top">Designation</th><th align="left" valign="top">Source or reference</th><th align="left" valign="top">Identifiers</th><th align="left" valign="top">Additional information</th></tr></thead><tbody><tr><td align="left" valign="top">Genetic reagent (<italic>Drosophila melanogaster</italic>)</td><td align="left" valign="top"><inline-formula><mml:math id="inf41"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi mathvariant="normal">W</mml:mi><mml:mo>;</mml:mo><mml:mfrac><mml:mrow><mml:mi mathvariant="normal">t</mml:mi><mml:mi mathvariant="normal">u</mml:mi><mml:mi mathvariant="normal">b</mml:mi><mml:mo>&gt;</mml:mo><mml:mi mathvariant="normal">s</mml:mi><mml:mi mathvariant="normal">t</mml:mi><mml:mi mathvariant="normal">o</mml:mi><mml:mi mathvariant="normal">p</mml:mi><mml:mo>&gt;</mml:mo><mml:mi mathvariant="normal">G</mml:mi><mml:mi mathvariant="normal">A</mml:mi><mml:mi mathvariant="normal">L</mml:mi><mml:mn>80</mml:mn></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi mathvariant="normal">C</mml:mi><mml:mi mathvariant="normal">y</mml:mi><mml:mi mathvariant="normal">O</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mfrac><mml:mo>;</mml:mo><mml:mspace width="thinmathspace"/><mml:mfrac><mml:mrow><mml:mi mathvariant="normal">M</mml:mi><mml:mi mathvariant="normal">K</mml:mi><mml:mi mathvariant="normal">R</mml:mi><mml:mi mathvariant="normal">S</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">T</mml:mi><mml:mi mathvariant="normal">M</mml:mi><mml:mn>3</mml:mn><mml:mo>,</mml:mo><mml:mspace width="thinmathspace"/><mml:mi mathvariant="normal">S</mml:mi><mml:mi mathvariant="normal">b</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mn>21</mml:mn><mml:mo>−</mml:mo><mml:mn>21</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mfrac></mml:mrow></mml:mstyle></mml:math></inline-formula></td><td align="left" valign="top">Asahina lab (Salk Institute, San Diego, CA) (<xref ref-type="bibr" rid="bib5">Asahina et al., 2014</xref>)</td><td align="left" valign="top"/><td align="left" valign="top"/></tr><tr><td align="left" valign="top">Genetic reagent (<italic>D. melanogaster</italic>)</td><td align="left" valign="top"><inline-formula><mml:math id="inf42"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi mathvariant="normal">W</mml:mi><mml:mo>;</mml:mo><mml:mfrac><mml:mrow><mml:mi mathvariant="normal">O</mml:mi><mml:mi mathvariant="normal">t</mml:mi><mml:mi mathvariant="normal">d</mml:mi><mml:mo>−</mml:mo><mml:mi mathvariant="normal">n</mml:mi><mml:mi mathvariant="normal">l</mml:mi><mml:mi mathvariant="normal">s</mml:mi><mml:mo>:</mml:mo><mml:mi mathvariant="normal">F</mml:mi><mml:mi mathvariant="normal">L</mml:mi><mml:mi mathvariant="normal">P</mml:mi><mml:mspace width="thinmathspace"/><mml:mo stretchy="false">(</mml:mo><mml:mi mathvariant="normal">a</mml:mi><mml:mi mathvariant="normal">t</mml:mi><mml:mi mathvariant="normal">t</mml:mi><mml:mi mathvariant="normal">P</mml:mi><mml:mn>40</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi mathvariant="normal">C</mml:mi><mml:mi mathvariant="normal">y</mml:mi><mml:mi mathvariant="normal">O</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mfrac><mml:mo>;</mml:mo><mml:mspace width="thinmathspace"/><mml:mfrac><mml:mrow><mml:mi mathvariant="normal">T</mml:mi><mml:mi mathvariant="normal">M</mml:mi><mml:mn>2</mml:mn></mml:mrow><mml:mrow><mml:mi mathvariant="normal">T</mml:mi><mml:mi mathvariant="normal">M</mml:mi><mml:mn>6</mml:mn><mml:mi mathvariant="normal">B</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mn>26</mml:mn><mml:mo>−</mml:mo><mml:mn>27</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mfrac></mml:mrow></mml:mstyle></mml:math></inline-formula></td><td align="left" valign="top">Asahina lab (Salk Institute, San Diego, CA) (<xref ref-type="bibr" rid="bib5">Asahina et al., 2014</xref>)</td><td align="left" valign="top"/><td align="left" valign="top"/></tr><tr><td align="left" valign="top">Genetic reagent (<italic>D. melanogaster</italic>)</td><td align="left" valign="top">w; tubP-(FRT.GAL80);</td><td align="left" valign="top">Bloomington <italic>Drosophila</italic> Stock Center</td><td align="left" valign="top">BDSC: #62103</td><td align="left" valign="top"/></tr><tr><td align="left" valign="top">Genetic reagent (<italic>D. melanogaster</italic>)</td><td align="left" valign="top">w; +; R57C10-GAL4;</td><td align="left" valign="top">Bloomington <italic>Drosophila</italic> Stock Center (<xref ref-type="bibr" rid="bib37">Jenett et al., 2012</xref>)</td><td align="left" valign="top">BDSC: #39171</td><td align="left" valign="top"/></tr><tr><td align="left" valign="top">Genetic reagent (<italic>D. melanogaster</italic>)</td><td align="left" valign="top">w; +; 10xUAS-IVS-myr::smGFP-FLAG (attP2)</td><td align="left" valign="top">Bloomington <italic>Drosophila</italic> Stock Center (<xref ref-type="bibr" rid="bib56">Nern et al., 2015</xref>)</td><td align="left" valign="top">BDSC: #62147</td><td align="left" valign="top"/></tr><tr><td align="left" valign="top">Genetic reagent (<italic>D. melanogaster</italic>)</td><td align="left" valign="top">+[HCS]; P{20XUAS-IVSGCaMP6s} attP40; P{w[+mC]=UAS-tdTom.S}3</td><td align="left" valign="top">Dickinson lab (Caltech, Pasadena, CA)</td><td align="left" valign="top"/><td align="left" valign="top"/></tr><tr><td align="left" valign="top">Genetic reagent (<italic>D. melanogaster</italic>)</td><td align="left" valign="top">;P20XUAS-IVS-Syn21- OpGCaMP6f-464 p10 su(Hw)attp5; Pw[+mC]=UAS-tdTom.S3</td><td align="left" valign="top">Dickinson lab (Caltech, Pasadena, CA)</td><td align="left" valign="top"/><td align="left" valign="top"/></tr><tr><td align="left" valign="top">Genetic reagent (<italic>D. melanogaster</italic>)</td><td align="left" valign="top">R57C10-446 Flp2::PEST in su(Hw)attP8;; HA-V5-FLAG</td><td align="left" valign="top">Bloomington <italic>Drosophila</italic> Stock Center (<xref ref-type="bibr" rid="bib56">Nern et al., 2015</xref>)</td><td align="left" valign="top">BDSC: #64089</td><td align="left" valign="top"/></tr><tr><td align="left" valign="top">Genetic reagent (<italic>D. melanogaster</italic>)</td><td align="left" valign="top">w;;P{w[+mC]=20xUAS-DSCP&gt;H2A::sfGFP-T2A-mKOk::Caax} JK66B</td><td align="left" valign="top">McCabe lab (EPFL, Lausanne, Switzerland) (<xref ref-type="bibr" rid="bib38">Jiao et al., 2022</xref>)</td><td align="left" valign="top"/><td align="left" valign="top"/></tr><tr><td align="left" valign="top">Genetic reagent (<italic>D. melanogaster</italic>)</td><td align="left" valign="top">;Otd-nls:FLPo (attP40)/(CyO); R57C10-GAL4, tub&gt;GAL80&gt;/(TM6B)</td><td align="left" valign="top">This paper</td><td align="left" valign="top"/><td align="left" valign="top"/></tr><tr><td align="left" valign="top">Antibody</td><td align="left" valign="top">Anti-GFP (rabbit monoclonal)</td><td align="left" valign="top">Thermo Fisher</td><td align="left" valign="top">AB2536526</td><td align="char" char="." valign="top">1:500</td></tr><tr><td align="left" valign="top">Antibody</td><td align="left" valign="top">Anti-Bruchpilot (mouse monoclonal)</td><td align="left" valign="top">Developmental Studies Hybridoma Bank</td><td align="left" valign="top">AB2314866</td><td align="char" char="." valign="top">1:20</td></tr><tr><td align="left" valign="top">Antibody</td><td align="left" valign="top">Anti-rabbit conjugated with Alexa 488 (goat polyclonal)</td><td align="left" valign="top">Thermo Fisher</td><td align="left" valign="top">AB143165</td><td align="char" char="." valign="top">1:500</td></tr><tr><td align="left" valign="top">Antibody</td><td align="left" valign="top">Anti-mouse conjugated with Alexa 633 (goat polyclonal)</td><td align="left" valign="top">Thermo Fisher</td><td align="left" valign="top">AB2535719</td><td align="char" char="." valign="top">1:500</td></tr><tr><td align="left" valign="top">Antibody</td><td align="left" valign="top">Anti-HA-tag (rabbit monoclonal)</td><td align="left" valign="top">Cell Signaling Technology</td><td align="left" valign="top">AB1549585</td><td align="char" char="." valign="top">1:300</td></tr><tr><td align="left" valign="top">Antibody</td><td align="left" valign="top">Anti-FLAG-tag DYKDDDDK (rat monoclonal)</td><td align="left" valign="top">Novus</td><td align="left" valign="top">AB1625981</td><td align="char" char="." valign="top">1:150</td></tr><tr><td align="left" valign="top">Software, algorithm</td><td align="left" valign="top">noise2void</td><td align="char" char="." valign="top"><xref ref-type="bibr" rid="bib42">Krull et al., 2019</xref></td><td align="left" valign="top"/><td align="left" valign="top">Denoising of red channel</td></tr><tr><td align="left" valign="top">Software, algorithm</td><td align="left" valign="top">deepinterpolation</td><td align="char" char="." valign="top"><xref ref-type="bibr" rid="bib44">Lecoq et al., 2021</xref></td><td align="left" valign="top"/><td align="left" valign="top">Denoising of green channel</td></tr><tr><td align="left" valign="top">Software, algorithm</td><td align="left" valign="top">DeepFly3D</td><td align="char" char="." valign="top"><xref ref-type="bibr" rid="bib27">Günel et al., 2019</xref></td><td align="left" valign="top"/><td align="left" valign="top">Pose estimation</td></tr><tr><td align="left" valign="top">Software, algorithm</td><td align="left" valign="top">NeuroMechFly</td><td align="char" char="." valign="top"><xref ref-type="bibr" rid="bib46">Lobato-Rios et al., 2022</xref></td><td align="left" valign="top"/><td align="left" valign="top">Kinematic replay, collision detection</td></tr><tr><td align="left" valign="top">Software, algorithm</td><td align="left" valign="top">utils2p</td><td align="left" valign="top">This paper</td><td align="left" valign="top"/><td align="left" valign="top">Preprocessing of two-photon images, synchronization</td></tr><tr><td align="left" valign="top">Software, algorithm</td><td align="left" valign="top">utils video</td><td align="left" valign="top">This paper</td><td align="left" valign="top"/><td align="left" valign="top">Creation of videos</td></tr></tbody></table></table-wrap><sec id="s4-1"><title>Fly husbandry and stocks</title><p>All experiments were performed on female <italic>D. melanogaster</italic> raised at 25°C and 50% humidity on a 12 hr light–dark cycle. Flies were 10 days post-eclosion (dpe) for experiments and had been starved overnight on a wet precision wipe (Kimtech Science, 05511, USA). Sources of each genotype used are indicated in Key Resources Table.</p></sec><sec id="s4-2"><title>Olfactometer</title><p>Mass flow controllers (MFCs) were used to regulate air flow (Vögtlin, GSC-B4SA-BB23 [<inline-formula><mml:math id="inf43"><mml:mrow><mml:mn>2</mml:mn><mml:mtext/><mml:mrow><mml:mi class="ltx_unit" mathvariant="normal">L</mml:mi><mml:mtext/><mml:msup><mml:mi class="ltx_unit">min</mml:mi><mml:mrow><mml:mo>-</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:mrow></mml:math></inline-formula>], GSC-A3KA-BB22 [<inline-formula><mml:math id="inf44"><mml:mrow><mml:mn>100</mml:mn><mml:mtext/><mml:mrow><mml:mi class="ltx_unit">mL</mml:mi><mml:mtext/><mml:msup><mml:mi class="ltx_unit">min</mml:mi><mml:mrow><mml:mo>-</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:mrow></mml:math></inline-formula>]). The larger MFC, set to <inline-formula><mml:math id="inf45"><mml:mrow><mml:mn>42</mml:mn><mml:mtext/><mml:mrow><mml:mi class="ltx_unit">mL</mml:mi><mml:mtext/><mml:msup><mml:mi class="ltx_unit">min</mml:mi><mml:mrow><mml:mo>-</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:mrow></mml:math></inline-formula>, was used to continuously bubble odor vials, maintaining a constant head space odorant concentration. The smaller MFC was used to stimulate the fly at <inline-formula><mml:math id="inf46"><mml:mrow><mml:mn>41</mml:mn><mml:mtext/><mml:mrow><mml:mi class="ltx_unit">mL</mml:mi><mml:mtext/><mml:msup><mml:mi class="ltx_unit">min</mml:mi><mml:mrow><mml:mo>-</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:mrow></mml:math></inline-formula>. We directed air flow using six solenoid valves (SMC, S070C-6AG-32, Japan) controlled by an Arduino Mega (Arduino, A000067, Italy). One valve in front of each of the three odor vials was used to switch between inputs from each MFC. A second valve after each odor vial was used to direct air flow either toward the fly or into an exhaust. The second valve was placed as close to the fly as possible (~10 cm) to minimize the delay between solenoid switching and odor stimulation. To direct air flow to the fly’s antennae, we used a glass capillary held in place by a Sensapex zero-drift micro-manipulator (Sensapex, uMp-3, Finland). We minimized mechanical perturbations by blowing humidified (nonodorized) air onto the fly between odor trials. We used a PID (Aurora Scientific, miniPID, Canada) and visual assessment of animal behavior to confirm that switching generated minimal mechanical perturbations.</p></sec><sec id="s4-3"><title>Two-photon microscopy</title><p>We performed neural recordings using a ThorLabs Bergamo two-photon microscope (Thorlabs, Bergamo II, USA) connected to a Mai Tai DeepSee laser (Spectra Physics, Mai Tai DeepSee, USA). To perform coronal section imaging, we operated the microscope in kymograph mode using the galvo-resonant light path. Images were acquired at a magnification of 7.4× resulting in a 82.3 μm wide FOV. To prevent the cervical connective from leaving the FOV, the full range of a 100 µm piezo collar was used to scan the objective lens (Olympus XLUMPlanFLN 20× , <inline-formula><mml:math id="inf47"><mml:mrow><mml:mn>1.0</mml:mn><mml:mtext/><mml:mi>NA</mml:mi></mml:mrow></mml:math></inline-formula> with <inline-formula><mml:math id="inf48"><mml:mrow><mml:mn>2</mml:mn><mml:mtext/><mml:mi class="ltx_unit">mm</mml:mi></mml:mrow></mml:math></inline-formula> working distance) in the z-axis. We could achieve a frame rate of approximately <inline-formula><mml:math id="inf49"><mml:mrow><mml:mn>16</mml:mn><mml:mtext/><mml:mi class="ltx_unit">Hz</mml:mi></mml:mrow></mml:math></inline-formula> by sampling 736 × 480 pixel (x- and z-axes, respectively) images and by enabling bidirectional scanning, with only one fly-back frame.</p></sec><sec id="s4-4"><title>Neural recordings</title><sec id="s4-4-1"><title>Descending neuron population recordings</title><p>Flies were dissected to obtain optical access to the thoracic cervical connective, as described in <xref ref-type="bibr" rid="bib20">Chen et al., 2018</xref>. Briefly, we opened the cuticle using a syringe and waited for the flight muscles to degrade before resecting trachea, the proventriculus, and the salivary glands. After removing these tissues covering the VNC, an implant (<xref ref-type="bibr" rid="bib32">Hermans et al., 2021</xref>) was inserted into the thoracic cavity to prevent inflation of the trachea and ensure a clear view of the cervical connective for extended periods of time. Flies were then given several minutes to adapt to positioning over a spherical treadmill in the two-photon microscope system. During this adaptation period, the nozzle of the olfactometer was positioned approximately <inline-formula><mml:math id="inf50"><mml:mrow><mml:mn>2</mml:mn><mml:mtext/><mml:mi class="ltx_unit">mm</mml:mi></mml:mrow></mml:math></inline-formula> in front of the fly’s head. As well, the thoracic cervical connective was brought into the imaging FOV. Following alignment, their position was further adjusted to maximize fluorescence signal and minimize the possibility of neurites leaving the imaging FOV. For each fly, a minimum of five <inline-formula><mml:math id="inf51"><mml:mrow><mml:mn>9</mml:mn><mml:mtext/><mml:mi class="ltx_unit">min</mml:mi></mml:mrow></mml:math></inline-formula> trials were recorded using a laser power of <inline-formula><mml:math id="inf52"><mml:mrow><mml:mn>9.25</mml:mn><mml:mtext/><mml:mi class="ltx_unit">mW</mml:mi></mml:mrow></mml:math></inline-formula> at <inline-formula><mml:math id="inf53"><mml:mrow><mml:mn>930</mml:mn><mml:mtext/><mml:mi class="ltx_unit">nm</mml:mi></mml:mrow></mml:math></inline-formula>.</p></sec><sec id="s4-4-2"><title>Sparse DNx01 recordings</title><p>Recordings of DNx01s in the R65D11-GAL4 driver line were performed as described in <xref ref-type="bibr" rid="bib21">Chen, 2022</xref>. This differed only slightly from DN population recordings in the following ways. First, flies were not starved. Second, the Gal4 drove expression of OpGCaMP6f rather than GCaMP6s. Third, a thoracic implant was not used. Fourth, instead of being presented with a constant flow of air and odors, animals were stimulated with CO2 puffs of alternating length (<inline-formula><mml:math id="inf54"><mml:mrow><mml:mn>0.5</mml:mn><mml:mtext/><mml:mi class="ltx_unit" mathvariant="normal">s</mml:mi></mml:mrow></mml:math></inline-formula>, <inline-formula><mml:math id="inf55"><mml:mrow><mml:mn>2</mml:mn><mml:mtext/><mml:mi class="ltx_unit" mathvariant="normal">s</mml:mi></mml:mrow></mml:math></inline-formula>) spaced <inline-formula><mml:math id="inf56"><mml:mrow><mml:mn>40</mml:mn><mml:mtext/><mml:mi class="ltx_unit" mathvariant="normal">s</mml:mi></mml:mrow></mml:math></inline-formula> apart. A higher pixel dwell time was used to achieve acceptably high imaging signal-to-noise. This resulted in a slower two-photon image acquisition rate (<inline-formula><mml:math id="inf57"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mn>4.3</mml:mn><mml:mspace width="thinmathspace"/><mml:mrow><mml:mi mathvariant="normal">f</mml:mi><mml:mi mathvariant="normal">p</mml:mi><mml:mi mathvariant="normal">s</mml:mi></mml:mrow></mml:mrow></mml:mstyle></mml:math></inline-formula>), which was matched by a slower behavior recording frequency (<inline-formula><mml:math id="inf58"><mml:mrow><mml:mn>30</mml:mn><mml:mtext/><mml:mi class="ltx_unit">Hz</mml:mi></mml:mrow></mml:math></inline-formula>). For additional details and a description of the stimulation system, see <xref ref-type="bibr" rid="bib21">Chen, 2022</xref>. Note that images of the connective in <xref ref-type="fig" rid="fig5">Figure 5a and e</xref> appear to have different heights due to a difference in z-step size during image acquisition.</p></sec></sec><sec id="s4-5"><title>Postprocessing of two-photon imaging data</title><sec id="s4-5-1"><title>Descending neuron population recordings</title><p>Binary output files from ThorImage (Thorlabs, ThorImage 3.2, USA) were converted into separate tiff files for each channel using custom Python code (<ext-link ext-link-type="uri" xlink:href="https://doi.org/10.5281/zenodo.5501119">https://doi.org/10.5281/zenodo.5501119</ext-link>). Images acquired from the red channel were then denoised (<xref ref-type="bibr" rid="bib42">Krull et al., 2019</xref>) and two-way alignment offset was corrected (<ext-link ext-link-type="uri" xlink:href="https://doi.org/10.5281/zenodo.6475468">https://doi.org/10.5281/zenodo.6475468</ext-link>) based on denoised images. We then used optic flow estimation to correct image translations and deformations based on the denoised red channel images (<ext-link ext-link-type="uri" xlink:href="https://doi.org/10.5281/zenodo.6475525">https://doi.org/10.5281/zenodo.6475525</ext-link>). The green channel was then corrected based on the motion field estimated from the red channel. Finally, we trained a DeepInterpolation network (<xref ref-type="bibr" rid="bib44">Lecoq et al., 2021</xref>) for each fly using the first 500 motion-corrected green channel images from each experimental trial (batch size = 20; epochs = 20; pre-post frames = 30). The first and the last trials were used as validation datasets. The trained network was then used to denoise green channel images.</p><p>Baseline fluorescence was then determined on a fly-wise and pixel-wise basis across all trials. The baseline of a pixel was defined as the minimum ‘mean of 15 consecutive values’ across all experimental trials. Motion correction introduces zeroes to two-photon images in background regions that were out of the FOV prior to warping. Therefore, values close to zero (floating point inaccuracy) were set to the maximum of the datatype of the array. This means essentially ignoring these pixels and their immediate surroundings for baseline computations. We used the baseline image <italic>F</italic><sub>0</sub> to calculate <inline-formula><mml:math id="inf59"><mml:mrow><mml:mo>%</mml:mo><mml:mfrac><mml:mrow><mml:mi>F</mml:mi><mml:mo>-</mml:mo><mml:msub><mml:mi>F</mml:mi><mml:mn>0</mml:mn></mml:msub></mml:mrow><mml:msub><mml:mi>F</mml:mi><mml:mn>0</mml:mn></mml:msub></mml:mfrac></mml:mrow></mml:math></inline-formula> images. These images were only used for visualization. To identify ROIs/neurons, we created a maximum intensity projection of <inline-formula><mml:math id="inf60"><mml:mrow><mml:mo>%</mml:mo><mml:mfrac><mml:mrow><mml:mi>F</mml:mi><mml:mo>-</mml:mo><mml:msub><mml:mi>F</mml:mi><mml:mn>0</mml:mn></mml:msub></mml:mrow><mml:msub><mml:mi>F</mml:mi><mml:mn>0</mml:mn></mml:msub></mml:mfrac></mml:mrow></mml:math></inline-formula> images and manually annotated ROIs. The <inline-formula><mml:math id="inf61"><mml:mrow><mml:mo>%</mml:mo><mml:mfrac><mml:mrow><mml:mi>F</mml:mi><mml:mo>-</mml:mo><mml:msub><mml:mi>F</mml:mi><mml:mn>0</mml:mn></mml:msub></mml:mrow><mml:msub><mml:mi>F</mml:mi><mml:mn>0</mml:mn></mml:msub></mml:mfrac></mml:mrow></mml:math></inline-formula> of each ROI was computed by first spatially averaging its raw pixel values. We then calculated the baseline of this average as described for a single pixel above. For brevity and readability, we refer to <inline-formula><mml:math id="inf62"><mml:mrow><mml:mo>%</mml:mo><mml:mfrac><mml:mrow><mml:mi>F</mml:mi><mml:mo>-</mml:mo><mml:msub><mml:mi>F</mml:mi><mml:mn>0</mml:mn></mml:msub></mml:mrow><mml:msub><mml:mi>F</mml:mi><mml:mn>0</mml:mn></mml:msub></mml:mfrac></mml:mrow></mml:math></inline-formula> as <inline-formula><mml:math id="inf63"><mml:mrow><mml:mo>%</mml:mo><mml:mi mathvariant="normal">Δ</mml:mi><mml:mi>F</mml:mi><mml:mo>/</mml:mo><mml:mi>F</mml:mi></mml:mrow></mml:math></inline-formula> throughout the article.</p></sec><sec id="s4-5-2"><title>Sparse DNx01 descending neuron recordings</title><p>ROIs were detected using AxoID. Raw, non-denoised traces were used for analysis. For more details concerning data postprocessing, see <xref ref-type="bibr" rid="bib21">Chen, 2022</xref>.</p></sec></sec><sec id="s4-6"><title>Behavior classification and quantification</title><sec id="s4-6-1"><title>Behavior measurement system</title><p>The behavior of tethered animals was recorded using a previously described (<xref ref-type="bibr" rid="bib27">Günel et al., 2019</xref>) 7-camera (Basler, acA1920-150um, Germany) system. Animals were illuminated using an infrared (<inline-formula><mml:math id="inf64"><mml:mrow><mml:mn>850</mml:mn><mml:mtext/><mml:mi class="ltx_unit">nm</mml:mi></mml:mrow></mml:math></inline-formula>) ring light (CSS, LDR2-74IR2-850-LA, Japan). To track the joint positions of each leg, six cameras were equipped with <inline-formula><mml:math id="inf65"><mml:mrow><mml:mn>94</mml:mn><mml:mtext/><mml:mi class="ltx_unit">mm</mml:mi></mml:mrow></mml:math></inline-formula> focal length 1.00× InfiniStix lenses (Infinity, 94 mm/1.00×, USA). All cameras recorded data at 100 fps and were synchronized using a hardware trigger. For more details, see <xref ref-type="bibr" rid="bib27">Günel et al., 2019</xref>.</p></sec><sec id="s4-6-2"><title>Inferring fictive locomotor trajectories</title><p>Video data from the front camera were processed using FicTrac (<xref ref-type="bibr" rid="bib51">Moore et al., 2014</xref>) to track ball movements. This camera was outfitted with a lens allowing adjustable focus and zoom (Computar, MLM3X-MP, 0.3X-1X, 1:4.5, Japan). To improve tracking accuracy, the quality factor of FicTrac was set to 40. The circumference of the ball was detected automatically using a Hough circle transform on the mean projection of all images for a given experimental trial. To determine the vertical angular FOV, <inline-formula><mml:math id="inf66"><mml:mi>α</mml:mi></mml:math></inline-formula>, the value given in the specifications of the Computar lens (8.74°) had to be adjusted, accommodating a smaller sensor size. We first determined the focal length to be <inline-formula><mml:math id="inf67"><mml:mrow><mml:mn>43.18</mml:mn><mml:mtext/><mml:mi class="ltx_unit">mm</mml:mi></mml:mrow></mml:math></inline-formula> using <xref ref-type="disp-formula" rid="equ1">Equation 1</xref>, where <inline-formula><mml:math id="inf68"><mml:mi>H</mml:mi></mml:math></inline-formula> is the height of the sensor. This was set to <inline-formula><mml:math id="inf69"><mml:mrow><mml:mn>6.6</mml:mn><mml:mtext/><mml:mi class="ltx_unit">mm</mml:mi></mml:mrow></mml:math></inline-formula> for a 2/3″ sensor.<disp-formula id="equ1"><label>(1)</label><mml:math id="m1"><mml:mrow><mml:mi>f</mml:mi><mml:mo>=</mml:mo><mml:mfrac><mml:mi>H</mml:mi><mml:mrow><mml:mn>2</mml:mn><mml:mo>⁢</mml:mo><mml:mi>t</mml:mi><mml:mo>⁢</mml:mo><mml:mi>a</mml:mi><mml:mo>⁢</mml:mo><mml:mi>n</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mfrac><mml:mi>α</mml:mi><mml:mn>2</mml:mn></mml:mfrac><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:mfrac></mml:mrow></mml:math></disp-formula></p><p>The ROI of the Basler camera was set to 960 × 480 pixels, reducing the effective sensor height from <inline-formula><mml:math id="inf70"><mml:mrow><mml:mn>5.8</mml:mn><mml:mtext/><mml:mi class="ltx_unit">mm</mml:mi></mml:mrow></mml:math></inline-formula> to <inline-formula><mml:math id="inf71"><mml:mrow><mml:mn>2.32</mml:mn><mml:mtext/><mml:mi class="ltx_unit">mm</mml:mi></mml:mrow></mml:math></inline-formula>. Rearranging <xref ref-type="disp-formula" rid="equ1">Equation 1</xref> and plugging in <inline-formula><mml:math id="inf72"><mml:mi>f</mml:mi></mml:math></inline-formula> and <inline-formula><mml:math id="inf73"><mml:mi>H</mml:mi></mml:math></inline-formula> yields a vertical angular FOV of 3.05°. Since the camera was already aligned with the animal, the camera-to-animal transform was set to zero. To obtain the fly’s trajectory, we developed custom code that integrates rotational velocities (<ext-link ext-link-type="uri" xlink:href="https://github.com/NeLy-EPFL/utils_ballrot">https://github.com/NeLy-EPFL/utils_ballrot</ext-link>; <xref ref-type="bibr" rid="bib6">Aymanns, 2022</xref>; copy archived at <ext-link ext-link-type="uri" xlink:href="https://archive.softwareheritage.org/swh:1:dir:897af8506da57a666a43a8312ec2c3d4cdc14b1c;origin=https://github.com/NeLy-EPFL/utils_ballrot;visit=swh:1:snp:ff136d6a979bb929ee069de70c742ccababbd08d;anchor=swh:1:rev:7247f448be62f349bb528ad70633b4b41be5bbaf">swh:1:rev:7247f448be62f349bb528ad70633b4b41be5bbaf</ext-link>).</p></sec><sec id="s4-6-3"><title>Postprocessing of 3D pose estimates</title><p>Outliers in 3D pose data were corrected as described in <xref ref-type="bibr" rid="bib21">Chen, 2022</xref>. Briefly, we detected outliers based on changes in leg segment length and chose the pair of cameras with minimal reprojection error for triangulation. After outlier correction, the data were aligned and joint angles were computed using published code (<xref ref-type="bibr" rid="bib46">Lobato-Rios et al., 2022</xref>): <ext-link ext-link-type="uri" xlink:href="https://github.com/NeLy-EPFL/df3dPostProcessing/tree/outlier_correction">https://github.com/NeLy-EPFL/df3dPostProcessing/tree/outlier_correction</ext-link>.</p></sec><sec id="s4-6-4"><title>Classification of behaviors</title><p>Behaviors were classified based on limb joint angles using the approach described in <xref ref-type="bibr" rid="bib84">Whiteway et al., 2021</xref>. Briefly, a network was trained using 1 min of annotations for each fly and heuristic labels. Motion energy, ball rotations, and joint positions were used to generate the heuristic labels. To compute the motion energy, each joint position was convolved with the finite difference coefficients of length nine, estimating the first derivative. After computing the <inline-formula><mml:math id="inf74"><mml:msup><mml:mi>L</mml:mi><mml:mn>1</mml:mn></mml:msup></mml:math></inline-formula>-norm, the signal was filtered with a tenth-order low-pass Butterworth filter of critical frequency <inline-formula><mml:math id="inf75"><mml:mrow><mml:mn>4</mml:mn><mml:mtext/><mml:mi class="ltx_unit">Hz</mml:mi></mml:mrow></mml:math></inline-formula>. The total, front, and hind motion energy were computed by summing over all joints, all front leg joints, and all hindleg joints, respectively. Forward ball rotation speeds were processed using the same Butterworth filter described above. First, we assigned heuristic labels for walking by thresholding the filtered forward walking velocity at <inline-formula><mml:math id="inf76"><mml:mrow><mml:mn>0.5</mml:mn><mml:mtext/><mml:mrow><mml:mi class="ltx_unit">mm</mml:mi><mml:mtext/><mml:msup><mml:mi class="ltx_unit" mathvariant="normal">s</mml:mi><mml:mrow><mml:mo>-</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:mrow></mml:math></inline-formula>. The remaining frames with a motion energy smaller than 0.3 were then classified as resting. Next, heuristic labels for front movements (front motion energy &gt; 0.2 and hind motion energy &lt; 0.2) and posterior movements (front motion energy &lt; 0.2 and hind motion energy &gt; 0.2) were assigned to all remaining frames. The front movement labels were further split into head grooming and front leg rubbing by thresholding the height of the front leg tarsi (the average between left and the right tarsi) at 0.05. After each step, a hysteresis filter was applied. This filter only changes state when at least 50 consecutive frames are in a new state. Based on a hyperparameter search using ‘leave one fly out’ cross-validation on the hand labels (<xref ref-type="fig" rid="fig1s1">Figure 1—figure supplement 1g</xref>), we selected the weights of <inline-formula><mml:math id="inf77"><mml:mrow><mml:msub><mml:mi>λ</mml:mi><mml:mrow><mml:mi>p</mml:mi><mml:mo>⁢</mml:mo><mml:mi>r</mml:mi><mml:mo>⁢</mml:mo><mml:mi>e</mml:mi><mml:mo>⁢</mml:mo><mml:mi>d</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:math></inline-formula> and <inline-formula><mml:math id="inf78"><mml:mrow><mml:msub><mml:mi>λ</mml:mi><mml:mrow><mml:mi>w</mml:mi><mml:mo>⁢</mml:mo><mml:mi>e</mml:mi><mml:mo>⁢</mml:mo><mml:mi>a</mml:mi><mml:mo>⁢</mml:mo><mml:mi>k</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:math></inline-formula> for the loss.</p></sec><sec id="s4-6-5"><title>Biomechanical simulation and antennal collision detection</title><p>To infer limb-antennal collisions, we performed kinematic replay using the NeuroMechFly physics simulation framework as described in <xref ref-type="bibr" rid="bib46">Lobato-Rios et al., 2022</xref>. We used joint angles to replay real limb movements in the simulation. To avoid model explosion and accumulating errors over long simulation times, we ran kinematic replay on time segments shorter than the full experimental trials. These segments consisted of individual head grooming and front leg rubbing events. The default head angle was fixed to 20°. The aristae yaw values were set to –32° and 32° and pedicel yaw values were set to –33° and 33° for the left and right sides, respectively. To speed up the simulation, we only detected collisions between the front legs and head segments.</p></sec></sec><sec id="s4-7"><title>Confocal imaging of the brain and ventral nerve cord</title><p>Confocal images were acquired using a Zeiss LSM700 microscope. These images were then registered to a brain and VNC template described in <xref ref-type="bibr" rid="bib21">Chen, 2022</xref> using the method from <xref ref-type="bibr" rid="bib36">Jefferis et al., 2007</xref>. Brain and VNC sample preparation was performed as described in <xref ref-type="bibr" rid="bib21">Chen, 2022</xref>. Both primary and secondary antibodies were applied for 24 hr and the sample was rinsed 2–3 times after each step. Antibodies and concentrations used for staining are indicated in Key Resources Table.</p></sec><sec id="s4-8"><title>Electron microscopy identification and tracing</title><p>Within an electron microscopy dataset of the VNC and neck connective (<xref ref-type="bibr" rid="bib62">Phelps et al., 2021</xref>), we identified the pair of DNx01s based on their large-caliber axons in the cervical connective positioned ventral to the giant fiber neurons axons (<xref ref-type="fig" rid="fig5">Figure 5l</xref>). We then manually reconstructed all branches of one DNx01 neuron using CATMAID (<xref ref-type="bibr" rid="bib67">Saalfeld et al., 2009</xref>; <xref ref-type="bibr" rid="bib69">Schneider-Mizell et al., 2016</xref>) as described in <xref ref-type="bibr" rid="bib62">Phelps et al., 2021</xref>. The reconstructed neuron was then registered to the female VNC standard template (<xref ref-type="bibr" rid="bib10">Bogovic et al., 2020</xref>) using an elastix-based atlas registration as described in <xref ref-type="bibr" rid="bib62">Phelps et al., 2021</xref>.</p></sec><sec id="s4-9"><title>Data analysis</title><p>Animals were excluded from analysis if they produced irregular behavior or fewer than 75 neuronal ROIs could be manually identified in two-photon imaging data.</p><sec id="s4-9-1"><title>Linear regression modeling</title><p>We relied primarily on regression techniques to link behavioral and neural data. Here, we first describe the general approaches used and then discuss the details and modifications for individual figure panels. To evaluate the success of regression models, we calculated explained variance in the form of the coefficient of determination (<inline-formula><mml:math id="inf79"><mml:msup><mml:mi>R</mml:mi><mml:mn>2</mml:mn></mml:msup></mml:math></inline-formula>) and unique explained variance (UEV) (<xref ref-type="bibr" rid="bib52">Musall et al., 2019</xref>). The explained variance is a measure of how much additional variance is explained by the model compared to an intercept-only model (i.e., approximating the data by taking the mean). A definition of the coefficient of determination can be found in <xref ref-type="disp-formula" rid="equ2">Equation 2</xref>, where SSE is the sum of squares of the error, SST is the total sum of squares, <italic>y</italic><sub><italic>i</italic></sub> is a data point, <inline-formula><mml:math id="inf80"><mml:msub><mml:mover accent="true"><mml:mi>y</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover><mml:mi>i</mml:mi></mml:msub></mml:math></inline-formula> is the prediction of <italic>y</italic><sub><italic>i</italic></sub>, and <inline-formula><mml:math id="inf81"><mml:mover accent="true"><mml:mi>y</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover></mml:math></inline-formula> is the mean of all data points.<disp-formula id="equ2"><label>(2)</label><mml:math id="m2"><mml:mrow><mml:msup><mml:mi>R</mml:mi><mml:mn>2</mml:mn></mml:msup><mml:mo>=</mml:mo><mml:mrow><mml:mn>1</mml:mn><mml:mo>-</mml:mo><mml:mfrac><mml:mtext>SSE</mml:mtext><mml:mtext>SST</mml:mtext></mml:mfrac></mml:mrow><mml:mo>=</mml:mo><mml:mrow><mml:mn>1</mml:mn><mml:mo>-</mml:mo><mml:mfrac><mml:mrow><mml:msub><mml:mo largeop="true" symmetric="true">∑</mml:mo><mml:mi>i</mml:mi></mml:msub><mml:msup><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:msub><mml:mi>y</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>-</mml:mo><mml:msub><mml:mover accent="true"><mml:mi>y</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover><mml:mi>i</mml:mi></mml:msub></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mn>2</mml:mn></mml:msup></mml:mrow><mml:mrow><mml:msub><mml:mo largeop="true" symmetric="true">∑</mml:mo><mml:mi>i</mml:mi></mml:msub><mml:msup><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:msub><mml:mi>y</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>-</mml:mo><mml:mover accent="true"><mml:mi>y</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mn>2</mml:mn></mml:msup></mml:mrow></mml:mfrac></mml:mrow></mml:mrow></mml:math></disp-formula></p><p>Note that <inline-formula><mml:math id="inf82"><mml:msup><mml:mi>R</mml:mi><mml:mn>2</mml:mn></mml:msup></mml:math></inline-formula> becomes negative when SSE is larger than SST. This is the case when the model prediction introduces additional variance due to overfitting. UEV is a measure for the importance of individual or a subset of regressors. It is computed as the reduction in <inline-formula><mml:math id="inf83"><mml:msup><mml:mi>R</mml:mi><mml:mn>2</mml:mn></mml:msup></mml:math></inline-formula> when a particular subset of regressors is randomly shuffled (<xref ref-type="disp-formula" rid="equ3">Equation 3</xref>).<disp-formula id="equ3"><label>(3)</label><mml:math id="m3"><mml:mrow><mml:mtext>UEV</mml:mtext><mml:mo>=</mml:mo><mml:mrow><mml:msubsup><mml:mi>R</mml:mi><mml:mtext>intact</mml:mtext><mml:mn>2</mml:mn></mml:msubsup><mml:mo>-</mml:mo><mml:msubsup><mml:mi>R</mml:mi><mml:mtext>shuffled</mml:mtext><mml:mn>2</mml:mn></mml:msubsup></mml:mrow></mml:mrow></mml:math></disp-formula></p><p>We performed fivefold cross-validation for all of our regression results to ensure good generalization. Nonregularized linear regression sometimes led to overfitting and negative <inline-formula><mml:math id="inf84"><mml:msup><mml:mi>R</mml:mi><mml:mn>2</mml:mn></mml:msup></mml:math></inline-formula> values. Therefore, we used ridge regression. The ridge coefficient was determined using fivefold nested cross-validation on the training data set. In some cases, we still observed small negative <inline-formula><mml:math id="inf85"><mml:msup><mml:mi>R</mml:mi><mml:mn>2</mml:mn></mml:msup></mml:math></inline-formula> values after applying ridge regularization. These were set to zero, in particular to avoid problems when computing UEVs. To account for the long decay dynamics of our calcium indicator, we convolved behavior variables with an approximation of the crf (<xref ref-type="disp-formula" rid="equ4">Equation 4</xref>).<disp-formula id="equ4"><label>(4)</label><mml:math id="m4"><mml:mrow><mml:mrow><mml:mtext>crf</mml:mtext><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mo>=</mml:mo><mml:mrow><mml:mrow><mml:mo>-</mml:mo><mml:msup><mml:mi>e</mml:mi><mml:mrow><mml:mo>-</mml:mo><mml:mrow><mml:mi>a</mml:mi><mml:mo>⁢</mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:mrow></mml:msup></mml:mrow><mml:mo>+</mml:mo><mml:msup><mml:mi>e</mml:mi><mml:mrow><mml:mo>-</mml:mo><mml:mrow><mml:mi>b</mml:mi><mml:mo>⁢</mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:mrow></mml:msup></mml:mrow></mml:mrow></mml:math></disp-formula></p><p>We used <inline-formula><mml:math id="inf86"><mml:mrow><mml:mi>a</mml:mi><mml:mo>=</mml:mo><mml:mn>7.4</mml:mn></mml:mrow></mml:math></inline-formula> and <inline-formula><mml:math id="inf87"><mml:mrow><mml:mi>b</mml:mi><mml:mo>=</mml:mo><mml:mn>0.3</mml:mn></mml:mrow></mml:math></inline-formula> to approximate the rise and decay times, respectively, as reported in <xref ref-type="bibr" rid="bib19">Chen et al., 2013</xref>. We also normalized the function to integrate to one on the interval <inline-formula><mml:math id="inf88"><mml:mrow><mml:mrow><mml:mn>0</mml:mn><mml:mtext>–</mml:mtext><mml:mn>30</mml:mn></mml:mrow><mml:mtext/><mml:mi class="ltx_unit" mathvariant="normal">s</mml:mi></mml:mrow></mml:math></inline-formula> In <xref ref-type="fig" rid="fig2">Figure 2</xref> and <xref ref-type="fig" rid="fig2s2">Figure 2—figure supplement 2</xref>, we predicted behavior from neural activity. To accomplish this, we trained models for all pairs of behaviors and neurons (e.g., walking and ROI 41 for the upper plot of <xref ref-type="fig" rid="fig2">Figure 2a</xref>). The target variable is a binary variable indicating whether the fly is walking or not. This was convolved with the crf (black line in <xref ref-type="fig" rid="fig2">Figure 2a</xref>). The single regressor besides the intercept in the model is the <inline-formula><mml:math id="inf89"><mml:mrow><mml:mrow><mml:mi mathvariant="normal">Δ</mml:mi><mml:mo>⁢</mml:mo><mml:mi>F</mml:mi></mml:mrow><mml:mo>/</mml:mo><mml:mi>F</mml:mi></mml:mrow></mml:math></inline-formula> of a single neuron. <xref ref-type="fig" rid="fig2">Figure 2b</xref> and <xref ref-type="fig" rid="fig2s2">Figure 2—figure supplement 2c</xref> show the <inline-formula><mml:math id="inf90"><mml:msup><mml:mi>R</mml:mi><mml:mn>2</mml:mn></mml:msup></mml:math></inline-formula> values for all models. Each neuron was then assigned to be encoding the behavior with the maximum <inline-formula><mml:math id="inf91"><mml:msup><mml:mi>R</mml:mi><mml:mn>2</mml:mn></mml:msup></mml:math></inline-formula>. For neurons with maxima smaller than 5%, no behavior was assigned. In <xref ref-type="fig" rid="fig2s1">Figure 2—figure supplement 1</xref>, using the approach described in the previous section, we observed that some neurons appear to predict both walking and posterior movements, while others predict both head grooming and front leg rubbing. Because fluorescence decays slowly following the cessation of neural activity, this may be caused by the frequent sequential occurrence of two behaviors. For instance, if front leg rubbing often occurs after head grooming, the <inline-formula><mml:math id="inf92"><mml:mrow><mml:mrow><mml:mi mathvariant="normal">Δ</mml:mi><mml:mo>⁢</mml:mo><mml:mi>F</mml:mi></mml:mrow><mml:mo>/</mml:mo><mml:mi>F</mml:mi></mml:mrow></mml:math></inline-formula> of a head groom encoding neuron may still be elevated during front leg rubbing. This can lead to false positives in our analysis. To address this potential artifact, we predicted neural activity from multiple behavior regressors (i.e., binary behavior indicators convolved with the crf). We then calculated the UEV for each behavior regressor. For example, when the front leg rubbing regressor is shuffled the <inline-formula><mml:math id="inf93"><mml:msup><mml:mi>R</mml:mi><mml:mn>2</mml:mn></mml:msup></mml:math></inline-formula> will not decrease by much because the head grooming regressor includes the expected decay through convolution with a crf. The model of <xref ref-type="fig" rid="fig1s1">Figure 1—figure supplement 1a</xref> includes a walking and a posterior movements regressor. For <xref ref-type="fig" rid="fig2s1">Figure 2—figure supplement 1b</xref>, the model includes a head grooming and a front leg rubbing regressor. No other regressors were included in these models and for a given model, only data during one of these two behaviors were used. In <xref ref-type="fig" rid="fig3">Figure 3</xref> and <xref ref-type="fig" rid="fig3s2">Figure 3—figure supplement 2</xref>, for <xref ref-type="fig" rid="fig3">Figure 3a</xref>, we used all behavior regressors and the <inline-formula><mml:math id="inf94"><mml:mrow><mml:mrow><mml:mi mathvariant="normal">Δ</mml:mi><mml:mo>⁢</mml:mo><mml:mi>F</mml:mi></mml:mrow><mml:mo>/</mml:mo><mml:mi>F</mml:mi></mml:mrow></mml:math></inline-formula> of all neurons to predict ball rotation speeds convolved with a crf. We then temporally shuffled each of the neural regressors to calculate their UEVs. Since knowing whether the fly is walking or not provides some information about forward speed, the <inline-formula><mml:math id="inf95"><mml:msubsup><mml:mi>R</mml:mi><mml:mtext>intact</mml:mtext><mml:mn>2</mml:mn></mml:msubsup></mml:math></inline-formula> did not decrease to zero in the speed prediction (<xref ref-type="fig" rid="fig3">Figure 3a</xref>, second row). We address this issue in <xref ref-type="fig" rid="fig3">Figure 3b</xref> by only including walking frames but otherwise using the same approach as in <xref ref-type="fig" rid="fig3">Figure 3a</xref>. To pinpoint the encoding of ball rotations to individual neurons (<xref ref-type="fig" rid="fig3">Figure 3c</xref>), we made two changes to our approach. First, instead of predicting turning in general, we split the turning velocity into right and left turning. Second, we only included the <inline-formula><mml:math id="inf96"><mml:mrow><mml:mrow><mml:mi mathvariant="normal">Δ</mml:mi><mml:mo>⁢</mml:mo><mml:mi>F</mml:mi></mml:mrow><mml:mo>/</mml:mo><mml:mi>F</mml:mi></mml:mrow></mml:math></inline-formula> of a single neuron in the model rather than the data from all neurons. As before, the target variables were spherical treadmill rotation speeds—right turning, left turning, and forward walking—convolved with the crf. In <xref ref-type="fig" rid="fig4">Figure 4</xref> and <xref ref-type="fig" rid="fig4s1">Figure 4—figure supplement 1</xref>, to model odor encoding, we predicted the activity of a single neuron using behavior regressors, including crf-convolved spherical treadmill rotation speeds, and odor regressors constructed by convolving the crf with a binary variable indicating whether a given odor was present or not. To determine how much neural variance can be explained by the behavior regressors in our model, we shuffled both odor regressors (<xref ref-type="fig" rid="fig4">Figure 4b</xref>, top row). We then calculated the UEV for each odor by first computing the <inline-formula><mml:math id="inf97"><mml:msup><mml:mi>R</mml:mi><mml:mn>2</mml:mn></mml:msup></mml:math></inline-formula> of the model with all regressors intact, and then subtracting the <inline-formula><mml:math id="inf98"><mml:msup><mml:mi>R</mml:mi><mml:mn>2</mml:mn></mml:msup></mml:math></inline-formula> of the model after shuffling the odor regressor in question (<xref ref-type="fig" rid="fig4">Figure 4b</xref>, bottom). In <xref ref-type="fig" rid="fig4">Figure 4c and d</xref>, the intact model’s prediction (blue) and the shuffled model’s prediction (red) are shown. In <xref ref-type="fig" rid="fig4s2">Figure 4—figure supplement 2</xref>, to see whether a neuron’s behavior encoding could change depending on the context of which odor is present, we only examined the most commonly encoded behaviors: walking and head grooming. Each row is equivalent to the walking or head grooming rows in <xref ref-type="fig" rid="fig2s2">Figure 2—figure supplement 2b</xref>. However, here we only used subsets of the data to train and validate our models. Each row only uses data when one odor (or humidified air) is present. If there is no context dependence, each of the three rows should look identical. However, we note that due to the significant reduction in the amount of data for each model, noise can introduce variation across conditions. Humidified air data was subsampled to match the amount of data available for the odors MSC and ACV. To test whether the encoding was significantly different across contexts, we used a two-sided Mann–Whitney <italic>U</italic>-test. The data points are individual cross-validation folds from each trial. Elsewhere in this study we report cross-validation means. In <xref ref-type="fig" rid="fig5">Figure 5b</xref>, we perform a regression to predict one neuron’s activity using the intercept as well as a crf-convolved antennal collision regressor derived from data in <xref ref-type="fig" rid="fig5">Figure 5d</xref>.</p></sec><sec id="s4-9-2"><title>Kernel density estimation</title><p>We performed 2D kernel density estimation (<xref ref-type="fig" rid="fig2">Figure 2h and i</xref>) using SciPy’s gaussian_kde (<xref ref-type="bibr" rid="bib80">Virtanen et al., 2020</xref>). We performed 1D kernel density estimation (<xref ref-type="fig" rid="fig3">Figure 3h and j</xref>, <xref ref-type="fig" rid="fig3s2">Figure 3—figure supplement 2d and f</xref>) using sklearn (<xref ref-type="bibr" rid="bib61">Pedregosa, 2011</xref>). We normalized kernel density estimates to correct for the variable density of neurons across the connective. The normalization factor was computed as a kernel density estimate of all annotated neuron locations. The kernel bandwidth was determined using leave-one-out cross-validation. This maximizes the log-likelihood of each sample under the model. Data from all flies were used to determine the bandwidth.</p></sec><sec id="s4-9-3"><title>Principal component analysis</title><p>We performed PCA on DN population data. First, as in <xref ref-type="bibr" rid="bib39">Kato et al., 2015</xref>, we observed that PCs from time derivatives of fluorescence traces produce more organized state space trajectories. Therefore, we calculated the derivative of the <inline-formula><mml:math id="inf99"><mml:mrow><mml:mrow><mml:mi mathvariant="normal">Δ</mml:mi><mml:mo>⁢</mml:mo><mml:mi>F</mml:mi></mml:mrow><mml:mo>/</mml:mo><mml:mi>F</mml:mi></mml:mrow></mml:math></inline-formula> traces for each neuron (extracted from nondenoised imaging data) using total variation regularization (<xref ref-type="bibr" rid="bib18">Chartrand, 2011</xref>). Empirically, we found that a regularization parameter of 5000 strikes a good balance between bias and variance in the derivatives. We then performed PCA on the derivatives of all neural data during walking only. This allowed us to specifically ask whether, during walking, neural activity largely remained constant or diverged as a function of specific locomotor features. We then embedded walking and resting neural data epochs into the same PC space (i.e., we did not refit the PCs for resting). We visualized the loadings of individual ROIs/neurons using vectors to illustrate how these neurons influence the position in PC space. For clarity, we only show vectors for whom <inline-formula><mml:math id="inf100"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msubsup><mml:mi>w</mml:mi><mml:mrow><mml:mi>p</mml:mi><mml:mi>c</mml:mi><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup><mml:mo>+</mml:mo><mml:msubsup><mml:mi>w</mml:mi><mml:mrow><mml:mi>p</mml:mi><mml:mi>c</mml:mi><mml:mn>2</mml:mn></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup><mml:mo>&gt;</mml:mo><mml:mn>0.1</mml:mn></mml:mrow></mml:mstyle></mml:math></inline-formula>, where <inline-formula><mml:math id="inf101"><mml:msub><mml:mi>w</mml:mi><mml:mrow><mml:mi>p</mml:mi><mml:mo>⁢</mml:mo><mml:mi>c</mml:mi><mml:mo>⁢</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:math></inline-formula> and <inline-formula><mml:math id="inf102"><mml:msub><mml:mi>w</mml:mi><mml:mrow><mml:mi>p</mml:mi><mml:mo>⁢</mml:mo><mml:mi>c</mml:mi><mml:mo>⁢</mml:mo><mml:mn>2</mml:mn></mml:mrow></mml:msub></mml:math></inline-formula> are the loadings of the first and second principal components.</p></sec><sec id="s4-9-4"><title>Linear discriminant analysis</title><p>We trained linear discriminant models to distinguish between ACV and humidified air, as well as MSC and humidified air (<xref ref-type="fig" rid="fig4">Figure 4a</xref>). To evaluate classification accuracy, the classification score was cross-validated. Input data to the model were either behavior regressors or neural residuals. The residuals were computed using ridge regression (as described above) with behavior regressors as input. In both cases, the behavior regressors were convolved with the crf.</p></sec><sec id="s4-9-5"><title>Event-triggered averaging</title><p>Here, ‘events’ describe individual epochs of a particular behavior. To perform event-triggered averaging of images/videos (<xref ref-type="video" rid="video2">Videos 2</xref>–<xref ref-type="video" rid="video4">4</xref>), we first identified all events that had no similar event in the previous 1 s. Raw microscope recordings were then chopped into blocks starting <inline-formula><mml:math id="inf103"><mml:mrow><mml:mn>1</mml:mn><mml:mtext/><mml:mi class="ltx_unit" mathvariant="normal">s</mml:mi></mml:mrow></mml:math></inline-formula> prior to event onset and lasting <inline-formula><mml:math id="inf104"><mml:mrow><mml:mn>4</mml:mn><mml:mtext/><mml:mi class="ltx_unit" mathvariant="normal">s</mml:mi></mml:mrow></mml:math></inline-formula> after event onset or until the end of the event, whichever was shorter. Each block was then converted into <inline-formula><mml:math id="inf105"><mml:mrow><mml:mrow><mml:mi mathvariant="normal">Δ</mml:mi><mml:mo>⁢</mml:mo><mml:mi>F</mml:mi></mml:mrow><mml:mo>/</mml:mo><mml:mi>F</mml:mi></mml:mrow></mml:math></inline-formula> using the mean of the first five frames as a baseline. All blocks were then temporally aligned and averaged frame-by-frame. We discarded behavior videos with fewer than 50 events <inline-formula><mml:math id="inf106"><mml:mrow><mml:mn>1</mml:mn><mml:mtext/><mml:mi class="ltx_unit" mathvariant="normal">s</mml:mi></mml:mrow></mml:math></inline-formula> after event onset. Event-triggered averaging of neural traces (<xref ref-type="fig" rid="fig5">Figure 5g and h</xref>) was performed in a similar fashion. However, instead of using raw images, <inline-formula><mml:math id="inf107"><mml:mrow><mml:mrow><mml:mi mathvariant="normal">Δ</mml:mi><mml:mo>⁢</mml:mo><mml:mi>F</mml:mi></mml:mrow><mml:mo>/</mml:mo><mml:mi>F</mml:mi></mml:mrow></mml:math></inline-formula> traces were used and no block-wise <inline-formula><mml:math id="inf108"><mml:mrow><mml:mrow><mml:mi mathvariant="normal">Δ</mml:mi><mml:mo>⁢</mml:mo><mml:mi>F</mml:mi></mml:mrow><mml:mo>/</mml:mo><mml:mi>F</mml:mi></mml:mrow></mml:math></inline-formula> was computed. The values were then averaged one time point at a time.</p></sec><sec id="s4-9-6"><title>Correlation coefficients</title><p>We calculated the Pearson’s correlation coefficient for each trial between the raw <inline-formula><mml:math id="inf109"><mml:mrow><mml:mrow><mml:mi mathvariant="normal">Δ</mml:mi><mml:mo>⁢</mml:mo><mml:mi>F</mml:mi></mml:mrow><mml:mo>/</mml:mo><mml:mi>F</mml:mi></mml:mrow></mml:math></inline-formula> trace and a time-shifted <inline-formula><mml:math id="inf110"><mml:mrow><mml:mrow><mml:mi mathvariant="normal">Δ</mml:mi><mml:mo>⁢</mml:mo><mml:mi>F</mml:mi></mml:mrow><mml:mo>/</mml:mo><mml:mi>F</mml:mi></mml:mrow></mml:math></inline-formula> trace calculated using denoised images (<xref ref-type="fig" rid="fig1s1">Figure 1—figure supplement 1b</xref>). We then either grouped the values by time lag and averaged each group (bottom), or we found the time shift with maximal cross-correlation. In <xref ref-type="fig" rid="fig3">Figure 3d</xref> and <xref ref-type="fig" rid="fig3s2">Figure 3—figure supplement 2b</xref>, we perform several types of correlation analyses. First, the larger matrices show the correlation between neurons. This is computed as the Pearson’s correlation coefficient between the <inline-formula><mml:math id="inf111"><mml:mrow><mml:mrow><mml:mi mathvariant="normal">Δ</mml:mi><mml:mo>⁢</mml:mo><mml:mi>F</mml:mi></mml:mrow><mml:mo>/</mml:mo><mml:mi>F</mml:mi></mml:mrow></mml:math></inline-formula> values of a pair of neurons. Correlations between neural activity and turning or walking speed were calculated as the Pearson’s correlation coefficient between the <inline-formula><mml:math id="inf112"><mml:mrow><mml:mrow><mml:mi mathvariant="normal">Δ</mml:mi><mml:mo>⁢</mml:mo><mml:mi>F</mml:mi></mml:mrow><mml:mo>/</mml:mo><mml:mi>F</mml:mi></mml:mrow></mml:math></inline-formula> values of a neuron and corresponding spherical treadmill rotations using only data when the fly was classified as walking. All of the above calculations were performed on individual trials and then averaged across all trials.</p></sec><sec id="s4-9-7"><title>Hierarchical clustering</title><p>We used Ward’s method (<xref ref-type="bibr" rid="bib83">Ward, 1963</xref>) to hierarchically cluster and sort neurons based on their correlation (<xref ref-type="fig" rid="fig3">Figure 3d</xref>). The distance between pairs of neurons was set to <inline-formula><mml:math id="inf113"><mml:mrow><mml:mn>1</mml:mn><mml:mo>-</mml:mo><mml:mi>r</mml:mi></mml:mrow></mml:math></inline-formula>, where <inline-formula><mml:math id="inf114"><mml:mi>r</mml:mi></mml:math></inline-formula> is the Pearson’s correlation coefficient for the two neurons.</p></sec></sec></sec></body><back><sec sec-type="additional-information" id="s5"><title>Additional information</title><fn-group content-type="competing-interest"><title>Competing interests</title><fn fn-type="COI-statement" id="conf1"><p>No competing interests declared</p></fn></fn-group><fn-group content-type="author-contribution"><title>Author contributions</title><fn fn-type="con" id="con1"><p>Data curation, Software, Formal analysis, Validation, Investigation, Visualization, Methodology, Writing - original draft, Writing - review and editing</p></fn><fn fn-type="con" id="con2"><p>Data curation, Formal analysis, Validation, Investigation, Visualization, Writing - review and editing</p></fn><fn fn-type="con" id="con3"><p>Conceptualization, Resources, Supervision, Funding acquisition, Methodology, Writing - original draft, Project administration, Writing - review and editing</p></fn></fn-group></sec><sec sec-type="supplementary-material" id="s6"><title>Additional files</title><supplementary-material id="mdar"><label>MDAR checklist</label><media xlink:href="elife-81527-mdarchecklist1-v1.pdf" mimetype="application" mime-subtype="pdf"/></supplementary-material></sec><sec sec-type="data-availability" id="s7"><title>Data availability</title><p>Data are available at: <ext-link ext-link-type="uri" xlink:href="https://dataverse.harvard.edu/dataverse/DNs">https://dataverse.harvard.edu/dataverse/DNs</ext-link>. Analysis code is available at: <ext-link ext-link-type="uri" xlink:href="https://github.com/NeLy-EPFL/DN_population_analysis">https://github.com/NeLy-EPFL/DN_population_analysis</ext-link> (copy archived at <ext-link ext-link-type="uri" xlink:href="https://archive.softwareheritage.org/swh:1:dir:33d032994f25ca9d123a8fd6828b3df0bcc2cfe6;origin=https://github.com/NeLy-EPFL/DN_population_analysis;visit=swh:1:snp:d78df23a50263dccb50c686dbe7bdaff200548dd;anchor=swh:1:rev:7c5527dae0d6ff760ddda657d3194cc19ccda3eb">swh:1:rev:7c5527dae0d6ff760ddda657d3194cc19ccda3eb</ext-link>).</p><p>The following datasets were generated:</p><p><element-citation publication-type="data" specific-use="isSupplementedBy" id="dataset1"><person-group person-group-type="author"><name><surname>Aymanns</surname><given-names>F</given-names></name><name><surname>Chen</surname><given-names>C-L</given-names></name><name><surname>Ramdya</surname><given-names>P</given-names></name></person-group><year iso-8601-date="2022">2022</year><data-title>R65D11 two-photon recording data</data-title><source>Harvard Dataverse</source><pub-id pub-id-type="doi">10.7910/DVN/YU1N1A</pub-id></element-citation></p><p><element-citation publication-type="data" specific-use="isSupplementedBy" id="dataset2"><person-group person-group-type="author"><name><surname>Aymanns</surname><given-names>F</given-names></name><name><surname>Chen</surname><given-names>C-L</given-names></name><name><surname>Ramdya</surname><given-names>P</given-names></name></person-group><year iso-8601-date="2022">2022</year><data-title>Brain_only_GAL4_population_data</data-title><source>Harvard Dataverse</source><pub-id pub-id-type="doi">10.7910/DVN/QQMNQK</pub-id></element-citation></p><p><element-citation publication-type="data" specific-use="isSupplementedBy" id="dataset3"><person-group person-group-type="author"><name><surname>Aymanns</surname><given-names>F</given-names></name><name><surname>Chen</surname><given-names>C-L</given-names></name><name><surname>Ramdya</surname><given-names>P</given-names></name></person-group><year iso-8601-date="2022">2022</year><data-title>Confocal images</data-title><source>Harvard Dataverse</source><pub-id pub-id-type="doi">10.7910/DVN/KTQT27</pub-id></element-citation></p></sec><ack id="ack"><title>Acknowledgements</title><p>We thank K Asahina (Salk Institute, San Diego, USA) and B McCabe (EPFL, Lausanne, Switzerland) for transgenic <italic>Drosophila</italic> strains. We thank J Phelps for discussions and assistance with manual annotation of the EM dataset. PR acknowledges support from an SNSF Project Grant (175667) and an SNSF Eccellenza Grant (181239). FA acknowledges support from a Boehringer Ingelheim Fonds PhD stipend.</p></ack><ref-list><title>References</title><ref id="bib1"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ache</surname><given-names>JM</given-names></name><name><surname>Namiki</surname><given-names>S</given-names></name><name><surname>Lee</surname><given-names>A</given-names></name><name><surname>Branson</surname><given-names>K</given-names></name><name><surname>Card</surname><given-names>GM</given-names></name></person-group><year iso-8601-date="2019">2019a</year><article-title>State-dependent decoupling of sensory and motor circuits underlies behavioral flexibility in <italic>Drosophila</italic></article-title><source>Nature Neuroscience</source><volume>22</volume><fpage>1132</fpage><lpage>1139</lpage><pub-id pub-id-type="doi">10.1038/s41593-019-0413-4</pub-id><pub-id pub-id-type="pmid">31182867</pub-id></element-citation></ref><ref id="bib2"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ache</surname><given-names>JM</given-names></name><name><surname>Polsky</surname><given-names>J</given-names></name><name><surname>Alghailani</surname><given-names>S</given-names></name><name><surname>Parekh</surname><given-names>R</given-names></name><name><surname>Breads</surname><given-names>P</given-names></name><name><surname>Peek</surname><given-names>MY</given-names></name><name><surname>Bock</surname><given-names>DD</given-names></name><name><surname>von Reyn</surname><given-names>CR</given-names></name><name><surname>Card</surname><given-names>GM</given-names></name></person-group><year iso-8601-date="2019">2019b</year><article-title>Neural basis for looming size and velocity encoding in the <italic>Drosophila</italic> giant fiber escape pathway</article-title><source>Current Biology</source><volume>29</volume><fpage>1073</fpage><lpage>1081</lpage><pub-id pub-id-type="doi">10.1016/j.cub.2019.01.079</pub-id><pub-id pub-id-type="pmid">30827912</pub-id></element-citation></ref><ref id="bib3"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Aimon</surname><given-names>S</given-names></name><name><surname>Katsuki</surname><given-names>T</given-names></name><name><surname>Jia</surname><given-names>T</given-names></name><name><surname>Grosenick</surname><given-names>L</given-names></name><name><surname>Broxton</surname><given-names>M</given-names></name><name><surname>Deisseroth</surname><given-names>K</given-names></name><name><surname>Sejnowski</surname><given-names>TJ</given-names></name><name><surname>Greenspan</surname><given-names>RJ</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>Fast near-whole-brain imaging in adult <italic>Drosophila</italic> during responses to stimuli and behavior</article-title><source>PLOS Biology</source><volume>17</volume><elocation-id>e2006732</elocation-id><pub-id pub-id-type="doi">10.1371/journal.pbio.2006732</pub-id><pub-id pub-id-type="pmid">30768592</pub-id></element-citation></ref><ref id="bib4"><element-citation publication-type="preprint"><person-group person-group-type="author"><name><surname>Aimon</surname><given-names>S</given-names></name><name><surname>Cheng</surname><given-names>KY</given-names></name><name><surname>Gjorgjieva</surname><given-names>J</given-names></name><name><surname>Kadow</surname><given-names>ICG</given-names></name></person-group><year iso-8601-date="2022">2022</year><article-title>Walking Elicits Global Brain Activity in <italic>Drosophila</italic></article-title><source>bioRxiv</source><pub-id pub-id-type="doi">10.1101/2022.01.17.476660</pub-id></element-citation></ref><ref id="bib5"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Asahina</surname><given-names>K</given-names></name><name><surname>Watanabe</surname><given-names>K</given-names></name><name><surname>Duistermars</surname><given-names>BJ</given-names></name><name><surname>Hoopfer</surname><given-names>E</given-names></name><name><surname>González</surname><given-names>CR</given-names></name><name><surname>Eyjólfsdóttir</surname><given-names>EA</given-names></name><name><surname>Perona</surname><given-names>P</given-names></name><name><surname>Anderson</surname><given-names>DJ</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>Tachykinin-expressing neurons control male-specific aggressive arousal in <italic>Drosophila</italic></article-title><source>Cell</source><volume>156</volume><fpage>221</fpage><lpage>235</lpage><pub-id pub-id-type="doi">10.1016/j.cell.2013.11.045</pub-id><pub-id pub-id-type="pmid">24439378</pub-id></element-citation></ref><ref id="bib6"><element-citation publication-type="software"><person-group person-group-type="author"><name><surname>Aymanns</surname><given-names>F</given-names></name></person-group><year iso-8601-date="2022">2022</year><data-title>Utils_ballrot</data-title><version designator="swh:1:rev:7247f448be62f349bb528ad70633b4b41be5bbaf">swh:1:rev:7247f448be62f349bb528ad70633b4b41be5bbaf</version><source>Software Heritage</source><ext-link ext-link-type="uri" xlink:href="https://archive.softwareheritage.org/swh:1:dir:897af8506da57a666a43a8312ec2c3d4cdc14b1c;origin=https://github.com/NeLy-EPFL/utils_ballrot;visit=swh:1:snp:ff136d6a979bb929ee069de70c742ccababbd08d;anchor=swh:1:rev:7247f448be62f349bb528ad70633b4b41be5bbaf">https://archive.softwareheritage.org/swh:1:dir:897af8506da57a666a43a8312ec2c3d4cdc14b1c;origin=https://github.com/NeLy-EPFL/utils_ballrot;visit=swh:1:snp:ff136d6a979bb929ee069de70c742ccababbd08d;anchor=swh:1:rev:7247f448be62f349bb528ad70633b4b41be5bbaf</ext-link></element-citation></ref><ref id="bib7"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Azevedo</surname><given-names>AW</given-names></name><name><surname>Dickinson</surname><given-names>ES</given-names></name><name><surname>Gurung</surname><given-names>P</given-names></name><name><surname>Venkatasubramanian</surname><given-names>L</given-names></name><name><surname>Mann</surname><given-names>RS</given-names></name><name><surname>Tuthill</surname><given-names>JC</given-names></name></person-group><year iso-8601-date="2020">2020</year><article-title>A size principle for recruitment of <italic>Drosophila</italic> leg motor neurons</article-title><source>eLife</source><volume>9</volume><elocation-id>e56754</elocation-id><pub-id pub-id-type="doi">10.7554/eLife.56754</pub-id></element-citation></ref><ref id="bib8"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bidaye</surname><given-names>SS</given-names></name><name><surname>Machacek</surname><given-names>C</given-names></name><name><surname>Wu</surname><given-names>Y</given-names></name><name><surname>Dickson</surname><given-names>BJ</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>Neuronal control of <italic>Drosophila</italic> walking direction</article-title><source>Science</source><volume>344</volume><fpage>97</fpage><lpage>101</lpage><pub-id pub-id-type="doi">10.1126/science.1249964</pub-id><pub-id pub-id-type="pmid">24700860</pub-id></element-citation></ref><ref id="bib9"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bidaye</surname><given-names>SS</given-names></name><name><surname>Laturney</surname><given-names>M</given-names></name><name><surname>Chang</surname><given-names>AK</given-names></name><name><surname>Liu</surname><given-names>Y</given-names></name><name><surname>Bockemühl</surname><given-names>T</given-names></name><name><surname>Büschges</surname><given-names>A</given-names></name><name><surname>Scott</surname><given-names>K</given-names></name></person-group><year iso-8601-date="2020">2020</year><article-title>Two brain pathways initiate distinct forward walking programs in <italic>Drosophila</italic></article-title><source>Neuron</source><volume>108</volume><fpage>469</fpage><lpage>485</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2020.07.032</pub-id><pub-id pub-id-type="pmid">32822613</pub-id></element-citation></ref><ref id="bib10"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bogovic</surname><given-names>JA</given-names></name><name><surname>Otsuna</surname><given-names>H</given-names></name><name><surname>Heinrich</surname><given-names>L</given-names></name><name><surname>Ito</surname><given-names>M</given-names></name><name><surname>Jeter</surname><given-names>J</given-names></name><name><surname>Meissner</surname><given-names>G</given-names></name><name><surname>Nern</surname><given-names>A</given-names></name><name><surname>Colonell</surname><given-names>J</given-names></name><name><surname>Malkesman</surname><given-names>O</given-names></name><name><surname>Ito</surname><given-names>K</given-names></name><name><surname>Saalfeld</surname><given-names>S</given-names></name></person-group><year iso-8601-date="2020">2020</year><article-title>An unbiased template of the <italic>Drosophila</italic> brain and ventral nerve cord</article-title><source>PLOS ONE</source><volume>15</volume><elocation-id>e0236495</elocation-id><pub-id pub-id-type="doi">10.1371/journal.pone.0236495</pub-id><pub-id pub-id-type="pmid">33382698</pub-id></element-citation></ref><ref id="bib11"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Böhm</surname><given-names>H</given-names></name><name><surname>Schildberger</surname><given-names>K</given-names></name></person-group><year iso-8601-date="1992">1992</year><article-title>Brain neurones involved in the control of walking in the cricket Gryllus bimaculatus</article-title><source>Journal of Experimental Biology</source><volume>166</volume><fpage>113</fpage><lpage>130</lpage><pub-id pub-id-type="doi">10.1242/jeb.166.1.113</pub-id></element-citation></ref><ref id="bib12"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bouvier</surname><given-names>J</given-names></name><name><surname>Caggiano</surname><given-names>V</given-names></name><name><surname>Leiras</surname><given-names>R</given-names></name><name><surname>Caldeira</surname><given-names>V</given-names></name><name><surname>Bellardita</surname><given-names>C</given-names></name><name><surname>Balueva</surname><given-names>K</given-names></name><name><surname>Fuchs</surname><given-names>A</given-names></name><name><surname>Kiehn</surname><given-names>O</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>Descending command neurons in the brainstem that halt locomotion</article-title><source>Cell</source><volume>163</volume><fpage>1191</fpage><lpage>1203</lpage><pub-id pub-id-type="doi">10.1016/j.cell.2015.10.074</pub-id><pub-id pub-id-type="pmid">26590422</pub-id></element-citation></ref><ref id="bib13"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Braitenberg</surname><given-names>V</given-names></name></person-group><year iso-8601-date="1986">1986</year><source>Vehicles: Experiments in Synthetic Psychology</source><publisher-name>MIT press</publisher-name></element-citation></ref><ref id="bib14"><element-citation publication-type="preprint"><person-group person-group-type="author"><name><surname>Brezovec</surname><given-names>LE</given-names></name><name><surname>Berger</surname><given-names>AB</given-names></name><name><surname>Druckmann</surname><given-names>S</given-names></name><name><surname>Clandinin</surname><given-names>TR</given-names></name></person-group><year iso-8601-date="2022">2022</year><article-title>Mapping the Neural Dynamics of Locomotion across the <italic>Drosophila</italic> Brain</article-title><source>bioRxiv</source><pub-id pub-id-type="doi">10.1101/2022.03.20.485047</pub-id></element-citation></ref><ref id="bib15"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Caggiano</surname><given-names>V</given-names></name><name><surname>Leiras</surname><given-names>R</given-names></name><name><surname>Goñi-Erro</surname><given-names>H</given-names></name><name><surname>Masini</surname><given-names>D</given-names></name><name><surname>Bellardita</surname><given-names>C</given-names></name><name><surname>Bouvier</surname><given-names>J</given-names></name><name><surname>Caldeira</surname><given-names>V</given-names></name><name><surname>Fisone</surname><given-names>G</given-names></name><name><surname>Kiehn</surname><given-names>O</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>Midbrain circuits that set locomotor speed and gait selection</article-title><source>Nature</source><volume>553</volume><fpage>455</fpage><lpage>460</lpage><pub-id pub-id-type="doi">10.1038/nature25448</pub-id><pub-id pub-id-type="pmid">29342142</pub-id></element-citation></ref><ref id="bib16"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Cande</surname><given-names>J</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>Optogenetic dissection of descending behavioral control in <italic>Drosophila</italic></article-title><source>eLife</source><volume>7</volume><elocation-id>e34275</elocation-id><pub-id pub-id-type="doi">10.7554/eLife.34275</pub-id></element-citation></ref><ref id="bib17"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Capelli</surname><given-names>P</given-names></name><name><surname>Pivetta</surname><given-names>C</given-names></name><name><surname>Soledad Esposito</surname><given-names>M</given-names></name><name><surname>Arber</surname><given-names>S</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>Locomotor speed control circuits in the caudal brainstem</article-title><source>Nature</source><volume>551</volume><fpage>373</fpage><lpage>377</lpage><pub-id pub-id-type="doi">10.1038/nature24064</pub-id><pub-id pub-id-type="pmid">29059682</pub-id></element-citation></ref><ref id="bib18"><element-citation publication-type="confproc"><person-group person-group-type="author"><name><surname>Chartrand</surname><given-names>R</given-names></name></person-group><year iso-8601-date="2011">2011</year><article-title>Numerical differentiation of noisy, nonsmooth data</article-title><conf-name>International Scholarly Research Notices</conf-name><pub-id pub-id-type="doi">10.5402/2011/164564</pub-id></element-citation></ref><ref id="bib19"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Chen</surname><given-names>T-W</given-names></name><name><surname>Wardill</surname><given-names>TJ</given-names></name><name><surname>Sun</surname><given-names>Y</given-names></name><name><surname>Pulver</surname><given-names>SR</given-names></name><name><surname>Renninger</surname><given-names>SL</given-names></name><name><surname>Baohan</surname><given-names>A</given-names></name><name><surname>Schreiter</surname><given-names>ER</given-names></name><name><surname>Kerr</surname><given-names>RA</given-names></name><name><surname>Orger</surname><given-names>MB</given-names></name><name><surname>Jayaraman</surname><given-names>V</given-names></name><name><surname>Looger</surname><given-names>LL</given-names></name><name><surname>Svoboda</surname><given-names>K</given-names></name><name><surname>Kim</surname><given-names>DS</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>Ultrasensitive fluorescent proteins for imaging neuronal activity</article-title><source>Nature</source><volume>499</volume><fpage>295</fpage><lpage>300</lpage><pub-id pub-id-type="doi">10.1038/nature12354</pub-id><pub-id pub-id-type="pmid">23868258</pub-id></element-citation></ref><ref id="bib20"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Chen</surname><given-names>C-L</given-names></name><name><surname>Hermans</surname><given-names>L</given-names></name><name><surname>Viswanathan</surname><given-names>MC</given-names></name><name><surname>Fortun</surname><given-names>D</given-names></name><name><surname>Aymanns</surname><given-names>F</given-names></name><name><surname>Unser</surname><given-names>M</given-names></name><name><surname>Cammarato</surname><given-names>A</given-names></name><name><surname>Dickinson</surname><given-names>MH</given-names></name><name><surname>Ramdya</surname><given-names>P</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>Imaging neural activity in the ventral nerve cord of behaving adult <italic>Drosophila</italic></article-title><source>Nature Communications</source><volume>9</volume><fpage>1</fpage><lpage>10</lpage><pub-id pub-id-type="doi">10.1038/s41467-018-06857-z</pub-id><pub-id pub-id-type="pmid">30348941</pub-id></element-citation></ref><ref id="bib21"><element-citation publication-type="preprint"><person-group person-group-type="author"><name><surname>Chen</surname><given-names>CL</given-names></name></person-group><year iso-8601-date="2022">2022</year><article-title>Ascending Neurons Convey Behavioral State to Integrative Sensory and Action Selection Centers in the Brain</article-title><source>bioRxiv</source><pub-id pub-id-type="doi">10.1101/2022.02.09.479566</pub-id></element-citation></ref><ref id="bib22"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Cisek</surname><given-names>P</given-names></name><name><surname>Kalaska</surname><given-names>JF</given-names></name></person-group><year iso-8601-date="2010">2010</year><article-title>Neural mechanisms for interacting with a world full of action choices</article-title><source>Annual Review of Neuroscience</source><volume>33</volume><fpage>269</fpage><lpage>298</lpage><pub-id pub-id-type="doi">10.1146/annurev.neuro.051508.135409</pub-id><pub-id pub-id-type="pmid">20345247</pub-id></element-citation></ref><ref id="bib23"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Coen</surname><given-names>P</given-names></name><name><surname>Clemens</surname><given-names>J</given-names></name><name><surname>Weinstein</surname><given-names>AJ</given-names></name><name><surname>Pacheco</surname><given-names>DA</given-names></name><name><surname>Deng</surname><given-names>Y</given-names></name><name><surname>Murthy</surname><given-names>M</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>Dynamic sensory cues shape song structure in <italic>Drosophila</italic></article-title><source>Nature</source><volume>507</volume><fpage>233</fpage><lpage>237</lpage><pub-id pub-id-type="doi">10.1038/nature13131</pub-id><pub-id pub-id-type="pmid">24598544</pub-id></element-citation></ref><ref id="bib24"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Datta</surname><given-names>SR</given-names></name><name><surname>Vasconcelos</surname><given-names>ML</given-names></name><name><surname>Ruta</surname><given-names>V</given-names></name><name><surname>Luo</surname><given-names>S</given-names></name><name><surname>Wong</surname><given-names>A</given-names></name><name><surname>Demir</surname><given-names>E</given-names></name><name><surname>Flores</surname><given-names>J</given-names></name><name><surname>Balonze</surname><given-names>K</given-names></name><name><surname>Dickson</surname><given-names>BJ</given-names></name><name><surname>Axel</surname><given-names>R</given-names></name></person-group><year iso-8601-date="2008">2008</year><article-title>The <italic>Drosophila</italic> pheromone CVA activates a sexually dimorphic neural circuit</article-title><source>Nature</source><volume>452</volume><fpage>473</fpage><lpage>477</lpage><pub-id pub-id-type="doi">10.1038/nature06808</pub-id><pub-id pub-id-type="pmid">18305480</pub-id></element-citation></ref><ref id="bib25"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Fujiwara</surname><given-names>T</given-names></name><name><surname>Brotas</surname><given-names>M</given-names></name><name><surname>Chiappe</surname><given-names>ME</given-names></name></person-group><year iso-8601-date="2022">2022</year><article-title>Walking strides direct rapid and flexible recruitment of visual circuits for course control in <italic>Drosophila</italic></article-title><source>Neuron</source><volume>110</volume><fpage>2124</fpage><lpage>2138</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2022.04.008</pub-id><pub-id pub-id-type="pmid">35525243</pub-id></element-citation></ref><ref id="bib26"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Gray</surname><given-names>JR</given-names></name><name><surname>Blincow</surname><given-names>E</given-names></name><name><surname>Robertson</surname><given-names>RM</given-names></name></person-group><year iso-8601-date="2010">2010</year><article-title>A pair of motion-sensitive neurons in the locust encode approaches of A looming object</article-title><source>Journal of Comparative Physiology</source><volume>196</volume><fpage>927</fpage><lpage>938</lpage><pub-id pub-id-type="doi">10.1007/s00359-010-0576-7</pub-id><pub-id pub-id-type="pmid">20827481</pub-id></element-citation></ref><ref id="bib27"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Günel</surname><given-names>S</given-names></name><name><surname>Rhodin</surname><given-names>H</given-names></name><name><surname>Morales</surname><given-names>D</given-names></name><name><surname>Campagnolo</surname><given-names>J</given-names></name><name><surname>Ramdya</surname><given-names>P</given-names></name><name><surname>Fua</surname><given-names>P</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>DeepFly3D, a deep learning-based approach for 3D limb and appendage tracking in tethered, adult <italic>Drosophila</italic></article-title><source>eLife</source><volume>8</volume><elocation-id>e48571</elocation-id><pub-id pub-id-type="doi">10.7554/eLife.48571</pub-id><pub-id pub-id-type="pmid">31584428</pub-id></element-citation></ref><ref id="bib28"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Guo</surname><given-names>L</given-names></name><name><surname>Zhang</surname><given-names>N</given-names></name><name><surname>Simpson</surname><given-names>JH</given-names></name></person-group><year iso-8601-date="2022">2022</year><article-title>Descending neurons coordinate anterior grooming behavior in <italic>Drosophila</italic></article-title><source>Current Biology</source><volume>32</volume><fpage>823</fpage><lpage>833</lpage><pub-id pub-id-type="doi">10.1016/j.cub.2021.12.055</pub-id><pub-id pub-id-type="pmid">35120659</pub-id></element-citation></ref><ref id="bib29"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hampel</surname><given-names>S</given-names></name><name><surname>Franconville</surname><given-names>R</given-names></name><name><surname>Simpson</surname><given-names>JH</given-names></name><name><surname>Seeds</surname><given-names>AM</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>A neural command circuit for grooming movement control</article-title><source>eLife</source><volume>4</volume><elocation-id>e08758</elocation-id><pub-id pub-id-type="doi">10.7554/eLife.08758</pub-id><pub-id pub-id-type="pmid">26344548</pub-id></element-citation></ref><ref id="bib30"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Harris</surname><given-names>RM</given-names></name><name><surname>Pfeiffer</surname><given-names>BD</given-names></name><name><surname>Rubin</surname><given-names>GM</given-names></name><name><surname>Truman</surname><given-names>JW</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>Neuron hemilineages provide the functional ground plan for the <italic>Drosophila</italic> ventral nervous system</article-title><source>eLife</source><volume>4</volume><elocation-id>e04493</elocation-id><pub-id pub-id-type="doi">10.7554/eLife.04493</pub-id></element-citation></ref><ref id="bib31"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Heinrich</surname><given-names>R</given-names></name></person-group><year iso-8601-date="2002">2002</year><article-title>Impact of descending brain neurons on the control of stridulation, walking, and flight in Orthoptera</article-title><source>Microscopy Research and Technique</source><volume>56</volume><fpage>292</fpage><lpage>301</lpage><pub-id pub-id-type="doi">10.1002/jemt.10033</pub-id><pub-id pub-id-type="pmid">11877804</pub-id></element-citation></ref><ref id="bib32"><element-citation publication-type="preprint"><person-group person-group-type="author"><name><surname>Hermans</surname><given-names>L</given-names></name><name><surname>Kaynak</surname><given-names>M</given-names></name><name><surname>Braun</surname><given-names>J</given-names></name><name><surname>Lobato Ríos</surname><given-names>V</given-names></name><name><surname>Chen</surname><given-names>CL</given-names></name><name><surname>Günel</surname><given-names>S</given-names></name><name><surname>Aymanns</surname><given-names>F</given-names></name><name><surname>Sakar</surname><given-names>MS</given-names></name><name><surname>Ramdya</surname><given-names>P</given-names></name></person-group><year iso-8601-date="2021">2021</year><article-title>Long-Term Imaging of the Ventral Nerve Cord in Behaving Adult <italic>Drosophila</italic></article-title><source>bioRxiv</source><pub-id pub-id-type="doi">10.1101/2021.10.15.463778</pub-id></element-citation></ref><ref id="bib33"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hsu</surname><given-names>CT</given-names></name><name><surname>Bhandawat</surname><given-names>V</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Organization of descending neurons in <italic>Drosophila melanogaster</italic></article-title><source>Scientific Reports</source><volume>6</volume><elocation-id>20259</elocation-id><pub-id pub-id-type="doi">10.1038/srep20259</pub-id><pub-id pub-id-type="pmid">26837716</pub-id></element-citation></ref><ref id="bib34"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Israel</surname><given-names>S</given-names></name><name><surname>Rozenfeld</surname><given-names>E</given-names></name><name><surname>Weber</surname><given-names>D</given-names></name><name><surname>Huetteroth</surname><given-names>W</given-names></name><name><surname>Parnas</surname><given-names>M</given-names></name></person-group><year iso-8601-date="2022">2022</year><article-title>Olfactory stimuli and Moonwalker sez neurons can drive backward locomotion in <italic>Drosophila</italic></article-title><source>Current Biology</source><volume>32</volume><fpage>1131</fpage><lpage>1149</lpage><pub-id pub-id-type="doi">10.1016/j.cub.2022.01.035</pub-id></element-citation></ref><ref id="bib35"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Jaske</surname><given-names>B</given-names></name><name><surname>Lepreux</surname><given-names>G</given-names></name><name><surname>Dürr</surname><given-names>V</given-names></name></person-group><year iso-8601-date="2021">2021</year><article-title>Input of hair field afferents to a descending interneuron</article-title><source>Journal of Neurophysiology</source><volume>126</volume><fpage>398</fpage><lpage>412</lpage><pub-id pub-id-type="doi">10.1152/jn.00169.2021</pub-id><pub-id pub-id-type="pmid">34161139</pub-id></element-citation></ref><ref id="bib36"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Jefferis</surname><given-names>GSXE</given-names></name><name><surname>Potter</surname><given-names>CJ</given-names></name><name><surname>Chan</surname><given-names>AM</given-names></name><name><surname>Marin</surname><given-names>EC</given-names></name><name><surname>Rohlfing</surname><given-names>T</given-names></name><name><surname>Maurer</surname><given-names>CR</given-names></name><name><surname>Luo</surname><given-names>L</given-names></name></person-group><year iso-8601-date="2007">2007</year><article-title>Comprehensive maps of <italic>Drosophila</italic> higher olfactory centers: spatially segregated fruit and pheromone representation</article-title><source>Cell</source><volume>128</volume><fpage>1187</fpage><lpage>1203</lpage><pub-id pub-id-type="doi">10.1016/j.cell.2007.01.040</pub-id><pub-id pub-id-type="pmid">17382886</pub-id></element-citation></ref><ref id="bib37"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Jenett</surname><given-names>A</given-names></name><name><surname>Rubin</surname><given-names>GM</given-names></name><name><surname>Ngo</surname><given-names>T-TB</given-names></name><name><surname>Shepherd</surname><given-names>D</given-names></name><name><surname>Murphy</surname><given-names>C</given-names></name><name><surname>Dionne</surname><given-names>H</given-names></name><name><surname>Pfeiffer</surname><given-names>BD</given-names></name><name><surname>Cavallaro</surname><given-names>A</given-names></name><name><surname>Hall</surname><given-names>D</given-names></name><name><surname>Jeter</surname><given-names>J</given-names></name><name><surname>Iyer</surname><given-names>N</given-names></name><name><surname>Fetter</surname><given-names>D</given-names></name><name><surname>Hausenfluck</surname><given-names>JH</given-names></name><name><surname>Peng</surname><given-names>H</given-names></name><name><surname>Trautman</surname><given-names>ET</given-names></name><name><surname>Svirskas</surname><given-names>RR</given-names></name><name><surname>Myers</surname><given-names>EW</given-names></name><name><surname>Iwinski</surname><given-names>ZR</given-names></name><name><surname>Aso</surname><given-names>Y</given-names></name><name><surname>DePasquale</surname><given-names>GM</given-names></name><name><surname>Enos</surname><given-names>A</given-names></name><name><surname>Hulamm</surname><given-names>P</given-names></name><name><surname>Lam</surname><given-names>SCB</given-names></name><name><surname>Li</surname><given-names>H-H</given-names></name><name><surname>Laverty</surname><given-names>TR</given-names></name><name><surname>Long</surname><given-names>F</given-names></name><name><surname>Qu</surname><given-names>L</given-names></name><name><surname>Murphy</surname><given-names>SD</given-names></name><name><surname>Rokicki</surname><given-names>K</given-names></name><name><surname>Safford</surname><given-names>T</given-names></name><name><surname>Shaw</surname><given-names>K</given-names></name><name><surname>Simpson</surname><given-names>JH</given-names></name><name><surname>Sowell</surname><given-names>A</given-names></name><name><surname>Tae</surname><given-names>S</given-names></name><name><surname>Yu</surname><given-names>Y</given-names></name><name><surname>Zugates</surname><given-names>CT</given-names></name></person-group><year iso-8601-date="2012">2012</year><article-title>A gal4-driver line resource for <italic>Drosophila</italic> neurobiology</article-title><source>Cell Reports</source><volume>2</volume><fpage>991</fpage><lpage>1001</lpage><pub-id pub-id-type="doi">10.1016/j.celrep.2012.09.011</pub-id><pub-id pub-id-type="pmid">23063364</pub-id></element-citation></ref><ref id="bib38"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Jiao</surname><given-names>W</given-names></name><name><surname>Spreemann</surname><given-names>G</given-names></name><name><surname>Ruchti</surname><given-names>E</given-names></name><name><surname>Banerjee</surname><given-names>S</given-names></name><name><surname>Vernon</surname><given-names>S</given-names></name><name><surname>Shi</surname><given-names>Y</given-names></name><name><surname>Stowers</surname><given-names>RS</given-names></name><name><surname>Hess</surname><given-names>K</given-names></name><name><surname>McCabe</surname><given-names>BD</given-names></name></person-group><year iso-8601-date="2022">2022</year><article-title>Intact <italic>Drosophila</italic> central nervous system cellular quantitation reveals sexual dimorphism</article-title><source>eLife</source><volume>11</volume><elocation-id>e74968</elocation-id><pub-id pub-id-type="doi">10.7554/eLife.74968</pub-id><pub-id pub-id-type="pmid">35801638</pub-id></element-citation></ref><ref id="bib39"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kato</surname><given-names>S</given-names></name><name><surname>Kaplan</surname><given-names>HS</given-names></name><name><surname>Schrödel</surname><given-names>T</given-names></name><name><surname>Skora</surname><given-names>S</given-names></name><name><surname>Lindsay</surname><given-names>TH</given-names></name><name><surname>Yemini</surname><given-names>E</given-names></name><name><surname>Lockery</surname><given-names>S</given-names></name><name><surname>Zimmer</surname><given-names>M</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>Global brain dynamics embed the motor command sequence of <italic>Caenorhabditis elegans</italic></article-title><source>Cell</source><volume>163</volume><fpage>656</fpage><lpage>669</lpage><pub-id pub-id-type="doi">10.1016/j.cell.2015.09.034</pub-id><pub-id pub-id-type="pmid">26478179</pub-id></element-citation></ref><ref id="bib40"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kien</surname><given-names>J</given-names></name></person-group><year iso-8601-date="1990">1990</year><article-title>Neuronal activity during spontaneous walking -- I. starting and stopping</article-title><source>Comparative Biochemistry and Physiology. A, Comparative Physiology</source><volume>95</volume><fpage>607</fpage><lpage>621</lpage><pub-id pub-id-type="doi">10.1016/0300-9629(90)90747-g</pub-id><pub-id pub-id-type="pmid">1971547</pub-id></element-citation></ref><ref id="bib41"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>King</surname><given-names>DG</given-names></name><name><surname>Wyman</surname><given-names>RJ</given-names></name></person-group><year iso-8601-date="1980">1980</year><article-title>Anatomy of the giant fibre pathway in <italic>Drosophila</italic>. I. three thoracic components of the pathway</article-title><source>Journal of Neurocytology</source><volume>9</volume><fpage>753</fpage><lpage>770</lpage><pub-id pub-id-type="doi">10.1007/BF01205017</pub-id><pub-id pub-id-type="pmid">6782199</pub-id></element-citation></ref><ref id="bib42"><element-citation publication-type="confproc"><person-group person-group-type="author"><name><surname>Krull</surname><given-names>A</given-names></name><name><surname>Buchholz</surname><given-names>TO</given-names></name><name><surname>Jug</surname><given-names>F</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>Noise2Void - Learning Denoising From Single Noisy Images</article-title><conf-name>2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR</conf-name><fpage>2129</fpage><lpage>2137</lpage><pub-id pub-id-type="doi">10.1109/CVPR.2019.00223</pub-id></element-citation></ref><ref id="bib43"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kupfermann</surname><given-names>I</given-names></name><name><surname>Weiss</surname><given-names>KR</given-names></name></person-group><year iso-8601-date="1978">1978</year><article-title>The command neuron concept</article-title><source>Behavioral and Brain Sciences</source><volume>1</volume><fpage>3</fpage><lpage>10</lpage><pub-id pub-id-type="doi">10.1017/S0140525X00059057</pub-id></element-citation></ref><ref id="bib44"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Lecoq</surname><given-names>J</given-names></name><name><surname>Oliver</surname><given-names>M</given-names></name><name><surname>Siegle</surname><given-names>JH</given-names></name><name><surname>Orlova</surname><given-names>N</given-names></name><name><surname>Ledochowitsch</surname><given-names>P</given-names></name><name><surname>Koch</surname><given-names>C</given-names></name></person-group><year iso-8601-date="2021">2021</year><article-title>Removing independent noise in systems neuroscience data using deepinterpolation</article-title><source>Nature Methods</source><volume>18</volume><fpage>1401</fpage><lpage>1408</lpage><pub-id pub-id-type="doi">10.1038/s41592-021-01285-2</pub-id><pub-id pub-id-type="pmid">34650233</pub-id></element-citation></ref><ref id="bib45"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Lima</surname><given-names>SQ</given-names></name><name><surname>Miesenböck</surname><given-names>G</given-names></name></person-group><year iso-8601-date="2005">2005</year><article-title>Remote control of behavior through genetically targeted photostimulation of neurons</article-title><source>Cell</source><volume>121</volume><fpage>141</fpage><lpage>152</lpage><pub-id pub-id-type="doi">10.1016/j.cell.2005.02.004</pub-id><pub-id pub-id-type="pmid">15820685</pub-id></element-citation></ref><ref id="bib46"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Lobato-Rios</surname><given-names>V</given-names></name><name><surname>Ramalingasetty</surname><given-names>ST</given-names></name><name><surname>Özdil</surname><given-names>PG</given-names></name><name><surname>Arreguit</surname><given-names>J</given-names></name><name><surname>Ijspeert</surname><given-names>AJ</given-names></name><name><surname>Ramdya</surname><given-names>P</given-names></name></person-group><year iso-8601-date="2022">2022</year><article-title>NeuroMechFly, a neuromechanical model of adult <italic>Drosophila melanogaster</italic></article-title><source>Nature Methods</source><volume>19</volume><fpage>620</fpage><lpage>627</lpage><pub-id pub-id-type="doi">10.1038/s41592-022-01466-7</pub-id><pub-id pub-id-type="pmid">35545713</pub-id></element-citation></ref><ref id="bib47"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Mann</surname><given-names>K</given-names></name><name><surname>Gordon</surname><given-names>MD</given-names></name><name><surname>Scott</surname><given-names>K</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>A pair of interneurons influences the choice between feeding and locomotion in <italic>Drosophila</italic></article-title><source>Neuron</source><volume>79</volume><fpage>754</fpage><lpage>765</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2013.06.018</pub-id><pub-id pub-id-type="pmid">23972600</pub-id></element-citation></ref><ref id="bib48"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Mann</surname><given-names>K</given-names></name><name><surname>Gallen</surname><given-names>CL</given-names></name><name><surname>Clandinin</surname><given-names>TR</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>Whole-Brain calcium imaging reveals an intrinsic functional network in <italic>Drosophila</italic></article-title><source>Current Biology</source><volume>27</volume><fpage>2389</fpage><lpage>2396</lpage><pub-id pub-id-type="doi">10.1016/j.cub.2017.06.076</pub-id><pub-id pub-id-type="pmid">28756955</pub-id></element-citation></ref><ref id="bib49"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Mendes</surname><given-names>CS</given-names></name><name><surname>Bartos</surname><given-names>I</given-names></name><name><surname>Akay</surname><given-names>T</given-names></name><name><surname>Márka</surname><given-names>S</given-names></name><name><surname>Mann</surname><given-names>RS</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>Quantification of gait parameters in freely walking wild type and sensory deprived <italic>Drosophila melanogaster</italic></article-title><source>eLife</source><volume>2</volume><elocation-id>e00231</elocation-id><pub-id pub-id-type="doi">10.7554/eLife.00231</pub-id></element-citation></ref><ref id="bib50"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Mohamed</surname><given-names>AAM</given-names></name><name><surname>Retzke</surname><given-names>T</given-names></name><name><surname>Das Chakraborty</surname><given-names>S</given-names></name><name><surname>Fabian</surname><given-names>B</given-names></name><name><surname>Hansson</surname><given-names>BS</given-names></name><name><surname>Knaden</surname><given-names>M</given-names></name><name><surname>Sachse</surname><given-names>S</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>Odor mixtures of opposing valence unveil inter-glomerular crosstalk in the <italic>Drosophila</italic> antennal lobe</article-title><source>Nature Communications</source><volume>10</volume><fpage>1</fpage><lpage>17</lpage><pub-id pub-id-type="doi">10.1038/s41467-019-09069-1</pub-id><pub-id pub-id-type="pmid">30867415</pub-id></element-citation></ref><ref id="bib51"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Moore</surname><given-names>RJD</given-names></name><name><surname>Taylor</surname><given-names>GJ</given-names></name><name><surname>Paulk</surname><given-names>AC</given-names></name><name><surname>Pearson</surname><given-names>T</given-names></name><name><surname>van Swinderen</surname><given-names>B</given-names></name><name><surname>Srinivasan</surname><given-names>MV</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>FicTrac: a visual method for tracking spherical motion and generating fictive animal paths</article-title><source>Journal of Neuroscience Methods</source><volume>225</volume><fpage>106</fpage><lpage>119</lpage><pub-id pub-id-type="doi">10.1016/j.jneumeth.2014.01.010</pub-id><pub-id pub-id-type="pmid">24491637</pub-id></element-citation></ref><ref id="bib52"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Musall</surname><given-names>S</given-names></name><name><surname>Kaufman</surname><given-names>MT</given-names></name><name><surname>Juavinett</surname><given-names>AL</given-names></name><name><surname>Gluf</surname><given-names>S</given-names></name><name><surname>Churchland</surname><given-names>AK</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>Single-trial neural dynamics are dominated by richly varied movements</article-title><source>Nature Neuroscience</source><volume>22</volume><fpage>1677</fpage><lpage>1686</lpage><pub-id pub-id-type="doi">10.1038/s41593-019-0502-4</pub-id><pub-id pub-id-type="pmid">31551604</pub-id></element-citation></ref><ref id="bib53"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Namiki</surname><given-names>S</given-names></name><name><surname>Dickinson</surname><given-names>MH</given-names></name><name><surname>Wong</surname><given-names>AM</given-names></name><name><surname>Korff</surname><given-names>W</given-names></name><name><surname>Card</surname><given-names>GM</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>The functional organization of descending sensory-motor pathways in <italic>Drosophila</italic></article-title><source>eLife</source><volume>7</volume><elocation-id>e34272</elocation-id><pub-id pub-id-type="doi">10.7554/eLife.34272</pub-id><pub-id pub-id-type="pmid">29943730</pub-id></element-citation></ref><ref id="bib54"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Namiki</surname><given-names>S</given-names></name><name><surname>Ros</surname><given-names>IG</given-names></name><name><surname>Morrow</surname><given-names>C</given-names></name><name><surname>Rowell</surname><given-names>WJ</given-names></name><name><surname>Card</surname><given-names>GM</given-names></name><name><surname>Korff</surname><given-names>W</given-names></name><name><surname>Dickinson</surname><given-names>MH</given-names></name></person-group><year iso-8601-date="2022">2022</year><article-title>A population of descending neurons that regulates the flight motor of <italic>Drosophila</italic></article-title><source>Current Biology</source><volume>32</volume><fpage>1189</fpage><lpage>1196</lpage><pub-id pub-id-type="doi">10.1016/j.cub.2022.01.008</pub-id></element-citation></ref><ref id="bib55"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Nässel</surname><given-names>DR</given-names></name><name><surname>Högmo</surname><given-names>O</given-names></name><name><surname>Hallberg</surname><given-names>E</given-names></name></person-group><year iso-8601-date="1984">1984</year><article-title>Antennal receptors in the blowfly Calliphora erythrocephala. I. the gigantic central projection of the pedicellar campaniform sensillum</article-title><source>Journal of Morphology</source><volume>180</volume><fpage>159</fpage><lpage>169</lpage><pub-id pub-id-type="doi">10.1002/jmor.1051800206</pub-id><pub-id pub-id-type="pmid">30016846</pub-id></element-citation></ref><ref id="bib56"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Nern</surname><given-names>A</given-names></name><name><surname>Pfeiffer</surname><given-names>BD</given-names></name><name><surname>Rubin</surname><given-names>GM</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>Optimized tools for multicolor stochastic labeling reveal diverse stereotyped cell arrangements in the fly visual system</article-title><source>PNAS</source><volume>112</volume><fpage>E2967</fpage><lpage>E2976</lpage><pub-id pub-id-type="doi">10.1073/pnas.1506763112</pub-id></element-citation></ref><ref id="bib57"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Nicholas</surname><given-names>S</given-names></name><name><surname>Supple</surname><given-names>J</given-names></name><name><surname>Leibbrandt</surname><given-names>R</given-names></name><name><surname>Gonzalez-Bellido</surname><given-names>PT</given-names></name><name><surname>Nordström</surname><given-names>K</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>Integration of small- and wide-field visual features in target-selective descending neurons of both predatory and nonpredatory dipterans</article-title><source>The Journal of Neuroscience</source><volume>38</volume><fpage>10725</fpage><lpage>10733</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.1695-18.2018</pub-id><pub-id pub-id-type="pmid">30373766</pub-id></element-citation></ref><ref id="bib58"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Olsen</surname><given-names>SR</given-names></name><name><surname>Wilson</surname><given-names>RI</given-names></name></person-group><year iso-8601-date="2008">2008</year><article-title>Cracking neural circuits in a tiny brain: new approaches for understanding the neural circuitry of <italic>Drosophila</italic></article-title><source>Trends in Neurosciences</source><volume>31</volume><fpage>512</fpage><lpage>520</lpage><pub-id pub-id-type="doi">10.1016/j.tins.2008.07.006</pub-id><pub-id pub-id-type="pmid">18775572</pub-id></element-citation></ref><ref id="bib59"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Orger</surname><given-names>MB</given-names></name><name><surname>Kampff</surname><given-names>AR</given-names></name><name><surname>Severi</surname><given-names>KE</given-names></name><name><surname>Bollmann</surname><given-names>JH</given-names></name><name><surname>Engert</surname><given-names>F</given-names></name></person-group><year iso-8601-date="2008">2008</year><article-title>Control of visually guided behavior by distinct populations of spinal projection neurons</article-title><source>Nature Neuroscience</source><volume>11</volume><fpage>327</fpage><lpage>333</lpage><pub-id pub-id-type="doi">10.1038/nn2048</pub-id><pub-id pub-id-type="pmid">18264094</pub-id></element-citation></ref><ref id="bib60"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Pavlou</surname><given-names>HJ</given-names></name><name><surname>Goodwin</surname><given-names>SF</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>Courtship behavior in <italic>Drosophila melanogaster</italic>: towards a “courtship connectome.”</article-title><source>Current Opinion in Neurobiology</source><volume>23</volume><fpage>76</fpage><lpage>83</lpage><pub-id pub-id-type="doi">10.1016/j.conb.2012.09.002</pub-id><pub-id pub-id-type="pmid">23021897</pub-id></element-citation></ref><ref id="bib61"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Pedregosa</surname><given-names>F</given-names></name></person-group><year iso-8601-date="2011">2011</year><article-title>Scikit-learn: machine learning in python</article-title><source>Journal of Machine Learning Research</source><volume>12</volume><fpage>2825</fpage><lpage>2830</lpage></element-citation></ref><ref id="bib62"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Phelps</surname><given-names>JS</given-names></name><name><surname>Hildebrand</surname><given-names>DGC</given-names></name><name><surname>Graham</surname><given-names>BJ</given-names></name><name><surname>Kuan</surname><given-names>AT</given-names></name><name><surname>Thomas</surname><given-names>LA</given-names></name><name><surname>Nguyen</surname><given-names>TM</given-names></name><name><surname>Buhmann</surname><given-names>J</given-names></name><name><surname>Azevedo</surname><given-names>AW</given-names></name><name><surname>Sustar</surname><given-names>A</given-names></name><name><surname>Agrawal</surname><given-names>S</given-names></name><name><surname>Liu</surname><given-names>M</given-names></name><name><surname>Shanny</surname><given-names>BL</given-names></name><name><surname>Funke</surname><given-names>J</given-names></name><name><surname>Tuthill</surname><given-names>JC</given-names></name><name><surname>Lee</surname><given-names>W-CA</given-names></name></person-group><year iso-8601-date="2021">2021</year><article-title>Reconstruction of motor control circuits in adult <italic>Drosophila</italic> using automated transmission electron microscopy</article-title><source>Cell</source><volume>184</volume><fpage>759</fpage><lpage>774</lpage><pub-id pub-id-type="doi">10.1016/j.cell.2020.12.013</pub-id><pub-id pub-id-type="pmid">33400916</pub-id></element-citation></ref><ref id="bib63"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Piatkevich</surname><given-names>KD</given-names></name><name><surname>Jung</surname><given-names>EE</given-names></name><name><surname>Straub</surname><given-names>C</given-names></name><name><surname>Linghu</surname><given-names>C</given-names></name><name><surname>Park</surname><given-names>D</given-names></name><name><surname>Suk</surname><given-names>H-J</given-names></name><name><surname>Hochbaum</surname><given-names>DR</given-names></name><name><surname>Goodwin</surname><given-names>D</given-names></name><name><surname>Pnevmatikakis</surname><given-names>E</given-names></name><name><surname>Pak</surname><given-names>N</given-names></name><name><surname>Kawashima</surname><given-names>T</given-names></name><name><surname>Yang</surname><given-names>C-T</given-names></name><name><surname>Rhoades</surname><given-names>JL</given-names></name><name><surname>Shemesh</surname><given-names>O</given-names></name><name><surname>Asano</surname><given-names>S</given-names></name><name><surname>Yoon</surname><given-names>Y-G</given-names></name><name><surname>Freifeld</surname><given-names>L</given-names></name><name><surname>Saulnier</surname><given-names>JL</given-names></name><name><surname>Riegler</surname><given-names>C</given-names></name><name><surname>Engert</surname><given-names>F</given-names></name><name><surname>Hughes</surname><given-names>T</given-names></name><name><surname>Drobizhev</surname><given-names>M</given-names></name><name><surname>Szabo</surname><given-names>B</given-names></name><name><surname>Ahrens</surname><given-names>MB</given-names></name><name><surname>Flavell</surname><given-names>SW</given-names></name><name><surname>Sabatini</surname><given-names>BL</given-names></name><name><surname>Boyden</surname><given-names>ES</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>A robotic multidimensional directed evolution approach applied to fluorescent voltage reporters</article-title><source>Nature Chemical Biology</source><volume>14</volume><fpage>352</fpage><lpage>360</lpage><pub-id pub-id-type="doi">10.1038/s41589-018-0004-9</pub-id><pub-id pub-id-type="pmid">29483642</pub-id></element-citation></ref><ref id="bib64"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ravbar</surname><given-names>P</given-names></name><name><surname>Zhang</surname><given-names>N</given-names></name><name><surname>Simpson</surname><given-names>JH</given-names></name></person-group><year iso-8601-date="2021">2021</year><article-title>Behavioral evidence for nested central pattern generator control of <italic>Drosophila</italic> grooming</article-title><source>eLife</source><volume>10</volume><elocation-id>e71508</elocation-id><pub-id pub-id-type="doi">10.7554/eLife.71508</pub-id></element-citation></ref><ref id="bib65"><element-citation publication-type="preprint"><person-group person-group-type="author"><name><surname>Rayshubskiy</surname><given-names>A</given-names></name></person-group><year iso-8601-date="2020">2020</year><article-title>Neural Circuit Mechanisms for Steering Control in Walking <italic>Drosophila</italic></article-title><source>bioRxiv</source><pub-id pub-id-type="doi">10.1101/2020.04.04.024703</pub-id></element-citation></ref><ref id="bib66"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ruta</surname><given-names>V</given-names></name><name><surname>Datta</surname><given-names>SR</given-names></name><name><surname>Vasconcelos</surname><given-names>ML</given-names></name><name><surname>Freeland</surname><given-names>J</given-names></name><name><surname>Looger</surname><given-names>LL</given-names></name><name><surname>Axel</surname><given-names>R</given-names></name></person-group><year iso-8601-date="2010">2010</year><article-title>A dimorphic pheromone circuit in <italic>Drosophila</italic> from sensory input to descending output</article-title><source>Nature</source><volume>468</volume><fpage>686</fpage><lpage>690</lpage><pub-id pub-id-type="doi">10.1038/nature09554</pub-id><pub-id pub-id-type="pmid">21124455</pub-id></element-citation></ref><ref id="bib67"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Saalfeld</surname><given-names>S</given-names></name><name><surname>Cardona</surname><given-names>A</given-names></name><name><surname>Hartenstein</surname><given-names>V</given-names></name><name><surname>Tomancak</surname><given-names>P</given-names></name></person-group><year iso-8601-date="2009">2009</year><article-title>CATMAID: collaborative annotation toolkit for massive amounts of image data</article-title><source>Bioinformatics</source><volume>25</volume><fpage>1984</fpage><lpage>1986</lpage><pub-id pub-id-type="doi">10.1093/bioinformatics/btp266</pub-id><pub-id pub-id-type="pmid">19376822</pub-id></element-citation></ref><ref id="bib68"><element-citation publication-type="preprint"><person-group person-group-type="author"><name><surname>Schaffer</surname><given-names>ES</given-names></name><name><surname>Mishra</surname><given-names>N</given-names></name><name><surname>Whiteway</surname><given-names>MR</given-names></name><name><surname>Li</surname><given-names>W</given-names></name><name><surname>Vancura</surname><given-names>MB</given-names></name><name><surname>Freedman</surname><given-names>J</given-names></name><name><surname>Patel</surname><given-names>KB</given-names></name><name><surname>Voleti</surname><given-names>V</given-names></name><name><surname>Paninski</surname><given-names>L</given-names></name><name><surname>Hillman</surname><given-names>EMC</given-names></name><name><surname>Abbott</surname><given-names>LF</given-names></name><name><surname>Axel</surname><given-names>R</given-names></name></person-group><year iso-8601-date="2021">2021</year><article-title>Flygenvectors: The Spatial and Temporal Structure of Neural Activity across the Fly Brain</article-title><source>bioRxiv</source><pub-id pub-id-type="doi">10.1101/2021.09.25.461804</pub-id></element-citation></ref><ref id="bib69"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Schneider-Mizell</surname><given-names>CM</given-names></name><name><surname>Gerhard</surname><given-names>S</given-names></name><name><surname>Longair</surname><given-names>M</given-names></name><name><surname>Kazimiers</surname><given-names>T</given-names></name><name><surname>Li</surname><given-names>F</given-names></name><name><surname>Zwart</surname><given-names>MF</given-names></name><name><surname>Champion</surname><given-names>A</given-names></name><name><surname>Midgley</surname><given-names>FM</given-names></name><name><surname>Fetter</surname><given-names>RD</given-names></name><name><surname>Saalfeld</surname><given-names>S</given-names></name><name><surname>Cardona</surname><given-names>A</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Quantitative neuroanatomy for connectomics in <italic>Drosophila</italic></article-title><source>eLife</source><volume>5</volume><elocation-id>e12059</elocation-id><pub-id pub-id-type="doi">10.7554/eLife.12059</pub-id><pub-id pub-id-type="pmid">26990779</pub-id></element-citation></ref><ref id="bib70"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Schnell</surname><given-names>B</given-names></name><name><surname>Ros</surname><given-names>IG</given-names></name><name><surname>Dickinson</surname><given-names>MH</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>A descending neuron correlated with the rapid steering maneuvers of flying <italic>Drosophila</italic></article-title><source>Current Biology</source><volume>27</volume><fpage>1200</fpage><lpage>1205</lpage><pub-id pub-id-type="doi">10.1016/j.cub.2017.03.004</pub-id><pub-id pub-id-type="pmid">28392112</pub-id></element-citation></ref><ref id="bib71"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Seeds</surname><given-names>AM</given-names></name><name><surname>Ravbar</surname><given-names>P</given-names></name><name><surname>Chung</surname><given-names>P</given-names></name><name><surname>Hampel</surname><given-names>S</given-names></name><name><surname>Midgley</surname><given-names>FM</given-names><suffix>Jr</suffix></name><name><surname>Mensh</surname><given-names>BD</given-names></name><name><surname>Simpson</surname><given-names>JH</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>A suppression hierarchy among competing motor programs drives sequential grooming in <italic>Drosophila</italic></article-title><source>eLife</source><volume>3</volume><elocation-id>e02951</elocation-id><pub-id pub-id-type="doi">10.7554/eLife.02951</pub-id><pub-id pub-id-type="pmid">25139955</pub-id></element-citation></ref><ref id="bib72"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Semmelhack</surname><given-names>JL</given-names></name><name><surname>Wang</surname><given-names>JW</given-names></name></person-group><year iso-8601-date="2009">2009</year><article-title>Select <italic>Drosophila</italic> glomeruli mediate innate olfactory attraction and aversion</article-title><source>Nature</source><volume>459</volume><fpage>218</fpage><lpage>223</lpage><pub-id pub-id-type="doi">10.1038/nature07983</pub-id><pub-id pub-id-type="pmid">19396157</pub-id></element-citation></ref><ref id="bib73"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Sen</surname><given-names>R</given-names></name><name><surname>Wu</surname><given-names>M</given-names></name><name><surname>Branson</surname><given-names>K</given-names></name><name><surname>Robie</surname><given-names>A</given-names></name><name><surname>Rubin</surname><given-names>GM</given-names></name><name><surname>Dickson</surname><given-names>BJ</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>Moonwalker descending neurons mediate visually evoked retreat in <italic>Drosophila</italic></article-title><source>Current Biology</source><volume>27</volume><fpage>766</fpage><lpage>771</lpage><pub-id pub-id-type="doi">10.1016/j.cub.2017.02.008</pub-id><pub-id pub-id-type="pmid">28238656</pub-id></element-citation></ref><ref id="bib74"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Simpson</surname><given-names>JH</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Rationally subdividing the fly nervous system with versatile expression reagents</article-title><source>Journal of Neurogenetics</source><volume>30</volume><fpage>185</fpage><lpage>194</lpage><pub-id pub-id-type="doi">10.1080/01677063.2016.1248761</pub-id><pub-id pub-id-type="pmid">27846759</pub-id></element-citation></ref><ref id="bib75"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Sterne</surname><given-names>GR</given-names></name><name><surname>Otsuna</surname><given-names>H</given-names></name><name><surname>Dickson</surname><given-names>BJ</given-names></name><name><surname>Scott</surname><given-names>K</given-names></name></person-group><year iso-8601-date="2021">2021</year><article-title>Classification and genetic targeting of cell types in the primary taste and premotor center of the adult <italic>Drosophila</italic> brain</article-title><source>eLife</source><volume>10</volume><elocation-id>e71679</elocation-id><pub-id pub-id-type="doi">10.7554/eLife.71679</pub-id></element-citation></ref><ref id="bib76"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Suver</surname><given-names>MP</given-names></name><name><surname>Huda</surname><given-names>A</given-names></name><name><surname>Iwasaki</surname><given-names>N</given-names></name><name><surname>Safarik</surname><given-names>S</given-names></name><name><surname>Dickinson</surname><given-names>MH</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>An array of descending visual interneurons encoding self-motion in <italic>Drosophila</italic></article-title><source>The Journal of Neuroscience</source><volume>36</volume><fpage>11768</fpage><lpage>11780</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.2277-16.2016</pub-id><pub-id pub-id-type="pmid">27852783</pub-id></element-citation></ref><ref id="bib77"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Tanaka</surname><given-names>R</given-names></name><name><surname>Clark</surname><given-names>DA</given-names></name></person-group><year iso-8601-date="2022">2022</year><article-title>Neural mechanisms to exploit positional geometry for collision avoidance</article-title><source>Current Biology</source><volume>32</volume><fpage>2357</fpage><lpage>2374</lpage><pub-id pub-id-type="doi">10.1016/j.cub.2022.04.023</pub-id><pub-id pub-id-type="pmid">35508172</pub-id></element-citation></ref><ref id="bib78"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Tastekin</surname><given-names>I</given-names></name><name><surname>Riedl</surname><given-names>J</given-names></name><name><surname>Schilling-Kurz</surname><given-names>V</given-names></name><name><surname>Gomez-Marin</surname><given-names>A</given-names></name><name><surname>Truman</surname><given-names>JW</given-names></name><name><surname>Louis</surname><given-names>M</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>Role of the subesophageal zone in sensorimotor control of orientation in <italic>Drosophila</italic> larva</article-title><source>Current Biology</source><volume>25</volume><fpage>1448</fpage><lpage>1460</lpage><pub-id pub-id-type="doi">10.1016/j.cub.2015.04.016</pub-id><pub-id pub-id-type="pmid">25959970</pub-id></element-citation></ref><ref id="bib79"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Triphan</surname><given-names>T</given-names></name><name><surname>Poeck</surname><given-names>B</given-names></name><name><surname>Neuser</surname><given-names>K</given-names></name><name><surname>Strauss</surname><given-names>R</given-names></name></person-group><year iso-8601-date="2010">2010</year><article-title>Visual targeting of motor actions in climbing <italic>Drosophila</italic></article-title><source>Current Biology</source><volume>20</volume><fpage>663</fpage><lpage>668</lpage><pub-id pub-id-type="doi">10.1016/j.cub.2010.02.055</pub-id><pub-id pub-id-type="pmid">20346674</pub-id></element-citation></ref><ref id="bib80"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Virtanen</surname><given-names>P</given-names></name><name><surname>Gommers</surname><given-names>R</given-names></name><name><surname>Oliphant</surname><given-names>TE</given-names></name><name><surname>Haberland</surname><given-names>M</given-names></name><name><surname>Reddy</surname><given-names>T</given-names></name><name><surname>Cournapeau</surname><given-names>D</given-names></name><name><surname>Burovski</surname><given-names>E</given-names></name><name><surname>Peterson</surname><given-names>P</given-names></name><name><surname>Weckesser</surname><given-names>W</given-names></name><name><surname>Bright</surname><given-names>J</given-names></name><name><surname>van der Walt</surname><given-names>SJ</given-names></name><name><surname>Brett</surname><given-names>M</given-names></name><name><surname>Wilson</surname><given-names>J</given-names></name><name><surname>Millman</surname><given-names>KJ</given-names></name><name><surname>Mayorov</surname><given-names>N</given-names></name><name><surname>Nelson</surname><given-names>ARJ</given-names></name><name><surname>Jones</surname><given-names>E</given-names></name><name><surname>Kern</surname><given-names>R</given-names></name><name><surname>Larson</surname><given-names>E</given-names></name><name><surname>Carey</surname><given-names>CJ</given-names></name><name><surname>Polat</surname><given-names>İ</given-names></name><name><surname>Feng</surname><given-names>Y</given-names></name><name><surname>Moore</surname><given-names>EW</given-names></name><name><surname>VanderPlas</surname><given-names>J</given-names></name><name><surname>Laxalde</surname><given-names>D</given-names></name><name><surname>Perktold</surname><given-names>J</given-names></name><name><surname>Cimrman</surname><given-names>R</given-names></name><name><surname>Henriksen</surname><given-names>I</given-names></name><name><surname>Quintero</surname><given-names>EA</given-names></name><name><surname>Harris</surname><given-names>CR</given-names></name><name><surname>Archibald</surname><given-names>AM</given-names></name><name><surname>Ribeiro</surname><given-names>AH</given-names></name><name><surname>Pedregosa</surname><given-names>F</given-names></name><name><surname>van Mulbregt</surname><given-names>P</given-names></name><collab>SciPy 1.0 Contributors</collab></person-group><year iso-8601-date="2020">2020</year><article-title>SciPy 1.0: fundamental algorithms for scientific computing in python</article-title><source>Nature Methods</source><volume>17</volume><fpage>261</fpage><lpage>272</lpage><pub-id pub-id-type="doi">10.1038/s41592-019-0686-2</pub-id><pub-id pub-id-type="pmid">32015543</pub-id></element-citation></ref><ref id="bib81"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Voleti</surname><given-names>V</given-names></name><name><surname>Patel</surname><given-names>KB</given-names></name><name><surname>Li</surname><given-names>W</given-names></name><name><surname>Perez Campos</surname><given-names>C</given-names></name><name><surname>Bharadwaj</surname><given-names>S</given-names></name><name><surname>Yu</surname><given-names>H</given-names></name><name><surname>Ford</surname><given-names>C</given-names></name><name><surname>Casper</surname><given-names>MJ</given-names></name><name><surname>Yan</surname><given-names>RW</given-names></name><name><surname>Liang</surname><given-names>W</given-names></name><name><surname>Wen</surname><given-names>C</given-names></name><name><surname>Kimura</surname><given-names>KD</given-names></name><name><surname>Targoff</surname><given-names>KL</given-names></name><name><surname>Hillman</surname><given-names>EMC</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>Real-Time volumetric microscopy of in vivo dynamics and large-scale samples with scape 2.0</article-title><source>Nature Methods</source><volume>16</volume><fpage>1054</fpage><lpage>1062</lpage><pub-id pub-id-type="doi">10.1038/s41592-019-0579-4</pub-id><pub-id pub-id-type="pmid">31562489</pub-id></element-citation></ref><ref id="bib82"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>von Reyn</surname><given-names>CR</given-names></name><name><surname>Breads</surname><given-names>P</given-names></name><name><surname>Peek</surname><given-names>MY</given-names></name><name><surname>Zheng</surname><given-names>GZ</given-names></name><name><surname>Williamson</surname><given-names>WR</given-names></name><name><surname>Yee</surname><given-names>AL</given-names></name><name><surname>Leonardo</surname><given-names>A</given-names></name><name><surname>Card</surname><given-names>GM</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>A spike-timing mechanism for action selection</article-title><source>Nature Neuroscience</source><volume>17</volume><fpage>962</fpage><lpage>970</lpage><pub-id pub-id-type="doi">10.1038/nn.3741</pub-id><pub-id pub-id-type="pmid">24908103</pub-id></element-citation></ref><ref id="bib83"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ward</surname><given-names>JH</given-names></name></person-group><year iso-8601-date="1963">1963</year><article-title>Hierarchical grouping to optimize an objective function</article-title><source>Journal of the American Statistical Association</source><volume>58</volume><fpage>236</fpage><lpage>244</lpage><pub-id pub-id-type="doi">10.1080/01621459.1963.10500845</pub-id></element-citation></ref><ref id="bib84"><element-citation publication-type="preprint"><person-group person-group-type="author"><name><surname>Whiteway</surname><given-names>MR</given-names></name><name><surname>Schaffer</surname><given-names>ES</given-names></name><name><surname>Wu</surname><given-names>A</given-names></name><name><surname>Buchanan</surname><given-names>EK</given-names></name><name><surname>Onder</surname><given-names>OF</given-names></name><name><surname>Mishra</surname><given-names>N</given-names></name><name><surname>Paninski</surname><given-names>L</given-names></name></person-group><year iso-8601-date="2021">2021</year><article-title>Semi-Supervised Sequence Modeling for Improved Behavioral Segmentation</article-title><source>bioRxiv</source><pub-id pub-id-type="doi">10.1101/2021.06.16.448685</pub-id></element-citation></ref><ref id="bib85"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Zacarias</surname><given-names>R</given-names></name><name><surname>Namiki</surname><given-names>S</given-names></name><name><surname>Card</surname><given-names>GM</given-names></name><name><surname>Vasconcelos</surname><given-names>ML</given-names></name><name><surname>Moita</surname><given-names>MA</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>Speed dependent descending control of freezing behavior in <italic>Drosophila melanogaster</italic></article-title><source>Nature Communications</source><volume>9</volume><elocation-id>3697</elocation-id><pub-id pub-id-type="doi">10.1038/s41467-018-05875-1</pub-id></element-citation></ref><ref id="bib86"><element-citation publication-type="software"><person-group person-group-type="author"><name><surname>Zhang</surname><given-names>Y</given-names></name></person-group><year iso-8601-date="2020">2020</year><data-title>Jgcamp8 fast genetically encoded calcium indicators</data-title><source>Jgcamp8</source></element-citation></ref><ref id="bib87"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Zheng</surname><given-names>Z</given-names></name><name><surname>Lauritzen</surname><given-names>JS</given-names></name><name><surname>Perlman</surname><given-names>E</given-names></name><name><surname>Robinson</surname><given-names>CG</given-names></name><name><surname>Nichols</surname><given-names>M</given-names></name><name><surname>Milkie</surname><given-names>D</given-names></name><name><surname>Torrens</surname><given-names>O</given-names></name><name><surname>Price</surname><given-names>J</given-names></name><name><surname>Fisher</surname><given-names>CB</given-names></name><name><surname>Sharifi</surname><given-names>N</given-names></name><name><surname>Calle-Schuler</surname><given-names>SA</given-names></name><name><surname>Kmecova</surname><given-names>L</given-names></name><name><surname>Ali</surname><given-names>IJ</given-names></name><name><surname>Karsh</surname><given-names>B</given-names></name><name><surname>Trautman</surname><given-names>ET</given-names></name><name><surname>Bogovic</surname><given-names>JA</given-names></name><name><surname>Hanslovsky</surname><given-names>P</given-names></name><name><surname>Jefferis</surname><given-names>GSXE</given-names></name><name><surname>Kazhdan</surname><given-names>M</given-names></name><name><surname>Khairy</surname><given-names>K</given-names></name><name><surname>Saalfeld</surname><given-names>S</given-names></name><name><surname>Fetter</surname><given-names>RD</given-names></name><name><surname>Bock</surname><given-names>DD</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>A complete electron microscopy volume of the brain of adult <italic>Drosophila melanogaster</italic></article-title><source>Cell</source><volume>174</volume><fpage>730</fpage><lpage>743</lpage><pub-id pub-id-type="doi">10.1016/j.cell.2018.06.019</pub-id><pub-id pub-id-type="pmid">30033368</pub-id></element-citation></ref><ref id="bib88"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Zorović</surname><given-names>M</given-names></name><name><surname>Hedwig</surname><given-names>B</given-names></name></person-group><year iso-8601-date="2011">2011</year><article-title>Processing of species-specific auditory patterns in the cricket brain by ascending, local, and descending neurons during standing and walking</article-title><source>Journal of Neurophysiology</source><volume>105</volume><fpage>2181</fpage><lpage>2194</lpage><pub-id pub-id-type="doi">10.1152/jn.00416.2010</pub-id><pub-id pub-id-type="pmid">21346206</pub-id></element-citation></ref></ref-list></back><sub-article article-type="editor-report" id="sa0"><front-stub><article-id pub-id-type="doi">10.7554/eLife.81527.sa0</article-id><title-group><article-title>Editor's evaluation</article-title></title-group><contrib-group><contrib contrib-type="author"><name><surname>VijayRaghavan</surname><given-names>K</given-names></name><role specific-use="editor">Reviewing Editor</role><aff><institution-wrap><institution-id institution-id-type="ror">https://ror.org/03ht1xw27</institution-id><institution>National Centre for Biological Sciences, Tata Institute of Fundamental Research</institution></institution-wrap><country>India</country></aff></contrib></contrib-group><related-object id="sa0ro1" object-id-type="id" object-id="10.1101/2022.06.30.497612" link-type="continued-by" xlink:href="https://sciety.org/articles/activity/10.1101/2022.06.30.497612"/></front-stub><body><p>This article uses a genetically encoded calcium indicator to assess neural activity across a population of axons connecting the fly’s brain to its ventral nerve cord while the tethered fly behaves on a floating ball. The preparation and large-scale analysis represent a significant step forward in determining how the brain compresses sensory and state information to convey commands to the ventral nervous system for behavior execution by motor circuits.</p></body></sub-article><sub-article article-type="decision-letter" id="sa1"><front-stub><article-id pub-id-type="doi">10.7554/eLife.81527.sa1</article-id><title-group><article-title>Decision letter</article-title></title-group><contrib-group content-type="section"><contrib contrib-type="editor"><name><surname>VijayRaghavan</surname><given-names>K</given-names></name><role>Reviewing Editor</role><aff><institution-wrap><institution-id institution-id-type="ror">https://ror.org/03ht1xw27</institution-id><institution>National Centre for Biological Sciences, Tata Institute of Fundamental Research</institution></institution-wrap><country>India</country></aff></contrib></contrib-group></front-stub><body><boxed-text id="sa2-box1"><p>Our editorial process produces two outputs: (i) <ext-link ext-link-type="uri" xlink:href="https://sciety.org/articles/activity/10.1101/2022.06.30.497612">public reviews</ext-link> designed to be posted alongside <ext-link ext-link-type="uri" xlink:href="https://www.biorxiv.org/content/10.1101/2022.06.30.497612v1">the preprint</ext-link> for the benefit of readers; (ii) feedback on the manuscript for the authors, including requests for revisions, shown below. We also include an acceptance summary that explains what the editors found interesting or important about the work.</p></boxed-text><p><bold>Decision letter after peer review:</bold></p><p>Thank you for submitting your article &quot;Descending neuron population dynamics during odor-evoked and spontaneous limb-dependent behaviors&quot; for consideration by <italic>eLife</italic>. Your article has been reviewed by 2 peer reviewers, and the evaluation has been overseen by a Reviewing Editor and K VijayRaghavan as the Senior Editor. The reviewers have opted to remain anonymous.</p><p>The reviewers have discussed their reviews with one another, and the Reviewing Editor has drafted this to help you prepare a revised submission.</p><p>Essential revisions:</p><p>The authors use a challenging preparation in which they were able to record from up to 100 DNs simultaneously in tethered flies performing spontaneous and odor-evoked behaviors on a treadmill. They combine their recordings with motion capture approaches and automated behavioral classification, which allows them to correlate DN population activity with behavior on an unprecedented scale. This approach is valuable and adds a different perspective to previously published studies aimed at tying individual, often command-like DNs to different behaviors and characterizing their activity in detail. The authors use relatively complex analysis methods, which is necessary due to the rich behavioral and neuronal activity data sets. In several instances, they verify that their conclusions drawn from the output of their analysis pipeline hold when tested with more simple and common analysis methods (see for example Figures 5g or 4c). After correlating the activity of the DN population with aspects of walking and grooming, they outline an approach that allowed them to identify a single pair of DNs from the population data set. Overall, the study combines several cutting-edge methods and significantly adds to our understanding of descending motor control. For example, the authors demonstrate that a large number of DNs likely contributes to turning, whereas changes in walking speed are encoded, perhaps driven, by fewer, more distributed DNs.</p><p>In our consultation, we agreed that the data and presentation are strong, and the biological findings are important. Some word choices are confusing, and some additional discussion of implications, comparisons, or limits is warranted, but can be achieved with text revision. It is with this in mind that the major points are to be addressed. These points are given below.</p><p>1) The use of the word &quot;encoding&quot; is problematic. It may be best reserved for when we know that a neuron's activity pattern occurs in direct response to specific sensory inputs or causes specific motor outputs. The changes in fluorescence seen here correlate better with certain behaviors than others, but the sensory input is not controlled, the time resolution is limited, and the causality is not shown. The experimental data is fine – but we would describe it as signal correlation rather than encoding.</p><p>We would prefer to see that word – encoding – removed. If not, an early definition and an extended Discussion of the way the authors are using the word with a clear presentation of the caveats would be acceptable.</p><p>2) How do the authors handle statistical significance in rare behaviors or comparisons of correlation strength between behaviors that occur with different frequencies? Turning doesn't happen that often. Particular combinations of joint angles might not be common. If you bin all of the micromovements that compose grooming, you'd aggregate a lot more signal than for any of the individual limb positions. Do you normalize by time? This is a concern for assessing the conclusion that the calcium signal correlates better with higher-order behavior categories (walking or grooming) than it does with shorter, rarer movements or limb positions.</p><p>3) In their experiments, the authors did not perturb the activity of any of the DNs, either by activation or silencing. Moreover, the temporal resolution of the DN population recordings is relatively low compared to, for example, single cell patch-clamp recordings. This is fair given the scope of the study, but as a consequence it remains unclear whether a DN whose activity is correlated with a certain behavior is driving this particular behavior, or whether the DN is activated because the behavior is executed. The latter could for example be due to sensory feedback. This caveat makes it challenging to interpret the results presented since a causal link between DN activity and behavior cannot be assumed. Overall, the authors are relatively careful when interpreting their data, but there are several instances where they overinterpret their findings. These instances need to be addressed and clarified:</p><p>– The statements in line 63ff regarding the reasoning for using an approach that allows parallel recordings from many DNs do not seem ideal for several reasons:</p><p>a) To resolve how different DNs modulate ongoing behavior, it seems the best approach would be to activate these DNs individually or in groups to get an idea of their behavioral effects and establish causality, as opposed to correlating their activity with spontaneous behavior at low temporal resolution.</p><p>b) In order to establish how DNs are recruited depending on sensory context, it would seem more important to provide a large variety of sensory contexts rather than recording from many neurons at the same time. It would be perfectly fine to establish sensory context for one DN at a time.</p><p>c) If one main goal was to establish whether DNs provide raw sensory information or processed, abstract commands, it would seem more important to have precise control over sensory stimuli and perhaps a higher temporal resolution on the DN activity readout rather than recording from multiple DNs in spontaneously behaving flies at relatively low temporal resolution.</p><p>The approach used by the authors is very valuable and it provides insights that single neuron recordings or optogenetic activation will never be able to deliver, but the reasons stated in the introduction do not really highlight the strengths of the present study.</p><p>4) – Line 82ff: The experiments presented do not rule out a strong context-dependence of DN activity in general. They merely show that many of the DNs found to 'encode' aspects of walking and grooming do so independently of whether the behavior was spontaneous or facilitated by olfactory stimulation. However, it is absolutely conceivable that different subsets of DNs control turning when it is induced by visual vs. mechanosensory vs. unilateral olfactory cues, for example. As far as I can see, this possibility has not been explored or tested in any of the experiments presented.</p><p>5) – l. 89: 'global view' seems overstated given that the authors recorded from &lt;100 out of about 1000 DNs (in one species). It is certainly a wider view than we had before!</p><p>6) – In l. 167, the authors suggest that DNs encode high-level behaviors and in l. 136f they speculate that DNs likely drive these behaviors. This would seem like a reasonable assumption for descending neurons. However, when the authors follow up on one of the DNs they identified individually using EM tracing and a sparse driver lines, they actually show that this particular DN (DNx01) neither encodes high-level behaviors, nor does it seem to drive the behavior its activity is most strongly correlated with (head grooming). Instead, DNx01 seems to convey simple, mechanosensory inputs from the antennae to the VNC (figure 5g). How do the authors reconcile this observation with the general underlying assumption that the large majority of DNs they recorded drive behavior rather than encode sensory feedback?</p><p>7) – It seems that it was possible to identify the DNx01s due to their strong sensory responses and large axons that were easily distinguishable in EM stacks and functional imaging. It would be nice if the authors could discuss a little further whether and how it will be feasible to expand this approach to other DNs in the future.</p><p>8) In l. 254, the authors suggest that turning might be driven by asymmetries in VNC networks rather than by asymmetric activation of VNC networks via DNs. This model is hard to reconcile with existing knowledge about motor control. It is possible for VNC networks to independently generate asymmetric activity of course (for example in response to unilateral local sensory inputs). However, if DNs are not asymmetrically activated to drive turning, how would the brain be able to drive voluntary turns? What is the underlying model?</p><p>9) The authors use NeuroMechFly, a biomechanical simulation of the <italic>Drosophila</italic> body, to play back movements recorded by their motion capturing pipeline and detect collisions between the front legs and the right and left antennae. What is the reason for using such an indirect approach to detect potential antennal deflections? It seems the authors should be able to detect antennal deflections unambiguously in their video recordings. From looking at the supplemental videos, the leg movements of the model and the fly do not always seem to match perfectly (as would be expected from an approximation). Did the authors verify that their predictions were accurate?</p><p>10) The definition of 'posterior movement' (l.127) is vague. Does this include every instance of abdominal bending? Were hind leg movements and abdominal bending treated the same way in the analysis? Why would that be a reasonable simplification? It would be nice if the authors could expand on this a little bit.</p><p>11) The Discussion of the implications should be expanded, in particular, to include parallels to the ascending neurons, whose activity also seems to correlate with higher order/larger scale representations. An explicit comparison to electrophysiological recordings of DNs should be included. An advantage of calcium imaging over electrophysiological recordings is the population aspect – signal can be compared among neurons to determine patterns and co-activation. How was this employed here? Why express GCaMP in most DNs at once, rather than in specific DN split GAL4 lines? Whether fluorescence changes correlated with behaviors could have been explored in both cases.</p></body></sub-article><sub-article article-type="reply" id="sa2"><front-stub><article-id pub-id-type="doi">10.7554/eLife.81527.sa2</article-id><title-group><article-title>Author response</article-title></title-group></front-stub><body><disp-quote content-type="editor-comment"><p>Essential revisions:</p><p>The authors use a challenging preparation in which they were able to record from up to 100 DNs simultaneously in tethered flies performing spontaneous and odor-evoked behaviors on a treadmill. They combine their recordings with motion capture approaches and automated behavioral classification, which allows them to correlate DN population activity with behavior on an unprecedented scale. This approach is valuable and adds a different perspective to previously published studies aimed at tying individual, often command-like DNs to different behaviors and characterizing their activity in detail. The authors use relatively complex analysis methods, which is necessary due to the rich behavioral and neuronal activity data sets. In several instances, they verify that their conclusions drawn from the output of their analysis pipeline hold when tested with more simple and common analysis methods (see for example Figures 5g or 4c). After correlating the activity of the DN population with aspects of walking and grooming, they outline an approach that allowed them to identify a single pair of DNs from the population data set. Overall, the study combines several cutting-edge methods and significantly adds to our understanding of descending motor control. For example, the authors demonstrate that a large number of DNs likely contributes to turning, whereas changes in walking speed are encoded, perhaps driven, by fewer, more distributed DNs.</p></disp-quote><p>We thank the Editor and Reviewers for their positive appreciation of our work.</p><disp-quote content-type="editor-comment"><p>In our consultation, we agreed that the data and presentation are strong, and the biological findings are important. Some word choices are confusing, and some additional discussion of implications, comparisons, or limits is warranted, but can be achieved with text revision. It is with this in mind that the major points are to be addressed. These points are given below.</p><p>1) The use of the word &quot;encoding&quot; is problematic. It may be best reserved for when we know that a neuron's activity pattern occurs in direct response to specific sensory inputs or causes specific motor outputs. The changes in fluorescence seen here correlate better with certain behaviors than others, but the sensory input is not controlled, the time resolution is limited, and the causality is not shown. The experimental data is fine – but we would describe it as signal correlation rather than encoding.</p><p>We would prefer to see that word – encoding – removed. If not, an early definition and an extended Discussion of the way the authors are using the word with a clear presentation of the caveats would be acceptable.</p></disp-quote><p>We agree that this is an interesting point for discussion. Notably, other laboratories have also previously described the ‘encoding’ of insect descending neurons (e.g., in locust: J.R. Gray et al., <italic>J. Comp Physiol A</italic>, 2010; in <italic>Drosophila</italic>: M. Suver et al., <italic>J. Neurosci.</italic> 2016; in flies: S. Nicolas et al., <italic>J. Neurosci.</italic>, 2018; in stick insects: B. Jaske et al., <italic>J. Neurophysiol.</italic>, 2021). This word is less cumbersome than the full phrase ‘the activity of X neuron is correlated with Y’. Therefore, in one instance we have exchanged “encoding” for “is active during” but we have otherwise opted to use the word “encoding” in the manuscript. As suggested, we provide an early definition and discussion of the way we are using the word with a presentation of caveats.</p><disp-quote content-type="editor-comment"><p>2) How do the authors handle statistical significance in rare behaviors or comparisons of correlation strength between behaviors that occur with different frequencies? Turning doesn't happen that often. Particular combinations of joint angles might not be common. If you bin all of the micromovements that compose grooming, you'd aggregate a lot more signal than for any of the individual limb positions. Do you normalize by time? This is a concern for assessing the conclusion that the calcium signal correlates better with higher-order behavior categories (walking or grooming) than it does with shorter, rarer movements or limb positions.</p></disp-quote><p>The relative frequencies of different behaviors is an important consideration when quantifying their correlations with DN activity. We found a strong encoding of turning among many DNs (Figure 3 and Figure 3 —figure supplement 2 (previously Figure S7)) suggesting that there are sufficient examples of this behavior. In the case of more rare behaviors we addressed these concerns by balancing the data. In other words, we ensure that an equal amount of each behavior is used to calculate relative encoding. This was particularly important in the case of rare behaviors that are likely to occur after more common actions. Specifically, in Figure 2 —figure supplement 1 (previously Figure S2), we balanced the data to confirm that DNs encode walking rather than posterior movements, and that other DNs encode head grooming rather than front leg rubbing.</p><p>With respect to joint angle probabilities, in the revised manuscript we now include a new analysis (new Figure 1 —figure supplement 2) which shows that a wide range of joint angles are measured for different leg joint degrees of freedom. In particular, we find a wider distribution of FTi pitch angles compared with ThC pitch angles.</p><disp-quote content-type="editor-comment"><p>3) In their experiments, the authors did not perturb the activity of any of the DNs, either by activation or silencing. Moreover, the temporal resolution of the DN population recordings is relatively low compared to, for example, single cell patch-clamp recordings. This is fair given the scope of the study, but as a consequence it remains unclear whether a DN whose activity is correlated with a certain behavior is driving this particular behavior, or whether the DN is activated because the behavior is executed. The latter could for example be due to sensory feedback. This caveat makes it challenging to interpret the results presented since a causal link between DN activity and behavior cannot be assumed. Overall, the authors are relatively careful when interpreting their data, but there are several instances where they overinterpret their findings. These instances need to be addressed and clarified:</p><p>– The statements in line 63ff regarding the reasoning for using an approach that allows parallel recordings from many DNs do not seem ideal for several reasons:</p><p>a) To resolve how different DNs modulate ongoing behavior, it seems the best approach would be to activate these DNs individually or in groups to get an idea of their behavioral effects and establish causality, as opposed to correlating their activity with spontaneous behavior at low temporal resolution.</p></disp-quote><p>We agree with the Reviewer that to establish causality it would be best to activate groups of DNs in behaving animals (i.e., as in Cande et al., <italic>eLife</italic> 2018 but for multiple DN classes at once). However, this approach is currently technically challenging for several reasons. First, it is not yet clear how one might target many different arbitrary combinations of DNs using existing genetic reagents. For example, simply combining split-Gal4 driver lines can lead to off-target expression and does not permit the co-activation of more than several DN classes at once. This approach also yields a massive combinatorial space of required experiments. Our approach of measuring the population code of DNs is an important step toward motivating specific co-activation experiments in future work.</p><p>We note that a future alternative could be to perform spatially restricted (e.g., SLM-based) optogenetic activation of multiple DN axons in the neck connective of behaving animals. However, the axial resolution of SLM-based stimulation is too broad with respect to the size of DN axons. As well, experiments in behaving animals suffer from constant tissue movement and deformation. This makes precise optogenetic targeting impossible without extremely fast closed-loop stimulation control.</p><disp-quote content-type="editor-comment"><p>b) In order to establish how DNs are recruited depending on sensory context, it would seem more important to provide a large variety of sensory contexts rather than recording from many neurons at the same time. It would be perfectly fine to establish sensory context for one DN at a time.</p><p>c) If one main goal was to establish whether DNs provide raw sensory information or processed, abstract commands, it would seem more important to have precise control over sensory stimuli and perhaps a higher temporal resolution on the DN activity readout rather than recording from multiple DNs in spontaneously behaving flies at relatively low temporal resolution.</p><p>The approach used by the authors is very valuable and it provides insights that single neuron recordings or optogenetic activation will never be able to deliver, but the reasons stated in the introduction do not really highlight the strengths of the present study.</p></disp-quote><p>We agree with the Reviewer that measuring individual DNs’ precise responses to a wide panel of sensory stimuli is a valuable and complementary approach to population recordings. However, we note that the proposed investigation requires a combinatorially massive number of experiments given (i) the number of different DN classes and (ii) the vast number of sensory cues across visual, olfactory, gustatory, and mechanosensory modalities. We believe that population recordings can therefore contribute to this endeavor by enabling the more rapid investigation of sensory-based recruitment of DNs in future work. We discuss these points in the Introduction of the revised manuscript.</p><disp-quote content-type="editor-comment"><p>4) – Line 82ff: The experiments presented do not rule out a strong context-dependence of DN activity in general. They merely show that many of the DNs found to 'encode' aspects of walking and grooming do so independently of whether the behavior was spontaneous or facilitated by olfactory stimulation. However, it is absolutely conceivable that different subsets of DNs control turning when it is induced by visual vs. mechanosensory vs. unilateral olfactory cues, for example. As far as I can see, this possibility has not been explored or tested in any of the experiments presented.</p></disp-quote><p>We agree with the Reviewer that generalizing our findings across a wider panel of sensory stimuli is a valuable future direction. Therefore, in the revised manuscript’s Introduction we now state:</p><p>“These data suggest a lack of strong context dependence in DN population recruitment. In the future, this finding can be strengthened and made more general by examining DN population activity in the presence of other visual, mechanosensory and olfactory cues.”</p><disp-quote content-type="editor-comment"><p>5) – l. 89: 'global view' seems overstated given that the authors recorded from &lt;100 out of about 1000 DNs (in one species). It is certainly a wider view than we had before!</p></disp-quote><p>We have modified the text to read “…an expansive view…”.</p><disp-quote content-type="editor-comment"><p>6) – In l. 167, the authors suggest that DNs encode high-level behaviors and in l. 136f they speculate that DNs likely drive these behaviors. This would seem like a reasonable assumption for descending neurons. However, when the authors follow up on one of the DNs they identified individually using EM tracing and a sparse driver lines, they actually show that this particular DN (DNx01) neither encodes high-level behaviors, nor does it seem to drive the behavior its activity is most strongly correlated with (head grooming). Instead, DNx01 seems to convey simple, mechanosensory inputs from the antennae to the VNC (figure 5g). How do the authors reconcile this observation with the general underlying assumption that the large majority of DNs they recorded drive behavior rather than encode sensory feedback?</p></disp-quote><p>We believe that DNx01 is likely exceptional in encoding sensory feedback. This is underpinned by its unusually large caliber axons. However, we do not exclude the possibility that selective DNx01 activation may drive or suppress specific behaviors (e.g., generating a stance stabilization reflex to strong gusts of wind). As we now state in the Discussion of the revised manuscript, testing this hypothesis will require the generation of a sparse and selective DNx01 sparse driver line.</p><disp-quote content-type="editor-comment"><p>7) – It seems that it was possible to identify the DNx01s due to their strong sensory responses and large axons that were easily distinguishable in EM stacks and functional imaging. It would be nice if the authors could discuss a little further whether and how it will be feasible to expand this approach to other DNs in the future.</p></disp-quote><p>We agree with the Reviewer that the identification of DNx01s was facilitated by the unique properties of these neurons. We believe that additional tools may be required to expand this approach to arbitrary DNs in the future. We now state in the revised manuscript:</p><p>“Our analysis of DNx01 illustrates a potential road map for combining functional, topological, and morphological data to uncover the identity of individual DNs from population recordings. Notably, our efforts were facilitated by DNx01's unusual bilaterally asymmetric functional properties and large caliber axons. Taking this route to identify another, arbitrary DN would likely be more challenging and may require additional tools. For example, after functional imaging of DN populations, one might focally photoactivate GFP within individual DN axons of interest (Datta et al., 2008; Ruta et al., 2010). Subsequent morphological imaging could then be compared with DNs reconstructed in connectomics datasets (Zheng et al., 2018; Phelps et al., 2021).”</p><disp-quote content-type="editor-comment"><p>8) In l. 254, the authors suggest that turning might be driven by asymmetries in VNC networks rather than by asymmetric activation of VNC networks via DNs. This model is hard to reconcile with existing knowledge about motor control. It is possible for VNC networks to independently generate asymmetric activity of course (for example in response to unilateral local sensory inputs). However, if DNs are not asymmetrically activated to drive turning, how would the brain be able to drive voluntary turns? What is the underlying model?</p></disp-quote><p>We agree with the Reviewer that this model is not well-supported by evidence regarding the asymmetric DN control of steering. For example, asymmetric DNa01 activity has been associated with steering (Chen, Hermans et al., <italic>Nature Communications</italic> 2018; Rayshubksy <italic>bioRxiv</italic>, 2021) and unilateral MDN stimulation yield backward turning (Sen et al., <italic>Current Biology</italic> 2017). Therefore, we have removed this model from our revised manuscript.</p><p>We now state: “Simple models for locomotor control (Braitenberg, 1986) suggest that turning can be controlled by the relative activities of DNs on one side of the brain versus the other. This is supported by studies showing that flies generate turning during asymmetric activation or asymmetric activity of DNa01 neurons (Chen, Hermans et al., 2018; Rayshubskiy et al., 2020) and MDNs (Sen et al., 2017). To examine the degree to which this spatial asymmetry extends beyond pairs of neurons to much larger DN populations, we quantified the spatial location of turn-encoding DNs in the cervical connective.”</p><disp-quote content-type="editor-comment"><p>9) The authors use NeuroMechFly, a biomechanical simulation of the <italic>Drosophila</italic> body, to play back movements recorded by their motion capturing pipeline and detect collisions between the front legs and the right and left antennae. What is the reason for using such an indirect approach to detect potential antennal deflections? It seems the authors should be able to detect antennal deflections unambiguously in their video recordings. From looking at the supplemental videos, the leg movements of the model and the fly do not always seem to match perfectly (as would be expected from an approximation). Did the authors verify that their predictions were accurate?</p></disp-quote><p>We used NeuroMechFly to quantify collisions between the front legs and antennae because it provides a relatively rapid way to quantify contacts and, most importantly, because it is surprisingly difficult to confidently manually detect collisions in our low contrast camera images. This is because the cameras were intentionally focused on the legs to facilitate DeepFly3D joint pose estimation and the focal depth is not sufficient to resolve both the antennae and legs at sufficiently high contrast. We selected the data for Video 5 as the most clear example of individual legs contacting individual antennae. We agree with the Reviewer that future work focusing on leg-antennal contacts should explicitly include an in-depth manual validation like that performed to verify leg-ground contacts in the manuscript for NeuroMechFly (Lobato-Ríos et al., 2022, Extended Data Figure 7).</p><disp-quote content-type="editor-comment"><p>10) The definition of 'posterior movement' (l.127) is vague. Does this include every instance of abdominal bending? Were hind leg movements and abdominal bending treated the same way in the analysis? Why would that be a reasonable simplification? It would be nice if the authors could expand on this a little bit.</p></disp-quote><p>Classified behaviors were quantified using leg joint angles. Thus, ‘posterior movements’ do not include every instance of abdominal bending. Initially, our behavior classification included separate classes for hindleg grooming and abdominal grooming. However, these behaviors were rare and highly overlapping in our confusion matrix. Therefore, we grouped them together. We now expand on the definition of ‘posterior movements’ in the revised manuscript. We state:</p><p>“…and posterior movements (a grouping of rare hindleg and abdominal grooming movements)”.</p><disp-quote content-type="editor-comment"><p>11) The Discussion of the implications should be expanded, in particular, to include parallels to the ascending neurons, whose activity also seems to correlate with higher order/larger scale representations.</p></disp-quote><p>In the Discussion of the revised manuscript we now state: “Interestingly, many ascending neurons (AN) have also been shown to encode walking (Chen et al., <italic>bioRxiv</italic> 2022; Fujiwara et al., <italic>Neuron</italic> 2022) with a large fraction projecting to the gnathal ganglia (GNG), a brain region that is also heavily innervated by DNs (Namiki et al., <italic>eLife</italic> 2018). Thus, we speculate that ANs and DNs may be directly connected---possibly to mediate action selection (Mann et al., <italic>Neuron</italic> 2013; Bidaye et al., <italic>Science</italic> 2014)---and that this may lead to similar functional encoding.”</p><disp-quote content-type="editor-comment"><p>An explicit comparison to electrophysiological recordings of DNs should be included. An advantage of calcium imaging over electrophysiological recordings is the population aspect – signal can be compared among neurons to determine patterns and co-activation. How was this employed here?</p></disp-quote><p>In the Discussion of the revised manuscript we now state:</p><p>“Although electrophysiology provides higher temporal resolution (e.g., measuring spike timing (Von reyn et al., <italic>Nature Neuroscience</italic> 2014)), neural population imaging serves an important complementary role in capturing the proportion and spatial locations of co-active neurons.”</p><disp-quote content-type="editor-comment"><p>Why express GCaMP in most DNs at once, rather than in specific DN split GAL4 lines? Whether fluorescence changes correlated with behaviors could have been explored in both cases.</p></disp-quote><p>In the Discussion of the revised manuscript we now state: “Electrophysiological recordings and calcium imaging of sparse DN driver lines can more easily enable links to be made between neural encoding and cellular identity. However, these approaches suffer from two major disadvantages. First, there exist split-Gal4 driver lines for only a small fraction of DNs (Namiki et al., <italic>eLife</italic> 2018). Second, determining the encoding of an equivalent number of neurons requires many more sparse neural recordings than population imaging experiments. Therefore, by focusing on population imaging our study allowed us to more rapidly survey the encoding of a large number of DNs.”</p></body></sub-article></article>