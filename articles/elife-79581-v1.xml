<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD v1.1d3 20150301//EN"  "JATS-archivearticle1.dtd"><article xmlns:xlink="http://www.w3.org/1999/xlink" article-type="research-article" dtd-version="1.1d3"><front><journal-meta><journal-id journal-id-type="nlm-ta">elife</journal-id><journal-id journal-id-type="publisher-id">eLife</journal-id><journal-title-group><journal-title>eLife</journal-title></journal-title-group><issn publication-format="electronic">2050-084X</issn><publisher><publisher-name>eLife Sciences Publications, Ltd</publisher-name></publisher></journal-meta><article-meta><article-id pub-id-type="publisher-id">79581</article-id><article-id pub-id-type="doi">10.7554/eLife.79581</article-id><article-categories><subj-group subj-group-type="display-channel"><subject>Research Article</subject></subj-group><subj-group subj-group-type="heading"><subject>Computational and Systems Biology</subject></subj-group></article-categories><title-group><article-title>Quantifying dynamic facial expressions under naturalistic conditions</article-title></title-group><contrib-group><contrib contrib-type="author" corresp="yes" id="author-277070"><name><surname>Jeganathan</surname><given-names>Jayson</given-names></name><contrib-id contrib-id-type="orcid">http://orcid.org/0000-0003-4175-918X</contrib-id><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="corresp" rid="cor1">*</xref><xref ref-type="other" rid="par-1"/><xref ref-type="other" rid="par-2"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" id="author-278435"><name><surname>Campbell</surname><given-names>Megan</given-names></name><contrib-id contrib-id-type="orcid">http://orcid.org/0000-0003-4051-1529</contrib-id><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" id="author-278436"><name><surname>Hyett</surname><given-names>Matthew</given-names></name><xref ref-type="aff" rid="aff2">2</xref><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" id="author-278437"><name><surname>Parker</surname><given-names>Gordon</given-names></name><xref ref-type="aff" rid="aff3">3</xref><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" id="author-189435"><name><surname>Breakspear</surname><given-names>Michael</given-names></name><contrib-id contrib-id-type="orcid">http://orcid.org/0000-0003-4943-3969</contrib-id><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="other" rid="par-2"/><xref ref-type="other" rid="par-3"/><xref ref-type="other" rid="par-4"/><xref ref-type="fn" rid="conf1"/></contrib><aff id="aff1"><institution content-type="dept">School of Psychology</institution>, <institution>University of Newcastle Australia</institution>, <addr-line><named-content content-type="city">Newcastle</named-content></addr-line>, <country>Australia</country></aff><aff id="aff2"><institution content-type="dept">School of Psychological Sciences</institution>, <institution>University of Western Australia</institution>, <addr-line><named-content content-type="city">Perth</named-content></addr-line>, <country>Australia</country></aff><aff id="aff3"><institution content-type="dept">School of Psychiatry</institution>, <institution>University of New South Wales</institution>, <addr-line><named-content content-type="city">Kensington</named-content></addr-line>, <country>Australia</country></aff></contrib-group><contrib-group content-type="section"><contrib contrib-type="editor" id="author-133489"><name><surname>Shackman</surname><given-names>Alexander</given-names></name><role>Reviewing editor</role><aff><institution>University of Maryland</institution>, <country>United States</country></aff></contrib></contrib-group><author-notes><corresp id="cor1"><label>*</label>For correspondence: <email>jayson.jeganathan@gmail.com</email> (JJ);</corresp></author-notes><pub-date date-type="pub" publication-format="electronic"><day>31</day><month>08</month><year>2022</year></pub-date><volume>11</volume><elocation-id>e79581</elocation-id><history><date date-type="received"><day>19</day><month>04</month><year>2022</year></date><date date-type="accepted"><day>24</day><month>08</month><year>2022</year></date></history><permissions><copyright-statement>Â© 2022, Jeganathan et al</copyright-statement><copyright-year>2022</copyright-year><copyright-holder>Jeganathan et al</copyright-holder><license xlink:href="http://creativecommons.org/licenses/by/4.0/"><license-p>This article is distributed under the terms of the <ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/licenses/by/4.0/">Creative Commons Attribution License</ext-link> permitting unrestricted use and redistribution provided that the original author and source are credited.</license-p></license></permissions><self-uri content-type="pdf" xlink:href="elife-79581-v1.pdf"/><abstract><p>Facial affect is expressed dynamically - a giggle, grimace, or an agitated frown. However, the characterization of human affect has relied almost exclusively on static images. This approach cannot capture the nuances of human communication or support the naturalistic assessment of affective disorders. Using the latest in machine vision and systems modelling, we studied dynamic facial expressions of people viewing emotionally salient film clips. We found that the apparent complexity of dynamic facial expressions can be captured by a small number of simple spatiotemporal states - composites of distinct facial actions, each expressed with a unique spectral fingerprint. Sequential expression of these states is common across individuals viewing the same film stimuli but varies in those with the melancholic subtype of major depressive disorder. This approach provides a platform for translational research, capturing dynamic facial expressions under naturalistic conditions and enabling new quantitative tools for the study of affective disorders and related mental illnesses.</p></abstract><kwd-group kwd-group-type="research-organism"><title>Research organism</title><kwd>Human</kwd></kwd-group><funding-group><award-group id="par-1"><funding-source><institution-wrap><institution>Health Education and Training Institute Award in Psychiatry and Mental Health</institution></institution-wrap></funding-source><principal-award-recipient><name><surname>Jeganathan</surname><given-names>Jayson</given-names></name></principal-award-recipient></award-group><award-group id="par-2"><funding-source><institution-wrap><institution>Rainbow Foundation</institution></institution-wrap></funding-source><principal-award-recipient><name><surname>Jeganathan</surname><given-names>Jayson</given-names></name><name><surname>Breakspear</surname><given-names>Michael</given-names></name></principal-award-recipient></award-group><award-group id="par-3"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/501100000925</institution-id><institution>National Health and Medical Research Council</institution></institution-wrap></funding-source><award-id>1118153,10371296,1095227</award-id><principal-award-recipient><name><surname>Breakspear</surname><given-names>Michael</given-names></name></principal-award-recipient></award-group><award-group id="par-4"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/501100000923</institution-id><institution>Australian Research Council</institution></institution-wrap></funding-source><award-id>CE140100007</award-id><principal-award-recipient><name><surname>Breakspear</surname><given-names>Michael</given-names></name></principal-award-recipient></award-group><funding-statement>The funders had no role in study design, data collection and interpretation, or the decision to submit the work for publication.</funding-statement></funding-group></article-meta></front><back><sec id="s1" sec-type="additional-information"><title>Additional information</title><fn-group content-type="competing-interest"><title>Competing interest</title><fn fn-type="conflict" id="conf1"><p>The authors declare that no competing interests exist.</p></fn></fn-group><fn-group content-type="ethics-information"><title>Ethics</title><fn fn-type="other"><p>Human subjects: Participants provided informed consent for the study. Ethics approval was obtained from the University of New South Wales (HREC-08077) and the University of Newcastle (H-2020-0137). Figure 1a shows images of a person's face from the DISFA dataset. Consent to reproduce their image in publications was obtained by the original DISFA authors, and is detailed in the dataset agreement (http://mohammadmahoor.com/disfa-contact-form/) and the original paper (https://ieeexplore.ieee.org/document/6475933).</p></fn></fn-group></sec><sec id="s2" sec-type="supplementary-material"><title>Additional Files</title><sec id="s3" sec-type="data-availability"><title>Data availability</title><p>The DISFA dataset is publically available at http://mohammadmahoor.com/disfa/, and can be accessed by application at http://mohammadmahoor.com/disfa-contact-form/. The melancholia dataset is not publically available due to ethical and privacy considerations for patients, and because the original ethics approval does not permit sharing this data.</p><p>The following previously published datasets were used:</p><p><element-citation id="dataset1" publication-type="data" specific-use="references"><person-group person-group-type="author"><collab>avadati SM</collab><collab>Mahoor MH</collab><collab>Bartlett K</collab><collab>Trinh P</collab><collab>Cohn JF</collab></person-group><year iso-8601-date="2013">2013</year><source>DISFA: A Spontaneous Facial Action Intensity Database</source><ext-link ext-link-type="uri" xlink:href="http://mohammadmahoor.com/disfa/">http://mohammadmahoor.com/disfa/</ext-link><comment>http://mohammadmahoor.com/</comment></element-citation></p></sec><supplementary-material><ext-link xlink:href="elife-79581-supp-v1.zip">Download zip</ext-link><p>Any figures and tables for this article are included in the PDF. The zip folder contains additional supplemental files.</p></supplementary-material></sec></back></article>